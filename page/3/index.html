
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/3/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CL_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.CL_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.CL_2023_08_22/">cs.CL - 2023-08-22 19:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Empowering-Refugee-Claimants-and-their-Lawyers-Using-Machine-Learning-to-Examine-Decision-Making-in-Refugee-Law"><a href="#Empowering-Refugee-Claimants-and-their-Lawyers-Using-Machine-Learning-to-Examine-Decision-Making-in-Refugee-Law" class="headerlink" title="Empowering Refugee Claimants and their Lawyers: Using Machine Learning to Examine Decision-Making in Refugee Law"></a>Empowering Refugee Claimants and their Lawyers: Using Machine Learning to Examine Decision-Making in Refugee Law</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11531">http://arxiv.org/abs/2308.11531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Claire Barale</li>
<li>For: This paper aims to help stakeholders in refugee status adjudications, such as lawyers, judges, governing bodies, and claimants, make better decisions through data-driven intelligence and increase understanding and transparency of the refugee application process.* Methods: The paper presents a completed experiment on retrieving past cases and ongoing efforts related to analyzing legal decision-making processes on a dataset of Canadian cases, using NLP-based solutions.* Results: The paper introduces a novel benchmark for future NLP research in refugee law and expects to achieve benefits such as reduced time-to-decision, fairer and more transparent outcomes, and improved decision quality.Here are the three points in Simplified Chinese text:* For: 这个论文旨在帮助难民地位评估中的潜在利益相关者，如律师、法官、管理机构和申请人，通过数据驱动智能来做出更好的决策，并提高难民申请过程中所有参与者的理解和透明度。* Methods: 论文提出了一个完成的实验，涉及到过去案例的收集，以及对加拿大案例集进行法律决策过程的分析，使用NLP技术解决问题。* Results: 论文引入了一个新的NLP研究 benchmark，预计可以实现减少决策时间、提高决策质量、更公平和透明的决策结果等利益。<details>
<summary>Abstract</summary>
Our project aims at helping and supporting stakeholders in refugee status adjudications, such as lawyers, judges, governing bodies, and claimants, in order to make better decisions through data-driven intelligence and increase the understanding and transparency of the refugee application process for all involved parties. This PhD project has two primary objectives: (1) to retrieve past cases, and (2) to analyze legal decision-making processes on a dataset of Canadian cases. In this paper, we present the current state of our work, which includes a completed experiment on part (1) and ongoing efforts related to part (2). We believe that NLP-based solutions are well-suited to address these challenges, and we investigate the feasibility of automating all steps involved. In addition, we introduce a novel benchmark for future NLP research in refugee law. Our methodology aims to be inclusive to all end-users and stakeholders, with expected benefits including reduced time-to-decision, fairer and more transparent outcomes, and improved decision quality.
</details>
<details>
<summary>摘要</summary>
我们的项目的目标是帮助和支持难民地位审批相关方，如律师、法官、管理机构和申请人，以使更好的决策。我们通过数据驱动智能来增加所有参与方的理解和透明度，并提高决策的质量。这个博士项目有两个主要目标：（1）检索历史案例，（2）分析加拿大案例的法律决策过程。在这篇论文中，我们介绍了我们的当前工作，包括已经完成的试验部分（1）以及正在进行的努力（2）。我们认为，NLP技术非常适合解决这些挑战，我们正在调查是否可以自动化所有步骤。此外，我们还介绍了一个新的标准测试集，用于未来NLP研究领域的难民法。我们的方法旨在包容所有终端用户和参与方，期望的利益包括减少时间决策、更公平和透明的结果，以及改善决策质量。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Prototype-Adapter-for-Vision-Language-Models"><a href="#Unsupervised-Prototype-Adapter-for-Vision-Language-Models" class="headerlink" title="Unsupervised Prototype Adapter for Vision-Language Models"></a>Unsupervised Prototype Adapter for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11507">http://arxiv.org/abs/2308.11507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He</li>
<li>for: 本研究旨在提高视觉语言模型的适应性，并且不需要大量的标注样本。</li>
<li>methods: 我们提出了一种无监督的训练方法，通过CLIP自动选择最确定的示例，并生成类prototype来初始化可学习的原型模型。</li>
<li>results: 我们的实验结果表明，我们的方法可以大幅超越8批CoOp、8批Tip-Adapter和现有的UPL方法，并且在图像识别和领域泛化任务中具有优秀的表现。<details>
<summary>Abstract</summary>
Recently, large-scale pre-trained vision-language models (e.g. CLIP and ALIGN) have demonstrated remarkable effectiveness in acquiring transferable visual representations. To leverage the valuable knowledge encoded within these models for downstream tasks, several fine-tuning approaches, including prompt tuning methods and adapter-based methods, have been developed to adapt vision-language models effectively with supervision. However, these methods rely on the availability of annotated samples, which can be labor-intensive and time-consuming to acquire, thus limiting scalability. To address this issue, in this work, we design an unsupervised fine-tuning approach for vision-language models called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for the unannotated target datasets, we leverage the text-image aligning capability of CLIP to automatically select the most confident samples for each class. Utilizing these selected samples, we generate class prototypes, which serve as the initialization for the learnable prototype model. After fine-tuning, the prototype model prediction is combined with the original CLIP's prediction by a residual connection to perform downstream recognition tasks. Our extensive experimental results on image recognition and domain generalization show that the proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter, and also the state-of-the-art UPL method by large margins.
</details>
<details>
<summary>摘要</summary>
现在，大规模预训练视觉语言模型（例如CLIP和ALIGN）已经表现出了很好的抽象能力。为了利用这些模型中嵌入的有价值知识来进行下游任务，有多种精度调整方法，如提示调整方法和适配器基本方法，已经开发出来。然而，这些方法需要有注解样本，这可以是劳动密集和时间消耗的。为了解决这个问题，在这项工作中，我们设计了一种无监督的精度调整方法 для视觉语言模型，即Unsupervised Prototype Adapter（UP-Adapter）。具体来说，对于无注解目标数据集，我们利用CLIP的文本图像对齐能力自动选择每个类型的最有信心的样本。使用这些选择的样本，我们生成类prototype，这些类prototype作为初始化来学习可变prototype模型。经过精度调整后，prototype模型预测结果与原CLIP预测结果之间进行差分连接，以进行下游识别任务。我们对图像识别和领域泛化进行了广泛的实验，结果表明，提posed的无监督方法可以大幅超越8批CoOp、8批Tip-Adapter以及状态监督UPL方法。
</details></li>
</ul>
<hr>
<h2 id="Can-Authorship-Representation-Learning-Capture-Stylistic-Features"><a href="#Can-Authorship-Representation-Learning-Capture-Stylistic-Features" class="headerlink" title="Can Authorship Representation Learning Capture Stylistic Features?"></a>Can Authorship Representation Learning Capture Stylistic Features?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11490">http://arxiv.org/abs/2308.11490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llnl/luar">https://github.com/llnl/luar</a></li>
<li>paper_authors: Andrew Wang, Cristina Aggazzotti, Rebecca Kotula, Rafael Rivera Soto, Marcus Bishop, Nicholas Andrews</li>
<li>for: 这 paper 的目的是用数据驱动的方式学习作者表示，以便进行作者归属性预测。</li>
<li>methods: 这 paper 使用了大量的文本 corpus 和作者标签，通过数据驱动的方式学习作者表示。</li>
<li>results: 这 paper 的实验结果表明，学习的作者表示可以准确地捕捉作者的写作风格，并且可以鲁棒地抗压缩数据变换，如主题的变化。<details>
<summary>Abstract</summary>
Automatically disentangling an author's style from the content of their writing is a longstanding and possibly insurmountable problem in computational linguistics. At the same time, the availability of large text corpora furnished with author labels has recently enabled learning authorship representations in a purely data-driven manner for authorship attribution, a task that ostensibly depends to a greater extent on encoding writing style than encoding content. However, success on this surrogate task does not ensure that such representations capture writing style since authorship could also be correlated with other latent variables, such as topic. In an effort to better understand the nature of the information these representations convey, and specifically to validate the hypothesis that they chiefly encode writing style, we systematically probe these representations through a series of targeted experiments. The results of these experiments suggest that representations learned for the surrogate authorship prediction task are indeed sensitive to writing style. As a consequence, authorship representations may be expected to be robust to certain kinds of data shift, such as topic drift over time. Additionally, our findings may open the door to downstream applications that require stylistic representations, such as style transfer.
</details>
<details>
<summary>摘要</summary>
自动分解作者的风格从写作内容中分离是计算语言学领域的长期问题。同时，有大量文本库已经标注作者的出现，使得可以通过数据驱动方式学习作者表示，这种任务显然更加依赖于编码写作风格而非编码内容。然而，成功完成这个代理任务并不能确保这些表示capture风格，因为作者可能也与其他隐藏变量相关，如话题。为了更好地理解这些表示中传递的信息，以及特别是验证假设是编码写作风格的，我们系统地进行了一系列targeted实验。实验结果表明，learned for surrogate authorship prediction task的表示确实敏感于写作风格。因此，作者表示可能会对某些数据变换具有Robustness，如时间的话题漂移。此外，我们的发现可能会开启下游应用需要风格表示的应用场景，如样式传递。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-generate-and-corr-uh-I-mean-repair-language-in-real-time"><a href="#Learning-to-generate-and-corr-uh-I-mean-repair-language-in-real-time" class="headerlink" title="Learning to generate and corr- uh I mean repair language in real-time"></a>Learning to generate and corr- uh I mean repair language in real-time</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11683">http://arxiv.org/abs/2308.11683</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://bitbucket.org/dylandialoguesystem/dsttr">https://bitbucket.org/dylandialoguesystem/dsttr</a></li>
<li>paper_authors: Arash Eshghi, Arash Ashrafzadeh</li>
<li>for: 这个论文的目的是为了开发一种能够在实时语言处理中进行自然和控制的对话AI系统。</li>
<li>methods: 这个论文使用了之前已经学习的动态语法语法和CHILDES数据集，开发了一个基于 probabilistic model 的增量生成模型，用于实现实时语言处理。</li>
<li>results: 研究发现，使用这个模型可以在78%的情况下输出金标候选答案，ROUGE-l分数为0.86。此外，模型还可以在生成目标改变时自动生成自修复，自动评估显示，模型可以正确地生成自修复的情况为85%。小规模的人工评估也证明了生成的自修复是自然和正确的。<details>
<summary>Abstract</summary>
In conversation, speakers produce language incrementally, word by word, while continuously monitoring the appropriateness of their own contribution in the dynamically unfolding context of the conversation; and this often leads them to repair their own utterance on the fly. This real-time language processing capacity is furthermore crucial to the development of fluent and natural conversational AI. In this paper, we use a previously learned Dynamic Syntax grammar and the CHILDES corpus to develop, train and evaluate a probabilistic model for incremental generation where input to the model is a purely semantic generation goal concept in Type Theory with Records (TTR). We show that the model's output exactly matches the gold candidate in 78% of cases with a ROUGE-l score of 0.86. We further do a zero-shot evaluation of the ability of the same model to generate self-repairs when the generation goal changes mid-utterance. Automatic evaluation shows that the model can generate self-repairs correctly in 85% of cases. A small human evaluation confirms the naturalness and grammaticality of the generated self-repairs. Overall, these results further highlight the generalisation power of grammar-based models and lay the foundations for more controllable, and naturally interactive conversational AI systems.
</details>
<details>
<summary>摘要</summary>
在对话中，说话人会生成语言Word by Word，同时监测自己的言语是否适切，并在对话背景下动态地进行修复。这种实时语言处理能力是对话AI的自然化和流畅化的关键。在这篇论文中，我们使用先前学习的动态 syntax grammatical model和CHILDES corpus来开发、训练和评估一种随机生成模型，其输入是在类型理论中的某种语义生成目标概念。我们显示该模型的输出与金标准候选之间的匹配率为78%，ROUGE-l分数为0.86。我们进一步进行零shot评估模型在生成自修复时的能力。自动评估显示模型可以正确地生成自修复的85%情况下。一小规模的人工评估也证明了生成的自修复是自然和正确的。总的来说，这些结果再次强调了基于语法模型的模型的通用性，并为更可控、自然交互的对话AI系统开创了基础。
</details></li>
</ul>
<hr>
<h2 id="SONAR-Sentence-Level-Multimodal-and-Language-Agnostic-Representations"><a href="#SONAR-Sentence-Level-Multimodal-and-Language-Agnostic-Representations" class="headerlink" title="SONAR: Sentence-Level Multimodal and Language-Agnostic Representations"></a>SONAR: Sentence-Level Multimodal and Language-Agnostic Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11466">http://arxiv.org/abs/2308.11466</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/sonar">https://github.com/facebookresearch/sonar</a></li>
<li>paper_authors: Paul-Ambroise Duquenne, Holger Schwenk, Benoît Sagot</li>
<li>for: 本文提出了一个新的多语言多模式固定大小句子嵌入空间SONAR，用于实现多语言多模式嵌入。</li>
<li>methods: 作者使用了一种新的 sentence encoder 和 speech encoder，通过 teacher-student  Setting来训练语言特定的语音编码器，并使用了一种文本解码器来实现文本到文本和语音到文本翻译。</li>
<li>results: 作者的方法在多语言多模式嵌入搜索任务上显著超越了现有的嵌入方法，如LASER3和LabSE。此外，作者的语音编码器在相似搜索任务上也表现出色，并且可以实现零shot语言和模式组合的语音翻译。<details>
<summary>Abstract</summary>
We introduce SONAR, a new multilingual and multimodal fixed-size sentence embedding space. Our single text encoder, covering 200 languages, substantially outperforms existing sentence embeddings such as LASER3 and LabSE on the xsim and xsim++ multilingual similarity search tasks. Speech segments can be embedded in the same SONAR embedding space using language-specific speech encoders trained in a teacher-student setting on speech transcription data. Our encoders outperform existing speech encoders on similarity search tasks. We also provide a text decoder for 200 languages, which allows us to perform text-to-text and speech-to-text machine translation, including for zero-shot language and modality combinations. Our text-to-text results are competitive compared to the state-of-the-art NLLB~1B model, despite the fixed-size bottleneck representation. Our zero-shot speech-to-text translation results compare favorably with strong supervised baselines such as Whisper.
</details>
<details>
<summary>摘要</summary>
我们介绍SONAR，一个新的多语言多模式固定大小句子嵌入空间。我们的单一文本编码器，覆盖200种语言，与现有的句子嵌入 such as LASER3和LabSE在xsim和xsim++多 lingual similarity搜寻任务上表现出色，并可以将语音段落嵌入同一个 SONAR嵌入空间中使用语言特定的语音编码器在教师-学生设定下在语音识别数据上训练。我们的编码器在类似搜寻任务上表现出色，而我们还提供了200种语言的文本解oder，可以进行文本-文本和语音-文本机器翻译，包括零��� conocido语言和模式组合。我们的文本-文本结果与现有的NLLB1B模型相匹配，即使受到固定大小瓶颈表现的限制。我们的零��� known语音-文本翻译结果与强化过的基准模型such as Whisper相匹配。
</details></li>
</ul>
<hr>
<h2 id="Extracting-Relational-Triples-Based-on-Graph-Recursive-Neural-Network-via-Dynamic-Feedback-Forest-Algorithm"><a href="#Extracting-Relational-Triples-Based-on-Graph-Recursive-Neural-Network-via-Dynamic-Feedback-Forest-Algorithm" class="headerlink" title="Extracting Relational Triples Based on Graph Recursive Neural Network via Dynamic Feedback Forest Algorithm"></a>Extracting Relational Triples Based on Graph Recursive Neural Network via Dynamic Feedback Forest Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11411">http://arxiv.org/abs/2308.11411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyin Zhu</li>
<li>for: 将文本数据转化为结构化知识</li>
<li>methods: 使用依赖树分析和图 recursive neural networks (GRNNs) 实现 triple extraction 任务</li>
<li>results: 提出了一种新的方法，可以在模型训练时通过推理操作连接各个子任务的表示，实现子任务的 интеграción<details>
<summary>Abstract</summary>
Extracting relational triples (subject, predicate, object) from text enables the transformation of unstructured text data into structured knowledge. The named entity recognition (NER) and the relation extraction (RE) are two foundational subtasks in this knowledge generation pipeline. The integration of subtasks poses a considerable challenge due to their disparate nature. This paper presents a novel approach that converts the triple extraction task into a graph labeling problem, capitalizing on the structural information of dependency parsing and graph recursive neural networks (GRNNs). To integrate subtasks, this paper proposes a dynamic feedback forest algorithm that connects the representations of subtasks by inference operations during model training. Experimental results demonstrate the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
将文本数据转化为结构化知识，EXTRACTING relational triples（主语、谓语、谓 Object）从文本中提取是一个基本任务。命名实体识别（NER）和关系提取（RE）是这个知识生成管道的两个基础任务。这两个任务的集成带来了很大挑战，因为它们之间存在很大的差异。本文提出了一种新的方法，将 triple 提取任务转化为图标注问题，利用语言结构信息和图循环神经网络（GRNN）。为了将子任务集成，本文提出了一种动态反馈森林算法，在模型训练过程中，通过推理操作连接子任务的表示。实验结果表明，提出的方法有效。
</details></li>
</ul>
<hr>
<h2 id="Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition"><a href="#Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition" class="headerlink" title="Convoifilter: A case study of doing cocktail party speech recognition"></a>Convoifilter: A case study of doing cocktail party speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11380">http://arxiv.org/abs/2308.11380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thai-Binh Nguyen, Alexander Waibel</li>
<li>for: 提高特定说话人在嘈杂环境中自动语音识别（ASR）的精度。</li>
<li>methods: 使用单通道语音净化模块减少背景噪声，并与ASR模块结合使用。通过这种方法，模型可以将单个说话人的语音净化到26.4%。</li>
<li>results: 模型可以将单个说话人的语音净化到14.5%，比单独调整的26.4%更低。<details>
<summary>Abstract</summary>
This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise, along with an ASR module. Through this approach, the model is able to decrease the word error rate (WER) of ASR from 80% to 26.4%. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning.
</details>
<details>
<summary>摘要</summary>
这份研究报告介绍了一种用于改进特定发音人员在嘈杂环境下的自动语音识别（ASR）模型。该模型使用单通道语音提升模块，以隔离发音人员的声音与背景噪声，同时还包括ASR模块。通过这种方法，模型可以降低ASR的单词错误率（WER）从80%降至26.4%。通常，这两个组件在数据需求的变化下独立地调整。然而，语音提升可能会导致ASR效率下降。通过实施联合细调策略，模型可以在联合细调中降低WER从26.4%下降至14.5%。
</details></li>
</ul>
<hr>
<h2 id="M3PS-End-to-End-Multi-Grained-Multi-Modal-Attribute-Aware-Product-Summarization-in-E-commerce"><a href="#M3PS-End-to-End-Multi-Grained-Multi-Modal-Attribute-Aware-Product-Summarization-in-E-commerce" class="headerlink" title="M3PS: End-to-End Multi-Grained Multi-Modal Attribute-Aware Product Summarization in E-commerce"></a>M3PS: End-to-End Multi-Grained Multi-Modal Attribute-Aware Product Summarization in E-commerce</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11351">http://arxiv.org/abs/2308.11351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Chen, Ze Lin, Hui Li, Jiayi Ji, Yiyi Zhou, Guanbin Li, Rongrong Ji</li>
<li>for: 这篇论文的目的是提出一种高质量产品概要生成方法，以吸引顾客兴趣，提高购买意愿。</li>
<li>methods: 该方法使用多Modal模型，同时考虑了多个细腻的特征，包括文本和图像模式，以生成高质量的产品概要。</li>
<li>results: 实验结果表明，该方法在一个大规模的中文电商 dataset 上的评价metric 上显著 OUTPERFORMS 现有的产品概要方法。<details>
<summary>Abstract</summary>
Given the long textual product information and the product image, Multi-Modal Product Summarization (MMPS) aims to attract customers' interest and increase their desire to purchase by highlighting product characteristics with a short textual summary. Existing MMPS methods have achieved promising performance. Nevertheless, there still exist several problems: 1) lack end-to-end product summarization, 2) lack multi-grained multi-modal modeling, and 3) lack multi-modal attribute modeling. To address these issues, we propose an end-to-end multi-grained multi-modal attribute-aware product summarization method (M3PS) for generating high-quality product summaries in e-commerce. M3PS jointly models product attributes and generates product summaries. Meanwhile, we design several multi-grained multi-modal tasks to better guide the multi-modal learning of M3PS. Furthermore, we model product attributes based on both text and image modalities so that multi-modal product characteristics can be manifested in the generated summaries. Extensive experiments on a real large-scale Chinese e-commence dataset demonstrate that our model outperforms state-of-the-art product summarization methods w.r.t. several summarization metrics.
</details>
<details>
<summary>摘要</summary>
文本级别的产品描述和产品图像，多模式产品概述（MMPS）目标是通过突出产品特点而吸引顾客兴趣，提高购买意愿。现有的MMPS方法已经实现了一定的成果。然而，还存在一些问题：1）缺乏端到端产品概述，2）缺乏多层多模式模型，3）缺乏多模式属性模型。为了解决这些问题，我们提出了一种端到端多层多模式属性感知产品概述方法（M3PS），用于生成高质量的电商产品概述。M3PS同时模型产品属性，并生成产品概述。此外，我们设计了多个多层多模式任务，以更好地引导多模式学习。同时，我们基于文本和图像模式来模型产品属性，以便在生成的概述中表达多模式产品特点。我们对大规模中国电商数据进行了广泛的实验，并证明了我们的模型在多个概述指标上表现比现状态的产品概述方法更高。
</details></li>
</ul>
<hr>
<h2 id="LEAP-Efficient-and-Automated-Test-Method-for-NLP-Software"><a href="#LEAP-Efficient-and-Automated-Test-Method-for-NLP-Software" class="headerlink" title="LEAP: Efficient and Automated Test Method for NLP Software"></a>LEAP: Efficient and Automated Test Method for NLP Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11284">http://arxiv.org/abs/2308.11284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lumos-xiao/leap">https://github.com/lumos-xiao/leap</a></li>
<li>paper_authors: Mingxuan Xiao, Yan Xiao, Hai Dong, Shunhui Ji, Pengcheng Zhang</li>
<li>for: 提高 DNN 模型的Robustness，透过自动生成 adversarial test cases。</li>
<li>methods: 使用 Levy flight-based Adaptive Particle swarm optimization integrated with textual features，并采用 initialization population 增加测试用例的多样性，以及使用启动器算法和精准搜索缩短搜索时间。</li>
<li>results: 对 NLP 软件进行了系列测试，并证明了 LEAP 能够生成高精度的 adversarial test cases，同时具有较高的效率和可迁移性。<details>
<summary>Abstract</summary>
The widespread adoption of DNNs in NLP software has highlighted the need for robustness. Researchers proposed various automatic testing techniques for adversarial test cases. However, existing methods suffer from two limitations: weak error-discovering capabilities, with success rates ranging from 0% to 24.6% for BERT-based NLP software, and time inefficiency, taking 177.8s to 205.28s per test case, making them challenging for time-constrained scenarios. To address these issues, this paper proposes LEAP, an automated test method that uses LEvy flight-based Adaptive Particle swarm optimization integrated with textual features to generate adversarial test cases. Specifically, we adopt Levy flight for population initialization to increase the diversity of generated test cases. We also design an inertial weight adaptive update operator to improve the efficiency of LEAP's global optimization of high-dimensional text examples and a mutation operator based on the greedy strategy to reduce the search time. We conducted a series of experiments to validate LEAP's ability to test NLP software and found that the average success rate of LEAP in generating adversarial test cases is 79.1%, which is 6.1% higher than the next best approach (PSOattack). While ensuring high success rates, LEAP significantly reduces time overhead by up to 147.6s compared to other heuristic-based methods. Additionally, the experimental results demonstrate that LEAP can generate more transferable test cases and significantly enhance the robustness of DNN-based systems.
</details>
<details>
<summary>摘要</summary>
“随着深度神经网络（DNN）在自然语言处理（NLP）软件中的广泛应用，问题的Robustness问题得到了吸引注意。研究人员提出了多种自动测试技术，但现有方法受到两个限制：一是弱的错误发现能力，成功率从0%到24.6%之间，二是时间浪费，每个测试案例需要177.8s至205.28s，这使得它们在时间紧张的情况下具有挑战性。为了解决这些问题，本文提出了LEAP，一个自动测试方法，利用LEvy flight-based Adaptive Particle swarm optimization与文本特征来生成攻击测试案例。具体来说，我们在人口初始化中采用Levy flight，以增加生成的测试案例的多样性。我们还设计了一个吸引力适应更新算法，以提高LEAP的全球优化高维文本示例的效率。此外，我们还设计了基于推导策略的突变算法，以减少搜索时间。我们对NLP软件进行了一系列实验， Validate LEAP的测试能力，结果显示，LEAP的平均成功率为79.1%，高于下一个最佳方法（PSOattack）的6.1%。同时，LEAP可以保证高的成功率，并对其他着重基于规律的方法实现时间优化，最多减少147.6s。实验结果显示，LEAP可以生成更转移的测试案例，并对DNN基于系统增加了更高的Robustness。”
</details></li>
</ul>
<hr>
<h2 id="HopPG-Self-Iterative-Program-Generation-for-Multi-Hop-Question-Answering-over-Heterogeneous-Knowledge"><a href="#HopPG-Self-Iterative-Program-Generation-for-Multi-Hop-Question-Answering-over-Heterogeneous-Knowledge" class="headerlink" title="HopPG: Self-Iterative Program Generation for Multi-Hop Question Answering over Heterogeneous Knowledge"></a>HopPG: Self-Iterative Program Generation for Multi-Hop Question Answering over Heterogeneous Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11257">http://arxiv.org/abs/2308.11257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingyao Wang, Yongwei Zhou, Chaoqun Duan, Junwei Bao, Tiejun Zhao</li>
<li>for: 本研究旨在提高semantic parsing方法的多步问答能力，特别是在非结构化知识库中进行多步问答。</li>
<li>methods: 本研究提出了一种自适应框架（HopPG），通过利用前一步执行结果来检索支持信息和生成后续程序，解决了传统semantic parsing方法在多步问答中的缺陷。</li>
<li>results: 实验结果表明，HopPG在MMQA-T^2上表现出色，特别是在多步问答中超过了现有semantic-parsing基eline。<details>
<summary>Abstract</summary>
The semantic parsing-based method is an important research branch for knowledge-based question answering. It usually generates executable programs lean upon the question and then conduct them to reason answers over a knowledge base. Benefit from this inherent mechanism, it has advantages in the performance and the interpretability. However,traditional semantic parsing methods usually generate a complete program before executing it, which struggles with multi-hop question answering over heterogeneous knowledge. Firstly,a complete multi-hop program relies on multiple heterogeneous supporting facts, and it is difficult for models to receive these facts simultaneously. Secondly,these methods ignore the interaction information between the previous-hop execution result and the current-hop program generation. To alleviate these challenges, we propose a self-iterative framework for multi-hop program generation (HopPG) over heterogeneous knowledge, which leverages the previous-hop execution results to retrieve supporting facts and generate subsequent programs iteratively. We evaluate our model on MMQA-T^2. The experimental results show that HopPG outperforms existing semantic-parsing-based baselines, especially on the multi-hop questions.
</details>
<details>
<summary>摘要</summary>
“ semantic parsing-based 方法是知识基于问题回答的重要研究分支。它通常将问题转换为可执行的程式，然后将其与知识库进行推理，获得答案。由于这个自然的机制，它具有性能和可读性的优势。然而，传统的 semantic parsing 方法通常会生成完整的程式 перед执行，这会对于多步骤问题回答 sobre 不同的知识类型产生困难。首先，完整的多步骤程式需要多个不同的支持事实，而这些模型很难同时获取这些事实。其次，这些方法忽略了前一步执行结果和现在一步程式生成之间的互动信息。为了解决这些挑战，我们提出了一个自我迭代框架 для 多步骤程式生成 (HopPG) over 不同的知识，它利用前一步执行结果来获取支持事实并生成下一步程式。我们将我们的模型评估在 MMQA-T^2 上。实验结果显示，HopPG 比 existed semantic-parsing-based 基eline更高效，特别是在多步骤问题上。”
</details></li>
</ul>
<hr>
<h2 id="ViCo-Engaging-Video-Comment-Generation-with-Human-Preference-Rewards"><a href="#ViCo-Engaging-Video-Comment-Generation-with-Human-Preference-Rewards" class="headerlink" title="ViCo: Engaging Video Comment Generation with Human Preference Rewards"></a>ViCo: Engaging Video Comment Generation with Human Preference Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11171">http://arxiv.org/abs/2308.11171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuchong Sun, Bei Liu, Xu Chen, Ruihua Song, Jianlong Fu</li>
<li>for: 本研究旨在生成视频评论，以增强视频社交媒体上的互动性和参与度。</li>
<li>methods: 本研究提出了三种新的设计方案，包括利用赞数作为评论的表现度量，自动评估评论的参与度，以及使用初始生成器生成评论，然后通过奖励模型进行反馈优化。</li>
<li>results: 实验结果表明，使用本研究提出的方法可以生成高质量的视频评论，特别是在考虑参与度时。<details>
<summary>Abstract</summary>
Engaging video comments play an important role in video social media, as they are the carrier of feelings, thoughts, or humor of the audience. Preliminary works have made initial exploration for video comment generation by adopting caption-style encoder-decoder models. However, comment generation presents some unique challenges distinct from caption generation, which makes these methods somewhat less effective at generating engaging comments. In contrast to the objective and descriptive nature of captions, comments tend to be inherently subjective, making it hard to quantify and evaluate the engagement of comments. Furthermore, the scarcity of truly engaging comments brings difficulty to collecting enough high-quality training examples. In this paper, we propose ViCo with three novel designs to tackle the above challenges for generating engaging Video Comments. Firstly, to quantify the engagement of comments, we utilize the number of "likes" each comment receives as a proxy of human preference after an appropriate debiasing procedure. Secondly, to automatically evaluate the engagement of comments, we train a reward model to align its judgment to the above proxy. Our user studies indicate that this reward model effectively aligns with human judgments. Lastly, to alleviate the scarcity of high-quality comments, an initial generator is trained on readily available but noisy data to generate comments. Then the reward model is employed to offer feedback on the generated comments, thus optimizing the initial generator. To facilitate the research of video commenting, we collect a large video comment-dataset (ViCo-20k) with rich metadata from a popular video website. Experiments on ViCo-20k show that the comments generated by our ViCo model exhibit the best performance in terms of both quantitative and qualitative results, particularly when engagement is considered.
</details>
<details>
<summary>摘要</summary>
优化视频评论的核心在于促进视频社交媒体上的评论内容的互动性和趣味性。现有的初步工作已经采用了caption风格的编解oder模型进行视频评论生成。然而，评论生成存在一些独特的挑战，与caption生成不同，这些挑战使得这些方法在生成互动评论时有所不足。在评论中，评论内容具有主观性，使得评估评论的互动性变得更加困难。此外，缺乏真正有趣的评论使得收集高质量的训练示例具有挑战性。在这篇论文中，我们提出了ViCo模型，其中包括三个新的设计来解决以上挑战。首先，我们利用每个评论 receives的“喜欢”数作为人类偏好的代理，并进行了适当的偏移处理。其次，我们训练了一个奖励模型，以使其对于上述代理的评价与人类评价相互对应。我们的用户研究表明，这个奖励模型与人类评价之间具有良好的一致性。最后，我们使用初始生成器在 readily available但含有噪声的数据上生成评论，然后使用奖励模型来反馈给初始生成器，以便优化初始生成器。为促进视频评论研究，我们收集了一个大量的视频评论数据集（ViCo-20k），其中包括了视频网站上具有丰富 metadata 的视频评论。我们在ViCo-20k数据集上进行了实验，结果显示，我们的ViCo模型在互动性和质量两个方面表现出色，特别是在考虑互动性时。
</details></li>
</ul>
<hr>
<h2 id="LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report"><a href="#LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report" class="headerlink" title="LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)"></a>LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11148">http://arxiv.org/abs/2308.11148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Lu, Lei Yu, Xiaojia Li, Li Yang, Chun Zuo</li>
<li>for:  automatizing code review activities</li>
<li>methods:  utilizes parameter-efficient fine-tuning (PEFT) methods and LLaMA, a popular large language model</li>
<li>results:  equals the performance of existing code-review-focused models with a small model size and limited tuning epochs<details>
<summary>Abstract</summary>
The automation of code review activities, a long-standing pursuit in software engineering, has been primarily addressed by numerous domain-specific pre-trained models. Despite their success, these models frequently demand extensive resources for pre-training from scratch. In contrast, Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge. However, their potential for automating code review tasks remains largely unexplored.   In response to this research gap, we present LLaMA-Reviewer, an innovative framework that leverages the capabilities of LLaMA, a popular LLM, in the realm of code review. Mindful of resource constraints, this framework employs parameter-efficient fine-tuning (PEFT) methods, delivering high performance while using less than 1% of trainable parameters.   An extensive evaluation of LLaMA-Reviewer is conducted on two diverse, publicly available datasets. Notably, even with the smallest LLaMA base model consisting of 6.7B parameters and a limited number of tuning epochs, LLaMA-Reviewer equals the performance of existing code-review-focused models.   The ablation experiments provide insights into the influence of various fine-tuning process components, including input representation, instruction tuning, and different PEFT methods. To foster continuous progress in this field, the code and all PEFT-weight plugins have been made open-source.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>软件工程中的代码审查活动自动化，是一项长期追求的问题，已经由许多域 especific pre-trained models  addresses。Despite their success, these models often require extensive resources for pre-training from scratch。In contrast, Large Language Models (LLMs) provide an interesting alternative，given their remarkable capabilities when supplemented with domain-specific knowledge。However，their potential for automating code review tasks remains largely unexplored。In response to this research gap，we present LLaMA-Reviewer，an innovative framework that leverages the capabilities of LLaMA，a popular LLM，in the realm of code review。Mindful of resource constraints，this framework employs parameter-efficient fine-tuning (PEFT) methods，delivering high performance while using less than 1% of trainable parameters。An extensive evaluation of LLaMA-Reviewer is conducted on two diverse，publicly available datasets。Notably，even with the smallest LLaMA base model consisting of 6.7B parameters and a limited number of tuning epochs，LLaMA-Reviewer equals the performance of existing code-review-focused models。The ablation experiments provide insights into the influence of various fine-tuning process components，including input representation，instruction tuning，and different PEFT methods。To foster continuous progress in this field，the code and all PEFT-weight plugins have been made open-source。
</details></li>
</ul>
<hr>
<h2 id="NLP-based-detection-of-systematic-anomalies-among-the-narratives-of-consumer-complaints"><a href="#NLP-based-detection-of-systematic-anomalies-among-the-narratives-of-consumer-complaints" class="headerlink" title="NLP-based detection of systematic anomalies among the narratives of consumer complaints"></a>NLP-based detection of systematic anomalies among the narratives of consumer complaints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11138">http://arxiv.org/abs/2308.11138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiheng Gao, Ning Sun, Xuefeng Wang, Chen Yang, Ričardas Zitikis</li>
<li>for: 该研究是为了检测consumer complaint narratives中的系统性异常（systematic anomalies）。</li>
<li>methods: 该研究使用NLP技术将consumer complaint narratives转化为量化数据，然后使用一种算法检测系统性异常。</li>
<li>results: 研究使用Consumer Financial Protection Bureau的consumer complaint database示例，并成功地检测到了一些系统性异常。<details>
<summary>Abstract</summary>
We develop an NLP-based procedure for detecting systematic nonmeritorious consumer complaints, simply called systematic anomalies, among complaint narratives. While classification algorithms are used to detect pronounced anomalies, in the case of smaller and frequent systematic anomalies, the algorithms may falter due to a variety of reasons, including technical ones as well as natural limitations of human analysts. Therefore, as the next step after classification, we convert the complaint narratives into quantitative data, which are then analyzed using an algorithm for detecting systematic anomalies. We illustrate the entire procedure using complaint narratives from the Consumer Complaint Database of the Consumer Financial Protection Bureau.
</details>
<details>
<summary>摘要</summary>
我们开发了一种基于自然语言处理（NLP）技术的系统性异常检测程序，用于检测消费者投诉文本中的系统性异常。尽管分类算法可以检测明显的异常，但在小型和频繁的系统性异常情况下，算法可能会失败，这可能是技术上的限制以及人类分析员的自然限制。因此，我们将投诉文本转换成量化数据，然后使用一种检测系统性异常的算法进行分析。我们使用美国消费者金融保护署的消费者投诉数据库中的投诉文本进行示例。
</details></li>
</ul>
<hr>
<h2 id="Towards-Objective-Evaluation-of-Socially-Situated-Conversational-Robots-Assessing-Human-Likeness-through-Multimodal-User-Behaviors"><a href="#Towards-Objective-Evaluation-of-Socially-Situated-Conversational-Robots-Assessing-Human-Likeness-through-Multimodal-User-Behaviors" class="headerlink" title="Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors"></a>Towards Objective Evaluation of Socially-Situated Conversational Robots: Assessing Human-Likeness through Multimodal User Behaviors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11020">http://arxiv.org/abs/2308.11020</a></li>
<li>repo_url: None</li>
<li>paper_authors: Koji Inoue, Divesh Lala, Keiko Ochi, Tatsuya Kawahara, Gabriel Skantze</li>
<li>for: 评估社交对话机器人的人类化程度</li>
<li>methods: 基于多Modal用户行为的对话对话集采集，并对用户行为与人类化分数之间进行相似性分析，以评估机器人的人类化程度</li>
<li>results: 研究发现，通过对用户行为进行分析，可以对机器人的人类化程度进行评估，并且这种方法可以增强 объекivity和可重复性。<details>
<summary>Abstract</summary>
This paper tackles the challenging task of evaluating socially situated conversational robots and presents a novel objective evaluation approach that relies on multimodal user behaviors. In this study, our main focus is on assessing the human-likeness of the robot as the primary evaluation metric. While previous research often relied on subjective evaluations from users, our approach aims to evaluate the robot's human-likeness based on observable user behaviors indirectly, thus enhancing objectivity and reproducibility. To begin, we created an annotated dataset of human-likeness scores, utilizing user behaviors found in an attentive listening dialogue corpus. We then conducted an analysis to determine the correlation between multimodal user behaviors and human-likeness scores, demonstrating the feasibility of our proposed behavior-based evaluation method.
</details>
<details>
<summary>摘要</summary>
To begin, we created an annotated dataset of human-likeness scores, utilizing user behaviors found in an attentive listening dialogue corpus. We then conducted an analysis to determine the correlation between multimodal user behaviors and human-likeness scores, demonstrating the feasibility of our proposed behavior-based evaluation method.Translation notes:* "socially situated" is translated as "社交境中" (shè jìoù zhōng zhī)* "conversational robots" is translated as "对话机器人" (duì yǔ jī rén)* "human-likeness" is translated as "人类化" (rén xìng huà)* "objective evaluation" is translated as "客观评价" (kè jiàn píng jì)* "multimodal user behaviors" is translated as "多Modal用户行为" (duō modāl yòng hòu xíng bèi)* "attentive listening dialogue corpus" is translated as "注意听录对话 corpus" (zhù yì tīng luō duì hǎo)
</details></li>
</ul>
<hr>
<h2 id="Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items"><a href="#Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items" class="headerlink" title="Using language models in the implicit automated assessment of mathematical short answer items"></a>Using language models in the implicit automated assessment of mathematical short answer items</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11006">http://arxiv.org/abs/2308.11006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Ormerod</li>
<li>for: 这项研究的目的是提出一种新的短 constructed response assessment方法，以便更准确地评估学生的数学知识。</li>
<li>methods: 该方法使用一个管道，从Student response中提取关键值。这个管道包括两个精心调整的语言模型，第一个模型判断学生回答中是否含有关键值，第二个模型则确定回答中关键值的位置。</li>
<li>results: 研究表明，这种管道方法比传统的分桌评分法更加准确和有用，可以为学生提供更有arget的反馈，帮助学生提高数学知识。<details>
<summary>Abstract</summary>
We propose a new way to assess certain short constructed responses to mathematics items. Our approach uses a pipeline that identifies the key values specified by the student in their response. This allows us to determine the correctness of the response, as well as identify any misconceptions. The information from the value identification pipeline can then be used to provide feedback to the teacher and student. The value identification pipeline consists of two fine-tuned language models. The first model determines if a value is implicit in the student response. The second model identifies where in the response the key value is specified. We consider both a generic model that can be used for any prompt and value, as well as models that are specific to each prompt and value. The value identification pipeline is a more accurate and informative way to assess short constructed responses than traditional rubric-based scoring. It can be used to provide more targeted feedback to students, which can help them improve their understanding of mathematics.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来评估某些短 constructed responses 的数学项目。我们的方法使用一个管道，以确定学生在回答中提供的关键值。这些值可以确定回答的正确性，以及学生可能存在的误解。管道中的信息可以用于向教师和学生提供反馈。我们的值标识管道包括两个精心调整的自然语言模型。第一个模型判断学生回答中是否包含关键值。第二个模型确定回答中关键值的位置。我们考虑了一个通用的模型，可以用于任何提问和值，以及每个提问和值的特定模型。值标识管道比传统的分类型分配法更准确和有用，可以为学生提供更有向导性的反馈，帮助他们深化数学理解。
</details></li>
</ul>
<hr>
<h2 id="LatEval-An-Interactive-LLMs-Evaluation-Benchmark-with-Incomplete-Information-from-Lateral-Thinking-Puzzles"><a href="#LatEval-An-Interactive-LLMs-Evaluation-Benchmark-with-Incomplete-Information-from-Lateral-Thinking-Puzzles" class="headerlink" title="LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles"></a>LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete Information from Lateral Thinking Puzzles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10855">http://arxiv.org/abs/2308.10855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thukelab/lateval">https://github.com/thukelab/lateval</a></li>
<li>paper_authors: Shulin Huang, Shirong Ma, Yinghui Li, Mengzuo Huang, Wuhe Zou, Weidong Zhang, Hai-Tao Zheng</li>
<li>for: 评估大语言模型的横向思维能力</li>
<li>methods: 使用 Lateral Thinking Puzzles  benchmark 评估模型的问题提出和信息 интеграción能力</li>
<li>results: 发现大多数语言模型在交互中具有差guide的横向思维能力，比如 GPT-4 也存在一定的差异，与人类相比仍有很大差距<details>
<summary>Abstract</summary>
With the continuous evolution and refinement of LLMs, they are endowed with impressive logical reasoning or vertical thinking capabilities. But can they think out of the box? Do they possess proficient lateral thinking abilities? Following the setup of Lateral Thinking Puzzles, we propose a novel evaluation benchmark, LatEval, which assesses the model's lateral thinking within an interactive framework. In our benchmark, we challenge LLMs with 2 aspects: the quality of questions posed by the model and the model's capability to integrate information for problem-solving. We find that nearly all LLMs struggle with employing lateral thinking during interactions. For example, even the most advanced model, GPT-4, exhibits the advantage to some extent, yet still maintain a noticeable gap when compared to human. This evaluation benchmark provides LLMs with a highly challenging and distinctive task that is crucial to an effective AI assistant.
</details>
<details>
<summary>摘要</summary>
We challenge LLMs with two aspects: the quality of questions posed by the model and the model's ability to integrate information for problem-solving. Our results show that nearly all LLMs struggle with using lateral thinking during interactions. For example, even the most advanced model, GPT-4, exhibits some advantage, but still maintains a noticeable gap compared to humans. This evaluation benchmark provides LLMs with a highly challenging and distinctive task that is crucial for an effective AI assistant.
</details></li>
</ul>
<hr>
<h2 id="AgentVerse-Facilitating-Multi-Agent-Collaboration-and-Exploring-Emergent-Behaviors-in-Agents"><a href="#AgentVerse-Facilitating-Multi-Agent-Collaboration-and-Exploring-Emergent-Behaviors-in-Agents" class="headerlink" title="AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents"></a>AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10848">http://arxiv.org/abs/2308.10848</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/openbmb/agentverse">https://github.com/openbmb/agentverse</a></li>
<li>paper_authors: Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan Liu, Maosong Sun, Jie Zhou</li>
<li>for: 这篇论文旨在提出一种基于大语言模型的多代理框架，以增强任务完成效率和效果。</li>
<li>methods: 该框架使用了多种方法，包括 dynamically adjusting its composition 和 collaboratively accomplishing tasks。</li>
<li>results: 实验结果表明，该框架可以有效地派Send multi-agent groups that outperform a single agent。 Additionally, the paper explores the emergence of social behaviors among individual agents within a group during collaborative task accomplishment.<details>
<summary>Abstract</summary>
Autonomous agents empowered by Large Language Models (LLMs) have undergone significant improvements, enabling them to generalize across a broad spectrum of tasks. However, in real-world scenarios, cooperation among individuals is often required to enhance the efficiency and effectiveness of task accomplishment. Hence, inspired by human group dynamics, we propose a multi-agent framework \framework that can collaboratively and dynamically adjust its composition as a greater-than-the-sum-of-its-parts system. Our experiments demonstrate that \framework framework can effectively deploy multi-agent groups that outperform a single agent. Furthermore, we delve into the emergence of social behaviors among individual agents within a group during collaborative task accomplishment. In view of these behaviors, we discuss some possible strategies to leverage positive ones and mitigate negative ones for improving the collaborative potential of multi-agent groups. Our codes for \framework will soon be released at \url{https://github.com/OpenBMB/AgentVerse}.
</details>
<details>
<summary>摘要</summary>
自主代理 empowered by Large Language Models (LLMs) 已经经历了重要的改进，使其能够广泛应用于多种任务。然而，在实际场景中，人们之间的合作是经常需要的，以提高任务完成的效率和效果。因此， drawing inspiration from human group dynamics, we propose a multi-agent framework \framework that can collaboratively and dynamically adjust its composition as a greater-than-the-sum-of-its-parts system. Our experiments demonstrate that \framework framework can effectively deploy multi-agent groups that outperform a single agent. Furthermore, we delve into the emergence of social behaviors among individual agents within a group during collaborative task accomplishment. In view of these behaviors, we discuss some possible strategies to leverage positive ones and mitigate negative ones for improving the collaborative potential of multi-agent groups. Our codes for \framework will soon be released at \url{https://github.com/OpenBMB/AgentVerse}.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/cs.CL_2023_08_22/" data-id="clltau91j001zcr889x151laj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.CV_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.CV_2023_08_22/">cs.CV - 2023-08-22 21:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SwinFace-A-Multi-task-Transformer-for-Face-Recognition-Expression-Recognition-Age-Estimation-and-Attribute-Estimation"><a href="#SwinFace-A-Multi-task-Transformer-for-Face-Recognition-Expression-Recognition-Age-Estimation-and-Attribute-Estimation" class="headerlink" title="SwinFace: A Multi-task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation"></a>SwinFace: A Multi-task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11509">http://arxiv.org/abs/2308.11509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lxq1000/swinface">https://github.com/lxq1000/swinface</a></li>
<li>paper_authors: Lixiong Qin, Mei Wang, Chao Deng, Ke Wang, Xi Chen, Jiani Hu, Weihong Deng</li>
<li>for: 这个论文的目的是提出一种多功能的Face recognition和表情识别、年龄估计和面部特征估计（40个特征包括性别）的算法基于单个Swin Transformer。</li>
<li>methods: 该算法使用了一个共享背景和每个相关任务的子网络，并在每个任务特定分析子网络中实现了一种多级渠道注意力（MLCA）模块，以适应不同任务的冲突和需求。</li>
<li>results: 对于所有任务，提出的模型具有出色的表现，尤其是在RAF-DB和CLAP2015上达到了90.97%的准确率和0.22 $\epsilon$-的误差分别，这些结果在表情识别和年龄估计领域是状态的最佳结果。<details>
<summary>Abstract</summary>
In recent years, vision transformers have been introduced into face recognition and analysis and have achieved performance breakthroughs. However, most previous methods generally train a single model or an ensemble of models to perform the desired task, which ignores the synergy among different tasks and fails to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper presents a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, the SwinFace, consists of a single shared backbone together with a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and 0.22 $\epsilon$-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. The code and models will be made publicly available at https://github.com/lxq1000/SwinFace.
</details>
<details>
<summary>摘要</summary>
Recently, vision transformers have been applied to face recognition and analysis, achieving performance breakthroughs. However, most previous methods train a single model or an ensemble of models to perform the desired task, ignoring the synergy among different tasks and failing to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper proposes a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, called SwinFace, consists of a single shared backbone and a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and 0.22 $\epsilon$-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. The code and models will be made publicly available at https://github.com/lxq1000/SwinFace.
</details></li>
</ul>
<hr>
<h2 id="LCCo-Lending-CLIP-to-Co-Segmentation"><a href="#LCCo-Lending-CLIP-to-Co-Segmentation" class="headerlink" title="LCCo: Lending CLIP to Co-Segmentation"></a>LCCo: Lending CLIP to Co-Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11506">http://arxiv.org/abs/2308.11506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Duan, Yan Yang, Liyuan Pan, Xiabi Liu</li>
<li>for: 本文研究了一种基于语言图像预训练框架(CLIP)的图像集合中的共同Semantic object划分方法。</li>
<li>methods: 该方法使用了一种基于CLIP的三个关键模块：一个图像集合特征匹配模块，一个CLIP交互模块，和一个CLIP规范模块。这些模块共同使用CLIP来提高图像划分精度。</li>
<li>results: 实验结果表明，该方法在四个标准图像划分 benchmark 数据集上的性能比前state-of-the-art方法高。<details>
<summary>Abstract</summary>
This paper studies co-segmenting the common semantic object in a set of images. Existing works either rely on carefully engineered networks to mine the implicit semantic information in visual features or require extra data (i.e., classification labels) for training. In this paper, we leverage the contrastive language-image pre-training framework (CLIP) for the task. With a backbone segmentation network that independently processes each image from the set, we introduce semantics from CLIP into the backbone features, refining them in a coarse-to-fine manner with three key modules: i) an image set feature correspondence module, encoding global consistent semantic information of the image set; ii) a CLIP interaction module, using CLIP-mined common semantics of the image set to refine the backbone feature; iii) a CLIP regularization module, drawing CLIP towards this co-segmentation task, identifying the best CLIP semantic and using it to regularize the backbone feature. Experiments on four standard co-segmentation benchmark datasets show that the performance of our method outperforms state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Image set feature correspondence module: Encodes global consistent semantic information of the image set.2. CLIP interaction module: Uses CLIP-mined common semantics of the image set to refine the backbone feature.3. CLIP regularization module: Draws CLIP towards this co-segmentation task, identifying the best CLIP semantic and using it to regularize the backbone feature.Experiments on four standard co-segmentation benchmark datasets show that our method outperforms state-of-the-art methods.</details></li>
</ol>
<hr>
<h2 id="Learning-from-Semantic-Alignment-between-Unpaired-Multiviews-for-Egocentric-Video-Recognition"><a href="#Learning-from-Semantic-Alignment-between-Unpaired-Multiviews-for-Egocentric-Video-Recognition" class="headerlink" title="Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition"></a>Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11489">http://arxiv.org/abs/2308.11489</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wqtwjt1996/sum-l">https://github.com/wqtwjt1996/sum-l</a></li>
<li>paper_authors: Qitong Wang, Long Zhao, Liangzhe Yuan, Ting Liu, Xi Peng</li>
<li>For: The paper aims to tackle the challenging problem of unpaired multiview video learning, where the model needs to learn comprehensive multiview representations while dealing with variations in cross-view semantic information.* Methods: The proposed method, called Semantics-based Unpaired Multiview Learning (SUM-L), builds cross-view pseudo-pairs and performs view-invariant alignment by leveraging the semantic information of videos. Additionally, video-text alignment is performed for first-person and third-person videos to improve video representations.* Results: The method is evaluated on multiple benchmark datasets and outperforms multiple existing view-alignment methods, demonstrating its effectiveness in improving video representations under a more challenging scenario than typical paired or unpaired multimodal or multiview learning.Here are the three key points in Simplified Chinese text:* For: 本文目的是解决无对视照视频学习的挑战问题，即学习多视图表示而处理视频cross-view semantic信息的变化。* Methods: 提出的方法是基于Semantics-based Unpaired Multiview Learning（SUM-L），建立cross-view Pseudo-pairs并实现视图不变的Alignment，通过利用视频semantic信息。此外，还进行了首人和第三人视频的文本对齐，以提高视频表示。* Results: 方法在多个benchmark dataset上进行了广泛的实验，并证明其在不同于 Typical paired或Unpaired multimodal或Multiview learning的场景下表现更高效。<details>
<summary>Abstract</summary>
We are concerned with a challenging scenario in unpaired multiview video learning. In this case, the model aims to learn comprehensive multiview representations while the cross-view semantic information exhibits variations. We propose Semantics-based Unpaired Multiview Learning (SUM-L) to tackle this unpaired multiview learning problem. The key idea is to build cross-view pseudo-pairs and do view-invariant alignment by leveraging the semantic information of videos. To facilitate the data efficiency of multiview learning, we further perform video-text alignment for first-person and third-person videos, to fully leverage the semantic knowledge to improve video representations. Extensive experiments on multiple benchmark datasets verify the effectiveness of our framework. Our method also outperforms multiple existing view-alignment methods, under the more challenging scenario than typical paired or unpaired multimodal or multiview learning. Our code is available at https://github.com/wqtwjt1996/SUM-L.
</details>
<details>
<summary>摘要</summary>
我们面临了一种复杂的无对视视频学习场景。在这种情况下，模型需要学习全面的无对视视频表示，而cross-view含义信息具有变化性。我们提议使用Semantics-based Unpaired Multiview Learning（SUM-L）解决这个无对视视频学习问题。关键思想是建立cross-view Pseudo-对和视图不变Alignment，通过利用视频含义信息来做这两个任务。为了提高多视图学习的数据效率，我们进一步进行了视频文本对齐，以全面利用视频含义知识来改善视频表示。我们的方法在多个benchmark数据集上进行了广泛的实验，并证明了我们的框架的效果。我们的方法还比多种现有的视图对齐方法高效，在更加复杂的场景下。我们的代码可以在https://github.com/wqtwjt1996/SUM-L中找到。
</details></li>
</ul>
<hr>
<h2 id="Opening-the-Vocabulary-of-Egocentric-Actions"><a href="#Opening-the-Vocabulary-of-Egocentric-Actions" class="headerlink" title="Opening the Vocabulary of Egocentric Actions"></a>Opening the Vocabulary of Egocentric Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11488">http://arxiv.org/abs/2308.11488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dibyadip Chatterjee, Fadime Sener, Shugao Ma, Angela Yao</li>
<li>for: 本文旨在提出一种开放词汇动作识别任务，能够扩展 Verb 到一个开放词汇的动作中，同时处理已知和未知的对象。</li>
<li>methods: 本文提出了一种嵌入 CLIP 表示的提示来预测开放词汇中的交互对象，并使用一个对象agnostic verb encoder 来预测verb。</li>
<li>results: 对于 EPIC-KITCHENS-100 和 Assembly101  datasets，本文创建了一些开放词汇的benchmark，而关闭动作方法无法泛化，而我们的提议方法却效果很好，同时，我们的对象Encoder 也比既有的开放词汇视觉识别方法更高效。<details>
<summary>Abstract</summary>
Human actions in egocentric videos are often hand-object interactions composed from a verb (performed by the hand) applied to an object. Despite their extensive scaling up, egocentric datasets still face two limitations - sparsity of action compositions and a closed set of interacting objects. This paper proposes a novel open vocabulary action recognition task. Given a set of verbs and objects observed during training, the goal is to generalize the verbs to an open vocabulary of actions with seen and novel objects. To this end, we decouple the verb and object predictions via an object-agnostic verb encoder and a prompt-based object encoder. The prompting leverages CLIP representations to predict an open vocabulary of interacting objects. We create open vocabulary benchmarks on the EPIC-KITCHENS-100 and Assembly101 datasets; whereas closed-action methods fail to generalize, our proposed method is effective. In addition, our object encoder significantly outperforms existing open-vocabulary visual recognition methods in recognizing novel interacting objects.
</details>
<details>
<summary>摘要</summary>
人类行为在 egocentric 视频中经常是手部-物体互动，由 verb（由手部执行的动作）和物体组成。尽管这些数据集已经大量扩大，但是它们仍然面临两个限制：动作组合稀缺和固定的交互物体集。本文提出了一个开放词汇动作认知任务。给定一组 verb 和在训练中观察到的物体，目标是将 verb 扩展到一个开放词汇的动作中，包括已知和新的交互物体。为此，我们分离 verb 和物体预测，使用 объекc-agnostic verb 编码器和提示基于 CLIP 表示来预测开放词汇的交互物体。我们创建了开放词汇 benchmark 在 EPIC-KITCHENS-100 和 Assembly101 数据集上，而封闭动作方法无法泛化，我们提posed 方法是有效的。此外，我们的物体编码器在认识新交互物体方面表现出色，大大超过了现有的开放词汇视觉认知方法。
</details></li>
</ul>
<hr>
<h2 id="Free-Lunch-for-Gait-Recognition-A-Novel-Relation-Descriptor"><a href="#Free-Lunch-for-Gait-Recognition-A-Novel-Relation-Descriptor" class="headerlink" title="Free Lunch for Gait Recognition: A Novel Relation Descriptor"></a>Free Lunch for Gait Recognition: A Novel Relation Descriptor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11487">http://arxiv.org/abs/2308.11487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jilong Wang, Saihui Hou, Yan Huang, Chunshui Cao, Xu Liu, Yongzhen Huang, Liang Wang</li>
<li>For: This paper focuses on improving gait recognition performance by reconsidering gait representation and emphasizing inter-personal relationships among different subjects’ gait features.* Methods: The proposed method, called Relationship Descriptor (RD), uses reference-anchored gaits to describe each person’s gait and emphasizes meaningful features by normalizing the dot product between gait features and classifier weights. To address the dimensionality challenges, the method proposes a Farthest Anchored gaits Selection algorithm and a dimension reduction method.* Results: The proposed method achieves higher recognition performance than directly using extracted features and consistently outperforms the baselines on four popular gait recognition datasets (GREW, Gait3D, CASIA-B, and OU-MVLP), achieving state-of-the-art performances.Here’s the simplified Chinese text:* For: 本研究目的是提高步行识别性能，重新评估步行表示方式，强调不同人群之间的步行特征关系。* Methods: 提出的方法是关系描述符（RD），使用参照锚定的步行特征来描述每个人的步行，强调意义更高的特征，通过归一化点积分来表示每个测试样本与每个训练ID的步行原型之间的相似性。* Results: 比较直接使用提取的特征，关系描述符可以提高步行识别性能，在四个流行的步行识别数据集（GREW、Gait3D、CASIA-B、OU-MVLP）上表现出state-of-the-art的性能。<details>
<summary>Abstract</summary>
Gait recognition is to seek correct matches for query individuals by their unique walking patterns at a long distance. However, current methods focus solely on individual gait features, disregarding inter-personal relationships. In this paper, we reconsider gait representation, asserting that gait is not just an aggregation of individual features, but also the relationships among different subjects' gait features once reference gaits are established. From this perspective, we redefine classifier weights as reference-anchored gaits, allowing each person's gait to be described by their relationship with these references. In our work, we call this novel descriptor Relationship Descriptor (RD). This Relationship Descriptor offers two benefits: emphasizing meaningful features and enhancing robustness. To be specific, The normalized dot product between gait features and classifier weights signifies a similarity relation, where each dimension indicates the similarity between the test sample and each training ID's gait prototype, respectively. Despite its potential, the direct use of relationship descriptors poses dimensionality challenges since the dimension of RD depends on the training set's identity count. To address this, we propose a Farthest Anchored gaits Selection algorithm and a dimension reduction method to boost gait recognition performance. Our method can be built on top of off-the-shelf pre-trained classification-based models without extra parameters. We show that RD achieves higher recognition performance than directly using extracted features. We evaluate the effectiveness of our method on the popular GREW, Gait3D, CASIA-B, and OU-MVLP, showing that our method consistently outperforms the baselines and achieves state-of-the-art performances.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translation_direction: zh-CNGait recognition是寻找正确的匹配个体的唯一步态特征，但现有方法强调个体特征，忽略了人之间的关系。在这篇论文中，我们重新定义步态表示，认为步态不仅是个体特征的汇集，还包括不同个体之间的关系。从这个视角，我们定义了一种新的描述符called Relationship Descriptor (RD)。这个描述符有两个优点：强调意义性特征和增强稳定性。具体来说，在测试样本和训练ID之间的标准化点积分比率表示两个样本之间的相似性关系，每个维度表示测试样本与每个训练ID的步态原型之间的相似性。虽有潜在的优势，直接使用关系描述符存在维度挑战，因为关系描述符的维度取决于训练集中个体数量。为解决这个问题，我们提出了最远锚定 gaits 选择算法和维度减少方法，以提高步态识别性能。我们的方法可以在现有的预训练分类模型基础上建立，无需添加参数。我们证明，RD 可以高于直接使用提取的特征来实现更高的识别性能。我们对广泛使用的 GREW、Gait3D、CASIA-B 和 OU-MVLP 进行评估，并证明我们的方法可以一直达到领先水平。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Composed-Image-Retrieval-using-Contrastive-Learning-and-Task-oriented-CLIP-based-Features"><a href="#Composed-Image-Retrieval-using-Contrastive-Learning-and-Task-oriented-CLIP-based-Features" class="headerlink" title="Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features"></a>Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11485">http://arxiv.org/abs/2308.11485</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ABaldrati/CLIP4Cir">https://github.com/ABaldrati/CLIP4Cir</a></li>
<li>paper_authors: Alberto Baldrati, Marco Bertini, Tiberio Uricchio, Alberto del Bimbo</li>
<li>for: 本研究的目的是寻找基于referenced图像和相关的caption的compose image retrieval，即检索图像具有与referenced图像相同的视觉特征并满足caption中的修改。</li>
<li>methods: 本研究使用OpenAI CLIP模型的特征进行任务调整和组合，并使用对比学习进行训练。首先，通过任务特有的方式进行CLIP encoder的任务调整，然后在第二个阶段使用Combiner网络将图像和文本特征相结合，提供了组合特征进行检索。</li>
<li>results: 实验结果表明，基于CLIP特征的任务调整和Combiner网络对于FashionIQ和CIRR两个Popular和挑战性的compose image retrieval dataset具有高效性，并且超过了更复杂的现有方法。<details>
<summary>Abstract</summary>
Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Given that recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir
</details>
<details>
<summary>摘要</summary>
Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, so we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir.Here's the translation in Traditional Chinese: Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, so we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir.
</details></li>
</ul>
<hr>
<h2 id="Pose2Gait-Extracting-Gait-Features-from-Monocular-Video-of-Individuals-with-Dementia"><a href="#Pose2Gait-Extracting-Gait-Features-from-Monocular-Video-of-Individuals-with-Dementia" class="headerlink" title="Pose2Gait: Extracting Gait Features from Monocular Video of Individuals with Dementia"></a>Pose2Gait: Extracting Gait Features from Monocular Video of Individuals with Dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11484">http://arxiv.org/abs/2308.11484</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taatiteam/pose2gait_public">https://github.com/taatiteam/pose2gait_public</a></li>
<li>paper_authors: Caroline Malin-Mayor, Vida Adeli, Andrea Sabo, Sergey Noritsyn, Carolina Gorodetsky, Alfonso Fasano, Andrea Iaboni, Babak Taati</li>
<li>for: 这项研究旨在通过视频监测 older adults with dementia 的步态，早期发现健康状况下降，以防止跌倒或入院。</li>
<li>methods: 该研究使用了计算机视觉基于pose tracking模型来自动处理视频数据，并提取了人体 JOINT 位置。</li>
<li>results: 该模型能够从视频中提取步态特征，并与深度摄像头中的特征相比，Spearman 相关系数为。83和.60。这表明，三维空间时间特征可以从单一视频中预测。<details>
<summary>Abstract</summary>
Video-based ambient monitoring of gait for older adults with dementia has the potential to detect negative changes in health and allow clinicians and caregivers to intervene early to prevent falls or hospitalizations. Computer vision-based pose tracking models can process video data automatically and extract joint locations; however, publicly available models are not optimized for gait analysis on older adults or clinical populations. In this work we train a deep neural network to map from a two dimensional pose sequence, extracted from a video of an individual walking down a hallway toward a wall-mounted camera, to a set of three-dimensional spatiotemporal gait features averaged over the walking sequence. The data of individuals with dementia used in this work was captured at two sites using a wall-mounted system to collect the video and depth information used to train and evaluate our model. Our Pose2Gait model is able to extract velocity and step length values from the video that are correlated with the features from the depth camera, with Spearman's correlation coefficients of .83 and .60 respectively, showing that three dimensional spatiotemporal features can be predicted from monocular video. Future work remains to improve the accuracy of other features, such as step time and step width, and test the utility of the predicted values for detecting meaningful changes in gait during longitudinal ambient monitoring.
</details>
<details>
<summary>摘要</summary>
视频基于环境监测 older adults 的步态有潜力检测身体健康状况下降，并允许临床专业人员和照顾者在早期发现并预防滥落或入院。通过计算机视觉技术，可自动处理视频数据，并提取关节位置。然而，目前公共可用的模型并没有适应老年人或临床人群的步态分析。在这项工作中，我们训练了深度神经网络，将二维姿态序列，从视频中捕捉到人走向墙面镜头的人走动捕捉到三维空间时间步态特征的映射。我们的 Pose2Gait 模型可以从视频中提取速度和步长值，与深度相机中的特征相关性 coefficient 为 0.83 和 0.60，表明可以从单视频中预测三维空间时间步态特征。未来的工作是提高其他特征的准确性，如步时和步宽，并测试预测值的检测意义步长监测。
</details></li>
</ul>
<hr>
<h2 id="VadCLIP-Adapting-Vision-Language-Models-for-Weakly-Supervised-Video-Anomaly-Detection"><a href="#VadCLIP-Adapting-Vision-Language-Models-for-Weakly-Supervised-Video-Anomaly-Detection" class="headerlink" title="VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection"></a>VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11681">http://arxiv.org/abs/2308.11681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wu, Xuerong Zhou, Guansong Pang, Lingru Zhou, Qingsen Yan, Peng Wang, Yanning Zhang</li>
<li>for: 这个研究的目的是提出一个新的弱监督类别 видео异常探测（WSVAD）方法，并将CLIP模型 directly applied to WSVAD任务。</li>
<li>methods: 这个方法使用了CLIP模型的冻结版本，不需要进行预训练。它还包括一个双支路径，其中一支使用了视觉特征进行粗糙分类，另一支则全面利用语言-图像Alignment。</li>
<li>results: 实验结果显示，VadCLIP在两个常用的标准集上（XD-Violence和UCF-Crime）都达到了最高性能，比前一代方法高度超越。具体来说，VadCLIP在XD-Violence上 achieve 84.51% AP和88.02% AUC，在UCF-Crime上 achieve 84.51% AP和88.02% AUC。<details>
<summary>Abstract</summary>
The recent contrastive language-image pre-training (CLIP) model has shown great success in a wide range of image-level tasks, revealing remarkable ability for learning powerful visual representations with rich semantics. An open and worthwhile problem is efficiently adapting such a strong model to the video domain and designing a robust video anomaly detector. In this work, we propose VadCLIP, a new paradigm for weakly supervised video anomaly detection (WSVAD) by leveraging the frozen CLIP model directly without any pre-training and fine-tuning process. Unlike current works that directly feed extracted features into the weakly supervised classifier for frame-level binary classification, VadCLIP makes full use of fine-grained associations between vision and language on the strength of CLIP and involves dual branch. One branch simply utilizes visual features for coarse-grained binary classification, while the other fully leverages the fine-grained language-image alignment. With the benefit of dual branch, VadCLIP achieves both coarse-grained and fine-grained video anomaly detection by transferring pre-trained knowledge from CLIP to WSVAD task. We conduct extensive experiments on two commonly-used benchmarks, demonstrating that VadCLIP achieves the best performance on both coarse-grained and fine-grained WSVAD, surpassing the state-of-the-art methods by a large margin. Specifically, VadCLIP achieves 84.51% AP and 88.02% AUC on XD-Violence and UCF-Crime, respectively. Code and features will be released to facilitate future VAD research.
</details>
<details>
<summary>摘要</summary>
Recent contrastive language-image pre-training (CLIP) 模型已经在各种图像任务中显示出惊人的成功，揭示出了强大的视觉表示和丰富的 semantics。一个值得关注的问题是如何有效地适应这种强大模型到视频领域，并设计一个强健的视频异常检测器。在这种工作中，我们提出了VadCLIP，一种新的弱相关视频异常检测（WSVAD）方法，利用直接使用冻结CLIP模型，而不需要任何预训练和调整过程。与当前工作不同，VadCLIP不直接将提取的特征 fed into 弱相关分类器进行帧级二分类，而是利用CLIP模型的细腻语义关系，在两个分支中进行检测。一个分支使用视觉特征进行粗略二分类，另一个分支完全利用语义-图像对齐来进行细腻异常检测。通过两个分支的合作，VadCLIP可以将CLIP模型的预训练知识传递到WSVAD任务中，从而实现粗略和细腻的视频异常检测。我们进行了广泛的实验，证明VadCLIP在XD-Violence和UCF-Crime上的表现均高于当前最佳方法，具体来说是84.51% AP和88.02% AUC。代码和特征将会被发布，以便未来的VAD研究。
</details></li>
</ul>
<hr>
<h2 id="Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms"><a href="#Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms" class="headerlink" title="Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms"></a>Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11468">http://arxiv.org/abs/2308.11468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariapia Rita Iandolo, Francesca Razzano, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 这个研究旨在使用Google Earth Engine（GEE）平台进行多时间分析，检测城市区域的变化 using 光学数据和专门的机器学习（ML）算法。</li>
<li>methods: 这个研究使用了GEE平台和光学数据，以及专门的ML算法进行分类和变化检测分析。</li>
<li>results: 结果表明，提posed方法可以准确地标识 changed和unchanged的城市区域在选定的时间段内。此外，这个研究也证明了GEE的云存储平台对处理大量卫星数据的管理有所重要性。<details>
<summary>Abstract</summary>
The aim of this work is to perform a multitemporal analysis using the Google Earth Engine (GEE) platform for the detection of changes in urban areas using optical data and specific machine learning (ML) algorithms. As a case study, Cairo City has been identified, in Egypt country, as one of the five most populous megacities of the last decade in the world. Classification and change detection analysis of the region of interest (ROI) have been carried out from July 2013 to July 2021. Results demonstrate the validity of the proposed method in identifying changed and unchanged urban areas over the selected period. Furthermore, this work aims to evidence the growing significance of GEE as an efficient cloud-based solution for managing large quantities of satellite data.
</details>
<details>
<summary>摘要</summary>
本工作的目的是使用Google Earth Engine（GEE）平台进行多时间分析，以探测城市区域的变化使用光学数据和专门的机器学习（ML）算法。作为案例研究，埃及国的开罗城市被选为世界上最后一个十年内最为人口稠密的五大都市之一。从2013年7月至2021年7月的时间段进行了区域 интерес（ROI）的分类和变化检测分析。结果表明提出的方法的有效性，可以准确地标识变化和不变的城市区域在选定的时间段内。此外，这项工作还旨在证明GEE作为云端解决方案，对处理巨量卫星数据的管理有着高效的能力。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning"><a href="#An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning" class="headerlink" title="An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning"></a>An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11677">http://arxiv.org/abs/2308.11677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grégoire Petit, Michael Soumm, Eva Feillet, Adrian Popescu, Bertrand Delezoide, David Picard, Céline Hudelot</li>
<li>for: 这个论文的目的是探讨分类模型在数据流中建立的增量学习问题。</li>
<li>methods: 论文使用的方法包括增量学习过程中的新类 интеграción、采用先前学习的模型初始化、选择合适的增量学习算法和评估增量学习模型的性能等。</li>
<li>results: 论文的主要发现是初始学习策略对增量准确率的影响是最大的，但是选择合适的增量学习算法更重要地防止忘记。根据这些发现，论文提出了实践增量学习的实用建议。<details>
<summary>Abstract</summary>
Class-Incremental Learning (CIL) aims to build classification models from data streams. At each step of the CIL process, new classes must be integrated into the model. Due to catastrophic forgetting, CIL is particularly challenging when examples from past classes cannot be stored, the case on which we focus here. To date, most approaches are based exclusively on the target dataset of the CIL process. However, the use of models pre-trained in a self-supervised way on large amounts of data has recently gained momentum. The initial model of the CIL process may only use the first batch of the target dataset, or also use pre-trained weights obtained on an auxiliary dataset. The choice between these two initial learning strategies can significantly influence the performance of the incremental learning model, but has not yet been studied in depth. Performance is also influenced by the choice of the CIL algorithm, the neural architecture, the nature of the target task, the distribution of classes in the stream and the number of examples available for learning. We conduct a comprehensive experimental study to assess the roles of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing the average incremental accuracy, but that the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations are intended to facilitate the practical deployment of incremental learning.
</details>
<details>
<summary>摘要</summary>
We conduct a comprehensive study to assess the influence of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing average incremental accuracy, but the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations aim to facilitate the practical deployment of incremental learning.
</details></li>
</ul>
<hr>
<h2 id="Food-Image-Classification-and-Segmentation-with-Attention-based-Multiple-Instance-Learning"><a href="#Food-Image-Classification-and-Segmentation-with-Attention-based-Multiple-Instance-Learning" class="headerlink" title="Food Image Classification and Segmentation with Attention-based Multiple Instance Learning"></a>Food Image Classification and Segmentation with Attention-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11452">http://arxiv.org/abs/2308.11452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valasia Vlachopoulou, Ioannis Sarafis, Alexandros Papadopoulos<br>for:* 这个论文是为了解决食物量计量问题而写的，它适用于食物监测应用场景。methods:* 这篇论文使用了弱监视学习方法，不需要像素级别的标注数据来训练食物图像分类和Semantic Segmentation模型。* 该方法基于多例学习approach，并使用了注意力机制来自动生成食物类划分图像。results:* 在FoodSeg103数据集上进行了实验，并证明了提议的方法的可行性和注意力机制的作用。<details>
<summary>Abstract</summary>
The demand for accurate food quantification has increased in the recent years, driven by the needs of applications in dietary monitoring. At the same time, computer vision approaches have exhibited great potential in automating tasks within the food domain. Traditionally, the development of machine learning models for these problems relies on training data sets with pixel-level class annotations. However, this approach introduces challenges arising from data collection and ground truth generation that quickly become costly and error-prone since they must be performed in multiple settings and for thousands of classes. To overcome these challenges, the paper presents a weakly supervised methodology for training food image classification and semantic segmentation models without relying on pixel-level annotations. The proposed methodology is based on a multiple instance learning approach in combination with an attention-based mechanism. At test time, the models are used for classification and, concurrently, the attention mechanism generates semantic heat maps which are used for food class segmentation. In the paper, we conduct experiments on two meta-classes within the FoodSeg103 data set to verify the feasibility of the proposed approach and we explore the functioning properties of the attention mechanism.
</details>
<details>
<summary>摘要</summary>
随着食物质量评估的需求增加，计算机视觉方法在食物领域中表现出了很大的潜力。然而，传统的机器学习模型开发方法仍然需要带有像素级别的分类注释。然而，这种方法会导致数据收集和真实性生成的挑战，这些挑战会在多个设置下并且对 тысячи个类型进行多次重复。为了缓解这些挑战，文章提出了一种弱型监督的方法，不需要像素级别的注释来训练食物图像分类和 semantic segmentation 模型。该方法基于多例学习approach和注意力机制。在测试时，模型用于分类，同时注意力机制生成 semantic heat map，用于食物类划分。在文章中，我们对 FoodSeg103 数据集中的两个元类进行了实验，以验证提议的可行性，并探索注意力机制的工作性质。
</details></li>
</ul>
<hr>
<h2 id="Towards-Discriminative-Representations-with-Contrastive-Instances-for-Real-Time-UAV-Tracking"><a href="#Towards-Discriminative-Representations-with-Contrastive-Instances-for-Real-Time-UAV-Tracking" class="headerlink" title="Towards Discriminative Representations with Contrastive Instances for Real-Time UAV Tracking"></a>Towards Discriminative Representations with Contrastive Instances for Real-Time UAV Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11450">http://arxiv.org/abs/2308.11450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zeng, Mingliang Zou, Xucheng Wang, Shuiwang Li</li>
<li>for: 提高UAV跟踪中的精准率和效率，这两个基本挑战是由于计算资源限制、电池容量和UAV最大荷载所带来的。</li>
<li>methods: 使用异构相关矩阵（DCF）基于的跟踪器可以在单个CPU上实现高效性，但是精准率较差。具有轻量级深度学习（DL）基于的跟踪器可以实现精准率和效率的平衡，但是性能增加受压缩率的限制。</li>
<li>results: 根据四个UAV标准测试集（UAV123@10fps、DTB70、UAVDT和VisDrone2018）的广泛实验结果，提出的DRCI跟踪器在对state-of-the-art UAV跟踪方法进行比较时表现出了显著的优势。<details>
<summary>Abstract</summary>
Maintaining high efficiency and high precision are two fundamental challenges in UAV tracking due to the constraints of computing resources, battery capacity, and UAV maximum load. Discriminative correlation filters (DCF)-based trackers can yield high efficiency on a single CPU but with inferior precision. Lightweight Deep learning (DL)-based trackers can achieve a good balance between efficiency and precision but performance gains are limited by the compression rate. High compression rate often leads to poor discriminative representations. To this end, this paper aims to enhance the discriminative power of feature representations from a new feature-learning perspective. Specifically, we attempt to learn more disciminative representations with contrastive instances for UAV tracking in a simple yet effective manner, which not only requires no manual annotations but also allows for developing and deploying a lightweight model. We are the first to explore contrastive learning for UAV tracking. Extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that the proposed DRCI tracker significantly outperforms state-of-the-art UAV tracking methods.
</details>
<details>
<summary>摘要</summary>
维护高效率和高精度是无人机追踪中的两个基本挑战，因为计算资源、电池容量和无人机的最大负载对紧。对应式相关滤波器（DCF）基本trackers可以在单一CPU上提供高效率，但是精度较差。轻量级深度学习（DL）基本trackers可以实现高效率和精度的平衡，但是性能增加受压缩率的限制。高压缩率通常会导致糟糕的描述表现。因此，本文的目标是将无人机追踪中的特征表现强化，以提高追踪精度。具体来说，我们尝试通过新的特征学习角度，从而学习更有弹性的特征表现，这不仅不需要手动标注，而且允许开发和部署轻量级模型。我们是无人机追踪中首次应用对照学习。实验结果显示，提案的DRCI tracker在四个无人机测试 benchmark 上具有明显的 superiority，包括UAV123@10fps、DTB70、UAVDT和VisDrone2018。
</details></li>
</ul>
<hr>
<h2 id="Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding"><a href="#Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding" class="headerlink" title="Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding"></a>Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11448">http://arxiv.org/abs/2308.11448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiantao Wu, Shentong Mo, Muhammad Awais, Sara Atito, Zhenhua Feng, Josef Kittler</li>
<li>for: 本研究旨在评估自主学习技术在计算机视觉任务中的效iveness，以避免训练和finetuning大型模型。</li>
<li>methods: 本研究提出了一种评估协议，基于提示 patch，用于评估零shot segmentation的能力。此外，还提出了一种简单的SSL方法，称为MMC，该方法组合了masked image modelling、 momentum based self-distillation和global contrast等技术，以提高SSL ViTs的描述性表示。</li>
<li>results: 实验表明，MMC方法在零shot semantic segmentation中达到了顶尖水平，并且在不同的 dataset 上都表现出色。<details>
<summary>Abstract</summary>
Self-supervised pretraining (SSP) has emerged as a popular technique in machine learning, enabling the extraction of meaningful feature representations without labelled data. In the realm of computer vision, pretrained vision transformers (ViTs) have played a pivotal role in advancing transfer learning. Nonetheless, the escalating cost of finetuning these large models has posed a challenge due to the explosion of model size. This study endeavours to evaluate the effectiveness of pure self-supervised learning (SSL) techniques in computer vision tasks, obviating the need for finetuning, with the intention of emulating human-like capabilities in generalisation and recognition of unseen objects. To this end, we propose an evaluation protocol for zero-shot segmentation based on a prompting patch. Given a point on the target object as a prompt, the algorithm calculates the similarity map between the selected patch and other patches, upon that, a simple thresholding is applied to segment the target. Another evaluation is intra-object and inter-object similarity to gauge discriminatory ability of SSP ViTs. Insights from zero-shot segmentation from prompting and discriminatory abilities of SSP led to the design of a simple SSP approach, termed MMC. This approaches combines Masked image modelling for encouraging similarity of local features, Momentum based self-distillation for transferring semantics from global to local features, and global Contrast for promoting semantics of global features, to enhance discriminative representations of SSP ViTs. Consequently, our proposed method significantly reduces the overlap of intra-object and inter-object similarities, thereby facilitating effective object segmentation within an image. Our experiments reveal that MMC delivers top-tier results in zero-shot semantic segmentation across various datasets.
</details>
<details>
<summary>摘要</summary>
自顾学前教程（SSP）在机器学习中得到广泛应用，帮助提取有意义的特征表示无需标注数据。在计算机视觉领域，预训练视transformer（ViT）已经发挥了重要的作用，促进了转移学习。然而，模型的规模快速增长带来了训练成本的涨幅问题。本研究旨在评估无标注学习（SSL）技术在计算机视觉任务中的效果，不需要训练，以模仿人类对未看到对象的概念化和识别能力。为此，我们提出了一种零shot segmentation的评估协议，基于提示 patch。给定目标对象的一点作为提示，算法计算selected patch和其他 patch之间的相似度图，然后应用简单的阈值处理来 segment the target。此外，我们还进行了内部和外部相似性评估，以评估 SSL ViTs 的泛化能力。通过零shot segmentation和泛化能力的研究，我们设计了一种简单的 SSP 方法，称为 MMC。该方法结合了做masked image模型，自身融合和全局对比，以提高 SSL ViTs 的泛化表示。实验表明，MMC 可以在不同的 dataset 上达到顶尖的 zero-shot semantic segmentation结果。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-and-Exploring-Efficient-Fast-Adversarial-Training-via-LAW-Lipschitz-Regularization-and-Auto-Weight-Averaging"><a href="#Revisiting-and-Exploring-Efficient-Fast-Adversarial-Training-via-LAW-Lipschitz-Regularization-and-Auto-Weight-Averaging" class="headerlink" title="Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging"></a>Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11443">http://arxiv.org/abs/2308.11443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojun Jia, Yuefeng Chen, Xiaofeng Mao, Ranjie Duan, Jindong Gu, Rong Zhang, Hui Xue, Xiaochun Cao</li>
<li>For: The paper aims to improve the robustness of machine learning models against adversarial attacks while reducing the training cost of standard adversarial training.* Methods: The paper proposes an effective Lipschitz regularization method for fast adversarial training and explores the effect of data augmentation and weight averaging in fast adversarial training.* Results: The proposed method, FGSM-LAW, demonstrates superior robustness performance compared to state-of-the-art fast adversarial training methods and advanced standard adversarial training methods, as shown in experimental evaluations on four benchmark databases.<details>
<summary>Abstract</summary>
Fast Adversarial Training (FAT) not only improves the model robustness but also reduces the training cost of standard adversarial training. However, fast adversarial training often suffers from Catastrophic Overfitting (CO), which results in poor robustness performance. Catastrophic Overfitting describes the phenomenon of a sudden and significant decrease in robust accuracy during the training of fast adversarial training. Many effective techniques have been developed to prevent Catastrophic Overfitting and improve the model robustness from different perspectives. However, these techniques adopt inconsistent training settings and require different training costs, i.e, training time and memory costs, leading to unfair comparisons. In this paper, we conduct a comprehensive study of over 10 fast adversarial training methods in terms of adversarial robustness and training costs. We revisit the effectiveness and efficiency of fast adversarial training techniques in preventing Catastrophic Overfitting from the perspective of model local nonlinearity and propose an effective Lipschitz regularization method for fast adversarial training. Furthermore, we explore the effect of data augmentation and weight averaging in fast adversarial training and propose a simple yet effective auto weight averaging method to improve robustness further. By assembling these techniques, we propose a FGSM-based fast adversarial training method equipped with Lipschitz regularization and Auto Weight averaging, abbreviated as FGSM-LAW. Experimental evaluations on four benchmark databases demonstrate the superiority of the proposed method over state-of-the-art fast adversarial training methods and the advanced standard adversarial training methods.
</details>
<details>
<summary>摘要</summary>
快速对抗训练（FAT）不仅提高模型的Robustness，还可以降低标准对抗训练的训练成本。然而，快速对抗训练经常会遭遇Catastrophic Overfitting（CO），这会导致对抗性性能很差。Catastrophic Overfitting是指在快速对抗训练中突然和 significatively减少对抗性性能的现象。许多有效的技术已经开发以预防Catastrophic Overfitting并提高模型的Robustness，但这些技术采用不一致的训练设置和不同的训练成本，如训练时间和内存成本，导致不公平的比较。在这篇论文中，我们进行了快速对抗训练方法超过10种的全面研究，包括对抗性和训练成本。我们从模型本地非线性的角度重新评估快速对抗训练技术的效iveness和效率，并提出了一种有效的Lipschitz regularization方法。此外，我们还研究了快速对抗训练中数据扩展和权重平均的效果，并提出了一种简单又有效的自动权重平均方法，以进一步提高对抗性。通过组合这些技术，我们提出了一种基于FGSM的快速对抗训练方法，即FGSM-LAW。实验评估在四个基本数据库中，显示我们的方法在与标准对抗训练方法和先进的标准对抗训练方法相比，具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="SDeMorph-Towards-Better-Facial-De-morphing-from-Single-Morph"><a href="#SDeMorph-Towards-Better-Facial-De-morphing-from-Single-Morph" class="headerlink" title="SDeMorph: Towards Better Facial De-morphing from Single Morph"></a>SDeMorph: Towards Better Facial De-morphing from Single Morph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11442">http://arxiv.org/abs/2308.11442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nitish Shukla</li>
<li>for: 防止摸索攻击 (Morph Attack Detection)</li>
<li>methods: 无参考基于Diffusion Probabilistic Models (DDPM)和branched-UNet</li>
<li>results: 可以准确地回归真实的人脸特征，提高了人脸识别系统的安全性<details>
<summary>Abstract</summary>
Face Recognition Systems (FRS) are vulnerable to morph attacks. A face morph is created by combining multiple identities with the intention to fool FRS and making it match the morph with multiple identities. Current Morph Attack Detection (MAD) can detect the morph but are unable to recover the identities used to create the morph with satisfactory outcomes. Existing work in de-morphing is mostly reference-based, i.e. they require the availability of one identity to recover the other. Sudipta et al. \cite{ref9} proposed a reference-free de-morphing technique but the visual realism of outputs produced were feeble. In this work, we propose SDeMorph (Stably Diffused De-morpher), a novel de-morphing method that is reference-free and recovers the identities of bona fides. Our method produces feature-rich outputs that are of significantly high quality in terms of definition and facial fidelity. Our method utilizes Denoising Diffusion Probabilistic Models (DDPM) by destroying the input morphed signal and then reconstructing it back using a branched-UNet. Experiments on ASML, FRLL-FaceMorph, FRLL-MorDIFF, and SMDD datasets support the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
人脸识别系统（FRS）容易受到形态攻击。一个形态是通过将多个标识 combine 以达到欺骗 FRS 并让它匹配形态中的多个标识。现有的形态攻击检测（MAD）可以检测形态，但无法恢复创建形态的标识。现有的工作大多数是参考基于的，即需要一个标识的可用性来恢复另一个标识。Sudipta et al. \cite{ref9} 提出了一种无参考的恢复技术，但Visual realism 输出的质量不够高。在这个工作中，我们提出了SDeMorph（稳定扩散恢复器），一种新的无参考恢复方法，可以恢复创建形态的标识。我们的方法生成了高质量的输出，具有高度的定义和人脸准确性。我们的方法利用了Denosing Diffusion Probabilistic Models (DDPM)，通过破坏输入形态信号，然后使用分支-UNet 重建它。实验表明，我们的方法在 ASML、FRLL-FaceMorph、FRLL-MorDIFF 和 SMDD 数据集上具有效果。
</details></li>
</ul>
<hr>
<h2 id="Learning-a-More-Continuous-Zero-Level-Set-in-Unsigned-Distance-Fields-through-Level-Set-Projection"><a href="#Learning-a-More-Continuous-Zero-Level-Set-in-Unsigned-Distance-Fields-through-Level-Set-Projection" class="headerlink" title="Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection"></a>Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11441">http://arxiv.org/abs/2308.11441</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junshengzhou/levelsetudf">https://github.com/junshengzhou/levelsetudf</a></li>
<li>paper_authors: Junsheng Zhou, Baorui Ma, Shujuan Li, Yu-Shen Liu, Zhizhong Han</li>
<li>for: 该paper aimed to address the problem of reconstructing surfaces with open surfaces using unsigned distance functions (UDFs).</li>
<li>methods: The authors proposed to learn UDFs using neural networks and reconstruct surfaces with the gradients around the zero level set of the UDF. However, they found that the differential networks struggled to learn the zero level set, leading to large errors on unsigned distances and gradients. To resolve this, they proposed to learn a more continuous zero level set using level set projections.</li>
<li>results: The authors conducted comprehensive experiments in surface reconstruction for point clouds, real scans or depth maps, and demonstrated non-trivial improvements over the state-of-the-art methods. They also explored the performance in unsupervised point cloud upsampling and unsupervised point normal estimation with the learned UDF.<details>
<summary>Abstract</summary>
Latest methods represent shapes with open surfaces using unsigned distance functions (UDFs). They train neural networks to learn UDFs and reconstruct surfaces with the gradients around the zero level set of the UDF. However, the differential networks struggle from learning the zero level set where the UDF is not differentiable, which leads to large errors on unsigned distances and gradients around the zero level set, resulting in highly fragmented and discontinuous surfaces. To resolve this problem, we propose to learn a more continuous zero level set in UDFs with level set projections. Our insight is to guide the learning of zero level set using the rest non-zero level sets via a projection procedure. Our idea is inspired from the observations that the non-zero level sets are much smoother and more continuous than the zero level set. We pull the non-zero level sets onto the zero level set with gradient constraints which align gradients over different level sets and correct unsigned distance errors on the zero level set, leading to a smoother and more continuous unsigned distance field. We conduct comprehensive experiments in surface reconstruction for point clouds, real scans or depth maps, and further explore the performance in unsupervised point cloud upsampling and unsupervised point normal estimation with the learned UDF, which demonstrate our non-trivial improvements over the state-of-the-art methods. Code is available at https://github.com/junshengzhou/LevelSetUDF .
</details>
<details>
<summary>摘要</summary>
最新的方法使用无符号距离函数（UDF）来表示形状。它们使用神经网络学习UDF并重建表面的梯度在UDF的零水平面周围。然而，� diferencial networks 受到学习零水平面的约束，在零水平面不 diferenciable 的情况下，会导致大量的unsigned distance 和梯度 around the zero level set 的错误，从而导致表面变得高度分裂和不连续。为解决这问题，我们提议通过约束水平面投影来学习更加连续的零水平面。我们的想法来自于观察到非零水平面比零水平面更加平滑和连续。我们使用梯度约束将非零水平面投影到零水平面，以实现梯度的对齐和unsigned distance 错误的修正，从而导致更加平滑和连续的unsigned distance field。我们进行了广泛的实验，包括点云重建、真实扫描或深度图重建，以及不supervised point cloud upsampling 和不supervised point normal estimation 等，其中所获得的改进均非常 significativ。代码可以在 <https://github.com/junshengzhou/LevelSetUDF> 上找到。
</details></li>
</ul>
<hr>
<h2 id="PoseGraphNet-Enriching-3D-Human-Pose-with-Orientation-Estimation"><a href="#PoseGraphNet-Enriching-3D-Human-Pose-with-Orientation-Estimation" class="headerlink" title="PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation"></a>PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11440">http://arxiv.org/abs/2308.11440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soubarna Banik, Edvard Avagyan, Alejandro Mendoza Gracia, Alois Knoll</li>
<li>for: 本研究旨在提出一种基于图гра夫 convolutional neural network（Graph Convolutional Network，GCN）的2D-to-3D提升方法，以便预测人体3D姿态包括关节位置和骨orientation。</li>
<li>methods: 我们提出了一种名为PoseGraphNet++的新型2D-to-3D提升网络，该网络通过节点和边卷积来利用关节和骨特征。</li>
<li>results: 我们在多个标准测试集上评估了我们的模型，并与状态的艺术结果相比，我们的模型在位置和旋转度量上具有类似或更高的性能。此外，我们还通过广泛的减少研究，证明了PoseGraphNet++可以借鉴关节和骨之间的相互关系，从而提高预测性能。<details>
<summary>Abstract</summary>
Existing kinematic skeleton-based 3D human pose estimation methods only predict joint positions. Although this is sufficient to compute the yaw and pitch of the bone rotations, the roll around the axis of the bones remains unresolved by these methods. In this paper, we propose a novel 2D-to-3D lifting Graph Convolution Network named PoseGraphNet++ to predict the complete human pose including the joint positions and the bone orientations. We employ node and edge convolutions to utilize the joint and bone features. Our model is evaluated on multiple benchmark datasets, and its performance is either on par with or better than the state-of-the-art in terms of both position and rotation metrics. Through extensive ablation studies, we show that PoseGraphNet++ benefits from exploiting the mutual relationship between the joints and the bones.
</details>
<details>
<summary>摘要</summary>
现有的骨骼基本体系3D人姿估算方法只预测关节位置。尽管这足够计算关节的封顶和旋转，但是关节的滚动仍然无法被这些方法解决。在这篇论文中，我们提出了一种新的2D-to-3D提升图 convolution neural network（PoseGraphNet++），用于预测完整的人姿，包括关节位置和骨头orientation。我们利用节点和边卷积来利用关节和骨头特征。我们的模型在多个基准数据集上进行评估，其性能与或超过了现有的状态的艺术metric。通过广泛的减少研究，我们表明了PoseGraphNet++可以通过利用关节和骨头之间的相互关系来增强性能。
</details></li>
</ul>
<hr>
<h2 id="ScanNet-A-High-Fidelity-Dataset-of-3D-Indoor-Scenes"><a href="#ScanNet-A-High-Fidelity-Dataset-of-3D-Indoor-Scenes" class="headerlink" title="ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes"></a>ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11417">http://arxiv.org/abs/2308.11417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chandan Yeshwanth, Yueh-Cheng Liu, Matthias Nießner, Angela Dai</li>
<li>for: 提供了一个大规模的indoor场景数据集，其中每个场景都是使用高级激光扫描仪获得高分辨率的geometry和颜色信息，同时还包括了 региSTR的3300万像素图像和iPhone的RGB-D流。</li>
<li>methods: 使用高级激光扫描仪和DSLR相机捕捉场景图像，并使用iPhone捕捉RGB-D流。场景重建还包括了开放词汇的semantics标注，以便实现全面的semantic理解。</li>
<li>results: ScanNet++提供了一个新的real-worldbenchmark дляnovel view synthesis，包括高品质RGB捕捉和商业级图像的synthesis，以及一个新的3Dsemantic scene理解 benchmark，全面地涵盖了多种和抽象的semantic标注方案。ScanNet++ currently contains 460 scenes, 280,000 captured DSLR images, and over 3.7M iPhone RGBD frames.<details>
<summary>Abstract</summary>
We present ScanNet++, a large-scale dataset that couples together capture of high-quality and commodity-level geometry and color of indoor scenes. Each scene is captured with a high-end laser scanner at sub-millimeter resolution, along with registered 33-megapixel images from a DSLR camera, and RGB-D streams from an iPhone. Scene reconstructions are further annotated with an open vocabulary of semantics, with label-ambiguous scenarios explicitly annotated for comprehensive semantic understanding. ScanNet++ enables a new real-world benchmark for novel view synthesis, both from high-quality RGB capture, and importantly also from commodity-level images, in addition to a new benchmark for 3D semantic scene understanding that comprehensively encapsulates diverse and ambiguous semantic labeling scenarios. Currently, ScanNet++ contains 460 scenes, 280,000 captured DSLR images, and over 3.7M iPhone RGBD frames.
</details>
<details>
<summary>摘要</summary>
我们现在提供ScanNet++ dataset，这是一个大规模的数据集，它结合了高质量的激光扫描仪和商用级别的颜色捕捉indoor场景。每个场景都被高级激光扫描仪 capture，并与注册的3300万像素DSLR镜头拍摄的图像，以及iPhone的RGB-D流相匹配。场景重建还被标注为开放词汇Semantics，并且明确标注了涉及多义 Label的情况，以便全面理解semantic。ScanNet++提供了一个新的真实世界标准 benchmark for novel view synthesis，不仅来自高质量RGB捕捉，还来自商用级别的图像，以及一个新的3Dsemantic场景理解标准，全面涵盖多样化和涉及多义标签的情况。目前，ScanNet++包含460个场景，280,000个拍摄的DSLR图像，以及超过370万个iPhone RGBD帧。
</details></li>
</ul>
<hr>
<h2 id="MatFuse-Controllable-Material-Generation-with-Diffusion-Models"><a href="#MatFuse-Controllable-Material-Generation-with-Diffusion-Models" class="headerlink" title="MatFuse: Controllable Material Generation with Diffusion Models"></a>MatFuse: Controllable Material Generation with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11408">http://arxiv.org/abs/2308.11408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giuseppe Vecchio, Renato Sortino, Simone Palazzo, Concetto Spampinato</li>
<li>for: This paper aims to simplify the creation of SVBRDF maps in computer graphics, using a novel unified approach based on diffusion models.</li>
<li>methods: The proposed method integrates multiple sources of conditioning, such as color palettes, sketches, and pictures, to enable fine-grained control and flexibility in material synthesis.</li>
<li>results: The proposed method yields performance comparable to state-of-the-art approaches in estimating SVBRDF, both qualitatively and quantitatively, under various conditioning settings.<details>
<summary>Abstract</summary>
Creating high quality and realistic materials in computer graphics is a challenging and time-consuming task, which requires great expertise. In this paper, we present MatFuse, a novel unified approach that harnesses the generative power of diffusion models (DM) to simplify the creation of SVBRDF maps. Our DM-based pipeline integrates multiple sources of conditioning, such as color palettes, sketches, and pictures, enabling fine-grained control and flexibility in material synthesis. This design allows for the combination of diverse information sources (e.g., sketch + image embedding), enhancing creative possibilities in line with the principle of compositionality. We demonstrate the generative capabilities of the proposed method under various conditioning settings; on the SVBRDF estimation task, we show that our method yields performance comparable to state-of-the-art approaches, both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer"><a href="#Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer" class="headerlink" title="Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer"></a>Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11389">http://arxiv.org/abs/2308.11389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebeca Vétil, Clément Abi-Nader, Alexandre Bône, Marie-Pierre Vullierme, Marc-Michel Rohé, Pietro Gori, Isabelle Bloch</li>
<li>for: 这篇论文旨在解决深度学习医学影像特征（DLR）和手工设计医学影像特征（HCR）之间的重复性问题。</li>
<li>methods: 作者使用了一种简单的Variational Autoencoder（VAE）来提取DLR特征，并且通过降低这两种特征之间的相互信息来确保它们之间的独立性。</li>
<li>results: 作者的方法可以与手工设计的特征结合，并且通过一个分类器来预测抑制肝癌的早期标志。实验结果显示，结合非重复的DLR和HCR特征可以提高预测性能，比基eline方法更好。<details>
<summary>Abstract</summary>
We address the problem of learning Deep Learning Radiomics (DLR) that are not redundant with Hand-Crafted Radiomics (HCR). To do so, we extract DLR features using a VAE while enforcing their independence with HCR features by minimizing their mutual information. The resulting DLR features can be combined with hand-crafted ones and leveraged by a classifier to predict early markers of cancer. We illustrate our method on four early markers of pancreatic cancer and validate it on a large independent test set. Our results highlight the value of combining non-redundant DLR and HCR features, as evidenced by an improvement in the Area Under the Curve compared to baseline methods that do not address redundancy or solely rely on HCR features.
</details>
<details>
<summary>摘要</summary>
我们解决了深度学习医学影像特征（DLR）不重复的问题。我们使用VAE将DLR特征提取出来，并在这些特征之间强制独立性，以避免与手工设计的医学影像特征（HCR）之间的相互信息。这些DLR特征可以与手工设计的特征结合，并由分类器使用来预测早期癌症 markers。我们在四种早期肝癌标志物中进行了实验，并在一个大型独立测试集上验证了我们的方法。我们的结果显示了结合非重复的DLR和HCR特征的价值，即比基eline方法不 addressed 或仅仅靠赖于HCR特征的情况下，预测性能有所提高。
</details></li>
</ul>
<hr>
<h2 id="Targeted-Data-Augmentation-for-bias-mitigation"><a href="#Targeted-Data-Augmentation-for-bias-mitigation" class="headerlink" title="Targeted Data Augmentation for bias mitigation"></a>Targeted Data Augmentation for bias mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11386">http://arxiv.org/abs/2308.11386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Maria Ferlin, Michał Grochowski</li>
<li>for: This paper aims to address the issue of bias in AI systems by introducing a novel approach called Targeted Data Augmentation (TDA).</li>
<li>methods: The TDA method leverages classical data augmentation techniques to insert biases into the training data, which helps to mitigate biases in the models.</li>
<li>results: The paper shows that the TDA method can significantly decrease bias measures while maintaining a negligible increase in the error rate, using two diverse datasets of clinical skin lesions and male and female faces.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目的是解决人工智能系统中的偏见问题，通过引入一种新的方法 called Targeted Data Augmentation (TDA)。</li>
<li>methods: TDA方法利用经典的数据增强技术，插入偏见到训练数据中，以减少模型中的偏见。</li>
<li>results: 论文显示，TDA方法可以Significantly减少偏见度量，同时保持误差率的增长在较低水平，使用了两个多样化的数据集：皮肤病变和男女面孔数据集。<details>
<summary>Abstract</summary>
The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decrease in bias measures, ranging from two-fold to more than 50-fold, while maintaining a negligible increase in the error rate.
</details>
<details>
<summary>摘要</summary>
发展公正和伦理AI系统需要仔细考虑偏见缓解，这个领域经常被排除或忽略。在这个研究中，我们提出了一种新的和高效的偏见缓解方法，即目标数据扩展（TDA），该方法利用了经典数据扩展技术来解决数据和模型中的偏见问题。与努力除去偏见不同，我们的方法提议在训练过程中插入偏见，从而提高性能。为了标识偏见，我们对两个多样化的数据集进行了标注：一个是皮肤病变 dataset，另一个是男女脸部 dataset。这些偏见标注在本研究中首次公布，为未来研究提供了一个有价值的资源。通过对比方案插入，我们发现了框架、尺度和镜片等偏见对模型产生了重要影响。通过随机在训练过程中引入偏见，我们减少了这些偏见的度量，从2倍到更多于50倍，同时保持了错误率的增长在较低水平。
</details></li>
</ul>
<hr>
<h2 id="DALNet-A-Rail-Detection-Network-Based-on-Dynamic-Anchor-Line"><a href="#DALNet-A-Rail-Detection-Network-Based-on-Dynamic-Anchor-Line" class="headerlink" title="DALNet: A Rail Detection Network Based on Dynamic Anchor Line"></a>DALNet: A Rail Detection Network Based on Dynamic Anchor Line</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11381">http://arxiv.org/abs/2308.11381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yzichen/mmlanedet">https://github.com/yzichen/mmlanedet</a></li>
<li>paper_authors: Zichen Yu, Quanli Liu, Wei Wang, Liyong Zhang, Xiaoguang Zhao</li>
<li>for: 提高智能列车的轨道检测精度</li>
<li>methods: 基于动态锚点线的轨道检测网络DALNet，包括动态锚点生成器和轨道检测模块</li>
<li>results: DALNet在我们提供的DL-Rail轨道检测数据集和知名的Tusimple和LLAMAS车道检测标准 benchmark中达到了状态之精度表现。<details>
<summary>Abstract</summary>
Rail detection is one of the key factors for intelligent train. In the paper, motivated by the anchor line-based lane detection methods, we propose a rail detection network called DALNet based on dynamic anchor line. Aiming to solve the problem that the predefined anchor line is image agnostic, we design a novel dynamic anchor line mechanism. It utilizes a dynamic anchor line generator to dynamically generate an appropriate anchor line for each rail instance based on the position and shape of the rails in the input image. These dynamically generated anchor lines can be considered as better position references to accurately localize the rails than the predefined anchor lines. In addition, we present a challenging urban rail detection dataset DL-Rail with high-quality annotations and scenario diversity. DL-Rail contains 7000 pairs of images and annotations along with scene tags, and it is expected to encourage the development of rail detection. We extensively compare DALNet with many competitive lane methods. The results show that our DALNet achieves state-of-the-art performance on our DL-Rail rail detection dataset and the popular Tusimple and LLAMAS lane detection benchmarks. The code will be released at https://github.com/Yzichen/mmLaneDet.
</details>
<details>
<summary>摘要</summary>
铁路检测是智能列车的关键因素之一。在论文中，我们被动 anchor line-based 铁路检测方法所 inspirited，并提出了基于动态 anchor line 的铁路检测网络 DALNet。为了解决预定义的 anchor line 是图像不特定的问题，我们设计了一种新的动态 anchor line 机制。它利用动态 anchor line 生成器生成每个铁路实例的相应 anchor line，根据输入图像中铁路的位置和形状。这些动态生成的 anchor line 可以视为更好的位置参考，以准确地 Localize 铁路。此外，我们提供了一个挑战性的城市铁路检测数据集 DL-Rail，其包括7000个图像和注释对，以及Scene 标签。我们进行了广泛的比较，结果显示，我们的 DALNet 在我们的 DL-Rail 铁路检测数据集和知名的 Tusimple 和 LLAMAS lane detection benchmark 上均达到了状态组件表现。代码将在 GitHub 上发布，详细信息请参考 <https://github.com/Yzichen/mmLaneDet>。
</details></li>
</ul>
<hr>
<h2 id="Boundary-RL-Reinforcement-Learning-for-Weakly-Supervised-Prostate-Segmentation-in-TRUS-Images"><a href="#Boundary-RL-Reinforcement-Learning-for-Weakly-Supervised-Prostate-Segmentation-in-TRUS-Images" class="headerlink" title="Boundary-RL: Reinforcement Learning for Weakly-Supervised Prostate Segmentation in TRUS Images"></a>Boundary-RL: Reinforcement Learning for Weakly-Supervised Prostate Segmentation in TRUS Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11376">http://arxiv.org/abs/2308.11376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixi Yi, Vasilis Stavrinides, Zachary M. C. Baum, Qianye Yang, Dean C. Barratt, Matthew J. Clarkson, Yipeng Hu, Shaheer U. Saeed<br>for: 这个研究旨在提出一种弱度指导的类别分割方法，使用仅有单元标签进行训练，并且将类别分割看作是范围检测问题，而不是像前一些研究所使用的像素级别分类。methods: 这个方法使用了强化学习来训练一个控制函数，以寻找范围内的类别 bounding，使用一个从预训练的边界存在检测器获得的赏兹。results: 在评估这个方法的临床实际任务中，关于胆囊组织分类，我们获得了与其他已知的弱度指导方法相比，更好的表现，使用相同的标签，例如多个例问题学习。<details>
<summary>Abstract</summary>
We propose Boundary-RL, a novel weakly supervised segmentation method that utilises only patch-level labels for training. We envision the segmentation as a boundary detection problem, rather than a pixel-level classification as in previous works. This outlook on segmentation may allow for boundary delineation under challenging scenarios such as where noise artefacts may be present within the region-of-interest (ROI) boundaries, where traditional pixel-level classification-based weakly supervised methods may not be able to effectively segment the ROI. Particularly of interest, ultrasound images, where intensity values represent acoustic impedance differences between boundaries, may also benefit from the boundary delineation approach. Our method uses reinforcement learning to train a controller function to localise boundaries of ROIs using a reward derived from a pre-trained boundary-presence classifier. The classifier indicates when an object boundary is encountered within a patch, as the controller modifies the patch location in a sequential Markov decision process. The classifier itself is trained using only binary patch-level labels of object presence, which are the only labels used during training of the entire boundary delineation framework, and serves as a weak signal to inform the boundary delineation. The use of a controller function ensures that a sliding window over the entire image is not necessary. It also prevents possible false-positive or -negative cases by minimising number of patches passed to the boundary-presence classifier. We evaluate our proposed approach for a clinically relevant task of prostate gland segmentation on trans-rectal ultrasound images. We show improved performance compared to other tested weakly supervised methods, using the same labels e.g., multiple instance learning.
</details>
<details>
<summary>摘要</summary>
我们提出了Boundary-RL，一种新的弱类标注方法，只使用补丁级别标签进行训练。我们认为 segmentation 是一个边检测问题，而不是像前一些工作一样将每个像素分类为不同的类别。这种对 segmentation 的看法可能allow for 边界定义在具有噪声artifacts的区域内的场景中，其中传统的像素级别分类基于的弱类标注方法可能无法有效地分类区域。特别是，ultrasound 图像，其中 интенсивности值表示物体边界上的声学阻抗差异，也可能受惠于边界定义方法。我们的方法使用 reinforcement learning 训练一个控制函数，用于localize 区域内的边界。该控制函数通过一个Markov 决策过程来修改补丁位置，并且使用一个预训练的边界存在分类器来指示在补丁中是否遇到了物体边界。该分类器只使用补丁级别标签进行训练，这些标签也是训练整个边界定义框架的唯一标签。我们使用控制函数来避免使用滑块窗口覆盖整个图像，并且避免可能的 false-positive 或 false-negative 情况。我们对肾脏成像进行评估，并与其他测试的弱类标注方法进行比较。我们显示出我们的方法在评估中表现出色，使用相同的标签。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Interpretable-Object-Abstraction-via-Clustering-based-Slot-Initialization"><a href="#Enhancing-Interpretable-Object-Abstraction-via-Clustering-based-Slot-Initialization" class="headerlink" title="Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization"></a>Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11369">http://arxiv.org/abs/2308.11369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Gao, Bernard Hohmann, Gerhard Neumann</li>
<li>For: The paper is focused on improving object-centric representations using slots for efficient, flexible, and interpretable abstraction from low-level perceptual features in a compositional scene.* Methods: The paper proposes using clustering algorithms conditioned on perceptual input features to initialize the slot representations, and designs permutation invariant and permutation equivariant versions of this layer to enable exchangeable slot representations after clustering.* Results: The paper shows that its method outperforms prior works consistently, especially for complex scenes, through experiments on object discovery and novel view synthesis tasks with various datasets.<details>
<summary>Abstract</summary>
Object-centric representations using slots have shown the advances towards efficient, flexible and interpretable abstraction from low-level perceptual features in a compositional scene. Current approaches randomize the initial state of slots followed by an iterative refinement. As we show in this paper, the random slot initialization significantly affects the accuracy of the final slot prediction. Moreover, current approaches require a predetermined number of slots from prior knowledge of the data, which limits the applicability in the real world. In our work, we initialize the slot representations with clustering algorithms conditioned on the perceptual input features. This requires an additional layer in the architecture to initialize the slots given the identified clusters. We design permutation invariant and permutation equivariant versions of this layer to enable the exchangeable slot representations after clustering. Additionally, we employ mean-shift clustering to automatically identify the number of slots for a given scene. We evaluate our method on object discovery and novel view synthesis tasks with various datasets. The results show that our method outperforms prior works consistently, especially for complex scenes.
</details>
<details>
<summary>摘要</summary>
使用槽来表示对象已经取得了高效、灵活和可解释的抽象优势。现有方法在初始化槽时随机，然后进行迭代优化。我们在这篇论文中表明，随机槽初始化会对最终槽预测的准确性产生显著影响。此外，现有方法需要先知道数据中的槽数量，这限制了实际应用的可行性。在我们的工作中，我们使用基于感知输入特征的 clustering 算法来初始化槽表示。这需要一个额外的架构层来初始化槽给确定的群集。我们设计了卷积不变和卷积对称版本的这层，以便在 clustering 后换取可交换的槽表示。此外，我们使用 Mean-Shift  clustering 自动确定Scene中的槽数量。我们在对象发现和新视图合成任务中使用了多个数据集进行评估，结果表明，我们的方法在复杂场景下一直高于先前的方法。
</details></li>
</ul>
<hr>
<h2 id="Towards-Clip-Free-Quantized-Super-Resolution-Networks-How-to-Tame-Representative-Images"><a href="#Towards-Clip-Free-Quantized-Super-Resolution-Networks-How-to-Tame-Representative-Images" class="headerlink" title="Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images"></a>Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11365">http://arxiv.org/abs/2308.11365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alperen Kalay, Bahri Batuhan Bilecen, Mustafa Ayazoglu</li>
<li>for: 这个研究旨在解决 SR 网络中训练后量化 (PTQ) 阶段的一个重要问题，即代表性数据集 (RD)。</li>
<li>methods: 我们提出了一个新的 clip-free 量化管道 (CFQP)，并提供了广泛的实验证明，以 cleverly 使用 FP32 模型的输出来增强 RD 图像。这种方法可以消除不必要的 clipped 活动层，从而提高整体稳定性、减少推理时间（最多下降到 54%）、提高视觉质量 Results  compared to INT8 clipped models，并在一些 SR 模型上甚至超越了不量化 FP32 模型。</li>
<li>results: 我们的方法可以在某些 SR 模型上提高视觉质量，同时减少推理时间，并且不需要重新训练 clipped activation。在一些情况下，我们的方法可以超越不量化 FP32 模型， both in runtime and visual quality。<details>
<summary>Abstract</summary>
Super-resolution (SR) networks have been investigated for a while, with their mobile and lightweight versions gaining noticeable popularity recently. Quantization, the procedure of decreasing the precision of network parameters (mostly FP32 to INT8), is also utilized in SR networks for establishing mobile compatibility. This study focuses on a very important but mostly overlooked post-training quantization (PTQ) step: representative dataset (RD), which adjusts the quantization range for PTQ. We propose a novel pipeline (clip-free quantization pipeline, CFQP) backed up with extensive experimental justifications to cleverly augment RD images by only using outputs of the FP32 model. Using the proposed pipeline for RD, we can successfully eliminate unwanted clipped activation layers, which nearly all mobile SR methods utilize to make the model more robust to PTQ in return for a large overhead in runtime. Removing clipped activations with our method significantly benefits overall increased stability, decreased inference runtime up to 54% on some SR models, better visual quality results compared to INT8 clipped models - and outperforms even some FP32 non-quantized models, both in runtime and visual quality, without the need for retraining with clipped activation.
</details>
<details>
<summary>摘要</summary>
超解像（SR）网络已经被研究了一段时间，其移动和轻量级版本在最近得到了关注。量化，减小网络参数的精度（主要是FP32到INT8），也在SR网络中使用，以实现移动兼容性。这项研究关注一个很重要但又多少被注意的后training量化（PTQ）步骤：代表数据集（RD），它调整PTQ的范围。我们提出一个新的批处理管道（clip-free quantization pipeline，CFQP），并提供了详细的实验证明，以智能地增强RD图像，只使用FP32模型的输出。使用我们的方法进行RD，可以成功地消除无用的clip activation层，这些层通常在移动SR方法中使用，以使模型更具 robustness to PTQ，但是带来了大量的运行时间开销。从我们的方法中消除clip activation可以获得更好的稳定性、下降到54%的推理时间、更好的视觉质量结果，并且超过了INT8clip模型，以及FP32非量化模型，无需重新训练clip activation。
</details></li>
</ul>
<hr>
<h2 id="Exemplar-Free-Continual-Transformer-with-Convolutions"><a href="#Exemplar-Free-Continual-Transformer-with-Convolutions" class="headerlink" title="Exemplar-Free Continual Transformer with Convolutions"></a>Exemplar-Free Continual Transformer with Convolutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11357">http://arxiv.org/abs/2308.11357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anurag Roy, Vinay Kumar Verma, Sravan Voonna, Kripabandhu Ghosh, Saptarshi Ghosh, Abir Das</li>
<li>for: 这 paper 的目的是提出一种新的无例子（exemplar-free）的类&#x2F;任务逐步学习方法，不需要在测试时显式提供任务标识符（task identifier），并且不需要保留之前训练集。</li>
<li>methods: 该方法使用 transformer 架构，并通过重新权重 multi-head self-attention 层中的键、查询和值权重来实现类&#x2F;任务逐步学习。具体来说，通过 convolution 来重新权重这些权重，以便在每个任务上保持低的参数数量。此外，使用图像增强技术来预测任务，而无需在测试时显式提供任务标识符。</li>
<li>results: 实验结果表明，该方法可以在四个 benchmark 数据集上超越许多竞争方法，而且需要更少的参数。<details>
<summary>Abstract</summary>
Continual Learning (CL) involves training a machine learning model in a sequential manner to learn new information while retaining previously learned tasks without the presence of previous training data. Although there has been significant interest in CL, most recent CL approaches in computer vision have focused on convolutional architectures only. However, with the recent success of vision transformers, there is a need to explore their potential for CL. Although there have been some recent CL approaches for vision transformers, they either store training instances of previous tasks or require a task identifier during test time, which can be limiting. This paper proposes a new exemplar-free approach for class/task incremental learning called ConTraCon, which does not require task-id to be explicitly present during inference and avoids the need for storing previous training instances. The proposed approach leverages the transformer architecture and involves re-weighting the key, query, and value weights of the multi-head self-attention layers of a transformer trained on a similar task. The re-weighting is done using convolution, which enables the approach to maintain low parameter requirements per task. Additionally, an image augmentation-based entropic task identification approach is used to predict tasks without requiring task-ids during inference. Experiments on four benchmark datasets demonstrate that the proposed approach outperforms several competitive approaches while requiring fewer parameters.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine"><a href="#Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine" class="headerlink" title="Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine"></a>Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11340">http://arxiv.org/abs/2308.11340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesca Razzano, Mariapia Rita Iandolo, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 本研究使用Synthetic Aperture Radar (SAR)和光学数据进行地面分类。</li>
<li>methods: 通过在Google Earth Engine (GEE)平台上实施监督式机器学习（ML）算法，将Sentinel-1 (S-1)和Sentinel-2 (S-2)数据集成起来，用于地面覆盖分类。</li>
<li>results: 研究结果表明，在这种情况下，雷达和光学远程探测提供了补偿信息，有利地面覆盖分类，通常导致映射精度的提高。此外，本研究也证明了GEE在处理大量卫星数据方面的emerging角色。<details>
<summary>Abstract</summary>
In this study, Synthetic Aperture Radar (SAR) and optical data are both considered for Earth surface classification. Specifically, the integration of Sentinel-1 (S-1) and Sentinel-2 (S-2) data is carried out through supervised Machine Learning (ML) algorithms implemented on the Google Earth Engine (GEE) platform for the classification of a particular region of interest. Achieved results demonstrate how in this case radar and optical remote detection provide complementary information, benefiting surface cover classification and generally leading to increased mapping accuracy. In addition, this paper works in the direction of proving the emerging role of GEE as an effective cloud-based tool for handling large amounts of satellite data.
</details>
<details>
<summary>摘要</summary>
在这项研究中，人造 aperature radar（SAR）和光学数据都被考虑用于地球表面分类。具体来说，Sentinel-1（S-1）和Sentinel-2（S-2）数据的集成通过在Google Earth Engine（GEE）平台上实施监督式机器学习（ML）算法进行地区特定的分类。实现的结果表明在这种情况下，雷达和光学远程探测提供了补做的信息，从而改善表面覆盖分类和通常提高地图准确性。此外，这篇论文还在irection towards proving the emerging role of GEE as an effective cloud-based tool for handling large amounts of satellite data.
</details></li>
</ul>
<hr>
<h2 id="Object-Detection-Difficulty-Suppressing-Over-aggregation-for-Faster-and-Better-Video-Object-Detection"><a href="#Object-Detection-Difficulty-Suppressing-Over-aggregation-for-Faster-and-Better-Video-Object-Detection" class="headerlink" title="Object Detection Difficulty: Suppressing Over-aggregation for Faster and Better Video Object Detection"></a>Object Detection Difficulty: Suppressing Over-aggregation for Faster and Better Video Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11327">http://arxiv.org/abs/2308.11327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bingqingzhang/odd-vod">https://github.com/bingqingzhang/odd-vod</a></li>
<li>paper_authors: Bingqing Zhang, Sen Wang, Yifan Liu, Brano Kusy, Xue Li, Jiajun Liu</li>
<li>for: 提高视频对象检测（VOD）系统的实用性</li>
<li>methods: 提出一种图像级对象检测难度（ODD）指标，用于衡量检测图像中对象的难度，并在VOD过程中应用该指标来减少过度聚合。</li>
<li>results: 对8种VOD模型进行了广泛的实验，结果表明，当选择全局参照帧时，ODD-VOD可以不断提高全局基于VOD模型的准确率。当用于加速时，ODD-VOD可以不断提高帧数（FPS），并且不会降低准确率。<details>
<summary>Abstract</summary>
Current video object detection (VOD) models often encounter issues with over-aggregation due to redundant aggregation strategies, which perform feature aggregation on every frame. This results in suboptimal performance and increased computational complexity. In this work, we propose an image-level Object Detection Difficulty (ODD) metric to quantify the difficulty of detecting objects in a given image. The derived ODD scores can be used in the VOD process to mitigate over-aggregation. Specifically, we train an ODD predictor as an auxiliary head of a still-image object detector to compute the ODD score for each image based on the discrepancies between detection results and ground-truth bounding boxes. The ODD score enhances the VOD system in two ways: 1) it enables the VOD system to select superior global reference frames, thereby improving overall accuracy; and 2) it serves as an indicator in the newly designed ODD Scheduler to eliminate the aggregation of frames that are easy to detect, thus accelerating the VOD process. Comprehensive experiments demonstrate that, when utilized for selecting global reference frames, ODD-VOD consistently enhances the accuracy of Global-frame-based VOD models. When employed for acceleration, ODD-VOD consistently improves the frames per second (FPS) by an average of 73.3% across 8 different VOD models without sacrificing accuracy. When combined, ODD-VOD attains state-of-the-art performance when competing with many VOD methods in both accuracy and speed. Our work represents a significant advancement towards making VOD more practical for real-world applications.
</details>
<details>
<summary>摘要</summary>
当前的视频对象检测（VOD）模型经常遇到过度聚合的问题，这是因为 redundancy 的聚合策略在每帧进行特征聚合，从而导致性能下降和计算复杂性增加。在这种情况下，我们提出了一个图像级别的对象检测困难度（ODD）度量，用于衡量检测图像中对象的困难度。这些计算的ODD分数可以在 VOD 过程中使用，以避免过度聚合。我们在 VOD 系统中训练了一个 ODD 预测器，用于计算每幅图像的 ODD 分数，基于检测结果和真实 bounding box 之间的差异。ODD 分数可以在两种方式帮助 VOD 系统：1）选择更高精度的全局参照帧，以提高总体精度；2）作为 ODD 调度器中的指标，以消除容易检测的帧的聚合，从而加速 VOD 过程。我们的实验表明，当用于选择全局参照帧时，ODD-VOD 可以不断提高全球帧基本 VOD 模型的精度。当用于加速时，ODD-VOD 可以平均提高 FPS 值 by 73.3%，无需牺牲精度。当两者结合使用时，ODD-VOD 可以在精度和速度两个方面占据领先地位，代表了对 VOD 实际应用的一项重要进步。
</details></li>
</ul>
<hr>
<h2 id="CiteTracker-Correlating-Image-and-Text-for-Visual-Tracking"><a href="#CiteTracker-Correlating-Image-and-Text-for-Visual-Tracking" class="headerlink" title="CiteTracker: Correlating Image and Text for Visual Tracking"></a>CiteTracker: Correlating Image and Text for Visual Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11322">http://arxiv.org/abs/2308.11322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NorahGreen/CiteTracker">https://github.com/NorahGreen/CiteTracker</a></li>
<li>paper_authors: Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang</li>
<li>for: 提高视觉跟踪中目标模型和推理的精度，使得在目标呈现大幅变化时仍能准确跟踪。</li>
<li>methods: 提出了一种基于图像和文本的目标跟踪方法，通过图像转文本模块将目标图像区域转换为描述性文本，并通过动态描述模块适应目标变化以提高跟踪精度。</li>
<li>results: 经过了五种不同的数据集测试，并与现有方法进行比较，研究发现提出的跟踪方法在跟踪目标呈现大幅变化时表现出了优于现有方法的性能。<details>
<summary>Abstract</summary>
Existing visual tracking methods typically take an image patch as the reference of the target to perform tracking. However, a single image patch cannot provide a complete and precise concept of the target object as images are limited in their ability to abstract and can be ambiguous, which makes it difficult to track targets with drastic variations. In this paper, we propose the CiteTracker to enhance target modeling and inference in visual tracking by connecting images and text. Specifically, we develop a text generation module to convert the target image patch into a descriptive text containing its class and attribute information, providing a comprehensive reference point for the target. In addition, a dynamic description module is designed to adapt to target variations for more effective target representation. We then associate the target description and the search image using an attention-based correlation module to generate the correlated features for target state reference. Extensive experiments on five diverse datasets are conducted to evaluate the proposed algorithm and the favorable performance against the state-of-the-art methods demonstrates the effectiveness of the proposed tracking method.
</details>
<details>
<summary>摘要</summary>
现有的视觉跟踪方法通常使用图像块作为目标的参考点进行跟踪。然而，单个图像块无法提供完整和准确的目标对象概念，因为图像有限制，容易受到歧义和变化的影响，这使得跟踪目标变化具有挑战性。在这篇论文中，我们提出了CiteTracker，用于增强视觉跟踪中目标模型化和推理的方法。具体来说，我们开发了一个文本生成模块，将目标图像块转换为包含类和特征信息的详细文本描述，为目标提供了全面的参考点。此外，我们还设计了一个动态描述模块，以适应目标变化，以更有效地表示目标。然后，我们使用关注机制来关联目标描述和搜索图像，生成相关特征，用于目标状态参考。我们对五种不同的数据集进行了广泛的实验，以评估提出的算法效果。结果表明，与现有方法相比，我们的跟踪方法具有优秀的效果。
</details></li>
</ul>
<hr>
<h2 id="Using-and-Abusing-Equivariance"><a href="#Using-and-Abusing-Equivariance" class="headerlink" title="Using and Abusing Equivariance"></a>Using and Abusing Equivariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11316">http://arxiv.org/abs/2308.11316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Edixhoven, Attila Lengyel, Jan van Gemert</li>
<li>for: 学习破坏对称性的群同态卷积神经网络</li>
<li>methods: 使用抽样来学习破坏对称性，对2D旋转和反射进行研究</li>
<li>results: 发现小变化的输入维度可以使通用的网络变得相对均匀，而不是精确均匀；研究不同对称性的网络如何影响其性能，并发现在训练数据中的对称性与网络的对称性不同时，相对均匀网络可以放弃自己的对称性约束，与精确均匀网络匹配或超越它们在常用 benchmark 数据上。<details>
<summary>Abstract</summary>
In this paper we show how Group Equivariant Convolutional Neural Networks use subsampling to learn to break equivariance to their symmetries. We focus on 2D rotations and reflections and investigate the impact of broken equivariance on network performance. We show that a change in the input dimension of a network as small as a single pixel can be enough for commonly used architectures to become approximately equivariant, rather than exactly. We investigate the impact of networks not being exactly equivariant and find that approximately equivariant networks generalise significantly worse to unseen symmetries compared to their exactly equivariant counterparts. However, when the symmetries in the training data are not identical to the symmetries of the network, we find that approximately equivariant networks are able to relax their own equivariant constraints, causing them to match or outperform exactly equivariant networks on common benchmark datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们展示了GROUP等变征 convolutional neural networks 如何通过抽象来学习破坏对其Symmetries的等变征性。我们关注了2D旋转和反射，并调查了不等变征性对网络性能的影响。我们发现，只需将网络输入维度改变一个像素，常用的架构就可以变得相对等变征了，而不是精确等变征。我们调查了不等变征网络在未seen Symmetries上的generalization情况，发现它们与等变征网络相比在Common benchmark datasets上匹配或超越。但当网络中的Symmetries与训练数据中的Symmetries不同时，我们发现approximately等变征网络能够放弃自己的等变征约束，使其与等变征网络在Common benchmark datasets上匹配或超越。
</details></li>
</ul>
<hr>
<h2 id="Approaching-human-3D-shape-perception-with-neurally-mappable-models"><a href="#Approaching-human-3D-shape-perception-with-neurally-mappable-models" class="headerlink" title="Approaching human 3D shape perception with neurally mappable models"></a>Approaching human 3D shape perception with neurally mappable models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11300">http://arxiv.org/abs/2308.11300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas P. O’Connell, Tyler Bonnen, Yoni Friedman, Ayush Tewari, Josh B. Tenenbaum, Vincent Sitzmann, Nancy Kanwisher</li>
<li>for: 这研究旨在理解人类如何自然地推测三维形状，以及这种能力是如何被计算机模型重建的？</li>
<li>methods: 研究使用了一种新的计算模型，即3D神经场（3D-LFN），该模型基于深度神经网络（DNN），并通过多视角训练和多视角学习目标来实现人类水平的性能。</li>
<li>results: 研究发现，3D-LFN支持人类水平的三维匹配判断，并在针对标准DNN模型的攻击性定义比较中表现出色。此外，研究还发现，通过多视角训练和多视角学习目标，even conventional DNN architectures可以更接近人类行为。但是，这些模型在处理新的物体类别时仍有所限制。<details>
<summary>Abstract</summary>
Humans effortlessly infer the 3D shape of objects. What computations underlie this ability? Although various computational models have been proposed, none of them capture the human ability to match object shape across viewpoints. Here, we ask whether and how this gap might be closed. We begin with a relatively novel class of computational models, 3D neural fields, which encapsulate the basic principles of classic analysis-by-synthesis in a deep neural network (DNN). First, we find that a 3D Light Field Network (3D-LFN) supports 3D matching judgments well aligned to humans for within-category comparisons, adversarially-defined comparisons that accentuate the 3D failure cases of standard DNN models, and adversarially-defined comparisons for algorithmically generated shapes with no category structure. We then investigate the source of the 3D-LFN's ability to achieve human-aligned performance through a series of computational experiments. Exposure to multiple viewpoints of objects during training and a multi-view learning objective are the primary factors behind model-human alignment; even conventional DNN architectures come much closer to human behavior when trained with multi-view objectives. Finally, we find that while the models trained with multi-view learning objectives are able to partially generalize to new object categories, they fall short of human alignment. This work provides a foundation for understanding human shape inferences within neurally mappable computational architectures and highlights important questions for future work.
</details>
<details>
<summary>摘要</summary>
人类努力地推断物体的3D形状。这些计算是如何进行的？虽然一些计算模型已经被提出，但None of them capture the human ability to match object shape across viewpoints。在这里，我们问whether and how this gap might be closed。我们开始于一种相对新的计算模型，3D神经场（3D-LFN），这个模型涵盖了经典分析synthesis的基本原理，并将其 embedding在深度神经网络（DNN）中。我们发现，3D-LFN支持3D匹配判断，与人类匹配的性能很高，包括在类别内的比较、对抗定义的比较和对算法生成的形状进行比较。然后，我们通过一系列计算实验来研究3D-LFN的能力是如何实现人类对应的性能的。我们发现，在训练中 expose to multiple viewpoints of objects和多视图学习目标是模型人类匹配的主要因素。甚至使用标准DNN架构，通过多视图学习目标进行训练，模型的性能就会更接近人类的行为。最后，我们发现，使用多视图学习目标训练的模型可以部分地泛化到新的物体类别，但是它们仍然不够接近人类的匹配。这个研究提供了人类形状推断在神经Mappable的计算架构中的基础，并高亮了未来工作的重要问题。
</details></li>
</ul>
<hr>
<h2 id="BHSD-A-3D-Multi-Class-Brain-Hemorrhage-Segmentation-Dataset"><a href="#BHSD-A-3D-Multi-Class-Brain-Hemorrhage-Segmentation-Dataset" class="headerlink" title="BHSD: A 3D Multi-Class Brain Hemorrhage Segmentation Dataset"></a>BHSD: A 3D Multi-Class Brain Hemorrhage Segmentation Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11298">http://arxiv.org/abs/2308.11298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biao Wu, Yutong Xie, Zeyu Zhang, Jinchao Ge, Kaspar Yaxley, Suzan Bahadir, Qi Wu, Yifan Liu, Minh-Son To</li>
<li>for: 本研究旨在提供一个3D多类血肿 segmentation dataset（BHSD），以便为血肿 segmentation任务提供支持。</li>
<li>methods: 本研究使用了深度学习技术来进行 médical image segmentation，并应用于血肿 segmentation任务。</li>
<li>results: 本研究提供了一个包含192个Volume的多类血肿数据集，以及2200个slice-level标注的数据集。通过对这些数据集进行supervised和semi-supervisedsegmentation任务的实验，我们证明了数据集的实用性。<details>
<summary>Abstract</summary>
Intracranial hemorrhage (ICH) is a pathological condition characterized by bleeding inside the skull or brain, which can be attributed to various factors. Identifying, localizing and quantifying ICH has important clinical implications, in a bleed-dependent manner. While deep learning techniques are widely used in medical image segmentation and have been applied to the ICH segmentation task, existing public ICH datasets do not support the multi-class segmentation problem. To address this, we develop the Brain Hemorrhage Segmentation Dataset (BHSD), which provides a 3D multi-class ICH dataset containing 192 volumes with pixel-level annotations and 2200 volumes with slice-level annotations across five categories of ICH. To demonstrate the utility of the dataset, we formulate a series of supervised and semi-supervised ICH segmentation tasks. We provide experimental results with state-of-the-art models as reference benchmarks for further model developments and evaluations on this dataset.
</details>
<details>
<summary>摘要</summary>
Intracranial hemorrhage (ICH) 是一种生物学条件，表示脑内或脑部内出血，这可以归因于多种因素。正确地识别、定位和评估ICH具有重要临床意义，具体取决于出血情况。although deep learning techniques have been widely used in medical image segmentation and have been applied to the ICH segmentation task, existing public ICH datasets do not support the multi-class segmentation problem. To address this, we develop the Brain Hemorrhage Segmentation Dataset (BHSD), which provides a 3D multi-class ICH dataset containing 192 volumes with pixel-level annotations and 2200 volumes with slice-level annotations across five categories of ICH. To demonstrate the utility of the dataset, we formulate a series of supervised and semi-supervised ICH segmentation tasks. We provide experimental results with state-of-the-art models as reference benchmarks for further model developments and evaluations on this dataset.Here's the word-for-word translation:Intracranial hemorrhage (ICH) 是一种生物学条件，表示脑内或脑部内出血，这可以归因于多种因素。正确地识别、定位和评估ICH具有重要临床意义，具体取决于出血情况。虽然深度学习技术已经广泛应用于医疗图像分割，并已经应用于ICH分割任务，但现有的公共ICH数据集不支持多类分割问题。为解决这个问题，我们开发了脑出血分割数据集（BHSD），该数据集包含192卷Pixel级别标注和2200卷Slice级别标注，涵盖五类ICH。为证明数据集的实用性，我们提出了一系列的超级vised和半监督ICH分割任务。我们提供了实验结果，作为参考标准模型，以便进一步的模型开发和评估。
</details></li>
</ul>
<hr>
<h2 id="PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction"><a href="#PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction" class="headerlink" title="PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction"></a>PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11281">http://arxiv.org/abs/2308.11281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eyal Hanania, Ilya Volovik, Lilach Barkat, Israel Cohen, Moti Freiman</li>
<li>for: The paper is focused on developing a deep-learning-based method for motion correction in free-breathing T1 mapping, which can improve the accuracy and accessibility of diffuse myocardial disease diagnosis.</li>
<li>methods: The proposed method, called PCMC-T1, incorporates a physically-constrained signal decay model into a deep-learning network to correct for motion artifacts in free-breathing T1 mapping.</li>
<li>results: PCMC-T1 was compared to baseline methods using a 5-fold experimental setup on a public dataset of 210 patients and demonstrated superior model fitting quality and clinical impact, with anatomical alignment results that were comparable to the baseline methods.<details>
<summary>Abstract</summary>
T1 mapping is a quantitative magnetic resonance imaging (qMRI) technique that has emerged as a valuable tool in the diagnosis of diffuse myocardial diseases. However, prevailing approaches have relied heavily on breath-hold sequences to eliminate respiratory motion artifacts. This limitation hinders accessibility and effectiveness for patients who cannot tolerate breath-holding. Image registration can be used to enable free-breathing T1 mapping. Yet, inherent intensity differences between the different time points make the registration task challenging. We introduce PCMC-T1, a physically-constrained deep-learning model for motion correction in free-breathing T1 mapping. We incorporate the signal decay model into the network architecture to encourage physically-plausible deformations along the longitudinal relaxation axis. We compared PCMC-T1 to baseline deep-learning-based image registration approaches using a 5-fold experimental setup on a publicly available dataset of 210 patients. PCMC-T1 demonstrated superior model fitting quality (R2: 0.955) and achieved the highest clinical impact (clinical score: 3.93) compared to baseline methods (0.941, 0.946 and 3.34, 3.62 respectively). Anatomical alignment results were comparable (Dice score: 0.9835 vs. 0.984, 0.988). Our code and trained models are available at https://github.com/eyalhana/PCMC-T1.
</details>
<details>
<summary>摘要</summary>
T1映射是一种量化核磁共振成像（qMRI）技术，已经成为诊断散布性心肺疾病的有价值工具。然而，现有的方法几乎完全依赖呼吸停止序列来消除呼吸运动 artifacts。这限制了患者的访问和效果，特别是那些无法忍受呼吸停止的患者。图像 регистраción可以使得呼吸自由T1映射成为可能。然而，内在的时刻点不同INTENSITY带来了注册任务的挑战。我们介绍PCMC-T1，一种基于物理约束的深度学习模型，用于呼吸自由T1映射中的运动 corrections。我们将信号衰减模型integrated into网络架构，以便鼓励物理可能的扭轴运动。我们与基线方法进行比较，使用一个5-fold实验设置，在公共可用的210名患者数据集上进行了测试。PCMC-T1显示出了最高的模型适应质量（R2: 0.955）和最高的临床影响（临床分数：3.93），与基线方法（0.941、0.946和3.34、3.62分别）相比。结构对应结果相似（Dice分数：0.9835 vs. 0.984、0.988）。我们的代码和训练模型可以在https://github.com/eyalhana/PCMC-T1中获得。
</details></li>
</ul>
<hr>
<h2 id="HMD-NeMo-Online-3D-Avatar-Motion-Generation-From-Sparse-Observations"><a href="#HMD-NeMo-Online-3D-Avatar-Motion-Generation-From-Sparse-Observations" class="headerlink" title="HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations"></a>HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11261">http://arxiv.org/abs/2308.11261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadegh Aliakbarian, Fatemeh Saleh, David Collier, Pashmina Cameron, Darren Cosker</li>
<li>for: 这个论文的目的是提出一种能够生成正确和可信的全身动作，即使只有部分手部可见，以提高混合现实场景中的吸引力。</li>
<li>methods: 该论文使用了一种名为HMD-NeMo的轻量级神经网络，通过在线和实时方式预测全身动作，并使用了新的时间适应mask токен来促进合理的动作在手部不可见情况下。</li>
<li>results: 经过了广泛的分析和评估，该论文在AMASS数据集上达到了新的状态元。<details>
<summary>Abstract</summary>
Generating both plausible and accurate full body avatar motion is the key to the quality of immersive experiences in mixed reality scenarios. Head-Mounted Devices (HMDs) typically only provide a few input signals, such as head and hands 6-DoF. Recently, different approaches achieved impressive performance in generating full body motion given only head and hands signal. However, to the best of our knowledge, all existing approaches rely on full hand visibility. While this is the case when, e.g., using motion controllers, a considerable proportion of mixed reality experiences do not involve motion controllers and instead rely on egocentric hand tracking. This introduces the challenge of partial hand visibility owing to the restricted field of view of the HMD. In this paper, we propose the first unified approach, HMD-NeMo, that addresses plausible and accurate full body motion generation even when the hands may be only partially visible. HMD-NeMo is a lightweight neural network that predicts the full body motion in an online and real-time fashion. At the heart of HMD-NeMo is the spatio-temporal encoder with novel temporally adaptable mask tokens that encourage plausible motion in the absence of hand observations. We perform extensive analysis of the impact of different components in HMD-NeMo and introduce a new state-of-the-art on AMASS dataset through our evaluation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>创造真实和准确的全身人物动作是混合现实场景中质量体验的关键。头戴设备（HMD）通常只提供头和手6个自由度的输入信号。近期，不同的方法已经实现了在只有头和手信号的情况下取得了出色的表现。然而，根据我们所知，所有现有的方法均依赖于全手可见。这会导致在使用动作控制器时是可见的，但是一部分混合现实经验不使用动作控制器，而是基于自己центric的手姿跟踪。这引入了只有部分手可见的挑战，即HMD的视野限制。在这篇论文中，我们提出了第一个统一的方法，即HMD-NeMo，它可以在线和实时方式下生成真实和准确的全身动作。HMD-NeMo是一个轻量级的神经网络，它通过在线和实时方式下预测全身动作来解决部分手可见的挑战。我们对HMD-NeMo中不同组件的影响进行了广泛的分析，并通过我们的评估而提出了新的状态码。
</details></li>
</ul>
<hr>
<h2 id="Video-BagNet-short-temporal-receptive-fields-increase-robustness-in-long-term-action-recognition"><a href="#Video-BagNet-short-temporal-receptive-fields-increase-robustness-in-long-term-action-recognition" class="headerlink" title="Video BagNet: short temporal receptive fields increase robustness in long-term action recognition"></a>Video BagNet: short temporal receptive fields increase robustness in long-term action recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11249">http://arxiv.org/abs/2308.11249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ombretta/videobagnet">https://github.com/ombretta/videobagnet</a></li>
<li>paper_authors: Ombretta Strafforello, Xin Liu, Klamer Schutte, Jan van Gemert</li>
<li>for: 提高视频动作识别模型的 robustness，使其能够更好地承受视频中的子动作顺序变化。</li>
<li>methods: 对于现有的深度3D convolutional模型，我们采用了限制时间响应领域大小的方法，从而实现了模型的时间响应领域的缩小。</li>
<li>results: 我们在 sintetic 和 real-world 视频数据集上进行了实验，发现短时间响应领域的模型具有较高的 robustness，而大于17帧的时间响应领域模型具有较低的 robustness。<details>
<summary>Abstract</summary>
Previous work on long-term video action recognition relies on deep 3D-convolutional models that have a large temporal receptive field (RF). We argue that these models are not always the best choice for temporal modeling in videos. A large temporal receptive field allows the model to encode the exact sub-action order of a video, which causes a performance decrease when testing videos have a different sub-action order. In this work, we investigate whether we can improve the model robustness to the sub-action order by shrinking the temporal receptive field of action recognition models. For this, we design Video BagNet, a variant of the 3D ResNet-50 model with the temporal receptive field size limited to 1, 9, 17 or 33 frames. We analyze Video BagNet on synthetic and real-world video datasets and experimentally compare models with varying temporal receptive fields. We find that short receptive fields are robust to sub-action order changes, while larger temporal receptive fields are sensitive to the sub-action order.
</details>
<details>
<summary>摘要</summary>
previous research on long-term video action recognition relies on deep 3D-convolutional models with a large temporal receptive field (RF). we argue that these models are not always the best choice for temporal modeling in videos. a large temporal receptive field allows the model to encode the exact sub-action order of a video, which causes a performance decrease when testing videos have a different sub-action order. in this work, we investigate whether we can improve the model robustness to the sub-action order by shrinking the temporal receptive field of action recognition models. for this, we design video bagnet, a variant of the 3D ResNet-50 model with the temporal receptive field size limited to 1, 9, 17 or 33 frames. we analyze video bagnet on synthetic and real-world video datasets and experimentally compare models with varying temporal receptive fields. we find that short receptive fields are robust to sub-action order changes, while larger temporal receptive fields are sensitive to the sub-action order.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format instead.
</details></li>
</ul>
<hr>
<h2 id="Are-current-long-term-video-understanding-datasets-long-term"><a href="#Are-current-long-term-video-understanding-datasets-long-term" class="headerlink" title="Are current long-term video understanding datasets long-term?"></a>Are current long-term video understanding datasets long-term?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11244">http://arxiv.org/abs/2308.11244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ombretta/longterm_datasets">https://github.com/ombretta/longterm_datasets</a></li>
<li>paper_authors: Ombretta Strafforello, Klamer Schutte, Jan van Gemert</li>
<li>for: This paper aims to evaluate the suitability of video datasets for long-term action recognition.</li>
<li>methods: The proposed method defines long-term actions as those that cannot be recognized using solely short-term information, and tests this definition on three popular real-world datasets.</li>
<li>results: The study finds that the existing datasets can be effectively solved using shortcuts based on short-term information, and encourages researchers to use datasets that require long-term information to be solved.Here’s the simplified Chinese text for the three pieces of information:</li>
<li>for: 这篇论文目的是评估视频数据集是否适用于长期动作识别。</li>
<li>methods: 该方法定义长期动作为不能通过短期信息alone来识别的动作，并对三个实际世界数据集进行测试。</li>
<li>results: 研究发现现有数据集可以使用短期信息 shortcut 进行解决，并促使研究人员使用需要长期信息来解决的数据集。<details>
<summary>Abstract</summary>
Many real-world applications, from sport analysis to surveillance, benefit from automatic long-term action recognition. In the current deep learning paradigm for automatic action recognition, it is imperative that models are trained and tested on datasets and tasks that evaluate if such models actually learn and reason over long-term information. In this work, we propose a method to evaluate how suitable a video dataset is to evaluate models for long-term action recognition. To this end, we define a long-term action as excluding all the videos that can be correctly recognized using solely short-term information. We test this definition on existing long-term classification tasks on three popular real-world datasets, namely Breakfast, CrossTask and LVU, to determine if these datasets are truly evaluating long-term recognition. Our study reveals that these datasets can be effectively solved using shortcuts based on short-term information. Following this finding, we encourage long-term action recognition researchers to make use of datasets that need long-term information to be solved.
</details>
<details>
<summary>摘要</summary>
很多现实世界应用，从运动分析到监测，都会受益于自动长期动作识别。在当前的深度学习框架中，自动动作识别模型的训练和测试通常是基于长期信息的。在这种情况下，我们提议一种方法来评估视频集是否适用于评估长期动作识别模型。为此，我们定义长期动作为排除所有可以通过短期信息来正确地识别的视频。我们在三个流行的实际世界数据集上进行测试，分别是Breakfast、CrossTask和LVU，以确定这些数据集是否真的评估长期认知。我们的研究发现，这些数据集可以通过快捷途径基于短期信息来解决。根据这个发现，我们鼓励长期动作识别研究人员使用需要长期信息来解决的数据集。
</details></li>
</ul>
<hr>
<h2 id="LOCATE-Self-supervised-Object-Discovery-via-Flow-guided-Graph-cut-and-Bootstrapped-Self-training"><a href="#LOCATE-Self-supervised-Object-Discovery-via-Flow-guided-Graph-cut-and-Bootstrapped-Self-training" class="headerlink" title="LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and Bootstrapped Self-training"></a>LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and Bootstrapped Self-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11239">http://arxiv.org/abs/2308.11239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silky Singh, Shripad Deshmukh, Mausoom Sarkar, Balaji Krishnamurthy</li>
<li>for: 本研究旨在无需人工监督下完成图像和视频数据集中的对象分割问题。</li>
<li>methods: 我们提出了一种自动化对象发现方法，利用运动和外观信息来生成高质量的对象分割面积。我们在传统图像树剖中添加了运动信息，并与外观信息进行线性组合来生成边权。</li>
<li>results: 我们的方法在多个标准视频对象分割、图像吸引力检测和对象分割 benchmark 上达到了与现状对照的性能。我们还通过自我训练来进一步提高性能。在审查实验中，我们的方法在未知领域中的转移性也得到了证明。<details>
<summary>Abstract</summary>
Learning object segmentation in image and video datasets without human supervision is a challenging problem. Humans easily identify moving salient objects in videos using the gestalt principle of common fate, which suggests that what moves together belongs together. Building upon this idea, we propose a self-supervised object discovery approach that leverages motion and appearance information to produce high-quality object segmentation masks. Specifically, we redesign the traditional graph cut on images to include motion information in a linear combination with appearance information to produce edge weights. Remarkably, this step produces object segmentation masks comparable to the current state-of-the-art on multiple benchmarks. To further improve performance, we bootstrap a segmentation network trained on these preliminary masks as pseudo-ground truths to learn from its own outputs via self-training. We demonstrate the effectiveness of our approach, named LOCATE, on multiple standard video object segmentation, image saliency detection, and object segmentation benchmarks, achieving results on par with and, in many cases surpassing state-of-the-art methods. We also demonstrate the transferability of our approach to novel domains through a qualitative study on in-the-wild images. Additionally, we present extensive ablation analysis to support our design choices and highlight the contribution of each component of our proposed method.
</details>
<details>
<summary>摘要</summary>
学习图像和视频集合中的对象分割无人监督是一个具有挑战性的问题。人类容易通过gestalt原则的共同命运来识别视频中移动的焦点对象，这个原则表明移动 вместе的对象属于同一个集合。基于这个想法，我们提出了一种自动化对象发现方法，利用运动和外观信息生成高质量的对象分割面积。 Specifically,我们重新设计了传统的图像截割方法，在线性组合中包括运动信息和外观信息来生成边重量。这一步生成的对象分割面积与当前状态的各种标准测试 benchmark 相当。为了进一步提高性能，我们使用这些初步的面积作为 pseudo-ground truth 来自我准备一个 segmentation 网络，并通过自我训练来学习自己的输出。我们命名这种方法为 LOCATE，并在多个标准视频对象分割、图像焦点检测和对象分割 bencmarks 上实现了与和超越当前状态的方法。我们还进行了质量研究，以证明我们的方法在新领域中的传输性。此外，我们还提供了广泛的减少分析，以支持我们的设计选择，并高亮每个方法的贡献。
</details></li>
</ul>
<hr>
<h2 id="Affordance-segmentation-of-hand-occluded-containers-from-exocentric-images"><a href="#Affordance-segmentation-of-hand-occluded-containers-from-exocentric-images" class="headerlink" title="Affordance segmentation of hand-occluded containers from exocentric images"></a>Affordance segmentation of hand-occluded containers from exocentric images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11233">http://arxiv.org/abs/2308.11233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Apicella, Alessio Xompero, Edoardo Ragusa, Riccardo Berta, Andrea Cavallaro, Paolo Gastaldo</li>
<li>for: 本研究旨在解决手持物体上 occlusion 问题，提高机器人可视且抓取物体的可行性。</li>
<li>methods: 提议的模型使用辅助分支处理物体和手部分 separately，学习受 occlusion 影响的可行特征。</li>
<li>results: 实验表明，我们的模型在实际和混合现实图像上具有更好的可行分割和泛化能力，比现有模型更好。<details>
<summary>Abstract</summary>
Visual affordance segmentation identifies the surfaces of an object an agent can interact with. Common challenges for the identification of affordances are the variety of the geometry and physical properties of these surfaces as well as occlusions. In this paper, we focus on occlusions of an object that is hand-held by a person manipulating it. To address this challenge, we propose an affordance segmentation model that uses auxiliary branches to process the object and hand regions separately. The proposed model learns affordance features under hand-occlusion by weighting the feature map through hand and object segmentation. To train the model, we annotated the visual affordances of an existing dataset with mixed-reality images of hand-held containers in third-person (exocentric) images. Experiments on both real and mixed-reality images show that our model achieves better affordance segmentation and generalisation than existing models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Visual affordance segmentation 可以识别物体上可互动的表面。常见的挑战是物体表面的多样性和物理特性以及遮挡。在这篇论文中，我们专注于人手持物体时的遮挡问题。为解决这个挑战，我们提议一种基于辅助分支的可互动分割模型。该模型通过对手和物体区域进行分割来学习可互动特征。通过对手和物体分割来权重特征图，以便在手遮挡情况下学习可互动特征。我们使用混合现实图像的混合现实数据集进行训练。实验表明，我们的模型在实际和混合现实图像上的可互动分割和泛化性比较好。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="LDP-Feat-Image-Features-with-Local-Differential-Privacy"><a href="#LDP-Feat-Image-Features-with-Local-Differential-Privacy" class="headerlink" title="LDP-Feat: Image Features with Local Differential Privacy"></a>LDP-Feat: Image Features with Local Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11223">http://arxiv.org/abs/2308.11223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Pittaluga, Bingbing Zhuang</li>
<li>for: 保护隐私，防止恶意攻击者通过图像特征恢复原始图像</li>
<li>methods: 使用嵌入式法律空间和对抗性特征样本来隐藏图像特征，并提出了两种新的倒转攻击来缓解隐私风险</li>
<li>results: 实现了在保护隐私的情况下具有强大的视觉本地化性能，并提供了一种基于地方散布隐私的方法，这种方法可以提供固定的隐私泄露 bound，不受攻击强度的影响<details>
<summary>Abstract</summary>
Modern computer vision services often require users to share raw feature descriptors with an untrusted server. This presents an inherent privacy risk, as raw descriptors may be used to recover the source images from which they were extracted. To address this issue, researchers recently proposed privatizing image features by embedding them within an affine subspace containing the original feature as well as adversarial feature samples. In this paper, we propose two novel inversion attacks to show that it is possible to (approximately) recover the original image features from these embeddings, allowing us to recover privacy-critical image content. In light of such successes and the lack of theoretical privacy guarantees afforded by existing visual privacy methods, we further propose the first method to privatize image features via local differential privacy, which, unlike prior approaches, provides a guaranteed bound for privacy leakage regardless of the strength of the attacks. In addition, our method yields strong performance in visual localization as a downstream task while enjoying the privacy guarantee.
</details>
<details>
<summary>摘要</summary>
现代计算机视觉服务经常需要用户将原始特征描述分发到不可信服务器。这会导致隐私风险，因为原始特征可能可以用来恢复源图像。为解决这问题，研究人员最近提出了嵌入图像特征的私有化方法，以确保图像内容的隐私。在这篇论文中，我们提出了两种新的反向攻击，以示它们可以（相对）回归原始图像特征，从而恢复隐私关键的图像内容。另外，我们还提出了首个基于本地差分隐私的图像特征隐私方法，与先前的方法不同，它提供了隐私泄露的保证，无论攻击者的强度如何。此外，我们的方法在视觉本地化任务中具有强表现力，同时享有隐私保证。
</details></li>
</ul>
<hr>
<h2 id="DiffCloth-Diffusion-Based-Garment-Synthesis-and-Manipulation-via-Structural-Cross-modal-Semantic-Alignment"><a href="#DiffCloth-Diffusion-Based-Garment-Synthesis-and-Manipulation-via-Structural-Cross-modal-Semantic-Alignment" class="headerlink" title="DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment"></a>DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11206">http://arxiv.org/abs/2308.11206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xujie Zhang, Binbin Yang, Michael C. Kampffmeyer, Wenqing Zhang, Shiyue Zhang, Guansong Lu, Liang Lin, Hang Xu, Xiaodan Liang</li>
<li>for: 这个论文旨在提高模式融合和修改的方式，帮助时尚设计师更加方便地生成和修改他们的设计。</li>
<li>methods: 这个论文使用了DiffCloth，一种扩展了Diffusion-based管道，通过strucurally aligning cross-modal semantics来强化 diffusion models的可 composeability。</li>
<li>results:  experiments on CM-Fashion benchmark demonstrate that DiffCloth can both yield state-of-the-art garment synthesis results and support flexible manipulation with region consistency.<details>
<summary>Abstract</summary>
Cross-modal garment synthesis and manipulation will significantly benefit the way fashion designers generate garments and modify their designs via flexible linguistic interfaces.Current approaches follow the general text-to-image paradigm and mine cross-modal relations via simple cross-attention modules, neglecting the structural correspondence between visual and textual representations in the fashion design domain. In this work, we instead introduce DiffCloth, a diffusion-based pipeline for cross-modal garment synthesis and manipulation, which empowers diffusion models with flexible compositionality in the fashion domain by structurally aligning the cross-modal semantics. Specifically, we formulate the part-level cross-modal alignment as a bipartite matching problem between the linguistic Attribute-Phrases (AP) and the visual garment parts which are obtained via constituency parsing and semantic segmentation, respectively. To mitigate the issue of attribute confusion, we further propose a semantic-bundled cross-attention to preserve the spatial structure similarities between the attention maps of attribute adjectives and part nouns in each AP. Moreover, DiffCloth allows for manipulation of the generated results by simply replacing APs in the text prompts. The manipulation-irrelevant regions are recognized by blended masks obtained from the bundled attention maps of the APs and kept unchanged. Extensive experiments on the CM-Fashion benchmark demonstrate that DiffCloth both yields state-of-the-art garment synthesis results by leveraging the inherent structural information and supports flexible manipulation with region consistency.
</details>
<details>
<summary>摘要</summary>
cross-modal 服装合成和修改将会对时尚设计师如何生成服装和修改他们的设计进行深见改进，通过灵活的语言接口。目前的方法采用通用的文本到图像模式，通过简单的跨模态关系抽象模块，忽略了时尚设计领域中的视觉表示结构匹配。在这个工作中，我们发展了DiffCloth，一种基于扩散的渠道管道，用于跨模态服装合成和修改，具有时尚领域的可 compose 性。具体来说，我们将部级跨模态匹配问题定义为语言特征短语（AP）和视觉服装部分之间的对应问题，并通过分词分析和 semantic segmentation 获得视觉服装部分。为了解决特征混淆问题，我们还提出了一种 semantic-bundled 跨注意力，以保持每个AP的注意力地图之间的空间结构相似性。此外，DiffCloth 支持通过简单地更换文本提示中的AP来进行 manipulate 操作，并且识别并保持不变的混合mask。广泛的实验表明，DiffCloth 可以利用内置的结构信息，同时支持灵活的 manipulate 操作，并保持区域一致性。
</details></li>
</ul>
<hr>
<h2 id="Masked-Cross-image-Encoding-for-Few-shot-Segmentation"><a href="#Masked-Cross-image-Encoding-for-Few-shot-Segmentation" class="headerlink" title="Masked Cross-image Encoding for Few-shot Segmentation"></a>Masked Cross-image Encoding for Few-shot Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11201">http://arxiv.org/abs/2308.11201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenbo Xu, Huaxi Huang, Ming Cheng, Litao Yu, Qiang Wu, Jian Zhang</li>
<li>for: 这个论文旨在提高几张支持图像上的几个类别的描述，使用少量标注图像进行推断。</li>
<li>methods: 该方法使用Masked Cross-Image Encoding（MCE）来捕捉对象细节的共同视觉特征，以及图像之间的相互依赖关系。</li>
<li>results: 实验表明，该方法在PASCAL-$5^i$和COCO-$20^i$中表现出色，可以快速学习新类别，并且对于描述对象细节的任务有进一步的改进。<details>
<summary>Abstract</summary>
Few-shot segmentation (FSS) is a dense prediction task that aims to infer the pixel-wise labels of unseen classes using only a limited number of annotated images. The key challenge in FSS is to classify the labels of query pixels using class prototypes learned from the few labeled support exemplars. Prior approaches to FSS have typically focused on learning class-wise descriptors independently from support images, thereby ignoring the rich contextual information and mutual dependencies among support-query features. To address this limitation, we propose a joint learning method termed Masked Cross-Image Encoding (MCE), which is designed to capture common visual properties that describe object details and to learn bidirectional inter-image dependencies that enhance feature interaction. MCE is more than a visual representation enrichment module; it also considers cross-image mutual dependencies and implicit guidance. Experiments on FSS benchmarks PASCAL-$5^i$ and COCO-$20^i$ demonstrate the advanced meta-learning ability of the proposed method.
</details>
<details>
<summary>摘要</summary>
几个例图分类（FSS）是一种密集预测任务，旨在只使用有限数量的标注图像来预测未经看过的类别。关键挑战在FSS中是将查询像素的标签分类用支持图像中学习的类 prototype。现有的FSS方法通常是独立地从支持图像中学习类Descriptor，从而忽略了支持图像和查询图像之间的丰富Contextual information和相互依赖关系。为了解决这一限制，我们提出了一种联合学习方法，称为Masked Cross-Image Encoding（MCE），旨在捕捉对象细节中的共同视觉特性，以及在支持图像和查询图像之间的双向依赖关系。MCE不仅是一种视觉表示增强模块，还考虑了图像之间的相互依赖关系和隐藏导航。在PASCAL-$5^i$和COCO-$20^i$的FSS标准测试集上，我们的提议方法表现出了更高级的元学习能力。
</details></li>
</ul>
<hr>
<h2 id="Novel-view-Synthesis-and-Pose-Estimation-for-Hand-Object-Interaction-from-Sparse-Views"><a href="#Novel-view-Synthesis-and-Pose-Estimation-for-Hand-Object-Interaction-from-Sparse-Views" class="headerlink" title="Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views"></a>Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11198">http://arxiv.org/abs/2308.11198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentian Qu, Zhaopeng Cui, Yinda Zhang, Chenyu Meng, Cuixia Ma, Xiaoming Deng, Hongan Wang</li>
<li>for: 这个论文主要是关于手对象交互的理解和生成三维手对象交互的方法。</li>
<li>methods: 该论文提出了一种基于神经网络的渲染和姿态估计系统，用于从稀疏视图中理解手对象交互。该系统还可以实现3D手对象交互编辑。</li>
<li>results: 实验表明，该方法比前州艺术法具有更高的性能。Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这个论文主要是关于手对象交互的理解和生成三维手对象交互的方法。</li>
<li>methods: 该论文提出了一种基于神经网络的渲染和姿态估计系统，用于从稀疏视图中理解手对象交互。该系统还可以实现3D手对象交互编辑。</li>
<li>results: 实验表明，该方法比前州艺术法具有更高的性能。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Hand-object interaction understanding and the barely addressed novel view synthesis are highly desired in the immersive communication, whereas it is challenging due to the high deformation of hand and heavy occlusions between hand and object. In this paper, we propose a neural rendering and pose estimation system for hand-object interaction from sparse views, which can also enable 3D hand-object interaction editing. We share the inspiration from recent scene understanding work that shows a scene specific model built beforehand can significantly improve and unblock vision tasks especially when inputs are sparse, and extend it to the dynamic hand-object interaction scenario and propose to solve the problem in two stages. We first learn the shape and appearance prior knowledge of hands and objects separately with the neural representation at the offline stage. During the online stage, we design a rendering-based joint model fitting framework to understand the dynamic hand-object interaction with the pre-built hand and object models as well as interaction priors, which thereby overcomes penetration and separation issues between hand and object and also enables novel view synthesis. In order to get stable contact during the hand-object interaction process in a sequence, we propose a stable contact loss to make the contact region to be consistent. Experiments demonstrate that our method outperforms the state-of-the-art methods. Code and dataset are available in project webpage https://iscas3dv.github.io/HO-NeRF.
</details>
<details>
<summary>摘要</summary>
手动对象交互理解和 hardly addressed 新视图合成是 immerse 通信中的高优先级需求，但是受到手动对象的高变形和对手与对象的 occlusion 的影响，是一个挑战。在这篇论文中，我们提出了一种基于 neural 渲染和 pose 估计的手动对象交互从稀疏视图系统，可以帮助解决3D 手动对象交互编辑问题。我们 draw 了 scene 理解工作的 inspirations，使用 scene 特定模型在 offline 阶段学习手动对象交互的 shape 和 appearance 特征，然后在 online 阶段使用 rendering-based joint 模型来理解动态手动对象交互，并且通过 pre-built 手和对象模型以及交互 prior 来解决 penetration 和 separation 问题，并实现 novel view synthesis。为了在手动对象交互过程中保持稳定的 contacts，我们提出了一种稳定 contact loss。实验表明，我们的方法超过了现有方法的性能。代码和数据集可以在项目网站 https://iscas3dv.github.io/HO-NeRF 中获取。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Aware-Prompt-Tuning-for-Generalizable-Vision-Language-Models"><a href="#Knowledge-Aware-Prompt-Tuning-for-Generalizable-Vision-Language-Models" class="headerlink" title="Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models"></a>Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11186">http://arxiv.org/abs/2308.11186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baoshuo Kan, Teng Wang, Wenpeng Lu, Xiantong Zhen, Weili Guan, Feng Zheng</li>
<li>for: 这篇论文旨在提出一种基于人工知识的潜在图像分类模型，以提高图像分类器的泛化能力。</li>
<li>methods: 该方法使用两种不同类型的知识感知提问，一种是精确提取对象类型的描述信息，另一种是通过学习获得总上下文信息。此外，还设计了一个适应头来归一化重要视觉特征。</li>
<li>results: 对11种广泛使用的基准数据集进行了广泛的实验，结果表明，KAPT方法可以在少量样本下进行图像分类，特别是在新类别上具有泛化能力。与当前最佳方法CoCoOp相比，KAPT方法在新类别上显示了有利的性能，升准值为3.22%和2.57%。<details>
<summary>Abstract</summary>
Pre-trained vision-language models, e.g., CLIP, working with manually designed prompts have demonstrated great capacity of transfer learning. Recently, learnable prompts achieve state-of-the-art performance, which however are prone to overfit to seen classes, failing to generalize to unseen classes. In this paper, we propose a Knowledge-Aware Prompt Tuning (KAPT) framework for vision-language models. Our approach takes inspiration from human intelligence in which external knowledge is usually incorporated into recognizing novel categories of objects. Specifically, we design two complementary types of knowledge-aware prompts for the text encoder to leverage the distinctive characteristics of category-related external knowledge. The discrete prompt extracts the key information from descriptions of an object category, and the learned continuous prompt captures overall contexts. We further design an adaptation head for the visual encoder to aggregate salient attentive visual cues, which establishes discriminative and task-aware visual representations. We conduct extensive experiments on 11 widely-used benchmark datasets and the results verify the effectiveness in few-shot image classification, especially in generalizing to unseen categories. Compared with the state-of-the-art CoCoOp method, KAPT exhibits favorable performance and achieves an absolute gain of 3.22% on new classes and 2.57% in terms of harmonic mean.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的视觉语言模型，如CLIP，通过手动设计的提示符可以实现很好的转移学习效果。然而，这些提示符容易过拟合已经看过的类别，导致无法泛化到未看过的类别。在这篇论文中，我们提出了一个知识感知提示调整（KAPT）框架，用于视觉语言模型。我们的方法启取人类智能中在识别新类别对象时，通常会 incorporate 外部知识。我们设计了两种强调知识的提示符，一种是精确提取对象类别的描述信息，另一种是学习对象上的总上下文。此外，我们还设计了一个适应头，用于Visual encoder 中的视觉特征汇聚，以建立特异性和任务意识的视觉表示。我们对11种广泛使用的 benchmark 数据集进行了广泛的实验，结果证明了我们的方法的有效性，特别是在新类别上的泛化。相比之下，与状态之arte CoCoOp 方法相比，KAPT 表现更加优秀，在新类别上实现了3.22%的绝对提升和2.57%的harmonic mean。
</details></li>
</ul>
<hr>
<h2 id="MEGA-Multimodal-Alignment-Aggregation-and-Distillation-For-Cinematic-Video-Segmentation"><a href="#MEGA-Multimodal-Alignment-Aggregation-and-Distillation-For-Cinematic-Video-Segmentation" class="headerlink" title="MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation"></a>MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11185">http://arxiv.org/abs/2308.11185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Najmeh Sadoughi, Xinyu Li, Avijit Vajpayee, David Fan, Bing Shuai, Hector Santos-Villalobos, Vimal Bhat, Rohith MV</li>
<li>for: 本研究旨在提高长形视频（&gt;60分钟）的场景和剧情槽分 segmentation 效果。</li>
<li>methods: 本研究提出了一种基于多媒体Modalities的 Multimodal alignmEnt aGgregation and distillAtion（MEGA）方法，通过多种输入的粗略对应和模式维度的嵌入来解决长形视频的同步问题。</li>
<li>results: 实验结果表明，MEGA方法在 MovieNet 数据集上场景分 segmentation  Task 上提高了+1.19%的平均准确率，并在 TRIPOD 数据集上剧情分 segmentation  Task 上提高了+5.51%的总一致率。<details>
<summary>Abstract</summary>
Previous research has studied the task of segmenting cinematic videos into scenes and into narrative acts. However, these studies have overlooked the essential task of multimodal alignment and fusion for effectively and efficiently processing long-form videos (>60min). In this paper, we introduce Multimodal alignmEnt aGgregation and distillAtion (MEGA) for cinematic long-video segmentation. MEGA tackles the challenge by leveraging multiple media modalities. The method coarsely aligns inputs of variable lengths and different modalities with alignment positional encoding. To maintain temporal synchronization while reducing computation, we further introduce an enhanced bottleneck fusion layer which uses temporal alignment. Additionally, MEGA employs a novel contrastive loss to synchronize and transfer labels across modalities, enabling act segmentation from labeled synopsis sentences on video shots. Our experimental results show that MEGA outperforms state-of-the-art methods on MovieNet dataset for scene segmentation (with an Average Precision improvement of +1.19%) and on TRIPOD dataset for act segmentation (with a Total Agreement improvement of +5.51%)
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ReFit-Recurrent-Fitting-Network-for-3D-Human-Recovery"><a href="#ReFit-Recurrent-Fitting-Network-for-3D-Human-Recovery" class="headerlink" title="ReFit: Recurrent Fitting Network for 3D Human Recovery"></a>ReFit: Recurrent Fitting Network for 3D Human Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11184">http://arxiv.org/abs/2308.11184</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yufu-wang/ReFit">https://github.com/yufu-wang/ReFit</a></li>
<li>paper_authors: Yufu Wang, Kostas Daniilidis</li>
<li>for: 本研究旨在提出一种基于神经网络的单影像参数3D人体重建方法，以解决人体重建问题。</li>
<li>methods: 本方法使用反馈更新循环，通过在每个迭代步骤中将人体模型中的关键点投影到特征图中，并使用回归型更新器来调整模型以更好地适应图像。</li>
<li>results: 本研究表明，使用反馈更新循环可以更快速地训练神经网络模型，同时提高了标准benchmark测试数据集上的性能。此外，本方法还可以应用于多视图适应和单视图形状适应等其他优化设定。<details>
<summary>Abstract</summary>
We present Recurrent Fitting (ReFit), a neural network architecture for single-image, parametric 3D human reconstruction. ReFit learns a feedback-update loop that mirrors the strategy of solving an inverse problem through optimization. At each iterative step, it reprojects keypoints from the human model to feature maps to query feedback, and uses a recurrent-based updater to adjust the model to fit the image better. Because ReFit encodes strong knowledge of the inverse problem, it is faster to train than previous regression models. At the same time, ReFit improves state-of-the-art performance on standard benchmarks. Moreover, ReFit applies to other optimization settings, such as multi-view fitting and single-view shape fitting. Project website: https://yufu-wang.github.io/refit_humans/
</details>
<details>
<summary>摘要</summary>
我们介绍Recurrent Fitting（ReFit），一个神经网络架构，用于单一图像、Parametric 3D人体重建。ReFit学习了一个反馈-更新循环，与解析问题的解决策略相似。在每个迭代步骤中，它将人体模型中的关键点投射到特征对称中，以查询反馈，并使用回归型更新器进行调整，以更好地适应图像。由于ReFit传递强大的倒数问题知识，因此它在训练时比前一代 regression 模型更快。同时，ReFit在标准参考数据上提高了现场性能。此外，ReFit可以应用到其他优化设定，例如多视点适摄和单视点形状适摄。相关网站：https://yufu-wang.github.io/refit_humans/
</details></li>
</ul>
<hr>
<h2 id="A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology"><a href="#A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology" class="headerlink" title="A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology"></a>A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11179">http://arxiv.org/abs/2308.11179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibtihaj Ahmad, Syed Muhammad Israr, Zain Ul Islam<br>for: 这paper是用于同时进行核体分割和分类的数字 histology 的研究，它们在计算机协助癌症诊断中扮演着关键的角色，但是这个问题仍然是一个挑战。methods: 这paper使用了一种多头decoder的结构，其中每个头都有独立的权重损失函数，用于生成核体分割、边提议和分类地图。这些输出被用来进行后处理，生成最终的核体分割和分类结果。results: 该paper实现了高性能的核体分割和分类，其中semantic segmentation的Dice score为0.841，实例 segmentation的bPQ score为0.713，和nuclei classification的mPQ score为0.633。此外，该方法在19种组织中得到了普适性。<details>
<summary>Abstract</summary>
Simultaneous segmentation and classification of nuclei in digital histology play an essential role in computer-assisted cancer diagnosis; however, it remains challenging. The highest achieved binary and multi-class Panoptic Quality (PQ) remains as low as 0.68 bPQ and 0.49 mPQ, respectively. It is due to the higher staining variability, variability across the tissue, rough clinical conditions, overlapping nuclei, and nuclear class imbalance. The generic deep-learning methods usually rely on end-to-end models, which fail to address these problems associated explicitly with digital histology. In our previous work, DAN-NucNet, we resolved these issues for semantic segmentation with an end-to-end model. This work extends our previous model to simultaneous instance segmentation and classification. We introduce additional decoder heads with independent weighted losses, which produce semantic segmentation, edge proposals, and classification maps. We use the outputs from the three-head model to apply post-processing to produce the final segmentation and classification. Our multi-stage approach utilizes edge proposals and semantic segmentations compared to direct segmentation and classification strategies followed by most state-of-the-art methods. Due to this, we demonstrate a significant performance improvement in producing high-quality instance segmentation and nuclei classification. We have achieved a 0.841 Dice score for semantic segmentation, 0.713 bPQ scores for instance segmentation, and 0.633 mPQ for nuclei classification. Our proposed framework is generalized across 19 types of tissues. Furthermore, the framework is less complex compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
同时分割和分类肿瘤细胞在数字 histology 中扮演着重要的角色，但是它仍然是一个挑战。最高的二分和多分类 Panoptic Quality (PQ) 只有0.68 bPQ和0.49 mPQ，这是因为细胞染色的变化、组织内部的变化、较为恶劣的临床条件、重叠的细胞和核类别偏度。通用的深度学习方法通常采用端到端模型，这些模型无法直接地解决数字 histology 中相关的问题。在我们的前一个工作中，我们提出了 DAN-NucNet 模型，解决了这些问题。本文将 extend 我们的前一个模型，以实现同时的实例分割和分类。我们添加了多个解码头，每个解码头都有独立的权重损失，它们生成的结果包括semantic segmentation、edge proposal 和分类图像。我们使用这些三个头的输出来进行后处理，以生成最终的分割和分类结果。我们的多阶段方法利用了 edge proposal 和 semantic segmentation，而不是直接进行分割和分类的方法，这使得我们可以提高高质量的实例分割和核类分类。我们在19种组织中实现了0.841 Dice 分割率、0.713 bPQ 分割率和0.633 mPQ 分类率。我们提出的框架比现有的状态之一更加简单。
</details></li>
</ul>
<hr>
<h2 id="Improving-Misaligned-Multi-modality-Image-Fusion-with-One-stage-Progressive-Dense-Registration"><a href="#Improving-Misaligned-Multi-modality-Image-Fusion-with-One-stage-Progressive-Dense-Registration" class="headerlink" title="Improving Misaligned Multi-modality Image Fusion with One-stage Progressive Dense Registration"></a>Improving Misaligned Multi-modality Image Fusion with One-stage Progressive Dense Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11165">http://arxiv.org/abs/2308.11165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Wang, Jinyuan Liu, Long Ma, Risheng Liu, Xin Fan</li>
<li>for:  addressing the challenges of misalignments between multi-modality images in image fusion</li>
<li>methods: 一种Cross-modality Multi-scale Progressive Dense Registration (C-MPDR) scheme, which uses a one-stage optimization to improve the fusion performance of misaligned multi-modality images</li>
<li>results: 提高了多模态图像匹配的混合性能<details>
<summary>Abstract</summary>
Misalignments between multi-modality images pose challenges in image fusion, manifesting as structural distortions and edge ghosts. Existing efforts commonly resort to registering first and fusing later, typically employing two cascaded stages for registration,i.e., coarse registration and fine registration. Both stages directly estimate the respective target deformation fields. In this paper, we argue that the separated two-stage registration is not compact, and the direct estimation of the target deformation fields is not accurate enough. To address these challenges, we propose a Cross-modality Multi-scale Progressive Dense Registration (C-MPDR) scheme, which accomplishes the coarse-to-fine registration exclusively using a one-stage optimization, thus improving the fusion performance of misaligned multi-modality images. Specifically, two pivotal components are involved, a dense Deformation Field Fusion (DFF) module and a Progressive Feature Fine (PFF) module. The DFF aggregates the predicted multi-scale deformation sub-fields at the current scale, while the PFF progressively refines the remaining misaligned features. Both work together to accurately estimate the final deformation fields. In addition, we develop a Transformer-Conv-based Fusion (TCF) subnetwork that considers local and long-range feature dependencies, allowing us to capture more informative features from the registered infrared and visible images for the generation of high-quality fused images. Extensive experimental analysis demonstrates the superiority of the proposed method in the fusion of misaligned cross-modality images.
</details>
<details>
<summary>摘要</summary>
《多Modalität图像误差问题在图像融合中带来挑战，导致结构扭曲和边幻影。现有尝试通常采用分两个阶段进行 регистрирование，即粗略 регистрирование和精细 регистрирование，两个阶段直接估计目标扭曲场。在这篇论文中，我们认为分开的两个阶段 регистрирование不是 компакт的，而直接估计目标扭曲场也不够精确。为了解决这些挑战，我们提出了一种交叉模态多尺度进行密度注registratin（C-MPDR）方案，通过一个单一的优化过程，提高误差的多模态图像融合性能。具体来说，这种方案包括两个关键组件：一个密集的Deformation Field Fusion（DFF）模块和一个进行进行精细调整的Progressive Feature Fine（PFF）模块。DFF模块将在当前级别预测多尺度扭曲子场，而PFF模块将逐渐调整剩下的误差特征。两个模块共同帮助估计最终的扭曲场。此外，我们还开发了基于Transformer-Conv的融合（TCF）子网络，该子网络考虑了本地和远程特征依赖关系，使我们能够更好地捕捉融合后的高质量混合图像中的有用特征。广泛的实验分析表明，我们提出的方法在跨模态图像融合中具有显著的优势。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Decoupled-Contrastive-Multi-view-Clustering-with-High-order-Random-Walks"><a href="#Decoupled-Contrastive-Multi-view-Clustering-with-High-order-Random-Walks" class="headerlink" title="Decoupled Contrastive Multi-view Clustering with High-order Random Walks"></a>Decoupled Contrastive Multi-view Clustering with High-order Random Walks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11164">http://arxiv.org/abs/2308.11164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiding Lu, Yijie Lin, Mouxing Yang, Dezhong Peng, Peng Hu, Xi Peng</li>
<li>for: 提高多视图集群（MvC）的稳定性和抗衰落性，解决false negative和false positive问题。</li>
<li>methods: 提出了一种新的多视图集群方法（DIVIDE），通过随机游走进行全球性地标识数据对，从而可以正确地标识内部负样本和外部正样本。同时，DIVIDE采用了一种新的多视图集群架构，在不同的嵌入空间进行对比学习，以提高集群性能和抗衰落性。</li>
<li>results: 通过对四个标准测试集进行广泛的实验，证明了DIVIDE在完整的MvC设定下和缺失视图的MvC设定下都有较高的性能，并且在不同的缺失视图情况下保持稳定性。<details>
<summary>Abstract</summary>
In recent, some robust contrastive multi-view clustering (MvC) methods have been proposed, which construct data pairs from neighborhoods to alleviate the false negative issue, i.e., some intra-cluster samples are wrongly treated as negative pairs. Although promising performance has been achieved by these methods, the false negative issue is still far from addressed and the false positive issue emerges because all in- and out-of-neighborhood samples are simply treated as positive and negative, respectively. To address the issues, we propose a novel robust method, dubbed decoupled contrastive multi-view clustering with high-order random walks (DIVIDE). In brief, DIVIDE leverages random walks to progressively identify data pairs in a global instead of local manner. As a result, DIVIDE could identify in-neighborhood negatives and out-of-neighborhood positives. Moreover, DIVIDE embraces a novel MvC architecture to perform inter- and intra-view contrastive learning in different embedding spaces, thus boosting clustering performance and embracing the robustness against missing views. To verify the efficacy of DIVIDE, we carry out extensive experiments on four benchmark datasets comparing with nine state-of-the-art MvC methods in both complete and incomplete MvC settings.
</details>
<details>
<summary>摘要</summary>
近些年，一些强大的多视图决定 clustering（MvC）方法被提出，这些方法从邻居中构建数据对以解决内部样本被错误地视为负对的问题。 although these methods have achieved promising performance, the false negative issue is still not fully addressed, and a new issue has emerged, i.e., false positives, because all in- and out-of-neighborhood samples are simply treated as positive and negative, respectively. To address these issues, we propose a novel robust method, called decoupled contrastive multi-view clustering with high-order random walks (DIVIDE).DIVIDE 方法利用Random Walk来逐渐标识全球的数据对，而不是局部的方法。 As a result, DIVIDE could identify in-neighborhood negatives and out-of-neighborhood positives. 更over, DIVIDE 方法采用一种新的MvC架构，以进行不同的嵌入空间中的对比学习，从而提高划分性和对缺失视图的抗性。 To verify the effectiveness of DIVIDE, we conduct extensive experiments on four benchmark datasets, comparing with nine state-of-the-art MvC methods in both complete and incomplete MvC settings.
</details></li>
</ul>
<hr>
<h2 id="A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks"><a href="#A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks" class="headerlink" title="A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks"></a>A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11162">http://arxiv.org/abs/2308.11162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abubakr Shafique, Ricardo Gonzalez, Liron Pantanowitz, Puay Hoon Tan, Alberto Machado, Ian A Cree, Hamid R. Tizhoosh</li>
<li>for: 这项研究旨在开发一个基于深度学习的搜索able数字Atlas，用于帮助病理学家对悉数据库中的罕见癌症进行查找和匹配。</li>
<li>methods: 该研究使用了一个国际知名的TCGA数据库，并使用了一个国际顶尖的深度学习模型，对 millions of diagnostic histopathology images进行了预训练。然后，对WHO乳腺分类系统（第5版）中的35种肿瘤类型进行了索引和分析，并使用了深度特征来Visualize所有肿瘤类型。</li>
<li>results: 该研究发现，使用深度学习模型对WHO乳腺分类系统数据进行索引和分析，可以达到88%的准确率，并且使用top-n肿瘤类型进行验证可以达到91%的准确率。这些结果表明，使用索引数字Archive可以investigate complex relationships among common and rare breast lesions。<details>
<summary>Abstract</summary>
Breast cancer is one of the most common cancers affecting women worldwide. They include a group of malignant neoplasms with a variety of biological, clinical, and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attention for the computerized representation of medical images. Searchable digital atlases can provide pathologists with patch matching tools allowing them to search among evidently diagnosed and treated archival cases, a technology that may be regarded as computational second opinion. In this study, we indexed and analyzed the WHO breast taxonomy (Classification of Tumours 5th Ed.) spanning 35 tumour types. We visualized all tumour types using deep features extracted from a state-of-the-art deep learning model, pre-trained on millions of diagnostic histopathology images from the TCGA repository. Furthermore, we test the concept of a digital "atlas" as a reference for search and matching with rare test cases. The patch similarity search within the WHO breast taxonomy data reached over 88% accuracy when validating through "majority vote" and more than 91% accuracy when validating using top-n tumour types. These results show for the first time that complex relationships among common and rare breast lesions can be investigated using an indexed digital archive.
</details>
<details>
<summary>摘要</summary>
乳癌是全球女性最常见的恶性肿瘤之一，其包括多种生物学、临床和 histopathological 特征的肿瘤。有超过35种不同的乳腺病变可以根据细胞形态、生长和建筑模式进行分类和诊断。近些年来，人工智能技术中的深度学习在医疗领域得到了广泛的关注，特别是在计算机化的医疗图像 Representation 方面。搜索able digital atlas 可以为病理学家提供一个搜索和匹配已诊断和治疗的档案库，这种技术可以视为计算机化的第二次诊断。本研究对 WHO 乳腺分类（第5版）进行了索引和分析，包括35种肿瘤类型。我们使用了一个国际上最新的深度学习模型，该模型在TCGA 数据库上进行了 millions 个诊断 Histopathology 图像的预处理，然后对所有肿瘤类型进行了深度特征提取和可视化。此外，我们还测试了一个数字"atlas"作为参考，用于搜索和匹配罕见案例。在 WHO 乳腺分类数据中进行了质心精度搜索，结果表明，使用 "多数投票" 验证的精度高达88%，使用 top-n 肿瘤类型验证的精度高达91%。这些结果表明，使用索引数字档案库，可以 investigate Complex relationships among common and rare breast lesions.
</details></li>
</ul>
<hr>
<h2 id="SwinV2DNet-Pyramid-and-Self-Supervision-Compounded-Feature-Learning-for-Remote-Sensing-Images-Change-Detection"><a href="#SwinV2DNet-Pyramid-and-Self-Supervision-Compounded-Feature-Learning-for-Remote-Sensing-Images-Change-Detection" class="headerlink" title="SwinV2DNet: Pyramid and Self-Supervision Compounded Feature Learning for Remote Sensing Images Change Detection"></a>SwinV2DNet: Pyramid and Self-Supervision Compounded Feature Learning for Remote Sensing Images Change Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11159">http://arxiv.org/abs/2308.11159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dalong Zheng, Zebin Wu, Jia Liu, Zhihui Wei</li>
<li>for: 本研究旨在提出一种综合厚度网络（SwinV2DNet），以综合利用 transformer 和 CNN 的优点，解决现有网络在特征学习中的缺陷。</li>
<li>methods: 该网络包括 Swin V2 和 VGG16 两部分，通过 densely connected 的 Swin V2 脊梁和 CNN 分支，捕捉到 cambio 关系特征，并通过 mixed feature pyramid (MFP) 提供了多层次和协调的特征学习。</li>
<li>results: 对四个常用的公共遥感数据集进行比较，该网络可以达到state-of-the-art 的变化检测分数和细化变化地图，并且通过自我监督策略提高了 CNN 分支的训练问题。<details>
<summary>Abstract</summary>
Among the current mainstream change detection networks, transformer is deficient in the ability to capture accurate low-level details, while convolutional neural network (CNN) is wanting in the capacity to understand global information and establish remote spatial relationships. Meanwhile, both of the widely used early fusion and late fusion frameworks are not able to well learn complete change features. Therefore, based on swin transformer V2 (Swin V2) and VGG16, we propose an end-to-end compounded dense network SwinV2DNet to inherit the advantages of both transformer and CNN and overcome the shortcomings of existing networks in feature learning. Firstly, it captures the change relationship features through the densely connected Swin V2 backbone, and provides the low-level pre-changed and post-changed features through a CNN branch. Based on these three change features, we accomplish accurate change detection results. Secondly, combined with transformer and CNN, we propose mixed feature pyramid (MFP) which provides inter-layer interaction information and intra-layer multi-scale information for complete feature learning. MFP is a plug and play module which is experimentally proven to be also effective in other change detection networks. Further more, we impose a self-supervision strategy to guide a new CNN branch, which solves the untrainable problem of the CNN branch and provides the semantic change information for the features of encoder. The state-of-the-art (SOTA) change detection scores and fine-grained change maps were obtained compared with other advanced methods on four commonly used public remote sensing datasets. The code is available at https://github.com/DalongZ/SwinV2DNet.
</details>
<details>
<summary>摘要</summary>
当前主流的变化检测网络中，变换器缺乏捕捉准确的低级细节的能力，而卷积神经网络（CNN）缺乏建立远程空间关系和全局信息的能力。同时，现有的早期融合和晚期融合框架都不能良好地学习完整的变化特征。因此，基于Swin transformer V2（Swin V2）和VGG16，我们提出了一种端到端融合密集网络SwinV2DNet，继承了变换器和CNN的优点，并超越了现有网络在特征学习方面的缺陷。首先，SwinV2DNet通过密集连接的Swin V2脊梁捕捉变化关系特征，并提供低级预变和后变特征通过一个CNN分支。基于这三个变化特征，我们实现了准确的变化检测结果。其次，我们提出了混合特征阶梯（MFP），该模块通过卷积神经网络和变换器的结合，为完整的特征学习提供了间层交互信息和多尺度内层信息。MFP是一个可插入的模块，实验证明其效果也可以应用于其他变化检测网络。此外，我们对新的CNN分支进行自我超vision策略，解决了CNN分支的训练不可能问题，并为encoder的特征提供了semantic变化信息。与其他先进方法相比，我们在四个常用的公共遥感数据集上获得了状态前的变化检测分数和细化变化地图。代码可以在https://github.com/DalongZ/SwinV2DNet上获取。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalization-via-Rationale-Invariance"><a href="#Domain-Generalization-via-Rationale-Invariance" class="headerlink" title="Domain Generalization via Rationale Invariance"></a>Domain Generalization via Rationale Invariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11158">http://arxiv.org/abs/2308.11158</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liangchen527/ridg">https://github.com/liangchen527/ridg</a></li>
<li>paper_authors: Liang Chen, Yong Zhang, Yibing Song, Anton van den Hengel, Lingqiao Liu</li>
<li>for: 提高领域总结的稳定性，以便在未见 environments 中维持良好的结果。</li>
<li>methods: 通过对决策过程的最后一层抽象来解决领域总结挑战。具体来说，我们提议将每个样本的元素级别贡献视为决策的理由，并将每个样本的理由表示为一个矩阵。为了确保模型具有良好的普适性，我们建议每个类别的理由矩阵具有相似性，表明模型在各个环境中依靠域外特征来做出决策。</li>
<li>results: 我们的实验表明，通过引入 rational invariance loss 来实现这一思路，可以在不同的领域上实现竞争性的结果，即使使用的是简单的代码。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/liangchen527/RIDG%7D">https://github.com/liangchen527/RIDG}</a> 上找到。<details>
<summary>Abstract</summary>
This paper offers a new perspective to ease the challenge of domain generalization, which involves maintaining robust results even in unseen environments. Our design focuses on the decision-making process in the final classifier layer. Specifically, we propose treating the element-wise contributions to the final results as the rationale for making a decision and representing the rationale for each sample as a matrix. For a well-generalized model, we suggest the rationale matrices for samples belonging to the same category should be similar, indicating the model relies on domain-invariant clues to make decisions, thereby ensuring robust results. To implement this idea, we introduce a rationale invariance loss as a simple regularization technique, requiring only a few lines of code. Our experiments demonstrate that the proposed approach achieves competitive results across various datasets, despite its simplicity. Code is available at \url{https://github.com/liangchen527/RIDG}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TOPIC-A-Parallel-Association-Paradigm-for-Multi-Object-Tracking-under-Complex-Motions-and-Diverse-Scenes"><a href="#TOPIC-A-Parallel-Association-Paradigm-for-Multi-Object-Tracking-under-Complex-Motions-and-Diverse-Scenes" class="headerlink" title="TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes"></a>TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11157">http://arxiv.org/abs/2308.11157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/holmescao/TOPICTrack">https://github.com/holmescao/TOPICTrack</a></li>
<li>paper_authors: Xiaoyan Cao, Yiyao Zheng, Yao Yao, Huapeng Qin, Xiaoyu Cao, Shihui Guo</li>
<li>for: 这 paper 的目的是提出一种新的多对目标跟踪（MOT）数据集，以解决现有数据集忽略了复杂的运动模式的问题。</li>
<li>methods: 该 paper 使用了一种新的并行相关模式（Parallel Paradigm），并提出了一种基于运动和外观特征的两个圆形相关机制（TOPIC），以及一种基于注意力的外观重建模块（AARM）来提高跟踪效果。</li>
<li>results: 该 paper 的方法在四个公共数据集和新 introduce 的 BEE23 数据集上实现了领先的表现，包括减少 false negatives 12% 到 51% compared to 单一特征相关模式。<details>
<summary>Abstract</summary>
Video data and algorithms have been driving advances in multi-object tracking (MOT). While existing MOT datasets focus on occlusion and appearance similarity, complex motion patterns are widespread yet overlooked. To address this issue, we introduce a new dataset called BEE23 to highlight complex motions. Identity association algorithms have long been the focus of MOT research. Existing trackers can be categorized into two association paradigms: single-feature paradigm (based on either motion or appearance feature) and serial paradigm (one feature serves as secondary while the other is primary). However, these paradigms are incapable of fully utilizing different features. In this paper, we propose a parallel paradigm and present the Two rOund Parallel matchIng meChanism (TOPIC) to implement it. The TOPIC leverages both motion and appearance features and can adaptively select the preferable one as the assignment metric based on motion level. Moreover, we provide an Attention-based Appearance Reconstruct Module (AARM) to reconstruct appearance feature embeddings, thus enhancing the representation of appearance features. Comprehensive experiments show that our approach achieves state-of-the-art performance on four public datasets and BEE23. Notably, our proposed parallel paradigm surpasses the performance of existing association paradigms by a large margin, e.g., reducing false negatives by 12% to 51% compared to the single-feature association paradigm. The introduced dataset and association paradigm in this work offers a fresh perspective for advancing the MOT field. The source code and dataset are available at https://github.com/holmescao/TOPICTrack.
</details>
<details>
<summary>摘要</summary>
视频数据和算法在多对目标跟踪（MOT）领域取得了重大进步。现有的MOT数据集集中焦点在 occlusion 和外观相似性上，然而复杂的运动模式却被忽略。为了解决这个问题，我们提出了一个新的数据集called BEE23，以强调复杂的运动。目标跟踪算法的研究总是围绕着 Identity association 问题进行，现有的跟踪器可以分为两种联系思维：单一特征思维（基于 either motion 或 appearance feature）以及串行思维（一个特征服务为次要，另一个特征服务为主要）。然而，这些思维方法无法完全利用不同的特征。在这篇论文中，我们提议了并行联系思维，并通过 Two rOund Parallel matchIng meChanism（TOPIC）来实现。TOPIC 利用了运动和外观特征，并可以根据运动水平选择适合的一个作为分配度量。此外，我们还提供了 Attention-based Appearance Reconstruct Module（AARM）来重建外观特征嵌入，从而提高外观特征的表示。我们对四个公共数据集和 BEE23 进行了广泛的实验，结果显示我们的方法在这些数据集上达到了当前最佳性能。尤其是，我们提出的并行联系思维在现有的联系思维方法之上减少了12%至51%的假阳性。在这篇论文中，我们还提供了一个新的数据集和联系思维方法，这将为 MOT 领域带来新的视角，并且代码和数据集可以在 <https://github.com/holmescao/TOPICTrack> 上获取。
</details></li>
</ul>
<hr>
<h2 id="High-Dynamic-Range-Imaging-of-Dynamic-Scenes-with-Saturation-Compensation-but-without-Explicit-Motion-Compensation"><a href="#High-Dynamic-Range-Imaging-of-Dynamic-Scenes-with-Saturation-Compensation-but-without-Explicit-Motion-Compensation" class="headerlink" title="High Dynamic Range Imaging of Dynamic Scenes with Saturation Compensation but without Explicit Motion Compensation"></a>High Dynamic Range Imaging of Dynamic Scenes with Saturation Compensation but without Explicit Motion Compensation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11140">http://arxiv.org/abs/2308.11140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haesoochung/hdri-saturation-compensation">https://github.com/haesoochung/hdri-saturation-compensation</a></li>
<li>paper_authors: Haesoo Chung, Nam Ik Cho</li>
<li>for: 提高高动态范围（HDR）图像的获得和修复，解决由相机传感器的限制导致的信息损失问题。</li>
<li>methods: 使用改进的运动补偿和灰度调整问题的解决方案，通过 Contextual attention 技术来修复过度曝光区域。</li>
<li>results: 比对 state-of-the-art 方法，示出了更高的质量和量化评价结果。<details>
<summary>Abstract</summary>
High dynamic range (HDR) imaging is a highly challenging task since a large amount of information is lost due to the limitations of camera sensors. For HDR imaging, some methods capture multiple low dynamic range (LDR) images with altering exposures to aggregate more information. However, these approaches introduce ghosting artifacts when significant inter-frame motions are present. Moreover, although multi-exposure images are given, we have little information in severely over-exposed areas. Most existing methods focus on motion compensation, i.e., alignment of multiple LDR shots to reduce the ghosting artifacts, but they still produce unsatisfying results. These methods also rather overlook the need to restore the saturated areas. In this paper, we generate well-aligned multi-exposure features by reformulating a motion alignment problem into a simple brightness adjustment problem. In addition, we propose a coarse-to-fine merging strategy with explicit saturation compensation. The saturated areas are reconstructed with similar well-exposed content using adaptive contextual attention. We demonstrate that our method outperforms the state-of-the-art methods regarding qualitative and quantitative evaluations.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）摄影是一项非常具有挑战性的任务，因为摄像头传感器的限制会导致大量信息的丢失。为实现HDR摄影，一些方法会 capture多个低动态范围（LDR）图像，并将它们进行不同的曝光设定来聚集更多的信息。然而，这些方法会导致在 significative 的运动误差存在时出现幻影artefacts。此外，虽然我们有多个曝光图像，但我们在严重过曝光区域中具有少量信息。大多数现有方法将焦点放在运动补做上，即将多个LDR拍摄Alignment 来减少幻影artefacts，但这些方法仍然生成不满足的结果。这些方法还往往忽略了重建过曝光区域的需求。在这篇论文中，我们将生成准确尺度的多个曝光特征，通过将运动Alignment 转换为简单的明亮调整问题来实现。此外，我们还提出了一种粗略到细节的合并策略，并且使用明确的过曝光补做。在过曝光区域中，我们使用适应的上下文关注来重建相似的准确曝光内容。我们示示了我们的方法在质量和量度上的超越现有方法。
</details></li>
</ul>
<hr>
<h2 id="Efficient-View-Synthesis-with-Neural-Radiance-Distribution-Field"><a href="#Efficient-View-Synthesis-with-Neural-Radiance-Distribution-Field" class="headerlink" title="Efficient View Synthesis with Neural Radiance Distribution Field"></a>Efficient View Synthesis with Neural Radiance Distribution Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11130">http://arxiv.org/abs/2308.11130</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushuang-wu/NeRDF">https://github.com/yushuang-wu/NeRDF</a></li>
<li>paper_authors: Yushuang Wu, Xiao Li, Jinglu Wang, Xiaoguang Han, Shuguang Cui, Yan Lu</li>
<li>For: 高品质视角合成* Methods: 使用小型网络模型，采用频率基准来模型光度分布，采样一次网络前进来计算像素值* Results: 提供了一个更好的权衡 между速度、质量和网络大小，与传统方法相比，具有约254倍的速度提升，同时保持了类似的网络大小和质量水平。<details>
<summary>Abstract</summary>
Recent work on Neural Radiance Fields (NeRF) has demonstrated significant advances in high-quality view synthesis. A major limitation of NeRF is its low rendering efficiency due to the need for multiple network forwardings to render a single pixel. Existing methods to improve NeRF either reduce the number of required samples or optimize the implementation to accelerate the network forwarding. Despite these efforts, the problem of multiple sampling persists due to the intrinsic representation of radiance fields. In contrast, Neural Light Fields (NeLF) reduce the computation cost of NeRF by querying only one single network forwarding per pixel. To achieve a close visual quality to NeRF, existing NeLF methods require significantly larger network capacities which limits their rendering efficiency in practice. In this work, we propose a new representation called Neural Radiance Distribution Field (NeRDF) that targets efficient view synthesis in real-time. Specifically, we use a small network similar to NeRF while preserving the rendering speed with a single network forwarding per pixel as in NeLF. The key is to model the radiance distribution along each ray with frequency basis and predict frequency weights using the network. Pixel values are then computed via volume rendering on radiance distributions. Experiments show that our proposed method offers a better trade-off among speed, quality, and network size than existing methods: we achieve a ~254x speed-up over NeRF with similar network size, with only a marginal performance decline. Our project page is at yushuang-wu.github.io/NeRDF.
</details>
<details>
<summary>摘要</summary>
最近的神经辐射场（NeRF）研究取得了高品质视图合成的重要进步。然而，NeRF具有辐射场的内置表示，导致每个像素需要多个网络请求，从而降低了渲染效率。现有的方法可以减少需要的样本数或者优化网络实现以加速网络请求。然而，这些努力仍然无法消除多样本的问题。相比之下，神经光场（NeLF）可以通过每个像素只需要一次网络请求来减少计算成本。然而，现有的NeLF方法需要较大的网络容量，从而限制了实际的渲染效率。在这种情况下，我们提出了一种新的表示方式 called Neural Radiance Distribution Field（NeRDF），旨在实现高效的视图合成。具体来说，我们使用一个小型神经网络，类似于NeRF，同时保持与NeLF一样的渲染速度。关键在于，我们使用频率基is来模型每个辐射线上的光辐射分布，并使用网络来预测频率权重。然后，通过量 rendering 技术来计算像素值。实验表明，我们的提议方法可以在Speed、质量和网络大小之间取得更好的平衡，相比之下NeRF和NeLF的方法。我们的项目页面是 yushuang-wu.github.io/NeRDF。
</details></li>
</ul>
<hr>
<h2 id="Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs"><a href="#Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs" class="headerlink" title="Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs"></a>Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11123">http://arxiv.org/abs/2308.11123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 保护内容在线分享</li>
<li>methods: 使用隐形水印技术训练生成模型，并测试其能够在生成图像中检测水印。</li>
<li>results: 通过统计测试，确定了模型是否训练使用水印数据，以及水印数据中的特征与生成图像之间的相关性。<details>
<summary>Abstract</summary>
Generative models have seen an explosion in popularity with the release of huge generative Diffusion models like Midjourney and Stable Diffusion to the public. Because of this new ease of access, questions surrounding the automated collection of data and issues regarding content ownership have started to build. In this paper we present new work which aims to provide ways of protecting content when shared to the public. We show that a generative Diffusion model trained on data that has been imperceptibly watermarked will generate new images with these watermarks present. We further show that if a given watermark is correlated with a certain feature of the training data, the generated images will also have this correlation. Using statistical tests we show that we are able to determine whether a model has been trained on marked data, and what data was marked. As a result our system offers a solution to protect intellectual property when sharing content online.
</details>
<details>
<summary>摘要</summary>
traducciona el texto a chino simplificado.<</SYS>>广泛的生成模型在大量生成扩散模型如中途和稳定扩散的公共释放后得到了普及。由于这新的访问方便，自动收集数据和内容所有权问题开始升温。在这篇论文中，我们介绍新的工作，旨在在公共分享时保护内容。我们显示，通过训练在不可见水印数据上的生成扩散模型，新生成的图像都会包含这些水印。此外，如果给定的水印与训练数据中某个特征相关，那么生成的图像也会具有这种相关性。通过统计测试，我们表明可以判断模型是否训练在标记数据上，以及具体的标记数据。因此，我们的系统可以解决在线分享内容时保护知识产权。
</details></li>
</ul>
<hr>
<h2 id="Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection"><a href="#Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection" class="headerlink" title="Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection"></a>Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11119">http://arxiv.org/abs/2308.11119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Tamura</li>
<li>for: 这个研究是为了开发一个 zero-shot anomaly detection 方法，利用 CLIP 的视觉语言模型来提供数据源。</li>
<li>methods: 这个方法使用 CLIP 的 prompt-guided classification 技术，将每个图像分成多个部分，并将每个部分作为 input 进行类别。此外，还使用了一些随机生成的词语，以增加训练数据的多样性。</li>
<li>results: 实验结果显示，这个方法可以在 zero-shot 设定下 achieves state-of-the-art 性能，不需要耗费很多时间进行训练。<details>
<summary>Abstract</summary>
This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLIP with typical prompts that include words of normal and anomaly. In addition to these words, we insert several randomly generated words into prompts, which enables the encoder to generate a diverse set of normal and anomalous samples. Using the generated embeddings as training data, a feed-forward neural network learns to extract features of normal and anomaly from CLIP's embeddings, and as a result, a category-agnostic anomaly detector can be obtained without any training images. Experimental results demonstrate that our method achieves state-of-the-art performance without laborious prompt ensembling in zero-shot setups.
</details>
<details>
<summary>摘要</summary>
To overcome these issues, the proposed method leverages CLIP as a data source for training. The method generates text embeddings with the text encoder in CLIP using typical prompts that include words related to normal and anomalous samples. Additionally, several randomly generated words are inserted into the prompts to enable the encoder to generate a diverse set of normal and anomalous samples. These embeddings are then used as training data for a feed-forward neural network to extract features of normal and anomalous samples from CLIP's embeddings. As a result, a category-agnostic anomaly detector can be obtained without any training images.Experimental results demonstrate that the proposed method achieves state-of-the-art performance in zero-shot setups without the need for laborious prompt ensembling.
</details></li>
</ul>
<hr>
<h2 id="LAN-HDR-Luminance-based-Alignment-Network-for-High-Dynamic-Range-Video-Reconstruction"><a href="#LAN-HDR-Luminance-based-Alignment-Network-for-High-Dynamic-Range-Video-Reconstruction" class="headerlink" title="LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction"></a>LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11116">http://arxiv.org/abs/2308.11116</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haesoochung/lan-hdr">https://github.com/haesoochung/lan-hdr</a></li>
<li>paper_authors: Haesoo Chung, Nam Ik Cho</li>
<li>for: 提高高清晰度和动态范围（HDR）影像技术，以满足用户对高质量视频的需求。</li>
<li>methods: 基于特征空间的灵活抽象网络（LAN-HDR），包括对适应模块和梦想模块。对模块使用灵活抽象来减少流量估计错误。</li>
<li>results: 比较现有方法表现更好或相当，在多个标准测试数据集上进行了广泛的实验。<details>
<summary>Abstract</summary>
As demands for high-quality videos continue to rise, high-resolution and high-dynamic range (HDR) imaging techniques are drawing attention. To generate an HDR video from low dynamic range (LDR) images, one of the critical steps is the motion compensation between LDR frames, for which most existing works employed the optical flow algorithm. However, these methods suffer from flow estimation errors when saturation or complicated motions exist. In this paper, we propose an end-to-end HDR video composition framework, which aligns LDR frames in the feature space and then merges aligned features into an HDR frame, without relying on pixel-domain optical flow. Specifically, we propose a luminance-based alignment network for HDR (LAN-HDR) consisting of an alignment module and a hallucination module. The alignment module aligns a frame to the adjacent reference by evaluating luminance-based attention, excluding color information. The hallucination module generates sharp details, especially for washed-out areas due to saturation. The aligned and hallucinated features are then blended adaptively to complement each other. Finally, we merge the features to generate a final HDR frame. In training, we adopt a temporal loss, in addition to frame reconstruction losses, to enhance temporal consistency and thus reduce flickering. Extensive experiments demonstrate that our method performs better or comparable to state-of-the-art methods on several benchmarks.
</details>
<details>
<summary>摘要</summary>
As demands for high-quality videos continue to rise, high-resolution and high-dynamic range (HDR) imaging techniques are drawing attention. To generate an HDR video from low dynamic range (LDR) images, one of the critical steps is the motion compensation between LDR frames, for which most existing works employed the optical flow algorithm. However, these methods suffer from flow estimation errors when saturation or complicated motions exist. In this paper, we propose an end-to-end HDR video composition framework, which aligns LDR frames in the feature space and then merges aligned features into an HDR frame, without relying on pixel-domain optical flow. Specifically, we propose a luminance-based alignment network for HDR (LAN-HDR) consisting of an alignment module and a hallucination module. The alignment module aligns a frame to the adjacent reference by evaluating luminance-based attention, excluding color information. The hallucination module generates sharp details, especially for washed-out areas due to saturation. The aligned and hallucinated features are then blended adaptively to complement each other. Finally, we merge the features to generate a final HDR frame. In training, we adopt a temporal loss, in addition to frame reconstruction losses, to enhance temporal consistency and thus reduce flickering. Extensive experiments demonstrate that our method performs better or comparable to state-of-the-art methods on several benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models"><a href="#Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models" class="headerlink" title="Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models"></a>Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11112">http://arxiv.org/abs/2308.11112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hajimesuzuki999/qpf">https://github.com/hajimesuzuki999/qpf</a></li>
<li>paper_authors: Farina Riaz, Shahab Abdulla, Hajime Suzuki, Srinjoy Ganguly, Ravinesh C. Deo, Susan Hopkins</li>
<li>for: 提高图像分类准确率</li>
<li>methods: 使用量子预处理筛选器（QPF），应用于图像分类神经网络模型中</li>
<li>results: 在MNIST和EMNIST数据集上，图像分类准确率提高至95.4%和75.9%，分别提高了2.9%和7.1%，无需添加额外参数或优化机器学习过程。<details>
<summary>Abstract</summary>
This paper proposes a novel quantum pre-processing filter (QPF) to improve the image classification accuracy of neural network (NN) models. A simple four qubit quantum circuit that uses Y rotation gates for encoding and two controlled NOT gates for creating correlation among the qubits is applied as a feature extraction filter prior to passing data into the fully connected NN architecture. By applying the QPF approach, the results show that the image classification accuracy based on the MNIST (handwritten 10 digits) and the EMNIST (handwritten 47 class digits and letters) datasets can be improved, from 92.5% to 95.4% and from 68.9% to 75.9%, respectively. These improvements were obtained without introducing extra model parameters or optimizations in the machine learning process. However, tests performed on the developed QPF approach against a relatively complex GTSRB dataset with 43 distinct class real-life traffic sign images showed a degradation in the classification accuracy. Considering this result, further research into the understanding and the design of a more suitable quantum circuit approach for image classification neural networks could be explored utilizing the baseline method proposed in this paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Classification-of-the-lunar-surface-pattern-by-AI-architectures-Does-AI-see-a-rabbit-in-the-Moon"><a href="#Classification-of-the-lunar-surface-pattern-by-AI-architectures-Does-AI-see-a-rabbit-in-the-Moon" class="headerlink" title="Classification of the lunar surface pattern by AI architectures: Does AI see a rabbit in the Moon?"></a>Classification of the lunar surface pattern by AI architectures: Does AI see a rabbit in the Moon?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11107">http://arxiv.org/abs/2308.11107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daigo Shoji</li>
<li>for: 这篇论文的目的是研究月面的颜色模式是否类似于兔子。</li>
<li>methods: 这篇论文使用了七种人工智能架构来评估月面颜色模式与兔子之间的相似性。</li>
<li>results: 测试结果显示，在某些地区，月面颜色模式更容易被识别为兔子，而不是人脸。此外，使用ImageNet权重时，ConvNeXt和CLIP occasionally可以归类月面颜色模式为兔子。<details>
<summary>Abstract</summary>
In Asian countries, there is a tradition that a rabbit (the Moon rabbit) lives on the Moon. As the origin of this tradition, usually, two reasons are mentioned. One reason is that the color pattern of the lunar surface is similar to the shape of a rabbit. The other reason is that both the Moon and rabbit are symbols of fertility because the Moon appears and disappears (i.e., waxing and waning) cyclically, and rabbits bear children frequently. Considering the latter reason, is the lunar surface color pattern not similar to a rabbit? Here, the similarity between rabbit and the lunar surface pattern was evaluated using seven AI architectures. In the test by CLIP, assuming that people look at the Moon in the early evening frequently, the lunar surface is more similar to a rabbit than a face at low latitude regions, while it can be classified as face as latitude increases, which is consistent with that the oldest literature about the Moon rabbit was written in India and that there is a culture of human's face in the Moon in Europe. Tested with ImageNet weights, ConvNeXt and CLIP sometimes classified the lunar surface pattern into rabbit with relatively high probabilities. Cultures are generated by our attitude to the environment. Both dynamic and static similarities may be required to induce our imagination.
</details>
<details>
<summary>摘要</summary>
在亚洲国家，有一传统认为月球上有兔子（月兔）生活。这个传统的起源通常被推断为两个理由。一个理由是月球表面的颜色排列与兔子的形状类似。另一个理由是月球和兔子都是生育的符号，因为月球出现和消失（即增减）的征例行为，兔子则经常产下幼崽。考虑后一个理由，月球表面的颜色排列与兔子是否类似？在这个问题上，我们使用了七种人工智能架构进行评估。在CLIP测试中，假设人们在晚上经常看到月球，那么月球表面的颜色排列更像兔子 than 人脸，而且随着纬度增加，月球表面可以被识别为人脸。这与最古老的月兔文学成果在印度被写成，以及欧洲文化中人类面部在月球上的存在相一致。使用ImageNet权重，ConvNeXt和CLIP occasionally将月球表面 Pattern classification为兔子，并且拥有相对高的概率。文化是由我们对环境的态度所生成的。我们可能需要同时考虑动态和静态相似性，以便让我们的想象力激发。
</details></li>
</ul>
<hr>
<h2 id="Recursive-Video-Lane-Detection"><a href="#Recursive-Video-Lane-Detection" class="headerlink" title="Recursive Video Lane Detection"></a>Recursive Video Lane Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11106">http://arxiv.org/abs/2308.11106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dongkwonjin/rvld">https://github.com/dongkwonjin/rvld</a></li>
<li>paper_authors: Dongkwon Jin, Dahyun Kim, Chang-Su Kim</li>
<li>for: 这篇论文提出了一种用于视频中检测路面线的新算法，即回归视频lane检测器（RVLD），用于在视频中检测路面线。</li>
<li>methods: 该算法包括一个内部lane检测器（ILD）和一个预测lane检测器（PLD）。首先，我们设计了ILD来在当前帧中地址路面线。然后，我们开发了PLD，以利用上一帧的信息来在当前帧中更可靠地检测路面线。为此，我们估算了运动场和将上一帧的输出折叠到当前帧中。使用折叠后的信息，我们精细地修改当前帧的特征图以更好地检测路面线。</li>
<li>results: 实验结果表明，RVLD在视频路面线数据集上的性能明显超过了现有的检测器。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/dongkwonjin/RVLD%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/dongkwonjin/RVLD中下载。</a><details>
<summary>Abstract</summary>
A novel algorithm to detect road lanes in videos, called recursive video lane detector (RVLD), is proposed in this paper, which propagates the state of a current frame recursively to the next frame. RVLD consists of an intra-frame lane detector (ILD) and a predictive lane detector (PLD). First, we design ILD to localize lanes in a still frame. Second, we develop PLD to exploit the information of the previous frame for lane detection in a current frame. To this end, we estimate a motion field and warp the previous output to the current frame. Using the warped information, we refine the feature map of the current frame to detect lanes more reliably. Experimental results show that RVLD outperforms existing detectors on video lane datasets. Our codes are available at https://github.com/dongkwonjin/RVLD.
</details>
<details>
<summary>摘要</summary>
“本文提出了一种新的算法检测视频中的路线，即回归视频车道检测器（RVLD）。这种算法在当前帧中进行回归状态，并在下一帧中使用这些状态来提高车道检测的准确性。RVLD由内帧车道检测器（ILD）和预测车道检测器（PLD）两部分组成。首先，我们设计了 ILD 以确定视频帧中的车道。其次，我们开发了 PLD，以利用上一帧的信息来提高当前帧中的车道检测。为此，我们对上一帧的视频进行了运动场景的估算，并将上一帧的输出折叠到当前帧中。使用折叠后的信息，我们可以更加精确地修改当前帧的特征图，以更好地检测车道。实验结果表明，RVLD 在视频车道数据集上的性能比既有的检测器更高。我们的代码可以在 GitHub 上找到：https://github.com/dongkwonjin/RVLD。”
</details></li>
</ul>
<hr>
<h2 id="MosaiQ-Quantum-Generative-Adversarial-Networks-for-Image-Generation-on-NISQ-Computers"><a href="#MosaiQ-Quantum-Generative-Adversarial-Networks-for-Image-Generation-on-NISQ-Computers" class="headerlink" title="MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers"></a>MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11096">http://arxiv.org/abs/2308.11096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Silver, Tirthak Patel, William Cutler, Aditya Ranjan, Harshitta Gandhi, Devesh Tiwari</li>
<li>for: 研究量子机器学习和视觉技术，尤其是量子图像生成技术，以提高图像质量和可靠性。</li>
<li>methods: 我们提出了一个名为MosaiQ的高质量量子图像生成GAN框架，可以在当今的中期级量子计算机（NISQ）上执行。</li>
<li>results: MosaiQ可以生成高质量的图像，并且可以在不同的图像生成任务中实现高度的可靠性和稳定性。<details>
<summary>Abstract</summary>
Quantum machine learning and vision have come to the fore recently, with hardware advances enabling rapid advancement in the capabilities of quantum machines. Recently, quantum image generation has been explored with many potential advantages over non-quantum techniques; however, previous techniques have suffered from poor quality and robustness. To address these problems, we introduce, MosaiQ, a high-quality quantum image generation GAN framework that can be executed on today's Near-term Intermediate Scale Quantum (NISQ) computers.
</details>
<details>
<summary>摘要</summary>
量子机器学习和视觉在最近几年来得到了更多的关注，各种硬件进步使得量子机器的能力得到了快速提升。近期，量子图像生成得到了广泛研究，但以前的技术受到了低质量和稳定性的限制。为了解决这些问题，我们介绍了 MosaiQ，一个高质量量子图像生成GAN框架，可以在当今的中等规模量子计算机上执行。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport"><a href="#Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport" class="headerlink" title="Addressing Fairness and Explainability in Image Classification Using Optimal Transport"></a>Addressing Fairness and Explainability in Image Classification Using Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11090">http://arxiv.org/abs/2308.11090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ratz, François Hu, Arthur Charpentier</li>
<li>for: 本研究旨在提高人工智能系统的可信worthiness和公平性，使其在医疗和警察等领域中建立信任和责任感。</li>
<li>methods: 本研究使用优化的运输理论来揭示图像中偏见的起源和后果，这种方法可以轻松扩展到表格数据中。</li>
<li>results: 研究发现，通过使用拟合度量来评估模型的偏见，可以独立地保持预测准确性和揭示偏见的起源。这些发现对于建立可信worthiness和公平性的人工智能系统具有重要意义。<details>
<summary>Abstract</summary>
Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we obtain scores that are independent of a sensitive variable but keep their marginal orderings. This step ensures predictive accuracy but also helps us to recover the regions most associated with the generation of the biases. Our findings hold significant implications for the development of trustworthy and unbiased AI systems, fostering transparency, accountability, and fairness in critical decision-making scenarios across diverse domains.
</details>
<details>
<summary>摘要</summary>
算法公平和可解释性是建立人工智能系统信任和负责任的关键因素，尤其在医疗和警察领域。虽然在每个领域 separately 有所进步，但在公平应用中实现可解释性仍然是挑战，特别是在使用深度神经网络时。同时，伦理数据挖掘已成为非常重要，因为无数次证明了不公平的算法会导致偏见的结果。现有的方法主要是减轻模型的偏见结果，但几乎没有尝试解释模型为何偏见。为了bridging这个差距，我们提出了一种全面的方法，利用最优运输理论来揭示偏见区域在图像中的原因和后果，这种方法可以轻松扩展到表格数据上。通过使用拓扑 Wasserstein 中心，我们可以获得不виси于敏感变量的分数，但保持其排序。这一步确保预测精度，同时帮助我们回归偏见区域的生成。我们的发现对于开发可靠、无偏的人工智能系统的发展有着深远的意义，推动了诚实、负责任和公平在多个领域中的决策过程中的透明度和公平。
</details></li>
</ul>
<hr>
<h2 id="Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors"><a href="#Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors" class="headerlink" title="Long-Term Prediction of Natural Video Sequences with Robust Video Predictors"></a>Long-Term Prediction of Natural Video Sequences with Robust Video Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11079">http://arxiv.org/abs/2308.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 预测高维视频序列是一个非常困难的问题，因为可能的未来场景的数量会 exponential 增长随着时间的推移。特别是在从有限的世界Snapshot中预测自然的视频场景时，内在的不确定性会快速增加，使长期预测变得非常困难。</li>
<li>methods: 我们在这篇论文中引入了一些改进了现有工作，以创建Robust Video Predictors (RoViPs)。我们使用深度Perceptual和 uncertainty-based reconstructionloss来创建高质量短期预测。使用Attention-based skip connections以实现跨距离空间特征输入的长距离移动，以进一步提高性能。</li>
<li>results: 我们显示了使用单步预测任务iterated 可以生成非常长、自然的视频序列。<details>
<summary>Abstract</summary>
Predicting high dimensional video sequences is a curiously difficult problem. The number of possible futures for a given video sequence grows exponentially over time due to uncertainty. This is especially evident when trying to predict complicated natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict making long-term prediction very difficult. In this work we introduce a number of improvements to existing work that aid in creating Robust Video Predictors (RoViPs). We show that with a combination of deep Perceptual and uncertainty-based reconstruction losses we are able to create high quality short-term predictions. Attention-based skip connections are utilised to allow for long range spatial movement of input features to further improve performance. Finally, we show that by simply making the predictor robust to its own prediction errors, it is possible to produce very long, realistic natural video sequences using an iterated single-step prediction task.
</details>
<details>
<summary>摘要</summary>
Predicting high-dimensional video sequences is a challenging problem. The number of possible futures for a given video sequence grows exponentially with time due to uncertainty. This is particularly evident when trying to predict complex natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict, making long-term prediction very difficult. In this work, we introduce several improvements to existing methods that aid in creating Robust Video Predictors (RoViPs). We show that by combining deep perceptual and uncertainty-based reconstruction losses, we can create high-quality short-term predictions. Attention-based skip connections are used to allow for long-range spatial movement of input features, further improving performance. Finally, we show that by simply making the predictor robust to its own prediction errors, we can produce very long, realistic natural video sequences using an iterated single-step prediction task.Here's the text with some notes on the translation:* "high-dimensional" is translated as "高维的" (gāo wéi de), which is a common way to describe high-dimensional data in Chinese.* "video sequences" is translated as "视频序列" (pǐn yǐng xù xià), which is a literal translation of the English phrase.* "uncertainty" is translated as "不确定性" (bù jì dìng xìng), which is a common way to describe uncertainty in Chinese.* "complicated" is translated as "复杂的" (fù zhòng de), which is a common way to describe complex or intricate things in Chinese.* "natural video scenes" is translated as "自然的视频场景" (zì rán de pǐn yǐng chǎng jǐng), which is a literal translation of the English phrase.* "long-term prediction" is translated as "长期预测" (cháng qī yù tiè), which is a common way to describe long-term predictions in Chinese.* "iterated single-step prediction task" is translated as " iterate 单步预测任务" (pītī yī xiào yù jì), which is a literal translation of the English phrase.I hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Class-Incremental-Learning"><a href="#Audio-Visual-Class-Incremental-Learning" class="headerlink" title="Audio-Visual Class-Incremental Learning"></a>Audio-Visual Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11073">http://arxiv.org/abs/2308.11073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weiguopian/av-cil_iccv2023">https://github.com/weiguopian/av-cil_iccv2023</a></li>
<li>paper_authors: Weiguo Pian, Shentong Mo, Yunhui Guo, Yapeng Tian</li>
<li>for: 这篇论文提出了一种 audio-visual 类增 learning 问题，即在 audio-visual 视频认知中进行类增 learning。</li>
<li>methods: 该论文提出了一种叫做 AV-CIL 的方法，该方法通过 dual-audio-visual 相似性约束 (D-AVSC) 和视觉注意力练化 (VAD) 来保持音频视频modalities之间的semantic similarity，并且能够在类增 learning 过程中 preserved previously learned audio-guided visual attentive ability。</li>
<li>results: 该论文的实验结果表明，AV-CIL 方法在 audio-visual 类增 learning 中 Significantly outperforms 现有的类增 learning 方法。<details>
<summary>Abstract</summary>
In this paper, we introduce audio-visual class-incremental learning, a class-incremental learning scenario for audio-visual video recognition. We demonstrate that joint audio-visual modeling can improve class-incremental learning, but current methods fail to preserve semantic similarity between audio and visual features as incremental step grows. Furthermore, we observe that audio-visual correlations learned in previous tasks can be forgotten as incremental steps progress, leading to poor performance. To overcome these challenges, we propose AV-CIL, which incorporates Dual-Audio-Visual Similarity Constraint (D-AVSC) to maintain both instance-aware and class-aware semantic similarity between audio-visual modalities and Visual Attention Distillation (VAD) to retain previously learned audio-guided visual attentive ability. We create three audio-visual class-incremental datasets, AVE-Class-Incremental (AVE-CI), Kinetics-Sounds-Class-Incremental (K-S-CI), and VGGSound100-Class-Incremental (VS100-CI) based on the AVE, Kinetics-Sounds, and VGGSound datasets, respectively. Our experiments on AVE-CI, K-S-CI, and VS100-CI demonstrate that AV-CIL significantly outperforms existing class-incremental learning methods in audio-visual class-incremental learning. Code and data are available at: https://github.com/weiguoPian/AV-CIL_ICCV2023.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了音频视频类增长学习（Audio-Visual Class-Incremental Learning，AVCIL），这是一种类增长学习场景 для音频视频识别。我们示示了 joint audio-visual 模型可以提高类增长学习性能，但现有方法无法保持音频视频特征之间的semantic similarity，特别是在增量步骤增长时。此外，我们发现在前一个任务学习的音频视频相关性可以在后续任务学习过程中被忘记，导致性能下降。为了解决这些挑战，我们提出了 Dual-Audio-Visual Similarity Constraint（D-AVSC）和 Visual Attention Distillation（VAD）两种方法。我们创建了三个音频视频类增长数据集： AVE-Class-Incremental（AVE-CI）、Kinetics-Sounds-Class-Incremental（K-S-CI）和 VGGSound100-Class-Incremental（VS100-CI），基于 AVE、Kinetics-Sounds 和 VGGSound 数据集。我们在 AVE-CI、K-S-CI 和 VS100-CI 上进行了实验，并证明了 AV-CIL 在音频视频类增长学习中表现出色，超过了现有的类增长学习方法。代码和数据可以在 GitHub 上获取：https://github.com/weiguoPian/AV-CIL_ICCV2023。
</details></li>
</ul>
<hr>
<h2 id="TeD-SPAD-Temporal-Distinctiveness-for-Self-supervised-Privacy-preservation-for-video-Anomaly-Detection"><a href="#TeD-SPAD-Temporal-Distinctiveness-for-Self-supervised-Privacy-preservation-for-video-Anomaly-Detection" class="headerlink" title="TeD-SPAD: Temporal Distinctiveness for Self-supervised Privacy-preservation for video Anomaly Detection"></a>TeD-SPAD: Temporal Distinctiveness for Self-supervised Privacy-preservation for video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11072">http://arxiv.org/abs/2308.11072</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UCF-CRCV/TeD-SPAD">https://github.com/UCF-CRCV/TeD-SPAD</a></li>
<li>paper_authors: Joseph Fioresi, Ishan Rajendrakumar Dave, Mubarak Shah</li>
<li>for: 这个研究的目的是为了提出一个具有隐私保护的视预测异常探测方法，以解决现有的人工监控不足和隐私泄露问题。</li>
<li>methods: 这个方法使用了一个自我监控的三元损害函数来增强时间特征，并且使用了一个具有隐私保护的数据隐藏技术来防止隐私泄露。</li>
<li>results: 这个方法在三个弱型监控的视预测异常探测 datasets（UCF-Crime、XD-Violence和ShanghaiTech）上取得了一个良好的平衡，即在保护隐私的同时，也能够维持视预测异常探测的性能。<details>
<summary>Abstract</summary>
Video anomaly detection (VAD) without human monitoring is a complex computer vision task that can have a positive impact on society if implemented successfully. While recent advances have made significant progress in solving this task, most existing approaches overlook a critical real-world concern: privacy. With the increasing popularity of artificial intelligence technologies, it becomes crucial to implement proper AI ethics into their development. Privacy leakage in VAD allows models to pick up and amplify unnecessary biases related to people's personal information, which may lead to undesirable decision making. In this paper, we propose TeD-SPAD, a privacy-aware video anomaly detection framework that destroys visual private information in a self-supervised manner. In particular, we propose the use of a temporally-distinct triplet loss to promote temporally discriminative features, which complements current weakly-supervised VAD methods. Using TeD-SPAD, we achieve a positive trade-off between privacy protection and utility anomaly detection performance on three popular weakly supervised VAD datasets: UCF-Crime, XD-Violence, and ShanghaiTech. Our proposed anonymization model reduces private attribute prediction by 32.25% while only reducing frame-level ROC AUC on the UCF-Crime anomaly detection dataset by 3.69%. Project Page: https://joefioresi718.github.io/TeD-SPAD_webpage/
</details>
<details>
<summary>摘要</summary>
“视频异常检测（VAD）无人监测是一项复杂的计算机视觉任务，如果成功实施，它将对社会产生积极的影响。然而，现有的大多数方法忽略了一个重要的现实问题：隐私。随着人工智能技术的普及，它们的开发中需要落实合适的人工智能伦理。VAD模型可以捕捉和强调人们个人信息的无关的偏见，导致不良决策。在这篇论文中，我们提出了一种隐私意识视频异常检测框架，即TeD-SPAD。具体来说，我们提出使用时间特征分别的 triplet损失来促进时间特征分别，这与现有的弱监测VAD方法相 complement。使用TeD-SPAD，我们在三个流行的弱监测VAD数据集上实现了隐私保护和异常检测性能的积极负作用。我们的提出的匿名化模型可以降低人员特征预测值32.25%，只减某些数据集的异常检测精度3.69%。项目页面：https://joefioresi718.github.io/TeD-SPAD_webpage/”
</details></li>
</ul>
<hr>
<h2 id="MetaGCD-Learning-to-Continually-Learn-in-Generalized-Category-Discovery"><a href="#MetaGCD-Learning-to-Continually-Learn-in-Generalized-Category-Discovery" class="headerlink" title="MetaGCD: Learning to Continually Learn in Generalized Category Discovery"></a>MetaGCD: Learning to Continually Learn in Generalized Category Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11063">http://arxiv.org/abs/2308.11063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanan Wu, Zhixiang Chi, Yang Wang, Songhe Feng</li>
<li>for: 本研究的目的是解决一种实际场景，在训练过程中遇到未标注的数据，该数据包含已知和新类的混合类。目标是不断发现新类，同时保持已知类的性能。我们称之为 Continual Generalized Category Discovery (C-GCD) Setting。</li>
<li>methods: 我们提出了一种方法，即 MetaGCD，以便在 C-GCD  Setting 中不断发现新类而不忘记已知类。我们使用了一个元学习框架，并利用了在线标注数据来模拟测试增量学习过程。我们定义了一个元目标，旨在同时解决两个矛盾的学习目标，以实现不断发现新类而不忘记已知类。此外，我们还提出了一种软邻域基于对比网络，以便区分无关图像而吸引相关图像。</li>
<li>results: 我们在三个广泛使用的标准测试benchmark上建立了强大的基准，并进行了广泛的实验。我们的方法在 C-GCD  Setting 中表现出色，可以不断发现新类而不忘记已知类。<details>
<summary>Abstract</summary>
In this paper, we consider a real-world scenario where a model that is trained on pre-defined classes continually encounters unlabeled data that contains both known and novel classes. The goal is to continually discover novel classes while maintaining the performance in known classes. We name the setting Continual Generalized Category Discovery (C-GCD). Existing methods for novel class discovery cannot directly handle the C-GCD setting due to some unrealistic assumptions, such as the unlabeled data only containing novel classes. Furthermore, they fail to discover novel classes in a continual fashion. In this work, we lift all these assumptions and propose an approach, called MetaGCD, to learn how to incrementally discover with less forgetting. Our proposed method uses a meta-learning framework and leverages the offline labeled data to simulate the testing incremental learning process. A meta-objective is defined to revolve around two conflicting learning objectives to achieve novel class discovery without forgetting. Furthermore, a soft neighborhood-based contrastive network is proposed to discriminate uncorrelated images while attracting correlated images. We build strong baselines and conduct extensive experiments on three widely used benchmarks to demonstrate the superiority of our method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们考虑了一个真实世界场景，在这个场景中，一个已经训练过的模型在不断接触到预先定义的类和未经标注的数据中遇到了新类。目标是同时发现新类并保持已知类的性能。我们称这种设定为总类发现（C-GCD）。现有的新类发现方法无法直接处理这种设定，这是因为它们假设了尚未标注的数据只包含新类。此外，它们也无法在不断发现新类的情况下保持已知类的性能。在这种工作中，我们终止了这些假设，并提出了一种方法，称为MetaGCD，以incremental learning来发现新类而减少忘记。我们的提出的方法使用了meta-学框架，利用了在线标注数据来模拟测试增量学习过程。我们定义了一个meta-目标，旨在在新类发现和已知类性能之间协调两个不同的学习目标。此外，我们还提出了一种软邻域基于的对比网络，以便在不同类型之间分辨细分图像。我们建立了强大的基elines并进行了广泛的实验，以证明我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="UnLoc-A-Unified-Framework-for-Video-Localization-Tasks"><a href="#UnLoc-A-Unified-Framework-for-Video-Localization-Tasks" class="headerlink" title="UnLoc: A Unified Framework for Video Localization Tasks"></a>UnLoc: A Unified Framework for Video Localization Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11062">http://arxiv.org/abs/2308.11062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/scenic">https://github.com/google-research/scenic</a></li>
<li>paper_authors: Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid</li>
<li>for: 这个研究的目的是提出一种新的视频地理ocalization方法，用于在未经trim的视频中进行时间地理ocalization。</li>
<li>methods: 这个方法使用预训练的图像和文本楼层，并将 tokens 传递给一个视频-文本融合模型。输出的融合模型输出将用于构建一个特征 пирамид，每个层与一个头相连，以预测每帧的相关性分数和开始&#x2F;结束时间偏移。</li>
<li>results: 这个方法可以实现视频地理ocalization、时间地理ocalization和动作分割等三个任务，并且在所有三个任务中达到了现有最佳Result。<details>
<summary>Abstract</summary>
While large-scale image-text pretrained models such as CLIP have been used for multiple video-level tasks on trimmed videos, their use for temporal localization in untrimmed videos is still a relatively unexplored task. We design a new approach for this called UnLoc, which uses pretrained image and text towers, and feeds tokens to a video-text fusion model. The output of the fusion module are then used to construct a feature pyramid in which each level connects to a head to predict a per-frame relevancy score and start/end time displacements. Unlike previous works, our architecture enables Moment Retrieval, Temporal Localization, and Action Segmentation with a single stage model, without the need for action proposals, motion based pretrained features or representation masking. Unlike specialized models, we achieve state of the art results on all three different localization tasks with a unified approach. Code will be available at: \url{https://github.com/google-research/scenic}.
</details>
<details>
<summary>摘要</summary>
大规模图像文本预训练模型，如CLIP，已经在剪辑后的视频上进行多种任务，但是它们在未剪辑视频中的时间本地化仍然是一个未解决的问题。我们设计了一种新的方法called UnLoc，它使用预训练的图像和文本楼层，并将Token传递给视频-文本融合模型。融合模块的输出被用construct一个功能PYRAMID，每个层与一个头连接，以预测每帧的相关性分数和开始/结束时间偏移。与之前的方法不同，我们的体系允许场景检索、时间本地化和动作分割使用单一的阶段模型，不需要动作提案、运动基于预训练特征或表示掩码。与专门的模型不同，我们在所有三种本地化任务中达到了状态arta的结果，代码将在：\url{https://github.com/google-research/scenic}上提供。
</details></li>
</ul>
<hr>
<h2 id="Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI"><a href="#Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI" class="headerlink" title="Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI"></a>Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11047">http://arxiv.org/abs/2308.11047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhijeet Parida, Zhifan Jiang, Syed Muhammad Anwar, Nicholas Foreman, Nicholas Stence, Michael J. Fisher, Roger J. Packer, Robert A. Avery, Marius George Linguraru</li>
<li>for: 这篇论文旨在提出一种用于类比较罕见疾病，如儿童脑肿瘤的机器学习基于医疗影像诊断和预测方法。</li>
<li>methods: 本论文使用了生成对抗网络（GANs）进行深度学习预测，并提出了一种一击学习方法，使用神经风格转移来调整医疗影像的强度标准。</li>
<li>results: 实验结果显示，该方法可以保持病人解剖结构，并调整影像强度以适应新的诊疗所需。此外，该方法可以在未见到训练数据的情况下进行应用，因此具有实际应用和临床试验的价值。<details>
<summary>Abstract</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.
</details>
<details>
<summary>摘要</summary>
Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. We also propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures.Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.Here's the Simplified Chinese translation:为了使用机器学习来诊断和预测罕见疾病，如儿童脑肿瘤，需要从多个临床Site收集医学成像数据，这些数据可能使用不同的设备和协议。但是，使用生成对抗网络（GANs）进行深度学习驱动的成像融合可能会导致“幻觉”现象，即生成不存在于训练数据中的 pseudo 结构。为了避免幻觉在医学成像中，我们提议一种一键学习方法，利用神经风格传输来融合。在测试时，方法使用一个来自临床Site的图像，通过神经风格传输来生成医学成像，以适应新的临床Site的INTENSITY规模。我们还提出了一种新的评估图像融合方法的效果的策略，该策略包括评估图像风格融合和评估结构保持。实验结果表明，我们的方法可以保持患者的解剖结构，同时调整图像INTENSITY来适应新的临床Site。我们的通用融合模型可以在新的Site上使用未看过的数据，因此它是实际医疗应用和临床试验中的有价值工具。
</details></li>
</ul>
<hr>
<h2 id="Coordinate-Quantized-Neural-Implicit-Representations-for-Multi-view-Reconstruction"><a href="#Coordinate-Quantized-Neural-Implicit-Representations-for-Multi-view-Reconstruction" class="headerlink" title="Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction"></a>Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11025">http://arxiv.org/abs/2308.11025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/machineperceptionlab/cq-nir">https://github.com/machineperceptionlab/cq-nir</a></li>
<li>paper_authors: Sijia Jiang, Jing Hua, Zhizhong Han</li>
<li>for: 用于学习神经隐式表示法从多视图图像中获取3D重建</li>
<li>methods: 使用量化坐标为神经网络中的输入，并使用离散坐标和其позициональ编码来学习隐式函数</li>
<li>results: 提高了多视图一致性约束，并且不会增加计算负担，在最新的方法上显示了超过状态艺术的优势<details>
<summary>Abstract</summary>
In recent years, huge progress has been made on learning neural implicit representations from multi-view images for 3D reconstruction. As an additional input complementing coordinates, using sinusoidal functions as positional encodings plays a key role in revealing high frequency details with coordinate-based neural networks. However, high frequency positional encodings make the optimization unstable, which results in noisy reconstructions and artifacts in empty space. To resolve this issue in a general sense, we introduce to learn neural implicit representations with quantized coordinates, which reduces the uncertainty and ambiguity in the field during optimization. Instead of continuous coordinates, we discretize continuous coordinates into discrete coordinates using nearest interpolation among quantized coordinates which are obtained by discretizing the field in an extremely high resolution. We use discrete coordinates and their positional encodings to learn implicit functions through volume rendering. This significantly reduces the variations in the sample space, and triggers more multi-view consistency constraints on intersections of rays from different views, which enables to infer implicit function in a more effective way. Our quantized coordinates do not bring any computational burden, and can seamlessly work upon the latest methods. Our evaluations under the widely used benchmarks show our superiority over the state-of-the-art. Our code is available at https://github.com/MachinePerceptionLab/CQ-NIR.
</details>
<details>
<summary>摘要</summary>
Recently, there have been significant advancements in learning neural implicit representations from multi-view images for 3D reconstruction. Using sinusoidal functions as positional encodings has proven to be crucial in revealing high-frequency details with coordinate-based neural networks. However, the use of high-frequency positional encodings can lead to unstable optimization, resulting in noisy reconstructions and artifacts in empty space. To address this issue, we propose learning neural implicit representations with quantized coordinates, which reduces uncertainty and ambiguity in the field during optimization. Instead of using continuous coordinates, we discretize them into discrete coordinates using nearest interpolation among quantized coordinates, which are obtained by discretizing the field in an extremely high resolution. We then use these discrete coordinates and their positional encodings to learn implicit functions through volume rendering, significantly reducing variations in the sample space and triggering more multi-view consistency constraints on intersections of rays from different views, enabling more effective inference of implicit functions. Our quantized coordinates do not increase computational burden and can seamlessly work with the latest methods. Our evaluations on widely used benchmarks show our superiority over the state-of-the-art. Our code is available at https://github.com/MachinePerceptionLab/CQ-NIR.
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations"><a href="#Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations" class="headerlink" title="Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations"></a>Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11021">http://arxiv.org/abs/2308.11021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mihai Pirvu, Alina Marcu, Alexandra Dobrescu, Nabil Belbachir, Marius Leordeanu</li>
<li>for: 这个论文是为了解决多任务学习中数据缺失问题，特别是在地球观测领域，where ground-truth data is often missing.</li>
<li>methods: 该论文提出了一种多任务hypergraphSelf-supervised learning方法，其中每个节点是一个任务，不同的路径通过hypergraph到达给定任务都成为了无监督教师，并通过 ensemble 学习生成可靠的pseudolabels。</li>
<li>results: 经过对NASA NEO数据集的广泛实验，论文示出了其多任务半监督方法的价值，包括在强基elines和最近的工作上的一致提升。此外，论文还表明了hypergraph可以适应不监督数据分布变化，并可靠地恢复缺失数据，以及其可以在多个观测层次上适应数据缺失情况。<details>
<summary>Abstract</summary>
There are many ways of interpreting the world and they are highly interdependent. We exploit such complex dependencies and introduce a powerful multi-task hypergraph, in which every node is a task and different paths through the hypergraph reaching a given task become unsupervised teachers, by forming ensembles that learn to generate reliable pseudolabels for that task. Each hyperedge is part of an ensemble teacher for a given task and it is also a student of the self-supervised hypergraph system. We apply our model to one of the most important problems of our times, that of Earth Observation, which is highly multi-task and it often suffers from missing ground-truth data. By performing extensive experiments on the NASA NEO Dataset, spanning a period of 22 years, we demonstrate the value of our multi-task semi-supervised approach, by consistent improvements over strong baselines and recent work. We also show that the hypergraph can adapt unsupervised to gradual data distribution shifts and reliably recover, through its multi-task self-supervision process, the missing data for several observational layers for up to seven years.
</details>
<details>
<summary>摘要</summary>
世界上有很多方法来解释，它们之间很高度相互依赖。我们利用这些复杂的依赖关系，引入一个强大的多任务超графи，其中每个节点是一个任务，不同的路径通过超графи到达某个任务就会成为无监督教师。每个超边都是一个任务的ensemble教师，同时也是自我超vised系统的学生。我们应用我们的模型到现代时代最重要的问题之一：地球观测，这是一个高度多任务的问题，经常缺少真实数据。通过对NASA NEO数据集进行广泛的实验，覆盖22年时间段，我们展示了我们的多任务半超监教学方法的价值，通过与强基线和最新研究的相对比较，我们的模型在多个任务上具有稳定和可靠的表现。此外，我们还证明了超графи可以适应无监督数据分布变化，通过自我超vision过程，可以重新生成多个观测层的缺失数据，保持稳定的表现，达到7年之久。
</details></li>
</ul>
<hr>
<h2 id="Spectral-Graphormer-Spectral-Graph-based-Transformer-for-Egocentric-Two-Hand-Reconstruction-using-Multi-View-Color-Images"><a href="#Spectral-Graphormer-Spectral-Graph-based-Transformer-for-Egocentric-Two-Hand-Reconstruction-using-Multi-View-Color-Images" class="headerlink" title="Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images"></a>Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11015">http://arxiv.org/abs/2308.11015</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eldentse/Spectral-Graphormer">https://github.com/eldentse/Spectral-Graphormer</a></li>
<li>paper_authors: Tze Ho Elden Tse, Franziska Mueller, Zhengyang Shen, Danhang Tang, Thabo Beeler, Mingsong Dou, Yinda Zhang, Sasa Petrovic, Hyung Jin Chang, Jonathan Taylor, Bardia Doosti</li>
<li>For:  reconstruction of two high fidelity hands from multi-view RGB images* Methods: transformer-based framework with spectral graph convolution decoder and optimization-based refinement stage* Results: realistic two-hand reconstructions with physical plausibility and generalization to real data, as well as real-time AR&#x2F;VR applications.Here’s the full summary in Simplified Chinese:</li>
<li>for: 重构两个高精度手掌从多视图RGB图像中</li>
<li>methods: 使用变换器基于框架，并使用spectral graph convolution decoder和优化基于的反馈阶段</li>
<li>results: 生成真实的两手重构，并实现数据实际性和AR&#x2F;VR应用中的实时渲染。<details>
<summary>Abstract</summary>
We propose a novel transformer-based framework that reconstructs two high fidelity hands from multi-view RGB images. Unlike existing hand pose estimation methods, where one typically trains a deep network to regress hand model parameters from single RGB image, we consider a more challenging problem setting where we directly regress the absolute root poses of two-hands with extended forearm at high resolution from egocentric view. As existing datasets are either infeasible for egocentric viewpoints or lack background variations, we create a large-scale synthetic dataset with diverse scenarios and collect a real dataset from multi-calibrated camera setup to verify our proposed multi-view image feature fusion strategy. To make the reconstruction physically plausible, we propose two strategies: (i) a coarse-to-fine spectral graph convolution decoder to smoothen the meshes during upsampling and (ii) an optimisation-based refinement stage at inference to prevent self-penetrations. Through extensive quantitative and qualitative evaluations, we show that our framework is able to produce realistic two-hand reconstructions and demonstrate the generalisation of synthetic-trained models to real data, as well as real-time AR/VR applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于转换器的新框架，可以从多视角RGB图像中重建高精度两只手。与现有的手姿估计方法不同，我们处理一个更加复杂的问题Setting，即从 egocentric 视角直接将两只手的绝对根姿 Parameters 高分辨率RGB图像中进行重建。由于现有的数据集不可能进行 egocentric 视角或缺乏背景变化，我们创建了一个大规模的 simulate 数据集和实际数据集，以验证我们的多视角图像特征融合策略。为使重建 Physically plausible，我们提出了两种策略：（i）一种粗到细 spectral 图像 conv 嵌入器来平滑网格时的抗锯齿，以及（ii）在推理时进行优化基于反射 stage 以避免自身穿孔。经过广泛的量化和质量评估，我们表明我们的框架可以生成真实的两只手重建，并示出了 synthetic 训练的模型在实际数据上的普适性，以及实时 AR/VR 应用。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning"><a href="#Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning" class="headerlink" title="Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning"></a>Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11003">http://arxiv.org/abs/2308.11003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bertrand Rouet-Leduc, Thomas Kerdreux, Alexandre Tuel, Claudia Hulbert</li>
<li>for: 监控全球暖化的一种重要方法，减少温室气体的排放</li>
<li>methods: 使用深度学习方法自动识别几何图像中的甲烷泄漏</li>
<li>results: 比前一代多spectrum甲烷数据产品降低假阳性率，无需对潜在泄漏地点有专业知识<details>
<summary>Abstract</summary>
Methane is one of the most potent greenhouse gases, and its short atmospheric half-life makes it a prime target to rapidly curb global warming. However, current methane emission monitoring techniques primarily rely on approximate emission factors or self-reporting, which have been shown to often dramatically underestimate emissions. Although initially designed to monitor surface properties, satellite multispectral data has recently emerged as a powerful method to analyze atmospheric content. However, the spectral resolution of multispectral instruments is poor, and methane measurements are typically very noisy. Methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis. Here, we show that the image recognition capabilities of deep learning methods can be leveraged to automatize the detection of methane leaks in Sentinel-2 satellite multispectral data, with dramatically reduced false positive rates compared with state-of-the-art multispectral methane data products, and without the need for a priori knowledge of potential leak sites. Our proposed approach paves the way for the automated, high-definition and high-frequency monitoring of point-source methane emissions across the world.
</details>
<details>
<summary>摘要</summary>
偏二氢（methane）是全球暖化气体中最强大的一种，它的大气半衰期短，使其成为快速降低全球暖化的目标。然而，当前的偏二氢泄漏监测技术主要基于估算性的泄漏因素或者自我报告，这些估算经常会很大的下降估计。虽然初始设计用于观察地面特性，但卫星多spectral数据最近才被发现作为分析大气内容的 poderoso方法。然而，多spectral工具的 spectral resolution很差，偏二氢测量通常很吵闹。偏二氢数据产品也受到地面和其他大气气体（水蒸气特别是）的吸收，因此提供的偏二氢潮区图像通常需要人工分析。在这里，我们展示了深度学习方法的图像识别能力可以自动化卫星Sentinel-2多spectral数据中的偏二氢泄漏检测，与现有的多spectral偏二氢数据产品相比， false positive 率有所下降，而无需先知泄漏点位置的假设。我们的提出的方法开 up a new way for the automatic, high-definition and high-frequency monitoring of point-source methane emissions around the world.
</details></li>
</ul>
<hr>
<h2 id="Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation"><a href="#Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation" class="headerlink" title="Switched auxiliary loss for robust training of transformer models for histopathological image segmentation"></a>Switched auxiliary loss for robust training of transformer models for histopathological image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10994">http://arxiv.org/abs/2308.10994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mustaffa Hussain, Saharsh Barve</li>
<li>For: 本研究旨在提供一种模型，用于分类多个器官Functional Tissue Units (FTUs)的cell population neighborhoods，以便帮助病理学家更好地理解人体疾病的影响。* Methods: 该模型使用HuBMAP + HPA - Hacking the Human Body competition dataset进行训练，并提出了shifted auxiliary loss来解决深度模型的减速问题。* Results: 该模型在公共数据集上取得了0.793的dice分数，而在私有数据集上取得了0.778的dice分数，与传统方法相比，该方法提供了1%的提升。这些结果表明 transformers 模型在医学图像分析中的粗粒预测任务中的表现非常出色，并且可以帮助我们更好地理解人体细胞和组织的关系，从而更好地理解人体健康的影响。<details>
<summary>Abstract</summary>
Functional tissue Units (FTUs) are cell population neighborhoods local to a particular organ performing its main function. The FTUs provide crucial information to the pathologist in understanding the disease affecting a particular organ by providing information at the cellular level. In our research, we have developed a model to segment multi-organ FTUs across 5 organs namely: the kidney, large intestine, lung, prostate and spleen by utilizing the HuBMAP + HPA - Hacking the Human Body competition dataset. We propose adding shifted auxiliary loss for training models like the transformers to overcome the diminishing gradient problem which poses a challenge towards optimal training of deep models. Overall, our model achieved a dice score of 0.793 on the public dataset and 0.778 on the private dataset and shows a 1% improvement with the use of the proposed method. The findings also bolster the use of transformers models for dense prediction tasks in the field of medical image analysis. The study assists in understanding the relationships between cell and tissue organization thereby providing a useful medium to look at the impact of cellular functions on human health.
</details>
<details>
<summary>摘要</summary>
功能组织单元（FTU）是指器官本地的细胞群聚，提供了病理学家理解器官疾病的关键信息。在我们的研究中，我们开发了一种方法来在5种器官（肾脏、大小肠、肺、肾脏和脾脏）的FTU中进行多器官分割，使用了HuBMAP+HPA-Hacking the Human Body竞赛数据集。我们提议在训练模型时使用偏移 auxiliary loss，以解决深度模型训练过程中的减少梯度问题。总的来说，我们的模型在公共数据集上 achievement了0.793的 dice 分数，在私有数据集上 achievement了0.778的 dice 分数，与使用我们提议的方法相比，提高了1%。这些结果也证明了transformers模型在医学影像分析中的稠密预测任务中的可靠性。本研究帮助我们理解细胞和组织结构之间的关系，从而提供了一个有用的媒体来查看细胞功能对人类健康的影响。
</details></li>
</ul>
<hr>
<h2 id="Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations"><a href="#Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations" class="headerlink" title="Debiasing Counterfactuals In the Presence of Spurious Correlations"></a>Debiasing Counterfactuals In the Presence of Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10984">http://arxiv.org/abs/2308.10984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amar Kumar, Nima Fathi, Raghav Mehta, Brennan Nichyporuk, Jean-Pierre R. Falet, Sotirios Tsaftaris, Tal Arbel</li>
<li>for: The paper is written for the task of medical imaging classification, specifically addressing the issue of deep learning models relying on spurious correlations in the training data.</li>
<li>methods: The paper proposes an end-to-end training framework that integrates popular debiasing classifiers (such as distributionally robust optimization) with counterfactual image generation to expose generalizable imaging markers of relevance to the task, and a novel metric (Spurious Correlation Latching Score) to quantify the extent of classifier reliance on spurious correlations.</li>
<li>results: The paper demonstrates through comprehensive experiments on two public datasets (with simulated and real visual artifacts) that the debiasing method (i) learns generalizable markers across the population and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了医学成像分类任务而写的，特别是处理深度学习模型在训练数据中遇到的假 correlate 问题。</li>
<li>methods: 这篇论文提出了一种结合流行的偏差纠正分类器（如分布式稳定优化）和对假 correlate 进行抗衡的末端训练框架，以及一个新的指标（假 correlate 抓取得分）来衡量分类器偏差的程度。</li>
<li>results: 这篇论文通过对公共数据集（包括模拟和实际视觉杂质）进行了广泛的实验，证明了偏差方法可以（一）学习人口中的通用标记，并（二）忽略假 correlate 并专注于下面疾病生物学。<details>
<summary>Abstract</summary>
Deep learning models can perform well in complex medical imaging classification tasks, even when basing their conclusions on spurious correlations (i.e. confounders), should they be prevalent in the training dataset, rather than on the causal image markers of interest. This would thereby limit their ability to generalize across the population. Explainability based on counterfactual image generation can be used to expose the confounders but does not provide a strategy to mitigate the bias. In this work, we introduce the first end-to-end training framework that integrates both (i) popular debiasing classifiers (e.g. distributionally robust optimization (DRO)) to avoid latching onto the spurious correlations and (ii) counterfactual image generation to unveil generalizable imaging markers of relevance to the task. Additionally, we propose a novel metric, Spurious Correlation Latching Score (SCLS), to quantify the extent of the classifier reliance on the spurious correlation as exposed by the counterfactual images. Through comprehensive experiments on two public datasets (with the simulated and real visual artifacts), we demonstrate that the debiasing method: (i) learns generalizable markers across the population, and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.
</details>
<details>
<summary>摘要</summary>
In this work, we introduce the first end-to-end training framework that integrates both (i) popular debiasing classifiers (e.g. distributionally robust optimization (DRO)) to avoid latching onto the spurious correlations and (ii) counterfactual image generation to unveil generalizable imaging markers of relevance to the task. We also propose a novel metric, Spurious Correlation Latching Score (SCLS), to quantify the extent of the classifier reliance on the spurious correlation as exposed by the counterfactual images.Through comprehensive experiments on two public datasets (with simulated and real visual artifacts), we demonstrate that the debiasing method: (i) learns generalizable markers across the population, and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.
</details></li>
</ul>
<hr>
<h2 id="VQA-Therapy-Exploring-Answer-Differences-by-Visually-Grounding-Answers"><a href="#VQA-Therapy-Exploring-Answer-Differences-by-Visually-Grounding-Answers" class="headerlink" title="VQA Therapy: Exploring Answer Differences by Visually Grounding Answers"></a>VQA Therapy: Exploring Answer Differences by Visually Grounding Answers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11662">http://arxiv.org/abs/2308.11662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ccychongyanchen/vqatherapycrowdsourcing">https://github.com/ccychongyanchen/vqatherapycrowdsourcing</a></li>
<li>paper_authors: Chongyan Chen, Samreen Anjum, Danna Gurari</li>
<li>for: 这篇论文是关于视觉问答任务的研究，旨在更好地理解不同人对同一张图片的问题提出不同的答案的原因。</li>
<li>methods: 该论文引入了第一个可视地将每个答案与每个视觉问题相关联的数据集，称为VQAAnswerTherapy。然后，该论文提出了两个新的问题：一是判断视觉问题是否有唯一的答案基础，二是找到所有答案基础的地方。</li>
<li>results: 该论文使用现代算法对这两个新问题进行了评估，以示其在这些问题上的成功和缺点。数据集和评估服务器可以在<a target="_blank" rel="noopener" href="https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/上公开获取。</a><details>
<summary>Abstract</summary>
Visual question answering is a task of predicting the answer to a question about an image. Given that different people can provide different answers to a visual question, we aim to better understand why with answer groundings. We introduce the first dataset that visually grounds each unique answer to each visual question, which we call VQAAnswerTherapy. We then propose two novel problems of predicting whether a visual question has a single answer grounding and localizing all answer groundings. We benchmark modern algorithms for these novel problems to show where they succeed and struggle. The dataset and evaluation server can be found publicly at https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/.
</details>
<details>
<summary>摘要</summary>
“视觉问答是一项任务，旨在预测图像上的问题的答案。由于不同的人可能对同一个视觉问题提供不同的答案，我们想要更好地理解这些答案的原因。我们引入了首个可视地固定每个独特答案的视觉问题数据集，称之为VQAAnswerTherapy。我们then提出了两个新的问题：可视地判断问题是否有唯一的答案固定，以及本地化所有答案固定。我们对现代算法进行了测试，以示其在这些新问题上的表现。数据集和评估服务器可以在https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/上公共获取。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance"><a href="#SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance" class="headerlink" title="SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance"></a>SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10973">http://arxiv.org/abs/2308.10973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jarrod Haas</li>
<li>for: 本研究旨在提出一种简单而有效的Out-of-Distribution（OoD）检测方法，可以在标准benchmark上达到state-of-the-art的结果。</li>
<li>methods: 本研究使用Supervised Contrastive Learning（SCL）将ResNet18进行训练，并使用Euclidean distance作为分数规则进行评价。</li>
<li>results: 研究发现，使用SCL训练的ResNet18可以在近和远OoD检测benchmark上达到state-of-the-art的结果，无需使用更复杂的方法或更大的模型。<details>
<summary>Abstract</summary>
Out-of-Distribution (OoD) detection has developed substantially in the past few years, with available methods approaching, and in a few cases achieving, perfect data separation on standard benchmarks. These results generally involve large or complex models, pretraining, exposure to OoD examples or extra hyperparameter tuning. Remarkably, it is possible to achieve results that can exceed many of these state-of-the-art methods with a very simple method. We demonstrate that ResNet18 trained with Supervised Contrastive Learning (SCL) produces state-of-the-art results out-of-the-box on near and far OoD detection benchmarks using only Euclidean distance as a scoring rule. This may obviate the need in some cases for more sophisticated methods or larger models, and at the very least provides a very strong, easy to use baseline for further experimentation and analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer"><a href="#MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer" class="headerlink" title="MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer"></a>MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10968">http://arxiv.org/abs/2308.10968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoyao Shen, Yancheng Zhu, Hernan Jara, Sean B. Andersson, Chad W. Farris, Stephan Anderson, Xin Zhang</li>
<li>for: 高品质的MRI重建方法</li>
<li>methods: 使用深度学习模型和风格传递的减噪方法</li>
<li>results: 使用 клиничеMRI扫描数据，能够显著提高图像质量<details>
<summary>Abstract</summary>
Recent works have demonstrated success in MRI reconstruction using deep learning-based models. However, most reported approaches require training on a task-specific, large-scale dataset. Regularization by denoising (RED) is a general pipeline which embeds a denoiser as a prior for image reconstruction. The potential of RED has been demonstrated for multiple image-related tasks such as denoising, deblurring and super-resolution. In this work, we propose a regularization by neural style transfer (RNST) method to further leverage the priors from the neural transfer and denoising engine. This enables RNST to reconstruct a high-quality image from a noisy low-quality image with different image styles and limited data. We validate RNST with clinical MRI scans from 1.5T and 3T and show that RNST can significantly boost image quality. Our results highlight the capability of the RNST framework for MRI reconstruction and the potential for reconstruction tasks with limited data.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:近期研究表明，深度学习基于模型可以成功地进行MRI重建。然而，大多数报道的方法需要任务特定、大规模的数据集来进行训练。噪声除掉（RED）是一个通用管道，它将噪声除掉作为图像重建的前提。RED已经在多种图像相关任务中展示出色，如噪声除掉、锐化和超分辨率。在这个工作中，我们提出了基于神经风格传输的噪声除掉方法（RNST），以更好地利用神经传输和噪声除掉引擎中的前提。这使得RNST可以从噪声低质量图像中重建高质量图像，并且可以处理不同的图像风格和有限的数据。我们验证了RNST使用临床MRI扫描数据，并证明了RNST可以显著提高图像质量。我们的结果表明RNST框架可以用于MRI重建，并且可能在有限数据情况下实现高质量重建。
</details></li>
</ul>
<hr>
<h2 id="BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation"><a href="#BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation" class="headerlink" title="BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation"></a>BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10958">http://arxiv.org/abs/2308.10958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Etienne St-Onge, Kurt G Schilling, Francois Rheault</li>
<li>for: 提供一种可靠、可重复、快速的白 matter 路径EXTRACTING方法</li>
<li>methods:  combinest 一种迭代注册过程与一种新发展的精确流线搜索算法，以高效地分割流线无需 трактogram clustering 或简化假设</li>
<li>results: 比state-of-the-art segmentation方法具有改进的重复性和复制性，以及显著的速度提高。 通过增强精度和减少变化，提供了一种 valuabe 的工具 для neuroscience 研究，提高了轨迹学研究中white matter pathways的敏感性和特异性。<details>
<summary>Abstract</summary>
This work presents BundleSeg, a reliable, reproducible, and fast method for extracting white matter pathways. The proposed method combines an iterative registration procedure with a recently developed precise streamline search algorithm that enables efficient segmentation of streamlines without the need for tractogram clustering or simplifying assumptions. We show that BundleSeg achieves improved repeatability and reproducibility than state-of-the-art segmentation methods, with significant speed improvements. The enhanced precision and reduced variability in extracting white matter connections offer a valuable tool for neuroinformatic studies, increasing the sensitivity and specificity of tractography-based studies of white matter pathways.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种可靠、可重复、快速的白 mater 血管路径EXTRACTING方法，称为BundleSeg。该方法结合了迭代注册过程和最近开发的精炼流线搜索算法，可以高效地 segments 流线，无需进行跟踪ogram clustering 或假设。我们展示了 BundleSeg 在EXTRACTING white matter 血管路径上的重复性和复制性得到了提高，同时速度也得到了显著提高。这种更高精度和减少的变化可以为 neuroscience 研究提供一个有价值的工具，提高了追踪学基于 white matter 血管路径的敏感性和特异性。
</details></li>
</ul>
<hr>
<h2 id="CamP-Camera-Preconditioning-for-Neural-Radiance-Fields"><a href="#CamP-Camera-Preconditioning-for-Neural-Radiance-Fields" class="headerlink" title="CamP: Camera Preconditioning for Neural Radiance Fields"></a>CamP: Camera Preconditioning for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10902">http://arxiv.org/abs/2308.10902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keunhong Park, Philipp Henzler, Ben Mildenhall, Jonathan T. Barron, Ricardo Martin-Brualla</li>
<li>for: 高精度3D场景重建</li>
<li>methods: 使用Proxy问题计算抑制器，并使用该抑制器作为预Conditioner进行相机参数优化</li>
<li>results: 对Mip-NeRF 360 dataset中的场景进行重建，比对其他State-of-the-art NeRF方法（如Zip-NeRF）和State-of-the-art联合优化方法（如SCNeRF）减少错误率（RMSE）67%，相比减少29%Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written for optimizing Neural Radiance Fields (NeRF) to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes.</li>
<li>methods: The paper proposes using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and using this transform as a preconditioner for the camera parameters during joint optimization.</li>
<li>results: The paper shows that the proposed approach significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset, reducing error rates (RMSE) by 67% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF.<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) can be optimized to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes. However, NeRFs require accurate camera parameters as input -- inaccurate camera parameters result in blurry renderings. Extrinsic and intrinsic camera parameters are usually estimated using Structure-from-Motion (SfM) methods as a pre-processing step to NeRF, but these techniques rarely yield perfect estimates. Thus, prior works have proposed jointly optimizing camera parameters alongside a NeRF, but these methods are prone to local minima in challenging settings. In this work, we analyze how different camera parameterizations affect this joint optimization problem, and observe that standard parameterizations exhibit large differences in magnitude with respect to small perturbations, which can lead to an ill-conditioned optimization problem. We propose using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and we propose to use this transform as a preconditioner for the camera parameters during joint optimization. Our preconditioned camera optimization significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset: we reduce error rates (RMSE) by 67% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF. Our approach is easy to implement, does not significantly increase runtime, can be applied to a wide variety of camera parameterizations, and can straightforwardly be incorporated into other NeRF-like models.
</details>
<details>
<summary>摘要</summary>
神经辐射场（NeRF）可以优化以获得高精度3D场景重建。然而，NeRF需要准确的摄像头参数作为输入，否则会得到模糊的渲染。通常来说，摄像头参数的内在和外在参数通过Structure-from-Motion（SfM）方法进行估计，但这些技术很少能提供完美的估计。因此，先前的工作已经提议同时优化摄像头参数和NeRF，但这些方法容易陷入困难的设置中。在这个工作中，我们分析了不同的摄像头参数化对这个联合优化问题的影响，并发现标准参数化 exhibit 大量的差异幅度，这可能导致一个不正确的优化问题。我们提出使用一个代理问题计算一个卷积变换，该变换消除了摄像头参数与normalize 其效果的相关性，并我们提议使用这个变换作为摄像头参数的预处理器。我们的预处理后的摄像头优化显著提高了Mip-NeRF 360 dataset中的重建质量：我们降低了误差率（RMSE）相比领先的NeRF方法，Zip-NeRF，和相对于领先的联合优化方法使用摄像头参数化的 SCNeRF，降低了29%。我们的方法易于实现，不会增加运行时间，可以应用于多种摄像头参数化，并可以 straightforwardly 与其他NeRF-like模型结合使用。
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Physically-Aware-Articulated-Mesh-Generation-via-Hierarchical-Deformation"><a href="#Few-Shot-Physically-Aware-Articulated-Mesh-Generation-via-Hierarchical-Deformation" class="headerlink" title="Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation"></a>Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10898">http://arxiv.org/abs/2308.10898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xueyi Liu, Bin Wang, He Wang, Li Yi</li>
<li>for: 本研究旨在解决具有少量示例的物理可知树状对象生成问题。通过观察含有只几个示例的人工骨架对象数据集，我们希望通过学习一个模型，以生成多样化的骨架，并保证其视觉准确性和物理可行性。</li>
<li>methods: 我们提出了两项关键创新，即1）基于分治哲学的层次骨架变换基本模型，以适应具有少量示例的问题，并且可以借鉴大规模的固定骨架上的可转移变换模式；2）基于物理学的变换修正方案，以促进物理可行的生成。</li>
<li>results: 我们在6种人工骨架类别上进行了广泛的实验，并证明了我们的方法在几何上比前方法更好，可以更好地生成具有多样性、高视觉准确性和物理可行性的骨架。此外，我们还进行了ablation研究，以验证我们的两项创新的准确性。研究页面及代码可以在<a target="_blank" rel="noopener" href="https://meowuu7.github.io/few-arti-obj-gen%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://meowuu7.github.io/few-arti-obj-gen中找到。</a><details>
<summary>Abstract</summary>
We study the problem of few-shot physically-aware articulated mesh generation. By observing an articulated object dataset containing only a few examples, we wish to learn a model that can generate diverse meshes with high visual fidelity and physical validity. Previous mesh generative models either have difficulties in depicting a diverse data space from only a few examples or fail to ensure physical validity of their samples. Regarding the above challenges, we propose two key innovations, including 1) a hierarchical mesh deformation-based generative model based upon the divide-and-conquer philosophy to alleviate the few-shot challenge by borrowing transferrable deformation patterns from large scale rigid meshes and 2) a physics-aware deformation correction scheme to encourage physically plausible generations. We conduct extensive experiments on 6 articulated categories to demonstrate the superiority of our method in generating articulated meshes with better diversity, higher visual fidelity, and better physical validity over previous methods in the few-shot setting. Further, we validate solid contributions of our two innovations in the ablation study. Project page with code is available at https://meowuu7.github.io/few-arti-obj-gen.
</details>
<details>
<summary>摘要</summary>
我们研究几何物体生成中受限的几何物体生成问题。通过观察一个具有少量示例的柔软物体数据集，我们希望通过学习一个可以生成多样化的几何模型，以保证高Visual faithfulness和物理有效性。先前的几何生成模型容易在几何空间中示出少量示例的多样性或者缺乏物理有效性的问题。为了解决这些挑战，我们提出了两项关键创新：1. 基于分治理的几何变形生成模型，根据分治理的哲学，从大规模的固定几何中继承可质量的变形模式，以便在几何空间中减少几何数据的几何变形问题。2. 基于物理知识的几何变形修正方案，以促进物理可能的生成。我们对6种柔软物体类型进行了广泛的实验，并证明了我们的方法在几何数据中生成的几何模型具有更高的多样性、更高的Visual faithfulness和更高的物理有效性，相比之前的方法。此外，我们还进行了减少几何变形和物理变形修正的精细分析，以证明我们的两项创新的凝聚性。项目页面和代码可以在https://meowuu7.github.io/few-arti-obj-gen中找到。
</details></li>
</ul>
<hr>
<h2 id="Can-Language-Models-Learn-to-Listen"><a href="#Can-Language-Models-Learn-to-Listen" class="headerlink" title="Can Language Models Learn to Listen?"></a>Can Language Models Learn to Listen?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10897">http://arxiv.org/abs/2308.10897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Evonne Ng, Sanjay Subramanian, Dan Klein, Angjoo Kanazawa, Trevor Darrell, Shiry Ginosar</li>
<li>For: The paper is written for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker’s words.* Methods: The approach uses an autoregressive model that predicts a response of a listener, which is a sequence of listener facial gestures, quantized using a VQ-VAE. The model treats the quantized atomic motion elements as additional language token inputs to a transformer-based large language model.* Results: The generated listener motion is fluent and reflective of language semantics, as shown through quantitative metrics and a qualitative user study. The model demonstrates the ability to utilize temporal and semantic aspects of spoken text.<details>
<summary>Abstract</summary>
We present a framework for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker's words. Given an input transcription of the speaker's words with their timestamps, our approach autoregressively predicts a response of a listener: a sequence of listener facial gestures, quantized using a VQ-VAE. Since gesture is a language component, we propose treating the quantized atomic motion elements as additional language token inputs to a transformer-based large language model. Initializing our transformer with the weights of a language model pre-trained only on text results in significantly higher quality listener responses than training a transformer from scratch. We show that our generated listener motion is fluent and reflective of language semantics through quantitative metrics and a qualitative user study. In our evaluation, we analyze the model's ability to utilize temporal and semantic aspects of spoken text. Project page: https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
</details>
<details>
<summary>摘要</summary>
我们提出了一个框架，用于基于说话人的话语生成适当的面部响应。给定输入词语讲解和时间戳，我们的方法通过自动递归预测一个听众的响应：一个序列化的听众面部姿势，使用VQ-VAE进行量化。由于姿势是语言成分，我们提议对量化的原子运动元素视为额外的语言标记输入，并将其传递给基于转换器的大语言模型进行处理。初始化我们的转换器使用已经预训练的语言模型的权重，比训练从零开始的转换器更有显著的质量提升。我们表示我们生成的听众动作是流畅的，并具有语言 semantics 的表达。在我们的评估中，我们分析了模型对说话文本的时间和 semantics 方面的使用。项目页面：https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Shadow-Mapping-for-Efficient-Inverse-Graphics"><a href="#Differentiable-Shadow-Mapping-for-Efficient-Inverse-Graphics" class="headerlink" title="Differentiable Shadow Mapping for Efficient Inverse Graphics"></a>Differentiable Shadow Mapping for Efficient Inverse Graphics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10896">http://arxiv.org/abs/2308.10896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mworchel/differentiable-shadow-mapping">https://github.com/mworchel/differentiable-shadow-mapping</a></li>
<li>paper_authors: Markus Worchel, Marc Alexa</li>
<li>for: 该论文主要研究如何高效地生成triangle mesh中的阴影。</li>
<li>methods: 该论文提出了一种将预filtered shadow mapping技术与现有的可导着色器结合使用，以实现 triangle mesh中的可导visibility信息。</li>
<li>results: 研究发现，使用可导阴影图可以与不同的 inverse graphics problems 比较快速，并且与不同的灯光传输模拟相比，可以达到类似的准确性水平，而不同的可导着色器无法收敛。<details>
<summary>Abstract</summary>
We show how shadows can be efficiently generated in differentiable rendering of triangle meshes. Our central observation is that pre-filtered shadow mapping, a technique for approximating shadows based on rendering from the perspective of a light, can be combined with existing differentiable rasterizers to yield differentiable visibility information. We demonstrate at several inverse graphics problems that differentiable shadow maps are orders of magnitude faster than differentiable light transport simulation with similar accuracy -- while differentiable rasterization without shadows often fails to converge.
</details>
<details>
<summary>摘要</summary>
我们显示了如何有效地生成阴影在分割形状的几何 Rendering 中。我们的中心观察是可以将阴影预filtering，一种基于灯光的见识测试，与现有的可微化矿物 Rendering 结合，以获得可微化可视性信息。我们在一些逆图学问题中展示了这种方法比对于对称的阴影传递 Simulation 更快速，并且与不含阴影的可微化矿物 Rendering 相比，通常会出现不收敛的问题。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification"><a href="#Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification" class="headerlink" title="Unlocking Accuracy and Fairness in Differentially Private Image Classification"></a>Unlocking Accuracy and Fairness in Differentially Private Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10888">http://arxiv.org/abs/2308.10888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle</li>
<li>For: 这个研究的目的是让机器学习模型在保护敏感资料的情况下训练，以确保对敏感资料的训练不会泄露敏感信息。* Methods: 这个研究使用了差异调教（Differential Privacy）的金标准框架，以提供正式的隐私保证。* Results: 研究发现，使用预先训练的基础模型，并在这些模型上实现差异调教，可以实现与非隐私模型相似的准确性水平，甚至在资料分布shift的情况下仍能保持高度的准确性。<details>
<summary>Abstract</summary>
Privacy-preserving machine learning aims to train models on private data without leaking sensitive information. Differential privacy (DP) is considered the gold standard framework for privacy-preserving training, as it provides formal privacy guarantees. However, compared to their non-private counterparts, models trained with DP often have significantly reduced accuracy. Private classifiers are also believed to exhibit larger performance disparities across subpopulations, raising fairness concerns. The poor performance of classifiers trained with DP has prevented the widespread adoption of privacy preserving machine learning in industry. Here we show that pre-trained foundation models fine-tuned with DP can achieve similar accuracy to non-private classifiers, even in the presence of significant distribution shifts between pre-training data and downstream tasks. We achieve private accuracies within a few percent of the non-private state of the art across four datasets, including two medical imaging benchmarks. Furthermore, our private medical classifiers do not exhibit larger performance disparities across demographic groups than non-private models. This milestone to make DP training a practical and reliable technology has the potential to widely enable machine learning practitioners to train safely on sensitive datasets while protecting individuals' privacy.
</details>
<details>
<summary>摘要</summary>
隐私保护机器学习的目标是在使用private数据进行训练时保持敏感信息的隐私。不同于其非私有对应的模型，模型通过隐私保护（DP）训练的准确率通常会下降 significatively。此外，private分类器可能会在不同的人口群体之间存在更大的性别差异，引发公平性的问题。由于DP训练的模型性能较差，因此在实业中广泛采用隐私保护机器学习的应用仍然受限。在这篇文章中，我们表明了基于预先训练的基础模型，通过DP进行细化训练可以达到与非私有模型相同的准确率，即使在数据分布变化较大的情况下。我们在四个数据集上达到了与非私有状态的准确率，包括两个医疗影像标准 benchmark。此外，我们的私有医疗分类器不会在不同的人口群体中存在更大的性别差异，与非私有模型相比。这一突破可能使DP训练成为实用和可靠的技术，使机器学习实践者可以在敏感数据上进行安全的训练，同时保护个人隐私。
</details></li>
</ul>
<hr>
<h2 id="Vision-Transformer-Pruning-Via-Matrix-Decomposition"><a href="#Vision-Transformer-Pruning-Via-Matrix-Decomposition" class="headerlink" title="Vision Transformer Pruning Via Matrix Decomposition"></a>Vision Transformer Pruning Via Matrix Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10839">http://arxiv.org/abs/2308.10839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyi Sun</li>
<li>for: 降低存储、运行时内存和计算需求</li>
<li>methods: 使用矩阵分解方法（包括各种QR分解和LU分解）来降低矩阵维度和复杂度</li>
<li>results: 结果表明使用Singular Value Decomposition方法可以保持重要特征的生成，同时降低存储、运行时内存和计算需求。<details>
<summary>Abstract</summary>
This is a further development of Vision Transformer Pruning via matrix decomposition. The purpose of the Vision Transformer Pruning is to prune the dimension of the linear projection of the dataset by learning their associated importance score in order to reduce the storage, run-time memory, and computational demands. In this paper we further reduce dimension and complexity of the linear projection by implementing and comparing several matrix decomposition methods while preserving the generated important features. We end up selected the Singular Value Decomposition as the method to achieve our goal by comparing the original accuracy scores in the original Github repository and the accuracy scores of using those matrix decomposition methods, including Singular Value Decomposition, four versions of QR Decomposition, and LU factorization.
</details>
<details>
<summary>摘要</summary>
这是vision transformer减少的进一步发展，通过矩阵分解来减少数据集的维度。vision transformer减少的目的是学习数据集中每个特征的重要性分数，以降低存储、运行内存和计算成本。在这篇论文中，我们进一步减少了矩阵 projection 的维度和复杂性，并比较了多种矩阵分解方法，包括四种QR分解版本和LU分解。最终，我们选择了单值分解来实现我们的目标，并比较了原始数据集的准确率和使用这些矩阵分解方法得到的准确率。
</details></li>
</ul>
<hr>
<h2 id="EigenPlaces-Training-Viewpoint-Robust-Models-for-Visual-Place-Recognition"><a href="#EigenPlaces-Training-Viewpoint-Robust-Models-for-Visual-Place-Recognition" class="headerlink" title="EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition"></a>EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10832">http://arxiv.org/abs/2308.10832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gmberton/eigenplaces">https://github.com/gmberton/eigenplaces</a></li>
<li>paper_authors: Gabriele Berton, Gabriele Trivigno, Barbara Caputo, Carlo Masone</li>
<li>For: The paper is written for the task of visual place recognition, specifically to improve the robustness of the model to different viewpoints.* Methods: The proposed method, called EigenPlaces, uses a new approach to train the neural network on images from different viewpoints, which embeds viewpoint robustness into the learned global descriptors. The method clusters the training data to explicitly present the model with different views of the same points of interest, without the need for extra supervision.* Results: The paper presents experiments on the most comprehensive set of datasets in literature, showing that EigenPlaces outperforms previous state-of-the-art methods on the majority of datasets, while requiring 60% less GPU memory for training and using 50% smaller descriptors.Here are the three key points in Simplified Chinese text:* For: 这篇论文是为了解决视觉地点识别任务中的视角不一致问题，以提高模型的视角Robustness。* Methods: 提议的方法是EigenPlaces，它使用了一种新的方法来在不同视角的图像上训练神经网络，从而在学习的全球描述符中嵌入视角Robustness。该方法通过对训练数据进行分组，以显式地给模型提供不同视角的同一个点的兴趣点。无需额外监督。* Results: 论文通过对Literature中最完整的数据集进行实验，发现EigenPlaces在大多数数据集上超过了之前的状态之为，而且需要60% menos的GPU内存进行训练，并使用50%更小的描述符。<details>
<summary>Abstract</summary>
Visual Place Recognition is a task that aims to predict the place of an image (called query) based solely on its visual features. This is typically done through image retrieval, where the query is matched to the most similar images from a large database of geotagged photos, using learned global descriptors. A major challenge in this task is recognizing places seen from different viewpoints. To overcome this limitation, we propose a new method, called EigenPlaces, to train our neural network on images from different point of views, which embeds viewpoint robustness into the learned global descriptors. The underlying idea is to cluster the training data so as to explicitly present the model with different views of the same points of interest. The selection of this points of interest is done without the need for extra supervision. We then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60\% less GPU memory for training and using 50\% smaller descriptors. The code and trained models for EigenPlaces are available at {\small{\url{https://github.com/gmberton/EigenPlaces}}}, while results with any other baseline can be computed with the codebase at {\small{\url{https://github.com/gmberton/auto_VPR}}}.
</details>
<details>
<summary>摘要</summary>
“视觉地标识任务的目标是根据图像（叫做查询）的视觉特征来预测图像的位置。通常通过图像检索，将查询图像与大量地标注的图像库中的最相似图像进行匹配，使用学习的全局描述符。一个主要挑战在这个任务中是识别不同视点下的地标。为解决这个限制，我们提出了一新的方法，叫做EigenPlaces，通过在不同视点下训练神经网络，将视点强度嵌入到学习的全局描述符中。这个思想是将训练数据集分为不同视点下的部分，以便显式地将模型暴露给不同视点下的同一个点感兴趣。无需额外监督，我们选择了这些点感兴趣。我们then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60% less GPU memory for training and using 50% smaller descriptors. The code and trained models for EigenPlaces are available at [https://github.com/gmberton/EigenPlaces](https://github.com/gmberton/EigenPlaces), while results with any other baseline can be computed with the codebase at [https://github.com/gmberton/auto_VPR](https://github.com/gmberton/auto_VPR).”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction"><a href="#Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction" class="headerlink" title="Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction"></a>Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10820">http://arxiv.org/abs/2308.10820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miaoyu Li, Ying Fu, Ji Liu, Yulun Zhang</li>
<li>for: 本文提出了一种基于深度 unfolding 框架的高spectral像素 (HSI) 重建方法，以解决现有方法尚未能充分匹配 HSI 数据的问题。</li>
<li>methods: 本文使用了一种拥有 pixele adaptive descent 步长的数据模块，并引入了 Non-local Spectral Transformer (NST) 来强调 HSI 的3D特性。另外，通过 Fast Fourier Transform (FFT) 改进了不同阶段和层次的特征表达，以解决不同阶段和层次之间的交互问题。</li>
<li>results: 实验结果表明， compared to 现有 HSI 重建方法，本文提出的方法在 simulated 和实际场景中具有更高的重建性能。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/MyuLi/PADUT">https://github.com/MyuLi/PADUT</a> 上下载。<details>
<summary>Abstract</summary>
Hyperspectral Image (HSI) reconstruction has made gratifying progress with the deep unfolding framework by formulating the problem into a data module and a prior module. Nevertheless, existing methods still face the problem of insufficient matching with HSI data. The issues lie in three aspects: 1) fixed gradient descent step in the data module while the degradation of HSI is agnostic in the pixel-level. 2) inadequate prior module for 3D HSI cube. 3) stage interaction ignoring the differences in features at different stages. To address these issues, in this work, we propose a Pixel Adaptive Deep Unfolding Transformer (PADUT) for HSI reconstruction. In the data module, a pixel adaptive descent step is employed to focus on pixel-level agnostic degradation. In the prior module, we introduce the Non-local Spectral Transformer (NST) to emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by the diverse expression of features in different stages and depths, the stage interaction is improved by the Fast Fourier Transform (FFT). Experimental results on both simulated and real scenes exhibit the superior performance of our method compared to state-of-the-art HSI reconstruction methods. The code is released at: https://github.com/MyuLi/PADUT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Fixed gradient descent step in the data module while the degradation of HSI is agnostic in the pixel level.2. Inadequate prior module for 3D HSI cube.3. Stage interaction ignoring the differences in features at different stages.To address these issues, we propose a Pixel Adaptive Deep Unfolding Transformer (PADUT) for HSI reconstruction. In the data module, we employ a pixel adaptive descent step to focus on pixel-level agnostic degradation. In the prior module, we introduce the Non-local Spectral Transformer (NST) to emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by the diverse expression of features in different stages and depths, we improve the stage interaction by the Fast Fourier Transform (FFT).Experimental results on both simulated and real scenes demonstrate the superior performance of our method compared to state-of-the-art HSI reconstruction methods. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/MyuLi/PADUT">https://github.com/MyuLi/PADUT</a>.</details></li>
</ol>
<hr>
<h2 id="Jumping-through-Local-Minima-Quantization-in-the-Loss-Landscape-of-Vision-Transformers"><a href="#Jumping-through-Local-Minima-Quantization-in-the-Loss-Landscape-of-Vision-Transformers" class="headerlink" title="Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers"></a>Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10814">http://arxiv.org/abs/2308.10814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Natalia Frumkin, Dibakar Gope, Diana Marculescu</li>
<li>for: 提高量化神经网络的精度和效率</li>
<li>methods: 使用进化搜索和infoNCE损失函数 traverse非线性测试损失 landscape</li>
<li>results: 在不同量化级别（3-bit、4-bit、8-bit）下，提高全量化ViT-Base的top-1准确率，并在极端量化场景下保持稳定性和可靠性<details>
<summary>Abstract</summary>
Quantization scale and bit-width are the most important parameters when considering how to quantize a neural network. Prior work focuses on optimizing quantization scales in a global manner through gradient methods (gradient descent \& Hessian analysis). Yet, when applying perturbations to quantization scales, we observe a very jagged, highly non-smooth test loss landscape. In fact, small perturbations in quantization scale can greatly affect accuracy, yielding a $0.5-0.8\%$ accuracy boost in 4-bit quantized vision transformers (ViTs). In this regime, gradient methods break down, since they cannot reliably reach local minima. In our work, dubbed Evol-Q, we use evolutionary search to effectively traverse the non-smooth landscape. Additionally, we propose using an infoNCE loss, which not only helps combat overfitting on the small calibration dataset ($1,000$ images) but also makes traversing such a highly non-smooth surface easier. Evol-Q improves the top-1 accuracy of a fully quantized ViT-Base by $10.30\%$, $0.78\%$, and $0.15\%$ for $3$-bit, $4$-bit, and $8$-bit weight quantization levels. Extensive experiments on a variety of CNN and ViT architectures further demonstrate its robustness in extreme quantization scenarios. Our code is available at https://github.com/enyac-group/evol-q
</details>
<details>
<summary>摘要</summary>
《量化缩放和位宽是神经网络量化时的关键参数。先前的工作通过梯度方法优化量化缩放，但当应用扰动时，我们发现测试损失 landscape 非常峰峦，高度不平。事实上，小于扰动量化缩放可以大幅提高准确性，达到 $0.5-0.8\%$ 的准确率提升。在这种情况下，梯度方法失效，因为它们无法可靠地到达地方最优点。在我们的工作中，称为 Evol-Q，我们使用进化搜索来有效地探索非平坦的表面。此外，我们也提议使用 infoNCE 损失函数，它不仅能够降低在小训练集（1,000 张图像）中的溢出问题，而且使探索非平坦表面更加容易。 Evol-Q 在完全量化 ViT-Base 上提高了 top-1 准确率，分别为 $10.30\%$, $0.78\%$, $0.15\%$  для $3$-bit、$4$-bit 和 $8$-bit 量化 веса级别。我们还进行了对多种 CNN 和 ViT 架构的广泛实验，以证明它的稳定性在极端量化场景下。我们的代码可以在 https://github.com/enyac-group/evol-q 上获取。》
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/cs.CV_2023_08_22/" data-id="clltau91y003ccr88g86232bb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.LG_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.LG_2023_08_22/">cs.LG - 2023-08-22 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks"><a href="#A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks" class="headerlink" title="A free from local minima algorithm for training regressive MLP neural networks"></a>A free from local minima algorithm for training regressive MLP neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11532">http://arxiv.org/abs/2308.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Augusto Montisci</li>
<li>for: 这篇论文旨在提出一种不受地方最小值的多层感知网络训练方法。</li>
<li>methods: 该方法基于训练集分布的特性，通过内部图像来避免地方最小值问题。</li>
<li>results: 研究表明，该方法可以减少地方最小值问题，并且在知名的测试集上达到了良好的性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
In this article an innovative method for training regressive MLP networks is presented, which is not subject to local minima. The Error-Back-Propagation algorithm, proposed by William-Hinton-Rummelhart, has had the merit of favouring the development of machine learning techniques, which has permeated every branch of research and technology since the mid-1980s. This extraordinary success is largely due to the black-box approach, but this same factor was also seen as a limitation, as soon more challenging problems were approached. One of the most critical aspects of the training algorithms was that of local minima of the loss function, typically the mean squared error of the output on the training set. In fact, as the most popular training algorithms are driven by the derivatives of the loss function, there is no possibility to evaluate if a reached minimum is local or global. The algorithm presented in this paper avoids the problem of local minima, as the training is based on the properties of the distribution of the training set, or better on its image internal to the neural network. The performance of the algorithm is shown for a well-known benchmark.
</details>
<details>
<summary>摘要</summary>
在本文中，一种创新的多层感知网络训练方法被介绍，不受局部最小点的限制。欧文-希金特-吕姆哈特提出的错误反传播算法，在1980年代中期以来，对机器学习技术的发展做出了重要贡献，这种成功是由黑盒方法引起的，但同时也被认为是局限性的因素。当面临更复杂的问题时，最 kritical的训练算法问题是搜索函数的局部最小点，通常是训练集的平均方差。因为现有最popular的训练算法都是根据损失函数的导数进行驱动，因此无法确定是否到达了局部最小点或全局最小点。本文中提出的算法解决了局部最小点问题，基于训练集的分布性质或更好地说是其内部图像。文章中展示了一个知名的标准 bencmark 的性能。
</details></li>
</ul>
<hr>
<h2 id="ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm"><a href="#ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm" class="headerlink" title="ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm"></a>ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11522">http://arxiv.org/abs/2308.11522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Kantic, Fabian C. Legl, Walter Stechele, Jakob Hermann</li>
<li>for: 这个论文目的是提出一种基于细胞自动机模型的泵Computing优化算法，用于处理时间序列应用。</li>
<li>methods: 该算法不仅选择模型的超参数，而且解决了线性细胞自动机规则选择的开放问题。选择方法可以从无限增长的规则空间中预选出一些有潜力的规则。</li>
<li>results: 应用于相关的参考数据集时，选择的规则可以实现低的错误率，其中最佳规则位于总规则空间的前5%。该算法基于细胞自动机属性的数学分析，通过约一百万个实验，计算时间约为一年。与其他现状最佳时间序列模型比较，提出的泵Computing使用细胞自动机模型具有较低的计算复杂度，同时实现较低的错误率。因此，我们的方法可以减少训练和超参数优化所需的时间，达到数量级减少。<details>
<summary>Abstract</summary>
In this paper, we present a novel algorithm to optimize the design of Reservoir Computing using Cellular Automata models for time series applications. Besides selecting the models' hyperparameters, the proposed algorithm particularly solves the open problem of linear Cellular Automaton rule selection. The selection method pre-selects only a few promising candidate rules out of an exponentially growing rule space. When applied to relevant benchmark datasets, the selected rules achieve low errors, with the best rules being among the top 5% of the overall rule space. The algorithm was developed based on mathematical analysis of linear Cellular Automaton properties and is backed by almost one million experiments, adding up to a computational runtime of nearly one year. Comparisons to other state-of-the-art time series models show that the proposed Reservoir Computing using Cellular Automata models have lower computational complexity, at the same time, achieve lower errors. Hence, our approach reduces the time needed for training and hyperparameter optimization by up to several orders of magnitude.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的算法优化储池计算机using Cellular Automata模型 для时间序列应用。除了选择模型的超参数之外，提出的算法特别解决了开放问题，即选择线性Cellular Automaton规则。选择方法先选择了一些有前途的候选规则，从急增的规则空间中选择出来。当应用到相关的标准数据集时，选择的规则都达到了低错误率，最好的规则在总规则空间中排名前5%。算法基于Cellular Automata模型的数学分析和大约一百万个实验，计算时间约为一年。与其他当前最佳时间序列模型进行比较，我们的方法具有较低的计算复杂度，同时实现了较低的错误率。因此，我们的方法可以减少训练和超参数优化所需的时间，可能是数量级减少。
</details></li>
</ul>
<hr>
<h2 id="EM-for-Mixture-of-Linear-Regression-with-Clustered-Data"><a href="#EM-for-Mixture-of-Linear-Regression-with-Clustered-Data" class="headerlink" title="EM for Mixture of Linear Regression with Clustered Data"></a>EM for Mixture of Linear Regression with Clustered Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11518">http://arxiv.org/abs/2308.11518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Reisizadeh, Khashayar Gatmiry, Asuman Ozdaglar</li>
<li>for: 这篇论文是为了提高分布式学习中数据不同性的问题。</li>
<li>methods: 这篇论文使用了Expectation-Maximization（EM）方法来估计两组线性回归问题的最佳参数。</li>
<li>results: 论文显示，如果初始化得当，EM在结构化数据上只需要O(1)迭代iterations来达到同样的统计精度，provided that m grows as e^(o(n))。<details>
<summary>Abstract</summary>
Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ batches of dependent samples each containing $n$ measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\log(mn/d))$ iterations to reach the statistical accuracy of $O(\sqrt{d/(mn)})$. In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as $m$ grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest.
</details>
<details>
<summary>摘要</summary>
现代数据驱动和分布式学习框架面临着各种各样的大量数据，由客户端分布在不同环境中生成。实际上，数据异ogeneity是规模化多个分布式学习模式的主要瓶颈。然而，在许多应用程序中，客户端生成的数据可能会组成带有共同结构的分布，如联邦学习中，所有样本的共同隐变量控制所有样本的分布。因此，可以问到如何利用分布式数据中的下层结构来改进学习方案。在这篇论文中，我们解决这个问题，在特定的两个分布线性回归问题中。我们使用已知的期望-最大化（EM）方法来估算最大有可能性参数，从$m$个批处理中获取$n$个测量结果。不考虑分布式数据中的带有共同结构的混合模型，EM在$O(\log(mn/d))$迭代中可以达到同等的统计准确性，其中$d$是维度，$m$是节点数，$n$是测量结果数。然而，我们证明，如果初始化得当，EM在结构化数据上只需要$O(1)$迭代来达到同等的统计准确性，只要$m$在$e^{o(n)}$中增长。我们的分析提出和组合了新的极限优化和通用验证保证，可能是独立有价值的。
</details></li>
</ul>
<hr>
<h2 id="TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows"><a href="#TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows" class="headerlink" title="TrackFlow: Multi-Object Tracking with Normalizing Flows"></a>TrackFlow: Multi-Object Tracking with Normalizing Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11513">http://arxiv.org/abs/2308.11513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianluca Mancusi, Aniello Panariello, Angelo Porrello, Matteo Fabbri, Simone Calderara, Rita Cucchiara</li>
<li>for: 提高多对目标跟踪的性能，特别是在多模态场景下。</li>
<li>methods: 基于深度概率分布模型，计算候选关联的成本为负极log值，以提高跟踪检测算法的性能。</li>
<li>results: 对多种跟踪检测算法进行实验，显示我们的方法可以一致提高其性能。<details>
<summary>Abstract</summary>
The field of multi-object tracking has recently seen a renewed interest in the good old schema of tracking-by-detection, as its simplicity and strong priors spare it from the complex design and painful babysitting of tracking-by-attention approaches. In view of this, we aim at extending tracking-by-detection to multi-modal settings, where a comprehensive cost has to be computed from heterogeneous information e.g., 2D motion cues, visual appearance, and pose estimates. More precisely, we follow a case study where a rough estimate of 3D information is also available and must be merged with other traditional metrics (e.g., the IoU). To achieve that, recent approaches resort to either simple rules or complex heuristics to balance the contribution of each cost. However, i) they require careful tuning of tailored hyperparameters on a hold-out set, and ii) they imply these costs to be independent, which does not hold in reality. We address these issues by building upon an elegant probabilistic formulation, which considers the cost of a candidate association as the negative log-likelihood yielded by a deep density estimator, trained to model the conditional joint probability distribution of correct associations. Our experiments, conducted on both simulated and real benchmarks, show that our approach consistently enhances the performance of several tracking-by-detection algorithms.
</details>
<details>
<summary>摘要</summary>
“multi-object tracking领域最近又重新启发了使用检测方法的古老schema，因为它的简单性和强有力的假设，使其不需要复杂的设计和痛苦的照顾，相比之下，tracking-by-attention方法更加复杂。在视野内，我们想扩展tracking-by-detection到多modal设置，在其中需要从多种不同的信息（例如2D运动cue、视觉外观和姿态估计）计算全面的成本。更准确地说，我们采用了一个实际案例，其中有一个粗略的3D信息估计也可以与传统的metric（例如IoU）一起使用。为了实现这一点，现有的方法通常采用简单的规则或复杂的规则来均衡每个成本的贡献。然而，这些方法有以下两个问题：一是需要精心调整特定的超参数，二是它们假设成本是独立的，这并不符合实际情况。我们解决这些问题 by 建立在一种简洁的概率形式上，即使用深度概率分布来模型correct association的 conditional joint probability distribution。我们的实验在模拟和实际 benchmark上展示了我们的方法可以不断提高多个tracking-by-detection算法的性能。”
</details></li>
</ul>
<hr>
<h2 id="Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models"><a href="#Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models" class="headerlink" title="Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models"></a>Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11511">http://arxiv.org/abs/2308.11511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrián Csiszárik, Melinda F. Kiss, Péter Kőrösi-Szabó, Márton Muntag, Gergely Papp, Dániel Varga</li>
<li>for: 本文研究了两个嵌入型神经网络参数 вектора $\Theta_A$ 和 $\Theta_B$ 的元素wise convex combination，以探索这些模型组合的可行性和特性。</li>
<li>methods: 作者采用了大量的实验，对不同的模型组合 parametrized by $[0,1]^d$ 的元素进行了探索，发现了广泛的超平面存在低损值，这表明了线性模式连接的概念扩展到一般情况，称为模式可 conjugacy。</li>
<li>results: 作者发现了一些新的线性模式连接和模型重新定位的观察结果，包括模型重新定位的转移性和稳定性，以及模型组合的功能和权重相似性。<details>
<summary>Abstract</summary>
We explore element-wise convex combinations of two permutation-aligned neural network parameter vectors $\Theta_A$ and $\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are non-vacuous in the sense that there are significant functional differences between the resulting models.
</details>
<details>
<summary>摘要</summary>
我们探索两个 permutation-aligned 神经网络参数 вектор $\Theta_A$ 和 $\Theta_B$ 的元素层次 convex 组合。我们进行了广泛的实验，检查了不同的模型组合参数化的元素随机分布在 $[0,1]^d$ 和其邻近区域，我们的发现表明，广泛的区域在卷积体中形成低损值表面，这表明了线性模式连接的概念扩展到一般现象，我们称之为模式可组合性。我们还做了一些新的观察，包括线性模式连接和模型重定向。我们证明了两个模型重定向到共同的第三模型时，也是线性模式连接的，并且在神经元匹配的干扰下，得到的组合仍然可以形成一个工作模型。此外，我们分析了模型组合的功能和权重相似性，并证明了这些组合不是空的，即存在 significativ functional differences  между得到的模型。
</details></li>
</ul>
<hr>
<h2 id="Can-Authorship-Representation-Learning-Capture-Stylistic-Features"><a href="#Can-Authorship-Representation-Learning-Capture-Stylistic-Features" class="headerlink" title="Can Authorship Representation Learning Capture Stylistic Features?"></a>Can Authorship Representation Learning Capture Stylistic Features?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11490">http://arxiv.org/abs/2308.11490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/llnl/luar">https://github.com/llnl/luar</a></li>
<li>paper_authors: Andrew Wang, Cristina Aggazzotti, Rebecca Kotula, Rafael Rivera Soto, Marcus Bishop, Nicholas Andrews</li>
<li>for: 这篇论文主要是为了研究如何自动分离作者的风格和内容。</li>
<li>methods: 这篇论文使用了数据驱动的方法来学习作者表示，并通过一系列定制的实验来评估这些表示是否能够捕捉作者的风格。</li>
<li>results: 研究发现，这些表示确实受到作者的风格影响，并且可能对于某些类型的数据变换（如时间上的话题变化）具有一定的Robustness。这些结果可能对于应用于风格转换等下渠应用有所帮助。<details>
<summary>Abstract</summary>
Automatically disentangling an author's style from the content of their writing is a longstanding and possibly insurmountable problem in computational linguistics. At the same time, the availability of large text corpora furnished with author labels has recently enabled learning authorship representations in a purely data-driven manner for authorship attribution, a task that ostensibly depends to a greater extent on encoding writing style than encoding content. However, success on this surrogate task does not ensure that such representations capture writing style since authorship could also be correlated with other latent variables, such as topic. In an effort to better understand the nature of the information these representations convey, and specifically to validate the hypothesis that they chiefly encode writing style, we systematically probe these representations through a series of targeted experiments. The results of these experiments suggest that representations learned for the surrogate authorship prediction task are indeed sensitive to writing style. As a consequence, authorship representations may be expected to be robust to certain kinds of data shift, such as topic drift over time. Additionally, our findings may open the door to downstream applications that require stylistic representations, such as style transfer.
</details>
<details>
<summary>摘要</summary>
自动分离作者的风格从他们的写作内容是计算语言学领域的长期问题。同时，Recently有大量的文本 corpus 提供了作者标签，使得可以通过数据驱动方式学习作者表示。然而，这种表示是否真的捕捉了作者的风格呢？我们通过系统的实验来彻底检验这些表示是否具有风格特征。结果表明，这些表示对作者预测任务有高度敏感性，表明它们主要捕捉了作者的风格。这意味着作者表示可能对某些类型的数据变换具有较高的Robustness，例如在时间上的话题变化。此外，我们的发现可能开启了在下游应用中使用风格表示的可能性，如样式转移。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions"><a href="#Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions" class="headerlink" title="Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions"></a>Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11483">http://arxiv.org/abs/2308.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pouya Pezeshkpour, Estevam Hruschka</li>
<li>for:  investigate the sensitivity of large language models (LLMs) towards the order of options in multiple-choice questions, and to understand the underlying reasons for this sensitivity.</li>
<li>methods:  the authors use various benchmarks and experiments to study the performance of LLMs on multiple-choice questions, and they adopt two approaches to calibrate the models’ predictions.</li>
<li>results:  the authors find a significant performance gap of approximately 13% to 75% in LLMs on different benchmarks when answer options are reordered, and they identify patterns in top-2 choices that amplify or mitigate the model’s bias toward option placement. Additionally, they show that calibrating the models’ predictions can improve their performance by up to 8 percentage points across different models and benchmarks.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在不同的自然语言处理任务中表现出了很好的能力。然而，之前的研究表明这些模型对示例语言和示例的顺序有敏感性，这会带来评估这些模型的困难。随着这些模型的力量的提高，我们需要更好地理解和解决这些局限性。在这篇论文中，我们关注LLM在多选题上的Robustness——一个常用的任务来评估这些模型的理解和知识检索能力。我们发现，当选项的顺序变化时，LLM的表现会受到较大的影响，在不同的benchmark上，表现差距可达13%到75%，即使使用几个示例。通过详细分析，我们推断这种敏感性是由于LLM在前两选项之间的uncertainty，specific option placement可能会对certain prediction between those top choices产生影响，这是因为位置偏好。我们还发现了在top-2选项之间的抗抑补偏好和增强偏好的模式。对于增强偏好，我们发现可以将top two选项放在第一和最后的位置。相反，为了减轻偏好，我们建议将这些选项放在相邻的位置。为了证明我们的推断，我们进行了多种实验和采用了两种方法来调整LLM的预测，导致在不同的模型和benchmark上的改进率达到8%。
</details></li>
</ul>
<hr>
<h2 id="Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection"><a href="#Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection" class="headerlink" title="Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection"></a>Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11480">http://arxiv.org/abs/2308.11480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/servicenow/broad-openood">https://github.com/servicenow/broad-openood</a></li>
<li>paper_authors: Charles Guille-Escuret, Pierre-André Noël, Ioannis Mitliagkas, David Vazquez, Joao Monteiro</li>
<li>for: 本研究旨在提高部署在机器学习系统上的可靠性，通过开发检测异常输入（Out-of-distribution，OOD）方法。</li>
<li>methods: 我们分类了五种不同类型的分布偏移，并评估了最新的OOD检测方法在每种分布偏移下的表现。</li>
<li>results: 我们发现，现有方法可以很好地检测未知类别的异常输入，但它们在其他类型的分布偏移下表现不一致。即，它们只可以可靠地检测它们已经特定地设计来预期的异常输入。我们通过学习现有检测分数的生成模型，提出了一种ensemble方法，可以为广泛的OOD检测提供一种更加一致和全面的解决方案，并证明其性能比现有方法更高。<details>
<summary>Abstract</summary>
Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expect. As a first step toward broad OOD detection, we learn a generative model of existing detection scores with a Gaussian mixture. By doing so, we present an ensemble approach that offers a more consistent and comprehensive solution for broad OOD detection, demonstrating superior performance compared to existing methods. Our code to download BROAD and reproduce our experiments is publicly available.
</details>
<details>
<summary>摘要</summary>
增强已部署的机器学习系统的可靠性通常需要开发检测异常输入（OOD）的方法。然而，现有研究通常只关注未在训练集中出现的样本，忽略其他类型的可能的分布Shift。这种限制使得这些方法在实际应用中的可用性受到限制，因为系统会遇到各种异常输入。在本研究中，我们将五种不同类型的分布Shift分类，并且严格评估最近的OOD检测方法在每一类中的性能。我们将这些数据集公开发布，名为BROAD（Benchmarking Resilience Over Anomaly Diversity）。我们的发现表明，虽然这些方法可以很好地检测未知的类别，但是它们在其他类型的分布Shift下的性能不一致。即它们只能可靠地检测它们已经特定地设计来预期的异常输入。作为广泛OOD检测的第一步，我们学习了现有检测分数的生成模型，使用高斯混合模型。通过这种ensemble方法，我们提供了一种更加一致和全面的广泛OOD检测解决方案，并且在与现有方法进行比较时表现出了superior的性能。我们在下载BROAD和复现我们的实验的代码是公开可用的。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-column-generation-based-matheuristic-for-learning-classification-trees"><a href="#Revisiting-column-generation-based-matheuristic-for-learning-classification-trees" class="headerlink" title="Revisiting column-generation-based matheuristic for learning classification trees"></a>Revisiting column-generation-based matheuristic for learning classification trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11477">http://arxiv.org/abs/2308.11477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krooonal/col_gen_estimator">https://github.com/krooonal/col_gen_estimator</a></li>
<li>paper_authors: Krunal Kishor Patel, Guy Desaulniers, Andrea Lodi</li>
<li>for: 提高分类问题中decision trees的准确性和可扩展性</li>
<li>methods: 使用列生成方法优化decision trees的训练</li>
<li>results: 提高了分类问题中decision trees的准确性和可扩展性，并且可以处理大型数据集<details>
<summary>Abstract</summary>
Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. \cite{firat2020column} proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their corresponding constraints. We conclude by presenting computational results that show that these modifications result in better scalability.
</details>
<details>
<summary>摘要</summary>
决策树是机器学习中高度可解释的模型，用于解决分类问题。标准的机器学习算法可以快速训练决策树，但是会生成准确性不高的树。文献中的其他离散优化模型可以解决优化问题，但只能在较小的数据集上工作。 \cite{firat2020column} 提出了一种基于列生成的规则方法来学习决策树。这种方法可以扩展到大型数据集。在这篇论文中，我们介绍了对这种列生成方法的改进。首先，我们修改了多类分类实例中的子问题模型，以Significantly reduce the number of subproblems。然后，我们显示了数据依赖的约束在主问题中被含有，并使用它们作为裁剪平面。此外，我们描述了一种分离模型，用于生成具有Linear programming relaxation solution违反其相应约束的数据点。我们 conclude by presenting computational results that show that these modifications result in better scalability。
</details></li>
</ul>
<hr>
<h2 id="Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning"><a href="#Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning" class="headerlink" title="Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"></a>Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11464">http://arxiv.org/abs/2308.11464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Hin Chan, Rui Zhou, Running Zhao, Zhihan Jiang, Edith C. -H. Ngai</li>
<li>for: 提高实际场景中 Federated Learning（FL）系统的兼容性和灵活性。</li>
<li>methods: 提出一种基于内部相似层次梯度的聚合方法，可以增强深层模型之间的相似性，无需更多的客户端之间的交流。</li>
<li>results: 经验证明，该方法可以提高FL系统的性能，并且可以跨种模型进行扩展。<details>
<summary>Abstract</summary>
Federated learning (FL) inevitably confronts the challenge of system heterogeneity in practical scenarios. To enhance the capabilities of most model-homogeneous FL methods in handling system heterogeneity, we propose a training scheme that can extend their capabilities to cope with this challenge. In this paper, we commence our study with a detailed exploration of homogeneous and heterogeneous FL settings and discover three key observations: (1) a positive correlation between client performance and layer similarities, (2) higher similarities in the shallow layers in contrast to the deep layers, and (3) the smoother gradients distributions indicate the higher layer similarities. Building upon these observations, we propose InCo Aggregation that leverags internal cross-layer gradients, a mixture of gradients from shallow and deep layers within a server model, to augment the similarity in the deep layers without requiring additional communication between clients. Furthermore, our methods can be tailored to accommodate model-homogeneous FL methods such as FedAvg, FedProx, FedNova, Scaffold, and MOON, to expand their capabilities to handle the system heterogeneity. Copious experimental results validate the effectiveness of InCo Aggregation, spotlighting internal cross-layer gradients as a promising avenue to enhance the performance in heterogenous FL.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在实际应用中会面临系统不同性的挑战。为了增强大多数模型同质FL方法的处理能力，我们提出了一个训练方案，可以将其扩展到处理这个挑战。在这篇论文中，我们开始我们的研究，进行了详细的探索同质和不同质FL环境，发现了三个关键观察结果：（1）客户端性能与层 Similarity 之间存在正相关，（2）在浅层比深层更高的 Similarity，（3）更平滑的梯度分布显示了更高的层 Similarity。基于这些观察结果，我们提出了内部混合层梯度（InCo Aggregation），利用服务器模型内部的混合梯度，以增强深层层 Similarity 而无需更多的客户端通信。此外，我们的方法可以与模型同质FL方法，如FedAvg、FedProx、FedNova、Scaffold和MOON，整合，扩展其处理能力，处理不同系统的挑战。丰富的实验结果证明了InCo Aggregation 的效果，显示了内部混合层梯度作为提高hetrogenous FL性能的有前途之路。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning"><a href="#An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning" class="headerlink" title="An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning"></a>An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11677">http://arxiv.org/abs/2308.11677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grégoire Petit, Michael Soumm, Eva Feillet, Adrian Popescu, Bertrand Delezoide, David Picard, Céline Hudelot</li>
<li>for: 本研究的目的是研究分类模型在数据流中建立和维护的问题，具体来说是在不能保留过去类的情况下，通过累积学习来逐步增加新类。</li>
<li>methods: 本研究使用了累积学习的增量学习策略，并对不同的策略、神经网络架构、目标任务、类别分布和数据量进行了广泛的实验研究。</li>
<li>results: 研究发现，初始训练策略是增量性能的主要影响因素，但是选择适合的增量学习算法更重要地防止忘记。基于这些分析结果，提出了实践中增量学习的实用建议。<details>
<summary>Abstract</summary>
Class-Incremental Learning (CIL) aims to build classification models from data streams. At each step of the CIL process, new classes must be integrated into the model. Due to catastrophic forgetting, CIL is particularly challenging when examples from past classes cannot be stored, the case on which we focus here. To date, most approaches are based exclusively on the target dataset of the CIL process. However, the use of models pre-trained in a self-supervised way on large amounts of data has recently gained momentum. The initial model of the CIL process may only use the first batch of the target dataset, or also use pre-trained weights obtained on an auxiliary dataset. The choice between these two initial learning strategies can significantly influence the performance of the incremental learning model, but has not yet been studied in depth. Performance is also influenced by the choice of the CIL algorithm, the neural architecture, the nature of the target task, the distribution of classes in the stream and the number of examples available for learning. We conduct a comprehensive experimental study to assess the roles of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing the average incremental accuracy, but that the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations are intended to facilitate the practical deployment of incremental learning.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:类cremental Learning (CIL) 目标是从数据流中建立分类模型。在每个步骤中，新的类需要被添加到模型中。由于悬崖式忘记，CIL 特别在不能存储过去类例时是挑战。到目前为止，大多数方法都是专注于目标数据集。然而，使用基于大量数据的自动学习模型的预训练方法在最近几年中得到了迅速发展。CIL 过程的初始模型可以使用目标数据集的第一个批处或者使用 auxiliary 数据集上预训练的模型。这两种初始学习策略的选择会对增量性表现产生重要的影响，但是这个问题还没有得到深入的研究。增量表现的性能也受到 CIL 算法、神经网络架构、任务性质、类别分布和学习例数的影响。我们进行了全面的实验研究，以评估这些因素对增量性表现的影响。我们提供了一个统计分析框架，以量化每个因素对增量性表现的贡献。我们的主要发现是，初始训练策略是增量性表现的主导因素，但是选择 CIL 算法更重要地防止忘记。基于这种分析，我们提供了实用的初始训练策略选择指南，这些指南旨在促进实际部署增量学习。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Self-Supervised-Representation-Learning"><a href="#A-Survey-on-Self-Supervised-Representation-Learning" class="headerlink" title="A Survey on Self-Supervised Representation Learning"></a>A Survey on Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11455">http://arxiv.org/abs/2308.11455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/esvit">https://github.com/microsoft/esvit</a></li>
<li>paper_authors: Tobias Uelwer, Jan Robine, Stefan Sylvius Wagner, Marc Höftmann, Eric Upschulte, Sebastian Konietzny, Maike Behrendt, Stefan Harmeling</li>
<li>for: 本文提供了一个抽象的审视，概述了一些不需要监督学习的图像表示学习方法。</li>
<li>methods: 本文使用了一些不需要监督学习的图像表示学习方法，包括自适应 Representation Learning 方法和卷积神经网络方法。</li>
<li>results: 本文对图像表示学习方法进行了一个系统的审视，并对相关的实验结果进行了一个综合的Meta-study。<details>
<summary>Abstract</summary>
Learning meaningful representations is at the heart of many tasks in the field of modern machine learning. Recently, a lot of methods were introduced that allow learning of image representations without supervision. These representations can then be used in downstream tasks like classification or object detection. The quality of these representations is close to supervised learning, while no labeled images are needed. This survey paper provides a comprehensive review of these methods in a unified notation, points out similarities and differences of these methods, and proposes a taxonomy which sets these methods in relation to each other. Furthermore, our survey summarizes the most-recent experimental results reported in the literature in form of a meta-study. Our survey is intended as a starting point for researchers and practitioners who want to dive into the field of representation learning.
</details>
<details>
<summary>摘要</summary>
学习有意义的表示是现代机器学习领域中的核心任务之一。最近，许多没有监督的方法被引入，可以学习图像表示。这些表示可以在下游任务中使用，如分类或物体检测。这些表示质量与监督学习几乎相同，但无需标注图像。本文提供了这些方法的统一notation，指出了这些方法之间的相似性和差异，并提出了这些方法的分类方法。此外，我们的survey还summarized literaturereported最新的实验结果，以meta-study的形式。本文作为研究者和实践者入门点，准备了涉及表示学习领域的所有信息。
</details></li>
</ul>
<hr>
<h2 id="Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding"><a href="#Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding" class="headerlink" title="Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding"></a>Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11448">http://arxiv.org/abs/2308.11448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiantao Wu, Shentong Mo, Muhammad Awais, Sara Atito, Zhenhua Feng, Josef Kittler</li>
<li>for: 本研究旨在评估无监督学习（SSL）技术在计算机视觉任务中的效果，以便模拟人类对未看过的对象的总结和识别。</li>
<li>methods: 本研究使用了一种基于提示 patch的评估协议来进行零shot segmentation，以及一种内部和外部相似性评估来评估 SSL ViTs 的准确性。</li>
<li>results: 研究发现，通过提取本地特征的相似性和全局特征的准确性，可以提高 SSL ViTs 的准确性和总结能力。此外，提出了一种简单的 SSL 方法，称为 MMC，可以减少内部和外部相似性的重叠，从而实现图像中的有效对象 segmentation。<details>
<summary>Abstract</summary>
Self-supervised pretraining (SSP) has emerged as a popular technique in machine learning, enabling the extraction of meaningful feature representations without labelled data. In the realm of computer vision, pretrained vision transformers (ViTs) have played a pivotal role in advancing transfer learning. Nonetheless, the escalating cost of finetuning these large models has posed a challenge due to the explosion of model size. This study endeavours to evaluate the effectiveness of pure self-supervised learning (SSL) techniques in computer vision tasks, obviating the need for finetuning, with the intention of emulating human-like capabilities in generalisation and recognition of unseen objects. To this end, we propose an evaluation protocol for zero-shot segmentation based on a prompting patch. Given a point on the target object as a prompt, the algorithm calculates the similarity map between the selected patch and other patches, upon that, a simple thresholding is applied to segment the target. Another evaluation is intra-object and inter-object similarity to gauge discriminatory ability of SSP ViTs. Insights from zero-shot segmentation from prompting and discriminatory abilities of SSP led to the design of a simple SSP approach, termed MMC. This approaches combines Masked image modelling for encouraging similarity of local features, Momentum based self-distillation for transferring semantics from global to local features, and global Contrast for promoting semantics of global features, to enhance discriminative representations of SSP ViTs. Consequently, our proposed method significantly reduces the overlap of intra-object and inter-object similarities, thereby facilitating effective object segmentation within an image. Our experiments reveal that MMC delivers top-tier results in zero-shot semantic segmentation across various datasets.
</details>
<details>
<summary>摘要</summary>
自适应预训练（SSP）已经成为机器学习中受欢迎的技术之一，允许无需标注数据抽取有意义的特征表示。在计算机视觉领域，预训练视transformer（ViT）已经发挥了重要的作用，促进了转移学习。然而，模型的规模快速增长，使得训练这些大型模型的成本急剧增加。本研究旨在评估无标注自适应学习（SSL）技术在计算机视觉任务中的效果，不需要训练，以模仿人类的一般化和未看过物体的识别能力。为此，我们提出了一种零shot分割评估方法，基于提示 patch。给定目标对象的一点为提示，算法计算选定 patch 和其他 patches 之间的相似度图，然后应用简单的阈值分割目标。此外，我们还进行了内部和外部相似性评估，以评估 SSL ViTs 的抽象能力。基于零shot分割和抽象能力的发现，我们设计了一种简单的 SSP 方法，称为 MMC。这种方法结合了压缩图像模型，自动填充自适应特征，以及全局对比，以提高 SSL ViTs 的抽象表示能力。因此，我们的提案可以减少内部和外部相似性的重叠，从而实现图像中效果的对象分割。我们的实验表明，MMC 在多个数据集上达到了顶尖的 zero-shot semantic segmentation结果。
</details></li>
</ul>
<hr>
<h2 id="Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data"><a href="#Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data" class="headerlink" title="Exploration of Rashomon Set Assists Explanations for Medical Data"></a>Exploration of Rashomon Set Assists Explanations for Medical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11446">http://arxiv.org/abs/2308.11446</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarzyna Kobylińska, Mateusz Krzyziński, Rafał Machowicz, Mariusz Adamek, Przemysław Biecek<br>for:This paper aims to address the problem of selecting a single model that maximizes a performance metric in machine learning modeling, particularly in medical and healthcare studies where the objective is to generate valuable insights beyond predictions.methods:The proposed approach uses a novel process to explore the Rashomon set of models, which includes identifying the most different models within the set using the $\texttt{Rashomon_DETECT}$ algorithm and comparing profiles illustrating prediction dependencies on variable values generated by XAI techniques. The Profile Disparity Index (PDI) is introduced to quantify differences in variable effects among models.results:The approach is applied to predict survival among hemophagocytic lymphohistiocytosis (HLH) patients and is shown to be effective in identifying the most informative models. The approach is also benchmarked on other medical data sets, demonstrating its versatility and utility in various contexts.<details>
<summary>Abstract</summary>
The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorithm. This algorithm compares profiles illustrating prediction dependencies on variable values generated by eXplainable Artificial Intelligence (XAI) techniques. To quantify differences in variable effects among models, we introduce the Profile Disparity Index (PDI) based on measures from functional data analysis. To illustrate the effectiveness of our approach, we showcase its application in predicting survival among hemophagocytic lymphohistiocytosis (HLH) patients - a foundational case study. Additionally, we benchmark our approach on other medical data sets, demonstrating its versatility and utility in various contexts.
</details>
<details>
<summary>摘要</summary>
传统的机器学习模型选择过程是选择最大化一个选择性指标的模型。然而，这种方法会忽略一些较差的模型，尤其在医疗和健康研究中， где目标不仅是预测，还是获得有价值的发现。在一个称为“Rashomon set”的集合中，包含一些性能几乎与最佳一样的模型时，这种问题变得非常棘手。这篇论文提出了一种新的方法，以探索Rashomon set模型，从传统模型选择方法的基础上扩展。我们的核心思想是通过引入的 $\texttt{Rashomon_DETECT}$ 算法，确定Rashomon set中最为不同的模型。我们还引入了 Profile Disparity Index（PDI），以量化不同模型中变量效果的差异。我们通过使用扩展ible Artificial Intelligence（XAI）技术生成的变量值预测 Profiling，来评估模型之间的差异。我们在针对 Hemophagocytic lymphohistiocytosis（HLH）患者的存活预测中进行了应用示例，并在其他医疗数据集上进行了多种场景的比较。
</details></li>
</ul>
<hr>
<h2 id="Inferring-gender-from-name-a-large-scale-performance-evaluation-study"><a href="#Inferring-gender-from-name-a-large-scale-performance-evaluation-study" class="headerlink" title="Inferring gender from name: a large scale performance evaluation study"></a>Inferring gender from name: a large scale performance evaluation study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12381">http://arxiv.org/abs/2308.12381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kriste Krstovski, Yao Lu, Ye Xu</li>
<li>for: 本研究旨在评估现有名字到性别推断的方法的性能，以及提出新的混合方法以提高性别推断的准确性。</li>
<li>methods: 本研究使用了多个现有的名字推断算法和软件产品，并对其进行大规模的性能评估。同时，我们还提出了两种新的混合方法，以提高性别推断的准确性。</li>
<li>results: 研究结果显示，现有的名字推断方法在不同的数据集上的性能差异较大。此外，我们还发现了一些新的混合方法，可以提高性别推断的准确性。<details>
<summary>Abstract</summary>
A person's gender is a crucial piece of information when performing research across a wide range of scientific disciplines, such as medicine, sociology, political science, and economics, to name a few. However, in increasing instances, especially given the proliferation of big data, gender information is not readily available. In such cases researchers need to infer gender from readily available information, primarily from persons' names. While inferring gender from name may raise some ethical questions, the lack of viable alternatives means that researchers have to resort to such approaches when the goal justifies the means - in the majority of such studies the goal is to examine patterns and determinants of gender disparities. The necessity of name-to-gender inference has generated an ever-growing domain of algorithmic approaches and software products. These approaches have been used throughout the world in academia, industry, governmental and non-governmental organizations. Nevertheless, the existing approaches have yet to be systematically evaluated and compared, making it challenging to determine the optimal approach for future research. In this work, we conducted a large scale performance evaluation of existing approaches for name-to-gender inference. Analysis are performed using a variety of large annotated datasets of names. We further propose two new hybrid approaches that achieve better performance than any single existing approach.
</details>
<details>
<summary>摘要</summary>
人的性别信息是科学研究的重要参数，广泛应用于医学、社会学、政治科学和经济等多个领域。然而，随着大数据的普及， gender信息越来越难以获得。在这些情况下，研究人员需要从可用的信息中推断性别，主要来自人名。虽然这可能会提出一些伦理问题，但由于没有可靠的替代方案，研究人员需要采用这种方法，以达到研究目标。由于这种方法在全球各地的学术机构、产业、政府和非政府组织中都有广泛应用，因此需要系统地评估和比较现有的方法，以确定未来研究中最佳的方法。在这项工作中，我们进行了大规模性能评估现有的名称到性别推断方法。我们使用了多个大型注释的名称集来进行分析，并提出了两种新的混合方法，其性能比任何单独的现有方法更高。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework"><a href="#A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework" class="headerlink" title="A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework"></a>A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11676">http://arxiv.org/abs/2308.11676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghe Zhao, Shuai Fu, Huiyan Sun</li>
<li>for: 这个论文的主要目标是解释 causal inference 中 confounding 问题的几种方法，以及这些方法如何处理高维 covariates。</li>
<li>methods: 这个论文使用了 Potential Outcome Framework (POF) 和 causal inference models based on POF (CIMs-B-POF)，并对这些模型的应用进行了系统性的分析。</li>
<li>results: 研究发现，在减少偏见时，最佳情况是 covariates 仅包含 confounders；在推断 counterfactual outcomes 时，调整变量对准确预测做出了贡献。此外，对 synthetic datasets 进行了广泛的实验，并经过了 теоретиче分析。<details>
<summary>Abstract</summary>
The Potential Outcome Framework (POF) plays a prominent role in the field of causal inference. Most causal inference models based on the POF (CIMs-B-POF) are designed for eliminating confounding bias and default to an underlying assumption of Confounding Covariates. This assumption posits that the covariates consist solely of confounders. However, the assumption of Confounding Covariates is challenging to maintain in practice, particularly when dealing with high-dimensional covariates. While certain methods have been proposed to differentiate the distinct components of covariates prior to conducting causal inference, the consequences of treating non-confounding covariates as confounders remain unclear. This ambiguity poses a potential risk when applying the CIMs-B-POF in practical scenarios. In this paper, we present a unified graphical framework for the CIMs-B-POF, which greatly enhances the comprehension of these models' underlying principles. Using this graphical framework, we quantitatively analyze the extent to which the inference performance of CIMs-B-POF is influenced when incorporating various types of non-confounding covariates, such as instrumental variables, mediators, colliders, and adjustment variables. The key findings are: in the task of eliminating confounding bias, the optimal scenario is for the covariates to exclusively encompass confounders; in the subsequent task of inferring counterfactual outcomes, the adjustment variables contribute to more accurate inferences. Furthermore, extensive experiments conducted on synthetic datasets consistently validate these theoretical conclusions.
</details>
<details>
<summary>摘要</summary>
《潜在结果框架（POF）在 causal inference 领域发挥突出作用。大多数基于 POF 的 causal inference 模型（CIMs-B-POF）是设计用于消除干扰偏见的，默认假设是 Confounding Covariates 假设。这个假设认为covariates 仅仅包含干扰因素。然而，在实践中保持 Confounding Covariates 假设是困难的，特别是面临高维 covariates 时。虽然一些方法已经提出来分解 covariates 的不同组成部分以前进行 causal inference，但对于不是干扰因素的 covariates 的处理仍然存在uncertainty。这种不确定性可能会在实践中应用 CIMs-B-POF 时产生风险。在这篇论文中，我们提出了一个统一的图形框架 для CIMs-B-POF，这有助于更好地理解这些模型的内在原理。使用这个图形框架，我们量化分析了 CIMs-B-POF 在不同类型的非干扰 covariates （如工具变量、中介变量、冲击变量和调整变量）的 incorporation 影响了 causal inference 的性能。我们发现，在消除干扰偏见的任务中，covariates 应该仅仅包含干扰因素；在接下来的计算Counterfactual 结果任务中，调整变量对更加准确的推断做出了贡献。此外，我们在 synthetic 数据上进行了广泛的实验，并 consistently 验证了这些理论结论。
</details></li>
</ul>
<hr>
<h2 id="TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search"><a href="#TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search" class="headerlink" title="TurboViT: Generating Fast Vision Transformers via Generative Architecture Search"></a>TurboViT: Generating Fast Vision Transformers via Generative Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11421">http://arxiv.org/abs/2308.11421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Wong, Saad Abbasi, Saeejith Nair</li>
<li>for: 本研究旨在设计高效的视觉 трансформер架构，以满足高速、低内存的应用需求。</li>
<li>methods: 本研究使用生成架构搜索（GAS）技术，通过搜索和优化mask单元注意力和Q-pooling设计模式，生成高效的层次结构视觉 трансформер架构设计。</li>
<li>results: 对于ImageNet-1K数据集，TurboViT架构设计在同等准确性下，与10个状态的有效视觉 трансформер网络架构设计相比，具有较低的建筑计算复杂度（&gt;2.47倍小于FasterViT-0）和计算复杂度（&gt;3.4倍少于MobileViT2-2.0），同时在低延迟和批处理场景中也表现出了优秀的执行速度和吞吐量（&gt;3.21倍低于FasterViT-0的延迟和&gt;3.18倍高于MobileViT2-2.0）。<details>
<summary>Abstract</summary>
Vision transformers have shown unprecedented levels of performance in tackling various visual perception tasks in recent years. However, the architectural and computational complexity of such network architectures have made them challenging to deploy in real-world applications with high-throughput, low-memory requirements. As such, there has been significant research recently on the design of efficient vision transformer architectures. In this study, we explore the generation of fast vision transformer architecture designs via generative architecture search (GAS) to achieve a strong balance between accuracy and architectural and computational efficiency. Through this generative architecture search process, we create TurboViT, a highly efficient hierarchical vision transformer architecture design that is generated around mask unit attention and Q-pooling design patterns. The resulting TurboViT architecture design achieves significantly lower architectural computational complexity (>2.47$\times$ smaller than FasterViT-0 while achieving same accuracy) and computational complexity (>3.4$\times$ fewer FLOPs and 0.9% higher accuracy than MobileViT2-2.0) when compared to 10 other state-of-the-art efficient vision transformer network architecture designs within a similar range of accuracy on the ImageNet-1K dataset. Furthermore, TurboViT demonstrated strong inference latency and throughput in both low-latency and batch processing scenarios (>3.21$\times$ lower latency and >3.18$\times$ higher throughput compared to FasterViT-0 for low-latency scenario). These promising results demonstrate the efficacy of leveraging generative architecture search for generating efficient transformer architecture designs for high-throughput scenarios.
</details>
<details>
<summary>摘要</summary>
视transformer在近年来的视觉任务中表现出了无 precedent的水平。然而，这些网络架构的建筑和计算复杂性使其在实际应用中高throughput低内存要求下部署成为了挑战。因此，有一些研究最近关于效率视transformer架构设计。在这项研究中，我们通过生成架构搜索（GAS）生成高效的视transformer架构设计，以达到精准和建筑计算效率的平衡。通过这种生成架构搜索过程，我们创造了TurboViT，一种高效的层次结构视transformer架构设计，围绕着面积单元注意力和Q-pooling设计模式。得到的TurboViT架构设计在与其他10种状态当前高效视transformer网络架构设计相比，在ImageNet-1K dataset上实现了明显的建筑计算复杂性下降（>2.47倍小于FasterViT-0，同等精准）和计算复杂性下降（>3.4倍少于MobileViT2-2.0，同等精准）。此外，TurboViT在低延迟和批处理场景中显示出了强大的执行速度和吞吐量（>3.21倍低于FasterViT-0的延迟和>3.18倍高于MobileViT2-2.0）。这些出色的结果证明了利用生成架构搜索生成高效的transformer架构设计的可行性。
</details></li>
</ul>
<hr>
<h2 id="Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition"><a href="#Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition" class="headerlink" title="Designing an attack-defense game: how to increase robustness of financial transaction models via a competition"></a>Designing an attack-defense game: how to increase robustness of financial transaction models via a competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11406">http://arxiv.org/abs/2308.11406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexey Zaytsev, Alex Natekin, Evgeni Vorsin, Valerii Smirnov, Georgii Smirnov, Oleg Sidorshin, Alexander Senin, Alexander Dudin, Dmitry Berestnev</li>
<li>for: 这种研究旨在 Investigating the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.</li>
<li>methods: 作者们使用了一场竞赛来进行实际和详细的研究问题，并对现代金融交易数据进行了实际应用。</li>
<li>results: 研究发现了一些新的攻击和防御策略，并证明了这些策略在现实生活中的可行性和有效性。<details>
<summary>Abstract</summary>
Given the escalating risks of malicious attacks in the finance sector and the consequential severe damage, a thorough understanding of adversarial strategies and robust defense mechanisms for machine learning models is critical. The threat becomes even more severe with the increased adoption in banks more accurate, but potentially fragile neural networks. We aim to investigate the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.   To achieve this goal, we have designed a competition that allows realistic and detailed investigation of problems in modern financial transaction data. The participants compete directly against each other, so possible attacks and defenses are examined in close-to-real-life conditions. Our main contributions are the analysis of the competition dynamics that answers the questions on how important it is to conceal a model from malicious users, how long does it take to break it, and what techniques one should use to make it more robust, and introduction additional way to attack models or increase their robustness.   Our analysis continues with a meta-study on the used approaches with their power, numerical experiments, and accompanied ablations studies. We show that the developed attacks and defenses outperform existing alternatives from the literature while being practical in terms of execution, proving the validity of the competition as a tool for uncovering vulnerabilities of machine learning models and mitigating them in various domains.
</details>
<details>
<summary>摘要</summary>
随着金融业的风险增加，机器学习模型的攻击和防御技术成为了紧迫的问题。随着银行更广泛地应用更加准确但可能脆弱的神经网络，这种威胁变得更加严重。我们希望通过研究现有的敌对攻击和防御策略来深入理解这些机器学习模型在使用时的漏洞和攻击方法。为了实现这一目标，我们设计了一项竞赛，允许参与者在真实的金融交易数据上进行实际的攻击和防御研究。参与者在直接对抗的环境中竞争，这使得可能的攻击和防御策略得到了充分的检验。我们的主要贡献包括对竞赛的竞争动态进行分析，回答如何隐藏模型于恶意用户，模型如何快速被破坏，以及如何使模型更加坚强的问题。我们的分析继续进行meta研究，对使用的方法进行评估，并通过数学实验和附加的ablation研究来证明我们的攻击和防御策略的有效性。我们的结果显示，我们提出的攻击和防御策略在实施上具有优势，并在不同领域中能够实现有效的抵御。因此，我们的竞赛和分析证明了竞赛是一种有效的工具，用于探索机器学习模型的漏洞并实现其在不同领域的防御。
</details></li>
</ul>
<hr>
<h2 id="Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer"><a href="#Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer" class="headerlink" title="Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer"></a>Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11389">http://arxiv.org/abs/2308.11389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebeca Vétil, Clément Abi-Nader, Alexandre Bône, Marie-Pierre Vullierme, Marc-Michel Rohé, Pietro Gori, Isabelle Bloch</li>
<li>for: 这篇论文旨在解决深度学习医学影像特征（DLR）和手工设计医学影像特征（HCR）之间的重叠问题。</li>
<li>methods: 作者使用VAE实现DLR特征EXTRACTING，并通过最小化这两种特征之间的相互信息来保持其独立性。</li>
<li>results: 研究结果显示，结合非重叠DLR和HCR特征可以提高预测早期肝癌标志物的精度，相比基eline方法不 Addressing redundancy or solely relying on HCR features。<details>
<summary>Abstract</summary>
We address the problem of learning Deep Learning Radiomics (DLR) that are not redundant with Hand-Crafted Radiomics (HCR). To do so, we extract DLR features using a VAE while enforcing their independence with HCR features by minimizing their mutual information. The resulting DLR features can be combined with hand-crafted ones and leveraged by a classifier to predict early markers of cancer. We illustrate our method on four early markers of pancreatic cancer and validate it on a large independent test set. Our results highlight the value of combining non-redundant DLR and HCR features, as evidenced by an improvement in the Area Under the Curve compared to baseline methods that do not address redundancy or solely rely on HCR features.
</details>
<details>
<summary>摘要</summary>
我们对深度学习医学图像学习（DLR）进行非重复的应用，以避免与手工医学图像学习（HCR）的重复。我们使用VAE对DLR特征进行提取，并在HCR特征和DLR特征之间强制独立性，以避免它们之间的相互信息。得到的DLR特征可以与手工医学图像学习特征结合，并由分类器使用以预测肝癌的早期标志。我们在四种肝癌早期标志上运算我们的方法，并在一个大的独立测试集上验证。我们的结果表明，结合非重复的DLR和HCR特征可以提高预测性能，比基eline方法不 Addressing redundancy or solely relying on HCR features。
</details></li>
</ul>
<hr>
<h2 id="Targeted-Data-Augmentation-for-bias-mitigation"><a href="#Targeted-Data-Augmentation-for-bias-mitigation" class="headerlink" title="Targeted Data Augmentation for bias mitigation"></a>Targeted Data Augmentation for bias mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11386">http://arxiv.org/abs/2308.11386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Maria Ferlin, Michał Grochowski</li>
<li>For: The paper aims to address the issue of bias in AI systems by introducing a novel approach called Targeted Data Augmentation (TDA).* Methods: The paper uses classical data augmentation techniques to insert biases into the training data, which helps to mitigate biases in the models.* Results: The paper shows that the proposed TDA approach can significantly decrease bias measures while maintaining a negligible increase in the error rate, using two diverse datasets of clinical skin lesions and male and female faces.Here are the three key points in Simplified Chinese text:* For: 这篇论文目标是解决人工智能系统中的偏见问题，提出了一种新的方法called Targeted Data Augmentation (TDA)。* Methods: 这篇论文使用了经典的数据扩展技术，插入了偏见到训练数据中，以减少模型中的偏见。* Results: 论文表明，提出的TDA方法可以在两个多样化的数据集上（皮肤病和♂♀脸）获得了显著减少偏见的效果，而且保持了误差率的增加在一定范围内。<details>
<summary>Abstract</summary>
The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decrease in bias measures, ranging from two-fold to more than 50-fold, while maintaining a negligible increase in the error rate.
</details>
<details>
<summary>摘要</summary>
发展公平和伦理AI系统需要仔细考虑偏见缓解，这一领域经常被排在第二队列。在这项研究中，我们介绍了一种新的和高效的方法，称为目标数据扩充（TDA），该方法利用经典数据扩充技术来解决数据和模型中的偏见问题。不同于努力地去除偏见，我们的方法提议插入偏见，从而提高性能。为了识别偏见，我们对两个多样化的数据集进行了标注：一个是皮肤病变数据集，另一个是♂♂♀♀脸部数据集。这些偏见标注在本研究中首次公布，为未来研究提供了一个价值的资源。通过对比事实插入偏见，我们发现了框架、尺度和镜片等偏见对模型产生了重要影响。通过在训练过程中随机插入偏见，我们成功缓解了这些偏见，并实现了偏见度量的显著减少，从2倍到更多于50倍，同时保持了错误率的微不足百分之一增加。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores"><a href="#Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores" class="headerlink" title="Interpretable Distribution-Invariant Fairness Measures for Continuous Scores"></a>Interpretable Distribution-Invariant Fairness Measures for Continuous Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11375">http://arxiv.org/abs/2308.11375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ann-Kristin Becker, Oana Dumitrasc, Klaus Broelemann</li>
<li>for: 这篇论文的目的是扩展 binary 决策中的算法公平度量到连续分数上。</li>
<li>methods: 这篇论文提出了一种基于 Wasserstein 距离的分布不变的公平度量方法，这种方法可以快速计算并对不同的模型、数据集、时间点进行比较。</li>
<li>results: 这篇论文通过实验表明，提出的公平度量方法可以更好地捕捉和评估不同群体之间的差异，并且可以比较不同的模型和数据集之间的偏见。<details>
<summary>Abstract</summary>
Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-based fairness measures miss. Finally, we demonstrate their effectiveness through experiments on the most commonly used fairness benchmark datasets.
</details>
<details>
<summary>摘要</summary>
通常情况下，算法公平性的度量是在二进制决策中讨论的。我们将这种方法扩展到连续分数上。目前，ROC基本的度量是为此目的提出的。其他现有的方法对于分数的分布取决于，不适用于排名任务，或者其效果大小不容易理解。我们提议一种对连续分数的公平度量，基于 Wasserstein 距离，具有合理的解释，可以量化和解释群体偏见的强度以及不同模型、数据集、时间点之间的偏见。我们还 derivates了不同家族的现有公平度量的连接，并证明了我们的分布不变的公平度量在ROC基本的公平度量之上表现更好，因为它们更加显着，可以捕捉ROC基本的公平度量所miss的重要偏见。最后，我们通过使用最常用的公平性标准数据集进行实验，证明了它们的效果。
</details></li>
</ul>
<hr>
<h2 id="How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation"><a href="#How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation" class="headerlink" title="How Much Temporal Long-Term Context is Needed for Action Segmentation?"></a>How Much Temporal Long-Term Context is Needed for Action Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11358">http://arxiv.org/abs/2308.11358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ltcontext/ltcontext">https://github.com/ltcontext/ltcontext</a></li>
<li>paper_authors: Emad Bahrami, Gianpiero Francesca, Juergen Gall</li>
<li>for: 本研究的目的是回答 temporal action segmentation 中需要多少长期 temporal context 以达到最佳性能。</li>
<li>methods: 我们提出了一种基于 transformer 的模型，使用 sparse attention  capture 全视频的 context。</li>
<li>results: 我们的实验表明，模型全视频的 context 是 temporal action segmentation 中获得最佳性能的必要条件。<details>
<summary>Abstract</summary>
Modeling long-term context in videos is crucial for many fine-grained tasks including temporal action segmentation. An interesting question that is still open is how much long-term temporal context is needed for optimal performance. While transformers can model the long-term context of a video, this becomes computationally prohibitive for long videos. Recent works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window. While these approaches show good results, their performance is limited by their inability to capture the full context of a video. In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video. We compare our model with the current state of the art on three datasets for temporal action segmentation, namely 50Salads, Breakfast, and Assembly101. Our experiments show that modeling the full context of a video is necessary to obtain the best performance for temporal action segmentation.
</details>
<details>
<summary>摘要</summary>
模型长期视频上下文是多种细化任务中的关键，包括时间动作分割。一个有趣的问题是如何确定最佳长期时间上下文的范围。虽然转换器可以模型视频的长期上下文，但这在长视频时会变得计算拒绝。 current works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window。although these approaches show good results, their performance is limited by their inability to capture the full context of a video。在这项工作中，我们试图回答 temporal action segmentation 需要多少长期时间上下文来达到最佳性能的问题。我们提出了一种基于转换器的模型，通过采用缺省注意力来捕捉整个视频的上下文。我们与当前领先的三个数据集（50Salads、Breakfast和Assembly101）进行比较，实验结果表明，模型整个视频的上下文是 temporal action segmentation 获得最佳性能的必要条件。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties"><a href="#Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties" class="headerlink" title="Machine learning assisted exploration for affine Deligne-Lusztig varieties"></a>Machine learning assisted exploration for affine Deligne-Lusztig varieties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11355">http://arxiv.org/abs/2308.11355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinpf314/ml4adlv">https://github.com/jinpf314/ml4adlv</a></li>
<li>paper_authors: Bin Dong, Xuhua He, Pengfei Jin, Felix Schremmer, Qingchao Yu</li>
<li>for: 这 paper 的 primary objective 是 investigate the nonemptiness pattern, dimension 和 enumeration of irreducible components of affine Deligne-Lusztig varieties (ADLV).</li>
<li>methods: 这 paper 使用了 Machine Learning (ML) 协助的 framework 来探索 ADLV 的几何结构。 The proposed framework 包括 data generation, model training, pattern analysis, 和 human examination, which presents an intricate interplay between ML 和 pure mathematical research.</li>
<li>results: 这 paper 提出了一种新的, interdisciplinary 的方法，可以帮助加速 pure mathematical research, 并且可以找到新的 conjectures 和 promising research directions。 The paper 还 rediscovered the virtual dimension formula 和 provided a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension.<details>
<summary>Abstract</summary>
This paper presents a novel, interdisciplinary study that leverages a Machine Learning (ML) assisted framework to explore the geometry of affine Deligne-Lusztig varieties (ADLV). The primary objective is to investigate the nonemptiness pattern, dimension and enumeration of irreducible components of ADLV. Our proposed framework demonstrates a recursive pipeline of data generation, model training, pattern analysis, and human examination, presenting an intricate interplay between ML and pure mathematical research. Notably, our data-generation process is nuanced, emphasizing the selection of meaningful subsets and appropriate feature sets. We demonstrate that this framework has a potential to accelerate pure mathematical research, leading to the discovery of new conjectures and promising research directions that could otherwise take significant time to uncover. We rediscover the virtual dimension formula and provide a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension. Furthermore, we extend an open invitation to the readers by providing the source code for computing ADLV and the ML models, promoting further explorations. This paper concludes by sharing valuable experiences and highlighting lessons learned from this collaboration.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了一项新的、混合数学和机器学习（ML）的研究方法，用于探索非线性Deligne-Lusztig多样体（ADLV）的几何学。研究的主要目标是研究ADLV中的非空性模式、维度和总数，以及其不同组成部分的分析。我们提出的框架包括数据生成、模型训练、模式分析和人类检查，这些步骤之间存在着细腻的交互。特别是，我们的数据生成过程强调选择有意义的子集和适当的特征集。我们示出了这种框架的潜在可能性，可以加速纯数学研究，导致新的推测和潜在的研究方向的发现。此外，我们还重新发现了虚方尺式和一个新的问题的证明，即某些维度下的下界问题。此外，我们还向读者开放了源代码，以便进一步探索ADLV和ML模型。这篇论文结束于分享有价值的经验和学习到的教训。
</details></li>
</ul>
<hr>
<h2 id="WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data"><a href="#WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data" class="headerlink" title="WEARS: Wearable Emotion AI with Real-time Sensor data"></a>WEARS: Wearable Emotion AI with Real-time Sensor data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11673">http://arxiv.org/abs/2308.11673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhruv Limbani, Daketi Yatin, Nitish Chaturvedi, Vaishnavi Moorthy, Pushpalatha M, Harichandana BSS, Sumit Kumar</li>
<li>For: The paper aims to predict user emotion using smartwatch sensors, with a focus on developing a practical and user-friendly system for everyday use.* Methods: The authors propose a framework that collects ground truth data in real-time using a combination of English and regional language-based videos to evoke emotions in participants. They use a binary classification approach due to limited dataset size and experiment with multiple machine-learning models, including Multi-Layer Perceptron, which achieves a maximum accuracy of 93.75% for pleasant-unpleasant moods.* Results: The paper reports an accuracy of 93.75% for predicting pleasant-unpleasant moods using Multi-Layer Perceptron, indicating the effectiveness of using smartwatch sensors for emotion recognition.Here’s the simplified Chinese text for the three key points:* For: 这篇论文旨在使用智能手表传感器预测用户情绪，旨在开发一个实用、日常使用的系统。* Methods: 作者提出了一种基于英文和地方语言基于视频诱发情感的实验框架，并使用多种机器学习模型进行实验，其中多层感知器达到了93.75%的最高准确率。* Results: 论文报告了使用多层感知器预测愉悦-不愉悦情绪的准确率为93.75%，表明智能手表传感器可以有效地进行情绪识别。<details>
<summary>Abstract</summary>
Emotion prediction is the field of study to understand human emotions. Existing methods focus on modalities like text, audio, facial expressions, etc., which could be private to the user. Emotion can be derived from the subject's psychological data as well. Various approaches that employ combinations of physiological sensors for emotion recognition have been proposed. Yet, not all sensors are simple to use and handy for individuals in their daily lives. Thus, we propose a system to predict user emotion using smartwatch sensors. We design a framework to collect ground truth in real-time utilizing a mix of English and regional language-based videos to invoke emotions in participants and collect the data. Further, we modeled the problem as binary classification due to the limited dataset size and experimented with multiple machine-learning models. We also did an ablation study to understand the impact of features including Heart Rate, Accelerometer, and Gyroscope sensor data on mood. From the experimental results, Multi-Layer Perceptron has shown a maximum accuracy of 93.75 percent for pleasant-unpleasant (high/low valence classification) moods.
</details>
<details>
<summary>摘要</summary>
预测人类情感是一个研究领域，旨在理解人们的情感。现有方法主要集中在文本、音频、脸部表现等Modalities上，这些modalities可能是用户私有的。情感还可以从主题的心理数据中 derivation。许多方法使用多种生物学传感器进行情感识别，但不是所有传感器都是用户日常生活中容易使用。因此，我们提出了一个基于智能手表传感器的情感预测系统。我们设计了一个框架，以实时收集真实数据，使用英文和地区语言基于视频释放情感并收集数据。此外，我们将问题定型为二分类问题，因为数据集的小型限制了我们的实验。我们还进行了减少研究，以了解特征包括心率、加速度和陀螺仪传感器数据对情感的影响。从实验结果来看，多层感知器在高/低积极情感（愉悦-不愉悦）类别上达到最高的准确率为93.75%。
</details></li>
</ul>
<hr>
<h2 id="Careful-at-Estimation-and-Bold-at-Exploration"><a href="#Careful-at-Estimation-and-Bold-at-Exploration" class="headerlink" title="Careful at Estimation and Bold at Exploration"></a>Careful at Estimation and Bold at Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11348">http://arxiv.org/abs/2308.11348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing Chen, Yijun Liu, Zhaogeng Liu, Hechang Chen, Hengshuai Yao, Yi Chang</li>
<li>for: 本研究旨在解决 kontinuous action space 中的尝试策略问题，即因为无限多个动作而导致的规则性尝试策略不能得出总体结论。</li>
<li>methods: 我们基于 double-Q 函数框架，提出了一种新的尝试策略，以解决issues 1和2。我们首先提出了 Q 值更新的greedy Q softmax schema，然后 derivated expected Q value 的公式，并将其与 Q 值更新相结合。</li>
<li>results: 我们在 Mujoco  benchmark 上评估了我们的方法，并与之前的 state-of-the-art 方法进行比较。结果显示，我们的方法在不同环境中表现出色，特别是在最复杂的 Humanoid 环境中。<details>
<summary>Abstract</summary>
Exploration strategies in continuous action space are often heuristic due to the infinite actions, and these kinds of methods cannot derive a general conclusion. In prior work, it has been shown that policy-based exploration is beneficial for continuous action space in deterministic policy reinforcement learning(DPRL). However, policy-based exploration in DPRL has two prominent issues: aimless exploration and policy divergence, and the policy gradient for exploration is only sometimes helpful due to inaccurate estimation. Based on the double-Q function framework, we introduce a novel exploration strategy to mitigate these issues, separate from the policy gradient. We first propose the greedy Q softmax update schema for Q value update. The expected Q value is derived by weighted summing the conservative Q value over actions, and the weight is the corresponding greedy Q value. Greedy Q takes the maximum value of the two Q functions, and conservative Q takes the minimum value of the two different Q functions. For practicality, this theoretical basis is then extended to allow us to combine action exploration with the Q value update, except for the premise that we have a surrogate policy that behaves like this exploration policy. In practice, we construct such an exploration policy with a few sampled actions, and to meet the premise, we learn such a surrogate policy by minimizing the KL divergence between the target policy and the exploration policy constructed by the conservative Q. We evaluate our method on the Mujoco benchmark and demonstrate superior performance compared to previous state-of-the-art methods across various environments, particularly in the most complex Humanoid environment.
</details>
<details>
<summary>摘要</summary>
在连续动作空间中，探索策略经常是规则性的，因为动作的数量是无限的。在先前的工作中，已经证明了在决定性政策学习（DPRL）中，政策基于的探索是有利的。然而，DPRL中的政策基于探索有两个明显的问题：无目的探索和政策分化，并且政策梯度对探索是不一定有帮助的，因为估计不准确。基于双Q函数框架，我们介绍了一种新的探索策略，以解决这些问题。我们首先提出了Q值更新的软MAX schema，其中预期Q值是通过对动作的权重 sums来计算的。在这个过程中，权重是根据动作的greedy Q值进行调整。greedy Q值是两个Q函数中的最大值，而conservative Q值是两个Q函数中的最小值。为了实用，我们将这种理论基础扩展到允许我们将探索策略与Q值更新结合，只要我们有一个伪函数，这个伪函数在探索策略下被学习。在实践中，我们构建了一个这种探索策略，并通过最小化KL抽象度来学习这个伪函数。我们在Mujoco benchmark上评估了我们的方法，并在不同的环境中达到了先前的状态艺术方法的超越性表现，特别是在最复杂的人型环境中。
</details></li>
</ul>
<hr>
<h2 id="ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models"><a href="#ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models" class="headerlink" title="ProAgent: Building Proactive Cooperative AI with Large Language Models"></a>ProAgent: Building Proactive Cooperative AI with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11339">http://arxiv.org/abs/2308.11339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PKU-Alignment/ProAgent">https://github.com/PKU-Alignment/ProAgent</a></li>
<li>paper_authors: Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang, Feng Yin, Yitao Liang, Yaodong Yang<br>for:This paper aims to develop a novel framework called ProAgent that enables AI agents to cooperate with other agents and humans in a more effective and adaptive manner.methods:ProAgent leverages large language models (LLMs) to anticipate teammates’ decisions and formulate better plans, and it has a high degree of modularity and interpretability, making it easy to integrate with different coordination scenarios.results:Experimental evaluations show that ProAgent outperforms five comparison methods in cooperation with AI agents, and it also performs better than the current state-of-the-art, COLE, when cooperating with human proxy models, with an average improvement of over 10%. These results demonstrate the effectiveness of ProAgent in facilitating human-AI collaboration.Here’s the simplified Chinese version:for:这篇论文目标是开发一种名为ProAgent的新框架，使AI代理能够更有效地和其他代理和人类合作。methods:ProAgent利用大型自然语言模型（LLMs）预测同事的决策并提出更好的计划，它具有高度的可模块化和可解释性，方便与不同的协调方案集成。results:实验评估表明，ProAgent比五种参考方法在与AI代理合作中表现更出色，并且与当前状态艺术的COLE相比，在与人类代理模型合作时的表现也有超过10%的提升。这些结果证明ProAgent在人AI合作方面的作用是有效的。<details>
<summary>Abstract</summary>
Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations conducted within the framework of \textit{Overcook-AI} unveil the remarkable performance superiority of ProAgent, outperforming five methods based on self-play and population-based training in cooperation with AI agents. Further, when cooperating with human proxy models, its performance exhibits an average improvement exceeding 10\% compared to the current state-of-the-art, COLE. The advancement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. These findings inspire future research for human-robot collaborations. For a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details>
<details>
<summary>摘要</summary>
building 人工智能（AI） WITH adaptive behaviors in human-AI cooperation 是AGI研究中的重点ocus。 current methods for developing cooperative agents mainly rely on learning-based methods, where policy generalization heavily relies on past interactions with specific teammates. these approaches limit the agent's ability to adjust its strategy when faced with new teammates. we propose \textbf{ProAgent}, a novel framework that leverages large language models (LLMs) to create a proactive agent that can anticipate teammates' upcoming decisions and formulate improved plans for itself. ProAgent excels at cooperative reasoning and can dynamically adapt its behavior to enhance collaborative efforts with teammates. furthermore, the ProAgent framework has a high degree of modularity and interpretability, making it easy to integrate into various coordination scenarios. experimental evaluations conducted within the Overcook-AI framework show that ProAgent outperforms five self-play and population-based training methods in cooperation with AI agents, with an average improvement of over 10% compared to the current state-of-the-art, COLE. this improvement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. these findings pave the way for future research on human-robot collaborations. for a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details></li>
</ul>
<hr>
<h2 id="Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings"><a href="#Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings" class="headerlink" title="Generalising sequence models for epigenome predictions with tissue and assay embeddings"></a>Generalising sequence models for epigenome predictions with tissue and assay embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11671">http://arxiv.org/abs/2308.11671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacob Deasy, Ron Schwessinger, Ferran Gonzalez, Stephen Young, Kim Branson</li>
<li>for: 本研究旨在提高epigenetic profile预测方法的精度和可靠性，通过integrating tissue和assay embeddings into a Contextualised Genomic Network (CGN)来增强long-range sequence embeddings的准确性。</li>
<li>methods: 本研究使用了Contextualised Genomic Network (CGN)，其中integrates tissue和assay embeddings into a single network，以增强long-range sequence embeddings的准确性。</li>
<li>results: 研究表明，使用CGN可以在各种实验条件下实现强相关性，而且超过了现有方法的表现。此外，研究还提供了关于基因变化对epigenetic sequence模型训练的首个发现。<details>
<summary>Abstract</summary>
Sequence modelling approaches for epigenetic profile prediction have recently expanded in terms of sequence length, model size, and profile diversity. However, current models cannot infer on many experimentally feasible tissue and assay pairs due to poor usage of contextual information, limiting $\textit{in silico}$ understanding of regulatory genomics. We demonstrate that strong correlation can be achieved across a large range of experimental conditions by integrating tissue and assay embeddings into a Contextualised Genomic Network (CGN). In contrast to previous approaches, we enhance long-range sequence embeddings with contextual information in the input space, rather than expanding the output space. We exhibit the efficacy of our approach across a broad set of epigenetic profiles and provide the first insights into the effect of genetic variants on epigenetic sequence model training. Our general approach to context integration exceeds state of the art in multiple settings while employing a more rigorous validation procedure.
</details>
<details>
<summary>摘要</summary>
Sequence模型方法 для脱氧核型谱预测最近几年得到了较长的序列长度、更大的模型大小和更多的谱型多样性。然而，当前的模型无法对许多实验可行的组织和检测对照进行预测，因为忽略了Contextual信息的使用，这限制了$\textit{in silico}$的规则生物学理解。我们示示了在各种实验条件下强相关性的 achievement，通过将组织和检测嵌入到Contextualised Genomic Network（CGN）中，而不是扩展输出空间。我们在输入空间中增强长距离序列嵌入中的Contextual信息，而不是扩展输出空间。我们在多种脱氧核型谱中展示了我们的方法的效果，并提供了脱氧核型序列模型训练中基因变化的首次研究。我们的通用方法进行Context集成超过了当前状态的多个设置，而且采用更严格的验证过程。
</details></li>
</ul>
<hr>
<h2 id="Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation"><a href="#Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation" class="headerlink" title="Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation"></a>Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11333">http://arxiv.org/abs/2308.11333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen</li>
<li>for: 防止 Federated Learning (FL) 中的毒蛋攻击 (backdoor attacks)</li>
<li>methods: 基于毒蛋攻击的两个特点（ triggers 更快学习，触发图像分类更大）的数据free trigger-generation-based 防御方法</li>
<li>results: 对多种现有毒蛋攻击和七种现有防御方法进行了广泛的实验，结果表明我们的方法可以成功防止毒蛋攻击，并在 IID 和非 IID 场景下出perform 所有七种防御方法。特别是，我们的方法可以在 80% 的客户端被恶意攻击时仍然成功防止毒蛋攻击。<details>
<summary>Abstract</summary>
As a distributed machine learning paradigm, Federated Learning (FL) enables large-scale clients to collaboratively train a model without sharing their raw data. However, due to the lack of data auditing for untrusted clients, FL is vulnerable to poisoning attacks, especially backdoor attacks. By using poisoned data for local training or directly changing the model parameters, attackers can easily inject backdoors into the model, which can trigger the model to make misclassification of targeted patterns in images. To address these issues, we propose a novel data-free trigger-generation-based defense approach based on the two characteristics of backdoor attacks: i) triggers are learned faster than normal knowledge, and ii) trigger patterns have a greater effect on image classification than normal class patterns. Our approach generates the images with newly learned knowledge by identifying the differences between the old and new global models, and filters trigger images by evaluating the effect of these generated images. By using these trigger images, our approach eliminates poisoned models to ensure the updated global model is benign. Comprehensive experiments demonstrate that our approach can defend against almost all the existing types of backdoor attacks and outperform all the seven state-of-the-art defense methods with both IID and non-IID scenarios. Especially, our approach can successfully defend against the backdoor attack even when 80\% of the clients are malicious.
</details>
<details>
<summary>摘要</summary>
作为分布式机器学习模式，联邦学习（FL）允许大规模客户端共同训练模型，而无需分享原始数据。然而，由于客户端数据审核不足，FL容易受到毒素攻击，尤其是后门攻击。攻击者可以使用毒素数据进行本地训练或直接改变模型参数，从而轻松地植入后门到模型中，使模型在目标图像中产生误分类。为解决这些问题，我们提出了一种基于两个后门攻击特征的新防御方法：一是触发更快速学习than正常知识，二是触发模式在图像分类中比正常类型更大的影响。我们的方法生成图像新学习的知识，并将触发图像过滤通过评估这些生成的图像的效果。通过使用这些触发图像，我们的方法可以消除毒素模型，确保更新的全局模型是无辜的。我们的实验表明，我们的方法可以对现有的所有类型后门攻击进行防御，并在IID和非IID场景中高效超越七种现状防御方法。特别是，我们的方法可以成功防御80%的客户端恶意攻击。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments"><a href="#Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments" class="headerlink" title="Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments"></a>Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11670">http://arxiv.org/abs/2308.11670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nisal Hemadasa Manikku Badu, Marcus Venzke, Volker Turau, Yanqiu Huang</li>
<li>for: 这个论文是为了解决在私隐要求高的Factory环境中实现indoor位置系统（IPS），而不需要外部基础设施和数据。</li>
<li>methods: 该论文使用机器学习（ML）技术，利用运动和室内传感器来定位移动物体。它将问题定义为多变量时间序列分类（MTSC）问题，并对不同的机器学习模型进行比较分析，以选择最佳适用于IoT设备的模型。</li>
<li>results: 研究人员通过使用一个新的时间序列数据集来评估和比较不同的机器学习模型，发现所有评估模型的准确率都超过80%。CNN-1D表现最佳，其次是MLP。DT模型具有最低的内存占用量和计算延迟，因此有可能在实际应用中使用。<details>
<summary>Abstract</summary>
Indoor Positioning Systems (IPS) gained importance in many industrial applications. State-of-the-art solutions heavily rely on external infrastructures and are subject to potential privacy compromises, external information requirements, and assumptions, that make it unfavorable for environments demanding privacy and prolonged functionality. In certain environments deploying supplementary infrastructures for indoor positioning could be infeasible and expensive. Recent developments in machine learning (ML) offer solutions to address these limitations relying only on the data from onboard sensors of IoT devices. However, it is unclear which model fits best considering the resource constraints of IoT devices. This paper presents a machine learning-based indoor positioning system, using motion and ambient sensors, to localize a moving entity in privacy concerned factory environments. The problem is formulated as a multivariate time series classification (MTSC) and a comparative analysis of different machine learning models is conducted in order to address it. We introduce a novel time series dataset emulating the assembly lines of a factory. This dataset is utilized to assess and compare the selected models in terms of accuracy, memory footprint and inference speed. The results illustrate that all evaluated models can achieve accuracies above 80 %. CNN-1D shows the most balanced performance, followed by MLP. DT was found to have the lowest memory footprint and inference latency, indicating its potential for a deployment in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
内部定位系统（IPS）在多个业务应用中升级了其重要性。现代解决方案强依赖于外部基础设施，受到隐私侵犯、外部信息需求和假设的限制，使其不适合需要隐私和持续性的环境。在某些环境中，为实现内部定位而部署补充基础设施可能是不可能的和昂贵的。现代机器学习（ML）技术提供了解决这些限制的方案，不需要外部基础设施，只需基于 IoT 设备上的固件传感器数据。然而，选择最佳模型是有困难的，因为 IoT 设备的资源限制是一个重要的考虑因素。本文描述了一种基于机器学习的内部定位系统，使用运动和室内传感器来确定在隐私问题中的工厂环境中移动的实体。问题被формализова为多变量时间序列分类（MTSC），并对不同的机器学习模型进行比较分析，以解决它。我们引入了一个新的时间序列数据集，该数据集模拟了制造工程厂的生产线。这个数据集用于评估和比较选择的模型，以确定它们的准确率、内存占用量和推理速度。结果显示所有评估模型均可达到上百分之八的准确率。CNN-1D表现最佳，其次是 MLP。DT 具有最低的内存占用量和推理延迟，因此它在实际应用中具有潜在的优势。
</details></li>
</ul>
<hr>
<h2 id="Class-Label-aware-Graph-Anomaly-Detection"><a href="#Class-Label-aware-Graph-Anomaly-Detection" class="headerlink" title="Class Label-aware Graph Anomaly Detection"></a>Class Label-aware Graph Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11669">http://arxiv.org/abs/2308.11669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jhkim611/clad">https://github.com/jhkim611/clad</a></li>
<li>paper_authors: Junghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, Chanyoung Park</li>
<li>for: 本研究旨在提高无监督图像检测方法的性能，特别是在缺乏类别标签信息的情况下。</li>
<li>methods: 本研究提出了一种基于类别标签的图像检测方法，即类别标签感知图像检测方法（CLAD）。该方法利用有限数量的标签节点来增强无监督图像检测的性能。</li>
<li>results: 对于十个数据集，CLAD方法在无监督情况下表现出了比较出色的性能，甚至超过了现有的无监督图像检测方法。<details>
<summary>Abstract</summary>
Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese:Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.Translate the text into Simplified Chinese:<</SYS>>Here's the translation:Unsupervised GAD方法假设缺乏异常标签，即节点是否异常。我们从前一些无监督方法中发现，不仅假设缺乏这些异常标签，还假设缺乏类别标签（用于普通的节点分类任务中）。在这个工作中，我们研究了类别标签是否增强了无监督GAD的检测性。为此，我们提出了一个具有限量标签的Class Label-aware Graph Anomaly Detection框架（CLAD），可以将有限量的标签用于增强无监督GAD的性能。我们在十个数据集上进行了广泛的实验，结果显示CLAD在与现有的无监督GAD方法比较时表现更好，甚至在没有真实的类别标签信息时仍能取得更高的性能。CLAD的源代码可以在\url{https://github.com/jhkim611/CLAD}中找到。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices"><a href="#Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices" class="headerlink" title="Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices"></a>Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11295">http://arxiv.org/abs/2308.11295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kostenok, Daniil Cherniavskii, Alexey Zaytsev</li>
<li>for: This paper aims to address the open problem of determining the degree of confidence of deep learning models in their predictions, specifically for text classification models using the Transformer architecture.</li>
<li>methods: The proposed method for uncertainty estimation is based on Topological Data Analysis (TDA) and utilizes the attention mechanism to form relationships between internal representations.</li>
<li>results: The proposed method outperforms classical methods in quality and opens up a new area of application for the attention mechanism, but requires the selection of topological features.<details>
<summary>Abstract</summary>
Determining the degree of confidence of deep learning model in its prediction is an open problem in the field of natural language processing. Most of the classical methods for uncertainty estimation are quite weak for text classification models. We set the task of obtaining an uncertainty estimate for neural networks based on the Transformer architecture. A key feature of such mo-dels is the attention mechanism, which supports the information flow between the hidden representations of tokens in the neural network. We explore the formed relationships between internal representations using Topological Data Analysis methods and utilize them to predict model's confidence. In this paper, we propose a method for uncertainty estimation based on the topological properties of the attention mechanism and compare it with classical methods. As a result, the proposed algorithm surpasses the existing methods in quality and opens up a new area of application of the attention mechanism, but requires the selection of topological features.
</details>
<details>
<summary>摘要</summary>
决定深度学习模型预测结果的信任度是自然语言处理领域的一个开问题。大多数经典方法的不确定性估计对文本分类模型来说是很弱的。我们设定了基于Transformer架构的神经网络中的不确定性估计任务。Transformer模型的一个重要特征是对应机制，它支持内部表示之间的信息流动。我们使用Topological Data Analysis方法来探索内部表示之间的关系，并将其用于预测模型的信任度。在这篇论文中，我们提出了基于对应机制的不确定性估计方法，并与经典方法进行比较。结果显示，提案的算法在质量上超过了现有的方法，并开启了一个新的对应机制的应用领域，但是需要选择几个类型的特征。
</details></li>
</ul>
<hr>
<h2 id="Network-Momentum-across-Asset-Classes"><a href="#Network-Momentum-across-Asset-Classes" class="headerlink" title="Network Momentum across Asset Classes"></a>Network Momentum across Asset Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11294">http://arxiv.org/abs/2308.11294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyue Pu, Stephen Roberts, Xiaowen Dong, Stefan Zohren</li>
<li>for: 这篇论文探讨了网络势力的概念，即基于资产之间的势力扩散的新交易信号。</li>
<li>methods: 该论文使用了一种可读性高的图学学习模型，以探索不同资产类型之间的势力扩散网络。</li>
<li>results: 该论文提出了一种基于网络势力的多资产投资策略，并通过实证分析表明其具有1.5的沙勃级效果和22%的年化收益。<details>
<summary>Abstract</summary>
We investigate the concept of network momentum, a novel trading signal derived from momentum spillover across assets. Initially observed within the confines of pairwise economic and fundamental ties, such as the stock-bond connection of the same company and stocks linked through supply-demand chains, momentum spillover implies a propagation of momentum risk premium from one asset to another. The similarity of momentum risk premium, exemplified by co-movement patterns, has been spotted across multiple asset classes including commodities, equities, bonds and currencies. However, studying the network effect of momentum spillover across these classes has been challenging due to a lack of readily available common characteristics or economic ties beyond the company level. In this paper, we explore the interconnections of momentum features across a diverse range of 64 continuous future contracts spanning these four classes. We utilise a linear and interpretable graph learning model with minimal assumptions to reveal the intricacies of the momentum spillover network. By leveraging the learned networks, we construct a network momentum strategy that exhibits a Sharpe ratio of 1.5 and an annual return of 22%, after volatility scaling, from 2000 to 2022. This paper pioneers the examination of momentum spillover across multiple asset classes using only pricing data, presents a multi-asset investment strategy based on network momentum, and underscores the effectiveness of this strategy through robust empirical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation"><a href="#Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation" class="headerlink" title="Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation"></a>Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11291">http://arxiv.org/abs/2308.11291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeremyfix/icvs2023">https://github.com/jeremyfix/icvs2023</a></li>
<li>paper_authors: Salim Khazem, Jeremy Fix, Cédric Pradalier</li>
<li>for: 本研究旨在预测木材中内部缺陷的位置，以提高木材质量评估的准确性和效率。</li>
<li>methods: 本研究使用了卷积回归神经网络来解决木材外形特征与内部缺陷之间的关系。</li>
<li>results: 研究结果表明，通过使用卷积回归神经网络进行预测，可以准确地预测木材内部缺陷的位置，并且可以通过便宜的外形测量设备进行实时检测。<details>
<summary>Abstract</summary>
The quality of a wood log in the wood industry depends heavily on the presence of both outer and inner defects, including inner knots that are a result of the growth of tree branches. Today, locating the inner knots require the use of expensive equipment such as X-ray scanners. In this paper, we address the task of predicting the location of inner defects from the outer shape of the logs. The dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.
</details>
<details>
<summary>摘要</summary>
木材行业中木材质量受到内部和外部缺陷的影响，其中包括由树木支 Branches 生长而成的内部缺陷。当前，发现内部缺陷需要使用昂贵的设备如X射验器。在这篇论文中，我们Addressing the task of predicting the location of inner defects from the outer shape of the logs. Our dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.Here's the breakdown of the translation:* 木材 (mù cǎi) - wood* 行业 (xíng yè) - industry* 质量 (zhì yù) - quality* 受到 (shòu dào) - influenced by* 内部 (nèi bù) - inner* 缺陷 (jiǔ jī) - defects* 包括 (bāo gè) - including* 内部缺陷 (nèi bù jī jī) - inner defects* 由 (yù) - caused by* 树木 (shù mù) - trees* 支 (zhī) - branches* 生长 (shēng cháng) - growth* 成 (chéng) - formed* 内部缺陷 (nèi bù jī jī) - inner defects* 需要 (xū yào) - need* 使用 (shǐ yòng) - use* 昂贵 (áng jí) - expensive* 设备 (tiě bì) - equipment* X射验器 (X chū zhì qi) - X-ray scanner* Addressing (dào zhèng) - addressing* task (dao) - task* predicting (jì dì) - predicting* location (dì yì) - location* of (de) - of* inner defects (nèi bù jī jī) - inner defects* from (from) - from* the outer shape (wài xíng) - the outer shape* of the logs (de logs) - of the logs* Our dataset (wǒ de dataset) - our dataset* is built (is built) - is built* by extracting (by extracting) - by extracting* both (both) - both* the contours (the contours) - the contours* and the knots (and the knots) - and the knots* with X-ray measurements (with X-ray measurements) - with X-ray measurements* We propose (wǒ yù) - we propose* to solve (to solve) - to solve* this binary segmentation task (this binary segmentation task) - this binary segmentation task* by leveraging (by leveraging) - by leveraging* convolutional recurrent neural networks (convolutional recurrent neural networks) - convolutional recurrent neural networks* Once (once) - once* the neural network (the neural network) - the neural network* is trained (is trained) - is trained* inference can be performed (inference can be performed) - inference can be performed* from the outer shape (from the outer shape) - from the outer shape* measured with cheap devices (measured with cheap devices) - measured with cheap devices* such as laser profilers (such as laser profilers) - such as laser profilers* We demonstrate (wǒ yù) - we demonstrate* the effectiveness (the effectiveness) - the effectiveness* of our approach (of our approach) - of our approach* on fir (on fir) - on fir* and spruce (and spruce) - and spruce* tree species (tree species) - tree species* and perform ablation (and perform ablation) - and perform ablation* on the recurrence (on the recurrence) - on the recurrence* to demonstrate (to demonstrate) - to demonstrate* its importance (its importance) - its importance
</details></li>
</ul>
<hr>
<h2 id="ShadowNet-for-Data-Centric-Quantum-System-Learning"><a href="#ShadowNet-for-Data-Centric-Quantum-System-Learning" class="headerlink" title="ShadowNet for Data-Centric Quantum System Learning"></a>ShadowNet for Data-Centric Quantum System Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11290">http://arxiv.org/abs/2308.11290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Du, Yibo Yang, Tongliang Liu, Zhouchen Lin, Bernard Ghanem, Dacheng Tao<br>for: 这篇论文的目的是提出一种数据驱动学习方法，帮助解决大量量子系统的研究困难，尤其是量子状态实物探测和精确性评估等任务。methods: 这篇论文使用了神经网络协议和古典影子的方法，但这两种方法都有限制：前者受到预测不确定性的影响，后者则缺乏扩展能力。这篇论文提出了一个融合这两种方法的数据驱动学习模式，通过将古典影子与其他量子系统的轻松可取信息融合，创建训练数据集，然后让神经网络学习这个数据集中的对应规律。results: 这篇论文的结果显示，这个数据驱动学习模式可以在没有量子系统的资料时，通过训练神经网络，实现预测未见过的量子系统。此外，这个模式还具有快速适应和储存效率的特点，可以实现在大量量子系统中的应用。<details>
<summary>Abstract</summary>
Understanding the dynamics of large quantum systems is hindered by the curse of dimensionality. Statistical learning offers new possibilities in this regime by neural-network protocols and classical shadows, while both methods have limitations: the former is plagued by the predictive uncertainty and the latter lacks the generalization ability. Here we propose a data-centric learning paradigm combining the strength of these two approaches to facilitate diverse quantum system learning (QSL) tasks. Particularly, our paradigm utilizes classical shadows along with other easily obtainable information of quantum systems to create the training dataset, which is then learnt by neural networks to unveil the underlying mapping rule of the explored QSL problem. Capitalizing on the generalization power of neural networks, this paradigm can be trained offline and excel at predicting previously unseen systems at the inference stage, even with few state copies. Besides, it inherits the characteristic of classical shadows, enabling memory-efficient storage and faithful prediction. These features underscore the immense potential of the proposed data-centric approach in discovering novel and large-scale quantum systems. For concreteness, we present the instantiation of our paradigm in quantum state tomography and direct fidelity estimation tasks and conduct numerical analysis up to 60 qubits. Our work showcases the profound prospects of data-centric artificial intelligence to advance QSL in a faithful and generalizable manner.
</details>
<details>
<summary>摘要</summary>
大量量子系统的dinamics受到维度祸害。统计学学习提供了新的可能性，通过神经网络协议和类型暂影，然而这两种方法均有局限性：前者受到预测不确定性的困扰，后者缺乏泛化能力。我们提议一种数据驱动学习思维方式，结合这两种方法，以便推动多种量子学习任务（QSL）。特别是，我们的思维方式利用类型暂影和其他可见的量子系统信息，创建训练集，然后由神经网络学习探索QSL问题的下面规则。通过神经网络的泛化能力，这种思维方式可以在训练前线上进行offline训练，在推断阶段可以准确预测未经见过的系统，即使只有几个状态复制。此外，它继承了类型暂影的特点，具有储存效率和准确预测的特点。这些特点说明了我们提议的数据驱动方法在发现新的大规模量子系统方面的极大潜力。为了具体展示我们的思维方式，我们在量子状态探测和直接准确度估计任务中实现了这种思维方式，并进行了数值分析至60个量子比特。我们的工作展示了数据驱动人工智能在 faithful和泛化的方式下，进一步推动量子学习的前iers。
</details></li>
</ul>
<hr>
<h2 id="Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation"><a href="#Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation" class="headerlink" title="Test Time Embedding Normalization for Popularity Bias Mitigation"></a>Test Time Embedding Normalization for Popularity Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11288">http://arxiv.org/abs/2308.11288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ml-postech/tten">https://github.com/ml-postech/tten</a></li>
<li>paper_authors: Dain Kim, Jinhyeok Park, Dongwoo Kim</li>
<li>for: 本研究旨在解决推荐系统中的人気偏袋问题，即推荐结果受到item popularity的影响。</li>
<li>methods: 本研究提出了’Test Time Embedding Normalization’方法，它是一种简单 yet effective的方法，可以有效地减少人気偏袋的影响。该方法在推荐阶段使用 норmalized item embedding来控制 embedding magnitude的影响，其与item popularity高度相关。</li>
<li>results: 通过广泛的实验，本研究证明了我们的方法可以与之前的偏袋缓解方法相比，提高了推荐结果的准确性。此外，我们还发现了用户和项目 embedding之间的关系，angular similarity between embeddings可以分辨 preferable 和 non-preferable 的项目，不abhängigkeit von их popularity。这些分析解释了我们的方法如何成功地减少人気偏袋的影响。<details>
<summary>Abstract</summary>
Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.
</details>
<details>
<summary>摘要</summary>
受欢迎偏见是推荐系统领域中的一个广泛存在的问题，它导致受欢迎的项目在推荐结果中占据着主导地位。在这个工作中，我们提出了“测试时嵌入 normalization”作为一种简单 yet有效的策略来 Mitigate 受欢迎偏见，该策略在previous mitigation Approaches的性能上超过了很大的差。我们的方法利用了normalized item embedding During the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity。经过了广泛的实验，我们表明了我们的方法与sampled softmax loss combination 能够有效地减少受欢迎偏见，比之前的缓解方法更高效。我们进一步investigated the relationship between user and item embeddings and found that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity。这种分析解释了我们的方法在消除受欢迎偏见的机制。我们的代码可以在https://github.com/ml-postech/TTEN中找到。
</details></li>
</ul>
<hr>
<h2 id="CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation"><a href="#CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation" class="headerlink" title="CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation"></a>CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11277">http://arxiv.org/abs/2308.11277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernst Stötzner, Timo Homburg, Hubert Mara</li>
<li>for: 这篇论文是为了提供一种用于处理古代中东文明的数字工具，尤其是用于处理码iform文字，这种文字在陶 TABLETS上印刷了三千年以上，并且包含了许多不同的语言。</li>
<li>methods: 这篇论文使用了一种novel OCR-like方法来处理混合图像数据，包括将3D Rendering和摄影照片的标签转换到对应的3D模型上。它还使用了一个RepPoints探测器来预测文字的位置，并使用了GigaMesh的MSII基于曲线的呈现、Phong-shaded 3D模型和摄影照片，以及照明增强。</li>
<li>results: 根据结果，使用 Rendering 3D图像进行文字探测比使用摄影照片更好，而且这种方法在混合数据集上也表现良好。此外，使用Phong renderings和特别是MSII renderings可以提高摄影照片上的结果，这是全球规模最大的数据集。<details>
<summary>Abstract</summary>
Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D models, and photographs as well as illumination augmentation. The results show that using rendered 3D images for sign detection performs better than other work on photographs. In addition, our approach gives reasonably good results for photographs only, while it is best used for mixed datasets. More importantly, the Phong renderings, and especially the MSII renderings, improve the results on photographs, which is the largest dataset on a global scale.
</details>
<details>
<summary>摘要</summary>
受到古近东学界的挑战启发，我们开发了用于处理古代 кли牒文字的数字工具。这种3D文字印刷在泥 TABLETS上用于 более三千年和至少八种主要语言，它包含了数以千计的字符，其中一些在时间和空间上发生了变化。相比之下，图片是最常用于机器学习的表示方式，而墨渍绘制则容易被解释。我们使用的最佳3D数据集在可用。我们创建了HeiCuBeDa和MaiCuBeDa数据集，它们包含约500个注释的板。为了我们的新的OCR-like方法，我们提供了一个将3D渲染与图片之间的映射工具。我们使用的签名地址使用RepPoints探测器预测字符的位置。我们使用GigaMesh的MSII（曲率，请参考https://gigamesh.eu）基于的渲染、Phong灯光渲染和图片以及照明增强。结果表明，使用渲染的3D图像进行字符检测比其他工作更好。此外，我们的方法在图片只的情况下也能达到相对良好的结果，而且在混合数据集情况下表现最佳。特别是MSII渲染和Phong渲染在图片上提高了结果，这是全球规模最大的图片数据集。
</details></li>
</ul>
<hr>
<h2 id="FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning"><a href="#FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning" class="headerlink" title="FoX: Formation-aware exploration in multi-agent reinforcement learning"></a>FoX: Formation-aware exploration in multi-agent reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11272">http://arxiv.org/abs/2308.11272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghyeon Jo, Sunwoo Lee, Junghyuk Yum, Seungyul Han</li>
<li>for: 这篇论文的目的是解决多智能代理人学习（MARL）中的探索问题，因为代理人的partial observability和探索空间的增长会导致探索问题增加。</li>
<li>methods: 本文使用了一个formation-based equivalence relation来缩小探索空间，并提出了一个novel的formation-aware探索（FoX）框架，帮助部分可观代理人探索到不同的formation中的状态。</li>
<li>results: numerical results显示，提出的FoX框架在Google Research Football（GRF）和Sparse Starcraft II multi-agent challenge（SMAC）任务上明显超过了现有的MARL算法。<details>
<summary>Abstract</summary>
Recently, deep multi-agent reinforcement learning (MARL) has gained significant popularity due to its success in various cooperative multi-agent tasks. However, exploration still remains a challenging problem in MARL due to the partial observability of the agents and the exploration space that can grow exponentially as the number of agents increases. Firstly, in order to address the scalability issue of the exploration space, we define a formation-based equivalence relation on the exploration space and aim to reduce the search space by exploring only meaningful states in different formations. Then, we propose a novel formation-aware exploration (FoX) framework that encourages partially observable agents to visit the states in diverse formations by guiding them to be well aware of their current formation solely based on their own observations. Numerical results show that the proposed FoX framework significantly outperforms the state-of-the-art MARL algorithms on Google Research Football (GRF) and sparse Starcraft II multi-agent challenge (SMAC) tasks.
</details>
<details>
<summary>摘要</summary>
近些年来，深度多代理人学习（MARL）已经受到了各种合作多代理人任务中的成功，但是探索仍然是MARL中的挑战。这是因为代理人的部分可见性和代理人探索空间的快速增长，尤其是在代理人数量增加时。为解决探索空间的扩展性问题，我们定义了基于形态的相似关系在探索空间上，并尝试将搜索空间减少到有意义的状态。然后，我们提出了一种新的形态意识探索（FoX）框架，该框架鼓励部分可见的代理人访问不同形态中的状态，通过根据自己的观察来让代理人更加了解当前形态。 numerically results show that the proposed FoX framework significantly outperforms the state-of-the-art MARL algorithms on Google Research Football (GRF) and sparse Starcraft II multi-agent challenge (SMAC) tasks.
</details></li>
</ul>
<hr>
<h2 id="Quantum-Inspired-Machine-Learning-a-Survey"><a href="#Quantum-Inspired-Machine-Learning-a-Survey" class="headerlink" title="Quantum-Inspired Machine Learning: a Survey"></a>Quantum-Inspired Machine Learning: a Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11269">http://arxiv.org/abs/2308.11269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Larry Huynh, Jin Hong, Ajmal Mian, Hajime Suzuki, Yanqiu Wu, Seyit Camtepe</li>
<li>for: This survey provides an integrated and comprehensive examination of Quantum-inspired Machine Learning (QiML), exploring its diverse research domains and recent advancements, as well as showcasing practical applications and potential future research avenues.</li>
<li>methods: The survey covers a range of methods in QiML, including tensor network simulations and dequantized algorithms.</li>
<li>results: The survey provides a comprehensive overview of the current landscape of QiML, including recent advancements and potential future directions for research in this field.Here is the information in Simplified Chinese text:</li>
<li>for: 这份报告提供了量子概念Machine Learning（QiML）的全面和综合性评估，探讨其多样化的研究领域，包括维度网络仿真和量子化算法等，以及展示实际应用和未来研究方向。</li>
<li>methods: 报告覆盖了QiML中的多种方法，包括维度网络仿真和量子化算法等。</li>
<li>results: 报告提供了量子概念Machine Learning（QiML）当前的景观，包括最新的进展和未来研究方向。<details>
<summary>Abstract</summary>
Quantum-inspired Machine Learning (QiML) is a burgeoning field, receiving global attention from researchers for its potential to leverage principles of quantum mechanics within classical computational frameworks. However, current review literature often presents a superficial exploration of QiML, focusing instead on the broader Quantum Machine Learning (QML) field. In response to this gap, this survey provides an integrated and comprehensive examination of QiML, exploring QiML's diverse research domains including tensor network simulations, dequantized algorithms, and others, showcasing recent advancements, practical applications, and illuminating potential future research avenues. Further, a concrete definition of QiML is established by analyzing various prior interpretations of the term and their inherent ambiguities. As QiML continues to evolve, we anticipate a wealth of future developments drawing from quantum mechanics, quantum computing, and classical machine learning, enriching the field further. This survey serves as a guide for researchers and practitioners alike, providing a holistic understanding of QiML's current landscape and future directions.
</details>
<details>
<summary>摘要</summary>
量子机器学习（QiML）是一个快速发展的领域，在全球的研究者中受到广泛关注，因为它可以利用量子力学的原理在类别计算框架中进行应用。然而，当前的文献综述往往停留在更广泛的量子机器学习（QML）领域上，而不是深入探讨QiML。为了填补这一空白，本调查提供了一个整合和完整的量子机器学习的调查，探讨了QiML的多个研究领域，包括张量网络 simulations、dequantized算法和其他，展示了最新的进展、实践应用和未来研究方向。此外，本文还提供了一个具体的QiML定义，通过分析各种先前解释的term和其内在的歧义来确定。随着QiML的进一步发展，我们预计将有更多的未来发展，借鉴量子力学、量子计算和类别机器学习，使QiML更加丰富。本调查作为研究者和实践者的指南，提供了量子机器学习当前领域的整体认识和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes"><a href="#Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes" class="headerlink" title="Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes"></a>Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11267">http://arxiv.org/abs/2308.11267</a></li>
<li>repo_url: None</li>
<li>paper_authors: David M. Bossens</li>
<li>for: 本 paper 目的是提出两种基于 RCMDP 的算法，以提高 reinforcement learning 中的 robustness 和可靠性。</li>
<li>methods: 本 paper 使用了两种方法：RCPG with Robust Lagrangian 和 Adversarial RCPG。RCPG with Robust Lagrangian 是修改了 traditional RCPG 的方法，通过使用 Lagrangian 来计算 worst-case dynamics。Adversarial RCPG 则是通过 directly 和 incrementally 学习 adversarial policy 来提高 robustness。</li>
<li>results: 实验结果表明，本 paper 提出的两种算法在 inventory management 和 safe navigation 任务中具有竞争性的性能，并且比 traditional RCPG  variants 和非 robust 的 ablation 更高。尤其是 Adversarial RCPG，在所有测试中排名第二。<details>
<summary>Abstract</summary>
The robust constrained Markov decision process (RCMDP) is a recent task-modelling framework for reinforcement learning that incorporates behavioural constraints and that provides robustness to errors in the transition dynamics model through the use of an uncertainty set. Simulating RCMDPs requires computing the worst-case dynamics based on value estimates for each state, an approach which has previously been used in the Robust Constrained Policy Gradient (RCPG). Highlighting potential downsides of RCPG such as not robustifying the full constrained objective and the lack of incremental learning, this paper introduces two algorithms, called RCPG with Robust Lagrangian and Adversarial RCPG. RCPG with Robust Lagrangian modifies RCPG by taking the worst-case dynamics based on the Lagrangian rather than either the value or the constraint. Adversarial RCPG also formulates the worst-case dynamics based on the Lagrangian but learns this directly and incrementally as an adversarial policy through gradient descent rather than indirectly and abruptly through constrained optimisation on a sorted value list. A theoretical analysis first derives the Lagrangian policy gradient for the policy optimisation of both proposed algorithms and then the adversarial policy gradient to learn the adversary for Adversarial RCPG. Empirical experiments injecting perturbations in inventory management and safe navigation tasks demonstrate the competitive performance of both algorithms compared to traditional RCPG variants as well as non-robust and non-constrained ablations. In particular, Adversarial RCPG ranks among the top two performing algorithms on all tests.
</details>
<details>
<summary>摘要</summary>
RCMDP（Robust Constrained Markov Decision Process）是一种最近的任务建模框架，用于学习奖励学习，它包含行为约束和对过程动态模型的不确定性集。在计算 RCMDP 的 worst-case 动态时，需要根据每个状态的值估计来进行计算，这种方法曾经在 Robust Constrained Policy Gradient (RCPG) 中使用。然而，RCPG 存在一些缺点，如不能对完整的约束目标进行强化，以及不具备逐步学习的能力。这篇论文提出了两种算法，即 RCPG with Robust Lagrangian 和 Adversarial RCPG。RCPG with Robust Lagrangian 修改了 RCPG，通过使用 Lagrangian 而不是值或约束来计算 worst-case 动态。Adversarial RCPG 则通过直接和逐步地使用各元的敌对策略来学习 Lagrangian，而不是通过受限优化来 indirectly 和突然地修改 value 列表。这篇论文首先 derive Lagrangian 政策偏移量，然后是对 Adversarial RCPG 的敌对策略学习。实验表明，两种算法在具有扰动的 inventory management 和 safe navigation 任务中表现竞争性。特别是，Adversarial RCPG 在所有测试中排名第二。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games"><a href="#Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games" class="headerlink" title="Efficient Last-iterate Convergence Algorithms in Solving Games"></a>Efficient Last-iterate Convergence Algorithms in Solving Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11256">http://arxiv.org/abs/2308.11256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linjian Meng, Zhenxing Ge, Wenbin Li, Bo An, Yang Gao</li>
<li>for: 学习二人 zero-sum 正规形游戏（NFG）和广泛形游戏（EFG）中的 Nash 平衡（NE）。</li>
<li>methods: 使用 last-iterate convergence no-regret 算法，包括 Optimistic Gradient Descent Ascent（OGDA）和 Optimistic Multiplicative Weight Update（OMWU）。</li>
<li>results: 提出了一种 Reward Transformation（RT）框架，可以减少 OGDA 的每次迭代复杂性，并在不假设 NE 唯一的情况下保证 converge。但是，RT 基于的算法在同样的迭代次数下表现较差，而且其 convergence  garantuee 基于 continuous-time feedback 假设，不符合实际场景。通过对 RT 框架进行更深入的分析，我们发现 RT 框架可以将学习 NE 问题转化为一系列 strongly convex-concave 优化问题（SCCPs）。我们还设计了一种新的转换方法，使得 SCCPs 可以通过 Regret Matching+（RM+）算法解决，并且使得算法在离散时间反馈设定下 converge。实验结果表明，我们的算法在 existing last-iterate convergence 算法和 RM+（CFR+）上表现出色。<details>
<summary>Abstract</summary>
No-regret algorithms are popular for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs). Many recent works consider the last-iterate convergence no-regret algorithms. Among them, the two most famous algorithms are Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weight Update (OMWU). However, OGDA has high per-iteration complexity. OMWU exhibits a lower per-iteration complexity but poorer empirical performance, and its convergence holds only when NE is unique. Recent works propose a Reward Transformation (RT) framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU. Unfortunately, RT-based algorithms perform worse than OGDA under the same number of iterations, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios. To address these issues, we provide a closer analysis of the RT framework, which holds for both continuous and discrete-time feedback. We demonstrate that the essence of the RT framework is to transform the problem of learning NE in the original game into a series of strongly convex-concave optimization problems (SCCPs). We show that the bottleneck of RT-based algorithms is the speed of solving SCCPs. To improve the their empirical performance, we design a novel transformation method to enable the SCCPs can be solved by Regret Matching+ (RM+), a no-regret algorithm with better empirical performance, resulting in Reward Transformation RM+ (RTRM+). RTRM+ enjoys last-iterate convergence under the discrete-time feedback setting. Using the counterfactual regret decomposition framework, we propose Reward Transformation CFR+ (RTCFR+) to extend RTRM+ to EFGs. Experimental results show that our algorithms significantly outperform existing last-iterate convergence algorithms and RM+ (CFR+).
</details>
<details>
<summary>摘要</summary>
“调整算法”在二 player零差游戏（NFG）和延展游戏（EFG）中学习 Nash 均衡（NE）很受欢迎。多些最近的研究专注于最后迭代具有调整性的算法。其中最具名望的两个算法是Optimistic Gradient Descent Ascent（OGDA）和Optimistic Multiplicative Weight Update（OMWU）。但OGDA的每迭代复杂度高，OMWU具有较低的每迭代复杂度，但实际性较差，且它的均衡性只适用于当 NE 独特的情况。现有的工作提出了一个 Reward Transformation（RT）框架，用于MWU，可以将 NE 独特性的假设移除，并实现与 OMWU 的竞争性表现。但RT-based algorithms 在同一数量的迭代下表现较差，且其均衡保证基于紧急时间反馈假设，这不是大多数情况下的假设。为了解决这些问题，我们进行了更深入的 RT 框架分析，这个框架在紧急时间反馈下和离散时间反馈下都适用。我们证明了 RT 框架的核心是将原始游戏中学习 NE 的问题转换为一系列强弱点减游戏（SCCPs）。我们显示了 SCCPs 的瓶颈在 RT-based algorithms 中，以及如何使用 Regret Matching+（RM+）这个 no-regret 算法来解决这个问题。我们给出了一个新的变换方法，使得 SCCPs 可以使用 RM+ 来解决，从而获得 Reward Transformation RM+（RTRM+）。RTRM+ 在离散时间反馈下具有最后迭代均衡性。使用 counterfactual regret decomposition 框架，我们提出了 Reward Transformation CFR+（RTCFR+）来扩展 RTRM+ 到 EFGs。实验结果显示我们的算法在与现有的最后迭代均衡算法和 RM+（CFR+）进行比较时，具有更好的实际表现。”
</details></li>
</ul>
<hr>
<h2 id="A-survey-on-bias-in-machine-learning-research"><a href="#A-survey-on-bias-in-machine-learning-research" class="headerlink" title="A survey on bias in machine learning research"></a>A survey on bias in machine learning research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11254">http://arxiv.org/abs/2308.11254</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aastha2104/Parkinson-Disease-Prediction">https://github.com/Aastha2104/Parkinson-Disease-Prediction</a></li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Michał Grochowski</li>
<li>for: 本研究旨在强调机器学习中的偏见问题，而不仅仅是公平性。</li>
<li>methods: 本文提供了机器学习管道中偏见的多种可能来源和错误的数据和模型阶段的分类。</li>
<li>results: 本研究通过对四十多个机器学习管道中偏见的分析，提供了具体的示例，以便更好地理解和掌握机器学习中的偏见问题，并开发更公平、更透明、更准确的机器学习模型。<details>
<summary>Abstract</summary>
Current research on bias in machine learning often focuses on fairness, while overlooking the roots or causes of bias. However, bias was originally defined as a "systematic error," often caused by humans at different stages of the research process. This article aims to bridge the gap between past literature on bias in research by providing taxonomy for potential sources of bias and errors in data and models. The paper focus on bias in machine learning pipelines. Survey analyses over forty potential sources of bias in the machine learning (ML) pipeline, providing clear examples for each. By understanding the sources and consequences of bias in machine learning, better methods can be developed for its detecting and mitigating, leading to fairer, more transparent, and more accurate ML models.
</details>
<details>
<summary>摘要</summary>
当前的研究对机器学习中的偏见通常集中于公平性，而忽视了偏见的根源或原因。然而，偏见最初是定义为一种"系统性错误"，经常由人类在不同阶段的研究过程中引入。这篇文章试图 bridge 过去的Literature on bias在研究中的偏见，提供机器学习管道中可能的偏见和错误的分类。文章专注于机器学习管道中的偏见。survey分析了超过四十个机器学习管道中的偏见来源，并提供了明确的示例。通过理解机器学习中的偏见源头和后果，可以开发出更好的检测和缓解偏见方法，导致更公平、更透明和更准确的机器学习模型。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes"><a href="#Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes" class="headerlink" title="Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes"></a>Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11247">http://arxiv.org/abs/2308.11247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Fernandes Montesuma, Michela Mulas, Fred Ngolè Mboula, Francesco Corona, Antoine Souloumiac</li>
<li>for: 本研究旨在对过程监测中的故障诊断进行自动化，并使用机器学习来预测故障类型基于传感器读ings。</li>
<li>methods: 本研究使用单源隐式预测（SSDA）和多源隐式预测（MSDA）算法进行过程监测中的故障诊断，并在田东曼过程中进行了广泛的比较。</li>
<li>results: 研究结果表明，在多个源数据中训练时，使用多源隐式预测算法可以提高故障类型的预测精度，相比单源隐式预测算法，多源隐式预测算法在无适应情况下提高了平均23%的分类精度。此外，在多源数据中训练时，无适应情况下，多源隐式预测算法可以提高故障类型的预测精度8.4%的平均提升。<details>
<summary>Abstract</summary>
Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classification accuracy by 23% on average. In addition, under the multiple-sources scenario, we improve classification accuracy of the no adaptation setting by 8.4% on average.
</details>
<details>
<summary>摘要</summary>
检测 fault 是 proces supervision 中的一个重要组件。它可以确定已经检测到的 fault 类型，并且允许适当的 intervención。自动 fault 检测系统 使用机器学习来预测 fault 类型从 sensor 读数中。然而，这些模型对数据分布的变化敏感，这可能是由监测过程中的变化引起的，例如操作模式的变化。这种情况被称为 Cross-Domain Fault Diagnosis (CDFD)。我们提供了单和多源无监督领域适应 (SSDA 和 MSDA 分别) 算法的广泛比较，用于 CDFD。我们在 Tennessee-Eastmann 过程中进行研究，这是化学工业中 widely 使用的标准测试集。我们发现，在训练时使用多个领域可以提高分类精度，即使没有适应。因此，MSDA 基线比 SSDA 基线分类精度高出 23% 的平均值。此外，在多源enario 下，我们可以提高无适应设置的分类精度的平均值8.4%。
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification"><a href="#An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification" class="headerlink" title="An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification"></a>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11241">http://arxiv.org/abs/2308.11241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harunorikawano/speaker-identification-with-tgp">https://github.com/harunorikawano/speaker-identification-with-tgp</a></li>
<li>paper_authors: Harunori Kawano, Sota Shimizu</li>
<li>for: 这 paper 的目的是提出一种基于 Transformer 架构和自我超vised 学习的高效 speaker identification 模型。</li>
<li>methods: 该 paper 使用了 Transformer-based contextual model，并进行了参数与性能之间的关系研究，以探索一个有效的模型结构。此外， paper 还提出了 Temporal Gate Pooling（TGP）方法，可以增强 speaker identification 的学习能力。</li>
<li>results: 通过使用 Conformer 编码器和 BEST-RQ 预训练， authors 实现了一个准确率为 85.9%，参数量为 28.5M 的 speaker identification 模型，与 wav2vec2 的 317.7M 参数量相当。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/HarunoriKawano/speaker-identification-with-tgp">https://github.com/HarunoriKawano/speaker-identification-with-tgp</a> 上获取。<details>
<summary>Abstract</summary>
Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 85.9% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at https://github.com/HarunoriKawano/speaker-identification-with-tgp.
</details>
<details>
<summary>摘要</summary>
噪声2vec2在应用transformer架构和自动学习方法上取得了成功，现在不仅用于语音识别，还用于整个语音处理。这篇论文介绍了一种高效的端到端Speaker Identification模型，该模型基于Transformer-based contextual模型。我们研究了参数和性能之间的关系，以便理解有效模型的结构。此外，我们提出了一种强大学习能力的pooling方法：Temporal Gate Pooling。我们使用Conformer作Encoder，并在BEST-RQ上进行预训练，对VoxCeleb1中的Speaker Identification进行评估。我们的方法实现了85.9%的准确率， Parameters为28.5M，与wav2vec2的317.7M Parameters相比，表现相对较高。代码可以在https://github.com/HarunoriKawano/speaker-identification-with-tgp中找到。
</details></li>
</ul>
<hr>
<h2 id="Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features"><a href="#Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features" class="headerlink" title="Minwise-Independent Permutations with Insertion and Deletion of Features"></a>Minwise-Independent Permutations with Insertion and Deletion of Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11240">http://arxiv.org/abs/2308.11240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rameshwar Pratap, Raghav Kulkarni</li>
<li>for: 本研究的目的是研究在动态插入和删除特征的情况下，$\mathrm{minHash}$ 算法是否可以提供高效和精准的笛卡尔相似性计算。</li>
<li>methods: 本研究使用了动态插入和删除特征的 $\mathrm{minHash}$ 算法，并提出了一种基于随机排序的算法来使$\mathrm{minHash}$ 笛卡尔相似性计算更加高效和精准。</li>
<li>results: 本研究通过了一系列的实验和理论分析，证明了该算法在动态插入和删除特征的情况下可以具有显著的时间效益和相似性表现。<details>
<summary>Abstract</summary>
In their seminal work, Broder \textit{et. al.}~\citep{BroderCFM98} introduces the $\mathrm{minHash}$ algorithm that computes a low-dimensional sketch of high-dimensional binary data that closely approximates pairwise Jaccard similarity. Since its invention, $\mathrm{minHash}$ has been commonly used by practitioners in various big data applications. Further, the data is dynamic in many real-life scenarios, and their feature sets evolve over time. We consider the case when features are dynamically inserted and deleted in the dataset. We note that a naive solution to this problem is to repeatedly recompute $\mathrm{minHash}$ with respect to the updated dimension. However, this is an expensive task as it requires generating fresh random permutations. To the best of our knowledge, no systematic study of $\mathrm{minHash}$ is recorded in the context of dynamic insertion and deletion of features. In this work, we initiate this study and suggest algorithms that make the $\mathrm{minHash}$ sketches adaptable to the dynamic insertion and deletion of features. We show a rigorous theoretical analysis of our algorithms and complement it with extensive experiments on several real-world datasets. Empirically we observe a significant speed-up in the running time while simultaneously offering comparable performance with respect to running $\mathrm{minHash}$ from scratch. Our proposal is efficient, accurate, and easy to implement in practice.
</details>
<details>
<summary>摘要</summary>
它们的著名论文《CFM98》中，布罗德等人（Broder et al.)提出了一种低维度的$\mathrm{minHash}$算法，用于计算高维度二分类数据的紧密相似性。自其发明以来，$\mathrm{minHash}$在各种大数据应用中广泛使用。然而，在许多实际场景中，数据的特征集合会随着时间的推移而变化。我们考虑在数据集中动态插入和删除特征的情况。一个简单的解决方案是在更新后重新计算$\mathrm{minHash}$。然而，这是一项昂贵的任务，需要生成新的随机排序。到目前为止，我们未发现任何关于动态插入和删除特征的$\mathrm{minHash}$系统性研究。在这个研究中，我们开始了这个研究，并提出了一些使$\mathrm{minHash}$签名适应动态插入和删除特征的算法。我们进行了严格的理论分析，并通过多个实际数据集的实验观察，证明了我们的方法可以快速、精准地计算$\mathrm{minHash}$签名，同时保持与从scratch计算$\mathrm{minHash}$的性能相似。我们的提议是高效、准确、易于实现的。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment"><a href="#Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment" class="headerlink" title="Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment"></a>Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11220">http://arxiv.org/abs/2308.11220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toriqiu/fl-pcos">https://github.com/toriqiu/fl-pcos</a></li>
<li>paper_authors: Lucia Morris, Tori Qiu, Nikhil Raghuraman</li>
<li>for: 这个研究旨在应用 Federated Learning (FL) 技术来预测女性患有多囊淋巴综合症 (PCOS) 的最佳药物。</li>
<li>methods: 本研究使用了多种 Federated Learning 方法，包括 Federated Averaging (FedAvg)、Proximal Federated Learning (PFL) 和 Federated Transfer Learning (FTL)，并证明这些方法在人工生成的 PCOS 患者数据集上得到了成功。</li>
<li>results: 研究发现，这些 Federated Learning 方法可以在 accessed massive quantities of diverse data 中提供最佳的治疗选择，并为 PCOS 患者提供隐私保证。<details>
<summary>Abstract</summary>
The field of women's endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data. Valuable datapoints about hormone levels or menstrual cycling could expose patients who suffer from comorbidities or terminate a pregnancy, violating their privacy. We explore the application of Federated Learning (FL) to predict the optimal drug for patients with polycystic ovary syndrome (PCOS). PCOS is a serious hormonal disorder impacting millions of women worldwide, yet it's poorly understood and its research is stunted by a lack of patient data. We demonstrate that a variety of FL approaches succeed on a synthetic PCOS patient dataset. Our proposed FL models are a tool to access massive quantities of diverse data and identify the most effective treatment option while providing PCOS patients with privacy guarantees.
</details>
<details>
<summary>摘要</summary>
女性内分泌学领域落后于数据驱动医疗解决方案，主要是因为担心病人数据隐私问题。病人患有混合症或终止怀孕的情况可能会透露出有价值的内分泌水平或月经周期数据，违反病人隐私。我们研究了 Federated Learning（FL）的应用，以预测患有多囊卵巢综合症（PCOS）的女性患者需要哪种药物。PCOS 是全球数百万女性患有的严重内分泌疾病，但它的研究受到缺乏病人数据的限制。我们展示了多种 FL 方法在 sintetic PCOS 患者数据集上取得成功。我们提议的 FL 模型可以访问庞大的多样数据，并在保证病人隐私的情况下，为患有 PCOS 的女性患者预测最有效的治疗方案。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models"><a href="#Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models" class="headerlink" title="Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models"></a>Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11217">http://arxiv.org/abs/2308.11217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxiang Li, Zhaoxiang Hou, Hui Liu, Ying Wang, Tongzhi Li, Longfei Xie, Chao Shi, Chengyi Yang, Weishan Zhang, Zelei Liu, Liang Xu</li>
<li>for: 提出一种多模态联合学习框架，以帮助多家企业通过私有领域数据来共同训练大型模型，实现各种场景下的智能服务。</li>
<li>methods: 提出了多模态联合学习框架，包括智能基础和目标的战略转变，以及新的多样数据、模型聚合、性能和成本负担、数据隐私和奖励机制等挑战。</li>
<li>results: 通过实施多模态联合学习框架，企业可以增强和积累智能能力，共同创造智能城市模型，提供高质量智能服务，包括能源基础设施安全、住宅社区安全和城市运营管理。<details>
<summary>Abstract</summary>
Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. This paper proposes a multimodal federated learning framework that enables multiple enterprises to utilize private domain data to collaboratively train large models for vertical domains, achieving intelligent services across scenarios. The authors discuss in-depth the strategic transformation of federated learning in terms of intelligence foundation and objectives in the era of big model, as well as the new challenges faced in heterogeneous data, model aggregation, performance and cost trade-off, data privacy, and incentive mechanism. The paper elaborates a case study of leading enterprises contributing multimodal data and expert knowledge to city safety operation management , including distributed deployment and efficient coordination of the federated learning platform, technical innovations on data quality improvement based on large model capabilities and efficient joint fine-tuning approaches. Preliminary experiments show that enterprises can enhance and accumulate intelligent capabilities through multimodal model federated learning, thereby jointly creating an smart city model that provides high-quality intelligent services covering energy infrastructure safety, residential community security, and urban operation management. The established federated learning cooperation ecosystem is expected to further aggregate industry, academia, and research resources, realize large models in multiple vertical domains, and promote the large-scale industrial application of artificial intelligence and cutting-edge research on multimodal federated learning.
</details>
<details>
<summary>摘要</summary>
多modal数据，可以全面感受和认可物理世界，已成为通往通用人工智能的重要路径。然而，多modal大型模型在公共数据集上训练时经常下perform。这篇论文提出了一个多modal联合学习框架，允许多家企业使用私有领域数据共同训练大型模型，实现多场景智能服务。作者们详细讲解联合学习在智能基础和目标方面的战略转型，以及在不同数据和模型聚合、性能和成本权衡、数据隐私和奖励机制方面新出现的挑战。论文还介绍了一个城市安全运营管理案例研究，包括分布式部署和有效协调联合学习平台，以及基于大型模型能力的数据质量改进技术和有效联合精度调整方法。初步实验表明，企业可以通过多modal模型联合学习增强和积累智能能力，共同创建一个智能城市模型，提供高质量智能服务，涵盖能源基础设施安全、居民社区安全和城市运营管理。建立的联合学习合作生态系统预计会进一步吸引产业、学术和研究资源，实现多个垂直领域的大型模型，并推动人工智能的大规模工业应用和多modal联合学习的前沿研究。
</details></li>
</ul>
<hr>
<h2 id="Hamiltonian-GAN"><a href="#Hamiltonian-GAN" class="headerlink" title="Hamiltonian GAN"></a>Hamiltonian GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11216">http://arxiv.org/abs/2308.11216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/koritsky/hamiltonian_learning">https://github.com/koritsky/hamiltonian_learning</a></li>
<li>paper_authors: Christine Allen-Blanchette</li>
<li>for: 这个论文旨在使用 Hamiltonian  formalism 作为一种 физи学上有效的视频生成方法的 inductive bias。</li>
<li>methods: 该方法使用了一种叫做 Hamiltonian neural network 的 Motion Model，通过学习配置空间地图和 Hamiltonian 来学习一个可以表示配置空间的表示。</li>
<li>results: 该方法在使用 physics-inspired cyclic-coordinate loss function 进行训练后，能够在 Hamiltonian Dynamics Suite Toy Physics 数据集上实现更高的效果和可 interpretability。<details>
<summary>Abstract</summary>
A growing body of work leverages the Hamiltonian formalism as an inductive bias for physically plausible neural network based video generation. The structure of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and imposes a phase-space interpretation on the low-dimensional manifold underlying the input video. While this interpretation has the potential to facilitate the integration of learned representations in downstream tasks, existing methods are limited in their applicability as they require a structural prior for the configuration space at design time. In this work, we present a GAN-based video generation pipeline with a learned configuration space map and Hamiltonian neural network motion model, to learn a representation of the configuration space from data. We train our model with a physics-inspired cyclic-coordinate loss function which encourages a minimal representation of the configuration space and improves interpretability. We demonstrate the efficacy and advantages of our approach on the Hamiltonian Dynamics Suite Toy Physics dataset.
</details>
<details>
<summary>摘要</summary>
“一个增长中的研究利用哈密顿ormalism作为神经网络基于视频生成的假设逻辑。哈密顿结构保证学习的量（例如能量）的保守和要求输入视频的低维度抽象空间具有相位空间的解释，这有助于在下游任务中集成学习的表示。然而现有的方法有限于其应用，因为它们在设计时需要一个结构的假设 для配置空间。在这项工作中，我们提出了一个基于GAN的视频生成管线，使用学习的配置空间地图和哈密顿神经网络动力学模型来学习配置空间的表示。我们使用一种受物理灵感的循环坐标损失函数来驱动学习，这种损失函数鼓励最小化配置空间的表示，并提高可读性。我们在哈密顿动力学集 Toy Physics 数据集上证明了我们的方法的有效性和优势。”Note: Simplified Chinese is used in this translation, which is a more casual and widely-used version of Chinese. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling"><a href="#A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling" class="headerlink" title="A Simple Framework for Multi-mode Spatial-Temporal Data Modeling"></a>A Simple Framework for Multi-mode Spatial-Temporal Data Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11204">http://arxiv.org/abs/2308.11204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lzhmarkk/simmst">https://github.com/lzhmarkk/simmst</a></li>
<li>paper_authors: Zihang Liu, Le Yu, Tongyu Zhu, Leiei Sun</li>
<li>for: 本文旨在提出一种简单的多模式空间时间数据模型方法，以提高效率和效果的权衡。</li>
<li>methods: 本文提出了一种通用的对角模式空间关系学习组件，可以适应多种模式之间的连接和信息传递。此外，文章还使用多层感知器来捕捉时间相关性和通道相关性，技术上和概念上都非常简洁。</li>
<li>results: 实验结果表明，我们的模型可以在三个实际数据集上经常超越基线，并且具有较低的空间和时间复杂度。此外，通用的对角模式空间关系学习模块的一致性也得到了验证。<details>
<summary>Abstract</summary>
Spatial-temporal data modeling aims to mine the underlying spatial relationships and temporal dependencies of objects in a system. However, most existing methods focus on the modeling of spatial-temporal data in a single mode, lacking the understanding of multiple modes. Though very few methods have been presented to learn the multi-mode relationships recently, they are built on complicated components with higher model complexities. In this paper, we propose a simple framework for multi-mode spatial-temporal data modeling to bring both effectiveness and efficiency together. Specifically, we design a general cross-mode spatial relationships learning component to adaptively establish connections between multiple modes and propagate information along the learned connections. Moreover, we employ multi-layer perceptrons to capture the temporal dependencies and channel correlations, which are conceptually and technically succinct. Experiments on three real-world datasets show that our model can consistently outperform the baselines with lower space and time complexity, opening up a promising direction for modeling spatial-temporal data. The generalizability of the cross-mode spatial relationships learning module is also validated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting"><a href="#SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting" class="headerlink" title="SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting"></a>SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11200">http://arxiv.org/abs/2308.11200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Feiyu Zhao, Ruichao Mo, Haotong Zhang</li>
<li>for: 这 paper 是为了解决 RNN 在长期时间序列预测（LTSF）领域中遇到的挑战，特别是面临非常长的寻回窗口和预测范围。</li>
<li>methods: 这 paper 提出了两种新的策略来减少 RNN 在 LTSF 任务中的迭代次数：Segment-wise Iterations 和 Parallel Multi-step Forecasting（PMF）。这两种策略可以减少 RNN 的迭代次数，从而提高预测精度和执行速度。</li>
<li>results: 对比 SOTA Transformer-based 模型，SegRNN 能够显著提高预测精度和执行速度，同时减少了 runtime 和内存使用量，减少了超过 78%。这些成果证明 RNN 仍然在 LTSF 任务中具有优势，并促使更多的 RNN-based 方法在这个领域进行进一步的探索。<details>
<summary>Abstract</summary>
RNN-based methods have faced challenges in the Long-term Time Series Forecasting (LTSF) domain when dealing with excessively long look-back windows and forecast horizons. Consequently, the dominance in this domain has shifted towards Transformer, MLP, and CNN approaches. The substantial number of recurrent iterations are the fundamental reasons behind the limitations of RNNs in LTSF. To address these issues, we propose two novel strategies to reduce the number of iterations in RNNs for LTSF tasks: Segment-wise Iterations and Parallel Multi-step Forecasting (PMF). RNNs that combine these strategies, namely SegRNN, significantly reduce the required recurrent iterations for LTSF, resulting in notable improvements in forecast accuracy and inference speed. Extensive experiments demonstrate that SegRNN not only outperforms SOTA Transformer-based models but also reduces runtime and memory usage by more than 78%. These achievements provide strong evidence that RNNs continue to excel in LTSF tasks and encourage further exploration of this domain with more RNN-based approaches. The source code is coming soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs"><a href="#ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs" class="headerlink" title="ConcatPlexer: Additional Dim1 Batching for Faster ViTs"></a>ConcatPlexer: Additional Dim1 Batching for Faster ViTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11199">http://arxiv.org/abs/2308.11199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghoon Han, Seunghyeon Seo, Donghyeon Jeon, Jiho Jang, Chaerin Kong, Nojun Kwak</li>
<li>for: 降低计算成本，提高图像识别效率</li>
<li>methods: 使用额外维度批处理（ concatenation）和改进的图像多路径（Image Multiplexer），提高通过put和精度之间的平衡</li>
<li>results: 在ImageNet1K和CIFAR100 dataset上训练ConcatPlexer，相比ViT-B&#x2F;16，减少了23.5%的GFLOPs，并在验证集上达到69.5%和83.4%的验证精度I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Transformers have demonstrated tremendous success not only in the natural language processing (NLP) domain but also the field of computer vision, igniting various creative approaches and applications. Yet, the superior performance and modeling flexibility of transformers came with a severe increase in computation costs, and hence several works have proposed methods to reduce this burden. Inspired by a cost-cutting method originally proposed for language models, Data Multiplexing (DataMUX), we propose a novel approach for efficient visual recognition that employs additional dim1 batching (i.e., concatenation) that greatly improves the throughput with little compromise in the accuracy. We first introduce a naive adaptation of DataMux for vision models, Image Multiplexer, and devise novel components to overcome its weaknesses, rendering our final model, ConcatPlexer, at the sweet spot between inference speed and accuracy. The ConcatPlexer was trained on ImageNet1K and CIFAR100 dataset and it achieved 23.5% less GFLOPs than ViT-B/16 with 69.5% and 83.4% validation accuracy, respectively.
</details>
<details>
<summary>摘要</summary>
启发于语言模型的成本减少方法，我们提出了一种新的方法 для快速识别图像，即 concatenation 方法。我们首先介绍了图像多元化（Image Multiplexer），然后开发了新的组件以解决其缺陷，最终得到了 ConcatPlexer 模型。ConcatPlexer 模型在 ImageNet1K 和 CIFAR100 数据集上训练，并实现了与 ViT-B/16 相比的 23.5%  menos GFLOPs，同时保持了69.5% 和 83.4% 的验证精度。
</details></li>
</ul>
<hr>
<h2 id="Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation"><a href="#Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation" class="headerlink" title="Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation"></a>Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11197">http://arxiv.org/abs/2308.11197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamzeh Ghasemzadeh, Robert E. Hillman, Daryush D. Mehta</li>
<li>for: 提供量化证据，鼓励研究人员使用更加稳健的嵌套十字验证法。</li>
<li>methods: 使用 Monte Carlo 仿真和 Matlab 代码进行 ML 分析的力度分析，比较不同的十字验证方法（单个割裂、10-fold、训练-验证-测试和嵌套10-fold）的统计能力和统计信任度。</li>
<li>results: 结果显示，使用嵌套十字验证法可以获得最高的统计信任度和统计能力，并提供了不偏的准确率估计。相比之下，使用单个割裂法可能会过估准确率，需要50%更多的样本来达到同等的统计能力。<details>
<summary>Abstract</summary>
This study's first purpose is to provide quantitative evidence that would incentivize researchers to instead use the more robust method of nested cross-validation. The second purpose is to present methods and MATLAB codes for doing power analysis for ML-based analysis during the design of a study. Monte Carlo simulations were used to quantify the interactions between the employed cross-validation method, the discriminative power of features, the dimensionality of the feature space, and the dimensionality of the model. Four different cross-validations (single holdout, 10-fold, train-validation-test, and nested 10-fold) were compared based on the statistical power and statistical confidence of the ML models. Distributions of the null and alternative hypotheses were used to determine the minimum required sample size for obtaining a statistically significant outcome ({\alpha}=0.05, 1-\b{eta}=0.8). Statistical confidence of the model was defined as the probability of correct features being selected and hence being included in the final model. Our analysis showed that the model generated based on the single holdout method had very low statistical power and statistical confidence and that it significantly overestimated the accuracy. Conversely, the nested 10-fold cross-validation resulted in the highest statistical confidence and the highest statistical power, while providing an unbiased estimate of the accuracy. The required sample size with a single holdout could be 50% higher than what would be needed if nested cross-validation were used. Confidence in the model based on nested cross-validation was as much as four times higher than the confidence in the single holdout-based model. A computational model, MATLAB codes, and lookup tables are provided to assist researchers with estimating the sample size during the design of their future studies.
</details>
<details>
<summary>摘要</summary>
In simplified Chinese, the text might be translated as:这个研究的第一个目的是提供量化证据，以便激励研究人员使用更加稳定的嵌套十分之分验方法。第二个目的是向研究人员提供方法和MATLAB代码，以便在设计研究时进行能量分析。 Monte Carlo仿真被用来评估各种十分之分验方法的交互作用，包括单个停留、10个折衣、训练验证测试、嵌套10个折衣。研究发现，使用嵌套10个折衣方法可以获得最高的统计信任度和统计能力，而且可以提供不偏的准确率估计。单个停留方法的模型具有很低的统计信任度和统计能力，并且很大程度上过估了准确率。相比之下，使用嵌套10个折衣方法可以避免这些问题。这个研究提供了一个计算模型、MATLAB代码和查找表，以帮助研究人员在设计未来研究时估计样本大小。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models"><a href="#Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models" class="headerlink" title="Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models"></a>Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11192">http://arxiv.org/abs/2308.11192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srinjoy Das, Lawrence Rauchwerger</li>
<li>for: 加速 Machine Learning(ML) 和 Deep-Learning(DL) 模型的训练和执行，以提高性能和效率。</li>
<li>methods: 使用 Critical-Path-based Linear Clustering 方法，利用 ML 数据流图中的自然平行路径进行并行处理，并通过clone和常量传递来优化图结构。此外，我们还使用一个新建的工具 called {\bf Ramiel}，将 ML 模型转换成可读写并可执行的 Pytorch+Python 代码，以便利用其他下游加速技术。</li>
<li>results: 我们的实验结果表明，使用我们的方法可以在多个 ML 图中获得至多 1.9 倍的速度提升，并在 compile 和 runtime 中超越一些当前的机制。此外，我们的方法具有轻量级和快速的特点，适用于资源和电源受限的设备，同时仍能启用下游优化。<details>
<summary>Abstract</summary>
Several methods exist today to accelerate Machine Learning(ML) or Deep-Learning(DL) model performance for training and inference. However, modern techniques that rely on various graph and operator parallelism methodologies rely on search space optimizations which are costly in terms of power and hardware usage. Especially in the case of inference, when the batch size is 1 and execution is on CPUs or for power-constrained edge devices, current techniques can become costly, complicated or inapplicable. To ameliorate this, we present a Critical-Path-based Linear Clustering approach to exploit inherent parallel paths in ML dataflow graphs. Our task parallelization approach further optimizes the structure of graphs via cloning and prunes them via constant propagation and dead-code elimination. Contrary to other work, we generate readable and executable parallel Pytorch+Python code from input ML models in ONNX format via a new tool that we have built called {\bf Ramiel}. This allows us to benefit from other downstream acceleration techniques like intra-op parallelism and potentially pipeline parallelism. Our preliminary results on several ML graphs demonstrate up to 1.9$\times$ speedup over serial execution and outperform some of the current mechanisms in both compile and runtimes. Lastly, our methods are lightweight and fast enough so that they can be used effectively for power and resource-constrained devices, while still enabling downstream optimizations.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, but please note that the translation may not be perfect and may require some adjustments to accurately convey the intended meaning.)
</details></li>
</ul>
<hr>
<h2 id="Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries"><a href="#Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries" class="headerlink" title="Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries"></a>Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11189">http://arxiv.org/abs/2308.11189</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab-v2/diversity_measures">https://github.com/lab-v2/diversity_measures</a></li>
<li>paper_authors: Noel Ngu, Nathaniel Lee, Paulo Shakarian</li>
<li>for: 这篇论文是针对大型语言模型中的错误预测进行研究，特别是基于领域专门知识。</li>
<li>methods: 本文提出了基于对答几何的多元性来衡量错误的三种方法：基于熵、基于金尼逊级别和基于中心距离。</li>
<li>results: 本文通过多个数据集和温度设定的实验显示，这三种方法强相关于错误的可能性。此外，本文还提供了实践结果，说明了这些方法可以应用于几何问题、链式思维和错误检测。<details>
<summary>Abstract</summary>
Error prediction in large language models often relies on domain-specific information. In this paper, we present measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt - hence independent of the underlying application. We describe how three such measures - based on entropy, Gini impurity, and centroid distance - can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.
</details>
<details>
<summary>摘要</summary>
大型语言模型中的错误预测通常需要对特定领域的信息。在这篇文章中，我们提出了基于响应问题的多样性的评估方法，以独立于下游应用。我们详细描述了三种评估方法，包括基于熵、基于吉尼不纯度和中心距离。我们在多个数据集和温度设定下进行了一系列实验，以示这些评估方法与错误的机会强相关。此外，我们还提供了实践结果，详细介绍了如何将这些评估方法应用到几个问题、推理和错误检测。
</details></li>
</ul>
<hr>
<h2 id="A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology"><a href="#A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology" class="headerlink" title="A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology"></a>A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11179">http://arxiv.org/abs/2308.11179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibtihaj Ahmad, Syed Muhammad Israr, Zain Ul Islam</li>
<li>for: 这篇论文主要关注于电子显微镜中的细胞构成物分类和分 segmentation的问题，以协助电脑助癌诊断。</li>
<li>methods: 这篇论文使用了多个增强型深度学习模型，包括多个核心decoder head和独立的复杂损失函数，以解决电子显微镜中的挑战。</li>
<li>results: 这篇论文获得了高品质的分类和分 segmentation结果，包括0.841 dice score、0.713 bPQ score和0.633 mPQ score等。此外，这个框架可以在19种不同的组织中进行通用化。<details>
<summary>Abstract</summary>
Simultaneous segmentation and classification of nuclei in digital histology play an essential role in computer-assisted cancer diagnosis; however, it remains challenging. The highest achieved binary and multi-class Panoptic Quality (PQ) remains as low as 0.68 bPQ and 0.49 mPQ, respectively. It is due to the higher staining variability, variability across the tissue, rough clinical conditions, overlapping nuclei, and nuclear class imbalance. The generic deep-learning methods usually rely on end-to-end models, which fail to address these problems associated explicitly with digital histology. In our previous work, DAN-NucNet, we resolved these issues for semantic segmentation with an end-to-end model. This work extends our previous model to simultaneous instance segmentation and classification. We introduce additional decoder heads with independent weighted losses, which produce semantic segmentation, edge proposals, and classification maps. We use the outputs from the three-head model to apply post-processing to produce the final segmentation and classification. Our multi-stage approach utilizes edge proposals and semantic segmentations compared to direct segmentation and classification strategies followed by most state-of-the-art methods. Due to this, we demonstrate a significant performance improvement in producing high-quality instance segmentation and nuclei classification. We have achieved a 0.841 Dice score for semantic segmentation, 0.713 bPQ scores for instance segmentation, and 0.633 mPQ for nuclei classification. Our proposed framework is generalized across 19 types of tissues. Furthermore, the framework is less complex compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
计算机助enciaría的数字 histology 中的同时分割和分类问题具有重要的作用，但是它还是一个挑战。最高的二进制和多类 Panoptic Quality (PQ) 仍然为 0.68 bPQ 和 0.49 mPQ，分别。这是因为数字 histology 中的染色变化、组织内部的变化、临床条件不稳定、核体重叠和核类异质性等问题。通常的深度学习方法通常采用端到端模型，而这些模型无法直接解决数字 histology 中的这些问题。在我们之前的工作中，我们已经解决了这些问题，并在 DAN-NucNet 中提出了一种终端模型。这个工作是基于这个模型，并增加了一些额外的解码头，以生成 semantic segmentation、edge proposal 和分类图像。我们使用这些头的输出来进行后处理，以生成最终的分割和分类结果。我们的多阶段方法比较多样化，比如直接分割和分类策略，并且我们展示了一个显著的性能提高。我们在 19 种组织中实现了 0.841 Dice 分割率、0.713 bPQ 分割率和 0.633 mPQ 分类率。我们的提案的框架通过对 19 种组织进行扩展，并且比 state-of-the-art 更加简单。
</details></li>
</ul>
<hr>
<h2 id="A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks"><a href="#A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks" class="headerlink" title="A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks"></a>A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11162">http://arxiv.org/abs/2308.11162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abubakr Shafique, Ricardo Gonzalez, Liron Pantanowitz, Puay Hoon Tan, Alberto Machado, Ian A Cree, Hamid R. Tizhoosh</li>
<li>for: 这种研究旨在使用深度学习技术，对世界卫生组织乳腺癌分类（TCGA数据集）进行分类和检索。</li>
<li>methods: 研究人员使用了一种state-of-the-art的深度学习模型，通过对数百万个诊断 histopathology 图像进行预训练，提取了深度特征来visualize所有 sorts of tumor。</li>
<li>results: 研究人员发现，使用深度学习模型可以准确地检索和匹配罕见的乳腺癌种类，并且可以 investigating complex relationships among common and rare breast lesions。patch similarity search 的准确率达到了88%以上，并且使用 top-n tumor types 的验证率高达91%。<details>
<summary>Abstract</summary>
Breast cancer is one of the most common cancers affecting women worldwide. They include a group of malignant neoplasms with a variety of biological, clinical, and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attention for the computerized representation of medical images. Searchable digital atlases can provide pathologists with patch matching tools allowing them to search among evidently diagnosed and treated archival cases, a technology that may be regarded as computational second opinion. In this study, we indexed and analyzed the WHO breast taxonomy (Classification of Tumours 5th Ed.) spanning 35 tumour types. We visualized all tumour types using deep features extracted from a state-of-the-art deep learning model, pre-trained on millions of diagnostic histopathology images from the TCGA repository. Furthermore, we test the concept of a digital "atlas" as a reference for search and matching with rare test cases. The patch similarity search within the WHO breast taxonomy data reached over 88% accuracy when validating through "majority vote" and more than 91% accuracy when validating using top-n tumour types. These results show for the first time that complex relationships among common and rare breast lesions can be investigated using an indexed digital archive.
</details>
<details>
<summary>摘要</summary>
乳癌是全球女性中最常见的一种恶性肿瘤，其包括多种生物学、临床和 Histopathological 特征。存在超过35种乳腺病变型，可以根据细胞 morfology、生长和建筑模式进行分类和诊断。最近，人工智能领域的深度学习技术在医学图像计算方面吸引了很多关注，并在计算机化第二次诊断方面发挥了重要作用。在本研究中，我们对WHO乳腺分类（第五版）进行了索引和分析，覆盖了35种肿瘤类型。使用深度学习模型，我们将所有肿瘤类型视觉化，并使用从TCGA数据库中获得的数百万个诊断 histopathology 图像进行预处理。此外，我们测试了一种数字“图鉴”的概念，作为搜索和匹配罕见检测例的参考。在WHO乳腺分类数据集中进行质心 Similarity 搜索可达88%的准确率，并在“主要投票”验证方法下达到91%的准确率。这些结果表明，使用索引数字档案可以Investigate  Complex 乳腺病变之间的关系。
</details></li>
</ul>
<hr>
<h2 id="xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium"><a href="#xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium" class="headerlink" title="xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium"></a>xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11155">http://arxiv.org/abs/2308.11155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zpengmei/xxmd">https://github.com/zpengmei/xxmd</a></li>
<li>paper_authors: Zihan Pengmei, Junyu Liu, Yinan Shu</li>
<li>for: 这个论文旨在探讨神经力场（NFFs）在计算化学中作为参数模型，取代量子化学计算在初始态分子动力学中的地位。</li>
<li>methods: 该论文使用了非对易动力学方法，以获得更加精准的分子动力学数据。</li>
<li>results: 论文发现了MD17数据集的约束分布不足，导致其不适用于描述化学反应中的分子变形。该论文还引入了xxMD数据集，该数据集包括基于多参考波函数理论和density functional theory的能量和力学数据，并且更加 authentically depicts chemical reactions。<details>
<summary>Abstract</summary>
Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset and its subsequent extension. These datasets predominantly comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampling from direct adiabatic dynamics. However, many chemical reactions entail significant molecular deformations, notably bond breaking. We demonstrate the constrained distribution of internal coordinates and energies in the MD17 datasets, underscoring their inadequacy for representing systems undergoing chemical reactions. Addressing this sampling limitation, we introduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived from non-adiabatic dynamics. This dataset encompasses energies and forces ascertained from both multireference wave function theory and density functional theory. Furthermore, its nuclear configuration spaces authentically depict chemical reactions, making xxMD a more chemically relevant dataset. Our re-assessment of equivariant models on the xxMD datasets reveals notably higher mean absolute errors than those reported for MD17 and its variants. This observation underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability. Our proposed xxMD-CASSCF and xxMD-DFT datasets are available at \url{https://github.com/zpengmei/xxMD}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning"><a href="#Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning" class="headerlink" title="Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning"></a>Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11154">http://arxiv.org/abs/2308.11154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiucheng Wang, Hongzhi Guo</li>
<li>for:  automatize dirty, dangerous, and dull tasks with limited robot resources</li>
<li>methods:  mobile edge computing, mobility-aware deep reinforcement learning model for computing scheduling and resource allocation</li>
<li>results:  meet delay requirements, guarantee computation precision with minimum robot energy<details>
<summary>Abstract</summary>
Swarm robotics is envisioned to automate a large number of dirty, dangerous, and dull tasks. Robots have limited energy, computation capability, and communication resources. Therefore, current swarm robotics have a small number of robots, which can only provide limited spatio-temporal information. In this paper, we propose to leverage the mobile edge computing to alleviate the computation burden. We develop an effective solution based on a mobility-aware deep reinforcement learning model at the edge server side for computing scheduling and resource. Our results show that the proposed approach can meet delay requirements and guarantee computation precision by using minimum robot energy.
</details>
<details>
<summary>摘要</summary>
《群体机器人自动化技术》是旨在自动执行大量污 dirty、危险、无聊任务的。机器人具有有限的能量、计算能力和通信资源，因此当前的群体机器人只有少量机器人，可以提供有限的空间时间信息。在本文中，我们提议利用移动边缘计算来减轻计算负担。我们开发了基于移动性感知深度学习模型的Edge服务器端解决方案，以实现计算调度和资源分配。我们的结果显示，我们的方法可以遵循延迟要求，保证计算精度，并使用最小的机器人能量。
</details></li>
</ul>
<hr>
<h2 id="Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing"><a href="#Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing" class="headerlink" title="Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing"></a>Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11152">http://arxiv.org/abs/2308.11152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Flor Ortiz, Nicolas Skatchkovsky, Eva Lagunas, Wallace A. Martins, Geoffrey Eappen, Saed Daoud, Osvaldo Simeone, Bipin Rajendran, Symeon Chatzinotas</li>
<li>for: 本研究旨在应用能效的脑意传播模型来进行卫星通信（SatCom）系统中的无线资源管理。</li>
<li>methods: 本研究使用了复视预测（CNN）和脊搏神经网络（SNN）等机器学习（ML）技术，并进行了软件模拟和实验实践。</li>
<li>results: 比较 Convention CNN 和 SNN 的实验结果显示，在相关的工作负载下，SNN 在 Loihi 2 芯片上实现了更高的准确性，同时降低了电力消耗量超过 100 倍。这些结果显示了脑意 computing 和 SNN 在未来 SatCom 系统中的潜在潜力，并点出了这些技术在支持无线资源管理方面的应用前景。<details>
<summary>Abstract</summary>
The latest satellite communication (SatCom) missions are characterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning (ML)-based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks (CNN) on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks (SNNs) implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100$\times$ as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details>
<details>
<summary>摘要</summary>
最新的卫星通信（SatCom）任务 caracterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning（ML）based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks（CNN）on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks（SNNs）implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100 times as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details></li>
</ul>
<hr>
<h2 id="LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report"><a href="#LLaMA-Reviewer-Advancing-Code-Review-Automation-with-Large-Language-Models-through-Parameter-Efficient-Fine-Tuning-Practical-Experience-Report" class="headerlink" title="LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)"></a>LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning (Practical Experience Report)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11148">http://arxiv.org/abs/2308.11148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Lu, Lei Yu, Xiaojia Li, Li Yang, Chun Zuo</li>
<li>for:  automatización de tareas de revisión de código</li>
<li>methods:  utilización de modelos de lenguaje grande y técnicas de fine-tuning eficiente de parámetros</li>
<li>results:  iguala el rendimiento de modelos existentes de código de revisión con una base de datos pequeña y limitada cantidad de epochas de entrenamiento<details>
<summary>Abstract</summary>
The automation of code review activities, a long-standing pursuit in software engineering, has been primarily addressed by numerous domain-specific pre-trained models. Despite their success, these models frequently demand extensive resources for pre-training from scratch. In contrast, Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge. However, their potential for automating code review tasks remains largely unexplored.   In response to this research gap, we present LLaMA-Reviewer, an innovative framework that leverages the capabilities of LLaMA, a popular LLM, in the realm of code review. Mindful of resource constraints, this framework employs parameter-efficient fine-tuning (PEFT) methods, delivering high performance while using less than 1% of trainable parameters.   An extensive evaluation of LLaMA-Reviewer is conducted on two diverse, publicly available datasets. Notably, even with the smallest LLaMA base model consisting of 6.7B parameters and a limited number of tuning epochs, LLaMA-Reviewer equals the performance of existing code-review-focused models.   The ablation experiments provide insights into the influence of various fine-tuning process components, including input representation, instruction tuning, and different PEFT methods. To foster continuous progress in this field, the code and all PEFT-weight plugins have been made open-source.
</details>
<details>
<summary>摘要</summary>
自动化代码审查活动，软件工程中长期追求的问题，主要通过许多域специфи的预训模型解决。尽管它们获得了成功，但它们经常需要大量的资源进行预训。相比之下，大型语言模型（LLM）提供了一个吸引人的代替方案，因为它们在域специфи知识的支持下表现出了惊人的能力。然而，它们在代码审查任务上的潜在作用仍然未得到了充分的探索。为了解决这个研究空白，我们介绍了 LLama Reviewer，一个创新的框架，利用 LLama 语言模型在代码审查中的能力。注意资源限制，这个框架使用了 parameter-efficient fine-tuning（PEFT）方法，以提高性能，同时使用的可调参数少于 1%。我们对 LLama Reviewer 进行了广泛的评估，使用了两个公开available的数据集。结果显示，即使使用 LLama 基础模型的最小版本（6.7B参数）和有限制的调教 epoch，LLama Reviewer 与现有的代码审查专注模型表现相同。我们还进行了一系列的减少实验，以了解不同的精细调教过程组件的影响，包括输入表示、指令调教和不同的 PEFT 方法。为了促进这个领域的不断发展，我们将代码和所有 PEFT-weight 插件公开发布。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps"><a href="#Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps" class="headerlink" title="Exploring Unsupervised Cell Recognition with Prior Self-activation Maps"></a>Exploring Unsupervised Cell Recognition with Prior Self-activation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11144">http://arxiv.org/abs/2308.11144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cpystan/psm">https://github.com/cpystan/psm</a></li>
<li>paper_authors: Pingyi Chen, Chenglu Zhu, Zhongyi Shui, Jiatong Cai, Sunyi Zheng, Shichuan Zhang, Lin Yang</li>
<li>for: 提高cell recognition任务中supervised deep learning模型的成功率，减少标注成本。</li>
<li>methods: 使用自我活化图（PSM）生成 Pseudo 面积标注，通过自动学习训练 activation network 生成 PSM，然后通过semantic clustering模块将 PSM 转换为像素级别的semantic pseudo mask。</li>
<li>results: 在两个 histological 数据集（MoNuSeg 和 BCData）上评估了我们的方法，与其他完全超vised 和弱supervised 方法相比，我们的方法可以实现竞争性的性能，而无需任何手动标注。我们的简单 yet effective 框架还可以实现多类细胞检测，其他无supervised 方法无法完成这一点。结果表明 PSM 的潜在价值，可能会激励其他研究人员在医疗领域尝试解决标注的问题。<details>
<summary>Abstract</summary>
The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. To this end, we explored label-free methods for cell recognition. Prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. To be specific, an activation network is trained with self-supervised learning. The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. Afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets: MoNuSeg (cell segmentation) and BCData (multi-class cell detection). Compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. Our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. The results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.
</details>
<details>
<summary>摘要</summary>
success of supervised deep learning models on cell recognition tasks rely on detailed annotations. many previous works have managed to reduce the dependency on labels. however, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. to this end, we explored label-free methods for cell recognition. prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. to be specific, an activation network is trained with self-supervised learning. the gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. we evaluated our method on two histological datasets: monunseg (cell segmentation) and bcdata (multi-class cell detection). compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. the results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.Note that Simplified Chinese is used here, as it is the more commonly used standard for Chinese translation. Traditional Chinese is also an option, but it may be less widely understood by some readers. Let me know if you would like me to translate the text into Traditional Chinese instead.
</details></li>
</ul>
<hr>
<h2 id="Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions"><a href="#Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions" class="headerlink" title="Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions"></a>Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11142">http://arxiv.org/abs/2308.11142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rhys Tracy, Haotian Xia, Alex Rasla, Yuan-Fang Wang, Ambuj Singh</li>
<li>for: 本研究旨在提高复杂排球预测精度，为教练和运动员提供更加有意义的洞察。</li>
<li>methods: 我们引入专门的图编码技术，为已有的排球数据添加了额外的接触接触排球上下文。我们使用图神经网络（GNNs）进行三个不同的排球预测任务：落点预测、场地预测和击球类型预测。</li>
<li>results: 我们的图基模型比基线模型表现更出色，在落点预测、场地预测和击球类型预测等三个任务上显著提高了预测结果。此外，我们还发现了一些简单的调整，如移除封锁的击球，可以显著提高预测结果。最后，我们展示了选择合适的模型结构对于某个任务的预测结果具有重要的作用。总的来说，我们的研究表明使用图编码在运动数据分析中具有极大的潜力，并希望未来的机器学习策略在运动和应用中使用图基编码。<details>
<summary>Abstract</summary>
This research aims to improve the accuracy of complex volleyball predictions and provide more meaningful insights to coaches and players. We introduce a specialized graph encoding technique to add additional contact-by-contact volleyball context to an already available volleyball dataset without any additional data gathering. We demonstrate the potential benefits of using graph neural networks (GNNs) on this enriched dataset for three different volleyball prediction tasks: rally outcome prediction, set location prediction, and hit type prediction. We compare the performance of our graph-based models to baseline models and analyze the results to better understand the underlying relationships in a volleyball rally. Our results show that the use of GNNs with our graph encoding yields a much more advanced analysis of the data, which noticeably improves prediction results overall. We also show that these baseline tasks can be significantly improved with simple adjustments, such as removing blocked hits. Lastly, we demonstrate the importance of choosing a model architecture that will better extract the important information for a certain task. Overall, our study showcases the potential strengths and weaknesses of using graph encodings in sports data analytics and hopefully will inspire future improvements in machine learning strategies across sports and applications by using graphbased encodings.
</details>
<details>
<summary>摘要</summary>
（简化中文）这项研究的目标是提高复杂的排球预测精度并为教练和运动员提供更深刻的意义。我们引入特殊的图编码技术，以添加更多的接触点排球上下文到现有的排球数据集中，而无需收集更多数据。我们示出了使用图神经网络（GNNs）在这种增强的数据集上进行三种不同的排球预测任务：落点预测、场地预测和击打类型预测。我们与基线模型进行比较，分析结果以更好地理解排球落点中的下面关系。我们的结果表明，使用GNNs与我们的图编码可以提供更高级的数据分析，显著提高预测结果总体。我们还示出了可以通过简单的调整，如移除封锁的击球，提高基线任务的性能。最后，我们表明了选择合适的模型结构，可以更好地提取关键信息，以便更好地完成特定任务。总之，我们的研究展示了使用图编码在体育数据分析中的潜在优势和不足，希望能启发未来的机器学习策略的改进，以及在体育和应用程序中使用图基于编码。
</details></li>
</ul>
<hr>
<h2 id="Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems"><a href="#Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems" class="headerlink" title="Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems"></a>Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11137">http://arxiv.org/abs/2308.11137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Hojoon Lee, Dongyoon Hwang, Kyushik Min, Jaegul Choo</li>
<li>for: 这个论文的目的是为了评估基于奖励学习（RL）的推荐系统在互动过程中的性能。</li>
<li>methods: 论文使用了公共可用的评价数据集来比较和评估不同的算法。</li>
<li>results: 研究发现，简单的资产奖励模型在长期效果方面一直表现出优异，而RL基本模型在评价数据集上表现较差。此外，研究还发现，在评价数据集上，用户的反馈具有较少的长期效果。<details>
<summary>Abstract</summary>
Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects of the IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to a degradation of recommendation performance. Third, user feedbacks have mere long-term effects on the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>一个简单的奖励模型在累绩奖励方面一直表现出色，常常高于 RL-based 模型。2. 将更高的权重传递到长期奖励导致推荐性能下降。3. 在评价数据上，用户的反馈仅具有微不足道的长期影响。根据我们的发现，我们结论是，一个数据集需要仔细验证，而且一个简单的奖励基准应该包括在评估 RL-based IRS 方法的评估中。</details></li>
</ol>
<hr>
<h2 id="Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances"><a href="#Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances" class="headerlink" title="Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances"></a>Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11129">http://arxiv.org/abs/2308.11129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuankai Luo</li>
<li>for: 本研究旨在提高现有图Transformer的表现，通过设计一种基于层次距离的结构编码方法（HDSE），以适应不同类型的图像处理任务。</li>
<li>methods: 本研究使用的方法包括HDSE方法和现有的位置表示方法的综合应用，以捕捉图像中的多层次、层次结构。</li>
<li>results: 经过广泛的实验 validate，HDSE方法能够在12种实际 dataset上提高多种基eline transformer的表现，达到了10个benchmark dataset的状态时表现。<details>
<summary>Abstract</summary>
Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current proposals rarely address methods capturing longer ranges, hierarchical structures, or community structures, as they appear in various graphs such as molecules, social networks, and citation networks. In this paper, we propose a hierarchy-distance structural encoding (HDSE), which models a hierarchical distance between the nodes in a graph focusing on its multi-level, hierarchical nature. In particular, this yields a framework which can be flexibly integrated with existing graph transformers, allowing for simultaneous application with other positional representations. Through extensive experiments on 12 real-world datasets, we demonstrate that our HDSE method successfully enhances various types of baseline transformers, achieving state-of-the-art empirical performances on 10 benchmark datasets.
</details>
<details>
<summary>摘要</summary>
图形转换器需要强大的推导性偏好，以获得有意义的注意分数。然而，当前的建议通常不会考虑 capture longer ranges, hierarchical structures 或 community structures, 这些结构在分子、社交网络和引用网络等图形中都存在。在这篇论文中，我们提出了一种层次距离结构编码（HDSE），它模型了图形中节点之间的层次距离，特别是这些距离的多层、层次结构。因此，我们的 HDSE 方法可以与现有的图形转换器集成，以同时应用其他位置表示。通过对 12 个真实世界数据集进行了广泛的实验，我们示出了 HDSE 方法可以成功地提高多种基eline transformers，在 10 个标准测试集上达到了最佳的实验性能。
</details></li>
</ul>
<hr>
<h2 id="How-Expressive-are-Graph-Neural-Networks-in-Recommendation"><a href="#How-Expressive-are-Graph-Neural-Networks-in-Recommendation" class="headerlink" title="How Expressive are Graph Neural Networks in Recommendation?"></a>How Expressive are Graph Neural Networks in Recommendation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11127">http://arxiv.org/abs/2308.11127</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkuds/gte">https://github.com/hkuds/gte</a></li>
<li>paper_authors: Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang</li>
<li>for: 这篇论文主要针对推荐问题的Graph Neural Networks（GNNs）表现能力进行了系统的理论分析，以强化GNNs在推荐 task中的表现。</li>
<li>methods: 该论文使用了三种表达能力指标：图同构（graph-level）、节点自同构（node-level）和结构靠近性（link-level），其中结构靠近性指标是专门为推荐任务设计的，能够评估GNNs在推荐任务中表现的准确性。</li>
<li>results: 该论文通过对多种现有GNN模型进行比较，证明了结构靠近性指标在评估GNNs在推荐任务中表现的效果。此外，该论文还提出了一种学习无关的GNN算法，可以在结构靠近性指标下达到优化的表现。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have demonstrated superior performance on various graph learning tasks, including recommendation, where they leverage user-item collaborative filtering signals in graphs. However, theoretical formulations of their capability are scarce, despite their empirical effectiveness in state-of-the-art recommender models. Recently, research has explored the expressiveness of GNNs in general, demonstrating that message passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that GNNs combined with random node initialization are universal. Nevertheless, the concept of "expressiveness" for GNNs remains vaguely defined. Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness. In this paper, we provide a comprehensive theoretical analysis of the expressiveness of GNNs in recommendation, considering three levels of expressiveness metrics: graph isomorphism (graph-level), node automorphism (node-level), and topological closeness (link-level). We propose the topological closeness metric to evaluate GNNs' ability to capture the structural distance between nodes, which aligns closely with the objective of recommendation. To validate the effectiveness of this new metric in evaluating recommendation performance, we introduce a learning-less GNN algorithm that is optimal on the new metric and can be optimal on the node-level metric with suitable modification. We conduct extensive experiments comparing the proposed algorithm against various types of state-of-the-art GNN models to explore the explainability of the new metric in the recommendation task. For reproducibility, implementation codes are available at https://github.com/HKUDS/GTE.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 已经在不同的图学任务上展现出优秀的性能，包括推荐，其中利用用户Item的协同过滤信号在图中。然而，GNNs的理论表述还很缺乏，尽管它们在现有的推荐模型中的实际效果很高。最近，研究人员开始探索GNNs的表达能力，并证明了消息传递GNNs在最多情况下与维氏-莱曼测试相当强大，并且GNNs与随机节点初始化结合起来是 universally expressive。然而，GNNs的“表达能力”概念仍然很模糊。大多数现有的工作采用图 isomorphism test作为表达能力的度量，但这可能不能有效地评估一个模型在推荐任务中的能力，因为推荐任务的目标是将节点分类为不同的靠近程度。在这篇论文中，我们提供了对GNNs在推荐任务中表达能力的全面性分析，包括图 isomorphism（图级），节点自身omorphism（节点级）和 topological closeness（链级）三种表达能力度量。我们提出了 topological closeness 度量，以评估 GNNs 在不同节点之间的结构距离，这与推荐任务的目标很 closely align。为验证这个新的度量在推荐任务中的效用，我们引入了一种不含学习的 GNN 算法，该算法在新的度量上是优化的，并且可以通过修改来在节点级度量上达到优化。我们对多种现有的 state-of-the-art GNN 模型进行了广泛的比较，以探索这个新的度量在推荐任务中的解释性。为保持可重现性，我们在 GitHub 上提供了实现代码，可以在 https://github.com/HKUDS/GTE 中找到。
</details></li>
</ul>
<hr>
<h2 id="Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection"><a href="#Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection" class="headerlink" title="Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection"></a>Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11119">http://arxiv.org/abs/2308.11119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Tamura</li>
<li>for: 这个研究是为了开发一个基于 CLIP 的零数据Point Anomaly Detection 方法。</li>
<li>methods: 这个方法使用 CLIP 的显示语言模型来生成图像中的文本嵌入，并使用这些嵌入进行类别。</li>
<li>results: 实验结果显示，这个方法可以在零数据情况下 дости持state-of-the-art表现，并且不需要传入任何训练图像。<details>
<summary>Abstract</summary>
This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLIP with typical prompts that include words of normal and anomaly. In addition to these words, we insert several randomly generated words into prompts, which enables the encoder to generate a diverse set of normal and anomalous samples. Using the generated embeddings as training data, a feed-forward neural network learns to extract features of normal and anomaly from CLIP's embeddings, and as a result, a category-agnostic anomaly detector can be obtained without any training images. Experimental results demonstrate that our method achieves state-of-the-art performance without laborious prompt ensembling in zero-shot setups.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文提出了一种新的方法，利用视觉语言模型CLIP作为数据源，实现零例异常检测。因为异常样本很难获得，现有的方法通常只使用正常样本进行训练，并在推理时对正常样本的分布进行评估，这需要对每个物体类型进行训练。这种不fficient的训练方式被解决了，通过使用CLIP中的提示引导分类来对每个图像中的每个部分进行滑动窗口 manner进行异常检测。然而，这种方法仍然受到提示的精心组合的压力。为了解决以上问题，我们提议利用CLIP作为训练数据源。我们的方法生成了文本嵌入，使用CLIP中的文本编码器，并使用典型的提示，包括正常和异常的词语。此外，我们还在提示中插入了一些随机生成的词语，使编码器生成的嵌入集是多样的正常和异常样本。使用生成的嵌入作为训练数据，一个卷积神经网络学习提取CLIP的嵌入中的正常和异常特征，从而实现了没有任何训练图像的类型无关异常检测器。实验结果表明，我们的方法在零例设置下达到了状态的艺术性表现，无需劳累的提示组合。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models"><a href="#Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models" class="headerlink" title="Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models"></a>Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11112">http://arxiv.org/abs/2308.11112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hajimesuzuki999/qpf">https://github.com/hajimesuzuki999/qpf</a></li>
<li>paper_authors: Farina Riaz, Shahab Abdulla, Hajime Suzuki, Srinjoy Ganguly, Ravinesh C. Deo, Susan Hopkins</li>
<li>for: 提高图像分类模型的准确率</li>
<li>methods: 使用量子预处理筛选器（QPF），应用于图像分类模型中</li>
<li>results: 对于MNIST和EMNIST dataset，使用QPF提高了图像分类精度，从92.5%提高到95.4%和从68.9%提高到75.9%，而不需要额外的模型参数或优化。但是在GTSRB dataset上，使用QPF显示了一个较大的下降。<details>
<summary>Abstract</summary>
This paper proposes a novel quantum pre-processing filter (QPF) to improve the image classification accuracy of neural network (NN) models. A simple four qubit quantum circuit that uses Y rotation gates for encoding and two controlled NOT gates for creating correlation among the qubits is applied as a feature extraction filter prior to passing data into the fully connected NN architecture. By applying the QPF approach, the results show that the image classification accuracy based on the MNIST (handwritten 10 digits) and the EMNIST (handwritten 47 class digits and letters) datasets can be improved, from 92.5% to 95.4% and from 68.9% to 75.9%, respectively. These improvements were obtained without introducing extra model parameters or optimizations in the machine learning process. However, tests performed on the developed QPF approach against a relatively complex GTSRB dataset with 43 distinct class real-life traffic sign images showed a degradation in the classification accuracy. Considering this result, further research into the understanding and the design of a more suitable quantum circuit approach for image classification neural networks could be explored utilizing the baseline method proposed in this paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CAME-Contrastive-Automated-Model-Evaluation"><a href="#CAME-Contrastive-Automated-Model-Evaluation" class="headerlink" title="CAME: Contrastive Automated Model Evaluation"></a>CAME: Contrastive Automated Model Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11111">http://arxiv.org/abs/2308.11111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pengr/contrastive_autoeval">https://github.com/pengr/contrastive_autoeval</a></li>
<li>paper_authors: Ru Peng, Qiuyang Duan, Haobo Wang, Jiachen Ma, Yanbo Jiang, Yongjun Tu, Xiu Jiang, Junbo Zhao</li>
<li>for: 评估已经训练的机器学习模型的性能，无需使用标注的测试集。</li>
<li>methods: 提出了一种新的自动评估框架，即对比自动评估（CAME），不再需要使用训练集。基于理论分析和广泛的实验验证，CAME可以在无标注测试集的情况下建立模型性能和对比损失之间的可预测关系。</li>
<li>results: CAME在自动评估领域的新标准时间（SOTA）Result，舒过先前的工作。<details>
<summary>Abstract</summary>
The Automated Model Evaluation (AutoEval) framework entertains the possibility of evaluating a trained machine learning model without resorting to a labeled testing set. Despite the promise and some decent results, the existing AutoEval methods heavily rely on computing distribution shifts between the unlabelled testing set and the training set. We believe this reliance on the training set becomes another obstacle in shipping this technology to real-world ML development. In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop. The core idea of CAME bases on a theoretical analysis which bonds the model performance with a contrastive loss. Further, with extensive empirical validation, we manage to set up a predictable relationship between the two, simply by deducing on the unlabeled/unseen testing set. The resulting framework CAME establishes a new SOTA results for AutoEval by surpassing prior work significantly.
</details>
<details>
<summary>摘要</summary>
自动模型评估（AutoEval）框架考虑不使用标注测试集来评估训练完成的机器学习模型。尽管存在承诺和一些不错的结果，现有的AutoEval方法仍然很重要地依赖于计算测试集和训练集之间的分布差异。我们认为，这种依赖于训练集会成为实际机器学习开发中这种技术的又一个障碍。在这种工作中，我们提出了对比自动模型评估（CAME）框架，它不再依赖于训练集。CAME框架的核心思想是基于一种理论分析，它将模型性能与对比损失相关联。然后，通过广泛的实验验证，我们成功地建立了测试集中未经标注的模型性能和对比损失之间的可预测关系。这种关系的建立使得CAME框架可以超越现有的AutoEval方法，并设置新的最高纪录（SOTA）。
</details></li>
</ul>
<hr>
<h2 id="Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models"><a href="#Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models" class="headerlink" title="Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models"></a>Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11103">http://arxiv.org/abs/2308.11103</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models">https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models</a></li>
<li>paper_authors: Alex Nyffenegger, Matthias Stürmer, Joel Niklaus</li>
<li>for:  This paper aims to explore the potential of large language models (LLMs) to re-identify individuals in court rulings, with a focus on the Federal Supreme Court of Switzerland.</li>
<li>methods:  The authors constructed a proof-of-concept using actual legal data from the Swiss federal supreme court and an anonymized Wikipedia dataset to investigate the feasibility of re-identifying individuals using LLMs. They introduced new metrics to measure performance and systematically analyzed the factors that influence successful re-identifications.</li>
<li>results:  Despite high re-identification rates on Wikipedia, the authors found that even the best LLMs struggled with court decisions, attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification. The study demonstrates that re-identification using LLMs may not be feasible for now, but it might become possible in the future.<details>
<summary>Abstract</summary>
Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions. The complexity is attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification. In conclusion, this study demonstrates that re-identification using LLMs may not be feasible for now, but as the proof-of-concept on Wikipedia showed, it might become possible in the future. We hope that our system can help enhance the confidence in the security of anonymized decisions, thus leading to the courts being more confident to publish decisions.
</details>
<details>
<summary>摘要</summary>
欧盟和瑞士的法院判决中的自然人和法人匿名性是隐私保护的关键方面。随着LLM的出现，大规模重新标识匿名人士的问题减少。根据瑞士联邦最高法院的规定，我们在实际的法院判决数据上进行了证明。然后，我们使用了一个更加严格的Wikipedia数据集进行进一步的研究。我们将重新标识文本中的人员为新任务，并引入了新的评价指标。我们系统地分析了重要因素的影响，包括模型大小、输入长度和调整指南。尽管在Wikipedia上达到了高重新标识率，但是even the best LLMs在法院判决上遇到了困难。这种复杂性归结于缺乏测试集，需要巨量的训练资源以及重要的数据稀缺。因此，本研究表明，使用LLM重新标识可能不可能现在，但是在未来可能变得可能。我们希望通过我们的系统，增强对匿名判决的信任，使法院更自信地发布判决。
</details></li>
</ul>
<hr>
<h2 id="Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks"><a href="#Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks" class="headerlink" title="Explicability and Inexplicability in the Interpretation of Quantum Neural Networks"></a>Explicability and Inexplicability in the Interpretation of Quantum Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11098">http://arxiv.org/abs/2308.11098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lirandepira/interpret-qnn">https://github.com/lirandepira/interpret-qnn</a></li>
<li>paper_authors: Lirandë Pira, Chris Ferrie</li>
<li>for: 本研究旨在探讨量子神经网络的解释性，以帮助建立可信任的量子AI系统。</li>
<li>methods: 本研究使用了本地模型无关解释性度量来研究量子和类传统神经网络的解释性。它还 introduce了带宽不可解释区（band of inexplicability），表示无法解释的数据样本。</li>
<li>results: 研究发现，量子神经网络的解释性与其数据采样方式有关，并且存在一个带宽不可解释区，表示无法解释的数据样本。这些结果为建立负责任和可负责的量子AI模型提供了一个重要的基础。<details>
<summary>Abstract</summary>
Interpretability of artificial intelligence (AI) methods, particularly deep neural networks, is of great interest due to the widespread use of AI-backed systems, which often have unexplainable behavior. The interpretability of such models is a crucial component of building trusted systems. Many methods exist to approach this problem, but they do not obviously generalize to the quantum setting. Here we explore the interpretability of quantum neural networks using local model-agnostic interpretability measures of quantum and classical neural networks. We introduce the concept of the band of inexplicability, representing the interpretable region in which data samples have no explanation, likely victims of inherently random quantum measurements. We see this as a step toward understanding how to build responsible and accountable quantum AI models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对人工智能（AI）技术的可解释性（Interpretability）是非常关键的，因为AI支持的系统在使用中经常表现出不可解释的行为。这种可解释性是建立可信系统的重要组成部分。虽然有很多方法可以解决这个问题，但它们不显而易懂地推广到量子设置下。在这里，我们研究了量子神经网络的可解释性，使用本地模型无关的解释度量来评估量子和经典神经网络的可解释性。我们称之为“不可解释的带”（band of inexplicability），表示无法解释的数据样本的解释不可能， probable victims of inherently random quantum measurements。我们认为这是一步向于理解如何构建负责任和可负责的量子AI模型。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video"><a href="#Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video" class="headerlink" title="Video OWL-ViT: Temporally-consistent open-world localization in video"></a>Video OWL-ViT: Temporally-consistent open-world localization in video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11093">http://arxiv.org/abs/2308.11093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Heigold, Matthias Minderer, Alexey Gritsenko, Alex Bewley, Daniel Keysers, Mario Lučić, Fisher Yu, Thomas Kipf</li>
<li>for: 本文采用预训练的开放世界图像模型进行视频地标定。</li>
<li>methods: 本文使用了对大量图像文本数据进行对比预训练，然后将该模型应用到视频地标定任务上，并添加了一个变换器解码器来在视频帧中传播物体表示。</li>
<li>results: 本文在TAO-OW标准测试集上展示了对开放世界地标定任务的成功转移，而且与基于检测的跟踪基eline相比，本文的模型具有更好的时间一致性。<details>
<summary>Abstract</summary>
We present an architecture and a training recipe that adapts pre-trained open-world image models to localization in videos. Understanding the open visual world (without being constrained by fixed label spaces) is crucial for many real-world vision tasks. Contrastive pre-training on large image-text datasets has recently led to significant improvements for image-level tasks. For more structured tasks involving object localization applying pre-trained models is more challenging. This is particularly true for video tasks, where task-specific data is limited. We show successful transfer of open-world models by building on the OWL-ViT open-vocabulary detection model and adapting it to video by adding a transformer decoder. The decoder propagates object representations recurrently through time by using the output tokens for one frame as the object queries for the next. Our model is end-to-end trainable on video data and enjoys improved temporal consistency compared to tracking-by-detection baselines, while retaining the open-world capabilities of the backbone detector. We evaluate our model on the challenging TAO-OW benchmark and demonstrate that open-world capabilities, learned from large-scale image-text pre-training, can be transferred successfully to open-world localization across diverse videos.
</details>
<details>
<summary>摘要</summary>
我们提出了一种体系和训练方法，可以将预训练的开放世界图像模型适应到视频本地化。理解开放视觉世界（不受固定标签空间的限制）对实际视觉任务非常重要。最近，对大量图像文本数据进行对比预训练已经导致了图像级任务的显著改进。但是，对于结构化任务，如对象本地化，使用预训练模型更加具有挑战性。特别是在视频任务中，任务特有的数据受限。我们构建了基于 OWL-ViT 开放 vocabulary 检测模型，并将其适应到视频中。将输出 токен用于下一帧的对象查询。我们的模型是可以综合训练在视频数据上，并且具有更好的时间一致性，与racking-by-detection 基elines相比，保留了预训练模型的开放世界能力。我们在 TAO-OW 测试准则上评估了我们的模型，并证明了预训练的开放世界能力可以成功地传递到多种视频中的开放本地化。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport"><a href="#Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport" class="headerlink" title="Addressing Fairness and Explainability in Image Classification Using Optimal Transport"></a>Addressing Fairness and Explainability in Image Classification Using Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11090">http://arxiv.org/abs/2308.11090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ratz, François Hu, Arthur Charpentier</li>
<li>for: 本研究旨在提高人工智能系统的可靠性和负责任性，通过推导对不公平结果的解释来建立信任和负责任。</li>
<li>methods: 本研究提出了一种完整的方法，利用最优运输理论来探索图像中偏见的原因和影响，这种方法可以轻松扩展到表格数据上。</li>
<li>results: 研究发现，通过使用沃氏矩阵中心来获得不受敏感变量影响的分数，同时保持分数的排序结果，可以帮助找出偏见的主要来源和影响。这些发现有助于构建可靠、公平和透明的人工智能系统，在医疗和巡捕等领域中应用。<details>
<summary>Abstract</summary>
Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we obtain scores that are independent of a sensitive variable but keep their marginal orderings. This step ensures predictive accuracy but also helps us to recover the regions most associated with the generation of the biases. Our findings hold significant implications for the development of trustworthy and unbiased AI systems, fostering transparency, accountability, and fairness in critical decision-making scenarios across diverse domains.
</details>
<details>
<summary>摘要</summary>
算法公正和可解释性是在医疗和警察等领域建立人工智能系统的信任和负责任的关键因素。虽然在每个领域 separately 有所进步，但在公正性应用中保持可解释性仍然是挑战，特别是在使用深度神经网络时。同时，伦理数据挖掘已经变得更加重要，因为不公正的算法结果常常导致偏见。现有的方法主要是为了减轻模型的偏见结果，但很少人尝试解释为何模型偏见。为了bridging这个差距，我们提出了一种全面的方法，利用最优运输理论来揭示偏见区域在图像中的原因和后果，这种方法也可以轻松扩展到表格数据。通过使用沃asserstein矩阵，我们可以获得不同敏感变量之间的相对排名，这步确保预测精度，同时帮助我们回溯偏见的生成原因。我们的发现对于开发可靠、不偏见的人工智能系统产生了重要的影响，推动了透明度、负责任和公正在多个领域中的决策过程中的发展。
</details></li>
</ul>
<hr>
<h2 id="Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen"><a href="#Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen" class="headerlink" title="Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen"></a>Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11080">http://arxiv.org/abs/2308.11080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan N. Fuhg, Nikolaos Bouklas, Reese E. Jones</li>
<li>For: This paper focuses on developing and comparing different neural network models for modeling hyperelastic materials in a finite deformation context.* Methods: The paper uses a variety of tensor basis neural network models, including some unexplored formulations, and compares their performance against noisy and noiseless datasets for three different materials. The paper also examines the effectiveness of potential-based and coefficient-based approaches, as well as different calibration techniques.* Results: The paper provides theoretical and practical insights into the performance of each formulation, and compares the results of the nine variants tested.<details>
<summary>Abstract</summary>
Data-driven constitutive modeling frameworks based on neural networks and classical representation theorems have recently gained considerable attention due to their ability to easily incorporate constitutive constraints and their excellent generalization performance. In these models, the stress prediction follows from a linear combination of invariant-dependent coefficient functions and known tensor basis generators. However, thus far the formulations have been limited to stress representations based on the classical Rivlin and Ericksen form, while the performance of alternative representations has yet to be investigated. In this work, we survey a variety of tensor basis neural network models for modeling hyperelastic materials in a finite deformation context, including a number of so far unexplored formulations which use theoretically equivalent invariants and generators to Finger-Rivlin-Ericksen. Furthermore, we compare potential-based and coefficient-based approaches, as well as different calibration techniques. Nine variants are tested against both noisy and noiseless datasets for three different materials. Theoretical and practical insights into the performance of each formulation are given.
</details>
<details>
<summary>摘要</summary>
“数据驱动的构成模型框架，基于神经网络和经典表述定理，在最近受到了广泛关注，因为它们可以轻松地包含构成约束和优秀的泛化性能。在这些模型中，压力预测来自于线性组合的不变 coefficient 函数和已知的张量基 generator。然而，至今为止，这些形ulation 仅限于压力表示基于经典的 Rivlin 和 Eriksson 形式，尚未探讨其他表示形式的性能。在这种工作中，我们检验了一种多种张量基神经网络模型，用于模型弹性材料在有限减形上，包括一些尚未探讨的形式，它们使用了同等的 invariants 和生成器来 Finger-Rivlin-Eriksson。此外，我们比较了 potential-based 和 coefficient-based 方法，以及不同的 calibration 技术。 nine 个变体被测试在三种不同材料上，对于噪声和噪声无的数据集。我们提供了理论和实践的深入分析每种形式的性能。”Note: Simplified Chinese is used in this translation, which is a simplified version of Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors"><a href="#Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors" class="headerlink" title="Long-Term Prediction of Natural Video Sequences with Robust Video Predictors"></a>Long-Term Prediction of Natural Video Sequences with Robust Video Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11079">http://arxiv.org/abs/2308.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 预测高维度视频序列是一个具有挑战性的问题，由于未知性的增加，预测范围越长，难度也越大。本文提出了一些改进方案来创建Robust Video Predictors（RoViPs），以提高短期预测质量。</li>
<li>methods: 本文使用深度Perceptual和不确定性基于的重建损失，以及注意力机制 skip 连接，以提高输入特征的长距离空间移动性。</li>
<li>results: 本文表明，通过使用这些改进方案，可以创建高质量的短期预测，并且可以通过迭代单步预测任务，生成非常长的自然视频序列。<details>
<summary>Abstract</summary>
Predicting high dimensional video sequences is a curiously difficult problem. The number of possible futures for a given video sequence grows exponentially over time due to uncertainty. This is especially evident when trying to predict complicated natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict making long-term prediction very difficult. In this work we introduce a number of improvements to existing work that aid in creating Robust Video Predictors (RoViPs). We show that with a combination of deep Perceptual and uncertainty-based reconstruction losses we are able to create high quality short-term predictions. Attention-based skip connections are utilised to allow for long range spatial movement of input features to further improve performance. Finally, we show that by simply making the predictor robust to its own prediction errors, it is possible to produce very long, realistic natural video sequences using an iterated single-step prediction task.
</details>
<details>
<summary>摘要</summary>
“预测高维视频序列是一个奇怪地困难的问题。视频序列中可能的未来数量因时间不确定性而呈指数增长。特别是当试图从有限的世界快照中预测自然的视频场景时，这种不确定性会更加突出。在这种情况下，我们介绍了一些改进现有工作的方法，以创建robust Video Predictors（RoViPs）。我们表明，通过深度感知和不确定性基于的重建损失，可以创造高质量短期预测。增强功能skip连接使得输入特征可以在较长距离上进行空间运动，进一步改善性能。最后，我们表明，只需要让预测器具有自己预测错误的抗性，就可以使用迭代单步预测任务生成非常长、自然的视频序列。”Note that Simplified Chinese is a standardized form of Chinese that is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and other parts of the world. The translation may vary slightly depending on the specific dialect or variation of Chinese that is used.
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model"><a href="#A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model" class="headerlink" title="A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model"></a>A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11075">http://arxiv.org/abs/2308.11075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelsie Taylor</li>
<li>for: 这个论文是关于物理理论和量子场论中的粒子规范群（RG）技术，以及深度学习（Deep Learning）的相互关系。</li>
<li>methods: 作者使用了Restricted Boltzmann Machines（RBMs）来实现深度学习，并对2D最近邻Iseng模型进行了Kadanoff块 renormalization。作者还开发了1D和2D Ising模型的扩展renormalization技术作为比较基准。</li>
<li>results: 作者成功地使用了Adam优化器和相关长度损失函数来学习群流，并对1D Ising模型获得了与分析模型相符的结果。作者还使用了Wolff算法生成了Iseng模型样本，并使用了 quasi-deterministic方法进行了群流。最后，作者发现了RBM学习层次结构与RG块化结构之间的相似性。<details>
<summary>Abstract</summary>
The renormalization group (RG) is an essential technique in statistical physics and quantum field theory, which considers scale-invariant properties of physical theories and how these theories' parameters change with scaling. Deep learning is a powerful computational technique that uses multi-layered neural networks to solve a myriad of complicated problems. Previous research suggests the possibility that unsupervised deep learning may be a form of RG flow, by being a layer-by-layer coarse graining of the original data. We examined this connection on a more rigorous basis for the simple example of Kadanoff block renormalization of the 2D nearest-neighbor Ising model, with our deep learning accomplished via Restricted Boltzmann Machines (RBMs). We developed extensive renormalization techniques for the 1D and 2D Ising model to provide a baseline for comparison. For the 1D Ising model, we successfully used Adam optimization on a correlation length loss function to learn the group flow, yielding results consistent with the analytical model for infinite N. For the 2D Ising model, we successfully generated Ising model samples using the Wolff algorithm, and performed the group flow using a quasi-deterministic method, validating these results by calculating the critical exponent \nu. We then examined RBM learning of the Ising model layer by layer, finding a blocking structure in the learning that is qualitatively similar to RG. Lastly, we directly compared the weights of each layer from the learning to Ising spin renormalization, but found quantitative inconsistencies for the simple case of nearest-neighbor Ising models.
</details>
<details>
<summary>摘要</summary>
“ renormalization group（RG）是物理学和量子场论中的一种重要技术，它考虑物理理论中尺度不变性的性质和尺度下降参数的变化。深度学习是一种强大的计算技术，使用多层神经网络解决各种复杂问题。以前的研究表明，无监督深度学习可能是一种RG流，通过层次归约原始数据来实现。我们在2D nearest-neighbor Ising模型中进行了更加严谨的研究，我们使用Restricted Boltzmann Machines（RBMs）来实现深度学习。我们为1D和2D Ising模型开发了广泛的renoormalization技术，以提供比较基eline。对1D Ising模型，我们使用Adam优化器和尺度长度损失函数来学习群流，得到了与分析模型的一致 результа。对2D Ising模型，我们使用Wolff算法生成样本，并使用一种 quasi-deterministic 方法来实现群流，并计算了扩散率 \nu。然后，我们对 Ising 模型层次进行了 RBM 学习，发现了一种块结构，与RG有趋同性。最后，我们直接比较了各层 weights 的学习结果和 Ising 磁力 renormalization，发现了简单 nearest-neighbor Ising 模型中的量化不一致。”
</details></li>
</ul>
<hr>
<h2 id="Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning"><a href="#Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning" class="headerlink" title="Neural Amortized Inference for Nested Multi-agent Reasoning"></a>Neural Amortized Inference for Nested Multi-agent Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11071">http://arxiv.org/abs/2308.11071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunal Jha, Tuan Anh Le, Chuanyang Jin, Yen-Ling Kuo, Joshua B. Tenenbaum, Tianmin Shu</li>
<li>for: 本研究旨在提高多代理交互中的社会推理能力，以便更好地模拟人类的社会听说和推理能力。</li>
<li>methods: 本研究使用神经网络来快速化高阶社会推理，以便在多代理交互中提高推理效率。</li>
<li>results: 实验结果显示，使用神经网络可以减少计算复杂性，同时保持准确性。<details>
<summary>Abstract</summary>
Multi-agent interactions, such as communication, teaching, and bluffing, often rely on higher-order social inference, i.e., understanding how others infer oneself. Such intricate reasoning can be effectively modeled through nested multi-agent reasoning. Nonetheless, the computational complexity escalates exponentially with each level of reasoning, posing a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.
</details>
<details>
<summary>摘要</summary>
多智能机器人之间的交互，如 коммуника、教学和谎言，frequently rely on高级社会推理，即理解他们如何推理自己。这种复杂的推理可以通过嵌入式多智能推理模型来有效地模拟。然而，计算复杂性随着每级别推理的层次层次增加， pose a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Topological-Graph-Signal-Compression"><a href="#Topological-Graph-Signal-Compression" class="headerlink" title="Topological Graph Signal Compression"></a>Topological Graph Signal Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11068">http://arxiv.org/abs/2308.11068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, Lev Telyatnikov, Eduard Alarcón, Albert Cabellos-Aparicio, Pere Barlet-Ros, Pietro Liò</li>
<li>for: 提出了一种基于Topological Deep Learning（TDL）方法的信号压缩方法，用于处理图structured数据。</li>
<li>methods: 方法包括两个主要步骤：首先，基于原始信号，使用 clustering 将 $N$ 个数据点分为 $K\ll N$ 个多元素集合；然后，使用 topological-inspired message passing 获取这些多元素集合中的压缩表示。</li>
<li>results: 我们的框架可以在两个实际Internet Service Provider Networks的数据集上提高标准GNN和Feed-Forward架构的压缩率，从 $30%$ 提高到 $90%$，表明它更好地捕捉和利用图structured网络结构中的空间和时间相关性。<details>
<summary>Abstract</summary>
Recently emerged Topological Deep Learning (TDL) methods aim to extend current Graph Neural Networks (GNN) by naturally processing higher-order interactions, going beyond the pairwise relations and local neighborhoods defined by graph representations. In this paper we propose a novel TDL-based method for compressing signals over graphs, consisting in two main steps: first, disjoint sets of higher-order structures are inferred based on the original signal --by clustering $N$ datapoints into $K\ll N$ collections; then, a topological-inspired message passing gets a compressed representation of the signal within those multi-element sets. Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-word Internet Service Provider Networks' datasets --from $30\%$ up to $90\%$ better reconstruction errors across all evaluation scenarios--, suggesting that it better captures and exploits spatial and temporal correlations over the whole graph-based network structure.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Disjoint sets of higher-order structures are inferred based on the original signal by clustering $N$ datapoints into $K\ll N$ collections.2. A topological-inspired message passing gets a compressed representation of the signal within those multi-element sets.Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-world Internet Service Provider Networks’ datasets - from $30%$ up to $90%$ better reconstruction errors across all evaluation scenarios - suggesting that it better captures and exploits spatial and temporal correlations over the whole graph-based network structure.Translated into Simplified Chinese:最近提出的 topological deep learning (TDL) 方法目的是扩展当前的图神经网络 (GNN)，以自然处理更高级别的交互，超越对图表示的对称关系和本地邻域。在这篇论文中，我们提出了一种基于 TDL 的图信号压缩方法，包括两个主要步骤：1. 根据原始信号，使用 clustering 将 $N$ 个数据点分为 $K\ll N$ 个集合。2. 使用图启发的消息传递机制，在多个元素集中获得压缩表示。我们的结果表明，我们的框架可以提高标准 GNN 和Feed-Forward 架构在图信号压缩方面的性能，从两个实际的互联网服务提供商网络数据集中，提高压缩率，从 $30%$ 到 $90%$，表明它更好地捕捉和利用图structured 网络的空间和时间相关性。</details></li>
</ol>
<hr>
<h2 id="UnLoc-A-Unified-Framework-for-Video-Localization-Tasks"><a href="#UnLoc-A-Unified-Framework-for-Video-Localization-Tasks" class="headerlink" title="UnLoc: A Unified Framework for Video Localization Tasks"></a>UnLoc: A Unified Framework for Video Localization Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11062">http://arxiv.org/abs/2308.11062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/scenic">https://github.com/google-research/scenic</a></li>
<li>paper_authors: Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid</li>
<li>for: 这篇论文是为了解决无法裁剪视频的视频地址Localization问题而设计的。</li>
<li>methods: 该论文使用预训练的图像和文本楼层，并将其传递给视频-文本融合模型。输出的融合模块 then用于构建一个特征峰，每个级别与一个头相连，以预测每帧的相关性分数和开始&#x2F;结束时间偏移。</li>
<li>results: 该方法可以实现Moment Retrieval、Temporal Localization和Action Segmentation三个任务，而无需动作提案、运动基于预训练特征或 Representation masking。与专门的模型不同，我们在三个不同的地址Localization任务上达到了状态 искусственный智能的最佳result。<details>
<summary>Abstract</summary>
While large-scale image-text pretrained models such as CLIP have been used for multiple video-level tasks on trimmed videos, their use for temporal localization in untrimmed videos is still a relatively unexplored task. We design a new approach for this called UnLoc, which uses pretrained image and text towers, and feeds tokens to a video-text fusion model. The output of the fusion module are then used to construct a feature pyramid in which each level connects to a head to predict a per-frame relevancy score and start/end time displacements. Unlike previous works, our architecture enables Moment Retrieval, Temporal Localization, and Action Segmentation with a single stage model, without the need for action proposals, motion based pretrained features or representation masking. Unlike specialized models, we achieve state of the art results on all three different localization tasks with a unified approach. Code will be available at: \url{https://github.com/google-research/scenic}.
</details>
<details>
<summary>摘要</summary>
大规模图像文本预训练模型，如CLIP，已经用于多个视频级任务，但它们在未处理的视频中进行时间地理化仍然是一个相对未探索的任务。我们设计了一种新的方法，即UnLoc，它使用预训练的图像和文本楼层，并将Token传递给视频文本融合模型。模型的输出被用construct一个特征 pyramid，其中每个层与一个头连接，以预测每帧相关性分数和开始/结束时间偏移。与先前的工作不同，我们的架构允许每帧 Localization、Temporal Localization 和 Action Segmentation 通过单一的阶段模型进行，不需要动作提案、运动基于预训练特征或表示掩码。与专门的模型不同，我们在三个不同的地理化任务上达到了状态机器的最佳result，代码将在： \url{https://github.com/google-research/scenic} 中提供。
</details></li>
</ul>
<hr>
<h2 id="FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning"><a href="#FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning" class="headerlink" title="FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning"></a>FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12305">http://arxiv.org/abs/2308.12305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Yao Zhang, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 这个研究是为了提高基础模型在多modal学习中的表现，并且解决训练需要大量数据的问题。</li>
<li>methods: 这个研究使用了联合学习（Federated Learning）和内部知识传播（Mutual Knowledge Distillation）等方法，以及一个叫做DAT的双适束教师，来处理客户端资料不同性。</li>
<li>results: 这个研究的结果显示，使用FedDAT可以将基础模型进行高效的分布式调整，并且在不同类型的多modal任务上表现出色，比较现有的中央PEFT方法更高效。<details>
<summary>Abstract</summary>
Recently, foundation models have exhibited remarkable advancements in multi-modal learning. These models, equipped with millions (or billions) of parameters, typically require a substantial amount of data for finetuning. However, collecting and centralizing training data from diverse sectors becomes challenging due to distinct privacy regulations. Federated Learning (FL) emerges as a promising solution, enabling multiple clients to collaboratively train neural networks without centralizing their local data. To alleviate client computation burdens and communication overheads, previous works have adapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a small fraction of the model parameters are optimized and communicated during federated communications. Nevertheless, most previous works have focused on a single modality and neglected one common phenomenon, i.e., the presence of data heterogeneity across the clients. Therefore, in this work, we propose a finetuning framework tailored to heterogeneous multi-modal FL, called Federated Dual-Aadapter Teacher (FedDAT). Specifically, our approach leverages a Dual-Adapter Teacher (DAT) to address data heterogeneity by regularizing the client local updates and applying Mutual Knowledge Distillation (MKD) for an efficient knowledge transfer. FedDAT is the first approach that enables an efficient distributed finetuning of foundation models for a variety of heterogeneous Vision-Language tasks. To demonstrate its effectiveness, we conduct extensive experiments on four multi-modality FL benchmarks with different types of data heterogeneity, where FedDAT substantially outperforms the existing centralized PEFT methods adapted for FL.
</details>
<details>
<summary>摘要</summary>
近些时候，基金会模型在多Modal学习方面做出了很大的进步。这些模型通常需要大量数据进行微调，但由于不同领域的隐私规定，收集和中央化训练数据变得困难。为了解决这问题，联邦学习（FL）出现了，允许多个客户共同训练神经网络，无需中央化地方数据。为了减轻客户计算负担和通信开销，先前的工作已经采用了精度高的微调方法（PEFT）。然而，大多数先前的工作都是单modal的，忽略了客户数据的不同性。因此，在这项工作中，我们提出了适用于多样性多Modal FL的微调框架，即联邦双Adapter教师（FedDAT）。我们的方法利用了双Adapter教师（DAT）来 Address客户本地更新的数据不同性，并通过互助知识传播（MKD）来进行高效的知识传递。FedDAT 是首个可以有效地分布式微调基础模型的多Modal Vision-Language 联邦FL 方法。为证明其有效性，我们在四个多Modal FL 标准准的不同类型的数据不同性上进行了广泛的实验，并证明FedDAT 在这些标准上大幅超越了已有的中央化 PEFT 方法。
</details></li>
</ul>
<hr>
<h2 id="Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression"><a href="#Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression" class="headerlink" title="Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression"></a>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11053">http://arxiv.org/abs/2308.11053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</li>
<li>for: 实现全动频通信的杂音抑制和调变减少，但大多数现有的神经网络具有高计算成本和不可靠的模型复杂度调整。</li>
<li>methods: 我们提出了时间-频率二重路径压缩，以实现广泛的压缩比率选择。特别是在频率压缩方面，使用可训练的范子网络来进行维度减少。在时间压缩方面，仅使用几帧预测会导致巨大的性能下降，可以通过全序模型来缓和这一下。</li>
<li>results: 我们发现，将时间和频率两种方法组合在一起，可以实现更好的性能改进，覆盖压缩比率的选择范围从4x至32x，而且这些提案的模型具有与快速FullSubNet和DeepFilterNet相似的竞争性能。<details>
<summary>Abstract</summary>
Echo cancellation and noise reduction are essential for full-duplex communication, yet most existing neural networks have high computational costs and are inflexible in tuning model complexity. In this paper, we introduce time-frequency dual-path compression to achieve a wide range of compression ratios on computational cost. Specifically, for frequency compression, trainable filters are used to replace manually designed filters for dimension reduction. For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io/ultra_dual_path_compression.github.io/.
</details>
<details>
<summary>摘要</summary>
echo 抑制和噪声减少是全双工通信的必备条件，然而大多数现有的神经网络具有高计算成本和不 flexible 的模型复杂度调整。在这篇论文中，我们引入时频双路压缩来实现广泛的压缩比例。 Specifically， для频率压缩，使用可训练的滤波器来替代手动设计的滤波器进行维度减少。 For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io/ultra_dual_path_compression.github.io/.Note that the text has been translated using Simplified Chinese characters and grammar. If you prefer Traditional Chinese, please let me know and I can provide the translation using Traditional Chinese characters and grammar.
</details></li>
</ul>
<hr>
<h2 id="Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI"><a href="#Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI" class="headerlink" title="Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI"></a>Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11047">http://arxiv.org/abs/2308.11047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhijeet Parida, Zhifan Jiang, Syed Muhammad Anwar, Nicholas Foreman, Nicholas Stence, Michael J. Fisher, Roger J. Packer, Robert A. Avery, Marius George Linguraru</li>
<li>for: 这篇论文旨在应用深度学习技术来进行少见疾病，如儿童脑肿瘤的诊断和预测。</li>
<li>methods: 本论文使用生成对抗网络（GANs）进行深度学习预测，并提出了一个一击学习方法，将单一的诊断影像转换为医疗影像集合中的一个标准化影像。</li>
<li>results: 实验结果显示，本方法可以优化医疗影像的尺度，同时保持病人解剖结构的稳定性。<details>
<summary>Abstract</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.
</details>
<details>
<summary>摘要</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Spurious-Correlations-and-Where-to-Find-Them"><a href="#Spurious-Correlations-and-Where-to-Find-Them" class="headerlink" title="Spurious Correlations and Where to Find Them"></a>Spurious Correlations and Where to Find Them</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11043">http://arxiv.org/abs/2308.11043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gautam Sreekumar, Vishnu Naresh Boddeti</li>
<li>for: 本研究旨在探讨数据驱动学习中的假 correlate 问题，并提出一种基于 causal graph 的方法来解决这个问题。</li>
<li>methods: 本研究使用了一些常见的假 correlate 假设，并通过对标准 ERM 基elines 进行比较，检验这些假设对模型性能的影响。</li>
<li>results: 研究发现，在不同的假 correlate 假设下，模型的性能会受到不同程度的影响，并且可以通过对模型设计 Parameters 进行调整来改善模型性能。<details>
<summary>Abstract</summary>
Spurious correlations occur when a model learns unreliable features from the data and are a well-known drawback of data-driven learning. Although there are several algorithms proposed to mitigate it, we are yet to jointly derive the indicators of spurious correlations. As a result, the solutions built upon standalone hypotheses fail to beat simple ERM baselines. We collect some of the commonly studied hypotheses behind the occurrence of spurious correlations and investigate their influence on standard ERM baselines using synthetic datasets generated from causal graphs. Subsequently, we observe patterns connecting these hypotheses and model design choices.
</details>
<details>
<summary>摘要</summary>
伪 correlate 发生在模型从数据中学习不可靠特征时，这是数据驱动学习的一个知名缺陷。虽然有多种算法提出来 mitigate 其影响，但我们还没有共同 derivation 这些伪 correlate 的指标。因此，基于单独的假设建立的解决方案不能超过简单的 ERM 基elines。我们收集了一些常study 的假设下伪 correlate 的发生，并 investigate 这些假设对标准 ERM 基elines 的影响使用 synthetic 数据集。然后，我们发现了这些假设和模型设计选择之间的 Patterns。
</details></li>
</ul>
<hr>
<h2 id="Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics"><a href="#Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics" class="headerlink" title="Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics"></a>Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11027">http://arxiv.org/abs/2308.11027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuohang Li, Chao Yan, Xinmeng Zhang, Gharib Gharibi, Zhijun Yin, Xiaoqian Jiang, Bradley A. Malin</li>
<li>for: 本研究旨在Addressing the challenge of training deep learning models across healthcare organizations with privacy requirements.</li>
<li>methods: 该研究提出了一种新的隐私保护分布式学习框架，可以在私有保持原始数据和模型参数的情况下进行分布式学习。</li>
<li>results: 研究表明，通过使用分布式学习，可以实现高度相似的性能与中央化和联合学习，同时提高计算效率和降低隐私风险。<details>
<summary>Abstract</summary>
Deep learning continues to rapidly evolve and is now demonstrating remarkable potential for numerous medical prediction tasks. However, realizing deep learning models that generalize across healthcare organizations is challenging. This is due, in part, to the inherent siloed nature of these organizations and patient privacy requirements. To address this problem, we illustrate how split learning can enable collaborative training of deep learning models across disparate and privately maintained health datasets, while keeping the original records and model parameters private. We introduce a new privacy-preserving distributed learning framework that offers a higher level of privacy compared to conventional federated learning. We use several biomedical imaging and electronic health record (EHR) datasets to show that deep learning models trained via split learning can achieve highly similar performance to their centralized and federated counterparts while greatly improving computational efficiency and reducing privacy risks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata"><a href="#Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata" class="headerlink" title="Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata"></a>Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11022">http://arxiv.org/abs/2308.11022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filipa Valdeira, Stevo Racković, Valeria Danalachi, Qiwei Han, Cláudia Soares</li>
<li>for: 预测医生 Referral 建议，包括新患者和已有咨询历史</li>
<li>methods: 使用 Extreme Multilabel Classification (XML) 编码可用特征，并 explore 不同的场景</li>
<li>results: 比对标准推荐 metric ，our approach 在有咨询历史的患者群体中提高推荐精度大约 $10%$，并在新患者群体中提高 recall 纪录In English, this means:</li>
<li>for: Predicting doctor referrals, including new patients and those with a consultation history</li>
<li>methods: Using Extreme Multilabel Classification (XML) to encode available features and explore different scenarios</li>
<li>results: Comparing standard recommendation metrics, our approach consistently improves recommendation accuracy by approximately $10%$ for patients with a previous consultation history, and outperforms the benchmark in favorable scenarios for new patients, with a focus on recall metrics.<details>
<summary>Abstract</summary>
Recommendation Systems (RS) are often used to address the issue of medical doctor referrals. However, these systems require access to patient feedback and medical records, which may not always be available in real-world scenarios. Our research focuses on medical referrals and aims to predict recommendations in different specialties of physicians for both new patients and those with a consultation history. We use Extreme Multilabel Classification (XML), commonly employed in text-based classification tasks, to encode available features and explore different scenarios. While its potential for recommendation tasks has often been suggested, this has not been thoroughly explored in the literature. Motivated by the doctor referral case, we show how to recast a traditional recommender setting into a multilabel classification problem that current XML methods can solve. Further, we propose a unified model leveraging patient history across different specialties. Compared to state-of-the-art RS using the same features, our approach consistently improves standard recommendation metrics up to approximately $10\%$ for patients with a previous consultation history. For new patients, XML proves better at exploiting available features, outperforming the benchmark in favorable scenarios, with particular emphasis on recall metrics. Thus, our approach brings us one step closer to creating more effective and personalized doctor referral systems. Additionally, it highlights XML as a promising alternative to current hybrid or content-based RS, while identifying key aspects to take into account when using XML for recommendation tasks.
</details>
<details>
<summary>摘要</summary>
医疗专家推荐系统（RS）经常用于解决医疗专家推荐问题。然而，这些系统可能需要患者反馈和医疗记录，这些资料在实际场景中可能不常可用。我们的研究关注医疗推荐，并且想要预测不同专业医生的推荐建议，包括新患者和已经有咨询历史的患者。我们使用极端多类标签分类（XML），通常用于文本分类任务，来编码可用的特征并explore不同的场景。虽然XML在推荐任务中的潜力尚未得到了足够的研究，但我们在医疗推荐中提出了一种新的方法。我们的方法可以将传统的推荐设定转换成多类标签分类问题，使得现有的XML方法可以解决。此外，我们提议一种综合模型，利用患者历史跨专业。相比于使用同样的特征的状态体系，我们的方法在患者历史存在时可以保持标准推荐指标的提高，达到约10%。在新患者情况下，XML较好地利用可用的特征，超越了标准。特别是，我们的方法在反报率指标方面具有明显的优势。因此，我们的方法可以为创建更有效和个性化的医疗专家推荐系统做出一步进展。此外，它也证明了XML作为推荐任务的一种有前途的alternative，而且标识了在使用XML时需要注意的关键方面。
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations"><a href="#Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations" class="headerlink" title="Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations"></a>Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11021">http://arxiv.org/abs/2308.11021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mihai Pirvu, Alina Marcu, Alexandra Dobrescu, Nabil Belbachir, Marius Leordeanu</li>
<li>for: 这个论文的目的是为了解决EARTH OBSERVATION问题，这个问题是多任务的并且常常缺少地面真实数据。</li>
<li>methods: 这篇论文提出了一种多任务希пер图模型，其中每个节点是一个任务，不同的路径通过希пер图达到某个任务都成为了无监督教师，这些教师 ensemble 学习生成可靠的假标签 для该任务。每个希PERedge 是一个任务的教师和学生，它也是一个自动матичеSK hypergraph 系统的学生。</li>
<li>results: 通过对NASA NEO Dataset进行广泛的实验，证明了我们的多任务半监督方法的价值， consistently 超过了强基eline和最新的工作。此外，我们还证明了希PERgraph 可以适应无监督数据分布变化，并可靠地恢复多个观测层的缺失数据，超过了7年。<details>
<summary>Abstract</summary>
There are many ways of interpreting the world and they are highly interdependent. We exploit such complex dependencies and introduce a powerful multi-task hypergraph, in which every node is a task and different paths through the hypergraph reaching a given task become unsupervised teachers, by forming ensembles that learn to generate reliable pseudolabels for that task. Each hyperedge is part of an ensemble teacher for a given task and it is also a student of the self-supervised hypergraph system. We apply our model to one of the most important problems of our times, that of Earth Observation, which is highly multi-task and it often suffers from missing ground-truth data. By performing extensive experiments on the NASA NEO Dataset, spanning a period of 22 years, we demonstrate the value of our multi-task semi-supervised approach, by consistent improvements over strong baselines and recent work. We also show that the hypergraph can adapt unsupervised to gradual data distribution shifts and reliably recover, through its multi-task self-supervision process, the missing data for several observational layers for up to seven years.
</details>
<details>
<summary>摘要</summary>
世界的解释有多种方法，它们之间具有高度的互相依赖关系。我们利用这些复杂的依赖关系，引入一个强大的多任务跨граф，其中每个节点是一个任务，不同的路径通过跨граф到达给定任务都变成了无监督教师。每个跨边都是一个任务的ensemble教师，同时也是自动编程跨 graf系统的学生。我们应用我们的模型到现代时代最重要的问题之一——地球观测，这是一个高度多任务的问题， часто会 missing ground-truth data。通过对 NASA NEO 数据集进行了22年的广泛实验，我们展示了我们的多任务半监督方法的价值，通过不断超过强大的基准和最新的研究成果。我们还表明了跨 graf 可以适应无监督的数据分布变化，并可靠地恢复多个观测层的缺失数据，达7年之久。
</details></li>
</ul>
<hr>
<h2 id="Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems"><a href="#Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems" class="headerlink" title="Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems"></a>Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11019">http://arxiv.org/abs/2308.11019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Sziburis, Markus Nowak, Davide Brunelli</li>
<li>for: 这篇论文探讨了基于kNN的手势识别方法，用于辅助控制 prosthesis。</li>
<li>methods: 方法包括实现kNN scheme，并评估不同的实现方式和参数化方法，以提高运算效率和可靠性。</li>
<li>results: 结果显示，使用kNN scheme和Decision Surface Mapping（DSM）可以实现高精度的手势识别，并且在实时运算中保持高速度和可靠性。<details>
<summary>Abstract</summary>
This work presents the design, implementation and validation of learning techniques based on the kNN scheme for gesture detection in prosthetic control. To cope with high computational demands in instance-based prediction, methods of dataset reduction are evaluated considering real-time determinism to allow for the reliable integration into battery-powered portable devices. The influence of parameterization and varying proportionality schemes is analyzed, utilizing an eight-channel-sEMG armband. Besides offline cross-validation accuracy, success rates in real-time pilot experiments (online target achievement tests) are determined. Based on the assessment of specific dataset reduction techniques' adequacy for embedded control applications regarding accuracy and timing behaviour, Decision Surface Mapping (DSM) proves itself promising when applying kNN on the reduced set. A randomized, double-blind user study was conducted to evaluate the respective methods (kNN and kNN with DSM-reduction) against Ridge Regression (RR) and RR with Random Fourier Features (RR-RFF). The kNN-based methods performed significantly better (p<0.0005) than the regression techniques. Between DSM-kNN and kNN, there was no statistically significant difference (significance level 0.05). This is remarkable in consideration of only one sample per class in the reduced set, thus yielding a reduction rate of over 99% while preserving success rate. The same behaviour could be confirmed in an extended user study. With k=1, which turned out to be an excellent choice, the runtime complexity of both kNN (in every prediction step) as well as DSM-kNN (in the training phase) becomes linear concerning the number of original samples, favouring dependable wearable prosthesis applications.
</details>
<details>
<summary>摘要</summary>
这个工作介绍了基于kNN算法的手势检测技术的设计、实现和验证。为了应对实例基本预测的高计算需求，dataset减少方法被评估，包括实时决定性以便可靠地 интеGRATE到电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池电池
</details></li>
</ul>
<hr>
<h2 id="Personalized-Event-Prediction-for-Electronic-Health-Records"><a href="#Personalized-Event-Prediction-for-Electronic-Health-Records" class="headerlink" title="Personalized Event Prediction for Electronic Health Records"></a>Personalized Event Prediction for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11013">http://arxiv.org/abs/2308.11013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeong Min Lee, Milos Hauskrecht</li>
<li>for: 这篇论文的目的是为了开发一些准确的预测模型，以支持不同的医疗执行和病例分析，并且提高病人照顾质量。</li>
<li>methods: 这篇论文使用了多种新的事件序列预测模型和方法，包括人群内部模型修饰、自适应和元件水平模型转换，以更好地适应个别病人和其特定情况。</li>
<li>results: 这篇论文的结果显示，这些新的预测模型和方法可以对医疗纪录中的事件序列进行更准确的预测，并且可以适应不同的病人和其特定情况。<details>
<summary>Abstract</summary>
Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient's sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for individual patients and their specific conditions. The methods developed in this work pursue refinement of population-wide models to subpopulations, self-adaptation, and a meta-level model switching that is able to adaptively select the model with the best chance to support the immediate prediction. We analyze and test the performance of these models on clinical event sequences of patients in MIMIC-III database.
</details>
<details>
<summary>摘要</summary>
临床事件序列包含数百个临床事件记录，表示患者的时间序列记录。开发准确预测临床序列模型是非常重要的，以支持评估当前患者状况、分类临床事件类型和预测不良临床结果等，以提高患者治疗。一个重要的预测临床序列模型挑战是每个患者的序列可能具有不同的临床事件集（观察结果、实验室测试结果、药物和处理），因此通用于许多患者的人口级别模型可能无法准确预测每个患者的特定状况和差异。为解决这个问题，我们提出并研究了多种新的临床序列预测模型和方法，使得我们可以更好地适应每个患者和其特定状况。我们在MIMIC-III数据库中分析和测试了这些模型的性能。
</details></li>
</ul>
<hr>
<h2 id="Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items"><a href="#Using-language-models-in-the-implicit-automated-assessment-of-mathematical-short-answer-items" class="headerlink" title="Using language models in the implicit automated assessment of mathematical short answer items"></a>Using language models in the implicit automated assessment of mathematical short answer items</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11006">http://arxiv.org/abs/2308.11006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Ormerod</li>
<li>for: 这个论文旨在提出一种新的短 constructed response 评估方法，用于评估学生在数学题目上的答案。</li>
<li>methods: 该方法使用一个管道来标识学生的答案中关键的值。该管道包括两个精心定制的自然语言模型，第一个模型判断答案中是否含有关键值，第二个模型则确定答案中关键值的位置。</li>
<li>results: 相比传统的分页式评估方法，该管道可以更准确地评估短 constructed response，并且可以提供更有arget的反馈给学生和教师，帮助学生提高数学理解。<details>
<summary>Abstract</summary>
We propose a new way to assess certain short constructed responses to mathematics items. Our approach uses a pipeline that identifies the key values specified by the student in their response. This allows us to determine the correctness of the response, as well as identify any misconceptions. The information from the value identification pipeline can then be used to provide feedback to the teacher and student. The value identification pipeline consists of two fine-tuned language models. The first model determines if a value is implicit in the student response. The second model identifies where in the response the key value is specified. We consider both a generic model that can be used for any prompt and value, as well as models that are specific to each prompt and value. The value identification pipeline is a more accurate and informative way to assess short constructed responses than traditional rubric-based scoring. It can be used to provide more targeted feedback to students, which can help them improve their understanding of mathematics.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法来评估某些短 constructed responses 的数学项目。我们的方法使用一个管道，从student response中提取关键值。这使得我们可以确定答案是否正确，以及学生是否存在误会。管道中的信息可以用于给教师和学生提供反馈。我们的值标识管道包括两个精度调整的自然语言模型。第一个模型判断学生答案中是否存在某个值。第二个模型则确定答案中关键值的位置。我们考虑了一个通用的模型，可以用于任何提问和值，以及每个提问和值的特定模型。值标识管道比传统基于满分表格的评分方法更准确和有用，可以为学生提供更加精准的反馈，从而帮助学生提高数学理解。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning"><a href="#Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning" class="headerlink" title="Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning"></a>Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11003">http://arxiv.org/abs/2308.11003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bertrand Rouet-Leduc, Thomas Kerdreux, Alexandre Tuel, Claudia Hulbert</li>
<li>For: The paper aims to develop a method for automatically detecting methane leaks in satellite multispectral data using deep learning techniques.* Methods: The paper uses Sentinel-2 satellite multispectral data and leverages the image recognition capabilities of deep learning methods to detect methane leaks.* Results: The paper shows that the proposed approach can dramatically reduce false positive rates compared to state-of-the-art multispectral methane data products and can automatically detect methane leaks without the need for a priori knowledge of potential leak sites.Here’s the same information in Simplified Chinese:* For: 该文章目的是开发一种自动检测卫星多spectral数据中的甲烷泄漏的方法，使用深度学习技术。* Methods: 文章使用Sentinel-2卫星多spectral数据，利用深度学习方法对图像进行识别，检测甲烷泄漏。* Results: 文章显示，提议的方法可以减少false positive率，比state-of-the-art多spectral甲烷数据产品更加精准，无需先知道泄漏点的位置。<details>
<summary>Abstract</summary>
Methane is one of the most potent greenhouse gases, and its short atmospheric half-life makes it a prime target to rapidly curb global warming. However, current methane emission monitoring techniques primarily rely on approximate emission factors or self-reporting, which have been shown to often dramatically underestimate emissions. Although initially designed to monitor surface properties, satellite multispectral data has recently emerged as a powerful method to analyze atmospheric content. However, the spectral resolution of multispectral instruments is poor, and methane measurements are typically very noisy. Methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis. Here, we show that the image recognition capabilities of deep learning methods can be leveraged to automatize the detection of methane leaks in Sentinel-2 satellite multispectral data, with dramatically reduced false positive rates compared with state-of-the-art multispectral methane data products, and without the need for a priori knowledge of potential leak sites. Our proposed approach paves the way for the automated, high-definition and high-frequency monitoring of point-source methane emissions across the world.
</details>
<details>
<summary>摘要</summary>
孕气是最强烈的绿色气体之一，它的大气半衰期短，使其成为缓解全球变暖的 prime target。然而，现有的甲烷排放监测技术主要基于估算的排放因子或自我报告，这些估算通常会很大幅度地下估排放。虽然初始设计用于监测地面属性，但卫星多spectral数据最近在气象Content的分析方面 emerged as a powerful tool。然而，多spectral instrument的 spectral resolution poor, and methane measurements are typically very noisy. methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis。在这里，我们展示了深度学习方法的图像识别能力可以用来自动检测Sentinel-2卫星多spectral数据中的甲烷泄漏，与现有的多spectral甲烷数据产品相比， false positive rate 下降了多少，而无需对潜在泄漏点的 prior knowledge。我们的提议方法开 up the possibility of automated, high-definition and high-frequency monitoring of point-source methane emissions across the world。
</details></li>
</ul>
<hr>
<h2 id="SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance"><a href="#SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance" class="headerlink" title="SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance"></a>SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10973">http://arxiv.org/abs/2308.10973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jarrod Haas</li>
<li>for: 本研究旨在提出一种非常简单的方法来检测数据集外的异常（Out-of-Distribution，OoD）样本。</li>
<li>methods: 本研究使用了Supervised Contrastive Learning（SCL）方法将ResNet18模型训练，并使用欧几丁度评分函数来评估OoD样本。</li>
<li>results: 研究发现，使用SCL方法训练ResNet18模型，可以直接使用Euclidean distance评分函数来检测OoD样本，并且可以达到或超过许多现有的州态艺法和大型模型的效果。<details>
<summary>Abstract</summary>
Out-of-Distribution (OoD) detection has developed substantially in the past few years, with available methods approaching, and in a few cases achieving, perfect data separation on standard benchmarks. These results generally involve large or complex models, pretraining, exposure to OoD examples or extra hyperparameter tuning. Remarkably, it is possible to achieve results that can exceed many of these state-of-the-art methods with a very simple method. We demonstrate that ResNet18 trained with Supervised Contrastive Learning (SCL) produces state-of-the-art results out-of-the-box on near and far OoD detection benchmarks using only Euclidean distance as a scoring rule. This may obviate the need in some cases for more sophisticated methods or larger models, and at the very least provides a very strong, easy to use baseline for further experimentation and analysis.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION（OOD）检测在最近几年内发展了很大，现有的方法已经几乎完美地分离了标准 benchmark 上的数据。这些结果通常需要使用大型或复杂的模型，预训练，对 OOD 示例进行暴露或额外的 гиперпараметр调整。很 Remarkably，我们发现可以使用非常简单的方法来超越许多state-of-the-art方法。我们示出，使用 Supervised Contrastive Learning（SCL）训练的 ResNet18 在靠近和远 OOD 检测 benchmark 上达到了 state-of-the-art 结果，只使用 euclidian distance 作为分数规则。这可能将一些情况下取代更复杂的方法或更大的模型，而且最少提供了一个非常强大、易于使用的基准， для 进一步的实验和分析。
</details></li>
</ul>
<hr>
<h2 id="Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes"><a href="#Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes" class="headerlink" title="Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes"></a>Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12304">http://arxiv.org/abs/2308.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abram Magner, Arun Padakandla</li>
<li>for: 本文研究了量子测量类的学习可能性，并提出了匹配的必要和 suficient conditions，以及相应的样本复杂度下界。</li>
<li>methods: 本文使用了Empirical Risk Minimization（ERM）和denoised ERM来学习量子测量类，并提出了新的学习规则——denoised ERM，以及其uniform convergence的condition。</li>
<li>results: 本文证明了POVM和概率观测类是PAC可学习的，并给出了量子测量类的样本复杂度下界。此外，本文还证明了所有在finite-dimensional Hilbert space上定义的测量类都是PAC可学习的。<details>
<summary>Abstract</summary>
We characterize learnability for quantum measurement classes by establishing matching necessary and sufficient conditions for their PAC learnability, along with corresponding sample complexity bounds, in the setting where the learner is given access only to prepared quantum states. We first probe the results from previous works on this setting. We show that the empirical risk defined in previous works and matching the definition in the classical theory fails to satisfy the uniform convergence property enjoyed in the classical setting for some learnable classes. Moreover, we show that VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes. To surmount the failure of the standard ERM to satisfy uniform convergence, we define a new learning rule -- denoised ERM. We show this to be a universal learning rule for POVM and probabilistically observed concept classes, and the condition for it to satisfy uniform convergence is finite fat shattering dimension of the class. We give quantitative sample complexity upper and lower bounds for learnability in terms of finite fat-shattering dimension and a notion of approximate finite partitionability into approximately jointly measurable subsets, which allow for sample reuse. We then show that finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets, leading to our matching conditions. We also show that every measurement class defined on a finite-dimensional Hilbert space is PAC learnable. We illustrate our results on several example POVM classes.
</details>
<details>
<summary>摘要</summary>
我们 caracteriza 学习可能性 для量子测量类型 by 确定匹配的必需和充分条件，以及相应的样本复杂性 bound，在learner 被给定只有准备好的量子状态的设置下。我们首先探究 previous works 中的结果。我们显示了empirical risk 定义在 previous works 中并不满足 classical setting 中的各种learnable classes 上的 uniform convergence property。此外，我们还显示了 previous work 中的VC dimension 泛化Upper bound  часто是无限大，即使是 finite-dimensional POVM 类型。为了缺乏标准 ERM 满足 uniform convergence，我们定义了一种新的学习规则 -- denoised ERM。我们显示这是一种universal learning rule  для POVM 和 probabilistically observed concept classes，并且 condition  для它满足 uniform convergence 是类型的 finite fat shattering dimension。我们给出了量化样本复杂性 upper 和 lower bound ，用于描述learnability 的conditions。我们然后显示了 finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets，导致我们的matching conditions。最后，我们还显示了 every measurement class defined on a finite-dimensional Hilbert space 是 PAC learnable。我们在 several example POVM classes 中应用我们的结果。
</details></li>
</ul>
<hr>
<h2 id="MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer"><a href="#MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer" class="headerlink" title="MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer"></a>MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10968">http://arxiv.org/abs/2308.10968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoyao Shen, Yancheng Zhu, Hernan Jara, Sean B. Andersson, Chad W. Farris, Stephan Anderson, Xin Zhang</li>
<li>for: 这 paper 的目的是提出一种基于深度学习的 MRI 重建方法，以提高 MRI 的图像质量。</li>
<li>methods: 这 paper 使用了 regularization by denoising (RED) 和 regularization by neural style transfer (RNST) 两种方法，将它们组合使用以实现高质量的 MRI 重建。</li>
<li>results: 研究发现，使用 RNST 方法可以在不同的图像风格和有限数据情况下，从噪声低质量图像中重建出高质量图像。这些结果表明 RNST 框架在 MRI 重建中具有广泛的应用前景和可能性。<details>
<summary>Abstract</summary>
Recent works have demonstrated success in MRI reconstruction using deep learning-based models. However, most reported approaches require training on a task-specific, large-scale dataset. Regularization by denoising (RED) is a general pipeline which embeds a denoiser as a prior for image reconstruction. The potential of RED has been demonstrated for multiple image-related tasks such as denoising, deblurring and super-resolution. In this work, we propose a regularization by neural style transfer (RNST) method to further leverage the priors from the neural transfer and denoising engine. This enables RNST to reconstruct a high-quality image from a noisy low-quality image with different image styles and limited data. We validate RNST with clinical MRI scans from 1.5T and 3T and show that RNST can significantly boost image quality. Our results highlight the capability of the RNST framework for MRI reconstruction and the potential for reconstruction tasks with limited data.
</details>
<details>
<summary>摘要</summary>
近期研究表明，使用深度学习模型进行MRI重建有成功经验。然而，大多数报道的方法需要对特定任务的大规模数据进行训练。抑制权（RED）是一个通用管道，它嵌入了一个抑制器作为图像重建的先验。抑制权的潜力已经在多种图像相关任务中展现出来，如降噪、去锈和超解等。在这种工作中，我们提议一种基于神经传输和抑制器的常规化（RNST）方法，以利用神经传输和抑制器的先验来重建高质量图像。我们验证了RNST方法使用临床MRI扫描数据，并显示RNST可以在噪声低质量图像中重建高质量图像，并且可以在有限数据情况下进行重建。我们的结果显示RNST框架在MRI重建中具有优秀的能力，并且有潜力应用于有限数据的重建任务。
</details></li>
</ul>
<hr>
<h2 id="Structured-World-Models-from-Human-Videos"><a href="#Structured-World-Models-from-Human-Videos" class="headerlink" title="Structured World Models from Human Videos"></a>Structured World Models from Human Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10901">http://arxiv.org/abs/2308.10901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Russell Mendonca, Shikhar Bahl, Deepak Pathak</li>
<li>for: 本研究旨在训练机器人通过互联网大规模人类视频数据来快速学习复杂的 manipulate 技能。</li>
<li>methods: 本研究使用了人类视频数据来构建一个结构化的人类行为空间，并在这个空间中学习视觉可行性。然后，通过人类视频数据进行世界模型训练，并在小量机器人互动数据上进行细化调整。</li>
<li>results: 研究发现，通过这种方法，不同的机器人可以在复杂的设置下快速学习 manipulate 技能，仅需在30分钟内进行互动。视频可以在<a target="_blank" rel="noopener" href="https://human-world-model.github.io找到./">https://human-world-model.github.io找到。</a><details>
<summary>Abstract</summary>
We tackle the problem of learning complex, general behaviors directly in the real world. We propose an approach for robots to efficiently learn manipulation skills using only a handful of real-world interaction trajectories from many different settings. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, our belief is that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. Our approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. Further, we train a world model on human videos and fine-tune on a small amount of robot interaction data without any task supervision. We show that this approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction. Videos can be found at https://human-world-model.github.io
</details>
<details>
<summary>摘要</summary>
我们面对现实世界中学习复杂、通用行为的问题。我们提议一种方法，让机器人通过几个不同设定下的实际互动路径学习摄取技能。我们受到电视频道和自然语言领域中大规模数据集的成功所激发，我们信服机器人可以通过互联网规模的人类视频数据来快速学习。人类在世界中进行许多有趣的互动，这可以让机器人不仅建立用Actions和可用性的理解，也可以了解如何这些Actions影响世界来进行摄取。我们的方法建立了基于视觉可用性的结构化人类行为空间，然后将人类视频中的世界模型训练，并在小量机器人互动数据上精致调整。我们显示这种价值空间世界模型可以让不同的机器人在复杂的设定下学习不同的摄取技能，仅需30分钟的互动。视频可以在https://human-world-model.github.io获取。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification"><a href="#Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification" class="headerlink" title="Unlocking Accuracy and Fairness in Differentially Private Image Classification"></a>Unlocking Accuracy and Fairness in Differentially Private Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10888">http://arxiv.org/abs/2308.10888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle</li>
<li>for:  trains models on private data without leaking sensitive information</li>
<li>methods:  uses differential privacy (DP) framework, fine-tunes pre-trained foundation models with DP</li>
<li>results: achieves similar accuracy to non-private classifiers, with private accuracies within a few percent of the non-private state of the art, and without larger performance disparities across demographic groups.<details>
<summary>Abstract</summary>
Privacy-preserving machine learning aims to train models on private data without leaking sensitive information. Differential privacy (DP) is considered the gold standard framework for privacy-preserving training, as it provides formal privacy guarantees. However, compared to their non-private counterparts, models trained with DP often have significantly reduced accuracy. Private classifiers are also believed to exhibit larger performance disparities across subpopulations, raising fairness concerns. The poor performance of classifiers trained with DP has prevented the widespread adoption of privacy preserving machine learning in industry. Here we show that pre-trained foundation models fine-tuned with DP can achieve similar accuracy to non-private classifiers, even in the presence of significant distribution shifts between pre-training data and downstream tasks. We achieve private accuracies within a few percent of the non-private state of the art across four datasets, including two medical imaging benchmarks. Furthermore, our private medical classifiers do not exhibit larger performance disparities across demographic groups than non-private models. This milestone to make DP training a practical and reliable technology has the potential to widely enable machine learning practitioners to train safely on sensitive datasets while protecting individuals' privacy.
</details>
<details>
<summary>摘要</summary>
“隐私保护机器学习” aim to 训练模型在私人数据上无泄露敏感信息。“数据隐私”（DP）被视为机器学习隐私保护的金标准框架，但与非私人模型相比，DP 训练的模型通常会有很大的准确性下降。私人分类器也被认为会在不同的人口集中Displaying 更大的性差，引起公平性的关注。DP 训练的模型表现不佳的问题阻碍了机器学习领域广泛采用隐私保护技术。我们在这篇文章中显示，将预训练的基础模型 fine-tune  avec DP 可以 дости到与非私人模型相似的准确性，甚至在数据分布差异很大的情况下。我们在四个数据集上 achieve private accuracy 与非私人模型相似，包括两个医疗影像标准 benchmark。此外，我们的私人医疗分类器不会在不同的民族群体中表现出更大的性差，与非私人模型相比。这个突破可以让机器学习实践者在敏感数据上安全地训练模型，保护个人隐私。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space"><a href="#Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space" class="headerlink" title="Analyzing Transformer Dynamics as Movement through Embedding Space"></a>Analyzing Transformer Dynamics as Movement through Embedding Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10874">http://arxiv.org/abs/2308.10874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumeet S. Singh</li>
<li>for: 本研究探讨了 transformer 语言模型的基本机制如何导致智能行为的出现。</li>
<li>methods: 我们采用系统方法分析 transformer 的具体机制，并开发了一个数学框架来解释它们的动态。这种新的视角提供了一个原则性的方法来思考问题，并且显示出了智能行为的出现的重要意义。</li>
<li>results: 研究发现，transformer 的核心是一个嵌入空间漫步者，将智能行为映射到嵌入空间中的路径上。每步漫步都会将上下文组合成一个单一的 composite vector，该 vector 的位置定义下一步的路径。无需学习，decode 只是一种嵌入空间中的漫步。知识、智能和技能都是嵌入空间中 vectors 的组织方式，而不是特定神经元或层。关注的贡献是对 vector 的组合Association-bias，但需要更多的研究来证明其重要性。transformer 的整体结构由两种基本操作组成：数据独立的滤波和数据依赖的聚合。这种一致性将 transformer 与其他序列模型和模式联系起来。<details>
<summary>Abstract</summary>
Transformer language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. We adopt a systems approach to analyze Transformers in detail and develop a mathematical framework that frames their dynamics as movement through embedding space. This novel perspective provides a principled way of thinking about the problem and reveals important insights related to the emergence of intelligence:   1. At its core the Transformer is a Embedding Space walker, mapping intelligent behavior to trajectories in this vector space.   2. At each step of the walk, it composes context into a single composite vector whose location in Embedding Space defines the next step.   3. No learning actually occurs during decoding; in-context learning and generalization are simply the result of different contexts composing into different vectors.   4. Ultimately the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in Embedding Space rather than in specific neurons or layers. These abilities are properties of this organization.   5. Attention's contribution boils down to the association-bias it lends to vector composition and which influences the aforementioned organization. However, more investigation is needed to ascertain its significance.   6. The entire model is composed from two principal operations: data independent filtering and data dependent aggregation. This generalization unifies Transformers with other sequence models and across modalities.   Building upon this foundation we formalize and test a semantic space theory which posits that embedding vectors represent semantic concepts and find some evidence of its validity.
</details>
<details>
<summary>摘要</summary>
transformer 语言模型会示出智能行为，如理解自然语言、识别模式、获取知识、理解、规划和使用工具。这篇研究探索了 transformer 底下的机制如何导致智能行为。我们采用系统方法来分析 transformer 的细节，开发了一个数学框架，将 transformer 的动态视为嵌入空间中的运动。这个新的观点提供了一个原理式的思考方式，并显示出智能行为的出现有重要的意义：1. transformer 的核心是嵌入空间漫步者，将智能行为映射到嵌入空间中的路径上。2. 在每次漫步过程中，它会将上下文转换为单一的合成vector，其位于嵌入空间中的位置定义下一步的方向。3. 在解oding过程中，不会有真正的学习 occuring; 内在学习和泛化都是由不同的上下文对vector的聚合所带来的。4.  ultimately, the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in embedding space rather than in specific neurons or layers. these abilities are properties of this organization.5. attention 的贡献可以理解为对 vector 的聚合中带来的协议偏好，这影响了 embedding space 中 vectors 的组织。但是，需要进一步的研究，以了解它的重要性。6. transformer 的整个模型由两个主要操作组成：data independent filtering和data dependent aggregation。这个一致性使 transformer 与其他序列模型以及不同的模式之间建立了联系。基于这个基础，我们正式化了一个 semantic space 理论，提出 embedding vectors 代表 semantics concepts，并发现了一些证据支持这个理论的正确性。
</details></li>
</ul>
<hr>
<h2 id="Majorana-Demonstrator-Data-Release-for-AI-ML-Applications"><a href="#Majorana-Demonstrator-Data-Release-for-AI-ML-Applications" class="headerlink" title="Majorana Demonstrator Data Release for AI&#x2F;ML Applications"></a>Majorana Demonstrator Data Release for AI&#x2F;ML Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10856">http://arxiv.org/abs/2308.10856</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. J. Arnquist, F. T. Avignone III, A. S. Barabash, C. J. Barton, K. H. Bhimani, E. Blalock, B. Bos, M. Busch, M. Buuck, T. S. Caldwell, Y. -D. Chan, C. D. Christofferson, P. -H. Chu, M. L. Clark, C. Cuesta, J. A. Detwiler, Yu. Efremenko, H. Ejiri, S. R. Elliott, N. Fuad, G. K. Giovanetti, M. P. Green, J. Gruszko, I. S. Guinn, V. E. Guiseppe, C. R. Haufe, R. Henning, D. Hervas Aguilar, E. W. Hoppe, A. Hostiuc, M. F. Kidd, I. Kim, R. T. Kouzes, T. E. Lannen V, A. Li, J. M. Lopez-Castano, R. D. Martin, R. Massarczyk, S. J. Meijer, S. Mertens, T. K. Oli, L. S. Paudel, W. Pettus, A. W. P. Poon, B. Quenallata, D. C. Radford, A. L. Reine, K. Rielage, N. W. Ruof, D. C. Schaper, S. J. Schleich, D. Tedeschi, R. L. Varner, S. Vasilyev, S. L. Watkins, J. F. Wilkerson, C. Wiseman, W. Xu, C. -H. Yu, B. X. Zhu</li>
<li>for: 本研究的目的是为了提供一个 Majorana 实验中的数据集，用于训练和测试人工智能和机器学习算法。</li>
<li>methods: 本研究使用了 Majorana 实验中的数据，包括 raw Germanium 探测器波形、激光形态分割cuts 和加工后的能量，共同存储在 HDF5 文件格式中，并附带相关的元数据。</li>
<li>results: 本研究提供了一个特定的数据集，用于支持人工智能和机器学习算法的训练和测试。<details>
<summary>Abstract</summary>
The enclosed data release consists of a subset of the calibration data from the Majorana Demonstrator experiment. Each Majorana event is accompanied by raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, all shared in an HDF5 file format along with relevant metadata. This release is specifically designed to support the training and testing of Artificial Intelligence (AI) and Machine Learning (ML) algorithms upon our data. This document is structured as follows. Section I provides an overview of the dataset's content and format; Section II outlines the location of this dataset and the method for accessing it; Section III presents the NPML Machine Learning Challenge associated with this dataset; Section IV contains a disclaimer from the Majorana collaboration regarding the use of this dataset; Appendix A contains technical details of this data release. Please direct questions about the material provided within this release to liaobo77@ucsd.edu (A. Li).
</details>
<details>
<summary>摘要</summary>
<<SYS>>将附件的数据发布包括 Majorana实验中的一个子集调整数据。每个 Majorana 事件都由 raw 氙元器波形、激发形分割 cuts 和调整后的能量， alles 共享在 HDF5 文件格式中，并附带相关的元数据。这个发布是为支持人工智能（AI）和机器学习（ML）算法的训练和测试而设计的。本文分为以下四部分：I. 数据集的内容和格式的概述II. 数据集的位置和访问方法III. NPML 机器学习挑战与这个数据集相关IV. Majorana 团队的免责声明 appendix A. 数据发布的技术详细信息请对这个发布中的内容向 liaobo77@ucsd.edu (A. Li) 提出问题。>>Note: "Majorana" in the text should be translated as "抗随机扰动器" (anti-random noise device) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks"><a href="#Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks" class="headerlink" title="Evaluating quantum generative models via imbalanced data classification benchmarks"></a>Evaluating quantum generative models via imbalanced data classification benchmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10847">http://arxiv.org/abs/2308.10847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Graham R. Enos, Matthew J. Reagor, Eric Hulburd</li>
<li>for: 这个论文是为了研究量子机器学习模型的不同行为是否与传统模型不同，并在实际数据集上进行系统性的分析。</li>
<li>methods: 这个论文使用可解释人工智能技术来分析从混合量子-классификаル нейрон网络中生成的数据，并对这些数据进行比较与当前的 Mitigating 方法。</li>
<li>results: 研究发现，不同的数据集 exhibits varying degrees of complexity and class imbalance，并且可以使用 hybrid 量子-классификаル生成模型来分析这些数据。这些结果可以帮助我们理解哪些问题是可以使用 hybrid 模型解决，哪些问题则需要更多的研究。<details>
<summary>Abstract</summary>
A limited set of tools exist for assessing whether the behavior of quantum machine learning models diverges from conventional models, outside of abstract or theoretical settings. We present a systematic application of explainable artificial intelligence techniques to analyze synthetic data generated from a hybrid quantum-classical neural network adapted from twenty different real-world data sets, including solar flares, cardiac arrhythmia, and speech data. Each of these data sets exhibits varying degrees of complexity and class imbalance. We benchmark the quantum-generated data relative to state-of-the-art methods for mitigating class imbalance for associated classification tasks. We leverage this approach to elucidate the qualities of a problem that make it more or less likely to be amenable to a hybrid quantum-classical generative model.
</details>
<details>
<summary>摘要</summary>
有限的工具存在，用于判断量子机器学习模型与传统模型之间的行为异同，除了抽象或理论上的设置。我们将可追踪的人工智能技术系统化应用于生成从混合量子-классификаLL大 neural network中的 synthetic数据，该数据来自20个真实世界数据集，包括太阳风暴、心脏 arrhythmia 和语音数据。每个数据集都具有不同的复杂度和类别偏好。我们将量子生成的数据与当前的状态艺术方法进行比较，以mitigate class imbalance相关的分类任务。我们利用这种方法，以便描述一个问题的特点，使其更或 menos适合混合量子-классификаLL生成模型。
</details></li>
</ul>
<hr>
<h2 id="Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility"><a href="#Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility" class="headerlink" title="Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility"></a>Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10846">http://arxiv.org/abs/2308.10846</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oilpricebenchmarks/COB">https://github.com/oilpricebenchmarks/COB</a></li>
<li>paper_authors: Pranay Pasula</li>
<li>for: 这个论文旨在提供一个适用于金融领域的时间序列benchmark，以促进持续学习的进步。</li>
<li>methods: 该论文使用了asset price数据的转换方法，并使用了期望最大化（EM）方法来适应模型。</li>
<li>results: 论文通过生成相关的任务标签，以及对四种持续学习算法的比较，证明了这些benchmark的有效性。<details>
<summary>Abstract</summary>
The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accelerate research in handling distribution shifts in real-world data, especially due to the global importance of the assets considered. We've made the (1) raw price data, (2) task labels generated by our approach, (3) and code for our algorithm available at https://oilpricebenchmarks.github.io.
</details>
<details>
<summary>摘要</summary>
“财经领域内的任务标签时间序列库 scarcity 阻碍了无终学习的进步。解决这个不足，将促进这个领域的创新。因此，我们提出了 COB，即原油价格库存数据。COB 包含了30年的资产价格，其中具有明显的分布迁移，并且根据这些分布迁移生成对应的任务（即频率）标签。我们的贡献包括将资产价格数据转换为可用性干扰量表现，使用期望最大化（EM）运算进行模型适应，生成基于实际世界事件的任务标签，并且将这些标签以及通用的算法公开给社区。我们显示，将这些任务标签包含在内，可以在多个预测时间点上 universally 提高四种不断学习算法的性能，其中一些是现有的State-of-the-art。我们希望这些库可以促进实际数据中的分布迁移处理研究，尤其是由于考虑到资产考虑的全球重要性。我们将（1）原始价格数据、（2）生成的任务标签、以及（3）实现这种算法的代码公开在https://oilpricebenchmarks.github.io。”
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection"><a href="#Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection" class="headerlink" title="Neural Networks Optimizations Against Concept and Data Drift in Malware Detection"></a>Neural Networks Optimizations Against Concept and Data Drift in Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10821">http://arxiv.org/abs/2308.10821</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Maillet, Benjamin Marais</li>
<li>for: 提高基eline神经网络对抗演化漏斗问题</li>
<li>methods: 提出了一种模型无关协议，包括特征减少和使用最新验证集训练，并提出了一种适应退化损失函数 named Drift-Resilient Binary Cross-Entropy</li>
<li>results: 对EMBER数据集（2018）进行训练，对2020-2023年间的恶意文件进行评估，提高了15.2%的恶意软件检测率<details>
<summary>Abstract</summary>
Despite the promising results of machine learning models in malware detection, they face the problem of concept drift due to malware constant evolution. This leads to a decline in performance over time, as the data distribution of the new files differs from the training one, requiring regular model update. In this work, we propose a model-agnostic protocol to improve a baseline neural network to handle with the drift problem. We show the importance of feature reduction and training with the most recent validation set possible, and propose a loss function named Drift-Resilient Binary Cross-Entropy, an improvement to the classical Binary Cross-Entropy more effective against drift. We train our model on the EMBER dataset (2018) and evaluate it on a dataset of recent malicious files, collected between 2020 and 2023. Our improved model shows promising results, detecting 15.2% more malware than a baseline model.
</details>
<details>
<summary>摘要</summary>
尽管机器学习模型在恶意软件检测方面表现良好，但它们面临着概念漂移问题，即恶意软件不断演化导致模型性能逐渐下降。这是因为新的文件数据分布与训练数据分布不同，需要定期更新模型。在这种情况下，我们提出了一种模型无关协议，用于改进基eline neural network，以适应概念漂移问题。我们表明了特征减少和使用最新的验证集进行训练的重要性，并提出了一种名为漂移抗耐 binary cross-entropy 的损失函数，它在对漂移问题更有效。我们使用 EMBER 数据集（2018）进行训练，并对2020-2023年间收集的恶意文件进行评估。我们改进后的模型表现出色，可以检测到基eline模型无法检测到的15.2%更多的恶意软件。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/cs.LG_2023_08_22/" data-id="clltau92x006jcr886bwhe3g7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.SD_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.SD_2023_08_22/">cs.SD - 2023-08-22 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Furnishing-Sound-Event-Detection-with-Language-Model-Abilities"><a href="#Furnishing-Sound-Event-Detection-with-Language-Model-Abilities" class="headerlink" title="Furnishing Sound Event Detection with Language Model Abilities"></a>Furnishing Sound Event Detection with Language Model Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11530">http://arxiv.org/abs/2308.11530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang</li>
<li>for: 本文further探讨语言模型（LMs）在视觉交互中的能力，特别是声事件检测（SED）。</li>
<li>methods: 提议一种精炼的方法，将音频特征和文本特征进行对应，以实现声事件分类和时间位置检测。该框架包括声学编码器、对应模块和解 Coupled语言解码器，从 audio 特征中生成时间和事件序列。与传统方法相比，我们的模型更简洁和全面，因为语言模型直接利用其语义能力来生成序列。</li>
<li>results: 研究表明，提议的方法可以准确地检测声事件。<details>
<summary>Abstract</summary>
Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification. Evaluation results show that the proposed method achieves accurate sequences of sound event detection.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Recently" is translated as "最近" (most recent)* "ability" is translated as "能力" (capability)* "language models" is translated as "语言模型" (language models)* "visual cross-modality" is translated as "视觉交叠" (visual intersection)* "sound event detection" is translated as "声音事件检测" (sound event detection)* "acoustic encoder" is translated as "声音编码器" (acoustic encoder)* "contrastive module" is translated as "对比模块" (contrastive module)* "decoupled language decoder" is translated as "分离语言解码器" (decoupled language decoder)* "temporal and event sequences" is translated as "时间和事件序列" (temporal and event sequences)* "compared with conventional works" is translated as "与传统工作比较" (compared with conventional works)* "require complicated processing" is translated as "需要复杂处理" (require complicated processing)* "barely utilize limited audio features" is translated as "几乎只使用有限的音频特征" (barely utilize limited audio features)* "our model is more concise and comprehensive" is translated as "我们的模型更简洁和全面" (our model is more concise and comprehensive)* "directly leverage its semantic capabilities" is translated as "直接利用它的 semantic 能力" (directly leverage its semantic capabilities)* "generate the sequences" is translated as "生成序列" (generate the sequences)* "timestamps capture" is translated as "时间捕捉" (timestamps capture)* "event classification" is translated as "事件分类" (event classification)* "evaluation results show" is translated as "评估结果表明" (evaluation results show)* "accurate sequences of sound event detection" is translated as "准确的声音事件检测序列" (accurate sequences of sound event detection)
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users"><a href="#Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users" class="headerlink" title="Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users"></a>Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11456">http://arxiv.org/abs/2308.11456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Udo Diehl, Hannes Zilly, Felix Sattler, Yosef Singer, Kevin Kepp, Mark Berry, Henning Hasemann, Marlene Zippel, Müge Kaya, Paul Meyer-Rachner, Annett Pudszuhn, Veit M. Hofmann, Matthias Vormann, Elias Sprengel<br>for:The paper is written for people with hearing loss who use hearing aids, particularly those in real-world noisy environments.methods:The paper uses deep learning-based denoising systems that run in real-time on mobile devices (iPhone 7 and Samsung Galaxy S10) with a total delay of around 75ms.results:The denoising system improves audio quality, as measured by subjective ratings, speech intelligibility, and live conversations in noisy environments. Subjective ratings increase by more than 40%, and speech reception thresholds improve by 1.6 dB SRT compared to a fitted hearing aid as a baseline. The system is the first of its kind to be implemented on a mobile device and streamed directly to users’ hearing aids using only a single channel of audio input, resulting in improved user satisfaction.<details>
<summary>Abstract</summary>
The hearing loss of almost half a billion people is commonly treated with hearing aids. However, current hearing aids often do not work well in real-world noisy environments. We present a deep learning based denoising system that runs in real time on iPhone 7 and Samsung Galaxy S10 (25ms algorithmic latency). The denoised audio is streamed to the hearing aid, resulting in a total delay of around 75ms. In tests with hearing aid users having moderate to severe hearing loss, our denoising system improves audio across three tests: 1) listening for subjective audio ratings, 2) listening for objective speech intelligibility, and 3) live conversations in a noisy environment for subjective ratings. Subjective ratings increase by more than 40%, for both the listening test and the live conversation compared to a fitted hearing aid as a baseline. Speech reception thresholds, measuring speech understanding in noise, improve by 1.6 dB SRT. Ours is the first denoising system that is implemented on a mobile device, streamed directly to users' hearing aids using only a single channel as audio input while improving user satisfaction on all tested aspects, including speech intelligibility. This includes overall preference of the denoised and streamed signal over the hearing aid, thereby accepting the higher latency for the significant improvement in speech understanding.
</details>
<details>
<summary>摘要</summary>
现有约一亿人的听力问题，通常通过听觉器进行治疗。然而，现有的听觉器 frequently 在实际噪音环境中不够有效。我们提出了基于深度学习的噪音除除系统，可以在 iPhone 7 和 Samsung Galaxy S10 上进行实时运行（25ms 的算法遅延）。噪音除除系统将运算到听觉器上，总延迟约 75ms。在听觉器用户进行 moderate 至 severe 的听力损伤时，我们的噪音除除系统在三个测试中表现出色：1）聆听Subjective 音乐评分，2）聆听Speech 智能度测试，3）在噪音环境中进行生活对话的Subjective 评分。聆听者的评分提高了 más de 40%，包括聆听测试和生活对话。Speech 收集阈值（SRT）也提高了1.6 dB。我们的噪音除除系统是首个在 mobil device 上实现的，直接将清晰的音频流传递到用户的听觉器，使用单一通道的音频输入，而不需要听觉器的额外配件。在所有测试项目中，包括聆听者对清晰音频的偏好和生活对话中的听力理解，我们的系统获得了更高的使用者满意度。
</details></li>
</ul>
<hr>
<h2 id="Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition"><a href="#Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition" class="headerlink" title="Convoifilter: A case study of doing cocktail party speech recognition"></a>Convoifilter: A case study of doing cocktail party speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11380">http://arxiv.org/abs/2308.11380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thai-Binh Nguyen, Alexander Waibel</li>
<li>for: 提高自动语音识别（ASR）的精度，特别是在响度高、听录环境中。</li>
<li>methods: 使用单通道speech减少模块减少干扰声音，同时使用ASR模块。通过这种方法，模型可以降低ASR的单词错误率（WER）从80%降至26.4%。</li>
<li>results: 通过对这两个组件进行联合细调，降低WER从26.4%下降至14.5%。<details>
<summary>Abstract</summary>
This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise, along with an ASR module. Through this approach, the model is able to decrease the word error rate (WER) of ASR from 80% to 26.4%. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1"><a href="#Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1" class="headerlink" title="Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1"></a>Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11337">http://arxiv.org/abs/2308.11337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ünal Ege Gaznepoglu, Nils Peters</li>
<li>for: 这项研究旨在评估VPC基线B1是否能够生成人性化的语音。</li>
<li>methods: 这项研究使用了VPC基线B1中的神经 vocoder 将 F0、x-vectors 和瓶颈特征转换为语音示例。</li>
<li>results: 研究发现，神经 vocoder 在语音示例中引入了 artifacts，导致语音具有不自然的感觉。 MUSHRA-like 听试中，18名参与者也证实了这一点，促使进一步研究VPC基线B1的分析和 sintesis 组件。<details>
<summary>Abstract</summary>
Speaker anonymization systems continue to improve their ability to obfuscate the original speaker characteristics in a speech signal, but often create processing artifacts and unnatural sounding voices as a tradeoff. Many of those systems stem from the VoicePrivacy Challenge (VPC) Baseline B1, using a neural vocoder to synthesize speech from an F0, x-vectors and bottleneck features-based speech representation. Inspired by this, we investigate the reproduction capabilities of the aforementioned baseline, to assess how successful the shared methodology is in synthesizing human-like speech. We use four objective metrics to measure speech quality, waveform similarity, and F0 similarity. Our findings indicate that both the speech representation and the vocoder introduces artifacts, causing an unnatural perception. A MUSHRA-like listening test on 18 subjects corroborate our findings, motivating further research on the analysis and synthesis components of the VPC Baseline B1.
</details>
<details>
<summary>摘要</summary>
对话匿名系统继续提高了对话者特征的隐蔽能力，但经常会产生处理 artifacts 和不自然的声音作为交易。这些系统多数来自于 VoicePrivacy Challenge（VPC）基线B1，使用神经 vocoder 将 F0、x-vectors 和瓶颈特征转化为语音。受这些基线的启发，我们调查了论文中的复制能力，以评估这种方法是否能够 sinthez human-like 语音。我们使用四个对象指标测量语音质量、波形相似性和 F0 相似性。我们的发现表明， tanto 语音表示法 quanto  vocoder 都会产生缺陷，导致不自然的感觉。一个 MUSHRA-like 听众测试中，18名参与者证实了我们的发现，并促使了对分析和 sinthez 组件的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning"><a href="#Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning" class="headerlink" title="Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning"></a>Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11276">http://arxiv.org/abs/2308.11276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shansong Liu, Atin Sakkeer Hussain, Chenshuo Sun, Ying Shan</li>
<li>for: 这篇论文旨在解决文本到音乐生成（T2M-Gen）领域中的一个主要障碍，即公共可用的大规模音乐数据集中的缺乏。</li>
<li>methods: 我们提出了一种名为Music Understanding LLaMA（MU-LLaMA）的模型，可以回答音乐相关的问题并生成音乐文件的标题。我们的模型使用一个预训练的MERT模型来提取音乐特征。</li>
<li>results: 我们的实验表明，使用我们设计的MusicQA数据集训练MU-LLaMA模型可以在多个维度上达到出色的表现，包括音乐问答和音乐标题生成。我们的模型在不同的维度上的表现都高于当前状态的艺术模型，并为T2M-Gen领域的进步带来了希望。<details>
<summary>Abstract</summary>
Text-to-music generation (T2M-Gen) faces a major obstacle due to the scarcity of large-scale publicly available music datasets with natural language captions. To address this, we propose the Music Understanding LLaMA (MU-LLaMA), capable of answering music-related questions and generating captions for music files. Our model utilizes audio representations from a pretrained MERT model to extract music features. However, obtaining a suitable dataset for training the MU-LLaMA model remains challenging, as existing publicly accessible audio question answering datasets lack the necessary depth for open-ended music question answering. To fill this gap, we present a methodology for generating question-answer pairs from existing audio captioning datasets and introduce the MusicQA Dataset designed for answering open-ended music-related questions. The experiments demonstrate that the proposed MU-LLaMA model, trained on our designed MusicQA dataset, achieves outstanding performance in both music question answering and music caption generation across various metrics, outperforming current state-of-the-art (SOTA) models in both fields and offering a promising advancement in the T2M-Gen research field.
</details>
<details>
<summary>摘要</summary>
文本转换为乐曲生成（T2M-Gen）遇到了一个主要的障碍，即公共可用的大规模乐曲数据集中的自然语言标签缺乏。为解决这一问题，我们提议了Music Understanding LLaMA（MU-LLaMA），能够回答乐曲相关的问题并生成乐曲文件的标签。我们的模型利用了预训练的MERT模型来提取乐曲特征。但是，为了训练MU-LLaMA模型，获得合适的数据集仍然是一个挑战，因为现有的公共可用的音频问答数据集缺乏必要的深度来回答开放式乐曲问题。为了填补这一漏洞，我们提出了一种方法，可以从现有的音频描述数据集中生成问题答案对。我们还介绍了MusicQA数据集，用于回答开放式乐曲相关的问题。实验结果表明，我们提出的MU-LLaMA模型，使用我们设计的MusicQA数据集进行训练，在不同的纪录metric上取得了极佳的表现，超过了当前状态的前方模型在乐曲问题回答和乐曲描述生成方面，并提供了T2M-Gen研究领域的一个可能的进步。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Bends-in-Popular-Music-Guitar-Tablatures"><a href="#Modeling-Bends-in-Popular-Music-Guitar-Tablatures" class="headerlink" title="Modeling Bends in Popular Music Guitar Tablatures"></a>Modeling Bends in Popular Music Guitar Tablatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12307">http://arxiv.org/abs/2308.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/adhooge1/bend-prediction">https://gitlab.com/adhooge1/bend-prediction</a></li>
<li>paper_authors: Alexandre D’Hooge, Louis Bigo, Ken Déguernel</li>
<li>For: 本研究旨在提高电 guitar tablature 中的折衣预测，以便帮助将其他乐器的乐谱转换成 guitar tablature。* Methods: 本研究使用了一组25个高级特征，对每个 tablature 进行分析，以预测下一个折衣的发生。* Results: 实验结果显示，使用决策树可以成功预测折衣的发生，F1 分数为 0.71，false positive 预测很少，这表明这种方法可以有效地帮助将非 guitar 乐谱转换成 guitar tablature。<details>
<summary>Abstract</summary>
Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on/pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into guitar tablatures.
</details>
<details>
<summary>摘要</summary>
Tablature notation widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information, including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on/pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into guitar tablatures.
</details></li>
</ul>
<hr>
<h2 id="PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion"><a href="#PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion" class="headerlink" title="PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion"></a>PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11084">http://arxiv.org/abs/2308.11084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yimin Deng, Huaizhen Tang, Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao</li>
<li>for: 本研究旨在提出一个新的声音转换框架，以实现无需文本转换的自然声音转换。</li>
<li>methods: 本研究使用了一新的声音增强算法来提取robust的调音信息，并应用了mask和predict机制来分离调音和内容信息。</li>
<li>results: 实验结果显示，PMVC框架能够提高声音转换的自然性和相似度。<details>
<summary>Abstract</summary>
Voice conversion as the style transfer task applied to speech, refers to converting one person's speech into a new speech that sounds like another person's. Up to now, there has been a lot of research devoted to better implementation of VC tasks. However, a good voice conversion model should not only match the timbre information of the target speaker, but also expressive information such as prosody, pace, pause, etc. In this context, prosody modeling is crucial for achieving expressive voice conversion that sounds natural and convincing. Unfortunately, prosody modeling is important but challenging, especially without text transcriptions. In this paper, we firstly propose a novel voice conversion framework named 'PMVC', which effectively separates and models the content, timbre, and prosodic information from the speech without text transcriptions. Specially, we introduce a new speech augmentation algorithm for robust prosody extraction. And building upon this, mask and predict mechanism is applied in the disentanglement of prosody and content information. The experimental results on the AIShell-3 corpus supports our improvement of naturalness and similarity of converted speech.
</details>
<details>
<summary>摘要</summary>
声音转换作为样式传递任务应用于语音，指的是将一个人的语音转换成另一个人的语音，以致 зву量和样式相似。至今，对于更好地实现声音转换任务的研究已经很多。然而，一个好的声音转换模型应该不仅匹配目标说话者的时刻信息，还应该包括表达信息 such as 味道、速度、停顿等。在这种情况下，味道模型化是关键的，以实现自然和吸引人的声音转换。可惜，味道模型化是重要但困难的，特别是无文本词汇。在这篇论文中，我们首先提出了一种新的声音转换框架，名为PMVC，可以有效地从语音中分离和模型内容、时刻和表达信息。特别是，我们提出了一种新的语音增强算法，用于Robust prosody extraction。然后，我们在内容和味道信息之间进行遮盖和预测，以实现味道和内容信息的分离。实验结果表示，PMVC框架在AIShell-3 corpus上提高了转换后语音的自然性和相似性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/cs.SD_2023_08_22/" data-id="clltau93x009ecr8861lo4lfr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/eess.AS_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/eess.AS_2023_08_22/">eess.AS - 2023-08-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Furnishing-Sound-Event-Detection-with-Language-Model-Abilities"><a href="#Furnishing-Sound-Event-Detection-with-Language-Model-Abilities" class="headerlink" title="Furnishing Sound Event Detection with Language Model Abilities"></a>Furnishing Sound Event Detection with Language Model Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11530">http://arxiv.org/abs/2308.11530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang</li>
</ul>
<p>Abstract:<br>Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification. Evaluation results show that the proposed method achieves accurate sequences of sound event detection.</p>
<hr>
<h2 id="Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users"><a href="#Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users" class="headerlink" title="Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users"></a>Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11456">http://arxiv.org/abs/2308.11456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Udo Diehl, Hannes Zilly, Felix Sattler, Yosef Singer, Kevin Kepp, Mark Berry, Henning Hasemann, Marlene Zippel, Müge Kaya, Paul Meyer-Rachner, Annett Pudszuhn, Veit M. Hofmann, Matthias Vormann, Elias Sprengel</li>
</ul>
<p>Abstract:<br>The hearing loss of almost half a billion people is commonly treated with hearing aids. However, current hearing aids often do not work well in real-world noisy environments. We present a deep learning based denoising system that runs in real time on iPhone 7 and Samsung Galaxy S10 (25ms algorithmic latency). The denoised audio is streamed to the hearing aid, resulting in a total delay of around 75ms. In tests with hearing aid users having moderate to severe hearing loss, our denoising system improves audio across three tests: 1) listening for subjective audio ratings, 2) listening for objective speech intelligibility, and 3) live conversations in a noisy environment for subjective ratings. Subjective ratings increase by more than 40%, for both the listening test and the live conversation compared to a fitted hearing aid as a baseline. Speech reception thresholds, measuring speech understanding in noise, improve by 1.6 dB SRT. Ours is the first denoising system that is implemented on a mobile device, streamed directly to users’ hearing aids using only a single channel as audio input while improving user satisfaction on all tested aspects, including speech intelligibility. This includes overall preference of the denoised and streamed signal over the hearing aid, thereby accepting the higher latency for the significant improvement in speech understanding.</p>
<hr>
<h2 id="Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition"><a href="#Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition" class="headerlink" title="Convoifilter: A case study of doing cocktail party speech recognition"></a>Convoifilter: A case study of doing cocktail party speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11380">http://arxiv.org/abs/2308.11380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thai-Binh Nguyen, Alexander Waibel</li>
</ul>
<p>Abstract:<br>This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker’s voice from background noise, along with an ASR module. Through this approach, the model is able to decrease the word error rate (WER) of ASR from 80% to 26.4%. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning.</p>
<hr>
<h2 id="Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1"><a href="#Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1" class="headerlink" title="Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1"></a>Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11337">http://arxiv.org/abs/2308.11337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ünal Ege Gaznepoglu, Nils Peters</li>
</ul>
<p>Abstract:<br>Speaker anonymization systems continue to improve their ability to obfuscate the original speaker characteristics in a speech signal, but often create processing artifacts and unnatural sounding voices as a tradeoff. Many of those systems stem from the VoicePrivacy Challenge (VPC) Baseline B1, using a neural vocoder to synthesize speech from an F0, x-vectors and bottleneck features-based speech representation. Inspired by this, we investigate the reproduction capabilities of the aforementioned baseline, to assess how successful the shared methodology is in synthesizing human-like speech. We use four objective metrics to measure speech quality, waveform similarity, and F0 similarity. Our findings indicate that both the speech representation and the vocoder introduces artifacts, causing an unnatural perception. A MUSHRA-like listening test on 18 subjects corroborate our findings, motivating further research on the analysis and synthesis components of the VPC Baseline B1.</p>
<hr>
<h2 id="Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning"><a href="#Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning" class="headerlink" title="Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning"></a>Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11276">http://arxiv.org/abs/2308.11276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shansong Liu, Atin Sakkeer Hussain, Chenshuo Sun, Ying Shan</li>
</ul>
<p>Abstract:<br>Text-to-music generation (T2M-Gen) faces a major obstacle due to the scarcity of large-scale publicly available music datasets with natural language captions. To address this, we propose the Music Understanding LLaMA (MU-LLaMA), capable of answering music-related questions and generating captions for music files. Our model utilizes audio representations from a pretrained MERT model to extract music features. However, obtaining a suitable dataset for training the MU-LLaMA model remains challenging, as existing publicly accessible audio question answering datasets lack the necessary depth for open-ended music question answering. To fill this gap, we present a methodology for generating question-answer pairs from existing audio captioning datasets and introduce the MusicQA Dataset designed for answering open-ended music-related questions. The experiments demonstrate that the proposed MU-LLaMA model, trained on our designed MusicQA dataset, achieves outstanding performance in both music question answering and music caption generation across various metrics, outperforming current state-of-the-art (SOTA) models in both fields and offering a promising advancement in the T2M-Gen research field.</p>
<hr>
<h2 id="Modeling-Bends-in-Popular-Music-Guitar-Tablatures"><a href="#Modeling-Bends-in-Popular-Music-Guitar-Tablatures" class="headerlink" title="Modeling Bends in Popular Music Guitar Tablatures"></a>Modeling Bends in Popular Music Guitar Tablatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12307">http://arxiv.org/abs/2308.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/adhooge1/bend-prediction">https://gitlab.com/adhooge1/bend-prediction</a></li>
<li>paper_authors: Alexandre D’Hooge, Louis Bigo, Ken Déguernel</li>
</ul>
<p>Abstract:<br>Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on&#x2F;pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into guitar tablatures.</p>
<hr>
<h2 id="An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification"><a href="#An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification" class="headerlink" title="An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification"></a>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11241">http://arxiv.org/abs/2308.11241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harunorikawano/speaker-identification-with-tgp">https://github.com/harunorikawano/speaker-identification-with-tgp</a></li>
<li>paper_authors: Harunori Kawano, Sota Shimizu</li>
</ul>
<p>Abstract:<br>Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 85.9% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at <a target="_blank" rel="noopener" href="https://github.com/HarunoriKawano/speaker-identification-with-tgp">https://github.com/HarunoriKawano/speaker-identification-with-tgp</a>.</p>
<hr>
<h2 id="PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion"><a href="#PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion" class="headerlink" title="PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion"></a>PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11084">http://arxiv.org/abs/2308.11084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yimin Deng, Huaizhen Tang, Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao</li>
</ul>
<p>Abstract:<br>Voice conversion as the style transfer task applied to speech, refers to converting one person’s speech into a new speech that sounds like another person’s. Up to now, there has been a lot of research devoted to better implementation of VC tasks. However, a good voice conversion model should not only match the timbre information of the target speaker, but also expressive information such as prosody, pace, pause, etc. In this context, prosody modeling is crucial for achieving expressive voice conversion that sounds natural and convincing. Unfortunately, prosody modeling is important but challenging, especially without text transcriptions. In this paper, we firstly propose a novel voice conversion framework named ‘PMVC’, which effectively separates and models the content, timbre, and prosodic information from the speech without text transcriptions. Specially, we introduce a new speech augmentation algorithm for robust prosody extraction. And building upon this, mask and predict mechanism is applied in the disentanglement of prosody and content information. The experimental results on the AIShell-3 corpus supports our improvement of naturalness and similarity of converted speech.</p>
<hr>
<h2 id="Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression"><a href="#Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression" class="headerlink" title="Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression"></a>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11053">http://arxiv.org/abs/2308.11053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</li>
</ul>
<p>Abstract:<br>Echo cancellation and noise reduction are essential for full-duplex communication, yet most existing neural networks have high computational costs and are inflexible in tuning model complexity. In this paper, we introduce time-frequency dual-path compression to achieve a wide range of compression ratios on computational cost. Specifically, for frequency compression, trainable filters are used to replace manually designed filters for dimension reduction. For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io&#x2F;ultra_dual_path_compression.github.io&#x2F;.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/eess.AS_2023_08_22/" data-id="clltau94l00bbcr8811zu4a61" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/eess.IV_2023_08_22/" class="article-date">
  <time datetime="2023-08-21T16:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/eess.IV_2023_08_22/">eess.IV - 2023-08-22 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms"><a href="#Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms" class="headerlink" title="Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms"></a>Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11468">http://arxiv.org/abs/2308.11468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariapia Rita Iandolo, Francesca Razzano, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 本研究使用Google Earth Engine（GEE）平台进行多时间分析，检测城市区域的变化使用光学数据和专门的机器学习（ML）算法。</li>
<li>methods: 作为案例研究，选择了埃及国家的开罗市，为过去一个十年内世界上最多人口的五个超大城市之一。从2013年7月到2021年7月，对研究区域进行分类和变化检测分析。</li>
<li>results: 结果表明提出的方法有效地确定了在选定时间间发生变化和不发生变化的城市区域。此外，本研究也证明了GEE作为云端解决方案，可以有效地处理大量的卫星数据。<details>
<summary>Abstract</summary>
The aim of this work is to perform a multitemporal analysis using the Google Earth Engine (GEE) platform for the detection of changes in urban areas using optical data and specific machine learning (ML) algorithms. As a case study, Cairo City has been identified, in Egypt country, as one of the five most populous megacities of the last decade in the world. Classification and change detection analysis of the region of interest (ROI) have been carried out from July 2013 to July 2021. Results demonstrate the validity of the proposed method in identifying changed and unchanged urban areas over the selected period. Furthermore, this work aims to evidence the growing significance of GEE as an efficient cloud-based solution for managing large quantities of satellite data.
</details>
<details>
<summary>摘要</summary>
目的是使用Google Earth Engine（GEE）平台进行多时间分析，以探测城市区域的变化使用光学数据和专门的机器学习（ML）算法。作为案例研究，埃及的开罗城市被选为全球最后一个十年最为人口稠密的五个超级城市之一。从2013年7月至2021年7月的时间段进行了区域兴趣（ROI）的分类和变化检测分析。结果表明提出的方法有效地标识了在选定时间段内发生变化和不发生变化的城市区域。此外，本研究也旨在证明GEE作为云计算平台，对快速处理大量卫星数据表现出了高效的能力。
</details></li>
</ul>
<hr>
<h2 id="Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine"><a href="#Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine" class="headerlink" title="Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine"></a>Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11340">http://arxiv.org/abs/2308.11340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesca Razzano, Mariapia Rita Iandolo, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 这个研究旨在使用Synthetic Aperture Radar (SAR)和光学数据进行地球表面分类。</li>
<li>methods: 这个研究使用了Sentinel-1 (S-1)和Sentinel-2 (S-2)数据的集成，通过超vision机器学习算法在Google Earth Engine (GEE)平台上进行分类。</li>
<li>results: 研究结果表明，Radar和光学Remote探测提供了补充性信息，有利于地表覆盖分类，通常导致映射精度提高。此外，这篇论文也证明了GEE在处理大量卫星数据方面的emerging角色。<details>
<summary>Abstract</summary>
In this study, Synthetic Aperture Radar (SAR) and optical data are both considered for Earth surface classification. Specifically, the integration of Sentinel-1 (S-1) and Sentinel-2 (S-2) data is carried out through supervised Machine Learning (ML) algorithms implemented on the Google Earth Engine (GEE) platform for the classification of a particular region of interest. Achieved results demonstrate how in this case radar and optical remote detection provide complementary information, benefiting surface cover classification and generally leading to increased mapping accuracy. In addition, this paper works in the direction of proving the emerging role of GEE as an effective cloud-based tool for handling large amounts of satellite data.
</details>
<details>
<summary>摘要</summary>
这个研究中，使用Synthetic Aperture Radar（SAR）和光学数据进行地面分类。特别是通过监督式机器学习（ML）算法在Google Earth Engine（GEE）平台上结合Sentinel-1（S-1）和Sentinel-2（S-2）数据进行地面覆盖分类。实际结果表明在这种情况下，雷达和光学Remote探测提供了补充性信息，有利于地面覆盖分类，通常导致增加的地图精度。此外，这篇论文还证明了GEE在处理巨量卫星数据方面的emerging角色。
</details></li>
</ul>
<hr>
<h2 id="PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction"><a href="#PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction" class="headerlink" title="PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction"></a>PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11281">http://arxiv.org/abs/2308.11281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eyal Hanania, Ilya Volovik, Lilach Barkat, Israel Cohen, Moti Freiman</li>
<li>for: 这篇论文旨在描述一种基于深度学习的自由呼吸T1映像注射技术，以增强diffuse myocardial disease的诊断。</li>
<li>methods: 该技术使用了深度学习模型来 correction of motion artifacts in free-breathing T1 mapping. The model incorporates the signal decay model to encourage physically-plausible deformations along the longitudinal relaxation axis.</li>
<li>results: 对于5个 эксперименталь setup，PCMC-T1表现出最高的模型适应质量(R2: 0.955)和最高的клиниче影响(clinical score: 3.93)，在比较基eline方法时表现出了优异性。<details>
<summary>Abstract</summary>
T1 mapping is a quantitative magnetic resonance imaging (qMRI) technique that has emerged as a valuable tool in the diagnosis of diffuse myocardial diseases. However, prevailing approaches have relied heavily on breath-hold sequences to eliminate respiratory motion artifacts. This limitation hinders accessibility and effectiveness for patients who cannot tolerate breath-holding. Image registration can be used to enable free-breathing T1 mapping. Yet, inherent intensity differences between the different time points make the registration task challenging. We introduce PCMC-T1, a physically-constrained deep-learning model for motion correction in free-breathing T1 mapping. We incorporate the signal decay model into the network architecture to encourage physically-plausible deformations along the longitudinal relaxation axis. We compared PCMC-T1 to baseline deep-learning-based image registration approaches using a 5-fold experimental setup on a publicly available dataset of 210 patients. PCMC-T1 demonstrated superior model fitting quality (R2: 0.955) and achieved the highest clinical impact (clinical score: 3.93) compared to baseline methods (0.941, 0.946 and 3.34, 3.62 respectively). Anatomical alignment results were comparable (Dice score: 0.9835 vs. 0.984, 0.988). Our code and trained models are available at https://github.com/eyalhana/PCMC-T1.
</details>
<details>
<summary>摘要</summary>
T1映射是一种量化核磁共振成像（qMRI）技术，在慢性心肺疾病诊断中发挥了重要作用。然而，现有的方法都是基于呼吸停止序列来消除呼吸运动artefacts，这限制了患者可以tolerate的范围。图像 registrtion可以使得自由呼吸T1映射成为可能。然而，不同时点的信号强度之间的自然差异使得注册任务变得困难。我们介绍了PCMC-T1，一种基于深度学习的物理约束模型，用于自由呼吸T1映射中的运动 corrections。我们在网络架构中包含了信号衰减模型，以便鼓励物理可能的扭曲 along the longitudinal relaxation axis。我们与基eline deep learning based image registrtion方法进行了5-fold实验，结果显示PCMC-T1的模型适应质量（R2：0.955）和临床影响（临床分数：3.93）都高于基eline方法（0.941、0.946和3.34、3.62分别）。解剖对应结果相似（Dice分数：0.9835 vs. 0.984、0.988）。我们的代码和训练模型可以在https://github.com/eyalhana/PCMC-T1上获取。
</details></li>
</ul>
<hr>
<h2 id="Validation-of-apparent-intra-and-extra-myocellular-lipid-content-indicator-using-spiral-spectroscopic-imaging-at-3T"><a href="#Validation-of-apparent-intra-and-extra-myocellular-lipid-content-indicator-using-spiral-spectroscopic-imaging-at-3T" class="headerlink" title="Validation of apparent intra-and extra-myocellular lipid content indicator using spiral spectroscopic imaging at 3T"></a>Validation of apparent intra-and extra-myocellular lipid content indicator using spiral spectroscopic imaging at 3T</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11668">http://arxiv.org/abs/2308.11668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Naëgel, Magalie Viallon, Jabrane Karkouri, Thomas Troalen, Pierre Croisille, Hélène Ratiney</li>
<li>for: 本研究旨在开发一种快速简单的征方法，用于映射IMCL和EMCL显示的内容，这是一项复杂的任务，并与经典质量量化结果进行比较。</li>
<li>methods: 本研究使用旋转MRSI技术来实现快速简单的征方法，并对肌肉区域进行研究。</li>
<li>results: 研究结果表明，本方法可以快速、简单地映射IMCL和EMCL显示的内容，并与经典质量量化结果相符。<details>
<summary>Abstract</summary>
This work presents a fast and simple method based on spiral MRSI for mapping the IMCL and EMCL apparent content, which is a challenging task and it compares this indicator to classical quantification results in muscles of interest.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种快速简单的方法，基于螺旋MRSI测量IMCL和EMCL显示的内容，这是一项复杂的任务，并与经典量化结果进行比较。Here's a breakdown of the translation:* 这个研究 (zhè ge yánjiū) - This study* 提出 (tīshuō) - proposes* 一种 (yī zhī) - a kind of* 方法 (fāngfa) - method* 基于 (jīyù) - based on* 螺旋MRSI (lúnshēn MRSI) - spiral MRSI* 测量 (cèliàng) - measurement* IMCL (yìmín cluò) - intramuscular adipose tissue* 和 (hé) - and* EMCL (èrmín cluò) - extramuscular adipose tissue* 显示 (xiǎnshì) - display* 的 (de) - possessive particle* 内容 (néngyòng) - content* 是 (shì) - is* 一项 (yījiàn) - a task* 复杂 (fùzé) - complex* 与 (yǔ) - and* 经典 (jīngdiǎn) - classical* 量化 (liàngzhèng) - quantification* 结果 (jiéguò) - result* 进行 (jìnxiàng) - to conduct* 比较 (bǐjiào) - comparisonNote that the translation of "IMCL" and "EMCL" as "内容" (content) is a bit ambiguous, as these terms typically refer to specific types of tissue, rather than a general term for content. However, in the context of the sentence, it seems to be using "内容" to refer to the apparent content of the tissue, rather than the tissue itself.
</details></li>
</ul>
<hr>
<h2 id="Phase-Aberration-Correction-A-Deep-Learning-Based-Aberration-to-Aberration-Approach"><a href="#Phase-Aberration-Correction-A-Deep-Learning-Based-Aberration-to-Aberration-Approach" class="headerlink" title="Phase Aberration Correction: A Deep Learning-Based Aberration to Aberration Approach"></a>Phase Aberration Correction: A Deep Learning-Based Aberration to Aberration Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11149">http://arxiv.org/abs/2308.11149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mostafa Sharifzadeh, Sobhan Goudarzi, An Tang, Habib Benali, Hassan Rivaz</li>
<li>for: 本研究旨在开发一种不需要真实ground truth的深度学习方法，用于correcting phase aberration问题在ultrasound imaging中。</li>
<li>methods: 我们提出了一种使用深度学习方法，并使用Randomly Aberrated RF Data作为输入和目标输出。我们还提出了一种适应性混合损失函数，以便更高效地训练这种网络。</li>
<li>results: 我们在实验中发现，使用我们提出的方法可以高效地correct phase aberration问题，并且可以在实际场景中使用。此外，我们还发布了一个包含161,701个单平面波图像（RF数据）的数据集，以便解决深度学习方法的数据不足问题。<details>
<summary>Abstract</summary>
One of the primary sources of suboptimal image quality in ultrasound imaging is phase aberration. It is caused by spatial changes in sound speed over a heterogeneous medium, which disturbs the transmitted waves and prevents coherent summation of echo signals. Obtaining non-aberrated ground truths in real-world scenarios can be extremely challenging, if not impossible. This challenge hinders training of deep learning-based techniques' performance due to the presence of domain shift between simulated and experimental data. Here, for the first time, we propose a deep learning-based method that does not require ground truth to correct the phase aberration problem, and as such, can be directly trained on real data. We train a network wherein both the input and target output are randomly aberrated radio frequency (RF) data. Moreover, we demonstrate that a conventional loss function such as mean square error is inadequate for training such a network to achieve optimal performance. Instead, we propose an adaptive mixed loss function that employs both B-mode and RF data, resulting in more efficient convergence and enhanced performance. Finally, we publicly release our dataset, including 161,701 single plane-wave images (RF data). This dataset serves to mitigate the data scarcity problem in the development of deep learning-based techniques for phase aberration correction.
</details>
<details>
<summary>摘要</summary>
For the first time, we propose a deep learning-based method that does not require ground truth to correct the phase aberration problem, and can be directly trained on real data. We train a network where the input and target output are randomly aberrated radio frequency (RF) data. Moreover, we find that a conventional loss function such as mean square error is inadequate for training such a network to achieve optimal performance. Instead, we propose an adaptive mixed loss function that employs both B-mode and RF data, resulting in more efficient convergence and enhanced performance.We publicly release our dataset, including 161,701 single plane-wave images (RF data), which serves to mitigate the data scarcity problem in the development of deep learning-based techniques for phase aberration correction.
</details></li>
</ul>
<hr>
<h2 id="Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs"><a href="#Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs" class="headerlink" title="Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs"></a>Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11123">http://arxiv.org/abs/2308.11123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 保护内容在线分享</li>
<li>methods: 使用隐藏水印技术训练生成模型，并测试模型是否可以检测水印并恢复水印特征</li>
<li>results: 通过统计测试，确认模型可以检测和恢复水印，提供了一种保护知识产权的解决方案<details>
<summary>Abstract</summary>
Generative models have seen an explosion in popularity with the release of huge generative Diffusion models like Midjourney and Stable Diffusion to the public. Because of this new ease of access, questions surrounding the automated collection of data and issues regarding content ownership have started to build. In this paper we present new work which aims to provide ways of protecting content when shared to the public. We show that a generative Diffusion model trained on data that has been imperceptibly watermarked will generate new images with these watermarks present. We further show that if a given watermark is correlated with a certain feature of the training data, the generated images will also have this correlation. Using statistical tests we show that we are able to determine whether a model has been trained on marked data, and what data was marked. As a result our system offers a solution to protect intellectual property when sharing content online.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>生成模型在发布大量生成扩散模型 Midjourney 和 Stable Diffusion 后得到了广泛的投入。由于这种新的访问权，人们开始关注自动收集数据的问题以及内容所有权问题。在这篇论文中，我们提出了一种保护内容的新方法。我们证明了一个基于不可见水印的生成扩散模型，会在生成新图像时包含这些水印。此外，如果给定的水印与训练数据中的某个特征相关，那么生成的图像也将具有这种相关性。通过统计测试，我们证明了我们是否可以判断模型是否训练用到了水印数据，以及这些数据是什么。因此，我们的系统可以保护在线分享内容的知识产权。
</details></li>
</ul>
<hr>
<h2 id="Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation"><a href="#Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation" class="headerlink" title="Switched auxiliary loss for robust training of transformer models for histopathological image segmentation"></a>Switched auxiliary loss for robust training of transformer models for histopathological image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10994">http://arxiv.org/abs/2308.10994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mustaffa Hussain, Saharsh Barve</li>
<li>for: 本研究旨在开发一种用于多器官功能组织单元（FTUs）分割模型，以帮助病理学家更好地理解人体疾病的 Cellular 水平信息。</li>
<li>methods: 我们使用了HuBMAP + HPA - Hacking the Human Body竞赛数据集，并提出了使用偏移式助理损失来解决深度模型衰减问题，以便在训练深度模型时获得最佳result。</li>
<li>results: 我们的模型在公共数据集上得到了0.793的dice分数，与私有数据集上的0.778的dice分数相比，表明使用我们提议的方法可以提高模型的表现。这些发现也证明了transformers模型在医学图像分析中的紧密预测任务中的可靠性。<details>
<summary>Abstract</summary>
Functional tissue Units (FTUs) are cell population neighborhoods local to a particular organ performing its main function. The FTUs provide crucial information to the pathologist in understanding the disease affecting a particular organ by providing information at the cellular level. In our research, we have developed a model to segment multi-organ FTUs across 5 organs namely: the kidney, large intestine, lung, prostate and spleen by utilizing the HuBMAP + HPA - Hacking the Human Body competition dataset. We propose adding shifted auxiliary loss for training models like the transformers to overcome the diminishing gradient problem which poses a challenge towards optimal training of deep models. Overall, our model achieved a dice score of 0.793 on the public dataset and 0.778 on the private dataset and shows a 1% improvement with the use of the proposed method. The findings also bolster the use of transformers models for dense prediction tasks in the field of medical image analysis. The study assists in understanding the relationships between cell and tissue organization thereby providing a useful medium to look at the impact of cellular functions on human health.
</details>
<details>
<summary>摘要</summary>
Functional tissue Units (FTUs) 是指器官当地的细胞群聚地区，它们提供了病理学家理解器官疾病的关键信息。在我们的研究中，我们已经开发了一种方法来在5个器官（肾脏、大小肠、肺、生殖腺和脾膜）的多个Functional tissue Units（FTUs）中进行分割，使用了HuBMAP + HPA - Hacking the Human Body competition dataset。我们提议在训练模型时使用偏移 auxiliary loss，以解决深度模型训练中的减少梯度问题，从而提高模型的训练效果。总的来说，我们的模型在公共数据集上达到了0.793的 dice score，在私有数据集上达到了0.778的 dice score，与使用我们提议的方法相比，提高了1%。这些结果也证明了使用 transformers 模型在医学图像分析中进行紧密预测任务是有效的。这个研究帮助我们更好地理解细胞和组织之间的关系，从而更好地了解人类健康的影响因素。
</details></li>
</ul>
<hr>
<h2 id="Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations"><a href="#Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations" class="headerlink" title="Debiasing Counterfactuals In the Presence of Spurious Correlations"></a>Debiasing Counterfactuals In the Presence of Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10984">http://arxiv.org/abs/2308.10984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amar Kumar, Nima Fathi, Raghav Mehta, Brennan Nichyporuk, Jean-Pierre R. Falet, Sotirios Tsaftaris, Tal Arbel</li>
<li>for: This paper aims to improve the performance of deep learning models in medical imaging classification tasks by addressing the issue of spurious correlations in the training data.</li>
<li>methods: The proposed method integrates two techniques: (1) popular debiasing classifiers, such as distributionally robust optimization (DRO), to avoid relying on spurious correlations, and (2) counterfactual image generation to unveil generalizable imaging markers of relevance to the task.</li>
<li>results: The proposed method is evaluated on two public datasets with simulated and real visual artifacts, and the results show that it (1) learns generalizable markers across the population and (2) successfully ignores spurious correlations and focuses on the underlying disease pathology.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文目标是解决医学成像分类任务中的干扰因素问题，使深度学习模型能够更好地在人口中学习。</li>
<li>methods: 提议的方法组合了两种技术：（1）流行的偏差修正分类器（DRO），以避免基于干扰因素的推断，和（2）对应ifactual图像生成，以揭示有关任务的可靠成像标记。</li>
<li>results: 在两个公共数据集上（包括模拟和实际视觉artefacts）进行了评估，结果显示：（1）可以在人口中学习普遍的标记，和（2）成功忽略干扰因素，关注下面疾病趋势。<details>
<summary>Abstract</summary>
Deep learning models can perform well in complex medical imaging classification tasks, even when basing their conclusions on spurious correlations (i.e. confounders), should they be prevalent in the training dataset, rather than on the causal image markers of interest. This would thereby limit their ability to generalize across the population. Explainability based on counterfactual image generation can be used to expose the confounders but does not provide a strategy to mitigate the bias. In this work, we introduce the first end-to-end training framework that integrates both (i) popular debiasing classifiers (e.g. distributionally robust optimization (DRO)) to avoid latching onto the spurious correlations and (ii) counterfactual image generation to unveil generalizable imaging markers of relevance to the task. Additionally, we propose a novel metric, Spurious Correlation Latching Score (SCLS), to quantify the extent of the classifier reliance on the spurious correlation as exposed by the counterfactual images. Through comprehensive experiments on two public datasets (with the simulated and real visual artifacts), we demonstrate that the debiasing method: (i) learns generalizable markers across the population, and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation"><a href="#BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation" class="headerlink" title="BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation"></a>BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10958">http://arxiv.org/abs/2308.10958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Etienne St-Onge, Kurt G Schilling, Francois Rheault</li>
<li>for: 提供一种可靠、可重现、快速的白 matter 通路EXTRACTION方法</li>
<li>methods: 利用迭代注册程序和精确流线搜索算法，能够高效地分 Segment 流线，无需进行追gram clustering或简化假设</li>
<li>results: 在repeatability和 reproduceability方面，BundleSeg 表现更好于现状的分Segmentation方法，并且具有显著的速度提升。提高了白 matter 连接的精度和减少了变化，为 neuroscience 研究提供了一种有价值的工具，从而提高了追gram-based 研究的敏感性和特点。<details>
<summary>Abstract</summary>
This work presents BundleSeg, a reliable, reproducible, and fast method for extracting white matter pathways. The proposed method combines an iterative registration procedure with a recently developed precise streamline search algorithm that enables efficient segmentation of streamlines without the need for tractogram clustering or simplifying assumptions. We show that BundleSeg achieves improved repeatability and reproducibility than state-of-the-art segmentation methods, with significant speed improvements. The enhanced precision and reduced variability in extracting white matter connections offer a valuable tool for neuroinformatic studies, increasing the sensitivity and specificity of tractography-based studies of white matter pathways.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种可靠、可重复、快速的白 matter 路径提取方法，称为 BundleSeg。该方法结合了一种迭代注册过程和最近发展的精确流线搜索算法，可以高效地分 segments 流线无需进行 tractogram 归类或简化假设。我们示出了 BundleSeg 在比较州-of-the-art 分 segmentation 方法的重复性和可重复性有所提高，同时速度也有显著提高。增强的精度和流线分 segments 的变化率提供了一种有价值的工具 для neuroscience 研究，提高了追踪性-based 研究中白 matter 路径的敏感性和特点。
</details></li>
</ul>
<hr>
<h2 id="Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction"><a href="#Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction" class="headerlink" title="Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction"></a>Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10820">http://arxiv.org/abs/2308.10820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miaoyu Li, Ying Fu, Ji Liu, Yulun Zhang</li>
<li>for: 高光谱像 (HSI) 重建，解决深度折衣框架中的匹配问题。</li>
<li>methods: 提出了一种Pixel Adaptive Deep Unfolding Transformer (PADUT)，在数据模块中使用了像素适应下降步骤，在假设模块中引入了Non-local Spectral Transformer (NST)，并在不同阶段和深度中的特征表达中进行了改进。</li>
<li>results: 对比于现有的HSI重建方法，实验结果表明PADUT方法在实验场景中具有更高的重建质量。代码可以在<a target="_blank" rel="noopener" href="https://github.com/MyuLi/PADUT%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/MyuLi/PADUT中下载。</a><details>
<summary>Abstract</summary>
Hyperspectral Image (HSI) reconstruction has made gratifying progress with the deep unfolding framework by formulating the problem into a data module and a prior module. Nevertheless, existing methods still face the problem of insufficient matching with HSI data. The issues lie in three aspects: 1) fixed gradient descent step in the data module while the degradation of HSI is agnostic in the pixel-level. 2) inadequate prior module for 3D HSI cube. 3) stage interaction ignoring the differences in features at different stages. To address these issues, in this work, we propose a Pixel Adaptive Deep Unfolding Transformer (PADUT) for HSI reconstruction. In the data module, a pixel adaptive descent step is employed to focus on pixel-level agnostic degradation. In the prior module, we introduce the Non-local Spectral Transformer (NST) to emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by the diverse expression of features in different stages and depths, the stage interaction is improved by the Fast Fourier Transform (FFT). Experimental results on both simulated and real scenes exhibit the superior performance of our method compared to state-of-the-art HSI reconstruction methods. The code is released at: https://github.com/MyuLi/PADUT.
</details>
<details>
<summary>摘要</summary>
高spectral像素（HSI）重建已经取得了满意的进步，透过深度发散框架，将问题转化为数据模组和假设模组。然而，现有方法仍然面临HSI数据不足的问题，这些问题包括：1）固定的梯度下降步骤在数据模组中，而HSI质量下降是无知的Pixel水平。2）不够的假设模组 для3D HSI立方体。3）阶段交互忽略了不同阶段和层级的特征之间的不同。为了解决这些问题，在这个研究中，我们提出了适应Pixel深度 unfolding transformer（PADUT） дляHSI重建。在数据模组中，我们使用适应梯度下降步骤，以注意到Pixel水平的不知质量下降。在假设模组中，我们引入了Non-local Spectral Transformer（NST），以强调3D特征的HSI重建。此外，受到不同阶段和层级的特征表达的多样性的惊叹，我们改进了阶段交互，使用Fast Fourier Transform（FFT）。实验结果显示，我们的方法与现有的HSI重建方法相比，在 simulated和RealScene 上具有更高的性能。代码可以在：https://github.com/MyuLi/PADUT 获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/22/eess.IV_2023_08_22/" data-id="clltau95i00edcr88cviedvdp" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/21/cs.LG_2023_08_21/" class="article-date">
  <time datetime="2023-08-20T16:00:00.000Z" itemprop="datePublished">2023-08-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/21/cs.LG_2023_08_21/">cs.LG - 2023-08-21 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Graph-Neural-Bandits"><a href="#Graph-Neural-Bandits" class="headerlink" title="Graph Neural Bandits"></a>Graph Neural Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10808">http://arxiv.org/abs/2308.10808</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lasgroup/GNNBO">https://github.com/lasgroup/GNNBO</a></li>
<li>paper_authors: Yunzhe Qi, Yikun Ban, Jingrui He</li>
<li>for: 这篇论文是为了提出一种基于图神经网络的推荐算法框架，以便利用用户之间的协同作用来提高推荐效果。</li>
<li>methods: 该论文使用了图神经网络来建模用户之间的协同关系，并分别使用GNN-based模型来进行优化的推荐策略。</li>
<li>results: 该论文通过对多个实际数据集进行比较，证明了其提出的推荐算法框架的有效性。<details>
<summary>Abstract</summary>
Contextual bandits algorithms aim to choose the optimal arm with the highest reward out of a set of candidates based on the contextual information. Various bandit algorithms have been applied to real-world applications due to their ability of tackling the exploitation-exploration dilemma. Motivated by online recommendation scenarios, in this paper, we propose a framework named Graph Neural Bandits (GNB) to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Instead of estimating rigid user clusters as in existing works, we model the "fine-grained" collaborative effects through estimated user graphs in terms of exploitation and exploration respectively. Then, to refine the recommendation strategy, we utilize separate GNN-based models on estimated user graphs for exploitation and adaptive exploration. Theoretical analysis and experimental results on multiple real data sets in comparison with state-of-the-art baselines are provided to demonstrate the effectiveness of our proposed framework.
</details>
<details>
<summary>摘要</summary>
Contextual bandits算法目的是选择最高奖励的武器（arm）中的集合基于Contextual信息。多种bandit算法在实际应用中使用，因为它们可以解决探索和利用之间的矛盾。在这篇论文中，我们提出了一个名为图 neural bandits（GNB）的框架，利用用户之间的协同作用，激活了图神经网络（GNNs）。而不是在现有的工作中估计固定的用户群集，我们通过估计用户图来模型“细化”的协同效果，分别用于探索和适应探索。然后，我们使用分开的GNN-based模型来修改推荐策略，并对多个实际数据集进行了 teoretic 分析和实验研究，以证明我们的提出的框架的效果。
</details></li>
</ul>
<hr>
<h2 id="DynED-Dynamic-Ensemble-Diversification-in-Data-Stream-Classification"><a href="#DynED-Dynamic-Ensemble-Diversification-in-Data-Stream-Classification" class="headerlink" title="DynED: Dynamic Ensemble Diversification in Data Stream Classification"></a>DynED: Dynamic Ensemble Diversification in Data Stream Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10807">http://arxiv.org/abs/2308.10807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soheilabadifard/dyned">https://github.com/soheilabadifard/dyned</a></li>
<li>paper_authors: Soheil Abadifard, Sepehr Bakhshi, Sanaz Gheibuni, Fazli Can</li>
<li>for: 这篇论文是为了提高在数据流中的类别准确率，因为数据流中的变化可能会导致模型的性能下降。</li>
<li>methods: 这篇论文使用了一种新的集成方法，叫做DynED，它可以在数据流中维持集成模型的性能。DynED使用了MMR（最大margin relevance）来选择最佳的集成元件，以确保集成模型的各个元件都能够做出贡献。</li>
<li>results: 根据实验结果，DynED在11个 sintetic dataset和4个真实 dataset上的平均准确率高于5个现有的基eline。<details>
<summary>Abstract</summary>
Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
ensemble方法在分类 task 中广泛应用，因其表现出色。在数据流环境中达到高精度是一项具有挑战性的任务，因为数据分布会不断变化，也就是说 concept drift。更多的ensemble组件可以提高预测精度。 despite the diversity of components within an ensemble, not all contribute as expected to its overall performance。这种情况需要一种方法来选择表现好的和多样的组件。我们提出了一种基于 MMR（最大边际相关）的新集成建立和维护方法，可以在构建集成时动态组合多样性和预测精度。实验结果表明，我们的方法（DynED）在14个实验数据集上比基eline5种状态 искусственный顶峰表现出更高的平均含义精度。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Frank-Wolfe-Optimization-Layer"><a href="#Differentiable-Frank-Wolfe-Optimization-Layer" class="headerlink" title="Differentiable Frank-Wolfe Optimization Layer"></a>Differentiable Frank-Wolfe Optimization Layer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10806">http://arxiv.org/abs/2308.10806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Liu, Liu Liu, Xueqian Wang, Peilin Zhao</li>
<li>for: 提出了一种高效的梯度下降优化层（DFWLayer），用于解决具有约束的机器学习问题。</li>
<li>methods: 基于Frank-Wolfe算法，DFWLayer不需要计算投影和希格曼矩阵，从而实现了高效的大规模问题解决方法。</li>
<li>results: 在实验中，DFWLayer不仅实现了竞争性的准确率和梯度，还可靠地遵守约束。此外，它在前向和反向计算速度方面也超过了基elines。<details>
<summary>Abstract</summary>
Differentiable optimization has received a significant amount of attention due to its foundational role in the domain of machine learning based on neural networks. The existing methods leverages the optimality conditions and implicit function theorem to obtain the Jacobian matrix of the output, which increases the computational cost and limits the application of differentiable optimization. In addition, some non-differentiable constraints lead to more challenges when using prior differentiable optimization layers. This paper proposes a differentiable layer, named Differentiable Frank-Wolfe Layer (DFWLayer), by rolling out the Frank-Wolfe method, a well-known optimization algorithm which can solve constrained optimization problems without projections and Hessian matrix computations, thus leading to a efficient way of dealing with large-scale problems. Theoretically, we establish a bound on the suboptimality gap of the DFWLayer in the context of l1-norm constraints. Experimental assessments demonstrate that the DFWLayer not only attains competitive accuracy in solutions and gradients but also consistently adheres to constraints. Moreover, it surpasses the baselines in both forward and backward computational speeds.
</details>
<details>
<summary>摘要</summary>
differentiable 优化在机器学习领域中得到了广泛的关注，因为它在神经网络上构建的机器学习模型中扮演了基础性的角色。现有的方法利用优化性条件和隐函数定理来获取输出的雅可比矩阵，这会增加计算成本并限制 differentiable 优化的应用。此外，一些非 differentiable 约束会使得使用先前的 differentiable 优化层更加困难。这篇论文提出了一种名为差分可 differentiable Frank-Wolfe 层（DFWLayer）的层，通过折衔 Frank-Wolfe 算法，该算法可以解决具有约束的优化问题，而不需要计算投影和资料矩阵，因此可以方便地处理大规模问题。理论上，我们提出了在 l1-norm 约束下的优化误差幅度的下界。实验评估表明，DFWLayer 不仅在解决方案和梯度方面达到了竞争性的准确性，而且一致地遵循约束。此外，它在前向和后向计算速度方面也超过了基eline。
</details></li>
</ul>
<hr>
<h2 id="Stabilizing-Unsupervised-Environment-Design-with-a-Learned-Adversary"><a href="#Stabilizing-Unsupervised-Environment-Design-with-a-Learned-Adversary" class="headerlink" title="Stabilizing Unsupervised Environment Design with a Learned Adversary"></a>Stabilizing Unsupervised Environment Design with a Learned Adversary</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10797">http://arxiv.org/abs/2308.10797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dcd">https://github.com/facebookresearch/dcd</a></li>
<li>paper_authors: Ishita Mediratta, Minqi Jiang, Jack Parker-Holder, Michael Dennis, Eugene Vinitsky, Tim Rocktäschel</li>
<li>for: 本研究旨在提高普通能力Agent的训练，通过设计适应环境变化的训练任务来促进广泛的普通化和稳定性。</li>
<li>methods: 本研究使用了强化学习（RL）来训练教师策略，从 scratch generate任务，使得可以直接生成适应当前机器人能力的任务。</li>
<li>results: 本研究在多个已知的难度 Navigation 和赛车环境中实现了与当前状态的比较或超越，生成了可靠的普通化Agent。<details>
<summary>Abstract</summary>
A key challenge in training generally-capable agents is the design of training tasks that facilitate broad generalization and robustness to environment variations. This challenge motivates the problem setting of Unsupervised Environment Design (UED), whereby a student agent trains on an adaptive distribution of tasks proposed by a teacher agent. A pioneering approach for UED is PAIRED, which uses reinforcement learning (RL) to train a teacher policy to design tasks from scratch, making it possible to directly generate tasks that are adapted to the agent's current capabilities. Despite its strong theoretical backing, PAIRED suffers from a variety of challenges that hinder its practical performance. Thus, state-of-the-art methods currently rely on curation and mutation rather than generation of new tasks. In this work, we investigate several key shortcomings of PAIRED and propose solutions for each shortcoming. As a result, we make it possible for PAIRED to match or exceed state-of-the-art methods, producing robust agents in several established challenging procedurally-generated environments, including a partially-observed maze navigation task and a continuous-control car racing environment. We believe this work motivates a renewed emphasis on UED methods based on learned models that directly generate challenging environments, potentially unlocking more open-ended RL training and, as a result, more general agents.
</details>
<details>
<summary>摘要</summary>
training 通常遇到的一个挑战是设计训练任务，以便在环境变化时能够广泛通用和Robust。这个挑战激发了无监督环境设计（UED）的问题，其中学生机器人通过一个教师机器人提供的 adaptive 任务分布进行训练。一种开拓性的方法是 PAIRED，它使用强化学习（RL）来训练一个教师策略，从scratch生成任务，使得可以直接生成适应机器人当前能力的任务。然而，PAIRED 受到多种挑战，这些挑战使得实际性受到影响。因此，当前的state-of-the-art方法通常采用审核和变化而不是生成新任务。在这种情况下，我们调查了 PAIRED 的一些关键缺陷，并提出了解决方案。结果是，我们使得 PAIRED 能够与当前的state-of-the-art方法匹配或超越，在一些已知的复杂生成环境中训练 robust 的机器人，包括部分观察 Maze 导航任务和连续控制汽车竞赛环境。我们认为这项工作将激励更多的 UED 方法基于学习的模型，直接生成挑战任务，可能解锁更多的 open-ended RL 训练和更一般的机器人。
</details></li>
</ul>
<hr>
<h2 id="MGMAE-Motion-Guided-Masking-for-Video-Masked-Autoencoding"><a href="#MGMAE-Motion-Guided-Masking-for-Video-Masked-Autoencoding" class="headerlink" title="MGMAE: Motion Guided Masking for Video Masked Autoencoding"></a>MGMAE: Motion Guided Masking for Video Masked Autoencoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10794">http://arxiv.org/abs/2308.10794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingkun Huang, Zhiyu Zhao, Guozhen Zhang, Yu Qiao, Limin Wang</li>
<li>For: The paper is focused on improving the performance of video masked autoencoding (MMAE) by incorporating motion information into the masking strategy.* Methods: The paper introduces a motion guided masking strategy that explicitly incorporates motion information to build temporal consistent masking volume. The authors also use an online efficient optical flow estimator and backward masking map warping strategy to implement their method.* Results: The authors demonstrate superior performance of their motion guided MMAE (MGMAE) compared to the original VideoMAE on the datasets of Something-Something V2 and Kinetics-400. They also provide visualization analysis to illustrate that their method can sample temporal consistent cubes in a motion-adaptive manner for more effective video pre-training.Here is the simplified Chinese text for the three key points:* 为：本文主要关注提高视频Masked Autoencoding（MMAE）性能，通过 incorporating 运动信息到Masking策略中。* 方法：本文引入运动指导Masking策略，其中Explicitly incorporates 运动信息构建 temporal consistent 的Masking volume。作者还使用了在线高效的Optical flow estimator和backward Masking map warping策略来实现方法。* 结果：作者在Something-Something V2和Kinetics-400 datasets上展示了MGMAE的超越VideoMAE性能。他们还提供了可视化分析，以 illustrate MGMAE可以在运动响应的方式采样时间一致的cubes，以便更有效地预训练视频。<details>
<summary>Abstract</summary>
Masked autoencoding has shown excellent performance on self-supervised video representation learning. Temporal redundancy has led to a high masking ratio and customized masking strategy in VideoMAE. In this paper, we aim to further improve the performance of video masked autoencoding by introducing a motion guided masking strategy. Our key insight is that motion is a general and unique prior in video, which should be taken into account during masked pre-training. Our motion guided masking explicitly incorporates motion information to build temporal consistent masking volume. Based on this masking volume, we can track the unmasked tokens in time and sample a set of temporal consistent cubes from videos. These temporal aligned unmasked tokens will further relieve the information leakage issue in time and encourage the MGMAE to learn more useful structure information. We implement our MGMAE with an online efficient optical flow estimator and backward masking map warping strategy. We perform experiments on the datasets of Something-Something V2 and Kinetics-400, demonstrating the superior performance of our MGMAE to the original VideoMAE. In addition, we provide the visualization analysis to illustrate that our MGMAE can sample temporal consistent cubes in a motion-adaptive manner for more effective video pre-training.
</details>
<details>
<summary>摘要</summary>
卷积自编码（Masked Autoencoding）在自我监督视频表示学习中表现出色。视频中的时间重复性导致了高的面罩率和自定义面罩策略，在这篇论文中，我们想要进一步提高视频卷积自编码的性能，通过引入运动指导的面罩策略。我们的关键发现是，运动是视频中一个通用和特殊的先验，应该在面罩预训练中考虑。我们的运动指导面罩 explictly incorporates 运动信息，建立了时间一致的面罩量。基于这个面罩量，我们可以在时间上跟踪不面罩的 токен，并从视频中采样一组时间一致的立方体。这些时间一致的不面罩的 токен将进一步减轻时间泄露问题，促使MGMAE学习更有用的结构信息。我们实现了我们的MGMAE，使用了在线高效的滤波器估计器和反向面罩地图抽象策略。我们在Something-Something V2和Kinetics-400 datasets上进行了实验，并证明了我们的MGMAE在原始VideoMAE的基础上具有更高的性能。此外，我们还提供了视觉分析，以 Illustrate 我们的MGMAE可以在运动适应的方式下采样时间一致的立方体，以更有效地进行视频预训练。
</details></li>
</ul>
<hr>
<h2 id="Instruction-Tuning-for-Large-Language-Models-A-Survey"><a href="#Instruction-Tuning-for-Large-Language-Models-A-Survey" class="headerlink" title="Instruction Tuning for Large Language Models: A Survey"></a>Instruction Tuning for Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10792">http://arxiv.org/abs/2308.10792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, Guoyin Wang</li>
<li>for: 本文审查了大语言模型（LLM）的指令调整（IT）研究，以提高LLM的能力和可控性。</li>
<li>methods: 本文使用系统性的文献综述方法，包括IT的总方法、IT数据集的构建、IT模型的训练、不同Modalities、领域和应用程序中的应用，以及影响IT结果的因素的分析（如生成指令输出、指令数据集的大小等）。</li>
<li>results: 本文对IT的总体结果进行了分析，包括IT的应用、潜在的坏处和批评，以及现有策略的不足和未来研究的可能性。<details>
<summary>Abstract</summary>
This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of \textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies of existing strategies and suggest some avenues for fruitful research.
</details>
<details>
<summary>摘要</summary>
The paper provides a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains, and applications. The review also analyzes factors that influence the outcome of IT, such as the generation of instruction outputs and the size of the instruction dataset.Furthermore, the paper discusses potential pitfalls of IT and criticism against it, as well as efforts to address current deficiencies in existing strategies and suggests avenues for fruitful research. Overall, the paper provides a comprehensive overview of the current state of IT research and its potential applications in various domains.Here is the translation in Simplified Chinese:这篇论文检讨了大语言模型（LLM）的指令调整（IT）研究，这是一种能够提高LLM的能力和可控性的重要技术。IT通过在指令集合（instruction, output）的supervised模式下进行进一步训练LLM， bridge了LLM的下一个词预测目标和用户的目标，即使LLM遵循人类的指令。论文提供了系统性的文献综述，包括IT的总方法、IT数据集的建构、IT模型的训练、以及不同的modalities、domains和应用程序中的应用。文献还分析了IT的结果受到的因素，如生成指令输出和指令集合的大小。此外，论文还讨论了IT的潜在弱点和批评，以及现有策略的不足和改进的可能性。文献还提出了一些有优势的研究方向。总的来说，论文提供了大语言模型研究的现状和IT研究的潜在应用领域。
</details></li>
</ul>
<hr>
<h2 id="Zero-and-Few-Shot-Prompting-with-LLMs-A-Comparative-Study-with-Fine-tuned-Models-for-Bangla-Sentiment-Analysis"><a href="#Zero-and-Few-Shot-Prompting-with-LLMs-A-Comparative-Study-with-Fine-tuned-Models-for-Bangla-Sentiment-Analysis" class="headerlink" title="Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis"></a>Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10783">http://arxiv.org/abs/2308.10783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj Alam, Anika Anjum, Avijit Sarker, Sheak Rashed Haider Noori</li>
<li>for: 本研究旨在提供大量手动标注的孟加拉语新闻微博和Facebook评论数据集，以及对多种语言模型进行零、几shot在场景学习的研究。</li>
<li>methods: 本研究使用了零、几shot在场景学习的方法，包括Flan-T5、GPT-4和Bloomz等语言模型，并进行了对比研究。</li>
<li>results: 研究发现，单语言变换器模型在零、几shot场景下表现出了强劲的性能，超过其他模型。<details>
<summary>Abstract</summary>
The rapid expansion of the digital world has propelled sentiment analysis into a critical tool across diverse sectors such as marketing, politics, customer service, and healthcare. While there have been significant advancements in sentiment analysis for widely spoken languages, low-resource languages, such as Bangla, remain largely under-researched due to resource constraints. Furthermore, the recent unprecedented performance of Large Language Models (LLMs) in various applications highlights the need to evaluate them in the context of low-resource languages. In this study, we present a sizeable manually annotated dataset encompassing 33,605 Bangla news tweets and Facebook comments. We also investigate zero- and few-shot in-context learning with several language models, including Flan-T5, GPT-4, and Bloomz, offering a comparative analysis against fine-tuned models. Our findings suggest that monolingual transformer-based models consistently outperform other models, even in zero and few-shot scenarios. To foster continued exploration, we intend to make this dataset and our research tools publicly available to the broader research community. In the spirit of further research, we plan to make this dataset and our experimental resources publicly accessible to the wider research community.
</details>
<details>
<summary>摘要</summary>
随着数字世界的快速扩张，情感分析已成为多个领域的关键工具，包括市场营销、政治、客户服务和医疗等。虽然普通话和其他语言的情感分析得到了 significiant 进步，但低资源语言，如孟加拉语，仍然受到资源限制，因此它们尚未得到了足够的研究。此外，最近的不同应用中大型自然语言处理器（LLMs）的表现也提出了对低资源语言进行评估的需求。在本研究中，我们提供了一个大量手动标注的孟加拉语新闻微博和Facebook评论数据集，并进行了零、几个适应学习和翻译模型的研究。我们的发现表明，单语言转换器基于模型在零和几个适应场景中一直表现出色，even in zero and few-shot scenarios。为了促进进一步的探索，我们计划在未来公开这个数据集和我们的研究工具，以便更广泛的研究者社区可以进行更多的研究。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Linear-Concept-Discovery-Models"><a href="#Sparse-Linear-Concept-Discovery-Models" class="headerlink" title="Sparse Linear Concept Discovery Models"></a>Sparse Linear Concept Discovery Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10782">http://arxiv.org/abs/2308.10782</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/konpanousis/conceptdiscoverymodels">https://github.com/konpanousis/conceptdiscoverymodels</a></li>
<li>paper_authors: Konstantinos P. Panousis, Dino Ienco, Diego Marcos</li>
<li>for: This paper aims to improve the interpretability of Deep Neural Networks (DNNs) by proposing a simple and intuitive framework based on Contrastive Language Image models and a single sparse linear layer.</li>
<li>methods: The proposed framework uses a data-driven Bernoulli distribution to infer concept presence and achieve sparsity in the model, which is a novel approach compared to previous CBM methods.</li>
<li>results: The proposed framework outperforms recent CBM approaches in accuracy and achieves high per-example concept sparsity, making it easier to investigate the emerging concepts.<details>
<summary>Abstract</summary>
The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also yields high per example concept sparsity, facilitating the individual investigation of the emerging concepts.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a simple and highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. Unlike other approaches, our framework achieves sparsity through principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. Our experiments show that our framework not only outperforms recent CBM approaches in terms of accuracy, but it also yields high per-example concept sparsity, making it easier to investigate the emerging concepts.Here is the text in Simplified Chinese:近些时间，深度神经网络（DNNs）在安全关键场景中广泛应用，导致研究人员强调创建可解释性强的模型。概念瓶颈模型（CBMs）是一种受欢迎的方法，它将隐藏层与人理解的概念绑定在一起，以便调查和修正网络决策的过程。然而，CBMs 通常会受到以下两个问题的影响：（i）性能下降，和（ii）解释性比预期更低，这是因为每个决策中的概念的数量过多。在这项工作中，我们提出了一种简单、易于理解的框架，基于对比语言图像模型和单个稀疏线性层。与相关方法不同，我们的框架中的稀疏性是通过原则性的极 bayesian 理由来实现的，通过数据驱动的 Берну利分布来判断概念存在。我们的实验表明，我们的框架不仅在准确性上超越了最近的 CBM 方法，而且每个例子的概念稀疏性也很高，使得可以轻松地调查出现的概念。
</details></li>
</ul>
<hr>
<h2 id="Mixed-Integer-Projections-for-Automated-Data-Correction-of-EMRs-Improve-Predictions-of-Sepsis-among-Hospitalized-Patients"><a href="#Mixed-Integer-Projections-for-Automated-Data-Correction-of-EMRs-Improve-Predictions-of-Sepsis-among-Hospitalized-Patients" class="headerlink" title="Mixed-Integer Projections for Automated Data Correction of EMRs Improve Predictions of Sepsis among Hospitalized Patients"></a>Mixed-Integer Projections for Automated Data Correction of EMRs Improve Predictions of Sepsis among Hospitalized Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10781">http://arxiv.org/abs/2308.10781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehak Arora, Hassan Mortagy, Nathan Dwarshius, Swati Gupta, Andre L. Holder, Rishikesan Kamaleswaran</li>
<li>for: 这个研究目的是为了提高机器学习模型在医疗内容中自动化诊断决策的精度。</li>
<li>methods: 这篇研究使用了一种创新的投影方法，将诊断领域的专业知识融入机器学习工作流程中，生成重要的元数据，并通过高维混合整数程式来修正患者数据，以确保数据的正确性。</li>
<li>results: 研究结果显示，使用这种投影方法可以提高机器学习分类器在实际医疗 Setting中的性能，特别是在检测 septic shock 的早期检测中，AUROC 为 0.865，精度为 0.922，较无投影的机器学习模型更高。<details>
<summary>Abstract</summary>
Machine learning (ML) models are increasingly pivotal in automating clinical decisions. Yet, a glaring oversight in prior research has been the lack of proper processing of Electronic Medical Record (EMR) data in the clinical context for errors and outliers. Addressing this oversight, we introduce an innovative projections-based method that seamlessly integrates clinical expertise as domain constraints, generating important meta-data that can be used in ML workflows. In particular, by using high-dimensional mixed-integer programs that capture physiological and biological constraints on patient vitals and lab values, we can harness the power of mathematical "projections" for the EMR data to correct patient data. Consequently, we measure the distance of corrected data from the constraints defining a healthy range of patient data, resulting in a unique predictive metric we term as "trust-scores". These scores provide insight into the patient's health status and significantly boost the performance of ML classifiers in real-life clinical settings. We validate the impact of our framework in the context of early detection of sepsis using ML. We show an AUROC of 0.865 and a precision of 0.922, that surpasses conventional ML models without such projections.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）模型在医疗决策自动化中日益重要。然而，在先前的研究中，缺乏对电子医疗记录（EMR）数据在临床上的正确处理是一大缺点。我们解决这一问题，引入了一种创新的投影方法，它可以融合临床专业知识作为领域约束，生成重要的元数据，可以在机器学习工作流中使用。具体来说，我们使用高维混合整数程序，捕捉了生物和生物学约束，以 Correct patient数据。然后，我们测量了对约束定义的健康范围内的 corrected data 的距离，得到了一个唯一的预测指标，我们称之为 "信任分数"。这些分数可以提供患者的健康状况信息，并在实际临床设置中显著提高机器学习分类器的性能。我们验证了我们的框架在早期识别 septic shock 中的效果，我们显示了 AUC 为 0.865，精度为 0.922，这些结果超过了不含投影的 ML 模型。
</details></li>
</ul>
<hr>
<h2 id="Spear-and-Shield-Adversarial-Attacks-and-Defense-Methods-for-Model-Based-Link-Prediction-on-Continuous-Time-Dynamic-Graphs"><a href="#Spear-and-Shield-Adversarial-Attacks-and-Defense-Methods-for-Model-Based-Link-Prediction-on-Continuous-Time-Dynamic-Graphs" class="headerlink" title="Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs"></a>Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10779">http://arxiv.org/abs/2308.10779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjin Lee, Juho Lee, Kijung Shin</li>
<li>for: 这 paper 的目的是调查 Temporal Graph Neural Networks (TGNNs) 在静态图模型中的敏感性，并提出了一种简单而有效的针对链接预测任务的对抗攻击方法。</li>
<li>methods: 作者提出了一种名为 T-SPEAR 的对抗攻击方法，通过在预测过程之前对数据进行边扰动，使得预测模型失效。同时，作者还提出了一种名为 T-SHIELD 的Robust Training Approach，通过边筛选和时间稳定性来提高预测模型的Robustness。</li>
<li>results: 实验表明，T-SPEAR 可以很好地降低预测模型的链接预测性能，而且这些攻击可以转移到其他 TGNNs 上，即使它们与预测模型不同。此外，T-SHIELD 可以有效地筛选出对预测模型不良的边，并在对抗攻击时表现出更高的Robustness。<details>
<summary>Abstract</summary>
Real-world graphs are dynamic, constantly evolving with new interactions, such as financial transactions in financial networks. Temporal Graph Neural Networks (TGNNs) have been developed to effectively capture the evolving patterns in dynamic graphs. While these models have demonstrated their superiority, being widely adopted in various important fields, their vulnerabilities against adversarial attacks remain largely unexplored. In this paper, we propose T-SPEAR, a simple and effective adversarial attack method for link prediction on continuous-time dynamic graphs, focusing on investigating the vulnerabilities of TGNNs. Specifically, before the training procedure of a victim model, which is a TGNN for link prediction, we inject edge perturbations to the data that are unnoticeable in terms of the four constraints we propose, and yet effective enough to cause malfunction of the victim model. Moreover, we propose a robust training approach T-SHIELD to mitigate the impact of adversarial attacks. By using edge filtering and enforcing temporal smoothness to node embeddings, we enhance the robustness of the victim model. Our experimental study shows that T-SPEAR significantly degrades the victim model's performance on link prediction tasks, and even more, our attacks are transferable to other TGNNs, which differ from the victim model assumed by the attacker. Moreover, we demonstrate that T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Modular-and-Adaptive-System-for-Business-Email-Compromise-Detection"><a href="#A-Modular-and-Adaptive-System-for-Business-Email-Compromise-Detection" class="headerlink" title="A Modular and Adaptive System for Business Email Compromise Detection"></a>A Modular and Adaptive System for Business Email Compromise Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10776">http://arxiv.org/abs/2308.10776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Brabec, Filip Šrajer, Radek Starosta, Tomáš Sixta, Marc Dupont, Miloš Lenoch, Jiří Menšík, Florian Becker, Jakub Boros, Tomáš Pop, Pavel Novák</li>
<li>for: 防止商业电子邮件骗财（BEC）和特攻钓鱼攻击，帮助组织nings worldwide  Addressing the growing sophistication of Business Email Compromise (BEC) and spear phishing attacks, which pose significant challenges to organizations worldwide.</li>
<li>methods:  combining multiple machine learning approaches, including Natural Language Understanding (NLU), to detect BEC-related behaviors across various email modalities such as text, images, metadata, and the email’s communication context. </li>
<li>results:  CAPE, a comprehensive and efficient system for BEC detection that has been proven in a production environment for over two years, with naturally explainable verdicts. The system combines independent ML models and algorithms to detect BEC-related behaviors and adapts continuously through a Bayesian approach that combines limited data with domain knowledge.<details>
<summary>Abstract</summary>
The growing sophistication of Business Email Compromise (BEC) and spear phishing attacks poses significant challenges to organizations worldwide. The techniques featured in traditional spam and phishing detection are insufficient due to the tailored nature of modern BEC attacks as they often blend in with the regular benign traffic. Recent advances in machine learning, particularly in Natural Language Understanding (NLU), offer a promising avenue for combating such attacks but in a practical system, due to limitations such as data availability, operational costs, verdict explainability requirements or a need to robustly evolve the system, it is essential to combine multiple approaches together. We present CAPE, a comprehensive and efficient system for BEC detection that has been proven in a production environment for a period of over two years. Rather than being a single model, CAPE is a system that combines independent ML models and algorithms detecting BEC-related behaviors across various email modalities such as text, images, metadata and the email's communication context. This decomposition makes CAPE's verdicts naturally explainable. In the paper, we describe the design principles and constraints behind its architecture, as well as the challenges of model design, evaluation and adapting the system continuously through a Bayesian approach that combines limited data with domain knowledge. Furthermore, we elaborate on several specific behavioral detectors, such as those based on Transformer neural architectures.
</details>
<details>
<summary>摘要</summary>
企业电子邮件攻击（BEC）和攻击者针对邮件的攻击（spear phishing）的复杂度不断增加，对全球企业造成了严重的挑战。传统的防御策略，如防火墙和杀毒软件，已经无法满足现代BEC攻击的需求，因为这些攻击往往与正常的邮件交互混合在一起。现代机器学习技术，特别是自然语言理解（NLU），在抗击BEC攻击方面提供了一个有希望的方向。然而，在实践中，由于数据可用性、运营成本、评估透明度和持续性提高等因素，需要结合多种方法来实现。我们提出了CAPE，一个涵盖和高效的BEC检测系统，在生产环境中证明了超过两年的有效性。CAPE不是单一的模型，而是一个结合独立的机器学习模型和算法，检测电子邮件中的BEC相关行为，包括文本、图像、元数据和邮件交互Context。这种分解使得CAPE的评决具有自然的透明度。在这篇论文中，我们介绍了CAPE的设计原则和限制，以及模型设计、评估和持续性改进的挑战。此外，我们还详细介绍了一些特定的行为检测器，如基于Transformer нейロ网络架构的检测器。
</details></li>
</ul>
<hr>
<h2 id="GBM-based-Bregman-Proximal-Algorithms-for-Constrained-Learning"><a href="#GBM-based-Bregman-Proximal-Algorithms-for-Constrained-Learning" class="headerlink" title="GBM-based Bregman Proximal Algorithms for Constrained Learning"></a>GBM-based Bregman Proximal Algorithms for Constrained Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10767">http://arxiv.org/abs/2308.10767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenweilin/constrainedgbm">https://github.com/zhenweilin/constrainedgbm</a></li>
<li>paper_authors: Zhenwei Lin, Qi Deng<br>for:* The paper is focused on developing a new algorithm for constrained learning tasks in machine learning, specifically for Neyman-Pearson classification and fairness classification.methods:* The authors adapt the gradient boosting machine (GBM) algorithm for constrained learning tasks within the framework of Bregman proximal algorithms.* They introduce a new Bregman primal-dual method with a global optimality guarantee for convex learning objectives and constraint functions.results:* The authors provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework for NPC and fairness ML, and demonstrate its potential for a broader range of constrained learning applications.<details>
<summary>Abstract</summary>
As the complexity of learning tasks surges, modern machine learning encounters a new constrained learning paradigm characterized by more intricate and data-driven function constraints. Prominent applications include Neyman-Pearson classification (NPC) and fairness classification, which entail specific risk constraints that render standard projection-based training algorithms unsuitable. Gradient boosting machines (GBMs) are among the most popular algorithms for supervised learning; however, they are generally limited to unconstrained settings. In this paper, we adapt the GBM for constrained learning tasks within the framework of Bregman proximal algorithms. We introduce a new Bregman primal-dual method with a global optimality guarantee when the learning objective and constraint functions are convex. In cases of nonconvex functions, we demonstrate how our algorithm remains effective under a Bregman proximal point framework. Distinct from existing constrained learning algorithms, ours possess a unique advantage in their ability to seamlessly integrate with publicly available GBM implementations such as XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017), exclusively relying on their public interfaces. We provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework. While our primary focus is on NPC and fairness ML, our framework holds significant potential for a broader range of constrained learning applications. The source code is currently freely available at https://github.com/zhenweilin/ConstrainedGBM}{https://github.com/zhenweilin/ConstrainedGBM.
</details>
<details>
<summary>摘要</summary>
As the complexity of learning tasks increases, modern machine learning encounters a new constrained learning paradigm with more intricate and data-driven function constraints. Prominent applications include Neyman-Pearson classification (NPC) and fairness classification, which involve specific risk constraints that render standard projection-based training algorithms unsuitable. Gradient boosting machines (GBMs) are among the most popular algorithms for supervised learning; however, they are generally limited to unconstrained settings. In this paper, we adapt the GBM for constrained learning tasks within the framework of Bregman proximal algorithms. We introduce a new Bregman primal-dual method with a global optimality guarantee when the learning objective and constraint functions are convex. In cases of nonconvex functions, we demonstrate how our algorithm remains effective under a Bregman proximal point framework. Distinct from existing constrained learning algorithms, ours possess a unique advantage in their ability to seamlessly integrate with publicly available GBM implementations such as XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017), exclusively relying on their public interfaces. We provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework. While our primary focus is on NPC and fairness ML, our framework holds significant potential for a broader range of constrained learning applications. The source code is currently freely available at <https://github.com/zhenweilin/ConstrainedGBM>.
</details></li>
</ul>
<hr>
<h2 id="To-Whom-are-You-Talking-A-Deep-Learning-Model-to-Endow-Social-Robots-with-Addressee-Estimation-Skills"><a href="#To-Whom-are-You-Talking-A-Deep-Learning-Model-to-Endow-Social-Robots-with-Addressee-Estimation-Skills" class="headerlink" title="To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills"></a>To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10757">http://arxiv.org/abs/2308.10757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlo Mazzola, Marta Romeo, Francesco Rea, Alessandra Sciutti, Angelo Cangelosi</li>
<li>for: 本研究旨在理解人类对话中的 адресат估计问题，以便在人机交互中使用机器人。</li>
<li>methods: 本研究使用了一种hybrid深度学习模型，组合了卷积层和LSTM细胞，将说话者的面部表情和姿势vector作为输入。</li>
<li>results: 研究表明，该模型能够在 robot egocentric 视角下解决 addressee 的本地化问题。<details>
<summary>Abstract</summary>
Communicating shapes our social word. For a robot to be considered social and being consequently integrated in our social environment it is fundamental to understand some of the dynamics that rule human-human communication. In this work, we tackle the problem of Addressee Estimation, the ability to understand an utterance's addressee, by interpreting and exploiting non-verbal bodily cues from the speaker. We do so by implementing an hybrid deep learning model composed of convolutional layers and LSTM cells taking as input images portraying the face of the speaker and 2D vectors of the speaker's body posture. Our implementation choices were guided by the aim to develop a model that could be deployed on social robots and be efficient in ecological scenarios. We demonstrate that our model is able to solve the Addressee Estimation problem in terms of addressee localisation in space, from a robot ego-centric point of view.
</details>
<details>
<summary>摘要</summary>
人际交流 shapes our 社会语言。为了让机器人被视为社交的并被顺利地整合到我们的社交环境中，我们必须理解一些人类对人交流的dinamics。在这项工作中，我们面临了Addresssee Estimation问题，即理解说话者的utterance的接收人，通过解释和利用说话者的非语言性肢体姿势。我们通过实施一种hybrid深度学习模型，组合 convolutional层和LSTM细胞，将说话者的脸部图像和说话者的身姿 вектор作为输入。我们的实现选择是根据目标开发一种可部署于社交机器人上的模型，并能在生态环境中高效地解决问题。我们示示了我们的模型能够解决Addresssee Estimation问题，从机器人自身的视角来看，对话者的位置在空间中。
</details></li>
</ul>
<hr>
<h2 id="On-the-Adversarial-Robustness-of-Multi-Modal-Foundation-Models"><a href="#On-the-Adversarial-Robustness-of-Multi-Modal-Foundation-Models" class="headerlink" title="On the Adversarial Robustness of Multi-Modal Foundation Models"></a>On the Adversarial Robustness of Multi-Modal Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10741">http://arxiv.org/abs/2308.10741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Schlarmann, Matthias Hein</li>
<li>for: 保护用户免受恶意内容的误导和害害</li>
<li>methods: 使用隐形攻击破坏图像，改变多模态基础模型的描述输出</li>
<li>results: 显示了恶意内容提供者可以使用隐形攻击诱导善良用户访问恶势力网站或播报假信息，需要对多模态基础模型进行防御性减噪措施<details>
<summary>Abstract</summary>
Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model.
</details>
<details>
<summary>摘要</summary>
多modal基础模型，如FLAMINGO或GPT-4，在最近受到了巨大的关注。对基础模型的Alignment用于防止模型提供有害或肤浅的输出。然而，有人试图使用恶意内容来攻击基础模型，这也是一个非常重要的问题。在这篇论文中，我们展示了如何使用图像攻击来改变多modal基础模型的描述输出，从而导致善意用户被诱导到有害网站或接受假信息。这表明，在部署多modal基础模型时应该使用防御性攻击的countermeasure。
</details></li>
</ul>
<hr>
<h2 id="We-Don’t-Need-No-Adam-All-We-Need-Is-EVE-On-The-Variance-of-Dual-Learning-Rate-And-Beyond"><a href="#We-Don’t-Need-No-Adam-All-We-Need-Is-EVE-On-The-Variance-of-Dual-Learning-Rate-And-Beyond" class="headerlink" title="We Don’t Need No Adam, All We Need Is EVE: On The Variance of Dual Learning Rate And Beyond"></a>We Don’t Need No Adam, All We Need Is EVE: On The Variance of Dual Learning Rate And Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10740">http://arxiv.org/abs/2308.10740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhadangi/EVE">https://github.com/akhadangi/EVE</a></li>
<li>paper_authors: Afshin Khadangi</li>
<li>for: 这篇论文是为了优化深度学习模型而写的。</li>
<li>methods: 这篇论文提出了一种新的方法，即增强速度估计（EVE），它利用不同的学习率来区分不同的组件。</li>
<li>results: 实验表明，EVE方法可以快速地 converge 并且在不同的数据集和架构上表现出色，与现有的优化技术相比有所提高。<details>
<summary>Abstract</summary>
In the rapidly advancing field of deep learning, optimising deep neural networks is paramount. This paper introduces a novel method, Enhanced Velocity Estimation (EVE), which innovatively applies different learning rates to distinct components of the gradients. By bifurcating the learning rate, EVE enables more nuanced control and faster convergence, addressing the challenges associated with traditional single learning rate approaches. Utilising a momentum term that adapts to the learning landscape, the method achieves a more efficient navigation of the complex loss surface, resulting in enhanced performance and stability. Extensive experiments demonstrate that EVE significantly outperforms existing optimisation techniques across various benchmark datasets and architectures.
</details>
<details>
<summary>摘要</summary>
在深度学习领域的快速发展中，优化深度神经网络非常重要。本文介绍了一种新方法，即增强速度估计（EVE），它创新地将不同的学习率应用到不同的梯度组件。通过分化学习率，EVE允许更细化的控制和更快的 converges，解决传统单学习率方法所遇到的挑战。利用适应学习地面的旋转矩阵，方法实现了更高效地导航复杂的损失函数表面，从而提高性能和稳定性。广泛的实验表明，EVEsignificantly exceeds现有优化技术在各种 benchmark 数据集和架构上。
</details></li>
</ul>
<hr>
<h2 id="UGSL-A-Unified-Framework-for-Benchmarking-Graph-Structure-Learning"><a href="#UGSL-A-Unified-Framework-for-Benchmarking-Graph-Structure-Learning" class="headerlink" title="UGSL: A Unified Framework for Benchmarking Graph Structure Learning"></a>UGSL: A Unified Framework for Benchmarking Graph Structure Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10737">http://arxiv.org/abs/2308.10737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Bahare Fatemi, Sami Abu-El-Haija, Anton Tsitsulin, Mehran Kazemi, Dustin Zelle, Neslihan Bulut, Jonathan Halcrow, Bryan Perozzi</li>
<li>for: 本研究旨在提供一个统一的框架，用于评估图structured learning模型的效果。</li>
<li>methods: 本研究使用了多种现有的图structured learning模型，并对这些模型进行了广泛的分析和比较。</li>
<li>results: 研究结果表明，不同的模型在不同的情况下具有不同的优劣点，并提供了一个清晰和简洁的理解于这些模型的效果。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) demonstrate outstanding performance in a broad range of applications. While the majority of GNN applications assume that a graph structure is given, some recent methods substantially expanded the applicability of GNNs by showing that they may be effective even when no graph structure is explicitly provided. The GNN parameters and a graph structure are jointly learned. Previous studies adopt different experimentation setups, making it difficult to compare their merits. In this paper, we propose a benchmarking strategy for graph structure learning using a unified framework. Our framework, called Unified Graph Structure Learning (UGSL), reformulates existing models into a single model. We implement a wide range of existing models in our framework and conduct extensive analyses of the effectiveness of different components in the framework. Our results provide a clear and concise understanding of the different methods in this area as well as their strengths and weaknesses. The benchmark code is available at https://github.com/google-research/google-research/tree/master/ugsl.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 在广泛的应用领域中表现出色。大多数 GNN 应用假设给定的图结构，但一些最近的方法已经大幅扩展了 GNN 的可应用范围，显示它们可以在没有明确提供图结构的情况下也是有效的。在这些方法中，GNN 参数和图结构都是共同学习的。先前的研究采用了不同的实验设置，使得比较他们的优劣很Difficult。本文提出了一种图结构学习的 benchmarking 策略，称为 Unified Graph Structure Learning (UGSL)。我们将现有的模型重新表述为单一的模型，并在这个框架中实现了广泛的现有模型。我们进行了广泛的现有模型的分析，并对不同的组件的效果进行了广泛的分析。我们的结果为这一领域的不同方法、优劣点提供了清晰和简洁的理解。代码可以在 https://github.com/google-research/google-research/tree/master/ugsl 中下载。
</details></li>
</ul>
<hr>
<h2 id="Artificial-intelligence-driven-antimicrobial-peptide-discovery"><a href="#Artificial-intelligence-driven-antimicrobial-peptide-discovery" class="headerlink" title="Artificial intelligence-driven antimicrobial peptide discovery"></a>Artificial intelligence-driven antimicrobial peptide discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10921">http://arxiv.org/abs/2308.10921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paulina Szymczak, Ewa Szczurek</li>
<li>for: 抗微生物蛋白（AMPs）作为替代性抗生素，提供了一种新的抗菌抗性材料。</li>
<li>methods: 人工智能（AI）在AMP发现中扮演了关键角色，通过对优秀候选者的预测和材料的生成。</li>
<li>results: AI在AMP发现中取得了 significiant advances，包括预测活性和药理性，以及生成新的AMP候选者。<details>
<summary>Abstract</summary>
Antimicrobial peptides (AMPs) emerge as promising agents against antimicrobial resistance, providing an alternative to conventional antibiotics. Artificial intelligence (AI) revolutionized AMP discovery through both discrimination and generation approaches. The discriminators aid the identification of promising candidates by predicting key peptide properties such as activity and toxicity, while the generators learn the distribution over peptides and enable sampling novel AMP candidates, either de novo, or as analogues of a prototype peptide. Moreover, the controlled generation of AMPs with desired properties is achieved by discriminator-guided filtering, positive-only learning, latent space sampling, as well as conditional and optimized generation. Here we review recent achievements in AI-driven AMP discovery, highlighting the most exciting directions.
</details>
<details>
<summary>摘要</summary>
antimicrobial peptides (AMPs) emerge as promising agents against antimicrobial resistance, providing an alternative to conventional antibiotics. artificial intelligence (AI) revolutionized AMP discovery through both discrimination and generation approaches. the discriminators aid the identification of promising candidates by predicting key peptide properties such as activity and toxicity, while the generators learn the distribution over peptides and enable sampling novel AMP candidates, either de novo, or as analogues of a prototype peptide. Moreover, the controlled generation of AMPs with desired properties is achieved by discriminator-guided filtering, positive-only learning, latent space sampling, as well as conditional and optimized generation. here we review recent achievements in AI-driven AMP discovery, highlighting the most exciting directions.Note: Simplified Chinese is used here as the text is intended for a general audience and not for academic or technical purposes. If you need a more formal or precise translation, please let me know and I can provide it in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="What’s-Race-Got-to-do-with-it-Predicting-Youth-Depression-Across-Racial-Groups-Using-Machine-and-Deep-Learning"><a href="#What’s-Race-Got-to-do-with-it-Predicting-Youth-Depression-Across-Racial-Groups-Using-Machine-and-Deep-Learning" class="headerlink" title="What’s Race Got to do with it? Predicting Youth Depression Across Racial Groups Using Machine and Deep Learning"></a>What’s Race Got to do with it? Predicting Youth Depression Across Racial Groups Using Machine and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11591">http://arxiv.org/abs/2308.11591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Zhong, Nikhil Yadav</li>
<li>for: 本研究旨在透过机器学习（ML）和人工神经网络（ANN）模型，识别高中生中的抑郁症状。</li>
<li>methods: 本研究使用了全国青少年风险行为调查系统（YRBSS）调查数据，并对不同的种族 subgroup 进行了不同的分类。</li>
<li>results: 研究发现，不同的种族 subgroup 有不同的参量，这些参量对于识别抑郁症状具有不同的重要性。ANN模型在整个数据集上得到了82.90%的F1分数，而最佳表现的机器学习模型支持向量机器（SVM）则得到了81.90%的F1分数。<details>
<summary>Abstract</summary>
Depression is a common yet serious mental disorder that affects millions of U.S. high schoolers every year. Still, accurate diagnosis and early detection remain significant challenges. In the field of public health, research shows that neural networks produce promising results in identifying other diseases such as cancer and HIV. This study proposes a similar approach, utilizing machine learning (ML) and artificial neural network (ANN) models to classify depression in a student. Additionally, the study highlights the differences in relevant factors for race subgroups and advocates the need for more extensive and diverse datasets. The models train on nationwide Youth Risk Behavior Surveillance System (YRBSS) survey data, in which the most relevant factors of depression are found with statistical analysis. The survey data is a structured dataset with 15000 entries including three race subsets each consisting of 900 entries. For classification, the research problem is modeled as a supervised learning binary classification problem. Factors relevant to depression for different racial subgroups are also identified. The ML and ANN models are trained on the entire dataset followed by different race subsets to classify whether an individual has depression. The ANN model achieves the highest F1 score of 82.90% while the best-performing machine learning model, support vector machines (SVM), achieves a score of 81.90%. This study reveals that different parameters are more valuable for modeling depression across diverse racial groups and furthers research regarding American youth depression.
</details>
<details>
<summary>摘要</summary>
每年数百万美国高中生都会患上抑郁症，但确定诊断和早期发现仍然是一项大型挑战。在公共卫生领域，研究表明，神经网络生成出了对其他疾病，如癌症和HIV，的识别promising results。这个研究提议了类似的方法，使用机器学习（ML）和人工神经网络（ANN）模型来识别高中生中的抑郁。此外，研究还 highlights the differences in relevant factors for different racial subgroups and advocates the need for more extensive and diverse datasets.研究使用全国青年风险行为监测系统（YRBSS）调查数据进行训练，该数据包括3个种族 subsets，每个 subsets包含900个数据。为了进行分类，研究问题被模型为一个指导学习binary classification问题。对于不同的种族 subgroup，研究还 indentified the factors relevant to depression.使用整个数据集和不同种族 subsets进行训练，ANN模型 achieve最高的F1分数为82.90%，而最佳performing机器学习模型，support vector machines（SVM）， achieve分数为81.90%。这个研究表明，不同种族 subgroup的参数在模型抑郁有所不同，并且推动了美国青年抑郁的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="Test-time-augmentation-based-active-learning-and-self-training-for-label-efficient-segmentation"><a href="#Test-time-augmentation-based-active-learning-and-self-training-for-label-efficient-segmentation" class="headerlink" title="Test-time augmentation-based active learning and self-training for label-efficient segmentation"></a>Test-time augmentation-based active learning and self-training for label-efficient segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10727">http://arxiv.org/abs/2308.10727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bella Specktor-Fadida, Anna Levchakov, Dana Schonberger, Liat Ben-Sira, Dafna Ben-Bashat, Leo Joskowicz</li>
<li>for: 这个论文目的是提出一种 combining 自动学习（AL）和自我教学（ST）方法，以减轻数据注释的卷积 neural network 的Annotation burden。</li>
<li>methods: 这个论文使用的方法包括 Test-Time Augmentations（TTA）、自动学习（AL）和自我教学（ST）。</li>
<li>results: 研究结果显示，ST 是对 MRI 胚胎体和 Placenta 分割任务的非常有效的，可以提高 ID 和 OOD 数据的性能。但是，对于单序列胚胎体分割任务，搅拌自动学习可以提高性能，而对于多序列 Placenta 分割任务，搅拌自我教学可以提高性能。此外，AL 在高变化 Placenta 数据上是有帮助的，但是对于单序列胚胎体数据，AL 不能提高性能。<details>
<summary>Abstract</summary>
Deep learning techniques depend on large datasets whose annotation is time-consuming. To reduce annotation burden, the self-training (ST) and active-learning (AL) methods have been developed as well as methods that combine them in an iterative fashion. However, it remains unclear when each method is the most useful, and when it is advantageous to combine them. In this paper, we propose a new method that combines ST with AL using Test-Time Augmentations (TTA). First, TTA is performed on an initial teacher network. Then, cases for annotation are selected based on the lowest estimated Dice score. Cases with high estimated scores are used as soft pseudo-labels for ST. The selected annotated cases are trained with existing annotated cases and ST cases with border slices annotations. We demonstrate the method on MRI fetal body and placenta segmentation tasks with different data variability characteristics. Our results indicate that ST is highly effective for both tasks, boosting performance for in-distribution (ID) and out-of-distribution (OOD) data. However, while self-training improved the performance of single-sequence fetal body segmentation when combined with AL, it slightly deteriorated performance of multi-sequence placenta segmentation on ID data. AL was helpful for the high variability placenta data, but did not improve upon random selection for the single-sequence body data. For fetal body segmentation sequence transfer, combining AL with ST following ST iteration yielded a Dice of 0.961 with only 6 original scans and 2 new sequence scans. Results using only 15 high-variability placenta cases were similar to those using 50 cases. Code is available at: https://github.com/Bella31/TTA-quality-estimation-ST-AL
</details>
<details>
<summary>摘要</summary>
深度学习技术需要大量的数据集，其标注是时间consuming的。为了减轻标注压力，自适应学习（ST）和活动学习（AL）方法已经被开发出来，同时也有将其结合在迭代方式下的方法。然而，尚未确定哪些情况下使用哪一种方法是最有用，并且何时结合它们是有利的。在这篇论文中，我们提出了一种新的方法，即将ST与AL结合使用测试时间扩展（TTA）。首先，TTA被应用于初始教师网络。然后，根据最低估计的 dice 分数选择标注案例。高估分数的案例用作软件 Pseudo-标注，并与现有标注案例和ST案例进行训练。我们在MRI胎体和胎盘分割任务上进行了实验，并通过不同数据特征来评估我们的方法。我们的结果表明，ST具有高效性，对于ID和OOD数据都有提高性。然而，当与AL结合使用时，单个序列胎体分割的性能有所下降，而多个序列胎盘分割的性能则没有得到提高。AL对高变化胎盘数据是有帮助的，但对单个序列胎体数据没有提高。在胎体分割序列传输中，将AL与ST结合使用，并在ST迭代后进行AL，可以达到0.961的Dice值，只需要6个原始扫描和2个新序列扫描。在50个高变化胎盘案例中，结果与使用50个案例相同。相关代码可以在GitHub上找到：https://github.com/Bella31/TTA-quality-estimation-ST-AL。
</details></li>
</ul>
<hr>
<h2 id="Clustered-Linear-Contextual-Bandits-with-Knapsacks"><a href="#Clustered-Linear-Contextual-Bandits-with-Knapsacks" class="headerlink" title="Clustered Linear Contextual Bandits with Knapsacks"></a>Clustered Linear Contextual Bandits with Knapsacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10722">http://arxiv.org/abs/2308.10722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichuan Deng, Michalis Mamakos, Zhao Song</li>
<li>for: 本研究studies clustered contextual bandits, where rewards and resource consumption are the outcomes of cluster-specific linear models.</li>
<li>methods: 该算法使用了 clustering 技术，并 combining techniques from the literature of econometrics and of bandits with constraints.</li>
<li>results: 该算法可以 achieve regret sublinear in the number of time periods, without requiring access to all of the arms.<details>
<summary>Abstract</summary>
In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究集中的上下文抽奖问题，其中奖励和资源消耗是集中的线性模型的结果。武器被分成集群，集群成员身份未知于算法。在一个时间段内抽一把武器会得到奖励和每种多种资源的消耗，而某些资源的总消耗超过限制，则算法将被终止。因此，最大化总奖励需要学习不仅奖励和资源消耗，还需要集群成员身份。我们提供一种算法，其 regret 是时间段数量的下界，不需要所有武器的访问。具体来说，我们表明只需要对随机选择的一 subset of 武器进行分 clustering 即可。为 достичь这一结果，我们 combinated 了文献中的 econometrics 和抽奖问题的技术。
</details></li>
</ul>
<hr>
<h2 id="CoMIX-A-Multi-agent-Reinforcement-Learning-Training-Architecture-for-Efficient-Decentralized-Coordination-and-Independent-Decision-Making"><a href="#CoMIX-A-Multi-agent-Reinforcement-Learning-Training-Architecture-for-Efficient-Decentralized-Coordination-and-Independent-Decision-Making" class="headerlink" title="CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision Making"></a>CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10721">http://arxiv.org/abs/2308.10721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Minelli, Mirco Musolesi</li>
<li>for: 这篇论文的目的是提出一种基于协调的多代理人训练框架，以便在共享环境中协同完成共同目标，同时保持每个代理人的独立决策能力。</li>
<li>methods: 这篇论文提出了一种名为Coordinated QMIX（CoMIX）的训练框架，该框架基于协调的策略，允许每个代理人在决策过程中独立地做出决定，同时能够适应不同的情况，保持独立和协同的平衡。</li>
<li>results: 实验结果表明，CoMIX在协同任务上表现出色，比基线方法高效。这 validate了 authors 的增量策略方法是一种有效的协调提高多代理人系统的技术。<details>
<summary>Abstract</summary>
Robust coordination skills enable agents to operate cohesively in shared environments, together towards a common goal and, ideally, individually without hindering each other's progress. To this end, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing at the same time independent decision-making at individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process. This allows agents to dynamically adapt their behavior to different situations balancing independence and collaboration. Experiments using a variety of simulation environments demonstrate that CoMIX outperforms baselines on collaborative tasks. The results validate our incremental policy approach as effective technique for improving coordination in multi-agent systems.
</details>
<details>
<summary>摘要</summary>
<<SYS>> transtable text into Simplified Chinese.<</SYS>> Robust coordination skills allow agents to work together in shared environments, working towards a common goal and, ideally, making decisions independently without hindering each other's progress. To achieve this, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing for independent decision-making at the individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process, allowing agents to adapt their behavior dynamically to different situations, balancing independence and collaboration. Experimental results using a variety of simulation environments show that CoMIX outperforms baselines on collaborative tasks, validating our incremental policy approach as an effective technique for improving coordination in multi-agent systems.
</details></li>
</ul>
<hr>
<h2 id="Relax-and-penalize-a-new-bilevel-approach-to-mixed-binary-hyperparameter-optimization"><a href="#Relax-and-penalize-a-new-bilevel-approach-to-mixed-binary-hyperparameter-optimization" class="headerlink" title="Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization"></a>Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10711">http://arxiv.org/abs/2308.10711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marianna de Santis, Jordan Frecon, Francesco Rinaldi, Saverio Salzo, Martin Schmidt</li>
<li>for: 这篇论文是为了提出一种能够有效地优化高维度机器学习模型的混合二级方法的研究。</li>
<li>methods: 该论文使用了一种基于罚项的等值 continous bilevel reformulation 方法，以解决现有的二级参数问题。</li>
<li>results: 该论文的实验结果表明，使用该方法可以对 regression 问题中的组 sparse 结构进行优化，并且比现有的 relaxation 和 rounding 方法表现更好。<details>
<summary>Abstract</summary>
In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for a specific machine learning problem, i.e., the estimation of the group-sparsity structure in regression problems. Reported results clearly show that our method outperforms state-of-the-art approaches based on relaxation and rounding
</details>
<details>
<summary>摘要</summary>
近年来，二级方法已经非常受欢迎地用于高维度机器学习模型参数的效率估算。然而，至今为止，Binary参数都是通过连续弹簧和圆拟法来处理，这可能会导致不一致的解决方案。在这个上下文中，我们解决了高维度混合 Binary 参数的困难优化问题，通过适当的罚项来转化为连续二级 reformulation。我们提出了一个算法框架，在适当的假设下，可以保证提供混合 Binary 解决方案。此外，我们的方法总体来说具有一致性和可靠性，可以安全地使用现有的连续二级解决方案。我们对一个特定的机器学习问题，即回归问题中的集群稀疏结构估算进行评估。报告的结果显示，我们的方法明显超过了当前的 relaxation 和圆拟法所能达到的性能。
</details></li>
</ul>
<hr>
<h2 id="Measuring-the-Effect-of-Causal-Disentanglement-on-the-Adversarial-Robustness-of-Neural-Network-Models"><a href="#Measuring-the-Effect-of-Causal-Disentanglement-on-the-Adversarial-Robustness-of-Neural-Network-Models" class="headerlink" title="Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models"></a>Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10708">http://arxiv.org/abs/2308.10708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prebenness/causal_disentanglement_robustness">https://github.com/prebenness/causal_disentanglement_robustness</a></li>
<li>paper_authors: Preben M. Ness, Dusica Marijan, Sunanda Bose</li>
<li>for: 这些论文主要用于研究 causal Neural Network 模型在针对性攻击方面的Robustness和通用性能。</li>
<li>methods: 这些模型使用了 causal disentanglement 来提高其 Robustness和通用性能，并使用了 Computer Vision 领域的内容&#x2F;风格分离指标来衡量 causal disentanglement。</li>
<li>results: 研究发现， causal Neural Network 模型在针对性攻击方面的 Robustness 与模型 decorrelate causal 和干扰信号的程度有很强的相关性（r&#x3D;0.820， p&#x3D;0.001），同时也发现隐藏信号的像素级信息含量与针对性攻击的Robustness有负相关性（r&#x3D;-0.597， p&#x3D;0.040）。<details>
<summary>Abstract</summary>
Causal Neural Network models have shown high levels of robustness to adversarial attacks as well as an increased capacity for generalisation tasks such as few-shot learning and rare-context classification compared to traditional Neural Networks. This robustness is argued to stem from the disentanglement of causal and confounder input signals. However, no quantitative study has yet measured the level of disentanglement achieved by these types of causal models or assessed how this relates to their adversarial robustness.   Existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets. We, therefore, utilise metrics of content/style disentanglement from the field of Computer Vision to measure different aspects of the causal disentanglement for four state-of-the-art causal Neural Network models. By re-implementing these models with a common ResNet18 architecture we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks. We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness. Additionally, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040).
</details>
<details>
<summary>摘要</summary>
causal neural network 模型在针对敌意攻击方面表现出了高水平的 robustness，以及在几个类型的泛化任务中提高了能力，如少量学习和罕见情况分类。这种 robustness 被认为是由 causal 和干扰输入信号的分离所带来的。然而，现在没有任何量化研究 measure 了这些类型的 causal 模型中的分离水平，或者如何这与其针对敌意攻击的 robustness 相关。现有的 causal 分离度量不适用于 deterministic 模型在实际数据集上的训练。我们因此利用计算机视觉领域中的内容/风格分离度量来测量不同 causal 模型的不同方面的分离度。通过对四种 state-of-the-art causal neural network 模型重新实现，并使用共同的 ResNet18 架构，我们可以公平地测量它们在三个标准图像分类 benchmark 数据集上的针对敌意攻击的 robustness。我们发现 causal 和干扰信号的分离度与模型的针对敌意攻击的 robustness 之间存在强相关性（r = 0.820， p = 0.001）。此外，我们发现干扰信号的像素级信息 contenido 和针对敌意攻击的 robustness 之间存在负相关性（r = -0.597， p = 0.040）。
</details></li>
</ul>
<hr>
<h2 id="Sampling-From-Autoencoders’-Latent-Space-via-Quantization-And-Probability-Mass-Function-Concepts"><a href="#Sampling-From-Autoencoders’-Latent-Space-via-Quantization-And-Probability-Mass-Function-Concepts" class="headerlink" title="Sampling From Autoencoders’ Latent Space via Quantization And Probability Mass Function Concepts"></a>Sampling From Autoencoders’ Latent Space via Quantization And Probability Mass Function Concepts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10704">http://arxiv.org/abs/2308.10704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aymene Mohammed Bouayed, Adrian Iaccovelli, David Naccache</li>
<li>for: 这篇论文主要关注于从生成模型中的伪扩散空间抽样，以确保生成的数据是生活化的图像。</li>
<li>methods: 我们提出了一个新的后训练抽样算法，基于几率质量函数的概念，并与量化过程相结合。我们的算法在每个伪扩散 вектор的输入数据中定义了一个范围，然后从这些定义的邻域中抽样数据。这种策略可以确保抽样的伪扩散 вектор主要 inhabit 高几率区域，并且可以实际地转换为真实世界的图像。</li>
<li>results: 我们的抽样算法在多种模型和数据集上展现出了统计上的优势，特别是在MNIST Benchmark dataset上，我们的方法与GMM抽样比较之下，增加了0.89的FID值。此外，在生成面孔和眼睛图像时，我们的方法也显示了明显的改善，FID值分别提高了1.69和0.87。<details>
<summary>Abstract</summary>
In this study, we focus on sampling from the latent space of generative models built upon autoencoders so as the reconstructed samples are lifelike images. To do to, we introduce a novel post-training sampling algorithm rooted in the concept of probability mass functions, coupled with a quantization process. Our proposed algorithm establishes a vicinity around each latent vector from the input data and then proceeds to draw samples from these defined neighborhoods. This strategic approach ensures that the sampled latent vectors predominantly inhabit high-probability regions, which, in turn, can be effectively transformed into authentic real-world images. A noteworthy point of comparison for our sampling algorithm is the sampling technique based on Gaussian mixture models (GMM), owing to its inherent capability to represent clusters. Remarkably, we manage to improve the time complexity from the previous $\mathcal{O}(n\times d \times k \times i)$ associated with GMM sampling to a much more streamlined $\mathcal{O}(n\times d)$, thereby resulting in substantial speedup during runtime. Moreover, our experimental results, gauged through the Fr\'echet inception distance (FID) for image generation, underscore the superior performance of our sampling algorithm across a diverse range of models and datasets. On the MNIST benchmark dataset, our approach outperforms GMM sampling by yielding a noteworthy improvement of up to $0.89$ in FID value. Furthermore, when it comes to generating images of faces and ocular images, our approach showcases substantial enhancements with FID improvements of $1.69$ and $0.87$ respectively, as compared to GMM sampling, as evidenced on the CelebA and MOBIUS datasets. Lastly, we substantiate our methodology's efficacy in estimating latent space distributions in contrast to GMM sampling, particularly through the lens of the Wasserstein distance.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们关注生成模型基于autoencoder的 latent space采样，以便生成真实的图像。为此，我们提出了一种新的 posterior 采样算法，基于概率质量函数，并与量化过程结合。我们的算法在每个输入数据的 latent vector周围建立一个定义的邻域，然后从这些定义的邻域中采样。这种策略使得采样的 latent vector主要居住在高概率区域中，从而可以有效地转换为真实的世界图像。与基于 Gaussian mixture models (GMM) 的采样技术相比，我们的采样算法具有更高的时间复杂度优化，从 $\mathcal{O}(n\times d\times k\times i)$ 降低到 $\mathcal{O}(n\times d)$，从而在运行时间中获得了显著的加速。此外，我们通过 Fréchet inception distance (FID) 测试，发现我们的采样算法在不同的模型和数据集上显示出了显著的性能优势。在 MNIST 测试集上，我们的方法与 GMM 采样相比，提高了 FID 值的不可或缺的提升，达到 $0.89$。此外，在生成人脸和眼部图像时，我们的方法也表现出了显著的改善，FID 提升 $1.69$ 和 $0.87$ 分别，与 GMM 采样相比。最后，我们通过 Wasserstein distance 测试，证明我们的方法在估计 latent space 分布方面的效果比 GMM 采样更好。
</details></li>
</ul>
<hr>
<h2 id="Refashioning-Emotion-Recognition-Modelling-The-Advent-of-Generalised-Large-Models"><a href="#Refashioning-Emotion-Recognition-Modelling-The-Advent-of-Generalised-Large-Models" class="headerlink" title="Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models"></a>Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11578">http://arxiv.org/abs/2308.11578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixing Zhang, Liyizhe Peng, Tao Pang, Jing Han, Huan Zhao, Bjorn W. Schuller</li>
<li>for: This paper aims to investigate the performance of large language models (LLMs) in emotion recognition, specifically looking at in-context learning, few-shot learning, accuracy, generalization, and explanation.</li>
<li>methods: The paper uses LLMs, such as ChatGPT, to perform emotion recognition tasks, and examines their performance in various aspects.</li>
<li>results: The paper provides insights into the performance of LLMs in emotion recognition, including their ability to learn with few examples, adapt to new contexts, and provide explanations for their predictions.<details>
<summary>Abstract</summary>
After the inception of emotion recognition or affective computing, it has increasingly become an active research topic due to its broad applications. Over the past couple of decades, emotion recognition models have gradually migrated from statistically shallow models to neural network-based deep models, which can significantly boost the performance of emotion recognition models and consistently achieve the best results on different benchmarks. Therefore, in recent years, deep models have always been considered the first option for emotion recognition. However, the debut of large language models (LLMs), such as ChatGPT, has remarkably astonished the world due to their emerged capabilities of zero/few-shot learning, in-context learning, chain-of-thought, and others that are never shown in previous deep models. In the present paper, we comprehensively investigate how the LLMs perform in emotion recognition in terms of diverse aspects, including in-context learning, few-short learning, accuracy, generalisation, and explanation. Moreover, we offer some insights and pose other potential challenges, hoping to ignite broader discussions about enhancing emotion recognition in the new era of advanced and generalised large models.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: послеinception of emotion recognition or affective computing, it has increasingly become an active research topic due to its broad applications. Over the past couple of decades, emotion recognition models have gradually migrated from statistically shallow models to neural network-based deep models, which can significantly boost the performance of emotion recognition models and consistently achieve the best results on different benchmarks. Therefore, in recent years, deep models have always been considered the first option for emotion recognition. However, the debut of large language models (LLMs), such as ChatGPT, has remarkably astonished the world due to their emerged capabilities of zero/few-shot learning, in-context learning, chain-of-thought, and others that are never shown in previous deep models. In the present paper, we comprehensively investigate how the LLMs perform in emotion recognition in terms of diverse aspects, including in-context learning, few-short learning, accuracy, generalisation, and explanation. Moreover, we offer some insights and pose other potential challenges, hoping to ignite broader discussions about enhancing emotion recognition in the new era of advanced and generalised large models.Translated into Traditional Chinese:在内心 recognition of emotion or affective computing 的启动以来，它已经成为一个活跃的研究领域，因为它的应用非常广泛。过去几十年，情感识别模型在从 statistically shallow 模型演化到基于神经网络的深度模型，可以对情感识别模型的性能提高，并在不同的 benchmark 上获得最好的结果。因此，在最近的年份，深度模型一直被视为情感识别的首选。然而，大型语言模型（LLMs），如 ChatGPT，在世界上发生了惊人的出现，因为它们的发展出了过去深度模型 nunca 显示的一些能力，包括零/几架学习、上下文学习、链接思维等。在 presente 纸上，我们全面调查了 LLMs 在情感识别方面的表现，包括上下文学习、几架学习、准确性、一致性和解释等方面。此外，我们还提供了一些问题和潜在的挑战，希望能够发球更广泛的讨论，以推动情感识别在新的时代的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="An-engine-to-simulate-insurance-fraud-network-data"><a href="#An-engine-to-simulate-insurance-fraud-network-data" class="headerlink" title="An engine to simulate insurance fraud network data"></a>An engine to simulate insurance fraud network data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11659">http://arxiv.org/abs/2308.11659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bavo D. C. Campo, Katrien Antonio</li>
<li>for: 本研究旨在开发高效、准确的欺诈检测模型，以便更好地检测保险欺诈laims。</li>
<li>methods: 本研究使用社交网络中充满特征的数据进行学习，并可以控制数据生成机制以便模拟不同的情况。</li>
<li>results: 通过使用这些synthetic数据，研究人员和实践者可以测试不同的检测模型，并评估其预测性能。<details>
<summary>Abstract</summary>
Traditionally, the detection of fraudulent insurance claims relies on business rules and expert judgement which makes it a time-consuming and expensive process (\'Oskarsd\'ottir et al., 2022). Consequently, researchers have been examining ways to develop efficient and accurate analytic strategies to flag suspicious claims. Feeding learning methods with features engineered from the social network of parties involved in a claim is a particularly promising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et al. (2023)). When developing a fraud detection model, however, we are confronted with several challenges. The uncommon nature of fraud, for example, creates a high class imbalance which complicates the development of well performing analytic classification models. In addition, only a small number of claims are investigated and get a label, which results in a large corpus of unlabeled data. Yet another challenge is the lack of publicly available data. This hinders not only the development of new methods, but also the validation of existing techniques. We therefore design a simulation machine that is engineered to create synthetic data with a network structure and available covariates similar to the real life insurance fraud data set analyzed in \'Oskarsd\'ottir et al. (2022). Further, the user has control over several data-generating mechanisms. We can specify the total number of policyholders and parties, the desired level of imbalance and the (effect size of the) features in the fraud generating model. As such, the simulation engine enables researchers and practitioners to examine several methodological challenges as well as to test their (development strategy of) insurance fraud detection models in a range of different settings. Moreover, large synthetic data sets can be generated to evaluate the predictive performance of (advanced) machine learning techniques.
</details>
<details>
<summary>摘要</summary>
传统上，探测欺诈保险索赔靠业务规则和专家判断，这使得过程时间consuming和成本高（'Oskarsd\'ottir等，2022）。因此，研究人员在尝试开发高效和准确的分析策略来标识可疑索赔。从社交网络中提取和Engineered特征来帮助学习方法是一种非常有前途的策略（如Van Vlasselaer等，2016；Tumminello等，2023）。在开发欺诈检测模型时，我们面临了多个挑战。欺诈的罕见性导致分类问题的吸引性异常高，这使得开发高性能分类模型的发展具有挑战性。此外，只有一小部分索赔被调查并获得标签，导致大量的无标签数据。此外，公共数据的缺乏也阻碍了新方法的开发和现有技术的验证。为了解决这些问题，我们设计了一台模拟机器，可以生成具有网络结构和实际欺诈数据集中可用特征的 sintetic数据。用户可以控制数据生成机制，包括总体保险持有人和相关人数、欺诈水平和特征效果等。因此，模拟机器可以帮助研究人员和实践者在不同的设定下测试开发策略和检测模型，并生成大量的 sintetic数据来评估高级机器学习技术的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Cost-Efficient-Online-Decision-Making-A-Combinatorial-Multi-Armed-Bandit-Approach"><a href="#Cost-Efficient-Online-Decision-Making-A-Combinatorial-Multi-Armed-Bandit-Approach" class="headerlink" title="Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach"></a>Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10699">http://arxiv.org/abs/2308.10699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arman Rahbar, Niklas Åkerblom, Morteza Haghir Chehreghani</li>
<li>for: 这篇论文是关于在多种应用场景中进行在线决策的研究，具体来说是在收到新数据点时进行测试序列的决策。</li>
<li>methods: 本文提出了一种基于 combinatorial multi-armed bandits 的新的在线决策问题的形式ulation，并使用 posterior sampling 或 BayesUCB 进行探索。</li>
<li>results: 本文提供了一种新的成本效益的在线决策框架，并进行了严格的理论分析和多种实验 validate 其可用性。<details>
<summary>Abstract</summary>
Online decision making plays a crucial role in numerous real-world applications. In many scenarios, the decision is made based on performing a sequence of tests on the incoming data points. However, performing all tests can be expensive and is not always possible. In this paper, we provide a novel formulation of the online decision making problem based on combinatorial multi-armed bandits and take the cost of performing tests into account. Based on this formulation, we provide a new framework for cost-efficient online decision making which can utilize posterior sampling or BayesUCB for exploration. We provide a rigorous theoretical analysis for our framework and present various experimental results that demonstrate its applicability to real-world problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-expectations-Residual-Dynamic-Mode-Decomposition-and-Variance-for-Stochastic-Dynamical-Systems"><a href="#Beyond-expectations-Residual-Dynamic-Mode-Decomposition-and-Variance-for-Stochastic-Dynamical-Systems" class="headerlink" title="Beyond expectations: Residual Dynamic Mode Decomposition and Variance for Stochastic Dynamical Systems"></a>Beyond expectations: Residual Dynamic Mode Decomposition and Variance for Stochastic Dynamical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10697">http://arxiv.org/abs/2308.10697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew J. Colbrook, Qin Li, Ryan V. Raut, Alex Townsend</li>
<li>For: 这个论文的目的是为了解决非线性动力系统中的库曼操作符的特征，以及其spectral information的计算方法。* Methods: 这篇论文使用了Dynamic Mode Decomposition（DMD）方法，以及一个额外的DMD-type矩阵，来 aproximate the sum of a squared residual and a variance term，从而控制 projection error。* Results: 这篇论文的结果表明，通过包含差异的库曼框架，可以 Addressing challenges such as spurious modes, essential spectra, and the verification of Koopman mode decompositions for stochastic systems。 In addition, the authors introduce the concept of variance-pseudospectra to gauge statistical coherence, and present a suite of convergence results for the spectral quantities of stochastic Koopman operators. Finally, the study demonstrates practical applications using both simulated and experimental data, and reveals physiologically significant information unavailable to standard expectation-based dynamical models.<details>
<summary>Abstract</summary>
Koopman operators linearize nonlinear dynamical systems, making their spectral information of crucial interest. Numerous algorithms have been developed to approximate these spectral properties, and Dynamic Mode Decomposition (DMD) stands out as the poster child of projection-based methods. Although the Koopman operator itself is linear, the fact that it acts in an infinite-dimensional space of observables poses various challenges. These include spurious modes, essential spectra, and the verification of Koopman mode decompositions. While recent work has addressed these challenges for deterministic systems, there remains a notable gap in verified DMD methods tailored for stochastic systems, where the Koopman operator measures the expectation of observables. We show that it is necessary to go beyond expectations to address these issues. By incorporating variance into the Koopman framework, we address these challenges. Through an additional DMD-type matrix, we approximate the sum of a squared residual and a variance term, each of which can be approximated individually using batched snapshot data. This allows verified computation of the spectral properties of stochastic Koopman operators, controlling the projection error. We also introduce the concept of variance-pseudospectra to gauge statistical coherency. Finally, we present a suite of convergence results for the spectral quantities of stochastic Koopman operators. Our study concludes with practical applications using both simulated and experimental data. In neural recordings from awake mice, we demonstrate how variance-pseudospectra can reveal physiologically significant information unavailable to standard expectation-based dynamical models.
</details>
<details>
<summary>摘要</summary>
黑曼操作符 linearizes nonlinear dynamical systems, making its spectral information of crucial interest. numerous algorithms have been developed to approximate these spectral properties, and Dynamic Mode Decomposition (DMD) stands out as the poster child of projection-based methods. Although the Koopman operator itself is linear, the fact that it acts in an infinite-dimensional space of observables poses various challenges. These include spurious modes, essential spectra, and the verification of Koopman mode decompositions. While recent work has addressed these challenges for deterministic systems, there remains a notable gap in verified DMD methods tailored for stochastic systems, where the Koopman operator measures the expectation of observables. We show that it is necessary to go beyond expectations to address these issues. By incorporating variance into the Koopman framework, we address these challenges. Through an additional DMD-type matrix, we approximate the sum of a squared residual and a variance term, each of which can be approximated individually using batched snapshot data. This allows verified computation of the spectral properties of stochastic Koopman operators, controlling the projection error. We also introduce the concept of variance-pseudospectra to gauge statistical coherency. Finally, we present a suite of convergence results for the spectral quantities of stochastic Koopman operators. Our study concludes with practical applications using both simulated and experimental data. In neural recordings from awake mice, we demonstrate how variance-pseudospectra can reveal physiologically significant information unavailable to standard expectation-based dynamical models.Here's the translation in Traditional Chinese:科普曼操作符可以线性化非线性动力学系统，使其特征对应的spectral information得到了核心地位。numerous algorithms have been developed to approximate these spectral properties, and Dynamic Mode Decomposition (DMD) stands out as the poster child of projection-based methods. although the Koopman operator itself is linear, the fact that it acts in an infinite-dimensional space of observables poses various challenges. These include spurious modes, essential spectra, and the verification of Koopman mode decompositions. While recent work has addressed these challenges for deterministic systems, there remains a notable gap in verified DMD methods tailored for stochastic systems, where the Koopman operator measures the expectation of observables. We show that it is necessary to go beyond expectations to address these issues. By incorporating variance into the Koopman framework, we address these challenges. Through an additional DMD-type matrix, we approximate the sum of a squared residual and a variance term, each of which can be approximated individually using batched snapshot data. This allows verified computation of the spectral properties of stochastic Koopman operators, controlling the projection error. We also introduce the concept of variance-pseudospectra to gauge statistical coherency. Finally, we present a suite of convergence results for the spectral quantities of stochastic Koopman operators. Our study concludes with practical applications using both simulated and experimental data. In neural recordings from awake mice, we demonstrate how variance-pseudospectra can reveal physiologically significant information unavailable to standard expectation-based dynamical models.
</details></li>
</ul>
<hr>
<h2 id="An-Improved-Best-of-both-worlds-Algorithm-for-Bandits-with-Delayed-Feedback"><a href="#An-Improved-Best-of-both-worlds-Algorithm-for-Bandits-with-Delayed-Feedback" class="headerlink" title="An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback"></a>An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10675">http://arxiv.org/abs/2308.10675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeed Masoudian, Julian Zimmert, Yevgeny Seldin</li>
<li>for: 本文提出了一种新的best-of-both-worlds算法，用于带延迟反馈的bandit问题。该算法改进了先前的 Masoudian et al. 的工作，不需要先知道最大延迟 $d_{\max}$，并提供了更紧的 regret bounds。</li>
<li>methods: 本文使用了 counts of outstanding observations（在动作时间被观察到的尚未完成的观察数）而不是延迟或最大延迟（只在反馈 arrive时被观察到）来实现。一个重要贡献是控制分布漂移，基于偏损失估计器和延迟过大的观察被跳过。</li>
<li>results: 本文的 regret bounds 是基于 counts of outstanding observations after skipping of observations with excessively large delays，而不是延迟或最大延迟。这一结论表明了best-of-both-worlds bandit with delayed feedback的复杂性是由出standing observations的总计数所定义，而不是延迟或最大延迟。<details>
<summary>Abstract</summary>
We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的最佳之both-worlds算法，用于带有变化延迟反馈的带宽问题。该算法超越了先前的 Masoudian 等人（2022）的工作，不需要先知道最大延迟 $d_{\max}$，并提供了更紧的 regret bound 在两个 режиме下。该算法和其 regret bound 基于当时行动时观察到的待机数（一个观察到的量）而不是延迟或最大延迟（只有在反馈来到时才能观察到的量）。我们的一个重要贡献是一种新的分布漂移控制，基于偏置损失估计器和延迟过长的观察抛弃。另一个重要贡献是表明了最佳之both-worlds 带宽问题的复杂度被定义为在延迟抛弃后的累积待机数后，而不是延迟或最大延迟。
</details></li>
</ul>
<hr>
<h2 id="A-Safe-Deep-Reinforcement-Learning-Approach-for-Energy-Efficient-Federated-Learning-in-Wireless-Communication-Networks"><a href="#A-Safe-Deep-Reinforcement-Learning-Approach-for-Energy-Efficient-Federated-Learning-in-Wireless-Communication-Networks" class="headerlink" title="A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks"></a>A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10664">http://arxiv.org/abs/2308.10664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolaos Koursioumpas, Lina Magoula, Nikolaos Petropouleas, Alexandros-Ioannis Thanopoulos, Theodora Panagea, Nancy Alonistioti, M. A. Gutierrez-Estevez, Ramin Khalili</li>
<li>for: 提高 Federated Learning（FL）过程中的能源占用率，并保证模型的性能。</li>
<li>methods: 提出一种 Soft Actor Critic Deep Reinforcement Learning（DRL）解决方案，并在训练过程中引入罚函数，以避免环境约束的违反。</li>
<li>results: 与四个州OF-the-art基eline解决方案进行比较，在静态和动态环境中达到了94%的能源占用减少。<details>
<summary>Abstract</summary>
Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and ensuring a safe RL process. A device level synchronization method, along with a computationally cost effective FL environment are proposed, with the goal of further reducing the energy consumption and communication overhead. Evaluation results show the effectiveness of the proposed scheme compared to four state-of-the-art baseline solutions in both static and dynamic environments, achieving a decrease of up to 94% in the total energy consumption.
</details>
<details>
<summary>摘要</summary>
Note: Simplified Chinese is also known as "简化字" or "简化字".Translation Notes:* "Federated Learning" is translated as "联合学习" (Liánhégòngxué)* "Soft Actor Critic" is translated as "软 actor 批评" (Ruǎn yuǎn jīng zhì)* "Deep Reinforcement Learning" is translated as "深度强化学习" (Shēngrán jīnghòu xuéxí)* "Device level synchronization" is translated as "设备层同步" (Jījī kuàng yì)* "Computationally cost-effective" is translated as "计算成本低" (Jìsuàn jīngbèi dī)
</details></li>
</ul>
<hr>
<h2 id="Practical-Parallel-Algorithms-for-Non-Monotone-Submodular-Maximization"><a href="#Practical-Parallel-Algorithms-for-Non-Monotone-Submodular-Maximization" class="headerlink" title="Practical Parallel Algorithms for Non-Monotone Submodular Maximization"></a>Practical Parallel Algorithms for Non-Monotone Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10656">http://arxiv.org/abs/2308.10656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, Aakas Zhiyuli, Hanxiao Li</li>
<li>for: 这paper focuses on developing efficient and parallelizable algorithms for submodular maximization in various domains of artificial intelligence, such as machine learning, computer vision, and natural language processing.</li>
<li>methods: 该paper proposes two algorithms for non-monotone submodular maximization subject to a knapsack constraint and a $k$-system constraint, respectively. The first algorithm achieves an $(8+\epsilon)$-approximation under $\mathcal{O}(\log n)$ adaptive complexity, which is optimal up to a factor of $\mathcal{O}(\log\log n)$. The second algorithm has both provable approximation ratio and sublinear adaptive complexity.</li>
<li>results: 该paper achieves performance bounds comparable with those of state-of-the-art algorithms on the special case of submodular maximization subject to a cardinality constraint. Extensive experiments on real-world applications demonstrate the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Submodular maximization has found extensive applications in various domains within the field of artificial intelligence, including but not limited to machine learning, computer vision, and natural language processing. With the increasing size of datasets in these domains, there is a pressing need to develop efficient and parallelizable algorithms for submodular maximization. One measure of the parallelizability of a submodular maximization algorithm is its adaptive complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an $(8+\epsilon)$-approximation under $\mathcal{O}(\log n)$ adaptive complexity, which is \textit{optimal} up to a factor of $\mathcal{O}(\log\log n)$. Moreover, we also propose the first algorithm with both provable approximation ratio and sublinear adaptive complexity for the problem of non-monotone submodular maximization subject to a $k$-system constraint. As a by-product, we show that our two algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.
</details>
<details>
<summary>摘要</summary>
“对于人工智能领域内的不同领域，例如机器学习、computer vision和自然语言处理，submodular maximization已经获得了广泛的应用。随着这些领域的数据规模的增加，发展高效且可并行化的submodular maximization算法成为了一个紧迫的需求。一个measure of the parallelizability of a submodular maximization algorithm是其adaptive complexity，它指出在执行多个并行查询时，可以在执行多个sequential round中 Execute a polynomial number of queries to the objective function。在这篇论文中，我们研究了非单调submodular maximization subject to a knapsack constraint，并提出了首次的 combinatorial algorithm，可以在 $\mathcal{O}(\log n)$ adaptive complexity下实现 $(8+\epsilon)$-approximation，这是optimal up to a factor of $\mathcal{O}(\log\log n)$。此外，我们还提出了首次的一个Algorithm with both provable approximation ratio and sublinear adaptive complexity for the problem of non-monotone submodular maximization subject to a $k$-system constraint。在特殊情况下，我们的两个算法可以应用到submodular maximization subject to a cardinality constraint，并实现与现有算法相当的性能。最后，我们通过实验证明了我们的方法的有效性。”
</details></li>
</ul>
<hr>
<h2 id="Deep-Evidential-Learning-for-Bayesian-Quantile-Regression"><a href="#Deep-Evidential-Learning-for-Bayesian-Quantile-Regression" class="headerlink" title="Deep Evidential Learning for Bayesian Quantile Regression"></a>Deep Evidential Learning for Bayesian Quantile Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10650">http://arxiv.org/abs/2308.10650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frederik Boe Hüttel, Filipe Rodrigues, Francisco Câmara Pereira</li>
<li>for: 这篇论文旨在提出一种深度 bayesian 量化回归模型，能够无需 Gaussian 假设来Estimate 连续目标分布的Quantiles。</li>
<li>methods: 该方法基于 evidential learning，通过单个推理过程来捕捉 aleatoric 和 epistemic uncertainty。</li>
<li>results: 对于非 Gaussian 分布，该方法可以实现准确的 uncertainty estimation，并且可以分解 aleatoric 和 epistemic uncertainty，以及对于异常样本的 Robustness。<details>
<summary>Abstract</summary>
It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncertainties on non-Gaussian distributions, disentanglement of aleatoric and epistemic uncertainty, and robustness to out-of-distribution samples.
</details>
<details>
<summary>摘要</summary>
希望通过单个决定性前进模型获得准确的不确定性估计，然而这是困难的因为单个前进模型在推理过程中不会采样权重。传统方法的不确定性量化 computationally expensive。这些方法经常假设目标分布是 Gaussian，这可能是回归任务中的限制。这篇文章提出了深度 bayesian 量化回归模型，可以无需 Gaussian 假设来估计连续目标分布的quantiles。提出的方法基于证据学习，使得模型能够捕捉 aleatoric 和 epistemic 不确定性。这使得方法高效可扩展。我们示示了该方法可以在非 Gaussian 分布上获得准确的不确定性估计，分离 aleatoric 和 epistemic 不确定性，并对异常样本具有鲁棒性。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-Based-Sensor-Optimization-for-Bio-markers"><a href="#Reinforcement-Learning-Based-Sensor-Optimization-for-Bio-markers" class="headerlink" title="Reinforcement Learning Based Sensor Optimization for Bio-markers"></a>Reinforcement Learning Based Sensor Optimization for Bio-markers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10649">http://arxiv.org/abs/2308.10649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sajal Khandelwal, Pawan Kumar, Syed Azeemuddin</li>
<li>for: 这个论文旨在提高基于电子板的射频生物感测器的敏感度。</li>
<li>methods: 这个论文使用了一种新的强化学习基于二进制蜂群优化（RLBPSO）算法来优化感测器的设计参数，并与其他当前领域的方法进行比较。</li>
<li>results: 研究发现，RLBPSO方法可以在不同频率范围内提高感测器的敏感度，并且在不同的电极设计和脚宽参数下显示出最佳性能。<details>
<summary>Abstract</summary>
Radio frequency (RF) biosensors, in particular those based on inter-digitated capacitors (IDCs), are pivotal in areas like biomedical diagnosis, remote sensing, and wireless communication. Despite their advantages of low cost and easy fabrication, their sensitivity can be hindered by design imperfections, environmental factors, and circuit noise. This paper investigates enhancing the sensitivity of IDC-based RF sensors using novel reinforcement learning based Binary Particle Swarm Optimization (RLBPSO), and it is compared to Ant Colony Optimization (ACO), and other state-of-the-art methods. By focusing on optimizing design parameters like electrode design and finger width, the proposed study found notable improvements in sensor sensitivity. The proposed RLBPSO method shows best optimized design for various frequency ranges when compared to current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Radio frequency (RF) 感测器，尤其是基于交错电极（IDC）的感测器，在生物医学诊断、远程探测和无线通信等领域具有重要地位。尽管它们具有低成本和易于制造的优点，但是设计瑕疵、环境因素和电路噪声可能会减少它们的敏感度。这篇论文探讨了使用新的强化学习基于二进制群集优化（RLBPSO）方法来提高IDC基于RF感测器的敏感度，并与抗群优化（ACO）和其他当前最佳方法进行比较。通过对设计参数如电极设计和脚宽进行优化，该研究发现了显著提高感测器敏感度的可能性。RLBPSO方法在不同频率范围内对感测器设计优化表现出了最佳的效果。
</details></li>
</ul>
<hr>
<h2 id="Faster-Training-of-Neural-ODEs-Using-Gaus-Legendre-Quadrature"><a href="#Faster-Training-of-Neural-ODEs-Using-Gaus-Legendre-Quadrature" class="headerlink" title="Faster Training of Neural ODEs Using Gauß-Legendre Quadrature"></a>Faster Training of Neural ODEs Using Gauß-Legendre Quadrature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10644">http://arxiv.org/abs/2308.10644</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-norcliffe/torch_gq_adjoint">https://github.com/a-norcliffe/torch_gq_adjoint</a></li>
<li>paper_authors: Alexander Norcliffe, Marc Peter Deisenroth</li>
<li>for: 提高神经泛化方法的训练速度，尤其是大型神经网络。</li>
<li>methods: 使用Gau{\ss}-Legendre quadrature来更快地解决 интегралы，而不会影响神经网络的表达能力。</li>
<li>results: 提出了一种新的方法来快速训练神经泛化方法，并且可以应用于大型神经网络和SDE-based模型的训练。<details>
<summary>Abstract</summary>
Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SCULPT-Shape-Conditioned-Unpaired-Learning-of-Pose-dependent-Clothed-and-Textured-Human-Meshes"><a href="#SCULPT-Shape-Conditioned-Unpaired-Learning-of-Pose-dependent-Clothed-and-Textured-Human-Meshes" class="headerlink" title="SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes"></a>SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10638">http://arxiv.org/abs/2308.10638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soubhik Sanyal, Partha Ghosh, Jinlong Yang, Michael J. Black, Justus Thies, Timo Bolkart</li>
<li>for: 这个论文的目的是提出一种基于深度学习的3D生成模型，用于生成披覆的人体3D模型。</li>
<li>methods: 这个论文使用的方法包括：（1）利用CAPE数据集和大规模的2D图像数据集来隐式学习 clothed human body的几何和外观分布；（2）提出一种不需要对数据集进行对应的学习方法，可以从2D图像数据集中学习 pose-dependent clothed human body的几何和外观特征；（3）使用 attribute labels 来分离 cloth 类型和 pose 之间的杂糅关系，以及 cloth 颜色和 pose 之间的杂糅关系。</li>
<li>results: 这个论文的结果显示，使用这种方法可以生成高质量的 clothed human body 3D模型，并且比之前的方法更加灵活和可控。<details>
<summary>Abstract</summary>
We present SCULPT, a novel 3D generative model for clothed and textured 3D meshes of humans. Specifically, we devise a deep neural network that learns to represent the geometry and appearance distribution of clothed human bodies. Training such a model is challenging, as datasets of textured 3D meshes for humans are limited in size and accessibility. Our key observation is that there exist medium-sized 3D scan datasets like CAPE, as well as large-scale 2D image datasets of clothed humans and multiple appearances can be mapped to a single geometry. To effectively learn from the two data modalities, we propose an unpaired learning procedure for pose-dependent clothed and textured human meshes. Specifically, we learn a pose-dependent geometry space from 3D scan data. We represent this as per vertex displacements w.r.t. the SMPL model. Next, we train a geometry conditioned texture generator in an unsupervised way using the 2D image data. We use intermediate activations of the learned geometry model to condition our texture generator. To alleviate entanglement between pose and clothing type, and pose and clothing appearance, we condition both the texture and geometry generators with attribute labels such as clothing types for the geometry, and clothing colors for the texture generator. We automatically generated these conditioning labels for the 2D images based on the visual question answering model BLIP and CLIP. We validate our method on the SCULPT dataset, and compare to state-of-the-art 3D generative models for clothed human bodies. We will release the codebase for research purposes.
</details>
<details>
<summary>摘要</summary>
我们介绍SCULPT，一种新的3D生成模型，用于 clothed和textured 3D雷达图像的人体。我们设计了一个深度神经网络，用于表示人体的几何和外观分布。由于人体3D扫描数据的限制，训练这种模型是一个挑战。我们的关键观察是，存在中等大小的3D扫描数据集，如CAPE，以及大规模的2D图像数据集，包含不同的服装和人体姿势。为了有效地利用这两种数据模式，我们提出了一种无关的学习过程，用于pose-dependent clothed和textured人体3D雷达图像。我们从3D扫描数据中学习一个pose-dependent的几何空间，并将其表示为每个顶点的位差相对于SMPL模型。然后，我们在无监督的情况下使用2D图像数据来训练一个几何条件的文本生成器。我们使用学习的几何模型的中间活动来condition我们的文本生成器。为了避免姿势和服装类型之间的杂谱和姿势和服装外观之间的杂谱，我们将condition both texture和geometry生成器使用属性标签，例如服装类型 для几何和服装颜色 для文本生成器。我们自动生成了这些conditioning标签基于视觉问答模型BLIP和CLIP。我们验证了我们的方法SCULPT数据集上，并与状态之前的3D生成模型进行比较。我们将发布代码库用于研究目的。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-oriented-Robustness-Robust-Image-Model-Evaluation-with-Pretrained-Models"><a href="#Foundation-Model-oriented-Robustness-Robust-Image-Model-Evaluation-with-Pretrained-Models" class="headerlink" title="Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"></a>Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10632">http://arxiv.org/abs/2308.10632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyan Zhang, Haoyang Liu, Chaozhuo Li, Xing Xie, Sunghun Kim, Haohan Wang</li>
<li>for: 这篇论文主要关注于评估图像分类模型的 robustness 性能，以及开发一种新的评估方法以外测试模型的性能。</li>
<li>methods: 本论文提出了一种新的评估方法，即与基本模型（oracle）进行比较，以评估图像分类模型的性能。此外， authors还提出了一种使用新的样本生成方法，以增加测试数据的多样性。</li>
<li>results: 本论文的实验结果表明，使用该新的评估方法可以准确地评估图像分类模型的 robustness 性能，并且可以免除 fix benchmarks 的限制。此外， authors 还通过对模型的行为进行分析，了解模型在不同情况下的行为。<details>
<summary>Abstract</summary>
Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretrained with a large amount of samples. As a result, our new method will offer us a new way to evaluate the models' robustness performance, free of limitations of fixed benchmarks or constrained perturbations, although scoped by the power of the oracle. In addition to the evaluation results, we also leverage our generated data to understand the behaviors of the model and our new evaluation strategies.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Homogenization-Approach-for-Gradient-Dominated-Stochastic-Optimization"><a href="#A-Homogenization-Approach-for-Gradient-Dominated-Stochastic-Optimization" class="headerlink" title="A Homogenization Approach for Gradient-Dominated Stochastic Optimization"></a>A Homogenization Approach for Gradient-Dominated Stochastic Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10630">http://arxiv.org/abs/2308.10630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiyuan Tan, Chenyu Xue, Chuwen Zhang, Qi Deng, Dongdong Ge, Yinyu Ye</li>
<li>for: 这篇论文是关于非对称优化的研究，尤其是gradient-dominated optimization，并使用了homogenization approach来解决问题。</li>
<li>methods: 本文使用了stochastic homogeneous second-order descent method (SHSODM)，并提出了一种具有variance reduction技术的SHSODM，具体来说是使用extremal eigenvector problems来解决问题。</li>
<li>results: 本文的结果显示SHSODM可以在非对称优化中实现global convergence，并且可以比其他off-the-shelf方法更高效。具体来说，本文的结果显示SHSODM可以在$\alpha \in [1, 2]$的情况下实现sample complexity bound of $O(\epsilon^{-7&#x2F;(2 \alpha) +1})$和$\tilde{O}(\epsilon^{-2&#x2F;\alpha})$。此外，本文还提出了一种具有variance reduction技术的SHSODM，其sample complexity bound为$O( \epsilon ^{-( 7-3\alpha ) &#x2F;( 2\alpha )})$。<details>
<summary>Abstract</summary>
Gradient dominance property is a condition weaker than strong convexity, yet it sufficiently ensures global convergence for first-order methods even in non-convex optimization. This property finds application in various machine learning domains, including matrix decomposition, linear neural networks, and policy-based reinforcement learning (RL). In this paper, we study the stochastic homogeneous second-order descent method (SHSODM) for gradient-dominated optimization with $\alpha \in [1, 2]$ based on a recently proposed homogenization approach. Theoretically, we show that SHSODM achieves a sample complexity of $O(\epsilon^{-7/(2 \alpha) +1})$ for $\alpha \in [1, 3/2)$ and $\tilde{O}(\epsilon^{-2/\alpha})$ for $\alpha \in [3/2, 2]$. We further provide a SHSODM with a variance reduction technique enjoying an improved sample complexity of $O( \epsilon ^{-( 7-3\alpha ) /( 2\alpha )})$ for $\alpha \in [1,3/2)$. Our results match the state-of-the-art sample complexity bounds for stochastic gradient-dominated optimization without \emph{cubic regularization}. Since the homogenization approach only relies on solving extremal eigenvector problems instead of Newton-type systems, our methods gain the advantage of cheaper iterations and robustness in ill-conditioned problems. Numerical experiments on several RL tasks demonstrate the efficiency of SHSODM compared to other off-the-shelf methods.
</details>
<details>
<summary>摘要</summary>
“Gradient占主性质是一种弱于强Converter的条件，但它足够保证全局收敛性 для首频方法，即使在非 convex 优化中。这种性质在机器学习中有很多应用，包括矩阵分解、线性神经网络和Policy-based 强化学习（RL）。在这篇论文中，我们研究了随机同质二阶 descend 方法（SHSODM）在 Gradient-dominated 优化中，基于最近提出的同质化方法。我们证明了 SHSODM 的样本复杂度为 $O(\epsilon^{-7/(2\alpha) +1})$ for $\alpha \in [1, 3/2)$ 和 $\tilde{O}(\epsilon^{-2/\alpha})$ for $\alpha \in [3/2, 2]$。我们还提供了一种 SHSODM 使用减少噪声的技术，其样本复杂度为 $O( \epsilon ^{-( 7-3\alpha ) /( 2\alpha )})$ for $\alpha \in [1,3/2)$。我们的结果与不含 кубиック regularization 的 Stochastic gradient-dominated 优化的状态艺术性样本复杂度匹配。由于同质化方法只需解决极值 eigenvector 问题而不需要 Newton-type 系统，我们的方法具有更便宜的迭代和稳定性。 numerical experiments on several RL tasks 表明 SHSODM 比其他 off-the-shelf 方法更高效。”
</details></li>
</ul>
<hr>
<h2 id="GaitPT-Skeletons-Are-All-You-Need-For-Gait-Recognition"><a href="#GaitPT-Skeletons-Are-All-You-Need-For-Gait-Recognition" class="headerlink" title="GaitPT: Skeletons Are All You Need For Gait Recognition"></a>GaitPT: Skeletons Are All You Need For Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10623">http://arxiv.org/abs/2308.10623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andy Catruna, Adrian Cosma, Emilian Radoi</li>
<li>for: 人脸识别（人脸认知）</li>
<li>methods: pose estimation skeletons + hierarchical transformer architecture</li>
<li>results: 比其他skeleton-based gait recognition工作高出6%的平均准确率（82.6%），以及52.16%的排名第1精度（Rank-1）。<details>
<summary>Abstract</summary>
The analysis of patterns of walking is an important area of research that has numerous applications in security, healthcare, sports and human-computer interaction. Lately, walking patterns have been regarded as a unique fingerprinting method for automatic person identification at a distance. In this work, we propose a novel gait recognition architecture called Gait Pyramid Transformer (GaitPT) that leverages pose estimation skeletons to capture unique walking patterns, without relying on appearance information. GaitPT adopts a hierarchical transformer architecture that effectively extracts both spatial and temporal features of movement in an anatomically consistent manner, guided by the structure of the human skeleton. Our results show that GaitPT achieves state-of-the-art performance compared to other skeleton-based gait recognition works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6% average accuracy on CASIA-B, surpassing other works by a margin of 6%. Moreover, it obtains 52.16% Rank-1 accuracy on GREW, outperforming both skeleton-based and appearance-based approaches.
</details>
<details>
<summary>摘要</summary>
研究人行姿势的分析是一个重要的领域，它在安全、医疗、运动和人机交互等领域都有广泛的应用。最近，人行姿势被视为一种唯一的指纹方法，用于自动识别人员。在这项工作中，我们提出了一种新的步态识别架构，称为步态 pyramid transformer（GaitPT），它利用 pose estimation skeleton 来捕捉唯一的人行姿势特征，不依赖于外观信息。GaitPT 采用了层次 transformer 架构，能够有效地提取人体运动的空间和时间特征，并且以人体骨架为引导，以遵循人体解剖结构。我们的结果表明，GaitPT 在 CASIA-B 上取得了82.6% 的平均准确率，比其他skeleton-based gait recognition 工作高出6%。此外，它在 GREW 上取得了52.16% 的排名第一准确率，超过了skeleton-based和 appearance-based Approaches。
</details></li>
</ul>
<hr>
<h2 id="Weighting-by-Tying-A-New-Approach-to-Weighted-Rank-Correlation"><a href="#Weighting-by-Tying-A-New-Approach-to-Weighted-Rank-Correlation" class="headerlink" title="Weighting by Tying: A New Approach to Weighted Rank Correlation"></a>Weighting by Tying: A New Approach to Weighted Rank Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10622">http://arxiv.org/abs/2308.10622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sascha Henzgen, Eyke Hüllermeier</li>
<li>for: 这篇论文是关于 Statistics 中的排名相关性度量的研究，旨在捕捉两个排名的相同集合中的项目之间的协调程度。</li>
<li>methods: 该论文使用了基于杂态顺序关系的尺度的权重版本，具有可 Parametrized 的权重分配方式，以及一种灵活的权重分配方法。</li>
<li>results: 研究人员通过提出了一种基于杂态顺序关系的尺度的权重版本，具有sound的形式基础和灵活的权重分配方式，实现了在排名相关性度量中增加权重。<details>
<summary>Abstract</summary>
Measures of rank correlation are commonly used in statistics to capture the degree of concordance between two orderings of the same set of items. Standard measures like Kendall's tau and Spearman's rho coefficient put equal emphasis on each position of a ranking. Yet, motivated by applications in which some of the positions (typically those on the top) are more important than others, a few weighted variants of these measures have been proposed. Most of these generalizations fail to meet desirable formal properties, however. Besides, they are often quite inflexible in the sense of committing to a fixed weighing scheme. In this paper, we propose a weighted rank correlation measure on the basis of fuzzy order relations. Our measure, called scaled gamma, is related to Goodman and Kruskal's gamma rank correlation. It is parametrized by a fuzzy equivalence relation on the rank positions, which in turn is specified conveniently by a so-called scaling function. This approach combines soundness with flexibility: it has a sound formal foundation and allows for weighing rank positions in a flexible way.
</details>
<details>
<summary>摘要</summary>
ranking 关系度量通常用于统计学中，用于捕捉两个顺序化的同一组项目之间的协调度。标准度量 LIKE Kendall tau 和 Spearman ρ 系数都强调每个排名位置的等效性。然而，基于应用场景中一些排名位置（通常是排名的顶部）更重要 than others，一些加权变体的度量已经被提议。然而，大多数这些扩展都不具备 Desirable 的正式性质，而且它们通常具有固定的加权方案。在这篇论文中，我们提出了基于杂元顺序关系的加权排名相关度量。我们的度量，叫做 scaled gamma，与 Goodman 和 Kruskal 的 gamma 排名相关度量相关。它是通过一个杂元等同关系来规定排名位置，这个关系再次是通过一个called scaling function来指定。这种方法结合了准确性和灵活性：它具有准确的形式基础，同时允许对排名位置进行灵活的归一化。
</details></li>
</ul>
<hr>
<h2 id="centroIDA-Cross-Domain-Class-Discrepancy-Minimization-Based-on-Accumulative-Class-Centroids-for-Imbalanced-Domain-Adaptation"><a href="#centroIDA-Cross-Domain-Class-Discrepancy-Minimization-Based-on-Accumulative-Class-Centroids-for-Imbalanced-Domain-Adaptation" class="headerlink" title="centroIDA: Cross-Domain Class Discrepancy Minimization Based on Accumulative Class-Centroids for Imbalanced Domain Adaptation"></a>centroIDA: Cross-Domain Class Discrepancy Minimization Based on Accumulative Class-Centroids for Imbalanced Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10619">http://arxiv.org/abs/2308.10619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaona Sun, Zhenyu Wu, Yichen Liu, Saier Hu, Zhiqiang Zhan, Yang Ji</li>
<li>for: 本研究targets the imbalanced domain adaptation (IDA) problem, which involves both covariate and long-tailed label shifts across domains.</li>
<li>methods: The proposed method, called centroIDA, uses a cross-domain class discrepancy minimization approach based on accumulative class-centroids alignment. This method includes class-based re-sampling, accumulative class-centroids alignment, and class-wise feature alignment.</li>
<li>results: The proposed method outperforms other state-of-the-art (SOTA) methods on the IDA problem, especially when the degree of label shift increases.<details>
<summary>Abstract</summary>
Unsupervised Domain Adaptation (UDA) approaches address the covariate shift problem by minimizing the distribution discrepancy between the source and target domains, assuming that the label distribution is invariant across domains. However, in the imbalanced domain adaptation (IDA) scenario, covariate and long-tailed label shifts both exist across domains. To tackle the IDA problem, some current research focus on minimizing the distribution discrepancies of each corresponding class between source and target domains. Such methods rely much on the reliable pseudo labels' selection and the feature distributions estimation for target domain, and the minority classes with limited numbers makes the estimations more uncertainty, which influences the model's performance. In this paper, we propose a cross-domain class discrepancy minimization method based on accumulative class-centroids for IDA (centroIDA). Firstly, class-based re-sampling strategy is used to obtain an unbiased classifier on source domain. Secondly, the accumulative class-centroids alignment loss is proposed for iterative class-centroids alignment across domains. Finally, class-wise feature alignment loss is used to optimize the feature representation for a robust classification boundary. A series of experiments have proved that our method outperforms other SOTA methods on IDA problem, especially with the increasing degree of label shift.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation (UDA)方法解决 covariate shift 问题，即在源频率和目标频率之间的分布差异假设 label 分布是各频率之间不变。然而，在不平衡频率适应 (IDA) 场景中，covariate 和长尾标签各自存在在不同频率之间的差异。为解决 IDA 问题，一些当前研究强调在每个匹配的类之间分布差异的最小化。这些方法需要可靠的 pseudo label 选择和目标频率的特征分布估计，但是少数类的数量有限，这会使估计更加不确定，影响模型的性能。在这篇论文中，我们提出了一种基于积累类中心的 cross-domain 类差异最小化方法（centroIDA）。首先，使用 class-based 重采样策略来在源频率上获得不偏向的类ifier。其次，为了迭代类中心的对齐，我们提出了积累类中心对齐损失。最后，使用类别特征对齐损失来优化特征表示，以实现一个可靠的分类边界。经过一系列实验证明，我们的方法在 IDA 问题上表现出优于现有 SOTA 方法，特别是随着标签差异的增加。
</details></li>
</ul>
<hr>
<h2 id="ST-RAP-A-Spatio-Temporal-Framework-for-Real-Estate-Appraisal"><a href="#ST-RAP-A-Spatio-Temporal-Framework-for-Real-Estate-Appraisal" class="headerlink" title="ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal"></a>ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10609">http://arxiv.org/abs/2308.10609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dojeon-ai/strap">https://github.com/dojeon-ai/strap</a></li>
<li>paper_authors: Hojoon Lee, Hawon Jeong, Byungkun Lee, Kyungyup Lee, Jaegul Choo</li>
<li>for: 这个论文是为了提出一种新的空间 temporal 框架，用于房地产评估。</li>
<li>methods: 这个框架使用层次结构和不同类型的图神经网络来同时捕捉空间和时间方面的关系和动态。</li>
<li>results: 通过对大规模房地产数据集进行广泛的实验，ST-RAP 表明了在房地产评估中同时考虑空间和时间方面的综合效果。Here’s the translation in English:</li>
<li>for: This paper proposes a novel Spatio-Temporal framework for Real estate APpraisal.</li>
<li>methods: The framework employs a hierarchical architecture with a heterogeneous graph neural network to simultaneously capture temporal dynamics and spatial relationships.</li>
<li>results: Through comprehensive experiments on a large-scale real estate dataset, ST-RAP outperforms previous methods, demonstrating the significant benefits of integrating spatial and temporal aspects in real estate appraisal.<details>
<summary>Abstract</summary>
In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for Real estate APpraisal. ST-RAP employs a hierarchical architecture with a heterogeneous graph neural network to encapsulate temporal dynamics and spatial relationships simultaneously. Through comprehensive experiments on a large-scale real estate dataset, ST-RAP outperforms previous methods, demonstrating the significant benefits of integrating spatial and temporal aspects in real estate appraisal. Our code and dataset are available at https://github.com/dojeon-ai/STRAP.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了ST-RAP，一种新的空间-时间框架，用于房地产评估。ST-RAP使用层次架构和不同类型的图 neural network来同时捕捉时间动态和空间关系。通过对大规模房地产数据进行全面的实验，ST-RAP表明了将空间和时间方面综合考虑在房地产评估中的重要性，并且超过了之前的方法。我们的代码和数据可以在https://github.com/dojeon-ai/STRAP上获取。
</details></li>
</ul>
<hr>
<h2 id="FocalDreamer-Text-driven-3D-Editing-via-Focal-fusion-Assembly"><a href="#FocalDreamer-Text-driven-3D-Editing-via-Focal-fusion-Assembly" class="headerlink" title="FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly"></a>FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10608">http://arxiv.org/abs/2308.10608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Li, Yishun Dou, Yue Shi, Yu Lei, Xuanhong Chen, Yi Zhang, Peng Zhou, Bingbing Ni</li>
<li>for: 该论文旨在提供一种基于文本指示的高级3D编辑方法，以便在特定区域内进行精细编辑。</li>
<li>methods: 该方法基于文本蒸馈采样的技术，并使用geometry union和双轨渲染技术将独立的3D部件组合成完整的物体。此外，该方法还提出了geometry focal loss和样式一致准则，以促进焦点融合和整体外观的一致性。</li>
<li>results: 实验结果表明，FocalDreamer方法可以在量化和质量上提供高级3D编辑功能，并且在多种图形引擎下生成高质量的几何学和PBRTexture。<details>
<summary>Abstract</summary>
While text-3D editing has made significant strides in leveraging score distillation sampling, emerging approaches still fall short in delivering separable, precise and consistent outcomes that are vital to content creation. In response, we introduce FocalDreamer, a framework that merges base shape with editable parts according to text prompts for fine-grained editing within desired regions. Specifically, equipped with geometry union and dual-path rendering, FocalDreamer assembles independent 3D parts into a complete object, tailored for convenient instance reuse and part-wise control. We propose geometric focal loss and style consistency regularization, which encourage focal fusion and congruent overall appearance. Furthermore, FocalDreamer generates high-fidelity geometry and PBR textures which are compatible with widely-used graphics engines. Extensive experiments have highlighted the superior editing capabilities of FocalDreamer in both quantitative and qualitative evaluations.
</details>
<details>
<summary>摘要</summary>
“文本3D编辑在利用分数浸泡样本方面已经做出了重要进步，但现有方法仍然缺乏提供分解、精准和一致的结果，这些结果对内容创建至关重要。为此，我们介绍了FOCAL Dreamer框架，该框架将基本形状与可编辑部分相结合，根据文本提示进行细致的编辑，并在 Desired 区域内进行精细控制。Specifically, FOCAL Dreamer 使用geometry union和双路渲染技术，将独立的3D部件组合成完整的 объек，且适用于便捷的实例重用和部件控制。我们还提出了 геометрической专注损失和风格一致 regularization，这两种正则化激励核心融合和一致的整体外观。此外，FOCAL Dreamer 生成高质量的几何学和PBR文本ure，与广泛使用的图形引擎相容。我们的实验表明，FOCAL Dreamer 在量化和质量两个方面的评价都具有明显的优势。”
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Complex-Systems-with-Cascades-Using-Continuous-Time-Bayesian-Networks"><a href="#Analyzing-Complex-Systems-with-Cascades-Using-Continuous-Time-Bayesian-Networks" class="headerlink" title="Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks"></a>Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10606">http://arxiv.org/abs/2308.10606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Bregoli, Karin Rathsman, Marco Scutari, Fabio Stella, Søren Wengel Mogensen</li>
<li>for: 本研究旨在分析复杂系统中的协同事件链的冲击行为，以便更好地理解系统中哪些状态会触发冲击行为。</li>
<li>methods: 本研究使用连续时间权重网络（CTBN）模型来分析复杂系统中的协同事件链，并提出了一种新的知识提取方法来从CTBN中提取有用的信息。</li>
<li>results: 研究人员通过应用CTBN模型和新的知识提取方法，成功地找到了可能导致冲击行为的系统状态，并获得了可读的输出结果。<details>
<summary>Abstract</summary>
Interacting systems of events may exhibit cascading behavior where events tend to be temporally clustered. While the cascades themselves may be obvious from the data, it is important to understand which states of the system trigger them. For this purpose, we propose a modeling framework based on continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in complex systems. This framework allows us to describe how events propagate through the system and to identify likely sentry states, that is, system states that may lead to imminent cascading behavior. Moreover, CTBNs have a simple graphical representation and provide interpretable outputs, both of which are important when communicating with domain experts. We also develop new methods for knowledge extraction from CTBNs and we apply the proposed methodology to a data set of alarms in a large industrial system.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：复杂系统中的事件互动可能会展现堆叠行为，其中事件倾向于在时间上叠加。虽然堆叠本身可能从数据中容易看到，但是要理解触发它们的系统状态非常重要。为了解决这个问题，我们提出了基于连续时间概率网络（CTBN）的模型化框架，用于分析复杂系统中的堆叠行为。这个框架可以描述事件如何在系统中传播，并识别可能导致堆叠行为的系统状态。此外，CTBN具有简单的图形表示和可解释的输出，这两点都是与领域专家交流时非常重要。我们还开发了新的知识提取方法，并将该方法应用于一个大型工业系统的数据集。
</details></li>
</ul>
<hr>
<h2 id="BackTrack-Robust-template-update-via-Backward-Tracking-of-candidate-template"><a href="#BackTrack-Robust-template-update-via-Backward-Tracking-of-candidate-template" class="headerlink" title="BackTrack: Robust template update via Backward Tracking of candidate template"></a>BackTrack: Robust template update via Backward Tracking of candidate template</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10604">http://arxiv.org/abs/2308.10604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongwook Lee, Wonjun Choi, Seohyung Lee, ByungIn Yoo, Eunho Yang, Seongju Hwang</li>
<li>for: 提高视觉对象跟踪性能，解决模板更新引起的模型漂移问题</li>
<li>methods: 提出BackTrack方法，通过倒计时追踪候选模板，计算候选模板的可靠程度，选择可靠的候选模板更新模板</li>
<li>results: 对多个跟踪 benchmark 进行了广泛的实验，证明BackTrack方法可以提高模板更新精度，达到最新的状态角度表现In English, this translates to:</li>
<li>for: Improving visual object tracking performance, solving the template drift problem caused by template updates</li>
<li>methods: Propose BackTrack method, which backward tracks candidates on past frames to calculate their reliability, and selects reliable candidates to update the template</li>
<li>results: Extensive experiments on various tracking benchmarks demonstrate that BackTrack method can improve template update accuracy, achieving state-of-the-art performance.<details>
<summary>Abstract</summary>
Variations of target appearance such as deformations, illumination variance, occlusion, etc., are the major challenges of visual object tracking that negatively impact the performance of a tracker. An effective method to tackle these challenges is template update, which updates the template to reflect the change of appearance in the target object during tracking. However, with template updates, inadequate quality of new templates or inappropriate timing of updates may induce a model drift problem, which severely degrades the tracking performance. Here, we propose BackTrack, a robust and reliable method to quantify the confidence of the candidate template by backward tracking it on the past frames. Based on the confidence score of candidates from BackTrack, we can update the template with a reliable candidate at the right time while rejecting unreliable candidates. BackTrack is a generic template update scheme and is applicable to any template-based trackers. Extensive experiments on various tracking benchmarks verify the effectiveness of BackTrack over existing template update algorithms, as it achieves SOTA performance on various tracking benchmarks.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traduction de texte en chinois simplifiéVariations de l'apparence cible telles que les déformations, les variations d'éclairage, les occlusions, etc., sont les principales difficultés de la suivi d'objets visuels qui négativement affectent la performance d'un traqueur. Une méthode efficace pour relever ces défis est l'actualisation du modèle, qui met à jour le modèle pour refléter les changements d'apparence dans l'objet cible pendant la traque. Cependant, avec des mises à jour de modèle, la qualité inadéquate des nouveaux modèles ou la mise à jour inopportune peuvent entraîner un problème de drift de modèle, qui altère gravement la performance de la traque. Voici ce que nous proposons : BackTrack, un méthode robuste et fiable pour estimer la confiance du modèle de candidature en backward tracking les frames passées. En fonction de la note de confiance des candidats de BackTrack, nous pouvons mettre à jour le modèle avec un candidat fiable à temps opportun, tout en rejetant les candidats non fiables. BackTrack est un schéma d'actualisation de modèle générique et est applicable à tous les trackers de modèle. Les expériences extensives sur divers bancs d'essai de suivi ont verifié l'efficacité de BackTrack par rapport aux algorithmes d'actualisation de modèle existants, car elle atteint des performances SOTA sur divers bancs d'essai de suivi.
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Transferability-of-Adversarial-Examples-with-Arbitrary-Style-Transfer"><a href="#Improving-the-Transferability-of-Adversarial-Examples-with-Arbitrary-Style-Transfer" class="headerlink" title="Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer"></a>Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10601">http://arxiv.org/abs/2308.10601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhijin-ge/stm">https://github.com/zhijin-ge/stm</a></li>
<li>paper_authors: Zhijin Ge, Fanhua Shang, Hongying Liu, Yuanyuan Liu, Liang Wan, Wei Feng, Xiaosen Wang</li>
<li>for: 本研究旨在提高黑盒 Setting 下 adversarial example 的转移性，通过将具有不同领域的资料作为增强资料。</li>
<li>methods: 我们提出了一种名为 Style Transfer Method (STM) 的新攻击方法，它利用一个提案的自由式类别转换网络将图像转换为不同的领域。为了确保涂抹后的图像仍保持 semantics 信息，我们在涂抹过程中进行了精确的调整和混合。</li>
<li>results: 我们在 ImageNet-compatible 数据集上进行了广泛的实验，结果显示，我们的提案的 STM 方法可以在 normally 训练的模型或 adversarially 训练的模型上提高 adversarial transferability，较前者的 state-of-the-art input transformation-based 攻击方法。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/Zhijin-Ge/STM%E3%80%82">https://github.com/Zhijin-Ge/STM。</a><details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on clean inputs. Although many attack methods can achieve high success rates in the white-box setting, they also exhibit weak transferability in the black-box setting. Recently, various methods have been proposed to improve adversarial transferability, in which the input transformation is one of the most effective methods. In this work, we notice that existing input transformation-based works mainly adopt the transformed data in the same domain for augmentation. Inspired by domain generalization, we aim to further improve the transferability using the data augmented from different domains. Specifically, a style transfer network can alter the distribution of low-level visual features in an image while preserving semantic content for humans. Hence, we propose a novel attack method named Style Transfer Method (STM) that utilizes a proposed arbitrary style transfer network to transform the images into different domains. To avoid inconsistent semantic information of stylized images for the classification network, we fine-tune the style transfer network and mix up the generated images added by random noise with the original images to maintain semantic consistency and boost input diversity. Extensive experimental results on the ImageNet-compatible dataset show that our proposed method can significantly improve the adversarial transferability on either normally trained models or adversarially trained models than state-of-the-art input transformation-based attacks. Code is available at: https://github.com/Zhijin-Ge/STM.
</details>
<details>
<summary>摘要</summary>
Extensive experimental results on the ImageNet-compatible dataset show that our proposed method can significantly improve the adversarial transferability on either normally trained models or adversarially trained models than state-of-the-art input transformation-based attacks. Code is available at: https://github.com/Zhijin-Ge/STM.Translated into Simplified Chinese:深度神经网络受到人类不可见的攻击例子的威胁，尽管许多攻击方法在白盒设定下可以达到高成功率，但它们也表现出了软输送性。在黑盒设定下，许多方法已经被提出来改进攻击传输性，其中输入转换是最有效的方法。在这项工作中，我们注意到现有的输入转换基于工作主要采用转换后的数据进行增强。受到域泛化的启发，我们想要进一步提高传输性，使用不同域的数据进行增强。Specifically, a style transfer network can alter the distribution of low-level visual features in an image while preserving semantic content for humans. Hence, we propose a novel attack method named Style Transfer Method (STM) that utilizes a proposed arbitrary style transfer network to transform the images into different domains. To avoid inconsistent semantic information of stylized images for the classification network, we fine-tune the style transfer network and mix up the generated images added by random noise with the original images to maintain semantic consistency and boost input diversity. 广泛的实验结果表明，我们提出的方法可以在 ImageNet  compatible 数据集上对 normally 训练的模型和 adversarially 训练的模型进行较好的攻击传输性，比采用 state-of-the-art 的输入转换基于攻击方法高。代码可以在：https://github.com/Zhijin-Ge/STM 中找到。
</details></li>
</ul>
<hr>
<h2 id="Image-free-Classifier-Injection-for-Zero-Shot-Classification"><a href="#Image-free-Classifier-Injection-for-Zero-Shot-Classification" class="headerlink" title="Image-free Classifier Injection for Zero-Shot Classification"></a>Image-free Classifier Injection for Zero-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10599">http://arxiv.org/abs/2308.10599</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/explainableml/imagefreezsl">https://github.com/explainableml/imagefreezsl</a></li>
<li>paper_authors: Anders Christensen, Massimiliano Mancini, A. Sophia Koepke, Ole Winther, Zeynep Akata</li>
<li>for: 这个研究目的是为了将预训模型转换为零shot学习模型，不需要训练图像数据。</li>
<li>methods: 我们提出了一种名为Image-free Classifier Injection with Semantics（ICIS）的方法，可以在预训模型上附加零shot学习能力，不需要任何图像数据。ICIS使用两个encoder-decoder网络，将描述器转换为分类器的重量，并且运用(cross-)重建和偏角损失来调整解oding过程。</li>
<li>results: 实验结果显示，ICIS可以在 benchmark ZSL 数据集上生成出高性能的零shot分类器。code可以在<a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ImageFreeZSL">https://github.com/ExplainableML/ImageFreeZSL</a> 上获取。<details>
<summary>Abstract</summary>
Zero-shot learning models achieve remarkable results on image classification for samples from classes that were not seen during training. However, such models must be trained from scratch with specialised methods: therefore, access to a training dataset is required when the need for zero-shot classification arises. In this paper, we aim to equip pre-trained models with zero-shot classification capabilities without the use of image data. We achieve this with our proposed Image-free Classifier Injection with Semantics (ICIS) that injects classifiers for new, unseen classes into pre-trained classification models in a post-hoc fashion without relying on image data. Instead, the existing classifier weights and simple class-wise descriptors, such as class names or attributes, are used. ICIS has two encoder-decoder networks that learn to reconstruct classifier weights from descriptors (and vice versa), exploiting (cross-)reconstruction and cosine losses to regularise the decoding process. Notably, ICIS can be cheaply trained and applied directly on top of pre-trained classification models. Experiments on benchmark ZSL datasets show that ICIS produces unseen classifier weights that achieve strong (generalised) zero-shot classification performance. Code is available at https://github.com/ExplainableML/ImageFreeZSL .
</details>
<details>
<summary>摘要</summary>
Zero-shot learning模型在图像分类任务中达到了非常出色的结果，但是这些模型必须通过特殊的方法进行训练，因此需要训练集的存在。在这篇论文中，我们想要让预训练模型具有零批学习的分类能力，而无需使用图像数据。我们通过我们提出的图像自由分类插入（ICIS）技术来实现这一目标。ICIS使用两个Encoder-Decoder网络来学习从描述符（包括类名或属性）中重建分类器权重，不需要使用图像数据。我们通过（cross-）重建和归一化损失来规范解码过程。吸引人的是，ICIS可以便宜地训练和应用于预训练分类模型之上。我们在 benchmark ZSL 数据集上进行了实验，并证明了 ICIS 可以生成出高性能的零批分类器。代码可以在 GitHub 上找到：https://github.com/ExplainableML/ImageFreeZSL。
</details></li>
</ul>
<hr>
<h2 id="RADIANCE-Radio-Frequency-Adversarial-Deep-learning-Inference-for-Automated-Network-Coverage-Estimation"><a href="#RADIANCE-Radio-Frequency-Adversarial-Deep-learning-Inference-for-Automated-Network-Coverage-Estimation" class="headerlink" title="RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for Automated Network Coverage Estimation"></a>RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for Automated Network Coverage Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10584">http://arxiv.org/abs/2308.10584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sopan Sarkar, Mohammad Hossein Manshaei, Marwan Krunz</li>
<li>for: 这个研究是为了自动生成无线电网络的覆盖地图（RF maps），以便于无线网络的计划、Access Point和基站的位置设置、地点定位和覆盖估计。</li>
<li>methods: 这个研究使用了一个对抗式深度学习推断（GAN）基础的方法，叫做 radio-frequency adversarial deep-learning inference for automated network coverage estimation（RADIANCE），它使用了一个 semantic map，一个高级的内部环境表示，来编码空间关系和内部环境中物体的特征。这个方法还使用了一个新的梯度基于的损失函数，它计算了从环境中的点到接收信号强度（RSS）值的变化的大小和方向。</li>
<li>results: 这个研究的结果显示，使用 RADIANCE 可以实现覆盖地图的自动生成，并且与射线追踪模拟相比，RADIANCE 可以得到较佳的结果，其中的 mean average error（MAE）为 0.09，root-mean-squared error（RMSE）为 0.29，peak signal-to-noise ratio（PSNR）为 10.78，multi-scale structural similarity index（MS-SSIM）为 0.80。<details>
<summary>Abstract</summary>
Radio-frequency coverage maps (RF maps) are extensively utilized in wireless networks for capacity planning, placement of access points and base stations, localization, and coverage estimation. Conducting site surveys to obtain RF maps is labor-intensive and sometimes not feasible. In this paper, we propose radio-frequency adversarial deep-learning inference for automated network coverage estimation (RADIANCE), a generative adversarial network (GAN) based approach for synthesizing RF maps in indoor scenarios. RADIANCE utilizes a semantic map, a high-level representation of the indoor environment to encode spatial relationships and attributes of objects within the environment and guide the RF map generation process. We introduce a new gradient-based loss function that computes the magnitude and direction of change in received signal strength (RSS) values from a point within the environment. RADIANCE incorporates this loss function along with the antenna pattern to capture signal propagation within a given indoor configuration and generate new patterns under new configuration, antenna (beam) pattern, and center frequency. Extensive simulations are conducted to compare RADIANCE with ray-tracing simulations of RF maps. Our results show that RADIANCE achieves a mean average error (MAE) of 0.09, root-mean-squared error (RMSE) of 0.29, peak signal-to-noise ratio (PSNR) of 10.78, and multi-scale structural similarity index (MS-SSIM) of 0.80.
</details>
<details>
<summary>摘要</summary>
射频覆盖地图（RF 地图）在无线网络中广泛使用，用于容量规划、Access Point和基站的布局、地理位置和覆盖估计。进行场景调查以获取RF地图是劳动密集且不可靠。在这篇论文中，我们提出了射频对抗深度学习推断（RADIANCE），一种基于生成对抗网络（GAN）的方法，用于自动生成室内场景中的射频地图。RADIANCE利用了 semantic map，一个高级的室内环境表示，以编码空间关系和环境中对象的特征。我们引入了一个新的梯度基于损失函数，计算从环境中的点的受信号强度（RSS）值的变化大小和方向。RADIANCE将这个损失函数与天线 patrón 混合，以捕捉室内配置下的信号传播特性，并生成新的射频地图。我们对RADIANCE与射频投影 simulations进行了广泛的比较。结果显示，RADIANCE的 mean average error（MAE）为0.09，root-mean-squared error（RMSE）为0.29，受信号强度比（PSNR）为10.78，和多尺度结构相似度（MS-SSIM）为0.80。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-online-framework-for-BCI-evaluation-A-MOABB-perspective"><a href="#Pseudo-online-framework-for-BCI-evaluation-A-MOABB-perspective" class="headerlink" title="Pseudo-online framework for BCI evaluation: A MOABB perspective"></a>Pseudo-online framework for BCI evaluation: A MOABB perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11656">http://arxiv.org/abs/2308.11656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Igor Carrara, Théodore Papadopoulo</li>
<li>for: 本研究旨在扩展现有的MOABB框架，以便在 Pseudo-online 模式下比较不同算法的性能。</li>
<li>methods: 本研究使用了 overlaping sliding windows 技术，并引入了停靠状态事件，以考虑所有不同的思维方式。</li>
<li>results: 研究分析了过去 15 年的州际顶点算法，并对多个 Motor Imagery 数据集进行了分析，显示了两种方法之间的统计上的差异。<details>
<summary>Abstract</summary>
Objective: BCI (Brain-Computer Interface) technology operates in three modes: online, offline, and pseudo-online. In the online mode, real-time EEG data is constantly analyzed. In offline mode, the signal is acquired and processed afterwards. The pseudo-online mode processes collected data as if they were received in real-time. The main difference is that the offline mode often analyzes the whole data, while the online and pseudo-online modes only analyze data in short time windows. Offline analysis is usually done with asynchronous BCIs, which restricts analysis to predefined time windows. Asynchronous BCI, compatible with online and pseudo-online modes, allows flexible mental activity duration. Offline processing tends to be more accurate, while online analysis is better for therapeutic applications. Pseudo-online implementation approximates online processing without real-time constraints. Many BCI studies being offline introduce biases compared to real-life scenarios, impacting classification algorithm performance. Approach: The objective of this research paper is therefore to extend the current MOABB framework, operating in offline mode, so as to allow a comparison of different algorithms in a pseudo-online setting with the use of a technology based on overlapping sliding windows. To do this will require the introduction of a idle state event in the dataset that takes into account all different possibilities that are not task thinking. To validate the performance of the algorithms we will use the normalized Matthews Correlation Coefficient (nMCC) and the Information Transfer Rate (ITR). Main results: We analyzed the state-of-the-art algorithms of the last 15 years over several Motor Imagery (MI) datasets composed by several subjects, showing the differences between the two approaches from a statistical point of view. Significance: The ability to analyze the performance of different algorithms in offline and pseudo-online modes will allow the BCI community to obtain more accurate and comprehensive reports regarding the performance of classification algorithms.
</details>
<details>
<summary>摘要</summary>
目标：BCI（脑computer接口）技术运行在三种模式之一：在线、离线和假在线模式。在在线模式下，实时EEG数据被不断分析。在离线模式下，信号被获取并处理后进行分析。假在线模式处理收集的数据，如果收集的数据是在实时进行处理的话。主要的区别在于离线模式通常分析整个数据，而在线和假在线模式只分析短时间窗口中的数据。离线分析通常更加准确，而在线分析更适合治疗应用。假在线实现方式模拟在线处理，不受实时限制。许多BCI研究都是离线进行，这会引入比实际情况更多的偏见，影响分类算法的性能。方法：为了扩展当前的MOABB框架，它在离线模式下运行，以便对不同算法的比较在假在线设置下进行。为此，需要引入一个假静止状态事件，考虑所有不同的可能性，不是任务思考。为了验证算法的性能，我们使用 норма化的玛特维克相互相关系数（nMCC）和信息传输率（ITR）。结果：我们对过去15年的State-of-the-art算法进行分析，并在多个motor imagery（MI）数据集上进行了比较。显示了两种方法的 statistically 的差异。重要性：能够在离线和假在线模式下分析不同算法的性能，将BCI社区获得更加准确和全面的报告关于分类算法的性能。
</details></li>
</ul>
<hr>
<h2 id="Overcoming-Overconfidence-for-Active-Learning"><a href="#Overcoming-Overconfidence-for-Active-Learning" class="headerlink" title="Overcoming Overconfidence for Active Learning"></a>Overcoming Overconfidence for Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10571">http://arxiv.org/abs/2308.10571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujin Hwang, Won Jo, Juyoung Hong, Yukyung Choi</li>
<li>for: 这篇论文主要关注于解决人工智能学习中的数据选择问题，以提高模型的准确性和可靠性。</li>
<li>methods: 本论文提出了两种解决过去误差问题的方法：一是将数据扩展为多个不同的数据分布，以帮助模型更好地调整；二是根据预测margin的排名，选择数据进行调整，以避免选择过度自信的数据。</li>
<li>results: 经过各种实验和分析， authors发现了两种方法可以有效地缓和过度自信的问题，并且这些方法可以轻松地应用。<details>
<summary>Abstract</summary>
It is not an exaggeration to say that the recent progress in artificial intelligence technology depends on large-scale and high-quality data. Simultaneously, a prevalent issue exists everywhere: the budget for data labeling is constrained. Active learning is a prominent approach for addressing this issue, where valuable data for labeling is selected through a model and utilized to iteratively adjust the model. However, due to the limited amount of data in each iteration, the model is vulnerable to bias; thus, it is more likely to yield overconfident predictions. In this paper, we present two novel methods to address the problem of overconfidence that arises in the active learning scenario. The first is an augmentation strategy named Cross-Mix-and-Mix (CMaM), which aims to calibrate the model by expanding the limited training distribution. The second is a selection strategy named Ranked Margin Sampling (RankedMS), which prevents choosing data that leads to overly confident predictions. Through various experiments and analyses, we are able to demonstrate that our proposals facilitate efficient data selection by alleviating overconfidence, even though they are readily applicable.
</details>
<details>
<summary>摘要</summary>
不是订正说，现代人工智能技术的进步几乎完全取决于大规模高质量数据。然而，一个普遍存在的问题是 everywhere：数据标注预算受限。活动学习是一种主要的方法来解决这个问题，其中通过模型选择有价值的数据进行标注，并使用这些数据来逐次调整模型。然而，由于每次迭代中的数据量有限，模型容易受到偏见，因此更可能产生过optimistic预测。在这篇论文中，我们提出了两种解决活动学习场景中出现的过optimistic问题的方法。首先是一种扩展训练分布的扩展策略名为 Cross-Mix-and-Mix (CMaM)，其目的是使模型更加准确。其次是一种名为 Ranked Margin Sampling (RankedMS)的选择策略，它避免选择导致过optimistic预测的数据。通过多种实验和分析，我们能够证明我们的建议可以有效地选择数据，减少过optimistic预测，即使它们可以应用。
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Riemannian-Conjugate-Gradient-Method-on-the-Stiefel-Manifold"><a href="#Decentralized-Riemannian-Conjugate-Gradient-Method-on-the-Stiefel-Manifold" class="headerlink" title="Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"></a>Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10547">http://arxiv.org/abs/2308.10547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Chen, Haishan Ye, Mengmeng Wang, Tianxin Huang, Guang Dai, Ivor W. Tsang, Yong Liu</li>
<li>for: 这个论文 targets at solving optimization problems on the Stiefel manifold, a non-convex set, using a decentralized Riemannian conjugate gradient descent (DRCGD) method.</li>
<li>methods: 该方法使用了一种分布式的agent网络，每个agent负责一个本地函数，并且通过无向连接图进行交互。DRCGD方法不需要进行Expensive的里曼几何运算，从而减少了每个agent的计算复杂性。</li>
<li>results: 该论文提出了一种首次在分布式里曼空间中实现全球收敛的DRCGD方法，并且证明了该方法的 globally convergence。<details>
<summary>Abstract</summary>
The conjugate gradient method is a crucial first-order optimization method that generally converges faster than the steepest descent method, and its computational cost is much lower than the second-order methods. However, while various types of conjugate gradient methods have been studied in Euclidean spaces and on Riemannian manifolds, there has little study for those in distributed scenarios. This paper proposes a decentralized Riemannian conjugate gradient descent (DRCGD) method that aims at minimizing a global function over the Stiefel manifold. The optimization problem is distributed among a network of agents, where each agent is associated with a local function, and communication between agents occurs over an undirected connected graph. Since the Stiefel manifold is a non-convex set, a global function is represented as a finite sum of possibly non-convex (but smooth) local functions. The proposed method is free from expensive Riemannian geometric operations such as retractions, exponential maps, and vector transports, thereby reducing the computational complexity required by each agent. To the best of our knowledge, DRCGD is the first decentralized Riemannian conjugate gradient algorithm to achieve global convergence over the Stiefel manifold.
</details>
<details>
<summary>摘要</summary>
“ conjugate gradient 方法是一种重要的首尔顺化方法，通常比坡度下降法快速 converges，且计算成本较低于第二项方法。然而，在分布式场景中，各种 conjugate gradient 方法已经在欧几何空间和里曼尼投影上进行了许多研究，但对于分布式场景的研究却有很少。这篇论文提出了一种分布式里曼尼 conjugate gradient descent（DRCGD）方法，旨在全局函数的最小化，这个函数是在Stiefel manifold上的一个全部函数。实际上，这个问题是分布式在一个无向网络中的一个问题，每个代理人都有一个本地函数，并且在各个代理人之间进行了无向网络上的通信。由于Stiefel manifold是一个非凸集，因此全球函数是一个可能非凸（但是光滑的）的全部函数。提案的方法不需要 expensive Riemannian geometric operations，例如投影、对映图和向量运输，因此每个代理人的计算复杂度很低。到目前为止，DRCGD 是首个在 Stiefel manifold 上实现全球均衡的分布式里曼尼 conjugate gradient 算法。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Accelerated-Model-Training-via-Bayesian-Data-Selection"><a href="#Towards-Accelerated-Model-Training-via-Bayesian-Data-Selection" class="headerlink" title="Towards Accelerated Model Training via Bayesian Data Selection"></a>Towards Accelerated Model Training via Bayesian Data Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10544">http://arxiv.org/abs/2308.10544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhijie Deng, Peng Cui, Jun Zhu</li>
<li>for: This paper is written to address the problem of mislabeled, duplicated, or biased data in real-world scenarios, which can hinder model convergence and prolong training.</li>
<li>methods: The paper proposes a more reasonable data selection principle by examining the data’s impact on the model’s generalization loss, and incorporates off-the-shelf zero-shot predictors built on large-scale pre-trained models.</li>
<li>results: The paper performs extensive empirical studies on challenging benchmarks with considerable data noise and imbalance in the online batch selection scenario, and observes superior training efficiency over competitive baselines. Specifically, the method achieves similar predictive performance with significantly fewer training iterations than leading data selection methods on the challenging WebVision benchmark.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解决现实世界中的杂乱数据问题，包括杂乱标签、重复数据和偏见数据，这些问题会延长模型训练和抑制模型的准确性。</li>
<li>methods: 论文提出了一种更加合理的数据选择原则，即通过考虑数据对模型通用损失的影响来选择数据。此外，它还 incorporates off-the-shelf zero-shot predictors built on large-scale pre-trained models。</li>
<li>results: 论文在实际中进行了严格的实验研究，包括在具有较大数据噪和数据不均衡的online批处理场景中进行了训练效率的比较。研究结果显示，该方法在比较难的WebVision数据集上可以在相对较少的训练迭代数下达到类似的预测性能，与主流数据选择方法相比。<details>
<summary>Abstract</summary>
Mislabeled, duplicated, or biased data in real-world scenarios can lead to prolonged training and even hinder model convergence. Traditional solutions prioritizing easy or hard samples lack the flexibility to handle such a variety simultaneously. Recent work has proposed a more reasonable data selection principle by examining the data's impact on the model's generalization loss. However, its practical adoption relies on less principled approximations and additional clean holdout data. This work solves these problems by leveraging a lightweight Bayesian treatment and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. The resulting algorithm is efficient and easy-to-implement. We perform extensive empirical studies on challenging benchmarks with considerable data noise and imbalance in the online batch selection scenario, and observe superior training efficiency over competitive baselines. Notably, on the challenging WebVision benchmark, our method can achieve similar predictive performance with significantly fewer training iterations than leading data selection methods.
</details>
<details>
<summary>摘要</summary>
错分、重复或偏袋数据在实际场景中可能导致模型训练延长，甚至阻碍模型平衡。传统解决方案会优先级化易于或困难的样本，缺乏适应性来处理多种样本同时。现有研究提出了一种更合理的数据选择原则，通过评估模型通用损失来评估数据的影响。然而，其实践几乎依赖于不原则的近似和额外的干净保留数据。这种方法解决了这些问题，通过利用轻量级权重抽象和大规模预训练模型建立的零shot预测器。该算法是高效和易于实现。我们在具有较大数据噪音和不均衡的在线批处理场景中进行了广泛的实验研究，并观察到了与竞争对手基eline的高效训练性能。尤其是在WebVision标准园 benchmark上，我们的方法可以在与其他数据选择方法相比较同等预测性能的情况下，通过significantly fewer training iterations获得更高的训练效率。
</details></li>
</ul>
<hr>
<h2 id="Learning-Weakly-Convex-Regularizers-for-Convergent-Image-Reconstruction-Algorithms"><a href="#Learning-Weakly-Convex-Regularizers-for-Convergent-Image-Reconstruction-Algorithms" class="headerlink" title="Learning Weakly Convex Regularizers for Convergent Image-Reconstruction Algorithms"></a>Learning Weakly Convex Regularizers for Convergent Image-Reconstruction Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10542">http://arxiv.org/abs/2308.10542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexis Goujon, Sebastian Neumayer, Michael Unser</li>
<li>for: 本研究旨在学习非凸正则化方法，并将其的弱凸性模块规定为上限。这些正则化方法可以用来实现变分降噪器，并且具有少量参数（ fewer than 15,000）和可解释性。</li>
<li>methods: 本研究使用了数字实验来证明这些变分降噪器可以超越凸正则化方法和BM3D降噪器的性能。此外，学习的正则化方法还可以用于解决反射问题，并且可以提供可靠的分布式迭代方法。</li>
<li>results: 数据驱动的实验结果表明，使用学习的非凸正则化方法可以在CT和MRI重建中提供优秀的平衡点，并且在性能、参数数量、保证和可解释性等方面表现出色，在比较其他数据驱动方法时表现更好。<details>
<summary>Abstract</summary>
We propose to learn non-convex regularizers with a prescribed upper bound on their weak-convexity modulus. Such regularizers give rise to variational denoisers that minimize a convex energy. They rely on few parameters (less than 15,000) and offer a signal-processing interpretation as they mimic handcrafted sparsity-promoting regularizers. Through numerical experiments, we show that such denoisers outperform convex-regularization methods as well as the popular BM3D denoiser. Additionally, the learned regularizer can be deployed to solve inverse problems with iterative schemes that provably converge. For both CT and MRI reconstruction, the regularizer generalizes well and offers an excellent tradeoff between performance, number of parameters, guarantees, and interpretability when compared to other data-driven approaches.
</details>
<details>
<summary>摘要</summary>
我们提议使用具有固定上界的弱矩形变数的非凸调教器。这些调教器将实现一个内部平面上的内附式数据过滤，并且具有少于15,000个参数。它们可以视为手工设计的稀疏化调教器，并且通过数据实验显示，这些调教器可以超过对称调教器和BM3D调教器的性能。此外，学习的调教器可以用迭代方案来解决反射问题，并且可以提供可靠的收敛保证。在CT和MRI重建中，调教器具有良好的泛化性和优秀的贡献比例、保证和可读性，在与其他数据驱动方法比较之下表现出色。
</details></li>
</ul>
<hr>
<h2 id="KGrEaT-A-Framework-to-Evaluate-Knowledge-Graphs-via-Downstream-Tasks"><a href="#KGrEaT-A-Framework-to-Evaluate-Knowledge-Graphs-via-Downstream-Tasks" class="headerlink" title="KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks"></a>KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10537">http://arxiv.org/abs/2308.10537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Heist, Sven Hertling, Heiko Paulheim</li>
<li>for: 这种研究旨在创建、扩展或完善知识图，以便创建更大、更正确或更多样化的知识图。</li>
<li>methods: 这些研究通常使用创建或扩展知识图的方法，而不是评估下游任务的性能。</li>
<li>results: KGrEaT 框架可以评估知识图的质量，并对不同的知识图进行比较，以确定它们在实际任务上的表现。<details>
<summary>Abstract</summary>
In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.
</details>
<details>
<summary>摘要</summary>
To better evaluate the performance of knowledge graphs on actual tasks, we propose KGrEaT, a framework for estimating the quality of knowledge graphs through actual downstream tasks such as classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs for a single task, KGrEaT compares various knowledge graphs by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is designed to be easily extendable with additional tasks and datasets.
</details></li>
</ul>
<hr>
<h2 id="DPAN-Dynamic-Preference-based-and-Attribute-aware-Network-for-Relevant-Recommendations"><a href="#DPAN-Dynamic-Preference-based-and-Attribute-aware-Network-for-Relevant-Recommendations" class="headerlink" title="DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations"></a>DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10527">http://arxiv.org/abs/2308.10527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Dai, Yingmin Su, Xiaofeng Pan</li>
<li>for: 提高电商平台的相关推荐的Click-Through Rate (CTR)</li>
<li>methods: 提出了一种名为动态偏好和特征意识网络（DPAN）的新方法，通过Attribute-aware Activation Values Generation (AAVG)、Bi-dimensional Compression-based Re-expression (BCR)和Shallow and Deep Union-based Fusion (SDUF)等技术来学习用户的动态偏好和物品信息的细致表示，并Capture users’ dynamic preferences for the diverse degree of recommendation results according to various conditions。</li>
<li>results: 经过大量的Offline experiment和Online A&#x2F;B testing，DPAN已经 demonstrably improved CTR by 7.62%。现在DPAN已经成功部署到了我们的电商平台，并为主要交通的相关推荐提供服务。代码已经公开发布。<details>
<summary>Abstract</summary>
In e-commerce platforms, the relevant recommendation is a unique scenario providing related items for a trigger item that users are interested in. However, users' preferences for the similarity and diversity of recommendation results are dynamic and vary under different conditions. Moreover, individual item-level diversity is too coarse-grained since all recommended items are related to the trigger item. Thus, the two main challenges are to learn fine-grained representations of similarity and diversity and capture users' dynamic preferences for them under different conditions. To address these challenges, we propose a novel method called the Dynamic Preference-based and Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in relevant recommendations. Specifically, based on Attribute-aware Activation Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR) is designed to obtain similarity and diversity representations of user interests and item information. Then Shallow and Deep Union-based Fusion (SDUF) is proposed to capture users' dynamic preferences for the diverse degree of recommendation results according to various conditions. DPAN has demonstrated its effectiveness through extensive offline experiments and online A/B testing, resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been successfully deployed on our e-commerce platform serving the primary traffic for relevant recommendations. The code of DPAN has been made publicly available.
</details>
<details>
<summary>摘要</summary>
在电商平台上，相关推荐的情况是一种特殊的enario，提供用户感兴趣的相关物品的相关物品。然而，用户对相似性和多样性的偏好是动态的，并在不同情况下发生变化。此外，单个物品级别的多样性是太粗糙，所有推荐的物品都与触发项目有关。因此，两大挑战是学习细化的相似性和多样性表示，以及在不同情况下捕捉用户的动态偏好。为解决这些挑战，我们提出了一种新的方法 called Dynamic Preference-based and Attribute-aware Network (DPAN)，用于预测相关推荐的Click-Through Rate (CTR)。具体来说，基于Attribute-aware Activation Values Generation (AAVG)，我们设计了Bi-dimensional Compression-based Re-expression (BCR)，以获取用户兴趣的相似性和多样性表示。然后，我们提出了Shallow and Deep Union-based Fusion (SDUF)，以捕捉用户在不同情况下对多样度推荐结果的动态偏好。DPAN在广泛的Offline实验和Online A/B测试中表现出色，对相关推荐的Click-Through Rate (CTR)进行了7.62%的提升。现在，DPAN已经成功地部署在我们的电商平台上，负责主要的相关推荐任务。我们已经公开发布DPAN的代码。
</details></li>
</ul>
<hr>
<h2 id="Information-Theory-Guided-Heuristic-Progressive-Multi-View-Coding"><a href="#Information-Theory-Guided-Heuristic-Progressive-Multi-View-Coding" class="headerlink" title="Information Theory-Guided Heuristic Progressive Multi-View Coding"></a>Information Theory-Guided Heuristic Progressive Multi-View Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10522">http://arxiv.org/abs/2308.10522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangmeng Li, Hang Gao, Wenwen Qiang, Changwen Zheng</li>
<li>for: 本研究旨在提出一种基于信息理论的多视图学习方法，以捕捉多个视图共享的全面信息。</li>
<li>methods: 该方法基于对各视图之间的对比学习，并采用三级进行可加进程设计：分布层、集合层和实例层。在分布层中，IPMC方法对各视图的分布进行协调，以减少视图特定的噪声。在集合层中，IPMC方法建立自适应对比池，并通过视图筛选器进行适应修改。在实例层中，我们采用设计的统一损失函数来学习表示和减少梯度干扰。</li>
<li>results: 理论和实验研究表明，IPMC方法在比较 estado-of-the-art 方法时具有superiority。<details>
<summary>Abstract</summary>
Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided hierarchical Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier, we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>View-specific noise is not filtered in learning view-shared representations.2. The fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated.3. Evenly measuring the similarities between terms might interfere with optimization.To address these limitations, we propose a novel information theoretical framework for generalized multi-view learning. Guided by this framework, we develop a multi-view coding method with a three-tier progressive architecture, called Information theory-guided hierarchical Progressive Multi-view Coding (IPMC).The IPMC method consists of three tiers:1. Distribution-tier: IPMC aligns the distribution between views to reduce view-specific noise.2. Set-tier: IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter.3. Instance-tier: We adopt a designed unified loss to learn representations and reduce the gradient interference.Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.</details></li>
</ol>
<hr>
<h2 id="Performance-Enhancement-Leveraging-Mask-RCNN-on-Bengali-Document-Layout-Analysis"><a href="#Performance-Enhancement-Leveraging-Mask-RCNN-on-Bengali-Document-Layout-Analysis" class="headerlink" title="Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis"></a>Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10511">http://arxiv.org/abs/2308.10511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shrestha Datta, Md Adith Mollah, Raisa Fairooz, Tariful Islam Fahim</li>
<li>for: 这个论文的目的是提高机器理解报告文档，尤其是历史报告文档。</li>
<li>methods: 这个论文使用了文档格式分析（Document Layout Analysis，DLA）技术，将报告文档分解成不同的部分，如段落、图片和表格。此外，它还使用了一种特殊的模型 called Mask R-CNN 来帮助机器理解这些文档。</li>
<li>results: 这个论文在DL Sprint 2.0比赛中达到了一个好的 dice 分数（0.889），但并不是所有情况都是如此。它发现使用英文文档的模型并不适用于孟加拉文档，这说明了每种语言都有其独特的挑战。<details>
<summary>Abstract</summary>
Understanding digital documents is like solving a puzzle, especially historical ones. Document Layout Analysis (DLA) helps with this puzzle by dividing documents into sections like paragraphs, images, and tables. This is crucial for machines to read and understand these documents. In the DL Sprint 2.0 competition, we worked on understanding Bangla documents. We used a dataset called BaDLAD with lots of examples. We trained a special model called Mask R-CNN to help with this understanding. We made this model better by step-by-step hyperparameter tuning, and we achieved a good dice score of 0.889. However, not everything went perfectly. We tried using a model trained for English documents, but it didn't fit well with Bangla. This showed us that each language has its own challenges. Our solution for the DL Sprint 2.0 is publicly available at https://www.kaggle.com/competitions/dlsprint2/discussion/432201 along with notebooks, weights, and inference notebook.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Clustering-Algorithm-to-Organize-Satellite-Hotspot-Data-for-the-Purpose-of-Tracking-Bushfires-Remotely"><a href="#A-Clustering-Algorithm-to-Organize-Satellite-Hotspot-Data-for-the-Purpose-of-Tracking-Bushfires-Remotely" class="headerlink" title="A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely"></a>A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10505">http://arxiv.org/abs/2308.10505</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tengmcing/hotspots-clustering-algorithm">https://github.com/tengmcing/hotspots-clustering-algorithm</a></li>
<li>paper_authors: Weihao Li, Emily Dodwell, Dianne Cook</li>
<li>for: 这篇论文旨在提出一种空间时间划分算法和其在R包spotoroo中的实现，以应对澳大利亚2019-2020年夏季的恶劣森林大火。</li>
<li>methods: 该算法受两种现有的空间时间划分算法的影响，并在每个时间间隔期间将点云 spatially划分，同时考虑点云的运动。它还允许根据不同的地点和卫星数据源进行参数调整。</li>
<li>results: 使用澳大利亚维多利亚省的 bushfire 数据示例，该算法可以准确划分空间时间点云，并且可以根据不同的参数进行调整。<details>
<summary>Abstract</summary>
This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Adaptive-Thresholding-Heuristic-for-KPI-Anomaly-Detection"><a href="#Adaptive-Thresholding-Heuristic-for-KPI-Anomaly-Detection" class="headerlink" title="Adaptive Thresholding Heuristic for KPI Anomaly Detection"></a>Adaptive Thresholding Heuristic for KPI Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10504">http://arxiv.org/abs/2308.10504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ebenezer R. H. P. Isaac, Akshat Sharma</li>
<li>For: The paper is written for the purpose of proposing an Adaptive Thresholding Heuristic (ATH) for anomaly detection in time series Key Performance Indicators (KPIs).* Methods: The paper uses a combination of seasonality decomposition and outlier detection techniques to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns.* Results: The paper validates the effectiveness of ATH using experimental results on a labeled KPI anomaly dataset produced by Ericsson, showing that ATH is computationally efficient and flexible with multiple forecasters and outlier detectors.Here’s the simplified Chinese version of the three key points:* For: 这篇论文是为了提出一种适应阈值规则（ATH），用于时间序列指标预测异常检测。* Methods: 论文使用了时间序列分解和异常检测技术，以适应数据分布的本地特性和时间序列模式的变化，动态调整检测阈值。* Results: 论文使用实验结果 validate ATH 的有效性，并表明它可以扩展到多个预测器和异常检测技术，并且可以实现实时异常检测。<details>
<summary>Abstract</summary>
A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying seasonality decomposition method and an outlier detector that yields an outlier score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly dataset produced by Ericsson, to validate our hypothesis. Experimental results show that ATH is computationally efficient making it scalable for near real time anomaly detection and flexible with multiple forecasters and outlier detectors.
</details>
<details>
<summary>摘要</summary>
“有许多异常检测器在时间序列领域被探索，但在业务上，不 все异常都是产生关注的异常。现有的异常检测解决方案受到一定的限制，因此无法应用于更广泛的异常检测用例。网络 KPI（关键性能指标）通常会表现出统计学异常，大多数这些异常不会影响业务运行。因此，需要一个决策规则来捕捉业务定义的异常。这篇文章提出了一种适应阈值调整规则（ATH），可以基于数据分布的本地特性和时间序列模式来动态调整检测阈值，以避免假阳性和概念退化。ATH可以与任何基础seasonality分解方法和异常检测器结合使用，并且可以在实时异常检测中进行批处理。我们在Ericsson提供的EON1-Cell-U标注异常数据集上进行了试验，实验结果表明，ATH具有计算效率和灵活性，可以在实时异常检测中执行。”
</details></li>
</ul>
<hr>
<h2 id="GradientCoin-A-Peer-to-Peer-Decentralized-Large-Language-Models"><a href="#GradientCoin-A-Peer-to-Peer-Decentralized-Large-Language-Models" class="headerlink" title="GradientCoin: A Peer-to-Peer Decentralized Large Language Models"></a>GradientCoin: A Peer-to-Peer Decentralized Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10502">http://arxiv.org/abs/2308.10502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeqi Gao, Zhao Song, Junze Yin</li>
<li>For: The paper proposes a decentralized large language model (LLM) that operates similarly to a Bitcoin cash system, but it is unlikely to perform better than the standard Bitcoin system in economics.* Methods: The paper uses a purely theoretical design of a decentralized LLM, but implementing such a system might encounter various practical difficulties.* Results: The paper suggests that only two types of people may be interested in setting up a practical system for the decentralized LLM: those who prefer to use a decentralized ChatGPT-like software, and those who believe that the purpose of carbon-based life is to create silicon-based life.<details>
<summary>Abstract</summary>
Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin has fundamentally changed the economic system over the last decade. Since 2022, large language models (LLMs) such as GPT have outperformed humans in many real-life tasks. However, these large language models have several practical issues. For example, the model is centralized and controlled by a specific unit. One weakness is that if that unit decides to shut down the model, it cannot be used anymore. The second weakness is the lack of guaranteed discrepancy behind this model, as certain dishonest units may design their own models and feed them unhealthy training data.   In this work, we propose a purely theoretical design of a decentralized LLM that operates similarly to a Bitcoin cash system. However, implementing such a system might encounter various practical difficulties. Furthermore, this new system is unlikely to perform better than the standard Bitcoin system in economics. Therefore, the motivation for designing such a system is limited. It is likely that only two types of people would be interested in setting up a practical system for it:   $\bullet$ Those who prefer to use a decentralized ChatGPT-like software.   $\bullet$ Those who believe that the purpose of carbon-based life is to create silicon-based life, such as Optimus Prime in Transformers.   The reason the second type of people may be interested is that it is possible that one day an AI system like this will awaken and become the next level of intelligence on this planet.
</details>
<details>
<summary>摘要</summary>
自2008年提出比特币电子币系统以来，比特币已经在过去的一个十年内对经济系统进行了深刻的改变。自2022年以来，大型自然语言模型（LLM）如GPT已经在许多实际任务上超越了人类。然而，这些大型语言模型存在多个实用问题。例如，模型是由特定单位控制和中央化的，如果这个单位停止使用模型，它就不能再使用了。第二个弱点是模型的 garantizado desviación缺失，因为恶意单位可能会设计自己的模型并Feed it unhealthy training data。在这种情况下，我们提出了一种理论上的减中心化LLM设计，其运作方式类似于比特币现金系统。然而，实施这种系统可能会遇到各种实际困难。此外，这新的系统不太可能超越标准比特币系统在经济方面的性能。因此，设计这种系统的动机相对有限。只有两种人可能会尝试实现这种系统：‧ Those who prefer to use a decentralized ChatGPT-like software.‧ Those who believe that the purpose of carbon-based life is to create silicon-based life, such as Optimus Prime in Transformers.这种第二种人可能有兴趣的原因是，可能有一天AI系统像这样会醒来，成为地球上下一个水平的智慧。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-of-Delay-Compensated-Backstepping-for-Reaction-Diffusion-PDEs"><a href="#Deep-Learning-of-Delay-Compensated-Backstepping-for-Reaction-Diffusion-PDEs" class="headerlink" title="Deep Learning of Delay-Compensated Backstepping for Reaction-Diffusion PDEs"></a>Deep Learning of Delay-Compensated Backstepping for Reaction-Diffusion PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10501">http://arxiv.org/abs/2308.10501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Wang, Mamadou Diagne, Miroslav Krstić</li>
<li>for: 这篇论文是用于描述深度神经网络（DeepONet）如何用于近似非线性函数-to-函数映射（operator）的研究。</li>
<li>methods: 该论文使用的方法包括深度神经网络（DeepONet）以及backstepping控制方法。</li>
<li>results: 该论文的研究结果表明，使用深度神经网络对多个非线性运算（cascade&#x2F;composition of operators）的近似可以实现稳定控制。<details>
<summary>Abstract</summary>
Deep neural networks that approximate nonlinear function-to-function mappings, i.e., operators, which are called DeepONet, have been demonstrated in recent articles to be capable of encoding entire PDE control methodologies, such as backstepping, so that, for each new functional coefficient of a PDE plant, the backstepping gains are obtained through a simple function evaluation. These initial results have been limited to single PDEs from a given class, approximating the solutions of only single-PDE operators for the gain kernels. In this paper we expand this framework to the approximation of multiple (cascaded) nonlinear operators. Multiple operators arise in the control of PDE systems from distinct PDE classes, such as the system in this paper: a reaction-diffusion plant, which is a parabolic PDE, with input delay, which is a hyperbolic PDE. The DeepONet-approximated nonlinear operator is a cascade/composition of the operators defined by one hyperbolic PDE of the Goursat form and one parabolic PDE on a rectangle, both of which are bilinear in their input functions and not explicitly solvable. For the delay-compensated PDE backstepping controller, which employs the learned control operator, namely, the approximated gain kernel, we guarantee exponential stability in the $L^2$ norm of the plant state and the $H^1$ norm of the input delay state. Simulations illustrate the contributed theory.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DeepONet），用于表示非线性函数-函数映射（operator），已经在 latest articles 中展示了能够编码整个PDE控制方法ologies，例如backstepping，以便为每个新的函数系数的PDE植物获得简单的函数评估。这些初始结果受限于单个PDE的扩展。在这篇文章中，我们将扩展这个框架，以便多个（堆叠）非线性运算的 aproximation。多个运算出现在PDE系统的控制中，例如在这篇文章中所描述的反应扩散植物，这是一个parabolic PDE，带有输入延迟，这是一个拥有Goursat形式的hyperbolic PDE。 DeepONet-approximated nonlinear operator是一个堆叠/组合的操作，其中一个hyperbolic PDE和一个parabolic PDE在一个矩形上都是 bilinear 的输入函数，并不能直接解决。为延迟补偿PDE backstepping控制器，我们提供了对learn control operator，即approximated gain kernel的 guarantee 的稳定性。我们 guarantee 在植物状态的 $L^2$  нор和输入延迟状态的 $H^1$  нор中的稳定性。实验证明了我们的理论。
</details></li>
</ul>
<hr>
<h2 id="Using-Autoencoders-and-AutoDiff-to-Reconstruct-Missing-Variables-in-a-Set-of-Time-Series"><a href="#Using-Autoencoders-and-AutoDiff-to-Reconstruct-Missing-Variables-in-a-Set-of-Time-Series" class="headerlink" title="Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series"></a>Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10496">http://arxiv.org/abs/2308.10496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan-Philipp Roche, Oliver Niggemann, Jens Friebe</li>
<li>for: 本研究旨在提供一种能够重构缺失变量的黑盒模型方法，以解决现有黑盒模型方法中的固定输入和输出特征组合限制。</li>
<li>methods: 本研究使用自适应神经网络模型（autoencoder），通过定义缺失变量并对其进行优化，实现不同的输入和输出特征组合。</li>
<li>results: 实验结果表明，当一个变量缺失时，使用本方法可以很好地重构缺失变量，而且可以处理多个缺失变量。<details>
<summary>Abstract</summary>
Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missing variables.
</details>
<details>
<summary>摘要</summary>
现有的黑盒模型方法在机器学习中受到固定输入和输出特征组合的限制。本文提出了一种新的方法来重建时间序列中缺失的变量。在这种方法中，首先训练一个自适应神经网络，然后定义搜索变量为神经网络输入中缺失的变量，通过自动微分优化。这种优化基于可用特征损失计算。通过这种方法，可以实现不同的输入和输出特征组合，而不需要再训练自适应神经网络。这种方法在一种强不连续电子元件上进行了评估，并且在一个变量缺失的情况下工作良好，甚至可以处理多个缺失变量。
</details></li>
</ul>
<hr>
<h2 id="Deciphering-Raw-Data-in-Neuro-Symbolic-Learning-with-Provable-Guarantees"><a href="#Deciphering-Raw-Data-in-Neuro-Symbolic-Learning-with-Provable-Guarantees" class="headerlink" title="Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees"></a>Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10487">http://arxiv.org/abs/2308.10487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lue Tao, Yu-Xuan Huang, Wang-Zhou Dai, Yuan Jiang</li>
<li>for: 这篇论文旨在探讨neuromorphic hybrid系统的学习可能性，以整合机器学习和符号逻辑的优点。</li>
<li>methods: 这篇论文使用了一种新的方法来描述知识库的指导信号，并提出了一个条件来评估知识库是否能够有效地帮助学习。</li>
<li>results: 这篇论文的实验结果显示，许多知识库满足了这个条件，因此能够有效地帮助学习，而其他知识库则无法满足这个条件，这表示可能会出现学习失败的情况。<details>
<summary>Abstract</summary>
Neuro-symbolic hybrid systems are promising for integrating machine learning and symbolic reasoning, where perception models are facilitated with information inferred from a symbolic knowledge base through logical reasoning. Despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Hence, it remains unclear why a hybrid system succeeds for a specific task and when it may fail given a different knowledge base. In this paper, we introduce a novel way of characterising supervision signals from a knowledge base, and establish a criterion for determining the knowledge's efficacy in facilitating successful learning. This, for the first time, allows us to address the two questions above by inspecting the knowledge base under investigation. Our analysis suggests that many knowledge bases satisfy the criterion, thus enabling effective learning, while some fail to satisfy it, indicating potential failures. Comprehensive experiments confirm the utility of our criterion on benchmark tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Metric-Loss-for-Multimodal-Learning"><a href="#Deep-Metric-Loss-for-Multimodal-Learning" class="headerlink" title="Deep Metric Loss for Multimodal Learning"></a>Deep Metric Loss for Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10486">http://arxiv.org/abs/2308.10486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sehwan Moon, Hyunju Lee</li>
<li>for:  This paper is written for researchers and practitioners in the field of multimodal learning, particularly those interested in developing more effective and efficient multimodal models.</li>
<li>methods:  The paper introduces a novel loss function called \text{MultiModal} loss, which subgroups instances according to their unimodal contributions. This loss function is designed to prevent inefficient learning caused by overfitting and to efficiently optimize multimodal models.</li>
<li>results:  The paper demonstrates improved classification performance on synthetic data and four real multimodal datasets using the proposed \text{MultiModal} loss. Ablation studies verify the effectiveness of the loss, and the paper shows that the loss generates a reliable prediction score for each modality, which is essential for subgrouping.<details>
<summary>Abstract</summary>
Multimodal learning often outperforms its unimodal counterparts by exploiting unimodal contributions and cross-modal interactions. However, focusing only on integrating multimodal features into a unified comprehensive representation overlooks the unimodal characteristics. In real data, the contributions of modalities can vary from instance to instance, and they often reinforce or conflict with each other. In this study, we introduce a novel \text{MultiModal} loss paradigm for multimodal learning, which subgroups instances according to their unimodal contributions. \text{MultiModal} loss can prevent inefficient learning caused by overfitting and efficiently optimize multimodal models. On synthetic data, \text{MultiModal} loss demonstrates improved classification performance by subgrouping difficult instances within certain modalities. On four real multimodal datasets, our loss is empirically shown to improve the performance of recent models. Ablation studies verify the effectiveness of our loss. Additionally, we show that our loss generates a reliable prediction score for each modality, which is essential for subgrouping. Our \text{MultiModal} loss is a novel loss function to subgroup instances according to the contribution of modalities in multimodal learning and is applicable to a variety of multimodal models with unimodal decisions. Our code is available at https://github.com/SehwanMoon/MultiModalLoss.
</details>
<details>
<summary>摘要</summary>
多模态学习通常超越单模态对手，因为它可以利用单模态贡献和跨模态交互。然而，只专注于将多模态特征集成到一个总体表示中，就会忽视单模态特征。在实际数据中，不同模态的贡献可能会从实例到实例不同，而且经常增强或冲突。在这项研究中，我们提出了一种新的多模态损失函数（MultiModal loss），可以将实例 subgrouped 根据它们的单模态贡献。MultiModal损失可以避免过拟合并有效地优化多模态模型。在 sintetic 数据上，我们证明了MultiModal损失可以提高分类性能，并在四个实际多模态数据集上证明了我们的损失。我们的损失函数可以 subgrouping 实例根据不同模态的贡献，并且可以应用于多种多模态模型。我们的代码可以在 <https://github.com/SehwanMoon/MultiModalLoss> 中找到。
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Method-using-Phrase-Mechanism-in-Neural-Machine-Translation"><a href="#An-Effective-Method-using-Phrase-Mechanism-in-Neural-Machine-Translation" class="headerlink" title="An Effective Method using Phrase Mechanism in Neural Machine Translation"></a>An Effective Method using Phrase Mechanism in Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10482">http://arxiv.org/abs/2308.10482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/phuongnm94/PhraseTransformer">https://github.com/phuongnm94/PhraseTransformer</a></li>
<li>paper_authors: Phuong Minh Nguyen, Le Minh Nguyen</li>
<li>for: 本研究的目的是提高基eline模型Transformer在构建并行文本翻译系统（NMT）中的性能。</li>
<li>methods: 本研究使用了一种句子机制，PhraseTransformer，来改进基eline模型Transformer。</li>
<li>results: 我们在VLSP 2022大赛的MT数据集上进行了实验，得到了 Vietnamese to Chinese 的 BLEU 分数为 35.3，以及 Chinese to Vietnamese 的 BLEU 分数为 33.2。<details>
<summary>Abstract</summary>
Machine Translation is one of the essential tasks in Natural Language Processing (NLP), which has massive applications in real life as well as contributing to other tasks in the NLP research community. Recently, Transformer -based methods have attracted numerous researchers in this domain and achieved state-of-the-art results in most of the pair languages. In this paper, we report an effective method using a phrase mechanism, PhraseTransformer, to improve the strong baseline model Transformer in constructing a Neural Machine Translation (NMT) system for parallel corpora Vietnamese-Chinese. Our experiments on the MT dataset of the VLSP 2022 competition achieved the BLEU score of 35.3 on Vietnamese to Chinese and 33.2 BLEU scores on Chinese to Vietnamese data. Our code is available at https://github.com/phuongnm94/PhraseTransformer.
</details>
<details>
<summary>摘要</summary>
机器翻译是自然语言处理（NLP）中的一项重要任务，它在实际生活中有很大的应用，同时也对其他NLP研究领域的任务产生了重要的贡献。近些年，基于Transformer算法的方法在这个领域中吸引了大量研究人员，并在大多数对应语言的情况下实现了状态的报表结果。在这篇论文中，我们报告了一种使用短语机制，PhraseTransformer，以改进基eline模型Transformer在建立并行 corpora Vietnamese-Chinese 的神经机器翻译（NMT）系统。我们在 VLSP 2022 比赛的MT数据集上进行了实验，实现了对越南语到中文的 BLEU 分数为 35.3，以及对中文到越南语的 BLEU 分数为 33.2。我们的代码可以在 GitHub 上找到：https://github.com/phuongnm94/PhraseTransformer。
</details></li>
</ul>
<hr>
<h2 id="Deep-Semi-supervised-Anomaly-Detection-with-Metapath-based-Context-Knowledge"><a href="#Deep-Semi-supervised-Anomaly-Detection-with-Metapath-based-Context-Knowledge" class="headerlink" title="Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge"></a>Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10918">http://arxiv.org/abs/2308.10918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hwan Kim, Junghoon Kim, Byung Suk Lee, Sungsu Lim</li>
<li>for: 本研究旨在提出一种基于metapath semi-supervised learning的图像异常检测方法，以解决现有方法的局限性。</li>
<li>methods: 本方法基于GCN层，在编码器和解码器中都使用GCN层，以高效地传播Context信息 между异常和正常节点。 métapath基于的上下文信息和特定的异常社区，可以增强学习结构和属性的差异， both globally and locally。</li>
<li>results: 通过对7个真实网络进行了全面的实验，本研究证明了MSAD方法在比 estado-of-the-art技术的比较优于。 这些成果铺垫了未来的研究，关注metapath模式的优化和分析，以进一步提高异常检测的效果在特征化网络上。<details>
<summary>Abstract</summary>
Graph anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of anomaly detection on attributed networks.
</details>
<details>
<summary>摘要</summary>
《图像异常检测在最近几年内吸引了广泛关注。本文介绍一种新的方法，即基于мета路 semi-supervised learning的图像异常检测方法（MSAD），解决前方法的局限性。我们提出了一新框架，包括GCN层在编码器和解码器中，以高效地传播图像异常和正常节点之间的上下文信息。基于ме타路上的上下文信息设计和特制的异常社区，可以增强学习结构和属性之间的差异， both globally and locally。经过对7个真实网络的广泛实验，本文证明MSAD方法比现有技术更高效。这些成果开创了未来的研究，关注于优化和分析méta路模式，以进一步提高图像异常检测的效iveness。》Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Parameter-Efficient-Fine-Tuning-Techniques-for-Code-Generation-with-Large-Language-Models"><a href="#Exploring-Parameter-Efficient-Fine-Tuning-Techniques-for-Code-Generation-with-Large-Language-Models" class="headerlink" title="Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models"></a>Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10462">http://arxiv.org/abs/2308.10462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, Houari Sahraoui</li>
<li>for: 这 paper 的目的是研究 Parameter-Efficient Fine-Tuning (PEFT) 技术在自动代码生成场景下的影响，以提高 Large Language Models (LLMs) 的表现和可扩展性。</li>
<li>methods: 这 paper 使用了多种 Parameter-Efficient Fine-Tuning (PEFT) 技术，包括 Weight-Decay Fine-Tuning (WDFT)、Adversarial Training (AT) 和 Multi-Task Learning (MTL)，以提高 LLMs 的表现和可扩展性。</li>
<li>results: 这 paper 的实验结果表明，使用 PEFT 技术可以有效地降低 LLMs 的计算成本和提高其表现，特别是在资源受限的情况下。 In-Context Learning (ICL) 方法在某种程度上受到了 PEFT 技术的替代，但 PEFT 技术可以在执行时间上具有更高的灵活性和可扩展性。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) possess impressive capabilities to generate meaningful code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. In the perspective of unleashing their full potential, prior work has demonstrated the benefits of fine-tuning the models to task-specific data. However, fine-tuning process demands heavy computational costs and is intractable when resources are scarce, especially for models with billions of parameters. In light of these challenges, previous studies explored In-Context Learning (ICL) as an effective strategy to generate contextually appropriate code without fine-tuning. However, it operates at inference time and does not involve learning task-specific parameters, potentially limiting the model's performance on downstream tasks. In this context, we foresee that Parameter-Efficient Fine-Tuning (PEFT) techniques carry a high potential for efficiently specializing LLMs to task-specific data. In this paper, we deliver a comprehensive study of LLMs with the impact of PEFT techniques under the automated code generation scenario. Our experimental results reveal the superiority and potential of such techniques over ICL on a wide range of LLMs in reducing the computational burden and improving performance. Therefore, the study opens opportunities for broader applications of PEFT in software engineering scenarios.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）具有吸引人的能力，可以生成 relevante 的代码几何 Natural Language Intent 的零shot 环境下，无需特定的精细调整。在探索这些模型的全面潜力方面，先前的研究显示了对任务特定数据的特定调整可以提供多项优点。然而，调整过程需要巨大的计算成本，尤其是当模型具有十亿个参数时，这使得调整成为不可能的。为了解决这个问题，先前的研究探访了内部学习（ICL）作为一种可能的策略，可以在没有调整的情况下生成适当的代码。然而，ICL 在推论时进行操作，不会学习任务特定的参数，这可能会限制模型在下游任务中的表现。在这个情况下，我们认为 Paramter-Efficient Fine-Tuning（PEFT）技术具有可能的高效特化能力。在这篇文章中，我们进行了 LLMS 的全面研究，以评估 PEFT 技术在自动代码生成 scenarios 中的影响。我们的实验结果显示，PEFT 技术可以对多种 LLMS 提供更高效的特化和改善表现。因此，这些研究开启了软件工程enario 中 PEFT 技术的更广泛应用的可能性。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Local-Steps-Federated-Learning-with-Differential-Privacy-Driven-by-Convergence-Analysis"><a href="#Adaptive-Local-Steps-Federated-Learning-with-Differential-Privacy-Driven-by-Convergence-Analysis" class="headerlink" title="Adaptive Local Steps Federated Learning with Differential Privacy Driven by Convergence Analysis"></a>Adaptive Local Steps Federated Learning with Differential Privacy Driven by Convergence Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10457">http://arxiv.org/abs/2308.10457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinpeng Ling, Jie Fu, Zhili Chen</li>
<li>for: 这个研究是为了研究在资源限制的情况下，如何实现隐私保护和联合学习。</li>
<li>methods: 这个研究使用了分散式机器学习技术和隐私保护技术，具体的是使用了差异攻击和隐私保护加密。</li>
<li>results: 这个研究的实验结果显示，在资源限制的情况下，使用ALS-DPFL算法可以实现隐私保护和联合学习，并且与之前的研究相比，其性能几乎相同。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning technique that allows model training among multiple devices or organizations without sharing data. However, while FL ensures that the raw data is not directly accessible to external adversaries, adversaries can still obtain some statistical information about the data through differential attacks. Differential Privacy (DP) has been proposed, which adds noise to the model or gradients to prevent adversaries from inferring private information from the transmitted parameters. We reconsider the framework of differential privacy federated learning in resource-constrained scenarios (privacy budget and communication resources). We analyze the convergence of federated learning with differential privacy (DPFL) on resource-constrained scenarios and propose an Adaptive Local Steps Differential Privacy Federated Learning (ALS-DPFL) algorithm. We experiment our algorithm on the FashionMNIST and Cifar-10 datasets and achieve quite good performance relative to previous work.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式机器学习技术，允许多个设备或组织共同训练模型，无需共享数据。然而，FL 确保外部敌对者无法直接访问原始数据，但敌对者可以通过差异攻击获取数据的一些统计信息。差异隐私 (DP) 被提出，它在传输参数或梯度中添加噪声，以防止敌对者从 Parameters 中推断私人信息。我们在有限的隐私预算和通信资源的情况下重新考虑了差异隐私联合学习 (DPFL) 框架。我们分析了在有限隐私预算和通信资源的情况下 DPFL 的整合和稳定性，并提出了适应性的本地步骤差异隐私联合学习 (ALS-DPFL) 算法。我们在 FashionMNIST 和 Cifar-10 数据集上实验了我们的算法，并与之前的工作相比获得了很好的性能。
</details></li>
</ul>
<hr>
<h2 id="DOMINO-Domain-aware-Loss-Regularization-for-Deep-Learning-Generalizability"><a href="#DOMINO-Domain-aware-Loss-Regularization-for-Deep-Learning-Generalizability" class="headerlink" title="DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability"></a>DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10453">http://arxiv.org/abs/2308.10453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skylar E. Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam J. Woods, Kevin Brink, Matthew Hale, Ruogu Fang</li>
<li>for: 这篇论文主要应用于提高深度学习（DL）模型在不同测试数据上的外部数据（OOD）纵贯性。</li>
<li>methods: 这篇论文提出了DOMINO++方法，它是一种两种引导和动态领域相关调整的损失调整方法，旨在提高DL模型的OOD纵贯性。</li>
<li>results: 实验结果显示，DOMINO++方法在不同类型的OOD数据上具有较高的纵贯性，并且比基eline模型和DOMINO方法更具有可靠性。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) generalization poses a serious challenge for modern deep learning (DL). OOD data consists of test data that is significantly different from the model's training data. DL models that perform well on in-domain test data could struggle on OOD data. Overcoming this discrepancy is essential to the reliable deployment of DL. Proper model calibration decreases the number of spurious connections that are made between model features and class outputs. Hence, calibrated DL can improve OOD generalization by only learning features that are truly indicative of the respective classes. Previous work proposed domain-aware model calibration (DOMINO) to improve DL calibration, but it lacks designs for model generalizability to OOD data. In this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss regularization focused on OOD generalizability. DOMINO++ integrates expert-guided and data-guided knowledge in its regularization. Unlike DOMINO which imposed a fixed scaling and regularization rate, DOMINO++ designs a dynamic scaling factor and an adaptive regularization rate. Comprehensive evaluations compare DOMINO++ with DOMINO and the baseline model for head tissue segmentation from magnetic resonance images (MRIs) on OOD data. The OOD data consists of synthetic noisy and rotated datasets, as well as real data using a different MRI scanner from a separate site. DOMINO++'s superior performance demonstrates its potential to improve the trustworthy deployment of DL on real clinical data.
</details>
<details>
<summary>摘要</summary>
现代深度学习（DL）面临了对外部数据（OOD）泛化的严重挑战。OOD数据包括测试数据，与DL模型训练数据异常不同。DL模型在域内测试数据上表现良好，但在OOD数据上可能表现不佳。解决这种差异是DL模型的可靠部署的关键。正确地调整DL模型可以减少模型中的偶极连接，从而提高OOD泛化。先前的工作提出了领域相关的模型准确（DOMINO）以提高DL准确性，但它缺乏关注OOD数据的设计。在这种工作中，我们提出了DOMINO++，一种双引导和动态领域相关损失规范，专注于OOD泛化。DOMINO++结合了专家指导和数据指导的知识在其规范中。与DOMINO不同，DOMINO++不同的是动态缩放因子和自适应规则率。我们对DOMINO++与DOMINO和基eline模型进行了广泛的评估，用于头部组织 segmentation from magnetic resonance imaging（MRI）数据上的OOD数据。OOD数据包括synthetic noisy和旋转数据集，以及实际数据使用不同的MRI扫描仪from separate site。DOMINO++的优秀表现表明它在实际临床数据上的可靠部署的潜力。
</details></li>
</ul>
<hr>
<h2 id="PACS-Prediction-and-analysis-of-cancer-subtypes-from-multi-omics-data-based-on-a-multi-head-attention-mechanism-model"><a href="#PACS-Prediction-and-analysis-of-cancer-subtypes-from-multi-omics-data-based-on-a-multi-head-attention-mechanism-model" class="headerlink" title="PACS: Prediction and analysis of cancer subtypes from multi-omics data based on a multi-head attention mechanism model"></a>PACS: Prediction and analysis of cancer subtypes from multi-omics data based on a multi-head attention mechanism model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10917">http://arxiv.org/abs/2308.10917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangrui Pan, Dazheng Liu, Zhichao Feng, Wenjuan Liu, Shaoliang Peng</li>
<li>for: 这个研究旨在精确分类不同抑衰癌种，帮助医生选择最适合的治疗选择，提高治疗结果，并提供更准确的病人存活预测。</li>
<li>methods: 本研究提出了一个监督式多头注意力机制模型（SMA），它可以成功地学习多种资料的全球和地方特征信息。其第二，通过深度融合多头注意力嵌入式的融合模块，扩大模型的参数。</li>
<li>results: 根据广泛的实验验证，SMA模型在实验、单细胞和癌多资料集中的准确分类率最高，比AE、CNN和GNN-based模型高。因此，我们对多资料分析中的注意力方法做出了贡献。<details>
<summary>Abstract</summary>
Due to the high heterogeneity and clinical characteristics of cancer, there are significant differences in multi-omic data and clinical characteristics among different cancer subtypes. Therefore, accurate classification of cancer subtypes can help doctors choose the most appropriate treatment options, improve treatment outcomes, and provide more accurate patient survival predictions. In this study, we propose a supervised multi-head attention mechanism model (SMA) to classify cancer subtypes successfully. The attention mechanism and feature sharing module of the SMA model can successfully learn the global and local feature information of multi-omics data. Second, it enriches the parameters of the model by deeply fusing multi-head attention encoders from Siamese through the fusion module. Validated by extensive experiments, the SMA model achieves the highest accuracy, F1 macroscopic, F1 weighted, and accurate classification of cancer subtypes in simulated, single-cell, and cancer multiomics datasets compared to AE, CNN, and GNN-based models. Therefore, we contribute to future research on multiomics data using our attention-based approach.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)由于肿瘤多样性和临床特征之间的高度不同，肿瘤分型中存在显著的差异。因此，正确地分类肿瘤分型可以帮助医生选择最适合的治疗方案，提高治疗效果，并为患者生存预测提供更加准确的信息。在本研究中，我们提出了一种supervised多头注意机制模型（SMA），用于成功地分类肿瘤分型。SMA模型的注意机制和特征共享模块可以成功地学习多Omics数据的全局和本地特征信息。其次，它通过深度融合多头注意Encoder从Siamese中深度融合多头注意Encoder来增强模型的参数。经验证ified by extensive experiments, SMA模型在simulated、单细群和肿瘤多Omics数据集中的准确率、F1宽泛、F1权重和肿瘤分型准确率上达到了AE、CNN和GNN-based模型的最高水平。因此，我们对多Omics数据进行未来研究的贡献。
</details></li>
</ul>
<hr>
<h2 id="CVFC-Attention-Based-Cross-View-Feature-Consistency-for-Weakly-Supervised-Semantic-Segmentation-of-Pathology-Images"><a href="#CVFC-Attention-Based-Cross-View-Feature-Consistency-for-Weakly-Supervised-Semantic-Segmentation-of-Pathology-Images" class="headerlink" title="CVFC: Attention-Based Cross-View Feature Consistency for Weakly Supervised Semantic Segmentation of Pathology Images"></a>CVFC: Attention-Based Cross-View Feature Consistency for Weakly Supervised Semantic Segmentation of Pathology Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10449">http://arxiv.org/abs/2308.10449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangrui Pan, Lian Wang, Zhichao Feng, Liwen Xu, Shaoliang Peng</li>
<li>for:  histopathology image segmentation for cancer diagnosis and prognosis</li>
<li>methods:  attention-based cross-view feature consistency end-to-end pseudo-mask generation framework (CVFC) using Resnet38 and Resnet50, with multi-scale integrated feature map and class activation map (CAM)</li>
<li>results:  outperformed HistoSegNet, SEAM, C-CAM, WSSS-Tissue, and OEEM on WSSS4LUAD dataset, with IoU of 0.7122 and fwIoU of 0.7018<details>
<summary>Abstract</summary>
Histopathology image segmentation is the gold standard for diagnosing cancer, and can indicate cancer prognosis. However, histopathology image segmentation requires high-quality masks, so many studies now use imagelevel labels to achieve pixel-level segmentation to reduce the need for fine-grained annotation. To solve this problem, we propose an attention-based cross-view feature consistency end-to-end pseudo-mask generation framework named CVFC based on the attention mechanism. Specifically, CVFC is a three-branch joint framework composed of two Resnet38 and one Resnet50, and the independent branch multi-scale integrated feature map to generate a class activation map (CAM); in each branch, through down-sampling and The expansion method adjusts the size of the CAM; the middle branch projects the feature matrix to the query and key feature spaces, and generates a feature space perception matrix through the connection layer and inner product to adjust and refine the CAM of each branch; finally, through the feature consistency loss and feature cross loss to optimize the parameters of CVFC in co-training mode. After a large number of experiments, An IoU of 0.7122 and a fwIoU of 0.7018 are obtained on the WSSS4LUAD dataset, which outperforms HistoSegNet, SEAM, C-CAM, WSSS-Tissue, and OEEM, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DySuse-Susceptibility-Estimation-in-Dynamic-Social-Networks"><a href="#DySuse-Susceptibility-Estimation-in-Dynamic-Social-Networks" class="headerlink" title="DySuse: Susceptibility Estimation in Dynamic Social Networks"></a>DySuse: Susceptibility Estimation in Dynamic Social Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10442">http://arxiv.org/abs/2308.10442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingdan Shi, Jingya Zhou, Congcong Zhang</li>
<li>for: 预测社交网络中 influencer 的总影响范围，并且更具吸引力和实用价值的是预测每个用户是否被影响。</li>
<li>methods: 基于动态网络特性和启发性的 embeddings 技术，提出了一种名为 DySuse 的框架，包括结构特征模块、进步机制和自注意力块。</li>
<li>results: 对多种影响扩散模型进行了实验，得到了比现有动态图像模型更高的预测性能。<details>
<summary>Abstract</summary>
Influence estimation aims to predict the total influence spread in social networks and has received surged attention in recent years. Most current studies focus on estimating the total number of influenced users in a social network, and neglect susceptibility estimation that aims to predict the probability of each user being influenced from the individual perspective. As a more fine-grained estimation task, susceptibility estimation is full of attractiveness and practical value. Based on the significance of susceptibility estimation and dynamic properties of social networks, we propose a task, called susceptibility estimation in dynamic social networks, which is even more realistic and valuable in real-world applications. Susceptibility estimation in dynamic networks has yet to be explored so far and is computationally intractable to naively adopt Monte Carlo simulation to obtain the results. To this end, we propose a novel end-to-end framework DySuse based on dynamic graph embedding technology. Specifically, we leverage a structural feature module to independently capture the structural information of influence diffusion on each single graph snapshot. Besides, {we propose the progressive mechanism according to the property of influence diffusion,} to couple the structural and temporal information during diffusion tightly. Moreover, a self-attention block {is designed to} further capture temporal dependency by flexibly weighting historical timestamps. Experimental results show that our framework is superior to the existing dynamic graph embedding models and has satisfactory prediction performance in multiple influence diffusion models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译成简化中文。<</SYS>>社交网络的影响估计目标是预测社交网络中总的影响扩散，在最近几年内受到了广泛关注。大多数当前的研究都是专注于预测社交网络中总的感染用户数量，而忽略了各个用户的感染可能性，即每个用户是否会被感染。作为一个更细化的估计任务，感染可能性估计具有吸引力和实际价值。基于社交网络的动态性和感染的特性，我们提出了一项任务，即动态社交网络中的感染可能性估计，这项任务在实际应用中更加真实和有价值。动态网络中的感染可能性估计还未被探索，而且直接使用 Monte Carlo  simulations 来获取结果是计算上不可能的。为此，我们提出了一个新的框架，即 DySuse，基于动态图像技术。具体来说，我们利用一个结构特征模块来独立地捕捉影响扩散在每个单Graph快照中的结构信息。此外，我们还提出了一种进程机制，根据感染的特性，将结构和时间信息紧密地连接起来。此外，我们还设计了一个自注意机制，以捕捉 diffusion 过程中的时间相关性，并通过灵活地赋予历史时间权重来进行权重补做。实验结果表明，我们的框架在多种感染模型下具有优于现有的动态图像嵌入模型，并且在多种实际应用中具有满意的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Approximately-Equivariant-Graph-Networks"><a href="#Approximately-Equivariant-Graph-Networks" class="headerlink" title="Approximately Equivariant Graph Networks"></a>Approximately Equivariant Graph Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10436">http://arxiv.org/abs/2308.10436</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhuang37/approx_equivariant_graph_nets">https://github.com/nhuang37/approx_equivariant_graph_nets</a></li>
<li>paper_authors: Ningyuan Huang, Ron Levie, Soledad Villar</li>
<li>for: 这种研究是为了解决图像填充、交通流量预测和人体姿态估计等问题，通过选择合适的同质群来提高模型的泛化性和稳定性。</li>
<li>methods: 这篇论文使用了图 neural network (GNN) 和自Symmetry group 来解决这些问题，并提出了一种基于同质群的权重补做法来提高模型的泛化性。</li>
<li>results: 实验结果表明，通过选择合适的同质群可以提高模型的泛化性和稳定性，并且可以在不同的问题上达到最佳的泛化性和精度。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that quantifies the tradeoff between the loss in expressivity and the gain in the regularity of the learned estimator, depending on the chosen symmetry group. To illustrate our approach, we conduct extensive experiments on image inpainting, traffic flow prediction, and human pose estimation with different choices of symmetries. We show theoretically and empirically that the best generalization performance can be achieved by choosing a suitably larger group than the graph automorphism group, but smaller than the full permutation group.
</details>
<details>
<summary>摘要</summary>
Graph neural networks (GNNs) 通常被描述为对节点重新分配 permutation 对称的。这种 GNNs 的对称性和图像抽象卷积神经网络 (CNNs) 中的翻译对称性有所不同：图像抽象卷积的对称性对应于图像信号中的活动对称性 (sometimes known as active symmetries),而 GNNs 中任意 permutation 都会影响图像信号和图像domain (sometimes described as passive symmetries)。在这个工作中，我们关注 GNNs 中的活动对称性，通过考虑固定图像上支持的信号来进行学习设定。在这种情况下，GNNs 的自然对称性是图像的自动omorphism。由于实际图像往往偏 asymmetric，我们放宽了对称性的定义，通过图像缩放来形式化 Approximate symmetries。我们提出了一个 bias-variance 公式，它量化了在选择的对称群时，损失表达能力和学习器的规范性之间的交易。为了证明我们的方法，我们在图像填充、交通流量预测和人体姿态估计中进行了广泛的实验，并证明了在不同的对称群选择情况下，可以达到最佳的总体化性能。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Robust-to-Byzantine-Attacks-Achieving-Zero-Optimality-Gap"><a href="#Federated-Learning-Robust-to-Byzantine-Attacks-Achieving-Zero-Optimality-Gap" class="headerlink" title="Federated Learning Robust to Byzantine Attacks: Achieving Zero Optimality Gap"></a>Federated Learning Robust to Byzantine Attacks: Achieving Zero Optimality Gap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10427">http://arxiv.org/abs/2308.10427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyuan Zuo, Rongfei Fan, Han Hu, Ning Zhang, Shimin Gong</li>
<li>for: 这个研究旨在提出一种适应 federated learning (FL) 中抗衡邪恶拜仁攻击的强健聚合方法，能够有效地解决这种攻击。</li>
<li>methods: 在每个用户端，首先更新模型参数通过多个步骤，这些步骤可调整到迭代过程中，然后直接将更新后的模型参数发送到聚合中心。这减少了聚合中心和用户端之间的互动次数，让每个用户可以自主设定训练parameter，并减少了与已有的方法相比的计算负担。在聚合中心，使用几何 médian 合并接收到的各个用户的模型参数。</li>
<li>results: 这个方法可以在邪恶攻击者占 Fraction 不超过半的情况下，实现零优化差和线性参数。 numéríques résultats 显示了这个方法的有效性。<details>
<summary>Abstract</summary>
In this paper, we propose a robust aggregation method for federated learning (FL) that can effectively tackle malicious Byzantine attacks. At each user, model parameter is firstly updated by multiple steps, which is adjustable over iterations, and then pushed to the aggregation center directly. This decreases the number of interactions between the aggregation center and users, allows each user to set training parameter in a flexible way, and reduces computation burden compared with existing works that need to combine multiple historical model parameters. At the aggregation center, geometric median is leveraged to combine the received model parameters from each user. Rigorous proof shows that zero optimality gap is achieved by our proposed method with linear convergence, as long as the fraction of Byzantine attackers is below half. Numerical results verify the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种鲁棒的聚合方法 для联邦学习（FL），可以有效地对恶意的比宗安攻击进行防御。每个用户的模型参数首先通过多个步骤进行更新，可以在迭代中调整，然后直接将更新后的参数发送到聚合中心。这会减少聚合中心和用户之间的交互次数，让每个用户可以自由地设置训练参数，并且相比现有的方法，减少计算卷积的负担。在聚合中心，使用几何中心来合并来自每个用户的接收到的模型参数。严格的证明显示，我们的提议的方法可以在拥有比宗安攻击者少于半数的情况下，实现零优化差和线性快速收敛。numerical Results表明我们的提议的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Adaptive-Embedding-Makes-Vanilla-Transformer-SOTA-for-Traffic-Forecasting"><a href="#Spatio-Temporal-Adaptive-Embedding-Makes-Vanilla-Transformer-SOTA-for-Traffic-Forecasting" class="headerlink" title="Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting"></a>Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10425">http://arxiv.org/abs/2308.10425</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xdzhelheim/staeformer">https://github.com/xdzhelheim/staeformer</a></li>
<li>paper_authors: Hangchen Liu, Zheng Dong, Renhe Jiang, Jiewen Deng, Jinliang Deng, Quanjun Chen, Xuan Song</li>
<li>for: 预测交通流量，即使在复杂的交通环境下。</li>
<li>methods: 使用vanilla transformer和spatio-temporal adaptive embedding技术。</li>
<li>results: 在五个真实的交通预测数据集上达到了状态之最的表现。<details>
<summary>Abstract</summary>
With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.
</details>
<details>
<summary>摘要</summary>
随着智能交通系统（ITS）的快速发展，准确的交通预测已成为一项关键挑战。关键瓶颈在于捕捉复杂的空间-时间交通模式。在过去几年，许多基于神经网络的复杂架构的方法已经被提出来解决这个问题。然而，网络架构的提高带来的性能提升减少。在本研究中，我们提出了一种新的组件 called spatio-temporal adaptive embedding（STAEformer），它可以在vanilla transformers中实现出色的效果。我们的提posed Spatio-Temporal Adaptive Embedding transformer（STAEformer）在五个真实世界交通预测数据集上实现了状态的最佳性能。进一步的实验表明，spatio-temporal adaptive embedding在交通预测中扮演着关键的作用，可以有效地捕捉交通时序序中的内在空间-时间关系和时间序列信息。
</details></li>
</ul>
<hr>
<h2 id="TokenSplit-Using-Discrete-Speech-Representations-for-Direct-Refined-and-Transcript-Conditioned-Speech-Separation-and-Recognition"><a href="#TokenSplit-Using-Discrete-Speech-Representations-for-Direct-Refined-and-Transcript-Conditioned-Speech-Separation-and-Recognition" class="headerlink" title="TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition"></a>TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10415">http://arxiv.org/abs/2308.10415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hakan Erdogan, Scott Wisdom, Xuankai Chang, Zalán Borsos, Marco Tagliasacchi, Neil Zeghidour, John R. Hershey</li>
<li>for: 这个论文是为了提出一种基于字符序列的语音分离模型，用于分离多个语音源。</li>
<li>methods: 该模型是一种基于Transformer架构的序列-到-序列编码器-解码器模型，通过masking输入来实现多任务同时训练。</li>
<li>results: 使用对象指标和主观MUSHRA听测， authors表明该模型在语音分离方面表现出色，并且可以在不使用文本条件下也 достичь好的效果。  Additionally, the authors also measure the automatic speech recognition (ASR) performance and provide audio samples of speech synthesis to demonstrate the additional utility of their model.<details>
<summary>Abstract</summary>
We present TokenSplit, a speech separation model that acts on discrete token sequences. The model is trained on multiple tasks simultaneously: separate and transcribe each speech source, and generate speech from text. The model operates on transcripts and audio token sequences and achieves multiple tasks through masking of inputs. The model is a sequence-to-sequence encoder-decoder model that uses the Transformer architecture. We also present a "refinement" version of the model that predicts enhanced audio tokens from the audio tokens of speech separated by a conventional separation model. Using both objective metrics and subjective MUSHRA listening tests, we show that our model achieves excellent performance in terms of separation, both with or without transcript conditioning. We also measure the automatic speech recognition (ASR) performance and provide audio samples of speech synthesis to demonstrate the additional utility of our model.
</details>
<details>
<summary>摘要</summary>
我们介绍了TokenSplit，一种基于字符串的语音分离模型。该模型同时进行多个任务的训练：分离每个语音来源，并将语音转化为文本。模型操作于讲解和音频TokenSequence上，通过masking输入来实现多个任务。该模型采用Transformer架构，是一种sequence-to-sequence编码器-解码器模型。我们还介绍了一个"精度"版本的模型，该模型使用传统分离模型生成优化的音频Token。通过对象指标和主观MUSHRA听测，我们证明了我们的模型在分离方面具有出色的表现，无论是否使用讲解conditioning。我们还测量了自动语音识别（ASR）性能，并提供了语音合成示例，以示出该模型的其他应用价值。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Connected-and-Automated-Vehicles-A-Survey-of-Existing-Approaches-and-Challenges"><a href="#Federated-Learning-for-Connected-and-Automated-Vehicles-A-Survey-of-Existing-Approaches-and-Challenges" class="headerlink" title="Federated Learning for Connected and Automated Vehicles: A Survey of Existing Approaches and Challenges"></a>Federated Learning for Connected and Automated Vehicles: A Survey of Existing Approaches and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10407">http://arxiv.org/abs/2308.10407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vishnu Pandi Chellapandi, Liangqi Yuan, Christopher G. Brinton, Stanislaw H Zak, Ziran Wang</li>
<li>for: 本文主要针对Connected and Automated Vehicles (CAV) 领域内的机器学习 (ML) 技术，即使在各种驾驶环境中进行学习和控制。</li>
<li>methods: 本文使用了联邦学习 (Federated Learning, FL) 方法，允许多辆车辆协同发展模型，从而拓宽学习环境，提高总性能，同时保护每辆车辆的本地数据隐私和安全。</li>
<li>results: 本文对 FL 在 CAV 领域的应用进行了评论，包括分析中心化和分布式架构的 FL 方法，评估不同数据源、模型和数据安全技术的重要性，以及各种特定应用中的基模型和数据集使用情况。<details>
<summary>Abstract</summary>
Machine learning (ML) is widely used for key tasks in Connected and Automated Vehicles (CAV), including perception, planning, and control. However, its reliance on vehicular data for model training presents significant challenges related to in-vehicle user privacy and communication overhead generated by massive data volumes. Federated learning (FL) is a decentralized ML approach that enables multiple vehicles to collaboratively develop models, broadening learning from various driving environments, enhancing overall performance, and simultaneously securing local vehicle data privacy and security. This survey paper presents a review of the advancements made in the application of FL for CAV (FL4CAV). First, centralized and decentralized frameworks of FL are analyzed, highlighting their key characteristics and methodologies. Second, diverse data sources, models, and data security techniques relevant to FL in CAVs are reviewed, emphasizing their significance in ensuring privacy and confidentiality. Third, specific and important applications of FL are explored, providing insight into the base models and datasets employed for each application. Finally, existing challenges for FL4CAV are listed and potential directions for future work are discussed to further enhance the effectiveness and efficiency of FL in the context of CAV.
</details>
<details>
<summary>摘要</summary>
本文对 FL4CAV 的应用进行了评论，包括中央化和分布式框架的分析，以及相关的数据源、模型和数据安全技术。此外，文章还探讨了 FL4CAV 在不同应用中的特点和挑战。最后，文章列出了现有的挑战和未来工作的可能性，以便进一步提高 FL4CAV 的效率和效果。中央化和分布式框架的分析：中央化框架是一种传统的机器学习方法，它需要所有的数据集中集成到一个中央服务器上，然后进行训练和推理。分布式框架则是一种分布式机器学习方法，它允许多个车辆共同开发模型，从而扩大学习到不同的驾驶环境。数据源、模型和数据安全技术的评论：FL4CAV 的数据源包括车辆的传感器数据、GPS 数据、路况数据等。模型包括深度学习模型、支持向量机模型等。数据安全技术包括数据加密、数据隐私保护等。特定应用的探讨：FL4CAV 可以应用于许多不同的领域，包括自动驾驶、路况预测、车辆追踪等。每个应用都有其特点和挑战。现有的挑战和未来工作的可能性：FL4CAV 面临着许多挑战，包括数据安全性、通信开销、模型质量等。未来工作可能包括提高 FL4CAV 的效率和效果，开发更加智能的车辆系统，以及解决数据隐私和安全性问题等。
</details></li>
</ul>
<hr>
<h2 id="Label-Selection-Approach-to-Learning-from-Crowds"><a href="#Label-Selection-Approach-to-Learning-from-Crowds" class="headerlink" title="Label Selection Approach to Learning from Crowds"></a>Label Selection Approach to Learning from Crowds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10396">http://arxiv.org/abs/2308.10396</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssatsuki/label-selection-layer">https://github.com/ssatsuki/label-selection-layer</a></li>
<li>paper_authors: Kosuke Yoshimura, Hisashi Kashima</li>
<li>for:  This paper is written for the purpose of improving the performance of supervised deep learning models by using crowdsourced labeled data, which is often noisy and contains label noise.</li>
<li>methods: The proposed method, called Label Selection Layer, uses a selector network to determine whether to use a worker’s label for training, and can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models.</li>
<li>results: The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case.<details>
<summary>Abstract</summary>
Supervised learning, especially supervised deep learning, requires large amounts of labeled data. One approach to collect large amounts of labeled data is by using a crowdsourcing platform where numerous workers perform the annotation tasks. However, the annotation results often contain label noise, as the annotation skills vary depending on the crowd workers and their ability to complete the task correctly. Learning from Crowds is a framework which directly trains the models using noisy labeled data from crowd workers. In this study, we propose a novel Learning from Crowds model, inspired by SelectiveNet proposed for the selective prediction problem. The proposed method called Label Selection Layer trains a prediction model by automatically determining whether to use a worker's label for training using a selector network. A major advantage of the proposed method is that it can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models, without explicitly assuming a model of the noise in crowd annotations. The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate english text into simplified chinese文本：Supervised learning, especially supervised deep learning, requires large amounts of labeled data. One approach to collect large amounts of labeled data is by using a crowdsourcing platform where numerous workers perform the annotation tasks. However, the annotation results often contain label noise, as the annotation skills vary depending on the crowd workers and their ability to complete the task correctly. Learning from Crowds is a framework which directly trains the models using noisy labeled data from crowd workers. In this study, we propose a novel Learning from Crowds model, inspired by SelectiveNet proposed for the selective prediction problem. The proposed method called Label Selection Layer trains a prediction model by automatically determining whether to use a worker's label for training using a selector network. A major advantage of the proposed method is that it can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models, without explicitly assuming a model of the noise in crowd annotations. The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case.翻译结果：超级vised learning，特别是深度学习，需要大量标注数据。一种收集大量标注数据的方法是使用一个人工智能平台，让多名工作者完成标注任务。然而，标注结果经常包含标签噪音，因为 annotator的技能因人而异，完成任务正确性不一致。我们提出了一种 Learning from Crowds 框架，直接使用群体标注数据来训练模型。这种方法称为 Label Selection Layer，通过一个选择器网络来自动决定使用工作者的标注来训练预测模型。我们的方法具有一个优势，可以适用于大多数supervised learning问题，只需要添加一个选择器网络，修改现有模型的目标函数，不需要直接假设群体标注中的噪音模型。实验结果表明，我们的方法与 State-of-the-art 方法 Crowd Layer 相当或更好，除了回归问题例外。
</details></li>
</ul>
<hr>
<h2 id="DiffPrep-Differentiable-Data-Preprocessing-Pipeline-Search-for-Learning-over-Tabular-Data"><a href="#DiffPrep-Differentiable-Data-Preprocessing-Pipeline-Search-for-Learning-over-Tabular-Data" class="headerlink" title="DiffPrep: Differentiable Data Preprocessing Pipeline Search for Learning over Tabular Data"></a>DiffPrep: Differentiable Data Preprocessing Pipeline Search for Learning over Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10915">http://arxiv.org/abs/2308.10915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chu-data-lab/diffprep">https://github.com/chu-data-lab/diffprep</a></li>
<li>paper_authors: Peng Li, Zhiyi Chen, Xu Chu, Kexin Rong</li>
<li>for: 提高机器学习模型的性能，自动搜索数据预处理管道。</li>
<li>methods: 使用梯度下降法和一次训练的机器学习模型，将数据预处理管道的搜索转化为连续和可导的问题，以提高搜索效率。</li>
<li>results: 在15个实际世界数据集中，DiffPrep得到了最佳测试精度，并在一些数据集上提高了机器学习模型的测试精度达6.6%。<details>
<summary>Abstract</summary>
Data preprocessing is a crucial step in the machine learning process that transforms raw data into a more usable format for downstream ML models. However, it can be costly and time-consuming, often requiring the expertise of domain experts. Existing automated machine learning (AutoML) frameworks claim to automate data preprocessing. However, they often use a restricted search space of data preprocessing pipelines which limits the potential performance gains, and they are often too slow as they require training the ML model multiple times. In this paper, we propose DiffPrep, a method that can automatically and efficiently search for a data preprocessing pipeline for a given tabular dataset and a differentiable ML model such that the performance of the ML model is maximized. We formalize the problem of data preprocessing pipeline search as a bi-level optimization problem. To solve this problem efficiently, we transform and relax the discrete, non-differential search space into a continuous and differentiable one, which allows us to perform the pipeline search using gradient descent with training the ML model only once. Our experiments show that DiffPrep achieves the best test accuracy on 15 out of the 18 real-world datasets evaluated and improves the model's test accuracy by up to 6.6 percentage points.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换 raw 数据 into 更usable 格式，以便下游机器学习模型使用。然而，这可能是 costly 和时间consuming的，并且frequently 需要域专家的帮助。现有的自动机器学习（AutoML）框架声称可以自动化数据预处理。然而，它们通常使用一个限制的搜索空间，这限制了性能提高的可能性，并且它们经常是slow，因为它们需要训练 ML 模型多次。在这篇论文中，我们提出了 DiffPrep，一种可以自动和高效地搜索一个 tabular 数据集和一个可导 ML 模型的数据预处理管道，以便maximize 模型的性能。我们将数据预处理管道搜索问题形式化为二级优化问题。为了解决这个问题高效，我们将离散、不准确的搜索空间转换为连续和可导的一个，这allowed us 使用梯度下降来搜索管道，只需要训练 ML 模型一次。我们的实验表明，DiffPrep 在 18 个实际世界数据集上测试精度最高，提高模型的测试精度 by up to 6.6 个百分点。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Opinion-Aggregation-–-A-Statistical-Perspective"><a href="#Unsupervised-Opinion-Aggregation-–-A-Statistical-Perspective" class="headerlink" title="Unsupervised Opinion Aggregation – A Statistical Perspective"></a>Unsupervised Opinion Aggregation – A Statistical Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10386">http://arxiv.org/abs/2308.10386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noyan C. Sevuktekin, Andrew C. Singer</li>
<li>for: 这篇论文旨在探讨一种无需知道真实状况的情况下，基于专家意见来评估专家准确性的统计方法。</li>
<li>methods: 该论文提出了一种基于专家意见的准确性评估方法，即measure the competence of each expert by their likeliness to agree with their peers。</li>
<li>results: 论文表明，更可靠的专家更有可能与其他专家一致，并提出了一种无监督的朴素贝叶斯分类器，可以在较大的问题空间达到最优性。<details>
<summary>Abstract</summary>
Complex decision-making systems rarely have direct access to the current state of the world and they instead rely on opinions to form an understanding of what the ground truth could be. Even in problems where experts provide opinions without any intention to manipulate the decision maker, it is challenging to decide which expert's opinion is more reliable -- a challenge that is further amplified when decision-maker has limited, delayed, or no access to the ground truth after the fact. This paper explores a statistical approach to infer the competence of each expert based on their opinions without any need for the ground truth. Echoing the logic behind what is commonly referred to as \textit{the wisdom of crowds}, we propose measuring the competence of each expert by their likeliness to agree with their peers. We further show that the more reliable an expert is the more likely it is that they agree with their peers. We leverage this fact to propose a completely unsupervised version of the na\"{i}ve Bayes classifier and show that the proposed technique is asymptotically optimal for a large class of problems. In addition to aggregating a large block of opinions, we further apply our technique for online opinion aggregation and for decision-making based on a limited the number of opinions.
</details>
<details>
<summary>摘要</summary>
复杂的决策系统通常没有直接访问当前世界的现状，而是基于意见来形成决策者的理解。即使在专家提供意见无恶意欺诈决策者的情况下，决策者难以判断哪个专家的意见更可靠，这个问题在决策者没有或延迟了现实后的真实信息时变得更加复杂。本文探讨一种统计方法来评估每位专家的能力基于他们的意见，不需要真实信息。按照群体智慧的逻辑，我们提出测量每位专家的能力的方法是根据他们与同行的相互一致程度。我们还证明了更可靠的专家更likely会与同行一致。我们利用这一点来提出一种完全不需要监督的na\"{i}ve Bayes分类器，并证明该技术在一类问题上是 asymptotically 优化的。除了聚合大量意见外，我们还应用该技术于在线意见聚合和基于有限数量的意见做出决策。
</details></li>
</ul>
<hr>
<h2 id="Automated-mapping-of-virtual-environments-with-visual-predictive-coding"><a href="#Automated-mapping-of-virtual-environments-with-visual-predictive-coding" class="headerlink" title="Automated mapping of virtual environments with visual predictive coding"></a>Automated mapping of virtual environments with visual predictive coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10913">http://arxiv.org/abs/2308.10913</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Gornet, Matthew Thomson</li>
<li>for: 这个论文的目的是探索人类大脑中的内在地图构建方式，以及如何使用预测编码来实现这一目的。</li>
<li>methods: 这个论文使用了预测编码网络，该网络使用自我注意力来学习从视觉数据中预测下一幅图像。在学习过程中，网络自动地构建了一个内部表示环境的空间地图，该地图可以让Agent在只有视觉信息的情况下准确地确定自己的位置。</li>
<li>results: 研究结果表明，预测编码可以作为一种自然的和通用的神经网络算法，用于构建大脑中的内在地图。这种地图可以自动地扩展到听觉、感觉和语言输入。<details>
<summary>Abstract</summary>
Humans construct internal cognitive maps of their environment directly from sensory inputs without access to a system of explicit coordinates or distance measurements. While machine learning algorithms like SLAM utilize specialized visual inference procedures to identify visual features and construct spatial maps from visual and odometry data, the general nature of cognitive maps in the brain suggests a unified mapping algorithmic strategy that can generalize to auditory, tactile, and linguistic inputs. Here, we demonstrate that predictive coding provides a natural and versatile neural network algorithm for constructing spatial maps using sensory data. We introduce a framework in which an agent navigates a virtual environment while engaging in visual predictive coding using a self-attention-equipped convolutional neural network. While learning a next image prediction task, the agent automatically constructs an internal representation of the environment that quantitatively reflects distances. The internal map enables the agent to pinpoint its location relative to landmarks using only visual information.The predictive coding network generates a vectorized encoding of the environment that supports vector navigation where individual latent space units delineate localized, overlapping neighborhoods in the environment. Broadly, our work introduces predictive coding as a unified algorithmic framework for constructing cognitive maps that can naturally extend to the mapping of auditory, sensorimotor, and linguistic inputs.
</details>
<details>
<summary>摘要</summary>
人类直接从感知输入中构建内部的认知地图，而不需要访问专门的坐标系或距离测量。而机器学习算法如SLAM则利用专门的视觉推理过程来识别视觉特征并从视觉和运动数据中构建空间地图。然而，大脑内部的认知地图的通用性 suggets a unified mapping algorithmic strategy that can generalize to auditory, tactile, and linguistic inputs。在这里，我们展示了预测编码提供了一种自然和灵活的神经网络算法，可以使用感知数据来构建空间地图。我们介绍了一个框架，在该框架中，一个代理人在虚拟环境中导航，同时使用自我注意力抽象 convolutional neural network 进行视觉预测任务。通过学习预测图像任务，代理人自动构建了内部表示环境，该表示环境可以量化地表示距离。内部地图使得代理人可以使用仅视觉信息来定位自己的位置相对于标志。预测编码网络生成了一个vector化的环境编码，该编码支持vector Navigation，其中个别的latent space单位界定了环境中的局部、重叠的区域。总之，我们的工作将预测编码作为一种统一的算法框架，可以自然扩展到对听频、感知动作和语言输入的映射。
</details></li>
</ul>
<hr>
<h2 id="HoSNN-Adversarially-Robust-Homeostatic-Spiking-Neural-Networks-with-Adaptive-Firing-Thresholds"><a href="#HoSNN-Adversarially-Robust-Homeostatic-Spiking-Neural-Networks-with-Adaptive-Firing-Thresholds" class="headerlink" title="HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds"></a>HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10373">http://arxiv.org/abs/2308.10373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hejia Geng, Peng Li<br>for: 这个研究旨在开发一种具有防御性的神经网络模型，以抵抗神经网络对于攻击性输入的脆弱性。methods: 这个研究使用了一种叫做阀值自适应的 neuron 模型，具有自适应的阀值动态调整机制，以减少攻击性输入的传播和保护神经网络的稳定性。results: 研究发现，这种具有防御性的神经网络模型能够在 CIFAR-10 测试集上实现高度的抗攻击性和稳定性，并且在不需要Explicit adversarial training的情况下，具有较高的抗攻击性和稳定性。<details>
<summary>Abstract</summary>
Spiking neural networks (SNNs) offer promise for efficient and powerful neurally inspired computation. Common to other types of neural networks, however, SNNs face the severe issue of vulnerability to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to develop a bio-inspired solution that counters the susceptibilities of SNNs to adversarial onslaughts. At the heart of our approach is a novel threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN). Distinct from traditional LIF models, our TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. Theoretical analysis is presented to shed light on the stability and convergence properties of the TA-LIF neurons, underscoring their superior dynamic robustness under input distributional shifts over traditional LIF neurons. Remarkably, without explicit adversarial training, our HoSNNs demonstrate inherent robustness on CIFAR-10, with accuracy improvements to 72.6% and 54.19% against FGSM and PGD attacks, up from 20.97% and 0.6%, respectively. Furthermore, with minimal FGSM adversarial training, our HoSNNs surpass previous models by 29.99% under FGSM and 47.83% under PGD attacks on CIFAR-10. Our findings offer a new perspective on harnessing biological principles for bolstering SNNs adversarial robustness and defense, paving the way to more resilient neuromorphic computing.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）具有高效和强大的神经元灵感计算的承诺。然而，SNN也面临严重的攻击性风险攻击的问题。我们的研究是首先借鉴神经自适应性来开发一种生物发生的解决方案，以抵御SNN对攻击的抵触性。我们的方法的核心是一种新的阈值调整泄漏 integrate-and-fire（TA-LIF）神经元模型，我们采用这种模型来构建我们的提案的对抗性 robust homeostatic SNN（HoSNN）。与传统的LIF模型不同，我们的TA-LIF模型包含一种自我稳定的动态阈值调整机制， thereby curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. 我们的理论分析表明，TA-LIF neurons具有更高的稳定性和对输入分布的适应性，而不需要显式的对抗训练。在CIFAR-10上，我们的HoSNNs没有接受过对抗训练，具有72.6%和54.19%的准确率提升，分别对抗FGSM和PGD攻击。此外，通过最小化FGSM对抗训练，我们的HoSNNs超越了先前的模型，在FGSM和PGD攻击下的CIFAR-10上具有29.99%和47.83%的提升。我们的发现开 up a new perspective on harnessing biological principles for bolstering SNNs adversarial robustness and defense, paving the way to more resilient neuromorphic computing.
</details></li>
</ul>
<hr>
<h2 id="Developing-a-Machine-Learning-Based-Clinical-Decision-Support-Tool-for-Uterine-Tumor-Imaging"><a href="#Developing-a-Machine-Learning-Based-Clinical-Decision-Support-Tool-for-Uterine-Tumor-Imaging" class="headerlink" title="Developing a Machine Learning-Based Clinical Decision Support Tool for Uterine Tumor Imaging"></a>Developing a Machine Learning-Based Clinical Decision Support Tool for Uterine Tumor Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10372">http://arxiv.org/abs/2308.10372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Darryl E. Wright, Adriana V. Gregory, Deema Anaam, Sepideh Yadollahi, Sumana Ramanathan, Kafayat A. Oyemade, Reem Alsibai, Heather Holmes, Harrison Gottlich, Cherie-Akilah G. Browne, Sarah L. Cohen Rassier, Isabel Green, Elizabeth A. Stewart, Hiroaki Takahashi, Bohyun Kim, Shannon Laughlin-Tommaso, Timothy L. Kline</li>
<li>for: 这个研究是为了开发一个自动化的方法来分类uterus和uterine tumor（UT），以及在不同的肿瘤型别之间进行分类。</li>
<li>methods: 这个研究使用了nnU-Net来自动分类uterus和UT，并评估了不同训练集大小的影响。</li>
<li>results: 研究获得了在分类degenerated leiomyoma（LM）和uterine leiomyosarcoma（LMS）之间的F1分数为0.80，并在分类不同的肿瘤型别时获得了F1分数在0.53-0.80之间。<details>
<summary>Abstract</summary>
Uterine leiomyosarcoma (LMS) is a rare but aggressive malignancy. On imaging, it is difficult to differentiate LMS from, for example, degenerated leiomyoma (LM), a prevalent but benign condition. We curated a data set of 115 axial T2-weighted MRI images from 110 patients (mean [range] age=45 [17-81] years) with UTs that included five different tumor types. These data were randomly split stratifying on tumor volume into training (n=85) and test sets (n=30). An independent second reader (reader 2) provided manual segmentations for all test set images. To automate segmentation, we applied nnU-Net and explored the effect of training set size on performance by randomly generating subsets with 25, 45, 65 and 85 training set images. We evaluated the ability of radiomic features to distinguish between types of UT individually and when combined through feature selection and machine learning. Using the entire training set the mean [95% CI] fibroid DSC was measured as 0.87 [0.59-1.00] and the agreement between the two readers was 0.89 [0.77-1.0] on the test set. When classifying degenerated LM from LMS we achieve a test set F1-score of 0.80. Classifying UTs based on radiomic features we identify classifiers achieving F1-scores of 0.53 [0.45, 0.61] and 0.80 [0.80, 0.80] on the test set for the benign versus malignant, and degenerated LM versus LMS tasks. We show that it is possible to develop an automated method for 3D segmentation of the uterus and UT that is close to human-level performance with fewer than 150 annotated images. For distinguishing UT types, while we train models that merit further investigation with additional data, reliable automatic differentiation of UTs remains a challenge.
</details>
<details>
<summary>摘要</summary>
uterine leiomyosarcoma (LMS) 是一种罕见 yet aggressive 的肿瘤。在医学影像上，它与、例如，退化的子宫omyoma (LM) 相似，这是一种常见 yet benign 的疾病。我们筛选了115个轴向T2束重MRI图像，来自110名患者（年龄的 mean [range] = 45 [17-81] 岁），包括五种不同的肿瘤类型。这些数据被随机分割，按照肿瘤体积进行训练（n=85）和测试集（n=30）。一名独立的第二读者（读者2）提供了测试集图像的手动分割。为了自动分割，我们应用了nnU-Net，并通过 randomly generating subsets with 25, 45, 65 and 85 训练集图像来调查训练集大小对性能的影响。我们评估了用于分类不同类型的uterine tumor 的 радиомiros特征的能力，并通过特征选择和机器学习来组合这些特征。使用整个训练集，我们测算了 fibroid DSC 的 mean [95% CI] 为 0.87 [0.59-1.00]，并且测试集上的两个读者之间的一致性为 0.89 [0.77-1.0]。在分类退化LM from LMS 时，我们在测试集上获得了 F1 分数为 0.80。基于 радиомiros特征，我们identified classifiers achieving F1 分数为 0.53 [0.45, 0.61] 和 0.80 [0.80, 0.80] 在测试集上，用于分类 benign versus malignant 和 degenerated LM versus LMS 任务。我们显示，可以通过使用 fewer than 150 annotated images 来开发一种可以与人类水平的自动 segmentation of the uterus and UT 的方法。然而，在分类不同类型的 UT 时，尽管我们训练了一些值得进一步调查的模型，但可靠的自动分类 UT 仍然是一个挑战。
</details></li>
</ul>
<hr>
<h2 id="SE-3-Equivariant-Augmented-Coupling-Flows"><a href="#SE-3-Equivariant-Augmented-Coupling-Flows" class="headerlink" title="SE(3) Equivariant Augmented Coupling Flows"></a>SE(3) Equivariant Augmented Coupling Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10364">http://arxiv.org/abs/2308.10364</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lollcat/se3-augmented-coupling-flows">https://github.com/lollcat/se3-augmented-coupling-flows</a></li>
<li>paper_authors: Laurence I. Midgley, Vincent Stimper, Javier Antorán, Emile Mathieu, Bernhard Schölkopf, José Miguel Hernández-Lobato</li>
<li>for: 本文为了提出一种可以保持SE(3)和 permutation equivariant的coupling流程，以便在物理系统中进行 probabilistic modeling。</li>
<li>methods: 本文使用了coordinate splits along additional augmented dimensions，将原始坐标映射到学习的SE(3) invarianton bases中，然后应用标准流转换。</li>
<li>results: 本文的coupling流程可以保持fast sampling和density evaluation，并且可以生成无偏见的期望值。在训练DW4、LJ13和QM9-positional数据集时，本文的coupling流程与equivarian continuous normalizing flows相比，可以快速样本两个数量级。此外，本文还是第一个通过只模型分子的Cartesian坐标位置来学习全 Boltzmann 分布的 Alanine dipeptide。最后，本文示出了其可以使用只有能量函数来 aproximately 样本 DW4 和 LJ13 粒子系统的Boltzmann分布。<details>
<summary>Abstract</summary>
Coupling normalizing flows allow for fast sampling and density evaluation, making them the tool of choice for probabilistic modeling of physical systems. However, the standard coupling architecture precludes endowing flows that operate on the Cartesian coordinates of atoms with the SE(3) and permutation invariances of physical systems. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation, and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling. When trained on the DW4, LJ13 and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows, while allowing sampling two orders of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions.
</details>
<details>
<summary>摘要</summary>
通过卷积整合流可以快速采样和评估概率分布，使其成为物理系统的概率模型工具。然而，标准 coupling 架构禁止将 Cartesian 坐标系中的 atoms 映射到 SE(3) 和 permutation 协变的物理系统中。这项工作提议一种 coupling 流，可以保持 SE(3) 和 permutation 协变，通过在附加的扩展维度上进行坐标拆分。在每层中，流量将 atoms 的位置映射到学习的 SE(3) 不变基底中，然后应用标准 flow 变换，如 monotonic rational-quadratic splines，然后返回到原基底。关键的是，我们的流量保持快速采样和概率评估，并可以生成偏向采样来计算对 Target 分布的预期值。当我们在 DW4、LJ13 和 QM9-positional 数据集上训练我们的流量时，它与 equivariant continuous normalizing flows 相当竞争，而且可以快速采样两个数量级。此外，我们是第一个通过只模型 Cartesian 坐标系中 atoms 的概率分布来学习 full Boltzmann 分布的 alanine dipeptide。最后，我们示示了我们的流量可以使用 DW4 和 LJ13 粒子系统的能量函数来约 approximate 其 Boltzmann 分布。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Find-And-Fix-Vulnerable-Software"><a href="#Can-Large-Language-Models-Find-And-Fix-Vulnerable-Software" class="headerlink" title="Can Large Language Models Find And Fix Vulnerable Software?"></a>Can Large Language Models Find And Fix Vulnerable Software?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10345">http://arxiv.org/abs/2308.10345</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Noever</li>
<li>for: 这个研究是用于评估大语言模型（LLMs）在检测软件漏洞方面的能力，特别是OpenAI的GPT-4，并与传统的静态代码分析工具如Snyk和Fortify进行比较。</li>
<li>methods: 这个研究使用了许多Repository，包括NASA和美国国防部的Repository，并使用了129个代码示例 across eight programming languages来测试GPT-4的性能。</li>
<li>results: GPT-4可以检测到 aproximately four times 的漏洞，并且可以提供可行的修复方案，false positive rate很低。Code corrections可以减少漏洞的数量by 90%，但需要增加代码行数by 11%。LLMs还能够自我审查，并提供修复漏洞的建议。<details>
<summary>Abstract</summary>
In this study, we evaluated the capability of Large Language Models (LLMs), particularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing their performance against traditional static code analyzers like Snyk and Fortify. Our analysis covered numerous repositories, including those from NASA and the Department of Defense. GPT-4 identified approximately four times the vulnerabilities than its counterparts. Furthermore, it provided viable fixes for each vulnerability, demonstrating a low rate of false positives. Our tests encompassed 129 code samples across eight programming languages, revealing the highest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to a 90% reduction in vulnerabilities, requiring only an 11% increase in code lines. A critical insight was LLMs' ability to self-audit, suggesting fixes for their identified vulnerabilities and underscoring their precision. Future research should explore system-level vulnerabilities and integrate multiple static code analyzers for a holistic perspective on LLMs' potential.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们评估了大型自然语言模型（LLM），尤其是OpenAI的GPT-4，在检测软件漏洞方面的能力，并与传统的静态代码分析工具如Snyk和Fortify进行比较。我们的分析覆盖了多个Repository，包括NASA和国防部的Repository。GPT-4在检测漏洞方面表现出了约四倍的能力，并提供了每个漏洞的可行的修复方案，表明了它的假阳性率非常低。我们的测试包括129个代码样本 across eight种编程语言，发现PHP和JavaScript中的漏洞最高。GPT-4的代码更正引起了漏洞的减少率达90%，仅需要11%的代码行数增加。LLMs的自我审查能力为我们提供了一个关键的发现，它们可以自动提供修复方案，并证明了它们的精度。未来的研究应该探索系统级别的漏洞和将多个静态代码分析工具集成到LLMs的潜在力量中。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Empirical-Evaluation-on-Online-Continual-Learning"><a href="#A-Comprehensive-Empirical-Evaluation-on-Online-Continual-Learning" class="headerlink" title="A Comprehensive Empirical Evaluation on Online Continual Learning"></a>A Comprehensive Empirical Evaluation on Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10328">http://arxiv.org/abs/2308.10328</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albinsou/ocl_survey">https://github.com/albinsou/ocl_survey</a></li>
<li>paper_authors: Albin Soutif–Cormerais, Antonio Carta, Andrea Cossu, Julio Hurtado, Vincenzo Lomonaco, Joost Van de Weijer, Hamed Hemati</li>
<li>for: 本研究旨在评估在流动数据上进行连续学习的不同方法，以实现更加接近实际学习经验。</li>
<li>methods: 本研究考虑了Literature中的多种方法，包括分类增量学习。</li>
<li>results: 研究发现大多数方法受到稳定性和过拟合问题的影响，但是学习表示的质量与同样计算预算下的随机批处理相当。<details>
<summary>Abstract</summary>
Online continual learning aims to get closer to a live learning experience by learning directly on a stream of data with temporally shifting distribution and by storing a minimum amount of data from that stream. In this empirical evaluation, we evaluate various methods from the literature that tackle online continual learning. More specifically, we focus on the class-incremental setting in the context of image classification, where the learner must learn new classes incrementally from a stream of data. We compare these methods on the Split-CIFAR100 and Split-TinyImagenet benchmarks, and measure their average accuracy, forgetting, stability, and quality of the representations, to evaluate various aspects of the algorithm at the end but also during the whole training period. We find that most methods suffer from stability and underfitting issues. However, the learned representations are comparable to i.i.d. training under the same computational budget. No clear winner emerges from the results and basic experience replay, when properly tuned and implemented, is a very strong baseline. We release our modular and extensible codebase at https://github.com/AlbinSou/ocl_survey based on the avalanche framework to reproduce our results and encourage future research.
</details>
<details>
<summary>摘要</summary>
在线连续学习目标是通过直接学习流动数据的方式，与时间变化的分布进行融合，并将最少量的数据存储在流动中。在这个实验性评估中，我们评估了文献中的多种在线连续学习方法。更specifically，我们在图像分类任务中强调类增量设置，learner需要从数据流中逐渐学习新类。我们在Split-CIFAR100和Split-TinyImagenet bencmarks上对这些方法进行了平均精度、忘记、稳定性和表示质量的评估，以评估不同方法的各个方面。我们发现大多数方法受到稳定性和下降问题的影响。然而，学习的表示比i.i.d.培育下相同计算预算下的表示相当。没有一个明确的赢家，基本的经验回快在适度调整和实现下成为了强大的基准。我们在https://github.com/AlbinSou/ocl_survey中发布了我们的模块化和可扩展的代码基础，以便重现我们的结果并促进未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Quantum-State-Tomography-using-Quantum-Machine-Learning"><a href="#Quantum-State-Tomography-using-Quantum-Machine-Learning" class="headerlink" title="Quantum State Tomography using Quantum Machine Learning"></a>Quantum State Tomography using Quantum Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10327">http://arxiv.org/abs/2308.10327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hongyehu/Machine_Learning_Quantum_State_Tomography">https://github.com/hongyehu/Machine_Learning_Quantum_State_Tomography</a></li>
<li>paper_authors: Nouhaila Innan, Owais Ishtiaq Siddiqui, Shivang Arora, Tamojit Ghosh, Yasemin Poyraz Koçak, Dominic Paragas, Abdullah Al Omar Galib, Muhammad Al-Zafar Khan, Mohamed Bennai</li>
<li>for: 这个论文的目的是提出一种基于量子机器学习（QML）技术的量子状态探测（QST）方法，以提高QST的效率。</li>
<li>methods: 这个论文使用了多种类ссиkal和量子方法来进行QST，并评估了不同的QML方法的效果。</li>
<li>results: 研究结果表明，使用QML技术可以significantly reduce the number of measurements required for QST, 并且可以达到高准确率（98%）。<details>
<summary>Abstract</summary>
Quantum State Tomography (QST) is a fundamental technique in Quantum Information Processing (QIP) for reconstructing unknown quantum states. However, the conventional QST methods are limited by the number of measurements required, which makes them impractical for large-scale quantum systems. To overcome this challenge, we propose the integration of Quantum Machine Learning (QML) techniques to enhance the efficiency of QST. In this paper, we conduct a comprehensive investigation into various approaches for QST, encompassing both classical and quantum methodologies; We also implement different QML approaches for QST and demonstrate their effectiveness on various simulated and experimental quantum systems, including multi-qubit networks. Our results show that our QML-based QST approach can achieve high fidelity (98%) with significantly fewer measurements than conventional methods, making it a promising tool for practical QIP applications.
</details>
<details>
<summary>摘要</summary>
量子状态测测（QST）是Quantum Information Processing（QIP）中重要的技术，用于重建未知量子状态。然而，现有的QST方法受限于测量数量的限制，使其对大规模量子系统不实际。为解决这个挑战，我们提议通过量子机器学习（QML）技术来增强QST的效率。在这篇论文中，我们进行了各种QST方法的全面调查，包括класси方法和量子方法；我们还实施了不同的QML方法，并在多个模拟和实验量子系统上进行了测试，包括多元比特网络。我们的结果表明，我们的QML基于QST方法可以达到高准确率（98%），并且使用了许多 fewer measurements than conventional methods，这使其成为实际QIP应用中的一个有前途的工具。
</details></li>
</ul>
<hr>
<h2 id="Homogenising-SoHO-EIT-and-SDO-AIA-171A-Images-A-Deep-Learning-Approach"><a href="#Homogenising-SoHO-EIT-and-SDO-AIA-171A-Images-A-Deep-Learning-Approach" class="headerlink" title="Homogenising SoHO&#x2F;EIT and SDO&#x2F;AIA 171Å$~$ Images: A Deep Learning Approach"></a>Homogenising SoHO&#x2F;EIT and SDO&#x2F;AIA 171Å$~$ Images: A Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10322">http://arxiv.org/abs/2308.10322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhamoy Chatterjee, Andrés Muñoz-Jaramillo, Maher Dayeh, Hazel M. Bain, Kimberly Moreland</li>
<li>for: 这个研究旨在创建一个具有同一个特征的 EUV 图像数据集，以便进行太阳气候预测任务。</li>
<li>methods: 这个研究使用了 SoHO&#x2F;EIT 和 SDO&#x2F;AIA 171 ~\AA ~的探测数据，通过 ensemble learning 技术将多个探测数据集合并，并使用 Approximate Bayesian Ensembling 方法来生成一个 ensemble 模型，以估计对于不同气候预测任务的 uncertainty。</li>
<li>results: 研究发现， ensemble 模型的 uncertainty 随着训练集大小的增加而降低，而且 ensemble 模型在测试数据中表现出较高的 uncertainty，表明它可以准确地预测不同的气候预测任务。<details>
<summary>Abstract</summary>
Extreme Ultraviolet images of the Sun are becoming an integral part of space weather prediction tasks. However, having different surveys requires the development of instrument-specific prediction algorithms. As an alternative, it is possible to combine multiple surveys to create a homogeneous dataset. In this study, we utilize the temporal overlap of SoHO/EIT and SDO/AIA 171~\AA ~surveys to train an ensemble of deep learning models for creating a single homogeneous survey of EUV images for 2 solar cycles. Prior applications of deep learning have focused on validating the homogeneity of the output while overlooking the systematic estimation of uncertainty. We use an approach called `Approximate Bayesian Ensembling' to generate an ensemble of models whose uncertainty mimics that of a fully Bayesian neural network at a fraction of the cost. We find that ensemble uncertainty goes down as the training set size increases. Additionally, we show that the model ensemble adds immense value to the prediction by showing higher uncertainty in test data that are not well represented in the training data.
</details>
<details>
<summary>摘要</summary>
Extreme Ultraviolet 图像的太阳是天气预测任务中的一个重要组成部分。然而，不同的调查需要开发专门的仪器预测算法。作为一种 alternatives，我们可以将多个调查结合起来创建一个一致的数据集。在这项研究中，我们利用SOHO/EIT和SDO/AIA 171 Å 调查的时间重叠来训练一个深度学习模型的 ensemble，以生成一个包含2个太阳周期的homogeneous EUV图像数据集。先前的深度学习应用都是验证输出的一致性，而忽略了系统性的估计不确定性。我们使用一种名为“ Approximate Bayesian Ensembling”的方法，生成一个ensemble的模型，其不确定性与完全 Bayesian 神经网络相似，但是比其便宜。我们发现，ensemble 不确定性随着训练集大小的增加而下降。此外，我们还显示，模型ensemble 对预测具有很大的价值，可以在测试数据中显示更高的不确定性，这些数据不良 represent 在训练数据中。
</details></li>
</ul>
<hr>
<h2 id="Towards-Sustainable-Development-A-Novel-Integrated-Machine-Learning-Model-for-Holistic-Environmental-Health-Monitoring"><a href="#Towards-Sustainable-Development-A-Novel-Integrated-Machine-Learning-Model-for-Holistic-Environmental-Health-Monitoring" class="headerlink" title="Towards Sustainable Development: A Novel Integrated Machine Learning Model for Holistic Environmental Health Monitoring"></a>Towards Sustainable Development: A Novel Integrated Machine Learning Model for Holistic Environmental Health Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10317">http://arxiv.org/abs/2308.10317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anirudh Mazumder, Sarthak Engala, Aditya Nallaparaju</li>
<li>for: 这个研究旨在帮助政府确定 intervención点，改善规划和保护努力，以促进可持续发展。</li>
<li>methods: 这个研究使用机器学习技术来识别环境状况的预测特征，并使用污染物水平和 particulate matter 作为环境状况的指标。</li>
<li>results: 研究发现了连接不良环境 condition 的特征，帮助政府更好地识别 intervención点，并且可以促进可持续发展。<details>
<summary>Abstract</summary>
Urbanization enables economic growth but also harms the environment through degradation. Traditional methods of detecting environmental issues have proven inefficient. Machine learning has emerged as a promising tool for tracking environmental deterioration by identifying key predictive features. Recent research focused on developing a predictive model using pollutant levels and particulate matter as indicators of environmental state in order to outline challenges. Machine learning was employed to identify patterns linking areas with worse conditions. This research aims to assist governments in identifying intervention points, improving planning and conservation efforts, and ultimately contributing to sustainable development.
</details>
<details>
<summary>摘要</summary>
城市化促进经济增长，但也导致环境退化。传统的环境问题检测方法已经证明不够有效。机器学习技术在跟踪环境衰退方面表现出了替代性，通过确定关键预测特征来开发预测模型。最近的研究集中于开发基于污染物水平和悬尘物含量的预测模型，以描述环境状况的挑战。机器学习技术被用来找出与环境状况相关的模式，以帮助政府确定 intervención点，改善规划和保护努力，最终贡献到可持续发展。
</details></li>
</ul>
<hr>
<h2 id="Demystifying-the-Performance-of-Data-Transfers-in-High-Performance-Research-Networks"><a href="#Demystifying-the-Performance-of-Data-Transfers-in-High-Performance-Research-Networks" class="headerlink" title="Demystifying the Performance of Data Transfers in High-Performance Research Networks"></a>Demystifying the Performance of Data Transfers in High-Performance Research Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10312">http://arxiv.org/abs/2308.10312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Saeedizade, Bing Zhang, Engin Arslan</li>
<li>for: 本文旨在提供一个可扩展的监控框架，以便监测高速研究网络中数据传输的性能问题。</li>
<li>methods: 本文使用了一种可扩展的监控框架，可以收集和存储关键性能指标，以便了解数据传输的性能问题。</li>
<li>results: 评估结果显示，提案的框架可以同时监测400个传输并收集一秒精度的性能统计数据，并且可以自动处理收集到的性能指标，并在87-98%的准确率下识别性能异常。<details>
<summary>Abstract</summary>
High-speed research networks are built to meet the ever-increasing needs of data-intensive distributed workflows. However, data transfers in these networks often fail to attain the promised transfer rates for several reasons, including I/O and network interference, server misconfigurations, and network anomalies. Although understanding the root causes of performance issues is critical to mitigating them and increasing the utilization of expensive network infrastructures, there is currently no available mechanism to monitor data transfers in these networks. In this paper, we present a scalable, end-to-end monitoring framework to gather and store key performance metrics for file transfers to shed light on the performance of transfers. The evaluation results show that the proposed framework can monitor up to 400 transfers per host and more than 40, 000 transfers in total while collecting performance statistics at one-second precision. We also introduce a heuristic method to automatically process the gathered performance metrics and identify the root causes of performance anomalies with an F-score of 87 - 98%.
</details>
<details>
<summary>摘要</summary>
高速研究网络是为满足数据敏感分布式工作流程的需求而建立的。然而，在这些网络中的数据传输经常无法实现承诺的传输速率，这可能是因为输入输出和网络干扰、服务器配置错误以及网络异常。虽然了解性能问题的根本原因是解决性能问题的关键，但目前没有可用的监控数据传输的机制。在本文中，我们提出了一个可扩展的终端到终端监控框架，以收集和存储关键性能指标。评估结果显示，我们的框架可以同时监控400个传输任务和总共超过40,000个传输任务，并在1秒精度收集性能统计数据。我们还提出了一种冒险法来自动处理收集到的性能指标，并使用F-score在87-98%的情况下自动确定性能异常的根本原因。
</details></li>
</ul>
<hr>
<h2 id="I-O-Burst-Prediction-for-HPC-Clusters-using-Darshan-Logs"><a href="#I-O-Burst-Prediction-for-HPC-Clusters-using-Darshan-Logs" class="headerlink" title="I&#x2F;O Burst Prediction for HPC Clusters using Darshan Logs"></a>I&#x2F;O Burst Prediction for HPC Clusters using Darshan Logs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10311">http://arxiv.org/abs/2308.10311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Saeedizade, Roya Taheri, Engin Arslan<br>for: 这篇论文的目的是分析大规模高性能计算（HPC）集群内的各种I&#x2F;O模式，以便最小化I&#x2F;O干扰的发生和影响。methods: 论文使用Darshan报告来抽出系统水平的读写I&#x2F;O率，并使用机器学习模型预测系统层级I&#x2F;O填充的发生。results: 结果显示在五分钟间隔内，读写I&#x2F;O率会有明显的颠簸（超过100倍），并且使用机器学习模型可以预测I&#x2F;O填充的发生，精度高于90%（F-1分数）。此外，研究还显示了一个可以根据I&#x2F;O填充预测的内存管理策略，可以降低应用程序的执行时间。<details>
<summary>Abstract</summary>
Understanding cluster-wide I/O patterns of large-scale HPC clusters is essential to minimize the occurrence and impact of I/O interference. Yet, most previous work in this area focused on monitoring and predicting task and node-level I/O burst events. This paper analyzes Darshan reports from three supercomputers to extract system-level read and write I/O rates in five minutes intervals. We observe significant (over 100x) fluctuations in read and write I/O rates in all three clusters. We then train machine learning models to estimate the occurrence of system-level I/O bursts 5 - 120 minutes ahead. Evaluation results show that we can predict I/O bursts with more than 90% accuracy (F-1 score) five minutes ahead and more than 87% accuracy two hours ahead. We also show that the ML models attain more than 70% accuracy when estimating the degree of the I/O burst. We believe that high-accuracy predictions of I/O bursts can be used in multiple ways, such as postponing delay-tolerant I/O operations (e.g., checkpointing), pausing nonessential applications (e.g., file system scrubbers), and devising I/O-aware job scheduling methods. To validate this claim, we simulated a burst-aware job scheduler that can postpone the start time of applications to avoid I/O bursts. We show that the burst-aware job scheduling can lead to an up to 5x decrease in application runtime.
</details>
<details>
<summary>摘要</summary>
理解大规模HPC集群的总体I/O模式是必要的，以避免I/O干扰的发生和影响。然而，大多数前一些研究都集中于监测和预测任务和节点级I/O异常事件。这篇论文使用Darshan报告数据分析了三个超级计算机的系统级读写I/O速率，发现了所有三个集群中的读写I/O速率存在明显的异常波动（大于100倍）。然后，我们使用机器学习模型来预测系统级I/O异常事件的发生5-120分钟前。评估结果表明，我们可以在5分钟前预测I/O异常事件的发生率高于90%（F-1分数），并在2小时前预测精度高于87%。此外，我们发现ML模型在预测I/O异常事件的严重程度时的准确率超过70%。我们认为高精度的I/O异常预测可以用于多种方式，如延迟快速I/O操作（例如检查点）、挂起非关键应用程序（例如文件系统扫描器），并开发I/O意识的任务调度策略。为验证这一点，我们 simulate了一种基于I/O异常预测的任务调度策略，并证明该策略可以减少应用程序执行时间的最大幅度达5倍。
</details></li>
</ul>
<hr>
<h2 id="Co-Evolution-of-Pose-and-Mesh-for-3D-Human-Body-Estimation-from-Video"><a href="#Co-Evolution-of-Pose-and-Mesh-for-3D-Human-Body-Estimation-from-Video" class="headerlink" title="Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video"></a>Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10305">http://arxiv.org/abs/2308.10305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kasvii/pmce">https://github.com/kasvii/pmce</a></li>
<li>paper_authors: Yingxuan You, Hong Liu, Ti Wang, Wenhao Li, Runwei Ding, Xia Li</li>
<li>for: 用于重建3D人体动作 from video</li>
<li>methods: 使用 Pose and Mesh Co-Evolution network (PMCE)，分为两个部分：1) 视频基于3D人体pose estimation，2) 从估计 pose 和时间图像特征中进行预测 mesh  vertices</li>
<li>results: 在三个基准数据集上（3DPW、Human3.6M 和 MPI-INF-3DHP）实现了以前没有达到的高精度和temporal consistency，并且超越了之前的状态 искусственный智能方法。<details>
<summary>Abstract</summary>
Despite significant progress in single image-based 3D human mesh recovery, accurately and smoothly recovering 3D human motion from a video remains challenging. Existing video-based methods generally recover human mesh by estimating the complex pose and shape parameters from coupled image features, whose high complexity and low representation ability often result in inconsistent pose motion and limited shape patterns. To alleviate this issue, we introduce 3D pose as the intermediary and propose a Pose and Mesh Co-Evolution network (PMCE) that decouples this task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature. Specifically, we propose a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature from the input image sequence. In addition, we design a co-evolution decoder that performs pose and mesh interactions with the image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the human body shape. Extensive experiments demonstrate that the proposed PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M, and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.
</details>
<details>
<summary>摘要</summary>
尽管单个图像基于的3D人体模lesh recovering已经取得了 significativ progress,但从视频中准确地和平滑地recover 3D人体运动仍然是一个挑战。现有的视频基于方法通常通过估算复杂的姿势和形状参数从相关的图像特征来recover人体模lesh, whose high complexity and low representation ability often result in inconsistent pose motion and limited shape patterns. To address this issue, we introduce 3D pose as the intermediary and propose a Pose and Mesh Co-Evolution network (PMCE) that decouples this task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature. Specifically, we propose a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature from the input image sequence. In addition, we design a co-evolution decoder that performs pose and mesh interactions with the image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the human body shape. Extensive experiments demonstrate that the proposed PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M, and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/21/cs.LG_2023_08_21/" data-id="clltau92v006dcr884ey36sg1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/21/cs.SD_2023_08_21/" class="article-date">
  <time datetime="2023-08-20T16:00:00.000Z" itemprop="datePublished">2023-08-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/21/cs.SD_2023_08_21/">cs.SD - 2023-08-21 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="LibriWASN-A-Data-Set-for-Meeting-Separation-Diarization-and-Recognition-with-Asynchronous-Recording-Devices"><a href="#LibriWASN-A-Data-Set-for-Meeting-Separation-Diarization-and-Recognition-with-Asynchronous-Recording-Devices" class="headerlink" title="LibriWASN: A Data Set for Meeting Separation, Diarization, and Recognition with Asynchronous Recording Devices"></a>LibriWASN: A Data Set for Meeting Separation, Diarization, and Recognition with Asynchronous Recording Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10682">http://arxiv.org/abs/2308.10682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joerg Schmalenstroeer, Tobias Gburrek, Reinhold Haeb-Umbach</li>
<li>for: 这个论文是为测试随机位置的无线听写系统而设计的数据集。</li>
<li>methods: 该数据集使用了九种不同的设备，包括五个智能手机和四个麦克风阵列，共记录了29个通道的数据。</li>
<li>results: 该数据集包含了与LibriCSS相似的LibriSpeech句子播放和会议 overlap的情况，可以用于测试时钟同步算法、会议分离、转录和讲话系统。<details>
<summary>Abstract</summary>
We present LibriWASN, a data set whose design follows closely the LibriCSS meeting recognition data set, with the marked difference that the data is recorded with devices that are randomly positioned on a meeting table and whose sampling clocks are not synchronized. Nine different devices, five smartphones with a single recording channel and four microphone arrays, are used to record a total of 29 channels. Other than that, the data set follows closely the LibriCSS design: the same LibriSpeech sentences are played back from eight loudspeakers arranged around a meeting table and the data is organized in subsets with different percentages of speech overlap. LibriWASN is meant as a test set for clock synchronization algorithms, meeting separation, diarization and transcription systems on ad-hoc wireless acoustic sensor networks. Due to its similarity to LibriCSS, meeting transcription systems developed for the former can readily be tested on LibriWASN. The data set is recorded in two different rooms and is complemented with ground-truth diarization information of who speaks when.
</details>
<details>
<summary>摘要</summary>
我们介绍LibriWASN数据集，其设计与LibriCSS会议认知数据集相似，但唯一不同之处是数据记录设备随机分布在会议表前，并且采样时钟不同步。数据集使用了五款智能手机和四个麦克风组合，共记录29个通道。除此之外，数据集的设计与LibriCSS相同：同样使用LibriSpeech句子在会议表周围的八个扬声器播放，并将数据分成不同的发言重叠百分比。LibriWASN是为无线听取感知网络的时钟同步算法、会议分离、笔记录和转录系统进行测试而设计的。由于与LibriCSS的相似性，可以将为LibriCSS开发的会议转录系统直接应用到LibriWASN上。数据集在两个不同的房间中录制，并且配备了会议发言人员时间ground truth的 диари化信息。
</details></li>
</ul>
<hr>
<h2 id="An-Anchor-Point-Based-Image-Model-for-Room-Impulse-Response-Simulation-with-Directional-Source-Radiation-and-Sensor-Directivity-Patterns"><a href="#An-Anchor-Point-Based-Image-Model-for-Room-Impulse-Response-Simulation-with-Directional-Source-Radiation-and-Sensor-Directivity-Patterns" class="headerlink" title="An Anchor-Point Based Image-Model for Room Impulse Response Simulation with Directional Source Radiation and Sensor Directivity Patterns"></a>An Anchor-Point Based Image-Model for Room Impulse Response Simulation with Directional Source Radiation and Sensor Directivity Patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10543">http://arxiv.org/abs/2308.10543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Pan, Lei Zhang, Yilong Lu, Jilu Jin, Lin Qiu, Jingdong Chen, Jacob Benesty</li>
<li>for: 这篇论文的目的是扩展图像模型方法，以便在不同应用中使用。</li>
<li>methods: 该方法使用了 anchor point image model (APIM) 方法，包括源辐射和感知器直达性特征。</li>
<li>results: 该方法可以根据方向函数、分解时延和计算复杂性生成房间响应。可用于多种声学问题，以便模拟房间响应和评估处理算法。<details>
<summary>Abstract</summary>
The image model method has been widely used to simulate room impulse responses and the endeavor to adapt this method to different applications has also piqued great interest over the last few decades. This paper attempts to extend the image model method and develops an anchor-point-image-model (APIM) approach as a solution for simulating impulse responses by including both the source radiation and sensor directivity patterns. To determine the orientations of all the virtual sources, anchor points are introduced to real sources, which subsequently lead to the determination of the orientations of the virtual sources. An algorithm is developed to generate room impulse responses with APIM by taking into account the directional pattern functions, factional time delays, as well as the computational complexity. The developed model and algorithms can be used in various acoustic problems to simulate room acoustics and improve and evaluate processing algorithms.
</details>
<details>
<summary>摘要</summary>
“图像模型方法在过去几十年内已经广泛使用来模拟房间快速响应，而将这方法应用于不同的应用场景也引起了很大的兴趣。本文尝试将图像模型方法扩展，开发出一个图像模型（APIM）方法来模拟快速响应，这个方法包括了源辐射和感应器直径图形的考虑。为了决定所有虚拟源的方向，本文引入了紧缩点，这些紧缩点将导致虚拟源的方向的决定。具有考虑irectional pattern functions、分割时延和计算复杂度的算法是为了生成房间快速响应的APIM模型和算法。这个模型和算法可以在各种音响问题中模拟房间音响，提高和评估处理算法。”
</details></li>
</ul>
<hr>
<h2 id="Implicit-Self-supervised-Language-Representation-for-Spoken-Language-Diarization"><a href="#Implicit-Self-supervised-Language-Representation-for-Spoken-Language-Diarization" class="headerlink" title="Implicit Self-supervised Language Representation for Spoken Language Diarization"></a>Implicit Self-supervised Language Representation for Spoken Language Diarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10470">http://arxiv.org/abs/2308.10470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jagabandhu Mishra, S. R. Mahadeva Prasanna<br>for: 这个论文的目的是提出一种基于自适应框架的语音话语分类方法，以便在低资源语言上进行语音分类。methods: 这个论文使用了三种不同的框架，分别是固定分 segmentation、变点基本分 segmentation 和 E2E 框架，并使用 x-vector 作为隐式语言表示。results: 该论文的实验结果表明，使用 x-vector 作为隐式语言表示可以达到同样的表达效果，而且使用 E2E 框架可以达到最佳的隐式语言分类性能（JER &#x3D; 6.38）。然而，在使用实际的 Microsoft CS（MSCS）数据集时，隐式语言分类性能下降至 60.4，主要是因为 MSCS 数据集中次语言的分段持续时间的分布不同于 TTSF-LD 数据集。此外，使用小值 N 可以避免分段膨润，但是同时 x-vector 表示不能够捕捉到语言差异，因为同一个 speaker 在两种语言中说话。因此，该研究提出了一种自适应隐式语言表示，并与 x-vector 表示进行比较。<details>
<summary>Abstract</summary>
In a code-switched (CS) scenario, the use of spoken language diarization (LD) as a pre-possessing system is essential. Further, the use of implicit frameworks is preferable over the explicit framework, as it can be easily adapted to deal with low/zero resource languages. Inspired by speaker diarization (SD) literature, three frameworks based on (1) fixed segmentation, (2) change point-based segmentation and (3) E2E are proposed to perform LD. The initial exploration with synthetic TTSF-LD dataset shows, using x-vector as implicit language representation with appropriate analysis window length ($N$) can able to achieve at per performance with explicit LD. The best implicit LD performance of $6.38$ in terms of Jaccard error rate (JER) is achieved by using the E2E framework. However, considering the E2E framework the performance of implicit LD degrades to $60.4$ while using with practical Microsoft CS (MSCS) dataset. The difference in performance is mostly due to the distributional difference between the monolingual segment duration of secondary language in the MSCS and TTSF-LD datasets. Moreover, to avoid segment smoothing, the smaller duration of the monolingual segment suggests the use of a small value of $N$. At the same time with small $N$, the x-vector representation is unable to capture the required language discrimination due to the acoustic similarity, as the same speaker is speaking both languages. Therefore, to resolve the issue a self-supervised implicit language representation is proposed in this study. In comparison with the x-vector representation, the proposed representation provides a relative improvement of $63.9\%$ and achieved a JER of $21.8$ using the E2E framework.
</details>
<details>
<summary>摘要</summary>
在码换（CS）场景中，使用口语语音分类（LD）作为预处理系统是必备的。此外，使用隐式框架更有利于处理低/零资源语言，因此根据说话者分类（SD）文献，提出了三种基于（1）固定分 segmentation、（2）变点分 segmentation和（3）E2E的框架来实现LD。使用xvector作为隐式语言表示，并选择合适的分析窗口长度($N$)，可以达到与Explicit LD相同的性能。最佳隐式LD性能为6.38个Jaccard错误率（JER）， achievable by using E2E框架。然而，在使用实际的微软CS（MSCS） dataset时，隐式LD性能下降到60.4个JER，主要是由于MSCS dataset中次语言的单语言分段时间的分布不同于TTSF-LD dataset。此外，避免分段平滑的问题，需要选择小的分段时间。同时，使用小的$N$值，xvector表示无法捕捉到必要的语言划分，因为同一个说话者同时说两种语言，导致问题。因此，本研究提出了一种自动学习的隐式语言表示，与xvector表示相比，提供了63.9%的相对改进，并使用E2E框架达到JER21.8。
</details></li>
</ul>
<hr>
<h2 id="Multi-GradSpeech-Towards-Diffusion-based-Multi-Speaker-Text-to-speech-Using-Consistent-Diffusion-Models"><a href="#Multi-GradSpeech-Towards-Diffusion-based-Multi-Speaker-Text-to-speech-Using-Consistent-Diffusion-Models" class="headerlink" title="Multi-GradSpeech: Towards Diffusion-based Multi-Speaker Text-to-speech Using Consistent Diffusion Models"></a>Multi-GradSpeech: Towards Diffusion-based Multi-Speaker Text-to-speech Using Consistent Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10428">http://arxiv.org/abs/2308.10428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heyang Xue, Shuai Guo, Pengcheng Zhu, Mengxiao Bi</li>
<li>for: 提高多 speaker Text-to-Speech（TTS）性能</li>
<li>methods: 引入 Consistent Diffusion Model（CDM）生成模型，在训练过程中保证 CDM 的一致性，以避免抽取难点问题</li>
<li>results: 对多 speaker TTS 表现有显著提高，甚至超过了细化调整方法的表现In English:</li>
<li>for: Improving the performance of multi-speaker Text-to-Speech (TTS)</li>
<li>methods: Introducing the Consistent Diffusion Model (CDM) as a generative modeling approach, ensuring the consistency property during training to alleviate the sampling drift problem in the inference stage</li>
<li>results: Significant improvements in multi-speaker TTS performance, outperforming the fine-tuning approach and available audio samples at <a target="_blank" rel="noopener" href="https://welkinyang.github.io/multi-gradspeech/">https://welkinyang.github.io/multi-gradspeech/</a><details>
<summary>Abstract</summary>
Recent advancements in diffusion-based acoustic models have revolutionized data-sufficient single-speaker Text-to-Speech (TTS) approaches, with Grad-TTS being a prime example. However, diffusion models suffer from drift in training and sampling distributions due to imperfect score-matching. The sampling drift problem leads to these approaches struggling in multi-speaker scenarios in practice. In this paper, we present Multi-GradSpeech, a multi-speaker diffusion-based acoustic models which introduces the Consistent Diffusion Model (CDM) as a generative modeling approach. We enforce the consistency property of CDM during the training process to alleviate the sampling drift problem in the inference stage, resulting in significant improvements in multi-speaker TTS performance. Our experimental results corroborate that our proposed approach can improve the performance of different speakers involved in multi-speaker TTS compared to Grad-TTS, even outperforming the fine-tuning approach. Audio samples are available at https://welkinyang.github.io/multi-gradspeech/
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Neural-Architectures-Learning-Fourier-Transforms-Signal-Processing-and-Much-More…"><a href="#Neural-Architectures-Learning-Fourier-Transforms-Signal-Processing-and-Much-More…" class="headerlink" title="Neural Architectures Learning Fourier Transforms, Signal Processing and Much More…."></a>Neural Architectures Learning Fourier Transforms, Signal Processing and Much More….</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10388">http://arxiv.org/abs/2308.10388</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Verma</li>
<li>For: The paper explores the use of neural architectures for learning kernels in Fourier Transform, specifically for audio signal processing applications.* Methods: The paper uses a neural network to learn sinusoidal kernel shapes and discovers various signal-processing properties such as windowing functions, onset detectors, high pass filters, low pass filters, modulations, etc. The neural architecture has a comb filter-like structure on top of the learned kernels.* Results: The paper shows that the neural architecture not only learns sinusoidal kernel shapes but also discovers all kinds of incredible signal-processing properties, such as windowing functions, onset detectors, high pass filters, low pass filters, modulations, etc. The learned kernels can be used for a variety of signal processing tasks, and the content of the kernels can be made adaptive to different inputs.<details>
<summary>Abstract</summary>
This report will explore and answer fundamental questions about taking Fourier Transforms and tying it with recent advances in AI and neural architecture. One interpretation of the Fourier Transform is decomposing a signal into its constituent components by projecting them onto complex exponentials. Variants exist, such as discrete cosine transform that does not operate on the complex domain and projects an input signal to only cosine functions oscillating at different frequencies. However, this is a fundamental limitation, and it needs to be more suboptimal. The first one is that all kernels are sinusoidal: What if we could have some kernels adapted or learned according to the problem? What if we can use neural architectures for this? We show how one can learn these kernels from scratch for audio signal processing applications. We find that the neural architecture not only learns sinusoidal kernel shapes but discovers all kinds of incredible signal-processing properties. E.g., windowing functions, onset detectors, high pass filters, low pass filters, modulations, etc. Further, upon analysis of the filters, we find that the neural architecture has a comb filter-like structure on top of the learned kernels. Comb filters that allow harmonic frequencies to pass through are one of the core building blocks/types of filters similar to high-pass, low-pass, and band-pass filters of various traditional signal processing algorithms. Further, we can also use the convolution operation with a signal to be learned from scratch, and we will explore papers in the literature that uses this with that robust Transformer architectures. Further, we would also explore making the learned kernel's content adaptive, i.e., learning different kernels for different inputs.
</details>
<details>
<summary>摘要</summary>
traducción al chino simplificado:这份报告将探索并回答关于使用傅立叶变换和最新的人工智能和神经网络架构之间的关系的基本问题。傅立叶变换的一种解释是将信号分解成其成分部分，并将它们 proyect onto 复杂的指数函数。 variants exist， such as the discrete cosine transform that does not operate on the complex domain and projects an input signal to only cosine functions oscillating at different frequencies. However, this is a fundamental limitation, and it needs to be more suboptimal. The first one is that all kernels are sinusoidal: What if we could have some kernels adapted or learned according to the problem? What if we can use neural architectures for this? We show how one can learn these kernels from scratch for audio signal processing applications. We find that the neural architecture not only learns sinusoidal kernel shapes but discovers all kinds of incredible signal-processing properties. E.g., windowing functions, onset detectors, high pass filters, low pass filters, modulations, etc. Further, upon analysis of the filters, we find that the neural architecture has a comb filter-like structure on top of the learned kernels. Comb filters that allow harmonic frequencies to pass through are one of the core building blocks/types of filters similar to high-pass, low-pass, and band-pass filters of various traditional signal processing algorithms. Further, we can also use the convolution operation with a signal to be learned from scratch, and we will explore papers in the literature that uses this with that robust Transformer architectures. Further, we would also explore making the learned kernel's content adaptive, i.e., learning different kernels for different inputs.
</details></li>
</ul>
<hr>
<h2 id="Local-Periodicity-Based-Beat-Tracking-for-Expressive-Classical-Piano-Music"><a href="#Local-Periodicity-Based-Beat-Tracking-for-Expressive-Classical-Piano-Music" class="headerlink" title="Local Periodicity-Based Beat Tracking for Expressive Classical Piano Music"></a>Local Periodicity-Based Beat Tracking for Expressive Classical Piano Music</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10355">http://arxiv.org/abs/2308.10355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunnycyc/plpdp4beat">https://github.com/sunnycyc/plpdp4beat</a></li>
<li>paper_authors: Ching-Yu Chiu, Meinard Müller, Matthew E. P. Davies, Alvin Wen-Yu Su, Yi-Hsuan Yang</li>
<li>for: 这个论文是为了探讨现代拍谱系统如何模型拍子的征性，以及如何在西 classical 钢琴音乐中提高拍谱的准确性。</li>
<li>methods: 这个论文使用了两个大的西 classical 钢琴音乐数据集， namely Aligned Scores and Performances (ASAP) 数据集和 Chopin 的 Mazurkas (Maz-5) 数据集，并通过实验表明了现有的拍谱系统在地方拍子变化时的缺陷，因此需要新的方法。这个论文提出了一种新的本地征性基于的拍谱系统，即 predominant local pulse-based dynamic programming (PLPDP) 跟踪方法，它可以更好地考虑地方的拍子变化。</li>
<li>results: 相比现有的拍谱系统，PLPDP 方法可以提高 ASAP 数据集中的 F1-score 从 0.473 提高到 0.493，并在 Maz-5 数据集中提高 F1-score 从 0.595 提高到 0.838。<details>
<summary>Abstract</summary>
To model the periodicity of beats, state-of-the-art beat tracking systems use "post-processing trackers" (PPTs) that rely on several empirically determined global assumptions for tempo transition, which work well for music with a steady tempo. For expressive classical music, however, these assumptions can be too rigid. With two large datasets of Western classical piano music, namely the Aligned Scores and Performances (ASAP) dataset and a dataset of Chopin's Mazurkas (Maz-5), we report on experiments showing the failure of existing PPTs to cope with local tempo changes, thus calling for new methods. In this paper, we propose a new local periodicity-based PPT, called predominant local pulse-based dynamic programming (PLPDP) tracking, that allows for more flexible tempo transitions. Specifically, the new PPT incorporates a method called "predominant local pulses" (PLP) in combination with a dynamic programming (DP) component to jointly consider the locally detected periodicity and beat activation strength at each time instant. Accordingly, PLPDP accounts for the local periodicity, rather than relying on a global tempo assumption. Compared to existing PPTs, PLPDP particularly enhances the recall values at the cost of a lower precision, resulting in an overall improvement of F1-score for beat tracking in ASAP (from 0.473 to 0.493) and Maz-5 (from 0.595 to 0.838).
</details>
<details>
<summary>摘要</summary>
<<SYS>>请将以下文本翻译成简化中文。<</SYS>>现代拍谱系统使用“后处理跟踪器”（PPT）来模拟拍征的周期性，这些PPTs基于一些实际所确定的全球假设，以适应音乐中的稳定拍 tempo。然而，对于表达力强的古典音乐来说，这些假设可能是太僵化了。基于西方古典钢琴音乐的两大数据集， namely Aligned Scores and Performances（ASAP）数据集和钢琴 Mazurkas（Maz-5）数据集，我们报告了现有PPTs在本地拍征变化时的失败，从而需要新的方法。在这篇论文中，我们提出了一种新的本地周期性基于的PPT，即主导性本地拍（PLP）基于的动态规划（DP）跟踪器。PLPDP通过同时考虑检测到的本地周期性和拍动强度来联合考虑本地拍征和全球拍征。因此，PLPDP不依赖于全球拍假设，而是根据本地周期性来跟踪拍征。相比现有PPTs，PLPDP尤其提高了ASAP和Maz-5中的回归值（从0.473提高到0.493）和总体的F1分数（从0.595提高到0.838）。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/21/cs.SD_2023_08_21/" data-id="clltau93x009gcr88ecs4edo5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/21/eess.IV_2023_08_21/" class="article-date">
  <time datetime="2023-08-20T16:00:00.000Z" itemprop="datePublished">2023-08-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/21/eess.IV_2023_08_21/">eess.IV - 2023-08-21 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Extraction-of-Text-from-Optic-Nerve-Optical-Coherence-Tomography-Reports"><a href="#Extraction-of-Text-from-Optic-Nerve-Optical-Coherence-Tomography-Reports" class="headerlink" title="Extraction of Text from Optic Nerve Optical Coherence Tomography Reports"></a>Extraction of Text from Optic Nerve Optical Coherence Tomography Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10790">http://arxiv.org/abs/2308.10790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iyad Majid, Youchen Victor Zhang, Robert Chang, Sophia Y. Wang</li>
<li>for: This study aimed to develop and evaluate rule-based algorithms for extracting text data, including RNFL values and GCC data, from Zeiss Cirrus OCT scan reports.</li>
<li>methods: The study used DICOM files with encapsulated PDF reports, converted them into image files, and used the PaddleOCR Python package for optical character recognition. Rule-based algorithms were designed and optimized for improved performance in extracting RNFL and GCC data.</li>
<li>results: The developed algorithms demonstrated high precision in extracting data from both RNFL and GCC scans, with slightly better precision for the right eye in RNFL extraction and for the left eye in GCC extraction. However, some values presented more challenges in extraction, such as clock hours 5 and 6 for RNFL thickness and signal strength for GCC.Here’s the information in Simplified Chinese text:</li>
<li>for: 这项研究的目的是开发和评估基于规则的算法，以提高从Zeiss Cirrus光子共振成像扫描报告中提取文本数据，包括肾脉层（RNFL）值和其他膝肾细胞计数（GCC）数据。</li>
<li>methods: 该研究使用DICOM文件中嵌入的PDF报告，并将其转换为图像文件，使用Python中的PaddleOCR包进行光学字符识别。研究人员设计了和优化了基于规则的算法，以提高对RNFL和GCC扫描报告中的数据提取精度。</li>
<li>results: 开发的算法在提取RNFL和GCC扫描报告中的数据时显示了高精度。对于右眼，RNFL提取精度较高（OD: 0.9803 vs. OS: 0.9046），对于左眼，GCC提取精度较高（OD: 0.9567 vs. OS: 0.9677）。然而，一些值在提取时存在更大的挑战，如RNFL厚度的时钟小时5和6，以及GCC的信号强度。<details>
<summary>Abstract</summary>
Purpose: The purpose of this study was to develop and evaluate rule-based algorithms to enhance the extraction of text data, including retinal nerve fiber layer (RNFL) values and other ganglion cell count (GCC) data, from Zeiss Cirrus optical coherence tomography (OCT) scan reports. Methods: DICOM files that contained encapsulated PDF reports with RNFL or Ganglion Cell in their document titles were identified from a clinical imaging repository at a single academic ophthalmic center. PDF reports were then converted into image files and processed using the PaddleOCR Python package for optical character recognition. Rule-based algorithms were designed and iteratively optimized for improved performance in extracting RNFL and GCC data. Evaluation of the algorithms was conducted through manual review of a set of RNFL and GCC reports. Results: The developed algorithms demonstrated high precision in extracting data from both RNFL and GCC scans. Precision was slightly better for the right eye in RNFL extraction (OD: 0.9803 vs. OS: 0.9046), and for the left eye in GCC extraction (OD: 0.9567 vs. OS: 0.9677). Some values presented more challenges in extraction, particularly clock hours 5 and 6 for RNFL thickness, and signal strength for GCC. Conclusions: A customized optical character recognition algorithm can identify numeric results from optical coherence scan reports with high precision. Automated processing of PDF reports can greatly reduce the time to extract OCT results on a large scale.
</details>
<details>
<summary>摘要</summary>
目的：本研究的目的是开发和评估基于规则的算法，以提高从Zeiss Cirrus光合成 Tomatoes(OCT)扫描报告中提取文本数据的精度，包括胁肤神经层(RNFL)值和神经细胞计数(GCC)数据。方法：从一所学术眼科中心的临床扫描存储系统中标记为包含DICOM文档的PDF报告，并将PDF报告转换为图像文件，然后使用Python包PaddleOCR进行光学字符识别。基于规则的算法被设计并优化，以提高提取RNFL和GCC数据的精度。评估算法的效果通过手动复审一组RNFL和GCC报告进行评估。结果：开发的算法在RNFL和GCC扫描报告中提取数据的精度很高，OD和OS的精度分别为0.9803和0.9046，以及0.9567和0.9677。但是，某些值在提取中存在更大的挑战，例如RNFL厚度的时钟小时5和6，以及GCC的信号强度。结论：可以使用自定义的光学字符识别算法来从OCT扫描报告中提取数据，并且自动处理PDF报告可以大幅减少大规模提取OCT结果的时间。
</details></li>
</ul>
<hr>
<h2 id="Dense-Error-Map-Estimation-for-MRI-Ultrasound-Registration-in-Brain-Tumor-Surgery-Using-Swin-UNETR"><a href="#Dense-Error-Map-Estimation-for-MRI-Ultrasound-Registration-in-Brain-Tumor-Surgery-Using-Swin-UNETR" class="headerlink" title="Dense Error Map Estimation for MRI-Ultrasound Registration in Brain Tumor Surgery Using Swin UNETR"></a>Dense Error Map Estimation for MRI-Ultrasound Registration in Brain Tumor Surgery Using Swin UNETR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10784">http://arxiv.org/abs/2308.10784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soorena Salari, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao</li>
<li>for: 降低脑肿瘤手术死亡率的早期手术治疗</li>
<li>methods: 使用投射照像（iUS）跟踪脑组织变形，并使用高精度的MRI-iUS匹配技术更新先前的手术计划，以提高手术安全性和效果</li>
<li>results: 提出了一种基于深度学习（DL）的框架，可以自动评估MRI-iUS匹配结果的质量，并在实际临床数据上显示其性能。<details>
<summary>Abstract</summary>
Early surgical treatment of brain tumors is crucial in reducing patient mortality rates. However, brain tissue deformation (called brain shift) occurs during the surgery, rendering pre-operative images invalid. As a cost-effective and portable tool, intra-operative ultrasound (iUS) can track brain shift, and accurate MRI-iUS registration techniques can update pre-surgical plans and facilitate the interpretation of iUS. This can boost surgical safety and outcomes by maximizing tumor removal while avoiding eloquent regions. However, manual assessment of MRI-iUS registration results in real-time is difficult and prone to errors due to the 3D nature of the data. Automatic algorithms that can quantify the quality of inter-modal medical image registration outcomes can be highly beneficial. Therefore, we propose a novel deep-learning (DL) based framework with the Swin UNETR to automatically assess 3D-patch-wise dense error maps for MRI-iUS registration in iUS-guided brain tumor resection and show its performance with real clinical data for the first time.
</details>
<details>
<summary>摘要</summary>
早期手术治疗脑肿的时间点对病人死亡率有重要影响。然而，手术过程中脑组织变形（称为脑Shift）会使先前的图像无效。作为一种cost-effective和可搬式工具，在手术过程中的ultrasound（iUS）可以跟踪脑Shift，并且精准的MRI-iUS注册技术可以更新先前的 планы和促进iUS的解释。这可以提高手术安全性和效果，最大化肿瘤除除而避免感知区域。然而，手动评估MRI-iUS注册结果的实时性具有困难和错误的可能性，因为数据的3D性。自动的算法可以评估多Modal医疗图像注册结果的质量。因此，我们提出了一个基于深度学习（DL）的框架，使用Swin UNITER来自动评估3D-patch-wise稠密错误地图进行MRI-iUS注册的性能，并在实际临床数据上展示其性能。
</details></li>
</ul>
<hr>
<h2 id="Automated-Identification-of-Failure-Cases-in-Organ-at-Risk-Segmentation-Using-Distance-Metrics-A-Study-on-CT-Data"><a href="#Automated-Identification-of-Failure-Cases-in-Organ-at-Risk-Segmentation-Using-Distance-Metrics-A-Study-on-CT-Data" class="headerlink" title="Automated Identification of Failure Cases in Organ at Risk Segmentation Using Distance Metrics: A Study on CT Data"></a>Automated Identification of Failure Cases in Organ at Risk Segmentation Using Distance Metrics: A Study on CT Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10636">http://arxiv.org/abs/2308.10636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Honarmandi Shandiz, Attila Rádics, Rajesh Tamada, Makk Árpád, Karolina Glowacka, Lehel Ferenczi, Sandeep Dutta, Michael Fanariotis</li>
<li>for: 提高自动生成的肿瘤分割精度，以便更好地规划辐射治疗</li>
<li>methods: 使用维度距离和 Hausdorff 距离的组合来自动标识失败案例，从而更快地修复失败案例</li>
<li>results: 通过设置维度距离和 Hausdorff 距离的阈值，能够快速地自动标识失败案例，并且可以对12个不同的失败案例进行视觉评估<details>
<summary>Abstract</summary>
Automated organ at risk (OAR) segmentation is crucial for radiation therapy planning in CT scans, but the generated contours by automated models can be inaccurate, potentially leading to treatment planning issues. The reasons for these inaccuracies could be varied, such as unclear organ boundaries or inaccurate ground truth due to annotation errors. To improve the model's performance, it is necessary to identify these failure cases during the training process and to correct them with some potential post-processing techniques. However, this process can be time-consuming, as traditionally it requires manual inspection of the predicted output. This paper proposes a method to automatically identify failure cases by setting a threshold for the combination of Dice and Hausdorff distances. This approach reduces the time-consuming task of visually inspecting predicted outputs, allowing for faster identification of failure case candidates. The method was evaluated on 20 cases of six different organs in CT images from clinical expert curated datasets. By setting the thresholds for the Dice and Hausdorff distances, the study was able to differentiate between various states of failure cases and evaluate over 12 cases visually. This thresholding approach could be extended to other organs, leading to faster identification of failure cases and thereby improving the quality of radiation therapy planning.
</details>
<details>
<summary>摘要</summary>
自动化器官风险（OAR）分割是辐射疗法规划CT扫描图中的关键，但自动生成的边界可能存在误差，可能导致治疗规划问题。这些误差的原因可能是不清晰的器官边界或者实际数据错误，导致标注错误。为了提高模型的性能，需要在训练过程中识别这些失败案例，并使用一些可能的后处理技术来更正。然而，这个过程可能占用很多时间，因为传统上需要手动检查预测输出。这篇论文提出了一种方法，通过设置Dice和 Hausdorff距离的组合阈值，自动地识别失败案例。这种方法可以减少手动检查预测输出的时间占用，并允许更快地识别失败案例候选者。该方法在20个不同器官的CT图像中进行了20个案例的评估，通过设置阈值，能够分辨出不同类型的失败案例，并评估12个案例。这种阈值设置方法可以扩展到其他器官，从而更快地识别失败案例，提高辐射疗法规划的质量。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Medical-Image-Segmentation-Optimizing-Cross-Entropy-Weights-and-Post-Processing-with-Autoencoders"><a href="#Enhancing-Medical-Image-Segmentation-Optimizing-Cross-Entropy-Weights-and-Post-Processing-with-Autoencoders" class="headerlink" title="Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders"></a>Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10488">http://arxiv.org/abs/2308.10488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranav Singh, Luoyao Chen, Mei Chen, Jinqian Pan, Raviteja Chukkapalli, Shravan Chaudhari, Jacopo Cirrone</li>
<li>for: 本研究旨在提高医学图像分割的精度和效率，特别是在抗体性疾病如皮肤粘液病中分割细胞和炎症的过程中。</li>
<li>methods: 本研究采用深度学习技术，开发了一种适应性能高的医学图像分割方法，并对捷克网络（U-Net）和U-Net++进行了比较。</li>
<li>results: 实验结果表明，本研究的方法在皮肤粘液病图像分割任务上比现有技术高效率12.26%和12.04%。此外，我们还对loss函数权重的优化和三个医学图像分割任务进行了比较。<details>
<summary>Abstract</summary>
The task of medical image segmentation presents unique challenges, necessitating both localized and holistic semantic understanding to accurately delineate areas of interest, such as critical tissues or aberrant features. This complexity is heightened in medical image segmentation due to the high degree of inter-class similarities, intra-class variations, and possible image obfuscation. The segmentation task further diversifies when considering the study of histopathology slides for autoimmune diseases like dermatomyositis. The analysis of cell inflammation and interaction in these cases has been less studied due to constraints in data acquisition pipelines. Despite the progressive strides in medical science, we lack a comprehensive collection of autoimmune diseases. As autoimmune diseases globally escalate in prevalence and exhibit associations with COVID-19, their study becomes increasingly essential. While there is existing research that integrates artificial intelligence in the analysis of various autoimmune diseases, the exploration of dermatomyositis remains relatively underrepresented. In this paper, we present a deep-learning approach tailored for Medical image segmentation. Our proposed method outperforms the current state-of-the-art techniques by an average of 12.26% for U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the dermatomyositis dataset. Furthermore, we probe the importance of optimizing loss function weights and benchmark our methodology on three challenging medical image segmentation tasks
</details>
<details>
<summary>摘要</summary>
医疗图像分割任务具有独特的挑战，需要同时具备本地化和整体 semantics 的理解，以准确地分割关键区域，如病理性组织或异常特征。这种复杂性在医疗图像分割中受到高度的类间相似性、类内变化和可能的图像掩蔽的影响。医疗图像分割任务进一步复杂化，当考虑到研究 histopathology 板块 для自遗护疾病如dermatomyositis时。对于这些病例，分割和检测细胞Inflammation和互动的分析尚未得到了充分的研究，这主要是因为数据获取管道的限制。尽管医学科技在进步的同时，我们缺乏一个完整的自遗护疾病集合。自遗护疾病在全球范围内的发病率不断增长，并与 COVID-19 相关，因此其研究变得越来越重要。虽然现有的研究已经将人工智能 integrate 到了不同的自遗护疾病的分析中，但是dermatomyositis 的研究仍然相对落后。在这篇文章中，我们提出了一种适用于医疗图像分割的深度学习方法。我们的提议方法在 ResNet 家族Encoder 上的 U-Net 和 U-Net++ 中超过了平均提高12.26%和12.04%。此外，我们还评估了优化损失函数的重要性，并在三个困难的医疗图像分割任务上进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Prediction-of-Pneumonia-and-COVID-19-Using-Deep-Neural-Networks"><a href="#Prediction-of-Pneumonia-and-COVID-19-Using-Deep-Neural-Networks" class="headerlink" title="Prediction of Pneumonia and COVID-19 Using Deep Neural Networks"></a>Prediction of Pneumonia and COVID-19 Using Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10368">http://arxiv.org/abs/2308.10368</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. S. Haque, M. S. Taluckder, S. B. Shawkat, M. A. Shahriyar, M. A. Sayed, C. Modak</li>
<li>for: 这个研究旨在探讨医疗图像分析是否可以帮助早期识别感染病毒和细菌所致的肺炎，以便减少其传播。</li>
<li>methods: 这个研究使用机器学习技术来预测肺炎，并评估不同的机器学习模型在肺炎患者的颈部X射线图像上的表现。</li>
<li>results: 研究发现，使用DenseNet121模型可以实现肺炎的准确预测，其准确率为99.58%。这项研究显示了机器学习技术在精确肺炎诊断中的重要性，并提供了这方面的技术传承。<details>
<summary>Abstract</summary>
Pneumonia, caused by bacteria and viruses, is a rapidly spreading viral infection with global implications. Prompt identification of infected individuals is crucial for containing its transmission. This study explores the potential of medical image analysis to address this challenge. We propose machine-learning techniques for predicting Pneumonia from chest X-ray images. Chest X-ray imaging is vital for Pneumonia diagnosis due to its accessibility and cost-effectiveness. However, interpreting X-rays for Pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions. We evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients. Performance measures and confusion matrices are employed to assess and compare the models. The findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%. This study underscores the significance of machine learning in the accurate detection of Pneumonia, leveraging chest X-ray images. Our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics.
</details>
<details>
<summary>摘要</summary>
《肺炎，由病毒和 бактерий引起的，是一种迅速传播的感染病种，具有全球化的意义。》Prompt identification of infected individuals is crucial for containing the transmission of pneumonia. This study explores the potential of medical image analysis to address this challenge. We propose machine-learning techniques for predicting pneumonia from chest X-ray images. Chest X-ray imaging is vital for pneumonia diagnosis due to its accessibility and cost-effectiveness. However, interpreting X-rays for pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions. We evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients. Performance measures and confusion matrices are employed to assess and compare the models. The findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%. This study underscores the significance of machine learning in the accurate detection of pneumonia, leveraging chest X-ray images. Our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics.Here's the text with some notes on the translation:* "肺炎" (pneumonia) is a noun, and it is translated as "肺炎" (pneumonia) in Simplified Chinese.* "由病毒和 бактерий引起" (caused by bacteria and viruses) is a prepositional phrase, and it is translated as "由病毒和 бактерий引起" (caused by bacteria and viruses) in Simplified Chinese.* "是一种迅速传播的感染病种" (a rapidly spreading viral infection) is a sentence, and it is translated as "是一种迅速传播的感染病种" (a rapidly spreading viral infection) in Simplified Chinese.* "Prompt identification of infected individuals is crucial for containing the transmission of pneumonia" is a sentence, and it is translated as "Prompt identification of infected individuals is crucial for containing the transmission of pneumonia" in Simplified Chinese.* "This study explores the potential of medical image analysis to address this challenge" is a sentence, and it is translated as "这种研究探讨了医疗图像分析如何解决这一挑战" (this study explores the potential of medical image analysis to address this challenge) in Simplified Chinese.* "We propose machine-learning techniques for predicting pneumonia from chest X-ray images" is a sentence, and it is translated as "我们提议使用机器学习技术预测肺炎从胸部X射图像" (we propose machine-learning techniques for predicting pneumonia from chest X-ray images) in Simplified Chinese.* "Chest X-ray imaging is vital for pneumonia diagnosis due to its accessibility and cost-effectiveness" is a sentence, and it is translated as "胸部X射图像诊断肺炎具有可行性和成本效益" (chest X-ray imaging is vital for pneumonia diagnosis due to its accessibility and cost-effectiveness) in Simplified Chinese.* "However, interpreting X-rays for pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions" is a sentence, and it is translated as "然而，从X射图像中诊断肺炎可能会具有复杂性，因为肺炎的Radiographic特征可能与其他呼吸道疾病重叠" (however, interpreting X-rays for pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions) in Simplified Chinese.* "We evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients" is a sentence, and it is translated as "我们使用不同的机器学习模型，包括DenseNet121、Inception Resnet-v2、Inception Resnet-v3、Resnet50和Xception，使用肺炎患者的胸部X射图像进行评估" (we evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients) in Simplified Chinese.* "Performance measures and confusion matrices are employed to assess and compare the models" is a sentence, and it is translated as "我们使用性能指标和混淆矩阵来评估和比较不同模型的表现" (performance measures and confusion matrices are employed to assess and compare the models) in Simplified Chinese.* "The findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%" is a sentence, and it is translated as "发现结果表明，DenseNet121模型在识别肺炎方面的准确率为99.58%" (the findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%) in Simplified Chinese.* "This study underscores the significance of machine learning in the accurate detection of pneumonia, leveraging chest X-ray images" is a sentence, and it is translated as "这种研究强调了机器学习在肺炎检测中的重要性，利用胸部X射图像" (this study underscores the significance of machine learning in the accurate detection of pneumonia, leveraging chest X-ray images) in Simplified Chinese.* "Our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics" is a sentence, and it is translated as "我们的研究提供了有关技术在防止肺炎传播的精准诊断方面的洞察" (our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics) in Simplified Chinese.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/21/eess.IV_2023_08_21/" data-id="clltau95h00ebcr882cov25pi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.LG_2023_08_20/" class="article-date">
  <time datetime="2023-08-19T16:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.LG_2023_08_20/">cs.LG - 2023-08-20 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification"><a href="#Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification" class="headerlink" title="Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification"></a>Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10302">http://arxiv.org/abs/2308.10302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhao Zhang, Qianqian Wang, Xiaochuan Wang, Lishan Qiao, Mingxia Liu</li>
<li>for: 这个研究旨在应用Resting-state functional magnetic resonance imaging (rs-fMRI)和 Federated Learning (FL)技术来探索脑疾病的不均衡连接性，并且考虑到体域特点如年龄、性别和教育水准。</li>
<li>methods: 本研究使用了Graph Neural Network (GNN)和 Federated Learning (FL)技术，并且提出了特定性敏感 Federated Graph Learning (SFGL)框架，以探索不同体域特点下的脑疾病特征。</li>
<li>results: 实验结果显示，SFGL方法在两个rs-fMRI数据集上的调整后，较前方的方法提高了10%至20%的准确率。<details>
<summary>Abstract</summary>
Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive approach to examining abnormal brain connectivity associated with brain disorders. Graph neural network (GNN) gains popularity in fMRI representation learning and brain disorder analysis with powerful graph representation capabilities. Training a general GNN often necessitates a large-scale dataset from multiple imaging centers/sites, but centralizing multi-site data generally faces inherent challenges related to data privacy, security, and storage burden. Federated Learning (FL) enables collaborative model training without centralized multi-site fMRI data. Unfortunately, previous FL approaches for fMRI analysis often ignore site-specificity, including demographic factors such as age, gender, and education level. To this end, we propose a specificity-aware federated graph learning (SFGL) framework for rs-fMRI analysis and automated brain disorder identification, with a server and multiple clients/sites for federated model aggregation and prediction. At each client, our model consists of a shared and a personalized branch, where parameters of the shared branch are sent to the server while those of the personalized branch remain local. This can facilitate knowledge sharing among sites and also helps preserve site specificity. In the shared branch, we employ a spatio-temporal attention graph isomorphism network to learn dynamic fMRI representations. In the personalized branch, we integrate vectorized demographic information (i.e., age, gender, and education years) and functional connectivity networks to preserve site-specific characteristics. Representations generated by the two branches are then fused for classification. Experimental results on two fMRI datasets with a total of 1,218 subjects suggest that SFGL outperforms several state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
RESTING-STATE ФУНКЦИОНАЛНО МАГНЕТНО РЕЗОНАНСНА ИМАЖИНГ (RS-fMRI) ПРОВОДИ ГНИЛОСТИВЫЙ ПОДХОД К ИЗУЧЕНИЮ АБНОРМАЛЬНОЙ БРАИНОВОЙ СОЕДИНЕНИЯ ПРОВОДЗЕМ СО БРАИНОВЫМИ РАЗЛИЧИЯМИ. ГРАФОВАЯ НЕРВНАЯ СИСТЕМА (GNN) ЗНАЧАЕТСЯ В ФМРИ ЗАПИСИВАНИЕ И БРАИНОВОЙ РАЗЛИЧИЕВАНИИ СО ВСЕМОГОВОРТНОЙ ГРАФОЙОЙ РЕПРЕСЕНТАЦИЕЙ. ОБУЧЕНИЕ ГЕНЕРАЛЬНОЙ GNN НОВОЕ РЕЗУЛЬТАТО ВОЗМОЖНО СОВЕРШИТЬ БЕЗ ЦЕНТРАЛИЗОВАННОГО МНОГОСИТЕЙНОГО ДАННЫХ, НО ОБЫЧЕСКИЕ ПРОТОКОЛЫ ФЛЕARNING (FL) ДЛЯ ФМРИАНАЛИЗА СНИЖАЮТ ОБЪЕМ ДАННЫХ ПО КОРАБОРАТИВНОМУ ОБЪЕМУ. НО В ПРЕДЫДСТВИИ ТОГО, ПРОПОЛОЖЕННЫЕ ФЛЕARNING (SFGL) ПРОВОДИТ К КОМБИНИРОВАНИЮ МЕСТООБРАЗНЫХ КАРАКТЕРИСТИК ИЗУЧЕНИЯ БРАИНОВОГО РАЗЛИЧИЕВАНИА. В НАШЕМ ФРАМВОРКЕ, МАТЕРИАЛЫ СЕРВЕРА И МУЛЬТИПЛОВЫЕ КЛИЕНТЫ/СИТИ ИСКАЗЫВАТЬСЯ В ФЕДЕРАТИВНОМ ОБЪЕМЕ, ГДЕ ВСЕ КЛИЕНТЫ ПРОВОДЗЕМ ИЗ СЕРВЕРА СОБСТВЕННЫЕ И ПЕРСОНАЛИЗОВАННЫЕ БРАНЧИ. В СОБСТВЕННОМ БРАНЧЕ МЫ ЗЕМЛЯЕМ СПАЦИО-ВРЕМЕННЫЙ ВАТЕРНЫЙ ГРАФОВЫЙ ИЗОМОРФИЗМ КАК РЕПРЕСЕНТАЦИЮ ФМРИ. В ПЕРСОНАЛИЗОВАННЫМ БРАНЧЕ МЫ СОБИРАЕММ ВЕКТОРИЗИРОВАННЫЕ ДЕМОГРАФИЧЕСКИЕ ИЗМЕРЕНИЯ (НАПРИМЕР, ВОСРОД СТОРОК, И УЧЕТ ОБУЧЕНИЯ) И ФУНКЦИОНАЛЬНУЮ СОЕДИНЕННУЮ СИТЬ, ЧТОБЫ ПРЕЗЕРВИТЬ МЕСТООБРАЗНЫЕ КАРАКТЕРИСТИКИ. ЗАПИСИВАННЫЕ В ДВУХ БРАНЧАХ ЗАТОМ СОБИРАЕТСЯ ДЛЯ КЛАССИРОВКИ. ЭКСПЕРИМЕНТАЛЬНЫЕ РЕЗУЛЬТАТЫ ПРОВОДИТЫ КТОРЫМУ, ЧТО SFGL ПРОВОДИТ К БЫСТРОМ И ГОРОДОМ ПОКОВКЕ, ПРОТИВОЗАПИСАНИЮ ИЗУЧЕНИЯ БРАИНОВОГО РАЗЛИЧИЕВАНИА.
</details></li>
</ul>
<hr>
<h2 id="An-interpretable-deep-learning-method-for-bearing-fault-diagnosis"><a href="#An-interpretable-deep-learning-method-for-bearing-fault-diagnosis" class="headerlink" title="An interpretable deep learning method for bearing fault diagnosis"></a>An interpretable deep learning method for bearing fault diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10292">http://arxiv.org/abs/2308.10292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Lu, Austin M. Bray, Chao Hu, Andrew T. Zimmerman, Hongyi Xu</li>
<li>for: 这个研究旨在解决深度学习模型中的黑盒问题，以提高人工维护人员对模型的信任度。</li>
<li>methods: 本研究使用了卷积神经网组合Gradient-weighted Class Activation Mapping（Grad-CAM）来实现深度学习模型的解释和可读性。</li>
<li>results: 研究结果显示，使用Grad-CAM可以从training sample中找到重要的特征对照，并将其annotate为健康库（health library）中的一部分。在评估过程中，提出的方法可以从健康库中选择相似的预测基础样本，以提高模型的可信度。<details>
<summary>Abstract</summary>
Deep learning (DL) has gained popularity in recent years as an effective tool for classifying the current health and predicting the future of industrial equipment. However, most DL models have black-box components with an underlying structure that is too complex to be interpreted and explained to human users. This presents significant challenges when deploying these models for safety-critical maintenance tasks, where non-technical personnel often need to have complete trust in the recommendations these models give. To address these challenges, we utilize a convolutional neural network (CNN) with Gradient-weighted Class Activation Mapping (Grad-CAM) activation map visualizations to form an interpretable DL method for classifying bearing faults. After the model training process, we apply Grad-CAM to identify a training sample's feature importance and to form a library of diagnosis knowledge (or health library) containing training samples with annotated feature maps. During the model evaluation process, the proposed approach retrieves prediction basis samples from the health library according to the similarity of the feature importance. The proposed method can be easily applied to any CNN model without modifying the model architecture, and our experimental results show that this method can select prediction basis samples that are intuitively and physically meaningful, improving the model's trustworthiness for human users.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在最近几年内得到了广泛应用，用于现代工业设备的类型和未来预测。然而，大多数DL模型具有黑盒子组件，其下面结构太复杂，无法被人类用户理解和解释。这些问题在安全维护任务中具有重要性，因为非技术人员经常需要对这些模型的建议产生完全的信任。为解决这些问题，我们使用卷积神经网络（CNN）和梯度权重分类图像（Grad-CAM）活动图像可视化来形成可解释的DL方法，用于分类承载问题。在模型训练过程中，我们使用Grad-CAM来标识训练样本的特征重要性，并将其作为健康图书馆（health library）中的训练样本，并将其标注为特征图像。在评估模型过程中，我们的方法可以从健康图书馆中检索预测基础样本，根据特征重要性的相似性。我们的方法可以轻松地应用于任何CNN模型，无需修改模型结构，我们的实验结果表明，这种方法可以选择Physically meaningful和直观的预测基础样本，提高模型的人类用户的信任度。
</details></li>
</ul>
<hr>
<h2 id="Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi"><a href="#Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi" class="headerlink" title="Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi"></a>Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10284">http://arxiv.org/abs/2308.10284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Nekoei, Xutong Zhao, Janarthanan Rajendran, Miao Liu, Sarath Chandar</li>
<li>for: 这个论文的目的是研究 Cooperative Multi-agent Reinforcement Learning（MARL）算法中的零批合作（ZSC）能力，以及如何提高这种能力以适应复杂的任务和变化的环境。</li>
<li>methods: 该论文使用了一种基于 Hanabi 游戏的实验框架，并定义了一个新的 metric called adaptation regret，用于衡量 MARL 算法的适应能力。</li>
<li>results: 实验结果显示，当将 ZSC 算法与不同的学习方法训练的 Agent 结合时，state-of-the-art ZSC 算法的性能很差，并且需要 millions of interaction samples 来适应这些新的合作伙伴。此外，研究发现，通过调整不同的 hyper-parameter 和设计选择，可以提高 Hanabi 算法的适应能力。<details>
<summary>Abstract</summary>
Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with Zero-Shot Coordination (ZSC) have gained significant attention in recent years. ZSC refers to the ability of agents to coordinate zero-shot (without additional interaction experience) with independently trained agents. While ZSC is crucial for cooperative MARL agents, it might not be possible for complex tasks and changing environments. Agents also need to adapt and improve their performance with minimal interaction with other agents. In this work, we show empirically that state-of-the-art ZSC algorithms have poor performance when paired with agents trained with different learning methods, and they require millions of interaction samples to adapt to these new partners. To investigate this issue, we formally defined a framework based on a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods. In particular, we created a diverse set of pre-trained agents and defined a new metric called adaptation regret that measures the agent's ability to efficiently adapt and improve its coordination performance when paired with some held-out pool of partners on top of its ZSC performance. After evaluating several SOTA algorithms using our framework, our experiments reveal that naive Independent Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC algorithm Off-Belief Learning (OBL). This finding raises an interesting research question: How to design MARL algorithms with high ZSC performance and capability of fast adaptation to unseen partners. As a first step, we studied the role of different hyper-parameters and design choices on the adaptability of current MARL algorithms. Our experiments show that two categories of hyper-parameters controlling the training data diversity and optimization process have a significant impact on the adaptability of Hanabi agents.
</details>
<details>
<summary>摘要</summary>
合作多智能 reinforcement learning（MARL）算法 WITH Zero-Shot Coordination（ZSC）在 recent 年份中受到了关注。 ZSC 指的是无需额外交互经验的 AGENTS 之间的协调。 虽然 ZSC 对协作 MARL 代理人来说非常重要，但在复杂任务和变化环境下可能无法实现。 AGENTS 也需要通过最小化交互amples 来改进其性能。 在这项工作中，我们通过实验表明，当将最新的 ZSC 算法与另外的学习方法训练的 AGENTS 结合时，其性能很差。 为了解释这个问题，我们形式地定义了一个基于流行的合作多智能游戏 Hanabi 的框架，用于评估 MARL 方法的适应性。 具体来说，我们创建了一组多样化的预训练 AGENTS，并定义了一个新的指标called adaptation regret，用于衡量 AGENTS 在与其他另外的合作伙伴交互时的快速适应和改进协调性能。 经过我们的实验，我们发现，在 Hanabi 游戏中，简单的独立 Q-学习（IQL） AGENTS 在大多数情况下可以与 SOTA ZSC 算法 Off-Belief Learning（OBL）相当快地适应。 这一发现提出了一个有趣的研究问题：如何设计 MARL 算法，具有高度的 ZSC 性能和适应不visible 合作伙伴的能力。 作为一个第一步，我们研究了现有 MARL 算法中的不同超参数和设计选择对 Hanabi 代理人的适应性有多大的影响。 我们的实验表明，控制训练数据多样性和优化过程的两类超参数具有重要的影响。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery"><a href="#Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery" class="headerlink" title="Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery"></a>Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10283">http://arxiv.org/abs/2308.10283</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pongpisit-thanasutives/ubic">https://github.com/pongpisit-thanasutives/ubic</a></li>
<li>paper_authors: Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui</li>
<li>For: 本研究提出了一种新的参数 adaptive uncertainty-penalized Bayesian information criterion (UBIC), 用于优先选择含有噪声的空间-时间观察数据的简洁参数化 differential equation (PDE)。* Methods: 本研究使用了一种physics-informed neural network learning的数据驱动方法来验证选择的 PDE 是否具有足够的准确性。* Results: 实验结果表明，UBIC 可以成功地选择真实的管理 PDE，并且发现了对噪声数据的适当处理可以提高模型选择的trade-off。Here’s the same information in English:* For: This study proposes a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms.* Methods: The study uses a physics-informed neural network learning approach to validate the selected PDE flexibly against the other discovered PDE.* Results: Experimental results show that UBIC can successfully select the true governing PDE, and reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity.<details>
<summary>Abstract</summary>
We propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms. Since the naive use of the BIC for model selection has been known to yield an undesirable overfitted PDE, the UBIC penalizes the found PDE not only by its complexity but also the quantified uncertainty, derived from the model supports' coefficient of variation in a probabilistic view. We also introduce physics-informed neural network learning as a simulation-based approach to further validate the selected PDE flexibly against the other discovered PDE. Numerical results affirm the successful application of the UBIC in identifying the true governing PDE. Additionally, we reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity. Code is available at https://github.com/Pongpisit-Thanasutives/UBIC.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的参数适应不确定性加权 bayesian信息条件（UBIC），用于优先选择含有噪声的空间-时间观测数据中的简洁partial differential equation（PDE）。由于直接使用BIC来进行模型选择可能会导致不想要的过拟合PDE，因此UBIC不仅对发现的PDE进行复杂度惩罚，还对其进行量化的不确定性惩罚，从概率视角来看。我们还引入了物理学习神经网络，作为一种基于实验的方法，以验证选择的PDE的可行性。numerical results表明，UBIC成功地实现了选择真实的导导PDE。此外，我们发现了对观测数据进行降噪有助于改善模型复杂度和BIC分数之间的交互效应。代码可以在https://github.com/Pongpisit-Thanasutives/UBIC上获取。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis"><a href="#Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis" class="headerlink" title="Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis"></a>Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10282">http://arxiv.org/abs/2308.10282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suminhan/traffic-uagcrntf">https://github.com/suminhan/traffic-uagcrntf</a></li>
<li>paper_authors: Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee</li>
<li>for: 提高城市交通预测精度，帮助确保公民的安全和便利。</li>
<li>methods: 基于图 convolution deep learning 算法，利用人员活动频率数据从国家家庭旅行调查来增强推理 causal 关系 между活动和交通模式。</li>
<li>results: 对比传统的深度学习模型，该方法实现了状态之 искусственный智能模型，无需增加计算负担。<details>
<summary>Abstract</summary>
Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.
</details>
<details>
<summary>摘要</summary>
traffic prediction 是一个关键的元素，以确保公民的安全和便利。现有的交通预测模型主要采用深度学习架构，以捕捉空间和时间相关性。它们经常忽略交通的本质。具体来说，交通数据集中的感知网络不准确地表示实际行驶的道路网络，失去了对交通模式的探索。为了解决这些限制，我们提出了基于图конvolution深度学习算法的改进交通预测方法。我们利用国家家庭旅行调查中的人类活动频率数据，以提高 causal 关系 между活动和交通模式的推理能力。虽然我们对传统的图 convolutional recurrent networks 和图 convolutional transformer 架构进行了最小的修改，但我们的方法可以在计算开销不增加的情况下达到状态的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023"><a href="#The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023" class="headerlink" title="The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023"></a>The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10281">http://arxiv.org/abs/2308.10281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Cai, Weiqing Wang, Yikang Wang, Ming Li</li>
<li>for: 本文描述了我们在 Audio Deepfake Detection Challenge (ADD 2023) 中的 Track 2 系统，它的目的是识别受修改的音频段。</li>
<li>methods: 我们的方法包括使用多个检测系统来确定受修改的区域和确定其真实性。我们训练并结合了两个帧级系统：一个用于边界检测，另一个用于深伪检测。此外，我们还使用了专门使用真实数据训练的 VAE 模型来确定音频剪辑的真实性。</li>
<li>results: 通过将这三个系统融合，我们的topperforming解决方案在 ADD 挑战中取得了82.23% 的句子准确率和60.66%的 F1 分数，最终的 ADD 分数为0.6713，在 Track 2 中获得了第一名。<details>
<summary>Abstract</summary>
This paper introduces our system designed for Track 2, which focuses on locating manipulated regions, in the second Audio Deepfake Detection Challenge (ADD 2023). Our approach involves the utilization of multiple detection systems to identify splicing regions and determine their authenticity. Specifically, we train and integrate two frame-level systems: one for boundary detection and the other for deepfake detection. Additionally, we employ a third VAE model trained exclusively on genuine data to determine the authenticity of a given audio clip. Through the fusion of these three systems, our top-performing solution for the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1 score of 60.66%. This results in a final ADD score of 0.6713, securing the first rank in Track 2 of ADD 2023.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了我们为Track 2设计的系统，专注于寻找操作区域（splicing regions），在第二届音频深圳检测比赛（ADD 2023）中获得第一名。我们的方法包括多个检测系统的结合，以确定声音片断的真实性。具体来说，我们训练并集成了两个帧级别系统：一个用于边界检测，另一个用于深圳检测。此外，我们还使用专门用于真实数据训练的VAE模型，以确定声音片断的真实性。通过这三种系统的融合，我们在ADD挑战中获得了82.23%的句子准确率和60.66%的F1分数，最终得分为0.6713，在Track 2中排名第一。
</details></li>
</ul>
<hr>
<h2 id="GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning"><a href="#GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning" class="headerlink" title="GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning"></a>GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10279">http://arxiv.org/abs/2308.10279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao, Haibing Guan</li>
<li>for: 这个论文主要是为了解决 Federated Learning (FL) 中的个人化特征提取问题，提出了一种新的个人化 Federated Learning (pFL) 方法，以实现在多客户端上同时学习全局和个人特征信息。</li>
<li>methods: 该方法使用了一种新的特征提取技术，可以同时学习全局和个人特征信息，并在多客户端上进行协同学习。</li>
<li>results: 在六个数据集上进行了三种统计上不同的实验，证明了 GPFL 在效果、可扩展性、公平性、稳定性和隐私方面比十种现有方法更优。此外，GPFL 还可以避免过拟合并超过基eline的提升。<details>
<summary>Abstract</summary>
Federated Learning (FL) is popular for its privacy-preserving and collaborative learning capabilities. Recently, personalized FL (pFL) has received attention for its ability to address statistical heterogeneity and achieve personalization in FL. However, from the perspective of feature extraction, most existing pFL methods only focus on extracting global or personalized feature information during local training, which fails to meet the collaborative learning and personalization goals of pFL. To address this, we propose a new pFL method, named GPFL, to simultaneously learn global and personalized feature information on each client. We conduct extensive experiments on six datasets in three statistically heterogeneous settings and show the superiority of GPFL over ten state-of-the-art methods regarding effectiveness, scalability, fairness, stability, and privacy. Besides, GPFL mitigates overfitting and outperforms the baselines by up to 8.99% in accuracy.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是由于其隐私保护和合作学习能力而受欢迎的。最近，个性化 federated learning (pFL) 已经受到关注，因为它可以 Address statistical heterogeneity 和实现个性化。然而，从特征提取的角度来看，大多数现有的 pFL 方法只是在本地训练中提取全局或个性化特征信息，这不符合 pFL 的协作学习和个性化目标。为解决这个问题，我们提出了一种新的 pFL 方法，名为 GPFL，它可以在每个客户端同时学习全局和个性化特征信息。我们在六个数据集上进行了三种 statistically heterogeneous 的实验，并证明 GPFL 在效果、可扩展性、公平性、稳定性和隐私方面超过了十个现有方法。此外，GPFL 可以 Mitigate overfitting 并超过基eline 的性能。
</details></li>
</ul>
<hr>
<h2 id="Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need"><a href="#Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need" class="headerlink" title="Minimalist Traffic Prediction: Linear Layer Is All You Need"></a>Minimalist Traffic Prediction: Linear Layer Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10276">http://arxiv.org/abs/2308.10276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenyingduan/STLinear">https://github.com/wenyingduan/STLinear</a></li>
<li>paper_authors: Wenying Duan, Hong Rao, Wei Huang, Xiaoxi He</li>
<li>for: 这篇论文是为了解决智能交通系统（ITS）和智能城市的发展中的交通预测问题而写的。</li>
<li>methods: 本论文提出了三个解决方案：节点嵌入方法、时间序列分解和周期学习。它还介绍了一种名为 STLinear 的简单化模型架构，它在计算复杂性和计算负担方面具有明显的优势。</li>
<li>results: 实验表明，STLinear 能够与其他领先的 STGNN 模型匹配或超越其精度，但具有明显的计算复杂性和计算负担减少（相比于2023年的状态艺术 STGNN 基eline，MACs每个epoch减少了超过95%）。<details>
<summary>Abstract</summary>
Traffic prediction is essential for the progression of Intelligent Transportation Systems (ITS) and the vision of smart cities. While Spatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this domain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs or Transformers, they present challenges such as computational complexity, gradient issues, and resource-intensiveness. This paper addresses these challenges, advocating for three main solutions: a node-embedding approach, time series decomposition, and periodicity learning. We introduce STLinear, a minimalist model architecture designed for optimized efficiency and performance. Unlike traditional STGNNs, STlinear operates fully locally, avoiding inter-node data exchanges, and relies exclusively on linear layers, drastically cutting computational demands. Our empirical studies on real-world datasets confirm STLinear's prowess, matching or exceeding the accuracy of leading STGNNs, but with significantly reduced complexity and computation overhead (more than 95% reduction in MACs per epoch compared to state-of-the-art STGNN baseline published in 2023). In summary, STLinear emerges as a potent, efficient alternative to conventional STGNNs, with profound implications for the future of ITS and smart city initiatives.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统（ITS）的核心和智能城市的视野。而 spatial-temporal graph neural networks（STGNNs）在这个领域表现了承诺，通过结合图神经网络（GNNs）和 either RNNs 或 Transformers 来预测交通流。然而，STGNNs 还存在一些挑战，如计算复杂性、梯度问题和资源占用性。这篇文章解决了这些挑战，提出三个主要解决方案：节点嵌入方法、时间序列分解和周期学习。我们介绍了 STLinear，一种最佳化的模型建立，与传统的 STGNNs 不同，STLinear 完全地地方处理，不需要 между节点数据交换，并且仅仅使用线性层，减少了计算需求。我们对实际数据集进行了实验，确认 STLinear 的强大性，与状态之前的 STGNNs 准确性相当或超过，但计算负担减少了超过 95%。总之，STLinear  emerges 为智能交通系统和智能城市initiatives的强大、高效的代替方案。
</details></li>
</ul>
<hr>
<h2 id="SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins"><a href="#SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins" class="headerlink" title="SBSM-Pro: Support Bio-sequence Machine for Proteins"></a>SBSM-Pro: Support Bio-sequence Machine for Proteins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10275">http://arxiv.org/abs/2308.10275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wyzbio/support-bio-sequence-machine">https://github.com/wyzbio/support-bio-sequence-machine</a></li>
<li>paper_authors: Yizheng Wang, Yixiao Zhai, Yijie Ding, Quan Zou</li>
<li>for: 本研究旨在提出一种特制 для生物序列分类的支持机器学习模型（SBSM-Pro），帮助指导生物实验和应用。</li>
<li>methods: 该模型从原始序列开始，根据蛋白质物理化学性质进行氨基酸分组，并使用序列对 alignment 测量蛋白质之间的相似性。它采用了一种新的 MKL 方法，将不同类型的信息集成，使用支持向量机器学习进行分类预测。</li>
<li>results: 研究结果表明，SBSM-Pro 在 10 个数据集中表现出色，在蛋白质功能预测和后转录修饰方面进行了正确的识别。这项研究不仅代表了生物序列分类领域的国际前沿，还开创了新的方向，为生物序列分类平台的开发做出了重要贡献。<details>
<summary>Abstract</summary>
Proteins play a pivotal role in biological systems. The use of machine learning algorithms for protein classification can assist and even guide biological experiments, offering crucial insights for biotechnological applications. We propose a support bio-sequence machine for proteins, a model specifically designed for biological sequence classification. This model starts with raw sequences and groups amino acids based on their physicochemical properties. It incorporates sequence alignment to measure the similarities between proteins and uses a novel MKL approach to integrate various types of information, utilizing support vector machines for classification prediction. The results indicate that our model demonstrates commendable performance across 10 datasets in terms of the identification of protein function and posttranslational modification. This research not only showcases state-of-the-art work in protein classification but also paves the way for new directions in this domain, representing a beneficial endeavour in the development of platforms tailored for biological sequence classification. SBSM-Pro is available for access at http://lab.malab.cn/soft/SBSM-Pro/.
</details>
<details>
<summary>摘要</summary>
生物系统中，蛋白质扮演着关键角色。使用机器学习算法进行蛋白质分类可以帮助和指导生物实验，提供生物技术应用中关键的发现。我们提出了一种专门为蛋白质分类设计的生物序列机器学习模型（SBSM-Pro）。这个模型从原始序列开始，根据蛋白质物理化学性质分组氨基酸。它利用序列对alignment测量蛋白质之间的相似性，并采用一种新的MKL方法集成不同类型的信息，使用支持向量机进行分类预测。结果表明，我们的模型在10个数据集中表现出色地预测蛋白质功能和后转化 modify。这项研究不仅代表了蛋白质分类领域的 estado-of-the-art，还开拓了新的发展方向，代表了一项有利的生物序列分类平台开发的努力。SBSM-Pro可以在http://lab.malab.cn/soft/SBSM-Pro/上下载。
</details></li>
</ul>
<hr>
<h2 id="An-alternative-to-SVM-Method-for-Data-Classification"><a href="#An-alternative-to-SVM-Method-for-Data-Classification" class="headerlink" title="An alternative to SVM Method for Data Classification"></a>An alternative to SVM Method for Data Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11579">http://arxiv.org/abs/2308.11579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning">https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning</a></li>
<li>paper_authors: Lakhdar Remaki</li>
<li>for: 这篇论文是为了提出一种新的分类方法，以解决支持向量机（SVM）的一些缺点。</li>
<li>methods: 该方法使用最小距离到优化的子空间，以确定分类结果。</li>
<li>results: 研究发现，新方法与支持向量机（SVM）的性能相似，但具有轻量级的优势，如减少计算时间、避免优化过程失败、扩展到多类分类、处理不均衡类型和动态分类等问题。<details>
<summary>Abstract</summary>
Support vector machine (SVM), is a popular kernel method for data classification that demonstrated its efficiency for a large range of practical applications. The method suffers, however, from some weaknesses including; time processing, risk of failure of the optimization process for high dimension cases, generalization to multi-classes, unbalanced classes, and dynamic classification. In this paper an alternative method is proposed having a similar performance, with a sensitive improvement of the aforementioned shortcomings. The new method is based on a minimum distance to optimal subspaces containing the mapped original classes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks"><a href="#Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks" class="headerlink" title="Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks"></a>Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10273">http://arxiv.org/abs/2308.10273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Ding, Yongwei Wang, Zuheng Xu<br>for: 这个论文旨在提高Continuous Conditional Generative Adversarial Networks（CcGANs）中的生成模型，使其能够基于连续数值变量（称为回归标签）进行生成。methods: 这个论文提出了一种新的Negative Data Augmentation（NDA）方法，称为Dual-NDA，以解决CcGANs中的问题，即生成低质量的假图像。Dual-NDA使用了两种类型的负样本：来自预训练CcGAN的视觉不真实图像和 manipulate 真实图像的标签。results: 实验表明，Dual-NDA可以提高CcGANs中生成图像的视觉准确性和标签一致性，而且可以超越当前的状态艺术Conditional GANs和扩散模型，达到新的高水平性能。<details>
<summary>Abstract</summary>
Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance.
</details>
<details>
<summary>摘要</summary>
Dual-NDA 使用了两种负样本：由预训练 CcGAN 生成的视觉不可能的图像，以及 manipulate 真实图像的标签以创造的 label-inconsistent 图像。我们利用这些负样本，引入了一种新的识别器目标 alongside 修改后 CcGAN 训练算法。我们的实验表明，使用 Dual-NDA，CcGANs 能够在 UTKFace 和 Steering Angle 上提高假图像的视觉准确性和标签一致性，并且表现出了明显的性能提升。此外，通过应用 Dual-NDA，CcGANs 能够超越现有的 conditional GANs 和扩散模型，达到新的高点性能。
</details></li>
</ul>
<hr>
<h2 id="Large-Transformers-are-Better-EEG-Learners"><a href="#Large-Transformers-are-Better-EEG-Learners" class="headerlink" title="Large Transformers are Better EEG Learners"></a>Large Transformers are Better EEG Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11654">http://arxiv.org/abs/2308.11654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxin Wang, Xiaowen Fu, Yuan Lan, Luchan Zhang, Yang Xiang</li>
<li>for: 这个论文主要针对的是如何将类型变数的电enzephalogram（EEG）资料转换为图像或文本格式，以便使用预训Transformer模型进行预测。</li>
<li>methods: 作者提出了一个名为AdaCE的专案，用于将EEG资料转换为图像或文本格式，并将这些格式与预训Transformer模型进行混合，以便进行预测。</li>
<li>results: 作者的实验结果显示，使用AdaCE模组可以将预训Transformer模型直接 fine-tune 为EEG预测任务，并 achieve state-of-the-art 性能在多种EEG预测任务上。例如，AdaCE在预训Swin-Transformer上 achieve 99.6%，即相对提高9.2%的精度。此外，作者还证明了，将更大的预训模型通过AdaCE进行 fine-tune 可以在EEG预测任务上 achieve better performance。<details>
<summary>Abstract</summary>
Pre-trained large transformer models have achieved remarkable performance in the fields of natural language processing and computer vision. Since the magnitude of available labeled electroencephalogram (EEG) data is much lower than that of text and image data, it is difficult for transformer models pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash the potential of this architecture. In this paper, we show that transformers pre-trained from images as well as text can be directly fine-tuned for EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for Converting EEG data into image as well as text forms, to fine-tune pre-trained vision and language transformers. The proposed AdaCE module is highly effective for fine-tuning pre-trained transformers while achieving state-of-the-art performance on diverse EEG-based prediction tasks. For example, AdaCE on the pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%, on the EEG-decoding task of human activity recognition (UCI HAR). Furthermore, we empirically show that applying the proposed AdaCE to fine-tune larger pre-trained models can achieve better performance on EEG-based predicting tasks, indicating the potential of our adapters for even larger transformers. The plug-and-play AdaCE module can be applied to fine-tuning most of the popular pre-trained transformers on many other time-series data with multiple channels, not limited to EEG data and the models we use. Our code will be available at https://github.com/wangbxj1234/AdaCE.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>大型预训练变换器模型在自然语言处理和计算机视觉领域已经实现了很好的表现。由于电生成ogram（EEG）数据的数量相对较少，预训练后的变换器模型难以达到GPT-4 100T的规模，以全面发挥变换器模型的潜力。在这篇论文中，我们表明了从图像和文本预训练的变换器模型可以直接进行EEG数据适应。我们设计了AdaCE模块，它是一种用于将EEG数据转换为图像和文本形式的插件，以便适应预训练的视觉和语言变换器。我们的AdaCE模块非常有效地进行适应预训练后的变换器模型，并在多种EEG预测任务中达到了状态元的表现。例如，AdaCE在预训练Swin-Transformer上的EEG解码任务上达到了99.6%，相对于基线方法的9.2%提升。此外，我们还证明了在应用我们的AdaCE插件后，可以进行更大的预训练模型的精度调整，这表明了我们的插件在更大的变换器模型上的潜力。插件可以应用于大多数流行的预训练变换器模型上，并不限于EEG数据和我们所用的模型。我们的代码将在https://github.com/wangbxj1234/AdaCE上提供。
</details></li>
</ul>
<hr>
<h2 id="Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking"><a href="#Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking" class="headerlink" title="Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking"></a>Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10255">http://arxiv.org/abs/2308.10255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doğanalp Ergenç, Nurefşan Sertbaş Bülbül, Lisa Maile, Anna Arestova, Mathias Fischer</li>
<li>for: 本文旨在探讨IEEE 802.1时间敏感网络协议在不同的传统系统中的应用，以及使用人工智能和机器学习模型来开发高级配置和维护方法。</li>
<li>methods: 本文提出了一种使用人工智能和机器学习模型来开发高级配置和维护方法的方法，并分析了该方法的主要需求和可行设计。</li>
<li>results: 本文指出，为了推进IEEE 802.1时间敏感网络协议的研究，需要开发一些可靠的TSN数据集，以便训练人工智能和机器学习模型。<details>
<summary>Abstract</summary>
IEEE 802.1 Time-sensitive Networking (TSN) protocols have recently been proposed to replace legacy networking technologies across different mission-critical systems (MCSs). Design, configuration, and maintenance of TSN within MCSs require advanced methods to tackle the highly complex and interconnected nature of those systems. Accordingly, artificial intelligence (AI) and machine learning (ML) models are the most prominent enablers to develop such methods. However, they usually require a significant amount of data for model training, which is not easily accessible. This short paper aims to recapitulate the need for TSN datasets to flourish research on AI/ML-based techniques for TSN systems. Moreover, it analyzes the main requirements and alternative designs to build a TSN platform to synthesize realistic datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data"><a href="#StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data" class="headerlink" title="StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data"></a>StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10253">http://arxiv.org/abs/2308.10253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/icoz69/stablellava">https://github.com/icoz69/stablellava</a></li>
<li>paper_authors: Yanda Li, Chi Zhang, Gang Yu, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei</li>
<li>for: 这些论文的主要研究目标是开发一种能够有效地对应文本和视觉模式的大型自然语言模型（LLM），以便理解人类的指令。</li>
<li>methods: 我们提议一种新的数据收集方法，即同步生成图像和对话，以便对视觉指令进行调整。这种方法利用了生成模型的能力，将文本生成模型和对话生成模型结合起来，以生成多样化和可控的数据集。</li>
<li>results: 我们的研究包括对多个数据集进行了广泛的实验，使用开源的 LLAVA 模型作为我们提议的管道进行测试。我们的结果表明，我们的方法可以明显提高 LLM 的多种常见能力，包括图像生成、对话生成、问题回答、文本生成等。<details>
<summary>Abstract</summary>
The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions. Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these datasets often exhibit domain bias, potentially constraining the generative capabilities of the models. In an effort to mitigate these limitations, we propose a novel data collection methodology that synchronously synthesizes images and dialogues for visual instruction tuning. This approach harnesses the power of generative models, marrying the abilities of ChatGPT and text-to-image generative models to yield a diverse and controllable dataset with varied image content. This not only provides greater flexibility compared to existing methodologies but also significantly enhances several model capabilities. Our research includes comprehensive experiments conducted on various datasets using the open-source LLAVA model as a testbed for our proposed pipeline. Our results underscore marked enhancements across more than ten commonly assessed capabilities,
</details>
<details>
<summary>摘要</summary>
“OpenAI的GPT-4的多模式能力引起了很大的关注，推动了多模式大语言模型（LLM）的研发。这些模型的主要研究目标是在理解人类 instrucion 时，有效地对文本和视觉模式进行对应。现有的方法ologies  oft en rely on来自标准 benchmark dataset 的注释来构建图像对话集 для训练purpose，类似于 instruction tuning 在 LLM 中。然而，这些数据集经常受到领域偏见的影响，可能限制模型的生成能力。为了缓解这些限制，我们提出了一种新的数据采集方法，同时生成图像和对话，以便对视觉 instrucion 进行调整。这种方法利用了生成模型的能力，将文本生成模型和图像生成模型结合起来，生成了多样化和可控的数据集。这不仅提供了现有方法所不具备的灵活性，还显著提高了多种模型能力。我们的研究包括对多个数据集进行了全面的实验，使用开源的 LLAVA 模型作为我们提议的管道测试环境。我们的结果表明，我们的方法在多达十个常评价指标上具有明显的提升。”
</details></li>
</ul>
<hr>
<h2 id="Activation-Addition-Steering-Language-Models-Without-Optimization"><a href="#Activation-Addition-Steering-Language-Models-Without-Optimization" class="headerlink" title="Activation Addition: Steering Language Models Without Optimization"></a>Activation Addition: Steering Language Models Without Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10248">http://arxiv.org/abs/2308.10248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, Monte MacDiarmid</li>
<li>for: 这个论文旨在提出一种可靠地控制大型自然语言模型（LLM）的行为的方法。</li>
<li>methods: 论文使用激活工程（Activation Addition，ActAdd）方法，在推理时添加一个“导航向量”，通过自然语言来隐式地定义。</li>
<li>results: 论文在GPT-2上进行了OpenWebText和ConceptNet的测试，表明ActAdd方法可以在推理时控制输出的高级性质，并且不会影响模型的目标性能。此外，ActAdd方法比超visionfinetuning和人类反馈学习（RLHF）更加快速，需要更少的计算资源和实现努力，同时允许用户提供自然语言指令。<details>
<summary>Abstract</summary>
Reliably controlling the behavior of large language models (LLMs) is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback (RLHF), prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language.   Unlike past work which learned these steering vectors (Subramani, Suresh, and Peters 2022; Hernandez, Li, and Andreas 2023), our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort compared to finetuning or RLHF, allows users to provide natural language specifications, and its overhead scales naturally with model size.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的可靠控制问题仍是一个开放的问题。现有的方法包括监督微调、人工反馈学习（RLHF）、提示工程和导航解码。我们则是活动工程：在推理时修改激活来预测性地改变模型行为。具体来说，我们在前进通过添加“导航向量”来隐式地指定自然语言中的批处理。与过去的工作不同（Subramani et al. 2022；Hernandez et al. 2023），我们的激活添加（ActAdd）方法不是学习这些导航向量，而是通过对提示对的激活差异来计算它们。我们在GPT-2上使用OpenWebText和ConceptNet进行了实验，并证明了ActAdd可以在推理时控制输出的高级性质，并且保持目标模型性能。这种在推理时进行的方法比微调或RLHF需要更少的计算和实现努力，允许用户提供自然语言规范，并且其开销随模型大小呈指数增长。
</details></li>
</ul>
<hr>
<h2 id="From-Global-to-Local-Multi-scale-Out-of-distribution-Detection"><a href="#From-Global-to-Local-Multi-scale-Out-of-distribution-Detection" class="headerlink" title="From Global to Local: Multi-scale Out-of-distribution Detection"></a>From Global to Local: Multi-scale Out-of-distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10239">http://arxiv.org/abs/2308.10239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jimzai/mode-ood">https://github.com/jimzai/mode-ood</a></li>
<li>paper_authors: Ji Zhang, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Hengtao Shen</li>
<li>for: 这个研究的目的是提高OD detection的精度，尤其是在遇到未知数据时。</li>
<li>methods: 这个方法使用了多个缩寸的方法，包括global visual information和local region details，以提高OD detection的精度。</li>
<li>results: 这个方法在多个benchmark上的表现比前一代方法好，具体的表现提高了19.24%在False Positive Rate和2.77%在AUC上。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection aims to detect "unknown" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION (OOD) 检测的目标是检测“未知”数据，其标签在ID 训练过程中没有出现过。随着表征学学习的进步，距离基于 OOD 检测已经得到了广泛应用。然而，过去的方法通常基于全局图像表征，忽略了图像内部的细节信息，这可能会导致同一个ID类型的图像在给定的表征空间中被分化。在这种情况下，我们提出了一个新的框架，即多scale OOD 检测（MODE），它利用全局视觉信息和图像内部的局部区域特征来最大化 OOD 检测的效果。Specifically, we find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details></li>
</ul>
<hr>
<h2 id="Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit"><a href="#Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit" class="headerlink" title="Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit"></a>Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10238">http://arxiv.org/abs/2308.10238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shintaro Nakamura, Masashi Sugiyama</li>
<li>for:  solve the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem, which is to find the optimal action from a finite-sized real-valued action set with as few arm pulls as possible.</li>
<li>methods:  the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in d.</li>
<li>results:  a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.Here are the three information in a more concise format, using bullet points:</li>
<li>for:  solve the R-CPE-MAB problem with a large action set.</li>
<li>methods:  GenTS-Explore algorithm.</li>
<li>results:  a novel problem-dependent sample complexity lower bound, and the GenTS-Explore algorithm achieves the optimal sample complexity up to a constant factor.<details>
<summary>Abstract</summary>
We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.
</details>
<details>
<summary>摘要</summary>
我们研究了实数值的可整合探索多臂枪手问题（R-CPE-MAB）。在R-CPE-MAB中，一个玩家被分配了$d$个随机臂，每个臂$s\in\{1, \ldots, d\}$的奖励follows一个未知分布的mean $\mu_s$。在每个时间步骤中，一个玩家抓一个臂并观察其奖励。玩家的目标是从一个封闭的实数值动作集$\mathcal{A}\subset \mathbb{R}^{d}$中选择最佳的动作 $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$，以最少的臂抓次数为目标。先前的R-CPE-MAB方法假设动作集$\mathcal{A}$的大小是对数函数的$d$。我们介绍了一个名为Generalized Thompson Sampling Explore（GenTS-Explore）算法，这是第一个可以在动作集$\mathcal{A}$的大小是指数增长的$d$时工作的算法。我们还介绍了一个问题内部依赖的样本缩减下限，并证明GenTS-Explore算法实现了问题内部依赖的样本缩减下限。
</details></li>
</ul>
<hr>
<h2 id="FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection"><a href="#FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection" class="headerlink" title="FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection"></a>FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10236">http://arxiv.org/abs/2308.10236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naiftt/fedsis">https://github.com/naiftt/fedsis</a></li>
<li>paper_authors: Naif Alkhunaizi, Koushik Srivatsan, Faris Almalik, Ibrahim Almakky, Karthik Nandakumar</li>
<li>for: 本研究旨在提高面部攻击检测算法（FacePAD）的通用性，解决现有算法的 Achilles heel 问题。</li>
<li>methods: 本研究提出了一种新的框架called Federated Split learning with Intermediate representation Sampling（FedSIS），combines federated learning（FL）和split learning，以保持隐私而实现预测通用性。</li>
<li>results: 研究表明，FedSIS 可以在不需要数据共享的情况下，达到面部攻击检测算法的状态之最游标性表现，并在未见过的频道上实现良好的泛化性。<details>
<summary>Abstract</summary>
Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS
</details>
<details>
<summary>摘要</summary>
缺乏泛化到未经见的领域/攻击是现有的面孔展示攻击检测（FacePAD）算法的 Achilles heel。现有的增强FacePAD解决方案假设有多个源领域的数据可以在单一实体上进行中央式训练。然而，在实践中，来自不同的源领域的数据可能是由不同的实体收集的，这些实体经常因为法律和隐私限制无法共享自己的数据。而合作学习 paradigm such as federated learning（FL）可以解决这个问题，但标准的FL方法在适应新的领域时存在两大挑战：处理非标一Client数据分布在训练中和在推断中适应未经见的领域。在这种情况下，一种名为 Federated Split learning with Intermediate representation Sampling（FedSIS）的新框架被引入，用于保护隐私的领域泛化。在 FedSIS 中，使用一种混合的 Vision Transformer（ViT）架构，通过 combining FL 和 split learning 来实现对Client数据分布的统计异质性的Robustness，而不需要 Client 数据的共享。为了进一步提高适应未经见的领域，一种名为 intermediate representation sampling 的新的特征增强策略被使用，并通过一个共享的 adapter 网络来浓缩出权威信息。FedSIS 方法在两个常用的 cross-domain FacePAD  benchmark 上进行了评估，并证明了可以在没有数据共享情况下实现状态码的泛化性能。代码：https://github.com/Naiftt/FedSIS
</details></li>
</ul>
<hr>
<h2 id="Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling"><a href="#Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling" class="headerlink" title="Karma: Adaptive Video Streaming via Causal Sequence Modeling"></a>Karma: Adaptive Video Streaming via Causal Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10230">http://arxiv.org/abs/2308.10230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fcbw2012/Karma">https://github.com/fcbw2012/Karma</a></li>
<li>paper_authors: Bowei Xu, Hao Chen, Zhan Ma</li>
<li>For: This paper aims to improve the adaptive bitrate (ABR) decision-making process by utilizing causal sequence modeling to comprehend the interrelated causality among past observations, returns, and actions, and timely refining actions when deviations occur.* Methods: The proposed Karma algorithm uses a decision transformer to determine the next action based on a multi-dimensional time series of observations, returns, and actions, with the maximum cumulative future quality of experience (QoE) as an extended return signal.* Results: The paper demonstrates superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions, and strong generalization capabilities under unseen networks in both simulations and real-world tests.Here is the text in Simplified Chinese:* For: 这篇论文目标是通过利用 causal sequence modeling 改善 adaptive bitrate (ABR) 决策过程，以便更好地理解过去观察、返回和行为之间的相互关系，并在偏差发生时及时更新行动。* Methods: 提议的 Karma 算法使用决策转换器来确定下一步行动，基于多维时间序列观察、返回和行动中的观察、返回和行动。* Results: 论文表明，相比现有的状态艺术 ABR 算法，Karma 算法在多种网络条件下表现出较高的平均Quality of Experience（QoE）提升，从10.8% 到18.7%。此外，Karma 算法在未见网络上也显示出了强大的泛化能力。<details>
<summary>Abstract</summary>
Optimal adaptive bitrate (ABR) decision depends on a comprehensive characterization of state transitions that involve interrelated modalities over time including environmental observations, returns, and actions. However, state-of-the-art learning-based ABR algorithms solely rely on past observations to decide the next action. This paradigm tends to cause a chain of deviations from optimal action when encountering unfamiliar observations, which consequently undermines the model generalization. This paper presents Karma, an ABR algorithm that utilizes causal sequence modeling to improve generalization by comprehending the interrelated causality among past observations, returns, and actions and timely refining action when deviation occurs. Unlike direct observation-to-action mapping, Karma recurrently maintains a multi-dimensional time series of observations, returns, and actions as input and employs causal sequence modeling via a decision transformer to determine the next action. In the input sequence, Karma uses the maximum cumulative future quality of experience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is periodically estimated based on current network conditions and playback status. We evaluate Karma through trace-driven simulations and real-world field tests, demonstrating superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions. Furthermore, Karma exhibits strong generalization capabilities, showing leading performance under unseen networks in both simulations and real-world tests.
</details>
<details>
<summary>摘要</summary>
优化的适应比率（ABR）决策需要对状态转移进行全面的特征化，包括时间上的相关Modalities。然而，现有的学习基于ABR算法只是基于过去的观察来决定下一个动作。这种做法会导致对于不熟悉的观察而引起链式偏差，从而下降模型泛化。这篇论文提出了Karma算法，它利用 causal sequence modeling来提高泛化性，通过理解过去观察、返回和动作之间的相关 causality，并在偏差发生时进行时间 opportune 的修正。与直接观察到动作映射不同，Karma 使用循环维护一个多维时间序列，并使用决策变换器来确定下一个动作。在输入序列中，Karma 使用最大累积未来体验质量（QoE）作为延长返回信号，这些信号 periodically 根据当前网络conditions和播放状态来 estimating。我们通过跟踪驱动的 simulations 和实际场景测试评估了Karma，并证明它在不同的网络条件下表现出优于现有状态艺术ABR算法，QoE 提升平均值在10.8%到18.7%之间。此外，Karma 表现出了强大的泛化能力，在未看到的网络上仍然保持领先的表现。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-powered-Combinatorial-Clock-Auction"><a href="#Machine-Learning-powered-Combinatorial-Clock-Auction" class="headerlink" title="Machine Learning-powered Combinatorial Clock Auction"></a>Machine Learning-powered Combinatorial Clock Auction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10226">http://arxiv.org/abs/2308.10226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marketdesignresearch/ml-cca">https://github.com/marketdesignresearch/ml-cca</a></li>
<li>paper_authors: Ermis Soumalias, Jakob Weissteiner, Jakob Heiss, Sven Seuken</li>
<li>for: 这篇论文关注了迭代 combinatorial 拍卖（ICA）的设计。ICA 中的主要挑战在于bundle空间随着物品数量的增加而 exponentiates。</li>
<li>methods: 这篇论文提出了一种基于机器学习（ML）的偏好拟合算法，以便从投标者那里获取最重要的信息。</li>
<li>results: 这篇论文的实验结果表明，相比 combinatorial clock auction（CCA），我们的 ML-based demand query mechanism在各个频谱拍卖领域中表现出了显著的高效性。它在一个较小的数量的拍卖轮次中达到了更高的效率，并且使用线性价格时可以达到了巨大的清算潜力。因此，这篇论文 bridge了研究和实践之间的差距，并提出了首个实用的 ML-powered ICA。<details>
<summary>Abstract</summary>
We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what is your most preferred bundle of items?''). We make two key technical contributions: First, we present a novel method for training an ML model on demand queries. Second, based on those trained ML models, we introduce an efficient method for determining the demand query with the highest clearing potential, for which we also provide a theoretical foundation. We experimentally evaluate our ML-based demand query mechanism in several spectrum auction domains and compare it against the most established real-world ICA: the combinatorial clock auction (CCA). Our mechanism significantly outperforms the CCA in terms of efficiency in all domains, it achieves higher efficiency in a significantly reduced number of rounds, and, using linear prices, it exhibits vastly higher clearing potential. Thus, with this paper we bridge the gap between research and practice and propose the first practical ML-powered ICA.
</details>
<details>
<summary>摘要</summary>
我们研究Iterative Combinatorial Auctions（ICA）的设计。ICA的主要挑战在于bundle空间随着物品数量的增加而增加 exponentially。为了解决这个问题，一些最近的论文已经提出了基于机器学习（ML）的偏好探索算法，以探索供应商对不同套件的偏好。然而，从实践的角度来看，这些设计都是通过值询问（i.e.,“What is your value for the bundle $\{A,B\}$?”）来探索供应商的偏好，这种方法在实际应用中被视为不实际。在这篇论文中，我们解决这个问题，通过设计一个基于ML的套件时钟拍卖，通过需求询问（i.e.,“At prices $p$, what is your most preferred bundle of items?”）来探索供应商的偏好。我们的研究做出了两个关键技术贡献：首先，我们提出了一种新的需求询问训练ML模型的方法；其次，基于这些训练的ML模型，我们引入了一种高效的需求询问找到最高清算潜力的方法，并提供了理论基础。我们在几个频谱拍卖领域进行了实验评估，与现有最具実际应用的ICA：套件时钟拍卖（CCA）进行比较。我们的机制在所有领域中都有着明显的高效性，在许多领域中，它在许多更少的轮数中达到了更高的高效性，并且使用线性价格，它的清算潜力是极大的。因此，这篇论文通过实践和理论的研究，提出了第一个实际应用的ML-Powered ICA。
</details></li>
</ul>
<hr>
<h2 id="Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL"><a href="#Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL" class="headerlink" title="Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL"></a>Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10203">http://arxiv.org/abs/2308.10203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechen Zhang, Jian Sun, Gang Wang, Zhuo Li, Wei Chen</li>
<li>for: 解决连续控制问题中的维度爆炸问题</li>
<li>methods: combines soft RL和actor-critic技术，独立地对每个动作维度进行柔化，使用共享批处理网络来最大化柔化$Q$-函数</li>
<li>results: 在多种连续控制任务中，比如Mujoco的人工智能和Box2d的两脚行走器，实验结果表明我们提出的方法可以超越现有的连续RL算法表现。<details>
<summary>Abstract</summary>
Discrete reinforcement learning (RL) algorithms have demonstrated exceptional performance in solving sequential decision tasks with discrete action spaces, such as Atari games. However, their effectiveness is hindered when applied to continuous control problems due to the challenge of dimensional explosion. In this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods to overcome this limitation. SDPC discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. This novel approach enables SDPC to support two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments, we demonstrate that our proposed approach outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate the effectiveness of the SDPC architecture in addressing the challenges associated with continuous control.
</details>
<details>
<summary>摘要</summary>
离散强化学习（RL）算法在解决顺序决策任务中的离散动作空间方面表现出色，如Atari游戏。然而，当应用于连续控制问题时，它们的效iveness受到维度爆炸的挑战。在这篇论文中，我们提出了软分解策略-批评（SDPC）架构，它将离散RL和演员-批评技术与离散RL方法相结合，以解决这一问题。SDPC独立地对每个动作维度进行分解，并使用共享批评网络来最大化软Q函数。这种新的方法使得SDPC支持两种策略：分解演员，导致Soft Decomposed Actor-Critic（SDAC）算法，以及分解Q网络，生成Boltzmann软探索策略，导致Soft Decomposed-Critic Q（SDCQ）算法。我们通过广泛的实验表明，我们提出的方法在多种连续控制任务中比州前的连续RL算法表现出色，包括Mujoco的人iform和Box2d的BipedalWalker。这些实验结果证明了SDPC架构在连续控制问题中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks"><a href="#Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks" class="headerlink" title="Hiding Backdoors within Event Sequence Data via Poisoning Attacks"></a>Hiding Backdoors within Event Sequence Data via Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10201">http://arxiv.org/abs/2308.10201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev</li>
<li>for: 这个论文旨在描述如何在金融业中使用深度学习模型，同时解决这些模型受到恶意攻击的问题。</li>
<li>methods: 这个论文使用了一种名为“潜藏后门”的方法，通过在训练过程中插入一个隐藏的攻击点来引入攻击性质的模型。</li>
<li>results:  experiments 表明，这种方法可以在不同的 dataset、架构和模型组件上实现攻击，并且可以让模型在检测攻击时保持正常的功能。<details>
<summary>Abstract</summary>
The financial industry relies on deep learning models for making important decisions. This adoption brings new danger, as deep black-box models are known to be vulnerable to adversarial attacks. In computer vision, one can shape the output during inference by performing an adversarial attack called poisoning via introducing a backdoor into the model during training. For sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.
</details>
<details>
<summary>摘要</summary>
Financial industry 使用深度学习模型作重要决策，这种采用带来新的危险，深度黑盒模型容易受到抗击攻击。在计算机视觉中，可以在推理过程中Shape the outputby performing an adversarial attack called poisoning via introducing a backdoor into the model during training. However, for sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan, Hong Kong, and other regions.
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management"><a href="#Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management" class="headerlink" title="Deep Reinforcement Learning for Artificial Upwelling Energy Management"></a>Deep Reinforcement Learning for Artificial Upwelling Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10199">http://arxiv.org/abs/2308.10199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Zhang, Wei Fan</li>
<li>for: 这篇论文旨在探讨人工上升（Artificial Upwelling，AU）技术是否能够提高海洋抑 carbon 储存，以及AU 系统如何 efficiently 运行。</li>
<li>methods: 该论文提出了一种使用深度强化学习（Deep Reinforcement Learning，DRL）算法来开发高效的 AU 系统操作策略。</li>
<li>results: 通过大量的 simulations，该论文表明了 DRL 算法比传统的规则型approaches和其他 DRL 算法更有效率地减少能源浪费，同时确保 AU 系统的稳定和高效操作。<details>
<summary>Abstract</summary>
The potential of artificial upwelling (AU) as a means of lifting nutrient-rich bottom water to the surface, stimulating seaweed growth, and consequently enhancing ocean carbon sequestration, has been gaining increasing attention in recent years. This has led to the development of the first solar-powered and air-lifted AU system (AUS) in China. However, efficient scheduling of air injection systems remains a crucial challenge in operating AUS, as it holds the potential to significantly improve system efficiency. Conventional approaches based on rules or models are often impractical due to the complex and heterogeneous nature of the marine environment and its associated disturbances. To address this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details>
<details>
<summary>摘要</summary>
人工升浮（AU）的潜在作用是将有营养物质的底水升到表层，促进海藻生长，从而提高海洋碳储存量。在最近几年中，AU在中国已经开始研发首个太阳能驱动、空气升降系统（AUS）。然而，AU系统的有效调度仍然是一个主要挑战，因为它们的 marine 环境复杂且多样化，以及其关联的干扰。为 Addressing this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details></li>
</ul>
<hr>
<h2 id="ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning"><a href="#ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning" class="headerlink" title="ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning"></a>ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10193">http://arxiv.org/abs/2308.10193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Sarkar, Dongning Guo, Danijela Cabric</li>
<li>for: 这个研究旨在帮助无线网络中的输送器预测电磁环境，以提高无线网络的多样性和可靠性。</li>
<li>methods: 这个研究使用了一个新的、受到监督学习的框架，即ProSpire，以实现对输送器的探测。ProSpire 利用了一个叫做 RSSu-net 的深度学习方法，实现了对输送器的预测。</li>
<li>results: 这个研究获得了reasonable的实验结果，其中预测误差为5 dB的平均绝对误差，与其他相关方法相当。此外，ProSpire 可以实现对输送器的探测，使其可以在97%的机会下不会导致干扰。相比之下，RSSu-net 的性能比其他相似方法更好，增加了19%的可能性。<details>
<summary>Abstract</summary>
Spatial prediction of the radio propagation environment of a transmitter can assist and improve various aspects of wireless networks. The majority of research in this domain can be categorized as 'reactive' spatial prediction, where the predictions are made based on a small set of measurements from an active transmitter whose radio environment is to be predicted. Emerging spectrum-sharing paradigms would benefit from 'proactive' spatial prediction of the radio environment, where the spatial predictions must be done for a transmitter for which no measurement has been collected.   This paper proposes a novel, supervised deep learning-based framework, ProSpire, that enables spectrum sharing by leveraging the idea of proactive spatial prediction. We carefully address several challenges in ProSpire, such as designing a framework that conveniently collects training data for learning, performing the predictions in a fast manner, enabling operations without an area map, and ensuring that the predictions do not lead to undesired interference. ProSpire relies on the crowdsourcing of transmitters and receivers during their normal operations to address some of the aforementioned challenges. The core component of ProSpire is a deep learning-based image-to-image translation method, which we call RSSu-net. We generate several diverse datasets using ray tracing software and numerically evaluate ProSpire. Our evaluations show that RSSu-net performs reasonably well in terms of signal strength prediction, 5 dB mean absolute error, which is comparable to the average error of other relevant methods. Importantly, due to the merits of RSSu-net, ProSpire creates proactive boundaries around transmitters such that they can be activated with 97% probability of not causing interference. In this regard, the performance of RSSu-net is 19% better than that of other comparable methods.
</details>
<details>
<summary>摘要</summary>
通过预测广播环境，可以提高无线网络的多种方面。大多数研究在这个领域是“反应式”的预测，基于活动发送器的 радио环境进行预测。然而，新兴的spectrum-sharing paradigms需要“积极”的预测，预测发送器没有收集过数据。这篇论文提出了一种新的、深度学习基于的框架，名为ProSpire，它利用了积极预测的想法。我们仔细解决了一些挑战，例如如何便捷地收集训练数据，在快速方式进行预测，不需要地图，以及预测不导致不必要的干扰。ProSpire通过在正常运行时 solicit 发送器和接收器来解决一些上述挑战。核心组件是一种基于图像至图像翻译的深度学习方法，我们称之为RSSu-net。我们使用 ray tracing 软件生成了多种多样的数据集，并 numerically 评估了ProSpire。我们的评估结果表明，RSSu-net在信号强度预测方面表现reasonably well，相比其他相关方法的平均误差为5 dB。这意味着ProSpire可以创建积极的边界，使 transmitter 有97%的概率不会导致干扰。这种性能比其他相似方法高出19%。
</details></li>
</ul>
<hr>
<h2 id="Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games"><a href="#Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games" class="headerlink" title="Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games"></a>Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10188">http://arxiv.org/abs/2308.10188</a></li>
<li>repo_url: None</li>
<li>paper_authors: The Viet Bui, Tien Mai, Thanh Hong Nguyen</li>
<li>for: 本研究旨在Addressing the challenges of training agents in multi-agent competitive games, particularly in mitigating uncertainties in game dynamics.</li>
<li>methods: 我们提出了一种新的多体学习模型，可以预测对手的下一步行动，基于隐藏的对手行动和本地观察。此外，我们还提出了一种新的多体强化学习算法，可以结合我们的模型和策略训练进行一起训练。</li>
<li>results: 我们在三个复杂的游戏环境中进行了广泛的实验，包括SMACv2。实验结果表明，我们的方法可以比现有的多体RL算法 achieve superior performance.<details>
<summary>Abstract</summary>
Training agents in multi-agent competitive games presents significant challenges due to their intricate nature. These challenges are exacerbated by dynamics influenced not only by the environment but also by opponents' strategies. Existing methods often struggle with slow convergence and instability. To address this, we harness the potential of imitation learning to comprehend and anticipate opponents' behavior, aiming to mitigate uncertainties with respect to the game dynamics. Our key contributions include: (i) a new multi-agent imitation learning model for predicting next moves of the opponents -- our model works with hidden opponents' actions and local observations; (ii) a new multi-agent reinforcement learning algorithm that combines our imitation learning model and policy training into one single training process; and (iii) extensive experiments in three challenging game environments, including an advanced version of the Star-Craft multi-agent challenge (i.e., SMACv2). Experimental results show that our approach achieves superior performance compared to existing state-of-the-art multi-agent RL algorithms.
</details>
<details>
<summary>摘要</summary>
training 多个代理人在多代理人竞争游戏中存在巨大的挑战，这些挑战受到环境以及对手策略的影响。现有方法经常受到慢性和不稳定性的影响。为了解决这些问题，我们利用仿制学来理解和预测对手的行为，以降低与游戏动力学有关的不确定性。我们的关键贡献包括：(i) 一种新的多个代理人仿制学模型，用于预测对手的下一步行动，该模型可以处理隐藏的对手行动和地方观察。(ii) 一种新的多个代理人 reinforcement learning 算法，将我们的仿制学模型和策略训练集成在一起，以实现单一的训练过程。(iii) 在三个复杂的游戏环境中进行了广泛的实验，包括 Star-Craft 多代理人挑战（SMACv2）的高级版本。实验结果表明，我们的方法可以与现有的多代理人 RL 算法相比，实现更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics"><a href="#Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics" class="headerlink" title="Quantization-based Optimization with Perspective of Quantum Mechanics"></a>Quantization-based Optimization with Perspective of Quantum Mechanics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11594">http://arxiv.org/abs/2308.11594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinwuk Seok, Changsik Cho</li>
<li>for: 本研究旨在探讨量子逻辑如何应用于全球优化问题中，提供一种新的研究框架。</li>
<li>methods: 本文使用量子谱分法对全球优化问题进行分析，揭示了量子力学中允许全球优化的特性。</li>
<li>results: 实验结果表明，量子谱分法中的 Tunneling 效应可以使得找到局部最优点的问题逃脱局部最优点，并且这种效应与量子力学基础的全球优化问题相同。<details>
<summary>Abstract</summary>
Statistical and stochastic analysis based on thermodynamics has been the main analysis framework for stochastic global optimization. Recently, appearing quantum annealing or quantum tunneling algorithm for global optimization, we require a new researching framework for global optimization algorithms. In this paper, we provide the analysis for quantization-based optimization based on the Schr\"odinger equation to reveal what property in quantum mechanics enables global optimization. We present that the tunneling effect derived by the Schr\"odinger equation in quantization-based optimization enables to escape of a local minimum. Additionally, we confirm that this tunneling effect is the same property included in quantum mechanics-based global optimization. Experiments with standard multi-modal benchmark functions represent that the proposed analysis is valid.
</details>
<details>
<summary>摘要</summary>
基于热力学的统计学和随机分析已经是全球优化的主要分析框架。在最近，量子气体或量子隧道算法在全球优化中出现，我们需要一个新的研究框架来探讨全球优化算法。在这篇论文中，我们提供了量子化基于Schrödinger方程的优化分析，以探索量子力学中允许全球优化的属性。我们发现，通过Schrödinger方程中的隧道效应，可以在量子化基于优化中突破本地最小值。此外，我们证明这种隧道效应与量子力学基于全球优化中的同一性。通过对标准多模式函数的实验，我们证明了我们的分析的有效性。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective"><a href="#Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective" class="headerlink" title="Rethinking Client Drift in Federated Learning: A Logit Perspective"></a>Rethinking Client Drift in Federated Learning: A Logit Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10162">http://arxiv.org/abs/2308.10162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Mang Ye, Wangmeng Zuo, Ping Li, Rick Siow Mong Goh, Lei Zhu, C. L. Philip Chen</li>
<li>for: 这个研究是为了解决 Federated Learning (FL) 中 Client Drift 问题，并提高 FL 的性能。</li>
<li>methods: 本研究使用了一个新的 Class prototype Similarity Distillation (FedCSD) 算法，将本地和全球模型进行对预。 FedCSD 不仅将全球知识转移到本地客户端，因为一个未熟悉的全球模型无法提供可靠的知识，即类别相似性信息。而是将本地征推与全球原型之间的相似性用于对预。</li>
<li>results: 实验结果显示，FedCSD 在不同的多 клиєн端数据设定下表现更好，并且可以避免 Catastrophic Forgetting 问题。<details>
<summary>Abstract</summary>
Federated Learning (FL) enables multiple clients to collaboratively learn in a distributed way, allowing for privacy protection. However, the real-world non-IID data will lead to client drift which degrades the performance of FL. Interestingly, we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance. This is mainly due to catastrophic forgetting caused by data heterogeneity between clients. To alleviate this problem, we propose a new algorithm, named FedCSD, a Class prototype Similarity Distillation in a federated framework to align the local and global models. FedCSD does not simply transfer global knowledge to local clients, as an undertrained global model cannot provide reliable knowledge, i.e., class similarity information, and its wrong soft labels will mislead the optimization of local models. Concretely, FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype. To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models, thereby preventing them to mislead local optimization. Extensive experiments demonstrate the superiority of our method over the state-of-the-art federated learning approaches in various heterogeneous settings. The source code will be released.
</details>
<details>
<summary>摘要</summary>
受欢迎的 Federated Learning (FL) 技术允许多个客户端共同学习，以保护隐私。然而，在实际世界中，客户端数据不够一致，导致客户端漂移，从而下降 FL 性能。我们发现，在不断更新模型时，本地和全球模型之间的差异在逐渐增加，从而严重降低 FL 性能。这主要是由于客户端数据不同性导致的慢速忘记。为解决这问题，我们提出了一种新的算法，即 FedCSD，它是一种基于联合类prototype similarity distillation的联邦框架，用于对本地和全球模型进行对齐。FedCSD不仅将全球知识传递给本地客户端，因为一个受训练不充分的全球模型无法提供可靠的类 similarity 信息，而且其错误的软标签会mislead本地优化。具体来说，FedCSD 引入一种类 prototype similarity distillation，用于对本地征标与全球 проtotypes 之间的类 similarity进行对齐。为提高全球征标的质量，FedCSD 采用了一种适应性掩模，以过滤全球模型的差异化软标签，从而避免它们对本地优化产生负面影响。我们的实验表明，FedCSD 在不同的异质设置下表现出优于当前 state-of-the-art 联邦学习方法。我们将源代码发布。
</details></li>
</ul>
<hr>
<h2 id="Resource-Adaptive-Newton’s-Method-for-Distributed-Learning"><a href="#Resource-Adaptive-Newton’s-Method-for-Distributed-Learning" class="headerlink" title="Resource-Adaptive Newton’s Method for Distributed Learning"></a>Resource-Adaptive Newton’s Method for Distributed Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10154">http://arxiv.org/abs/2308.10154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuzhen Chen, Yuan Yuan, Youming Tao, Zhipeng Cai, Dongxiao Yu</li>
<li>for: 这篇论文是用于探讨分布式随机优化方法，特别是以新顿方法为基础，以提高性能。</li>
<li>methods: 这篇论文使用了一种名为RANL的新型和有效的算法，它利用了简单的希腊矩来初始化，并通过自适应训练区域的分配来解决新顿方法的问题。</li>
<li>results: 这篇论文的结果显示了RANL算法在数据不均匀和训练资料组件复杂的情况下仍然能够实现线性的快速减退。此外，RANL算法还能够自动适应可用资源，以确保高效率。<details>
<summary>Abstract</summary>
Distributed stochastic optimization methods based on Newton's method offer significant advantages over first-order methods by leveraging curvature information for improved performance. However, the practical applicability of Newton's method is hindered in large-scale and heterogeneous learning environments due to challenges such as high computation and communication costs associated with the Hessian matrix, sub-model diversity, staleness in training, and data heterogeneity. To address these challenges, this paper introduces a novel and efficient algorithm called RANL, which overcomes the limitations of Newton's method by employing a simple Hessian initialization and adaptive assignments of training regions. The algorithm demonstrates impressive convergence properties, which are rigorously analyzed under standard assumptions in stochastic optimization. The theoretical analysis establishes that RANL achieves a linear convergence rate while effectively adapting to available resources and maintaining high efficiency. Unlike traditional first-order methods, RANL exhibits remarkable independence from the condition number of the problem and eliminates the need for complex parameter tuning. These advantages make RANL a promising approach for distributed stochastic optimization in practical scenarios.
</details>
<details>
<summary>摘要</summary>
新类的分布式数据估计方法，基于牛顿法，可以实现更好的性能，但是它实际应用在大规模和多标的学习环境中受到一些挑战，例如牛顿矩阵的计算和通信成本高昂，模型多标的问题，训练过程中的偏预设问题，数据多标性。为了解决这些挑战，本文提出了一个新的和高效的算法，叫做RANL，它可以超越牛顿法的限制，通过简单的牛顿矩阵初始化和自适应的训练区域分配。这个算法在标准假设下进行了严谨的分析，证明了RANL可以在线性几何中实现快速的渐近稳定。不同于传统的首项方法，RANL不受问题的条件数值影响，并且不需要复杂的参数调整。这些优点使RANL成为实际应用中的分布式数据估计方法。
</details></li>
</ul>
<hr>
<h2 id="Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades"><a href="#Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades" class="headerlink" title="Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades"></a>Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10909">http://arxiv.org/abs/2308.10909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Attih</li>
<li>for: 这项研究旨在 investigate Ghana 四大城市的长期温度趋势，以了解地方气候变化的影响和政策制定的依据。</li>
<li>methods: 该研究使用 NASA 的 Prediction of Worldwide Energy Resource (POWER) 数据，并使用统计分析和 XGBoost 机器学习算法来预测温度变化。 地表温度 profiling 图表从 RSLab 平台生成，以提高准确性。</li>
<li>results: 研究发现各城市都有本地气候变化趋势，特别是工业化的 Accra 显示明显的升高趋势。 涉及人口因素不显著。 XGBoost 模型的低 Root Mean Square Error (RMSE) 分数表明其能够准确地捕捉温度模式。 Wa  unexpectedly 的平均温度最高。 预计2023 中期 Accra 的平均温度为 27.86℃，Kumasi 为 27.15℃， Kete-Krachi 为 29.39℃， Wa 为 30.76℃。这些结果可以帮助气候变化策略的制定和实施。<details>
<summary>Abstract</summary>
Global warming's impact on high temperatures in various parts of the world has raised concerns. This study investigates long-term temperature trends in four major Ghanaian cities representing distinct climatic zones. Using NASA's Prediction of Worldwide Energy Resource (POWER) data, statistical analyses assess local climate warming and its implications. Linear regression trend analysis and eXtreme Gradient Boosting (XGBoost) machine learning predict temperature variations. Land Surface Temperature (LST) profile maps generated from the RSLab platform enhance accuracy. Results reveal local warming trends, particularly in industrialized Accra. Demographic factors aren't significant. XGBoost model's low Root Mean Square Error (RMSE) scores demonstrate effectiveness in capturing temperature patterns. Wa unexpectedly has the highest mean temperature. Estimated mean temperatures for mid-2023 are: Accra 27.86{\deg}C, Kumasi 27.15{\deg}C, Kete-Krachi 29.39{\deg}C, and Wa 30.76{\deg}C. These findings improve understanding of local climate warming for policymakers and communities, aiding climate change strategies.
</details>
<details>
<summary>摘要</summary>
全球气候变化对各地高温的影响已引发了关注。这项研究对四个加纳城市进行了长期气温趋势分析，这些城市代表了不同的气候区。使用NASA的Prediction of Worldwide Energy Resource（POWER）数据，统计分析评估了地方气候变暖的影响。线性回归方法和极限梯度提升（XGBoost）机器学习方法预测温度变化。RSLab平台生成的土地表面温度（LST）profile图表提高了准确性。结果显示了地方气候变暖趋势，特别是工业化的阿克拉。人口因素没有显著影响。XGBoost模型的低根据平方误差（RMSE）得分表明其能够准确捕捉温度模式。意外地，华有最高的平均温度。预计2023年中的温度为：阿克拉27.86℃，库马西27.15℃，别克拉29.39℃，和华30.76℃。这些发现可以帮助气候变化策略的制定和社区的决策。
</details></li>
</ul>
<hr>
<h2 id="OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision"><a href="#OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision" class="headerlink" title="OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision"></a>OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10146">http://arxiv.org/abs/2308.10146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shujie Zhang, Tianyue Zheng, Zhe Chen, Jingzhi Hu, Abdelwahed Khamis, Jiajun Liu, Jun Luo<br>for: occluded hand pose estimationmethods: RF-vision and adversarial learningresults: comparable accuracy to CM-HPE under normal conditions, maintains accuracy in occluded scenarios, generalizable to new domains.Here’s the simplified Chinese text:for:  occluded手势识别methods: RF-vision和对抗学习results: 与CM-HPE在正常情况下具有相同的准确率，在遮盖情况下保持准确率，并能在新领域中普适应用.<details>
<summary>Abstract</summary>
Hand Pose Estimation (HPE) is crucial to many applications, but conventional cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as cameras cannot capture occluded objects. In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging given its human incomprehensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via adversarial learning, enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.
</details>
<details>
<summary>摘要</summary>
手势识别（HPE）是许多应用程序的关键，但传统的相机基于CM-HPE方法是完全依赖于直线视野（LoS），因为相机无法捕捉遮盖物体。在这篇论文中，我们提议利用Radio-Frequency-Vision（RF-vision）来绕过障碍物实现遮盖物体HPE，并介绍了OCHID-Fi作为首个RF-HPE方法，具有3D手势 pose estimation能力。OCHID-Fi利用了广泛可用的智能设备（如iPhone）上的宽频RF传感器来探测3D人手势 pose和其骨架，并在障碍物下实现了高精度的手势识别。为了解决RF图像标注的挑战，OCHID-Fi采用了交叉模式和交叉领域训练过程。它使用了预训练的CM-HPE网络和同步CM/RF数据集，以导引其复杂的RF-HPE网络在LoS条件下进行训练。它还通过对LoS频谱频谱中的标注进行反向传播学习，使OCHID-Fi能够在未看到障碍物的情况下泛化到新领域。实验结果表明，OCHID-Fi具有较高的精度和泛化能力，可以在正常情况下与CM-HPE具有相同的精度，而在障碍物下仍然保持高精度，并且在新领域中进行泛化。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Geodesic-Generator-for-Conditional-Distributions"><a href="#Wasserstein-Geodesic-Generator-for-Conditional-Distributions" class="headerlink" title="Wasserstein Geodesic Generator for Conditional Distributions"></a>Wasserstein Geodesic Generator for Conditional Distributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10145">http://arxiv.org/abs/2308.10145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions">https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions</a></li>
<li>paper_authors: Young-geun Kim, Kyungbok Lee, Youngwon Choi, Joong-Ho Won, Myunghee Cho Paik</li>
<li>for: 这篇论文是用于研究如何获得高品质的条件生成。</li>
<li>methods: 论文使用估计条件分布的方法，包括 derive 一个可诠释的上界 bound 来定义条件分布，并使用 optimal transport 理论来设计一个名为 Wasserstein geodesic generator 的新型条件生成器。</li>
<li>results: 实验结果显示，提案的方法可以高效地学习条件分布，并可以生成高品质的条件生成。<details>
<summary>Abstract</summary>
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
<<SYS>计算样本 Given Specific标签需要估算conditional Distributions。我们得出了可观察 Wasserstein distance的Upper bound，以准备 theoretically learn conditional Distributions。 Based on this result, we propose a novel conditional generation algorithm, where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method. tranlation notes:* "conditional distributions" translated as "条件分布"* "Wasserstein distance" translated as "沃斯坦距离"* "metric space" translated as "度量空间"* "optimal transport theory" translated as "最优运输理论"* "Wasserstein geodesic" translated as "沃斯坦曲线"* "conditional generator" translated as "条件生成器"* "observed domains" translated as "观察Domain"* "unobserved intermediate domains" translated as "未观察中间Domain"* "light conditions" translated as "照明条件"Please note that the translation is in Simplified Chinese, and the word order may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="ExpeL-LLM-Agents-Are-Experiential-Learners"><a href="#ExpeL-LLM-Agents-Are-Experiential-Learners" class="headerlink" title="ExpeL: LLM Agents Are Experiential Learners"></a>ExpeL: LLM Agents Are Experiential Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10144">http://arxiv.org/abs/2308.10144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Andrewzh112/ExpeL">https://github.com/Andrewzh112/ExpeL</a></li>
<li>paper_authors: Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang</li>
<li>for: 这篇论文的目的是提出一种新的语言模型学习方法，以便在做决策任务时不需要进行参数更新。</li>
<li>methods: 该方法使用自然语言从训练任务中收集经验，并通过自动提取知识来做出 Informed 决策。</li>
<li>results: 该方法在实验中表现出了Robust 的学习效果，表明随着经验的积累，模型的性能会不断提高。<details>
<summary>Abstract</summary>
The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results show that the ExpeL agent exhibits robust learning efficacy, with its performance consistently improving as it accumulates experiences. We also explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-Objective-Driven-Artificial-Intelligence"><a href="#A-Review-on-Objective-Driven-Artificial-Intelligence" class="headerlink" title="A Review on Objective-Driven Artificial Intelligence"></a>A Review on Objective-Driven Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10135">http://arxiv.org/abs/2308.10135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Apoorv Singh</li>
<li>for: 本文旨在探讨人工智能（AI）技术目前的缺陷，以及如何通过层次规划和能量基、隐变量方法等方法来减少人机智能差距。</li>
<li>methods: 本文主要使用层次规划、能量基、隐变量方法等方法来探讨人工智能技术的发展和应用。</li>
<li>results: 本文指出，现有的AI技术尚未能够准确地理解人类的语言和情感表达，而层次规划和能量基、隐变量方法等方法可以帮助人工智能技术更好地理解人类的语言和情感表达。<details>
<summary>Abstract</summary>
While advancing rapidly, Artificial Intelligence still falls short of human intelligence in several key aspects due to inherent limitations in current AI technologies and our understanding of cognition. Humans have an innate ability to understand context, nuances, and subtle cues in communication, which allows us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret such contextual information accurately. Humans possess a vast repository of common-sense knowledge that helps us make logical inferences and predictions about the world. Machines lack this innate understanding and often struggle with making sense of situations that humans find trivial. In this article, we review the prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close this gap between human and machine intelligence. Specifically, we talk about what's lacking with the current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then we show how Hierarchical planning-based approaches can help us close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.
</details>
<details>
<summary>摘要</summary>
artifical intelligence 在快速发展中，但仍然缺乏人类智能的一些关键方面，这主要归结于当前的 AI 技术和我们认知神经科学的限制。人类有内置的理解上下文、涵义和微妙提示的能力，使得我们能够理解讽刺、讽刺和 метаFOR。机器则很难准确地理解这些上下文信息。人类拥有庞大的通用智能知识，帮助我们做出逻辑推理和世界上的预测。机器缺乏这种内置的理解，经常陷入人类轻视的情况。在这篇文章中，我们评论了当前的机器智能候选人，包括Prof. Yann LeCun的评论以及其他工作，以帮助关闭人类和机器智能之间的差距。我们讨论了当前 AI 技术的缺陷，如监督学习、奖励学习、自监学习等。然后，我们介绍了层次规划基础的方法，可以帮助我们关闭这个差距。我们还深入探讨了能量基础、隐变量方法和联合嵌入预测架构。
</details></li>
</ul>
<hr>
<h2 id="AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference"><a href="#AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference" class="headerlink" title="AutoReP: Automatic ReLU Replacement for Fast Private Network Inference"></a>AutoReP: Automatic ReLU Replacement for Fast Private Network Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10134">http://arxiv.org/abs/2308.10134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harveyp123/autorep">https://github.com/harveyp123/autorep</a></li>
<li>paper_authors: Hongwu Peng, Shaoyi Huang, Tong Zhou, Yukui Luo, Chenghong Wang, Zigeng Wang, Jiahui Zhao, Xi Xie, Ang Li, Tony Geng, Kaleel Mahmood, Wujie Wen, Xiaolin Xu, Caiwen Ding<br>for: This paper aims to address the data privacy and security issues in Machine-Learning-As-A-Service (MLaaS) market by proposing a gradient-based approach called AutoReP, which reduces the number of non-linear operators and maintains model expressivity.methods: The proposed AutoReP method uses gradient-based approach to select appropriate ReLU and polynomial functions for private inference, and introduces distribution-aware polynomial approximation (DaPa) to accurately approximate ReLUs.results: The experimental results on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets show significant accuracy improvements over current state-of-the-art methods, e.g., SNL. Specifically, the accuracy improvements are 6.12%, 8.39%, and 9.45%, respectively. Additionally, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, achieving 75.55% accuracy with 176.1 times ReLU budget reduction.<details>
<summary>Abstract</summary>
The growth of the Machine-Learning-As-A-Service (MLaaS) market has highlighted clients' data privacy and security issues. Private inference (PI) techniques using cryptographic primitives offer a solution but often have high computation and communication costs, particularly with non-linear operators like ReLU. Many attempts to reduce ReLU operations exist, but they may need heuristic threshold selection or cause substantial accuracy loss. This work introduces AutoReP, a gradient-based approach to lessen non-linear operators and alleviate these issues. It automates the selection of ReLU and polynomial functions to speed up PI applications and introduces distribution-aware polynomial approximation (DaPa) to maintain model expressivity while accurately approximating ReLUs. Our experimental results demonstrate significant accuracy improvements of 6.12% (94.31%, 12.9K ReLU budget, CIFAR-10), 8.39% (74.92%, 12.9K ReLU budget, CIFAR-100), and 9.45% (63.69%, 55K ReLU budget, Tiny-ImageNet) over current state-of-the-art methods, e.g., SNL. Morever, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, and achieved 75.55% accuracy with 176.1 times ReLU budget reduction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning"><a href="#Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning" class="headerlink" title="Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning"></a>Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10124">http://arxiv.org/abs/2308.10124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Hu, Jinhang Zuo, Bob Iannucci, Carlee Joe-Wong</li>
<li>for: 这篇论文旨在提高环境监测和风险警告，通过部署一个网络的物联网设备（IoT）。</li>
<li>methods: 该论文使用多代理学习（MARL）方法来优化物联网设备的通信策略，以最大化环境数据跟踪准确性，同时满足功率和带宽限制。</li>
<li>results: 实验表明，使用MARL方法可以学习和利用环境数据的空间时间相关性，以减少物联网设备的重复报告。<details>
<summary>Abstract</summary>
Internet of Things (IoT) technologies have enabled numerous data-driven mobile applications and have the potential to significantly improve environmental monitoring and hazard warnings through the deployment of a network of IoT sensors. However, these IoT devices are often power-constrained and utilize wireless communication schemes with limited bandwidth. Such power constraints limit the amount of information each device can share across the network, while bandwidth limitations hinder sensors' coordination of their transmissions. In this work, we formulate the communication planning problem of IoT sensors that track the state of the environment. We seek to optimize sensors' decisions in collecting environmental data under stringent resource constraints. We propose a multi-agent reinforcement learning (MARL) method to find the optimal communication policies for each sensor that maximize the tracking accuracy subject to the power and bandwidth limitations. MARL learns and exploits the spatial-temporal correlation of the environmental data at each sensor's location to reduce the redundant reports from the sensors. Experiments on wildfire spread with LoRA wireless network simulators show that our MARL method can learn to balance the need to collect enough data to predict wildfire spread with unknown bandwidth limitations.
</details>
<details>
<summary>摘要</summary>
互联网物件技术（IoT）已经启用了许多数据驱动的移动应用程序，并有潜力增强环境监控和险情警告通过网络设置 IoT 感知器。然而，这些 IoT 设备通常受限于能源和无线通信协议的限制，这限制每个设备可以在网络上分享的资讯量，而且对于感知器的传输协议的协调也受到限制。在这个工作中，我们将环境监控 IoT 感知器的通信规划问题形式化为一个最佳化问题，以最大化感知器对环境状态的追踪精度，同时遵循能源和传输协议的限制。我们提出了一种基于多代理问题学习（MARL）方法，以便每个感知器可以在网络上传输环境数据，并且可以适当地调整传输策略，以最大化追踪精度。实验结果显示，我们的 MARL 方法可以在不知道传输协议的情况下，对野火传播进行精确的预测。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets"><a href="#Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets" class="headerlink" title="Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets"></a>Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10120">http://arxiv.org/abs/2308.10120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farah Alsafadi, Xu Wu</li>
<li>for: 这个论文的目的是用深度学习（DL）技术来扩展科学数据，以便更好地训练深度学习模型。</li>
<li>methods: 这个论文使用了深度生成模型（DGM），包括生成敌对网络（GAN）、标准化流（NF）、变换自动编码器（VAE）和条件VAE（CVAE）等，来学习训练数据集的下面分布。</li>
<li>results: 研究发现，使用DGM生成的 sintetic数据可以覆盖现有训练数据的限制，并且可以减少训练数据的缺失值。CVAEs的生成性能最佳，其生成的数据具有最小的错误。这些结果表明，DGM可以有效地扩展科学数据，并且可以帮助深度学习模型更加准确地训练。<details>
<summary>Abstract</summary>
Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of ``big data''. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在许多领域取得了很大成功，如计算机视觉和自然语言处理，这主要归功于大量数据的可用性。然而，在核工程问题中，由于数据的有限性，特别是高成本实验室中的数据，因此复制这种成功是不容易的。为解决这个数据缺乏问题，本文探讨了在科学数据增强方面使用深度生成模型（DGM）的应用。DGM包括生成对抗网络（GAN）、Normalizing Flows（NF）、Variational Autoencoders（VAE）和 Conditional VAEs（CVAE）等，可以在训练数据集的下采用学习下面的概率分布。一旦训练完成，它们可以生成与训练数据相似的 sintetic 数据，并大大增加数据集的大小。本研究通过使用 DGM 增强 TRACE 仿真数据，基于 NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test（BFBT）标准底本，展示了 VAE、CVAE 和 GAN 在生成数据时的相似性，CVAE 的错误最小。这些发现表明 DGM 在核工程领域有很大的潜力，可以增强数据增强模型的准确性，从而提高核工程领域的研究效果。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Random-Networks-with-Heterogeneous-Reciprocity"><a href="#Modeling-Random-Networks-with-Heterogeneous-Reciprocity" class="headerlink" title="Modeling Random Networks with Heterogeneous Reciprocity"></a>Modeling Random Networks with Heterogeneous Reciprocity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10113">http://arxiv.org/abs/2308.10113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Cirkovic, Tiandong Wang</li>
<li>For: 本研究旨在模型社交网络中不同水平的反馈行为。* Methods: 本文提出了一种偏好附加模型，用于模拟用户吸引受欢迎用户的行为，以及不同水平的反馈行为。文章还比较了 bayesian 和 frequentist 模型适应技术，以及计算效率高的变量方案。* Results: 对 Facebook 墙上的墙文网络进行分析，发现用户的反馈行为呈差异性分布，并使用模型预测用户之间的连接关系。模型能够捕捉 Facebook 数据中的重概率分布，并分别确定了多个用户群体的反馈行为特征。<details>
<summary>Abstract</summary>
Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behavior patterns. The fitted model captures the heavy-tailed nature of the empirical degree distributions in the Facebook data and identifies multiple groups of users that differ in their tendency to reply to and receive responses to wallposts.
</details>
<details>
<summary>摘要</summary>
“循环性”或“模仿行为”是社交网络中信息交换的关键指标。社交网络中的用户通常在不同的水平上进行反馈行为。不同的反馈行为可能表示社交网络中存在不同的社群，这些社群在链接reciprocate的速率上有所不同。在这篇论文中，我们开发了模型社交网络中多样化反馈行为的方法ологи。特别是，我们提出了具有异质反馈的偏好附着模型，该模型模拟用户循环行为的吸引力和不同的反馈方式。我们比较了 bayesian 和频率主义模型适应技术，以及计算效率高的变量替代方法。我们还考虑了知道和不知道社群数量的两种情况。我们应用这些方法分析Facebook墙上的墙posts网络，发现用户的反馈行为具有不均匀的特点，并确定了不同的用户群体。Note: "循环性" (reciprocity) in the text refers to the tendency of individuals to mirror behavior in a social network.
</details></li>
</ul>
<hr>
<h2 id="Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks"><a href="#Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks" class="headerlink" title="Robust Mixture-of-Expert Training for Convolutional Neural Networks"></a>Robust Mixture-of-Expert Training for Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10110">http://arxiv.org/abs/2308.10110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optml-group/robust-moe-cnn">https://github.com/optml-group/robust-moe-cnn</a></li>
<li>paper_authors: Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu</li>
<li>for: 本研究旨在探讨如何使用 sparse-gated Mixture of Expert (MoE) 模型提高 convolutional neural networks (CNNs) 的鲁棒性。</li>
<li>methods: 本研究提出了一种新的 router-expert alternating Adversarial training 框架，以提高 MoE-CNN 模型的鲁棒性。</li>
<li>results: 实验结果表明，相比 dense CNN，AdvMoE 可以提高 adversarial robustness 1% ~ 4%，同时具有较高的计算效率，减少了 более半个 inference cost。<details>
<summary>Abstract</summary>
Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details>
<details>
<summary>摘要</summary>
这是一篇研究档案，探讨了一种新的深度学习模型架构，即零价对抗性混合专家（MoE）。这种模型架构已经展示了高精度和高效率的推断能力。 despite its growing popularity, little work has been done to investigate its potential to improve convolutional neural networks (CNNs)， especially in the area of adversarial robustness. therefore, we ask: how to adversarially robustify a CNN-based MoE model? can we train it like an ordinary CNN model? our preliminary study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) is no longer effective to robustify an MoE-CNN. to better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: the robustness of routers (i.e., gating functions to select data-specific experts) and the robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). our analyses show that routers and experts are difficult to adapt to each other in the vanilla AT. therefore, we propose a new router-expert alternating adversarial training framework for MoE, termed AdvMoE. the effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. we find that AdvMoE achieves 1% to 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details></li>
</ul>
<hr>
<h2 id="An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme"><a href="#An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme" class="headerlink" title="An Online Multiple Kernel Parallelizable Learning Scheme"></a>An Online Multiple Kernel Parallelizable Learning Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10101">http://arxiv.org/abs/2308.10101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emilio Ruiz-Moreno, Baltasar Beferull-Lozano</li>
<li>for: 提高单kernel方法的选择灵活性和计算效率，使其能够更好地适应数据丰富任务中的解决空间。</li>
<li>methods: 基于多kernel学习形式，可以将单kernel解决空间扩展到更广泛的解决空间，从而提高解决空间内的性能。同时，该学习形式可以并行化，以便分配计算负担到不同的计算单元。</li>
<li>results: 在实验中，提出的学习方案比单个单kernel方法相比，在累积较少的最小二乘loss metric上表现出更高的性能。<details>
<summary>Abstract</summary>
The performance of reproducing kernel Hilbert space-based methods is known to be sensitive to the choice of the reproducing kernel. Choosing an adequate reproducing kernel can be challenging and computationally demanding, especially in data-rich tasks without prior information about the solution domain. In this paper, we propose a learning scheme that scalably combines several single kernel-based online methods to reduce the kernel-selection bias. The proposed learning scheme applies to any task formulated as a regularized empirical risk minimization convex problem. More specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.
</details>
<details>
<summary>摘要</summary>
“kernel Hilbert space-based方法的性能受选择kernel的影响很大。选择合适的kernel可以是一个问题，特别是在没有对解题域的内部信息的情况下。本文提出了一个学习方案，可以可扩展性地结合多个单kernel-based在线方法，以减少kernel-选择偏见。这个学习方案适用于任何形式化为单倍阶调整项目的问题。更 Specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.”Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Geometric-instability-of-graph-neural-networks-on-large-graphs"><a href="#Geometric-instability-of-graph-neural-networks-on-large-graphs" class="headerlink" title="Geometric instability of graph neural networks on large graphs"></a>Geometric instability of graph neural networks on large graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10099">http://arxiv.org/abs/2308.10099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brs96/geometric-instability-gnn-large-graphs">https://github.com/brs96/geometric-instability-gnn-large-graphs</a></li>
<li>paper_authors: Emily Morris, Haotian Shen, Weiling Du, Muhammad Hamza Sajjad, Borun Shi</li>
<li>for: 研究图 Néural Networks（GNNs）中的几何不稳定性。</li>
<li>methods: 提出了一种简单、高效的图native Graph Gram Index（GGI）来测量这种不稳定性，该指标具有卷积、旋转、平移和评估顺序不敏感的特点。</li>
<li>results: 通过研究大图上GNN embedding的不稳定性，发现 embeddings的不稳定性随图的大小而变化，并且在node classification和链接预测 tasks上有不同的不稳定性行为。<details>
<summary>Abstract</summary>
We analyse the geometric instability of embeddings produced by graph neural networks (GNNs). Existing methods are only applicable for small graphs and lack context in the graph domain. We propose a simple, efficient and graph-native Graph Gram Index (GGI) to measure such instability which is invariant to permutation, orthogonal transformation, translation and order of evaluation. This allows us to study the varying instability behaviour of GNN embeddings on large graphs for both node classification and link prediction.
</details>
<details>
<summary>摘要</summary>
我们分析图 neural network (GNN) 生成的嵌入的几何不稳定性。现有方法只适用于小图，缺乏图域上的上下文。我们提议一种简单、高效、图原生的图agram Gram Index (GGI) 来衡量这种不稳定性，该指标是对Permutation、旋转、平移和评估顺序进行 invariant。这使得我们可以研究 GNN 嵌入在大图上的不同不稳定行为，包括节点分类和链接预测。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Bilevel-Learning-with-Inexact-Line-Search"><a href="#Dynamic-Bilevel-Learning-with-Inexact-Line-Search" class="headerlink" title="Dynamic Bilevel Learning with Inexact Line Search"></a>Dynamic Bilevel Learning with Inexact Line Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10098">http://arxiv.org/abs/2308.10098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</li>
<li>for: 这篇论文的目的是解决在各种图像和数据科学领域中，特别是使用变分regularization方法时，手动配置正则化参数的问题。</li>
<li>methods: 这篇论文使用了积分学习来学习适当的正则化参数。</li>
<li>results: 这篇论文的实验结果表明，该方法可以有效地解决手动配置正则化参数的问题，并且可以根据实际需求动态地确定需要的精度。<details>
<summary>Abstract</summary>
In various domains within imaging and data science, particularly when addressing tasks modeled utilizing the variational regularization approach, manually configuring regularization parameters presents a formidable challenge. The difficulty intensifies when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning is employed to learn suitable hyperparameters. However, due to the use of numerical solvers, the exact gradient with respect to the hyperparameters is unattainable, necessitating the use of methods relying on approximate gradients. State-of-the-art inexact methods a priori select a decreasing summable sequence of the required accuracy and only assure convergence given a sufficiently small fixed step size. Despite this, challenges persist in determining the Lipschitz constant of the hypergradient and identifying an appropriate fixed step size. Conversely, computing exact function values is not feasible, impeding the use of line search. In this work, we introduce a provably convergent inexact backtracking line search involving inexact function evaluations and hypergradients. We show convergence to a stationary point of the loss with respect to hyperparameters. Additionally, we propose an algorithm to determine the required accuracy dynamically. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation in variational regularization problems, alongside its robustness in terms of the initial accuracy and step size choices.
</details>
<details>
<summary>摘要</summary>
在各种图像和数据科学领域中，特别是使用变分regularization方法解决问题时，手动配置正则化参数是一项具有挑战性的任务。这种挑战会加剧，当使用含有大量hyperparameter的正则izers时。为了解决这个问题，我们使用笛卡尔学习来学习适当的hyperparameter。然而，由于使用数值解析器，不能获取正则izers的精确梯度，因此需要使用 Approximate Gradients 的方法。现有的 state-of-the-art 不精确方法会选择一个递减和可加性的精度要求，并且只有在 sufficiently small fixed step size 下才能确保收敛。然而，在确定 Lipschitz 常数和选择合适的fixed step size 方面，仍然存在挑战。另外，计算精确函数值是不可能的，从而阻碍了使用线搜索。在这种情况下，我们提出了一种可证明收敛的不精确返回搜索，该搜索利用不精确函数评估和正则izers的梯度。我们证明了该方法可以收敛到正则izers中的一个站点点。此外，我们还提出了一种动态确定所需的精度的算法。我们的数值实验表明，我们的方法可以有效地进行正则izers的优化，并且具有较好的Robustness 性。
</details></li>
</ul>
<hr>
<h2 id="MLOps-A-Review"><a href="#MLOps-A-Review" class="headerlink" title="MLOps: A Review"></a>MLOps: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10908">http://arxiv.org/abs/2308.10908</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenningst/ecommerce-ops">https://github.com/jenningst/ecommerce-ops</a></li>
<li>paper_authors: Samar Wazir, Gautam Siddharth Kashyap, Parag Saxena</li>
<li>for: The paper aims to explore the significance of Machine Learning Operations (MLOps) methods and assess their features and operability to help create software that is simple to use.</li>
<li>methods: The authors evaluate 22 papers that attempted to apply the MLOps idea and assess the features and operability of various MLOps methods.</li>
<li>results: The authors conclude that there is a scarcity of fully effective MLOps methods that can self-regulate by limiting human engagement.Here’s the same information in Simplified Chinese text:</li>
<li>for: 该论文旨在探讨机器学习运维（MLOps）方法的重要性和评估各种MLOps方法的特性和操作性，以帮助创建简单易用的软件。</li>
<li>methods: 作者评估了22篇应用了MLOps想法的论文，并评估各种MLOps方法的特性和操作性。</li>
<li>results: 作者认为，目前 még 缺乏完全有效的MLOps方法，可以通过限制人类参与来自动化进程。<details>
<summary>Abstract</summary>
Recently, Machine Learning (ML) has become a widely accepted method for significant progress that is rapidly evolving. Since it employs computational methods to teach machines and produce acceptable answers. The significance of the Machine Learning Operations (MLOps) methods, which can provide acceptable answers for such problems, is examined in this study. To assist in the creation of software that is simple to use, the authors research MLOps methods. To choose the best tool structure for certain projects, the authors also assess the features and operability of various MLOps methods. A total of 22 papers were assessed that attempted to apply the MLOps idea. Finally, the authors admit the scarcity of fully effective MLOps methods based on which advancements can self-regulate by limiting human engagement.
</details>
<details>
<summary>摘要</summary>
最近，机器学习（ML）已成为广泛接受的方法，迅速发展。由于它利用计算方法教育机器并生成可接受的答案。本研究研究机器学习操作（MLOps）方法，以便为解决这些问题提供可靠的答案。为便于创建简单易用的软件，作者研究了不同的MLOps方法。为选择特定项目适用的最佳工具结构，作者还评估了各种MLOps方法的特性和操作性。本研究总共评估了22篇尝试应用MLOps想法的论文。最后，作者承认MLOps方法的完全可效性尚未得到保证，尤其是限制人类参与的情况下。
</details></li>
</ul>
<hr>
<h2 id="Securing-Pathways-with-Orthogonal-Robots"><a href="#Securing-Pathways-with-Orthogonal-Robots" class="headerlink" title="Securing Pathways with Orthogonal Robots"></a>Securing Pathways with Orthogonal Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10093">http://arxiv.org/abs/2308.10093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Faraneh Fathi, Sara Moshtaghi Largani, Alireza Bagheri</li>
<li>for: 本研究旨在提供一种新型的路径保护方法，使用正交机器人来保护路径。</li>
<li>methods: 本研究使用了正交机器人来 efficiently guard orthogonal areas with the minimum number of orthogonal robots.</li>
<li>results: 研究表明可以在线时确定最小数量的正交机器人，以保护路径。<details>
<summary>Abstract</summary>
The protection of pathways holds immense significance across various domains, including urban planning, transportation, surveillance, and security. This article introduces a groundbreaking approach to safeguarding pathways by employing orthogonal robots. The study specifically addresses the challenge of efficiently guarding orthogonal areas with the minimum number of orthogonal robots. The primary focus is on orthogonal pathways, characterized by a path-like dual graph of vertical decomposition. It is demonstrated that determining the minimum number of orthogonal robots for pathways can be achieved in linear time. However, it is essential to note that the general problem of finding the minimum number of robots for simple polygons with general visibility, even in the orthogonal case, is known to be NP-hard. Emphasis is placed on the flexibility of placing robots anywhere within the polygon, whether on the boundary or in the interior.
</details>
<details>
<summary>摘要</summary>
保护路径在多个领域，如城市规划、交通、监视和安全方面，具有极高的重要性。本文介绍了一种创新的路径保护方法，利用正交机器人。研究特点在于有效地使用最少的正交机器人来保护正交区域。研究主要关注正交路径，即笛卡尔分解中的路径 dual graph。实验表明，可以在线性时间内确定最少正交机器人数量。然而，需要注意的是，对于简单多边形的通用可见情况，即使是正交情况，找到最少机器人数量的问题是NP困难的。研究强调了机器人的位置可以在多边形边界上或者在内部。
</details></li>
</ul>
<hr>
<h2 id="Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions"><a href="#Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions" class="headerlink" title="Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions"></a>Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10090">http://arxiv.org/abs/2308.10090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Sara Moshtaghi Largani, Reza Rahimi, Alireza Bagheri</li>
<li>For: 这篇论文的目的是解决监视人员路径问题（OWRP），即在多边形环境中找到最短路径，使机器人可以在一次连续扫描整个环境。* Methods: 本研究使用了有效的线性时间算法，解决OWRP问题，假设环境是单调的。* Results: 研究发现，这种算法可以减少机器人转弯的数量，从而提高机器人在观察和监视方面的效率，并且可以应用于各种实际应用中。<details>
<summary>Abstract</summary>
The Orthogonal Watchman Route Problem (OWRP) entails the search for the shortest path, known as the watchman route, that a robot must follow within a polygonal environment. The primary objective is to ensure that every point in the environment remains visible from at least one point on the route, allowing the robot to survey the entire area in a single, continuous sweep. This research places particular emphasis on reducing the number of turns in the route, as it is crucial for optimizing navigation in watchman routes within the field of robotics. The cost associated with changing direction is of significant importance, especially for specific types of robots. This paper introduces an efficient linear-time algorithm for solving the OWRP under the assumption that the environment is monotone. The findings of this study contribute to the progress of robotic systems by enabling the design of more streamlined patrol robots. These robots are capable of efficiently navigating complex environments while minimizing the number of turns. This advancement enhances their coverage and surveillance capabilities, making them highly effective in various real-world applications.
</details>
<details>
<summary>摘要</summary>
orthogonal 看守路径问题 (OWRP) 是关于找到最短路径，也称为看守路径，Robot在多边形环境中移动的问题。主要目标是确保环境中每个点都可以在一个点上看到，使Robot在一次连续扫描中涵盖整个区域。这种研究强调减少路径转弯数量，因为这对于某些类型的Robot来说非常重要。这篇论文介绍了一种高效的直线时间算法，用于解决 OWRP，假设环境是均匀的。这些发现对于 robotic 系统的进步做出了贡献，可以设计更加流畅的执勤Robot，这些Robot可以在复杂环境中高效巡捕，最小化转弯数量，提高覆盖和监测能力，使其在实际应用中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views"><a href="#Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views" class="headerlink" title="Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views"></a>Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10077">http://arxiv.org/abs/2308.10077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asif Khan, Amos Storkey</li>
<li>for: 学习不同类型图的节点水平表示，用于识别骗子和蛋白质功能预测等应用。</li>
<li>methods: 提出了一种基于多视图对比学习的新方法，该方法通过在图上执行扩散缓动来捕捉高级别图 структуры，从而提高节点表示的准确性。</li>
<li>results: 在synthetic和实际结构数据上比较baseline，该方法的表现较佳，胜过best baseline by 16.06% on Cornell, 3.27% on Texas, and 8.04% on Wisconsin。此外，它在邻近任务上也表现出优异，这表明它有效地捕捉了结构信息，并且可以提高下游应用的性能。<details>
<summary>Abstract</summary>
Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\%$ on Cornell, $3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.
</details>
<details>
<summary>摘要</summary>
学习不同类型图的节点级别表示是关键的，包括诈器检测和蛋白质功能预测。在这些图中，节点具有同类结构，可以通过节点之间的连接相似性来隐式地编码在图中。对比方法是选择学习节点在图中的表示方法，但现有的对比方法很难捕捉更高级别的图结构。为解决这些限制，我们提出了一种新的多视图对比学习方法，该方法在图中integration多个视图作为增强。通过这种方法，我们可以捕捉到不同类型图中节点之间的结构相似性，从而找到隐藏的关系和相似性，不同于传统节点表示。我们的方法在 sintetic和实际结构数据上比基eline表现出色，胜过最佳基eline的$16.06\%$在 Cornell，$3.27\%$在 Texas，和$8.04\%$在 Wisconsin。此外，我们的方法在邻近任务上持续表现出色，证明它的有效性在揭示结构信息和提高下游应用中。
</details></li>
</ul>
<hr>
<h2 id="ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration"><a href="#ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration" class="headerlink" title="ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration"></a>ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10068">http://arxiv.org/abs/2308.10068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duo Wu, Dayou Zhang, Miao Zhang, Ruoyu Zhang, Fangxin Wang, Shuguang Cui</li>
<li>for: 这个论文目的是为了提出一个基于模仿学习的配置适应式视频分析系统（ILCAS），以减少对网络带宽的需求和处理时间，并且能够适应不同的视频内容变化。</li>
<li>methods: ILCAS使用了视频动态特征地图和镜头间协力机制，以捕捉视频内容变化并选择适当的配置。它还使用了专家示范的对策来训练代理人，通过动态计划来解决配置适应问题。</li>
<li>results: 实验结果显示，ILCAS比之前的方案有2-20.9%的增加精度和19.9-85.3%的减少块上传延迟。<details>
<summary>Abstract</summary>
The high-accuracy and resource-intensive deep neural networks (DNNs) have been widely adopted by live video analytics (VA), where camera videos are streamed over the network to resource-rich edge/cloud servers for DNN inference. Common video encoding configurations (e.g., resolution and frame rate) have been identified with significant impacts on striking the balance between bandwidth consumption and inference accuracy and therefore their adaption scheme has been a focus of optimization. However, previous profiling-based solutions suffer from high profiling cost, while existing deep reinforcement learning (DRL) based solutions may achieve poor performance due to the usage of fixed reward function for training the agent, which fails to craft the application goals in various scenarios. In this paper, we propose ILCAS, the first imitation learning (IL) based configuration-adaptive VA streaming system. Unlike DRL-based solutions, ILCAS trains the agent with demonstrations collected from the expert which is designed as an offline optimal policy that solves the configuration adaption problem through dynamic programming. To tackle the challenge of video content dynamics, ILCAS derives motion feature maps based on motion vectors which allow ILCAS to visually ``perceive'' video content changes. Moreover, ILCAS incorporates a cross-camera collaboration scheme to exploit the spatio-temporal correlations of cameras for more proper configuration selection. Extensive experiments confirm the superiority of ILCAS compared with state-of-the-art solutions, with 2-20.9% improvement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.
</details>
<details>
<summary>摘要</summary>
高精度和资源占用深度神经网络（DNN）在实时视频分析（VA）中广泛应用，其中摄像头视频流经网络传输至 Edge/云服务器进行DNN推理。常见的视频编码配置（例如分辨率和帧率）有显著影响于占用带宽和推理精度的平衡，因此其适应方案成为优化的焦点。然而，先前的 Profiling-based 解决方案具有高 Profiling 成本，而现有的深度强化学习（DRL）基于解决方案可能因为使用固定的奖励函数进行训练代理人，导致在不同enario中拟合应用目标的问题。在本文中，我们提出了 ILCAS，第一个仿学学习（IL）基于配置适应VA流动系统。与 DRL-based 解决方案不同，ILCAS 通过收集专家设计的示例来训练代理人，通过动态计划解决配置适应问题。为了解决视频内容变化的挑战，ILCAS  derivates 基于运动 вектор的动作特征图， Allow ILCAS 在视觉上“感受”视频内容变化。此外，ILCAS 还实现了相机间协作机制，以便更好地选择适配。经验证明，ILCAS 相比现有的解决方案具有2-20.9%的提升精度和19.9-85.3%的减少块上传延迟。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.LG_2023_08_20/" data-id="clltau92u0069cr88f1ij3dez" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/4/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">54</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">92</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">165</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
