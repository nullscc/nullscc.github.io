
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.AI_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CR/">cs.CR</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.AI_2023_08_22/">cs.AI - 2023-08-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Furnishing-Sound-Event-Detection-with-Language-Model-Abilities"><a href="#Furnishing-Sound-Event-Detection-with-Language-Model-Abilities" class="headerlink" title="Furnishing Sound Event Detection with Language Model Abilities"></a>Furnishing Sound Event Detection with Language Model Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11530">http://arxiv.org/abs/2308.11530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang</li>
<li>for: 本研究探讨语言模型（LM）在视觉跨模态中的能力，特别是sound event detection（SED）领域。</li>
<li>methods: 我们提出了一种简洁的方法，通过对音频特征和文本特征的对应进行对齐，实现声音事件分类和时间位置的生成。该框架包括一个音频编码器、一个对应模块和一个独立的语言解码器。</li>
<li>results: 我们的模型可以准确地生成声音事件探测序列。与传统方法相比，我们的模型更加简洁和全面，因为它直接利用语言模型的 semantic 能力来生成序列。我们还对不同的解码模块进行了研究，以示timestamps capture和事件分类的效果。<details>
<summary>Abstract</summary>
Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification. Evaluation results show that the proposed method achieves accurate sequences of sound event detection.
</details>
<details>
<summary>摘要</summary>
最近，语言模型（LM）在视觉交互领域的能力受到了越来越多的关注。在这篇论文中，我们进一步探索语言模型对声音事件检测（SED）的生成能力，超出视觉领域。我们提出了一种简洁的方法，将音频特征和文本特征进行对齐，以完成声音事件类型和时间位置的分类。该框架包括一个声音编码器、一个对应模块，将文本和音频特征的对应表示进行对齐，以及一个独立的语言解码器，从音频特征中生成时间序列和事件序列。相比于传统的方法，需要复杂的处理和尝试用有限的音频特征，我们的模型更简洁和全面，因为语言模型直接利用其语义能力来生成序列。我们 investigate了不同的解 Coupling模块，以示出对时间捕捉和事件分类的效果。评估结果显示，我们的方法可以准确地检测声音事件。
</details></li>
</ul>
<hr>
<h2 id="TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows"><a href="#TrackFlow-Multi-Object-Tracking-with-Normalizing-Flows" class="headerlink" title="TrackFlow: Multi-Object Tracking with Normalizing Flows"></a>TrackFlow: Multi-Object Tracking with Normalizing Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11513">http://arxiv.org/abs/2308.11513</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianluca Mancusi, Aniello Panariello, Angelo Porrello, Matteo Fabbri, Simone Calderara, Rita Cucchiara</li>
<li>for: 提高多对象跟踪的性能，尤其是在多模态 Setting 中。</li>
<li>methods: 使用深度概率模型来计算候选对应关系的可能性，以提高跟踪-by-检测算法的性能。</li>
<li>results: 在 simulate 和实际 benchmark 上进行了实验，显示了我们的方法可以提高跟踪-by-检测算法的性能。<details>
<summary>Abstract</summary>
The field of multi-object tracking has recently seen a renewed interest in the good old schema of tracking-by-detection, as its simplicity and strong priors spare it from the complex design and painful babysitting of tracking-by-attention approaches. In view of this, we aim at extending tracking-by-detection to multi-modal settings, where a comprehensive cost has to be computed from heterogeneous information e.g., 2D motion cues, visual appearance, and pose estimates. More precisely, we follow a case study where a rough estimate of 3D information is also available and must be merged with other traditional metrics (e.g., the IoU). To achieve that, recent approaches resort to either simple rules or complex heuristics to balance the contribution of each cost. However, i) they require careful tuning of tailored hyperparameters on a hold-out set, and ii) they imply these costs to be independent, which does not hold in reality. We address these issues by building upon an elegant probabilistic formulation, which considers the cost of a candidate association as the negative log-likelihood yielded by a deep density estimator, trained to model the conditional joint probability distribution of correct associations. Our experiments, conducted on both simulated and real benchmarks, show that our approach consistently enhances the performance of several tracking-by-detection algorithms.
</details>
<details>
<summary>摘要</summary>
隐身多目标跟踪领域最近又有新的关注，旧的schema tracking-by-detection，因为它的简单性和强制约束，不需要复杂的设计和痛苦照顾 tracking-by-attention 方法。在这个视图下，我们想扩展 tracking-by-detection 到多模式设定，其中需要从不同的信息源（例如，2D 运动指示、视觉特征和姿态估计）计算总成本。更加准确地说，我们采用了一个实验研究，其中有一个粗略的3D 信息估计也可以与传统的 метри（例如，IoU）一起使用。为了实现这一点，现有的方法通常采用 either simple rules or complex heuristics 来均衡每个成本的贡献。然而，i) 它们需要在保留集上精心调整特制的超参数，并 ii) 它们假设这些成本是独立的，而实际上不是。我们解决这些问题，是通过基于简洁概率形式ulation，它考虑候选关联的成本为负极log-概率的深度概率预测器，用于模型候选关联的条件联合概率分布。我们的实验，在 Both simulated 和 real  benchmarks 上进行，显示了我们的方法能够一致提高许多 tracking-by-detection 算法的性能。
</details></li>
</ul>
<hr>
<h2 id="User-Identity-Linkage-in-Social-Media-Using-Linguistic-and-Social-Interaction-Features"><a href="#User-Identity-Linkage-in-Social-Media-Using-Linguistic-and-Social-Interaction-Features" class="headerlink" title="User Identity Linkage in Social Media Using Linguistic and Social Interaction Features"></a>User Identity Linkage in Social Media Using Linguistic and Social Interaction Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11684">http://arxiv.org/abs/2308.11684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Despoina Chatzakou, Juan Soler-Company, Theodora Tsikrika, Leo Wanner, Stefanos Vrochidis, Ioannis Kompatsiaris</li>
<li>for: 防止社交媒体上的负面内容的 spreadof and retain online identity</li>
<li>methods: 使用多个用户活动特征进行机器学习基于检测，以确定两个或多个虚拟标识是否属于同一个真实人</li>
<li>results: 在恶意和恐怖主义相关的推特内容中，模型的效果得到证明<details>
<summary>Abstract</summary>
Social media users often hold several accounts in their effort to multiply the spread of their thoughts, ideas, and viewpoints. In the particular case of objectionable content, users tend to create multiple accounts to bypass the combating measures enforced by social media platforms and thus retain their online identity even if some of their accounts are suspended. User identity linkage aims to reveal social media accounts likely to belong to the same natural person so as to prevent the spread of abusive/illegal activities. To this end, this work proposes a machine learning-based detection model, which uses multiple attributes of users' online activity in order to identify whether two or more virtual identities belong to the same real natural person. The models efficacy is demonstrated on two cases on abusive and terrorism-related Twitter content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions"><a href="#Large-Language-Models-Sensitivity-to-The-Order-of-Options-in-Multiple-Choice-Questions" class="headerlink" title="Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions"></a>Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11483">http://arxiv.org/abs/2308.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pouya Pezeshkpour, Estevam Hruschka<br>for: 这 paper 探讨了 Large Language Models (LLMs) 在不同的 NLP 任务中表现的稳定性问题，特别是在多选问题上。methods: 作者们使用了多种方法来 investigate LLMs 的不稳定性，包括对选项的重新排序和几个示例的尝试。results: 研究发现，当选项的顺序发生变化时，LLMs 的表现会受到很大的影响，表现差异可达 13% 到 75% 不同的benchmark上。通过 detailed 分析，作者们 conjecture 这种不稳定性源于 LLMs 对最佳选项的不确定性，并且特定的选项位置可能会帮助模型更准确地预测最佳选项。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable capabilities in various NLP tasks. However, previous works have shown these models are sensitive towards prompt wording, and few-shot demonstrations and their order, posing challenges to fair assessment of these models. As these models become more powerful, it becomes imperative to understand and address these limitations. In this paper, we focus on LLMs robustness on the task of multiple-choice questions -- commonly adopted task to study reasoning and fact-retrieving capability of LLMs. Investigating the sensitivity of LLMs towards the order of options in multiple-choice questions, we demonstrate a considerable performance gap of approximately 13% to 75% in LLMs on different benchmarks, when answer options are reordered, even when using demonstrations in a few-shot setting. Through a detailed analysis, we conjecture that this sensitivity arises when LLMs are uncertain about the prediction between the top-2/3 choices, and specific options placements may favor certain prediction between those top choices depending on the question caused by positional bias. We also identify patterns in top-2 choices that amplify or mitigate the model's bias toward option placement. We found that for amplifying bias, the optimal strategy involves positioning the top two choices as the first and last options. Conversely, to mitigate bias, we recommend placing these choices among the adjacent options. To validate our conjecture, we conduct various experiments and adopt two approaches to calibrate LLMs' predictions, leading to up to 8 percentage points improvement across different models and benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection"><a href="#Expecting-The-Unexpected-Towards-Broad-Out-Of-Distribution-Detection" class="headerlink" title="Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection"></a>Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11480">http://arxiv.org/abs/2308.11480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/servicenow/broad-openood">https://github.com/servicenow/broad-openood</a></li>
<li>paper_authors: Charles Guille-Escuret, Pierre-André Noël, Ioannis Mitliagkas, David Vazquez, Joao Monteiro</li>
<li>for: 本研究旨在提高部署机器学习系统的可靠性，通过开发检测出现在训练集之外的输入（Out-of-distribution，OOD）方法。</li>
<li>methods: 本研究对现有的OOD检测方法进行了评估，并发现这些方法只能够有效地检测未知的类型，而对其他类型的分布转移表现不一致。为解决这个问题，我们提出了一种基于生成模型的ensemble方法，可以提供更一致和全面的OOD检测解决方案。</li>
<li>results: 我们的研究发现，现有的OOD检测方法在不同类型的分布转移中的性能不一致，而我们的ensemble方法可以提供更高的可靠性和敏感性。我们还发布了一个名为BROAD（Benchmarking Resilience Over Anomaly Diversity）的数据集，以便评估OOD检测方法的性能。<details>
<summary>Abstract</summary>
Improving the reliability of deployed machine learning systems often involves developing methods to detect out-of-distribution (OOD) inputs. However, existing research often narrowly focuses on samples from classes that are absent from the training set, neglecting other types of plausible distribution shifts. This limitation reduces the applicability of these methods in real-world scenarios, where systems encounter a wide variety of anomalous inputs. In this study, we categorize five distinct types of distribution shifts and critically evaluate the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expect. As a first step toward broad OOD detection, we learn a generative model of existing detection scores with a Gaussian mixture. By doing so, we present an ensemble approach that offers a more consistent and comprehensive solution for broad OOD detection, demonstrating superior performance compared to existing methods. Our code to download BROAD and reproduce our experiments is publicly available.
</details>
<details>
<summary>摘要</summary>
提高机器学习系统部署时的可靠性通常涉及到开发检测出idanormal inputs的方法。然而，现有研究通常只关注 absent classes 中的样本，忽视其他类型的可能性 Distribution Shift。这种限制 reduce了这些方法在实际应用中的适用性，因为系统会遇到各种异常输入。在这种研究中，我们分类ified five distinct types of distribution shifts, and critically evaluated the performance of recent OOD detection methods on each of them. We publicly release our benchmark under the name BROAD (Benchmarking Resilience Over Anomaly Diversity). Our findings reveal that while these methods excel in detecting unknown classes, their performance is inconsistent when encountering other types of distribution shifts. In other words, they only reliably detect unexpected inputs that they have been specifically designed to expect. As a first step toward broad OOD detection, we learn a generative model of existing detection scores with a Gaussian mixture. By doing so, we present an ensemble approach that offers a more consistent and comprehensive solution for broad OOD detection, demonstrating superior performance compared to existing methods. Our code to download BROAD and reproduce our experiments is publicly available.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Revisiting-column-generation-based-matheuristic-for-learning-classification-trees"><a href="#Revisiting-column-generation-based-matheuristic-for-learning-classification-trees" class="headerlink" title="Revisiting column-generation-based matheuristic for learning classification trees"></a>Revisiting column-generation-based matheuristic for learning classification trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11477">http://arxiv.org/abs/2308.11477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krooonal/col_gen_estimator">https://github.com/krooonal/col_gen_estimator</a></li>
<li>paper_authors: Krunal Kishor Patel, Guy Desaulniers, Andrea Lodi</li>
<li>for: 这篇论文目的是提高分类问题的解决方法，特别是在机器学习领域中使用决策树模型。</li>
<li>methods: 该论文使用的方法是基于列生成的规则逻辑，以提高分类问题的解决效率和可扩展性。</li>
<li>results: 对于多类分类问题，该方法可以减少数据点数量，并使用数据依赖的约束来提高分类质量。 computational results表明，这些改进可以提高解决效率。<details>
<summary>Abstract</summary>
Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. \cite{firat2020column} proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their corresponding constraints. We conclude by presenting computational results that show that these modifications result in better scalability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="IT3D-Improved-Text-to-3D-Generation-with-Explicit-View-Synthesis"><a href="#IT3D-Improved-Text-to-3D-Generation-with-Explicit-View-Synthesis" class="headerlink" title="IT3D: Improved Text-to-3D Generation with Explicit View Synthesis"></a>IT3D: Improved Text-to-3D Generation with Explicit View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11473">http://arxiv.org/abs/2308.11473</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/buaacyw/it3d-text-to-3d">https://github.com/buaacyw/it3d-text-to-3d</a></li>
<li>paper_authors: Yiwen Chen, Chi Zhang, Xiaofeng Yang, Zhongang Cai, Gang Yu, Lei Yang, Guosheng Lin</li>
<li>for: 本研究旨在提高文本到3D图像转换技术，并使用大型文本到图像扩散模型（LDM）提取知识。</li>
<li>methods: 本研究使用图像到图像管道，利用LDM生成高质量多视图图像，并通过Diffusion-GAN双向训练策略来引导3D模型训练。</li>
<li>results: 实验结果表明，本方法比基eline方法有更高的质量和精度，能够更好地解决文本到3D图像转换中的一些问题，如过度满、缺乏细节和不实际的输出。<details>
<summary>Abstract</summary>
Recent strides in Text-to-3D techniques have been propelled by distilling knowledge from powerful large text-to-image diffusion models (LDMs). Nonetheless, existing Text-to-3D approaches often grapple with challenges such as over-saturation, inadequate detailing, and unrealistic outputs. This study presents a novel strategy that leverages explicitly synthesized multi-view images to address these issues. Our approach involves the utilization of image-to-image pipelines, empowered by LDMs, to generate posed high-quality images based on the renderings of coarse 3D models. Although the generated images mostly alleviate the aforementioned issues, challenges such as view inconsistency and significant content variance persist due to the inherent generative nature of large diffusion models, posing extensive difficulties in leveraging these images effectively. To overcome this hurdle, we advocate integrating a discriminator alongside a novel Diffusion-GAN dual training strategy to guide the training of 3D models. For the incorporated discriminator, the synthesized multi-view images are considered real data, while the renderings of the optimized 3D models function as fake data. We conduct a comprehensive set of experiments that demonstrate the effectiveness of our method over baseline approaches.
</details>
<details>
<summary>摘要</summary>
最近的文本到3D技术发展受到了大型文本到图像扩散模型（LDM）的知识储存的推动。然而，现有的文本到3D方法通常会遇到过度饱和、不够细节和不实际的输出等问题。本研究提出了一种新的策略，利用可控多视图图像来解决这些问题。我们的方法是利用图像到图像管道，利用LDM来生成基于粗糙3D模型的高质量poses图像。虽然生成的图像大多消除了以上问题，但是由于大扩散模型的生成性，仍然存在视角不一致和内容差异等问题。为解决这个障碍，我们提议在3D模型训练中添加一个判别器，并采用Diffusion-GAN双向训练策略来引导3D模型的训练。对于添加的判别器，生成的多视图图像被视为真实数据，而 renderings of 优化的3D模型则被视为假数据。我们进行了一系列的实验，证明了我们的方法在基础方法上表现更高效。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Open-Vocabulary-Enhanced-Safe-landing-with-Intelligence-DOVESEI"><a href="#Dynamic-Open-Vocabulary-Enhanced-Safe-landing-with-Intelligence-DOVESEI" class="headerlink" title="Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI)"></a>Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11471">http://arxiv.org/abs/2308.11471</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mistlab/dovesei">https://github.com/mistlab/dovesei</a></li>
<li>paper_authors: Haechan Mark Bong, Rongge Zhang, Ricardo de Azambuja, Giovanni Beltrame</li>
<li>for: 本研究目标是为城市空中机器人开发安全降落。</li>
<li>methods: 本研究使用视 servoing 技术，利用开放词汇图像分割，适应不同场景，并且不需要大量数据更新内部模型。</li>
<li>results: 实验表明，该系统可以在100米高度下成功执行降落动作，且通过引入动态专注机制，提高降落成功率。<details>
<summary>Abstract</summary>
This work targets what we consider to be the foundational step for urban airborne robots, a safe landing. Our attention is directed toward what we deem the most crucial aspect of the safe landing perception stack: segmentation. We present a streamlined reactive UAV system that employs visual servoing by harnessing the capabilities of open vocabulary image segmentation. This approach can adapt to various scenarios with minimal adjustments, bypassing the necessity for extensive data accumulation for refining internal models, thanks to its open vocabulary methodology. Given the limitations imposed by local authorities, our primary focus centers on operations originating from altitudes of 100 meters. This choice is deliberate, as numerous preceding works have dealt with altitudes up to 30 meters, aligning with the capabilities of small stereo cameras. Consequently, we leave the remaining 20m to be navigated using conventional 3D path planning methods. Utilizing monocular cameras and image segmentation, our findings demonstrate the system's capability to successfully execute landing maneuvers at altitudes as low as 20 meters. However, this approach is vulnerable to intermittent and occasionally abrupt fluctuations in the segmentation between frames in a video stream. To address this challenge, we enhance the image segmentation output by introducing what we call a dynamic focus: a masking mechanism that self adjusts according to the current landing stage. This dynamic focus guides the control system to avoid regions beyond the drone's safety radius projected onto the ground, thus mitigating the problems with fluctuations. Through the implementation of this supplementary layer, our experiments have reached improvements in the landing success rate of almost tenfold when compared to global segmentation. All the source code is open source and available online (github.com/MISTLab/DOVESEI).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning"><a href="#Internal-Cross-layer-Gradients-for-Extending-Homogeneity-to-Heterogeneity-in-Federated-Learning" class="headerlink" title="Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning"></a>Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11464">http://arxiv.org/abs/2308.11464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Hin Chan, Rui Zhou, Running Zhao, Zhihan Jiang, Edith C. -H. Ngai</li>
<li>for: 提高模型不同的 Federated Learning 方法处理系统不同性能的能力</li>
<li>methods: 利用内部交叉层导数，不需要客户端之间的通信，可以增强深层导数的相似性</li>
<li>results: 实验结果证明 InCo Aggregation 的效果，显示内部交叉层导数是提高性能的有效途径<details>
<summary>Abstract</summary>
Federated learning (FL) inevitably confronts the challenge of system heterogeneity in practical scenarios. To enhance the capabilities of most model-homogeneous FL methods in handling system heterogeneity, we propose a training scheme that can extend their capabilities to cope with this challenge. In this paper, we commence our study with a detailed exploration of homogeneous and heterogeneous FL settings and discover three key observations: (1) a positive correlation between client performance and layer similarities, (2) higher similarities in the shallow layers in contrast to the deep layers, and (3) the smoother gradients distributions indicate the higher layer similarities. Building upon these observations, we propose InCo Aggregation that leverags internal cross-layer gradients, a mixture of gradients from shallow and deep layers within a server model, to augment the similarity in the deep layers without requiring additional communication between clients. Furthermore, our methods can be tailored to accommodate model-homogeneous FL methods such as FedAvg, FedProx, FedNova, Scaffold, and MOON, to expand their capabilities to handle the system heterogeneity. Copious experimental results validate the effectiveness of InCo Aggregation, spotlighting internal cross-layer gradients as a promising avenue to enhance the performance in heterogenous FL.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在实际应用中遇到系统多样性的挑战。为了增强大多数模型相似的FL方法在处理系统多样性的能力，我们提出了一个训练方案，可以将其扩展到处理这个挑战。在这篇论文中，我们开始我们的研究，进行了详细的探索Homogeneous和Heterogeneous FL Setting中的三个关键观察：（1）客户端性能和层 similarity 之间的正相关，（2）在浅层较为高 similarity ，而深层较低 similarity，（3）在各层 Similarity 中更平滑的梯度分布，这些观察可以帮助我们更好地理解FL系统的多样性问题。基于这些观察，我们提出了InCo Aggregation，利用服务器模型中的内部交叉层梯度，把深层层梯度与浅层梯度混合，以增强深层层梯度的相似性，不需要客户端之间的额外交流。此外，我们的方法可以与模型相似的FL方法，如FedAvg、FedProx、FedNova、Scaffold和MOON相容，以扩展它们的能力，处理系统多样性。实际实验结果显示，InCo Aggregation 具有很好的效果，强调了内部交叉层梯度作为提高FL系统多样性性能的有力之路。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Self-Supervised-Representation-Learning"><a href="#A-Survey-on-Self-Supervised-Representation-Learning" class="headerlink" title="A Survey on Self-Supervised Representation Learning"></a>A Survey on Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11455">http://arxiv.org/abs/2308.11455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/esvit">https://github.com/microsoft/esvit</a></li>
<li>paper_authors: Tobias Uelwer, Jan Robine, Stefan Sylvius Wagner, Marc Höftmann, Eric Upschulte, Sebastian Konietzny, Maike Behrendt, Stefan Harmeling</li>
<li>for: 本文提供了一个总结性的综述，探讨了一些无监督学习方法，用于学习图像表示。这些表示可以用于下游任务，如分类或物体检测。</li>
<li>methods: 本文使用了一些无监督学习方法，包括自适应卷积神经网络、自适应层次神经网络和卷积神经网络。</li>
<li>results: 根据Literature review，这些方法在下游任务中表现非常出色，与监督学习方法相当。Here’s the translation in English:</li>
<li>for: This paper provides a comprehensive review of methods for learning image representations without supervision, which can be used in downstream tasks such as classification or object detection.</li>
<li>methods: The paper uses several unsupervised learning methods, including autoencoders, self-attention mechanisms, and convolutional neural networks.</li>
<li>results: According to the literature review, these methods have performed extremely well in downstream tasks, comparable to supervised learning methods.<details>
<summary>Abstract</summary>
Learning meaningful representations is at the heart of many tasks in the field of modern machine learning. Recently, a lot of methods were introduced that allow learning of image representations without supervision. These representations can then be used in downstream tasks like classification or object detection. The quality of these representations is close to supervised learning, while no labeled images are needed. This survey paper provides a comprehensive review of these methods in a unified notation, points out similarities and differences of these methods, and proposes a taxonomy which sets these methods in relation to each other. Furthermore, our survey summarizes the most-recent experimental results reported in the literature in form of a meta-study. Our survey is intended as a starting point for researchers and practitioners who want to dive into the field of representation learning.
</details>
<details>
<summary>摘要</summary>
学习有意义的表示是现代机器学习领域中的核心任务之一。最近，许多无监督学习方法被引入，可以学习图像表示。这些表示可以在下游任务中使用，如分类或物体检测。这些无监督学习方法的表示质量与监督学习相似，但无需标注图像。本文提供了这些方法的统一notation，指出这些方法之间的相似性和差异，并提出了这些方法的分类方式。此外，我们的survey还summarized了Literature中最近的实验结果，并进行了meta-study。本文为研究者和实践者提供了进入无监督学习领域的开始点。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Convergence-guarantee-for-consistency-models"><a href="#Convergence-guarantee-for-consistency-models" class="headerlink" title="Convergence guarantee for consistency models"></a>Convergence guarantee for consistency models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11449">http://arxiv.org/abs/2308.11449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junlong Lyu, Zhitang Chen, Shoubo Feng</li>
<li>for: 这 paper 的目的是为Consistency Models (CMs) 提供首次一致性保证，这种一步生成模型可以生成与Diffusion Models相同的样本。</li>
<li>methods: 这 paper 使用了基本的score-matching error assumption, consistency error assumption和数据分布的smoothness假设，以确保CMs 可以效率地从任何现实数据分布中采样，并且采样Error小于$W_2$.</li>
<li>results: 这 paper 的结果包括：(1) 对于$L^2$-accurate score和consistency假设，CMs 可以在一步中采样到任何现实数据分布，并且采样Error scales polynomially in all parameters; (2) 不需要强制对数据分布的假设，如log-Sobelev inequality; (3) 可以further reduce the error by using Multistep Consistency Sampling procedure.<details>
<summary>Abstract</summary>
We provide the first convergence guarantees for the Consistency Models (CMs), a newly emerging type of one-step generative models that can generate comparable samples to those generated by Diffusion Models. Our main result is that, under the basic assumptions on score-matching errors, consistency errors and smoothness of the data distribution, CMs can efficiently sample from any realistic data distribution in one step with small $W_2$ error. Our results (1) hold for $L^2$-accurate score and consistency assumption (rather than $L^\infty$-accurate); (2) do note require strong assumptions on the data distribution such as log-Sobelev inequality; (3) scale polynomially in all parameters; and (4) match the state-of-the-art convergence guarantee for score-based generative models (SGMs). We also provide the result that the Multistep Consistency Sampling procedure can further reduce the error comparing to one step sampling, which support the original statement of "Consistency Models, Yang Song 2023". Our result further imply a TV error guarantee when take some Langevin-based modifications to the output distributions.
</details>
<details>
<summary>摘要</summary>
我们提供了一些一步生成模型（CM）的协调保证，这是一种最近崛起的一种生成模型，可以生成与演化模型（Diffusion Models）相似的样本。我们的主要结果是，假设score-matching error、consistency error和资料分布的平滑性满足某些基本假设，则CM可以将任何现实的资料分布 efficiently sampled in one step with small $W_2$ error。我们的结果包括：1. 对于$L^2$-accurate score和consistency假设（而不是$L^\infty$-accurate）;2. 不需要对于资料分布的强则假设，如log-Sobelev不等式;3. 随所有参数的度量 polynomially scale;4. 与state-of-the-art score-based生成模型（SGMs）的协调保证相符。我们还提供了一个Multistep Consistency Sampling程序，可以降低比一步样本的错误，这支持原始的“Consistency Models, Yang Song 2023”的声明。我们的结果进一步显示了一个TV错误保证，当将一些Langevin-based modifications套用到输出分布时。
</details></li>
</ul>
<hr>
<h2 id="Aspect-oriented-Opinion-Alignment-Network-for-Aspect-Based-Sentiment-Classification"><a href="#Aspect-oriented-Opinion-Alignment-Network-for-Aspect-Based-Sentiment-Classification" class="headerlink" title="Aspect-oriented Opinion Alignment Network for Aspect-Based Sentiment Classification"></a>Aspect-oriented Opinion Alignment Network for Aspect-Based Sentiment Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11447">http://arxiv.org/abs/2308.11447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aone-nlp/absa-aoan">https://github.com/aone-nlp/absa-aoan</a></li>
<li>paper_authors: Xueyi Liu, Rui Hou, Yanglei Gan, Da Luo, Changlin Li, Xiaojun Shi, Qiao Liu</li>
<li>for: 这篇论文目的是提出一种新的方法来解决在多个方面的文本分析中存在的semantic mismatch问题，以提高 Fine-grained sentiment analysis 的精度。</li>
<li>methods: 该方法使用了一种新的Aspect-oriented Opinion Alignment Network (AOAN)，包括一个邻域span增强模块和一个多元视角注意机制，以强调对Opinion words和对应的方面的上下文关系。</li>
<li>results: 实验结果表明，该模型在三个标准数据集上达到了领域的最佳效果，代表着该方法在 Fine-grained sentiment analysis 中的成功应用。<details>
<summary>Abstract</summary>
Aspect-based sentiment classification is a crucial problem in fine-grained sentiment analysis, which aims to predict the sentiment polarity of the given aspect according to its context. Previous works have made remarkable progress in leveraging attention mechanism to extract opinion words for different aspects. However, a persistent challenge is the effective management of semantic mismatches, which stem from attention mechanisms that fall short in adequately aligning opinions words with their corresponding aspect in multi-aspect sentences. To address this issue, we propose a novel Aspect-oriented Opinion Alignment Network (AOAN) to capture the contextual association between opinion words and the corresponding aspect. Specifically, we first introduce a neighboring span enhanced module which highlights various compositions of neighboring words and given aspects. In addition, we design a multi-perspective attention mechanism that align relevant opinion information with respect to the given aspect. Extensive experiments on three benchmark datasets demonstrate that our model achieves state-of-the-art results. The source code is available at https://github.com/AONE-NLP/ABSA-AOAN.
</details>
<details>
<summary>摘要</summary>
<SYS>    <TRANSLATE_TEXT>        非常详细的 sentiment 分析中，尤其是 aspect-based sentiment classification，目标是根据不同的上下文来预测具体的 sentiment 偏好。先前的研究已经做出了很大的进步，通过使用注意力机制来提取不同的 opinion 词。但是，一个持续的挑战是如何有效地处理 semantic 匹配问题，这些问题来自于注意力机制不够地对 opinion 词和对应的 aspect 进行匹配。为了解决这个问题，我们提出了一种新的 Aspect-oriented Opinion Alignment Network (AOAN)，用于捕捉不同的 opinion 词和 aspect 之间的上下文关系。</TRANSLATE_TEXT></SYS>Here's the translation in Traditional Chinese:<SYS>    <TRANSLATE_TEXT>        非常细致的 sentiment 分析中，尤其是 aspect-based sentiment classification，目标是根据不同的上下文来预测具体的 sentiment 偏好。先前的研究已经做出了很大的进步，通过使用注意力机制来提取不同的 opinion 词。但是，一个持续的挑战是如何有效地处理 semantic 匹配问题，这些问题来自于注意力机制不够地对 opinion 词和对应的 aspect 进行匹配。为了解决这个问题，我们提出了一种新的 Aspect-oriented Opinion Alignment Network (AOAN)，用于捕捉不同的 opinion 词和 aspect 之间的上下文关系。</TRANSLATE_TEXT></SYS>Note that the translation is in Simplified Chinese, as requested. If you would like the translation in Traditional Chinese instead, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data"><a href="#Exploration-of-Rashomon-Set-Assists-Explanations-for-Medical-Data" class="headerlink" title="Exploration of Rashomon Set Assists Explanations for Medical Data"></a>Exploration of Rashomon Set Assists Explanations for Medical Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11446">http://arxiv.org/abs/2308.11446</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarzyna Kobylińska, Mateusz Krzyziński, Rafał Machowicz, Mariusz Adamek, Przemysław Biecek</li>
<li>For: This paper aims to address the problem of relying solely on performance metrics in machine learning modeling, particularly in medical and healthcare studies, by introducing a novel process to explore Rashomon set models.* Methods: The proposed approach uses the $\texttt{Rashomon_DETECT}$ algorithm to identify the most different models within the Rashomon set, and the Profile Disparity Index (PDI) to quantify differences in variable effects among models.* Results: The approach is demonstrated on a foundational case study of predicting survival among hemophagocytic lymphohistiocytosis (HLH) patients, as well as on other medical data sets, showing its effectiveness and versatility in various contexts.Here are the three points in Simplified Chinese:* For: 这篇论文目的是解决机器学习模型选择过程中围绕性能指标偏重的问题，尤其在医疗和健康研究中，以获得更多的有价值信息。* Methods: 该方法使用 $\texttt{Rashomon_DETECT}$ 算法 Identify Rashomon set 中最为不同的模型，并使用 Profile Disparity Index (PDI) 量化变量效果之间的差异。* Results: 该方法在针对 Hemophagocytic lymphohistiocytosis (HLH) 患者存活预测的基本案例研究中，以及其他医疗数据集中，得到了有效和多样的结果。<details>
<summary>Abstract</summary>
The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorithm. This algorithm compares profiles illustrating prediction dependencies on variable values generated by eXplainable Artificial Intelligence (XAI) techniques. To quantify differences in variable effects among models, we introduce the Profile Disparity Index (PDI) based on measures from functional data analysis. To illustrate the effectiveness of our approach, we showcase its application in predicting survival among hemophagocytic lymphohistiocytosis (HLH) patients - a foundational case study. Additionally, we benchmark our approach on other medical data sets, demonstrating its versatility and utility in various contexts.
</details>
<details>
<summary>摘要</summary>
传统的机器学习模型选择过程是通过选择最大化一个选择的性能指标来完成的。然而，这种方法会抛弃更深入的模型分析。特别在医疗和健康研究中，目标不仅是预测，还是生成有价值的理解。只靠性能指标来结论可能导致误导或不完整的结论。这种问题特别存在于处理一组性能几乎最大的模型集合，称为“Rashomon集”。这个集合可能很多，其中包含描述数据不同方式的模型，需要全面的分析。本文提出了一种新的模型探索过程，扩展传统模型选择策略。其核心是在Rashomon集中 identific 最不同的模型，由我们引入的 $\texttt{Rashomon\_DETECT}$ 算法实现。这个算法比较使用 eXplainable Artificial Intelligence（XAI）技术生成的变量值预测依赖的profile。为了量化不同模型中变量效应的差异，我们引入了 Profile Disparity Index（PDI），基于函数数据分析中的度量。我们通过应用这种方法在 Hemophagocytic lymphohistiocytosis（HLH）患者的存活预测中进行了示例，并将其应用于其他医疗数据集，以示其多样性和可用性。
</details></li>
</ul>
<hr>
<h2 id="Inferring-gender-from-name-a-large-scale-performance-evaluation-study"><a href="#Inferring-gender-from-name-a-large-scale-performance-evaluation-study" class="headerlink" title="Inferring gender from name: a large scale performance evaluation study"></a>Inferring gender from name: a large scale performance evaluation study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12381">http://arxiv.org/abs/2308.12381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kriste Krstovski, Yao Lu, Ye Xu</li>
<li>for: 这个论文主要目的是为了对名称到性别推断的算法和软件产品进行大规模性能评估，以及提出两种新的混合方法以实现更高的性能。</li>
<li>methods: 本文使用了多个大量注释的名称数据集来进行分析，并提出了两种新的混合方法。</li>
<li>results: 研究发现现有方法中的任何一种都无法在所有情况下达到最佳性能，而两种新提出的混合方法均可以在所有情况下实现更高的性能。<details>
<summary>Abstract</summary>
A person's gender is a crucial piece of information when performing research across a wide range of scientific disciplines, such as medicine, sociology, political science, and economics, to name a few. However, in increasing instances, especially given the proliferation of big data, gender information is not readily available. In such cases researchers need to infer gender from readily available information, primarily from persons' names. While inferring gender from name may raise some ethical questions, the lack of viable alternatives means that researchers have to resort to such approaches when the goal justifies the means - in the majority of such studies the goal is to examine patterns and determinants of gender disparities. The necessity of name-to-gender inference has generated an ever-growing domain of algorithmic approaches and software products. These approaches have been used throughout the world in academia, industry, governmental and non-governmental organizations. Nevertheless, the existing approaches have yet to be systematically evaluated and compared, making it challenging to determine the optimal approach for future research. In this work, we conducted a large scale performance evaluation of existing approaches for name-to-gender inference. Analysis are performed using a variety of large annotated datasets of names. We further propose two new hybrid approaches that achieve better performance than any single existing approach.
</details>
<details>
<summary>摘要</summary>
人的性别信息是科学研究中不可或缺的重要信息，包括医学、社会学、政治科学和经济学等领域。然而，随着大数据的普及，性别信息越来越难以获得。在这些情况下，研究人员需要根据可用的信息进行性别推断，主要是根据人名。虽然从名字中推断性别可能会附带一些伦理问题，但由于现有的可行方法缺乏，研究人员需要采用这些方法以实现研究目标。在全球范围内，这些方法已经广泛应用于大学、企业、政府和非政府组织中。然而，现有的方法尚未得到系统性的评估和比较，这使得未来研究中选择最佳方法仍然存在挑战。在这项工作中，我们进行了大规模性能评估现有的名字到性别推断方法。分析使用了多种大量注释的名字数据集。此外，我们还提出了两种新的混合方法，其性能更高于任何单独的现有方法。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Large-Language-Model-based-Autonomous-Agents"><a href="#A-Survey-on-Large-Language-Model-based-Autonomous-Agents" class="headerlink" title="A Survey on Large Language Model based Autonomous Agents"></a>A Survey on Large Language Model based Autonomous Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11432">http://arxiv.org/abs/2308.11432</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paitesanshi/llm-agent-survey">https://github.com/paitesanshi/llm-agent-survey</a></li>
<li>paper_authors: Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, Ji-Rong Wen</li>
<li>for: 本研究准备了一份总结LLM基于自主代理的研究，包括LLM基于代理的构建、应用领域和评价策略等方面。</li>
<li>methods: 本研究使用了大量网络知识获得的大语言模型(LLM)，并提出了一个统一框架来涵盖大多数之前的工作。</li>
<li>results: 本研究通过对LLM基于代理的各种应用领域和评价策略的总结，提出了一些挑战和未来方向，并将相关参考文献存储在<a target="_blank" rel="noopener" href="https://github.com/Paitesanshi/LLM-Agent-Survey%E4%B8%AD%E3%80%82">https://github.com/Paitesanshi/LLM-Agent-Survey中。</a><details>
<summary>Abstract</summary>
Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework that encompasses a majority of the previous work. Additionally, we provide a summary of the various applications of LLM-based AI agents in the domains of social science, natural science, and engineering. Lastly, we discuss the commonly employed evaluation strategies for LLM-based AI agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository for the related references at https://github.com/Paitesanshi/LLM-Agent-Survey.
</details>
<details>
<summary>摘要</summary>
自主代理已经是学术界的一个主要研究话题，早期的研究通常是在隔离环境中训练有限知识的代理，这与人类学习过程不同，导致代理做出的决策困难达到人类水平。然而，随着互联网知识的掌握，大型自然语言模型（LLM）在实现人类智能水平方面表现出了很好的潜力。这导致了对自主代理基于 LLM 的研究的快速增长。为了挖掘 LLM 的潜力，研究者们设计了多种特定应用场景的代理建模。在这篇文章中，我们提供了一份系统性的评论，涵盖了这些研究的大部分。我们更加关注 LLM 基于代理的建模，并提出了一个统一框架，覆盖了大多数前期工作。此外，我们还提供了自然科学、社会科学和工程等领域 LLM 基于 AI 代理的多种应用案例。最后，我们讨论了对 LLM 基于 AI 代理的评价策略，并根据前期研究提出了一些挑战和未来方向。为了保持这一领域的报道和不断更新我们的评论，我们在 GitHub 上建立了一个参考库，可以在 https://github.com/Paitesanshi/LLM-Agent-Survey 中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework"><a href="#A-Study-on-the-Impact-of-Non-confounding-Covariates-on-the-Inferential-Performance-of-Methods-based-on-the-Potential-Outcome-Framework" class="headerlink" title="A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework"></a>A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11676">http://arxiv.org/abs/2308.11676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghe Zhao, Shuai Fu, Huiyan Sun</li>
<li>for: The paper is written to provide a unified graphical framework for causal inference models based on the Potential Outcome Framework (POF), and to analyze the influence of non-confounding covariates on the inference performance of these models.</li>
<li>methods: The paper uses a graphical framework to present the underlying principles of causal inference models based on the POF, and conducts extensive experiments on synthetic datasets to validate the theoretical conclusions.</li>
<li>results: The paper finds that the optimal scenario for eliminating confounding bias is for the covariates to exclusively encompass confounders, and that adjustment variables contribute to more accurate inferences in the task of inferring counterfactual outcomes.<details>
<summary>Abstract</summary>
The Potential Outcome Framework (POF) plays a prominent role in the field of causal inference. Most causal inference models based on the POF (CIMs-B-POF) are designed for eliminating confounding bias and default to an underlying assumption of Confounding Covariates. This assumption posits that the covariates consist solely of confounders. However, the assumption of Confounding Covariates is challenging to maintain in practice, particularly when dealing with high-dimensional covariates. While certain methods have been proposed to differentiate the distinct components of covariates prior to conducting causal inference, the consequences of treating non-confounding covariates as confounders remain unclear. This ambiguity poses a potential risk when applying the CIMs-B-POF in practical scenarios. In this paper, we present a unified graphical framework for the CIMs-B-POF, which greatly enhances the comprehension of these models' underlying principles. Using this graphical framework, we quantitatively analyze the extent to which the inference performance of CIMs-B-POF is influenced when incorporating various types of non-confounding covariates, such as instrumental variables, mediators, colliders, and adjustment variables. The key findings are: in the task of eliminating confounding bias, the optimal scenario is for the covariates to exclusively encompass confounders; in the subsequent task of inferring counterfactual outcomes, the adjustment variables contribute to more accurate inferences. Furthermore, extensive experiments conducted on synthetic datasets consistently validate these theoretical conclusions.
</details>
<details>
<summary>摘要</summary>
Potential Outcome Framework (POF) 在 causal inference 领域扮演着重要的角色。大多数基于 POF 的 causal inference 模型 (CIMs-B-POF) 是为了消除干扰偏见而设计的，默认假设是 Confounding Covariates 假设，即 covariates 仅仅包含干扰因素。然而，在实践中保持 Confounding Covariates 假设是困难的，特别是处理高维 covariates 时。虽然一些方法已经被提出来分解 covariates 的不同组成部分，然而对非干扰 covariates 被视为干扰因素的后果仍然不清楚。这种不确定性在实践中应用 CIMs-B-POF 时可能存在风险。在这篇论文中，我们提出了一个统一的图形 Framework  для CIMs-B-POF，这有助于更好地理解这些模型的基本原理。使用这个图形 Framework，我们量化分析了在不同类型的非干扰 covariates 存在时，CIMs-B-POF 的推理性能是如何受影响的。我们发现，在消除干扰偏见的任务中，理想的情况是 covariates 仅仅包含干扰因素；在后续的对 counterfactual 结果进行推理任务中，调整变量对更准确的推理做出了贡献。此外，我们在 synthetic 数据上进行了广泛的实验，并 consistently 验证了这些理论结论。
</details></li>
</ul>
<hr>
<h2 id="AIxArtist-A-First-Person-Tale-of-Interacting-with-Artificial-Intelligence-to-Escape-Creative-Block"><a href="#AIxArtist-A-First-Person-Tale-of-Interacting-with-Artificial-Intelligence-to-Escape-Creative-Block" class="headerlink" title="AIxArtist: A First-Person Tale of Interacting with Artificial Intelligence to Escape Creative Block"></a>AIxArtist: A First-Person Tale of Interacting with Artificial Intelligence to Escape Creative Block</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11424">http://arxiv.org/abs/2308.11424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Makayla Lewis</li>
<li>for: 这篇论文探讨了人工智能（AI）如何支持艺术创作，以及在艺术创作过程中AI的可追溯性。</li>
<li>methods: 本论文采用了人工智能工具HIS、ChatGPT和Midjourney，进行了一些实验和探索，以探索AI如何支持艺术创作。</li>
<li>results: 本论文发现了一些关键问题，包括创作过程的透明性、作品的起源和伦理问题，以及创作是 copying 还是灵感？这些问题需要进一步的讨论和探索。<details>
<summary>Abstract</summary>
The future of the arts and artificial intelligence (AI) is promising as technology advances. As the use of AI in design becomes more widespread, art practice may not be a human-only art form and could instead become a digitally integrated experience. With enhanced creativity and collaboration, arts and AI could work together towards creating artistic outputs that are visually appealing and meet the needs of the artist and viewer. While it is uncertain how far the integration will go, arts and AI will likely influence one another. This workshop pictorial puts forward first-person research that shares interactions between an HCI researcher and AI as they try to escape the creative block. The pictorial paper explores two questions: How can AI support artists' creativity, and what does it mean to be explainable in this context? HIs, ChatGPT and Midjourney were engaged; the result was a series of reflections that require further discussion and explorations in the XAIxArts community: Transparency of attribution, the creation process, ethics of asking, and inspiration vs copying.
</details>
<details>
<summary>摘要</summary>
This workshop pictorial presents first-person research that explores the interactions between an HCI researcher and AI as they try to escape creative blocks. The pictorial paper examines two questions: how can AI support artists' creativity, and what does it mean to be explainable in this context? The research involved engaging with AI models such as ChatGPT and Midjourney, leading to a series of reflections that require further discussion and exploration in the XAIxArts community. These reflections include transparency of attribution, the creation process, ethics of asking, and inspiration vs copying.
</details></li>
</ul>
<hr>
<h2 id="TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search"><a href="#TurboViT-Generating-Fast-Vision-Transformers-via-Generative-Architecture-Search" class="headerlink" title="TurboViT: Generating Fast Vision Transformers via Generative Architecture Search"></a>TurboViT: Generating Fast Vision Transformers via Generative Architecture Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11421">http://arxiv.org/abs/2308.11421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Wong, Saad Abbasi, Saeejith Nair</li>
<li>for: 这个研究的目的是实现高通过率且低 computation complexity的类比视觉 Transformer 架构设计。</li>
<li>methods: 这个研究使用了 Generative Architecture Search (GAS) 来生成高效的类比视觉 Transformer 架构设计，并且将注意力集中在面精度和 Q-pooling 设计模式上。</li>
<li>results: TurboViT 架构设计在 ImageNet-1K 数据集上实现了比较高的精度和低的 computation complexity，与其他 10 个现有的高效类比视觉 Transformer 网络架构设计相比。 Inference 延误和批处处理时间都表现出色，在低延误场景下，TurboViT 的延误时间比 FasterViT-0 低了 &gt;3.21 倍，而且对 batch 处理也表现出 &gt;3.18 倍的提高。<details>
<summary>Abstract</summary>
Vision transformers have shown unprecedented levels of performance in tackling various visual perception tasks in recent years. However, the architectural and computational complexity of such network architectures have made them challenging to deploy in real-world applications with high-throughput, low-memory requirements. As such, there has been significant research recently on the design of efficient vision transformer architectures. In this study, we explore the generation of fast vision transformer architecture designs via generative architecture search (GAS) to achieve a strong balance between accuracy and architectural and computational efficiency. Through this generative architecture search process, we create TurboViT, a highly efficient hierarchical vision transformer architecture design that is generated around mask unit attention and Q-pooling design patterns. The resulting TurboViT architecture design achieves significantly lower architectural computational complexity (>2.47$\times$ smaller than FasterViT-0 while achieving same accuracy) and computational complexity (>3.4$\times$ fewer FLOPs and 0.9% higher accuracy than MobileViT2-2.0) when compared to 10 other state-of-the-art efficient vision transformer network architecture designs within a similar range of accuracy on the ImageNet-1K dataset. Furthermore, TurboViT demonstrated strong inference latency and throughput in both low-latency and batch processing scenarios (>3.21$\times$ lower latency and >3.18$\times$ higher throughput compared to FasterViT-0 for low-latency scenario). These promising results demonstrate the efficacy of leveraging generative architecture search for generating efficient transformer architecture designs for high-throughput scenarios.
</details>
<details>
<summary>摘要</summary>
视transformer在近年来的视觉任务中表现出了前所未有的水平。然而，这些网络架构的建筑和计算复杂性使得它们在实际应用中高速、低内存要求下部署困难。因此，有一些研究是设计高效的视transformer架构。在这项研究中，我们通过生成式建筑搜索（GAS）来生成高效的视transformer架构设计，以达到精度和建筑计算效率的平衡。通过这个生成过程，我们创造了TurboViT，一种高效的层次视transformer架构设计，基于面积注意力和Q-Pooling设计模式。TurboViT架构设计的建筑计算复杂性比FasterViT-0大于2.47倍，计算复杂性比MobileViT2-2.0大于3.4倍，同时精度相同。此外，TurboViT在低延迟和批处理场景中表现出了优秀的执行时间和 Throughput，比FasterViT-0在低延迟场景下执行时间大于3.21倍，比MobileViT2-2.0在批处理场景下执行时间大于3.18倍。这些优秀的结果表明了利用生成式建筑搜索生成高效的transformer架构设计的有效性。
</details></li>
</ul>
<hr>
<h2 id="Tensor-Regression"><a href="#Tensor-Regression" class="headerlink" title="Tensor Regression"></a>Tensor Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11419">http://arxiv.org/abs/2308.11419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tensorly/torch">https://github.com/tensorly/torch</a></li>
<li>paper_authors: Jiani Liu, Ce Zhu, Zhen Long, Yipeng Liu</li>
<li>for:  This paper is written for students, researchers, and practitioners who work with high dimensional data and are interested in tensor-based regression analysis.</li>
<li>methods: The paper provides a systematic study and analysis of tensor-based regression models and their applications, including a comprehensive review of existing methods, their core ideas, and theoretical characteristics.</li>
<li>results: The paper covers the basics of tensor-based regression, provides examples of how to use existing methods to solve specific regression tasks with multiway data, and discusses available datasets and software resources for efficient implementation.<details>
<summary>Abstract</summary>
Regression analysis is a key area of interest in the field of data analysis and machine learning which is devoted to exploring the dependencies between variables, often using vectors. The emergence of high dimensional data in technologies such as neuroimaging, computer vision, climatology and social networks, has brought challenges to traditional data representation methods. Tensors, as high dimensional extensions of vectors, are considered as natural representations of high dimensional data. In this book, the authors provide a systematic study and analysis of tensor-based regression models and their applications in recent years. It groups and illustrates the existing tensor-based regression methods and covers the basics, core ideas, and theoretical characteristics of most tensor-based regression methods. In addition, readers can learn how to use existing tensor-based regression methods to solve specific regression tasks with multiway data, what datasets can be selected, and what software packages are available to start related work as soon as possible. Tensor Regression is the first thorough overview of the fundamentals, motivations, popular algorithms, strategies for efficient implementation, related applications, available datasets, and software resources for tensor-based regression analysis. It is essential reading for all students, researchers and practitioners of working on high dimensional data.
</details>
<details>
<summary>摘要</summary>
“tensor regression”是数据分析和机器学习领域的一个关键领域，旨在探索变量之间的依赖关系，通常使用向量。随着神经成像、计算机视觉、气候学和社交网络等技术的发展，传统的数据表示方法面临了挑战。tensor是高维数据的自然表示方法。本书提供了tensor-based regression模型的系统性研究和分析，以及其在最近几年的应用。它分组和描述了现有的tensor-based regression方法，覆盖基础知识、核心思想和主要特征。此外，读者还可以了解如何使用现有的tensor-based regression方法来解决特定的多向数据回归任务，选择合适的数据集和使用哪些软件包来进行相关工作。“tensor regression”是高维数据处理的基础知识，是所有师生、研究人员和实践者都必须阅读的一本书。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores"><a href="#Interpretable-Distribution-Invariant-Fairness-Measures-for-Continuous-Scores" class="headerlink" title="Interpretable Distribution-Invariant Fairness Measures for Continuous Scores"></a>Interpretable Distribution-Invariant Fairness Measures for Continuous Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11375">http://arxiv.org/abs/2308.11375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ann-Kristin Becker, Oana Dumitrasc, Klaus Broelemann</li>
<li>for: 这个论文主要是为了扩展对连续分数的算法公平性评估方法。</li>
<li>methods: 该论文提出了一种基于沃氏距离的公平性评估方法，该方法可以快速计算并且对不同模型、数据集或时间点进行比较。</li>
<li>results: 研究人员通过实验表明，新提出的公平性评估方法可以更好地捕捉到不同群体之间的差异，并且可以比较不同的模型、数据集或时间点之间的偏见。<details>
<summary>Abstract</summary>
Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-based fairness measures miss. Finally, we demonstrate their effectiveness through experiments on the most commonly used fairness benchmark datasets.
</details>
<details>
<summary>摘要</summary>
各种算法公平度量通常在二分类决策中被讨论。我们扩展了这种方法，以适应连续分数。目前，ROC基尼度量是为此目的提出的主要方法。其他现有方法受分布的影响很大，不适用于排名任务，或者其效果不能解释。我们提议一种不受分布影响的公平度量方法，基于温顿距离。我们的度量方法容易计算，适合量化和解释群体差异的强度以及不同模型、数据集、时间点之间的偏见。我们还 derivates了不同家族的现有公平度量方法之间的连接，并证明了我们提议的不受分布影响的公平度量方法在ROC基尼度量方法之上表现更好，因为它们更加明确，可以量化ROC基尼度量方法所过look的重要偏见。最后，我们通过使用最常用的公平性标准数据集进行实验，证明了它们的有效性。
</details></li>
</ul>
<hr>
<h2 id="How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation"><a href="#How-Much-Temporal-Long-Term-Context-is-Needed-for-Action-Segmentation" class="headerlink" title="How Much Temporal Long-Term Context is Needed for Action Segmentation?"></a>How Much Temporal Long-Term Context is Needed for Action Segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11358">http://arxiv.org/abs/2308.11358</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ltcontext/ltcontext">https://github.com/ltcontext/ltcontext</a></li>
<li>paper_authors: Emad Bahrami, Gianpiero Francesca, Juergen Gall</li>
<li>for:  temporal action segmentation</li>
<li>methods:  transformer-based model with sparse attention</li>
<li>results:  best performance for temporal action segmentationHere’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文是为了解决视频中的时间动作分割问题而写的。</li>
<li>methods: 这篇论文使用了 transformer 模型，并使用了稀谱注意力来捕捉整个视频的上下文。</li>
<li>results: 实验结果表明，模型需要捕捉整个视频的上下文，才能达到最佳的时间动作分割性能。<details>
<summary>Abstract</summary>
Modeling long-term context in videos is crucial for many fine-grained tasks including temporal action segmentation. An interesting question that is still open is how much long-term temporal context is needed for optimal performance. While transformers can model the long-term context of a video, this becomes computationally prohibitive for long videos. Recent works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window. While these approaches show good results, their performance is limited by their inability to capture the full context of a video. In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video. We compare our model with the current state of the art on three datasets for temporal action segmentation, namely 50Salads, Breakfast, and Assembly101. Our experiments show that modeling the full context of a video is necessary to obtain the best performance for temporal action segmentation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>模型长期视频上下文是多个细致任务的关键，包括时间动作 segmentation。一个有趣的问题是如何多少长期时间上下文是必需的 для最佳性能。虽然变换器可以模型视频的长期上下文，但这会对长视频计算昂贵。现有的时间动作 segmentation方法通过将时间卷积网络与自注意力组合在一起，但其性能受到当前视频上下文的限制。在这个工作中，我们尝试回答如何多少长期时间上下文是必需的 для时间动作 segmentation，我们提出了一种基于变换器的模型，通过稀疏注意力来捕捉整个视频的上下文。我们与当前领域的状态速算三个数据集进行比较，分别是50Salads、Breakfast和Assembly101。我们的实验结果表明，模型整个视频的上下文是获得最佳性能的关键。
</details></li>
</ul>
<hr>
<h2 id="Semantic-RGB-D-Image-Synthesis"><a href="#Semantic-RGB-D-Image-Synthesis" class="headerlink" title="Semantic RGB-D Image Synthesis"></a>Semantic RGB-D Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11356">http://arxiv.org/abs/2308.11356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Li, Rong Li, Juergen Gall</li>
<li>for: 提高RGB-D图像Semantic分割的训练数据多样性</li>
<li>methods: 提出了一种基于Semantic图像Synthesis的方法，使用多模态数据生成真实的RGB-D图像</li>
<li>results: 比前一代单模态方法有大幅提高，并且通过混合实际和生成图像进行训练可以进一步提高RGB-D图像Semantic分割的精度<details>
<summary>Abstract</summary>
Collecting diverse sets of training images for RGB-D semantic image segmentation is not always possible. In particular, when robots need to operate in privacy-sensitive areas like homes, the collection is often limited to a small set of locations. As a consequence, the annotated images lack diversity in appearance and approaches for RGB-D semantic image segmentation tend to overfit the training data. In this paper, we thus introduce semantic RGB-D image synthesis to address this problem. It requires synthesising a realistic-looking RGB-D image for a given semantic label map. Current approaches, however, are uni-modal and cannot cope with multi-modal data. Indeed, we show that extending uni-modal approaches to multi-modal data does not perform well. In this paper, we therefore propose a generator for multi-modal data that separates modal-independent information of the semantic layout from the modal-dependent information that is needed to generate an RGB and a depth image, respectively. Furthermore, we propose a discriminator that ensures semantic consistency between the label maps and the generated images and perceptual similarity between the real and generated images. Our comprehensive experiments demonstrate that the proposed method outperforms previous uni-modal methods by a large margin and that the accuracy of an approach for RGB-D semantic segmentation can be significantly improved by mixing real and generated images during training.
</details>
<details>
<summary>摘要</summary>
Collecting diverse sets of training images for RGB-D semantic image segmentation 不一定是可能的。特别是当机器人需要在隐私敏感的地方 like 家庭中运行时，收集是经常受限于一小组地点。因此，标注图像缺乏多样性的外观和RGB-D semantic image segmentation 的方法容易过拟合训练数据。在这篇论文中，我们因此引入semantic RGB-D 图像合成来解决这个问题。它需要生成一个看起来很真实的 RGB-D 图像，以及一个给定的semantic label map。current approach是单模的，无法处理多模数据。我们实际上发现，将单模方法扩展到多模数据并不能达到好的效果。因此，我们提议一个生成器，可以分离modal-independent信息和modal-dependent信息。此外，我们还提议一个检验器，确保标注图像和生成的图像之间的semantic consistency，以及生成的图像和实际图像之间的 percepatual similarity。我们的全面实验表明，我们的方法可以大幅提高前一代单模方法的性能，并且可以在训练时混合实际和生成的图像，以提高RGB-D semantic segmentation的精度。
</details></li>
</ul>
<hr>
<h2 id="ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models"><a href="#ProAgent-Building-Proactive-Cooperative-AI-with-Large-Language-Models" class="headerlink" title="ProAgent: Building Proactive Cooperative AI with Large Language Models"></a>ProAgent: Building Proactive Cooperative AI with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11339">http://arxiv.org/abs/2308.11339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PKU-Alignment/ProAgent">https://github.com/PKU-Alignment/ProAgent</a></li>
<li>paper_authors: Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang, Feng Yin, Yitao Liang, Yaodong Yang</li>
<li>for: 这个论文主要目标是为了开发一种能够在人机合作中表现出突出的智能代理（ProAgent），帮助人机合作实现更高效的协同作业。</li>
<li>methods: 这个论文使用了大型自然语言模型（LLM）来为代理机制表现出更高级别的智能行为，包括预测合作伙伴的下一步决策并根据此形ulate更好的计划。</li>
<li>results: 实验结果表明，ProAgent在与其他AI代理和人类代理合作时表现出了remarkable的性能优势，比如自适应学习和人类学习等方法。此外，ProAgent还具有高度可模块化和可解释性，可以轻松地整合到各种协同enario中。<details>
<summary>Abstract</summary>
Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations conducted within the framework of \textit{Overcook-AI} unveil the remarkable performance superiority of ProAgent, outperforming five methods based on self-play and population-based training in cooperation with AI agents. Further, when cooperating with human proxy models, its performance exhibits an average improvement exceeding 10\% compared to the current state-of-the-art, COLE. The advancement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. These findings inspire future research for human-robot collaborations. For a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)建立AI具有适应行为的概念在人类-AI合作中是AGI研究中的核心焦点。目前，开发合作代理人的方法主要依赖于学习方法，其策略泛化强度受到特定团队成员的交互影响。这些方法限制了代理人的策略重塑能力，面临新的团队成员时。我们提出了\textbf{ProAgent}框架，利用大型自然语言模型（LLMs）为代理人带来了能预测伙伴的决策并提出改进的计划的能力。ProAgent在合作理解方面表现出色，可以适应团队合作中的各种情况，并且具有高度的可重新组合性和可读性，可以轻松地与不同的协调enario进行集成。在\textit{Overcook-AI}框架下，我们进行了实验评估，发现ProAgent在与基于自我玩家和人口学习的五种方法进行比较时，在合作 with AI代理人方面表现出了杰出的性能优势。此外，当与人类代理模型进行合作时，其性能表现出了平均提高超过10%，与当前的状态艺术COLE相比。这些发现在不同的情况下，包括与不同特征的AI代理人和人类对手进行交互时，均得到了证明。这些发现 inspirits future research on human-robot collaboration. For a hands-on demonstration, please visit \url{https://pku-proagent.github.io}.
</details></li>
</ul>
<hr>
<h2 id="On-the-Opportunities-and-Challenges-of-Offline-Reinforcement-Learning-for-Recommender-Systems"><a href="#On-the-Opportunities-and-Challenges-of-Offline-Reinforcement-Learning-for-Recommender-Systems" class="headerlink" title="On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems"></a>On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11336">http://arxiv.org/abs/2308.11336</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaocong Chen, Siyu Wang, Julian McAuley, Dietmar Jannach, Lina Yao</li>
<li>for: 本研究旨在探讨在推荐系统中使用无线连接学习，特别是在不同的环境下进行学习和推荐。</li>
<li>methods: 本研究使用了无线连接学习的各种方法，包括Q-learning、SARSA和 Deep Q-Networks等，以学习用户的偏好和行为。</li>
<li>results: 研究发现，使用无线连接学习可以提高推荐系统的数据效率和学习速度，同时也可以提高用户的满意度和使用频率。<details>
<summary>Abstract</summary>
Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on recommender systems utilizing offline reinforcement learning remain limited. This survey aims to introduce and delve into offline reinforcement learning within recommender systems, offering an inclusive review of existing literature in this domain. Furthermore, we strive to underscore prevalent challenges, opportunities, and future pathways, poised to propel research in this evolving field.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GrowCLIP-Data-aware-Automatic-Model-Growing-for-Large-scale-Contrastive-Language-Image-Pre-training"><a href="#GrowCLIP-Data-aware-Automatic-Model-Growing-for-Large-scale-Contrastive-Language-Image-Pre-training" class="headerlink" title="GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-training"></a>GrowCLIP: Data-aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11331">http://arxiv.org/abs/2308.11331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinchi Deng, Han Shi, Runhui Huang, Changlin Li, Hang Xu, Jianhua Han, James Kwok, Shen Zhao, Wei Zhang, Xiaodan Liang</li>
<li>for: 本文提出了一种数据驱动自动模型增长算法，用于对语言-图像做contrastive预训练，并且可以处理不断增长的在线数据。</li>
<li>methods: 本文使用了动态增长空间和最优化 архитектуры，以适应在线学习场景。同时，提出了共享编码器，以增强语言-图像融合度。</li>
<li>results: 相比已有方法，GrowCLIP在零参数图像分类任务上提高了2.3%的平均排名第一精度。在Flickr30K dataset上，GrowCLIP在零参数图像检索任务上提高了1.2%的找到第一图像-文本准确率。<details>
<summary>Abstract</summary>
Cross-modal pre-training has shown impressive performance on a wide range of downstream tasks, benefiting from massive image-text pairs collected from the Internet. In practice, online data are growing constantly, highlighting the importance of the ability of pre-trained model to learn from data that is continuously growing. Existing works on cross-modal pre-training mainly focus on training a network with fixed architecture. However, it is impractical to limit the model capacity when considering the continuously growing nature of pre-training data in real-world applications. On the other hand, it is important to utilize the knowledge in the current model to obtain efficient training and better performance. To address the above issues, in this paper, we propose GrowCLIP, a data-driven automatic model growing algorithm for contrastive language-image pre-training with continuous image-text pairs as input. Specially, we adopt a dynamic growth space and seek out the optimal architecture at each growth step to adapt to online learning scenarios. And the shared encoder is proposed in our growth space to enhance the degree of cross-modal fusion. Besides, we explore the effect of growth in different dimensions, which could provide future references for the design of cross-modal model architecture. Finally, we employ parameter inheriting with momentum (PIM) to maintain the previous knowledge and address the issue of the local minimum dilemma. Compared with the existing methods, GrowCLIP improves 2.3% average top-1 accuracy on zero-shot image classification of 9 downstream tasks. As for zero-shot image retrieval, GrowCLIP can improve 1.2% for top-1 image-to-text recall on Flickr30K dataset.
</details>
<details>
<summary>摘要</summary>
跨modal预训练已经在各种下游任务中显示出很好的性能，受到互联网上庞大的图片文本对的收集启发。在实践中，网络上数据不断增长，高亮了预训练数据的不断增长的重要性。现有的跨modal预训练方法主要是通过固定的网络架构进行训练。然而，在实际应用中，限制模型容量是不切实际的，因为预训练数据的不断增长会导致模型无法适应。相反，我们需要利用当前模型的知识来获得高效的训练和更好的性能。为此，在这篇论文中，我们提出了GrowCLIP，一种基于数据驱动的自动模型增长算法，用于对冲对的语言图片预训练。我们采用动态生长空间，在每个增长步骤中寻找最佳的网络架构，以适应在线学习场景。此外，我们还提出了共享编码器，以增强模型之间的混合度。此外，我们还研究了不同维度的增长效果，这可能会对未来的跨modal模型架构设计产生影响。最后，我们采用参数继承与势（PIM）来维护之前的知识，解决局部最小问题。相比之下，GrowCLIP与现有方法相比，提高了9个下游任务的zero-shot图像分类精度，平均提高2.3%。此外，GrowCLIP还可以提高Flickr30K dataset上的zero-shot图像检索的top-1图像文本恢复率，提高1.2%。
</details></li>
</ul>
<hr>
<h2 id="From-Mundane-to-Meaningful-AI’s-Influence-on-Work-Dynamics-–-evidence-from-ChatGPT-and-Stack-Overflow"><a href="#From-Mundane-to-Meaningful-AI’s-Influence-on-Work-Dynamics-–-evidence-from-ChatGPT-and-Stack-Overflow" class="headerlink" title="From Mundane to Meaningful: AI’s Influence on Work Dynamics – evidence from ChatGPT and Stack Overflow"></a>From Mundane to Meaningful: AI’s Influence on Work Dynamics – evidence from ChatGPT and Stack Overflow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11302">http://arxiv.org/abs/2308.11302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quentin Gallea</li>
<li>for: 这篇论文探讨了如何利用生成AI实现代码编程的产生效率提升，同时也提出了这些新技术对工作和知识共享方式的影响。</li>
<li>methods: 该论文使用了 quasi-experimental 方法（差异分析），利用Stack Overflow上最大的在线编程社区的使用情况，评估 ChatGPT 的发布对编程问题的影响。</li>
<li>results: 研究发现，ChatGPT 的发布导致编程问题数量减少，同时问题的 докуumenation 质量也有所提高。此外，剩下的问题也变得更加复杂。这些结果表明，利用生成AI可以实现工作效率提升，同时也会导致工作方式的重大变革，让人类专注于更加复杂的任务。<details>
<summary>Abstract</summary>
This paper illustrates how generative AI could give opportunities for big productivity gains but also opens up questions about the impact of these new powerful technologies on the way we work and share knowledge. More specifically, we explore how ChatGPT changed a fundamental aspect of coding: problem-solving. To do so, we exploit the effect of the sudden release of ChatGPT on the 30th of November 2022 on the usage of the largest online community for coders: Stack Overflow. Using quasi-experimental methods (Difference-in-Difference), we find a significant drop in the number of questions. In addition, the questions are better documented after the release of ChatGPT. Finally, we find evidence that the remaining questions are more complex. These findings suggest not only productivity gains but also a fundamental change in the way we work where routine inquiries are solved by AI allowing humans to focus on more complex tasks.
</details>
<details>
<summary>摘要</summary>
In Simplified Chinese:这篇论文描述了如何生成AI可以带来大量的产出增长，但同时也提出了这些新技术对我们工作和知识分享方式的影响。我们Specifically，我们研究了ChatGPT如何改变编程中的问题解决方式。为此，我们利用了chatGPT于11月30日的突然发布对Stack Overflow上最大的编程社区的使用情况产生的影响。使用 quasi-experimental方法（Difference-in-Difference），我们发现了问题数量减少的显著影响。此外，剩下的问题更加详细。这些发现不仅表明产出增长，还表明了我们工作的基本变革，Routine inquiry由AI解决，让人类可以专注于更复杂的任务。
</details></li>
</ul>
<hr>
<h2 id="Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation"><a href="#Improving-Knot-Prediction-in-Wood-Logs-with-Longitudinal-Feature-Propagation" class="headerlink" title="Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation"></a>Improving Knot Prediction in Wood Logs with Longitudinal Feature Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11291">http://arxiv.org/abs/2308.11291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeremyfix/icvs2023">https://github.com/jeremyfix/icvs2023</a></li>
<li>paper_authors: Salim Khazem, Jeremy Fix, Cédric Pradalier</li>
<li>for: 本研究旨在预测木材内部缺陷的位置，以提高木材质量评估的准确性和效率。</li>
<li>methods: 本研究使用了卷积回归神经网络来解决木材外形特征与内部缺陷的Binary segmentation任务。</li>
<li>results: 研究表明，通过使用便宜的外形测量设备（如激光 Profiler）进行训练，可以通过卷积回归神经网络来预测木材内部缺陷的位置，并且可以在不同的树种上进行效果评估。<details>
<summary>Abstract</summary>
The quality of a wood log in the wood industry depends heavily on the presence of both outer and inner defects, including inner knots that are a result of the growth of tree branches. Today, locating the inner knots require the use of expensive equipment such as X-ray scanners. In this paper, we address the task of predicting the location of inner defects from the outer shape of the logs. The dataset is built by extracting both the contours and the knots with X-ray measurements. We propose to solve this binary segmentation task by leveraging convolutional recurrent neural networks. Once the neural network is trained, inference can be performed from the outer shape measured with cheap devices such as laser profilers. We demonstrate the effectiveness of our approach on fir and spruce tree species and perform ablation on the recurrence to demonstrate its importance.
</details>
<details>
<summary>摘要</summary>
木材行业中木材质量受到内部和外部缺陷的影响，包括由树木分支生长而成的内弯。今天，找到内弯需要使用昂贵的设备，如X射线扫描仪。在这篇论文中，我们解决了根据外形测量内弯的任务。我们提出使用卷积回归神经网络解决这个二分类任务。一旦神经网络训练完毕，可以通过便宜的设备，如激光 Profilers 进行推理。我们在桦树和落叶树种中展示了我们的方法的效果，并对循环的重要性进行了剖除。
</details></li>
</ul>
<hr>
<h2 id="ShadowNet-for-Data-Centric-Quantum-System-Learning"><a href="#ShadowNet-for-Data-Centric-Quantum-System-Learning" class="headerlink" title="ShadowNet for Data-Centric Quantum System Learning"></a>ShadowNet for Data-Centric Quantum System Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11290">http://arxiv.org/abs/2308.11290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Du, Yibo Yang, Tongliang Liu, Zhouchen Lin, Bernard Ghanem, Dacheng Tao</li>
<li>for: 本研究旨在探讨大量量子系统的动态学习问题，以减轻维度祸咎的影响。</li>
<li>methods: 本研究提出了一种数据驱动学习 paradigma，结合了神经网络协议和经典阴影，以便实现多种量子学习任务。</li>
<li>results: 研究表明，该 paradigma可以在偏远量子系统中提供准确和可靠的预测结果，并且可以在批处理大量量子系统时实现快速和高效的预测。<details>
<summary>Abstract</summary>
Understanding the dynamics of large quantum systems is hindered by the curse of dimensionality. Statistical learning offers new possibilities in this regime by neural-network protocols and classical shadows, while both methods have limitations: the former is plagued by the predictive uncertainty and the latter lacks the generalization ability. Here we propose a data-centric learning paradigm combining the strength of these two approaches to facilitate diverse quantum system learning (QSL) tasks. Particularly, our paradigm utilizes classical shadows along with other easily obtainable information of quantum systems to create the training dataset, which is then learnt by neural networks to unveil the underlying mapping rule of the explored QSL problem. Capitalizing on the generalization power of neural networks, this paradigm can be trained offline and excel at predicting previously unseen systems at the inference stage, even with few state copies. Besides, it inherits the characteristic of classical shadows, enabling memory-efficient storage and faithful prediction. These features underscore the immense potential of the proposed data-centric approach in discovering novel and large-scale quantum systems. For concreteness, we present the instantiation of our paradigm in quantum state tomography and direct fidelity estimation tasks and conduct numerical analysis up to 60 qubits. Our work showcases the profound prospects of data-centric artificial intelligence to advance QSL in a faithful and generalizable manner.
</details>
<details>
<summary>摘要</summary>
大量量子系统的动力学是由维度瓶颈所困难。统计学学习提供了新的可能性，通过神经网络协议和类型热影，然而两者都有局限性：前者受到预测不确定性的困扰，而后者缺乏泛化能力。我们提议一种数据驱动学习思想，结合这两种方法，以便实现多样化量子系统学习（QSL）任务。具体来说，我们的思想利用类型热影并与量子系统其他易获得信息一起创建训练集，然后通过神经网络学习探索QSL问题下的底层映射规则。通过神经网络的泛化能力，这种思想可以在训练阶段在线上培养，并在探索阶段预测未经见过的系统，即使只有几个状态的复制。此外，它继承类型热影的特点，即储存和预测的具有快速储存和准确预测的特点。这些特点强调了我们提议的数据驱动方法在发现新的大规模量子系统方面的极大潜力。为了证明这一点，我们在量子状态探测和直接准确率估计任务中实现了实例，并进行了数值分析至60个量子比特。我们的工作展示了数据驱动人工智能在忠实和泛化的方式下提高量子系统学习的可能性。
</details></li>
</ul>
<hr>
<h2 id="Recording-of-50-Business-Assignments"><a href="#Recording-of-50-Business-Assignments" class="headerlink" title="Recording of 50 Business Assignments"></a>Recording of 50 Business Assignments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12211">http://arxiv.org/abs/2308.12211</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/50BusinessAssignmentsLog">https://github.com/microsoft/50BusinessAssignmentsLog</a></li>
<li>paper_authors: Michal Sroka, Mohammadreza Fani Sani</li>
<li>for: 本研究用于发现和分析用户如何完成业务任务，提供有价值的进程效率和优化的研究发现。</li>
<li>methods: 本文提供了50个真实的企业过程数据集，这些数据集有很大的研究应用potential，包括任务挖掘和过程自动化。</li>
<li>results: 本研究提供了一个有价值的数据集，这些数据集有助于研究人员和实践者了解进程效率和优化。<details>
<summary>Abstract</summary>
One of the main use cases of process mining is to discover and analyze how users follow business assignments, providing valuable insights into process efficiency and optimization. In this paper, we present a comprehensive dataset consisting of 50 real business processes. The dataset holds significant potential for research in various applications, including task mining and process automation which is a valuable resource for researchers and practitioners.
</details>
<details>
<summary>摘要</summary>
一个主要的用 caso of  proces mining 是发现和分析用户如何跟踪商业任务，提供有价值的信息来进行过程效率和优化。在这篇论文中，我们提供了完整的数据集，包含50个真实的商业过程。该数据集具有较高的研究价值，包括任务挖掘和过程自动化，是研究人员和实践者的宝贵资源。
</details></li>
</ul>
<hr>
<h2 id="CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation"><a href="#CNN-based-Cuneiform-Sign-Detection-Learned-from-Annotated-3D-Renderings-and-Mapped-Photographs-with-Illumination-Augmentation" class="headerlink" title="CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation"></a>CNN based Cuneiform Sign Detection Learned from Annotated 3D Renderings and Mapped Photographs with Illumination Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11277">http://arxiv.org/abs/2308.11277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernst Stötzner, Timo Homburg, Hubert Mara</li>
<li>for: 针对ancient near eastern studies (DANES) 社区面临的挑战，我们开发了数字工具来处理篆字体系，这是一种3D文字痕迹在泥 TABLETS上的历史文化，覆盖了三千多年和至少八种主要语言。</li>
<li>methods: 我们使用了HeiCuBeDa和MaiCuBeDa数据集，包括约500个标注的板表，并提供了一种新的OCR-like方法来处理混合图像数据。我们的签名localization使用RepPoints探测器来预测字符的位置为 bounding boxes。我们使用了GigaMesh的MSII（曲率）基于的渲染、Phong-ashed 3D模型和照片，以及光照增强。</li>
<li>results: 使用渲染的3D图像进行签名检测比使用照片更好，而且我们的方法在混合数据集上表现良好，而且Phong renderings和特别是MSII renderings在照片上提高了结果。<details>
<summary>Abstract</summary>
Motivated by the challenges of the Digital Ancient Near Eastern Studies (DANES) community, we develop digital tools for processing cuneiform script being a 3D script imprinted into clay tablets used for more than three millennia and at least eight major languages. It consists of thousands of characters that have changed over time and space. Photographs are the most common representations usable for machine learning, while ink drawings are prone to interpretation. Best suited 3D datasets that are becoming available. We created and used the HeiCuBeDa and MaiCuBeDa datasets, which consist of around 500 annotated tablets. For our novel OCR-like approach to mixed image data, we provide an additional mapping tool for transferring annotations between 3D renderings and photographs. Our sign localization uses a RepPoints detector to predict the locations of characters as bounding boxes. We use image data from GigaMesh's MSII (curvature, see https://gigamesh.eu) based rendering, Phong-shaded 3D models, and photographs as well as illumination augmentation. The results show that using rendered 3D images for sign detection performs better than other work on photographs. In addition, our approach gives reasonably good results for photographs only, while it is best used for mixed datasets. More importantly, the Phong renderings, and especially the MSII renderings, improve the results on photographs, which is the largest dataset on a global scale.
</details>
<details>
<summary>摘要</summary>
受到数字古近东研究（DANES）社区的挑战启发，我们开发了数字工具来处理古代 Mesopotamia 文字，这是一种3D字符印制在泥版上，用于超过三千年和至少八种主要语言。它包含了数千个字符，随着时间和空间的变化而变化。 photographs 是最常用的机器学习 Representation，而墨水Drawing 容易被解释。我们创建了 HeiCuBeDa 和 MaiCuBeDa 数据集，包含约500个注释的泥版。为了我们的新的 OCR-like 方法，我们提供了一个附加的映射工具，用于将3D渲染与 photographs 之间的注释传输。我们使用 GigaMesh 的 MSII（曲率，见 <https://gigamesh.eu>）基于的渲染、Phong 灯光渲染和 photographs 以及照明增强。结果表明，使用3D渲染来检测字符性能更高于其他工作的 photographs 上。此外，我们的方法在 photographs 上提供了reasonably good的结果，而且在混合数据集上表现最佳。尤其是 Phong 渲染和 MSII 渲染，对于 photographs 上的结果有所提高。
</details></li>
</ul>
<hr>
<h2 id="Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning"><a href="#Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning" class="headerlink" title="Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning"></a>Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11276">http://arxiv.org/abs/2308.11276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shansong Liu, Atin Sakkeer Hussain, Chenshuo Sun, Ying Shan</li>
<li>for:  solves the problem of text-to-music generation (T2M-Gen) faced due to the scarcity of large-scale publicly available music datasets with natural language captions.</li>
<li>methods:  utilizes audio representations from a pretrained MERT model to extract music features, and introduces a methodology for generating question-answer pairs from existing audio captioning datasets, as well as the MusicQA Dataset designed for answering open-ended music-related questions.</li>
<li>results:  achieves outstanding performance in both music question answering and music caption generation across various metrics, outperforming current state-of-the-art (SOTA) models in both fields and offering a promising advancement in the T2M-Gen research field.<details>
<summary>Abstract</summary>
Text-to-music generation (T2M-Gen) faces a major obstacle due to the scarcity of large-scale publicly available music datasets with natural language captions. To address this, we propose the Music Understanding LLaMA (MU-LLaMA), capable of answering music-related questions and generating captions for music files. Our model utilizes audio representations from a pretrained MERT model to extract music features. However, obtaining a suitable dataset for training the MU-LLaMA model remains challenging, as existing publicly accessible audio question answering datasets lack the necessary depth for open-ended music question answering. To fill this gap, we present a methodology for generating question-answer pairs from existing audio captioning datasets and introduce the MusicQA Dataset designed for answering open-ended music-related questions. The experiments demonstrate that the proposed MU-LLaMA model, trained on our designed MusicQA dataset, achieves outstanding performance in both music question answering and music caption generation across various metrics, outperforming current state-of-the-art (SOTA) models in both fields and offering a promising advancement in the T2M-Gen research field.
</details>
<details>
<summary>摘要</summary>
文本转换为乐曲生成（T2M-Gen）遇到了一个重要的障碍，即公共可用的大规模乐曲数据集中的自然语言描述缺乏。为解决这个问题，我们提议了Music Understanding LLaMA（MU-LLaMA），可以回答乐曲相关的问题并生成乐曲文件的描述。我们的模型利用了预训练的MERT模型来提取乐曲特征。但是获得合适的模型训练数据集仍然是一个挑战，因为现有的公共可用的音频问答数据集缺乏必要的深度来回答开放式乐曲问题。为了填补这个空白，我们提出了一种方法，可以将现有的音频描述数据集转换成问题-答案对，并介绍了MusicQA数据集，用于回答开放式乐曲相关的问题。实验结果表明，我们提出的MU-LLaMA模型，在我们设计的MusicQA数据集上进行训练，在多种纪录计中表现出色，超越当前的状态机（SOTA）模型在乐曲问题回答和乐曲描述生成方面，并为T2M-Gen研究领域带来了可期的进步。
</details></li>
</ul>
<hr>
<h2 id="Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes"><a href="#Robust-Lagrangian-and-Adversarial-Policy-Gradient-for-Robust-Constrained-Markov-Decision-Processes" class="headerlink" title="Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes"></a>Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11267">http://arxiv.org/abs/2308.11267</a></li>
<li>repo_url: None</li>
<li>paper_authors: David M. Bossens</li>
<li>for: 本 paper 目的是提出一种基于 reinforcement learning 的任务模型框架，即 robust constrained Markov decision process (RCMDP)，该框架可以考虑行为约束和模型不确定性，并提供了对模型不确定性的鲁棒性。</li>
<li>methods: 本 paper 使用的方法包括：1) 基于值估计的最坏情况动力学；2) 基于拉格朗日点的最坏情况动力学；3) 对 RCMDP 的劣化策略算法。</li>
<li>results: 本 paper 的实验结果表明，提出的 two algorithms（RCPG with Robust Lagrangian 和 Adversarial RCPG）在 injecting perturbations 的 inventory management 和 safe navigation 任务中表现比较出色，特别是 Adversarial RCPG 在所有测试中排名第二。<details>
<summary>Abstract</summary>
The robust constrained Markov decision process (RCMDP) is a recent task-modelling framework for reinforcement learning that incorporates behavioural constraints and that provides robustness to errors in the transition dynamics model through the use of an uncertainty set. Simulating RCMDPs requires computing the worst-case dynamics based on value estimates for each state, an approach which has previously been used in the Robust Constrained Policy Gradient (RCPG). Highlighting potential downsides of RCPG such as not robustifying the full constrained objective and the lack of incremental learning, this paper introduces two algorithms, called RCPG with Robust Lagrangian and Adversarial RCPG. RCPG with Robust Lagrangian modifies RCPG by taking the worst-case dynamics based on the Lagrangian rather than either the value or the constraint. Adversarial RCPG also formulates the worst-case dynamics based on the Lagrangian but learns this directly and incrementally as an adversarial policy through gradient descent rather than indirectly and abruptly through constrained optimisation on a sorted value list. A theoretical analysis first derives the Lagrangian policy gradient for the policy optimisation of both proposed algorithms and then the adversarial policy gradient to learn the adversary for Adversarial RCPG. Empirical experiments injecting perturbations in inventory management and safe navigation tasks demonstrate the competitive performance of both algorithms compared to traditional RCPG variants as well as non-robust and non-constrained ablations. In particular, Adversarial RCPG ranks among the top two performing algorithms on all tests.
</details>
<details>
<summary>摘要</summary>
RCMDP（有约束的马尔可夫决策过程）是一种最近的任务模型框架，用于机器学习中的激励学习，它包含行为约束并提供了对转移动力学模型中的错误的Robustness。模拟RCMDP需要基于每个状态的值估计计算最差情况的动力学，这同RCPG（有约束的策略梯度）一样。在RCPG中，作者提出了两种算法，即RCPG with Robust Lagrangian和Adversarial RCPG。RCPG with Robust Lagrangian通过基于Lagrangian而不是值或约束来修改RCPG。Adversarial RCPG也基于Lagrangian，但是通过对敌对策略进行准确的梯度下降来直接和逐步地学习对敌。作者首先 derivates Lagrangian policy gradient для政策优化两个提出的算法，然后 derivates adversarial policy gradient来学习对敌。实验表明，两种算法在各种任务中表现竞争性，特别是Adversarial RCPG在所有测试中排名第二。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games"><a href="#Efficient-Last-iterate-Convergence-Algorithms-in-Solving-Games" class="headerlink" title="Efficient Last-iterate Convergence Algorithms in Solving Games"></a>Efficient Last-iterate Convergence Algorithms in Solving Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11256">http://arxiv.org/abs/2308.11256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linjian Meng, Zhenxing Ge, Wenbin Li, Bo An, Yang Gao</li>
<li>For: The paper is written for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs) using no-regret algorithms.* Methods: The paper uses the Reward Transformation (RT) framework, which transforms the problem of learning NE in the original game into a series of strongly convex-concave optimization problems (SCCPs). The authors also use Regret Matching+ (RM+) algorithm to solve the SCCPs, and propose a novel transformation method to enable RM+ to solve the SCCPs.* Results: The paper shows that the proposed algorithm, Reward Transformation RM+ (RTRM+), enjoys last-iterate convergence under the discrete-time feedback setting, and significantly outperforms existing last-iterate convergence algorithms and RM+ (CFR+) in experiments.<details>
<summary>Abstract</summary>
No-regret algorithms are popular for learning Nash equilibrium (NE) in two-player zero-sum normal-form games (NFGs) and extensive-form games (EFGs). Many recent works consider the last-iterate convergence no-regret algorithms. Among them, the two most famous algorithms are Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weight Update (OMWU). However, OGDA has high per-iteration complexity. OMWU exhibits a lower per-iteration complexity but poorer empirical performance, and its convergence holds only when NE is unique. Recent works propose a Reward Transformation (RT) framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU. Unfortunately, RT-based algorithms perform worse than OGDA under the same number of iterations, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios. To address these issues, we provide a closer analysis of the RT framework, which holds for both continuous and discrete-time feedback. We demonstrate that the essence of the RT framework is to transform the problem of learning NE in the original game into a series of strongly convex-concave optimization problems (SCCPs). We show that the bottleneck of RT-based algorithms is the speed of solving SCCPs. To improve the their empirical performance, we design a novel transformation method to enable the SCCPs can be solved by Regret Matching+ (RM+), a no-regret algorithm with better empirical performance, resulting in Reward Transformation RM+ (RTRM+). RTRM+ enjoys last-iterate convergence under the discrete-time feedback setting. Using the counterfactual regret decomposition framework, we propose Reward Transformation CFR+ (RTCFR+) to extend RTRM+ to EFGs. Experimental results show that our algorithms significantly outperform existing last-iterate convergence algorithms and RM+ (CFR+).
</details>
<details>
<summary>摘要</summary>
“无后悔算法”受欢迎用于学习两player零余游戏（NFG）和广泛游戏（EFG）中的 Nash  equilibriium（NE）。许多最近的研究将注意力集中在最后迭代具有无后悔性的算法。其中最具知名度的两个算法是Optimistic Gradient Descent Ascent（OGDA）和Optimistic Multiplicative Weight Update（OMWU）。然而，OGDA的每迭代复杂度较高，而OMWU的实际性较差，且其对NE的唯一性Conditions不够严格。Recent works propose a Reward Transformation（RT） framework for MWU, which removes the uniqueness condition and achieves competitive performance with OMWU。然而，RT-based algorithms under the same number of iterations than OGDA, and their convergence guarantee is based on the continuous-time feedback assumption, which does not hold in most scenarios。To address these issues, we provide a closer analysis of the RT framework, which holds for both continuous and discrete-time feedback。我们展示了RT framework的核心是将学习NE在原始游戏中的问题转换为一系列强oly convex-concave optimization problems（SCCPs）。我们显示了RT-based algorithms的瓶颈在SCCPs的解决方法。为了提高它们的实际性表现，我们设计了一个新的变换方法，让SCCPs可以通过Regret Matching+（RM+），一个无后悔算法，解决，从而产生Reward Transformation RM+（RTRM+）。RTRM+ 满足最后迭代具有无后悔性的条件。使用Counterfactual regret decomposition framework，我们提出Reward Transformation CFR+（RTCFR+）来扩展RTRM+到EFGs。实验结果显示我们的算法在已知的最后迭代具有无后悔性的算法和RM+（CFR+）中具有优秀的实际表现。
</details></li>
</ul>
<hr>
<h2 id="A-survey-on-bias-in-machine-learning-research"><a href="#A-survey-on-bias-in-machine-learning-research" class="headerlink" title="A survey on bias in machine learning research"></a>A survey on bias in machine learning research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11254">http://arxiv.org/abs/2308.11254</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aastha2104/Parkinson-Disease-Prediction">https://github.com/Aastha2104/Parkinson-Disease-Prediction</a></li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Michał Grochowski</li>
<li>for: 本研究旨在帮助理解机器学习中的偏见源泉和错误，以提高机器学习模型的公平、透明和准确性。</li>
<li>methods: 本文提供了四十个可能的机器学习漏洞和错误的示例，并对每个示例进行了详细的描述。</li>
<li>results: 本文通过对机器学习管道中的偏见和错误的分析，帮助开发者更好地检测和缓解偏见，从而提高机器学习模型的公平性和准确性。<details>
<summary>Abstract</summary>
Current research on bias in machine learning often focuses on fairness, while overlooking the roots or causes of bias. However, bias was originally defined as a "systematic error," often caused by humans at different stages of the research process. This article aims to bridge the gap between past literature on bias in research by providing taxonomy for potential sources of bias and errors in data and models. The paper focus on bias in machine learning pipelines. Survey analyses over forty potential sources of bias in the machine learning (ML) pipeline, providing clear examples for each. By understanding the sources and consequences of bias in machine learning, better methods can be developed for its detecting and mitigating, leading to fairer, more transparent, and more accurate ML models.
</details>
<details>
<summary>摘要</summary>
现有研究 often focuses on fairness 的偏见在机器学习中，而忽略了偏见的根源或 causa。然而，偏见原本是一种“系统性错误”，常由人类在不同阶段的研究过程中引入。这篇文章目的是 bridge the gap between past literature on bias in research by providing a taxonomy for potential sources of bias and errors in data and models. The paper focuses on bias in machine learning pipelines. The survey analyzes over forty potential sources of bias in the machine learning (ML) pipeline, providing clear examples for each. By understanding the sources and consequences of bias in machine learning, better methods can be developed for its detecting and mitigating, leading to fairer, more transparent, and more accurate ML models.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Modeling-Bends-in-Popular-Music-Guitar-Tablatures"><a href="#Modeling-Bends-in-Popular-Music-Guitar-Tablatures" class="headerlink" title="Modeling Bends in Popular Music Guitar Tablatures"></a>Modeling Bends in Popular Music Guitar Tablatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12307">http://arxiv.org/abs/2308.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/adhooge1/bend-prediction">https://gitlab.com/adhooge1/bend-prediction</a></li>
<li>paper_authors: Alexandre D’Hooge, Louis Bigo, Ken Déguernel</li>
<li>for: 这篇论文主要用于研究 guitar 乐谱中的弯曲技巧，以及如何使用数据分析方法来预测弯曲的发生。</li>
<li>methods: 这篇论文使用了一些数据分析技术，包括决策树等，来研究弯曲的预测。</li>
<li>results: 实验结果表明，使用这些数据分析技术可以准确预测弯曲的发生，并且具有一定的可靠性和精度。<details>
<summary>Abstract</summary>
Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on/pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into guitar tablatures.
</details>
<details>
<summary>摘要</summary>
Tablaturenotation是流行音乐中广泛使用的notation方式，用于记录和分享吉他乐器的音乐内容。作为标准notation的补充，tablaturenotation记录了演奏手势信息，包括手指位置和许多特有的吉他演奏技巧，如滑弹、弹压和弯曲。本文关注的是弯曲，它可以使演奏者在不改变 физиical fretted fingerboard的前提下，逐渐改变音符的抑制值。在本文中，我们提出了25个高级特征，用于研究如何通过检测短期内的前后文来预测琴曲中的弯曲出现。实验使用了932首流行乐器琴曲tablature，并显示了一棵决策树可以成功预测琴曲中的弯曲出现，F1分数为0.71，并且具有有限的假阳性预测，这表明可以用于将非吉他音乐转换成琴曲tablature。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes"><a href="#Multi-Source-Domain-Adaptation-for-Cross-Domain-Fault-Diagnosis-of-Chemical-Processes" class="headerlink" title="Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes"></a>Multi-Source Domain Adaptation for Cross-Domain Fault Diagnosis of Chemical Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11247">http://arxiv.org/abs/2308.11247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Fernandes Montesuma, Michela Mulas, Fred Ngolè Mboula, Francesco Corona, Antoine Souloumiac</li>
<li>for: 这种研究旨在提高过程监测中的故障诊断精度，具体来说是利用机器学习算法预测故障类型基于感知器读ings。</li>
<li>methods: 该研究使用单源预处理适应（SSDA）和多源预处理适应（MSDA）算法进行故障诊断，并在田东曼进程中进行了广泛的比较。</li>
<li>results: 研究显示，在多源场景下使用多个预处理源可以提高故障诊断精度，具体来说是比单源场景提高23%的平均精度。此外，无适应情况下，多源场景可以提高不适应精度的平均提升率为8.4%。<details>
<summary>Abstract</summary>
Fault diagnosis is an essential component in process supervision. Indeed, it determines which kind of fault has occurred, given that it has been previously detected, allowing for appropriate intervention. Automatic fault diagnosis systems use machine learning for predicting the fault type from sensor readings. Nonetheless, these models are sensible to changes in the data distributions, which may be caused by changes in the monitored process, such as changes in the mode of operation. This scenario is known as Cross-Domain Fault Diagnosis (CDFD). We provide an extensive comparison of single and multi-source unsupervised domain adaptation (SSDA and MSDA respectively) algorithms for CDFD. We study these methods in the context of the Tennessee-Eastmann Process, a widely used benchmark in the chemical industry. We show that using multiple domains during training has a positive effect, even when no adaptation is employed. As such, the MSDA baseline improves over the SSDA baseline classification accuracy by 23% on average. In addition, under the multiple-sources scenario, we improve classification accuracy of the no adaptation setting by 8.4% on average.
</details>
<details>
<summary>摘要</summary>
FAULT诊断是 proces supervision 中的一个重要组件。它可以确定哪种缺陷已经发生，只要它已经检测到了，然后采取相应的 intervención。自动FAULT诊断系统 使用机器学习来预测缺陷类型从感知值中。然而，这些模型对数据分布的变化敏感，这些变化可能是由监测过程中的变化所致，如操作模式的变化。这种情况被称为 Cross-Domain Fault Diagnosis (CDFD)。我们提供了广泛的单源和多源无监督领域适应 (SSDA 和 MSDA 分别) 算法的 Comparative study  для CDFD。我们在 Tennessee-Eastmann 过程中进行了这些方法的研究，这是化学工业中广泛使用的一个标准测试 benchmark。我们发现在训练时使用多个频道有益，即使没有适应也。因此，MSDA 基线提高了 SSDA 基eline 的分类精度，在 average 上提高了 23%。此外，在多源场景下，我们在无适应情况下提高了分类精度的 average 上提高了 8.4%。
</details></li>
</ul>
<hr>
<h2 id="Faster-Optimization-in-S-Graphs-Exploiting-Hierarchy"><a href="#Faster-Optimization-in-S-Graphs-Exploiting-Hierarchy" class="headerlink" title="Faster Optimization in S-Graphs Exploiting Hierarchy"></a>Faster Optimization in S-Graphs Exploiting Hierarchy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11242">http://arxiv.org/abs/2308.11242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hriday Bavle, Jose Luis Sanchez-Lopez, Javier Civera, Holger Voos<br>for:This paper aims to improve the scalability of Situational Graphs (S-Graphs) in large environments for Simultaneous Localization and Mapping (SLAM) by marginalizing redundant robot poses and their connections to observations.methods:The proposed method generates and optimizes room-local graphs encompassing all graph entities within a room-like structure, compresses the S-Graphs, and performs windowed local optimization of the compressed graph at regular time-distance intervals. Global optimization is performed every time a loop closure is detected.results:The proposed method achieves similar accuracy compared to the baseline while reducing the computation time by 39.81% compared to the baseline.<details>
<summary>Abstract</summary>
3D scene graphs hierarchically represent the environment appropriately organizing different environmental entities in various layers. Our previous work on situational graphs extends the concept of 3D scene graph to SLAM by tightly coupling the robot poses with the scene graph entities, achieving state-of-the-art results. Though, one of the limitations of S-Graphs is scalability in really large environments due to the increased graph size over time, increasing the computational complexity.   To overcome this limitation in this work we present an initial research of an improved version of S-Graphs exploiting the hierarchy to reduce the graph size by marginalizing redundant robot poses and their connections to the observations of the same structural entities. Firstly, we propose the generation and optimization of room-local graphs encompassing all graph entities within a room-like structure. These room-local graphs are used to compress the S-Graphs marginalizing the redundant robot keyframes within the given room. We then perform windowed local optimization of the compressed graph at regular time-distance intervals. A global optimization of the compressed graph is performed every time a loop closure is detected. We show similar accuracy compared to the baseline while showing a 39.81% reduction in the computation time with respect to the baseline.
</details>
<details>
<summary>摘要</summary>
三维场景图 hierarchically represents the environment, appropriately organizing different environmental entities in various layers. Our previous work on situational graphs extends the concept of 3D scene graph to SLAM by tightly coupling the robot poses with the scene graph entities, achieving state-of-the-art results. However, one of the limitations of S-Graphs is scalability in really large environments due to the increased graph size over time, increasing the computational complexity. To overcome this limitation, in this work we present an initial research of an improved version of S-Graphs by exploiting the hierarchy to reduce the graph size by marginalizing redundant robot poses and their connections to the observations of the same structural entities. First, we propose the generation and optimization of room-local graphs encompassing all graph entities within a room-like structure. These room-local graphs are used to compress the S-Graphs marginalizing the redundant robot keyframes within the given room. We then perform windowed local optimization of the compressed graph at regular time-distance intervals. A global optimization of the compressed graph is performed every time a loop closure is detected. We show similar accuracy compared to the baseline while showing a 39.81% reduction in computation time with respect to the baseline.
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification"><a href="#An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification" class="headerlink" title="An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification"></a>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11241">http://arxiv.org/abs/2308.11241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harunorikawano/speaker-identification-with-tgp">https://github.com/harunorikawano/speaker-identification-with-tgp</a></li>
<li>paper_authors: Harunori Kawano, Sota Shimizu</li>
<li>for: 这个研究是为了开发一个高精度的 speaker identification 模型，使用 Transformer 架构和自我超vised learning。</li>
<li>methods: 本研究使用了 Transformer-based contextual model，并进一步提出了 Temporal Gate Pooling 方法来增强模型的学习能力。</li>
<li>results: 研究获得了使用 VoxCeleb1 资料集进行认个者识别 tasks 的85.9%的精度，与 wav2vec2 的317.7M个parameters相比，这个方法具有较高的精度和较低的 Parameters 数量。<details>
<summary>Abstract</summary>
Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 85.9% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at https://github.com/HarunoriKawano/speaker-identification-with-tgp.
</details>
<details>
<summary>摘要</summary>
它使用 transformer 架构和自动学习来实现了speech recognition的成功。最近，这些技术不仅用于speech recognition，还用于整个speech processing。这篇论文介绍了一种高效的端到端speaker identification模型，该模型使用 transformer-based 上下文模型。我们研究了参数与性能之间的关系，以便理解高效模型的结构。此外，我们提出了一种pooling方法， named Temporal Gate Pooling，具有强大的学习能力。我们使用 Conformer 作为编码器，并使用 BEST-RQ 进行预训练。我们对 VoxCeleb1 进行了评估，并实现了85.9%的准确率，相比之下，wav2vec2 的参数数量为317.7M，我们的方法准确率相对较高。代码可以在 GitHub 上找到：https://github.com/HarunoriKawano/speaker-identification-with-tgp。
</details></li>
</ul>
<hr>
<h2 id="ROSGPT-Vision-Commanding-Robots-Using-Only-Language-Models’-Prompts"><a href="#ROSGPT-Vision-Commanding-Robots-Using-Only-Language-Models’-Prompts" class="headerlink" title="ROSGPT_Vision: Commanding Robots Using Only Language Models’ Prompts"></a>ROSGPT_Vision: Commanding Robots Using Only Language Models’ Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11236">http://arxiv.org/abs/2308.11236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bilel-bj/rosgpt_vision">https://github.com/bilel-bj/rosgpt_vision</a></li>
<li>paper_authors: Bilel Benjdira, Anis Koubaa, Anas M. Ali</li>
<li>for: 这个论文主要是提出一种新的 робо控制方法，使用语言模型提示来控制 робо。</li>
<li>methods: 该方法使用语言模型和视觉模型结合在一起，通过自动化机制来执行 robotic 任务。</li>
<li>results: 这个方法可以减少 robotic 开发成本，并且可以在实际应用中提高应用质量。Here’s a more detailed explanation of each point:</li>
<li>for: The paper proposes a new method for controlling robots using only language prompts, which is a significant departure from traditional methods that rely on technical details and programming.</li>
<li>methods: The method uses a combination of language models and vision models to automate the mechanisms behind the prompts, allowing the robot to execute tasks based on natural language descriptions.</li>
<li>results: The method has been shown to reduce development costs and improve the quality of applications, and it has the potential to advance robotic research in this direction.I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
In this paper, we argue that the next generation of robots can be commanded using only Language Models' prompts. Every prompt interrogates separately a specific Robotic Modality via its Modality Language Model (MLM). A central Task Modality mediates the whole communication to execute the robotic mission via a Large Language Model (LLM). This paper gives this new robotic design pattern the name of: Prompting Robotic Modalities (PRM). Moreover, this paper applies this PRM design pattern in building a new robotic framework named ROSGPT_Vision. ROSGPT_Vision allows the execution of a robotic task using only two prompts: a Visual and an LLM prompt. The Visual Prompt extracts, in natural language, the visual semantic features related to the task under consideration (Visual Robotic Modality). Meanwhile, the LLM Prompt regulates the robotic reaction to the visual description (Task Modality). The framework automates all the mechanisms behind these two prompts. The framework enables the robot to address complex real-world scenarios by processing visual data, making informed decisions, and carrying out actions automatically. The framework comprises one generic vision module and two independent ROS nodes. As a test application, we used ROSGPT_Vision to develop CarMate, which monitors the driver's distraction on the roads and makes real-time vocal notifications to the driver. We showed how ROSGPT_Vision significantly reduced the development cost compared to traditional methods. We demonstrated how to improve the quality of the application by optimizing the prompting strategies, without delving into technical details. ROSGPT_Vision is shared with the community (link: https://github.com/bilel-bj/ROSGPT_Vision) to advance robotic research in this direction and to build more robotic frameworks that implement the PRM design pattern and enables controlling robots using only prompts.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们 argueThat the next generation of robots can be commanded using only Language Models' prompts. Every prompt interrogates separately a specific Robotic Modality via its Modality Language Model (MLM). A central Task Modality mediates the whole communication to execute the robotic mission via a Large Language Model (LLM). This paper gives this new robotic design pattern the name of: Prompting Robotic Modalities (PRM). Moreover, this paper applies this PRM design pattern in building a new robotic framework named ROSGPT_Vision. ROSGPT_Vision allows the execution of a robotic task using only two prompts: a Visual and an LLM prompt. The Visual Prompt extracts, in natural language, the visual semantic features related to the task under consideration (Visual Robotic Modality). Meanwhile, the LLM Prompt regulates the robotic reaction to the visual description (Task Modality). The framework automates all the mechanisms behind these two prompts. The framework enables the robot to address complex real-world scenarios by processing visual data, making informed decisions, and carrying out actions automatically. The framework comprises one generic vision module and two independent ROS nodes. As a test application, we used ROSGPT_Vision to develop CarMate, which monitors the driver's distraction on the roads and makes real-time vocal notifications to the driver. We showed how ROSGPT_Vision significantly reduced the development cost compared to traditional methods. We demonstrated how to improve the quality of the application by optimizing the prompting strategies, without delving into technical details. ROSGPT_Vision is shared with the community (link: https://github.com/bilel-bj/ROSGPT_Vision) to advance robotic research in this direction and to build more robotic frameworks that implement the PRM design pattern and enables controlling robots using only prompts.
</details></li>
</ul>
<hr>
<h2 id="Adaptive-White-Box-Watermarking-with-Self-Mutual-Check-Parameters-in-Deep-Neural-Networks"><a href="#Adaptive-White-Box-Watermarking-with-Self-Mutual-Check-Parameters-in-Deep-Neural-Networks" class="headerlink" title="Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks"></a>Adaptive White-Box Watermarking with Self-Mutual Check Parameters in Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11235">http://arxiv.org/abs/2308.11235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenzhe Gao, Zhaoxia Yin, Hongjian Zhan, Heng Yin, Yue Lu</li>
<li>for: 检测和防止人工智能模型中的意外或恶意篡改。</li>
<li>methods: 使用敏感 watermarking 技术来识别和检测篡改。</li>
<li>results: 测试结果表明，当篡改率低于 20% 时，我们的方法可以达到很高的恢复性能。而对于受到 watermarking 影响的模型，我们使用可适应位数技术来恢复模型的精度。<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) has found wide application, but also poses risks due to unintentional or malicious tampering during deployment. Regular checks are therefore necessary to detect and prevent such risks. Fragile watermarking is a technique used to identify tampering in AI models. However, previous methods have faced challenges including risks of omission, additional information transmission, and inability to locate tampering precisely. In this paper, we propose a method for detecting tampered parameters and bits, which can be used to detect, locate, and restore parameters that have been tampered with. We also propose an adaptive embedding method that maximizes information capacity while maintaining model accuracy. Our approach was tested on multiple neural networks subjected to attacks that modified weight parameters, and our results demonstrate that our method achieved great recovery performance when the modification rate was below 20%. Furthermore, for models where watermarking significantly affected accuracy, we utilized an adaptive bit technique to recover more than 15% of the accuracy loss of the model.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在应用广泛，但也存在风险，因为在部署过程中可能会有不恰当或恶意篡改。因此， Regular checks 是必要的，以检测和预防这些风险。某些攻击可能会导致模型参数的篡改，因此我们需要一种方法来检测和修复篡改的参数。在这篇论文中，我们提出了一种用于检测篡改参数和位数的方法，可以用来检测、定位和修复篡改的参数。此外，我们还提出了一种适应式嵌入方法，可以最大化信息容量，同时保持模型的准确性。我们的方法在多个神经网络上进行了测试，并达到了篡改率低于20%时的恢复性能。此外，对于模型中 watermarking 对准确性产生了较大的影响，我们使用适应位数技术来恢复模型的准确性，达到了超过15%的恢复效果。
</details></li>
</ul>
<hr>
<h2 id="Traffic-Flow-Optimisation-for-Lifelong-Multi-Agent-Path-Finding"><a href="#Traffic-Flow-Optimisation-for-Lifelong-Multi-Agent-Path-Finding" class="headerlink" title="Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding"></a>Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11234">http://arxiv.org/abs/2308.11234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Chen, Daniel Harabor, Jiaoyang Li, Peter J. Stuckey</li>
<li>for: 解决多 Agent 路径规划问题，即 robotics 中多 Agent 需要计算共享地图上免撞的路径。</li>
<li>methods: 提出一种新的方法，使用填充避免拥填的路径引导 Agent 达到目的地。</li>
<li>results: 在一shot MAPF 和 Lifelong MAPF 两个大规模场景中，提供了较好的解决方案，对一shot MAPF 的解决质量做出了重要改进，对 Lifelong MAPF 的总 Throughput 做出了大幅提高。<details>
<summary>Abstract</summary>
Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics that asks us to compute collision-free paths for a team of agents, all moving across a shared map. Although many works appear on this topic, all current algorithms struggle as the number of agents grows. The principal reason is that existing approaches typically plan free-flow optimal paths, which creates congestion. To tackle this issue we propose a new approach for MAPF where agents are guided to their destination by following congestion-avoiding paths. We evaluate the idea in two large-scale settings: one-shot MAPF, where each agent has a single destination, and lifelong MAPF, where agents are continuously assigned new tasks. For one-shot MAPF we show that our approach substantially improves solution quality. For Lifelong MAPF we report large improvements in overall throughput.
</details>
<details>
<summary>摘要</summary>
多智能路径找（MAPF）是 robotics 中的基本问题，它要求我们计算多个智能机器人在共享地图上的冲突自由路径。虽然有很多研究对这个问题进行了努力，但现有的方法都难以承受多个机器人的增加。主要的原因是现有的方法通常计划自由流优化路径，这会导致堵塞。为解决这个问题，我们提出了一种新的 MAPF 方法，即使 agents 跟随堵塞避免路径来达到目的地。我们在两个大规模设置中评估了这个想法：一个是一次 MAPF，每个机器人都有单个目的地；另一个是持续 MAPF，机器人 continuous 被分配新任务。对一次 MAPF 我们显示了我们的方法可以显著提高解决方案质量。对持续 MAPF 我们报告了大幅提高总吞吐量。
</details></li>
</ul>
<hr>
<h2 id="On-Premise-AIOps-Infrastructure-for-a-Software-Editor-SME-An-Experience-Report"><a href="#On-Premise-AIOps-Infrastructure-for-a-Software-Editor-SME-An-Experience-Report" class="headerlink" title="On-Premise AIOps Infrastructure for a Software Editor SME: An Experience Report"></a>On-Premise AIOps Infrastructure for a Software Editor SME: An Experience Report</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11225">http://arxiv.org/abs/2308.11225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anes Bendimerad, Youcef Remil, Romain Mathonat, Mehdi Kaytoue</li>
<li>for: 本研究旨在探讨在企业内部实施基于开源工具的AIOps解决方案，以提高软件维护和监测。</li>
<li>methods: 本研究使用开源工具构建了一套完整的AIOps基础设施，并提供了不同选择的原则和策略。</li>
<li>results: 研究结果表明，使用开源工具构建AIOps基础设施可以减少成本和提高软件维护效率，同时也可以满足公司的数据管理和安全需求。<details>
<summary>Abstract</summary>
Information Technology has become a critical component in various industries, leading to an increased focus on software maintenance and monitoring. With the complexities of modern software systems, traditional maintenance approaches have become insufficient. The concept of AIOps has emerged to enhance predictive maintenance using Big Data and Machine Learning capabilities. However, exploiting AIOps requires addressing several challenges related to the complexity of data and incident management. Commercial solutions exist, but they may not be suitable for certain companies due to high costs, data governance issues, and limitations in covering private software. This paper investigates the feasibility of implementing on-premise AIOps solutions by leveraging open-source tools. We introduce a comprehensive AIOps infrastructure that we have successfully deployed in our company, and we provide the rationale behind different choices that we made to build its various components. Particularly, we provide insights into our approach and criteria for selecting a data management system and we explain its integration. Our experience can be beneficial for companies seeking to internally manage their software maintenance processes with a modern AIOps approach.
</details>
<details>
<summary>摘要</summary>
信息技术已成为不同行业的关键组成部分，导致软件维护和监测得到了更大的关注。由于现代软件系统的复杂性，传统维护方法已成为不足。AIOps概念出现以增强预测维护，通过大数据和机器学习技术来提高维护效率。然而，使用AIOps存在数据复杂性和事件管理等挑战。 comercial解决方案存在，但它们可能不适用于某些公司，因为高成本、数据管理问题和私有软件的限制。本文探讨在公司内部实施On-premise AIOps解决方案的可行性，通过使用开源工具。我们介绍了一个完整的AIOps基础设施，我们在公司中成功地部署了这个基础设施，并提供了不同组件的选择原则。尤其是数据管理系统的选择和集成方法。我们的经验可以帮助公司通过现代AIOps方法 internally管理软件维护过程。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Large-Language-Models-on-Graphs-Performance-Insights-and-Comparative-Analysis"><a href="#Evaluating-Large-Language-Models-on-Graphs-Performance-Insights-and-Comparative-Analysis" class="headerlink" title="Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis"></a>Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11224">http://arxiv.org/abs/2308.11224</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ayame1006/llmtograph">https://github.com/ayame1006/llmtograph</a></li>
<li>paper_authors: Chang Liu, Bo Wu</li>
<li>for: 这个研究旨在评估四种大语言模型（LLMs）在处理图数据上的应用能力。</li>
<li>methods: 该研究使用了四种不同的评估指标：理解、正确性、准确性和修复能力。</li>
<li>results: 研究发现，LLMs可以很好地理解图数据的自然语言描述，并且可以对图结构进行有效的推理。GPT模型在正确性方面表现出色，而其他模型则在结构理解方面表现较差。GPT模型在多个答案 зада题上常出现错误答案，这可能会降低其修复能力。另外，GPT-4能够修复GPT-3.5-turbo和自己之前的迭代的答案。研究代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/Ayame1006/LLMtoGraph%E3%80%82">https://github.com/Ayame1006/LLMtoGraph。</a><details>
<summary>Abstract</summary>
Large Language Models (LLMs) have garnered considerable interest within both academic and industrial. Yet, the application of LLMs to graph data remains under-explored. In this study, we evaluate the capabilities of four LLMs in addressing several analytical problems with graph data. We employ four distinct evaluation metrics: Comprehension, Correctness, Fidelity, and Rectification. Our results show that: 1) LLMs effectively comprehend graph data in natural language and reason with graph topology. 2) GPT models can generate logical and coherent results, outperforming alternatives in correctness. 3) All examined LLMs face challenges in structural reasoning, with techniques like zero-shot chain-of-thought and few-shot prompting showing diminished efficacy. 4) GPT models often produce erroneous answers in multi-answer tasks, raising concerns in fidelity. 5) GPT models exhibit elevated confidence in their outputs, potentially hindering their rectification capacities. Notably, GPT-4 has demonstrated the capacity to rectify responses from GPT-3.5-turbo and its own previous iterations. The code is available at: https://github.com/Ayame1006/LLMtoGraph.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在学术和业务领域都受到了广泛关注。然而，对图数据的应用仍然尚未得到充分探索。本研究通过评估四种LLM在解决多个分析问题上的能力来评估LLM在图数据上的应用。我们采用了四种评估指标：理解、正确性、准确性和修复。我们的结果显示：1）LLM可以很好地理解图数据的自然语言描述和图结构的关系。2）GPT模型在正确性方面表现出色，超越了其他选择。3）所有考试LLM都面临着结构理解的挑战，特别是零shot链条思维和几个shot提示的效果减退。4）GPT模型在多个答案任务中很容易出现错误答案，这可能会影响它们的准确性。5）GPT模型表现出高度自信心，这可能会阻碍它们的修复能力。备注的是，GPT-4已经示出了可以修复GPT-3.5-turbo和自己的前一个迭代的能力。代码可以在 GitHub上找到：https://github.com/Ayame1006/LLMtoGraph。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment"><a href="#Federated-Learning-on-Patient-Data-for-Privacy-Protecting-Polycystic-Ovary-Syndrome-Treatment" class="headerlink" title="Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment"></a>Federated Learning on Patient Data for Privacy-Protecting Polycystic Ovary Syndrome Treatment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11220">http://arxiv.org/abs/2308.11220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toriqiu/fl-pcos">https://github.com/toriqiu/fl-pcos</a></li>
<li>paper_authors: Lucia Morris, Tori Qiu, Nikhil Raghuraman</li>
<li>for: 这篇论文是为了探讨 Federated Learning（FL）在预测女性淋巴疾病多囊卵巢综合症（PCOS）的优化药物方案。</li>
<li>methods: 这篇论文使用了多种 Federated Learning 方法，并在人工合成 PCOS 患者数据集上进行了测试。</li>
<li>results: 研究发现，这些 Federated Learning 方法在论文中提出的数据隐私保护和药物优选问题上都具有出色的表现。<details>
<summary>Abstract</summary>
The field of women's endocrinology has trailed behind data-driven medical solutions, largely due to concerns over the privacy of patient data. Valuable datapoints about hormone levels or menstrual cycling could expose patients who suffer from comorbidities or terminate a pregnancy, violating their privacy. We explore the application of Federated Learning (FL) to predict the optimal drug for patients with polycystic ovary syndrome (PCOS). PCOS is a serious hormonal disorder impacting millions of women worldwide, yet it's poorly understood and its research is stunted by a lack of patient data. We demonstrate that a variety of FL approaches succeed on a synthetic PCOS patient dataset. Our proposed FL models are a tool to access massive quantities of diverse data and identify the most effective treatment option while providing PCOS patients with privacy guarantees.
</details>
<details>
<summary>摘要</summary>
妇女激素学的应用落后于数据驱动医疗解决方案，主要是由于患者数据隐私问题的担忧。 valuable datapoints about 激素水平或月经周期可能暴露患有并发症或中止怀孕的患者，违反其隐私。 我们探讨了 Federated Learning（FL）的应用，以预测患有多囊卵巢综合症（PCOS）患者最佳药物。 PCOS 是世界上数百万女性中的一种严重激素失衡症，但它的研究受到缺乏患者数据的限制。 我们示出了多种 FL 方法在 sintetic PCOS 患者数据集上得到成功。我们的提议的 FL 模型是一种访问庞大数据量和鉴别最有效的治疗方案的工具，同时为 PCOS 患者提供隐私保证。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models"><a href="#Federated-Learning-in-Big-Model-Era-Domain-Specific-Multimodal-Large-Models" class="headerlink" title="Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models"></a>Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11217">http://arxiv.org/abs/2308.11217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxiang Li, Zhaoxiang Hou, Hui Liu, Ying Wang, Tongzhi Li, Longfei Xie, Chao Shi, Chengyi Yang, Weishan Zhang, Zelei Liu, Liang Xu</li>
<li>for: 这篇论文旨在提出一种多模态联合学习框架，帮助多家企业通过私有领域数据来共同训练大型模型，实现多enario智能服务。</li>
<li>methods: 论文提出了多模态联合学习的策略性转型，包括智能基础和目标的重要性在大模型时代，以及在多种数据、模型聚合、性能和成本交易、数据隐私和奖励机制等方面的新挑战。</li>
<li>results: 论文介绍了一个城市安全运营管理案例研究，其中多家企业共同提供多模态数据和专业知识，实现了城市安全运营管理的分布部署和有效协调。初步实验表明，企业可以通过多模态模型联合学习提高和储存智能能力，共同创造出高质量智能服务，涵盖能源基础设施安全、住宅社区安全和城市运营管理等多个领域。<details>
<summary>Abstract</summary>
Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. This paper proposes a multimodal federated learning framework that enables multiple enterprises to utilize private domain data to collaboratively train large models for vertical domains, achieving intelligent services across scenarios. The authors discuss in-depth the strategic transformation of federated learning in terms of intelligence foundation and objectives in the era of big model, as well as the new challenges faced in heterogeneous data, model aggregation, performance and cost trade-off, data privacy, and incentive mechanism. The paper elaborates a case study of leading enterprises contributing multimodal data and expert knowledge to city safety operation management , including distributed deployment and efficient coordination of the federated learning platform, technical innovations on data quality improvement based on large model capabilities and efficient joint fine-tuning approaches. Preliminary experiments show that enterprises can enhance and accumulate intelligent capabilities through multimodal model federated learning, thereby jointly creating an smart city model that provides high-quality intelligent services covering energy infrastructure safety, residential community security, and urban operation management. The established federated learning cooperation ecosystem is expected to further aggregate industry, academia, and research resources, realize large models in multiple vertical domains, and promote the large-scale industrial application of artificial intelligence and cutting-edge research on multimodal federated learning.
</details>
<details>
<summary>摘要</summary>
多模式数据，能够全面感知和识别物理世界，已成为通往普遍人工智能的关键Path。然而，多模式大型模型在公共数据集上训练时经常表现不佳在特定行业领域。这篇论文提出了一种多模式联合学习框架，允许多家企业使用私有领域数据共同训练大型模型，以实现多场景智能服务。作者对联合学习在智能基础和目标时代的战略性转变进行了深入探讨，以及新的多样数据、模型汇集、性能和成本负担、数据隐私和奖励机制等挑战。论文还介绍了一个城市安全运营管理案例研究，包括分布式部署和有效协调联合学习平台，以及基于大型模型技术的数据质量改进和高效联合练习方法。初步实验显示，企业可以通过多模式模型联合学习增强和积累智能能力，共同创造出高质量智能服务，涵盖能源基础设施安全、住宅社区安全和城市运营管理。建立的联合学习合作生态系统预期会进一步吸引产业、学术和研究资源，实现多个垂直领域的大型模型，并推动人工智能和多模式联合学习的大规模产业应用。
</details></li>
</ul>
<hr>
<h2 id="ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs"><a href="#ConcatPlexer-Additional-Dim1-Batching-for-Faster-ViTs" class="headerlink" title="ConcatPlexer: Additional Dim1 Batching for Faster ViTs"></a>ConcatPlexer: Additional Dim1 Batching for Faster ViTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11199">http://arxiv.org/abs/2308.11199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donghoon Han, Seunghyeon Seo, Donghyeon Jeon, Jiho Jang, Chaerin Kong, Nojun Kwak<br>for: 这个研究旨在提高视觉识别的效率，以提高模型的测试速度和精度。methods: 本研究使用了一种叫做Data Multiplexing（DataMUX）的成本削减方法，并将其应用到视觉模型中。它还导入了一个名为Image Multiplexer的新方法，以及一些新的组件，以解决DataMux在视觉模型中的弱点。results: 研究发现，使用ConcatPlexer模型可以大幅提高视觉识别的启动速度，同时保持了69.5%和83.4%的验证精度。相比之下，ViT-B&#x2F;16模型需要23.5%更多的GFLOPs以达到相同的验证精度。<details>
<summary>Abstract</summary>
Transformers have demonstrated tremendous success not only in the natural language processing (NLP) domain but also the field of computer vision, igniting various creative approaches and applications. Yet, the superior performance and modeling flexibility of transformers came with a severe increase in computation costs, and hence several works have proposed methods to reduce this burden. Inspired by a cost-cutting method originally proposed for language models, Data Multiplexing (DataMUX), we propose a novel approach for efficient visual recognition that employs additional dim1 batching (i.e., concatenation) that greatly improves the throughput with little compromise in the accuracy. We first introduce a naive adaptation of DataMux for vision models, Image Multiplexer, and devise novel components to overcome its weaknesses, rendering our final model, ConcatPlexer, at the sweet spot between inference speed and accuracy. The ConcatPlexer was trained on ImageNet1K and CIFAR100 dataset and it achieved 23.5% less GFLOPs than ViT-B/16 with 69.5% and 83.4% validation accuracy, respectively.
</details>
<details>
<summary>摘要</summary>
transformers 在自然语言处理（NLP）领域表现出色，同时在计算机视觉领域也引发了多种创新应用。然而，transformers 的高性能和模型灵活性却导致计算成本增加，因此许多研究团队提出了降低计算成本的方法。 draw inspiration from language models 的 cost-cutting method，我们提出了一种新的方法 для高效的视觉识别，即图像多重化（Image Multiplexer）。我们首先介绍了图像多重化的原型，然后开发了新的组件来缓解其缺点，最终得到了我们的最终模型——ConcatPlexer。ConcatPlexer 在 ImageNet1K 和 CIFAR100  dataset 上训练，与 ViT-B/16 的 GFLOPs 相比，减少了 23.5%，而 validation accuracy 则达到了 69.5% 和 83.4%。
</details></li>
</ul>
<hr>
<h2 id="ViLLA-Fine-Grained-Vision-Language-Representation-Learning-from-Real-World-Data"><a href="#ViLLA-Fine-Grained-Vision-Language-Representation-Learning-from-Real-World-Data" class="headerlink" title="ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data"></a>ViLLA: Fine-Grained Vision-Language Representation Learning from Real-World Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11194">http://arxiv.org/abs/2308.11194</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanfordmimi/villa">https://github.com/stanfordmimi/villa</a></li>
<li>paper_authors: Maya Varma, Jean-Benoit Delbrouck, Sarah Hooper, Akshay Chaudhari, Curtis Langlotz</li>
<li>For: 这种研究旨在评估当前的视觉语言模型（VLM）在高度复杂的多模态数据上的表现，以及如何改进VLM以更好地捕捉高度复杂的图像区域和文本特征之间的关系。* Methods: 该研究使用了一种名为ViLLA的新方法，它包括一个轻量级自动生成的地图模型和一个对比度VLM，以学习从复杂数据中捕捉高度复杂的区域特征和文本特征之间的关系。* Results: 研究表明，在四个领域（合成图像、产品图像、医疗图像和自然图像）上，ViLLA可以在精细的理解任务中表现出色，比如零shot对象检测（COCO上AP50点为3.6，LVIS上mAP点为0.6）和检索任务（R-Precision点为14.2）。<details>
<summary>Abstract</summary>
Vision-language models (VLMs), such as CLIP and ALIGN, are generally trained on datasets consisting of image-caption pairs obtained from the web. However, real-world multimodal datasets, such as healthcare data, are significantly more complex: each image (e.g. X-ray) is often paired with text (e.g. physician report) that describes many distinct attributes occurring in fine-grained regions of the image. We refer to these samples as exhibiting high pairwise complexity, since each image-text pair can be decomposed into a large number of region-attribute pairings. The extent to which VLMs can capture fine-grained relationships between image regions and textual attributes when trained on such data has not been previously evaluated. The first key contribution of this work is to demonstrate through systematic evaluations that as the pairwise complexity of the training dataset increases, standard VLMs struggle to learn region-attribute relationships, exhibiting performance degradations of up to 37% on retrieval tasks. In order to address this issue, we introduce ViLLA as our second key contribution. ViLLA, which is trained to capture fine-grained region-attribute relationships from complex datasets, involves two components: (a) a lightweight, self-supervised mapping model to decompose image-text samples into region-attribute pairs, and (b) a contrastive VLM to learn representations from generated region-attribute pairs. We demonstrate with experiments across four domains (synthetic, product, medical, and natural images) that ViLLA outperforms comparable VLMs on fine-grained reasoning tasks, such as zero-shot object detection (up to 3.6 AP50 points on COCO and 0.6 mAP points on LVIS) and retrieval (up to 14.2 R-Precision points).
</details>
<details>
<summary>摘要</summary>
视力语言模型（VLM），如CLIP和ALIGN，通常在图像-描述文本对 obtained from the web 上进行训练。然而，真实世界多Modal数据，如医疗数据，是非常复杂的：每个图像（例如 X-ray）通常与描述多个细腻区域的文本（例如医生报告）相对应。我们称这些样本为具有高对比复杂性，因为每个图像-文本对可以被分解成大量的区域-特征对。VLM 是否能够在这些数据上捕捉细腻的区域-特征关系，尚未被评估。我们的第一个关键贡献是通过系统性的评估表明，随着对于训练数据的对比复杂性的增加，标准的 VLM 会遇到性能下降，最高达37% 的搜索任务。为解决这个问题，我们介绍了我们的第二个关键贡献——ViLLA。ViLLA 是一种可以从复杂数据中捕捉细腻区域-特征关系的模型，它包括两个组件：（a）一种轻量级、自动学习的映射模型，用于将图像-文本对分解成区域-特征对，以及（b）一种对比 VLM，用于从生成的区域-特征对中学习表示。我们通过在四个领域（人工、产品、医疗和自然图像）进行实验，证明 ViLLA 在细腻理解任务中（例如零shot物体检测和搜索）表现出色，比较类似 VLM 高出3.6 AP50 点和0.6 mAP 点。
</details></li>
</ul>
<hr>
<h2 id="Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries"><a href="#Diversity-Measures-Domain-Independent-Proxies-for-Failure-in-Language-Model-Queries" class="headerlink" title="Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries"></a>Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11189">http://arxiv.org/abs/2308.11189</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab-v2/diversity_measures">https://github.com/lab-v2/diversity_measures</a></li>
<li>paper_authors: Noel Ngu, Nathaniel Lee, Paulo Shakarian</li>
<li>for: 这篇论文旨在提供一些基于它的各种应用领域的错误预测方法，以便更好地评估大语言模型的性能。</li>
<li>methods: 这篇论文使用了三种不同的方法来衡量大语言模型的错误程度，即熵度、金尼鲁分离度和中心距离。这些方法不仅可以独立地评估模型的性能，还可以应用于几个不同的应用场景，如几个示例问题、链式思维和错误检测。</li>
<li>results: 根据实验结果，这三种方法都强相关于模型的失败概率。此外，这些方法还可以应用于不同的数据集和温度设置，并且可以用于评估模型的性能。<details>
<summary>Abstract</summary>
Error prediction in large language models often relies on domain-specific information. In this paper, we present measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt - hence independent of the underlying application. We describe how three such measures - based on entropy, Gini impurity, and centroid distance - can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.
</details>
<details>
<summary>摘要</summary>
大型语言模型中的错误预测通常需要对特定领域的信息。在这篇论文中，我们提出了基于响应中的弹性、盖尼不纯和中心距离的三种度量来衡量大型语言模型的错误。我们描述了如何使用这三种度量来评估大型语言模型的错误probability，并在多个数据集和温度设定下进行了一系列实验，以示这些度量强相关于错误的可能性。此外，我们还提供了实验结果，说明了如何使用这些度量来应用少量提示、链接思维和错误探测。
</details></li>
</ul>
<hr>
<h2 id="MISSRec-Pre-training-and-Transferring-Multi-modal-Interest-aware-Sequence-Representation-for-Recommendation"><a href="#MISSRec-Pre-training-and-Transferring-Multi-modal-Interest-aware-Sequence-Representation-for-Recommendation" class="headerlink" title="MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation"></a>MISSRec: Pre-training and Transferring Multi-modal Interest-aware Sequence Representation for Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11175">http://arxiv.org/abs/2308.11175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinpeng Wang, Ziyun Zeng, Yunxiao Wang, Yuting Wang, Xingyu Lu, Tianxiang Li, Jun Yuan, Rui Zhang, Hai-Tao Zheng, Shu-Tao Xia</li>
<li>for: 这篇研究旨在解决缺乏ID特征的问题，以及实际推荐情况中的冷开头问题。</li>
<li>methods: 本研究提出了一个多 modal 信息学习框架，包括一个基于 transformer 架构的使用者端 encoder-decoder 模型，以及一个适应项目端的动态融合模块。</li>
<li>results: 实验结果显示，MISSRec 能够实现高效的实际推荐情况下的推荐。<details>
<summary>Abstract</summary>
The goal of sequential recommendation (SR) is to predict a user's potential interested items based on her/his historical interaction sequences. Most existing sequential recommenders are developed based on ID features, which, despite their widespread use, often underperform with sparse IDs and struggle with the cold-start problem. Besides, inconsistent ID mappings hinder the model's transferability, isolating similar recommendation domains that could have been co-optimized. This paper aims to address these issues by exploring the potential of multi-modal information in learning robust and generalizable sequence representations. We propose MISSRec, a multi-modal pre-training and transfer learning framework for SR. On the user side, we design a Transformer-based encoder-decoder model, where the contextual encoder learns to capture the sequence-level multi-modal synergy while a novel interest-aware decoder is developed to grasp item-modality-interest relations for better sequence representation. On the candidate item side, we adopt a dynamic fusion module to produce user-adaptive item representation, providing more precise matching between users and items. We pre-train the model with contrastive learning objectives and fine-tune it in an efficient manner. Extensive experiments demonstrate the effectiveness and flexibility of MISSRec, promising an practical solution for real-world recommendation scenarios.
</details>
<details>
<summary>摘要</summary>
目标是强化用户潜在有趣的ITEM predication，基于她/his历史交互序列。现有的大多数分列推荐器都是基于ID特征，尽管广泛使用，但它们经常在罕见ID下表现不佳，并且困难解决冷启动问题。此外，不一致的ID映射使模型的可移植性受阻，隔离类似推荐领域的相似性，这些领域可能可以协同优化。这篇论文旨在解决这些问题，通过学习多 modal 信息来学习Robust和可 generalized 序列表示。我们提议MISSRec，一种多 modal 预训练和传输学习框架，用于SR。用户方面，我们设计了一个基于Transformer的Encoder-Decoder模型，其中Contextual Encoder 学习 capture 序列级别多 modal 共谐，而一种新的兴趣相关 Decoder 被开发以更好地捕捉ITEM-modality-兴趣关系，以提高序列表示。候选ITEM 方面，我们采用动态融合模块生成用户适应ITEM表示，为用户和ITEM之间更精准的匹配提供更多的精度。我们在对照学习目标下预训练模型，并在有效的方式进行精度调整。广泛的实验表明MISSRec的有效性和灵活性，提供了实际解决现实推荐场景中的实际解决方案。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Point-based-Active-Learning-for-Semi-supervised-Point-Cloud-Semantic-Segmentation"><a href="#Hierarchical-Point-based-Active-Learning-for-Semi-supervised-Point-Cloud-Semantic-Segmentation" class="headerlink" title="Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation"></a>Hierarchical Point-based Active Learning for Semi-supervised Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11166">http://arxiv.org/abs/2308.11166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SmiletoE/HPAL">https://github.com/SmiletoE/HPAL</a></li>
<li>paper_authors: Zongyi Xu, Bo Yuan, Shanshan Zhao, Qianni Zhang, Xinbo Gao</li>
<li>for: 本研究旨在 Addressing the issue of limited annotations in 3D point cloud segmentation using active learning.</li>
<li>methods: 方法包括一个层次最小准确度模块，以及一种特征距离抑制策略，以选择重要和代表性的点 для人工标注。此外，基于这个活动策略，我们还建立了一个半监督分割框架。</li>
<li>results: 实验结果表明，提档的方法可以达到96.5%和100%的完全监督基线性能，只需使用0.07%和0.1%的训练数据。这些结果超越了当前最佳弱监督和活动学习方法。代码将在<a target="_blank" rel="noopener" href="https://github.com/SmiletoE/HPAL%E4%B8%AD%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/SmiletoE/HPAL中发布。</a><details>
<summary>Abstract</summary>
Impressive performance on point cloud semantic segmentation has been achieved by fully-supervised methods with large amounts of labelled data. As it is labour-intensive to acquire large-scale point cloud data with point-wise labels, many attempts have been made to explore learning 3D point cloud segmentation with limited annotations. Active learning is one of the effective strategies to achieve this purpose but is still under-explored. The most recent methods of this kind measure the uncertainty of each pre-divided region for manual labelling but they suffer from redundant information and require additional efforts for region division. This paper aims at addressing this issue by developing a hierarchical point-based active learning strategy. Specifically, we measure the uncertainty for each point by a hierarchical minimum margin uncertainty module which considers the contextual information at multiple levels. Then, a feature-distance suppression strategy is designed to select important and representative points for manual labelling. Besides, to better exploit the unlabelled data, we build a semi-supervised segmentation framework based on our active strategy. Extensive experiments on the S3DIS and ScanNetV2 datasets demonstrate that the proposed framework achieves 96.5% and 100% performance of fully-supervised baseline with only 0.07% and 0.1% training data, respectively, outperforming the state-of-the-art weakly-supervised and active learning methods. The code will be available at https://github.com/SmiletoE/HPAL.
</details>
<details>
<summary>摘要</summary>
具有印象的表现在点云semantic segmentation方面已经由完全监督的方法实现了出色的成绩。由于获得大规模点云数据和点 wise标签的劳动密集，许多尝试已经被作出以探索学习3D点云 segmentation的方法。活动学习是这种目标的有效策略之一，但是仍然受到了不足的探索。最近的这些方法会测量每个预分区的uncertainty，但它们受到重复信息的困扰和需要额外的劳动进行区分。这篇论文目的在于解决这个问题，通过开发一种层次 minimum margin uncertainty module来测量每个点的uncertainty，考虑多个层次的contextual信息。然后，我们设计了一种特征距离抑制策略，以选择重要和代表性的点进行手动标注。此外，为了更好地利用无标注数据，我们构建了基于我们的活动策略的半supervised segmentation框架。广泛的实验在S3DIS和ScanNetV2数据集上表明，我们的提案的框架可以与完全监督基准相同的96.5%和100%的性能，只使用0.07%和0.1%的训练数据。此外，我们的方法还能够超越当前的弱监督和活动学习方法。代码将在https://github.com/SmiletoE/HPAL上提供。
</details></li>
</ul>
<hr>
<h2 id="xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium"><a href="#xxMD-Benchmarking-Neural-Force-Fields-Using-Extended-Dynamics-beyond-Equilibrium" class="headerlink" title="xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium"></a>xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11155">http://arxiv.org/abs/2308.11155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zpengmei/xxmd">https://github.com/zpengmei/xxmd</a></li>
<li>paper_authors: Zihan Pengmei, Junyu Liu, Yinan Shu</li>
<li>For: The paper aims to address the limitations of current neural force field (NFF) models in representing chemical reactions by introducing a new dataset called xxMD, which includes energies and forces computed from both multireference wave function theory and density functional theory.* Methods: The paper uses a constrained distribution of internal coordinates and energies in the MD17 datasets to demonstrate their inadequacy for representing systems undergoing chemical reactions. The authors then introduce the xxMD dataset, which includes nuclear configuration spaces that authentically depict chemical reactions, making it a more chemically relevant dataset.* Results: The authors re-assess equivariant models on the xxMD datasets and find notably higher mean absolute errors than those reported for MD17 and its variants, highlighting the challenges faced in crafting a generalizable NFF model with extrapolation capability. The authors propose two new datasets, xxMD-CASSCF and xxMD-DFT, which are available online.<details>
<summary>Abstract</summary>
Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset and its subsequent extension. These datasets predominantly comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampling from direct adiabatic dynamics. However, many chemical reactions entail significant molecular deformations, notably bond breaking. We demonstrate the constrained distribution of internal coordinates and energies in the MD17 datasets, underscoring their inadequacy for representing systems undergoing chemical reactions. Addressing this sampling limitation, we introduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived from non-adiabatic dynamics. This dataset encompasses energies and forces ascertained from both multireference wave function theory and density functional theory. Furthermore, its nuclear configuration spaces authentically depict chemical reactions, making xxMD a more chemically relevant dataset. Our re-assessment of equivariant models on the xxMD datasets reveals notably higher mean absolute errors than those reported for MD17 and its variants. This observation underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability. Our proposed xxMD-CASSCF and xxMD-DFT datasets are available at \url{https://github.com/zpengmei/xxMD}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps"><a href="#Exploring-Unsupervised-Cell-Recognition-with-Prior-Self-activation-Maps" class="headerlink" title="Exploring Unsupervised Cell Recognition with Prior Self-activation Maps"></a>Exploring Unsupervised Cell Recognition with Prior Self-activation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11144">http://arxiv.org/abs/2308.11144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cpystan/psm">https://github.com/cpystan/psm</a></li>
<li>paper_authors: Pingyi Chen, Chenglu Zhu, Zhongyi Shui, Jiatong Cai, Sunyi Zheng, Shichuan Zhang, Lin Yang</li>
<li>for: 本研究旨在降低生物标注成本，提高生物图像识别效果。</li>
<li>methods: 我们提出了一种基于自动激活图的方法，通过自动激活图中的特征来生成假标记。然后，我们引入了一种语义归一化模块，将假标记转换为像素级别的语义假标记。</li>
<li>results: 我们在两个 histological 数据集上进行评估，结果表明我们的方法可以与其他全盘和弱盘方法竞争，而无需任何手动标注。此外，我们的简单 yet 有效的框架还可以实现多类细胞检测，这在已有的无监督方法中无法完成。<details>
<summary>Abstract</summary>
The success of supervised deep learning models on cell recognition tasks relies on detailed annotations. Many previous works have managed to reduce the dependency on labels. However, considering the large number of cells contained in a patch, costly and inefficient labeling is still inevitable. To this end, we explored label-free methods for cell recognition. Prior self-activation maps (PSM) are proposed to generate pseudo masks as training targets. To be specific, an activation network is trained with self-supervised learning. The gradient information in the shallow layers of the network is aggregated to generate prior self-activation maps. Afterward, a semantic clustering module is then introduced as a pipeline to transform PSMs to pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets: MoNuSeg (cell segmentation) and BCData (multi-class cell detection). Compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. Our simple but effective framework can also achieve multi-class cell detection which can not be done by existing unsupervised methods. The results show the potential of PSMs that might inspire other research to deal with the hunger for labels in medical area.
</details>
<details>
<summary>摘要</summary>
Successful supervised deep learning models for cell recognition rely heavily on detailed annotations. However, obtaining these annotations can be costly and inefficient. To address this issue, we explored label-free methods for cell recognition. Our proposed method uses prior self-activation maps (PSMs) to generate pseudo masks as training targets. Specifically, we train an activation network using self-supervised learning to generate the PSMs, and then use a semantic clustering module to transform the PSMs into pixel-level semantic pseudo masks for downstream tasks. We evaluated our method on two histological datasets (MoNuSeg and BCData) and found that it can achieve competitive performance without any manual annotations. Our method is simple but effective, and can also perform multi-class cell detection, which is not possible with existing unsupervised methods. The results demonstrate the potential of PSMs to address the need for labels in medical applications.
</details></li>
</ul>
<hr>
<h2 id="Is-There-Any-Social-Principle-for-LLM-Based-Agents"><a href="#Is-There-Any-Social-Principle-for-LLM-Based-Agents" class="headerlink" title="Is There Any Social Principle for LLM-Based Agents?"></a>Is There Any Social Principle for LLM-Based Agents?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11136">http://arxiv.org/abs/2308.11136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jitao Bai, Simiao Zhang, Zhonghao Chen</li>
<li>for: 这篇论文主要是关于大语言模型基于代理的应用。</li>
<li>methods: 论文使用了大语言模型来实现代理，并考虑了社会科学的应用。</li>
<li>results: 论文提出了一种新的代理方法，并通过实验证明了其效果。In English, this translates to:</li>
<li>for: This paper is primarily about the application of large language models based on proxies.</li>
<li>methods: The paper uses large language models to implement proxies and considers applications in social sciences.</li>
<li>results: The paper proposes a new proxy method and experiments prove its effectiveness.<details>
<summary>Abstract</summary>
Focus on Large Language Model based agents should involve more than "human-centered" alignment or application. We argue that more attention should be paid to the agent itself and discuss the potential of social sciences for agents.
</details>
<details>
<summary>摘要</summary>
大语言模型基于代理应该超出人类中心的启aligned或应用。我们认为代理本身应该受到更多的注意力，并讨论社会科学在代理方面的潜力。Here's a word-for-word translation:大语言模型基于代理应该超出人类中心的启aligned或应用。我们认为代理本身应该受到更多的注意力，并讨论社会科学在代理方面的潜力。Note that Simplified Chinese is the standard writing system used in mainland China, while Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="ReLLa-Retrieval-enhanced-Large-Language-Models-for-Lifelong-Sequential-Behavior-Comprehension-in-Recommendation"><a href="#ReLLa-Retrieval-enhanced-Large-Language-Models-for-Lifelong-Sequential-Behavior-Comprehension-in-Recommendation" class="headerlink" title="ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation"></a>ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11131">http://arxiv.org/abs/2308.11131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, Weinan Zhang</li>
<li>for: 这 paper 主要针对 recommendation  зада务中的 zero-shot 和 few-shot 设置，以提高大语言模型 (LLM) 的表现。</li>
<li>methods: 该 paper 提出了一种 novel 框架，名为 Retrieval-enhanced Large Language models (ReLLa)，用于解决 LLM 在 recommendation 领域中的各种问题。</li>
<li>results: 经过广泛的实验，ReLLa 表现出优于现有基线模型，并能够解决 LLM 在长期序列行为理解方面的问题。<details>
<summary>Abstract</summary>
With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on a real-world public dataset (i.e., MovieLens-1M) to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension.
</details>
<details>
<summary>摘要</summary>
Large language models (LLMs) 在自然语言处理（NLP）领域取得了显著的突破， LLM-enhanced recommender systems 也在当前得到了广泛的关注。在这篇论文中，我们关注在适应和强化纯大语言模型（LLM）的零shot和几shot推荐任务上。首先，我们识别和描述了 LLM 在推荐领域中的生命周期行为无法理解问题，即 LLM 无法从用户行为序列中提取有用信息，即使用户行为序列的长度远远超过 LLM 的上下文限制。为解决这一问题并提高 LLM 的推荐性能，我们提出了一种新的框架，即 Retrieval-enhanced Large Language models (ReLLa)，用于零shot和几shot的推荐任务。 для零shot推荐，我们实施了 semantic user behavior retrieval (SUBR)，以提高测试样本的数据质量，从而减轻 LLM 提取用户行为序列中的关键知识的困难。而为了几shot推荐，我们进一步设计了 retrieval-enhanced instruction tuning (ReiT)，通过采用 SUBR 作为数据增强技术来培育训练样本。具体来说，我们构建了一个混合训练集，包括原始数据样本和其增强后的对应样本。我们在一个真实的公共数据集（即 MovieLens-1M）上进行了广泛的实验，以证明 ReLLa 与现有基eline模型相比，具有更高的优势，同时也能够解决生命周期行为无法理解问题。
</details></li>
</ul>
<hr>
<h2 id="Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances"><a href="#Transformers-for-Capturing-Multi-level-Graph-Structure-using-Hierarchical-Distances" class="headerlink" title="Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances"></a>Transformers for Capturing Multi-level Graph Structure using Hierarchical Distances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11129">http://arxiv.org/abs/2308.11129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuankai Luo</li>
<li>for: 本研究旨在提出一种基于层次结构编码的图变换器，以提高图变换器对不同类型图的表现。</li>
<li>methods: 本研究使用了一种名为层次距离结构编码（HDSE）的方法，该方法利用图中节点之间的层次距离来建模图的多层次结构。</li>
<li>results: 经过对12个实际数据集的广泛实验，研究发现，使用HDSE方法可以成功地提高多种基eline transformers的表现，在10个标准测试集上实现了状态的领先性表现。<details>
<summary>Abstract</summary>
Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current proposals rarely address methods capturing longer ranges, hierarchical structures, or community structures, as they appear in various graphs such as molecules, social networks, and citation networks. In this paper, we propose a hierarchy-distance structural encoding (HDSE), which models a hierarchical distance between the nodes in a graph focusing on its multi-level, hierarchical nature. In particular, this yields a framework which can be flexibly integrated with existing graph transformers, allowing for simultaneous application with other positional representations. Through extensive experiments on 12 real-world datasets, we demonstrate that our HDSE method successfully enhances various types of baseline transformers, achieving state-of-the-art empirical performances on 10 benchmark datasets.
</details>
<details>
<summary>摘要</summary>
GRaph transformers需要强大的推导性偏好，以derive meaningful attention scores。然而，当前的提议 rarely address methods capturing longer ranges, hierarchical structures, or community structures，as they appear in various graphs such as molecules, social networks, and citation networks。在这篇论文中，我们提议了一种层次距离结构编码(HDSE)，该模型在图中节点之间的层次距离，强调图的多层、层次结构。特别是，这种方法可以flexibly integrate with existing graph transformers，allowing for simultaneous application with other positional representations。通过对12个实际 dataset进行了广泛的实验，我们证明了我们的HDSE方法成功地提高了多种基eline transformers的性能，达到了10个标准 benchmark dataset的状态态表现。
</details></li>
</ul>
<hr>
<h2 id="CAME-Contrastive-Automated-Model-Evaluation"><a href="#CAME-Contrastive-Automated-Model-Evaluation" class="headerlink" title="CAME: Contrastive Automated Model Evaluation"></a>CAME: Contrastive Automated Model Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11111">http://arxiv.org/abs/2308.11111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pengr/contrastive_autoeval">https://github.com/pengr/contrastive_autoeval</a></li>
<li>paper_authors: Ru Peng, Qiuyang Duan, Haobo Wang, Jiachen Ma, Yanbo Jiang, Yongjun Tu, Xiu Jiang, Junbo Zhao</li>
<li>for: 本研究旨在提出一种新的自动模型评估（AutoEval）框架，以便评估训练完成的机器学习模型而无需使用标注测试集。</li>
<li>methods: 该框架基于一种新的对比损失函数，通过对比测试集中的模型表现和训练集中的模型表现来评估模型的性能。</li>
<li>results: 研究人员通过实验证明，CAME框架可以在AutoEval中达到新的最佳性能水平，超过先前的工作。<details>
<summary>Abstract</summary>
The Automated Model Evaluation (AutoEval) framework entertains the possibility of evaluating a trained machine learning model without resorting to a labeled testing set. Despite the promise and some decent results, the existing AutoEval methods heavily rely on computing distribution shifts between the unlabelled testing set and the training set. We believe this reliance on the training set becomes another obstacle in shipping this technology to real-world ML development. In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop. The core idea of CAME bases on a theoretical analysis which bonds the model performance with a contrastive loss. Further, with extensive empirical validation, we manage to set up a predictable relationship between the two, simply by deducing on the unlabeled/unseen testing set. The resulting framework CAME establishes a new SOTA results for AutoEval by surpassing prior work significantly.
</details>
<details>
<summary>摘要</summary>
autoeval框架可能无需使用标注测试集来评估已经训练的机器学习模型。尽管存在承诺和一些不错的结果，现有的autoeval方法都仰赖计算分布shift между无标测试集和训练集。我们认为这种依赖于训练集的方法会成为实际ml开发中的另一个障碍。在这项工作中，我们提出了对比自动评估（CAME）框架，它不再需要使用训练集。CAME的核心想法基于对模型性能与对比损失的理论分析。我们通过大量的实验验证，成功地建立了对比测试集上的模型性能和对比损失之间的可预测关系。这种关系可以通过对无标测试集进行推理来获得。CAME的框架在autoeval领域创造了新的最佳实践（SOTA）结果，超过了之前的工作。
</details></li>
</ul>
<hr>
<h2 id="Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models"><a href="#Anonymity-at-Risk-Assessing-Re-Identification-Capabilities-of-Large-Language-Models" class="headerlink" title="Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models"></a>Anonymity at Risk? Assessing Re-Identification Capabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11103">http://arxiv.org/abs/2308.11103</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models">https://github.com/skatinger/anonymity-at-risk-assessing-re-identification-capabilities-of-large-language-models</a></li>
<li>paper_authors: Alex Nyffenegger, Matthias Stürmer, Joel Niklaus</li>
<li>for: The paper explores the potential of large language models (LLMs) to re-identify individuals in court rulings, with a focus on privacy protection in the European Union and Switzerland.</li>
<li>methods: The authors construct a proof-of-concept using actual legal data from the Swiss federal supreme court and create an anonymized Wikipedia dataset for more rigorous testing. They introduce new metrics to measure performance and systematically analyze the factors that influence successful re-identifications.</li>
<li>results: Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions due to a lack of test datasets, the need for substantial training resources, and data sparsity in the information used for re-identification. The study concludes that re-identification using LLMs may not be feasible for now, but it could become possible in the future.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究探讨了大语言模型（LLMs）在法律案例中重新标识个人的可能性，强调欧盟和瑞士隐私保护。</li>
<li>methods: 作者们使用实际的瑞士最高法院判决文档构建了证明，并创建了一个匿名的Wikipedia数据集进行更加严格的测试。他们引入了新的成本度量来衡量表现，并系统地分析了重要的成本因素。</li>
<li>results: 尽管在Wikipedia上获得了高的重新标识率，甚至最好的LLMs在法律案例中仍然遇到了困难，这是因为缺乏测试数据集，需要巨大的训练资源，以及法律案例中数据的稀缺性。研究结论是，使用LLMs进行重新标识可能不太可能，但是未来可能变得可能。<details>
<summary>Abstract</summary>
Anonymity of both natural and legal persons in court rulings is a critical aspect of privacy protection in the European Union and Switzerland. With the advent of LLMs, concerns about large-scale re-identification of anonymized persons are growing. In accordance with the Federal Supreme Court of Switzerland, we explore the potential of LLMs to re-identify individuals in court rulings by constructing a proof-of-concept using actual legal data from the Swiss federal supreme court. Following the initial experiment, we constructed an anonymized Wikipedia dataset as a more rigorous testing ground to further investigate the findings. With the introduction and application of the new task of re-identifying people in texts, we also introduce new metrics to measure performance. We systematically analyze the factors that influence successful re-identifications, identifying model size, input length, and instruction tuning among the most critical determinants. Despite high re-identification rates on Wikipedia, even the best LLMs struggled with court decisions. The complexity is attributed to the lack of test datasets, the necessity for substantial training resources, and data sparsity in the information used for re-identification. In conclusion, this study demonstrates that re-identification using LLMs may not be feasible for now, but as the proof-of-concept on Wikipedia showed, it might become possible in the future. We hope that our system can help enhance the confidence in the security of anonymized decisions, thus leading to the courts being more confident to publish decisions.
</details>
<details>
<summary>摘要</summary>
“欧盟和瑞士的司法预测中的匿名性保护是一个重要的问题。随着大规模数据预测技术的发展，对匿名化后的个人重新识别的担忧增加。根据瑞士联邦最高法院的判决，我们进行了一个实验，使用瑞士联邦最高法院的法律数据来测试LLM的重新识别能力。在进一步的测试中，我们使用了一个匿名化的Wikipedia数据集，以更加严谨地检验发现。我们也引入了一个新的任务，即在文本中重新识别个人，并且引入了新的衡量表现的指标。我们系统性地分析了对成功重新识别的影响因素，发现模型大小、输入长度和调整受到最大的影响。尽管在Wikipedia上有高的重新识别率，但是even the best LLMs仅在法院的判决中取得了 moderate的成功率。这些成功率的低度是由于没有足够的测试数据、需要很大的训练资源和数据潜在的缺乏。因此，我们的研究结果表明，使用LLMs进行重新识别可能不太可能，但是在未来，这个技术可能会成为可能的。我们希望，我们的系统可以帮助提高匿名化判决的安全性，使得法院更自信地发布判决。”
</details></li>
</ul>
<hr>
<h2 id="Using-Early-Exits-for-Fast-Inference-in-Automatic-Modulation-Classification"><a href="#Using-Early-Exits-for-Fast-Inference-in-Automatic-Modulation-Classification" class="headerlink" title="Using Early Exits for Fast Inference in Automatic Modulation Classification"></a>Using Early Exits for Fast Inference in Automatic Modulation Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11100">http://arxiv.org/abs/2308.11100</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elsayed Mohammed, Omar Mashaal, Hatem Abou-Zeid</li>
<li>for: 本研究旨在提高无线通信中的自动模式分类（AMC）技术的效率，通过使用深度学习（DL）技术提取无线信号特征。</li>
<li>methods: 本研究提出使用早期离开（EE）技术加速DL模型的推理，并研究了四种不同的早期离开架构和自定义多支分支训练算法。</li>
<li>results: 通过广泛的实验，我们发现对于中度到高度的信号含杂率（SNR），使用EE技术可以显著降低深度神经网络的推理速度，而不会产生分类精度的下降。我们还进行了推理时间与分类精度之间的平衡分析。这是目前所知道的首次应用EE技术于AMC领域的研究。<details>
<summary>Abstract</summary>
Automatic modulation classification (AMC) plays a critical role in wireless communications by autonomously classifying signals transmitted over the radio spectrum. Deep learning (DL) techniques are increasingly being used for AMC due to their ability to extract complex wireless signal features. However, DL models are computationally intensive and incur high inference latencies. This paper proposes the application of early exiting (EE) techniques for DL models used for AMC to accelerate inference. We present and analyze four early exiting architectures and a customized multi-branch training algorithm for this problem. Through extensive experimentation, we show that signals with moderate to high signal-to-noise ratios (SNRs) are easier to classify, do not require deep architectures, and can therefore leverage the proposed EE architectures. Our experimental results demonstrate that EE techniques can significantly reduce the inference speed of deep neural networks without sacrificing classification accuracy. We also thoroughly study the trade-off between classification accuracy and inference time when using these architectures. To the best of our knowledge, this work represents the first attempt to apply early exiting methods to AMC, providing a foundation for future research in this area.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:自动模式分类（AMC）在无线通信中扮演了关键的角色，可以自动将广播信号分类。深度学习（DL）技术在AMC中越来越受到关注，因为它们可以提取广播信号的复杂特征。然而，DL模型具有高计算复杂度和高推理延迟。这篇论文提出使用早退出（EE）技术来加速DL模型在AMC中的推理。我们提出了四种EE架构和一种自定义多支分支训练算法。经过广泛的实验，我们发现在moderate to high signal-to-noise ratio（SNR）下，信号更容易分类，不需要深度的架构，可以利用我们提出的EE架构。我们的实验结果表明，EE技术可以减少深度神经网络的推理速度，而不会增加分类精度的损失。我们还在使用这些架构时进行了严格的质量评估和时间评估。根据我们所知，这是首次将EE技术应用于AMC，这为未来的相关研究提供了基础。
</details></li>
</ul>
<hr>
<h2 id="Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video"><a href="#Video-OWL-ViT-Temporally-consistent-open-world-localization-in-video" class="headerlink" title="Video OWL-ViT: Temporally-consistent open-world localization in video"></a>Video OWL-ViT: Temporally-consistent open-world localization in video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11093">http://arxiv.org/abs/2308.11093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Heigold, Matthias Minderer, Alexey Gritsenko, Alex Bewley, Daniel Keysers, Mario Lučić, Fisher Yu, Thomas Kipf</li>
<li>for: 本研究旨在适应预训练的开放视界图像模型到视频本地化中。</li>
<li>methods: 我们基于OWL-ViT开放词汇检测模型，并添加了一个变换器解码器，以卷积神经网络输出的一帧图像作为下一帧对象查询。</li>
<li>results: 我们的模型在面对挑战性的TAO-OWBenchmark上表现出色，证明了预训练大量图像文本数据可以成功传递到开放视界本地化中。<details>
<summary>Abstract</summary>
We present an architecture and a training recipe that adapts pre-trained open-world image models to localization in videos. Understanding the open visual world (without being constrained by fixed label spaces) is crucial for many real-world vision tasks. Contrastive pre-training on large image-text datasets has recently led to significant improvements for image-level tasks. For more structured tasks involving object localization applying pre-trained models is more challenging. This is particularly true for video tasks, where task-specific data is limited. We show successful transfer of open-world models by building on the OWL-ViT open-vocabulary detection model and adapting it to video by adding a transformer decoder. The decoder propagates object representations recurrently through time by using the output tokens for one frame as the object queries for the next. Our model is end-to-end trainable on video data and enjoys improved temporal consistency compared to tracking-by-detection baselines, while retaining the open-world capabilities of the backbone detector. We evaluate our model on the challenging TAO-OW benchmark and demonstrate that open-world capabilities, learned from large-scale image-text pre-training, can be transferred successfully to open-world localization across diverse videos.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:我们提出了一种架构和训练方法，可以将预训练的开放视界图像模型适应到视频地图Localization。理解开放视界（不受固定标签空间约束）是许多实际视觉任务的关键。在大量图像文本数据集上进行对比预训练，最近导致了图像级别任务的显著改进。然而，对于结构化任务，如对象localization，使用预训练模型更加困难。特别是在视频任务中，任务特定数据受限。我们在OWL-ViT开放词汇探测模型的基础上建立了一个Transformer解码器，以便在视频中传播对象表示。解码器使用下一帧的输出符号来作为下一帧的对象查询。我们的模型是基于视频数据的端到端训练的，并且比较tracking-by-detection基eline更有优势，同时保留了预训练模型的开放视界能力。我们在TAO-OWbenchmark上评估了我们的模型，并证明了可以成功传递开放视界的能力，从大规模图像文本预训练中学习到开放视界地图Localization across多种视频。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Route-Planning-of-UAVs-Workers-and-Cars-for-Crowdsensing-in-Disaster-Response"><a href="#Collaborative-Route-Planning-of-UAVs-Workers-and-Cars-for-Crowdsensing-in-Disaster-Response" class="headerlink" title="Collaborative Route Planning of UAVs, Workers and Cars for Crowdsensing in Disaster Response"></a>Collaborative Route Planning of UAVs, Workers and Cars for Crowdsensing in Disaster Response</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11088">http://arxiv.org/abs/2308.11088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Han, Chunyu Tu, Zhiwen Yu, Zhiyong Yu, Weihua Shan, Liang Wang, Bin Guo</li>
<li>for: 本研究旨在提高灾区内部合作多代理器（UAV、工人和车辆）的数据收集效率。</li>
<li>methods: 本研究提出了一个多代理器路径观察法（MANF-RL-RP），具有多效设计，包括全球与本地信息处理、特定多代理器系统模型结构等。</li>
<li>results: 比较基准算法（Greedy-SC-RP和MANF-DNN-RP），MANF-RL-RP在任务完成率方面有显著提高。<details>
<summary>Abstract</summary>
Efficiently obtaining the up-to-date information in the disaster-stricken area is the key to successful disaster response. Unmanned aerial vehicles (UAVs), workers and cars can collaborate to accomplish sensing tasks, such as data collection, in disaster-stricken areas. In this paper, we explicitly address the route planning for a group of agents, including UAVs, workers, and cars, with the goal of maximizing the task completion rate. We propose MANF-RL-RP, a heterogeneous multi-agent route planning algorithm that incorporates several efficient designs, including global-local dual information processing and a tailored model structure for heterogeneous multi-agent systems. Global-local dual information processing encompasses the extraction and dissemination of spatial features from global information, as well as the partitioning and filtering of local information from individual agents. Regarding the construction of the model structure for heterogeneous multi-agent, we perform the following work. We design the same data structure to represent the states of different agents, prove the Markovian property of the decision-making process of agents to simplify the model structure, and also design a reasonable reward function to train the model. Finally, we conducted detailed experiments based on the rich simulation data. In comparison to the baseline algorithms, namely Greedy-SC-RP and MANF-DNN-RP, MANF-RL-RP has exhibited a significant improvement in terms of task completion rate.
</details>
<details>
<summary>摘要</summary>
efficiently 获取在灾难 struck 地区的最新信息是灾难应对的关键。无人飞行器（UAV）、工人和车辆可以在灾难 struck 地区合作完成感知任务，如数据收集。在这篇论文中，我们明确地讨论了一组代理人（包括UAV、工人和车辆）的路径规划，以最大化任务完成率为目标。我们提出了多Agent Route Planning Algorithm（MANF-RL-RP），该算法包括了许多高效的设计，如全球-本地双信息处理和特定的模型结构 для多种Agent系统。全球-本地双信息处理包括从全球信息中提取和传递空间特征，以及来自个体代理人的本地信息的分区和筛选。在构建多种Agent系统的模型结构方面，我们进行了以下工作。我们设计了同样的数据结构来表示不同代理人的状态，证明代理人决策过程的markt价性以简化模型结构，并设计了合理的奖励函数来训练模型。最后，我们对着富有的 simulate 数据进行了详细的实验。与基准算法（即Greedy-SC-RP和MANF-DNN-RP）相比，MANF-RL-RP 在任务完成率方面表现出了显著的提升。
</details></li>
</ul>
<hr>
<h2 id="Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning"><a href="#Neural-Amortized-Inference-for-Nested-Multi-agent-Reasoning" class="headerlink" title="Neural Amortized Inference for Nested Multi-agent Reasoning"></a>Neural Amortized Inference for Nested Multi-agent Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11071">http://arxiv.org/abs/2308.11071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunal Jha, Tuan Anh Le, Chuanyang Jin, Yen-Ling Kuo, Joshua B. Tenenbaum, Tianmin Shu</li>
<li>for: 本研究旨在提高多智能体交互中的复杂社会推理能力，使其能够更好地理解别人对自己的推理。</li>
<li>methods: 本研究使用神经网络来减轻高阶社会推理的计算复杂性，以提高多智能体交互的效率。</li>
<li>results: 实验结果表明，我们的方法可以减少计算复杂性，同时减少准确性的削弱。<details>
<summary>Abstract</summary>
Multi-agent interactions, such as communication, teaching, and bluffing, often rely on higher-order social inference, i.e., understanding how others infer oneself. Such intricate reasoning can be effectively modeled through nested multi-agent reasoning. Nonetheless, the computational complexity escalates exponentially with each level of reasoning, posing a significant challenge. However, humans effortlessly perform complex social inferences as part of their daily lives. To bridge the gap between human-like inference capabilities and computational limitations, we propose a novel approach: leveraging neural networks to amortize high-order social inference, thereby expediting nested multi-agent reasoning. We evaluate our method in two challenging multi-agent interaction domains. The experimental results demonstrate that our method is computationally efficient while exhibiting minimal degradation in accuracy.
</details>
<details>
<summary>摘要</summary>
多代理交互，如通信、教学和威胁，经常需要高级社会推理，即理解他们如何推理自己。这种复杂的推理可以通过嵌套多代理推理来有效模型。然而，计算复杂性随着每层推理层数的增加而呈指数增长， pose significant challenges。然而，人类在日常生活中很自然地完成复杂的社会推理。为了bridging这个 gap，我们提出了一种新的方法：利用神经网络来减轻高级社会推理，从而加快嵌套多代理推理。我们在两个复杂多代理交互领域进行了实验，结果表明我们的方法具有高效性和减少准确性下降的能力。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Distributed-Backdoor-Attack-Against-Video-Based-Action-Recognition"><a href="#Temporal-Distributed-Backdoor-Attack-Against-Video-Based-Action-Recognition" class="headerlink" title="Temporal-Distributed Backdoor Attack Against Video Based Action Recognition"></a>Temporal-Distributed Backdoor Attack Against Video Based Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11070">http://arxiv.org/abs/2308.11070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Li, Songhe Wang, Ruiquan Huang, Mahanth Gowda, George Kesidis</li>
<li>for: 本研究旨在探讨视频数据下的后门攻击（Trojan），以及现有模型对这种攻击的抵御性。</li>
<li>methods: 本研究提出了一种简单 yet 有效的后门攻击方法，通过在转换域中添加杂音来植入潜在的攻击词。这种攻击可以在视频帧中逐帧插入，并且可以在攻击后继续保持高准确率。</li>
<li>results: 经过广泛的实验，研究人员发现这种攻击方法可以在多种知名模型上达到高度可见性和鲁棒性，并且可以在不同的视频识别 benchmark 上实现攻击。此外，研究人员还发现了一种称为 “Collateral Damage” 的现象，即在攻击过程中可能会导致模型对非目标类型的数据进行误分类。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have achieved tremendous success in various applications including video action recognition, yet remain vulnerable to backdoor attacks (Trojans). The backdoor-compromised model will mis-classify to the target class chosen by the attacker when a test instance (from a non-target class) is embedded with a specific trigger, while maintaining high accuracy on attack-free instances. Although there are extensive studies on backdoor attacks against image data, the susceptibility of video-based systems under backdoor attacks remains largely unexplored. Current studies are direct extensions of approaches proposed for image data, e.g., the triggers are \textbf{independently} embedded within the frames, which tend to be detectable by existing defenses. In this paper, we introduce a \textit{simple} yet \textit{effective} backdoor attack against video data. Our proposed attack, adding perturbations in a transformed domain, plants an \textbf{imperceptible, temporally distributed} trigger across the video frames, and is shown to be resilient to existing defensive strategies. The effectiveness of the proposed attack is demonstrated by extensive experiments with various well-known models on two video recognition benchmarks, UCF101 and HMDB51, and a sign language recognition benchmark, Greek Sign Language (GSL) dataset. We delve into the impact of several influential factors on our proposed attack and identify an intriguing effect termed "collateral damage" through extensive studies.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在不同应用场景中取得了很大成功，如视频动作识别，然而它们却容易受到后门攻击（Trojan）。攻击者可以通过特定的触发符使得恶意修改的模型在测试实例（非目标类）中产生错误分类，而保持高精度水平。虽然对于图像数据已有广泛的研究，但视频系统对于后门攻击的抗性仍然尚未得到充分研究。现有的研究多是对图像数据进行直接扩展，例如在帧内独立地插入触发符，这些触发符可以被现有的防御策略检测。在这篇论文中，我们提出了一种简单又有效的后门攻击方法，通过在转换域中添加噪声，在视频帧中植入不可见、时间分布的触发符，并证明其具有抗性。我们通过对多种知名模型在UCf101、HMDB51和希腊手语认知 benchmark 上进行了广泛的实验，证明了我们的提案的有效性。我们还进行了详细的研究，探讨了一些影响我们提案的因素，并发现了一种感人的效果，我们称之为“副作用”。
</details></li>
</ul>
<hr>
<h2 id="Topological-Graph-Signal-Compression"><a href="#Topological-Graph-Signal-Compression" class="headerlink" title="Topological Graph Signal Compression"></a>Topological Graph Signal Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11068">http://arxiv.org/abs/2308.11068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, Lev Telyatnikov, Eduard Alarcón, Albert Cabellos-Aparicio, Pere Barlet-Ros, Pietro Liò</li>
<li>for: 这 paper 的目的是提出一种基于 Topological Deep Learning (TDL) 方法来压缩信号 над 图 structures。</li>
<li>methods: 这 paper 使用的方法包括对原始信号进行分 clustering，然后使用 topological-inspired message passing 获取压缩后的信号表示。</li>
<li>results: 该方法可以在两个实际 Internet Service Provider Networks 的数据集上提高标准 GNN 和 feed-forward 架构的压缩性能，从 $30%$ 到 $90%$ 的压缩率提高，表明它更好地捕捉和利用图结构中的空间和时间相关性。<details>
<summary>Abstract</summary>
Recently emerged Topological Deep Learning (TDL) methods aim to extend current Graph Neural Networks (GNN) by naturally processing higher-order interactions, going beyond the pairwise relations and local neighborhoods defined by graph representations. In this paper we propose a novel TDL-based method for compressing signals over graphs, consisting in two main steps: first, disjoint sets of higher-order structures are inferred based on the original signal --by clustering $N$ datapoints into $K\ll N$ collections; then, a topological-inspired message passing gets a compressed representation of the signal within those multi-element sets. Our results show that our framework improves both standard GNN and feed-forward architectures in compressing temporal link-based signals from two real-word Internet Service Provider Networks' datasets --from $30\%$ up to $90\%$ better reconstruction errors across all evaluation scenarios--, suggesting that it better captures and exploits spatial and temporal correlations over the whole graph-based network structure.
</details>
<details>
<summary>摘要</summary>
最近爆发的拓扑深度学习（TDL）方法希望可以补充当前图ael neural network（GNN）的限制，自然处理更高阶交互，超出现有图表示中的对角相关和本地邻里hood。在这篇论文中，我们提出了一种基于TDL的图信号压缩方法，包括两个主要步骤：首先，通过原始信号对$N$个数据点进行分 clustering，将其分成$K\ll N$个集合；然后，基于图的拓扑结构，进行多元素集合内的扩展传递，以获得压缩后的信号表示。我们的结果表明，我们的框架可以在两个实际世界互联网服务提供商网络数据集上，将标准GNN和批处理架构超越，在压缩时间链接基于网络结构中的信号方面达到$30\%$到$90\%$的更好的重建错误，表明它更好地捕捉和利用图结构中的空间和时间相关性。
</details></li>
</ul>
<hr>
<h2 id="CSM-H-R-An-Automatic-Context-Reasoning-Framework-for-Interoperable-Intelligent-Systems-and-Privacy-Protection"><a href="#CSM-H-R-An-Automatic-Context-Reasoning-Framework-for-Interoperable-Intelligent-Systems-and-Privacy-Protection" class="headerlink" title="CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection"></a>CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11066">http://arxiv.org/abs/2308.11066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/songhui01/csm-h-r">https://github.com/songhui01/csm-h-r</a></li>
<li>paper_authors: Songhui Yue, Xiaoyan Hong, Randy K. Smith</li>
<li>for: 这个论文的目的是提出一个自动化高级上下文（HLC）理解框架，以便在智能系统规模上实现智能系统的自动化整合。</li>
<li>methods: 该框架使用ontology和状态在运行时和模型存储阶段进行程序式组合，以实现意义full HLC的认知，并将结果应用于不同的理解技术。</li>
<li>results: 实验表明，该框架可以自动捕捉和理解高级上下文，并将其转换为可以应用于不同的理解技术的数据表示。此外，该框架还实现了隐私保护功能，通过域嵌入和信息卷积来减少信息相关性。<details>
<summary>Abstract</summary>
Automation of High-Level Context (HLC) reasoning for intelligent systems at scale is imperative due to the unceasing accumulation of contextual data in the IoT era, the trend of the fusion of data from multi-sources, and the intrinsic complexity and dynamism of the context-based decision-making process. To mitigate this issue, we propose an automatic context reasoning framework CSM-H-R, which programmatically combines ontologies and states at runtime and the model-storage phase for attaining the ability to recognize meaningful HLC, and the resulting data representation can be applied to different reasoning techniques. Case studies are developed based on an intelligent elevator system in a smart campus setting. An implementation of the framework - a CSM Engine, and the experiments of translating the HLC reasoning into vector and matrix computing especially take care of the dynamic aspects of context and present the potentiality of using advanced mathematical and probabilistic models to achieve the next level of automation in integrating intelligent systems; meanwhile, privacy protection support is achieved by anonymization through label embedding and reducing information correlation. The code of this study is available at: https://github.com/songhui01/CSM-H-R.
</details>
<details>
<summary>摘要</summary>
自然语言处理（NLP）技术在智能系统中的应用在不断增长，特别是在互联网物联网（IoT）时代，数据来源的融合和上下文决策过程的内在复杂性和动态性使得高级上下文（HLC）理解成为非常重要的。为解决这一问题，我们提出了一个自动上下文理解框架CSM-H-R，该框架在运行时和模型存储阶段使用ontologies和状态进行程序性结合，以实现对有意义的HLC的识别，并且可以应用于不同的理解技术。在智能电梯系统的实际案例中，我们开发了CSM引擎，并对HLC理解进行了vector和矩阵计算的实验，特别是处理上下文的动态性，表明了使用高级数学和统计模型可以实现下一个自动化层次的智能系统集成。同时，我们实现了隐私保护支持，通过嵌入标签和减少信息相关性来实现隐身。CSM框架的代码可以在以下链接中找到：https://github.com/songhui01/CSM-H-R。
</details></li>
</ul>
<hr>
<h2 id="FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning"><a href="#FedDAT-An-Approach-for-Foundation-Model-Finetuning-in-Multi-Modal-Heterogeneous-Federated-Learning" class="headerlink" title="FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning"></a>FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12305">http://arxiv.org/abs/2308.12305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Yao Zhang, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 这则研究旨在提高基础模型在多modal学习中的表现，并且解决集中训练数据的问题。</li>
<li>methods: 本研究使用 Federated Dual-Adapter Teacher (FedDAT) 方法，具有调整客户端本地更新和实施多元知识传播 (MKD)，以解决客户端数据不具同一性的问题。</li>
<li>results: 实验结果显示，FedDAT 在多modal Vision-Language 任务上substantially 超过了现有的中央化 PEFT 方法适应 FL 的表现。<details>
<summary>Abstract</summary>
Recently, foundation models have exhibited remarkable advancements in multi-modal learning. These models, equipped with millions (or billions) of parameters, typically require a substantial amount of data for finetuning. However, collecting and centralizing training data from diverse sectors becomes challenging due to distinct privacy regulations. Federated Learning (FL) emerges as a promising solution, enabling multiple clients to collaboratively train neural networks without centralizing their local data. To alleviate client computation burdens and communication overheads, previous works have adapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a small fraction of the model parameters are optimized and communicated during federated communications. Nevertheless, most previous works have focused on a single modality and neglected one common phenomenon, i.e., the presence of data heterogeneity across the clients. Therefore, in this work, we propose a finetuning framework tailored to heterogeneous multi-modal FL, called Federated Dual-Aadapter Teacher (FedDAT). Specifically, our approach leverages a Dual-Adapter Teacher (DAT) to address data heterogeneity by regularizing the client local updates and applying Mutual Knowledge Distillation (MKD) for an efficient knowledge transfer. FedDAT is the first approach that enables an efficient distributed finetuning of foundation models for a variety of heterogeneous Vision-Language tasks. To demonstrate its effectiveness, we conduct extensive experiments on four multi-modality FL benchmarks with different types of data heterogeneity, where FedDAT substantially outperforms the existing centralized PEFT methods adapted for FL.
</details>
<details>
<summary>摘要</summary>
最近，基金会模型在多模态学习中展现了显著的进步。这些模型通常需要大量数据进行微调，但收集和中央化训练数据因为不同隐私规定而变得困难。为了解决这问题，聚合学习（FL）成为了一种有前途的解决方案，允许多个客户共同训练神经网络，无需中央化本地数据。以减少客户计算负担和通信开销为目的，先前的工作已经采用了参数效率微调（PEFT）方法进行FL。然而，大多数先前的工作宁悠单一模式，忽视了客户端数据的不同性。因此，在本工作中，我们提出了适应多模式、多数据类型 federated 微调框架，称为 FedDAT。具体来说，我们的方法利用了双适应教师（DAT）来处理客户端数据的不同性，通过规则化客户端本地更新和应用知识传播（MKD）进行高效的知识传递。FedDAT 是首个能够有效地在多模态 FL 上进行基础模型的分布式微调。为证明其效果，我们在四个多模态 FL 测试准则上进行了广泛的实验，其中 FedDAT 在不同类型的数据不同性下显著超过了已有的中央化 PEFT 方法。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Discriminative-Regions-Saliency-Maps-as-Alternatives-to-CAMs-for-Weakly-Supervised-Semantic-Segmentation"><a href="#Beyond-Discriminative-Regions-Saliency-Maps-as-Alternatives-to-CAMs-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation"></a>Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11052">http://arxiv.org/abs/2308.11052</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Maruf, Arka Daw, Amartya Dutta, Jie Bu, Anuj Karpatne</li>
<li>for: 本研究比较了抽象图和特征图两种方法在弱监督 semantic segmentation (WS3) 中的表现，并提出了一些新的评价指标来全面评估这两种方法的性能。</li>
<li>methods: 本研究使用了特征图和抽象图两种方法来生成pseudo-ground truth，并通过多个视角来比较它们的相似性和不同性。</li>
<li>results: 研究发现，使用抽象图可以更好地解决WS3中的非特征区域 (NDR) 问题，并且通过随机裁剪提高了抽象图的性能。<details>
<summary>Abstract</summary>
In recent years, several Weakly Supervised Semantic Segmentation (WS3) methods have been proposed that use class activation maps (CAMs) generated by a classifier to produce pseudo-ground truths for training segmentation models. While CAMs are good at highlighting discriminative regions (DR) of an image, they are known to disregard regions of the object that do not contribute to the classifier's prediction, termed non-discriminative regions (NDR). In contrast, attribution methods such as saliency maps provide an alternative approach for assigning a score to every pixel based on its contribution to the classification prediction. This paper provides a comprehensive comparison between saliencies and CAMs for WS3. Our study includes multiple perspectives on understanding their similarities and dissimilarities. Moreover, we provide new evaluation metrics that perform a comprehensive assessment of WS3 performance of alternative methods w.r.t. CAMs. We demonstrate the effectiveness of saliencies in addressing the limitation of CAMs through our empirical studies on benchmark datasets. Furthermore, we propose random cropping as a stochastic aggregation technique that improves the performance of saliency, making it a strong alternative to CAM for WS3.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Weakly Supervised Semantic Segmentation" (WS3) is translated as "弱指示 semantic segmentation" (WS3) in Simplified Chinese.* "Class activation map" (CAM) is translated as "类划分图" (CAM) in Simplified Chinese.* "Discriminative regions" (DR) is translated as "分化区" (DR) in Simplified Chinese.* "Non-discriminative regions" (NDR) is translated as "非分化区" (NDR) in Simplified Chinese.* "Attribution methods" such as "saliency maps" is translated as "责任方法" such as "吸引图" in Simplified Chinese.* "Stochastic aggregation technique" such as "random cropping" is translated as "随机聚合技术" such as "随机裁剪" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Personalized-Event-Prediction-for-Electronic-Health-Records"><a href="#Personalized-Event-Prediction-for-Electronic-Health-Records" class="headerlink" title="Personalized Event Prediction for Electronic Health Records"></a>Personalized Event Prediction for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11013">http://arxiv.org/abs/2308.11013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeong Min Lee, Milos Hauskrecht</li>
<li>For: The paper aims to develop accurate predictive models of clinical event sequences to support patient care, specifically by addressing the challenge of patient-specific variability in clinical conditions.* Methods: The paper proposes and investigates multiple new event sequence prediction models and methods, including refinement of population-wide models to subpopulations, self-adaptation, and meta-level model switching.* Results: The paper analyzes and tests the performance of these models on clinical event sequences of patients in the MIMIC-III database.<details>
<summary>Abstract</summary>
Clinical event sequences consist of hundreds of clinical events that represent records of patient care in time. Developing accurate predictive models of such sequences is of a great importance for supporting a variety of models for interpreting/classifying the current patient condition, or predicting adverse clinical events and outcomes, all aimed to improve patient care. One important challenge of learning predictive models of clinical sequences is their patient-specific variability. Based on underlying clinical conditions, each patient's sequence may consist of different sets of clinical events (observations, lab results, medications, procedures). Hence, simple population-wide models learned from event sequences for many different patients may not accurately predict patient-specific dynamics of event sequences and their differences. To address the problem, we propose and investigate multiple new event sequence prediction models and methods that let us better adjust the prediction for individual patients and their specific conditions. The methods developed in this work pursue refinement of population-wide models to subpopulations, self-adaptation, and a meta-level model switching that is able to adaptively select the model with the best chance to support the immediate prediction. We analyze and test the performance of these models on clinical event sequences of patients in MIMIC-III database.
</details>
<details>
<summary>摘要</summary>
临床事件序列包括数百个临床事件记录，表示患者 receiving 的记录时间。 开发准确预测模型临床序列非常重要，以支持多种模型，用于解释/分类当前患者状况，预测不良临床事件和结果，以提高患者治疗。 一个重要的预测临床序列模型挑战是每个患者的病人特有性。 基于下面的临床状况，每个患者的序列可能包含不同的临床事件（观察结果、实验室测试、药物、手术）。 因此，从事件序列中学习的人口广泛模型可能无法准确预测每个患者的特定动态和差异。 为解决问题，我们提出和探索多种新的事件序列预测模型和方法，使我们能更好地适应患者和其特定状况。 我们在MIMIC-III数据库中分析和测试这些模型的性能。
</details></li>
</ul>
<hr>
<h2 id="“Guinea-Pig-Trials”-Utilizing-GPT-A-Novel-Smart-Agent-Based-Modeling-Approach-for-Studying-Firm-Competition-and-Collusion"><a href="#“Guinea-Pig-Trials”-Utilizing-GPT-A-Novel-Smart-Agent-Based-Modeling-Approach-for-Studying-Firm-Competition-and-Collusion" class="headerlink" title="“Guinea Pig Trials” Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion"></a>“Guinea Pig Trials” Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10974">http://arxiv.org/abs/2308.10974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Han, Zengqing Wu, Chuan Xiao</li>
<li>For: The paper is written to study firm competition and collusion using a novel framework called Smart Agent-Based Modeling (SABM), which employs GPT-4 technologies to represent firms and their interactions.* Methods: The study uses a controlled experiment with smart agents to examine firm price competition and collusion behaviors under various conditions, comparing the results to those obtained through experiments with human subjects.* Results: The paper finds that smart agents consistently reach tacit collusion in the absence of communication, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. With communication allowed, smart agents achieve a higher-level collusion with prices close to cartel prices, and collusion forms more quickly with communication. These results highlight the importance of communication in enhancing trust between firms and facilitating collusion.<details>
<summary>Abstract</summary>
Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling (SABM), wherein smart agents, supported by GPT-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. SABM is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional ABM agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate that, in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices. Collusion forms more quickly with communication, while price convergence is smoother without it. These results indicate that communication enhances trust between firms, encouraging frequent small price deviations to explore opportunities for a higher-level win-win situation and reducing the likelihood of triggering a price war. We also assigned different personas to firms to analyze behavioral differences and tested variant models under diverse market structures. The findings showcase the effectiveness and robustness of SABM and provide intriguing insights into competition and collusion.
</details>
<details>
<summary>摘要</summary>
企业竞争和勾结涉及到复杂的动态，特别是在公司之间的交流方面。这些问题可以通过人类实验或智能代理模型（ABM）来模拟。我们提出了一种创新的框架called Smart Agent-Based Modeling（SABM），其中智能代理，受到GPT-4技术支持，代表公司，并互动相互。我们进行了一项控制性实验，以研究企业价格竞争和勾结行为的不同情况。SABM相比人类实验更加经济和灵活。智能代理具有广泛的知识库和人类策略能力，超过传统ABM代理。此外，智能代理可以模拟人类对话，可个性化，使其适用于研究复杂的交流情况。我们的结果表明，在无交流情况下，智能代理一般会达成tacit collusion，导致价格相对于BERTRAND平衡价格高，但比单一垄断或垄断价格低。当交流被允许时，智能代理可以实现更高级别的勾结，价格接近垄断价格。勾结形成更快，无交流情况下价格均衡更平滑。这些结果表明，交流可以增强公司之间的信任，使小价格偏移更频繁地探索机会，降低价格战的可能性。我们还将不同的公司个性分配给不同的公司，以分析行为差异，并在多种市场结构下测试不同的模型。结果显示SABM的效果和稳定性，并提供了精彩的竞争和勾结的新思路。
</details></li>
</ul>
<hr>
<h2 id="DocPrompt-Large-scale-continue-pretrain-for-zero-shot-and-few-shot-document-question-answering"><a href="#DocPrompt-Large-scale-continue-pretrain-for-zero-shot-and-few-shot-document-question-answering" class="headerlink" title="DocPrompt: Large-scale continue pretrain for zero-shot and few-shot document question answering"></a>DocPrompt: Large-scale continue pretrain for zero-shot and few-shot document question answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10959">http://arxiv.org/abs/2308.10959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sijin Wu, Dan Zhang, Teng Hu, Shikun Feng</li>
<li>for: 文章旨在提出一种名为 Docprompt 的文档问答模型，可以在文档问答任务中实现强大的零学习和几学习性能。</li>
<li>methods: 文章提出了一种新的弱监督数据生成方法、一种多Stage训练方法和一种理解模型&amp;生成模型集成方法。</li>
<li>results: 实验结果显示， после继续预训练， Docprompt 模型在文档问答任务上明显超过了现有的强基线模型，并且可以大幅提高文档问答客户项目的交付效率和模型性能，降低注释成本和劳动成本。<details>
<summary>Abstract</summary>
In this paper, we propose Docprompt for document question answering tasks with powerful zero-shot and few-shot performance. We proposed a novel weakly supervised data generation method, a novel multl-stage training method and a novel understanding model & generation model ensemble method. Experiment results show that the Docprompt model after continue pretrain significantly outperforms the existing strong baseline models on document question answering tasks. This method greatly improves the delivery efficiency and model performance of document question answering customer projects, reducing annotation costs and labor costs. Our demo can be found at https://huggingface.co/spaces/PaddlePaddle/ERNIE-Layout.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了 Docprompt，用于文档问答任务的强大零shot和几shot性能的解决方案。我们提出了一种新的软参数生成方法、一种多Stage训练方法和一种新的理解模型&生成模型结合方法。实验结果显示，在继续预训练后，Docprompt模型在文档问答任务上明显超越了现有的强基线模型。这种方法可以大幅提高文档问答客户项目的交付效率和模型性能，降低注释成本和劳动成本。您可以在https://huggingface.co/spaces/PaddlePaddle/ERNIE-Layout找到我们的demo。
</details></li>
</ul>
<hr>
<h2 id="Structured-World-Models-from-Human-Videos"><a href="#Structured-World-Models-from-Human-Videos" class="headerlink" title="Structured World Models from Human Videos"></a>Structured World Models from Human Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10901">http://arxiv.org/abs/2308.10901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Russell Mendonca, Shikhar Bahl, Deepak Pathak</li>
<li>For: The paper aims to enable robots to learn complex manipulation skills directly in the real world using a small amount of interaction data.* Methods: The approach uses human video data to build a structured, human-centric action space grounded in visual affordances, and trains a world model on human videos before fine-tuning on a small amount of robot interaction data without task supervision.* Results: The approach allows robots to learn various manipulation skills in complex settings in under 30 minutes of interaction.Here is the same information in Simplified Chinese:* For: 论文旨在帮助机器人直接在真实世界中学习复杂的抓取技能，只需要很少的互动数据。* Methods: 方法使用人类视频数据构建一个基于视觉可用性的结构化人类行为空间，然后在人类视频上训练世界模型，并在小量机器人互动数据上练习而不需要任务指导。* Results: 方法可以让机器人在复杂的设置下快速学习多种抓取技能，仅需要30分钟的互动。<details>
<summary>Abstract</summary>
We tackle the problem of learning complex, general behaviors directly in the real world. We propose an approach for robots to efficiently learn manipulation skills using only a handful of real-world interaction trajectories from many different settings. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, our belief is that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. Our approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. Further, we train a world model on human videos and fine-tune on a small amount of robot interaction data without any task supervision. We show that this approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction. Videos can be found at https://human-world-model.github.io
</details>
<details>
<summary>摘要</summary>
我们面临的问题是直接在实际世界中学习复杂的通用行为。我们提议一种方法，使用只需一些不同场景的实际互动轨迹来教育机器人快速学习抓取技能。从计算机视觉和自然语言学习领域的成功经验中，我们认为，为了高效地学习，机器人必须能够利用互联网规模的人类视频数据。人类在与世界交互中有很多有趣的方式，这些方式可以帮助机器人不仅构建有用的动作和可用性的理解，还可以了解这些动作如何影响世界进行抓取。我们的方法是建立基于视觉可用性学习的人类行为空间，并在这个空间中训练一个世界模型。我们在人类视频上进行了训练，并在少量机器人互动数据上进行了精度调整。我们显示，这种可用性空间世界模型的方法可以让不同的机器人在复杂的设置下快速学习多种抓取技能，仅用30分钟的互动。视频可以在https://human-world-model.github.io找到。
</details></li>
</ul>
<hr>
<h2 id="TADA-Text-to-Animatable-Digital-Avatars"><a href="#TADA-Text-to-Animatable-Digital-Avatars" class="headerlink" title="TADA! Text to Animatable Digital Avatars"></a>TADA! Text to Animatable Digital Avatars</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10899">http://arxiv.org/abs/2308.10899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TingtingLiao/TADA">https://github.com/TingtingLiao/TADA</a></li>
<li>paper_authors: Tingting Liao, Hongwei Yi, Yuliang Xiu, Jiaxaing Tang, Yangyi Huang, Justus Thies, Michael J. Black</li>
<li>For: The paper aims to generate high-quality 3D avatars from textual descriptions, with realistic animations and detailed geometry.* Methods: The approach uses a 2D diffusion model and an animatable parametric body model, along with hierarchical rendering and score distillation sampling (SDS) to create detailed 3D avatars from text.* Results: The paper demonstrates that TADA significantly surpasses existing approaches on both qualitative and quantitative measures, enabling the creation of large-scale digital character assets that are ready for animation and rendering, and are easily editable through natural language.<details>
<summary>Abstract</summary>
We introduce TADA, a simple-yet-effective approach that takes textual descriptions and produces expressive 3D avatars with high-quality geometry and lifelike textures, that can be animated and rendered with traditional graphics pipelines. Existing text-based character generation methods are limited in terms of geometry and texture quality, and cannot be realistically animated due to inconsistent alignment between the geometry and the texture, particularly in the face region. To overcome these limitations, TADA leverages the synergy of a 2D diffusion model and an animatable parametric body model. Specifically, we derive an optimizable high-resolution body model from SMPL-X with 3D displacements and a texture map, and use hierarchical rendering with score distillation sampling (SDS) to create high-quality, detailed, holistic 3D avatars from text. To ensure alignment between the geometry and texture, we render normals and RGB images of the generated character and exploit their latent embeddings in the SDS training process. We further introduce various expression parameters to deform the generated character during training, ensuring that the semantics of our generated character remain consistent with the original SMPL-X model, resulting in an animatable character. Comprehensive evaluations demonstrate that TADA significantly surpasses existing approaches on both qualitative and quantitative measures. TADA enables creation of large-scale digital character assets that are ready for animation and rendering, while also being easily editable through natural language. The code will be public for research purposes.
</details>
<details>
<summary>摘要</summary>
我们介绍TADA，一个简单又有效的方法，将文本描述转换为高品质的3D人物模型，包括高级的几何和生命力的纹理，可以通过传统的グラフィックス管线进行动画和渲染。现有的文本基于的人物生成方法受到几何和纹理质量的限制，并且无法真实地动画，因为几何和纹理之间的对齐不稳定，尤其是在脸部区域。为了突破这些限制，TADA利用了2D传播模型和可动的 Parametric Body Model。具体来说，我们从SMPL-X中 derivated一个可优化的高分辨率人体模型，包括3D偏移和纹理图像，并使用层次渲染和分析抽象 Sampling (SDS) 创建高品质、细节满怀的3D人物。为了保证几何和纹理之间的对齐，我们在SDS训练过程中使用 render 的 норма和 RGB 图像，并利用它们的隐藏嵌入来稳定训练。此外，我们还引入了多种表情参数，以使得生成的人物在训练过程中具有表情，以保持与原始 SMPL-X 模型的 semantics 一致，使得生成的人物可以被动画。我们的评估结果显示，TADA 在 both 质量和量化度上有所提高，与现有的方法相比。TADA 可以实现大规模的数码人物资产的创建，并且可以通过自然语言进行易于修改。我们将代码公开供研究用途。
</details></li>
</ul>
<hr>
<h2 id="Giraffe-Adventures-in-Expanding-Context-Lengths-in-LLMs"><a href="#Giraffe-Adventures-in-Expanding-Context-Lengths-in-LLMs" class="headerlink" title="Giraffe: Adventures in Expanding Context Lengths in LLMs"></a>Giraffe: Adventures in Expanding Context Lengths in LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10882">http://arxiv.org/abs/2308.10882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abacusai/long-context">https://github.com/abacusai/long-context</a></li>
<li>paper_authors: Arka Pal, Deep Karkhanis, Manley Roberts, Samuel Dooley, Arvind Sundararajan, Siddartha Naidu</li>
<li>for: 这个论文主要用于探讨现代大型自然语言处理器（LLMs）如何在评估时处理长输入序列。</li>
<li>methods: 该论文使用现有的context length extrapolation方法，包括修改 pozitional encoding 系统以指示输入序列中token或活动的位置。并 introduce some new design,如修改基于position encoding的减少策略。</li>
<li>results: 该论文通过三个新的评估任务（FreeFormQA、AlteredNumericQA和LongChat-Lines）以及折减指标来测试这些方法。发现线性扩展是最佳的扩展方法，并示出可以通过使用更长的扩展级别在评估时获得更好的性能。同时，发现修改基于position encoding的减少策略也有扩展能力。基于这些结果，该论文释放了三个新的13B参数长Context模型，即4k和16k context模型从基础LLaMA-13B中训练，以及32k context模型从基础LLaMA2-13B中训练。同时还释放了 reproduce 结果的代码。<details>
<summary>Abstract</summary>
Modern large language models (LLMs) that rely on attention mechanisms are typically trained with fixed context lengths which enforce upper limits on the length of input sequences that they can handle at evaluation time. To use these models on sequences longer than the train-time context length, one might employ techniques from the growing family of context length extrapolation methods -- most of which focus on modifying the system of positional encodings used in the attention mechanism to indicate where tokens or activations are located in the input sequence. We conduct a wide survey of existing methods of context length extrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own design as well -- in particular, a new truncation strategy for modifying the basis for the position encoding.   We test these methods using three new evaluation tasks (FreeFormQA, AlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to be less fine-grained as a measure of long context performance of LLMs. We release the three tasks publicly as datasets on HuggingFace. We discover that linear scaling is the best method for extending context length, and show that further gains can be achieved by using longer scales at evaluation time. We also discover promising extrapolation capabilities in the truncated basis. To support further research in this area, we release three new 13B parameter long-context models which we call Giraffe: 4k and 16k context models trained from base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We also release the code to replicate our results.
</details>
<details>
<summary>摘要</summary>
现代大语言模型（LLM）通常通过注意机制训练，但是它们的评估时间上下文长度是固定的，这限制了它们可以处理的输入序列长度。为了使这些模型处理 longer than train-time context length 的序列，可以使用Context length extrapolation方法。我们对现有的方法进行了广泛的survey，并介绍了一些我们自己的设计，包括一种新的截断策略 для修改基于位置编码的系统。我们使用三个新的评估任务（FreeFormQA、AlteredNumericQA和LongChat-Lines）以及折叠指标来测试这些方法。我们发现线性扩展是最佳的扩展方法，并且可以通过使用更长的扩展级别来进一步提高性能。此外，我们发现 truncated basis 具有扩展的潜在能力。为支持进一步的研究，我们释放了三个13B参数的长 context模型，即4k和16k上下文模型从基础 LLMA-13B 开始，以及32k上下文模型从基础 LLMA2-13B 开始。我们还释放了复制我们结果的代码。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space"><a href="#Analyzing-Transformer-Dynamics-as-Movement-through-Embedding-Space" class="headerlink" title="Analyzing Transformer Dynamics as Movement through Embedding Space"></a>Analyzing Transformer Dynamics as Movement through Embedding Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10874">http://arxiv.org/abs/2308.10874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumeet S. Singh</li>
<li>for: This paper explores the underlying mechanics of Transformer language models and how they give rise to intelligent behaviors.</li>
<li>methods: The authors use a systems approach to analyze Transformers and develop a mathematical framework that views the models as movement through embedding space.</li>
<li>results: The paper reveals important insights into the emergence of intelligence in Transformers, including the idea that the models are essentially “Embedding Space walkers” that compose context into a single vector, and that attention plays a key role in associating vectors and influencing the organization of the embedding space. Additionally, the authors find some evidence for their semantic space theory, which posits that embedding vectors represent semantic concepts.<details>
<summary>Abstract</summary>
Transformer language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. We adopt a systems approach to analyze Transformers in detail and develop a mathematical framework that frames their dynamics as movement through embedding space. This novel perspective provides a principled way of thinking about the problem and reveals important insights related to the emergence of intelligence:   1. At its core the Transformer is a Embedding Space walker, mapping intelligent behavior to trajectories in this vector space.   2. At each step of the walk, it composes context into a single composite vector whose location in Embedding Space defines the next step.   3. No learning actually occurs during decoding; in-context learning and generalization are simply the result of different contexts composing into different vectors.   4. Ultimately the knowledge, intelligence and skills exhibited by the model are embodied in the organization of vectors in Embedding Space rather than in specific neurons or layers. These abilities are properties of this organization.   5. Attention's contribution boils down to the association-bias it lends to vector composition and which influences the aforementioned organization. However, more investigation is needed to ascertain its significance.   6. The entire model is composed from two principal operations: data independent filtering and data dependent aggregation. This generalization unifies Transformers with other sequence models and across modalities.   Building upon this foundation we formalize and test a semantic space theory which posits that embedding vectors represent semantic concepts and find some evidence of its validity.
</details>
<details>
<summary>摘要</summary>
吸收器语言模型展示出智能行为，如理解自然语言、识别模式、获得知识、reasoning、规划、反思和使用工具。这篇论文探讨它们的基本机制如何产生智能行为。我们采用系统方法分析吸收器，并开发了一个数学框架来描述它们的动态。这种新的视角提供了一个原则性的方法来思考问题，并揭示了智能行为的出现的重要关键点：1. 吸收器的核心是Embedding Space漫步者，将智能行为映射到vector空间中的路径上。2. 在每一步中，吸收器将上下文融合成一个单一的复合向量，该向量在Embedding Space中的位置定义下一步的路径。3. 在解码过程中，没有实际学习发生，而是在不同上下文中的融合导致了不同的向量组合，从而实现了吸收器的智能行为。4. 吸收器的智能、智慧和技能都是Embedding Space中向量的组织方式所具有的，而不是特定的神经元或层。这些能力是这种组织的属性。5. 关注的贡献在向量组合中带来了关联偏好，影响了Embedding Space中向量的组织，但需要进一步的调查以确定其重要性。6. 整个模型由两种主要操作组成：数据独立的滤波和数据依赖的聚合。这种一致性将吸收器与其他序列模型和多种模式相连接。基于这个基础，我们正式提出了一种 semantics空间理论，即向量表示 semantic concepts，并发现了一些证据支持这一理论的有效性。
</details></li>
</ul>
<hr>
<h2 id="Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility"><a href="#Real-World-Time-Series-Benchmark-Datasets-with-Distribution-Shifts-Global-Crude-Oil-Price-and-Volatility" class="headerlink" title="Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility"></a>Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10846">http://arxiv.org/abs/2308.10846</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oilpricebenchmarks/COB">https://github.com/oilpricebenchmarks/COB</a></li>
<li>paper_authors: Pranay Pasula</li>
<li>for: 本研究的目的是提供task-labeled时间序列数据集，用于驱动 kontinual learning在金融领域的进步。</li>
<li>methods: 本研究使用了资产价格数据的变换，生成了volatility proxy，并使用了期望最大化（EM）算法来适应模型。</li>
<li>results: 研究发现，通过包含任务标签，四种 kontinual learning算法在多个预测时间 horizon 上表现出了 Universal 的改进。<details>
<summary>Abstract</summary>
The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accelerate research in handling distribution shifts in real-world data, especially due to the global importance of the assets considered. We've made the (1) raw price data, (2) task labels generated by our approach, (3) and code for our algorithm available at https://oilpricebenchmarks.github.io.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本为简化中文。<</SYS>>金融领域内存续ous task-标注时间序列 benchmark 的缺乏，阻碍了持续学习的进步。为了解决这一问题，我们提出了 COB，即 Crude Oil Benchmark 数据集。 COB 包含了30年的资产价格，其中 exhibit 显著的分布shift，并且根据这些分布shift 生成对应的任务（即 режи）标签。我们的贡献包括将资产价格数据转换为Volatility proxy，使用期望最大化（EM）方法进行适应，生成基于实际世界事件的contextual task标签，并将这些标签以及通用的算法公开发布。我们表明，包括这些任务标签在内的 continual learning 算法在多个预测时间 horizon 上 universally 提高了四种状态之际的表现。我们希望这些 benchmark 可以加速实际数据中的分布shift处理研究，特别是由于我们考虑的资产的全球重要性。我们在 <https://oilpricebenchmarks.github.io> 上提供了（1）原始价格数据，（2）由我们方法生成的任务标签，（3）以及代码。
</details></li>
</ul>
<hr>
<h2 id="Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection"><a href="#Neural-Networks-Optimizations-Against-Concept-and-Data-Drift-in-Malware-Detection" class="headerlink" title="Neural Networks Optimizations Against Concept and Data Drift in Malware Detection"></a>Neural Networks Optimizations Against Concept and Data Drift in Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10821">http://arxiv.org/abs/2308.10821</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Maillet, Benjamin Marais</li>
<li>for: 提高基eline neural network对概念飘移问题的处理能力</li>
<li>methods: Feature reduction和使用最新验证集训练，并提出了Drift-Resilient Binary Cross-Entropy损失函数</li>
<li>results: 对2020-2023年间 collected的新型恶意文件进行评估，提高了15.2%的恶意文件检测率 compared to baseline model<details>
<summary>Abstract</summary>
Despite the promising results of machine learning models in malware detection, they face the problem of concept drift due to malware constant evolution. This leads to a decline in performance over time, as the data distribution of the new files differs from the training one, requiring regular model update. In this work, we propose a model-agnostic protocol to improve a baseline neural network to handle with the drift problem. We show the importance of feature reduction and training with the most recent validation set possible, and propose a loss function named Drift-Resilient Binary Cross-Entropy, an improvement to the classical Binary Cross-Entropy more effective against drift. We train our model on the EMBER dataset (2018) and evaluate it on a dataset of recent malicious files, collected between 2020 and 2023. Our improved model shows promising results, detecting 15.2% more malware than a baseline model.
</details>
<details>
<summary>摘要</summary>
尽管机器学习模型在针对恶意软件检测方面表现出色，但它们面临着概念漂移问题，这是因为恶意软件不断演化，导致模型在时间上的性能下降。为了解决这个问题，我们提出了一种模型无关协议，用于改进基eline神经网络，以适应漂移问题。我们表明了减少特征和使用最新的验证集训练的重要性，并提出了一种名为“漂移抗性二进制十字积分”的损失函数，比 класси的二进制十字积分更有效地防止漂移。我们在EMBER数据集（2018）上训练了我们的模型，并在2020-2023年间收集的一个数据集上进行了评估。我们改进后的模型显示了出色的表现，能够检测到2018年训练集中的15.2%更多的恶意软件。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/cs.AI_2023_08_22/" data-id="cllt9prv8000bol882bz43g8e" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.CV_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.CV_2023_08_22/">cs.CV - 2023-08-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SwinFace-A-Multi-task-Transformer-for-Face-Recognition-Expression-Recognition-Age-Estimation-and-Attribute-Estimation"><a href="#SwinFace-A-Multi-task-Transformer-for-Face-Recognition-Expression-Recognition-Age-Estimation-and-Attribute-Estimation" class="headerlink" title="SwinFace: A Multi-task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation"></a>SwinFace: A Multi-task Transformer for Face Recognition, Expression Recognition, Age Estimation and Attribute Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11509">http://arxiv.org/abs/2308.11509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lxq1000/swinface">https://github.com/lxq1000/swinface</a></li>
<li>paper_authors: Lixiong Qin, Mei Wang, Chao Deng, Ke Wang, Xi Chen, Jiani Hu, Weihong Deng</li>
<li>for: 这个论文的目的是提出一种多功能的Face recognition和表情识别、年龄估计和面部特征估计（40个特征包括性别）的算法基于单个Swin Transformer。</li>
<li>methods: 该算法使用了一个共享背景和每个相关任务的子网络，并在每个任务特定分析子网络中实现了一种多级渠道注意力（MLCA）模块，以适应不同任务的冲突和需求。</li>
<li>results: 对于所有任务，提出的模型具有出色的表现，尤其是在RAF-DB和CLAP2015上达到了90.97%的准确率和0.22 $\epsilon$-的误差分别，这些结果在表情识别和年龄估计领域是状态的最佳结果。<details>
<summary>Abstract</summary>
In recent years, vision transformers have been introduced into face recognition and analysis and have achieved performance breakthroughs. However, most previous methods generally train a single model or an ensemble of models to perform the desired task, which ignores the synergy among different tasks and fails to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper presents a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, the SwinFace, consists of a single shared backbone together with a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and 0.22 $\epsilon$-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. The code and models will be made publicly available at https://github.com/lxq1000/SwinFace.
</details>
<details>
<summary>摘要</summary>
Recently, vision transformers have been applied to face recognition and analysis, achieving performance breakthroughs. However, most previous methods train a single model or an ensemble of models to perform the desired task, ignoring the synergy among different tasks and failing to achieve improved prediction accuracy, increased data efficiency, and reduced training time. This paper proposes a multi-purpose algorithm for simultaneous face recognition, facial expression recognition, age estimation, and face attribute estimation (40 attributes including gender) based on a single Swin Transformer. Our design, called SwinFace, consists of a single shared backbone and a subnet for each set of related tasks. To address the conflicts among multiple tasks and meet the different demands of tasks, a Multi-Level Channel Attention (MLCA) module is integrated into each task-specific analysis subnet, which can adaptively select the features from optimal levels and channels to perform the desired tasks. Extensive experiments show that the proposed model has a better understanding of the face and achieves excellent performance for all tasks. Especially, it achieves 90.97% accuracy on RAF-DB and 0.22 $\epsilon$-error on CLAP2015, which are state-of-the-art results on facial expression recognition and age estimation respectively. The code and models will be made publicly available at https://github.com/lxq1000/SwinFace.
</details></li>
</ul>
<hr>
<h2 id="LCCo-Lending-CLIP-to-Co-Segmentation"><a href="#LCCo-Lending-CLIP-to-Co-Segmentation" class="headerlink" title="LCCo: Lending CLIP to Co-Segmentation"></a>LCCo: Lending CLIP to Co-Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11506">http://arxiv.org/abs/2308.11506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Duan, Yan Yang, Liyuan Pan, Xiabi Liu</li>
<li>for: 本文研究了一种基于语言图像预训练框架(CLIP)的图像集合中的共同Semantic object划分方法。</li>
<li>methods: 该方法使用了一种基于CLIP的三个关键模块：一个图像集合特征匹配模块，一个CLIP交互模块，和一个CLIP规范模块。这些模块共同使用CLIP来提高图像划分精度。</li>
<li>results: 实验结果表明，该方法在四个标准图像划分 benchmark 数据集上的性能比前state-of-the-art方法高。<details>
<summary>Abstract</summary>
This paper studies co-segmenting the common semantic object in a set of images. Existing works either rely on carefully engineered networks to mine the implicit semantic information in visual features or require extra data (i.e., classification labels) for training. In this paper, we leverage the contrastive language-image pre-training framework (CLIP) for the task. With a backbone segmentation network that independently processes each image from the set, we introduce semantics from CLIP into the backbone features, refining them in a coarse-to-fine manner with three key modules: i) an image set feature correspondence module, encoding global consistent semantic information of the image set; ii) a CLIP interaction module, using CLIP-mined common semantics of the image set to refine the backbone feature; iii) a CLIP regularization module, drawing CLIP towards this co-segmentation task, identifying the best CLIP semantic and using it to regularize the backbone feature. Experiments on four standard co-segmentation benchmark datasets show that the performance of our method outperforms state-of-the-art methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Image set feature correspondence module: Encodes global consistent semantic information of the image set.2. CLIP interaction module: Uses CLIP-mined common semantics of the image set to refine the backbone feature.3. CLIP regularization module: Draws CLIP towards this co-segmentation task, identifying the best CLIP semantic and using it to regularize the backbone feature.Experiments on four standard co-segmentation benchmark datasets show that our method outperforms state-of-the-art methods.</details></li>
</ol>
<hr>
<h2 id="Learning-from-Semantic-Alignment-between-Unpaired-Multiviews-for-Egocentric-Video-Recognition"><a href="#Learning-from-Semantic-Alignment-between-Unpaired-Multiviews-for-Egocentric-Video-Recognition" class="headerlink" title="Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition"></a>Learning from Semantic Alignment between Unpaired Multiviews for Egocentric Video Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11489">http://arxiv.org/abs/2308.11489</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wqtwjt1996/sum-l">https://github.com/wqtwjt1996/sum-l</a></li>
<li>paper_authors: Qitong Wang, Long Zhao, Liangzhe Yuan, Ting Liu, Xi Peng</li>
<li>For: The paper aims to tackle the challenging problem of unpaired multiview video learning, where the model needs to learn comprehensive multiview representations while dealing with variations in cross-view semantic information.* Methods: The proposed method, called Semantics-based Unpaired Multiview Learning (SUM-L), builds cross-view pseudo-pairs and performs view-invariant alignment by leveraging the semantic information of videos. Additionally, video-text alignment is performed for first-person and third-person videos to improve video representations.* Results: The method is evaluated on multiple benchmark datasets and outperforms multiple existing view-alignment methods, demonstrating its effectiveness in improving video representations under a more challenging scenario than typical paired or unpaired multimodal or multiview learning.Here are the three key points in Simplified Chinese text:* For: 本文目的是解决无对视照视频学习的挑战问题，即学习多视图表示而处理视频cross-view semantic信息的变化。* Methods: 提出的方法是基于Semantics-based Unpaired Multiview Learning（SUM-L），建立cross-view Pseudo-pairs并实现视图不变的Alignment，通过利用视频semantic信息。此外，还进行了首人和第三人视频的文本对齐，以提高视频表示。* Results: 方法在多个benchmark dataset上进行了广泛的实验，并证明其在不同于 Typical paired或Unpaired multimodal或Multiview learning的场景下表现更高效。<details>
<summary>Abstract</summary>
We are concerned with a challenging scenario in unpaired multiview video learning. In this case, the model aims to learn comprehensive multiview representations while the cross-view semantic information exhibits variations. We propose Semantics-based Unpaired Multiview Learning (SUM-L) to tackle this unpaired multiview learning problem. The key idea is to build cross-view pseudo-pairs and do view-invariant alignment by leveraging the semantic information of videos. To facilitate the data efficiency of multiview learning, we further perform video-text alignment for first-person and third-person videos, to fully leverage the semantic knowledge to improve video representations. Extensive experiments on multiple benchmark datasets verify the effectiveness of our framework. Our method also outperforms multiple existing view-alignment methods, under the more challenging scenario than typical paired or unpaired multimodal or multiview learning. Our code is available at https://github.com/wqtwjt1996/SUM-L.
</details>
<details>
<summary>摘要</summary>
我们面临了一种复杂的无对视视频学习场景。在这种情况下，模型需要学习全面的无对视视频表示，而cross-view含义信息具有变化性。我们提议使用Semantics-based Unpaired Multiview Learning（SUM-L）解决这个无对视视频学习问题。关键思想是建立cross-view Pseudo-对和视图不变Alignment，通过利用视频含义信息来做这两个任务。为了提高多视图学习的数据效率，我们进一步进行了视频文本对齐，以全面利用视频含义知识来改善视频表示。我们的方法在多个benchmark数据集上进行了广泛的实验，并证明了我们的框架的效果。我们的方法还比多种现有的视图对齐方法高效，在更加复杂的场景下。我们的代码可以在https://github.com/wqtwjt1996/SUM-L中找到。
</details></li>
</ul>
<hr>
<h2 id="Opening-the-Vocabulary-of-Egocentric-Actions"><a href="#Opening-the-Vocabulary-of-Egocentric-Actions" class="headerlink" title="Opening the Vocabulary of Egocentric Actions"></a>Opening the Vocabulary of Egocentric Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11488">http://arxiv.org/abs/2308.11488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dibyadip Chatterjee, Fadime Sener, Shugao Ma, Angela Yao</li>
<li>for: 本文旨在提出一种开放词汇动作识别任务，能够扩展 Verb 到一个开放词汇的动作中，同时处理已知和未知的对象。</li>
<li>methods: 本文提出了一种嵌入 CLIP 表示的提示来预测开放词汇中的交互对象，并使用一个对象agnostic verb encoder 来预测verb。</li>
<li>results: 对于 EPIC-KITCHENS-100 和 Assembly101  datasets，本文创建了一些开放词汇的benchmark，而关闭动作方法无法泛化，而我们的提议方法却效果很好，同时，我们的对象Encoder 也比既有的开放词汇视觉识别方法更高效。<details>
<summary>Abstract</summary>
Human actions in egocentric videos are often hand-object interactions composed from a verb (performed by the hand) applied to an object. Despite their extensive scaling up, egocentric datasets still face two limitations - sparsity of action compositions and a closed set of interacting objects. This paper proposes a novel open vocabulary action recognition task. Given a set of verbs and objects observed during training, the goal is to generalize the verbs to an open vocabulary of actions with seen and novel objects. To this end, we decouple the verb and object predictions via an object-agnostic verb encoder and a prompt-based object encoder. The prompting leverages CLIP representations to predict an open vocabulary of interacting objects. We create open vocabulary benchmarks on the EPIC-KITCHENS-100 and Assembly101 datasets; whereas closed-action methods fail to generalize, our proposed method is effective. In addition, our object encoder significantly outperforms existing open-vocabulary visual recognition methods in recognizing novel interacting objects.
</details>
<details>
<summary>摘要</summary>
人类行为在 egocentric 视频中经常是手部-物体互动，由 verb（由手部执行的动作）和物体组成。尽管这些数据集已经大量扩大，但是它们仍然面临两个限制：动作组合稀缺和固定的交互物体集。本文提出了一个开放词汇动作认知任务。给定一组 verb 和在训练中观察到的物体，目标是将 verb 扩展到一个开放词汇的动作中，包括已知和新的交互物体。为此，我们分离 verb 和物体预测，使用 объекc-agnostic verb 编码器和提示基于 CLIP 表示来预测开放词汇的交互物体。我们创建了开放词汇 benchmark 在 EPIC-KITCHENS-100 和 Assembly101 数据集上，而封闭动作方法无法泛化，我们提posed 方法是有效的。此外，我们的物体编码器在认识新交互物体方面表现出色，大大超过了现有的开放词汇视觉认知方法。
</details></li>
</ul>
<hr>
<h2 id="Free-Lunch-for-Gait-Recognition-A-Novel-Relation-Descriptor"><a href="#Free-Lunch-for-Gait-Recognition-A-Novel-Relation-Descriptor" class="headerlink" title="Free Lunch for Gait Recognition: A Novel Relation Descriptor"></a>Free Lunch for Gait Recognition: A Novel Relation Descriptor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11487">http://arxiv.org/abs/2308.11487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jilong Wang, Saihui Hou, Yan Huang, Chunshui Cao, Xu Liu, Yongzhen Huang, Liang Wang</li>
<li>For: This paper focuses on improving gait recognition performance by reconsidering gait representation and emphasizing inter-personal relationships among different subjects’ gait features.* Methods: The proposed method, called Relationship Descriptor (RD), uses reference-anchored gaits to describe each person’s gait and emphasizes meaningful features by normalizing the dot product between gait features and classifier weights. To address the dimensionality challenges, the method proposes a Farthest Anchored gaits Selection algorithm and a dimension reduction method.* Results: The proposed method achieves higher recognition performance than directly using extracted features and consistently outperforms the baselines on four popular gait recognition datasets (GREW, Gait3D, CASIA-B, and OU-MVLP), achieving state-of-the-art performances.Here’s the simplified Chinese text:* For: 本研究目的是提高步行识别性能，重新评估步行表示方式，强调不同人群之间的步行特征关系。* Methods: 提出的方法是关系描述符（RD），使用参照锚定的步行特征来描述每个人的步行，强调意义更高的特征，通过归一化点积分来表示每个测试样本与每个训练ID的步行原型之间的相似性。* Results: 比较直接使用提取的特征，关系描述符可以提高步行识别性能，在四个流行的步行识别数据集（GREW、Gait3D、CASIA-B、OU-MVLP）上表现出state-of-the-art的性能。<details>
<summary>Abstract</summary>
Gait recognition is to seek correct matches for query individuals by their unique walking patterns at a long distance. However, current methods focus solely on individual gait features, disregarding inter-personal relationships. In this paper, we reconsider gait representation, asserting that gait is not just an aggregation of individual features, but also the relationships among different subjects' gait features once reference gaits are established. From this perspective, we redefine classifier weights as reference-anchored gaits, allowing each person's gait to be described by their relationship with these references. In our work, we call this novel descriptor Relationship Descriptor (RD). This Relationship Descriptor offers two benefits: emphasizing meaningful features and enhancing robustness. To be specific, The normalized dot product between gait features and classifier weights signifies a similarity relation, where each dimension indicates the similarity between the test sample and each training ID's gait prototype, respectively. Despite its potential, the direct use of relationship descriptors poses dimensionality challenges since the dimension of RD depends on the training set's identity count. To address this, we propose a Farthest Anchored gaits Selection algorithm and a dimension reduction method to boost gait recognition performance. Our method can be built on top of off-the-shelf pre-trained classification-based models without extra parameters. We show that RD achieves higher recognition performance than directly using extracted features. We evaluate the effectiveness of our method on the popular GREW, Gait3D, CASIA-B, and OU-MVLP, showing that our method consistently outperforms the baselines and achieves state-of-the-art performances.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translation_direction: zh-CNGait recognition是寻找正确的匹配个体的唯一步态特征，但现有方法强调个体特征，忽略了人之间的关系。在这篇论文中，我们重新定义步态表示，认为步态不仅是个体特征的汇集，还包括不同个体之间的关系。从这个视角，我们定义了一种新的描述符called Relationship Descriptor (RD)。这个描述符有两个优点：强调意义性特征和增强稳定性。具体来说，在测试样本和训练ID之间的标准化点积分比率表示两个样本之间的相似性关系，每个维度表示测试样本与每个训练ID的步态原型之间的相似性。虽有潜在的优势，直接使用关系描述符存在维度挑战，因为关系描述符的维度取决于训练集中个体数量。为解决这个问题，我们提出了最远锚定 gaits 选择算法和维度减少方法，以提高步态识别性能。我们的方法可以在现有的预训练分类模型基础上建立，无需添加参数。我们证明，RD 可以高于直接使用提取的特征来实现更高的识别性能。我们对广泛使用的 GREW、Gait3D、CASIA-B 和 OU-MVLP 进行评估，并证明我们的方法可以一直达到领先水平。Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Composed-Image-Retrieval-using-Contrastive-Learning-and-Task-oriented-CLIP-based-Features"><a href="#Composed-Image-Retrieval-using-Contrastive-Learning-and-Task-oriented-CLIP-based-Features" class="headerlink" title="Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features"></a>Composed Image Retrieval using Contrastive Learning and Task-oriented CLIP-based Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11485">http://arxiv.org/abs/2308.11485</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ABaldrati/CLIP4Cir">https://github.com/ABaldrati/CLIP4Cir</a></li>
<li>paper_authors: Alberto Baldrati, Marco Bertini, Tiberio Uricchio, Alberto del Bimbo</li>
<li>for: 本研究的目的是寻找基于referenced图像和相关的caption的compose image retrieval，即检索图像具有与referenced图像相同的视觉特征并满足caption中的修改。</li>
<li>methods: 本研究使用OpenAI CLIP模型的特征进行任务调整和组合，并使用对比学习进行训练。首先，通过任务特有的方式进行CLIP encoder的任务调整，然后在第二个阶段使用Combiner网络将图像和文本特征相结合，提供了组合特征进行检索。</li>
<li>results: 实验结果表明，基于CLIP特征的任务调整和Combiner网络对于FashionIQ和CIRR两个Popular和挑战性的compose image retrieval dataset具有高效性，并且超过了更复杂的现有方法。<details>
<summary>Abstract</summary>
Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Given that recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir
</details>
<details>
<summary>摘要</summary>
Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, so we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir.Here's the translation in Traditional Chinese: Given a query composed of a reference image and a relative caption, the Composed Image Retrieval goal is to retrieve images visually similar to the reference one that integrates the modifications expressed by the caption. Recent research has demonstrated the efficacy of large-scale vision and language pre-trained (VLP) models in various tasks, so we rely on features from the OpenAI CLIP model to tackle the considered task. We initially perform a task-oriented fine-tuning of both CLIP encoders using the element-wise sum of visual and textual features. Then, in the second stage, we train a Combiner network that learns to combine the image-text features integrating the bimodal information and providing combined features used to perform the retrieval. We use contrastive learning in both stages of training. Starting from the bare CLIP features as a baseline, experimental results show that the task-oriented fine-tuning and the carefully crafted Combiner network are highly effective and outperform more complex state-of-the-art approaches on FashionIQ and CIRR, two popular and challenging datasets for composed image retrieval. Code and pre-trained models are available at https://github.com/ABaldrati/CLIP4Cir.
</details></li>
</ul>
<hr>
<h2 id="Pose2Gait-Extracting-Gait-Features-from-Monocular-Video-of-Individuals-with-Dementia"><a href="#Pose2Gait-Extracting-Gait-Features-from-Monocular-Video-of-Individuals-with-Dementia" class="headerlink" title="Pose2Gait: Extracting Gait Features from Monocular Video of Individuals with Dementia"></a>Pose2Gait: Extracting Gait Features from Monocular Video of Individuals with Dementia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11484">http://arxiv.org/abs/2308.11484</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taatiteam/pose2gait_public">https://github.com/taatiteam/pose2gait_public</a></li>
<li>paper_authors: Caroline Malin-Mayor, Vida Adeli, Andrea Sabo, Sergey Noritsyn, Carolina Gorodetsky, Alfonso Fasano, Andrea Iaboni, Babak Taati</li>
<li>for: 这项研究旨在通过视频监测 older adults with dementia 的步态，早期发现健康状况下降，以防止跌倒或入院。</li>
<li>methods: 该研究使用了计算机视觉基于pose tracking模型来自动处理视频数据，并提取了人体 JOINT 位置。</li>
<li>results: 该模型能够从视频中提取步态特征，并与深度摄像头中的特征相比，Spearman 相关系数为。83和.60。这表明，三维空间时间特征可以从单一视频中预测。<details>
<summary>Abstract</summary>
Video-based ambient monitoring of gait for older adults with dementia has the potential to detect negative changes in health and allow clinicians and caregivers to intervene early to prevent falls or hospitalizations. Computer vision-based pose tracking models can process video data automatically and extract joint locations; however, publicly available models are not optimized for gait analysis on older adults or clinical populations. In this work we train a deep neural network to map from a two dimensional pose sequence, extracted from a video of an individual walking down a hallway toward a wall-mounted camera, to a set of three-dimensional spatiotemporal gait features averaged over the walking sequence. The data of individuals with dementia used in this work was captured at two sites using a wall-mounted system to collect the video and depth information used to train and evaluate our model. Our Pose2Gait model is able to extract velocity and step length values from the video that are correlated with the features from the depth camera, with Spearman's correlation coefficients of .83 and .60 respectively, showing that three dimensional spatiotemporal features can be predicted from monocular video. Future work remains to improve the accuracy of other features, such as step time and step width, and test the utility of the predicted values for detecting meaningful changes in gait during longitudinal ambient monitoring.
</details>
<details>
<summary>摘要</summary>
视频基于环境监测 older adults 的步态有潜力检测身体健康状况下降，并允许临床专业人员和照顾者在早期发现并预防滥落或入院。通过计算机视觉技术，可自动处理视频数据，并提取关节位置。然而，目前公共可用的模型并没有适应老年人或临床人群的步态分析。在这项工作中，我们训练了深度神经网络，将二维姿态序列，从视频中捕捉到人走向墙面镜头的人走动捕捉到三维空间时间步态特征的映射。我们的 Pose2Gait 模型可以从视频中提取速度和步长值，与深度相机中的特征相关性 coefficient 为 0.83 和 0.60，表明可以从单视频中预测三维空间时间步态特征。未来的工作是提高其他特征的准确性，如步时和步宽，并测试预测值的检测意义步长监测。
</details></li>
</ul>
<hr>
<h2 id="VadCLIP-Adapting-Vision-Language-Models-for-Weakly-Supervised-Video-Anomaly-Detection"><a href="#VadCLIP-Adapting-Vision-Language-Models-for-Weakly-Supervised-Video-Anomaly-Detection" class="headerlink" title="VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection"></a>VadCLIP: Adapting Vision-Language Models for Weakly Supervised Video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11681">http://arxiv.org/abs/2308.11681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wu, Xuerong Zhou, Guansong Pang, Lingru Zhou, Qingsen Yan, Peng Wang, Yanning Zhang</li>
<li>for: 这个研究的目的是提出一个新的弱监督类别 видео异常探测（WSVAD）方法，并将CLIP模型 directly applied to WSVAD任务。</li>
<li>methods: 这个方法使用了CLIP模型的冻结版本，不需要进行预训练。它还包括一个双支路径，其中一支使用了视觉特征进行粗糙分类，另一支则全面利用语言-图像Alignment。</li>
<li>results: 实验结果显示，VadCLIP在两个常用的标准集上（XD-Violence和UCF-Crime）都达到了最高性能，比前一代方法高度超越。具体来说，VadCLIP在XD-Violence上 achieve 84.51% AP和88.02% AUC，在UCF-Crime上 achieve 84.51% AP和88.02% AUC。<details>
<summary>Abstract</summary>
The recent contrastive language-image pre-training (CLIP) model has shown great success in a wide range of image-level tasks, revealing remarkable ability for learning powerful visual representations with rich semantics. An open and worthwhile problem is efficiently adapting such a strong model to the video domain and designing a robust video anomaly detector. In this work, we propose VadCLIP, a new paradigm for weakly supervised video anomaly detection (WSVAD) by leveraging the frozen CLIP model directly without any pre-training and fine-tuning process. Unlike current works that directly feed extracted features into the weakly supervised classifier for frame-level binary classification, VadCLIP makes full use of fine-grained associations between vision and language on the strength of CLIP and involves dual branch. One branch simply utilizes visual features for coarse-grained binary classification, while the other fully leverages the fine-grained language-image alignment. With the benefit of dual branch, VadCLIP achieves both coarse-grained and fine-grained video anomaly detection by transferring pre-trained knowledge from CLIP to WSVAD task. We conduct extensive experiments on two commonly-used benchmarks, demonstrating that VadCLIP achieves the best performance on both coarse-grained and fine-grained WSVAD, surpassing the state-of-the-art methods by a large margin. Specifically, VadCLIP achieves 84.51% AP and 88.02% AUC on XD-Violence and UCF-Crime, respectively. Code and features will be released to facilitate future VAD research.
</details>
<details>
<summary>摘要</summary>
Recent contrastive language-image pre-training (CLIP) 模型已经在各种图像任务中显示出惊人的成功，揭示出了强大的视觉表示和丰富的 semantics。一个值得关注的问题是如何有效地适应这种强大模型到视频领域，并设计一个强健的视频异常检测器。在这种工作中，我们提出了VadCLIP，一种新的弱相关视频异常检测（WSVAD）方法，利用直接使用冻结CLIP模型，而不需要任何预训练和调整过程。与当前工作不同，VadCLIP不直接将提取的特征 fed into 弱相关分类器进行帧级二分类，而是利用CLIP模型的细腻语义关系，在两个分支中进行检测。一个分支使用视觉特征进行粗略二分类，另一个分支完全利用语义-图像对齐来进行细腻异常检测。通过两个分支的合作，VadCLIP可以将CLIP模型的预训练知识传递到WSVAD任务中，从而实现粗略和细腻的视频异常检测。我们进行了广泛的实验，证明VadCLIP在XD-Violence和UCF-Crime上的表现均高于当前最佳方法，具体来说是84.51% AP和88.02% AUC。代码和特征将会被发布，以便未来的VAD研究。
</details></li>
</ul>
<hr>
<h2 id="Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms"><a href="#Multitemporal-analysis-in-Google-Earth-Engine-for-detecting-urban-changes-using-optical-data-and-machine-learning-algorithms" class="headerlink" title="Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms"></a>Multitemporal analysis in Google Earth Engine for detecting urban changes using optical data and machine learning algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11468">http://arxiv.org/abs/2308.11468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariapia Rita Iandolo, Francesca Razzano, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 这个研究旨在使用Google Earth Engine（GEE）平台进行多时间分析，检测城市区域的变化 using 光学数据和专门的机器学习（ML）算法。</li>
<li>methods: 这个研究使用了GEE平台和光学数据，以及专门的ML算法进行分类和变化检测分析。</li>
<li>results: 结果表明，提posed方法可以准确地标识 changed和unchanged的城市区域在选定的时间段内。此外，这个研究也证明了GEE的云存储平台对处理大量卫星数据的管理有所重要性。<details>
<summary>Abstract</summary>
The aim of this work is to perform a multitemporal analysis using the Google Earth Engine (GEE) platform for the detection of changes in urban areas using optical data and specific machine learning (ML) algorithms. As a case study, Cairo City has been identified, in Egypt country, as one of the five most populous megacities of the last decade in the world. Classification and change detection analysis of the region of interest (ROI) have been carried out from July 2013 to July 2021. Results demonstrate the validity of the proposed method in identifying changed and unchanged urban areas over the selected period. Furthermore, this work aims to evidence the growing significance of GEE as an efficient cloud-based solution for managing large quantities of satellite data.
</details>
<details>
<summary>摘要</summary>
本工作的目的是使用Google Earth Engine（GEE）平台进行多时间分析，以探测城市区域的变化使用光学数据和专门的机器学习（ML）算法。作为案例研究，埃及国的开罗城市被选为世界上最后一个十年内最为人口稠密的五大都市之一。从2013年7月至2021年7月的时间段进行了区域 интерес（ROI）的分类和变化检测分析。结果表明提出的方法的有效性，可以准确地标识变化和不变的城市区域在选定的时间段内。此外，这项工作还旨在证明GEE作为云端解决方案，对处理巨量卫星数据的管理有着高效的能力。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning"><a href="#An-Analysis-of-Initial-Training-Strategies-for-Exemplar-Free-Class-Incremental-Learning" class="headerlink" title="An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning"></a>An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11677">http://arxiv.org/abs/2308.11677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grégoire Petit, Michael Soumm, Eva Feillet, Adrian Popescu, Bertrand Delezoide, David Picard, Céline Hudelot</li>
<li>for: 这个论文的目的是探讨分类模型在数据流中建立的增量学习问题。</li>
<li>methods: 论文使用的方法包括增量学习过程中的新类 интеграción、采用先前学习的模型初始化、选择合适的增量学习算法和评估增量学习模型的性能等。</li>
<li>results: 论文的主要发现是初始学习策略对增量准确率的影响是最大的，但是选择合适的增量学习算法更重要地防止忘记。根据这些发现，论文提出了实践增量学习的实用建议。<details>
<summary>Abstract</summary>
Class-Incremental Learning (CIL) aims to build classification models from data streams. At each step of the CIL process, new classes must be integrated into the model. Due to catastrophic forgetting, CIL is particularly challenging when examples from past classes cannot be stored, the case on which we focus here. To date, most approaches are based exclusively on the target dataset of the CIL process. However, the use of models pre-trained in a self-supervised way on large amounts of data has recently gained momentum. The initial model of the CIL process may only use the first batch of the target dataset, or also use pre-trained weights obtained on an auxiliary dataset. The choice between these two initial learning strategies can significantly influence the performance of the incremental learning model, but has not yet been studied in depth. Performance is also influenced by the choice of the CIL algorithm, the neural architecture, the nature of the target task, the distribution of classes in the stream and the number of examples available for learning. We conduct a comprehensive experimental study to assess the roles of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing the average incremental accuracy, but that the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations are intended to facilitate the practical deployment of incremental learning.
</details>
<details>
<summary>摘要</summary>
We conduct a comprehensive study to assess the influence of these factors. We present a statistical analysis framework that quantifies the relative contribution of each factor to incremental performance. Our main finding is that the initial training strategy is the dominant factor influencing average incremental accuracy, but the choice of CIL algorithm is more important in preventing forgetting. Based on this analysis, we propose practical recommendations for choosing the right initial training strategy for a given incremental learning use case. These recommendations aim to facilitate the practical deployment of incremental learning.
</details></li>
</ul>
<hr>
<h2 id="Food-Image-Classification-and-Segmentation-with-Attention-based-Multiple-Instance-Learning"><a href="#Food-Image-Classification-and-Segmentation-with-Attention-based-Multiple-Instance-Learning" class="headerlink" title="Food Image Classification and Segmentation with Attention-based Multiple Instance Learning"></a>Food Image Classification and Segmentation with Attention-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11452">http://arxiv.org/abs/2308.11452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valasia Vlachopoulou, Ioannis Sarafis, Alexandros Papadopoulos<br>for:* 这个论文是为了解决食物量计量问题而写的，它适用于食物监测应用场景。methods:* 这篇论文使用了弱监视学习方法，不需要像素级别的标注数据来训练食物图像分类和Semantic Segmentation模型。* 该方法基于多例学习approach，并使用了注意力机制来自动生成食物类划分图像。results:* 在FoodSeg103数据集上进行了实验，并证明了提议的方法的可行性和注意力机制的作用。<details>
<summary>Abstract</summary>
The demand for accurate food quantification has increased in the recent years, driven by the needs of applications in dietary monitoring. At the same time, computer vision approaches have exhibited great potential in automating tasks within the food domain. Traditionally, the development of machine learning models for these problems relies on training data sets with pixel-level class annotations. However, this approach introduces challenges arising from data collection and ground truth generation that quickly become costly and error-prone since they must be performed in multiple settings and for thousands of classes. To overcome these challenges, the paper presents a weakly supervised methodology for training food image classification and semantic segmentation models without relying on pixel-level annotations. The proposed methodology is based on a multiple instance learning approach in combination with an attention-based mechanism. At test time, the models are used for classification and, concurrently, the attention mechanism generates semantic heat maps which are used for food class segmentation. In the paper, we conduct experiments on two meta-classes within the FoodSeg103 data set to verify the feasibility of the proposed approach and we explore the functioning properties of the attention mechanism.
</details>
<details>
<summary>摘要</summary>
随着食物质量评估的需求增加，计算机视觉方法在食物领域中表现出了很大的潜力。然而，传统的机器学习模型开发方法仍然需要带有像素级别的分类注释。然而，这种方法会导致数据收集和真实性生成的挑战，这些挑战会在多个设置下并且对 тысячи个类型进行多次重复。为了缓解这些挑战，文章提出了一种弱型监督的方法，不需要像素级别的注释来训练食物图像分类和 semantic segmentation 模型。该方法基于多例学习approach和注意力机制。在测试时，模型用于分类，同时注意力机制生成 semantic heat map，用于食物类划分。在文章中，我们对 FoodSeg103 数据集中的两个元类进行了实验，以验证提议的可行性，并探索注意力机制的工作性质。
</details></li>
</ul>
<hr>
<h2 id="Towards-Discriminative-Representations-with-Contrastive-Instances-for-Real-Time-UAV-Tracking"><a href="#Towards-Discriminative-Representations-with-Contrastive-Instances-for-Real-Time-UAV-Tracking" class="headerlink" title="Towards Discriminative Representations with Contrastive Instances for Real-Time UAV Tracking"></a>Towards Discriminative Representations with Contrastive Instances for Real-Time UAV Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11450">http://arxiv.org/abs/2308.11450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zeng, Mingliang Zou, Xucheng Wang, Shuiwang Li</li>
<li>for: 提高UAV跟踪中的精准率和效率，这两个基本挑战是由于计算资源限制、电池容量和UAV最大荷载所带来的。</li>
<li>methods: 使用异构相关矩阵（DCF）基于的跟踪器可以在单个CPU上实现高效性，但是精准率较差。具有轻量级深度学习（DL）基于的跟踪器可以实现精准率和效率的平衡，但是性能增加受压缩率的限制。</li>
<li>results: 根据四个UAV标准测试集（UAV123@10fps、DTB70、UAVDT和VisDrone2018）的广泛实验结果，提出的DRCI跟踪器在对state-of-the-art UAV跟踪方法进行比较时表现出了显著的优势。<details>
<summary>Abstract</summary>
Maintaining high efficiency and high precision are two fundamental challenges in UAV tracking due to the constraints of computing resources, battery capacity, and UAV maximum load. Discriminative correlation filters (DCF)-based trackers can yield high efficiency on a single CPU but with inferior precision. Lightweight Deep learning (DL)-based trackers can achieve a good balance between efficiency and precision but performance gains are limited by the compression rate. High compression rate often leads to poor discriminative representations. To this end, this paper aims to enhance the discriminative power of feature representations from a new feature-learning perspective. Specifically, we attempt to learn more disciminative representations with contrastive instances for UAV tracking in a simple yet effective manner, which not only requires no manual annotations but also allows for developing and deploying a lightweight model. We are the first to explore contrastive learning for UAV tracking. Extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that the proposed DRCI tracker significantly outperforms state-of-the-art UAV tracking methods.
</details>
<details>
<summary>摘要</summary>
维护高效率和高精度是无人机追踪中的两个基本挑战，因为计算资源、电池容量和无人机的最大负载对紧。对应式相关滤波器（DCF）基本trackers可以在单一CPU上提供高效率，但是精度较差。轻量级深度学习（DL）基本trackers可以实现高效率和精度的平衡，但是性能增加受压缩率的限制。高压缩率通常会导致糟糕的描述表现。因此，本文的目标是将无人机追踪中的特征表现强化，以提高追踪精度。具体来说，我们尝试通过新的特征学习角度，从而学习更有弹性的特征表现，这不仅不需要手动标注，而且允许开发和部署轻量级模型。我们是无人机追踪中首次应用对照学习。实验结果显示，提案的DRCI tracker在四个无人机测试 benchmark 上具有明显的 superiority，包括UAV123@10fps、DTB70、UAVDT和VisDrone2018。
</details></li>
</ul>
<hr>
<h2 id="Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding"><a href="#Masked-Momentum-Contrastive-Learning-for-Zero-shot-Semantic-Understanding" class="headerlink" title="Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding"></a>Masked Momentum Contrastive Learning for Zero-shot Semantic Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11448">http://arxiv.org/abs/2308.11448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiantao Wu, Shentong Mo, Muhammad Awais, Sara Atito, Zhenhua Feng, Josef Kittler</li>
<li>for: 本研究旨在评估自主学习技术在计算机视觉任务中的效iveness，以避免训练和finetuning大型模型。</li>
<li>methods: 本研究提出了一种评估协议，基于提示 patch，用于评估零shot segmentation的能力。此外，还提出了一种简单的SSL方法，称为MMC，该方法组合了masked image modelling、 momentum based self-distillation和global contrast等技术，以提高SSL ViTs的描述性表示。</li>
<li>results: 实验表明，MMC方法在零shot semantic segmentation中达到了顶尖水平，并且在不同的 dataset 上都表现出色。<details>
<summary>Abstract</summary>
Self-supervised pretraining (SSP) has emerged as a popular technique in machine learning, enabling the extraction of meaningful feature representations without labelled data. In the realm of computer vision, pretrained vision transformers (ViTs) have played a pivotal role in advancing transfer learning. Nonetheless, the escalating cost of finetuning these large models has posed a challenge due to the explosion of model size. This study endeavours to evaluate the effectiveness of pure self-supervised learning (SSL) techniques in computer vision tasks, obviating the need for finetuning, with the intention of emulating human-like capabilities in generalisation and recognition of unseen objects. To this end, we propose an evaluation protocol for zero-shot segmentation based on a prompting patch. Given a point on the target object as a prompt, the algorithm calculates the similarity map between the selected patch and other patches, upon that, a simple thresholding is applied to segment the target. Another evaluation is intra-object and inter-object similarity to gauge discriminatory ability of SSP ViTs. Insights from zero-shot segmentation from prompting and discriminatory abilities of SSP led to the design of a simple SSP approach, termed MMC. This approaches combines Masked image modelling for encouraging similarity of local features, Momentum based self-distillation for transferring semantics from global to local features, and global Contrast for promoting semantics of global features, to enhance discriminative representations of SSP ViTs. Consequently, our proposed method significantly reduces the overlap of intra-object and inter-object similarities, thereby facilitating effective object segmentation within an image. Our experiments reveal that MMC delivers top-tier results in zero-shot semantic segmentation across various datasets.
</details>
<details>
<summary>摘要</summary>
自顾学前教程（SSP）在机器学习中得到广泛应用，帮助提取有意义的特征表示无需标注数据。在计算机视觉领域，预训练视transformer（ViT）已经发挥了重要的作用，促进了转移学习。然而，模型的规模快速增长带来了训练成本的涨幅问题。本研究旨在评估无标注学习（SSL）技术在计算机视觉任务中的效果，不需要训练，以模仿人类对未看到对象的概念化和识别能力。为此，我们提出了一种零shot segmentation的评估协议，基于提示 patch。给定目标对象的一点作为提示，算法计算selected patch和其他 patch之间的相似度图，然后应用简单的阈值处理来 segment the target。此外，我们还进行了内部和外部相似性评估，以评估 SSL ViTs 的泛化能力。通过零shot segmentation和泛化能力的研究，我们设计了一种简单的 SSP 方法，称为 MMC。该方法结合了做masked image模型，自身融合和全局对比，以提高 SSL ViTs 的泛化表示。实验表明，MMC 可以在不同的 dataset 上达到顶尖的 zero-shot semantic segmentation结果。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-and-Exploring-Efficient-Fast-Adversarial-Training-via-LAW-Lipschitz-Regularization-and-Auto-Weight-Averaging"><a href="#Revisiting-and-Exploring-Efficient-Fast-Adversarial-Training-via-LAW-Lipschitz-Regularization-and-Auto-Weight-Averaging" class="headerlink" title="Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging"></a>Revisiting and Exploring Efficient Fast Adversarial Training via LAW: Lipschitz Regularization and Auto Weight Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11443">http://arxiv.org/abs/2308.11443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojun Jia, Yuefeng Chen, Xiaofeng Mao, Ranjie Duan, Jindong Gu, Rong Zhang, Hui Xue, Xiaochun Cao</li>
<li>For: The paper aims to improve the robustness of machine learning models against adversarial attacks while reducing the training cost of standard adversarial training.* Methods: The paper proposes an effective Lipschitz regularization method for fast adversarial training and explores the effect of data augmentation and weight averaging in fast adversarial training.* Results: The proposed method, FGSM-LAW, demonstrates superior robustness performance compared to state-of-the-art fast adversarial training methods and advanced standard adversarial training methods, as shown in experimental evaluations on four benchmark databases.<details>
<summary>Abstract</summary>
Fast Adversarial Training (FAT) not only improves the model robustness but also reduces the training cost of standard adversarial training. However, fast adversarial training often suffers from Catastrophic Overfitting (CO), which results in poor robustness performance. Catastrophic Overfitting describes the phenomenon of a sudden and significant decrease in robust accuracy during the training of fast adversarial training. Many effective techniques have been developed to prevent Catastrophic Overfitting and improve the model robustness from different perspectives. However, these techniques adopt inconsistent training settings and require different training costs, i.e, training time and memory costs, leading to unfair comparisons. In this paper, we conduct a comprehensive study of over 10 fast adversarial training methods in terms of adversarial robustness and training costs. We revisit the effectiveness and efficiency of fast adversarial training techniques in preventing Catastrophic Overfitting from the perspective of model local nonlinearity and propose an effective Lipschitz regularization method for fast adversarial training. Furthermore, we explore the effect of data augmentation and weight averaging in fast adversarial training and propose a simple yet effective auto weight averaging method to improve robustness further. By assembling these techniques, we propose a FGSM-based fast adversarial training method equipped with Lipschitz regularization and Auto Weight averaging, abbreviated as FGSM-LAW. Experimental evaluations on four benchmark databases demonstrate the superiority of the proposed method over state-of-the-art fast adversarial training methods and the advanced standard adversarial training methods.
</details>
<details>
<summary>摘要</summary>
快速对抗训练（FAT）不仅提高模型的Robustness，还可以降低标准对抗训练的训练成本。然而，快速对抗训练经常会遭遇Catastrophic Overfitting（CO），这会导致对抗性性能很差。Catastrophic Overfitting是指在快速对抗训练中突然和 significatively减少对抗性性能的现象。许多有效的技术已经开发以预防Catastrophic Overfitting并提高模型的Robustness，但这些技术采用不一致的训练设置和不同的训练成本，如训练时间和内存成本，导致不公平的比较。在这篇论文中，我们进行了快速对抗训练方法超过10种的全面研究，包括对抗性和训练成本。我们从模型本地非线性的角度重新评估快速对抗训练技术的效iveness和效率，并提出了一种有效的Lipschitz regularization方法。此外，我们还研究了快速对抗训练中数据扩展和权重平均的效果，并提出了一种简单又有效的自动权重平均方法，以进一步提高对抗性。通过组合这些技术，我们提出了一种基于FGSM的快速对抗训练方法，即FGSM-LAW。实验评估在四个基本数据库中，显示我们的方法在与标准对抗训练方法和先进的标准对抗训练方法相比，具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="SDeMorph-Towards-Better-Facial-De-morphing-from-Single-Morph"><a href="#SDeMorph-Towards-Better-Facial-De-morphing-from-Single-Morph" class="headerlink" title="SDeMorph: Towards Better Facial De-morphing from Single Morph"></a>SDeMorph: Towards Better Facial De-morphing from Single Morph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11442">http://arxiv.org/abs/2308.11442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nitish Shukla</li>
<li>for: 防止摸索攻击 (Morph Attack Detection)</li>
<li>methods: 无参考基于Diffusion Probabilistic Models (DDPM)和branched-UNet</li>
<li>results: 可以准确地回归真实的人脸特征，提高了人脸识别系统的安全性<details>
<summary>Abstract</summary>
Face Recognition Systems (FRS) are vulnerable to morph attacks. A face morph is created by combining multiple identities with the intention to fool FRS and making it match the morph with multiple identities. Current Morph Attack Detection (MAD) can detect the morph but are unable to recover the identities used to create the morph with satisfactory outcomes. Existing work in de-morphing is mostly reference-based, i.e. they require the availability of one identity to recover the other. Sudipta et al. \cite{ref9} proposed a reference-free de-morphing technique but the visual realism of outputs produced were feeble. In this work, we propose SDeMorph (Stably Diffused De-morpher), a novel de-morphing method that is reference-free and recovers the identities of bona fides. Our method produces feature-rich outputs that are of significantly high quality in terms of definition and facial fidelity. Our method utilizes Denoising Diffusion Probabilistic Models (DDPM) by destroying the input morphed signal and then reconstructing it back using a branched-UNet. Experiments on ASML, FRLL-FaceMorph, FRLL-MorDIFF, and SMDD datasets support the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
人脸识别系统（FRS）容易受到形态攻击。一个形态是通过将多个标识 combine 以达到欺骗 FRS 并让它匹配形态中的多个标识。现有的形态攻击检测（MAD）可以检测形态，但无法恢复创建形态的标识。现有的工作大多数是参考基于的，即需要一个标识的可用性来恢复另一个标识。Sudipta et al. \cite{ref9} 提出了一种无参考的恢复技术，但Visual realism 输出的质量不够高。在这个工作中，我们提出了SDeMorph（稳定扩散恢复器），一种新的无参考恢复方法，可以恢复创建形态的标识。我们的方法生成了高质量的输出，具有高度的定义和人脸准确性。我们的方法利用了Denosing Diffusion Probabilistic Models (DDPM)，通过破坏输入形态信号，然后使用分支-UNet 重建它。实验表明，我们的方法在 ASML、FRLL-FaceMorph、FRLL-MorDIFF 和 SMDD 数据集上具有效果。
</details></li>
</ul>
<hr>
<h2 id="Learning-a-More-Continuous-Zero-Level-Set-in-Unsigned-Distance-Fields-through-Level-Set-Projection"><a href="#Learning-a-More-Continuous-Zero-Level-Set-in-Unsigned-Distance-Fields-through-Level-Set-Projection" class="headerlink" title="Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection"></a>Learning a More Continuous Zero Level Set in Unsigned Distance Fields through Level Set Projection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11441">http://arxiv.org/abs/2308.11441</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junshengzhou/levelsetudf">https://github.com/junshengzhou/levelsetudf</a></li>
<li>paper_authors: Junsheng Zhou, Baorui Ma, Shujuan Li, Yu-Shen Liu, Zhizhong Han</li>
<li>for: 该paper aimed to address the problem of reconstructing surfaces with open surfaces using unsigned distance functions (UDFs).</li>
<li>methods: The authors proposed to learn UDFs using neural networks and reconstruct surfaces with the gradients around the zero level set of the UDF. However, they found that the differential networks struggled to learn the zero level set, leading to large errors on unsigned distances and gradients. To resolve this, they proposed to learn a more continuous zero level set using level set projections.</li>
<li>results: The authors conducted comprehensive experiments in surface reconstruction for point clouds, real scans or depth maps, and demonstrated non-trivial improvements over the state-of-the-art methods. They also explored the performance in unsupervised point cloud upsampling and unsupervised point normal estimation with the learned UDF.<details>
<summary>Abstract</summary>
Latest methods represent shapes with open surfaces using unsigned distance functions (UDFs). They train neural networks to learn UDFs and reconstruct surfaces with the gradients around the zero level set of the UDF. However, the differential networks struggle from learning the zero level set where the UDF is not differentiable, which leads to large errors on unsigned distances and gradients around the zero level set, resulting in highly fragmented and discontinuous surfaces. To resolve this problem, we propose to learn a more continuous zero level set in UDFs with level set projections. Our insight is to guide the learning of zero level set using the rest non-zero level sets via a projection procedure. Our idea is inspired from the observations that the non-zero level sets are much smoother and more continuous than the zero level set. We pull the non-zero level sets onto the zero level set with gradient constraints which align gradients over different level sets and correct unsigned distance errors on the zero level set, leading to a smoother and more continuous unsigned distance field. We conduct comprehensive experiments in surface reconstruction for point clouds, real scans or depth maps, and further explore the performance in unsupervised point cloud upsampling and unsupervised point normal estimation with the learned UDF, which demonstrate our non-trivial improvements over the state-of-the-art methods. Code is available at https://github.com/junshengzhou/LevelSetUDF .
</details>
<details>
<summary>摘要</summary>
最新的方法使用无符号距离函数（UDF）来表示形状。它们使用神经网络学习UDF并重建表面的梯度在UDF的零水平面周围。然而，� diferencial networks 受到学习零水平面的约束，在零水平面不 diferenciable 的情况下，会导致大量的unsigned distance 和梯度 around the zero level set 的错误，从而导致表面变得高度分裂和不连续。为解决这问题，我们提议通过约束水平面投影来学习更加连续的零水平面。我们的想法来自于观察到非零水平面比零水平面更加平滑和连续。我们使用梯度约束将非零水平面投影到零水平面，以实现梯度的对齐和unsigned distance 错误的修正，从而导致更加平滑和连续的unsigned distance field。我们进行了广泛的实验，包括点云重建、真实扫描或深度图重建，以及不supervised point cloud upsampling 和不supervised point normal estimation 等，其中所获得的改进均非常 significativ。代码可以在 <https://github.com/junshengzhou/LevelSetUDF> 上找到。
</details></li>
</ul>
<hr>
<h2 id="PoseGraphNet-Enriching-3D-Human-Pose-with-Orientation-Estimation"><a href="#PoseGraphNet-Enriching-3D-Human-Pose-with-Orientation-Estimation" class="headerlink" title="PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation"></a>PoseGraphNet++: Enriching 3D Human Pose with Orientation Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11440">http://arxiv.org/abs/2308.11440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soubarna Banik, Edvard Avagyan, Alejandro Mendoza Gracia, Alois Knoll</li>
<li>for: 本研究旨在提出一种基于图гра夫 convolutional neural network（Graph Convolutional Network，GCN）的2D-to-3D提升方法，以便预测人体3D姿态包括关节位置和骨orientation。</li>
<li>methods: 我们提出了一种名为PoseGraphNet++的新型2D-to-3D提升网络，该网络通过节点和边卷积来利用关节和骨特征。</li>
<li>results: 我们在多个标准测试集上评估了我们的模型，并与状态的艺术结果相比，我们的模型在位置和旋转度量上具有类似或更高的性能。此外，我们还通过广泛的减少研究，证明了PoseGraphNet++可以借鉴关节和骨之间的相互关系，从而提高预测性能。<details>
<summary>Abstract</summary>
Existing kinematic skeleton-based 3D human pose estimation methods only predict joint positions. Although this is sufficient to compute the yaw and pitch of the bone rotations, the roll around the axis of the bones remains unresolved by these methods. In this paper, we propose a novel 2D-to-3D lifting Graph Convolution Network named PoseGraphNet++ to predict the complete human pose including the joint positions and the bone orientations. We employ node and edge convolutions to utilize the joint and bone features. Our model is evaluated on multiple benchmark datasets, and its performance is either on par with or better than the state-of-the-art in terms of both position and rotation metrics. Through extensive ablation studies, we show that PoseGraphNet++ benefits from exploiting the mutual relationship between the joints and the bones.
</details>
<details>
<summary>摘要</summary>
现有的骨骼基本体系3D人姿估算方法只预测关节位置。尽管这足够计算关节的封顶和旋转，但是关节的滚动仍然无法被这些方法解决。在这篇论文中，我们提出了一种新的2D-to-3D提升图 convolution neural network（PoseGraphNet++），用于预测完整的人姿，包括关节位置和骨头orientation。我们利用节点和边卷积来利用关节和骨头特征。我们的模型在多个基准数据集上进行评估，其性能与或超过了现有的状态的艺术metric。通过广泛的减少研究，我们表明了PoseGraphNet++可以通过利用关节和骨头之间的相互关系来增强性能。
</details></li>
</ul>
<hr>
<h2 id="ScanNet-A-High-Fidelity-Dataset-of-3D-Indoor-Scenes"><a href="#ScanNet-A-High-Fidelity-Dataset-of-3D-Indoor-Scenes" class="headerlink" title="ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes"></a>ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11417">http://arxiv.org/abs/2308.11417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chandan Yeshwanth, Yueh-Cheng Liu, Matthias Nießner, Angela Dai</li>
<li>for: 提供了一个大规模的indoor场景数据集，其中每个场景都是使用高级激光扫描仪获得高分辨率的geometry和颜色信息，同时还包括了 региSTR的3300万像素图像和iPhone的RGB-D流。</li>
<li>methods: 使用高级激光扫描仪和DSLR相机捕捉场景图像，并使用iPhone捕捉RGB-D流。场景重建还包括了开放词汇的semantics标注，以便实现全面的semantic理解。</li>
<li>results: ScanNet++提供了一个新的real-worldbenchmark дляnovel view synthesis，包括高品质RGB捕捉和商业级图像的synthesis，以及一个新的3Dsemantic scene理解 benchmark，全面地涵盖了多种和抽象的semantic标注方案。ScanNet++ currently contains 460 scenes, 280,000 captured DSLR images, and over 3.7M iPhone RGBD frames.<details>
<summary>Abstract</summary>
We present ScanNet++, a large-scale dataset that couples together capture of high-quality and commodity-level geometry and color of indoor scenes. Each scene is captured with a high-end laser scanner at sub-millimeter resolution, along with registered 33-megapixel images from a DSLR camera, and RGB-D streams from an iPhone. Scene reconstructions are further annotated with an open vocabulary of semantics, with label-ambiguous scenarios explicitly annotated for comprehensive semantic understanding. ScanNet++ enables a new real-world benchmark for novel view synthesis, both from high-quality RGB capture, and importantly also from commodity-level images, in addition to a new benchmark for 3D semantic scene understanding that comprehensively encapsulates diverse and ambiguous semantic labeling scenarios. Currently, ScanNet++ contains 460 scenes, 280,000 captured DSLR images, and over 3.7M iPhone RGBD frames.
</details>
<details>
<summary>摘要</summary>
我们现在提供ScanNet++ dataset，这是一个大规模的数据集，它结合了高质量的激光扫描仪和商用级别的颜色捕捉indoor场景。每个场景都被高级激光扫描仪 capture，并与注册的3300万像素DSLR镜头拍摄的图像，以及iPhone的RGB-D流相匹配。场景重建还被标注为开放词汇Semantics，并且明确标注了涉及多义 Label的情况，以便全面理解semantic。ScanNet++提供了一个新的真实世界标准 benchmark for novel view synthesis，不仅来自高质量RGB捕捉，还来自商用级别的图像，以及一个新的3Dsemantic场景理解标准，全面涵盖多样化和涉及多义标签的情况。目前，ScanNet++包含460个场景，280,000个拍摄的DSLR图像，以及超过370万个iPhone RGBD帧。
</details></li>
</ul>
<hr>
<h2 id="MatFuse-Controllable-Material-Generation-with-Diffusion-Models"><a href="#MatFuse-Controllable-Material-Generation-with-Diffusion-Models" class="headerlink" title="MatFuse: Controllable Material Generation with Diffusion Models"></a>MatFuse: Controllable Material Generation with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11408">http://arxiv.org/abs/2308.11408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giuseppe Vecchio, Renato Sortino, Simone Palazzo, Concetto Spampinato</li>
<li>for: This paper aims to simplify the creation of SVBRDF maps in computer graphics, using a novel unified approach based on diffusion models.</li>
<li>methods: The proposed method integrates multiple sources of conditioning, such as color palettes, sketches, and pictures, to enable fine-grained control and flexibility in material synthesis.</li>
<li>results: The proposed method yields performance comparable to state-of-the-art approaches in estimating SVBRDF, both qualitatively and quantitatively, under various conditioning settings.<details>
<summary>Abstract</summary>
Creating high quality and realistic materials in computer graphics is a challenging and time-consuming task, which requires great expertise. In this paper, we present MatFuse, a novel unified approach that harnesses the generative power of diffusion models (DM) to simplify the creation of SVBRDF maps. Our DM-based pipeline integrates multiple sources of conditioning, such as color palettes, sketches, and pictures, enabling fine-grained control and flexibility in material synthesis. This design allows for the combination of diverse information sources (e.g., sketch + image embedding), enhancing creative possibilities in line with the principle of compositionality. We demonstrate the generative capabilities of the proposed method under various conditioning settings; on the SVBRDF estimation task, we show that our method yields performance comparable to state-of-the-art approaches, both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer"><a href="#Non-Redundant-Combination-of-Hand-Crafted-and-Deep-Learning-Radiomics-Application-to-the-Early-Detection-of-Pancreatic-Cancer" class="headerlink" title="Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer"></a>Non-Redundant Combination of Hand-Crafted and Deep Learning Radiomics: Application to the Early Detection of Pancreatic Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11389">http://arxiv.org/abs/2308.11389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebeca Vétil, Clément Abi-Nader, Alexandre Bône, Marie-Pierre Vullierme, Marc-Michel Rohé, Pietro Gori, Isabelle Bloch</li>
<li>for: 这篇论文旨在解决深度学习医学影像特征（DLR）和手工设计医学影像特征（HCR）之间的重复性问题。</li>
<li>methods: 作者使用了一种简单的Variational Autoencoder（VAE）来提取DLR特征，并且通过降低这两种特征之间的相互信息来确保它们之间的独立性。</li>
<li>results: 作者的方法可以与手工设计的特征结合，并且通过一个分类器来预测抑制肝癌的早期标志。实验结果显示，结合非重复的DLR和HCR特征可以提高预测性能，比基eline方法更好。<details>
<summary>Abstract</summary>
We address the problem of learning Deep Learning Radiomics (DLR) that are not redundant with Hand-Crafted Radiomics (HCR). To do so, we extract DLR features using a VAE while enforcing their independence with HCR features by minimizing their mutual information. The resulting DLR features can be combined with hand-crafted ones and leveraged by a classifier to predict early markers of cancer. We illustrate our method on four early markers of pancreatic cancer and validate it on a large independent test set. Our results highlight the value of combining non-redundant DLR and HCR features, as evidenced by an improvement in the Area Under the Curve compared to baseline methods that do not address redundancy or solely rely on HCR features.
</details>
<details>
<summary>摘要</summary>
我们解决了深度学习医学影像特征（DLR）不重复的问题。我们使用VAE将DLR特征提取出来，并在这些特征之间强制独立性，以避免与手工设计的医学影像特征（HCR）之间的相互信息。这些DLR特征可以与手工设计的特征结合，并由分类器使用来预测早期癌症 markers。我们在四种早期肝癌标志物中进行了实验，并在一个大型独立测试集上验证了我们的方法。我们的结果显示了结合非重复的DLR和HCR特征的价值，即比基eline方法不 addressed 或仅仅靠赖于HCR特征的情况下，预测性能有所提高。
</details></li>
</ul>
<hr>
<h2 id="Targeted-Data-Augmentation-for-bias-mitigation"><a href="#Targeted-Data-Augmentation-for-bias-mitigation" class="headerlink" title="Targeted Data Augmentation for bias mitigation"></a>Targeted Data Augmentation for bias mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11386">http://arxiv.org/abs/2308.11386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła, Maria Ferlin, Michał Grochowski</li>
<li>for: This paper aims to address the issue of bias in AI systems by introducing a novel approach called Targeted Data Augmentation (TDA).</li>
<li>methods: The TDA method leverages classical data augmentation techniques to insert biases into the training data, which helps to mitigate biases in the models.</li>
<li>results: The paper shows that the TDA method can significantly decrease bias measures while maintaining a negligible increase in the error rate, using two diverse datasets of clinical skin lesions and male and female faces.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目的是解决人工智能系统中的偏见问题，通过引入一种新的方法 called Targeted Data Augmentation (TDA)。</li>
<li>methods: TDA方法利用经典的数据增强技术，插入偏见到训练数据中，以减少模型中的偏见。</li>
<li>results: 论文显示，TDA方法可以Significantly减少偏见度量，同时保持误差率的增长在较低水平，使用了两个多样化的数据集：皮肤病变和男女面孔数据集。<details>
<summary>Abstract</summary>
The development of fair and ethical AI systems requires careful consideration of bias mitigation, an area often overlooked or ignored. In this study, we introduce a novel and efficient approach for addressing biases called Targeted Data Augmentation (TDA), which leverages classical data augmentation techniques to tackle the pressing issue of bias in data and models. Unlike the laborious task of removing biases, our method proposes to insert biases instead, resulting in improved performance. To identify biases, we annotated two diverse datasets: a dataset of clinical skin lesions and a dataset of male and female faces. These bias annotations are published for the first time in this study, providing a valuable resource for future research. Through Counterfactual Bias Insertion, we discovered that biases associated with the frame, ruler, and glasses had a significant impact on models. By randomly introducing biases during training, we mitigated these biases and achieved a substantial decrease in bias measures, ranging from two-fold to more than 50-fold, while maintaining a negligible increase in the error rate.
</details>
<details>
<summary>摘要</summary>
发展公正和伦理AI系统需要仔细考虑偏见缓解，这个领域经常被排除或忽略。在这个研究中，我们提出了一种新的和高效的偏见缓解方法，即目标数据扩展（TDA），该方法利用了经典数据扩展技术来解决数据和模型中的偏见问题。与努力除去偏见不同，我们的方法提议在训练过程中插入偏见，从而提高性能。为了标识偏见，我们对两个多样化的数据集进行了标注：一个是皮肤病变 dataset，另一个是男女脸部 dataset。这些偏见标注在本研究中首次公布，为未来研究提供了一个有价值的资源。通过对比方案插入，我们发现了框架、尺度和镜片等偏见对模型产生了重要影响。通过随机在训练过程中引入偏见，我们减少了这些偏见的度量，从2倍到更多于50倍，同时保持了错误率的增长在较低水平。
</details></li>
</ul>
<hr>
<h2 id="DALNet-A-Rail-Detection-Network-Based-on-Dynamic-Anchor-Line"><a href="#DALNet-A-Rail-Detection-Network-Based-on-Dynamic-Anchor-Line" class="headerlink" title="DALNet: A Rail Detection Network Based on Dynamic Anchor Line"></a>DALNet: A Rail Detection Network Based on Dynamic Anchor Line</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11381">http://arxiv.org/abs/2308.11381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yzichen/mmlanedet">https://github.com/yzichen/mmlanedet</a></li>
<li>paper_authors: Zichen Yu, Quanli Liu, Wei Wang, Liyong Zhang, Xiaoguang Zhao</li>
<li>for: 提高智能列车的轨道检测精度</li>
<li>methods: 基于动态锚点线的轨道检测网络DALNet，包括动态锚点生成器和轨道检测模块</li>
<li>results: DALNet在我们提供的DL-Rail轨道检测数据集和知名的Tusimple和LLAMAS车道检测标准 benchmark中达到了状态之精度表现。<details>
<summary>Abstract</summary>
Rail detection is one of the key factors for intelligent train. In the paper, motivated by the anchor line-based lane detection methods, we propose a rail detection network called DALNet based on dynamic anchor line. Aiming to solve the problem that the predefined anchor line is image agnostic, we design a novel dynamic anchor line mechanism. It utilizes a dynamic anchor line generator to dynamically generate an appropriate anchor line for each rail instance based on the position and shape of the rails in the input image. These dynamically generated anchor lines can be considered as better position references to accurately localize the rails than the predefined anchor lines. In addition, we present a challenging urban rail detection dataset DL-Rail with high-quality annotations and scenario diversity. DL-Rail contains 7000 pairs of images and annotations along with scene tags, and it is expected to encourage the development of rail detection. We extensively compare DALNet with many competitive lane methods. The results show that our DALNet achieves state-of-the-art performance on our DL-Rail rail detection dataset and the popular Tusimple and LLAMAS lane detection benchmarks. The code will be released at https://github.com/Yzichen/mmLaneDet.
</details>
<details>
<summary>摘要</summary>
铁路检测是智能列车的关键因素之一。在论文中，我们被动 anchor line-based 铁路检测方法所 inspirited，并提出了基于动态 anchor line 的铁路检测网络 DALNet。为了解决预定义的 anchor line 是图像不特定的问题，我们设计了一种新的动态 anchor line 机制。它利用动态 anchor line 生成器生成每个铁路实例的相应 anchor line，根据输入图像中铁路的位置和形状。这些动态生成的 anchor line 可以视为更好的位置参考，以准确地 Localize 铁路。此外，我们提供了一个挑战性的城市铁路检测数据集 DL-Rail，其包括7000个图像和注释对，以及Scene 标签。我们进行了广泛的比较，结果显示，我们的 DALNet 在我们的 DL-Rail 铁路检测数据集和知名的 Tusimple 和 LLAMAS lane detection benchmark 上均达到了状态组件表现。代码将在 GitHub 上发布，详细信息请参考 <https://github.com/Yzichen/mmLaneDet>。
</details></li>
</ul>
<hr>
<h2 id="Boundary-RL-Reinforcement-Learning-for-Weakly-Supervised-Prostate-Segmentation-in-TRUS-Images"><a href="#Boundary-RL-Reinforcement-Learning-for-Weakly-Supervised-Prostate-Segmentation-in-TRUS-Images" class="headerlink" title="Boundary-RL: Reinforcement Learning for Weakly-Supervised Prostate Segmentation in TRUS Images"></a>Boundary-RL: Reinforcement Learning for Weakly-Supervised Prostate Segmentation in TRUS Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11376">http://arxiv.org/abs/2308.11376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixi Yi, Vasilis Stavrinides, Zachary M. C. Baum, Qianye Yang, Dean C. Barratt, Matthew J. Clarkson, Yipeng Hu, Shaheer U. Saeed<br>for: 这个研究旨在提出一种弱度指导的类别分割方法，使用仅有单元标签进行训练，并且将类别分割看作是范围检测问题，而不是像前一些研究所使用的像素级别分类。methods: 这个方法使用了强化学习来训练一个控制函数，以寻找范围内的类别 bounding，使用一个从预训练的边界存在检测器获得的赏兹。results: 在评估这个方法的临床实际任务中，关于胆囊组织分类，我们获得了与其他已知的弱度指导方法相比，更好的表现，使用相同的标签，例如多个例问题学习。<details>
<summary>Abstract</summary>
We propose Boundary-RL, a novel weakly supervised segmentation method that utilises only patch-level labels for training. We envision the segmentation as a boundary detection problem, rather than a pixel-level classification as in previous works. This outlook on segmentation may allow for boundary delineation under challenging scenarios such as where noise artefacts may be present within the region-of-interest (ROI) boundaries, where traditional pixel-level classification-based weakly supervised methods may not be able to effectively segment the ROI. Particularly of interest, ultrasound images, where intensity values represent acoustic impedance differences between boundaries, may also benefit from the boundary delineation approach. Our method uses reinforcement learning to train a controller function to localise boundaries of ROIs using a reward derived from a pre-trained boundary-presence classifier. The classifier indicates when an object boundary is encountered within a patch, as the controller modifies the patch location in a sequential Markov decision process. The classifier itself is trained using only binary patch-level labels of object presence, which are the only labels used during training of the entire boundary delineation framework, and serves as a weak signal to inform the boundary delineation. The use of a controller function ensures that a sliding window over the entire image is not necessary. It also prevents possible false-positive or -negative cases by minimising number of patches passed to the boundary-presence classifier. We evaluate our proposed approach for a clinically relevant task of prostate gland segmentation on trans-rectal ultrasound images. We show improved performance compared to other tested weakly supervised methods, using the same labels e.g., multiple instance learning.
</details>
<details>
<summary>摘要</summary>
我们提出了Boundary-RL，一种新的弱类标注方法，只使用补丁级别标签进行训练。我们认为 segmentation 是一个边检测问题，而不是像前一些工作一样将每个像素分类为不同的类别。这种对 segmentation 的看法可能allow for 边界定义在具有噪声artifacts的区域内的场景中，其中传统的像素级别分类基于的弱类标注方法可能无法有效地分类区域。特别是，ultrasound 图像，其中 интенсивности值表示物体边界上的声学阻抗差异，也可能受惠于边界定义方法。我们的方法使用 reinforcement learning 训练一个控制函数，用于localize 区域内的边界。该控制函数通过一个Markov 决策过程来修改补丁位置，并且使用一个预训练的边界存在分类器来指示在补丁中是否遇到了物体边界。该分类器只使用补丁级别标签进行训练，这些标签也是训练整个边界定义框架的唯一标签。我们使用控制函数来避免使用滑块窗口覆盖整个图像，并且避免可能的 false-positive 或 false-negative 情况。我们对肾脏成像进行评估，并与其他测试的弱类标注方法进行比较。我们显示出我们的方法在评估中表现出色，使用相同的标签。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Interpretable-Object-Abstraction-via-Clustering-based-Slot-Initialization"><a href="#Enhancing-Interpretable-Object-Abstraction-via-Clustering-based-Slot-Initialization" class="headerlink" title="Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization"></a>Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11369">http://arxiv.org/abs/2308.11369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Gao, Bernard Hohmann, Gerhard Neumann</li>
<li>For: The paper is focused on improving object-centric representations using slots for efficient, flexible, and interpretable abstraction from low-level perceptual features in a compositional scene.* Methods: The paper proposes using clustering algorithms conditioned on perceptual input features to initialize the slot representations, and designs permutation invariant and permutation equivariant versions of this layer to enable exchangeable slot representations after clustering.* Results: The paper shows that its method outperforms prior works consistently, especially for complex scenes, through experiments on object discovery and novel view synthesis tasks with various datasets.<details>
<summary>Abstract</summary>
Object-centric representations using slots have shown the advances towards efficient, flexible and interpretable abstraction from low-level perceptual features in a compositional scene. Current approaches randomize the initial state of slots followed by an iterative refinement. As we show in this paper, the random slot initialization significantly affects the accuracy of the final slot prediction. Moreover, current approaches require a predetermined number of slots from prior knowledge of the data, which limits the applicability in the real world. In our work, we initialize the slot representations with clustering algorithms conditioned on the perceptual input features. This requires an additional layer in the architecture to initialize the slots given the identified clusters. We design permutation invariant and permutation equivariant versions of this layer to enable the exchangeable slot representations after clustering. Additionally, we employ mean-shift clustering to automatically identify the number of slots for a given scene. We evaluate our method on object discovery and novel view synthesis tasks with various datasets. The results show that our method outperforms prior works consistently, especially for complex scenes.
</details>
<details>
<summary>摘要</summary>
使用槽来表示对象已经取得了高效、灵活和可解释的抽象优势。现有方法在初始化槽时随机，然后进行迭代优化。我们在这篇论文中表明，随机槽初始化会对最终槽预测的准确性产生显著影响。此外，现有方法需要先知道数据中的槽数量，这限制了实际应用的可行性。在我们的工作中，我们使用基于感知输入特征的 clustering 算法来初始化槽表示。这需要一个额外的架构层来初始化槽给确定的群集。我们设计了卷积不变和卷积对称版本的这层，以便在 clustering 后换取可交换的槽表示。此外，我们使用 Mean-Shift  clustering 自动确定Scene中的槽数量。我们在对象发现和新视图合成任务中使用了多个数据集进行评估，结果表明，我们的方法在复杂场景下一直高于先前的方法。
</details></li>
</ul>
<hr>
<h2 id="Towards-Clip-Free-Quantized-Super-Resolution-Networks-How-to-Tame-Representative-Images"><a href="#Towards-Clip-Free-Quantized-Super-Resolution-Networks-How-to-Tame-Representative-Images" class="headerlink" title="Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images"></a>Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11365">http://arxiv.org/abs/2308.11365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alperen Kalay, Bahri Batuhan Bilecen, Mustafa Ayazoglu</li>
<li>for: 这个研究旨在解决 SR 网络中训练后量化 (PTQ) 阶段的一个重要问题，即代表性数据集 (RD)。</li>
<li>methods: 我们提出了一个新的 clip-free 量化管道 (CFQP)，并提供了广泛的实验证明，以 cleverly 使用 FP32 模型的输出来增强 RD 图像。这种方法可以消除不必要的 clipped 活动层，从而提高整体稳定性、减少推理时间（最多下降到 54%）、提高视觉质量 Results  compared to INT8 clipped models，并在一些 SR 模型上甚至超越了不量化 FP32 模型。</li>
<li>results: 我们的方法可以在某些 SR 模型上提高视觉质量，同时减少推理时间，并且不需要重新训练 clipped activation。在一些情况下，我们的方法可以超越不量化 FP32 模型， both in runtime and visual quality。<details>
<summary>Abstract</summary>
Super-resolution (SR) networks have been investigated for a while, with their mobile and lightweight versions gaining noticeable popularity recently. Quantization, the procedure of decreasing the precision of network parameters (mostly FP32 to INT8), is also utilized in SR networks for establishing mobile compatibility. This study focuses on a very important but mostly overlooked post-training quantization (PTQ) step: representative dataset (RD), which adjusts the quantization range for PTQ. We propose a novel pipeline (clip-free quantization pipeline, CFQP) backed up with extensive experimental justifications to cleverly augment RD images by only using outputs of the FP32 model. Using the proposed pipeline for RD, we can successfully eliminate unwanted clipped activation layers, which nearly all mobile SR methods utilize to make the model more robust to PTQ in return for a large overhead in runtime. Removing clipped activations with our method significantly benefits overall increased stability, decreased inference runtime up to 54% on some SR models, better visual quality results compared to INT8 clipped models - and outperforms even some FP32 non-quantized models, both in runtime and visual quality, without the need for retraining with clipped activation.
</details>
<details>
<summary>摘要</summary>
超解像（SR）网络已经被研究了一段时间，其移动和轻量级版本在最近得到了关注。量化，减小网络参数的精度（主要是FP32到INT8），也在SR网络中使用，以实现移动兼容性。这项研究关注一个很重要但又多少被注意的后training量化（PTQ）步骤：代表数据集（RD），它调整PTQ的范围。我们提出一个新的批处理管道（clip-free quantization pipeline，CFQP），并提供了详细的实验证明，以智能地增强RD图像，只使用FP32模型的输出。使用我们的方法进行RD，可以成功地消除无用的clip activation层，这些层通常在移动SR方法中使用，以使模型更具 robustness to PTQ，但是带来了大量的运行时间开销。从我们的方法中消除clip activation可以获得更好的稳定性、下降到54%的推理时间、更好的视觉质量结果，并且超过了INT8clip模型，以及FP32非量化模型，无需重新训练clip activation。
</details></li>
</ul>
<hr>
<h2 id="Exemplar-Free-Continual-Transformer-with-Convolutions"><a href="#Exemplar-Free-Continual-Transformer-with-Convolutions" class="headerlink" title="Exemplar-Free Continual Transformer with Convolutions"></a>Exemplar-Free Continual Transformer with Convolutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11357">http://arxiv.org/abs/2308.11357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anurag Roy, Vinay Kumar Verma, Sravan Voonna, Kripabandhu Ghosh, Saptarshi Ghosh, Abir Das</li>
<li>for: 这 paper 的目的是提出一种新的无例子（exemplar-free）的类&#x2F;任务逐步学习方法，不需要在测试时显式提供任务标识符（task identifier），并且不需要保留之前训练集。</li>
<li>methods: 该方法使用 transformer 架构，并通过重新权重 multi-head self-attention 层中的键、查询和值权重来实现类&#x2F;任务逐步学习。具体来说，通过 convolution 来重新权重这些权重，以便在每个任务上保持低的参数数量。此外，使用图像增强技术来预测任务，而无需在测试时显式提供任务标识符。</li>
<li>results: 实验结果表明，该方法可以在四个 benchmark 数据集上超越许多竞争方法，而且需要更少的参数。<details>
<summary>Abstract</summary>
Continual Learning (CL) involves training a machine learning model in a sequential manner to learn new information while retaining previously learned tasks without the presence of previous training data. Although there has been significant interest in CL, most recent CL approaches in computer vision have focused on convolutional architectures only. However, with the recent success of vision transformers, there is a need to explore their potential for CL. Although there have been some recent CL approaches for vision transformers, they either store training instances of previous tasks or require a task identifier during test time, which can be limiting. This paper proposes a new exemplar-free approach for class/task incremental learning called ConTraCon, which does not require task-id to be explicitly present during inference and avoids the need for storing previous training instances. The proposed approach leverages the transformer architecture and involves re-weighting the key, query, and value weights of the multi-head self-attention layers of a transformer trained on a similar task. The re-weighting is done using convolution, which enables the approach to maintain low parameter requirements per task. Additionally, an image augmentation-based entropic task identification approach is used to predict tasks without requiring task-ids during inference. Experiments on four benchmark datasets demonstrate that the proposed approach outperforms several competitive approaches while requiring fewer parameters.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine"><a href="#Integration-of-Sentinel-1-and-Sentinel-2-data-for-Earth-surface-classification-using-Machine-Learning-algorithms-implemented-on-Google-Earth-Engine" class="headerlink" title="Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine"></a>Integration of Sentinel-1 and Sentinel-2 data for Earth surface classification using Machine Learning algorithms implemented on Google Earth Engine</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11340">http://arxiv.org/abs/2308.11340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesca Razzano, Mariapia Rita Iandolo, Chiara Zarro, G. S. Yogesh, Silvia Liberata Ullo</li>
<li>for: 本研究使用Synthetic Aperture Radar (SAR)和光学数据进行地面分类。</li>
<li>methods: 通过在Google Earth Engine (GEE)平台上实施监督式机器学习（ML）算法，将Sentinel-1 (S-1)和Sentinel-2 (S-2)数据集成起来，用于地面覆盖分类。</li>
<li>results: 研究结果表明，在这种情况下，雷达和光学远程探测提供了补偿信息，有利地面覆盖分类，通常导致映射精度的提高。此外，本研究也证明了GEE在处理大量卫星数据方面的emerging角色。<details>
<summary>Abstract</summary>
In this study, Synthetic Aperture Radar (SAR) and optical data are both considered for Earth surface classification. Specifically, the integration of Sentinel-1 (S-1) and Sentinel-2 (S-2) data is carried out through supervised Machine Learning (ML) algorithms implemented on the Google Earth Engine (GEE) platform for the classification of a particular region of interest. Achieved results demonstrate how in this case radar and optical remote detection provide complementary information, benefiting surface cover classification and generally leading to increased mapping accuracy. In addition, this paper works in the direction of proving the emerging role of GEE as an effective cloud-based tool for handling large amounts of satellite data.
</details>
<details>
<summary>摘要</summary>
在这项研究中，人造 aperature radar（SAR）和光学数据都被考虑用于地球表面分类。具体来说，Sentinel-1（S-1）和Sentinel-2（S-2）数据的集成通过在Google Earth Engine（GEE）平台上实施监督式机器学习（ML）算法进行地区特定的分类。实现的结果表明在这种情况下，雷达和光学远程探测提供了补做的信息，从而改善表面覆盖分类和通常提高地图准确性。此外，这篇论文还在irection towards proving the emerging role of GEE as an effective cloud-based tool for handling large amounts of satellite data.
</details></li>
</ul>
<hr>
<h2 id="Object-Detection-Difficulty-Suppressing-Over-aggregation-for-Faster-and-Better-Video-Object-Detection"><a href="#Object-Detection-Difficulty-Suppressing-Over-aggregation-for-Faster-and-Better-Video-Object-Detection" class="headerlink" title="Object Detection Difficulty: Suppressing Over-aggregation for Faster and Better Video Object Detection"></a>Object Detection Difficulty: Suppressing Over-aggregation for Faster and Better Video Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11327">http://arxiv.org/abs/2308.11327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bingqingzhang/odd-vod">https://github.com/bingqingzhang/odd-vod</a></li>
<li>paper_authors: Bingqing Zhang, Sen Wang, Yifan Liu, Brano Kusy, Xue Li, Jiajun Liu</li>
<li>for: 提高视频对象检测（VOD）系统的实用性</li>
<li>methods: 提出一种图像级对象检测难度（ODD）指标，用于衡量检测图像中对象的难度，并在VOD过程中应用该指标来减少过度聚合。</li>
<li>results: 对8种VOD模型进行了广泛的实验，结果表明，当选择全局参照帧时，ODD-VOD可以不断提高全局基于VOD模型的准确率。当用于加速时，ODD-VOD可以不断提高帧数（FPS），并且不会降低准确率。<details>
<summary>Abstract</summary>
Current video object detection (VOD) models often encounter issues with over-aggregation due to redundant aggregation strategies, which perform feature aggregation on every frame. This results in suboptimal performance and increased computational complexity. In this work, we propose an image-level Object Detection Difficulty (ODD) metric to quantify the difficulty of detecting objects in a given image. The derived ODD scores can be used in the VOD process to mitigate over-aggregation. Specifically, we train an ODD predictor as an auxiliary head of a still-image object detector to compute the ODD score for each image based on the discrepancies between detection results and ground-truth bounding boxes. The ODD score enhances the VOD system in two ways: 1) it enables the VOD system to select superior global reference frames, thereby improving overall accuracy; and 2) it serves as an indicator in the newly designed ODD Scheduler to eliminate the aggregation of frames that are easy to detect, thus accelerating the VOD process. Comprehensive experiments demonstrate that, when utilized for selecting global reference frames, ODD-VOD consistently enhances the accuracy of Global-frame-based VOD models. When employed for acceleration, ODD-VOD consistently improves the frames per second (FPS) by an average of 73.3% across 8 different VOD models without sacrificing accuracy. When combined, ODD-VOD attains state-of-the-art performance when competing with many VOD methods in both accuracy and speed. Our work represents a significant advancement towards making VOD more practical for real-world applications.
</details>
<details>
<summary>摘要</summary>
当前的视频对象检测（VOD）模型经常遇到过度聚合的问题，这是因为 redundancy 的聚合策略在每帧进行特征聚合，从而导致性能下降和计算复杂性增加。在这种情况下，我们提出了一个图像级别的对象检测困难度（ODD）度量，用于衡量检测图像中对象的困难度。这些计算的ODD分数可以在 VOD 过程中使用，以避免过度聚合。我们在 VOD 系统中训练了一个 ODD 预测器，用于计算每幅图像的 ODD 分数，基于检测结果和真实 bounding box 之间的差异。ODD 分数可以在两种方式帮助 VOD 系统：1）选择更高精度的全局参照帧，以提高总体精度；2）作为 ODD 调度器中的指标，以消除容易检测的帧的聚合，从而加速 VOD 过程。我们的实验表明，当用于选择全局参照帧时，ODD-VOD 可以不断提高全球帧基本 VOD 模型的精度。当用于加速时，ODD-VOD 可以平均提高 FPS 值 by 73.3%，无需牺牲精度。当两者结合使用时，ODD-VOD 可以在精度和速度两个方面占据领先地位，代表了对 VOD 实际应用的一项重要进步。
</details></li>
</ul>
<hr>
<h2 id="CiteTracker-Correlating-Image-and-Text-for-Visual-Tracking"><a href="#CiteTracker-Correlating-Image-and-Text-for-Visual-Tracking" class="headerlink" title="CiteTracker: Correlating Image and Text for Visual Tracking"></a>CiteTracker: Correlating Image and Text for Visual Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11322">http://arxiv.org/abs/2308.11322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NorahGreen/CiteTracker">https://github.com/NorahGreen/CiteTracker</a></li>
<li>paper_authors: Xin Li, Yuqing Huang, Zhenyu He, Yaowei Wang, Huchuan Lu, Ming-Hsuan Yang</li>
<li>for: 提高视觉跟踪中目标模型和推理的精度，使得在目标呈现大幅变化时仍能准确跟踪。</li>
<li>methods: 提出了一种基于图像和文本的目标跟踪方法，通过图像转文本模块将目标图像区域转换为描述性文本，并通过动态描述模块适应目标变化以提高跟踪精度。</li>
<li>results: 经过了五种不同的数据集测试，并与现有方法进行比较，研究发现提出的跟踪方法在跟踪目标呈现大幅变化时表现出了优于现有方法的性能。<details>
<summary>Abstract</summary>
Existing visual tracking methods typically take an image patch as the reference of the target to perform tracking. However, a single image patch cannot provide a complete and precise concept of the target object as images are limited in their ability to abstract and can be ambiguous, which makes it difficult to track targets with drastic variations. In this paper, we propose the CiteTracker to enhance target modeling and inference in visual tracking by connecting images and text. Specifically, we develop a text generation module to convert the target image patch into a descriptive text containing its class and attribute information, providing a comprehensive reference point for the target. In addition, a dynamic description module is designed to adapt to target variations for more effective target representation. We then associate the target description and the search image using an attention-based correlation module to generate the correlated features for target state reference. Extensive experiments on five diverse datasets are conducted to evaluate the proposed algorithm and the favorable performance against the state-of-the-art methods demonstrates the effectiveness of the proposed tracking method.
</details>
<details>
<summary>摘要</summary>
现有的视觉跟踪方法通常使用图像块作为目标的参考点进行跟踪。然而，单个图像块无法提供完整和准确的目标对象概念，因为图像有限制，容易受到歧义和变化的影响，这使得跟踪目标变化具有挑战性。在这篇论文中，我们提出了CiteTracker，用于增强视觉跟踪中目标模型化和推理的方法。具体来说，我们开发了一个文本生成模块，将目标图像块转换为包含类和特征信息的详细文本描述，为目标提供了全面的参考点。此外，我们还设计了一个动态描述模块，以适应目标变化，以更有效地表示目标。然后，我们使用关注机制来关联目标描述和搜索图像，生成相关特征，用于目标状态参考。我们对五种不同的数据集进行了广泛的实验，以评估提出的算法效果。结果表明，与现有方法相比，我们的跟踪方法具有优秀的效果。
</details></li>
</ul>
<hr>
<h2 id="Using-and-Abusing-Equivariance"><a href="#Using-and-Abusing-Equivariance" class="headerlink" title="Using and Abusing Equivariance"></a>Using and Abusing Equivariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11316">http://arxiv.org/abs/2308.11316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Edixhoven, Attila Lengyel, Jan van Gemert</li>
<li>for: 学习破坏对称性的群同态卷积神经网络</li>
<li>methods: 使用抽样来学习破坏对称性，对2D旋转和反射进行研究</li>
<li>results: 发现小变化的输入维度可以使通用的网络变得相对均匀，而不是精确均匀；研究不同对称性的网络如何影响其性能，并发现在训练数据中的对称性与网络的对称性不同时，相对均匀网络可以放弃自己的对称性约束，与精确均匀网络匹配或超越它们在常用 benchmark 数据上。<details>
<summary>Abstract</summary>
In this paper we show how Group Equivariant Convolutional Neural Networks use subsampling to learn to break equivariance to their symmetries. We focus on 2D rotations and reflections and investigate the impact of broken equivariance on network performance. We show that a change in the input dimension of a network as small as a single pixel can be enough for commonly used architectures to become approximately equivariant, rather than exactly. We investigate the impact of networks not being exactly equivariant and find that approximately equivariant networks generalise significantly worse to unseen symmetries compared to their exactly equivariant counterparts. However, when the symmetries in the training data are not identical to the symmetries of the network, we find that approximately equivariant networks are able to relax their own equivariant constraints, causing them to match or outperform exactly equivariant networks on common benchmark datasets.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们展示了GROUP等变征 convolutional neural networks 如何通过抽象来学习破坏对其Symmetries的等变征性。我们关注了2D旋转和反射，并调查了不等变征性对网络性能的影响。我们发现，只需将网络输入维度改变一个像素，常用的架构就可以变得相对等变征了，而不是精确等变征。我们调查了不等变征网络在未seen Symmetries上的generalization情况，发现它们与等变征网络相比在Common benchmark datasets上匹配或超越。但当网络中的Symmetries与训练数据中的Symmetries不同时，我们发现approximately等变征网络能够放弃自己的等变征约束，使其与等变征网络在Common benchmark datasets上匹配或超越。
</details></li>
</ul>
<hr>
<h2 id="Approaching-human-3D-shape-perception-with-neurally-mappable-models"><a href="#Approaching-human-3D-shape-perception-with-neurally-mappable-models" class="headerlink" title="Approaching human 3D shape perception with neurally mappable models"></a>Approaching human 3D shape perception with neurally mappable models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11300">http://arxiv.org/abs/2308.11300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas P. O’Connell, Tyler Bonnen, Yoni Friedman, Ayush Tewari, Josh B. Tenenbaum, Vincent Sitzmann, Nancy Kanwisher</li>
<li>for: 这研究旨在理解人类如何自然地推测三维形状，以及这种能力是如何被计算机模型重建的？</li>
<li>methods: 研究使用了一种新的计算模型，即3D神经场（3D-LFN），该模型基于深度神经网络（DNN），并通过多视角训练和多视角学习目标来实现人类水平的性能。</li>
<li>results: 研究发现，3D-LFN支持人类水平的三维匹配判断，并在针对标准DNN模型的攻击性定义比较中表现出色。此外，研究还发现，通过多视角训练和多视角学习目标，even conventional DNN architectures可以更接近人类行为。但是，这些模型在处理新的物体类别时仍有所限制。<details>
<summary>Abstract</summary>
Humans effortlessly infer the 3D shape of objects. What computations underlie this ability? Although various computational models have been proposed, none of them capture the human ability to match object shape across viewpoints. Here, we ask whether and how this gap might be closed. We begin with a relatively novel class of computational models, 3D neural fields, which encapsulate the basic principles of classic analysis-by-synthesis in a deep neural network (DNN). First, we find that a 3D Light Field Network (3D-LFN) supports 3D matching judgments well aligned to humans for within-category comparisons, adversarially-defined comparisons that accentuate the 3D failure cases of standard DNN models, and adversarially-defined comparisons for algorithmically generated shapes with no category structure. We then investigate the source of the 3D-LFN's ability to achieve human-aligned performance through a series of computational experiments. Exposure to multiple viewpoints of objects during training and a multi-view learning objective are the primary factors behind model-human alignment; even conventional DNN architectures come much closer to human behavior when trained with multi-view objectives. Finally, we find that while the models trained with multi-view learning objectives are able to partially generalize to new object categories, they fall short of human alignment. This work provides a foundation for understanding human shape inferences within neurally mappable computational architectures and highlights important questions for future work.
</details>
<details>
<summary>摘要</summary>
人类努力地推断物体的3D形状。这些计算是如何进行的？虽然一些计算模型已经被提出，但None of them capture the human ability to match object shape across viewpoints。在这里，我们问whether and how this gap might be closed。我们开始于一种相对新的计算模型，3D神经场（3D-LFN），这个模型涵盖了经典分析synthesis的基本原理，并将其 embedding在深度神经网络（DNN）中。我们发现，3D-LFN支持3D匹配判断，与人类匹配的性能很高，包括在类别内的比较、对抗定义的比较和对算法生成的形状进行比较。然后，我们通过一系列计算实验来研究3D-LFN的能力是如何实现人类对应的性能的。我们发现，在训练中 expose to multiple viewpoints of objects和多视图学习目标是模型人类匹配的主要因素。甚至使用标准DNN架构，通过多视图学习目标进行训练，模型的性能就会更接近人类的行为。最后，我们发现，使用多视图学习目标训练的模型可以部分地泛化到新的物体类别，但是它们仍然不够接近人类的匹配。这个研究提供了人类形状推断在神经Mappable的计算架构中的基础，并高亮了未来工作的重要问题。
</details></li>
</ul>
<hr>
<h2 id="BHSD-A-3D-Multi-Class-Brain-Hemorrhage-Segmentation-Dataset"><a href="#BHSD-A-3D-Multi-Class-Brain-Hemorrhage-Segmentation-Dataset" class="headerlink" title="BHSD: A 3D Multi-Class Brain Hemorrhage Segmentation Dataset"></a>BHSD: A 3D Multi-Class Brain Hemorrhage Segmentation Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11298">http://arxiv.org/abs/2308.11298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biao Wu, Yutong Xie, Zeyu Zhang, Jinchao Ge, Kaspar Yaxley, Suzan Bahadir, Qi Wu, Yifan Liu, Minh-Son To</li>
<li>for: 本研究旨在提供一个3D多类血肿 segmentation dataset（BHSD），以便为血肿 segmentation任务提供支持。</li>
<li>methods: 本研究使用了深度学习技术来进行 médical image segmentation，并应用于血肿 segmentation任务。</li>
<li>results: 本研究提供了一个包含192个Volume的多类血肿数据集，以及2200个slice-level标注的数据集。通过对这些数据集进行supervised和semi-supervisedsegmentation任务的实验，我们证明了数据集的实用性。<details>
<summary>Abstract</summary>
Intracranial hemorrhage (ICH) is a pathological condition characterized by bleeding inside the skull or brain, which can be attributed to various factors. Identifying, localizing and quantifying ICH has important clinical implications, in a bleed-dependent manner. While deep learning techniques are widely used in medical image segmentation and have been applied to the ICH segmentation task, existing public ICH datasets do not support the multi-class segmentation problem. To address this, we develop the Brain Hemorrhage Segmentation Dataset (BHSD), which provides a 3D multi-class ICH dataset containing 192 volumes with pixel-level annotations and 2200 volumes with slice-level annotations across five categories of ICH. To demonstrate the utility of the dataset, we formulate a series of supervised and semi-supervised ICH segmentation tasks. We provide experimental results with state-of-the-art models as reference benchmarks for further model developments and evaluations on this dataset.
</details>
<details>
<summary>摘要</summary>
Intracranial hemorrhage (ICH) 是一种生物学条件，表示脑内或脑部内出血，这可以归因于多种因素。正确地识别、定位和评估ICH具有重要临床意义，具体取决于出血情况。although deep learning techniques have been widely used in medical image segmentation and have been applied to the ICH segmentation task, existing public ICH datasets do not support the multi-class segmentation problem. To address this, we develop the Brain Hemorrhage Segmentation Dataset (BHSD), which provides a 3D multi-class ICH dataset containing 192 volumes with pixel-level annotations and 2200 volumes with slice-level annotations across five categories of ICH. To demonstrate the utility of the dataset, we formulate a series of supervised and semi-supervised ICH segmentation tasks. We provide experimental results with state-of-the-art models as reference benchmarks for further model developments and evaluations on this dataset.Here's the word-for-word translation:Intracranial hemorrhage (ICH) 是一种生物学条件，表示脑内或脑部内出血，这可以归因于多种因素。正确地识别、定位和评估ICH具有重要临床意义，具体取决于出血情况。虽然深度学习技术已经广泛应用于医疗图像分割，并已经应用于ICH分割任务，但现有的公共ICH数据集不支持多类分割问题。为解决这个问题，我们开发了脑出血分割数据集（BHSD），该数据集包含192卷Pixel级别标注和2200卷Slice级别标注，涵盖五类ICH。为证明数据集的实用性，我们提出了一系列的超级vised和半监督ICH分割任务。我们提供了实验结果，作为参考标准模型，以便进一步的模型开发和评估。
</details></li>
</ul>
<hr>
<h2 id="PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction"><a href="#PCMC-T1-Free-breathing-myocardial-T1-mapping-with-Physically-Constrained-Motion-Correction" class="headerlink" title="PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction"></a>PCMC-T1: Free-breathing myocardial T1 mapping with Physically-Constrained Motion Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11281">http://arxiv.org/abs/2308.11281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eyal Hanania, Ilya Volovik, Lilach Barkat, Israel Cohen, Moti Freiman</li>
<li>for: The paper is focused on developing a deep-learning-based method for motion correction in free-breathing T1 mapping, which can improve the accuracy and accessibility of diffuse myocardial disease diagnosis.</li>
<li>methods: The proposed method, called PCMC-T1, incorporates a physically-constrained signal decay model into a deep-learning network to correct for motion artifacts in free-breathing T1 mapping.</li>
<li>results: PCMC-T1 was compared to baseline methods using a 5-fold experimental setup on a public dataset of 210 patients and demonstrated superior model fitting quality and clinical impact, with anatomical alignment results that were comparable to the baseline methods.<details>
<summary>Abstract</summary>
T1 mapping is a quantitative magnetic resonance imaging (qMRI) technique that has emerged as a valuable tool in the diagnosis of diffuse myocardial diseases. However, prevailing approaches have relied heavily on breath-hold sequences to eliminate respiratory motion artifacts. This limitation hinders accessibility and effectiveness for patients who cannot tolerate breath-holding. Image registration can be used to enable free-breathing T1 mapping. Yet, inherent intensity differences between the different time points make the registration task challenging. We introduce PCMC-T1, a physically-constrained deep-learning model for motion correction in free-breathing T1 mapping. We incorporate the signal decay model into the network architecture to encourage physically-plausible deformations along the longitudinal relaxation axis. We compared PCMC-T1 to baseline deep-learning-based image registration approaches using a 5-fold experimental setup on a publicly available dataset of 210 patients. PCMC-T1 demonstrated superior model fitting quality (R2: 0.955) and achieved the highest clinical impact (clinical score: 3.93) compared to baseline methods (0.941, 0.946 and 3.34, 3.62 respectively). Anatomical alignment results were comparable (Dice score: 0.9835 vs. 0.984, 0.988). Our code and trained models are available at https://github.com/eyalhana/PCMC-T1.
</details>
<details>
<summary>摘要</summary>
T1映射是一种量化核磁共振成像（qMRI）技术，已经成为诊断散布性心肺疾病的有价值工具。然而，现有的方法几乎完全依赖呼吸停止序列来消除呼吸运动 artifacts。这限制了患者的访问和效果，特别是那些无法忍受呼吸停止的患者。图像 регистраción可以使得呼吸自由T1映射成为可能。然而，内在的时刻点不同INTENSITY带来了注册任务的挑战。我们介绍PCMC-T1，一种基于物理约束的深度学习模型，用于呼吸自由T1映射中的运动 corrections。我们将信号衰减模型integrated into网络架构，以便鼓励物理可能的扭轴运动。我们与基线方法进行比较，使用一个5-fold实验设置，在公共可用的210名患者数据集上进行了测试。PCMC-T1显示出了最高的模型适应质量（R2: 0.955）和最高的临床影响（临床分数：3.93），与基线方法（0.941、0.946和3.34、3.62分别）相比。结构对应结果相似（Dice分数：0.9835 vs. 0.984、0.988）。我们的代码和训练模型可以在https://github.com/eyalhana/PCMC-T1中获得。
</details></li>
</ul>
<hr>
<h2 id="HMD-NeMo-Online-3D-Avatar-Motion-Generation-From-Sparse-Observations"><a href="#HMD-NeMo-Online-3D-Avatar-Motion-Generation-From-Sparse-Observations" class="headerlink" title="HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations"></a>HMD-NeMo: Online 3D Avatar Motion Generation From Sparse Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11261">http://arxiv.org/abs/2308.11261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadegh Aliakbarian, Fatemeh Saleh, David Collier, Pashmina Cameron, Darren Cosker</li>
<li>for: 这个论文的目的是提出一种能够生成正确和可信的全身动作，即使只有部分手部可见，以提高混合现实场景中的吸引力。</li>
<li>methods: 该论文使用了一种名为HMD-NeMo的轻量级神经网络，通过在线和实时方式预测全身动作，并使用了新的时间适应mask токен来促进合理的动作在手部不可见情况下。</li>
<li>results: 经过了广泛的分析和评估，该论文在AMASS数据集上达到了新的状态元。<details>
<summary>Abstract</summary>
Generating both plausible and accurate full body avatar motion is the key to the quality of immersive experiences in mixed reality scenarios. Head-Mounted Devices (HMDs) typically only provide a few input signals, such as head and hands 6-DoF. Recently, different approaches achieved impressive performance in generating full body motion given only head and hands signal. However, to the best of our knowledge, all existing approaches rely on full hand visibility. While this is the case when, e.g., using motion controllers, a considerable proportion of mixed reality experiences do not involve motion controllers and instead rely on egocentric hand tracking. This introduces the challenge of partial hand visibility owing to the restricted field of view of the HMD. In this paper, we propose the first unified approach, HMD-NeMo, that addresses plausible and accurate full body motion generation even when the hands may be only partially visible. HMD-NeMo is a lightweight neural network that predicts the full body motion in an online and real-time fashion. At the heart of HMD-NeMo is the spatio-temporal encoder with novel temporally adaptable mask tokens that encourage plausible motion in the absence of hand observations. We perform extensive analysis of the impact of different components in HMD-NeMo and introduce a new state-of-the-art on AMASS dataset through our evaluation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>创造真实和准确的全身人物动作是混合现实场景中质量体验的关键。头戴设备（HMD）通常只提供头和手6个自由度的输入信号。近期，不同的方法已经实现了在只有头和手信号的情况下取得了出色的表现。然而，根据我们所知，所有现有的方法均依赖于全手可见。这会导致在使用动作控制器时是可见的，但是一部分混合现实经验不使用动作控制器，而是基于自己центric的手姿跟踪。这引入了只有部分手可见的挑战，即HMD的视野限制。在这篇论文中，我们提出了第一个统一的方法，即HMD-NeMo，它可以在线和实时方式下生成真实和准确的全身动作。HMD-NeMo是一个轻量级的神经网络，它通过在线和实时方式下预测全身动作来解决部分手可见的挑战。我们对HMD-NeMo中不同组件的影响进行了广泛的分析，并通过我们的评估而提出了新的状态码。
</details></li>
</ul>
<hr>
<h2 id="Video-BagNet-short-temporal-receptive-fields-increase-robustness-in-long-term-action-recognition"><a href="#Video-BagNet-short-temporal-receptive-fields-increase-robustness-in-long-term-action-recognition" class="headerlink" title="Video BagNet: short temporal receptive fields increase robustness in long-term action recognition"></a>Video BagNet: short temporal receptive fields increase robustness in long-term action recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11249">http://arxiv.org/abs/2308.11249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ombretta/videobagnet">https://github.com/ombretta/videobagnet</a></li>
<li>paper_authors: Ombretta Strafforello, Xin Liu, Klamer Schutte, Jan van Gemert</li>
<li>for: 提高视频动作识别模型的 robustness，使其能够更好地承受视频中的子动作顺序变化。</li>
<li>methods: 对于现有的深度3D convolutional模型，我们采用了限制时间响应领域大小的方法，从而实现了模型的时间响应领域的缩小。</li>
<li>results: 我们在 sintetic 和 real-world 视频数据集上进行了实验，发现短时间响应领域的模型具有较高的 robustness，而大于17帧的时间响应领域模型具有较低的 robustness。<details>
<summary>Abstract</summary>
Previous work on long-term video action recognition relies on deep 3D-convolutional models that have a large temporal receptive field (RF). We argue that these models are not always the best choice for temporal modeling in videos. A large temporal receptive field allows the model to encode the exact sub-action order of a video, which causes a performance decrease when testing videos have a different sub-action order. In this work, we investigate whether we can improve the model robustness to the sub-action order by shrinking the temporal receptive field of action recognition models. For this, we design Video BagNet, a variant of the 3D ResNet-50 model with the temporal receptive field size limited to 1, 9, 17 or 33 frames. We analyze Video BagNet on synthetic and real-world video datasets and experimentally compare models with varying temporal receptive fields. We find that short receptive fields are robust to sub-action order changes, while larger temporal receptive fields are sensitive to the sub-action order.
</details>
<details>
<summary>摘要</summary>
previous research on long-term video action recognition relies on deep 3D-convolutional models with a large temporal receptive field (RF). we argue that these models are not always the best choice for temporal modeling in videos. a large temporal receptive field allows the model to encode the exact sub-action order of a video, which causes a performance decrease when testing videos have a different sub-action order. in this work, we investigate whether we can improve the model robustness to the sub-action order by shrinking the temporal receptive field of action recognition models. for this, we design video bagnet, a variant of the 3D ResNet-50 model with the temporal receptive field size limited to 1, 9, 17 or 33 frames. we analyze video bagnet on synthetic and real-world video datasets and experimentally compare models with varying temporal receptive fields. we find that short receptive fields are robust to sub-action order changes, while larger temporal receptive fields are sensitive to the sub-action order.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format instead.
</details></li>
</ul>
<hr>
<h2 id="Are-current-long-term-video-understanding-datasets-long-term"><a href="#Are-current-long-term-video-understanding-datasets-long-term" class="headerlink" title="Are current long-term video understanding datasets long-term?"></a>Are current long-term video understanding datasets long-term?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11244">http://arxiv.org/abs/2308.11244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ombretta/longterm_datasets">https://github.com/ombretta/longterm_datasets</a></li>
<li>paper_authors: Ombretta Strafforello, Klamer Schutte, Jan van Gemert</li>
<li>for: This paper aims to evaluate the suitability of video datasets for long-term action recognition.</li>
<li>methods: The proposed method defines long-term actions as those that cannot be recognized using solely short-term information, and tests this definition on three popular real-world datasets.</li>
<li>results: The study finds that the existing datasets can be effectively solved using shortcuts based on short-term information, and encourages researchers to use datasets that require long-term information to be solved.Here’s the simplified Chinese text for the three pieces of information:</li>
<li>for: 这篇论文目的是评估视频数据集是否适用于长期动作识别。</li>
<li>methods: 该方法定义长期动作为不能通过短期信息alone来识别的动作，并对三个实际世界数据集进行测试。</li>
<li>results: 研究发现现有数据集可以使用短期信息 shortcut 进行解决，并促使研究人员使用需要长期信息来解决的数据集。<details>
<summary>Abstract</summary>
Many real-world applications, from sport analysis to surveillance, benefit from automatic long-term action recognition. In the current deep learning paradigm for automatic action recognition, it is imperative that models are trained and tested on datasets and tasks that evaluate if such models actually learn and reason over long-term information. In this work, we propose a method to evaluate how suitable a video dataset is to evaluate models for long-term action recognition. To this end, we define a long-term action as excluding all the videos that can be correctly recognized using solely short-term information. We test this definition on existing long-term classification tasks on three popular real-world datasets, namely Breakfast, CrossTask and LVU, to determine if these datasets are truly evaluating long-term recognition. Our study reveals that these datasets can be effectively solved using shortcuts based on short-term information. Following this finding, we encourage long-term action recognition researchers to make use of datasets that need long-term information to be solved.
</details>
<details>
<summary>摘要</summary>
很多现实世界应用，从运动分析到监测，都会受益于自动长期动作识别。在当前的深度学习框架中，自动动作识别模型的训练和测试通常是基于长期信息的。在这种情况下，我们提议一种方法来评估视频集是否适用于评估长期动作识别模型。为此，我们定义长期动作为排除所有可以通过短期信息来正确地识别的视频。我们在三个流行的实际世界数据集上进行测试，分别是Breakfast、CrossTask和LVU，以确定这些数据集是否真的评估长期认知。我们的研究发现，这些数据集可以通过快捷途径基于短期信息来解决。根据这个发现，我们鼓励长期动作识别研究人员使用需要长期信息来解决的数据集。
</details></li>
</ul>
<hr>
<h2 id="LOCATE-Self-supervised-Object-Discovery-via-Flow-guided-Graph-cut-and-Bootstrapped-Self-training"><a href="#LOCATE-Self-supervised-Object-Discovery-via-Flow-guided-Graph-cut-and-Bootstrapped-Self-training" class="headerlink" title="LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and Bootstrapped Self-training"></a>LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and Bootstrapped Self-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11239">http://arxiv.org/abs/2308.11239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silky Singh, Shripad Deshmukh, Mausoom Sarkar, Balaji Krishnamurthy</li>
<li>for: 本研究旨在无需人工监督下完成图像和视频数据集中的对象分割问题。</li>
<li>methods: 我们提出了一种自动化对象发现方法，利用运动和外观信息来生成高质量的对象分割面积。我们在传统图像树剖中添加了运动信息，并与外观信息进行线性组合来生成边权。</li>
<li>results: 我们的方法在多个标准视频对象分割、图像吸引力检测和对象分割 benchmark 上达到了与现状对照的性能。我们还通过自我训练来进一步提高性能。在审查实验中，我们的方法在未知领域中的转移性也得到了证明。<details>
<summary>Abstract</summary>
Learning object segmentation in image and video datasets without human supervision is a challenging problem. Humans easily identify moving salient objects in videos using the gestalt principle of common fate, which suggests that what moves together belongs together. Building upon this idea, we propose a self-supervised object discovery approach that leverages motion and appearance information to produce high-quality object segmentation masks. Specifically, we redesign the traditional graph cut on images to include motion information in a linear combination with appearance information to produce edge weights. Remarkably, this step produces object segmentation masks comparable to the current state-of-the-art on multiple benchmarks. To further improve performance, we bootstrap a segmentation network trained on these preliminary masks as pseudo-ground truths to learn from its own outputs via self-training. We demonstrate the effectiveness of our approach, named LOCATE, on multiple standard video object segmentation, image saliency detection, and object segmentation benchmarks, achieving results on par with and, in many cases surpassing state-of-the-art methods. We also demonstrate the transferability of our approach to novel domains through a qualitative study on in-the-wild images. Additionally, we present extensive ablation analysis to support our design choices and highlight the contribution of each component of our proposed method.
</details>
<details>
<summary>摘要</summary>
学习图像和视频集合中的对象分割无人监督是一个具有挑战性的问题。人类容易通过gestalt原则的共同命运来识别视频中移动的焦点对象，这个原则表明移动 вместе的对象属于同一个集合。基于这个想法，我们提出了一种自动化对象发现方法，利用运动和外观信息生成高质量的对象分割面积。 Specifically,我们重新设计了传统的图像截割方法，在线性组合中包括运动信息和外观信息来生成边重量。这一步生成的对象分割面积与当前状态的各种标准测试 benchmark 相当。为了进一步提高性能，我们使用这些初步的面积作为 pseudo-ground truth 来自我准备一个 segmentation 网络，并通过自我训练来学习自己的输出。我们命名这种方法为 LOCATE，并在多个标准视频对象分割、图像焦点检测和对象分割 bencmarks 上实现了与和超越当前状态的方法。我们还进行了质量研究，以证明我们的方法在新领域中的传输性。此外，我们还提供了广泛的减少分析，以支持我们的设计选择，并高亮每个方法的贡献。
</details></li>
</ul>
<hr>
<h2 id="Affordance-segmentation-of-hand-occluded-containers-from-exocentric-images"><a href="#Affordance-segmentation-of-hand-occluded-containers-from-exocentric-images" class="headerlink" title="Affordance segmentation of hand-occluded containers from exocentric images"></a>Affordance segmentation of hand-occluded containers from exocentric images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11233">http://arxiv.org/abs/2308.11233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Apicella, Alessio Xompero, Edoardo Ragusa, Riccardo Berta, Andrea Cavallaro, Paolo Gastaldo</li>
<li>for: 本研究旨在解决手持物体上 occlusion 问题，提高机器人可视且抓取物体的可行性。</li>
<li>methods: 提议的模型使用辅助分支处理物体和手部分 separately，学习受 occlusion 影响的可行特征。</li>
<li>results: 实验表明，我们的模型在实际和混合现实图像上具有更好的可行分割和泛化能力，比现有模型更好。<details>
<summary>Abstract</summary>
Visual affordance segmentation identifies the surfaces of an object an agent can interact with. Common challenges for the identification of affordances are the variety of the geometry and physical properties of these surfaces as well as occlusions. In this paper, we focus on occlusions of an object that is hand-held by a person manipulating it. To address this challenge, we propose an affordance segmentation model that uses auxiliary branches to process the object and hand regions separately. The proposed model learns affordance features under hand-occlusion by weighting the feature map through hand and object segmentation. To train the model, we annotated the visual affordances of an existing dataset with mixed-reality images of hand-held containers in third-person (exocentric) images. Experiments on both real and mixed-reality images show that our model achieves better affordance segmentation and generalisation than existing models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Visual affordance segmentation 可以识别物体上可互动的表面。常见的挑战是物体表面的多样性和物理特性以及遮挡。在这篇论文中，我们专注于人手持物体时的遮挡问题。为解决这个挑战，我们提议一种基于辅助分支的可互动分割模型。该模型通过对手和物体区域进行分割来学习可互动特征。通过对手和物体分割来权重特征图，以便在手遮挡情况下学习可互动特征。我们使用混合现实图像的混合现实数据集进行训练。实验表明，我们的模型在实际和混合现实图像上的可互动分割和泛化性比较好。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="LDP-Feat-Image-Features-with-Local-Differential-Privacy"><a href="#LDP-Feat-Image-Features-with-Local-Differential-Privacy" class="headerlink" title="LDP-Feat: Image Features with Local Differential Privacy"></a>LDP-Feat: Image Features with Local Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11223">http://arxiv.org/abs/2308.11223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Pittaluga, Bingbing Zhuang</li>
<li>for: 保护隐私，防止恶意攻击者通过图像特征恢复原始图像</li>
<li>methods: 使用嵌入式法律空间和对抗性特征样本来隐藏图像特征，并提出了两种新的倒转攻击来缓解隐私风险</li>
<li>results: 实现了在保护隐私的情况下具有强大的视觉本地化性能，并提供了一种基于地方散布隐私的方法，这种方法可以提供固定的隐私泄露 bound，不受攻击强度的影响<details>
<summary>Abstract</summary>
Modern computer vision services often require users to share raw feature descriptors with an untrusted server. This presents an inherent privacy risk, as raw descriptors may be used to recover the source images from which they were extracted. To address this issue, researchers recently proposed privatizing image features by embedding them within an affine subspace containing the original feature as well as adversarial feature samples. In this paper, we propose two novel inversion attacks to show that it is possible to (approximately) recover the original image features from these embeddings, allowing us to recover privacy-critical image content. In light of such successes and the lack of theoretical privacy guarantees afforded by existing visual privacy methods, we further propose the first method to privatize image features via local differential privacy, which, unlike prior approaches, provides a guaranteed bound for privacy leakage regardless of the strength of the attacks. In addition, our method yields strong performance in visual localization as a downstream task while enjoying the privacy guarantee.
</details>
<details>
<summary>摘要</summary>
现代计算机视觉服务经常需要用户将原始特征描述分发到不可信服务器。这会导致隐私风险，因为原始特征可能可以用来恢复源图像。为解决这问题，研究人员最近提出了嵌入图像特征的私有化方法，以确保图像内容的隐私。在这篇论文中，我们提出了两种新的反向攻击，以示它们可以（相对）回归原始图像特征，从而恢复隐私关键的图像内容。另外，我们还提出了首个基于本地差分隐私的图像特征隐私方法，与先前的方法不同，它提供了隐私泄露的保证，无论攻击者的强度如何。此外，我们的方法在视觉本地化任务中具有强表现力，同时享有隐私保证。
</details></li>
</ul>
<hr>
<h2 id="DiffCloth-Diffusion-Based-Garment-Synthesis-and-Manipulation-via-Structural-Cross-modal-Semantic-Alignment"><a href="#DiffCloth-Diffusion-Based-Garment-Synthesis-and-Manipulation-via-Structural-Cross-modal-Semantic-Alignment" class="headerlink" title="DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment"></a>DiffCloth: Diffusion Based Garment Synthesis and Manipulation via Structural Cross-modal Semantic Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11206">http://arxiv.org/abs/2308.11206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xujie Zhang, Binbin Yang, Michael C. Kampffmeyer, Wenqing Zhang, Shiyue Zhang, Guansong Lu, Liang Lin, Hang Xu, Xiaodan Liang</li>
<li>for: 这个论文旨在提高模式融合和修改的方式，帮助时尚设计师更加方便地生成和修改他们的设计。</li>
<li>methods: 这个论文使用了DiffCloth，一种扩展了Diffusion-based管道，通过strucurally aligning cross-modal semantics来强化 diffusion models的可 composeability。</li>
<li>results:  experiments on CM-Fashion benchmark demonstrate that DiffCloth can both yield state-of-the-art garment synthesis results and support flexible manipulation with region consistency.<details>
<summary>Abstract</summary>
Cross-modal garment synthesis and manipulation will significantly benefit the way fashion designers generate garments and modify their designs via flexible linguistic interfaces.Current approaches follow the general text-to-image paradigm and mine cross-modal relations via simple cross-attention modules, neglecting the structural correspondence between visual and textual representations in the fashion design domain. In this work, we instead introduce DiffCloth, a diffusion-based pipeline for cross-modal garment synthesis and manipulation, which empowers diffusion models with flexible compositionality in the fashion domain by structurally aligning the cross-modal semantics. Specifically, we formulate the part-level cross-modal alignment as a bipartite matching problem between the linguistic Attribute-Phrases (AP) and the visual garment parts which are obtained via constituency parsing and semantic segmentation, respectively. To mitigate the issue of attribute confusion, we further propose a semantic-bundled cross-attention to preserve the spatial structure similarities between the attention maps of attribute adjectives and part nouns in each AP. Moreover, DiffCloth allows for manipulation of the generated results by simply replacing APs in the text prompts. The manipulation-irrelevant regions are recognized by blended masks obtained from the bundled attention maps of the APs and kept unchanged. Extensive experiments on the CM-Fashion benchmark demonstrate that DiffCloth both yields state-of-the-art garment synthesis results by leveraging the inherent structural information and supports flexible manipulation with region consistency.
</details>
<details>
<summary>摘要</summary>
cross-modal 服装合成和修改将会对时尚设计师如何生成服装和修改他们的设计进行深见改进，通过灵活的语言接口。目前的方法采用通用的文本到图像模式，通过简单的跨模态关系抽象模块，忽略了时尚设计领域中的视觉表示结构匹配。在这个工作中，我们发展了DiffCloth，一种基于扩散的渠道管道，用于跨模态服装合成和修改，具有时尚领域的可 compose 性。具体来说，我们将部级跨模态匹配问题定义为语言特征短语（AP）和视觉服装部分之间的对应问题，并通过分词分析和 semantic segmentation 获得视觉服装部分。为了解决特征混淆问题，我们还提出了一种 semantic-bundled 跨注意力，以保持每个AP的注意力地图之间的空间结构相似性。此外，DiffCloth 支持通过简单地更换文本提示中的AP来进行 manipulate 操作，并且识别并保持不变的混合mask。广泛的实验表明，DiffCloth 可以利用内置的结构信息，同时支持灵活的 manipulate 操作，并保持区域一致性。
</details></li>
</ul>
<hr>
<h2 id="Masked-Cross-image-Encoding-for-Few-shot-Segmentation"><a href="#Masked-Cross-image-Encoding-for-Few-shot-Segmentation" class="headerlink" title="Masked Cross-image Encoding for Few-shot Segmentation"></a>Masked Cross-image Encoding for Few-shot Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11201">http://arxiv.org/abs/2308.11201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenbo Xu, Huaxi Huang, Ming Cheng, Litao Yu, Qiang Wu, Jian Zhang</li>
<li>for: 这个论文旨在提高几张支持图像上的几个类别的描述，使用少量标注图像进行推断。</li>
<li>methods: 该方法使用Masked Cross-Image Encoding（MCE）来捕捉对象细节的共同视觉特征，以及图像之间的相互依赖关系。</li>
<li>results: 实验表明，该方法在PASCAL-$5^i$和COCO-$20^i$中表现出色，可以快速学习新类别，并且对于描述对象细节的任务有进一步的改进。<details>
<summary>Abstract</summary>
Few-shot segmentation (FSS) is a dense prediction task that aims to infer the pixel-wise labels of unseen classes using only a limited number of annotated images. The key challenge in FSS is to classify the labels of query pixels using class prototypes learned from the few labeled support exemplars. Prior approaches to FSS have typically focused on learning class-wise descriptors independently from support images, thereby ignoring the rich contextual information and mutual dependencies among support-query features. To address this limitation, we propose a joint learning method termed Masked Cross-Image Encoding (MCE), which is designed to capture common visual properties that describe object details and to learn bidirectional inter-image dependencies that enhance feature interaction. MCE is more than a visual representation enrichment module; it also considers cross-image mutual dependencies and implicit guidance. Experiments on FSS benchmarks PASCAL-$5^i$ and COCO-$20^i$ demonstrate the advanced meta-learning ability of the proposed method.
</details>
<details>
<summary>摘要</summary>
几个例图分类（FSS）是一种密集预测任务，旨在只使用有限数量的标注图像来预测未经看过的类别。关键挑战在FSS中是将查询像素的标签分类用支持图像中学习的类 prototype。现有的FSS方法通常是独立地从支持图像中学习类Descriptor，从而忽略了支持图像和查询图像之间的丰富Contextual information和相互依赖关系。为了解决这一限制，我们提出了一种联合学习方法，称为Masked Cross-Image Encoding（MCE），旨在捕捉对象细节中的共同视觉特性，以及在支持图像和查询图像之间的双向依赖关系。MCE不仅是一种视觉表示增强模块，还考虑了图像之间的相互依赖关系和隐藏导航。在PASCAL-$5^i$和COCO-$20^i$的FSS标准测试集上，我们的提议方法表现出了更高级的元学习能力。
</details></li>
</ul>
<hr>
<h2 id="Novel-view-Synthesis-and-Pose-Estimation-for-Hand-Object-Interaction-from-Sparse-Views"><a href="#Novel-view-Synthesis-and-Pose-Estimation-for-Hand-Object-Interaction-from-Sparse-Views" class="headerlink" title="Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views"></a>Novel-view Synthesis and Pose Estimation for Hand-Object Interaction from Sparse Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11198">http://arxiv.org/abs/2308.11198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentian Qu, Zhaopeng Cui, Yinda Zhang, Chenyu Meng, Cuixia Ma, Xiaoming Deng, Hongan Wang</li>
<li>for: 这个论文主要是关于手对象交互的理解和生成三维手对象交互的方法。</li>
<li>methods: 该论文提出了一种基于神经网络的渲染和姿态估计系统，用于从稀疏视图中理解手对象交互。该系统还可以实现3D手对象交互编辑。</li>
<li>results: 实验表明，该方法比前州艺术法具有更高的性能。Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这个论文主要是关于手对象交互的理解和生成三维手对象交互的方法。</li>
<li>methods: 该论文提出了一种基于神经网络的渲染和姿态估计系统，用于从稀疏视图中理解手对象交互。该系统还可以实现3D手对象交互编辑。</li>
<li>results: 实验表明，该方法比前州艺术法具有更高的性能。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Hand-object interaction understanding and the barely addressed novel view synthesis are highly desired in the immersive communication, whereas it is challenging due to the high deformation of hand and heavy occlusions between hand and object. In this paper, we propose a neural rendering and pose estimation system for hand-object interaction from sparse views, which can also enable 3D hand-object interaction editing. We share the inspiration from recent scene understanding work that shows a scene specific model built beforehand can significantly improve and unblock vision tasks especially when inputs are sparse, and extend it to the dynamic hand-object interaction scenario and propose to solve the problem in two stages. We first learn the shape and appearance prior knowledge of hands and objects separately with the neural representation at the offline stage. During the online stage, we design a rendering-based joint model fitting framework to understand the dynamic hand-object interaction with the pre-built hand and object models as well as interaction priors, which thereby overcomes penetration and separation issues between hand and object and also enables novel view synthesis. In order to get stable contact during the hand-object interaction process in a sequence, we propose a stable contact loss to make the contact region to be consistent. Experiments demonstrate that our method outperforms the state-of-the-art methods. Code and dataset are available in project webpage https://iscas3dv.github.io/HO-NeRF.
</details>
<details>
<summary>摘要</summary>
手动对象交互理解和 hardly addressed 新视图合成是 immerse 通信中的高优先级需求，但是受到手动对象的高变形和对手与对象的 occlusion 的影响，是一个挑战。在这篇论文中，我们提出了一种基于 neural 渲染和 pose 估计的手动对象交互从稀疏视图系统，可以帮助解决3D 手动对象交互编辑问题。我们 draw 了 scene 理解工作的 inspirations，使用 scene 特定模型在 offline 阶段学习手动对象交互的 shape 和 appearance 特征，然后在 online 阶段使用 rendering-based joint 模型来理解动态手动对象交互，并且通过 pre-built 手和对象模型以及交互 prior 来解决 penetration 和 separation 问题，并实现 novel view synthesis。为了在手动对象交互过程中保持稳定的 contacts，我们提出了一种稳定 contact loss。实验表明，我们的方法超过了现有方法的性能。代码和数据集可以在项目网站 https://iscas3dv.github.io/HO-NeRF 中获取。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Aware-Prompt-Tuning-for-Generalizable-Vision-Language-Models"><a href="#Knowledge-Aware-Prompt-Tuning-for-Generalizable-Vision-Language-Models" class="headerlink" title="Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models"></a>Knowledge-Aware Prompt Tuning for Generalizable Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11186">http://arxiv.org/abs/2308.11186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baoshuo Kan, Teng Wang, Wenpeng Lu, Xiantong Zhen, Weili Guan, Feng Zheng</li>
<li>for: 这篇论文旨在提出一种基于人工知识的潜在图像分类模型，以提高图像分类器的泛化能力。</li>
<li>methods: 该方法使用两种不同类型的知识感知提问，一种是精确提取对象类型的描述信息，另一种是通过学习获得总上下文信息。此外，还设计了一个适应头来归一化重要视觉特征。</li>
<li>results: 对11种广泛使用的基准数据集进行了广泛的实验，结果表明，KAPT方法可以在少量样本下进行图像分类，特别是在新类别上具有泛化能力。与当前最佳方法CoCoOp相比，KAPT方法在新类别上显示了有利的性能，升准值为3.22%和2.57%。<details>
<summary>Abstract</summary>
Pre-trained vision-language models, e.g., CLIP, working with manually designed prompts have demonstrated great capacity of transfer learning. Recently, learnable prompts achieve state-of-the-art performance, which however are prone to overfit to seen classes, failing to generalize to unseen classes. In this paper, we propose a Knowledge-Aware Prompt Tuning (KAPT) framework for vision-language models. Our approach takes inspiration from human intelligence in which external knowledge is usually incorporated into recognizing novel categories of objects. Specifically, we design two complementary types of knowledge-aware prompts for the text encoder to leverage the distinctive characteristics of category-related external knowledge. The discrete prompt extracts the key information from descriptions of an object category, and the learned continuous prompt captures overall contexts. We further design an adaptation head for the visual encoder to aggregate salient attentive visual cues, which establishes discriminative and task-aware visual representations. We conduct extensive experiments on 11 widely-used benchmark datasets and the results verify the effectiveness in few-shot image classification, especially in generalizing to unseen categories. Compared with the state-of-the-art CoCoOp method, KAPT exhibits favorable performance and achieves an absolute gain of 3.22% on new classes and 2.57% in terms of harmonic mean.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的视觉语言模型，如CLIP，通过手动设计的提示符可以实现很好的转移学习效果。然而，这些提示符容易过拟合已经看过的类别，导致无法泛化到未看过的类别。在这篇论文中，我们提出了一个知识感知提示调整（KAPT）框架，用于视觉语言模型。我们的方法启取人类智能中在识别新类别对象时，通常会 incorporate 外部知识。我们设计了两种强调知识的提示符，一种是精确提取对象类别的描述信息，另一种是学习对象上的总上下文。此外，我们还设计了一个适应头，用于Visual encoder 中的视觉特征汇聚，以建立特异性和任务意识的视觉表示。我们对11种广泛使用的 benchmark 数据集进行了广泛的实验，结果证明了我们的方法的有效性，特别是在新类别上的泛化。相比之下，与状态之arte CoCoOp 方法相比，KAPT 表现更加优秀，在新类别上实现了3.22%的绝对提升和2.57%的harmonic mean。
</details></li>
</ul>
<hr>
<h2 id="MEGA-Multimodal-Alignment-Aggregation-and-Distillation-For-Cinematic-Video-Segmentation"><a href="#MEGA-Multimodal-Alignment-Aggregation-and-Distillation-For-Cinematic-Video-Segmentation" class="headerlink" title="MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation"></a>MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11185">http://arxiv.org/abs/2308.11185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Najmeh Sadoughi, Xinyu Li, Avijit Vajpayee, David Fan, Bing Shuai, Hector Santos-Villalobos, Vimal Bhat, Rohith MV</li>
<li>for: 本研究旨在提高长形视频（&gt;60分钟）的场景和剧情槽分 segmentation 效果。</li>
<li>methods: 本研究提出了一种基于多媒体Modalities的 Multimodal alignmEnt aGgregation and distillAtion（MEGA）方法，通过多种输入的粗略对应和模式维度的嵌入来解决长形视频的同步问题。</li>
<li>results: 实验结果表明，MEGA方法在 MovieNet 数据集上场景分 segmentation  Task 上提高了+1.19%的平均准确率，并在 TRIPOD 数据集上剧情分 segmentation  Task 上提高了+5.51%的总一致率。<details>
<summary>Abstract</summary>
Previous research has studied the task of segmenting cinematic videos into scenes and into narrative acts. However, these studies have overlooked the essential task of multimodal alignment and fusion for effectively and efficiently processing long-form videos (>60min). In this paper, we introduce Multimodal alignmEnt aGgregation and distillAtion (MEGA) for cinematic long-video segmentation. MEGA tackles the challenge by leveraging multiple media modalities. The method coarsely aligns inputs of variable lengths and different modalities with alignment positional encoding. To maintain temporal synchronization while reducing computation, we further introduce an enhanced bottleneck fusion layer which uses temporal alignment. Additionally, MEGA employs a novel contrastive loss to synchronize and transfer labels across modalities, enabling act segmentation from labeled synopsis sentences on video shots. Our experimental results show that MEGA outperforms state-of-the-art methods on MovieNet dataset for scene segmentation (with an Average Precision improvement of +1.19%) and on TRIPOD dataset for act segmentation (with a Total Agreement improvement of +5.51%)
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ReFit-Recurrent-Fitting-Network-for-3D-Human-Recovery"><a href="#ReFit-Recurrent-Fitting-Network-for-3D-Human-Recovery" class="headerlink" title="ReFit: Recurrent Fitting Network for 3D Human Recovery"></a>ReFit: Recurrent Fitting Network for 3D Human Recovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11184">http://arxiv.org/abs/2308.11184</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yufu-wang/ReFit">https://github.com/yufu-wang/ReFit</a></li>
<li>paper_authors: Yufu Wang, Kostas Daniilidis</li>
<li>for: 本研究旨在提出一种基于神经网络的单影像参数3D人体重建方法，以解决人体重建问题。</li>
<li>methods: 本方法使用反馈更新循环，通过在每个迭代步骤中将人体模型中的关键点投影到特征图中，并使用回归型更新器来调整模型以更好地适应图像。</li>
<li>results: 本研究表明，使用反馈更新循环可以更快速地训练神经网络模型，同时提高了标准benchmark测试数据集上的性能。此外，本方法还可以应用于多视图适应和单视图形状适应等其他优化设定。<details>
<summary>Abstract</summary>
We present Recurrent Fitting (ReFit), a neural network architecture for single-image, parametric 3D human reconstruction. ReFit learns a feedback-update loop that mirrors the strategy of solving an inverse problem through optimization. At each iterative step, it reprojects keypoints from the human model to feature maps to query feedback, and uses a recurrent-based updater to adjust the model to fit the image better. Because ReFit encodes strong knowledge of the inverse problem, it is faster to train than previous regression models. At the same time, ReFit improves state-of-the-art performance on standard benchmarks. Moreover, ReFit applies to other optimization settings, such as multi-view fitting and single-view shape fitting. Project website: https://yufu-wang.github.io/refit_humans/
</details>
<details>
<summary>摘要</summary>
我们介绍Recurrent Fitting（ReFit），一个神经网络架构，用于单一图像、Parametric 3D人体重建。ReFit学习了一个反馈-更新循环，与解析问题的解决策略相似。在每个迭代步骤中，它将人体模型中的关键点投射到特征对称中，以查询反馈，并使用回归型更新器进行调整，以更好地适应图像。由于ReFit传递强大的倒数问题知识，因此它在训练时比前一代 regression 模型更快。同时，ReFit在标准参考数据上提高了现场性能。此外，ReFit可以应用到其他优化设定，例如多视点适摄和单视点形状适摄。相关网站：https://yufu-wang.github.io/refit_humans/
</details></li>
</ul>
<hr>
<h2 id="A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology"><a href="#A-three-in-one-bottom-up-framework-for-simultaneous-semantic-segmentation-instance-segmentation-and-classification-of-multi-organ-nuclei-in-digital-cancer-histology" class="headerlink" title="A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology"></a>A three in one bottom-up framework for simultaneous semantic segmentation, instance segmentation and classification of multi-organ nuclei in digital cancer histology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11179">http://arxiv.org/abs/2308.11179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibtihaj Ahmad, Syed Muhammad Israr, Zain Ul Islam<br>for: 这paper是用于同时进行核体分割和分类的数字 histology 的研究，它们在计算机协助癌症诊断中扮演着关键的角色，但是这个问题仍然是一个挑战。methods: 这paper使用了一种多头decoder的结构，其中每个头都有独立的权重损失函数，用于生成核体分割、边提议和分类地图。这些输出被用来进行后处理，生成最终的核体分割和分类结果。results: 该paper实现了高性能的核体分割和分类，其中semantic segmentation的Dice score为0.841，实例 segmentation的bPQ score为0.713，和nuclei classification的mPQ score为0.633。此外，该方法在19种组织中得到了普适性。<details>
<summary>Abstract</summary>
Simultaneous segmentation and classification of nuclei in digital histology play an essential role in computer-assisted cancer diagnosis; however, it remains challenging. The highest achieved binary and multi-class Panoptic Quality (PQ) remains as low as 0.68 bPQ and 0.49 mPQ, respectively. It is due to the higher staining variability, variability across the tissue, rough clinical conditions, overlapping nuclei, and nuclear class imbalance. The generic deep-learning methods usually rely on end-to-end models, which fail to address these problems associated explicitly with digital histology. In our previous work, DAN-NucNet, we resolved these issues for semantic segmentation with an end-to-end model. This work extends our previous model to simultaneous instance segmentation and classification. We introduce additional decoder heads with independent weighted losses, which produce semantic segmentation, edge proposals, and classification maps. We use the outputs from the three-head model to apply post-processing to produce the final segmentation and classification. Our multi-stage approach utilizes edge proposals and semantic segmentations compared to direct segmentation and classification strategies followed by most state-of-the-art methods. Due to this, we demonstrate a significant performance improvement in producing high-quality instance segmentation and nuclei classification. We have achieved a 0.841 Dice score for semantic segmentation, 0.713 bPQ scores for instance segmentation, and 0.633 mPQ for nuclei classification. Our proposed framework is generalized across 19 types of tissues. Furthermore, the framework is less complex compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
同时分割和分类肿瘤细胞在数字 histology 中扮演着重要的角色，但是它仍然是一个挑战。最高的二分和多分类 Panoptic Quality (PQ) 只有0.68 bPQ和0.49 mPQ，这是因为细胞染色的变化、组织内部的变化、较为恶劣的临床条件、重叠的细胞和核类别偏度。通用的深度学习方法通常采用端到端模型，这些模型无法直接地解决数字 histology 中相关的问题。在我们的前一个工作中，我们提出了 DAN-NucNet 模型，解决了这些问题。本文将 extend 我们的前一个模型，以实现同时的实例分割和分类。我们添加了多个解码头，每个解码头都有独立的权重损失，它们生成的结果包括semantic segmentation、edge proposal 和分类图像。我们使用这些三个头的输出来进行后处理，以生成最终的分割和分类结果。我们的多阶段方法利用了 edge proposal 和 semantic segmentation，而不是直接进行分割和分类的方法，这使得我们可以提高高质量的实例分割和核类分类。我们在19种组织中实现了0.841 Dice 分割率、0.713 bPQ 分割率和0.633 mPQ 分类率。我们提出的框架比现有的状态之一更加简单。
</details></li>
</ul>
<hr>
<h2 id="Improving-Misaligned-Multi-modality-Image-Fusion-with-One-stage-Progressive-Dense-Registration"><a href="#Improving-Misaligned-Multi-modality-Image-Fusion-with-One-stage-Progressive-Dense-Registration" class="headerlink" title="Improving Misaligned Multi-modality Image Fusion with One-stage Progressive Dense Registration"></a>Improving Misaligned Multi-modality Image Fusion with One-stage Progressive Dense Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11165">http://arxiv.org/abs/2308.11165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Wang, Jinyuan Liu, Long Ma, Risheng Liu, Xin Fan</li>
<li>for:  addressing the challenges of misalignments between multi-modality images in image fusion</li>
<li>methods: 一种Cross-modality Multi-scale Progressive Dense Registration (C-MPDR) scheme, which uses a one-stage optimization to improve the fusion performance of misaligned multi-modality images</li>
<li>results: 提高了多模态图像匹配的混合性能<details>
<summary>Abstract</summary>
Misalignments between multi-modality images pose challenges in image fusion, manifesting as structural distortions and edge ghosts. Existing efforts commonly resort to registering first and fusing later, typically employing two cascaded stages for registration,i.e., coarse registration and fine registration. Both stages directly estimate the respective target deformation fields. In this paper, we argue that the separated two-stage registration is not compact, and the direct estimation of the target deformation fields is not accurate enough. To address these challenges, we propose a Cross-modality Multi-scale Progressive Dense Registration (C-MPDR) scheme, which accomplishes the coarse-to-fine registration exclusively using a one-stage optimization, thus improving the fusion performance of misaligned multi-modality images. Specifically, two pivotal components are involved, a dense Deformation Field Fusion (DFF) module and a Progressive Feature Fine (PFF) module. The DFF aggregates the predicted multi-scale deformation sub-fields at the current scale, while the PFF progressively refines the remaining misaligned features. Both work together to accurately estimate the final deformation fields. In addition, we develop a Transformer-Conv-based Fusion (TCF) subnetwork that considers local and long-range feature dependencies, allowing us to capture more informative features from the registered infrared and visible images for the generation of high-quality fused images. Extensive experimental analysis demonstrates the superiority of the proposed method in the fusion of misaligned cross-modality images.
</details>
<details>
<summary>摘要</summary>
《多Modalität图像误差问题在图像融合中带来挑战，导致结构扭曲和边幻影。现有尝试通常采用分两个阶段进行 регистрирование，即粗略 регистрирование和精细 регистрирование，两个阶段直接估计目标扭曲场。在这篇论文中，我们认为分开的两个阶段 регистрирование不是 компакт的，而直接估计目标扭曲场也不够精确。为了解决这些挑战，我们提出了一种交叉模态多尺度进行密度注registratin（C-MPDR）方案，通过一个单一的优化过程，提高误差的多模态图像融合性能。具体来说，这种方案包括两个关键组件：一个密集的Deformation Field Fusion（DFF）模块和一个进行进行精细调整的Progressive Feature Fine（PFF）模块。DFF模块将在当前级别预测多尺度扭曲子场，而PFF模块将逐渐调整剩下的误差特征。两个模块共同帮助估计最终的扭曲场。此外，我们还开发了基于Transformer-Conv的融合（TCF）子网络，该子网络考虑了本地和远程特征依赖关系，使我们能够更好地捕捉融合后的高质量混合图像中的有用特征。广泛的实验分析表明，我们提出的方法在跨模态图像融合中具有显著的优势。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Decoupled-Contrastive-Multi-view-Clustering-with-High-order-Random-Walks"><a href="#Decoupled-Contrastive-Multi-view-Clustering-with-High-order-Random-Walks" class="headerlink" title="Decoupled Contrastive Multi-view Clustering with High-order Random Walks"></a>Decoupled Contrastive Multi-view Clustering with High-order Random Walks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11164">http://arxiv.org/abs/2308.11164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiding Lu, Yijie Lin, Mouxing Yang, Dezhong Peng, Peng Hu, Xi Peng</li>
<li>for: 提高多视图集群（MvC）的稳定性和抗衰落性，解决false negative和false positive问题。</li>
<li>methods: 提出了一种新的多视图集群方法（DIVIDE），通过随机游走进行全球性地标识数据对，从而可以正确地标识内部负样本和外部正样本。同时，DIVIDE采用了一种新的多视图集群架构，在不同的嵌入空间进行对比学习，以提高集群性能和抗衰落性。</li>
<li>results: 通过对四个标准测试集进行广泛的实验，证明了DIVIDE在完整的MvC设定下和缺失视图的MvC设定下都有较高的性能，并且在不同的缺失视图情况下保持稳定性。<details>
<summary>Abstract</summary>
In recent, some robust contrastive multi-view clustering (MvC) methods have been proposed, which construct data pairs from neighborhoods to alleviate the false negative issue, i.e., some intra-cluster samples are wrongly treated as negative pairs. Although promising performance has been achieved by these methods, the false negative issue is still far from addressed and the false positive issue emerges because all in- and out-of-neighborhood samples are simply treated as positive and negative, respectively. To address the issues, we propose a novel robust method, dubbed decoupled contrastive multi-view clustering with high-order random walks (DIVIDE). In brief, DIVIDE leverages random walks to progressively identify data pairs in a global instead of local manner. As a result, DIVIDE could identify in-neighborhood negatives and out-of-neighborhood positives. Moreover, DIVIDE embraces a novel MvC architecture to perform inter- and intra-view contrastive learning in different embedding spaces, thus boosting clustering performance and embracing the robustness against missing views. To verify the efficacy of DIVIDE, we carry out extensive experiments on four benchmark datasets comparing with nine state-of-the-art MvC methods in both complete and incomplete MvC settings.
</details>
<details>
<summary>摘要</summary>
近些年，一些强大的多视图决定 clustering（MvC）方法被提出，这些方法从邻居中构建数据对以解决内部样本被错误地视为负对的问题。 although these methods have achieved promising performance, the false negative issue is still not fully addressed, and a new issue has emerged, i.e., false positives, because all in- and out-of-neighborhood samples are simply treated as positive and negative, respectively. To address these issues, we propose a novel robust method, called decoupled contrastive multi-view clustering with high-order random walks (DIVIDE).DIVIDE 方法利用Random Walk来逐渐标识全球的数据对，而不是局部的方法。 As a result, DIVIDE could identify in-neighborhood negatives and out-of-neighborhood positives. 更over, DIVIDE 方法采用一种新的MvC架构，以进行不同的嵌入空间中的对比学习，从而提高划分性和对缺失视图的抗性。 To verify the effectiveness of DIVIDE, we conduct extensive experiments on four benchmark datasets, comparing with nine state-of-the-art MvC methods in both complete and incomplete MvC settings.
</details></li>
</ul>
<hr>
<h2 id="A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks"><a href="#A-Preliminary-Investigation-into-Search-and-Matching-for-Tumour-Discrimination-in-WHO-Breast-Taxonomy-Using-Deep-Networks" class="headerlink" title="A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks"></a>A Preliminary Investigation into Search and Matching for Tumour Discrimination in WHO Breast Taxonomy Using Deep Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11162">http://arxiv.org/abs/2308.11162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abubakr Shafique, Ricardo Gonzalez, Liron Pantanowitz, Puay Hoon Tan, Alberto Machado, Ian A Cree, Hamid R. Tizhoosh</li>
<li>for: 这项研究旨在开发一个基于深度学习的搜索able数字Atlas，用于帮助病理学家对悉数据库中的罕见癌症进行查找和匹配。</li>
<li>methods: 该研究使用了一个国际知名的TCGA数据库，并使用了一个国际顶尖的深度学习模型，对 millions of diagnostic histopathology images进行了预训练。然后，对WHO乳腺分类系统（第5版）中的35种肿瘤类型进行了索引和分析，并使用了深度特征来Visualize所有肿瘤类型。</li>
<li>results: 该研究发现，使用深度学习模型对WHO乳腺分类系统数据进行索引和分析，可以达到88%的准确率，并且使用top-n肿瘤类型进行验证可以达到91%的准确率。这些结果表明，使用索引数字Archive可以investigate complex relationships among common and rare breast lesions。<details>
<summary>Abstract</summary>
Breast cancer is one of the most common cancers affecting women worldwide. They include a group of malignant neoplasms with a variety of biological, clinical, and histopathological characteristics. There are more than 35 different histological forms of breast lesions that can be classified and diagnosed histologically according to cell morphology, growth, and architecture patterns. Recently, deep learning, in the field of artificial intelligence, has drawn a lot of attention for the computerized representation of medical images. Searchable digital atlases can provide pathologists with patch matching tools allowing them to search among evidently diagnosed and treated archival cases, a technology that may be regarded as computational second opinion. In this study, we indexed and analyzed the WHO breast taxonomy (Classification of Tumours 5th Ed.) spanning 35 tumour types. We visualized all tumour types using deep features extracted from a state-of-the-art deep learning model, pre-trained on millions of diagnostic histopathology images from the TCGA repository. Furthermore, we test the concept of a digital "atlas" as a reference for search and matching with rare test cases. The patch similarity search within the WHO breast taxonomy data reached over 88% accuracy when validating through "majority vote" and more than 91% accuracy when validating using top-n tumour types. These results show for the first time that complex relationships among common and rare breast lesions can be investigated using an indexed digital archive.
</details>
<details>
<summary>摘要</summary>
乳癌是全球女性最常见的恶性肿瘤之一，其包括多种生物学、临床和 histopathological 特征的肿瘤。有超过35种不同的乳腺病变可以根据细胞形态、生长和建筑模式进行分类和诊断。近些年来，人工智能技术中的深度学习在医疗领域得到了广泛的关注，特别是在计算机化的医疗图像 Representation 方面。搜索able digital atlas 可以为病理学家提供一个搜索和匹配已诊断和治疗的档案库，这种技术可以视为计算机化的第二次诊断。本研究对 WHO 乳腺分类（第5版）进行了索引和分析，包括35种肿瘤类型。我们使用了一个国际上最新的深度学习模型，该模型在TCGA 数据库上进行了 millions 个诊断 Histopathology 图像的预处理，然后对所有肿瘤类型进行了深度特征提取和可视化。此外，我们还测试了一个数字"atlas"作为参考，用于搜索和匹配罕见案例。在 WHO 乳腺分类数据中进行了质心精度搜索，结果表明，使用 "多数投票" 验证的精度高达88%，使用 top-n 肿瘤类型验证的精度高达91%。这些结果表明，使用索引数字档案库，可以 investigate Complex relationships among common and rare breast lesions.
</details></li>
</ul>
<hr>
<h2 id="SwinV2DNet-Pyramid-and-Self-Supervision-Compounded-Feature-Learning-for-Remote-Sensing-Images-Change-Detection"><a href="#SwinV2DNet-Pyramid-and-Self-Supervision-Compounded-Feature-Learning-for-Remote-Sensing-Images-Change-Detection" class="headerlink" title="SwinV2DNet: Pyramid and Self-Supervision Compounded Feature Learning for Remote Sensing Images Change Detection"></a>SwinV2DNet: Pyramid and Self-Supervision Compounded Feature Learning for Remote Sensing Images Change Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11159">http://arxiv.org/abs/2308.11159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dalong Zheng, Zebin Wu, Jia Liu, Zhihui Wei</li>
<li>for: 本研究旨在提出一种综合厚度网络（SwinV2DNet），以综合利用 transformer 和 CNN 的优点，解决现有网络在特征学习中的缺陷。</li>
<li>methods: 该网络包括 Swin V2 和 VGG16 两部分，通过 densely connected 的 Swin V2 脊梁和 CNN 分支，捕捉到 cambio 关系特征，并通过 mixed feature pyramid (MFP) 提供了多层次和协调的特征学习。</li>
<li>results: 对四个常用的公共遥感数据集进行比较，该网络可以达到state-of-the-art 的变化检测分数和细化变化地图，并且通过自我监督策略提高了 CNN 分支的训练问题。<details>
<summary>Abstract</summary>
Among the current mainstream change detection networks, transformer is deficient in the ability to capture accurate low-level details, while convolutional neural network (CNN) is wanting in the capacity to understand global information and establish remote spatial relationships. Meanwhile, both of the widely used early fusion and late fusion frameworks are not able to well learn complete change features. Therefore, based on swin transformer V2 (Swin V2) and VGG16, we propose an end-to-end compounded dense network SwinV2DNet to inherit the advantages of both transformer and CNN and overcome the shortcomings of existing networks in feature learning. Firstly, it captures the change relationship features through the densely connected Swin V2 backbone, and provides the low-level pre-changed and post-changed features through a CNN branch. Based on these three change features, we accomplish accurate change detection results. Secondly, combined with transformer and CNN, we propose mixed feature pyramid (MFP) which provides inter-layer interaction information and intra-layer multi-scale information for complete feature learning. MFP is a plug and play module which is experimentally proven to be also effective in other change detection networks. Further more, we impose a self-supervision strategy to guide a new CNN branch, which solves the untrainable problem of the CNN branch and provides the semantic change information for the features of encoder. The state-of-the-art (SOTA) change detection scores and fine-grained change maps were obtained compared with other advanced methods on four commonly used public remote sensing datasets. The code is available at https://github.com/DalongZ/SwinV2DNet.
</details>
<details>
<summary>摘要</summary>
当前主流的变化检测网络中，变换器缺乏捕捉准确的低级细节的能力，而卷积神经网络（CNN）缺乏建立远程空间关系和全局信息的能力。同时，现有的早期融合和晚期融合框架都不能良好地学习完整的变化特征。因此，基于Swin transformer V2（Swin V2）和VGG16，我们提出了一种端到端融合密集网络SwinV2DNet，继承了变换器和CNN的优点，并超越了现有网络在特征学习方面的缺陷。首先，SwinV2DNet通过密集连接的Swin V2脊梁捕捉变化关系特征，并提供低级预变和后变特征通过一个CNN分支。基于这三个变化特征，我们实现了准确的变化检测结果。其次，我们提出了混合特征阶梯（MFP），该模块通过卷积神经网络和变换器的结合，为完整的特征学习提供了间层交互信息和多尺度内层信息。MFP是一个可插入的模块，实验证明其效果也可以应用于其他变化检测网络。此外，我们对新的CNN分支进行自我超vision策略，解决了CNN分支的训练不可能问题，并为encoder的特征提供了semantic变化信息。与其他先进方法相比，我们在四个常用的公共遥感数据集上获得了状态前的变化检测分数和细化变化地图。代码可以在https://github.com/DalongZ/SwinV2DNet上获取。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalization-via-Rationale-Invariance"><a href="#Domain-Generalization-via-Rationale-Invariance" class="headerlink" title="Domain Generalization via Rationale Invariance"></a>Domain Generalization via Rationale Invariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11158">http://arxiv.org/abs/2308.11158</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liangchen527/ridg">https://github.com/liangchen527/ridg</a></li>
<li>paper_authors: Liang Chen, Yong Zhang, Yibing Song, Anton van den Hengel, Lingqiao Liu</li>
<li>for: 提高领域总结的稳定性，以便在未见 environments 中维持良好的结果。</li>
<li>methods: 通过对决策过程的最后一层抽象来解决领域总结挑战。具体来说，我们提议将每个样本的元素级别贡献视为决策的理由，并将每个样本的理由表示为一个矩阵。为了确保模型具有良好的普适性，我们建议每个类别的理由矩阵具有相似性，表明模型在各个环境中依靠域外特征来做出决策。</li>
<li>results: 我们的实验表明，通过引入 rational invariance loss 来实现这一思路，可以在不同的领域上实现竞争性的结果，即使使用的是简单的代码。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/liangchen527/RIDG%7D">https://github.com/liangchen527/RIDG}</a> 上找到。<details>
<summary>Abstract</summary>
This paper offers a new perspective to ease the challenge of domain generalization, which involves maintaining robust results even in unseen environments. Our design focuses on the decision-making process in the final classifier layer. Specifically, we propose treating the element-wise contributions to the final results as the rationale for making a decision and representing the rationale for each sample as a matrix. For a well-generalized model, we suggest the rationale matrices for samples belonging to the same category should be similar, indicating the model relies on domain-invariant clues to make decisions, thereby ensuring robust results. To implement this idea, we introduce a rationale invariance loss as a simple regularization technique, requiring only a few lines of code. Our experiments demonstrate that the proposed approach achieves competitive results across various datasets, despite its simplicity. Code is available at \url{https://github.com/liangchen527/RIDG}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TOPIC-A-Parallel-Association-Paradigm-for-Multi-Object-Tracking-under-Complex-Motions-and-Diverse-Scenes"><a href="#TOPIC-A-Parallel-Association-Paradigm-for-Multi-Object-Tracking-under-Complex-Motions-and-Diverse-Scenes" class="headerlink" title="TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes"></a>TOPIC: A Parallel Association Paradigm for Multi-Object Tracking under Complex Motions and Diverse Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11157">http://arxiv.org/abs/2308.11157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/holmescao/TOPICTrack">https://github.com/holmescao/TOPICTrack</a></li>
<li>paper_authors: Xiaoyan Cao, Yiyao Zheng, Yao Yao, Huapeng Qin, Xiaoyu Cao, Shihui Guo</li>
<li>for: 这 paper 的目的是提出一种新的多对目标跟踪（MOT）数据集，以解决现有数据集忽略了复杂的运动模式的问题。</li>
<li>methods: 该 paper 使用了一种新的并行相关模式（Parallel Paradigm），并提出了一种基于运动和外观特征的两个圆形相关机制（TOPIC），以及一种基于注意力的外观重建模块（AARM）来提高跟踪效果。</li>
<li>results: 该 paper 的方法在四个公共数据集和新 introduce 的 BEE23 数据集上实现了领先的表现，包括减少 false negatives 12% 到 51% compared to 单一特征相关模式。<details>
<summary>Abstract</summary>
Video data and algorithms have been driving advances in multi-object tracking (MOT). While existing MOT datasets focus on occlusion and appearance similarity, complex motion patterns are widespread yet overlooked. To address this issue, we introduce a new dataset called BEE23 to highlight complex motions. Identity association algorithms have long been the focus of MOT research. Existing trackers can be categorized into two association paradigms: single-feature paradigm (based on either motion or appearance feature) and serial paradigm (one feature serves as secondary while the other is primary). However, these paradigms are incapable of fully utilizing different features. In this paper, we propose a parallel paradigm and present the Two rOund Parallel matchIng meChanism (TOPIC) to implement it. The TOPIC leverages both motion and appearance features and can adaptively select the preferable one as the assignment metric based on motion level. Moreover, we provide an Attention-based Appearance Reconstruct Module (AARM) to reconstruct appearance feature embeddings, thus enhancing the representation of appearance features. Comprehensive experiments show that our approach achieves state-of-the-art performance on four public datasets and BEE23. Notably, our proposed parallel paradigm surpasses the performance of existing association paradigms by a large margin, e.g., reducing false negatives by 12% to 51% compared to the single-feature association paradigm. The introduced dataset and association paradigm in this work offers a fresh perspective for advancing the MOT field. The source code and dataset are available at https://github.com/holmescao/TOPICTrack.
</details>
<details>
<summary>摘要</summary>
视频数据和算法在多对目标跟踪（MOT）领域取得了重大进步。现有的MOT数据集集中焦点在 occlusion 和外观相似性上，然而复杂的运动模式却被忽略。为了解决这个问题，我们提出了一个新的数据集called BEE23，以强调复杂的运动。目标跟踪算法的研究总是围绕着 Identity association 问题进行，现有的跟踪器可以分为两种联系思维：单一特征思维（基于 either motion 或 appearance feature）以及串行思维（一个特征服务为次要，另一个特征服务为主要）。然而，这些思维方法无法完全利用不同的特征。在这篇论文中，我们提议了并行联系思维，并通过 Two rOund Parallel matchIng meChanism（TOPIC）来实现。TOPIC 利用了运动和外观特征，并可以根据运动水平选择适合的一个作为分配度量。此外，我们还提供了 Attention-based Appearance Reconstruct Module（AARM）来重建外观特征嵌入，从而提高外观特征的表示。我们对四个公共数据集和 BEE23 进行了广泛的实验，结果显示我们的方法在这些数据集上达到了当前最佳性能。尤其是，我们提出的并行联系思维在现有的联系思维方法之上减少了12%至51%的假阳性。在这篇论文中，我们还提供了一个新的数据集和联系思维方法，这将为 MOT 领域带来新的视角，并且代码和数据集可以在 <https://github.com/holmescao/TOPICTrack> 上获取。
</details></li>
</ul>
<hr>
<h2 id="High-Dynamic-Range-Imaging-of-Dynamic-Scenes-with-Saturation-Compensation-but-without-Explicit-Motion-Compensation"><a href="#High-Dynamic-Range-Imaging-of-Dynamic-Scenes-with-Saturation-Compensation-but-without-Explicit-Motion-Compensation" class="headerlink" title="High Dynamic Range Imaging of Dynamic Scenes with Saturation Compensation but without Explicit Motion Compensation"></a>High Dynamic Range Imaging of Dynamic Scenes with Saturation Compensation but without Explicit Motion Compensation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11140">http://arxiv.org/abs/2308.11140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haesoochung/hdri-saturation-compensation">https://github.com/haesoochung/hdri-saturation-compensation</a></li>
<li>paper_authors: Haesoo Chung, Nam Ik Cho</li>
<li>for: 提高高动态范围（HDR）图像的获得和修复，解决由相机传感器的限制导致的信息损失问题。</li>
<li>methods: 使用改进的运动补偿和灰度调整问题的解决方案，通过 Contextual attention 技术来修复过度曝光区域。</li>
<li>results: 比对 state-of-the-art 方法，示出了更高的质量和量化评价结果。<details>
<summary>Abstract</summary>
High dynamic range (HDR) imaging is a highly challenging task since a large amount of information is lost due to the limitations of camera sensors. For HDR imaging, some methods capture multiple low dynamic range (LDR) images with altering exposures to aggregate more information. However, these approaches introduce ghosting artifacts when significant inter-frame motions are present. Moreover, although multi-exposure images are given, we have little information in severely over-exposed areas. Most existing methods focus on motion compensation, i.e., alignment of multiple LDR shots to reduce the ghosting artifacts, but they still produce unsatisfying results. These methods also rather overlook the need to restore the saturated areas. In this paper, we generate well-aligned multi-exposure features by reformulating a motion alignment problem into a simple brightness adjustment problem. In addition, we propose a coarse-to-fine merging strategy with explicit saturation compensation. The saturated areas are reconstructed with similar well-exposed content using adaptive contextual attention. We demonstrate that our method outperforms the state-of-the-art methods regarding qualitative and quantitative evaluations.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）摄影是一项非常具有挑战性的任务，因为摄像头传感器的限制会导致大量信息的丢失。为实现HDR摄影，一些方法会 capture多个低动态范围（LDR）图像，并将它们进行不同的曝光设定来聚集更多的信息。然而，这些方法会导致在 significative 的运动误差存在时出现幻影artefacts。此外，虽然我们有多个曝光图像，但我们在严重过曝光区域中具有少量信息。大多数现有方法将焦点放在运动补做上，即将多个LDR拍摄Alignment 来减少幻影artefacts，但这些方法仍然生成不满足的结果。这些方法还往往忽略了重建过曝光区域的需求。在这篇论文中，我们将生成准确尺度的多个曝光特征，通过将运动Alignment 转换为简单的明亮调整问题来实现。此外，我们还提出了一种粗略到细节的合并策略，并且使用明确的过曝光补做。在过曝光区域中，我们使用适应的上下文关注来重建相似的准确曝光内容。我们示示了我们的方法在质量和量度上的超越现有方法。
</details></li>
</ul>
<hr>
<h2 id="Efficient-View-Synthesis-with-Neural-Radiance-Distribution-Field"><a href="#Efficient-View-Synthesis-with-Neural-Radiance-Distribution-Field" class="headerlink" title="Efficient View Synthesis with Neural Radiance Distribution Field"></a>Efficient View Synthesis with Neural Radiance Distribution Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11130">http://arxiv.org/abs/2308.11130</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushuang-wu/NeRDF">https://github.com/yushuang-wu/NeRDF</a></li>
<li>paper_authors: Yushuang Wu, Xiao Li, Jinglu Wang, Xiaoguang Han, Shuguang Cui, Yan Lu</li>
<li>For: 高品质视角合成* Methods: 使用小型网络模型，采用频率基准来模型光度分布，采样一次网络前进来计算像素值* Results: 提供了一个更好的权衡 между速度、质量和网络大小，与传统方法相比，具有约254倍的速度提升，同时保持了类似的网络大小和质量水平。<details>
<summary>Abstract</summary>
Recent work on Neural Radiance Fields (NeRF) has demonstrated significant advances in high-quality view synthesis. A major limitation of NeRF is its low rendering efficiency due to the need for multiple network forwardings to render a single pixel. Existing methods to improve NeRF either reduce the number of required samples or optimize the implementation to accelerate the network forwarding. Despite these efforts, the problem of multiple sampling persists due to the intrinsic representation of radiance fields. In contrast, Neural Light Fields (NeLF) reduce the computation cost of NeRF by querying only one single network forwarding per pixel. To achieve a close visual quality to NeRF, existing NeLF methods require significantly larger network capacities which limits their rendering efficiency in practice. In this work, we propose a new representation called Neural Radiance Distribution Field (NeRDF) that targets efficient view synthesis in real-time. Specifically, we use a small network similar to NeRF while preserving the rendering speed with a single network forwarding per pixel as in NeLF. The key is to model the radiance distribution along each ray with frequency basis and predict frequency weights using the network. Pixel values are then computed via volume rendering on radiance distributions. Experiments show that our proposed method offers a better trade-off among speed, quality, and network size than existing methods: we achieve a ~254x speed-up over NeRF with similar network size, with only a marginal performance decline. Our project page is at yushuang-wu.github.io/NeRDF.
</details>
<details>
<summary>摘要</summary>
最近的神经辐射场（NeRF）研究取得了高品质视图合成的重要进步。然而，NeRF具有辐射场的内置表示，导致每个像素需要多个网络请求，从而降低了渲染效率。现有的方法可以减少需要的样本数或者优化网络实现以加速网络请求。然而，这些努力仍然无法消除多样本的问题。相比之下，神经光场（NeLF）可以通过每个像素只需要一次网络请求来减少计算成本。然而，现有的NeLF方法需要较大的网络容量，从而限制了实际的渲染效率。在这种情况下，我们提出了一种新的表示方式 called Neural Radiance Distribution Field（NeRDF），旨在实现高效的视图合成。具体来说，我们使用一个小型神经网络，类似于NeRF，同时保持与NeLF一样的渲染速度。关键在于，我们使用频率基is来模型每个辐射线上的光辐射分布，并使用网络来预测频率权重。然后，通过量 rendering 技术来计算像素值。实验表明，我们的提议方法可以在Speed、质量和网络大小之间取得更好的平衡，相比之下NeRF和NeLF的方法。我们的项目页面是 yushuang-wu.github.io/NeRDF。
</details></li>
</ul>
<hr>
<h2 id="Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs"><a href="#Hey-That’s-Mine-Imperceptible-Watermarks-are-Preserved-in-Diffusion-Generated-Outputs" class="headerlink" title="Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs"></a>Hey That’s Mine Imperceptible Watermarks are Preserved in Diffusion Generated Outputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11123">http://arxiv.org/abs/2308.11123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 保护内容在线分享</li>
<li>methods: 使用隐形水印技术训练生成模型，并测试其能够在生成图像中检测水印。</li>
<li>results: 通过统计测试，确定了模型是否训练使用水印数据，以及水印数据中的特征与生成图像之间的相关性。<details>
<summary>Abstract</summary>
Generative models have seen an explosion in popularity with the release of huge generative Diffusion models like Midjourney and Stable Diffusion to the public. Because of this new ease of access, questions surrounding the automated collection of data and issues regarding content ownership have started to build. In this paper we present new work which aims to provide ways of protecting content when shared to the public. We show that a generative Diffusion model trained on data that has been imperceptibly watermarked will generate new images with these watermarks present. We further show that if a given watermark is correlated with a certain feature of the training data, the generated images will also have this correlation. Using statistical tests we show that we are able to determine whether a model has been trained on marked data, and what data was marked. As a result our system offers a solution to protect intellectual property when sharing content online.
</details>
<details>
<summary>摘要</summary>
traducciona el texto a chino simplificado.<</SYS>>广泛的生成模型在大量生成扩散模型如中途和稳定扩散的公共释放后得到了普及。由于这新的访问方便，自动收集数据和内容所有权问题开始升温。在这篇论文中，我们介绍新的工作，旨在在公共分享时保护内容。我们显示，通过训练在不可见水印数据上的生成扩散模型，新生成的图像都会包含这些水印。此外，如果给定的水印与训练数据中某个特征相关，那么生成的图像也会具有这种相关性。通过统计测试，我们表明可以判断模型是否训练在标记数据上，以及具体的标记数据。因此，我们的系统可以解决在线分享内容时保护知识产权。
</details></li>
</ul>
<hr>
<h2 id="Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection"><a href="#Random-Word-Data-Augmentation-with-CLIP-for-Zero-Shot-Anomaly-Detection" class="headerlink" title="Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection"></a>Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11119">http://arxiv.org/abs/2308.11119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Tamura</li>
<li>for: 这个研究是为了开发一个 zero-shot anomaly detection 方法，利用 CLIP 的视觉语言模型来提供数据源。</li>
<li>methods: 这个方法使用 CLIP 的 prompt-guided classification 技术，将每个图像分成多个部分，并将每个部分作为 input 进行类别。此外，还使用了一些随机生成的词语，以增加训练数据的多样性。</li>
<li>results: 实验结果显示，这个方法可以在 zero-shot 设定下 achieves state-of-the-art 性能，不需要耗费很多时间进行训练。<details>
<summary>Abstract</summary>
This paper presents a novel method that leverages a visual-language model, CLIP, as a data source for zero-shot anomaly detection. Tremendous efforts have been put towards developing anomaly detectors due to their potential industrial applications. Considering the difficulty in acquiring various anomalous samples for training, most existing methods train models with only normal samples and measure discrepancies from the distribution of normal samples during inference, which requires training a model for each object category. The problem of this inefficient training requirement has been tackled by designing a CLIP-based anomaly detector that applies prompt-guided classification to each part of an image in a sliding window manner. However, the method still suffers from the labor of careful prompt ensembling with known object categories. To overcome the issues above, we propose leveraging CLIP as a data source for training. Our method generates text embeddings with the text encoder in CLIP with typical prompts that include words of normal and anomaly. In addition to these words, we insert several randomly generated words into prompts, which enables the encoder to generate a diverse set of normal and anomalous samples. Using the generated embeddings as training data, a feed-forward neural network learns to extract features of normal and anomaly from CLIP's embeddings, and as a result, a category-agnostic anomaly detector can be obtained without any training images. Experimental results demonstrate that our method achieves state-of-the-art performance without laborious prompt ensembling in zero-shot setups.
</details>
<details>
<summary>摘要</summary>
To overcome these issues, the proposed method leverages CLIP as a data source for training. The method generates text embeddings with the text encoder in CLIP using typical prompts that include words related to normal and anomalous samples. Additionally, several randomly generated words are inserted into the prompts to enable the encoder to generate a diverse set of normal and anomalous samples. These embeddings are then used as training data for a feed-forward neural network to extract features of normal and anomalous samples from CLIP's embeddings. As a result, a category-agnostic anomaly detector can be obtained without any training images.Experimental results demonstrate that the proposed method achieves state-of-the-art performance in zero-shot setups without the need for laborious prompt ensembling.
</details></li>
</ul>
<hr>
<h2 id="LAN-HDR-Luminance-based-Alignment-Network-for-High-Dynamic-Range-Video-Reconstruction"><a href="#LAN-HDR-Luminance-based-Alignment-Network-for-High-Dynamic-Range-Video-Reconstruction" class="headerlink" title="LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction"></a>LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11116">http://arxiv.org/abs/2308.11116</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haesoochung/lan-hdr">https://github.com/haesoochung/lan-hdr</a></li>
<li>paper_authors: Haesoo Chung, Nam Ik Cho</li>
<li>for: 提高高清晰度和动态范围（HDR）影像技术，以满足用户对高质量视频的需求。</li>
<li>methods: 基于特征空间的灵活抽象网络（LAN-HDR），包括对适应模块和梦想模块。对模块使用灵活抽象来减少流量估计错误。</li>
<li>results: 比较现有方法表现更好或相当，在多个标准测试数据集上进行了广泛的实验。<details>
<summary>Abstract</summary>
As demands for high-quality videos continue to rise, high-resolution and high-dynamic range (HDR) imaging techniques are drawing attention. To generate an HDR video from low dynamic range (LDR) images, one of the critical steps is the motion compensation between LDR frames, for which most existing works employed the optical flow algorithm. However, these methods suffer from flow estimation errors when saturation or complicated motions exist. In this paper, we propose an end-to-end HDR video composition framework, which aligns LDR frames in the feature space and then merges aligned features into an HDR frame, without relying on pixel-domain optical flow. Specifically, we propose a luminance-based alignment network for HDR (LAN-HDR) consisting of an alignment module and a hallucination module. The alignment module aligns a frame to the adjacent reference by evaluating luminance-based attention, excluding color information. The hallucination module generates sharp details, especially for washed-out areas due to saturation. The aligned and hallucinated features are then blended adaptively to complement each other. Finally, we merge the features to generate a final HDR frame. In training, we adopt a temporal loss, in addition to frame reconstruction losses, to enhance temporal consistency and thus reduce flickering. Extensive experiments demonstrate that our method performs better or comparable to state-of-the-art methods on several benchmarks.
</details>
<details>
<summary>摘要</summary>
As demands for high-quality videos continue to rise, high-resolution and high-dynamic range (HDR) imaging techniques are drawing attention. To generate an HDR video from low dynamic range (LDR) images, one of the critical steps is the motion compensation between LDR frames, for which most existing works employed the optical flow algorithm. However, these methods suffer from flow estimation errors when saturation or complicated motions exist. In this paper, we propose an end-to-end HDR video composition framework, which aligns LDR frames in the feature space and then merges aligned features into an HDR frame, without relying on pixel-domain optical flow. Specifically, we propose a luminance-based alignment network for HDR (LAN-HDR) consisting of an alignment module and a hallucination module. The alignment module aligns a frame to the adjacent reference by evaluating luminance-based attention, excluding color information. The hallucination module generates sharp details, especially for washed-out areas due to saturation. The aligned and hallucinated features are then blended adaptively to complement each other. Finally, we merge the features to generate a final HDR frame. In training, we adopt a temporal loss, in addition to frame reconstruction losses, to enhance temporal consistency and thus reduce flickering. Extensive experiments demonstrate that our method performs better or comparable to state-of-the-art methods on several benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models"><a href="#Development-of-a-Novel-Quantum-Pre-processing-Filter-to-Improve-Image-Classification-Accuracy-of-Neural-Network-Models" class="headerlink" title="Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models"></a>Development of a Novel Quantum Pre-processing Filter to Improve Image Classification Accuracy of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11112">http://arxiv.org/abs/2308.11112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hajimesuzuki999/qpf">https://github.com/hajimesuzuki999/qpf</a></li>
<li>paper_authors: Farina Riaz, Shahab Abdulla, Hajime Suzuki, Srinjoy Ganguly, Ravinesh C. Deo, Susan Hopkins</li>
<li>for: 提高图像分类准确率</li>
<li>methods: 使用量子预处理筛选器（QPF），应用于图像分类神经网络模型中</li>
<li>results: 在MNIST和EMNIST数据集上，图像分类准确率提高至95.4%和75.9%，分别提高了2.9%和7.1%，无需添加额外参数或优化机器学习过程。<details>
<summary>Abstract</summary>
This paper proposes a novel quantum pre-processing filter (QPF) to improve the image classification accuracy of neural network (NN) models. A simple four qubit quantum circuit that uses Y rotation gates for encoding and two controlled NOT gates for creating correlation among the qubits is applied as a feature extraction filter prior to passing data into the fully connected NN architecture. By applying the QPF approach, the results show that the image classification accuracy based on the MNIST (handwritten 10 digits) and the EMNIST (handwritten 47 class digits and letters) datasets can be improved, from 92.5% to 95.4% and from 68.9% to 75.9%, respectively. These improvements were obtained without introducing extra model parameters or optimizations in the machine learning process. However, tests performed on the developed QPF approach against a relatively complex GTSRB dataset with 43 distinct class real-life traffic sign images showed a degradation in the classification accuracy. Considering this result, further research into the understanding and the design of a more suitable quantum circuit approach for image classification neural networks could be explored utilizing the baseline method proposed in this paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Classification-of-the-lunar-surface-pattern-by-AI-architectures-Does-AI-see-a-rabbit-in-the-Moon"><a href="#Classification-of-the-lunar-surface-pattern-by-AI-architectures-Does-AI-see-a-rabbit-in-the-Moon" class="headerlink" title="Classification of the lunar surface pattern by AI architectures: Does AI see a rabbit in the Moon?"></a>Classification of the lunar surface pattern by AI architectures: Does AI see a rabbit in the Moon?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11107">http://arxiv.org/abs/2308.11107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daigo Shoji</li>
<li>for: 这篇论文的目的是研究月面的颜色模式是否类似于兔子。</li>
<li>methods: 这篇论文使用了七种人工智能架构来评估月面颜色模式与兔子之间的相似性。</li>
<li>results: 测试结果显示，在某些地区，月面颜色模式更容易被识别为兔子，而不是人脸。此外，使用ImageNet权重时，ConvNeXt和CLIP occasionally可以归类月面颜色模式为兔子。<details>
<summary>Abstract</summary>
In Asian countries, there is a tradition that a rabbit (the Moon rabbit) lives on the Moon. As the origin of this tradition, usually, two reasons are mentioned. One reason is that the color pattern of the lunar surface is similar to the shape of a rabbit. The other reason is that both the Moon and rabbit are symbols of fertility because the Moon appears and disappears (i.e., waxing and waning) cyclically, and rabbits bear children frequently. Considering the latter reason, is the lunar surface color pattern not similar to a rabbit? Here, the similarity between rabbit and the lunar surface pattern was evaluated using seven AI architectures. In the test by CLIP, assuming that people look at the Moon in the early evening frequently, the lunar surface is more similar to a rabbit than a face at low latitude regions, while it can be classified as face as latitude increases, which is consistent with that the oldest literature about the Moon rabbit was written in India and that there is a culture of human's face in the Moon in Europe. Tested with ImageNet weights, ConvNeXt and CLIP sometimes classified the lunar surface pattern into rabbit with relatively high probabilities. Cultures are generated by our attitude to the environment. Both dynamic and static similarities may be required to induce our imagination.
</details>
<details>
<summary>摘要</summary>
在亚洲国家，有一传统认为月球上有兔子（月兔）生活。这个传统的起源通常被推断为两个理由。一个理由是月球表面的颜色排列与兔子的形状类似。另一个理由是月球和兔子都是生育的符号，因为月球出现和消失（即增减）的征例行为，兔子则经常产下幼崽。考虑后一个理由，月球表面的颜色排列与兔子是否类似？在这个问题上，我们使用了七种人工智能架构进行评估。在CLIP测试中，假设人们在晚上经常看到月球，那么月球表面的颜色排列更像兔子 than 人脸，而且随着纬度增加，月球表面可以被识别为人脸。这与最古老的月兔文学成果在印度被写成，以及欧洲文化中人类面部在月球上的存在相一致。使用ImageNet权重，ConvNeXt和CLIP occasionally将月球表面 Pattern classification为兔子，并且拥有相对高的概率。文化是由我们对环境的态度所生成的。我们可能需要同时考虑动态和静态相似性，以便让我们的想象力激发。
</details></li>
</ul>
<hr>
<h2 id="Recursive-Video-Lane-Detection"><a href="#Recursive-Video-Lane-Detection" class="headerlink" title="Recursive Video Lane Detection"></a>Recursive Video Lane Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11106">http://arxiv.org/abs/2308.11106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dongkwonjin/rvld">https://github.com/dongkwonjin/rvld</a></li>
<li>paper_authors: Dongkwon Jin, Dahyun Kim, Chang-Su Kim</li>
<li>for: 这篇论文提出了一种用于视频中检测路面线的新算法，即回归视频lane检测器（RVLD），用于在视频中检测路面线。</li>
<li>methods: 该算法包括一个内部lane检测器（ILD）和一个预测lane检测器（PLD）。首先，我们设计了ILD来在当前帧中地址路面线。然后，我们开发了PLD，以利用上一帧的信息来在当前帧中更可靠地检测路面线。为此，我们估算了运动场和将上一帧的输出折叠到当前帧中。使用折叠后的信息，我们精细地修改当前帧的特征图以更好地检测路面线。</li>
<li>results: 实验结果表明，RVLD在视频路面线数据集上的性能明显超过了现有的检测器。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/dongkwonjin/RVLD%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/dongkwonjin/RVLD中下载。</a><details>
<summary>Abstract</summary>
A novel algorithm to detect road lanes in videos, called recursive video lane detector (RVLD), is proposed in this paper, which propagates the state of a current frame recursively to the next frame. RVLD consists of an intra-frame lane detector (ILD) and a predictive lane detector (PLD). First, we design ILD to localize lanes in a still frame. Second, we develop PLD to exploit the information of the previous frame for lane detection in a current frame. To this end, we estimate a motion field and warp the previous output to the current frame. Using the warped information, we refine the feature map of the current frame to detect lanes more reliably. Experimental results show that RVLD outperforms existing detectors on video lane datasets. Our codes are available at https://github.com/dongkwonjin/RVLD.
</details>
<details>
<summary>摘要</summary>
“本文提出了一种新的算法检测视频中的路线，即回归视频车道检测器（RVLD）。这种算法在当前帧中进行回归状态，并在下一帧中使用这些状态来提高车道检测的准确性。RVLD由内帧车道检测器（ILD）和预测车道检测器（PLD）两部分组成。首先，我们设计了 ILD 以确定视频帧中的车道。其次，我们开发了 PLD，以利用上一帧的信息来提高当前帧中的车道检测。为此，我们对上一帧的视频进行了运动场景的估算，并将上一帧的输出折叠到当前帧中。使用折叠后的信息，我们可以更加精确地修改当前帧的特征图，以更好地检测车道。实验结果表明，RVLD 在视频车道数据集上的性能比既有的检测器更高。我们的代码可以在 GitHub 上找到：https://github.com/dongkwonjin/RVLD。”
</details></li>
</ul>
<hr>
<h2 id="MosaiQ-Quantum-Generative-Adversarial-Networks-for-Image-Generation-on-NISQ-Computers"><a href="#MosaiQ-Quantum-Generative-Adversarial-Networks-for-Image-Generation-on-NISQ-Computers" class="headerlink" title="MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers"></a>MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11096">http://arxiv.org/abs/2308.11096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Silver, Tirthak Patel, William Cutler, Aditya Ranjan, Harshitta Gandhi, Devesh Tiwari</li>
<li>for: 研究量子机器学习和视觉技术，尤其是量子图像生成技术，以提高图像质量和可靠性。</li>
<li>methods: 我们提出了一个名为MosaiQ的高质量量子图像生成GAN框架，可以在当今的中期级量子计算机（NISQ）上执行。</li>
<li>results: MosaiQ可以生成高质量的图像，并且可以在不同的图像生成任务中实现高度的可靠性和稳定性。<details>
<summary>Abstract</summary>
Quantum machine learning and vision have come to the fore recently, with hardware advances enabling rapid advancement in the capabilities of quantum machines. Recently, quantum image generation has been explored with many potential advantages over non-quantum techniques; however, previous techniques have suffered from poor quality and robustness. To address these problems, we introduce, MosaiQ, a high-quality quantum image generation GAN framework that can be executed on today's Near-term Intermediate Scale Quantum (NISQ) computers.
</details>
<details>
<summary>摘要</summary>
量子机器学习和视觉在最近几年来得到了更多的关注，各种硬件进步使得量子机器的能力得到了快速提升。近期，量子图像生成得到了广泛研究，但以前的技术受到了低质量和稳定性的限制。为了解决这些问题，我们介绍了 MosaiQ，一个高质量量子图像生成GAN框架，可以在当今的中等规模量子计算机上执行。
</details></li>
</ul>
<hr>
<h2 id="Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport"><a href="#Addressing-Fairness-and-Explainability-in-Image-Classification-Using-Optimal-Transport" class="headerlink" title="Addressing Fairness and Explainability in Image Classification Using Optimal Transport"></a>Addressing Fairness and Explainability in Image Classification Using Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11090">http://arxiv.org/abs/2308.11090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ratz, François Hu, Arthur Charpentier</li>
<li>for: 本研究旨在提高人工智能系统的可信worthiness和公平性，使其在医疗和警察等领域中建立信任和责任感。</li>
<li>methods: 本研究使用优化的运输理论来揭示图像中偏见的起源和后果，这种方法可以轻松扩展到表格数据中。</li>
<li>results: 研究发现，通过使用拟合度量来评估模型的偏见，可以独立地保持预测准确性和揭示偏见的起源。这些发现对于建立可信worthiness和公平性的人工智能系统具有重要意义。<details>
<summary>Abstract</summary>
Algorithmic Fairness and the explainability of potentially unfair outcomes are crucial for establishing trust and accountability of Artificial Intelligence systems in domains such as healthcare and policing. Though significant advances have been made in each of the fields separately, achieving explainability in fairness applications remains challenging, particularly so in domains where deep neural networks are used. At the same time, ethical data-mining has become ever more relevant, as it has been shown countless times that fairness-unaware algorithms result in biased outcomes. Current approaches focus on mitigating biases in the outcomes of the model, but few attempts have been made to try to explain \emph{why} a model is biased. To bridge this gap, we propose a comprehensive approach that leverages optimal transport theory to uncover the causes and implications of biased regions in images, which easily extends to tabular data as well. Through the use of Wasserstein barycenters, we obtain scores that are independent of a sensitive variable but keep their marginal orderings. This step ensures predictive accuracy but also helps us to recover the regions most associated with the generation of the biases. Our findings hold significant implications for the development of trustworthy and unbiased AI systems, fostering transparency, accountability, and fairness in critical decision-making scenarios across diverse domains.
</details>
<details>
<summary>摘要</summary>
算法公平和可解释性是建立人工智能系统信任和负责任的关键因素，尤其在医疗和警察领域。虽然在每个领域 separately 有所进步，但在公平应用中实现可解释性仍然是挑战，特别是在使用深度神经网络时。同时，伦理数据挖掘已成为非常重要，因为无数次证明了不公平的算法会导致偏见的结果。现有的方法主要是减轻模型的偏见结果，但几乎没有尝试解释模型为何偏见。为了bridging这个差距，我们提出了一种全面的方法，利用最优运输理论来揭示偏见区域在图像中的原因和后果，这种方法可以轻松扩展到表格数据上。通过使用拓扑 Wasserstein 中心，我们可以获得不виси于敏感变量的分数，但保持其排序。这一步确保预测精度，同时帮助我们回归偏见区域的生成。我们的发现对于开发可靠、无偏的人工智能系统的发展有着深远的意义，推动了诚实、负责任和公平在多个领域中的决策过程中的透明度和公平。
</details></li>
</ul>
<hr>
<h2 id="Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors"><a href="#Long-Term-Prediction-of-Natural-Video-Sequences-with-Robust-Video-Predictors" class="headerlink" title="Long-Term Prediction of Natural Video Sequences with Robust Video Predictors"></a>Long-Term Prediction of Natural Video Sequences with Robust Video Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11079">http://arxiv.org/abs/2308.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Ditria, Tom Drummond</li>
<li>for: 预测高维视频序列是一个非常困难的问题，因为可能的未来场景的数量会 exponential 增长随着时间的推移。特别是在从有限的世界Snapshot中预测自然的视频场景时，内在的不确定性会快速增加，使长期预测变得非常困难。</li>
<li>methods: 我们在这篇论文中引入了一些改进了现有工作，以创建Robust Video Predictors (RoViPs)。我们使用深度Perceptual和 uncertainty-based reconstructionloss来创建高质量短期预测。使用Attention-based skip connections以实现跨距离空间特征输入的长距离移动，以进一步提高性能。</li>
<li>results: 我们显示了使用单步预测任务iterated 可以生成非常长、自然的视频序列。<details>
<summary>Abstract</summary>
Predicting high dimensional video sequences is a curiously difficult problem. The number of possible futures for a given video sequence grows exponentially over time due to uncertainty. This is especially evident when trying to predict complicated natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict making long-term prediction very difficult. In this work we introduce a number of improvements to existing work that aid in creating Robust Video Predictors (RoViPs). We show that with a combination of deep Perceptual and uncertainty-based reconstruction losses we are able to create high quality short-term predictions. Attention-based skip connections are utilised to allow for long range spatial movement of input features to further improve performance. Finally, we show that by simply making the predictor robust to its own prediction errors, it is possible to produce very long, realistic natural video sequences using an iterated single-step prediction task.
</details>
<details>
<summary>摘要</summary>
Predicting high-dimensional video sequences is a challenging problem. The number of possible futures for a given video sequence grows exponentially with time due to uncertainty. This is particularly evident when trying to predict complex natural video scenes from a limited snapshot of the world. The inherent uncertainty accumulates the further into the future you predict, making long-term prediction very difficult. In this work, we introduce several improvements to existing methods that aid in creating Robust Video Predictors (RoViPs). We show that by combining deep perceptual and uncertainty-based reconstruction losses, we can create high-quality short-term predictions. Attention-based skip connections are used to allow for long-range spatial movement of input features, further improving performance. Finally, we show that by simply making the predictor robust to its own prediction errors, we can produce very long, realistic natural video sequences using an iterated single-step prediction task.Here's the text with some notes on the translation:* "high-dimensional" is translated as "高维的" (gāo wéi de), which is a common way to describe high-dimensional data in Chinese.* "video sequences" is translated as "视频序列" (pǐn yǐng xù xià), which is a literal translation of the English phrase.* "uncertainty" is translated as "不确定性" (bù jì dìng xìng), which is a common way to describe uncertainty in Chinese.* "complicated" is translated as "复杂的" (fù zhòng de), which is a common way to describe complex or intricate things in Chinese.* "natural video scenes" is translated as "自然的视频场景" (zì rán de pǐn yǐng chǎng jǐng), which is a literal translation of the English phrase.* "long-term prediction" is translated as "长期预测" (cháng qī yù tiè), which is a common way to describe long-term predictions in Chinese.* "iterated single-step prediction task" is translated as " iterate 单步预测任务" (pītī yī xiào yù jì), which is a literal translation of the English phrase.I hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Class-Incremental-Learning"><a href="#Audio-Visual-Class-Incremental-Learning" class="headerlink" title="Audio-Visual Class-Incremental Learning"></a>Audio-Visual Class-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11073">http://arxiv.org/abs/2308.11073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weiguopian/av-cil_iccv2023">https://github.com/weiguopian/av-cil_iccv2023</a></li>
<li>paper_authors: Weiguo Pian, Shentong Mo, Yunhui Guo, Yapeng Tian</li>
<li>for: 这篇论文提出了一种 audio-visual 类增 learning 问题，即在 audio-visual 视频认知中进行类增 learning。</li>
<li>methods: 该论文提出了一种叫做 AV-CIL 的方法，该方法通过 dual-audio-visual 相似性约束 (D-AVSC) 和视觉注意力练化 (VAD) 来保持音频视频modalities之间的semantic similarity，并且能够在类增 learning 过程中 preserved previously learned audio-guided visual attentive ability。</li>
<li>results: 该论文的实验结果表明，AV-CIL 方法在 audio-visual 类增 learning 中 Significantly outperforms 现有的类增 learning 方法。<details>
<summary>Abstract</summary>
In this paper, we introduce audio-visual class-incremental learning, a class-incremental learning scenario for audio-visual video recognition. We demonstrate that joint audio-visual modeling can improve class-incremental learning, but current methods fail to preserve semantic similarity between audio and visual features as incremental step grows. Furthermore, we observe that audio-visual correlations learned in previous tasks can be forgotten as incremental steps progress, leading to poor performance. To overcome these challenges, we propose AV-CIL, which incorporates Dual-Audio-Visual Similarity Constraint (D-AVSC) to maintain both instance-aware and class-aware semantic similarity between audio-visual modalities and Visual Attention Distillation (VAD) to retain previously learned audio-guided visual attentive ability. We create three audio-visual class-incremental datasets, AVE-Class-Incremental (AVE-CI), Kinetics-Sounds-Class-Incremental (K-S-CI), and VGGSound100-Class-Incremental (VS100-CI) based on the AVE, Kinetics-Sounds, and VGGSound datasets, respectively. Our experiments on AVE-CI, K-S-CI, and VS100-CI demonstrate that AV-CIL significantly outperforms existing class-incremental learning methods in audio-visual class-incremental learning. Code and data are available at: https://github.com/weiguoPian/AV-CIL_ICCV2023.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了音频视频类增长学习（Audio-Visual Class-Incremental Learning，AVCIL），这是一种类增长学习场景 для音频视频识别。我们示示了 joint audio-visual 模型可以提高类增长学习性能，但现有方法无法保持音频视频特征之间的semantic similarity，特别是在增量步骤增长时。此外，我们发现在前一个任务学习的音频视频相关性可以在后续任务学习过程中被忘记，导致性能下降。为了解决这些挑战，我们提出了 Dual-Audio-Visual Similarity Constraint（D-AVSC）和 Visual Attention Distillation（VAD）两种方法。我们创建了三个音频视频类增长数据集： AVE-Class-Incremental（AVE-CI）、Kinetics-Sounds-Class-Incremental（K-S-CI）和 VGGSound100-Class-Incremental（VS100-CI），基于 AVE、Kinetics-Sounds 和 VGGSound 数据集。我们在 AVE-CI、K-S-CI 和 VS100-CI 上进行了实验，并证明了 AV-CIL 在音频视频类增长学习中表现出色，超过了现有的类增长学习方法。代码和数据可以在 GitHub 上获取：https://github.com/weiguoPian/AV-CIL_ICCV2023。
</details></li>
</ul>
<hr>
<h2 id="TeD-SPAD-Temporal-Distinctiveness-for-Self-supervised-Privacy-preservation-for-video-Anomaly-Detection"><a href="#TeD-SPAD-Temporal-Distinctiveness-for-Self-supervised-Privacy-preservation-for-video-Anomaly-Detection" class="headerlink" title="TeD-SPAD: Temporal Distinctiveness for Self-supervised Privacy-preservation for video Anomaly Detection"></a>TeD-SPAD: Temporal Distinctiveness for Self-supervised Privacy-preservation for video Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11072">http://arxiv.org/abs/2308.11072</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UCF-CRCV/TeD-SPAD">https://github.com/UCF-CRCV/TeD-SPAD</a></li>
<li>paper_authors: Joseph Fioresi, Ishan Rajendrakumar Dave, Mubarak Shah</li>
<li>for: 这个研究的目的是为了提出一个具有隐私保护的视预测异常探测方法，以解决现有的人工监控不足和隐私泄露问题。</li>
<li>methods: 这个方法使用了一个自我监控的三元损害函数来增强时间特征，并且使用了一个具有隐私保护的数据隐藏技术来防止隐私泄露。</li>
<li>results: 这个方法在三个弱型监控的视预测异常探测 datasets（UCF-Crime、XD-Violence和ShanghaiTech）上取得了一个良好的平衡，即在保护隐私的同时，也能够维持视预测异常探测的性能。<details>
<summary>Abstract</summary>
Video anomaly detection (VAD) without human monitoring is a complex computer vision task that can have a positive impact on society if implemented successfully. While recent advances have made significant progress in solving this task, most existing approaches overlook a critical real-world concern: privacy. With the increasing popularity of artificial intelligence technologies, it becomes crucial to implement proper AI ethics into their development. Privacy leakage in VAD allows models to pick up and amplify unnecessary biases related to people's personal information, which may lead to undesirable decision making. In this paper, we propose TeD-SPAD, a privacy-aware video anomaly detection framework that destroys visual private information in a self-supervised manner. In particular, we propose the use of a temporally-distinct triplet loss to promote temporally discriminative features, which complements current weakly-supervised VAD methods. Using TeD-SPAD, we achieve a positive trade-off between privacy protection and utility anomaly detection performance on three popular weakly supervised VAD datasets: UCF-Crime, XD-Violence, and ShanghaiTech. Our proposed anonymization model reduces private attribute prediction by 32.25% while only reducing frame-level ROC AUC on the UCF-Crime anomaly detection dataset by 3.69%. Project Page: https://joefioresi718.github.io/TeD-SPAD_webpage/
</details>
<details>
<summary>摘要</summary>
“视频异常检测（VAD）无人监测是一项复杂的计算机视觉任务，如果成功实施，它将对社会产生积极的影响。然而，现有的大多数方法忽略了一个重要的现实问题：隐私。随着人工智能技术的普及，它们的开发中需要落实合适的人工智能伦理。VAD模型可以捕捉和强调人们个人信息的无关的偏见，导致不良决策。在这篇论文中，我们提出了一种隐私意识视频异常检测框架，即TeD-SPAD。具体来说，我们提出使用时间特征分别的 triplet损失来促进时间特征分别，这与现有的弱监测VAD方法相 complement。使用TeD-SPAD，我们在三个流行的弱监测VAD数据集上实现了隐私保护和异常检测性能的积极负作用。我们的提出的匿名化模型可以降低人员特征预测值32.25%，只减某些数据集的异常检测精度3.69%。项目页面：https://joefioresi718.github.io/TeD-SPAD_webpage/”
</details></li>
</ul>
<hr>
<h2 id="MetaGCD-Learning-to-Continually-Learn-in-Generalized-Category-Discovery"><a href="#MetaGCD-Learning-to-Continually-Learn-in-Generalized-Category-Discovery" class="headerlink" title="MetaGCD: Learning to Continually Learn in Generalized Category Discovery"></a>MetaGCD: Learning to Continually Learn in Generalized Category Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11063">http://arxiv.org/abs/2308.11063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanan Wu, Zhixiang Chi, Yang Wang, Songhe Feng</li>
<li>for: 本研究的目的是解决一种实际场景，在训练过程中遇到未标注的数据，该数据包含已知和新类的混合类。目标是不断发现新类，同时保持已知类的性能。我们称之为 Continual Generalized Category Discovery (C-GCD) Setting。</li>
<li>methods: 我们提出了一种方法，即 MetaGCD，以便在 C-GCD  Setting 中不断发现新类而不忘记已知类。我们使用了一个元学习框架，并利用了在线标注数据来模拟测试增量学习过程。我们定义了一个元目标，旨在同时解决两个矛盾的学习目标，以实现不断发现新类而不忘记已知类。此外，我们还提出了一种软邻域基于对比网络，以便区分无关图像而吸引相关图像。</li>
<li>results: 我们在三个广泛使用的标准测试benchmark上建立了强大的基准，并进行了广泛的实验。我们的方法在 C-GCD  Setting 中表现出色，可以不断发现新类而不忘记已知类。<details>
<summary>Abstract</summary>
In this paper, we consider a real-world scenario where a model that is trained on pre-defined classes continually encounters unlabeled data that contains both known and novel classes. The goal is to continually discover novel classes while maintaining the performance in known classes. We name the setting Continual Generalized Category Discovery (C-GCD). Existing methods for novel class discovery cannot directly handle the C-GCD setting due to some unrealistic assumptions, such as the unlabeled data only containing novel classes. Furthermore, they fail to discover novel classes in a continual fashion. In this work, we lift all these assumptions and propose an approach, called MetaGCD, to learn how to incrementally discover with less forgetting. Our proposed method uses a meta-learning framework and leverages the offline labeled data to simulate the testing incremental learning process. A meta-objective is defined to revolve around two conflicting learning objectives to achieve novel class discovery without forgetting. Furthermore, a soft neighborhood-based contrastive network is proposed to discriminate uncorrelated images while attracting correlated images. We build strong baselines and conduct extensive experiments on three widely used benchmarks to demonstrate the superiority of our method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们考虑了一个真实世界场景，在这个场景中，一个已经训练过的模型在不断接触到预先定义的类和未经标注的数据中遇到了新类。目标是同时发现新类并保持已知类的性能。我们称这种设定为总类发现（C-GCD）。现有的新类发现方法无法直接处理这种设定，这是因为它们假设了尚未标注的数据只包含新类。此外，它们也无法在不断发现新类的情况下保持已知类的性能。在这种工作中，我们终止了这些假设，并提出了一种方法，称为MetaGCD，以incremental learning来发现新类而减少忘记。我们的提出的方法使用了meta-学框架，利用了在线标注数据来模拟测试增量学习过程。我们定义了一个meta-目标，旨在在新类发现和已知类性能之间协调两个不同的学习目标。此外，我们还提出了一种软邻域基于的对比网络，以便在不同类型之间分辨细分图像。我们建立了强大的基elines并进行了广泛的实验，以证明我们的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="UnLoc-A-Unified-Framework-for-Video-Localization-Tasks"><a href="#UnLoc-A-Unified-Framework-for-Video-Localization-Tasks" class="headerlink" title="UnLoc: A Unified Framework for Video Localization Tasks"></a>UnLoc: A Unified Framework for Video Localization Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11062">http://arxiv.org/abs/2308.11062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/scenic">https://github.com/google-research/scenic</a></li>
<li>paper_authors: Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid</li>
<li>for: 这个研究的目的是提出一种新的视频地理ocalization方法，用于在未经trim的视频中进行时间地理ocalization。</li>
<li>methods: 这个方法使用预训练的图像和文本楼层，并将 tokens 传递给一个视频-文本融合模型。输出的融合模型输出将用于构建一个特征 пирамид，每个层与一个头相连，以预测每帧的相关性分数和开始&#x2F;结束时间偏移。</li>
<li>results: 这个方法可以实现视频地理ocalization、时间地理ocalization和动作分割等三个任务，并且在所有三个任务中达到了现有最佳Result。<details>
<summary>Abstract</summary>
While large-scale image-text pretrained models such as CLIP have been used for multiple video-level tasks on trimmed videos, their use for temporal localization in untrimmed videos is still a relatively unexplored task. We design a new approach for this called UnLoc, which uses pretrained image and text towers, and feeds tokens to a video-text fusion model. The output of the fusion module are then used to construct a feature pyramid in which each level connects to a head to predict a per-frame relevancy score and start/end time displacements. Unlike previous works, our architecture enables Moment Retrieval, Temporal Localization, and Action Segmentation with a single stage model, without the need for action proposals, motion based pretrained features or representation masking. Unlike specialized models, we achieve state of the art results on all three different localization tasks with a unified approach. Code will be available at: \url{https://github.com/google-research/scenic}.
</details>
<details>
<summary>摘要</summary>
大规模图像文本预训练模型，如CLIP，已经在剪辑后的视频上进行多种任务，但是它们在未剪辑视频中的时间本地化仍然是一个未解决的问题。我们设计了一种新的方法called UnLoc，它使用预训练的图像和文本楼层，并将Token传递给视频-文本融合模型。融合模块的输出被用construct一个功能PYRAMID，每个层与一个头连接，以预测每帧的相关性分数和开始/结束时间偏移。与之前的方法不同，我们的体系允许场景检索、时间本地化和动作分割使用单一的阶段模型，不需要动作提案、运动基于预训练特征或表示掩码。与专门的模型不同，我们在所有三种本地化任务中达到了状态arta的结果，代码将在：\url{https://github.com/google-research/scenic}上提供。
</details></li>
</ul>
<hr>
<h2 id="Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI"><a href="#Harmonization-Across-Imaging-Locations-HAIL-One-Shot-Learning-for-Brain-MRI" class="headerlink" title="Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI"></a>Harmonization Across Imaging Locations(HAIL): One-Shot Learning for Brain MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11047">http://arxiv.org/abs/2308.11047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhijeet Parida, Zhifan Jiang, Syed Muhammad Anwar, Nicholas Foreman, Nicholas Stence, Michael J. Fisher, Roger J. Packer, Robert A. Avery, Marius George Linguraru</li>
<li>for: 这篇论文旨在提出一种用于类比较罕见疾病，如儿童脑肿瘤的机器学习基于医疗影像诊断和预测方法。</li>
<li>methods: 本论文使用了生成对抗网络（GANs）进行深度学习预测，并提出了一种一击学习方法，使用神经风格转移来调整医疗影像的强度标准。</li>
<li>results: 实验结果显示，该方法可以保持病人解剖结构，并调整影像强度以适应新的诊疗所需。此外，该方法可以在未见到训练数据的情况下进行应用，因此具有实际应用和临床试验的价值。<details>
<summary>Abstract</summary>
For machine learning-based prognosis and diagnosis of rare diseases, such as pediatric brain tumors, it is necessary to gather medical imaging data from multiple clinical sites that may use different devices and protocols. Deep learning-driven harmonization of radiologic images relies on generative adversarial networks (GANs). However, GANs notoriously generate pseudo structures that do not exist in the original training data, a phenomenon known as "hallucination". To prevent hallucination in medical imaging, such as magnetic resonance images (MRI) of the brain, we propose a one-shot learning method where we utilize neural style transfer for harmonization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. We further propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures. Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.
</details>
<details>
<summary>摘要</summary>
Our approach combines learning a feature extractor, neural style transfer, and adaptive instance normalization. At test time, the method uses one image from a clinical site to generate an image that matches the intensity scale of the collaborating sites. We also propose a novel strategy to evaluate the effectiveness of image harmonization approaches with evaluation metrics that both measure image style harmonization and assess the preservation of anatomical structures.Experimental results demonstrate the effectiveness of our method in preserving patient anatomy while adjusting the image intensities to a new clinical site. Our general harmonization model can be used on unseen data from new sites, making it a valuable tool for real-world medical applications and clinical trials.Here's the Simplified Chinese translation:为了使用机器学习来诊断和预测罕见疾病，如儿童脑肿瘤，需要从多个临床Site收集医学成像数据，这些数据可能使用不同的设备和协议。但是，使用生成对抗网络（GANs）进行深度学习驱动的成像融合可能会导致“幻觉”现象，即生成不存在于训练数据中的 pseudo 结构。为了避免幻觉在医学成像中，我们提议一种一键学习方法，利用神经风格传输来融合。在测试时，方法使用一个来自临床Site的图像，通过神经风格传输来生成医学成像，以适应新的临床Site的INTENSITY规模。我们还提出了一种新的评估图像融合方法的效果的策略，该策略包括评估图像风格融合和评估结构保持。实验结果表明，我们的方法可以保持患者的解剖结构，同时调整图像INTENSITY来适应新的临床Site。我们的通用融合模型可以在新的Site上使用未看过的数据，因此它是实际医疗应用和临床试验中的有价值工具。
</details></li>
</ul>
<hr>
<h2 id="Coordinate-Quantized-Neural-Implicit-Representations-for-Multi-view-Reconstruction"><a href="#Coordinate-Quantized-Neural-Implicit-Representations-for-Multi-view-Reconstruction" class="headerlink" title="Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction"></a>Coordinate Quantized Neural Implicit Representations for Multi-view Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11025">http://arxiv.org/abs/2308.11025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/machineperceptionlab/cq-nir">https://github.com/machineperceptionlab/cq-nir</a></li>
<li>paper_authors: Sijia Jiang, Jing Hua, Zhizhong Han</li>
<li>for: 用于学习神经隐式表示法从多视图图像中获取3D重建</li>
<li>methods: 使用量化坐标为神经网络中的输入，并使用离散坐标和其позициональ编码来学习隐式函数</li>
<li>results: 提高了多视图一致性约束，并且不会增加计算负担，在最新的方法上显示了超过状态艺术的优势<details>
<summary>Abstract</summary>
In recent years, huge progress has been made on learning neural implicit representations from multi-view images for 3D reconstruction. As an additional input complementing coordinates, using sinusoidal functions as positional encodings plays a key role in revealing high frequency details with coordinate-based neural networks. However, high frequency positional encodings make the optimization unstable, which results in noisy reconstructions and artifacts in empty space. To resolve this issue in a general sense, we introduce to learn neural implicit representations with quantized coordinates, which reduces the uncertainty and ambiguity in the field during optimization. Instead of continuous coordinates, we discretize continuous coordinates into discrete coordinates using nearest interpolation among quantized coordinates which are obtained by discretizing the field in an extremely high resolution. We use discrete coordinates and their positional encodings to learn implicit functions through volume rendering. This significantly reduces the variations in the sample space, and triggers more multi-view consistency constraints on intersections of rays from different views, which enables to infer implicit function in a more effective way. Our quantized coordinates do not bring any computational burden, and can seamlessly work upon the latest methods. Our evaluations under the widely used benchmarks show our superiority over the state-of-the-art. Our code is available at https://github.com/MachinePerceptionLab/CQ-NIR.
</details>
<details>
<summary>摘要</summary>
Recently, there have been significant advancements in learning neural implicit representations from multi-view images for 3D reconstruction. Using sinusoidal functions as positional encodings has proven to be crucial in revealing high-frequency details with coordinate-based neural networks. However, the use of high-frequency positional encodings can lead to unstable optimization, resulting in noisy reconstructions and artifacts in empty space. To address this issue, we propose learning neural implicit representations with quantized coordinates, which reduces uncertainty and ambiguity in the field during optimization. Instead of using continuous coordinates, we discretize them into discrete coordinates using nearest interpolation among quantized coordinates, which are obtained by discretizing the field in an extremely high resolution. We then use these discrete coordinates and their positional encodings to learn implicit functions through volume rendering, significantly reducing variations in the sample space and triggering more multi-view consistency constraints on intersections of rays from different views, enabling more effective inference of implicit functions. Our quantized coordinates do not increase computational burden and can seamlessly work with the latest methods. Our evaluations on widely used benchmarks show our superiority over the state-of-the-art. Our code is available at https://github.com/MachinePerceptionLab/CQ-NIR.
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations"><a href="#Multi-Task-Hypergraphs-for-Semi-supervised-Learning-using-Earth-Observations" class="headerlink" title="Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations"></a>Multi-Task Hypergraphs for Semi-supervised Learning using Earth Observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11021">http://arxiv.org/abs/2308.11021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mihai Pirvu, Alina Marcu, Alexandra Dobrescu, Nabil Belbachir, Marius Leordeanu</li>
<li>for: 这个论文是为了解决多任务学习中数据缺失问题，特别是在地球观测领域，where ground-truth data is often missing.</li>
<li>methods: 该论文提出了一种多任务hypergraphSelf-supervised learning方法，其中每个节点是一个任务，不同的路径通过hypergraph到达给定任务都成为了无监督教师，并通过 ensemble 学习生成可靠的pseudolabels。</li>
<li>results: 经过对NASA NEO数据集的广泛实验，论文示出了其多任务半监督方法的价值，包括在强基elines和最近的工作上的一致提升。此外，论文还表明了hypergraph可以适应不监督数据分布变化，并可靠地恢复缺失数据，以及其可以在多个观测层次上适应数据缺失情况。<details>
<summary>Abstract</summary>
There are many ways of interpreting the world and they are highly interdependent. We exploit such complex dependencies and introduce a powerful multi-task hypergraph, in which every node is a task and different paths through the hypergraph reaching a given task become unsupervised teachers, by forming ensembles that learn to generate reliable pseudolabels for that task. Each hyperedge is part of an ensemble teacher for a given task and it is also a student of the self-supervised hypergraph system. We apply our model to one of the most important problems of our times, that of Earth Observation, which is highly multi-task and it often suffers from missing ground-truth data. By performing extensive experiments on the NASA NEO Dataset, spanning a period of 22 years, we demonstrate the value of our multi-task semi-supervised approach, by consistent improvements over strong baselines and recent work. We also show that the hypergraph can adapt unsupervised to gradual data distribution shifts and reliably recover, through its multi-task self-supervision process, the missing data for several observational layers for up to seven years.
</details>
<details>
<summary>摘要</summary>
世界上有很多方法来解释，它们之间很高度相互依赖。我们利用这些复杂的依赖关系，引入一个强大的多任务超графи，其中每个节点是一个任务，不同的路径通过超графи到达某个任务就会成为无监督教师。每个超边都是一个任务的ensemble教师，同时也是自我超vised系统的学生。我们应用我们的模型到现代时代最重要的问题之一：地球观测，这是一个高度多任务的问题，经常缺少真实数据。通过对NASA NEO数据集进行广泛的实验，覆盖22年时间段，我们展示了我们的多任务半超监教学方法的价值，通过与强基线和最新研究的相对比较，我们的模型在多个任务上具有稳定和可靠的表现。此外，我们还证明了超графи可以适应无监督数据分布变化，通过自我超vision过程，可以重新生成多个观测层的缺失数据，保持稳定的表现，达到7年之久。
</details></li>
</ul>
<hr>
<h2 id="Spectral-Graphormer-Spectral-Graph-based-Transformer-for-Egocentric-Two-Hand-Reconstruction-using-Multi-View-Color-Images"><a href="#Spectral-Graphormer-Spectral-Graph-based-Transformer-for-Egocentric-Two-Hand-Reconstruction-using-Multi-View-Color-Images" class="headerlink" title="Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images"></a>Spectral Graphormer: Spectral Graph-based Transformer for Egocentric Two-Hand Reconstruction using Multi-View Color Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11015">http://arxiv.org/abs/2308.11015</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eldentse/Spectral-Graphormer">https://github.com/eldentse/Spectral-Graphormer</a></li>
<li>paper_authors: Tze Ho Elden Tse, Franziska Mueller, Zhengyang Shen, Danhang Tang, Thabo Beeler, Mingsong Dou, Yinda Zhang, Sasa Petrovic, Hyung Jin Chang, Jonathan Taylor, Bardia Doosti</li>
<li>For:  reconstruction of two high fidelity hands from multi-view RGB images* Methods: transformer-based framework with spectral graph convolution decoder and optimization-based refinement stage* Results: realistic two-hand reconstructions with physical plausibility and generalization to real data, as well as real-time AR&#x2F;VR applications.Here’s the full summary in Simplified Chinese:</li>
<li>for: 重构两个高精度手掌从多视图RGB图像中</li>
<li>methods: 使用变换器基于框架，并使用spectral graph convolution decoder和优化基于的反馈阶段</li>
<li>results: 生成真实的两手重构，并实现数据实际性和AR&#x2F;VR应用中的实时渲染。<details>
<summary>Abstract</summary>
We propose a novel transformer-based framework that reconstructs two high fidelity hands from multi-view RGB images. Unlike existing hand pose estimation methods, where one typically trains a deep network to regress hand model parameters from single RGB image, we consider a more challenging problem setting where we directly regress the absolute root poses of two-hands with extended forearm at high resolution from egocentric view. As existing datasets are either infeasible for egocentric viewpoints or lack background variations, we create a large-scale synthetic dataset with diverse scenarios and collect a real dataset from multi-calibrated camera setup to verify our proposed multi-view image feature fusion strategy. To make the reconstruction physically plausible, we propose two strategies: (i) a coarse-to-fine spectral graph convolution decoder to smoothen the meshes during upsampling and (ii) an optimisation-based refinement stage at inference to prevent self-penetrations. Through extensive quantitative and qualitative evaluations, we show that our framework is able to produce realistic two-hand reconstructions and demonstrate the generalisation of synthetic-trained models to real data, as well as real-time AR/VR applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于转换器的新框架，可以从多视角RGB图像中重建高精度两只手。与现有的手姿估计方法不同，我们处理一个更加复杂的问题Setting，即从 egocentric 视角直接将两只手的绝对根姿 Parameters 高分辨率RGB图像中进行重建。由于现有的数据集不可能进行 egocentric 视角或缺乏背景变化，我们创建了一个大规模的 simulate 数据集和实际数据集，以验证我们的多视角图像特征融合策略。为使重建 Physically plausible，我们提出了两种策略：（i）一种粗到细 spectral 图像 conv 嵌入器来平滑网格时的抗锯齿，以及（ii）在推理时进行优化基于反射 stage 以避免自身穿孔。经过广泛的量化和质量评估，我们表明我们的框架可以生成真实的两只手重建，并示出了 synthetic 训练的模型在实际数据上的普适性，以及实时 AR/VR 应用。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning"><a href="#Autonomous-Detection-of-Methane-Emissions-in-Multispectral-Satellite-Data-Using-Deep-Learning" class="headerlink" title="Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning"></a>Autonomous Detection of Methane Emissions in Multispectral Satellite Data Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11003">http://arxiv.org/abs/2308.11003</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bertrand Rouet-Leduc, Thomas Kerdreux, Alexandre Tuel, Claudia Hulbert</li>
<li>for: 监控全球暖化的一种重要方法，减少温室气体的排放</li>
<li>methods: 使用深度学习方法自动识别几何图像中的甲烷泄漏</li>
<li>results: 比前一代多spectrum甲烷数据产品降低假阳性率，无需对潜在泄漏地点有专业知识<details>
<summary>Abstract</summary>
Methane is one of the most potent greenhouse gases, and its short atmospheric half-life makes it a prime target to rapidly curb global warming. However, current methane emission monitoring techniques primarily rely on approximate emission factors or self-reporting, which have been shown to often dramatically underestimate emissions. Although initially designed to monitor surface properties, satellite multispectral data has recently emerged as a powerful method to analyze atmospheric content. However, the spectral resolution of multispectral instruments is poor, and methane measurements are typically very noisy. Methane data products are also sensitive to absorption by the surface and other atmospheric gases (water vapor in particular) and therefore provide noisy maps of potential methane plumes, that typically require extensive human analysis. Here, we show that the image recognition capabilities of deep learning methods can be leveraged to automatize the detection of methane leaks in Sentinel-2 satellite multispectral data, with dramatically reduced false positive rates compared with state-of-the-art multispectral methane data products, and without the need for a priori knowledge of potential leak sites. Our proposed approach paves the way for the automated, high-definition and high-frequency monitoring of point-source methane emissions across the world.
</details>
<details>
<summary>摘要</summary>
偏二氢（methane）是全球暖化气体中最强大的一种，它的大气半衰期短，使其成为快速降低全球暖化的目标。然而，当前的偏二氢泄漏监测技术主要基于估算性的泄漏因素或者自我报告，这些估算经常会很大的下降估计。虽然初始设计用于观察地面特性，但卫星多spectral数据最近才被发现作为分析大气内容的 poderoso方法。然而，多spectral工具的 spectral resolution很差，偏二氢测量通常很吵闹。偏二氢数据产品也受到地面和其他大气气体（水蒸气特别是）的吸收，因此提供的偏二氢潮区图像通常需要人工分析。在这里，我们展示了深度学习方法的图像识别能力可以自动化卫星Sentinel-2多spectral数据中的偏二氢泄漏检测，与现有的多spectral偏二氢数据产品相比， false positive 率有所下降，而无需先知泄漏点位置的假设。我们的提出的方法开 up a new way for the automatic, high-definition and high-frequency monitoring of point-source methane emissions around the world.
</details></li>
</ul>
<hr>
<h2 id="Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation"><a href="#Switched-auxiliary-loss-for-robust-training-of-transformer-models-for-histopathological-image-segmentation" class="headerlink" title="Switched auxiliary loss for robust training of transformer models for histopathological image segmentation"></a>Switched auxiliary loss for robust training of transformer models for histopathological image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10994">http://arxiv.org/abs/2308.10994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mustaffa Hussain, Saharsh Barve</li>
<li>For: 本研究旨在提供一种模型，用于分类多个器官Functional Tissue Units (FTUs)的cell population neighborhoods，以便帮助病理学家更好地理解人体疾病的影响。* Methods: 该模型使用HuBMAP + HPA - Hacking the Human Body competition dataset进行训练，并提出了shifted auxiliary loss来解决深度模型的减速问题。* Results: 该模型在公共数据集上取得了0.793的dice分数，而在私有数据集上取得了0.778的dice分数，与传统方法相比，该方法提供了1%的提升。这些结果表明 transformers 模型在医学图像分析中的粗粒预测任务中的表现非常出色，并且可以帮助我们更好地理解人体细胞和组织的关系，从而更好地理解人体健康的影响。<details>
<summary>Abstract</summary>
Functional tissue Units (FTUs) are cell population neighborhoods local to a particular organ performing its main function. The FTUs provide crucial information to the pathologist in understanding the disease affecting a particular organ by providing information at the cellular level. In our research, we have developed a model to segment multi-organ FTUs across 5 organs namely: the kidney, large intestine, lung, prostate and spleen by utilizing the HuBMAP + HPA - Hacking the Human Body competition dataset. We propose adding shifted auxiliary loss for training models like the transformers to overcome the diminishing gradient problem which poses a challenge towards optimal training of deep models. Overall, our model achieved a dice score of 0.793 on the public dataset and 0.778 on the private dataset and shows a 1% improvement with the use of the proposed method. The findings also bolster the use of transformers models for dense prediction tasks in the field of medical image analysis. The study assists in understanding the relationships between cell and tissue organization thereby providing a useful medium to look at the impact of cellular functions on human health.
</details>
<details>
<summary>摘要</summary>
功能组织单元（FTU）是指器官本地的细胞群聚，提供了病理学家理解器官疾病的关键信息。在我们的研究中，我们开发了一种方法来在5种器官（肾脏、大小肠、肺、肾脏和脾脏）的FTU中进行多器官分割，使用了HuBMAP+HPA-Hacking the Human Body竞赛数据集。我们提议在训练模型时使用偏移 auxiliary loss，以解决深度模型训练过程中的减少梯度问题。总的来说，我们的模型在公共数据集上 achievement了0.793的 dice 分数，在私有数据集上 achievement了0.778的 dice 分数，与使用我们提议的方法相比，提高了1%。这些结果也证明了transformers模型在医学影像分析中的稠密预测任务中的可靠性。本研究帮助我们理解细胞和组织结构之间的关系，从而提供了一个有用的媒体来查看细胞功能对人类健康的影响。
</details></li>
</ul>
<hr>
<h2 id="Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations"><a href="#Debiasing-Counterfactuals-In-the-Presence-of-Spurious-Correlations" class="headerlink" title="Debiasing Counterfactuals In the Presence of Spurious Correlations"></a>Debiasing Counterfactuals In the Presence of Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10984">http://arxiv.org/abs/2308.10984</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amar Kumar, Nima Fathi, Raghav Mehta, Brennan Nichyporuk, Jean-Pierre R. Falet, Sotirios Tsaftaris, Tal Arbel</li>
<li>for: The paper is written for the task of medical imaging classification, specifically addressing the issue of deep learning models relying on spurious correlations in the training data.</li>
<li>methods: The paper proposes an end-to-end training framework that integrates popular debiasing classifiers (such as distributionally robust optimization) with counterfactual image generation to expose generalizable imaging markers of relevance to the task, and a novel metric (Spurious Correlation Latching Score) to quantify the extent of classifier reliance on spurious correlations.</li>
<li>results: The paper demonstrates through comprehensive experiments on two public datasets (with simulated and real visual artifacts) that the debiasing method (i) learns generalizable markers across the population and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了医学成像分类任务而写的，特别是处理深度学习模型在训练数据中遇到的假 correlate 问题。</li>
<li>methods: 这篇论文提出了一种结合流行的偏差纠正分类器（如分布式稳定优化）和对假 correlate 进行抗衡的末端训练框架，以及一个新的指标（假 correlate 抓取得分）来衡量分类器偏差的程度。</li>
<li>results: 这篇论文通过对公共数据集（包括模拟和实际视觉杂质）进行了广泛的实验，证明了偏差方法可以（一）学习人口中的通用标记，并（二）忽略假 correlate 并专注于下面疾病生物学。<details>
<summary>Abstract</summary>
Deep learning models can perform well in complex medical imaging classification tasks, even when basing their conclusions on spurious correlations (i.e. confounders), should they be prevalent in the training dataset, rather than on the causal image markers of interest. This would thereby limit their ability to generalize across the population. Explainability based on counterfactual image generation can be used to expose the confounders but does not provide a strategy to mitigate the bias. In this work, we introduce the first end-to-end training framework that integrates both (i) popular debiasing classifiers (e.g. distributionally robust optimization (DRO)) to avoid latching onto the spurious correlations and (ii) counterfactual image generation to unveil generalizable imaging markers of relevance to the task. Additionally, we propose a novel metric, Spurious Correlation Latching Score (SCLS), to quantify the extent of the classifier reliance on the spurious correlation as exposed by the counterfactual images. Through comprehensive experiments on two public datasets (with the simulated and real visual artifacts), we demonstrate that the debiasing method: (i) learns generalizable markers across the population, and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.
</details>
<details>
<summary>摘要</summary>
In this work, we introduce the first end-to-end training framework that integrates both (i) popular debiasing classifiers (e.g. distributionally robust optimization (DRO)) to avoid latching onto the spurious correlations and (ii) counterfactual image generation to unveil generalizable imaging markers of relevance to the task. We also propose a novel metric, Spurious Correlation Latching Score (SCLS), to quantify the extent of the classifier reliance on the spurious correlation as exposed by the counterfactual images.Through comprehensive experiments on two public datasets (with simulated and real visual artifacts), we demonstrate that the debiasing method: (i) learns generalizable markers across the population, and (ii) successfully ignores spurious correlations and focuses on the underlying disease pathology.
</details></li>
</ul>
<hr>
<h2 id="VQA-Therapy-Exploring-Answer-Differences-by-Visually-Grounding-Answers"><a href="#VQA-Therapy-Exploring-Answer-Differences-by-Visually-Grounding-Answers" class="headerlink" title="VQA Therapy: Exploring Answer Differences by Visually Grounding Answers"></a>VQA Therapy: Exploring Answer Differences by Visually Grounding Answers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11662">http://arxiv.org/abs/2308.11662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ccychongyanchen/vqatherapycrowdsourcing">https://github.com/ccychongyanchen/vqatherapycrowdsourcing</a></li>
<li>paper_authors: Chongyan Chen, Samreen Anjum, Danna Gurari</li>
<li>for: 这篇论文是关于视觉问答任务的研究，旨在更好地理解不同人对同一张图片的问题提出不同的答案的原因。</li>
<li>methods: 该论文引入了第一个可视地将每个答案与每个视觉问题相关联的数据集，称为VQAAnswerTherapy。然后，该论文提出了两个新的问题：一是判断视觉问题是否有唯一的答案基础，二是找到所有答案基础的地方。</li>
<li>results: 该论文使用现代算法对这两个新问题进行了评估，以示其在这些问题上的成功和缺点。数据集和评估服务器可以在<a target="_blank" rel="noopener" href="https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/%E4%B8%8A%E5%85%AC%E5%BC%80%E8%8E%B7%E5%8F%96%E3%80%82">https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/上公开获取。</a><details>
<summary>Abstract</summary>
Visual question answering is a task of predicting the answer to a question about an image. Given that different people can provide different answers to a visual question, we aim to better understand why with answer groundings. We introduce the first dataset that visually grounds each unique answer to each visual question, which we call VQAAnswerTherapy. We then propose two novel problems of predicting whether a visual question has a single answer grounding and localizing all answer groundings. We benchmark modern algorithms for these novel problems to show where they succeed and struggle. The dataset and evaluation server can be found publicly at https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/.
</details>
<details>
<summary>摘要</summary>
“视觉问答是一项任务，旨在预测图像上的问题的答案。由于不同的人可能对同一个视觉问题提供不同的答案，我们想要更好地理解这些答案的原因。我们引入了首个可视地固定每个独特答案的视觉问题数据集，称之为VQAAnswerTherapy。我们then提出了两个新的问题：可视地判断问题是否有唯一的答案固定，以及本地化所有答案固定。我们对现代算法进行了测试，以示其在这些新问题上的表现。数据集和评估服务器可以在https://vizwiz.org/tasks-and-datasets/vqa-answer-therapy/上公共获取。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance"><a href="#SupEuclid-Extremely-Simple-High-Quality-OoD-Detection-with-Supervised-Contrastive-Learning-and-Euclidean-Distance" class="headerlink" title="SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance"></a>SupEuclid: Extremely Simple, High Quality OoD Detection with Supervised Contrastive Learning and Euclidean Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10973">http://arxiv.org/abs/2308.10973</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jarrod Haas</li>
<li>for: 本研究旨在提出一种简单而有效的Out-of-Distribution（OoD）检测方法，可以在标准benchmark上达到state-of-the-art的结果。</li>
<li>methods: 本研究使用Supervised Contrastive Learning（SCL）将ResNet18进行训练，并使用Euclidean distance作为分数规则进行评价。</li>
<li>results: 研究发现，使用SCL训练的ResNet18可以在近和远OoD检测benchmark上达到state-of-the-art的结果，无需使用更复杂的方法或更大的模型。<details>
<summary>Abstract</summary>
Out-of-Distribution (OoD) detection has developed substantially in the past few years, with available methods approaching, and in a few cases achieving, perfect data separation on standard benchmarks. These results generally involve large or complex models, pretraining, exposure to OoD examples or extra hyperparameter tuning. Remarkably, it is possible to achieve results that can exceed many of these state-of-the-art methods with a very simple method. We demonstrate that ResNet18 trained with Supervised Contrastive Learning (SCL) produces state-of-the-art results out-of-the-box on near and far OoD detection benchmarks using only Euclidean distance as a scoring rule. This may obviate the need in some cases for more sophisticated methods or larger models, and at the very least provides a very strong, easy to use baseline for further experimentation and analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer"><a href="#MRI-Field-transfer-Reconstruction-with-Limited-Data-Regularization-by-Neural-Style-Transfer" class="headerlink" title="MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer"></a>MRI Field-transfer Reconstruction with Limited Data: Regularization by Neural Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10968">http://arxiv.org/abs/2308.10968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoyao Shen, Yancheng Zhu, Hernan Jara, Sean B. Andersson, Chad W. Farris, Stephan Anderson, Xin Zhang</li>
<li>for: 高品质的MRI重建方法</li>
<li>methods: 使用深度学习模型和风格传递的减噪方法</li>
<li>results: 使用 клиничеMRI扫描数据，能够显著提高图像质量<details>
<summary>Abstract</summary>
Recent works have demonstrated success in MRI reconstruction using deep learning-based models. However, most reported approaches require training on a task-specific, large-scale dataset. Regularization by denoising (RED) is a general pipeline which embeds a denoiser as a prior for image reconstruction. The potential of RED has been demonstrated for multiple image-related tasks such as denoising, deblurring and super-resolution. In this work, we propose a regularization by neural style transfer (RNST) method to further leverage the priors from the neural transfer and denoising engine. This enables RNST to reconstruct a high-quality image from a noisy low-quality image with different image styles and limited data. We validate RNST with clinical MRI scans from 1.5T and 3T and show that RNST can significantly boost image quality. Our results highlight the capability of the RNST framework for MRI reconstruction and the potential for reconstruction tasks with limited data.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:近期研究表明，深度学习基于模型可以成功地进行MRI重建。然而，大多数报道的方法需要任务特定、大规模的数据集来进行训练。噪声除掉（RED）是一个通用管道，它将噪声除掉作为图像重建的前提。RED已经在多种图像相关任务中展示出色，如噪声除掉、锐化和超分辨率。在这个工作中，我们提出了基于神经风格传输的噪声除掉方法（RNST），以更好地利用神经传输和噪声除掉引擎中的前提。这使得RNST可以从噪声低质量图像中重建高质量图像，并且可以处理不同的图像风格和有限的数据。我们验证了RNST使用临床MRI扫描数据，并证明了RNST可以显著提高图像质量。我们的结果表明RNST框架可以用于MRI重建，并且可能在有限数据情况下实现高质量重建。
</details></li>
</ul>
<hr>
<h2 id="BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation"><a href="#BundleSeg-A-versatile-reliable-and-reproducible-approach-to-white-matter-bundle-segmentation" class="headerlink" title="BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation"></a>BundleSeg: A versatile, reliable and reproducible approach to white matter bundle segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10958">http://arxiv.org/abs/2308.10958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Etienne St-Onge, Kurt G Schilling, Francois Rheault</li>
<li>for: 提供一种可靠、可重复、快速的白 matter 路径EXTRACTING方法</li>
<li>methods:  combinest 一种迭代注册过程与一种新发展的精确流线搜索算法，以高效地分割流线无需 трактogram clustering 或简化假设</li>
<li>results: 比state-of-the-art segmentation方法具有改进的重复性和复制性，以及显著的速度提高。 通过增强精度和减少变化，提供了一种 valuabe 的工具 для neuroscience 研究，提高了轨迹学研究中white matter pathways的敏感性和特异性。<details>
<summary>Abstract</summary>
This work presents BundleSeg, a reliable, reproducible, and fast method for extracting white matter pathways. The proposed method combines an iterative registration procedure with a recently developed precise streamline search algorithm that enables efficient segmentation of streamlines without the need for tractogram clustering or simplifying assumptions. We show that BundleSeg achieves improved repeatability and reproducibility than state-of-the-art segmentation methods, with significant speed improvements. The enhanced precision and reduced variability in extracting white matter connections offer a valuable tool for neuroinformatic studies, increasing the sensitivity and specificity of tractography-based studies of white matter pathways.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种可靠、可重复、快速的白 mater 血管路径EXTRACTING方法，称为BundleSeg。该方法结合了迭代注册过程和最近开发的精炼流线搜索算法，可以高效地 segments 流线，无需进行跟踪ogram clustering 或假设。我们展示了 BundleSeg 在EXTRACTING white matter 血管路径上的重复性和复制性得到了提高，同时速度也得到了显著提高。这种更高精度和减少的变化可以为 neuroscience 研究提供一个有价值的工具，提高了追踪学基于 white matter 血管路径的敏感性和特异性。
</details></li>
</ul>
<hr>
<h2 id="CamP-Camera-Preconditioning-for-Neural-Radiance-Fields"><a href="#CamP-Camera-Preconditioning-for-Neural-Radiance-Fields" class="headerlink" title="CamP: Camera Preconditioning for Neural Radiance Fields"></a>CamP: Camera Preconditioning for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10902">http://arxiv.org/abs/2308.10902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keunhong Park, Philipp Henzler, Ben Mildenhall, Jonathan T. Barron, Ricardo Martin-Brualla</li>
<li>for: 高精度3D场景重建</li>
<li>methods: 使用Proxy问题计算抑制器，并使用该抑制器作为预Conditioner进行相机参数优化</li>
<li>results: 对Mip-NeRF 360 dataset中的场景进行重建，比对其他State-of-the-art NeRF方法（如Zip-NeRF）和State-of-the-art联合优化方法（如SCNeRF）减少错误率（RMSE）67%，相比减少29%Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written for optimizing Neural Radiance Fields (NeRF) to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes.</li>
<li>methods: The paper proposes using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and using this transform as a preconditioner for the camera parameters during joint optimization.</li>
<li>results: The paper shows that the proposed approach significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset, reducing error rates (RMSE) by 67% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF.<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) can be optimized to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes. However, NeRFs require accurate camera parameters as input -- inaccurate camera parameters result in blurry renderings. Extrinsic and intrinsic camera parameters are usually estimated using Structure-from-Motion (SfM) methods as a pre-processing step to NeRF, but these techniques rarely yield perfect estimates. Thus, prior works have proposed jointly optimizing camera parameters alongside a NeRF, but these methods are prone to local minima in challenging settings. In this work, we analyze how different camera parameterizations affect this joint optimization problem, and observe that standard parameterizations exhibit large differences in magnitude with respect to small perturbations, which can lead to an ill-conditioned optimization problem. We propose using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and we propose to use this transform as a preconditioner for the camera parameters during joint optimization. Our preconditioned camera optimization significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset: we reduce error rates (RMSE) by 67% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF. Our approach is easy to implement, does not significantly increase runtime, can be applied to a wide variety of camera parameterizations, and can straightforwardly be incorporated into other NeRF-like models.
</details>
<details>
<summary>摘要</summary>
神经辐射场（NeRF）可以优化以获得高精度3D场景重建。然而，NeRF需要准确的摄像头参数作为输入，否则会得到模糊的渲染。通常来说，摄像头参数的内在和外在参数通过Structure-from-Motion（SfM）方法进行估计，但这些技术很少能提供完美的估计。因此，先前的工作已经提议同时优化摄像头参数和NeRF，但这些方法容易陷入困难的设置中。在这个工作中，我们分析了不同的摄像头参数化对这个联合优化问题的影响，并发现标准参数化 exhibit 大量的差异幅度，这可能导致一个不正确的优化问题。我们提出使用一个代理问题计算一个卷积变换，该变换消除了摄像头参数与normalize 其效果的相关性，并我们提议使用这个变换作为摄像头参数的预处理器。我们的预处理后的摄像头优化显著提高了Mip-NeRF 360 dataset中的重建质量：我们降低了误差率（RMSE）相比领先的NeRF方法，Zip-NeRF，和相对于领先的联合优化方法使用摄像头参数化的 SCNeRF，降低了29%。我们的方法易于实现，不会增加运行时间，可以应用于多种摄像头参数化，并可以 straightforwardly 与其他NeRF-like模型结合使用。
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Physically-Aware-Articulated-Mesh-Generation-via-Hierarchical-Deformation"><a href="#Few-Shot-Physically-Aware-Articulated-Mesh-Generation-via-Hierarchical-Deformation" class="headerlink" title="Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation"></a>Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10898">http://arxiv.org/abs/2308.10898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xueyi Liu, Bin Wang, He Wang, Li Yi</li>
<li>for: 本研究旨在解决具有少量示例的物理可知树状对象生成问题。通过观察含有只几个示例的人工骨架对象数据集，我们希望通过学习一个模型，以生成多样化的骨架，并保证其视觉准确性和物理可行性。</li>
<li>methods: 我们提出了两项关键创新，即1）基于分治哲学的层次骨架变换基本模型，以适应具有少量示例的问题，并且可以借鉴大规模的固定骨架上的可转移变换模式；2）基于物理学的变换修正方案，以促进物理可行的生成。</li>
<li>results: 我们在6种人工骨架类别上进行了广泛的实验，并证明了我们的方法在几何上比前方法更好，可以更好地生成具有多样性、高视觉准确性和物理可行性的骨架。此外，我们还进行了ablation研究，以验证我们的两项创新的准确性。研究页面及代码可以在<a target="_blank" rel="noopener" href="https://meowuu7.github.io/few-arti-obj-gen%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://meowuu7.github.io/few-arti-obj-gen中找到。</a><details>
<summary>Abstract</summary>
We study the problem of few-shot physically-aware articulated mesh generation. By observing an articulated object dataset containing only a few examples, we wish to learn a model that can generate diverse meshes with high visual fidelity and physical validity. Previous mesh generative models either have difficulties in depicting a diverse data space from only a few examples or fail to ensure physical validity of their samples. Regarding the above challenges, we propose two key innovations, including 1) a hierarchical mesh deformation-based generative model based upon the divide-and-conquer philosophy to alleviate the few-shot challenge by borrowing transferrable deformation patterns from large scale rigid meshes and 2) a physics-aware deformation correction scheme to encourage physically plausible generations. We conduct extensive experiments on 6 articulated categories to demonstrate the superiority of our method in generating articulated meshes with better diversity, higher visual fidelity, and better physical validity over previous methods in the few-shot setting. Further, we validate solid contributions of our two innovations in the ablation study. Project page with code is available at https://meowuu7.github.io/few-arti-obj-gen.
</details>
<details>
<summary>摘要</summary>
我们研究几何物体生成中受限的几何物体生成问题。通过观察一个具有少量示例的柔软物体数据集，我们希望通过学习一个可以生成多样化的几何模型，以保证高Visual faithfulness和物理有效性。先前的几何生成模型容易在几何空间中示出少量示例的多样性或者缺乏物理有效性的问题。为了解决这些挑战，我们提出了两项关键创新：1. 基于分治理的几何变形生成模型，根据分治理的哲学，从大规模的固定几何中继承可质量的变形模式，以便在几何空间中减少几何数据的几何变形问题。2. 基于物理知识的几何变形修正方案，以促进物理可能的生成。我们对6种柔软物体类型进行了广泛的实验，并证明了我们的方法在几何数据中生成的几何模型具有更高的多样性、更高的Visual faithfulness和更高的物理有效性，相比之前的方法。此外，我们还进行了减少几何变形和物理变形修正的精细分析，以证明我们的两项创新的凝聚性。项目页面和代码可以在https://meowuu7.github.io/few-arti-obj-gen中找到。
</details></li>
</ul>
<hr>
<h2 id="Can-Language-Models-Learn-to-Listen"><a href="#Can-Language-Models-Learn-to-Listen" class="headerlink" title="Can Language Models Learn to Listen?"></a>Can Language Models Learn to Listen?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10897">http://arxiv.org/abs/2308.10897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Evonne Ng, Sanjay Subramanian, Dan Klein, Angjoo Kanazawa, Trevor Darrell, Shiry Ginosar</li>
<li>For: The paper is written for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker’s words.* Methods: The approach uses an autoregressive model that predicts a response of a listener, which is a sequence of listener facial gestures, quantized using a VQ-VAE. The model treats the quantized atomic motion elements as additional language token inputs to a transformer-based large language model.* Results: The generated listener motion is fluent and reflective of language semantics, as shown through quantitative metrics and a qualitative user study. The model demonstrates the ability to utilize temporal and semantic aspects of spoken text.<details>
<summary>Abstract</summary>
We present a framework for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker's words. Given an input transcription of the speaker's words with their timestamps, our approach autoregressively predicts a response of a listener: a sequence of listener facial gestures, quantized using a VQ-VAE. Since gesture is a language component, we propose treating the quantized atomic motion elements as additional language token inputs to a transformer-based large language model. Initializing our transformer with the weights of a language model pre-trained only on text results in significantly higher quality listener responses than training a transformer from scratch. We show that our generated listener motion is fluent and reflective of language semantics through quantitative metrics and a qualitative user study. In our evaluation, we analyze the model's ability to utilize temporal and semantic aspects of spoken text. Project page: https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
</details>
<details>
<summary>摘要</summary>
我们提出了一个框架，用于基于说话人的话语生成适当的面部响应。给定输入词语讲解和时间戳，我们的方法通过自动递归预测一个听众的响应：一个序列化的听众面部姿势，使用VQ-VAE进行量化。由于姿势是语言成分，我们提议对量化的原子运动元素视为额外的语言标记输入，并将其传递给基于转换器的大语言模型进行处理。初始化我们的转换器使用已经预训练的语言模型的权重，比训练从零开始的转换器更有显著的质量提升。我们表示我们生成的听众动作是流畅的，并具有语言 semantics 的表达。在我们的评估中，我们分析了模型对说话文本的时间和 semantics 方面的使用。项目页面：https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Shadow-Mapping-for-Efficient-Inverse-Graphics"><a href="#Differentiable-Shadow-Mapping-for-Efficient-Inverse-Graphics" class="headerlink" title="Differentiable Shadow Mapping for Efficient Inverse Graphics"></a>Differentiable Shadow Mapping for Efficient Inverse Graphics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10896">http://arxiv.org/abs/2308.10896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mworchel/differentiable-shadow-mapping">https://github.com/mworchel/differentiable-shadow-mapping</a></li>
<li>paper_authors: Markus Worchel, Marc Alexa</li>
<li>for: 该论文主要研究如何高效地生成triangle mesh中的阴影。</li>
<li>methods: 该论文提出了一种将预filtered shadow mapping技术与现有的可导着色器结合使用，以实现 triangle mesh中的可导visibility信息。</li>
<li>results: 研究发现，使用可导阴影图可以与不同的 inverse graphics problems 比较快速，并且与不同的灯光传输模拟相比，可以达到类似的准确性水平，而不同的可导着色器无法收敛。<details>
<summary>Abstract</summary>
We show how shadows can be efficiently generated in differentiable rendering of triangle meshes. Our central observation is that pre-filtered shadow mapping, a technique for approximating shadows based on rendering from the perspective of a light, can be combined with existing differentiable rasterizers to yield differentiable visibility information. We demonstrate at several inverse graphics problems that differentiable shadow maps are orders of magnitude faster than differentiable light transport simulation with similar accuracy -- while differentiable rasterization without shadows often fails to converge.
</details>
<details>
<summary>摘要</summary>
我们显示了如何有效地生成阴影在分割形状的几何 Rendering 中。我们的中心观察是可以将阴影预filtering，一种基于灯光的见识测试，与现有的可微化矿物 Rendering 结合，以获得可微化可视性信息。我们在一些逆图学问题中展示了这种方法比对于对称的阴影传递 Simulation 更快速，并且与不含阴影的可微化矿物 Rendering 相比，通常会出现不收敛的问题。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification"><a href="#Unlocking-Accuracy-and-Fairness-in-Differentially-Private-Image-Classification" class="headerlink" title="Unlocking Accuracy and Fairness in Differentially Private Image Classification"></a>Unlocking Accuracy and Fairness in Differentially Private Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10888">http://arxiv.org/abs/2308.10888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonard Berrada, Soham De, Judy Hanwen Shen, Jamie Hayes, Robert Stanforth, David Stutz, Pushmeet Kohli, Samuel L. Smith, Borja Balle</li>
<li>For: 这个研究的目的是让机器学习模型在保护敏感资料的情况下训练，以确保对敏感资料的训练不会泄露敏感信息。* Methods: 这个研究使用了差异调教（Differential Privacy）的金标准框架，以提供正式的隐私保证。* Results: 研究发现，使用预先训练的基础模型，并在这些模型上实现差异调教，可以实现与非隐私模型相似的准确性水平，甚至在资料分布shift的情况下仍能保持高度的准确性。<details>
<summary>Abstract</summary>
Privacy-preserving machine learning aims to train models on private data without leaking sensitive information. Differential privacy (DP) is considered the gold standard framework for privacy-preserving training, as it provides formal privacy guarantees. However, compared to their non-private counterparts, models trained with DP often have significantly reduced accuracy. Private classifiers are also believed to exhibit larger performance disparities across subpopulations, raising fairness concerns. The poor performance of classifiers trained with DP has prevented the widespread adoption of privacy preserving machine learning in industry. Here we show that pre-trained foundation models fine-tuned with DP can achieve similar accuracy to non-private classifiers, even in the presence of significant distribution shifts between pre-training data and downstream tasks. We achieve private accuracies within a few percent of the non-private state of the art across four datasets, including two medical imaging benchmarks. Furthermore, our private medical classifiers do not exhibit larger performance disparities across demographic groups than non-private models. This milestone to make DP training a practical and reliable technology has the potential to widely enable machine learning practitioners to train safely on sensitive datasets while protecting individuals' privacy.
</details>
<details>
<summary>摘要</summary>
隐私保护机器学习的目标是在使用private数据进行训练时保持敏感信息的隐私。不同于其非私有对应的模型，模型通过隐私保护（DP）训练的准确率通常会下降 significatively。此外，private分类器可能会在不同的人口群体之间存在更大的性别差异，引发公平性的问题。由于DP训练的模型性能较差，因此在实业中广泛采用隐私保护机器学习的应用仍然受限。在这篇文章中，我们表明了基于预先训练的基础模型，通过DP进行细化训练可以达到与非私有模型相同的准确率，即使在数据分布变化较大的情况下。我们在四个数据集上达到了与非私有状态的准确率，包括两个医疗影像标准 benchmark。此外，我们的私有医疗分类器不会在不同的人口群体中存在更大的性别差异，与非私有模型相比。这一突破可能使DP训练成为实用和可靠的技术，使机器学习实践者可以在敏感数据上进行安全的训练，同时保护个人隐私。
</details></li>
</ul>
<hr>
<h2 id="Vision-Transformer-Pruning-Via-Matrix-Decomposition"><a href="#Vision-Transformer-Pruning-Via-Matrix-Decomposition" class="headerlink" title="Vision Transformer Pruning Via Matrix Decomposition"></a>Vision Transformer Pruning Via Matrix Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10839">http://arxiv.org/abs/2308.10839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyi Sun</li>
<li>for: 降低存储、运行时内存和计算需求</li>
<li>methods: 使用矩阵分解方法（包括各种QR分解和LU分解）来降低矩阵维度和复杂度</li>
<li>results: 结果表明使用Singular Value Decomposition方法可以保持重要特征的生成，同时降低存储、运行时内存和计算需求。<details>
<summary>Abstract</summary>
This is a further development of Vision Transformer Pruning via matrix decomposition. The purpose of the Vision Transformer Pruning is to prune the dimension of the linear projection of the dataset by learning their associated importance score in order to reduce the storage, run-time memory, and computational demands. In this paper we further reduce dimension and complexity of the linear projection by implementing and comparing several matrix decomposition methods while preserving the generated important features. We end up selected the Singular Value Decomposition as the method to achieve our goal by comparing the original accuracy scores in the original Github repository and the accuracy scores of using those matrix decomposition methods, including Singular Value Decomposition, four versions of QR Decomposition, and LU factorization.
</details>
<details>
<summary>摘要</summary>
这是vision transformer减少的进一步发展，通过矩阵分解来减少数据集的维度。vision transformer减少的目的是学习数据集中每个特征的重要性分数，以降低存储、运行内存和计算成本。在这篇论文中，我们进一步减少了矩阵 projection 的维度和复杂性，并比较了多种矩阵分解方法，包括四种QR分解版本和LU分解。最终，我们选择了单值分解来实现我们的目标，并比较了原始数据集的准确率和使用这些矩阵分解方法得到的准确率。
</details></li>
</ul>
<hr>
<h2 id="EigenPlaces-Training-Viewpoint-Robust-Models-for-Visual-Place-Recognition"><a href="#EigenPlaces-Training-Viewpoint-Robust-Models-for-Visual-Place-Recognition" class="headerlink" title="EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition"></a>EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10832">http://arxiv.org/abs/2308.10832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gmberton/eigenplaces">https://github.com/gmberton/eigenplaces</a></li>
<li>paper_authors: Gabriele Berton, Gabriele Trivigno, Barbara Caputo, Carlo Masone</li>
<li>For: The paper is written for the task of visual place recognition, specifically to improve the robustness of the model to different viewpoints.* Methods: The proposed method, called EigenPlaces, uses a new approach to train the neural network on images from different viewpoints, which embeds viewpoint robustness into the learned global descriptors. The method clusters the training data to explicitly present the model with different views of the same points of interest, without the need for extra supervision.* Results: The paper presents experiments on the most comprehensive set of datasets in literature, showing that EigenPlaces outperforms previous state-of-the-art methods on the majority of datasets, while requiring 60% less GPU memory for training and using 50% smaller descriptors.Here are the three key points in Simplified Chinese text:* For: 这篇论文是为了解决视觉地点识别任务中的视角不一致问题，以提高模型的视角Robustness。* Methods: 提议的方法是EigenPlaces，它使用了一种新的方法来在不同视角的图像上训练神经网络，从而在学习的全球描述符中嵌入视角Robustness。该方法通过对训练数据进行分组，以显式地给模型提供不同视角的同一个点的兴趣点。无需额外监督。* Results: 论文通过对Literature中最完整的数据集进行实验，发现EigenPlaces在大多数数据集上超过了之前的状态之为，而且需要60% menos的GPU内存进行训练，并使用50%更小的描述符。<details>
<summary>Abstract</summary>
Visual Place Recognition is a task that aims to predict the place of an image (called query) based solely on its visual features. This is typically done through image retrieval, where the query is matched to the most similar images from a large database of geotagged photos, using learned global descriptors. A major challenge in this task is recognizing places seen from different viewpoints. To overcome this limitation, we propose a new method, called EigenPlaces, to train our neural network on images from different point of views, which embeds viewpoint robustness into the learned global descriptors. The underlying idea is to cluster the training data so as to explicitly present the model with different views of the same points of interest. The selection of this points of interest is done without the need for extra supervision. We then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60\% less GPU memory for training and using 50\% smaller descriptors. The code and trained models for EigenPlaces are available at {\small{\url{https://github.com/gmberton/EigenPlaces}}}, while results with any other baseline can be computed with the codebase at {\small{\url{https://github.com/gmberton/auto_VPR}}}.
</details>
<details>
<summary>摘要</summary>
“视觉地标识任务的目标是根据图像（叫做查询）的视觉特征来预测图像的位置。通常通过图像检索，将查询图像与大量地标注的图像库中的最相似图像进行匹配，使用学习的全局描述符。一个主要挑战在这个任务中是识别不同视点下的地标。为解决这个限制，我们提出了一新的方法，叫做EigenPlaces，通过在不同视点下训练神经网络，将视点强度嵌入到学习的全局描述符中。这个思想是将训练数据集分为不同视点下的部分，以便显式地将模型暴露给不同视点下的同一个点感兴趣。无需额外监督，我们选择了这些点感兴趣。我们then present experiments on the most comprehensive set of datasets in literature, finding that EigenPlaces is able to outperform previous state of the art on the majority of datasets, while requiring 60% less GPU memory for training and using 50% smaller descriptors. The code and trained models for EigenPlaces are available at [https://github.com/gmberton/EigenPlaces](https://github.com/gmberton/EigenPlaces), while results with any other baseline can be computed with the codebase at [https://github.com/gmberton/auto_VPR](https://github.com/gmberton/auto_VPR).”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction"><a href="#Pixel-Adaptive-Deep-Unfolding-Transformer-for-Hyperspectral-Image-Reconstruction" class="headerlink" title="Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction"></a>Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10820">http://arxiv.org/abs/2308.10820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miaoyu Li, Ying Fu, Ji Liu, Yulun Zhang</li>
<li>for: 本文提出了一种基于深度 unfolding 框架的高spectral像素 (HSI) 重建方法，以解决现有方法尚未能充分匹配 HSI 数据的问题。</li>
<li>methods: 本文使用了一种拥有 pixele adaptive descent 步长的数据模块，并引入了 Non-local Spectral Transformer (NST) 来强调 HSI 的3D特性。另外，通过 Fast Fourier Transform (FFT) 改进了不同阶段和层次的特征表达，以解决不同阶段和层次之间的交互问题。</li>
<li>results: 实验结果表明， compared to 现有 HSI 重建方法，本文提出的方法在 simulated 和实际场景中具有更高的重建性能。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/MyuLi/PADUT">https://github.com/MyuLi/PADUT</a> 上下载。<details>
<summary>Abstract</summary>
Hyperspectral Image (HSI) reconstruction has made gratifying progress with the deep unfolding framework by formulating the problem into a data module and a prior module. Nevertheless, existing methods still face the problem of insufficient matching with HSI data. The issues lie in three aspects: 1) fixed gradient descent step in the data module while the degradation of HSI is agnostic in the pixel-level. 2) inadequate prior module for 3D HSI cube. 3) stage interaction ignoring the differences in features at different stages. To address these issues, in this work, we propose a Pixel Adaptive Deep Unfolding Transformer (PADUT) for HSI reconstruction. In the data module, a pixel adaptive descent step is employed to focus on pixel-level agnostic degradation. In the prior module, we introduce the Non-local Spectral Transformer (NST) to emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by the diverse expression of features in different stages and depths, the stage interaction is improved by the Fast Fourier Transform (FFT). Experimental results on both simulated and real scenes exhibit the superior performance of our method compared to state-of-the-art HSI reconstruction methods. The code is released at: https://github.com/MyuLi/PADUT.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Fixed gradient descent step in the data module while the degradation of HSI is agnostic in the pixel level.2. Inadequate prior module for 3D HSI cube.3. Stage interaction ignoring the differences in features at different stages.To address these issues, we propose a Pixel Adaptive Deep Unfolding Transformer (PADUT) for HSI reconstruction. In the data module, we employ a pixel adaptive descent step to focus on pixel-level agnostic degradation. In the prior module, we introduce the Non-local Spectral Transformer (NST) to emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by the diverse expression of features in different stages and depths, we improve the stage interaction by the Fast Fourier Transform (FFT).Experimental results on both simulated and real scenes demonstrate the superior performance of our method compared to state-of-the-art HSI reconstruction methods. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/MyuLi/PADUT">https://github.com/MyuLi/PADUT</a>.</details></li>
</ol>
<hr>
<h2 id="Jumping-through-Local-Minima-Quantization-in-the-Loss-Landscape-of-Vision-Transformers"><a href="#Jumping-through-Local-Minima-Quantization-in-the-Loss-Landscape-of-Vision-Transformers" class="headerlink" title="Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers"></a>Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10814">http://arxiv.org/abs/2308.10814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Natalia Frumkin, Dibakar Gope, Diana Marculescu</li>
<li>for: 提高量化神经网络的精度和效率</li>
<li>methods: 使用进化搜索和infoNCE损失函数 traverse非线性测试损失 landscape</li>
<li>results: 在不同量化级别（3-bit、4-bit、8-bit）下，提高全量化ViT-Base的top-1准确率，并在极端量化场景下保持稳定性和可靠性<details>
<summary>Abstract</summary>
Quantization scale and bit-width are the most important parameters when considering how to quantize a neural network. Prior work focuses on optimizing quantization scales in a global manner through gradient methods (gradient descent \& Hessian analysis). Yet, when applying perturbations to quantization scales, we observe a very jagged, highly non-smooth test loss landscape. In fact, small perturbations in quantization scale can greatly affect accuracy, yielding a $0.5-0.8\%$ accuracy boost in 4-bit quantized vision transformers (ViTs). In this regime, gradient methods break down, since they cannot reliably reach local minima. In our work, dubbed Evol-Q, we use evolutionary search to effectively traverse the non-smooth landscape. Additionally, we propose using an infoNCE loss, which not only helps combat overfitting on the small calibration dataset ($1,000$ images) but also makes traversing such a highly non-smooth surface easier. Evol-Q improves the top-1 accuracy of a fully quantized ViT-Base by $10.30\%$, $0.78\%$, and $0.15\%$ for $3$-bit, $4$-bit, and $8$-bit weight quantization levels. Extensive experiments on a variety of CNN and ViT architectures further demonstrate its robustness in extreme quantization scenarios. Our code is available at https://github.com/enyac-group/evol-q
</details>
<details>
<summary>摘要</summary>
《量化缩放和位宽是神经网络量化时的关键参数。先前的工作通过梯度方法优化量化缩放，但当应用扰动时，我们发现测试损失 landscape 非常峰峦，高度不平。事实上，小于扰动量化缩放可以大幅提高准确性，达到 $0.5-0.8\%$ 的准确率提升。在这种情况下，梯度方法失效，因为它们无法可靠地到达地方最优点。在我们的工作中，称为 Evol-Q，我们使用进化搜索来有效地探索非平坦的表面。此外，我们也提议使用 infoNCE 损失函数，它不仅能够降低在小训练集（1,000 张图像）中的溢出问题，而且使探索非平坦表面更加容易。 Evol-Q 在完全量化 ViT-Base 上提高了 top-1 准确率，分别为 $10.30\%$, $0.78\%$, $0.15\%$  для $3$-bit、$4$-bit 和 $8$-bit 量化 веса级别。我们还进行了对多种 CNN 和 ViT 架构的广泛实验，以证明它的稳定性在极端量化场景下。我们的代码可以在 https://github.com/enyac-group/evol-q 上获取。》
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/cs.CV_2023_08_22/" data-id="cllt9prvd000lol884zavfiez" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.LG_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.LG_2023_08_22/">cs.LG - 2023-08-22 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks"><a href="#A-free-from-local-minima-algorithm-for-training-regressive-MLP-neural-networks" class="headerlink" title="A free from local minima algorithm for training regressive MLP neural networks"></a>A free from local minima algorithm for training regressive MLP neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11532">http://arxiv.org/abs/2308.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Augusto Montisci</li>
<li>for: 本文提出了一种创新的多层感知网络训练方法，以避免地方最小值问题。</li>
<li>methods: 该方法基于训练集分布的性质，或者说是其内部图像，以避免地方最小值问题。</li>
<li>results: 本文对一个知名的基准数据集进行了表现示例，并证明了该方法可以减少地方最小值问题。<details>
<summary>Abstract</summary>
In this article an innovative method for training regressive MLP networks is presented, which is not subject to local minima. The Error-Back-Propagation algorithm, proposed by William-Hinton-Rummelhart, has had the merit of favouring the development of machine learning techniques, which has permeated every branch of research and technology since the mid-1980s. This extraordinary success is largely due to the black-box approach, but this same factor was also seen as a limitation, as soon more challenging problems were approached. One of the most critical aspects of the training algorithms was that of local minima of the loss function, typically the mean squared error of the output on the training set. In fact, as the most popular training algorithms are driven by the derivatives of the loss function, there is no possibility to evaluate if a reached minimum is local or global. The algorithm presented in this paper avoids the problem of local minima, as the training is based on the properties of the distribution of the training set, or better on its image internal to the neural network. The performance of the algorithm is shown for a well-known benchmark.
</details>
<details>
<summary>摘要</summary>
本文提出了一种创新的多层感知网络训练方法，不受地方最小值限制。惠威姆-希茨-鲁姆哈特提出的错误反传播算法在1980年代中期以来，在机器学习领域取得了杰出成就，这一成就主要归功于黑盒模型，但同时也被视为一个限制，因为随着问题的增加 complexity，这种方法的应用逐渐受限。训练算法中最 kritical的问题是搜索函数的地方最小值，通常是训练集上输出的平均方差。因为现有训练算法都是根据损失函数的导数进行驱动，因此无法评估是否到达了地方最小值。本文所提出的方法解决了本问题，基于训练集的分布特性或更好地说，是基于其内部图像的。文中所示的性能表现对一个知名的测试集进行了展示。
</details></li>
</ul>
<hr>
<h2 id="ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm"><a href="#ReLiCADA-–-Reservoir-Computing-using-Linear-Cellular-Automata-Design-Algorithm" class="headerlink" title="ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm"></a>ReLiCADA – Reservoir Computing using Linear Cellular Automata Design Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11522">http://arxiv.org/abs/2308.11522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Kantic, Fabian C. Legl, Walter Stechele, Jakob Hermann</li>
<li>for: 优化Reservoir Computing的设计用于时间序列应用。</li>
<li>methods: 使用Cellular Automata模型选择规则，并解决线性Cellular Automaton规则选择问题。</li>
<li>results: 对相关的标准数据集进行了严格的测试，选择的规则在总规则空间中排名在前5%，并且与其他当前领域模型相比，提供了更低的计算复杂性和训练时间，同时实现了更低的错误率。<details>
<summary>Abstract</summary>
In this paper, we present a novel algorithm to optimize the design of Reservoir Computing using Cellular Automata models for time series applications. Besides selecting the models' hyperparameters, the proposed algorithm particularly solves the open problem of linear Cellular Automaton rule selection. The selection method pre-selects only a few promising candidate rules out of an exponentially growing rule space. When applied to relevant benchmark datasets, the selected rules achieve low errors, with the best rules being among the top 5% of the overall rule space. The algorithm was developed based on mathematical analysis of linear Cellular Automaton properties and is backed by almost one million experiments, adding up to a computational runtime of nearly one year. Comparisons to other state-of-the-art time series models show that the proposed Reservoir Computing using Cellular Automata models have lower computational complexity, at the same time, achieve lower errors. Hence, our approach reduces the time needed for training and hyperparameter optimization by up to several orders of magnitude.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的算法优化储量计算机使用细胞自动机模型进行时间序列应用。除了选择模型的超参数之外，我们的算法特别解决了线性细胞自动机规则选择的开放问题。选择方法先于搜索极其庞大的规则空间中的一些有潜力的候选规则。应用到相关的基准数据集上，选择的规则可以 дости到低的错误率，最好的规则在总规则空间中排名前5%。我们的算法基于细胞自动机的数学分析和大约一百万个实验，计算时间近一年。与其他当前最佳时间序列模型比较，我们的方法具有更低的计算复杂度，同时可以实现更低的错误率。因此，我们的方法可以减少训练和超参数优化所需的时间，可能是数量级减少。
</details></li>
</ul>
<hr>
<h2 id="EM-for-Mixture-of-Linear-Regression-with-Clustered-Data"><a href="#EM-for-Mixture-of-Linear-Regression-with-Clustered-Data" class="headerlink" title="EM for Mixture of Linear Regression with Clustered Data"></a>EM for Mixture of Linear Regression with Clustered Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11518">http://arxiv.org/abs/2308.11518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Reisizadeh, Khashayar Gatmiry, Asuman Ozdaglar</li>
<li>for: 这种问题的答案是如何利用分布式学习框架中的数据归一化来提高学习效果。</li>
<li>methods: 作者使用了Expectation-Maximization（EM）方法来估计二元混合线性回归模型中的参数。</li>
<li>results: 作者表明，如果 Initialize EM 方法正确，并且 $m$ 增长为 $e^{o(n)}$，那么 EM 方法只需要 $O(1)$ 轮次来达到同样的统计准确性，并且提供了新的 asymptotic optimization 和通用的验证保证。<details>
<summary>Abstract</summary>
Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ batches of dependent samples each containing $n$ measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\log(mn/d))$ iterations to reach the statistical accuracy of $O(\sqrt{d/(mn)})$. In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as $m$ grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest.
</details>
<details>
<summary>摘要</summary>
现代数据驱动和分布式学习框架面临各种各样的大规模数据，这些数据来自客户端分布在不同环境中。实际上，数据的差异性是规模化多个分布式学习模式的主要障碍。然而，在一些应用中，客户端生成的数据可能会具有共同结构，例如联邦学习中，每个客户端都生成的所有样本均具有共同的隐藏变量。因此，可以问到如何利用分布式数据中的层次结构来改进学习方案。在这篇论文中，我们解决这个问题，特别是在估计$d$-维参数的两组线性回归问题中。我们使用常见的期望-最大化（EM）方法来估计最大 LIKELIHOOD 参数，从$m$ 批次的相互依赖样本中获取 $n$ 个测量。不考虑分布式数据中的层次结构，EM 知道需要 $O(\log(mn/d))$ 迭代来达到同样的统计准确性，其中 $m$ 是 Client 数量，$n$ 是每个客户端生成的样本数量，$d$ 是维度。然而，我们显示，如果INITIALIZED 正确， THEN EM 在结构化数据上只需要 $O(1)$ 迭代来达到同样的统计准确性，只要 $m$ 增长为 $e^{o(n)}$。我们的分析建立了和更新了可opus和总体Optimization guarantees for population和empirical EM with dependent samples，这可能是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models"><a href="#Mode-Combinability-Exploring-Convex-Combinations-of-Permutation-Aligned-Models" class="headerlink" title="Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models"></a>Mode Combinability: Exploring Convex Combinations of Permutation Aligned Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11511">http://arxiv.org/abs/2308.11511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrián Csiszárik, Melinda F. Kiss, Péter Kőrösi-Szabó, Márton Muntag, Gergely Papp, Dániel Varga</li>
<li>for: 本研究探讨了两个具有相同结构的神经网络参数向量 $\Theta_A$ 和 $\Theta_B$ 的元素积体weighted组合的可能性。</li>
<li>methods: 作者采用了广泛的实验方法，检查了不同的模型组合parametrized by elements of the hypercube $[0,1]^d$ 和其附近的区域。</li>
<li>results: 研究发现，大部分的hypercube区域具有低损失值，表明了模型连接性的扩展到一般现象，称为模式可连接性。 作者还发现了一些新的线性模式连接性和模型重新定位的观察结果。<details>
<summary>Abstract</summary>
We explore element-wise convex combinations of two permutation-aligned neural network parameter vectors $\Theta_A$ and $\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are non-vacuous in the sense that there are significant functional differences between the resulting models.
</details>
<details>
<summary>摘要</summary>
我们探索element-wise convex combinations of two permutation-aligned neural network parameter vectors $\Theta_A$和$\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are non-vacuous in the sense that there are significant functional differences between the resulting models.Here's the translation in Traditional Chinese:我们探索element-wise convex combinations of two permutation-aligned neural network parameter vectors $\Theta_A$和$\Theta_B$ of size $d$. We conduct extensive experiments by examining various distributions of such model combinations parametrized by elements of the hypercube $[0,1]^{d}$ and its vicinity. Our findings reveal that broad regions of the hypercube form surfaces of low loss values, indicating that the notion of linear mode connectivity extends to a more general phenomenon which we call mode combinability. We also make several novel observations regarding linear mode connectivity and model re-basin. We demonstrate a transitivity property: two models re-based to a common third model are also linear mode connected, and a robustness property: even with significant perturbations of the neuron matchings the resulting combinations continue to form a working model. Moreover, we analyze the functional and weight similarity of model combinations and show that such combinations are non-vacuous in the sense that there are significant functional differences between the resulting models.
</details></li>
</ul>
<hr>
<h2 id="Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition"><a href="#Designing-an-attack-defense-game-how-to-increase-robustness-of-financial-transaction-models-via-a-competition" class="headerlink" title="Designing an attack-defense game: how to increase robustness of financial transaction models via a competition"></a>Designing an attack-defense game: how to increase robustness of financial transaction models via a competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11406">http://arxiv.org/abs/2308.11406</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexey Zaytsev, Alex Natekin, Evgeni Vorsin, Valerii Smirnov, Georgii Smirnov, Oleg Sidorshin, Alexander Senin, Alexander Dudin, Dmitry Berestnev</li>
<li>for: 本研究旨在 investigate 机器学习模型在金融交易数据上的护盾机制和攻击策略，以提高金融领域机器学习模型的安全性。</li>
<li>methods: 我们采用了一场竞赛来实现这一目标，其中参与者之间进行直接竞争，以模拟现实生活中的攻击和防御情况。我们还进行了一系列的数学实验和相关的ablation study，以评估不同方法的效果。</li>
<li>results: 我们的分析表明，我们开发的攻击和防御策略在实际执行中表现出色，并且在不同领域中都能够得到显著的提升。此外，我们还发现了一些现有方法的局限性和不足，并提出了一些改进的建议。<details>
<summary>Abstract</summary>
Given the escalating risks of malicious attacks in the finance sector and the consequential severe damage, a thorough understanding of adversarial strategies and robust defense mechanisms for machine learning models is critical. The threat becomes even more severe with the increased adoption in banks more accurate, but potentially fragile neural networks. We aim to investigate the current state and dynamics of adversarial attacks and defenses for neural network models that use sequential financial data as the input.   To achieve this goal, we have designed a competition that allows realistic and detailed investigation of problems in modern financial transaction data. The participants compete directly against each other, so possible attacks and defenses are examined in close-to-real-life conditions. Our main contributions are the analysis of the competition dynamics that answers the questions on how important it is to conceal a model from malicious users, how long does it take to break it, and what techniques one should use to make it more robust, and introduction additional way to attack models or increase their robustness.   Our analysis continues with a meta-study on the used approaches with their power, numerical experiments, and accompanied ablations studies. We show that the developed attacks and defenses outperform existing alternatives from the literature while being practical in terms of execution, proving the validity of the competition as a tool for uncovering vulnerabilities of machine learning models and mitigating them in various domains.
</details>
<details>
<summary>摘要</summary>
随着金融领域中邪恶攻击的升级风险和相应严重的损害，对机器学习模型的敌对策略和鲁棒防御机制的全面理解变得非常重要。随着银行更广泛采用更准确但可能脆弱的神经网络，这种威胁变得更加严重。我们希望通过 investigate现有的敌对攻击和防御策略，以及对神经网络模型使用时间序列金融数据的影响。为实现这个目标，我们设计了一项竞赛，allowing participants to directly compete against each other, allowing for realistic and detailed investigation of problems in modern financial transaction data. Our main contributions include:1. 分析竞赛动态，回答如何隐藏模型从恶意用户，如何打砸它，以及如何使它更加鲁棒。2.  introduce additional way to attack models or increase their robustness.3.  conduct a meta-study on the used approaches, including their power, numerical experiments, and accompanied ablation studies.我们的分析表明，我们提出的攻击和防御策略在实现方面具有优势，并且在不同领域中能够有效地抵御邪恶攻击。这些策略的实现可以在实际应用中进行 praktikable 的执行，证明了竞赛的有效性作为机器学习模型的漏洞探测和 mitigation 工具。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties"><a href="#Machine-learning-assisted-exploration-for-affine-Deligne-Lusztig-varieties" class="headerlink" title="Machine learning assisted exploration for affine Deligne-Lusztig varieties"></a>Machine learning assisted exploration for affine Deligne-Lusztig varieties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11355">http://arxiv.org/abs/2308.11355</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinpf314/ml4adlv">https://github.com/jinpf314/ml4adlv</a></li>
<li>paper_authors: Bin Dong, Xuhua He, Pengfei Jin, Felix Schremmer, Qingchao Yu</li>
<li>for: 本研究使用机器学习助手框架研究非齐次Deligne-Lusztig变换（ADLV）的几何结构，主要目标是研究ADLV中不同维度和分解成分的非空性模式。</li>
<li>methods: 本研究提出了一种数据生成、模型训练、模式分析和人工审阅的可重复管道，表现出机器学习和纯 математиче研究之间的细腻互动。数据生成过程强调选择 significative 子集和适当的特征集。</li>
<li>results: 本研究通过这种框架， rediscovered 虚维度公式并提供了一个新的问题的完整数学证明，同时还扩展了一个已经开放的问题，即一个certain lower bound of dimension的下界。此外，我们还提供了计算ADLV和机器学习模型的源代码，以便进一步的探索。<details>
<summary>Abstract</summary>
This paper presents a novel, interdisciplinary study that leverages a Machine Learning (ML) assisted framework to explore the geometry of affine Deligne-Lusztig varieties (ADLV). The primary objective is to investigate the nonemptiness pattern, dimension and enumeration of irreducible components of ADLV. Our proposed framework demonstrates a recursive pipeline of data generation, model training, pattern analysis, and human examination, presenting an intricate interplay between ML and pure mathematical research. Notably, our data-generation process is nuanced, emphasizing the selection of meaningful subsets and appropriate feature sets. We demonstrate that this framework has a potential to accelerate pure mathematical research, leading to the discovery of new conjectures and promising research directions that could otherwise take significant time to uncover. We rediscover the virtual dimension formula and provide a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension. Furthermore, we extend an open invitation to the readers by providing the source code for computing ADLV and the ML models, promoting further explorations. This paper concludes by sharing valuable experiences and highlighting lessons learned from this collaboration.
</details>
<details>
<summary>摘要</summary>
Notably, our data generation process is sophisticated, focusing on selecting meaningful subsets and appropriate feature sets. We show that this framework has the potential to accelerate pure mathematical research, leading to the discovery of new conjectures and promising research directions that might otherwise take a long time to uncover.In this paper, we rediscover the virtual dimension formula and provide a full mathematical proof of a newly identified problem concerning a certain lower bound of dimension. Furthermore, we extend an open invitation to readers by providing the source code for computing ADLV and the ML models, encouraging further explorations.This paper concludes by sharing valuable experiences and highlighting lessons learned from this collaboration.
</details></li>
</ul>
<hr>
<h2 id="WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data"><a href="#WEARS-Wearable-Emotion-AI-with-Real-time-Sensor-data" class="headerlink" title="WEARS: Wearable Emotion AI with Real-time Sensor data"></a>WEARS: Wearable Emotion AI with Real-time Sensor data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11673">http://arxiv.org/abs/2308.11673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhruv Limbani, Daketi Yatin, Nitish Chaturvedi, Vaishnavi Moorthy, Pushpalatha M, Harichandana BSS, Sumit Kumar</li>
<li>for: 这 paper 的目的是提出一种基于智能手表传感器的情绪预测系统，以便在日常生活中识别用户的情绪。</li>
<li>methods: 这 paper 使用了一种混合英文和地方语言的视频来采集真实数据，并使用多种机器学习模型进行模型化。</li>
<li>results: 实验结果显示，使用多层感知器模型可以达到93.75%的最高准确率，并且对心率、加速度和自转仪器数据进行了ablation研究，以便更好地理解各种传感器数据对情绪识别的影响。<details>
<summary>Abstract</summary>
Emotion prediction is the field of study to understand human emotions. Existing methods focus on modalities like text, audio, facial expressions, etc., which could be private to the user. Emotion can be derived from the subject's psychological data as well. Various approaches that employ combinations of physiological sensors for emotion recognition have been proposed. Yet, not all sensors are simple to use and handy for individuals in their daily lives. Thus, we propose a system to predict user emotion using smartwatch sensors. We design a framework to collect ground truth in real-time utilizing a mix of English and regional language-based videos to invoke emotions in participants and collect the data. Further, we modeled the problem as binary classification due to the limited dataset size and experimented with multiple machine-learning models. We also did an ablation study to understand the impact of features including Heart Rate, Accelerometer, and Gyroscope sensor data on mood. From the experimental results, Multi-Layer Perceptron has shown a maximum accuracy of 93.75 percent for pleasant-unpleasant (high/low valence classification) moods.
</details>
<details>
<summary>摘要</summary>
预测人类情感是一个研究领域，旨在理解人类情感的变化。现有方法主要基于模式如文本、音频、脸部表达等，这些模式可能是用户私有的。另外，情感也可以从主体的心理数据中 derivation。多种方法使用组合的生物学传感器进行情感识别的建议。然而，不是所有传感器都是容易使用和日常生活中手动使用的。因此，我们提出了使用智能手表传感器预测用户情感的系统。我们设计了一个框架，通过混合英文和地区语言基于视频诱发情感并收集数据。此外，我们将问题设置为二分类问题，因为数据集的限制性，并试用多种机器学习模型。我们还进行了减少研究，以了解特定传感器数据的影响。从实验结果来看，多层感知网络在高/低积极情感（愉悦-不愉悦）类别上达到了最高的准确率为93.75%。
</details></li>
</ul>
<hr>
<h2 id="Careful-at-Estimation-and-Bold-at-Exploration"><a href="#Careful-at-Estimation-and-Bold-at-Exploration" class="headerlink" title="Careful at Estimation and Bold at Exploration"></a>Careful at Estimation and Bold at Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11348">http://arxiv.org/abs/2308.11348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xing Chen, Yijun Liu, Zhaogeng Liu, Hechang Chen, Hengshuai Yao, Yi Chang</li>
<li>for: 该 paper 的目的是提出一种新的探索策略来解决DPRL中的探索问题，以提高DPRL的性能。</li>
<li>methods: 该 paper 使用了double-Q函数框架，提出了一种新的探索策略，包括greedy Q softmax更新 schema和action探索与Q值更新的组合。</li>
<li>results: 该 paper 在Mujoco benchmark上进行了实验，并证明了其在不同环境中的优秀表现，特别是在最复杂的人工智能环境中。<details>
<summary>Abstract</summary>
Exploration strategies in continuous action space are often heuristic due to the infinite actions, and these kinds of methods cannot derive a general conclusion. In prior work, it has been shown that policy-based exploration is beneficial for continuous action space in deterministic policy reinforcement learning(DPRL). However, policy-based exploration in DPRL has two prominent issues: aimless exploration and policy divergence, and the policy gradient for exploration is only sometimes helpful due to inaccurate estimation. Based on the double-Q function framework, we introduce a novel exploration strategy to mitigate these issues, separate from the policy gradient. We first propose the greedy Q softmax update schema for Q value update. The expected Q value is derived by weighted summing the conservative Q value over actions, and the weight is the corresponding greedy Q value. Greedy Q takes the maximum value of the two Q functions, and conservative Q takes the minimum value of the two different Q functions. For practicality, this theoretical basis is then extended to allow us to combine action exploration with the Q value update, except for the premise that we have a surrogate policy that behaves like this exploration policy. In practice, we construct such an exploration policy with a few sampled actions, and to meet the premise, we learn such a surrogate policy by minimizing the KL divergence between the target policy and the exploration policy constructed by the conservative Q. We evaluate our method on the Mujoco benchmark and demonstrate superior performance compared to previous state-of-the-art methods across various environments, particularly in the most complex Humanoid environment.
</details>
<details>
<summary>摘要</summary>
<SYS><translation>探索策略在连续动作空间 frequently 是随机的，因为动作的数量是无限的，这类方法无法得出一般结论。在先前的工作中，已经证明了在 deterministic policy reinforcement learning（DPRL） 中的策略基于探索是有利。然而，DPRL 中的策略基于探索存在两个明显的问题：无目的探索和策略分化，并且Policy gradient for exploration 只有在不准确的估计时才能帮助。基于 double-Q 函数框架，我们介绍了一种新的探索策略，与 Policy gradient 分离。我们首先提出了 Q 值更新 schema，将 Q 值更新为 greedy Q softmax Weighted sum。预期 Q 值由 actions 的 greedy Q 值Weighted sum  derive，greedy Q 取得最大值，conservative Q 取得最小值。为了实用，我们将这种理论基础EXTEND TO ALLOW US TO COMBINE ACTION EXPLORATION WITH Q VALUE UPDATE，只要我们有一个 substitute policy ，该策略在探索过程中与目标策略类似。在实践中，我们构建了一个这种探索策略，使用了一些采样的动作，并为了满足这种前提，我们学习了一个 substitute policy ，通过最小化 KL divergence  между target policy 和探索策略来减少 KL divergence。我们在 Mujoco  benchmark 上评估了我们的方法，并在不同的环境中表现出优于先前的状态艺术方法，特别是在最复杂的人类形态环境中。</translation></SYS>Note: Simplified Chinese is used in this translation, as it is more widely used in mainland China and is the standard for most online content. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings"><a href="#Generalising-sequence-models-for-epigenome-predictions-with-tissue-and-assay-embeddings" class="headerlink" title="Generalising sequence models for epigenome predictions with tissue and assay embeddings"></a>Generalising sequence models for epigenome predictions with tissue and assay embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11671">http://arxiv.org/abs/2308.11671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacob Deasy, Ron Schwessinger, Ferran Gonzalez, Stephen Young, Kim Branson</li>
<li>for: 预测epigenetic profile的Sequence模型方法在最近几年内得到了广泛发展，包括序列长度、模型大小以及profile多样性。</li>
<li>methods: 我们使用Contextualised Genomic Network（CGN）来集成组织和assay嵌入，从而利用上下文信息来增强长距离序列嵌入。与之前的方法不同，我们在输入空间中使用上下文信息来增强长距离序列嵌入，而不是扩展输出空间。</li>
<li>results: 我们在一个广泛的epigenetic profile集合中展示了我们的方法的效果，并为genetic variant对epigenetic sequence模型训练的影响提供了第一个洞见。我们的总体方法在多个设置中超越了现状，并且采用了更严格的验证过程。<details>
<summary>Abstract</summary>
Sequence modelling approaches for epigenetic profile prediction have recently expanded in terms of sequence length, model size, and profile diversity. However, current models cannot infer on many experimentally feasible tissue and assay pairs due to poor usage of contextual information, limiting $\textit{in silico}$ understanding of regulatory genomics. We demonstrate that strong correlation can be achieved across a large range of experimental conditions by integrating tissue and assay embeddings into a Contextualised Genomic Network (CGN). In contrast to previous approaches, we enhance long-range sequence embeddings with contextual information in the input space, rather than expanding the output space. We exhibit the efficacy of our approach across a broad set of epigenetic profiles and provide the first insights into the effect of genetic variants on epigenetic sequence model training. Our general approach to context integration exceeds state of the art in multiple settings while employing a more rigorous validation procedure.
</details>
<details>
<summary>摘要</summary>
Sequence模型方法 дляepigeneticprofile预测最近几年来有所扩展，包括序列长度、模型大小和profile多样性。然而，当前的模型无法涵盖许多实验可行的组织和测试对 pair，因为各种Contextualinformation的使用不佳，限制了$\textit{in silico}$理解的规则 genomics。我们示出，可以在各种实验条件下 achieves强相关性，通过在输入空间中 integrating组织和测试嵌入（CGN）。与之前的方法不同，我们在长距离序列嵌入中增强了 Contextualinformation，而不是扩展输出空间。我们在多种epigeneticprofile中展示了我们的方法的效果，并提供了遗传变种对epigenetic sequence模型训练的首次研究。我们的通用方法可以在多个设置中超越当前状态，并采用更严格的验证过程。
</details></li>
</ul>
<hr>
<h2 id="Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation"><a href="#Protect-Federated-Learning-Against-Backdoor-Attacks-via-Data-Free-Trigger-Generation" class="headerlink" title="Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation"></a>Protect Federated Learning Against Backdoor Attacks via Data-Free Trigger Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11333">http://arxiv.org/abs/2308.11333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanxin Yang, Ming Hu, Yue Cao, Jun Xia, Yihao Huang, Yang Liu, Mingsong Chen<br>for: This paper aims to address the vulnerability of Federated Learning (FL) to poisoning attacks, specifically backdoor attacks, by proposing a novel data-free trigger-generation-based defense approach.methods: The proposed approach uses two characteristics of backdoor attacks to generate trigger images that can eliminate poisoned models and ensure the updated global model is benign. These trigger images are generated by identifying the differences between the old and new global models and evaluating the effect of these generated images.results: The proposed approach can defend against almost all existing types of backdoor attacks and outperform all seven state-of-the-art defense methods with both IID and non-IID scenarios. In addition, the approach can successfully defend against backdoor attacks even when 80% of the clients are malicious.<details>
<summary>Abstract</summary>
As a distributed machine learning paradigm, Federated Learning (FL) enables large-scale clients to collaboratively train a model without sharing their raw data. However, due to the lack of data auditing for untrusted clients, FL is vulnerable to poisoning attacks, especially backdoor attacks. By using poisoned data for local training or directly changing the model parameters, attackers can easily inject backdoors into the model, which can trigger the model to make misclassification of targeted patterns in images. To address these issues, we propose a novel data-free trigger-generation-based defense approach based on the two characteristics of backdoor attacks: i) triggers are learned faster than normal knowledge, and ii) trigger patterns have a greater effect on image classification than normal class patterns. Our approach generates the images with newly learned knowledge by identifying the differences between the old and new global models, and filters trigger images by evaluating the effect of these generated images. By using these trigger images, our approach eliminates poisoned models to ensure the updated global model is benign. Comprehensive experiments demonstrate that our approach can defend against almost all the existing types of backdoor attacks and outperform all the seven state-of-the-art defense methods with both IID and non-IID scenarios. Especially, our approach can successfully defend against the backdoor attack even when 80\% of the clients are malicious.
</details>
<details>
<summary>摘要</summary>
如一种分布式机器学习 paradigma，联邦学习（FL）允许大规模客户端共同训练模型，而无需分享 raw 数据。然而，由于没有数据审核 для不可信客户端，FL 容易受到毒素攻击，特别是后门攻击。攻击者可以使用毒素数据进行本地训练或直接修改模型参数，轻松地植入后门到模型中，导致模型对预期的图像模式进行误分类。为解决这些问题，我们提出了一种基于两个特征的数据-自由触发器生成防御方法：一、触发器更快学习Normal Knowledge，二、触发器图像在图像分类中具有更大的效果。我们的方法生成新学习的图像，并将触发器图像筛选出来。通过使用这些触发器图像，我们的方法可以消除毒素模型，以确保更新的全球模型是善意的。我们的实验表明，我们的方法可以防御大多数现有的后门攻击，并在IID和非IID场景下超过所有七种现有的防御方法。特别是，我们的方法可以成功防御80%的客户端是恶意的情况下的后门攻击。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments"><a href="#Machine-Learning-based-Positioning-using-Multivariate-Time-Series-Classification-for-Factory-Environments" class="headerlink" title="Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments"></a>Machine Learning-based Positioning using Multivariate Time Series Classification for Factory Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11670">http://arxiv.org/abs/2308.11670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nisal Hemadasa Manikku Badu, Marcus Venzke, Volker Turau, Yanqiu Huang</li>
<li>for: 这篇论文是用于解决室内定位系统（IPS）在各种产业应用中的问题的。</li>
<li>methods: 这篇论文使用了机器学习（ML）技术，通过使用固件设备的动态和环境感知器来实现室内定位。</li>
<li>results: 论文通过对多个机器学习模型进行比较，发现了一个名为 CNN-1D 的模型，它在精度、内存占用率和推理速度三个方面均有优秀的性能。<details>
<summary>Abstract</summary>
Indoor Positioning Systems (IPS) gained importance in many industrial applications. State-of-the-art solutions heavily rely on external infrastructures and are subject to potential privacy compromises, external information requirements, and assumptions, that make it unfavorable for environments demanding privacy and prolonged functionality. In certain environments deploying supplementary infrastructures for indoor positioning could be infeasible and expensive. Recent developments in machine learning (ML) offer solutions to address these limitations relying only on the data from onboard sensors of IoT devices. However, it is unclear which model fits best considering the resource constraints of IoT devices. This paper presents a machine learning-based indoor positioning system, using motion and ambient sensors, to localize a moving entity in privacy concerned factory environments. The problem is formulated as a multivariate time series classification (MTSC) and a comparative analysis of different machine learning models is conducted in order to address it. We introduce a novel time series dataset emulating the assembly lines of a factory. This dataset is utilized to assess and compare the selected models in terms of accuracy, memory footprint and inference speed. The results illustrate that all evaluated models can achieve accuracies above 80 %. CNN-1D shows the most balanced performance, followed by MLP. DT was found to have the lowest memory footprint and inference latency, indicating its potential for a deployment in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
室内定位系统（IPS）在多个工业应用中升级到了重要地位。当前的解决方案大多依赖于外部基础设施，并且受到外部信息要求、假设和隐私问题的限制，这使得在需要隐私和长期可用性的环境中部署室内定位系统变得不可能或者太过昂贵。当前的机器学习（ML）技术提供了解决这些限制的解决方案，不需要外部基础设施，仅仅使用宠物设备上的固件传感器数据。然而，选择最佳的机器学习模型仍然存在问题，特别是考虑到宠物设备的资源限制。本文提出了一种基于机器学习的室内定位系统，使用运动和 ambient 传感器来确定移动实体在隐私关注的制造厂房环境中的位置。问题被形式化为多变量时间序列分类（MTSC），并进行了不同机器学习模型的比较分析，以解决其中的问题。我们提供了一个新的时间序列数据集，模拟了制造厂房的生产线。这个数据集被用来评估和比较选择的模型，以确定它们在精度、内存占用量和推理速度等方面的表现。结果表明所有评估模型均可以达到上百分之八十的准确率。CNN-1D 表现最平衡，其次是 MLP。DT 具有最低的内存占用量和推理延迟，表明其在实际场景中的部署潜在性。
</details></li>
</ul>
<hr>
<h2 id="Class-Label-aware-Graph-Anomaly-Detection"><a href="#Class-Label-aware-Graph-Anomaly-Detection" class="headerlink" title="Class Label-aware Graph Anomaly Detection"></a>Class Label-aware Graph Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11669">http://arxiv.org/abs/2308.11669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jhkim611/clad">https://github.com/jhkim611/clad</a></li>
<li>paper_authors: Junghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, Chanyoung Park</li>
<li>for: 检测图像中的结构异常（structural anomalies）</li>
<li>methods: 使用有限的标注节点来增强无监督图像异常检测（unsupervised graph anomaly detection）的性能</li>
<li>results: 在十个数据集上进行了广泛的实验，并证明了CLAD在缺乏类别标签信息的情况下也能够显著提高异常检测性能，比较于现有的无监督图像异常检测方法。<details>
<summary>Abstract</summary>
Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}." into Simplified Chinese.<<SYS>>不监督的GAD方法假设缺乏异常标签，即节点是否异常。我们从前一些不监督方法中所观察到的一个常见现象是，它们不仅假设缺乏异常标签，还假设缺乏类标签（用于普通的节点分类任务中的节点类别）。在这种情况下，我们研究了基于类标签的不监督GAD框架（CLAD）的utilidad，特别是如何通过限制数量的标签节点来提高不监督GAD的性能。我们对10个数据集进行了广泛的实验，结果表明CLAD在对不监督GAD方法进行比较时表现更优秀，即使没有地面真实的类标签信息。CLAD的源代码可以在\url{https://github.com/jhkim611/CLAD}中找到。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices"><a href="#Uncertainty-Estimation-of-Transformers’-Predictions-via-Topological-Analysis-of-the-Attention-Matrices" class="headerlink" title="Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices"></a>Uncertainty Estimation of Transformers’ Predictions via Topological Analysis of the Attention Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11295">http://arxiv.org/abs/2308.11295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kostenok, Daniil Cherniavskii, Alexey Zaytsev</li>
<li>for: 本研究旨在解决深度学习模型在预测中的信任度评估问题，这是自然语言处理领域的一个开放问题。</li>
<li>methods: 我们使用基于Transformer架构的神经网络，并利用Topological Data Analysis方法来探索内部表示关系，以估计模型的信任度。</li>
<li>results: 我们的方法比传统方法更高质量，并开启了新的应用领域，但是需要选择 topological 特征。<details>
<summary>Abstract</summary>
Determining the degree of confidence of deep learning model in its prediction is an open problem in the field of natural language processing. Most of the classical methods for uncertainty estimation are quite weak for text classification models. We set the task of obtaining an uncertainty estimate for neural networks based on the Transformer architecture. A key feature of such mo-dels is the attention mechanism, which supports the information flow between the hidden representations of tokens in the neural network. We explore the formed relationships between internal representations using Topological Data Analysis methods and utilize them to predict model's confidence. In this paper, we propose a method for uncertainty estimation based on the topological properties of the attention mechanism and compare it with classical methods. As a result, the proposed algorithm surpasses the existing methods in quality and opens up a new area of application of the attention mechanism, but requires the selection of topological features.
</details>
<details>
<summary>摘要</summary>
确定深度学习模型的预测结果的可信度是自然语言处理领域的一个开放问题。大多数经典方法对文本分类模型的不确定性估计非常弱。我们将任务设置为基于Transformer架构的神经网络不确定性估计。Transformer模型的一个关键特点是听力机制，可以支持神经网络中token的隐藏表示之间的信息流动。我们通过使用Topological Data Analysis方法探索神经网络内部表示的关系，并利用它们来预测模型的可信度。在这篇论文中，我们提出了基于Topological Properties的不确定性估计方法，并与经典方法进行比较。结果显示，我们的方法质量高于现有方法，开启了新的应用领域，但需要选择Topological特征。
</details></li>
</ul>
<hr>
<h2 id="Network-Momentum-across-Asset-Classes"><a href="#Network-Momentum-across-Asset-Classes" class="headerlink" title="Network Momentum across Asset Classes"></a>Network Momentum across Asset Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11294">http://arxiv.org/abs/2308.11294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyue Pu, Stephen Roberts, Xiaowen Dong, Stefan Zohren</li>
<li>for: 这篇论文探讨了网络势头概念，即资产之间的势头延伸效应。</li>
<li>methods: 该论文使用了一种可读性强的网络学习模型，揭示了不同资产类别之间势头延伸的网络效应。</li>
<li>results: 研究发现，基于网络势头的投资策略可以实现年化返报率为22%，并且具有1.5的希尔帕雷利率。<details>
<summary>Abstract</summary>
We investigate the concept of network momentum, a novel trading signal derived from momentum spillover across assets. Initially observed within the confines of pairwise economic and fundamental ties, such as the stock-bond connection of the same company and stocks linked through supply-demand chains, momentum spillover implies a propagation of momentum risk premium from one asset to another. The similarity of momentum risk premium, exemplified by co-movement patterns, has been spotted across multiple asset classes including commodities, equities, bonds and currencies. However, studying the network effect of momentum spillover across these classes has been challenging due to a lack of readily available common characteristics or economic ties beyond the company level. In this paper, we explore the interconnections of momentum features across a diverse range of 64 continuous future contracts spanning these four classes. We utilise a linear and interpretable graph learning model with minimal assumptions to reveal the intricacies of the momentum spillover network. By leveraging the learned networks, we construct a network momentum strategy that exhibits a Sharpe ratio of 1.5 and an annual return of 22%, after volatility scaling, from 2000 to 2022. This paper pioneers the examination of momentum spillover across multiple asset classes using only pricing data, presents a multi-asset investment strategy based on network momentum, and underscores the effectiveness of this strategy through robust empirical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation"><a href="#Test-Time-Embedding-Normalization-for-Popularity-Bias-Mitigation" class="headerlink" title="Test Time Embedding Normalization for Popularity Bias Mitigation"></a>Test Time Embedding Normalization for Popularity Bias Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11288">http://arxiv.org/abs/2308.11288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ml-postech/tten">https://github.com/ml-postech/tten</a></li>
<li>paper_authors: Dain Kim, Jinhyeok Park, Dongwoo Kim</li>
<li>For:  Mitigating popularity bias in recommender systems* Methods:  Test Time Embedding Normalization (TTEN)* Results:  Surpasses previous mitigation approaches by a significant margin, effectively reducing popularity biasHere’s the full text in Simplified Chinese:* 为： Mitigating popularity bias in recommender systems* 方法： Test Time Embedding Normalization (TTEN)* 结果： Surpasses previous mitigation approaches by a significant margin, effectively reducing popularity biasI hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.
</details>
<details>
<summary>摘要</summary>
受欢迎偏见是推荐系统领域中的一个广泛存在的问题，即受欢迎的项目往往占据推荐结果的主导地位。在这项工作中，我们提议了“测试时嵌入normalization”作为一种简单而高效的策略来缓解受欢迎偏见，该策略在前一些缓解方法的性能上超越了很大的差距。我们的方法在推荐阶段使用normalized的项目嵌入来控制嵌入量的影响，这与项目受欢迎程度高度相关。通过广泛的实验，我们证明了我们的方法与采样的softmax损失相结合可以有效缓解受欢迎偏见，而且比前一些缓解方法高效得多。我们进一步调查用户和项目嵌入之间的关系，发现angular相似性可以分辨用户喜欢和不喜欢的项目，无论它们的受欢迎程度如何。这种分析解释了我们的方法在消除受欢迎偏见的机制。我们的代码可以在https://github.com/ml-postech/TTEN中找到。
</details></li>
</ul>
<hr>
<h2 id="FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning"><a href="#FoX-Formation-aware-exploration-in-multi-agent-reinforcement-learning" class="headerlink" title="FoX: Formation-aware exploration in multi-agent reinforcement learning"></a>FoX: Formation-aware exploration in multi-agent reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11272">http://arxiv.org/abs/2308.11272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yonghyeon Jo, Sunwoo Lee, Junghyuk Yum, Seungyul Han</li>
<li>for: 解决多智能体 MARL 中的探索问题，提高多智能体任务的可行性和稳定性。</li>
<li>methods: 定义基于形态关系的探索空间减少法，并提出基于形态意识的探索框架 FoX，使部分可见智能体更好地了解自己的当前形态。</li>
<li>results: 在 GRF 和 SMAC 任务上，提出的 FoX 框架与现状册列 MARL 算法相比，显著提高了多智能体任务的性能。<details>
<summary>Abstract</summary>
Recently, deep multi-agent reinforcement learning (MARL) has gained significant popularity due to its success in various cooperative multi-agent tasks. However, exploration still remains a challenging problem in MARL due to the partial observability of the agents and the exploration space that can grow exponentially as the number of agents increases. Firstly, in order to address the scalability issue of the exploration space, we define a formation-based equivalence relation on the exploration space and aim to reduce the search space by exploring only meaningful states in different formations. Then, we propose a novel formation-aware exploration (FoX) framework that encourages partially observable agents to visit the states in diverse formations by guiding them to be well aware of their current formation solely based on their own observations. Numerical results show that the proposed FoX framework significantly outperforms the state-of-the-art MARL algorithms on Google Research Football (GRF) and sparse Starcraft II multi-agent challenge (SMAC) tasks.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:近期，深度多智能游戏学习（MARL）获得了重要的 популяр性，因为它在多种合作多智能任务中取得了成功。然而，探索仍然是 MARL 中的挑战，因为智能机器人的partial observability和探索空间的增长速度可以 exponential with the number of agents。为了解决探索空间的扩展问题，我们定义了基于formation的等价关系在探索空间上，并且尝试将搜索空间减少到只包含有意义的状态。然后，我们提出了一种新的formation-aware探索（FoX）框架，该框架鼓励部分可见的智能机器人 посеща多种formation中的状态，基于它们自己的观察结果而不是全局视角。数值结果显示，我们的 FoX 框架在 Google Research Football (GRF) 和 sparse Starcraft II multi-agent challenge (SMAC) 任务上明显超过了现状MARL算法的性能。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Inspired-Machine-Learning-a-Survey"><a href="#Quantum-Inspired-Machine-Learning-a-Survey" class="headerlink" title="Quantum-Inspired Machine Learning: a Survey"></a>Quantum-Inspired Machine Learning: a Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11269">http://arxiv.org/abs/2308.11269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Larry Huynh, Jin Hong, Ajmal Mian, Hajime Suzuki, Yanqiu Wu, Seyit Camtepe</li>
<li>For: This paper provides an integrated and comprehensive examination of Quantum-inspired Machine Learning (QiML), exploring its diverse research domains and recent advancements.* Methods: The paper uses a concrete definition of QiML, established by analyzing various prior interpretations of the term and their inherent ambiguities. It also showcases practical applications and illuminates potential future research avenues.* Results: The paper provides a holistic understanding of QiML’s current landscape and future directions, serving as a guide for researchers and practitioners alike.<details>
<summary>Abstract</summary>
Quantum-inspired Machine Learning (QiML) is a burgeoning field, receiving global attention from researchers for its potential to leverage principles of quantum mechanics within classical computational frameworks. However, current review literature often presents a superficial exploration of QiML, focusing instead on the broader Quantum Machine Learning (QML) field. In response to this gap, this survey provides an integrated and comprehensive examination of QiML, exploring QiML's diverse research domains including tensor network simulations, dequantized algorithms, and others, showcasing recent advancements, practical applications, and illuminating potential future research avenues. Further, a concrete definition of QiML is established by analyzing various prior interpretations of the term and their inherent ambiguities. As QiML continues to evolve, we anticipate a wealth of future developments drawing from quantum mechanics, quantum computing, and classical machine learning, enriching the field further. This survey serves as a guide for researchers and practitioners alike, providing a holistic understanding of QiML's current landscape and future directions.
</details>
<details>
<summary>摘要</summary>
量子逻辑机器学习（QiML）是一个迅速发展的领域，在全球的研究者中备受关注，因为它可以在类比量子机制的计算框架中利用量子力学原理。然而，现有的文献综述通常会对QiML进行 superficiel的探讨，而不是对量子机器学习（QML）领域进行深入的探讨。为了填补这一空白，本调查提供了一个综合和完整的QiML的检视，探讨了QiML的多样化研究领域，包括张量网络仿真、量子化算法等，介绍了最新的进步、实践应用以及未来研究方向。此外，本文还提供了QiML的具体定义，通过分析各种先前的定义和其内在的歧义，为读者提供一个准确的理解。随着QiML的进一步发展，我们预计未来将有许多基于量子力学、量子计算和经典机器学习的发展，使得QiML领域变得更加丰富。本调查作为研究者和实践者的指南，为读者提供了QiML当前的领域景观和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features"><a href="#Minwise-Independent-Permutations-with-Insertion-and-Deletion-of-Features" class="headerlink" title="Minwise-Independent Permutations with Insertion and Deletion of Features"></a>Minwise-Independent Permutations with Insertion and Deletion of Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11240">http://arxiv.org/abs/2308.11240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rameshwar Pratap, Raghav Kulkarni</li>
<li>for: 本文研究的目的是提出一种能够适应高维数据动态特征添加和删除的MINHash算法，以提高MINHash的运行效率和精度。</li>
<li>methods: 本文提出了一种基于批处理和快速搜索的方法，使MINHash sketches可以适应动态添加和删除特征。此外，本文还提供了一种基于哈希函数的方法，可以快速地更新MINHash sketches。</li>
<li>results: 本文通过了严格的理论分析和广泛的实验研究，证明了提出的方法可以快速地更新MINHash sketches，同时保持与静态MINHash的性能相似。实验结果表明，在几个实际 datasets 上，提出的方法可以获得显著的运行时间加速，而无需重新生成随机排序。<details>
<summary>Abstract</summary>
In their seminal work, Broder \textit{et. al.}~\citep{BroderCFM98} introduces the $\mathrm{minHash}$ algorithm that computes a low-dimensional sketch of high-dimensional binary data that closely approximates pairwise Jaccard similarity. Since its invention, $\mathrm{minHash}$ has been commonly used by practitioners in various big data applications. Further, the data is dynamic in many real-life scenarios, and their feature sets evolve over time. We consider the case when features are dynamically inserted and deleted in the dataset. We note that a naive solution to this problem is to repeatedly recompute $\mathrm{minHash}$ with respect to the updated dimension. However, this is an expensive task as it requires generating fresh random permutations. To the best of our knowledge, no systematic study of $\mathrm{minHash}$ is recorded in the context of dynamic insertion and deletion of features. In this work, we initiate this study and suggest algorithms that make the $\mathrm{minHash}$ sketches adaptable to the dynamic insertion and deletion of features. We show a rigorous theoretical analysis of our algorithms and complement it with extensive experiments on several real-world datasets. Empirically we observe a significant speed-up in the running time while simultaneously offering comparable performance with respect to running $\mathrm{minHash}$ from scratch. Our proposal is efficient, accurate, and easy to implement in practice.
</details>
<details>
<summary>摘要</summary>
布罗德等人在 seminal 论文中提出了 $\minHash$ 算法，该算法可以计算高维二分数据的低维笔记，并且可以准确地近似对应对 Jaccard 相似性。自其发明以来， $\minHash$ 已经广泛地应用于各种大数据应用场景中。然而，在许多实际场景中，数据的特征集是动态变化的，因此需要对数据进行不断的更新。在这种情况下，直接重新计算 $\minHash$ 是一个昂贵的任务，因为需要生成新的随机排序。在这篇文章中，我们开始了对 $\minHash$ 在动态插入和删除特征时的研究。我们提出了一些可靠的算法，使得 $\minHash$ 笔记可以适应动态插入和删除特征。我们提供了严谨的理论分析，并补充了大量实验数据，证明了我们的方法可以减少运行时间，同时保持与从头开始计算 $\minHash$ 的性能相似。我们的提议是高效、准确、易于实现。
</details></li>
</ul>
<hr>
<h2 id="Hamiltonian-GAN"><a href="#Hamiltonian-GAN" class="headerlink" title="Hamiltonian GAN"></a>Hamiltonian GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11216">http://arxiv.org/abs/2308.11216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/koritsky/hamiltonian_learning">https://github.com/koritsky/hamiltonian_learning</a></li>
<li>paper_authors: Christine Allen-Blanchette</li>
<li>for: 这个论文是为了探讨使用泊松方程来学习视频生成的可能性。</li>
<li>methods: 该论文使用了一种基于GAN的视频生成管道，其中包含一个学习的配置空间地图和泊松 нейрон网络运动模型，以从数据中学习配置空间的表示。</li>
<li>results: 该论文通过使用一种物理启发的循环坐标损失函数，以提高模型的解释性和可靠性。并在Hamiltonian Dynamics Suite Toy Physics dataset上进行了证明。<details>
<summary>Abstract</summary>
A growing body of work leverages the Hamiltonian formalism as an inductive bias for physically plausible neural network based video generation. The structure of the Hamiltonian ensures conservation of a learned quantity (e.g., energy) and imposes a phase-space interpretation on the low-dimensional manifold underlying the input video. While this interpretation has the potential to facilitate the integration of learned representations in downstream tasks, existing methods are limited in their applicability as they require a structural prior for the configuration space at design time. In this work, we present a GAN-based video generation pipeline with a learned configuration space map and Hamiltonian neural network motion model, to learn a representation of the configuration space from data. We train our model with a physics-inspired cyclic-coordinate loss function which encourages a minimal representation of the configuration space and improves interpretability. We demonstrate the efficacy and advantages of our approach on the Hamiltonian Dynamics Suite Toy Physics dataset.
</details>
<details>
<summary>摘要</summary>
一种增长的研究利用 Hamiltonian  formalism 作为 физи学 plausible 的神经网络视频生成的 inductive bias。 Hamiltonian 的结构保证学习的一个量（例如，能量）的保守和在输入视频的低维度抽象空间中强制phase-space interpretation。这种解释有助于在下游任务中集成学习的表示，但现有方法受限于需要在设计时提供结构的 prior  для配置空间。在这篇文章中，我们提出了一个基于 GAN 的视频生成管道，其中包含学习的配置空间地图和 Hamiltonian 神经网络动力学模型，以从数据中学习配置空间的表示。我们使用一种 физи学 inspires 的循环坐标损失函数来驱动我们的模型，该函数鼓励了配置空间的最小表示，并提高了解释性。我们在 Hamiltonian Dynamics Suite Toy Physics 数据集上证明了我们的方法的有效性和优势。
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling"><a href="#A-Simple-Framework-for-Multi-mode-Spatial-Temporal-Data-Modeling" class="headerlink" title="A Simple Framework for Multi-mode Spatial-Temporal Data Modeling"></a>A Simple Framework for Multi-mode Spatial-Temporal Data Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11204">http://arxiv.org/abs/2308.11204</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lzhmarkk/simmst">https://github.com/lzhmarkk/simmst</a></li>
<li>paper_authors: Zihang Liu, Le Yu, Tongyu Zhu, Leiei Sun</li>
<li>for: 本研究旨在提出一种简单 yet effective 的多模式空间时间数据模型，以捕捉多种空间关系和时间依赖关系。</li>
<li>methods: 我们提出了一种通用的cross-mode空间关系学习组件，可以适应多种模式之间的连接，并在这些连接上传递信息。此外，我们采用多层感知器来捕捉时间依赖关系和通道相关性。</li>
<li>results: 我们在三个实际数据集上进行了实验，结果显示，我们的模型可以在空间和时间复杂度下 consistently 高于基elines，并且具有更好的一致性和泛化能力。<details>
<summary>Abstract</summary>
Spatial-temporal data modeling aims to mine the underlying spatial relationships and temporal dependencies of objects in a system. However, most existing methods focus on the modeling of spatial-temporal data in a single mode, lacking the understanding of multiple modes. Though very few methods have been presented to learn the multi-mode relationships recently, they are built on complicated components with higher model complexities. In this paper, we propose a simple framework for multi-mode spatial-temporal data modeling to bring both effectiveness and efficiency together. Specifically, we design a general cross-mode spatial relationships learning component to adaptively establish connections between multiple modes and propagate information along the learned connections. Moreover, we employ multi-layer perceptrons to capture the temporal dependencies and channel correlations, which are conceptually and technically succinct. Experiments on three real-world datasets show that our model can consistently outperform the baselines with lower space and time complexity, opening up a promising direction for modeling spatial-temporal data. The generalizability of the cross-mode spatial relationships learning module is also validated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting"><a href="#SegRNN-Segment-Recurrent-Neural-Network-for-Long-Term-Time-Series-Forecasting" class="headerlink" title="SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting"></a>SegRNN: Segment Recurrent Neural Network for Long-Term Time Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11200">http://arxiv.org/abs/2308.11200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Feiyu Zhao, Ruichao Mo, Haotong Zhang</li>
<li>for: 这个研究是为了解决长期时间序列预测（LTSF）领域中RNN方法面临的挑战，特别是在处理极长回顾窗口和预测时间 horizon时。</li>
<li>methods: 本研究提出了两种新的策略来减少RNN在LTSF任务中的迭代次数：Segment-wise Iterations和Parallel Multi-step Forecasting（PMF）。</li>
<li>results: 实验结果显示，SegRNN不仅能够超越现有的Transformer-based模型，而且能够降低运行时间和内存使用量超过78%。这些成果证明RNN仍然在LTSF任务中 excel，并且鼓励更多的RNN-based方法在这个领域进行更多的探索。<details>
<summary>Abstract</summary>
RNN-based methods have faced challenges in the Long-term Time Series Forecasting (LTSF) domain when dealing with excessively long look-back windows and forecast horizons. Consequently, the dominance in this domain has shifted towards Transformer, MLP, and CNN approaches. The substantial number of recurrent iterations are the fundamental reasons behind the limitations of RNNs in LTSF. To address these issues, we propose two novel strategies to reduce the number of iterations in RNNs for LTSF tasks: Segment-wise Iterations and Parallel Multi-step Forecasting (PMF). RNNs that combine these strategies, namely SegRNN, significantly reduce the required recurrent iterations for LTSF, resulting in notable improvements in forecast accuracy and inference speed. Extensive experiments demonstrate that SegRNN not only outperforms SOTA Transformer-based models but also reduces runtime and memory usage by more than 78%. These achievements provide strong evidence that RNNs continue to excel in LTSF tasks and encourage further exploration of this domain with more RNN-based approaches. The source code is coming soon.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation"><a href="#Toward-Generalizable-Machine-Learning-Models-in-Speech-Language-and-Hearing-Sciences-Power-Analysis-and-Sample-Size-Estimation" class="headerlink" title="Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation"></a>Toward Generalizable Machine Learning Models in Speech, Language, and Hearing Sciences: Power Analysis and Sample Size Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11197">http://arxiv.org/abs/2308.11197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamzeh Ghasemzadeh, Robert E. Hillman, Daryush D. Mehta</li>
<li>For: The paper aims to provide quantitative evidence to incentivize researchers to use the more robust method of nested cross-validation in machine learning-based analysis, and to present methods and MATLAB codes for power analysis during the design of a study.* Methods: The paper uses Monte Carlo simulations to compare the performance of four different cross-validation methods (single holdout, 10-fold, train-validation-test, and nested 10-fold) in terms of statistical power and statistical confidence.* Results: The paper finds that the nested 10-fold cross-validation method results in the highest statistical confidence and statistical power, while providing an unbiased estimate of the accuracy. The required sample size with a single holdout is found to be 50% higher than what would be needed with nested cross-validation, and confidence in the model based on nested cross-validation is found to be as much as four times higher than the confidence in the single holdout-based model.<details>
<summary>Abstract</summary>
This study's first purpose is to provide quantitative evidence that would incentivize researchers to instead use the more robust method of nested cross-validation. The second purpose is to present methods and MATLAB codes for doing power analysis for ML-based analysis during the design of a study. Monte Carlo simulations were used to quantify the interactions between the employed cross-validation method, the discriminative power of features, the dimensionality of the feature space, and the dimensionality of the model. Four different cross-validations (single holdout, 10-fold, train-validation-test, and nested 10-fold) were compared based on the statistical power and statistical confidence of the ML models. Distributions of the null and alternative hypotheses were used to determine the minimum required sample size for obtaining a statistically significant outcome ({\alpha}=0.05, 1-\b{eta}=0.8). Statistical confidence of the model was defined as the probability of correct features being selected and hence being included in the final model. Our analysis showed that the model generated based on the single holdout method had very low statistical power and statistical confidence and that it significantly overestimated the accuracy. Conversely, the nested 10-fold cross-validation resulted in the highest statistical confidence and the highest statistical power, while providing an unbiased estimate of the accuracy. The required sample size with a single holdout could be 50% higher than what would be needed if nested cross-validation were used. Confidence in the model based on nested cross-validation was as much as four times higher than the confidence in the single holdout-based model. A computational model, MATLAB codes, and lookup tables are provided to assist researchers with estimating the sample size during the design of their future studies.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这项研究的主要目标是提供量化证据，以便激励研究人员使用更加稳定的嵌套十进制验证方法。第二个目标是提供方法和MATLAB代码，以便在设计研究时进行能量分析。 Monte Carlo仿真被用来比较不同的十进制验证方法（单个弃置、10进制、训练验证测试和嵌套10进制）的统计能力和统计信任度。研究发现，使用嵌套10进制验证方法可以获得最高的统计信任度和统计能力，同时提供不偏估的准确率估计。单个弃置方法的模型有very low的统计信任度和统计能力，并且显著地过分估计准确率。相比之下，嵌套10进制验证方法可以降低样本大小，同时提供更高的统计信任度和统计能力。研究提供了一个计算模型、MATLAB代码和lookup表来帮助研究人员在设计未来的研究时估计样本大小。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models"><a href="#Automatic-Task-Parallelization-of-Dataflow-Graphs-in-ML-DL-models" class="headerlink" title="Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models"></a>Automatic Task Parallelization of Dataflow Graphs in ML&#x2F;DL models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11192">http://arxiv.org/abs/2308.11192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srinjoy Das, Lawrence Rauchwerger</li>
<li>for: 提高机器学习（ML）或深度学习（DL）模型的训练和推理性能</li>
<li>methods: 使用批处理、卷积和常量传递优化方法，并使用一新建的工具 called Ramiel 生成可读可执行的平行 PyTorch+Python 代码</li>
<li>results: 在多个 ML 图表中达到了最高的 1.9 倍的速度提升，并在编译和运行时间方面表现出色，超过了一些当前的机制，同时可以在资源和功能限制的设备上使用<details>
<summary>Abstract</summary>
Several methods exist today to accelerate Machine Learning(ML) or Deep-Learning(DL) model performance for training and inference. However, modern techniques that rely on various graph and operator parallelism methodologies rely on search space optimizations which are costly in terms of power and hardware usage. Especially in the case of inference, when the batch size is 1 and execution is on CPUs or for power-constrained edge devices, current techniques can become costly, complicated or inapplicable. To ameliorate this, we present a Critical-Path-based Linear Clustering approach to exploit inherent parallel paths in ML dataflow graphs. Our task parallelization approach further optimizes the structure of graphs via cloning and prunes them via constant propagation and dead-code elimination. Contrary to other work, we generate readable and executable parallel Pytorch+Python code from input ML models in ONNX format via a new tool that we have built called {\bf Ramiel}. This allows us to benefit from other downstream acceleration techniques like intra-op parallelism and potentially pipeline parallelism. Our preliminary results on several ML graphs demonstrate up to 1.9$\times$ speedup over serial execution and outperform some of the current mechanisms in both compile and runtimes. Lastly, our methods are lightweight and fast enough so that they can be used effectively for power and resource-constrained devices, while still enabling downstream optimizations.
</details>
<details>
<summary>摘要</summary>
Unlike other work, we generate readable and executable parallel PyTorch+Python code from input ML models in ONNX format via a new tool we have built called Ramiel. This allows us to benefit from other downstream acceleration techniques like intra-op parallelism and potentially pipeline parallelism. Our preliminary results on several ML graphs demonstrate up to 1.9 times speedup over serial execution and outperform some of the current mechanisms in both compile and runtimes. Lastly, our methods are lightweight and fast enough to be used effectively for power and resource-constrained devices, while still enabling downstream optimizations.Translated into Simplified Chinese:有很多方法可以加速机器学习（ML）或深度学习（DL）模型的训练和推理性能。然而，现代技术，它们基于各种图和运算符并行方法，它们需要搜索空间优化，这些优化对于硬件使用量和电力占用来说是昂贵的。尤其是在推理时，批处理数为1，执行在CPUs或有限功能边缘设备上时，当前技术可能变得昂贵、复杂或不可靠。为了改善这种情况，我们提出了一种基于执行路径的线性聚类方法，以利用ML数据流图中的自然并行路径。我们的任务并行方法还可以优化图的结构via副本和减少via常量卷积和死代码消除。与其他工作不同，我们可以将输入ML模型的ONNX格式转换为可读可执行的并行PyTorch+Python代码，通过我们新建的工具Ramiel。这样，我们就可以从其他下游加速技术，如内部操作并行和可能的管道并行中受益。我们的初步结果表明，对于一些ML图，我们可以在序列执行下获得最高达1.9倍的加速，并且超越一些当前机制。此外，我们的方法具有轻量级和快速的特点，可以有效地在功率和资源有限的设备上使用，而仍可以开启下游优化。
</details></li>
</ul>
<hr>
<h2 id="Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning"><a href="#Mobility-Aware-Computation-Offloading-for-Swarm-Robotics-using-Deep-Reinforcement-Learning" class="headerlink" title="Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning"></a>Mobility-Aware Computation Offloading for Swarm Robotics using Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11154">http://arxiv.org/abs/2308.11154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiucheng Wang, Hongzhi Guo</li>
<li>for: 自动化废弃、危险、无聊任务</li>
<li>methods: 利用移动边计算减轻计算负担</li>
<li>results: 提出了一种基于移动端深度学习算法的计算调度和资源分配解决方案，可以 garantizar computation preciseness 并使用最少机器人能量。<details>
<summary>Abstract</summary>
Swarm robotics is envisioned to automate a large number of dirty, dangerous, and dull tasks. Robots have limited energy, computation capability, and communication resources. Therefore, current swarm robotics have a small number of robots, which can only provide limited spatio-temporal information. In this paper, we propose to leverage the mobile edge computing to alleviate the computation burden. We develop an effective solution based on a mobility-aware deep reinforcement learning model at the edge server side for computing scheduling and resource. Our results show that the proposed approach can meet delay requirements and guarantee computation precision by using minimum robot energy.
</details>
<details>
<summary>摘要</summary>
群体 робототехника预见到自动执行大量污秽危险讨厌任务。机器人有限的能源、计算能力和通信资源，因此当前的群体 робототехника只有一小数量的机器人，可以提供有限的空间时间信息。在这篇论文中，我们提议利用移动边缘计算来减轻计算负担。我们开发了一种基于移动性意识深度学习模型的边缘服务器端解决方案，以实现计算调度和资源管理。我们的结果表明，我们的方法可以遵循延迟要求，保证计算精度，并使最小化机器人能量消耗。
</details></li>
</ul>
<hr>
<h2 id="Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing"><a href="#Energy-Efficient-On-Board-Radio-Resource-Management-for-Satellite-Communications-via-Neuromorphic-Computing" class="headerlink" title="Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing"></a>Energy-Efficient On-Board Radio Resource Management for Satellite Communications via Neuromorphic Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11152">http://arxiv.org/abs/2308.11152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Flor Ortiz, Nicolas Skatchkovsky, Eva Lagunas, Wallace A. Martins, Geoffrey Eappen, Saed Daoud, Osvaldo Simeone, Bipin Rajendran, Symeon Chatzinotas</li>
<li>for: 这个论文是为了研究使用能效的大脑发现学模型来管理空间通信系统中的电磁资源。</li>
<li>methods: 本论文使用了软件仿真和实验方法来评估提议的模型。在实验中，使用了最新的英特尔洛瑞2芯片。</li>
<li>results: 研究发现，使用神经元发现学模型可以提高准确率和能效性，而且可以降低电力消耗。相比传统的卷积神经网络，使用神经元发现学模型可以降低电力消耗超过100倍。这些结果表明，使用神经元发现学模型可以在空间通信系统中提供更高的效率和可持续性。<details>
<summary>Abstract</summary>
The latest satellite communication (SatCom) missions are characterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning (ML)-based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks (CNN) on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks (SNNs) implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100$\times$ as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details>
<details>
<summary>摘要</summary>
最新的卫星通信（SatCom）任务 caracterized by a fully reconfigurable on-board software-defined payload, capable of adapting radio resources to the temporal and spatial variations of the system traffic. As pure optimization-based solutions have shown to be computationally tedious and to lack flexibility, machine learning (ML)-based methods have emerged as promising alternatives. We investigate the application of energy-efficient brain-inspired ML models for on-board radio resource management. Apart from software simulation, we report extensive experimental results leveraging the recently released Intel Loihi 2 chip. To benchmark the performance of the proposed model, we implement conventional convolutional neural networks (CNN) on a Xilinx Versal VCK5000, and provide a detailed comparison of accuracy, precision, recall, and energy efficiency for different traffic demands. Most notably, for relevant workloads, spiking neural networks (SNNs) implemented on Loihi 2 yield higher accuracy, while reducing power consumption by more than 100 times as compared to the CNN-based reference platform. Our findings point to the significant potential of neuromorphic computing and SNNs in supporting on-board SatCom operations, paving the way for enhanced efficiency and sustainability in future SatCom systems.
</details></li>
</ul>
<hr>
<h2 id="Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions"><a href="#Graph-Encoding-and-Neural-Network-Approaches-for-Volleyball-Analytics-From-Game-Outcome-to-Individual-Play-Predictions" class="headerlink" title="Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions"></a>Graph Encoding and Neural Network Approaches for Volleyball Analytics: From Game Outcome to Individual Play Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11142">http://arxiv.org/abs/2308.11142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rhys Tracy, Haotian Xia, Alex Rasla, Yuan-Fang Wang, Ambuj Singh</li>
<li>For: 本研究旨在提高复杂排球预测精度，为教练和运动员提供更有意义的洞察。* Methods: 我们引入特殊的图编码技术，将已有的排球数据集添加了更多的接触接触排球上下文。我们使用图神经网络（GNNs）进行三个不同的排球预测任务的预测：排球结果预测、场地预测和击TYPE预测。* Results: 我们的图基模型比基线模型表现更出色，特别是在 removing blocked hits 这个简单的调整下。我们还发现，选择合适的模型结构可以更好地提取重要信息，从而提高预测结果。总的来说，我们的研究展示了使用图编码在体育数据分析中的潜在优势和局限性，并希望未来的机器学习策略在体育和应用程序中使用图基编码。<details>
<summary>Abstract</summary>
This research aims to improve the accuracy of complex volleyball predictions and provide more meaningful insights to coaches and players. We introduce a specialized graph encoding technique to add additional contact-by-contact volleyball context to an already available volleyball dataset without any additional data gathering. We demonstrate the potential benefits of using graph neural networks (GNNs) on this enriched dataset for three different volleyball prediction tasks: rally outcome prediction, set location prediction, and hit type prediction. We compare the performance of our graph-based models to baseline models and analyze the results to better understand the underlying relationships in a volleyball rally. Our results show that the use of GNNs with our graph encoding yields a much more advanced analysis of the data, which noticeably improves prediction results overall. We also show that these baseline tasks can be significantly improved with simple adjustments, such as removing blocked hits. Lastly, we demonstrate the importance of choosing a model architecture that will better extract the important information for a certain task. Overall, our study showcases the potential strengths and weaknesses of using graph encodings in sports data analytics and hopefully will inspire future improvements in machine learning strategies across sports and applications by using graphbased encodings.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文翻译，不同于正式中文）这个研究的目标是提高复杂的排球预测精度，为教练和运动员提供更有意义的洞察。我们引入了一种特殊的图编码技术，将已有的排球数据集添加了更多的接触点接触之间的排球上下文。我们示出了使用图神经网络（GNNs）在这些丰富的数据集上进行三种不同的排球预测任务：赛点预测、场地预测和击打类型预测。我们对基线模型和我们的图基于模型进行比较，分析结果，以更好地理解排球赛中的下面关系。我们的结果显示，使用GNNs和我们的图编码可以提供更高级的数据分析，全面提高预测结果。我们还示出了一些简单的调整，如移除堵塞的击球，可以大幅提高基线任务的性能。最后，我们证明选择适合的模型架构可以更好地提取关键信息，以便更好地进行特定任务。总之，我们的研究展示了使用图编码在体育数据分析中的潜在优势和缺点，希望这些研究结果可以激励未来在体育和应用领域的机器学习策略的改进。
</details></li>
</ul>
<hr>
<h2 id="Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems"><a href="#Towards-Validating-Long-Term-User-Feedbacks-in-Interactive-Recommendation-Systems" class="headerlink" title="Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems"></a>Towards Validating Long-Term User Feedbacks in Interactive Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11137">http://arxiv.org/abs/2308.11137</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Hojoon Lee, Dongyoon Hwang, Kyushik Min, Jaegul Choo</li>
<li>for: 这paper的目的是检验RL算法在Interactive Recommender Systems (IRSs) 中的性能，以及公共数据集是否适合评估IRS算法。</li>
<li>methods: 该paper使用了Reinforcement Learning (RL)算法，并 compare它们与简单的奖励模型。</li>
<li>results: 主要发现结果包括：1) 简单的奖励模型在 maximizing 累积奖励方面一直处于领先地位; 2) 应用更高的长期奖励权重会导致推荐性能下降; 3) 用户反馈对 benchmark datasets 中的长期影响很小。<details>
<summary>Abstract</summary>
Interactive Recommender Systems (IRSs) have attracted a lot of attention, due to their ability to model interactive processes between users and recommender systems. Numerous approaches have adopted Reinforcement Learning (RL) algorithms, as these can directly maximize users' cumulative rewards. In IRS, researchers commonly utilize publicly available review datasets to compare and evaluate algorithms. However, user feedback provided in public datasets merely includes instant responses (e.g., a rating), with no inclusion of delayed responses (e.g., the dwell time and the lifetime value). Thus, the question remains whether these review datasets are an appropriate choice to evaluate the long-term effects of the IRS. In this work, we revisited experiments on IRS with review datasets and compared RL-based models with a simple reward model that greedily recommends the item with the highest one-step reward. Following extensive analysis, we can reveal three main findings: First, a simple greedy reward model consistently outperforms RL-based models in maximizing cumulative rewards. Second, applying higher weighting to long-term rewards leads to a degradation of recommendation performance. Third, user feedbacks have mere long-term effects on the benchmark datasets. Based on our findings, we conclude that a dataset has to be carefully verified and that a simple greedy baseline should be included for a proper evaluation of RL-based IRS approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>使用简单的奖励模型可以在总奖励方面 consistently 高于 RL 基eline。2. 对 RL 模型应用更高的长期奖励权重会导致推荐性能下降。3. 在 benchmark 数据集上，用户反馈的长期效果很少。根据我们的发现，我们结论是一个数据集需要仔细验证，而且一个简单的奖励基eline应该包含在评估 RL 基eline 方法的评估中。</details></li>
</ol>
<hr>
<h2 id="How-Expressive-are-Graph-Neural-Networks-in-Recommendation"><a href="#How-Expressive-are-Graph-Neural-Networks-in-Recommendation" class="headerlink" title="How Expressive are Graph Neural Networks in Recommendation?"></a>How Expressive are Graph Neural Networks in Recommendation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11127">http://arxiv.org/abs/2308.11127</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkuds/gte">https://github.com/hkuds/gte</a></li>
<li>paper_authors: Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang</li>
<li>for: 本研究旨在提供对graph neural networks（GNNs）在推荐任务中的理论分析，包括GNNs的表达能力、难度和可解性。</li>
<li>methods: 本研究使用了message passing GNNs和random node initialization来评估GNNs的表达能力，并提出了一种新的表达能力度量—— topological closeness，用于评估GNNs在推荐任务中的能力。</li>
<li>results: 研究发现，GNNs在推荐任务中的表达能力可以通过三种度量来评估：graph isomorphism（图像同构）、node automorphism（节点自同构）和topological closeness（结构距离）。其中，topological closeness度量能够更好地评估GNNs在推荐任务中的能力，并且可以与node-level度量相比较。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have demonstrated superior performance on various graph learning tasks, including recommendation, where they leverage user-item collaborative filtering signals in graphs. However, theoretical formulations of their capability are scarce, despite their empirical effectiveness in state-of-the-art recommender models. Recently, research has explored the expressiveness of GNNs in general, demonstrating that message passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that GNNs combined with random node initialization are universal. Nevertheless, the concept of "expressiveness" for GNNs remains vaguely defined. Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness. In this paper, we provide a comprehensive theoretical analysis of the expressiveness of GNNs in recommendation, considering three levels of expressiveness metrics: graph isomorphism (graph-level), node automorphism (node-level), and topological closeness (link-level). We propose the topological closeness metric to evaluate GNNs' ability to capture the structural distance between nodes, which aligns closely with the objective of recommendation. To validate the effectiveness of this new metric in evaluating recommendation performance, we introduce a learning-less GNN algorithm that is optimal on the new metric and can be optimal on the node-level metric with suitable modification. We conduct extensive experiments comparing the proposed algorithm against various types of state-of-the-art GNN models to explore the explainability of the new metric in the recommendation task. For reproducibility, implementation codes are available at https://github.com/HKUDS/GTE.
</details>
<details>
<summary>摘要</summary>
格Nodes Neural Networks (GNNs) 在不同的图学任务中表现出色，包括推荐，其利用用户ITEM的协同过滤信号在图中。然而，GNNs的理论表述仍然缺乏，即使它们在现有的推荐模型中有较高的实际效果。最近，研究人员已经开始探讨GNNs的表达能力，并证明了message passing GNNs 是 Weisfeiler-Lehman test 的最多Equivalent，并且GNNs 与随机节点初始化相结合是 universal。然而，GNNs 的“表达能力”概念仍然具有模糊的定义。大多数现有的工作采用图 isomorphism test 作为表达能力的度量，但这可能并不是在推荐任务中效果最高的度量，因为推荐任务的目标是分辨不同的节点之间的邻域关系。在这篇论文中，我们提供了对GNNs在推荐任务中的表达能力进行了全面的理论分析，考虑了三级别的表达能力度量：图 isomorphism（图级）、节点自动机制（节点级）和topological closeness（链级）。我们提出了topological closeness度量，用于评估GNNs在推荐任务中 capture 节点之间的结构距离，这与推荐任务的目标吻合。为验证这种新的度量在推荐任务中的效果，我们提出了一种不含学习的GNN算法，该算法在新的度量上是最优的，并且可以通过修改而在节点级度量上达到最优性。我们在多种现有的state-of-the-art GNN模型的比较中进行了广泛的实验，以探索这种新的度量在推荐任务中的解释性。为保持可重现性，我们在 GitHub 上提供了实现代码。
</details></li>
</ul>
<hr>
<h2 id="Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks"><a href="#Explicability-and-Inexplicability-in-the-Interpretation-of-Quantum-Neural-Networks" class="headerlink" title="Explicability and Inexplicability in the Interpretation of Quantum Neural Networks"></a>Explicability and Inexplicability in the Interpretation of Quantum Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11098">http://arxiv.org/abs/2308.11098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lirandepira/interpret-qnn">https://github.com/lirandepira/interpret-qnn</a></li>
<li>paper_authors: Lirandë Pira, Chris Ferrie</li>
<li>for: 研究人工智能（AI）方法的可解释性，尤其是深度神经网络，因为AI后台系统的使用很普遍，但它们的行为往往无法解释。</li>
<li>methods: 使用本地模型独立可解释性测试方法来评估Quantum和Classical神经网络的可解释性。</li>
<li>results: 发现Quantum神经网络的可解释性遭受困难，尤其是在数据样本的很多情况下，这些样本被称为“不可解释的带”（band of inexplicability）。这些结果表明了如何建立可靠和负责任的量子AI模型。<details>
<summary>Abstract</summary>
Interpretability of artificial intelligence (AI) methods, particularly deep neural networks, is of great interest due to the widespread use of AI-backed systems, which often have unexplainable behavior. The interpretability of such models is a crucial component of building trusted systems. Many methods exist to approach this problem, but they do not obviously generalize to the quantum setting. Here we explore the interpretability of quantum neural networks using local model-agnostic interpretability measures of quantum and classical neural networks. We introduce the concept of the band of inexplicability, representing the interpretable region in which data samples have no explanation, likely victims of inherently random quantum measurements. We see this as a step toward understanding how to build responsible and accountable quantum AI models.
</details>
<details>
<summary>摘要</summary>
artifical intelligence（AI）方法的解释性（interpretability）是非常有价值的，因为AI支持的系统在使用中经常表现出不可解释的行为。解释性是建立可信系统的重要组成部分。许多方法可以解决这个问题，但它们不明显推广到量子设置。在这里，我们研究了量子神经网络的解释性，使用本地模型独立可解释性度量来评估量子和类传统神经网络的解释性。我们引入了带彩色不可解释区域的概念，表示无法解释的数据样本， probable victims of inherently random quantum measurements。我们认为这是一步 towards understanding how to build responsible and accountable quantum AI models。Here's the breakdown of the translation:*  artifical intelligence (AI) 是指人工智能的全称，用于描述使用机器学习和深度学习等技术实现的智能系统。* 解释性 (interpretability) 是指可以理解和解释的程度，在这种情况下是指可以理解和解释的AI模型。* 量子设置 (quantum setting) 是指使用量子计算机和量子信息处理技术实现的系统。* 本地模型独立可解释性度量 (local model-agnostic interpretability measures) 是指可以评估不同模型的解释性的度量，不同于特定的模型或算法。* 带彩色不可解释区域 (band of inexplicability) 是指无法解释的数据样本， probable victims of inherently random quantum measurements。这个概念是在量子神经网络中引入的，表示在量子计算中，由于随机性的原因，一些数据样本无法被解释。* responsible and accountable quantum AI models (responsible and accountable quantum AI models) 是指可以被信任和负责的量子AI模型，即可以被解释和控制的模型。
</details></li>
</ul>
<hr>
<h2 id="Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen"><a href="#Stress-representations-for-tensor-basis-neural-networks-alternative-formulations-to-Finger-Rivlin-Ericksen" class="headerlink" title="Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen"></a>Stress representations for tensor basis neural networks: alternative formulations to Finger-Rivlin-Ericksen</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11080">http://arxiv.org/abs/2308.11080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan N. Fuhg, Nikolaos Bouklas, Reese E. Jones</li>
<li>for: 这个论文主要研究了数据驱动的 constitutive 模型框架，以及其中的神经网络和经典表述定理的结合使用。</li>
<li>methods: 这个论文使用了各种神经网络模型来模拟弹性材料的弹性行为，包括一些尚未探讨过的表述形式。它们使用了同等的 invariants 和生成器来替代经典的 Rivlin 和 Ericksen 表述。</li>
<li>results: 论文测试了九种不同的变体，并对三种不同的材料进行了测试。结果表明，各种表述形式之间存在差异，而且具有不同的优劣点。<details>
<summary>Abstract</summary>
Data-driven constitutive modeling frameworks based on neural networks and classical representation theorems have recently gained considerable attention due to their ability to easily incorporate constitutive constraints and their excellent generalization performance. In these models, the stress prediction follows from a linear combination of invariant-dependent coefficient functions and known tensor basis generators. However, thus far the formulations have been limited to stress representations based on the classical Rivlin and Ericksen form, while the performance of alternative representations has yet to be investigated. In this work, we survey a variety of tensor basis neural network models for modeling hyperelastic materials in a finite deformation context, including a number of so far unexplored formulations which use theoretically equivalent invariants and generators to Finger-Rivlin-Ericksen. Furthermore, we compare potential-based and coefficient-based approaches, as well as different calibration techniques. Nine variants are tested against both noisy and noiseless datasets for three different materials. Theoretical and practical insights into the performance of each formulation are given.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate(given_text, to='zh-CN', language='zh-CN')</SYS>>Here's the translated text: Data-driven constitutive modeling frameworks based on neural networks and classical representation theorems have recently gained considerable attention due to their ability to easily incorporate constitutive constraints and their excellent generalization performance. In these models, the stress prediction follows from a linear combination of invariant-dependent coefficient functions and known tensor basis generators. However, thus far the formulations have been limited to stress representations based on the classical Rivlin and Ericksen form, while the performance of alternative representations has yet to be investigated. In this work, we survey a variety of tensor basis neural network models for modeling hyperelastic materials in a finite deformation context, including a number of so far unexplored formulations which use theoretically equivalent invariants and generators to Finger-Rivlin-Ericksen. Furthermore, we compare potential-based and coefficient-based approaches, as well as different calibration techniques. Nine variants are tested against both noisy and noiseless datasets for three different materials. Theoretical and practical insights into the performance of each formulation are given.Here's the translation in Traditional Chinese:<<SYS>>translate(given_text, to='zh-TW', language='zh-TW')</SYS>>Here's the translated text:Data-driven constitutive modeling frameworks based on neural networks and classical representation theorems have recently gained considerable attention due to their ability to easily incorporate constitutive constraints and their excellent generalization performance. In these models, the stress prediction follows from a linear combination of invariant-dependent coefficient functions and known tensor basis generators. However, thus far the formulations have been limited to stress representations based on the classical Rivlin and Ericksen form, while the performance of alternative representations has yet to be investigated. In this work, we survey a variety of tensor basis neural network models for modeling hyperelastic materials in a finite deformation context, including a number of so far unexplored formulations which use theoretically equivalent invariants and generators to Finger-Rivlin-Ericksen. Furthermore, we compare potential-based and coefficient-based approaches, as well as different calibration techniques. Nine variants are tested against both noisy and noiseless datasets for three different materials. Theoretical and practical insights into the performance of each formulation are given.
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model"><a href="#A-Deep-Dive-into-the-Connections-Between-the-Renormalization-Group-and-Deep-Learning-in-the-Ising-Model" class="headerlink" title="A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model"></a>A Deep Dive into the Connections Between the Renormalization Group and Deep Learning in the Ising Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11075">http://arxiv.org/abs/2308.11075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelsie Taylor</li>
<li>for: 这个论文的目的是探讨深度学习和 renormalization group（RG）之间的联系，以及深度学习是否可以被视为 RG 流。</li>
<li>methods: 作者使用了 Restricted Boltzmann Machines（RBMs）进行深度学习，并开发了一系列的 renormalization 技术来对 1D 和 2D Ising 模型进行比较。</li>
<li>results: 作者成功地使用 Adam 优化器和 correlation length 损失函数来学习 RG 流，并对 2D Ising 模型进行了验证。他们还发现了层次结构的学习，这与 RG 的层次结构有相似之处。但是，对于 simplest 的 nearest-neighbor Ising 模型，作者发现了量化上的不一致。<details>
<summary>Abstract</summary>
The renormalization group (RG) is an essential technique in statistical physics and quantum field theory, which considers scale-invariant properties of physical theories and how these theories' parameters change with scaling. Deep learning is a powerful computational technique that uses multi-layered neural networks to solve a myriad of complicated problems. Previous research suggests the possibility that unsupervised deep learning may be a form of RG flow, by being a layer-by-layer coarse graining of the original data. We examined this connection on a more rigorous basis for the simple example of Kadanoff block renormalization of the 2D nearest-neighbor Ising model, with our deep learning accomplished via Restricted Boltzmann Machines (RBMs). We developed extensive renormalization techniques for the 1D and 2D Ising model to provide a baseline for comparison. For the 1D Ising model, we successfully used Adam optimization on a correlation length loss function to learn the group flow, yielding results consistent with the analytical model for infinite N. For the 2D Ising model, we successfully generated Ising model samples using the Wolff algorithm, and performed the group flow using a quasi-deterministic method, validating these results by calculating the critical exponent \nu. We then examined RBM learning of the Ising model layer by layer, finding a blocking structure in the learning that is qualitatively similar to RG. Lastly, we directly compared the weights of each layer from the learning to Ising spin renormalization, but found quantitative inconsistencies for the simple case of nearest-neighbor Ising models.
</details>
<details>
<summary>摘要</summary>
“ renormalization group（RG）是物理学和量子场论中的一种重要技术，它考虑物理理论中的尺度无关性和参数如何随缩放变化。深度学习是一种强大的计算技术，使用多层神经网络解决了许多复杂的问题。之前的研究表明，无监督的深度学习可能是一种RG流，通过层次的粗化来描述原始数据。我们在更加严格的基础上进行了这种连接的研究，使用了Restricted Boltzmann Machines（RBMs）来实现深度学习。我们还开发了对1D和2D Ising模型的广泛的renoormalization技术，以提供一个基准 для比较。对于1D Ising模型，我们使用Adam优化器和尺度长度损失函数来学习群流，得到了与分析模型相符的结果。对于2D Ising模型，我们使用了Wolff算法生成样本，并使用 quasi-deterministic方法进行群流，并计算了扩散 exponent ν。然后，我们查看了RBM学习中每层的权重和Ising模型的renoormalization，发现了一种块结构，与RG具有相似的特征。最后，我们直接比较了每层权重的 weights 和Ising spin renormalization，发现了简单的 nearest-neighbor Ising 模型中的量化差异。”
</details></li>
</ul>
<hr>
<h2 id="Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression"><a href="#Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression" class="headerlink" title="Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression"></a>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11053">http://arxiv.org/abs/2308.11053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</li>
<li>for: 提高全双工通信中的干扰抑制和听频补做的灵活性和效率。</li>
<li>methods: 提出时空双路压缩法，通过可调 filters 实现维度减少，并通过后处理网络实现全序数据模型化来解决时间压缩导致的性能下降。</li>
<li>results: 实现了各种压缩比例（4x-32x）的灵活性，并与 FastFullSubNet 和 DeepFilterNet 的表现竞争。<details>
<summary>Abstract</summary>
Echo cancellation and noise reduction are essential for full-duplex communication, yet most existing neural networks have high computational costs and are inflexible in tuning model complexity. In this paper, we introduce time-frequency dual-path compression to achieve a wide range of compression ratios on computational cost. Specifically, for frequency compression, trainable filters are used to replace manually designed filters for dimension reduction. For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io/ultra_dual_path_compression.github.io/.
</details>
<details>
<summary>摘要</summary>
双路压缩是全二重通信中不可或缺的，但大多数现有的神经网络具有高计算成本和不可调整的模型复杂度。在这篇论文中，我们引入时间频率双路压缩以 дости持续各种压缩比率的 Computational Cost。具体来说，用于频率压缩的专案网络取代了手动设计的范本网络，以进行维度缩减。而用于时间压缩的专案网络则使用几个几个帧的预测来缓和大量的预测误差，以免受几个几个帧的预测误差对准确性的影响。我们发现，具有固定压缩比率的双路压缩可以提供更好的性能，覆盖压缩比率 від 4x 到 32x 之间，而且模型大小几乎不变。此外，我们的模型也与快速FullSubNet和DeepFilterNet的性能相当。更多详情可以查看hangtingchen.github.io/ultra_dual_path_compression.github.io/.
</details></li>
</ul>
<hr>
<h2 id="Spurious-Correlations-and-Where-to-Find-Them"><a href="#Spurious-Correlations-and-Where-to-Find-Them" class="headerlink" title="Spurious Correlations and Where to Find Them"></a>Spurious Correlations and Where to Find Them</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11043">http://arxiv.org/abs/2308.11043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gautam Sreekumar, Vishnu Naresh Boddeti</li>
<li>for: 本研究旨在探讨数据驱动学习中存在的假 correlate 问题，并提出一种基于 causal graph 生成的 Synthetic dataset，以便研究这种问题的影响。</li>
<li>methods: 本研究使用了一些常见的假 correlate 假设，并对标准 ERM 基elines 进行比较，以评估这些假设对模型性能的影响。</li>
<li>results: 研究发现，假 correlate 的存在会导致模型学习到不可靠的特征，从而降低模型的性能。同时，研究还发现了一些模型设计选择和假 correlate 之间的相互关系。<details>
<summary>Abstract</summary>
Spurious correlations occur when a model learns unreliable features from the data and are a well-known drawback of data-driven learning. Although there are several algorithms proposed to mitigate it, we are yet to jointly derive the indicators of spurious correlations. As a result, the solutions built upon standalone hypotheses fail to beat simple ERM baselines. We collect some of the commonly studied hypotheses behind the occurrence of spurious correlations and investigate their influence on standard ERM baselines using synthetic datasets generated from causal graphs. Subsequently, we observe patterns connecting these hypotheses and model design choices.
</details>
<details>
<summary>摘要</summary>
非常有用的关系会发生假冒险，这是数据驱动学习的一个重要问题。虽然有许多算法提出来解决这个问题，但我们还未能同时 derivate 假冒险的指标。因此，基于独立的假设建立的解决方案不能超过简单的 ERM 基elines。我们收集了一些通常研究的假设，这些假设会导致假冒险的发生，并通过使用 causal 图生成的 sintetic 数据进行调查。我们发现了这些假设和模型设计选择之间的征 patterns。
</details></li>
</ul>
<hr>
<h2 id="Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics"><a href="#Split-Learning-for-Distributed-Collaborative-Training-of-Deep-Learning-Models-in-Health-Informatics" class="headerlink" title="Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics"></a>Split Learning for Distributed Collaborative Training of Deep Learning Models in Health Informatics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11027">http://arxiv.org/abs/2308.11027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuohang Li, Chao Yan, Xinmeng Zhang, Gharib Gharibi, Zhijun Yin, Xiaoqian Jiang, Bradley A. Malin</li>
<li>for: 这篇论文旨在解决医疗机构内部数据分散和隐私要求的问题，使得深度学习模型能够在不同医疗机构之间分享数据并进行模型训练。</li>
<li>methods: 该论文提出了一种新的隐私保护分布式学习框架，该框架可以在不同医疗机构之间分享数据，而不需要将原始数据或模型参数泄露出去。</li>
<li>results: 根据实验结果，使用这种分布式学习框架可以让深度学习模型在不同医疗机构的数据上进行合作训练，而不会产生隐私泄露或计算效率的问题。<details>
<summary>Abstract</summary>
Deep learning continues to rapidly evolve and is now demonstrating remarkable potential for numerous medical prediction tasks. However, realizing deep learning models that generalize across healthcare organizations is challenging. This is due, in part, to the inherent siloed nature of these organizations and patient privacy requirements. To address this problem, we illustrate how split learning can enable collaborative training of deep learning models across disparate and privately maintained health datasets, while keeping the original records and model parameters private. We introduce a new privacy-preserving distributed learning framework that offers a higher level of privacy compared to conventional federated learning. We use several biomedical imaging and electronic health record (EHR) datasets to show that deep learning models trained via split learning can achieve highly similar performance to their centralized and federated counterparts while greatly improving computational efficiency and reducing privacy risks.
</details>
<details>
<summary>摘要</summary>
深度学习继续迅速发展，现在表现出了各种医疗预测任务的惊人潜力。然而，实现通用于医疗机构的深度学习模型却是一大挑战。这主要归结于医疗机构的自然分化性和患者隐私要求。为解决这问题，我们介绍了一种新的隐私保护分布式学习框架，可以在不同的私有保持健康数据集上进行分布式学习，同时保持原始记录和模型参数的私有性。我们使用了多个生物医学成像和电子医疗记录（EHR）数据集，展示了通过Split Learning训练的深度学习模型可以与中央化和联邦化模型相比，达到同等或更高的性能水平，同时大幅提高计算效率和降低隐私风险。
</details></li>
</ul>
<hr>
<h2 id="Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata"><a href="#Extreme-Multilabel-Classification-for-Specialist-Doctor-Recommendation-with-Implicit-Feedback-and-Limited-Patient-Metadata" class="headerlink" title="Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata"></a>Extreme Multilabel Classification for Specialist Doctor Recommendation with Implicit Feedback and Limited Patient Metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11022">http://arxiv.org/abs/2308.11022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filipa Valdeira, Stevo Racković, Valeria Danalachi, Qiwei Han, Cláudia Soares</li>
<li>for: This paper aims to predict medical referrals for both new patients and those with a consultation history, using Extreme Multilabel Classification (XML) to encode available features and explore different scenarios.</li>
<li>methods: The authors use XML, commonly employed in text-based classification tasks, to recast a traditional recommender setting into a multilabel classification problem that current XML methods can solve. They propose a unified model leveraging patient history across different specialties.</li>
<li>results: Compared to state-of-the-art recommendation systems using the same features, the authors’ approach consistently improves standard recommendation metrics up to approximately $10%$ for patients with a previous consultation history. For new patients, XML proves better at exploiting available features, outperforming the benchmark in favorable scenarios, with particular emphasis on recall metrics.<details>
<summary>Abstract</summary>
Recommendation Systems (RS) are often used to address the issue of medical doctor referrals. However, these systems require access to patient feedback and medical records, which may not always be available in real-world scenarios. Our research focuses on medical referrals and aims to predict recommendations in different specialties of physicians for both new patients and those with a consultation history. We use Extreme Multilabel Classification (XML), commonly employed in text-based classification tasks, to encode available features and explore different scenarios. While its potential for recommendation tasks has often been suggested, this has not been thoroughly explored in the literature. Motivated by the doctor referral case, we show how to recast a traditional recommender setting into a multilabel classification problem that current XML methods can solve. Further, we propose a unified model leveraging patient history across different specialties. Compared to state-of-the-art RS using the same features, our approach consistently improves standard recommendation metrics up to approximately $10\%$ for patients with a previous consultation history. For new patients, XML proves better at exploiting available features, outperforming the benchmark in favorable scenarios, with particular emphasis on recall metrics. Thus, our approach brings us one step closer to creating more effective and personalized doctor referral systems. Additionally, it highlights XML as a promising alternative to current hybrid or content-based RS, while identifying key aspects to take into account when using XML for recommendation tasks.
</details>
<details>
<summary>摘要</summary>
医疗专家 recombination系统（RS）经常用于解决医疗专家推荐的问题。然而，这些系统可能需要患者反馈和医疗记录，却不一定在实际场景中可用。我们的研究关注医疗推荐，并 стремятся预测不同专业医生的建议，包括新患者和已有咨询历史。我们使用极端多标签分类（XML），通常用于文本基于分类任务，来编码可用的特征并探索不同场景。虽然XML在推荐任务中的潜在优势已经得到了一些研究，但这还没有得到充分的探讨。受医生推荐 случа件 inspirited，我们提出了一种将传统推荐设定转化为多标签分类问题的方法，使得现有的XML方法可以解决。此外，我们提议一种综合模型，利用患者历史跨不同专业。与现有的RS使用同样的特征相比，我们的方法在拥有历史记录的患者上 consistently 改善标准推荐指标，最高提高约10%。对新患者来说，XML表现出色地利用可用的特征，在有利场景下超越 benchmark，尤其是在回溯率指标上。因此，我们的方法使得我们更近一步到创造更有效和个性化的医生推荐系统。此外，它还证明了XML作为推荐任务的一种有前途的alternative，而且标识了在使用XML时需要注意的关键方面。
</details></li>
</ul>
<hr>
<h2 id="Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems"><a href="#Instance-based-Learning-with-Prototype-Reduction-for-Real-Time-Proportional-Myocontrol-A-Randomized-User-Study-Demonstrating-Accuracy-preserving-Data-Reduction-for-Prosthetic-Embedded-Systems" class="headerlink" title="Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems"></a>Instance-based Learning with Prototype Reduction for Real-Time Proportional Myocontrol: A Randomized User Study Demonstrating Accuracy-preserving Data Reduction for Prosthetic Embedded Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11019">http://arxiv.org/abs/2308.11019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Sziburis, Markus Nowak, Davide Brunelli</li>
<li>for:  Gesture detection in prosthetic control</li>
<li>methods:  kNN scheme with dataset reduction techniques (Decision Surface Mapping)</li>
<li>results:  Significantly better performance than regression techniques, with a reduction rate of over 99% and no statistically significant difference between kNN and kNN with DSM.<details>
<summary>Abstract</summary>
This work presents the design, implementation and validation of learning techniques based on the kNN scheme for gesture detection in prosthetic control. To cope with high computational demands in instance-based prediction, methods of dataset reduction are evaluated considering real-time determinism to allow for the reliable integration into battery-powered portable devices. The influence of parameterization and varying proportionality schemes is analyzed, utilizing an eight-channel-sEMG armband. Besides offline cross-validation accuracy, success rates in real-time pilot experiments (online target achievement tests) are determined. Based on the assessment of specific dataset reduction techniques' adequacy for embedded control applications regarding accuracy and timing behaviour, Decision Surface Mapping (DSM) proves itself promising when applying kNN on the reduced set. A randomized, double-blind user study was conducted to evaluate the respective methods (kNN and kNN with DSM-reduction) against Ridge Regression (RR) and RR with Random Fourier Features (RR-RFF). The kNN-based methods performed significantly better (p<0.0005) than the regression techniques. Between DSM-kNN and kNN, there was no statistically significant difference (significance level 0.05). This is remarkable in consideration of only one sample per class in the reduced set, thus yielding a reduction rate of over 99% while preserving success rate. The same behaviour could be confirmed in an extended user study. With k=1, which turned out to be an excellent choice, the runtime complexity of both kNN (in every prediction step) as well as DSM-kNN (in the training phase) becomes linear concerning the number of original samples, favouring dependable wearable prosthesis applications.
</details>
<details>
<summary>摘要</summary>
Based on the assessment of specific dataset reduction techniques for embedded control applications regarding accuracy and timing behavior, Decision Surface Mapping (DSM) proves to be promising when applied to the reduced set using kNN. A randomized, double-blind user study was conducted to evaluate the kNN-based methods against Ridge Regression (RR) and RR with Random Fourier Features (RR-RFF). The kNN-based methods performed significantly better (p < 0.0005) than the regression techniques. Between DSM-kNN and kNN, there was no statistically significant difference (significance level 0.05). This is noteworthy, considering only one sample per class in the reduced set, resulting in a reduction rate of over 99% while preserving success rate. The same behavior was confirmed in an extended user study.With k = 1, which was found to be an excellent choice, the runtime complexity of both kNN (in every prediction step) and DSM-kNN (in the training phase) becomes linear concerning the number of original samples, favoring dependable wearable prosthesis applications.
</details></li>
</ul>
<hr>
<h2 id="Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes"><a href="#Fat-Shattering-Joint-Measurability-and-PAC-Learnability-of-POVM-Hypothesis-Classes" class="headerlink" title="Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes"></a>Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12304">http://arxiv.org/abs/2308.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abram Magner, Arun Padakandla</li>
<li>for: 这篇论文主要研究了量子测量类的学习可能性，并提出了匹配的必要和 suficient conditions，以及相应的样本复杂性上限。</li>
<li>methods: 作者使用了empirical risk和denoised ERM来学习量子测量类，并证明了这两种方法的universal性和有效性。</li>
<li>results: 作者证明了一些量子测量类是可学习的，并提供了对应的样本复杂性上限。此外，作者还证明了一些previous works中的result不正确，并提供了一种新的学习规则—denoised ERM。<details>
<summary>Abstract</summary>
We characterize learnability for quantum measurement classes by establishing matching necessary and sufficient conditions for their PAC learnability, along with corresponding sample complexity bounds, in the setting where the learner is given access only to prepared quantum states. We first probe the results from previous works on this setting. We show that the empirical risk defined in previous works and matching the definition in the classical theory fails to satisfy the uniform convergence property enjoyed in the classical setting for some learnable classes. Moreover, we show that VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes. To surmount the failure of the standard ERM to satisfy uniform convergence, we define a new learning rule -- denoised ERM. We show this to be a universal learning rule for POVM and probabilistically observed concept classes, and the condition for it to satisfy uniform convergence is finite fat shattering dimension of the class. We give quantitative sample complexity upper and lower bounds for learnability in terms of finite fat-shattering dimension and a notion of approximate finite partitionability into approximately jointly measurable subsets, which allow for sample reuse. We then show that finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets, leading to our matching conditions. We also show that every measurement class defined on a finite-dimensional Hilbert space is PAC learnable. We illustrate our results on several example POVM classes.
</details>
<details>
<summary>摘要</summary>
我们characterize学习可能性 для量子测量类by establishing匹配的必需和充分条件，以及相应的样本复杂度上限，在learner只有访问准备好的量子状态的设置下。我们首先探讨previous works中的结果。我们发现，employmedical risk定义在previous works和classical theory中匹配的不满足uniform convergence性 enjoyed in the classical setting for some learnable classes。此外，我们发现VC dimension generalization upper bounds in previous work are frequently infinite, even for finite-dimensional POVM classes。为了缺乏标准ERM的uniform convergence，我们定义了一个新的学习规则——denoised ERM。我们证明这是一个universal learning rule for POVM和 probabilistically observed concept classes，并且condition for it to satisfy uniform convergence is finite fat shattering dimension of the class。我们给出了量子sample complexity upper和lower bounds in terms offinite fat-shattering dimension和一种notion of approximate finite partitionability into approximately jointly measurable subsets，which allow for sample reuse。然后，我们证明finite fat shattering dimension implies finite coverability by approximately jointly measurable subsets, leading to our matching conditions。最后，我们证明每个定义在finite-dimensional Hilbert space上的测量类都是PAC可学习的。我们在several example POVM classes中ILLustrate our results。
</details></li>
</ul>
<hr>
<h2 id="Majorana-Demonstrator-Data-Release-for-AI-ML-Applications"><a href="#Majorana-Demonstrator-Data-Release-for-AI-ML-Applications" class="headerlink" title="Majorana Demonstrator Data Release for AI&#x2F;ML Applications"></a>Majorana Demonstrator Data Release for AI&#x2F;ML Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10856">http://arxiv.org/abs/2308.10856</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. J. Arnquist, F. T. Avignone III, A. S. Barabash, C. J. Barton, K. H. Bhimani, E. Blalock, B. Bos, M. Busch, M. Buuck, T. S. Caldwell, Y. -D. Chan, C. D. Christofferson, P. -H. Chu, M. L. Clark, C. Cuesta, J. A. Detwiler, Yu. Efremenko, H. Ejiri, S. R. Elliott, N. Fuad, G. K. Giovanetti, M. P. Green, J. Gruszko, I. S. Guinn, V. E. Guiseppe, C. R. Haufe, R. Henning, D. Hervas Aguilar, E. W. Hoppe, A. Hostiuc, M. F. Kidd, I. Kim, R. T. Kouzes, T. E. Lannen V, A. Li, J. M. Lopez-Castano, R. D. Martin, R. Massarczyk, S. J. Meijer, S. Mertens, T. K. Oli, L. S. Paudel, W. Pettus, A. W. P. Poon, B. Quenallata, D. C. Radford, A. L. Reine, K. Rielage, N. W. Ruof, D. C. Schaper, S. J. Schleich, D. Tedeschi, R. L. Varner, S. Vasilyev, S. L. Watkins, J. F. Wilkerson, C. Wiseman, W. Xu, C. -H. Yu, B. X. Zhu<br>for:This paper is written for the purpose of releasing a subset of calibration data from the Majorana Demonstrator experiment to support the training and testing of Artificial Intelligence (AI) and Machine Learning (ML) algorithms.methods:The paper uses HDF5 file format to store the raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, along with relevant metadata.results:The paper provides a dataset that includes a subset of the calibration data from the Majorana Demonstrator experiment, which is specifically designed for the training and testing of AI and ML algorithms. The dataset includes raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, along with relevant metadata.<details>
<summary>Abstract</summary>
The enclosed data release consists of a subset of the calibration data from the Majorana Demonstrator experiment. Each Majorana event is accompanied by raw Germanium detector waveforms, pulse shape discrimination cuts, and calibrated final energies, all shared in an HDF5 file format along with relevant metadata. This release is specifically designed to support the training and testing of Artificial Intelligence (AI) and Machine Learning (ML) algorithms upon our data. This document is structured as follows. Section I provides an overview of the dataset's content and format; Section II outlines the location of this dataset and the method for accessing it; Section III presents the NPML Machine Learning Challenge associated with this dataset; Section IV contains a disclaimer from the Majorana collaboration regarding the use of this dataset; Appendix A contains technical details of this data release. Please direct questions about the material provided within this release to liaobo77@ucsd.edu (A. Li).
</details>
<details>
<summary>摘要</summary>
附件的数据释放包含 Majorana 实验中的一个子集 calibration 数据。每个 Majorana 事件都包含Raw Germanium 探测器波形、振荡形态分离cuts 和加工后的最终能量， alles 共同存储在 HDF5 文件格式中，并同时包含相关的元数据。这个释放是为支持使用人工智能（AI）和机器学习（ML）算法进行训练和测试而设计的。本文结构如下：Section I 提供了数据集的内容和格式的概述；Section II 描述了数据集的位置和访问方法；Section III 介绍了NPML 机器学习挑战与此数据集相关的详细信息；Section IV 包含 Majorana 团队的声明关于使用这个数据集； Appendix A 包含这个数据释放的技术详细信息。如有关于附件中提供的内容的问题，请邮件 liaobo77@ucsd.edu (A. Li)。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks"><a href="#Evaluating-quantum-generative-models-via-imbalanced-data-classification-benchmarks" class="headerlink" title="Evaluating quantum generative models via imbalanced data classification benchmarks"></a>Evaluating quantum generative models via imbalanced data classification benchmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10847">http://arxiv.org/abs/2308.10847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Graham R. Enos, Matthew J. Reagor, Eric Hulburd</li>
<li>for: 这个论文是为了研究量子机器学习模型的异常行为是否可以用现实世界数据集来评估的。</li>
<li>methods: 该论文使用可解释人工智能技术来分析生成自量子-类型 нейрон网络的合成数据，并对这些数据进行比较与现有的措施来mitigate类别偏好。</li>
<li>results: 该论文发现，对于不同的数据集，量子生成的数据会具有不同的特征，这些特征可以用来评估量子机器学习模型的性能。<details>
<summary>Abstract</summary>
A limited set of tools exist for assessing whether the behavior of quantum machine learning models diverges from conventional models, outside of abstract or theoretical settings. We present a systematic application of explainable artificial intelligence techniques to analyze synthetic data generated from a hybrid quantum-classical neural network adapted from twenty different real-world data sets, including solar flares, cardiac arrhythmia, and speech data. Each of these data sets exhibits varying degrees of complexity and class imbalance. We benchmark the quantum-generated data relative to state-of-the-art methods for mitigating class imbalance for associated classification tasks. We leverage this approach to elucidate the qualities of a problem that make it more or less likely to be amenable to a hybrid quantum-classical generative model.
</details>
<details>
<summary>摘要</summary>
有限的工具存在用于判断量子机器学习模型的行为与常规模型 diverges，外部的抽象或理论设置之外。我们们提出了一种系统的应用 explainable artificial intelligence 技术来分析量子-классиical 神经网络在 twenty 个真实世界数据集中生成的synthetic数据。这些数据集包括太阳风暴、心脏 arrhythmia 和语音数据，每个数据集都具有不同的复杂度和类别偏度。我们将量子生成的数据与现有的方法进行比较，以衡量对类别偏度的影响。我们利用这种方法来描述问题的特质，使其更或 menos 可能适用于量子-классиical 生成模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/cs.LG_2023_08_22/" data-id="cllt9prw2002pol885j5batpa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/cs.SD_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/cs.SD_2023_08_22/">cs.SD - 2023-08-22 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users"><a href="#Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users" class="headerlink" title="Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users"></a>Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11456">http://arxiv.org/abs/2308.11456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Udo Diehl, Hannes Zilly, Felix Sattler, Yosef Singer, Kevin Kepp, Mark Berry, Henning Hasemann, Marlene Zippel, Müge Kaya, Paul Meyer-Rachner, Annett Pudszuhn, Veit M. Hofmann, Matthias Vormann, Elias Sprengel</li>
<li>For: The paper is written to improve the performance of hearing aids in real-world noisy environments using deep learning-based denoising.* Methods: The paper uses a deep learning-based denoising system that runs in real time on a mobile device (iPhone 7 or Samsung Galaxy S10) and streams the denoised audio to the hearing aid, resulting in a total delay of around 75ms.* Results: The denoising system improves audio quality in three tests: subjective audio ratings, objective speech intelligibility, and live conversations in a noisy environment. Subjective ratings increase by more than 40%, and speech reception thresholds improve by 1.6 dB SRT compared to a fitted hearing aid as a baseline.<details>
<summary>Abstract</summary>
The hearing loss of almost half a billion people is commonly treated with hearing aids. However, current hearing aids often do not work well in real-world noisy environments. We present a deep learning based denoising system that runs in real time on iPhone 7 and Samsung Galaxy S10 (25ms algorithmic latency). The denoised audio is streamed to the hearing aid, resulting in a total delay of around 75ms. In tests with hearing aid users having moderate to severe hearing loss, our denoising system improves audio across three tests: 1) listening for subjective audio ratings, 2) listening for objective speech intelligibility, and 3) live conversations in a noisy environment for subjective ratings. Subjective ratings increase by more than 40%, for both the listening test and the live conversation compared to a fitted hearing aid as a baseline. Speech reception thresholds, measuring speech understanding in noise, improve by 1.6 dB SRT. Ours is the first denoising system that is implemented on a mobile device, streamed directly to users' hearing aids using only a single channel as audio input while improving user satisfaction on all tested aspects, including speech intelligibility. This includes overall preference of the denoised and streamed signal over the hearing aid, thereby accepting the higher latency for the significant improvement in speech understanding.
</details>
<details>
<summary>摘要</summary>
现有约半亿人的听力问题，通常由听力器进行治疗。然而，现有的听力器frequently不会在实际的噪音环境中工作良好。我们提出了基于深度学习的噪音去除系统，可以在real-time中运行于iPhone 7和Samsung Galaxy S10（25ms的算法延迟）。去除的音频被传送到听力器，总延迟约75ms。在听力器用户（moderate to severe hearing loss）进行了三种测试：1）聆听主观音乐评分，2）聆听语音智能度测试，3）在噪音环境中进行生活对话主观评分。主观评分提高了超过40%，包括聆听测试和生活对话。语音接收阈值（SRT）也提高了1.6dB。我们的噪音去除系统是首个在 mobildevice上实现，通过单一通道音频输入，实时传送到用户的听力器，同时改善用户满意度在所有测试方面，包括语音理解度、主观满意度和全面满意度。这包括听力器用户对去除和传送的音频的偏好，因此愿意接受更高的延迟以换取明显提高的语音理解度。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1"><a href="#Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1" class="headerlink" title="Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1"></a>Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11337">http://arxiv.org/abs/2308.11337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ünal Ege Gaznepoglu, Nils Peters</li>
<li>for: 本研究旨在评估VPC基线B1是否能够Synthesize人类语音的可重现性。</li>
<li>methods: 本研究使用四个对象指标测试语音质量、波形相似度和F0相似度，以评估VPC基线B1是否引入了artifacts。</li>
<li>results: 研究发现，both speech representation和vocoder都会引入artifacts，导致语音具有不自然的感觉。一个MUSHRA-like listening test中，18名参与者也证实了我们的发现，这促使了进一步的分析和 sintesis组件的研究。<details>
<summary>Abstract</summary>
Speaker anonymization systems continue to improve their ability to obfuscate the original speaker characteristics in a speech signal, but often create processing artifacts and unnatural sounding voices as a tradeoff. Many of those systems stem from the VoicePrivacy Challenge (VPC) Baseline B1, using a neural vocoder to synthesize speech from an F0, x-vectors and bottleneck features-based speech representation. Inspired by this, we investigate the reproduction capabilities of the aforementioned baseline, to assess how successful the shared methodology is in synthesizing human-like speech. We use four objective metrics to measure speech quality, waveform similarity, and F0 similarity. Our findings indicate that both the speech representation and the vocoder introduces artifacts, causing an unnatural perception. A MUSHRA-like listening test on 18 subjects corroborate our findings, motivating further research on the analysis and synthesis components of the VPC Baseline B1.
</details>
<details>
<summary>摘要</summary>
Note:* "Speaker anonymization" is translated as " speaker obscurity" (说话者匿名)* "VPC" is translated as "VoicePrivacy Challenge" (voice privacy challenge)* "baseline" is translated as "基线" (baseline)* "neural vocoder" is translated as "神经 vocoder" (neural vocoder)* "F0" is translated as " Fundamental Frequency" (基频)* "x-vectors" is translated as "cross-vector" (跨 vector)* "bottleneck features" is translated as "瓶颈特征" (bottleneck features)* "speech representation" is translated as "speech representation" (speech representation)* "objective metrics" is translated as "对象指标" (objective metrics)* "waveform similarity" is translated as "waveform similarity" (waveform similarity)* "F0 similarity" is translated as "F0 similarity" (F0 similarity)* "MUSHRA-like listening test" is translated as "MUSHRA-like listening test" (MUSHRA-like listening test)
</details></li>
</ul>
<hr>
<h2 id="PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion"><a href="#PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion" class="headerlink" title="PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion"></a>PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11084">http://arxiv.org/abs/2308.11084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yimin Deng, Huaizhen Tang, Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao</li>
<li>for: 本研究旨在提出一种新的voice conversion（VC）框架，以提高VC任务中的自然语音表达。</li>
<li>methods: 本研究使用了一种新的speech augmentation算法，以提取robust的prosody信息。然后，通过mask和predict机制，实现了content和prosody信息的独立分解。</li>
<li>results: 实验结果表明，PMVC框架可以提高 converted speech的自然性和相似性。<details>
<summary>Abstract</summary>
Voice conversion as the style transfer task applied to speech, refers to converting one person's speech into a new speech that sounds like another person's. Up to now, there has been a lot of research devoted to better implementation of VC tasks. However, a good voice conversion model should not only match the timbre information of the target speaker, but also expressive information such as prosody, pace, pause, etc. In this context, prosody modeling is crucial for achieving expressive voice conversion that sounds natural and convincing. Unfortunately, prosody modeling is important but challenging, especially without text transcriptions. In this paper, we firstly propose a novel voice conversion framework named 'PMVC', which effectively separates and models the content, timbre, and prosodic information from the speech without text transcriptions. Specially, we introduce a new speech augmentation algorithm for robust prosody extraction. And building upon this, mask and predict mechanism is applied in the disentanglement of prosody and content information. The experimental results on the AIShell-3 corpus supports our improvement of naturalness and similarity of converted speech.
</details>
<details>
<summary>摘要</summary>
<<SYS>>请将以下文本翻译成简化中文。<</SYS>>声音转换作为样式传递任务应用于语音，指的是将一个人的语音转换成另一个人的语音，以致声音更像target speaker的。至今，对voice conversion task的实现有很多研究。然而，一个好的声音转换模型应该不仅匹配target speaker的嗓音信息，还应该包括表达信息 such as 句子结构、速度、停顿等。在这种情况下，句子结构模型化是实现自然和有力的声音转换的关键。然而，句子结构模型化是重要但困难的，尤其是无文本转写。在这篇论文中，我们首先提出了一种新的声音转换框架名为'PMVC'，可以有效地从语音中分离和模型 contenido、嗓音和表达信息。具体来说，我们首次提出了一种新的语音增强算法，用于robust的句子结构EXTRACTION。然后，基于这种增强算法，我们应用了mas和predict机制来分离句子结构和 contenido信息。实验结果表明，在AIShell-3 corpus上，我们的改进方法可以提高转换后语音的自然性和相似性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/cs.SD_2023_08_22/" data-id="cllt9prwx0052ol88gfgh3s3l" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/eess.AS_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/eess.AS_2023_08_22/">eess.AS - 2023-08-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Furnishing-Sound-Event-Detection-with-Language-Model-Abilities"><a href="#Furnishing-Sound-Event-Detection-with-Language-Model-Abilities" class="headerlink" title="Furnishing Sound Event Detection with Language Model Abilities"></a>Furnishing Sound Event Detection with Language Model Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11530">http://arxiv.org/abs/2308.11530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hualei Wang, Jianguo Mao, Zhifang Guo, Jiarui Wan, Hong Liu, Xiangdong Wang</li>
</ul>
<p>Abstract:<br>Recently, the ability of language models (LMs) has attracted increasing attention in visual cross-modality. In this paper, we further explore the generation capacity of LMs for sound event detection (SED), beyond the visual domain. Specifically, we propose an elegant method that aligns audio features and text features to accomplish sound event classification and temporal location. The framework consists of an acoustic encoder, a contrastive module that align the corresponding representations of the text and audio, and a decoupled language decoder that generates temporal and event sequences from the audio characteristic. Compared with conventional works that require complicated processing and barely utilize limited audio features, our model is more concise and comprehensive since language model directly leverage its semantic capabilities to generate the sequences. We investigate different decoupling modules to demonstrate the effectiveness for timestamps capture and event classification. Evaluation results show that the proposed method achieves accurate sequences of sound event detection.</p>
<hr>
<h2 id="Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users"><a href="#Deep-learning-based-denoising-streamed-from-mobile-phones-improves-speech-in-noise-understanding-for-hearing-aid-users" class="headerlink" title="Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users"></a>Deep learning-based denoising streamed from mobile phones improves speech-in-noise understanding for hearing aid users</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11456">http://arxiv.org/abs/2308.11456</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Udo Diehl, Hannes Zilly, Felix Sattler, Yosef Singer, Kevin Kepp, Mark Berry, Henning Hasemann, Marlene Zippel, Müge Kaya, Paul Meyer-Rachner, Annett Pudszuhn, Veit M. Hofmann, Matthias Vormann, Elias Sprengel</li>
</ul>
<p>Abstract:<br>The hearing loss of almost half a billion people is commonly treated with hearing aids. However, current hearing aids often do not work well in real-world noisy environments. We present a deep learning based denoising system that runs in real time on iPhone 7 and Samsung Galaxy S10 (25ms algorithmic latency). The denoised audio is streamed to the hearing aid, resulting in a total delay of around 75ms. In tests with hearing aid users having moderate to severe hearing loss, our denoising system improves audio across three tests: 1) listening for subjective audio ratings, 2) listening for objective speech intelligibility, and 3) live conversations in a noisy environment for subjective ratings. Subjective ratings increase by more than 40%, for both the listening test and the live conversation compared to a fitted hearing aid as a baseline. Speech reception thresholds, measuring speech understanding in noise, improve by 1.6 dB SRT. Ours is the first denoising system that is implemented on a mobile device, streamed directly to users’ hearing aids using only a single channel as audio input while improving user satisfaction on all tested aspects, including speech intelligibility. This includes overall preference of the denoised and streamed signal over the hearing aid, thereby accepting the higher latency for the significant improvement in speech understanding.</p>
<hr>
<h2 id="Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition"><a href="#Convoifilter-A-case-study-of-doing-cocktail-party-speech-recognition" class="headerlink" title="Convoifilter: A case study of doing cocktail party speech recognition"></a>Convoifilter: A case study of doing cocktail party speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11380">http://arxiv.org/abs/2308.11380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thai-Binh Nguyen, Alexander Waibel</li>
</ul>
<p>Abstract:<br>This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker’s voice from background noise, along with an ASR module. Through this approach, the model is able to decrease the word error rate (WER) of ASR from 80% to 26.4%. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning.</p>
<hr>
<h2 id="Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1"><a href="#Evaluation-of-the-Speech-Resynthesis-Capabilities-of-the-VoicePrivacy-Challenge-Baseline-B1" class="headerlink" title="Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1"></a>Evaluation of the Speech Resynthesis Capabilities of the VoicePrivacy Challenge Baseline B1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11337">http://arxiv.org/abs/2308.11337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ünal Ege Gaznepoglu, Nils Peters</li>
</ul>
<p>Abstract:<br>Speaker anonymization systems continue to improve their ability to obfuscate the original speaker characteristics in a speech signal, but often create processing artifacts and unnatural sounding voices as a tradeoff. Many of those systems stem from the VoicePrivacy Challenge (VPC) Baseline B1, using a neural vocoder to synthesize speech from an F0, x-vectors and bottleneck features-based speech representation. Inspired by this, we investigate the reproduction capabilities of the aforementioned baseline, to assess how successful the shared methodology is in synthesizing human-like speech. We use four objective metrics to measure speech quality, waveform similarity, and F0 similarity. Our findings indicate that both the speech representation and the vocoder introduces artifacts, causing an unnatural perception. A MUSHRA-like listening test on 18 subjects corroborate our findings, motivating further research on the analysis and synthesis components of the VPC Baseline B1.</p>
<hr>
<h2 id="Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning"><a href="#Music-Understanding-LLaMA-Advancing-Text-to-Music-Generation-with-Question-Answering-and-Captioning" class="headerlink" title="Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning"></a>Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11276">http://arxiv.org/abs/2308.11276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shansong Liu, Atin Sakkeer Hussain, Chenshuo Sun, Ying Shan</li>
</ul>
<p>Abstract:<br>Text-to-music generation (T2M-Gen) faces a major obstacle due to the scarcity of large-scale publicly available music datasets with natural language captions. To address this, we propose the Music Understanding LLaMA (MU-LLaMA), capable of answering music-related questions and generating captions for music files. Our model utilizes audio representations from a pretrained MERT model to extract music features. However, obtaining a suitable dataset for training the MU-LLaMA model remains challenging, as existing publicly accessible audio question answering datasets lack the necessary depth for open-ended music question answering. To fill this gap, we present a methodology for generating question-answer pairs from existing audio captioning datasets and introduce the MusicQA Dataset designed for answering open-ended music-related questions. The experiments demonstrate that the proposed MU-LLaMA model, trained on our designed MusicQA dataset, achieves outstanding performance in both music question answering and music caption generation across various metrics, outperforming current state-of-the-art (SOTA) models in both fields and offering a promising advancement in the T2M-Gen research field.</p>
<hr>
<h2 id="Modeling-Bends-in-Popular-Music-Guitar-Tablatures"><a href="#Modeling-Bends-in-Popular-Music-Guitar-Tablatures" class="headerlink" title="Modeling Bends in Popular Music Guitar Tablatures"></a>Modeling Bends in Popular Music Guitar Tablatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12307">http://arxiv.org/abs/2308.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/adhooge1/bend-prediction">https://gitlab.com/adhooge1/bend-prediction</a></li>
<li>paper_authors: Alexandre D’Hooge, Louis Bigo, Ken Déguernel</li>
</ul>
<p>Abstract:<br>Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on&#x2F;pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into guitar tablatures.</p>
<hr>
<h2 id="An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification"><a href="#An-Effective-Transformer-based-Contextual-Model-and-Temporal-Gate-Pooling-for-Speaker-Identification" class="headerlink" title="An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification"></a>An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11241">http://arxiv.org/abs/2308.11241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harunorikawano/speaker-identification-with-tgp">https://github.com/harunorikawano/speaker-identification-with-tgp</a></li>
<li>paper_authors: Harunori Kawano, Sota Shimizu</li>
</ul>
<p>Abstract:<br>Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 85.9% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at <a target="_blank" rel="noopener" href="https://github.com/HarunoriKawano/speaker-identification-with-tgp">https://github.com/HarunoriKawano/speaker-identification-with-tgp</a>.</p>
<hr>
<h2 id="PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion"><a href="#PMVC-Data-Augmentation-Based-Prosody-Modeling-for-Expressive-Voice-Conversion" class="headerlink" title="PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion"></a>PMVC: Data Augmentation-Based Prosody Modeling for Expressive Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11084">http://arxiv.org/abs/2308.11084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yimin Deng, Huaizhen Tang, Xulong Zhang, Jianzong Wang, Ning Cheng, Jing Xiao</li>
</ul>
<p>Abstract:<br>Voice conversion as the style transfer task applied to speech, refers to converting one person’s speech into a new speech that sounds like another person’s. Up to now, there has been a lot of research devoted to better implementation of VC tasks. However, a good voice conversion model should not only match the timbre information of the target speaker, but also expressive information such as prosody, pace, pause, etc. In this context, prosody modeling is crucial for achieving expressive voice conversion that sounds natural and convincing. Unfortunately, prosody modeling is important but challenging, especially without text transcriptions. In this paper, we firstly propose a novel voice conversion framework named ‘PMVC’, which effectively separates and models the content, timbre, and prosodic information from the speech without text transcriptions. Specially, we introduce a new speech augmentation algorithm for robust prosody extraction. And building upon this, mask and predict mechanism is applied in the disentanglement of prosody and content information. The experimental results on the AIShell-3 corpus supports our improvement of naturalness and similarity of converted speech.</p>
<hr>
<h2 id="Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression"><a href="#Ultra-Dual-Path-Compression-For-Joint-Echo-Cancellation-And-Noise-Suppression" class="headerlink" title="Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression"></a>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11053">http://arxiv.org/abs/2308.11053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</li>
</ul>
<p>Abstract:<br>Echo cancellation and noise reduction are essential for full-duplex communication, yet most existing neural networks have high computational costs and are inflexible in tuning model complexity. In this paper, we introduce time-frequency dual-path compression to achieve a wide range of compression ratios on computational cost. Specifically, for frequency compression, trainable filters are used to replace manually designed filters for dimension reduction. For time compression, only using frame skipped prediction causes large performance degradation, which can be alleviated by a post-processing network with full sequence modeling. We have found that under fixed compression ratios, dual-path compression combining both the time and frequency methods will give further performance improvement, covering compression ratios from 4x to 32x with little model size change. Moreover, the proposed models show competitive performance compared with fast FullSubNet and DeepFilterNet. A demo page can be found at hangtingchen.github.io&#x2F;ultra_dual_path_compression.github.io&#x2F;.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/eess.AS_2023_08_22/" data-id="cllt9prxh006wol88dmiz0k8n" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/22/eess.IV_2023_08_22/" class="article-date">
  <time datetime="2023-08-22T00:00:00.000Z" itemprop="datePublished">2023-08-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/22/eess.IV_2023_08_22/">eess.IV - 2023-08-22 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Validation-of-apparent-intra-and-extra-myocellular-lipid-content-indicator-using-spiral-spectroscopic-imaging-at-3T"><a href="#Validation-of-apparent-intra-and-extra-myocellular-lipid-content-indicator-using-spiral-spectroscopic-imaging-at-3T" class="headerlink" title="Validation of apparent intra-and extra-myocellular lipid content indicator using spiral spectroscopic imaging at 3T"></a>Validation of apparent intra-and extra-myocellular lipid content indicator using spiral spectroscopic imaging at 3T</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11668">http://arxiv.org/abs/2308.11668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Naëgel, Magalie Viallon, Jabrane Karkouri, Thomas Troalen, Pierre Croisille, Hélène Ratiney</li>
<li>for: 本研究はIMCL和EMCLの视觉的な内容を地図化するための、高速かつ単纯な方法を提案します。</li>
<li>methods: 本研究では、スパイラルMRSIを基盘とした方法を使用します。</li>
<li>results: 本研究では、クラシック质量结果との比较により、IMCLとEMCLの视觉的な内容の测定に高い精度を示します。<details>
<summary>Abstract</summary>
This work presents a fast and simple method based on spiral MRSI for mapping the IMCL and EMCL apparent content, which is a challenging task and it compares this indicator to classical quantification results in muscles of interest.
</details>
<details>
<summary>摘要</summary>
这个研究提出了一种快速简单的方法，基于螺旋MRSI测量IMCL和EMCL显示的内容，这是一项复杂的任务，并与经典量化结果进行比较。Here's a breakdown of the translation:* 这个研究 (zhè ge yánjiū) - This study* 提出了 (tīshào le) - proposes* 一种 (yī zhǒng) - a kind of* 快速简单的 (kuài sù jiǎn jiǎn de) - fast and simple* 方法 (fāngédé) - method* 基于 (jīyù) - based on* 螺旋MRSI (chuān xuān MRSI) - spiral MRSI* 测量 (cèliang) - measuring* IMCL (yìmóu zhīlè) - intramuscular fat* 和 (hé) - and* EMCL (èmelè zhīlè) - extracellular fat* 显示 (xiǎngshì) - display* 的内容 (de nèirong) - of the content* 这是 (zhè shì) - this is* 一项 (yī jiāo) - a project* 复杂的 (fùzé de) - complex* 任务 (róngzú) - task* 并 (bìng) - and* 与 (yǔ) - with* 经典量化结果 (jīngdiǎn liàngjié yuèshì) - classical quantification results* 进行比较 (jìnxíng bǐjiāo) - to compareI hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Phase-Aberration-Correction-A-Deep-Learning-Based-Aberration-to-Aberration-Approach"><a href="#Phase-Aberration-Correction-A-Deep-Learning-Based-Aberration-to-Aberration-Approach" class="headerlink" title="Phase Aberration Correction: A Deep Learning-Based Aberration to Aberration Approach"></a>Phase Aberration Correction: A Deep Learning-Based Aberration to Aberration Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11149">http://arxiv.org/abs/2308.11149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mostafa Sharifzadeh, Sobhan Goudarzi, An Tang, Habib Benali, Hassan Rivaz</li>
<li>for: This paper aims to correct phase aberration in ultrasound imaging without requiring ground truth data.</li>
<li>methods: The proposed method uses deep learning and trains a network on randomly aberrated radio frequency (RF) data, with an adaptive mixed loss function that combines both B-mode and RF data.</li>
<li>results: The proposed method achieves optimal performance and the authors publicly release a dataset of 161,701 single plane-wave images (RF data) to mitigate the data scarcity problem in the development of deep learning-based techniques for phase aberration correction.Here is the Chinese translation of the three key information points:</li>
<li>for: 本研究旨在无需基准数据 correction  Ultrasound imaging 中的相位扭曲问题。</li>
<li>methods: 提议的方法使用深度学习，并将网络训练在randomly 扭曲的 radio frequency (RF) 数据上，使用适应混合损失函数，其中包括 B-mode 和 RF 数据。</li>
<li>results: 提议的方法实现了优化性能，并将161,701个单平波图像 (RF 数据) 公共发布，以解决深度学习基于 phase aberration correction 的数据不足问题。<details>
<summary>Abstract</summary>
One of the primary sources of suboptimal image quality in ultrasound imaging is phase aberration. It is caused by spatial changes in sound speed over a heterogeneous medium, which disturbs the transmitted waves and prevents coherent summation of echo signals. Obtaining non-aberrated ground truths in real-world scenarios can be extremely challenging, if not impossible. This challenge hinders training of deep learning-based techniques' performance due to the presence of domain shift between simulated and experimental data. Here, for the first time, we propose a deep learning-based method that does not require ground truth to correct the phase aberration problem, and as such, can be directly trained on real data. We train a network wherein both the input and target output are randomly aberrated radio frequency (RF) data. Moreover, we demonstrate that a conventional loss function such as mean square error is inadequate for training such a network to achieve optimal performance. Instead, we propose an adaptive mixed loss function that employs both B-mode and RF data, resulting in more efficient convergence and enhanced performance. Finally, we publicly release our dataset, including 161,701 single plane-wave images (RF data). This dataset serves to mitigate the data scarcity problem in the development of deep learning-based techniques for phase aberration correction.
</details>
<details>
<summary>摘要</summary>
一个主要导致不优化图像质量的因素在ultrasound imaging中是相位偏移。它是由空间上的 зву速变化所引起的，这会影响传输波的干扰和阻止了干扰的汇集。在实际场景中获得不受偏移影响的真实数据是极其困难，甚至不可能。这种挑战使得深度学习基于技术的性能受到域shift的影响，从而降低了训练的效果。在本文中，我们首次提出了一种不需要真实数据的深度学习基于方法，可以直接在实际数据上训练。我们训练了一个网络，其中输入和目标输出都是随机偏移的 radio frequency（RF）数据。此外，我们表明了使用mean square error（MSE）函数训练这种网络并不是最佳的选择，而是需要采用适应混合损失函数，以实现更高效的收敛和提高性能。最后，我们在网上发布了我们的数据集，包括161,701个单平面波图像（RF数据）。这个数据集可以减轻在深度学习基于技术的发展中数据缺乏问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/22/eess.IV_2023_08_22/" data-id="cllt9pryb009iol88413v2vor" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.LG_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T00:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.LG_2023_08_08/">cs.LG - 2023-08-08 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation"><a href="#TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation" class="headerlink" title="TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation"></a>TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10843">http://arxiv.org/abs/2308.10843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mireille Fares, Catherine Pelachaud, Nicolas Obin</li>
<li>for: 本文解决了让虚拟代表人物的行为特征风格转移到另一个代表人物中，保持行为的形态不变的挑战。</li>
<li>methods: 我们提出了一种基于多模态trasformer模型的TranSTYLer模型，可以将多模态讲话者的行为风格转移到目标讲话者中，同时保持行为的意思表达。</li>
<li>results: 我们的模型在PATS数据集上进行了训练，并在对seen和unseen风格进行了目标和主观评价，结果显示我们的模型在样式转移中超过了现有模型的性能。<details>
<summary>Abstract</summary>
This paper addresses the challenge of transferring the behavior expressivity style of a virtual agent to another one while preserving behaviors shape as they carry communicative meaning. Behavior expressivity style is viewed here as the qualitative properties of behaviors. We propose TranSTYLer, a multimodal transformer based model that synthesizes the multimodal behaviors of a source speaker with the style of a target speaker. We assume that behavior expressivity style is encoded across various modalities of communication, including text, speech, body gestures, and facial expressions. The model employs a style and content disentanglement schema to ensure that the transferred style does not interfere with the meaning conveyed by the source behaviors. Our approach eliminates the need for style labels and allows the generalization to styles that have not been seen during the training phase. We train our model on the PATS corpus, which we extended to include dialog acts and 2D facial landmarks. Objective and subjective evaluations show that our model outperforms state of the art models in style transfer for both seen and unseen styles during training. To tackle the issues of style and content leakage that may arise, we propose a methodology to assess the degree to which behavior and gestures associated with the target style are successfully transferred, while ensuring the preservation of the ones related to the source content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accurate-Explainable-and-Private-Models-Providing-Recourse-While-Minimizing-Training-Data-Leakage"><a href="#Accurate-Explainable-and-Private-Models-Providing-Recourse-While-Minimizing-Training-Data-Leakage" class="headerlink" title="Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage"></a>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04341">http://arxiv.org/abs/2308.04341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Catherine Huang, Chelse Swoopes, Christina Xiao, Jiaqi Ma, Himabindu Lakkaraju</li>
<li>for: 防止机器学习模型中的隐私泄露</li>
<li>methods: 使用差异隐私模型（DPM）和拉普拉斯回退（LR）两种方法来生成差异隐私的回退</li>
<li>results: 使用логистиック回归类ifier和实际世界和生成的数据集，发现DPM和LR方法可以减少对敌人的攻击，尤其是在低 False Positive Rate 下。当训练集大小充分时，我们发现LR方法能够很好地防止隐私泄露，同时保持模型和回退的准确率。<details>
<summary>Abstract</summary>
Machine learning models are increasingly utilized across impactful domains to predict individual outcomes. As such, many models provide algorithmic recourse to individuals who receive negative outcomes. However, recourse can be leveraged by adversaries to disclose private information. This work presents the first attempt at mitigating such attacks. We present two novel methods to generate differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR). Using logistic regression classifiers and real world and synthetic datasets, we find that DPM and LR perform well in reducing what an adversary can infer, especially at low FPR. When training dataset size is large enough, we find particular success in preventing privacy leakage while maintaining model and recourse accuracy with our novel LR method.
</details>
<details>
<summary>摘要</summary>
机器学习模型在影响各界预测个人结果的应用越来越普遍。因此，许多模型提供了算法性的纠正机制，以便对不良结果进行纠正。然而，这些纠正机制可能会被敌对者利用，泄露private信息。这项工作首次介绍了纠正攻击的防范方法。我们提出了两种新的敏感度保护纠正方法：敏感度保护模型（DPM）和拉普拉斯纠正（LR）。使用Logistic回归分类器和实际世界和 sintetic数据集，我们发现，DPM和LR在低False Positive Rate（FP）下具有良好的隐私保护性，特别是在训练数据集规模充分时。我们的LR方法在防止隐私泄露的同时保持模型和纠正精度的情况下表现出特别的成功。
</details></li>
</ul>
<hr>
<h2 id="RLHF-Blender-A-Configurable-Interactive-Interface-for-Learning-from-Diverse-Human-Feedback"><a href="#RLHF-Blender-A-Configurable-Interactive-Interface-for-Learning-from-Diverse-Human-Feedback" class="headerlink" title="RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback"></a>RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04332">http://arxiv.org/abs/2308.04332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yannick Metz, David Lindner, Raphaël Baur, Daniel Keim, Mennatallah El-Assady</li>
<li>for: 这篇论文旨在应用人工增强学习（RL）在实际应用中，并且从多种人类反馈中学习奖励模型，同时考虑人类因素的影响。</li>
<li>methods: 这篇论文提出了RLHF-Blender，一个可配置的交互式界面，用于从人类反馈中学习奖励模型。RLHF-Blender提供了一个模块化的实验框架和实现，使研究人员可以系统地研究人类反馈的性质和质量。</li>
<li>results: RLHF-Blender可以帮助研究人员系统地探索不同类型的人类反馈，包括示例、排名、比较和自然语言指令，以及考虑人类因素的影响。RLHF-Blender还提供了一些具体的研究机会，详细信息请参阅<a target="_blank" rel="noopener" href="https://rlhfblender.info/">https://rlhfblender.info/</a>.<details>
<summary>Abstract</summary>
To use reinforcement learning from human feedback (RLHF) in practical applications, it is crucial to learn reward models from diverse sources of human feedback and to consider human factors involved in providing feedback of different types. However, the systematic study of learning from diverse types of feedback is held back by limited standardized tooling available to researchers. To bridge this gap, we propose RLHF-Blender, a configurable, interactive interface for learning from human feedback. RLHF-Blender provides a modular experimentation framework and implementation that enables researchers to systematically investigate the properties and qualities of human feedback for reward learning. The system facilitates the exploration of various feedback types, including demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness. We discuss a set of concrete research opportunities enabled by RLHF-Blender. More information is available at https://rlhfblender.info/.
</details>
<details>
<summary>摘要</summary>
为了在实际应用中使用人类反馈学习（RLHF），必须从多种人类反馈来学习奖励模型，并考虑人类提供反馈的因素。然而，实际研究从多种反馈类型中学习的系统atic study 受到了研究人员的限制。为了bridging这个差距，我们提议RLHF-Blender，一个可配置的交互式界面，用于学习人类反馈。RLHF-Blender提供了一个可组合的实验框架和实现，帮助研究人员系统地 investigate人类反馈的性质和质量，以及人类因素对其效果的影响。系统支持 exploration多种反馈类型，包括示例、排名、比较和自然语言指令，以及考虑人类因素对其效果的研究。我们介绍了RLHF-Blender启发的具体研究机会。更多信息请访问https://rlhfblender.info/.
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs"><a href="#Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs" class="headerlink" title="Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs"></a>Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04314">http://arxiv.org/abs/2308.04314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yang, Xuchuang Wang, Mohammad Hajiesmaili, Lijun Zhang, John C. S. Lui, Don Towsley</li>
<li>for: 这个研究旨在开发多代理多臂枪击游戏中的合作多代理算法，以实现最佳的集体和个人后悔，并且将通信成本降到最低。</li>
<li>methods: 这篇论文使用了两种方法：领导者-追随者和完全分布式算法。这些方法都能够实现集体后悔的最佳后悔，但是领导者-追随者算法对个人后悔不够优秀，而完全分布式算法则对通信成本不够优秀。</li>
<li>results: 这篇论文提出了一个简单 yet有效的通信策略，并将其整合到一个学习算法中，以实现最佳的个人后悔和常规通信成本。<details>
<summary>Abstract</summary>
Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Model-Inversion-Eavesdropping-Attack-in-Semantic-Communication-Systems"><a href="#The-Model-Inversion-Eavesdropping-Attack-in-Semantic-Communication-Systems" class="headerlink" title="The Model Inversion Eavesdropping Attack in Semantic Communication Systems"></a>The Model Inversion Eavesdropping Attack in Semantic Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04304">http://arxiv.org/abs/2308.04304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Chen, Qianqian Yang, Zhiguo Shi, Jiming Chen</li>
<li>for: 本研究探讨了 semantic communication 系统中的隐私泄露问题，并提出了一种基于 random permutation 和 substitution 的防御方法来解决这问题。</li>
<li>methods: 本研究使用了 model inversion eavesdropping attack (MIEA) 来攻击 semantic communication 系统，并考虑了 white-box 和 black-box 两种设定。</li>
<li>results: 实验结果表明，提出的防御方法可以有效防止 MIEA，并且在不同的 channel conditions 下可以 obtaint 高质量的重建结果。<details>
<summary>Abstract</summary>
In recent years, semantic communication has been a popular research topic for its superiority in communication efficiency. As semantic communication relies on deep learning to extract meaning from raw messages, it is vulnerable to attacks targeting deep learning models. In this paper, we introduce the model inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in the semantic communication system. In MIEA, the attacker first eavesdrops the signal being transmitted by the semantic communication system and then performs model inversion attack to reconstruct the raw message, where both the white-box and black-box settings are considered. Evaluation results show that MIEA can successfully reconstruct the raw message with good quality under different channel conditions. We then propose a defense method based on random permutation and substitution to defend against MIEA in order to achieve secure semantic communication. Our experimental results demonstrate the effectiveness of the proposed defense method in preventing MIEA.
</details>
<details>
<summary>摘要</summary>
现在的几年，semantic communication在通信效率方面的研究非常流行，因为它可以通过深度学习提取消息的意义来提高通信效率。然而，由于semantic communication依赖于深度学习模型，因此它是攻击目标。在这篇论文中，我们介绍了模型反向窃听攻击（MIEA），以探索 semantic communication系统中隐私泄露的风险。在MIEA中，攻击者首先监听 semantic communication系统传输的信号，然后通过模型反向攻击来重construct原始消息，包括白盒和黑盒两种设置。我们的评估结果表明，MIEA可以在不同的通信频率下成功重construct原始消息，并且可以在不同的通信条件下保持高质量。我们then propose了一种基于随机排序和替换的防御方法，以防止MIEA。我们的实验结果表明，我们的防御方法可以有效防止MIEA，以实现安全的semantic communication。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor"><a href="#Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor" class="headerlink" title="Comparative Analysis of the wav2vec 2.0 Feature Extractor"></a>Comparative Analysis of the wav2vec 2.0 Feature Extractor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04286">http://arxiv.org/abs/2308.04286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Vieting, Ralf Schlüter, Hermann Ney</li>
<li>for:  This paper aims to evaluate the capability of neural raw waveform feature extractors (FEs) in replacing standard feature extraction methods in a connectionist temporal classification (CTC) automatic speech recognition (ASR) model, and to compare it with an alternative neural FE.</li>
<li>methods:  The paper uses a convolutional FE, which operates directly on the speech waveform, and a set of bandpass filters to analyze the learned filters and the most important information for the ASR system.</li>
<li>results:  The paper shows that both the neural raw waveform FE and the alternative neural FE are competitive with traditional FEs on the LibriSpeech benchmark, and analyzes the effect of the individual components. The paper also shows that the most important information for the ASR system is obtained by a set of bandpass filters.<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) systems typically use handcrafted feature extraction pipelines. To avoid their inherent information loss and to achieve more consistent modeling from speech to transcribed text, neural raw waveform feature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model, which has recently gained large popularity, uses a convolutional FE which operates directly on the speech waveform. However, it is not yet studied extensively in the literature. In this work, we study its capability to replace the standard feature extraction methods in a connectionist temporal classification (CTC) ASR model and compare it to an alternative neural FE. We show that both are competitive with traditional FEs on the LibriSpeech benchmark and analyze the effect of the individual components. Furthermore, we analyze the learned filters and show that the most important information for the ASR system is obtained by a set of bandpass filters.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）系统通常使用手工设计的特征提取管道。以避免它们的内在信息损失并实现更一致的模型化从语音到转录文本，神经原始波形特征提取器（FE）是一种吸引人的方法。另外，最近广受欢迎的wav2vec 2.0模型使用了一种卷积 convolutional FE，该模型直接操作语音波形。然而，它在文献中还没有得到广泛的研究。在这个工作中，我们研究了它是否可以取代标准特征提取方法在一个连接主义时间分类（CTC） ASR 模型中，并与一个 alternativa neural FE 进行比较。我们发现两者都能够与传统的特征提取方法竞争在 LibriSpeech benchmark 上，并分析了各个组件的效果。此外，我们还分析了学习的滤波器，发现最重要的信息对 ASR 系统来说是由一组带通频滤波器提取出来的。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning"><a href="#In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning" class="headerlink" title="In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning"></a>In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04275">http://arxiv.org/abs/2308.04275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xhan77/in-context-alignment">https://github.com/xhan77/in-context-alignment</a></li>
<li>paper_authors: Xiaochuang Han</li>
<li>for: 这个论文是关于在运行时进行匹配的研究，即使没有任何细化调教。</li>
<li>methods: 作者使用了一个名为Llama-2的预训练语言模型，并通过在对话式指令下提取示例来进行匹配。</li>
<li>results: 结果显示，在没有改变模型参数的情况下，通过在上下文中学习进行匹配，可以使得 vanilla 语言模型与 OpenAI 提供的 text-davinci-003 模型相当，并且比直接提示的方法提高了7倍的赢利率。<details>
<summary>Abstract</summary>
In this note, we explore inference-time alignment through in-context learning. We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions. Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning.
</details>
<details>
<summary>摘要</summary>
在这份笔记中，我们探讨了在上下文学习中进行推理时的对齐。我们考虑了未经任何精度调整的语言模型Llama-2，并在模型被提示按照带ialog式指令时获取了9个示例对齐例。与直接提示相比，无需更改模型参数的上下文对齐导致了与文本-达梦系统OpenAI的模型003相比的7倍增加赢利率，使得vanilla语言模型与对齐调整相当。
</details></li>
</ul>
<hr>
<h2 id="Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey"><a href="#Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey" class="headerlink" title="Teacher-Student Architecture for Knowledge Distillation: A Survey"></a>Teacher-Student Architecture for Knowledge Distillation: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04268">http://arxiv.org/abs/2308.04268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengming Hu, Xuan Li, Dan Liu, Haolun Wu, Xi Chen, Ju Wang, Xue Liu</li>
<li>for: 这篇论文的目的是对于知识传递（Knowledge Distillation，KD）领域的研究和发展，特别是关于多个知识传递目标的教师生成架构。</li>
<li>methods: 这篇论文使用了教师生成架构，包括知识传递、知识增强、知识适应和知识压缩等多种知识传递目标。它还使用了各种学习算法和有效的传递方案。</li>
<li>results: 这篇论文总结了现有的教师生成架构和学习算法，并评估了它们在多个知识传递目标上的性能。它还概述了现有的应用案例，包括分类、识别、生成、排名和回归等多种应用。<details>
<summary>Abstract</summary>
Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. This survey presents an introduction to various knowledge representations and their corresponding optimization objectives. Additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes. This survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. Lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. Through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives.
</details>
<details>
<summary>摘要</summary>
although deep neural networks (DNNs) have shown strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. to tackle this issue, teacher-student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. recently, teacher-student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. with the help of teacher-student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. different from existing KD surveys that primarily focus on knowledge compression, this survey first explores teacher-student architectures across multiple distillation objectives. this survey presents an introduction to various knowledge representations and their corresponding optimization objectives. additionally, we provide a systematic overview of teacher-student architectures with representative learning algorithms and effective distillation schemes. this survey also summarizes recent applications of teacher-student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying teacher-student architectures on various distillation objectives.
</details></li>
</ul>
<hr>
<h2 id="BarlowRL-Barlow-Twins-for-Data-Efficient-Reinforcement-Learning"><a href="#BarlowRL-Barlow-Twins-for-Data-Efficient-Reinforcement-Learning" class="headerlink" title="BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning"></a>BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04263">http://arxiv.org/abs/2308.04263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omer Veysel Cagatan</li>
<li>for: 这个论文是为了提出一种数据效果的强化学习代理人BarlowRL，该代理人结合Barlow Twins自动学习框架和DER数据效果雨bow算法。</li>
<li>methods: BarlowRL使用了Barlow Twins自动学习框架和DER算法，以提高数据效果和避免维度塌陷。</li>
<li>results: BarlowRL在Atari 100k测试 benchmark 上表现出色，超过了DER和其对应的对比算法CURL。 BarlowRL能够充分利用均匀分布的状态表示，从而达到了很高的性能。<details>
<summary>Abstract</summary>
This paper introduces BarlowRL, a data-efficient reinforcement learning agent that combines the Barlow Twins self-supervised learning framework with DER (Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its contrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids dimensional collapse by enforcing information spread to the whole space. This helps RL algorithms to utilize uniformly spread state representation that eventually results in a remarkable performance. The integration of Barlow Twins with DER enhances data efficiency and achieves superior performance in the RL tasks. BarlowRL demonstrates the potential of incorporating self-supervised learning techniques to improve RL algorithms.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了BarlowRL，一种数据效率的 reinforcement learning代理人，它将Barlow Twins自我超vised学习框架和DER（数据效率雨bow）算法相结合。BarlowRL在Atari 100k测试 benchmark 上表现出色，比DER和其它对比算法 CURL 更高。BarlowRL通过保证信息在全空间传播来避免维度坍缩，从而使RL算法可以利用 uniformly 分布的状态表示，最终导致了非常出色的性能。将Barlow Twins与DER相结合可以提高数据效率，并在RL任务中实现优秀表现。BarlowRL表明了在RL算法中 интеGRating自我超vised学习技术的潜力。
</details></li>
</ul>
<hr>
<h2 id="SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction"><a href="#SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction" class="headerlink" title="SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction"></a>SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04262">http://arxiv.org/abs/2308.04262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer">https://github.com/rahul-gs-16/sdlformer</a></li>
<li>paper_authors: Rahul G. S., Sriprabha Ramnarayanan, Mohammad Al Fahim, Keerthi Ram, Preejith S. P, Mohanasankar Sivaprakasam</li>
<li>for: 本研究旨在提出一种基于窗口变换器的快速MRI图像重建方法，以提高MRI图像重建的计算效率。</li>
<li>methods: 该方法使用了窗口变换器网络，并将它与增强 distant neighborhood pixel relationship 的层 dilated attention 机制和depth-wise convolutions 结合在一起。</li>
<li>results: 对多栅积MRI加速的多栅积PD、PDFS和T2对照图进行了广泛的实验，并与其他重建架构和平行领域自我超vised学习基准进行了比较。结果显示，提出的方法在PSNR和SSIM两个指标上具有1.40dB和0.028的提升差。<details>
<summary>Abstract</summary>
Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. The proposed model is trained in a self-supervised manner. We perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. We compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. Results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. The code is available at https://github.com/rahul-gs-16/sdlformer.git
</details>
<details>
<summary>摘要</summary>
transformers 已经成为了卷积神经网络的可行 альтернатив，因为它们可以学习图像空间中的非本地区关系。 transformers 的归一化机制使得它们可以捕捉图像中的长距离依赖关系，这可能是加速 MRI 图像重建的潜在优点。 despite its 计算效率，窗口基于的 transformers 受限于图像窗口范围内的依赖关系。 we propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. the proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. the proposed model is trained in a self-supervised manner. we perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. we compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. the code is available at https://github.com/rahul-gs-16/sdlformer.git.
</details></li>
</ul>
<hr>
<h2 id="Advancing-Natural-Language-Based-Audio-Retrieval-with-PaSST-and-Large-Audio-Caption-Data-Sets"><a href="#Advancing-Natural-Language-Based-Audio-Retrieval-with-PaSST-and-Large-Audio-Caption-Data-Sets" class="headerlink" title="Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets"></a>Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04258">http://arxiv.org/abs/2308.04258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optimusprimus/dcase2023_task6b">https://github.com/optimusprimus/dcase2023_task6b</a></li>
<li>paper_authors: Paul Primus, Khaled Koutini, Gerhard Widmer</li>
<li>for: 这篇论文旨在提出一种基于预训练文本和 спектogram transformer 的文本至声音回 recuperation 系统。</li>
<li>methods: 该方法将录音和文本描述 proyect 到一个共享的声音-caption 空间中，使相关的不同模式的示例在空间上相互靠近。通过系统atic分析，我们查看每个系统组件对回 recuperation性能的影响。</li>
<li>results: 我们发现两个关键组件对回 recuperation性能具有关键作用：基于自我注意力的声音编码器为声音嵌入，以及在预训练阶段使用additional human-generated和 sintetic 数据集。我们进一步尝试了在 ClothoV2 描述中添加可用的关键词，但这只导致了微妙的改进。我们的系统在 2023 年 DCASE 挑战中 Ranking 第一，并在 ClothoV2  bencmark 上比当前状态的艺术高5.6 pp. mAP@10。<details>
<summary>Abstract</summary>
This work presents a text-to-audio-retrieval system based on pre-trained text and spectrogram transformers. Our method projects recordings and textual descriptions into a shared audio-caption space in which related examples from different modalities are close. Through a systematic analysis, we examine how each component of the system influences retrieval performance. As a result, we identify two key components that play a crucial role in driving performance: the self-attention-based audio encoder for audio embedding and the utilization of additional human-generated and synthetic data sets during pre-training. We further experimented with augmenting ClothoV2 captions with available keywords to increase their variety; however, this only led to marginal improvements. Our system ranked first in the 2023's DCASE Challenge, and it outperforms the current state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.
</details>
<details>
<summary>摘要</summary>
Note:* "pre-trained text and spectrogram transformers" refers to the use of pre-trained language models and audio processing models to improve the performance of the text-to-audio retrieval system.* "self-attention-based audio encoder" refers to a specific type of audio encoding method that uses self-attention mechanisms to extract relevant features from the audio data.* "additional human-generated and synthetic data sets" refers to the use of additional data sets that are generated by humans or by algorithms to improve the performance of the system.* "ClothoV2 captions" refers to a specific dataset of textual descriptions that are used to evaluate the performance of the text-to-audio retrieval system.* "mAP@10" refers to the mean average precision at the 10th position, which is a common evaluation metric for text-to-audio retrieval systems.
</details></li>
</ul>
<hr>
<h2 id="Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction"><a href="#Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction" class="headerlink" title="Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction"></a>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04237">http://arxiv.org/abs/2308.04237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Osvaldo Simeone</li>
<li>for: 这个论文主要探讨了一种名为联邦兼容预测（Federated Conformal Prediction，简称FCP）的技术，该技术利用设备到服务器的通信来提高服务器的决策质量。</li>
<li>methods: 这个论文提出了一种新的协议，名为无线联邦兼容预测（WFCP），它基于类型基本多访问（TBMA）和一种新的量化更正策略。WFCP提供了正式的可靠性保证，包括预测集的覆盖率。</li>
<li>results: 数据分析表明，WFCP在有限通信资源和大量设备情况下具有显著优势，特别是在对比数字实现的现有联邦CP方案时。<details>
<summary>Abstract</summary>
Consider a setting in which devices and a server share a pre-trained model. The server wishes to make an inference on a new input given the model. Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel. If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server? Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.
</details>
<details>
<summary>摘要</summary>
假设设备和服务器共享预训练模型。服务器想要对新输入进行推断。设备有访问未使用过训练数据的权限，可以与服务器通过共享的无线通信chnnel进行通信。如果设备没有访问新输入，是否可以通过设备到服务器的交流提高服务器的推断决策质量？latest work introduce federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.
</details></li>
</ul>
<hr>
<h2 id="OpinionConv-Conversational-Product-Search-with-Grounded-Opinions"><a href="#OpinionConv-Conversational-Product-Search-with-Grounded-Opinions" class="headerlink" title="OpinionConv: Conversational Product Search with Grounded Opinions"></a>OpinionConv: Conversational Product Search with Grounded Opinions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04226">http://arxiv.org/abs/2308.04226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vahid Sadiri Javadi, Martin Potthast, Lucie Flek</li>
<li>for: 本研究旨在帮助语言模型在对话中更加真实地表达用户的主观意见，以便更好地帮助用户做出决策。</li>
<li>methods: 本研究使用产品评论作为实际用户的主观意见的来源，并通过一种新的对话模型来 simulate sales conversations。</li>
<li>results: 研究发现，使用产品评论来生成对话可以提供更加真实的用户意见，并且用户认为这些意见具有决策价值。<details>
<summary>Abstract</summary>
When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在寻找产品时，其他人的意见具有重要的指导作用，可以提供有价值的信息。这也是销售对话中的事实，客户和销售助手交换产品的信息和意见。然而，用语言模型训练销售对话是复杂的，因为语言模型缺乏真实的世界经验。我们解决这个问题，利用产品评论作为产品意见的丰富源，将对话AI根据真实的主观故事进行定制。通过我们的 OpinionConv，我们开发了首个用于模拟销售对话的对话AI。为验证生成的对话，我们进行了多个用户研究，显示生成的意见被视为真实。我们的评估人也证实了意见作为决策基础的重要性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models"><a href="#Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models" class="headerlink" title="Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models"></a>Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04220">http://arxiv.org/abs/2308.04220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Efimia Panagiotaki, Daniele De Martini, Lars Kunze</li>
<li>for: 这 paper aims to enhance the explainability of Graph Neural Network (GNN)-based models by applying semantic attention and establishing a correlation between predicted feature-importance weights and model accuracy.</li>
<li>methods: 该 paper introduces semantically-informed perturbations and utilizes attention mechanisms to provide feature-based explanations for GNN predictions. It extends existing attention-based graph-explainability methods by analyzing the behavior of predicted attention-weights distribution in correlation with model accuracy.</li>
<li>results: 通过应用这些方法， paper successfully identifies key semantic classes that contribute to enhanced performance and generates reliable post-hoc semantic explanations for the GNN model.<details>
<summary>Abstract</summary>
In this work, we propose a methodology for investigating the application of semantic attention to enhance the explainability of Graph Neural Network (GNN)-based models, introducing semantically-informed perturbations and establishing a correlation between predicted feature-importance weights and model accuracy. Graph Deep Learning (GDL) has emerged as a promising field for tasks like scene interpretation, leveraging flexible graph structures to concisely describe complex features and relationships. As traditional explainability methods used in eXplainable AI (XAI) cannot be directly applied to such structures, graph-specific approaches are introduced. Attention mechanisms have demonstrated their efficacy in estimating the importance of input features in deep learning models and thus have been previously employed to provide feature-based explanations for GNN predictions. Building upon these insights, we extend existing attention-based graph-explainability methods investigating the use of attention weights as importance indicators of semantically sorted feature sets. Through analysing the behaviour of predicted attention-weights distribution in correlation with model accuracy, we gain valuable insights into feature importance with respect to the behaviour of the GNN model. We apply our methodology to a lidar pointcloud estimation model successfully identifying key semantic classes that contribute to enhanced performance effectively generating reliable post-hoc semantic explanations.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种方法来使用semantic attention提高graph neural network（GNN）模型的解释性，通过引入semantically-informed的干扰和建立predicted feature-importance权重和模型精度之间的相关性。 Graph Deep Learning（GDL）已经成为一个有前途的领域，用于场景理解等任务，利用flexible graph结构 concisely describe复杂的特征和关系。 Traditional explainability方法在XAI中无法直接应用于这些结构，因此需要graph-specific approach。 Attention机制已经在深度学习模型中证明其能力 estimating输入特征的重要性，因此在GNN预测中也被使用来提供基于特征的解释。 在这些基础上，我们进一步扩展了现有的注意力基本graph-explainability方法， investigate使用注意力权重作为semantic sorted feature set的重要性指标。 通过分析预测注意力权重分布与模型精度之间的相关性，我们获得了对feature importance的重要性见解，并且可以有效地生成post-hoc semantic explanation。 我们应用了我们的方法ology lidar pointcloud estimation模型，成功地标识了改进性的 semantic classes，从而生成了可靠的后期semantic explanation。
</details></li>
</ul>
<hr>
<h2 id="Varying-coefficients-for-regional-quantile-via-KNN-based-LASSO-with-applications-to-health-outcome-study"><a href="#Varying-coefficients-for-regional-quantile-via-KNN-based-LASSO-with-applications-to-health-outcome-study" class="headerlink" title="Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study"></a>Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04212">http://arxiv.org/abs/2308.04212</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/younghhk/software">https://github.com/younghhk/software</a></li>
<li>paper_authors: Seyoung Park, Eun Ryung Lee, Hyokyoung G. Hong</li>
<li>for: 本研究旨在建立一种动态模型，描述健康结果和风险因素之间的关系，并考虑年龄的时间变化。</li>
<li>methods: 本研究使用 varying-coefficients (VC) 区域量化回归，结合 K-nearest neighbors (KNN) 融合lasso，以捕捉年龄的时间变化效应。</li>
<li>results: 研究结果表明，提议的方法能够准确捕捉健康结果和风险因素之间的复杂年龄dependent关系。<details>
<summary>Abstract</summary>
Health outcomes, such as body mass index and cholesterol levels, are known to be dependent on age and exhibit varying effects with their associated risk factors. In this paper, we propose a novel framework for dynamic modeling of the associations between health outcomes and risk factors using varying-coefficients (VC) regional quantile regression via K-nearest neighbors (KNN) fused Lasso, which captures the time-varying effects of age. The proposed method has strong theoretical properties, including a tight estimation error bound and the ability to detect exact clustered patterns under certain regularity conditions. To efficiently solve the resulting optimization problem, we develop an alternating direction method of multipliers (ADMM) algorithm. Our empirical results demonstrate the efficacy of the proposed method in capturing the complex age-dependent associations between health outcomes and their risk factors.
</details>
<details>
<summary>摘要</summary>
健康结果，如体重指数和胆固酶水平，与年龄存在相互关系，其影响因素的效果随着年龄的变化而变化。在这篇论文中，我们提出了一种新的动态模型，使用不同系数（VC）地域量规 regression via K-最近邻（KNN）混合lasso，以捕捉年龄的时间变化效应。我们的提议方法具有强制实现的理论属性，包括紧张估计误差 bound和在某些常数条件下检测精确的征性征 Patterns。为解决相应的优化问题，我们开发了一种分解方法 OF multipliers（ADMM）算法。我们的实验结果表明，我们的提议方法能够准确捕捉健康结果和其风险因素之间的复杂年龄相关性。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Sketching-for-Secure-Coded-Regression"><a href="#Iterative-Sketching-for-Secure-Coded-Regression" class="headerlink" title="Iterative Sketching for Secure Coded Regression"></a>Iterative Sketching for Secure Coded Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04185">http://arxiv.org/abs/2308.04185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neophytos Charalambides, Hessam Mahdavifar, Mert Pilanci, Alfred O. Hero III</li>
<li>for: 提高线性回归的速度，保证安全性。</li>
<li>methods: 利用随机抽取技术，改进异步系统中的延迟性。Specifically, 应用随机正交矩阵，并对块进行抽样，同时保护信息和降低回归问题的维度。</li>
<li>results: 实现了一种分布式iterative sketching方法，用于生成 $\ell_2$-子空间嵌入。此外，还对特殊情况下的随机化哈达姆变换进行推广，并讨论如何保护数据。<details>
<summary>Abstract</summary>
In this work, we propose methods for speeding up linear regression distributively, while ensuring security. We leverage randomized sketching techniques, and improve straggler resilience in asynchronous systems. Specifically, we apply a random orthonormal matrix and then subsample \textit{blocks}, to simultaneously secure the information and reduce the dimension of the regression problem. In our setup, the transformation corresponds to an encoded encryption in an \textit{approximate gradient coding scheme}, and the subsampling corresponds to the responses of the non-straggling workers; in a centralized coded computing network. This results in a distributive \textit{iterative sketching} approach for an $\ell_2$-subspace embedding, \textit{i.e.} a new sketch is considered at each iteration. We also focus on the special case of the \textit{Subsampled Randomized Hadamard Transform}, which we generalize to block sampling; and discuss how it can be modified in order to secure the data.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了加速线性回归的分布式方法，同时保证安全性。我们利用随机抽象技术，并改进异步系统中的延迟鲁棒性。具体来说，我们首先应用随机正交矩阵，然后对块进行抽样，以同时保护信息和减少回归问题的维度。在我们的设置中，这种变换对应于一种编码加密在一个 Approximate Gradient Coding Scheme 中，而抽样对应于非延迟工作者的响应；在中央coded computing网络中。这 führt zu a distributed iterative sketching approach for an $\ell_2$-subspace embedding, i.e., a new sketch is considered at each iteration.我们还专注于特殊情况下的 Subsampled Randomized Hadamard Transform，我们扩展了块抽样，并讨论了如何修改以保护数据。
</details></li>
</ul>
<hr>
<h2 id="Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”"><a href="#Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”" class="headerlink" title="Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”"></a>Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04180">http://arxiv.org/abs/2308.04180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlinardicyu/sud_study_different_eyes">https://github.com/mlinardicyu/sud_study_different_eyes</a></li>
<li>paper_authors: Bruno Machado Carneiro, Michele Linardi, Julien Longhi</li>
<li>for: 本研究探讨了在在线文本中分类和检测社会不CCE接受的语言（SUD）。</li>
<li>methods: 我们首先构建了一个包含多种不同在线来源的手动标注文本的新集合，以便测试现有的机器学习（ML）SUD检测解决方案中的通用性。</li>
<li>results: 我们发现，不同的注解模式可能会影响SUD学习，并提出了一些开放的挑战和研究方向。  Additionally, we provide several data insights that can support domain experts in the annotation task.<details>
<summary>Abstract</summary>
We study Socially Unacceptable Discourse (SUD) characterization and detection in online text. We first build and present a novel corpus that contains a large variety of manually annotated texts from different online sources used so far in state-of-the-art Machine learning (ML) SUD detection solutions. This global context allows us to test the generalization ability of SUD classifiers that acquire knowledge around the same SUD categories, but from different contexts. From this perspective, we can analyze how (possibly) different annotation modalities influence SUD learning by discussing open challenges and open research directions. We also provide several data insights which can support domain experts in the annotation task.
</details>
<details>
<summary>摘要</summary>
我们研究社会不可接受的语言（SUD）Characterization和检测在在线文本中。我们首先建立了一个新的 corpus，包含不同在线来源的手动标注的文本，这些文本在前一个 Machine learning（ML） SUD检测解决方案中使用过。这种全球背景允许我们测试SUD分类器在不同上下文中 acquire 知识的泛化能力。从这个角度来看，我们可以分析不同标注模式对 SUD 学习的影响，并讨论开放的挑战和未来研究方向。我们还提供了一些数据视角，可以支持领域专家在标注任务中。Note: "SUD" stands for "Socially Unacceptable Discourse" in English.
</details></li>
</ul>
<hr>
<h2 id="Dual-input-neural-networks-for-positional-sound-source-localization"><a href="#Dual-input-neural-networks-for-positional-sound-source-localization" class="headerlink" title="Dual input neural networks for positional sound source localization"></a>Dual input neural networks for positional sound source localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04169">http://arxiv.org/abs/2308.04169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/egrinstein/di_nn">https://github.com/egrinstein/di_nn</a></li>
<li>paper_authors: Eric Grinstein, Vincent W. Neo, Patrick A. Naylor</li>
<li>for: 本研究用于提高音频信号处理中Metadata的使用，以优化输出。</li>
<li>methods: 本研究提出了 dual input neural networks (DI-NNs) 作为一种简单 yet effective的方法，将多个感知器的 audio 信号和场景特性信息结合在一起，以优化音源位置估计。</li>
<li>results: 对于不同的难度和真实性水平的场景，DI-NNs 与基准方法（Least-Squares 方法和 Convolutional Recurrent Neural Network）进行比较，结果显示 DI-NNs 在实际录制数据集中表现出五倍于基准方法的Localization error 下降，并且与 CRNN 相比，有两倍的性能提升。<details>
<summary>Abstract</summary>
In many signal processing applications, metadata may be advantageously used in conjunction with a high dimensional signal to produce a desired output. In the case of classical Sound Source Localization (SSL) algorithms, information from a high dimensional, multichannel audio signals received by many distributed microphones is combined with information describing acoustic properties of the scene, such as the microphones' coordinates in space, to estimate the position of a sound source. We introduce Dual Input Neural Networks (DI-NNs) as a simple and effective way to model these two data types in a neural network. We train and evaluate our proposed DI-NN on scenarios of varying difficulty and realism and compare it against an alternative architecture, a classical Least-Squares (LS) method as well as a classical Convolutional Recurrent Neural Network (CRNN). Our results show that the DI-NN significantly outperforms the baselines, achieving a five times lower localization error than the LS method and two times lower than the CRNN in a test dataset of real recordings.
</details>
<details>
<summary>摘要</summary>
在许多信号处理应用中，元数据可以与高维信号结合使用，以生成所需的输出。在传统的Sound Source Localization（SSL）算法中，来自多个分布式麦克风的高维多通道音频信号和场景的听音性特征，如麦克风的空间坐标，被组合以估算声源的位置。我们介绍了双输入神经网络（DI-NN）作为一种简单而有效的方法，将这两种数据类型模型在神经网络中。我们在不同的难度和真实性水平上训练和评估我们的提议DI-NN，并与基准 Architecture，即经典的最小二乘法（LS）方法和经典的卷积回归神经网络（CRNN）进行比较。我们的结果表明，DI-NN在测试数据集中与LS方法和CRNN相比，显著地下降了5倍的地标错误，达到了2倍的CRNN水平。
</details></li>
</ul>
<hr>
<h2 id="Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness"><a href="#Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness" class="headerlink" title="Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness"></a>Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04137">http://arxiv.org/abs/2308.04137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael W. Spratling</li>
<li>for: The paper aims to evaluate the robustness of machine learning models, particularly deep neural networks, and to develop a more comprehensive benchmarking protocol for assessing their performance.</li>
<li>methods: The paper proposes using a wide range of different types of data to benchmark the performance of machine learning models, and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance.</li>
<li>results: The paper finds that current deep neural networks are extremely vulnerable to making mistakes on certain types of data, and that they are insecure as they can easily be fooled into making the wrong decisions. The results suggest that more comprehensive testing methods are needed to develop more robust machine learning models in the future.<details>
<summary>Abstract</summary>
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to produce state-of-the-art robustness, are extremely vulnerable to making mistakes on certain types of data. This means that such models will be unreliable in real-world scenarios where they may encounter data from many different domains, and that they are insecure as they can easily be fooled into making the wrong decisions. It is hoped that these results will motivate the wider adoption of more comprehensive testing methods that will, in turn, lead to the development of more robust machine learning methods in the future.   Code is available at: \url{https://codeberg.org/mwspratling/RobustnessEvaluation}
</details>
<details>
<summary>摘要</summary>
可靠且可靠的评估方法是机器学习模型的发展的必要首步。然而，当前的评估协议通常只使用有限种的测试数据来评估性能，而忽略其他类型的数据。例如，使用标准测试数据将不能评估机器学习器对未知类型的样本进行预测。相反，使用包含未知类型样本的数据进行测试将不能评估机器学习器对已知类型样本的预测。这篇文章提议使用多种不同类型的数据进行比较，并使用一个可以应用于所有数据类型的单一指标来生成一致的评估性能。使用这种标准可以发现，当前的深度神经网络，包括通过认为会生成状态的最佳Robustness训练方法，在某些类型的数据上表现出极高的敏感性。这意味着这些模型在实际世界中将是不可靠的，因为它们可能会遇到来自多个领域的数据，并且它们容易被骗到作出错误的决策。希望这些结果能够激励更广泛的测试方法的采用，以便在未来发展更加可靠的机器学习方法。Code可以在以下链接中找到：https://codeberg.org/mwspratling/RobustnessEvaluation
</details></li>
</ul>
<hr>
<h2 id="D-Score-A-Synapse-Inspired-Approach-for-Filter-Pruning"><a href="#D-Score-A-Synapse-Inspired-Approach-for-Filter-Pruning" class="headerlink" title="D-Score: A Synapse-Inspired Approach for Filter Pruning"></a>D-Score: A Synapse-Inspired Approach for Filter Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04470">http://arxiv.org/abs/2308.04470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doyoung Park, Jinsoo Kim, Jina Nam, Jooyoung Chang, Sang Min Park</li>
<li>for: 本研究旨在提出一种基于神经元系统的筛选方法，用于降低卷积神经网络（CNN）中不重要的筛选器的计算量。</li>
<li>methods: 该方法基于神经科学的视角，提出了一种名为动态分数（D-Score）的筛选器分数分析方法，该方法分析了每个筛选器中独立重要的正向和负向权重，并将其分配分数。</li>
<li>results: 实验结果表明，使用该方法可以在CIFAR-10和ImageNet datasets上减少显著的计算量和参数，而无需导致准确率下降。<details>
<summary>Abstract</summary>
This paper introduces a new aspect for determining the rank of the unimportant filters for filter pruning on convolutional neural networks (CNNs). In the human synaptic system, there are two important channels known as excitatory and inhibitory neurotransmitters that transmit a signal from a neuron to a cell. Adopting the neuroscientific perspective, we propose a synapse-inspired filter pruning method, namely Dynamic Score (D-Score). D-Score analyzes the independent importance of positive and negative weights in the filters and ranks the independent importance by assigning scores. Filters having low overall scores, and thus low impact on the accuracy of neural networks are pruned. The experimental results on CIFAR-10 and ImageNet datasets demonstrate the effectiveness of our proposed method by reducing notable amounts of FLOPs and Params without significant Acc. Drop.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation"><a href="#OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation" class="headerlink" title="OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation"></a>OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04126">http://arxiv.org/abs/2308.04126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyang Yu, Shihao Wang, Yuan Fang, Wangpeng An</li>
<li>for: 这篇论文旨在提出一种新的多模态数据融合和无限数据生成方法，以协调和简化不同数据模式之间的交互。</li>
<li>methods: 该方法使用了多种先进算法，包括视频&#x2F;图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、Recognize Anything Model（RAM）和对象跟踪。</li>
<li>results: 该方法可以识别6400种类型的对象，显著扩大了视觉信息的谱度。它将多种模式融合起来，促进不同模式之间的互助和cross-模式数据校正。最终输出将每个视频输入转化为详细的时间序列文档，使得视频更容易被大语言模型处理。<details>
<summary>Abstract</summary>
This paper presents OmniDataComposer, an innovative approach for multimodal data fusion and unlimited data generation with an intent to refine and uncomplicate interplay among diverse data modalities. Coming to the core breakthrough, it introduces a cohesive data structure proficient in processing and merging multimodal data inputs, which include video, audio, and text.   Our crafted algorithm leverages advancements across multiple operations such as video/image caption extraction, dense caption extraction, Automatic Speech Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything Model(RAM), and object tracking. OmniDataComposer is capable of identifying over 6400 categories of objects, substantially broadening the spectrum of visual information. It amalgamates these diverse modalities, promoting reciprocal enhancement among modalities and facilitating cross-modal data correction. \textbf{The final output metamorphoses each video input into an elaborate sequential document}, virtually transmuting videos into thorough narratives, making them easier to be processed by large language models.   Future prospects include optimizing datasets for each modality to encourage unlimited data generation. This robust base will offer priceless insights to models like ChatGPT, enabling them to create higher quality datasets for video captioning and easing question-answering tasks based on video content. OmniDataComposer inaugurates a new stage in multimodal learning, imparting enormous potential for augmenting AI's understanding and generation of complex, real-world data.
</details>
<details>
<summary>摘要</summary>
The final output transforms each video input into an elaborate sequential document, virtually transmuting videos into thorough narratives that can be easily processed by large language models. Future prospects include optimizing datasets for each modality to encourage unlimited data generation, which will offer valuable insights to models like ChatGPT and ease question-answering tasks based on video content.OmniDataComposer opens a new stage in multimodal learning, possessing enormous potential for augmenting AI's understanding and generation of complex, real-world data. With the ability to identify over 6400 categories of objects, the algorithm significantly broadens the spectrum of visual information. By merging diverse modalities and facilitating cross-modal data correction, OmniDataComposer promotes reciprocal enhancement among modalities, leading to more accurate and comprehensive data analysis.
</details></li>
</ul>
<hr>
<h2 id="Constructing-Custom-Thermodynamics-Using-Deep-Learning"><a href="#Constructing-Custom-Thermodynamics-Using-Deep-Learning" class="headerlink" title="Constructing Custom Thermodynamics Using Deep Learning"></a>Constructing Custom Thermodynamics Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04119">http://arxiv.org/abs/2308.04119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoli Chen, Beatrice W. Soh, Zi-En Ooi, Eleonore Vissol-Gaudin, Haijun Yu, Kostya S. Novoselov, Kedar Hippalgaonkar, Qianxiao Li</li>
<li>for: 这项研究旨在开发一种基于总体热动力学原理的自动化科学发现平台，用于研究复杂动态系统，以提高科学家对这些系统的理解和预测能力。</li>
<li>methods: 该平台基于一种总体热动力学原理来学习微观轨迹的 макро观动力学描述，并同时构建了减少的热动力学坐标系和解释动力学。</li>
<li>results: 通过对长聚合物链的延伸行为进行理论和实验研究，该方法学习了三个可解释的热动力学坐标，并构建了聚合物延伸的动力学景观，包括稳定和过渡态的标识以及延伸速率的控制。此外，该方法还应用于了不同领域的另一个问题——构建空间传染疫苗的macroscopic动力学，展示了该方法的广泛科学和技术应用前景。<details>
<summary>Abstract</summary>
One of the most exciting applications of AI is automated scientific discovery based on previously amassed data, coupled with restrictions provided by the known physical principles, including symmetries and conservation laws. Such automated hypothesis creation and verification can assist scientists in studying complex phenomena, where traditional physical intuition may fail. Of particular importance are complex dynamic systems where their time evolution is strongly influenced by varying external parameters. In this paper we develop a platform based on a generalised Onsager principle to learn macroscopic dynamical descriptions of arbitrary stochastic dissipative systems directly from observations of their microscopic trajectories. We focus on systems whose complexity and sheer sizes render complete microscopic description impractical, and constructing theoretical macroscopic models requires extensive domain knowledge or trial-and-error. Our machine learning approach addresses this by simultaneously constructing reduced thermodynamic coordinates and interpreting the dynamics on these coordinates. We demonstrate our method by studying theoretically and validating experimentally, the stretching of long polymer chains in an externally applied field. Specifically, we learn three interpretable thermodynamic coordinates and build a dynamical landscape of polymer stretching, including (1) the identification of stable and transition states and (2) the control of the stretching rate. We further demonstrate the universality of our approach by applying it to an unrelated problem in a different domain: constructing macroscopic dynamics for spatial epidemics, showing that our method addresses wide scientific and technological applications.
</details>
<details>
<summary>摘要</summary>
In this paper, we develop a platform based on a generalised Onsager principle to learn macroscopic dynamical descriptions of arbitrary stochastic dissipative systems directly from observations of their microscopic trajectories. We focus on systems whose complexity and sheer sizes make complete microscopic description impractical, and constructing theoretical macroscopic models requires extensive domain knowledge or trial-and-error. Our machine learning approach addresses this by simultaneously constructing reduced thermodynamic coordinates and interpreting the dynamics on these coordinates.We demonstrate our method by studying theoretically and validating experimentally the stretching of long polymer chains in an externally applied field. Specifically, we learn three interpretable thermodynamic coordinates and build a dynamical landscape of polymer stretching, including the identification of stable and transition states and the control of the stretching rate. We further demonstrate the universality of our approach by applying it to an unrelated problem in a different domain: constructing macroscopic dynamics for spatial epidemics, showing that our method addresses wide scientific and technological applications.
</details></li>
</ul>
<hr>
<h2 id="PTransIPs-Identification-of-phosphorylation-sites-based-on-protein-pretrained-language-model-and-Transformer"><a href="#PTransIPs-Identification-of-phosphorylation-sites-based-on-protein-pretrained-language-model-and-Transformer" class="headerlink" title="PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer"></a>PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05115">http://arxiv.org/abs/2308.05115</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/statxzy7/ptransips">https://github.com/statxzy7/ptransips</a></li>
<li>paper_authors: Ziyang Xu, Haitian Zhong<br>for:这个研究旨在开发一个新的深度学习模型，用于识别蛋白质中的磷酸化位点。methods:这个模型使用了深度学习的卷积神经网络和传统的Transformer模型，并且使用了大量预训练的蛋白质模型嵌入。results:实验结果显示，这个模型比现有的State-of-the-art方法高效，具有AUROC值为0.9232和0.9660 для识别磷酸化S&#x2F;T和Y位点。<details>
<summary>Abstract</summary>
Phosphorylation is central to numerous fundamental cellular processes, influencing the onset and progression of a variety of diseases. The correct identification of these phosphorylation sites is of great importance to unravel the intricate molecular mechanisms within cells and during viral infections, potentially leading to the discovery of new therapeutic targets. In this study, we introduce PTransIPs, a novel deep learning model for the identification of phosphorylation sites. PTransIPs treat amino acids within protein sequences as words, extracting unique encodings based on their type and sequential position. The model also incorporates embeddings from large pretrained protein models as additional data inputs. PTransIPS is further trained on a combination model of convolutional neural network with residual connections and Transformer model equipped with multi-head attention mechanisms. At last, the model outputs classification results through a fully connected layer. The results of independent testing reveal that PTransIPs outperforms existing state-of-the-art(SOTA) methods, achieving AUROCs of 0.9232 and 0.9660 for identifying phosphorylated S/T and Y sites respectively. In addition, ablation studies prove that pretrained model embeddings contribute to the performance of PTransIPs. Furthermore, PTransIPs has interpretable amino acid preference, visible training process and shows generalizability on other bioactivity classification tasks. To facilitate usage, our code and data are publicly accessible at \url{https://github.com/StatXzy7/PTransIPs}.
</details>
<details>
<summary>摘要</summary>
“磷酸化是细胞内多种基本生物过程的中心，影响疾病的发生和进程。正确识别这些磷酸化位点非常重要，以解释细胞内分子机制，并在病毒感染时发挥作用，可能导致新的药 targets 的发现。在这项研究中，我们介绍 PTransIPs，一种新的深度学习模型，用于磷酸化位点的识别。 PTransIPs 将蛋白质序列中的氨基酸看作为单词，提取唯一的编码，基于其类型和顺序位置。模型还使用大型预训练蛋白质模型的嵌入。 PTransIPS 通过将 convolutional neural network 与 residual connections 和 transformer 模型组合，并在其中添加多头注意机制。最后，模型输出分类结果通过完全连接层。独立测试结果显示，PTransIPs 在识别磷酸化 S/T 和 Y 位点方面的 AUROC 分别达到 0.9232 和 0.9660。此外，归因研究表明，预训练模型嵌入对 PTransIPs 的表现有助。此外，PTransIPs 具有可读性的氨基酸偏好、可见的训练过程和普适性。为便于使用，我们在 GitHub 上公开了代码和数据，请参考 \url{https://github.com/StatXzy7/PTransIPs}.”
</details></li>
</ul>
<hr>
<h2 id="Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks"><a href="#Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks" class="headerlink" title="Correlating Medi-Claim Service by Deep Learning Neural Networks"></a>Correlating Medi-Claim Service by Deep Learning Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04469">http://arxiv.org/abs/2308.04469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayanthi Vajiram, Negha Senthil, Nean Adhith. P</li>
<li>for: 医疗保险诈骗案件与患者、医生、诊断中心和保险公司之间的关系，需要不断监测。这种诈骗活动会对保险人和医疗保险公司的财务发展产生影响。</li>
<li>methods: 这篇论文使用卷积神经网络架构来检测诈骗申请，通过对不同提供者的申请进行相关性研究，帮助检测洗钱活动。用于检测诈骗和非诈骗申请的有supervised和Unsupervised分类器。</li>
<li>results: 该论文的结果表明，使用卷积神经网络架构和相关性研究可以帮助检测医疗保险诈骗案件，并且可以提高检测精度。<details>
<summary>Abstract</summary>
Medical insurance claims are of organized crimes related to patients, physicians, diagnostic centers, and insurance providers, forming a chain reaction that must be monitored constantly. These kinds of frauds affect the financial growth of both insured people and health insurance companies. The Convolution Neural Network architecture is used to detect fraudulent claims through a correlation study of regression models, which helps to detect money laundering on different claims given by different providers. Supervised and unsupervised classifiers are used to detect fraud and non-fraud claims.
</details>
<details>
<summary>摘要</summary>
医疗保险laims有组织犯罪关系到patients、医生、诊断中心和保险公司，形成一个排序链 reaction，需要不断监测。这种骗局会影响保险人和健康保险公司的财务增长。通过对不同提供者的laims进行相关性研究，涂抹神经网络架构可以检测针对不同提供者的骗局。使用supervised和Unsupervised分类器可以检测骗局和非骗局laims。
</details></li>
</ul>
<hr>
<h2 id="Explainable-machine-learning-to-enable-high-throughput-electrical-conductivity-optimization-of-doped-conjugated-polymers"><a href="#Explainable-machine-learning-to-enable-high-throughput-electrical-conductivity-optimization-of-doped-conjugated-polymers" class="headerlink" title="Explainable machine learning to enable high-throughput electrical conductivity optimization of doped conjugated polymers"></a>Explainable machine learning to enable high-throughput electrical conductivity optimization of doped conjugated polymers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04103">http://arxiv.org/abs/2308.04103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Wei Yoon, Adithya Kumar, Pawan Kumar, Kedar Hippalgaonkar, J Senthilnath, Vijila Chellappan</li>
<li>for: 加速材料发现和优化</li>
<li>methods: 使用机器学习（ML）技术，利用易于测量的吸收спектроскопия数据，加速测量电性征的工作流程</li>
<li>results: 提高测量电性征的效率89%，并且可以解释ML模型的具体影响因素，从而获得了有用的科学见解。<details>
<summary>Abstract</summary>
The combination of high-throughput experimentation techniques and machine learning (ML) has recently ushered in a new era of accelerated material discovery, enabling the identification of materials with cutting-edge properties. However, the measurement of certain physical quantities remains challenging to automate. Specifically, meticulous process control, experimentation and laborious measurements are required to achieve optimal electrical conductivity in doped polymer materials. We propose a ML approach, which relies on readily measured absorbance spectra, to accelerate the workflow associated with measuring electrical conductivity. The first ML model (classification model), accurately classifies samples with a conductivity >~25 to 100 S/cm, achieving a maximum of 100% accuracy rate. For the subset of highly conductive samples, we employed a second ML model (regression model), to predict their conductivities, yielding an impressive test R2 value of 0.984. To validate the approach, we showed that the models, neither trained on the samples with the two highest conductivities of 498 and 506 S/cm, were able to, in an extrapolative manner, correctly classify and predict them at satisfactory levels of errors. The proposed ML workflow results in an improvement in the efficiency of the conductivity measurements by 89% of the maximum achievable using our experimental techniques. Furthermore, our approach addressed the common challenge of the lack of explainability in ML models by exploiting bespoke mathematical properties of the descriptors and ML model, allowing us to gain corroborated insights into the spectral influences on conductivity. Through this study, we offer an accelerated pathway for optimizing the properties of doped polymer materials while showcasing the valuable insights that can be derived from purposeful utilization of ML in experimental science.
</details>
<details>
<summary>摘要</summary>
高通过率实验技术和机器学习（ML）的结合，已经 ushered in一个新的时代，用于加速材料发现，并使得可以通过高级特性来标识材料。然而，一些物理量的测量仍然具有挑战。Specifically, 需要精心控制过程，实验和劳动ioso measurements 以实现高电导率填充 polymer 材料中的优化。我们提议一种 ML 方法，基于Ready-to-measure absorbance spectrum，以加速测量电导率的工作流程。首先，我们使用了一种分类模型（第一种 ML 模型），准确地将样本分类为电导率 > ~25 to 100 S/cm，实现最高的准确率（100%）。对于高电导率样本 subset，我们使用了一种 regression 模型（第二种 ML 模型），来预测他们的电导率，得到了惊人的 test R2 值为 0.984。为了验证方法，我们表明，无论在填充 polymer 材料中的两个最高电导率样本（498和506 S/cm）的情况下，模型都能够，在扩展性的方式下，正确地分类和预测它们，并且得到了满意的误差水平。我们的 ML 工作流程对于测量电导率的效率提高了89%的最大可达水平。此外，我们的方法解决了通用机器学习模型的普遍问题，即无法解释性。我们通过抽象数学属性和 ML 模型的特性，获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠的干涉因素，从而获得了可靠
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-Evolution-of-Deep-Neural-Network-Architectures"><a href="#Asynchronous-Evolution-of-Deep-Neural-Network-Architectures" class="headerlink" title="Asynchronous Evolution of Deep Neural Network Architectures"></a>Asynchronous Evolution of Deep Neural Network Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04102">http://arxiv.org/abs/2308.04102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jason Liang, Hormoz Shahrzad, Risto Miikkulainen</li>
<li>for: 提高 ENAS 的并发评估速度</li>
<li>methods: 使用异步评估策略 (AES)，维护最多 $K$ 个个体Ready to be sent to the workers for evaluation，并在 $M&lt;&lt;K$ 个个体已经被评估的情况下提交下一代</li>
<li>results: 在 11-bit 多路分配和图像描述任务中观察到多倍性和开放式优化任务中的性能提高，表明 AES 是一种有效的并发评估策略，适用于复杂系统的进化中长度和变化很大的评估时间。<details>
<summary>Abstract</summary>
Many evolutionary algorithms (EAs) take advantage of parallel evaluation of candidates. However, if evaluation times vary significantly, many worker nodes (i.e.,\ compute clients) are idle much of the time, waiting for the next generation to be created. Evolutionary neural architecture search (ENAS), a class of EAs that optimizes the architecture and hyperparameters of deep neural networks, is particularly vulnerable to this issue. This paper proposes a generic asynchronous evaluation strategy (AES) that is then adapted to work with ENAS. AES increases throughput by maintaining a queue of upto $K$ individuals ready to be sent to the workers for evaluation and proceeding to the next generation as soon as $M<<K$ individuals have been evaluated by the workers. A suitable value for $M$ is determined experimentally, balancing diversity and efficiency. To showcase the generality and power of AES, it was first evaluated in 11-bit multiplexer design (a single-population verifiable discovery task) and then scaled up to ENAS for image captioning (a multi-population open-ended-optimization task). In both problems, a multifold performance improvement was observed, suggesting that AES is a promising method for parallelizing the evolution of complex systems with long and variable evaluation times, such as those in ENAS.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)许多进化算法（EA）利用并发评估候选者。然而，如果评估时间异常长， THEN 多个工作节点（即计算客户端）会大部分时间浪费于等待下一代被创建。进化神经网络架构搜索（ENAS），一类进化算法，特别容易受到这种问题的影响。这篇论文提出了一种通用异步评估策略（AES），然后将其应用于 ENAS。AES 通过维护一个最多 $K$ 个个体ready to be sent to the workers for evaluation，并在工作者评估 $M\ll K$ 个个体后进行下一代的创建，提高了 durchput。一个合适的 $M$ 值由实验确定，平衡多样性和效率。为了证明 AES 的普适性和能力，它首先在 11-bit 多路复用器设计（一个单种人口可验证发现任务）中进行了测试，然后扩展到 ENAS  для图像描述（一个多种人口开放结束优化任务）。在这两个问题中，都观察到了多倍性的性能改进，表明 AES 是一种有前途的方法 для并发进化复杂系统的评估，如 ENAS 中的长变化评估时间。
</details></li>
</ul>
<hr>
<h2 id="Why-Data-Science-Projects-Fail"><a href="#Why-Data-Science-Projects-Fail" class="headerlink" title="Why Data Science Projects Fail"></a>Why Data Science Projects Fail</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04896">http://arxiv.org/abs/2308.04896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xLaszlo/datascience-fails">https://github.com/xLaszlo/datascience-fails</a></li>
<li>paper_authors: Balaram Panda</li>
</ul>
<details>
<summary>Abstract</summary>
Data Science is a modern Data Intelligence practice, which is the core of many businesses and helps businesses build smart strategies around to deal with businesses challenges more efficiently. Data Science practice also helps in automating business processes using the algorithm, and it has several other benefits, which also deliver in a non-profitable framework. In regards to data science, three key components primarily influence the effective outcome of a data science project. Those are 1.Availability of Data 2.Algorithm 3.Processing power or infrastructure
</details>
<details>
<summary>摘要</summary>
现代数据智能实践---数据科学，是许多企业的核心，帮助企业建立更智能的策略，更有效地面对企业挑战。数据科学实践还可以自动化商业过程，并具有许多其他利点，如非营利框架。在关于数据科学的问题上，三个关键组件主要影响项目的效果。那是1.数据可用性2.算法3.处理能力或基础设施。
</details>


<hr>
<h2 id="Application-Oriented-Benchmarking-of-Quantum-Generative-Learning-Using-QUARK"><a href="#Application-Oriented-Benchmarking-of-Quantum-Generative-Learning-Using-QUARK" class="headerlink" title="Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK"></a>Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04082">http://arxiv.org/abs/2308.04082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian J. Kiwit, Marwa Marso, Philipp Ross, Carlos A. Riofrío, Johannes Klepsch, Andre Luckow</li>
<li>for: 本研究旨在提供一个标准化和简化量子机器学习（QML）算法评估的框架，以便更好地评估量子 Computing 应用程序的性能。</li>
<li>methods: 本研究使用了更新后的 QUantum computing Application benchmaRK（QUARK）框架，以便评估量子生成模型的训练和部署。</li>
<li>results: 本研究通过训练不同的量子生成模型，使用不同的图体设计、数据集和转换，并评估模型的普遍性和可靠性。<details>
<summary>Abstract</summary>
Benchmarking of quantum machine learning (QML) algorithms is challenging due to the complexity and variability of QML systems, e.g., regarding model ansatzes, data sets, training techniques, and hyper-parameters selection. The QUantum computing Application benchmaRK (QUARK) framework simplifies and standardizes benchmarking studies for quantum computing applications. Here, we propose several extensions of QUARK to include the ability to evaluate the training and deployment of quantum generative models. We describe the updated software architecture and illustrate its flexibility through several example applications: (1) We trained different quantum generative models using several circuit ansatzes, data sets, and data transformations. (2) We evaluated our models on GPU and real quantum hardware. (3) We assessed the generalization capabilities of our generative models using a broad set of metrics that capture, e.g., the novelty and validity of the generated data.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将量子机器学习（QML）算法进行测试和评估是具有复杂性和变化性的，例如模型 ansatzes、数据集、训练技术和超参数选择等。QUantum computing Application benchmaRK（QUARK）框架可以简化和标准化量子计算应用程序的测试和评估研究。我们提议在QUARK框架中添加了评估量子生成模型的训练和部署功能。我们描述了更新后的软件架构，并通过多个示例应用 illustrate its flexibility：(1) 我们使用不同的量子生成模型circuit ansatzes、数据集和数据变换来训练不同的量子生成模型。(2) 我们在GPU和真正量子硬件上评估了我们的模型。(3) 我们使用了一系列的metric来评估我们的生成模型的通用性，例如生成数据的新鲜性和有效性。Note: "quantum generative models" in the text refers to quantum neural networks or quantum machine learning models that can generate new data samples.
</details></li>
</ul>
<hr>
<h2 id="Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients"><a href="#Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients" class="headerlink" title="Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients"></a>Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04077">http://arxiv.org/abs/2308.04077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shu, Xiaoqiang Lin, Zhongxiang Dai, Bryan Kian Hsiang Low</li>
<li>for: 这个研究是为了提出一种能够在无法读取本地数据的情况下进行联合优化的方法，并且可以在各种实际应用中实现更好的效率和积极性。</li>
<li>methods: 这个研究使用了联合优化的背景下的零次项目优化（ZOO）方法，并且提出了一种基于轨迹信息的渐进幂函数估计（Trajectory-Informed Gradient Surrogates，TIGS）以及一种适应性的渐进幂函数调整（Adaptive Gradient Correction，AGC）技术，以提高查询和通信效率。</li>
<li>results: 这个研究透过实际实验（包括联合黑洞攻击和联合非对称度量优化），证明了FZooS方法的理论上的改进，并且在实际应用中实现了更好的效率和积极性。<details>
<summary>Abstract</summary>
Federated optimization, an emerging paradigm which finds wide real-world applications such as federated learning, enables multiple clients (e.g., edge devices) to collaboratively optimize a global function. The clients do not share their local datasets and typically only share their local gradients. However, the gradient information is not available in many applications of federated optimization, which hence gives rise to the paradigm of federated zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from the limitations of query and communication inefficiency, which can be attributed to (a) their reliance on a substantial number of function queries for gradient estimation and (b) the significant disparity between their realized local updates and the intended global updates. To this end, we (a) introduce trajectory-informed gradient surrogates which is able to use the history of function queries during optimization for accurate and query-efficient gradient estimation, and (b) develop the technique of adaptive gradient correction using these gradient surrogates to mitigate the aforementioned disparity. Based on these, we propose the federated zeroth-order optimization using trajectory-informed surrogate gradients (FZooS) algorithm for query- and communication-efficient federated ZOO. Our FZooS achieves theoretical improvements over the existing approaches, which is supported by our real-world experiments such as federated black-box adversarial attack and federated non-differentiable metric optimization.
</details>
<details>
<summary>摘要</summary>
federated optimization, an emerging paradigm which finds wide real-world applications such as federated learning, enables multiple clients (e.g., edge devices) to collaboratively optimize a global function. The clients do not share their local datasets and typically only share their local gradients. However, the gradient information is not available in many applications of federated optimization, which hence gives rise to the paradigm of federated zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from the limitations of query and communication inefficiency, which can be attributed to (a) their reliance on a substantial number of function queries for gradient estimation and (b) the significant disparity between their realized local updates and the intended global updates. To this end, we (a) introduce trajectory-informed gradient surrogates which is able to use the history of function queries during optimization for accurate and query-efficient gradient estimation, and (b) develop the technique of adaptive gradient correction using these gradient surrogates to mitigate the aforementioned disparity. Based on these, we propose the federated zeroth-order optimization using trajectory-informed surrogate gradients (FZooS) algorithm for query- and communication-efficient federated ZOO. Our FZooS achieves theoretical improvements over the existing approaches, which is supported by our real-world experiments such as federated black-box adversarial attack and federated non-differentiable metric optimization.Note that Simplified Chinese is a romanization of Chinese, and the actual Chinese characters may be different.
</details></li>
</ul>
<hr>
<h2 id="Learning-Specialized-Activation-Functions-for-Physics-informed-Neural-Networks"><a href="#Learning-Specialized-Activation-Functions-for-Physics-informed-Neural-Networks" class="headerlink" title="Learning Specialized Activation Functions for Physics-informed Neural Networks"></a>Learning Specialized Activation Functions for Physics-informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04073">http://arxiv.org/abs/2308.04073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leaplabthu/adaafforpinns">https://github.com/leaplabthu/adaafforpinns</a></li>
<li>paper_authors: Honghui Wang, Lu Lu, Shiji Song, Gao Huang</li>
<li>for: 解决Physics-informed neural networks (PINNs)中的优化困难问题。</li>
<li>methods: 提出了一种基于活动函数的自适应搜索方法，并对不同的问题进行比较和讨论。</li>
<li>results: 通过对多个 benchmark 进行测试，证明了该方法的效果和可INTERPRETABLE性。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) are known to suffer from optimization difficulty. In this work, we reveal the connection between the optimization difficulty of PINNs and activation functions. Specifically, we show that PINNs exhibit high sensitivity to activation functions when solving PDEs with distinct properties. Existing works usually choose activation functions by inefficient trial-and-error. To avoid the inefficient manual selection and to alleviate the optimization difficulty of PINNs, we introduce adaptive activation functions to search for the optimal function when solving different problems. We compare different adaptive activation functions and discuss their limitations in the context of PINNs. Furthermore, we propose to tailor the idea of learning combinations of candidate activation functions to the PINNs optimization, which has a higher requirement for the smoothness and diversity on learned functions. This is achieved by removing activation functions which cannot provide higher-order derivatives from the candidate set and incorporating elementary functions with different properties according to our prior knowledge about the PDE at hand. We further enhance the search space with adaptive slopes. The proposed adaptive activation function can be used to solve different PDE systems in an interpretable way. Its effectiveness is demonstrated on a series of benchmarks. Code is available at https://github.com/LeapLabTHU/AdaAFforPINNs.
</details>
<details>
<summary>摘要</summary>
物理学信息感知神经网络（PINNs）经常遇到优化困难。在这项工作中，我们揭示了PINNs在解决不同类型的偏微分方程（PDEs）时的优化困难和活动函数之间的关系。特别是，我们发现PINNs在解决不同类型的PDEs时会具有高敏感性，而且现有的活动函数通常是通过不必要的试错来选择的。为了避免不必要的手动选择和提高PINNs的优化效果，我们引入了适应性的活动函数来搜索解决不同问题的最佳函数。我们比较了不同的适应性活动函数，并讨论了它们在PINNs中的限制。此外，我们提议在PINNs优化中应用学习组合候选活动函数的思想，以提高学习的稳定性和多样性。我们通过从候选函数中移除无法提供高阶导数的活动函数，并根据我们对PDE的先验知识添加不同性质的元素函数来实现这一点。最终，我们还使用自适应坡度来增强搜索空间。我们提出的适应性活动函数可以在可解释的方式下解决不同PDE系统。我们在一系列的benchmark中证明了它的效果。代码可以在https://github.com/LeapLabTHU/AdaAFforPINNs上获取。
</details></li>
</ul>
<hr>
<h2 id="Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation"><a href="#Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation" class="headerlink" title="Path Signatures for Diversity in Probabilistic Trajectory Optimisation"></a>Path Signatures for Diversity in Probabilistic Trajectory Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04071">http://arxiv.org/abs/2308.04071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Barcelos, Tin Lai, Rafael Oliveira, Paulo Borges, Fabio Ramos</li>
<li>for: 这篇论文主要应用于精确的机器人动作规划，尤其是在具有复杂障碍物和复杂 geometrical 的环境下。</li>
<li>methods: 这篇论文使用了当代 computation 硬件的平行优化方法，通过将多个解 initialize 自不同的起始点，同时解决问题。然而，如果没有一个策略来避免解彼此灰度，则可能会出现模式崩溃，从而降低了方法的效率和寻找全局解的可能性。这篇论文利用了最近的条件paths 理论，设计了一个避免模式崩溃的算法，并且使用了path signatures 和 Hilbert space representation of trajectories。</li>
<li>results: 这篇论文的实验结果显示，该算法可以在许多问题上取得更低的平均成本，比如2D navigation 和 robotic manipulators 在填充环境下的运作。<details>
<summary>Abstract</summary>
Motion planning can be cast as a trajectory optimisation problem where a cost is minimised as a function of the trajectory being generated. In complex environments with several obstacles and complicated geometry, this optimisation problem is usually difficult to solve and prone to local minima. However, recent advancements in computing hardware allow for parallel trajectory optimisation where multiple solutions are obtained simultaneously, each initialised from a different starting point. Unfortunately, without a strategy preventing two solutions to collapse on each other, naive parallel optimisation can suffer from mode collapse diminishing the efficiency of the approach and the likelihood of finding a global solution. In this paper we leverage on recent advances in the theory of rough paths to devise an algorithm for parallel trajectory optimisation that promotes diversity over the range of solutions, therefore avoiding mode collapses and achieving better global properties. Our approach builds on path signatures and Hilbert space representations of trajectories, and connects parallel variational inference for trajectory estimation with diversity promoting kernels. We empirically demonstrate that this strategy achieves lower average costs than competing alternatives on a range of problems, from 2D navigation to robotic manipulators operating in cluttered environments.
</details>
<details>
<summary>摘要</summary>
moviment planning 可以被看作为一个轨迹优化问题，其中要尽可能地降低轨迹的成本。在复杂的环境中，充满障碍物和复杂的几何结构时，这个优化问题通常很难解，容易陷入地方最优点。然而，当前的计算硬件技术允许同时进行多个解的优化，每个解从不同的初始点开始。然而，如果没有避免两个解归并在一起的策略，纯粹的平行优化可能会受到模式归并的影响，从而降低方法的效率和找到全局解的可能性。在这篇论文中，我们利用了最近的粗路理论进行平行轨迹优化算法，以便在轨迹优化过程中促进多元性，因此避免模式归并，并实现更好的全局性质。我们的方法基于路径签名和希尔伯特空间表示轨迹，并将平行变分推理与多样性激活函数连接起来。我们在几个问题上进行了实验，证明了这种策略在相对轨迹成本方面具有更好的性能。
</details></li>
</ul>
<hr>
<h2 id="ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data"><a href="#ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data" class="headerlink" title="ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data"></a>ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04070">http://arxiv.org/abs/2308.04070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvidia/nvflare">https://github.com/nvidia/nvflare</a></li>
<li>paper_authors: Pochuan Wang, Chen Shen, Weichung Wang, Masahiro Oda, Chiou-Shann Fuh, Kensaku Mori, Holger R. Roth</li>
<li>for: 提出了一种总结多器官多疾病的整合分割模型，使用联邦学习（FL）技术实现共同开发模型而无需交换训练数据。</li>
<li>methods: 提出了一种名为ConDistFL的框架，将FL与知识塑造相结合，以便从部分标注数据中提取本地模型中的器官和肿瘤知识。</li>
<li>results: 在四个不同的部分标注腹部CT数据集上进行验证，结果表明提出的框架在FedAvg和FedOpt基elines之上显著提高了性能，并且在外部测试数据集上表现出了更高的普适性。<details>
<summary>Abstract</summary>
Developing a generalized segmentation model capable of simultaneously delineating multiple organs and diseases is highly desirable. Federated learning (FL) is a key technology enabling the collaborative development of a model without exchanging training data. However, the limited access to fully annotated training data poses a major challenge to training generalizable models. We propose "ConDistFL", a framework to solve this problem by combining FL with knowledge distillation. Local models can extract the knowledge of unlabeled organs and tumors from partially annotated data from the global model with an adequately designed conditional probability representation. We validate our framework on four distinct partially annotated abdominal CT datasets from the MSD and KiTS19 challenges. The experimental results show that the proposed framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the performance on an external test dataset demonstrates superior generalizability compared to models trained on each dataset separately. Our ablation study suggests that ConDistFL can perform well without frequent aggregation, reducing the communication cost of FL. Our implementation will be available at https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.
</details>
<details>
<summary>摘要</summary>
开发一个通用分割模型，可同时分割多个器官和疾病，是非常感兴趣的。联邦学习（FL）是一种关键技术，它允许参与者共同开发模型，无需交换训练数据。然而，受到完全注释训练数据的限制，很难训练通用的模型。我们提议一种名为“ConDistFL”的框架，通过结合FL和知识储存来解决这个问题。本地模型可以从全球模型中提取不完全注释的器官和肿瘤的知识，并使用适当的条件概率表示。我们在四个不同的部分注释的腹部CT数据集上验证了我们的框架。实验结果表明，我们的框架在FedAvg和FedOpt基elines之上显著提高了性能。此外，对于外部测试数据集的性能表明，我们的模型具有更高的普适性比于每个数据集 separately 训练的模型。我们的剖析研究表明，ConDistFL可以在不经常的聚合下perform well， thereby reducing the communication cost of FL。我们的实现将在https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl中提供。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation"><a href="#Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation" class="headerlink" title="Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation"></a>Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04061">http://arxiv.org/abs/2308.04061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Insung Kong, Yongdai Kim</li>
<li>for: 本研究强调 semi-supervised adversarial training，即在标注数据稀缺的情况下进行鲁棒化训练。</li>
<li>methods: 本文提出了两个Upper bound的robust risk，并提出了一个基于这两个Upper bound的Regularization term。此外，本文还提出了一种基于知识传播的semi-supervised teacher的方法。</li>
<li>results: 实验表明，我们的提议的算法可以 дости得 estado-of-the-art的性能，与现有算法相比，它在标注数据稀缺的情况下表现更优。例如，我们的算法只使用8%的标注数据时，与全量标注数据使用的超参数比较，其性能与标准准确率和鲁棒准确率在CIFAR-10上几乎相同。<details>
<summary>Abstract</summary>
Adversarial robustness is a research area that has recently received a lot of attention in the quest for trustworthy artificial intelligence. However, recent works on adversarial robustness have focused on supervised learning where it is assumed that labeled data is plentiful. In this paper, we investigate semi-supervised adversarial training where labeled data is scarce. We derive two upper bounds for the robust risk and propose a regularization term for unlabeled data motivated by these two upper bounds. Then, we develop a semi-supervised adversarial training algorithm that combines the proposed regularization term with knowledge distillation using a semi-supervised teacher (i.e., a teacher model trained using a semi-supervised learning algorithm). Our experiments show that our proposed algorithm achieves state-of-the-art performance with significant margins compared to existing algorithms. In particular, compared to supervised learning algorithms, performance of our proposed algorithm is not much worse even when the amount of labeled data is very small. For example, our algorithm with only 8\% labeled data is comparable to supervised adversarial training algorithms that use all labeled data, both in terms of standard and robust accuracies on CIFAR-10.
</details>
<details>
<summary>摘要</summary>
“反抗学习”是一个在人工智能领域受到非常多关注的研究领域，最近几年来它已经受到了很多关注。然而，当前的研究主要集中在超级vised学习中，假设有充足的标注数据。在这篇论文中，我们研究了半supervised adversarial training，即在标注数据匮乏的情况下进行反抗训练。我们 derive了两个Upper bound的 robust risk，并提出了一个基于这两个Upper bound的Regularization term。然后，我们开发了一种半supervised adversarial training算法，该算法将该Regularization term与知识塑化（即使用半supervised学习算法训练的教师模型）结合使用。我们的实验表明，我们的提出的算法可以达到现有算法的状态之巅性表现，并且与supervised学习算法相比，它在很小量标注数据下的性能不会太差。例如，我们的算法只使用8%的标注数据时，与supervised adversarial training算法相比，其性能在标准和Robust度上都不会太差，尤其是在CIFAR-10上。
</details></li>
</ul>
<hr>
<h2 id="Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers"><a href="#Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers" class="headerlink" title="Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"></a>Backdoor Federated Learning by Poisoning Backdoor-Critical Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04466">http://arxiv.org/abs/2308.04466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan</li>
<li>for: 本研究旨在探讨 Federated Learning（FL）中的后门攻击和防御策略，特别是关注小部分层次（Backdoor-Critical，BC）的攻击和防御。</li>
<li>methods: 本研究提出了一种基于实际攻击者视角的BC层自适应后门攻击方法，通过细化地攻击BC层来实现较好的攻击效果和隐蔽性。</li>
<li>results: 实验结果显示，对于七种SOTA防御策略，我们的BC层自适应后门攻击可以成功攻击FL模型，仅需10%的坏客户端，并且超过最新的后门攻击方法。<details>
<summary>Abstract</summary>
Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that our BC layer-aware backdoor attacks can successfully backdoor FL under seven SOTA defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 已经广泛应用于在分布式设备上进行敏感数据的机器学习训练。然而，分布式学习 paradigma 和 FL 中的不同设备之间的差异，使得攻击表面变得更加扩大。现有的 FL 攻击和防御方法ologies 通常集中在整个模型上。其中没有一个认可 BC 层（backdoor-critical layers）——一个小型层的 subsets 控制模型的漏洞。对 BC 层进行攻击可以达到攻击整个模型的同样效果，但是在现有的防御策略下可以让攻击更加隐蔽。本文提出了一种通用的即场方法，可以从攻击者的角度进行 BC 层的识别和验证。根据识别的 BC 层，我们针对这些层进行了一种新的后门攻击方法，可以在不同的防御策略下寻求一种基本的平衡，以确保攻击的效果和隐蔽性。经过广泛的实验，我们发现，我们的 BC 层认可后门攻击可以在七种 SOTA 防御策略下成功后门 FL，且比最新的后门攻击方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Toward-Improving-Predictive-Risk-Modelling-for-New-Zealand’s-Child-Welfare-System-Using-Clustering-Methods"><a href="#Toward-Improving-Predictive-Risk-Modelling-for-New-Zealand’s-Child-Welfare-System-Using-Clustering-Methods" class="headerlink" title="Toward Improving Predictive Risk Modelling for New Zealand’s Child Welfare System Using Clustering Methods"></a>Toward Improving Predictive Risk Modelling for New Zealand’s Child Welfare System Using Clustering Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04060">http://arxiv.org/abs/2308.04060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahar Barmomanesh, Victor Miranda-Soberanis</li>
<li>For: 这个论文旨在帮助社工更好地识别受到虐待儿童的风险，并决定当局是否应该 intervene。* Methods: 这个论文使用了行政数据和机器学习算法，以及主成分分析和K-Means聚类分析方法，以identify特定的儿童特征，并分析这些特征如何影响现有的风险模型的性能。* Results: 研究发现，使用不同的聚类方法可以分解出不同的儿童群体，并且这些群体之间存在显著的差异。LASSO逻辑回归模型在不同的聚类中都表现了较好的性能，但是对于年龄较小的儿童，模型表现更好。这些结果表明，可能需要为不同的年龄组分开发不同的风险模型，以提高模型的准确性。<details>
<summary>Abstract</summary>
The combination of clinical judgement and predictive risk models crucially assist social workers to segregate children at risk of maltreatment and decide when authorities should intervene. Predictive risk modelling to address this matter has been initiated by several governmental welfare authorities worldwide involving administrative data and machine learning algorithms. While previous studies have investigated risk factors relating to child maltreatment, several gaps remain as to understanding how such risk factors interact and whether predictive risk models perform differently for children with different features. By integrating Principal Component Analysis and K-Means clustering, this paper presents initial findings of our work on the identification of such features as well as their potential effect on current risk modelling frameworks. This approach allows examining existent, unidentified yet, clusters of New Zealand (NZ) children reported with care and protection concerns, as well as to analyse their inner structure, and evaluate the performance of prediction models trained cluster wise. We aim to discover the extent of clustering degree required as an early step in the development of predictive risk models for child maltreatment and so enhance the accuracy of such models intended for use by child protection authorities. The results from testing LASSO logistic regression models trained on identified clusters revealed no significant difference in their performance. The models, however, performed slightly better for two clusters including younger children. our results suggest that separate models might need to be developed for children of certain age to gain additional control over the error rates and to improve model accuracy. While results are promising, more evidence is needed to draw definitive conclusions, and further investigation is necessary.
</details>
<details>
<summary>摘要</summary>
“职业判断和预测风险模型在社工为了识别受到虐待风险的儿童和应否干预时作出决策非常重要。世界各地政府的儿童福利机构已经开始使用行政数据和机器学习算法进行预测风险模型。 although previous studies have investigated child maltreatment risk factors, there are still gaps in understanding how these risk factors interact and whether predictive risk models perform differently for children with different features. 本研究通过统计分析和K-Means聚类技术，初步发现了儿童特有的特征，并评估了这些特征对现有的风险模型的影响。我们的目标是发现这些群集的弹性度合理的程度，以便在开发预测风险模型时提高模型的准确性。我们发现，将模型训练分为各群集而训练，不会有 statistically significant difference in their performance. however, the models performed slightly better for two clusters including younger children. our results suggest that separate models might need to be developed for children of certain age to gain additional control over the error rates and to improve model accuracy. although the results are promising, more evidence is needed to draw definitive conclusions, and further investigation is necessary.”
</details></li>
</ul>
<hr>
<h2 id="The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings"><a href="#The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings" class="headerlink" title="The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings"></a>The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04052">http://arxiv.org/abs/2308.04052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TimMerino1710/five-dollar-model">https://github.com/TimMerino1710/five-dollar-model</a></li>
<li>paper_authors: Timothy Merino, Roman Negri, Dipika Rajesh, M Charity, Julian Togelius</li>
<li>for: 用于生成低维度图像，维护文本提示中的含义 semantics</li>
<li>methods: 使用五元模型，应用新的扩展策略来提高模型在有限数据集上的性能</li>
<li>results: 生成的图像保持文本提示中的含义，并且在三个小数据集上达到了良好的性能Here’s the same information in Traditional Chinese:</li>
<li>for: 用于生成低维度图像，维护文本提示中的含义 semantics</li>
<li>methods: 使用五元模型，应用新的扩展策略来提高模型在有限数据集上的性能</li>
<li>results: 生成的图像保持文本提示中的含义，并且在三个小数据集上达到了良好的性能<details>
<summary>Abstract</summary>
The five-dollar model is a lightweight text-to-image generative architecture that generates low dimensional images from an encoded text prompt. This model can successfully generate accurate and aesthetically pleasing content in low dimensional domains, with limited amounts of training data. Despite the small size of both the model and datasets, the generated images are still able to maintain the encoded semantic meaning of the textual prompt. We apply this model to three small datasets: pixel art video game maps, video game sprite images, and down-scaled emoji images and apply novel augmentation strategies to improve the performance of our model on these limited datasets. We evaluate our models performance using cosine similarity score between text-image pairs generated by the CLIP VIT-B/32 model.
</details>
<details>
<summary>摘要</summary>
五元模型是一种轻量级的文本到图像生成架构，可以将编码的文本提示转换成低维度的图像。这种模型可以在有限的训练数据量下生成准确和美观的内容，并且保持文本提示中的编码含义。我们对三个小 datasets（像素艺术视频游戏地图、视频游戏 sprite 图像和缩小的表情图像）进行应用，并使用新的扩展策略来提高我们的模型在这些有限的 datasets 上的性能。我们使用 CLIP VIT-B/32 模型计算文本-图像对的cosine相似性分数来评估我们的模型表现。
</details></li>
</ul>
<hr>
<h2 id="Generative-Models-for-Anomaly-Detection-and-Design-Space-Dimensionality-Reduction-in-Shape-Optimization"><a href="#Generative-Models-for-Anomaly-Detection-and-Design-Space-Dimensionality-Reduction-in-Shape-Optimization" class="headerlink" title="Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization"></a>Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04051">http://arxiv.org/abs/2308.04051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danny D’Agostino</li>
<li>for: 提高全球优化算法的效率，同时促进优化过程中高质量设计的生成。</li>
<li>methods: 减少原始设计变量，定义一个新的减少子空间，在这个子空间中最大化几何差异，并使用概率线性隐藏变量模型，如因子分析和概率主成分分析。</li>
<li>results: 通过测试DTMB 5415模型的壳体优化问题，示出了新框架可以提高全球优化算法的收敛，同时仅生成高质量几何特征的设计。<details>
<summary>Abstract</summary>
Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This enables the definition of a new optimization model where anomalous geometries are penalized and consequently avoided during the optimization loop. The procedure is demonstrated for hull shape optimization of the DTMB 5415 model, extensively used as an international benchmark for shape optimization problems. The global optimization routine is carried out using Bayesian Optimization and the DIRECT algorithm. From the numerical results, the new framework improves the convergence of global optimization algorithms, while only designs with high-quality geometrical features are generated through the optimization routine thereby avoiding the wastage of precious computationally expensive simulations.
</details>
<details>
<summary>摘要</summary>
我们的工作提出了一种新的形优化方法，旨在提高全球优化算法的效率，同时在优化过程中生成高质量的设计，免受几何缺陷。这是通过减少原始设计变量数，定义一个新的减少子空间，在这个子空间中最大化几何差异，并通过泛化线性latent variable模型，如因子分析和概率主成分分析来模型数据。我们证明，当shape modification方法是线性的，并且设计变量是随机选择的时候，数据 approximate Gaussian distribution。模型不确定性是通过Mahalanobis距离测量的。我们发现，异常设计通常具有高值的这个指标。这使得我们可以定义一个新的优化模型，惩罚异常几何，并在优化过程中避免几何缺陷。我们使用 bayesian优化和DIRECT算法进行全球优化。从数值结果来看，新的框架可以提高全球优化算法的收敛速度，同时只有高质量的几何特征被生成，从而避免了 computationally expensive simulations的浪费。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset"><a href="#A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset" class="headerlink" title="A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset"></a>A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04037">http://arxiv.org/abs/2308.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse<br>for: 本研究旨在提高文本分类的精度，并 investigate了文本特征权重方法的影响。methods: 本研究使用了两种特征提取方法：N-Grams和TF-IDF，并使用了多种State-of-the-art分类器进行验证，包括支持向量机(SVM)、概率Logistic Regression、多omial Naive Bayes(Multinomial NB)、Random Forest、决策树和k-nearest neighbors(KNN)。results: 结果显示，基于TF-IDF特征而不是基于N-Grams特征时，文本特征权重方法可以获得显著提高的性能，TF-IDF得到了最高的准确率(93.81%),精度(94.20%),回归率(93.81%)和F1-score(91.99%)值，在Random Forest分类器中。<details>
<summary>Abstract</summary>
Text Classification is the process of categorizing text into the relevant categories and its algorithms are at the core of many Natural Language Processing (NLP). Term Frequency-Inverse Document Frequency (TF-IDF) and NLP are the most highly used information retrieval methods in text classification. We have investigated and analyzed the feature weighting method for text classification on unstructured data. The proposed model considered two features N-Grams and TF-IDF on the IMDB movie reviews and Amazon Alexa reviews dataset for sentiment analysis. Then we have used the state-of-the-art classifier to validate the method i.e., Support Vector Machine (SVM), Logistic Regression, Multinomial Naive Bayes (Multinomial NB), Random Forest, Decision Tree, and k-nearest neighbors (KNN). From those two feature extractions, a significant increase in feature extraction with TF-IDF features rather than based on N-Gram. TF-IDF got the maximum accuracy (93.81%), precision (94.20%), recall (93.81%), and F1-score (91.99%) value in Random Forest classifier.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering"><a href="#Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering" class="headerlink" title="Top K Relevant Passage Retrieval for Biomedical Question Answering"></a>Top K Relevant Passage Retrieval for Biomedical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04028">http://arxiv.org/abs/2308.04028</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shashank140195/Biomedical_QA_Model">https://github.com/shashank140195/Biomedical_QA_Model</a></li>
<li>paper_authors: Shashank Gupta</li>
<li>for:  answers medical questions in the biomedical domain</li>
<li>methods:  uses the existing Dense Passage Retrieval framework and retrieves answers from Pubmed articles</li>
<li>results:  achieved a 0.81 F1 score on the BioASQ QA dataset<details>
<summary>Abstract</summary>
Question answering is a task that answers factoid questions using a large collection of documents. It aims to provide precise answers in response to the user's questions in natural language. Question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. On the web, there is no single article that could provide all the possible answers available on the internet to the question of the problem asked by the user. The existing Dense Passage Retrieval model has been trained on Wikipedia dump from Dec. 20, 2018, as the source documents for answering questions. Question answering (QA) has made big strides with several open-domain and machine comprehension systems built using large-scale annotated datasets. However, in the clinical domain, this problem remains relatively unexplored. According to multiple surveys, Biomedical Questions cannot be answered correctly from Wikipedia Articles. In this work, we work on the existing DPR framework for the biomedical domain and retrieve answers from the Pubmed articles which is a reliable source to answer medical questions. When evaluated on a BioASQ QA dataset, our fine-tuned dense retriever results in a 0.81 F1 score.
</details>
<details>
<summary>摘要</summary>
问答任务是回答用户问题，使用大量文档库。其目的是在自然语言中提供精确的答案。问答需要高效的段落检索，以选择可能的上下文，传统的稀疏 вектор空间模型，如TF-IDF或BM25，是现行的方法。在互联网上，没有单独的文章可以提供用户问题的所有可能的答案。现有的 dense passage retrieval 模型在2018年12月20日的Wikipedia dump上进行训练，用作答案的来源文档。问答（QA）在开放领域和机器理解领域得到了 significanthuge strides，但在医学领域，这个问题还很未得到了探索。根据多份调查，生物医学问题无法从Wikipedia文章中正确地回答。在这项工作中，我们在现有的 DPR 框架上进行了修改，并从可靠的 Pubmed 文章中检索答案。当 evaluated 在 BioASQ QA 数据集上时，我们的精制 dense retriever 得到了0.81 F1 分数。
</details></li>
</ul>
<hr>
<h2 id="Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration"><a href="#Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration" class="headerlink" title="Scope Loss for Imbalanced Classification and RL Exploration"></a>Scope Loss for Imbalanced Classification and RL Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04024">http://arxiv.org/abs/2308.04024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hasham Burhani, Xiao Qi Shi, Jonathan Jaegerman, Daniel Balicki</li>
<li>for: This paper is written for researchers and practitioners in the field of reinforcement learning and supervised classification.</li>
<li>methods: The paper uses a novel loss function called Scope Loss, which adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances.</li>
<li>results: The paper shows that Scope Loss outperforms state-of-the-art loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了针对机器学习领域的奖励学习和监督学习而写的。</li>
<li>methods: 这篇论文使用了一种新的损失函数called Scope Loss，它调整 gradients来避免过度利用和数据不均衡导致的性能损失。</li>
<li>results: 这篇论文显示，Scope Loss 在一个笔记式的奖励学习任务和一个偏见的分类 dataset 上比 State-of-the-art 损失函数表现出色。<details>
<summary>Abstract</summary>
We demonstrate equivalence between the reinforcement learning problem and the supervised classification problem. We consequently equate the exploration exploitation trade-off in reinforcement learning to the dataset imbalance problem in supervised classification, and find similarities in how they are addressed. From our analysis of the aforementioned problems we derive a novel loss function for reinforcement learning and supervised classification. Scope Loss, our new loss function, adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances, without the need for any tuning. We test Scope Loss against SOTA loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset, and show that Scope Loss outperforms other loss functions.
</details>
<details>
<summary>摘要</summary>
我们证明了增强学习问题和分类问题之间的等价性。我们遂视探索优化和数据集不均势问题在增强学习和分类中的相似性，并从这些问题的分析中获得了一个新的损失函数。我们称之为Scope Loss。Scope Loss可以调整Gradient以避免过度探索和数据集不均势导致的性能损失，无需任何调整。我们对一签benchmark增强学习任务和一个偏斜的分类 dataset进行测试，与现有的损失函数进行比较，发现Scope Loss在这些任务中表现更好。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks"><a href="#Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks" class="headerlink" title="Improving Performance of Semi-Supervised Learning by Adversarial Attacks"></a>Improving Performance of Semi-Supervised Learning by Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04018">http://arxiv.org/abs/2308.04018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Kunwoong Kim, Yongdai Kim</li>
<li>for: 提高现代半监督学习算法的性能</li>
<li>methods: 使用对预训练模型进行 adversarial 攻击，选择高自信度无标样本进行标注</li>
<li>results: 在 CIFAR10 上，与 SCAR 结合的三种现代半监督学习算法显著提高图像分类性能<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) algorithm is a setup built upon a realistic assumption that access to a large amount of labeled data is tough. In this study, we present a generalized framework, named SCAR, standing for Selecting Clean samples with Adversarial Robustness, for improving the performance of recent SSL algorithms. By adversarially attacking pre-trained models with semi-supervision, our framework shows substantial advances in classifying images. We introduce how adversarial attacks successfully select high-confident unlabeled data to be labeled with current predictions. On CIFAR10, three recent SSL algorithms with SCAR result in significantly improved image classification.
</details>
<details>
<summary>摘要</summary>
半supervised learning（SSL）算法是基于现实的假设，即获得大量标注数据困难。在这项研究中，我们提出了一个通用框架，名为SCAR，意为选择干净样本并具有对抗性强化，以提高最近的SSL算法性能。我们通过对预训练模型进行对抗攻击，成功地选择高度自信的未标注样本进行标注。在CIFAR10上，我们使用SCAR结果与三种最近的SSL算法显著提高图像分类。
</details></li>
</ul>
<hr>
<h2 id="Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model"><a href="#Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model" class="headerlink" title="Continual Pre-Training of Large Language Models: How to (re)warm your model?"></a>Continual Pre-Training of Large Language Models: How to (re)warm your model?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04014">http://arxiv.org/abs/2308.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kshitij Gupta, Benjamin Thérien, Adam Ibrahim, Mats L. Richter, Quentin Anthony, Eugene Belilovsky, Irina Rish, Timothée Lesort</li>
<li>for: 这个论文的目的是探讨 kontinual pre-training 的可行性，即在新数据上更新先前训练的模型，而不是从scratch重新训练。</li>
<li>methods: 作者们使用了不同的暖身策略来研究模型在新数据上的表现。他们的假设是，在训练新数据时，学习率需要重新增加以提高计算效率。</li>
<li>results: 研究结果显示，虽然在训练新数据时模型的损失 initially increases，但在长期运行时，它们的下游数据表现得更好，even outperforming scratch-trained models。<details>
<summary>Abstract</summary>
Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and evaluate performance through validation perplexity. We experiment with different pre-training checkpoints, various maximum learning rates, and various warmup lengths. Our results show that while rewarming models first increases the loss on upstream and downstream data, in the longer run it improves the downstream performance, outperforming models trained from scratch$\unicode{x2013}$even for a large downstream dataset.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）通常在数十亿个字符上进行预训练，然后重新开始预训练过程。然而，这样的方法可能是比较昂贵和不fficient的。因此，我们提出了一种更有效的方法，即在新数据出现后不断更新已经预训练的模型，而不是从scratch重新训练模型。然而，新数据引入的分布变化通常会导致过去的数据表现下降。为了减少这种问题，在这项工作中，我们研究了不同的暖身策略的效果。我们假设，在训练新数据集时，学习率应该进行适度的增加，以提高计算效率。我们在Pile（上游数据集，300亿个字符）和SlimPajama（下游数据集，297亿个字符）中继续预训练Pythia 410M语言模型 architecture，并采用线性暖身和cosine衰减调度。我们在预训练检查点、最大学习率和暖身长度等方面进行了多种实验。我们的结果表明，虽然在upstream和downstream数据集上，首先使模型暖身会导致损失增加，但在更长时间后，它会提高下游表现，并在大下游数据集上超越从scratch训练的模型，即使使用大型数据集。
</details></li>
</ul>
<hr>
<h2 id="Generalization-bound-for-estimating-causal-effects-from-observational-network-data"><a href="#Generalization-bound-for-estimating-causal-effects-from-observational-network-data" class="headerlink" title="Generalization bound for estimating causal effects from observational network data"></a>Generalization bound for estimating causal effects from observational network data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04011">http://arxiv.org/abs/2308.04011</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruichu Cai, Zeqin Yang, Weilin Chen, Yuguang Yan, Zhifeng Hao</li>
<li>for: 这篇论文旨在适用于 causal effect estimation 问题，具体来说是在 observational network 数据上进行 causal effect 估计。</li>
<li>methods: 该论文使用了 joint propensity score 重新分配 schema 和 Integral Probability Metric (IPM) 表示学习 schema， derive 了一个通用的 generalization bound  для causal effect estimation。</li>
<li>results: 实验研究表明，该算法在两个实际网络上的 semi-synthetic 数据上具有效果。<details>
<summary>Abstract</summary>
Estimating causal effects from observational network data is a significant but challenging problem. Existing works in causal inference for observational network data lack an analysis of the generalization bound, which can theoretically provide support for alleviating the complex confounding bias and practically guide the design of learning objectives in a principled manner. To fill this gap, we derive a generalization bound for causal effect estimation in network scenarios by exploiting 1) the reweighting schema based on joint propensity score and 2) the representation learning schema based on Integral Probability Metric (IPM). We provide two perspectives on the generalization bound in terms of reweighting and representation learning, respectively. Motivated by the analysis of the bound, we propose a weighting regression method based on the joint propensity score augmented with representation learning. Extensive experimental studies on two real-world networks with semi-synthetic data demonstrate the effectiveness of our algorithm.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: estimating causal effects from observational network data is a significant but challenging problem. existing works in causal inference for observational network data lack an analysis of the generalization bound, which can theoretically provide support for alleviating the complex confounding bias and practically guide the design of learning objectives in a principled manner. to fill this gap, we derive a generalization bound for causal effect estimation in network scenarios by exploiting 1) the reweighting schema based on joint propensity score and 2) the representation learning schema based on integral probability metric (ipm). we provide two perspectives on the generalization bound in terms of reweighting and representation learning, respectively. motivated by the analysis of the bound, we propose a weighting regression method based on the joint propensity score augmented with representation learning. extensive experimental studies on two real-world networks with semi-synthetic data demonstrate the effectiveness of our algorithm.
</details></li>
</ul>
<hr>
<h2 id="Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning"><a href="#Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning" class="headerlink" title="Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning"></a>Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03999">http://arxiv.org/abs/2308.03999</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii">https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii</a></li>
<li>paper_authors: Abhilekha Dalal, Md Kamruzzaman Sarker, Adrita Barua, Eugene Vasserman, Pascal Hitzler</li>
<li>for: This paper aims to provide a systematic and automated method for interpreting the activations of hidden neurons in deep learning systems, specifically Convolutional Neural Networks (CNNs).</li>
<li>methods: The proposed method uses large-scale background knowledge and a symbolic reasoning approach called Concept Induction based on description logics to attach meaningful labels from the background knowledge to individual neurons in the dense layer of a CNN.</li>
<li>results: The paper demonstrates that the proposed method provides meaningful interpretations of hidden neuron activations, allowing for a better understanding of what the CNN has internally detected as relevant on the input.<details>
<summary>Abstract</summary>
A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, demystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Our results show that we can automatically attach meaningful labels from the background knowledge to individual neurons in the dense layer of a Convolutional Neural Network through a hypothesis and verification process.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释AI是正确解释隐藏节点的活动：正确的解释可以提供关于深度学习系统内部检测到的输入相关信息的深入了解，从而使深度学习系统从黑盒模型变为 clearer。现状的最佳实践表明，隐藏节点的活动可以在某些情况下被解释为人类可理解的方式，但是系统化的自动方法，能够对隐藏节点的活动进行假设和验证，尚未得到充分的探索。在这篇论文中，我们提供了一种这样的方法，并证明了它可以提供有意义的解释。我们的方法基于使用大规模的背景知识，约200万个类型从Wikipedia概念层次结构中精心筛选出来，并使用符号逻辑方法called Concept Induction，原本是为Semantic Web领域开发的。我们的结果表明，我们可以通过一种假设和验证过程，自动将 background knowledge 中的意义 labels 附加到 convolutional Neural Network 的稠密层中的各个神经元。
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks"><a href="#Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks" class="headerlink" title="Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks"></a>Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03995">http://arxiv.org/abs/2308.03995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengxi Zhang, Huaze Tang, Wenbo Ding, Xiao-Ping Zhang</li>
<li>for: 提高智能城市应用的潜在价值和可行性</li>
<li>methods: 提出了一种涵盖五个不同通信链的完整SAGIN系统，并提出了一种高效的多类多代理深度学习方法来解决资源管理问题</li>
<li>results: 实验结果表明提议的CMT-MARL方法能够提高总传输率和传输成功率，这些结果证明SAGIN的可能性和实现性<details>
<summary>Abstract</summary>
The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous devices including low earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users (GUs), holds significant promise for advancing smart city applications. However, resource management of the SAGIN is a challenge requiring urgent study in that inappropriate resource management will cause poor data transmission, and hence affect the services in smart cities. In this paper, we develop a comprehensive SAGIN system that encompasses five distinct communication links and propose an efficient cooperative multi-type multi-agent deep reinforcement learning (CMT-MARL) method to address the resource management issue. The experimental results highlight the efficacy of the proposed CMT-MARL, as evidenced by key performance indicators such as the overall transmission rate and transmission success rate. These results underscore the potential value and feasibility of future implementation of the SAGIN.
</details>
<details>
<summary>摘要</summary>
space-air-ground 集成网络（SAGIN），包括低地球轨道卫星（LEO）、无人飞行器（UAV）和地面用户（GU）等多种设备，具有推动智能城市应用的潜在优势。然而，SAGIN资源管理却是一项需要紧迫研究的挑战，因为不当的资源管理可能导致数据传输差，影响智能城市服务的质量。在本文中，我们提出了一个全面的 SAGIN 系统，包括五种不同的通信链接，并提出了一种高效的合作多类多代理深度学习（CMT-MARL）方法来解决资源管理问题。实验结果表明，提议的 CMT-MARL 方法具有优秀的性能指标，如总传输率和传输成功率。这些结果证明了 SAGIN 的可能价值和可行性，并且为未来实施 SAGIN 提供了重要的参考。
</details></li>
</ul>
<hr>
<h2 id="Fourier-neural-operator-for-real-time-simulation-of-3D-dynamic-urban-microclimate"><a href="#Fourier-neural-operator-for-real-time-simulation-of-3D-dynamic-urban-microclimate" class="headerlink" title="Fourier neural operator for real-time simulation of 3D dynamic urban microclimate"></a>Fourier neural operator for real-time simulation of 3D dynamic urban microclimate</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03985">http://arxiv.org/abs/2308.03985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhui Peng, Shaoxiang Qin, Senwen Yang, Jianchun Wang, Xue Liu, Liangzhu, Wang</li>
<li>for: 这篇论文主要关注于城市微气候的研究，以提高城市舒适性、健康性和建筑物能效性。</li>
<li>methods: 该论文使用了深度学习技术来加速复杂非线性交互的模型化。特别是使用了快速傅里叶 ней网络（FNO）来实时三维城市风场 simulate。</li>
<li>results: 实验结果表明，FNO模型可以准确重建快速更新的三维城市风场。此外，FNO方法可以在不同风向下进行泛化，并且在图形处理器上进行实时预测，使得城市微气候的实时模拟成为可能。<details>
<summary>Abstract</summary>
Global urbanization has underscored the significance of urban microclimates for human comfort, health, and building/urban energy efficiency. They profoundly influence building design and urban planning as major environmental impacts. Understanding local microclimates is essential for cities to prepare for climate change and effectively implement resilience measures. However, analyzing urban microclimates requires considering a complex array of outdoor parameters within computational domains at the city scale over a longer period than indoors. As a result, numerical methods like Computational Fluid Dynamics (CFD) become computationally expensive when evaluating the impact of urban microclimates. The rise of deep learning techniques has opened new opportunities for accelerating the modeling of complex non-linear interactions and system dynamics. Recently, the Fourier Neural Operator (FNO) has been shown to be very promising in accelerating solving the Partial Differential Equations (PDEs) and modeling fluid dynamic systems. In this work, we apply the FNO network for real-time three-dimensional (3D) urban wind field simulation. The training and testing data are generated from CFD simulation of the urban area, based on the semi-Lagrangian approach and fractional stepping method to simulate urban microclimate features for modeling large-scale urban problems. Numerical experiments show that the FNO model can accurately reconstruct the instantaneous spatial velocity field. We further evaluate the trained FNO model on unseen data with different wind directions, and the results show that the FNO model can generalize well on different wind directions. More importantly, the FNO approach can make predictions within milliseconds on the graphics processing unit, making real-time simulation of 3D dynamic urban microclimate possible.
</details>
<details>
<summary>摘要</summary>
全球城市化强调了城市微气候对人类舒适、健康和建筑/城市能效的重要性。它们对城市规划和建筑设计产生了深远的影响，是主要的环境因素。了解当地微气候非常重要，以便城市在气候变化面前做好准备，有效地实施抗逆性措施。然而，分析城市微气候需要考虑一系列的外部参数，包括城市规模内的计算领域和时间长达于室内。这使得计算流体动力学（CFD）方法成为计算成本较高的方法。随着深度学习技术的发展，新的机会在于加速复杂非线性交互和系统动力学模型化。在这种情况下，我们使用了整流神经网络（FNO）来实现实时三维城市风场 simulate。我们的实验表明，FNO网络可以准确重construct三维风场的快速变化。此外，我们还评估了在不同风向下测试的FNO模型，结果表明FNO模型可以在不同风向下 generale well。更重要的是，FNO方法可以在毫秒级别内进行预测，使实时三维动态城市微气候的模拟成为可能。
</details></li>
</ul>
<hr>
<h2 id="Characterization-of-Human-Balance-through-a-Reinforcement-Learning-based-Muscle-Controller"><a href="#Characterization-of-Human-Balance-through-a-Reinforcement-Learning-based-Muscle-Controller" class="headerlink" title="Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller"></a>Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04462">http://arxiv.org/abs/2308.04462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kübra Akbaş, Carlotta Mummolo, Xianlian Zhou</li>
<li>for: This paper aims to provide a new approach for objectively assessing balance capability in humans by using a musculoskeletal model integrated with a balance controller trained through reinforcement learning.</li>
<li>methods: The paper employs a musculoskeletal model, reinforcement learning, and Proximal Policy Optimization to train a balance controller and investigate balancing capabilities.</li>
<li>results: The study shows that the approach can provide a promising new method for establishing balance recovery limits and objectively assessing balance capability in bipedal systems, particularly in humans, and reveals the effects of muscle weakness and neural excitation delay on balance recovery.Here is the simplified Chinese translation of the three key points:</li>
<li>for: 这篇论文目的是提供一种新的方法来对人类的平衡能力进行 объектив评估，使用一种 integrate 了 musculoskeletal 模型和平衡控制器的 reinforcement learning 方法。</li>
<li>methods: 这篇论文使用了 musculoskeletal 模型、reinforcement learning 和 Proximal Policy Optimization 等方法来训练平衡控制器并调查平衡能力。</li>
<li>results: 这个研究表明这种方法可以提供一种有前途的新方法来确定平衡恢复限制和对人类的平衡能力进行 объектив评估，并揭示了肌肉衰竭和神经延迟对平衡恢复的影响。<details>
<summary>Abstract</summary>
Balance assessment during physical rehabilitation often relies on rubric-oriented battery tests to score a patient's physical capabilities, leading to subjectivity. While some objective balance assessments exist, they are often limited to tracking the center of pressure (COP), which does not fully capture the whole-body postural stability. This study explores the use of the center of mass (COM) state space and presents a promising avenue for monitoring the balance capabilities in humans. We employ a musculoskeletal model integrated with a balance controller, trained through reinforcement learning (RL), to investigate balancing capabilities. The RL framework consists of two interconnected neural networks governing balance recovery and muscle coordination respectively, trained using Proximal Policy Optimization (PPO) with reference state initialization, early termination, and multiple training strategies. By exploring recovery from random initial COM states (position and velocity) space for a trained controller, we obtain the final BR enclosing successful balance recovery trajectories. Comparing the BRs with analytical postural stability limits from a linear inverted pendulum model, we observe a similar trend in successful COM states but more limited ranges in the recoverable areas. We further investigate the effect of muscle weakness and neural excitation delay on the BRs, revealing reduced balancing capability in different regions. Overall, our approach of learning muscular balance controllers presents a promising new method for establishing balance recovery limits and objectively assessing balance capability in bipedal systems, particularly in humans.
</details>
<details>
<summary>摘要</summary>
评估身体重建期间的平衡能力frequently使用测试 battery Rubric-oriented 评估病人的身体能力，导致主观性。 Although some objective balance assessments exist, they are often limited to tracking the center of pressure (COP), which does not fully capture the whole-body postural stability. This study explores the use of the center of mass (COM) state space and presents a promising avenue for monitoring balance capabilities in humans. We employ a musculoskeletal model integrated with a balance controller, trained through reinforcement learning (RL), to investigate balancing capabilities. The RL framework consists of two interconnected neural networks governing balance recovery and muscle coordination, respectively, trained using Proximal Policy Optimization (PPO) with reference state initialization, early termination, and multiple training strategies. By exploring recovery from random initial COM states (position and velocity) space for a trained controller, we obtain the final balance recovery (BR) enclosing successful balance recovery trajectories. Comparing the BRs with analytical postural stability limits from a linear inverted pendulum model, we observe a similar trend in successful COM states but more limited ranges in the recoverable areas. We further investigate the effect of muscle weakness and neural excitation delay on the BRs, revealing reduced balancing capability in different regions. Overall, our approach of learning muscular balance controllers presents a promising new method for establishing balance recovery limits and objectively assessing balance capability in bipedal systems, particularly in humans.
</details></li>
</ul>
<hr>
<h2 id="PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning"><a href="#PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning" class="headerlink" title="PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning"></a>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03977">http://arxiv.org/abs/2308.03977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/pug">https://github.com/facebookresearch/pug</a></li>
<li>paper_authors: Florian Bordes, Shashank Shekhar, Mark Ibrahim, Diane Bouchacourt, Pascal Vincent, Ari S. Morcos</li>
<li>for: 这项研究旨在推广使用真实准确的 sintetic 图像数据，以便更好地设计和评估深度神经网络。</li>
<li>methods: 这项研究使用了 Unreal Engine 游戏引擎，生成了 Photorealistic Unreal Graphics（PUG）环境和数据集，以便进行表示学习研究。</li>
<li>results: 这项研究示出了 PUG 环境和数据集可以帮助进行更加正式的视觉模型评估。<details>
<summary>Abstract</summary>
Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的实验室数据集有以下几个缺点：首先，它们的数据量有限，使得模型的训练和评估受到限制。其次，实验室数据集通常是从互联网上抓取的，可能受到隐私、偏见和版权问题的影响。最后，实验室数据集的分布shift可能会导致模型在测试中表现不佳。在这种情况下，使用合成图像数据集成为一个有利的选择。合成图像数据集可以提供大量的数据样本，并且可以准确地控制每个场景和获得精细的标签和描述。在本研究中，我们提出了一种使用Unreal Engine游戏引擎生成PUG（实际图像）环境和数据集，以便进行表征学学习的研究。我们使用Unreal Engine来生成PUG环境，以提供更加准确和有利的图像数据。在本篇论文中，我们展示了PUG环境的潜在力量，可以帮助更好地评估视觉模型。>>
</details></li>
</ul>
<hr>
<h2 id="Amortized-Global-Search-for-Efficient-Preliminary-Trajectory-Design-with-Deep-Generative-Models"><a href="#Amortized-Global-Search-for-Efficient-Preliminary-Trajectory-Design-with-Deep-Generative-Models" class="headerlink" title="Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models"></a>Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03960">http://arxiv.org/abs/2308.03960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anjian Li, Amlan Sinha, Ryne Beeson</li>
<li>for: 本 paper 的目的是提出一种基于归一化搜索的抽象轨迹设计方法，以解决高维度和非几何的轨迹优化问题。</li>
<li>methods: 本 paper 使用深度生成模型来预测 trajectory 解的结构，并使用这些结构来加速对未经过seen的参数值进行全球搜索。</li>
<li>results: 本 paper 通过使用 deep generative models 预测 trajectory 解的结构，提高了轨迹优化问题的解决效率。<details>
<summary>Abstract</summary>
Preliminary trajectory design is a global search problem that seeks multiple qualitatively different solutions to a trajectory optimization problem. Due to its high dimensionality and non-convexity, and the frequent adjustment of problem parameters, the global search becomes computationally demanding. In this paper, we exploit the clustering structure in the solutions and propose an amortized global search (AmorGS) framework. We use deep generative models to predict trajectory solutions that share similar structures with previously solved problems, which accelerates the global search for unseen parameter values. Our method is evaluated using De Jong's 5th function and a low-thrust circular restricted three-body problem.
</details>
<details>
<summary>摘要</summary>
先期轨迹设计是一个全球搜索问题，旨在找到多个 качеitatively 不同的轨迹优化问题的解。由于其高维度和非拟合性，以及问题参数的频繁调整，全球搜索变得计算挑战。在这篇论文中，我们利用聚类结构在解决方案中，并提出了一个总体搜索（AmorGS）框架。我们使用深度生成模型预测轨迹解决方案，这些解决方案与之前解决过的问题有相似的结构，从而加速全球搜索未见参数值。我们的方法在De Jong的第五函数和一个低推力圆形三体问题中进行评估。
</details></li>
</ul>
<hr>
<h2 id="Fixed-Inter-Neuron-Covariability-Induces-Adversarial-Robustness"><a href="#Fixed-Inter-Neuron-Covariability-Induces-Adversarial-Robustness" class="headerlink" title="Fixed Inter-Neuron Covariability Induces Adversarial Robustness"></a>Fixed Inter-Neuron Covariability Induces Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03956">http://arxiv.org/abs/2308.03956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ahmed Shah, Bhiksha Raj</li>
<li>for: 提高深度神经网络（DNN）对 adversarial perturbation 的Robustness，以确保其在实际应用中的可靠性。</li>
<li>methods: 开发了 Self-Consistent Activation（SCA）层，该层包含 neuron 的活动是相互协调的，以满足一定的 covariability 模式。</li>
<li>results: 在图像和声音识别任务中，使用 SCA 层的模型可以达到高精度，并对 state-of-the-art Auto-PGD adversarial attack 显示出更高的Robustness，无需在 adversarially perturbed data 上进行训练。<details>
<summary>Abstract</summary>
The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated on image and sound recognition tasks, the models with a SCA layer achieved high accuracy, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks \textit{without being trained on adversarially perturbed data
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PMU-measurements-based-short-term-voltage-stability-assessment-of-power-systems-via-deep-transfer-learning"><a href="#PMU-measurements-based-short-term-voltage-stability-assessment-of-power-systems-via-deep-transfer-learning" class="headerlink" title="PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning"></a>PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03953">http://arxiv.org/abs/2308.03953</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SuperBruceJia/Power-Systems-Stability-Transfer-Learning">https://github.com/SuperBruceJia/Power-Systems-Stability-Transfer-Learning</a></li>
<li>paper_authors: Yang Li, Shitu Zhang, Yuanzheng Li, Jiting Cao, Shuyue Jia</li>
<li>for: 本研究旨在提出一种基于PMU测量数据的短期电压稳定评估方法，以解决现有深度学习方法对于电网结构变化、标签采集和小样本处理的局限性。</li>
<li>methods: 本方法使用深度传输学习，利用PMU测量数据创建初始数据集，采用时间拼接标注法和LSGAN数据增强技术，实现深度学习在小样本上的有效采用。另外，该方法还具有适应电网结构变化的能力，通过探索不同缺陷之间的连接关系。</li>
<li>results: 对于IEEE 39-bus试验系统，提出的方法可以通过转移学习提高评估精度约20%，并且具有强大的适应电网结构变化能力。与浅学习方法和其他深度学习基于方法相比，该方法具有显著的优势，特别是通过使用Transformer模型中的自注意机制。<details>
<summary>Abstract</summary>
Deep learning has emerged as an effective solution for addressing the challenges of short-term voltage stability assessment (STVSA) in power systems. However, existing deep learning-based STVSA approaches face limitations in adapting to topological changes, sample labeling, and handling small datasets. To overcome these challenges, this paper proposes a novel phasor measurement unit (PMU) measurements-based STVSA method by using deep transfer learning. The method leverages the real-time dynamic information captured by PMUs to create an initial dataset. It employs temporal ensembling for sample labeling and utilizes least squares generative adversarial networks (LSGAN) for data augmentation, enabling effective deep learning on small-scale datasets. Additionally, the method enhances adaptability to topological changes by exploring connections between different faults. Experimental results on the IEEE 39-bus test system demonstrate that the proposed method improves model evaluation accuracy by approximately 20% through transfer learning, exhibiting strong adaptability to topological changes. Leveraging the self-attention mechanism of the Transformer model, this approach offers significant advantages over shallow learning methods and other deep learning-based approaches.
</details>
<details>
<summary>摘要</summary>
深度学习已成为电力系统短期电压稳定评估（STVSA）的有效解决方案。然而，现有的深度学习基于STVSA方法存在适应性改变和小样本标注的限制。为了突破这些挑战，本文提出了一种基于phasor measurement unit（PMU）测量的新型STVSA方法。该方法利用PMU在实时动态信息中捕捉到的实际数据来创建初始数据集。它采用时间ensemble для样本标注，并使用最小二乘生成整形网络（LSGAN）进行数据扩展，以便在小规模数据集上进行深度学习。此外，该方法增强了 topological change 的适应性，通过探索不同的缺陷之间的连接。实验结果表明，该方法在IEEE 39-bus测试系统上提高了模型评估精度约20%，并且具有强大的适应性。基于Transformer模型的自注意机制，这种方法在对比浅学习方法和其他深度学习基于方法上表现出了显著优势。
</details></li>
</ul>
<hr>
<h2 id="The-Prospect-of-Enhancing-Large-Scale-Heterogeneous-Federated-Learning-with-Transformers"><a href="#The-Prospect-of-Enhancing-Large-Scale-Heterogeneous-Federated-Learning-with-Transformers" class="headerlink" title="The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers"></a>The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03945">http://arxiv.org/abs/2308.03945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulan Gao, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Han Yu</li>
<li>for: This paper investigates the use of Transformer-based federated learning (FL) models for achieving generalization and personalization in large-scale, heterogeneous FL tasks.</li>
<li>methods: The paper compares the performance of Transformer-based FL models with other deep neural network-based approaches, including ResNet and personalized ResNet-based FL, under various scenarios with varying numbers of data owners.</li>
<li>results: The paper shows that Transformer-based FL models outperform other approaches in large-scale, heterogeneous FL tasks, and provides insight into the reasons behind their superior performance through analysis of the Centered Kernel Alignment (CKA) representation similarity across different layers and FL models.<details>
<summary>Abstract</summary>
Federated learning (FL) addresses data privacy concerns by enabling collaborative training of AI models across distributed data owners. Wide adoption of FL faces the fundamental challenges of data heterogeneity and the large scale of data owners involved. In this paper, we investigate the prospect of Transformer-based FL models for achieving generalization and personalization in this setting. We conduct extensive comparative experiments involving FL with Transformers, ResNet, and personalized ResNet-based FL approaches under various scenarios. These experiments consider varying numbers of data owners to demonstrate Transformers' advantages over deep neural networks in large-scale heterogeneous FL tasks. In addition, we analyze the superior performance of Transformers by comparing the Centered Kernel Alignment (CKA) representation similarity across different layers and FL models to gain insight into the reasons behind their promising capabilities.
</details>
<details>
<summary>摘要</summary>
合作学习（FL）解决了数据隐私问题，通过在分布式数据所有者之间进行AI模型的共同训练。随着FL的广泛应用，面临着数据不一致和数据所有者的大规模挑战。本文 investigate了使用Transformer-based FL模型来实现泛化和个性化在这种情况下。我们进行了对FL与Transformers、ResNet和个性化ResNet-based FL方法的比较性实验，包括不同数据所有者的场景。这些实验演示了Transformers在大规模不一致FL任务中的优势。此外，我们还分析了CKA表示相似性的中心kernel对FL模型的性能提高的原因。
</details></li>
</ul>
<hr>
<h2 id="GraPhSyM-Graph-Physical-Synthesis-Model"><a href="#GraPhSyM-Graph-Physical-Synthesis-Model" class="headerlink" title="GraPhSyM: Graph Physical Synthesis Model"></a>GraPhSyM: Graph Physical Synthesis Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03944">http://arxiv.org/abs/2308.03944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Agiza, Rajarshi Roy, Teodor Dumitru Ene, Saad Godil, Sherief Reda, Bryan Catanzaro</li>
<li>For: 预计算机化电路延迟和面积指标的快速和准确估算。* Methods: 使用图structure、连接性和电学性特征来预测物理合成变换的影响，并通过图注意力网络模型（GATv2）进行预测。* Results: 在6000个预测器添加器设计中训练GraPhSyM模型，可以快速和准确地预测未看过的添加器延迟和面积指标（98.3%和96.1%），并且可以在不同的延迟目标下精确预测添加器延迟和面积指标。<details>
<summary>Abstract</summary>
In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model for fast and accurate estimation of post-physical synthesis circuit delay and area metrics from pre-physical synthesis circuit netlists. Once trained, GraPhSyM provides accurate visibility of final design metrics to early EDA stages, such as logic synthesis, without running the slow physical synthesis flow, enabling global co-optimization across stages. Additionally, the swift and precise feedback provided by GraPhSym is instrumental for machine-learning-based EDA optimization frameworks. Given a gate-level netlist of a circuit represented as a graph, GraPhSyM utilizes graph structure, connectivity, and electrical property features to predict the impact of physical synthesis transformations such as buffer insertion and gate sizing. When trained on a dataset of 6000 prefix adder designs synthesized at an aggressive delay target, GraPhSyM can accurately predict the post-synthesis delay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s inference time. Furthermore, we illustrate the compositionality of GraPhSyM by employing the model trained on a fixed delay target to accurately anticipate post-synthesis metrics at a variety of unseen delay targets. Lastly, we report promising generalization capabilities of the GraPhSyM model when it is evaluated on circuits different from the adders it was exclusively trained on. The results show the potential for GraPhSyM to serve as a powerful tool for advanced optimization techniques and as an oracle for EDA machine learning frameworks.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们引入了GraPhSyM模型，它是基于图注意力网络（GATv2）的一种快速和准确地计算逻辑电路延迟和面积指标的模型。一旦训练完成，GraPhSyM可以在普通逻辑合成阶段提供准确的最终设计指标视图，不需要执行慢速物理合成流程，从而实现全球协调。此外，GraPhSyM提供了快速和准确的反馈，这对机器学习基于EDA优化框架是非常有利的。给定一个逻辑电路的门级网络表示，GraPhSyM利用图结构、连接性和电学性特征来预测物理合成转换（如缓冲插入和ゲート大小调整）后的影响。当训练在6000个逻辑加法器的逻辑合成过程中，GraPhSyM可以准确预测未看过的加法器延迟（98.3%）和面积（96.1%）指标，并且具有0.22秒的快速推理时间。此外，我们证明了GraPhSyM模型的可组合性，可以使用已训练的固定延迟目标来准确预测未看过的延迟目标。最后，我们报告了GraPhSyM模型在不同于它专门训练的逻辑加法器上的良好泛化能力。结果表明，GraPhSyM可能成为高级优化技术和EDA机器学习框架的强大工具。
</details></li>
</ul>
<hr>
<h2 id="The-Compatibility-between-the-Pangu-Weather-Forecasting-Model-and-Meteorological-Operational-Data"><a href="#The-Compatibility-between-the-Pangu-Weather-Forecasting-Model-and-Meteorological-Operational-Data" class="headerlink" title="The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data"></a>The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04460">http://arxiv.org/abs/2308.04460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wencong Cheng, Yan Yan, Jiangjiang Xia, Qi Liu, Chang Qu, Zhigang Wang</li>
<li>for: 这 paper 是为了评估 Pangu-Weather 模型与各种常用的 NWP 操作分析相容性。</li>
<li>methods: 这 paper 使用了 Pangu-Weather 模型，并通过 caso studies 评估了模型与不同 NWP 系统的操作分析之间的 compatibilty。</li>
<li>results: 结果表明，Pangu-Weather 模型与不同的操作分析相容，并且可以提高初始条件质量以提高预测性能。<details>
<summary>Abstract</summary>
Recently, multiple data-driven models based on machine learning for weather forecasting have emerged. These models are highly competitive in terms of accuracy compared to traditional numerical weather prediction (NWP) systems. In particular, the Pangu-Weather model, which is open source for non-commercial use, has been validated for its forecasting performance by the European Centre for Medium-Range Weather Forecasts (ECMWF) and has recently been published in the journal "Nature". In this paper, we evaluate the compatibility of the Pangu-Weather model with several commonly used NWP operational analyses through case studies. The results indicate that the Pangu-Weather model is compatible with different operational analyses from various NWP systems as the model initial conditions, and it exhibits a relatively stable forecasting capability. Furthermore, we have verified that improving the quality of global or local initial conditions significantly contributes to enhancing the forecasting performance of the Pangu-Weather model.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:近期，基于机器学习的多种气象预报模型已经出现，与传统的数值天气预测系统（NWP）相比，它们的准确性非常高。特别是Pangu-Weather模型，该模型为非商业用途开源，在ECMWF（欧洲中期天气预测中心）的验证下，最近发表在《自然》杂志上。在这篇论文中，我们通过实例研究了Pangu-Weather模型与各种常用的NWP操作分析相容性。结果表明，Pangu-Weather模型可以与不同的NWP系统的操作分析相容，并且在初始条件质量提高后，预报性能有所提高。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-the-switching-operation-in-monoclonal-antibody-production-Economic-MPC-and-reinforcement-learning"><a href="#Optimizing-the-switching-operation-in-monoclonal-antibody-production-Economic-MPC-and-reinforcement-learning" class="headerlink" title="Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning"></a>Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03928">http://arxiv.org/abs/2308.03928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra A. Obiri, Song Bo, Bernard T. Agyeman, Benjamin Decardi-Nelson, Jinfeng Liu</li>
<li>for: 这paper的目的是提出了一种可靠的、高效的continuous manufacturing process для大规模生产monoclonal antibodies (mAbs)。</li>
<li>methods: 这paper使用了经济模控算法（EMPC）和深度强化学习（DRL）来优化连续生产过程中的换 columns操作。</li>
<li>results: 这paper的实验结果表明，使用sigmoid function approximation approach和ReLU approximation approach可以提高连续生产过程的效率和质量，而传统的 switching approach based on 1% product breakthrough rule则不能达到这样的效果。<details>
<summary>Abstract</summary>
Monoclonal antibodies (mAbs) have emerged as indispensable assets in medicine, and are currently at the forefront of biopharmaceutical product development. However, the growing market demand and the substantial doses required for mAb clinical treatments necessitate significant progress in its large-scale production. Most of the processes for industrial mAb production rely on batch operations, which result in significant downtime. The shift towards a fully continuous and integrated manufacturing process holds the potential to boost product yield and quality, while eliminating the extra expenses associated with storing intermediate products. The integrated continuous mAb production process can be divided into the upstream and downstream processes. One crucial aspect that ensures the continuity of the integrated process is the switching of the capture columns, which are typically chromatography columns operated in a fed-batch manner downstream. Due to the discrete nature of the switching operation, advanced process control algorithms such as economic MPC (EMPC) are computationally difficult to implement. This is because an integer nonlinear program (INLP) needs to be solved online at each sampling time. This paper introduces two computationally-efficient approaches for EMPC implementation, namely, a sigmoid function approximation approach and a rectified linear unit (ReLU) approximation approach. It also explores the application of deep reinforcement learning (DRL). These three methods are compared to the traditional switching approach which is based on a 1% product breakthrough rule and which involves no optimization.
</details>
<details>
<summary>摘要</summary>
单核球抗体（mAb）在医疗中已经成为不可或缺的资产，目前在生物制药产品开发中扮演了前列的角色。然而，增长的市场需求和大量的药品临床使用需要大幅提高大规模生产的效率。现有的大规模生产过程大多数采用批量操作，它们导致了很大的下时间。将生产过程推向完全连续和整合的制程可以提高产品的收益和质量，同时消除储存中间产品的额外成本。生产过程中的连续过程可以分为上游和下游过程。一个重要的确保连续过程的因素是捕捉Column的转换，它们通常是在下游过程中运行的牛顿批量方式。由于这个离散的转换操作，高级的调控算法如经济多项式控制（EMPC）在computationally具有问题。这是因为在每个样本时间点上需要解决一个数学问题。这篇文章介绍了三种 computationally-efficient的EMPC实现方法，namely，σ函数近似方法和Rectified Linear Unit（ReLU）近似方法。它还探讨了深度征兆学习（DRL）的应用。这三种方法与传统的转换方法，基于1%产品破坏规则，并不含优化。
</details></li>
</ul>
<hr>
<h2 id="Spellburst-A-Node-based-Interface-for-Exploratory-Creative-Coding-with-Natural-Language-Prompts"><a href="#Spellburst-A-Node-based-Interface-for-Exploratory-Creative-Coding-with-Natural-Language-Prompts" class="headerlink" title="Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts"></a>Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03921">http://arxiv.org/abs/2308.03921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tyler Angert, Miroslav Ivan Suzara, Jenny Han, Christopher Lawrence Pondoc, Hariharan Subramonyam</li>
<li>for: This paper aims to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.</li>
<li>methods: The paper introduces Spellburst, a large language model (LLM) powered creative-coding environment that provides a node-based interface, expressive prompt-based interactions, and dynamic prompt-driven interfaces and direct code editing.</li>
<li>results: The paper evaluates Spellburst with artists and demonstrates its potential to enhance creative coding practices and inform the design of computational creativity tools.<details>
<summary>Abstract</summary>
Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a "stained glass filter" and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don't lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation with artists demonstrates Spellburst's potential to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.
</details>
<details>
<summary>摘要</summary>
创造性编程任务经常具有探索性质。当生成数字艺术作品时，艺术家通常从高水平semantic construct开始，如镜面纹理滤波器，然后通过代码参数的变化，如形状、颜色、线条和透明度，来生成visually appealing的结果。根据艺术家的采访，将semantic constructs翻译成编程语法可能会困难，现有的编程工具也不适合快速的创造性探索。为解决这些挑战，我们介绍Spellburst，一个基于大语言模型（LLM）的创造性编程环境。Spellburst提供以下特性：1. 节点基本的界面，允许艺术家通过分支和合并操作来生成生成艺术作品并探索不同的变化。2. 表达式基本的交互方式，让艺术家通过自然语言提示来参与semantic programming。3. dinamic prompt-driven界面和直接代码编辑，允许艺术家轻松地在semantic和syntactic空间之间转换。我们的评估表明，Spellburst可以提高创造性编程实践，并为计算创ativity工具的设计提供指导。
</details></li>
</ul>
<hr>
<h2 id="Predicting-and-explaining-nonlinear-material-response-using-deep-Physically-Guided-Neural-Networks-with-Internal-Variables"><a href="#Predicting-and-explaining-nonlinear-material-response-using-deep-Physically-Guided-Neural-Networks-with-Internal-Variables" class="headerlink" title="Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables"></a>Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03915">http://arxiv.org/abs/2308.03915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier Orera-Echeverria, Jacobo Ayensa-Jiménez, Manuel Doblare</li>
<li>for: 这篇论文是为了探讨非线性材料模型化的问题，尤其是使用 físicamente guided neural networks with internal variables (PGNNIV) 方法来找出 constitutive laws。</li>
<li>methods: 这篇论文使用了PGNNIV方法，这是一种基于物理定义的神经网络方法，通过对压缩数据进行训练，可以预测 external 和 internal 变量，无需内部变量数据。</li>
<li>results: 研究发现，PGNNIV 方法可以预测不同类型材料（线性、硬化、软化）的 external 和 internal 变量，并且可以解释材料的 constitutive law，属于 Explainable Artificial Intelligence (XAI) 领域。<details>
<summary>Abstract</summary>
Nonlinear materials are often difficult to model with classical state model theory because they have a complex and sometimes inaccurate physical and mathematical description or we simply do not know how to describe such materials in terms of relations between external and internal variables. In many disciplines, Neural Network methods have arisen as powerful tools to identify very complex and non-linear correlations. In this work, we use the very recently developed concept of Physically Guided Neural Networks with Internal Variables (PGNNIV) to discover constitutive laws using a model-free approach and training solely with measured force-displacement data. PGNNIVs make a particular use of the physics of the problem to enforce constraints on specific hidden layers and are able to make predictions without internal variable data. We demonstrate that PGNNIVs are capable of predicting both internal and external variables under unseen load scenarios, regardless of the nature of the material considered (linear, with hardening or softening behavior and hyperelastic), unravelling the constitutive law of the material hence explaining its nature altogether, placing the method in what is known as eXplainable Artificial Intelligence (XAI).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition"><a href="#ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition" class="headerlink" title="ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition"></a>ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03908">http://arxiv.org/abs/2308.03908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumyabrata Chaudhuri, Saumik Bhattacharya</li>
<li>for: 这个论文旨在提出一种基于多modal学习的人体动作识别方法，以提高人体动作识别的准确率。</li>
<li>methods: 该方法使用了视觉信息（RGB模式）和人体姿态信息（2D skeleton或pose模式），并将这两种模式与文本特征相结合，以提高人体动作识别的精度。</li>
<li>results: 该方法在两个人体动作识别 benchmark dataset（UCF-101和HMDB-51）上达到了92.81%和73.02%的准确率，而无需视频数据预训练，并且 после kinetics 预训练，准确率提高至96.11%和75.75%。<details>
<summary>Abstract</summary>
Video Action Recognition (VAR) is a challenging task due to its inherent complexities. Though different approaches have been explored in the literature, designing a unified framework to recognize a large number of human actions is still a challenging problem. Recently, Multi-Modal Learning (MML) has demonstrated promising results in this domain. In literature, 2D skeleton or pose modality has often been used for this task, either independently or in conjunction with the visual information (RGB modality) present in videos. However, the combination of pose, visual information, and text attributes has not been explored yet, though text and pose attributes independently have been proven to be effective in numerous computer vision tasks. In this paper, we present the first pose augmented Vision-language model (VLM) for VAR. Notably, our scheme achieves an accuracy of 92.81% and 73.02% on two popular human video action recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even without any video data pre-training, and an accuracy of 96.11% and 75.75% after kinetics pre-training.
</details>
<details>
<summary>摘要</summary>
视频动作识别（VAR）是一项复杂的任务，具有内在的复杂性。不同的方法在文献中已经被探讨，但设计一个统一的框架来识别大量人类动作仍然是一个挑战。近年来，多模态学习（MML）已经在这个领域展现出了有前途的成绩。在文献中，2D骨骼或姿势特征经常用于这项任务，可以独立或与视觉信息（RGB模式）一起使用。然而，将姿势、视觉信息和文本特征结合使用还没有被探讨，尽管姿势特征和文本特征独立地已经在计算机视觉任务中证明有效。在本文中，我们首次提出了一种姿势增强的视觉语言模型（VLM），并实现了92.81%和73.02%的准确率在两个流行的人类视频动作识别标准 dataset（UCF-101和HMDB-51）中，而无需任何视频数据预训练，并且在预训练后达到96.11%和75.75%的准确率。
</details></li>
</ul>
<hr>
<h2 id="Advancements-In-Crowd-Monitoring-System-A-Comprehensive-Analysis-of-Systematic-Approaches-and-Automation-Algorithms-State-of-The-Art"><a href="#Advancements-In-Crowd-Monitoring-System-A-Comprehensive-Analysis-of-Systematic-Approaches-and-Automation-Algorithms-State-of-The-Art" class="headerlink" title="Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art"></a>Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03907">http://arxiv.org/abs/2308.03907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Ameen, Richard Stone</li>
<li>for: 这篇论文主要关注于如何提供可靠和安全的人群监测系统，以满足现在全球各地政府和安全机构对公共安全的担忧。</li>
<li>methods: 这篇论文将研究两种方法：视觉基础的技术和非视觉基础的技术，并进行深入的分析，以了解它们在不同的环境和时间上的效果。</li>
<li>results: 这篇论文将强调现代应用程序和人工智能算法在自动化系统中的应用，以及它们在不同情况下的效果。<details>
<summary>Abstract</summary>
Growing apprehensions surrounding public safety have captured the attention of numerous governments and security agencies across the globe. These entities are increasingly acknowledging the imperative need for reliable and secure crowd-monitoring systems to address these concerns. Effectively managing human gatherings necessitates proactive measures to prevent unforeseen events or complications, ensuring a safe and well-coordinated environment. The scarcity of research focusing on crowd monitoring systems and their security implications has given rise to a burgeoning area of investigation, exploring potential approaches to safeguard human congregations effectively. Crowd monitoring systems depend on a bifurcated approach, encompassing vision-based and non-vision-based technologies. An in-depth analysis of these two methodologies will be conducted in this research. The efficacy of these approaches is contingent upon the specific environment and temporal context in which they are deployed, as they each offer distinct advantages. This paper endeavors to present an in-depth analysis of the recent incorporation of artificial intelligence (AI) algorithms and models into automated systems, emphasizing their contemporary applications and effectiveness in various contexts.
</details>
<details>
<summary>摘要</summary>
全球各地政府和安全机构都有增长的担忧，即使是公众安全的问题。这些机构认为，有效地管理人群聚集需要采取积极措施，以防止意外事件或复杂的情况，确保安全和有效的环境。由于关于人群监测系统的研究不够，这个领域在过去几年中得到了快速发展。人群监测系统通常采用分两部分的方法：视觉基本的和非视觉基本的技术。本研究将进行深入的分析这两种方法，并评估它们在不同的环境和时间上的效果。此外，本文还将评估人群监测系统中的人工智能（AI）算法和模型的应用，包括它们在不同情况下的当代应用和效果。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Assistant-Language-Understanding-On-Device"><a href="#Intelligent-Assistant-Language-Understanding-On-Device" class="headerlink" title="Intelligent Assistant Language Understanding On Device"></a>Intelligent Assistant Language Understanding On Device</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03905">http://arxiv.org/abs/2308.03905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Cecilia Aas, Hisham Abdelsalam, Irina Belousova, Shruti Bhargava, Jianpeng Cheng, Robert Daland, Joris Driesen, Federico Flego, Tristan Guigue, Anders Johannsen, Partha Lal, Jiarui Lu, Joel Ruben Antony Moniz, Nathan Perkins, Dhivya Piraviperumal, Stephen Pulman, Diarmuid Ó Séaghdha, David Q. Sun, John Torr, Marco Del Vecchio, Jay Wacker, Jason D. Williams, Hong Yu</li>
<li>for: 这篇论文目标是描述一种运行于个人设备上的自然语言理解系统的设计。</li>
<li>methods: 该系统采用了一些选择的建筑和技术，例如在对话系统文献中一些方法可能在部署环境中困难维护。</li>
<li>results: 该系统比服务器端助手更加私钥、可靠、快速、表达力强、准确。<details>
<summary>Abstract</summary>
It has recently become feasible to run personal digital assistants on phones and other personal devices. In this paper we describe a design for a natural language understanding system that runs on device. In comparison to a server-based assistant, this system is more private, more reliable, faster, more expressive, and more accurate. We describe what led to key choices about architecture and technologies. For example, some approaches in the dialog systems literature are difficult to maintain over time in a deployment setting. We hope that sharing learnings from our practical experiences may help inform future work in the research community.
</details>
<details>
<summary>摘要</summary>
现在可以在手机和其他个人设备上运行个人数字助手。在这篇论文中，我们描述了一种运行于设备上的自然语言理解系统的设计。相比服务器基于的助手，这种系统更加私钥、可靠、快速、表达力 stronger和更准确。我们介绍了一些关键的架构和技术选择的原因。例如，一些对话系统文献中的方法在部署环境中具有困难维护的特点。我们希望通过分享我们的实践经验，可以对未来的研究工作产生影响。
</details></li>
</ul>
<hr>
<h2 id="On-genuine-invariance-learning-without-weight-tying"><a href="#On-genuine-invariance-learning-without-weight-tying" class="headerlink" title="On genuine invariance learning without weight-tying"></a>On genuine invariance learning without weight-tying</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03904">http://arxiv.org/abs/2308.03904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amoskalev/ginvariance">https://github.com/amoskalev/ginvariance</a></li>
<li>paper_authors: Artem Moskalev, Anna Sepliarskaia, Erik J. Bekkers, Arnold Smeulders</li>
<li>for: 本研究探讨神经网络学习的不变性和其限制，并与固定权重绑定的真正不变性进行比较。</li>
<li>methods: 作者采用群理论的视角分析神经网络的不变性学习，并未受权重绑定的限制。他们发现，即使神经网络能够正确地分类样本，但是下面的决策不具有真正的不变性。</li>
<li>results: 作者提出了几种度量学习不变性的指标，包括预测分布不变性、对数不变性和响应不变性相似性。他们发现，通过在训练过程中加权error regularization来引导学习不变性，可以使得神经网络学习的不变性与固定权重绑定模型的不变性相似。<details>
<summary>Abstract</summary>
In this paper, we investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying. To do so, we adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints. We demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance. Instead, learned invariance is strongly conditioned on the input data, rendering it unreliable if the input distribution shifts. We next demonstrate how to guide invariance learning toward genuine invariance by regularizing the invariance of a model at the training. To this end, we propose several metrics to quantify learned invariance: (i) predictive distribution invariance, (ii) logit invariance, and (iii) saliency invariance similarity. We show that the invariance learned with the invariance error regularization closely reassembles the genuine invariance of weight-tying models and reliably holds even under a severe input distribution shift. Closer analysis of the learned invariance also reveals the spectral decay phenomenon, when a network chooses to achieve the invariance to a specific transformation group by reducing the sensitivity to any input perturbation.
</details>
<details>
<summary>摘要</summary>
本文研究神经网络学习的不变性和其限制，并与真正的不变性相比较。为此，我们采用群理论的视角，分析神经网络没有重量约束时的不变性学习。我们发现，即使神经网络能正确地分类样本，其下面的决策过程并不具有真正的不变性。相反，学习的不变性受到输入数据的强烈条件，因此在输入分布变化时变得不可靠。我们后来提出了一些度量学习的不变性的指标，包括预测分布不变性、Logit不变性和吸引力不变性相似性。我们发现，通过不变性错误规范来帮助学习不变性可以很好地寄存真正的不变性，并且可以在输入分布变化时保持稳定。进一步分析学习的不变性还发现，神经网络会选择通过减少输入变化的敏感度来实现不变性。
</details></li>
</ul>
<hr>
<h2 id="FLIPS-Federated-Learning-using-Intelligent-Participant-Selection"><a href="#FLIPS-Federated-Learning-using-Intelligent-Participant-Selection" class="headerlink" title="FLIPS: Federated Learning using Intelligent Participant Selection"></a>FLIPS: Federated Learning using Intelligent Participant Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03901">http://arxiv.org/abs/2308.03901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Atul Bhope, K. R. Jayaram, Nalini Venkatasubramanian, Ashish Verma, Gegi Thomas</li>
<li>for: 这篇论文旨在设计和实现一个基于中间件的聚合系统，用于管理数据和参与者多样性在联合学习训练任务中。具体来说，文章研究了在联合学习训练中使用标签分布划分的参与者选择方法的效果。</li>
<li>methods: 文章使用了标签分布划分来 clustering 参与者，并在联合学习训练过程中确保每个群组都具有相对的代表性。文章还 incorporates 一种异常管理机制来处理分布式环境中的资源变化。</li>
<li>results: 文章的实验比较了 FLIPS 与随机选择、Oort 和梯度划分等三种 “聪明” 选择方法，并在两个真实世界数据集和三种常见的联合学习算法（FedYogi、FedProx 和 FedAvg）上进行了广泛的 empirical evaluation。结果表明，FLIPS 可以提高收敛率，并在具有延迟参与者的情况下保持高度的准确率，这些优点在不同的分布式环境和资源条件下也能够持续。<details>
<summary>Abstract</summary>
This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as two other "smart" selection mechanisms - Oort and gradient clustering using two real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17 - 20 % with 20 - 60 % lower communication costs, and these benefits endure in the presence of straggler participants.
</details>
<details>
<summary>摘要</summary>
Empirical evaluation compares FLIPS with random participant selection, as well as two other "smart" selection mechanisms - Oort and gradient clustering. The results show that FLIPS significantly improves convergence, achieving higher accuracy by 17-20% with 20-60% lower communication costs. These benefits persist even in the presence of straggler participants. The paper uses two real-world datasets, two different non-IID distributions, and three common FL algorithms (FedYogi, FedProx, and FedAvg) to demonstrate the effectiveness of FLIPS.
</details></li>
</ul>
<hr>
<h2 id="Scalable-and-Equitable-Math-Problem-Solving-Strategy-Prediction-in-Big-Educational-Data"><a href="#Scalable-and-Equitable-Math-Problem-Solving-Strategy-Prediction-in-Big-Educational-Data" class="headerlink" title="Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data"></a>Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03892">http://arxiv.org/abs/2308.03892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anupshakya07/attn-scaling">https://github.com/anupshakya07/attn-scaling</a></li>
<li>paper_authors: Anup Shakya, Vasile Rus, Deepak Venugopal</li>
<li>for: 这项研究的目的是提高学生数学学习的效果，使用智能教育系统（ITS）和适应教学系统（AIS）。</li>
<li>methods: 该研究使用机器学习和人工智能技术，开发了一种名为MVec的嵌入，以学习学生的掌握度表示。然后使用非 Parametric 聚类方法，将这些嵌入分成不同的群集。最后，使用Transformers和Node2Vec进行学习mastery embedding，并使用LSTM进行策略预测。</li>
<li>results: 该研究可以在大规模学生互动数据集上实现高精度的策略预测，并且具有预测平等性，即可以平等地预测学生的策略水平。<details>
<summary>Abstract</summary>
Understanding a student's problem-solving strategy can have a significant impact on effective math learning using Intelligent Tutoring Systems (ITSs) and Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better personalize itself to correct specific misconceptions that are indicated by incorrect strategies, specific problems can be designed to improve strategies and frustration can be minimized by adapting to a student's natural way of thinking rather than trying to fit a standard strategy for all. While it may be possible for human experts to identify strategies manually in classroom settings with sufficient student interaction, it is not possible to scale this up to big data. Therefore, we leverage advances in Machine Learning and AI methods to perform scalable strategy prediction that is also fair to students at all skill levels. Specifically, we develop an embedding called MVec where we learn a representation based on the mastery of students. We then cluster these embeddings with a non-parametric clustering method where we progressively learn clusters such that we group together instances that have approximately symmetrical strategies. The strategy prediction model is trained on instances sampled from these clusters. This ensures that we train the model over diverse strategies and also that strategies from a particular group do not bias the DNN model, thus allowing it to optimize its parameters over all groups. Using real world large-scale student interaction datasets from MATHia, we implement our approach using transformers and Node2Vec for learning the mastery embeddings and LSTMs for predicting strategies. We show that our approach can scale up to achieve high accuracy by training on a small sample of a large dataset and also has predictive equality, i.e., it can predict strategies equally well for learners at diverse skill levels.
</details>
<details>
<summary>摘要</summary>
理解学生的问题解决策略可以对智能教学系统（ITS）和适应教学系统（AIS）的有效学习产生重要影响。例如，ITS/AIS可以更好地个性化自己，根据学生提交的错误策略来更正特定的误解，设计特定问题以提高策略，并降低学生的沮丧情绪，而不是强制学生遵循标准策略。虽然在教室 SETTINGS 中，人工专家可能可以手动确定策略，但不可能扩大到大数据。因此，我们利用机器学习和人工智能技术进行可扩展的策略预测，并保证该方法对所有技能水平的学生是公平的。我们开发了一个名为 MVec 的嵌入，其中我们学习基于学生的尝试情况的表示。然后，我们使用非Parametric 分 clustering方法，将这些嵌入进行分组，以便将相似策略的实例相互分组。我们的策略预测模型是基于这些分组的实例进行训练的。这种方法可以扩大到达到高准确率，并且有Predictive Equality 性，即它可以平等地预测学生的策略，无论他们的技能水平如何。使用实际世界的大规模学生互动数据集，我们使用 transformers 和 Node2Vec 来学习尝试情况的尝试情况，并使用 LSTM 来预测策略。我们的方法可以扩大到达到高准确率，并且有Predictive Equality 性。
</details></li>
</ul>
<hr>
<h2 id="Generative-Benchmark-Creation-for-Table-Union-Search"><a href="#Generative-Benchmark-Creation-for-Table-Union-Search" class="headerlink" title="Generative Benchmark Creation for Table Union Search"></a>Generative Benchmark Creation for Table Union Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03883">http://arxiv.org/abs/2308.03883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/northeastern-datalab/alt-gen">https://github.com/northeastern-datalab/alt-gen</a></li>
<li>paper_authors: Koyena Pal, Aamod Khatiwada, Roee Shraga, Renée J. Miller<br>for: tables union search benchmarkmethods: generative AI models large language modelsresults: new benchmark more challenging for existing methods top-performing method achieves lower Mean Average Precision on new benchmark compared to existing manually created benchmarks detailed analysis of methods possible with new benchmark<details>
<summary>Abstract</summary>
Data management has traditionally relied on synthetic data generators to generate structured benchmarks, like the TPC suite, where we can control important parameters like data size and its distribution precisely. These benchmarks were central to the success and adoption of database management systems. But more and more, data management problems are of a semantic nature. An important example is finding tables that can be unioned. While any two tables with the same cardinality can be unioned, table union search is the problem of finding tables whose union is semantically coherent. Semantic problems cannot be benchmarked using synthetic data. Our current methods for creating benchmarks involve the manual curation and labeling of real data. These methods are not robust or scalable and perhaps more importantly, it is not clear how robust the created benchmarks are. We propose to use generative AI models to create structured data benchmarks for table union search. We present a novel method for using generative models to create tables with specified properties. Using this method, we create a new benchmark containing pairs of tables that are both unionable and non-unionable but related. We thoroughly evaluate recent existing table union search methods over existing benchmarks and our new benchmark. We also present and evaluate a new table search methods based on recent large language models over all benchmarks. We show that the new benchmark is more challenging for all methods than hand-curated benchmarks, specifically, the top-performing method achieves a Mean Average Precision of around 60%, over 30% less than its performance on existing manually created benchmarks. We examine why this is the case and show that the new benchmark permits more detailed analysis of methods, including a study of both false positives and false negatives that were not possible with existing benchmarks.
</details>
<details>
<summary>摘要</summary>
传统上，数据管理受到人工生成的数据生成器的限制，如TPC集成，以控制数据大小和分布的重要参数。这些标准 benchmark 对数据库管理系统的采用和普及做出了重要贡献。然而，随着数据管理问题的 semanticization，人工生成的数据不能满足需求。我们的当前方法是通过手动筛选和标注实际数据来创建 benchmark。这些方法不具有可靠性和扩展性，而且无法确定创建的标准 benchmark 的可靠性。我们提议使用生成 AI 模型创建结构化数据 benchmark。我们介绍了一种使用生成模型创建表 avec 指定属性的方法。使用这种方法，我们创建了一个新的标准 benchmark，其中包含可 union 和不可 union 的表对。我们进行了现有benchmark和我们新创建的benchmark上现有方法的严格评估。我们还介绍了基于最新大语言模型的新表搜索方法，并对所有benchmark进行评估。我们发现新benchmark比手动创建的benchmark更加具有挑战性，特别是最高级performing方法在新benchmark上的 Mean Average Precision 约为 60%，相比手动创建 benchmark 上的表现下降了30%。我们分析了这种情况，并证明新benchmark允许更加细致的方法分析，包括对方法的false positives和false negatives进行研究，这些研究不可能通过现有benchmark进行。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations"><a href="#Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations" class="headerlink" title="Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations"></a>Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03882">http://arxiv.org/abs/2308.03882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirbhay Modhe, Qiaozi Gao, Ashwin Kalyan, Dhruv Batra, Govind Thattai, Gaurav Sukhatme</li>
<li>for: 这篇论文是关于线上强化学习（RL）方法的研究，它们可以寻找未经见过的状态和动作。</li>
<li>methods: 这些方法使用保守的价值估计，对未经见过的状态和动作进行惩罚，以保证在探索和利用之间寻找平衡。</li>
<li>results: 研究人员通过提出一种新的未经见过状态扩展策略，使得RL方法能够更好地找到未经见过的状态，并且可以更好地适应不同的任务。此外，他们还发现，使用这种扩展策略可以降低平均数据集Q估计的值，即更保守的估计。<details>
<summary>Abstract</summary>
Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to seen data). We observe improved performance in several offline RL tasks and find that our augmentation strategy consistently leads to overall lower average dataset Q-value estimates i.e. more conservative Q-value estimates than a baseline.
</details>
<details>
<summary>摘要</summary>
在线RL方法寻求 между探索和占用的平衡，通过保守的价值估计---对未见的状态和动作进行惩罚。无模型方法对所有未见动作进行惩罚，而模型基于方法可以通过模型执行来进一步利用未见状态。然而，这些方法在找到未见状态的远程处理方面受到两个因素的限制：1. 在模型中的很短执行 horizon，由于链式模型错误而导致。2. 模型执行仅从看到的Offline数据中的状态开始。我们relax这个第二个假设，并提出一种新的未见状态扩充策略，以便在已学习的模型和价值估计中进行扩充。我们的策略通过值指导的扰动seen状态，然后过滤出epistemicuncertainty度量过高（高错误）或过低（太相似于seen数据）的状态。我们发现在多个OfflineRL任务中表现出色，并发现我们的扩充策略通常比基线靠前。我们的augmentation策略通过在seen状态中进行值指导的扰动，以及过滤出高错误或太相似于seen数据的状态来实现。这使得我们的价值估计更加保守，并且在多个OfflineRL任务中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-and-Explaining-Large-Language-Models-for-Code-Using-Syntactic-Structures"><a href="#Evaluating-and-Explaining-Large-Language-Models-for-Code-Using-Syntactic-Structures" class="headerlink" title="Evaluating and Explaining Large Language Models for Code Using Syntactic Structures"></a>Evaluating and Explaining Large Language Models for Code Using Syntactic Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03873">http://arxiv.org/abs/2308.03873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wm-semeru/codesyntaxconcept">https://github.com/wm-semeru/codesyntaxconcept</a></li>
<li>paper_authors: David N Palacio, Alejandro Velasco, Daniel Rodriguez-Cardenas, Kevin Moran, Denys Poshyvanyk</li>
<li>for: This paper aims to provide a new method for explaining the predictions of large language models (LLMs) for code, called ASTxplainer, which can be used to evaluate the effectiveness of these models and help end-users understand their predictions.</li>
<li>methods: The paper proposes a novel approach called ASTxplainer, which aligns token predictions with abstract syntax trees (ASTs) to provide a fine-grained understanding of LLM predictions. The method extracts and aggregates normalized model logits within AST structures to provide insights into model behavior.</li>
<li>results: The paper presents the results of an empirical evaluation on 12 popular LLMs for code using a curated dataset of the most popular GitHub projects. The results show that ASTxplainer can provide valuable insights into LLM effectiveness and aid end-users in understanding predictions. Additionally, a user study found that the visualization of model predictions provided by ASTxplainer was useful for enabling end-users to explain predictions.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) for code are a family of high-parameter, transformer-based neural networks pre-trained on massive datasets of both natural and programming languages. These models are rapidly being employed in commercial AI-based developer tools, such as GitHub CoPilot. However, measuring and explaining their effectiveness on programming tasks is a challenging proposition, given their size and complexity. The methods for evaluating and explaining LLMs for code are inextricably linked. That is, in order to explain a model's predictions, they must be reliably mapped to fine-grained, understandable concepts. Once this mapping is achieved, new methods for detailed model evaluations are possible. However, most current explainability techniques and evaluation benchmarks focus on model robustness or individual task performance, as opposed to interpreting model predictions.   To this end, this paper introduces ASTxplainer, an explainability method specific to LLMs for code that enables both new methods for LLM evaluation and visualizations of LLM predictions that aid end-users in understanding model predictions. At its core, ASTxplainer provides an automated method for aligning token predictions with AST nodes, by extracting and aggregating normalized model logits within AST structures. To demonstrate the practical benefit of ASTxplainer, we illustrate the insights that our framework can provide by performing an empirical evaluation on 12 popular LLMs for code using a curated dataset of the most popular GitHub projects. Additionally, we perform a user study examining the usefulness of an ASTxplainer-derived visualization of model predictions aimed at enabling model users to explain predictions. The results of these studies illustrate the potential for ASTxplainer to provide insights into LLM effectiveness, and aid end-users in understanding predictions.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM） для代码是一家高参数、转换器基于神经网络的家族，预训练在庞大的自然语言和编程语言数据集上。这些模型在商业AI基于开发者工具中使用，如GitHub CoPilot。然而，评估和解释LLMs的效果在编程任务上是一个复杂的问题，因为它们的大小和复杂性。LLMs的评估和解释方法紧密相关，即要可靠地将模型预测映射到细腻可理解的概念上。一旦这种映射实现，新的详细模型评估方法就可能实现。然而，现有的解释技术和评估标准主要关注模型稳定性或个别任务性能，而不是解释模型预测。为此，本文介绍了ASTxplainer，一种特有的解释方法，用于LLMs for code。ASTxplainer提供了一种自动将字符预测映射到AST结构中的方法，通过提取和聚合 норциали化模型强度的技术。为证明ASTxplainer的实用性，我们对12种流行的LLMs for code进行了一系列实验，并使用一个优选的GitHub项目数据集进行了一个详细的评估。此外，我们还进行了一次用户研究，以确定ASTxplainer derivated的可视化是否有用于解释模型预测。研究结果表明，ASTxplainer有可能为LLM效果提供新的视角，并帮助用户理解预测。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Equivalence-of-e-Commerce-Queries"><a href="#Semantic-Equivalence-of-e-Commerce-Queries" class="headerlink" title="Semantic Equivalence of e-Commerce Queries"></a>Semantic Equivalence of e-Commerce Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03869">http://arxiv.org/abs/2308.03869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aritra Mandal, Daniel Tunkelang, Zhe Wu</li>
<li>for: 本研究旨在提高电商搜索中的搜索结果和商业效果，通过认可和利用查询Equivalence来解决搜索查询的问题。</li>
<li>methods: 本研究提出了一种框架，包括将查询映射到搜索意图的 вектор表示，并使用surface similarity和行为相似性来确定查询Equivalence。</li>
<li>results: 实验结果表明，提出的方法可以高效地认可和利用查询Equivalence，并在 Popular sentence transformer模型之上出performanced。结果还 highlights the potential of  leveraging历史行为数据和训练模型来提高电商搜索的用户体验和商业效果。<details>
<summary>Abstract</summary>
Search query variation poses a challenge in e-commerce search, as equivalent search intents can be expressed through different queries with surface-level differences. This paper introduces a framework to recognize and leverage query equivalence to enhance searcher and business outcomes. The proposed approach addresses three key problems: mapping queries to vector representations of search intent, identifying nearest neighbor queries expressing equivalent or similar intent, and optimizing for user or business objectives. The framework utilizes both surface similarity and behavioral similarity to determine query equivalence. Surface similarity involves canonicalizing queries based on word inflection, word order, compounding, and noise words. Behavioral similarity leverages historical search behavior to generate vector representations of query intent. An offline process is used to train a sentence similarity model, while an online nearest neighbor approach supports processing of unseen queries. Experimental evaluations demonstrate the effectiveness of the proposed approach, outperforming popular sentence transformer models and achieving a Pearson correlation of 0.85 for query similarity. The results highlight the potential of leveraging historical behavior data and training models to recognize and utilize query equivalence in e-commerce search, leading to improved user experiences and business outcomes. Further advancements and benchmark datasets are encouraged to facilitate the development of solutions for this critical problem in the e-commerce domain.
</details>
<details>
<summary>摘要</summary>
<SYS>    输入文本翻译为简化字符串。</SYS>搜索查询的变化 pose 电商搜索中的挑战，因为相同的搜索意图可以通过不同的查询语句表达。本文介绍了一种框架，用于认可和利用查询等价性，以提高搜索者和商业目标的结果。该框架解决了三个关键问题：将查询映射到搜索意图的 вектор表示，标识Equivalent或相似的搜索意图的查询，以及优化用户或商业目标。该框架利用了表面相似性和行为相似性来确定查询等价性。表面相似性包括根据词形变化、词序排序、复合词和噪音词进行 canonicalization。行为相似性利用历史搜索行为生成搜索意图的 вектор表示。在线上进行训练的offline进程用于培训句子相似性模型，而在线上的最近邻近approach支持处理未经看过的查询。实验证明了提案的方法的有效性，比 популяр的句子转换模型更好，并达到了0.85的Pearson相关系数 для查询相似性。结果表明，通过利用历史行为数据和训练模型，可以认可和利用查询等价性，从而提高用户体验和商业结果。进一步的进步和标准 datasets 鼓励开发者们在电商领域开发解决这个关键问题的解决方案。
</details></li>
</ul>
<hr>
<h2 id="AI-Text-to-Behavior-A-Study-In-Steerability"><a href="#AI-Text-to-Behavior-A-Study-In-Steerability" class="headerlink" title="AI Text-to-Behavior: A Study In Steerability"></a>AI Text-to-Behavior: A Study In Steerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07326">http://arxiv.org/abs/2308.07326</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Noever, Sam Hyams</li>
<li>for: 这项研究探讨了大语言模型（LLM）的可控性，尤其是OpenAI的ChatGPT迭代。</li>
<li>methods: 我们使用了行为心理学框架OCEAN（开放性、聪明性、外向性、合作性、情绪性），量测模型对特定提示的回应。</li>
<li>results: 我们发现，“开放性”存在语言含义模糊，而“聪明性”和“情绪性”在OCEAN框架中明确表现出来，而“外向性”和“合作性”则显示出了明确的分化。这些结果表明GPT的多样性和适应能力，但也指出了LLM的快速进步和一些训练技术的权限性。<details>
<summary>Abstract</summary>
The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while "openness" presented linguistic ambiguity, "conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN framework, with "extroversion" and "agreeableness" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. However, the rapid advancements in LLM capabilities and the opaque nature of some training techniques make metric proposals degrade rapidly. Our research emphasizes a quantitative role to describe steerability in LLMs, presenting both its promise and areas for further refinement in aligning its progress to human intentions.
</details>
<details>
<summary>摘要</summary>
研究探讨大语言模型（LLM）的可控性，特别是OpenAI的ChatGPT迭代。通过使用行为心理学框架 called OCEAN（开放性、亲和力、EXTROVERSION、善于合作性、神经性），我们量化了模型对特定提示的应对性。当请求生成 simulate extroverted personality 的文本时，OCEAN 评分语言对该行为特征的Alignment。在我们的分析中，“开放性”表现出语言的ambiguity，而“谨慎性”和“神经性”在OCEAN框架中得到了明确的识别，而“EXTROVERSION”和“善于合作性”则显示了明显的重叠 yet distinct separation from other traits。我们的发现推动GPT的多样性和能力，并且可以根据人类的INTENTIONS来定制和适应。然而，LLM的快速进步和一些训练技术的不透明性使得度量建议迅速衰退。我们的研究强调了量化描述 LLM 的可控性的作用，并提出了该领域的进一步完善和人类INTENTIONS的Alignment。
</details></li>
</ul>
<hr>
<h2 id="MCTS-guided-Genetic-Algorithm-for-optimization-of-neural-network-weights"><a href="#MCTS-guided-Genetic-Algorithm-for-optimization-of-neural-network-weights" class="headerlink" title="MCTS guided Genetic Algorithm for optimization of neural network weights"></a>MCTS guided Genetic Algorithm for optimization of neural network weights</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04459">http://arxiv.org/abs/2308.04459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AkshayHebbar/MCTS-GA">https://github.com/AkshayHebbar/MCTS-GA</a></li>
<li>paper_authors: Akshay Hebbar</li>
<li>for: 本研究探讨了如何使用搜寻策略应用于遗传算法，以搜寻整个遗传树结构中的优化解决方案。</li>
<li>methods: 本研究使用了许多搜寻策略，包括宽度优先、深度优先和迭代法，但这些方法通常需要大量计算时间。在搜寻过程中，我们采用了反对抗技术，以快速获得最优解。</li>
<li>results: 本研究结果表明，将遗传算法和蒙特卡洛tree搜寻策略结合使用，可以快速找到遗传算法优化解决方案。<details>
<summary>Abstract</summary>
In this research, we investigate the possibility of applying a search strategy to genetic algorithms to explore the entire genetic tree structure. Several methods aid in performing tree searches; however, simpler algorithms such as breadth-first, depth-first, and iterative techniques are computation-heavy and often result in a long execution time. Adversarial techniques are often the preferred mechanism when performing a probabilistic search, yielding optimal results more quickly. The problem we are trying to tackle in this paper is the optimization of neural networks using genetic algorithms. Genetic algorithms (GA) form a tree of possible states and provide a mechanism for rewards via the fitness function. Monte Carlo Tree Search (MCTS) has proven to be an effective tree search strategy given states and rewards; therefore, we will combine these approaches to optimally search for the best result generated with genetic algorithms.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究了将搜索策略应用于生物学算法，以探索整个遗传树结构。许多方法可以进行树搜索，但是简单的算法如广度优先、深度优先和迭代方法通常需要较长的计算时间。对于 probabilistic 搜索，反击技术通常是首选的机制，可以快速获得优化结果。我们在这篇论文中面临的问题是使用生物学算法优化神经网络。生物学算法形成一棵可能状态的树，并提供了回归函数来计算奖励。蒙特卡洛树搜索（MCTS）已经证明是在给定状态和奖励时效果的搜索策略，因此我们将这些方法结合使用，以优化使用生物学算法生成的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing"><a href="#Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing" class="headerlink" title="Revisiting Prompt Engineering via Declarative Crowdsourcing"></a>Revisiting Prompt Engineering via Declarative Crowdsourcing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03854">http://arxiv.org/abs/2308.03854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya G. Parameswaran, Shreya Shankar, Parth Asawa, Naman Jain, Yujie Wang</li>
<li>for: 提高 LLM 数据处理工作流程的质量和效率，以及提供一种更原则化的描述引擎方法。</li>
<li>methods: 利用多种描述策略、保证内部一致性，以及混合 LLM 和非 LLM 方法来实现更原则化的描述引擎。</li>
<li>results: 在排序、实体解析和填充等应用中，采用该方法可以提高 LLM 的性能和可靠性，并且可以自动化和机器化描述引擎过程。<details>
<summary>Abstract</summary>
Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach
</details>
<details>
<summary>摘要</summary>
巨型语言模型（LLM）拥有强大的文本理解和生成能力，但是容易受到影响和出错。随着召集工具和热门趋势的出现，有关提问工程（prompt engineering）的研究得到了更多的关注，即通过一系列提问请求LLM进行某种任务。然而，为LLM数据处理工作流程而优化质量，同时保持成本在可控范围内，是一个繁琐、手动的过程。我们提出了声明式提问工程的视野，将LLM视为众生力量，并借鉴了声明式人员召集文献中的一些想法，包括多种提问策略、保证内部一致性，以及混合LLM非LLM方法。这些案例研究显示了排序、实体匹配和填充等应用场景的搅麻潜力。
</details></li>
</ul>
<hr>
<h2 id="Search-Engine-and-Recommendation-System-for-the-Music-Industry-built-with-JinaAI"><a href="#Search-Engine-and-Recommendation-System-for-the-Music-Industry-built-with-JinaAI" class="headerlink" title="Search Engine and Recommendation System for the Music Industry built with JinaAI"></a>Search Engine and Recommendation System for the Music Industry built with JinaAI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03842">http://arxiv.org/abs/2308.03842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishita Gopalakrishnan, Sanjjushri Varshini R, Ponshriharini V</li>
<li>for: 这篇论文的目的是为了开发一个基于 Machine Learning 的音乐产业搜索引擎和推荐系统。</li>
<li>methods: 这篇论文使用了 Jina AI 框架，一个基于 MLOps 的搜索引擎架构，以提高搜索引擎的速度、精度和搜寻结果的质量。</li>
<li>results: 这篇论文的结果显示，使用 Jina AI 框架可以实现更好的搜寻结果和推荐系统，帮助用户更加方便地搜寻音乐。<details>
<summary>Abstract</summary>
One of the most intriguing debates regarding a novel task is the development of search engines and recommendation-based systems in the music industry. Studies have shown a drastic depression in the search engine fields, due to concerning factors such as speed, accuracy and the format of data given for querying. Often people face difficulty in searching for a song solely based on the title, hence a solution is proposed to complete a search analysis through a single query input and is matched with the lyrics of the songs present in the database. Hence it is essential to incorporate cutting-edge technology tools for developing a user-friendly search engine. Jina AI is an MLOps framework for building neural search engines that are utilized, in order for the user to obtain accurate results. Jina AI effectively helps to maintain and enhance the quality of performance for the search engine for the query given. An effective search engine and a recommendation system for the music industry, built with JinaAI.
</details>
<details>
<summary>摘要</summary>
一个非常吸引人的问题在音乐产业中是搜索引擎和推荐系统的开发。研究表明，搜索引擎领域受到了严重的萧瑟，主要原因包括速度、准确性和数据格式的问题。人们经常遇到查找歌曲 solely based on the title 是困难的，因此一种解决方案是通过单个查询输入完成搜索分析，并将数据库中的歌曲 lyrics 与输入进行匹配。因此，搜索引擎的开发需要采用 cutting-edge 技术工具，以建立用户友好的搜索引擎。Jina AI 是一个 MLOps 框架，用于构建基于神经网络的搜索引擎，可以帮助用户 obtian 精准的结果。Jina AI 有效地帮助维护和提高搜索引擎的性能质量。一个基于 JinaAI 的高效搜索引擎和推荐系统，可以为音乐产业提供更好的用户体验。
</details></li>
</ul>
<hr>
<h2 id="The-Copycat-Perceptron-Smashing-Barriers-Through-Collective-Learning"><a href="#The-Copycat-Perceptron-Smashing-Barriers-Through-Collective-Learning" class="headerlink" title="The Copycat Perceptron: Smashing Barriers Through Collective Learning"></a>The Copycat Perceptron: Smashing Barriers Through Collective Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03743">http://arxiv.org/abs/2308.03743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Catania, Aurélien Decelle, Beatriz Seoane</li>
<li>for: 研究一种 teacher-student enario中的 $y$ coupled binary perceptrons 的平衡性质。</li>
<li>methods: 使用一种适当的学习规则，并对学生模型的权重进行显式杂化，使其与教师模型的权重具有哈明顿距离的关系。</li>
<li>results: 在存在温度噪声的情况下，研究发现，在教师模型的指导下，学生模型的学习表现得到改进，而且随着学生模型的数量增加，学习表现得到进一步改进。<details>
<summary>Abstract</summary>
We characterize the equilibrium properties of a model of $y$ coupled binary perceptrons in the teacher-student scenario, subject to a suitable learning rule, with an explicit ferromagnetic coupling proportional to the Hamming distance between the students' weights. In contrast to recent works, we analyze a more general setting in which a thermal noise is present that affects the generalization performance of each student. Specifically, in the presence of a nonzero temperature, which assigns nonzero probability to configurations that misclassify samples with respect to the teacher's prescription, we find that the coupling of replicas leads to a shift of the phase diagram to smaller values of $\alpha$: This suggests that the free energy landscape gets smoother around the solution with good generalization (i.e., the teacher) at a fixed fraction of reviewed examples, which allows local update algorithms such as Simulated Annealing to reach the solution before the dynamics gets frozen. Finally, from a learning perspective, these results suggest that more students (in this case, with the same amount of data) are able to learn the same rule when coupled together with a smaller amount of data.
</details>
<details>
<summary>摘要</summary>
我们描述一个 teacher-student 模型中的 $y$ coupled binary perceptron 的平衡性能，采用一种合适的学习规则，带有明确的 ferromagnetic 相互作用，其比例与学生们的权重之间的汉明距离相关。与先前的研究不同，我们分析了一个更通用的设置，在其中每个学生都受到一定温度的影响，这使得每个学生的泛化性能受到影响。 Specifically, 在非零温度下，权重的配置可能会错误地分类样本，从而导致学生的泛化性能下降。我们发现，在这种情况下，同学生之间的相互作用会使得解析的相对稳定点变小，这意味着解析的自由能面积变得更加平滑，使得本地更新算法如模拟热化可以更容易地到达解析。最后，从学习角度来看，这些结果表明，当学生们相互couple时，可以通过更小的数据量来学习同样的规则，这意味着更多的学生可以在同样的数据量下学习。
</details></li>
</ul>
<hr>
<h2 id="Randomized-algorithms-for-precise-measurement-of-differentially-private-personalized-recommendations"><a href="#Randomized-algorithms-for-precise-measurement-of-differentially-private-personalized-recommendations" class="headerlink" title="Randomized algorithms for precise measurement of differentially-private, personalized recommendations"></a>Randomized algorithms for precise measurement of differentially-private, personalized recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03735">http://arxiv.org/abs/2308.03735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-dprecs">https://github.com/apple/ml-dprecs</a></li>
<li>paper_authors: Allegra Laro, Yanqing Chen, Hao He, Babak Aghazadeh</li>
<li>for: 提出一种隐私保护的个性化推荐算法，以便在个性化推荐中保护用户隐私。</li>
<li>methods: 提出的算法使用幂等函数和均值分布来保证隐私，并通过实验证明其可以保持 preciseness 和隐私性。</li>
<li>results: 对于广告应用场景，该算法可以提高用户体验、广告商价值和平台收入，同时保持隐私性。<details>
<summary>Abstract</summary>
Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content. However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy. Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first. In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement. We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations.
</details>
<details>
<summary>摘要</summary>
个人化推荐作为今天互联网生态系统中的一部分，帮助艺术家和创作者达到有趣用户，并帮助用户发现新的有趣内容。然而，许多用户今天对个人化推荐平台表示怀疑，其中一部分是由于历史上不谨慎处理个人数据和隐私。现在，企业们正在进入一个新的平台，其中许多系统需要重新设计，以保持隐私First。在这篇文章中，我们提出一种用于个人化推荐的算法，以实现精准和隐私保护。我们使用广告作为应用例子，并在线上实验来衡量该提议的隐私保护算法对用户体验、广告商价值和平台收入的影响，与非个人化和非隐私的个人化实现相比。
</details></li>
</ul>
<hr>
<h2 id="SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator"><a href="#SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator" class="headerlink" title="SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator"></a>SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03730">http://arxiv.org/abs/2308.03730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danilaeremenko/survbex">https://github.com/danilaeremenko/survbex</a></li>
<li>paper_authors: Lev V. Utkin, Danila Y. Eremenko, Andrei V. Konstantinov</li>
<li>For: The paper proposes a new method called SurvBeX to explain the predictions of machine learning survival black-box models.* Methods: The method uses a modified Beran estimator as a surrogate explanation model, and generates many points in a local area around an example of interest to compute the survival function of the black-box model and the Beran estimator.* Results: The paper demonstrates the efficiency of SurvBeX through numerical experiments with synthetic and real survival data, and compares the method with the well-known method SurvLIME and SurvSHAP. The code implementing SurvBeX is available online.Here are the three points in Simplified Chinese text:* For: 这篇论文提出了一种新的方法SurvBeX，用于解释机器学习生存黑盒模型的预测结果。* Methods: SurvBeX使用修改后的Beran估计器作为准确解释模型，并在 интерес示例附近生成多个点，以计算黑盒模型和Beran估计器的生存函数。* Results: 论文通过synthetic和实际生存数据的numerical实验，证明SurvBeX的效果，并与SurvLIME和SurvSHAP进行比较。代码实现SurvBeX可以在<a target="_blank" rel="noopener" href="https://github.com/DanilaEremenko/SurvBeX%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/DanilaEremenko/SurvBeX上获取。</a><details>
<summary>Abstract</summary>
An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the well-known method SurvLIME. The method is also compared with the method SurvSHAP. The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX
</details>
<details>
<summary>摘要</summary>
提出一种名为SurvBeX的解释方法，用于解释机器学习预测模型的逝去黑盒模型。该方法的主要想法是使用修改后的Beran估计器作为解释模型。 incorporated into Beran estimator的系数可以 viewed as预测模型中特征影响值。采用LIME方法的思路，在对 interessant example的local区域附近生成多个例子。每个生成的例子中，预测模型的生存函数被计算，并将生存函数转化为解释系数的函数。以 minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples。 numerically experiments with synthetic and real survival data demonstrate SurvBeX efficiency and compare the method with well-known method SurvLIME. The method is also compared with SurvSHAP method. SurvBeX的代码可以在以下链接获取：https://github.com/DanilaEremenko/SurvBeX。
</details></li>
</ul>
<hr>
<h2 id="Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation"><a href="#Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation" class="headerlink" title="Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation"></a>Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03723">http://arxiv.org/abs/2308.03723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mckellwoodland/dimen_reduce_mahal">https://github.com/mckellwoodland/dimen_reduce_mahal</a></li>
<li>paper_authors: McKell Woodland, Nihil Patel, Mais Al Taie, Joshua P. Yung, Tucker J. Netherton, Ankit B. Patel, Kristy K. Brock</li>
<li>for: 这个研究是为了检测MRI肿瘤影像分类模型的外部分布情况，以避免自动偏见。</li>
<li>methods: 这个研究使用了Mahalanobis距离后置法，将Swin UNITER模型的瓶颈特征使用主成分分析，实现高性能的外部分布检测。</li>
<li>results: 研究发现，这种方法可以实现高度的外部分布检测，并且具有较少的计算负载。<details>
<summary>Abstract</summary>
Clinically deployed segmentation models are known to fail on data outside of their training distribution. As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias. This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging. By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load.
</details>
<details>
<summary>摘要</summary>
临床部署的分割模型经常会在训练数据外部失败。由于这些模型在大多数情况下表现良好，因此在推断时检测出对外部数据的自动偏见是必要的。这项工作使用Swin UNITER模型的瓶颈特征进行 Mahalanobis 距离后处理，以检测T1核磁共振成像上的肝脏分割图像。通过减少瓶颈特征的维度使用主成分分析，可以高效地检测到对外部数据的图像。
</details></li>
</ul>
<hr>
<h2 id="“Do-Anything-Now”-Characterizing-and-Evaluating-In-The-Wild-Jailbreak-Prompts-on-Large-Language-Models"><a href="#“Do-Anything-Now”-Characterizing-and-Evaluating-In-The-Wild-Jailbreak-Prompts-on-Large-Language-Models" class="headerlink" title="“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"></a>“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03825">http://arxiv.org/abs/2308.03825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/verazuo/jailbreak_llms">https://github.com/verazuo/jailbreak_llms</a></li>
<li>paper_authors: Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, Yang Zhang</li>
<li>for: This paper aims to study the emergence and evolution of jailbreak prompts in the wild, and to assess the potential harm caused by these prompts on large language models (LLMs).</li>
<li>methods: The authors use natural language processing technologies and graph-based community detection methods to collect and analyze 6,387 jailbreak prompts from four platforms over six months. They also create a question set comprising 46,800 samples across 13 forbidden scenarios to evaluate the effectiveness of current LLMs and safeguards in defending against jailbreak prompts.</li>
<li>results: The authors find unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. They also observe that jailbreak prompts are increasingly shifting from public platforms to private ones, posing new challenges for LLM vendors in proactive detection. Additionally, they identify two highly effective jailbreak prompts that achieve 0.99 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and have persisted online for over 100 days.<details>
<summary>Abstract</summary>
The misuse of large language models (LLMs) has garnered significant attention from the general public and LLM vendors. In response, efforts have been made to align LLMs with human values and intent use. However, a particular type of adversarial prompts, known as jailbreak prompt, has emerged and continuously evolved to bypass the safeguards and elicit harmful content from LLMs. In this paper, we conduct the first measurement study on jailbreak prompts in the wild, with 6,387 prompts collected from four platforms over six months. Leveraging natural language processing technologies and graph-based community detection methods, we discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from public platforms to private ones, posing new challenges for LLM vendors in proactive detection. To assess the potential harm caused by jailbreak prompts, we create a question set comprising 46,800 samples across 13 forbidden scenarios. Our experiments show that current LLMs and safeguards cannot adequately defend jailbreak prompts in all scenarios. Particularly, we identify two highly effective jailbreak prompts which achieve 0.99 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and they have persisted online for over 100 days. Our work sheds light on the severe and evolving threat landscape of jailbreak prompts. We hope our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的不当使用已经引起了广泛的关注，并且有努力以寻求对human values和合法用途进行Alignment。然而，一种特殊的恶意提示，称为监狱提示，已经出现并不断演化以绕过安全措施并征引出危险内容。在这篇论文中，我们进行了第一次在野外中对监狱提示的量化研究，收集了6,387个提示从四个平台上经过六个月。通过自然语言处理技术和图形基本社区探测方法，我们发现了监狱提示的独特特征和主要攻击策略，如提示注入和特权提升。我们还发现，监狱提示逐渐从公共平台迁移到私有平台，这对LLM供应商提出了新的检测挑战。为了评估监狱提示的可能伤害，我们创建了46,800个问题组合，覆盖13种禁止enario。我们的实验表明，当前的LLM和安全措施无法在所有情况下有效防御监狱提示。特别是，我们标识出了两个非常有效的监狱提示，在ChatGPT（GPT-3.5）和GPT-4上具有0.99攻击成功率，并且它们在线上延续了超过100天。我们的工作照明了监狱提示的严重和演化的威胁风险。我们希望我们的研究可以促进研究社区和LLM供应商在推广安全和有序的LLM方面做出更多的努力。
</details></li>
</ul>
<hr>
<h2 id="Communication-Efficient-Framework-for-Distributed-Image-Semantic-Wireless-Transmission"><a href="#Communication-Efficient-Framework-for-Distributed-Image-Semantic-Wireless-Transmission" class="headerlink" title="Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission"></a>Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03713">http://arxiv.org/abs/2308.03713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingyan Xie, Yongpeng Wu, Yuxuan Shi, Derrick Wing Kwan Ng, Wenjun Zhang</li>
<li>for: 这篇论文主要targets the problem of communication-efficient distributed data transmission in Internet-of-Things (IoT) scenarios with multiple devices, and proposes a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission.</li>
<li>methods: The proposed FLSC framework uses a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation, and a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise.</li>
<li>results: Simulation results show that the coarse semantic information can deal with a range of image-level tasks, and the FLSC framework outperforms traditional schemes in low signal-to-noise ratio and channel bandwidth ratio regimes, with a gain of around 10 peak signal-to-noise ratio in the 3 dB channel condition.<details>
<summary>Abstract</summary>
Multi-node communication, which refers to the interaction among multiple devices, has attracted lots of attention in many Internet-of-Things (IoT) scenarios. However, its huge amounts of data flows and inflexibility for task extension have triggered the urgent requirement of communication-efficient distributed data transmission frameworks. In this paper, inspired by the great superiorities on bandwidth reduction and task adaptation of semantic communications, we propose a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices. Federated learning enables the design of independent semantic communication link of each user while further improves the semantic extraction and task performance through global aggregation. Each link in FLSC is composed of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation according to specific tasks. In order to extend the FLSC into more realistic conditions, we design a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise. Simulation results show that the coarse semantic information can deal with a range of image-level tasks. Moreover, especially in low signal-to-noise ratio and channel bandwidth ratio regimes, FLSC evidently outperforms the traditional scheme, e.g. about 10 peak signal-to-noise ratio gain in the 3 dB channel condition.
</details>
<details>
<summary>摘要</summary>
多节点通信，指的是多个设备之间的交互，在互联网关键设备（IoT）场景中吸引了很多关注。然而，它的巨量数据流和任务扩展不灵活性已经触发了高效通信分布数据传输框架的紧迫需求。本文提出了基于联合学习的 semantic communication（FLSC）框架，用于多任务分布式图像传输。联合学习使得每个用户独立的semantic communication链接可以进一步提高semantic抽取和任务性能通过全球汇总。每个FLSC链接都包括层次视transformer（HVT）基于抽取器和任务适应译码器，用于层次semantic抽取和意义翻译。为了扩展FLSC到更加实际的情况，我们设计了基于 kanal 状态信息的多输入多输出传输模块，以对抗通道抖动和噪声。实验结果显示，粗粒度semantic信息可以处理多种图像级任务。此外，特别在低信号噪声比和通道宽bandwidth比例 regime下，FLSC明显超过传统方案，例如在3dB通道条件下约10带宽比例的增强。
</details></li>
</ul>
<hr>
<h2 id="Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience"><a href="#Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience" class="headerlink" title="Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience"></a>Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03712">http://arxiv.org/abs/2308.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eminorhan/humanlike-vits">https://github.com/eminorhan/humanlike-vits</a></li>
<li>paper_authors: A. Emin Orhan</li>
<li>for: 这 paper  investigate whether current self-supervised learning methods can reach human-level visual object recognition capabilities with the same type and amount of visual experience as humans.</li>
<li>methods: 这 paper 使用 vision transformers 和 masked autoencoders (MAEs) 进行自然语言处理，并进行了数据大小、模型大小和图像分辨率的同时缩放实验。</li>
<li>results: 结果表明，可以通过同时缩放数据大小、模型大小和图像分辨率来达到人类水平的 объекRecognition 能力，而无需使用专门的 inductive biases。例如，一个 2.5B 参数的 ViT 模型，通过使用 20K 小时的人类样式视频数据和 952x952 像素的空间分辨率，应该可以达到 ImageNet 上的人类水平准确率。<details>
<summary>Abstract</summary>
This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach roughly human-level accuracy on ImageNet. Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DeRisk-An-Effective-Deep-Learning-Framework-for-Credit-Risk-Prediction-over-Real-World-Financial-Data"><a href="#DeRisk-An-Effective-Deep-Learning-Framework-for-Credit-Risk-Prediction-over-Real-World-Financial-Data" class="headerlink" title="DeRisk: An Effective Deep Learning Framework for Credit Risk Prediction over Real-World Financial Data"></a>DeRisk: An Effective Deep Learning Framework for Credit Risk Prediction over Real-World Financial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03704">http://arxiv.org/abs/2308.03704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yancheng Liang, Jiajie Zhang, Hui Li, Xiaochen Liu, Yi Hu, Yong Wu, Jinyao Zhang, Yongyan Liu, Yi Wu</li>
<li>for: 预测信用风险（credit risk prediction）在真实世界金融数据上。</li>
<li>methods: 提出了一种深度学习风险预测框架（DeRisk），该框架可以在真实世界金融数据上高效地预测信用风险。</li>
<li>results: DeRisk 已经在实际生产环境中超过了统计学学习方法的表现，并进行了广泛的缺失研究以证明模型的成功因素。<details>
<summary>Abstract</summary>
Despite the tremendous advances achieved over the past years by deep learning techniques, the latest risk prediction models for industrial applications still rely on highly handtuned stage-wised statistical learning tools, such as gradient boosting and random forest methods. Different from images or languages, real-world financial data are high-dimensional, sparse, noisy and extremely imbalanced, which makes deep neural network models particularly challenging to train and fragile in practice. In this work, we propose DeRisk, an effective deep learning risk prediction framework for credit risk prediction on real-world financial data. DeRisk is the first deep risk prediction model that outperforms statistical learning approaches deployed in our company's production system. We also perform extensive ablation studies on our method to present the most critical factors for the empirical success of DeRisk.
</details>
<details>
<summary>摘要</summary>
尽管深度学习技术过去几年取得了很大的进步，现在最新的风险预测模型仍然基于高度手动调整的阶段性统计学学习工具，如梯度批量和随机森林方法。与图像或语言不同，实际世界金融数据具有高维、稀疏、噪音和极其不均衡的特点，这使得深度神经网络模型在实践中特别困难并脆弱。在这项工作中，我们提出了DeRisk，一种高效的深度学习风险预测框架，用于实际世界金融数据上的信用风险预测。DeRisk是我们公司生产系统中部署的统计学学习方法的首个深度风险预测模型，我们还进行了广泛的减少研究，以阐明DeRisk的成功的重要因素。
</details></li>
</ul>
<hr>
<h2 id="AgentBench-Evaluating-LLMs-as-Agents"><a href="#AgentBench-Evaluating-LLMs-as-Agents" class="headerlink" title="AgentBench: Evaluating LLMs as Agents"></a>AgentBench: Evaluating LLMs as Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03688">http://arxiv.org/abs/2308.03688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/agentbench">https://github.com/thudm/agentbench</a></li>
<li>paper_authors: Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, Jie Tang</li>
<li>for: 评估大型自然语言处理器（LLM）在实际世界中的智能和自主能力。</li>
<li>methods: 使用多维度演化的 benchmark 来评估 LLM 作为代理的判断和决策能力。</li>
<li>results: 测试了 25 个 LLM（包括 API 和开源模型），发现商业 LLM 表现出色，但是开源竞争对手的表现差异较大。Note: “LLM” stands for “Large Language Models” in English.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors. It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation. Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Almost-sure-convergence-of-iterates-and-multipliers-in-stochastic-sequential-quadratic-optimization"><a href="#Almost-sure-convergence-of-iterates-and-multipliers-in-stochastic-sequential-quadratic-optimization" class="headerlink" title="Almost-sure convergence of iterates and multipliers in stochastic sequential quadratic optimization"></a>Almost-sure convergence of iterates and multipliers in stochastic sequential quadratic optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03687">http://arxiv.org/abs/2308.03687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank E. Curtis, Xin Jiang, Qi Wang</li>
<li>for:  solves large-scale data-fitting problems subject to nonconvex constraints</li>
<li>methods:  stochastic-gradient methodology from the unconstrained setting</li>
<li>results:  new almost-sure convergence guarantees for the primal iterates, Lagrange multipliers, and stationarity measures<details>
<summary>Abstract</summary>
Stochastic sequential quadratic optimization (SQP) methods for solving continuous optimization problems with nonlinear equality constraints have attracted attention recently, such as for solving large-scale data-fitting problems subject to nonconvex constraints. However, for a recently proposed subclass of such methods that is built on the popular stochastic-gradient methodology from the unconstrained setting, convergence guarantees have been limited to the asymptotic convergence of the expected value of a stationarity measure to zero. This is in contrast to the unconstrained setting in which almost-sure convergence guarantees (of the gradient of the objective to zero) can be proved for stochastic-gradient-based methods. In this paper, new almost-sure convergence guarantees for the primal iterates, Lagrange multipliers, and stationarity measures generated by a stochastic SQP algorithm in this subclass of methods are proved. It is shown that the error in the Lagrange multipliers can be bounded by the distance of the primal iterate to a primal stationary point plus the error in the latest stochastic gradient estimate. It is further shown that, subject to certain assumptions, this latter error can be made to vanish by employing a running average of the Lagrange multipliers that are computed during the run of the algorithm. The results of numerical experiments are provided to demonstrate the proved theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
This paper presents new almost-sure convergence guarantees for the primal iterates, Lagrange multipliers, and stationarity measures generated by a stochastic SQP algorithm in this subclass of methods. The error in the Lagrange multipliers can be bounded by the distance of the primal iterate to a primal stationary point plus the error in the latest stochastic gradient estimate. Furthermore, it is shown that this latter error can be made to vanish by employing a running average of the Lagrange multipliers computed during the run of the algorithm, subject to certain assumptions.Numerical experiments are provided to demonstrate the proved theoretical guarantees. These results demonstrate the effectiveness of the proposed method in solving continuous optimization problems with nonlinear equality constraints.
</details></li>
</ul>
<hr>
<h2 id="Linear-Convergence-Bounds-for-Diffusion-Models-via-Stochastic-Localization"><a href="#Linear-Convergence-Bounds-for-Diffusion-Models-via-Stochastic-Localization" class="headerlink" title="Linear Convergence Bounds for Diffusion Models via Stochastic Localization"></a>Linear Convergence Bounds for Diffusion Models via Stochastic Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03686">http://arxiv.org/abs/2308.03686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joe Benton, Valentin De Bortoli, Arnaud Doucet, George Deligiannidis</li>
<li>for: 这个论文的目的是提供高维数据分布采样的精度模型，并且提供了对这些模型的证明。</li>
<li>methods: 这个论文使用了扩散模型，并且使用了$L^2$-精度分布估计器。</li>
<li>results: 这个论文提供了高维数据分布采样的 linear  bounds，即在数据维度上具有 $\tilde O(\frac{d \log^2(1&#x2F;\delta)}{\varepsilon^2})$ 步骤可以将数据分布 approximate 到 Within $\varepsilon^2$ 的 Kullback–Leibler 差分。<details>
<summary>Abstract</summary>
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SDE, which is based on tools from stochastic localization.
</details>
<details>
<summary>摘要</summary>
传播模型是一种强大的方法来生成高维数据分布的近似样本。一些最近的结果提供了多项关于传播模型的数值精度，假设$L^2$-精确的分配 estimator。然而，直到现在，最好的知识是 either 超过线性的数据维度或需要强大的平滑假设。我们提供了首个线性于数据维度（以logarithmic factor）的传播模型数值精度 bound，只需要对数据分布的第二 moment finite。我们证明了传播模型可以在 $\mathbb{R}^d$ 上静态数据分布上静态数据分布 corrupted with Gaussian noise of variance $\delta$ 到 Within $\varepsilon^2$ 库拉克-莱比勒分布 divergence 以内 $\tilde O\left(\frac{d \log^2(1/\delta)}{\varepsilon^2}\right)$ 步骤。我们的证明基于先前的 Girsanov-based 方法，并 introducing 对 reverse SDE 的精度误差的更加精确的处理，基于 Stochastic localization 的工具。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/08/cs.LG_2023_08_08/" data-id="cllt9prws004sol887w12521p" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.SD_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T00:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.SD_2023_08_08/">cs.SD - 2023-08-08 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz"><a href="#Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz" class="headerlink" title="Towards an AI to Win Ghana’s National Science and Maths Quiz"></a>Towards an AI to Win Ghana’s National Science and Maths Quiz</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04333">http://arxiv.org/abs/2308.04333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nsmq-ai/nsmqai">https://github.com/nsmq-ai/nsmqai</a></li>
<li>paper_authors: George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah</li>
<li>For: The paper aims to build an AI system to compete in Ghana’s National Science and Maths Quiz (NSMQ) and win.* Methods: The project uses open-source technology and involves building AI systems to answer questions across biology, chemistry, physics, and math.* Results: The AI system is being developed and tested, with progress made thus far and the next steps planned for a launch in October 2023.Here is the information in Simplified Chinese text:* For: 这个论文的目的是建立一个AI系统，参加加纳国家科学和数学竞赛（NSMQ），并赢得奖。* Methods: 这个项目使用开源技术，建立AI系统，以回答生物、化学、物理和数学等领域的问题。* Results: AI系统正在开发和测试中，已经完成了一些进度，下一步计划在2023年10月发布。<details>
<summary>Abstract</summary>
Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win. The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction. In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023. An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI.
</details>
<details>
<summary>摘要</summary>
可以AI赢得加纳的国家科学与数学竞赛（NSMQ）呢？我们正在NSMQ AI项目中努力解决这个问题，这是一个开源项目，用AI参加NSMQ并赢得奖。NSMQ是每年举行的生活科学和数学竞赛，参赛者是加纳高中二年级学生，他们需要在5轮5个阶段中回答生物、化学、物理和数学等领域的问题。这是一项有趣的现场竞赛，涉及到语音识别、文本识别、问题回答和人机交互等技术挑战。在我们自2023年1月开始的工作中，我们将介绍项目的概况，描述各个团队，已经成就的进度以及下一步的计划，以准在10月份的NSMQ 2023上发布和使用AI。如果AI成功完成这项挑战，可以对教育产生实际的影响，例如，使得非洲的数百万学生得到AI一对一的学习支持。
</details></li>
</ul>
<hr>
<h2 id="Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning"><a href="#Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning" class="headerlink" title="Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning"></a>Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04244">http://arxiv.org/abs/2308.04244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Chen, Changde Du, Qiongyi Zhou, Huiguang He</li>
<li>For: 本研究旨在解决现有深度学习方法困难充分利用不同视角（即注意力和EEG数据）的问题，并提取有利的表示。* Methods: 我们提出了基于多视角VAE的听觉注意力解码方法（AAD），并使用任务相关多视角对比（TMC）学习来融合不同视角的知识。* Results: 我们在两个常用AAD数据集上进行了实验，并证明了我们的方法在比较当前状态方法时表现出了超越。<details>
<summary>Abstract</summary>
The human brain can easily focus on one speaker and suppress others in scenarios such as a cocktail party. Recently, researchers found that auditory attention can be decoded from the electroencephalogram (EEG) data. However, most existing deep learning methods are difficult to use prior knowledge of different views (that is attended speech and EEG are task-related views) and extract an unsatisfactory representation. Inspired by Broadbent's filter model, we decode auditory attention in a multi-view paradigm and extract the most relevant and important information utilizing the missing view. Specifically, we propose an auditory attention decoding (AAD) method based on multi-view VAE with task-related multi-view contrastive (TMC) learning. Employing TMC learning in multi-view VAE can utilize the missing view to accumulate prior knowledge of different views into the fusion of representation, and extract the approximate task-related representation. We examine our method on two popular AAD datasets, and demonstrate the superiority of our method by comparing it to the state-of-the-art method.
</details>
<details>
<summary>摘要</summary>
人脑可以轻松地专注一个说话者，而抑制其他说话者的场景，如cocktail party。最近，研究人员发现了基于电enzephalogram（EEG）数据的听力注意力可以被解码。然而，现有的深度学习方法很难以利用不同视图（即注意力和EEG数据是关联任务的视图）的先前知识，提取不满足的表示。受布洛满特的筛子模型启发，我们在多视图 paradigm 中解码听力注意力，并使用缺失视图来汇集不同视图中的先前知识，提取关键和重要的信息。我们提出了基于多视图VAE的听力注意力解码方法（AAD），并使用任务相关多视图强制学习（TMC）来学习。通过TMC学习在多视图VAE中，可以利用缺失视图来汇集不同视图中的先前知识，提取相似任务的表示。我们在两个流行的AAD数据集上测试了我们的方法，并证明了我们的方法在比较顶尖方法的基础上具有优势。
</details></li>
</ul>
<hr>
<h2 id="Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack"><a href="#Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack" class="headerlink" title="Evil Operation: Breaking Speaker Recognition with PaddingBack"></a>Evil Operation: Breaking Speaker Recognition with PaddingBack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04179">http://arxiv.org/abs/2308.04179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Ye, Diqun Yan, Li Dong, Kailai Shen</li>
<li>for: 这篇论文旨在攻击语音识别系统，实现隐蔽的攻击方式。</li>
<li>methods: 论文使用了padding操作来制造恶意样本，并且通过滥聚积极的方式来降低人工干预的可见性。</li>
<li>results: 实验结果表明，提案的方法可以达到高度的攻击成功率，同时保持高度的正常准确率。此外，方法还能够抵抗防御方法并继续保持隐蔽性。<details>
<summary>Abstract</summary>
Machine Learning as a Service (MLaaS) has gained popularity due to advancements in machine learning. However, untrusted third-party platforms have raised concerns about AI security, particularly in backdoor attacks. Recent research has shown that speech backdoors can utilize transformations as triggers, similar to image backdoors. However, human ears easily detect these transformations, leading to suspicion. In this paper, we introduce PaddingBack, an inaudible backdoor attack that utilizes malicious operations to make poisoned samples indistinguishable from clean ones. Instead of using external perturbations as triggers, we exploit the widely used speech signal operation, padding, to break speaker recognition systems. Our experimental results demonstrate the effectiveness of the proposed approach, achieving a significantly high attack success rate while maintaining a high rate of benign accuracy. Furthermore, PaddingBack demonstrates the ability to resist defense methods while maintaining its stealthiness against human perception. The results of the stealthiness experiment have been made available at https://nbufabio25.github.io/paddingback/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition"><a href="#MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition" class="headerlink" title="MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition"></a>MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04025">http://arxiv.org/abs/2308.04025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Pan</li>
<li>for: 本研究旨在提高speech emotion recognition（SER）的可靠性和泛化能力，探讨如何从数据分布角度模型speech emotion。</li>
<li>methods: 本研究提出了一种基于CNN的SER模型，采用了添加marginsoftmax损失函数以提高类别间特征之间的距离，以提高分类的准确性。此外，还提出了一种多个speech attribute控制方法（MSAC），可以控制speech attribute，使模型更加具有感情相关特征。</li>
<li>results: 实验结果表明，提出的SER工作流程在单个和跨库SER场景中具有优秀的认知、泛化和可靠性性能。单个库SER场景中，提出的SER工作流程在IEMOCAP数据集上达到了72.97%的WR和71.76%的UAR。<details>
<summary>Abstract</summary>
Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97\% and a UAR of 71.76\% on the IEMOCAP corpus.
</details>
<details>
<summary>摘要</summary>
尽管已经做出了 significiant 进步，speech emotion recognition（SER）仍然具有挑战性，尤其在野外环境中。当前的研究主要关注recognition和泛化能力，而这个工作则倡导一种探索SER方法的可靠性，并研究如何从数据分布角度来模型speech emotion。具体来说，我们首先构建了一个基于CNN的SER模型，采用添加式margin softmax损失函数，以增强不同类别之间的距离，从而提高 их分辨率。其次，我们提出了一种多个speech attribute控制方法（MSAC），以控制speech attribute，使模型免受情感无关的 attribute的影响，捕捉更细腻的情感相关特征。最后，我们对提议的SER工作流进行了首次可靠性测试和分析，并通过out-of-distribution检测方法进行评估。广泛的实验表明，我们的提议的SER工作流在recognition、泛化和可靠性性能方面均具有优异表现。此外，在单 Corporpus SER 情况下，我们的提议SER工作流的识别率为72.97%和71.76%，在IEMOCAP corpora上。
</details></li>
</ul>
<hr>
<h2 id="Target-Speech-Extraction-with-Conditional-Diffusion-Model"><a href="#Target-Speech-Extraction-with-Conditional-Diffusion-Model" class="headerlink" title="Target Speech Extraction with Conditional Diffusion Model"></a>Target Speech Extraction with Conditional Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03987">http://arxiv.org/abs/2308.03987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoyuki Kamo, Marc Delcroix, Tomohiro Nakatani</li>
<li>for: 这篇论文旨在提出一种基于分散模型的目标语音提取方法，用于在多话者杂音场景中提取目标话者的干净语音信号。</li>
<li>methods: 该方法基于一种基于决定器的分散模型，通过条件式地使用决定器来识别目标话者，然后使用分散模型来提取目标话者的语音信号。此外，该方法还使用ensemble推理来降低可能的提取错误。</li>
<li>results: 在Libri2mix数据集上进行实验，提出的分散模型基于TSE方法，结合ensemble推理，与相对的分类式TSE系统相比，显示更高的性能。<details>
<summary>Abstract</summary>
Diffusion model-based speech enhancement has received increased attention since it can generate very natural enhanced signals and generalizes well to unseen conditions. Diffusion models have been explored for several sub-tasks of speech enhancement, such as speech denoising, dereverberation, and source separation. In this paper, we investigate their use for target speech extraction (TSE), which consists of estimating the clean speech signal of a target speaker in a mixture of multi-talkers. TSE is realized by conditioning the extraction process on a clue identifying the target speaker. We show we can realize TSE using a conditional diffusion model conditioned on the clue. Besides, we introduce ensemble inference to reduce potential extraction errors caused by the diffusion process. In experiments on Libri2mix corpus, we show that the proposed diffusion model-based TSE combined with ensemble inference outperforms a comparable TSE system trained discriminatively.
</details>
<details>
<summary>摘要</summary>
模式：简化中文报告：听话提升技术基于分散模型已经受到更多关注，因为它可以生成非常自然的提升信号，并且适用于未经见过的情况。分散模型在各种听话提升任务中被探索，如听话噪声除除、听话反射消除和源分离。在这篇论文中，我们研究了它们在目标听话提取（TSE）任务中的使用，该任务的目标是估计一个混合多个人的听话信号中的清晰听话信号。TSE通过将提取过程conditioning于特征标识target speaker来实现。我们表明可以使用conditioned diffusion model来实现TSE。此外，我们引入ensemble inference来降低扩散过程可能导致的抽取错误。在对Libri2mix数据集进行实验的结果表明，我们提出的扩散模型基于TSE，并与ensemble inference结合，可以与相似的TSE系统进行比较，并且表现更好。
</details></li>
</ul>
<hr>
<h2 id="Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet"><a href="#Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet" class="headerlink" title="Universal Automatic Phonetic Transcription into the International Phonetic Alphabet"></a>Universal Automatic Phonetic Transcription into the International Phonetic Alphabet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03917">http://arxiv.org/abs/2308.03917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctaguchi/multipa">https://github.com/ctaguchi/multipa</a></li>
<li>paper_authors: Chihiro Taguchi, Yusuke Sakai, Parisa Haghani, David Chiang</li>
<li>for: 这个研究旨在开发一种能够将任何语言的语音转换为国际音响字母表（IPA）的模型。</li>
<li>methods: 这个模型基于wav2vec 2.0，并在听音输入上进行了微调，以预测IPA。</li>
<li>results: 该模型可以准确地将语音转换为IPA，并且与人工标注的质量相似。<details>
<summary>Abstract</summary>
This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种最新的语音转写模型，可以将任何语言的语音转写为国际音域字母（IPA）。将口语语言转写为IPA是语言记录的重要步骤，但是这个过程占用了大量时间。即使只是部分自动化这个过程，也可以快速化语言记录的过程，特别是对于受威胁的语言。我们的模型基于wav2vec 2.0，并在音频输入上进行了微调，以预测IPA。我们使用了CommonVoice 11.0中的七种语言的训练数据，这些数据被 semi-automatically 转写为IPA。虽然这个训练集比前一个最佳语音到IPA模型（Wav2Vec2Phoneme）更小，但是它的质量更高，使我们的模型在比较或更好的结果。此外，我们还证明了我们的通用语音到IPA模型的质量与人工标注几乎相同。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/08/cs.SD_2023_08_08/" data-id="cllt9prwx0054ol881h8y7fqz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/eess.AS_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T00:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/eess.AS_2023_08_08/">eess.AS - 2023-08-08 22:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech"><a href="#Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech" class="headerlink" title="Investigating Speaker Embedding Disentanglement on Natural Read Speech"></a>Investigating Speaker Embedding Disentanglement on Natural Read Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04225">http://arxiv.org/abs/2308.04225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach</li>
<li>for:  investigate the degree to which speech representations encoding speaker identity can be disentangled</li>
<li>methods: use standard objectives promoting disentanglement and compare with vanilla representation learning</li>
<li>results: limited disentanglement of the speaker embedding when using standard objectives, but some improvement with vanilla representation learning<details>
<summary>Abstract</summary>
Disentanglement is the task of learning representations that identify and separate factors that explain the variation observed in data. Disentangled representations are useful to increase the generalizability, explainability, and fairness of data-driven models. Only little is known about how well such disentanglement works for speech representations. A major challenge when tackling disentanglement for speech representations are the unknown generative factors underlying the speech signal. In this work, we investigate to what degree speech representations encoding speaker identity can be disentangled. To quantify disentanglement, we identify acoustic features that are highly speaker-variant and can serve as proxies for the factors of variation underlying speech. We find that disentanglement of the speaker embedding is limited when trained with standard objectives promoting disentanglement but can be improved over vanilla representation learning to some extent.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language=zh-CN<</SYS>>文本：分离是学习表示的任务，以分解数据中变化的因素为目的。分离的表示可以提高数据驱动模型的通用性、可读性和公平性。然而，对于语音表示来说，尚未知 много关于如何实现分离。在这项工作中，我们研究了基于说话者标识的语音表示是否可以分离。为了衡量分离程度，我们标识出了具有高度说话者特征的音频特征，这些特征可以作为变化的因素下的 фактор代表。我们发现，通过标准的分离目标训练，说话者嵌入可以有限地分离，但可以通过一些程度上的改进来提高一些。
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 本研究旨在提出一种能够同时实现高精度地 segmentation 和交互 flexibility 的方法，用于解决现代方法在不同模式之间的表示模型化问题。</li>
<li>methods: 本研究提出了两种方法：一是 Expression Prompt Collaboration Transformer（EPCFormer）架构，二是 Expression Alignment（EA）机制，用于同时利用语音和文本表达的 semantic equivalence 来提高 segmentation 精度。</li>
<li>results: 实验结果表明，通过在语音、文本和视频特征之间进行深度交互，EPCFormer 可以同时实现高精度的 Video Object Segmentation 和 Referring Video Object Segmentation 任务，并且在两个任务上均 achieve state-of-the-art Result。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
audio-guided video对象分割(A-VOS)和引用video对象分割(R-VOS)是两个非常相关的任务，它们都是根据用户提供的表达提示分割视频序列中的特定对象。然而，由于不同模式之间的表示模型化困难，当前方法很难平衡用户交互的灵活性和高精度的本地化和分割。在这篇论文中，我们解决这个问题从两个方面：表达提示的对Alignment和深度交互。首先，我们提出一个通用架构，即表达Prompt Collaboration Transformer（EPCFormer）。然后，我们提出一个表达对接（EA）机制，用于对音频和文本表达进行对接。通过对音频和文本表达进行对比学习，我们的EPCFormer实现了对音频和文本表达的semantic相似性的认知。然后，为了促进音频、文本和视频特征之间的深度交互，我们引入表达-视觉注意力（EVA）机制。通过深入探索音频、文本和视频特征之间的相互补做，我们的EPCFormer可以快速 Transfer learning between the two tasks by leveraging complementary cues between text and audio.我们的实验表明，我们的通用EPCFormer在两个任务上都达到了状态艺术的Result。我们将EPCFormer的源代码公开在GitHub上，地址为https://github.com/lab206/EPCFormer。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/08/eess.AS_2023_08_08/" data-id="cllt9prxf006qol88fdmv1ucl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/eess.IV_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T00:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/eess.IV_2023_08_08/">eess.IV - 2023-08-08 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras"><a href="#Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras" class="headerlink" title="Blur aware metric depth estimation with multi-focus plenoptic cameras"></a>Blur aware metric depth estimation with multi-focus plenoptic cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04252">http://arxiv.org/abs/2308.04252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/comsee-research/blade">https://github.com/comsee-research/blade</a></li>
<li>paper_authors: Mathieu Labussière, Céline Teulière, Omar Ait-Aider</li>
<li>for: 这篇论文的目的是提出一种基于raw图像的多Focus plenoptic摄像机的metric depth estimation算法，以提高对不同距离物体的depth estimation。</li>
<li>methods: 该算法使用了 correspondence和defocus规则，并利用了模糊信息来提高depth estimation。具体来说， authors derivied一个 inverse projection模型，包括了defocus模糊，并提出了一种Calibration方法来实现精确的depth scaling。</li>
<li>results: 论文的实验结果表明，通过引入模糊信息，可以提高depth estimation的准确性。 authors还进行了实验，并证明了该算法在实际场景中的效果。<details>
<summary>Abstract</summary>
While a traditional camera only captures one point of view of a scene, a plenoptic or light-field camera, is able to capture spatial and angular information in a single snapshot, enabling depth estimation from a single acquisition. In this paper, we present a new metric depth estimation algorithm using only raw images from a multi-focus plenoptic camera. The proposed approach is especially suited for the multi-focus configuration where several micro-lenses with different focal lengths are used. The main goal of our blur aware depth estimation (BLADE) approach is to improve disparity estimation for defocus stereo images by integrating both correspondence and defocus cues. We thus leverage blur information where it was previously considered a drawback. We explicitly derive an inverse projection model including the defocus blur providing depth estimates up to a scale factor. A method to calibrate the inverse model is then proposed. We thus take into account depth scaling to achieve precise and accurate metric depth estimates. Our results show that introducing defocus cues improves the depth estimation. We demonstrate the effectiveness of our framework and depth scaling calibration on relative depth estimation setups and on real-world 3D complex scenes with ground truth acquired with a 3D lidar scanner.
</details>
<details>
<summary>摘要</summary>
while a traditional camera only captures one point of view of a scene, a plenoptic or light-field camera can capture spatial and angular information in a single snapshot, enabling depth estimation from a single acquisition. in this paper, we present a new metric depth estimation algorithm using only raw images from a multi-focus plenoptic camera. the proposed approach is especially suited for the multi-focus configuration where several micro-lenses with different focal lengths are used. the main goal of our blur-aware depth estimation (blade) approach is to improve disparity estimation for defocus stereo images by integrating both correspondence and defocus cues. we thus leverage blur information where it was previously considered a drawback. we explicitly derive an inverse projection model including the defocus blur providing depth estimates up to a scale factor. a method to calibrate the inverse model is then proposed. we thus take into account depth scaling to achieve precise and accurate metric depth estimates. our results show that introducing defocus cues improves the depth estimation. we demonstrate the effectiveness of our framework and depth scaling calibration on relative depth estimation setups and on real-world 3d complex scenes with ground truth acquired with a 3d lidar scanner.
</details></li>
</ul>
<hr>
<h2 id="Under-Display-Camera-Image-Restoration-with-Scattering-Effect"><a href="#Under-Display-Camera-Image-Restoration-with-Scattering-Effect" class="headerlink" title="Under-Display Camera Image Restoration with Scattering Effect"></a>Under-Display Camera Image Restoration with Scattering Effect</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04163">http://arxiv.org/abs/2308.04163</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/namecantbenull/srudc">https://github.com/namecantbenull/srudc</a></li>
<li>paper_authors: Binbin Song, Xiangyu Chen, Shuning Xu, Jiantao Zhou</li>
<li>for: 提供全屏视频经验而不受缺口或孔洞的干扰，但是半透明显示器引入了严重的图像干扰。</li>
<li>methods: 使用物理干扰模型来模拟显示器的散射效应，并改进图像synthesis的形成管道来构建真实的UDC数据集。</li>
<li>results: 提出了一种基于自注意力的两极分支网络，其中散射分支利用通道级自注意力来估算散射效应的参数，而图像分支利用CNN来恢复清晰的场景图像。对实验和 sinthezied 数据进行了广泛的测试，并证明了该方法在UDC图像恢复方面的优越性。<details>
<summary>Abstract</summary>
The under-display camera (UDC) provides consumers with a full-screen visual experience without any obstruction due to notches or punched holes. However, the semi-transparent nature of the display inevitably introduces the severe degradation into UDC images. In this work, we address the UDC image restoration problem with the specific consideration of the scattering effect caused by the display. We explicitly model the scattering effect by treating the display as a piece of homogeneous scattering medium. With the physical model of the scattering effect, we improve the image formation pipeline for the image synthesis to construct a realistic UDC dataset with ground truths. To suppress the scattering effect for the eventual UDC image recovery, a two-branch restoration network is designed. More specifically, the scattering branch leverages global modeling capabilities of the channel-wise self-attention to estimate parameters of the scattering effect from degraded images. While the image branch exploits the local representation advantage of CNN to recover clear scenes, implicitly guided by the scattering branch. Extensive experiments are conducted on both real-world and synthesized data, demonstrating the superiority of the proposed method over the state-of-the-art UDC restoration techniques. The source code and dataset are available at \url{https://github.com/NamecantbeNULL/SRUDC}.
</details>
<details>
<summary>摘要</summary>
“display under-camera（UDC）允许消耗者欣赏全屏视觉体验，不受萤幕上的不透明或孔径所阻碍。然而，半透明的萤幕将导致UDC图像受到严重的损坏。在这个工作中，我们解决UDC图像修复问题，特别是考虑到类推效应。我们明确地模型类推效应，将类推效应视为一个 homogeneous 散射媒体。使用物理模型，我们改善图像形成管道，以建立一个实际的 UDC 数据集，并提供真实的参考数据。为了抑制类推效应，我们设计了两条分支网络。更 specifically，类推分支利用通道wise self-attention 的全局模型能力，从受损图像中估计类推效应的参数。另一方面，图像分支利用 CNN 的地方表现优势，复原清晰的景象，协力地 guid 由类推分支。我们对真实和 sinthe 的数据进行了广泛的实验，展示了我们的方法与现有的 UDC 修复技术相比，具有superiority。请参考 \url{https://github.com/NamecantbeNULL/SRUDC} 以下载取源代码和数据。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention"><a href="#Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention" class="headerlink" title="Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention"></a>Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04156">http://arxiv.org/abs/2308.04156</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanning-zhang/satnet">https://github.com/fanning-zhang/satnet</a></li>
<li>paper_authors: Huilin Zhang, Sumei Li, Yongli Chang</li>
<li>for: This paper proposes a novel network for stereoscopic image quality assessment (SIQA) that utilizes a top-down approach to guide the quality assessment process.</li>
<li>methods: The proposed method employs a stereo attention mechanism that fuses high-level binocular signals with low-level monocular signals, and utilizes an energy coefficient to adaptively tune the magnitude of binocular responses. The method also utilizes a dual-pooling strategy to extract the most discriminative quality information from the two branches of monocular features.</li>
<li>results: Experimental results show that the proposed top-down method outperforms existing bottom-up methods in simulating the property of visual perception and advancing the state-of-the-art in the SIQA field.<details>
<summary>Abstract</summary>
Stereoscopic image quality assessment (SIQA) plays a crucial role in evaluating and improving the visual experience of 3D content. Existing binocular properties and attention-based methods for SIQA have achieved promising performance. However, these bottom-up approaches are inadequate in exploiting the inherent characteristics of the human visual system (HVS). This paper presents a novel network for SIQA via stereo attention, employing a top-down perspective to guide the quality assessment process. Our proposed method realizes the guidance from high-level binocular signals down to low-level monocular signals, while the binocular and monocular information can be calibrated progressively throughout the processing pipeline. We design a generalized Stereo AttenTion (SAT) block to implement the top-down philosophy in stereo perception. This block utilizes the fusion-generated attention map as a high-level binocular modulator, influencing the representation of two low-level monocular features. Additionally, we introduce an Energy Coefficient (EC) to account for recent findings indicating that binocular responses in the primate primary visual cortex are less than the sum of monocular responses. The adaptive EC can tune the magnitude of binocular response flexibly, thus enhancing the formation of robust binocular features within our framework. To extract the most discriminative quality information from the summation and subtraction of the two branches of monocular features, we utilize a dual-pooling strategy that applies min-pooling and max-pooling operations to the respective branches. Experimental results highlight the superiority of our top-down method in simulating the property of visual perception and advancing the state-of-the-art in the SIQA field. The code of this work is available at https://github.com/Fanning-Zhang/SATNet.
</details>
<details>
<summary>摘要</summary>
三维内容的视觉体验评估（SIQA）在评估和改进三维内容的视觉体验方面发挥关键性的作用。现有的异常性和注意力基于的方法已经实现了有前途的表现。然而，这些底层方法无法充分利用人类视觉系统（HVS）的内在特征。本文提出了一种新的网络 для SIQA，通过双目注意力来引导评估过程。我们的提议方法可以从高级双目信号下降到低级单目信号，而双目和单目信息可以在处理管道中进行满足进行进度性规整。我们设计了一种通用的双目注意力块（SAT）来实现上述哲学。这个块使用生成的注意力地图作为高级双目调制器，影响两个低级单目特征表示。此外，我们引入了能量系数（EC），以考虑实验发现，双目响应在人类初级视觉层中小于单目响应的现象。可以根据实际情况灵活调整EC的大小，从而提高在我们框架中形成的可靠双目特征。为了从两个分支中提取最有价值的质量信息，我们采用了双pooling策略，将各个分支的最小和最大池化操作应用于相应的分支。实验结果表明，我们的底层方法在模拟视觉启发和提高SIQA领域的状态而且取得了更好的表现。代码可以在https://github.com/Fanning-Zhang/SATNet上获取。
</details></li>
</ul>
<hr>
<h2 id="Physics-driven-universal-twin-image-removal-network-for-digital-in-line-holographic-microscopy"><a href="#Physics-driven-universal-twin-image-removal-network-for-digital-in-line-holographic-microscopy" class="headerlink" title="Physics-driven universal twin-image removal network for digital in-line holographic microscopy"></a>Physics-driven universal twin-image removal network for digital in-line holographic microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04471">http://arxiv.org/abs/2308.04471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikołaj Rogalski, Piotr Arcab, Luiza Stanaszek, Vicente Micó, Chao Zuo, Maciej Trusiak</li>
<li>for: 这项研究旨在开发一种能够高效、成本低的数字探针式干涉 Microscopy（DIHM）中的量子阶段成像技术，以便研究细胞运动、迁徙和生物微流体动力学。</li>
<li>methods: 该研究使用深度学习解决方案UTIRnet，可以快速、稳定、universally applicable地纹理双像干涉，并且通过数字生成的数据进行训练。</li>
<li>results: 实验证明，UTIRnet可以快速、稳定地抑制双像干涉，并且保持输入干涉图像的一致性，从而提高了计算量相对于传统深度学习方法的可靠性。此外，UTIRnet在live neural glial cell culture migration感知中得到了实验证明。<details>
<summary>Abstract</summary>
Digital in-line holographic microscopy (DIHM) enables efficient and cost-effective computational quantitative phase imaging with a large field of view, making it valuable for studying cell motility, migration, and bio-microfluidics. However, the quality of DIHM reconstructions is compromised by twin-image noise, posing a significant challenge. Conventional methods for mitigating this noise involve complex hardware setups or time-consuming algorithms with often limited effectiveness. In this work, we propose UTIRnet, a deep learning solution for fast, robust, and universally applicable twin-image suppression, trained exclusively on numerically generated datasets. The availability of open-source UTIRnet codes facilitates its implementation in various DIHM systems without the need for extensive experimental training data. Notably, our network ensures the consistency of reconstruction results with input holograms, imparting a physics-based foundation and enhancing reliability compared to conventional deep learning approaches. Experimental verification was conducted among others on live neural glial cell culture migration sensing, which is crucial for neurodegenerative disease research.
</details>
<details>
<summary>摘要</summary>
数字内线投射微镜（DIHM）可提供高效且成本下降的计算量相图像，大幅提高了生物学研究中cell motility、迁徙和生物微流体等领域的研究价值。然而，DIHM重建的质量受到双像噪声的限制，这成为一大挑战。传统的方法对这种噪声进行缓解通常包括复杂的硬件设置或时间消耗的算法，效果不一定。在这种工作中，我们提出了UTIRnet，一种深度学习解决方案，能够快速、稳定、universally aplicable的双像抑制。我们的网络具有数字生成的数据集进行培训，不需要大量的实验室训练数据。特别是，我们的网络保证重建结果与输入投射图像之间的一致性，从而增强了physics-based的基础和可靠性，与传统的深度学习方法相比。实验证明包括live neural glial cell culture migration感知等，这些研究对 neuroscience disease 有重要意义。
</details></li>
</ul>
<hr>
<h2 id="Single-shot-experimental-numerical-twin-image-removal-in-lensless-digital-holographic-microscopy"><a href="#Single-shot-experimental-numerical-twin-image-removal-in-lensless-digital-holographic-microscopy" class="headerlink" title="Single-shot experimental-numerical twin-image removal in lensless digital holographic microscopy"></a>Single-shot experimental-numerical twin-image removal in lensless digital holographic microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04131">http://arxiv.org/abs/2308.04131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piotr Arcab, Mikolaj Rogalski, Maciej Trusiak</li>
<li>for: 这篇论文旨在提出一种新的单shot实验数字折射镜微scopic技术，用于解决折射镜微scopic图像中的双像问题。</li>
<li>methods: 该技术基于两个源的偏心折射agram记录，使用简单的纤维分 splitting器实现。此外，该技术还提出了一种专门为获取的HOLOGRAMS数据进行 phase retrieval numerical algorithm，以提供无双像的重建。</li>
<li>results: 作者通过对频率测试目标和唾液细胞样本进行质量和量化验证，证明了该技术可以提供低成本、外围实验室的LDHM成像，并且可以提高图像的精度。这些结果开创了新的可靠性和生物医学成像应用领域，特别是在成本效益和可搬运性是关键的场景下。<details>
<summary>Abstract</summary>
Lensless digital holographic microscopy (LDHM) offers very large field-of-view label-free imaging crucial, e.g., in high-throughput particle tracking and biomedical examination of cells and tissues. Compact layouts promote point-of-case and out-of-laboratory applications. The LDHM, based on the Gabor in-line holographic principle, is inherently spoiled by the twin-image effect, which complicates the quantitative analysis of reconstructed phase and amplitude maps. Popular family of solutions consists of numerical methods, which tend to minimize twin-image upon iterative process based on data redundancy. Additional hologram recordings are needed, and final results heavily depend on the algorithmic parameters, however. In this contribution we present a novel single-shot experimental-numerical twin-image removal technique for LDHM. It leverages two-source off-axis hologram recording deploying simple fiber splitter. Additionally, we introduce a novel phase retrieval numerical algorithm specifically tailored to the acquired holograms, that provides twin-image-free reconstruction without compromising the resolution. We quantitatively and qualitatively verify proposed method employing phase test target and cheek cells biosample. The results demonstrate that the proposed technique enables low-cost, out-of-laboratory LDHM imaging with enhanced precision, achieved through the elimination of twin-image errors. This advancement opens new avenues for more accurate technical and biomedical imaging applications using LDHM, particularly in scenarios where cost-effective and portable imaging solutions are desired.
</details>
<details>
<summary>摘要</summary>
凡�жен数字投射icroscopy (LDHM) 提供了非常大的视场label-free 图像，对于高通过率粒子跟踪和生物医学Cells和组织的检查非常重要。 紧凑的设计使得点检测和出 laboratory 应用更加容易。基于Gabor直线投射原理的 LDHM 由于双像效应而受到质量分析重建phasemap和ampliute map中的干扰。通过数字方法来减少双像效应，但需要多个捕获图像，并且算法参数会影响最终结果。在这篇论文中，我们提出了一种新的单shot实验numerical twin-image removal技术，利用两个偏移 angle 的折分纤维Splitter来记录两个源的偏移 angle 折分图像。此外，我们还提出了一种专门为获取的ho lograms而设计的phaserecovery数字算法，可以在无需多个捕获图像的情况下提供无双像效应的重建结果，而且不会减少分辨率。我们使用phasetest target和唾液细胞样本进行量化和质量检测，结果表明，我们的方法可以提供低成本、出 laboratory的LDHM映像，并且提高了精度。这一进展打开了更多的技术和生物医学应用的可能性，特别是在成本效益和可搬式设备的情况下。
</details></li>
</ul>
<hr>
<h2 id="Non-Intrusive-Electric-Load-Monitoring-Approach-Based-on-Current-Feature-Visualization-for-Smart-Energy-Management"><a href="#Non-Intrusive-Electric-Load-Monitoring-Approach-Based-on-Current-Feature-Visualization-for-Smart-Energy-Management" class="headerlink" title="Non-Intrusive Electric Load Monitoring Approach Based on Current Feature Visualization for Smart Energy Management"></a>Non-Intrusive Electric Load Monitoring Approach Based on Current Feature Visualization for Smart Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11627">http://arxiv.org/abs/2308.11627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiwen Xu, Dengfeng Liu, Liangtao Huang, Zhiquan Lin, Tiesong Zhao, Sam Kwong</li>
<li>for: 这篇论文的目的是为智能城市的电力系统进行经济可效的能源管理。特别是监控和分析所有用户的电力负载。</li>
<li>methods: 这篇论文使用了人工智能的受欢迎计算机视觉技术，设计了一种非侵入式负载监控方法。首先，使用信号变换（包括波лет变换和离散傅立叶变换）和gramianangular场（GAF）方法将一维现在信号映射到二维色彩特征图像。其次，提出了使用U型深度神经网络，具有多尺度特征提取和注意机制，从色彩特征图像中识别所有的电力负载。</li>
<li>results: 实验结果显示，该方法在公共和私人数据集上均 achieves superior performance，并支持大规模互联网的非侵入式监控。<details>
<summary>Abstract</summary>
The state-of-the-art smart city has been calling for an economic but efficient energy management over large-scale network, especially for the electric power system. It is a critical issue to monitor, analyze and control electric loads of all users in system. In this paper, we employ the popular computer vision techniques of AI to design a non-invasive load monitoring method for smart electric energy management. First of all, we utilize both signal transforms (including wavelet transform and discrete Fourier transform) and Gramian Angular Field (GAF) methods to map one-dimensional current signals onto two-dimensional color feature images. Second, we propose to recognize all electric loads from color feature images using a U-shape deep neural network with multi-scale feature extraction and attention mechanism. Third, we design our method as a cloud-based, non-invasive monitoring of all users, thereby saving energy cost during electric power system control. Experimental results on both public and our private datasets have demonstrated our method achieves superior performances than its peers, and thus supports efficient energy management over large-scale Internet of Things (IoT).
</details>
<details>
<summary>摘要</summary>
现代智能城市需要一种经济高效的能源管理方法，特别是电力系统。监测、分析和控制所有用户的电压信号是一个关键问题。在这篇论文中，我们使用了人工智能的流行计算机视觉技术，设计了一种不侵入式的负荷监测方法。首先，我们使用了声波变换（包括wavelet transform和Discrete Fourier Transform）和 Gramian Angular Field（GAF）方法将一维电流信号映射到二维颜色特征图像上。其次，我们提议使用U型深度神经网络，并提取多个尺度的特征和注意机制来识别所有的电荷。最后，我们设计了一种云端的、不侵入式的监测方法，从而在电力系统控制中节省能源成本。实验结果表明，我们的方法在公共和私人数据集上达到了比其他方法更高的性能，因此支持了大规模互联网智能（IoT）中的高效能源管理。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Semi-Supervised-Detection-in-Lung-Ultrasound-Videos"><a href="#Weakly-Semi-Supervised-Detection-in-Lung-Ultrasound-Videos" class="headerlink" title="Weakly Semi-Supervised Detection in Lung Ultrasound Videos"></a>Weakly Semi-Supervised Detection in Lung Ultrasound Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04463">http://arxiv.org/abs/2308.04463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahong Ouyang, Li Chen, Gary Y. Li, Naveen Balaraju, Shubham Patil, Courosh Mehanian, Sourabh Kulhare, Rachel Millin, Kenton W. Gregory, Cynthia R. Gregory, Meihua Zhu, David O. Kessler, Laurie Malia, Almaz Dessie, Joni Rabiner, Di Coneybeare, Bo Shopsin, Andrew Hersh, Cristian Madar, Jeffrey Shupp, Laura S. Johnson, Jacob Avila, Kristin Dwyer, Peter Weimersheimer, Balasundar Raju, Jochen Kruecker, Alvin Chen</li>
<li>for: 医学视频数据上进行全supervised对象检测模型训练中需要临床专家进行 Frame-by-frame 注解 boundling box.</li>
<li>methods: 我们提出了一种基于弱级别 labels 的方法，将个体检测预测结果聚合到视频级别预测中，并通过视频级别损失来提供额外约束。我们还介绍了一些改进 pseudo-labels 的方法，以及适应性调整知识传递Student 和 teacher 网络之间的调整方案。</li>
<li>results: 我们在医学超声视频中检测肺聚集（如 COVID-19 肺炎）的方法中应用了这种方法，实验表明，我们的框架可以提高检测精度和鲁棒性，并提高数据和注解使用效率。<details>
<summary>Abstract</summary>
Frame-by-frame annotation of bounding boxes by clinical experts is often required to train fully supervised object detection models on medical video data. We propose a method for improving object detection in medical videos through weak supervision from video-level labels. More concretely, we aggregate individual detection predictions into video-level predictions and extend a teacher-student training strategy to provide additional supervision via a video-level loss. We also introduce improvements to the underlying teacher-student framework, including methods to improve the quality of pseudo-labels based on weak supervision and adaptive schemes to optimize knowledge transfer between the student and teacher networks. We apply this approach to the clinically important task of detecting lung consolidations (seen in respiratory infections such as COVID-19 pneumonia) in medical ultrasound videos. Experiments reveal that our framework improves detection accuracy and robustness compared to baseline semi-supervised models, and improves efficiency in data and annotation usage.
</details>
<details>
<summary>摘要</summary>
<SYS>医学视频数据上进行完全监督物体检测模型训练常需要 клиниче专家进行框架帧标注。我们提出一种基于弱监督的方法，通过视频级别标签来改进医学视频中的物体检测。更具体来说，我们将个体检测预测结果聚合成视频级别预测，并通过视频级别损失来提供额外监督。我们还介绍了改进 teacher-student 框架的方法，包括基于弱监督的pseudo标签质量改进和 adaptive 优化学习知识传递between teacher和学生网络。我们在识别尘埃散发（常见于呼吸道感染，如 COVID-19 肺炎）的医学超声视频中应用这种方法。实验表明，我们的框架可以提高检测精度和可靠性，并提高数据和标注的使用效率。</SYS>Here's the text with some minor adjustments to make it more natural in Simplified Chinese:<SYS>医学视频数据上训练完全监督物体检测模型时，常常需要 клиниче专家进行框架帧标注。我们提出一种基于弱监督的方法，通过视频级别标签来改进医学视频中的物体检测。更具体来说，我们将个体检测预测结果聚合成视频级别预测，并通过视频级别损失来提供额外监督。我们还介绍了改进 teacher-student 框架的方法，包括基于弱监督的pseudo标签质量改进和 adaptive 优化学习知识传递between teacher和学生网络。我们在识别尘埃散发（常见于呼吸道感染，如 COVID-19 肺炎）的医学超声视频中应用这种方法。实验表明，我们的框架可以提高检测精度和可靠性，并提高数据和标注的使用效率。</SYS>Please note that the translation is based on the original text and may not capture all the nuances and details of the original text.
</details></li>
</ul>
<hr>
<h2 id="DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction"><a href="#DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction" class="headerlink" title="DefCor-Net: Physics-Aware Ultrasound Deformation Correction"></a>DefCor-Net: Physics-Aware Ultrasound Deformation Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03865">http://arxiv.org/abs/2308.03865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karolinezhy/defcornet">https://github.com/karolinezhy/defcornet</a></li>
<li>paper_authors: Zhongliang Jiang, Yue Zhou, Dongliang Cao, Nassir Navab</li>
<li>for:  correction of deformed anatomical images in ultrasound (US) image acquisition</li>
<li>methods: multi-scale deep neural network (DefCor-Net) with biomedical knowledge and real-time estimation of pixel-wise tissue properties</li>
<li>results: significant improvement in accuracy of deformation correction (Dice Coefficient: from $14.3\pm20.9$ to $82.6\pm12.1$ when the force is $6N$)<details>
<summary>Abstract</summary>
The recovery of morphologically accurate anatomical images from deformed ones is challenging in ultrasound (US) image acquisition, but crucial to accurate and consistent diagnosis, particularly in the emerging field of computer-assisted diagnosis. This article presents a novel anatomy-aware deformation correction approach based on a coarse-to-fine, multi-scale deep neural network (DefCor-Net). To achieve pixel-wise performance, DefCor-Net incorporates biomedical knowledge by estimating pixel-wise stiffness online using a U-shaped feature extractor. The deformation field is then computed using polynomial regression by integrating the measured force applied by the US probe. Based on real-time estimation of pixel-by-pixel tissue properties, the learning-based approach enables the potential for anatomy-aware deformation correction. To demonstrate the effectiveness of the proposed DefCor-Net, images recorded at multiple locations on forearms and upper arms of six volunteers are used to train and validate DefCor-Net. The results demonstrate that DefCor-Net can significantly improve the accuracy of deformation correction to recover the original geometry (Dice Coefficient: from $14.3\pm20.9$ to $82.6\pm12.1$ when the force is $6N$).
</details>
<details>
<summary>摘要</summary>
医学影像中的形态准确度恢复问题在ultrasound（US）图像获取中是一个挑战，但是对医学诊断的准确性和一致性很重要，特别是在计算机助理诊断领域。这篇文章提出了一种基于多尺度深度神经网络（DefCor-Net）的新型形态意识恢复方法。为了实现像素级性能，DefCor-Net在核心网络中加入了生物医学知识，通过在U型特征提取器中线性估计每个像素的刚性来实现。然后，通过积分测量US probes应用的力场来计算扭formation场。基于实时测量像素级刚性特性，这种学习基于的方法具有可能性 для形态意识恢复。为了证明DefCor-Net的效果，文章使用了多个臂部和上臂部的六名志愿者记录的图像进行训练和验证。结果表明，DefCor-Net可以显著提高恢复原geometry的准确度（Dice Coefficient：从14.3±20.9到82.6±12.1，当力场为6N）。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://example.com/2023/08/08/eess.IV_2023_08_08/" data-id="cllt9pry80098ol8805xcbf3j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/4/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">43</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">42</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">27</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">44</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">53</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">114</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
