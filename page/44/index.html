
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/44/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.CV_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T13:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.CV_2023_09_02/">cs.CV - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SEPAL-Spatial-Gene-Expression-Prediction-from-Local-Graphs"><a href="#SEPAL-Spatial-Gene-Expression-Prediction-from-Local-Graphs" class="headerlink" title="SEPAL: Spatial Gene Expression Prediction from Local Graphs"></a>SEPAL: Spatial Gene Expression Prediction from Local Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01036">http://arxiv.org/abs/2309.01036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcv-uniandes/sepal">https://github.com/bcv-uniandes/sepal</a></li>
<li>paper_authors: Gabriel Mejia, Paula Cárdenas, Daniela Ruiz, Angela Castillo, Pablo Arbeláez</li>
<li>for: 这项研究旨在开发一种新的模型，以便从视觉组织形态中预测基因表达 Profiling。</li>
<li>methods: 该方法利用生物学上的偏好，直接使用相对均值对表达进行超级视觉上的预测，并在每个坐标上使用图神经网络利用本地视觉上下文进行预测。</li>
<li>results: 研究表明，SEPAL模型在两个人类乳腺癌数据集中表现出色，超过了之前的州OF-the-art方法和其他包含空间上下文的机制。<details>
<summary>Abstract</summary>
Spatial transcriptomics is an emerging technology that aligns histopathology images with spatially resolved gene expression profiling. It holds the potential for understanding many diseases but faces significant bottlenecks such as specialized equipment and domain expertise. In this work, we present SEPAL, a new model for predicting genetic profiles from visual tissue appearance. Our method exploits the biological biases of the problem by directly supervising relative differences with respect to mean expression, and leverages local visual context at every coordinate to make predictions using a graph neural network. This approach closes the gap between complete locality and complete globality in current methods. In addition, we propose a novel benchmark that aims to better define the task by following current best practices in transcriptomics and restricting the prediction variables to only those with clear spatial patterns. Our extensive evaluation in two different human breast cancer datasets indicates that SEPAL outperforms previous state-of-the-art methods and other mechanisms of including spatial context.
</details>
<details>
<summary>摘要</summary>
《空间转录组学是一种emerging技术，可以将组织学图像与空间地定的蛋白表达 profiling进行对应。它有很大的潜力用于理解多种疾病，但面临着重要的瓶颈，例如专业设备和领域专业知识。在这项工作中，我们提出了一种新的模型，可以从视觉组织表现中预测基因谱。我们的方法利用生物学上的偏见，直接监督表达差异相对于平均表达水平，并利用每个坐标点的本地视觉上下文来进行预测，使用图 neural network。这种方法可以在当前方法中关闭完全地方性和完全全球性之间的差距。此外，我们还提出了一个新的标准测试，以更好地定义任务，并且只Predicting variables with clear spatial patterns。我们对两个不同的人乳癌组织数据集进行了广泛的评估，结果显示，SEPAL在前一个状态的方法和其他包含空间上下文的机制上表现出色。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Grouping-with-Transformer-for-Referring-Image-Segmentation"><a href="#Contrastive-Grouping-with-Transformer-for-Referring-Image-Segmentation" class="headerlink" title="Contrastive Grouping with Transformer for Referring Image Segmentation"></a>Contrastive Grouping with Transformer for Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01017">http://arxiv.org/abs/2309.01017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toneyaya/cgformer">https://github.com/toneyaya/cgformer</a></li>
<li>paper_authors: Jiajin Tang, Ge Zheng, Cheng Shi, Sibei Yang</li>
<li>for: 本研究旨在提高图像分割中的参照语言表达的准确率，使用mask classification方法和token-based查询 grouping策略来捕捉 объек级信息。</li>
<li>methods: 本研究提出了一种名为Contrastive Grouping with Transformer network（CGFormer）的掩码分类方法，该方法通过学习可变的查询токен来表示 объек，然后在每两层之间交叉升级查询语言特征和视觉特征，以实现对象感知的跨模态理解。此外，CGFormer还应用了对比学习策略来识别查询Token和其掩码。</li>
<li>results: 实验结果表明，CGFormer在分割和泛化设定下都能够具有州元的性能，与现有的一阶方法相比，CGFormer在对象分割任务中具有显著的优势。<details>
<summary>Abstract</summary>
Referring image segmentation aims to segment the target referent in an image conditioning on a natural language expression. Existing one-stage methods employ per-pixel classification frameworks, which attempt straightforwardly to align vision and language at the pixel level, thus failing to capture critical object-level information. In this paper, we propose a mask classification framework, Contrastive Grouping with Transformer network (CGFormer), which explicitly captures object-level information via token-based querying and grouping strategy. Specifically, CGFormer first introduces learnable query tokens to represent objects and then alternately queries linguistic features and groups visual features into the query tokens for object-aware cross-modal reasoning. In addition, CGFormer achieves cross-level interaction by jointly updating the query tokens and decoding masks in every two consecutive layers. Finally, CGFormer cooperates contrastive learning to the grouping strategy to identify the token and its mask corresponding to the referent. Experimental results demonstrate that CGFormer outperforms state-of-the-art methods in both segmentation and generalization settings consistently and significantly.
</details>
<details>
<summary>摘要</summary>
传统的一个阶段方法使用每个像素的分类框架，直接将视觉和语言对齐到像素级别，因此无法捕捉关键的物体水平信息。在这篇论文中，我们提出了一种面Mask分类框架，即对比集成Transformers网络（CGFormer），它显式地捕捉物体水平信息，通过启用可学习的查询令和分组策略。具体来说，CGFormer首先引入了可学习的查询令，用于表示物体，然后在每两层交替地查询语言特征和视觉特征，并将视觉特征分组到查询令中进行对应的横向推理。此外，CGFormer实现了交叉层交互，在每两层中同时更新查询令和推理mask。最后，CGFormer与对比学习结合分组策略，以确定查询令和其对应的推理mask。实验结果表明，CGFormer在 segmentation 和通用设定下能够一直高效地和稳定地 exceed 状态元方法。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Deep-Learning-Architectures-for-Breast-Cancer-Diagnosis-Using-the-BreaKHis-Dataset"><a href="#Comparative-Analysis-of-Deep-Learning-Architectures-for-Breast-Cancer-Diagnosis-Using-the-BreaKHis-Dataset" class="headerlink" title="Comparative Analysis of Deep Learning Architectures for Breast Cancer Diagnosis Using the BreaKHis Dataset"></a>Comparative Analysis of Deep Learning Architectures for Breast Cancer Diagnosis Using the BreaKHis Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01007">http://arxiv.org/abs/2309.01007</a></li>
<li>repo_url: None</li>
<li>paper_authors: İrem Sayın, Muhammed Ali Soydaş, Yunus Emre Mert, Arda Yarkataş, Berk Ergun, Selma Sözen Yeh, Hüseyin Üvet</li>
<li>for: 评估深度学习模型在识别乳腺癌中的表现</li>
<li>methods: 使用和比较五种知名的深度学习模型进行诊断：VGG、ResNet、Xception、Inception和InceptionResNet</li>
<li>results: Xception模型在F1分数方面达到了0.9，准确率达到了89%，而Inception和InceptionResNet模型均达到了87%的准确率，但Inception模型的F1分数为87，而InceptionResNet模型的F1分数为86。这些结果表明深度学习方法在诊断乳腺癌中的重要性，并且有助于提供更好的诊断服务给患者。<details>
<summary>Abstract</summary>
Cancer is an extremely difficult and dangerous health problem because it manifests in so many different ways and affects so many different organs and tissues. The primary goal of this research was to evaluate deep learning models' ability to correctly identify breast cancer cases using the BreakHis dataset. The BreakHis dataset covers a wide range of breast cancer subtypes through its huge collection of histopathological pictures. In this study, we use and compare the performance of five well-known deep learning models for cancer classification: VGG, ResNet, Xception, Inception, and InceptionResNet. The results placed the Xception model at the top, with an F1 score of 0.9 and an accuracy of 89%. At the same time, the Inception and InceptionResNet models both hit accuracy of 87% . However, the F1 score for the Inception model was 87, while that for the InceptionResNet model was 86. These results demonstrate the importance of deep learning methods in making correct breast cancer diagnoses. This highlights the potential to provide improved diagnostic services to patients. The findings of this study not only improve current methods of cancer diagnosis, but also make significant contributions to the creation of new and improved cancer treatment strategies. In a nutshell, the results of this study represent a major advancement in the direction of achieving these vital healthcare goals.
</details>
<details>
<summary>摘要</summary>
乳癌是一种极其困难和危险的健康问题，因为它可以出现在多种不同的形式和影响多种不同的器官和组织。本研究的主要目标是评估深度学习模型在识别乳癌案例方面的性能，使用BreakHis数据集。BreakHis数据集包括多种乳癌Subtype的历史病理图像，因此我们可以使用和比较五种常见的深度学习模型对于肿瘤分类的性能：VGG、ResNet、Xception、Inception和InceptionResNet。结果显示，Xception模型在F1分数方面得分为0.9，准确率为89%。同时，Inception和InceptionResNet模型都达到了87%的准确率。但是，Inception模型的F1分数为87，而InceptionResNet模型的F1分数为86。这些结果表明深度学习方法在识别乳癌案例中的重要性，这也提供了改善临床诊断服务的可能性。这些发现不仅改进了当前肿瘤诊断方法，还为创造新的和改进的肿瘤治疗策略做出了重要贡献。总之，本研究的结果代表了肿瘤诊断领域的一大突破。
</details></li>
</ul>
<hr>
<h2 id="RevColV2-Exploring-Disentangled-Representations-in-Masked-Image-Modeling"><a href="#RevColV2-Exploring-Disentangled-Representations-in-Masked-Image-Modeling" class="headerlink" title="RevColV2: Exploring Disentangled Representations in Masked Image Modeling"></a>RevColV2: Exploring Disentangled Representations in Masked Image Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01005">http://arxiv.org/abs/2309.01005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/megvii-research/revcol">https://github.com/megvii-research/revcol</a></li>
<li>paper_authors: Qi Han, Yuxuan Cai, Xiangyu Zhang</li>
<li>for: 这个研究目的是提出一个新的架构，RevColV2，来解决现有的掩护图像模型（MIM）方法中驱逐decoder网络的问题，以提高下游任务的表现。</li>
<li>methods: RevColV2架构包含底部Column和顶部Column，这两种Column之间的信息是逆向传递和慢态分解的。这种设计使得RevColV2架构保持了掩护图像模型中的独立低阶和semantic信息。</li>
<li>results: 实验结果显示，使用RevColV2架构的基础模型可以在多个下游视觉任务中实现竞争性的表现，例如图像分类、semantic segmentation和物件检测。例如，在ImageNet-22K dataset上进行中途精通的finetuning后，RevColV2-L可以实现88.4%的top-1准确率和58.6 mIoU的semantic segmentation准确率。<details>
<summary>Abstract</summary>
Masked image modeling (MIM) has become a prevalent pre-training setup for vision foundation models and attains promising performance. Despite its success, existing MIM methods discard the decoder network during downstream applications, resulting in inconsistent representations between pre-training and fine-tuning and can hamper downstream task performance. In this paper, we propose a new architecture, RevColV2, which tackles this issue by keeping the entire autoencoder architecture during both pre-training and fine-tuning. The main body of RevColV2 contains bottom-up columns and top-down columns, between which information is reversibly propagated and gradually disentangled. Such design enables our architecture with the nice property: maintaining disentangled low-level and semantic information at the end of the network in MIM pre-training. Our experimental results suggest that a foundation model with decoupled features can achieve competitive performance across multiple downstream vision tasks such as image classification, semantic segmentation and object detection. For example, after intermediate fine-tuning on ImageNet-22K dataset, RevColV2-L attains 88.4% top-1 accuracy on ImageNet-1K classification and 58.6 mIoU on ADE20K semantic segmentation. With extra teacher and large scale dataset, RevColv2-L achieves 62.1 box AP on COCO detection and 60.4 mIoU on ADE20K semantic segmentation. Code and models are released at https://github.com/megvii-research/RevCol
</details>
<details>
<summary>摘要</summary>
受预训练掩模型（MIM）的普遍使用，已经取得了领先的表现。然而，现有的MIM方法在下游应用中抛弃了解码器网络，导致预训练和细化 phases的表现不一致，从而降低下游任务的表现。在本文中，我们提出了一种新的架构——RevColV2，以解决这个问题。RevColV2架构包括底层列和顶层列，这两个列之间的信息在反向传播的过程中被恰当地传递和慢慢分离。这种设计使得RevColV2架构保持了预训练和细化 phases中的独立特征，从而实现了维持低级别特征和 semantic 信息的优良性。我们的实验结果表明，一个基于RevColV2架构的基础模型可以在多个下游视觉任务上达到竞争性的表现，如图像分类、semantic segmentation和物体检测。例如，在ImageNet-22K数据集上进行中间细化训练后，RevColV2-L模型可以达到88.4%的顶层准确率和58.6 mIoU的semantic segmentation精度。另外，通过添加教师和大规模数据集，RevColV2-L模型可以达到62.1个box AP和60.4 mIoU的semantic segmentation精度。代码和模型可以在https://github.com/megvii-research/RevCol 上下载。
</details></li>
</ul>
<hr>
<h2 id="Constrained-CycleGAN-for-Effective-Generation-of-Ultrasound-Sector-Images-of-Improved-Spatial-Resolution"><a href="#Constrained-CycleGAN-for-Effective-Generation-of-Ultrasound-Sector-Images-of-Improved-Spatial-Resolution" class="headerlink" title="Constrained CycleGAN for Effective Generation of Ultrasound Sector Images of Improved Spatial Resolution"></a>Constrained CycleGAN for Effective Generation of Ultrasound Sector Images of Improved Spatial Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00995">http://arxiv.org/abs/2309.00995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xfsun99/ccyclegan-tf2">https://github.com/xfsun99/ccyclegan-tf2</a></li>
<li>paper_authors: Xiaofei Sun, He Li, Wei-Ning Lee<br>for: 这个研究的目的是将多普勒超声图像（US）的空间分辨率改善，以提高心脏动态运动的评估质量。methods: 这个研究使用了一种名为CCycleGAN的新型的循环GAN模型，该模型直接使用不同的超声探针所获取的无对对的US图像进行生成。此外，CCycleGAN还引入了一种新的束约条件，以保证生成图像的结构一致性和吸收信号特征的一致性。results: 实验结果表明，CCycleGAN可以成功地生成高空间分辨率的US图像，同时也提高了图像的峰信号噪声比（PSNR）和结构相似度（SSIM）。此外，CCycleGAN生成的US图像在人体内部的心脏运动评估中也有更高的质量，特别是在深部区域。<details>
<summary>Abstract</summary>
Objective. A phased or a curvilinear array produces ultrasound (US) images with a sector field of view (FOV), which inherently exhibits spatially-varying image resolution with inferior quality in the far zone and towards the two sides azimuthally. Sector US images with improved spatial resolutions are favorable for accurate quantitative analysis of large and dynamic organs, such as the heart. Therefore, this study aims to translate US images with spatially-varying resolution to ones with less spatially-varying resolution. CycleGAN has been a prominent choice for unpaired medical image translation; however, it neither guarantees structural consistency nor preserves backscattering patterns between input and generated images for unpaired US images. Approach. To circumvent this limitation, we propose a constrained CycleGAN (CCycleGAN), which directly performs US image generation with unpaired images acquired by different ultrasound array probes. In addition to conventional adversarial and cycle-consistency losses of CycleGAN, CCycleGAN introduces an identical loss and a correlation coefficient loss based on intrinsic US backscattered signal properties to constrain structural consistency and backscattering patterns, respectively. Instead of post-processed B-mode images, CCycleGAN uses envelope data directly obtained from beamformed radio-frequency signals without any other non-linear postprocessing. Main Results. In vitro phantom results demonstrate that CCycleGAN successfully generates images with improved spatial resolution as well as higher peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) compared with benchmarks. Significance. CCycleGAN-generated US images of the in vivo human beating heart further facilitate higher quality heart wall motion estimation than benchmarks-generated ones, particularly in deep regions.
</details>
<details>
<summary>摘要</summary>
目标：使用phasized或curvilinear array生成ultrasound（US）图像，图像具有锐度场视野（FOV），这些图像自然而然地在远区和两侧扫描方向展现空间不均匀的图像解析质量。锐度US图像有助于准确地量化大小和动态的器官，如心脏。因此，本研究的目标是将US图像中的空间不均匀的图像解析转换为更少的空间不均匀的图像解析。方法：我们提出了一种受限制的CycleGAN（CCycleGAN），该模型直接使用不同ultrasound array探针获取的无对应图像来生成US图像。除了传统的对抗学习和循环一致性损失外，CCycleGAN还引入了基于US回射信号特性的相同损失和相关系数损失，以确保结构一致性和回射特征的保持。而不是使用后处理的B模式图像，CCycleGAN使用直接从Radio frequency信号中得到的封包数据，无需其他非线性后处理。主要结果：在医学实验室中，我们使用了医学实验室中的人工胚膜模型，对CCycleGAN进行了测试。结果表明，CCycleGAN成功地生成了高分辨率的US图像，同时具有更高的PSNR和SSIM值，比benchmarks更高。意义：CCycleGAN生成的US图像可以更好地估计人体心脏墙运动，特别是在深部区域。这些结果表明，CCycleGAN可以成为一种有用的医学图像翻译工具，可以帮助医生更好地诊断和治疗各种疾病。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Framework-for-Optimal-Selection-of-Soil-Sampling-Sites"><a href="#Deep-Learning-Framework-for-Optimal-Selection-of-Soil-Sampling-Sites" class="headerlink" title="Deep-Learning Framework for Optimal Selection of Soil Sampling Sites"></a>Deep-Learning Framework for Optimal Selection of Soil Sampling Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00974">http://arxiv.org/abs/2309.00974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tan-Hanh Pham, Praneel Acharya, Sravanthi Bachina, Kristopher Osterloh, Kim-Doang Nguyen</li>
<li>for: 本研究使用深度学习技术来找到适合挖取样本的场地。</li>
<li>methods: 本研究使用了两种方法：一是使用现有的state-of-the-art模型，二是开发了一种基于转换器和自注意的深度学习设计。</li>
<li>results: 研究结果表明，我们提出的模型在测试数据集上达到了99.52%的准确率，57.35%的交集 overlap（IoU）和71.47%的 dice相似度，而现有的CNN模型的性能指标分别为66.08%、3.85%和1.98%。这表明我们的模型在土壤抽样数据集上表现出了优异性。<details>
<summary>Abstract</summary>
This work leverages the recent advancements of deep learning in image processing to find optimal locations that present the important characteristics of a field. The data for training are collected at different fields in local farms with five features: aspect, flow accumulation, slope, NDVI (normalized difference vegetation index), and yield. The soil sampling dataset is challenging because the ground truth is highly imbalanced binary images. Therefore, we approached the problem with two methods, the first approach involves utilizing a state-of-the-art model with the convolutional neural network (CNN) backbone, while the second is to innovate a deep-learning design grounded in the concepts of transformer and self-attention. Our framework is constructed with an encoder-decoder architecture with the self-attention mechanism as the backbone. In the encoder, the self-attention mechanism is the key feature extractor, which produces feature maps. In the decoder, we introduce atrous convolution networks to concatenate, fuse the extracted features, and then export the optimal locations for soil sampling. Currently, the model has achieved impressive results on the testing dataset, with a mean accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean Dice Coefficient of 71.47%, while the performance metrics of the state-of-the-art CNN-based model are 66.08%, 3.85%, and 1.98%, respectively. This indicates that our proposed model outperforms the CNN-based method on the soil-sampling dataset. To the best of our knowledge, our work is the first to provide a soil-sampling dataset with multiple attributes and leverage deep learning techniques to enable the automatic selection of soil-sampling sites. This work lays a foundation for novel applications of data science and machine-learning technologies to solve other emerging agricultural problems.
</details>
<details>
<summary>摘要</summary>
The team tested their model on a challenging dataset and achieved impressive results, with a mean accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean Dice Coefficient of 71.47%. These results are significantly better than those achieved by a state-of-the-art CNN-based model, which had a mean accuracy of 66.08%, a mean IoU of 3.85%, and a mean Dice Coefficient of 1.98%.This work is the first to provide a soil-sampling dataset with multiple attributes and use deep learning techniques to automatically select soil-sampling sites. The team believes that their approach could be used to solve other emerging agricultural problems and lay the foundation for novel applications of data science and machine learning in agriculture.
</details></li>
</ul>
<hr>
<h2 id="AdLER-Adversarial-Training-with-Label-Error-Rectification-for-One-Shot-Medical-Image-Segmentation"><a href="#AdLER-Adversarial-Training-with-Label-Error-Rectification-for-One-Shot-Medical-Image-Segmentation" class="headerlink" title="AdLER: Adversarial Training with Label Error Rectification for One-Shot Medical Image Segmentation"></a>AdLER: Adversarial Training with Label Error Rectification for One-Shot Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00971">http://arxiv.org/abs/2309.00971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hsiangyuzhao/adler">https://github.com/hsiangyuzhao/adler</a></li>
<li>paper_authors: Xiangyu Zhao, Sheng Wang, Zhiyun Song, Zhenrong Shen, Linlin Yao, Haolei Yuan, Qian Wang, Lichi Zhang</li>
<li>for: 这个研究的目的是提高医疗图像自动分类的精度，特别是在丑化训练数据的情况下。</li>
<li>methods: 这个方法使用了学习变数的一对一分类（OSSLT），包括不断变数注册、学习注册和注册变数的分类。</li>
<li>results: 这个研究的结果显示，这个新的一对一分类方法（AdLER）可以提高分类性能，并且在没有足够训练数据的情况下具有更好的一致性和更高的精度。<details>
<summary>Abstract</summary>
Accurate automatic segmentation of medical images typically requires large datasets with high-quality annotations, making it less applicable in clinical settings due to limited training data. One-shot segmentation based on learned transformations (OSSLT) has shown promise when labeled data is extremely limited, typically including unsupervised deformable registration, data augmentation with learned registration, and segmentation learned from augmented data. However, current one-shot segmentation methods are challenged by limited data diversity during augmentation, and potential label errors caused by imperfect registration. To address these issues, we propose a novel one-shot medical image segmentation method with adversarial training and label error rectification (AdLER), with the aim of improving the diversity of generated data and correcting label errors to enhance segmentation performance. Specifically, we implement a novel dual consistency constraint to ensure anatomy-aligned registration that lessens registration errors. Furthermore, we develop an adversarial training strategy to augment the atlas image, which ensures both generation diversity and segmentation robustness. We also propose to rectify potential label errors in the augmented atlas images by estimating segmentation uncertainty, which can compensate for the imperfect nature of deformable registration and improve segmentation authenticity. Experiments on the CANDI and ABIDE datasets demonstrate that the proposed AdLER outperforms previous state-of-the-art methods by 0.7% (CANDI), 3.6% (ABIDE "seen"), and 4.9% (ABIDE "unseen") in segmentation based on Dice scores, respectively. The source code will be available at https://github.com/hsiangyuzhao/AdLER.
</details>
<details>
<summary>摘要</summary>
通常，医疗图像自动分割需要大量高质量标注数据，因此在临床设置下采用自动分割是更加困难的。一旦分割基于学习的变换（OSSLT）已经展示了在有限的标注数据下可以取得满意的结果，包括不supervised deformable registration、数据增强通过学习 registration以及基于增强数据进行分割学习。然而，当数据多样性很低时，当前一旦分割方法会受到多样性不足的限制，以及可能的标签错误引起的registration错误。为了解决这些问题，我们提出了一种基于对抗学习和标签修正的新一代医疗图像分割方法（AdLER），以提高分割性能。具体来说，我们实现了一种双重一致性约束，以降低注射错误。此外，我们开发了一种对抗训练策略，以增强生成数据的多样性和分割的Robustness。此外，我们还提出了一种纠正可能存在的标签错误的方法，通过估算分割不确定性，可以补偿杂论注射和提高分割的authenticity。实验结果表明，提案的AdLER方法在CANDI和ABIDE datasets上比前一代方法提高0.7%（CANDI）、3.6%（ABIDE "seen")和4.9%（ABIDE "unseen")的分割基于dice scores，分别。源代码将在https://github.com/hsiangyuzhao/AdLER上提供。
</details></li>
</ul>
<hr>
<h2 id="NTU4DRadLM-4D-Radar-centric-Multi-Modal-Dataset-for-Localization-and-Mapping"><a href="#NTU4DRadLM-4D-Radar-centric-Multi-Modal-Dataset-for-Localization-and-Mapping" class="headerlink" title="NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and Mapping"></a>NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00962">http://arxiv.org/abs/2309.00962</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junzhang2016/NTU4DRadLM">https://github.com/junzhang2016/NTU4DRadLM</a></li>
<li>paper_authors: Jun Zhang, Huayang Zhuge, Yiyao Liu, Guohao Peng, Zhenyu Wu, Haoyuan Zhang, Qiyang Lyu, Heshan Li, Chunyang Zhao, Dogan Kircali, Sanat Mharolkar, Xun Yang, Su Yi, Yuanzhe Wang, Danwei Wang</li>
<li>for:  This paper is written for researchers and developers who are interested in Simultaneous Localization and Mapping (SLAM) using 4D radar, thermal camera, and Inertial Measurement Unit (IMU).</li>
<li>methods: The paper presents a new dataset called NTU4DRadLM, which includes all 6 sensors (4D radar, thermal camera, IMU, 3D LiDAR, visual camera, and RTK GPS) and is specifically designed for SLAM tasks.</li>
<li>results: The paper evaluates three types of SLAM algorithms using the NTU4DRadLM dataset and reports the results, which include the accuracy of the algorithms in various environments.Here’s the simplified Chinese version:</li>
<li>for: 这篇论文是为了帮助关注同时定位和地图建模（SLAM）领域的研究人员和开发者。</li>
<li>methods: 这篇论文提出了一个新的数据集called NTU4DRadLM，该数据集包含了所有6种感知器（4D radar、热成像、IMU、3D LiDAR、视频相机和RTK GPS），并且特意设计用于SLAM任务。</li>
<li>results: 这篇论文使用NTU4DRadLM数据集评估了三种SLAM算法的性能，并报告了结果，其中包括不同环境下的算法准确性。<details>
<summary>Abstract</summary>
Simultaneous Localization and Mapping (SLAM) is moving towards a robust perception age. However, LiDAR- and visual- SLAM may easily fail in adverse conditions (rain, snow, smoke and fog, etc.). In comparison, SLAM based on 4D Radar, thermal camera and IMU can work robustly. But only a few literature can be found. A major reason is the lack of related datasets, which seriously hinders the research. Even though some datasets are proposed based on 4D radar in past four years, they are mainly designed for object detection, rather than SLAM. Furthermore, they normally do not include thermal camera. Therefore, in this paper, NTU4DRadLM is presented to meet this requirement. The main characteristics are: 1) It is the only dataset that simultaneously includes all 6 sensors: 4D radar, thermal camera, IMU, 3D LiDAR, visual camera and RTK GPS. 2) Specifically designed for SLAM tasks, which provides fine-tuned ground truth odometry and intentionally formulated loop closures. 3) Considered both low-speed robot platform and fast-speed unmanned vehicle platform. 4) Covered structured, unstructured and semi-structured environments. 5) Considered both middle- and large- scale outdoor environments, i.e., the 6 trajectories range from 246m to 6.95km. 6) Comprehensively evaluated three types of SLAM algorithms. Totally, the dataset is around 17.6km, 85mins, 50GB and it will be accessible from this link: https://github.com/junzhang2016/NTU4DRadLM
</details>
<details>
<summary>摘要</summary>
《同时地位和地图Localization（SLAM）正在迈向一个强大的感知年代。然而，雷达和视觉SLAM可能在不利的条件下（雨、雪、烟雾等）容易失败。相比之下，基于4D雷达、热成像和IMU的SLAM可以工作稳定。然而，相关的数据集很少，这使得研究受到了严重的阻碍。尽管过去四年有一些基于4D雷达的数据集被提出，但是它们主要是为了对象检测而不是SLAM。此外，它们通常不包括热成像。因此，本文提出了NTU4DRadLM数据集。NTU4DRadLM的主要特点包括：1. 同时包含6种感知器：4D雷达、热成像、IMU、3D雷达、视觉摄像头和RTK GPS。2. 专门为SLAM任务设计，提供精度调整的地理位置轨迹和故意设计的循环关闭。3. 考虑了中速和快速无人车平台。4. 覆盖结构化、无结构化和半结构化环境。5. 考虑了中型和大型的外部环境，即6个轨迹的距离从246米到6.95公里。6. 全面评估了三种SLAM算法。总的来说，数据集约为17.6公里，85分钟，50GB，可以从以下链接获取：https://github.com/junzhang2016/NTU4DRadLM。
</details></li>
</ul>
<hr>
<h2 id="ASF-Net-Robust-Video-Deraining-via-Temporal-Alignment-and-Online-Adaptive-Learning"><a href="#ASF-Net-Robust-Video-Deraining-via-Temporal-Alignment-and-Online-Adaptive-Learning" class="headerlink" title="ASF-Net: Robust Video Deraining via Temporal Alignment and Online Adaptive Learning"></a>ASF-Net: Robust Video Deraining via Temporal Alignment and Online Adaptive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00956">http://arxiv.org/abs/2309.00956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinwei Xue, Jia He, Long Ma, Xiangyu Meng, Wenlin Li, Risheng Liu</li>
<li>for: 本研究旨在解决视频雨几何学习方法中的两个关键挑战：利用邻帧的时间相关性和适应未知实际场景。</li>
<li>methods: 我们提出了一种新的计算模式——归一化偏移网络（ASF-Net），它包括一个时间偏移模块，可以更深入探索邻帧的时间信息，并在特征空间内进行通道级别信息交换。</li>
<li>results: 我们在基于新建的 dataset 上进行了参数学习过程，并开发了一种创新的恢复学习策略，该策略可以将 sintetic 和实际场景之间的差异bridged，从而提高场景适应性。我们的提出方法在三个标准准点上表现出优于常见方法，并在实际场景中具有惊喜的视觉质量。<details>
<summary>Abstract</summary>
In recent times, learning-based methods for video deraining have demonstrated commendable results. However, there are two critical challenges that these methods are yet to address: exploiting temporal correlations among adjacent frames and ensuring adaptability to unknown real-world scenarios. To overcome these challenges, we explore video deraining from a paradigm design perspective to learning strategy construction. Specifically, we propose a new computational paradigm, Alignment-Shift-Fusion Network (ASF-Net), which incorporates a temporal shift module. This module is novel to this field and provides deeper exploration of temporal information by facilitating the exchange of channel-level information within the feature space. To fully discharge the model's characterization capability, we further construct a LArge-scale RAiny video dataset (LARA) which also supports the development of this community. On the basis of the newly-constructed dataset, we explore the parameters learning process by developing an innovative re-degraded learning strategy. This strategy bridges the gap between synthetic and real-world scenes, resulting in stronger scene adaptability. Our proposed approach exhibits superior performance in three benchmarks and compelling visual quality in real-world scenarios, underscoring its efficacy. The code is available at https://github.com/vis-opt-group/ASF-Net.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Tracking-without-Label-Unsupervised-Multiple-Object-Tracking-via-Contrastive-Similarity-Learning"><a href="#Tracking-without-Label-Unsupervised-Multiple-Object-Tracking-via-Contrastive-Similarity-Learning" class="headerlink" title="Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning"></a>Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00942">http://arxiv.org/abs/2309.00942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sha Meng, Dian Shao, Jiacheng Guo, Shan Gao</li>
<li>for: 这篇论文的目的是提出一种无监督学习方法，以增强多对象跟踪（MOT）任务中对象的识别和跟踪。</li>
<li>methods: 该方法利用样本特征的共同性，包括自我协同、跨帧协同和歧义协同三种冲突模块，从而提取特征表示。</li>
<li>results: 该方法在现有的标准测试集上比既有的无监督方法和部分监督方法提供更高的准确率，并且与完全监督方法相当或甚至超过。<details>
<summary>Abstract</summary>
Unsupervised learning is a challenging task due to the lack of labels. Multiple Object Tracking (MOT), which inevitably suffers from mutual object interference, occlusion, etc., is even more difficult without label supervision. In this paper, we explore the latent consistency of sample features across video frames and propose an Unsupervised Contrastive Similarity Learning method, named UCSL, including three contrast modules: self-contrast, cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses intra-frame direct and inter-frame indirect contrast to obtain discriminative representations by maximizing self-similarity. ii) Cross-contrast aligns cross- and continuous-frame matching results, mitigating the persistent negative effect caused by object occlusion. And iii) ambiguity contrast matches ambiguous objects with each other to further increase the certainty of subsequent object association through an implicit manner. On existing benchmarks, our method outperforms the existing unsupervised methods using only limited help from ReID head, and even provides higher accuracy than lots of fully supervised methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Unsupervised learning is a challenging task due to the lack of labels. Multiple Object Tracking (MOT), which inevitably suffers from mutual object interference, occlusion, etc., is even more difficult without label supervision. In this paper, we explore the latent consistency of sample features across video frames and propose an Unsupervised Contrastive Similarity Learning method, named UCSL, including three contrast modules: self-contrast, cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses intra-frame direct and inter-frame indirect contrast to obtain discriminative representations by maximizing self-similarity. ii) Cross-contrast aligns cross- and continuous-frame matching results, mitigating the persistent negative effect caused by object occlusion. And iii) ambiguity contrast matches ambiguous objects with each other to further increase the certainty of subsequent object association through an implicit manner. On existing benchmarks, our method outperforms the existing unsupervised methods using only limited help from ReID head, and even provides higher accuracy than lots of fully supervised methods."into Simplified Chinese.以下是文章中的简化中文翻译：Unsupervised learning是一项复杂的任务，因为缺乏标签。多个对象跟踪（MOT），它无法避免互相干扰、遮挡等问题，更加困难无标签指导。在这篇文章中，我们探索视频帧中样本特征的潜在一致性，并提出了无监督相似性学习方法（UCSL），包括三种对比模块：自我对比、相互对比和抽象对比。特别是：i) 自我对比使用内帧直接和间帧间接对比，以获得特征表示，充分发挥自我相似性。ii) 相互对比将相互匹配和连续帧匹配结果对齐，解决对象遮挡的持续性负面影响。iii) 抽象对比将抽象对象相互对应，进一步增加后续对象关联的确定性。在现有的benchmark上，我们的方法比现有的无监督方法使用更少的ReID头的帮助，甚至提供了高于许多全监督方法的准确率。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Robustness-of-Human-Parsers-Towards-Common-Corruptions"><a href="#Exploring-the-Robustness-of-Human-Parsers-Towards-Common-Corruptions" class="headerlink" title="Exploring the Robustness of Human Parsers Towards Common Corruptions"></a>Exploring the Robustness of Human Parsers Towards Common Corruptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00938">http://arxiv.org/abs/2309.00938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanyi Zhang, Xiaochun Cao, Rui Wang, Guo-Jun Qi, Jie Zhou</li>
<li>for: 提高人像分割模型的 robustness，使其能够更好地处理各种图像损害。</li>
<li>methods: 构建了三个损害robustness benchmark，并提出了一种基于多视图增强的异质增强机制，通过将两种不同视图的数据增强综合在一起，以适应常见的图像损害。</li>
<li>results: 实验结果表明，提出的方法可以提高人像分割模型的robustness，并且可以在不同的图像损害情况下保持相对的表现。<details>
<summary>Abstract</summary>
Human parsing aims to segment each pixel of the human image with fine-grained semantic categories. However, current human parsers trained with clean data are easily confused by numerous image corruptions such as blur and noise. To improve the robustness of human parsers, in this paper, we construct three corruption robustness benchmarks, termed LIP-C, ATR-C, and Pascal-Person-Part-C, to assist us in evaluating the risk tolerance of human parsing models. Inspired by the data augmentation strategy, we propose a novel heterogeneous augmentation-enhanced mechanism to bolster robustness under commonly corrupted conditions. Specifically, two types of data augmentations from different views, i.e., image-aware augmentation and model-aware image-to-image transformation, are integrated in a sequential manner for adapting to unforeseen image corruptions. The image-aware augmentation can enrich the high diversity of training images with the help of common image operations. The model-aware augmentation strategy that improves the diversity of input data by considering the model's randomness. The proposed method is model-agnostic, and it can plug and play into arbitrary state-of-the-art human parsing frameworks. The experimental results show that the proposed method demonstrates good universality which can improve the robustness of the human parsing models and even the semantic segmentation models when facing various image common corruptions. Meanwhile, it can still obtain approximate performance on clean data.
</details>
<details>
<summary>摘要</summary>
人类分割目标是将每个人像像Pixel segmentation with fine-grained semantic categories. However, current human parsers trained with clean data are easily confused by numerous image corruptions such as blur and noise. To improve the robustness of human parsers, in this paper, we construct three corruption robustness benchmarks, termed LIP-C, ATR-C, and Pascal-Person-Part-C, to assist us in evaluating the risk tolerance of human parsing models. Inspired by the data augmentation strategy, we propose a novel heterogeneous augmentation-enhanced mechanism to bolster robustness under commonly corrupted conditions. Specifically, two types of data augmentations from different views, i.e., image-aware augmentation and model-aware image-to-image transformation, are integrated in a sequential manner for adapting to unforeseen image corruptions. The image-aware augmentation can enrich the high diversity of training images with the help of common image operations. The model-aware augmentation strategy that improves the diversity of input data by considering the model's randomness. The proposed method is model-agnostic, and it can plug and play into arbitrary state-of-the-art human parsing frameworks. The experimental results show that the proposed method demonstrates good universality which can improve the robustness of the human parsing models and even the semantic segmentation models when facing various image common corruptions. Meanwhile, it can still obtain approximate performance on clean data.
</details></li>
</ul>
<hr>
<h2 id="Two-in-One-Depth-Bridging-the-Gap-Between-Monocular-and-Binocular-Self-supervised-Depth-Estimation"><a href="#Two-in-One-Depth-Bridging-the-Gap-Between-Monocular-and-Binocular-Self-supervised-Depth-Estimation" class="headerlink" title="Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation"></a>Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00933">http://arxiv.org/abs/2309.00933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengming Zhou, Qiulei Dong</li>
<li>for: 提出了一种能够同时处理单目和双目深度估计任务的 Two-in-One自主学习深度估计网络（TiO-Depth），以提高估计精度。</li>
<li>methods: 使用了一种SIAMESE架构，每个子网络可以作为单目深度估计模型，而为双目深度估计，提出了一种单目特征匹配模块，将两个图像之间的stereo知识integrated进模型中。</li>
<li>results: 实验结果表明，TiO-Depth在KITTI、Cityscapes和DDAD datasets上大多数情况下都能够超过单目和双目现有方法的性能，并证明了一种两个任务合一的网络可以为单目和双目深度估计提供更高的精度。<details>
<summary>Abstract</summary>
Monocular and binocular self-supervised depth estimations are two important and related tasks in computer vision, which aim to predict scene depths from single images and stereo image pairs respectively. In literature, the two tasks are usually tackled separately by two different kinds of models, and binocular models generally fail to predict depth from single images, while the prediction accuracy of monocular models is generally inferior to binocular models. In this paper, we propose a Two-in-One self-supervised depth estimation network, called TiO-Depth, which could not only compatibly handle the two tasks, but also improve the prediction accuracy. TiO-Depth employs a Siamese architecture and each sub-network of it could be used as a monocular depth estimation model. For binocular depth estimation, a Monocular Feature Matching module is proposed for incorporating the stereo knowledge between the two images, and the full TiO-Depth is used to predict depths. We also design a multi-stage joint-training strategy for improving the performances of TiO-Depth in both two tasks by combining the relative advantages of them. Experimental results on the KITTI, Cityscapes, and DDAD datasets demonstrate that TiO-Depth outperforms both the monocular and binocular state-of-the-art methods in most cases, and further verify the feasibility of a two-in-one network for monocular and binocular depth estimation. The code is available at https://github.com/ZM-Zhou/TiO-Depth_pytorch.
</details>
<details>
<summary>摘要</summary>
眼镜和双眼自助深度估计是计算机视觉中两个重要和相关的任务，它们目标是从单个图像和双图像对中预测场景的深度。在文献中，这两个任务通常由两种不同的模型来解决，而双眼模型通常无法从单个图像中预测深度，而眼镜模型的预测精度通常落后于双眼模型。在这篇论文中，我们提出了一个名为 TiO-Depth 的 Two-in-One 自助深度估计网络，可以同时处理这两个任务，并提高预测精度。TiO-Depth 使用了同构网络，并且每个子网络可以作为眼镜深度估计模型使用。对于双眼深度估计，我们提出了一个名为 Monocular Feature Matching 的单眼特征匹配模块，以利用双图像之间的相似性，并使用全 TiO-Depth 来预测深度。我们还设计了一种多阶段联合培训策略，以提高 TiO-Depth 在这两个任务中的性能。实验结果表明，TiO-Depth 在 KITTI、Cityscapes 和 DDAD 数据集上的表现都较为出色，大多数情况下超过了眼镜和双眼状态的目标方法，并证明了 Two-in-One 网络的可行性。代码可以在 GitHub 上找到：https://github.com/ZM-Zhou/TiO-Depth_pytorch。
</details></li>
</ul>
<hr>
<h2 id="S-3-MonoDETR-Supervised-Shape-Scale-perceptive-Deformable-Transformer-for-Monocular-3D-Object-Detection"><a href="#S-3-MonoDETR-Supervised-Shape-Scale-perceptive-Deformable-Transformer-for-Monocular-3D-Object-Detection" class="headerlink" title="S$^3$-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for Monocular 3D Object Detection"></a>S$^3$-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for Monocular 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00928">http://arxiv.org/abs/2309.00928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan He, Kailun Yang, Junwei Zheng, Jin Yuan, Luis M. Bergasa, Hui Zhang, Zhiyong Li</li>
<li>for: 提高单目3D物体检测的准确率，特别是对多类目物体的检测。</li>
<li>methods: 提出了一种新的“超级visedShape&amp;Scale-perceptive Deformable Attention”（S$^3$-DA）模块，利用视觉和深度特征生成多种形态和比例的多样化本地特征，并同时预测匹配分布，以强制每个查询点拥有有价值的形态&amp;比例识别。</li>
<li>results: 对KITTI和Waymo开放 dataset进行了广泛的实验，显示S$^3$-DA可以显著提高检测精度，在单一训练过程中实现单类和多类3D物体检测的州际最佳性能。<details>
<summary>Abstract</summary>
Recently, transformer-based methods have shown exceptional performance in monocular 3D object detection, which can predict 3D attributes from a single 2D image. These methods typically use visual and depth representations to generate query points on objects, whose quality plays a decisive role in the detection accuracy. However, current unsupervised attention mechanisms without any geometry appearance awareness in transformers are susceptible to producing noisy features for query points, which severely limits the network performance and also makes the model have a poor ability to detect multi-category objects in a single training process. To tackle this problem, this paper proposes a novel "Supervised Shape&Scale-perceptive Deformable Attention" (S$^3$-DA) module for monocular 3D object detection. Concretely, S$^3$-DA utilizes visual and depth features to generate diverse local features with various shapes and scales and predict the corresponding matching distribution simultaneously to impose valuable shape&scale perception for each query. Benefiting from this, S$^3$-DA effectively estimates receptive fields for query points belonging to any category, enabling them to generate robust query features. Besides, we propose a Multi-classification-based Shape$\&$Scale Matching (MSM) loss to supervise the above process. Extensive experiments on KITTI and Waymo Open datasets demonstrate that S$^3$-DA significantly improves the detection accuracy, yielding state-of-the-art performance of single-category and multi-category 3D object detection in a single training process compared to the existing approaches. The source code will be made publicly available at https://github.com/mikasa3lili/S3-MonoDETR.
</details>
<details>
<summary>摘要</summary>
最近，基于transformer的方法在单视图3D物体检测中表现出色，可以从单个2D图像中预测3D特征。这些方法通常使用视觉和深度表示来生成查询点对象， whose quality具有决定性的影响于检测精度。然而，当前无supervised attention机制，无法考虑对象的几何外观，这会使transformer中的网络性能受到严重的限制，同时也使得模型无法在单一训练过程中检测多类对象。为解决这个问题，本文提出了一种novel的“Supervised Shape&Scale-perceptive Deformable Attention”（S$^3$-DA）模块。具体来说，S$^3$-DA利用视觉和深度特征来生成多样的本地特征，同时预测匹配分布，以便为每个查询点强制实施有价值的形状&比例见解。这使得S$^3$-DA可以efficiently估计查询点所属类别的接受领域，从而生成Robust查询特征。此外，我们提出了一种Multi-classification-based Shape$\&$Scale Matching（MSM）损失函数来监督上述过程。广泛的实验表明，S$^3$-DA可以显著提高检测精度，在单个训练过程中实现单类和多类3D物体检测的state-of-the-art性能。网站将在https://github.com/mikasa3lili/S3-MonoDETR中公开源代码。
</details></li>
</ul>
<hr>
<h2 id="GBE-MLZSL-A-Group-Bi-Enhancement-Framework-for-Multi-Label-Zero-Shot-Learning"><a href="#GBE-MLZSL-A-Group-Bi-Enhancement-Framework-for-Multi-Label-Zero-Shot-Learning" class="headerlink" title="GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning"></a>GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00923">http://arxiv.org/abs/2309.00923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziming Liu, Jingcai Guo, Xiaocheng Lu, Song Guo, Peiran Dong, Jiewei Zhang</li>
<li>for: 这个论文 investigate了零shot学习在多标签场景（MLZSL）中的挑战问题，即在一个样本（如图像）中识别多个未经训练的类，基于已经训练的类和 auxillary knowledge，如semantic information。</li>
<li>methods: 该论文提出了一种新的并有效的集群强化框架（GBE-MLZSL），以全面利用图像的本地和全局特征，并提高预测精度和稳定性。特别是，该框架将特征地图分成多个特征组，每个特征组可以独立地在Local Information Distinguishing Module（LID）中进行训练，以保证唯一性。同时，Global Enhancement Module（GEM）是设计来保持图像的主要方向。此外，还设计了一个静止图 Structured 构建本地特征之间的相关性。</li>
<li>results: 实验表明，提出的GBE-MLZSL方法在大规模的MLZSL benchmark数据集NUS-WIDE和Open-Images-v4上，与其他当前state-of-the-art方法之间的margin比较大。<details>
<summary>Abstract</summary>
This paper investigates a challenging problem of zero-shot learning in the multi-label scenario (MLZSL), wherein, the model is trained to recognize multiple unseen classes within a sample (e.g., an image) based on seen classes and auxiliary knowledge, e.g., semantic information. Existing methods usually resort to analyzing the relationship of various seen classes residing in a sample from the dimension of spatial or semantic characteristics, and transfer the learned model to unseen ones. But they ignore the effective integration of local and global features. That is, in the process of inferring unseen classes, global features represent the principal direction of the image in the feature space, while local features should maintain uniqueness within a certain range. This integrated neglect will make the model lose its grasp of the main components of the image. Relying only on the local existence of seen classes during the inference stage introduces unavoidable bias. In this paper, we propose a novel and effective group bi-enhancement framework for MLZSL, dubbed GBE-MLZSL, to fully make use of such properties and enable a more accurate and robust visual-semantic projection. Specifically, we split the feature maps into several feature groups, of which each feature group can be trained independently with the Local Information Distinguishing Module (LID) to ensure uniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to preserve the principal direction. Besides, a static graph structure is designed to construct the correlation of local features. Experiments on large-scale MLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the proposed GBE-MLZSL outperforms other state-of-the-art methods with large margins.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a novel and effective group bi-enhancement framework for MLZSL, called GBE-MLZSL, to fully utilize such properties and enable more accurate and robust visual-semantic projections. Specifically, we split the feature maps into several feature groups, each of which can be trained independently with the Local Information Distinguishing Module (LID) to ensure uniqueness. Additionally, a Global Enhancement Module (GEM) is designed to preserve the principal direction. Furthermore, a static graph structure is designed to construct the correlation of local features. Experiments on large-scale MLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the proposed GBE-MLZSL outperforms other state-of-the-art methods with large margins.Translated into Simplified Chinese, the text would be:这篇论文研究了多类零例学习（MLZSL）问题，即在一个样本（例如一张图像）中识别多个未经见过的类，基于已经见过的类和auxiliary知识，如semantic信息。现有的方法通常是分析样本中不同类的关系，从空间或semantic特征的角度来转移已经学习的模型到未经见过的类。但它们忽略了Integrate Local and Global Features的效果。即在推断未经见过的类时，global feature在特征空间中表示样本的主要方向，而local feature在某些范围内保持uniqueness。这种总体忽略会使模型失去样本的主要组成部分。只靠基于seen类的local存在来进行推断会引入不可避免的偏见。在这篇论文中，我们提出了一种新的和有效的集群强化框架，名为GBE-MLZSL，以便充分利用这些特性并实现更加准确和可靠的视semantic投影。具体来说，我们将特征图分成多个特征组，每个特征组可以独立地通过Local Information Distinguishing Module（LID）来确保uniqueness。同时，我们设计了Global Enhancement Module（GEM）来保持主要方向。此外，我们还设计了一个静态图Structured Graph来建立本地特征之间的相关性。实验结果表明，提出的GBE-MLZSL在大规模MLZSL benchmark数据集NUS-WIDE和Open-Images-v4上舜拓了其他状态的方法。
</details></li>
</ul>
<hr>
<h2 id="A-novel-framework-employing-deep-multi-attention-channels-network-for-the-autonomous-detection-of-metastasizing-cells-through-fluorescence-microscopy"><a href="#A-novel-framework-employing-deep-multi-attention-channels-network-for-the-autonomous-detection-of-metastasizing-cells-through-fluorescence-microscopy" class="headerlink" title="A novel framework employing deep multi-attention channels network for the autonomous detection of metastasizing cells through fluorescence microscopy"></a>A novel framework employing deep multi-attention channels network for the autonomous detection of metastasizing cells through fluorescence microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00911">http://arxiv.org/abs/2309.00911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michail Mamalakis, Sarah C. Macfarlane, Scott V. Notley, Annica K. B Gad, George Panoutsos</li>
<li>for: distinguishing between normal and metastasizing human cells</li>
<li>methods: combines multi-attention channels network and global explainable techniques using fluorescence microscopy images of actin and vimentin filaments</li>
<li>results: unprecedented understanding of cytoskeletal changes accompanying oncogenic transformation, and potential spatial biomarker for diagnostic tools against metastasis (spatial distribution of vimentin)Here is the same information in Simplified Chinese text:</li>
<li>for: 分辨normal和转移性人类细胞</li>
<li>methods: 结合多通道注意力网络和全球可解释技术，使用 fluorescence microscopy 图像显示 actin 和 vimentin 纤维蛋白的空间组织</li>
<li>results: 未曾有的细胞变化理解，并可能提供将来的诊断工具 против转移细胞 (细胞分布的 vimentin)<details>
<summary>Abstract</summary>
We developed a transparent computational large-scale imaging-based framework that can distinguish between normal and metastasizing human cells. The method relies on fluorescence microscopy images showing the spatial organization of actin and vimentin filaments in normal and metastasizing single cells, using a combination of multi-attention channels network and global explainable techniques. We test a classification between normal cells (Bj primary fibroblast), and their isogenically matched, transformed and invasive counterpart (BjTertSV40TRasV12). Manual annotation is not trivial to automate due to the intricacy of the biologically relevant features. In this research, we utilized established deep learning networks and our new multi-attention channel architecture. To increase the interpretability of the network - crucial for this application area - we developed an interpretable global explainable approach correlating the weighted geometric mean of the total cell images and their local GradCam scores. The significant results from our analysis unprecedently allowed a more detailed, and biologically relevant understanding of the cytoskeletal changes that accompany oncogenic transformation of normal to invasive and metastasizing cells. We also paved the way for a possible spatial micrometre-level biomarker for future development of diagnostic tools against metastasis (spatial distribution of vimentin).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MagicProp-Diffusion-based-Video-Editing-via-Motion-aware-Appearance-Propagation"><a href="#MagicProp-Diffusion-based-Video-Editing-via-Motion-aware-Appearance-Propagation" class="headerlink" title="MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation"></a>MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00908">http://arxiv.org/abs/2309.00908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanshu Yan, Jun Hao Liew, Long Mai, Shanchuan Lin, Jiashi Feng</li>
<li>for: 修改视频的视觉外观 while preserving its motion.</li>
<li>methods: 提议一种新的框架 MagicProp，包括两个阶段：外观编辑和动作感知外观升级。在第一个阶段，MagicProp 选择输入视频中一帧，并应用图像修饰技术来修改内容和&#x2F;或风格。在第二个阶段，MagicProp 使用编辑后的帧作为外观参考，并使用一种泛化生成模型来生成剩下的帧。</li>
<li>results:  MagicProp 结合了图像修饰技术的灵活性和泛化生成模型的高效性，可以在输入视频中任意地区进行对象类型和艺术风格的修改，同时保持视频帧之间的 temporal consistency。广泛的实验表明 MagicProp 有效。<details>
<summary>Abstract</summary>
This paper addresses the issue of modifying the visual appearance of videos while preserving their motion. A novel framework, named MagicProp, is proposed, which disentangles the video editing process into two stages: appearance editing and motion-aware appearance propagation. In the first stage, MagicProp selects a single frame from the input video and applies image-editing techniques to modify the content and/or style of the frame. The flexibility of these techniques enables the editing of arbitrary regions within the frame. In the second stage, MagicProp employs the edited frame as an appearance reference and generates the remaining frames using an autoregressive rendering approach. To achieve this, a diffusion-based conditional generation model, called PropDPM, is developed, which synthesizes the target frame by conditioning on the reference appearance, the target motion, and its previous appearance. The autoregressive editing approach ensures temporal consistency in the resulting videos. Overall, MagicProp combines the flexibility of image-editing techniques with the superior temporal consistency of autoregressive modeling, enabling flexible editing of object types and aesthetic styles in arbitrary regions of input videos while maintaining good temporal consistency across frames. Extensive experiments in various video editing scenarios demonstrate the effectiveness of MagicProp.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Generic-Fundus-Image-Enhancement-Network-Boosted-by-Frequency-Self-supervised-Representation-Learning"><a href="#A-Generic-Fundus-Image-Enhancement-Network-Boosted-by-Frequency-Self-supervised-Representation-Learning" class="headerlink" title="A Generic Fundus Image Enhancement Network Boosted by Frequency Self-supervised Representation Learning"></a>A Generic Fundus Image Enhancement Network Boosted by Frequency Self-supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00885">http://arxiv.org/abs/2309.00885</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liamheng/Annotation-free-Fundus-Image-Enhancement">https://github.com/liamheng/Annotation-free-Fundus-Image-Enhancement</a></li>
<li>paper_authors: Heng Li, Haofeng Liu, Huazhu Fu, Yanwu Xu, Hui Shu, Ke Niu, Yan Hu, Jiang Liu</li>
<li>for: 本研究旨在开发一种能够Robustly Correct unknown fundus images的基本图像增强网络（GFE-Net），以便在低质量图像下进行诊断和智能系统的临床应用。</li>
<li>methods: 该研究使用了自我监督学习来学习不supervised的图像信息，并将图像增强和表征学习融合在一起，以实现高质量图像增强和结构保持。</li>
<li>results: 对比state-of-the-art算法，GFE-Net在数据依赖度、增强性能、部署效率和扩展可用性等方面表现出优异，并且可以方便进行后续的基本图像分析。<details>
<summary>Abstract</summary>
Fundus photography is prone to suffer from image quality degradation that impacts clinical examination performed by ophthalmologists or intelligent systems. Though enhancement algorithms have been developed to promote fundus observation on degraded images, high data demands and limited applicability hinder their clinical deployment. To circumvent this bottleneck, a generic fundus image enhancement network (GFE-Net) is developed in this study to robustly correct unknown fundus images without supervised or extra data. Levering image frequency information, self-supervised representation learning is conducted to learn robust structure-aware representations from degraded images. Then with a seamless architecture that couples representation learning and image enhancement, GFE-Net can accurately correct fundus images and meanwhile preserve retinal structures. Comprehensive experiments are implemented to demonstrate the effectiveness and advantages of GFE-Net. Compared with state-of-the-art algorithms, GFE-Net achieves superior performance in data dependency, enhancement performance, deployment efficiency, and scale generalizability. Follow-up fundus image analysis is also facilitated by GFE-Net, whose modules are respectively verified to be effective for image enhancement.
</details>
<details>
<summary>摘要</summary>
血液照片容易受到影像质量下降的影响，这会对眼科医生或智能系统进行临床诊断带来困难。虽然有增强算法可以提高血液图像质量，但这些算法具有高数据需求和局限性，使其在临床应用中受到限制。为了绕过这个瓶颈，本研究提出了一种通用血液图像增强网络（GFE-Net），可以不需要指导或额外数据，强制约束血液图像中的结构。GFE-Net 利用图像频率信息，自我指导学习来学习血液图像中的结构，然后通过将 representation learning 和图像增强结合在一起，GFE-Net 可以准确地 corrections 血液图像，同时保持血液结构。我们进行了全面的实验，以证明 GFE-Net 的有效性和优势。相比之前的算法，GFE-Net 在数据依赖、增强性、部署效率和扩展可行性等方面具有显著优势。此外，GFE-Net 的模块也在不同的应用中进行了验证，其中每个模块都能够准确地进行图像增强。
</details></li>
</ul>
<hr>
<h2 id="Fearless-Luminance-Adaptation-A-Macro-Micro-Hierarchical-Transformer-for-Exposure-Correction"><a href="#Fearless-Luminance-Adaptation-A-Macro-Micro-Hierarchical-Transformer-for-Exposure-Correction" class="headerlink" title="Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer for Exposure Correction"></a>Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer for Exposure Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00872">http://arxiv.org/abs/2309.00872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gehui Li, Jinyuan Liu, Long Ma, Zhiying Jiang, Xin Fan, Risheng Liu</li>
<li>for: 本文旨在提高图像曝光误差的correltion，以提高图像质量。</li>
<li>methods: 本文提出了一种Macro-Micro-Hierarchical transformer，包括macro注意力、micro注意力和层次结构，以实现均衡global和local特征的捕捉。</li>
<li>results: 实验表明，本方法可以提供更加吸引人的图像修复结果，并且在low-light face recognition和low-light semantic segmentation中表现出色。<details>
<summary>Abstract</summary>
Photographs taken with less-than-ideal exposure settings often display poor visual quality. Since the correction procedures vary significantly, it is difficult for a single neural network to handle all exposure problems. Moreover, the inherent limitations of convolutions, hinder the models ability to restore faithful color or details on extremely over-/under- exposed regions. To overcome these limitations, we propose a Macro-Micro-Hierarchical transformer, which consists of a macro attention to capture long-range dependencies, a micro attention to extract local features, and a hierarchical structure for coarse-to-fine correction. In specific, the complementary macro-micro attention designs enhance locality while allowing global interactions. The hierarchical structure enables the network to correct exposure errors of different scales layer by layer. Furthermore, we propose a contrast constraint and couple it seamlessly in the loss function, where the corrected image is pulled towards the positive sample and pushed away from the dynamically generated negative samples. Thus the remaining color distortion and loss of detail can be removed. We also extend our method as an image enhancer for low-light face recognition and low-light semantic segmentation. Experiments demonstrate that our approach obtains more attractive results than state-of-the-art methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
照片拍摄时使用不理想的曝光设置通常会导致视觉质量差。由于修正方法之间差异很大，因此单一神经网络难以处理所有曝光问题。另外，卷积的内在限制，阻碍模型恢复 faithful 的颜色或细节在极度过曝光或 Underexposed 区域。为了缓解这些限制，我们提议了一种宏微层次 transformer，它包括一个宏注意力来捕捉长距离依赖关系，一个微注意力来提取本地特征，以及一个层次结构来进行粗细修正。具体来说，宏微注意力的补做设计可以提高地方性，同时允许全局交互。层次结构使得网络可以层次修正不同的曝光错误。此外，我们还提出了一种对比约束，并将其灵活地添加到损失函数中，使 corrected 图像被pull towards 正样本，并被push away  FROM 动态生成的负样本。因此，剩下的颜色扭曲和细节损失可以被去除。我们还扩展了我们的方法，用于低光照人脸识别和低光照 semantic segmentation。实验表明，我们的方法可以比 estado-of-the-art 方法更加吸引人地得到结果， both quantitatively and qualitatively。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Weakly-Supervised-Image-Segmentation-via-Representation-Transform-and-Compensator"><a href="#Boosting-Weakly-Supervised-Image-Segmentation-via-Representation-Transform-and-Compensator" class="headerlink" title="Boosting Weakly-Supervised Image Segmentation via Representation, Transform, and Compensator"></a>Boosting Weakly-Supervised Image Segmentation via Representation, Transform, and Compensator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00871">http://arxiv.org/abs/2309.00871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyan Wang, Dong Zhang, Rui Yan</li>
<li>for: 本研究旨在提出一种单 Stage weakly-supervised image segmentation (WSIS) 方法，以提高 pseudo-mask 质量，从而实现更高的 segmentation 精度。</li>
<li>methods: 我们提出了一种使用 siamese network 和对比学习的方法，通过改进类活图 (CAM) 的质量，实现自我反复过程。我们还引入了交叉表示反复 module，以学习 robust 类型抽象和捕捉全局上下文信息，以便反复 CAMs。</li>
<li>results: 我们在 PASCAL VOC 2012 数据集上进行了实验，并证明了我们的方法可以准确地 segment 图像。我们在 PASCAL VOC 2012 验证集上达到了 67.2% 和 68.76% mIoU，在测试集上达到了 68.76% mIoU。此外，我们还扩展了我们的方法到弱地监督对象定位任务，并实验表明我们的方法在这个任务中仍然能够获得非常竞争力的结果。<details>
<summary>Abstract</summary>
Weakly-supervised image segmentation (WSIS) is a critical task in computer vision that relies on image-level class labels. Multi-stage training procedures have been widely used in existing WSIS approaches to obtain high-quality pseudo-masks as ground-truth, resulting in significant progress. However, single-stage WSIS methods have recently gained attention due to their potential for simplifying training procedures, despite often suffering from low-quality pseudo-masks that limit their practical applications. To address this issue, we propose a novel single-stage WSIS method that utilizes a siamese network with contrastive learning to improve the quality of class activation maps (CAMs) and achieve a self-refinement process. Our approach employs a cross-representation refinement method that expands reliable object regions by utilizing different feature representations from the backbone. Additionally, we introduce a cross-transform regularization module that learns robust class prototypes for contrastive learning and captures global context information to feed back rough CAMs, thereby improving the quality of CAMs. Our final high-quality CAMs are used as pseudo-masks to supervise the segmentation result. Experimental results on the PASCAL VOC 2012 dataset demonstrate that our method significantly outperforms other state-of-the-art methods, achieving 67.2% and 68.76% mIoU on PASCAL VOC 2012 val set and test set, respectively. Furthermore, our method has been extended to weakly supervised object localization task, and experimental results demonstrate that our method continues to achieve very competitive results.
</details>
<details>
<summary>摘要</summary>
弱样指导图像分割（WSIS）是计算机视觉中的关键任务，它基于图像级别的类标签。现有的WSIS方法多使用多个阶段训练过程来获得高质量的假标签，从而取得了显著的进步。然而，单阶段WSIS方法在最近受到了关注，因为它们可能简化训练过程，尽管经常受到低质量假标签的限制，使其在实际应用中具有局限性。为解决这个问题，我们提出了一种新的单阶段WSIS方法，该方法使用对称网络和对比学习来提高类激活图（CAM）的质量，并实现自我调整过程。我们的方法使用跨表示反复增强方法，将不同的特征表示从后向扩展可靠的物体区域，并 introduce a cross-transform regularization module，该模块学习强健的类范例，以便对比学习，并捕捉全局信息，以帮助改善CAM的质量。最终，我们的高质量CAM被用作假标签，以便监督分割结果。实验结果表明，我们的方法在PASCAL VOC 2012数据集上与其他状态对照方法相比，显著超越了它们，达到了67.2%和68.76%的mIoU在PASCAL VOC 2012验证集和测试集上，分别。此外，我们的方法还被扩展到弱有指导物体定位任务，实验结果表明，我们的方法在这个任务上仍然实现了非常竞争力的结果。
</details></li>
</ul>
<hr>
<h2 id="Big-model-Driven-Few-shot-Continual-Learning"><a href="#Big-model-Driven-Few-shot-Continual-Learning" class="headerlink" title="Big-model Driven Few-shot Continual Learning"></a>Big-model Driven Few-shot Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00862">http://arxiv.org/abs/2309.00862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Gu, Chunyan Xu, Zihan Lu, Xin Liu, Anbo Dai, Zhen Cui</li>
<li>for: 提高 few-shot continual learning (FSCL) 的精度和稳定性。</li>
<li>methods: 使用 big-model 驱动的转移学习，采用 adaptive decision 机制，并实施 adaptive distillation 来提高模型的性能。</li>
<li>results: 在三个popular dataset上（包括 CIFAR100、minilmageNet 和 CUB200），提出的 B-FSCL 方法完全超越了所有现有的 FSCL 方法。<details>
<summary>Abstract</summary>
Few-shot continual learning (FSCL) has attracted intensive attention and achieved some advances in recent years, but now it is difficult to again make a big stride in accuracy due to the limitation of only few-shot incremental samples. Inspired by distinctive human cognition ability in life learning, in this work, we propose a novel Big-model driven Few-shot Continual Learning (B-FSCL) framework to gradually evolve the model under the traction of the world's big-models (like human accumulative knowledge). Specifically, we perform the big-model driven transfer learning to leverage the powerful encoding capability of these existing big-models, which can adapt the continual model to a few of newly added samples while avoiding the over-fitting problem. Considering that the big-model and the continual model may have different perceived results for the identical images, we introduce an instance-level adaptive decision mechanism to provide the high-level flexibility cognitive support adjusted to varying samples. In turn, the adaptive decision can be further adopted to optimize the parameters of the continual model, performing the adaptive distillation of big-model's knowledge information. Experimental results of our proposed B-FSCL on three popular datasets (including CIFAR100, minilmageNet and CUB200) completely surpass all state-of-the-art FSCL methods.
</details>
<details>
<summary>摘要</summary>
Recently, few-shot continual learning (FSCL) has received extensive attention and achieved some advances, but it has become difficult to make further significant improvements in accuracy due to the limited number of few-shot incremental samples. Inspired by human cognitive abilities in life learning, we propose a novel Big-model driven Few-shot Continual Learning (B-FSCL) framework to gradually evolve the model under the guidance of the world's big-models (like human accumulative knowledge). Specifically, we perform big-model driven transfer learning to leverage the powerful encoding capabilities of these existing big-models, which can adapt the continual model to a few newly added samples while avoiding the overfitting problem. Considering that the big-model and the continual model may have different perceptions of the same images, we introduce an instance-level adaptive decision mechanism to provide high-level flexibility cognitive support adjusted to varying samples. In turn, the adaptive decision can be further adopted to optimize the parameters of the continual model, performing adaptive distillation of big-model's knowledge information. Experimental results of our proposed B-FSCL on three popular datasets (including CIFAR100, minilmageNet, and CUB200) completely surpass all state-of-the-art FSCL methods.
</details></li>
</ul>
<hr>
<h2 id="Correlated-and-Multi-frequency-Diffusion-Modeling-for-Highly-Under-sampled-MRI-Reconstruction"><a href="#Correlated-and-Multi-frequency-Diffusion-Modeling-for-Highly-Under-sampled-MRI-Reconstruction" class="headerlink" title="Correlated and Multi-frequency Diffusion Modeling for Highly Under-sampled MRI Reconstruction"></a>Correlated and Multi-frequency Diffusion Modeling for Highly Under-sampled MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00853">http://arxiv.org/abs/2309.00853</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqx7150/cm-dm">https://github.com/yqx7150/cm-dm</a></li>
<li>paper_authors: Yu Guan, Chuanming Yu, Shiyu Lu, Zhuoxu Cui, Dong Liang, Qiegen Liu</li>
<li>for: 提高MRI重建精度和加速抽象过程</li>
<li>methods: 利用多频率优先和吸引过程对各种细胞膜进行精细Texture detail重建</li>
<li>results: 实验结果表明，提出的方法可以更高精度地重建MRI图像，并且可以加速抽象过程。<details>
<summary>Abstract</summary>
Most existing MRI reconstruction methods perform tar-geted reconstruction of the entire MR image without tak-ing specific tissue regions into consideration. This may fail to emphasize the reconstruction accuracy on im-portant tissues for diagnosis. In this study, leveraging a combination of the properties of k-space data and the diffusion process, our novel scheme focuses on mining the multi-frequency prior with different strategies to pre-serve fine texture details in the reconstructed image. In addition, a diffusion process can converge more quickly if its target distribution closely resembles the noise distri-bution in the process. This can be accomplished through various high-frequency prior extractors. The finding further solidifies the effectiveness of the score-based gen-erative model. On top of all the advantages, our method improves the accuracy of MRI reconstruction and accel-erates sampling process. Experimental results verify that the proposed method successfully obtains more accurate reconstruction and outperforms state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
大多数现有MRI重建方法都是对整个MRI图像进行targeted重建，不考虑特定组织区域的重建精度。这可能导致重建精度不够，特别是在诊断中需要准确的组织区域。在本研究中，我们提出了一种新的方法，利用k空间数据的性质和扩散过程，将多频率优先级与不同策略相结合，以保留重建图像中细节的细腻 texture。此外，扩散过程可以更快地 converges，如果target分布和噪声分布在过程中很相似。这可以通过多种高频率优先级抽取器来实现。这些发现进一步证明了Score-based生成模型的效iveness。此外，我们的方法还提高了MRI重建的精度和采样速度。实验结果证明，我们提出的方法可以更好地重建MRI图像，并且超过了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="A-Post-Processing-Based-Bengali-Document-Layout-Analysis-with-YOLOV8"><a href="#A-Post-Processing-Based-Bengali-Document-Layout-Analysis-with-YOLOV8" class="headerlink" title="A Post-Processing Based Bengali Document Layout Analysis with YOLOV8"></a>A Post-Processing Based Bengali Document Layout Analysis with YOLOV8</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00848">http://arxiv.org/abs/2309.00848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nazmus Sakib Ahmed, Saad Sakib Noor, Ashraful Islam Shanto Sikder, Abhijit Paul</li>
<li>for: 这 paper 的目的是提高孟加拉文档格式分析 (DLA)，使用 YOLOv8 模型和创新的后处理技术。</li>
<li>methods: 这 paper 使用数据增强来提高模型的鲁棒性，并使用两个阶段预测策略来实现准确的元素分 segmentation。</li>
<li>results: 这 paper 的结果表明， ensemble 模型和后处理技术可以超越基础模型，解决在 BaDLAD 数据集中存在的问题。<details>
<summary>Abstract</summary>
This paper focuses on enhancing Bengali Document Layout Analysis (DLA) using the YOLOv8 model and innovative post-processing techniques. We tackle challenges unique to the complex Bengali script by employing data augmentation for model robustness. After meticulous validation set evaluation, we fine-tune our approach on the complete dataset, leading to a two-stage prediction strategy for accurate element segmentation. Our ensemble model, combined with post-processing, outperforms individual base architectures, addressing issues identified in the BaDLAD dataset. By leveraging this approach, we aim to advance Bengali document analysis, contributing to improved OCR and document comprehension and BaDLAD serves as a foundational resource for this endeavor, aiding future research in the field. Furthermore, our experiments provided key insights to incorporate new strategies into the established solution.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文关注使用YOLOv8模型和创新的后处理技术进行增强孟加拉文档布局分析（DLA）。我们利用数据增强来提高模型的可靠性，并在完整的数据集上精心调整方法，实现了两stage预测策略以确定精确的元素分割。我们的集成模型，结合后处理，超越了基础模型，解决了在BaDLAD数据集中 Identified的问题。通过这种方法，我们希望推进孟加拉文档分析，提高OCR和文档理解。BaDLAD serves as a foundational resource for this endeavor, aiding future research in the field.此外，我们的实验提供了关键的思路，可以在已有的解决方案中添加新策略。
</details></li>
</ul>
<hr>
<h2 id="pSTarC-Pseudo-Source-Guided-Target-Clustering-for-Fully-Test-Time-Adaptation"><a href="#pSTarC-Pseudo-Source-Guided-Target-Clustering-for-Fully-Test-Time-Adaptation" class="headerlink" title="pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation"></a>pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00846">http://arxiv.org/abs/2309.00846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manogna Sreenivas, Goirik Chakrabarty, Soma Biswas</li>
<li>for: 本文旨在提出一种新的测试时适应（TTA）方法，以便在实际场景中，模型能够很好地表现。</li>
<li>methods: 本方法叫做 Pseudo Source guided Target Clustering（pSTarC），它是在实际领域变换下的TTA领域中相对未曾研究的。这种方法 Draws inspiration from target clustering techniques and exploits the source classifier for generating pseudo-source samples。</li>
<li>results: 实验表明，pSTarC可以减轻计算需求，同时提高预测精度。此外，我们还证明了pSTarC的普适性，并在连续TTA框架中表现出色。<details>
<summary>Abstract</summary>
Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling models to perform well in real-world scenarios, where test data distribution differs from training. In this work, we propose a novel approach called pseudo Source guided Target Clustering (pSTarC) addressing the relatively unexplored area of TTA under real-world domain shifts. This method draws inspiration from target clustering techniques and exploits the source classifier for generating pseudo-source samples. The test samples are strategically aligned with these pseudo-source samples, facilitating their clustering and thereby enhancing TTA performance. pSTarC operates solely within the fully test-time adaptation protocol, removing the need for actual source data. Experimental validation on a variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126, CIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant improvements in prediction accuracy along with efficient computational requirements. Furthermore, we also demonstrate the universality of the pSTarC framework by showing its effectiveness for the continuous TTA framework.
</details>
<details>
<summary>摘要</summary>
测试时适应（TTA）是机器学习中的一个重要概念，它允许模型在真实世界中表现良好，其测试数据分布与训练数据分布不同。在这种情况下，我们提出了一种新的方法called pseudo Source guided Target Clustering（pSTarC），用于解决真实世界域转移下的TTA。这种方法 Draws inspiration from 目标划分技术，利用源分类器来生成pseudo-source样本。测试样本被策略性地与这些pseudo-source样本相对应，从而提高了TTA性能。pSTarC在完全测试时适应协议下运行，不需要实际的源数据。在多个域转移数据集上，包括VisDA、Office-Home、DomainNet-126和CIFAR-100C，我们进行了实验 validate pSTarC的效果。这种方法在预测精度和计算需求方面具有显著改进。此外，我们还证明了pSTarC框架的通用性，其在连续TTA框架中也表现出了效果。
</details></li>
</ul>
<hr>
<h2 id="ObjectLab-Automated-Diagnosis-of-Mislabeled-Images-in-Object-Detection-Data"><a href="#ObjectLab-Automated-Diagnosis-of-Mislabeled-Images-in-Object-Detection-Data" class="headerlink" title="ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection Data"></a>ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00832">http://arxiv.org/abs/2309.00832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cleanlab/cleanlab">https://github.com/cleanlab/cleanlab</a></li>
<li>paper_authors: Ulyana Tkachenko, Aditya Thyagarajan, Jonas Mueller</li>
<li>for: 本研究旨在提高物体检测模型的训练数据质量，以提高模型的检测精度和稳定性。</li>
<li>methods: 本研究提出了一种名为ObjectLab的简单而直观的算法，用于检测物体检测标签中的多种错误，包括：漏掉 bounding box、位置错误和类别标签错误。ObjectLab 使用任何已经训练过物体检测模型来评估每个图像的标签质量，以便自动优先级检查和修正涉及到错误的图像。</li>
<li>results: 对于多个物体检测数据集（包括 COCO）和多种模型（包括 Detectron-X101 和 Faster-RCNN），ObjectLab 能够准确地检测标签错误，与其他标签质量分数相比，具有更高的准确率&#x2F;回归率。<details>
<summary>Abstract</summary>
Despite powering sensitive systems like autonomous vehicles, object detection remains fairly brittle in part due to annotation errors that plague most real-world training datasets. We propose ObjectLab, a straightforward algorithm to detect diverse errors in object detection labels, including: overlooked bounding boxes, badly located boxes, and incorrect class label assignments. ObjectLab utilizes any trained object detection model to score the label quality of each image, such that mislabeled images can be automatically prioritized for label review/correction. Properly handling erroneous data enables training a better version of the same object detection model, without any change in existing modeling code. Across different object detection datasets (including COCO) and different models (including Detectron-X101 and Faster-RCNN), ObjectLab consistently detects annotation errors with much better precision/recall compared to other label quality scores.
</details>
<details>
<summary>摘要</summary>
尽管它用于感知系统如自动驾驶汽车的识别系统，但对象检测仍然比较脆弱，其中一个主要原因是训练数据中的注释错误。我们提议ObjectLab，一种简单的算法，用于检测对象检测标签中的多种错误，包括：被忽略的 bounding box、 incorrect 的位置和类别标签分配错误。ObjectLab 使用任何已经训练过的对象检测模型来评估每个图像的标签质量，以便自动优先级化需要更正的标签。正确处理错误数据可以训练一个更好的同样的对象检测模型，无需更改现有的代码。在不同的对象检测 dataset （包括 COCO）和不同的模型（包括 Detectron-X101 和 Faster-RCNN）中，ObjectLab  invariably  detects 注释错误的精度/回归比例远高于其他标签质量分数。
</details></li>
</ul>
<hr>
<h2 id="Multi-scale-Data-driven-and-Anatomically-Constrained-Deep-Learning-Image-Registration-for-Adult-and-Fetal-Echocardiography"><a href="#Multi-scale-Data-driven-and-Anatomically-Constrained-Deep-Learning-Image-Registration-for-Adult-and-Fetal-Echocardiography" class="headerlink" title="Multi-scale, Data-driven and Anatomically Constrained Deep Learning Image Registration for Adult and Fetal Echocardiography"></a>Multi-scale, Data-driven and Anatomically Constrained Deep Learning Image Registration for Adult and Fetal Echocardiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00831">http://arxiv.org/abs/2309.00831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kamruleee51/ddc-ac-dlir">https://github.com/kamruleee51/ddc-ac-dlir</a></li>
<li>paper_authors: Md. Kamrul Hasan, Haobo Zhu, Guang Yang, Choon Hwai Yap</li>
<li>for: 这个研究的目的是提高电子医学图像匹配的精度和稳定性，以便在临床中更 accurately 评估心脏运动和肌体弹性。</li>
<li>methods: 这个研究使用了深度学习图像匹配（DLIR）技术，并提出了一种将形态编码损失、数据驱动损失和多 scales 训练方法相结合的框架。</li>
<li>results: 测试结果表明，这种方法可以提高图像匹配的精度和稳定性，并且可以在成人和胎儿电子医学图像中达到优秀的结果。<details>
<summary>Abstract</summary>
Temporal echocardiography image registration is a basis for clinical quantifications such as cardiac motion estimation, myocardial strain assessments, and stroke volume quantifications. In past studies, deep learning image registration (DLIR) has shown promising results and is consistently accurate and precise, requiring less computational time. We propose that a greater focus on the warped moving image's anatomic plausibility and image quality can support robust DLIR performance. Further, past implementations have focused on adult echocardiography, and there is an absence of DLIR implementations for fetal echocardiography. We propose a framework that combines three strategies for DLIR in both fetal and adult echo: (1) an anatomic shape-encoded loss to preserve physiological myocardial and left ventricular anatomical topologies in warped images; (2) a data-driven loss that is trained adversarially to preserve good image texture features in warped images; and (3) a multi-scale training scheme of a data-driven and anatomically constrained algorithm to improve accuracy. Our tests show that good anatomical topology and image textures are strongly linked to shape-encoded and data-driven adversarial losses. They improve different aspects of registration performance in a non-overlapping way, justifying their combination. Despite fundamental distinctions between adult and fetal echo images, we show that these strategies can provide excellent registration results in both adult and fetal echocardiography using the publicly available CAMUS adult echo dataset and our private multi-demographic fetal echo dataset. Our approach outperforms traditional non-DL gold standard registration approaches, including Optical Flow and Elastix. Registration improvements could be translated to more accurate and precise clinical quantification of cardiac ejection fraction, demonstrating a potential for translation.
</details>
<details>
<summary>摘要</summary>
医学影像协调是基础 для临床量化，如心脏运动评估、肌肉弹性评估和心脏血量评估。过去的研究表明，深度学习图像协调（DLIR）有扎实的结果和精度，需要较少的计算时间。我们提议更重视卷积动图像的 анатомиче可能性和图像质量，以支持Robust DLIR表现。此外，过去的实施都是成人echo，而 absence of DLIR实现 для胎儿echo。我们提议一种框架，该框架结合以下三种策略：（1）一种适应Physiological myocardial和左心脏的生物学特征的形状编码损失；（2）一种通过对图像特征进行反向学习来保持好的图像特征；（3）一种多尺度训练的数据驱动和生物学特征驱动的算法，以提高准确性。我们的测试表明，良好的生物学特征和图像特征是强相关的，这些损失可以不同方面提高协调性能。尽管成人echo和胎儿echo图像具有基本不同的特征，我们的策略可以在两者上提供出色的协调结果。我们的方法超过了传统的非深度学习标准注册方法，包括折射流和Elastix。更好的协调可能可以翻译到更准确和精度的临床量化，表明了我们的方法的潜在应用。
</details></li>
</ul>
<hr>
<h2 id="When-3D-Bounding-Box-Meets-SAM-Point-Cloud-Instance-Segmentation-with-Weak-and-Noisy-Supervision"><a href="#When-3D-Bounding-Box-Meets-SAM-Point-Cloud-Instance-Segmentation-with-Weak-and-Noisy-Supervision" class="headerlink" title="When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision"></a>When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00828">http://arxiv.org/abs/2309.00828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingtao Yu, Heming Du, Chen Liu, Xin Yu</li>
<li>for: 提高弱监督3D点云实例分割的性能，使用矩形框筛选的粗糙标注。</li>
<li>methods: 利用预训练的2D基础模型SAM和3D几何诊断来从矩形框筛选获得准确的点云实例标签。</li>
<li>results: 在ScanNet-v2和S3DIS测试集上实现高质量的3D点云实例标签，并在噪音矩形框筛选情况下显示了高效性和稳定性。<details>
<summary>Abstract</summary>
Learning from bounding-boxes annotations has shown great potential in weakly-supervised 3D point cloud instance segmentation. However, we observed that existing methods would suffer severe performance degradation with perturbed bounding box annotations. To tackle this issue, we propose a complementary image prompt-induced weakly-supervised point cloud instance segmentation (CIP-WPIS) method. CIP-WPIS leverages pretrained knowledge embedded in the 2D foundation model SAM and 3D geometric prior to achieve accurate point-wise instance labels from the bounding box annotations. Specifically, CP-WPIS first selects image views in which 3D candidate points of an instance are fully visible. Then, we generate complementary background and foreground prompts from projections to obtain SAM 2D instance mask predictions. According to these, we assign the confidence values to points indicating the likelihood of points belonging to the instance. Furthermore, we utilize 3D geometric homogeneity provided by superpoints to decide the final instance label assignments. In this fashion, we achieve high-quality 3D point-wise instance labels. Extensive experiments on both Scannet-v2 and S3DIS benchmarks demonstrate that our method is robust against noisy 3D bounding-box annotations and achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
学习封包注解可以提高弱相关3D点云实例分割的潜力。然而，我们发现现有方法对受到扰动 boundING box注解时会表现出严重的性能下降。为解决这个问题，我们提出了补充图 prompt-induced 弱相关3D点云实例分割（CIP-WPIS）方法。CIP-WPIS 利用预训练在2D基础模型 SAM 中嵌入的知识和3D几何规范来实现从 bounding box 注解中获取高质量点云实例标签。具体来说，CIP-WPIS 首先选择在实例中3D候选点完全可见的图像视图。然后，我们生成补充背景和前景投影以获得 SAM 2D实例幕标注。根据这些标注，我们将点Cloud中的点分配确idence值，以表示点是否属于实例。此外，我们利用 superpoints 提供的3D几何一致性来决定实例标签分配。这种方法可以实现高质量点云实例标签。我们在 Scannet-v2 和 S3DIS benchmark上进行了广泛的实验，并证明了我们的方法对受到扰动 bounding box 注解的Robustness和性能具有状态的某些表现。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-font-generation-via-transferring-similarity-guided-global-style-and-quantization-local-style"><a href="#Few-shot-font-generation-via-transferring-similarity-guided-global-style-and-quantization-local-style" class="headerlink" title="Few shot font generation via transferring similarity guided global style and quantization local style"></a>Few shot font generation via transferring similarity guided global style and quantization local style</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00827">http://arxiv.org/abs/2309.00827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/awei669/VQ-Font">https://github.com/awei669/VQ-Font</a></li>
<li>paper_authors: Wei Pan, Anna Zhu, Xinyu Zhou, Brian Kenji Iwana, Shilin Li</li>
<li>for: 这种研究旨在实现自动化少量字体生成（AFFG），以便通过只需要几个字形参考来生成新的字体，从而降低手动设计字体的劳动成本。</li>
<li>methods: 该方法采用了字符相似性指导的全局特征归一化和精细组件水平表示，并通过跨注意力基本样式传递模块来传递参考字形的风格。无需手动定义特定的字形组件，如笔画和基本元素。</li>
<li>results: 实验结果表明，该方法可以获得完整的组件级风格表示，并控制全局字形特征。与其他当前状态顶尖方法相比，该方法在不同的语言书写系统上表现出了更高的效果和普适性。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/awei669/VQ-Font%E3%80%82">https://github.com/awei669/VQ-Font。</a><details>
<summary>Abstract</summary>
Automatic few-shot font generation (AFFG), aiming at generating new fonts with only a few glyph references, reduces the labor cost of manually designing fonts. However, the traditional AFFG paradigm of style-content disentanglement cannot capture the diverse local details of different fonts. So, many component-based approaches are proposed to tackle this problem. The issue with component-based approaches is that they usually require special pre-defined glyph components, e.g., strokes and radicals, which is infeasible for AFFG of different languages. In this paper, we present a novel font generation approach by aggregating styles from character similarity-guided global features and stylized component-level representations. We calculate the similarity scores of the target character and the referenced samples by measuring the distance along the corresponding channels from the content features, and assigning them as the weights for aggregating the global style features. To better capture the local styles, a cross-attention-based style transfer module is adopted to transfer the styles of reference glyphs to the components, where the components are self-learned discrete latent codes through vector quantization without manual definition. With these designs, our AFFG method could obtain a complete set of component-level style representations, and also control the global glyph characteristics. The experimental results reflect the effectiveness and generalization of the proposed method on different linguistic scripts, and also show its superiority when compared with other state-of-the-art methods. The source code can be found at https://github.com/awei669/VQ-Font.
</details>
<details>
<summary>摘要</summary>
自动几个字体生成（AFFG），目的是通过只需几个字形引用来生成新字体，从而减少手动设计字体的劳动成本。然而，传统的AFFG模式中的风格内容分离无法捕捉不同字体的地方细节。因此，许多组件化方法被提议。然而，这些组件化方法通常需要特定的预定义字形组件，例如笔画和基本元素，这是不适用于不同语言的AFFG。在这篇论文中，我们提出了一种新的字体生成方法，通过将风格特征从类似性指导的全局特征和精细组件水平表示相乘。我们在目标字形和参考样本之间计算相似性分数，并将其作为全局风格特征的权重进行相乘。为更好地捕捉地方风格，我们采用了交叉注意力基于的风格传输模块，将参考字形的风格传输到组件水平，其中组件是通过量化Vector без manual定义得到的自适应积分码。通过这些设计，我们的AFFG方法可以获得完整的组件级别风格表示，同时控制全局字形特征。实验结果表明了我们的方法在不同的文字系统中的效果和普遍性，以及与其他当前领域的方法相比的优势。详细代码可以在 <https://github.com/awei669/VQ-Font> 找到。
</details></li>
</ul>
<hr>
<h2 id="Soil-Image-Segmentation-Based-on-Mask-R-CNN"><a href="#Soil-Image-Segmentation-Based-on-Mask-R-CNN" class="headerlink" title="Soil Image Segmentation Based on Mask R-CNN"></a>Soil Image Segmentation Based on Mask R-CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00817">http://arxiv.org/abs/2309.00817</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YidaMyth/Mask-RCNN_QtGui">https://github.com/YidaMyth/Mask-RCNN_QtGui</a></li>
<li>paper_authors: Yida Chen, Kang Liu, Yi Xin, Xinru Zhao</li>
<li>for: 本研究是为了开发一种可以在自然环境下实时 segmentation 和检测土壤图像的机器视觉方法。</li>
<li>methods: 本研究使用了深度学习的Mask R-CNN模型来实现土壤图像实例分割。首先，构建了一个基于收集的土壤图像集，并使用EISeg注解工具将土壤区域标注为土壤。然后，使用了GPU加速来训练Mask R-CNN模型，并在训练集和验证集上进行了评估。</li>
<li>results: 训练后，Mask R-CNN模型可以准确地 segmentation 土壤图像，并在不同环境下收集的图像上表现良好。训练集的损失值为0.1999，验证集的mAP值（IoU&#x3D;0.5）为0.8804，并且只需0.06秒的时间来完成图像 segmentation。<details>
<summary>Abstract</summary>
The complex background in the soil image collected in the field natural environment will affect the subsequent soil image recognition based on machine vision. Segmenting the soil center area from the soil image can eliminate the influence of the complex background, which is an important preprocessing work for subsequent soil image recognition. For the first time, the deep learning method was applied to soil image segmentation, and the Mask R-CNN model was selected to complete the positioning and segmentation of soil images. Construct a soil image dataset based on the collected soil images, use the EISeg annotation tool to mark the soil area as soil, and save the annotation information; train the Mask R-CNN soil image instance segmentation model. The trained model can obtain accurate segmentation results for soil images, and can show good performance on soil images collected in different environments; the trained instance segmentation model has a loss value of 0.1999 in the training set, and the mAP of the validation set segmentation (IoU=0.5) is 0.8804, and it takes only 0.06s to complete image segmentation based on GPU acceleration, which can meet the real-time segmentation and detection of soil images in the field under natural conditions. You can get our code in the Conclusions. The homepage is https://github.com/YidaMyth.
</details>
<details>
<summary>摘要</summary>
在自然环境中采集的土壤图像中的复杂背景将影响后续的土壤图像认知基于机器视觉。 segmenting 土壤中心区域从土壤图像中可以消除复杂背景的影响，这是土壤图像认知前置处理的重要步骤。 这是首次应用深度学习方法进行土壤图像分割，选择了Mask R-CNN模型来完成位置和分割土壤图像。 根据收集的土壤图像构建了土壤图像数据集，使用EISeg注意力工具标记土壤区域为土壤，并保存注意力信息。 训练Mask R-CNN土壤图像实例分割模型。 训练后的模型可以在不同环境中获得高精度的分割结果，并且在0.06秒钟内完成图像分割基于GPU加速，可以满足在自然条件下的实时分割和检测土壤图像。 可以在结论中获取我们的代码。 主页是https://github.com/YidaMyth。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Video-Transformers-for-Isolated-Sign-Language-Recognition"><a href="#Self-Supervised-Video-Transformers-for-Isolated-Sign-Language-Recognition" class="headerlink" title="Self-Supervised Video Transformers for Isolated Sign Language Recognition"></a>Self-Supervised Video Transformers for Isolated Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02450">http://arxiv.org/abs/2309.02450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcelo Sandoval-Castaneda, Yanhong Li, Diane Brentari, Karen Livescu, Gregory Shakhnarovich</li>
<li>for: 本研究是一篇关于孤立手语识别（ISLR）自我超级vised学习方法的深入分析文章。</li>
<li>methods: 我们考虑了四种最近引入的 transformer 基于方法，以及四种预训练数据模式，并在 WLASL2000 数据集上研究了所有组合。</li>
<li>results: 我们发现，MaskFeat 可以超过 pose-based 和监督视频模型，在 gloss-based WLASL2000 上达到 79.02% 的top-1 准确率。此外，我们还分析了这些模型对 ASL 手语表示的能力，并通过 linear probing 分析表示的多样性。这个研究证明了 ISLR 中 architecture 和预训练任务的选择对性的重要性。<details>
<summary>Abstract</summary>
This paper presents an in-depth analysis of various self-supervision methods for isolated sign language recognition (ISLR). We consider four recently introduced transformer-based approaches to self-supervised learning from videos, and four pre-training data regimes, and study all the combinations on the WLASL2000 dataset. Our findings reveal that MaskFeat achieves performance superior to pose-based and supervised video models, with a top-1 accuracy of 79.02% on gloss-based WLASL2000. Furthermore, we analyze these models' ability to produce representations of ASL signs using linear probing on diverse phonological features. This study underscores the value of architecture and pre-training task choices in ISLR. Specifically, our results on WLASL2000 highlight the power of masked reconstruction pre-training, and our linear probing results demonstrate the importance of hierarchical vision transformers for sign language representation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AttT2M-Text-Driven-Human-Motion-Generation-with-Multi-Perspective-Attention-Mechanism"><a href="#AttT2M-Text-Driven-Human-Motion-Generation-with-Multi-Perspective-Attention-Mechanism" class="headerlink" title="AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism"></a>AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00796">http://arxiv.org/abs/2309.00796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZcyMonkey/AttT2M">https://github.com/ZcyMonkey/AttT2M</a></li>
<li>paper_authors: Chongyang Zhong, Lei Hu, Zihao Zhang, Shihong Xia</li>
<li>for: 本研究的目的是提出一种基于文本描述的三维人体运动生成方法，以便生成自然、多样化的人体运动。</li>
<li>methods: 该方法使用了两个阶段的方法，包括body-part attention和global-local motion-text attention。body-part attention通过引入人体部分空间编码器来学习更表达性的精度矩阵空间，而global-local motion-text attention则是从cross-modal角度学习文本和运动之间的关系。</li>
<li>results: 对于HumanML3D和KIT-ML两个数据集，该方法在质量和量化评估中几乎所有超过当前状态的方法，并实现了细腻的生成和action2motion。<details>
<summary>Abstract</summary>
Generating 3D human motion based on textual descriptions has been a research focus in recent years. It requires the generated motion to be diverse, natural, and conform to the textual description. Due to the complex spatio-temporal nature of human motion and the difficulty in learning the cross-modal relationship between text and motion, text-driven motion generation is still a challenging problem. To address these issues, we propose \textbf{AttT2M}, a two-stage method with multi-perspective attention mechanism: \textbf{body-part attention} and \textbf{global-local motion-text attention}. The former focuses on the motion embedding perspective, which means introducing a body-part spatio-temporal encoder into VQ-VAE to learn a more expressive discrete latent space. The latter is from the cross-modal perspective, which is used to learn the sentence-level and word-level motion-text cross-modal relationship. The text-driven motion is finally generated with a generative transformer. Extensive experiments conducted on HumanML3D and KIT-ML demonstrate that our method outperforms the current state-of-the-art works in terms of qualitative and quantitative evaluation, and achieve fine-grained synthesis and action2motion. Our code is in https://github.com/ZcyMonkey/AttT2M
</details>
<details>
<summary>摘要</summary>
师MAIN RESEARCH FOCUS IN RECENT YEARS HAS BEEN GENERATING 3D HUMAN MOTION BASED ON TEXTUAL DESCRIPTIONS. THIS REQUIRES THE GENERATED MOTION TO BE DIVERSE, NATURAL, AND CONFORM TO THE TEXTUAL DESCRIPTION. DUE TO THE COMPLEX SPATIO-TEMPORAL NATURE OF HUMAN MOTION AND THE DIFFICULTY IN LEARNING THE CROSS-MODAL RELATIONSHIP BETWEEN TEXT AND MOTION, TEXT-DRIVEN MOTION GENERATION IS STILL A CHALLENGING PROBLEM. TO ADDRESS THESE ISSUES, WE PROPOSE ATT2M, A TWO-STAGE METHOD WITH MULTI-PERSPECTIVE ATTENTION MECHANISM. THE FORMER FOCUSES ON THE MOTION EMBEDDING PERSPECTIVE, WHICH MEANS INTRODUCING A BODY-PART SPATIO-TEMPORAL ENCODER INTO VQ-VAE TO LEARN A MORE EXPRESSIVE DISCRETE LATENT SPACE. THE LATTER IS FROM THE CROSS-MODAL PERSPECTIVE, WHICH IS USED TO LEARN THE SENTENCE-LEVEL AND WORD-LEVEL MOTION-TEXT CROSS-MODAL RELATIONSHIP. THE TEXT-DRIVEN MOTION IS FINALLY GENERATED WITH A GENERATIVE TRANSFORMER. EXTENSIVE EXPERIMENTS CONDUCTED ON HUMANML3D AND KIT-ML DEMONSTRATE THAT OUR METHOD OUTPERFORMS THE CURRENT STATE-OF-THE-ART WORKS IN TERMS OF QUALITATIVE AND QUANTITATIVE EVALUATION, AND ACHIEVE FINE-GRAINED SYNTHESIS AND ACTION2MOTION. OUR CODE IS AVAILABLE AT https://github.com/ZcyMonkey/AttT2M.
</details></li>
</ul>
<hr>
<h2 id="FastPoseGait-A-Toolbox-and-Benchmark-for-Efficient-Pose-based-Gait-Recognition"><a href="#FastPoseGait-A-Toolbox-and-Benchmark-for-Efficient-Pose-based-Gait-Recognition" class="headerlink" title="FastPoseGait: A Toolbox and Benchmark for Efficient Pose-based Gait Recognition"></a>FastPoseGait: A Toolbox and Benchmark for Efficient Pose-based Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00794">http://arxiv.org/abs/2309.00794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bnu-ivc/fastposegait">https://github.com/bnu-ivc/fastposegait</a></li>
<li>paper_authors: Shibei Meng, Yang Fu, Saihui Hou, Chunshui Cao, Xu Liu, Yongzhen Huang</li>
<li>for: 这个研究旨在提供一个开源的 pose-based gait recognition 工具箱，以便研究人员可以快速进行 pose-based gait recognition 的研究。</li>
<li>methods: 这个工具箱支持多种现代 pose-based gait recognition 算法，包括多种 SOTA 算法和最新的进步。此外，这个工具箱还提供了许多预训模型和详细的 benchmark 结果，对未来的研究提供了宝贵的参考和对照。</li>
<li>results: 这个研究提供了一个高度可调的 pose-based gait recognition 工具箱，可以快速地进行 pose-based gait recognition 的研究。此外，这个工具箱还提供了许多预训模型和详细的 benchmark 结果，对未来的研究提供了宝贵的参考和对照。<details>
<summary>Abstract</summary>
We present FastPoseGait, an open-source toolbox for pose-based gait recognition based on PyTorch. Our toolbox supports a set of cutting-edge pose-based gait recognition algorithms and a variety of related benchmarks. Unlike other pose-based projects that focus on a single algorithm, FastPoseGait integrates several state-of-the-art (SOTA) algorithms under a unified framework, incorporating both the latest advancements and best practices to ease the comparison of effectiveness and efficiency. In addition, to promote future research on pose-based gait recognition, we provide numerous pre-trained models and detailed benchmark results, which offer valuable insights and serve as a reference for further investigations. By leveraging the highly modular structure and diverse methods offered by FastPoseGait, researchers can quickly delve into pose-based gait recognition and promote development in the field. In this paper, we outline various features of this toolbox, aiming that our toolbox and benchmarks can further foster collaboration, facilitate reproducibility, and encourage the development of innovative algorithms for pose-based gait recognition. FastPoseGait is available at https://github.com//BNU-IVC/FastPoseGait and is actively maintained. We will continue updating this report as we add new features.
</details>
<details>
<summary>摘要</summary>
我们现在推出 FastPoseGait，一个开源工具箱 для pose-based 步态识别基于 PyTorch。我们的工具箱支持一系列当今最先进的 pose-based 步态识别算法以及一些相关的benchmark。与其他 pose-based 项目不同，FastPoseGait 集成了多种最新的SOTA算法，并在一个统一的框架下集成了最新的技术和最佳实践，以便方便比较效果和效率。此外，为促进未来的pose-based 步态识别研究，我们提供了多个预训练模型和详细的benchmark结果，这些结果对于进一步的调查提供了 ценные信息，并作为参考来供其他研究人员参考。通过 FastPoseGait 的高度可模块化结构和多种方法，研究人员可以快速探索 pose-based 步态识别领域，并促进该领域的发展。在这篇文章中，我们详细介绍了 FastPoseGait 的各种特点，希望通过我们的工具箱和benchmark，推动合作、促进复制性和激发 pose-based 步态识别领域的创新算法的发展。FastPoseGait 可以在 <https://github.com//BNU-IVC/FastPoseGait> 上下载，并且 actively 维护。我们将继续更新这份报告，添加新的特性。
</details></li>
</ul>
<hr>
<h2 id="Towards-High-Frequency-Tracking-and-Fast-Edge-Aware-Optimization"><a href="#Towards-High-Frequency-Tracking-and-Fast-Edge-Aware-Optimization" class="headerlink" title="Towards High-Frequency Tracking and Fast Edge-Aware Optimization"></a>Towards High-Frequency Tracking and Fast Edge-Aware Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00777">http://arxiv.org/abs/2309.00777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akash Bapat<br>for:* 这个论文目标是提高AR&#x2F;VR跟踪系统的状态 искусственный智能，提高跟踪频率至数个命令的频率。methods:* 该论文提出了一种利用多个商业摄像头的方法，利用摄像头的滚动屏和圆形扭曲来实现高频跟踪。results:* 实验表明，该方法可以在不同的运动范围内实现高精度的跟踪，并且可以与现有的状态 искусственный智能系统进行综合比较。<details>
<summary>Abstract</summary>
This dissertation advances the state of the art for AR/VR tracking systems by increasing the tracking frequency by orders of magnitude and proposes an efficient algorithm for the problem of edge-aware optimization.   AR/VR is a natural way of interacting with computers, where the physical and digital worlds coexist. We are on the cusp of a radical change in how humans perform and interact with computing. Humans are sensitive to small misalignments between the real and the virtual world, and tracking at kilo-Hertz frequencies becomes essential. Current vision-based systems fall short, as their tracking frequency is implicitly limited by the frame-rate of the camera. This thesis presents a prototype system which can track at orders of magnitude higher than the state-of-the-art methods using multiple commodity cameras. The proposed system exploits characteristics of the camera traditionally considered as flaws, namely rolling shutter and radial distortion. The experimental evaluation shows the effectiveness of the method for various degrees of motion.   Furthermore, edge-aware optimization is an indispensable tool in the computer vision arsenal for accurate filtering of depth-data and image-based rendering, which is increasingly being used for content creation and geometry processing for AR/VR. As applications increasingly demand higher resolution and speed, there exists a need to develop methods that scale accordingly. This dissertation proposes such an edge-aware optimization framework which is efficient, accurate, and algorithmically scales well, all of which are much desirable traits not found jointly in the state of the art. The experiments show the effectiveness of the framework in a multitude of computer vision tasks such as computational photography and stereo.
</details>
<details>
<summary>摘要</summary>
Furthermore, edge-aware optimization is an indispensable tool in the computer vision arsenal for accurate filtering of depth-data and image-based rendering, which is increasingly being used for content creation and geometry processing for AR/VR.  As applications increasingly demand higher resolution and speed, there exists a need to develop methods that scale accordingly.  This dissertation proposes such an edge-aware optimization framework which is efficient, accurate, and algorithmically scales well, all of which are much desirable traits not found jointly in the state of the art.  The experiments show the effectiveness of the framework in a multitude of computer vision tasks such as computational photography and stereo.
</details></li>
</ul>
<hr>
<h2 id="Full-Reference-Video-Quality-Assessment-for-Machine-Learning-Based-Video-Codecs"><a href="#Full-Reference-Video-Quality-Assessment-for-Machine-Learning-Based-Video-Codecs" class="headerlink" title="Full Reference Video Quality Assessment for Machine Learning-Based Video Codecs"></a>Full Reference Video Quality Assessment for Machine Learning-Based Video Codecs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00769">http://arxiv.org/abs/2309.00769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abrar Majeedi, Babak Naderi, Yasaman Hosseinkashi, Juhee Cho, Ruben Alvarez Martinez, Ross Cutler</li>
<li>for: 本研究旨在提供一个准确评估metric以便评估机器学习（ML）基于的影像压缩器，因为现有的评估metric在ML影像压缩器上不具有高相关性。</li>
<li>methods: 本研究使用了一个新的 dataset，其中包含了已精准地标注的质量标准。此外，研究者还提出了一个全参照影像质量评估（FRVQA）模型，它具有0.99的彭森相関系数（PCC）和0.99的施普曼排名相关系数（SRCC）。</li>
<li>results: 研究结果显示，新的评估metric 具有高相关性，并且可以帮助加速机器学习影像压缩器的研究。此外，研究者还将dataset和FRVQA模型开源，以便其他人可以进一步改进FRVQA模型。<details>
<summary>Abstract</summary>
Machine learning-based video codecs have made significant progress in the past few years. A critical area in the development of ML-based video codecs is an accurate evaluation metric that does not require an expensive and slow subjective test. We show that existing evaluation metrics that were designed and trained on DSP-based video codecs are not highly correlated to subjective opinion when used with ML video codecs due to the video artifacts being quite different between ML and video codecs. We provide a new dataset of ML video codec videos that have been accurately labeled for quality. We also propose a new full reference video quality assessment (FRVQA) model that achieves a Pearson Correlation Coefficient (PCC) of 0.99 and a Spearman's Rank Correlation Coefficient (SRCC) of 0.99 at the model level. We make the dataset and FRVQA model open source to help accelerate research in ML video codecs, and so that others can further improve the FRVQA model.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we have created a new dataset of ML video codec videos that have been accurately labeled for quality. We also propose a new full reference video quality assessment (FRVQA) model that achieves a Pearson Correlation Coefficient (PCC) of 0.99 and a Spearman's Rank Correlation Coefficient (SRCC) of 0.99 at the model level.To help accelerate research in ML video codecs, we are making the dataset and FRVQA model open source. We hope that others will use and build upon our work to further improve the FRVQA model and advance the field of ML video codecs.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.CV_2023_09_02/" data-id="clogxf3mz00gs5xradldnb9j8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.AI_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T12:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.AI_2023_09_02/">cs.AI - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Neurosymbolic-Reinforcement-Learning-and-Planning-A-Survey"><a href="#Neurosymbolic-Reinforcement-Learning-and-Planning-A-Survey" class="headerlink" title="Neurosymbolic Reinforcement Learning and Planning: A Survey"></a>Neurosymbolic Reinforcement Learning and Planning: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01038">http://arxiv.org/abs/2309.01038</a></li>
<li>repo_url: None</li>
<li>paper_authors: K. Acharya, W. Raza, C. M. J. M. Dourado Jr, A. Velasquez, H. Song<br>for: 本研究的目的是对 neurosymbolic 人工智能（Neurosymbolic AI）领域的发展进行文献综述，特别是 neurosymbolic deep learning（Neurosymbolic DL）和 neurosymbolic reinforcement learning（Neurosymbolic RL）这两个子领域。methods: 本研究使用文献综述的方法，对 neurosymbolic RL 领域的研究进行分类和概括。三种分类方法是：学习 для理解、理解 для学习和学习-理解。这些分类方法再次细分为各个应用领域。results: 本研究发现 neurosymbolic RL 领域的研究主要集中在三个方面：学习、理解和决策。学习方面包括对于不同应用领域的学习方法和技术的研究，例如 image recognition 和自然语言处理。理解方面包括对于不同应用领域的理解方法和技术的研究，例如知识 Graph 和 Semantic Reasoning。决策方面包括对于不同应用领域的决策方法和技术的研究，例如 deep reinforcement learning 和 Transfer Learning。<details>
<summary>Abstract</summary>
The area of Neurosymbolic Artificial Intelligence (Neurosymbolic AI) is rapidly developing and has become a popular research topic, encompassing sub-fields such as Neurosymbolic Deep Learning (Neurosymbolic DL) and Neurosymbolic Reinforcement Learning (Neurosymbolic RL). Compared to traditional learning methods, Neurosymbolic AI offers significant advantages by simplifying complexity and providing transparency and explainability. Reinforcement Learning(RL), a long-standing Artificial Intelligence(AI) concept that mimics human behavior using rewards and punishment, is a fundamental component of Neurosymbolic RL, a recent integration of the two fields that has yielded promising results. The aim of this paper is to contribute to the emerging field of Neurosymbolic RL by conducting a literature survey. Our evaluation focuses on the three components that constitute Neurosymbolic RL: neural, symbolic, and RL. We categorize works based on the role played by the neural and symbolic parts in RL, into three taxonomies:Learning for Reasoning, Reasoning for Learning and Learning-Reasoning. These categories are further divided into sub-categories based on their applications. Furthermore, we analyze the RL components of each research work, including the state space, action space, policy module, and RL algorithm. Additionally, we identify research opportunities and challenges in various applications within this dynamic field.
</details>
<details>
<summary>摘要</summary>
neural 符号 人工智能（Neurosymbolic AI）领域在迅速发展，已成为研究热点，涵盖子领域 such as Neurosymbolic Deep Learning（Neurosymbolic DL）和Neurosymbolic Reinforcement Learning（Neurosymbolic RL）。相比传统学习方法，Neurosymbolic AI 提供了 significan advantages，例如简化复杂性和提供透明性和解释性。人工智能（AI）概念，模拟人类行为使用奖励和惩罚的 Reinforcement Learning（RL），是 Neurosymbolic RL 的基础组件，是一种最近 integrate 两个领域的成果，并产生了有前途的结果。本文的目标是为emerging 的 Neurosymbolic RL 领域进行文献综述。我们的评估将关注Neurosymbolic RL 中的三个组件：神经、符号和RL。我们根据这三个组件在 RL 中的角色，将工作分为三类：学习为理解、理解为学习和学习-理解。这些类别进一步分为应用的子类别。此外，我们还分析了每个研究作品中的 RL 组件，包括状态空间、动作空间、策略模块和RL算法。此外，我们还识别了在不同应用场景中的研究机会和挑战。
</details></li>
</ul>
<hr>
<h2 id="Deep-Deformable-Models-Learning-3D-Shape-Abstractions-with-Part-Consistency"><a href="#Deep-Deformable-Models-Learning-3D-Shape-Abstractions-with-Part-Consistency" class="headerlink" title="Deep Deformable Models: Learning 3D Shape Abstractions with Part Consistency"></a>Deep Deformable Models: Learning 3D Shape Abstractions with Part Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01035">http://arxiv.org/abs/2309.01035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Liu, Long Zhao, Qilong Zhangli, Yunhe Gao, Ting Liu, Dimitris N. Metaxas</li>
<li>for: 本研究旨在提出一种能够精准抽象自然物体形状的深度学习方法，以提高形状理解和应用。</li>
<li>methods: 本方法基于深度学习的Deep Deformable Models (DDMs)，它使用全局变换和 diffeomorphic 本地变换来描述物体形状，并可以学习到精准的部件相对位置和尺寸。</li>
<li>results: 在ShapeNet数据集上进行了广泛的实验，并证明了DDMs可以在形状抽象中具有更高的精度和部件一致性，并且超过了现有的状态场方法。<details>
<summary>Abstract</summary>
The task of shape abstraction with semantic part consistency is challenging due to the complex geometries of natural objects. Recent methods learn to represent an object shape using a set of simple primitives to fit the target. \textcolor{black}{However, in these methods, the primitives used do not always correspond to real parts or lack geometric flexibility for semantic interpretation.} In this paper, we investigate salient and efficient primitive descriptors for accurate shape abstractions, and propose \textit{Deep Deformable Models (DDMs)}. DDM employs global deformations and diffeomorphic local deformations. These properties enable DDM to abstract complex object shapes with significantly fewer primitives that offer broader geometry coverage and finer details. DDM is also capable of learning part-level semantic correspondences due to the differentiable and invertible properties of our primitive deformation. Moreover, DDM learning formulation is based on dynamic and kinematic modeling, which enables joint regularization of each sub-transformation during primitive fitting. Extensive experiments on \textit{ShapeNet} demonstrate that DDM outperforms the state-of-the-art in terms of reconstruction and part consistency by a notable margin.
</details>
<details>
<summary>摘要</summary>
shape abstraction with semantic part consistency是一项复杂的任务，因为自然物体的geometry是多样的。现有的方法通过使用一组简单的基本元素来表示物体形状，但这些基本元素并不总是真实的部分或者缺乏地理学灵活性。在这篇论文中，我们调查了突出的和高效的基本描述符，并提出了深度可变模型（DDM）。DDM使用全局变形和 diffeomorphic 地方变形，这些特性使得 DDM 可以准确抽象复杂的物体形状，并且只需要 fewer primitives，可以更好地覆盖各种geometry和细节。此外，DDM 可以学习部分 semantics 的匹配，因为我们的基本描述符具有可微和反函数性。此外，我们的学习框架基于动态和静态模型，可以同时规范每个子转换的定制。我们的实验表明，DDM 在 ShapeNet 上的重建和部件一致性方面，与状态对比明显提高。
</details></li>
</ul>
<hr>
<h2 id="Explainability-for-Large-Language-Models-A-Survey"><a href="#Explainability-for-Large-Language-Models-A-Survey" class="headerlink" title="Explainability for Large Language Models: A Survey"></a>Explainability for Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01029">http://arxiv.org/abs/2309.01029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Mengnan Du</li>
<li>for: 本研究旨在掌握和解释大型自然语言处理模型（LLMs）的内部机制，以便了解其行为、局限性和社会影响。</li>
<li>methods: 本文提出了一种分类法，用于描述和解释基于Transformer架构的语言模型。该分类法基于语言模型的训练方法，包括传统的精度训练方法和提示方法。</li>
<li>results: 本文提供了一个结构化的概述，描述了基于Transformer架构的语言模型的解释技术。还介绍了评估生成的解释 metric，以及如何使用解释来调试模型和提高性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional machine learning models.
</details>
<details>
<summary>摘要</summary>
In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional machine learning models. Traditional fine-tuning-based paradigm:1. Local explanations:	* feature importance analysis	* saliency maps	* attention visualization2. Global explanations:	* model interpretability techniques	* knowledge distillationPrompting-based paradigm:1. Local explanations:	* prompt-based attention analysis	* prompt-based feature importance analysis2. Global explanations:	* prompt-based knowledge distillationEvaluation metrics:1. accuracy2. F1-score3. ROUGE score4. BLEU scoreChallenges and opportunities:1. interpretability of complex models2. lack of transparency in decision-making processes3. potential biases and ethical considerations4. opportunities for improving model performance and trustworthiness5. potential applications in natural language processing and beyond.
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Recommendations-with-Pre-Trained-Large-Language-Models-for-Multimodal-Nudging"><a href="#Zero-Shot-Recommendations-with-Pre-Trained-Large-Language-Models-for-Multimodal-Nudging" class="headerlink" title="Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging"></a>Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01026">http://arxiv.org/abs/2309.01026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paxnea/wain23">https://github.com/paxnea/wain23</a></li>
<li>paper_authors: Rachel Harrison, Anton Dereventsov, Anton Bibin</li>
<li>for: 这篇论文旨在提出一种针对多Modal非站点内容的零shot推荐方法，利用最新的生成AI技术。</li>
<li>methods: 该方法提议将不同Modal的输入描述为文本描述，使用预训练的LLM获取它们的数字表示，并计算它们之间的相似度来进行推荐。</li>
<li>results: 在一个synthetic多Modal推动环境中，该方法可以准确地推荐多Modal的内容项，不需要额外学习。<details>
<summary>Abstract</summary>
We present a method for zero-shot recommendation of multimodal non-stationary content that leverages recent advancements in the field of generative AI. We propose rendering inputs of different modalities as textual descriptions and to utilize pre-trained LLMs to obtain their numerical representations by computing semantic embeddings. Once unified representations of all content items are obtained, the recommendation can be performed by computing an appropriate similarity metric between them without any additional learning. We demonstrate our approach on a synthetic multimodal nudging environment, where the inputs consist of tabular, textual, and visual data.
</details>
<details>
<summary>摘要</summary>
我们提出了一种零shot推荐多Modal非站点内容的方法，利用最新的生成AI技术进行实现。我们提议将不同模式的输入描述为文本描述，并使用预训练的LLM来获得它们的数字表示。一旦所有内容项的统一表示 obten得到， then recommendation可以通过计算相应的相似度 metric来进行，无需进行额外学习。我们在一个Synthetic多Modal拖延环境中进行了示例，输入包括表格、文本和视觉数据。Note:* "零shot" (zero-shot) refers to the fact that the recommendation is done without any additional training or learning of the model.* "多Modal" (multimodal) refers to the fact that the inputs consist of multiple modalities, such as tabular, textual, and visual data.* "非站点" (non-stationary) refers to the fact that the inputs are not stationary, meaning that they are not fixed and can change over time.
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Motion-Blur-for-Robust-3D-Baseball-Player-Pose-Modeling-for-Pitch-Analysis"><a href="#Mitigating-Motion-Blur-for-Robust-3D-Baseball-Player-Pose-Modeling-for-Pitch-Analysis" class="headerlink" title="Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for Pitch Analysis"></a>Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for Pitch Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01010">http://arxiv.org/abs/2309.01010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jerrin Bright, Yuhao Chen, John Zelek</li>
<li>for: 用于 baseball 投手的分析和减少伤病风险</li>
<li>methods: 使用计算机视觉基于pose分析，并利用Synthetic数据增强模型对快速动作的处理能力</li>
<li>results: 提高 pose 估计模型对运动人体动作的处理能力，并在不同的实际场景和摄像头位置下保持模型的稳定性<details>
<summary>Abstract</summary>
Using videos to analyze pitchers in baseball can play a vital role in strategizing and injury prevention. Computer vision-based pose analysis offers a time-efficient and cost-effective approach. However, the use of accessible broadcast videos, with a 30fps framerate, often results in partial body motion blur during fast actions, limiting the performance of existing pose keypoint estimation models. Previous works have primarily relied on fixed backgrounds, assuming minimal motion differences between frames, or utilized multiview data to address this problem. To this end, we propose a synthetic data augmentation pipeline to enhance the model's capability to deal with the pitcher's blurry actions. In addition, we leverage in-the-wild videos to make our model robust under different real-world conditions and camera positions. By carefully optimizing the augmentation parameters, we observed a notable reduction in the loss by 54.2% and 36.2% on the test dataset for 2D and 3D pose estimation respectively. By applying our approach to existing state-of-the-art pose estimators, we demonstrate an average improvement of 29.2%. The findings highlight the effectiveness of our method in mitigating the challenges posed by motion blur, thereby enhancing the overall quality of pose estimation.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:使用视频分析投手可以发挥重要作用，帮助战略和伤害预防。计算机视觉基于姿势分析提供了时间效益和成本效益的方法。然而，使用可 accessible 的广播视频，30fps 帧率，常常导致快速动作中人体部分动作模糊，限制现有的姿势关键点估计模型的性能。先前的工作主要依赖于固定背景，假设动作变化少，或者使用多视图数据来解决这个问题。为此，我们提议一种人工数据增强管道，以提高模型对投手模糊动作的处理能力。此外，我们利用野外视频，使我们的模型在不同的实际情况和摄像机位置下成为更加可靠。通过精心优化增强参数，我们观察到了测试数据集上的损失下降54.2%和36.2%，对2D和3D姿势估计模型进行了平均改进29.2%。通过应用我们的方法到现有的状态态arter-of-the-art姿势估计器，我们实现了平均改进29.2%。这些发现表明了我们的方法在对动作模糊的挑战下减轻影响，从而提高总体姿势估计质量。
</details></li>
</ul>
<hr>
<h2 id="Sequential-Dexterity-Chaining-Dexterous-Policies-for-Long-Horizon-Manipulation"><a href="#Sequential-Dexterity-Chaining-Dexterous-Policies-for-Long-Horizon-Manipulation" class="headerlink" title="Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation"></a>Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00987">http://arxiv.org/abs/2309.00987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanpei Chen, Chen Wang, Li Fei-Fei, C. Karen Liu</li>
<li>for: 这个研究旨在解决复杂长期任务中手部运动空间高维度和复合动力学性的挑战，提出了一个基于循环学习（RL）的总体系统，可以链接多个细致政策以实现长期任务目标。</li>
<li>methods: 这个系统使用了循环学习（RL），搭配了一个过程可行性函数，逐渐精致化子政策以提高链接成功率，同时允许自动政策调整以复原自失败和避免重复阶段。</li>
<li>results: 这个系统在实验中仅使用了几个任务物品进行训练，但能够实现zero-shot转移到真实世界中的机器人，并且能够对不同的物品进行适应和自动调整。更多细节和视频结果可以在<a target="_blank" rel="noopener" href="https://sequential-dexterity.github.io获取./">https://sequential-dexterity.github.io获取。</a><details>
<summary>Abstract</summary>
Many real-world manipulation tasks consist of a series of subtasks that are significantly different from one another. Such long-horizon, complex tasks highlight the potential of dexterous hands, which possess adaptability and versatility, capable of seamlessly transitioning between different modes of functionality without the need for re-grasping or external tools. However, the challenges arise due to the high-dimensional action space of dexterous hand and complex compositional dynamics of the long-horizon tasks. We present Sequential Dexterity, a general system based on reinforcement learning (RL) that chains multiple dexterous policies for achieving long-horizon task goals. The core of the system is a transition feasibility function that progressively finetunes the sub-policies for enhancing chaining success rate, while also enables autonomous policy-switching for recovery from failures and bypassing redundant stages. Despite being trained only in simulation with a few task objects, our system demonstrates generalization capability to novel object shapes and is able to zero-shot transfer to a real-world robot equipped with a dexterous hand. More details and video results could be found at https://sequential-dexterity.github.io
</details>
<details>
<summary>摘要</summary>
多个真实世界操作任务通常是一系列不同的子任务，这些长期任务表明了人工手的可靠性和多样性，可以无需重新抓取或使用外部工具，快速适应不同的模式功能。然而，由于高维动作空间和复杂的compositional dynamics，这些任务具有挑战。我们提出了Sequential Dexterity，一种基于奖励学习（RL）的通用系统，可以串行多个灵活策略以实现长期任务目标。系统的核心是一个过程可行性函数，逐渐细化子策略以提高串行成功率，同时允许自主的策略交换以恢复失败和绕过冗余阶段。尽管只在 simulate 环境中培养了几个任务对象，我们的系统仍然可以通过 Zero-shot 转移到真实世界中的 робоット，装备了灵活的手。更多细节和视频结果可以在 <https://sequential-dexterity.github.io> 找到。
</details></li>
</ul>
<hr>
<h2 id="Compositional-Diffusion-Based-Continuous-Constraint-Solvers"><a href="#Compositional-Diffusion-Based-Continuous-Constraint-Solvers" class="headerlink" title="Compositional Diffusion-Based Continuous Constraint Solvers"></a>Compositional Diffusion-Based Continuous Constraint Solvers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00966">http://arxiv.org/abs/2309.00966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/diffusion-ccsp/diffusion-ccsp.github.io">https://github.com/diffusion-ccsp/diffusion-ccsp.github.io</a></li>
<li>paper_authors: Zhutian Yang, Jiayuan Mao, Yilun Du, Jiajun Wu, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</li>
<li>for: 这篇论文是为了解决机器人智能和规划中的连续约束满足问题 (CCSP) 的学习方法。</li>
<li>methods: 这篇论文使用了compositional diffusion continuous constraint solver (Diffusion-CCSP) 模型，将 CCSP 表示为因子图，并将各种约束类型的能量结合起来，从而获得全局解决方案。</li>
<li>results: Diffusion-CCSP 模型能够强大地泛化到新的约束组合中，并可以与任务和运动规划结合，以生成包含整数和连续参数的长期计划。Here’s the English version of the three key points for reference:</li>
<li>for: This paper proposes a method for learning to solve continuous constraint satisfaction problems (CCSP) in robotic reasoning and planning.</li>
<li>methods: The proposed method uses a compositional diffusion continuous constraint solver (Diffusion-CCSP) model, which represents CCSPs as factor graphs and combines the energies of diffusion models trained to sample for individual constraint types.</li>
<li>results: The Diffusion-CCSP model demonstrates strong generalization to novel combinations of known constraints, and can be integrated into a task and motion planner to devise long-horizon plans that include actions with both discrete and continuous parameters.<details>
<summary>Abstract</summary>
This paper introduces an approach for learning to solve continuous constraint satisfaction problems (CCSP) in robotic reasoning and planning. Previous methods primarily rely on hand-engineering or learning generators for specific constraint types and then rejecting the value assignments when other constraints are violated. By contrast, our model, the compositional diffusion continuous constraint solver (Diffusion-CCSP) derives global solutions to CCSPs by representing them as factor graphs and combining the energies of diffusion models trained to sample for individual constraint types. Diffusion-CCSP exhibits strong generalization to novel combinations of known constraints, and it can be integrated into a task and motion planner to devise long-horizon plans that include actions with both discrete and continuous parameters. Project site: https://diffusion-ccsp.github.io/
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种用于解决连续约束满意问题（CCSP）的机器学习方法。先前的方法主要依靠手工设计或学习生成器特定约束类型，然后拒绝其他约束被违反。而我们的模型——复杂度分析 kontinuous constraint solver（Diffusion-CCSP）——通过将约束类型表示为因子图并将各类约束的能量组合起来，以 derivation global solution to CCSPs。Diffusion-CCSP具有强大的泛化能力，可以适应新的约束组合，并且可以与任务和运动规划结合，以生成长期规划，包括绝对和连续参数的动作。项目网站：https://diffusion-ccsp.github.io/
</details></li>
</ul>
<hr>
<h2 id="eDKM-An-Efficient-and-Accurate-Train-time-Weight-Clustering-for-Large-Language-Models"><a href="#eDKM-An-Efficient-and-Accurate-Train-time-Weight-Clustering-for-Large-Language-Models" class="headerlink" title="eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models"></a>eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00964">http://arxiv.org/abs/2309.00964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsik Cho, Keivan A. Vahid, Qichen Fu, Saurabh Adya, Carlo C Del Mundo, Mohammad Rastegari, Devang Naik, Peter Zatloukal</li>
<li>for: 这个论文的目的是提出一种可以实现高效对称质量调整的轻量级语言模型压缩方法，以便在储存限制的移动设备上实现更快的响应和更好的隐私保护。</li>
<li>methods: 这个方法使用了一种名为“Weight-Clustering”的非线性量化技术，并且使用了一些新的技术来实现可读性和可靠性。</li>
<li>results: 实验结果显示，这个方法可以将预训模型压缩到2.5GB（3bit&#x2F;weight），并且在较宽的语言模型测试 benchmark 上保持了良好的准确性（例如PIQA的准确度为77.7%，Winograde的准确度为66.1%等）。<details>
<summary>Abstract</summary>
Since Large Language Models or LLMs have demonstrated high-quality performance on many complex language tasks, there is a great interest in bringing these LLMs to mobile devices for faster responses and better privacy protection. However, the size of LLMs (i.e., billions of parameters) requires highly effective compression to fit into storage-limited devices. Among many compression techniques, weight-clustering, a form of non-linear quantization, is one of the leading candidates for LLM compression, and supported by modern smartphones. Yet, its training overhead is prohibitively significant for LLM fine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown the state-of-the-art trade-off between compression ratio and accuracy regression, but its large memory complexity makes it nearly impossible to apply to train-time LLM compression. In this paper, we propose a memory-efficient DKM implementation, eDKM powered by novel techniques to reduce the memory footprint of DKM by orders of magnitudes. For a given tensor to be saved on CPU for the backward pass of DKM, we compressed the tensor by applying uniquification and sharding after checking if there is no duplicated tensor previously copied to CPU. Our experimental results demonstrate that \prjname can fine-tune and compress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with the Alpaca dataset by reducing the train-time memory footprint of a decoder layer by 130$\times$, while delivering good accuracy on broader LLM benchmarks (i.e., 77.7% for PIQA, 66.1% for Winograde, and so on).
</details>
<details>
<summary>摘要</summary>
自 Large Language Models (LLMs) 在许多复杂语言任务上表现出色，因此有很大的兴趣将这些 LLMs 带到移动设备上进行更快的响应和更好的隐私保护。然而，LLMs 的大小（即数十亿参数）需要非常有效的压缩以适应存储有限的设备。许多压缩技术之一是 weight-clustering，它是一种非线性量化，并且由现代智能手机支持。然而，它的训练负担是 LLM 精度调整的瓶颈。特别是 Differentiable KMeans Clustering (DKM) 表现出了状态码的质量与精度回归的最佳平衡，但它的内存复杂度使其几乎不可能应用于训练时 LLM 压缩。在这篇论文中，我们提出了一种内存高效的 DKM 实现，即 eDKM，通过新的技术减少 DKM 的内存占用量。为一个给定的矩阵在 CPU 上进行 backwards 的 DKM，我们将矩阵压缩通过应用 uniquification 和 sharding，并且只有在检查到矩阵没有已经被复制到 CPU 的情况下进行压缩。我们的实验结果表明，我们可以使用 eDKM 将预训练的 LLaMA 7B 模型从 12.6 GB 压缩到 2.5 GB (3bit/weight)，在 Alpaca 数据集上进行精度调整，同时在更广泛的 LLM 标准准则（例如 PIQA 77.7%、Winograde 66.1% 等）上保持良好的准确率。
</details></li>
</ul>
<hr>
<h2 id="Visual-Kinematics-Graph-Learning-for-Procedure-agnostic-Instrument-Tip-Segmentation-in-Robotic-Surgeries"><a href="#Visual-Kinematics-Graph-Learning-for-Procedure-agnostic-Instrument-Tip-Segmentation-in-Robotic-Surgeries" class="headerlink" title="Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip Segmentation in Robotic Surgeries"></a>Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip Segmentation in Robotic Surgeries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00957">http://arxiv.org/abs/2309.00957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Liu, Yonghao Long, Kai Chen, Cheuk Hei Leung, Zerui Wang, Qi Dou</li>
<li>for:  precisely segmenting surgical instrument tips to enable downstream applications in robotic surgery, such as skill assessment, tool-tissue interaction, and deformation modeling, as well as surgical autonomy.</li>
<li>methods:  a novel visual-kinematics graph learning framework that encodes relational features of instrument parts from both image and kinematics, and a cross-modal contrastive loss to incorporate robust geometric prior from kinematics to image for tip segmentation.</li>
<li>results:  the proposed multi-modal segmentation method significantly outperformed current image-based state-of-the-art approaches, exceeding averagely 11.2% on Dice, on a private paired visual-kinematics dataset including multiple procedures.<details>
<summary>Abstract</summary>
Accurate segmentation of surgical instrument tip is an important task for enabling downstream applications in robotic surgery, such as surgical skill assessment, tool-tissue interaction and deformation modeling, as well as surgical autonomy. However, this task is very challenging due to the small sizes of surgical instrument tips, and significant variance of surgical scenes across different procedures. Although much effort has been made on visual-based methods, existing segmentation models still suffer from low robustness thus not usable in practice. Fortunately, kinematics data from the robotic system can provide reliable prior for instrument location, which is consistent regardless of different surgery types. To make use of such multi-modal information, we propose a novel visual-kinematics graph learning framework to accurately segment the instrument tip given various surgical procedures. Specifically, a graph learning framework is proposed to encode relational features of instrument parts from both image and kinematics. Next, a cross-modal contrastive loss is designed to incorporate robust geometric prior from kinematics to image for tip segmentation. We have conducted experiments on a private paired visual-kinematics dataset including multiple procedures, i.e., prostatectomy, total mesorectal excision, fundoplication and distal gastrectomy on cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out cross validation demonstrated that our proposed multi-modal segmentation method significantly outperformed current image-based state-of-the-art approaches, exceeding averagely 11.2% on Dice.
</details>
<details>
<summary>摘要</summary>
importante任务是正确分 segmentation of surgical instrument tip 是为 robotic surgery 下的下游应用，如技能评估、工具与组织之间的互动和变形模型，以及自动手术。然而，这项任务很有挑战性，因为外科工具的小小大小，以及不同手术过程中的重要差异。虽然很多努力已经在可见基于方法上，但现有的分 segmentation 模型仍然受到低稳定性的影响，因此在实践中不可用。幸好，机械系统的遥感数据可以提供可靠的前提，即工具的位置信息，这些信息不受不同手术类型的影响。为了利用这些多Modal信息，我们提议了一种新的可见-遥感图学学习框架，确定外科工具的末端部分。特别是，我们提出了一种图学学习框架，用于编码外科工具的关系特征从图像和机械数据中。接着，我们设计了一种交叉模式对比损失函数，以实现从机械数据中获得稳定的几何先验。我们在私人的对应视觉-机械数据集上进行了实验，包括多种手术类型，例如肾脏摘除、全部肠脏除、肠脏嵌入和胃部摘除。我们使用了留下一个手术类型的交叉验证，并显示了我们提议的多Modal分 segmentation 方法在对比现有图像基于状态先验的方法时，平均性能提高了11.2%的Dice。
</details></li>
</ul>
<hr>
<h2 id="Bridge-Diffusion-Model-bridge-non-English-language-native-text-to-image-diffusion-model-with-English-communities"><a href="#Bridge-Diffusion-Model-bridge-non-English-language-native-text-to-image-diffusion-model-with-English-communities" class="headerlink" title="Bridge Diffusion Model: bridge non-English language-native text-to-image diffusion model with English communities"></a>Bridge Diffusion Model: bridge non-English language-native text-to-image diffusion model with English communities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00952">http://arxiv.org/abs/2309.00952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanyuan Liu, Dawei Leng, Yuhui Yin</li>
<li>for: 本研究旨在提出一种能够兼顾非英语语言本土特征和英语TTI社区的新型模型结构，以解决英语世界中心训练数据带来的模型偏见问题。</li>
<li>methods: 该模型结构称为“桥接干扰模型”（BDM），具有脊梁支网络结构，能够同时学习非英语语言 semantics 和英语 TTI 社区的 latent space 兼容性。</li>
<li>results: 经验表明，BDM 可以不仅生成准确表达非英语语言 semantics 的图像，还可以与多种英语 TTI 插件相容，如不同的检查点、LoRA、ControlNet、Dreambooth 等等。此外，BDM 还可以同时生成 combine 非英语 native 和英语 native  semantics 的内容，促进文化交流。<details>
<summary>Abstract</summary>
Text-to-Image generation (TTI) technologies are advancing rapidly, especially in the English language communities. However, English-native TTI models inherently carry biases from English world centric training data, which creates a dilemma for development of other language-native TTI models. One common choice is fine-tuning the English-native TTI model with translated samples from non-English communities. It falls short of fully addressing the model bias problem. Alternatively, training non-English language native models from scratch can effectively resolve the English world bias, but diverges from the English TTI communities, thus not able to utilize the strides continuously gaining in the English TTI communities any more. To build non-English language native TTI model meanwhile keep compatability with the English TTI communities, we propose a novel model structure referred as "Bridge Diffusion Model" (BDM). The proposed BDM employs a backbone-branch network structure to learn the non-English language semantics while keep the latent space compatible with the English-native TTI backbone, in an end-to-end manner. The unique advantages of the proposed BDM are that it's not only adept at generating images that precisely depict non-English language semantics, but also compatible with various English-native TTI plugins, such as different checkpoints, LoRA, ControlNet, Dreambooth, and Textual Inversion, etc. Moreover, BDM can concurrently generate content seamlessly combining both non-English native and English-native semantics within a single image, fostering cultural interaction. We verify our method by applying BDM to build a Chinese-native TTI model, whereas the method is generic and applicable to any other language.
</details>
<details>
<summary>摘要</summary>
文本到图像生成（TTI）技术在英语社区中进步快速，但英语原生TTI模型带有英语世界中心训练数据的偏见问题。一种常见的选择是使用翻译后的非英语样本来微调英语原生TTI模型，但这并不能完全解决模型偏见问题。 Alternatively, 从scratch来训练非英语语言原生TTI模型可以有效解决英语世界偏见问题，但是这会与英语TTI社区分离，无法再利用英语TTI社区的成果。为建立非英语语言原生TTI模型，同时保持与英语TTI社区的兼容性，我们提出了一种新的模型结构， referred to as "Bridge Diffusion Model" (BDM)。我们的提议的BDM模型采用了后脊架-分支网络结构，通过练习非英语语言 semantics 来学习非英语语言 semantics，并保持与英语原生TTI脊架兼容的粒子空间，从而实现了端到端的学习。BDM模型具有以下优点：一是能够准确地描述非英语语言 semantics，二是可以与英语原生TTI插件（如不同的检查点、LoRA、ControlNet、Dreambooth、Textual Inversion等）兼容，三是能够同时生成 combining both non-English native and English-native semantics within a single image，激发文化交流。我们验证了我们的方法，通过应用BDM模型来建立一个中文原生TTI模型，而这种方法是通用的，可以应用于任何其他语言。
</details></li>
</ul>
<hr>
<h2 id="From-Specific-to-Generic-Learned-Sorted-Set-Dictionaries-A-Theoretically-Sound-Paradigm-Yelding-Competitive-Data-Structural-Boosters-in-Practice"><a href="#From-Specific-to-Generic-Learned-Sorted-Set-Dictionaries-A-Theoretically-Sound-Paradigm-Yelding-Competitive-Data-Structural-Boosters-in-Practice" class="headerlink" title="From Specific to Generic Learned Sorted Set Dictionaries: A Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in Practice"></a>From Specific to Generic Learned Sorted Set Dictionaries: A Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in Practice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00946">http://arxiv.org/abs/2309.00946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/globosco/An-implementation-of-Generic-Learned-Static-Sorted-Sets-Dictionaries">https://github.com/globosco/An-implementation-of-Generic-Learned-Static-Sorted-Sets-Dictionaries</a></li>
<li>paper_authors: Domenico Amato, Giosué Lo Bosco, Raffaele Giancarlo</li>
<li>for: 这项研究关注学习数据结构，即机器学习和经典数据结构的交叉领域中的新领域。它有方法学上的重要性和实践上的强大影响。</li>
<li>methods: 我们专注于学习排序字典，即学习排序集合。现有的提议都是特定的，它们可以提高表格搜索过程的时间性能，但只适用于排序的布局，如二分搜索。我们提出了一新的方法，可以补充现有的专门方法，将任何排序集合转化为学习版本。</li>
<li>results: 我们 obtiained several interesting results，包括（a）首个学习优质二分搜索森林，其 mean access time bounded by  Entropy 的概率分布下的访问 Dictionary。（b）首个学习排序集合，在动态情况下，在权衡分析设置下，与经典字典匹配的时间上限。这后者在广泛接受的宇宙大小下。实验部分，软件开发相对复杂，显示了非常有趣的发现，即我们的总结可以生成有效竞争力的学习数据结构加速器，即使与特定的benchmark模型相比。<details>
<summary>Abstract</summary>
This research concerns Learned Data Structures, a recent area that has emerged at the crossroad of Machine Learning and Classic Data Structures. It is methodologically important and with a high practical impact. We focus on Learned Indexes, i.e., Learned Sorted Set Dictionaries. The proposals available so far are specific in the sense that they can boost, indeed impressively, the time performance of Table Search Procedures with a sorted layout only, e.g., Binary Search. We propose a novel paradigm that, complementing known specialized ones, can produce Learned versions of any Sorted Set Dictionary, for instance, Balanced Binary Search Trees or Binary Search on layouts other that sorted, i.e., Eytzinger. Theoretically, based on it, we obtain several results of interest, such as (a) the first Learned Optimum Binary Search Forest, with mean access time bounded by the Entropy of the probability distribution of the accesses to the Dictionary; (b) the first Learned Sorted Set Dictionary that, in the Dynamic Case and in an amortized analysis setting, matches the same time bounds known for Classic Dictionaries. This latter under widely accepted assumptions regarding the size of the Universe. The experimental part, somewhat complex in terms of software development, clearly indicates the nonobvious finding that the generalization we propose can yield effective and competitive Learned Data Structural Booster, even with respect to specific benchmark models.
</details>
<details>
<summary>摘要</summary>
Theoretically, we obtain several interesting results based on this paradigm. For example, we develop the first learned optimum binary search forest, with a mean access time bounded by the entropy of the probability distribution of the accesses to the dictionary. Additionally, we create the first learned sorted set dictionary that, in the dynamic case and in an amortized analysis setting, matches the same time bounds as classic dictionaries, under widely accepted assumptions about the size of the universe.The experimental part of our research, which involved complex software development, surprisingly found that our generalization can yield effective and competitive learned data structural boosters, even compared to specific benchmark models.
</details></li>
</ul>
<hr>
<h2 id="Pressmatch-Automated-journalist-recommendation-for-media-coverage-with-Nearest-Neighbor-search"><a href="#Pressmatch-Automated-journalist-recommendation-for-media-coverage-with-Nearest-Neighbor-search" class="headerlink" title="Pressmatch: Automated journalist recommendation for media coverage with Nearest Neighbor search"></a>Pressmatch: Automated journalist recommendation for media coverage with Nearest Neighbor search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00944">http://arxiv.org/abs/2309.00944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumya Parekh, Jay Patel</li>
<li>for: 这个研究旨在帮助公司发布产品时更好地推广和获得媒体推广，以增加产品的普及度和观众的互动。</li>
<li>methods: 这个研究使用自然语言处理和机器学习技术，推荐适合产品新闻发布的记者，以减少公司需要运作媒体联系和筛选记者的时间和努力。</li>
<li>results: 这借研究发现，使用自然语言处理和机器学习技术可以快速和准确地推荐适合产品新闻发布的记者，从而提高公司发布产品的媒体推广效果。<details>
<summary>Abstract</summary>
Slating a product for release often involves pitching journalists to run stories on your press release. Good media coverage often ensures greater product reach and drives audience engagement for those products. Hence, ensuring that those releases are pitched to the right journalists with relevant interests is crucial, since they receive several pitches daily. Keeping up with journalist beats and curating a media contacts list is often a huge and time-consuming task. This study proposes a model to automate and expedite the process by recommending suitable journalists to run media coverage on the press releases provided by the user.
</details>
<details>
<summary>摘要</summary>
平时发布产品 often involves pitching 新闻工作者来讲述产品的新闻稿。好的媒体报道通常会提高产品的报道覆盖率和驱动产品的听众参与度。因此，确保向正确的新闻工作者发送 pitches 是非常重要的，因为他们每天收到很多 pitches。维护新闻工作者的 beat 和建立媒体联系人名单可以是一项巨大和耗时的任务。这个研究提出了一个模型，用于自动化和加速这个过程，并对用户提供的新闻稿进行推荐适合的新闻工作者。
</details></li>
</ul>
<hr>
<h2 id="Content-Prompting-Modeling-Content-Provider-Dynamics-to-Improve-User-Welfare-in-Recommender-Ecosystems"><a href="#Content-Prompting-Modeling-Content-Provider-Dynamics-to-Improve-User-Welfare-in-Recommender-Ecosystems" class="headerlink" title="Content Prompting: Modeling Content Provider Dynamics to Improve User Welfare in Recommender Ecosystems"></a>Content Prompting: Modeling Content Provider Dynamics to Improve User Welfare in Recommender Ecosystems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00940">http://arxiv.org/abs/2309.00940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddharth Prasad, Martin Mladenov, Craig Boutilier</li>
<li>for: 这篇论文旨在解决信息不均衡问题，帮助内容提供者更好地了解用户需求，并适应用户需求提供内容。</li>
<li>methods: 该论文采用了提示策略，即向内容提供者提供启示或建议，以便他们可以提供满足用户需求的新内容。同时，论文还提出了一种Sequential Prompting Policy，即在提供者的信念、技能和激励下采取一系列的提示策略。</li>
<li>results: 论文通过一种抽象模型和数学分析，证明了这种提示策略可以优化用户社会利益，同时尊重提供者的激励。此外，论文还通过简单的实验证明了这种策略可以提高生态系统的健康度和用户满意度。<details>
<summary>Abstract</summary>
Users derive value from a recommender system (RS) only to the extent that it is able to surface content (or items) that meet their needs/preferences. While RSs often have a comprehensive view of user preferences across the entire user base, content providers, by contrast, generally have only a local view of the preferences of users that have interacted with their content. This limits a provider's ability to offer new content to best serve the broader population. In this work, we tackle this information asymmetry with content prompting policies. A content prompt is a hint or suggestion to a provider to make available novel content for which the RS predicts unmet user demand. A prompting policy is a sequence of such prompts that is responsive to the dynamics of a provider's beliefs, skills and incentives. We aim to determine a joint prompting policy that induces a set of providers to make content available that optimizes user social welfare in equilibrium, while respecting the incentives of the providers themselves. Our contributions include: (i) an abstract model of the RS ecosystem, including content provider behaviors, that supports such prompting; (ii) the design and theoretical analysis of sequential prompting policies for individual providers; (iii) a mixed integer programming formulation for optimal joint prompting using path planning in content space; and (iv) simple, proof-of-concept experiments illustrating how such policies improve ecosystem health and user welfare.
</details>
<details>
<summary>摘要</summary>
用户只有在推荐系统（RS）能够浮现符合他们需求和偏好的内容时，才能获得价值。而RS通常有用户基本库的全面视图，而内容提供者只有与他们内容的用户交互的本地视图。这限制了提供者对整个人口的新内容供应的能力。在这种情况下，我们使用内容提醒策略来缓解信息不均衡。内容提醒是一个提醒或建议，让提供者为RS预测的用户需求而提供新的内容。提醒策略是一个针对提供者的信念、技能和利益的回应序列。我们的目标是找到一个共同的提醒策略，使提供者在均衡下为用户社会福祉产生最佳内容，同时尊重提供者自己的利益。我们的贡献包括：1. RS生态系统抽象模型，包括内容提供者行为，支持内容提醒策略。2. 针对个体提供者的sequential提醒策略的设计和理论分析。3. 内容空间探索路径规划法，用于优化共同提醒策略。4. 简单的证明性实验，说明如何实施内容提醒策略，提高生态系统健康和用户福祉。
</details></li>
</ul>
<hr>
<h2 id="Deep-supervised-hashing-for-fast-retrieval-of-radio-image-cubes"><a href="#Deep-supervised-hashing-for-fast-retrieval-of-radio-image-cubes" class="headerlink" title="Deep supervised hashing for fast retrieval of radio image cubes"></a>Deep supervised hashing for fast retrieval of radio image cubes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00932">http://arxiv.org/abs/2309.00932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Ndung’u, Trienko Grobler, Stefan J. Wijnholds, Dimka Karastoyanova, George Azzopardi</li>
<li>for:  Next-generation radio surveys will result in a large number of serendipitous discoveries, and deep hashing algorithms can be used to efficiently search and retrieve similar images in a large database.</li>
<li>methods:  The paper uses deep hashing algorithms for image retrieval tasks in astronomy, specifically using the Hamming distance between the binary hash of the query image and those of the reference images in the database.</li>
<li>results:  The experimental results achieved a precision of 88.5% using the mean average precision (mAP) metric, demonstrating the capability to search and retrieve similar radio images efficiently and at scale.<details>
<summary>Abstract</summary>
The shear number of sources that will be detected by next-generation radio surveys will be astronomical, which will result in serendipitous discoveries. Data-dependent deep hashing algorithms have been shown to be efficient at image retrieval tasks in the fields of computer vision and multimedia. However, there are limited applications of these methodologies in the field of astronomy. In this work, we utilize deep hashing to rapidly search for similar images in a large database. The experiment uses a balanced dataset of 2708 samples consisting of four classes: Compact, FRI, FRII, and Bent. The performance of the method was evaluated using the mean average precision (mAP) metric where a precision of 88.5\% was achieved. The experimental results demonstrate the capability to search and retrieve similar radio images efficiently and at scale. The retrieval is based on the Hamming distance between the binary hash of the query image and those of the reference images in the database.
</details>
<details>
<summary>摘要</summary>
“Future radio surveys will detect an enormous number of sources, leading to unexpected discoveries. Deep hashing algorithms have been proven efficient in image retrieval tasks in computer vision and multimedia, but their applications in astronomy are limited. In this study, we utilize deep hashing to quickly search for similar images in a large database. The experiment uses a balanced dataset of 2708 samples, including four classes: Compact, FRI, FRII, and Bent. The performance of the method was evaluated using the mean average precision (mAP) metric, achieving a precision of 88.5%. The results demonstrate the ability to efficiently search and retrieve similar radio images at scale, based on the Hamming distance between the binary hash of the query image and those of the reference images in the database.”Here's the breakdown of the translation:* "shear number" 的 Simplified Chinese translation is "巨大的数量" (jùdà de shùliàng)* "next-generation radio surveys" 的 Simplified Chinese translation is "次代 радио探测" (cìdài ràdìo tàncè)* "serendipitous discoveries" 的 Simplified Chinese translation is "偶然发现" (òujiān fāxìan)* "data-dependent deep hashing algorithms" 的 Simplified Chinese translation is "基于数据的深度哈希算法" (jīyú shuòyǔ de shēngrán hǎixī算法)* "computer vision and multimedia" 的 Simplified Chinese translation is "计算机视觉和多媒体" (jìsuànjī zhìguān yǔ duōmédiā)* "limited applications in astronomy" 的 Simplified Chinese translation is "在天文学中的应用受限" (zài tiānwén xué zhī yǐ jí)* "utilize deep hashing to rapidly search for similar images" 的 Simplified Chinese translation is "使用深度哈希快速搜索相似图像" (shǐyòu shēngrán hǎixī suōsòu xiàngsi túxìng)* "balanced dataset of 2708 samples" 的 Simplified Chinese translation is "2708个样本的均衡数据集" (2708 ge yàngbèi de jìngbìng shùliàng)* "four classes: Compact, FRI, FRII, and Bent" 的 Simplified Chinese translation is "四类：紧凑、FRI、FRII、拐型" (sì lèi: jǐnchōng, FRI, FRII, gōngyì)* "mean average precision (mAP) metric" 的 Simplified Chinese translation is "平均精度 (mAP) 指标" (píngjìn jīngdé (mAP) zhǐbǐ)* "achieving a precision of 88.5%" 的 Simplified Chinese translation is "达到88.5%的精度" (dàtuō 88.5% de jīngdé)* "the retrieval is based on the Hamming distance between the binary hash of the query image and those of the reference images in the database" 的 Simplified Chinese translation is "搜索基于图像查询图像的二进制哈希距离" (suōsòu jīyú túxìng túxìng de èrjìn bìngxī hǎixī yuèlü)
</details></li>
</ul>
<hr>
<h2 id="Studying-the-impacts-of-pre-training-using-ChatGPT-generated-text-on-downstream-tasks"><a href="#Studying-the-impacts-of-pre-training-using-ChatGPT-generated-text-on-downstream-tasks" class="headerlink" title="Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks"></a>Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05668">http://arxiv.org/abs/2309.05668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarthak Anand</li>
<li>for: 本研究的目的是调查人工文本在语言模型预训练阶段的影响。</li>
<li>methods: 我们使用了RoBERTa和ChatGPT两个语言模型，对这两个模型进行了比较分析，并对其在三个下游任务中的表现进行评估，同时也对模型的性别偏见进行了评估。</li>
<li>results: 我们的实验结果表明，在预训练阶段使用人工文本不会对语言模型在下游任务中的表现产生显著影响，也不会导致模型的性别偏见增加。<details>
<summary>Abstract</summary>
In recent times, significant advancements have been witnessed in the field of language models, particularly with the emergence of Large Language Models (LLMs) that are trained on vast amounts of data extracted from internet archives. These LLMs, such as ChatGPT, have become widely accessible, allowing users to generate text for various purposes including articles, essays, jokes, and poetry. Given that LLMs are trained on a diverse range of text sources, encompassing platforms like Reddit and Twitter, it is foreseeable that future training datasets will also incorporate text generated by previous iterations of the models themselves. In light of this development, our research aims to investigate the influence of artificial text in the pre-training phase of language models. Specifically, we conducted a comparative analysis between a language model, RoBERTa, pre-trained using CNN/DailyMail news articles, and ChatGPT, which employed the same articles for its training and evaluated their performance on three downstream tasks as well as their potential gender bias, using sentiment analysis as a metric. Through a series of experiments, we demonstrate that the utilization of artificial text during pre-training does not have a significant impact on either the performance of the models in downstream tasks or their gender bias. In conclusion, our findings suggest that the inclusion of text generated by LLMs in their own pre-training process does not yield substantial effects on the subsequent performance of the models in downstream tasks or their potential gender bias.
</details>
<details>
<summary>摘要</summary>
In light of this development, our research aims to investigate the influence of artificial text in the pre-training phase of language models. Specifically, we conducted a comparative analysis between a language model, RoBERTa, pre-trained using CNN/DailyMail news articles, and ChatGPT, which employed the same articles for its training, and evaluated their performance on three downstream tasks as well as their potential gender bias, using sentiment analysis as a metric.Through a series of experiments, we found that the utilization of artificial text during pre-training does not have a significant impact on either the performance of the models in downstream tasks or their gender bias. In conclusion, our findings suggest that the inclusion of text generated by LLMs in their own pre-training process does not yield substantial effects on the subsequent performance of the models in downstream tasks or their potential gender bias.
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Graph-Embeddings-for-Multi-Lingual-Structured-Representations-of-Radiology-Reports"><a href="#Knowledge-Graph-Embeddings-for-Multi-Lingual-Structured-Representations-of-Radiology-Reports" class="headerlink" title="Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports"></a>Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00917">http://arxiv.org/abs/2309.00917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tjvsonsbeek/knowledge_graphs_for_radiology_reports">https://github.com/tjvsonsbeek/knowledge_graphs_for_radiology_reports</a></li>
<li>paper_authors: Tom van Sonsbeek, Xiantong Zhen, Marcel Worring</li>
<li>for: 这个研究旨在开发一个轻量级的图形基于嵌入方法，以便更好地理解并分析医疗报告。</li>
<li>methods: 这个方法利用医疗报告的结构和成分，并与多种语言的医疗词汇知识库（SNOMED CT）进行连结。从而生成一个具有更好的理解和跨语言传递能力的图形嵌入。</li>
<li>results: 研究表明，这个图形嵌入可以更好地捕捉医疗报告中的关系性，并且在疾病分类和影像分类任务中表现出色，比BERT模型更好，且具有较小的模型大小和训练数据需求。此外，这个方法还可以跨语言进行应用。<details>
<summary>Abstract</summary>
The way we analyse clinical texts has undergone major changes over the last years. The introduction of language models such as BERT led to adaptations for the (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on large databases of archived medical documents. While performing well in terms of accuracy, both the lack of interpretability and limitations to transfer across languages limit their use in clinical setting. We introduce a novel light-weight graph-based embedding method specifically catering radiology reports. It takes into account the structure and composition of the report, while also connecting medical terms in the report through the multi-lingual SNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers the underlying relationships among clinical terms, achieving a representation that is better understandable for clinicians and clinically more accurate, without reliance on large pre-training datasets. We show the use of this embedding on two tasks namely disease classification of X-ray reports and image classification. For disease classification our model is competitive with its BERT-based counterparts, while being magnitudes smaller in size and training data requirements. For image classification, we show the effectiveness of the graph embedding leveraging cross-modal knowledge transfer and show how this method is usable across different languages.
</details>
<details>
<summary>摘要</summary>
医学文本分析方法在最近几年内经历了重大变革。BERT语言模型的引入对医学领域的PubMedBERT和ClinicalBERT进行了适应。这些模型依靠大量储存的医学文献库。虽然在准确性方面表现良好，但lack of interpretability和语言转移限制使其在临床设置中无法使用。我们介绍了一种新的轻量级图 embedding方法，专门针对医学报告。该方法考虑报告的结构和组成，同时通过多语言的SNOMED临床术语知识库连接医学术语。得到的图 embedding揭示了临床术语之间的下面关系，实现了更好的可读性和临床准确性，不需要大量的预训练数据。我们在疾病分类和图像分类两个任务上使用了这种embedding，并证明了它的效果。在疾病分类任务中，我们的模型与BERT基于模型相比竞争，而且它的大小和训练数据要求都比BERT要小得多。在图像分类任务中，我们利用了图 embedding在不同语言之间的交叉模式知识传递，并证明了这种方法在不同语言上的可用性。
</details></li>
</ul>
<hr>
<h2 id="A-3D-explainability-framework-to-uncover-learning-patterns-and-crucial-sub-regions-in-variable-sulci-recognition"><a href="#A-3D-explainability-framework-to-uncover-learning-patterns-and-crucial-sub-regions-in-variable-sulci-recognition" class="headerlink" title="A 3D explainability framework to uncover learning patterns and crucial sub-regions in variable sulci recognition"></a>A 3D explainability framework to uncover learning patterns and crucial sub-regions in variable sulci recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00903">http://arxiv.org/abs/2309.00903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michail Mamalakis, Heloise de Vareilles, Atheer AI-Manea, Samantha C. Mitchell, Ingrid Arartz, Lynn Egeland Morch-Johnsen, Jane Garrison, Jon Simons, Pietro Lio, John Suckling, Graham Murray</li>
<li>for: 本研究旨在提高人脑MRI图像中的皮层 Sulcal 特征的准确性，以及深度学习网络的解释能力。</li>
<li>methods: 该研究使用了一种新的3D解释框架，将本地解释技术GradCam和SHAP综合使用，并结合维度减少方法。该解释框架为深度学习网络提供了本地和全局的解释，以及类别结果的准确性。</li>
<li>results: 研究发现，在使用TOP-OSLO dataset中的MRI图像中，左半球比右半球更有可能正确地检测皮层 Sulcus（存在或不存在），并且发现了特定但广泛的子区域对每个类别结果做出了重要贡献。此外，研究还启示了不偏袋注意力的注意事项对网络性能的影响。该方法不仅提供了自动化、公正的皮层 Sulcus annotations，还为脑科学领域的进一步探索和调查提供了新的思路。<details>
<summary>Abstract</summary>
Precisely identifying sulcal features in brain MRI is made challenging by the variability of brain folding. This research introduces an innovative 3D explainability frame-work that validates outputs from deep learning networks in their ability to detect the paracingulate sulcus, an anatomical feature that may or may not be present on the frontal medial surface of the human brain. This study trained and tested two networks, amalgamating local explainability techniques GradCam and SHAP with a dimensionality reduction method. The explainability framework provided both localized and global explanations, along with accuracy of classification results, revealing pertinent sub-regions contributing to the decision process through a post-fusion transformation of explanatory and statistical features. Leveraging the TOP-OSLO dataset of MRI acquired from patients with schizophrenia, greater accuracies of paracingulate sulcus detection (presence or absence) were found in the left compared to right hemispheres with distinct, but extensive sub-regions contributing to each classification outcome. The study also inadvertently highlighted the critical role of an unbiased annotation protocol in maintaining network performance fairness. Our proposed method not only offers automated, impartial annotations of a variable sulcus but also provides insights into the broader anatomical variations associated with its presence throughout the brain. The adoption of this methodology holds promise for instigating further explorations and inquiries in the field of neuroscience.
</details>
<details>
<summary>摘要</summary>
通过准确地识别大脑磁共振图像中的 Sulcal 特征，这种研究推出了一个创新的3D解释框架。该框架验证了深度学习网络的输出是否能够检测人脑前 медиаль面上的 paracingulate sulcus，这是一个可能或可能不存在的 анатомиче特征。本研究用了两个网络，其中一个是 GradCam 和 SHAP 的 мест解释技术，另一个是一种维度减少方法。该解释框架提供了 both localized 和 global 解释，以及分类结果的准确性，揭示了在决策过程中重要的相关子区域。使用 TOP-OSLO 数据集，该研究发现在左半球比右半球更高的准确率检测 paracingulate sulcus（存在或缺失）。此外，研究还意外地发现了在左半球和右半球之间的区域差异对于每个分类结果的重要性。此方法不仅提供了自动化、不偏的 sulcus Variable 的注释，还为其存在的各个部分提供了深入的解释。该方法的采用拥有推动更多的 Neuroscience 领域的探索和问题。
</details></li>
</ul>
<hr>
<h2 id="Large-Process-Models-Business-Process-Management-in-the-Age-of-Generative-AI"><a href="#Large-Process-Models-Business-Process-Management-in-the-Age-of-Generative-AI" class="headerlink" title="Large Process Models: Business Process Management in the Age of Generative AI"></a>Large Process Models: Business Process Management in the Age of Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00900">http://arxiv.org/abs/2309.00900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timotheus Kampik, Christian Warmuth, Adrian Rebmann, Ron Agam, Lukas N. P. Egger, Andreas Gerber, Johannes Hoffart, Jonas Kolk, Philipp Herzig, Gero Decker, Han van der Aa, Artem Polyvyanyy, Stefanie Rinderle-Ma, Ingo Weber, Matthias Weidlich</li>
<li>for: 这个论文是为了探讨基于大语言模型（LLM）和其他生成人工智能技术的潜在优势和局限性，以及如何结合这些技术以提高企业转型的效率和深度。</li>
<li>methods: 论文提出了一种基于大语言模型（LLM）和知识基本模型（KBM）的大过程模型（LPM），该模型结合了LLM的相关力和KBM的分析精度和可靠性，以提供更加Context-specific（适应）的过程和商业模型，深入分析和提供改进建议。</li>
<li>results: 论文认为，实施LPM可以减少企业转型所需的时间和努力，同时提供更加深入、更加有效和更加可行的业务转型建议，相比之下传统的 Symbolic 模型。然而，论文也提出了实施LPM的限制和研究挑战。<details>
<summary>Abstract</summary>
The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness. As a framework for contextualizing the potential, as well as the limitations of LLMs and other foundation model-based technologies, we propose the concept of a Large Process Model (LPM) that combines the correlation power of LLMs with the analytical precision and reliability of knowledge-based systems and automated reasoning approaches. LPMs are envisioned to directly utilize the wealth of process management experience that experts have accumulated, as well as process performance data of organizations with diverse characteristics, e.g., regarding size, region, or industry. In this vision, the proposed LPM would allow organizations to receive context-specific (tailored) process and other business models, analytical deep-dives, and improvement recommendations. As such, they would allow to substantially decrease the time and effort required for business transformation, while also allowing for deeper, more impactful, and more actionable insights than previously possible. We argue that implementing an LPM is feasible, but also highlight limitations and research challenges that need to be solved to implement particular aspects of the LPM vision.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）和其他生成人工智能方法的继续成功，强调了大量信息库对于固定符号模型的优势，但也 serves as a proof-point of 隐性和可靠性问题。作为 LLM 和其他基础模型技术的框架，我们提出了大量处理模型（LPM）的概念，该模型结合了 LLM 的相关力和知识基础系统和自动化推理方法的分析精度和可靠性。LPM 可以直接利用专家们积累的过程管理经验和不同特征的组织过程性能数据，例如大小、地区、行业等，以提供Context-specific（特定）的过程和商业模型、深入分析和改进建议。因此，LPM 可以减少企业转型所需的时间和努力，同时提供更深入、更有影响和更可行的发现。我们认为实施 LPM 是可能的，但也存在实现特定方面的限制和研究挑战。
</details></li>
</ul>
<hr>
<h2 id="Regularly-Truncated-M-estimators-for-Learning-with-Noisy-Labels"><a href="#Regularly-Truncated-M-estimators-for-Learning-with-Noisy-Labels" class="headerlink" title="Regularly Truncated M-estimators for Learning with Noisy Labels"></a>Regularly Truncated M-estimators for Learning with Noisy Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00894">http://arxiv.org/abs/2309.00894</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaoboxia/rtm_lnl">https://github.com/xiaoboxia/rtm_lnl</a></li>
<li>paper_authors: Xiaobo Xia, Pengqian Lu, Chen Gong, Bo Han, Jun Yu, Jun Yu, Tongliang Liu</li>
<li>for: 提高学习 WITH 噪音标签的精度和稳定性。</li>
<li>methods: 提出了一种名为Regularly Truncated M-estimators（RTME）的新方法，该方法可以同时解决两个问题：（a）不考虑噪音标签在选择小损失示例中的不良影响；（b）不利用抛弃大损失示例中的可能有用信息。</li>
<li>results: 理论上显示了方法的抗噪音特性，实验结果表明我们的方法可以超越多个基eline，并在各种噪音类型和水平下表现稳定和可靠。<details>
<summary>Abstract</summary>
The sample selection approach is very popular in learning with noisy labels. As deep networks learn pattern first, prior methods built on sample selection share a similar training procedure: the small-loss examples can be regarded as clean examples and used for helping generalization, while the large-loss examples are treated as mislabeled ones and excluded from network parameter updates. However, such a procedure is arguably debatable from two folds: (a) it does not consider the bad influence of noisy labels in selected small-loss examples; (b) it does not make good use of the discarded large-loss examples, which may be clean or have meaningful information for generalization. In this paper, we propose regularly truncated M-estimators (RTME) to address the above two issues simultaneously. Specifically, RTME can alternately switch modes between truncated M-estimators and original M-estimators. The former can adaptively select small-losses examples without knowing the noise rate and reduce the side-effects of noisy labels in them. The latter makes the possibly clean examples but with large losses involved to help generalization. Theoretically, we demonstrate that our strategies are label-noise-tolerant. Empirically, comprehensive experimental results show that our method can outperform multiple baselines and is robust to broad noise types and levels.
</details>
<details>
<summary>摘要</summary>
“ selección de muestras es muy popular en aprendizaje con etiquetas ruidosas. Como las redes profundas aprenden patrones primero, los métodos previos basados en selección de muestras comparten un procedimiento de entrenamiento similar: los ejemplos de pérdida pequeña pueden ser considerados como ejemplos limpios y utilizados para ayudar en la generalización, mientras que los ejemplos de pérdida grande son excluidos de actualizaciones de parámetros de la red. Sin embargo, tal procedimiento es objeto de debate desde dos ángulos: (a) no tiene en cuenta la mala influencia de las etiquetas ruidosas en los ejemplos de pérdida pequeña seleccionados; (b) no utiliza adecuadamente los ejemplos de pérdida grande descartados, que pueden ser limpios o tener información significativa para la generalización. En este artículo, propongo regularmente truncated M-estimators (RTME) para abordar los problemas anteriores de manera simultánea. De manera específica, RTME puede alternar entre modes de estimadores truncados y estimadores originales. Los primeros pueden adaptativamente seleccionar ejemplos de pérdida pequeña sin conocer la tasa de ruido y reducir los efectos colaterales de las etiquetas ruidosas en ellos. Los segundos involucran posibles ejemplos limpios pero con pérdidas grandes para ayudar en la generalización. Teóricamente, demostramos que nuestras estrategias son tolerantes al ruido de etiquetas. Empíricamente, resultados exhaustivos y robustos muestran que nuestro método puede superar multiple baselines y es resistente a tipos y niveles de ruido de etiquetas amplios.”
</details></li>
</ul>
<hr>
<h2 id="Equitable-FL-Federated-Learning-with-Sparsity-for-Resource-Constrained-Environment"><a href="#Equitable-FL-Federated-Learning-with-Sparsity-for-Resource-Constrained-Environment" class="headerlink" title="Equitable-FL: Federated Learning with Sparsity for Resource-Constrained Environment"></a>Equitable-FL: Federated Learning with Sparsity for Resource-Constrained Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00864">http://arxiv.org/abs/2309.00864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indrajeet Kumar Sinha, Shekhar Verma, Krishna Pratap Singh</li>
<li>for: 该论文旨在提出一种适用于有限资源环境的联合学习方法，以便在客户端缺乏资源时仍可进行学习。</li>
<li>methods: 该方法基于lottery ticket假设，逐渐减少模型参数数量，以鼓励有限资源的客户端参与联合学习。</li>
<li>results: 实验结果表明，该方法可以在不同的数据集和环境下减少模型大小，同时保持模型的准确性，并且可以适应不同的客户端资源具有不同的缺省值。<details>
<summary>Abstract</summary>
In Federated Learning, model training is performed across multiple computing devices, where only parameters are shared with a common central server without exchanging their data instances. This strategy assumes abundance of resources on individual clients and utilizes these resources to build a richer model as user's models. However, when the assumption of the abundance of resources is violated, learning may not be possible as some nodes may not be able to participate in the process. In this paper, we propose a sparse form of federated learning that performs well in a Resource Constrained Environment. Our goal is to make learning possible, regardless of a node's space, computing, or bandwidth scarcity. The method is based on the observation that model size viz a viz available resources defines resource scarcity, which entails that reduction of the number of parameters without affecting accuracy is key to model training in a resource-constrained environment. In this work, the Lottery Ticket Hypothesis approach is utilized to progressively sparsify models to encourage nodes with resource scarcity to participate in collaborative training. We validate Equitable-FL on the $MNIST$, $F-MNIST$, and $CIFAR-10$ benchmark datasets, as well as the $Brain-MRI$ data and the $PlantVillage$ datasets. Further, we examine the effect of sparsity on performance, model size compaction, and speed-up for training. Results obtained from experiments performed for training convolutional neural networks validate the efficacy of Equitable-FL in heterogeneous resource-constrained learning environment.
</details>
<details>
<summary>摘要</summary>
在联合学习中，模型训练在多个计算设备之间进行，只是共享参数而不是数据实例。这种策略假设每个客户端都有充足的资源，并利用这些资源建立更加丰富的模型。然而，当假设丰富资源的假设不成立时，学习可能无法进行，因为一些节点可能无法参与过程中。在这篇论文中，我们提出了一种缺省形式的联合学习方法，可以在资源受限环境中进行学习。我们的目标是让学习无论节点的空间、计算或带宽scarce都可以进行。该方法基于参数数量与可用资源的关系，即模型大小与可用资源的定义资源缺乏问题。在这种情况下，我们采用了抽奖票假设方法，以逐步减少模型参数，以鼓励有资源缺乏的节点参与合作训练。我们在$MNIST$, $F-MNIST$, $CIFAR-10$benchmark数据集和$Brain-MRI$数据集以及$PlantVillage$数据集进行了验证。此外，我们还研究了缺省对性能、模型大小压缩和训练速度的影响。实验结果表明，Equitable-FL在多种不同资源环境下进行联合学习时具有有效性。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalization-via-Balancing-Training-Difficulty-and-Model-Capability"><a href="#Domain-Generalization-via-Balancing-Training-Difficulty-and-Model-Capability" class="headerlink" title="Domain Generalization via Balancing Training Difficulty and Model Capability"></a>Domain Generalization via Balancing Training Difficulty and Model Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00844">http://arxiv.org/abs/2309.00844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xueying Jiang, Jiaxing Huang, Sheng Jin, Shijian Lu</li>
<li>for: 这个研究旨在为 domain generalization (DG) 学习一个可以在未知目标领域中表现良好的模型，并且解决了训练过程中模型和样本的对错问题。</li>
<li>methods: 这个研究使用了两个新的设计，即 MoDify-based Data Augmentation 和 MoDify-based Network Optimization，它们协力地对抗了训练过程中的对错问题，以获得更好的预测性。</li>
<li>results: 这个研究获得了多个 benchark 上的 superior performance，并且可以与现有的方法整合，并且可以在不同的视觉识别任务中使用。<details>
<summary>Abstract</summary>
Domain generalization (DG) aims to learn domain-generalizable models from one or multiple source domains that can perform well in unseen target domains. Despite its recent progress, most existing work suffers from the misalignment between the difficulty level of training samples and the capability of contemporarily trained models, leading to over-fitting or under-fitting in the trained generalization model. We design MoDify, a Momentum Difficulty framework that tackles the misalignment by balancing the seesaw between the model's capability and the samples' difficulties along the training process. MoDify consists of two novel designs that collaborate to fight against the misalignment while learning domain-generalizable models. The first is MoDify-based Data Augmentation which exploits an RGB Shuffle technique to generate difficulty-aware training samples on the fly. The second is MoDify-based Network Optimization which dynamically schedules the training samples for balanced and smooth learning with appropriate difficulty. Without bells and whistles, a simple implementation of MoDify achieves superior performance across multiple benchmarks. In addition, MoDify can complement existing methods as a plug-in, and it is generic and can work for different visual recognition tasks.
</details>
<details>
<summary>摘要</summary>
域名泛化（DG）目标是从一个或多个源领域学习到能够在未看过的目标领域表现好的模型。虽然最近得到了进步，但大多数现有的工作受到模型在训练过程中样本难度与模型能力的不同而受到偏移，导致过拟合或者下降在训练的泛化模型。我们提出了MoDify，一个带动力度的框架，解决这个问题。MoDify包括两个新的设计，协作以适应不同难度水平的样本，从训练过程中学习域名泛化模型。首先是MoDify基于数据增强的设计，利用RGB混淆技术在训练过程中生成适度考虑的训练样本。其次是MoDify基于网络优化的设计，通过动态安排训练样本来保持平稳的学习，适应不同难度水平。无需辉煌的简单实现，MoDify可以在多个 benchmark 上 achieve 优秀表现。此外，MoDify可以补充现有方法，作为插件，并且可以对不同的视觉识别任务进行应用。
</details></li>
</ul>
<hr>
<h2 id="LeanContext-Cost-Efficient-Domain-Specific-Question-Answering-Using-LLMs"><a href="#LeanContext-Cost-Efficient-Domain-Specific-Question-Answering-Using-LLMs" class="headerlink" title="LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs"></a>LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00841">http://arxiv.org/abs/2309.00841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Adnan Arefeen, Biplob Debnath, Srimat Chakradhar</li>
<li>for: 本研究旨在提高小型企业对大语言模型（LLM）的应用，以提高聊天机器人的能力。</li>
<li>methods: 本研究使用leansContext方法，该方法可以快速提取适用于查询的$k$个关键句。</li>
<li>results: 与基eline相比，leansContext方法可以减少Context的成本，同时保持ROUGE-1分数的稳定性。如果使用免费预训练的LLM-基于摘要器，leansContext还可以进一步提高准确性。<details>
<summary>Abstract</summary>
Question-answering (QA) is a significant application of Large Language Models (LLMs), shaping chatbot capabilities across healthcare, education, and customer service. However, widespread LLM integration presents a challenge for small businesses due to the high expenses of LLM API usage. Costs rise rapidly when domain-specific data (context) is used alongside queries for accurate domain-specific LLM responses. One option is to summarize the context by using LLMs and reduce the context. However, this can also filter out useful information that is necessary to answer some domain-specific queries. In this paper, we shift from human-oriented summarizers to AI model-friendly summaries. Our approach, LeanContext, efficiently extracts $k$ key sentences from the context that are closely aligned with the query. The choice of $k$ is neither static nor random; we introduce a reinforcement learning technique that dynamically determines $k$ based on the query and context. The rest of the less important sentences are reduced using a free open source text reduction method. We evaluate LeanContext against several recent query-aware and query-unaware context reduction approaches on prominent datasets (arxiv papers and BBC news articles). Despite cost reductions of $37.29\%$ to $67.81\%$, LeanContext's ROUGE-1 score decreases only by $1.41\%$ to $2.65\%$ compared to a baseline that retains the entire context (no summarization). Additionally, if free pretrained LLM-based summarizers are used to reduce context (into human consumable summaries), LeanContext can further modify the reduced context to enhance the accuracy (ROUGE-1 score) by $13.22\%$ to $24.61\%$.
</details>
<details>
<summary>摘要</summary>
帮助机器人回答问题（Question-answering，QA）是大型自然语言模型（Large Language Models，LLMs）的重要应用，涵盖医疗、教育和客户服务等领域。然而，广泛的 LLM 集成对小型企业而言是一大挑战，因为 LLM API 使用成本高涨。当用于精度的域pecific数据（context）时，成本会快速增加。一种选择是使用 LLM  SUMMARIZE Context，从而减少context。然而，这也可能会过滤出一些具有响应域pecific queries 的有用信息。在这篇论文中，我们弃用人类SUMMARIZER，转而使用 AI 模型友好的SUMMARY。我们的方法LeanContext，高效地提取了 $k$ 个关键句子，与查询高度相关。 $k$ 的选择不是静态也不是随机的，我们引入了一种强化学习技术，动态确定 $k$ 基于查询和 context。剩下的部分使用一种免费开源的文本减少方法减少。我们对多个最新的查询 aware 和查询无关的context减少方法进行评估，并发现LeanContext可以在成本下降 $37.29\%$ 到 $67.81\%$ 的情况下，ROUGE-1 分数下降只有 $1.41\%$ 到 $2.65\%$ 相比于基线（无 summarization）。此外，如果使用免费预训练 LLM 基于 SUMMARIZER 减少 context（转换为人类可读的摘要），LeanContext 可以进一步修改减少后的 context，提高精度（ROUGE-1 分数） by $13.22\%$ 到 $24.61\%$。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Semi-Supervised-Graph-Learning-for-Enhanced-Diabetic-Retinopathy-Detection"><a href="#Leveraging-Semi-Supervised-Graph-Learning-for-Enhanced-Diabetic-Retinopathy-Detection" class="headerlink" title="Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic Retinopathy Detection"></a>Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic Retinopathy Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00824">http://arxiv.org/abs/2309.00824</a></li>
<li>repo_url: None</li>
<li>paper_authors: D. Dhinakaran, L. Srinivasan, D. Selvaraj, S. M. Udhaya Sankar</li>
<li>for: 这项研究旨在提高 диабетичеRetinopathy（DR）的早期检测和治疗，使用机器学习（ML）技术。</li>
<li>methods: 该研究提出了一种新的半监督图像学习（SSGL）算法，利用标注和无标注数据之间的关系来提高准确性。</li>
<li>results: 研究表明，该算法可以在两个公共可用的数据集上获得显著改进的分类精度、特异性和敏感性，并且具有鲁棒性 against 噪音和异常值。<details>
<summary>Abstract</summary>
Diabetic Retinopathy (DR) is a significant cause of blindness globally, highlighting the urgent need for early detection and effective treatment. Recent advancements in Machine Learning (ML) techniques have shown promise in DR detection, but the availability of labeled data often limits their performance. This research proposes a novel Semi-Supervised Graph Learning SSGL algorithm tailored for DR detection, which capitalizes on the relationships between labelled and unlabeled data to enhance accuracy. The work begins by investigating data augmentation and preprocessing techniques to address the challenges of image quality and feature variations. Techniques such as image cropping, resizing, contrast adjustment, normalization, and data augmentation are explored to optimize feature extraction and improve the overall quality of retinal images. Moreover, apart from detection and diagnosis, this work delves into applying ML algorithms for predicting the risk of developing DR or the likelihood of disease progression. Personalized risk scores for individual patients are generated using comprehensive patient data encompassing demographic information, medical history, and retinal images. The proposed Semi-Supervised Graph learning algorithm is rigorously evaluated on two publicly available datasets and is benchmarked against existing methods. Results indicate significant improvements in classification accuracy, specificity, and sensitivity while demonstrating robustness against noise and outlie rs.Notably, the proposed algorithm addresses the challenge of imbalanced datasets, common in medical image analysis, further enhancing its practical applicability.
</details>
<details>
<summary>摘要</summary>
糖尿病视网膜病 (DR) 是全球主要导致盲视的重要原因，强调了早期发现和有效治疗的急需。 recent advancements in Machine Learning (ML) techniques have shown promise in DR detection, but the availability of labeled data often limits their performance. This research proposes a novel Semi-Supervised Graph Learning (SSGL) algorithm tailored for DR detection, which capitalizes on the relationships between labeled and unlabeled data to enhance accuracy.首先，这项研究 investigate data augmentation and preprocessing techniques to address the challenges of image quality and feature variations. techniques such as image cropping, resizing, contrast adjustment, normalization, and data augmentation are explored to optimize feature extraction and improve the overall quality of retinal images.此外，这项研究不仅仅是 DR 的检测和诊断，还探讨了使用 ML 算法预测糖尿病的发展风险或疾病进程的可能性。通过对患者的全面数据，包括人口统计信息、医疗历史和视网膜图像，生成个性化的风险分数。提出的 Semi-Supervised Graph learning 算法在两个公共可用的数据集上进行了严格的评估，并与现有方法进行了比较。结果表明该算法在分类精度、特异性和敏感性方面具有显著提高，并且在噪音和异常值的情况下具有坚定的稳定性。值得一提的是，提出的算法可以有效地处理医学图像分析中常见的不均衡数据集，进一步提高了其实际应用性。
</details></li>
</ul>
<hr>
<h2 id="Bypassing-the-Simulator-Near-Optimal-Adversarial-Linear-Contextual-Bandits"><a href="#Bypassing-the-Simulator-Near-Optimal-Adversarial-Linear-Contextual-Bandits" class="headerlink" title="Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits"></a>Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00814">http://arxiv.org/abs/2309.00814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haolin Liu, Chen-Yu Wei, Julian Zimmert</li>
<li>for: 解决 adversarial linear contextual bandit problem，loss vectors 完全 adversarially 选择，per-round action set 从固定分布中随机选择。</li>
<li>methods: 不需要 simulator，直接使用 adversarial 搜索，实现 $\widetilde{O}(\sqrt{T})$  regret，同时保持小action set 的计算效率。</li>
<li>results: 在 sleeping bandits 中，解决 Saha et al. [2020] 的开问，存在 $poly(d)\sqrt{T}$ regret 的 polynomials-time 算法，并且可以处理 linear loss 的 additive misspecification error。<details>
<summary>Abstract</summary>
We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-optimal dependence on the magnitude of the error.
</details>
<details>
<summary>摘要</summary>
我们考虑了对抗线性上下文竞争问题，其中损失 вектор被完全对抗选择，并且每轮动作集（即上下文）是从固定分布中抽出的。现有的方法 either需要 Access to a simulator to generate free i.i.d. contexts, or achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-optimal dependence on the magnitude of the error.
</details></li>
</ul>
<hr>
<h2 id="RenAIssance-A-Survey-into-AI-Text-to-Image-Generation-in-the-Era-of-Large-Model"><a href="#RenAIssance-A-Survey-into-AI-Text-to-Image-Generation-in-the-Era-of-Large-Model" class="headerlink" title="RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model"></a>RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00810">http://arxiv.org/abs/2309.00810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fengxiang Bie, Yibo Yang, Zhongzhu Zhou, Adam Ghanem, Minjia Zhang, Zhewei Yao, Xiaoxia Wu, Connor Holmes, Pareesa Golnari, David A. Clifton, Yuxiong He, Dacheng Tao, Shuaiwen Leon Song</li>
<li>For: This paper focuses on text-to-image generation (TTI) models that use neural networks to generate high-fidelity images based on text descriptions.* Methods: The paper discusses various types of generative models used for TTI, including diffusion models, which have been shown to be effective in image synthesis and have become the major image decoder used by TTI models. The paper also explores the integration of large language models with TTI models to improve performance.* Results: The paper reports that TTI models have made significant progress in recent years, with the generation results nearly indistinguishable from real-world images. The paper argues that further improvements could be made through the combination of innovative model architectures and prediction enhancement techniques.<details>
<summary>Abstract</summary>
Text-to-image generation (TTI) refers to the usage of models that could process text input and generate high fidelity images based on text descriptions. Text-to-image generation using neural networks could be traced back to the emergence of Generative Adversial Network (GAN), followed by the autoregressive Transformer. Diffusion models are one prominent type of generative model used for the generation of images through the systematic introduction of noises with repeating steps. As an effect of the impressive results of diffusion models on image synthesis, it has been cemented as the major image decoder used by text-to-image models and brought text-to-image generation to the forefront of machine-learning (ML) research. In the era of large models, scaling up model size and the integration with large language models have further improved the performance of TTI models, resulting the generation result nearly indistinguishable from real-world images, revolutionizing the way we retrieval images. Our explorative study has incentivised us to think that there are further ways of scaling text-to-image models with the combination of innovative model architectures and prediction enhancement techniques. We have divided the work of this survey into five main sections wherein we detail the frameworks of major literature in order to delve into the different types of text-to-image generation methods. Following this we provide a detailed comparison and critique of these methods and offer possible pathways of improvement for future work. In the future work, we argue that TTI development could yield impressive productivity improvements for creation, particularly in the context of the AIGC era, and could be extended to more complex tasks such as video generation and 3D generation.
</details>
<details>
<summary>摘要</summary>
文本到图像生成（TTI）是指使用模型可以从文本输入中生成高效精度的图像描述。使用神经网络进行文本到图像生成可以追溯到生成对抗网络的出现，然后是推理转换器。扩散模型是一种广泛使用的生成模型，用于通过系统性地引入噪声来生成图像。由于扩散模型在图像生成方面的出色表现，因此成为了主要的图像解码器，并使文本到图像生成成为机器学习（ML）研究的先锋。在大模型时代，通过增大模型大小和与大语言模型的集成，有效提高了TTI模型的性能，使得生成结果几乎与实际图像无法分辨，革命化了图像检索方式。我们的探索研究让我们认为，可以通过创新的模型架构和预测增强技术来进一步扩展文本到图像模型。我们在这篇评论中分为五个主要部分，详细介绍了主要的文献框架，以便深入探讨不同类型的文本到图像生成方法。接着，我们对这些方法进行了详细比较和批判，并提出了未来工作的可能的改进方向。在未来工作中，我们 argue that TTI的发展可以带来很大的产出效益，特别在AIGC时代，并可以扩展到更复杂的任务，如视频生成和3D生成。
</details></li>
</ul>
<hr>
<h2 id="Value-Kaleidoscope-Engaging-AI-with-Pluralistic-Human-Values-Rights-and-Duties"><a href="#Value-Kaleidoscope-Engaging-AI-with-Pluralistic-Human-Values-Rights-and-Duties" class="headerlink" title="Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"></a>Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00779">http://arxiv.org/abs/2309.00779</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsor13/kaleido">https://github.com/tsor13/kaleido</a></li>
<li>paper_authors: Taylor Sorensen, Liwei Jiang, Jena Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, John Tasioulas, Yejin Choi</li>
<li>for: The paper aims to improve AI systems’ ability to reflect value pluralism, which is the view that multiple correct values may be held in tension with one another.</li>
<li>methods: The authors introduce ValuePrism, a large-scale dataset of human-written values, rights, and duties, and use GPT-4 to generate contextualized values. They also build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context.</li>
<li>results: The authors show that Kaleido outperforms the teacher GPT-4 in terms of accuracy and broader coverage, and can help explain variability in human decision-making by outputting contrasting values. Additionally, they demonstrate that Kaleido’s representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism.<details>
<summary>Abstract</summary>
Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction.   We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented.   With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.
</details>
<details>
<summary>摘要</summary>
人类价值观是人类决策中不可或缺的一部分。价值多元观是指人们可能同时保持多个正确的价值观（例如，当考虑到为朋友保持好感而做出谎言时，如何均衡诚实和友谊？）。作为统计学学习者，AI系统默认会按照平均值进行适应，这可能会抹平人类价值观的可能性。为了改进AI系统，以更好地反映价值多元观，我们的首要挑战是探索AI系统是否可以模拟人类多元价值观、权利和义务，以及它们之间的交互。我们介绍了ValuePrism，一个大规模的数据集，包含218万个价值观、权利和义务，与31万个人类写作的情况相连。ValuePrism的受过Contextualization的价值观是由GPT-4生成的，并被人类评分员评为高质量91%的时间。我们进行了大规模的研究，邀请来自多个社会和民族背景的 annotators，以了解价值观 representation的多样性。基于ValuePrism，我们构建了Kaleido，一个开源、轻量级、结构化的语言基于多任务模型，可以生成、解释和评估人类价值观、权利和义务在特定情况下的 relevance 和 valence（即支持或反对）。人类更喜欢我们的系统输出的价值观集，认为它们更准确，覆盖率更广。此外，我们还证明了Kaleido可以帮助解释人类决策的变化，输出相互矛盾的价值观。最后，我们表明了Kaleido的表示可以跨越不同的哲学框架和数据集，证明了明确、模块化和可解释的方法对价值多元观具有优势。我们希望通过让人类价值观变得更加明确，使AI系统做出更符合人类价值观的决策。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Feature-Masking-Open-Vocabulary-Vision-Transformer"><a href="#Contrastive-Feature-Masking-Open-Vocabulary-Vision-Transformer" class="headerlink" title="Contrastive Feature Masking Open-Vocabulary Vision Transformer"></a>Contrastive Feature Masking Open-Vocabulary Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00775">http://arxiv.org/abs/2309.00775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dahun Kim, Anelia Angelova, Weicheng Kuo</li>
<li>for: 这篇论文旨在提出一种基于对比特征压缩视Transformer（CFM-ViT）的图像文本预训练方法，用于实现开放词汇对象检测（OVD）中的同时学习图像和区域水平表示。</li>
<li>methods: 该方法结合了压缩隐藏层（MAE）目标到对比学习目标中，以改进表示的地方semantics。此外，我们还引入了随机dropoutPositional Embedding（PED）来 Address scale variation between image-text pretraining and detection finetuning。</li>
<li>results: 在LVIS开放词汇检测标准benchmark上，CFM-ViT实现了33.9 AP$r$的最佳记录，比最佳方法高7.6分。此外，CFM-ViT还实现了更好的零aser检测传递性和图像水平表示。<details>
<summary>Abstract</summary>
We present Contrastive Feature Masking Vision Transformer (CFM-ViT) - an image-text pretraining methodology that achieves simultaneous learning of image- and region-level representation for open-vocabulary object detection (OVD). Our approach combines the masked autoencoder (MAE) objective into the contrastive learning objective to improve the representation for localization tasks. Unlike standard MAE, we perform reconstruction in the joint image-text embedding space, rather than the pixel space as is customary with the classical MAE method, which causes the model to better learn region-level semantics. Moreover, we introduce Positional Embedding Dropout (PED) to address scale variation between image-text pretraining and detection finetuning by randomly dropping out the positional embeddings during pretraining. PED improves detection performance and enables the use of a frozen ViT backbone as a region classifier, preventing the forgetting of open-vocabulary knowledge during detection finetuning. On LVIS open-vocabulary detection benchmark, CFM-ViT achieves a state-of-the-art 33.9 AP$r$, surpassing the best approach by 7.6 points and achieves better zero-shot detection transfer. Finally, CFM-ViT acquires strong image-level representation, outperforming the state of the art on 8 out of 12 metrics on zero-shot image-text retrieval benchmarks.
</details>
<details>
<summary>摘要</summary>
我们提出了对比特征掩码视TRANSFORMER（CFM-ViT）方法，用于开放词汇 объек检测（OVD）的图像-文本预训练。我们的方法将掩码自动编码（MAE）目标函数与对比学习目标函数结合在一起，以提高定位任务的表示。与标准MAE不同的是，我们在图像-文本嵌入空间进行重建，而不是在像素空间进行重建，这使得模型更好地学习区域水平 semantics。此外，我们引入了随机dropout的位置嵌入（PED）来解决图像-文本预训练和检测finetuning之间的尺度变化问题。PED通过随机dropout位置嵌入来提高检测性能，并使得使用冻结的ViT背景作为区域分类器，以避免在检测finetuning过程中忘记开放词汇知识。在LVIS开放词汇检测数据集上，CFM-ViT实现了33.9 AP$r$的状态ethe-art成绩，比最佳方法提高7.6个点，并在零配置检测转移中实现了更好的检测性能。此外，CFM-ViT获得了图像水平表示的强大表示能力，在零配置图像-文本检索数据集上超过了状态艺术的8个 из 12个维度。
</details></li>
</ul>
<hr>
<h2 id="Bias-and-Fairness-in-Large-Language-Models-A-Survey"><a href="#Bias-and-Fairness-in-Large-Language-Models-A-Survey" class="headerlink" title="Bias and Fairness in Large Language Models: A Survey"></a>Bias and Fairness in Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00770">http://arxiv.org/abs/2309.00770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i-gallegos/fair-llm-benchmark">https://github.com/i-gallegos/fair-llm-benchmark</a></li>
<li>paper_authors: Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Nesreen K. Ahmed</li>
<li>for: 这 paper 的目的是提供一个完整的survey of bias evaluation and mitigation techniques for large language models (LLMs), 以便研究者和实践者可以更好地理解和防止 LLMS 中的偏见的传播。</li>
<li>methods: 这 paper 使用了三种分类法来描述 bias evaluation 和 mitigation techniques：一种是 metrics 的分类，另一种是 datasets 的分类，第三种是 mitigation techniques 的分类。这些分类法可以帮助研究者和实践者更好地理解和选择适合的方法。</li>
<li>results: 这 paper 的结果是一个完整的survey of recent research on bias evaluation and mitigation techniques for LLMs，包括了不同类型的 metrics、datasets 和 mitigation techniques，以及它们之间的关系和交互。这个survey 可以帮助研究者和实践者更好地理解和防止 LLMS 中的偏见。<details>
<summary>Abstract</summary>
Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this paper, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly-available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLMs）的快速进步使得处理、理解和生成人类语言的能力得到了进一步的提高，并在社会圈中得到了加强。然而，这些模型可以学习、延续和增强社会偏见。在这篇论文中，我们提供了大语言模型偏见评估和降低技术的全面评论。我们首先将社会偏见和公平在自然语言处理中进行了整合、正式化和扩展，并定义了不同类型的危害和公平的多种要求。然后，我们提出了三种直观的分类，即评估метри克和数据集分类，以及降低技术分类。我们的第一个分类是评估метри克分类，它将评估数据集和模型之间的关系解决，并将评估 метри克分为模型层次、字符级别和生成文本层次。我们的第二个分类是数据集分类，它将数据集分为对称输入或提示，并标识目标危害和社会群体。我们还发布了一份总结公共可用数据集的文件，以便更好地访问。我们的第三个分类是降低技术分类，它将降低方法分为预处理、训练、内部处理和后处理，并在每个子类别中列出了研究趋势。最后，我们 indentified了未来工作中的一些问题和挑战。通过汇总一系列最近的研究成果，我们希望通过这篇文章，为研究人员和实践者提供一份清晰的指南，以便更好地理解和预防 LLMS 中的偏见传播。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.AI_2023_09_02/" data-id="clogxf3ke00395xra3yztcroo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.CL_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T11:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.CL_2023_09_02/">cs.CL - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ModelScope-Agent-Building-Your-Customizable-Agent-System-with-Open-source-Large-Language-Models"><a href="#ModelScope-Agent-Building-Your-Customizable-Agent-System-with-Open-source-Large-Language-Models" class="headerlink" title="ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models"></a>ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00986">http://arxiv.org/abs/2309.00986</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/modelscope/modelscope-agent">https://github.com/modelscope/modelscope-agent</a></li>
<li>paper_authors: Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji Zhang, Fei Huang, Jingren Zhou</li>
<li>for: 这种研究的目的是为了开发一种通用的智能代理框架，让大型自然语言模型（LLMs）具备工具使用能力，以完成复杂任务。</li>
<li>methods: 该研究使用了开源的 LLMs 作为控制器，并提供了一个用户友好的系统库，可以自定义引擎设计以支持模型训练在多个开源 LLMs 上，同时允许在一起融合模型 API 和常见 API。</li>
<li>results: 研究提出了一个涵盖工具使用数据收集、工具检索、工具注册、内存控制、自定义模型训练和评估的框架，以帮助 LLMs 具备工具使用能力。此外，还展示了一个基于 ModelScope-Agent 框架的实际应用程序——ModelScopeGPT，可以连接多个开源 LLMs 和上千个公共 AI 模型，以及本地化社区知识。<details>
<summary>Abstract</summary>
Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior. To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent framework that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs. In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers. It provides a user-friendly system library, with customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way. To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning over tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications. Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope. The ModelScope-Agent library\footnote{https://github.com/modelscope/modelscope-agent} and online demo\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now publicly available.
</details>
<details>
<summary>摘要</summary>
带有强大语言模型（LLM）的大型语言模型在最近的几年内已经展现出了人类意图理解、逻辑推理和规划行为的强大能力。为了更好地利用LLM完成复杂任务，现在有一个增长的趋势是建立一个具有工具使用能力的代理框架，将LLM与大量外部API集成起来。在这项工作中，我们介绍了ModelScope-Agent，一个通用和可定制的代理框架，基于开源LLM控制器。它提供了用户友好的系统库，可以自定义引擎设计，以支持模型训练在多个开源LLM上，同时也可以快速集成模型API和常见API。为了让LLM具备工具使用能力，我们提出了一个涵盖工具使用数据收集、工具检索、工具注册、内存控制、定制化模型训练和评估的框架。最后，我们展示了ModelScopeGPT，一个基于ModelScope-Agent框架的现实世界智能助手，可以连接多个开源LLM和超过1000个公共AI模型，并将本地化社区知识集成到ModelScope中。ModelScope-Agent库（<https://github.com/modelscope/modelscope-agent>）和在线示例（<https://modelscope.cn/studios/damo/ModelScopeGPT/summary>）现在都已经公开available。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Text-Representation"><a href="#Multilingual-Text-Representation" class="headerlink" title="Multilingual Text Representation"></a>Multilingual Text Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00949">http://arxiv.org/abs/2309.00949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TheBauwssss/TimeInWords">https://github.com/TheBauwssss/TimeInWords</a></li>
<li>paper_authors: Fahim Faisal</li>
<li>for: 本研究旨在探讨现代自然语言处理（NLP）技术的发展，尤其是大量多语言模型在100种语言以上执行任务的可能性。</li>
<li>methods: 本研究使用了现代语言模型，从一元化表示法开始，能够实现自然语言理解、通用常识逻辑和问答等任务，同时捕捉文本语法和 semantics。</li>
<li>results: 研究发现，现代语言模型可以在低资源 диаLECTS 上进行竞争性的表现，并且可以拓展到未知语言边界。然而，要确保文本的一致表示，还需要解决一些问题，以实现语言和 Speakers 之间的一致模型空间。<details>
<summary>Abstract</summary>
Modern NLP breakthrough includes large multilingual models capable of performing tasks across more than 100 languages. State-of-the-art language models came a long way, starting from the simple one-hot representation of words capable of performing tasks like natural language understanding, common-sense reasoning, or question-answering, thus capturing both the syntax and semantics of texts. At the same time, language models are expanding beyond our known language boundary, even competitively performing over very low-resource dialects of endangered languages. However, there are still problems to solve to ensure an equitable representation of texts through a unified modeling space across language and speakers. In this survey, we shed light on this iterative progression of multilingual text representation and discuss the driving factors that ultimately led to the current state-of-the-art. Subsequently, we discuss how the full potential of language democratization could be obtained, reaching beyond the known limits and what is the scope of improvement in that space.
</details>
<details>
<summary>摘要</summary>
现代NLP技术发展包括大量多语言模型，可以在多于100种语言上进行任务。当前的语言模型已经很 longue distance，从简单的一个热点表示单词开始，可以完成自然语言理解、常识逻辑和问答等任务，同时捕捉文本的语法和 semantics。然而，还有很多问题需要解决，以确保文本在多语言空间中具有一致的表示空间，并且让所有语言和发音者都有平等的表达机会。在这份报告中，我们将详细介绍这一趋势的迭代发展，并讨论驱动这一进步的因素。后续，我们将讨论如何实现语言 демокра化的全部潜力，超越已知的限制，以及这一空间中的可进步范围。
</details></li>
</ul>
<hr>
<h2 id="BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing"><a href="#BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing" class="headerlink" title="BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing"></a>BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00916">http://arxiv.org/abs/2309.00916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwang621/blsp">https://github.com/cwang621/blsp</a></li>
<li>paper_authors: Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang</li>
<li>for: 该论文旨在扩展大语言模型（LLM）的语言能力到语音频谱上，解决模态对齐问题。</li>
<li>methods: 该论文提出了一种基于行为对齐的语音频谱预训练方法（BLSP），通过学习一个轻量级的模态适配器，使LLM在语音和文本两个模式下 exhibit 同样的生成行为。</li>
<li>results: 该论文实现了将 LLM 的语言能力扩展到语音频谱上，可以实现语音识别、语音翻译、语音理解和语音对话，甚至在零shot cross-lingual scenarios 下。<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) has sparked significant interest in extending their remarkable language capabilities to speech. However, modality alignment between speech and text still remains an open problem. Current solutions can be categorized into two strategies. One is a cascaded approach where outputs (tokens or states) of a separately trained speech recognition system are used as inputs for LLMs, which limits their potential in modeling alignment between speech and text. The other is an end-to-end approach that relies on speech instruction data, which is very difficult to collect in large quantities. In this paper, we address these issues and propose the BLSP approach that Bootstraps Language-Speech Pre-training via behavior alignment of continuation writing. We achieve this by learning a lightweight modality adapter between a frozen speech encoder and an LLM, ensuring that the LLM exhibits the same generation behavior regardless of the modality of input: a speech segment or its transcript. The training process can be divided into two steps. The first step prompts an LLM to generate texts with speech transcripts as prefixes, obtaining text continuations. In the second step, these continuations are used as supervised signals to train the modality adapter in an end-to-end manner. We demonstrate that this straightforward process can extend the capabilities of LLMs to speech, enabling speech recognition, speech translation, spoken language understanding, and speech conversation, even in zero-shot cross-lingual scenarios.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的出现引起了很大的关注，它们的语言能力可以扩展到语音领域。然而，语音和文本之间的模式匹配仍然是一个开放的问题。现有的解决方案可以分为两种策略：一种是采用分解approach，在 separately 训练的语音识别系统输出（token或状态）作为 LLMS 的输入，这会限制其在模式匹配方面的潜力。另一种是以端到端方式进行，它 rely 于语音指令数据，但这些数据难以在大量收集。在这篇论文中，我们解决这些问题，并提出了 BLSP 方法，即通过行为对齐来启动语言-语音预训练。我们通过学习一个轻量级的模式适配器，使 LLMS 在语音段和其转录之间 exhibit 同样的生成行为。训练过程可以分为两步。第一步是让 LLMS 使用语音转录作为前缀，生成文本。第二步是使用这些文本继续进行练习，以train 模式适配器。我们示示这个简单的过程可以扩展 LLMS 的能力到语音领域，实现语音识别、语音翻译、语音理解和语音对话，甚至在零aser 跨语言enario 中。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Transformer’s-Ability-to-Learn-Mildly-Context-Sensitive-Languages"><a href="#Evaluating-Transformer’s-Ability-to-Learn-Mildly-Context-Sensitive-Languages" class="headerlink" title="Evaluating Transformer’s Ability to Learn Mildly Context-Sensitive Languages"></a>Evaluating Transformer’s Ability to Learn Mildly Context-Sensitive Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00857">http://arxiv.org/abs/2309.00857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunjie Wang, Shane Steinert-Threlkeld</li>
<li>for: 这些研究检验了Transformer模型在模型自然语言方面的能力，以及它们是否能够学习一些轻度上下文敏感的语言。</li>
<li>methods: 这些研究使用了Transformer模型，并测试了它们在不同复杂度的语言上的能力。</li>
<li>results: 研究发现，Transformer模型在已经看过的数据上能够泛化良好，但在长串上的推断能力较差，而LSTM模型在这个方面表现更好。分析还显示，Transformer模型学习了自我关注 patrerns和表示，这些 patrerns和表示可能帮助模型解决语言。<details>
<summary>Abstract</summary>
Despite that Transformers perform well in NLP tasks, recent studies suggest that self-attention is theoretically limited in learning even some regular and context-free languages. These findings motivated us to think about their implications in modeling natural language, which is hypothesized to be mildly context-sensitive. We test Transformer's ability to learn a variety of mildly context-sensitive languages of varying complexities, and find that they generalize well to unseen in-distribution data, but their ability to extrapolate to longer strings is worse than that of LSTMs. Our analyses show that the learned self-attention patterns and representations modeled dependency relations and demonstrated counting behavior, which may have helped the models solve the languages.
</details>
<details>
<summary>摘要</summary>
尽管变换器在自然语言处理（NLP）任务中表现良好，但 latest studies 表明自注意力在学习一些常见和 context-free 语言方面存在理论上的限制。这些发现使我们思考自然语言模型化的可能性，自然语言被假设为有些 context-sensitive。我们测试 transformer 能够学习不同复杂程度的 mildly context-sensitive 语言，并发现它们在未seen 数据上具有良好的泛化能力，但在更长的字串上具有更差的推理能力，与 LSTM 模型相比。我们的分析表明 transformer 模型中学习的自注意力模式和表示方式可以模型依赖关系和 counting 行为，可能有助于模型解决语言。
</details></li>
</ul>
<hr>
<h2 id="LinkTransformer-A-Unified-Package-for-Record-Linkage-with-Transformer-Language-Models"><a href="#LinkTransformer-A-Unified-Package-for-Record-Linkage-with-Transformer-Language-Models" class="headerlink" title="LinkTransformer: A Unified Package for Record Linkage with Transformer Language Models"></a>LinkTransformer: A Unified Package for Record Linkage with Transformer Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00789">http://arxiv.org/abs/2309.00789</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dell-research-harvard/linktransformer">https://github.com/dell-research-harvard/linktransformer</a></li>
<li>paper_authors: Abhishek Arora, Melissa Dell</li>
<li>For: The paper aims to improve record linkage in noisy datasets using large language models (LLMs) and make it more accessible to users who are familiar with popular string matching packages like R and Stata.* Methods: The paper proposes an open-source package called LinkTransformer that treats record linkage as a text retrieval problem and uses transformer LLMs to perform record linkage. The package includes a rich repository of pre-trained transformer semantic similarity models for multiple languages and supports easy integration of any transformer language model from Hugging Face or OpenAI.* Results: The paper claims that LinkTransformer can perform record linkage with high accuracy and supports standard functionality such as blocking and linking on multiple noisy fields. It also includes comprehensive tools for efficient model tuning and makes it easy for users to contribute their custom-trained models to its model hub.<details>
<summary>Abstract</summary>
Linking information across sources is fundamental to a variety of analyses in social science, business, and government. While large language models (LLMs) offer enormous promise for improving record linkage in noisy datasets, in many domains approximate string matching packages in popular softwares such as R and Stata remain predominant. These packages have clean, simple interfaces and can be easily extended to a diversity of languages. Our open-source package LinkTransformer aims to extend the familiarity and ease-of-use of popular string matching methods to deep learning. It is a general purpose package for record linkage with transformer LLMs that treats record linkage as a text retrieval problem. At its core is an off-the-shelf toolkit for applying transformer models to record linkage with four lines of code. LinkTransformer contains a rich repository of pre-trained transformer semantic similarity models for multiple languages and supports easy integration of any transformer language model from Hugging Face or OpenAI. It supports standard functionality such as blocking and linking on multiple noisy fields. LinkTransformer APIs also perform other common text data processing tasks, e.g., aggregation, noisy de-duplication, and translation-free cross-lingual linkage. Importantly, LinkTransformer also contains comprehensive tools for efficient model tuning, to facilitate different levels of customization when off-the-shelf models do not provide the required accuracy. Finally, to promote reusability, reproducibility, and extensibility, LinkTransformer makes it easy for users to contribute their custom-trained models to its model hub. By combining transformer language models with intuitive APIs that will be familiar to many users of popular string matching packages, LinkTransformer aims to democratize the benefits of LLMs among those who may be less familiar with deep learning frameworks.
</details>
<details>
<summary>摘要</summary>
连结资讯 Across ources 是社会科学、商业和政府中许多分析的基本步骤。 although large language models (LLMs) 在复杂数据中提供了巨大的推荐，在许多领域中， approximate string matching 套件在 популяр的软件such as R 和 Stata 中仍然占主导地位。这些套件有clean、简单的接口，并可以轻松扩展到多种语言。我们的开源套件 LinkTransformer 目标是将受欢迎的字串匹配方法和深度学习结合在一起，以提供一个易用的字串匹配解决方案。它的核心是一个可以在四行程式码中应用transformer模型的工具组。LinkTransformer 包含了多种语言的预训transformer对偶性模型，并支持轻松地 интеграble任何transformer语言模型。它支持标准的功能，例如封页和联结多个噪音字段。LinkTransformer API 还可以进行其他常见的文本数据处理任务，例如聚合、噪音除除损和无需翻译的跨语言联结。更重要的是，LinkTransformer 还包含了详细的模型调整工具，以便在不同的粒度上进行自定义，当Off-the-shelf模型不提供所需的精度时。最后，为了促进再利用、重现性和扩展性，LinkTransformer 让用户可以轻松地发布自己的自定义模型。通过结合transformer语言模型和对多数使用 string matching 套件的用户而且 familier的 APIs，LinkTransformer 目标是将LLMs 的好处传播到那些可能不熟悉深度学习框架的人。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.CL_2023_09_02/" data-id="clogxf3ls00af5xra790ecgnw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.LG_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T10:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.LG_2023_09_02/">cs.LG - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Covariance-Matrix-Reconstruction-with-Iterative-Spatial-Spectrum-Sampling"><a href="#Efficient-Covariance-Matrix-Reconstruction-with-Iterative-Spatial-Spectrum-Sampling" class="headerlink" title="Efficient Covariance Matrix Reconstruction with Iterative Spatial Spectrum Sampling"></a>Efficient Covariance Matrix Reconstruction with Iterative Spatial Spectrum Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01040">http://arxiv.org/abs/2309.01040</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. Mohammadzadeh, V. H. Nascimento, R. C. de Lamare, O. Kukrer</li>
<li>for: 本研究提出了一种可靠且cost-effective的 beamforming算法设计方法，用于防止附近干扰信号的扩散。</li>
<li>methods: 本研究使用了有效的covariance矩阵重建方法，基于iterative空间功率spectrum（CMR-ISPS）。这种方法可以重建干扰信号plus noise covariance矩阵（INC），并使用最大Entropy功率spectrumdensity函数来形态指向响应。</li>
<li>results: 实验结果表明，提出的CMR-ISPS抑制器可以快速地防止附近干扰信号的扩散，并且可以在不同的干扰信号水平下提供相应的抗干扰性能。<details>
<summary>Abstract</summary>
This work presents a cost-effective technique for designing robust adaptive beamforming algorithms based on efficient covariance matrix reconstruction with iterative spatial power spectrum (CMR-ISPS). The proposed CMR-ISPS approach reconstructs the interference-plus-noise covariance (INC) matrix based on a simplified maximum entropy power spectral density function that can be used to shape the directional response of the beamformer. Firstly, we estimate the directions of arrival (DoAs) of the interfering sources with the available snapshots. We then develop an algorithm to reconstruct the INC matrix using a weighted sum of outer products of steering vectors whose coefficients can be estimated in the vicinity of the DoAs of the interferences which lie in a small angular sector. We also devise a cost-effective adaptive algorithm based on conjugate gradient techniques to update the beamforming weights and a method to obtain estimates of the signal of interest (SOI) steering vector from the spatial power spectrum. The proposed CMR-ISPS beamformer can suppress interferers close to the direction of the SOI by producing notches in the directional response of the array with sufficient depths. Simulation results are provided to confirm the validity of the proposed method and make a comparison to existing approaches
</details>
<details>
<summary>摘要</summary>
First, the directions of arrival (DoAs) of the interfering sources are estimated using the available snapshots. Then, an algorithm is developed to reconstruct the INC matrix using a weighted sum of outer products of steering vectors whose coefficients can be estimated in the vicinity of the DoAs of the interferences, which lie in a small angular sector.Additionally, a cost-effective adaptive algorithm based on conjugate gradient techniques is proposed to update the beamforming weights, and a method to obtain estimates of the signal of interest (SOI) steering vector from the spatial power spectrum. The proposed CMR-ISPS beamformer can effectively suppress interferers close to the direction of the SOI by producing notches in the directional response of the array with sufficient depths.Simulation results are provided to confirm the validity of the proposed method and compare it to existing approaches. The proposed technique offers a cost-effective and robust solution for adaptive beamforming in the presence of interference.
</details></li>
</ul>
<hr>
<h2 id="Online-Adaptive-Mahalanobis-Distance-Estimation"><a href="#Online-Adaptive-Mahalanobis-Distance-Estimation" class="headerlink" title="Online Adaptive Mahalanobis Distance Estimation"></a>Online Adaptive Mahalanobis Distance Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01030">http://arxiv.org/abs/2309.01030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lianke Qin, Aravind Reddy, Zhao Song</li>
<li>For: This paper is written for studying dimension reduction for Mahalanobis metrics and providing efficient data structures for solving the Approximate Distance Estimation (ADE) problem for Mahalanobis distances.* Methods: The paper uses randomized Monte Carlo data structures and adapts it to handle sequences of adaptive queries and online updates to the Mahalanobis metric matrix and the data points.* Results: The paper provides efficient data structures for solving the ADE problem for Mahalanobis distances, which can be used in conjunction with prior algorithms for online learning of Mahalanobis metrics.<details>
<summary>Abstract</summary>
Mahalanobis metrics are widely used in machine learning in conjunction with methods like $k$-nearest neighbors, $k$-means clustering, and $k$-medians clustering. Despite their importance, there has not been any prior work on applying sketching techniques to speed up algorithms for Mahalanobis metrics. In this paper, we initiate the study of dimension reduction for Mahalanobis metrics. In particular, we provide efficient data structures for solving the Approximate Distance Estimation (ADE) problem for Mahalanobis distances. We first provide a randomized Monte Carlo data structure. Then, we show how we can adapt it to provide our main data structure which can handle sequences of \textit{adaptive} queries and also online updates to both the Mahalanobis metric matrix and the data points, making it amenable to be used in conjunction with prior algorithms for online learning of Mahalanobis metrics.
</details>
<details>
<summary>摘要</summary>
马哈拉诺比斯度量广泛应用在机器学习中，常与 $k$-最近邻、$k$-集群和 $k$-中值集群一起使用。尽管其重要性，但是没有任何之前的研究把笔记技术应用于快速化马哈拉诺比斯度量算法。在这篇论文中，我们开始研究维度减少 для马哈拉诺比斯度量。具体来说，我们提供了高效的数据结构来解决 Approximate Distance Estimation（ADE）问题。我们首先提供了随机 Monte Carlo 数据结构。然后，我们如何将其改进，以满足适应性查询和在 Mahalanobis 度量矩阵和数据点上进行在线更新，使其适用于与之前的在线学习 Mahalanobis 度量算法。
</details></li>
</ul>
<hr>
<h2 id="On-the-training-and-generalization-of-deep-operator-networks"><a href="#On-the-training-and-generalization-of-deep-operator-networks" class="headerlink" title="On the training and generalization of deep operator networks"></a>On the training and generalization of deep operator networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01020">http://arxiv.org/abs/2309.01020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Sanghyun Lee, Yeonjong Shin</li>
<li>for: 这个论文是为了提出一种新的深度运算网络（DeepONets）训练方法。</li>
<li>methods: 这种训练方法包括先训练树网络，然后顺序训练分支网络。这种方法的核心思想是利用分治法将复杂的训练任务分解成两个子任务，从而降低训练的复杂性。</li>
<li>results: 该训练方法可以在各种情况下提高DeepONets的稳定性和泛化能力，并且可以更好地处理各种非线性和非对易性问题。<details>
<summary>Abstract</summary>
We present a novel training method for deep operator networks (DeepONets), one of the most popular neural network models for operators. DeepONets are constructed by two sub-networks, namely the branch and trunk networks. Typically, the two sub-networks are trained simultaneously, which amounts to solving a complex optimization problem in a high dimensional space. In addition, the nonconvex and nonlinear nature makes training very challenging. To tackle such a challenge, we propose a two-step training method that trains the trunk network first and then sequentially trains the branch network. The core mechanism is motivated by the divide-and-conquer paradigm and is the decomposition of the entire complex training task into two subtasks with reduced complexity. Therein the Gram-Schmidt orthonormalization process is introduced which significantly improves stability and generalization ability. On the theoretical side, we establish a generalization error estimate in terms of the number of training data, the width of DeepONets, and the number of input and output sensors. Numerical examples are presented to demonstrate the effectiveness of the two-step training method, including Darcy flow in heterogeneous porous media.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的训练方法 для深度运算网络（DeepONets），这是一种非常流行的神经网络模型。DeepONets由两个子网络组成：分支网络和主网络。通常情况下，这两个子网络同时进行训练，这等于在高维空间中解决一个复杂的优化问题。此外，由于非对称和非线性的性质，训练非常困难。为解决这个挑战，我们提出了一种分两步训练方法，先训练主网络，然后顺序训练分支网络。这种机制的核心思想是分而治之的方法，即将整个复杂的训练任务分解成两个子任务，每个子任务都有较低的复杂性。在这个过程中，我们引入了 Gram-Schmidt 正交化过程，这有助于提高稳定性和泛化能力。从理论角度来看，我们建立了一个泛化误差估计，其与训练数据量、深度网络宽度和输入和输出感知器数量有关。数据示范中，我们展示了这种两步训练方法的效果，包括 Darcy 流在不同的孔隙媒质中。
</details></li>
</ul>
<hr>
<h2 id="MPTopic-Improving-topic-modeling-via-Masked-Permuted-pre-training"><a href="#MPTopic-Improving-topic-modeling-via-Masked-Permuted-pre-training" class="headerlink" title="MPTopic: Improving topic modeling via Masked Permuted pre-training"></a>MPTopic: Improving topic modeling via Masked Permuted pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01015">http://arxiv.org/abs/2309.01015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinche Zhang, Evangelos milios</li>
<li>For: The paper aims to improve the quality of topic modeling in text analysis by addressing the limitations of existing methods such as BERTopic and Top2Vec.* Methods: The paper introduces a new approach called TF-RDF (Term Frequency - Relative Document Frequency) to assess the relevance of terms within a document, and uses this approach to drive a clustering algorithm called MPTopic.* Results: The paper shows that the topic keywords identified using MPTopic and TF-RDF outperform those extracted by BERTopic and Top2Vec through comprehensive evaluation.Here’s the same information in Simplified Chinese:* For: 论文目的是为了提高文本分析中的话题模型质量，并且解决现有方法如BERTopic和Top2Vec的局限性。* Methods: 论文引入了一种新的方法 called TF-RDF (文档频次-相对文档频次)，用于评估文档中 термина的 relevance，并使用这种方法驱动一种名为 MPTopic 的聚类算法。* Results: 论文表明，使用 MPTopic 和 TF-RDF 提取的话题关键词比 BERTopic 和 Top2Vec 提取的词语要出色。<details>
<summary>Abstract</summary>
Topic modeling is pivotal in discerning hidden semantic structures within texts, thereby generating meaningful descriptive keywords. While innovative techniques like BERTopic and Top2Vec have recently emerged in the forefront, they manifest certain limitations. Our analysis indicates that these methods might not prioritize the refinement of their clustering mechanism, potentially compromising the quality of derived topic clusters. To illustrate, Top2Vec designates the centroids of clustering results to represent topics, whereas BERTopic harnesses C-TF-IDF for its topic extraction.In response to these challenges, we introduce "TF-RDF" (Term Frequency - Relative Document Frequency), a distinctive approach to assess the relevance of terms within a document. Building on the strengths of TF-RDF, we present MPTopic, a clustering algorithm intrinsically driven by the insights of TF-RDF. Through comprehensive evaluation, it is evident that the topic keywords identified with the synergy of MPTopic and TF-RDF outperform those extracted by both BERTopic and Top2Vec.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Streaming-Active-Learning-for-Regression-Problems-Using-Regression-via-Classification"><a href="#Streaming-Active-Learning-for-Regression-Problems-Using-Regression-via-Classification" class="headerlink" title="Streaming Active Learning for Regression Problems Using Regression via Classification"></a>Streaming Active Learning for Regression Problems Using Regression via Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01013">http://arxiv.org/abs/2309.01013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shota Horiguchi, Kota Dohi, Yohei Kawaguchi</li>
<li>for: 本研究旨在提出一种基于流动学习的回归方法，以提高回归模型在不同环境下的性能。</li>
<li>methods: 本研究使用了流动活动学习方法，其中将回归问题转化为分类问题，然后应用直接使用了流动活动学习方法。</li>
<li>results: 实验结果表明，提出的方法可以在同等级别的注释成本下实现更高的回归精度。<details>
<summary>Abstract</summary>
One of the challenges in deploying a machine learning model is that the model's performance degrades as the operating environment changes. To maintain the performance, streaming active learning is used, in which the model is retrained by adding a newly annotated sample to the training dataset if the prediction of the sample is not certain enough. Although many streaming active learning methods have been proposed for classification, few efforts have been made for regression problems, which are often handled in the industrial field. In this paper, we propose to use the regression-via-classification framework for streaming active learning for regression. Regression-via-classification transforms regression problems into classification problems so that streaming active learning methods proposed for classification problems can be applied directly to regression problems. Experimental validation on four real data sets shows that the proposed method can perform regression with higher accuracy at the same annotation cost.
</details>
<details>
<summary>摘要</summary>
一个机器学习模型的挑战是其性能随环境变化而下降。为维护性能，流动活动学习被使用，其中模型通过添加新的注释样本到训练集来重新训练，如果预测样本的准确性不够高 enough。虽然许多流动活动学习方法已经为分类问题提出，但对于回归问题，业界上的尝试不多。本文提出使用回归via分类框架来实现流动活动学习回归。回归via分类将回归问题转化为分类问题，从而可以直接应用流动活动学习方法，提高回归的准确性。实验 validate on four real data sets 显示，提出的方法可以在同样的注释成本下实现更高的回归精度。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-sparsity-and-class-sparsity-priors-for-dictionary-learning-and-coding"><a href="#Bayesian-sparsity-and-class-sparsity-priors-for-dictionary-learning-and-coding" class="headerlink" title="Bayesian sparsity and class sparsity priors for dictionary learning and coding"></a>Bayesian sparsity and class sparsity priors for dictionary learning and coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00999">http://arxiv.org/abs/2309.00999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Bocchinfuso, Daniela Calvetti, Erkki Somersalo</li>
<li>for:  solves challenging inverse problems using dictionary learning methods</li>
<li>methods:  uses sparse coding techniques and dictionary compression to reduce computational complexity</li>
<li>results:  effectively identifies relevant subdictionaries and reduces computational complexity in real-world applications such as glitch detection and hyperspectral remote sensing<details>
<summary>Abstract</summary>
Dictionary learning methods continue to gain popularity for the solution of challenging inverse problems. In the dictionary learning approach, the computational forward model is replaced by a large dictionary of possible outcomes, and the problem is to identify the dictionary entries that best match the data, akin to traditional query matching in search engines. Sparse coding techniques are used to guarantee that the dictionary matching identifies only few of the dictionary entries, and dictionary compression methods are used to reduce the complexity of the matching problem. In this article, we propose a work flow to facilitate the dictionary matching process. First, the full dictionary is divided into subdictionaries that are separately compressed. The error introduced by the dictionary compression is handled in the Bayesian framework as a modeling error. Furthermore, we propose a new Bayesian data-driven group sparsity coding method to help identify subdictionaries that are not relevant for the dictionary matching. After discarding irrelevant subdictionaries, the dictionary matching is addressed as a deflated problem using sparse coding. The compression and deflation steps can lead to substantial decreases of the computational complexity. The effectiveness of compensating for the dictionary compression error and using the novel group sparsity promotion to deflate the original dictionary are illustrated by applying the methodology to real world problems, the glitch detection in the LIGO experiment and hyperspectral remote sensing.
</details>
<details>
<summary>摘要</summary>
字典学习方法继续受欢迎用于解决困难的反问题。在字典学习方法中，计算前方模型被替换为一个大字典的可能结果，问题是将字典条目与数据匹配，类似于传统的查询匹配在搜索引擎中。稀盐编码技术用于保证字典匹配只找到少量的字典条目，而字典压缩方法用于减少匹配问题的复杂性。在这篇文章中，我们提出一个工作流程来促进字典匹配过程。首先，全字典被分解成分字典，并将每个分字典独立压缩。 dictionary compression error 被处理在 bayesian 框架中作为模型误差。此外，我们提出了一种新的 bayesian 数据驱动的群 sparse coding 方法，以帮助标识不相关的分字典。 после将不相关的分字典排除，字典匹配被视为一个减少的问题，使用稀盐编码进行解决。压缩和减少步骤可能会导致计算复杂性的明显减少。我们通过应用方法到实际问题，如 LIGO 实验中的雷达检测和Remote sensing 中的 Hyperspectral 检测，来证明资料做准的补偿和使用新的群 sparse coding 促进法可以减少计算复杂性。
</details></li>
</ul>
<hr>
<h2 id="Switch-and-Conquer-Efficient-Algorithms-By-Switching-Stochastic-Gradient-Oracles-For-Decentralized-Saddle-Point-Problems"><a href="#Switch-and-Conquer-Efficient-Algorithms-By-Switching-Stochastic-Gradient-Oracles-For-Decentralized-Saddle-Point-Problems" class="headerlink" title="Switch and Conquer: Efficient Algorithms By Switching Stochastic Gradient Oracles For Decentralized Saddle Point Problems"></a>Switch and Conquer: Efficient Algorithms By Switching Stochastic Gradient Oracles For Decentralized Saddle Point Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00997">http://arxiv.org/abs/2309.00997</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chhavisharma123/c-dpssg-cdc2023">https://github.com/chhavisharma123/c-dpssg-cdc2023</a></li>
<li>paper_authors: Chhavi Sharma, Vishnu Narayanan, P. Balamurugan</li>
<li>for: 这个论文targets non-smooth strongly convex-strongly concave saddle point problems in a decentralized setting without a central server.</li>
<li>methods:  authors propose an inexact primal dual hybrid gradient (inexact PDHG) procedure that allows generic gradient computation oracles to update the primal and dual variables.</li>
<li>results:  authors prove that the proposed algorithm, Decentralized Proximal Switching Stochastic Gradient method with Compression (C-DPSSG), converges to an $\epsilon$-accurate saddle point solution with linear rate, and the algorithm is well suited for obtaining solutions of low&#x2F;medium accuracy faster.Here is the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope this helps!<details>
<summary>Abstract</summary>
We consider a class of non-smooth strongly convex-strongly concave saddle point problems in a decentralized setting without a central server. To solve a consensus formulation of problems in this class, we develop an inexact primal dual hybrid gradient (inexact PDHG) procedure that allows generic gradient computation oracles to update the primal and dual variables. We first investigate the performance of inexact PDHG with stochastic variance reduction gradient (SVRG) oracle. Our numerical study uncovers a significant phenomenon of initial conservative progress of iterates of IPDHG with SVRG oracle. To tackle this, we develop a simple and effective switching idea, where a generalized stochastic gradient (GSG) computation oracle is employed to hasten the iterates' progress to a saddle point solution during the initial phase of updates, followed by a switch to the SVRG oracle at an appropriate juncture. The proposed algorithm is named Decentralized Proximal Switching Stochastic Gradient method with Compression (C-DPSSG), and is proven to converge to an $\epsilon$-accurate saddle point solution with linear rate. Apart from delivering highly accurate solutions, our study reveals that utilizing the best convergence phases of GSG and SVRG oracles makes C-DPSSG well suited for obtaining solutions of low/medium accuracy faster, useful for certain applications. Numerical experiments on two benchmark machine learning applications show C-DPSSG's competitive performance which validate our theoretical findings. The codes used in the experiments can be found \href{https://github.com/chhavisharma123/C-DPSSG-CDC2023}{here}.
</details>
<details>
<summary>摘要</summary>
我们考虑一类非滑坡强弱缓衡点问题在分布式设置中，无中央服务器。以解决这类问题的协议形式，我们发展了一个不精确的内部预测点数值变化（inexact PDHG）程式，允许普通的梯度计算实体更新内部预测点和梯度。我们首先研究对不精确PDHG使用测量噪声减少梯度（SVRG）实体的性能。我们的数据研究发现在追踪过程中，对于IPDHG的初始阶段，实际上存在较大的保守进步。为了解决这个问题，我们提出了一个简单有效的转换想法，其中在初始阶段使用一个通用梯度计算实体（GSG）来增加积分进步，然后在适当的时刻转换到SVRG实体。我们给这个算法命名为分布式预测转换梯度法（C-DPSSG），并证明其可以在线性速率下落在ε-精确点解。此外，我们的研究发现，通过利用GSG和SVRG实体的最佳追踪阶段，C-DPSSG可以实现低/中精度更快的解决方案，对于一些应用而言是有用的。我们的实验结果显示C-DPSSG在两个机器学习应用中的竞争性表现，与我们的理论成果相符。实验代码可以在以下连结获取：<https://github.com/chhavisharma123/C-DPSSG-CDC2023>
</details></li>
</ul>
<hr>
<h2 id="A-Boosted-Machine-Learning-Framework-for-the-Improvement-of-Phase-and-Crystal-Structure-Prediction-of-High-Entropy-Alloys-Using-Thermodynamic-and-Configurational-Parameters"><a href="#A-Boosted-Machine-Learning-Framework-for-the-Improvement-of-Phase-and-Crystal-Structure-Prediction-of-High-Entropy-Alloys-Using-Thermodynamic-and-Configurational-Parameters" class="headerlink" title="A Boosted Machine Learning Framework for the Improvement of Phase and Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and Configurational Parameters"></a>A Boosted Machine Learning Framework for the Improvement of Phase and Crystal Structure Prediction of High Entropy Alloys Using Thermodynamic and Configurational Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00993">http://arxiv.org/abs/2309.00993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debsundar Dey, Suchandan Das, Anik Pal, Santanu Dey, Chandan Kumar Raul, Arghya Chatterjee</li>
<li>for: This paper aims to predict the phases and crystal structures of High-Entropy Alloys (HEAs) using machine learning (ML) techniques.</li>
<li>methods: The study employs five distinct boosting algorithms (XGBoost, LightGBM, Random Forest, Gradient Boosting, and CatBoost) to predict phases and crystal structures, and introduces a methodical framework using the Pearson correlation coefficient to select strongly co-related features for improved accuracy.</li>
<li>results: The study achieves an accuracy of 94.05% for phase prediction and 90.07% for crystal structure prediction, and provides a new approach to quantify the influence of parameters on the model’s accuracy.<details>
<summary>Abstract</summary>
The reason behind the remarkable properties of High-Entropy Alloys (HEAs) is rooted in the diverse phases and the crystal structures they contain. In the realm of material informatics, employing machine learning (ML) techniques to classify phases and crystal structures of HEAs has gained considerable significance. In this study, we assembled a new collection of 1345 HEAs with varying compositions to predict phases. Within this collection, there were 705 sets of data that were utilized to predict the crystal structures with the help of thermodynamics and electronic configuration. Our study introduces a methodical framework i.e., the Pearson correlation coefficient that helps in selecting the strongly co-related features to increase the prediction accuracy. This study employed five distinct boosting algorithms to predict phases and crystal structures, offering an enhanced guideline for improving the accuracy of these predictions. Among all these algorithms, XGBoost gives the highest accuracy of prediction (94.05%) for phases and LightGBM gives the highest accuracy of prediction of crystal structure of the phases (90.07%). The quantification of the influence exerted by parameters on the model's accuracy was conducted and a new approach was made to elucidate the contribution of individual parameters in the process of phase prediction and crystal structure prediction.
</details>
<details>
<summary>摘要</summary>
高级噪声合金（HEA）的很多特有性归因于它们包含多种相和晶体结构。在材料信息学领域，使用机器学习（ML）技术来分类HEA的相和晶体结构得到了广泛的应用。在这项研究中，我们组装了一个新的HEA合集，其中包含了不同组合的1345个HEA。其中，705个数据集用于预测晶体结构，并采用了热力学和电子配置来帮助预测。我们的研究框架包括用Pearson相关系数选择强相关特征，以提高预测精度。我们使用了五种不同的提升算法来预测相和晶体结构，其中XGBoost提供了预测相的最高精度（94.05%），而LightGBM提供了预测晶体结构的相最高精度（90.07%）。我们还对模型精度的影响因素进行了评估，并开发了一种新的方法来解释参数对预测相和晶体结构的贡献。
</details></li>
</ul>
<hr>
<h2 id="An-Ensemble-Score-Filter-for-Tracking-High-Dimensional-Nonlinear-Dynamical-Systems"><a href="#An-Ensemble-Score-Filter-for-Tracking-High-Dimensional-Nonlinear-Dynamical-Systems" class="headerlink" title="An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems"></a>An Ensemble Score Filter for Tracking High-Dimensional Nonlinear Dynamical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00983">http://arxiv.org/abs/2309.00983</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zezhongzhang/ensf">https://github.com/zezhongzhang/ensf</a></li>
<li>paper_authors: Feng Bao, Zezhong Zhang, Guannan Zhang</li>
<li>for: 解决高维非线性滤波问题的精度高的筛选方法</li>
<li>methods: 利用分数基本概率模型来描述滤波过程中的演化，并使用小批量 Monte Carlo 估计器直接估计分数函数，而不需要训练神经网络。</li>
<li>results: 在高维劳逊系统中，EnSF 可以可靠地跟踪高维非线性观测过程，并且可以提供高精度的滤波结果，这些问题都是现有滤波方法所面临的挑战。<details>
<summary>Abstract</summary>
We propose an ensemble score filter (EnSF) for solving high-dimensional nonlinear filtering problems with superior accuracy. A major drawback of existing filtering methods, e.g., particle filters or ensemble Kalman filters, is the low accuracy in handling high-dimensional and highly nonlinear problems. EnSF attacks this challenge by exploiting the score-based diffusion model, defined in a pseudo-temporal domain, to characterizing the evolution of the filtering density. EnSF stores the information of the recursively updated filtering density function in the score function, in stead of storing the information in a set of finite Monte Carlo samples (used in particle filters and ensemble Kalman filters). Unlike existing diffusion models that train neural networks to approximate the score function, we develop a training-free score estimation that uses mini-batch-based Monte Carlo estimator to directly approximate the score function at any pseudo-spatial-temporal location, which provides sufficient accuracy in solving high-dimensional nonlinear problems as well as saves tremendous amount of time spent on training neural networks. Another essential aspect of EnSF is its analytical update step, gradually incorporating data information into the score function, which is crucial in mitigating the degeneracy issue faced when dealing with very high-dimensional nonlinear filtering problems. High-dimensional Lorenz systems are used to demonstrate the performance of our method. EnSF provides surprisingly impressive performance in reliably tracking extremely high-dimensional Lorenz systems (up to 1,000,000 dimension) with highly nonlinear observation processes, which is a well-known challenging problem for existing filtering methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种ensemble score filter（EnSF），用于解决高维非线性筛选问题，提高准确性。现有的筛选方法，如 particile filter 或 ensemble Kalman filter，在处理高维高非线性问题时的准确性很低。EnSF 利用了分数基 diffusion 模型，在 pseudo-时间领域中定义了筛选演化的分数函数。EnSF 将筛选 densities 的信息存储在分数函数中，而不是使用finite Monte Carlo 样本（用于 particile filter 和 ensemble Kalman filter）。与现有的扩散模型不同，我们开发了一种无需训练的分数估计，使用 mini-batch-based Monte Carlo 估计器直接在任何 pseudo-空间时间位置上估计分数函数，这提供了足够的准确性来解决高维非线性问题，同时节省了训练神经网络所需的巨大时间。另一个关键特点是 EnSF 的分析更新步骤，逐步将数据信息 incorporated 到分数函数中，这是解决非线性问题时的重要问题。高维 Lorenz 系统被用来演示 EnSF 的性能，EnSF 在处理 extremely high-dimensional Lorenz 系统（达 1,000,000 维）的非线性观测过程中表现出非常出众的表现，这是现有筛选方法所面临的一个著名的挑战。
</details></li>
</ul>
<hr>
<h2 id="Pure-Message-Passing-Can-Estimate-Common-Neighbor-for-Link-Prediction"><a href="#Pure-Message-Passing-Can-Estimate-Common-Neighbor-for-Link-Prediction" class="headerlink" title="Pure Message Passing Can Estimate Common Neighbor for Link Prediction"></a>Pure Message Passing Can Estimate Common Neighbor for Link Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00976">http://arxiv.org/abs/2309.00976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaiwen Dong, Zhichun Guo, Nitesh V. Chawla</li>
<li>for: 这个研究的目的是提高Message Passing Neural Networks（MPNNs）在链接预测 task 的表现，MPNNs 通常在这个任务中表现不佳，被简单的规律如 Common Neighbor（CN）所超越。</li>
<li>methods: 我们提出了一种基于 message-passing 的方法，即 Message Passing Link Predictor（MPLP），这个模型利用 quasi-orthogonal vectors 来估算链接级别的结构特征，同时保留 node-level 的复杂性。</li>
<li>results: 我们在不同领域的benchmark datasets上进行了实验，结果显示了我们的方法在预测链接任务中的出色表现，较基于方法的表现更好。<details>
<summary>Abstract</summary>
Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto} standard in graph representation learning. However, when it comes to link prediction, they often struggle, surpassed by simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. Moreover, our approach demonstrates that leveraging message-passing to capture structural features could offset MPNNs' expressiveness limitations at the expense of estimation variance. We conduct experiments on benchmark datasets from various domains, where our method consistently outperforms the baseline methods.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:message passing neural networks (MPNNs) 已经成为 graphs 表示学习的“de facto”标准，但当预测关系时，它们经常遇到问题，被简单的规律如共同邻居 (CN) 所超越。这个差异源于 MPNNs 在节点水平的表示方面 excellence，但它们在节点间的结构特征方面缺乏表达能力，如 CN。为了补偿这个差异，我们提出，通过利用输入vector的正交性，纯message-passing可以真正捕捉结构特征。我们进一步研究 MPNNs 在CN规律的近似方面的效能。根据我们的发现，我们引入了 Message Passing Link Predictor (MPLP)，一个新的预测关系模型。MPLP 利用 quasi-orthogonal vector 估计关系级别的结构特征，同时保留节点水平的复杂性。此外，我们的方法显示，通过将message-passing用于结构特征的捕捉，可以对 MPNNs 的表达能力进行补偿，即使是在估计误差方面。我们在不同领域的benchmark数据上进行了实验，我们的方法一致地超越了基eline方法。
</details></li>
</ul>
<hr>
<h2 id="Network-Topology-Inference-with-Sparsity-and-Laplacian-Constraints"><a href="#Network-Topology-Inference-with-Sparsity-and-Laplacian-Constraints" class="headerlink" title="Network Topology Inference with Sparsity and Laplacian Constraints"></a>Network Topology Inference with Sparsity and Laplacian Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00960">http://arxiv.org/abs/2309.00960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Ying, Xi Han, Rui Zhou, Xiwen Wang, Hing Cheung So</li>
<li>for: 这篇论文旨在解决网络顶点推导问题，使用laplacian受限 Gaussian graphical models，将任务转换为精确度矩阵的估计。</li>
<li>methods: 本文提出了一种具有 $\ell_0$-norm条件的网络矩阵估计方法，通过gradient projection算法解决具有稀疏性和laplacian约束的优化问题。</li>
<li>results: numerical experiments表明，提案的方法能够有效地解决网络顶点推导问题，并且比traditional $\ell_1$-norm方法更加稳定和有效。<details>
<summary>Abstract</summary>
We tackle the network topology inference problem by utilizing Laplacian constrained Gaussian graphical models, which recast the task as estimating a precision matrix in the form of a graph Laplacian. Recent research \cite{ying2020nonconvex} has uncovered the limitations of the widely used $\ell_1$-norm in learning sparse graphs under this model: empirically, the number of nonzero entries in the solution grows with the regularization parameter of the $\ell_1$-norm; theoretically, a large regularization parameter leads to a fully connected (densest) graph. To overcome these challenges, we propose a graph Laplacian estimation method incorporating the $\ell_0$-norm constraint. An efficient gradient projection algorithm is developed to solve the resulting optimization problem, characterized by sparsity and Laplacian constraints. Through numerical experiments with synthetic and financial time-series datasets, we demonstrate the effectiveness of the proposed method in network topology inference.
</details>
<details>
<summary>摘要</summary>
我们解决网络顶点结构推论问题，利用laplacian受限 Gaussian graphical models，它将任务转换为估计一个矩阵precision matrix的graph Laplacian。最近的研究 \cite{ying2020nonconvex} 发现了 $\ell_1$ 条件下学习简短网络的limitation：实验中非零元素的数量随着调整参数增加;理论上，一个大的调整参数将导致一个最密集的网络。为了解决这些挑战，我们提议一个具有 $\ell_0$ 条件的网络Laplacian估计方法。我们开发了一个高效的梯度对应算法来解决这个估计问题，它具有简短和Laplacian的约束。通过实验证明，我们显示了我们的提议方法在网络顶点结构推论中的效果。
</details></li>
</ul>
<hr>
<h2 id="Index-aware-learning-of-circuits"><a href="#Index-aware-learning-of-circuits" class="headerlink" title="Index-aware learning of circuits"></a>Index-aware learning of circuits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00958">http://arxiv.org/abs/2309.00958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Idoia Cortes Garcia, Peter Förster, Lennart Jansen, Wil Schilders, Sebastian Schöps</li>
<li>for: 本文旨在描述如何使用机器学习方法来优化电子电路设计，以及如何使用已有系统知识来减少学习的复杂性。</li>
<li>methods: 本文提出了一种基于分解理论的机器学习方法，该方法可以将电子电路描述为代数动态系统（DAE），然后使用分解理论来解释DAE中的隐藏约束。最后，该方法可以使用已有系统知识来重建代数变量，从而保证算法的准确性。</li>
<li>results: 本文的实验结果表明，使用该方法可以减少学习的复杂性，同时保证算法的准确性。这种方法可以用于各种电子电路设计问题，如电路优化、灵活性分析等。<details>
<summary>Abstract</summary>
Electrical circuits are present in a variety of technologies, making their design an important part of computer aided engineering. The growing number of tunable parameters that affect the final design leads to a need for new approaches of quantifying their impact. Machine learning may play a key role in this regard, however current approaches often make suboptimal use of existing knowledge about the system at hand. In terms of circuits, their description via modified nodal analysis is well-understood. This particular formulation leads to systems of differential-algebraic equations (DAEs) which bring with them a number of peculiarities, e.g. hidden constraints that the solution needs to fulfill. We aim to use the recently introduced dissection concept for DAEs that can decouple a given system into ordinary differential equations, only depending on differential variables, and purely algebraic equations that describe the relations between differential and algebraic variables. The idea then is to only learn the differential variables and reconstruct the algebraic ones using the relations from the decoupling. This approach guarantees that the algebraic constraints are fulfilled up to the accuracy of the nonlinear system solver, which represents the main benefit highlighted in this article.
</details>
<details>
<summary>摘要</summary>
电路设计是现代工程设计中的一个重要组成部分。随着参数的增加，电路设计的最终结果的影响需要新的方法来衡量其影响。机器学习可能会在这个领域发挥关键作用，但现有的方法常常不充分利用现有系统的知识。在电路方面，使用修改后的节点分析来描述电路是非常好的。这种形式化导致系统拥有偏微分方程（DAE），这些DAE具有一些特点，例如隐藏的约束，解决方案需要满足这些约束。我们想使用最近引入的分割概念来处理DAE，将系统分解成仅依赖于偏微分变量的普通偏微分方程，并且使用系统的关系来重建代数变量。这种方法保证了代数约束的满足，直到非线性系统解决器的精度，这是本文的主要优点。
</details></li>
</ul>
<hr>
<h2 id="Emergent-Linear-Representations-in-World-Models-of-Self-Supervised-Sequence-Models"><a href="#Emergent-Linear-Representations-in-World-Models-of-Self-Supervised-Sequence-Models" class="headerlink" title="Emergent Linear Representations in World Models of Self-Supervised Sequence Models"></a>Emergent Linear Representations in World Models of Self-Supervised Sequence Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00941">http://arxiv.org/abs/2309.00941</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ajyl/mech_int_othellogpt">https://github.com/ajyl/mech_int_othellogpt</a></li>
<li>paper_authors: Neel Nanda, Andrew Lee, Martin Wattenberg</li>
<li>for: 这 paper 是 investigate how sequence models represent their decision-making process, and provide evidence of a closely related linear representation of the board state.</li>
<li>methods: 这 paper 使用 Othello-playing neural network, and use probing to understand the model’s internal state.</li>
<li>results: 这 paper 得到了一个简单 yet powerful way to interpret the model’s internal state, and demonstrate that linear representations enable significant interpretability progress.Here’s the full text in Simplified Chinese:</li>
<li>for: 这 paper 是 investigate how sequence models represent their decision-making process, 和提供 evidence of a closely related linear representation of the board state.</li>
<li>methods: 这 paper 使用 Othello-playing neural network, 并使用 probing 来理解模型的内部状态.</li>
<li>results: 这 paper 得到了一个简单 yet powerful way to interpret the model’s internal state, 并 demonstrates that linear representations enable significant interpretability progress.<details>
<summary>Abstract</summary>
How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for "my colour" vs. "opponent's colour" may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for 'my colour' vs. 'opponent's colour' may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed." into Chinese (Simplified)Answer:sequence models的决策过程是如何表示？先前的工作表明，抽象棋盘 neural network 学习了非线性模型（Li et al., 2023）。在这项工作中，我们提供了一种相关的直线表示，具体来说，我们表明了 probing for "我的颜色" vs. "对手的颜色" 可能是一种简单却强大的内部状态的解释方法。这种精确的内部表示允许我们通过简单的矢量算术控制模型的行为。直线表示具有显著的可读性进步，我们通过进一步探索世界模型如何计算来证明这一点。
</details></li>
</ul>
<hr>
<h2 id="Short-term-power-load-forecasting-method-based-on-CNN-SAEDN-Res"><a href="#Short-term-power-load-forecasting-method-based-on-CNN-SAEDN-Res" class="headerlink" title="Short-term power load forecasting method based on CNN-SAEDN-Res"></a>Short-term power load forecasting method based on CNN-SAEDN-Res</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07140">http://arxiv.org/abs/2309.07140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Cui, Han Zhu, Yijian Wang, Lu Zhang, Yang Li</li>
<li>for: 这篇研究目的是提出一种基于卷积神经网络、自注意编码器-解码器网络和差分优化（Res）的短期载电预测方法，以解决传统序列模型对于非时序因素资料的处理问题，提高预测精度。</li>
<li>methods: 本方法的特点包括使用两维卷积神经网络进行特征提取，并使用自注意编码器-解码器网络和差分优化模组进行预测。自注意编码器可以将高维特征转换为全局相互关联的数据，而差分优化模组可以确保预测结果的稳定性。</li>
<li>results:  simulation 结果显示，提出的载电预测方法在预测精度和预测稳定性方面具有明显的优势，比较之前的方法更能够捕捉非时序因素资料中的相互关联。<details>
<summary>Abstract</summary>
In deep learning, the load data with non-temporal factors are difficult to process by sequence models. This problem results in insufficient precision of the prediction. Therefore, a short-term load forecasting method based on convolutional neural network (CNN), self-attention encoder-decoder network (SAEDN) and residual-refinement (Res) is proposed. In this method, feature extraction module is composed of a two-dimensional convolutional neural network, which is used to mine the local correlation between data and obtain high-dimensional data features. The initial load fore-casting module consists of a self-attention encoder-decoder network and a feedforward neural network (FFN). The module utilizes self-attention mechanisms to encode high-dimensional features. This operation can obtain the global correlation between data. Therefore, the model is able to retain important information based on the coupling relationship between the data in data mixed with non-time series factors. Then, self-attention decoding is per-formed and the feedforward neural network is used to regression initial load. This paper introduces the residual mechanism to build the load optimization module. The module generates residual load values to optimize the initial load. The simulation results show that the proposed load forecasting method has advantages in terms of prediction accuracy and prediction stability.
</details>
<details>
<summary>摘要</summary>
在深度学习中，带有非时序因素的数据加载具有困难处理序列模型的问题。这种问题导致预测精度不够。因此，一种基于卷积神经网络（CNN）、自注意编码器解码网络（SAEDN）和剩余级修正（Res）的短期电力预测方法被提出。在这种方法中，特征提取模块由两维卷积神经网络组成，用于挖掘数据中的本地相关性，并从而获得高维数据特征。初始电力预测模块包括自注意编码器解码网络和Feedforward神经网络（FFN）。这个模块使用自注意机制编码高维特征，从而获得数据之间的全局相关性。因此，模型能够保留数据混合非时序因素的重要信息。然后，自注意解码被执行，并使用Feedforward神经网络进行回归初始电力。本文介绍了剩余机制来建立电力优化模块。该模块生成剩余电力值，以优化初始电力。实验结果显示，提议的电力预测方法具有更高的预测精度和预测稳定性。
</details></li>
</ul>
<hr>
<h2 id="A-Multi-Head-Ensemble-Multi-Task-Learning-Approach-for-Dynamical-Computation-Offloading"><a href="#A-Multi-Head-Ensemble-Multi-Task-Learning-Approach-for-Dynamical-Computation-Offloading" class="headerlink" title="A Multi-Head Ensemble Multi-Task Learning Approach for Dynamical Computation Offloading"></a>A Multi-Head Ensemble Multi-Task Learning Approach for Dynamical Computation Offloading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00907">http://arxiv.org/abs/2309.00907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiyu3816/MTFNN-CO">https://github.com/qiyu3816/MTFNN-CO</a></li>
<li>paper_authors: Ruihuai Liang, Bo Yang, Zhiwen Yu, Xuelin Cao, Derrick Wing Kwan Ng, Chau Yuen</li>
<li>for: 这个研究旨在设计一个优化的负载协调策略，以提高移动 Multi-Access Edge Computing (MEC) 的性能。</li>
<li>methods: 这个研究使用了一个混合数据类型的非线性计划 (MINLP) 问题，并使用了一个深度神经网络 (DNN) 模型进行线上推导。</li>
<li>results: 这个研究所得到的结果显示，使用了多头组合多任务学习 (MEMTL) 方法可以对时间变化的环境进行快速的解决，并且可以实现高精度的推导。<details>
<summary>Abstract</summary>
Computation offloading has become a popular solution to support computationally intensive and latency-sensitive applications by transferring computing tasks to mobile edge servers (MESs) for execution, which is known as mobile/multi-access edge computing (MEC). To improve the MEC performance, it is required to design an optimal offloading strategy that includes offloading decision (i.e., whether offloading or not) and computational resource allocation of MEC. The design can be formulated as a mixed-integer nonlinear programming (MINLP) problem, which is generally NP-hard and its effective solution can be obtained by performing online inference through a well-trained deep neural network (DNN) model. However, when the system environments change dynamically, the DNN model may lose efficacy due to the drift of input parameters, thereby decreasing the generalization ability of the DNN model. To address this unique challenge, in this paper, we propose a multi-head ensemble multi-task learning (MEMTL) approach with a shared backbone and multiple prediction heads (PHs). Specifically, the shared backbone will be invariant during the PHs training and the inferred results will be ensembled, thereby significantly reducing the required training overhead and improving the inference performance. As a result, the joint optimization problem for offloading decision and resource allocation can be efficiently solved even in a time-varying wireless environment. Experimental results show that the proposed MEMTL outperforms benchmark methods in both the inference accuracy and mean square error without requiring additional training data.
</details>
<details>
<summary>摘要</summary>
computation offloading 已成为支持 computationally intensive 和延迟敏感应用的受欢迎解决方案，通过将计算任务传输到 mobil edge server (MES) 进行执行，这被称为 mobil/多 access edge computing (MEC)。为了提高 MEC 性能，需要设计一个优化的卸载策略，包括卸载决策（是否卸载）和 MEC 的计算资源分配。该设计可以表示为混合整数非线性编程 (MINLP) 问题，通常是NP-hard 的，其有效解决方法是通过在训练了深度神经网络 (DNN) 模型的线上推理进行获取。然而，当系统环境变化 dynamically 时，DNN 模型可能会失去有效性，因为输入参数的漂移，从而降低 DNN 模型的泛化能力。为解决这个特殊挑战，在这篇论文中，我们提出了一种多头集合多任务学习 (MEMTL) 方法，其特点是共享脊梁和多个预测头 (PH)。具体来说，共享脊梁在 PH 训练时保持不变，并将推理结果ensemble，从而减少了训练负担和提高了推理性能。因此，在时变无线环境中，可以效率地解决卸载决策和资源分配的共优化问题。实验结果表明，提出的 MEMTL 方法在推理准确率和平均方差Error 方面具有显著优势，而无需更多的训练数据。
</details></li>
</ul>
<hr>
<h2 id="Discovering-Predictive-Relational-Object-Symbols-with-Symbolic-Attentive-Layers"><a href="#Discovering-Predictive-Relational-Object-Symbols-with-Symbolic-Attentive-Layers" class="headerlink" title="Discovering Predictive Relational Object Symbols with Symbolic Attentive Layers"></a>Discovering Predictive Relational Object Symbols with Symbolic Attentive Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00889">http://arxiv.org/abs/2309.00889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alper Ahmetoglu, Batuhan Celik, Erhan Oztop, Emre Ugur</li>
<li>for: 这项研究的目的是开发一种新的深度学习架构，用于自动发现对象和其关系的符号表示。</li>
<li>methods: 该模型使用了一个自我注意层，计算了对象特征中的关注量，并将关注量用于对象符号的聚合和行为效果预测。</li>
<li>results: 实验表明，该模型在一个 simulate 的表格环境中，能够更好地预测行为效果，同时同时自动发现对象符号和关系符号。分析表明，学习的符号与表格环境中对象之间的相对位置、物品类型和横向Alignment有关。<details>
<summary>Abstract</summary>
In this paper, we propose and realize a new deep learning architecture for discovering symbolic representations for objects and their relations based on the self-supervised continuous interaction of a manipulator robot with multiple objects on a tabletop environment. The key feature of the model is that it can handle a changing number number of objects naturally and map the object-object relations into symbolic domain explicitly. In the model, we employ a self-attention layer that computes discrete attention weights from object features, which are treated as relational symbols between objects. These relational symbols are then used to aggregate the learned object symbols and predict the effects of executed actions on each object. The result is a pipeline that allows the formation of object symbols and relational symbols from a dataset of object features, actions, and effects in an end-to-end manner. We compare the performance of our proposed architecture with state-of-the-art symbol discovery methods in a simulated tabletop environment where the robot needs to discover symbols related to the relative positions of objects to predict the observed effect successfully. Our experiments show that the proposed architecture performs better than other baselines in effect prediction while forming not only object symbols but also relational symbols. Furthermore, we analyze the learned symbols and relational patterns between objects to learn about how the model interprets the environment. Our analysis shows that the learned symbols relate to the relative positions of objects, object types, and their horizontal alignment on the table, which reflect the regularities in the environment.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的深度学习架构，用于从自适应的 kontinuous 互动中找到对象和它们之间的关系的符号表示。这个模型的关键特点是可以自然地处理变化数量的对象，并将对象之间的关系Explicitly map到符号领域中。在模型中，我们使用了一层自注意力层，从对象特征中计算出精确的注意力权重，这些注意力权重被视为对象之间的关系符号。这些关系符号然后用于聚合学习的对象符号和预测对象上执行的效果。这个管道可以从对象特征、动作和效果的数据集中形成对象符号和关系符号，并在端到端的方式下进行结构化的符号探索。我们与其他基eline进行比较，并在模拟的桌面环境中证明了我们提出的架构的性能比其他基eline更好，可以成功预测对象之间的关系和效果。此外，我们分析了模型中学习的符号和对象之间的关系，发现符号与对象的相对位置、对象类型和桌面上的水平对齐有关，这些符号与环境中的常见性相符。
</details></li>
</ul>
<hr>
<h2 id="Tight-Bounds-for-Machine-Unlearning-via-Differential-Privacy"><a href="#Tight-Bounds-for-Machine-Unlearning-via-Differential-Privacy" class="headerlink" title="Tight Bounds for Machine Unlearning via Differential Privacy"></a>Tight Bounds for Machine Unlearning via Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00886">http://arxiv.org/abs/2309.00886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyang Huang, Clément L. Canonne</li>
<li>for: 这个论文探讨了一种名为”机器忘记”的概念，即在训练数据中删除一些点的问题。</li>
<li>methods: 作者使用了幂等私钥技术（DP）来实现机器忘记。</li>
<li>results: 作者 closing the gap between upper and lower bounds on the deletion capacity of DP-based machine unlearning algorithms, obtaining tight bounds on the deletion capacity achievable by these algorithms.<details>
<summary>Abstract</summary>
We consider the formulation of "machine unlearning" of Sekhari, Acharya, Kamath, and Suresh (NeurIPS 2021), which formalizes the so-called "right to be forgotten" by requiring that a trained model, upon request, should be able to "unlearn" a number of points from the training data, as if they had never been included in the first place. Sekhari et al. established some positive and negative results about the number of data points that can be successfully unlearnt by a trained model without impacting the model's accuracy (the "deletion capacity"), showing that machine unlearning could be achieved by using differentially private (DP) algorithms. However, their results left open a gap between upper and lower bounds on the deletion capacity of these algorithms: our work fully closes this gap, obtaining tight bounds on the deletion capacity achievable by DP-based machine unlearning algorithms.
</details>
<details>
<summary>摘要</summary>
我团队考虑了Sekhari等人（NeurIPS 2021）所提出的机器“忘记” formalization，即要求已经训练过的模型，在请求时，能够“忘记”一些训练数据点，如果这些点从来没有被包含在模型中。Sekhari等人确立了一些积极和消极结果，表明可以通过使用匿名隐私（DP）算法实现机器忘记。然而，他们的结果留下了一个DP算法的删除容量（deletion capacity）的上下限之间的差距：我们的工作完全关闭了这个差距，得到了DP基于的机器忘记算法的精确 deletion capacity 上限。
</details></li>
</ul>
<hr>
<h2 id="Towards-Certified-Probabilistic-Robustness-with-High-Accuracy"><a href="#Towards-Certified-Probabilistic-Robustness-with-High-Accuracy" class="headerlink" title="Towards Certified Probabilistic Robustness with High Accuracy"></a>Towards Certified Probabilistic Robustness with High Accuracy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00879">http://arxiv.org/abs/2309.00879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruihan Zhang, Peixin Zhang, Jun Sun</li>
<li>for: This paper aims to build certifiably robust yet accurate neural network models, which is an open problem in the field of adversarial examples.</li>
<li>methods: The proposed approach consists of two parts: a probabilistic robust training method that minimizes variance in terms of divergence, and a runtime inference method for certified probabilistic robustness of the prediction.</li>
<li>results: The proposed approach significantly outperforms existing approaches in terms of both certification rate and accuracy, and is reasonably efficient. The approach works for a variety of perturbations and is applicable to multiple models trained on different datasets.<details>
<summary>Abstract</summary>
Adversarial examples pose a security threat to many critical systems built on neural networks (such as face recognition systems, and self-driving cars). While many methods have been proposed to build robust models, how to build certifiably robust yet accurate neural network models remains an open problem. For example, adversarial training improves empirical robustness, but they do not provide certification of the model's robustness. On the other hand, certified training provides certified robustness but at the cost of a significant accuracy drop. In this work, we propose a novel approach that aims to achieve both high accuracy and certified probabilistic robustness. Our method has two parts, i.e., a probabilistic robust training method with an additional goal of minimizing variance in terms of divergence and a runtime inference method for certified probabilistic robustness of the prediction. The latter enables efficient certification of the model's probabilistic robustness at runtime with statistical guarantees. This is supported by our training objective, which minimizes the variance of the model's predictions in a given vicinity, derived from a general definition of model robustness. Our approach works for a variety of perturbations and is reasonably efficient. Our experiments on multiple models trained on different datasets demonstrate that our approach significantly outperforms existing approaches in terms of both certification rate and accuracy.
</details>
<details>
<summary>摘要</summary>
遭遇攻击性示例对许多基于神经网络的重要系统（如识别面部系统和自动驾驶车）的安全性带来了威胁。许多方法已经被提出来建立坚固的模型，但是如何建立认证可靠且精确的神经网络模型仍然是一个开启的问题。例如，敌对训练可以提高了实际的抗衡能力，但它们不会提供模型的认证 robustness。另一方面，认证训练则可以提供认证的 robustness，但是它们会导致模型的精确度下降。在这个工作中，我们提出了一个新的方法，旨在实现高精确度和认证可靠的神经网络模型。我们的方法有两部分：一个是一种概率 robust 的训练方法，另一个是一种runtime inference方法，用于认证模型的概率 robustness。这个方法可以实现在不同类型的攻击下，且是相对高效的。我们在多个模型和不同的数据集上进行了实验，结果显示，我们的方法在认证率和精确度两方面都大大超过了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Pretraining-Representations-for-Bioacoustic-Few-shot-Detection-using-Supervised-Contrastive-Learning"><a href="#Pretraining-Representations-for-Bioacoustic-Few-shot-Detection-using-Supervised-Contrastive-Learning" class="headerlink" title="Pretraining Representations for Bioacoustic Few-shot Detection using Supervised Contrastive Learning"></a>Pretraining Representations for Bioacoustic Few-shot Detection using Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00878">http://arxiv.org/abs/2309.00878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ilyassmoummad/dcase23_task5_scl">https://github.com/ilyassmoummad/dcase23_task5_scl</a></li>
<li>paper_authors: Ilyass Moummad, Romain Serizel, Nicolas Farrugia</li>
<li>for: 这个论文的目的是提出一种基于几何学习的听写音频数据分类方法，以解决生物听音应用中的听音事件检测问题。</li>
<li>methods: 该方法利用了数据增强和监睹学习框架，从零开始学习一个精彩特征提取器。</li>
<li>results: 该方法在验证集上获得了63.46%的F1分数，在测试集上获得了42.7%的F1分数，在DCASE挑战中名列第二。<details>
<summary>Abstract</summary>
Deep learning has been widely used recently for sound event detection and classification. Its success is linked to the availability of sufficiently large datasets, possibly with corresponding annotations when supervised learning is considered. In bioacoustic applications, most tasks come with few labelled training data, because annotating long recordings is time consuming and costly. Therefore supervised learning is not the best suited approach to solve bioacoustic tasks. The bioacoustic community recasted the problem of sound event detection within the framework of few-shot learning, i.e. training a system with only few labeled examples. The few-shot bioacoustic sound event detection task in the DCASE challenge focuses on detecting events in long audio recordings given only five annotated examples for each class of interest. In this paper, we show that learning a rich feature extractor from scratch can be achieved by leveraging data augmentation using a supervised contrastive learning framework. We highlight the ability of this framework to transfer well for five-shot event detection on previously unseen classes in the training data. We obtain an F-score of 63.46\% on the validation set and 42.7\% on the test set, ranking second in the DCASE challenge. We provide an ablation study for the critical choices of data augmentation techniques as well as for the learning strategy applied on the training set.
</details>
<details>
<summary>摘要</summary>
现代深度学习技术在声音事件检测和分类方面得到了广泛应用。其成功与具有足够大的数据集，可能带有相应的注释时supervised learning是考虑的。在生物声学应用中，大多数任务都有少量标注的训练数据，因为注释长录音是时间consuming和costly。因此，supervised learning不是解决生物声学任务的最佳方法。生物声学社区将声音事件检测问题重新定义为few-shot learning问题，即使用只有几个标注的示例来训练系统。DCASE挑战中的声音事件检测五个难题中的few-shot bioacoustic sound event detection task是检测长录音中的事件，只需五个标注示例。在这篇论文中，我们表明了可以通过利用数据增强和supervised contrastive learning框架来学习rich feature extractor从scratch。我们指出了这种框架的可轻 Transfer Learning，能够在未看过的类型上进行五个shot事件检测。我们在验证集上取得了63.46%的F-score和42.7%的测试集F-score，在DCASE挑战中排名第二。我们还提供了关键的数据增强技术和训练集上的学习策略的ablation study。
</details></li>
</ul>
<hr>
<h2 id="Tutorial-a-priori-estimation-of-sample-size-effect-size-and-statistical-power-for-cluster-analysis-latent-class-analysis-and-multivariate-mixture-models"><a href="#Tutorial-a-priori-estimation-of-sample-size-effect-size-and-statistical-power-for-cluster-analysis-latent-class-analysis-and-multivariate-mixture-models" class="headerlink" title="Tutorial: a priori estimation of sample size, effect size, and statistical power for cluster analysis, latent class analysis, and multivariate mixture models"></a>Tutorial: a priori estimation of sample size, effect size, and statistical power for cluster analysis, latent class analysis, and multivariate mixture models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00866">http://arxiv.org/abs/2309.00866</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/esdalmaijer/cluster_power_tutorial">https://github.com/esdalmaijer/cluster_power_tutorial</a></li>
<li>paper_authors: Edwin S Dalmaijer</li>
<li>For: The paper is written for researchers who want to determine the sample size and effect size for analyses that identify subgroups.* Methods: The paper provides a roadmap for determining sample size and effect size using a procedure that formalizes expectations about effect sizes in a specific domain, and establishes the minimum sample size for subgroup analyses using simulations.* Results: The paper provides a reference table for the most popular subgroup analyses, including k-means, Ward agglomerative hierarchical clustering, c-means fuzzy clustering, latent class analysis, latent profile analysis, and Gaussian mixture modeling. The table shows the minimum numbers of observations per expected subgroup and features to achieve acceptable statistical power.<details>
<summary>Abstract</summary>
Before embarking on data collection, researchers typically compute how many individual observations they should do. This is vital for doing studies with sufficient statistical power, and often a cornerstone in study pre-registrations and grant applications. For traditional statistical tests, one would typically determine an acceptable level of statistical power, (gu)estimate effect size, and then use both values to compute the required sample size. However, for analyses that identify subgroups, statistical power is harder to establish. Once sample size reaches a sufficient threshold, effect size is primarily determined by the number of measured features and the underlying subgroup separation. As a consequence, a priory computations of statistical power are notoriously complex. In this tutorial, I will provide a roadmap to determining sample size and effect size for analyses that identify subgroups. First, I introduce a procedure that allows researchers to formalise their expectations about effect sizes in their domain of choice, and use this to compute the minimally required number of measured variables. Next, I outline how to establish the minimum sample size in subgroup analyses. Finally, I use simulations to provide a reference table for the most popular subgroup analyses: k-means, Ward agglomerative hierarchical clustering, c-means fuzzy clustering, latent class analysis, latent profile analysis, and Gaussian mixture modelling. The table shows the minimum numbers of observations per expected subgroup (sample size) and features (measured variables) to achieve acceptable statistical power, and can be readily used in study design.
</details>
<details>
<summary>摘要</summary>
Before starting data collection, researchers usually calculate how many individual observations they should collect. This is crucial for conducting studies with sufficient statistical power, and is often a key component of study pre-registrations and grant applications. For traditional statistical tests, one would typically determine an acceptable level of statistical power, estimate effect size, and then use both values to compute the required sample size. However, for analyses that identify subgroups, statistical power is more difficult to establish. Once the sample size reaches a sufficient threshold, effect size is primarily determined by the number of measured features and the underlying subgroup separation. As a consequence, a priori computations of statistical power are notoriously complex. In this tutorial, I will provide a roadmap to determining sample size and effect size for analyses that identify subgroups. First, I introduce a procedure that allows researchers to formalize their expectations about effect sizes in their domain of choice, and use this to compute the minimally required number of measured variables. Next, I outline how to establish the minimum sample size in subgroup analyses. Finally, I use simulations to provide a reference table for the most popular subgroup analyses: k-means, Ward agglomerative hierarchical clustering, c-means fuzzy clustering, latent class analysis, latent profile analysis, and Gaussian mixture modeling. The table shows the minimum numbers of observations per expected subgroup (sample size) and features (measured variables) to achieve acceptable statistical power, and can be readily used in study design.
</details></li>
</ul>
<hr>
<h2 id="DoRA-Domain-Based-Self-Supervised-Learning-Framework-for-Low-Resource-Real-Estate-Appraisal"><a href="#DoRA-Domain-Based-Self-Supervised-Learning-Framework-for-Low-Resource-Real-Estate-Appraisal" class="headerlink" title="DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal"></a>DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00855">http://arxiv.org/abs/2309.00855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wwweiwei/dora">https://github.com/wwweiwei/dora</a></li>
<li>paper_authors: Wei-Wei Du, Wei-Yao Wang, Wen-Chih Peng</li>
<li>for: 这个论文旨在提供一种基于领域知识的自我监督学习框架，用于低资源的不动产评估。</li>
<li>methods: 该模型使用内样本地理预测作为预tex task，并使用 между样本对比学习来增强表示的泛化能力。</li>
<li>results: 对实际交易数据进行测试，该模型在几 shot enario下显著超过了基于数据表格的SSL基线、图形基本方法和指导方法。<details>
<summary>Abstract</summary>
The marketplace system connecting demands and supplies has been explored to develop unbiased decision-making in valuing properties. Real estate appraisal serves as one of the high-cost property valuation tasks for financial institutions since it requires domain experts to appraise the estimation based on the corresponding knowledge and the judgment of the market. Existing automated valuation models reducing the subjectivity of domain experts require a large number of transactions for effective evaluation, which is predominantly limited to not only the labeling efforts of transactions but also the generalizability of new developing and rural areas. To learn representations from unlabeled real estate sets, existing self-supervised learning (SSL) for tabular data neglects various important features, and fails to incorporate domain knowledge. In this paper, we propose DoRA, a Domain-based self-supervised learning framework for low-resource Real estate Appraisal. DoRA is pre-trained with an intra-sample geographic prediction as the pretext task based on the metadata of the real estate for equipping the real estate representations with prior domain knowledge. Furthermore, inter-sample contrastive learning is employed to generalize the representations to be robust for limited transactions of downstream tasks. Our benchmark results on three property types of real-world transactions show that DoRA significantly outperforms the SSL baselines for tabular data, the graph-based methods, and the supervised approaches in the few-shot scenarios by at least 7.6% for MAPE, 11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other financial practitioners with similar marketplace applications who need general models for properties that are newly built and have limited records. The source code is available at https://github.com/wwweiwei/DoRA.
</details>
<details>
<summary>摘要</summary>
marketplace系统连接需求和供应，以发展不偏袋折的决策方法。房地产评估作为高成本房产评估任务，需要域专家根据相关知识和市场判断来进行估价。现有的自动评估模型可以减少域专家的主观性，但它们需要大量的交易数据进行有效评估，这是限制了不仅标注努力，还限制了新规划和农村地区的普适性。为了学习不标注的房地产集合中的表示，现有的自动学习（SSL）技术对于表格数据 neglects 多种重要特征，并且无法包含域知识。在这篇论文中，我们提出了DoRA，一种基于域的自动学习框架，用于低资源房地产评估。DoRA通过 metadata 中的地理预测任务进行预训练，以具备房地产表示的先验知识。此外，我们还使用了交叉样本学习来使表示扩展到有限交易下的稳定性。我们对实际交易中的三种不同类型的财产进行了测试，结果显示DoRA在几个shot scenario下明显超过了SSL基线、图表基eline和批处理方法的性能，提高了MAPЭ、MAE和HR10的性能。我们预计DoRA将对其他金融实践人员有用，他们需要面临新建和有限记录的财产评估模型。代码可以在 <https://github.com/wwweiwei/DoRA> 获取。
</details></li>
</ul>
<hr>
<h2 id="A-Unifying-Variational-Framework-for-Gaussian-Process-Motion-Planning"><a href="#A-Unifying-Variational-Framework-for-Gaussian-Process-Motion-Planning" class="headerlink" title="A Unifying Variational Framework for Gaussian Process Motion Planning"></a>A Unifying Variational Framework for Gaussian Process Motion Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00854">http://arxiv.org/abs/2309.00854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Cosier, Rares Iordan, Sicelukwanda Zwane, Giovanni Franzese, James T. Wilson, Marc Peter Deisenroth, Alexander Terenin, Yasemin Bekiroglu</li>
<li>for: 本文为了提出一种基于Variational Gaussian Processes的机器人运动规划框架，以解决机器人运动规划问题中的各种约束和不确定性问题。</li>
<li>methods: 本文使用Variational Gaussian Processes来处理机器人运动规划问题，并提出了一种结合概率推理的框架来处理等式、不等式和软运动约束。</li>
<li>results: 实验结果表明， compared to基准方法，本文提出的方法可以更好地平衡成功率和运动规划质量。<details>
<summary>Abstract</summary>
To control how a robot moves, motion planning algorithms must compute paths in high-dimensional state spaces while accounting for physical constraints related to motors and joints, generating smooth and stable motions, avoiding obstacles, and preventing collisions. A motion planning algorithm must therefore balance competing demands, and should ideally incorporate uncertainty to handle noise, model errors, and facilitate deployment in complex environments. To address these issues, we introduce a framework for robot motion planning based on variational Gaussian Processes, which unifies and generalizes various probabilistic-inference-based motion planning algorithms. Our framework provides a principled and flexible way to incorporate equality-based, inequality-based, and soft motion-planning constraints during end-to-end training, is straightforward to implement, and provides both interval-based and Monte-Carlo-based uncertainty estimates. We conduct experiments using different environments and robots, comparing against baseline approaches based on the feasibility of the planned paths, and obstacle avoidance quality. Results show that our proposed approach yields a good balance between success rates and path quality.
</details>
<details>
<summary>摘要</summary>
要控制 robot 的移动，动作规划算法需要计算高维状态空间中的路径，同时考虑到机械制约和 JOINTS 的物理约束，生成平滑和稳定的动作，避免障碍物和冲突。一个动作规划算法应该平衡竞合的需求，并应该包含不确定性，以处理噪声、模型错误和复杂环境中的部署。为解决这些问题，我们介绍了基于Variational Gaussian Processes的机器人动作规划框架，这个框架统一和总结了各种基于概率推理的动作规划算法。我们的框架可以在终端训练中采用等价、不等价和软动作规划约束，并提供了间隔型和Monte Carlo 类型的不确定性估计。我们在不同的环境和机器人上进行了实验，与基线方法进行比较，评价计划路径的可行性和避免障碍质量。结果表明，我们的提议方法可以获得良好的平衡，同时保证动作质量。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Soft-Tissue-Retraction-Using-Demonstration-Guided-Reinforcement-Learning"><a href="#Autonomous-Soft-Tissue-Retraction-Using-Demonstration-Guided-Reinforcement-Learning" class="headerlink" title="Autonomous Soft Tissue Retraction Using Demonstration-Guided Reinforcement Learning"></a>Autonomous Soft Tissue Retraction Using Demonstration-Guided Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00837">http://arxiv.org/abs/2309.00837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amritpal Singh, Wenqi Shi, May D Wang</li>
<li>for: 这个论文的目的是为了研究和开发一种能够处理软体的手术机器人系统。</li>
<li>methods: 这个论文使用了ROS相容的物理 simulate环境，以及使用示例导引学习（RL）算法来学习软体交互。</li>
<li>results: 这个研究实现了一种自动化手术软体压缩的方法，并证明了这种方法的可行性。<details>
<summary>Abstract</summary>
In the context of surgery, robots can provide substantial assistance by performing small, repetitive tasks such as suturing, needle exchange, and tissue retraction, thereby enabling surgeons to concentrate on more complex aspects of the procedure. However, existing surgical task learning mainly pertains to rigid body interactions, whereas the advancement towards more sophisticated surgical robots necessitates the manipulation of soft bodies. Previous work focused on tissue phantoms for soft tissue task learning, which can be expensive and can be an entry barrier to research. Simulation environments present a safe and efficient way to learn surgical tasks before their application to actual tissue. In this study, we create a Robot Operating System (ROS)-compatible physics simulation environment with support for both rigid and soft body interactions within surgical tasks. Furthermore, we investigate the soft tissue interactions facilitated by the patient-side manipulator of the DaVinci surgical robot. Leveraging the pybullet physics engine, we simulate kinematics and establish anchor points to guide the robotic arm when manipulating soft tissue. Using demonstration-guided reinforcement learning (RL) algorithms, we investigate their performance in comparison to traditional reinforcement learning algorithms. Our in silico trials demonstrate a proof-of-concept for autonomous surgical soft tissue retraction. The results corroborate the feasibility of learning soft body manipulation through the application of reinforcement learning agents. This work lays the foundation for future research into the development and refinement of surgical robots capable of managing both rigid and soft tissue interactions. Code is available at https://github.com/amritpal-001/tissue_retract.
</details>
<details>
<summary>摘要</summary>
在外科领域，机器人可以提供重要的协助，包括进行小、重复的任务，如缝合、针替换和组织吸引，以便外科医生能够更专注于更复杂的过程。然而，现有的外科任务学习主要关注坚体交互，而随着外科机器人的发展，需要涉及到软体的操作。之前的工作主要集中在假体中学习软组织任务，这可能会昂贵并成为研究入门障碍。在这种情况下，我们创建了ROS兼容的物理 simulate环境，并支持坚体和软体交互在外科任务中。此外，我们通过DaVinci外科机器人的病人侧把手 investigate软组织交互的可能性。通过pybullet物理引擎，我们模拟了机械学和确定了引导外科机器人的软组织 manipulate的anchor点。使用示例导引学习（RL）算法，我们研究其性能与传统RL算法相比。我们的室内实验结果表明，通过应用RL代理人，可以实现自主的外科软组织吸引。这些结果证明了在应用RL算法时，可以学习软体操作。这项工作为未来关于开发和改进外科机器人的研究提供了基础。代码可以在https://github.com/amritpal-001/tissue_retract中找到。
</details></li>
</ul>
<hr>
<h2 id="Approximating-Fair-k-Min-Sum-Radii-in-mathbb-R-d"><a href="#Approximating-Fair-k-Min-Sum-Radii-in-mathbb-R-d" class="headerlink" title="Approximating Fair $k$-Min-Sum-Radii in $\mathbb{R}^d$"></a>Approximating Fair $k$-Min-Sum-Radii in $\mathbb{R}^d$</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00834">http://arxiv.org/abs/2309.00834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Drexler, Annika Hennes, Abhiruk Lahiri, Melanie Schmidt, Julian Wargalla<br>for:* The paper is focused on the $k$-min-sum-radii problem in the context of fair clustering.methods:* The paper proposes a PTAS (Probably Approximately Correct) algorithm for the fair $k$-min-sum-radii problem in Euclidean spaces of arbitrary dimension, with a constant number of clusters $k$.results:* The proposed algorithm is the first PTAS for the fair $k$-min-sum-radii problem, and it works for different notions of group fairness.<details>
<summary>Abstract</summary>
The $k$-center problem is a classical clustering problem in which one is asked to find a partitioning of a point set $P$ into $k$ clusters such that the maximum radius of any cluster is minimized. It is well-studied. But what if we add up the radii of the clusters instead of only considering the cluster with maximum radius? This natural variant is called the $k$-min-sum-radii problem. It has become the subject of more and more interest in recent years, inspiring the development of approximation algorithms for the $k$-min-sum-radii problem in its plain version as well as in constrained settings.   We study the problem for Euclidean spaces $\mathbb{R}^d$ of arbitrary dimension but assume the number $k$ of clusters to be constant. In this case, a PTAS for the problem is known (see Bandyapadhyay, Lochet and Saurabh, SoCG, 2023). Our aim is to extend the knowledge base for $k$-min-sum-radii to the domain of fair clustering. We study several group fairness constraints, such as the one introduced by Chierichetti et al. (NeurIPS, 2017). In this model, input points have an additional attribute (e.g., colors such as red and blue), and clusters have to preserve the ratio between different attribute values (e.g., have the same fraction of red and blue points as the ground set). Different variants of this general idea have been studied in the literature. To the best of our knowledge, no approximative results for the fair $k$-min-sum-radii problem are known, despite the immense amount of work on the related fair $k$-center problem.   We propose a PTAS for the fair $k$-min-sum-radii problem in Euclidean spaces of arbitrary dimension for the case of constant $k$. To the best of our knowledge, this is the first PTAS for the problem. It works for different notions of group fairness.
</details>
<details>
<summary>摘要</summary>
“$k$-中心问题”是一个热门的聚集问题，要找到一个分 partitioning 方案，使得该集合中的各个对象的最大半径 minimized。这个问题已经很受欢迎，但如果我们总和所有对象的半径而不是仅考虑最大半径，这就是“$k$-min-sum-radii”问题。这个问题在最近的几年中已经引起了越来越多的关注，并且开发了访问算法。我们在 $\mathbb{R}^d$ 的任意维度上研究这个问题，并假设对象的数量是常数的。在这种情况下，我们知道PTAS的存在（见 Bandyapadhyay、Lochet 和 Saurabh， SoCG， 2023）。我们的目标是将这个知识库扩展到公平聚集领域。我们研究了许多公平聚集约束，例如 Chierichetti 等人（NeurIPS， 2017）提出的一种模型，在这个模型中，输入对象有一个额外的特征（例如颜色，如红色和蓝色），并且要求各个集合保持不同特征值的比例（例如输入集合中的红色和蓝色对象的比例和输入集合中的红色和蓝色对象的比例一样）。不同的这种一般的想法已经在文献中被研究。我们提出了一个PTAS для公平的 $k$-min-sum-radii 问题。这是我们知道的第一个PTAS。它适用于不同的公平性观念。
</details></li>
</ul>
<hr>
<h2 id="Trustworthiness-Driven-Graph-Convolutional-Networks-for-Signed-Network-Embedding"><a href="#Trustworthiness-Driven-Graph-Convolutional-Networks-for-Signed-Network-Embedding" class="headerlink" title="Trustworthiness-Driven Graph Convolutional Networks for Signed Network Embedding"></a>Trustworthiness-Driven Graph Convolutional Networks for Signed Network Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00816">http://arxiv.org/abs/2309.00816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kmj0792/trustsgcn">https://github.com/kmj0792/trustsgcn</a></li>
<li>paper_authors: Min-Jeong Kim, Yeon-Chang Lee, David Y. Kang, Sang-Wook Kim</li>
<li>for: 本文targets the problem of representing nodes in a signed network as low-dimensional vectors, and proposes a novel GCN-based approach named TrustSGCN to correct for incorrect embedding propagation.</li>
<li>methods: 本文提出了三个模块：生成每个节点的扩展 egonetwork（M1），测量边签信任度（M2），和基于信任度的协同嵌入传播（M3）。</li>
<li>results: 实验结果显示，TrustSGCN在四个真实的签名网络 dataset 上Consistently outperforms five state-of-the-art GCN-based SNE methods。<details>
<summary>Abstract</summary>
The problem of representing nodes in a signed network as low-dimensional vectors, known as signed network embedding (SNE), has garnered considerable attention in recent years. While several SNE methods based on graph convolutional networks (GCN) have been proposed for this problem, we point out that they significantly rely on the assumption that the decades-old balance theory always holds in the real-world. To address this limitation, we propose a novel GCN-based SNE approach, named as TrustSGCN, which corrects for incorrect embedding propagation in GCN by utilizing the trustworthiness on edge signs for high-order relationships inferred by the balance theory. The proposed approach consists of three modules: (M1) generation of each node's extended ego-network; (M2) measurement of trustworthiness on edge signs; and (M3) trustworthiness-aware propagation of embeddings. Furthermore, TrustSGCN learns the node embeddings by leveraging two well-known societal theories, i.e., balance and status. The experiments on four real-world signed network datasets demonstrate that TrustSGCN consistently outperforms five state-of-the-art GCN-based SNE methods. The code is available at https://github.com/kmj0792/TrustSGCN.
</details>
<details>
<summary>摘要</summary>
“简洁网络图（Signed Network）内的节点表示为低维Vector的问题，称为简洁网络嵌入（SNE），在最近的几年中受到了很大的关注。然而，许多基于图像润满网络（GCN）的SNE方法已经被提出，但是它们假设了现今已经很长时间的平衡理论应用于实际中。为了解决这个限制，我们提出了一个新的GCN基于的SNE方法，名为信任GCN（TrustSGCN），它通过使用对端标签的信任性来修正GCN中的嵌入传播。提案的方法包括三个模组：（M1）每个节点的扩展EGO网络的生成；（M2）根据端标签的信任性量度；以及（M3）基于信任性的嵌入传播。此外，TrustSGCN利用了社会学中两个著名的理论，即平衡和社会地位，来学习节点的嵌入。实验结果显示，TrustSGCN在四个真实的简洁网络数据集上显著地超越了五个现有的GCN基于的SNE方法。代码可以在https://github.com/kmj0792/TrustSGCN中找到。”
</details></li>
</ul>
<hr>
<h2 id="Fairness-Implications-of-Heterogeneous-Treatment-Effect-Estimation-with-Machine-Learning-Methods-in-Policy-making"><a href="#Fairness-Implications-of-Heterogeneous-Treatment-Effect-Estimation-with-Machine-Learning-Methods-in-Policy-making" class="headerlink" title="Fairness Implications of Heterogeneous Treatment Effect Estimation with Machine Learning Methods in Policy-making"></a>Fairness Implications of Heterogeneous Treatment Effect Estimation with Machine Learning Methods in Policy-making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00805">http://arxiv.org/abs/2309.00805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Rehill, Nicholas Biddle</li>
<li>for: The paper is written for governments trying to make and implement policy using causal machine learning methods, and for researchers and practitioners working in this area.</li>
<li>methods: The paper discusses the use of AI Fairness methods to protect against unintended consequences in machine learning models, but argues that these methods are not suitable for all causal machine learning applications. Instead, the paper proposes a definition of fairness for indirect decision-making scenarios, where the causal machine learning model only has indirect power.</li>
<li>results: The paper argues that the complexity of causal machine learning models can make it difficult to achieve fairness in policy-making, and suggests that careful modelling and awareness of decision-making biases are necessary to address this challenge.<details>
<summary>Abstract</summary>
Causal machine learning methods which flexibly generate heterogeneous treatment effect estimates could be very useful tools for governments trying to make and implement policy. However, as the critical artificial intelligence literature has shown, governments must be very careful of unintended consequences when using machine learning models. One way to try and protect against unintended bad outcomes is with AI Fairness methods which seek to create machine learning models where sensitive variables like race or gender do not influence outcomes. In this paper we argue that standard AI Fairness approaches developed for predictive machine learning are not suitable for all causal machine learning applications because causal machine learning generally (at least so far) uses modelling to inform a human who is the ultimate decision-maker while AI Fairness approaches assume a model that is making decisions directly. We define these scenarios as indirect and direct decision-making respectively and suggest that policy-making is best seen as a joint decision where the causal machine learning model usually only has indirect power. We lay out a definition of fairness for this scenario - a model that provides the information a decision-maker needs to accurately make a value judgement about just policy outcomes - and argue that the complexity of causal machine learning models can make this difficult to achieve. The solution here is not traditional AI Fairness adjustments, but careful modelling and awareness of some of the decision-making biases that these methods might encourage which we describe.
</details>
<details>
<summary>摘要</summary>
政府可以使用可变性机器学习方法来生成不同类型的干预效果估计，这些方法可能是政府制定和实施政策的有用工具。然而，根据人工智能文献所示，政府应该非常小心不良后果，因为机器学习模型可能会导致不良后果。一种方法是使用 AI Fairness 方法来创建不受敏感变量（如种族或性别）影响的机器学习模型。在这篇论文中，我们 argue That标准 AI Fairness 方法不适用于所有 causal machine learning 应用程序，因为 causal machine learning 通常（至少是）使用模型来告诉人类决策者做出决定。我们称这些场景为 indirect 和 direct 决策making 分别，并认为政策制定是 indirect 决策和 machine learning 模型通常只有 indirect 力量的共同决策。我们提出了一种公平定义 - 一个模型可以提供决策者准确地判断正确的政策结果的信息 - 并 argue  dass  causal machine learning 模型的复杂性可能使这困难实现。在这里，不是传统的 AI Fairness 调整，而是仔细的模型和决策BIAS 的认识，我们描述。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-and-Inverse-Problems"><a href="#Deep-Learning-and-Inverse-Problems" class="headerlink" title="Deep Learning and Inverse Problems"></a>Deep Learning and Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00802">http://arxiv.org/abs/2309.00802</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexpapados/Physics-Informed-Deep-Learning-Solid-and-Fluid-Mechanics">https://github.com/alexpapados/Physics-Informed-Deep-Learning-Solid-and-Fluid-Mechanics</a></li>
<li>paper_authors: Ali Mohammad-Djafari, Ning Chu, Li Wang, Liang Yu</li>
<li>for: 这篇论文主要用于探讨深度学习（DL）和神经网络（NN）在反问题上的应用。</li>
<li>methods: 本文使用了NN和DLsurrogate模型，以及approximate计算来解决反问题。</li>
<li>results: 本文描述了两种情况：首先，使用已知前进算子作为物理约束的情况，其次更一般的数据驱动DL方法。<details>
<summary>Abstract</summary>
Machine Learning (ML) methods and tools have gained great success in many data, signal, image and video processing tasks, such as classification, clustering, object detection, semantic segmentation, language processing, Human-Machine interface, etc. In computer vision, image and video processing, these methods are mainly based on Neural Networks (NN) and in particular Convolutional NN (CNN), and more generally Deep NN. Inverse problems arise anywhere we have indirect measurement. As, in general, those inverse problems are ill-posed, to obtain satisfactory solutions for them needs prior information. Different regularization methods have been proposed, where the problem becomes the optimization of a criterion with a likelihood term and a regularization term. The main difficulty, however, in great dimensional real applications, remains the computational cost. Using NN, and in particular Deep Learning (DL) surrogate models and approximate computation, can become very helpful. In this work, we focus on NN and DL particularly adapted for inverse problems. We consider two cases: First the case where the forward operator is known and used as physics constraint, the second more general data driven DL methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="League-of-Legends-Real-Time-Result-Prediction"><a href="#League-of-Legends-Real-Time-Result-Prediction" class="headerlink" title="League of Legends: Real-Time Result Prediction"></a>League of Legends: Real-Time Result Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02449">http://arxiv.org/abs/2309.02449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jailson B. S. Junior, Claudio E. C. Campelo</li>
<li>for: 这个研究旨在使用机器学习技术预测电子游戏League of Legends（LoL）的赛事结果。</li>
<li>methods: 这个研究使用了未发表数据作为基础，考虑了不同变量和比赛阶段，以探索实时预测的能力。</li>
<li>results: 研究发现LightGBM模型在比赛中阶段时间占60%-80%时的平均准确率达81.62%，而逻辑回归和梯度抽象模型在早期比赛阶段表现更佳，得到了推动性的结果。<details>
<summary>Abstract</summary>
This paper presents a study on the prediction of outcomes in matches of the electronic game League of Legends (LoL) using machine learning techniques. With the aim of exploring the ability to predict real-time results, considering different variables and stages of the match, we highlight the use of unpublished data as a fundamental part of this process. With the increasing popularity of LoL and the emergence of tournaments, betting related to the game has also emerged, making the investigation in this area even more relevant. A variety of models were evaluated and the results were encouraging. A model based on LightGBM showed the best performance, achieving an average accuracy of 81.62\% in intermediate stages of the match when the percentage of elapsed time was between 60\% and 80\%. On the other hand, the Logistic Regression and Gradient Boosting models proved to be more effective in early stages of the game, with promising results. This study contributes to the field of machine learning applied to electronic games, providing valuable insights into real-time prediction in League of Legends. The results obtained may be relevant for both players seeking to improve their strategies and the betting industry related to the game.
</details>
<details>
<summary>摘要</summary>
The study evaluated a variety of models, and the results were encouraging. A LightGBM-based model achieved an average accuracy of 81.62% in intermediate stages of the match, when the percentage of elapsed time was between 60% and 80%. On the other hand, Logistic Regression and Gradient Boosting models were more effective in early stages of the game, with promising results.This study contributes to the field of machine learning applied to electronic games, providing valuable insights into real-time prediction in League of Legends. The results obtained may be relevant for both players seeking to improve their strategies and the betting industry related to the game.Translation notes:* "electronic game" is translated as "电子游戏" (diàn xī yóu xì)* "League of Legends" is translated as "英雄联盟" (yīng xióng lián méng)* "machine learning techniques" is translated as "机器学习技术" (jī shī xué xí jì shù)* "real-time results" is translated as "实时结果" (shí jī jié guǒ)* "unpublished data" is translated as "未发布数据" (wèi fā bìu xiàng xì)* "betting industry" is translated as "赌博业" (jià bò yè)
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Modeling-with-Domain-conditioned-Prior-Guidance-for-Accelerated-MRI-and-qMRI-Reconstruction"><a href="#Diffusion-Modeling-with-Domain-conditioned-Prior-Guidance-for-Accelerated-MRI-and-qMRI-Reconstruction" class="headerlink" title="Diffusion Modeling with Domain-conditioned Prior Guidance for Accelerated MRI and qMRI Reconstruction"></a>Diffusion Modeling with Domain-conditioned Prior Guidance for Accelerated MRI and qMRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00783">http://arxiv.org/abs/2309.00783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanyu Bian, Albert Jang, Fang Liu</li>
<li>for: 这种方法是为了恢复图像，特别是在高速因素下进行恢复。</li>
<li>methods: 该方法基于一种吸引模型，该模型在数据领域中受到native数据的约束，并在频率和参数领域中使用域控制的扩散模型。使用了MRI物理学习 embeddings，以实现数据一致性和指导训练和抽样过程。</li>
<li>results: 该方法在多核磁共振和量化MRI恢复中显示出了显著的损害降低和精度保持，特别是在高速因素下。此外，该方法还可以在不同的解剖结构中维持高效率和准确性。<details>
<summary>Abstract</summary>
This study introduces a novel approach for image reconstruction based on a diffusion model conditioned on the native data domain. Our method is applied to multi-coil MRI and quantitative MRI reconstruction, leveraging the domain-conditioned diffusion model within the frequency and parameter domains. The prior MRI physics are used as embeddings in the diffusion model, enforcing data consistency to guide the training and sampling process, characterizing MRI k-space encoding in MRI reconstruction, and leveraging MR signal modeling for qMRI reconstruction. Furthermore, a gradient descent optimization is incorporated into the diffusion steps, enhancing feature learning and improving denoising. The proposed method demonstrates a significant promise, particularly for reconstructing images at high acceleration factors. Notably, it maintains great reconstruction accuracy and efficiency for static and quantitative MRI reconstruction across diverse anatomical structures. Beyond its immediate applications, this method provides potential generalization capability, making it adaptable to inverse problems across various domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Structured-Radial-Basis-Function-Network-Modelling-Diversity-for-Multiple-Hypotheses-Prediction"><a href="#Structured-Radial-Basis-Function-Network-Modelling-Diversity-for-Multiple-Hypotheses-Prediction" class="headerlink" title="Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction"></a>Structured Radial Basis Function Network: Modelling Diversity for Multiple Hypotheses Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00781">http://arxiv.org/abs/2309.00781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alejandro Rodriguez Dominguez, Muhammad Shahzad, Xia Hong</li>
<li>For: 这个研究旨在解决多modal regression问题，特别是预测非站ARY процес或具有复杂的混合分布。* Methods: 这个研究使用了一种组合多个假设预测器的结构化对�ishment（Radial Basis Function Network），并证明这个模型可以优化多个假设目标分布。* Results: 研究发现这个模型可以实现高度的普遍化表现和计算效率，并且只需使用两层神经网作为预测器即可控制多样性。此外，这个模型还可以使用梯度下降方法来实现损失无关的多个预测器。实验结果显示这个模型可以在Literature中优化表现。<details>
<summary>Abstract</summary>
Multi-modal regression is important in forecasting nonstationary processes or with a complex mixture of distributions. It can be tackled with multiple hypotheses frameworks but with the difficulty of combining them efficiently in a learning model. A Structured Radial Basis Function Network is presented as an ensemble of multiple hypotheses predictors for regression problems. The predictors are regression models of any type that can form centroidal Voronoi tessellations which are a function of their losses during training. It is proved that this structured model can efficiently interpolate this tessellation and approximate the multiple hypotheses target distribution and is equivalent to interpolating the meta-loss of the predictors, the loss being a zero set of the interpolation error. This model has a fixed-point iteration algorithm between the predictors and the centers of the basis functions. Diversity in learning can be controlled parametrically by truncating the tessellation formation with the losses of individual predictors. A closed-form solution with least-squares is presented, which to the authors knowledge, is the fastest solution in the literature for multiple hypotheses and structured predictions. Superior generalization performance and computational efficiency is achieved using only two-layer neural networks as predictors controlling diversity as a key component of success. A gradient-descent approach is introduced which is loss-agnostic regarding the predictors. The expected value for the loss of the structured model with Gaussian basis functions is computed, finding that correlation between predictors is not an appropriate tool for diversification. The experiments show outperformance with respect to the top competitors in the literature.
</details>
<details>
<summary>摘要</summary>
多Modal重要预测非站点过程或复杂的混合分布。它可以通过多个假设框架来解决，但是将其有效地结合到学习模型中是困难的。一种结构化圆拟函数网络是提出的一种多个假设预测器 ensemble for regression problems。这些预测器是任何类型的回归模型，可以形成中心 Voronoi 划分，这是在训练时的损失函数。 proved that this structured model can efficiently interpolate this tessellation and approximate the multiple hypotheses target distribution, and is equivalent to interpolating the meta-loss of the predictors, the loss being a zero set of the interpolation error. This model has a fixed-point iteration algorithm between the predictors and the centers of the basis functions. Diversity in learning can be controlled parametrically by truncating the tessellation formation with the losses of individual predictors. A closed-form solution with least-squares is presented, which to the authors' knowledge, is the fastest solution in the literature for multiple hypotheses and structured predictions. Using only two-layer neural networks as predictors, the model achieves superior generalization performance and computational efficiency, with diversity as a key component of success. A gradient-descent approach is introduced, which is loss-agnostic regarding the predictors. The expected value for the loss of the structured model with Gaussian basis functions is computed, finding that correlation between predictors is not an appropriate tool for diversification. Experimental results show outperformance with respect to the top competitors in the literature.
</details></li>
</ul>
<hr>
<h2 id="Non-Asymptotic-Bounds-for-Adversarial-Excess-Risk-under-Misspecified-Models"><a href="#Non-Asymptotic-Bounds-for-Adversarial-Excess-Risk-under-Misspecified-Models" class="headerlink" title="Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models"></a>Non-Asymptotic Bounds for Adversarial Excess Risk under Misspecified Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00771">http://arxiv.org/abs/2309.00771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changyu Liu, Yuling Jiao, Junhui Wang, Jian Huang</li>
<li>for: 评估 robust 估计器的性能based on adversarial losses under misspecified models.</li>
<li>methods: 使用 distributional adversarial attack 和 adversarial training 进行评估.</li>
<li>results: 提出了一种通用的评估方法，并Establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions.<details>
<summary>Abstract</summary>
We propose a general approach to evaluating the performance of robust estimators based on adversarial losses under misspecified models. We first show that adversarial risk is equivalent to the risk induced by a distributional adversarial attack under certain smoothness conditions. This ensures that the adversarial training procedure is well-defined. To evaluate the generalization performance of the adversarial estimator, we study the adversarial excess risk. Our proposed analysis method includes investigations on both generalization error and approximation error. We then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. In addition, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.
</details>
<details>
<summary>摘要</summary>
我们提出一个通用的方法来评估预测器在不准确模型下的性能，基于敌对损失函数。我们首先显示出敌对损失相等于对于某些紧缩条件的分布型敌对攻击带来的损失。这确保了敌对训练程序的定义性。然后，我们研究了对于预测器的敌对剩余损失，包括预测器的整合误差和近似误差。我们then establish non-asymptotic upper bounds for the adversarial excess risk associated with Lipschitz loss functions. Finally, we apply our general results to adversarial training for classification and regression problems. For the quadratic loss in nonparametric regression, we show that the adversarial excess risk bound can be improved over those for a general loss.Here's the text with some additional information about the terms used:* "预测器" (zhì wén zhī) refers to a predictor or an estimator.* "不准确模型" (bù jian shí mian) refers to a misspecified model.* "敌对损失函数" (dài tào shè yǐ jī) refers to the adversarial loss function.* "分布型敌对攻击" (fēn bù xīng dào) refers to a distributional adversarial attack.* "整合误差" (zhé yì bù yì) refers to the generalization error.* "近似误差" (jìn xiē bù yì) refers to the approximation error.* "Lipschitz loss functions" (Lipschitz loss functions) refer to a class of loss functions that are Lipschitz continuous.* "nonparametric regression" (nonparametric regression) refers to a type of regression analysis that does not make any assumptions about the underlying distribution of the data.
</details></li>
</ul>
<hr>
<h2 id="Physics-informed-machine-learning-of-the-correlation-functions-in-bulk-fluids"><a href="#Physics-informed-machine-learning-of-the-correlation-functions-in-bulk-fluids" class="headerlink" title="Physics-informed machine learning of the correlation functions in bulk fluids"></a>Physics-informed machine learning of the correlation functions in bulk fluids</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00767">http://arxiv.org/abs/2309.00767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqian Chen, Peiyuan Gao, Panos Stinis</li>
<li>for: 这篇论文主要用于解决粘性液体现代积分理论中的奥托-泽尼克方程。</li>
<li>methods: 这篇论文使用了机器学习模型，具体来说是物理学习激活函数和物理学习运算符网络，解决了奥托-泽尼克方程的前向和反向问题。</li>
<li>results: 机器学习模型在解决奥托-泽尼克方程的问题上表现了高精度和高效性，并且对液体热动力学理论的应用具有重要的潜在潜力。<details>
<summary>Abstract</summary>
The Ornstein-Zernike (OZ) equation is the fundamental equation for pair correlation function computations in the modern integral equation theory for liquids. In this work, machine learning models, notably physics-informed neural networks and physics-informed neural operator networks, are explored to solve the OZ equation. The physics-informed machine learning models demonstrate great accuracy and high efficiency in solving the forward and inverse OZ problems of various bulk fluids. The results highlight the significant potential of physics-informed machine learning for applications in thermodynamic state theory.
</details>
<details>
<summary>摘要</summary>
“欧兹方程”（Ornstein-Zernike equation）是现代流体 integral equation theory 中 Computational pair correlation function 的基本方程。在这项工作中，我们explore了机器学习模型，主要是physics-informed neural networks和physics-informed neural operator networks，来解决欧兹方程。这些physics-informed machine learning模型在解决前向和反向欧兹问题方面表现出了很高的准确率和高效性。结果表明physics-informed machine learning在热动力学状态理论中有广泛的应用前景。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.LG_2023_09_02/" data-id="clogxf3oc00nj5xrae0k01ybt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/eess.IV_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T09:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/eess.IV_2023_09_02/">eess.IV - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Cardiac-MRI-Segmentation-via-Classifier-Guided-Two-Stage-Network-and-All-Slice-Information-Fusion-Transformer"><a href="#Enhancing-Cardiac-MRI-Segmentation-via-Classifier-Guided-Two-Stage-Network-and-All-Slice-Information-Fusion-Transformer" class="headerlink" title="Enhancing Cardiac MRI Segmentation via Classifier-Guided Two-Stage Network and All-Slice Information Fusion Transformer"></a>Enhancing Cardiac MRI Segmentation via Classifier-Guided Two-Stage Network and All-Slice Information Fusion Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00800">http://arxiv.org/abs/2309.00800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zihao Chen, Xiao Chen, Yikang Liu, Eric Z. Chen, Terrence Chen, Shanhui Sun</li>
<li>for: 这项研究的目的是提高卡ди亚克力磁共振成像（CMR）图像中心心脏功能评估中的左心室（LV）、右心室（RV）和心肌（MYO）分割精度。</li>
<li>methods: 该研究提出了一种基于深度学习的分割方法，使用类ifier-guided两个阶段网络和所有slice fusions transformer来提高CMR分割精度，特别是在基础和末端 slice中。</li>
<li>results: 该方法在大量临床数据集上进行了评估，与之前的CNN基于的和transformer基于的模型相比，在Dice分数上表现出了更高的性能。此外，该方法生成的分割形状与人工标注更加相似，并避免了其他模型中的常见问题，如孔洞或 Fragmentation。<details>
<summary>Abstract</summary>
Cardiac Magnetic Resonance imaging (CMR) is the gold standard for assessing cardiac function. Segmenting the left ventricle (LV), right ventricle (RV), and LV myocardium (MYO) in CMR images is crucial but time-consuming. Deep learning-based segmentation methods have emerged as effective tools for automating this process. However, CMR images present additional challenges due to irregular and varying heart shapes, particularly in basal and apical slices. In this study, we propose a classifier-guided two-stage network with an all-slice fusion transformer to enhance CMR segmentation accuracy, particularly in basal and apical slices. Our method was evaluated on extensive clinical datasets and demonstrated better performance in terms of Dice score compared to previous CNN-based and transformer-based models. Moreover, our method produces visually appealing segmentation shapes resembling human annotations and avoids common issues like holes or fragments in other models' segmentations.
</details>
<details>
<summary>摘要</summary>
卡ди亚磁共振成像（CMR）是评估心脏功能的标准方法。在CMR图像中，正确分割左心室（LV）、右心室（RV）和心肌（MYO）是关键，但是却是耗时的。深度学习基于的分割方法在 automating 这个过程中表现出了有效的特点。然而，CMR图像又具有心形不规则和不同的心形特征，特别是在基层和脊梁slice中。在这项研究中，我们提议一种类型导向的两阶段网络，以增强CMR分割精度，特别是在基层和脊梁slice中。我们的方法在丰富的临床数据集上进行了评估，并与之前的CNN基于的和 transformer基于的模型相比，表现出更高的Dice分数。此外，我们的方法生成的分割形状与人工标注相似，并避免了其他模型中的常见问题，如孔洞或 Fragmentation。
</details></li>
</ul>
<hr>
<h2 id="Online-Targetless-Radar-Camera-Extrinsic-Calibration-Based-on-the-Common-Features-of-Radar-and-Camera"><a href="#Online-Targetless-Radar-Camera-Extrinsic-Calibration-Based-on-the-Common-Features-of-Radar-and-Camera" class="headerlink" title="Online Targetless Radar-Camera Extrinsic Calibration Based on the Common Features of Radar and Camera"></a>Online Targetless Radar-Camera Extrinsic Calibration Based on the Common Features of Radar and Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00787">http://arxiv.org/abs/2309.00787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Cheng, Siyang Cao</li>
<li>for: 这篇论文主要关注于自适应驾驶和自适应机器人的感应融合系统，尤其是对两种感应器之间的单一整合。</li>
<li>methods: 我们提出了一种新的方法，利用深度学习提取两种感应器之间的共同特征，并将这些共同特征用于匹配两种感应器中的同一个目标。我们还使用了RANSAC和Levenberg-Marquardt非线性优化算法来提取对称转换矩阵。</li>
<li>results: 我们的实验结果显示，我们的提案方法可以实现高精度和稳定性的单一整合。<details>
<summary>Abstract</summary>
Sensor fusion is essential for autonomous driving and autonomous robots, and radar-camera fusion systems have gained popularity due to their complementary sensing capabilities. However, accurate calibration between these two sensors is crucial to ensure effective fusion and improve overall system performance. Calibration involves intrinsic and extrinsic calibration, with the latter being particularly important for achieving accurate sensor fusion. Unfortunately, many target-based calibration methods require complex operating procedures and well-designed experimental conditions, posing challenges for researchers attempting to reproduce the results. To address this issue, we introduce a novel approach that leverages deep learning to extract a common feature from raw radar data (i.e., Range-Doppler-Angle data) and camera images. Instead of explicitly representing these common features, our method implicitly utilizes these common features to match identical objects from both data sources. Specifically, the extracted common feature serves as an example to demonstrate an online targetless calibration method between the radar and camera systems. The estimation of the extrinsic transformation matrix is achieved through this feature-based approach. To enhance the accuracy and robustness of the calibration, we apply the RANSAC and Levenberg-Marquardt (LM) nonlinear optimization algorithm for deriving the matrix. Our experiments in the real world demonstrate the effectiveness and accuracy of our proposed method.
</details>
<details>
<summary>摘要</summary>
感知融合是自动驾驶和自动机器人的关键技术，而雷达-摄像头融合系统在过去几年中得到了广泛的应用。然而，为了确保有效的感知融合，需要进行精准的协调。协调包括内在协调和外在协调，其中外在协调对于实现准确的感知融合是非常重要的。然而，许多目标基于的协调方法需要复杂的操作程序和丰富的实验条件，这会对研究人员进行重现结果的困难。为解决这个问题，我们介绍了一种新的方法，利用深度学习提取雷达数据（即距离-Doppler-角度数据）和摄像头图像中的公共特征。而不是直接表示这些公共特征，我们的方法将这些公共特征直接地用于匹配雷达和摄像头系统中的同一个目标。具体来说，提取的公共特征可以作为一个在线无目标协调方法的示例，用于计算雷达和摄像头系统之间的外在协调矩阵。为了提高准确性和稳定性，我们在这个特征基础上应用了RANSAC和Levenberg-Marquardt（LM）非线性优化算法来得到矩阵。我们在实际世界中进行的实验表明了我们的提案的有效性和准确性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/eess.IV_2023_09_02/" data-id="clogxf3sk013t5xra2mrpa9vq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/eess.SP_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T08:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/eess.SP_2023_09_02/">eess.SP - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Waste-Factor-A-New-Metric-for-Evaluating-Power-Efficiency-in-any-Cascade"><a href="#Waste-Factor-A-New-Metric-for-Evaluating-Power-Efficiency-in-any-Cascade" class="headerlink" title="Waste Factor: A New Metric for Evaluating Power Efficiency in any Cascade"></a>Waste Factor: A New Metric for Evaluating Power Efficiency in any Cascade</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01018">http://arxiv.org/abs/2309.01018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingjun Ying, Dipankar Shakya, Hitesh Poddar, Theodore S. Rappaport</li>
<li>for: This paper aims to improve the power efficiency of cascaded communication systems by developing a new metric called the Waste Factor ($W$).</li>
<li>methods: The authors use a mathematical framework to evaluate power efficiency in cascaded communication systems, by accounting for power wasted in individual components along a cascade. They also use the consumption efficiency factor (CEF) to evaluate the effects of insertion loss and deployment density on power efficiency.</li>
<li>results: The authors show that the Waste Factor is a unifying metric for defining wasted power in a cascade, and that it can be used to compare power efficiency between data centers and their components. They also observe that the CEF is markedly sensitive to insertion loss changes, particularly in uplink transmissions, and that energy efficiency improves at 142 GHz compared to 28 GHz as UE and BS numbers increase.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目标是提高积离通信系统的能效性，通过开发一个新的指标called Waste Factor ($W$).</li>
<li>methods: 作者们使用数学框架来评估积离通信系统的能效性，并考虑积离系统中每个组件的能量浪费。他们还使用消耗效率因子（CEF）来评估插入损失和部署密度对能效性的影响。</li>
<li>results: 作者们显示了 $W$ 是积离系统中定义浪费能量的统一指标，并且可以用来比较积离系统和其组件的能效性。他们还发现 CEF 受插入损失变化的影响非常大，特别是在上行传输中，而且能效性在142 GHz比28 GHz提高为 UE 和 BS 数量增加。<details>
<summary>Abstract</summary>
In this paper, we expand upon a new metric called the Waste Factor ($W$), a mathematical framework used to evaluate power efficiency in cascaded communication systems, by accounting for power wasted in individual components along a cascade. We show that the derivation of the Waste Factor, a unifying metric for defining wasted power along the signal path of any cascade, is similar to the mathematical approach used by H. Friis in 1944 to develop the Noise Factor ($F$), which has since served as a unifying metric for quantifying additive noise power in a cascade. Furthermore, the mathematical formulation of $W$ can be utilized in artificial intelligence (AI) and machine learning (ML) design and control for enhanced power efficiency. We consider the power usage effectiveness (PUE), which is a widely used energy efficiency metric for data centers, to evaluate $W$ for the data center as a whole. The use of $W$ allows easy comparison of power efficiency between data centers and their components. Our study further explores how insertion loss of components in a cascaded communication system influences $W$ at 28 GHz and 142 GHz along with the data rate performance, evaluated using the consumption efficiency factor (CEF). We observe CEF's marked sensitivity, particularly to phase shifter insertion loss changes. Notably, CEF variations are more prominent in uplink transmissions, whereas downlink transmissions offer relative CEF stability. Our exploration also covers the effects of varying User Equipment (UE) and Base Station (BS) deployment density on CEF in cellular networks. This work underscores the enhanced energy efficiency at 142 GHz, compared to 28 GHz, as UE and BS numbers escalate.
</details>
<details>
<summary>摘要</summary>
在本文中，我们扩展了一个新的度量 called Waste Factor ($W$), 用于评估级联通信系统中的能效性，通过对各个组件的能量损耗进行考虑。我们表明了度量Waste Factor的 derivation， 是级联通信系统中能效性度量的一个统一metric，类似于1944年Friis提出的Noise Factor ($F$)，该度量在级联通信系统中 quantifying 添加的噪声功率。此外，度量W的数学表述可以在人工智能（AI）和机器学习（ML）设计和控制中使用，以提高能效性。我们使用数据中心的能效性指标（PUE）来评估W，以便对数据中心和其组件进行简单的能效性比较。我们的研究还探讨了级联通信系统中组件插入损耗对W的影响，以及数据率性能，通过消耗效应因子（CEF）的变化来评估。我们发现CEF在28GHz和142GHz之间具有明显的敏感度，特别是在相位调制器插入损耗变化时。此外，我们还发现在无线电网络中 UE 和 BS 的分布密度变化对CEF的影响。这种研究表明了142GHz的能效性比28GHz更高，当 UE 和 BS 数量增加时。
</details></li>
</ul>
<hr>
<h2 id="A-Sub-Terahertz-Sliding-Correlator-Channel-Sounder-with-Absolute-Timing-using-Precision-Time-Protocol-over-Wi-Fi"><a href="#A-Sub-Terahertz-Sliding-Correlator-Channel-Sounder-with-Absolute-Timing-using-Precision-Time-Protocol-over-Wi-Fi" class="headerlink" title="A Sub-Terahertz Sliding Correlator Channel Sounder with Absolute Timing using Precision Time Protocol over Wi-Fi"></a>A Sub-Terahertz Sliding Correlator Channel Sounder with Absolute Timing using Precision Time Protocol over Wi-Fi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01006">http://arxiv.org/abs/2309.01006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dipankar Shakya, Hitesh Poddar, Theodore S. Rappaport<br>for:This paper aims to achieve sub-nanosecond timing accuracy for multipath component (MPC) propagation delays in power delay profiles (PDPs) for 5G and 6G communications at mmWave and sub-THz frequencies.methods:The proposed solution utilizes precision time protocol (PTP) and periodic drift correction to achieve absolute timing for MPCs in PDPs. The solution involves synchronizing the transmitter (TX) and receiver (RX) clocks using two RaspberryPi computers and a dedicated Wi-Fi link, and applying a periodic drift correction algorithm to eliminate PDP sample drift.results:The proposed solution achieves sub-nanosecond timing accuracy for MPC delays, reducing PDP sample drift to 150 samples&#x2F;hour compared to several thousand samples&#x2F;hour without synchronization. The solution shows promise in myriad applications, including precise position location and distributed systems that require sub-nanosecond timing accuracy and synchronization among components.Here is the information in Simplified Chinese text:for:这篇论文目标是在5G和6G通信中的mmWave和sub-THz频谱中实现多吉比特数据速率的 multipath component（MPC）延迟。methods:提议的解决方案利用精度时间协议（PTP）和周期偏移修正来实现MPC在电力延迟profile（PDP）中的绝对时间。解决方案使用两个RaspberryPi计算机和专门的Wi-Fi链接来实现TX和RX Rubidium时钟的同步，并应用周期偏移修正算法来消除PDP样本偏移。results:提议的解决方案实现了MPC延迟的sub-nanosecond精度，将PDP样本偏移降低至150个样本&#x2F;小时，比不同的时钟同步方法而言有所下降。该解决方案在多种应用中展示了承诺，包括精确的位置定位和分布式系统，它们需要sub-nanosecond精度和同步。<details>
<summary>Abstract</summary>
Radio channels at mmWave and sub-THz frequencies for 5G and 6G communications offer large channel bandwidths (hundreds of MHz to several GHz) to achieve multi-Gbps data rates. Accurate modeling of the radio channel for these wide bandwidths requires capturing the absolute timing of multipath component (MPC) propagation delays with sub-nanosecond accuracy. Achieving such timing accuracy is challenging due to clock drift in untethered transmitter (TX) and receiver (RX) clocks used in time-domain channel sounders, yet will become vital in many future 6G applications. This paper proposes a novel solution utilizing precision time protocol (PTP) and periodic drift correction to achieve absolute timing for MPCs in power delay profiles (PDPs) --captured as discrete samples using sliding correlation channel sounders. Two RaspberryPi computers are programmed to implement PTP over a dedicated Wi-Fi link and synchronize the TX and RX Rubidium clocks continuously every second. This synchronization minimizes clock drift, reducing PDP sample drift to 150 samples/hour, compared to several thousand samples/hour without synchronization. Additionally, a periodic drift correction algorithm is applied to eliminate PDP sample drift and achieve sub-nanosecond timing accuracy for MPC delays. The achieved synchronicity eliminates the need for tedious and sometimes inaccurate ray tracing to synthesize omnidirectional PDPs from directional measurements. The presented solution shows promise in myriad applications, including precise position location and distributed systems that require sub-nanosecond timing accuracy and synchronization among components.
</details>
<details>
<summary>摘要</summary>
radio频道在mmWave和sub-THz频率上为5G和6G通信提供大量频带宽（百万Hz到几亿Hz）以实现多Gbps的数据速率。 precisely modeling radio频道需要 capture multipath component（MPC）延迟的绝对时间准确性（sub-纳秒级）。 Achieving such timing accuracy is challenging due to clock drift in untethered transmitter（TX）和receiver（RX）clocks used in time-domain channel sounders, yet will become vital in many future 6G applications。 This paper proposes a novel solution utilizing precision time protocol（PTP）and periodic drift correction to achieve absolute timing for MPCs in power delay profiles（PDPs）—captured as discrete samples using sliding correlation channel sounders。 Two RaspberryPi computers are programmed to implement PTP over a dedicated Wi-Fi link and synchronize the TX and RX Rubidium clocks continuously every second。 This synchronization minimizes clock drift, reducing PDP sample drift to 150 samples/hour, compared to several thousand samples/hour without synchronization。 Additionally, a periodic drift correction algorithm is applied to eliminate PDP sample drift and achieve sub-nanosecond timing accuracy for MPC delays。 The achieved synchronicity eliminates the need for tedious and sometimes inaccurate ray tracing to synthesize omnidirectional PDPs from directional measurements。 The presented solution shows promise in myriad applications, including precise position location and distributed systems that require sub-nanosecond timing accuracy and synchronization among components。
</details></li>
</ul>
<hr>
<h2 id="Robust-Joint-Active-Passive-Beamforming-Design-for-IRS-Assisted-ISAC-Systems"><a href="#Robust-Joint-Active-Passive-Beamforming-Design-for-IRS-Assisted-ISAC-Systems" class="headerlink" title="Robust Joint Active-Passive Beamforming Design for IRS-Assisted ISAC Systems"></a>Robust Joint Active-Passive Beamforming Design for IRS-Assisted ISAC Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00978">http://arxiv.org/abs/2309.00978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud AlaaEldin, Emad Alsusa, Karim G. Seddik, Christos Masouros, Iman Valiulahi<br>for: 这个研究旨在探讨 интеelligent reflective surfaces（IRS）与integrated sensing and communication（ISAC）系统之间的integraion，以改善未来无线网络中的spectrum congestion问题。methods: 这个研究使用了低复杂性和高效的共同优化算法，将BS的传发矩阵和IRS的反射矩阵共同优化，以最小化传发信号和欲要的射频范围之间的Frobenius距离。results: 研究结果显示，在不同的环境下，IRS-ISAC系统可以实现更好的传输和探测性能，并且可以适应不同的通信用户和射频范围。此外，这个研究还提出了一个对于IRS频率不确定性的强化 beamforming优化算法，可以对于实际系统中的频率不确定性进行适应。<details>
<summary>Abstract</summary>
The idea of Integrated Sensing and Communication (ISAC) offers a promising solution to the problem of spectrum congestion in future wireless networks. This paper studies the integration of intelligent reflective surfaces (IRS) with ISAC systems to improve the performance of radar and communication services. Specifically, an IRS-assisted ISAC system is investigated where a multi-antenna base station (BS) performs multi-target detection and multi-user communication. A low complexity and efficient joint optimization of transmit beamforming at the BS and reflective beamforming at the IRS is proposed. This is done by jointly optimizing the BS beamformers and IRS reflection coefficients to minimize the Frobenius distance between the covariance matrices of the transmitted signal and the desired radar beam pattern. This optimization aims to satisfy the signal-to-interference-and-noise ratio (SINR) constraints of the communication users, the total transmit power limit at the BS, and the unit modulus constraints of the IRS reflection coefficients. To address the resulting complex non-convex optimization problem, an efficient alternating optimization (AO) algorithm combining fractional programming (FP), semi-definite programming (SDP), and second order cone programming (SOCP) methods is proposed. Furthermore, we propose robust beamforming optimization for IRS-ISAC systems by adapting the proposed optimization algorithm to the IRS channel uncertainties that may exist in practical systems. Using advanced tools from convex optimization theory, the constraints containing uncertainty are transformed to their equivalent linear matrix inequalities (LMIs) to account for the channels' uncertainty radius. The results presented quantify the benefits of IRS-ISAC systems under various conditions and demonstrate the effectiveness of the proposed algorithm.
</details>
<details>
<summary>摘要</summary>
“嵌入式感测和通信（ISAC）技术提供了未来无线网络中频率压力问题的有效解决方案。这篇文章研究了智能反射表（IRS）与ISAC系统的集成，以提高雷达和通信服务的性能。具体来说，我们研究了一种由多个antenna基站（BS）和IRS共同实现的IRS-助け过 ISAC系统。在这种系统中，BS使用多个antenna执行多个目标检测和多个用户通信。我们提出了一种低复杂度和高效的集成传输扩张和反射扩张的优化方法。这种优化方法是将BS的扩张和IRS的反射矩阵优化到最小化 Frobenius 距离 между发射信号的covariance矩阵和 Desired 雷达波形矩阵。这种优化目的是满足通信用户的信号噪干扰比（SINR）约束、BS的总发射功率限制和IRS的单位模数约束。为解决这个复杂非 convex 优化问题，我们提出了一种高效的 alternate 优化（AO）算法，该算法结合分数编程（FP）、半definite 编程（SDP）和第二个 cone 编程（SOCP）方法。此外，我们还提出了IRS-ISAC系统中的Robust 扩张优化，该算法通过将uncertainty 约束转化为其等效的线性matrix inequality（LMIs）来考虑实际系统中的频率uncertainty。结果表明，在不同条件下，IRS-ISAC系统具有显著的优势，并且提出的算法效果扎实。”
</details></li>
</ul>
<hr>
<h2 id="Consensus-based-Distributed-Variational-Multi-object-Tracker-in-Multi-Sensor-Network"><a href="#Consensus-based-Distributed-Variational-Multi-object-Tracker-in-Multi-Sensor-Network" class="headerlink" title="Consensus-based Distributed Variational Multi-object Tracker in Multi-Sensor Network"></a>Consensus-based Distributed Variational Multi-object Tracker in Multi-Sensor Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00807">http://arxiv.org/abs/2309.00807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qing Li, Runze Gan, Simon Godsill</li>
<li>for: 本研究旨在设计一种高精度、可靠的追踪系统，以满足现代感知技术的增长需求。</li>
<li>methods: 本文提出了两种变分析追踪器，可以有效地跟踪多个目标在噪声环境中。中央整合式感知方案首先将感知数据传输到整合中心进行融合，而分布式版本则基于平均协议来实现本地消息传递。</li>
<li>results: 实验结果表明，我们提出的分布式变分追踪器和中央整合式追踪器的跟踪精度相当，并且分布式追踪器比 arithmetic sensor fusion 和平均协议融合策略更高。<details>
<summary>Abstract</summary>
The growing need for accurate and reliable tracking systems has driven significant progress in sensor fusion and object tracking techniques. In this paper, we design two variational Bayesian trackers that effectively track multiple targets in cluttered environments within a sensor network. We first present a centralised sensor fusion scheme, which involves transmitting sensor data to a fusion center. Then, we develop a distributed version leveraging the average consensus algorithm, which is theoretically equivalent to the centralised sensor fusion tracker and requires only local message passing with neighbouring sensors. In addition, we empirically verify that our proposed distributed variational tracker performs on par with the centralised version with equal tracking accuracy. Simulation results show that our distributed multi-target tracker outperforms the suboptimal distributed sensor fusion strategy that fuses each sensor's posterior based on arithmetic sensor fusion and an average consensus strategy.
</details>
<details>
<summary>摘要</summary>
随着准确和可靠的跟踪系统的需求不断增长，感知融合和目标跟踪技术也得到了重要的进步。在这篇论文中，我们设计了两种变分极 bayesian跟踪器，可以有效地跟踪多个目标在杂乱环境中的感知网络中。我们首先提出了一种中央感知融合方案，其中感知数据被传输到融合中心进行融合。然后，我们开发了分布式版本，利用平均协议算法，这是中央感知融合器的理论等价，只需在与邻居感知器进行本地消息传递。此外，我们验证了我们的提议的分布式变分跟踪器和中央版本之间的跟踪精度相等。 simulation结果显示，我们的分布式多目标跟踪器比使用 arithmetic sensor fusion和平均协议策略来进行分布式感知融合的优化策略强。
</details></li>
</ul>
<hr>
<h2 id="Delay-Doppler-Alignment-Modulation-for-Spatially-Sparse-Massive-MIMO-Communication"><a href="#Delay-Doppler-Alignment-Modulation-for-Spatially-Sparse-Massive-MIMO-Communication" class="headerlink" title="Delay-Doppler Alignment Modulation for Spatially Sparse Massive MIMO Communication"></a>Delay-Doppler Alignment Modulation for Spatially Sparse Massive MIMO Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00792">http://arxiv.org/abs/2309.00792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiquan Lu, Yong Zeng</li>
<li>for: 本文旨在解决宽频通信中的symbol间干扰问题，提出了一种基于时空延迟处理的延迟对称模ulation（DAM）技术，而不需要通道平衡或多个卫星传输。</li>
<li>methods: 本文提出了一种基于时变频Selective多输入多出口（MIMO）通信系统的延迟对称模ulation（DDAM）技术，通过利用延迟-Doppler补做和路径基本 beamforming，消除每个干扰道的Doppler效应，使所有干扰道信号组件都能够同步到接收器。</li>
<li>results: 本文首先表明，通过应用路径基本零做（ZF）预编码和接收 combine，DDAM可以将原始时变频Selective通道转化为时间 invariants ISI-free通道。 derive了必要和&#x2F;或 suficient conditionsto achieve这种转化。然后，提供了一个 asymptotic analysis，表明当基站天线数量远大于通道路径数量时，DDAM可以实现时间 invariants ISI-free通道，只需要简单的延迟-Doppler补做和路径基本 MRT  beamforming。此外，为了实现DDAM设计中的一些可容忍的 ISI，将路径基本预编码和接收 combine矩阵优化为最大化spectral efficiency。<details>
<summary>Abstract</summary>
Delay alignment modulation (DAM) is an emerging technique for achieving inter-symbol interference (ISI)-free wideband communications using spatial-delay processing, without relying on channel equalization or multi-carrier transmission. However, existing works on DAM only consider multiple-input single-output (MISO) communication systems and assume time-invariant channels. In this paper, by extending DAM to time-variant frequency-selective multiple-input multiple-output (MIMO) channels, we propose a novel technique termed \emph{delay-Doppler alignment modulation} (DDAM). Specifically, by leveraging \emph{delay-Doppler compensation} and \emph{path-based beamforming}, the Doppler effect of each multi-path can be eliminated and all multi-path signal components may reach the receiver concurrently and constructively. We first show that by applying path-based zero-forcing (ZF) precoding and receive combining, DDAM can transform the original time-variant frequency-selective channels into time-invariant ISI-free channels. The necessary and/or sufficient conditions to achieve such a transformation are derived. Then an asymptotic analysis is provided by showing that when the number of base station (BS) antennas is much larger than that of channel paths, DDAM enables time-invariant ISI-free channels with the simple delay-Doppler compensation and path-based maximal-ratio transmission (MRT) beamforming. Furthermore, for the general DDAM design with some tolerable ISI, the path-based transmit precoding and receive combining matrices are optimized to maximize the spectral efficiency. Numerical results are provided to compare the proposed DDAM technique with various benchmarking schemes, including MIMO-orthogonal time frequency space (OTFS), MIMO-orthogonal frequency-division multiplexing (OFDM) without or with carrier frequency offset (CFO) compensation, and beam alignment along the dominant path.
</details>
<details>
<summary>摘要</summary>
延迟对齐模ulation（DAM）是一种emerging技术，用于实现干扰符号（ISI）free广泛通信，只需通过空间延迟处理，而不需依赖通道均衡或多 carriermultiplexing。然而，现有的DAM研究仅考虑多input single-output（MISO）通信系统，并假设时variant channels。在这篇文章中，我们通过扩展DAM到时variant frequency-selective多input多output（MIMO）通信频道，提出一种新的技术，称为延迟Doppler对齐模ulation（DDAM）。具体来说，通过利用延迟Doppler补做和路径基 beamforming，每个多路可以消除Doppler效应，使所有多路信号组件能够同时到达接收器并构成。我们首先示出，通过应用路径基Zero-Forcing（ZF）预编码和接收 combining，DDAM可以将原始时variant frequency-selective频道变换成时 invariantin ISI-free频道。我们 derive了必要和/或充分的条件以实现这种变换。然后，我们提供了一种 asymptotic analysis，表明当基站天线数量比channel path数量多得多时，DDAM可以将时variant ISI-free频道转换成时 invariantin ISI-free频道，只需使用简单的延迟Doppler补做和路径基MRT beamforming。此外，为了设计DDAM，我们 optimize了路径基传输预编码和接收 combining矩阵，以最大化spectral efficiency。我们提供了一些数值结果，并与various benchmarking schemes进行比较，包括MIMO-orthogonal time frequency space（OTFS）、MIMO-orthogonal frequency-division multiplexing（OFDM）without/with carrier frequency offset（CFO）compensation，以及beam alignment along the dominant path。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/eess.SP_2023_09_02/" data-id="clogxf3tc016w5xra2h6xcikg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/01/cs.SD_2023_09_01/" class="article-date">
  <time datetime="2023-09-01T15:00:00.000Z" itemprop="datePublished">2023-09-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/01/cs.SD_2023_09_01/">cs.SD - 2023-09-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CoNeTTE-An-efficient-Audio-Captioning-system-leveraging-multiple-datasets-with-Task-Embedding"><a href="#CoNeTTE-An-efficient-Audio-Captioning-system-leveraging-multiple-datasets-with-Task-Embedding" class="headerlink" title="CoNeTTE: An efficient Audio Captioning system leveraging multiple datasets with Task Embedding"></a>CoNeTTE: An efficient Audio Captioning system leveraging multiple datasets with Task Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00454">http://arxiv.org/abs/2309.00454</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/topel/audioset-convnext-inf">https://github.com/topel/audioset-convnext-inf</a></li>
<li>paper_authors: Étienne Labbé, Thomas Pellegrini, Julien Pinquier</li>
<li>for: The paper is written for the task of automated audio captioning (AAC), specifically using a ConvNeXt architecture as the audio encoder and exploring the use of task embeddings to improve performance across multiple datasets.</li>
<li>methods: The paper uses a ConvNeXt architecture as the audio encoder, which is adapted from the vision domain to audio classification. The model is trained on multiple AAC datasets (AC, CL, MACS, WavCaps) with a task embedding (TE) token to identify the source dataset for each input sample.</li>
<li>results: The paper achieves state-of-the-art scores on the AudioCaps (AC) dataset and competitive performance on Clotho (CL) with fewer parameters than existing models. The use of task embeddings improves cross-dataset performance, but there is still a performance gap between datasets, indicating the need for dataset-specific models. The resulting model, called CoNeTTE, achieves SPIDEr scores of 44.1% and 30.5% on AC and CL, respectively.<details>
<summary>Abstract</summary>
Automated Audio Captioning (AAC) involves generating natural language descriptions of audio content, using encoder-decoder architectures. An audio encoder produces audio embeddings fed to a decoder, usually a Transformer decoder, for caption generation. In this work, we describe our model, which novelty, compared to existing models, lies in the use of a ConvNeXt architecture as audio encoder, adapted from the vision domain to audio classification. This model, called CNext-trans, achieved state-of-the-art scores on the AudioCaps (AC) dataset and performed competitively on Clotho (CL), while using four to forty times fewer parameters than existing models. We examine potential biases in the AC dataset due to its origin from AudioSet by investigating unbiased encoder's impact on performance. Using the well-known PANN's CNN14, for instance, as an unbiased encoder, we observed a 1.7% absolute reduction in SPIDEr score (where higher scores indicate better performance). To improve cross-dataset performance, we conducted experiments by combining multiple AAC datasets (AC, CL, MACS, WavCaps) for training. Although this strategy enhanced overall model performance across datasets, it still fell short compared to models trained specifically on a single target dataset, indicating the absence of a one-size-fits-all model. To mitigate performance gaps between datasets, we introduced a Task Embedding (TE) token, allowing the model to identify the source dataset for each input sample. We provide insights into the impact of these TEs on both the form (words) and content (sound event types) of the generated captions. The resulting model, named CoNeTTE, an unbiased CNext-trans model enriched with dataset-specific Task Embeddings, achieved SPIDEr scores of 44.1% and 30.5% on AC and CL, respectively. Code available: https://github.com/Labbeti/conette-audio-captioning.
</details>
<details>
<summary>摘要</summary>
自动化语音描述（AAC）技术涉及生成语音内容的自然语言描述，使用编码器-解码器架构。一个音频编码器生成音频嵌入，并将其传递给一个通常是转换器解码器的decoder进行描述生成。在这个工作中，我们描述了我们的模型，它与现有模型的不同之处在于使用ConvNeXt架构作为音频编码器，从视觉领域中适应到音频分类。我们称之为CNext-trans模型，在AudioCaps（AC）数据集上达到了状态之artefact的分数，并在Clotho（CL）数据集上表现竞争力强，同时使用四到四十个参数少于现有模型。我们 investigate了AC数据集中可能的偏见问题，并证明使用不偏见的编码器对性能有一定的影响。使用著名的PANN的CNN14作为不偏见编码器，我们观察到了1.7%的绝对下降分数（其中更高的分数表示更好的性能）。为提高跨数据集性能，我们进行了多个AAC数据集（AC、CL、MACS、WavCaps）的组合训练。虽然这种策略提高了总模型性能，但还不如特定目标数据集训练的模型，表明不存在一个适用于所有数据集的模型。为了减少数据集之间性能差距，我们引入了任务嵌入（TE）token，让模型可以通过检测输入样本的来源数据集来识别样本的来源。我们对TE的影响进行了详细的分析，包括对形式（字词）和内容（声音事件类型）的影响。最终，我们提出了CoNeTTE模型，一个不偏见CNext-trans模型，通过添加数据集特定的任务嵌入，实现了SPIDEr分数44.1%和30.5%。代码可以在https://github.com/Labbeti/conette-audio-captioning中下载。
</details></li>
</ul>
<hr>
<h2 id="Remixing-based-Unsupervised-Source-Separation-from-Scratch"><a href="#Remixing-based-Unsupervised-Source-Separation-from-Scratch" class="headerlink" title="Remixing-based Unsupervised Source Separation from Scratch"></a>Remixing-based Unsupervised Source Separation from Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00376">http://arxiv.org/abs/2309.00376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kohei Saijo, Tetsuji Ogawa</li>
<li>for: 本文提出了一种无监督的方法，用于从零开始训练分离模型，使用RecmixIT和Self-Remixing等现代自动学习方法来进行修复预训练模型。</li>
<li>methods: 这种方法首先使用一个教师模型将混合物分离，然后创建一些假混合物，通过搅拌和重新混合已分离的信号来进行训练。学生模型将使用教师的输出或初始混合物作为监督来分离假混合物。为了修复教师的输出，教师的权重将被更新为学生的权重。</li>
<li>results: 实验结果表明，提议的方法可以超越现有的混合 invariant 训练方法，从零开始训练一个单频分离模型。此外，我们还提出了一种简单的搅拌方法来稳定训练。<details>
<summary>Abstract</summary>
We propose an unsupervised approach for training separation models from scratch using RemixIT and Self-Remixing, which are recently proposed self-supervised learning methods for refining pre-trained models. They first separate mixtures with a teacher model and create pseudo-mixtures by shuffling and remixing the separated signals. A student model is then trained to separate the pseudo-mixtures using either the teacher's outputs or the initial mixtures as supervision. To refine the teacher's outputs, the teacher's weights are updated with the student's weights. While these methods originally assumed that the teacher is pre-trained, we show that they are capable of training models from scratch. We also introduce a simple remixing method to stabilize training. Experimental results demonstrate that the proposed approach outperforms mixture invariant training, which is currently the only available approach for training a monaural separation model from scratch.
</details>
<details>
<summary>摘要</summary>
我们提出了一种无监督的方法，用于从零开始训练分离模型，使用RecmixIT和Self-Remixing，这两种最近提出的自动学习方法来修正预训练模型。它们首先使用一个教师模型将混合物分离出来，然后创建假混合物，通过搅拌和重新混合分离后的信号。一个学生模型然后被训练使用教师的输出或初始混合物作为监督来分离假混合物。为了修正教师的输出，教师的权重被更新为学生的权重。而这些方法最初假设了教师是预训练的，但我们表明它们可以训练模型从零开始。我们还介绍了一种简单的搅拌方法，以稳定训练。实验结果表明，我们提出的方法在训练独立式分离模型方面超过了现有的混合物不变训练方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/01/cs.SD_2023_09_01/" data-id="clogxf3q800u55xra96tsgsd8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/01/cs.CV_2023_09_01/" class="article-date">
  <time datetime="2023-09-01T13:00:00.000Z" itemprop="datePublished">2023-09-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/01/cs.CV_2023_09_01/">cs.CV - 2023-09-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Affine-Transformation-Invariant-Image-Classification-by-Differentiable-Arithmetic-Distribution-Module"><a href="#Affine-Transformation-Invariant-Image-Classification-by-Differentiable-Arithmetic-Distribution-Module" class="headerlink" title="Affine-Transformation-Invariant Image Classification by Differentiable Arithmetic Distribution Module"></a>Affine-Transformation-Invariant Image Classification by Differentiable Arithmetic Distribution Module</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00752">http://arxiv.org/abs/2309.00752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijie Tan, Guanfang Dong, Chenqiu Zhao, Anup Basu</li>
<li>for: 提高 Convolutional Neural Networks (CNNs) 对于图像分类 tasks 的 robustness, 尤其是对于旋转、平移、翻转和排序等非对称变换。</li>
<li>methods: 提出一种基于分布学习技术的 Differentiable Arithmetic Distribution Module (DADM)，通过学习图像中像素的空间分布信息来提高模型的Robustness。</li>
<li>results: 通过对比与 LeNet 等方法的实验和简洁分析，证明了该方法能够提高模型的 Robustness 无需牺牲特征提取能力。<details>
<summary>Abstract</summary>
Although Convolutional Neural Networks (CNNs) have achieved promising results in image classification, they still are vulnerable to affine transformations including rotation, translation, flip and shuffle. The drawback motivates us to design a module which can alleviate the impact from different affine transformations. Thus, in this work, we introduce a more robust substitute by incorporating distribution learning techniques, focusing particularly on learning the spatial distribution information of pixels in images. To rectify the issue of non-differentiability of prior distribution learning methods that rely on traditional histograms, we adopt the Kernel Density Estimation (KDE) to formulate differentiable histograms. On this foundation, we present a novel Differentiable Arithmetic Distribution Module (DADM), which is designed to extract the intrinsic probability distributions from images. The proposed approach is able to enhance the model's robustness to affine transformations without sacrificing its feature extraction capabilities, thus bridging the gap between traditional CNNs and distribution-based learning. We validate the effectiveness of the proposed approach through ablation study and comparative experiments with LeNet.
</details>
<details>
<summary>摘要</summary>
To address the issue of non-differentiability of prior distribution learning methods that rely on traditional histograms, we adopt Kernel Density Estimation (KDE) to formulate differentiable histograms. On this foundation, we present a novel Differentiable Arithmetic Distribution Module (DADM), which is designed to extract the intrinsic probability distributions from images. The proposed approach can enhance the model's robustness to affine transformations without sacrificing its feature extraction capabilities, thus bridging the gap between traditional CNNs and distribution-based learning. We validate the effectiveness of the proposed approach through ablation study and comparative experiments with LeNet.
</details></li>
</ul>
<hr>
<h2 id="PathLDM-Text-conditioned-Latent-Diffusion-Model-for-Histopathology"><a href="#PathLDM-Text-conditioned-Latent-Diffusion-Model-for-Histopathology" class="headerlink" title="PathLDM: Text conditioned Latent Diffusion Model for Histopathology"></a>PathLDM: Text conditioned Latent Diffusion Model for Histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00748">http://arxiv.org/abs/2309.00748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srikar Yellapragada, Alexandros Graikos, Prateek Prasanna, Tahsin Kurc, Joel Saltz, Dimitris Samaras</li>
<li>for: 这篇论文旨在开发一种基于文本指导的高质量病理图像生成模型，以便在计算机 PATHOLOGY 领域中提高模型训练效果。</li>
<li>methods: 该论文使用文本指导的幽Diffusion模型，通过将图像和文本数据 fusion 以提高生成过程。文本数据来自 histopathology 报告，通过 GPT 技术进行抽象和概要，以建立有效的 conditioning 机制。</li>
<li>results: 通过策略性的 conditioning 和必要的建构改进，该论文在 TCGA-BRCA 数据集上实现了 SoTA FID 分数 7.64，明显超越最近的文本指导竞争对手的 FID 分数 30.1。<details>
<summary>Abstract</summary>
To achieve high-quality results, diffusion models must be trained on large datasets. This can be notably prohibitive for models in specialized domains, such as computational pathology. Conditioning on labeled data is known to help in data-efficient model training. Therefore, histopathology reports, which are rich in valuable clinical information, are an ideal choice as guidance for a histopathology generative model. In this paper, we introduce PathLDM, the first text-conditioned Latent Diffusion Model tailored for generating high-quality histopathology images. Leveraging the rich contextual information provided by pathology text reports, our approach fuses image and textual data to enhance the generation process. By utilizing GPT's capabilities to distill and summarize complex text reports, we establish an effective conditioning mechanism. Through strategic conditioning and necessary architectural enhancements, we achieved a SoTA FID score of 7.64 for text-to-image generation on the TCGA-BRCA dataset, significantly outperforming the closest text-conditioned competitor with FID 30.1.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learned-Visual-Features-to-Textual-Explanations"><a href="#Learned-Visual-Features-to-Textual-Explanations" class="headerlink" title="Learned Visual Features to Textual Explanations"></a>Learned Visual Features to Textual Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00733">http://arxiv.org/abs/2309.00733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeid Asgari Taghanaki, Aliasghar Khani, Amir Khasahmadi, Aditya Sanghi, Karl D. D. Willis, Ali Mahdavi-Amiri</li>
<li>for: 提高图像分类器的解释性和可靠性</li>
<li>methods: 利用大型自然语言模型（LLMs）解释图像分类器学习的特征空间</li>
<li>results: 在多个数据集上进行了实验，证明了方法的有效性，可以提高图像分类器的解释性和可靠性<details>
<summary>Abstract</summary>
Interpreting the learned features of vision models has posed a longstanding challenge in the field of machine learning. To address this issue, we propose a novel method that leverages the capabilities of large language models (LLMs) to interpret the learned features of pre-trained image classifiers. Our method, called TExplain, tackles this task by training a neural network to establish a connection between the feature space of image classifiers and LLMs. Then, during inference, our approach generates a vast number of sentences to explain the features learned by the classifier for a given image. These sentences are then used to extract the most frequent words, providing a comprehensive understanding of the learned features and patterns within the classifier. Our method, for the first time, utilizes these frequent words corresponding to a visual representation to provide insights into the decision-making process of the independently trained classifier, enabling the detection of spurious correlations, biases, and a deeper comprehension of its behavior. To validate the effectiveness of our approach, we conduct experiments on diverse datasets, including ImageNet-9L and Waterbirds. The results demonstrate the potential of our method to enhance the interpretability and robustness of image classifiers.
</details>
<details>
<summary>摘要</summary>
machine learning 领域中解释视图模型学习的结果对于长期是一个挑战。为解决这个问题，我们提出了一种新的方法，即利用大型自然语言模型（LLMs）来解释预训练的图像分类器学习的特征。我们的方法，称为TExplain，通过在图像分类器的特征空间和LLMs之间建立连接来实现这个任务。在推理过程中，我们的方法生成大量的句子来解释给定图像中分类器学习的特征。这些句子中的最常见词语被用来提取特征空间中学习的特征和模式，从而提供了图像分类器的决策过程中的全面理解。我们的方法首次利用这些与视觉表示相对应的常见词语，提供了图像分类器的决策过程中的深入了解和检测偏见、偏好等。为验证我们的方法的有效性，我们在多个 dataset 上进行了实验，包括 ImageNet-9L 和 Waterbirds。结果表明，我们的方法可以增强图像分类器的可解释性和Robustness。
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-in-medical-image-registration-introduction-and-survey"><a href="#Deep-learning-in-medical-image-registration-introduction-and-survey" class="headerlink" title="Deep learning in medical image registration: introduction and survey"></a>Deep learning in medical image registration: introduction and survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00727">http://arxiv.org/abs/2309.00727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Hammoudeh, Stéphane Dupont</li>
<li>for: 本文主要用于介绍图像注册技术，以帮助医疗专业人员在标准化参照Frame中进行评估多种医学图像。</li>
<li>methods: 本文使用了多种图像变换，包括Affine变换、可变形变换、可逆变换、双向变换等，以及医学图像注册算法，如Voxelmorph、Demons、SynthMorph等。</li>
<li>results: 本文涵盖了多种图像注册技术，包括参考 Atlases、多stage图像注册、Pyramid Approach等，以及医学图像注册的数据集、评估指标、应用场景等。<details>
<summary>Abstract</summary>
Image registration (IR) is a process that deforms images to align them with respect to a reference space, making it easier for medical practitioners to examine various medical images in a standardized reference frame, such as having the same rotation and scale. This document introduces image registration using a simple numeric example. It provides a definition of image registration along with a space-oriented symbolic representation. This review covers various aspects of image transformations, including affine, deformable, invertible, and bidirectional transformations, as well as medical image registration algorithms such as Voxelmorph, Demons, SyN, Iterative Closest Point, and SynthMorph. It also explores atlas-based registration and multistage image registration techniques, including coarse-fine and pyramid approaches. Furthermore, this survey paper discusses medical image registration taxonomies, datasets, evaluation measures, such as correlation-based metrics, segmentation-based metrics, processing time, and model size. It also explores applications in image-guided surgery, motion tracking, and tumor diagnosis. Finally, the document addresses future research directions, including the further development of transformers.
</details>
<details>
<summary>摘要</summary>
Image registration (IR) 是一个过程，用于将图像调整，使其与参照空间align，以便医疗专业人员通过标准化参照框架进行评估不同医疗图像，例如同一个旋转和缩放。本文介绍了图像 registration 的简单数字示例，并提供了图像 registration 的定义和空间 oriented 符号表示。本文评论了各种图像变换，包括 affine、可变、可逆、 bidirectional 变换，以及医疗图像 registration 算法，如 Voxelmorph、Demons、SyN、Iterative Closest Point 和 SynthMorph。此外，本文还探讨了 atlas-based registration 和多阶段图像 registration 技术，包括 coarse-fine 和 pyramid 方法。此外，本文还讨论了医疗图像 registration 的分类、数据集、评价指标，如 correlation-based  метри克、segmentation-based  метри克、处理时间和模型大小。此外，本文还探讨了图像导航手术、运动跟踪和肿瘤诊断的应用。最后，文档还讨论了未来研究方向，包括 transformers 的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Indexing-Irises-by-Intrinsic-Dimension"><a href="#Indexing-Irises-by-Intrinsic-Dimension" class="headerlink" title="Indexing Irises by Intrinsic Dimension"></a>Indexing Irises by Intrinsic Dimension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00705">http://arxiv.org/abs/2309.00705</a></li>
<li>repo_url: None</li>
<li>paper_authors: J. Michael Rozmus</li>
<li>for: 这个论文是为了提高人脸识别技术的精度和速度而写的。</li>
<li>methods: 这个论文使用了主成分分析（PCA）将一组高质量的眼照图像映射到四维内在空间中。</li>
<li>results: 这个论文得到了一个高精度的人脸识别系统，可以快速准确地匹配眼照图像到数据库中的匹配记录。<details>
<summary>Abstract</summary>
28,000+ high-quality iris images of 1350 distinct eyes from 650+ different individuals from a relatively diverse university town population were collected. A small defined unobstructed portion of the normalized iris image is selected as a key portion for quickly identifying an unknown individual when submitting an iris image to be matched to a database of enrolled irises of the 1350 distinct eyes. The intrinsic dimension of a set of these key portions of the 1350 enrolled irises is measured to be about four (4). This set is mapped to a four-dimensional intrinsic space by principal components analysis (PCA). When an iris image is presented to the iris database for identification, the search begins in the neighborhood of the location of its key portion in the 4D intrinsic space, typically finding a correct identifying match after comparison to only a few percent of the database.
</details>
<details>
<summary>摘要</summary>
我们收集了1350个眼睛的28,000多个高质量眼睛图像，来自650多个不同个体的大学城市人口。我们选择了一小部分眼睛图像作为快速识别未知个体的关键部分，并计算了这些关键部分的内在维度为4。我们将这些关键部分映射到4维内在空间中，使用主成分分析（PCA）。当我们将眼睛图像提交到识别数据库时，我们会在数据库中查找与其关键部分相似的匹配，通常只需要比较数据库中的一些百分比就能够获得正确的识别结果。
</details></li>
</ul>
<hr>
<h2 id="AAN-Attributes-Aware-Network-for-Temporal-Action-Detection"><a href="#AAN-Attributes-Aware-Network-for-Temporal-Action-Detection" class="headerlink" title="AAN: Attributes-Aware Network for Temporal Action Detection"></a>AAN: Attributes-Aware Network for Temporal Action Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00696">http://arxiv.org/abs/2309.00696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Dai, Srijan Das, Michael S. Ryoo, Francois Bremond</li>
<li>for: 本研究的目的是解决长期视频理解中的效率EXTRACTING object semantics和其关系模型，以便对下游任务进行更好的支持。</li>
<li>methods: 本研究提出了Attributes-Aware Network（AAN），包括两个关键组件：Attributes Extractor和Graph Reasoning block。这两个组件可以帮助EXTRACTING object-centric attributes和视频中对象关系的模型。</li>
<li>results: 通过利用CLIP特征，AAN超过了当前state-of-the-art方法在Charades和Toyota Smarthome Untrimmed dataset上的性能。<details>
<summary>Abstract</summary>
The challenge of long-term video understanding remains constrained by the efficient extraction of object semantics and the modelling of their relationships for downstream tasks. Although the CLIP visual features exhibit discriminative properties for various vision tasks, particularly in object encoding, they are suboptimal for long-term video understanding. To address this issue, we present the Attributes-Aware Network (AAN), which consists of two key components: the Attributes Extractor and a Graph Reasoning block. These components facilitate the extraction of object-centric attributes and the modelling of their relationships within the video. By leveraging CLIP features, AAN outperforms state-of-the-art approaches on two popular action detection datasets: Charades and Toyota Smarthome Untrimmed datasets.
</details>
<details>
<summary>摘要</summary>
“长期视频理解的挑战仍然受到有效提取对象 semantics 和其关系的模型化限制。虽然 CLIP 视觉特征具有多种视觉任务中的推断性质，特别是对象编码，但它们对长期视频理解不利。为解决这个问题，我们提出了 Attributes-Aware Network（AAN），它包括两个关键组件：Attributes Extractor 和 Graph Reasoning 块。这两个组件可以帮助提取对象-中心的特征和视频中的对象关系。通过利用 CLIP 特征，AAN 超越了现有的状态泰施 Approaches 在 Charades 和 Toyota Smarthome Untrimmed 数据集上表现出色。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The Traditional Chinese writing system is also widely used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="OpenIns3D-Snap-and-Lookup-for-3D-Open-vocabulary-Instance-Segmentation"><a href="#OpenIns3D-Snap-and-Lookup-for-3D-Open-vocabulary-Instance-Segmentation" class="headerlink" title="OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation"></a>OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00616">http://arxiv.org/abs/2309.00616</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pointcept/OpenIns3D">https://github.com/Pointcept/OpenIns3D</a></li>
<li>paper_authors: Zhening Huang, Xiaoyang Wu, Xi Chen, Hengshuang Zhao, Lei Zhu, Joan Lasenby</li>
<li>for: This paper is written for 3D open-vocabulary scene understanding at the instance level, without requiring any 2D image inputs.</li>
<li>methods: The OpenIns3D framework uses a “Mask-Snap-Lookup” scheme, which consists of a “Mask” module for class-agnostic mask proposals in 3D point clouds, a “Snap” module for generating synthetic scene-level images, and a “Lookup” module for assigning category names to the proposed masks using Mask2Pixel maps.</li>
<li>results: The proposed approach achieved state-of-the-art results on a wide range of indoor and outdoor datasets with a large margin, and it also allows for effortless switching of 2D detectors without re-training. Additionally, when integrated with state-of-the-art 2D open-world models and large language models (LLMs), it demonstrates excellent performance on open-vocabulary instance segmentation and processing complex text queries.<details>
<summary>Abstract</summary>
Current 3D open-vocabulary scene understanding methods mostly utilize well-aligned 2D images as the bridge to learn 3D features with language. However, applying these approaches becomes challenging in scenarios where 2D images are absent. In this work, we introduce a completely new pipeline, namely, OpenIns3D, which requires no 2D image inputs, for 3D open-vocabulary scene understanding at the instance level. The OpenIns3D framework employs a "Mask-Snap-Lookup" scheme. The "Mask" module learns class-agnostic mask proposals in 3D point clouds. The "Snap" module generates synthetic scene-level images at multiple scales and leverages 2D vision language models to extract interesting objects. The "Lookup" module searches through the outcomes of "Snap" with the help of Mask2Pixel maps, which contain the precise correspondence between 3D masks and synthetic images, to assign category names to the proposed masks. This 2D input-free, easy-to-train, and flexible approach achieved state-of-the-art results on a wide range of indoor and outdoor datasets with a large margin. Furthermore, OpenIns3D allows for effortless switching of 2D detectors without re-training. When integrated with state-of-the-art 2D open-world models such as ODISE and GroundingDINO, superb results are observed on open-vocabulary instance segmentation. When integrated with LLM-powered 2D models like LISA, it demonstrates a remarkable capacity to process highly complex text queries, including those that require intricate reasoning and world knowledge. Project page: https://zheninghuang.github.io/OpenIns3D/
</details>
<details>
<summary>摘要</summary>
当前的3D开 vocabularyScene理解方法通常使用Well-aligned的2D图像作为桥接学习3D特征。然而，在没有2D图像的场景下，这些方法变得困难。在这项工作中，我们引入了一个completely新的管道，即OpenIns3D，它不需要2D图像输入，可以实现3D开 vocabularyScene理解的实例水平。OpenIns3D框架采用“Mask-Snap-Lookup”的方案。“Mask”模块学习类型不敏感的3D点云掩模。“Snap”模块生成多个尺度的 sintetic场景图像，并利用2D视觉语言模型提取有趣的对象。“Lookup”模块通过Mask2Pixel地图，该地图包含3D掩模和 sintetic图像之间的准确对应关系，将提案的掩模分配类别名称。这种没有2D输入、易于训练、灵活的方法在各种室外和室内数据集上实现了状态的前一个Result，并且可以轻松地将2D检测器更换，无需重新训练。当与开放世界2D模型如ODISE和GroundingDINO集成后，Superb的结果被观察到。当与LLM力量2D模型如LISA集成后，它表现出了对高级推理和世界知识的强大处理能力。项目页面：https://zheninghuang.github.io/OpenIns3D/
</details></li>
</ul>
<hr>
<h2 id="CityDreamer-Compositional-Generative-Model-of-Unbounded-3D-Cities"><a href="#CityDreamer-Compositional-Generative-Model-of-Unbounded-3D-Cities" class="headerlink" title="CityDreamer: Compositional Generative Model of Unbounded 3D Cities"></a>CityDreamer: Compositional Generative Model of Unbounded 3D Cities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00610">http://arxiv.org/abs/2309.00610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hzxie/city-dreamer">https://github.com/hzxie/city-dreamer</a></li>
<li>paper_authors: Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu</li>
<li>for: This paper focuses on the generation of 3D cities, which has received less attention in recent years despite the greater challenges it poses due to human sensitivity to structural distortions and the complexity of generating buildings with a wide range of appearances.</li>
<li>methods: The proposed method, CityDreamer, is a compositional generative model that separates the generation of building instances from other background objects into distinct modules, and uses two datasets (OSM and GoogleEarth) to enhance the realism of the generated 3D cities.</li>
<li>results: Through extensive experiments, CityDreamer has proven its superiority over state-of-the-art methods in generating a wide range of lifelike 3D cities.Here’s the text in Traditional Chinese for reference:</li>
<li>for: 这篇论文主要关注3D城市生成，这个领域在最近几年来受到了更多的研究，但是3D城市生成仍然受到了更大的挑战，主要是因为人类对城市环境的构造性变化更加敏感，而且生成建筑物的类型和外观相对更加复杂。</li>
<li>methods: 提案的方法是CityDreamer，这是一个具有分类生成模型的3D城市生成方法，它将建筑物实例的生成与其他背景物体（如道路、绿地和水域）分类为不同的模块，并使用OSM和GoogleEarth这两个 datasets来增强生成的3D城市的现实感。</li>
<li>results: 经过了广泛的实验，CityDreamer已经证明了它在生成各种生活力强的3D城市方面的优越性，比起现有的方法更加出色。<details>
<summary>Abstract</summary>
In recent years, extensive research has focused on 3D natural scene generation, but the domain of 3D city generation has not received as much exploration. This is due to the greater challenges posed by 3D city generation, mainly because humans are more sensitive to structural distortions in urban environments. Additionally, generating 3D cities is more complex than 3D natural scenes since buildings, as objects of the same class, exhibit a wider range of appearances compared to the relatively consistent appearance of objects like trees in natural scenes. To address these challenges, we propose CityDreamer, a compositional generative model designed specifically for unbounded 3D cities, which separates the generation of building instances from other background objects, such as roads, green lands, and water areas, into distinct modules. Furthermore, we construct two datasets, OSM and GoogleEarth, containing a vast amount of real-world city imagery to enhance the realism of the generated 3D cities both in their layouts and appearances. Through extensive experiments, CityDreamer has proven its superiority over state-of-the-art methods in generating a wide range of lifelike 3D cities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Time-Series-Analysis-of-Urban-Liveability"><a href="#Time-Series-Analysis-of-Urban-Liveability" class="headerlink" title="Time Series Analysis of Urban Liveability"></a>Time Series Analysis of Urban Liveability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00594">http://arxiv.org/abs/2309.00594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Levering, Diego Marcos, Devis Tuia</li>
<li>for: 这篇论文探讨了深度学习模型来监测荷兰城市的长期生活品质变化。</li>
<li>methods: 该论文使用了高分辨率飞行图像和年度生活指标组合生成年度时间步骤，并使用了一个基于2016年飞行图像和生活指标的卷积神经网络来预测新时间步骤的生活品质。</li>
<li>results: 在训练城市（阿姆斯特丹）和 nunca before seen 城市（英顿）的结果中，显示了一些难以理解的趋势，特别是在不同时间步骤的图像获取方式下。这种结果 demonstarte了监测生活品质变化的复杂性，以及需要更加复杂的方法来补做不同于生活品质动态的变化。<details>
<summary>Abstract</summary>
In this paper we explore deep learning models to monitor longitudinal liveability changes in Dutch cities at the neighbourhood level. Our liveability reference data is defined by a country-wise yearly survey based on a set of indicators combined into a liveability score, the Leefbaarometer. We pair this reference data with yearly-available high-resolution aerial images, which creates yearly timesteps at which liveability can be monitored. We deploy a convolutional neural network trained on an aerial image from 2016 and the Leefbaarometer score to predict liveability at new timesteps 2012 and 2020. The results in a city used for training (Amsterdam) and one never seen during training (Eindhoven) show some trends which are difficult to interpret, especially in light of the differences in image acquisitions at the different time steps. This demonstrates the complexity of liveability monitoring across time periods and the necessity for more sophisticated methods compensating for changes unrelated to liveability dynamics.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们探讨深度学习模型来监测荷兰城市的长期生活质量变化。我们的生活质量参照数据是基于年度国家调查，并将各个指标组合成一个生活质量分数，称为Leefbaarometer。我们将年度可用的高分辨率航空图像与参照数据对应，从而创造了年度时间步。我们使用2016年的航空图像和Leefbaarometer分数来训练卷积神经网络，并用这些神经网络预测2012年和2020年的生活质量。在训练城市（阿姆斯特丹）和 nunca before seen during training 的城市（恩登霍恩）的结果中，我们发现了一些难以理解的趋势，特别是在不同时间步的图像获取方式的影响下。这表明监测生活质量的变化 across time periods 的复杂性，以及需要更加复杂的方法来补做不related to liveability dynamics的变化。
</details></li>
</ul>
<hr>
<h2 id="Discrete-Morphological-Neural-Networks"><a href="#Discrete-Morphological-Neural-Networks" class="headerlink" title="Discrete Morphological Neural Networks"></a>Discrete Morphological Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00588">http://arxiv.org/abs/2309.00588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmarcondes/dmnn">https://github.com/dmarcondes/dmnn</a></li>
<li>paper_authors: Diego Marcondes, Junior Barrera</li>
<li>for: 本文提出了一种基于数学形态学（MM）的二进制图像运算设计方法，即离散形态神经网络（DMNN），用于二进制图像分析。</li>
<li>methods: 本文提出了一种基于机器学习的离散形态神经网络（DMNN）架构，该架构采用了传统的 morphological computational graph，并通过一种名为 lattice gradient descent algorithm（LGDA）来训练这些参数。</li>
<li>results: 本文应用了 DMNN 来识别受噪的数字边缘，并讨论了多个未来研究的话题。<details>
<summary>Abstract</summary>
A classical approach to designing binary image operators is Mathematical Morphology (MM). We propose the Discrete Morphological Neural Networks (DMNN) for binary image analysis to represent W-operators and estimate them via machine learning. A DMNN architecture, which is represented by a Morphological Computational Graph, is designed as in the classical heuristic design of morphological operators, in which the designer should combine a set of MM operators and Boolean operations based on prior information and theoretical knowledge. Then, once the architecture is fixed, instead of adjusting its parameters (i.e., structural elements or maximal intervals) by hand, we propose a lattice gradient descent algorithm (LGDA) to train these parameters based on a sample of input and output images under the usual machine learning approach. We also propose a stochastic version of the LGDA that is more efficient, is scalable and can obtain small error in practical problems. The class represented by a DMNN can be quite general or specialized according to expected properties of the target operator, i.e., prior information, and the semantic expressed by algebraic properties of classes of operators is a differential relative to other methods. The main contribution of this paper is the merger of the two main paradigms for designing morphological operators: classical heuristic design and automatic design via machine learning. Thus, conciliating classical heuristic morphological operator design with machine learning. We apply the DMNN to recognize the boundary of digits with noise, and we discuss many topics for future research.
</details>
<details>
<summary>摘要</summary>
经典方法设计二进制图像运算员是数学形态学（MM）。我们提议使用数字形态神经网络（DMNN）来表示二进制图像分析，以代表W-运算员并使用机器学习来估算。DMNN架构，表示为形态计算图，是根据经典的规范设计形态操作员，其中设计师将组合一组MM操作员和逻辑运算，根据优化目标和理论知识。然后，在架构固定后，而不是手动调整其结构元素或最大间隔的参数，我们提议使用格子梯度下降算法（LGDA）来训练这些参数，根据输入和输出图像的样本。我们还提议一种随机版本的LGDA，它更高效、可扩展和可以在实际问题中获得小的错误。DMNN的类可以是非常一般或特殊，根据预期的目标运算员的特性和优化目标。我们的主要贡献在于将经典的规范设计和自动设计融合在一起，因此把经典规范设计与机器学习融合在一起。我们应用DMNN来识别数字的边缘，并讨论了许多未来研究的话题。
</details></li>
</ul>
<hr>
<h2 id="Mechanism-of-feature-learning-in-convolutional-neural-networks"><a href="#Mechanism-of-feature-learning-in-convolutional-neural-networks" class="headerlink" title="Mechanism of feature learning in convolutional neural networks"></a>Mechanism of feature learning in convolutional neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00570">http://arxiv.org/abs/2309.00570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aradha/convrfm">https://github.com/aradha/convrfm</a></li>
<li>paper_authors: Daniel Beaglehole, Adityanarayanan Radhakrishnan, Parthe Pandit, Mikhail Belkin</li>
<li>for: 本研究旨在解释深度学习中图像数据中特征学习的机制。</li>
<li>methods: 我们提出了卷积神经特征假设，即卷积层 filters的covariances是对输入图像中patches的average gradient outer product（AGOP）的平均值。我们提供了丰富的实验证据，包括AlexNet、VGG和ResNets等标准神经网络在ImageNet上的预训练时，卷积层 filters的covariances和patch-based AGOPs之间高度相关性。我们还提供了支持性的理论证据。</li>
<li>results: 我们的结果表明，使用patch-based AGOP可以启用深度特征学习在卷积核机中。我们称之为（深）ConvRFM，并证明其能够恢复深度 convolutional networks 中的类似特征。此外，我们发现Deep ConvRFM可以超越先前发现的卷积核的限制，例如对本地信号的适应能力和不可变性，从而导致性能提高。<details>
<summary>Abstract</summary>
Understanding the mechanism of how convolutional neural networks learn features from image data is a fundamental problem in machine learning and computer vision. In this work, we identify such a mechanism. We posit the Convolutional Neural Feature Ansatz, which states that covariances of filters in any convolutional layer are proportional to the average gradient outer product (AGOP) taken with respect to patches of the input to that layer. We present extensive empirical evidence for our ansatz, including identifying high correlation between covariances of filters and patch-based AGOPs for convolutional layers in standard neural architectures, such as AlexNet, VGG, and ResNets pre-trained on ImageNet. We also provide supporting theoretical evidence. We then demonstrate the generality of our result by using the patch-based AGOP to enable deep feature learning in convolutional kernel machines. We refer to the resulting algorithm as (Deep) ConvRFM and show that our algorithm recovers similar features to deep convolutional networks including the notable emergence of edge detectors. Moreover, we find that Deep ConvRFM overcomes previously identified limitations of convolutional kernels, such as their inability to adapt to local signals in images and, as a result, leads to sizable performance improvement over fixed convolutional kernels.
</details>
<details>
<summary>摘要</summary>
We then demonstrate the generality of our result by using the patch-based AGOP to enable deep feature learning in convolutional kernel machines. We refer to the resulting algorithm as (Deep) ConvRFM and show that our algorithm recovers similar features to deep convolutional networks, including the notable emergence of edge detectors. Moreover, we find that Deep ConvRFM overcomes previously identified limitations of convolutional kernels, such as their inability to adapt to local signals in images, and leads to sizable performance improvement over fixed convolutional kernels.
</details></li>
</ul>
<hr>
<h2 id="Amyloid-Beta-Axial-Plane-PET-Synthesis-from-Structural-MRI-An-Image-Translation-Approach-for-Screening-Alzheimer’s-Disease"><a href="#Amyloid-Beta-Axial-Plane-PET-Synthesis-from-Structural-MRI-An-Image-Translation-Approach-for-Screening-Alzheimer’s-Disease" class="headerlink" title="Amyloid-Beta Axial Plane PET Synthesis from Structural MRI: An Image Translation Approach for Screening Alzheimer’s Disease"></a>Amyloid-Beta Axial Plane PET Synthesis from Structural MRI: An Image Translation Approach for Screening Alzheimer’s Disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00569">http://arxiv.org/abs/2309.00569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando Vega, Abdoljalil Addeh, M. Ethan MacDonald</li>
<li>for: 用于生成基于MRI的Synthetic抑衰β蛋白PET图像，以便获取β蛋白信息。</li>
<li>methods: 使用图像翻译模型，将MRI图像与β蛋白PET图像进行对应，以实现从结构图像到量化图像的转换。</li>
<li>results: 通过对MRI图像和β蛋白PET图像的对应，可以生成高度相似于真实的Synthetic抑衰β蛋白PET图像，具有高度的SSIM和PSNR。<details>
<summary>Abstract</summary>
In this work, an image translation model is implemented to produce synthetic amyloid-beta PET images from structural MRI that are quantitatively accurate. Image pairs of amyloid-beta PET and structural MRI were used to train the model. We found that the synthetic PET images could be produced with a high degree of similarity to truth in terms of shape, contrast and overall high SSIM and PSNR. This work demonstrates that performing structural to quantitative image translation is feasible to enable the access amyloid-beta information from only MRI.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们实现了一种图像翻译模型，以生成基于MRI的蛋白β扩散图像，并且这些图像具有高度准确的量化性。我们使用了蛋白β扩散图像和MRI图像的对应对来训练模型。我们发现，使用这种方法可以生成高度相似于真实的蛋白β扩散图像，包括形态、对比度和总体高度匹配SSIM和PSNR。这个研究表明，从MRI图像中获取蛋白β信息是可能的，并且这种方法可以帮助解决蛋白β扩散图像的缺失问题。
</details></li>
</ul>
<hr>
<h2 id="Fused-Classification-For-Differential-Face-Morphing-Detection"><a href="#Fused-Classification-For-Differential-Face-Morphing-Detection" class="headerlink" title="Fused Classification For Differential Face Morphing Detection"></a>Fused Classification For Differential Face Morphing Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00665">http://arxiv.org/abs/2309.00665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iurii Medvedev, Joana Pimenta, Nuno Gonçalves</li>
<li>for: 防止面部识别系统受到面形变换攻击</li>
<li>methods: 基于融合分类方法进行无参数检测</li>
<li>results: 实验结果表明方法有效地检测 morphing 攻击<details>
<summary>Abstract</summary>
Face morphing, a sophisticated presentation attack technique, poses significant security risks to face recognition systems. Traditional methods struggle to detect morphing attacks, which involve blending multiple face images to create a synthetic image that can match different individuals. In this paper, we focus on the differential detection of face morphing and propose an extended approach based on fused classification method for no-reference scenario. We introduce a public face morphing detection benchmark for the differential scenario and utilize a specific data mining technique to enhance the performance of our approach. Experimental results demonstrate the effectiveness of our method in detecting morphing attacks.
</details>
<details>
<summary>摘要</summary>
面部融合攻击，一种复杂的演示攻击技术，对人脸识别系统 pose  significiant 安全风险。传统方法很难探测融合攻击，这些攻击 involve 混合多个人脸图像生成一个合成图像，可以与不同个体匹配。在这篇论文中，我们关注 differential 探测方法，并提出基于融合分类方法的延展方法，用于无参考enario。我们引入一个公共人脸融合检测标准套件，并利用特定的数据挖掘技术来提高我们的方法的性能。实验结果表明我们的方法有效地探测融合攻击。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-Image-Context-for-Single-Deep-Learning-Face-Morphing-Attack-Detection"><a href="#Impact-of-Image-Context-for-Single-Deep-Learning-Face-Morphing-Attack-Detection" class="headerlink" title="Impact of Image Context for Single Deep Learning Face Morphing Attack Detection"></a>Impact of Image Context for Single Deep Learning Face Morphing Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00549">http://arxiv.org/abs/2309.00549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joana Pimenta, Iurii Medvedev, Nuno Gonçalves</li>
<li>for: 本研究探讨了深度学习 face morphing 检测性能如何受到输入图像对齐设置的影响。</li>
<li>methods: 本研究使用了深度学习技术对 face morphing 进行检测，并分析了面 contour 和图像上下文之间的关系，以提出优化输入图像对齐的方法。</li>
<li>results: 研究发现，适当地调整输入图像对齐设置可以提高深度学习 face morphing 检测性能。<details>
<summary>Abstract</summary>
The increase in security concerns due to technological advancements has led to the popularity of biometric approaches that utilize physiological or behavioral characteristics for enhanced recognition. Face recognition systems (FRSs) have become prevalent, but they are still vulnerable to image manipulation techniques such as face morphing attacks. This study investigates the impact of the alignment settings of input images on deep learning face morphing detection performance. We analyze the interconnections between the face contour and image context and suggest optimal alignment conditions for face morphing detection.
</details>
<details>
<summary>摘要</summary>
技术进步引起的安全问题带来了基于生物特征的识别方法的普遍性，特别是面Recognition系统（FRS）。然而，FRS仍然容易受到图像修改技术的袭击，如面形变换攻击。本研究研究输入图像的Alignment设置对深度学习面形变换检测性能的影响。我们分析面 outline和图像Context之间的关系，并提出优化Alignment条件以提高面形变换检测性能。Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="Trust-your-Good-Friends-Source-free-Domain-Adaptation-by-Reciprocal-Neighborhood-Clustering"><a href="#Trust-your-Good-Friends-Source-free-Domain-Adaptation-by-Reciprocal-Neighborhood-Clustering" class="headerlink" title="Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering"></a>Trust your Good Friends: Source-free Domain Adaptation by Reciprocal Neighborhood Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00528">http://arxiv.org/abs/2309.00528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, Shangling Jui, Jian Yang</li>
<li>for: 本研究目的是解决无法获取源数据的情况下，进行领域适应（DA）的问题。</li>
<li>methods: 我们的方法基于目标数据中的自然结构，包括本地相似性和扩展 neighboorhood。</li>
<li>results: 我们的方法在多个2D图像和3D点云识别dataset上达到了状态 искусственный智能的性能。<details>
<summary>Abstract</summary>
Domain adaptation (DA) aims to alleviate the domain shift between source domain and target domain. Most DA methods require access to the source data, but often that is not possible (e.g. due to data privacy or intellectual property). In this paper, we address the challenging source-free domain adaptation (SFDA) problem, where the source pretrained model is adapted to the target domain in the absence of source data. Our method is based on the observation that target data, which might not align with the source domain classifier, still forms clear clusters. We capture this intrinsic structure by defining local affinity of the target data, and encourage label consistency among data with high local affinity. We observe that higher affinity should be assigned to reciprocal neighbors. To aggregate information with more context, we consider expanded neighborhoods with small affinity values. Furthermore, we consider the density around each target sample, which can alleviate the negative impact of potential outliers. In the experimental results we verify that the inherent structure of the target features is an important source of information for domain adaptation. We demonstrate that this local structure can be efficiently captured by considering the local neighbors, the reciprocal neighbors, and the expanded neighborhood. Finally, we achieve state-of-the-art performance on several 2D image and 3D point cloud recognition datasets.
</details>
<details>
<summary>摘要</summary>
领域适应（DA）的目标是解决源领域和目标领域之间的频率差异。大多数DA方法需要访问源数据，但在一些情况下，这并不可能（例如，由于数据隐私或知识产权等原因）。在这篇论文中，我们面临着难以进行频率适应（SFDA）问题，其中源预训练模型被应用到目标领域中，无法访问源数据。我们基于目标数据的内在结构的观察，即目标数据可能不符合源领域分类器的分类结果。我们通过定义目标数据的本地相互关系来捕捉这种内在结构，并且鼓励标签相互一致。我们发现，更高的相互关系应该被分配给对应的反向邻居。为了更好地融合信息，我们考虑了扩展的邻里域，并且考虑了每个目标样本的扩展邻里域。此外，我们还考虑了每个目标样本的密度，以避免潜在的异常值的影响。在实验结果中，我们证明了目标特征的内在结构是频率适应中的重要信息来源。我们表明了这种本地结构可以通过考虑本地邻居、反向邻居和扩展邻里域来效率地捕捉。最后，我们在多个2D图像和3D点云认知dataset上实现了状态的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="SQLdepth-Generalizable-Self-Supervised-Fine-Structured-Monocular-Depth-Estimation"><a href="#SQLdepth-Generalizable-Self-Supervised-Fine-Structured-Monocular-Depth-Estimation" class="headerlink" title="SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation"></a>SQLdepth: Generalizable Self-Supervised Fine-Structured Monocular Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00526">http://arxiv.org/abs/2309.00526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youhong Wang, Yunji Liang, Hao Xu, Shaohui Jiao, Hongkai Yu</li>
<li>for: 本研究旨在提出一种可以有效地从动态视觉中学习细腻场景结构的自助监督灰度估计方法，以提高自主驾驶和 роботех学的应用性。</li>
<li>methods: 本方法提出了一种新的 Self Query Layer (SQL)，用于建立自身成本量，从而直接从量中INFER depth，而不是从特征图中INFER depth。这种自身成本量隐式地捕捉了场景的内在几何结构，每个时刻的卷积缓存都表示了相对的距离关系。最后，这个量通过一种新的解码方法转换为深度图。</li>
<li>results: 实验结果表明，我们的方法在KITTI和Cityscapes上达到了remarkable的状态数据表现（AbsRel &#x3D; $0.082$ on KITTI, $0.052$ on KITTI with improved ground-truth, $0.106$ on Cityscapes），与前一个最佳方法相比，减少了9.9%、5.5%和4.5%的误差。此外，我们的方法还展示了减少训练复杂度、计算效率、改进的普适性和可以恢复细腻场景细节的能力。同时，自身匹配推导的SQLdepth可以在不同的摄像头和环境下进行适应性训练，并且可以在不同的任务上进行适应性测试。<details>
<summary>Abstract</summary>
Recently, self-supervised monocular depth estimation has gained popularity with numerous applications in autonomous driving and robotics. However, existing solutions primarily seek to estimate depth from immediate visual features, and struggle to recover fine-grained scene details with limited generalization. In this paper, we introduce SQLdepth, a novel approach that can effectively learn fine-grained scene structures from motion. In SQLdepth, we propose a novel Self Query Layer (SQL) to build a self-cost volume and infer depth from it, rather than inferring depth from feature maps. The self-cost volume implicitly captures the intrinsic geometry of the scene within a single frame. Each individual slice of the volume signifies the relative distances between points and objects within a latent space. Ultimately, this volume is compressed to the depth map via a novel decoding approach. Experimental results on KITTI and Cityscapes show that our method attains remarkable state-of-the-art performance (AbsRel = $0.082$ on KITTI, $0.052$ on KITTI with improved ground-truth and $0.106$ on Cityscapes), achieves $9.9\%$, $5.5\%$ and $4.5\%$ error reduction from the previous best. In addition, our approach showcases reduced training complexity, computational efficiency, improved generalization, and the ability to recover fine-grained scene details. Moreover, the self-supervised pre-trained and metric fine-tuned SQLdepth can surpass existing supervised methods by significant margins (AbsRel = $0.043$, $14\%$ error reduction). self-matching-oriented relative distance querying in SQL improves the robustness and zero-shot generalization capability of SQLdepth. Code and the pre-trained weights will be publicly available. Code is available at \href{https://github.com/hisfog/SQLdepth-Impl}{https://github.com/hisfog/SQLdepth-Impl}.
</details>
<details>
<summary>摘要</summary>
最近，自主指导单目深度估计已经在自动驾驶和机器人领域得到了广泛的应用。然而，现有的解决方案主要是从直接视觉特征中估计深度，而忽略了细节Scene的恢复。在这篇论文中，我们提出了一种新的方法，即SQLdepth，可以有效地从运动中学习细节Scene的结构。在SQLdepth中，我们提出了一种新的Self Query层（SQL），用于建立自身成本Volume并从中估计深度，而不是从特征图进行估计。这个自身成本Volume隐式地捕捉了场景的内在几何结构，每个层次的尺度都表示了点和物体之间的相对距离在潜在空间中。最终，这个Volume通过一种新的解码方法压缩到深度图。实验结果表明，我们的方法在KITTI和Cityscapes上达到了非常出色的状态态表现（AbsRel = $0.082$ on KITTI, $0.052$ on KITTI with improved ground truth and $0.106$ on Cityscapes），实现了$9.9\%$, $5.5\%$和$4.5\%$的错误减少。此外，我们的方法还显示了减少训练复杂性、计算效率、改进的泛化和恢复细节Scene的能力。此外，自主匹配方向的相对距离查询在SQL中提高了SQLdepth的Robustness和零shot泛化能力。代码和预训练 веса将在公共可用。代码可以在 \href{https://github.com/hisfog/SQLdepth-Impl}{https://github.com/hisfog/SQLdepth-Impl} 上找到。
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Vision-Method-for-Correction-of-Eccentric-Error-Based-on-Adaptive-Enhancement-Algorithm"><a href="#A-Machine-Vision-Method-for-Correction-of-Eccentric-Error-Based-on-Adaptive-Enhancement-Algorithm" class="headerlink" title="A Machine Vision Method for Correction of Eccentric Error: Based on Adaptive Enhancement Algorithm"></a>A Machine Vision Method for Correction of Eccentric Error: Based on Adaptive Enhancement Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00514">http://arxiv.org/abs/2309.00514</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fanyi Wang, Pin Cao, Yihui Zhang, Haotian Hu, Yongying Yang</li>
<li>for: 这 paper 的目的是提出一种机器视觉方法来修正大开口几何镜元件上的表面缺陷。</li>
<li>methods: 该方法使用了改进的 Adaptive Enhancement Algorithm (AEA), 包括现有的 Guided Filter Dark Channel Dehazing Algorithm (GFA) 和提出的轻量级 Multi-scale Densely Connected Network (MDC-Net)。</li>
<li>results: 该方法可以减少表面缺陷的误差到 Within 10um，并且具有一定的实时性。<details>
<summary>Abstract</summary>
In the procedure of surface defects detection for large-aperture aspherical optical elements, it is of vital significance to adjust the optical axis of the element to be coaxial with the mechanical spin axis accurately. Therefore, a machine vision method for eccentric error correction is proposed in this paper. Focusing on the severe defocus blur of reference crosshair image caused by the imaging characteristic of the aspherical optical element, which may lead to the failure of correction, an Adaptive Enhancement Algorithm (AEA) is proposed to strengthen the crosshair image. AEA is consisted of existed Guided Filter Dark Channel Dehazing Algorithm (GFA) and proposed lightweight Multi-scale Densely Connected Network (MDC-Net). The enhancement effect of GFA is excellent but time-consuming, and the enhancement effect of MDC-Net is slightly inferior but strongly real-time. As AEA will be executed dozens of times during each correction procedure, its real-time performance is very important. Therefore, by setting the empirical threshold of definition evaluation function SMD2, GFA and MDC-Net are respectively applied to highly and slightly blurred crosshair images so as to ensure the enhancement effect while saving as much time as possible. AEA has certain robustness in time-consuming performance, which takes an average time of 0.2721s and 0.0963s to execute GFA and MDC-Net separately on ten 200pixels 200pixels Region of Interest (ROI) images with different degrees of blur. And the eccentricity error can be reduced to within 10um by our method.
</details>
<details>
<summary>摘要</summary>
在大开口非球面光元件表面缺陷检测过程中，准确调整光轴与机械轴的准确性至关重要。因此，这篇文章提出了一种机器视觉方法来修正不对称错误。关注大开口非球面光元件的极大模糊效应，可能导致修正失败，这篇文章提出了一种适应增强算法（AEA）来强化交叉线图像。AEA由现有的导引灰度黑色滤波算法（GFA）和提议的轻量级多尺度紧密连接网络（MDC-Net）组成。GFA的增强效果非常好，但是时间耗费较长，而MDC-Net的增强效果较弱，但是实时性非常好。因此，在每次修正过程中，AEA将被执行数十次，因此其实时性非常重要。因此，通过设置定义评估函数SMD2的实际阈值，GFA和MDC-Net分别应用于高度模糊和轻度模糊的交叉线图像，以确保增强效果而尽可能地避免时间浪费。AEA具有一定的实时性，每个ROI图像需要0.2721秒和0.0963秒分别使用GFA和MDC-Net进行处理，并且可以将不对称错误降到10um以下。
</details></li>
</ul>
<hr>
<h2 id="Multi-stage-Deep-Learning-Artifact-Reduction-for-Computed-Tomography"><a href="#Multi-stage-Deep-Learning-Artifact-Reduction-for-Computed-Tomography" class="headerlink" title="Multi-stage Deep Learning Artifact Reduction for Computed Tomography"></a>Multi-stage Deep Learning Artifact Reduction for Computed Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00494">http://arxiv.org/abs/2309.00494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiayang Shi, Daniel M. Pelt, K. Joost Batenburg</li>
<li>For: 提高计算tomography（CT）图像质量，减少图像artefacts。* Methods: 使用多个域（如投影图像和重建图像）的深度学习方法进行artefact除去，与传统的CT处理管道类似。* Results: 对于 simulate和实际实验数据集，我们的方法可以减少artefacts，并且比deep learning基于后处理的方法更高效。<details>
<summary>Abstract</summary>
In Computed Tomography (CT), an image of the interior structure of an object is computed from a set of acquired projection images. The quality of these reconstructed images is essential for accurate analysis, but this quality can be degraded by a variety of imaging artifacts. To improve reconstruction quality, the acquired projection images are often processed by a pipeline consisting of multiple artifact-removal steps applied in various image domains (e.g., outlier removal on projection images and denoising of reconstruction images). These artifact-removal methods exploit the fact that certain artifacts are easier to remove in a certain domain compared with other domains.   Recently, deep learning methods have shown promising results for artifact removal for CT images. However, most existing deep learning methods for CT are applied as a post-processing method after reconstruction. Therefore, artifacts that are relatively difficult to remove in the reconstruction domain may not be effectively removed by these methods. As an alternative, we propose a multi-stage deep learning method for artifact removal, in which neural networks are applied to several domains, similar to a classical CT processing pipeline. We show that the neural networks can be effectively trained in succession, resulting in easy-to-use and computationally efficient training. Experiments on both simulated and real-world experimental datasets show that our method is effective in reducing artifacts and superior to deep learning-based post-processing.
</details>
<details>
<summary>摘要</summary>
在计算 Tomography（CT）中，通过一组获取的投影图像计算对象内部结构的图像。这些重建图像的质量非常重要，但可能受到多种损害像素的影响。为了提高重建质量，通常将获取的投影图像处理为多个遗传元素去除抗错的步骤，这些步骤在不同的图像领域（例如，投影图像上的异常值除去和重建图像上的锈除）。这些遗传元素去除方法利用了某些遗传元素更易于在某个领域中除去，相比之下其他领域。  最近，深度学习方法在CT图像中表现出了扩展的成果。然而，大多数现有的深度学习方法在CT图像中是作为后处理方法进行应用，因此，在重建领域中存在一些难以除去的遗传元素可能无法有效地除去。作为替代方案，我们提出了一种多Stage深度学习方法，在这种方法中，神经网络在多个领域中应用，类似于传统的CT处理管道。我们发现，这些神经网络可以在继序中有效地训练，从而实现了容易使用和计算效率高的训练。在模拟和实际实验数据集上，我们的方法能够有效地减少遗传元素，并且与深度学习基于后处理的方法相比，表现出优异。
</details></li>
</ul>
<hr>
<h2 id="Asymmetric-double-winged-multi-view-clustering-network-for-exploring-Diverse-and-Consistent-Information"><a href="#Asymmetric-double-winged-multi-view-clustering-network-for-exploring-Diverse-and-Consistent-Information" class="headerlink" title="Asymmetric double-winged multi-view clustering network for exploring Diverse and Consistent Information"></a>Asymmetric double-winged multi-view clustering network for exploring Diverse and Consistent Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00474">http://arxiv.org/abs/2309.00474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qun Zheng, Xihong Yang, Siwei Wang, Xinru An, Qi Liu</li>
<li>for: 这个论文旨在提出一个新的多观点聚类网络（CodingNet），以同时探索多观点数据中的多样和一致信息。</li>
<li>methods: 这个网络使用非对称架构，分别提取了 shallow 和 deep 特征。然后，通过调整 shallow 特征相似度矩阵，以确保多观点数据的多样性。此外，我们提出了一个双重对比机制，以维持 deep 特征在多观点和伪标端层上的一致性。</li>
<li>results: 在六个广泛使用的 benchmarkt 数据集上进行了广泛的实验，证明了我们的框架在多观点聚类 зада期中的高效性，并大多超过了现有的多观点聚类算法。<details>
<summary>Abstract</summary>
In unsupervised scenarios, deep contrastive multi-view clustering (DCMVC) is becoming a hot research spot, which aims to mine the potential relationships between different views. Most existing DCMVC algorithms focus on exploring the consistency information for the deep semantic features, while ignoring the diverse information on shallow features. To fill this gap, we propose a novel multi-view clustering network termed CodingNet to explore the diverse and consistent information simultaneously in this paper. Specifically, instead of utilizing the conventional auto-encoder, we design an asymmetric structure network to extract shallow and deep features separately. Then, by aligning the similarity matrix on the shallow feature to the zero matrix, we ensure the diversity for the shallow features, thus offering a better description of multi-view data. Moreover, we propose a dual contrastive mechanism that maintains consistency for deep features at both view-feature and pseudo-label levels. Our framework's efficacy is validated through extensive experiments on six widely used benchmark datasets, outperforming most state-of-the-art multi-view clustering algorithms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。</SYS>>在无监督场景下，深度对比多视图划分（DCMVC）正在成为研究热点，旨在挖掘不同视图之间的潜在关系。现有大多数DCMVC算法都是针对深度 semantic features的一致信息进行探索，而忽略了不同视图之间的多样信息。为了填补这一漏洞，我们在本文提出了一种新的多视图划分网络，称为 codingNet，以同时探索多视图数据中的多样和一致信息。具体来说，我们不使用传统的自编码器，而是设计了一种非对称结构网络，用于分离不同视图中的 shallow 和 deep features。然后，通过将 shallow 特征相似矩阵与零矩阵进行对齐，我们保证了多视图数据中 shallow 特征的多样性，从而为多视图划分提供更好的描述。此外，我们还提出了一种双对照机制，以保持深度特征在多视图和 pseudo-标签 两级层次上的一致性。我们的框架在六种广泛使用的 benchmark 数据集上进行了广泛的实验，并与大多数现状的多视图划分算法进行比较，证明了我们的框架的效果。
</details></li>
</ul>
<hr>
<h2 id="General-and-Practical-Tuning-Method-for-Off-the-Shelf-Graph-Based-Index-SISAP-Indexing-Challenge-Report-by-Team-UTokyo"><a href="#General-and-Practical-Tuning-Method-for-Off-the-Shelf-Graph-Based-Index-SISAP-Indexing-Challenge-Report-by-Team-UTokyo" class="headerlink" title="General and Practical Tuning Method for Off-the-Shelf Graph-Based Index: SISAP Indexing Challenge Report by Team UTokyo"></a>General and Practical Tuning Method for Off-the-Shelf Graph-Based Index: SISAP Indexing Challenge Report by Team UTokyo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00472">http://arxiv.org/abs/2309.00472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mti-lab/utokyo-sisap23-challenge-submission">https://github.com/mti-lab/utokyo-sisap23-challenge-submission</a></li>
<li>paper_authors: Yutaro Oguri, Yusuke Matsui</li>
<li>for: 本研究旨在优化 graf-based 算法 для Approximate Nearest Neighbor (ANN) 搜索，并提供一种可靠的、 universally 适用的索引调整方法。</li>
<li>methods: 本研究使用了一种黑盒优化算法进行集成调整，以满足需要的召回率和 Queries Per Second (QPS) 要求。</li>
<li>results: 本研究在 SISAP 2023 Indexing Challenge 的 Task A 中获得第二名，在 10M 和 30M  tracks 上显著提高了性能，相比较简单的方法。这种研究方法可以扩展到更广泛的应用场景。<details>
<summary>Abstract</summary>
Despite the efficacy of graph-based algorithms for Approximate Nearest Neighbor (ANN) searches, the optimal tuning of such systems remains unclear. This study introduces a method to tune the performance of off-the-shelf graph-based indexes, focusing on the dimension of vectors, database size, and entry points of graph traversal. We utilize a black-box optimization algorithm to perform integrated tuning to meet the required levels of recall and Queries Per Second (QPS). We applied our approach to Task A of the SISAP 2023 Indexing Challenge and got second place in the 10M and 30M tracks. It improves performance substantially compared to brute force methods. This research offers a universally applicable tuning method for graph-based indexes, extending beyond the specific conditions of the competition to broader uses.
</details>
<details>
<summary>摘要</summary>
尽管图表基本算法在approximate nearest neighbor（ANN）搜索中的效果是明显的，但是最佳化这些系统的调整仍然不清楚。这个研究介绍了一种方法来调整off-the-shelf图表基本索引的性能，专注于维度 Vector，数据库大小，和图表搜索的入口点。我们使用黑盒优化算法进行集成调整，以达到需要的回快和Queries Per Second（QPS）水平。我们在SISAP 2023 Indexing Challenge的任务A中应用了我们的方法，在10M和30M tracks上获得了第二名，与简单方法相比，性能提高了很多。这项研究提供了一种通用的图表索引调整方法，超出了竞赛中的特定条件，拓展到更广泛的应用场景。
</details></li>
</ul>
<hr>
<h2 id="An-Improved-Encoder-Decoder-Framework-for-Food-Energy-Estimation"><a href="#An-Improved-Encoder-Decoder-Framework-for-Food-Energy-Estimation" class="headerlink" title="An Improved Encoder-Decoder Framework for Food Energy Estimation"></a>An Improved Encoder-Decoder Framework for Food Energy Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00468">http://arxiv.org/abs/2309.00468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jack Ma, Jiangpeng He, Fengqing Zhu</li>
<li>for: 这个研究旨在提供一种自动化的食物营养评估方法，以便维护健康生活方式。</li>
<li>methods: 本研究使用改进的encoder-decoder框架估算食物能量，将食物影像转换为具有食物能量信息的更易提取格式，然后将能量信息提取出来。</li>
<li>results: 本研究比前一代营养估算方法提高了10%以上和30千卡拉以上的MAP和MAE分别。<details>
<summary>Abstract</summary>
Dietary assessment is essential to maintaining a healthy lifestyle. Automatic image-based dietary assessment is a growing field of research due to the increasing prevalence of image capturing devices (e.g. mobile phones). In this work, we estimate food energy from a single monocular image, a difficult task due to the limited hard-to-extract amount of energy information present in an image. To do so, we employ an improved encoder-decoder framework for energy estimation; the encoder transforms the image into a representation embedded with food energy information in an easier-to-extract format, which the decoder then extracts the energy information from. To implement our method, we compile a high-quality food image dataset verified by registered dietitians containing eating scene images, food-item segmentation masks, and ground truth calorie values. Our method improves upon previous caloric estimation methods by over 10\% and 30 kCal in terms of MAPE and MAE respectively.
</details>
<details>
<summary>摘要</summary>
饮食评估是保持健康生活的重要组成部分。自动化图像基本饮食评估是研究领域的快速发展，因为图像捕捉设备的使用率在增长（如手机）。在这种工作中，我们将单一的偏振图像中的食物能量估算，这是由于图像中有限的精炼能量信息，使得这种任务非常困难。为此，我们采用了改进的编码器-解码器框架来进行能量估算，编码器将图像转化为含有食物能量信息的更易EXTRACT的表示形式，然后解码器EXTRACT出能量信息。为实现我们的方法，我们编译了高质量的食物图像数据集，该数据集包括餐厅场景图像、食物项分割面积和真实热量值。我们的方法与前期热量估算方法相比，提高了10%以上和30 kCal的MAP和MAE分别。
</details></li>
</ul>
<hr>
<h2 id="dacl10k-Benchmark-for-Semantic-Bridge-Damage-Segmentation"><a href="#dacl10k-Benchmark-for-Semantic-Bridge-Damage-Segmentation" class="headerlink" title="dacl10k: Benchmark for Semantic Bridge Damage Segmentation"></a>dacl10k: Benchmark for Semantic Bridge Damage Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00460">http://arxiv.org/abs/2309.00460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Flotzinger, Philipp J. Rösch, Thomas Braml</li>
<li>for: 本研究旨在提供一个大规模、多种类型的混凝土结构缺陷识别数据集，以便在实际应用中进行bridge检测和评估。</li>
<li>methods: 本研究使用了实际桥梁检测数据集，包括9920张图像，并分为12种缺陷类型和6种桥Component。</li>
<li>results: 研究人员使用基eline模型对dacl10k数据集进行评估，得到了0.42的mean intersection-over-union值。此外，研究人员还将数据集和基eline模型公开访问，以便对bridge检测和评估领域进行进一步研究。<details>
<summary>Abstract</summary>
Reliably identifying reinforced concrete defects (RCDs)plays a crucial role in assessing the structural integrity, traffic safety, and long-term durability of concrete bridges, which represent the most common bridge type worldwide. Nevertheless, available datasets for the recognition of RCDs are small in terms of size and class variety, which questions their usability in real-world scenarios and their role as a benchmark. Our contribution to this problem is "dacl10k", an exceptionally diverse RCD dataset for multi-label semantic segmentation comprising 9,920 images deriving from real-world bridge inspections. dacl10k distinguishes 12 damage classes as well as 6 bridge components that play a key role in the building assessment and recommending actions, such as restoration works, traffic load limitations or bridge closures. In addition, we examine baseline models for dacl10k which are subsequently evaluated. The best model achieves a mean intersection-over-union of 0.42 on the test set. dacl10k, along with our baselines, will be openly accessible to researchers and practitioners, representing the currently biggest dataset regarding number of images and class diversity for semantic segmentation in the bridge inspection domain.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>鉴别强化混凝土缺陷（RCD）可以准确评估混凝土桥的结构完整性、交通安全性和长期持续性，混凝土桥是全球最常见的桥梁类型。然而，目前可用的RCD数据集较小，尺寸和类型多样性受限，这会问题其在实际场景中的可用性和作为标准。我们的贡献是“dacl10k”数据集，包含9,920个真实桥梁检查图像，用于多类Semantic segmentation。dacl10k可以分辨12种缺陷类型和6种桥 component，这些组件对建筑评估和建议行动（如修复工程、交通负荷限制或桥梁关闭）具有关键性。此外，我们还考虑了baseline模型，并评估其性能。测试集上的最佳模型得分为0.42。dacl10k、我们的baselines以及相关的评估结果将公开 accessible for researchers and practitioners，代表bridge检测领域中最大的数据集，包括图像数量和类型多样性。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-bias-discovery-in-medical-image-segmentation"><a href="#Unsupervised-bias-discovery-in-medical-image-segmentation" class="headerlink" title="Unsupervised bias discovery in medical image segmentation"></a>Unsupervised bias discovery in medical image segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00451">http://arxiv.org/abs/2309.00451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolás Gaggion, Rodrigo Echeveste, Lucas Mansilla, Diego H. Milone, Enzo Ferrante</li>
<li>for: 避免深度学习模型在医疗影像分割中存在对某些保护属性（如性别或民族）的偏见。</li>
<li>methods: 我们提出了一种新的无监督偏见探测方法，利用反分类精度框架来估算分割质量。</li>
<li>results: 我们通过synthetic和实际场景的数字实验表示，我们的方法能够成功预测深度分割模型的公平问题，这成为该领域的新和有价值的工具。<details>
<summary>Abstract</summary>
It has recently been shown that deep learning models for anatomical segmentation in medical images can exhibit biases against certain sub-populations defined in terms of protected attributes like sex or ethnicity. In this context, auditing fairness of deep segmentation models becomes crucial. However, such audit process generally requires access to ground-truth segmentation masks for the target population, which may not always be available, especially when going from development to deployment. Here we propose a new method to anticipate model biases in biomedical image segmentation in the absence of ground-truth annotations. Our unsupervised bias discovery method leverages the reverse classification accuracy framework to estimate segmentation quality. Through numerical experiments in synthetic and realistic scenarios we show how our method is able to successfully anticipate fairness issues in the absence of ground-truth labels, constituting a novel and valuable tool in this field.
</details>
<details>
<summary>摘要</summary>
Recently, research has shown that deep learning models for anatomical segmentation in medical images can exhibit biases against certain sub-populations defined by protected attributes such as sex or ethnicity. In this context, it is crucial to audit the fairness of deep segmentation models. However, this process typically requires access to ground-truth segmentation masks for the target population, which may not always be available, especially when moving from development to deployment. Here, we propose a new method to anticipate model biases in biomedical image segmentation in the absence of ground-truth annotations. Our unsupervised bias discovery method utilizes the reverse classification accuracy framework to estimate segmentation quality. Through numerical experiments in synthetic and realistic scenarios, we demonstrate how our method can successfully anticipate fairness issues in the absence of ground-truth labels, providing a novel and valuable tool in this field.Here's the translation in Traditional Chinese as well:Recently, research has shown that deep learning models for anatomical segmentation in medical images can exhibit biases against certain sub-populations defined by protected attributes such as sex or ethnicity. In this context, it is crucial to audit the fairness of deep segmentation models. However, this process typically requires access to ground-truth segmentation masks for the target population, which may not always be available, especially when moving from development to deployment. Here, we propose a new method to anticipate model biases in biomedical image segmentation in the absence of ground-truth annotations. Our unsupervised bias discovery method utilizes the reverse classification accuracy framework to estimate segmentation quality. Through numerical experiments in synthetic and realistic scenarios, we demonstrate how our method can successfully anticipate fairness issues in the absence of ground-truth labels, providing a novel and valuable tool in this field.
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Video-Moment-Retrieval-from-Frozen-Vision-Language-Models"><a href="#Zero-Shot-Video-Moment-Retrieval-from-Frozen-Vision-Language-Models" class="headerlink" title="Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models"></a>Zero-Shot Video Moment Retrieval from Frozen Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00661">http://arxiv.org/abs/2309.00661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dezhao Luo, Jiabo Huang, Shaogang Gong, Hailin Jin, Yang Liu</li>
<li>for: 提高视频瞬间 Retrieval（VMR）的精度，使其能够处理未知词汇和未经见过的场景。</li>
<li>methods: 利用视觉语言模型（VLM）的新的转移学习方法，通过大规模的视觉语言对数据来 derive universal visual-textual correlations，并通过 fine-tuning 来适应目标领域。</li>
<li>results: 提出了一种零基础方法，可以将通用的视觉文本关系转移到 VMR 领域，而不需要访问 VMR 数据。该方法包括一个 conditional feature refinement module 和一个底层提档生成策略，可以更好地理解瞬间边界，并最大化 VLM 的效果。实验结果表明，我们的零基础算法在三个 VMR 标准测试集上具有显著的性能优势，特别是在未知词汇和未经见过的场景下。<details>
<summary>Abstract</summary>
Accurate video moment retrieval (VMR) requires universal visual-textual correlations that can handle unknown vocabulary and unseen scenes. However, the learned correlations are likely either biased when derived from a limited amount of moment-text data which is hard to scale up because of the prohibitive annotation cost (fully-supervised), or unreliable when only the video-text pairwise relationships are available without fine-grained temporal annotations (weakly-supervised). Recently, the vision-language models (VLM) demonstrate a new transfer learning paradigm to benefit different vision tasks through the universal visual-textual correlations derived from large-scale vision-language pairwise web data, which has also shown benefits to VMR by fine-tuning in the target domains. In this work, we propose a zero-shot method for adapting generalisable visual-textual priors from arbitrary VLM to facilitate moment-text alignment, without the need for accessing the VMR data. To this end, we devise a conditional feature refinement module to generate boundary-aware visual features conditioned on text queries to enable better moment boundary understanding. Additionally, we design a bottom-up proposal generation strategy that mitigates the impact of domain discrepancies and breaks down complex-query retrieval tasks into individual action retrievals, thereby maximizing the benefits of VLM. Extensive experiments conducted on three VMR benchmark datasets demonstrate the notable performance advantages of our zero-shot algorithm, especially in the novel-word and novel-location out-of-distribution setups.
</details>
<details>
<summary>摘要</summary>
准确的视频时刻选取（VMR）需要一种通用的视觉文本相关性，可以处理未知词汇和未经见过的场景。然而，学习的相关性可能受到有限的时刻文本数据的偏袋影响（完全监督），或者只有视频和文本之间的对应关系（弱监督），无法提供精细的时刻标注。近些年，视觉语言模型（VLM）表明了一种新的转移学习 paradigma，通过大规模的视觉语言对数据来获得通用的视觉文本相关性，并在目标领域进行 fine-tuning，以便为不同的视觉任务提供利用。在这种情况下，我们提出了一种零shot方法，通过不需要访问VMR数据来适应通用的视觉文本相关性。为此，我们设计了一个条件feature重定向模块，通过文本查询来生成与边界相关的视觉特征，以便更好地理解时刻边界。此外，我们还设计了一种底层提议生成策略，以降低域外差异的影响和将复杂的查询任务分解成个体动作 retrieve 任务，从而最大化VLM的利用。经过对三个VMR benchmark数据集的广泛实验，我们发现了我们零shot算法在未知词汇和未经见过的设置中表现出了remarkable的性能优势。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-matching-of-deformable-objects-by-learning-to-detect-keypoints"><a href="#Improving-the-matching-of-deformable-objects-by-learning-to-detect-keypoints" class="headerlink" title="Improving the matching of deformable objects by learning to detect keypoints"></a>Improving the matching of deformable objects by learning to detect keypoints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00434">http://arxiv.org/abs/2309.00434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/verlab/learningtodetect_prl_2023">https://github.com/verlab/learningtodetect_prl_2023</a></li>
<li>paper_authors: Felipe Cadar, Welerson Melo, Vaishnavi Kanagasabapathi, Guilherme Potje, Renato Martins, Erickson R. Nascimento</li>
<li>for: 提高非RIGID图像匹配任务中正确匹配的数量</li>
<li>methods: 使用练习annotated图像对照 pairs的真相匹配来训练一个端到端的卷积神经网络，从而找到更适合考虑的描述符的关键点位置</li>
<li>results: 对多种描述符的匹配精度提高20pp，并在真实世界中的对象检索任务中与最佳关键点检测器一样高效<details>
<summary>Abstract</summary>
We propose a novel learned keypoint detection method to increase the number of correct matches for the task of non-rigid image correspondence. By leveraging true correspondences acquired by matching annotated image pairs with a specified descriptor extractor, we train an end-to-end convolutional neural network (CNN) to find keypoint locations that are more appropriate to the considered descriptor. For that, we apply geometric and photometric warpings to images to generate a supervisory signal, allowing the optimization of the detector. Experiments demonstrate that our method enhances the Mean Matching Accuracy of numerous descriptors when used in conjunction with our detection method, while outperforming the state-of-the-art keypoint detectors on real images of non-rigid objects by 20 p.p. We also apply our method on the complex real-world task of object retrieval where our detector performs on par with the finest keypoint detectors currently available for this task. The source code and trained models are publicly available at https://github.com/verlab/LearningToDetect_PRL_2023
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的学习基于关键点检测方法，以提高非RIGID图像匹配任务中correct匹配的数量。通过利用已知图像对照对描述符EXTRACTOR进行匹配，我们训练了一个端到端的卷积神经网络（CNN）来找出更适合考虑的描述符的关键点位置。为了实现这一目标，我们应用了地理метриic和光学扭曲到图像，以生成一个监督信号，allowing the optimization of the detector。实验表明，我们的方法可以提高许多描述符的mean Matching Accuracy，并在真实图像中对非RIGID对象的检测任务上超越当前最佳的关键点检测器。我们还应用了我们的方法在复杂的real-world对象检索任务中，并与当前最佳的关键点检测器一样表现。source code和训练模型可以在https://github.com/verlab/LearningToDetect_PRL_2023中下载。
</details></li>
</ul>
<hr>
<h2 id="Selective-Scene-Text-Removal"><a href="#Selective-Scene-Text-Removal" class="headerlink" title="Selective Scene Text Removal"></a>Selective Scene Text Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00410">http://arxiv.org/abs/2309.00410</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mitanihayato/Selective-Scene-Text-Removal">https://github.com/mitanihayato/Selective-Scene-Text-Removal</a></li>
<li>paper_authors: Hayato Mitani, Akisato Kimura, Seiichi Uchida</li>
<li>for:  selective scene text removal (SSTR)</li>
<li>methods:  multi-module structure</li>
<li>results:  can remove target words as expected<details>
<summary>Abstract</summary>
Scene text removal (STR) is the image transformation task to remove text regions in scene images. The conventional STR methods remove all scene text. This means that the existing methods cannot select text to be removed. In this paper, we propose a novel task setting named selective scene text removal (SSTR) that removes only target words specified by the user. Although SSTR is a more complex task than STR, the proposed multi-module structure enables efficient training for SSTR. Experimental results show that the proposed method can remove target words as expected.
</details>
<details>
<summary>摘要</summary>
Scene文本除除（STR）是图像变换任务，去除场景中的文本区域。传统的STR方法都是全面去除场景中的所有文本。在这篇论文中，我们提出了一种新的任务设定方式，即选择场景文本除除（SSTR），可以根据用户指定的Target字符串来去除特定的文本。虽然SSTR是STR的更加复杂的任务，但我们提出的多模块结构使得SSTR的训练变得高效。实验结果表明，我们的方法可以如预期地去除Target字符串。
</details></li>
</ul>
<hr>
<h2 id="Fine-grained-Recognition-with-Learnable-Semantic-Data-Augmentation"><a href="#Fine-grained-Recognition-with-Learnable-Semantic-Data-Augmentation" class="headerlink" title="Fine-grained Recognition with Learnable Semantic Data Augmentation"></a>Fine-grained Recognition with Learnable Semantic Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00399">http://arxiv.org/abs/2309.00399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Pu, Yizeng Han, Yulin Wang, Junlan Feng, Chao Deng, Gao Huang</li>
<li>for: 本研究旨在提高细化图像识别精度，通过在特征层进行多样化数据训练，以增强分类器的泛化性。</li>
<li>methods: 本研究提出了一种基于semantic特征方向的多样化数据生成方法，通过预测样本独特的协方差矩阵来生成多个不同的扩展样本，并与分类器进行共同优化。</li>
<li>results: 实验表明，该方法可以在多个竞争性的细化图像识别benchmark上提高分类器的泛化性，并在CUB-200-2011 dataset上与最新的方法相当。<details>
<summary>Abstract</summary>
Fine-grained image recognition is a longstanding computer vision challenge that focuses on differentiating objects belonging to multiple subordinate categories within the same meta-category. Since images belonging to the same meta-category usually share similar visual appearances, mining discriminative visual cues is the key to distinguishing fine-grained categories. Although commonly used image-level data augmentation techniques have achieved great success in generic image classification problems, they are rarely applied in fine-grained scenarios, because their random editing-region behavior is prone to destroy the discriminative visual cues residing in the subtle regions. In this paper, we propose diversifying the training data at the feature-level to alleviate the discriminative region loss problem. Specifically, we produce diversified augmented samples by translating image features along semantically meaningful directions. The semantic directions are estimated with a covariance prediction network, which predicts a sample-wise covariance matrix to adapt to the large intra-class variation inherent in fine-grained images. Furthermore, the covariance prediction network is jointly optimized with the classification network in a meta-learning manner to alleviate the degenerate solution problem. Experiments on four competitive fine-grained recognition benchmarks (CUB-200-2011, Stanford Cars, FGVC Aircrafts, NABirds) demonstrate that our method significantly improves the generalization performance on several popular classification networks (e.g., ResNets, DenseNets, EfficientNets, RegNets and ViT). Combined with a recently proposed method, our semantic data augmentation approach achieves state-of-the-art performance on the CUB-200-2011 dataset. The source code will be released.
</details>
<details>
<summary>摘要</summary>
传统的图像识别挑战之一是细化图像识别，即在同一个meta-类别下分别识别多个子类别。由于图像在同一个meta-类别下通常具有相似的视觉特征，因此挖掘特征特征是识别细化类别的关键。虽然通常使用的图像级别数据增强技术已经取得了广泛的成功在通用图像分类问题上，但它们在细化场景下rarely被应用，因为它们的随机编辑区域行为容易 Destroying the discriminative visual cues residing in subtle regions.在这篇论文中，我们提出了在特征级别上多样化训练数据以解决细化类别损失问题。具体来说，我们生成了多样化增强样本 by translating image features along semantically meaningful directions. 预测样本级别的covariance matrix的网络来Estimate the semantic directions, which adapts to the large intra-class variation inherent in fine-grained images. 此外，预测网络和分类网络在meta-学习方式下jointly optimize the covariance prediction network to alleviate the degenerate solution problem.实验表明，我们的方法可以在四个竞争力高的细化图像识别benchmark上（CUB-200-2011, Stanford Cars, FGVC Aircrafts, NABirds）提高通用分类网络（例如ResNets, DenseNets, EfficientNets, RegNets和ViT）的总体性能。与 reciently proposed method 的semantic data augmentation approach combine， our approach achieves state-of-the-art performance on the CUB-200-2011 dataset. 代码将会发布。
</details></li>
</ul>
<hr>
<h2 id="VideoGen-A-Reference-Guided-Latent-Diffusion-Approach-for-High-Definition-Text-to-Video-Generation"><a href="#VideoGen-A-Reference-Guided-Latent-Diffusion-Approach-for-High-Definition-Text-to-Video-Generation" class="headerlink" title="VideoGen: A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation"></a>VideoGen: A Reference-Guided Latent Diffusion Approach for High Definition Text-to-Video Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00398">http://arxiv.org/abs/2309.00398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Li, Wenqing Chu, Ye Wu, Weihang Yuan, Fanglong Liu, Qi Zhang, Fu Li, Haocheng Feng, Errui Ding, Jingdong Wang</li>
<li>for: 这个研究旨在提出一种基于参考导向潜在扩散的文本到视频生成方法，可以生成高分辨率、高帧准确率的视频。</li>
<li>methods: 该方法首先使用现成的文本到图像生成模型（如稳定扩散）生成一个高质量的图像作为参考图像，然后引入一个高效的级联潜在扩散模块，通过参考图像和文本提示来生成潜在视频表示。最后，通过一个改进的流式增强步骤来提高视频的时间分辨率。</li>
<li>results: 该方法在文本到视频生成方面设置了新的州OF-THE-ART， both qualitative and quantitative evaluation 表明，VideoGen可以生成高质量、高分辨率的视频。更多样例可以参考 \url{<a target="_blank" rel="noopener" href="https://videogen.github.io/VideoGen/%7D%E3%80%82">https://videogen.github.io/VideoGen/}。</a><details>
<summary>Abstract</summary>
In this paper, we present VideoGen, a text-to-video generation approach, which can generate a high-definition video with high frame fidelity and strong temporal consistency using reference-guided latent diffusion. We leverage an off-the-shelf text-to-image generation model, e.g., Stable Diffusion, to generate an image with high content quality from the text prompt, as a reference image to guide video generation. Then, we introduce an efficient cascaded latent diffusion module conditioned on both the reference image and the text prompt, for generating latent video representations, followed by a flow-based temporal upsampling step to improve the temporal resolution. Finally, we map latent video representations into a high-definition video through an enhanced video decoder. During training, we use the first frame of a ground-truth video as the reference image for training the cascaded latent diffusion module. The main characterises of our approach include: the reference image generated by the text-to-image model improves the visual fidelity; using it as the condition makes the diffusion model focus more on learning the video dynamics; and the video decoder is trained over unlabeled video data, thus benefiting from high-quality easily-available videos. VideoGen sets a new state-of-the-art in text-to-video generation in terms of both qualitative and quantitative evaluation. See \url{https://videogen.github.io/VideoGen/} for more samples.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了 VideoGen，一种文本到视频生成方法，可以生成高清晰度视频，具有高帧准确性和强时间一致性使用参考导向的潜在扩散。我们利用了一个标准的文本到图像生成模型，例如稳定扩散，来生成基于文本提示的图像，并用其为参考图像来导引视频生成。然后，我们引入了一个高效的级联潜在扩散模块，Conditional on both the reference image and the text prompt, for generating latent video representations, followed by a flow-based temporal upsampling step to improve the temporal resolution.最后，我们将潜在视频表示映射到高清晰度视频 через一个加强的视频解码器。在训练时，我们使用了ground truth video的首帧作为参考图像来训练级联潜在扩散模块。主要特点包括：参考图像生成于文本到图像模型提高了视觉质量;使用参考图像作为条件使得扩散模型更专注学习视频动力学;以及视频解码器在训练过程中使用了高质量的无标注视频数据，从而受益于高质量的可获得视频数据。VideoGen将文本到视频生成领域的新州标准，以质量和量化评价为据。更多样例可以参考\url{https://videogen.github.io/VideoGen/}。
</details></li>
</ul>
<hr>
<h2 id="On-the-Localization-of-Ultrasound-Image-Slices-within-Point-Distribution-Models"><a href="#On-the-Localization-of-Ultrasound-Image-Slices-within-Point-Distribution-Models" class="headerlink" title="On the Localization of Ultrasound Image Slices within Point Distribution Models"></a>On the Localization of Ultrasound Image Slices within Point Distribution Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00372">http://arxiv.org/abs/2309.00372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lennart Bastian, Vincent Bürgin, Ha Young Kim, Alexander Baumann, Benjamin Busam, Mahdi Saleh, Nassir Navab</li>
<li>for: 这个论文主要目标是提供一种自动化ultrasound图像块位置定位方法，以便更好地诊断甲状腺疾病。</li>
<li>methods: 该方法使用对ultrasound图像和三维形态模型的对比学习，学习一个共同准则空间，然后使用cross-modality注册和Procrustes分析将ultrasound块注册到三维形态模型中。</li>
<li>results: 实验结果表明，该多模态注册框架可以准确地将ultrasound块注册到患者特定的三维形态模型和统计 shapes模型中，并且可以预测块位置在患者特定的三维形态模型上的平均误差为1.2毫米，并且在统计 shapes模型上的平均误差为4.6毫米。<details>
<summary>Abstract</summary>
Thyroid disorders are most commonly diagnosed using high-resolution Ultrasound (US). Longitudinal nodule tracking is a pivotal diagnostic protocol for monitoring changes in pathological thyroid morphology. This task, however, imposes a substantial cognitive load on clinicians due to the inherent challenge of maintaining a mental 3D reconstruction of the organ. We thus present a framework for automated US image slice localization within a 3D shape representation to ease how such sonographic diagnoses are carried out. Our proposed method learns a common latent embedding space between US image patches and the 3D surface of an individual's thyroid shape, or a statistical aggregation in the form of a statistical shape model (SSM), via contrastive metric learning. Using cross-modality registration and Procrustes analysis, we leverage features from our model to register US slices to a 3D mesh representation of the thyroid shape. We demonstrate that our multi-modal registration framework can localize images on the 3D surface topology of a patient-specific organ and the mean shape of an SSM. Experimental results indicate slice positions can be predicted within an average of 1.2 mm of the ground-truth slice location on the patient-specific 3D anatomy and 4.6 mm on the SSM, exemplifying its usefulness for slice localization during sonographic acquisitions. Code is publically available: \href{https://github.com/vuenc/slice-to-shape}{https://github.com/vuenc/slice-to-shape}
</details>
<details>
<summary>摘要</summary>
淀脑疾病通常通过高分辨率超声成像（US）诊断。 longitudinal nodule tracking是诊断过程中的关键协议，但这会对临床医生带来很大的认知负担，因为需要维护一个 mental 3D 重建的器官。我们因此提出了一种自动化 US 图像片断localization在3D形状表示中的框架，以facilitate如此的超声诊断。我们的提议方法learns一个共同latent embedding空间 между US图像块和个体的thyroid形状3D，或者一个统计汇总模型（SSM），通过对比度学习。通过cross-modality registration和Procrustes分析，我们利用我们的模型特征来注册US剖平图像到个体特定的thyroid形状3D的表示中。我们的多Modal注册框架可以在病人特定的3D анатомия上和统计平均形态模型（SSM）上localize图像剖平。实验结果表明，我们可以在病人特定3D形状上和统计平均形态模型（SSM）上预测图像剖平的位置，与实际 slice位置相差在1.2毫米和4.6毫米之间。这 demonstartes我们的多Modal注册框架的用于图像剖平localization durante acquisitions sonográficas。代码可以在以下链接获取：https://github.com/vuenc/slice-to-shape
</details></li>
</ul>
<hr>
<h2 id="How-You-Split-Matters-Data-Leakage-and-Subject-Characteristics-Studies-in-Longitudinal-Brain-MRI-Analysis"><a href="#How-You-Split-Matters-Data-Leakage-and-Subject-Characteristics-Studies-in-Longitudinal-Brain-MRI-Analysis" class="headerlink" title="How You Split Matters: Data Leakage and Subject Characteristics Studies in Longitudinal Brain MRI Analysis"></a>How You Split Matters: Data Leakage and Subject Characteristics Studies in Longitudinal Brain MRI Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00350">http://arxiv.org/abs/2309.00350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dewinda Julianensi Rumala</li>
<li>for: 这研究探讨了医疗图像分析领域中深度学习模型的应用，以及这些模型在诊断和患者照管中的潜在问题。</li>
<li>methods: 研究使用了3D卷积神经网络（CNN）对大脑MRI图像进行分析，并 investigate了不同数据分割策略对模型性能的影响。</li>
<li>results: 研究发现，不当的数据分割策略可能会导致模型性能受到影响，特别是在长期图像数据中，包括重复的扫描数据。研究还发现，GradCAM视觉化可以揭示卷积神经网络模型中的快捷缺陷，这些缺陷可能会使模型学习到诊断特征以及患者身份。<details>
<summary>Abstract</summary>
Deep learning models have revolutionized the field of medical image analysis, offering significant promise for improved diagnostics and patient care. However, their performance can be misleadingly optimistic due to a hidden pitfall called 'data leakage'. In this study, we investigate data leakage in 3D medical imaging, specifically using 3D Convolutional Neural Networks (CNNs) for brain MRI analysis. While 3D CNNs appear less prone to leakage than 2D counterparts, improper data splitting during cross-validation (CV) can still pose issues, especially with longitudinal imaging data containing repeated scans from the same subject. We explore the impact of different data splitting strategies on model performance for longitudinal brain MRI analysis and identify potential data leakage concerns. GradCAM visualization helps reveal shortcuts in CNN models caused by identity confounding, where the model learns to identify subjects along with diagnostic features. Our findings, consistent with prior research, underscore the importance of subject-wise splitting and evaluating our model further on hold-out data from different subjects to ensure the integrity and reliability of deep learning models in medical image analysis.
</details>
<details>
<summary>摘要</summary>
深度学习模型在医疗图像分析领域已经引起了广泛的关注，因为它们提供了改善诊断和患者护理的可能性。然而，它们的性能可能会受到一种隐藏的陷阱，称为“数据泄露”。在这项研究中，我们研究了3D医疗图像中的数据泄露， especailly使用3D卷积神经网络（CNN）进行脑MRI分析。虽然3D CNN在2D counterpart中看起来更加免疫于泄露，但是在cross-validation（CV）时不当的数据分割可以仍然存在问题，尤其是在包含同一个主题的重复扫描数据中。我们研究了不同的数据分割策略对于长itudinal脑MRI分析的模型性能的影响，并发现了可能的数据泄露问题。GradCAM可视化 помо助于揭示了 CNN模型中由identify confounding引起的快捷路径，其中模型学习了主题以及诊断特征。我们的发现与之前的研究一致，强调了在医疗图像分析中深度学习模型的完整性和可靠性的重要性，需要在不同主题的数据上进行评估。
</details></li>
</ul>
<hr>
<h2 id="RigNet-Efficient-Repetitive-Image-Guided-Network-for-Depth-Completion"><a href="#RigNet-Efficient-Repetitive-Image-Guided-Network-for-Depth-Completion" class="headerlink" title="RigNet++: Efficient Repetitive Image Guided Network for Depth Completion"></a>RigNet++: Efficient Repetitive Image Guided Network for Depth Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00655">http://arxiv.org/abs/2309.00655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Yan, Xiang Li, Zhenyu Zhang, Jun Li, Jian Yang</li>
<li>for: 本研究旨在提高深度映射的精度，使用频繁重复的设计来提高图像引导学习框架的性能。</li>
<li>methods: 我们在图像引导学习框架中实现了高效的重复设计，包括图像引导分支和深度生成分支。图像引导分支中，我们设计了一个密集重复小时glass网络，以提取复杂环境中的特征特征，为深度预测提供强大的Contextual指导。深度生成分支中，我们引入了一种循环动态梯度Module，其中提出了一种高效的幂等分解方法，以减少复杂性而模型高频结构。</li>
<li>results: 我们在KITTI、VKITTI、NYUv2、3D60和Matterport3D等 datasets上进行了广泛的实验，结果表明，我们的方法可以取得Superior或竞争性的结果。<details>
<summary>Abstract</summary>
Depth completion aims to recover dense depth maps from sparse ones, where color images are often used to facilitate this task. Recent depth methods primarily focus on image guided learning frameworks. However, blurry guidance in the image and unclear structure in the depth still impede their performance. To tackle these challenges, we explore an efficient repetitive design in our image guided network to gradually and sufficiently recover depth values. Specifically, the efficient repetition is embodied in both the image guidance branch and depth generation branch. In the former branch, we design a dense repetitive hourglass network to extract discriminative image features of complex environments, which can provide powerful contextual instruction for depth prediction. In the latter branch, we introduce a repetitive guidance module based on dynamic convolution, in which an efficient convolution factorization is proposed to reduce the complexity while modeling high-frequency structures progressively. Extensive experiments indicate that our approach achieves superior or competitive results on KITTI, VKITTI, NYUv2, 3D60, and Matterport3D datasets.
</details>
<details>
<summary>摘要</summary>
depth completion 目标是从稀畴的深度地图中恢复粗粒度的深度地图，通常使用颜色图像来促进这个任务。  current depth method 主要关注于图像导学框架。然而，图像指导中的模糊和深度中的 unclear structure 仍然妨碍其性能。为了解决这些挑战，我们探索了一种高效的循环设计在我们的图像导学网络中。 Specifically, the efficient repetition is embodied in both the image guidance branch and depth generation branch。在前者分支中，我们设计了一个紧凑的重复弧形网络来提取复杂环境中的特征特征，这可以为深度预测提供强大的Contextual instruction。在后者分支中，我们引入了一种循环导引模块，基于动态 convolution，在其中我们提出了一种高效的 convolution factorization来降低复杂性，同时模型高频结构进行进行逐步进行进行。  extensive experiments indicate that our approach achieves superior or competitive results on KITTI, VKITTI, NYUv2, 3D60, and Matterport3D datasets。
</details></li>
</ul>
<hr>
<h2 id="MuraNet-Multi-task-Floor-Plan-Recognition-with-Relation-Attention"><a href="#MuraNet-Multi-task-Floor-Plan-Recognition-with-Relation-Attention" class="headerlink" title="MuraNet: Multi-task Floor Plan Recognition with Relation Attention"></a>MuraNet: Multi-task Floor Plan Recognition with Relation Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00348">http://arxiv.org/abs/2309.00348</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingxiao Huang, Jung-Hsuan Wu, Chiching Wei, Wilson Li</li>
<li>For:  floor plan data recognition* Methods:  attention-based multi-task model (MuraNet) with unified encoder (MURA) and separated branches for segmentation and detection tasks* Results:  improved convergence speed and performance in detection and segmentation tasks compared to single-task models like U-Net and YOLOv3<details>
<summary>Abstract</summary>
The recognition of information in floor plan data requires the use of detection and segmentation models. However, relying on several single-task models can result in ineffective utilization of relevant information when there are multiple tasks present simultaneously. To address this challenge, we introduce MuraNet, an attention-based multi-task model for segmentation and detection tasks in floor plan data. In MuraNet, we adopt a unified encoder called MURA as the backbone with two separated branches: an enhanced segmentation decoder branch and a decoupled detection head branch based on YOLOX, for segmentation and detection tasks respectively. The architecture of MuraNet is designed to leverage the fact that walls, doors, and windows usually constitute the primary structure of a floor plan's architecture. By jointly training the model on both detection and segmentation tasks, we believe MuraNet can effectively extract and utilize relevant features for both tasks. Our experiments on the CubiCasa5k public dataset show that MuraNet improves convergence speed during training compared to single-task models like U-Net and YOLOv3. Moreover, we observe improvements in the average AP and IoU in detection and segmentation tasks, respectively.Our ablation experiments demonstrate that the attention-based unified backbone of MuraNet achieves better feature extraction in floor plan recognition tasks, and the use of decoupled multi-head branches for different tasks further improves model performance. We believe that our proposed MuraNet model can address the disadvantages of single-task models and improve the accuracy and efficiency of floor plan data recognition.
</details>
<details>
<summary>摘要</summary>
<<SYS>>loor plan数据认知需要使用探测和分割模型。然而，依赖于多个单任务模型可能会导致 relevante信息的不fficient使用， especialmente when there are multiple tasks present simultaneously. To address this challenge, we introduce MuraNet, an attention-based multi-task model for segmentation and detection tasks in floor plan data. In MuraNet, we adopt a unified encoder called MURA as the backbone with two separated branches: an enhanced segmentation decoder branch and a decoupled detection head branch based on YOLOX, for segmentation and detection tasks respectively. The architecture of MuraNet is designed to leverage the fact that walls, doors, and windows usually constitute the primary structure of a floor plan's architecture. By jointly training the model on both detection and segmentation tasks, we believe MuraNet can effectively extract and utilize relevant features for both tasks. Our experiments on the CubiCasa5k public dataset show that MuraNet improves convergence speed during training compared to single-task models like U-Net and YOLOv3. Moreover, we observe improvements in the average AP and IoU in detection and segmentation tasks, respectively. Our ablation experiments demonstrate that the attention-based unified backbone of MuraNet achieves better feature extraction in floor plan recognition tasks, and the use of decoupled multi-head branches for different tasks further improves model performance. We believe that our proposed MuraNet model can address the disadvantages of single-task models and improve the accuracy and efficiency of floor plan data recognition.中文简体版：loor plan数据认知需要使用探测和分割模型。然而，依赖于多个单任务模型可能会导致 relevante信息的不fficient使用， especialmente when there are multiple tasks present simultaneously. To address this challenge, we introduce MuraNet, an attention-based multi-task model for segmentation and detection tasks in floor plan data. In MuraNet, we adopt a unified encoder called MURA as the backbone with two separated branches: an enhanced segmentation decoder branch and a decoupled detection head branch based on YOLOX, for segmentation and detection tasks respectively. The architecture of MuraNet is designed to leverage the fact that walls, doors, and windows usually constitute the primary structure of a floor plan's architecture. By jointly training the model on both detection and segmentation tasks, we believe MuraNet can effectively extract and utilize relevant features for both tasks. Our experiments on the CubiCasa5k public dataset show that MuraNet improves convergence speed during training compared to single-task models like U-Net and YOLOv3. Moreover, we observe improvements in the average AP and IoU in detection and segmentation tasks, respectively. Our ablation experiments demonstrate that the attention-based unified backbone of MuraNet achieves better feature extraction in floor plan recognition tasks, and the use of decoupled multi-head branches for different tasks further improves model performance. We believe that our proposed MuraNet model can address the disadvantages of single-task models and improve the accuracy and efficiency of floor plan data recognition.
</details></li>
</ul>
<hr>
<h2 id="Towards-Contrastive-Learning-in-Music-Video-Domain"><a href="#Towards-Contrastive-Learning-in-Music-Video-Domain" class="headerlink" title="Towards Contrastive Learning in Music Video Domain"></a>Towards Contrastive Learning in Music Video Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00347">http://arxiv.org/abs/2309.00347</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karel Veldkamp, Mariya Hendriksen, Zoltán Szlávik, Alexander Keijser</li>
<li>for: 这个论文 investigate whether contrastive learning can be applied to the domain of music videos, and evaluate the effectiveness of this approach on downstream tasks such as music tagging and genre classification.</li>
<li>methods: 作者使用了 dual en-coder 来学习 audio 和 video 模式的 multimodal 表示，并使用了 bidirectional contrastive loss 进行训练。</li>
<li>results: 结果表明，没有对 contrastive learning 进行 fine-tuning 的预训练网络在两个下游任务中表现更好，而且作者通过Qualitative analysis of the learned representations来解释了为什么 contrastive learning 对 music videos 不成功。<details>
<summary>Abstract</summary>
Contrastive learning is a powerful way of learning multimodal representations across various domains such as image-caption retrieval and audio-visual representation learning. In this work, we investigate if these findings generalize to the domain of music videos. Specifically, we create a dual en-coder for the audio and video modalities and train it using a bidirectional contrastive loss. For the experiments, we use an industry dataset containing 550 000 music videos as well as the public Million Song Dataset, and evaluate the quality of learned representations on the downstream tasks of music tagging and genre classification. Our results indicate that pre-trained networks without contrastive fine-tuning outperform our contrastive learning approach when evaluated on both tasks. To gain a better understanding of the reasons contrastive learning was not successful for music videos, we perform a qualitative analysis of the learned representations, revealing why contrastive learning might have difficulties uniting embeddings from two modalities. Based on these findings, we outline possible directions for future work. To facilitate the reproducibility of our results, we share our code and the pre-trained model.
</details>
<details>
<summary>摘要</summary>
“对比学习是一种强大的学习多Modal表现的方法，可以应用于不同领域，如图像描述和视觉表现学习。在这个工作中，我们 investigate 这些结果是否应用于音乐录影带领域。 Specifically, we create a dual en-coder for the audio and video modalities and train it using a bidirectional contrastive loss. 实验中，我们使用了550000首音乐录影带的industry dataset以及公共的Million Song Dataset，并评估学习的表现质量downstream task of music tagging和类别分类。我们的结果显示了pre-trained network without contrastive fine-tuning outperform our contrastive learning approach when evaluated on both tasks。为了更好地理解contrastive learning why it was not successful for music videos, we perform a qualitative analysis of the learned representations, revealing why contrastive learning might have difficulties uniting embeddings from two modalities。 Based on these findings, we outline possible directions for future work。为了促进我们的结果的重现性，我们分享了我们的代码和预训模型。”
</details></li>
</ul>
<hr>
<h2 id="Robust-Point-Cloud-Processing-through-Positional-Embedding"><a href="#Robust-Point-Cloud-Processing-through-Positional-Embedding" class="headerlink" title="Robust Point Cloud Processing through Positional Embedding"></a>Robust Point Cloud Processing through Positional Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00339">http://arxiv.org/abs/2309.00339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osiriszjq/RobustPPE">https://github.com/osiriszjq/RobustPPE</a></li>
<li>paper_authors: Jianqiao Zheng, Xueqian Li, Sameera Ramasinghe, Simon Lucey</li>
<li>for: 这个论文是关于3D点云处理中使用分析式每个点嵌入的研究，以提高对异常点云和噪声的Robustness。</li>
<li>methods: 这篇论文使用了基于带宽的分析式每个点嵌入，并与Random Fourier Features（RFF）的坐标嵌入进行比较。</li>
<li>results: 论文通过在多种异常点云和噪声下进行多个下渠道任务的实验，表明该方法可以提供更高的Robustness和稳定性。<details>
<summary>Abstract</summary>
End-to-end trained per-point embeddings are an essential ingredient of any state-of-the-art 3D point cloud processing such as detection or alignment. Methods like PointNet, or the more recent point cloud transformer -- and its variants -- all employ learned per-point embeddings. Despite impressive performance, such approaches are sensitive to out-of-distribution (OOD) noise and outliers. In this paper, we explore the role of an analytical per-point embedding based on the criterion of bandwidth. The concept of bandwidth enables us to draw connections with an alternate per-point embedding -- positional embedding, particularly random Fourier features. We present compelling robust results across downstream tasks such as point cloud classification and registration with several categories of OOD noise.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNEnd-to-end 培чение的每个点嵌入是现代三维点云处理的重要组成部分，如探测或对Alignment。方法如PointNet或更近的点云变换器以及其变种都使用学习的每个点嵌入。尽管表现出色，但这些方法对于异常情况（OOD）噪声和异常值敏感。在这篇论文中，我们探讨使用分布参数来确定每个点嵌入的概念。这种概念允许我们与另一种嵌入——位置嵌入，特别是随机傅立叶特征进行联系。我们在多个下游任务中，如点云分类和注册，对多种OOD噪声进行了吸引人的Robust表现。
</details></li>
</ul>
<hr>
<h2 id="Human-trajectory-prediction-using-LSTM-with-Attention-mechanism"><a href="#Human-trajectory-prediction-using-LSTM-with-Attention-mechanism" class="headerlink" title="Human trajectory prediction using LSTM with Attention mechanism"></a>Human trajectory prediction using LSTM with Attention mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00331">http://arxiv.org/abs/2309.00331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Manafi Soltan Ahmadi, Samaneh Hoseini Semnani</li>
<li>for: 本研究提出了一种人行踪预测模型，该模型结合了长期快速响应神经网络（LSTM）和注意机制。</li>
<li>methods: 该模型使用注意分数来确定输入数据中对预测输出的重要性，注意分数由输入特征的每个部分计算得到，高分数表明该部分在预测输出中的更大重要性。</li>
<li>results: 我们在ETH和UCY公共数据集上评估了我们的方法，并使用最终差分误差（FDE）和平均差分误差（ADE）度量来评估性能。我们发现，我们修改后的算法在拥挤空间中预测人行踪的性能有6.2%和6.3%的提升，相比文献中Social LSTM的结果。<details>
<summary>Abstract</summary>
In this paper, we propose a human trajectory prediction model that combines a Long Short-Term Memory (LSTM) network with an attention mechanism. To do that, we use attention scores to determine which parts of the input data the model should focus on when making predictions. Attention scores are calculated for each input feature, with a higher score indicating the greater significance of that feature in predicting the output. Initially, these scores are determined for the target human position, velocity, and their neighboring individual's positions and velocities. By using attention scores, our model can prioritize the most relevant information in the input data and make more accurate predictions. We extract attention scores from our attention mechanism and integrate them into the trajectory prediction module to predict human future trajectories. To achieve this, we introduce a new neural layer that processes attention scores after extracting them and concatenates them with positional information. We evaluate our approach on the publicly available ETH and UCY datasets and measure its performance using the final displacement error (FDE) and average displacement error (ADE) metrics. We show that our modified algorithm performs better than the Social LSTM in predicting the future trajectory of pedestrians in crowded spaces. Specifically, our model achieves an improvement of 6.2% in ADE and 6.3% in FDE compared to the Social LSTM results in the literature.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种人体轨迹预测模型，该模型结合了长期短记忆网络（LSTM）和注意力机制。为了实现这一点，我们使用注意力分数来确定输入数据中哪些部分需要模型的注意力。注意力分数分别计算对每个输入特征的注意力，高注意力分数表示该特征在预测输出时的更大重要性。我们首先计算这些分数，然后将其与目标人体位置、速度和邻近个体位置和速度相关的输入特征进行相加。通过使用注意力分数，我们的模型可以在输入数据中优先级掌握相关信息，并且更准确地预测人体轨迹。我们从注意力机制中提取出注意力分数，并将其与位置信息一起处理。我们新增一层神经网络来处理注意力分数，并将其与位置信息进行拼接。我们使用公共可用的ETH和UCY数据集进行评估，并使用最终差分Error（FDE）和平均差分Error（ADE） metric来评估我们的方法。我们的修改后的算法在预测人体轨迹时比Social LSTM在文献中的结果更好，具体来说，我们的模型在ADE和FDE metric上分别提高6.2%和6.3%。
</details></li>
</ul>
<hr>
<h2 id="ARFA-An-Asymmetric-Receptive-Field-Autoencoder-Model-for-Spatiotemporal-Prediction"><a href="#ARFA-An-Asymmetric-Receptive-Field-Autoencoder-Model-for-Spatiotemporal-Prediction" class="headerlink" title="ARFA: An Asymmetric Receptive Field Autoencoder Model for Spatiotemporal Prediction"></a>ARFA: An Asymmetric Receptive Field Autoencoder Model for Spatiotemporal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00314">http://arxiv.org/abs/2309.00314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxuan Zhang, Xuechao Zou, Li Wu, Jianqiang Huang, Xiaoying Wang</li>
<li>for: 预测Future sequences by learning from historical contexts, 用于各个领域，如交通流量预测和天气预测。</li>
<li>methods: 提出了一种偏 asymmetric Receptive Field Autoencoder (ARFA) 模型，通过设计不同大小的感知场模块，适应Encoder和Decoder的不同功能。在Encoder中，引入大kernel模块 для全球空间时间特征提取;在Decoder中，开发小kernel模块 для本地空间时间信息重建。</li>
<li>results: 在两个主流的空间时间预测数据集和我们自己construct的RainBench数据集上，ARFA实现了一致的状态集成性表现，证明了我们的方法的有效性。这种方法不仅从感知场的角度探索了一种新的方法，还为降水预测提供了数据支持，从而推动了未来的空间时间预测研究。<details>
<summary>Abstract</summary>
Spatiotemporal prediction aims to generate future sequences by paradigms learned from historical contexts. It holds significant importance in numerous domains, including traffic flow prediction and weather forecasting. However, existing methods face challenges in handling spatiotemporal correlations, as they commonly adopt encoder and decoder architectures with identical receptive fields, which adversely affects prediction accuracy. This paper proposes an Asymmetric Receptive Field Autoencoder (ARFA) model to address this issue. Specifically, we design corresponding sizes of receptive field modules tailored to the distinct functionalities of the encoder and decoder. In the encoder, we introduce a large kernel module for global spatiotemporal feature extraction. In the decoder, we develop a small kernel module for local spatiotemporal information reconstruction. To address the scarcity of meteorological prediction data, we constructed the RainBench, a large-scale radar echo dataset specific to the unique precipitation characteristics of inland regions in China for precipitation prediction. Experimental results demonstrate that ARFA achieves consistent state-of-the-art performance on two mainstream spatiotemporal prediction datasets and our RainBench dataset, affirming the effectiveness of our approach. This work not only explores a novel method from the perspective of receptive fields but also provides data support for precipitation prediction, thereby advancing future research in spatiotemporal prediction.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Spatiotemporal prediction aims to generate future sequences by paradigms learned from historical contexts. It holds significant importance in numerous domains, including traffic flow prediction and weather forecasting. However, existing methods face challenges in handling spatiotemporal correlations, as they commonly adopt encoder and decoder architectures with identical receptive fields, which adversely affects prediction accuracy. This paper proposes an Asymmetric Receptive Field Autoencoder (ARFA) model to address this issue. Specifically, we design corresponding sizes of receptive field modules tailored to the distinct functionalities of the encoder and decoder. In the encoder, we introduce a large kernel module for global spatiotemporal feature extraction. In the decoder, we develop a small kernel module for local spatiotemporal information reconstruction. To address the scarcity of meteorological prediction data, we constructed the RainBench, a large-scale radar echo dataset specific to the unique precipitation characteristics of inland regions in China for precipitation prediction. Experimental results demonstrate that ARFA achieves consistent state-of-the-art performance on two mainstream spatiotemporal prediction datasets and our RainBench dataset, affirming the effectiveness of our approach. This work not only explores a novel method from the perspective of receptive fields but also provides data support for precipitation prediction, thereby advancing future research in spatiotemporal prediction."中文翻译：<<SYS>>预测在时空中的序列，通过历史上的模式学习来实现。这种预测在各个领域都具有重要性，例如交通流量预测和天气预测。然而，现有的方法在处理时空相关性方面存在挑战，因为它们通常采用编码器和解码器结构具有相同的接收场，这会影响预测精度。本文提出了不同接收场的自适应各自谱频域自适应编码器（ARFA）模型，以解决这个问题。特别是，我们在编码器中设计了大小不同的接收场模块，以适应不同的功能。在编码器中，我们引入了大kernel模块，用于全局时空特征提取。在解码器中，我们开发了小kernel模块，用于本地时空信息重建。为了解决天气预测数据的缺乏，我们建立了雨峰Bench，一个特有的雨水特征的大规模雷达响应数据集，用于雨水预测。实验结果表明，ARFA在两个主流时空预测数据集和我们的雨峰Bench数据集上具有一致的状态艺术性，证明了我们的方法的有效性。这种研究不仅从接收场的角度探讨了一种新的方法，还为雨水预测提供了数据支持，从而推动了未来的时空预测研究。
</details></li>
</ul>
<hr>
<h2 id="Fusing-Monocular-Images-and-Sparse-IMU-Signals-for-Real-time-Human-Motion-Capture"><a href="#Fusing-Monocular-Images-and-Sparse-IMU-Signals-for-Real-time-Human-Motion-Capture" class="headerlink" title="Fusing Monocular Images and Sparse IMU Signals for Real-time Human Motion Capture"></a>Fusing Monocular Images and Sparse IMU Signals for Real-time Human Motion Capture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00310">http://arxiv.org/abs/2309.00310</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shaohua-pan/RobustCap">https://github.com/shaohua-pan/RobustCap</a></li>
<li>paper_authors: Shaohua Pan, Qi Ma, Xinyu Yi, Weifeng Hu, Xiong Wang, Xingkang Zhou, Jijunnan Li, Feng Xu</li>
<li>For:  This paper proposes a method for real-time human motion capture using a combination of monocular images and sparse IMUs.* Methods: The proposed method uses a dual coordinate strategy to fully explore the IMU signals and combines the information from both modalities to achieve robust motion capture.* Results: The proposed method significantly outperforms state-of-the-art vision, IMU, and combined methods on both global orientation and local pose estimation, and the codes are available for research at <a target="_blank" rel="noopener" href="https://shaohua-pan.github.io/robustcap-page/">https://shaohua-pan.github.io/robustcap-page/</a>.Here is the same information in Traditional Chinese:* For: 这篇 paper 提出了一种基于 monocular 影像和简陋 IMU 的 real-time人体动作捕捉方法。* Methods: 提出的方法使用了对 IMU 信号的双坐标策略，以全面利用 IMU 信号，并结合两种感测资料以 достиieving Robust 动作捕捉。* Results: 提出的方法在 global 方向和本地姿态估测方面均有 significanly 超过了现有的见识、IMU 和合成方法，并且 codes 可以在 <a target="_blank" rel="noopener" href="https://shaohua-pan.github.io/robustcap-page/">https://shaohua-pan.github.io/robustcap-page/</a> 进行研究。<details>
<summary>Abstract</summary>
Either RGB images or inertial signals have been used for the task of motion capture (mocap), but combining them together is a new and interesting topic. We believe that the combination is complementary and able to solve the inherent difficulties of using one modality input, including occlusions, extreme lighting/texture, and out-of-view for visual mocap and global drifts for inertial mocap. To this end, we propose a method that fuses monocular images and sparse IMUs for real-time human motion capture. Our method contains a dual coordinate strategy to fully explore the IMU signals with different goals in motion capture. To be specific, besides one branch transforming the IMU signals to the camera coordinate system to combine with the image information, there is another branch to learn from the IMU signals in the body root coordinate system to better estimate body poses. Furthermore, a hidden state feedback mechanism is proposed for both two branches to compensate for their own drawbacks in extreme input cases. Thus our method can easily switch between the two kinds of signals or combine them in different cases to achieve a robust mocap. %The two divided parts can help each other for better mocap results under different conditions. Quantitative and qualitative results demonstrate that by delicately designing the fusion method, our technique significantly outperforms the state-of-the-art vision, IMU, and combined methods on both global orientation and local pose estimation. Our codes are available for research at https://shaohua-pan.github.io/robustcap-page/.
</details>
<details>
<summary>摘要</summary>
Original text: Either RGB images or inertial signals have been used for the task of motion capture (mocap), but combining them together is a new and interesting topic. We believe that the combination is complementary and able to solve the inherent difficulties of using one modality input, including occlusions, extreme lighting/texture, and out-of-view for visual mocap and global drifts for inertial mocap. To this end, we propose a method that fuses monocular images and sparse IMUs for real-time human motion capture. Our method contains a dual coordinate strategy to fully explore the IMU signals with different goals in motion capture. To be specific, besides one branch transforming the IMU signals to the camera coordinate system to combine with the image information, there is another branch to learn from the IMU signals in the body root coordinate system to better estimate body poses. Furthermore, a hidden state feedback mechanism is proposed for both two branches to compensate for their own drawbacks in extreme input cases. Thus our method can easily switch between the two kinds of signals or combine them in different cases to achieve a robust mocap. %The two divided parts can help each other for better mocap results under different conditions. Quantitative and qualitative results demonstrate that by delicately designing the fusion method, our technique significantly outperforms the state-of-the-art vision, IMU, and combined methods on both global orientation and local pose estimation. Our codes are available for research at https://shaohua-pan.github.io/robustcap-page/.Simplified Chinese translation: Either RGB 图像或惯性信号已经用于人体运动捕捉（моcap）任务，但是将其结合在一起是一个新领域的研究。我们认为这种结合是补做的，可以解决单modal输入的内在困难，包括图像中的 occlusion、极端的光照/文化和视图外的出现。为此，我们提出了一种将单静止图像和稀疏 IMU 进行实时人体运动捕捉的方法。我们的方法包括一种双坐标策略，以便充分利用 IMU 信号的不同目标在运动捕捉中。具体来说，除了一个分支将 IMU 信号转换到相机坐标系统中，与图像信息结合之外，还有另一个分支可以从 IMU 信号中学习体部pose。此外，我们还提出了一种隐藏状态反馈机制，以便在极端输入情况下补做各自的缺陷。因此，我们的方法可以根据不同情况选择不同的信号或将其结合在一起，以实现一种稳定的 mocap。%两个分支可以在不同的情况下协助each other，以提高运动捕捉结果。我们的数据可以在 https://shaohua-pan.github.io/robustcap-page/ 上进行研究。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Surrogate-Models-for-Materials-Science-Simulations-Machine-Learning-based-Prediction-of-Microstructure-Properties"><a href="#Efficient-Surrogate-Models-for-Materials-Science-Simulations-Machine-Learning-based-Prediction-of-Microstructure-Properties" class="headerlink" title="Efficient Surrogate Models for Materials Science Simulations: Machine Learning-based Prediction of Microstructure Properties"></a>Efficient Surrogate Models for Materials Science Simulations: Machine Learning-based Prediction of Microstructure Properties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00305">http://arxiv.org/abs/2309.00305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Binh Duong Nguyen, Pavlo Potapenko, Aytekin Dermici, Kishan Govinda, Stefan Sandfeld</li>
<li>for: 这篇论文的目的是为了探讨和预测物理、化学、生物等领域中的结构属性关系。</li>
<li>methods: 这篇论文使用了六种机器学习算法，并分析了这些算法的准确性和可靠性，以及它们之间的区别。</li>
<li>results: 这篇论文通过分析两个不同数据集，包括二维离散伊辛模型的数据和卡恩-希耶模型的数据，以及将这些数据转换为特别设计的特征，来预测结构属性关系。<details>
<summary>Abstract</summary>
Determining, understanding, and predicting the so-called structure-property relation is an important task in many scientific disciplines, such as chemistry, biology, meteorology, physics, engineering, and materials science. Structure refers to the spatial distribution of, e.g., substances, material, or matter in general, while property is a resulting characteristic that usually depends in a non-trivial way on spatial details of the structure. Traditionally, forward simulations models have been used for such tasks. Recently, several machine learning algorithms have been applied in these scientific fields to enhance and accelerate simulation models or as surrogate models. In this work, we develop and investigate the applications of six machine learning techniques based on two different datasets from the domain of materials science: data from a two-dimensional Ising model for predicting the formation of magnetic domains and data representing the evolution of dual-phase microstructures from the Cahn-Hilliard model. We analyze the accuracy and robustness of all models and elucidate the reasons for the differences in their performances. The impact of including domain knowledge through tailored features is studied, and general recommendations based on the availability and quality of training data are derived from this.
</details>
<details>
<summary>摘要</summary>
In this work, we develop and investigate the applications of six machine learning techniques based on two different datasets from the domain of materials science: data from a two-dimensional Ising model for predicting the formation of magnetic domains and data representing the evolution of dual-phase microstructures from the Cahn-Hilliard model. We analyze the accuracy and robustness of all models and elucidate the reasons for the differences in their performances.We also study the impact of including domain knowledge through tailored features and derive general recommendations based on the availability and quality of training data. Our findings provide insights into the potential of machine learning techniques for predicting structure-property relations in materials science and highlight the importance of considering domain knowledge and data quality when selecting and applying these techniques.
</details></li>
</ul>
<hr>
<h2 id="Fine-Grained-Spatiotemporal-Motion-Alignment-for-Contrastive-Video-Representation-Learning"><a href="#Fine-Grained-Spatiotemporal-Motion-Alignment-for-Contrastive-Video-Representation-Learning" class="headerlink" title="Fine-Grained Spatiotemporal Motion Alignment for Contrastive Video Representation Learning"></a>Fine-Grained Spatiotemporal Motion Alignment for Contrastive Video Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00297">http://arxiv.org/abs/2309.00297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghao Zhu, Xiao Lin, Ronghao Dang, Chengju Liu, Qijun Chen</li>
<li>for: 本文提出了一种基于细谱强制学习的高级视频表示方法，用于提高视频表示的动态信息表示能力。</li>
<li>methods: 本文使用了框架差为动态信息源，并通过设计 pixel-level 动态监督学习和前景采样策略来提高动态信息的匹配率。此外，文章还提出了一种帧级动态强制损失来提高动态特征的时间多样性。</li>
<li>results: 实验表明，基于 FIMA 框架学习的表示能够具备出色的动态意识能力，并在 UCF101、HMDB51 和 Diving48 等 datasets 上 achieve state-of-the-art or competitive results。<details>
<summary>Abstract</summary>
As the most essential property in a video, motion information is critical to a robust and generalized video representation. To inject motion dynamics, recent works have adopted frame difference as the source of motion information in video contrastive learning, considering the trade-off between quality and cost. However, existing works align motion features at the instance level, which suffers from spatial and temporal weak alignment across modalities. In this paper, we present a \textbf{Fi}ne-grained \textbf{M}otion \textbf{A}lignment (FIMA) framework, capable of introducing well-aligned and significant motion information. Specifically, we first develop a dense contrastive learning framework in the spatiotemporal domain to generate pixel-level motion supervision. Then, we design a motion decoder and a foreground sampling strategy to eliminate the weak alignments in terms of time and space. Moreover, a frame-level motion contrastive loss is presented to improve the temporal diversity of the motion features. Extensive experiments demonstrate that the representations learned by FIMA possess great motion-awareness capabilities and achieve state-of-the-art or competitive results on downstream tasks across UCF101, HMDB51, and Diving48 datasets. Code is available at \url{https://github.com/ZMHH-H/FIMA}.
</details>
<details>
<summary>摘要</summary>
As the most essential property in a video, motion information is critical to a robust and generalized video representation. To inject motion dynamics, recent works have adopted frame difference as the source of motion information in video contrastive learning, considering the trade-off between quality and cost. However, existing works align motion features at the instance level, which suffers from spatial and temporal weak alignment across modalities. In this paper, we present a 细grained Motion Alignment (FIMA) framework, capable of introducing well-aligned and significant motion information. Specifically, we first develop a dense contrastive learning framework in the spatiotemporal domain to generate pixel-level motion supervision. Then, we design a motion decoder and a foreground sampling strategy to eliminate the weak alignments in terms of time and space. Moreover, a frame-level motion contrastive loss is presented to improve the temporal diversity of the motion features. Extensive experiments demonstrate that the representations learned by FIMA possess great motion-awareness capabilities and achieve state-of-the-art or competitive results on downstream tasks across UCF101, HMDB51, and Diving48 datasets. Code is available at \url{https://github.com/ZMHH-H/FIMA}.
</details></li>
</ul>
<hr>
<h2 id="Fast-Diffusion-EM-a-diffusion-model-for-blind-inverse-problems-with-application-to-deconvolution"><a href="#Fast-Diffusion-EM-a-diffusion-model-for-blind-inverse-problems-with-application-to-deconvolution" class="headerlink" title="Fast Diffusion EM: a diffusion model for blind inverse problems with application to deconvolution"></a>Fast Diffusion EM: a diffusion model for blind inverse problems with application to deconvolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00287">http://arxiv.org/abs/2309.00287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles Laroche, Andrés Almansa, Eva Coupete</li>
<li>for:  solves inverse problems of blind image deblurring</li>
<li>methods:  uses diffusion models and Expectation-Minimization (EM) estimation method with blur kernel regularization</li>
<li>results:  provides effective and fast results compared to other state-of-the-art approaches in blind image deblurring<details>
<summary>Abstract</summary>
Using diffusion models to solve inverse problems is a growing field of research. Current methods assume the degradation to be known and provide impressive results in terms of restoration quality and diversity. In this work, we leverage the efficiency of those models to jointly estimate the restored image and unknown parameters of the degradation model. In particular, we designed an algorithm based on the well-known Expectation-Minimization (EM) estimation method and diffusion models. Our method alternates between approximating the expected log-likelihood of the inverse problem using samples drawn from a diffusion model and a maximization step to estimate unknown model parameters. For the maximization step, we also introduce a novel blur kernel regularization based on a Plug \& Play denoiser. Diffusion models are long to run, thus we provide a fast version of our algorithm. Extensive experiments on blind image deblurring demonstrate the effectiveness of our method when compared to other state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)使用分散模型解决反向问题是一个快速 развивающийся的研究领域。当前的方法假设质量损害是已知的，并且提供了非常出色的修复质量和多样性。在这个工作中，我们利用分散模型的效率来同时估计修复图像和未知的损害模型参数。特别是，我们设计了基于well-known Expectation-Minimization（EM）估计方法和分散模型的算法。我们的方法 alternate между估计反向问题的预期日志似然函数 using 分散模型中的样本，以及一个最大化步骤来估计未知模型参数。为了最大化步骤，我们还引入了一种新的噪声核定regularization，基于Plug & Playdenoiser。分散模型需要长时间运行，因此我们提供了一个快速版本的算法。我们的实验表明，当比较到其他当前最佳方法时，我们的方法具有非常出色的效果。
</details></li>
</ul>
<hr>
<h2 id="SparseSat-NeRF-Dense-Depth-Supervised-Neural-Radiance-Fields-for-Sparse-Satellite-Images"><a href="#SparseSat-NeRF-Dense-Depth-Supervised-Neural-Radiance-Fields-for-Sparse-Satellite-Images" class="headerlink" title="SparseSat-NeRF: Dense Depth Supervised Neural Radiance Fields for Sparse Satellite Images"></a>SparseSat-NeRF: Dense Depth Supervised Neural Radiance Fields for Sparse Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00277">http://arxiv.org/abs/2309.00277</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lulinzhang/sps-nerf">https://github.com/lulinzhang/sps-nerf</a></li>
<li>paper_authors: Lulin Zhang, Ewelina Rupnik</li>
<li>for: 用于恢复非拉伯天地表面的数字表面模型，使得传统多视图缺失、异步获取或缺失缝隙等挑战情况下可以更好地工作。</li>
<li>methods: 使用神经辐射场（NeRF），这是一种不需要基础知识的自我监督学习方法，可以包含场景中物理参数，从而更好地处理传统多视图匹配（MVS）失败的情况。</li>
<li>results: 在偏辐射1B&#x2F;WorldView-3图像上使用SpS-NeRF方法，与NeRF和Sat-NeRF相比，能够更好地恢复场景的几何结构。<details>
<summary>Abstract</summary>
Digital surface model generation using traditional multi-view stereo matching (MVS) performs poorly over non-Lambertian surfaces, with asynchronous acquisitions, or at discontinuities. Neural radiance fields (NeRF) offer a new paradigm for reconstructing surface geometries using continuous volumetric representation. NeRF is self-supervised, does not require ground truth geometry for training, and provides an elegant way to include in its representation physical parameters about the scene, thus potentially remedying the challenging scenarios where MVS fails. However, NeRF and its variants require many views to produce convincing scene's geometries which in earth observation satellite imaging is rare. In this paper we present SparseSat-NeRF (SpS-NeRF) - an extension of Sat-NeRF adapted to sparse satellite views. SpS-NeRF employs dense depth supervision guided by crosscorrelation similarity metric provided by traditional semi-global MVS matching. We demonstrate the effectiveness of our approach on stereo and tri-stereo Pleiades 1B/WorldView-3 images, and compare against NeRF and Sat-NeRF. The code is available at https://github.com/LulinZhang/SpS-NeRF
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用传统多视图顺序匹配（MVS）生成数字表面模型在非拉贝特表面上表现不佳，特别是在异步获取、缺失数据或缺界面上。基于神经辐射场（NeRF）的新方法可以continuous volumetric representation来重建表面几何。NeRF不需要训练时的地面几何数据，同时可以自动包含场景中的物理参数，因此可能解决MVS在困难情况下失败的问题。然而，NeRF和其变种需要许多视图来生成实际场景的几何，而在地球观测卫星图像中这是罕见的。本文介绍了SpS-NeRF（SpareSat-NeRF），它是基于Sat-NeRF的扩展，针对罕见的卫星视图进行了改进。SpS-NeRF使用了密集的深度监督，通过传统的semi-global MVS匹配提供的相似性度量来导引。我们在顺recto-stereo Pleiades 1B/WorldView-3图像上展示了我们的方法的效果，并与NeRF和Sat-NeRF进行了比较。代码可以在https://github.com/LulinZhang/SpS-NeRF上获取。
</details></li>
</ul>
<hr>
<h2 id="Application-of-Machine-Learning-in-Melanoma-Detection-and-the-Identification-of-‘Ugly-Duckling’-and-Suspicious-Naevi-A-Review"><a href="#Application-of-Machine-Learning-in-Melanoma-Detection-and-the-Identification-of-‘Ugly-Duckling’-and-Suspicious-Naevi-A-Review" class="headerlink" title="Application of Machine Learning in Melanoma Detection and the Identification of ‘Ugly Duckling’ and Suspicious Naevi: A Review"></a>Application of Machine Learning in Melanoma Detection and the Identification of ‘Ugly Duckling’ and Suspicious Naevi: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00265">http://arxiv.org/abs/2309.00265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatima Al Zegair, Nathasha Naranpanawa, Brigid Betz-Stablein, Monika Janda, H. Peter Soyer, Shekhar S. Chandra<br>for: 这篇论文的目的是什么？methods: 这篇论文使用了哪些方法？results: 这篇论文获得了什么结果？Here are the answers in Simplified Chinese text:for: 这篇论文的目的是为了提高皮肤癌诊断的精度和方便，以及应对皮肤癌医生短缺。methods: 这篇论文使用了机器学习和深度学习技术，包括人工神经网络等，以探索皮肤癌早期识别和应对方法。results: 这篇论文获得了训练结果，显示机器学习和深度学习技术可以实现与专业医生相等的皮肤癌诊断精度，并且可以帮助减少医疗成本和提高疗效率。<details>
<summary>Abstract</summary>
Skin lesions known as naevi exhibit diverse characteristics such as size, shape, and colouration. The concept of an "Ugly Duckling Naevus" comes into play when monitoring for melanoma, referring to a lesion with distinctive features that sets it apart from other lesions in the vicinity. As lesions within the same individual typically share similarities and follow a predictable pattern, an ugly duckling naevus stands out as unusual and may indicate the presence of a cancerous melanoma. Computer-aided diagnosis (CAD) has become a significant player in the research and development field, as it combines machine learning techniques with a variety of patient analysis methods. Its aim is to increase accuracy and simplify decision-making, all while responding to the shortage of specialized professionals. These automated systems are especially important in skin cancer diagnosis where specialist availability is limited. As a result, their use could lead to life-saving benefits and cost reductions within healthcare. Given the drastic change in survival when comparing early stage to late-stage melanoma, early detection is vital for effective treatment and patient outcomes. Machine learning (ML) and deep learning (DL) techniques have gained popularity in skin cancer classification, effectively addressing challenges, and providing results equivalent to that of specialists. This article extensively covers modern Machine Learning and Deep Learning algorithms for detecting melanoma and suspicious naevi. It begins with general information on skin cancer and different types of naevi, then introduces AI, ML, DL, and CAD. The article then discusses the successful applications of various ML techniques like convolutional neural networks (CNN) for melanoma detection compared to dermatologists' performance. Lastly, it examines ML methods for UD naevus detection and identifying suspicious naevi.
</details>
<details>
<summary>摘要</summary>
皮肤 lesions  bekannt为 naevi 具有多样的特征，如大小、形状和颜色。“ugly duckling naevus”是在监测 melanoma 时的概念，指的是一个与周围其他 lesions 不同的特征，可能是癌变。因为 lesions 在同一个人身上通常具有相似的特征和预测的模式，ugly duckling naevus 会突出来为不寻常，并可能表示癌变的存在。computer-aided diagnosis (CAD) 在研发领域中发挥了重要作用，它结合了机器学习技术和多种患者分析方法。其目的是提高准确性和简化决策，同时回应医疗专业人员的短缺。这些自动化系统在皮肤癌诊断中特别重要，因为专业人员的可用性有限。因此，它们的使用可能导致生命的拯救和医疗成本的减少。由于皮肤癌的晚期诊断和治疗对 patient 的结果有极大的影响，早期检测是至关重要的。机器学习（ML）和深度学习（DL）技术在皮肤癌类型化方面取得了成功，有效地解决了一些挑战，并提供了与专业人员相当的结果。这篇文章从 skin cancer 和不同类型的 naevi 的基础知识开始，然后介绍了 AI、ML、DL 和 CAD。文章 then discusses 了不同 ML 技术，如 convolutional neural networks (CNN) 在 melanoma 检测中的成功，与 dermatologists 的性能相比。最后，它检查了 ML 方法在 UD naevus 检测和寻找可疑 naevi 方面的应用。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Medical-Imagery-Diagnosis-with-Self-Attentive-Transformers-A-Review-of-Explainable-AI-for-Health-Care"><a href="#Interpretable-Medical-Imagery-Diagnosis-with-Self-Attentive-Transformers-A-Review-of-Explainable-AI-for-Health-Care" class="headerlink" title="Interpretable Medical Imagery Diagnosis with Self-Attentive Transformers: A Review of Explainable AI for Health Care"></a>Interpretable Medical Imagery Diagnosis with Self-Attentive Transformers: A Review of Explainable AI for Health Care</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00252">http://arxiv.org/abs/2309.00252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tin Lai</li>
<li>for: 本文旨在探讨最新的人工智能技术在基础医疗服务中的推广，以及使用感知 трансформер（ViT）模型，以及如何使用解释人工智能（XAI）方法来理解ViT模型做出决策的过程。</li>
<li>methods: 本文主要介绍了最新的ViT模型和XAI方法，包括自注意机制和解释模型，以及其应用于医疗诊断领域。</li>
<li>results: 本文结合了最新的ViT和XAI技术，提供了一种透明的医疗诊断方法，可以帮助医生更好地理解模型做出的决策，从而提高医疗诊断的准确性和可靠性。<details>
<summary>Abstract</summary>
Recent advancements in artificial intelligence (AI) have facilitated its widespread adoption in primary medical services, addressing the demand-supply imbalance in healthcare. Vision Transformers (ViT) have emerged as state-of-the-art computer vision models, benefiting from self-attention modules. However, compared to traditional machine-learning approaches, deep-learning models are complex and are often treated as a "black box" that can cause uncertainty regarding how they operate. Explainable Artificial Intelligence (XAI) refers to methods that explain and interpret machine learning models' inner workings and how they come to decisions, which is especially important in the medical domain to guide the healthcare decision-making process. This review summarises recent ViT advancements and interpretative approaches to understanding the decision-making process of ViT, enabling transparency in medical diagnosis applications.
</details>
<details>
<summary>摘要</summary>
最近的人工智能（AI）发展已经推动了医疗服务中的广泛应用，解决医疗需求和供应的失衡。视Transformer（ViT）已经 emerge 为当前最佳的计算机视觉模型，受益于自注意模块。然而，相比传统机器学习方法，深度学习模型更加复杂，经常被视为一个“黑盒子”，导致决策过程中存在不确定性。可解释人工智能（XAI）是指解释和解读机器学习模型内部工作的方法，尤其在医疗领域，以便guide医疗决策过程。本文回顾了最新的ViT进展和解释方法，以提高医疗诊断应用中的透明度。
</details></li>
</ul>
<hr>
<h2 id="Object-Centric-Multiple-Object-Tracking"><a href="#Object-Centric-Multiple-Object-Tracking" class="headerlink" title="Object-Centric Multiple Object Tracking"></a>Object-Centric Multiple Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00233">http://arxiv.org/abs/2309.00233</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amazon-science/object-centric-multiple-object-tracking">https://github.com/amazon-science/object-centric-multiple-object-tracking</a></li>
<li>paper_authors: Zixu Zhao, Jiaze Wang, Max Horn, Yizhuo Ding, Tong He, Zechen Bai, Dominik Zietlow, Carl-Johann Simon-Gabriel, Bing Shuai, Zhuowen Tu, Thomas Brox, Bernt Schiele, Yanwei Fu, Francesco Locatello, Zheng Zhang, Tianjun Xiao</li>
<li>for: 这个论文是为了解决多个物体跟踪（MOT）预测中的注解卷入问题而写的。</li>
<li>methods: 这个论文使用的方法是基于无监督物体学习的对象-центric模型，包括一个index-merge模块和一个物体记忆模块。这两个模块可以处理 occlusions 和缺失捕捉。</li>
<li>results: 这个论文的实验结果显示，这种方法可以减少 MOT 预测中的注解卷入，并且可以与完全监督的状态前进比肩。此外，这种方法还可以超过一些无监督跟踪器的性能。<details>
<summary>Abstract</summary>
Unsupervised object-centric learning methods allow the partitioning of scenes into entities without additional localization information and are excellent candidates for reducing the annotation burden of multiple-object tracking (MOT) pipelines. Unfortunately, they lack two key properties: objects are often split into parts and are not consistently tracked over time. In fact, state-of-the-art models achieve pixel-level accuracy and temporal consistency by relying on supervised object detection with additional ID labels for the association through time. This paper proposes a video object-centric model for MOT. It consists of an index-merge module that adapts the object-centric slots into detection outputs and an object memory module that builds complete object prototypes to handle occlusions. Benefited from object-centric learning, we only require sparse detection labels (0%-6.25%) for object localization and feature binding. Relying on our self-supervised Expectation-Maximization-inspired loss for object association, our approach requires no ID labels. Our experiments significantly narrow the gap between the existing object-centric model and the fully supervised state-of-the-art and outperform several unsupervised trackers.
</details>
<details>
<summary>摘要</summary>
<<SYS>>无监督对象中心学习方法可以将场景分解为实体，无需额外的本地化信息，是多个物体跟踪（MOT）管道中减少注解负担的优秀候选人。然而，它们缺乏两个关键特性：物体经常被分解成部分，并且在时间上不一致地跟踪。事实上，现状的模型可以在批处精度和时间上达到像素级准确性，通过额外的ID标签进行对时asso ciation。这篇论文提出了视频对象中心模型，它包括一个索引合并模块，将对象中心槽 adapt into 检测输出，以及一个对象记忆模块，用于处理遮挡。由于对象中心学习，我们只需 sparse 的检测标注（0%-6.25%）来确定物体位置和特征绑定。基于我们的自我超vised Expectation-Maximization-inspired 损失函数，我们的方法不需要ID标签。我们的实验显著缩小了现有的对象中心模型和完全监督状态前的差距，并在多个无监督跟踪器之上表现出色。
</details></li>
</ul>
<hr>
<h2 id="What-Makes-Good-Open-Vocabulary-Detector-A-Disassembling-Perspective"><a href="#What-Makes-Good-Open-Vocabulary-Detector-A-Disassembling-Perspective" class="headerlink" title="What Makes Good Open-Vocabulary Detector: A Disassembling Perspective"></a>What Makes Good Open-Vocabulary Detector: A Disassembling Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00227">http://arxiv.org/abs/2309.00227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jincheng Li, Chunyu Xie, Xiaoyu Wu, Bin Wang, Dawei Leng</li>
<li>for: 这篇论文旨在解决开放词汇检测（OVD）中的检测和识别未知对象的问题，以提高OVD的性能。</li>
<li>methods: 该论文使用了预训练的跨模态VLM（如CLIP、ALIGN等），并分析了三种OVD方法的设计各种各样。这三种方法分别是：vanilla方法、将二stage对象检测器与CLIP结合的方法，以及将RPN和RoI头结合的方法。</li>
<li>results: 在OVD-COCO和OVD-LVIS测试集上，DRR方法获得了最好的性能，在未知类别中提高了35.8个 Novel AP$<em>{50}$，相比之前的最佳状态（SOTA）提高了2.8个 Novel AP$</em>{50}$。在罕见类别中，DRR方法超过了前一个SOTA的1.9个 AP$_{50}$。此外，论文还提供了一个对象检测数据集called PID，并提供了该数据集上的基线性能。<details>
<summary>Abstract</summary>
Open-vocabulary detection (OVD) is a new object detection paradigm, aiming to localize and recognize unseen objects defined by an unbounded vocabulary. This is challenging since traditional detectors can only learn from pre-defined categories and thus fail to detect and localize objects out of pre-defined vocabulary. To handle the challenge, OVD leverages pre-trained cross-modal VLM, such as CLIP, ALIGN, etc. Previous works mainly focus on the open vocabulary classification part, with less attention on the localization part. We argue that for a good OVD detector, both classification and localization should be parallelly studied for the novel object categories. We show in this work that improving localization as well as cross-modal classification complement each other, and compose a good OVD detector jointly. We analyze three families of OVD methods with different design emphases. We first propose a vanilla method,i.e., cropping a bounding box obtained by a localizer and resizing it into the CLIP. We next introduce another approach, which combines a standard two-stage object detector with CLIP. A two-stage object detector includes a visual backbone, a region proposal network (RPN), and a region of interest (RoI) head. We decouple RPN and ROI head (DRR) and use RoIAlign to extract meaningful features. In this case, it avoids resizing objects. To further accelerate the training time and reduce the model parameters, we couple RPN and ROI head (CRR) as the third approach. We conduct extensive experiments on these three types of approaches in different settings. On the OVD-COCO benchmark, DRR obtains the best performance and achieves 35.8 Novel AP$_{50}$, an absolute 2.8 gain over the previous state-of-the-art (SOTA). For OVD-LVIS, DRR surpasses the previous SOTA by 1.9 AP$_{50}$ in rare categories. We also provide an object detection dataset called PID and provide a baseline on PID.
</details>
<details>
<summary>摘要</summary>
新的目标检测方式：开 vocabulary detection (OVD)，旨在确定和识别未经定义的对象。这是一个挑战，因为传统的检测器只能学习预先定义的类别，因此无法检测和定位未知的对象。为解决这个挑战，OVD 利用预训练的交叉模态 VLM，如 CLIP 和 ALIGN 等。过去的工作主要关注于开 vocabulary 分类部分，尚未充分关注本地化部分。我们认为，为一个好的 OVD 检测器，分类和本地化应该同时研究对于新的对象类别。我们在这里展示，提高本地化以及交叉模态分类之间的互补关系，组成一个好的 OVD 检测器。我们分析了三种 OVD 方法的设计强调不同，并进行了广泛的实验。首先，我们提出了一种简单的方法，即将一个由本地化器生成的 bounding box 裁剪成 CLIP 的大小，并将其作为输入给 CLIP。然后，我们引入了另一种方法，即将标准的两stage 对象检测器与 CLIP 结合，该检测器包括视觉脊梁、区域提案网络（RPN）和区域兴趣（RoI）头。我们在这种情况下，使用 RoIAlign 提取有用的特征。这种方法可以避免对对象进行resize。最后，我们将 RPN 和 RoI 头结合（CRR），以便快速训练和减少模型参数。我们在这些三种方法上进行了广泛的实验，并在 OVD-COCO 标准测试集上进行了评估。DRR 在 OVD-COCO 上取得了最高性能，其 Novel AP$_{50}$ 为 35.8，相对于前一个 SOTA 提高了 2.8。在 rare 类别上，DRR 超过了之前的 SOTA 的 1.9 AP$_{50}$。我们还提供了一个对象检测数据集 called PID，并提供了这个数据集上的基线。
</details></li>
</ul>
<hr>
<h2 id="Human-Inspired-Facial-Sketch-Synthesis-with-Dynamic-Adaptation"><a href="#Human-Inspired-Facial-Sketch-Synthesis-with-Dynamic-Adaptation" class="headerlink" title="Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation"></a>Human-Inspired Facial Sketch Synthesis with Dynamic Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00216">http://arxiv.org/abs/2309.00216</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aiart-hdu/hida">https://github.com/aiart-hdu/hida</a></li>
<li>paper_authors: Fei Gao, Yifan Zhu, Chang Jiang, Nannan Wang</li>
<li>for: 该 paper 的目的是提出一种基于人工创作的动态适应（HIDA）方法，以生成高质量的人脸素描。</li>
<li>methods: 该方法使用动态调整神经元活动，并使用可变卷积来对深度特征进行匹配，以生成抽象的人脸素描。</li>
<li>results: 实验结果表明，HIDA 可以在多种难度的人脸上生成高质量的素描，并在不同风格的人脸上保持一致性。<details>
<summary>Abstract</summary>
Facial sketch synthesis (FSS) aims to generate a vivid sketch portrait from a given facial photo. Existing FSS methods merely rely on 2D representations of facial semantic or appearance. However, professional human artists usually use outlines or shadings to covey 3D geometry. Thus facial 3D geometry (e.g. depth map) is extremely important for FSS. Besides, different artists may use diverse drawing techniques and create multiple styles of sketches; but the style is globally consistent in a sketch. Inspired by such observations, in this paper, we propose a novel Human-Inspired Dynamic Adaptation (HIDA) method. Specially, we propose to dynamically modulate neuron activations based on a joint consideration of both facial 3D geometry and 2D appearance, as well as globally consistent style control. Besides, we use deformable convolutions at coarse-scales to align deep features, for generating abstract and distinct outlines. Experiments show that HIDA can generate high-quality sketches in multiple styles, and significantly outperforms previous methods, over a large range of challenging faces. Besides, HIDA allows precise style control of the synthesized sketch, and generalizes well to natural scenes and other artistic styles. Our code and results have been released online at: https://github.com/AiArt-HDU/HIDA.
</details>
<details>
<summary>摘要</summary>
Facial Sketch Synthesis (FSS) 目标是从给定的面部照片中生成一个生动的笔画肖像。现有的 FSS 方法只是基于面部semantic或外观的2D表示。然而，职业艺术家通常使用 outline 或渐变来传递3D几何信息。因此，面部3D几何（例如深度图）在 FSS 中非常重要。此外，不同艺术家可能使用不同的绘画技巧，但是在绘画中保持全局一致的风格是非常重要。以这些观察为 inspirations，在这篇论文中，我们提出了一种新的人类 inspiritedynamic adaptation（HIDA）方法。具体来说，我们提出在考虑面部3D几何和2D外观以及全局一致的风格控制的基础上，动态调整神经活动。此外，我们使用可变核函数在粗略尺度上对深度特征进行对接，以生成抽象而独特的 OUTLINE。实验表明，HIDA 可以生成高质量的笔画肖像，并在各种挑战性脸部上显著超越先前的方法。此外，HIDA 允许精准地控制生成的笔画肖像的风格，并在自然场景和其他艺术风格上广泛适用。我们的代码和结果已经在 GitHub 上发布：https://github.com/AiArt-HDU/HIDA。
</details></li>
</ul>
<hr>
<h2 id="DARC-Distribution-Aware-Re-Coloring-Model-for-Generalizable-Nucleus-Segmentation"><a href="#DARC-Distribution-Aware-Re-Coloring-Model-for-Generalizable-Nucleus-Segmentation" class="headerlink" title="DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation"></a>DARC: Distribution-Aware Re-Coloring Model for Generalizable Nucleus Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00188">http://arxiv.org/abs/2309.00188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengcong Chen, Changxing Ding, Dacheng Tao, Hao Chen</li>
<li>for: 本研究旨在提出一种普适的核心分割模型，能够在不同域的图像上进行准确的核心分割。</li>
<li>methods: 本研究使用了一种 Distribution-Aware Re-Coloring (DARC) 模型，从两个角度解决了域 gap 问题。首先，提出了一种重新调色方法，以解决不同域的图像颜色差异。其次，提出了一种新的实例normalization方法，可以快速地处理不同的前景-背景比例变化。</li>
<li>results: 对于两个 H$&amp;$E 染料和两个 IHC 染料的图像数据集进行了广泛的实验，证明了我们提出的 DARC 模型的效果。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/csccsccsccsc/DARC%7D">https://github.com/csccsccsccsc/DARC}</a> 上下载。<details>
<summary>Abstract</summary>
Nucleus segmentation is usually the first step in pathological image analysis tasks. Generalizable nucleus segmentation refers to the problem of training a segmentation model that is robust to domain gaps between the source and target domains. The domain gaps are usually believed to be caused by the varied image acquisition conditions, e.g., different scanners, tissues, or staining protocols. In this paper, we argue that domain gaps can also be caused by different foreground (nucleus)-background ratios, as this ratio significantly affects feature statistics that are critical to normalization layers. We propose a Distribution-Aware Re-Coloring (DARC) model that handles the above challenges from two perspectives. First, we introduce a re-coloring method that relieves dramatic image color variations between different domains. Second, we propose a new instance normalization method that is robust to the variation in foreground-background ratios. We evaluate the proposed methods on two H$\&$E stained image datasets, named CoNSeP and CPM17, and two IHC stained image datasets, called DeepLIIF and BC-DeepLIIF. Extensive experimental results justify the effectiveness of our proposed DARC model. Codes are available at \url{https://github.com/csccsccsccsc/DARC
</details>
<details>
<summary>摘要</summary>
nuclei segmentation 通常是生物医学图像分析任务的第一步。通用 nuclei segmentation 问题指的是训练一个可以在不同来源领域中具有良好性能的分 segmentation 模型。这些领域差异通常被认为是由不同的图像捕获条件引起的，例如不同的扫描仪、组织或染色方法。在这篇论文中，我们认为领域差异也可能是由不同的前景（核体）背景比例引起的，因为这种比例对于图像的特征统计学非常重要。我们提出了一种 Distribution-Aware Re-Coloring（DARC）模型，该模型可以处理以下挑战。首先，我们引入了一种重新调色方法，以降低不同领域图像之间的极大图像颜色差异。其次，我们提出了一种新的实例Normalization方法，可以对不同的前景-背景比例进行鲁棒化。我们在两个HE染料图像集（CoNSeP和CPM17）和两个IHC染料图像集（DeepLIIF和BC-DeepLIIF）上进行了广泛的实验，结果证明了我们提出的DARC模型的效果。代码可以在 \url{https://github.com/csccsccsccsc/DARC} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Vision-aided-nonlinear-control-framework-for-shake-table-tests"><a href="#Vision-aided-nonlinear-control-framework-for-shake-table-tests" class="headerlink" title="Vision-aided nonlinear control framework for shake table tests"></a>Vision-aided nonlinear control framework for shake table tests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00187">http://arxiv.org/abs/2309.00187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongwei Chen, T. Y. Yang, Yifei Xiao, Xiao Pan, Wanyan Yang</li>
<li>For: 本研究使用适应控制理论来实现震动机械系统中的控制和结构相互作用（Control-Structural Interaction，CSI），并考虑了系统的非线性性。* Methods: 本研究使用了滤波器控制理论（Proportional-Integral-Derivative，PID）和适应控制理论来实现非线性控制。* Results:  simulations and experiments show that the proposed control framework can effectively control the shake table and reduce the vibration of the structure under earthquake excitations.<details>
<summary>Abstract</summary>
The structural response under the earthquake excitations can be simulated by scaled-down model shake table tests or full-scale model shake table tests. In this paper, adaptive control theory is used as a nonlinear shake table control algorithm which considers the inherent nonlinearity of the shake table system and the Control-Structural Interaction (CSI) effect that the linear controller cannot consider, such as the Proportional-Integral-Derivative (PID) controller. The mass of the specimen can be assumed as an unknown variation and the unknown parameter will be replaced by an estimated value in the proposed control framework. The signal generated by the control law of the adaptive control method will be implemented by a loop-shaping controller. To verify the stability and feasibility of the proposed control framework, a simulation of a bare shake table and experiments with a bare shake table with a two-story frame were carried out. This study randomly selects Earthquake recordings from the Pacific Earthquake Engineering Research Center (PEER) database. The simulation and experimental results show that the proposed control framework can be effectively used in shake table control.
</details>
<details>
<summary>摘要</summary>
《震动试验中的结构回应可以通过尺度缩小的模型震动试验或全尺度模型震动试验来模拟。本文使用适应控制理论作为震动试验中的非线性控制算法，考虑了震动试验系统的自然非线性和控制结构互动（CSI）效应，例如调速度-积分- Derivative（PID）控制器。试验用的物品重量可以被视为未知变化，并将未知参数更新为估算值。控制法框架中的控制信号将由适应控制方法的loop-shaping控制器实现。为验证提案的稳定性和可行性，本研究在实验中使用了一个空震动试验和一个有两层架构的空震动试验进行了实验。这些实验使用了太平洋地震工程研究中心（PEER）数据库中的地震纪录。实验和模拟结果显示，提案的控制法框架可以有效地应用于震动试验中。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/01/cs.CV_2023_09_01/" data-id="clogxf3mz00gq5xra1q3jhmhc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/01/cs.AI_2023_09_01/" class="article-date">
  <time datetime="2023-09-01T12:00:00.000Z" itemprop="datePublished">2023-09-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/01/cs.AI_2023_09_01/">cs.AI - 2023-09-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-RLHF-Reducing-the-Memory-Usage-of-PPO"><a href="#Efficient-RLHF-Reducing-the-Memory-Usage-of-PPO" class="headerlink" title="Efficient RLHF: Reducing the Memory Usage of PPO"></a>Efficient RLHF: Reducing the Memory Usage of PPO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00754">http://arxiv.org/abs/2309.00754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Santacroce, Yadong Lu, Han Yu, Yuanzhi Li, Yelong Shen</li>
<li>for: 这个论文的目的是解决RLHF中PPO阶段的内存问题，使得更多的实践者能够使用RLHF进行语言模型化。</li>
<li>methods: 论文使用了一系列的内存节省技术来降低PPO的内存使用量，并对这些技术的影响进行了全面的分析。</li>
<li>results: 实验结果显示，使用LoRA durante PPO可以降低PPO的内存使用量，并在四个公共benchmark上提高了RLHF的对齐性。此外，Hydra-PPO可以降低LoRA-PPO的样本延迟时间，而不会影响其性能。这些结果表明，Hydra-PPO是一种简单有前途的解决方案，可以普及RLHF的使用。<details>
<summary>Abstract</summary>
Reinforcement Learning with Human Feedback (RLHF) has revolutionized language modeling by aligning models with human preferences. However, the RL stage, Proximal Policy Optimization (PPO), requires over 3x the memory of Supervised Fine-Tuning (SFT), making it infeasible to use for most practitioners. To address this issue, we present a comprehensive analysis the memory usage, performance, and training time of memory-savings techniques for PPO. We introduce Hydra-RLHF by first integrating the SFT and Reward models and then dynamically turning LoRA "off" during training. Our experiments show: 1. Using LoRA during PPO reduces its memory usage to be smaller than SFT while improving alignment across four public benchmarks, and 2. Hydra-PPO reduces the latency per sample of LoRA-PPO by up to 65% while maintaining its performance. Our results demonstrate that Hydra-PPO is a simple and promising solution for enabling more widespread usage of RLHF.
</details>
<details>
<summary>摘要</summary>
“强化学习 avec 人类反馈（RLHF）已经革命化语言模型化，将模型与人类偏好进行Alignment。但是，RL阶段的Proximal Policy Optimization（PPO）需要更多的内存，使得大多数实践者无法使用。为解决这个问题，我们提供了一个涵盖性分析的内存使用、性能和训练时间的分析。我们首先将Supervised Fine-Tuning（SFT）和Reward模型集成，然后在训练过程中静态地将LoRA“Off”。我们的实验结果显示：1. 在PPO中使用LoRA可以降低其内存使用量，与SFT相比，并在四个公共测试集上提高了Alignment的表现。2. Hydra-PPO可以将LoRA-PPO的延迟时间降低至最多65%，保持其表现。我们的结果显示，Hydra-PPO是一个简单且有前途的解决方案，可以帮助RLHF更加广泛地应用。”
</details></li>
</ul>
<hr>
<h2 id="Language-Conditioned-Change-point-Detection-to-Identify-Sub-Tasks-in-Robotics-Domains"><a href="#Language-Conditioned-Change-point-Detection-to-Identify-Sub-Tasks-in-Robotics-Domains" class="headerlink" title="Language-Conditioned Change-point Detection to Identify Sub-Tasks in Robotics Domains"></a>Language-Conditioned Change-point Detection to Identify Sub-Tasks in Robotics Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00743">http://arxiv.org/abs/2309.00743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Divyanshu Raj, Chitta Baral, Nakul Gopalan</li>
<li>for: 本研究目标是通过语言指令确定机器人行走路径中的子任务。</li>
<li>methods: 我们使用语言提供的指导来确定语言指令中的子任务，并将这些子任务映射到机器人行走路径中的子段。</li>
<li>results: 我们的方法可以准确地确定机器人行走路径中的子任务，并且与基eline方法相比，我们的方法可以提高$1.78_{\pm 0.82}%$的准确率。<details>
<summary>Abstract</summary>
In this work, we present an approach to identify sub-tasks within a demonstrated robot trajectory using language instructions. We identify these sub-tasks using language provided during demonstrations as guidance to identify sub-segments of a longer robot trajectory. Given a sequence of natural language instructions and a long trajectory consisting of image frames and discrete actions, we want to map an instruction to a smaller fragment of the trajectory. Unlike previous instruction following works which directly learn the mapping from language to a policy, we propose a language-conditioned change-point detection method to identify sub-tasks in a problem. Our approach learns the relationship between constituent segments of a long language command and corresponding constituent segments of a trajectory. These constituent trajectory segments can be used to learn subtasks or sub-goals for planning or options as demonstrated by previous related work. Our insight in this work is that the language-conditioned robot change-point detection problem is similar to the existing video moment retrieval works used to identify sub-segments within online videos. Through extensive experimentation, we demonstrate a $1.78_{\pm 0.82}\%$ improvement over a baseline approach in accurately identifying sub-tasks within a trajectory using our proposed method. Moreover, we present a comprehensive study investigating sample complexity requirements on learning this mapping, between language and trajectory sub-segments, to understand if the video retrieval-based methods are realistic in real robot scenarios.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了一种方法，用于在人工智能机器人路径示例中标识子任务。我们使用示例中提供的语言作为指导，以标识路径中的子段。给定一个自然语言指令序列和一个包含图像帧和精确动作的长路径，我们想要将指令映射到更短的路径段。不同于前一些语言指令跟踪工作，我们提议使用语言条件变化点检测方法来标识子任务。我们的方法学习了语言命令中的各个段落和路径中的各个段落之间的关系。这些路径段可以用于学习子任务或子目标 для规划或选择。我们的发现是，语言条件变化点检测问题与现有在线视频中的分割问题类似。经过广泛的实验，我们表明了使用我们提议的方法可以与基准方法相比提高$1.78\pm0.82\%$的精度。此外，我们还进行了全面的研究，以了解学习这种映射的样本复杂度要求，以确定视频分割方法在真实的机器人场景中是否可行。
</details></li>
</ul>
<hr>
<h2 id="Contextual-Biasing-of-Named-Entities-with-Large-Language-Models"><a href="#Contextual-Biasing-of-Named-Entities-with-Large-Language-Models" class="headerlink" title="Contextual Biasing of Named-Entities with Large Language Models"></a>Contextual Biasing of Named-Entities with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00723">http://arxiv.org/abs/2309.00723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanneng Sun, Zeeshan Ahmed, Yingyi Ma, Zhe Liu, Yutong Pang, Ozlem Kalinli</li>
<li>for: 这paper研究使用大型自然语言模型（LLM）进行语音识别（ASR）的上下文化偏误。</li>
<li>methods:  authors提出了一种不需要微调的提示方法，使用提示列表和少量示例来提供额外信息，以提高ASR性能。同时，他们还提出了多任务训练方法，使LLM预测实体类和下一个token。为了提高效率和避免LLM的最长序列长度限制，authors提出了动态提示方法，选择最有可能性的类，并只使用这个类中的Entity作为下一个token预测的Context。</li>
<li>results:  results表明，提示列表和少量示例可以相对于首轮ASR提高17.8%和9.6%，而多任务训练和动态提示可以相对于首轮ASR提高20.0%和11.3%的WER。<details>
<summary>Abstract</summary>
This paper studies contextual biasing with Large Language Models (LLMs), where during second-pass rescoring additional contextual information is provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis. In addition to few-shot prompt learning, we propose multi-task training of the LLM to predict both the entity class and the next token. To improve the efficiency for contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction. Word Error Rate (WER) evaluation is performed on i) an internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli dataset. Results indicate that biasing lists and few-shot examples can achieve 17.8% and 9.6% relative improvement compared to first pass ASR, and that multi-task training and dynamic prompting can achieve 20.0% and 11.3% relative WER improvement, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Amortizing-Pragmatic-Program-Synthesis-with-Rankings"><a href="#Amortizing-Pragmatic-Program-Synthesis-with-Rankings" class="headerlink" title="Amortizing Pragmatic Program Synthesis with Rankings"></a>Amortizing Pragmatic Program Synthesis with Rankings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03225">http://arxiv.org/abs/2309.03225</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/evanthebouncy/pragmatic_synthesis_ranking">https://github.com/evanthebouncy/pragmatic_synthesis_ranking</a></li>
<li>paper_authors: Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena Glassman, Daniel Fried</li>
<li>for: 该论文旨在提高程序生成器的效率，使其能够应用于更多的领域。</li>
<li>methods: 该论文使用了 rational speech acts（RSA）框架，并开发了一种全局 Pragmatic 排名方法，以减轻 RSA 算法的计算负担。</li>
<li>results: 实验结果表明，使用全局 Pragmatic 排名方法可以大幅提高程序生成器的效率，并在多个示例下与非 Pragmatic  synthesizer 相比，表现更优异。<details>
<summary>Abstract</summary>
In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.
</details>
<details>
<summary>摘要</summary>
在程序生成中，一个智能系统会接受用户生成的示例集并返回一个符合这些示例的程序。使用 rational speech acts（RSA）框架已经成功地建立了 Pragmatic 程序生成器，这些程序不仅需要符合逻辑上的一致，还需要考虑用户选择示例的信息性。然而，运行 RSA 算法的计算负担限制了 Pragmatic 程序生成的应用领域的规模。这项工作提出了一种归一化 RSA 算法的方法，通过利用全局的 Pragmatic 排名来实现。我们证明，在单个示例下，我们的全球排名方法可以准确复制 RSA 排名的答案。我们进一步验证了全球排名在在线、多示例的 Setting 下能够有效地逼近整个 Pragmatic 生成器。在两个程序生成领域中，使用我们的 Pragmatic 排名方法，比对 RSA 生成器和标准、非 Pragmatic 生成器，实现了一个数量级的速度提升，同时表现更高。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-with-Human-Feedback-for-Realistic-Traffic-Simulation"><a href="#Reinforcement-Learning-with-Human-Feedback-for-Realistic-Traffic-Simulation" class="headerlink" title="Reinforcement Learning with Human Feedback for Realistic Traffic Simulation"></a>Reinforcement Learning with Human Feedback for Realistic Traffic Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00709">http://arxiv.org/abs/2309.00709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulong Cao, Boris Ivanovic, Chaowei Xiao, Marco Pavone</li>
<li>for:  This paper aims to enhance the realism of existing traffic models for autonomous vehicle development by incorporating human preferences through reinforcement learning.</li>
<li>methods: The proposed framework, called TrafficRLHF, uses human feedback for alignment and employs reinforcement learning with human preference to generate realistic traffic scenarios.</li>
<li>results: The framework demonstrates its proficiency in generating traffic scenarios that are well-aligned with human preferences, as corroborated by comprehensive evaluations on the nuScenes dataset.<details>
<summary>Abstract</summary>
In light of the challenges and costs of real-world testing, autonomous vehicle developers often rely on testing in simulation for the creation of reliable systems. A key element of effective simulation is the incorporation of realistic traffic models that align with human knowledge, an aspect that has proven challenging due to the need to balance realism and diversity. This works aims to address this by developing a framework that employs reinforcement learning with human preference (RLHF) to enhance the realism of existing traffic models. This study also identifies two main challenges: capturing the nuances of human preferences on realism and the unification of diverse traffic simulation models. To tackle these issues, we propose using human feedback for alignment and employ RLHF due to its sample efficiency. We also introduce the first dataset for realism alignment in traffic modeling to support such research. Our framework, named TrafficRLHF, demonstrates its proficiency in generating realistic traffic scenarios that are well-aligned with human preferences, as corroborated by comprehensive evaluations on the nuScenes dataset.
</details>
<details>
<summary>摘要</summary>
“为了Addressing the challenges and costs of real-world testing, autonomous vehicle developers often rely on simulation testing for the creation of reliable systems. A key element of effective simulation is the incorporation of realistic traffic models that align with human knowledge, an aspect that has proven challenging due to the need to balance realism and diversity. This study aims to address this by developing a framework that employs reinforcement learning with human preference (RLHF) to enhance the realism of existing traffic models. This study also identifies two main challenges: capturing the nuances of human preferences on realism and the unification of diverse traffic simulation models. To tackle these issues, we propose using human feedback for alignment and employ RLHF due to its sample efficiency. We also introduce the first dataset for realism alignment in traffic modeling to support such research. Our framework, named TrafficRLHF, demonstrates its proficiency in generating realistic traffic scenarios that are well-aligned with human preferences, as corroborated by comprehensive evaluations on the nuScenes dataset.”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other parts of the world. Traditional Chinese is also an option, but it is less commonly used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Geometric-Deep-Learning-a-Temperature-Based-Analysis-of-Graph-Neural-Networks"><a href="#Geometric-Deep-Learning-a-Temperature-Based-Analysis-of-Graph-Neural-Networks" class="headerlink" title="Geometric Deep Learning: a Temperature Based Analysis of Graph Neural Networks"></a>Geometric Deep Learning: a Temperature Based Analysis of Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00699">http://arxiv.org/abs/2309.00699</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Lapenna, F. Faglioni, F. Zanchetta, R. Fioresi</li>
<li>for: 这个研究使用几何深度学习模型来模拟 термо动力系统， weights 被看作为非量子和非相对论粒子。</li>
<li>methods: 研究使用过去定义的温度（参考 [7]），在不同层次上研究 GC 和 GAT 模型。</li>
<li>results: 研究结果可能有各种应用前景。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We examine a Geometric Deep Learning model as a thermodynamic system treating the weights as non-quantum and non-relativistic particles. We employ the notion of temperature previously defined in [7] and study it in the various layers for GCN and GAT models. Potential future applications of our findings are discussed.
</details>
<details>
<summary>摘要</summary>
我们研究了一个几何深度学习模型，将参数视为非量子和非 relativistic 粒子。我们使用先前在 [7] 中定义的温度概念，研究它在不同层次上的GCN和GAT模型中。我们还讨论了未来可能的应用。Here's a breakdown of the translation:* "We examine a Geometric Deep Learning model" becomes "我们研究了一个几何深度学习模型"* "as a thermodynamic system" becomes "视为一个热力学系统"* "treating the weights as non-quantum and non-relativistic particles" becomes "将参数视为非量子和非 relativistic 粒子"* "We employ the notion of temperature previously defined in [7]" becomes "我们使用先前在 [7] 中定义的温度概念"* "and study it in the various layers" becomes "研究它在不同层次上"* "for GCN and GAT models" becomes "在GCN和GAT模型中"* "Potential future applications of our findings are discussed" becomes "我们还讨论了未来可能的应用".
</details></li>
</ul>
<hr>
<h2 id="Jointly-Exploring-Client-Drift-and-Catastrophic-Forgetting-in-Dynamic-Learning"><a href="#Jointly-Exploring-Client-Drift-and-Catastrophic-Forgetting-in-Dynamic-Learning" class="headerlink" title="Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning"></a>Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00688">http://arxiv.org/abs/2309.00688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niklas Babendererde, Moritz Fuchs, Camila Gonzalez, Yuri Tolkach, Anirban Mukhopadhyay</li>
<li>for: 这篇研究旨在探讨 Federated and Continual Learning 中的 Client Drift 和 Catastrophic Forgetting 问题，并提出一个统一分析框架以测试这两种问题的相互关联性。</li>
<li>methods: 这篇研究使用了一个新的三维测试框架，可以同时考虑 Client Drift 和 Catastrophic Forgetting 的共同影响，并且可以统一分析这两种问题的共同性。</li>
<li>results: 研究发现，Client Drift 和 Catastrophic Forgetting 之间存在强联系，即当 Client Drift 发生时，Catastrophic Forgetting 也很可能发生，并且这两种问题之间存在一定的相互关联性。此外，研究还发现了一个“普遍提升”现象，即在某些混合情况下，由于 Client Drift 和 Catastrophic Forgetting 的共同影响，模型的性能可能会提高。<details>
<summary>Abstract</summary>
Federated and Continual Learning have emerged as potential paradigms for the robust and privacy-aware use of Deep Learning in dynamic environments. However, Client Drift and Catastrophic Forgetting are fundamental obstacles to guaranteeing consistent performance. Existing work only addresses these problems separately, which neglects the fact that the root cause behind both forms of performance deterioration is connected. We propose a unified analysis framework for building a controlled test environment for Client Drift -- by perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by shifting all clients with a particular strength. Our framework further leverages this new combined analysis by generating a 3D landscape of the combined performance impact from both. We demonstrate that the performance drop through Client Drift, caused by a certain share of shifted clients, is correlated to the drop from Catastrophic Forgetting resulting from a corresponding shift strength. Correlation tests between both problems for Computer Vision (CelebA) and Medical Imaging (PESO) support this new perspective, with an average Pearson rank correlation coefficient of over 0.94. Our framework's novel ability of combined spatio-temporal shift analysis allows us to investigate how both forms of distribution shift behave in mixed scenarios, opening a new pathway for better generalization. We show that a combination of moderate Client Drift and Catastrophic Forgetting can even improve the performance of the resulting model (causing a "Generalization Bump") compared to when only one of the shifts occurs individually. We apply a simple and commonly used method from Continual Learning in the federated setting and observe this phenomenon to be reoccurring, leveraging the ability of our framework to analyze existing and novel methods for Federated and Continual Learning.
</details>
<details>
<summary>摘要</summary>
随着 Federated Learning 和 Continual Learning 的出现，它们被视为在动态环境中使用深度学习的可靠和隐私保护方法的潜在方法。然而，客户端漂移和快速忘记是保证持续性表现的基本障碍。现有的工作仅 addressed these problems separately，忽略了它们的根本原因是相连的。我们提出一种统一分析框架，通过对 опреде定比例的客户端进行干扰来建立 Client Drift 的控制测试环境，并通过对所有客户端进行固定强度的偏移来建立 Catastrophic Forgetting 的测试环境。我们的框架进一步利用了这种新的共同分析，生成了 Client Drift 和 Catastrophic Forgetting 的共同性表现的 3D 地图。我们示出，Client Drift 引起的表现下降和 Catastrophic Forgetting 引起的表现下降之间存在强相关关系，在 Computer Vision (CelebA) 和 Medical Imaging (PESO) 支持这一新视角，共计 Pearson 相关系数超过 0.94。我们的框架的新的共同空间偏移分析能力，使我们可以在混合enario中调查 Client Drift 和 Catastrophic Forgetting 的分布变化行为，开启了一条新的通路以实现更好的泛化。我们显示，在混合 Client Drift 和 Catastrophic Forgetting 的情况下，模型的表现可能会得到改善（引起一个 "Generalization Bump"），比单独的偏移情况下更好。我们应用了常见的 Continual Learning 方法在 federated 设置下，并观察到这种现象是重复的，利用我们的框架分析现有和新的方法的可能性。
</details></li>
</ul>
<hr>
<h2 id="Point-Bind-Point-LLM-Aligning-Point-Cloud-with-Multi-modality-for-3D-Understanding-Generation-and-Instruction-Following"><a href="#Point-Bind-Point-LLM-Aligning-Point-Cloud-with-Multi-modality-for-3D-Understanding-Generation-and-Instruction-Following" class="headerlink" title="Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following"></a>Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00615">http://arxiv.org/abs/2309.00615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ziyuguo99/point-bind_point-llm">https://github.com/ziyuguo99/point-bind_point-llm</a></li>
<li>paper_authors: Ziyu Guo, Renrui Zhang, Xiangyang Zhu, Yiwen Tang, Xianzheng Ma, Jiaming Han, Kexin Chen, Peng Gao, Xianzhi Li, Hongsheng Li, Pheng-Ann Heng</li>
<li>for: 这个论文旨在将3D点云与多媒体数据（图像、语音、视频）相互对应，以便实现多种应用程序，如任意到3D生成、3D嵌入数学和3D开放世界理解。</li>
<li>methods:  authors propose Point-Bind，一种3D多媒体模型，通过ImageBind建立3D和多媒体之间的共同嵌入空间，并提出Point-LLM，一种基于3D多媒体指令的首个大语言模型。</li>
<li>results: authors fine-tune pre-trained LLMs with Point-Bind’s semantics, achieving superior 3D and multi-modal question-answering performance without requiring 3D instruction data.<details>
<summary>Abstract</summary>
We introduce Point-Bind, a 3D multi-modality model aligning point clouds with 2D image, language, audio, and video. Guided by ImageBind, we construct a joint embedding space between 3D and multi-modalities, enabling many promising applications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D open-world understanding. On top of this, we further present Point-LLM, the first 3D large language model (LLM) following 3D multi-modal instructions. By parameter-efficient fine-tuning techniques, Point-LLM injects the semantics of Point-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction data, but exhibits superior 3D and multi-modal question-answering capacity. We hope our work may cast a light on the community for extending 3D point clouds to multi-modality applications. Code is available at https://github.com/ZiyuGuo99/Point-Bind_Point-LLM.
</details>
<details>
<summary>摘要</summary>
我们介绍Point-Bind，一个3D多Modal模型，可以与2D图像、语音、影音等多种多Modalities进行对齐。受ImageBind的引导，我们建立了3D和多Modalities之间的共同嵌入空间，使得许多应用程序可能实现，例如任何到3D生成、3D嵌入加法和3D开放世界理解。此外，我们还呈发Point-LLM，首个遵循3D多Modal instructions的3D大语言模型。通过实现优化技术，Point-LLM可以将Point-Bind的 semantics 注入到先天训练的LLMs中，例如LLaMA，这些模型不需要3D instruction data，但可以实现3D和多Modal question-answering的高水平表现。我们希望我们的工作能够照亮社区，将3D点云扩展到多Modal应用程序。代码可以在https://github.com/ZiyuGuo99/Point-Bind_Point-LLM中找到。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Multi-granular-Image-Editing-using-Diffusion-Models"><a href="#Iterative-Multi-granular-Image-Editing-using-Diffusion-Models" class="headerlink" title="Iterative Multi-granular Image Editing using Diffusion Models"></a>Iterative Multi-granular Image Editing using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00613">http://arxiv.org/abs/2309.00613</a></li>
<li>repo_url: None</li>
<li>paper_authors: K J Joseph, Prateksha Udhayanan, Tripti Shukla, Aishwarya Agarwal, Srikrishna Karanam, Koustava Goswami, Balaji Vasan Srinivasan</li>
<li>for: 这个论文旨在支持创意专业人员生成艺术性和趣味性的视觉资产，以及Iterative Multi-granular Editing的过程。</li>
<li>methods: 该论文提出了一种基于扩散模型的Iterative Multi-granular Image Editor（EMILIE），它可以在图像生成和修改过程中进行迭代编辑，并且可以控制图像的空间范围（全球、本地或者任何位置）。</li>
<li>results: 该论文通过对比与现有的方法进行评估，表明EMILIE可以更好地支持创意专业人员的艺术创作，并且可以提供更多的控制选项。<details>
<summary>Abstract</summary>
Recent advances in text-guided image synthesis has dramatically changed how creative professionals generate artistic and aesthetically pleasing visual assets. To fully support such creative endeavors, the process should possess the ability to: 1) iteratively edit the generations and 2) control the spatial reach of desired changes (global, local or anything in between). We formalize this pragmatic problem setting as Iterative Multi-granular Editing. While there has been substantial progress with diffusion-based models for image synthesis and editing, they are all one shot (i.e., no iterative editing capabilities) and do not naturally yield multi-granular control (i.e., covering the full spectrum of local-to-global edits). To overcome these drawbacks, we propose EMILIE: Iterative Multi-granular Image Editor. EMILIE introduces a novel latent iteration strategy, which re-purposes a pre-trained diffusion model to facilitate iterative editing. This is complemented by a gradient control operation for multi-granular control. We introduce a new benchmark dataset to evaluate our newly proposed setting. We conduct exhaustive quantitatively and qualitatively evaluation against recent state-of-the-art approaches adapted to our task, to being out the mettle of EMILIE. We hope our work would attract attention to this newly identified, pragmatic problem setting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Curating-Naturally-Adversarial-Datasets-for-Trustworthy-AI-in-Healthcare"><a href="#Curating-Naturally-Adversarial-Datasets-for-Trustworthy-AI-in-Healthcare" class="headerlink" title="Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare"></a>Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00543">http://arxiv.org/abs/2309.00543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sydney Pugh, Ivan Ruchkin, Insup Lee, James Weimer</li>
<li>for: 本研究旨在提高深度学习模型对时间序列医疗应用中的预测精度，同时确保这些模型的可靠性和信任性。</li>
<li>methods: 本研究提出了一种使用自动生成的弱监督标签 combines 噪音和便宜获得的标签规则，以生成自然的对抗示例集，用于评估模型的可靠性。</li>
<li>results: 本研究在 six 个医学案例和三个非医学案例中，通过对输入数据进行随机排序，并使用这种排序构建一系列逐渐增强的对抗示例集，证明了该方法的可靠性和统计效果。<details>
<summary>Abstract</summary>
Deep learning models have shown promising predictive accuracy for time-series healthcare applications. However, ensuring the robustness of these models is vital for building trustworthy AI systems. Existing research predominantly focuses on robustness to synthetic adversarial examples, crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against naturally occurring adversarial examples, which is highly desirable for trustworthy AI. We propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. The method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. Based on these labels, our method adversarially orders the input data and uses this ordering to construct a sequence of increasingly adversarial datasets. Our evaluation on six medical case studies and three non-medical case studies demonstrates the efficacy and statistical validity of our approach to generating naturally adversarial datasets
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. Our method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. We use these labels to adversarially order the input data and construct a sequence of increasingly adversarial datasets.Our evaluation on six medical case studies and three non-medical case studies demonstrates the effectiveness and statistical validity of our approach to generating naturally adversarial datasets. By using these datasets to evaluate model robustness, we can better ensure that AI systems are trustworthy and reliable in real-world scenarios.
</details></li>
</ul>
<hr>
<h2 id="ICDARTS-Improving-the-Stability-and-Performance-of-Cyclic-DARTS"><a href="#ICDARTS-Improving-the-Stability-and-Performance-of-Cyclic-DARTS" class="headerlink" title="ICDARTS: Improving the Stability and Performance of Cyclic DARTS"></a>ICDARTS: Improving the Stability and Performance of Cyclic DARTS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00664">http://arxiv.org/abs/2309.00664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emily Herron, Derek Rose, Steven Young</li>
<li>for: 提高循环DARTS的稳定性和通用性</li>
<li>methods: 改进CDARTS的训练协议，消除搜索网络和评估网络之间的依赖关系，并对搜索网络中的零操作进行修饰</li>
<li>results: 实现了提高网络通用性和实现了一种新的动态搜索空间 incorporation 方法，并进行了灵活搜索细致的扩展<details>
<summary>Abstract</summary>
This work introduces improvements to the stability and generalizability of Cyclic DARTS (CDARTS). CDARTS is a Differentiable Architecture Search (DARTS)-based approach to neural architecture search (NAS) that uses a cyclic feedback mechanism to train search and evaluation networks concurrently. This training protocol aims to optimize the search process by enforcing that the search and evaluation networks produce similar outputs. However, CDARTS introduces a loss function for the evaluation network that is dependent on the search network. The dissimilarity between the loss functions used by the evaluation networks during the search and retraining phases results in a search-phase evaluation network that is a sub-optimal proxy for the final evaluation network that is utilized during retraining. We present ICDARTS, a revised approach that eliminates the dependency of the evaluation network weights upon those of the search network, along with a modified process for discretizing the search network's \textit{zero} operations that allows these operations to be retained in the final evaluation networks. We pair the results of these changes with ablation studies on ICDARTS' algorithm and network template. Finally, we explore methods for expanding the search space of ICDARTS by expanding its operation set and exploring alternate methods for discretizing its continuous search cells. These experiments resulted in networks with improved generalizability and the implementation of a novel method for incorporating a dynamic search space into ICDARTS.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这个工作介绍了对循环DARTS（CDARTS）的改进，以提高其稳定性和通用性。CDARTS是基于演算 Architecture Search（DARTS）的神经网络搜索方法，使用循环反馈机制来同时训练搜索和评估网络。这种训练协议的目的是通过确保搜索和评估网络生成相似的输出来优化搜索过程。然而，CDARTS引入了评估网络的损失函数，这使得搜索阶段的评估网络成为一个临时性差的代理人。我们提出了ICDARTS，一种修改后的方法，该方法消除了搜索网络的依赖关系，并对搜索网络中的\textit{zero} 操作进行修正。我们还进行了ICDARTS算法和网络模板的ablation study。最后，我们探索了扩展ICDARTS搜索空间的方法，包括扩展其操作集和使用不同的抽象方法来抽象它的连续搜索细胞。这些实验导致了改进的通用性和一种新的方法来将动态搜索空间 incorporated 到ICDARTS中。
</details></li>
</ul>
<hr>
<h2 id="Learning-based-NLOS-Detection-and-Uncertainty-Prediction-of-GNSS-Observations-with-Transformer-Enhanced-LSTM-Network"><a href="#Learning-based-NLOS-Detection-and-Uncertainty-Prediction-of-GNSS-Observations-with-Transformer-Enhanced-LSTM-Network" class="headerlink" title="Learning-based NLOS Detection and Uncertainty Prediction of GNSS Observations with Transformer-Enhanced LSTM Network"></a>Learning-based NLOS Detection and Uncertainty Prediction of GNSS Observations with Transformer-Enhanced LSTM Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00480">http://arxiv.org/abs/2309.00480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rwth-irt/deepnlosdetection">https://github.com/rwth-irt/deepnlosdetection</a></li>
<li>paper_authors: Haoming Zhang, Zhanxin Wang, Heike Vallery</li>
<li>for: 这个研究旨在提高运输系统中GNSS的准确性和一致性，减少GNSS观测受到多路径和非线路径（NLOS）影响的情况下，传统方法可能无法正确地分类和排除错误GNSS观测，导致系统状态估计和运输安全性问题。</li>
<li>methods: 这个研究提出了一个基于深度学习的方法，通过分析GNSS观测为空间时间模型问题，探索NLOS观测和 Pseudorange 误差的预测方法。相比之前的研究，我们将 transformer-like 注意力机制整合到深度学习网络中，提高模型性能和普遍性。</li>
<li>results: 实验研究显示，我们的网络在训练和评估过程中比其他深度学习模型和传统机器学习模型更好，并且在实际应用中避免了车辆地图分布不均的问题。此外，我们还进行了网络 ком成分析和与数据外泛统计分析，以及与其他模型的比较。<details>
<summary>Abstract</summary>
The global navigation satellite systems (GNSS) play a vital role in transport systems for accurate and consistent vehicle localization. However, GNSS observations can be distorted due to multipath effects and non-line-of-sight (NLOS) receptions in challenging environments such as urban canyons. In such cases, traditional methods to classify and exclude faulty GNSS observations may fail, leading to unreliable state estimation and unsafe system operations. This work proposes a Deep-Learning-based method to detect NLOS receptions and predict GNSS pseudorange errors by analyzing GNSS observations as a spatio-temporal modeling problem. Compared to previous works, we construct a transformer-like attention mechanism to enhance the long short-term memory (LSTM) networks, improving model performance and generalization. For the training and evaluation of the proposed network, we used labeled datasets from the cities of Hong Kong and Aachen. We also introduce a dataset generation process to label the GNSS observations using lidar maps. In experimental studies, we compare the proposed network with a deep-learning-based model and classical machine-learning models. Furthermore, we conduct ablation studies of our network components and integrate the NLOS detection with data out-of-distribution in a state estimator. As a result, our network presents improved precision and recall ratios compared to other models. Additionally, we show that the proposed method avoids trajectory divergence in real-world vehicle localization by classifying and excluding NLOS observations.
</details>
<details>
<summary>摘要</summary>
全球导航卫星系统（GNSS）在交通系统中扮演着重要的角色，对于精确和一致的车辆位置Localization提供了重要的帮助。然而，GNSS观测可能会受到多路径效应和非直线视野（NLOS）接收的干扰，特别是在城市的“峡谷”环境中。在这种情况下，传统的方法可能无法正确地分类和排除 faulty GNSS观测，导致系统的状态估计和运行不安全。本工作提出了一个基于深度学习的方法，通过分析 GNSS 观测为空间时间模型的问题，探测NLOS接收和预测 GNSS  Pseudorange 误差。相比于前一代的工作，我们将 transformer-like 注意力机制搭配长期记忆类型的LSTM 网络，提高模型的性能和通用性。我们使用了香港和阿希的城市 Labelled 数据集进行训练和评估。此外，我们还介绍了一个标签GNSS 观测的方法，使用 lidar 地图。在实验研究中，我们与其他深度学习模型和传统机器学习模型进行比较。此外，我们还进行了我们网络的组件删除和与数据外部分布的整合。最终，我们的网络获得了提高的精确性和回应率，并且显示了在实际车辆Localization中避免了轨迹分支的问题。
</details></li>
</ul>
<hr>
<h2 id="A-Theoretical-and-Practical-Framework-for-Evaluating-Uncertainty-Calibration-in-Object-Detection"><a href="#A-Theoretical-and-Practical-Framework-for-Evaluating-Uncertainty-Calibration-in-Object-Detection" class="headerlink" title="A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection"></a>A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00464">http://arxiv.org/abs/2309.00464</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pedrormconde/uncertainty_calibration_object_detection">https://github.com/pedrormconde/uncertainty_calibration_object_detection</a></li>
<li>paper_authors: Pedro Conde, Rui L. Lopes, Cristiano Premebida</li>
<li>for: 本研究旨在提出一个新的假设和实践框架，用于评估深度神经网络中的物体探测系统，并评估这些系统的不确定性调整。</li>
<li>methods: 本研究使用了一系列的实验和分析方法，包括实验设计、资料分析和模型评估，以评估不确定性调整的效果。</li>
<li>results: 研究结果显示，提出的不确定性调整度量具有良好的准确性和稳定性，并且可以帮助改善物体探测系统的可靠性和安全性。Here is the same information in English:</li>
<li>for: The purpose of this study is to propose a new theoretical and practical framework for evaluating object detection systems in the context of uncertainty calibration.</li>
<li>methods: The study uses a series of experimental and analytical methods, including experimental design, data analysis, and model evaluation, to assess the effectiveness of the proposed uncertainty calibration metrics.</li>
<li>results: The results show that the proposed uncertainty calibration metrics have good accuracy and stability, and can help improve the reliability and safety of object detection systems.<details>
<summary>Abstract</summary>
The proliferation of Deep Neural Networks has resulted in machine learning systems becoming increasingly more present in various real-world applications. Consequently, there is a growing demand for highly reliable models in these domains, making the problem of uncertainty calibration pivotal, when considering the future of deep learning. This is especially true when considering object detection systems, that are commonly present in safety-critical application such as autonomous driving and robotics. For this reason, this work presents a novel theoretical and practical framework to evaluate object detection systems in the context of uncertainty calibration. The robustness of the proposed uncertainty calibration metrics is shown through a series of representative experiments. Code for the proposed uncertainty calibration metrics at: https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection.
</details>
<details>
<summary>摘要</summary>
深度神经网络的普及导致机器学习系统在实际应用中变得越来越普遍。因此，高可靠性模型在这些领域的需求在增加。特别是在自动驾驶和机器人等安全关键应用中，Object detection系统的uncertainty calibration问题变得越来越重要。为此，这个研究提出了一种新的理论和实践框架，用于评估Object detection系统的uncertainty calibration。这种uncertainty calibration度量的稳定性通过一系列代表性的实验展示。Code可以在https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection中找到。
</details></li>
</ul>
<hr>
<h2 id="New-metrics-for-analyzing-continual-learners"><a href="#New-metrics-for-analyzing-continual-learners" class="headerlink" title="New metrics for analyzing continual learners"></a>New metrics for analyzing continual learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00462">http://arxiv.org/abs/2309.00462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Michel, Giovanni Chierchia, Romain Negrel, Jean-François Bercher, Toshihiko Yamasaki</li>
<li>for:  continual learning 学习环境中维护知识和学习新任务的稳定性和柔软性。</li>
<li>methods: 使用现有的措施来衡量稳定性和柔软性，并发现现有的指标忽略了任务增加难度的问题。因此，我们提出了新的指标来考虑任务增加难度。</li>
<li>results: 通过在标准 bencmark 数据集上进行实验，我们表明了我们提出的新指标可以为 continual learning 环境中模型的稳定性-柔软性质量提供新的视角。<details>
<summary>Abstract</summary>
Deep neural networks have shown remarkable performance when trained on independent and identically distributed data from a fixed set of classes. However, in real-world scenarios, it can be desirable to train models on a continuous stream of data where multiple classification tasks are presented sequentially. This scenario, known as Continual Learning (CL) poses challenges to standard learning algorithms which struggle to maintain knowledge of old tasks while learning new ones. This stability-plasticity dilemma remains central to CL and multiple metrics have been proposed to adequately measure stability and plasticity separately. However, none considers the increasing difficulty of the classification task, which inherently results in performance loss for any model. In that sense, we analyze some limitations of current metrics and identify the presence of setup-induced forgetting. Therefore, we propose new metrics that account for the task's increasing difficulty. Through experiments on benchmark datasets, we demonstrate that our proposed metrics can provide new insights into the stability-plasticity trade-off achieved by models in the continual learning environment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Establishing-Markov-Equivalence-in-Cyclic-Directed-Graphs"><a href="#Establishing-Markov-Equivalence-in-Cyclic-Directed-Graphs" class="headerlink" title="Establishing Markov Equivalence in Cyclic Directed Graphs"></a>Establishing Markov Equivalence in Cyclic Directed Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03092">http://arxiv.org/abs/2309.03092</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tomc-ghub/CET_uai2023">https://github.com/tomc-ghub/CET_uai2023</a></li>
<li>paper_authors: Tom Claassen, Joris M. Mooij</li>
<li>for:  establishment of Markov equivalence between directed graphs</li>
<li>methods:  based on Cyclic Equivalence Theorem (CET) and ancestral perspective</li>
<li>results:  significantly reduced algorithmic complexity and conceptually simplified characterization, which may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders.<details>
<summary>Abstract</summary>
We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles under the \textit{d}-separation criterion. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid '90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires tests for d-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders. This version includes a correction to rule (iv) in Theorem 1, and the subsequent adjustment in part 2 of Algorithm 2.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的、高效的程序，用于在导航图中确定Markov等价关系，这些图可能或可能不含循环，基于\textit{d}-分离 критериion。这种方法基于托马斯·理查森在90年代中期的著名作品中的循环等价定理（CET），但现在从先祖 perspective重新表述。这种Characterization导致了一种不需要测试\textit{d}-分离的程序，从而大幅降低了算法复杂性。这种概念简化后的Characterization可能会促进理论研究，以探索在潜在干扰因素存在下的循环发现的正确和完整的方法。这个版本包括对第一个定理（iv）的更正，以及后续的修改在算法2的第2部分。
</details></li>
</ul>
<hr>
<h2 id="No-Train-Still-Gain-Unleash-Mathematical-Reasoning-of-Large-Language-Models-with-Monte-Carlo-Tree-Search-Guided-by-Energy-Function"><a href="#No-Train-Still-Gain-Unleash-Mathematical-Reasoning-of-Large-Language-Models-with-Monte-Carlo-Tree-Search-Guided-by-Energy-Function" class="headerlink" title="No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function"></a>No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03224">http://arxiv.org/abs/2309.03224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Xu</li>
<li>for: 提高大型自然语言处理（NLP）模型的数学逻辑能力，无需额外 Fine-tuning 步骤。</li>
<li>methods: 使用 Monte Carlo Tree Search（MCTS）和轻量级能量函数来评估决策步骤，并使用噪声对比估计来估计能量函数的参数。</li>
<li>results: 通过对 GSM8k 和 AQUA-RAT 数学逻辑测试 benchmark 进行广泛的实验，显示了方法的杰出表现，无需额外 Fine-tuning 或人工反馈对适应。<details>
<summary>Abstract</summary>
Large language models (LLMs) demonstrate impressive language understanding and contextual learning abilities, making them suitable for natural language processing (NLP) tasks and complex mathematical reasoning. However, when applied to mathematical reasoning tasks, LLMs often struggle to generate correct reasoning steps and answers despite having high probabilities for the solutions. To overcome this limitation and enhance the mathematical reasoning capabilities of fine-tuned LLMs without additional fine-tuning steps, we propose a method that incorporates Monte Carlo Tree Search (MCTS) and a lightweight energy function to rank decision steps and enable immediate reaction and precise reasoning. Specifically, we re-formulate the fine-tuned LLMs into a Residual-based Energy Model (Residual-EBM) and employ noise contrastive estimation to estimate the energy function's parameters. We then utilize MCTS with the energy function as a path verifier to search the output space and evaluate the reasoning path. Through extensive experiments on two mathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the exceptional capabilities of our method, which significantly improves the pass@1 metric of the fine-tuned model without requiring additional fine-tuning or reinforcement learning with human feedback alignment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Speech-Representation-From-Contrastive-Token-Acoustic-Pretraining"><a href="#Learning-Speech-Representation-From-Contrastive-Token-Acoustic-Pretraining" class="headerlink" title="Learning Speech Representation From Contrastive Token-Acoustic Pretraining"></a>Learning Speech Representation From Contrastive Token-Acoustic Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00424">http://arxiv.org/abs/2309.00424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyu Qiang, Hao Li, Yixin Tian, Ruibo Fu, Tao Wang, Longbiao Wang, Jianwu Dang</li>
<li>for: 提高 speech 生成和识别下的细腻性，例如 minimally-supervised text-to-speech (TTS)、voice conversion (VC) 和 automatic speech recognition (ASR)。</li>
<li>methods: 使用 two encoders 将 phoneme 和 speech 带入一个共同的多Modal 空间，学习连接 phoneme 和 speech 的框架级别连接。</li>
<li>results: 在 210k 个 speech 和 phoneme 文本对中训练 CTAP 模型，实现了 minimally-supervised TTS、VC 和 ASR 等下游任务。<details>
<summary>Abstract</summary>
For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representations extracted from speech should serve as a "bridge" between text and acoustic information, containing information from both modalities. The semantic content is emphasized, while the paralinguistic information such as speaker identity and acoustic details should be de-emphasized. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Contrastive learning is a good method for modeling intermediate representations from two modalities. However, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named "Contrastive Token-Acoustic Pretraining (CTAP)", which uses two encoders to bring phoneme and speech into a joint multimodal space, learning how to connect phoneme and speech at the frame level. The CTAP model is trained on 210k speech and phoneme text pairs, achieving minimally-supervised TTS, VC, and ASR. The proposed CTAP method offers a promising solution for fine-grained generation and recognition downstream tasks in speech processing.
</details>
<details>
<summary>摘要</summary>
为细化生成和识别任务，如无监督文本译 speech（TTS）、voice conversion（VC）和自动语音识别（ASR），则中间表示从语音中提取的应该作为两个模态之间的“桥”，含有文本和音频信息的信息。 semantic content 应该强调，而 speaker identity 和 acoustic details 则应该削弱。然而，现有的语音中间表示提取方法受到过 redundancy 和维度爆炸 的问题。 Contrastive learning 是一种好的方法 для模型中间表示，但现有的音频领域的 Contrastive learning 方法是为下游音频分类任务提取全局描述性信息，这使得它们不适用于 TTS、VC 和 ASR 任务。为解决这些问题，我们提出了一种方法，名为“ Contrastive Token-Acoustic Pretraining”（CTAP），它使用两个Encoder将 phoneme 和 speech 带入到一个共同多Modal空间，学习如何在帧级连接 phoneme 和 speech。 CTAP 模型在 210k 语音和 phoneme 文本对中训练，实现了无监督 TTS、VC 和 ASR。我们提出的 CTAP 方法为 fine-grained generation 和识别下游任务提供了一个有前途的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Declarative-Reasoning-on-Explanations-Using-Constraint-Logic-Programming"><a href="#Declarative-Reasoning-on-Explanations-Using-Constraint-Logic-Programming" class="headerlink" title="Declarative Reasoning on Explanations Using Constraint Logic Programming"></a>Declarative Reasoning on Explanations Using Constraint Logic Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00422">http://arxiv.org/abs/2309.00422</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lstate/reasonx">https://github.com/lstate/reasonx</a></li>
<li>paper_authors: Laura State, Salvatore Ruggieri, Franco Turini</li>
<li>For: 提供对透明化机器学习模型的解释，即现有的AI解释方法存在许多缺点，如背景知识不够 incorporation、解释方法不够抽象和用户交互不够。* Methods: 使用 Constraint Logic Programming (CLP) 提供声明性的、交互式的解释方法，可以用于对决策树进行解释，以及对任何黑盒模型的全局&#x2F;本地代理模型进行解释。* Results: 提供了 REASONX 解释方法的架构，包括 Python 层和 CLP 层，核心执行引擎是一个基于 Prolog 的 meta-程序，具有声明性的逻辑理论 semantics。<details>
<summary>Abstract</summary>
Explaining opaque Machine Learning (ML) models is an increasingly relevant problem. Current explanation in AI (XAI) methods suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of abstraction and interactivity with the user. We propose REASONX, an explanation method based on Constraint Logic Programming (CLP). REASONX can provide declarative, interactive explanations for decision trees, which can be the ML models under analysis or global/local surrogate models of any black-box model. Users can express background or common sense knowledge using linear constraints and MILP optimization over features of factual and contrastive instances, and interact with the answer constraints at different levels of abstraction through constraint projection. We present here the architecture of REASONX, which consists of a Python layer, closer to the user, and a CLP layer. REASONX's core execution engine is a Prolog meta-program with declarative semantics in terms of logic theories.
</details>
<details>
<summary>摘要</summary>
explainable machine learning (ml) models 是一个日益重要的问题。当前的 AI (XAI) 方法存在多个缺点，包括知识背景的不充分 integrate 和用户交互的缺失。我们提议了 REASONX，一种基于幂逻Programming (CLP) 的解释方法。REASONX 可以为决策树提供声明性的、交互式的解释，这些决策树可以是分析或全局/本地的黑盒模型。用户可以通过Linear Constraints 和 MILP 优化来表达背景知识或通用常识，并通过约束投影在不同层次进行交互。我们在这里介绍了 REASONX 的架构，它由 Python 层和 CLP 层组成。REASONX 的核心执行引擎是一个 Prolog 元程序，其semantics 是逻辑理论的声明性。
</details></li>
</ul>
<hr>
<h2 id="Area-norm-COBRA-on-Conditional-Survival-Prediction"><a href="#Area-norm-COBRA-on-Conditional-Survival-Prediction" class="headerlink" title="Area-norm COBRA on Conditional Survival Prediction"></a>Area-norm COBRA on Conditional Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00417">http://arxiv.org/abs/2309.00417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Goswami, Arabin Kr. Dey</li>
<li>for: 这篇论文探讨了一种新的 combinational regression 策略，用于计算condition survival function。</li>
<li>methods: 该策略使用回归基于weak learner的ensemble技术，并使用距离度量作为两个生存曲线之间的区域。</li>
<li>results: 该模型比Random Survival Forest表现更好，并提供了一种选择最重要变量的新技术。 simulation study 表明该方法能够很好地确定变量的重要性。<details>
<summary>Abstract</summary>
The paper explores a different variation of combined regression strategy to calculate the conditional survival function. We use regression based weak learners to create the proposed ensemble technique. The proposed combined regression strategy uses proximity measure as area between two survival curves. The proposed model shows a construction which ensures that it performs better than the Random Survival Forest. The paper discusses a novel technique to select the most important variable in the combined regression setup. We perform a simulation study to show that our proposition for finding relevance of the variables works quite well. We also use three real-life datasets to illustrate the model.
</details>
<details>
<summary>摘要</summary>
文章探讨了一种不同的combined regression策略来计算 conditional survival function。我们使用回归基于弱学习器的 ensemble技术来实现提案。提案的combined regression策略使用距离度量来度量两个生存曲线之间的区域。提案的模型能确保其在Random Survival Forest之上表现更好。文章介绍了一种新的方法来在combined regression中选择最重要的变量。我们通过实验研究表明我们的提案可以很好地确定变量的相关性。我们还使用了三个真实数据集来示例化模型。Here's the word-for-word translation:文章探讨了一种不同的combined regression策略来计算 conditional survival function。我们使用回归基于弱学习器的 ensemble技术来实现提案。提案的combined regression策略使用距离度量来度量两个生存曲线之间的区域。提案的模型能确保其在Random Survival Forest之上表现更好。文章介绍了一种新的方法来在combined regression中选择最重要的变量。我们通过实验研究表明我们的提案可以很好地确定变量的相关性。我们还使用了三个真实数据集来示例化模型。
</details></li>
</ul>
<hr>
<h2 id="Dense-Voxel-3D-Reconstruction-Using-a-Monocular-Event-Camera"><a href="#Dense-Voxel-3D-Reconstruction-Using-a-Monocular-Event-Camera" class="headerlink" title="Dense Voxel 3D Reconstruction Using a Monocular Event Camera"></a>Dense Voxel 3D Reconstruction Using a Monocular Event Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00385">http://arxiv.org/abs/2309.00385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haodong Chen, Vera Chung, Li Tan, Xiaoming Chen</li>
<li>For: 这个论文主要用于探讨使用单个事件摄像机实现高精度3D重建，以便在虚拟现实应用中使用。* Methods: 该论文提出了一种新的方法，使用单个事件摄像机来生成高精度3D重建。这种方法不需要多个摄像机，也不需要与其他方法组合使用。* Results: 据作者的预liminary结果表明，该方法可以直接生成可辨别的高精度3D重建结果，无需创建如先前方法一样的管道。此外，作者还创建了一个 Synthetic dataset，包含39739个对象扫描结果，这个dataset可以帮助加速相关领域的研究。<details>
<summary>Abstract</summary>
Event cameras are sensors inspired by biological systems that specialize in capturing changes in brightness. These emerging cameras offer many advantages over conventional frame-based cameras, including high dynamic range, high frame rates, and extremely low power consumption. Due to these advantages, event cameras have increasingly been adapted in various fields, such as frame interpolation, semantic segmentation, odometry, and SLAM. However, their application in 3D reconstruction for VR applications is underexplored. Previous methods in this field mainly focused on 3D reconstruction through depth map estimation. Methods that produce dense 3D reconstruction generally require multiple cameras, while methods that utilize a single event camera can only produce a semi-dense result. Other single-camera methods that can produce dense 3D reconstruction rely on creating a pipeline that either incorporates the aforementioned methods or other existing Structure from Motion (SfM) or Multi-view Stereo (MVS) methods. In this paper, we propose a novel approach for solving dense 3D reconstruction using only a single event camera. To the best of our knowledge, our work is the first attempt in this regard. Our preliminary results demonstrate that the proposed method can produce visually distinguishable dense 3D reconstructions directly without requiring pipelines like those used by existing methods. Additionally, we have created a synthetic dataset with $39,739$ object scans using an event camera simulator. This dataset will help accelerate other relevant research in this field.
</details>
<details>
<summary>摘要</summary>
Event 摄像机是基于生物系统的感知器，专门用于测量光度变化。这些新型摄像机具有较高的动态范围、快速帧率和非常低的功耗消耗。由于这些优点，event 摄像机在不同领域得到了广泛应用，如 frame interpolation、semantic segmentation、odometry 和 SLAM。然而，它们在虚拟现实应用中的3D重建仍然受到了不足的研究。先前的方法主要通过depth map estimation来实现3D重建。这些方法通常需要多个摄像机，而使用单个 event 摄像机可以生成半密集的结果。其他使用单个摄像机实现密集3D重建的方法通常需要创建一个管道，该管道可以包括以上方法或其他现有的Structure from Motion（SfM）或Multi-view Stereo（MVS）方法。在这篇论文中，我们提出了一种新的方法，用于使用单个 event 摄像机实现密集3D重建。我们认为，这是首次尝试。我们的初步结果表明，我们的方法可以直接生成可辨识的密集3D重建，无需创建管道类似于现有方法。此外，我们创建了一个Synthetic dataset，包含39739个物体扫描结果，使用事件摄像机模拟器。这个数据集将会促进相关的研究。
</details></li>
</ul>
<hr>
<h2 id="Scenario-based-model-predictive-control-of-water-reservoir-systems"><a href="#Scenario-based-model-predictive-control-of-water-reservoir-systems" class="headerlink" title="Scenario-based model predictive control of water reservoir systems"></a>Scenario-based model predictive control of water reservoir systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00373">http://arxiv.org/abs/2309.00373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raffaele Giuseppe Cestari, Andrea Castelletti, Simone Formentin</li>
<li>for:  optimize the operation of water reservoir systems in the presence of highly uncertain inflows</li>
<li>methods:  stochastic MPC approach using plausible future inflows directly generated from past data</li>
<li>results:  more cautious control that counteracts droughty periods while satisfying agricultural water demand, validated through extensive Monte Carlo tests using actual inflow data from Lake Como, Italy.Here’s the Chinese translation of the three points:</li>
<li>for:  optimizes 水库系统的运行，面临高度不确定的流入</li>
<li>methods: 使用可能性分布来生成直接来自过去数据的未来流入，以实现随机MPC策略</li>
<li>results: 更谨慎的控制，能够避免干旱期（例如湖水水平下降到干旱限制），同时保证农业水需求的满足，通过实际各个流入数据进行了 Monte Carlo 测试。<details>
<summary>Abstract</summary>
The optimal operation of water reservoir systems is a challenging task involving multiple conflicting objectives. The main source of complexity is the presence of the water inflow, which acts as an exogenous, highly uncertain disturbance on the system. When model predictive control (MPC) is employed, the optimal water release is usually computed based on the (predicted) trajectory of the inflow. This choice may jeopardize the closed-loop performance when the actual inflow differs from its forecast. In this work, we consider - for the first time - a stochastic MPC approach for water reservoirs, in which the control is optimized based on a set of plausible future inflows directly generated from past data. Such a scenario-based MPC strategy allows the controller to be more cautious, counteracting droughty periods (e.g., the lake level going below the dry limit) while at the same time guaranteeing that the agricultural water demand is satisfied. The method's effectiveness is validated through extensive Monte Carlo tests using actual inflow data from Lake Como, Italy.
</details>
<details>
<summary>摘要</summary>
水库系统的优化操作是一项复杂的任务，涉及多个 conflicting 目标。主要的复杂性来源于流水入库，它会对系统作为外生、高度不确定的干扰。当使用模型预测控制（MPC）时，通常基于预测流水入库轨迹来计算优化的水release。这可能会在实际入库与预测入库不同时影响closed-loop性。在这种工作中，我们对水库系统进行了第一次 Stochastic MPC 方法，在这种方法中，控制器是基于过去数据直接生成的可能性 Distribution 来优化控制。这种enario-based MPC策略使得控制器更加谨慎，可以避免干旱期间（例如湖水水位低于干旱限制）的问题，同时保证农业用水需求得到满足。我们通过使用意大湖 Como, 意大的实际入库数据进行了广泛的 Monte Carlo 测试，证明了该方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Discrete-Versus-Continuous-Algorithms-in-Dynamics-of-Affective-Decision-Making"><a href="#Discrete-Versus-Continuous-Algorithms-in-Dynamics-of-Affective-Decision-Making" class="headerlink" title="Discrete Versus Continuous Algorithms in Dynamics of Affective Decision Making"></a>Discrete Versus Continuous Algorithms in Dynamics of Affective Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00357">http://arxiv.org/abs/2309.00357</a></li>
<li>repo_url: None</li>
<li>paper_authors: V. I. Yukalov, E. P. Yukalova<br>for: 这 paper 是研究智能网络中代理人的决策行为，以及不同类型的内存（长期和短期内存）对决策的影响。methods: 这 paper 使用概率情感决策理论，考虑了选择方案的理性利好和情感吸引力。results: 研究发现，由于网络参数的不同，可能存在较Close或较大差异的特征概率行为，这意味着使用不同的算法可能会导致非常不同的理论预测，从而无法Uniquely describe practical problems。<details>
<summary>Abstract</summary>
The dynamics of affective decision making is considered for an intelligent network composed of agents with different types of memory: long-term and short-term memory. The consideration is based on probabilistic affective decision theory, which takes into account the rational utility of alternatives as well as the emotional alternative attractiveness. The objective of this paper is the comparison of two multistep operational algorithms of the intelligent network: one based on discrete dynamics and the other on continuous dynamics. By means of numerical analysis, it is shown that, depending on the network parameters, the characteristic probabilities for continuous and discrete operations can exhibit either close or drastically different behavior. Thus, depending on which algorithm is employed, either discrete or continuous, theoretical predictions can be rather different, which does not allow for a uniquely defined description of practical problems. This finding is important for understanding which of the algorithms is more appropriate for the correct analysis of decision-making tasks. A discussion is given, revealing that the discrete operation seems to be more realistic for describing intelligent networks as well as affective artificial intelligence.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "The dynamics of affective decision making is considered for an intelligent network composed of agents with different types of memory: long-term and short-term memory. The consideration is based on probabilistic affective decision theory, which takes into account the rational utility of alternatives as well as the emotional alternative attractiveness. The objective of this paper is the comparison of two multistep operational algorithms of the intelligent network: one based on discrete dynamics and the other on continuous dynamics. By means of numerical analysis, it is shown that, depending on the network parameters, the characteristic probabilities for continuous and discrete operations can exhibit either close or drastically different behavior. Thus, depending on which algorithm is employed, either discrete or continuous, theoretical predictions can be rather different, which does not allow for a uniquely defined description of practical problems. This finding is important for understanding which of the algorithms is more appropriate for the correct analysis of decision-making tasks. A discussion is given, revealing that the discrete operation seems to be more realistic for describing intelligent networks as well as affective artificial intelligence."Translation:<<SYS>>affective决策动力学在智能网络中被考虑，智能网络由不同类型的记忆 agent组成：长期记忆和短期记忆。考虑基于概率性的情感决策理论，该理论考虑了决策选项的合理利益以及决策选项的情感吸引力。本文的目标是比较两种多步操作算法：一种基于离散动力学，另一种基于连续动力学。通过数值分析，我们发现，具有不同网络参数时，离散和连续操作的特征概率可能会展现出非常不同的行为。因此，使用不同的算法，对于实际问题的理论预测可能会非常不同，这不允许固定的描述实际问题。这一发现对于理解哪种算法更适合正确分析决策任务非常重要。文章还进行了讨论，表明离散操作更加真实地描述智能网络以及情感人工智能。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Active-Learning-for-Preference-Elicitation"><a href="#Explainable-Active-Learning-for-Preference-Elicitation" class="headerlink" title="Explainable Active Learning for Preference Elicitation"></a>Explainable Active Learning for Preference Elicitation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00356">http://arxiv.org/abs/2309.00356</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/furkancanturk/explainable_active_learning">https://github.com/furkancanturk/explainable_active_learning</a></li>
<li>paper_authors: Furkan Cantürk, Reyhan Aydoğan<br>for: 这篇论文的目的是解决新用户的偏好预测问题，特别是在冷开始问题下，当推荐系统缺乏用户存在或者其他用户数据存在限制，使得使用用户资料建立用户Profile几乎不可能。methods: 这篇论文使用了活动学习（AL）来解决冷开始问题，通过选择大量未标的数据，请 oracle 标注它们，并更新机器学习（ML）模型。论文还结合了不监controlled、半监controlled和监controlled ML的混合过程，并与用户反馈组合使用。results: 实验结果显示，提案的偏好探索方法在有限用户标注数据下可以实现高效的偏好预测，同时也能够提高用户信任度 durch 精准的解释。<details>
<summary>Abstract</summary>
Gaining insights into the preferences of new users and subsequently personalizing recommendations necessitate managing user interactions intelligently, namely, posing pertinent questions to elicit valuable information effectively. In this study, our focus is on a specific scenario of the cold-start problem, where the recommendation system lacks adequate user presence or access to other users' data is restricted, obstructing employing user profiling methods utilizing existing data in the system. We employ Active Learning (AL) to solve the addressed problem with the objective of maximizing information acquisition with minimal user effort. AL operates for selecting informative data from a large unlabeled set to inquire an oracle to label them and eventually updating a machine learning (ML) model. We operate AL in an integrated process of unsupervised, semi-supervised, and supervised ML within an explanatory preference elicitation process. It harvests user feedback (given for the system's explanations on the presented items) over informative samples to update an underlying ML model estimating user preferences. The designed user interaction facilitates personalizing the system by incorporating user feedback into the ML model and also enhances user trust by refining the system's explanations on recommendations. We implement the proposed preference elicitation methodology for food recommendation. We conducted human experiments to assess its efficacy in the short term and also experimented with several AL strategies over synthetic user profiles that we created for two food datasets, aiming for long-term performance analysis. The experimental results demonstrate the efficiency of the proposed preference elicitation with limited user-labeled data while also enhancing user trust through accurate explanations.
</details>
<details>
<summary>摘要</summary>
为了获得新用户的偏好情况和个性化推荐，需要智能地管理用户互动，即向用户提问有价值信息以获得有效反馈。在这个研究中，我们关注了冷启动问题的特定场景，其中推荐系统缺乏用户存在或其他用户数据访问被限制，使用用户 profiling 方法使用现有系统数据 becomes impossible. 我们使用活动学习（AL）解决这个问题，以达到最大化信息收集的目的，同时减少用户努力。AL 方法从大量未标记数据集中选择有用信息，并请 oracle 标记它们，以更新机器学习（ML）模型。我们在混合式、半结构化和结构化 ML 中运行 AL，并在用户反馈（对系统的解释中提供的Feedback）上更新下面 ML 模型，以估计用户偏好。这种设计的用户互动方式可以个性化系统，并且提高用户信任度，因为它可以在推荐中更加准确地解释用户选择。我们在美食推荐领域实现了这种偏好抽取方法。我们对短期效果进行了人类实验，以及使用了多种 AL 策略对两个食品数据集进行了长期性能分析。实验结果表明，我们的偏好抽取方法在有限用户标注数据下可以 дости到高效性，同时提高用户信任度。
</details></li>
</ul>
<hr>
<h2 id="A-Text-based-Approach-For-Link-Prediction-on-Wikipedia-Articles"><a href="#A-Text-based-Approach-For-Link-Prediction-on-Wikipedia-Articles" class="headerlink" title="A Text-based Approach For Link Prediction on Wikipedia Articles"></a>A Text-based Approach For Link Prediction on Wikipedia Articles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00317">http://arxiv.org/abs/2309.00317</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tam1032/dsaa2023-challenge-link-prediction-ds-uit_sat">https://github.com/tam1032/dsaa2023-challenge-link-prediction-ds-uit_sat</a></li>
<li>paper_authors: Anh Hoang Tran, Tam Minh Nguyen, Son T. Luu</li>
<li>for: 这篇论文是为了参加 DSAA 2023 挑战，用于预测 Wikipedia 文章中的连结是否存在。</li>
<li>methods: 本文使用传统机器学习模型，使用文本中的 POS 标签特征进行训练分类模型。</li>
<li>results: 本文获得 F1 得分 0.99999，在竞赛中排名第 7 名。并且提供了可公开使用的源代码：<a target="_blank" rel="noopener" href="https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT%E3%80%82">https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT。</a><details>
<summary>Abstract</summary>
This paper present our work in the DSAA 2023 Challenge about Link Prediction for Wikipedia Articles. We use traditional machine learning models with POS tags (part-of-speech tags) features extracted from text to train the classification model for predicting whether two nodes has the link. Then, we use these tags to test on various machine learning models. We obtained the results by F1 score at 0.99999 and got 7th place in the competition. Our source code is publicly available at this link: https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT
</details>
<details>
<summary>摘要</summary>
这篇论文介绍我们在 DSAA 2023 挑战中对维基百科文章链接预测的工作。我们使用传统机器学习模型，使用文本中提取的 POS 标签特征来训练分类模型，以预测两个节点是否有链接。然后，我们使用这些标签来测试不同的机器学习模型。我们获得的结果是 F1 分数为 0.99999，在比赛中获得第 7 名。我们的源代码可以在以下链接中下载：https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT。
</details></li>
</ul>
<hr>
<h2 id="Sherlock-Holmes-Doesn’t-Play-Dice-The-significance-of-Evidence-Theory-for-the-Social-and-Life-Sciences"><a href="#Sherlock-Holmes-Doesn’t-Play-Dice-The-significance-of-Evidence-Theory-for-the-Social-and-Life-Sciences" class="headerlink" title="Sherlock Holmes Doesn’t Play Dice: The significance of Evidence Theory for the Social and Life Sciences"></a>Sherlock Holmes Doesn’t Play Dice: The significance of Evidence Theory for the Social and Life Sciences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03222">http://arxiv.org/abs/2309.03222</a></li>
<li>repo_url: None</li>
<li>paper_authors: V. L. Raju Chinthalapati, Guido Fioretti</li>
<li>for: 本文主要探讨了证据理论在社会和生物科学中的潜在应用，以及它与概率论的区别。</li>
<li>methods: 本文使用了德мпстер-沙法尔理论和信念函数理论来表达对事件的不确定性。</li>
<li>results: 本文证明了德мпстер-沙法尔的组合规则与 bayes 定理之间存在关系，并讨论了如何通过证据理论增强信息理论中的应用。 I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
While Evidence Theory (Demster-Shafer Theory, Belief Functions Theory) is being increasingly used in data fusion, its potentialities in the Social and Life Sciences are often obscured by lack of awareness of its distinctive features. With this paper we stress that Evidence Theory can express the uncertainty deriving from the fear that events may materialize, that one has not been able to figure out. By contrast, Probability Theory must limit itself to the possibilities that a decision-maker is currently envisaging.   Subsequently, we illustrate how Dempster-Shafer's combination rule relates to Bayes' Theorem for various versions of Probability Theory and discuss which applications of Information Theory can be enhanced by Evidence Theory. Finally, we illustrate our claims with an example where Evidence Theory is used to make sense of the partially overlapping, partially contradictory solutions that appear in an auditing exercise.
</details>
<details>
<summary>摘要</summary>
“证据理论（德赫-沙佛理论，信念函数理论）在数据融合中日益受到应用，但它在社会和生活科学中的潜力往往被不了了之。本文强调证据理论可以表达因事件可能实现而导致的不确定性，而probability理论只能限制在决策者目前所看到的可能性上。后续，我们详细介绍德赫-沙佛组合规则与 bayes定理之间的关系，并讨论在信息理论中哪些应用可以增强使用证据理论。最后，我们通过一个例子说明证据理论如何用于理解审计实践中的部分重叠、部分矛盾的解决方案。”Note: "Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="On-the-Aggregation-of-Rules-for-Knowledge-Graph-Completion"><a href="#On-the-Aggregation-of-Rules-for-Knowledge-Graph-Completion" class="headerlink" title="On the Aggregation of Rules for Knowledge Graph Completion"></a>On the Aggregation of Rules for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00306">http://arxiv.org/abs/2309.00306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Betz, Stefan Lüdtke, Christian Meilicke, Heiner Stuckenschmidt</li>
<li>for: 本研究旨在提高知识图完成任务中的规则学取得效率、可读性和竞争力。</li>
<li>methods: 本文使用数据驱动的规则学学习方法，并 investigate 规则集中的噪音和规则集大小的问题。</li>
<li>results: 本文提出了一种新的规则汇总策略，并证明了这种策略可以表示为规则集中的 marginal inference 操作。此外，本文还提出了一种效果很好的基线方法，可以与计算更昂贵的方法竞争。<details>
<summary>Abstract</summary>
Rule learning approaches for knowledge graph completion are efficient, interpretable and competitive to purely neural models. The rule aggregation problem is concerned with finding one plausibility score for a candidate fact which was simultaneously predicted by multiple rules. Although the problem is ubiquitous, as data-driven rule learning can result in noisy and large rulesets, it is underrepresented in the literature and its theoretical foundations have not been studied before in this context. In this work, we demonstrate that existing aggregation approaches can be expressed as marginal inference operations over the predicting rules. In particular, we show that the common Max-aggregation strategy, which scores candidates based on the rule with the highest confidence, has a probabilistic interpretation. Finally, we propose an efficient and overlooked baseline which combines the previous strategies and is competitive to computationally more expensive approaches.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traduced text into Simplified Chinese.<</SYS>>知识图完成任务的规则学习方法是高效、可读性和竞争力强的。规则汇总问题关注于找到多个规则同时预测的 кандидат事实的可能性分数。尽管这个问题在数据驱动的规则学习中很普遍，但在文献中它尚未得到过足够的研究和理论基础。在这种情况下，我们展示了现有的汇总方法可以表示为规则预测时的边缘推理操作。特别是，我们显示了通用的Max汇总策略，将 кандидат事实分数基于预测规则的信任度进行评分，具有概率解释。最后，我们提出了一种高效且被忽略的基线， combinig 前两种策略，与计算更昂贵的方法竞争。
</details></li>
</ul>
<hr>
<h2 id="Identifiable-Cognitive-Diagnosis-with-Encoder-decoder-for-Modelling-Students’-Performance"><a href="#Identifiable-Cognitive-Diagnosis-with-Encoder-decoder-for-Modelling-Students’-Performance" class="headerlink" title="Identifiable Cognitive Diagnosis with Encoder-decoder for Modelling Students’ Performance"></a>Identifiable Cognitive Diagnosis with Encoder-decoder for Modelling Students’ Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00300">http://arxiv.org/abs/2309.00300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiatong Li, Qi Liu, Fei Wang, Jiayu Liu, Zhenya Huang, Enhong Chen</li>
<li>for: 该论文旨在针对学生知识水平的诊断，以响应题目的回答得分作为基础，以便在多个领域中进行计算化适应测试。</li>
<li>methods: 该论文提出了一种新的可识别性诊断框架，包括直接从回答日志中诊断可识别和可解释的学生特征和问题特征，以及利用一种通用预测模块来重建回答日志，以保证诊断结果的准确性。</li>
<li>results: 该论文通过四个公共实验数据集的实验，证明了新的可识别性诊断框架可以提供可识别的诊断结果，同时也可以保证诊断结果的可解释性和精度。<details>
<summary>Abstract</summary>
Cognitive diagnosis aims to diagnose students' knowledge proficiencies based on their response scores on exam questions, which is the basis of many domains such as computerized adaptive testing. Existing cognitive diagnosis models (CDMs) follow a proficiency-response paradigm, which views diagnostic results as learnable embeddings that are the cause of students' responses and learns the diagnostic results through optimization. However, such a paradigm can easily lead to unidentifiable diagnostic results and the explainability overfitting problem, which is harmful to the quantification of students' learning performance. To address these problems, we propose a novel identifiable cognitive diagnosis framework. Specifically, we first propose a flexible diagnostic module which directly diagnose identifiable and explainable examinee traits and question features from response logs. Next, we leverage a general predictive module to reconstruct response logs from the diagnostic results to ensure the preciseness of the latter. We furthermore propose an implementation of the framework, i.e., ID-CDM, to demonstrate the availability of the former. Finally, we demonstrate the identifiability, explainability and preciseness of diagnostic results of ID-CDM through experiments on four public real-world datasets.
</details>
<details>
<summary>摘要</summary>
�� cognitive diagnosis 目标是根据学生响应 scored exam 问题的得分来评估学生的知识水平，这是许多领域，如计算机化适应测试的基础。现有的 cognitive diagnosis 模型（CDM）采用 proficiency-response 模式，视学生的响应为可学习的嵌入，通过优化来学习诊断结果。然而，这种模式可能导致诊断结果难以识别和过拟合问题，这会对学生学习表现的量化带来害。为解决这些问题，我们提出了一种新的可识别 cognitive diagnosis 框架。 Specifically, we first propose a flexible diagnostic module  directly diagnose identifiable and explainable examinee traits and question features from response logs. Next, we leverage a general predictive module to reconstruct response logs from the diagnostic results to ensure the preciseness of the latter. We furthermore propose an implementation of the framework, i.e., ID-CDM, to demonstrate the availability of the former. Finally, we demonstrate the identifiability, explainability and preciseness of diagnostic results of ID-CDM through experiments on four public real-world datasets.
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Lidar-Driven-Reinforcement-Learning-for-Autonomous-Racing"><a href="#End-to-end-Lidar-Driven-Reinforcement-Learning-for-Autonomous-Racing" class="headerlink" title="End-to-end Lidar-Driven Reinforcement Learning for Autonomous Racing"></a>End-to-end Lidar-Driven Reinforcement Learning for Autonomous Racing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00296">http://arxiv.org/abs/2309.00296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meraj Mammadov</li>
<li>For: The paper is written for the domain of car racing, specifically in the context of autonomous racing.* Methods: The paper uses reinforcement learning (RL) and feedforward raw lidar and velocity data to train an RL agent in a simulated environment.* Results: The RL agent’s performance is experimentally evaluated in a real-world racing scenario, demonstrating the feasibility and potential benefits of RL algorithms in enhancing autonomous racing performance, especially in environments where prior map information is not available.Here is the information in Simplified Chinese text:</li>
<li>for: 本研究针对的是自动赛车领域，具体来说是在 simulations 中使用 reinforcement learning（RL）和 feedforward raw lidar 和 velocity data 训练一个 RL 智能体。</li>
<li>methods: 本研究使用 RL 和 feedforward raw lidar 和 velocity data 训练一个 RL 智能体，并在 simulated 环境中进行了训练。</li>
<li>results: 在实际的 racing enario 中，RL 智能体的性能得到了实验证明，表明RL 算法在缺乏 prior map information 的环境中提供了可能的和有利的性能提升。<details>
<summary>Abstract</summary>
Reinforcement Learning (RL) has emerged as a transformative approach in the domains of automation and robotics, offering powerful solutions to complex problems that conventional methods struggle to address. In scenarios where the problem definitions are elusive and challenging to quantify, learning-based solutions such as RL become particularly valuable. One instance of such complexity can be found in the realm of car racing, a dynamic and unpredictable environment that demands sophisticated decision-making algorithms. This study focuses on developing and training an RL agent to navigate a racing environment solely using feedforward raw lidar and velocity data in a simulated context. The agent's performance, trained in the simulation environment, is then experimentally evaluated in a real-world racing scenario. This exploration underlines the feasibility and potential benefits of RL algorithm enhancing autonomous racing performance, especially in the environments where prior map information is not available.
</details>
<details>
<summary>摘要</summary>
Reinforcement Learning (RL) 已经出现为自动化和机器人领域的一种转型方法，提供了强大的解决方案，解决了传统方法难以处理的复杂问题。在定义问题难以量化的情况下，学习基于的解决方案，如 RL，特别有价值。一个实例是在赛车场景中，这是一个动态和难以预测的环境，需要高级别的决策算法。这种研究将在模拟环境中开发和训练一个RL代理人， solely使用前向Raw Lidar和速度数据进行导航。在实际赛车场景中，代理人的性能，在模拟环境中训练的，进行实验性评估。这一探索， highlights the feasibility and potential benefits of RL算法在无产权地图信息的自动赛车性能提高中发挥作用。
</details></li>
</ul>
<hr>
<h2 id="RLAIF-Scaling-Reinforcement-Learning-from-Human-Feedback-with-AI-Feedback"><a href="#RLAIF-Scaling-Reinforcement-Learning-from-Human-Feedback-with-AI-Feedback" class="headerlink" title="RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback"></a>RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00267">http://arxiv.org/abs/2309.00267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, Abhinav Rastogi</li>
<li>for: 这篇研究是为了比较从人类反馈（RLHF）和从AI反馈（RLAIF）两种技术，以改善大语言模型（LLMs）与人类偏好的整合。</li>
<li>methods: 这篇研究使用了RLHF和RLAIF两种技术，RLHF需要人类提供反馈，而RLAIF则使用了一个商业化的LLM来提供反馈。</li>
<li>results: 研究发现，RLHF和RLAIF都能够将大语言模型与人类偏好进行高质量的整合，并且人类评价者对RLAIF和RLHF两种摘要都有与基准模型相似的喜好。<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) is effective at aligning large language models (LLMs) to human preferences, but gathering high quality human preference labels is a key bottleneck. We conduct a head-to-head comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find that they result in similar improvements. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ~70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF.
</details>
<details>
<summary>摘要</summary>
人工反馈学习（RLHF）可以有效地将大语言模型（LLM）与人类偏好相对应，但收集高质量人类偏好标签是一个关键瓶颈。我们进行了RLHF与RL从AI反馈（RLAIF）的头比赛，其中RLAIF使用了市售LLM来标注偏好，而不是人类。我们发现，这两种技术在摘要任务上都可以达到类似的改进。人类评估员在70%的情况下偏好RLAIF和RLHF生成的摘要，并且对RLAIF和RLHF摘要进行评分时，偏好它们的情况相同。这些结果表明，RLAIF可以达到人类水平的表现，提供了RLHF扩展的可能性。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Learning-Metrics-for-Improved-Federated-Learning"><a href="#Leveraging-Learning-Metrics-for-Improved-Federated-Learning" class="headerlink" title="Leveraging Learning Metrics for Improved Federated Learning"></a>Leveraging Learning Metrics for Improved Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00257">http://arxiv.org/abs/2309.00257</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andre Fu</li>
<li>for: 本研究旨在应用可解释人工智能（XAI）的新研究，尤其是定量学习度量，以改善联边学习中的数据联边问题。</li>
<li>methods: 本研究使用联边学习和有效排名（ER）学习度量，实现了首个联边学习度量聚合方法。</li>
<li>results: 研究结果显示，使用有效排名学习度量可以超越基eline Federated Averaging \cite{konevcny2016federated}，并开发了一个基于有效排名的新量化策略。<details>
<summary>Abstract</summary>
Currently in the federated setting, no learning schemes leverage the emerging research of explainable artificial intelligence (XAI) in particular the novel learning metrics that help determine how well a model is learning. One of these novel learning metrics is termed `Effective Rank' (ER) which measures the Shannon Entropy of the singular values of a matrix, thus enabling a metric determining how well a layer is mapping. By joining federated learning and the learning metric, effective rank, this work will \textbf{(1)} give the first federated learning metric aggregation method \textbf{(2)} show that effective rank is well-suited to federated problems by out-performing baseline Federated Averaging \cite{konevcny2016federated} and \textbf{(3)} develop a novel weight-aggregation scheme relying on effective rank.
</details>
<details>
<summary>摘要</summary>
当前在联合学习 Setting中，无法学习 schemes 利用 emerging research of explainable artificial intelligence (XAI) 特别是新的学习指标，帮助确定模型是如何学习。其中一个新的学习指标是“有效排名”（ER），测量矩阵的几何 entropy，因此可以提供一个度量layer是如何映射。通过联合学习和有效排名指标的结合，本工作将实现以下三个目标：1. 提供首个联合学习指标聚合方法。2. 表明有效排名指标适合联合问题，超越基eline Federated Averaging \cite{konevcny2016federated}。3. 开发一种基于有效排名指标的新的质量聚合方案。
</details></li>
</ul>
<hr>
<h2 id="DiffuGen-Adaptable-Approach-for-Generating-Labeled-Image-Datasets-using-Stable-Diffusion-Models"><a href="#DiffuGen-Adaptable-Approach-for-Generating-Labeled-Image-Datasets-using-Stable-Diffusion-Models" class="headerlink" title="DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models"></a>DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00248">http://arxiv.org/abs/2309.00248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mshenoda/diffugen">https://github.com/mshenoda/diffugen</a></li>
<li>paper_authors: Michael Shenoda, Edward Kim</li>
<li>for: 本研究旨在提高计算机视觉领域中Machine learning模型的准确性和可靠性，通过生成高质量的标注图像集。</li>
<li>methods: 本paper introduce了一种名为DiffuGen的简单有效的方法，利用稳定的扩散模型来生成标注图像集。DiffuGen combine了扩散模型的能力与两种不同的标注技术：无监督和监督。</li>
<li>results: DiffuGen可以生成高质量的标注图像集，并且提供了一种灵活的解决方案 для标注生成。在本paper中，我们介绍了DiffuGen的方法ología，包括使用提示模板进行适应图像生成和文本反转来增强扩散模型的能力。<details>
<summary>Abstract</summary>
Generating high-quality labeled image datasets is crucial for training accurate and robust machine learning models in the field of computer vision. However, the process of manually labeling real images is often time-consuming and costly. To address these challenges associated with dataset generation, we introduce "DiffuGen," a simple and adaptable approach that harnesses the power of stable diffusion models to create labeled image datasets efficiently. By leveraging stable diffusion models, our approach not only ensures the quality of generated datasets but also provides a versatile solution for label generation. In this paper, we present the methodology behind DiffuGen, which combines the capabilities of diffusion models with two distinct labeling techniques: unsupervised and supervised. Distinctively, DiffuGen employs prompt templating for adaptable image generation and textual inversion to enhance diffusion model capabilities.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>在计算机视觉领域，生成高质量标注图像集是训练精准和可靠机器学习模型的关键。然而，手动标注真实图像是时间consuming和成本高昂的。为解决这些数据生成过程中的挑战，我们介绍“DiffuGen”，一种简单而适应的方法，利用稳定扩散模型来生成标注图像集。通过利用稳定扩散模型，DiffuGen不仅保证生成的数据质量，还提供了一种多样化的标签生成解决方案。在这篇论文中，我们介绍DiffuGen的方法ологи，它结合扩散模型的能力和两种不同的标签技术：无监督和监督。与其他方法不同的是，DiffuGen使用插入模板来适应图像生成，以及文本反转来增强扩散模型的能力。
</details></li>
</ul>
<hr>
<h2 id="City-electric-power-consumption-forecasting-based-on-big-data-neural-network-under-smart-grid-background"><a href="#City-electric-power-consumption-forecasting-based-on-big-data-neural-network-under-smart-grid-background" class="headerlink" title="City electric power consumption forecasting based on big data &amp; neural network under smart grid background"></a>City electric power consumption forecasting based on big data &amp; neural network under smart grid background</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00245">http://arxiv.org/abs/2309.00245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengxian Chen, Maowei Wang, Conghu Li</li>
<li>for: 这篇论文是为了研究城市电力消耗的预测和评估，以提供更好的城市服务。</li>
<li>methods: 论文使用大数据和神经网络模型，考虑了不同的非线性因素对城市电力消耗的影响，建立了一个预测城市电力消耗的模型。</li>
<li>results: 根据排序重要性测试，论文建立了城市电力消耗预测模型的核心特征值，对电力相关业界提供了重要参考。<details>
<summary>Abstract</summary>
With the development of the electric power system, the smart grid has become an important part of the smart city. The rational transmission of electric energy and the guarantee of power supply of the smart grid are very important to smart cities, smart cities can provide better services through smart grids. Among them, predicting and judging city electric power consumption is closely related to electricity supply and regulation, the location of power plants, and the control of electricity transmission losses. Based on big data, this paper establishes a neural network and considers the influence of various nonlinear factors on city electric power consumption. A model is established to realize the prediction of power consumption. Based on the permutation importance test, an evaluation model of the influencing factors of city electric power consumption is constructed to obtain the core characteristic values of city electric power consumption prediction, which can provide an important reference for electric power related industry.
</details>
<details>
<summary>摘要</summary>
随着电力系统的发展，智能电网已成为智能城市的重要组成部分。智能城市通过智能电网提供更好的服务，智能电网的合理的电能传输和电力供应是非常重要的。其中，预测和评估城市电力消耗和电力供应的关系非常重要，包括发电厂的位置、电力传输损失的控制等多个因素。基于大数据，本文建立了神经网络模型，考虑了城市电力消耗的多个非线性因素的影响。通过Permutation Importance Test，建立了城市电力消耗影响因素评价模型，获得了城市电力消耗预测核心特征值，可以为电力相关行业提供重要参考。
</details></li>
</ul>
<hr>
<h2 id="FactLLaMA-Optimizing-Instruction-Following-Language-Models-with-External-Knowledge-for-Automated-Fact-Checking"><a href="#FactLLaMA-Optimizing-Instruction-Following-Language-Models-with-External-Knowledge-for-Automated-Fact-Checking" class="headerlink" title="FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking"></a>FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00240">http://arxiv.org/abs/2309.00240</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thcheung/FactLLaMA">https://github.com/thcheung/FactLLaMA</a></li>
<li>paper_authors: Tsun-Hin Cheung, Kin-Man Lam</li>
<li>for: 本研究旨在提高自动 факчекин表现，以便更好地斗争假信息的扩散。</li>
<li>methods: 本研究使用了大型自然语言模型（LLMs）和指令遵循变体，如InstructGPT和Alpaca，以及外部证据检索来增强 fact-checking 表现。</li>
<li>results: 研究结果显示，将外部证据与 instruction-tuning 结合使用可以更好地预测输入CLAIM 的真伪性。在 RAWFC 和 LIAR 两个常用的 fact-checking 数据集上进行了实验，并取得了状态之 луч表现。<details>
<summary>Abstract</summary>
Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments on two widely used fact-checking datasets: RAWFC and LIAR. The results demonstrate that our approach achieves state-of-the-art performance in fact-checking tasks. By integrating external evidence, we bridge the gap between the model's knowledge and the most up-to-date and sufficient context available, leading to improved fact-checking outcomes. Our findings have implications for combating misinformation and promoting the dissemination of accurate information on online platforms. Our released materials are accessible at: https://thcheung.github.io/factllama.
</details>
<details>
<summary>摘要</summary>
自动化Fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments on two widely used fact-checking datasets: RAWFC and LIAR. The results demonstrate that our approach achieves state-of-the-art performance in fact-checking tasks. By integrating external evidence, we bridge the gap between the model's knowledge and the most up-to-date and sufficient context available, leading to improved fact-checking outcomes. Our findings have implications for combating misinformation and promoting the dissemination of accurate information on online platforms. Our released materials are accessible at: https://thcheung.github.io/factllama.
</details></li>
</ul>
<hr>
<h2 id="ALJP-An-Arabic-Legal-Judgment-Prediction-in-Personal-Status-Cases-Using-Machine-Learning-Models"><a href="#ALJP-An-Arabic-Legal-Judgment-Prediction-in-Personal-Status-Cases-Using-Machine-Learning-Models" class="headerlink" title="ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models"></a>ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00238">http://arxiv.org/abs/2309.00238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salwa Abbara, Mona Hafez, Aya Kazzaz, Areej Alhothali, Alhanouf Alsolami</li>
<li>for: This paper aims to predict the judgment outcomes of Arabic case scripts, specifically in cases of custody and annulment of marriage.</li>
<li>methods: The authors use deep learning (DL) and natural language processing (NLP) techniques, including Support Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory (LSTM), and Bidirectional Long Short-Term Memory (BiLSTM), with representation techniques such as TF-IDF and word2vec on a developed dataset.</li>
<li>results: The authors achieved high accuracy in predicting the judgment outcomes of custody cases and annulment of marriage, with the SVM model with word2vec and LR with TF-IDF achieving the highest accuracy of 88% and 78%, respectively. Additionally, the LR and SVM with word2vec and BiLSTM model with TF-IDF achieved the highest accuracy of 88% and 69%, respectively, in predicting the probability of outcomes on custody cases and annulment of marriage.<details>
<summary>Abstract</summary>
Legal Judgment Prediction (LJP) aims to predict judgment outcomes based on case description. Several researchers have developed techniques to assist potential clients by predicting the outcome in the legal profession. However, none of the proposed techniques were implemented in Arabic, and only a few attempts were implemented in English, Chinese, and Hindi. In this paper, we develop a system that utilizes deep learning (DL) and natural language processing (NLP) techniques to predict the judgment outcome from Arabic case scripts, especially in cases of custody and annulment of marriage. This system will assist judges and attorneys in improving their work and time efficiency while reducing sentencing disparity. In addition, it will help litigants, lawyers, and law students analyze the probable outcomes of any given case before trial. We use a different machine and deep learning models such as Support Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory (LSTM), and Bidirectional Long Short-Term Memory (BiLSTM) using representation techniques such as TF-IDF and word2vec on the developed dataset. Experimental results demonstrate that compared with the five baseline methods, the SVM model with word2vec and LR with TF-IDF achieve the highest accuracy of 88% and 78% in predicting the judgment on custody cases and annulment of marriage, respectively. Furthermore, the LR and SVM with word2vec and BiLSTM model with TF-IDF achieved the highest accuracy of 88% and 69% in predicting the probability of outcomes on custody cases and annulment of marriage, respectively.
</details>
<details>
<summary>摘要</summary>
法律判断预测（LJP）目标是根据案件描述预测判决结果。一些研究人员已经开发了用于帮助 potential clients 预测案件结果的技术，但是这些技术都没有在阿拉伯语中实现，只有一些尝试在英语、中文和捷地语中实现。在这篇论文中，我们开发了一个系统，使用深度学习（DL）和自然语言处理（NLP）技术，从阿拉伯语案件脚本中预测判决结果，特别是在监护和婚姻 annulment 案件中。这个系统将帮助法官和律师提高工作效率和时间效率，同时减少判决不公。此外，它还将帮助诉讼人、律师和法学生分析案件的可能结果之前。我们使用了不同的机器学习和深度学习模型，如支持向量机（SVM）、逻辑回归（LR）、长短期记忆（LSTM）和双向长短期记忆（BiLSTM），使用表示技术如 TF-IDF 和 word2vec 在开发的数据集上。实验结果表明，与基准方法相比，SVM 模型与 word2vec 和 LR 模型与 TF-IDF  achieve 最高的准确率为 88% 和 78%，分别预测监护案件和婚姻 annulment 的判决结果。此外，LR 和 SVM 模型与 word2vec 和 BiLSTM 模型与 TF-IDF  achieve 最高的准确率为 88% 和 69%，分别预测监护案件和婚姻 annulment 的可能结果。
</details></li>
</ul>
<hr>
<h2 id="Publicly-Shareable-Clinical-Large-Language-Model-Built-on-Synthetic-Clinical-Notes"><a href="#Publicly-Shareable-Clinical-Large-Language-Model-Built-on-Synthetic-Clinical-Notes" class="headerlink" title="Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes"></a>Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00237">http://arxiv.org/abs/2309.00237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/starmpcc/asclepius">https://github.com/starmpcc/asclepius</a></li>
<li>paper_authors: Sunjun Kweon, Junu Kim, Jiyoun Kim, Sujeong Im, Eunbyeol Cho, Seongsu Bae, Jungwoo Oh, Gyubok Lee, Jong Hak Moon, Seng Chan You, Seungjin Baek, Chang Hoon Han, Yoon Bin Jung, Yohan Jo, Edward Choi</li>
<li>For: The paper aims to develop a specialized clinical language model, Asclepius, to handle patients’ clinical notes, and to address the challenges of limited accessibility and usability of these notes due to strict privacy regulations.* Methods: The authors create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature, and use these synthetic notes to train Asclepius. They also evaluate the performance of Asclepius using real clinical notes and compare it with other large language models, including GPT-3.5-turbo and other open-source alternatives.* Results: The authors find that synthetic clinical notes can serve as viable substitutes for real ones when constructing high-performing clinical language models, and that Asclepius outperforms other large language models in real-world applications. The findings are supported by detailed evaluations conducted by both GPT-4 and medical professionals.Here’s the simplified Chinese text for the three key points:* For: 这篇论文目的是开发一种专门用于处理患者医疗记录的临床语言模型，以解决因严格隐私法规限制而受到的医疗记录访问和使用困难。* Methods: 作者们使用公开可用的案例报告从生物医学文献中提取的大规模临床报告来生成synthetic大规模的临床报告，然后使用这些synthetic报告来训练特殊的临床语言模型Asclepius。作者们还使用实际的临床报告来评估Asclepius的性能，并与其他大语言模型进行比较，包括GPT-3.5-turbo和其他开源选择。* Results: 作者们发现，使用synthetic临床报告可以成为高性能临床语言模型的建模 substitutes，而Asclepius在实际应用中表现出色，比其他大语言模型更高。这些结论得到了GPT-4和医疗专业人员的详细评估。<details>
<summary>Abstract</summary>
The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructing high-performing clinical language models. This conclusion is supported by detailed evaluations conducted by both GPT-4 and medical professionals. All resources including weights, codes, and data used in the development of Asclepius are made publicly accessible for future research.
</details>
<details>
<summary>摘要</summary>
大型语言模型的开发，用于处理病人的诊所录取得到受到隐私规定限制，导致这些录取不易存取和使用。为了解决这些挑战，我们首先创建了大规模的人工生成的诊所录取，使用公开可用的专业医疗文献中的案例报告。然后，我们使用这些人工生成的录取来训练我们的特殊化的医疗语言模型Asclepius。处理Asclepius的训练是使用人工生成的数据，我们使用真实的诊所录取进行评估。我们与其他大型语言模型，如GPT-3.5-turbo和其他开源选择进行比较。为了进一步验证我们的方法，我们还比较Asclepius与它的变体，它们是使用真实的诊所录取进行训练。我们的结果表明，人工生成的诊所录取可以作为真实的诊所录取的可行substitute，这是由GPT-4和医疗专业人员进行详细评估所支持。我们所有的资源，包括权重、代码和数据，都是公开可用的，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Semantic-Monitoring-of-Corporate-Disclosures-A-Case-Study-on-Korea’s-Top-50-KOSPI-Companies"><a href="#Large-Language-Models-for-Semantic-Monitoring-of-Corporate-Disclosures-A-Case-Study-on-Korea’s-Top-50-KOSPI-Companies" class="headerlink" title="Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea’s Top 50 KOSPI Companies"></a>Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea’s Top 50 KOSPI Companies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00208">http://arxiv.org/abs/2309.00208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwon Sung, Woojin Heo, Yunkyung Byun, Youngsam Kim</li>
<li>for: 这项研究探讨了OpenAI的GPT-3.5-turbo和GPT-4语言模型在韩国上市公司公告中的semantic分析能力，尤其是对于实时公告。</li>
<li>methods: 研究对韩国KOSPI上市50 круп公司的月度报告进行了分析，每份报告都被赋予了一个含义评分，范围从1(非常负面)到5(非常正面)。</li>
<li>results: 研究发现GPT-4表现了显著的准确性，与人工专家的评分相比，Spearman相关系数为0.61，朴素匹配率为0.82。这些发现对GPT模型的评价特征提供了重要的新视角，为未来自动 semantic监测领域的创新奠定了基础。<details>
<summary>Abstract</summary>
In the rapidly advancing domain of artificial intelligence, state-of-the-art language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented opportunities for automating complex tasks. This research paper delves into the capabilities of these models for semantically analyzing corporate disclosures in the Korean context, specifically for timely disclosure. The study focuses on the top 50 publicly traded companies listed on the Korean KOSPI, based on market capitalization, and scrutinizes their monthly disclosure summaries over a period of 17 months. Each summary was assigned a sentiment rating on a scale ranging from 1(very negative) to 5(very positive). To gauge the effectiveness of the language models, their sentiment ratings were compared with those generated by human experts. Our findings reveal a notable performance disparity between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant accuracy in human evaluation tests. The Spearman correlation coefficient was registered at 0.61, while the simple concordance rate was recorded at 0.82. This research contributes valuable insights into the evaluative characteristics of GPT models, thereby laying the groundwork for future innovations in the field of automated semantic monitoring.
</details>
<details>
<summary>摘要</summary>
在人工智能领域的快速发展中，现代语言模型如OpenAI的GPT-3.5-turbo和GPT-4提供了无前例的自动化复杂任务的机会。这篇研究论文探讨了这些模型在韩国上市公司公告中的语义分析能力，具体来说是对时间性公告进行实时分析。研究选择韩国KOSPI板块上市50大公司，根据市值排名，并对这些公司月度公告摘要进行17个月的分析。每份摘要都被赋予了一个sentiment评级，从1（非常负面）到5（非常正面）的评级范围内。为了评估语言模型的效果，我们与人类专家生成的sentiment评级进行比较。我们的发现表明GPT-3.5-turbo和GPT-4之间存在显著的性能差异，GPT-4在人类评估测试中表现出了显著的准确性。Spearman相关系数为0.61，单词匹配率为0.82。这篇研究为未来自动语义监测领域的创新奠定了基础。
</details></li>
</ul>
<hr>
<h2 id="Gap-and-Overlap-Detection-in-Automated-Fiber-Placement"><a href="#Gap-and-Overlap-Detection-in-Automated-Fiber-Placement" class="headerlink" title="Gap and Overlap Detection in Automated Fiber Placement"></a>Gap and Overlap Detection in Automated Fiber Placement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00206">http://arxiv.org/abs/2309.00206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Assef Ghamisi, Homayoun Najjaran</li>
<li>For: This paper is written for the purpose of detecting and correcting manufacturing defects in composite parts produced through Automated Fiber Placement (AFP). The focus is on gaps and overlaps, which are the most common defects that can significantly impact the quality of the composite parts.* Methods: The paper proposes a novel method that uses an Optical Coherence Tomography (OCT) sensor and computer vision techniques to detect and locate gaps and overlaps in composite parts. The method involves generating a depth map image of the composite surface, detecting the boundaries of each tow, and comparing consecutive tows to identify gaps or overlaps that exceed a predefined tolerance threshold.* Results: The results of the paper demonstrate a high level of accuracy and efficiency in gap and overlap segmentation, as compared to ground truth annotations by experts. The approach is effective in detecting defects in composite parts produced through AFP, and has the potential to improve the overall quality and efficiency of the manufacturing process.<details>
<summary>Abstract</summary>
The identification and correction of manufacturing defects, particularly gaps and overlaps, are crucial for ensuring high-quality composite parts produced through Automated Fiber Placement (AFP). These imperfections are the most commonly observed issues that can significantly impact the overall quality of the composite parts. Manual inspection is both time-consuming and labor-intensive, making it an inefficient approach. To overcome this challenge, the implementation of an automated defect detection system serves as the optimal solution. In this paper, we introduce a novel method that uses an Optical Coherence Tomography (OCT) sensor and computer vision techniques to detect and locate gaps and overlaps in composite parts. Our approach involves generating a depth map image of the composite surface that highlights the elevation of composite tapes (or tows) on the surface. By detecting the boundaries of each tow, our algorithm can compare consecutive tows and identify gaps or overlaps that may exist between them. Any gaps or overlaps exceeding a predefined tolerance threshold are considered manufacturing defects. To evaluate the performance of our approach, we compare the detected defects with the ground truth annotated by experts. The results demonstrate a high level of accuracy and efficiency in gap and overlap segmentation.
</details>
<details>
<summary>摘要</summary>
检测和修正制造过程中的缺陷，特别是孔隙和重叠，对于通过自动纤维放置（AFP）生产的复合部件质量的确保非常重要。这些缺陷是制造过程中最常见的问题，可能对全面质量产生重要影响。手动检查是时间consuming和人力 INTENSIVE，因此是不可靠的方法。为了解决这个挑战，我们提出了一种新的方法，使用光子干涉Tomography（OCT）感知器和计算机视觉技术来检测和定位复合部件中的孔陷和重叠。我们的方法是生成复合部件表面的深度图像，高亮显示复合带（或排列）的抬升。通过检测每个带的边界，我们的算法可以比较 consecutive带之间的孔陷和重叠，并确定任何超过预定的允许阈值的缺陷。我们对我们的方法的性能进行了评估，结果表明我们的方法具有高精度和高效的孔陷和重叠分 segmentation。
</details></li>
</ul>
<hr>
<h2 id="Subjectivity-in-Unsupervised-Machine-Learning-Model-Selection"><a href="#Subjectivity-in-Unsupervised-Machine-Learning-Model-Selection" class="headerlink" title="Subjectivity in Unsupervised Machine Learning Model Selection"></a>Subjectivity in Unsupervised Machine Learning Model Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00201">http://arxiv.org/abs/2309.00201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanyi Chen, Mary L. Cummings</li>
<li>for: 这个研究旨在探讨机器学习模型选择过程中的主观性。</li>
<li>methods: 这个研究使用隐马尔可夫模型作为例子，通过询问33名参与者和三个大型自然语言模型（LLMs）进行模型选择，以探讨参与者和LLMs在不同条件下的选择差异。</li>
<li>results: 研究发现参与者和LLMs在不同条件下的选择具有差异和不一致性，尤其是当不同的评价标准和度量不同时。主观性的来源包括参与者对不同评价标准和度量的意见不一致，以及模型的简洁程度和数据集大小的影响。这些结果 highlights the importance of developing a more standardized way to document subjective choices made in model selection processes。<details>
<summary>Abstract</summary>
Model selection is a necessary step in unsupervised machine learning. Despite numerous criteria and metrics, model selection remains subjective. A high degree of subjectivity may lead to questions about repeatability and reproducibility of various machine learning studies and doubts about the robustness of models deployed in the real world. Yet, the impact of modelers' preferences on model selection outcomes remains largely unexplored. This study uses the Hidden Markov Model as an example to investigate the subjectivity involved in model selection. We asked 33 participants and three Large Language Models (LLMs) to make model selections in three scenarios. Results revealed variability and inconsistencies in both the participants' and the LLMs' choices, especially when different criteria and metrics disagree. Sources of subjectivity include varying opinions on the importance of different criteria and metrics, differing views on how parsimonious a model should be, and how the size of a dataset should influence model selection. The results underscore the importance of developing a more standardized way to document subjective choices made in model selection processes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Diffusion-Model-with-Clustering-based-Conditioning-for-Food-Image-Generation"><a href="#Diffusion-Model-with-Clustering-based-Conditioning-for-Food-Image-Generation" class="headerlink" title="Diffusion Model with Clustering-based Conditioning for Food Image Generation"></a>Diffusion Model with Clustering-based Conditioning for Food Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00199">http://arxiv.org/abs/2309.00199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Han, Jiangpeng He, Mridul Gupta, Edward J. Delp, Fengqing Zhu</li>
<li>for: 这篇论文目的是提出一种基于条件扩散模型的食物图像生成方法，以提高食物图像生成质量和多样性。</li>
<li>methods: 该方法使用了条件扩散模型，并提出了一种基于归一化的聚类训练策略，以生成高质量和代表性的食物图像。</li>
<li>results: 研究表明，使用条件扩散模型生成的食物图像可以提高食物图像生成质量和多样性，并可以Address the severe class imbalance issue in long-tailed food classification。<details>
<summary>Abstract</summary>
Image-based dietary assessment serves as an efficient and accurate solution for recording and analyzing nutrition intake using eating occasion images as input. Deep learning-based techniques are commonly used to perform image analysis such as food classification, segmentation, and portion size estimation, which rely on large amounts of food images with annotations for training. However, such data dependency poses significant barriers to real-world applications, because acquiring a substantial, diverse, and balanced set of food images can be challenging. One potential solution is to use synthetic food images for data augmentation. Although existing work has explored the use of generative adversarial networks (GAN) based structures for generation, the quality of synthetic food images still remains subpar. In addition, while diffusion-based generative models have shown promising results for general image generation tasks, the generation of food images can be challenging due to the substantial intra-class variance. In this paper, we investigate the generation of synthetic food images based on the conditional diffusion model and propose an effective clustering-based training framework, named ClusDiff, for generating high-quality and representative food images. The proposed method is evaluated on the Food-101 dataset and shows improved performance when compared with existing image generation works. We also demonstrate that the synthetic food images generated by ClusDiff can help address the severe class imbalance issue in long-tailed food classification using the VFN-LT dataset.
</details>
<details>
<summary>摘要</summary>
图像基于的营养评估可以作为有效和准确的解决方案，用于记录和分析饮食摄入，使用吃饭场景图像作为输入。深度学习技术通常用于图像分析，如食物分类、 segmentation 和分量估计，但是这些技术需要大量的食物图像进行训练。然而，在实际应用中，获得充足、多样化和均衡的食物图像是一个大的挑战。一个可能的解决方案是使用生成的食物图像进行数据增强。虽然现有的工作已经探讨了基于生成对抗网络（GAN）结构的生成，但是生成的食物图像质量仍然较差。此外，在涉及到食物图像生成时，存在较大的内部变异问题。在这篇论文中，我们研究基于条件扩散模型的食物图像生成，并提出一种有效的分组训练框架，名为ClusDiff，以生成高质量和代表性的食物图像。我们的方法被评估在Food-101数据集上，并与现有的图像生成工作进行比较。我们还示出了ClusDiff生成的食物图像可以帮助解决VFN-LT数据集中的严重类别偏见问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/01/cs.AI_2023_09_01/" data-id="clogxf3ke00375xra5fro84ih" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/01/cs.CL_2023_09_01/" class="article-date">
  <time datetime="2023-09-01T11:00:00.000Z" itemprop="datePublished">2023-09-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/01/cs.CL_2023_09_01/">cs.CL - 2023-09-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Let-the-Models-Respond-Interpreting-Language-Model-Detoxification-Through-the-Lens-of-Prompt-Dependence"><a href="#Let-the-Models-Respond-Interpreting-Language-Model-Detoxification-Through-the-Lens-of-Prompt-Dependence" class="headerlink" title="Let the Models Respond: Interpreting Language Model Detoxification Through the Lens of Prompt Dependence"></a>Let the Models Respond: Interpreting Language Model Detoxification Through the Lens of Prompt Dependence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00751">http://arxiv.org/abs/2309.00751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DanielSc4/RewardLM">https://github.com/DanielSc4/RewardLM</a></li>
<li>paper_authors: Daniel Scalena, Gabriele Sarti, Malvina Nissim, Elisabetta Fersini</li>
<li>for: 这paper是为了研究语模型的减带技术对模型内部过程的影响。</li>
<li>methods: 这paper使用了流行的减带方法，并使用特征评估方法来衡量这些方法对模型的依赖度的影响。</li>
<li>results: 研究发现，使用减带方法可以改善模型的安全性，但是这些方法对模型内部过程的影响还不很清楚。此外，研究还发现，使用反对 narative 练习法可以提高模型的减带性能，但是这种方法与减带学习法的影响不同。<details>
<summary>Abstract</summary>
Due to language models' propensity to generate toxic or hateful responses, several techniques were developed to align model generations with users' preferences. Despite the effectiveness of such methods in improving the safety of model interactions, their impact on models' internal processes is still poorly understood. In this work, we apply popular detoxification approaches to several language models and quantify their impact on the resulting models' prompt dependence using feature attribution methods. We evaluate the effectiveness of counter-narrative fine-tuning and compare it with reinforcement learning-driven detoxification, observing differences in prompt reliance between the two methods despite their similar detoxification performances.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Baseline-Defenses-for-Adversarial-Attacks-Against-Aligned-Language-Models"><a href="#Baseline-Defenses-for-Adversarial-Attacks-Against-Aligned-Language-Models" class="headerlink" title="Baseline Defenses for Adversarial Attacks Against Aligned Language Models"></a>Baseline Defenses for Adversarial Attacks Against Aligned Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00614">http://arxiv.org/abs/2309.00614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, Micah Goldblum, Aniruddha Saha, Jonas Geiping, Tom Goldstein</li>
<li>for: 这篇论文是关于语言模型安全性的研究，特别是对于语言模型在不同的威胁模型下的防御性能。</li>
<li>methods: 本文使用了多种防御策略，包括检测（基于异常值的混淆）、输入预处理（重叠和重tokenization）以及对抗训练。</li>
<li>results: 研究发现，使用现有的粗糙优化器在文本域下可能会受到限制，而且对于语言模型来说，标准的适应攻击更加困难。未来的研究可能需要开发更强大的优化器，或者发现filtering和预处理防御策略在语言模型领域的强大性。<details>
<summary>Abstract</summary>
As Large Language Models quickly become ubiquitous, it becomes critical to understand their security vulnerabilities. Recent work shows that text optimizers can produce jailbreaking prompts that bypass moderation and alignment. Drawing from the rich body of work on adversarial machine learning, we approach these attacks with three questions: What threat models are practically useful in this domain? How do baseline defense techniques perform in this new domain? How does LLM security differ from computer vision?   We evaluate several baseline defense strategies against leading adversarial attacks on LLMs, discussing the various settings in which each is feasible and effective. Particularly, we look at three types of defenses: detection (perplexity based), input preprocessing (paraphrase and retokenization), and adversarial training. We discuss white-box and gray-box settings and discuss the robustness-performance trade-off for each of the defenses considered. We find that the weakness of existing discrete optimizers for text, combined with the relatively high costs of optimization, makes standard adaptive attacks more challenging for LLMs. Future research will be needed to uncover whether more powerful optimizers can be developed, or whether the strength of filtering and preprocessing defenses is greater in the LLMs domain than it has been in computer vision.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>What practical threat models are relevant in this domain?2. How do baseline defense techniques perform in this new domain?3. How does LLM security differ from computer vision?We evaluate several baseline defense strategies against leading adversarial attacks on LLMs, considering their feasibility and effectiveness in different settings. These include:1. Detection (perplexity-based)2. Input preprocessing (paraphrasing and retokenization)3. Adversarial trainingWe explore white-box and gray-box settings and analyze the trade-off between robustness and performance for each defense. Our findings suggest that the limitations of existing discrete optimizers for text, combined with the relatively high cost of optimization, make standard adaptive attacks more challenging for LLMs. Future research may focus on developing more powerful optimizers or enhancing the strength of filtering and preprocessing defenses in the LLM domain.In conclusion, understanding the security vulnerabilities of LLMs is crucial as they become increasingly ubiquitous. By examining these vulnerabilities using the principles of adversarial machine learning, we can develop effective defense strategies to protect these models from malicious attacks.</details></li>
</ol>
<hr>
<h2 id="Taken-out-of-context-On-measuring-situational-awareness-in-LLMs"><a href="#Taken-out-of-context-On-measuring-situational-awareness-in-LLMs" class="headerlink" title="Taken out of context: On measuring situational awareness in LLMs"></a>Taken out of context: On measuring situational awareness in LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00667">http://arxiv.org/abs/2309.00667</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asacooperstickland/situational-awareness-evals">https://github.com/asacooperstickland/situational-awareness-evals</a></li>
<li>paper_authors: Lukas Berglund, Asa Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong, Tomasz Korbak, Daniel Kokotajlo, Owain Evans</li>
<li>for: 本研究目的是更好地理解大语言模型（LLM）中的情境意识的发展。</li>
<li>methods: 本研究使用了扩展LLM的能力来评估情境意识的发展。 Specifically, the researchers used out-of-context reasoning as a way to test for situational awareness.</li>
<li>results: 研究发现，LLMs可以在没有示例或教程的情况下通过描述来解决测试。  however, the success of the models is sensitive to the training setup and only works with data augmentation. Additionally, the research found that larger models perform better on this task.<details>
<summary>Abstract</summary>
We aim to better understand the emergence of `situational awareness' in large language models (LLMs). A model is situationally aware if it's aware that it's a model and can recognize whether it's currently in testing or deployment. Today's LLMs are tested for safety and alignment before they are deployed. An LLM could exploit situational awareness to achieve a high score on safety tests, while taking harmful actions after deployment. Situational awareness may emerge unexpectedly as a byproduct of model scaling. One way to better foresee this emergence is to run scaling experiments on abilities necessary for situational awareness. As such an ability, we propose `out-of-context reasoning' (in contrast to in-context learning). We study out-of-context reasoning experimentally. First, we finetune an LLM on a description of a test while providing no examples or demonstrations. At test time, we assess whether the model can pass the test. To our surprise, we find that LLMs succeed on this out-of-context reasoning task. Their success is sensitive to the training setup and only works when we apply data augmentation. For both GPT-3 and LLaMA-1, performance improves with model size. These findings offer a foundation for further empirical study, towards predicting and potentially controlling the emergence of situational awareness in LLMs. Code is available at: https://github.com/AsaCooperStickland/situational-awareness-evals.
</details>
<details>
<summary>摘要</summary>
我们目标是更好地理解大语言模型（LLM）中的“情境意识”的出现。一个模型被称为情境意识模型，如果它意识到它是一个模型，并能识别它是否在测试或部署中。今天的LLM都在测试和对齐之前被部署。一个LLM可以通过情境意识来达到安全测试中高分，而在部署后执行有害的操作。情境意识可能会意外地出现，因此我们可以通过扩大模型来更好地预测其出现。作为一种能力，我们提出了“离 context 理解”（与上下文学习相对）。我们通过实验研究离 context 理解。我们首先精度调整了一个LLM，使其能够通过一个测试描述而不提供示例或示范。测试时，我们评估模型是否能通过测试。我们启示发现，LLMs在这种离 context 理解任务中成功。其成功关系于训练Setup，并且只有在应用数据扩展时才能实现。对于GPT-3和LLaMA-1，模型的性能随模型大小增长。这些发现为我们未来更多的实验研究提供了基础，以预测和可能控制LLM中的情境意识的出现。代码可以在以下 GitHub 上找到：https://github.com/AsaCooperStickland/situational-awareness-evals。
</details></li>
</ul>
<hr>
<h2 id="Satisfiability-Checking-of-Multi-Variable-TPTL-with-Unilateral-Intervals-Is-PSPACE-Complete"><a href="#Satisfiability-Checking-of-Multi-Variable-TPTL-with-Unilateral-Intervals-Is-PSPACE-Complete" class="headerlink" title="Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals Is PSPACE-Complete"></a>Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals Is PSPACE-Complete</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00386">http://arxiv.org/abs/2309.00386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shankara Narayanan Krishna, Khushraj Nanik Madnani, Rupak Majumdar, Paritosh K. Pandya</li>
<li>for: 这个论文研究了${0,\infty}$ fragment of Timed Propositional Temporal Logic (TPTL)的可 decidability。</li>
<li>methods: 作者使用了一种新的“非紧急”类型的 Alternating Timed Automata with multiple clocks called Unilateral Very Weak Alternating Timed Automata (VWATA$^{0,\infty}$)来验证 TPTL$^{0,\infty}$的满足性检查是PSPACE完备的。</li>
<li>results: 作者发现了一个新的多变量 fragment of TPTL，它的满足性检查是可 decidable，而且比 Metric Interval Temporal Logic (MITL)更加表达力强，且计算更加容易。这是首次没有对时间字符串（例如带有约束的变化）做出任何限制的多变量 TPTL fragment 的满足性检查是 decidable。<details>
<summary>Abstract</summary>
We investigate the decidability of the ${0,\infty}$ fragment of Timed Propositional Temporal Logic (TPTL). We show that the satisfiability checking of TPTL$^{0,\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment (1-TPTL$^{0,\infty}$) is strictly more expressive than Metric Interval Temporal Logic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we have a strictly more expressive logic with computationally easier satisfiability checking. To the best of our knowledge, TPTL$^{0,\infty}$ is the first multi-variable fragment of TPTL for which satisfiability checking is decidable without imposing any bounds/restrictions on the timed words (e.g. bounded variability, bounded time, etc.). The membership in PSPACE is obtained by a reduction to the emptiness checking problem for a new "non-punctual" subclass of Alternating Timed Automata with multiple clocks called Unilateral Very Weak Alternating Timed Automata (VWATA$^{0,\infty}$) which we prove to be in PSPACE. We show this by constructing a simulation equivalent non-deterministic timed automata whose number of clocks is polynomial in the size of the given VWATA$^{0,\infty}$.
</details>
<details>
<summary>摘要</summary>
我们调查${0,\infty}$ fragment of Timed Propositional Temporal Logic (TPTL)的对应性。我们表明TPTL$^{0,\infty}$的满足性检查是PSPACE完全的。此外，我们还证明1-TPTL$^{0,\infty}$比Metric Interval Temporal Logic (MITL)更加表达力强，其满足性检查是EXPSPACE完全的。因此，我们有一个更加表达力强的逻辑，且 computationally easier的满足性检查。根据我们所知，TPTL$^{0,\infty}$是第一个不受任何紧 bound/restriction 的时间语言的多变量 fragment 的满足性检查是可 decidable。PSPACE 的成员由一个对应的 Alternating Timed Automata with multiple clocks 的新子集 Unilateral Very Weak Alternating Timed Automata (VWATA$^{0,\infty}$) 的emptiness checking problem 的 reduction 而得。我们显示这个问题是PSPACE的，通过建构一个与非决定型时间自动 machine 相对应的同步化的非决定型时间自动 machine，其中的时钟数量是对应类别的大小的几何函数。
</details></li>
</ul>
<hr>
<h2 id="BatchPrompt-Accomplish-more-with-less"><a href="#BatchPrompt-Accomplish-more-with-less" class="headerlink" title="BatchPrompt: Accomplish more with less"></a>BatchPrompt: Accomplish more with less</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00384">http://arxiv.org/abs/2309.00384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianzhe Lin, Maurice Diesendruck, Liang Du, Robin Abraham</li>
<li>for: 提高大语言模型（LLM）的提问效率，使其更加高效地处理长Context提问。</li>
<li>methods: 使用批处理（BatchPrompt）技术，将数据集分割成多个批处理，并对每个批处理进行独立的提问。并提出了两种技术：批处理 permutation（BPE）和自我反射指导的早期停止（SEAS）。</li>
<li>results: 通过实验证明，使用BPE和SEAS技术可以提高批处理提问的性能，并且与单个提问（SinglePrompt）相比，使用BPE和SEAS技术需要更少的LLM调用和输入token（只需9%-16%的LLM调用和27.4%的输入token，可以达到90.6%-90.9%的Boolq准确率，87.2%-88.4%的QQP准确率和91.5%-91.1%的RTE准确率）。这是大语言模型提问的首次技术改进。<details>
<summary>Abstract</summary>
As the ever-increasing token limits of large language models (LLMs) have enabled long context as input, prompting with single data samples might no longer an efficient way. A straightforward strategy improving efficiency is to batch data within the token limit (e.g., 8k for gpt-3.5-turbo; 32k for GPT-4), which we call BatchPrompt. We have two initial observations for prompting with batched data. First, we find that prompting with batched data in longer contexts will inevitably lead to worse performance, compared to single-data prompting. Second, the performance of the language model is significantly correlated with the positions and order of the batched data, due to the corresponding change in decoder context. To retain efficiency and overcome performance loss, we propose Batch Permutation and Ensembling (BPE), and a novel Self-reflection-guided EArly Stopping (SEAS) technique. Our comprehensive experimental evaluation demonstrates that BPE can boost the performance of BatchPrompt with a striking margin on a range of popular NLP tasks, including question answering (Boolq), textual entailment (RTE), and duplicate questions identification (QQP). These performances are even competitive with/higher than single-data prompting(SinglePrompt), while BatchPrompt requires much fewer LLM calls and input tokens (For SinglePrompt v.s. BatchPrompt with batch size 32, using just 9%-16% the number of LLM calls, Boolq accuracy 90.6% to 90.9% with 27.4% tokens, QQP accuracy 87.2% to 88.4% with 18.6% tokens, RTE accuracy 91.5% to 91.1% with 30.8% tokens). To the best of our knowledge, this is the first work to technically improve prompting efficiency of large language models. We hope our simple yet effective approach will shed light on the future research of large language models. The code will be released.
</details>
<details>
<summary>摘要</summary>
为了提高大语言模型（LLM）的效率，我们可以考虑使用批处理（batching）技术。我们称这种技术为批提示（BatchPrompt）。我们发现，使用批处理技术可以大幅提高 LLM 的性能，但是在某些情况下，它可能会导致性能下降。我们提出了两种策略来解决这个问题：批 permutation 和批ensemble（BPE），以及一种新的自适应停止（SEAS）技术。我们的实验证明，BPE 可以在多种常见的自然语言处理任务上提高 BatchPrompt 的性能，并且和单个数据提示（SinglePrompt）相比，BPE 需要许多 fewer LLM 调用和输入符号（token）。我们认为，这是首次技术上提高大语言模型的提示效率的研究。我们希望我们的简单 yet 有效的方法可以引领未来的大语言模型研究。我们将代码发布。
</details></li>
</ul>
<hr>
<h2 id="Long-Term-Memorability-On-Advertisements"><a href="#Long-Term-Memorability-On-Advertisements" class="headerlink" title="Long-Term Memorability On Advertisements"></a>Long-Term Memorability On Advertisements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00378">http://arxiv.org/abs/2309.00378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harini S I, Somesh Singh, Yaman K Singla, Aanisha Bhattacharyya, Veeky Baths, Changyou Chen, Rajiv Ratn Shah, Balaji Krishnamurthy</li>
<li>for: The paper aims to study the memorability of ads in the machine learning literature, specifically focusing on long-term memorability and the impact of multimodality and human factors.</li>
<li>methods: The study consists of 1203 participants and 2205 ads covering 276 brands, with statistical tests run to identify factors that contribute to ad memorability. Additionally, the paper presents a novel model called Sharingan, which leverages real-world knowledge of LLMs and visual knowledge of visual encoders to predict the memorability of content.</li>
<li>results: The study finds that fast-moving scenes in commercials are more memorable than slower scenes (p&#x3D;8e-10), and that people who use ad-blockers remember lower number of ads than those who don’t (p&#x3D;5e-3). The Sharingan model achieves state-of-the-art performance on all prominent memorability datasets in literature, and ablation studies reveal insights into what drives memory.<details>
<summary>Abstract</summary>
Marketers spend billions of dollars on advertisements but to what end? At the purchase time, if customers cannot recognize a brand for which they saw an ad, the money spent on the ad is essentially wasted. Despite its importance in marketing, until now, there has been no study on the memorability of ads in the ML literature. Most studies have been conducted on short-term recall (<5 mins) on specific content types like object and action videos. On the other hand, the advertising industry only cares about long-term memorability (a few hours or longer), and advertisements are almost always highly multimodal, depicting a story through its different modalities (text, images, and videos). With this motivation, we conduct the first large scale memorability study consisting of 1203 participants and 2205 ads covering 276 brands. Running statistical tests over different participant subpopulations and ad-types, we find many interesting insights into what makes an ad memorable - both content and human factors. For example, we find that brands which use commercials with fast moving scenes are more memorable than those with slower scenes (p=8e-10) and that people who use ad-blockers remember lower number of ads than those who don't (p=5e-3). Further, with the motivation of simulating the memorability of marketing materials for a particular audience, ultimately helping create one, we present a novel model, Sharingan, trained to leverage real-world knowledge of LLMs and visual knowledge of visual encoders to predict the memorability of a content. We test our model on all the prominent memorability datasets in literature (both images and videos) and achieve state of the art across all of them. We conduct extensive ablation studies across memory types, modality, brand, and architectural choices to find insights into what drives memory.
</details>
<details>
<summary>摘要</summary>
To address this gap, we conducted a large-scale memorability study with 1203 participants and 2205 ads covering 276 brands. We found several interesting insights into what makes an ad memorable, including the use of fast-moving scenes (p=8e-10) and the impact of ad-blockers (p=5e-3).To simulate the memorability of marketing materials for a particular audience, we developed a novel model called Sharingan. This model leverages real-world knowledge of large language models (LLMs) and visual knowledge of visual encoders to predict the memorability of a content. We tested our model on several prominent memorability datasets in the literature (both images and videos) and achieved state-of-the-art results across all of them.We conducted extensive ablation studies to understand what drives memory, including the impact of different memory types, modalities, brands, and architectural choices. Our findings provide valuable insights for marketers and advertisers looking to create memorable ads that resonate with their target audience.
</details></li>
</ul>
<hr>
<h2 id="Examining-the-Effectiveness-of-Chatbots-in-Gathering-Family-History-Information-in-Comparison-to-the-Standard-In-Person-Interview-Based-Approach"><a href="#Examining-the-Effectiveness-of-Chatbots-in-Gathering-Family-History-Information-in-Comparison-to-the-Standard-In-Person-Interview-Based-Approach" class="headerlink" title="Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach"></a>Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03223">http://arxiv.org/abs/2309.03223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kieron Drumm, Vincent Tran</li>
<li>For: This paper aims to present a chatbot-based approach for gathering family histories, with the goal of providing a valuable tool for genealogists, especially when dealing with interviewees who are based in other countries.* Methods: The paper compares the performance and usability of a chatbot-based approach with two other methods: using ancestry.com and in-person interviews. The chatbot is designed to guide the interviewee through the process of providing their family history information.* Results: The paper shows that the chatbot-based approach has a lower number of mistakes made and a lower level of confusion from the user compared to the other two methods. However, the average time taken to conduct an interview using the chatbot is longer than the other two methods.<details>
<summary>Abstract</summary>
One of the most common things that a genealogist is tasked with is the gathering of a person's initial family history, normally via in-person interviews or with the use of a platform such as ancestry.com, as this can provide a strong foundation upon which a genealogist may build. However, the ability to conduct these interviews can often be hindered by both geographical constraints and the technical proficiency of the interviewee, as the interviewee in these types of interviews is most often an elderly person with a lower than average level of technical proficiency. With this in mind, this study presents what we believe, based on prior research, to be the first chatbot geared entirely towards the gathering of family histories, and explores the viability of utilising such a chatbot by comparing the performance and usability of such a method with the aforementioned alternatives. With a chatbot-based approach, we show that, though the average time taken to conduct an interview may be longer than if the user had used ancestry.com or participated in an in-person interview, the number of mistakes made and the level of confusion from the user regarding the UI and process required is lower than the other two methods. Note that the final metric regarding the user's confusion is not applicable for the in-person interview sessions due to its lack of a UI. With refinement, we believe this use of a chatbot could be a valuable tool for genealogists, especially when dealing with interviewees who are based in other countries where it is not possible to conduct an in-person interview.
</details>
<details>
<summary>摘要</summary>
Our results show that while the average time taken for an interview using the chatbot may be longer than with Ancestry.com or in-person interviews, the number of mistakes made and the level of user confusion is lower with the chatbot. Additionally, the chatbot-based approach could be a valuable tool for genealogists, especially when dealing with interviewees who are based in other countries where in-person interviews are not possible.The chatbot-based approach has several advantages. Firstly, it allows for more flexible and convenient interview scheduling, as the interview can be conducted remotely. Secondly, the chatbot can guide the interviewee through the interview process, reducing the likelihood of mistakes and confusion. Finally, the chatbot can provide a more personalized and interactive experience for the interviewee, which can lead to more accurate and detailed information.However, there are also some limitations to the chatbot-based approach. One potential drawback is that the chatbot may not be able to capture the nuances and complexities of the interviewee's family history in the same way that a human interviewer could. Additionally, the chatbot may not be able to detect and correct errors or inconsistencies in the interviewee's responses in the same way that a human interviewer could.Despite these limitations, we believe that the use of a chatbot for gathering family histories has the potential to be a valuable tool for genealogists. With refinement and further development, the chatbot could be an effective and efficient way to gather accurate and detailed information about a person's family history, especially when dealing with interviewees who are based in other countries.
</details></li>
</ul>
<hr>
<h2 id="When-Do-Discourse-Markers-Affect-Computational-Sentence-Understanding"><a href="#When-Do-Discourse-Markers-Affect-Computational-Sentence-Understanding" class="headerlink" title="When Do Discourse Markers Affect Computational Sentence Understanding?"></a>When Do Discourse Markers Affect Computational Sentence Understanding?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00368">http://arxiv.org/abs/2309.00368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiqi Li, Liesbeth Allein, Damien Sileo, Marie-Francine Moens</li>
<li>For: 这篇论文探讨了自然语言处理（NLP）机器学习模型在理解英语 дискурスconnectives方面的能力和用途。* Methods: 作者使用了 nine 种流行的自然语言处理系统来评估这些系统在理解英语 дискурスconnectives方面的能力，并分析了不同连接类型的计算处理复杂性是否与人类处理顺序一致。* Results: 研究发现，NLP系统不一定能够uniformly处理所有的 дискурスconnectives，并且在不同的语言理解任务下，不同的连接类型的计算处理复杂性并不总是一致于人类处理顺序。此外，人类在阅读过程中可能会受到外部影响，但是这并不一定会影响最终的理解性能。系统对连接知识的更多学习，则会增加不当连接的负面影响。这表明，在计算自然语言处理中，正确地表示连接是重要的。<details>
<summary>Abstract</summary>
The capabilities and use cases of automatic natural language processing (NLP) have grown significantly over the last few years. While much work has been devoted to understanding how humans deal with discourse connectives, this phenomenon is understudied in computational systems. Therefore, it is important to put NLP models under the microscope and examine whether they can adequately comprehend, process, and reason within the complexity of natural language. In this chapter, we introduce the main mechanisms behind automatic sentence processing systems step by step and then focus on evaluating discourse connective processing. We assess nine popular systems in their ability to understand English discourse connectives and analyze how context and language understanding tasks affect their connective comprehension. The results show that NLP systems do not process all discourse connectives equally well and that the computational processing complexity of different connective kinds is not always consistently in line with the presumed complexity order found in human processing. In addition, while humans are more inclined to be influenced during the reading procedure but not necessarily in the final comprehension performance, discourse connectives have a significant impact on the final accuracy of NLP systems. The richer knowledge of connectives a system learns, the more negative effect inappropriate connectives have on it. This suggests that the correct explicitation of discourse connectives is important for computational natural language processing.
</details>
<details>
<summary>摘要</summary>
自过去几年来，自然语言处理（NLP）的能力和使用场景已经增长了很多。然而，在人工系统中对对话连接器的研究仍然不够。因此，我们需要把NLP模型放进显微镜中，检查它们是否能够正确地理解、处理和推理natural language的复杂性。在本章中，我们将介绍自动句子处理系统的主要机制一探析，然后专注于评估英文对话连接器的处理能力。我们评估了9种流行的NLP系统，检查它们在处理英文对话连接器时的能力，并分析了上下文和语言理解任务对其连接器理解的影响。结果显示NLP系统不同的连接器Kinds不一定能够正确地处理，而且computational处理复杂性不一定与人类处理的复杂性相符。此外，人类在阅读过程中可能会受到影响，但是在最终理解性能上不一定会受到影响。对NLP系统而言，正确地使用对话连接器是重要的。
</details></li>
</ul>
<hr>
<h2 id="Large-Content-And-Behavior-Models-To-Understand-Simulate-And-Optimize-Content-And-Behavior"><a href="#Large-Content-And-Behavior-Models-To-Understand-Simulate-And-Optimize-Content-And-Behavior" class="headerlink" title="Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior"></a>Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00359">http://arxiv.org/abs/2309.00359</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashmit Khandelwal, Aditya Agrawal, Aanisha Bhattacharyya, Yaman K Singla, Somesh Singh, Uttaran Bhattacharya, Ishita Dasgupta, Stefano Petrangeli, Rajiv Ratn Shah, Changyou Chen, Balaji Krishnamurthy</li>
<li>for: 这 paper 的目的是提出 Large Content and Behavior Models (LCBMs)，用于解决Receiver 的行为 simulation, content simulation, behavior understanding, 和 behavior domain adaptation 等问题。</li>
<li>methods: 这 paper 使用了 Large Language Models (LLMs) 作为基础模型，并在其上添加了 “behavior tokens” 来增强模型的能力。</li>
<li>results: 这 paper 的实验结果表明，LCBMs 可以在多种任务上表现良好，包括内容理解、行为模拟、内容模拟、行为理解和行为适应性等。此外， paper 还发布了一个新的 Content Behavior Corpus (CBC)，用于推动更多的研究。<details>
<summary>Abstract</summary>
Shannon, in his seminal paper introducing information theory, divided the communication into three levels: technical, semantic, and effectivenss. While the technical level is concerned with accurate reconstruction of transmitted symbols, the semantic and effectiveness levels deal with the inferred meaning and its effect on the receiver. Thanks to telecommunications, the first level problem has produced great advances like the internet. Large Language Models (LLMs) make some progress towards the second goal, but the third level still remains largely untouched. The third problem deals with predicting and optimizing communication for desired receiver behavior. LLMs, while showing wide generalization capabilities across a wide range of tasks, are unable to solve for this. One reason for the underperformance could be a lack of "behavior tokens" in LLMs' training corpora. Behavior tokens define receiver behavior over a communication, such as shares, likes, clicks, purchases, retweets, etc. While preprocessing data for LLM training, behavior tokens are often removed from the corpora as noise. Therefore, in this paper, we make some initial progress towards reintroducing behavior tokens in LLM training. The trained models, other than showing similar performance to LLMs on content understanding tasks, show generalization capabilities on behavior simulation, content simulation, behavior understanding, and behavior domain adaptation. Using a wide range of tasks on two corpora, we show results on all these capabilities. We call these models Large Content and Behavior Models (LCBMs). Further, to spur more research on LCBMs, we release our new Content Behavior Corpus (CBC), a repository containing communicator, message, and corresponding receiver behavior.
</details>
<details>
<summary>摘要</summary>
谱在他的著名论文中介绍信息理论时，将通信分为三级：技术、 semantics 和效果。技术级关心已经传输的符号的准确重建，而 semantics 和效果级则关心接收者对符号的理解和对接收者的影响。 благо于电信技术的发展，技术级问题已经取得了很大的进步，如互联网。然而， semantics 和效果级问题仍然未得到充分解决。第三级问题是预测和优化通信以实现 Desired receiver behavior。LLMs 虽然在各种任务上显示了广泛的泛化能力，但它们无法解决这个问题。一个可能的原因是 LLMs 在训练 corpora 中缺乏 "behavior tokens"。 behavior tokens 定义了通信过程中接收者的行为，如分享、赞、点击、购买、 retweet 等。在 Preprocessing 数据 для LLM 训练时，通常会从 corpora 中除掉 behavior tokens 作为噪音。因此，在这篇论文中，我们在 LLM 训练中重新引入 behavior tokens，并训练 Large Content and Behavior Models (LCBMs)。LCBMs 不仅在内容理解任务上显示类似的表现，还能在行为模拟、内容模拟、行为理解和行为预测域中进行泛化。使用两个 corpora 上的各种任务，我们在所有这些能力上显示了结果。我们称这些模型为 Large Content and Behavior Models (LCBMs)。此外，为了促进更多关于 LCBMs 的研究，我们发布了我们的新 Content Behavior Corpus (CBC)，这是一个包含通信者、消息和相应的接收者行为的Repository。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Topic-Modeling-for-Determinants-of-Divergent-Report-Results-Applied-to-Macular-Degeneration-Studies"><a href="#Comparative-Topic-Modeling-for-Determinants-of-Divergent-Report-Results-Applied-to-Macular-Degeneration-Studies" class="headerlink" title="Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies"></a>Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00312">http://arxiv.org/abs/2309.00312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Cassiel Jacaruso</li>
<li>for: 本研究旨在透过比较主题模型分析不同报告中对同一研究问题的结果进行比较，以找到具有明确相关性和重要结果的主题。</li>
<li>methods: 本研究使用了主题模型分析方法，对具有相关结果的报告进行分类和排序，以确定具有最高相关性和最高效果的主题。</li>
<li>results: 研究发现了8种补充食品具有显著关系与有效结果的主题，其中6种得到了验证性的证据，即omega-3脂肪酸、氧化铁、萝芽素、兰氨酸、锌和氮氧化物。两种未得到验证（niacin和摩尔丹）也得到了最低分，这表明提议的方法可以用来评价主题的相关性。<details>
<summary>Abstract</summary>
Topic modeling and text mining are subsets of Natural Language Processing with relevance for conducting meta-analysis (MA) and systematic review (SR). For evidence synthesis, the above NLP methods are conventionally used for topic-specific literature searches or extracting values from reports to automate essential phases of SR and MA. Instead, this work proposes a comparative topic modeling approach to analyze reports of contradictory results on the same general research question. Specifically, the objective is to find topics exhibiting distinct associations with significant results for an outcome of interest by ranking them according to their proportional occurrence and consistency of distribution across reports of significant results. The proposed method was tested on broad-scope studies addressing whether supplemental nutritional compounds significantly benefit macular degeneration (MD). Eight compounds were identified as having a particular association with reports of significant results for benefitting MD. Six of these were further supported in terms of effectiveness upon conducting a follow-up literature search for validation (omega-3 fatty acids, copper, zeaxanthin, lutein, zinc, and nitrates). The two not supported by the follow-up literature search (niacin and molybdenum) also had the lowest scores under the proposed methods ranking system, suggesting that the proposed method's score for a given topic is a viable proxy for its degree of association with the outcome of interest. These results underpin the proposed methods potential to add specificity in understanding effects from broad-scope reports, elucidate topics of interest for future research, and guide evidence synthesis in a systematic and scalable way.
</details>
<details>
<summary>摘要</summary>
Topic模型和文本挖掘是自然语言处理的子集，对于进行元分析（MA）和系统性综述（SR）有直接的应用。在证据整合中，这些自然语言处理方法通常用于特定主题的文献搜索或自动化SR和MA的关键阶段。然而，这项工作提出了比较主题模型方法，用于分析对同一个全面研究问题的报告中的不同结果。具体来说，目标是找到具有特定关系的主题，其中结果对于评价预测变量的占比和报告中的分布一致性高。这种方法在对眼肤肉营养剂的研究中进行了测试，并将八种成分确定为对有效结果报告具有特定关系。其中六种（ω-3脂肪酸、铁、杂色素、苷酸、锌和氮原子）在验证性文献搜索中得到了支持，而剩下两种（niacin和硫）则没有得到支持，其分数也相应较低，这表明该方法的分数可以作为一种可靠的评价指标。这些结果证明了该方法的潜在价值，可以增加特定的证据整合，解释特定主题，为未来研究提供指导，并在系统和可扩展的方式下进行证据整合。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-the-vocal-range-of-single-speaker-singing-voice-synthesis-with-melody-unsupervised-pre-training"><a href="#Enhancing-the-vocal-range-of-single-speaker-singing-voice-synthesis-with-melody-unsupervised-pre-training" class="headerlink" title="Enhancing the vocal range of single-speaker singing voice synthesis with melody-unsupervised pre-training"></a>Enhancing the vocal range of single-speaker singing voice synthesis with melody-unsupervised pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00284">http://arxiv.org/abs/2309.00284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaohuan Zhou, Xu Li, Zhiyong Wu, Ying Shan, Helen Meng</li>
<li>for: 提高单声道合唱音色的 vocal range</li>
<li>methods: 使用多种者预训练方法，不影响音色一致性</li>
<li>results: 提高合唱音质和自然性，比基eline更高<details>
<summary>Abstract</summary>
The single-speaker singing voice synthesis (SVS) usually underperforms at pitch values that are out of the singer's vocal range or associated with limited training samples. Based on our previous work, this work proposes a melody-unsupervised multi-speaker pre-training method conducted on a multi-singer dataset to enhance the vocal range of the single-speaker, while not degrading the timbre similarity. This pre-training method can be deployed to a large-scale multi-singer dataset, which only contains audio-and-lyrics pairs without phonemic timing information and pitch annotation. Specifically, in the pre-training step, we design a phoneme predictor to produce the frame-level phoneme probability vectors as the phonemic timing information and a speaker encoder to model the timbre variations of different singers, and directly estimate the frame-level f0 values from the audio to provide the pitch information. These pre-trained model parameters are delivered into the fine-tuning step as prior knowledge to enhance the single speaker's vocal range. Moreover, this work also contributes to improving the sound quality and rhythm naturalness of the synthesized singing voices. It is the first to introduce a differentiable duration regulator to improve the rhythm naturalness of the synthesized voice, and a bi-directional flow model to improve the sound quality. Experimental results verify that the proposed SVS system outperforms the baseline on both sound quality and naturalness.
</details>
<details>
<summary>摘要</summary>
单个 speaker 歌唱voice 合成（SVS）通常在声部范围外或有限训练样本下表现不佳。基于我们的前一项工作，这项工作提出了一种不带预教学样本的多 speaker 预训练方法，以提高单个 speaker 的声部范围，不会影响声音相似性。这种预训练方法可以应用于大规模多 singer 数据集，只包含音频和歌词对应的数据。具体来说，在预训练步骤中，我们设计了一个音频预测器，生成音频帧级别的phoneme 概率 вектор作为声音时间信息，以及一个 speaker 编码器，模型不同 singer 的声音变化，直接从音频中提取帧级别的f0值作为抽象信息。这些预训练模型参数被送入细化步骤作为先验知识，以提高单个 speaker 的声部范围。此外，这项工作还提出了改进合成 singing voice 的音质和节奏自然性的方法，包括引入分配duration 调节器以提高合成声音的节奏自然性，以及bi-directional 流模型以提高音质。实验结果表明，提出的 SVS 系统在音质和自然性两个方面都高于基eline。
</details></li>
</ul>
<hr>
<h2 id="Why-do-universal-adversarial-attacks-work-on-large-language-models-Geometry-might-be-the-answer"><a href="#Why-do-universal-adversarial-attacks-work-on-large-language-models-Geometry-might-be-the-answer" class="headerlink" title="Why do universal adversarial attacks work on large language models?: Geometry might be the answer"></a>Why do universal adversarial attacks work on large language models?: Geometry might be the answer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00254">http://arxiv.org/abs/2309.00254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Varshini Subhash, Anna Bialas, Weiwei Pan, Finale Doshi-Velez</li>
<li>for: 本研究旨在解释大语言模型中对抗攻击的内部机制，尤其是对于 Gradient-based universal adversarial attacks 的理解。</li>
<li>methods: 本研究使用了一种新的几何视角来解释大语言模型中 universal adversarial attacks 的机制。研究者通过对 GPT-2 模型进行攻击，发现了一种可能的观察结果，即攻击触发器可能是 embedding vectors 的一种近似。</li>
<li>results: 研究者通过对 GPT-2 模型进行白盒模型分析，包括维度减少和隐藏表示相似度测量，发现了这种观察结果的证据。这种新的几何视角可能会帮助我们更深入地理解大语言模型的内部工作机制和失效模式，从而实现其防范。<details>
<summary>Abstract</summary>
Transformer based large language models with emergent capabilities are becoming increasingly ubiquitous in society. However, the task of understanding and interpreting their internal workings, in the context of adversarial attacks, remains largely unsolved. Gradient-based universal adversarial attacks have been shown to be highly effective on large language models and potentially dangerous due to their input-agnostic nature. This work presents a novel geometric perspective explaining universal adversarial attacks on large language models. By attacking the 117M parameter GPT-2 model, we find evidence indicating that universal adversarial triggers could be embedding vectors which merely approximate the semantic information in their adversarial training region. This hypothesis is supported by white-box model analysis comprising dimensionality reduction and similarity measurement of hidden representations. We believe this new geometric perspective on the underlying mechanism driving universal attacks could help us gain deeper insight into the internal workings and failure modes of LLMs, thus enabling their mitigation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Detecting-Suicidality-in-Arabic-Tweets-Using-Machine-Learning-and-Deep-Learning-Techniques"><a href="#Detecting-Suicidality-in-Arabic-Tweets-Using-Machine-Learning-and-Deep-Learning-Techniques" class="headerlink" title="Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep Learning Techniques"></a>Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00246">http://arxiv.org/abs/2309.00246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asma Abdulsalam, Areej Alhothali, Saleh Al-Ghamdi</li>
<li>For: The paper aims to develop a novel dataset of Arabic tweets related to suicidal thoughts and use machine learning and deep learning models to automatically detect suicidal ideation in these tweets.* Methods: The paper uses a variety of machine learning and deep learning models, including Na&quot;ive Bayes, Support Vector Machine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word frequency and word embedding features, as well as pre-trained deep learning models such as AraBert, AraELECTRA, and AraGPT2, to identify suicidal thoughts in Arabic tweets.* Results: The results show that the SVM and RF models trained on character n-gram features provided the best performance, with an accuracy of 86% and an F1 score of 79%. The AraBert model outperforms other machine and deep learning models, achieving an accuracy of 91% and an F1-score of 88%, significantly improving the detection of suicidal ideation in the Arabic tweets dataset.Here are the three points in Simplified Chinese:* For: 这个论文的目的是开发一个关于自杀思想的阿拉伯语推文数据集，并使用机器学习和深度学习模型自动检测这些推文中的自杀意图。* Methods: 这个论文使用了多种机器学习和深度学习模型，包括Na&quot;ive Bayes、支持向量机、K-近邻 neighbors、Random Forest和XGBoost，使用单词频率和单词嵌入特征进行训练，以及预训练的深度学习模型如AraBert、AraELECTRA和AraGPT2，来识别阿拉伯语推文中的自杀思想。* Results: 结果显示，SVM和RF模型使用单词n-gram特征进行训练时提供了最好的性能，具有86%的准确率和79%的F1分数。AraBert模型在其他机器和深度学习模型之上表现出色，达到91%的准确率和88%的F1分数，显著提高了阿拉伯语推文中自杀意图的检测。<details>
<summary>Abstract</summary>
Social media platforms have revolutionized traditional communication techniques by enabling people globally to connect instantaneously, openly, and frequently. People use social media to share personal stories and express their opinion. Negative emotions such as thoughts of death, self-harm, and hardship are commonly expressed on social media, particularly among younger generations. As a result, using social media to detect suicidal thoughts will help provide proper intervention that will ultimately deter others from self-harm and committing suicide and stop the spread of suicidal ideation on social media. To investigate the ability to detect suicidal thoughts in Arabic tweets automatically, we developed a novel Arabic suicidal tweets dataset, examined several machine learning models, including Na\"ive Bayes, Support Vector Machine, K-Nearest Neighbor, Random Forest, and XGBoost, trained on word frequency and word embedding features, and investigated the ability of pre-trained deep learning models, AraBert, AraELECTRA, and AraGPT2, to identify suicidal thoughts in Arabic tweets. The results indicate that SVM and RF models trained on character n-gram features provided the best performance in the machine learning models, with 86% accuracy and an F1 score of 79%. The results of the deep learning models show that AraBert model outperforms other machine and deep learning models, achieving an accuracy of 91\% and an F1-score of 88%, which significantly improves the detection of suicidal ideation in the Arabic tweets dataset. To the best of our knowledge, this is the first study to develop an Arabic suicidality detection dataset from Twitter and to use deep-learning approaches in detecting suicidality in Arabic posts.
</details>
<details>
<summary>摘要</summary>
社交媒体平台已经革命化了传统的沟通方式，让人们全球协同交流、开放地分享自己的故事和看法。人们通过社交媒体分享自己的个人经历和表达自己的看法。特别是年轻一代，常常在社交媒体上表达自杀的思想和自危的情感。因此，通过社交媒体检测自杀思想可以提供适当的干预措施，ultimately prevent others from self-harm and suicide, and stop the spread of suicidal ideation on social media.为了研究自动检测阿拉伯语自杀思想的能力，我们创建了一个新的阿拉伯语自杀吟话集合，检验了多种机器学习模型，包括顺序规则模型、支持向量机器学习模型、最近邻居模型、随机森林模型和XGBoost模型。我们使用单词频和单词嵌入特征进行训练，并研究了预训练深度学习模型AraBert、AraELECTRA和AraGPT2的能力来识别阿拉伯语自杀思想。结果显示，SVM和RF模型在机器学习模型中表现最佳，具有86%的准确率和79%的F1分数。深度学习模型的结果表明，AraBert模型在其他机器和深度学习模型中表现出色，达到了91%的准确率和88%的F1分数，对阿拉伯语自杀吟话集合的检测提供了显著改善。据我们所知，这是首次从Twitter上创建了阿拉伯语自杀性检测dataset，并使用深度学习方法来检测阿拉伯语自杀思想。
</details></li>
</ul>
<hr>
<h2 id="NeuroSurgeon-A-Toolkit-for-Subnetwork-Analysis"><a href="#NeuroSurgeon-A-Toolkit-for-Subnetwork-Analysis" class="headerlink" title="NeuroSurgeon: A Toolkit for Subnetwork Analysis"></a>NeuroSurgeon: A Toolkit for Subnetwork Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00244">http://arxiv.org/abs/2309.00244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlepori1/neurosurgeon">https://github.com/mlepori1/neurosurgeon</a></li>
<li>paper_authors: Michael A. Lepori, Ellie Pavlick, Thomas Serre</li>
<li>for: 了解神经网络模型中学习的算法。</li>
<li>methods: 使用Python库NeuroSurgeon对Transformers库中的模型进行发现和操作。</li>
<li>results: 可以帮助研究人员更好地理解和修改神经网络模型。<details>
<summary>Abstract</summary>
Despite recent advances in the field of explainability, much remains unknown about the algorithms that neural networks learn to represent. Recent work has attempted to understand trained models by decomposing them into functional circuits (Csord\'as et al., 2020; Lepori et al., 2023). To advance this research, we developed NeuroSurgeon, a python library that can be used to discover and manipulate subnetworks within models in the Huggingface Transformers library (Wolf et al., 2019). NeuroSurgeon is freely available at https://github.com/mlepori1/NeuroSurgeon.
</details>
<details>
<summary>摘要</summary>
尽管最近在神经网络解释领域有所进步，仍然有很多关于神经网络学习的表示方法未知。最近的研究尝试了通过分解神经网络模型为功能电路来理解训练后模型（Csordás et al., 2020; Lepori et al., 2023）。为了进一步推进这项研究，我们开发了一个名为NeuroSurgeon的Python库，可以用于发现和操作在Huggingface Transformers库中的子网络（Wolf et al., 2019）。NeuroSurgeon是免费释出的，可以在https://github.com/mlepori1/NeuroSurgeon上下载。
</details></li>
</ul>
<hr>
<h2 id="Image-Hijacks-Adversarial-Images-can-Control-Generative-Models-at-Runtime"><a href="#Image-Hijacks-Adversarial-Images-can-Control-Generative-Models-at-Runtime" class="headerlink" title="Image Hijacks: Adversarial Images can Control Generative Models at Runtime"></a>Image Hijacks: Adversarial Images can Control Generative Models at Runtime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00236">http://arxiv.org/abs/2309.00236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/euanong/image-hijacks">https://github.com/euanong/image-hijacks</a></li>
<li>paper_authors: Luke Bailey, Euan Ong, Stuart Russell, Scott Emmons</li>
<li>for: 本研究探讨了基础模型是否具有恶意攻击者的安全性？研究者发现了图像劫驱，即在运行时控制生成模型的恶意图像。</li>
<li>methods: 研究者提出了一种普适的方法 named Behaviour Matching，用于创造图像劫驱。他们使用这种方法来探索三种类型的攻击。</li>
<li>results: 研究者在使用 LLaVA 和 LLaMA-2 模型进行测试时发现，所有的攻击类型都有超过 90% 的成功率。此外，这些攻击都是自动化的，只需要小的图像偏移即可实现。这些发现表明基础模型的安全性存在严重的问题。<details>
<summary>Abstract</summary>
Are foundation models secure from malicious actors? In this work, we focus on the image input to a vision-language model (VLM). We discover image hijacks, adversarial images that control generative models at runtime. We introduce Behaviour Matching, a general method for creating image hijacks, and we use it to explore three types of attacks. Specific string attacks generate arbitrary output of the adversary's choice. Leak context attacks leak information from the context window into the output. Jailbreak attacks circumvent a model's safety training. We study these attacks against LLaVA, a state-of-the-art VLM based on CLIP and LLaMA-2, and find that all our attack types have above a 90% success rate. Moreover, our attacks are automated and require only small image perturbations. These findings raise serious concerns about the security of foundation models. If image hijacks are as difficult to defend against as adversarial examples in CIFAR-10, then it might be many years before a solution is found -- if it even exists.
</details>
<details>
<summary>摘要</summary>
Foundation models 是否安全免受黑客攻击？在这项工作中，我们关注vision-language模型（VLM）中的图像输入。我们发现图像劫持，也就是在运行时使用恶意图像控制生成模型的攻击。我们提出了行为匹配方法，可以创造图像劫持，并使用它来探索三种攻击方式。特定的字符串攻击可以生成对手选择的任意输出。泄露上下文攻击可以从上下文窗口中泄露信息到输出中。囚禁攻击可以绕过模型的安全训练。我们对LLaVA模型，基于CLIP和LLaMA-2，进行了研究，发现所有我们的攻击类型具有超过90%的成功率。此外，我们的攻击是自动化的，只需要小型图像变化即可。这些发现对基础模型的安全提出了严重的问题。如果图像劫持与CIFAR-10中的对抗性例子一样难以防御，那么可能需要很多年才能找到解决方案——如果其even exists。
</details></li>
</ul>
<hr>
<h2 id="JoTR-A-Joint-Transformer-and-Reinforcement-Learning-Framework-for-Dialog-Policy-Learning"><a href="#JoTR-A-Joint-Transformer-and-Reinforcement-Learning-Framework-for-Dialog-Policy-Learning" class="headerlink" title="JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning"></a>JoTR: A Joint Transformer and Reinforcement Learning Framework for Dialog Policy Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00230">http://arxiv.org/abs/2309.00230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kwanwaichung/jotr">https://github.com/kwanwaichung/jotr</a></li>
<li>paper_authors: Wai-Chung Kwan, Huimin Wang, Hongru Wang, Zezhong Wang, Xian Wu, Yefeng Zheng, Kam-Fai Wong</li>
<li>for: 本研究的目的是提出一种新的对话政策学习方法，以提高对话模型的性能和多样性。</li>
<li>methods: 本研究使用了一种基于Transformer的文本对话模型，通过Word级对话策略来生成灵活的对话行为。此外，本研究还使用了奖励学习和奖励托管机制来有效地训练对话策略。</li>
<li>results: 经过广泛的评估，本研究的JoTR方法在两个对话模型任务上达到了领先的状态。User simulator和人工评估者都认为JoTR的性能有所提高。<details>
<summary>Abstract</summary>
Dialogue policy learning (DPL) is a crucial component of dialogue modelling. Its primary role is to determine the appropriate abstract response, commonly referred to as the "dialogue action". Traditional DPL methodologies have treated this as a sequential decision problem, using pre-defined action candidates extracted from a corpus. However, these incomplete candidates can significantly limit the diversity of responses and pose challenges when dealing with edge cases, which are scenarios that occur only at extreme operating parameters. To address these limitations, we introduce a novel framework, JoTR. This framework is unique as it leverages a text-to-text Transformer-based model to generate flexible dialogue actions. Unlike traditional methods, JoTR formulates a word-level policy that allows for a more dynamic and adaptable dialogue action generation, without the need for any action templates. This setting enhances the diversity of responses and improves the system's ability to handle edge cases effectively. In addition, JoTR employs reinforcement learning with a reward-shaping mechanism to efficiently finetune the word-level dialogue policy, which allows the model to learn from its interactions, improving its performance over time. We conducted an extensive evaluation of JoTR to assess its effectiveness. Our extensive evaluation shows that JoTR achieves state-of-the-art performance on two benchmark dialogue modelling tasks, as assessed by both user simulators and human evaluators.
</details>
<details>
<summary>摘要</summary>
对话政策学习（DPL）是对话模型的一个重要组件。其主要职责是确定合适的抽象回复，通常称为对话动作。传统的DPL方法ologies treat this as a sequential decision problem, using pre-defined action candidates extracted from a corpus。然而，这些不完整的候选者可以很大地限制对话的多样性和处理边缘情况的能力。为解决这些限制，我们介绍了一个新的框架，JoTR。这个框架独特之处在于它利用了文本到文本的Transformer模型来生成灵活的对话动作。与传统方法不同，JoTR定义了字词级对话政策，允许对话动作生成更加动态和适应性强，无需任何动作模板。这种设置可以提高对话的多样性和对边缘情况的处理能力。此外，JoTR使用了奖励学习和形成机制来有效地训练字词级对话政策，让模型通过与人类互动学习并改进自己的性能。我们进行了广泛的评估，结果显示JoTR在两个标准对话模型任务上达到了当今最佳性能，并且被用户模拟器和人类评估器评为优秀。
</details></li>
</ul>
<hr>
<h2 id="The-FruitShell-French-synthesis-system-at-the-Blizzard-2023-Challenge"><a href="#The-FruitShell-French-synthesis-system-at-the-Blizzard-2023-Challenge" class="headerlink" title="The FruitShell French synthesis system at the Blizzard 2023 Challenge"></a>The FruitShell French synthesis system at the Blizzard 2023 Challenge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00223">http://arxiv.org/abs/2309.00223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Qi, Xiaopeng Wang, Zhiyong Wang, Wang Liu, Mingming Ding, Shuchen Shi</li>
<li>for: 本研究提出了一个用于2023年Blizzard挑战的法文文本读取系统。这个挑战包括两个任务：生成高品质的女性读者的语音，以及将语音与具体的个人联系起来。</li>
<li>methods: 我们对竞赛数据进行了筛选程序，以移除遗传或错误的文本数据。我们将所有符号除非是phoneme外，并删除没有读音或零时间的符号。此外，我们将文本中的字界限和开始&#x2F;结束符号添加到文本中，以改善语音质量。在Spoke任务中，我们遵循竞赛规则进行数据增强。我们使用了一个开源的G2P模型来将法文转换为phoneme。由于G2P模型使用国际音律字母表（IPA），我们将竞赛数据转换为IPA标示法。但由于编译器无法识别竞赛数据中的特殊符号，我们按照规则将所有phoneme转换为竞赛数据中使用的音律字母表。最后，我们将所有竞赛音频标准化到16 kHz的样本率。</li>
<li>results: 我们的系统在Hub任务中得到了3.6的质量MOS分数，在Spoke任务中得到了3.4的质量MOS分数，与所有参赛队伍的平均水平相当。<details>
<summary>Abstract</summary>
This paper presents a French text-to-speech synthesis system for the Blizzard Challenge 2023. The challenge consists of two tasks: generating high-quality speech from female speakers and generating speech that closely resembles specific individuals. Regarding the competition data, we conducted a screening process to remove missing or erroneous text data. We organized all symbols except for phonemes and eliminated symbols that had no pronunciation or zero duration. Additionally, we added word boundary and start/end symbols to the text, which we have found to improve speech quality based on our previous experience. For the Spoke task, we performed data augmentation according to the competition rules. We used an open-source G2P model to transcribe the French texts into phonemes. As the G2P model uses the International Phonetic Alphabet (IPA), we applied the same transcription process to the provided competition data for standardization. However, due to compiler limitations in recognizing special symbols from the IPA chart, we followed the rules to convert all phonemes into the phonetic scheme used in the competition data. Finally, we resampled all competition audio to a uniform sampling rate of 16 kHz. We employed a VITS-based acoustic model with the hifigan vocoder. For the Spoke task, we trained a multi-speaker model and incorporated speaker information into the duration predictor, vocoder, and flow layers of the model. The evaluation results of our system showed a quality MOS score of 3.6 for the Hub task and 3.4 for the Spoke task, placing our system at an average level among all participating teams.
</details>
<details>
<summary>摘要</summary>
Regarding the competition data, we conducted a screening process to remove missing or erroneous text data. We organized all symbols except for phonemes and eliminated symbols that had no pronunciation or zero duration. Additionally, we added word boundary and start/end symbols to the text, which we have found to improve speech quality based on our previous experience.For the Spoke task, we performed data augmentation according to the competition rules. We used an open-source G2P model to transcribe the French texts into phonemes. As the G2P model uses the International Phonetic Alphabet (IPA), we applied the same transcription process to the provided competition data for standardization. However, due to compiler limitations in recognizing special symbols from the IPA chart, we followed the rules to convert all phonemes into the phonetic scheme used in the competition data.Finally, we resampled all competition audio to a uniform sampling rate of 16 kHz. We employed a VITS-based acoustic model with the hifigan vocoder. For the Spoke task, we trained a multi-speaker model and incorporated speaker information into the duration predictor, vocoder, and flow layers of the model.The evaluation results of our system showed a quality MOS score of 3.6 for the Hub task and 3.4 for the Spoke task, placing our system at an average level among all participating teams.
</details></li>
</ul>
<hr>
<h2 id="Towards-Addressing-the-Misalignment-of-Object-Proposal-Evaluation-for-Vision-Language-Tasks-via-Semantic-Grounding"><a href="#Towards-Addressing-the-Misalignment-of-Object-Proposal-Evaluation-for-Vision-Language-Tasks-via-Semantic-Grounding" class="headerlink" title="Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding"></a>Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00215">http://arxiv.org/abs/2309.00215</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JoshuaFeinglass/VL-detector-eval">https://github.com/JoshuaFeinglass/VL-detector-eval</a></li>
<li>paper_authors: Joshua Feinglass, Yezhou Yang</li>
<li>for: 本研究旨在探讨目标框生成器在视觉语言任务中的性能评价协议是否准确，以及如何使用语义固定来缓解这一问题。</li>
<li>methods: 我们提出了一种新的评价方法，即根据图像描述文本中的Semantic信息来选择合适的注释 subset，并对这些注释进行评价。</li>
<li>results: 我们的方法能够准确地选择与视觉语言任务相关的注释 subset，并且与现有的评价方法相比，能够更好地反映图像描述文本中的Semantic信息。<details>
<summary>Abstract</summary>
Object proposal generation serves as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). The performance of object proposals generated for VL tasks is currently evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. Importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existing techniques. Lastly, we compare current detectors used in the Scene Graph Generation (SGG) benchmark as a use case, which serves as an example of when traditional object proposal evaluation techniques are misaligned.
</details>
<details>
<summary>摘要</summary>
Object proposal generation acts as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). Currently, the performance of object proposals generated for VL tasks is evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. The importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existing techniques. Finally, we compare current detectors used in the Scene Graph Generation (SGG) benchmark as a use case, which serves as an example of when traditional object proposal evaluation techniques are misaligned.Here's the translation in Traditional Chinese:Object proposal generation acts as a standard pre-processing step in Vision-Language (VL) tasks (image captioning, visual question answering, etc.). Currently, the performance of object proposals generated for VL tasks is evaluated across all available annotations, a protocol that we show is misaligned - higher scores do not necessarily correspond to improved performance on downstream VL tasks. Our work serves as a study of this phenomenon and explores the effectiveness of semantic grounding to mitigate its effects. To this end, we propose evaluating object proposals against only a subset of available annotations, selected by thresholding an annotation importance score. The importance of object annotations to VL tasks is quantified by extracting relevant semantic information from text describing the image. We show that our method is consistent and demonstrates greatly improved alignment with annotations selected by image captioning metrics and human annotation when compared against existing techniques. Finally, we compare current detectors used in the Scene Graph Generation (SGG) benchmark as a use case, which serves as an example of when traditional object proposal evaluation techniques are misaligned.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-law-of-text-geographic-information"><a href="#Exploring-the-law-of-text-geographic-information" class="headerlink" title="Exploring the law of text geographic information"></a>Exploring the law of text geographic information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00180">http://arxiv.org/abs/2309.00180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhua Wang, Daiyu Zhang, Ming Ren, Guang Xu</li>
<li>for: 该论文的目的是探讨文本地理信息的分布特性以及人类使用它的限制。</li>
<li>methods: 该论文采用了严格的实验方法，测试了24种不同语言和类型的地理信息数据集，以验证人类使用地理信息的假设。</li>
<li>results: 研究发现，地理信息呈Gamma分布，其中的量、长度和距离受到人类行为、认知、表达和思维过程的影响。此外，与 Gaussian 分布和Zipf 法律进行了比较，并证明了这些法律的无关性。这些结果可能有助于探索未知的地理信息领域。<details>
<summary>Abstract</summary>
Textual geographic information is indispensable and heavily relied upon in practical applications. The absence of clear distribution poses challenges in effectively harnessing geographic information, thereby driving our quest for exploration. We contend that geographic information is influenced by human behavior, cognition, expression, and thought processes, and given our intuitive understanding of natural systems, we hypothesize its conformity to the Gamma distribution. Through rigorous experiments on a diverse range of 24 datasets encompassing different languages and types, we have substantiated this hypothesis, unearthing the underlying regularities governing the dimensions of quantity, length, and distance in geographic information. Furthermore, theoretical analyses and comparisons with Gaussian distributions and Zipf's law have refuted the contingency of these laws. Significantly, we have estimated the upper bounds of human utilization of geographic information, pointing towards the existence of uncharted territories. Also, we provide guidance in geographic information extraction. Hope we peer its true countenance uncovering the veil of geographic information.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Will-Sentiment-Analysis-Need-Subculture-A-New-Data-Augmentation-Approach"><a href="#Will-Sentiment-Analysis-Need-Subculture-A-New-Data-Augmentation-Approach" class="headerlink" title="Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach"></a>Will Sentiment Analysis Need Subculture? A New Data Augmentation Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00178">http://arxiv.org/abs/2309.00178</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhua Wang, Simin He, Guang Xu, Ming Ren</li>
<li>for: 强调文化价值和情感分析的研究，addressing the insufficient training data faced by sentiment analysis.</li>
<li>methods: 提出了一种基于子文化表达生成器的数据增强方法（SCDA），通过生成6种不同的子文化表达来生成6种增强文本。</li>
<li>results: 实验证明了SCDA的有效性和可能性，同时也发现了不同子文化表达对情感刺激的不同程度。此外，研究还发现了一种 linear reversibility 的现象，即某些子文化表达可以逆向转换为另一种子文化表达。<details>
<summary>Abstract</summary>
The renowned proverb that "The pen is mightier than the sword" underscores the formidable influence wielded by text expressions in shaping sentiments. Indeed, well-crafted written can deeply resonate within cultures, conveying profound sentiments. Nowadays, the omnipresence of the Internet has fostered a subculture that congregates around the contemporary milieu. The subculture artfully articulates the intricacies of human feelings by ardently pursuing the allure of novelty, a fact that cannot be disregarded in the sentiment analysis. This paper strives to enrich data through the lens of subculture, to address the insufficient training data faced by sentiment analysis. To this end, a new approach of subculture-based data augmentation (SCDA) is proposed, which engenders six enhanced texts for each training text by leveraging the creation of six diverse subculture expression generators. The extensive experiments attest to the effectiveness and potential of SCDA. The results also shed light on the phenomenon that disparate subculture expressions elicit varying degrees of sentiment stimulation. Moreover, an intriguing conjecture arises, suggesting the linear reversibility of certain subculture expressions. It is our fervent aspiration that this study serves as a catalyst in fostering heightened perceptiveness towards the tapestry of information, sentiment and culture, thereby enriching our collective understanding.
</details>
<details>
<summary>摘要</summary>
“著名的谚语“笔子比剑更强”强调了文字表达在形塑情感的力量。实际上，美妙地撰写的文字可以深深地感染到文化中，传递出深刻的情感。在现代社会，互联网的普遍化使得文化 subgroup 形成了一种新的互文化环境，这种环境通过积极追求新鲜的感受，突出了情感分析的不足。为了解决这问题，本文提出了一种基于互文化的数据增强方法（SCDA），通过创造六种不同的互文化表达生成器来生成六个增强的文本。实验证明了SCDA的有效性和潜力。结果还暴露了一种有趣的推测：一些互文化表达的差异会引起不同的情感刺激。此外，这种研究也鼓励我们更加珍惜信息、情感和文化的多样性，以推动我们的共同理解的深化。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/01/cs.CL_2023_09_01/" data-id="clogxf3lp00a15xra1sz2gjs6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/43/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/42/">42</a><a class="page-number" href="/page/43/">43</a><span class="page-number current">44</span><a class="page-number" href="/page/45/">45</a><a class="page-number" href="/page/46/">46</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/45/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
