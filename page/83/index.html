
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/83/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/cs.SD_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T15:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/cs.SD_2023_07_02/">cs.SD - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Don’t-Stop-Self-Supervision-Accent-Adaptation-of-Speech-Representations-via-Residual-Adapters"><a href="#Don’t-Stop-Self-Supervision-Accent-Adaptation-of-Speech-Representations-via-Residual-Adapters" class="headerlink" title="Don’t Stop Self-Supervision: Accent Adaptation of Speech Representations via Residual Adapters"></a>Don’t Stop Self-Supervision: Accent Adaptation of Speech Representations via Residual Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00453">http://arxiv.org/abs/2307.00453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anshu Bhatia, Sanchit Sinha, Saket Dingliwal, Karthik Gopalakrishnan, Sravan Bodapati, Katrin Kirchhoff<br>for: 实现自动话语识别（ASR） tasks中的表现，尤其是针对非标准的话者口音 population。methods: 使用自我超级vised learning方法从大量无标注的话语数据库中学习speech表现，并训练具有口音特点的residual adapter来自适应非标准的话者口音。results: 在4种口音中实现了强大的word error rate reduction（WERR），较HuBERT-large更好，具体来说是22.7%。此外，我们还证明了我们的方法是model和task-agnostic的。<details>
<summary>Abstract</summary>
Speech representations learned in a self-supervised fashion from massive unlabeled speech corpora have been adapted successfully toward several downstream tasks. However, such representations may be skewed toward canonical data characteristics of such corpora and perform poorly on atypical, non-native accented speaker populations. With the state-of-the-art HuBERT model as a baseline, we propose and investigate self-supervised adaptation of speech representations to such populations in a parameter-efficient way via training accent-specific residual adapters. We experiment with 4 accents and choose automatic speech recognition (ASR) as the downstream task of interest. We obtain strong word error rate reductions (WERR) over HuBERT-large for all 4 accents, with a mean WERR of 22.7% with accent-specific adapters and a mean WERR of 25.1% if the entire encoder is accent-adapted. While our experiments utilize HuBERT and ASR as the downstream task, our proposed approach is both model and task-agnostic.
</details>
<details>
<summary>摘要</summary>
自然语音训练集中学习的自我超vised的语音表示方式，经验到了多种下游任务的适应。然而，这些表示方式可能受到大量无标注语音训练集的典型数据特征的偏见，对非典型、非本地口音 speaker  populations 表现不佳。基于当前顶峰 HuBERT 模型，我们提议并 investigate 自parameter-efficient 的方式，通过训练口音Specific residual adapter 来适应 speech 表示到这些 populations。我们实验了 4 种口音，选择了自动语音识别 (ASR) 作为下游任务。我们获得了所有 4 种口音的强大字误率减少 (WERR)，与 HuBERT-large 的mean WERR 相比， mean WERR 为 22.7%，全encoder 适应 WERR 为 25.1%。虽然我们的实验使用 HuBERT 和 ASR 作为下游任务，但我们提议的方法是模型和任务agnostic。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/cs.SD_2023_07_02/" data-id="cloimipcv00r6s48882pme4rx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/eess.AS_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T14:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/eess.AS_2023_07_02/">eess.AS - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Using-joint-training-speaker-encoder-with-consistency-loss-to-achieve-cross-lingual-voice-conversion-and-expressive-voice-conversion"><a href="#Using-joint-training-speaker-encoder-with-consistency-loss-to-achieve-cross-lingual-voice-conversion-and-expressive-voice-conversion" class="headerlink" title="Using joint training speaker encoder with consistency loss to achieve cross-lingual voice conversion and expressive voice conversion"></a>Using joint training speaker encoder with consistency loss to achieve cross-lingual voice conversion and expressive voice conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00393">http://arxiv.org/abs/2307.00393</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ConsistencyVC/ConsistencyVC-voive-conversion">https://github.com/ConsistencyVC/ConsistencyVC-voive-conversion</a></li>
<li>paper_authors: Houjian Guo, Chaoran Liu, Carlos Toshinori Ishi, Hiroshi Ishiguro</li>
<li>for: 这篇论文主要用于提高跨语言语音转换的性能，并且能够保持语音的自然性和特点。</li>
<li>methods: 本研究使用了一个共同训练的话员码生成器和跨语言语音识别模型Whisper的内容特征，以达到高品质的跨语言语音转换。另外，我们还引入了一个话员一致损失到共同encoder中，以提高转换后的语音与引用语音之间的一致性。</li>
<li>results: 研究发现，使用joint speaker encoder和phonetic posteriorgram可以实现高品质的跨语言语音转换，并且能够保持语音的自然性和特点。<details>
<summary>Abstract</summary>
Voice conversion systems have made significant advancements in terms of naturalness and similarity in common voice conversion tasks. However, their performance in more complex tasks such as cross-lingual voice conversion and expressive voice conversion remains imperfect. In this study, we propose a novel approach that combines a jointly trained speaker encoder and content features extracted from the cross-lingual speech recognition model Whisper to achieve high-quality cross-lingual voice conversion. Additionally, we introduce a speaker consistency loss to the joint encoder, which improves the similarity between the converted speech and the reference speech. To further explore the capabilities of the joint speaker encoder, we use the phonetic posteriorgram as the content feature, which enables the model to effectively reproduce both the speaker characteristics and the emotional aspects of the reference speech.
</details>
<details>
<summary>摘要</summary>
声音转换系统在日常声音转换任务中已经取得了显著的进步，但在跨语言声音转换和表情声音转换方面的表现仍然不够完美。在这项研究中，我们提出了一种新的方法， combinig a jointly trained speaker encoder和从跨语言语音识别模型Whisper提取的内容特征，以实现高质量的跨语言声音转换。此外，我们还添加了一个说话者一致性损失到联合编码器中，使模型能够更好地保持说话者的一致性。为了更好地探索联合说话者编码器的能力，我们使用了phonetic posteriorgram作为内容特征，这使得模型能够有效地复制参照语音中的说话者特征和情感特征。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/eess.AS_2023_07_02/" data-id="cloimipf300xms4884s822slt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/cs.CV_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T13:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/cs.CV_2023_07_02/">cs.CV - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="X-MLP-A-Patch-Embedding-Free-MLP-Architecture-for-Vision"><a href="#X-MLP-A-Patch-Embedding-Free-MLP-Architecture-for-Vision" class="headerlink" title="X-MLP: A Patch Embedding-Free MLP Architecture for Vision"></a>X-MLP: A Patch Embedding-Free MLP Architecture for Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00592">http://arxiv.org/abs/2307.00592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Wang, Zhicheng Cai, Chenglei Peng</li>
<li>For:  This paper proposes a new architecture for vision called X-MLP, which is designed to be independent from convolutions and self-attention operations.* Methods: The X-MLP architecture is constructed absolutely upon fully connected layers and is free from patch embedding. It decouples the features extremely and utilizes MLPs to interact the information across the dimension of width, height, and channel independently and alternately.* Results: X-MLP is tested on ten benchmark datasets and obtains better performance than other vision MLP models. It even surpasses CNNs by a clear margin on various datasets. Additionally, the paper visualizes the information communication between any couples of pixels in the feature map and observes the phenomenon of capturing long-range dependency.Here is the simplified Chinese text for the three key points:* For: 这篇论文提出了一种新的视觉建模方法，即X-MLP，它不依赖卷积和自注意力操作。* Methods: X-MLP采用全连接层构建，不需要负权重映射。它强制Feature decoupling，通过多层Perceptron交互信息，独立地处理宽高和通道维度。* Results: X-MLP在十个基准数据集上进行测试，与其他视觉MLP模型相比，表现更好。甚至在不同的数据集上，X-MLP还超过了CNN。此外，通过数学还原空间权重，可以visualize任意像素对像的信息交换，观察长距离关系。<details>
<summary>Abstract</summary>
Convolutional neural networks (CNNs) and vision transformers (ViT) have obtained great achievements in computer vision. Recently, the research of multi-layer perceptron (MLP) architectures for vision have been popular again. Vision MLPs are designed to be independent from convolutions and self-attention operations. However, existing vision MLP architectures always depend on convolution for patch embedding. Thus we propose X-MLP, an architecture constructed absolutely upon fully connected layers and free from patch embedding. It decouples the features extremely and utilizes MLPs to interact the information across the dimension of width, height and channel independently and alternately. X-MLP is tested on ten benchmark datasets, all obtaining better performance than other vision MLP models. It even surpasses CNNs by a clear margin on various dataset. Furthermore, through mathematically restoring the spatial weights, we visualize the information communication between any couples of pixels in the feature map and observe the phenomenon of capturing long-range dependency.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）和视Transformer（ViT）在计算机视觉领域已经取得了很大的成就。最近，视觉多层批处理（MLP）建筑的研究又再次受到了关注。视觉MLP建筑始终依赖于混合层和自我注意力操作。然而，现有的视觉MLP建筑都是通过混合层进行质心编码。因此，我们提出X-MLP，一种完全基于全连接层的建筑，不依赖于混合层和质心编码。它将特征分解得非常细致，并使用MLP进行特征之间的信息交互，在宽度、高度和通道维度上独立地交换信息。X-MLP在十个 benchmark 数据集上进行测试，都超过了其他视觉MLP模型。它甚至在不同的数据集上超过了 CNN。此外，通过数学还原空间权重，我们可以视觉化特征图中任意对的像素对之间的信息交换，并观察捕捉长距离相互作用。
</details></li>
</ul>
<hr>
<h2 id="ClipSitu-Effectively-Leveraging-CLIP-for-Conditional-Predictions-in-Situation-Recognition"><a href="#ClipSitu-Effectively-Leveraging-CLIP-for-Conditional-Predictions-in-Situation-Recognition" class="headerlink" title="ClipSitu: Effectively Leveraging CLIP for Conditional Predictions in Situation Recognition"></a>ClipSitu: Effectively Leveraging CLIP for Conditional Predictions in Situation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00586">http://arxiv.org/abs/2307.00586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debaditya Roy, Dhruv Verma, Basura Fernando</li>
<li>for: 这篇论文是关于图像上的情境识别任务，即通过活动词和图像中的人物和物品的SemanticRole来描述图像中的情境。</li>
<li>methods: 我们使用CLIP基础模型，CLIP已经通过语言描述学习了图像的上下文知识。我们还使用深度和宽的多层感知器（MLP）块，通过CLIP图像和文本嵌入特征来进行情境识别任务，并且超过了现有的State-of-the-art CoFormer模型。</li>
<li>results: 我们的结果显示，使用CLIP视觉token和架构设计的涉及式注意力Transformer（ClipSitu XTF）可以在semantic role labeling（值）任务中带来14.1%的提升，使得我们的模型在imSitu数据集上达到了最高的top-1准确率。<details>
<summary>Abstract</summary>
Situation Recognition is the task of generating a structured summary of what is happening in an image using an activity verb and the semantic roles played by actors and objects. In this task, the same activity verb can describe a diverse set of situations as well as the same actor or object category can play a diverse set of semantic roles depending on the situation depicted in the image. Hence model needs to understand the context of the image and the visual-linguistic meaning of semantic roles. Therefore, we leverage the CLIP foundational model that has learned the context of images via language descriptions. We show that deeper-and-wider multi-layer perceptron (MLP) blocks obtain noteworthy results for the situation recognition task by using CLIP image and text embedding features and it even outperforms the state-of-the-art CoFormer, a Transformer-based model, thanks to the external implicit visual-linguistic knowledge encapsulated by CLIP and the expressive power of modern MLP block designs. Motivated by this, we design a cross-attention-based Transformer using CLIP visual tokens that model the relation between textual roles and visual entities. Our cross-attention-based Transformer known as ClipSitu XTF outperforms existing state-of-the-art by a large margin of 14.1% on semantic role labelling (value) for top-1 accuracy using imSitu dataset. We will make the code publicly available.
</details>
<details>
<summary>摘要</summary>
Situation recognition是将图像中的活动和角色描述为结构化的摘要。在这个任务中，同一个活动词可以描述多种不同的情况，同一个actor或object category可以扮演多种不同的semantic role，具体取决于图像中所示的情况。因此，模型需要理解图像的上下文和视觉语言意义。为此，我们利用CLIP基础模型，它通过语言描述学习了图像的上下文。我们发现，在使用CLIP图像和文本嵌入特征的更深更宽多层感知（MLP）块时，可以获得优秀的结果，并在CoFormer，一种基于Transformer的模型，之上出现胜利。这是因为CLIP中的外部隐式视觉语言知识和现代MLP块设计的表达能力。为了进一步解决这个问题，我们设计了一个基于交叉关注的Transformer，使用CLIP的视觉token来模拟文本角色和视觉实体之间的关系。我们称之为ClipSitu XTF，它在imSitu数据集上的semantic role标签（值）的top-1准确率上超越了现有的状态艺术。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="A-multi-task-learning-framework-for-carotid-plaque-segmentation-and-classification-from-ultrasound-images"><a href="#A-multi-task-learning-framework-for-carotid-plaque-segmentation-and-classification-from-ultrasound-images" class="headerlink" title="A multi-task learning framework for carotid plaque segmentation and classification from ultrasound images"></a>A multi-task learning framework for carotid plaque segmentation and classification from ultrasound images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00583">http://arxiv.org/abs/2307.00583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitao Gan, Ran Zhou, Yanghan Ou, Furong Wang, Xinyao Cheng, Xiaoyan Wu, Aaron Fenster</li>
<li>for: 这种研究的目的是提出一种多任务学习框架，用于 ultrasound 血管壁瘤分割和分类。</li>
<li>methods: 该方法使用了一个区域权重模块 (RWM) 和一个样本权重模块 (SWM)，以利用分割和分类两个任务之间的相互关系。RWM 提供了一种含有血管壁瘤区域特征的特征知识，而 SWM 则是用于学习分割任务中的 categorical 样本权重。</li>
<li>results: 实验结果显示，提出的方法可以significantly提高与单个任务训练的网络性能，其中分类任务的准确率为 85.82%，分割任务的 dice similarity 系数为 84.92%。在减少研究中，结果表明了 RWM 和 SWM 都对网络性能的提高有所贡献。因此，我们认为该方法可以在临床试验和实践中用于血管壁瘤分析。<details>
<summary>Abstract</summary>
Carotid plaque segmentation and classification play important roles in the treatment of atherosclerosis and assessment for risk of stroke. Although deep learning methods have been used for carotid plaque segmentation and classification, most focused on a single task and ignored the relationship between the segmentation and classification of carotid plaques. Therefore, we propose a multi-task learning framework for ultrasound carotid plaque segmentation and classification, which utilizes a region-weight module (RWM) and a sample-weight module (SWM) to exploit the correlation between these two tasks. The RWM provides a plaque regional prior knowledge to the classification task, while the SWM is designed to learn the categorical sample weight for the segmentation task. A total of 1270 2D ultrasound images of carotid plaques were collected from Zhongnan Hospital (Wuhan, China) for our experiments. The results of the experiments showed that the proposed method can significantly improve the performance compared to existing networks trained for a single task, with an accuracy of 85.82% for classification and a Dice similarity coefficient of 84.92% for segmentation. In the ablation study, the results demonstrated that both the designed RWM and SWM were beneficial in improving the network's performance. Therefore, we believe that the proposed method could be useful for carotid plaque analysis in clinical trials and practice.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate("Carotid plaque segmentation and classification play important roles in the treatment of atherosclerosis and assessment for risk of stroke. Although deep learning methods have been used for carotid plaque segmentation and classification, most focused on a single task and ignored the relationship between the segmentation and classification of carotid plaques. Therefore, we propose a multi-task learning framework for ultrasound carotid plaque segmentation and classification, which utilizes a region-weight module (RWM) and a sample-weight module (SWM) to exploit the correlation between these two tasks. The RWM provides a plaque regional prior knowledge to the classification task, while the SWM is designed to learn the categorical sample weight for the segmentation task. A total of 1270 2D ultrasound images of carotid plaques were collected from Zhongnan Hospital (Wuhan, China) for our experiments. The results of the experiments showed that the proposed method can significantly improve the performance compared to existing networks trained for a single task, with an accuracy of 85.82% for classification and a Dice similarity coefficient of 84.92% for segmentation. In the ablation study, the results demonstrated that both the designed RWM and SWM were beneficial in improving the network's performance. Therefore, we believe that the proposed method could be useful for carotid plaque analysis in clinical trials and practice.")Here's the translation:脉络栓分割和分类在血栓病治疗和风险评估中发挥重要作用。虽然深度学习方法已经用于脉络栓分割和分类，但大多数方法只关注单一任务，忽略了脉络栓分割和分类之间的关系。因此，我们提出了一种多任务学习框架 для超声脉络栓分割和分类，该框架利用区域权重模块（RWM）和样本权重模块（SWM）来利用这两个任务之间的相关性。RWM提供了脉络栓区域先验知识 для分类任务，而SWM是用于学习分类任务中的 categorical 样本权重。我们对1270个2D超声脉络栓图像进行了实验，结果显示，我们的方法可以与现有的单任务网络相比，提高表现，具体数据为85.82%的准确率和84.92%的相似度。在剥离研究中，结果表明，我们设计的RWM和SWM都对网络表现有益。因此，我们认为该方法在临床试验和实践中可能是有用的。
</details></li>
</ul>
<hr>
<h2 id="TinySiamese-Network-for-Biometric-Analysis"><a href="#TinySiamese-Network-for-Biometric-Analysis" class="headerlink" title="TinySiamese Network for Biometric Analysis"></a>TinySiamese Network for Biometric Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00578">http://arxiv.org/abs/2307.00578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Islem Jarraya, Tarek M. Hamdani, Habib Chabchoub, Adel M. Alimi</li>
<li>for: 这篇论文主要关注于提高鉴定识别效率和适用范围，使用TinySiamese替代标准Siamese来实现这个目标。</li>
<li>methods: 这篇论文使用TinySiamese方法，它不需要全部CNN进行训练，可以使用预训练的CNN作为特征提取器，然后使用TinySiamese进行学习。</li>
<li>results: 这篇论文的结果显示，使用TinySiamese可以大幅降低训练时间和汇入时间，并且在鉴定和分类任务中获得了比标准Siamese更高的精度。<details>
<summary>Abstract</summary>
Biometric recognition is the process of verifying or classifying human characteristics in images or videos. It is a complex task that requires machine learning algorithms, including convolutional neural networks (CNNs) and Siamese networks. Besides, there are several limitations to consider when using these algorithms for image verification and classification tasks. In fact, training may be computationally intensive, requiring specialized hardware and significant computational resources to train and deploy. Moreover, it necessitates a large amount of labeled data, which can be time-consuming and costly to obtain. The main advantage of the proposed TinySiamese compared to the standard Siamese is that it does not require the whole CNN for training. In fact, using a pre-trained CNN as a feature extractor and the TinySiamese to learn the extracted features gave almost the same performance and efficiency as the standard Siamese for biometric verification. In this way, the TinySiamese solves the problems of memory and computational time with a small number of layers which did not exceed 7. It can be run under low-power machines which possess a normal GPU and cannot allocate a large RAM space. Using TinySiamese with only 8 GO of memory, the matching time decreased by 76.78% on the B2F (Biometric images of Fingerprints and Faces), FVC2000, FVC2002 and FVC2004 while the training time for 10 epochs went down by approximately 93.14% on the B2F, FVC2002, THDD-part1 and CASIA-B datasets. The accuracy of the fingerprint, gait (NM-angle 180 degree) and face verification tasks was better than the accuracy of a standard Siamese by 0.87%, 20.24% and 3.85% respectively. TinySiamese achieved comparable accuracy with related works for the fingerprint and gait classification tasks.
</details>
<details>
<summary>摘要</summary>
生物特征识别是将人体特征从图像或视频中鉴别或分类的过程。这是一项复杂的任务，需要机器学习算法，包括卷积神经网络（CNN）和同一个网络（Siamese）。然而，使用这些算法进行图像鉴别和分类任务时，存在一些限制。首先，训练可能会是 computationally intensive，需要特殊的硬件和大量计算资源来训练和部署。此外，需要大量标注数据，可能需要很长时间和成本来获得。与标准Siamese相比，我们提出的TinySiamese具有一些优点。首先，它不需要整个CNN进行训练。相反，使用预训练的CNN作为特征提取器，然后使用TinySiamese来学习提取的特征。这与标准Siamese的性能和效率几乎相同。此外，TinySiamese通过减少内存和计算时间的问题，使用只有7层的小型神经网络。这使得它可以在低功耗机器上运行，并且可以避免大量的内存和计算资源。使用TinySiamese，我们可以在10个epoch的训练时间下降约93.14%，而匹配时间下降约76.78%。此外，在B2F、FVC2000、FVC2002和FVC2004等数据集上，TinySiamese的精度比标准Siamese高出0.87%、20.24%和3.85%。此外，TinySiamese在指纹、步态（NM-angle 180度）和脸部鉴别任务中达到了相当的精度。
</details></li>
</ul>
<hr>
<h2 id="Bidirectional-Temporal-Diffusion-Model-for-Temporally-Consistent-Human-Animation"><a href="#Bidirectional-Temporal-Diffusion-Model-for-Temporally-Consistent-Human-Animation" class="headerlink" title="Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation"></a>Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00574">http://arxiv.org/abs/2307.00574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tserendorj Adiya, Sanghun Kim, Jung Eun Lee, Jae Shin Yoon, Hwasup Lim</li>
<li>for: 生成具有时间准确性的人体动画从单个图像、视频或随机噪声中。</li>
<li>methods: 我们提出了一种模型人体动画的auto-regressive生成方法，即预测过去帧来解码未来帧。然而，这种单向生成具有时间扩散的问题，容易产生人体动画中的不实际的干扰，如人体外观扭曲。我们认为，对于生成网络来说，双向时间模型可以强制实现人体动画的时间准确性。</li>
<li>results: 我们的方法在实验中表现出了强大的表现，与现有的单向方法相比，具有真实的时间准确性。<details>
<summary>Abstract</summary>
We introduce a method to generate temporally coherent human animation from a single image, a video, or a random noise. This problem has been formulated as modeling of an auto-regressive generation, i.e., to regress past frames to decode future frames. However, such unidirectional generation is highly prone to motion drifting over time, generating unrealistic human animation with significant artifacts such as appearance distortion. We claim that bidirectional temporal modeling enforces temporal coherence on a generative network by largely suppressing the motion ambiguity of human appearance. To prove our claim, we design a novel human animation framework using a denoising diffusion model: a neural network learns to generate the image of a person by denoising temporal Gaussian noises whose intermediate results are cross-conditioned bidirectionally between consecutive frames. In the experiments, our method demonstrates strong performance compared to existing unidirectional approaches with realistic temporal coherence
</details>
<details>
<summary>摘要</summary>
我们提出了一种将单一图像、视频或随机变数转换为有着时间对称的人体动画的方法。这问题被视为一个自动复原生成问题，即从过去的几帧图像中预测未来几帧图像。但这种单向生成很容易受到时间漂移的影响，导致生成的人体动画有着严重的扭转现象和错误。我们声称，将时间方向统一到生成网络中可以严重抑制人体出现的动作抽象。为了证明我们的声明，我们设计了一个新的人体动画框架，使用一个对应推对推的滤除扩散模型：一个神经网络将从随机 Gaussian 噪声中获得人体图像，并在过去和未来几帧图像之间进行对应推对推的滤除过程。在实验中，我们的方法与现有的单向方法相比，具有更强的时间对称性和更真实的人体动画。
</details></li>
</ul>
<hr>
<h2 id="A-MIL-Approach-for-Anomaly-Detection-in-Surveillance-Videos-from-Multiple-Camera-Views"><a href="#A-MIL-Approach-for-Anomaly-Detection-in-Surveillance-Videos-from-Multiple-Camera-Views" class="headerlink" title="A MIL Approach for Anomaly Detection in Surveillance Videos from Multiple Camera Views"></a>A MIL Approach for Anomaly Detection in Surveillance Videos from Multiple Camera Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00562">http://arxiv.org/abs/2307.00562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/santiagosilas/mc-vad-dataset-basedon-pets2009">https://github.com/santiagosilas/mc-vad-dataset-basedon-pets2009</a></li>
<li>paper_authors: Silas Santiago Lopes Pereira, José Everardo Bessa Maia</li>
<li>for: 本研究旨在解决监控视频中检测异常的问题，异常事件是罕见的，因此监控视频中的异常检测任务受到类别不平衡和缺乏异常数据的限制。</li>
<li>methods: 本研究使用多个视角的多例学习（MIL）和多视角视图（MC）技术来解决监控视频中异常检测任务中的缺乏标注数据和 occlusion 和干扰的问题。</li>
<li>results: 对多个视角PETS-2009benchmark dataset进行重新标注，并使用多视角combined损失函数和Sultani的MIL排名函数来训练一个回归网络，得到了与单视角配置相比显著的F1分数提升。<details>
<summary>Abstract</summary>
Occlusion and clutter are two scene states that make it difficult to detect anomalies in surveillance video. Furthermore, anomaly events are rare and, as a consequence, class imbalance and lack of labeled anomaly data are also key features of this task. Therefore, weakly supervised methods are heavily researched for this application. In this paper, we tackle these typical problems of anomaly detection in surveillance video by combining Multiple Instance Learning (MIL) to deal with the lack of labels and Multiple Camera Views (MC) to reduce occlusion and clutter effects. In the resulting MC-MIL algorithm we apply a multiple camera combined loss function to train a regression network with Sultani's MIL ranking function. To evaluate the MC-MIL algorithm first proposed here, the multiple camera PETS-2009 benchmark dataset was re-labeled for the anomaly detection task from multiple camera views. The result shows a significant performance improvement in F1 score compared to the single-camera configuration.
</details>
<details>
<summary>摘要</summary>
干扰和堵塞是两种场景状态，使得异常检测在监视视频中具有棘手。此外，异常事件是罕见的，因此类别不平衡和缺乏异常数据也是这个任务的关键特点。因此，弱地监视方法受到了广泛的研究。在这篇论文中，我们解决了监视视频中异常检测中的常见问题，包括缺乏标签和干扰和堵塞的影响。我们提出了 MC-MIL 算法，该算法通过将多个摄像头视图组合成一个多视图损失函数，来训练一个 regression 网络，并使用 Sulani 的 MIL 排名函数。为评估 MC-MIL 算法，我们对多Camera PETS-2009 数据集进行了重新标注，以便进行异常检测任务。结果表明，相比单摄像头配置，MC-MIL 算法在 F1 分数上显著提高了性能。
</details></li>
</ul>
<hr>
<h2 id="Partial-label-Learning-with-Mixed-Closed-set-and-Open-set-Out-of-candidate-Examples"><a href="#Partial-label-Learning-with-Mixed-Closed-set-and-Open-set-Out-of-candidate-Examples" class="headerlink" title="Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples"></a>Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00553">http://arxiv.org/abs/2307.00553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo He, Lei Feng, Guowu Yang</li>
<li>for: 本研究探讨了在半标签学习（PLL）中处理异常样本（OOC）的问题，即样本的真实标签可能不在归类集中。</li>
<li>methods: 本研究提出了两种类型的OOC例子，即关闭集&#x2F;开集OOC例子，并提出了一种基于特殊设计的识别 criterion。 然后，对关闭集OOC例子，进行反向标签混淆处理；对开集OOC例子，利用了一种有效的辅助正则化策略，动态分配随机的归类标签。</li>
<li>results: 对比州的PLL方法，本研究的方法得到了更高的性能。<details>
<summary>Abstract</summary>
Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (out-of-candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ARHNet-Adaptive-Region-Harmonization-for-Lesion-aware-Augmentation-to-Improve-Segmentation-Performance"><a href="#ARHNet-Adaptive-Region-Harmonization-for-Lesion-aware-Augmentation-to-Improve-Segmentation-Performance" class="headerlink" title="ARHNet: Adaptive Region Harmonization for Lesion-aware Augmentation to Improve Segmentation Performance"></a>ARHNet: Adaptive Region Harmonization for Lesion-aware Augmentation to Improve Segmentation Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.01220">http://arxiv.org/abs/2307.01220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/king-haw/arhnet">https://github.com/king-haw/arhnet</a></li>
<li>paper_authors: Jiayu Huo, Yang Liu, Xi Ouyang, Alejandro Granados, Sebastien Ourselin, Rachel Sparks</li>
<li>for: 提高MRI扫描图像中脑损伤的识别精度，以提供patients with prognoses和 neurosurgical monitoring。</li>
<li>methods: 使用CNN模型进行图像分割，并采用进步的数据增强策略来提高模型的可靠性。</li>
<li>results: 在实验中，ARHNet在实验中提高了下游分割性能，并在真实和Synthetic图像上达到了最高的表现。<details>
<summary>Abstract</summary>
Accurately segmenting brain lesions in MRI scans is critical for providing patients with prognoses and neurological monitoring. However, the performance of CNN-based segmentation methods is constrained by the limited training set size. Advanced data augmentation is an effective strategy to improve the model's robustness. However, they often introduce intensity disparities between foreground and background areas and boundary artifacts, which weakens the effectiveness of such strategies. In this paper, we propose a foreground harmonization framework (ARHNet) to tackle intensity disparities and make synthetic images look more realistic. In particular, we propose an Adaptive Region Harmonization (ARH) module to dynamically align foreground feature maps to the background with an attention mechanism. We demonstrate the efficacy of our method in improving the segmentation performance using real and synthetic images. Experimental results on the ATLAS 2.0 dataset show that ARHNet outperforms other methods for image harmonization tasks, and boosts the down-stream segmentation performance. Our code is publicly available at https://github.com/King-HAW/ARHNet.
</details>
<details>
<summary>摘要</summary>
优敏诊断患者的脑部病变需要高精度的MRI扫描图像分割，以提供病人诊断和 neuroscience 监测。然而，基于Convolutional Neural Network（CNN）的分割方法的性能受训练集大小的限制。高级数据增强技术可以提高模型的鲁棒性，但它们经常导致Intensity Disparity（ID）和边界artefacts，这会削弱这些策略的效果。本文提出了一种前景协调框架（ARHNet），以解决ID和Synthetic Image的不真实性问题。特别是，我们提出了一种适应区域协调（ARH）模块，通过关注机制来动态将前景特征图与背景图进行对齐。我们通过实验表明，ARHNet可以提高下游分割性能，并在ATLAS 2.0数据集上超越其他图像协调任务的方法。代码可以在https://github.com/King-HAW/ARHNet上获取。
</details></li>
</ul>
<hr>
<h2 id="Referring-Video-Object-Segmentation-with-Inter-Frame-Interaction-and-Cross-Modal-Correlation"><a href="#Referring-Video-Object-Segmentation-with-Inter-Frame-Interaction-and-Cross-Modal-Correlation" class="headerlink" title="Referring Video Object Segmentation with Inter-Frame Interaction and Cross-Modal Correlation"></a>Referring Video Object Segmentation with Inter-Frame Interaction and Cross-Modal Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00536">http://arxiv.org/abs/2307.00536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Lan, Fu Rong, Lefei Zhang</li>
<li>for: 提高视频对象分割的精度和准确性，并提出一个可插入执行器模块来增强视频序列中对象的时空协同特征学习。</li>
<li>methods: 提出了一种基于Transformer的新的对象分割框架，称为IFIRVOS，其包括一个插件式的时空交互模块和一个视频语言交互模块。</li>
<li>results: 经验 результаты表明，IFIRVOS在三个标准测试集上表现出了与state-of-the-art方法相比的superiority，并且 validate了我们提出的模块的有效性。<details>
<summary>Abstract</summary>
Referring video object segmentation (RVOS) aims to segment the target object in a video sequence described by a language expression. Typical query-based methods process the video sequence in a frame-independent manner to reduce the high computational cost, which however affects the performance due to the lack of inter-frame interaction for temporal coherence modeling and spatio-temporal representation learning of the referred object. Besides, they directly adopt the raw and high-level sentence feature as the language queries to decode the visual features, where the weak correlation between visual and linguistic features also increases the difficulty of decoding the target information and limits the performance of the model. In this paper, we proposes a novel RVOS framework, dubbed IFIRVOS, to address these issues. Specifically, we design a plug-and-play inter-frame interaction module in the Transformer decoder to efficiently learn the spatio-temporal features of the referred object, so as to decode the object information in the video sequence more precisely and generate more accurate segmentation results. Moreover, we devise the vision-language interaction module before the multimodal Transformer to enhance the correlation between the visual and linguistic features, thus facilitating the process of decoding object information from visual features by language queries in Transformer decoder and improving the segmentation performance. Extensive experimental results on three benchmarks validate the superiority of our IFIRVOS over state-of-the-art methods and the effectiveness of our proposed modules.
</details>
<details>
<summary>摘要</summary>
Traditional query-based methods for Referring Video Object Segmentation (RVOS) process the video sequence in a frame-independent manner, which can reduce computational cost but also affects performance due to the lack of inter-frame interaction for temporal coherence modeling and spatio-temporal representation learning of the referred object. Moreover, they directly use raw and high-level sentence features as language queries to decode visual features, which can lead to weak correlation between visual and linguistic features, limiting the performance of the model.In this paper, we propose a novel RVOS framework, called IFIRVOS, to address these issues. Specifically, we design a plug-and-play inter-frame interaction module in the Transformer decoder to efficiently learn spatio-temporal features of the referred object, allowing for more precise decoding of object information in the video sequence and generating more accurate segmentation results. Furthermore, we propose a vision-language interaction module before the multimodal Transformer to enhance the correlation between visual and linguistic features, facilitating the process of decoding object information from visual features using language queries in the Transformer decoder and improving segmentation performance.Experimental results on three benchmarks demonstrate the superiority of our IFIRVOS over state-of-the-art methods and the effectiveness of our proposed modules.
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Out-of-distribution-Detection-with-Self-supervised-Sampling"><a href="#End-to-End-Out-of-distribution-Detection-with-Self-supervised-Sampling" class="headerlink" title="End-to-End Out-of-distribution Detection with Self-supervised Sampling"></a>End-to-End Out-of-distribution Detection with Self-supervised Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00519">http://arxiv.org/abs/2307.00519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sen Pei, Jiaxi Sun, Peng Qin, Qi Chen, Xinglong Wu, Xun Wang</li>
<li>for: 提高 Open World 中的 Out-of-distribution (OOD) 检测精度，帮助模型在关闭集合训练后在开放世界中识别未知数据。</li>
<li>methods: 提出一个通用概率框架来看待多种已有方法，并提出一种无需 OOD 数据的模型，即 Self-supervised Sampling for OOD Detection (SSOD)，利用了 convolution 操作的本地性来从 ID 数据中抽取自然的 OOD 信号，并同时优化 OOD 检测和正常 ID 分类。</li>
<li>results: 在多个大规模 benchmark 上实现了竞争力的状态平台，比如 SUN 上的 FPR95 下的性能提高了大约 48.99% 到 35.52% 之间，比最近的方法，如 KNN，有大幅度的优势。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection empowers the model trained on the closed set to identify unknown data in the open world. Though many prior techniques have yielded considerable improvements, two crucial obstacles still remain. Firstly, a unified perspective has yet to be presented to view the developed arts with individual designs, which is vital for providing insights into the related directions. Secondly, most research focuses on the post-processing schemes of the pre-trained features while disregarding the superiority of end-to-end training, dramatically limiting the upper bound of OOD detection. To tackle these issues, we propose a general probabilistic framework to interpret many existing methods and an OOD-data-free model, namely Self-supervised Sampling for OOD Detection (SSOD), to unfold the potential of end-to-end learning. SSOD efficiently exploits natural OOD signals from the in-distribution (ID) data based on the local property of convolution. With these supervisions, it jointly optimizes the OOD detection and conventional ID classification. Extensive experiments reveal that SSOD establishes competitive state-of-the-art performance on many large-scale benchmarks, where it outperforms the most recent approaches, such as KNN, by a large margin, e.g., 48.99% to 35.52% on SUN at FPR95.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SUGAR-Spherical-Ultrafast-Graph-Attention-Framework-for-Cortical-Surface-Registration"><a href="#SUGAR-Spherical-Ultrafast-Graph-Attention-Framework-for-Cortical-Surface-Registration" class="headerlink" title="SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical Surface Registration"></a>SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical Surface Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00511">http://arxiv.org/abs/2307.00511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxun Ren, Ning An, Youjia Zhang, Danyang Wang, Zhenyu Sun, Cong Lin, Weigang Cui, Weiwei Wang, Ying Zhou, Wei Zhang, Qingyu Hu, Ping Zhang, Dan Hu, Danhong Wang, Hesheng Liu<br>for:SUGAR is designed to improve cortical surface registration, specifically addressing the challenge of aligning cortical functional and anatomical features across individuals.methods:SUGAR is a unified unsupervised deep-learning framework that incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation. The framework includes a similarity loss, fold loss, and multiple distortion losses to preserve topology and minimize various types of distortions.results:SUGAR exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods. Additionally, SUGAR achieves remarkable sub-second processing times, offering a notable speed-up of approximately 12,000 times in registering 9,000 subjects from the UK Biobank dataset in just 32 minutes.<details>
<summary>Abstract</summary>
Cortical surface registration plays a crucial role in aligning cortical functional and anatomical features across individuals. However, conventional registration algorithms are computationally inefficient. Recently, learning-based registration algorithms have emerged as a promising solution, significantly improving processing efficiency. Nonetheless, there remains a gap in the development of a learning-based method that exceeds the state-of-the-art conventional methods simultaneously in computational efficiency, registration accuracy, and distortion control, despite the theoretically greater representational capabilities of deep learning approaches. To address the challenge, we present SUGAR, a unified unsupervised deep-learning framework for both rigid and non-rigid registration. SUGAR incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation. In addition to the similarity loss, we introduce fold and multiple distortion losses, to preserve topology and minimize various types of distortions. Furthermore, we propose a data augmentation strategy specifically tailored for spherical surface registration, enhancing the registration performance. Through extensive evaluation involving over 10,000 scans from 7 diverse datasets, we showed that our framework exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods. Additionally, SUGAR achieves remarkable sub-second processing times, offering a notable speed-up of approximately 12,000 times in registering 9,000 subjects from the UK Biobank dataset in just 32 minutes. This combination of high registration performance and accelerated processing time may greatly benefit large-scale neuroimaging studies.
</details>
<details>
<summary>摘要</summary>
cortical surface registration 在跨个体标准化中扮演关键角色，但传统的注册算法 computationally inefficient。 recent learning-based registration algorithms 作为一个有前途的解决方案，Significantly improving processing efficiency。然而，there remains a gap in the development of a learning-based method that exceeds the state-of-the-art conventional methods simultaneously in computational efficiency, registration accuracy, and distortion control，despite the theoretically greater representational capabilities of deep learning approaches。To address the challenge，we present SUGAR，a unified unsupervised deep-learning framework for both rigid and non-rigid registration。SUGAR incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation。In addition to the similarity loss，we introduce fold and multiple distortion losses，to preserve topology and minimize various types of distortions。Furthermore，we propose a data augmentation strategy specifically tailored for spherical surface registration，enhancing the registration performance。Through extensive evaluation involving over 10,000 scans from 7 diverse datasets，we showed that our framework exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods。Additionally，SUGAR achieves remarkable sub-second processing times，offering a notable speed-up of approximately 12,000 times in registering 9,000 subjects from the UK Biobank dataset in just 32 minutes。This combination of high registration performance and accelerated processing time may greatly benefit large-scale neuroimaging studies。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Quantization-via-Mixed-Precision-Compensation-without-Fine-Tuning"><a href="#Data-Free-Quantization-via-Mixed-Precision-Compensation-without-Fine-Tuning" class="headerlink" title="Data-Free Quantization via Mixed-Precision Compensation without Fine-Tuning"></a>Data-Free Quantization via Mixed-Precision Compensation without Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00498">http://arxiv.org/abs/2307.00498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Chen, Shipeng Bai, Tianxin Huang, Mengmeng Wang, Guanzhong Tian, Yong Liu</li>
<li>for: 提高模型压缩后的精度，不需要原始数据和 fine-tuning 过程。</li>
<li>methods: 基于异常抽象数据的生成方法，提出了一种无数据的混合精度补偿方法（DF-MPC），通过减少量化误差，提高模型的精度。</li>
<li>results: 实验表明，DF-MPC 能够在无数据和 fine-tuning 过程的情况下，提高模型的精度，比较有效率。<details>
<summary>Abstract</summary>
Neural network quantization is a very promising solution in the field of model compression, but its resulting accuracy highly depends on a training/fine-tuning process and requires the original data. This not only brings heavy computation and time costs but also is not conducive to privacy and sensitive information protection. Therefore, a few recent works are starting to focus on data-free quantization. However, data-free quantization does not perform well while dealing with ultra-low precision quantization. Although researchers utilize generative methods of synthetic data to address this problem partially, data synthesis needs to take a lot of computation and time. In this paper, we propose a data-free mixed-precision compensation (DF-MPC) method to recover the performance of an ultra-low precision quantized model without any data and fine-tuning process. By assuming the quantized error caused by a low-precision quantized layer can be restored via the reconstruction of a high-precision quantized layer, we mathematically formulate the reconstruction loss between the pre-trained full-precision model and its layer-wise mixed-precision quantized model. Based on our formulation, we theoretically deduce the closed-form solution by minimizing the reconstruction loss of the feature maps. Since DF-MPC does not require any original/synthetic data, it is a more efficient method to approximate the full-precision model. Experimentally, our DF-MPC is able to achieve higher accuracy for an ultra-low precision quantized model compared to the recent methods without any data and fine-tuning process.
</details>
<details>
<summary>摘要</summary>
neural network 量化是一种非常有前途的解决方案在模型压缩领域，但它的结果准确度具有训练/精度调整过程和原始数据的依赖关系。这不仅带来了重量计算和时间成本，还不利于隐私信息保护。因此，一些最近的研究开始关注无数据量化。然而，无数据量化在ultra-low precision量化时不太好进行。虽然研究人员利用生成方法生成的假数据来解决这个问题，但数据生成需要很多计算和时间。在这篇论文中，我们提出了一种无数据混合精度补偿方法（DF-MPC）来恢复ultra-low precision量化模型的性能。我们假设量化错误由low-precision量化层引起的可以通过高精度量化层的重建来恢复。我们使用数学形式来表述重建loss между预训练全精度模型和它的层 wise混合精度量化模型。根据我们的形式，我们可以 theoretically得出closed-form解。由于DF-MPC不需要任何原始/生成数据，它是一种更高效的方法来近似全精度模型。实验表明，我们的DF-MPC可以在ultra-low precision量化模型中达到更高的准确度，比悉些最近的方法不需要任何数据和精度调整过程。
</details></li>
</ul>
<hr>
<h2 id="TopicFM-Boosting-Accuracy-and-Efficiency-of-Topic-Assisted-Feature-Matching"><a href="#TopicFM-Boosting-Accuracy-and-Efficiency-of-Topic-Assisted-Feature-Matching" class="headerlink" title="TopicFM+: Boosting Accuracy and Efficiency of Topic-Assisted Feature Matching"></a>TopicFM+: Boosting Accuracy and Efficiency of Topic-Assisted Feature Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00485">http://arxiv.org/abs/2307.00485</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/truongkhang/topicfm">https://github.com/truongkhang/topicfm</a></li>
<li>paper_authors: Khang Truong Giang, Soohwan Song, Sungho Jo</li>
<li>for: 本研究旨在解决图像匹配中难以处理的场景，如场景变化较大或 texture 较少，并强调计算效率。</li>
<li>methods: 我们提出了一种使用话题模型策略来捕捉图像中高级别上下文信息的新方法。每个图像都被表示为一个多omial分布中的话题，每个话题代表一个隐藏的semantic实例。通过这些话题，我们可以有效地捕捉具有广泛上下文信息的全面特征。此外，我们还提出了一种优化feature匹配的方法，通过估算 covisible 话题来匹配相应的semantic区域中的特征。</li>
<li>results: 我们通过了广泛的实验，证明了我们的方法在难以处理的场景中具有显著的优势。具体来说，我们的方法可以减少计算成本，同时保持高效性和高匹配精度。代码将在<a target="_blank" rel="noopener" href="https://github.com/TruongKhang/TopicFM">https://github.com/TruongKhang/TopicFM</a> 上更新。<details>
<summary>Abstract</summary>
This study tackles the challenge of image matching in difficult scenarios, such as scenes with significant variations or limited texture, with a strong emphasis on computational efficiency. Previous studies have attempted to address this challenge by encoding global scene contexts using Transformers. However, these approaches suffer from high computational costs and may not capture sufficient high-level contextual information, such as structural shapes or semantic instances. Consequently, the encoded features may lack discriminative power in challenging scenes. To overcome these limitations, we propose a novel image-matching method that leverages a topic-modeling strategy to capture high-level contexts in images. Our method represents each image as a multinomial distribution over topics, where each topic represents a latent semantic instance. By incorporating these topics, we can effectively capture comprehensive context information and obtain discriminative and high-quality features. Additionally, our method effectively matches features within corresponding semantic regions by estimating the covisible topics. To enhance the efficiency of feature matching, we have designed a network with a pooling-and-merging attention module. This module reduces computation by employing attention only on fixed-sized topics and small-sized features. Through extensive experiments, we have demonstrated the superiority of our method in challenging scenarios. Specifically, our method significantly reduces computational costs while maintaining higher image-matching accuracy compared to state-of-the-art methods. The code will be updated soon at https://github.com/TruongKhang/TopicFM
</details>
<details>
<summary>摘要</summary>
To overcome these limitations, we propose a novel image-matching method that leverages a topic-modeling strategy to capture high-level contexts in images. Our method represents each image as a multinomial distribution over topics, where each topic represents a latent semantic instance. By incorporating these topics, we can effectively capture comprehensive context information and obtain discriminative and high-quality features. Additionally, our method effectively matches features within corresponding semantic regions by estimating the covisible topics.To enhance the efficiency of feature matching, we have designed a network with a pooling-and-merging attention module. This module reduces computation by employing attention only on fixed-sized topics and small-sized features. Through extensive experiments, we have demonstrated the superiority of our method in challenging scenarios. Specifically, our method significantly reduces computational costs while maintaining higher image-matching accuracy compared to state-of-the-art methods. The code will be updated soon at <https://github.com/TruongKhang/TopicFM>.
</details></li>
</ul>
<hr>
<h2 id="Seeing-is-not-Believing-An-Identity-Hider-for-Human-Vision-Privacy-Protection"><a href="#Seeing-is-not-Believing-An-Identity-Hider-for-Human-Vision-Privacy-Protection" class="headerlink" title="Seeing is not Believing: An Identity Hider for Human Vision Privacy Protection"></a>Seeing is not Believing: An Identity Hider for Human Vision Privacy Protection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00481">http://arxiv.org/abs/2307.00481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Wang, Yushu Zhang, Zixuan Yang, Hua Zhang, Zhongyun Hua</li>
<li>for: 隐私保护和人脸识别稳定性</li>
<li>methods: 使用 StyleGAN2  manipulate 原始 face 的 latent space，生成虚拟 face，并将虚拟 face 的视觉内容传播到原始 face 上，然后替换背景。</li>
<li>results: 提出了一种可以具有出色隐私保护和人脸识别稳定性的身份隐藏方法，并通过实验证明其性能优秀。<details>
<summary>Abstract</summary>
Massive captured face images are stored in the database for the identification of individuals. However, the stored images can be observed intentionally or unintentionally by data managers, which is not at the will of individuals and may cause privacy violations. Existing protection works only slightly change the visual content of the face while maintaining the utility of identification, making it susceptible to the inference of the true identity by human vision. In this paper, we propose an identity hider that enables significant visual content change for human vision while preserving high identifiability for face recognizers. Firstly, the identity hider generates a virtual face with new visual content by manipulating the latent space in StyleGAN2. In particular, the virtual face has the same irrelevant attributes as the original face, e.g., pose and expression. Secondly, the visual content of the virtual face is transferred into the original face and then the background is replaced with the original one. In addition, the identity hider has strong transferability, which ensures an arbitrary face recognizer can achieve satisfactory accuracy. Adequate experiments show that the proposed identity hider achieves excellent performance on privacy protection and identifiability preservation.
</details>
<details>
<summary>摘要</summary>
巨大的捕捉到的面部图像被存储在数据库中，用于个体识别。然而，存储的图像可能会被意外或非意外地被数据管理人员见到，这会导致个人隐私被侵犯。现有的保护措施只是轻度地改变视觉内容，保留了识别功能，这使得真实身份易于推测。在这篇论文中，我们提出了一种隐身器，允许对人类视觉来源进行显著视觉内容变化，同时保留高度识别性。首先，隐身器使用StyleGAN2中的latent space进行抽象，生成一个虚拟面，该虚拟面具有与原始面相同的无关属性，例如姿势和表情。其次，虚拟面中的视觉内容被转移到原始面上，并将背景替换为原始的背景。此外，隐身器具有强大的传送性，使得任何面Recognizer都可以达到满意的准确率。经过合适的实验，我们的隐身器实现了出色的隐私保护和识别性 preserved。
</details></li>
</ul>
<hr>
<h2 id="Domain-Transfer-Through-Image-to-Image-Translation-for-Uncertainty-Aware-Prostate-Cancer-Classification"><a href="#Domain-Transfer-Through-Image-to-Image-Translation-for-Uncertainty-Aware-Prostate-Cancer-Classification" class="headerlink" title="Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware Prostate Cancer Classification"></a>Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware Prostate Cancer Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00479">http://arxiv.org/abs/2307.00479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Zhou, Amoon Jamzad, Jason Izard, Alexandre Menard, Robert Siemens, Parvin Mousavi</li>
<li>for: 这个研究是为了提供一种基于深度学习的检测过程，以帮助医生在诊断普通癌中的过程中更加准确。</li>
<li>methods: 这个研究使用了一种名为“域传递”的新方法，将不同域的照片转换为相同的域，以增加训练数据的数量。此外，研究还使用了一种名为“证据深度学习”的方法来估计模型的不确定性，并使用“统计扫描”技术来筛选训练数据。</li>
<li>results: 研究结果显示，这个新方法可以将AUC提高到20%以上，与先前的研究相比（98.4% vs. 76.2%）。这显示了这个方法的可行性和有效性。<details>
<summary>Abstract</summary>
Prostate Cancer (PCa) is often diagnosed using High-resolution 3.0 Tesla(T) MRI, which has been widely established in clinics. However, there are still many medical centers that use 1.5T MRI units in the actual diagnostic process of PCa. In the past few years, deep learning-based models have been proven to be efficient on the PCa classification task and can be successfully used to support radiologists during the diagnostic process. However, training such models often requires a vast amount of data, and sometimes it is unobtainable in practice. Additionally, multi-source MRIs can pose challenges due to cross-domain distribution differences. In this paper, we have presented a novel approach for unpaired image-to-image translation of prostate mp-MRI for classifying clinically significant PCa, to be applied in data-constrained settings. First, we introduce domain transfer, a novel pipeline to translate unpaired 3.0T multi-parametric prostate MRIs to 1.5T, to increase the number of training data. Second, we estimate the uncertainty of our models through an evidential deep learning approach; and leverage the dataset filtering technique during the training process. Furthermore, we introduce a simple, yet efficient Evidential Focal Loss that incorporates the focal loss with evidential uncertainty to train our model. Our experiments demonstrate that the proposed method significantly improves the Area Under ROC Curve (AUC) by over 20% compared to the previous work (98.4% vs. 76.2%). We envision that providing prediction uncertainty to radiologists may help them focus more on uncertain cases and thus expedite the diagnostic process effectively. Our code is available at https://github.com/med-i-lab/DT_UE_PCa
</details>
<details>
<summary>摘要</summary>
prostato cancer (PCa)  oftener diagnosed using High-resolution 3.0 Tesla(T) MRI, which has been widely established in clinics. However, there are still many medical centers that use 1.5T MRI units in the actual diagnostic process of PCa. In the past few years, deep learning-based models have been proven to be efficient on the PCa classification task and can be successfully used to support radiologists during the diagnostic process. However, training such models often requires a vast amount of data, and sometimes it is unobtainable in practice. Additionally, multi-source MRIs can pose challenges due to cross-domain distribution differences. In this paper, we have presented a novel approach for unpaired image-to-image translation of prostate mp-MRI for classifying clinically significant PCa, to be applied in data-constrained settings. First, we introduce domain transfer, a novel pipeline to translate unpaired 3.0T multi-parametric prostate MRIs to 1.5T, to increase the number of training data. Second, we estimate the uncertainty of our models through an evidential deep learning approach; and leverage the dataset filtering technique during the training process. Furthermore, we introduce a simple, yet efficient Evidential Focal Loss that incorporates the focal loss with evidential uncertainty to train our model. Our experiments demonstrate that the proposed method significantly improves the Area Under ROC Curve (AUC) by over 20% compared to the previous work (98.4% vs. 76.2%). We envision that providing prediction uncertainty to radiologists may help them focus more on uncertain cases and thus expedite the diagnostic process effectively. Our code is available at https://github.com/med-i-lab/DT_UE_PCa.
</details></li>
</ul>
<hr>
<h2 id="Query-Efficient-Decision-based-Black-Box-Patch-Attack"><a href="#Query-Efficient-Decision-based-Black-Box-Patch-Attack" class="headerlink" title="Query-Efficient Decision-based Black-Box Patch Attack"></a>Query-Efficient Decision-based Black-Box Patch Attack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00477">http://arxiv.org/abs/2307.00477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyu Chen, Bo Li, Shuang Wu, Shouhong Ding, Wenqiang Zhang</li>
<li>for: This paper is written to explore and improve the efficiency of black-box patch attacks on deep neural networks (DNNs), specifically in the decision-based setting.</li>
<li>methods: The paper proposes a new method called DevoPatch, which uses a differential evolutionary algorithm to optimize patches for black-box patch attacks. The method models patches using paired key-points and uses targeted images as the initialization of patches, and parameter optimizations are all performed on the integer domain.</li>
<li>results: The paper demonstrates that DevoPatch outperforms state-of-the-art black-box patch attacks in terms of patch area and attack success rate within a given query budget on image classification and face verification. Additionally, the paper conducts the vulnerability evaluation of ViT and MLP on image classification in the decision-based patch attack setting for the first time.<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have been showed to be highly vulnerable to imperceptible adversarial perturbations. As a complementary type of adversary, patch attacks that introduce perceptible perturbations to the images have attracted the interest of researchers. Existing patch attacks rely on the architecture of the model or the probabilities of predictions and perform poorly in the decision-based setting, which can still construct a perturbation with the minimal information exposed -- the top-1 predicted label. In this work, we first explore the decision-based patch attack. To enhance the attack efficiency, we model the patches using paired key-points and use targeted images as the initialization of patches, and parameter optimizations are all performed on the integer domain. Then, we propose a differential evolutionary algorithm named DevoPatch for query-efficient decision-based patch attacks. Experiments demonstrate that DevoPatch outperforms the state-of-the-art black-box patch attacks in terms of patch area and attack success rate within a given query budget on image classification and face verification. Additionally, we conduct the vulnerability evaluation of ViT and MLP on image classification in the decision-based patch attack setting for the first time. Using DevoPatch, we can evaluate the robustness of models to black-box patch attacks. We believe this method could inspire the design and deployment of robust vision models based on various DNN architectures in the future.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Deep neural networks" is translated as "深度神经网络" (shēn dào shén zhī wǎng luò)* "adversarial perturbations" is translated as "敌对扰动" (dí zhòu zhào dòng)* "patch attacks" is translated as "质子攻击" (zhì zǐ gōng jī)* "decision-based setting" is translated as "决策基础设定" (jīe yì jī bǎsè)* "top-1 predicted label" is translated as "预测的第一个标签" (yù jí de dì yī gè biǎo)* "DevoPatch" is translated as "DevoPatch" (德朋补丁)* "query-efficient" is translated as "高效的查询" (gāo fáng de kè qiú)* "black-box patch attacks" is translated as "黑盒质子攻击" (hēi bāo zhì zǐ gōng jī)* "ViT" and "MLP" are translated as "ViT" and "MLP" (Vision Transformer and Multi-Layer Perceptron) respectively.
</details></li>
</ul>
<hr>
<h2 id="Weighted-Anisotropic-Isotropic-Total-Variation-for-Poisson-Denoising"><a href="#Weighted-Anisotropic-Isotropic-Total-Variation-for-Poisson-Denoising" class="headerlink" title="Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising"></a>Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00439">http://arxiv.org/abs/2307.00439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kbui1993/official_aitv_poisson_denoising">https://github.com/kbui1993/official_aitv_poisson_denoising</a></li>
<li>paper_authors: Kevin Bui, Yifei Lou, Fredrick Park, Jack Xin</li>
<li>for: 这篇研究旨在提出一个基于偏微分方程的Poisson噪声去除模型，以提高受到Poisson噪声影响的影像质量。</li>
<li>methods: 本研究使用weighted anisotropic-isotropic总variation（AITV）作为调整器，并使用分布式向量运算来实现高效的实现。</li>
<li>results: numerical experiments显示，我们的算法在影像质量和计算效率方面都比其他Poisson噪声去除方法表现更好。<details>
<summary>Abstract</summary>
Poisson noise commonly occurs in images captured by photon-limited imaging systems such as in astronomy and medicine. As the distribution of Poisson noise depends on the pixel intensity value, noise levels vary from pixels to pixels. Hence, denoising a Poisson-corrupted image while preserving important details can be challenging. In this paper, we propose a Poisson denoising model by incorporating the weighted anisotropic-isotropic total variation (AITV) as a regularization. We then develop an alternating direction method of multipliers with a combination of a proximal operator for an efficient implementation. Lastly, numerical experiments demonstrate that our algorithm outperforms other Poisson denoising methods in terms of image quality and computational efficiency.
</details>
<details>
<summary>摘要</summary>
POisson 噪声通常发生在由光子限制的摄影系统中，如天文学和医学中的图像摄影。由于噪声分布取决于像素Intensity值，噪声水平各像素不同，因此去噪Poisson损带的图像保持重要细节是有挑战性的。在这篇论文中，我们提出了一种含有加重weighted anisotropic-isotropic总变量(AITV)的Poisson去噪模型。然后，我们开发了一种alternating direction method of multipliers，并使用距离算子进行高效实现。最后，数值实验表明，我们的算法在图像质量和计算效率方面比其他Poisson去噪方法更高效。Note: "Poisson denoising" is translated as "去噪Poisson" in Simplified Chinese, which is a common way to refer to the process of removing Poisson noise from an image.
</details></li>
</ul>
<hr>
<h2 id="One-Copy-Is-All-You-Need-Resource-Efficient-Streaming-of-Medical-Imaging-Data-at-Scale"><a href="#One-Copy-Is-All-You-Need-Resource-Efficient-Streaming-of-Medical-Imaging-Data-at-Scale" class="headerlink" title="One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale"></a>One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00438">http://arxiv.org/abs/2307.00438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/um2ii/openjphpy">https://github.com/um2ii/openjphpy</a></li>
<li>paper_authors: Pranav Kulkarni, Adway Kanhere, Eliot Siegel, Paul H. Yi, Vishwa S. Parekh</li>
<li>for: 这篇研究旨在解决医疗影像大量数据对于储存和网络带宽的瓶颈问题，并且提供一个开源框架来实现进程Resolution的运算。</li>
<li>methods: 这篇研究使用了一个名为MIST的开源框架，可以将医疗影像存储在单一高分辨率的档案中，并且可以根据使用者的需求进行不同的分辨率下载。</li>
<li>results: 研究发现，使用MIST可以对医疗影像储存和流程实现大量数据储存和网络带宽的节省，并且可以维持深度学习应用的诊断质量。<details>
<summary>Abstract</summary>
Large-scale medical imaging datasets have accelerated development of artificial intelligence tools for clinical decision support. However, the large size of these datasets is a bottleneck for users with limited storage and bandwidth. Many users may not even require such large datasets as AI models are often trained on lower resolution images. If users could directly download at their desired resolution, storage and bandwidth requirements would significantly decrease. However, it is impossible to anticipate every users' requirements and impractical to store the data at multiple resolutions. What if we could store images at a single resolution but send them at different ones? We propose MIST, an open-source framework to operationalize progressive resolution for streaming medical images at multiple resolutions from a single high-resolution copy. We demonstrate that MIST can dramatically reduce imaging infrastructure inefficiencies for hosting and streaming medical images by >90%, while maintaining diagnostic quality for deep learning applications.
</details>
<details>
<summary>摘要</summary>
大规模医疗影像数据集已经推动人工智能工具的开发，以支持临床决策。然而，这些大规模数据集的尺寸成为用户储存和带宽限制的瓶颈。许多用户可能不需要这么大的数据集，因为人工智能模型通常在较低分辨率的图像上训练。如果用户可以直接下载他们所需的分辨率，储存和带宽要求就会减少很多。然而，预测每个用户的需求是不可能的，并且不可能将数据存储在多个分辨率下。我们提出了MIST框架，一个开源的框架，用于在多个分辨率下进行进程式分辨率的流动医疗影像传输。我们示示了MIST可以减少医疗影像基础设施的不效ientecies >90%，同时保持深度学习应用的诊断质量。
</details></li>
</ul>
<hr>
<h2 id="Brightness-Restricted-Adversarial-Attack-Patch"><a href="#Brightness-Restricted-Adversarial-Attack-Patch" class="headerlink" title="Brightness-Restricted Adversarial Attack Patch"></a>Brightness-Restricted Adversarial Attack Patch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00421">http://arxiv.org/abs/2307.00421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingzhen Shao</li>
<li>for: 防御攻击补丁的实际应用场景中，尝试减少袋颜色的使用，以降低人类识别的风险。</li>
<li>methods: 使用光学特性来减少袋颜色的醒目性，保持图像独立性。</li>
<li>results: 对各种图像特征（如颜色、文本、噪声、大小）的分析，发现攻击袋 exhibit 强大的彩度相对性和颜色传输异常，并且对噪声有较强的抗性。基于这些发现，提出了进一步减少袋颜色的方法。<details>
<summary>Abstract</summary>
Adversarial attack patches have gained increasing attention due to their practical applicability in physical-world scenarios. However, the bright colors used in attack patches represent a significant drawback, as they can be easily identified by human observers. Moreover, even though these attacks have been highly successful in deceiving target networks, which specific features of the attack patch contribute to its success are still unknown. Our paper introduces a brightness-restricted patch (BrPatch) that uses optical characteristics to effectively reduce conspicuousness while preserving image independence. We also conducted an analysis of the impact of various image features (such as color, texture, noise, and size) on the effectiveness of an attack patch in physical-world deployment. Our experiments show that attack patches exhibit strong redundancy to brightness and are resistant to color transfer and noise. Based on our findings, we propose some additional methods to further reduce the conspicuousness of BrPatch. Our findings also explain the robustness of attack patches observed in physical-world scenarios.
</details>
<details>
<summary>摘要</summary>
侵略攻击贴图在实际场景中获得了越来越多的关注，但是侵略贴图中使用的鲜明颜色带来了一定的缺点，因为它们可以轻易被人类识别。尽管这些攻击已经在目标网络中取得了高度的成功，但是哪些特征使得攻击贴图成功还不清楚。我们的论文介绍了一种具有限制颜色的攻击贴图（BrPatch），使用光学特性来有效地减少鲜明程度，保持图像独立性。我们还进行了图像特征（如颜色、文本、噪声和大小）对攻击贴图的影响分析。我们的实验表明，攻击贴图具有强大的颜色减少和噪声抗耗特性。基于我们的发现，我们提出了进一步减少鲜明度的方法。我们的发现也解释了实际场景中观察到的攻击贴图 Robustness。
</details></li>
</ul>
<hr>
<h2 id="Applications-of-Binary-Similarity-and-Distance-Measures"><a href="#Applications-of-Binary-Similarity-and-Distance-Measures" class="headerlink" title="Applications of Binary Similarity and Distance Measures"></a>Applications of Binary Similarity and Distance Measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00411">http://arxiv.org/abs/2307.00411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manoj Muniswamaiah, Tilak Agerwala, Charles C. Tappert</li>
<li>for: 本研究探讨了二进制相似度测量在不同领域的应用。</li>
<li>methods: 本研究使用了二进制距离度量法和相似度测量方法。</li>
<li>results: 研究发现，二进制相似度测量在生物特征识别、手写字符识别和复眼图像识别等领域具有广泛的应用前景。Here’s a breakdown of each point:</li>
<li>for: 本研究探讨了二进制相似度测量在不同领域的应用。 (The paper explores the application of binary similarity measures in various fields.)</li>
<li>methods: 本研究使用了二进制距离度量法和相似度测量方法。 (The study uses binary distance measures and similarity measurement methods.)</li>
<li>results: 研究发现，二进制相似度测量在生物特征识别、手写字符识别和复眼图像识别等领域具有广泛的应用前景。 (The study finds that binary similarity measures have broad applications in fields such as biometric identification, handwritten character recognition, and iris image recognition.)<details>
<summary>Abstract</summary>
In the recent past, binary similarity measures have been applied in solving biometric identification problems, including fingerprint, handwritten character detection, and in iris image recognition. The application of the relevant measurements has also resulted in more accurate data analysis. This paper surveys the applicability of binary similarity and distance measures in various fields.
</details>
<details>
<summary>摘要</summary>
Note:* "二进制" (er-jie) means "binary" in Chinese.* "相似度度量" (xiang-si-duo-liang) means "similarity measures" or "distance measures" in Chinese.* "生物метриiddle" (shēng-wù-métài) means "biometric identification" in Chinese.* "指纹" (zhǐ-yīn) means "fingerprint" in Chinese.* "手写字符" (shǒu-xī-zi-fu) means "handwritten character" in Chinese.* "远景图像" (yuán-jǐng-tú-xìng) means "iris image" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Improving-CNN-based-Person-Re-identification-using-score-Normalization"><a href="#Improving-CNN-based-Person-Re-identification-using-score-Normalization" class="headerlink" title="Improving CNN-based Person Re-identification using score Normalization"></a>Improving CNN-based Person Re-identification using score Normalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00397">http://arxiv.org/abs/2307.00397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar Chouchane, Abdelmalik Ouamane, Yassine Himeur, Wathiq Mansoor, Shadi Atalla, Afaf Benzaibak, Chahrazed Boudellal</li>
<li>For: 本文提出了一种新的人识别方法，用于解决多视角和不同照明和背景的问题。* Methods: 本文使用了卷积神经网络（CNN）来提取特征，并使用了交叉视角Quadratic Discriminant Analysis（XQDA）来学习度量。* Results: 在四个复杂的数据集上进行测试，包括VIPer、GRID、CUHK01和PRID450S，并取得了承诺的结果，例如在GRID、CUHK01、VIPer和PRID450S数据集上，无 норма化情况下的rank-20率准确率分别为61.92%、83.90%、92.03%和96.22%，而经过分数 нормализа后，它们分别提高至64.64%、89.30%、92.78%和98.76%。<details>
<summary>Abstract</summary>
Person re-identification (PRe-ID) is a crucial task in security, surveillance, and retail analysis, which involves identifying an individual across multiple cameras and views. However, it is a challenging task due to changes in illumination, background, and viewpoint. Efficient feature extraction and metric learning algorithms are essential for a successful PRe-ID system. This paper proposes a novel approach for PRe-ID, which combines a Convolutional Neural Network (CNN) based feature extraction method with Cross-view Quadratic Discriminant Analysis (XQDA) for metric learning. Additionally, a matching algorithm that employs Mahalanobis distance and a score normalization process to address inconsistencies between camera scores is implemented. The proposed approach is tested on four challenging datasets, including VIPeR, GRID, CUHK01, and PRID450S, and promising results are obtained. For example, without normalization, the rank-20 rate accuracies of the GRID, CUHK01, VIPeR and PRID450S datasets were 61.92%, 83.90%, 92.03%, 96.22%; however, after score normalization, they have increased to 64.64%, 89.30%, 92.78%, and 98.76%, respectively. Accordingly, the promising results on four challenging datasets indicate the effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
人员重识别（PRe-ID）是安全、监测和营销分析中的关键任务，它的目标是在多个摄像头和视图下识别个体。然而，由于照明、背景和视角的变化，PRe-IDTask 是一项具有挑战性的任务。efficient的特征提取和度量学习算法是一个成功的 PRe-ID 系统的关键。这篇论文提出了一种新的 PRe-ID 方法，该方法结合了卷积神经网络（CNN）基于特征提取方法和跨视图quadratice Discriminant Analysis（XQDA）度量学习算法。此外，一种使用 Mahalanobis 距离和分数 нормализа处理来解决相机分数不一致的匹配算法也被实现。提议的方法在四个复杂的数据集上进行测试，包括 VIPeR、GRID、CUHK01 和 PRID450S，并取得了俊czy的结果。例如，无Normalization 的 GRID、CUHK01、VIPeR 和 PRID450S 数据集的 rank-20 率准确率分别为 61.92%、83.90%、92.03% 和 96.22%；然而，通过分数 Normalization 后，它们的 rank-20 率准确率分别提高到 64.64%、89.30%、92.78% 和 98.76%。因此，在四个复杂的数据集上取得的俊czy的结果表明了提议的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="MobileViG-Graph-Based-Sparse-Attention-for-Mobile-Vision-Applications"><a href="#MobileViG-Graph-Based-Sparse-Attention-for-Mobile-Vision-Applications" class="headerlink" title="MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications"></a>MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00395">http://arxiv.org/abs/2307.00395</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sldgroup/mobilevig">https://github.com/sldgroup/mobilevig</a></li>
<li>paper_authors: Mustafa Munir, William Avery, Radu Marculescu</li>
<li>For: This paper proposes a new graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA), and a hybrid CNN-GNN architecture, MobileViG, for vision tasks on mobile devices.* Methods: The proposed SVGA mechanism is designed to reduce the computational cost of representing images as graph structures, making it more suitable for mobile devices. The MobileViG architecture combines SVGA with a CNN backbone to achieve better performance and efficiency.* Results: The proposed MobileViG model achieves state-of-the-art performance and efficiency on image classification, object detection, and instance segmentation tasks on mobile devices. The fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy on ImageNet-1K with 0.78 ms inference latency, while the largest model, MobileViG-B, obtains 82.6% top-1 accuracy with only 2.30 ms latency.<details>
<summary>Abstract</summary>
Traditionally, convolutional neural networks (CNN) and vision transformers (ViT) have dominated computer vision. However, recently proposed vision graph neural networks (ViG) provide a new avenue for exploration. Unfortunately, for mobile applications, ViGs are computationally expensive due to the overhead of representing images as graph structures. In this work, we propose a new graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA), that is designed for ViGs running on mobile devices. Additionally, we propose the first hybrid CNN-GNN architecture for vision tasks on mobile devices, MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats existing ViG models and existing mobile CNN and ViT architectures in terms of accuracy and/or speed on image classification, object detection, and instance segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU (compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7% top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model, MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is faster and more accurate than the similarly sized EfficientFormer-L3 model (2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN architectures can be a new avenue of exploration for designing models that are extremely fast and accurate on mobile devices. Our code is publicly available at https://github.com/SLDGroup/MobileViG.
</details>
<details>
<summary>摘要</summary>
传统上，卷积神经网络（CNN）和视图转换器（ViT）在计算机视觉领域占据主导地位，但最近提出的视图图神经网络（ViG）提供了一个新的探索途径。然而，由于将图像表示为图结构的开销，ViG在移动设备上运行时 computationally expensive。在这种情况下，我们提出了一种新的图形基于的稀疏注意机制——图像稀疏视Graph注意（SVGA），用于ViG在移动设备上运行。此外，我们还提出了首个在移动设备上运行的hybrid CNN-GNN架构——MobileViG，它使用了SVGA。我们的实验表明，MobileViG可以在图像分类、物体检测和实例分割任务中比现有的ViG模型和移动设备上的CNN和ViT架构更高的准确率和/或速度。我们最快的模型MobileViG-Ti在ImageNet-1K上取得75.7%的顶部1准确率，并且在iPhone 13 Mini NPU上编译后的执行时间为0.78毫秒，比MobileNetV2x1.4（1.02毫秒，74.7%）和MobileNetV2x1.0（0.81毫秒，71.8%）更快。我们最大的模型MobileViG-B在82.6%的顶部1准确率下，只需2.30毫秒的执行时间，比同等大小的EfficientFormer-L3模型（2.77毫秒，82.4%）更快和更准确。我们的工作证明了，以Well designed hybrid CNN-GNN架构为基础的模型可以在移动设备上设计出非常快速和准确的模型。我们的代码公开在https://github.com/SLDGroup/MobileViG上。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/cs.CV_2023_07_02/" data-id="cloimip7z00dfs4888660fctm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/cs.AI_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T12:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/cs.AI_2023_07_02/">cs.AI - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="RH20T-A-Robotic-Dataset-for-Learning-Diverse-Skills-in-One-Shot"><a href="#RH20T-A-Robotic-Dataset-for-Learning-Diverse-Skills-in-One-Shot" class="headerlink" title="RH20T: A Robotic Dataset for Learning Diverse Skills in One-Shot"></a>RH20T: A Robotic Dataset for Learning Diverse Skills in One-Shot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00595">http://arxiv.org/abs/2307.00595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao-Shu Fang, Hongjie Fang, Zhenyu Tang, Jirong Liu, Junbo Wang, Haoyi Zhu, Cewu Lu</li>
<li>For: The paper aims to enable robots to acquire diverse and generalizable skills in open domains using one-shot imitation learning with multi-modal perception.* Methods: The paper uses a large-scale dataset of contact-rich robot manipulation sequences collected in the real world, with visual, force, audio, and action information, along with human demonstration videos. The dataset is calibrated and made publicly available.* Results: The paper aims to unlock the potential for an agent to generalize to hundreds of real-world skills with multi-modal perception.<details>
<summary>Abstract</summary>
A key challenge in robotic manipulation in open domains is how to acquire diverse and generalizable skills for robots. Recent research in one-shot imitation learning has shown promise in transferring trained policies to new tasks based on demonstrations. This feature is attractive for enabling robots to acquire new skills and improving task and motion planning. However, due to limitations in the training dataset, the current focus of the community has mainly been on simple cases, such as push or pick-place tasks, relying solely on visual guidance. In reality, there are many complex skills, some of which may even require both visual and tactile perception to solve. This paper aims to unlock the potential for an agent to generalize to hundreds of real-world skills with multi-modal perception. To achieve this, we have collected a dataset comprising over 110,000 \emph{contact-rich} robot manipulation sequences across diverse skills, contexts, robots, and camera viewpoints, all collected \emph{in the real world}. Each sequence in the dataset includes visual, force, audio, and action information, along with a corresponding human demonstration video. We have invested significant efforts in calibrating all the sensors and ensuring a high-quality dataset. The dataset is made publicly available at rh20t.github.io
</details>
<details>
<summary>摘要</summary>
一大挑战在机器人操作中是如何获得多样化和普遍适用的技能。最近的研究表明一次学习可以将训练的政策传递到新任务基于示例。这个特点很有吸引力，可以使机器人获得新的技能并改进任务和运动规划。然而，由于训练数据的限制，当前社区的关注主要集中在简单的情况，如推或捕捉任务，凭借视觉指导。在实际情况下，有许多复杂的技能，一些甚至需要视觉和感觉感知来解决。这篇论文旨在解锁一个代理人能够通过多模态感知泛化到百种真实世界技能。为了实现这一目标，我们收集了超过110,000个 contacts-rich机器人操作序列，涵盖多种技能、上下文、机器人和摄像头视点，全部在真实世界中收集。每个序列包括视觉、力、声音和动作信息，以及对应的人类示例视频。我们投入了大量的努力来准确各种感知器和高质量数据集。数据集现已公开在 rh20t.github.io
</details></li>
</ul>
<hr>
<h2 id="BioCPT-Contrastive-Pre-trained-Transformers-with-Large-scale-PubMed-Search-Logs-for-Zero-shot-Biomedical-Information-Retrieval"><a href="#BioCPT-Contrastive-Pre-trained-Transformers-with-Large-scale-PubMed-Search-Logs-for-Zero-shot-Biomedical-Information-Retrieval" class="headerlink" title="BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval"></a>BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00589">http://arxiv.org/abs/2307.00589</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ncbi/biocpt">https://github.com/ncbi/biocpt</a></li>
<li>paper_authors: Qiao Jin, Won Kim, Qingyu Chen, Donald C. Comeau, Lana Yeganova, John Wilbur, Zhiyong Lu</li>
<li>for:  This paper aims to improve the performance of biomedical information retrieval (IR) systems by introducing a new Contrastively Pre-trained Transformer (BioCPT) model.</li>
<li>methods:  The authors use contrastive learning to train a pair of closely-integrated retriever and re-ranker using an unprecedented scale of 255 million user click logs from PubMed.</li>
<li>results:  BioCPT sets new state-of-the-art performance on five biomedical IR tasks, outperforming various baselines including much larger models such as GPT-3-sized cpt-text-XL. Additionally, BioCPT generates better biomedical article and sentence representations for semantic evaluations.<details>
<summary>Abstract</summary>
Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained Transformer model for zero-shot biomedical IR. To train BioCPT, we collected an unprecedented scale of 255 million user click logs from PubMed. With such data, we use contrastive learning to train a pair of closely-integrated retriever and re-ranker. Experimental results show that BioCPT sets new state-of-the-art performance on five biomedical IR tasks, outperforming various baselines including much larger models such as GPT-3-sized cpt-text-XL. In addition, BioCPT also generates better biomedical article and sentence representations for semantic evaluations. As such, BioCPT can be readily applied to various real-world biomedical IR tasks. BioCPT API and code are publicly available at https://github.com/ncbi/BioCPT.
</details>
<details>
<summary>摘要</summary>
生物医学知识获取 (IR) 是生物医学领域的关键技术，帮助医生和研究人员快速找到有关疾病和病理的信息。然而，在生物医学领域，获取大量的查询-文章对应数据很困难，这限制了IR系统的发展。因此，大多数生物医学IR系统只能进行字面匹配。为了解决这个问题，我们提出了 BioCPT，一种首先在生物医学IR领域使用对比预训练变换器的方法。我们使用了255万次PubMed用户点击记录来训练 BioCPT，并使用对比学习训练一对 closely-integrated retriever和重新排序器。实验结果表明，BioCPT在五种生物医学IR任务中设置了新的状态态束表现，超过了多种基eline，包括GPT-3-sized cpt-text-XL。此外，BioCPT还生成了更好的生物医学文章和句子表示，用于semantic评估。因此，BioCPT可以轻松应用于各种生物医学IR任务。BioCPT API和代码在https://github.com/ncbi/BioCPT上公开提供。
</details></li>
</ul>
<hr>
<h2 id="Protecting-the-Future-Neonatal-Seizure-Detection-with-Spatial-Temporal-Modeling"><a href="#Protecting-the-Future-Neonatal-Seizure-Detection-with-Spatial-Temporal-Modeling" class="headerlink" title="Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling"></a>Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05382">http://arxiv.org/abs/2307.05382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyue Li, Yuchen Fang, You Li, Kan Ren, Yansen Wang, Xufang Luo, Juanyong Duan, Congrui Huang, Dongsheng Li, Lili Qiu<br>for: 这份研究是为了提出一个深度学习框架，以便帮助新生儿电脑 Tomography （EEG）中的癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫癫�<details>
<summary>Abstract</summary>
A timely detection of seizures for newborn infants with electroencephalogram (EEG) has been a common yet life-saving practice in the Neonatal Intensive Care Unit (NICU). However, it requires great human efforts for real-time monitoring, which calls for automated solutions to neonatal seizure detection. Moreover, the current automated methods focusing on adult epilepsy monitoring often fail due to (i) dynamic seizure onset location in human brains; (ii) different montages on neonates and (iii) huge distribution shift among different subjects. In this paper, we propose a deep learning framework, namely STATENet, to address the exclusive challenges with exquisite designs at the temporal, spatial and model levels. The experiments over the real-world large-scale neonatal EEG dataset illustrate that our framework achieves significantly better seizure detection performance.
</details>
<details>
<summary>摘要</summary>
新生儿在婴儿急救室（NICU）中的电энцефаogram（EEG）检测已成为一种常见 yet 生命存在的做法。然而，这需要大量的人工监测，呼吁自动化解决方案。然而，现有的自动化方法往往因（i）人脑突发发生地点的动态性；（ii）婴儿和成人montage的不同；以及（iii）不同个体之间的巨大分布变化而失败。本文提出了一个深度学习框架，即STATENet，以解决这些独特的挑战。实验表明，我们的框架在真实世界大规模的新生儿EEG数据集上表现出了明显更好的癫痫检测性能。
</details></li>
</ul>
<hr>
<h2 id="Filter-Bubbles-in-Recommender-Systems-Fact-or-Fallacy-–-A-Systematic-Review"><a href="#Filter-Bubbles-in-Recommender-Systems-Fact-or-Fallacy-–-A-Systematic-Review" class="headerlink" title="Filter Bubbles in Recommender Systems: Fact or Fallacy – A Systematic Review"></a>Filter Bubbles in Recommender Systems: Fact or Fallacy – A Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.01221">http://arxiv.org/abs/2307.01221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qazi Mohammad Areeb, Mohammad Nadeem, Shahab Saquib Sohail, Raza Imam, Faiyaz Doctor, Yassine Himeur, Amir Hussain, Abbes Amira</li>
<li>for: This paper aims to investigate the impact of filter bubbles in recommender systems and propose an integrated approach to mitigate their effects.</li>
<li>methods: The authors conduct a systematic literature review on the topic of filter bubbles in recommender systems, analyzing and classifying the reviewed articles to provide valuable insights.</li>
<li>results: The authors identify evidence of filter bubbles in recommendation systems, highlighting several biases that contribute to their existence. They also propose mechanisms to mitigate the impact of filter bubbles and demonstrate that incorporating diversity into recommendations can potentially help alleviate this issue.<details>
<summary>Abstract</summary>
A filter bubble refers to the phenomenon where Internet customization effectively isolates individuals from diverse opinions or materials, resulting in their exposure to only a select set of content. This can lead to the reinforcement of existing attitudes, beliefs, or conditions. In this study, our primary focus is to investigate the impact of filter bubbles in recommender systems. This pioneering research aims to uncover the reasons behind this problem, explore potential solutions, and propose an integrated tool to help users avoid filter bubbles in recommender systems. To achieve this objective, we conduct a systematic literature review on the topic of filter bubbles in recommender systems. The reviewed articles are carefully analyzed and classified, providing valuable insights that inform the development of an integrated approach. Notably, our review reveals evidence of filter bubbles in recommendation systems, highlighting several biases that contribute to their existence. Moreover, we propose mechanisms to mitigate the impact of filter bubbles and demonstrate that incorporating diversity into recommendations can potentially help alleviate this issue. The findings of this timely review will serve as a benchmark for researchers working in interdisciplinary fields such as privacy, artificial intelligence ethics, and recommendation systems. Furthermore, it will open new avenues for future research in related domains, prompting further exploration and advancement in this critical area.
</details>
<details>
<summary>摘要</summary>
Filter bubble 是指互联网个性化化导致个人仅浏览一 selec tset of content，从而隔离多元意见或内容，这可能会加剧现有的态度、信念或情况。在这项研究中，我们的主要关注点是调查推荐系统中的过滤层。我们通过系统性的文献综述，挖掘了这个问题的原因，探索可能的解决方案，并提出一种集成的工具，帮助用户避免推荐系统中的过滤层。我们认为，通过 incorporating 多样性到推荐中可能有助于缓解这个问题。我们的综述还发现了推荐系统中的过滤层证据，揭示了一些偏见的来源。我们还提出了一些缓解过滤层影响的机制，并证明了在推荐中 incorporating 多样性可能有助于缓解这个问题。我们的研究结果将成为互联网隐私、人工智能伦理和推荐系统等领域的研究 benchmark，并开创了未来研究的新途径。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-reinforcement-learning-of-multi-agent-ethically-aligned-behaviours-the-QSOM-and-QDSOM-algorithms"><a href="#Adaptive-reinforcement-learning-of-multi-agent-ethically-aligned-behaviours-the-QSOM-and-QDSOM-algorithms" class="headerlink" title="Adaptive reinforcement learning of multi-agent ethically-aligned behaviours: the QSOM and QDSOM algorithms"></a>Adaptive reinforcement learning of multi-agent ethically-aligned behaviours: the QSOM and QDSOM algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00552">http://arxiv.org/abs/2307.00552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémy Chaput, Olivier Boissier, Mathieu Guillermin</li>
<li>for: 这种论文是为了解决人工智能系统与我们的伦理考虑相协调的问题而写的。</li>
<li>methods: 这两种算法（QSOM 和 QDSOM）使用了自适应环境和奖励函数的方法，以适应环境和伦理考虑的变化。</li>
<li>results: 在一个小型智能Grid社区中，这两种算法在多个代理人能源分配问题上表现出了适应和高性能，比基eline Reinforcement Learning算法更好。<details>
<summary>Abstract</summary>
The numerous deployed Artificial Intelligence systems need to be aligned with our ethical considerations. However, such ethical considerations might change as time passes: our society is not fixed, and our social mores evolve. This makes it difficult for these AI systems; in the Machine Ethics field especially, it has remained an under-studied challenge. In this paper, we present two algorithms, named QSOM and QDSOM, which are able to adapt to changes in the environment, and especially in the reward function, which represents the ethical considerations that we want these systems to be aligned with. They associate the well-known Q-Table to (Dynamic) Self-Organizing Maps to handle the continuous and multi-dimensional state and action spaces. We evaluate them on a use-case of multi-agent energy repartition within a small Smart Grid neighborhood, and prove their ability to adapt, and their higher performance compared to baseline Reinforcement Learning algorithms.
</details>
<details>
<summary>摘要</summary>
各种部署的人工智能系统需要与我们的道德考虑进行协调。然而，这些道德考虑可能随着时间的推移而改变：我们的社会不固定，我们的社会习俗也在发展。这会让这些 AI 系统受到挑战，特别是在机器伦理学领域，这是一个未得到充分研究的挑战。在这篇论文中，我们提出了两种算法，即 QSOM 和 QDSOM，它们能够适应环境的变化，特别是奖励函数的变化，这些奖励函数表达我们想要这些系统与我们的道德考虑相协调。它们将知名的 Q-表与（动态）自组织地图相结合，以处理连续和多维状态和动作空间。我们在一个多个代理在小智能网格中的能源分配use case中评估了它们，并证明它们的适应性和高性能相比基eline Reinforcement Learning算法。
</details></li>
</ul>
<hr>
<h2 id="Defending-Against-Malicious-Behaviors-in-Federated-Learning-with-Blockchain"><a href="#Defending-Against-Malicious-Behaviors-in-Federated-Learning-with-Blockchain" class="headerlink" title="Defending Against Malicious Behaviors in Federated Learning with Blockchain"></a>Defending Against Malicious Behaviors in Federated Learning with Blockchain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00543">http://arxiv.org/abs/2307.00543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael Kampffmeyer, Yizhe Wen, Shuoying Zhang, William Knottenbelt, Eric Xing</li>
<li>for: 提出了一种基于区块链和分布ledger技术的安全可靠的联合学习系统，以解决现有联合学习方法中的单点失败风险。</li>
<li>methods: 我们的系统使用了点对点投票机制和奖励折损机制，这些机制通过在链上智能合约支持来检测和抵制不良客户端行为。</li>
<li>results: 我们的 teoría y empirical analyses 表明，我们的框架可以具有强大的对抗不良客户端行为的能力，并且可以提高联合学习的安全性和可靠性。<details>
<summary>Abstract</summary>
In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.
</details>
<details>
<summary>摘要</summary>
在深度学习时代，联邦学习（FL）提供了一种有前途的方法，允许多家机构数据所有者或客户集成机器学习模型，无需产生数据隐私问题。然而，大多数现有FL方法仍然依赖中央服务器进行全球模型汇总，这会导致单点失败。这会使系统易受到不良客户的攻击，特别是在与不诚实客户进行交互时。在这种情况下，我们解决这个问题，通过基于区块链和分布式日志技术的安全可靠FL系统。我们的系统包括了分布式投票机制和奖励折损机制，这些机制都是基于链上智能合约，以探测和抑制贪念行为。我们提供了理论和实证分析，以证明我们的框架具有对不良客户侧行为的强大抗性。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Super-Resolution-Networks-through-Realistic-Thick-Slice-CT-Simulation"><a href="#Enhancing-Super-Resolution-Networks-through-Realistic-Thick-Slice-CT-Simulation" class="headerlink" title="Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation"></a>Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10182">http://arxiv.org/abs/2307.10182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Tang, Xiaodan Xing, Guang Yang<br>for:The paper aims to develop and evaluate an innovative simulation algorithm for generating thick-slice CT images that closely resemble actual images.methods:The proposed method uses a novel simulation algorithm to generate thick-slice CT images, which are evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error (RMSE) metrics.results:The proposed method demonstrated substantial enhancements in terms of both PSNR and RMSE over other simulation methods, with the highest PSNR values obtained and the lowest RMSE. The generated images were then used to train four distinct super-resolution (SR) models, which exhibited enhanced performance when trained with data produced by the proposed algorithm.<details>
<summary>Abstract</summary>
This study aims to develop and evaluate an innovative simulation algorithm for generating thick-slice CT images that closely resemble actual images in the AAPM-Mayo's 2016 Low Dose CT Grand Challenge dataset. The proposed method was evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error (RMSE) metrics, with the hypothesis that our simulation would produce images more congruent with their real counterparts. Our proposed method demonstrated substantial enhancements in terms of both PSNR and RMSE over other simulation methods. The highest PSNR values were obtained with the proposed method, yielding 49.7369 $\pm$ 2.5223 and 48.5801 $\pm$ 7.3271 for D45 and B30 reconstruction kernels, respectively. The proposed method also registered the lowest RMSE with values of 0.0068 $\pm$ 0.0020 and 0.0108 $\pm$ 0.0099 for D45 and B30, respectively, indicating a distribution more closely aligned with the authentic thick-slice image. Further validation of the proposed simulation algorithm was conducted using the TCIA LDCT-and-Projection-data dataset. The generated images were then leveraged to train four distinct super-resolution (SR) models, which were subsequently evaluated using the real thick-slice images from the 2016 Low Dose CT Grand Challenge dataset. When trained with data produced by our novel algorithm, all four SR models exhibited enhanced performance.
</details>
<details>
<summary>摘要</summary>
Translation:这项研究的目的是开发和评估一种创新的厚slice CT图像生成算法，以便更好地模拟实际图像在AAPM-Mayo的2016年低剂量CT大挑战数据集中。提议的方法通过PSNR和RMSE метри来评估，假设我们的模拟会生成更加相似的实际图像。我们的提议方法显示了较大的改善，PSNR和RMSE都达到了最高值。对D45和B30重建核而言，提议方法的PSNR值为49.7369 ± 2.5223和48.5801 ± 7.3271，而RMSE值为0.0068 ± 0.0020和0.0108 ± 0.0099。这表明我们的方法生成的图像更加准确地反映实际图像。此外，我们还对使用TCIA LDCT-and-Projection-data数据集进行了进一步验证。生成的图像然后被用来训练四种不同的超分辨率（SR）模型，并使用实际厚slice图像从2016年低剂量CT大挑战数据集进行评估。当使用我们的新算法生成数据时，所有四种SR模型均表现出了改善。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Policy-Learning-for-Dynamic-Scheduling-Tasks-in-Cloud-Edge-Terminal-IoT-Networks-Using-Federated-Reinforcement-Learning"><a href="#Collaborative-Policy-Learning-for-Dynamic-Scheduling-Tasks-in-Cloud-Edge-Terminal-IoT-Networks-Using-Federated-Reinforcement-Learning" class="headerlink" title="Collaborative Policy Learning for Dynamic Scheduling Tasks in Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning"></a>Collaborative Policy Learning for Dynamic Scheduling Tasks in Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00541">http://arxiv.org/abs/2307.00541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Do-Yup Kim, Da-Eun Lee, Ji-Wan Kim, Hyun-Suk Lee</li>
<li>for: 这种论文探讨了云端-边缘-终端互联网络，其中边缘进行了一系列常见的动态调度任务。</li>
<li>methods: 该论文提出了一种基于联邦强化学习的共同策略学习框架，用于动态调度任务。此外，论文还提出了一种具有层次结构的互联网络，以实现对策略的集成学习。</li>
<li>results: 通过实验，论文表明了该框架在动态调度任务中的显著优势，包括加速策略学习速度和使新到达的边缘更容易适应其任务。<details>
<summary>Abstract</summary>
In this paper, we examine cloud-edge-terminal IoT networks, where edges undertake a range of typical dynamic scheduling tasks. In these IoT networks, a central policy for each task can be constructed at a cloud server. The central policy can be then used by the edges conducting the task, thereby mitigating the need for them to learn their own policy from scratch. Furthermore, this central policy can be collaboratively learned at the cloud server by aggregating local experiences from the edges, thanks to the hierarchical architecture of the IoT networks. To this end, we propose a novel collaborative policy learning framework for dynamic scheduling tasks using federated reinforcement learning. For effective learning, our framework adaptively selects the tasks for collaborative learning in each round, taking into account the need for fairness among tasks. In addition, as a key enabler of the framework, we propose an edge-agnostic policy structure that enables the aggregation of local policies from different edges. We then provide the convergence analysis of the framework. Through simulations, we demonstrate that our proposed framework significantly outperforms the approaches without collaborative policy learning. Notably, it accelerates the learning speed of the policies and allows newly arrived edges to adapt to their tasks more easily.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了云端-边缘-终端互联网络，其中边缘进行了一系列 Typical dynamic scheduling 任务。在这些互联网络中，可以在云服务器上构建每个任务的中央策略。然后，这些中央策略可以被边缘进行任务的边缘使用，从而减少边缘需要从头开始学习自己的策略的需求。此外，这些中央策略可以在云服务器上归一化地学习，通过对边缘的地址进行归一化。为了实现这一点，我们提出了一种基于联邦感知学习的共同策略学习框架。为了有效学习，我们的框架在每次轮次中选择需要合作学习的任务，考虑到任务之间的公平性。此外，我们还提出了一种不受边缘限制的策略结构，允许在不同的边缘上合并本地策略。然后，我们提供了框架的收敛分析。通过 simulate，我们示出了我们提出的框架可以非常有效地与无共同策略学习相比。尤其是，它可以加速策略学习的速度，并使新到达的边缘更容易适应自己的任务。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Network-based-Log-Anomaly-Detection-and-Explanation"><a href="#Graph-Neural-Network-based-Log-Anomaly-Detection-and-Explanation" class="headerlink" title="Graph Neural Network based Log Anomaly Detection and Explanation"></a>Graph Neural Network based Log Anomaly Detection and Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00527">http://arxiv.org/abs/2307.00527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhong Li, Jiayang Shi, Matthijs van Leeuwen</li>
<li>for: 本研究旨在提高高科技系统监控中的日志异常检测精度，使用图structure来捕捉日志中的异常。</li>
<li>methods: 本方法使用图 neural network来检测日志中的异常，首先将日志转换为特征化、指向的、权重图，然后使用One-Class Digraph Inception Convolutional Networks（OCDiGCN）模型来检测图中的异常。</li>
<li>results: 实验结果显示，Logs2Graphs在五个基准数据集上至少与状态计算机方法相当，而在复杂数据集上大幅超过状态计算机方法。此外，对每个异常检测结果，还提供一小 subsets of nodes 作为解释，这些节点可以为后续根本原因诊断提供有价值的提示。<details>
<summary>Abstract</summary>
Event logs are widely used to record the status of high-tech systems, making log anomaly detection important for monitoring those systems. Most existing log anomaly detection methods take a log event count matrix or log event sequences as input, exploiting quantitative and/or sequential relationships between log events to detect anomalies. Unfortunately, only considering quantitative or sequential relationships may result in many false positives and/or false negatives. To alleviate this problem, we propose a graph-based method for unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts event logs into attributed, directed, and weighted graphs, and then leverages graph neural networks to perform graph-level anomaly detection. Specifically, we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as OCDiGCN, a novel graph neural network model for detecting graph-level anomalies in a collection of attributed, directed, and weighted graphs. By coupling the graph representation and anomaly detection steps, OCDiGCN can learn a representation that is especially suited for anomaly detection, resulting in a high detection accuracy. Importantly, for each identified anomaly, we additionally provide a small subset of nodes that play a crucial role in OCDiGCN's prediction as explanations, which can offer valuable cues for subsequent root cause diagnosis. Experiments on five benchmark datasets show that Logs2Graphs performs at least on par state-of-the-art log anomaly detection methods on simple datasets while largely outperforming state-of-the-art log anomaly detection methods on complicated datasets.
</details>
<details>
<summary>摘要</summary>
Event logs 广泛用于记录高科技系统的状态，因此 log anomaly detection 成为监测这些系统的重要任务。现有大多数 log anomaly detection 方法都使用 log event count matrix 或 log event sequences 作为输入，利用量质和/或序列关系 между log events 检测异常。然而，只考虑量质和/或序列关系可能会导致许多假阳性和/或假阴性。为解决这个问题，我们提议一种基于图的方法，称为 Logs2Graphs，它将事件日志转换为带有属性、指向的、权重的图，然后使用图神经网络进行图级异常检测。特别是，我们引入 One-Class Digraph Inception Convolutional Networks，简称 OCDiGCN，一种基于图的异常检测模型，用于检测图级异常。通过对图表示和异常检测步骤的结合，OCDiGCN 可以学习一种特别适合异常检测的表示，从而实现高的检测精度。此外，对每个被检测到的异常，我们还提供一小 subsets of nodes 作为 OCDiGCN 的预测所需的关键节点，这些节点可以提供有价值的诊断依据。在五个基准数据集上进行实验，Logs2Graphs 在简单的数据集上与状态的检测方法相当，而在复杂的数据集上大幅超越状态的检测方法。
</details></li>
</ul>
<hr>
<h2 id="LEDITS-Real-Image-Editing-with-DDPM-Inversion-and-Semantic-Guidance"><a href="#LEDITS-Real-Image-Editing-with-DDPM-Inversion-and-Semantic-Guidance" class="headerlink" title="LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance"></a>LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00522">http://arxiv.org/abs/2307.00522</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adham-elarabawy/ledits">https://github.com/adham-elarabawy/ledits</a></li>
<li>paper_authors: Linoy Tsaban, Apolinário Passos</li>
<li>for: 这个论文的目的是提出一种轻量级的实像编辑方法，以便使用文本来编辑真实的图像。</li>
<li>methods: 该方法使用 Edit Friendly DDPM 倒推技术和semantic guidance 组合，以扩展semantic guidance到实像编辑领域，同时利用 DDPM 倒推的编辑功能。</li>
<li>results: 该方法可以实现多样化的编辑效果，包括细微的修改和大幅的修改，以及修改图像的组成和风格，而无需修改模型的架构。<details>
<summary>Abstract</summary>
Recent large-scale text-guided diffusion models provide powerful image-generation capabilities. Currently, a significant effort is given to enable the modification of these images using text only as means to offer intuitive and versatile editing. However, editing proves to be difficult for these generative models due to the inherent nature of editing techniques, which involves preserving certain content from the original image. Conversely, in text-based models, even minor modifications to the text prompt frequently result in an entirely distinct result, making attaining one-shot generation that accurately corresponds to the users intent exceedingly challenging. In addition, to edit a real image using these state-of-the-art tools, one must first invert the image into the pre-trained models domain - adding another factor affecting the edit quality, as well as latency. In this exploratory report, we propose LEDITS - a combined lightweight approach for real-image editing, incorporating the Edit Friendly DDPM inversion technique with Semantic Guidance, thus extending Semantic Guidance to real image editing, while harnessing the editing capabilities of DDPM inversion as well. This approach achieves versatile edits, both subtle and extensive as well as alterations in composition and style, while requiring no optimization nor extensions to the architecture.
</details>
<details>
<summary>摘要</summary>
现代大规模文本导向扩散模型提供了强大的图像生成能力。目前，很大的努力在 modifying these images using text only as means to offer intuitive and versatile editing. However, editing proves to be difficult for these generative models due to the inherent nature of editing techniques, which involves preserving certain content from the original image. Conversely, in text-based models, even minor modifications to the text prompt frequently result in an entirely distinct result, making attaining one-shot generation that accurately corresponds to the users intent exceedingly challenging. In addition, to edit a real image using these state-of-the-art tools, one must first invert the image into the pre-trained models domain - adding another factor affecting the edit quality, as well as latency. In this exploratory report, we propose LEDITS - a combined lightweight approach for real-image editing, incorporating the Edit Friendly DDPM inversion technique with Semantic Guidance, thus extending Semantic Guidance to real image editing, while harnessing the editing capabilities of DDPM inversion as well. This approach achieves versatile edits, both subtle and extensive as well as alterations in composition and style, while requiring no optimization nor extensions to the architecture.
</details></li>
</ul>
<hr>
<h2 id="DSTCGCN-Learning-Dynamic-Spatial-Temporal-Cross-Dependencies-for-Traffic-Forecasting"><a href="#DSTCGCN-Learning-Dynamic-Spatial-Temporal-Cross-Dependencies-for-Traffic-Forecasting" class="headerlink" title="DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for Traffic Forecasting"></a>DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for Traffic Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00518">http://arxiv.org/abs/2307.00518</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/water-wbq/dstcgcn">https://github.com/water-wbq/dstcgcn</a></li>
<li>paper_authors: Binqing Wu, Ling Chen</li>
<li>for: 预测交通流量是智能交通系统中的关键任务，但是由于路网的复杂性和时空关系，现有方法通常会分别学习空间和时间两个维度的相互关系，忽略了时空两个维度之间的相互关系。本文提出了DSTCGCN，一种能够同时学习空间和时间两个维度的动态空间-时间跨度Graph Convolutional Network，用于交通流量预测。</li>
<li>methods: 本文提出了一种基于快速傅立叶变换（FFT）的注意力选择器，可以根据时间序列数据选择相关的时间步骤。然后，本文引入了动态跨度图构建模块，包括空间图构建、时间连接图构建和融合模块，以无预先假设的方式学习动态空间-时间跨度关系。</li>
<li>results: 在六个真实世界数据集上进行了广泛的实验，显示了DSTCGCN可以达到领先性的表现。<details>
<summary>Abstract</summary>
Traffic forecasting is essential to intelligent transportation systems, which is challenging due to the complicated spatial and temporal dependencies within a road network. Existing works usually learn spatial and temporal dependencies separately, ignoring the dependencies crossing spatial and temporal dimensions. In this paper, we propose DSTCGCN, a dynamic spatial-temporal cross graph convolution network to learn dynamic spatial and temporal dependencies jointly via graphs for traffic forecasting. Specifically, we introduce a fast Fourier transform (FFT) based attentive selector to choose relevant time steps for each time step based on time-varying traffic data. Given the selected time steps, we introduce a dynamic cross graph construction module, consisting of the spatial graph construction, temporal connection graph construction, and fusion modules, to learn dynamic spatial-temporal cross dependencies without pre-defined priors. Extensive experiments on six real-world datasets demonstrate that DSTCGCN achieves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统的关键 component, 具有较复杂的空间和时间相关性, 使得现有的方法通常是分别学习空间和时间相关性, 忽略了空间和时间维度之间的相互关系. 在这篇论文中, 我们提出了 DSTCGCN, 一种动态空间-时间cross graph convolution network, 用于同时学习动态空间和时间相关性. 具体来说, 我们引入了 Fast Fourier Transform (FFT) 基于的选择器, 用于每个时间步选择相关的时间步, 基于时变交通数据. 给出选择的时间步, 我们引入了动态cross graph construction module, 包括空间图构建模块, 时间连接图构建模块和融合模块, 以无预先假设的方式学习动态空间-时间相关性. 我们在六个实际数据集上进行了广泛的实验, 并证明了 DSTCGCN 在智能交通预测中具有最佳性能.
</details></li>
</ul>
<hr>
<h2 id="HeGeL-A-Novel-Dataset-for-Geo-Location-from-Hebrew-Text"><a href="#HeGeL-A-Novel-Dataset-for-Geo-Location-from-Hebrew-Text" class="headerlink" title="HeGeL: A Novel Dataset for Geo-Location from Hebrew Text"></a>HeGeL: A Novel Dataset for Geo-Location from Hebrew Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00509">http://arxiv.org/abs/2307.00509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/onlplab/hegel">https://github.com/onlplab/hegel</a></li>
<li>paper_authors: Tzuf Paz-Argaman, Tal Bauman, Itai Mondshine, Itzhak Omer, Sagi Dalyot, Reut Tsarfaty<br>for:This paper aims to collect and analyze literal Hebrew place descriptions to study lingual geospatial reasoning and improve textual geolocation.methods:The paper uses crowdsourcing to collect 5,649 literal Hebrew place descriptions in three cities in Israel, and employs qualitative and empirical analysis to examine the data’s geospatial reasoning and the need for a novel environmental representation.results:The study finds that the data exhibits abundant use of geospatial reasoning, indicating the importance of a novel environmental representation for textual geolocation in morphologically rich and resource-poor languages like Hebrew.<details>
<summary>Abstract</summary>
The task of textual geolocation - retrieving the coordinates of a place based on a free-form language description - calls for not only grounding but also natural language understanding and geospatial reasoning. Even though there are quite a few datasets in English used for geolocation, they are currently based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, such that the location retrieval resolution is limited. Furthermore, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.
</details>
<details>
<summary>摘要</summary>
文本地理位置 Retrieving the coordinates of a place based on a free-form language description requires not only grounding but also natural language understanding and geospatial reasoning. Although there are several datasets in English for geolocation, they are based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, resulting in limited location retrieval resolution. Furthermore, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.Note: "Simplified Chinese" is used to refer to the standardized form of Chinese used in mainland China and Singapore, as opposed to "Traditional Chinese" used in Hong Kong and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="Deep-Cross-Modal-Steganography-Using-Neural-Representations"><a href="#Deep-Cross-Modal-Steganography-Using-Neural-Representations" class="headerlink" title="Deep Cross-Modal Steganography Using Neural Representations"></a>Deep Cross-Modal Steganography Using Neural Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08671">http://arxiv.org/abs/2307.08671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gyojin Han, Dong-Jae Lee, Jiwan Hur, Jaehyun Choi, Junmo Kim</li>
<li>for: 这个论文是为了提出一种基于深度学习的跨模式隐藏措施，以隐藏不同类型的机密数据在封面图像中。</li>
<li>methods: 该框架使用隐藏表示（INRs）来表示机密数据，可以处理不同的模式和分辨率。</li>
<li>results: 实验结果表明，提出的方法可以扩展到不同的机密数据集，并且可以处理不同的模式和分辨率。<details>
<summary>Abstract</summary>
Steganography is the process of embedding secret data into another message or data, in such a way that it is not easily noticeable. With the advancement of deep learning, Deep Neural Networks (DNNs) have recently been utilized in steganography. However, existing deep steganography techniques are limited in scope, as they focus on specific data types and are not effective for cross-modal steganography. Therefore, We propose a deep cross-modal steganography framework using Implicit Neural Representations (INRs) to hide secret data of various formats in cover images. The proposed framework employs INRs to represent the secret data, which can handle data of various modalities and resolutions. Experiments on various secret datasets of diverse types demonstrate that the proposed approach is expandable and capable of accommodating different modalities.
</details>
<details>
<summary>摘要</summary>
《隐藏数据在另一个消息或数据中》是стегаノграфия的过程。随着深度学习的发展，深度神经网络（DNNs）最近在隐藏中使用。然而，现有的深度隐藏技术有限，因为它们专注于特定的数据类型，并不适用于跨模态隐藏。因此，我们提出了一种基于含义神经表示（INRs）的深度跨模态隐藏框架，以隐藏不同类型的秘密数据在覆写图像中。我们的框架使用INRs来表示秘密数据，可以处理不同的模态和分辨率。对于不同的秘密数据集进行了各种实验，结果表明我们的方法可以扩展和适应不同的模态。
</details></li>
</ul>
<hr>
<h2 id="Cloud-Ensemble-Learning-for-Fault-Diagnosis-of-Rolling-Bearings-with-Stochastic-Configuration-Networks"><a href="#Cloud-Ensemble-Learning-for-Fault-Diagnosis-of-Rolling-Bearings-with-Stochastic-Configuration-Networks" class="headerlink" title="Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with Stochastic Configuration Networks"></a>Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with Stochastic Configuration Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00507">http://arxiv.org/abs/2307.00507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Dai, Jiang Liu, Lanhao Wang</li>
<li>for: 这篇论文主要应用于推导滚当 fault diagnosis 的问题，尤其是在仅有少量数据的情况下。</li>
<li>methods: 本文使用了 Stochastic Configuration Network (SCN) 基于云端集成学习的方法，包括云端特征抽象方法和云端抽象样本生成方法，以及一个 Ensemble Model 来涵盖缺失信息的不确定性。</li>
<li>results: 实验结果显示，提案的方法可以优化滚当 fault diagnosis 的精度和一致性，尤其在仅有少量数据的情况下。<details>
<summary>Abstract</summary>
Fault diagnosis of rolling bearings is of great significance for post-maintenance in rotating machinery, but it is a challenging work to diagnose faults efficiently with a few samples. Additionally, faults commonly occur with randomness and fuzziness due to the complexity of the external environment and the structure of rolling bearings, hindering effective mining of fault characteristics and eventually restricting accuracy of fault diagnosis. To overcome these problems, stochastic configuration network (SCN) based cloud ensemble learning, called SCN-CEL, is developed in this work. Concretely, a cloud feature extraction method is first developed by using a backward cloud generator of normal cloud model to mine the uncertainty of fault information. Then, a cloud sampling method, which generates enough cloud droplets using bidirectional cloud generator, is proposed to extend the cloud feature samples. Finally, an ensemble model with SCNs is developed to comprehensively characterize the uncertainty of fault information and advance the generalization performance of fault diagnosis machine. Experimental results demonstrate that the proposed method indeed performs favorably for distinguishing fault categories of rolling bearings in the few shot scenarios.
</details>
<details>
<summary>摘要</summary>
FAULT诊断 OF ROLLING BEARINGS IS OF GREAT IMPORTANCE FOR POST-maintenance OF ROTATING MACHINERY, BUT IT IS A CHALLENGING TASK TO DIAGNOSE FAULTS EFFICIENTLY WITH A FEW SAMPLES. ADDITIONALLY, FAULTS OFTEN OCCUR WITH RANDOMNESS AND FUZZINESS DUE TO THE COMPLEXITY OF THE EXTERNAL ENVIRONMENT AND THE STRUCTURE OF ROLLING BEARINGS, HINDERING EFFECTIVE MINING OF FAULT CHARACTERISTICS AND eventually RESTRICTING THE ACCURACY OF FAULT DIAGNOSIS. TO OVERCOME THESE PROBLEMS, A STOCHASTIC CONFIGURATION NETWORK (SCN) BASED CLOUD ENSEMBLE LEARNING METHOD, CALLED SCN-CEL, IS DEVELOPED IN THIS WORK. CONCRETely, A CLOUD FEATURE EXTRACTION METHOD IS FIRST DEVELOPED BY USING A BACKWARD CLOUD GENERATOR OF NORMAL CLOUD MODEL TO MINE THE UNCERTAINTY OF FAULT INFORMATION. THEN, A CLOUD SAMPLING METHOD, WHICH GENERATES ENOUGH CLOUD DROPLETS USING BIDIRECTIONAL CLOUD GENERATOR, IS PROPOSED TO EXTEND THE CLOUD FEATURE SAMPLES. FINALLY, AN ENSEMBLE MODEL WITH SCNs IS DEVELOPED TO COMPREHENSIVELY CHARACTERIZE THE UNCERTAINTY OF FAULT INFORMATION AND ADVANCE THE GENERALIZATION PERFORMANCE OF FAULT DIAGNOSIS MACHINE. EXPERIMENTAL RESULTS DEMONSTRATE THAT THE PROPOSED METHOD INDEED PERFORMS FAVORABLY FOR DISTINGUISHING FAULT CATEGORIES OF ROLLING BEARINGS IN THE FEW SHOT SCENARIOS.
</details></li>
</ul>
<hr>
<h2 id="On-efficient-computation-in-active-inference"><a href="#On-efficient-computation-in-active-inference" class="headerlink" title="On efficient computation in active inference"></a>On efficient computation in active inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00504">http://arxiv.org/abs/2307.00504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aswinpaul/dpefe_2023">https://github.com/aswinpaul/dpefe_2023</a></li>
<li>paper_authors: Aswin Paul, Noor Sajid, Lancelot Da Costa, Adeel Razi</li>
<li>for: 提高active inference的计算效率和定义目标分布的可能性</li>
<li>methods: 提出了两种解决方案，包括一种新的规划算法和一种基于Z-学习的目标分布设定方法</li>
<li>results: 通过实验在标准的网格世界任务中证明了这些方法的有效性和可行性，创造了新的应用机会<details>
<summary>Abstract</summary>
Despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behaviour in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behaviour even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:active inference在复杂环境中模拟智能行为存在困难，主要是计算成本高和设定合适的目标分布困难。本文介绍两种解决方案，它们在合作下解决这些限制。首先，我们提出了一种新的规划算法，可以在固定的时间途径上降低计算成本。其次，我们受控制理论文献中的Z学习启发，将定义目标分布的过程简化。我们的第一种方法利用动态计划算法，知道计算效率高，来最小化规划中的成本函数。根据bellman优化原理，我们递归评估动作的预期自由能量，从reverse temporal order进行评估。这些改进可以降低计算成本的许多次数，并允许精准的模型学习和规划，即使在不确定条件下。我们的方法简化了规划过程，并在指定Final Goal State时显示了有意义的行为。我们的提案使得从目标分布定义 become easier，而不是在更复杂的时间 informed target distribution中定义。我们的方法在标准grid-world任务中进行了测试和证明，这些进步创造了新的应用机会。
</details></li>
</ul>
<hr>
<h2 id="Don’t-Memorize-Mimic-The-Past-Federated-Class-Incremental-Learning-Without-Episodic-Memory"><a href="#Don’t-Memorize-Mimic-The-Past-Federated-Class-Incremental-Learning-Without-Episodic-Memory" class="headerlink" title="Don’t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory"></a>Don’t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00497">http://arxiv.org/abs/2307.00497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotabi, Salman Avestimehr</li>
<li>for: 这种纸是用于解决深度学习模型在新数据上忘记过去学习的问题。</li>
<li>methods: 这篇论文使用了生成模型来Synthesize过去分布，从而使得客户端可以在本地避免卡斯特罗φ菲律敦效应。</li>
<li>results: 论文对CIFAR-100数据集进行了实验，与现有基eline相比，呈现出了显著的改善。<details>
<summary>Abstract</summary>
Deep learning models are prone to forgetting information learned in the past when trained on new data. This problem becomes even more pronounced in the context of federated learning (FL), where data is decentralized and subject to independent changes for each user. Continual Learning (CL) studies this so-called \textit{catastrophic forgetting} phenomenon primarily in centralized settings, where the learner has direct access to the complete training dataset. However, applying CL techniques to FL is not straightforward due to privacy concerns and resource limitations. This paper presents a framework for federated class incremental learning that utilizes a generative model to synthesize samples from past distributions instead of storing part of past data. Then, clients can leverage the generative model to mitigate catastrophic forgetting locally. The generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Therefore, it reduces the risk of data leakage as opposed to training it on the client's private data. We demonstrate significant improvements for the CIFAR-100 dataset compared to existing baselines.
</details>
<details>
<summary>摘要</summary>
This paper proposes a framework for federated class incremental learning that utilizes a generative model to synthesize samples from past distributions instead of storing part of past data. Clients can leverage the generative model to mitigate catastrophic forgetting locally. The generative model is trained on the server using data-free methods at the end of each task without requesting data from clients, reducing the risk of data leakage compared to training it on the client's private data. We demonstrate significant improvements for the CIFAR-100 dataset compared to existing baselines.
</details></li>
</ul>
<hr>
<h2 id="STG4Traffic-A-Survey-and-Benchmark-of-Spatial-Temporal-Graph-Neural-Networks-for-Traffic-Prediction"><a href="#STG4Traffic-A-Survey-and-Benchmark-of-Spatial-Temporal-Graph-Neural-Networks-for-Traffic-Prediction" class="headerlink" title="STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural Networks for Traffic Prediction"></a>STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural Networks for Traffic Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00495">http://arxiv.org/abs/2307.00495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/trainingl/stg4traffic">https://github.com/trainingl/stg4traffic</a></li>
<li>paper_authors: Xunlian Luo, Chunjiang Zhu, Detian Zhang, Qing Li</li>
<li>for: 这篇论文的目的是为了提供一种系统的review of graph learning策略和通用的图 convolution算法，以及对最近提出的空间时间图网络模型的全面分析。</li>
<li>methods: 本论文使用了一种称为 STG4Traffic 的深度学习框架，使用 PyTorch 建立了一个标准化和扩展的 benchmark，并对两种交通数据集进行了评估。</li>
<li>results: 研究发现，STG4Traffic 可以在两种交通数据集上达到比较高的预测精度，并且可以根据不同的数据集和模型设置进行个性化定制。<details>
<summary>Abstract</summary>
Traffic prediction has been an active research topic in the domain of spatial-temporal data mining. Accurate real-time traffic prediction is essential to improve the safety, stability, and versatility of smart city systems, i.e., traffic control and optimal routing. The complex and highly dynamic spatial-temporal dependencies make effective predictions still face many challenges. Recent studies have shown that spatial-temporal graph neural networks exhibit great potential applied to traffic prediction, which combines sequential models with graph convolutional networks to jointly model temporal and spatial correlations. However, a survey study of graph learning, spatial-temporal graph models for traffic, as well as a fair comparison of baseline models are pending and unavoidable issues. In this paper, we first provide a systematic review of graph learning strategies and commonly used graph convolution algorithms. Then we conduct a comprehensive analysis of the strengths and weaknesses of recently proposed spatial-temporal graph network models. Furthermore, we build a study called STG4Traffic using the deep learning framework PyTorch to establish a standardized and scalable benchmark on two types of traffic datasets. We can evaluate their performance by personalizing the model settings with uniform metrics. Finally, we point out some problems in the current study and discuss future directions. Source codes are available at https://github.com/trainingl/STG4Traffic.
</details>
<details>
<summary>摘要</summary>
历史预测已经是智能城市系统中的活跃研究主题之一，准确的实时历史预测能够提高智能城市系统的安全、稳定性和多样性。然而，由于历史的复杂和高度动态关系，实现有效预测仍然面临着许多挑战。最近的研究表明，使用历史空间图神经网络可以有效地应用于历史预测，这种方法可以同时模型历史序列和空间相关性。然而，一项历史学习、空间历史图模型以及基准模型的比较仍然是一个潜在的问题。在这篇论文中，我们首先提供了一种系统性的历史学习策略和常用的历史 convolution 算法的评论。然后，我们进行了全面的审查最近提出的空间历史图网络模型的优劣点。此外，我们在 PyTorch 深度学习框架上建立了一个标准化和可扩展的 STG4Traffic 研究，并使用两种交通数据集来评估其性能。我们可以通过个性化模型设置来评估其表现，并且提出了一些问题和未来方向。源代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="Fourier-Mixed-Window-Attention-Accelerating-Informer-for-Long-Sequence-Time-Series-Forecasting"><a href="#Fourier-Mixed-Window-Attention-Accelerating-Informer-for-Long-Sequence-Time-Series-Forecasting" class="headerlink" title="Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting"></a>Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00493">http://arxiv.org/abs/2307.00493</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhatthanhtran/fwin2023">https://github.com/nhatthanhtran/fwin2023</a></li>
<li>paper_authors: Nhat Thanh Tran, Jack Xin</li>
<li>for: 快速地处理长序列时间预测中的Informer。</li>
<li>methods: 使用本地-全局窗口基于注意力方法加速Informer，而不需要查询稀缺性假设和经验上的近似准则。</li>
<li>results: FWin transformer可以提高Informer的总预测精度，同时提高推断速度，在uniivariate和multivariate dataset上实现40-50%的加速。此外，我们还证明了一个学习的FWin类注意力可以与Softmax全注意力相当或者超过基于Informer模型的全注意力层时间序列数据的键vector。<details>
<summary>Abstract</summary>
We study a fast local-global window-based attention method to accelerate Informer for long sequence time-series forecasting. While window attention is local and a considerable computational saving, it lacks the ability to capture global token information which is compensated by a subsequent Fourier transform block. Our method, named FWin, does not rely on query sparsity hypothesis and an empirical approximation underlying the ProbSparse attention of Informer. Through experiments on univariate and multivariate datasets, we show that FWin transformers improve the overall prediction accuracies of Informer while accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear regression model that a learned FWin type attention approaches or even outperforms softmax full attention based on key vectors extracted from an Informer model's full attention layer acting on time series data.
</details>
<details>
<summary>摘要</summary>
我们研究了一种快速的本地-全局窗口基于注意力方法，用于加速Informer进行长序时间序列预测。虽然窗口注意力是本地的，但lacks the ability to capture global token information，这被补偿了随后的傅立做块。我们的方法，名为FWin，不依赖于查询稀缺假设和Informer中的ProbSparse注意力的经验 aproximation。通过对单Variate和多Variate数据进行实验，我们显示了FWin transformers可以提高Informer的总预测精度，同时加速其推断速度，提高40到50%。我们还在非线性回归模型中表明，学习的FWin类型注意力可以与softmax全注意力相当或者超过，基于Informer模型中全注意力层中的键vector从时间序列数据中提取出来的。
</details></li>
</ul>
<hr>
<h2 id="PatternGPT-A-Pattern-Driven-Framework-for-Large-Language-Model-Text-Generation"><a href="#PatternGPT-A-Pattern-Driven-Framework-for-Large-Language-Model-Text-Generation" class="headerlink" title="PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation"></a>PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00470">http://arxiv.org/abs/2307.00470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Le Xiao, Xin Shan</li>
<li>For: This paper aims to improve the text generation capability of large language models (LLMs) by proposing a pattern-driven text generation framework called PatternGPT.* Methods: The framework uses the extraction capability of LLMs to generate rich and diversified structured and formalized patterns, which are then used to guide the generation of models. The framework also utilizes federated learning to share patterns among multiple agents and optimize the search for high-quality patterns.* Results: The proposed framework has several advantages, including generating diversified patterns, protecting data privacy, combining external knowledge, and improving the quality of generation. The framework provides an effective method to optimize the text generation capability of LLMs and apply them to the field of intelligent dialogue and content generation.Here is the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文目标是提高大语言模型（LLM）的文本生成能力，提出了一种基于模式的文本生成框架 PatternGPT。</li>
<li>methods: 该框架利用大语言模型的提取能力生成丰富和多样化的结构化和正式化模式，并使用联合学习来共享模式，优化搜索高质量模式。</li>
<li>results: 提议的框架具有多样性、数据隐私保护、外部知识组合和生成质量提高等优点，为大语言模型的文本生成能力优化提供有效的方法，应用于智能对话和内容生成等领域。<details>
<summary>Abstract</summary>
Large language models(LLMS)have shown excellent text generation capabilities, capable of generating fluent human-like responses for many downstream tasks. However, applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To cope with the above challenges, this paper proposes PatternGPT, a pattern-driven text generation framework for Large Language Models. Firstly, the framework utilizes the extraction capability of Large Language Models to generate rich and diversified structured and formalized patterns, which facilitates the introduction of external knowledge to do the computation, and then draws on the idea of federated learning to use multiple agents to achieve the sharing in order to obtain more diversified patterns, and finally uses judgment criteria and optimization algorithm to search for high-quality patterns to guide the generation of models. Finally, external knowledge such as judgment criteria and optimization algorithms are used to search for high-quality patterns, and the searched patterns are used to guide model generation. This framework has the advantages of generating diversified patterns, protecting data privacy, combining external knowledge, and improving the quality of generation, which provides an effective method to optimize the text generation capability of large language models, and make it better applied to the field of intelligent dialogue and content generation.
</details>
<details>
<summary>摘要</summary>
大型语言模型(LLM)已经显示出扎实的文本生成能力，能够生成流畅、人工智能的回应 для许多下游任务。但是，将大型语言模型应用到实际世界中的重要任务仍然具有挑战，主要是因为它们容易受到幻视和无法直接使用外部知识。为了解决以上问题，这篇论文提出了 PatternGPT，一个基于模式的文本生成框架 для Large Language Models。首先，这个框架利用了 Large Language Models 的提取能力来生成丰富和多样化的结构化和正式化模式，以便引入外部知识进行计算，然后参考 federated learning 的想法，使用多个代理人共享，以获得更多的多样化模式，最后使用判断标准和优化算法来搜寻高品质的模式，以导引模型的生成。最后，这个框架使用了外部知识，例如判断标准和优化算法，搜寻高品质的模式，并将搜寻到的模式用来导引模型的生成。这个框架有丰富的模式生成、保护数据隐私、结合外部知识、提高生成质量等优点，提供了一个有效的方法来优化大型语言模型的文本生成能力，并将其应用到智能对话和内容生成领域。
</details></li>
</ul>
<hr>
<h2 id="FedDefender-Backdoor-Attack-Defense-in-Federated-Learning"><a href="#FedDefender-Backdoor-Attack-Defense-in-Federated-Learning" class="headerlink" title="FedDefender: Backdoor Attack Defense in Federated Learning"></a>FedDefender: Backdoor Attack Defense in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08672">http://arxiv.org/abs/2307.08672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/warisgill/FedDefender">https://github.com/warisgill/FedDefender</a></li>
<li>paper_authors: Waris Gill, Ali Anwar, Muhammad Ali Gulzar</li>
<li>for: 防止targeted poisoning攻击在 Federated Learning (FL) 中，保护客户端模型免受攻击并维持模型的优化。</li>
<li>methods: 利用 differential testing 方法察看客户端模型的neuron activations的差异，以识别可能有恶意的客户端。</li>
<li>results: 在 MNIST 和 FashionMNIST  datasets上，FedDefender 有效地防止了targeted poisoning攻击，降低了攻击成功率（ASR）至 10%，而不会影响全球模型的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\% without deteriorating the global model performance.
</details>
<details>
<summary>摘要</summary>
federated learning（FL）是一种隐私保护的分布式机器学习技术，允许个体客户端（例如用户参与者、边缘设备或组织）在安全环境中使用本地数据进行模型训练，然后将训练好的模型分享给一个综合器，共同构建全球模型。在这项工作中，我们提出了FedDefender，一种防御机制，用于防止针对性攻击FL。我们的提议方法通过对客户端模型的神经元活动进行指纹测试，来确定潜在恶意客户端是否含有后门。我们使用MNIST和FashionMNIST数据集，并在20和30个客户端上进行了测试。我们的结果表明，FedDefender有效地 Mitigate Such attacks，降低攻击成功率（ASR）至10%，无需降低全球模型性能。
</details></li>
</ul>
<hr>
<h2 id="Human-to-Human-Interaction-Detection"><a href="#Human-to-Human-Interaction-Detection" class="headerlink" title="Human-to-Human Interaction Detection"></a>Human-to-Human Interaction Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00464">http://arxiv.org/abs/2307.00464</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kakaobrain/hotr">https://github.com/kakaobrain/hotr</a></li>
<li>paper_authors: Zhenhua Wang, Kaining Ying, Jiajun Meng, Jifeng Ning</li>
<li>for: 这篇论文旨在探讨人类之间的互动行为，如排队、握手、斗争和追逐，以便帮助公共安全监控领域中的视频监控。</li>
<li>methods: 这篇论文引入了一种新的人类互动检测任务（HID），该任务旨在在一个模型中检测人类的动作，识别每个人的动作，并将人类分组 according to their 互动关系。</li>
<li>results: 研究人员通过使用AVA dataset创建了一个新的HID benchмарke（AVA-I），并提出了一种基于Transformer模型的SaMFormer方法来解决HID任务。该方法在AVA-I上进行了广泛的实验，并被证明高效性。<details>
<summary>Abstract</summary>
A comprehensive understanding of interested human-to-human interactions in video streams, such as queuing, handshaking, fighting and chasing, is of immense importance to the surveillance of public security in regions like campuses, squares and parks. Different from conventional human interaction recognition, which uses choreographed videos as inputs, neglects concurrent interactive groups, and performs detection and recognition in separate stages, we introduce a new task named human-to-human interaction detection (HID). HID devotes to detecting subjects, recognizing person-wise actions, and grouping people according to their interactive relations, in one model. First, based on the popular AVA dataset created for action detection, we establish a new HID benchmark, termed AVA-Interaction (AVA-I), by adding annotations on interactive relations in a frame-by-frame manner. AVA-I consists of 85,254 frames and 86,338 interactive groups, and each image includes up to 4 concurrent interactive groups. Second, we present a novel baseline approach SaMFormer for HID, containing a visual feature extractor, a split stage which leverages a Transformer-based model to decode action instances and interactive groups, and a merging stage which reconstructs the relationship between instances and groups. All SaMFormer components are jointly trained in an end-to-end manner. Extensive experiments on AVA-I validate the superiority of SaMFormer over representative methods. The dataset and code will be made public to encourage more follow-up studies.
</details>
<details>
<summary>摘要</summary>
“一个全面的理解人际互动在视频流中，如排队、握手、战斗和追逐，对公共安全监控区域如校园、广场和公园来说是非常重要。不同于传统的人际互动识别，使用仪制化视频为输入，忽略同时互动的小组，并在不同阶段进行检测和识别，我们引入了一个新任务名为人际互动检测（HID）。HID的目的是在一个模型中检测主题，识别每个人的动作，并根据人们之间的互动关系分组人。首先，我们根据已知的AVA数据集，创建了一个新的HIDbenchmark，称为AVA-Interaction（AVA-I），通过在每个帧上添加互动关系的标注。AVA-I包含85,254帧和86,338个互动小组，每帧最多可以有4个同时互动的小组。其次，我们提出了一个基本的SaMFormer方法来进行HID，包括一个视觉特征提取器、一个分阶段使用Transformer型模型将动作实例和互动小组解析，以及一个合并阶段将实例和小组之间的关系重建。所有SaMFormer комponents都是以终端式方式进行集成训练。广泛的实验验证了SaMFormer在AVA-I上的超越性。这个数据集和代码将会公开，以便更多的后续研究。”
</details></li>
</ul>
<hr>
<h2 id="Conformer-LLMs-–-Convolution-Augmented-Large-Language-Models"><a href="#Conformer-LLMs-–-Convolution-Augmented-Large-Language-Models" class="headerlink" title="Conformer LLMs – Convolution Augmented Large Language Models"></a>Conformer LLMs – Convolution Augmented Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00461">http://arxiv.org/abs/2307.00461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Verma</li>
<li>for: 这个论文是为了开发一种基于卷积层和转换器的大语言模型（LLM）的 causal 训练方法。</li>
<li>methods: 这个论文使用了非 causal 卷积层和转换器，并将其适应到 causal 设置中进行训练 LLM。</li>
<li>results: 该论文实现了在听说任务中获得显著的性能提升，表明该方法可以在大规模语言模型中具有良好的性能。<details>
<summary>Abstract</summary>
This work builds together two popular blocks of neural architecture, namely convolutional layers and Transformers, for large language models (LLMs). Non-causal conformers are used ubiquitously in automatic speech recognition. This work aims to adapt these architectures in a causal setup for training LLMs. Transformers decoders effectively capture long-range dependencies over several modalities and form a core backbone of modern advancements in machine learning. Convolutional architectures have been popular in extracting features in domains such as raw 1-D signals, speech, and images, to name a few. In this paper, by combining local and global dependencies over latent representations using causal convolutional filters and Transformer, we achieve significant gains in performance. This work showcases a robust speech architecture that can be integrated and adapted in a causal setup beyond speech applications for large-scale language modeling.
</details>
<details>
<summary>摘要</summary>
这个工作将两种流行的神经网络块结合在一起，即卷积层和Transformers，用于大型语言模型（LLM）的训练。非 causal 的变体在自动语音识别中广泛使用。本工作想要将这些架构在 causal 设置中适应训练 LLM。Transformers 解码器可以效果地捕捉多modalities 中的长距离依赖关系，并成为现代机器学习的核心进步。卷积 arquitectures 在处理 Raw 1-D 信号、语音和图像等领域中受欢迎，以EXTRACT特征。在这篇论文中，我们通过将本地和全球依赖关系使用 causal 卷积Filter和Transformer 来实现显著提高性能。这个robust的语音架构可以在 causal 设置中被集成和适应 beyond speech 应用程序。
</details></li>
</ul>
<hr>
<h2 id="GenRec-Large-Language-Model-for-Generative-Recommendation"><a href="#GenRec-Large-Language-Model-for-Generative-Recommendation" class="headerlink" title="GenRec: Large Language Model for Generative Recommendation"></a>GenRec: Large Language Model for Generative Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00457">http://arxiv.org/abs/2307.00457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rutgerswiselab/genrec">https://github.com/rutgerswiselab/genrec</a></li>
<li>paper_authors: Jianchao Ji, Zelong Li, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Juntao Tan, Yongfeng Zhang</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）在生成推荐方式下的潜在应用。</li>
<li>methods: 该论文提出了一种基于大语言模型（LLM）的生成推荐方法（GenRec），利用LLM的理解能力来解释上下文、学习用户偏好和生成相关推荐。</li>
<li>results:  experiments 表明，GenRec 在大量数据集上具有显著优异表现，与传统的分类推荐方法相比，GenRec 可以更好地理解用户偏好和适应变化的用户需求。<details>
<summary>Abstract</summary>
In recent years, large language models (LLM) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommendation systems using large language models (LLMs) based on text data. In this paper, we present a novel LLM for generative recommendation (GenRec) that utilized the expressive power of LLM to directly generate the target item to recommend, rather than calculating ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendation. Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first we formulate specialized prompts to enhance the ability of LLM to comprehend recommendation tasks. Subsequently, we use these prompts to fine-tune the LLaMA backbone LLM on a dataset of user-item interactions, represented by textual data, to capture user preferences and item characteristics. Our research underscores the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems and offers a foundational framework for future explorations in this field. We conduct extensive experiments on benchmark datasets, and the experiments shows that our GenRec has significant better results on large dataset.
</details>
<details>
<summary>摘要</summary>
In this paper, we present a novel LLM for generative recommendation (GenRec) that leverages the expressive power of LLMs to directly generate the target item to recommend, rather than calculating ranking scores for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendations.Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first formulate specialized prompts to enhance the ability of LLMs to comprehend recommendation tasks. We then use these prompts to fine-tune the LLaMA backbone LLM on a dataset of user-item interactions, represented by textual data, to capture user preferences and item characteristics.Our research highlights the potential of LLM-based generative recommendation to revolutionize the field of recommendation systems and provides a foundational framework for future explorations in this area. We conduct extensive experiments on benchmark datasets, and the results show that our GenRec achieves significantly better results on large datasets.
</details></li>
</ul>
<hr>
<h2 id="3D-IDS-Doubly-Disentangled-Dynamic-Intrusion-Detection"><a href="#3D-IDS-Doubly-Disentangled-Dynamic-Intrusion-Detection" class="headerlink" title="3D-IDS: Doubly Disentangled Dynamic Intrusion Detection"></a>3D-IDS: Doubly Disentangled Dynamic Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11079">http://arxiv.org/abs/2307.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyang Qiu, Yingsheng Geng, Junrui Lu, Kaida Chen, Shitong Zhu, Ya Su, Guoshun Nan, Can Zhang, Junsong Fu, Qimei Cui, Xiaofeng Tao</li>
<li>For:	+ 3D-IDS is proposed to tackle the inconsistent performance of existing NIDS methods in detecting various unknown and known attacks, especially in encrypted traffic.	+ The proposed method aims to disentangle traffic features and highlight attack-specific features for effective identification of attacks.	+ The method is designed to improve the explainability of NIDS.* Methods:	+ Two-step feature disentanglements are used to differentiate complex features of various attacks.	+ A non-parameterized optimization based on mutual information is used to automatically disentangle traffic features.	+ A memory model is used to generate representations of the disentangled features.	+ A novel graph diffusion method is used to dynamically fuse the network topology for spatial-temporal aggregation in evolving data streams.* Results:	+ The proposed 3D-IDS method outperforms existing NIDS methods in detecting various attacks, including unknown threats and known ones that are not easily detected.	+ Experiments show the superiority of the proposed method.	+ The two-step feature disentanglements benefit the explainability of NIDS.<details>
<summary>Abstract</summary>
Network-based intrusion detection system (NIDS) monitors network traffic for malicious activities, forming the frontline defense against increasing attacks over information infrastructures. Although promising, our quantitative analysis shows that existing methods perform inconsistently in declaring various unknown attacks (e.g., 9% and 35% F1 respectively for two distinct unknown threats for an SVM-based method) or detecting diverse known attacks (e.g., 31% F1 for the Backdoor and 93% F1 for DDoS by a GCN-based state-of-the-art method), and reveals that the underlying cause is entangled distributions of flow features. This motivates us to propose 3D-IDS, a novel method that aims to tackle the above issues through two-step feature disentanglements and a dynamic graph diffusion scheme. Specifically, we first disentangle traffic features by a non-parameterized optimization based on mutual information, automatically differentiating tens and hundreds of complex features of various attacks. Such differentiated features will be fed into a memory model to generate representations, which are further disentangled to highlight the attack-specific features. Finally, we use a novel graph diffusion method that dynamically fuses the network topology for spatial-temporal aggregation in evolving data streams. By doing so, we can effectively identify various attacks in encrypted traffics, including unknown threats and known ones that are not easily detected. Experiments show the superiority of our 3D-IDS. We also demonstrate that our two-step feature disentanglements benefit the explainability of NIDS.
</details>
<details>
<summary>摘要</summary>
First, we disentangle traffic features using a non-parameterized optimization based on mutual information, which automatically differentiates tens and hundreds of complex features of various attacks. These differentiated features are then fed into a memory model to generate representations, which are further disentangled to highlight attack-specific features. Finally, we use a novel graph diffusion method that dynamically fuses the network topology for spatial-temporal aggregation in evolving data streams. This allows us to effectively identify various attacks in encrypted traffics, including unknown threats and known ones that are not easily detected.Experiments show the superiority of our 3D-IDS. We also demonstrate that our two-step feature disentanglements benefit the explainability of NIDS.
</details></li>
</ul>
<hr>
<h2 id="WaveMixSR-A-Resource-efficient-Neural-Network-for-Image-Super-resolution"><a href="#WaveMixSR-A-Resource-efficient-Neural-Network-for-Image-Super-resolution" class="headerlink" title="WaveMixSR: A Resource-efficient Neural Network for Image Super-resolution"></a>WaveMixSR: A Resource-efficient Neural Network for Image Super-resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00430">http://arxiv.org/abs/2307.00430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pranavphoenix/WaveMixSR">https://github.com/pranavphoenix/WaveMixSR</a></li>
<li>paper_authors: Pranav Jeevan, Akella Srinidhi, Pasunuri Prathiba, Amit Sethi</li>
<li>For: The paper is written for research on image super-resolution, specifically proposing a new neural network called WaveMixSR that uses a 2D-discrete wavelet transform for spatial token-mixing.* Methods: The paper uses the WaveMix architecture, which combines the inductive bias of convolutions with the lossless token-mixing property of wavelet transform to achieve higher performance in image super-resolution. The network does not unroll the image as a sequence of pixels&#x2F;patches like transformer-based models do.* Results: The paper compares the performance of WaveMixSR with other state-of-the-art methods for image super-resolution and shows that it achieves competitive performance in all datasets and reaches state-of-the-art performance in the BSD100 dataset on multiple super-resolution tasks. The model achieves this performance using less training data and computational resources while maintaining high parameter efficiency compared to current state-of-the-art models.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是关于图像超解析研究，具体是提出一种新的神经网络 called WaveMixSR，使用2D离散波лет变换来实现空间токен混合。* Methods: 论文使用WaveMix架构，结合卷积的假设导向和波лет变换的无损token混合性来实现图像超解析 task。不同于转换器模型，WaveMixSR不会将图像作为像素&#x2F;补丁序列推进。* Results: 论文对WaveMixSR与其他当前顶尖方法进行比较，并显示它在所有数据集中具有竞争性的性能，并在BSD100数据集中实现多个超解析任务的state-of-the-art性。WaveMixSR使用 fewer training data和计算资源，同时保持高参数效率与当前顶尖模型相比。<details>
<summary>Abstract</summary>
Image super-resolution research recently been dominated by transformer models which need higher computational resources than CNNs due to the quadratic complexity of self-attention. We propose a new neural network -- WaveMixSR -- for image super-resolution based on WaveMix architecture which uses a 2D-discrete wavelet transform for spatial token-mixing. Unlike transformer-based models, WaveMixSR does not unroll the image as a sequence of pixels/patches. It uses the inductive bias of convolutions along with the lossless token-mixing property of wavelet transform to achieve higher performance while requiring fewer resources and training data. We compare the performance of our network with other state-of-the-art methods for image super-resolution. Our experiments show that WaveMixSR achieves competitive performance in all datasets and reaches state-of-the-art performance in the BSD100 dataset on multiple super-resolution tasks. Our model is able to achieve this performance using less training data and computational resources while maintaining high parameter efficiency compared to current state-of-the-art models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Sparsity-aware-generalization-theory-for-deep-neural-networks"><a href="#Sparsity-aware-generalization-theory-for-deep-neural-networks" class="headerlink" title="Sparsity-aware generalization theory for deep neural networks"></a>Sparsity-aware generalization theory for deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00426">http://arxiv.org/abs/2307.00426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ramchandran Muthukumar, Jeremias Sulam</li>
<li>for: 这 paper 的目的是解释深度人工神经网络的泛化能力。</li>
<li>methods: 这 paper 使用了一种新的方法来分析深度循环ReLU网络的泛化性，利用隐藏层活动的稀烈程度来降低效果模型的大小。</li>
<li>results: 这 paper 表明了泛化性和稀烈程度之间的基本负面关系，而且这些结果不假设模型的稀烈程度有很大的限制。数值计算也验证了这些结果，并在特定情况下提供了非虚假的下界。<details>
<summary>Abstract</summary>
Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors in specific settings, even in over-parametrized models.
</details>
<details>
<summary>摘要</summary>
深度人工神经网络达到了意外的泛化能力，这种能力仍未得到充分理解。在这篇论文中，我们提出了一种新的分析泛化方法，利用隐藏层活动的稀疏度来提高分析效果。我们开发了一个考虑这种减少效果模型大小的框架，从而显示了泛化和稀疏度之间的基本负相关性。这些结果不假设模型达到了具体的稀疏度水平，并且超过了最近的 нор-based方法。我们通过数值示例，证明了这些结果的有效性，即在特定设定下，与数据依赖的假设结合使用时可以获得非虚无效的下限。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Counterspeech-for-Online-Harm-Mitigation"><a href="#Understanding-Counterspeech-for-Online-Harm-Mitigation" class="headerlink" title="Understanding Counterspeech for Online Harm Mitigation"></a>Understanding Counterspeech for Online Harm Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04761">http://arxiv.org/abs/2307.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi-Ling Chung, Gavin Abercrombie, Florence Enock, Jonathan Bright, Verena Rieser</li>
<li>for: 本研究旨在探讨对仇恨言论的抗议，以帮助制定有效的仇恨mitigation策略。</li>
<li>methods: 本研究使用社会科学和计算机科学的研究方法，对仇恨言论的抗议进行系统性的审查和比较，以找到最有效的抗议方法和最佳实施条件。</li>
<li>results: 研究发现，有效的抗议方法包括直接抗议、呈现反对意见、提供反对证据等，而且最佳实施条件包括在社交媒体平台上进行抗议、在抗议中使用正面语言、以及在抗议中强调团结和支持。<details>
<summary>Abstract</summary>
Counterspeech offers direct rebuttals to hateful speech by challenging perpetrators of hate and showing support to targets of abuse. It provides a promising alternative to more contentious measures, such as content moderation and deplatforming, by contributing a greater amount of positive online speech rather than attempting to mitigate harmful content through removal. Advances in the development of large language models mean that the process of producing counterspeech could be made more efficient by automating its generation, which would enable large-scale online campaigns. However, we currently lack a systematic understanding of several important factors relating to the efficacy of counterspeech for hate mitigation, such as which types of counterspeech are most effective, what are the optimal conditions for implementation, and which specific effects of hate it can best ameliorate. This paper aims to fill this gap by systematically reviewing counterspeech research in the social sciences and comparing methodologies and findings with computer science efforts in automatic counterspeech generation. By taking this multi-disciplinary view, we identify promising future directions in both fields.
</details>
<details>
<summary>摘要</summary>
对话抗言可以直接反驳仇恨言语，挑战仇恨行为者并表达对受害者的支持。它提供了一种有前途的替代方案，而不是通过内容审核和屏蔽来缓解伤害性内容。随着大语言模型的发展，生成对话抗言的过程可以通过自动化来加速，这将使得大规模的在线运动变得可能。然而，我们目前缺乏对对话抗言的效果进行系统性理解，例如最有效的类型、实施条件以及哪些特定情况下可以最好地缓解仇恨的效果。这篇论文希望通过对社科研究和计算机科学的自动对话抗言生成技术进行系统性比较，从而填补这些知识空白。通过这种多学科视角，我们可以找到未来的发展方向。
</details></li>
</ul>
<hr>
<h2 id="WavePaint-Resource-efficient-Token-mixer-for-Self-supervised-Inpainting"><a href="#WavePaint-Resource-efficient-Token-mixer-for-Self-supervised-Inpainting" class="headerlink" title="WavePaint: Resource-efficient Token-mixer for Self-supervised Inpainting"></a>WavePaint: Resource-efficient Token-mixer for Self-supervised Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00407">http://arxiv.org/abs/2307.00407</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pranavphoenix/WavePaint">https://github.com/pranavphoenix/WavePaint</a></li>
<li>paper_authors: Pranav Jeevan, Dharshan Sampath Kumar, Amit Sethi</li>
<li>for: 图像填充（image inpainting），用于重建 occluded 或 degraded 图像区域，以及作为自我监督前置任务。</li>
<li>methods: 使用 computationally-efficient WaveMix-based fully convolutional architecture – WavePaint，利用 2D-discrete wavelet transform (DWT)  для spatial 和 multi-resolution token-mixing 以及 convolutional layers。</li>
<li>results: 比现有 state-of-the-art 模型在 reconstruction 质量上表现出色，同时具有参数数量少于半、训练和评估时间较短的优势。对 CelebA-HQ 数据集进行了比较，无需使用对抗性训练的潜在探测器，而且还超过了当前 GAN-based 架构。<details>
<summary>Abstract</summary>
Image inpainting, which refers to the synthesis of missing regions in an image, can help restore occluded or degraded areas and also serve as a precursor task for self-supervision. The current state-of-the-art models for image inpainting are computationally heavy as they are based on transformer or CNN backbones that are trained in adversarial or diffusion settings. This paper diverges from vision transformers by using a computationally-efficient WaveMix-based fully convolutional architecture -- WavePaint. It uses a 2D-discrete wavelet transform (DWT) for spatial and multi-resolution token-mixing along with convolutional layers. The proposed model outperforms the current state-of-the-art models for image inpainting on reconstruction quality while also using less than half the parameter count and considerably lower training and evaluation times. Our model even outperforms current GAN-based architectures in CelebA-HQ dataset without using an adversarially trainable discriminator. Our work suggests that neural architectures that are modeled after natural image priors require fewer parameters and computations to achieve generalization comparable to transformers.
</details>
<details>
<summary>摘要</summary>
图像填充（image inpainting）是指将图像中缺失的区域重新生成，以便修复受遮挡或退化的区域。这项技术可以作为自我超级视觉任务的前置任务，以及图像修复和改善的方法。当前的状态 искусственный智能模型（state-of-the-art models） для图像填充都是基于 transformer 或 CNN 底层的，这些模型在对抗或扩散设置下训练。本文与视觉 transformer 不同，使用 computationally-efficient WaveMix-based fully convolutional architecture -- WavePaint。它使用 2D-discrete wavelet transform (DWT) 进行空间和多谱分辨率的混合，并使用卷积层。提议的模型在重建质量方面超过当前状态 искусственный智能模型，而且使用的参数数量少于half，并且训练和评估时间较短。我们的模型甚至在 CelebA-HQ 数据集上超过当前基于 GAN 架构的模型，而不需要 adversarially trainable 的识别器。我们的工作表明，基于自然图像假设的神经网络模型可以通过减少参数和计算来实现与 transformers 相同的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="ProbVLM-Probabilistic-Adapter-for-Frozen-Vison-Language-Models"><a href="#ProbVLM-Probabilistic-Adapter-for-Frozen-Vison-Language-Models" class="headerlink" title="ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models"></a>ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00398">http://arxiv.org/abs/2307.00398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ProbVLM">https://github.com/ExplainableML/ProbVLM</a></li>
<li>paper_authors: Uddeshya Upadhyay, Shyamgopal Karthik, Massimiliano Mancini, Zeynep Akata</li>
<li>for: 这paper是为了解决大规模视语言模型（VLMs）中的固定映射问题，使得模型能够更好地捕捉图像和文本之间的抽象关系。</li>
<li>methods: 这paper使用了一种名为ProbVLM的概率适配器，通过在后期manner中对已经预训练的VLMs进行多模态协调并且不需要大量的数据或计算来估计图像和文本的嵌入空间的概率分布。</li>
<li>results: 在四个复杂的dataset上（COCO、Flickr、CUB和Oxford-flowers），这paper测试了两个VLMs（CLIP和BLIP）的嵌入空间的不确定性，并证明了ProbVLM在检索任务中的评估和选择性能比其他方法更高。此外，paper还提出了在实际应用中的活动学习和模型选择任务中的 embeddinguncertainty 的使用，并证明了它们的有用性。最后，paper还介绍了一种使用大规模预训练的潜在扩散模型来可见化嵌入分布的新技术。<details>
<summary>Abstract</summary>
Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose active learning and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly, we present a novel technique for visualizing the embedding distributions using a large-scale pre-trained latent diffusion model.
</details>
<details>
<summary>摘要</summary>
大规模视力语言模型（VLM）如CLIP成功地找到图像和文本之间的对应关系。通过标准的推测映射过程，一个图像或文本样本将映射到单个向量空间中。这会引起问题：由于多个样本（图像或文本）可以抽象出physical world中的同一个概念，则推测的 embedding 空间中的固定 embedding 不会反映 embedding 空间的内在含义。我们提出了ProbVLM，一种可信度抑制器，通过模式/内部模式的对齐来对预训练VLM的embedding进行随机化，而无需大规模数据集或计算。在四个复杂的数据集上（COCO、Flickr、CUB和Oxford-flowers），我们估算了预训练VLM的多模态 embedding 不确定性，衡量预测任务中的评估和折衔，并显示了ProbVLM的超越性。此外，我们还提出了基于 VLM 的活动学习和模型选择两个现实世界下游任务，并证明了估算不确定性对这两个任务具有帮助作用。最后，我们介绍了一种基于大规模预训练潜在扩散模型的新技术来视觉化 embedding 分布。
</details></li>
</ul>
<hr>
<h2 id="CasTGAN-Cascaded-Generative-Adversarial-Network-for-Realistic-Tabular-Data-Synthesis"><a href="#CasTGAN-Cascaded-Generative-Adversarial-Network-for-Realistic-Tabular-Data-Synthesis" class="headerlink" title="CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis"></a>CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00384">http://arxiv.org/abs/2307.00384</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abedshantti/castgan">https://github.com/abedshantti/castgan</a></li>
<li>paper_authors: Abdallah Alshantti, Damiano Varagnolo, Adil Rasheed, Aria Rahmati, Frank Westad</li>
<li>for:  This paper aims to generate realistic tabular data with a specific focus on validity, addressing the limitations of traditional generative models.</li>
<li>methods: The proposed method, CasTGAN, uses a cascaded tabular GAN architecture, where a dedicated generator samples each feature, resulting in more representative synthetic output.</li>
<li>results: The experimental results show that CasTGAN well captures the constraints and correlations between features of real data, especially for high-dimensional datasets. Additionally, the model demonstrates robustness against white-box privacy attacks with perturbations applied to the auxiliary learners.<details>
<summary>Abstract</summary>
Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilized for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model well captures the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/cs.AI_2023_07_02/" data-id="cloimip3h0001s488688oazhh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/cs.CL_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T11:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/cs.CL_2023_07_02/">cs.CL - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SSP-Self-Supervised-Post-training-for-Conversational-Search"><a href="#SSP-Self-Supervised-Post-training-for-Conversational-Search" class="headerlink" title="SSP: Self-Supervised Post-training for Conversational Search"></a>SSP: Self-Supervised Post-training for Conversational Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00569">http://arxiv.org/abs/2307.00569</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/morecry/ssp">https://github.com/morecry/ssp</a></li>
<li>paper_authors: Quan Tu, Shen Gao, Xiaolong Wu, Zhao Cao, Ji-Rong Wen, Rui Yan</li>
<li>for: 提高对话结构和上下文 semantic 理解</li>
<li>methods: 提出三种自动学习任务来升级 conversational search 模型</li>
<li>results: 在 CAsT-19 和 CAsT-20 两个 benchmark 数据集上，对已有 conversational search 方法进行了改进，并取得了广泛的实验成果。<details>
<summary>Abstract</summary>
Conversational search has been regarded as the next-generation search paradigm. Constrained by data scarcity, most existing methods distill the well-trained ad-hoc retriever to the conversational retriever. However, these methods, which usually initialize parameters by query reformulation to discover contextualized dependency, have trouble in understanding the dialogue structure information and struggle with contextual semantic vanishing. In this paper, we propose \fullmodel (\model) which is a new post-training paradigm with three self-supervised tasks to efficiently initialize the conversational search model to enhance the dialogue structure and contextual semantic understanding. Furthermore, the \model can be plugged into most of the existing conversational models to boost their performance. To verify the effectiveness of our proposed method, we apply the conversational encoder post-trained by \model on the conversational search task using two benchmark datasets: CAsT-19 and CAsT-20. Extensive experiments that our \model can boost the performance of several existing conversational search methods. Our source code is available at \url{https://github.com/morecry/SSP}.
</details>
<details>
<summary>摘要</summary>
对话搜寻被视为未来搜寻模式。由于数据缺乏，大多现有方法将特定的对话搜寻器转换为对话搜寻器。然而，这些方法通常会将问题重新构成来发现对话结构信息，却对对话结构和上下文Semantic衰退过滤产生困难。在这篇论文中，我们提出了\fullmodel (\model)，一个新的后训练模式，具有三个自动训练任务，可以快速初始化对话搜寻模型，提高对话结构和上下文Semantic理解。此外，\model可以与大多数现有的对话模型整合，提高其表现。为了证明我们提出的方法的有效性，我们将对话核心过滤器训练后使用了\model进行对话搜寻任务，使用了两个benchmark数据集：CAsT-19和CAsT-20。广泛的实验结果表明，我们的\model可以提高许多现有的对话搜寻方法的表现。我们的原始代码可以在\url{https://github.com/morecry/SSP}获取。
</details></li>
</ul>
<hr>
<h2 id="TensorGPT-Efficient-Compression-of-the-Embedding-Layer-in-LLMs-based-on-the-Tensor-Train-Decomposition"><a href="#TensorGPT-Efficient-Compression-of-the-Embedding-Layer-in-LLMs-based-on-the-Tensor-Train-Decomposition" class="headerlink" title="TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition"></a>TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00526">http://arxiv.org/abs/2307.00526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxue Xu, Yao Lei Xu, Danilo P. Mandic</li>
<li>for: 这篇论文旨在解决大语言模型（LLM）中高维Token嵌入的问题，以提高复杂语言模式的模型化。</li>
<li>methods: 该论文提出了基于Tensor-Train Decomposition（TTD）的方法，将每个Token嵌入视为一个 Matrix Product State（MPS），可以高效地在分布式环境中计算。</li>
<li>results: 实验结果表明，通过该方法可以将嵌入层压缩 factor 达到 38.40 倍，并且当压缩因子为 3.31 倍时，even 超过原始 GPT-2 模型的性能。<details>
<summary>Abstract</summary>
High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, the associated high dimensionality also introduces considerable model parameters, and a prohibitively high model storage. To address this issue, this work proposes an approach based on the Tensor-Train Decomposition (TTD), where each token embedding is treated as a Matrix Product State (MPS) that can be efficiently computed in a distributed manner. The experimental results on GPT-2 demonstrate that, through our approach, the embedding layer can be compressed by a factor of up to 38.40 times, and when the compression factor is 3.31 times, even produced a better performance than the original GPT-2 model.
</details>
<details>
<summary>摘要</summary>
高维度的токен嵌入在大语言模型（LLM）中起到重要作用，因为它们可以捕捉细微语义信息和复杂语言模式的特征。然而，相关的高维度也导致了较大的模型参数和庞大的模型存储空间。为解决这个问题，本工作提出了基于tensor-train分解（TTD）的方法，其中每个tokен嵌入被视为一个矩阵乘积状态（MPS），可以高效地在分布式环境中计算。实验结果表明，通过我们的方法，嵌入层可以被压缩38.40倍，而当压缩因子为3.31倍时，甚至超越原始GPT-2模型的性能。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Enable-Few-Shot-Clustering"><a href="#Large-Language-Models-Enable-Few-Shot-Clustering" class="headerlink" title="Large Language Models Enable Few-Shot Clustering"></a>Large Language Models Enable Few-Shot Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00524">http://arxiv.org/abs/2307.00524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vijay Viswanathan, Kiril Gashteovski, Carolin Lawrence, Tongshuang Wu, Graham Neubig</li>
<li>for: 提高文本整合的粒度和准确性，使用大语言模型提供指导和约束，实现查询效率和几何培育的 semi-supervised 文本整合。</li>
<li>methods: 本文提出了三个阶段可以将大语言模型 incorporated 到整合过程中： перед整合（改进输入特征）、在整合（提供约束给整合算法）和 после整合（使用 LLM 后 corrections）。</li>
<li>results: 结果表明，在第一个和第二个阶段 incorporating LLMs 可以routinely提供显著改进，并且允许用户根据成本和准确性进行负担和让步，以生成满足需求的 clusters。<details>
<summary>Abstract</summary>
Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.
</details>
<details>
<summary>摘要</summary>
（traditional unsupervised clustering与 semi-supervised clustering的区别在于， semi-supervised clustering 允许用户提供有意义的数据结构，这帮助 clustering 算法与用户的意思相符。现有的 semi-supervised clustering 方法需要专家的重要反馈，以提高几何。在这篇文章中，我们询问 whether 大型语言模型可以增强专家的指导，以实现问题提交、少量 semi-supervised text clustering。我们发现 LLMs  surprisingly effective 的提高 clustering。我们探索了在 clustering 中应用 LLMs 的三个阶段： before clustering（改善输入特征）、during clustering（通过提供约束给 clustering 算法）和 after clustering（使用 LLMs 后修）。我们发现在第一个和第二个阶段中 incorporating LLMs 可以提供重要的改善，并且 LLMs 允许用户做成本和准确之间的调整，以生成适当的几何。我们发布了我们的代码和 LLM 提示，以便公众使用。）
</details></li>
</ul>
<hr>
<h2 id="Make-Text-Unlearnable-Exploiting-Effective-Patterns-to-Protect-Personal-Data"><a href="#Make-Text-Unlearnable-Exploiting-Effective-Patterns-to-Protect-Personal-Data" class="headerlink" title="Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal Data"></a>Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00456">http://arxiv.org/abs/2307.00456</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xinzhel/unlearnable_texts">https://github.com/xinzhel/unlearnable_texts</a></li>
<li>paper_authors: Xinzhe Li, Ming Liu, Shang Gao</li>
<li>for: 本研究旨在解决深度学习模型中使用未经授权公共数据所带来的伦理问题，并提出了一种新的解决方案。</li>
<li>methods: 我们基于 Huang et al. (2021) 的二级优化方法，通过梯度基于搜索技术生成不可学习的文本。然而，这种方法具有实际限制，例如需要批处理实例和模型架构知识，这些知识不是普通用户可以访问自己数据的限制。另外，即使使用语义保持约束，不可学习的噪声仍可能改变文本的语义。</li>
<li>results: 我们提取了生成不可学习文本中的简单模式，并证明这些模式可以使文本保持不可学习性，即使用户只有有限的数据和模型知识。此外，这些模式不是特定实例或数据集的，因此用户可以轻松地应用它们于文本分类和问答任务。我们还开源了生成不可学习文本的代码和评估不可学习噪声的代码，以便公共和未来研究中使用。<details>
<summary>Abstract</summary>
This paper addresses the ethical concerns arising from the use of unauthorized public data in deep learning models and proposes a novel solution. Specifically, building on the work of Huang et al. (2021), we extend their bi-level optimization approach to generate unlearnable text using a gradient-based search technique. However, although effective, this approach faces practical limitations, including the requirement of batches of instances and model architecture knowledge that is not readily accessible to ordinary users with limited access to their own data. Furthermore, even with semantic-preserving constraints, unlearnable noise can alter the text's semantics. To address these challenges, we extract simple patterns from unlearnable text produced by bi-level optimization and demonstrate that the data remains unlearnable for unknown models. Additionally, these patterns are not instance- or dataset-specific, allowing users to readily apply them to text classification and question-answering tasks, even if only a small proportion of users implement them on their public content. We also open-source codes to generate unlearnable text and assess unlearnable noise to benefit the public and future studies.
</details>
<details>
<summary>摘要</summary>
To address these challenges, we extract simple patterns from unlearnable text produced by bi-level optimization and demonstrate that the data remains unlearnable for unknown models. These patterns are not instance- or dataset-specific, allowing users to readily apply them to text classification and question-answering tasks, even if only a small proportion of users implement them on their public content. We also open-source our codes to generate unlearnable text and assess unlearnable noise to benefit the public and future studies.
</details></li>
</ul>
<hr>
<h2 id="Don’t-Stop-Self-Supervision-Accent-Adaptation-of-Speech-Representations-via-Residual-Adapters"><a href="#Don’t-Stop-Self-Supervision-Accent-Adaptation-of-Speech-Representations-via-Residual-Adapters" class="headerlink" title="Don’t Stop Self-Supervision: Accent Adaptation of Speech Representations via Residual Adapters"></a>Don’t Stop Self-Supervision: Accent Adaptation of Speech Representations via Residual Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00453">http://arxiv.org/abs/2307.00453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anshu Bhatia, Sanchit Sinha, Saket Dingliwal, Karthik Gopalakrishnan, Sravan Bodapati, Katrin Kirchhoff</li>
<li>for: 这个研究的目的是将自愿式学习的语音表现适应化为不同的口音和非本地语言人员的说话。</li>
<li>methods: 研究使用了一种名为“自愿式适应器”的方法，将语音表现适应化为不同的口音和非本地语言人员的说话。</li>
<li>results: 研究获得了强大的词音误差减少（WERR）值，对于4种口音都获得了良好的 результа。在所有4种口音中，使用自愿式适应器得到了22.7%的WERR减少，而使用整个Encoder进行适应得到了25.1%的WERR减少。<details>
<summary>Abstract</summary>
Speech representations learned in a self-supervised fashion from massive unlabeled speech corpora have been adapted successfully toward several downstream tasks. However, such representations may be skewed toward canonical data characteristics of such corpora and perform poorly on atypical, non-native accented speaker populations. With the state-of-the-art HuBERT model as a baseline, we propose and investigate self-supervised adaptation of speech representations to such populations in a parameter-efficient way via training accent-specific residual adapters. We experiment with 4 accents and choose automatic speech recognition (ASR) as the downstream task of interest. We obtain strong word error rate reductions (WERR) over HuBERT-large for all 4 accents, with a mean WERR of 22.7% with accent-specific adapters and a mean WERR of 25.1% if the entire encoder is accent-adapted. While our experiments utilize HuBERT and ASR as the downstream task, our proposed approach is both model and task-agnostic.
</details>
<details>
<summary>摘要</summary>
自然语言处理中的自我超vision学习方法可以自然地学习大量无标注语音 Corpora 中的语音特征。然而，这些表示可能受到大量数据的标准化影响，并且在非典型、非本地口音 speaker 人群中表现不佳。基于当前顶尖 HuBERT 模型的基线，我们提出了一种parameter-efficient的自我超vision adaptation方法，通过在 residual adapters 上进行听话特征的自适应。我们在4种口音上进行了实验，选择了自动化语音识别（ASR）作为下游任务。我们得到了对 HuBERT-large 的强大单词错误率减少（WERR），对所有4种口音都有很好的表现，平均WERR为22.7%，对整个编码器进行了全面适应时平均WERR为25.1%。虽然我们的实验使用了 HuBERT 和 ASR 作为下游任务，但我们的提出的方法是模型和任务无关的。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-Stream-Recurrence-Attention-Network-with-Global-Local-Awareness-for-Emotion-Recognition-in-Textual-Dialogue"><a href="#A-Dual-Stream-Recurrence-Attention-Network-with-Global-Local-Awareness-for-Emotion-Recognition-in-Textual-Dialogue" class="headerlink" title="A Dual-Stream Recurrence-Attention Network with Global-Local Awareness for Emotion Recognition in Textual Dialogue"></a>A Dual-Stream Recurrence-Attention Network with Global-Local Awareness for Emotion Recognition in Textual Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00449">http://arxiv.org/abs/2307.00449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiang Li, Xiaoping Wang, Zhigang Zeng</li>
<li>For: 这个论文的目的是提出一种简单的 dual-stream Recurrence-Attention Network (DualRAN)，用于实现 Emotion Recognition in Conversation (ERC) 任务。* Methods: 这个模型使用了 RNN 和 Multi-head ATtention network (MAT) 的组合，并提出了一种新的 dual-stream 结构，以模型对话的全局和局部上下文信息。* Results: 实验结果表明，提出的模型在四个常用的 benchmark 数据集上表现出色，超过了所有基eline。 并且，我们进行了一系列的ablation study，以证明每个组件的效果。<details>
<summary>Abstract</summary>
In real-world dialogue systems, the ability to understand the user's emotions and interact anthropomorphically is of great significance. Emotion Recognition in Conversation (ERC) is one of the key ways to accomplish this goal and has attracted growing attention. How to model the context in a conversation is a central aspect and a major challenge of ERC tasks. Most existing approaches are generally unable to capture both global and local contextual information efficiently, and their network structures are too complex to design. For this reason, in this work, we propose a straightforward Dual-stream Recurrence-Attention Network (DualRAN) based on Recurrent Neural Network (RNN) and Multi-head ATtention network (MAT). The proposed model eschews the complex network structure of current methods and focuses on combining recurrence-based methods with attention-based methods. DualRAN is a dual-stream structure mainly consisting of local- and global-aware modules, modeling a conversation from distinct perspectives. To achieve the local-aware module, we extend the structure of RNN, thus enhancing the expressive capability of the network. In addition, we develop two single-stream network variants for DualRAN, i.e., SingleRANv1 and SingleRANv2. We conduct extensive experiments on four widely used benchmark datasets, and the results reveal that the proposed model outshines all baselines. Ablation studies further demonstrate the effectiveness of each component.
</details>
<details>
<summary>摘要</summary>
在实际对话系统中，理解用户的情感和人工智能交互是非常重要的。情感识别在对话中（ERC）已经吸引了越来越多的关注，并且成为了解决这一问题的中心方向之一。在ERC任务中，模型对话上下文的捕捉是中心问题，也是一个主要挑战。现有的大多数方法都不能够有效地捕捉对话中的全局和局部上下文信息，其网络结构也很复杂，设计很难。因此，在这项工作中，我们提出了一种简单的双流回归注意网络（DualRAN），基于循环神经网络（RNN）和多头注意网络（MAT）。我们的模型弃用现有方法的复杂网络结构，而选择结合循环方法和注意方法来实现。DualRAN的主要结构是一种双流结构，主要由本地和全局意识模块组成，从不同的角度模型对话。为了提高网络表达能力，我们在RNN结构中进行了扩展。此外，我们还开发了两种单流网络变体，即SingleRANv1和SingleRANv2。我们在四个常用的 benchmark 数据集上进行了广泛的实验，结果显示，我们的模型胜过所有基准值。细化分析还证明了每个组件的有效性。
</details></li>
</ul>
<hr>
<h2 id="Low-Resource-Cross-Lingual-Adaptive-Training-for-Nigerian-Pidgin"><a href="#Low-Resource-Cross-Lingual-Adaptive-Training-for-Nigerian-Pidgin" class="headerlink" title="Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin"></a>Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00382">http://arxiv.org/abs/2307.00382</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/muhammed-saeed/clat">https://github.com/muhammed-saeed/clat</a></li>
<li>paper_authors: Pin-Jie Lin, Muhammed Saeed, Ernie Chang, Merel Scholman</li>
<li>for: 提高 Nigerian Pidgin（Naija）的口语处理系统的效果，采用大规模并行英文-pidgin corpus 收集和跨语言适应训练框架。</li>
<li>methods: 使用英语预训模型作为更强的先验，并在 task adaptive 和 continual 训练中使用数据增强和反向翻译来提高模型性能。</li>
<li>results: 研究显示，英语预训模型在英文-pidgin任务上比多语言语模型更强，具有最多2.38 BLEU 提升；同时，通过数据增强和反向翻译来进行任务适应训练，可以对模型性能产生显著的影响。<details>
<summary>Abstract</summary>
Developing effective spoken language processing systems for low-resource languages poses several challenges due to the lack of parallel data and limited resources for fine-tuning models. In this work, we target on improving upon both text classification and translation of Nigerian Pidgin (Naija) by collecting a large-scale parallel English-Pidgin corpus and further propose a framework of cross-lingual adaptive training that includes both continual and task adaptive training so as to adapt a base pre-trained model to low-resource languages. Our studies show that English pre-trained language models serve as a stronger prior than multilingual language models on English-Pidgin tasks with up to 2.38 BLEU improvements; and demonstrate that augmenting orthographic data and using task adaptive training with back-translation can have a significant impact on model performance.
</details>
<details>
<summary>摘要</summary>
developing effective spoken language processing systems for low-resource languages poses several challenges due to the lack of parallel data and limited resources for fine-tuning models. in this work, we target on improving upon both text classification and translation of nigerian pidgin (naija) by collecting a large-scale parallel english-pidgin corpus and further propose a framework of cross-lingual adaptive training that includes both continual and task adaptive training so as to adapt a base pre-trained model to low-resource languages. our studies show that english pre-trained language models serve as a stronger prior than multilingual language models on english-pidgin tasks with up to 2.38 bleu improvements; and demonstrate that augmenting orthographic data and using task adaptive training with back-translation can have a significant impact on model performance.
</details></li>
</ul>
<hr>
<h2 id="Effective-Matching-of-Patients-to-Clinical-Trials-using-Entity-Extraction-and-Neural-Re-ranking"><a href="#Effective-Matching-of-Patients-to-Clinical-Trials-using-Entity-Extraction-and-Neural-Re-ranking" class="headerlink" title="Effective Matching of Patients to Clinical Trials using Entity Extraction and Neural Re-ranking"></a>Effective Matching of Patients to Clinical Trials using Entity Extraction and Neural Re-ranking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00381">http://arxiv.org/abs/2307.00381</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ProjectDossier/patient-trial-matching">https://github.com/ProjectDossier/patient-trial-matching</a></li>
<li>paper_authors: Wojciech Kusa, Óscar E. Mendoza, Petr Knoth, Gabriella Pasi, Allan Hanbury</li>
<li>for: 本研究目的是解决临床试验（CT）招募缺乏问题，提出一种缓解病人招募困难的方法，包括两个关键组件：一个数据增强技术，用于在第一个检索阶段提高查询和文档，以及一种基于转换器网络的重新排序方法。</li>
<li>methods: 本研究使用了两个关键组件：一个数据增强技术，用于在第一个检索阶段提高查询和文档，以及一种基于转换器网络的重新排序方法。数据增强技术包括命名实体识别和否定检测，用于增强病人描述和试验条件段落。重新排序方法使用了一个基于转换器网络的二步训练方法，其中第一步是匹配病人信息与试验描述段落，第二步是匹配病人信息与试验条件段落。</li>
<li>results: 研究结果表明，包含病人描述段落的试验条件部分对lexical模型的重levance分数有很大的影响，而数据增强技术可以提高试验检索的有效率。基于我们的训练方法，重新排序方法可以持续提高试验检索的精度，比较效果高于大型神经网络模型，即使用有限的训练数据。<details>
<summary>Abstract</summary>
Clinical trials (CTs) often fail due to inadequate patient recruitment. This paper tackles the challenges of CT retrieval by presenting an approach that addresses the patient-to-trials paradigm. Our approach involves two key components in a pipeline-based model: (i) a data enrichment technique for enhancing both queries and documents during the first retrieval stage, and (ii) a novel re-ranking schema that uses a Transformer network in a setup adapted to this task by leveraging the structure of the CT documents. We use named entity recognition and negation detection in both patient description and the eligibility section of CTs. We further classify patient descriptions and CT eligibility criteria into current, past, and family medical conditions. This extracted information is used to boost the importance of disease and drug mentions in both query and index for lexical retrieval. Furthermore, we propose a two-step training schema for the Transformer network used to re-rank the results from the lexical retrieval. The first step focuses on matching patient information with the descriptive sections of trials, while the second step aims to determine eligibility by matching patient information with the criteria section. Our findings indicate that the inclusion criteria section of the CT has a great influence on the relevance score in lexical models, and that the enrichment techniques for queries and documents improve the retrieval of relevant trials. The re-ranking strategy, based on our training schema, consistently enhances CT retrieval and shows improved performance by 15\% in terms of precision at retrieving eligible trials. The results of our experiments suggest the benefit of making use of extracted entities. Moreover, our proposed re-ranking schema shows promising effectiveness compared to larger neural models, even with limited training data.
</details>
<details>
<summary>摘要</summary>
临床试验（CT）常常失败因为缺乏合适的病人招募。这篇论文解决了CT检索的挑战，提出了一种管道模型中的两个关键组成部分：（i）用于提高查询和文档的数据增强技术，以及（ii）基于Transformer网络的一种新的重新排名方法。我们使用命名实体识别和否定检测在病人描述和试验条件中。我们进一步将病人描述和试验条件分类为当前、过去和家族医疗状况。这些提取的信息用于提高病情和药物提及的重要性在查询和索引中。此外，我们提议一种两步训练方案，用于在重新排名过程中使用Transformer网络。第一步是匹配病人信息与试验描述部分，第二步是匹配病人信息与试验条件部分。我们的实验结果表明，试验条件部分对lexical模型的相关分数有着很大的影响，而我们的增强技术可以提高有关试验的检索。我们的重新排名策略基于我们的训练方案，在提高CT检索中表现出了显著的优异性，相比于大型神经网络，我们的方案更有效率，即使用限制的训练数据。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Sample-Size-Determination-in-Natural-Language-Understanding"><a href="#Revisiting-Sample-Size-Determination-in-Natural-Language-Understanding" class="headerlink" title="Revisiting Sample Size Determination in Natural Language Understanding"></a>Revisiting Sample Size Determination in Natural Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00374">http://arxiv.org/abs/2307.00374</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pjlintw/sample-size">https://github.com/pjlintw/sample-size</a></li>
<li>paper_authors: Ernie Chang, Muhammad Hassan Rashid, Pin-Jie Lin, Changsheng Zhao, Vera Demberg, Yangyang Shi, Vikas Chandra</li>
<li>for: 预测模型性能，减少数据标注预算</li>
<li>methods: 使用小量训练样本预测最大可达性能，并进行ablation study</li>
<li>results: 能够预测模型性能 within a small margin of mean absolute error (~ 0.9%) with only 10% data<details>
<summary>Abstract</summary>
Knowing exactly how many data points need to be labeled to achieve a certain model performance is a hugely beneficial step towards reducing the overall budgets for annotation. It pertains to both active learning and traditional data annotation, and is particularly beneficial for low resource scenarios. Nevertheless, it remains a largely under-explored area of research in NLP. We therefore explored various techniques for estimating the training sample size necessary to achieve a targeted performance value. We derived a simple yet effective approach to predict the maximum achievable model performance based on small amount of training samples - which serves as an early indicator during data annotation for data quality and sample size determination. We performed ablation studies on four language understanding tasks, and showed that the proposed approach allows us to forecast model performance within a small margin of mean absolute error (~ 0.9%) with only 10% data.
</details>
<details>
<summary>摘要</summary>
知道需要如多数据点标注以达到特定模型性能的准确数量是一项非常有利的进展，它适用于活动学习和传统数据标注，特别是在低资源情况下。然而，这还是一个相对较少研究的领域。我们因此探索了各种方法来估算需要达到目标性能值的训练样本数量。我们提出了一种简单 yet effective的方法，可以在小量训练样本下预测模型性能的最大可能值，并作为数据标注过程中的数据质量和样本数确定指标。我们在四种语言理解任务上进行了减少研究，并证明了我们的方法可以在只有10%的数据下预测模型性能，与实际值之间的差异在0.9%左右。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/cs.CL_2023_07_02/" data-id="cloimip5v006ls488dade82po" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/cs.LG_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T10:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/cs.LG_2023_07_02/">cs.LG - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Protecting-the-Future-Neonatal-Seizure-Detection-with-Spatial-Temporal-Modeling"><a href="#Protecting-the-Future-Neonatal-Seizure-Detection-with-Spatial-Temporal-Modeling" class="headerlink" title="Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling"></a>Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05382">http://arxiv.org/abs/2307.05382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyue Li, Yuchen Fang, You Li, Kan Ren, Yansen Wang, Xufang Luo, Juanyong Duan, Congrui Huang, Dongsheng Li, Lili Qiu</li>
<li>for: 旨在提供一种自动化新生儿癫痫识别方法，以替代人工监测。</li>
<li>methods: 使用深度学习框架STATENet，特点包括temporal、 spatial和model层次的精细设计，以便更好地适应新生儿癫痫特点。</li>
<li>results: 实验结果表明，我们的框架在大规模实际新生儿EEG数据集上表现出了显著更高的癫痫识别精度。<details>
<summary>Abstract</summary>
A timely detection of seizures for newborn infants with electroencephalogram (EEG) has been a common yet life-saving practice in the Neonatal Intensive Care Unit (NICU). However, it requires great human efforts for real-time monitoring, which calls for automated solutions to neonatal seizure detection. Moreover, the current automated methods focusing on adult epilepsy monitoring often fail due to (i) dynamic seizure onset location in human brains; (ii) different montages on neonates and (iii) huge distribution shift among different subjects. In this paper, we propose a deep learning framework, namely STATENet, to address the exclusive challenges with exquisite designs at the temporal, spatial and model levels. The experiments over the real-world large-scale neonatal EEG dataset illustrate that our framework achieves significantly better seizure detection performance.
</details>
<details>
<summary>摘要</summary>
新生儿电enzephalogram（EEG）检测是医疗单元（NICU）中一种常见 yet life-saving的做法。然而，这需要大量的人工劳动进行实时监测，因此需要自动化新生儿癫痫检测的解决方案。然而，现有的自动化方法通常因（i）脑动脉癫痫开始的地方不断变化；（ii）新生儿和成人的montage不同；以及（iii）不同个体之间的分布差异而失败。本文提出一种深度学习框架，即状态网络（STATENet），以解决这些独特的挑战。实验表明，我们的框架在大规模实际新生儿EEG数据集上显著提高了癫痫检测性能。
</details></li>
</ul>
<hr>
<h2 id="IoT-Based-Air-Quality-Monitoring-System-with-Machine-Learning-for-Accurate-and-Real-time-Data-Analysis"><a href="#IoT-Based-Air-Quality-Monitoring-System-with-Machine-Learning-for-Accurate-and-Real-time-Data-Analysis" class="headerlink" title="IoT-Based Air Quality Monitoring System with Machine Learning for Accurate and Real-time Data Analysis"></a>IoT-Based Air Quality Monitoring System with Machine Learning for Accurate and Real-time Data Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00580">http://arxiv.org/abs/2307.00580</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Hemanth-Karnati-HK/AQMS-ML">https://github.com/Hemanth-Karnati-HK/AQMS-ML</a></li>
<li>paper_authors: Hemanth Karnati</li>
<li>for:  addresses the issue of air pollution awareness in urban areas</li>
<li>methods:  uses two sensors (MQ135 and MQ3) to detect harmful gases and measure air quality in PPM, and employs machine learning analysis on the collected data</li>
<li>results:  provides real-time data specific to the user’s location, and visualizes the data using a cloud-based web app called ThinkSpeak<details>
<summary>Abstract</summary>
Air pollution in urban areas has severe consequences for both human health and the environment, predominantly caused by exhaust emissions from vehicles. To address the issue of air pollution awareness, Air Pollution Monitoring systems are used to measure the concentration of gases like CO2, smoke, alcohol, benzene, and NH3 present in the air. However, current mobile applications are unable to provide users with real-time data specific to their location. In this paper, we propose the development of a portable air quality detection device that can be used anywhere. The data collected will be stored and visualized using the cloud-based web app ThinkSpeak.   The device utilizes two sensors, MQ135 and MQ3, to detect harmful gases and measure air quality in parts per million (PPM). Additionally, machine learning analysis will be employed on the collected data.
</details>
<details>
<summary>摘要</summary>
城市空气污染造成人体健康和环境问题严重，主要由交通工具排放的废气引起。为解决空气污染意识问题，空气污染监测系统用于测量空气中的气体 like CO2、烟雾、酒精、苯并丙烯的浓度。但现有 mobil 应用程序无法为用户提供实时特定位置的数据。在这篇论文中，我们提议开发一种可携带的空气质量检测设备，可以在任何地方使用。收集的数据将被存储并视觉化使用云端的网站 ThinkSpeak。 该设备使用 MQ135 和 MQ3 两种传感器检测危险气体，并测量空气质量为每万分之一（PPM）。此外，我们还将机器学习分析集成到收集的数据中。
</details></li>
</ul>
<hr>
<h2 id="Mode-wise-Principal-Subspace-Pursuit-and-Matrix-Spiked-Covariance-Model"><a href="#Mode-wise-Principal-Subspace-Pursuit-and-Matrix-Spiked-Covariance-Model" class="headerlink" title="Mode-wise Principal Subspace Pursuit and Matrix Spiked Covariance Model"></a>Mode-wise Principal Subspace Pursuit and Matrix Spiked Covariance Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00575">http://arxiv.org/abs/2307.00575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runshi Tang, Ming Yuan, Anru R. Zhang</li>
<li>for: 这个论文提出了一种新的框架，叫做模式精炼主要特征追踪（MOP-UP），用于抽取矩阵数据中隐藏的变化。</li>
<li>methods: 该algorithm consists of two steps: Average Subspace Capture (ASC) and Alternating Projection (AP). These steps are specifically designed to capture the row-wise and column-wise dimension-reduced subspaces which contain the most informative features of the data.</li>
<li>results: The proposed framework is demonstrated to be effective through experiments on both simulated and real datasets, and the authors also discuss generalizations of their approach to higher-order data.<details>
<summary>Abstract</summary>
This paper introduces a novel framework called Mode-wise Principal Subspace Pursuit (MOP-UP) to extract hidden variations in both the row and column dimensions for matrix data. To enhance the understanding of the framework, we introduce a class of matrix-variate spiked covariance models that serve as inspiration for the development of the MOP-UP algorithm. The MOP-UP algorithm consists of two steps: Average Subspace Capture (ASC) and Alternating Projection (AP). These steps are specifically designed to capture the row-wise and column-wise dimension-reduced subspaces which contain the most informative features of the data. ASC utilizes a novel average projection operator as initialization and achieves exact recovery in the noiseless setting. We analyze the convergence and non-asymptotic error bounds of MOP-UP, introducing a blockwise matrix eigenvalue perturbation bound that proves the desired bound, where classic perturbation bounds fail. The effectiveness and practical merits of the proposed framework are demonstrated through experiments on both simulated and real datasets. Lastly, we discuss generalizations of our approach to higher-order data.
</details>
<details>
<summary>摘要</summary>
MOP-UP consists of two steps: Average Subspace Capture (ASC) and Alternating Projection (AP). These steps are designed to capture the row-wise and column-wise dimension-reduced subspaces that contain the most informative features of the data. ASC uses a novel average projection operator as initialization and can achieve exact recovery in the noiseless setting.We analyze the convergence and non-asymptotic error bounds of MOP-UP, using a blockwise matrix eigenvalue perturbation bound that proves the desired bound, where classic perturbation bounds fail. The effectiveness and practical merits of the proposed framework are demonstrated through experiments on both simulated and real datasets. Finally, we discuss generalizations of our approach to higher-order data.
</details></li>
</ul>
<hr>
<h2 id="Conditionally-Invariant-Representation-Learning-for-Disentangling-Cellular-Heterogeneity"><a href="#Conditionally-Invariant-Representation-Learning-for-Disentangling-Cellular-Heterogeneity" class="headerlink" title="Conditionally Invariant Representation Learning for Disentangling Cellular Heterogeneity"></a>Conditionally Invariant Representation Learning for Disentangling Cellular Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00558">http://arxiv.org/abs/2307.00558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hananeh Aliee, Ferdinand Kapl, Soroor Hediyeh-Zadeh, Fabian J. Theis</li>
<li>for: 这 paper 的目的是学习受到不想要的变化的表示，通过强制独立性来消除噪声，并建立可解释的模型。</li>
<li>methods: 该方法利用域变化来学习受到不想要的变化的表示，并在满足条件下强制独立性，以便构建可解释的模型。</li>
<li>results: 该方法可以在大规模的单元细胞 genomics 数据中实现数据集 Integration，并提供更深刻的理解单元细胞多样性和疾病细胞状态的能力。<details>
<summary>Abstract</summary>
This paper presents a novel approach that leverages domain variability to learn representations that are conditionally invariant to unwanted variability or distractors. Our approach identifies both spurious and invariant latent features necessary for achieving accurate reconstruction by placing distinct conditional priors on latent features. The invariant signals are disentangled from noise by enforcing independence which facilitates the construction of an interpretable model with a causal semantic. By exploiting the interplay between data domains and labels, our method simultaneously identifies invariant features and builds invariant predictors. We apply our method to grand biological challenges, such as data integration in single-cell genomics with the aim of capturing biological variations across datasets with many samples, obtained from different conditions or multiple laboratories. Our approach allows for the incorporation of specific biological mechanisms, including gene programs, disease states, or treatment conditions into the data integration process, bridging the gap between the theoretical assumptions and real biological applications. Specifically, the proposed approach helps to disentangle biological signals from data biases that are unrelated to the target task or the causal explanation of interest. Through extensive benchmarking using large-scale human hematopoiesis and human lung cancer data, we validate the superiority of our approach over existing methods and demonstrate that it can empower deeper insights into cellular heterogeneity and the identification of disease cell states.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Partial-label-Learning-with-Mixed-Closed-set-and-Open-set-Out-of-candidate-Examples"><a href="#Partial-label-Learning-with-Mixed-Closed-set-and-Open-set-Out-of-candidate-Examples" class="headerlink" title="Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples"></a>Partial-label Learning with Mixed Closed-set and Open-set Out-of-candidate Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00553">http://arxiv.org/abs/2307.00553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo He, Lei Feng, Guowu Yang</li>
<li>for: 本研究旨在解决部分标签学习中的一种限制性假设问题，即训练示例的真实标签必须在候选标签集中。</li>
<li>methods: 本研究使用了两种类型的假设例子，即闭集&#x2F;开集假设例子，其中true标签在知道标签空间内&#x2F;外。为解决这个新的部分标签学习问题，我们首先计算了木头克朗径分布损失函数，并根据特制的标签分类器来动态地区分两种假设例子。对于闭集假设例子，我们进行了反向标签混淆处理；对于开集假设例子，我们利用了一种有效的规范策略，在候选标签集中随机分配了假设标签。这样，两种假设例子都可以得到分化并利用于模型训练。</li>
<li>results: 我们的提议方法与现有的部分标签学习方法进行比较，实验结果显示，我们的方法在训练集中表现更好。<details>
<summary>Abstract</summary>
Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (out-of-candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.
</details>
<details>
<summary>摘要</summary>
假设学习（Partial-label learning，PLL）基于一个关键假设，即每个训练示例的真实标签必须在候选标签集中。然而，在复杂的实际场景中，这个假设可能会被违反，有些收集的示例的真实标签可能会不期望地外部候选标签集。在这篇论文中，我们称这些示例为“外部候选标签示例”（OOC，out-of-candidate），并开拓了一种新的PLL研究，以学习与OOC示例。我们在实际中考虑了两种类型的OOC示例，即关闭集/开放集OOC示例，其中true标签在知道的标签空间内/外。为解决这个新的PLL问题，我们首先计算了木材cross-entropy损失从候选标签和非候选标签分别来，然后通过特殊设计的标准来动态分类OOC示例。对关闭集OOC示例，我们进行了反向标签混淆在非候选标签集中；对开放集OOC示例，我们利用它们进行训练，通过使用一种有效的补偿策略，动态将候选标签集中的随机标签分配给OOC示例。这种方法可以区分和利用两种类型的OOC示例进行训练。我们的提议方法在现有的PLL方法之上具有优异性。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-reinforcement-learning-of-multi-agent-ethically-aligned-behaviours-the-QSOM-and-QDSOM-algorithms"><a href="#Adaptive-reinforcement-learning-of-multi-agent-ethically-aligned-behaviours-the-QSOM-and-QDSOM-algorithms" class="headerlink" title="Adaptive reinforcement learning of multi-agent ethically-aligned behaviours: the QSOM and QDSOM algorithms"></a>Adaptive reinforcement learning of multi-agent ethically-aligned behaviours: the QSOM and QDSOM algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00552">http://arxiv.org/abs/2307.00552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémy Chaput, Olivier Boissier, Mathieu Guillermin</li>
<li>for: 这篇论文主要是为了解决人工智能系统的伦理考虑问题，特别是随着时间的推移，我们社会的价值观念不断发展，这使得现有的AI系统困难以适应。</li>
<li>methods: 该论文提出了两种算法，即QSOM和QDSOM，它们可以适应环境和奖励函数的变化，以实现AI系统的伦理考虑。它们使用了知名的Q表格和动态自组织地图来处理连续和多维状态和动作空间。</li>
<li>results: 作者在一个小型智能网格中进行了多代理能量分配的用例，并证明了QSOM和QDSOM算法的适应性和比基eline Reinforcement Learning算法的高性能。<details>
<summary>Abstract</summary>
The numerous deployed Artificial Intelligence systems need to be aligned with our ethical considerations. However, such ethical considerations might change as time passes: our society is not fixed, and our social mores evolve. This makes it difficult for these AI systems; in the Machine Ethics field especially, it has remained an under-studied challenge. In this paper, we present two algorithms, named QSOM and QDSOM, which are able to adapt to changes in the environment, and especially in the reward function, which represents the ethical considerations that we want these systems to be aligned with. They associate the well-known Q-Table to (Dynamic) Self-Organizing Maps to handle the continuous and multi-dimensional state and action spaces. We evaluate them on a use-case of multi-agent energy repartition within a small Smart Grid neighborhood, and prove their ability to adapt, and their higher performance compared to baseline Reinforcement Learning algorithms.
</details>
<details>
<summary>摘要</summary>
各种已经部署的人工智能系统需要与我们的道德考虑相协调。然而，这些道德考虑可能随着时间的推移而发生变化：我们的社会不固定，我们的社会习俗也在不断发展。这会让这些 AI 系统受到挑战：在机器伦理学领域，这是一个未得到充分研究的挑战。在这篇论文中，我们提出了两种算法，即 QSOM 和 QDSOM，它们可以适应环境的变化，特别是奖励函数的变化，这些奖励函数表达我们想要这些系统遵循的道德考虑。它们将知名的 Q-表与（动态）自组织地图相结合，以处理连续和多维状态和动作空间。我们在一个小型智能网格社区中进行了多机器人能源分配的使用案例研究，并证明它们的适应性和与基准 Reinforcement Learning 算法相比的高性能。
</details></li>
</ul>
<hr>
<h2 id="Is-Risk-Sensitive-Reinforcement-Learning-Properly-Resolved"><a href="#Is-Risk-Sensitive-Reinforcement-Learning-Properly-Resolved" class="headerlink" title="Is Risk-Sensitive Reinforcement Learning Properly Resolved?"></a>Is Risk-Sensitive Reinforcement Learning Properly Resolved?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00547">http://arxiv.org/abs/2307.00547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiwen Zhou, Minghuan Liu, Kan Ren, Xufang Luo, Weinan Zhang, Dongsheng Li</li>
<li>for: 本研究旨在解决分布式强化学习中的风险敏感问题，提出了一种新的算法，即轨迹Q学习（TQL），以便在风险敏感目标下优化做法。</li>
<li>methods: 本研究使用了分布式强化学习框架，学习风险敏感目标函数，并提出了一种新的学习算法，即TQL，可以在不同的风险度量下学习不同的风险敏感策略。</li>
<li>results: 实验结果表明，TQL算法可以有效地实现风险敏感目标，并且可以在不同的风险度量下实现更好的性能。<details>
<summary>Abstract</summary>
Due to the nature of risk management in learning applicable policies, risk-sensitive reinforcement learning (RSRL) has been realized as an important direction. RSRL is usually achieved by learning risk-sensitive objectives characterized by various risk measures, under the framework of distributional reinforcement learning. However, it remains unclear if the distributional Bellman operator properly optimizes the RSRL objective in the sense of risk measures. In this paper, we prove that the existing RSRL methods do not achieve unbiased optimization and can not guarantee optimality or even improvements regarding risk measures over accumulated return distributions. To remedy this issue, we further propose a novel algorithm, namely Trajectory Q-Learning (TQL), for RSRL problems with provable convergence to the optimal policy. Based on our new learning architecture, we are free to introduce a general and practical implementation for different risk measures to learn disparate risk-sensitive policies. In the experiments, we verify the learnability of our algorithm and show how our method effectively achieves better performances toward risk-sensitive objectives.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)由于学习适用政策的风险管理性质，风险敏感回归学习（RSRL）已成为重要的方向。RSRL通常通过学习不同的风险度量来定义风险敏感目标，在分布式回归学习框架下进行学习。然而，是否存在分布式贝尔曼算子可以正确优化RSRL目标还存在unclear。在这篇论文中，我们证明现有的RSRL方法不能够实现不偏优化和 garantía优化或even improvements regarding风险度量 надaccumulated return分布。为了解决这个问题，我们进一步提出了一种新的算法，即轨迹Q学习（TQL），用于RSRL问题，并证明其可提供可靠的优化方案。基于我们的新学习架构，我们可以自由地引入不同的风险度量来学习不同的风险敏感政策。在实验中，我们验证了我们的算法的学习可能性并显示了我们的方法可以更好地实现风险敏感目标。
</details></li>
</ul>
<hr>
<h2 id="Defending-Against-Malicious-Behaviors-in-Federated-Learning-with-Blockchain"><a href="#Defending-Against-Malicious-Behaviors-in-Federated-Learning-with-Blockchain" class="headerlink" title="Defending Against Malicious Behaviors in Federated Learning with Blockchain"></a>Defending Against Malicious Behaviors in Federated Learning with Blockchain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00543">http://arxiv.org/abs/2307.00543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael Kampffmeyer, Yizhe Wen, Shuoying Zhang, William Knottenbelt, Eric Xing</li>
<li>for: 提高 federated learning 系统的安全性和可靠性，使其更易承受多个机构数据拥有者（客户）之间的合作训练。</li>
<li>methods: 基于区块链和分布式笔记技术，提出一种安全可靠的 federated learning 系统，包括对接触 peer-to-peer 投票机制和奖励折损机制，以检测和抵制恶意客户端行为。</li>
<li>results: 通过理论和实验分析，证明提出的方法可以具有高效性和可靠性，并能够抵制恶意客户端的行为。<details>
<summary>Abstract</summary>
In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.
</details>
<details>
<summary>摘要</summary>
在深度学习时代，联邦学习（FL）表现出了一种有前途的方法，允许多个机构数据所有者或客户端共同训练机器学习模型，无需违反数据隐私。然而，大多数现有FL方法仍然依赖中央服务器进行全球模型集成，导致单点失败的风险。这使得系统易受到不良客户端行为的攻击。在这种情况下，我们解决这个问题，提出一个安全可靠的FL系统，基于区块链和分布式记录技术。我们的系统包括一个点对点投票机制和一个奖励惩罚机制，这些机制由onto-chain智能合约动力，用于检测和抵制不良客户端行为。我们提供了理论和实验分析，证明我们的框架对客户端不良行为具有耐诡性。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Policy-Learning-for-Dynamic-Scheduling-Tasks-in-Cloud-Edge-Terminal-IoT-Networks-Using-Federated-Reinforcement-Learning"><a href="#Collaborative-Policy-Learning-for-Dynamic-Scheduling-Tasks-in-Cloud-Edge-Terminal-IoT-Networks-Using-Federated-Reinforcement-Learning" class="headerlink" title="Collaborative Policy Learning for Dynamic Scheduling Tasks in Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning"></a>Collaborative Policy Learning for Dynamic Scheduling Tasks in Cloud-Edge-Terminal IoT Networks Using Federated Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00541">http://arxiv.org/abs/2307.00541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Do-Yup Kim, Da-Eun Lee, Ji-Wan Kim, Hyun-Suk Lee</li>
<li>for: 这篇论文研究了云端-边缘-终端互联网络，其中边缘设备进行了一系列通常的动态调度任务。</li>
<li>methods: 该论文提出了一种基于联邦 reinforcement learning 的共同策略学习框架，用于动态调度任务。该框架可以在云服务器上协同学习每个任务的中央策略，并且可以通过Edge在每个任务上学习本地策略，以避免Edge需要从头开始学习策略。</li>
<li>results: 通过实验，论文表明，相比没有共同策略学习的方法，该框架能够加速策略学习速度，并且帮助新到达的Edge更容易适应其任务。<details>
<summary>Abstract</summary>
In this paper, we examine cloud-edge-terminal IoT networks, where edges undertake a range of typical dynamic scheduling tasks. In these IoT networks, a central policy for each task can be constructed at a cloud server. The central policy can be then used by the edges conducting the task, thereby mitigating the need for them to learn their own policy from scratch. Furthermore, this central policy can be collaboratively learned at the cloud server by aggregating local experiences from the edges, thanks to the hierarchical architecture of the IoT networks. To this end, we propose a novel collaborative policy learning framework for dynamic scheduling tasks using federated reinforcement learning. For effective learning, our framework adaptively selects the tasks for collaborative learning in each round, taking into account the need for fairness among tasks. In addition, as a key enabler of the framework, we propose an edge-agnostic policy structure that enables the aggregation of local policies from different edges. We then provide the convergence analysis of the framework. Through simulations, we demonstrate that our proposed framework significantly outperforms the approaches without collaborative policy learning. Notably, it accelerates the learning speed of the policies and allows newly arrived edges to adapt to their tasks more easily.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了云端-边缘-终端互联网络，其中边缘进行了一系列典型的动态调度任务。在这些互联网络中，可以在云服务器上构建一个中央政策 для每个任务。这个中央政策可以由边缘进行调度任务使用，从而减少边缘需要从零开始学习自己的策略。此外，这个中央政策可以在云服务器上协同学习，通过累累的结构来汇集不同边缘的地方经验。为了实现这一目标，我们提出了一种基于联邦束力学学习的共同策略学习框架。为了有效学习，我们的框架在每次轮次中适时选择需要协同学习的任务，考虑到任务之间的公平性。此外，我们还提出了一种不受边缘影响的策略结构，以便将不同边缘的本地策略集成。然后，我们提供了框架的收敛分析。通过实验，我们证明了我们提出的框架可以快速学习策略，并且新到达的边缘可以更容易适应自己的任务。
</details></li>
</ul>
<hr>
<h2 id="Shared-Growth-of-Graph-Neural-Networks-via-Free-direction-Knowledge-Distillation"><a href="#Shared-Growth-of-Graph-Neural-Networks-via-Free-direction-Knowledge-Distillation" class="headerlink" title="Shared Growth of Graph Neural Networks via Free-direction Knowledge Distillation"></a>Shared Growth of Graph Neural Networks via Free-direction Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00534">http://arxiv.org/abs/2307.00534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaituo Feng, Yikun Miao, Changsheng Li, Ye Yuan, Guoren Wang</li>
<li>for: 提高Graph Neural Networks（GNNs）的性能，避免过参数和过拟合问题。</li>
<li>methods: 提出了首个基于强化学习的Free-direction Knowledge Distillation框架（FreeKD），不再需要提供一个很深和优化的教师GNN。我们的核心想法是通过层次的强化学习来让两个相对较浅的GNN Collaboratively学习，以便在层次上交换知识。我们观察到，一个典型的GNN模型在训练中常常在不同的节点上展现出不同的性能，所以我们设计了一种动态和自由方向的知识传递策略，其中包括两个层次的操作：1）节点级别的操作确定了两个网络中相应节点之间的知识传递方向; 2）结构级别的操作确定了哪些本地结构由节点级别的操作生成的知识传递。</li>
<li>results: 对五个标准 benchmark dataset进行了广泛的实验，并显示了我们的方法可以大幅提高基GNN的性能，并且可以适应不同的GNN模型。最后，我们还提出了FreeKD++，可以在多视图输入下实现自由方向知识传递。<details>
<summary>Abstract</summary>
Knowledge distillation (KD) has shown to be effective to boost the performance of graph neural networks (GNNs), where the typical objective is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is often quite challenging to train a satisfactory deeper GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. Our core idea is to collaboratively learn two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often exhibits better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that involves two levels of actions: 1) node-level action determines the directions of knowledge transfer between the corresponding nodes of two networks; and then 2) structure-level action determines which of the local structures generated by the node-level actions to be propagated. Furthermore, considering the diverse knowledge present in different GNNs when dealing with multi-view inputs, we introduce FreeKD++ as a solution to enable free-direction knowledge transfer among multiple shallow GNNs operating on multi-view inputs. Extensive experiments on five benchmark datasets demonstrate our approaches outperform the base GNNs in a large margin, and shows their efficacy to various GNNs. More surprisingly, our FreeKD has comparable or even better performance than traditional KD algorithms that distill knowledge from a deeper and stronger teacher GNN.
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）已经证明可以提高图内 нейрон网络（GNN）的性能，通常的目标是将深度更大的教师GNN中的知识透传到更浅的学生GNN中。然而，在实际应用中，往往很难训练一个满意的深度更大的GNN，因为图内神经网络容易受到过参数和过缓态问题的影响，从而导致无效的知识传递。在这篇论文中，我们提出了首个基于奖励学习的自由方向知识塑化框架 для GNN，称为FreeKD。我们的核心想法是通过奖励学习的方式，将两个更浅的GNN合作学习，以便在其中交换知识。我们发现，一个典型的GNN模型在训练中经常在不同的节点表现出不同的性能，因此我们设计了一种动态和自由方向的知识传递策略，其中包括两个层次的动作：1）节点级别的动作确定了两个网络中对应节点之间的知识传递方向; 然后2）结构级别的动作确定了哪些本地结构，由节点级别的动作生成的。此外，当处理多视图输入时，我们引入FreeKD++，以允许多个浅GNN之间自由地进行知识传递。我们的方法在五个基准数据集上进行了广泛的实验，并证明了我们的方法在基GNN上大幅提高性能，并且可以适应不同的GNN模型。更重要的是，我们的FreeKD与传统的KD算法相比，在提取深度更大的教师GNN中的知识时，表现相对或甚至更好。
</details></li>
</ul>
<hr>
<h2 id="New-intelligent-defense-systems-to-reduce-the-risks-of-Selfish-Mining-and-Double-Spending-attacks-using-Learning-Automata"><a href="#New-intelligent-defense-systems-to-reduce-the-risks-of-Selfish-Mining-and-Double-Spending-attacks-using-Learning-Automata" class="headerlink" title="New intelligent defense systems to reduce the risks of Selfish Mining and Double-Spending attacks using Learning Automata"></a>New intelligent defense systems to reduce the risks of Selfish Mining and Double-Spending attacks using Learning Automata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00529">http://arxiv.org/abs/2307.00529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Ardalan Ghoreishi, Mohammad Reza Meybodi</li>
<li>for: 这 paper addresses the double-spending and selfish mining attacks challenges in blockchain-based digital currencies.</li>
<li>methods: 该 paper 提出了一种新的攻击方法， combinining double-spending 和 selfish mining attacks，并提出了一种基于机器学习的解决方案。 Specifically, 使用 learning automaton 来开发两种模型， namely SDTLA 和 WVBM，可以有效地防止自ish mining attacks。</li>
<li>results: 实验结果表明， SDTLA 方法可以提高自ish mining 的利润阈值达到 47%，而 WVBM 方法在许多情况下几乎达到理想情况，即每个矿工的收益与其分配的 hash 处理能力成正比。 此外，两种方法都可以有效地减少 double-spending 的风险。<details>
<summary>Abstract</summary>
In this paper, we address the critical challenges of double-spending and selfish mining attacks in blockchain-based digital currencies. Double-spending is a problem where the same tender is spent multiple times during a digital currency transaction, while selfish mining is an intentional alteration of a blockchain to increase rewards to one miner or a group of miners. We introduce a new attack that combines both these attacks and propose a machine learning-based solution to mitigate the risks associated with them. Specifically, we use the learning automaton, a powerful online learning method, to develop two models, namely the SDTLA and WVBM, which can effectively defend against selfish mining attacks. Our experimental results show that the SDTLA method increases the profitability threshold of selfish mining up to 47$\%$, while the WVBM method performs even better and is very close to the ideal situation where each miner's revenue is proportional to their shared hash processing power. Additionally, we demonstrate that both methods can effectively reduce the risks of double-spending by tuning the $Z$ Parameter. Our findings highlight the potential of SDTLA and WVBM as promising solutions for enhancing the security and efficiency of blockchain networks.
</details>
<details>
<summary>摘要</summary>
在本文中，我们讨论了区块链基于货币的双重支付和自私采矿攻击的关键挑战。双重支付是一个情况下，同一笔货币在数字货币交易中被使用多次，而自私采矿是故意修改区块链，以增加采矿奖励的情况。我们介绍了一种新的攻击，该攻击组合了这两种攻击，并提出了基于机器学习的解决方案。 Specifically，我们使用学习自动机，一种强大的在线学习方法，开发了两种模型， namely SDTLA和WVBM，以有效防止自私采矿攻击。我们的实验结果表明，SDTLA方法可以提高自私采矿的利润阈值，最高达47%；WVBM方法表现更好，与每个矿工的分配 hash 处理能力相似。此外，我们证明了这两种方法可以有效降低双重支付的风险，通过调整 $Z$ 参数。我们的发现表明 SDTLA 和 WVBM 是加强区块链网络安全性和效率的有力解决方案。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Network-based-Log-Anomaly-Detection-and-Explanation"><a href="#Graph-Neural-Network-based-Log-Anomaly-Detection-and-Explanation" class="headerlink" title="Graph Neural Network based Log Anomaly Detection and Explanation"></a>Graph Neural Network based Log Anomaly Detection and Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00527">http://arxiv.org/abs/2307.00527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhong Li, Jiayang Shi, Matthijs van Leeuwen</li>
<li>for: 该研究旨在提高高科技系统监控中的日志异常检测精度，使用图形模型来检测日志异常。</li>
<li>methods: 该方法首先将日志事件转换为有Attributes、指向和权重的图形模型，然后使用图形神经网络进行图形级别异常检测。</li>
<li>results: 实验结果显示，Logs2Graphs在五个基准数据集上表现至少与现状异常检测方法相当，而在复杂数据集上大量超过现状异常检测方法的性能。<details>
<summary>Abstract</summary>
Event logs are widely used to record the status of high-tech systems, making log anomaly detection important for monitoring those systems. Most existing log anomaly detection methods take a log event count matrix or log event sequences as input, exploiting quantitative and/or sequential relationships between log events to detect anomalies. Unfortunately, only considering quantitative or sequential relationships may result in many false positives and/or false negatives. To alleviate this problem, we propose a graph-based method for unsupervised log anomaly detection, dubbed Logs2Graphs, which first converts event logs into attributed, directed, and weighted graphs, and then leverages graph neural networks to perform graph-level anomaly detection. Specifically, we introduce One-Class Digraph Inception Convolutional Networks, abbreviated as OCDiGCN, a novel graph neural network model for detecting graph-level anomalies in a collection of attributed, directed, and weighted graphs. By coupling the graph representation and anomaly detection steps, OCDiGCN can learn a representation that is especially suited for anomaly detection, resulting in a high detection accuracy. Importantly, for each identified anomaly, we additionally provide a small subset of nodes that play a crucial role in OCDiGCN's prediction as explanations, which can offer valuable cues for subsequent root cause diagnosis. Experiments on five benchmark datasets show that Logs2Graphs performs at least on par state-of-the-art log anomaly detection methods on simple datasets while largely outperforming state-of-the-art log anomaly detection methods on complicated datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>>高科技系统的事件日志广泛应用，因此对事件日志异常检测非常重要。现有的大多数异常检测方法都是根据事件日志的数量或Sequential关系进行检测，但是只考虑数量或Sequential关系可能会导致许多假阳性和/或假阴性。为了解决这个问题，我们提出了一种基于图的方法，名为Logs2Graphs，它首先将事件日志转换为有 Attribute、指向和权重的图，然后利用图神经网络进行图级异常检测。我们引入了一种novel的图神经网络模型，称为One-Class Digraph Inception Convolutional Networks（简称OCDiGCN），可以在一个集合 Attribute、指向和权重的图中检测图级异常。通过将图表示和异常检测步骤结合起来，OCDiGCN可以学习一种特别适合异常检测的表示，从而实现高的检测精度。此外，对每个异常检测结果，我们还提供了一小 subsets of nodes，这些 nodes 在 OCDiGCN 的预测中发挥了关键作用，这些 nodes 可以提供有价值的诊断灵感。在五个 benchmark 数据集上进行了实验，Logs2Graphs 与 state-of-the-art 异常检测方法在简单的数据集上表现至少与state-of-the-art，而在复杂的数据集上则广泛超越 state-of-the-art。
</details></li>
</ul>
<hr>
<h2 id="TensorGPT-Efficient-Compression-of-the-Embedding-Layer-in-LLMs-based-on-the-Tensor-Train-Decomposition"><a href="#TensorGPT-Efficient-Compression-of-the-Embedding-Layer-in-LLMs-based-on-the-Tensor-Train-Decomposition" class="headerlink" title="TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition"></a>TensorGPT: Efficient Compression of the Embedding Layer in LLMs based on the Tensor-Train Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00526">http://arxiv.org/abs/2307.00526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxue Xu, Yao Lei Xu, Danilo P. Mandic</li>
<li>For: 提高 Large Language Models (LLMs) 的性能和压缩硬件需求* Methods: 使用 Tensor-Train Decomposition (TTD) 将每个token embedding treated as a Matrix Product State (MPS)，可以有效地在分布式环境中计算* Results: 对 GPT-2 进行实验，可以压缩 embedding layer 38.40 倍，并且当压缩因子为 3.31 倍时，甚至超过原始 GPT-2 模型的性能。<details>
<summary>Abstract</summary>
High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, the associated high dimensionality also introduces considerable model parameters, and a prohibitively high model storage. To address this issue, this work proposes an approach based on the Tensor-Train Decomposition (TTD), where each token embedding is treated as a Matrix Product State (MPS) that can be efficiently computed in a distributed manner. The experimental results on GPT-2 demonstrate that, through our approach, the embedding layer can be compressed by a factor of up to 38.40 times, and when the compression factor is 3.31 times, even produced a better performance than the original GPT-2 model.
</details>
<details>
<summary>摘要</summary>
高维度Token embedding在大型语言模型（LLM）中扮演着关键角色，它们可以捕捉语言表达中的细微含义并明显提高复杂语言模式的模型化。然而，相关的高维度也导致了较大的模型参数和庞大的模型存储。为解决这问题，本研究提出了基于张量积 Train Decomposition（TTD）的方法，其中每个Token embedding被视为一个Matrix Product State（MPS），可以有效地在分布式环境中计算。实验结果表明，通过我们的方法，Embedding层可以被压缩38.40倍，并且当压缩因子为3.31倍时，甚至超越了原始GPT-2模型的性能。
</details></li>
</ul>
<hr>
<h2 id="LEDITS-Real-Image-Editing-with-DDPM-Inversion-and-Semantic-Guidance"><a href="#LEDITS-Real-Image-Editing-with-DDPM-Inversion-and-Semantic-Guidance" class="headerlink" title="LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance"></a>LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00522">http://arxiv.org/abs/2307.00522</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adham-elarabawy/ledits">https://github.com/adham-elarabawy/ledits</a></li>
<li>paper_authors: Linoy Tsaban, Apolinário Passos</li>
<li>for: 本文旨在提出一种轻量级的真实图像编辑方法，以便使用文本来修改图像，而不需要更改模型结构。</li>
<li>methods: 本方法利用 Edit Friendly DDPM 倒推技术和 semantic guidance，将图像倒推到 DDPM 模型的预训练空间中，然后通过文本提示进行修改。</li>
<li>results: 本方法可以实现高质量的图像修改，包括细微和广泛的修改、组合和风格的变化，而无需进行优化或扩展模型结构。<details>
<summary>Abstract</summary>
Recent large-scale text-guided diffusion models provide powerful image-generation capabilities. Currently, a significant effort is given to enable the modification of these images using text only as means to offer intuitive and versatile editing. However, editing proves to be difficult for these generative models due to the inherent nature of editing techniques, which involves preserving certain content from the original image. Conversely, in text-based models, even minor modifications to the text prompt frequently result in an entirely distinct result, making attaining one-shot generation that accurately corresponds to the users intent exceedingly challenging. In addition, to edit a real image using these state-of-the-art tools, one must first invert the image into the pre-trained models domain - adding another factor affecting the edit quality, as well as latency. In this exploratory report, we propose LEDITS - a combined lightweight approach for real-image editing, incorporating the Edit Friendly DDPM inversion technique with Semantic Guidance, thus extending Semantic Guidance to real image editing, while harnessing the editing capabilities of DDPM inversion as well. This approach achieves versatile edits, both subtle and extensive as well as alterations in composition and style, while requiring no optimization nor extensions to the architecture.
</details>
<details>
<summary>摘要</summary>
现代大规模文本导向扩散模型提供了强大的图像生成能力。当前，许多努力是为了通过文本来修改这些图像，以便提供直观和灵活的编辑。然而，编辑 proves to be difficult for these generative models due to the inherent nature of editing techniques, which involves preserving certain content from the original image。 conversely, in text-based models, even minor modifications to the text prompt frequently result in an entirely distinct result, making one-shot generation that accurately corresponds to the user's intent exceedingly challenging。 In addition, to edit a real image using these state-of-the-art tools, one must first invert the image into the pre-trained models domain - adding another factor affecting the edit quality, as well as latency。在这份探索报告中，我们提出了 LEDITS - 一种轻量级的方法 для真实图像编辑，将 Edit Friendly DDPM 抽象技术与semantic guidance相结合，从而将semantic guidance扩展到真实图像编辑，同时利用 DDPM 抽象技术的编辑能力。这种方法可以实现多样化的修改，包括细微和广泛的修改，以及修改图像的结构和风格。此外，这种方法不需要扩展 nor optimization to the architecture。
</details></li>
</ul>
<hr>
<h2 id="DSTCGCN-Learning-Dynamic-Spatial-Temporal-Cross-Dependencies-for-Traffic-Forecasting"><a href="#DSTCGCN-Learning-Dynamic-Spatial-Temporal-Cross-Dependencies-for-Traffic-Forecasting" class="headerlink" title="DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for Traffic Forecasting"></a>DSTCGCN: Learning Dynamic Spatial-Temporal Cross Dependencies for Traffic Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00518">http://arxiv.org/abs/2307.00518</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/water-wbq/dstcgcn">https://github.com/water-wbq/dstcgcn</a></li>
<li>paper_authors: Binqing Wu, Ling Chen</li>
<li>for: 本研究旨在提出一种能够同时学习空间和时间关系的动态空间temporal crossing graph convolutional neural network (DSTCGCN)，以便进行智能交通系统中的交通预测。</li>
<li>methods: 该模型使用了快速傅立叶变换 (FFT) 基于的注意 selector，选择时间序列中相关的时间步骤，并将其作为动态cross graph构建模块进行学习。</li>
<li>results: 对于六个真实世界数据集，DSTCGCN实验结果表明，该模型在交通预测任务中达到了领先的性能。<details>
<summary>Abstract</summary>
Traffic forecasting is essential to intelligent transportation systems, which is challenging due to the complicated spatial and temporal dependencies within a road network. Existing works usually learn spatial and temporal dependencies separately, ignoring the dependencies crossing spatial and temporal dimensions. In this paper, we propose DSTCGCN, a dynamic spatial-temporal cross graph convolution network to learn dynamic spatial and temporal dependencies jointly via graphs for traffic forecasting. Specifically, we introduce a fast Fourier transform (FFT) based attentive selector to choose relevant time steps for each time step based on time-varying traffic data. Given the selected time steps, we introduce a dynamic cross graph construction module, consisting of the spatial graph construction, temporal connection graph construction, and fusion modules, to learn dynamic spatial-temporal cross dependencies without pre-defined priors. Extensive experiments on six real-world datasets demonstrate that DSTCGCN achieves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统的重要组成部分，但是它具有较复杂的空间和时间依赖关系，使得现有的方法通常只是分别学习空间和时间依赖关系，忽略了空间和时间维度之间的依赖关系。在这篇论文中，我们提出了DSTCGCN，一种能够同时学习空间和时间依赖关系的动态空间-时间跨Graph卷积网络。具体来说，我们引入了基于快速傅立叶变换（FFT）的注意力选择器，可以根据时间变化的交通数据选择相关的时间步骤。给定选择的时间步骤，我们引入了动态跨 Graph 建构模块，包括空间 Graph 建构模块、时间连接 Graph 建构模块和融合模块，以无预先假设的方式学习动态空间-时间跨依赖关系。我们在六个真实世界数据集上进行了广泛的实验，结果显示DSTCGCN可以达到领先的性能。
</details></li>
</ul>
<hr>
<h2 id="SUGAR-Spherical-Ultrafast-Graph-Attention-Framework-for-Cortical-Surface-Registration"><a href="#SUGAR-Spherical-Ultrafast-Graph-Attention-Framework-for-Cortical-Surface-Registration" class="headerlink" title="SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical Surface Registration"></a>SUGAR: Spherical Ultrafast Graph Attention Framework for Cortical Surface Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00511">http://arxiv.org/abs/2307.00511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxun Ren, Ning An, Youjia Zhang, Danyang Wang, Zhenyu Sun, Cong Lin, Weigang Cui, Weiwei Wang, Ying Zhou, Wei Zhang, Qingyu Hu, Ping Zhang, Dan Hu, Danhong Wang, Hesheng Liu<br>for:SUGAR is designed to improve cortical surface registration, which is crucial for aligning cortical functional and anatomical features across individuals.methods:SUGAR is a deep-learning framework that incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation. It also includes a similarity loss, fold loss, and multiple distortion losses to preserve topology and minimize distortions.results:SUGAR achieves high registration performance and accelerated processing times, making it a promising solution for large-scale neuroimaging studies. It exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods, and processes data much faster than conventional methods.<details>
<summary>Abstract</summary>
Cortical surface registration plays a crucial role in aligning cortical functional and anatomical features across individuals. However, conventional registration algorithms are computationally inefficient. Recently, learning-based registration algorithms have emerged as a promising solution, significantly improving processing efficiency. Nonetheless, there remains a gap in the development of a learning-based method that exceeds the state-of-the-art conventional methods simultaneously in computational efficiency, registration accuracy, and distortion control, despite the theoretically greater representational capabilities of deep learning approaches. To address the challenge, we present SUGAR, a unified unsupervised deep-learning framework for both rigid and non-rigid registration. SUGAR incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation. In addition to the similarity loss, we introduce fold and multiple distortion losses, to preserve topology and minimize various types of distortions. Furthermore, we propose a data augmentation strategy specifically tailored for spherical surface registration, enhancing the registration performance. Through extensive evaluation involving over 10,000 scans from 7 diverse datasets, we showed that our framework exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods. Additionally, SUGAR achieves remarkable sub-second processing times, offering a notable speed-up of approximately 12,000 times in registering 9,000 subjects from the UK Biobank dataset in just 32 minutes. This combination of high registration performance and accelerated processing time may greatly benefit large-scale neuroimaging studies.
</details>
<details>
<summary>摘要</summary>
cortical surface registration 在调整 cortical functional 和 anatomical features 之间扮演着关键角色。然而，传统的 registration algorithm  computationally inefficient。 recent years, learning-based registration algorithm  emerged as a promising solution，significantly improving processing efficiency。然而，there remains a gap in the development of a learning-based method that exceeds the state-of-the-art conventional methods simultaneously in computational efficiency, registration accuracy, and distortion control，despite the theoretically greater representational capabilities of deep learning approaches。to address the challenge, we present SUGAR, a unified unsupervised deep-learning framework for both rigid and non-rigid registration。SUGAR incorporates a U-Net-based spherical graph attention network and leverages the Euler angle representation for deformation。 In addition to the similarity loss, we introduce fold and multiple distortion losses, to preserve topology and minimize various types of distortions。furthermore, we propose a data augmentation strategy specifically tailored for spherical surface registration, enhancing the registration performance。through extensive evaluation involving over 10,000 scans from 7 diverse datasets, we showed that our framework exhibits comparable or superior registration performance in accuracy, distortion, and test-retest reliability compared to conventional and learning-based methods。 additionally, SUGAR achieves remarkable sub-second processing times, offering a notable speed-up of approximately 12,000 times in registering 9,000 subjects from the UK Biobank dataset in just 32 minutes。this combination of high registration performance and accelerated processing time may greatly benefit large-scale neuroimaging studies。
</details></li>
</ul>
<hr>
<h2 id="HeGeL-A-Novel-Dataset-for-Geo-Location-from-Hebrew-Text"><a href="#HeGeL-A-Novel-Dataset-for-Geo-Location-from-Hebrew-Text" class="headerlink" title="HeGeL: A Novel Dataset for Geo-Location from Hebrew Text"></a>HeGeL: A Novel Dataset for Geo-Location from Hebrew Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00509">http://arxiv.org/abs/2307.00509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/onlplab/hegel">https://github.com/onlplab/hegel</a></li>
<li>paper_authors: Tzuf Paz-Argaman, Tal Bauman, Itai Mondshine, Itzhak Omer, Sagi Dalyot, Reut Tsarfaty</li>
<li>for: 这篇论文的目的是提出一个新的地理位置检索方法，以解决文本地理位置检索问题。</li>
<li>methods: 论文使用了人工勘探方法，收集了5649个直接描述希伯来地点的 literal Hebrew 描述。</li>
<li>results: 研究发现，这些描述中有许多具有地ospatial reasoning的语言表达，需要一种新的环境表示方式。<details>
<summary>Abstract</summary>
The task of textual geolocation - retrieving the coordinates of a place based on a free-form language description - calls for not only grounding but also natural language understanding and geospatial reasoning. Even though there are quite a few datasets in English used for geolocation, they are currently based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, such that the location retrieval resolution is limited. Furthermore, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.
</details>
<details>
<summary>摘要</summary>
文本地理位置 Retrieving the coordinates of a place based on a natural language description requires not only grounding but also natural language understanding and geospatial reasoning. Although there are several datasets in English for geolocation, they are based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, resulting in limited location retrieval resolution. Moreover, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.Here's the translation in Traditional Chinese:文本地理位置 Retrieving the coordinates of a place based on a natural language description requires not only grounding but also natural language understanding and geospatial reasoning. Although there are several datasets in English for geolocation, they are based on open-source data (Wikipedia and Twitter), where the location of the described place is mostly implicit, resulting in limited location retrieval resolution. Moreover, there are no datasets available for addressing the problem of textual geolocation in morphologically rich and resource-poor languages, such as Hebrew. In this paper, we present the Hebrew Geo-Location (HeGeL) corpus, designed to collect literal place descriptions and analyze lingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place descriptions of various place types in three cities in Israel. Qualitative and empirical analysis show that the data exhibits abundant use of geospatial reasoning and requires a novel environmental representation.
</details></li>
</ul>
<hr>
<h2 id="Cloud-Ensemble-Learning-for-Fault-Diagnosis-of-Rolling-Bearings-with-Stochastic-Configuration-Networks"><a href="#Cloud-Ensemble-Learning-for-Fault-Diagnosis-of-Rolling-Bearings-with-Stochastic-Configuration-Networks" class="headerlink" title="Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with Stochastic Configuration Networks"></a>Cloud Ensemble Learning for Fault Diagnosis of Rolling Bearings with Stochastic Configuration Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00507">http://arxiv.org/abs/2307.00507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Dai, Jiang Liu, Lanhao Wang</li>
<li>for:  rolling bearing fault diagnosis in few shot scenarios</li>
<li>methods: stochastic configuration network (SCN) based cloud ensemble learning</li>
<li>results: accurate fault diagnosis with few training samples<details>
<summary>Abstract</summary>
Fault diagnosis of rolling bearings is of great significance for post-maintenance in rotating machinery, but it is a challenging work to diagnose faults efficiently with a few samples. Additionally, faults commonly occur with randomness and fuzziness due to the complexity of the external environment and the structure of rolling bearings, hindering effective mining of fault characteristics and eventually restricting accuracy of fault diagnosis. To overcome these problems, stochastic configuration network (SCN) based cloud ensemble learning, called SCN-CEL, is developed in this work. Concretely, a cloud feature extraction method is first developed by using a backward cloud generator of normal cloud model to mine the uncertainty of fault information. Then, a cloud sampling method, which generates enough cloud droplets using bidirectional cloud generator, is proposed to extend the cloud feature samples. Finally, an ensemble model with SCNs is developed to comprehensively characterize the uncertainty of fault information and advance the generalization performance of fault diagnosis machine. Experimental results demonstrate that the proposed method indeed performs favorably for distinguishing fault categories of rolling bearings in the few shot scenarios.
</details>
<details>
<summary>摘要</summary>
FAULT诊断rolling bearing是后续维护机器人的重要 significace，但是efficiently fault diagnosis with few samples是一项挑战性的工作。另外，FAULTS通常occurs randomly and fuzzily due to the complexity of the external environment and the structure of rolling bearings, which hinders the effective mining of fault characteristics and eventually restricts the accuracy of fault diagnosis. To overcome these problems, this work proposes a stochastic configuration network (SCN) based cloud ensemble learning method, called SCN-CEL. Specifically, a cloud feature extraction method is first developed by using a backward cloud generator of normal cloud model to mine the uncertainty of fault information. Then, a cloud sampling method, which generates enough cloud droplets using bidirectional cloud generator, is proposed to extend the cloud feature samples. Finally, an ensemble model with SCNs is developed to comprehensively characterize the uncertainty of fault information and improve the generalization performance of fault diagnosis machine. Experimental results show that the proposed method can indeed distinguish fault categories of rolling bearings in the few shot scenarios.Here's the translation in Traditional Chinese as well:FAULT诊断rolling bearing是后续维护机器人的重要 significace，但是efficiently fault diagnosis with few samples是一项挑战性的工作。另外，FAULTS通常occurs randomly and fuzzily due to the complexity of the external environment and the structure of rolling bearings, which hinders the effective mining of fault characteristics and eventually restricts the accuracy of fault diagnosis. To overcome these problems, this work proposes a stochastic configuration network (SCN) based cloud ensemble learning method, called SCN-CEL. Specifically, a cloud feature extraction method is first developed by using a backward cloud generator of normal cloud model to mine the uncertainty of fault information. Then, a cloud sampling method, which generates enough cloud droplets using bidirectional cloud generator, is proposed to extend the cloud feature samples. Finally, an ensemble model with SCNs is developed to comprehensively characterize the uncertainty of fault information and improve the generalization performance of fault diagnosis machine. Experimental results show that the proposed method can indeed distinguish fault categories of rolling bearings in the few shot scenarios.
</details></li>
</ul>
<hr>
<h2 id="On-efficient-computation-in-active-inference"><a href="#On-efficient-computation-in-active-inference" class="headerlink" title="On efficient computation in active inference"></a>On efficient computation in active inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00504">http://arxiv.org/abs/2307.00504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aswinpaul/dpefe_2023">https://github.com/aswinpaul/dpefe_2023</a></li>
<li>paper_authors: Aswin Paul, Noor Sajid, Lancelot Da Costa, Adeel Razi</li>
<li>for: 提高 active inference 的计算效率和定义目标分布的准确性</li>
<li>methods: 提出两种解决方案，包括一种基于动态Programming的新规划算法和一种基于 Z-学习的目标分布设定方法</li>
<li>results: 在标准的grid-world任务中进行了模拟测试，并显示了这些方法的效果和可行性<details>
<summary>Abstract</summary>
Despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behaviour in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behaviour even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.
</details>
<details>
<summary>摘要</summary>
despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behavior in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behavior even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.Here is the word-for-word translation of the text into Simplified Chinese:尽管被认可为神经生物学上可能的，活动推理却在复杂环境中模拟智能行为时遇到了计算成本和设置合适目标分布的困难。这篇论文介绍了两种解决方案，它们在合作下解决了这些限制。首先，我们提出了一种新的规划算法，可以在有限时间Horizon上降低计算成本。其次，我们受控制理论文学中的Z学习启发，使得设置合适的目标分布变得更加简单。我们的第一个方法利用了动态计划算法，知名的计算效率高，来最小化计划中使用的成本函数。因此，我们的算法递归评估行动的预期自由能量，从反时间顺序进行评估。这会提高计算效率，并允许精确地学习和规划，即使在不确定的条件下。我们的方法简化了规划过程，并在指定只有代理人的最终目标状态时显示了意义的行为。我们的提案使得从目标分布定义变得更加直观，而不是在更复杂的时间 informed target distribution中进行定义。我们的方法的效果通过标准网格世界任务的模拟测试而证明。这些进步创造了新的应用机会。
</details></li>
</ul>
<hr>
<h2 id="Classifying-World-War-II-Era-Ciphers-with-Machine-Learning"><a href="#Classifying-World-War-II-Era-Ciphers-with-Machine-Learning" class="headerlink" title="Classifying World War II Era Ciphers with Machine Learning"></a>Classifying World War II Era Ciphers with Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00501">http://arxiv.org/abs/2307.00501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brooke Dalton, Mark Stamp</li>
<li>for: 研究使用机器学习和深度学习技术对世界二战时期密码的分类，只使用密码文本。</li>
<li>methods: 使用支持向量机（SVM）、k-最近邻（$k$-NN）和随机森林（RF）等三种经典机器学习模型，以及多层感知机（MLP）、长短期记忆（LSTM）、极限学习机（ELM）和卷积神经网络（CNN）等四种深度学习神经网络模型。</li>
<li>results: 对四种密码（恩igma、M-209、Sigaba、Purple和Typex）进行分类，使用不同的enario和不同长度的密码文本。结果显示，在最实际的scenario下，使用1000个字的密码文本，可以分类密码的准确率高于97%。此外，对一些学习技术的准确率进行分析，发现经典机器学习模型和深度学习模型在一些情况下表现相当。<details>
<summary>Abstract</summary>
We determine the accuracy with which machine learning and deep learning techniques can classify selected World War II era ciphers when only ciphertext is available. The specific ciphers considered are Enigma, M-209, Sigaba, Purple, and Typex. We experiment with three classic machine learning models, namely, Support Vector Machines (SVM), $k$-Nearest Neighbors ($k$-NN), and Random Forest (RF). We also experiment with four deep learning neural network-based models: Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM), Extreme Learning Machines (ELM), and Convolutional Neural Networks (CNN). Each model is trained on features consisting of histograms, digrams, and raw ciphertext letter sequences. Furthermore, the classification problem is considered under four distinct scenarios: Fixed plaintext with fixed keys, random plaintext with fixed keys, fixed plaintext with random keys, and random plaintext with random keys. Under the most realistic scenario, given 1000 characters per ciphertext, we are able to distinguish the ciphers with greater than 97% accuracy. In addition, we consider the accuracy of a subset of the learning techniques as a function of the length of the ciphertext messages. Somewhat surprisingly, our classic machine learning models perform at least as well as our deep learning models. We also find that ciphers that are more similar in design are somewhat more challenging to distinguish, but not as difficult as might be expected.
</details>
<details>
<summary>摘要</summary>
我们测试了机器学习和深度学习技术可以在只有密文available情况下准确地分类选择的World War II时期密码。我们考虑了Enigma、M-209、Sigaba、Purple和Typex等密码。我们尝试了三种经典机器学习模型，namely Support Vector Machines（SVM）、$k$-Nearest Neighbors（$k$-NN）和Random Forest（RF）。我们还尝试了四种深度学习神经网络模型：Multi-Layer Perceptrons（MLP）、Long Short-Term Memory（LSTM）、Extreme Learning Machines（ELM）和Convolutional Neural Networks（CNN）。每个模型都在 histograms、digram和密文字符序列中的特征上进行训练。此外，我们还考虑了密码分类问题在四种不同的enario下进行解决：固定的平文和固定的密钥、随机的平文和固定的密钥、固定的平文和随机的密钥、随机的平文和随机的密钥。在最真实的scenario下，给定1000个密文字符，我们能够分类密码的准确率高于97%。此外，我们还考虑了学习技术的准确率与密文字符数量之间的关系。 surprisingly，我们的经典机器学习模型在准确率上至少与深度学习模型相当。我们还发现，在设计上更相似的密码相对较难分类，但不如可能所想的那么难。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Quantization-via-Mixed-Precision-Compensation-without-Fine-Tuning"><a href="#Data-Free-Quantization-via-Mixed-Precision-Compensation-without-Fine-Tuning" class="headerlink" title="Data-Free Quantization via Mixed-Precision Compensation without Fine-Tuning"></a>Data-Free Quantization via Mixed-Precision Compensation without Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00498">http://arxiv.org/abs/2307.00498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Chen, Shipeng Bai, Tianxin Huang, Mengmeng Wang, Guanzhong Tian, Yong Liu</li>
<li>For: The paper aims to propose a data-free mixed-precision compensation (DF-MPC) method to recover the performance of an ultra-low precision quantized model without any data and fine-tuning process.* Methods: The proposed DF-MPC method assumes that the quantized error caused by a low-precision quantized layer can be restored via the reconstruction of a high-precision quantized layer, and minimizes the reconstruction loss of the feature maps to achieve the closed-form solution.* Results: The experimental results show that the proposed DF-MPC method is able to achieve higher accuracy for an ultra-low precision quantized model compared to the recent methods without any data and fine-tuning process.Here are the three key points in Simplified Chinese text:* For: 本文提出的目标是无数据、无调教的情况下提高低精度量化模型的性能。* Methods: 提议的DF-MPC方法假设低精度量化层引起的量化误差可以通过高精度量化层的重建来修复，并将重建loss作为目标函数来求解closed-form解决方案。* Results: 实验结果表明，提议的DF-MPC方法可以在无数据、无调教的情况下提高低精度量化模型的性能，相比之下最近的方法表现更好。<details>
<summary>Abstract</summary>
Neural network quantization is a very promising solution in the field of model compression, but its resulting accuracy highly depends on a training/fine-tuning process and requires the original data. This not only brings heavy computation and time costs but also is not conducive to privacy and sensitive information protection. Therefore, a few recent works are starting to focus on data-free quantization. However, data-free quantization does not perform well while dealing with ultra-low precision quantization. Although researchers utilize generative methods of synthetic data to address this problem partially, data synthesis needs to take a lot of computation and time. In this paper, we propose a data-free mixed-precision compensation (DF-MPC) method to recover the performance of an ultra-low precision quantized model without any data and fine-tuning process. By assuming the quantized error caused by a low-precision quantized layer can be restored via the reconstruction of a high-precision quantized layer, we mathematically formulate the reconstruction loss between the pre-trained full-precision model and its layer-wise mixed-precision quantized model. Based on our formulation, we theoretically deduce the closed-form solution by minimizing the reconstruction loss of the feature maps. Since DF-MPC does not require any original/synthetic data, it is a more efficient method to approximate the full-precision model. Experimentally, our DF-MPC is able to achieve higher accuracy for an ultra-low precision quantized model compared to the recent methods without any data and fine-tuning process.
</details>
<details>
<summary>摘要</summary>
神经网络量化是一个非常有前途的解决方案，可以大幅压缩模型，但是它的结果准确性高度取决于训练/精度调整过程，并且需要原始数据。这不仅带来了重大的计算成本和时间开销，而且不利于隐私和敏感信息保护。因此，一些最近的研究开始关注数据无关量化。然而，数据无关量化在处理超低精度量化时并不很好。尽管研究人员利用生成方法 Synthetic Data 来解决这个问题，但是数据生成需要大量计算和时间。在这篇论文中，我们提出了一种不需要数据的混合精度补偿方法（DF-MPC），可以无需任何数据和精度调整过程，使得模型的性能得到改进。我们假设low-precision量化层所导致的量化误差可以通过高精度量化层的重建来还原。我们将这种情况Mathematically formulated as a reconstruction loss between the pre-trained full-precision model and its layer-wise mixed-precision quantized model。基于我们的形式化，我们可以 theoretically deduce the closed-form solution by minimizing the reconstruction loss of the feature maps。由于 DF-MPC 不需要任何原始/生成的数据，因此它是一种更高效的方法来 aproximate the full-precision model。实验表明，我们的 DF-MPC 能够在无需数据和精度调整过程的情况下，对ultra-low precision量化模型进行更高的准确性改进。
</details></li>
</ul>
<hr>
<h2 id="Don’t-Memorize-Mimic-The-Past-Federated-Class-Incremental-Learning-Without-Episodic-Memory"><a href="#Don’t-Memorize-Mimic-The-Past-Federated-Class-Incremental-Learning-Without-Episodic-Memory" class="headerlink" title="Don’t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory"></a>Don’t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00497">http://arxiv.org/abs/2307.00497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Babakniya, Zalan Fabian, Chaoyang He, Mahdi Soltanolkotabi, Salman Avestimehr</li>
<li>for: 本文研究的目的是解决深度学习模型在新数据上学习时忘记过去学习的问题，特别在联合学习（Federated Learning，FL）中，数据是分散的，每个用户都可以独立地更改自己的数据。</li>
<li>methods: 本文提出了一个基于生成模型的联合学习类增量学习框架，通过生成样本从过去的分布中来避免忘记现象，而不需要将过去的数据存储在客户端上。服务器端使用数据无需方法在每个任务结束时训练生成模型，因此减少了数据泄露的风险。</li>
<li>results: 对于CIFAR-100 dataset，本文比对 existed 的基准值显示了显著的改进。<details>
<summary>Abstract</summary>
Deep learning models are prone to forgetting information learned in the past when trained on new data. This problem becomes even more pronounced in the context of federated learning (FL), where data is decentralized and subject to independent changes for each user. Continual Learning (CL) studies this so-called \textit{catastrophic forgetting} phenomenon primarily in centralized settings, where the learner has direct access to the complete training dataset. However, applying CL techniques to FL is not straightforward due to privacy concerns and resource limitations. This paper presents a framework for federated class incremental learning that utilizes a generative model to synthesize samples from past distributions instead of storing part of past data. Then, clients can leverage the generative model to mitigate catastrophic forgetting locally. The generative model is trained on the server using data-free methods at the end of each task without requesting data from clients. Therefore, it reduces the risk of data leakage as opposed to training it on the client's private data. We demonstrate significant improvements for the CIFAR-100 dataset compared to existing baselines.
</details>
<details>
<summary>摘要</summary>
深度学习模型容易忘记过去学习的信息，特别在 federated learning（FL）上，数据分散化和每个用户独立变化。 kontinual learning（CL）在中心化Setting中主要研究这种称为“极端忘记”现象，但是在隐私和资源限制的情况下应用CL技术到FL不是直接的。这篇文章介绍了一种基于生成模型的联邦分类逐步学习框架，可以在客户端使用生成模型来避免极端忘记。生成模型在服务器端使用数据free方法在每个任务结束时训练，因此减少了数据泄露的风险，与在客户端私有数据上训练生成模型不同。我们对 CIFAR-100 数据集进行了比较，与现有基eline相比，我们得到了显著的改进。
</details></li>
</ul>
<hr>
<h2 id="STG4Traffic-A-Survey-and-Benchmark-of-Spatial-Temporal-Graph-Neural-Networks-for-Traffic-Prediction"><a href="#STG4Traffic-A-Survey-and-Benchmark-of-Spatial-Temporal-Graph-Neural-Networks-for-Traffic-Prediction" class="headerlink" title="STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural Networks for Traffic Prediction"></a>STG4Traffic: A Survey and Benchmark of Spatial-Temporal Graph Neural Networks for Traffic Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00495">http://arxiv.org/abs/2307.00495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/trainingl/stg4traffic">https://github.com/trainingl/stg4traffic</a></li>
<li>paper_authors: Xunlian Luo, Chunjiang Zhu, Detian Zhang, Qing Li</li>
<li>for: 这个论文主要是为了提出一种基于图学习的实时交通预测方法，以提高智能城市系统的安全、稳定性和多样性。</li>
<li>methods: 这篇论文使用了图学习策略和常见的图卷积网络来模型交通系统的空间时间相关性。</li>
<li>results: 研究人员通过设计了一个标准化和可扩展的benchmark，并对两种交通数据集进行了比较性评估，发现这种方法可以提供更高的准确率和更好的可扩展性。Please note that the above text is in Simplified Chinese, and the format of the output is as you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;<details>
<summary>Abstract</summary>
Traffic prediction has been an active research topic in the domain of spatial-temporal data mining. Accurate real-time traffic prediction is essential to improve the safety, stability, and versatility of smart city systems, i.e., traffic control and optimal routing. The complex and highly dynamic spatial-temporal dependencies make effective predictions still face many challenges. Recent studies have shown that spatial-temporal graph neural networks exhibit great potential applied to traffic prediction, which combines sequential models with graph convolutional networks to jointly model temporal and spatial correlations. However, a survey study of graph learning, spatial-temporal graph models for traffic, as well as a fair comparison of baseline models are pending and unavoidable issues. In this paper, we first provide a systematic review of graph learning strategies and commonly used graph convolution algorithms. Then we conduct a comprehensive analysis of the strengths and weaknesses of recently proposed spatial-temporal graph network models. Furthermore, we build a study called STG4Traffic using the deep learning framework PyTorch to establish a standardized and scalable benchmark on two types of traffic datasets. We can evaluate their performance by personalizing the model settings with uniform metrics. Finally, we point out some problems in the current study and discuss future directions. Source codes are available at https://github.com/trainingl/STG4Traffic.
</details>
<details>
<summary>摘要</summary>
宽泛研究领域：预测交通流量是智能城市系统中的一个活跃研究话题。实时准确的交通预测可以提高智能城市系统的安全性、稳定性和多样性，如交通控制和优化Routing。距离Complex and highly dynamic spatial-temporal dependencies make effective predictions still face many challenges. Recent studies have shown that spatial-temporal graph neural networks exhibit great potential applied to traffic prediction, which combines sequential models with graph convolutional networks to jointly model temporal and spatial correlations. However, a survey study of graph learning, spatial-temporal graph models for traffic, as well as a fair comparison of baseline models are pending and unavoidable issues.在这篇论文中，我们首先提供了系统性的图学策略和通用的图 convolution 算法的评估。然后，我们进行了广泛的 spatial-temporal graph network 模型的分析，探讨其优劣点。其次，我们使用 PyTorch 深度学习框架建立了一个标准化和可扩展的 benchmark，并在两种交通数据集上进行了研究。通过个性化模型设置，我们可以评估其性能。最后，我们指出了当前研究中的一些问题，并讨论了未来的方向。源代码可以在 https://github.com/trainingl/STG4Traffic 上获取。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-protein-fitness-using-Gibbs-sampling-with-Graph-based-Smoothing"><a href="#Optimizing-protein-fitness-using-Gibbs-sampling-with-Graph-based-Smoothing" class="headerlink" title="Optimizing protein fitness using Gibbs sampling with Graph-based Smoothing"></a>Optimizing protein fitness using Gibbs sampling with Graph-based Smoothing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00494">http://arxiv.org/abs/2307.00494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kirjner/ggs">https://github.com/kirjner/ggs</a></li>
<li>paper_authors: Andrew Kirjner, Jason Yim, Raman Samusevich, Tommi Jaakkola, Regina Barzilay, Ila Fiete</li>
<li>for: 本研究旨在设计高适应性蛋白质，以满足医学多种领域的需求。</li>
<li>methods: 本文提出了 Gibbs sampling with Graph-based Smoothing（GGS）方法，可以有效地探索蛋白质设计空间。GGS方法通过 iteratively 应用 Gibbs 与梯度来提出有利变化，并使用图基的平滑来消除干扰梯度导致的假阳性。</li>
<li>results: 对 GFP 和 AAV 设计问题，以及简单的ablations 和基线，本文进行了研究，并得到了 state-of-the-art 的结果，能够找到高适应性蛋白质的Up to 8 个变化。<details>
<summary>Abstract</summary>
The ability to design novel proteins with higher fitness on a given task would be revolutionary for many fields of medicine. However, brute-force search through the combinatorially large space of sequences is infeasible. Prior methods constrain search to a small mutational radius from a reference sequence, but such heuristics drastically limit the design space. Our work seeks to remove the restriction on mutational distance while enabling efficient exploration. We propose Gibbs sampling with Graph-based Smoothing (GGS) which iteratively applies Gibbs with gradients to propose advantageous mutations using graph-based smoothing to remove noisy gradients that lead to false positives. Our method is state-of-the-art in discovering high-fitness proteins with up to 8 mutations from the training set. We study the GFP and AAV design problems, ablations, and baselines to elucidate the results. Code: https://github.com/kirjner/GGS
</details>
<details>
<summary>摘要</summary>
能够设计新的蛋白质，其适应能力更高，将对医学多个领域带来革命。然而，简单地通过枚举空间的搜索是不可能的。先前的方法受限于小距离的参照序列，但这些决策限制了设计空间。我们的工作是要 removes 这种距离限制，同时允许有效探索。我们提议使用 Gibbs 抽象法和图像缓和（GGS），每步应用 Gibbs 与梯度相结合，提出有利мутации，并使用图像缓和来消除干扰梯度，以避免干扰梯度导致的假阳性。我们的方法目前为止在使用训练集上达到高适应能力蛋白质的设计问题上占据了国际领先地位。我们在 GFP 和 AAV 设计问题、ablations 和基准值进行了研究，以便解释结果。代码可以在 GitHub 上找到：https://github.com/kirjner/GGS。
</details></li>
</ul>
<hr>
<h2 id="Fourier-Mixed-Window-Attention-Accelerating-Informer-for-Long-Sequence-Time-Series-Forecasting"><a href="#Fourier-Mixed-Window-Attention-Accelerating-Informer-for-Long-Sequence-Time-Series-Forecasting" class="headerlink" title="Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting"></a>Fourier-Mixed Window Attention: Accelerating Informer for Long Sequence Time-Series Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00493">http://arxiv.org/abs/2307.00493</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhatthanhtran/fwin2023">https://github.com/nhatthanhtran/fwin2023</a></li>
<li>paper_authors: Nhat Thanh Tran, Jack Xin</li>
<li>for: 用于加速长序列时间预测 Informer 的快本地全球窗口基于注意力方法。</li>
<li>methods: 使用本地窗口注意力，而不是假设查询稀疏性，并使用 fourier 变换块来补做全球token信息。</li>
<li>results: 通过在单变量和多变量 datasets 上进行实验，我们表明 FWin 变换器可以提高 Informer 的总预测精度，同时提高其推理速度，比如40-50%。此外，我们还在非线性回归模型中显示了一种学习 FWin 类型注意力的方法可以超过 softmax 全注意力。<details>
<summary>Abstract</summary>
We study a fast local-global window-based attention method to accelerate Informer for long sequence time-series forecasting. While window attention is local and a considerable computational saving, it lacks the ability to capture global token information which is compensated by a subsequent Fourier transform block. Our method, named FWin, does not rely on query sparsity hypothesis and an empirical approximation underlying the ProbSparse attention of Informer. Through experiments on univariate and multivariate datasets, we show that FWin transformers improve the overall prediction accuracies of Informer while accelerating its inference speeds by 40 to 50 %. We also show in a nonlinear regression model that a learned FWin type attention approaches or even outperforms softmax full attention based on key vectors extracted from an Informer model's full attention layer acting on time series data.
</details>
<details>
<summary>摘要</summary>
我们研究一种快速的本地-全局窗口基于注意方法，以加速Informer进行长序时间序列预测。虽然窗口注意是本地的，可以获得较大的计算时间 saving，但是它缺乏捕捉全局Token信息的能力，这是通过后续的傅里叶变换块补做。我们的方法，名为FWin，不依赖于查询稀缺假设和Informer中的ProbSparse注意力的经验近似。通过对单variate和多variate数据集进行实验，我们显示了FWin变换器可以提高Informer的总预测精度，同时加速其推理速度 by 40% to 50%. 我们还在非线性回归模型中表明，一种学习的FWin类型注意力可以与Softmax全注意力相当或者超过从Informer模型的全注意层中提取的键vector。
</details></li>
</ul>
<hr>
<h2 id="Pricing-European-Options-with-Google-AutoML-TensorFlow-and-XGBoost"><a href="#Pricing-European-Options-with-Google-AutoML-TensorFlow-and-XGBoost" class="headerlink" title="Pricing European Options with Google AutoML, TensorFlow, and XGBoost"></a>Pricing European Options with Google AutoML, TensorFlow, and XGBoost</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00476">http://arxiv.org/abs/2307.00476</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juan-esteban-berger/options_pricing_automl_tensorflow_xgboost">https://github.com/juan-esteban-berger/options_pricing_automl_tensorflow_xgboost</a></li>
<li>paper_authors: Juan Esteban Berger</li>
<li>for: 该文章用于比较使用Google Cloud AutoML Regressor、TensorFlow神经网络和XGBoost分类决策树来估算欧洲Option价格。</li>
<li>methods: 该文章使用了三种不同的机器学习算法来估算欧洲Option价格，即Google Cloud AutoML Regressor、TensorFlow神经网络和XGBoost分类决策树。</li>
<li>results: 三种模型都能够超越黑色熊模型，具体来说，使用历史数据来估算欧洲Option价格尤其有效，尤其是使用机器学习算法来学习复杂的模式，传统参数模型不能考虑。<details>
<summary>Abstract</summary>
Researchers have been using Neural Networks and other related machine-learning techniques to price options since the early 1990s. After three decades of improvements in machine learning techniques, computational processing power, cloud computing, and data availability, this paper is able to provide a comparison of using Google Cloud's AutoML Regressor, TensorFlow Neural Networks, and XGBoost Gradient Boosting Decision Trees for pricing European Options. All three types of models were able to outperform the Black Scholes Model in terms of mean absolute error. These results showcase the potential of using historical data from an option's underlying asset for pricing European options, especially when using machine learning algorithms that learn complex patterns that traditional parametric models do not take into account.
</details>
<details>
<summary>摘要</summary>
研究人员 desde 1990年代开始使用神经网络和相关的机器学习技术来估算选择价格。过去三十年来，机器学习技术、计算机处理能力、云计算和数据可用性得到了大幅提高。本文能够对使用Google Cloud的AutoML Regressor、TensorFlow神经网络和XGBoost分布gradient Boosting Decision Trees来估算欧洲选择价格进行比较。这三种类型的模型都能够超越黑卫星模型（Black Scholes Model）的mean absolute error。这些结果表明，使用选择物品的历史数据来估算欧洲选择价格，尤其是使用机器学习算法来学习复杂的模式，传统参数模型无法考虑。
</details></li>
</ul>
<hr>
<h2 id="Moments-Random-Walks-and-Limits-for-Spectrum-Approximation"><a href="#Moments-Random-Walks-and-Limits-for-Spectrum-Approximation" class="headerlink" title="Moments, Random Walks, and Limits for Spectrum Approximation"></a>Moments, Random Walks, and Limits for Spectrum Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00474">http://arxiv.org/abs/2307.00474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujia Jin, Christopher Musco, Aaron Sidford, Apoorv Vikram Singh</li>
<li>for: 本文研究一维分布近似问题中的下界问题，具体来说是对于已知多项式级别的一维分布，可以达到伪随机性水平。</li>
<li>methods: 本文使用了induced by eigenvalue spectra of carefully constructed graph adjacency matrices的hard instance，以及Cohen-Steiner et al. [KDD 2018]提供的spectral moments approximations using $2^{O(1&#x2F;\epsilon)}$ random walks initiated at uniformly random nodes in the graph。</li>
<li>results: 本文证明了一些分布在[-1,1]上不能够在Wasserstein-1 distance上准确地近似，即使知道所有多项式级别的分布。这个结果与Kong和Valiant [Annals of Statistics, 2017]的Upper bound相符。<details>
<summary>Abstract</summary>
We study lower bounds for the problem of approximating a one dimensional distribution given (noisy) measurements of its moments. We show that there are distributions on $[-1,1]$ that cannot be approximated to accuracy $\epsilon$ in Wasserstein-1 distance even if we know \emph{all} of their moments to multiplicative accuracy $(1\pm2^{-\Omega(1/\epsilon)})$; this result matches an upper bound of Kong and Valiant [Annals of Statistics, 2017]. To obtain our result, we provide a hard instance involving distributions induced by the eigenvalue spectra of carefully constructed graph adjacency matrices. Efficiently approximating such spectra in Wasserstein-1 distance is a well-studied algorithmic problem, and a recent result of Cohen-Steiner et al. [KDD 2018] gives a method based on accurately approximating spectral moments using $2^{O(1/\epsilon)}$ random walks initiated at uniformly random nodes in the graph.   As a strengthening of our main result, we show that improving the dependence on $1/\epsilon$ in this result would require a new algorithmic approach. Specifically, no algorithm can compute an $\epsilon$-accurate approximation to the spectrum of a normalized graph adjacency matrix with constant probability, even when given the transcript of $2^{\Omega(1/\epsilon)}$ random walks of length $2^{\Omega(1/\epsilon)}$ started at random nodes.
</details>
<details>
<summary>摘要</summary>
我们研究一维分布的下界，对于受到杂度的测量的矩形几何。我们证明有在[-1,1]上的分布，不能够在 Wasserstein-1 距离下对准确度 $\epsilon$ 的测量。这个结果与 Kong 和 Valiant 的上界相匹配 [Annals of Statistics, 2017]。我们使用具有精确的数值矩阵的对角线几何来提供一个困难的实例。现有一个由 Cohen-Steiner 等人提出的方法 [KDD 2018]，可以使用 $2^{O(1/\epsilon)}$ 步骤的随机步进行精确地测量几何的spectrum。作为我们主要结果的强化，我们证明 improvving 这个结果中的 $1/\epsilon$ 取决因数需要一个新的算法方法。具体来说，无法使用现有的算法，在 givent 矩阵的转换矩阵上 compute 一个 $\epsilon$-精确的测量，即使被给定 $2^{\Omega(1/\epsilon)}$ 步骤的随机步进行测量。
</details></li>
</ul>
<hr>
<h2 id="Equal-Confusion-Fairness-Measuring-Group-Based-Disparities-in-Automated-Decision-Systems"><a href="#Equal-Confusion-Fairness-Measuring-Group-Based-Disparities-in-Automated-Decision-Systems" class="headerlink" title="Equal Confusion Fairness: Measuring Group-Based Disparities in Automated Decision Systems"></a>Equal Confusion Fairness: Measuring Group-Based Disparities in Automated Decision Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00472">http://arxiv.org/abs/2307.00472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/furkangursoy/equalconfusion">https://github.com/furkangursoy/equalconfusion</a></li>
<li>paper_authors: Furkan Gursoy, Ioannis A. Kakadiaris</li>
<li>for:  This paper focuses on evaluating the fairness of automated decision systems, specifically in terms of group fairness.</li>
<li>methods: The paper proposes a new equal confusion fairness test and a new confusion parity error metric to measure unfairness, as well as an appropriate post hoc analysis methodology to identify the source of potential unfairness.</li>
<li>results: The proposed methods and metrics are demonstrated on the case of COMPAS, an automated decision system used in the US to assess recidivism risks, and show their usefulness in assessing fairness as part of a more extensive accountability assessment.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文关注自动决策系统的公平性评估，尤其是集体公平性。</li>
<li>methods: 该论文提出了一种新的平衡决策公平测试和一个新的决策错误度量表来衡量不公平，以及一种适当的后续分析方法来检测潜在的不公平源头。</li>
<li>results: 提议的方法和指标在使用COMPAS例子进行示例后显示了它们在评估自动决策系统公平性的用于更广泛的责任评估中的用用ifulness。<details>
<summary>Abstract</summary>
As artificial intelligence plays an increasingly substantial role in decisions affecting humans and society, the accountability of automated decision systems has been receiving increasing attention from researchers and practitioners. Fairness, which is concerned with eliminating unjust treatment and discrimination against individuals or sensitive groups, is a critical aspect of accountability. Yet, for evaluating fairness, there is a plethora of fairness metrics in the literature that employ different perspectives and assumptions that are often incompatible. This work focuses on group fairness. Most group fairness metrics desire a parity between selected statistics computed from confusion matrices belonging to different sensitive groups. Generalizing this intuition, this paper proposes a new equal confusion fairness test to check an automated decision system for fairness and a new confusion parity error to quantify the extent of any unfairness. To further analyze the source of potential unfairness, an appropriate post hoc analysis methodology is also presented. The usefulness of the test, metric, and post hoc analysis is demonstrated via a case study on the controversial case of COMPAS, an automated decision system employed in the US to assist judges with assessing recidivism risks. Overall, the methods and metrics provided here may assess automated decision systems' fairness as part of a more extensive accountability assessment, such as those based on the system accountability benchmark.
</details>
<details>
<summary>摘要</summary>
随着人工智能在影响人类和社会决策中的角色变得越来越重要，决策系统的负责任得到了更多的关注。公平是考虑消除不公正对待和歧视的一个关键方面，它是负责任的一部分。然而，为了评估公平，在文献中有很多不同的公平指标，这些指标常有不同的视角和假设，导致它们之间不兼容。这项工作将关注于群体公平。大多数群体公平指标寻求在不同敏感群体的决策系统中计算的混乱矩阵中实现平衡。总之，这篇论文提出了一种新的平衡公平测试，用于检测自动决策系统的公平，以及一种新的混乱平衡错误来衡量任何不公正。此外，为了分析潜在的不公正来源，我们还提供了一种适用的后续分析方法。这些方法和指标在一个关于 COMPAS 案例的案例研究中被证明了其用于评估自动决策系统的公平。总之，提供的方法和指标可以用于评估自动决策系统的公平，并作为更广泛的负责任评估的一部分，如基于系统负责任指标。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Probabilistic-Energy-Consumption-Estimation-for-Battery-Electric-Vehicles-with-Model-Uncertainty"><a href="#Data-Driven-Probabilistic-Energy-Consumption-Estimation-for-Battery-Electric-Vehicles-with-Model-Uncertainty" class="headerlink" title="Data-Driven Probabilistic Energy Consumption Estimation for Battery Electric Vehicles with Model Uncertainty"></a>Data-Driven Probabilistic Energy Consumption Estimation for Battery Electric Vehicles with Model Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00469">http://arxiv.org/abs/2307.00469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayan Maity, Sudeshna Sarkar</li>
<li>for: 这个论文是为了提出一种基于概率数据驱动的电动汽车（BEV）行程级能耗估计方法。</li>
<li>methods: 该方法使用概率神经网络，并通过 Монテ卡洛分布来确定模型uncertainty。</li>
<li>results: 实验结果表明，该方法可以准确地估计电动汽车行程级能耗，并且与其他现有的电动汽车能耗模型相比，具有较高的准确率。<details>
<summary>Abstract</summary>
This paper presents a novel probabilistic data-driven approach to trip-level energy consumption estimation of battery electric vehicles (BEVs). As there are very few electric vehicle (EV) charging stations, EV trip energy consumption estimation can make EV routing and charging planning easier for drivers. In this research article, we propose a new driver behaviour-centric EV energy consumption estimation model using probabilistic neural networks with model uncertainty. By incorporating model uncertainty into neural networks, we have created an ensemble of neural networks using Monte Carlo approximation. Our method comprehensively considers various vehicle dynamics, driver behaviour and environmental factors to estimate EV energy consumption for a given trip. We propose relative positive acceleration (RPA), average acceleration and average deceleration as driver behaviour factors in EV energy consumption estimation and this paper shows that the use of these driver behaviour features improves the accuracy of the EV energy consumption model significantly. Instead of predicting a single-point estimate for EV trip energy consumption, this proposed method predicts a probability distribution for the EV trip energy consumption. The experimental results of our approach show that our proposed probabilistic neural network with weight uncertainty achieves a mean absolute percentage error of 9.3% and outperforms other existing EV energy consumption models in terms of accuracy.
</details>
<details>
<summary>摘要</summary>
The proposed method uses probabilistic neural networks with model uncertainty to estimate EV energy consumption. By incorporating model uncertainty into neural networks, an ensemble of neural networks is created using Monte Carlo approximation. The method considers various vehicle dynamics, driver behavior, and environmental factors to estimate EV energy consumption for a given trip.The proposed method uses relative positive acceleration (RPA), average acceleration, and average deceleration as driver behavior factors in EV energy consumption estimation. The experimental results show that the proposed method outperforms other existing EV energy consumption models in terms of accuracy, with a mean absolute percentage error of 9.3%. Instead of predicting a single-point estimate for EV trip energy consumption, the proposed method predicts a probability distribution for the EV trip energy consumption.Here is the translation in Simplified Chinese:这篇论文提出了一种新的可能性推理数据驱动的方法来估算电动汽车（BEVs）的旅程级能 consumption。由于有很少的电动汽车充电站， точно估算电动汽车旅程能 consumption可以让驾驶员更容易进行电动汽车路径和充电规划。提议的方法使用可能性神经网络 WITH 模型不确定性来估算电动汽车的能 consumption。通过将模型不确定性引入神经网络中，我们创建了一个 ensemble of 神经网络 using Monte Carlo approximation。该方法广泛考虑了不同的汽车动力学、驾驶行为和环境因素，以估算电动汽车旅程能 consumption。提议的方法使用幂加速度（RPA）、均值加速度和均值减速度作为驾驶行为因素。实验结果表明，提议的方法在准确性方面超过了其他现有的电动汽车能 consumption模型， Mean Absolute Percentage Error 为9.3%。而不是预测单点的电动汽车旅程能 consumption，提议的方法预测了电动汽车旅程能 consumption的概率分布。
</details></li>
</ul>
<hr>
<h2 id="MissDiff-Training-Diffusion-Models-on-Tabular-Data-with-Missing-Values"><a href="#MissDiff-Training-Diffusion-Models-on-Tabular-Data-with-Missing-Values" class="headerlink" title="MissDiff: Training Diffusion Models on Tabular Data with Missing Values"></a>MissDiff: Training Diffusion Models on Tabular Data with Missing Values</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00467">http://arxiv.org/abs/2307.00467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yidong Ouyang, Liyan Xie, Chongxuan Li, Guang Cheng</li>
<li>for: 模型学习从数据中缺失值的数据分布，以便在各种实际应用中处理缺失数据。</li>
<li>methods: 提出了一种统一的涉及原理的扩展 diffusion 模型，可以在不同的缺失机制下学习数据分布。</li>
<li>results: 与 state-of-the-art  diffusion model 比较，在多个实际的 tabular 数据集上达到了较大的性能提升。<details>
<summary>Abstract</summary>
The diffusion model has shown remarkable performance in modeling data distributions and synthesizing data. However, the vanilla diffusion model requires complete or fully observed data for training. Incomplete data is a common issue in various real-world applications, including healthcare and finance, particularly when dealing with tabular datasets. This work presents a unified and principled diffusion-based framework for learning from data with missing values under various missing mechanisms. We first observe that the widely adopted "impute-then-generate" pipeline may lead to a biased learning objective. Then we propose to mask the regression loss of Denoising Score Matching in the training phase. We prove the proposed method is consistent in learning the score of data distributions, and the proposed training objective serves as an upper bound for the negative likelihood in certain cases. The proposed framework is evaluated on multiple tabular datasets using realistic and efficacious metrics and is demonstrated to outperform state-of-the-art diffusion model on tabular data with "impute-then-generate" pipeline by a large margin.
</details>
<details>
<summary>摘要</summary>
diffusion 模型在数据分布模型和数据合成方面表现出色，但是普通的扩散模型需要完整或完全观察到的数据进行训练。实际应用中，包括医疗和金融等领域，数据中存在缺失数据是一个常见的问题。这项工作提出了一种统一的、原则正的扩散模型基于缺失数据学习框架，用于处理不同的缺失机制。我们首先发现，通过"填充然后生成"管道可能会导致偏向的学习目标。然后，我们提议在训练阶段对杜邦Score匹配的损失进行遮盖。我们证明了我们提议的方法是学习数据分布的分数的一种一致的方法，并且我们提议的训练目标为certain cases中的负概率下界。我们的框架在多个实际的 tabular 数据集上进行了实际和有效的评估，并与state-of-the-art扩散模型在 tabular 数据上"填充然后生成"管道的比较中表现出了大幅度的超越。
</details></li>
</ul>
<hr>
<h2 id="Towards-Unbiased-Exploration-in-Partial-Label-Learning"><a href="#Towards-Unbiased-Exploration-in-Partial-Label-Learning" class="headerlink" title="Towards Unbiased Exploration in Partial Label Learning"></a>Towards Unbiased Exploration in Partial Label Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00465">http://arxiv.org/abs/2307.00465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zsolt Zombori, Agapi Rissaki, Kristóf Szabó, Wolfgang Gatterbauer, Michael Benedikt</li>
<li>for: 这篇论文是用于描述一种基于半标注的学习方法，该方法可以在标准神经网络架构中使用softmax层进行推理，并且可以减轻softmax层中的偏见现象，以便更好地探索多个可能性。</li>
<li>methods: 这篇论文使用了一种新的损失函数，该损失函数可以减轻softmax层中的偏见现象，并且可以在标准神经网络架构中进行不偏的探索。</li>
<li>results: 论文通过对синтетиче数据、标准半标注benchmark和一个新的规则学习挑战中的数据进行广泛的评估，证明了该损失函数的有效性。<details>
<summary>Abstract</summary>
We consider learning a probabilistic classifier from partially-labelled supervision (inputs denoted with multiple possibilities) using standard neural architectures with a softmax as the final layer. We identify a bias phenomenon that can arise from the softmax layer in even simple architectures that prevents proper exploration of alternative options, making the dynamics of gradient descent overly sensitive to initialisation. We introduce a novel loss function that allows for unbiased exploration within the space of alternative outputs. We give a theoretical justification for our loss function, and provide an extensive evaluation of its impact on synthetic data, on standard partially labelled benchmarks and on a contributed novel benchmark related to an existing rule learning challenge.
</details>
<details>
<summary>摘要</summary>
我们考虑从受限的指导下学习一个概率分类器，使用标准的神经网络架构，并在最终层使用softmax层。我们发现在简单的架构中，softmax层可能会带来偏袋现象，使得梯度下降的几何对初始化的敏感性。我们介绍了一个新的损失函数，允许不偏的探索多个出力空间中的选项。我们提供了理论上的说明，并对实验数据、标准受限 benchmark和一个新的规则学习挑战中的贡献 benchmark进行了广泛的评估。
</details></li>
</ul>
<hr>
<h2 id="FedDefender-Backdoor-Attack-Defense-in-Federated-Learning"><a href="#FedDefender-Backdoor-Attack-Defense-in-Federated-Learning" class="headerlink" title="FedDefender: Backdoor Attack Defense in Federated Learning"></a>FedDefender: Backdoor Attack Defense in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08672">http://arxiv.org/abs/2307.08672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/warisgill/FedDefender">https://github.com/warisgill/FedDefender</a></li>
<li>paper_authors: Waris Gill, Ali Anwar, Muhammad Ali Gulzar</li>
<li>for: 防止targeted poisoning攻击在 Federated Learning (FL) 中</li>
<li>methods: 利用差异测试方法来识别可疑客户端（包含后门）</li>
<li>results: 在 MNIST 和 FashionMNIST 数据集上，FedDefender 有效地 mitigates 攻击，从而降低攻击成功率至 10%，无需对全球模型性能产生负面影响。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\% without deteriorating the global model performance.
</details>
<details>
<summary>摘要</summary>
federated 学习（FL）是一种隐私保护的分布式机器学习技术，允许个体客户端（例如用户参与者、边缘设备或组织）在安全环境中使用本地数据进行模型训练，然后将训练好的模型分享给汇总器以建立全球模型。在这项工作中，我们提议了 FedDefender，一种针对攻击型投毒攻击的防御机制，通过对客户端模型的神经元活动进行差异测试来识别可能有恶意后门的客户端。我们使用 MNIST 和 FashionMNIST 数据集，并与 20 和 30 个客户端进行评估，结果表明，FedDefender 有效地防止了这类攻击，攻击成功率降低至 10%，而全球模型性能不受影响。
</details></li>
</ul>
<hr>
<h2 id="Conformer-LLMs-–-Convolution-Augmented-Large-Language-Models"><a href="#Conformer-LLMs-–-Convolution-Augmented-Large-Language-Models" class="headerlink" title="Conformer LLMs – Convolution Augmented Large Language Models"></a>Conformer LLMs – Convolution Augmented Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00461">http://arxiv.org/abs/2307.00461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Verma</li>
<li>for: 这个研究旨在将两种受欢迎的神经架构combined，即卷积层和Transformers，以应用于大型语言模型（LLMs）。</li>
<li>methods: 这个研究使用了非 causal 的卷积层，并将它们应用于 causal 的训练架构中。transformers decoder 优化了跨多modalities的长距离依赖，并成为现代机器学习的核心进步。</li>
<li>results: 这个研究获得了显著的性能提升，并显示了一个可靠的语音架构，可以在 causal 设置中进行集成和适应。<details>
<summary>Abstract</summary>
This work builds together two popular blocks of neural architecture, namely convolutional layers and Transformers, for large language models (LLMs). Non-causal conformers are used ubiquitously in automatic speech recognition. This work aims to adapt these architectures in a causal setup for training LLMs. Transformers decoders effectively capture long-range dependencies over several modalities and form a core backbone of modern advancements in machine learning. Convolutional architectures have been popular in extracting features in domains such as raw 1-D signals, speech, and images, to name a few. In this paper, by combining local and global dependencies over latent representations using causal convolutional filters and Transformer, we achieve significant gains in performance. This work showcases a robust speech architecture that can be integrated and adapted in a causal setup beyond speech applications for large-scale language modeling.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GenRec-Large-Language-Model-for-Generative-Recommendation"><a href="#GenRec-Large-Language-Model-for-Generative-Recommendation" class="headerlink" title="GenRec: Large Language Model for Generative Recommendation"></a>GenRec: Large Language Model for Generative Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00457">http://arxiv.org/abs/2307.00457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rutgerswiselab/genrec">https://github.com/rutgerswiselab/genrec</a></li>
<li>paper_authors: Jianchao Ji, Zelong Li, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Juntao Tan, Yongfeng Zhang</li>
<li>For: This paper presents a novel approach to recommendation systems using large language models (LLMs) based on text data, which can directly generate the target item to recommend rather than calculating ranking scores for each candidate item.* Methods: The proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks, and uses specialized prompts to enhance the ability of LLM to comprehend recommendation tasks.* Results: The proposed GenRec approach has significant better results on large datasets, and the experiments show the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems.Here’s the summary in Chinese:* 用这篇论文，我们提出了一种基于文本数据的推荐系统方法，可以直接生成目标项目的推荐，而不需要计算每个候选项目的排名分数。* 我们的方法利用大型自然语言模型（LLM）的优秀表现能力，实现推荐任务。我们使用特殊的提示来增强LLM的理解能力，以便更好地理解用户喜好和项目特性。* 我们的实验结果显示，我们的GenRec方法在大型数据集上有很好的表现，并证明了LLM基于生成推荐的潜在力量。<details>
<summary>Abstract</summary>
In recent years, large language models (LLM) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommendation systems using large language models (LLMs) based on text data. In this paper, we present a novel LLM for generative recommendation (GenRec) that utilized the expressive power of LLM to directly generate the target item to recommend, rather than calculating ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendation. Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first we formulate specialized prompts to enhance the ability of LLM to comprehend recommendation tasks. Subsequently, we use these prompts to fine-tune the LLaMA backbone LLM on a dataset of user-item interactions, represented by textual data, to capture user preferences and item characteristics. Our research underscores the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems and offers a foundational framework for future explorations in this field. We conduct extensive experiments on benchmark datasets, and the experiments shows that our GenRec has significant better results on large dataset.
</details>
<details>
<summary>摘要</summary>
We first formulate specialized prompts to enhance the ability of LLM to comprehend recommendation tasks. Then, we use these prompts to fine-tune the LLaMA backbone LLM on a dataset of user-item interactions, represented by textual data, to capture user preferences and item characteristics. Our research highlights the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems and provides a foundational framework for future explorations in this field. We conduct extensive experiments on benchmark datasets, and the results show that our GenRec method has significantly better performance on large datasets.
</details></li>
</ul>
<hr>
<h2 id="3D-IDS-Doubly-Disentangled-Dynamic-Intrusion-Detection"><a href="#3D-IDS-Doubly-Disentangled-Dynamic-Intrusion-Detection" class="headerlink" title="3D-IDS: Doubly Disentangled Dynamic Intrusion Detection"></a>3D-IDS: Doubly Disentangled Dynamic Intrusion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11079">http://arxiv.org/abs/2307.11079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyang Qiu, Yingsheng Geng, Junrui Lu, Kaida Chen, Shitong Zhu, Ya Su, Guoshun Nan, Can Zhang, Junsong Fu, Qimei Cui, Xiaofeng Tao</li>
<li>for: 提高网络入侵检测系统（NIDS）的检测精度和可解释性，帮助旁减不良攻击对信息基础设施的威胁。</li>
<li>methods: 提出了一种基于两步特征分解和动态图diffusion算法的新方法（3D-IDS），通过自动对复杂的攻击特征进行非参数化优化，生成攻击特征表示，并使用动态图diffusion方法进行空间时间聚合，有效地识别多种攻击，包括未知威胁和已知威胁。</li>
<li>results: 实验表明，3D-IDS可以有效地识别多种攻击，包括未知威胁和已知威胁，并且比现有方法更高的检测精度和可解释性。<details>
<summary>Abstract</summary>
Network-based intrusion detection system (NIDS) monitors network traffic for malicious activities, forming the frontline defense against increasing attacks over information infrastructures. Although promising, our quantitative analysis shows that existing methods perform inconsistently in declaring various unknown attacks (e.g., 9% and 35% F1 respectively for two distinct unknown threats for an SVM-based method) or detecting diverse known attacks (e.g., 31% F1 for the Backdoor and 93% F1 for DDoS by a GCN-based state-of-the-art method), and reveals that the underlying cause is entangled distributions of flow features. This motivates us to propose 3D-IDS, a novel method that aims to tackle the above issues through two-step feature disentanglements and a dynamic graph diffusion scheme. Specifically, we first disentangle traffic features by a non-parameterized optimization based on mutual information, automatically differentiating tens and hundreds of complex features of various attacks. Such differentiated features will be fed into a memory model to generate representations, which are further disentangled to highlight the attack-specific features. Finally, we use a novel graph diffusion method that dynamically fuses the network topology for spatial-temporal aggregation in evolving data streams. By doing so, we can effectively identify various attacks in encrypted traffics, including unknown threats and known ones that are not easily detected. Experiments show the superiority of our 3D-IDS. We also demonstrate that our two-step feature disentanglements benefit the explainability of NIDS.
</details>
<details>
<summary>摘要</summary>
To address these issues, we propose 3D-IDS, a novel method that utilizes two-step feature disentanglement and a dynamic graph diffusion scheme. First, we disentangle traffic features using a non-parameterized optimization based on mutual information, automatically differentiating tens and hundreds of complex features of various attacks. These differentiated features are then fed into a memory model to generate representations, which are further disentangled to highlight attack-specific features. Finally, we use a novel graph diffusion method that dynamically fuses the network topology for spatial-temporal aggregation in evolving data streams. This enables effective identification of various attacks in encrypted traffics, including unknown threats and known ones that are not easily detected.Experiments show the superiority of our 3D-IDS. Additionally, we demonstrate that our two-step feature disentanglements improve the explainability of NIDS.
</details></li>
</ul>
<hr>
<h2 id="An-Adaptive-Optimization-Approach-to-Personalized-Financial-Incentives-in-Mobile-Behavioral-Weight-Loss-Interventions"><a href="#An-Adaptive-Optimization-Approach-to-Personalized-Financial-Incentives-in-Mobile-Behavioral-Weight-Loss-Interventions" class="headerlink" title="An Adaptive Optimization Approach to Personalized Financial Incentives in Mobile Behavioral Weight Loss Interventions"></a>An Adaptive Optimization Approach to Personalized Financial Incentives in Mobile Behavioral Weight Loss Interventions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00444">http://arxiv.org/abs/2307.00444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiaomei Li, Kara L. Gavin, Corrine I. Voils, Yonatan Mintz</li>
<li>for: 本研究旨在设计个性化的营养干预，使用直接金钱奖励来鼓励身高减轻，同时保持在研究预算内。</li>
<li>methods: 本研究使用机器学习方法预测参与者如何响应不同奖励计划，并在Behavioral 干预中使用这些预测来定制奖励。</li>
<li>results: 研究结果表明，个性化奖励设计可以提高营养干预的效果和经济性。<details>
<summary>Abstract</summary>
Obesity is a critical healthcare issue affecting the United States. The least risky treatments available for obesity are behavioral interventions meant to promote diet and exercise. Often these interventions contain a mobile component that allows interventionists to collect participants level data and provide participants with incentives and goals to promote long term behavioral change. Recently, there has been interest in using direct financial incentives to promote behavior change. However, adherence is challenging in these interventions, as each participant will react differently to different incentive structure and amounts, leading researchers to consider personalized interventions. The key challenge for personalization, is that the clinicians do not know a priori how best to administer incentives to participants, and given finite intervention budgets how to disburse costly resources efficiently. In this paper, we consider this challenge of designing personalized weight loss interventions that use direct financial incentives to motivate weight loss while remaining within a budget. We create a machine learning approach that is able to predict how individuals may react to different incentive schedules within the context of a behavioral intervention. We use this predictive model in an adaptive framework that over the course of the intervention computes what incentives to disburse to participants and remain within the study budget. We provide both theoretical guarantees for our modeling and optimization approaches as well as demonstrate their performance in a simulated weight loss study. Our results highlight the cost efficiency and effectiveness of our personalized intervention design for weight loss.
</details>
<details>
<summary>摘要</summary>
肥胖是美国医疗系统中的一个严重问题。最安全有效的肥胖治疗方法是行为改变方法，包括提倡饮食和运动。这些方法经常包括移动组件，允许 interveners 收集参与者的数据并为参与者提供激励和目标，以促进长期行为变化。在最近，有兴趣使用直接金钱激励来促进行为变化。然而，遵循性困难，因为每个参与者都会不同地对不同的激励结构和金额响应不同。这导致研究人员考虑个性化 intervención。个性化挑战是，临床医生不知道在先知道如何向参与者分配激励，以及如何有效地分配有限的投资资源。在这篇论文中，我们考虑这个个性化肥胖损重优化问题。我们开发了一种机器学习方法，可以预测参与者如何响应不同的激励计划。我们使用这个预测模型，在行为改变方法中进行adaptive框架，在训练期间计算怎样分配激励，以保持在研究预算内。我们提供了理论保证和优化方法的实践表现，并在模拟的肥胖损重研究中证明了我们的个性化 intervención的成本效果。我们的结果表明，我们的个性化 intervención设计可以有效地促进肥胖损重。
</details></li>
</ul>
<hr>
<h2 id="One-Copy-Is-All-You-Need-Resource-Efficient-Streaming-of-Medical-Imaging-Data-at-Scale"><a href="#One-Copy-Is-All-You-Need-Resource-Efficient-Streaming-of-Medical-Imaging-Data-at-Scale" class="headerlink" title="One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale"></a>One Copy Is All You Need: Resource-Efficient Streaming of Medical Imaging Data at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00438">http://arxiv.org/abs/2307.00438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/um2ii/openjphpy">https://github.com/um2ii/openjphpy</a></li>
<li>paper_authors: Pranav Kulkarni, Adway Kanhere, Eliot Siegel, Paul H. Yi, Vishwa S. Parekh</li>
<li>for: 这篇论文是为了解决医疗影像数据集大量化问题，并且提高人工智能工具的开发速度。</li>
<li>methods: 这篇论文使用了一个开源框架called MIST，实现了进度分辨率的运算过程，允许用户在不同的分辨率下载取医疗影像。</li>
<li>results: 这篇论文的结果显示，使用MIST可以将医疗影像集中存储和流式处理的设备不足问题降低&gt;90%，并且维持深度学习应用中的诊断质量。<details>
<summary>Abstract</summary>
Large-scale medical imaging datasets have accelerated development of artificial intelligence tools for clinical decision support. However, the large size of these datasets is a bottleneck for users with limited storage and bandwidth. Many users may not even require such large datasets as AI models are often trained on lower resolution images. If users could directly download at their desired resolution, storage and bandwidth requirements would significantly decrease. However, it is impossible to anticipate every users' requirements and impractical to store the data at multiple resolutions. What if we could store images at a single resolution but send them at different ones? We propose MIST, an open-source framework to operationalize progressive resolution for streaming medical images at multiple resolutions from a single high-resolution copy. We demonstrate that MIST can dramatically reduce imaging infrastructure inefficiencies for hosting and streaming medical images by >90%, while maintaining diagnostic quality for deep learning applications.
</details>
<details>
<summary>摘要</summary>
大规模医疗影像数据集的扩大已经推动了人工智能工具的临床决策支持发展。然而，这些大规模数据集的大小成为了用户储存和带宽限制的瓶颈。许多用户可能不需要这样大的数据集，因为人工智能模型通常是在更低的分辨率图像上训练的。如果用户可以直接下载他们所需的分辨率，储存和带宽需求将会减少很多。然而，预测每个用户的需求是不可能的，并且存储数据在多个分辨率下是不实用的。我们提出了MIST框架，一个开源的框架，用于实现进行式分辨率的流动医疗影像。我们示示了MIST可以减少医疗影像基础设施的不fficient的使用>90%，而且保持深度学习应用的诊断质量。
</details></li>
</ul>
<hr>
<h2 id="Data-Driven-Design-for-Metamaterials-and-Multiscale-Systems-A-Review"><a href="#Data-Driven-Design-for-Metamaterials-and-Multiscale-Systems-A-Review" class="headerlink" title="Data-Driven Design for Metamaterials and Multiscale Systems: A Review"></a>Data-Driven Design for Metamaterials and Multiscale Systems: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.05506">http://arxiv.org/abs/2307.05506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doksoo Lee, Wei Wayne Chen, Liwei Wang, Yu-Chin Chan, Wei Chen</li>
<li>for: 这篇论文旨在探讨数据驱动设计方法在Meta材料设计中的潜力。</li>
<li>methods: 该论文使用数据收集、机器学习基于单元细胞设计和数据驱动多尺度优化等方法来实现数据驱动设计。</li>
<li>results: 论文提出了一种束缚数据驱动设计的总体方法，并将现有研究分为数据驱动模块，包括数据收集、机器学习基于单元细胞设计和数据驱动多尺度优化等方法。<details>
<summary>Abstract</summary>
Metamaterials are artificial materials designed to exhibit effective material parameters that go beyond those found in nature. Composed of unit cells with rich designability that are assembled into multiscale systems, they hold great promise for realizing next-generation devices with exceptional, often exotic, functionalities. However, the vast design space and intricate structure-property relationships pose significant challenges in their design. A compelling paradigm that could bring the full potential of metamaterials to fruition is emerging: data-driven design. In this review, we provide a holistic overview of this rapidly evolving field, emphasizing the general methodology instead of specific domains and deployment contexts. We organize existing research into data-driven modules, encompassing data acquisition, machine learning-based unit cell design, and data-driven multiscale optimization. We further categorize the approaches within each module based on shared principles, analyze and compare strengths and applicability, explore connections between different modules, and identify open research questions and opportunities.
</details>
<details>
<summary>摘要</summary>
美特材料是人造材料，旨在实现自然界之外的效果。它们由单元细胞组合而成，单元细胞具有丰富的设计性，可以组成多尺度系统。这些材料具有极高的潜在功能，但是设计困难重大，因为设计空间庞大，结构-性能关系复杂。一种吸引人的思想是数据驱动设计，这种思想在这篇文章中得到了详细的介绍。我们将现有的研究分为三个数据驱动模块：数据收集、机器学习基于单元细胞设计和数据驱动多尺度优化。每个模块都包含不同的方法，我们根据共同原则分类和分析它们。我们还探讨了不同模块之间的连接，并评估了各模块的优劣和适用范围。最后，我们还提出了一些未解决的研究问题和机遇。
</details></li>
</ul>
<hr>
<h2 id="Sparsity-aware-generalization-theory-for-deep-neural-networks"><a href="#Sparsity-aware-generalization-theory-for-deep-neural-networks" class="headerlink" title="Sparsity-aware generalization theory for deep neural networks"></a>Sparsity-aware generalization theory for deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00426">http://arxiv.org/abs/2307.00426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ramchandran Muthukumar, Jeremias Sulam</li>
<li>for: 本研究旨在探讨深度人工神经网络的泛化能力，并提出一种新的分析方法来解释这种泛化能力。</li>
<li>methods: 本研究使用了深度循环神经网络，并开发了一种基于隐藏层活动的度量方法来衡量模型的泛化能力。</li>
<li>results: 研究发现，隐藏层活动的度量可以用于衡量模型的泛化能力，并且可以提供非虚假的下界，即使模型具有较高的参数数量。<details>
<summary>Abstract</summary>
Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors in specific settings, even in over-parametrized models.
</details>
<details>
<summary>摘要</summary>
深度人工神经网络实现了奇异的泛化能力，这些能力尚未得到充分理解。在这篇论文中，我们提出了一种新的分析泛化方法，利用隐藏层活动的稀畴程度来考虑。我们开发了一个考虑这个减少的有效模型大小的框架，以便为每个输入样本表示基准。我们可以显示泛化和稀畴之间存在基本的负面关系，这些结果不假设模型达到了哪个水平的稀畴程度。我们的结果超过了最近的 нор-based方法。我们通过数值计算示出了非虚无关的下界，即使在过参数化模型中。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Algorithms-for-Relaxed-Pareto-Set-Identification"><a href="#Adaptive-Algorithms-for-Relaxed-Pareto-Set-Identification" class="headerlink" title="Adaptive Algorithms for Relaxed Pareto Set Identification"></a>Adaptive Algorithms for Relaxed Pareto Set Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00424">http://arxiv.org/abs/2307.00424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrille Kone, Emilie Kaufmann, Laura Richert</li>
<li>for: 本文研究了一种多目标多枪支牛津模型中的固定信任性识别Pareto优点集的问题。由于确定精确的Pareto集可能需要很大的样本量，因此研究了一种允许输出一些近似优点枪支的放松。此外，本文还研究了其他放松方法，允许Identify一个相关的Pareto集子集。</li>
<li>methods: 本文提出了一种单一的抽样策略，called Adaptive Pareto Exploration，可以与不同的停止规则结合使用，以满足不同的放松。本文还分析了不同组合的抽样复杂度，特别是在寻找最多$k$ Pareto优点枪支时的减少样本复杂度。</li>
<li>results: 本文在一个实际应用中展示了Adaptive Pareto Exploration的良好实践性，在考虑多个免疫力标准时选择 Covid-19 疫苗策略的问题上。<details>
<summary>Abstract</summary>
In this paper we revisit the fixed-confidence identification of the Pareto optimal set in a multi-objective multi-armed bandit model. As the sample complexity to identify the exact Pareto set can be very large, a relaxation allowing to output some additional near-optimal arms has been studied. In this work we also tackle alternative relaxations that allow instead to identify a relevant subset of the Pareto set. Notably, we propose a single sampling strategy, called Adaptive Pareto Exploration, that can be used in conjunction with different stopping rules to take into account different relaxations of the Pareto Set Identification problem. We analyze the sample complexity of these different combinations, quantifying in particular the reduction in sample complexity that occurs when one seeks to identify at most $k$ Pareto optimal arms. We showcase the good practical performance of Adaptive Pareto Exploration on a real-world scenario, in which we adaptively explore several vaccination strategies against Covid-19 in order to find the optimal ones when multiple immunogenicity criteria are taken into account.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们重新审视了多目标多机枪猎猎人模型中固定信心的标准化集的预测。由于样本复杂度来确定精确的Pareto集可以非常大，因此有关输出一些附加的近似优致的机枪的放弃措施的研究。在这种工作中，我们也研究了不同的放弃措施，允许在Pareto集标准化问题中确定一个相关的子集。特别是，我们提出了一种单一的采样策略，called Adaptive Pareto Exploration，可以与不同的停止规则结合使用，以便在不同的放弃措施中考虑不同的Pareto集标准化问题。我们分析了不同组合的样本复杂度，特别是在寻找最多$k$ Pareto优致机枪时的样本复杂度减少。我们还展示了Adaptive Pareto Exploration在一个实际场景中的良好实践性，在多种immunogenicity标准下对covid-19疫苗的适应性进行了可控的探索。
</details></li>
</ul>
<hr>
<h2 id="JoinBoost-Grow-Trees-Over-Normalized-Data-Using-Only-SQL"><a href="#JoinBoost-Grow-Trees-Over-Normalized-Data-Using-Only-SQL" class="headerlink" title="JoinBoost: Grow Trees Over Normalized Data Using Only SQL"></a>JoinBoost: Grow Trees Over Normalized Data Using Only SQL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00422">http://arxiv.org/abs/2307.00422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zezhou Huang, Rathijit Sen, Jiaxiang Liu, Eugene Wu</li>
<li>for: 这种论文的目的是提出一种基于 SQL 的内存中 ML 系统，以避免数据移动和提供数据管理。</li>
<li>methods: 这种系统使用了纯 SQL 语句来训练树型模型，并且可以在任何 DBMS 上运行。</li>
<li>results: 实验表明，JoinBoost 比特有限的 LightGBM 快三倍（1.1倍），并且与现有的内存中 ML 系统相比，速度超过一个数量级。此外，JoinBoost 可以跨越 LightGBM 的特点，包括特性数、数据库大小和Join图复杂度。<details>
<summary>Abstract</summary>
Although dominant for tabular data, ML libraries that train tree models over normalized databases (e.g., LightGBM, XGBoost) require the data to be denormalized as a single table, materialized, and exported. This process is not scalable, slow, and poses security risks. In-DB ML aims to train models within DBMSes to avoid data movement and provide data governance. Rather than modify a DBMS to support In-DB ML, is it possible to offer competitive tree training performance to specialized ML libraries...with only SQL?   We present JoinBoost, a Python library that rewrites tree training algorithms over normalized databases into pure SQL. It is portable to any DBMS, offers performance competitive with specialized ML libraries, and scales with the underlying DBMS capabilities. JoinBoost extends prior work from both algorithmic and systems perspectives. Algorithmically, we support factorized gradient boosting, by updating the $Y$ variable to the residual in the non-materialized join result. Although this view update problem is generally ambiguous, we identify addition-to-multiplication preserving, the key property of variance semi-ring to support rmse, the most widely used criterion. System-wise, we identify residual updates as a performance bottleneck. Such overhead can be natively minimized on columnar DBMSes by creating a new column of residual values and adding it as a projection. We validate this with two implementations on DuckDB, with no or minimal modifications to its internals for portability. Our experiment shows that JoinBoost is 3x (1.1x) faster for random forests (gradient boosting) compared to LightGBM, and over an order magnitude faster than state-of-the-art In-DB ML systems. Further, JoinBoost scales well beyond LightGBM in terms of the # features, DB size (TPC-DS SF=1000), and join graph complexity (galaxy schemas).
</details>
<details>
<summary>摘要</summary>
although dominant for tabular data, machine learning（ML）libraries that train tree models over normalized databases（e.g., LightGBM, XGBoost）require the data to be denormalized as a single table, materialized, and exported. This process is not scalable, slow, and poses security risks. In-DB ML aims to train models within DBMSes to avoid data movement and provide data governance. Rather than modify a DBMS to support In-DB ML, is it possible to offer competitive tree training performance to specialized ML libraries...with only SQL?  We present JoinBoost, a Python library that rewrites tree training algorithms over normalized databases into pure SQL. It is portable to any DBMS, offers performance competitive with specialized ML libraries, and scales with the underlying DBMS capabilities. JoinBoost extends prior work from both algorithmic and systems perspectives. Algorithmically, we support factorized gradient boosting, by updating the $Y$ variable to the residual in the non-materialized join result. Although this view update problem is generally ambiguous, we identify addition-to-multiplication preserving, the key property of variance semi-ring to support rmse, the most widely used criterion. System-wise, we identify residual updates as a performance bottleneck. Such overhead can be natively minimized on columnar DBMSes by creating a new column of residual values and adding it as a projection. We validate this with two implementations on DuckDB, with no or minimal modifications to its internals for portability. Our experiment shows that JoinBoost is 3x (1.1x) faster for random forests (gradient boosting) compared to LightGBM, and over an order magnitude faster than state-of-the-art In-DB ML systems. Further, JoinBoost scales well beyond LightGBM in terms of the # features, DB size (TPC-DS SF=1000), and join graph complexity (galaxy schemas).
</details></li>
</ul>
<hr>
<h2 id="Provably-Efficient-UCB-type-Algorithms-For-Learning-Predictive-State-Representations"><a href="#Provably-Efficient-UCB-type-Algorithms-For-Learning-Predictive-State-Representations" class="headerlink" title="Provably Efficient UCB-type Algorithms For Learning Predictive State Representations"></a>Provably Efficient UCB-type Algorithms For Learning Predictive State Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00405">http://arxiv.org/abs/2307.00405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiquan Huang, Yingbin Liang, Jing Yang</li>
<li>for: 本研究旨在提高累积奖励的策略选择问题，包括Markov决策过程（MDPs）和部分可见MDPs（POMDPs）为特殊情况。</li>
<li>methods: 该研究提出了首个已知的UCB类型方法，基于预测状态表示（PSRs），其中包括一个新的奖励项来Upper bound total variation distance between estimated和true模型。</li>
<li>results: 我们计算出了在线和离线PSRs的样本复杂性下界，并证明了我们的设计的UCB类型算法具有计算效率、最后一轮保证近似优策、和模型准确性的优点。<details>
<summary>Abstract</summary>
The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the total variation distance between the estimated and true models. We further characterize the sample complexity bounds for our designed UCB-type algorithms for both online and offline PSRs. In contrast to existing approaches for PSRs, our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed near-optimal policy, and guaranteed model accuracy.
</details>
<details>
<summary>摘要</summary>
通用顺序决策问题（包括Markov决策过程（MDPs）和部分可见MDPs（POMDPs）为特例）的目标是通过时间序列的决策来 maximize 累积奖励。 recent studies have shown that this problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). However, existing approaches typically involve oracles or computationally inefficient steps. On the other hand, the upper confidence bound (UCB) based approaches, which have been successful in bandits and MDPs, have not been investigated for more general PSRs due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the total variation distance between the estimated and true models. We further characterize the sample complexity bounds for our designed UCB-type algorithms for both online and offline PSRs. Unlike existing approaches for PSRs, our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed near-optimal policy, and guaranteed model accuracy.Here's the word-for-word translation of the text into Simplified Chinese:通用顺序决策问题（包括Markov决策过程（MDPs）和部分可见MDPs（POMDPs）为特例）的目标是通过时间序列的决策来 maximize 累积奖励。 recent studies have shown that this problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). however, existing approaches typically involve oracles or computationally inefficient steps. On the other hand, the upper confidence bound (UCB) based approaches, which have been successful in bandits and MDPs, have not been investigated for more general PSRs due to the difficulty of optimistic bonus design in these more challenging settings. this paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the total variation distance between the estimated and true models. we further characterize the sample complexity bounds for our designed UCB-type algorithms for both online and offline PSRs. unlike existing approaches for PSRs, our UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed near-optimal policy, and guaranteed model accuracy.
</details></li>
</ul>
<hr>
<h2 id="ProbVLM-Probabilistic-Adapter-for-Frozen-Vison-Language-Models"><a href="#ProbVLM-Probabilistic-Adapter-for-Frozen-Vison-Language-Models" class="headerlink" title="ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models"></a>ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00398">http://arxiv.org/abs/2307.00398</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ExplainableML/ProbVLM">https://github.com/ExplainableML/ProbVLM</a></li>
<li>paper_authors: Uddeshya Upadhyay, Shyamgopal Karthik, Massimiliano Mancini, Zeynep Akata</li>
<li>for: 本研究旨在提高大规模视觉语言模型（VLM）的表现，以实现更好的协同运算和模型选择。</li>
<li>methods: 本研究提出了一种 probabilistic adapter，可以在posts-hoc方式中对已经预训练的 VLM 进行概率调整，以估计嵌入空间中的概率分布。</li>
<li>results: 在四个挑战性 dataset 上，包括 COCO、Flickr、CUB 和 Oxford-flowers，研究人员可以通过估计嵌入空间中的概率分布，评估 VLM 的嵌入不确定性，并证明 ProbVLM 在回归任务中表现出色。此外，研究人员还提出了两个现实世界下沉浸任务，即活动学习和模型选择，并证明在这些任务中，估计嵌入空间中的概率分布具有很好的帮助作用。最后，研究人员还介绍了一种基于大规模预训练的潜在扩散模型，用于可见化嵌入分布。<details>
<summary>Abstract</summary>
Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose active learning and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly, we present a novel technique for visualizing the embedding distributions using a large-scale pre-trained latent diffusion model.
</details>
<details>
<summary>摘要</summary>
大规模视力语言模型（VLM）如CLIP成功地找到图像和文本之间的对应关系。通过标准排定 mapping 过程，一个图像或文本样本将映射到 embedding 空间中的单个向量上。这是一个问题：多个样本（图像或文本）可以抽象 Physical 世界中的同一个概念，因此排定 embedding 不会反映 embedding 空间中的内在含义。我们提议 ProbVLM，一种 probabilistic adapter，通过对 pre-trained VLM 的嵌入进行概率分布的估计，在后续方式中无需大规模数据或计算。在四个具有挑战性的 datasets 上，我们估算 pre-trained VLM 的嵌入不确定性，衡量嵌入不确定性的准确性在检索任务中，并示出 ProbVLM 超过其他方法。此外，我们提出了基于 VLM 的活动学习和模型选择两个实际应用任务，并证明估计不确定性可以 aid 这两个任务。最后，我们介绍了一种使用大规模预训练的潜在扩散模型来可见 embedding 分布的新技术。
</details></li>
</ul>
<hr>
<h2 id="MobileViG-Graph-Based-Sparse-Attention-for-Mobile-Vision-Applications"><a href="#MobileViG-Graph-Based-Sparse-Attention-for-Mobile-Vision-Applications" class="headerlink" title="MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications"></a>MobileViG: Graph-Based Sparse Attention for Mobile Vision Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00395">http://arxiv.org/abs/2307.00395</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sldgroup/mobilevig">https://github.com/sldgroup/mobilevig</a></li>
<li>paper_authors: Mustafa Munir, William Avery, Radu Marculescu<br>for: This paper proposes a new graph-based sparse attention mechanism (SVGA) and a hybrid CNN-GNN architecture (MobileViG) for vision tasks on mobile devices.methods: The proposed SVGA mechanism is designed to reduce the computational cost of representing images as graph structures, while the MobileViG architecture combines SVGA with a CNN backbone.results: Extensive experiments show that MobileViG outperforms existing ViG models and mobile CNN and ViT architectures in terms of accuracy and&#x2F;or speed on image classification, object detection, and instance segmentation tasks. The fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy with 0.78 ms inference latency on iPhone 13 Mini NPU, while the largest model, MobileViG-B, obtains 82.6% top-1 accuracy with only 2.30 ms latency.<details>
<summary>Abstract</summary>
Traditionally, convolutional neural networks (CNN) and vision transformers (ViT) have dominated computer vision. However, recently proposed vision graph neural networks (ViG) provide a new avenue for exploration. Unfortunately, for mobile applications, ViGs are computationally expensive due to the overhead of representing images as graph structures. In this work, we propose a new graph-based sparse attention mechanism, Sparse Vision Graph Attention (SVGA), that is designed for ViGs running on mobile devices. Additionally, we propose the first hybrid CNN-GNN architecture for vision tasks on mobile devices, MobileViG, which uses SVGA. Extensive experiments show that MobileViG beats existing ViG models and existing mobile CNN and ViT architectures in terms of accuracy and/or speed on image classification, object detection, and instance segmentation tasks. Our fastest model, MobileViG-Ti, achieves 75.7% top-1 accuracy on ImageNet-1K with 0.78 ms inference latency on iPhone 13 Mini NPU (compiled with CoreML), which is faster than MobileNetV2x1.4 (1.02 ms, 74.7% top-1) and MobileNetV2x1.0 (0.81 ms, 71.8% top-1). Our largest model, MobileViG-B obtains 82.6% top-1 accuracy with only 2.30 ms latency, which is faster and more accurate than the similarly sized EfficientFormer-L3 model (2.77 ms, 82.4%). Our work proves that well designed hybrid CNN-GNN architectures can be a new avenue of exploration for designing models that are extremely fast and accurate on mobile devices. Our code is publicly available at https://github.com/SLDGroup/MobileViG.
</details>
<details>
<summary>摘要</summary>
传统上，卷积神经网络（CNN）和视Transformer（ViT）在计算机视觉领域占据主导地位，但最近提出的视图图神经网络（ViG）提供了一个新的探索方向。然而，由于图像表示为图结构所带来的计算开销，ViG在移动设备上是计算昂贵的。在这种情况下，我们提出了一种新的图像 sparse attention机制——图像 sparse vision graph attention（SVGA），用于适应移动设备上的 ViG 运行。此外，我们还提出了首个在移动设备上使用 CNN-GNN 架构的 Hybrid CNN-GNN 模型——MobileViG，该模型使用 SVGA。我们的实验表明，MobileViG 在图像分类、物体检测和实例 segmentation 任务上比现有的 ViG 模型和现有的移动 CNN 和 ViT 架构更高的准确率和/或运行速度。我们的最快模型，MobileViG-Ti，在 ImageNet-1K 上达到了 75.7% 的顶部 1 准确率，并且在 iPhone 13 Mini NPU 上编译 CoreML 时间为 0.78 ms，比 MobileNetV2x1.4 (1.02 ms, 74.7% top-1) 和 MobileNetV2x1.0 (0.81 ms, 71.8% top-1) 更快。我们的最大模型，MobileViG-B，在 82.6% 的顶部 1 准确率下，只需 2.30 ms 的时间，这比 EfficientFormer-L3 模型 (2.77 ms, 82.4%) 更快和更准确。我们的工作证明了，通过设计合适的 Hybrid CNN-GNN 架构，可以在移动设备上设计出EXTREMELY FAST和EXTREMELY ACCURATE的模型。我们的代码可以在 <https://github.com/SLDGroup/MobileViG> 上获取。
</details></li>
</ul>
<hr>
<h2 id="CasTGAN-Cascaded-Generative-Adversarial-Network-for-Realistic-Tabular-Data-Synthesis"><a href="#CasTGAN-Cascaded-Generative-Adversarial-Network-for-Realistic-Tabular-Data-Synthesis" class="headerlink" title="CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis"></a>CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00384">http://arxiv.org/abs/2307.00384</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abedshantti/castgan">https://github.com/abedshantti/castgan</a></li>
<li>paper_authors: Abdallah Alshantti, Damiano Varagnolo, Adil Rasheed, Aria Rahmati, Frank Westad</li>
<li>for: 本文提出了一种基于生成对抗网络（GAN）的方法，用于生成具有真实性的表格数据，特别是关注Validity问题。</li>
<li>methods: 本文提出了一种级联的表格GAN框架（CasTGAN），通过级联的扩展，使生成的数据更加真实地反映原始数据中的特征相互关系。</li>
<li>results: 实验结果表明，CasTGAN能够很好地捕捉原始数据中特征之间的相互关系和约束，尤其是高维数据集。此外，对模型进行一些扰动处理可以提高模型对特定攻击的抗性。<details>
<summary>Abstract</summary>
Generative adversarial networks (GANs) have drawn considerable attention in recent years for their proven capability in generating synthetic data which can be utilized for multiple purposes. While GANs have demonstrated tremendous successes in producing synthetic data samples that replicate the dynamics of the original datasets, the validity of the synthetic data and the underlying privacy concerns represent major challenges which are not sufficiently addressed. In this work, we design a cascaded tabular GAN framework (CasTGAN) for generating realistic tabular data with a specific focus on the validity of the output. In this context, validity refers to the the dependency between features that can be found in the real data, but is typically misrepresented by traditional generative models. Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data. Our experimental results demonstrate that our model well captures the constraints and the correlations between the features of the real data, especially the high dimensional datasets. Furthermore, we evaluate the risk of white-box privacy attacks on our model and subsequently show that applying some perturbations to the auxiliary learners in CasTGAN increases the overall robustness of our model against targeted attacks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Residual-based-attention-and-connection-to-information-bottleneck-theory-in-PINNs"><a href="#Residual-based-attention-and-connection-to-information-bottleneck-theory-in-PINNs" class="headerlink" title="Residual-based attention and connection to information bottleneck theory in PINNs"></a>Residual-based attention and connection to information bottleneck theory in PINNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00379">http://arxiv.org/abs/2307.00379</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soanagno/rba-pinns">https://github.com/soanagno/rba-pinns</a></li>
<li>paper_authors: Sokratis J. Anagnostopoulos, Juan Diego Toscano, Nikolaos Stergiopulos, George Em Karniadakis</li>
<li>for: 本研究旨在提高物理学习机制中的数据集成效率和无缝性。</li>
<li>methods: 该研究提出了一种高效、不需要梯度的重量规则，用于加速物理学习机制中的动态或静态系统的收敛。该简单 yet effective 的注意力机制是基于系统的演化准确误差，并且不需要额外的计算成本或反向学习。</li>
<li>results: 该研究表明，该重量规则可以在标准优化器上实现相对 $L^{2}$ 误差在 $10^{-5}$ 水平。此外，通过分析训练过程中的权重演化，研究人员发现了两个不同的学习阶段，与信息瓶颈理论（IB）中的匹配和扩散阶段相似。<details>
<summary>Abstract</summary>
Driven by the need for more efficient and seamless integration of physical models and data, physics-informed neural networks (PINNs) have seen a surge of interest in recent years. However, ensuring the reliability of their convergence and accuracy remains a challenge. In this work, we propose an efficient, gradient-less weighting scheme for PINNs, that accelerates the convergence of dynamic or static systems. This simple yet effective attention mechanism is a function of the evolving cumulative residuals and aims to make the optimizer aware of problematic regions at no extra computational cost or adversarial learning. We illustrate that this general method consistently achieves a relative $L^{2}$ error of the order of $10^{-5}$ using standard optimizers on typical benchmark cases of the literature. Furthermore, by investigating the evolution of weights during training, we identify two distinct learning phases reminiscent of the fitting and diffusion phases proposed by the information bottleneck (IB) theory. Subsequent gradient analysis supports this hypothesis by aligning the transition from high to low signal-to-noise ratio (SNR) with the transition from fitting to diffusion regimes of the adopted weights. This novel correlation between PINNs and IB theory could open future possibilities for understanding the underlying mechanisms behind the training and stability of PINNs and, more broadly, of neural operators.
</details>
<details>
<summary>摘要</summary>
驱动了更高效和无缝的物理模型和数据集成的需求，物理学 informed neural networks（PINNs）在最近几年内得到了广泛的关注。然而，保证其减少和精度的可靠性仍然是一个挑战。在这种工作中，我们提出了一种高效的无梯度权重方案，用于加速动态或静态系统的PINNs的收敛。这种简单 yet effective的注意力机制是函数所处的积累差异，并且在不Extra的计算成本或对抗学习的情况下，使得优化器对问题地带出更多的注意。我们示出，这种通用方法可以在典型的文献中的测试案例中实现相对的L2误差为10^-5水平。此外，通过分析训练过程中权重的发展，我们发现了IB理论中的两个不同学习阶段，即“适应阶段”和“扩散阶段”。这种预测和权重的采用支持了这一假设，并且对PINNs和更广泛的神经运算器的稳定性和训练机制的理解带来了新的可能性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/cs.LG_2023_07_02/" data-id="cloimip9x00k6s488e6aib4ex" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/02/eess.IV_2023_07_02/" class="article-date">
  <time datetime="2023-07-02T09:00:00.000Z" itemprop="datePublished">2023-07-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/02/eess.IV_2023_07_02/">eess.IV - 2023-07-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-multi-task-learning-framework-for-carotid-plaque-segmentation-and-classification-from-ultrasound-images"><a href="#A-multi-task-learning-framework-for-carotid-plaque-segmentation-and-classification-from-ultrasound-images" class="headerlink" title="A multi-task learning framework for carotid plaque segmentation and classification from ultrasound images"></a>A multi-task learning framework for carotid plaque segmentation and classification from ultrasound images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00583">http://arxiv.org/abs/2307.00583</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitao Gan, Ran Zhou, Yanghan Ou, Furong Wang, Xinyao Cheng, Xiaoyan Wu, Aaron Fenster</li>
<li>for: 本研究的目的是提出一种多任务学习框架，用于 ultrasound 脉搏凝固板分类和 segmentation，以利用这两个任务之间的相关性。</li>
<li>methods: 该方法使用了一个区域权重模块 (RWM) 和一个样本权重模块 (SWM)，以利用分类任务中的区域预知知识，并通过学习样本权重来提高分类和 segmentation 的性能。</li>
<li>results: 实验结果表明，提出的方法可以significantly提高与单任务网络相比的性能，包括分类精度为 85.82% 和 segmentation 的 Dice 相似度为 84.92%。<details>
<summary>Abstract</summary>
Carotid plaque segmentation and classification play important roles in the treatment of atherosclerosis and assessment for risk of stroke. Although deep learning methods have been used for carotid plaque segmentation and classification, most focused on a single task and ignored the relationship between the segmentation and classification of carotid plaques. Therefore, we propose a multi-task learning framework for ultrasound carotid plaque segmentation and classification, which utilizes a region-weight module (RWM) and a sample-weight module (SWM) to exploit the correlation between these two tasks. The RWM provides a plaque regional prior knowledge to the classification task, while the SWM is designed to learn the categorical sample weight for the segmentation task. A total of 1270 2D ultrasound images of carotid plaques were collected from Zhongnan Hospital (Wuhan, China) for our experiments. The results of the experiments showed that the proposed method can significantly improve the performance compared to existing networks trained for a single task, with an accuracy of 85.82% for classification and a Dice similarity coefficient of 84.92% for segmentation. In the ablation study, the results demonstrated that both the designed RWM and SWM were beneficial in improving the network's performance. Therefore, we believe that the proposed method could be useful for carotid plaque analysis in clinical trials and practice.
</details>
<details>
<summary>摘要</summary>
卡罗提脂板分割和分类在脉络疾病治疗和风险评估中发挥重要作用。虽然深度学习方法已经用于卡罗提脂板分割和分类，但大多数方法都专注于单一任务，忽略了这两个任务之间的关系。因此，我们提出了一种多任务学习框架 для脉络卡罗提脂板分割和分类，该框架利用区域权重模块（RWM）和样本权重模块（SWM）来利用这两个任务之间的相关性。RWM提供了脉络内分泌区域的知识，以便分类任务中的识别，而SWM是为分割任务学习样本权重。我们在 Zhongnan Hospital（武汉中南医院）收集了1270个2D脉络卡罗提脂板图像进行实验。实验结果表明，我们提出的方法可以明显提高与已有网络单任务培训的性能，具体数据为85.82%的分类精度和84.92%的分割同步率。在减少研究中，结果表明，设计的RWM和SWM都对网络性能的提高做出了贡献。因此，我们认为，我们的方法可以在临床试验和实践中用于脉络卡罗提脂板分析。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Super-Resolution-Networks-through-Realistic-Thick-Slice-CT-Simulation"><a href="#Enhancing-Super-Resolution-Networks-through-Realistic-Thick-Slice-CT-Simulation" class="headerlink" title="Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation"></a>Enhancing Super-Resolution Networks through Realistic Thick-Slice CT Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10182">http://arxiv.org/abs/2307.10182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Tang, Xiaodan Xing, Guang Yang</li>
<li>for: 这项研究旨在开发一种新的快速CT图像生成算法，以便生成与实际图像更加相似的厚片CT图像。</li>
<li>methods: 该研究使用了Peak Signal-to-Noise Ratio (PSNR)和Root Mean Square Error (RMSE)指标来评估提议的算法，并发现该算法能够提供更加与实际图像相似的图像。</li>
<li>results: 该研究表明，使用提议的算法可以获得较高的PSNR和较低的RMSE，并且生成的图像更加与实际图像相似。<details>
<summary>Abstract</summary>
This study aims to develop and evaluate an innovative simulation algorithm for generating thick-slice CT images that closely resemble actual images in the AAPM-Mayo's 2016 Low Dose CT Grand Challenge dataset. The proposed method was evaluated using Peak Signal-to-Noise Ratio (PSNR) and Root Mean Square Error (RMSE) metrics, with the hypothesis that our simulation would produce images more congruent with their real counterparts. Our proposed method demonstrated substantial enhancements in terms of both PSNR and RMSE over other simulation methods. The highest PSNR values were obtained with the proposed method, yielding 49.7369 $\pm$ 2.5223 and 48.5801 $\pm$ 7.3271 for D45 and B30 reconstruction kernels, respectively. The proposed method also registered the lowest RMSE with values of 0.0068 $\pm$ 0.0020 and 0.0108 $\pm$ 0.0099 for D45 and B30, respectively, indicating a distribution more closely aligned with the authentic thick-slice image. Further validation of the proposed simulation algorithm was conducted using the TCIA LDCT-and-Projection-data dataset. The generated images were then leveraged to train four distinct super-resolution (SR) models, which were subsequently evaluated using the real thick-slice images from the 2016 Low Dose CT Grand Challenge dataset. When trained with data produced by our novel algorithm, all four SR models exhibited enhanced performance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这项研究的目的是开发和评估一种创新的thick-slice CT图像生成算法，以便更加准确地模拟实际图像在AAPM-Mayo的2016年低剂量CT挑战数据集中。提出的方法使用PSNR和RMSE度量来评估，假设我们的生成算法可以生成更加与实际图像相似的图像。我们的提出方法在PSNR和RMSE上都达到了substantial提高，相比其他生成方法。我们的方法在D45和B30重建器中获得了最高PSNR值，具体值为49.7369 ± 2.5223和48.5801 ± 7.3271。我们的方法还在D45和B30重建器中 регистрирова了最低RMSE值，具体值为0.0068 ± 0.0020和0.0108 ± 0.0099。这表明我们的方法生成的图像更加与实际图像相似。我们进一步验证了我们的生成算法使用TCIA LDCT-and-Projection-data dataset。生成的图像然后被用来训练四种不同的super-resolution（SR）模型，并在2016年低剂量CT挑战数据集中使用实际thick-slice图像进行评估。当使用我们的新算法生成数据时，所有四种SR模型均展现出了改进的性能。
</details></li>
</ul>
<hr>
<h2 id="ARHNet-Adaptive-Region-Harmonization-for-Lesion-aware-Augmentation-to-Improve-Segmentation-Performance"><a href="#ARHNet-Adaptive-Region-Harmonization-for-Lesion-aware-Augmentation-to-Improve-Segmentation-Performance" class="headerlink" title="ARHNet: Adaptive Region Harmonization for Lesion-aware Augmentation to Improve Segmentation Performance"></a>ARHNet: Adaptive Region Harmonization for Lesion-aware Augmentation to Improve Segmentation Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.01220">http://arxiv.org/abs/2307.01220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/king-haw/arhnet">https://github.com/king-haw/arhnet</a></li>
<li>paper_authors: Jiayu Huo, Yang Liu, Xi Ouyang, Alejandro Granados, Sebastien Ourselin, Rachel Sparks</li>
<li>for: 提供更好的脑损害诊断和 neuromonitoring 服务</li>
<li>methods: 使用增强的数据增强技术和自适应区域协调模块</li>
<li>results: 提高 segmentation 性能，在真实和 sintetic 图像上达到最佳效果，代码公开在 GitHubHere’s the breakdown of each point:</li>
<li>for: The paper is written for providing better diagnosis and neurological monitoring services by accurately segmenting brain lesions in MRI scans.</li>
<li>methods: The paper proposes a foreground harmonization framework (ARHNet) that uses advanced data augmentation and an Adaptive Region Harmonization (ARH) module to dynamically align foreground feature maps to the background with an attention mechanism.</li>
<li>results: The paper demonstrates the effectiveness of ARHNet in improving segmentation performance using real and synthetic images, and outperforms other methods for image harmonization tasks. The code is publicly available on GitHub.<details>
<summary>Abstract</summary>
Accurately segmenting brain lesions in MRI scans is critical for providing patients with prognoses and neurological monitoring. However, the performance of CNN-based segmentation methods is constrained by the limited training set size. Advanced data augmentation is an effective strategy to improve the model's robustness. However, they often introduce intensity disparities between foreground and background areas and boundary artifacts, which weakens the effectiveness of such strategies. In this paper, we propose a foreground harmonization framework (ARHNet) to tackle intensity disparities and make synthetic images look more realistic. In particular, we propose an Adaptive Region Harmonization (ARH) module to dynamically align foreground feature maps to the background with an attention mechanism. We demonstrate the efficacy of our method in improving the segmentation performance using real and synthetic images. Experimental results on the ATLAS 2.0 dataset show that ARHNet outperforms other methods for image harmonization tasks, and boosts the down-stream segmentation performance. Our code is publicly available at https://github.com/King-HAW/ARHNet.
</details>
<details>
<summary>摘要</summary>
优先级段落：精准分割脑部损害的MRI扫描图像是诊断和脑科监测中非常重要的。然而，基于Convolutional Neural Network（CNN）的分割方法的性能受训练集大小的限制。高级数据增强是一种有效的策略来提高模型的鲁棒性。然而，它们通常会导致背景和前景区域之间的明暗差异和边缘artefacts，这会削弱这些策略的效果。在这篇论文中，我们提出了一种前景协调框架（ARHNet）来解决明暗差异和Synthetic图像的真实性。特别是，我们提出了一种适应区域协调（ARH）模块，通过注意力机制来动态对前景特征图与背景进行对齐。我们通过实验表明，ARHNet可以提高下游分割性能，并在ATLAS 2.0 dataset上超过其他图像协调任务的方法。我们的代码公开在GitHub上，请参考https://github.com/King-HAW/ARHNet。
</details></li>
</ul>
<hr>
<h2 id="Domain-Transfer-Through-Image-to-Image-Translation-for-Uncertainty-Aware-Prostate-Cancer-Classification"><a href="#Domain-Transfer-Through-Image-to-Image-Translation-for-Uncertainty-Aware-Prostate-Cancer-Classification" class="headerlink" title="Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware Prostate Cancer Classification"></a>Domain Transfer Through Image-to-Image Translation for Uncertainty-Aware Prostate Cancer Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00479">http://arxiv.org/abs/2307.00479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Zhou, Amoon Jamzad, Jason Izard, Alexandre Menard, Robert Siemens, Parvin Mousavi</li>
<li>for: 这个研究是为了提高肝癌诊断的精度和效率，使用深度学习模型来支持医生在诊断过程中。</li>
<li>methods: 这个研究使用了对照式图像转换方法，将3.0T MRI图像转换为1.5T MRI图像，以增加训练数据的量。还使用了证据深度学习方法来估计模型的不确定性，并运用数据范围技术来筛选训练数据。最后，这个研究引入了证据类型单元损失，将类型单元损失与证据不确定性结合以训练模型。</li>
<li>results: 这个研究的结果显示，使用对照式图像转换方法和证据深度学习方法可以提高肝癌诊断的精度，AUC值提高了20%以上（98.4% vs. 76.2%）。这些结果显示，提供预测不确定性可能会帮助医生更好地处理不确定的案例，并且更快地完成诊断过程。<details>
<summary>Abstract</summary>
Prostate Cancer (PCa) is often diagnosed using High-resolution 3.0 Tesla(T) MRI, which has been widely established in clinics. However, there are still many medical centers that use 1.5T MRI units in the actual diagnostic process of PCa. In the past few years, deep learning-based models have been proven to be efficient on the PCa classification task and can be successfully used to support radiologists during the diagnostic process. However, training such models often requires a vast amount of data, and sometimes it is unobtainable in practice. Additionally, multi-source MRIs can pose challenges due to cross-domain distribution differences. In this paper, we have presented a novel approach for unpaired image-to-image translation of prostate mp-MRI for classifying clinically significant PCa, to be applied in data-constrained settings. First, we introduce domain transfer, a novel pipeline to translate unpaired 3.0T multi-parametric prostate MRIs to 1.5T, to increase the number of training data. Second, we estimate the uncertainty of our models through an evidential deep learning approach; and leverage the dataset filtering technique during the training process. Furthermore, we introduce a simple, yet efficient Evidential Focal Loss that incorporates the focal loss with evidential uncertainty to train our model. Our experiments demonstrate that the proposed method significantly improves the Area Under ROC Curve (AUC) by over 20% compared to the previous work (98.4% vs. 76.2%). We envision that providing prediction uncertainty to radiologists may help them focus more on uncertain cases and thus expedite the diagnostic process effectively. Our code is available at https://github.com/med-i-lab/DT_UE_PCa
</details>
<details>
<summary>摘要</summary>
丙级尿道癌（PCa）经常通过高分辨率3.0T MRI进行诊断，但是医疗机构中仍有许多使用1.5T MRI单元进行诊断过程。过去几年，深度学习基于模型已经在PCa分类任务上证明效果良好，可以为医生提供支持。然而，训练这些模型通常需要巨量数据，而且在实践中可能无法获得。此外，多源MRIs可能会产生交叉领域分布差异。在这篇论文中，我们提出了一种新的方法，用于无拟合的图像到图像翻译，以便在数据紧张的情况下对丙级尿道癌进行分类。首先，我们引入域传递，一种新的管道，用于将3.0T多参量尿道MRIs翻译成1.5T，以增加训练数据的数量。其次，我们通过证明深度学习方法来估计模型的uncertainty;并在训练过程中运用数据筛选技术。此外，我们引入了一种简单 yet efficient的证明焦点损失，并将其与证明uncertainty相结合，以训练我们的模型。我们的实验表明，我们的方法可以提高ROC曲线面积（AUC）比前一个工作（98.4% vs. 76.2%）。我们认为，为医生提供预测不确定性可能会帮助他们更好地关注不确定的案例，从而更有效地快速诊断。我们的代码可以在https://github.com/med-i-lab/DT_UE_PCa中找到。
</details></li>
</ul>
<hr>
<h2 id="Weighted-Anisotropic-Isotropic-Total-Variation-for-Poisson-Denoising"><a href="#Weighted-Anisotropic-Isotropic-Total-Variation-for-Poisson-Denoising" class="headerlink" title="Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising"></a>Weighted Anisotropic-Isotropic Total Variation for Poisson Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00439">http://arxiv.org/abs/2307.00439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kbui1993/official_aitv_poisson_denoising">https://github.com/kbui1993/official_aitv_poisson_denoising</a></li>
<li>paper_authors: Kevin Bui, Yifei Lou, Fredrick Park, Jack Xin</li>
<li>for: 这篇研究旨在提出一种基于weighted anisotropic-isotropic total variation（AITV）的Poisson噪声除除法，以提高图像质量和计算效率。</li>
<li>methods: 该研究使用了一种基于替换方法的多值函数，并使用了一种组合 proximal 算法和权重补做法来实现。</li>
<li>results: 数值实验表明，该算法比其他Poisson噪声除除法具有更高的图像质量和计算效率。<details>
<summary>Abstract</summary>
Poisson noise commonly occurs in images captured by photon-limited imaging systems such as in astronomy and medicine. As the distribution of Poisson noise depends on the pixel intensity value, noise levels vary from pixels to pixels. Hence, denoising a Poisson-corrupted image while preserving important details can be challenging. In this paper, we propose a Poisson denoising model by incorporating the weighted anisotropic-isotropic total variation (AITV) as a regularization. We then develop an alternating direction method of multipliers with a combination of a proximal operator for an efficient implementation. Lastly, numerical experiments demonstrate that our algorithm outperforms other Poisson denoising methods in terms of image quality and computational efficiency.
</details>
<details>
<summary>摘要</summary>
Poisson 噪声通常发生在由光子限制的捕捉系统中，如天文学和医学中的图像捕捉。由于噪声分布取决于像素INTENSITY值，噪声水平各像素不同，因此去噪化Poisson受损图像保持重要细节可谓挑战。在这篇论文中，我们提出了包含加重度权重iso-anisotropic total variation（AITV）的Poisson去噪模型。然后，我们开发了一种alternating direction method of multipliers，并使用 proximal operator 实现高效的实现。最后，数值实验表明，我们的算法在图像质量和计算效率方面都超过了其他Poisson去噪方法。
</details></li>
</ul>
<hr>
<h2 id="Sulcal-Pattern-Matching-with-the-Wasserstein-Distance"><a href="#Sulcal-Pattern-Matching-with-the-Wasserstein-Distance" class="headerlink" title="Sulcal Pattern Matching with the Wasserstein Distance"></a>Sulcal Pattern Matching with the Wasserstein Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00385">http://arxiv.org/abs/2307.00385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/laplcebeltrami/sulcaltree">https://github.com/laplcebeltrami/sulcaltree</a></li>
<li>paper_authors: Zijian Chen, Soumya Das, Moo K. Chung</li>
<li>for: 该论文旨在提供一种统一的计算框架，用于模型人脑磁共振图像中的皱槽模式。</li>
<li>methods: 论文使用沃asserstein距离来非线性匹配皱槽模式，并开发了梯度下降算法来估计塑形场。</li>
<li>results: 该方法可以准确地识别男性和女性皱槽模式之间的差异。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We present the unified computational framework for modeling the sulcal patterns of human brain obtained from the magnetic resonance images. The Wasserstein distance is used to align the sulcal patterns nonlinearly. These patterns are topologically different across subjects making the pattern matching a challenge. We work out the mathematical details and develop the gradient descent algorithms for estimating the deformation field. We further quantify the image registration performance. This method is applied in identifying the differences between male and female sulcal patterns.
</details>
<details>
<summary>摘要</summary>
我们提出了一个统一的计算框架，用于模拟人类大脑磁共振成像中的脑隙Pattern。我们使用沃asserstein距离来非线性匹配这些Pattern。由于这些Pattern在不同个体中具有不同的拓扑结构，因此匹配这些Pattern是一个挑战。我们在详细的数学上下文中详细介绍了这些方法，并开发了梯度下降算法来估计扭变场。我们进一步评估了图像匹配性。这种方法可以用于对男女脑隙Pattern之间的差异进行识别。Here's the text with traditional Chinese characters:我们提出了一个统一的计算框架，用于模拟人类大脑磁共振成像中的脑隙Pattern。我们使用沃asserstein距离来非线性匹配这些Pattern。由于这些Pattern在不同个体中具有不同的拓扑结构，因此匹配这些Pattern是一个挑战。我们在详细的数学上下文中详细介绍了这些方法，并开发了梯度下降算法来估计扭变场。我们进一步评估了图像匹配性。这种方法可以用于对男女脑隙Pattern之间的差异进行识别。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/02/eess.IV_2023_07_02/" data-id="cloimipg8010vs488bshbfhq1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/01/cs.SD_2023_07_01/" class="article-date">
  <time datetime="2023-07-01T15:00:00.000Z" itemprop="datePublished">2023-07-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/01/cs.SD_2023_07_01/">cs.SD - 2023-07-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Human-Auditory-System-and-Audio"><a href="#The-Human-Auditory-System-and-Audio" class="headerlink" title="The Human Auditory System and Audio"></a>The Human Auditory System and Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00084">http://arxiv.org/abs/2307.00084</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chilldude/stereo-cipher">https://github.com/chilldude/stereo-cipher</a></li>
<li>paper_authors: Milind N. Kunchur</li>
<li>for: 这篇论文探讨了人类听觉系统，描述了一些特殊化机制和非线性路径，从物理声音的感知过程中。</li>
<li>methods: 该论文使用了一些新的技术和方法，包括声音响应的测量和分析，以及计算模型的构建。</li>
<li>results: 研究发现，人类听觉系统具有惊人的高精度和多样性，可以在微秒级别听觉和分辨声音细节，并且可以检测到声音的非常小的变化。<details>
<summary>Abstract</summary>
This work reviews the human auditory system, elucidating some of the specialized mechanisms and non-linear pathways along the chain of events between physical sound and its perception. Customary relationships between frequency, time, and phase--such as the uncertainty principle--that hold for linear systems, do not apply straightforwardly to the hearing process. Auditory temporal resolution for certain processes can be a hundredth of the period of the signal, and can extend down to the microseconds time scale. The astonishingly large number of variations that correspond to the neural excitation pattern of 30000 auditory nerve fibers, originating from 3500 inner hair cells, explicates the vast capacity of the auditory system for the resolution of sonic detail. And the ear is sensitive enough to detect a basilar-membrane amplitude at the level of a picometer, or about a hundred times smaller than an atom. This article surveys and provides new insights into some of the impressive capabilities of the human auditory system and explores their relationship to fidelity in reproduced sound.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇文章介绍人类听觉系统，描述了听觉过程中的一些特殊机制和非线性路径，从物理声音转化为感知。传统的关系 между频率、时间和相位，例如不确定原理，不直接适用于听觉过程。听觉时间分辨率可以达百万分之一秒级，并可以降到微秒级别。听觉系统的神经刺激模式有30000个 auditory nerve fibers，来自3500个内声毫细胞，这使得听觉系统具有很大的容量，用于分辨声音细节。而耳朵也够敏感，可以探测到基ляр膜振荡的振荡幅度，只有一个picometer级别，约相当于一个原子的100倍。这篇文章提供了新的意义和听觉系统的关系，并探讨其与重新生成的声音的准确性之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Towards-Improving-the-Performance-of-Pre-Trained-Speech-Models-for-Low-Resource-Languages-Through-Lateral-Inhibition"><a href="#Towards-Improving-the-Performance-of-Pre-Trained-Speech-Models-for-Low-Resource-Languages-Through-Lateral-Inhibition" class="headerlink" title="Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition"></a>Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17792">http://arxiv.org/abs/2306.17792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrei-Marius Avram, Răzvan-Alexandru Smădu, Vasile Păiş, Dumitru-Clementin Cercel, Radu Ion, Dan Tufiş</li>
<li>for: 提高预先训练的语音模型性能</li>
<li>methods: 取代细化 dense layer  avec lateral inhibition layer</li>
<li>results: 在 Romanian 语言下提高了12.5% 字异错率 (WER)，并在 Romanian Speech Corpus 和 Robin Technical Acquisition Corpus 上达到了状态机器人的result（1.78% WER 和 29.64% WER）。<details>
<summary>Abstract</summary>
With the rise of bidirectional encoder representations from Transformer models in natural language processing, the speech community has adopted some of their development methodologies. Therefore, the Wav2Vec models were introduced to reduce the data required to obtain state-of-the-art results. This work leverages this knowledge and improves the performance of the pre-trained speech models by simply replacing the fine-tuning dense layer with a lateral inhibition layer inspired by the biological process. Our experiments on Romanian, a low-resource language, show an average improvement of 12.5% word error rate (WER) using the lateral inhibition layer. In addition, we obtain state-of-the-art results on both the Romanian Speech Corpus and the Robin Technical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.
</details>
<details>
<summary>摘要</summary>
随着Transformer模型的bidirectional编码器表示法在自然语言处理领域的普及，语音社区开始采纳其开发方法。因此，Wav2Vec模型被引入，以降低需要获得状态对应的数据量。本工作借用这些知识，改进了预训练的语音模型，通过取代精度降低层为 lateral inhibition层，这种层启发自生物过程。我们的实验表明，在罗马尼亚语，一种低资源语言，使用 lateral inhibition 层可以提高语音识别精度，平均提高12.5%词错率（WER）。此外，我们在罗马尼亚语语音库和Robin技术获得 corpus 上达到了状态对应的最佳结果，分别为1.78% WER和29.64% WER。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/01/cs.SD_2023_07_01/" data-id="cloimipcv00r4s488au9rghrl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/01/eess.AS_2023_07_01/" class="article-date">
  <time datetime="2023-07-01T14:00:00.000Z" itemprop="datePublished">2023-07-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/01/eess.AS_2023_07_01/">eess.AS - 2023-07-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-the-EEG-Speech-Match-Mismatch-Tasks-With-Word-Boundaries"><a href="#Enhancing-the-EEG-Speech-Match-Mismatch-Tasks-With-Word-Boundaries" class="headerlink" title="Enhancing the EEG Speech Match Mismatch Tasks With Word Boundaries"></a>Enhancing the EEG Speech Match Mismatch Tasks With Word Boundaries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00366">http://arxiv.org/abs/2307.00366</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iiscleap/eegspeech-matchmismatch">https://github.com/iiscleap/eegspeech-matchmismatch</a></li>
<li>paper_authors: Akshara Soman, Vidhi Sinha, Sriram Ganapathy</li>
<li>for: This paper is written for analyzing the underlying neural mechanisms of human speech comprehension, specifically using a match-mismatch classification of speech stimuli and neural responses.</li>
<li>methods: The paper uses a network of convolution layers to process both speech and EEG signals, followed by a word boundary-based average pooling and a recurrent layer to incorporate inter-word context.</li>
<li>results: The experiments show that the modeling accuracy can be significantly improved to 93% on a publicly available speech-EEG data set, which is higher than previous efforts that achieved an accuracy of 65-75% for this task.<details>
<summary>Abstract</summary>
Recent studies have shown that the underlying neural mechanisms of human speech comprehension can be analyzed using a match-mismatch classification of the speech stimulus and the neural response. However, such studies have been conducted for fixed-duration segments without accounting for the discrete processing of speech in the brain. In this work, we establish that word boundary information plays a significant role in sentence processing by relating EEG to its speech input. We process the speech and the EEG signals using a network of convolution layers. Then, a word boundary-based average pooling is performed on the representations, and the inter-word context is incorporated using a recurrent layer. The experiments show that the modeling accuracy can be significantly improved (match-mismatch classification accuracy) to 93% on a publicly available speech-EEG data set, while previous efforts achieved an accuracy of 65-75% for this task.
</details>
<details>
<summary>摘要</summary>
近期研究表明，人类语言理解的下面神经机制可以通过匹配-不匹配分类的语音刺激和神经回快的方式进行分析。然而，这些研究通常是在固定时间段内进行的，没有考虑大脑对语音的精度处理。在这项工作中，我们证明了单词边界信息在句子处理中发挥了重要作用，并使用神经网络进行语音和EEG信号处理。然后，我们对表示进行了单词边界基于的均值抽取，并通过回快层 incorporate 了间隔词上下文。实验结果显示，我们的模型准确率可以提高至 93% 在一个公共可用的语音-EEG数据集上，而之前的努力只能达到 65-75% 的水平。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/01/eess.AS_2023_07_01/" data-id="cloimipf400xps488g30tgg9u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/01/cs.CV_2023_07_01/" class="article-date">
  <time datetime="2023-07-01T13:00:00.000Z" itemprop="datePublished">2023-07-01</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/01/cs.CV_2023_07_01/">cs.CV - 2023-07-01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learning-Content-enhanced-Mask-Transformer-for-Domain-Generalized-Urban-Scene-Segmentation"><a href="#Learning-Content-enhanced-Mask-Transformer-for-Domain-Generalized-Urban-Scene-Segmentation" class="headerlink" title="Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation"></a>Learning Content-enhanced Mask Transformer for Domain Generalized Urban-Scene Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00371">http://arxiv.org/abs/2307.00371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Bi, Shaodi You, Theo Gevers</li>
<li>for: 这个研究目的是为了发展一个可以应对不同城市景观风格的 semantic segmentation 方法（Domain-generalized urban-scene semantic segmentation，USSS）。</li>
<li>methods: 这篇研究提出了一个基于 Transformer 的 Content-enhanced Mask TransFormer（CMFormer）方法，它强调了面罩注意力机制的增强，以提高模型的内容识别能力。</li>
<li>results: 实验结果显示，CMFormer 在不同城市景观风格下的 semantic segmentation  task 中表现出色，与已有的 CNN 方法相比，CMFormer 可以达到14.00% 的 mIoU 提升（mean intersection over union）。<details>
<summary>Abstract</summary>
Domain-generalized urban-scene semantic segmentation (USSS) aims to learn generalized semantic predictions across diverse urban-scene styles. Unlike domain gap challenges, USSS is unique in that the semantic categories are often similar in different urban scenes, while the styles can vary significantly due to changes in urban landscapes, weather conditions, lighting, and other factors. Existing approaches typically rely on convolutional neural networks (CNNs) to learn the content of urban scenes.   In this paper, we propose a Content-enhanced Mask TransFormer (CMFormer) for domain-generalized USSS. The main idea is to enhance the focus of the fundamental component, the mask attention mechanism, in Transformer segmentation models on content information. To achieve this, we introduce a novel content-enhanced mask attention mechanism. It learns mask queries from both the image feature and its down-sampled counterpart, as lower-resolution image features usually contain more robust content information and are less sensitive to style variations. These features are fused into a Transformer decoder and integrated into a multi-resolution content-enhanced mask attention learning scheme.   Extensive experiments conducted on various domain-generalized urban-scene segmentation datasets demonstrate that the proposed CMFormer significantly outperforms existing CNN-based methods for domain-generalized semantic segmentation, achieving improvements of up to 14.00\% in terms of mIoU (mean intersection over union). The source code for CMFormer will be made available at this \href{https://github.com/BiQiWHU/domain-generalized-urban-scene-segmentation}{repository}.
</details>
<details>
<summary>摘要</summary>
领域总体化的城市场景semantic segmentation（USSS）目标是学习多样化城市场景风格下的通用semantic预测。与领域差异挑战不同，USSS的semantic类别通常在不同的城市场景中相似，而style可以因城市风貌、天气、照明和其他因素而发生显著变化。现有方法通常采用卷积神经网络（CNN）来学习城市场景的内容。在这篇论文中，我们提出了一种基于Transformer segmentation模型的Content-enhanced Mask TransFormer（CMFormer）。主要思想是在Transformer segmentation模型中增强基本组件的面积注意力，以便更好地利用内容信息。为此，我们提出了一种新的内容增强面积注意力机制。它从图像特征和其下采样后的图像特征中学习面 queries，以便更好地利用图像的内容信息和风格特征。这些特征被混合到Transformer解码器中，并在多resolution content-enhanced面积注意力学习方案中集成。我们对多个领域总体化城市场景semantic segmentation数据集进行了广泛的实验，结果表明，提出的CMFormer显著超过了现有的CNN基于方法，在领域总体化semantic segmentation中实现了14.00%的提升， measured by mean intersection over union（mIoU）。我们将CMFormer的源代码公开在这个\href{https://github.com/BiQiWHU/domain-generalized-urban-scene-segmentation}{存储库}中。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Enhanced-Transformer-Towards-Multi-Frame-3D-Object-Detection"><a href="#Spatial-Temporal-Enhanced-Transformer-Towards-Multi-Frame-3D-Object-Detection" class="headerlink" title="Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object Detection"></a>Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00347">http://arxiv.org/abs/2307.00347</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Zhang, Zhiyu Zhu, Junhui Hou</li>
<li>for: 这篇论文旨在探讨多帧3D物体检测系统中的DETR模型，并提出一个基于DETR的端到端框架STEMD，用于解决多帧3D物体检测中的问题。</li>
<li>methods: STEMD使用DETR-like的方法，将多帧3D物体检测视为一个序列到序列的任务，并具有优化的空间-时间对话网络，以实现更好地捕捉物体之间的空间-时间依存性。</li>
<li>results: 经过实验证明，STEMD可以在复杂的测试场景下实现更好的多帧3D物体检测效果，并且仅增加了少量的计算负载。<details>
<summary>Abstract</summary>
The Detection Transformer (DETR) has revolutionized the design of CNN-based object detection systems, showcasing impressive performance. However, its potential in the domain of multi-frame 3D object detection remains largely unexplored. In this paper, we present STEMD, a novel end-to-end framework for multi-frame 3D object detection based on the DETR-like paradigm. Our approach treats multi-frame 3D object detection as a sequence-to-sequence task and effectively captures spatial-temporal dependencies at both the feature and query levels. To model the inter-object spatial interaction and complex temporal dependencies, we introduce the spatial-temporal graph attention network. This network represents queries as nodes in a graph and enables effective modeling of object interactions within a social context. In addition, to solve the problem of missing hard cases in the proposed output of the encoder in the current frame, we incorporate the output of the previous frame to initialize the query input of the decoder. Moreover, we tackle the issue of redundant detection results, where the model generates numerous overlapping boxes from similar queries. To mitigate this, we introduce an IoU regularization term in the loss function. This term aids in distinguishing between queries matched with the ground-truth box and queries that are similar but unmatched during the refinement process, leading to reduced redundancy and more accurate detections. Through extensive experiments, we demonstrate the effectiveness of our approach in handling challenging scenarios, while incurring only a minor additional computational overhead. The code will be available at \url{https://github.com/Eaphan/STEMD}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>德州检测变换（DETR）已经革命化了基于Convolutional Neural Networks（CNN）的物体检测系统的设计，展示了出色的性能。然而，它在多帧三维物体检测领域的潜力仍然未能得到充分发挥。在这篇论文中，我们提出了STEMD，一种基于DETR的novel结束到终点框架 для多帧三维物体检测。我们的方法将多帧三维物体检测视为一个序列到序列任务，并有效地捕捉了空间-时间依赖关系在特征和查询层次。为了模型对象之间的空间依赖关系和复杂的时间依赖关系，我们引入了空间-时间图注意力网络。这个网络将查询视为图形节点，并允许有效地模型对象之间的社交往来。此外，为解决提议编码器输出的问题，我们在当前帧的输出作为查询输入初始化decoder。此外，我们解决了模型生成重复的检测结果问题，其中模型生成了多个重叠的检测框。为此，我们引入了交合率 regularization项到损失函数中，以助于在反调过程中分辨与实际匹配的查询和相似 yet 未匹配的查询。经过广泛的实验，我们证明了我们的方法在面临挑战的场景下表现出色，同时只增加了少量的计算负担。代码将在 \url{https://github.com/Eaphan/STEMD} 上提供。
</details></li>
</ul>
<hr>
<h2 id="SDRCNN-A-single-scale-dense-residual-connected-convolutional-neural-network-for-pansharpening"><a href="#SDRCNN-A-single-scale-dense-residual-connected-convolutional-neural-network-for-pansharpening" class="headerlink" title="SDRCNN: A single-scale dense residual connected convolutional neural network for pansharpening"></a>SDRCNN: A single-scale dense residual connected convolutional neural network for pansharpening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00327">http://arxiv.org/abs/2307.00327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Fang, Yuanzhi Cai, Lei Fan</li>
<li>for: 本研究开发了一个单枝、单测度的轻量级卷积神经网络（SDRCNN），用于折衣高分辨率多spectral影像和低分辨率摄像头影像的混合。</li>
<li>methods: SDRCNN使用了一个新的紧密连接的构造和卷积层，以取得更好的精确性和效率的协调。</li>
<li>results: 根据四个来自世界视三、世界视二和快鹰镜头的测试数据，SDRCNN在 Visual inspection 和相关统计量评估中表现最佳，与传统方法和轻量级深度学习方法相比。<details>
<summary>Abstract</summary>
Pansharpening is a process of fusing a high spatial resolution panchromatic image and a low spatial resolution multispectral image to create a high-resolution multispectral image. A novel single-branch, single-scale lightweight convolutional neural network, named SDRCNN, is developed in this study. By using a novel dense residual connected structure and convolution block, SDRCNN achieved a better trade-off between accuracy and efficiency. The performance of SDRCNN was tested using four datasets from the WorldView-3, WorldView-2 and QuickBird satellites. The compared methods include eight traditional methods (i.e., GS, GSA, PRACS, BDSD, SFIM, GLP-CBD, CDIF and LRTCFPan) and five lightweight deep learning methods (i.e., PNN, PanNet, BayesianNet, DMDNet and FusionNet). Based on a visual inspection of the pansharpened images created and the associated absolute residual maps, SDRCNN exhibited least spatial detail blurring and spectral distortion, amongst all the methods considered. The values of the quantitative evaluation metrics were closest to their ideal values when SDRCNN was used. The processing time of SDRCNN was also the shortest among all methods tested. Finally, the effectiveness of each component in the SDRCNN was demonstrated in ablation experiments. All of these confirmed the superiority of SDRCNN.
</details>
<details>
<summary>摘要</summary>
文本翻译：杜邦普兰推算（Pansharpening）是将高空间分辨率粉尘图和低空间分辨率多spectral图像联合成高分辨率多spectral图像的过程。本研究中提出了一种单支持单尺度轻量级卷积神经网络，即SDRCNN。通过使用单支持密集连接结构和卷积块，SDRCNN实现了更好的精度和效率之间的平衡。SDRCNN的性能在四个世界视图-3、世界视图-2和快鸟卫星的四个数据集上进行测试，与传统方法（GS、GSA、PRACS、BDSD、SFIM、GLP-CBD、CDIF和LRTCFPan）和轻量级深度学习方法（PNN、PanNet、概率网络、DMDNet和FusionNet）进行比较。视觉检查照片和相关绝对差异图中的详细信息，SDRCNN表现最好，其他方法中的详细信息均受到了锐化和spectral扭曲的影响。量化评价指标的值最接近理想值时，SDRCNN被使用。SDRCNN的处理时间也是所有方法中最短。最后，SDRCNN的每个组件的效果在减少实验中得到了证明。这些证明了SDRCNN的优越性。
</details></li>
</ul>
<hr>
<h2 id="DeepMediX-A-Deep-Learning-Driven-Resource-Efficient-Medical-Diagnosis-Across-the-Spectrum"><a href="#DeepMediX-A-Deep-Learning-Driven-Resource-Efficient-Medical-Diagnosis-Across-the-Spectrum" class="headerlink" title="DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum"></a>DeepMediX: A Deep Learning-Driven Resource-Efficient Medical Diagnosis Across the Spectrum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00324">http://arxiv.org/abs/2307.00324</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kishore Babu Nampalle, Pradeep Singh, Uppala Vivek Narayan, Balasubramanian Raman</li>
<li>for: 这个研究旨在提出一个高精度 yet computationally efficient 的医疗影像诊断模型，以应对医疗影像诊断中的挑战。</li>
<li>methods: 这个模型基于 MobileNetV2 架构，并包括 Federated Learning 的概念，实现了跨院所的学习合作，不需要直接存取敏感患者数据，同时保持数据隐私和完整性。</li>
<li>results: 这个研究透过严谨的测试，证明 DeepMediX 具有出色的诊断能力，与现有模型在大多数任务上匹配或超越其表现，并且适合在手持式设备上部署，实现实时诊断支持。<details>
<summary>Abstract</summary>
In the rapidly evolving landscape of medical imaging diagnostics, achieving high accuracy while preserving computational efficiency remains a formidable challenge. This work presents \texttt{DeepMediX}, a groundbreaking, resource-efficient model that significantly addresses this challenge. Built on top of the MobileNetV2 architecture, DeepMediX excels in classifying brain MRI scans and skin cancer images, with superior performance demonstrated on both binary and multiclass skin cancer datasets. It provides a solution to labor-intensive manual processes, the need for large datasets, and complexities related to image properties. DeepMediX's design also includes the concept of Federated Learning, enabling a collaborative learning approach without compromising data privacy. This approach allows diverse healthcare institutions to benefit from shared learning experiences without the necessity of direct data access, enhancing the model's predictive power while preserving the privacy and integrity of sensitive patient data. Its low computational footprint makes DeepMediX suitable for deployment on handheld devices, offering potential for real-time diagnostic support. Through rigorous testing on standard datasets, including the ISIC2018 for dermatological research, DeepMediX demonstrates exceptional diagnostic capabilities, matching the performance of existing models on almost all tasks and even outperforming them in some cases. The findings of this study underline significant implications for the development and deployment of AI-based tools in medical imaging and their integration into point-of-care settings. The source code and models generated would be released at https://github.com/kishorebabun/DeepMediX.
</details>
<details>
<summary>摘要</summary>
在医疗影像诊断领域中，快速发展的景象中，实现高精度的同时保持计算效率是一项具有挑战性的任务。本研究提出了《DeepMediX》，一种创新的、资源高效的模型，可以有效地解决这个问题。基于MobileNetV2架构，DeepMediX在脑MRI扫描和皮肤癌图像分类方面表现出色，在双类和多类皮肤癌数据集上都达到了优秀的性能。它解决了劳动 INTENSIVE 的手动过程、大量数据的需求以及图像属性的复杂性等问题。DeepMediX的设计还包括联邦学习概念，允许不同的医疗机构共同学习而不需要直接访问敏感 patient 数据，从而提高模型的预测力而保护患者数据的隐私和完整性。它的低计算脚本使得 DeepMediX 适用于手持设备上部署，为实时诊断支持提供了潜在的可能性。经过对标准数据集的严格测试，包括 ISIC2018 皮肤科研数据集，DeepMediX 在大多数任务上表现出了极佳的诊断能力，与现有模型在大多数任务上几乎相当，甚至在一些情况下超越它们。这些发现对医疗影像中的 AI 基于工具的开发和部署以及其集成到点您护Setting 中具有重要的含义。研究所生成的代码和模型将在 <https://github.com/kishorebabun/DeepMediX> 上发布。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Solver-Generator-for-Systems-of-Laurent-Polynomial-Equations"><a href="#Automatic-Solver-Generator-for-Systems-of-Laurent-Polynomial-Equations" class="headerlink" title="Automatic Solver Generator for Systems of Laurent Polynomial Equations"></a>Automatic Solver Generator for Systems of Laurent Polynomial Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00320">http://arxiv.org/abs/2307.00320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evgeniy Martyushev, Snehal Bhayani, Tomas Pajdla</li>
<li>for: 解决给定的 Laurent 多项式系统中的一家问题，即在不同的系统中寻找可以快速计算解的方法。</li>
<li>methods: 提出了一种新的实用算法，用于检查给定的 Laurent 多项式是否可以构建排除模板。基于这个算法，我们提出了一个自动生成器，可以快速地生成解系统的 Laurent 多项式方程的解。</li>
<li>results: 我们的生成器可以快速地生成解系统的 Laurent 多项式方程的解，并且可以自动探测部分 $p$-fold 对称性。我们对各种简单的问题进行了测试，并证明了我们的生成器比现有的方法快速。<details>
<summary>Abstract</summary>
In computer vision applications, the following problem often arises: Given a family of (Laurent) polynomial systems with the same monomial structure but varying coefficients, find a solver that computes solutions for any family member as fast as possible. Under appropriate genericity assumptions, the dimension and degree of the respective polynomial ideal remain unchanged for each particular system in the same family. The state-of-the-art approach to solving such problems is based on elimination templates, which are the coefficient (Macaulay) matrices that encode the transformation from the initial polynomials to the polynomials needed to construct the action matrix. Knowing an action matrix, the solutions of the system are computed from its eigenvectors. The important property of an elimination template is that it applies to all polynomial systems in the family. In this paper, we propose a new practical algorithm that checks whether a given set of Laurent polynomials is sufficient to construct an elimination template. Based on this algorithm, we propose an automatic solver generator for systems of Laurent polynomial equations. The new generator is simple and fast; it applies to ideals with positive-dimensional components; it allows one to uncover partial $p$-fold symmetries automatically. We test our generator on various minimal problems, mostly in geometric computer vision. The speed of the generated solvers exceeds the state-of-the-art in most cases. In particular, we propose the solvers for the following problems: optimal 3-view triangulation, semi-generalized hybrid pose estimation and minimal time-of-arrival self-calibration. The experiments on synthetic scenes show that our solvers are numerically accurate and either comparable to or significantly faster than the state-of-the-art solvers.
</details>
<details>
<summary>摘要</summary>
在计算机视觉应用中，常遇到以下问题：给定一个 Laurent 多项式系统家族，找到一个可以尽快计算系统解的求解器。在适当的泛化假设下，每个特定系统的多项式理想的维度和度数保持不变。现状的解决方法是基于减法模板，它们是变量多项式系统中的约化矩阵，它们编码了将初始多项式转换成构造动作矩阵的过程中的多项式。知道动作矩阵，系统的解可以从其各自的特征向量中计算出来。减法模板的重要特点是它适用于所有多项式系统家族中的系统。在这篇论文中，我们提出了一个新的实用算法，该算法可以判断给定的 Laurent 多项式集是否具有构建减法模板的能力。基于这个算法，我们提出了一个自动生成器 для Laurent 多项式方程系统的解。新的生成器简单快速，适用于具有正的维度组分的理想；它允许自动找到部分 $p$-次对称性。我们在各种最小问题上进行了测试，包括优化三视图三角形、半总化混合位姿估计和最小时间到达自我校准。实验结果表明，我们的生成器可以在大多数情况下提供更快的解决方案，并且数值精度和状态艺术家的解决方案相当或更高。
</details></li>
</ul>
<hr>
<h2 id="Detection-of-River-Sandbank-for-Sand-Mining-with-the-Presence-of-Other-High-Mineral-Content-Regions-Using-Multi-spectral-Images"><a href="#Detection-of-River-Sandbank-for-Sand-Mining-with-the-Presence-of-Other-High-Mineral-Content-Regions-Using-Multi-spectral-Images" class="headerlink" title="Detection of River Sandbank for Sand Mining with the Presence of Other High Mineral Content Regions Using Multi-spectral Images"></a>Detection of River Sandbank for Sand Mining with the Presence of Other High Mineral Content Regions Using Multi-spectral Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00314">http://arxiv.org/abs/2307.00314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jit Mukherjee</li>
<li>for: 检测河川砂岸区域，直接影响经济、社会和环境。</li>
<li>methods: 使用多Modal分析，包括多spectral成像、Synthetic Aperture Radar（SAR）成像、航空图像和点云数据，但尚未充分利用河川砂岸区域的特征。</li>
<li>results: 提出了一种基于多spectral成像的新方法，可以在不使用标注数据的情况下，准确地检测河川砂岸区域。该方法基于河川和矿物质的强烈相关性，可以在不同季节下提供90.75%的准确率、85.47%的精度和73.5%的回归率。<details>
<summary>Abstract</summary>
Sand mining is a booming industry. The river sandbank is one of the primary sources of sand mining. Detection of potential river sandbank regions for sand mining directly impacts the economy, society, and environment. In the past, semi-supervised and supervised techniques have been used to detect mining regions including sand mining. A few techniques employ multi-modal analysis combining different modalities such as multi-spectral imaging, synthetic aperture radar (\emph{SAR}) imaging, aerial images, and point cloud data. However, the distinguishing spectral characteristics of river sandbank regions are yet to be fully explored. This paper provides a novel method to detect river sandbank regions for sand mining using multi-spectral images without any labeled data over the seasons. Association with a river stream and the abundance of minerals are the most prominent features of such a region. The proposed work uses these distinguishing features to determine the spectral signature of a river sandbank region, which is robust to other high mineral abundance regions. It follows a two-step approach, where first, potential high mineral regions are detected and next, they are segregated using the presence of a river stream. The proposed technique provides average accuracy, precision, and recall of 90.75%, 85.47%, and 73.5%, respectively over the seasons from Landsat 8 images without using any labeled dataset.
</details>
<details>
<summary>摘要</summary>
river sandbank 是一个潜在的重要来源 для冲积泥矿产。探测 potential river sandbank 区域的泥矿可以直接影响经济、社会和环境。在过去，半supervised和supervised技术已经被用来探测包括冲积泥矿在内的采矿区域。一些技术使用多模态分析，结合不同的模式，如多spectral imaging、Synthetic Aperture Radar（SAR） imaging、飞行图像和点云数据。然而，river sandbank 区域的特征还未被完全探索。本文提出了一种新的方法，用于探测 river sandbank 区域，不需要任何标注数据。该方法基于river stream的相关性和矿物质的充足程度，可以准确地分类不同的区域。本文采用了两步方法，首先检测高矿物质区域，然后使用river stream的存在来分类。提出的方法在不使用任何标注数据的情况下，从LandSat 8 图像上获得了90.75%、85.47%和73.5%的平均准确率、精度和回归率。
</details></li>
</ul>
<hr>
<h2 id="PM-DETR-Domain-Adaptive-Prompt-Memory-for-Object-Detection-with-Transformers"><a href="#PM-DETR-Domain-Adaptive-Prompt-Memory-for-Object-Detection-with-Transformers" class="headerlink" title="PM-DETR: Domain Adaptive Prompt Memory for Object Detection with Transformers"></a>PM-DETR: Domain Adaptive Prompt Memory for Object Detection with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00313">http://arxiv.org/abs/2307.00313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peidong Jia, Jiaming Liu, Senqiao Yang, Jiarui Wu, Xiaodong Xie, Shanghang Zhang</li>
<li>for: 本研究旨在适应检测器（DETR）在不同数据分布下的性能下降问题。</li>
<li>methods: 我们提出了一种层次Prompt Domain Memory（PDM），用于适应检测器的适应。PDM通过各个提示和其相应的分布值的对应关系，抽象地提取了域特有的知识，并将其作为多级嵌入和DETR输入的一部分进行注入。此外，我们还引入了Prompt Memory Alignment（PMA），用于减少源和目标域之间的差异，并充分利用提取到的域特有的知识。</li>
<li>results: 我们的方法在三个测试准则上（场景、 sintetic to real 和天气适应）比靶状态的领域适应检测方法表现出色，得到了更好的性能。<details>
<summary>Abstract</summary>
The Transformer-based detectors (i.e., DETR) have demonstrated impressive performance on end-to-end object detection. However, transferring DETR to different data distributions may lead to a significant performance degradation. Existing adaptation techniques focus on model-based approaches, which aim to leverage feature alignment to narrow the distribution shift between different domains. In this study, we propose a hierarchical Prompt Domain Memory (PDM) for adapting detection transformers to different distributions. PDM comprehensively leverages the prompt memory to extract domain-specific knowledge and explicitly constructs a long-term memory space for the data distribution, which represents better domain diversity compared to existing methods. Specifically, each prompt and its corresponding distribution value are paired in the memory space, and we inject top M distribution-similar prompts into the input and multi-level embeddings of DETR. Additionally, we introduce the Prompt Memory Alignment (PMA) to reduce the discrepancy between the source and target domains by fully leveraging the domain-specific knowledge extracted from the prompt domain memory. Extensive experiments demonstrate that our method outperforms state-of-the-art domain adaptive object detection methods on three benchmarks, including scene, synthetic to real, and weather adaptation. Codes will be released.
</details>
<details>
<summary>摘要</summary>
《 transformer 基于检测器（即 DETR）在端到端对象检测方面表现出了很好的表现。然而，在不同数据分布下传输 DETR 可能会导致性能下降。现有的适应技术主要集中在模型基于的方法上， aiming to leverage feature alignment to narrow the distribution shift between different domains。在这种研究中，我们提出了层次结构 Prompt Domain Memory（PDM），用于适应检测转换器到不同分布。PDM 通过全面利用提示记忆来抽取域pecific的知识，并将每个提示和其相应的分布值配对在记忆空间中，以及在 DETR 的输入和多级嵌入中注入 top M  Distribution-similar 提示。此外，我们还引入了 Prompt Memory Alignment（PMA），以减少源和目标域之间的差异，全面利用域specific 知识从提示域记忆中提取。广泛的实验表明，我们的方法在三个标准检测benchmark上（包括场景、Synthetic to Real 和天气适应）都超过了现有的领先方法。代码将会被发布。》Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form as well.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Attacks-and-Defenses-on-3D-Point-Cloud-Classification-A-Survey"><a href="#Adversarial-Attacks-and-Defenses-on-3D-Point-Cloud-Classification-A-Survey" class="headerlink" title="Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey"></a>Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00309">http://arxiv.org/abs/2307.00309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanieh Naderi, Ivan V. Bajić</li>
<li>for: 本文主要探讨了点云分类领域中的 adversarial attack 和 defense 技术的现状，以便鼓励未来的研究。</li>
<li>methods: 本文首先介绍了反对攻击的原理和特点，然后总结了过去几年中的反对例生成方法。此外，它还分类了防御策略为输入变换、数据优化和深度模型修改。</li>
<li>results: 本文综合梳理了防御策略的效果，并提出了未来研究的一些挑战和方向。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Deep learning has successfully solved a wide range of tasks in 2D vision as a dominant AI technique. Recently, deep learning on 3D point clouds is becoming increasingly popular for addressing various tasks in this field. Despite remarkable achievements, deep learning algorithms are vulnerable to adversarial attacks. These attacks are imperceptible to the human eye but can easily fool deep neural networks in the testing and deployment stage. To encourage future research, this survey summarizes the current progress on adversarial attack and defense techniques on point cloud classification. This paper first introduces the principles and characteristics of adversarial attacks and summarizes and analyzes the adversarial example generation methods in recent years. Besides, it classifies defense strategies as input transformation, data optimization, and deep model modification. Finally, it presents several challenging issues and future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
深度学习在2D视觉任务中已经成为当今AI技术的主导者，最近它在3D点云任务中也越来越受欢迎。尽管它们已经取得了很多成就，但深度学习算法却容易受到抗击攻击。这些攻击可以让人类不可见，但可以轻松地让深度神经网络在测试和部署阶段出现错误。为鼓励未来的研究，本文将summarize了当前在点云分类领域中的抗击攻击和防御技术。本文首先介绍了抗击攻击的原则和特点，然后总结和分析了过去几年中的抗击示例生成方法。此外，它还分类了防御策略为输入转换、数据优化和深度模型修改。最后，它提出了一些挑战性的问题和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="DreamIdentity-Improved-Editability-for-Efficient-Face-identity-Preserved-Image-Generation"><a href="#DreamIdentity-Improved-Editability-for-Efficient-Face-identity-Preserved-Image-Generation" class="headerlink" title="DreamIdentity: Improved Editability for Efficient Face-identity Preserved Image Generation"></a>DreamIdentity: Improved Editability for Efficient Face-identity Preserved Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00300">http://arxiv.org/abs/2307.00300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuowei Chen, Shancheng Fang, Wei Liu, Qian He, Mengqi Huang, Yongdong Zhang, Zhendong Mao</li>
<li>for: 本研究旨在提高文本到图像模型的可编辑性，同时保持人脸identität的稳定性。</li>
<li>methods: 我们提出了一种无需优化的方法，通过学习多比例人脸特征并应用多个映射项目来直接生成文本空间中的pseudo字。此外，我们还提出了一种自适应可编辑学习方法，通过使用名人名称来构建对应的生成和修改的人脸图像对。</li>
<li>results: 我们的方法可以在不同的场景下生成快速速度下生成identity-保持的图像，并且可以增强模型的可编辑性。<details>
<summary>Abstract</summary>
While large-scale pre-trained text-to-image models can synthesize diverse and high-quality human-centric images, an intractable problem is how to preserve the face identity for conditioned face images. Existing methods either require time-consuming optimization for each face-identity or learning an efficient encoder at the cost of harming the editability of models. In this work, we present an optimization-free method for each face identity, meanwhile keeping the editability for text-to-image models. Specifically, we propose a novel face-identity encoder to learn an accurate representation of human faces, which applies multi-scale face features followed by a multi-embedding projector to directly generate the pseudo words in the text embedding space. Besides, we propose self-augmented editability learning to enhance the editability of models, which is achieved by constructing paired generated face and edited face images using celebrity names, aiming at transferring mature ability of off-the-shelf text-to-image models in celebrity faces to unseen faces. Extensive experiments show that our methods can generate identity-preserved images under different scenes at a much faster speed.
</details>
<details>
<summary>摘要</summary>
大规模预训练文本到图模型可以生成多样性和高质量的人acentric图像，但是一个不可解决的问题是如何保持人脸identidad дляconditioned face images。现有方法可以通过时间consuming的优化来保持每个face identity，但是这会对模型的可编辑性造成损害。在这种情况下，我们提出了一种不需要优化的方法，同时保持文本到图模型的可编辑性。具体来说，我们提出了一种新的人脸identidad encoder，该encoder通过多个scale的人脸特征 followed by一个多重投影器来直接生成 pseudo words在文本embedding空间中。此外，我们还提出了自然增强的可编辑性学习，该学习是通过使用celebrity名称construct paired generated face和 edited face图像来实现，以传递不visible faces的成熟能力到off-the-shelf文本到图模型中。广泛的实验表明，我们的方法可以在不同的场景下生成保持人脸identidad的图像，并且比 tradicional方法快得多。
</details></li>
</ul>
<hr>
<h2 id="AutoST-Training-free-Neural-Architecture-Search-for-Spiking-Transformers"><a href="#AutoST-Training-free-Neural-Architecture-Search-for-Spiking-Transformers" class="headerlink" title="AutoST: Training-free Neural Architecture Search for Spiking Transformers"></a>AutoST: Training-free Neural Architecture Search for Spiking Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00293">http://arxiv.org/abs/2307.00293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqing Wang, Qidong Zhao, Jinku Cui, Xu Liu, Dongkuan Xu<br>for: AutoST is designed to rapidly identify high-performance and energy-efficient Spiking Transformer architectures, addressing the limitations of traditional approaches.methods: AutoST uses Floating-Point Operations (FLOPs) as a performance metric, which is independent of model computations and training dynamics, leading to a stronger correlation with performance. Additionally, activation patterns are leveraged during initialization to estimate the energy consumption of Spiking Transformers.results: AutoST models outperform state-of-the-art manually or automatically designed SNN architectures on static and neuromorphic datasets, while significantly reducing energy consumption.<details>
<summary>Abstract</summary>
Spiking Transformers have gained considerable attention because they achieve both the energy efficiency of Spiking Neural Networks (SNNs) and the high capacity of Transformers. However, the existing Spiking Transformer architectures, derived from ANNs, exhibit a notable architectural gap, resulting in suboptimal performance compared to their ANN counterparts. Traditional approaches to discovering optimal architectures primarily rely on either manual procedures, which are time-consuming, or Neural Architecture Search (NAS) methods, which are usually expensive in terms of memory footprints and computation time. To address these limitations, we introduce AutoST, a training-free NAS method for Spiking Transformers, to rapidly identify high-performance and energy-efficient Spiking Transformer architectures. Unlike existing training-free NAS methods, which struggle with the non-differentiability and high sparsity inherent in SNNs, we propose to utilize Floating-Point Operations (FLOPs) as a performance metric, which is independent of model computations and training dynamics, leading to a stronger correlation with performance. Moreover, to enable the search for energy-efficient architectures, we leverage activation patterns during initialization to estimate the energy consumption of Spiking Transformers. Our extensive experiments show that AutoST models outperform state-of-the-art manually or automatically designed SNN architectures on static and neuromorphic datasets, while significantly reducing energy consumption.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese神经网络中的启突变换器在过去几年中获得了广泛关注，因为它们可以同时实现神经网络的能量效率和变换器的高容量。然而，现有的启突变换器架构，基于神经网络，存在一定的建筑性差距，导致其性能远低于其神经网络对应的架构。传统的最佳架构发现方法主要靠manual procedures，这些方法需要很长时间，或者使用神经网络搜索（NAS）方法，这些方法通常需要大量的存储空间和计算资源。为了解决这些限制，我们介绍了AutoST，一种无需训练的NAS方法，用于快速发现高性能和能效的启突变换器架构。与现有的无需训练NAS方法不同，我们使用操作数（FLOPs）作为性能指标，这个指标与模型计算和训练动态无关，从而具有更强的相关性。此外，为了搜索能效的架构，我们利用初始化时的活动模式来估算启突变换器的能 consumption。我们的广泛实验表明，AutoST模型在静态和 neuromorphic 数据集上都高于当前最佳手动或自动设计的神经网络架构，同时显著降低能 consumption。Note: Simplified Chinese is used here, as it is the most widely used variety of Chinese. However, if you prefer Traditional Chinese, I can also provide the translation.
</details></li>
</ul>
<hr>
<h2 id="All-in-SAM-from-Weak-Annotation-to-Pixel-wise-Nuclei-Segmentation-with-Prompt-based-Finetuning"><a href="#All-in-SAM-from-Weak-Annotation-to-Pixel-wise-Nuclei-Segmentation-with-Prompt-based-Finetuning" class="headerlink" title="All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning"></a>All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00290">http://arxiv.org/abs/2307.00290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Can Cui, Ruining Deng, Quan Liu, Tianyuan Yao, Shunxing Bao, Lucas W. Remedios, Yucheng Tang, Yuankai Huo</li>
<li>for: This paper aims to improve the efficiency of the Segment Anything Model (SAM) for biomedical image segmentation tasks by eliminating the need for manual prompts during the inference stage.</li>
<li>methods: The proposed pipeline utilizes SAM to generate pixel-level annotations from weak prompts (e.g., points, bounding boxes), which are then used to finetune the SAM segmentation model without requiring manual prompts during the inference stage.</li>
<li>results: The proposed pipeline achieved competitive performance compared to using strong pixel-wise annotated data, and surpassed the state-of-the-art (SOTA) methods in a nuclei segmentation task on the public Monuseg dataset.<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) is a recently proposed prompt-based segmentation model in a generic zero-shot segmentation approach. With the zero-shot segmentation capacity, SAM achieved impressive flexibility and precision on various segmentation tasks. However, the current pipeline requires manual prompts during the inference stage, which is still resource intensive for biomedical image segmentation. In this paper, instead of using prompts during the inference stage, we introduce a pipeline that utilizes the SAM, called all-in-SAM, through the entire AI development workflow (from annotation generation to model finetuning) without requiring manual prompts during the inference stage. Specifically, SAM is first employed to generate pixel-level annotations from weak prompts (e.g., points, bounding box). Then, the pixel-level annotations are used to finetune the SAM segmentation model rather than training from scratch. Our experimental results reveal two key findings: 1) the proposed pipeline surpasses the state-of-the-art (SOTA) methods in a nuclei segmentation task on the public Monuseg dataset, and 2) the utilization of weak and few annotations for SAM finetuning achieves competitive performance compared to using strong pixel-wise annotated data.
</details>
<details>
<summary>摘要</summary>
Segment Anything Model (SAM) 是一种最近提出的批处理基于的分割模型，可以在无预料分割的情况下实现出色的灵活性和精度。然而，现有的管道仍然需要在推理阶段手动提供批处理，这对生物医学图像分割而言仍然是资源浪费。在这篇文章中，我们提出一个管道，使用 SAM 来实现从注解生成到模型精度调整的整个人工智能开发工程，无需在推理阶段手动提供批处理。具体来说，SAM 首先用弱提示（例如，点和 bounding box）生成像素级注解。然后，这些像素级注解被用来调整 SAM 分割模型，而不是从 scratch  retrained。我们的实验结果表明了两点：1）我们的管道超过了目前最佳方法（SOTA）在公共的 Monuseg 数据集上核心分割任务中的性能；2）使用弱和少量的注解来调整 SAM 模型达到了与使用强像素级注解数据相同的性能。
</details></li>
</ul>
<hr>
<h2 id="Common-Knowledge-Learning-for-Generating-Transferable-Adversarial-Examples"><a href="#Common-Knowledge-Learning-for-Generating-Transferable-Adversarial-Examples" class="headerlink" title="Common Knowledge Learning for Generating Transferable Adversarial Examples"></a>Common Knowledge Learning for Generating Transferable Adversarial Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00274">http://arxiv.org/abs/2307.00274</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruijie Yang, Yuanfang Guo, Junfu Wang, Jiantao Zhou, Yunhong Wang<br>for:  This paper focuses on improving the adversarial transferability of transfer-based black-box attacks, where the attacker uses a substitute (source) model to generate adversarial examples for an unseen target model.methods: The proposed method uses a common knowledge learning (CKL) framework to learn better network weights for generating adversarial examples with better transferability, under fixed network architectures. The CKL framework involves constructing a multi-teacher framework where the knowledge is distilled from different teacher architectures into one student network, and imposing constraints on the gradients between the student and teacher models to alleviate the output inconsistency problem.results: The proposed method significantly improves the adversarial transferability, as demonstrated by extensive experiments.<details>
<summary>Abstract</summary>
This paper focuses on an important type of black-box attacks, i.e., transfer-based adversarial attacks, where the adversary generates adversarial examples by a substitute (source) model and utilize them to attack an unseen target model, without knowing its information. Existing methods tend to give unsatisfactory adversarial transferability when the source and target models are from different types of DNN architectures (e.g. ResNet-18 and Swin Transformer). In this paper, we observe that the above phenomenon is induced by the output inconsistency problem. To alleviate this problem while effectively utilizing the existing DNN models, we propose a common knowledge learning (CKL) framework to learn better network weights to generate adversarial examples with better transferability, under fixed network architectures. Specifically, to reduce the model-specific features and obtain better output distributions, we construct a multi-teacher framework, where the knowledge is distilled from different teacher architectures into one student network. By considering that the gradient of input is usually utilized to generated adversarial examples, we impose constraints on the gradients between the student and teacher models, to further alleviate the output inconsistency problem and enhance the adversarial transferability. Extensive experiments demonstrate that our proposed work can significantly improve the adversarial transferability.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文关注了一种重要的黑盒攻击方法，即传输基于敌意攻击，敌对方通过一个卷积神经网络（源模型）生成攻击示例，然后使用这些示例攻击一个未知的目标模型。现有的方法在不同类型的深度神经网络（DNN）模型之间存在很大的不满意的攻击传输性能。在这篇论文中，我们发现这种问题是由输出不一致问题引起的。为了解决这个问题并有效利用现有的DNN模型，我们提出了一个共同知识学习（CKL）框架，用于学习更好的网络权重，以生成更好的攻击示例，并且能够更好地传输到目标模型。具体来说，我们构建了一个多教程框架，其中知识从不同的教师模型中提取到一个学生网络中。由于通常通过输入的梯度来生成攻击示例，我们在学生和教师模型之间受限制梯度，以进一步缓解输出不一致问题，提高攻击传输性能。广泛的实验表明，我们的提议可以明显提高攻击传输性能。
</details></li>
</ul>
<hr>
<h2 id="HrSegNet-Real-time-High-Resolution-Neural-Network-with-Semantic-Guidance-for-Crack-Segmentation"><a href="#HrSegNet-Real-time-High-Resolution-Neural-Network-with-Semantic-Guidance-for-Crack-Segmentation" class="headerlink" title="HrSegNet : Real-time High-Resolution Neural Network with Semantic Guidance for Crack Segmentation"></a>HrSegNet : Real-time High-Resolution Neural Network with Semantic Guidance for Crack Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00270">http://arxiv.org/abs/2307.00270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CHDyshli/HrSegNet4CrackSegmentation">https://github.com/CHDyshli/HrSegNet4CrackSegmentation</a></li>
<li>paper_authors: Yongshang Li, Ronggui Ma, Han Liu, Gaoli Cheng</li>
<li>for: 这个研究是为了提高建筑物破损检测的精度和效率，特别是在实时应用中。</li>
<li>methods: 我们提出了一个高分辨率模型，具有semantic guidance，专门用于实时破损分类。我们的模型保持高分辨率 throughout the entire process，并使用low-resolution semantic features导引高分辨率 features的重建。我们还设计了一个简单 yet effective的方法来控制模型的计算成本，以提高效率。</li>
<li>results: 我们的模型HrSegNet在 crack dataset CrackSeg9k 上 achieves the best trade-off between efficiency and effectiveness。我们的最快模型HrSegNet-B16 在 182 FPS 上获得 78.43% mIoU，而我们的最精准模型HrSegNet-B48 在 140.3 FPS 上获得 80.32% mIoU。<details>
<summary>Abstract</summary>
Through extensive research on deep learning in recent years and its application in construction, crack detection has evolved rapidly from rough detection at the image-level and patch-level to fine-grained detection at the pixel-level, which better suits the nature of this field. Despite numerous existing studies utilizing off-the-shelf deep learning models or enhancing them, these models are not always effective or efficient in real-world applications. In order to bridge this gap, we propose a High-resolution model with Semantic guidance, specifically designed for real-time crack segmentation, referred to as HrSegNet. Our model maintains high resolution throughout the entire process, as opposed to recovering from low-resolution features to high-resolution ones, thereby maximizing the preservation of crack details. Moreover, to enhance the context information, we use low-resolution semantic features to guide the reconstruction of high-resolution features. To ensure the efficiency of the algorithm, we design a simple yet effective method to control the computation cost of the entire model by controlling the capacity of high-resolution channels, while providing the model with extremely strong scalability. Extensive quantitative and qualitative evaluations demonstrate that our proposed HrSegNet has exceptional crack segmentation capabilities, and that maintaining high resolution and semantic guidance are crucial to the final prediction. Compared to state-of-the-art segmentation models, HrSegNet achieves the best trade-off between efficiency and effectiveness. Specifically, on the crack dataset CrackSeg9k, our fastest model HrSegNet-B16 achieves a speed of 182 FPS with 78.43% mIoU, while our most accurate model HrSegNet-B48 achieves 80.32% mIoU with an inference speed of 140.3 FPS.
</details>
<details>
<summary>摘要</summary>
随着深度学习在近年的研究和应用于建筑领域的扩展，从图像级和补充级到像素级的裂隙检测技术快速发展，更加适应建筑领域的特点。 despite numerous existing studies using off-the-shelf deep learning models or enhancing them, these models are not always effective or efficient in real-world applications. To bridge this gap, we propose a High-resolution model with Semantic guidance, specifically designed for real-time crack segmentation, referred to as HrSegNet. Our model maintains high resolution throughout the entire process, as opposed to recovering from low-resolution features to high-resolution ones, thereby maximizing the preservation of crack details. Moreover, to enhance the context information, we use low-resolution semantic features to guide the reconstruction of high-resolution features. To ensure the efficiency of the algorithm, we design a simple yet effective method to control the computation cost of the entire model by controlling the capacity of high-resolution channels, while providing the model with extremely strong scalability. Extensive quantitative and qualitative evaluations demonstrate that our proposed HrSegNet has exceptional crack segmentation capabilities, and that maintaining high resolution and semantic guidance are crucial to the final prediction. Compared to state-of-the-art segmentation models, HrSegNet achieves the best trade-off between efficiency and effectiveness. Specifically, on the crack dataset CrackSeg9k, our fastest model HrSegNet-B16 achieves a speed of 182 FPS with 78.43% mIoU, while our most accurate model HrSegNet-B48 achieves 80.32% mIoU with an inference speed of 140.3 FPS.
</details></li>
</ul>
<hr>
<h2 id="AE-RED-A-Hyperspectral-Unmixing-Framework-Powered-by-Deep-Autoencoder-and-Regularization-by-Denoising"><a href="#AE-RED-A-Hyperspectral-Unmixing-Framework-Powered-by-Deep-Autoencoder-and-Regularization-by-Denoising" class="headerlink" title="AE-RED: A Hyperspectral Unmixing Framework Powered by Deep Autoencoder and Regularization by Denoising"></a>AE-RED: A Hyperspectral Unmixing Framework Powered by Deep Autoencoder and Regularization by Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00269">http://arxiv.org/abs/2307.00269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Zhao, Jie Chen, Nicolas Dobigeon</li>
<li>for:  This paper is written for the purpose of proposing a novel framework for spectral unmixing, which integrates autoencoder networks with regularization by denoising (RED) to enhance the unmixing performance.</li>
<li>methods: The paper uses a generic unmixing framework that combines deep autoencoder networks with regularization by denoising (RED) to solve the blind unmixing problem. The framework consists of two subproblems: the first one is solved using deep autoencoders to implicitly regularize the estimates and model the mixture mechanism, while the second one leverages denoising techniques to bring in explicit information.</li>
<li>results: The paper reports superior unmixing performance compared to state-of-the-art approaches on both synthetic and real data sets. The proposed framework is able to effectively integrate the advantages of deep autoencoder based unmixing methods and priors provided by denoisers, leading to improved unmixing results.<details>
<summary>Abstract</summary>
Spectral unmixing has been extensively studied with a variety of methods and used in many applications. Recently, data-driven techniques with deep learning methods have obtained great attention to spectral unmixing for its superior learning ability to automatically learn the structure information. In particular, autoencoder based architectures are elaborately designed to solve blind unmixing and model complex nonlinear mixtures. Nevertheless, these methods perform unmixing task as blackboxes and lack of interpretability. On the other hand, conventional unmixing methods carefully design the regularizer to add explicit information, in which algorithms such as plug-and-play (PnP) strategies utilize off-the-shelf denoisers to plug powerful priors. In this paper, we propose a generic unmixing framework to integrate the autoencoder network with regularization by denoising (RED), named AE-RED. More specially, we decompose the unmixing optimized problem into two subproblems. The first one is solved using deep autoencoders to implicitly regularize the estimates and model the mixture mechanism. The second one leverages the denoiser to bring in the explicit information. In this way, both the characteristics of the deep autoencoder based unmixing methods and priors provided by denoisers are merged into our well-designed framework to enhance the unmixing performance. Experiment results on both synthetic and real data sets show the superiority of our proposed framework compared with state-of-the-art unmixing approaches.
</details>
<details>
<summary>摘要</summary>
On the other hand, conventional unmixing methods use carefully designed regularizers to add explicit information. Algorithms such as plug-and-play (PnP) strategies use off-the-shelf denoisers to plug powerful priors. In this paper, we propose a generic unmixing framework that integrates autoencoder networks with regularization by denoising (RED), called AE-RED.We decompose the unmixing optimized problem into two subproblems. The first one is solved using deep autoencoders to implicitly regularize the estimates and model the mixture mechanism. The second one leverages the denoiser to bring in explicit information. By merging the characteristics of deep autoencoder-based unmixing methods and the priors provided by denoisers, our well-designed framework can enhance the unmixing performance.Experiment results on both synthetic and real data sets show the superiority of our proposed framework compared with state-of-the-art unmixing approaches.
</details></li>
</ul>
<hr>
<h2 id="Deep-Angiogram-Trivializing-Retinal-Vessel-Segmentation"><a href="#Deep-Angiogram-Trivializing-Retinal-Vessel-Segmentation" class="headerlink" title="Deep Angiogram: Trivializing Retinal Vessel Segmentation"></a>Deep Angiogram: Trivializing Retinal Vessel Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00245">http://arxiv.org/abs/2307.00245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dewei Hu, Xing Yao, Jiacheng Wang, Yuankai K. Tao, Ipek Oguz</li>
<li>for: 本研究旨在提出一种可以Robustly分割血管的深度学习模型，以便在不同的域域中进行血管分割。</li>
<li>methods: 该模型使用了对比强化自适应网络，可以过滤不相关的特征并生成一个深度图像，表示血管。然后通过阈值处理，可以实现血管分割。</li>
<li>results: 对比基eline模型，该模型在不同的目标域域上能够提供更高的分割性能，并且可以生成稳定的血管图像，提供非侵入性、安全的替代方案。<details>
<summary>Abstract</summary>
Among the research efforts to segment the retinal vasculature from fundus images, deep learning models consistently achieve superior performance. However, this data-driven approach is very sensitive to domain shifts. For fundus images, such data distribution changes can easily be caused by variations in illumination conditions as well as the presence of disease-related features such as hemorrhages and drusen. Since the source domain may not include all possible types of pathological cases, a model that can robustly recognize vessels on unseen domains is desirable but remains elusive, despite many proposed segmentation networks of ever-increasing complexity. In this work, we propose a contrastive variational auto-encoder that can filter out irrelevant features and synthesize a latent image, named deep angiogram, representing only the retinal vessels. Then segmentation can be readily accomplished by thresholding the deep angiogram. The generalizability of the synthetic network is improved by the contrastive loss that makes the model less sensitive to variations of image contrast and noisy features. Compared to baseline deep segmentation networks, our model achieves higher segmentation performance via simple thresholding. Our experiments show that the model can generate stable angiograms on different target domains, providing excellent visualization of vessels and a non-invasive, safe alternative to fluorescein angiography.
</details>
<details>
<summary>摘要</summary>
Among the research efforts to segment the retinal vasculature from fundus images, deep learning models consistently achieve superior performance. However, this data-driven approach is very sensitive to domain shifts. For fundus images, such data distribution changes can easily be caused by variations in illumination conditions as well as the presence of disease-related features such as hemorrhages and drusen. Since the source domain may not include all possible types of pathological cases, a model that can robustly recognize vessels on unseen domains is desirable but remains elusive, despite many proposed segmentation networks of ever-increasing complexity. In this work, we propose a contrastive variational auto-encoder that can filter out irrelevant features and synthesize a latent image, named deep angiogram, representing only the retinal vessels. Then segmentation can be readily accomplished by thresholding the deep angiogram. The generalizability of the synthetic network is improved by the contrastive loss that makes the model less sensitive to variations of image contrast and noisy features. Compared to baseline deep segmentation networks, our model achieves higher segmentation performance via simple thresholding. Our experiments show that the model can generate stable angiograms on different target domains, providing excellent visualization of vessels and a non-invasive, safe alternative to fluorescein angiography.Here is a word-for-word translation of the text into Simplified Chinese:在血管胶层图像分割方面，深度学习模型一直表现出超越性能。然而，这种数据驱动的方法对域Shift非常敏感。对于胶层图像，这种数据分布变化可以轻松地由照明条件的变化以及疾病相关特征所致。因为源领域可能不包含所有可能的疾病情况，一个可以在未seen域中坚定地识别血管的模型是极其愿望的，但尚未实现。在这项工作中，我们提出了一种对比吸引变换自动编码器，可以筛选出无关的特征，并生成一个含有只有血管的潜在图像，称为深度血管图像。然后，可以通过resholding这个深度血管图像来进行分割。对于基线深度分割网络，我们的模型可以通过简单的阈值设定来实现更高的分割性能。我们的实验表明，模型可以在不同的目标域上稳定生成安全、不侵入的抗颜色气体抑血管图像，提供出色的血管视化和替代吸入气体抑血管报告的非侵入、安全的选择。
</details></li>
</ul>
<hr>
<h2 id="S-Omninet-Structured-Data-Enhanced-Universal-Multimodal-Learning-Architecture"><a href="#S-Omninet-Structured-Data-Enhanced-Universal-Multimodal-Learning-Architecture" class="headerlink" title="S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture"></a>S-Omninet: Structured Data Enhanced Universal Multimodal Learning Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00226">http://arxiv.org/abs/2307.00226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Xue, Diego Klabjan, Jean Utke</li>
<li>for: 这篇论文主要是关于多模态多任务学习，强调在不同频谱和结构数据上学习多种任务的能力。</li>
<li>methods: 该论文提出了一种名为Structured-data-enhanced Omninet（S-Omninet）的新型多模态模型，通过跨缓存注意力和嵌入patch来增强视觉特征表示，同时支持结构数据。</li>
<li>results: 对多个多模态数据集进行测试，S-Omninet模型表现出了明显的改善，较基eline模型Omninet具有更好的学习能力和灵活性。<details>
<summary>Abstract</summary>
Multimodal multitask learning has attracted an increasing interest in recent years. Singlemodal models have been advancing rapidly and have achieved astonishing results on various tasks across multiple domains. Multimodal learning offers opportunities for further improvements by integrating data from multiple modalities. Many methods are proposed to learn on a specific type of multimodal data, such as vision and language data. A few of them are designed to handle several modalities and tasks at a time. In this work, we extend and improve Omninet, an architecture that is capable of handling multiple modalities and tasks at a time, by introducing cross-cache attention, integrating patch embeddings for vision inputs, and supporting structured data. The proposed Structured-data-enhanced Omninet (S-Omninet) is a universal model that is capable of learning from structured data of various dimensions effectively with unstructured data through cross-cache attention, which enables interactions among spatial, temporal, and structured features. We also enhance spatial representations in a spatial cache with patch embeddings. We evaluate the proposed model on several multimodal datasets and demonstrate a significant improvement over the baseline, Omninet.
</details>
<details>
<summary>摘要</summary>
多modal多任务学习在最近几年内受到了越来越多的关注。单modal模型在不同领域的多种任务上取得了非常出色的成绩。多modal学习具有融合多种数据的机会，可以进一步提高模型的性能。许多方法是为了处理特定类型的多modal数据而提出，其中一些可以同时处理多个模式和任务。在这个工作中，我们扩展并改进了Omninet架构，该架构可以同时处理多个模式和任务。我们引入了交叉缓存注意力，将视觉输入集成到缓存中，并支持结构化数据。我们称之为Structured-data-enhanced Omninet（S-Omninet）。该模型可以有效地从结构化数据中学习，并且可以通过交叉缓存注意力和覆盖式嵌入来实现视觉特征的增强。我们在多个多modal数据集上评估了提议模型，并证明了与基线模型Omninet相比有显著的提高。
</details></li>
</ul>
<hr>
<h2 id="StyleStegan-Leak-free-Style-Transfer-Based-on-Feature-Steganography"><a href="#StyleStegan-Leak-free-Style-Transfer-Based-on-Feature-Steganography" class="headerlink" title="StyleStegan: Leak-free Style Transfer Based on Feature Steganography"></a>StyleStegan: Leak-free Style Transfer Based on Feature Steganography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00225">http://arxiv.org/abs/2307.00225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiujian Liang, Bingshan Liu, Qichao Ying, Zhenxing Qian, Xinpeng Zhang</li>
<li>for: 解决现代社交媒体中存在的内容泄露问题，以便实现序列和反向的风格传递。</li>
<li>methods: 基于特征隐写技术的风格传递方法，包括两个主要组成部分：风格传递方法和图像隐写方法。</li>
<li>results: 对公共可用数据集MS-COCO和Wikiart进行了全面的实验验证，结果显示StyleStegan成功解决了风格传递中的内容泄露问题，相比于一个不优化的基线模型，SSIM表现指标在序列和反向风格传递任务中分别提高了14.98%和7.28%。<details>
<summary>Abstract</summary>
In modern social networks, existing style transfer methods suffer from a serious content leakage issue, which hampers the ability to achieve serial and reversible stylization, thereby hindering the further propagation of stylized images in social networks. To address this problem, we propose a leak-free style transfer method based on feature steganography. Our method consists of two main components: a style transfer method that accomplishes artistic stylization on the original image and an image steganography method that embeds content feature secrets on the stylized image. The main contributions of our work are as follows: 1) We identify and explain the phenomenon of content leakage and its underlying causes, which arise from content inconsistencies between the original image and its subsequent stylized image. 2) We design a neural flow model for achieving loss-free and biased-free style transfer. 3) We introduce steganography to hide content feature information on the stylized image and control the subsequent usage rights. 4) We conduct comprehensive experimental validation using publicly available datasets MS-COCO and Wikiart. The results demonstrate that StyleStegan successfully mitigates the content leakage issue in serial and reversible style transfer tasks. The SSIM performance metrics for these tasks are 14.98% and 7.28% higher, respectively, compared to a suboptimal baseline model.
</details>
<details>
<summary>摘要</summary>
现代社交媒体中，现有的风格传输方法受到严重的内容泄露问题困扰，这限制了实现串行和反转的风格化，从而阻碍了更多的风格化图像在社交媒体上传播。为解决这问题，我们提出了无泄露风格传输方法基于特征隐藏。我们的方法包括两个主要组成部分：一个实现艺术风格化的风格传输方法和一个嵌入隐藏特征信息的图像隐藏方法。我们的主要贡献如下：1. 我们识别和解释内容泄露问题的现象和其根本原因，这些原因来自于图像和其后风格化图像之间的内容不一致。2. 我们设计了一个无损和偏见的风格传输模型。3. 我们引入隐藏特征信息的图像隐藏技术，以控制后续使用权限。4. 我们对公开available的MS-COCO和Wikiart dataset进行了广泛的实验验证。结果表明，StyleStegan成功解决了串行和反转风格传输任务中的内容泄露问题。对于这两个任务，我们的SSIM性能指标分别高于相对优化的基eline模型14.98%和7.28%。
</details></li>
</ul>
<hr>
<h2 id="Q-YOLO-Efficient-Inference-for-Real-time-Object-Detection"><a href="#Q-YOLO-Efficient-Inference-for-Real-time-Object-Detection" class="headerlink" title="Q-YOLO: Efficient Inference for Real-time Object Detection"></a>Q-YOLO: Efficient Inference for Real-time Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.04816">http://arxiv.org/abs/2307.04816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingze Wang, Huixin Sun, Jun Shi, Xuhui Liu, Baochang Zhang, Xianbin Cao</li>
<li>for: 本研究旨在提高资源有限的边缘设备上部署实时物体检测模型的效率，以实现实时检测而减少计算和内存占用。</li>
<li>methods: 本文提出了一种低位数量化方法，称为Q-YOLO，以构建高效的一stage检测器。Q-YOLO使用了一个完整的Post-Training Quantization（PTQ）管道，并采用了一种名为Unilateral Histogram-based（UH）活动量化方案，通过 histogram 分析，确定最大 truncation 值，以最小化 Mean Squared Error（MSE）量化错误。</li>
<li>results: 对COCO数据集进行了广泛的实验， demonstarted Q-YOLO的有效性，并在其他PTQ方法之上具有更好的平衡性，同时实现了减少计算和内存占用的实时检测。这些研究启动了资源有限边缘设备上部署物体检测模型的高效部署，以实现实时检测而减少计算和内存占用。<details>
<summary>Abstract</summary>
Real-time object detection plays a vital role in various computer vision applications. However, deploying real-time object detectors on resource-constrained platforms poses challenges due to high computational and memory requirements. This paper describes a low-bit quantization method to build a highly efficient one-stage detector, dubbed as Q-YOLO, which can effectively address the performance degradation problem caused by activation distribution imbalance in traditional quantized YOLO models. Q-YOLO introduces a fully end-to-end Post-Training Quantization (PTQ) pipeline with a well-designed Unilateral Histogram-based (UH) activation quantization scheme, which determines the maximum truncation values through histogram analysis by minimizing the Mean Squared Error (MSE) quantization errors. Extensive experiments on the COCO dataset demonstrate the effectiveness of Q-YOLO, outperforming other PTQ methods while achieving a more favorable balance between accuracy and computational cost. This research contributes to advancing the efficient deployment of object detection models on resource-limited edge devices, enabling real-time detection with reduced computational and memory overhead.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="More-for-Less-Compact-Convolutional-Transformers-Enable-Robust-Medical-Image-Classification-with-Limited-Data"><a href="#More-for-Less-Compact-Convolutional-Transformers-Enable-Robust-Medical-Image-Classification-with-Limited-Data" class="headerlink" title="More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data"></a>More for Less: Compact Convolutional Transformers Enable Robust Medical Image Classification with Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00213">http://arxiv.org/abs/2307.00213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Kean Gao</li>
<li>for: 这篇研究旨在测试Compact Convolutional Transformers（CCT）在生物医学影像分类 зада中的可行性，以扩展Transformers在生物医学领域的应用。</li>
<li>methods: 本研究使用了一种混合了 transformers 和卷积层的方法——CCT，以扩展Transformers的应用范围。</li>
<li>results: 研究获得了92.49%的类别准确率和0.9935的微 averaged ROC AUC，表明CCT在有限数据情况下可以实现高度的类别准确率。<details>
<summary>Abstract</summary>
Transformers are very powerful tools for a variety of tasks across domains, from text generation to image captioning. However, transformers require substantial amounts of training data, which is often a challenge in biomedical settings, where high quality labeled data can be challenging or expensive to obtain. This study investigates the efficacy of Compact Convolutional Transformers (CCT) for robust medical image classification with limited data, addressing a key issue faced by conventional Vision Transformers - their requirement for large datasets. A hybrid of transformers and convolutional layers, CCTs demonstrate high accuracy on modestly sized datasets. We employed a benchmark dataset of peripheral blood cell images of eight distinct cell types, each represented by approximately 2,000 low-resolution (28x28x3 pixel) samples. Despite the dataset size being smaller than those typically used with Vision Transformers, we achieved a commendable classification accuracy of 92.49% and a micro-average ROC AUC of 0.9935. The CCT also learned quickly, exceeding 80% validation accuracy after five epochs. Analysis of per-class precision, recall, F1, and ROC showed that performance was strong across cell types. Our findings underscore the robustness of CCTs, indicating their potential as a solution to data scarcity issues prevalent in biomedical imaging. We substantiate the applicability of CCTs in data-constrained areas and encourage further work on CCTs.
</details>
<details>
<summary>摘要</summary>
它们（transformers）是非常强大的工具，可以在多个领域中进行多种任务，从文本生成到图像描述。然而，transformers需要大量的训练数据，而在生物医学领域，高质量的标注数据可能困难或昂贵。这项研究探讨了Compact Convolutional Transformers（CCT）在医学图像分类中的可靠性，解决了传统的视图变换器（Vision Transformers）的问题，即它们需要大量的数据。CCT是将transformers和卷积层结合在一起的混合模型。我们使用了一个标准的血液细胞图像数据集，包含8种不同的血液细胞类型，每种类型都有约2000个低分辨率（28x28x3像素）的样本。尽管数据集的大小较小于传统使用的Vision Transformers，但我们达到了92.49%的分类精度和0.9935的微均ROC AUC。CCT还快速学习，在5个epoch后超过80%的验证精度。我们的分析表明，CCT在每个类型中的精度、回归、F1和ROC都具有强大的表现。我们的发现证明了CCT的可靠性，表明它们在数据缺乏的情况下可以作为解决方案。我们鼓励进一步的研究和应用CCTs。
</details></li>
</ul>
<hr>
<h2 id="Internal-External-Boundary-Attention-Fusion-for-Glass-Surface-Segmentation"><a href="#Internal-External-Boundary-Attention-Fusion-for-Glass-Surface-Segmentation" class="headerlink" title="Internal-External Boundary Attention Fusion for Glass Surface Segmentation"></a>Internal-External Boundary Attention Fusion for Glass Surface Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00212">http://arxiv.org/abs/2307.00212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongshen Han, Seungkyu Lee</li>
<li>for: 本研究旨在提出一种基于深度学习的玻璃表面特征描述方法，以便从单色图像中提取玻璃区域。</li>
<li>methods: 我们提出了一种基于Semantic Segmentation的方法，其中包括内部和外部边界注意模块，通过分别学习和选择玻璃表面内和外部的视觉特征来描述玻璃区域。</li>
<li>results: 我们在六个公共评测 dataset 上进行了比较，与现状的方法进行了比较，得到了出色的结果。<details>
<summary>Abstract</summary>
Glass surfaces of transparent objects and mirrors are not able to be uniquely and explicitly characterized by their visual appearances because they contain the visual appearance of other reflected or transmitted surfaces as well. Detecting glass regions from a single-color image is a challenging task. Recent deep-learning approaches have paid attention to the description of glass surface boundary where the transition of visual appearances between glass and non-glass surfaces are observed. In this work, we analytically investigate how glass surface boundary helps to characterize glass objects. Inspired by prior semantic segmentation approaches with challenging image types such as X-ray or CT scans, we propose separated internal-external boundary attention modules that individually learn and selectively integrate visual characteristics of the inside and outside region of glass surface from a single color image. Our proposed method is evaluated on six public benchmarks comparing with state-of-the-art methods showing promising results.
</details>
<details>
<summary>摘要</summary>
玻璃表面和镜子的透明物体表面无法uniquely和explicitly characterized by their visual appearances，因为它们包含了其他反射或传输的表面的视觉特征。从单一颜色图像中检测玻璃区域是一个具有挑战性的任务。现代深度学习方法已经强调描述玻璃表面边界， где视觉特征的转变可以观察到。在这项工作中，我们分析了如何使用玻璃表面边界来 caracterize glass objects。受过去的semantic segmentation方法的启发，我们提议了分开的内部外部边界注意力模块，它们分别学习和选择ively integrate玻璃表面内部和外部区域的视觉特征从单一颜色图像中。我们的提议方法在六个公共benchmark上进行了评估，与现状的方法相比显示了可塑性的结果。
</details></li>
</ul>
<hr>
<h2 id="AIGCIQA2023-A-Large-scale-Image-Quality-Assessment-Database-for-AI-Generated-Images-from-the-Perspectives-of-Quality-Authenticity-and-Correspondence"><a href="#AIGCIQA2023-A-Large-scale-Image-Quality-Assessment-Database-for-AI-Generated-Images-from-the-Perspectives-of-Quality-Authenticity-and-Correspondence" class="headerlink" title="AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI Generated Images: from the Perspectives of Quality, Authenticity and Correspondence"></a>AIGCIQA2023: A Large-scale Image Quality Assessment Database for AI Generated Images: from the Perspectives of Quality, Authenticity and Correspondence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00211">http://arxiv.org/abs/2307.00211</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangjiarui153/aigciqa2023">https://github.com/wangjiarui153/aigciqa2023</a></li>
<li>paper_authors: Jiarui Wang, Huiyu Duan, Jing Liu, Shi Chen, Xiongkuo Min, Guangtao Zhai</li>
<li>for: 这研究的目的是为了更好地了解人类对AI生成图像的视觉偏好。</li>
<li>methods: 这些研究使用了6种现状最佳的文本到图像生成模型，生成了2000多个图像，并通过一组有组织的主观试验评估人类对每个图像的质量、真实性和准确性。</li>
<li>results: 这些研究结果显示了人类对AI生成图像的视觉偏好，并对现有的IQA指标进行了评估。<details>
<summary>Abstract</summary>
In this paper, in order to get a better understanding of the human visual preferences for AIGIs, a large-scale IQA database for AIGC is established, which is named as AIGCIQA2023. We first generate over 2000 images based on 6 state-of-the-art text-to-image generation models using 100 prompts. Based on these images, a well-organized subjective experiment is conducted to assess the human visual preferences for each image from three perspectives including quality, authenticity and correspondence. Finally, based on this large-scale database, we conduct a benchmark experiment to evaluate the performance of several state-of-the-art IQA metrics on our constructed database.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，为了更好地理解人类对AIGI的视觉偏好，我们建立了一个大规模的AIGC图像评价数据库，命名为AIGCIQA2023。我们首先生成了超过2000个图像，使用100个文本生成模型，并对这些图像进行了三个视觉偏好的主观测试，包括图像质量、准确性和匹配度。最后，基于这个大规模数据库，我们进行了多种现代IQA指标的 benchmark测试，以评估它们在我们构建的数据库中的表现。
</details></li>
</ul>
<hr>
<h2 id="Filter-Pruning-for-Efficient-CNNs-via-Knowledge-driven-Differential-Filter-Sampler"><a href="#Filter-Pruning-for-Efficient-CNNs-via-Knowledge-driven-Differential-Filter-Sampler" class="headerlink" title="Filter Pruning for Efficient CNNs via Knowledge-driven Differential Filter Sampler"></a>Filter Pruning for Efficient CNNs via Knowledge-driven Differential Filter Sampler</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00198">http://arxiv.org/abs/2307.00198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osilly/kdfs">https://github.com/osilly/kdfs</a></li>
<li>paper_authors: Shaohui Lin, Wenxuan Huang, Jiao Xie, Baochang Zhang, Yunhang Shen, Zhou Yu, Jungong Han, David Doermann</li>
<li>for: 这 paper 是为了提高 Convolutional Neural Networks (CNNs) 的计算速度和内存占用量，并且可以应用于 Edge 设备和云服务。</li>
<li>methods: 这 paper 提出了一种新的 Knowledge-driven Differential Filter Sampler (KDFS) 框架，用于对 CNNs 进行filter pruning。KDFS 使用一个 learnable 抽象 sampler 来生成一个 binary mask vector  для每个层，以确定该层的 filters 是否为 redundant。</li>
<li>results: 对多个 dataset 进行了广泛的实验，显示了 KDFS 的效果性。例如，使用 KDFS 压缩 Base Model 在 ImageNet 上 achieve $55.36%$ 计算减少，$42.86%$ 参数减少，仅 dropped $0.35%$ Top-1 准确率，significantly outperforming 现有方法。<details>
<summary>Abstract</summary>
Filter pruning simultaneously accelerates the computation and reduces the memory overhead of CNNs, which can be effectively applied to edge devices and cloud services. In this paper, we propose a novel Knowledge-driven Differential Filter Sampler~(KDFS) with Masked Filter Modeling~(MFM) framework for filter pruning, which globally prunes the redundant filters based on the prior knowledge of a pre-trained model in a differential and non-alternative optimization. Specifically, we design a differential sampler with learnable sampling parameters to build a binary mask vector for each layer, determining whether the corresponding filters are redundant. To learn the mask, we introduce masked filter modeling to construct PCA-like knowledge by aligning the intermediate features from the pre-trained teacher model and the outputs of the student decoder taking sampling features as the input. The mask and sampler are directly optimized by the Gumbel-Softmax Straight-Through Gradient Estimator in an end-to-end manner in combination with global pruning constraint, MFM reconstruction error, and dark knowledge. Extensive experiments demonstrate the proposed KDFS's effectiveness in compressing the base models on various datasets. For instance, the pruned ResNet-50 on ImageNet achieves $55.36\%$ computation reduction, and $42.86\%$ parameter reduction, while only dropping $0.35\%$ Top-1 accuracy, significantly outperforming the state-of-the-art methods. The code is available at \url{https://github.com/Osilly/KDFS}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通过同时进行过滤排序和减少计算和内存开销， convolutional neural networks (CNNs) 可以更加快速和高效地进行计算。在这篇论文中，我们提出了一种新的知识驱动的差分过滤排序（KDFS）框架，用于过滤排序。该框架基于预训练模型的先验知识，并在差分和非交换的优化下进行全局减少重复的过滤器。我们设计了一种差分抽样器，用于生成每层的二进制掩码向量，以确定对应的过滤器是否为重复的。为了学习掩码，我们引入了带有掩码的过滤器模型（MFM），以构建类似于Principal Component Analysis（PCA）的知识。我们使用Gumbel-Softmax Straight-Through Gradient Estimator来直接优化抽样器和掩码，并与全局减少约束、MFM重建误差和黑知识相结合。我们对多个数据集进行了广泛的实验，并证明了我们的KDFS有效地压缩基本模型。例如，采用KDFS压缩的ResNet-50在ImageNet上达到了$55.36\%$ 的计算减少和$42.86\%$ 的参数减少，而且只有$0.35\%$ 的Top-1准确率下降，与当前的方法显著超越。代码可以在 \url{https://github.com/Osilly/KDFS} 上获取。Note: The translation is in Simplified Chinese, which is one of the two standardized Chinese languages used in mainland China. The other standardized Chinese language is Traditional Chinese, which is used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Long-Tailed-Continual-Learning-For-Visual-Food-Recognition"><a href="#Long-Tailed-Continual-Learning-For-Visual-Food-Recognition" class="headerlink" title="Long-Tailed Continual Learning For Visual Food Recognition"></a>Long-Tailed Continual Learning For Visual Food Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00183">http://arxiv.org/abs/2307.00183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangpeng He, Luotao Lin, Jack Ma, Heather A. Eicher-Miller, Fengqing Zhu</li>
<li>for: 本研究旨在解决深度学习基于食物识别中的两个主要问题，即随着时间的推移，模型需要不断学习新的食物类型而不导致已知的食物类型忘记，以及食物图像在实际生活中的分布是长尾分布，其中一些食物类型的图像比较罕见。</li>
<li>methods: 本研究提出了一种新的终端向量 continual learning 方法，用于解决上述两个问题。该方法包括一个额外的预测器来实现知识储存，以避免在 kontinual learning 过程中的表现不一致，以及一种新的数据增强技术， integrate class-activation-map (CAM) 和 CutMix，以提高对instance-rare食物类型的泛化能力。</li>
<li>results: 对比 existed 方法，提出的方法显示了大幅度的提升性能，特别是在instance-rare食物类型上。<details>
<summary>Abstract</summary>
Deep learning based food recognition has achieved remarkable progress in predicting food types given an eating occasion image. However, there are two major obstacles that hinder deployment in real world scenario. First, as new foods appear sequentially overtime, a trained model needs to learn the new classes continuously without causing catastrophic forgetting for already learned knowledge of existing food types. Second, the distribution of food images in real life is usually long-tailed as a small number of popular food types are consumed more frequently than others, which can vary in different populations. This requires the food recognition method to learn from class-imbalanced data by improving the generalization ability on instance-rare food classes. In this work, we focus on long-tailed continual learning and aim to address both aforementioned challenges. As existing long-tailed food image datasets only consider healthy people population, we introduce two new benchmark food image datasets, VFN-INSULIN and VFN-T2D, which exhibits on the real world food consumption for insulin takers and individuals with type 2 diabetes without taking insulin, respectively. We propose a novel end-to-end framework for long-tailed continual learning, which effectively addresses the catastrophic forgetting by applying an additional predictor for knowledge distillation to avoid misalignment of representation during continual learning. We also introduce a novel data augmentation technique by integrating class-activation-map (CAM) and CutMix, which significantly improves the generalization ability for instance-rare food classes to address the class-imbalance issue. The proposed method show promising performance with large margin improvements compared with existing methods.
</details>
<details>
<summary>摘要</summary>
深度学习基于食物识别已经取得了非常出色的进步，可以预测给定食物吃掉的场景图像中的食物类型。然而，现实世界中的部署受到两个主要障碍：首先，随着时间的推移，已经学习的食物类型需要不断学习新的类型，而不会导致已经学习的食物类型的恐慌性忘记。其次，食物图像在实际生活中的分布是长尾分布，食物类型的极少数是常见的，而其他类型的食物往往很少被 consume，这会影响食物识别方法的学习。在这种情况下，我们将注意力集中在长尾 continual learning 上，以解决上述两个挑战。现有的长尾食物图像数据集只考虑了健康人口，因此我们引入了两个新的标准食物图像数据集：VFN-INSULIN和VFN-T2D，它们分别表示没有服用 инсулин的糖尿病患者和服用 инсулин的糖尿病患者。我们提出了一种新的端到端框架，用于长尾 continual learning，以避免在 continual learning 过程中的恐慌性忘记。我们还引入了一种新的数据增强技术，通过 integrating class-activation-map (CAM) 和 CutMix，可以显著提高对不常见食物类型的泛化能力，以解决类别不均衡问题。我们的方法在与现有方法进行比较时表现出了大幅提升的表现。
</details></li>
</ul>
<hr>
<h2 id="Single-Stage-Heavy-Tailed-Food-Classification"><a href="#Single-Stage-Heavy-Tailed-Food-Classification" class="headerlink" title="Single-Stage Heavy-Tailed Food Classification"></a>Single-Stage Heavy-Tailed Food Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00182">http://arxiv.org/abs/2307.00182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangpeng He, Fengqing Zhu</li>
<li>for: 这个论文旨在解决实际应用中食物分类问题的两个主要障碍。</li>
<li>methods: 我们提出了一种新的单阶段（即端到端）食物分类框架，以解决严重的类别不均衡问题和单例问题。</li>
<li>results: 我们在两个重点食物数据集上进行了评估，并实现了与现有方法相比的超过5%的提升。<details>
<summary>Abstract</summary>
Deep learning based food image classification has enabled more accurate nutrition content analysis for image-based dietary assessment by predicting the types of food in eating occasion images. However, there are two major obstacles to apply food classification in real life applications. First, real life food images are usually heavy-tailed distributed, resulting in severe class-imbalance issue. Second, it is challenging to train a single-stage (i.e. end-to-end) framework under heavy-tailed data distribution, which cause the over-predictions towards head classes with rich instances and under-predictions towards tail classes with rare instance. In this work, we address both issues by introducing a novel single-stage heavy-tailed food classification framework. Our method is evaluated on two heavy-tailed food benchmark datasets, Food101-LT and VFN-LT, and achieves the best performance compared to existing work with over 5% improvements for top-1 accuracy.
</details>
<details>
<summary>摘要</summary>
深度学习基于食物图像分类已经使得食物内含营养物质的分析变得更加精准，通过预测餐厅图像中的食物类型。然而，在实际应用中存在两个主要障碍：首先，实际食物图像通常具有极端分布，导致类型分布不均匀的问题。其次，在极端数据分布下训练单 Stage（即端到端）框架是困难的，这会导致头类（即常见食物）的过度预测和尾类（即罕见食物）的下预测。在这种情况下，我们提出了一种新的单Stage极端食物分类框架。我们的方法在两个极端食物标准测试集Food101-LT和VFN-LT上进行评估，并达到了现有方法的最高性能，相对于前一个最佳方法，我们的方法实现了超过5%的提升。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Coordinate-Based-Video-Denoising"><a href="#Unsupervised-Coordinate-Based-Video-Denoising" class="headerlink" title="Unsupervised Coordinate-Based Video Denoising"></a>Unsupervised Coordinate-Based Video Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00179">http://arxiv.org/abs/2307.00179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mary Damilola Aiyetigbo, Dineshchandar Ravichandran, Reda Chalhoub, Peter Kalivas, Nianyi Li</li>
<li>for: 这个论文旨在提出一种新的无监督视频干扰深度学习方法，可以帮助解决数据缺乏问题，并且对不同干扰模式具有耐性，因此它的应用范围广泛。</li>
<li>methods: 该方法包括三个模块：特征生成器生成特征地图，干扰约束网络生成清晰但微妙的参照帧，以及重新引入高频环境细节。通过坐标基网络，我们可以大幅简化网络结构，保留高频环境细节在干扰视频帧中。</li>
<li>results: 我们在 simulated 和实际捕获的 calcium 影像视频序列上进行了广泛的实验，并证明了我们的方法可以有效地去干扰真实世界的 calcium 影像视频序列，不需要对干扰模型和数据增强进行学习和训练。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel unsupervised video denoising deep learning approach that can help to mitigate data scarcity issues and shows robustness against different noise patterns, enhancing its broad applicability. Our method comprises three modules: a Feature generator creating features maps, a Denoise-Net generating denoised but slightly blurry reference frames, and a Refine-Net re-introducing high-frequency details. By leveraging the coordinate-based network, we can greatly simplify the network structure while preserving high-frequency details in the denoised video frames. Extensive experiments on both simulated and real-captured demonstrate that our method can effectively denoise real-world calcium imaging video sequences without prior knowledge of noise models and data augmentation during training.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的无监督视频干净深度学习方法，可以帮助解决数据缺乏问题，并且对不同噪声模式具有较好的Robustness，从而扩大其应用范围。我们的方法包括三个模块：一个特征生成器生成特征地图，一个Denoi-Net生成干净但有些模糊的参照帧，以及一个Refin-Net重新引入高频环境细节。通过利用坐标基于网络，我们可以大大简化网络结构，保留高频环境细节在干净视频帧中。我们在模拟和实际捕捉的视频序列上进行了广泛的实验，证明我们的方法可以有效地干净实际 calcium 影像视频序列，不需要先知噪声模型和数据扩展 durante 训练。
</details></li>
</ul>
<hr>
<h2 id="Multiscale-Progressive-Text-Prompt-Network-for-Medical-Image-Segmentation"><a href="#Multiscale-Progressive-Text-Prompt-Network-for-Medical-Image-Segmentation" class="headerlink" title="Multiscale Progressive Text Prompt Network for Medical Image Segmentation"></a>Multiscale Progressive Text Prompt Network for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00174">http://arxiv.org/abs/2307.00174</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/codehxj/MPTPN-for--Medical-Image-Segmentation">https://github.com/codehxj/MPTPN-for--Medical-Image-Segmentation</a></li>
<li>paper_authors: Xianjun Han, Qianqian Chen, Zhaoyang Xie, Xuejun Li, Hongyu Yang<br>for:本文旨在提出一种使用进步文本提示来引导医学图像分割任务的方法，以便降低需要大量标注数据的需求，从而提高分割结果的准确性。methods:本方法包括两个阶段。第一阶段使用对自然图像进行对比学习，先使得Prompt Encoder（PPE）学习出力强大的多样性特征。第二阶段将医学图像和文本提示送入PPE，以实现下游医学图像分割任务。一个多尺度特征融合块（MSFF）将PPE中的特征融合，生成多尺度多样性特征。results:与使用仅图像不同，我们的模型可以在低数据标注成本下获得高质量结果。此外，我们的模型不仅在医学图像上具有优秀可靠性和有效性，还在自然图像上表现良好。在不同的图像数据集上进行了实验，结果表明我们的模型是有效和可靠的。<details>
<summary>Abstract</summary>
The accurate segmentation of medical images is a crucial step in obtaining reliable morphological statistics. However, training a deep neural network for this task requires a large amount of labeled data to ensure high-accuracy results. To address this issue, we propose using progressive text prompts as prior knowledge to guide the segmentation process. Our model consists of two stages. In the first stage, we perform contrastive learning on natural images to pretrain a powerful prior prompt encoder (PPE). This PPE leverages text prior prompts to generate multimodality features. In the second stage, medical image and text prior prompts are sent into the PPE inherited from the first stage to achieve the downstream medical image segmentation task. A multiscale feature fusion block (MSFF) combines the features from the PPE to produce multiscale multimodality features. These two progressive features not only bridge the semantic gap but also improve prediction accuracy. Finally, an UpAttention block refines the predicted results by merging the image and text features. This design provides a simple and accurate way to leverage multiscale progressive text prior prompts for medical image segmentation. Compared with using only images, our model achieves high-quality results with low data annotation costs. Moreover, our model not only has excellent reliability and validity on medical images but also performs well on natural images. The experimental results on different image datasets demonstrate that our model is effective and robust for image segmentation.
</details>
<details>
<summary>摘要</summary>
“精确的医疗影像分类是医疗影像评估中不可或缺的一步。然而，将深度神经网络训练 для这个任务需要大量的标注数据，以确保高精度结果。为解决这个问题，我们提出使用进步文本提示来导引分类过程。我们的模型由两个阶段组成。在第一个阶段，我们使用对自然影像进行对比学习，以预训一个具有强大能力的文本提示encoder（PPE）。这个PPE通过文本提示来生成多元特征。在第二个阶段，医疗影像和文本提示被送入PPE来完成下游医疗影像分类任务。一个多尺度特征融合块（MSFF）组合PPE生成的特征，以生成多尺度多元特征。这两个进步特征不仅bridges semantic gap，而且提高预测精度。最后，一个UpAttention块精确地调整预测结果，通过融合影像和文本特征。这个设计提供了一个简单而准确的方法，使用多尺度进步文本提示来进行医疗影像分类。相比于仅使用影像，我们的模型可以 дости得高品质结果，并且降低标注数据的成本。此外，我们的模型不仅在医疗影像上表现出色，还能够在自然影像上表现出良好的性能。实验结果表明，我们的模型是可靠和有效的 для影像分类。”
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Neural-Coding-for-Controllable-CAD-Model-Generation"><a href="#Hierarchical-Neural-Coding-for-Controllable-CAD-Model-Generation" class="headerlink" title="Hierarchical Neural Coding for Controllable CAD Model Generation"></a>Hierarchical Neural Coding for Controllable CAD Model Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00149">http://arxiv.org/abs/2307.00149</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/samxuxiang/hnc-cad">https://github.com/samxuxiang/hnc-cad</a></li>
<li>paper_authors: Xiang Xu, Pradeep Kumar Jayaraman, Joseph G. Lambourne, Karl D. D. Willis, Yasutaka Furukawa</li>
<li>for: 这 paper 的目的是提出一种新的生成模型，用于计算机支持设计 (CAD) 领域。</li>
<li>methods: 这 paper 使用了一种三级层次结构的神经网络代码，从全局部件安排下降到本地曲线几何。具体来说，使用了一种新的矢量量化 VAE  WITH “masked skip connection” 抽取设计变化。两个阶段归一化变换学习代码树从不完整的 CAD 模型中生成代码树，然后按照设计意图完成 CAD 模型。</li>
<li>results: 广泛的实验表明，这种方法在Random generation 和 conditional generation 任务上具有优秀表现，同时允许用户在设计过程中进行新的交互操作。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/samxuxiang/hnc-cad">https://github.com/samxuxiang/hnc-cad</a> 上下载。<details>
<summary>Abstract</summary>
This paper presents a novel generative model for Computer Aided Design (CAD) that 1) represents high-level design concepts of a CAD model as a three-level hierarchical tree of neural codes, from global part arrangement down to local curve geometry; and 2) controls the generation or completion of CAD models by specifying the target design using a code tree. Concretely, a novel variant of a vector quantized VAE with "masked skip connection" extracts design variations as neural codebooks at three levels. Two-stage cascaded auto-regressive transformers learn to generate code trees from incomplete CAD models and then complete CAD models following the intended design. Extensive experiments demonstrate superior performance on conventional tasks such as random generation while enabling novel interaction capabilities on conditional generation tasks. The code is available at https://github.com/samxuxiang/hnc-cad.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的生成模型，用于计算机支持设计（CAD），它可以1）将高级设计想法表示为三级层次的神经码树，从全局部件安排下到本地曲线几何; 2）通过指定目标设计来控制生成或完成CAD模型。具体来说，这种新的vector量化VAE中的"masked skip connection"抽取出设计变化的神经码书在三级层次。两个阶段的堆叠自动逆Transformers学习从部分完整的CAD模型中生成代码树，然后根据意图的设计完成CAD模型。广泛的实验表明，这种方法在Random Generation任务上具有优秀的性能，同时允许 Conditional Generation任务中的新式交互能力。代码可以在https://github.com/samxuxiang/hnc-cad中找到。
</details></li>
</ul>
<hr>
<h2 id="An-End-to-End-Review-of-Gaze-Estimation-and-its-Interactive-Applications-on-Handheld-Mobile-Devices"><a href="#An-End-to-End-Review-of-Gaze-Estimation-and-its-Interactive-Applications-on-Handheld-Mobile-Devices" class="headerlink" title="An End-to-End Review of Gaze Estimation and its Interactive Applications on Handheld Mobile Devices"></a>An End-to-End Review of Gaze Estimation and its Interactive Applications on Handheld Mobile Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00122">http://arxiv.org/abs/2307.00122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaxiong Lei, Shijing He, Mohamed Khamis, Juan Ye</li>
<li>for: 本研究目的是审查手持式移动设备上的互动系统，以视线作为单独或辅助互动模式。</li>
<li>methods: 本研究使用了视线测量技术，包括深度学习等方法，以提高视线估计精度。</li>
<li>results: 本研究给出了互动系统中视线估计的状况，包括视线测量技术、视线估计工作流程、以及深度学习等方法。<details>
<summary>Abstract</summary>
In recent years we have witnessed an increasing number of interactive systems on handheld mobile devices which utilise gaze as a single or complementary interaction modality. This trend is driven by the enhanced computational power of these devices, higher resolution and capacity of their cameras, and improved gaze estimation accuracy obtained from advanced machine learning techniques, especially in deep learning. As the literature is fast progressing, there is a pressing need to review the state of the art, delineate the boundary, and identify the key research challenges and opportunities in gaze estimation and interaction. This paper aims to serve this purpose by presenting an end-to-end holistic view in this area, from gaze capturing sensors, to gaze estimation workflows, to deep learning techniques, and to gaze interactive applications.
</details>
<details>
<summary>摘要</summary>
Recently, there has been an increasing number of interactive systems on handheld mobile devices that use gaze as a single or complementary interaction modality. This trend is driven by the enhanced computational power of these devices, the higher resolution and capacity of their cameras, and the improved gaze estimation accuracy obtained from advanced machine learning techniques, especially in deep learning. As the literature is rapidly advancing, there is a pressing need to review the state of the art, delineate the boundary, and identify the key research challenges and opportunities in gaze estimation and interaction. This paper aims to serve this purpose by presenting an end-to-end holistic view in this area, from gaze capturing sensors, to gaze estimation workflows, to deep learning techniques, and to gaze interactive applications.
</details></li>
</ul>
<hr>
<h2 id="Prompting-classes-Exploring-the-Power-of-Prompt-Class-Learning-in-Weakly-Supervised-Semantic-Segmentation"><a href="#Prompting-classes-Exploring-the-Power-of-Prompt-Class-Learning-in-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Prompting classes: Exploring the Power of Prompt Class Learning in Weakly Supervised Semantic Segmentation"></a>Prompting classes: Exploring the Power of Prompt Class Learning in Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00097">http://arxiv.org/abs/2307.00097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rb080/wss_pole">https://github.com/rb080/wss_pole</a></li>
<li>paper_authors: Balamurali Murugesan, Rukhshanda Hussain, Rajarshi Bhattacharya, Ismail Ben Ayed, Jose Dolz</li>
<li>for: 这篇论文是关于弱监督semantic segmentation（WSSS）问题的研究，旨在exploring whether prompt tuning可以提高WSSS的性能。</li>
<li>methods: 该论文使用CLIP-based模型进行预训练，然后通过 modifying text prompt来进行prompt tuning。</li>
<li>results: 研究发现，只需要修改类token的文本提示，可以对Class Activation Map（CAM）产生更大的影响，而且类token与图像真实分类结果不一定相符。基于这些发现， authors提出了一种新的PrOmpt cLass lEarning（POLE）策略，并通过广泛的实验表明该方法可以在一个常见的WSSS benchmark中达到SOTA性能。<details>
<summary>Abstract</summary>
Recently, CLIP-based approaches have exhibited remarkable performance on generalization and few-shot learning tasks, fueled by the power of contrastive language-vision pre-training. In particular, prompt tuning has emerged as an effective strategy to adapt the pre-trained language-vision models to downstream tasks by employing task-related textual tokens. Motivated by this progress, in this work we question whether other fundamental problems, such as weakly supervised semantic segmentation (WSSS), can benefit from prompt tuning. Our findings reveal two interesting observations that shed light on the impact of prompt tuning on WSSS. First, modifying only the class token of the text prompt results in a greater impact on the Class Activation Map (CAM), compared to arguably more complex strategies that optimize the context. And second, the class token associated with the image ground truth does not necessarily correspond to the category that yields the best CAM. Motivated by these observations, we introduce a novel approach based on a PrOmpt cLass lEarning (POLE) strategy. Through extensive experiments we demonstrate that our simple, yet efficient approach achieves SOTA performance in a well-known WSSS benchmark. These results highlight not only the benefits of language-vision models in WSSS but also the potential of prompt learning for this problem. The code is available at https://github.com/rB080/WSS_POLE.
</details>
<details>
<summary>摘要</summary>
近期，基于CLIP的方法在泛化和少量学习任务上表现出色，受到语言视觉预训的能力的推动。特别是在任务相关的文本渠道上进行预训，以适应下游任务的灵活性。在这种进步的推动下，我们问题是否可以利用预训来解决基本的问题，如弱监督Semantic Segmentation（WSSS）。我们的发现是，只 modify文本提示中的类token，对于Class Activation Map（CAM）产生了更大的影响，相比较复杂的策略，如上下文优化。其次，与图像真实标签相关的类token不一定是导致CAM最佳化的类别。这些发现引发了我们提出一种基于Prompt Class Learning（POLE）策略的新方法。通过广泛的实验，我们证明了我们的简单 yet efficient approach可以在一个知名的WSSS标准 bencmark中达到SOTA性能。这些结果不仅 highlight了语言视觉模型在WSSS中的优势，还提醒了预训的潜在在这个问题上的潜力。代码可以在https://github.com/rB080/WSS_POLE上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Parts-Based-Registration-Loss-for-Detecting-Knee-Joint-Areas"><a href="#A-Parts-Based-Registration-Loss-for-Detecting-Knee-Joint-Areas" class="headerlink" title="A Parts Based Registration Loss for Detecting Knee Joint Areas"></a>A Parts Based Registration Loss for Detecting Knee Joint Areas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00083">http://arxiv.org/abs/2307.00083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juha Tiirola</li>
<li>for: 本 paper 是为了提高膝关节区域进行微调的精度和效率。</li>
<li>methods: 本 paper 使用了一种基于部件损失的微调方法，其中部件是从参照图像中自动提取的抽象特征向量，并且在测试图像上鼓励相应的部件具有与参照图像中相对应的空间配置。</li>
<li>results: 本 paper 的实验结果表明，使用该微调方法可以提高膝关节区域的匹配精度和效率。<details>
<summary>Abstract</summary>
In this paper, a parts based loss is considered for finetune registering knee joint areas. Here the parts are defined as abstract feature vectors with location and they are automatically selected from a reference image. For a test image the detected parts are encouraged to have a similar spatial configuration than the corresponding parts in the reference image.
</details>
<details>
<summary>摘要</summary>
在本文中，我们考虑了基于部件的损失函数进行膝关节区域软件定制。在这里，部件被定义为抽象特征向量，其中包含位置信息。这些部件将从参照图像自动选择出来。对测试图像来说，检测到的部件将被鼓励与对应的参照图像中的部件具有类似的空间配置。
</details></li>
</ul>
<hr>
<h2 id="Situated-Cameras-Situated-Knowledges-Towards-an-Egocentric-Epistemology-for-Computer-Vision"><a href="#Situated-Cameras-Situated-Knowledges-Towards-an-Egocentric-Epistemology-for-Computer-Vision" class="headerlink" title="Situated Cameras, Situated Knowledges: Towards an Egocentric Epistemology for Computer Vision"></a>Situated Cameras, Situated Knowledges: Towards an Egocentric Epistemology for Computer Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.00064">http://arxiv.org/abs/2307.00064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Goree, David Crandall</li>
<li>for: 讲述科学知识的 feminist epistemology 和 egocentric 计算机视觉之间的关系</li>
<li>methods: 使用质量的、人类中心的方法，以补充性能指标，强调人群工作者的literal和metaphorical视角</li>
<li>results:  argued for the use of qualitative, human-centric methods as a complement to performance benchmarks, to center both the literal and metaphorical perspective of human crowd workers in CV.<details>
<summary>Abstract</summary>
In her influential 1988 paper, Situated Knowledges, Donna Haraway uses vision and perspective as a metaphor to discuss scientific knowledge. Today, egocentric computer vision discusses many of the same issues, except in a literal vision context. In this short position paper, we collapse that metaphor, and explore the interactions between feminist epistemology and egocentric CV as "Egocentric Epistemology." Using this framework, we argue for the use of qualitative, human-centric methods as a complement to performance benchmarks, to center both the literal and metaphorical perspective of human crowd workers in CV.
</details>
<details>
<summary>摘要</summary>
哈拉韦（Donna Haraway）在1988年的著名论文《固有知识》中使用视野和视点作为比喻来讨论科学知识。今天， Egocentric Computer Vision（EGOCV）讨论了这些问题，但在literal视点上。在这篇短论文中，我们将这个比喻 collapse，并探讨 feminist epistemology 和 EGOCV 之间的交互。我们 argue 使用质量的、人类中心的方法作为性能指标的补充，以中心 literal 和比喻的人群工作者的视点在 CV 中。
</details></li>
</ul>
<hr>
<h2 id="Hardwiring-ViT-Patch-Selectivity-into-CNNs-using-Patch-Mixing"><a href="#Hardwiring-ViT-Patch-Selectivity-into-CNNs-using-Patch-Mixing" class="headerlink" title="Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing"></a>Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17848">http://arxiv.org/abs/2306.17848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ariel N. Lee, Sarah Adel Bargal, Janavi Kasera, Stan Sclaroff, Kate Saenko, Nataniel Ruiz</li>
<li>For: The paper aims to investigate whether CNNs can be trained to have the same ability as ViTs to ignore out-of-context information and handle occlusions using a data augmentation method called Patch Mixing.* Methods: The paper uses Patch Mixing to train both CNNs and ViTs and assesses their performance on occlusion benchmarks.* Results: The paper finds that ViTs do not improve nor degrade when trained using Patch Mixing, but CNNs acquire new capabilities to ignore out-of-context information and improve on occlusion benchmarks.Here are the three points in Simplified Chinese:* For: 这个研究的目标是看看 whether CNNs 可以通过 Patch Mixing 数据增强方法来模拟 VITs 的忽略外 context 信息和处理 occlusion 能力。* Methods: 这个研究使用 Patch Mixing 来训练 CNNs 和 VITs，并评估它们在 occlusion  benchmarck 上的表现。* Results: 研究发现，VITs 不会因 Patch Mixing 训练而改善或下降，但是 CNNs 通过 Patch Mixing 训练获得了新的忽略外 context 信息和改善 occlusion  benchmark 的能力。<details>
<summary>Abstract</summary>
Vision transformers (ViTs) have significantly changed the computer vision landscape and have periodically exhibited superior performance in vision tasks compared to convolutional neural networks (CNNs). Although the jury is still out on which model type is superior, each has unique inductive biases that shape their learning and generalization performance. For example, ViTs have interesting properties with respect to early layer non-local feature dependence, as well as self-attention mechanisms which enhance learning flexibility, enabling them to ignore out-of-context image information more effectively. We hypothesize that this power to ignore out-of-context information (which we name $\textit{patch selectivity}$), while integrating in-context information in a non-local manner in early layers, allows ViTs to more easily handle occlusion. In this study, our aim is to see whether we can have CNNs $\textit{simulate}$ this ability of patch selectivity by effectively hardwiring this inductive bias using Patch Mixing data augmentation, which consists of inserting patches from another image onto a training image and interpolating labels between the two image classes. Specifically, we use Patch Mixing to train state-of-the-art ViTs and CNNs, assessing its impact on their ability to ignore out-of-context patches and handle natural occlusions. We find that ViTs do not improve nor degrade when trained using Patch Mixing, but CNNs acquire new capabilities to ignore out-of-context information and improve on occlusion benchmarks, leaving us to conclude that this training method is a way of simulating in CNNs the abilities that ViTs already possess. We will release our Patch Mixing implementation and proposed datasets for public use. Project page: https://arielnlee.github.io/PatchMixing/
</details>
<details>
<summary>摘要</summary>
计算机视觉领域中，视传播器（ViTs）已经发生了重大的变革，并且在视觉任务中 periodic 表现出了更高的性能比 CNNs。虽然哪个模型类型是更好的仍然是一个问题，但每种模型都具有独特的推导偏见，这些偏见会影响它们的学习和泛化性能。例如，ViTs在 early layer 非本地特征依赖方面有许多有趣的性质，同时具有自注意机制，这使得它们可以更好地忽略不相关的图像信息，并且可以更好地处理 occlusion。在本研究中，我们想要看看我们可以使 CNNs 通过有效地硬编码这种偏见来模拟 ViTs 的能力。特别是，我们使用 Patch Mixing 数据增强来训练 state-of-the-art ViTs 和 CNNs，并评估其对不相关的 patch 和自然遮挡的影响。我们发现，ViTs 不会因 Patch Mixing 训练而改善或恶化，但 CNNs 可以通过 Patch Mixing 训练获得忽略不相关信息的新能力，并在 occlusion 标准测试中提高表现。因此，我们结论认为，这种训练方法可以在 CNNs 中模拟 ViTs 所拥有的能力。我们将在项目页面上发布我们的 Patch Mixing 实现和建议的数据集。项目页面：https://arielnlee.github.io/PatchMixing/
</details></li>
</ul>
<hr>
<h2 id="Magic123-One-Image-to-High-Quality-3D-Object-Generation-Using-Both-2D-and-3D-Diffusion-Priors"><a href="#Magic123-One-Image-to-High-Quality-3D-Object-Generation-Using-Both-2D-and-3D-Diffusion-Priors" class="headerlink" title="Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors"></a>Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17843">http://arxiv.org/abs/2306.17843</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guochengqian/magic123">https://github.com/guochengqian/magic123</a></li>
<li>paper_authors: Guocheng Qian, Jinjie Mai, Abdullah Hamdi, Jian Ren, Aliaksandr Siarohin, Bing Li, Hsin-Ying Lee, Ivan Skorokhodov, Peter Wonka, Sergey Tulyakov, Bernard Ghanem</li>
<li>for: 生成从单个未处理图像中的高质量、有Texture的3D模型</li>
<li>methods: 使用两个stage的Coarse-to-fineapproach，首先优化神经辐射场生成粗糙Geometry，然后采用具有内存效率的可微分网格表示方法生成高分辨率网格</li>
<li>results: 证明在Synthetic benchmark和多种真实图像上具有显著改进，并且提供了可用于下载代码、模型和生成的3D资产的链接<details>
<summary>Abstract</summary>
We present Magic123, a two-stage coarse-to-fine approach for high-quality, textured 3D meshes generation from a single unposed image in the wild using both2D and 3D priors. In the first stage, we optimize a neural radiance field to produce a coarse geometry. In the second stage, we adopt a memory-efficient differentiable mesh representation to yield a high-resolution mesh with a visually appealing texture. In both stages, the 3D content is learned through reference view supervision and novel views guided by a combination of 2D and 3D diffusion priors. We introduce a single trade-off parameter between the 2D and 3D priors to control exploration (more imaginative) and exploitation (more precise) of the generated geometry. Additionally, we employ textual inversion and monocular depth regularization to encourage consistent appearances across views and to prevent degenerate solutions, respectively. Magic123 demonstrates a significant improvement over previous image-to-3D techniques, as validated through extensive experiments on synthetic benchmarks and diverse real-world images. Our code, models, and generated 3D assets are available at https://github.com/guochengqian/Magic123.
</details>
<details>
<summary>摘要</summary>
我们介绍Magic123，一种两阶段粗糙到细节的方法，用单张未处理图像在野外生成高质量、纹理化3D mesh。在第一阶段，我们优化神经辐射场以生成粗糙的几何体。在第二阶段，我们采用内存效率高的可 diffeomorphic mesh表示来生成高分辨率的网格，并且使用参考视图监督和2D和3D扩散约束来学习3D内容。我们引入一个单一的变量来控制2D和3D约束之间的平衡，以便在生成几何体时进行更好的探索和利用。此外，我们采用文本反转和单目深度正则化来促进视图之间的一致性和避免崩溃解决方案。Magic123在前一代图像到3D技术的基础上显著提高了性能，经过了广泛的synthetic benchmark和多种实际图像的测试。我们的代码、模型和生成的3D资产可以在https://github.com/guochengqian/Magic123中下载。
</details></li>
</ul>
<hr>
<h2 id="Federated-Ensemble-YOLOv5-A-Better-Generalized-Object-Detection-Algorithm"><a href="#Federated-Ensemble-YOLOv5-A-Better-Generalized-Object-Detection-Algorithm" class="headerlink" title="Federated Ensemble YOLOv5 - A Better Generalized Object Detection Algorithm"></a>Federated Ensemble YOLOv5 - A Better Generalized Object Detection Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17829">http://arxiv.org/abs/2306.17829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinit Hegiste, Tatjana Legler, Martin Ruskowski</li>
<li>for: 这篇研究旨在探讨 Federated Learning（FL）在物件探测中的应用，以提高模型的通用性，并与中央训练方法进行比较。</li>
<li>methods: 本研究使用 Federated Averaging（FED Avg）和 Federated SGD（FED SGD）来训练 YOLOv5 模型，并使用随机抽样法无替换地将客户端上的数据分配给不同的客户端。</li>
<li>results: 实验结果显示，使用 FL 训练的 YOLOv5 模型在测试集上显示出更高的精度和更好的通用性，尤其是在测试集中包含了两个不同的客户端数据，并且这些数据不在训练集中。这些结果表明，FL 可以被视为一种聚合算法，类似于 Bagging 和 Boosting 技术的聚合。因此，FL 不只是一种关于隐私的方法，还是一种可以提高机器学习模型的性能的方法。<details>
<summary>Abstract</summary>
Federated learning (FL) has gained significant traction as a privacy-preserving algorithm, but the underlying resembles of federated learning algorithm like Federated averaging (FED Avg) or Federated SGD (FED SGD) to ensemble learning algorithms has not been fully explored. The purpose of this paper is to examine the application of FL to object detection as a method to enhance generalizability, and to compare its performance against a centralized training approach for an object detection algorithm. Specifically, we investigate the performance of a YOLOv5 model trained using FL across multiple clients and employ a random sampling strategy without replacement, so each client holds a portion of the same dataset used for centralized training. Our experimental results showcase the superior efficiency of the FL object detector's global model in generating accurate bounding boxes for unseen objects, with the test set being a mixture of objects from two distinct clients not represented in the training dataset. These findings suggest that FL can be viewed from an ensemble algorithm perspective, akin to a synergistic blend of Bagging and Boosting techniques. As a result, FL can be seen not only as a method to enhance privacy, but also as a method to enhance the performance of a machine learning model.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Look-Remember-and-Reason-Visual-Reasoning-with-Grounded-Rationales"><a href="#Look-Remember-and-Reason-Visual-Reasoning-with-Grounded-Rationales" class="headerlink" title="Look, Remember and Reason: Visual Reasoning with Grounded Rationales"></a>Look, Remember and Reason: Visual Reasoning with Grounded Rationales</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17778">http://arxiv.org/abs/2306.17778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Reza Pourreza, Pulkit Madan, Roland Memisevic</li>
<li>for: 本研究旨在探讨大型自然语言模型在视觉理解任务中的表现，以及如何使用人类视觉解决方法来改进模型的表现。</li>
<li>methods: 本研究使用了人类视觉解决方法，即“看、记忆、理解”的三步过程，将视觉信息逐步提取并融合到理解过程中。此外，研究还引入了视觉输入的理由，以便将低级视觉能力，如物体识别和跟踪，作为副任务来增强模型的表现。</li>
<li>results: 研究表明，通过引入人类视觉解决方法和低级视觉能力，可以使现有的大型自然语言模型在多种视觉理解任务中表现竞争力强，并且在CLEVR、CATER和ACRE数据集上达到了state-of-the-art水平。<details>
<summary>Abstract</summary>
Large language models have recently shown human level performance on a variety of reasoning tasks. However, the ability of these models to perform complex visual reasoning has not been studied in detail yet. A key challenge in many visual reasoning tasks is that the visual information needs to be tightly integrated in the reasoning process. We propose to address this challenge by drawing inspiration from human visual problem solving which depends on a variety of low-level visual capabilities. It can often be cast as the three step-process of ``Look, Remember, Reason'': visual information is incrementally extracted using low-level visual routines in a step-by-step fashion until a final answer is reached. We follow the same paradigm to enable existing large language models, with minimal changes to the architecture, to solve visual reasoning problems. To this end, we introduce rationales over the visual input that allow us to integrate low-level visual capabilities, such as object recognition and tracking, as surrogate tasks. We show competitive performance on diverse visual reasoning tasks from the CLEVR, CATER, and ACRE datasets over state-of-the-art models designed specifically for these tasks.
</details>
<details>
<summary>摘要</summary>
We propose a similar approach to enable existing large language models to solve visual reasoning problems with minimal changes to the architecture. To integrate low-level visual capabilities, such as object recognition and tracking, we introduce rationales over the visual input. Our approach allows us to demonstrate competitive performance on diverse visual reasoning tasks from the CLEVR, CATER, and ACRE datasets, outperforming state-of-the-art models designed specifically for these tasks.
</details></li>
</ul>
<hr>
<h2 id="MTR-Multi-Agent-Motion-Prediction-with-Symmetric-Scene-Modeling-and-Guided-Intention-Querying"><a href="#MTR-Multi-Agent-Motion-Prediction-with-Symmetric-Scene-Modeling-and-Guided-Intention-Querying" class="headerlink" title="MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying"></a>MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2306.17770">http://arxiv.org/abs/2306.17770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sshaoshuai/mtr">https://github.com/sshaoshuai/mtr</a></li>
<li>paper_authors: Shaoshuai Shi, Li Jiang, Dengxin Dai, Bernt Schiele</li>
<li>for: 提高自动驾驶系统的预测能力，更好地理解交通参与者的行为和环境 context。</li>
<li>methods: 提出了 Motion TRansformer（MTR）框架，使用变换器编码器-解码器结构，并增加了学习目的查询，以提高fficient和准确地预测未来轨迹。</li>
<li>results: 在多种 benchmark 上达到了状态zig-zag的表现，而 MTR++ 框架在多个 agent 同时预测多modal motion 方面表现出色，超越了 MTR 框架。<details>
<summary>Abstract</summary>
Motion prediction is crucial for autonomous driving systems to understand complex driving scenarios and make informed decisions. However, this task is challenging due to the diverse behaviors of traffic participants and complex environmental contexts. In this paper, we propose Motion TRansformer (MTR) frameworks to address these challenges. The initial MTR framework utilizes a transformer encoder-decoder structure with learnable intention queries, enabling efficient and accurate prediction of future trajectories. By customizing intention queries for distinct motion modalities, MTR improves multimodal motion prediction while reducing reliance on dense goal candidates. The framework comprises two essential processes: global intention localization, identifying the agent's intent to enhance overall efficiency, and local movement refinement, adaptively refining predicted trajectories for improved accuracy. Moreover, we introduce an advanced MTR++ framework, extending the capability of MTR to simultaneously predict multimodal motion for multiple agents. MTR++ incorporates symmetric context modeling and mutually-guided intention querying modules to facilitate future behavior interaction among multiple agents, resulting in scene-compliant future trajectories. Extensive experimental results demonstrate that the MTR framework achieves state-of-the-art performance on the highly-competitive motion prediction benchmarks, while the MTR++ framework surpasses its precursor, exhibiting enhanced performance and efficiency in predicting accurate multimodal future trajectories for multiple agents.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate("Motion prediction is crucial for autonomous driving systems to understand complex driving scenarios and make informed decisions. However, this task is challenging due to the diverse behaviors of traffic participants and complex environmental contexts. In this paper, we propose Motion TRansformer (MTR) frameworks to address these challenges. The initial MTR framework utilizes a transformer encoder-decoder structure with learnable intention queries, enabling efficient and accurate prediction of future trajectories. By customizing intention queries for distinct motion modalities, MTR improves multimodal motion prediction while reducing reliance on dense goal candidates. The framework comprises two essential processes: global intention localization, identifying the agent's intent to enhance overall efficiency, and local movement refinement, adaptively refining predicted trajectories for improved accuracy. Moreover, we introduce an advanced MTR++ framework, extending the capability of MTR to simultaneously predict multimodal motion for multiple agents. MTR++ incorporates symmetric context modeling and mutually-guided intention querying modules to facilitate future behavior interaction among multiple agents, resulting in scene-compliant future trajectories. Extensive experimental results demonstrate that the MTR framework achieves state-of-the-art performance on the highly-competitive motion prediction benchmarks, while the MTR++ framework surpasses its precursor, exhibiting enhanced performance and efficiency in predicting accurate multimodal future trajectories for multiple agents.")Here's the translation:自动驾驶系统需要有效预测动向，以便更好地理解复杂的驾驶场景和做出 Informed Decisions。然而，这个任务受到交通参与者的多样化行为和环境上下文的复杂性的限制。在这篇论文中，我们提出了 Motion TRansformer（MTR）框架，以解决这些挑战。MTR使用了可学习的意图查询，以提高效率和准确性。通过对不同的动态模式进行定制意图查询，MTR可以提高多模态动向预测，同时减少依赖于稠密目标候选人。MTR框架包括两个基本过程：全局意图划定，用于提高总体效率，以及本地运动细化，用于提高预测的准确性。此外，我们还提出了 MTR++ 框架，它可以同时预测多个 Agent 的多模态动向。MTR++ 框架包括对称上下文模型和互相引导意图查询模块，以便在多个 Agent 之间互动，并生成符合场景的未来轨迹。实验结果表明，MTR 框架在高度竞争的动向预测Benchmark上 achieve state-of-the-art 性能，而 MTR++ 框架在其前一代的基础上，具有更高的性能和效率，可以准确预测多个 Agent 的多模态未来轨迹。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/01/cs.CV_2023_07_01/" data-id="cloimip7z00dhs4884ie7dr30" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/82/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/81/">81</a><a class="page-number" href="/page/82/">82</a><span class="page-number current">83</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/84/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
