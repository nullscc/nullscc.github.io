
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/46/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.IV_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/eess.IV_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T09:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/eess.IV_2023_09_08/">eess.IV - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Non-convex-regularization-based-on-shrinkage-penalty-function"><a href="#Non-convex-regularization-based-on-shrinkage-penalty-function" class="headerlink" title="Non-convex regularization based on shrinkage penalty function"></a>Non-convex regularization based on shrinkage penalty function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04593">http://arxiv.org/abs/2309.04593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manu Ghulyani, Muthuvel Arigovindan</li>
<li>for: 这种论文主要研究了一种基于第二个Derivative的图像恢复方法，以提高图像的结构保持性。</li>
<li>methods: 这种方法使用了希尔бер施泰因约数（HSN）来 regularize 图像，HSN 使用了图像的第二 Derivative，而不是图像的 Gradient，从而减少了“阶梯效应”。</li>
<li>results: 该方法可以提供更加细节和结构保持的图像恢复结果，并且比 convex 方法更加稳定。<details>
<summary>Abstract</summary>
Total Variation regularization (TV) is a seminal approach for image recovery. TV involves the norm of the image's gradient, aggregated over all pixel locations. Therefore, TV leads to piece-wise constant solutions, resulting in what is known as the "staircase effect." To mitigate this effect, the Hessian Schatten norm regularization (HSN) employs second-order derivatives, represented by the pth norm of eigenvalues in the image hessian, summed across all pixels. HSN demonstrates superior structure-preserving properties compared to TV. However, HSN solutions tend to be overly smoothed. To address this, we introduce a non-convex shrinkage penalty applied to the Hessian's eigenvalues, deviating from the convex lp norm. It is important to note that the shrinkage penalty is not defined directly in closed form, but specified indirectly through its proximal operation. This makes constructing a provably convergent algorithm difficult as the singular values are also defined through a non-linear operation. However, we were able to derive a provably convergent algorithm using proximal operations. We prove the convergence by establishing that the proposed regularization adheres to restricted proximal regularity. The images recovered by this regularization were sharper than the convex counterparts.
</details>
<details>
<summary>摘要</summary>
全Variation正规化（TV）是一种杰出的方法 для图像恢复。TV通过图像梯度的norm，在所有像素位置上进行积分，因此TV会导致piece-wise常数解，这被称为“阶梯效应”。为了 mitigate这些效应，使用第二 derivatives，表示图像Hessian的pth norm的 eigenvalues，在所有像素位置上进行积分。HSN表现出比TV更好的结构保持性。然而，HSN解决方案通常是过度熔化。为了解决这个问题，我们引入了非CONvex shrinkage penalty，应用于图像Hessian的 eigenvalues。这个 penalty不是直接定义的closed form，而是通过其proximal操作定义。这使得构建可提供 garantía de convergencia的算法变得困难，因为singular values ​​也是通过非线性操作定义。然而，我们成功地 derivated a provably convergent algorithm using proximal operations。我们证明了这种正则化的 convergencia by establishing that the proposed regularization adheres to restricted proximal regularity。图像recovered by this regularization were sharper than the convex counterparts。
</details></li>
</ul>
<hr>
<h2 id="Motion-Compensated-Unsupervised-Deep-Learning-for-5D-MRI"><a href="#Motion-Compensated-Unsupervised-Deep-Learning-for-5D-MRI" class="headerlink" title="Motion Compensated Unsupervised Deep Learning for 5D MRI"></a>Motion Compensated Unsupervised Deep Learning for 5D MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04552">http://arxiv.org/abs/2309.04552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Kettelkamp, Ludovica Romanin, Davide Piccini, Sarv Priya, Mathews Jacob</li>
<li>for: 提高5D cardiac MRI数据重建速度和质量，并且使得数据重建不再依赖于数据分割的均匀性。</li>
<li>methods: 使用无监督深度学习算法，模拟数据在每个生物频率&#x2F;呼吸频率分割中的变形。使用卷积神经网络驱动数据变形映射，并与模板共优估计。</li>
<li>results: 在5D bSSFP数据上进行了验证，并实现了更高的数据效率和质量。<details>
<summary>Abstract</summary>
We propose an unsupervised deep learning algorithm for the motion-compensated reconstruction of 5D cardiac MRI data from 3D radial acquisitions. Ungated free-breathing 5D MRI simplifies the scan planning, improves patient comfort, and offers several clinical benefits over breath-held 2D exams, including isotropic spatial resolution and the ability to reslice the data to arbitrary views. However, the current reconstruction algorithms for 5D MRI take very long computational time, and their outcome is greatly dependent on the uniformity of the binning of the acquired data into different physiological phases. The proposed algorithm is a more data-efficient alternative to current motion-resolved reconstructions. This motion-compensated approach models the data in each cardiac/respiratory bin as Fourier samples of the deformed version of a 3D image template. The deformation maps are modeled by a convolutional neural network driven by the physiological phase information. The deformation maps and the template are then jointly estimated from the measured data. The cardiac and respiratory phases are estimated from 1D navigators using an auto-encoder. The proposed algorithm is validated on 5D bSSFP datasets acquired from two subjects.
</details>
<details>
<summary>摘要</summary>
我们提议一种无监督深度学习算法，用于从3D辐射式获取的5D心脏MRI数据进行运动补做重建。无门限自由呼吸5D MRI简化扫描计划，提高了患者的 COMFORT，并提供了许多临床优势，包括均匀的空间分辨率和可以在任意视图下重新构成数据。然而，目前的5D MRI重建算法需要很长的计算时间，其结果受到数据的划分方式的均匀性影响很大。我们的算法是一种更高效的替代方案。这种运动补做方法模型了数据在每个心脏/呼吸期中的变换为Fourier样本的扭曲版本的3D图像模板。变换地图是由基于生物频率信息的卷积神经网络驱动。模板和变换地图然后从测量数据中共同估计。心脏和呼吸频率是通过1D导航器使用自动Encoder来估计。我们的算法在5D bSSFP数据集上进行验证，从两个试验者中获得了 validate。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/eess.IV_2023_09_08/" data-id="closbroy7016l0g88f6bp99dv" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/eess.SP_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T08:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/eess.SP_2023_09_08/">eess.SP - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Missing-Data-Imputation-of-Non-stationary-Signals-with-Harmonic-Decomposition"><a href="#Enhancing-Missing-Data-Imputation-of-Non-stationary-Signals-with-Harmonic-Decomposition" class="headerlink" title="Enhancing Missing Data Imputation of Non-stationary Signals with Harmonic Decomposition"></a>Enhancing Missing Data Imputation of Non-stationary Signals with Harmonic Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04630">http://arxiv.org/abs/2309.04630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joaquin Ruiz, Hau-tieng Wu, Marcelo A. Colominas</li>
<li>for: 填充时间序列中缺失值，包括受低质量或过滤影响的时间序列，是一个重要的信号处理挑战。</li>
<li>methods: 本文提出了一种新的算法，即幂等级 interpolating（HaLI），用于提高现有的填充算法的性能 для振荡时间序列。 HaLI 利用基于自适应非幂模型的幂分解来提高填充精度。</li>
<li>results: 实验结果表明，HaLI 可以有效地提高现有填充算法的性能，并且可以在实验室和实际数据上进行应用。 Matlab 代码已经公开发布，供其他研究人员使用。<details>
<summary>Abstract</summary>
Dealing with time series with missing values, including those afflicted by low quality or over-saturation, presents a significant signal processing challenge. The task of recovering these missing values, known as imputation, has led to the development of several algorithms. However, we have observed that the efficacy of these algorithms tends to diminish when the time series exhibit non-stationary oscillatory behavior. In this paper, we introduce a novel algorithm, coined Harmonic Level Interpolation (HaLI), which enhances the performance of existing imputation algorithms for oscillatory time series. After running any chosen imputation algorithm, HaLI leverages the harmonic decomposition based on the adaptive nonharmonic model of the initial imputation to improve the imputation accuracy for oscillatory time series. Experimental assessments conducted on synthetic and real signals consistently highlight that HaLI enhances the performance of existing imputation algorithms. The algorithm is made publicly available as a readily employable Matlab code for other researchers to use.
</details>
<details>
<summary>摘要</summary>
处理含有欠拟合值的时间序列是一项重要的信号处理挑战。恢复这些欠拟合值，称为填充，已经导致了许多算法的发展。然而，我们观察到了这些算法在时间序列表现非站ARY抖动行为时的效果减退。在这篇论文中，我们介绍了一种新的算法，名为响应级 interpolate（HaLI），可以提高现有填充算法对抖动时间序列的准确性。在任何选择的填充算法后，HaLI利用基于适应非幂模型的响应级分解来提高填充精度。实验评估在synthetic和实际信号上 consistently表明，HaLI可以提高现有填充算法的性能。该算法已经公开提供了可靠地使用MATLAB代码，以便其他研究人员可以使用。
</details></li>
</ul>
<hr>
<h2 id="Wi-BFI-Extracting-the-IEEE-802-11-Beamforming-Feedback-Information-from-Commercial-Wi-Fi-Devices"><a href="#Wi-BFI-Extracting-the-IEEE-802-11-Beamforming-Feedback-Information-from-Commercial-Wi-Fi-Devices" class="headerlink" title="Wi-BFI: Extracting the IEEE 802.11 Beamforming Feedback Information from Commercial Wi-Fi Devices"></a>Wi-BFI: Extracting the IEEE 802.11 Beamforming Feedback Information from Commercial Wi-Fi Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04408">http://arxiv.org/abs/2309.04408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khandaker Foysal Haque, Francesca Meneghello, Francesco Restuccia</li>
<li>for: 这篇论文是为了提供一个开源的工具来提取和解码 Wi-Fi 多输入多Output（MIMO）操作中的扫描反馈角（BFAs），以便用于不同目的，如人活动识别和设备指纹。</li>
<li>methods: 这篇论文使用了 Wi-BFI 工具，该工具可以从 BFAs 框架中提取和重建扫描反馈信息（BFI），这是压缩表示器通道频率响应（CFR）的压缩表示。工具支持在 IEEE 802.11ac 和 IEEE 802.11ax 网络中提取 BFAs，并且可以处理多用户和单用户 MIMO 反馈。</li>
<li>results: 这篇论文通过开发 Wi-BFI 工具，实现了在空中捕获 BFAs 框架后，提取和重建扫描反馈信息的功能。工具支持实时和离线提取和存储 BFAs 和 BFI，并且在实时模式下还包括一个可视化的渠道状态显示器，可以实时地更新基于收集的数据。<details>
<summary>Abstract</summary>
Recently, researchers have shown that the beamforming feedback angles (BFAs) used for Wi-Fi multiple-input multiple-output (MIMO) operations can be effectively leveraged as a proxy of the channel frequency response (CFR) for different purposes. Examples are passive human activity recognition and device fingerprinting. However, even though the BFAs report frames are sent in clear text, there is not yet a unified open-source tool to extract and decode the BFAs from the frames. To fill this gap, we developed Wi-BFI, the first tool that allows retrieving Wi-Fi BFAs and reconstructing the beamforming feedback information (BFI) - a compressed representation of the CFR - from the BFAs frames captured over the air. The tool supports BFAs extraction within both IEEE 802.11ac and 802.11ax networks operating on radio channels with 160/80/40/20 MHz bandwidth. Both multi-user and single-user MIMO feedback can be decoded through Wi-BFI. The tool supports real-time and offline extraction and storage of BFAs and BFI. The real-time mode also includes a visual representation of the channel state that continuously updates based on the collected data. Wi-BFI code is open source and the tool is also available as a pip package.
</details>
<details>
<summary>摘要</summary>
近期，研究人员发现，Wi-Fi多输入多输出（MIMO）操作中的扫描反馈角（BFAs）可以作为通道频率响应（CFR）的代理。例如，悬浮人活动识别和设备打印。although BFAs report frames are sent in clear text, there is no unified open-source tool to extract and decode the BFAs from the frames. To fill this gap, we developed Wi-BFI, the first tool that allows retrieving Wi-Fi BFAs and reconstructing the beamforming feedback information (BFI) - a compressed representation of the CFR - from the BFAs frames captured over the air. The tool supports BFAs extraction within both IEEE 802.11ac and 802.11ax networks operating on radio channels with 160/80/40/20 MHz bandwidth. Both multi-user and single-user MIMO feedback can be decoded through Wi-BFI. The tool supports real-time and offline extraction and storage of BFAs and BFI. The real-time mode also includes a visual representation of the channel state that continuously updates based on the collected data. Wi-BFI code is open source and the tool is also available as a pip package.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Codesigned-Communication-and-Radar-Systems"><a href="#Sparse-Codesigned-Communication-and-Radar-Systems" class="headerlink" title="Sparse Codesigned Communication and Radar Systems"></a>Sparse Codesigned Communication and Radar Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04362">http://arxiv.org/abs/2309.04362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, Saravanan Nagesh, Andreas Bathelt, David González G., Osvaldo Gonsa, Hans-Ludwig Bloecher</li>
<li>for: 本文旨在提出一种新的ISAC frameworks，即“简单编码通信和雷达（SCCR）”系统，该系统通过简化资源域和波形 спектrum域来编码通信和雷达信号。</li>
<li>methods: 本文使用了多种简度 robust signal processing技术，如简度 reconstruction和指标模式（IM）来应对 sparse codesign 中的挑战。</li>
<li>results: 该文提出了一种新的SCCR frameworks，并采用了简度 robust signal processing技术来应对 sparse codesign 中的挑战。<details>
<summary>Abstract</summary>
In the envisioned beyond-fifth-generation (B5G) and sixth-generation (6G) scenarios which expect massive multiple-input multiple-output (mMIMO) and high frequency communications in the millimeter-wave (mmWave) and Terahertz (THz) bands, efficiency in both energy and spectrum is of increasing significance. To that extent, a novel ISAC framework called "sparse codesigned communication and radar (SCCR)" systems is described, which codesigns both communication and radar signals by a sparsification of the resource domain and the waveform spectrum domain. This improves the spectral and energy efficiency, but at the inherent cost of missing radar spectrum and irregular beampattern, and decreased throughput and diversity. Such challenges can however be corroborated, by leveraging various sparsity-robust signal processing techniques such as sparse radar reconstruction and index modulation (IM). In light of the above, the white paper aims to outlined the proposed article which provide an overview and a novel classification of the relevant state-of-the-art (SotA) methods and the implications of the challenges in the sparse codesign of the system, followed by a variety of novel SCCR frameworks.
</details>
<details>
<summary>摘要</summary>
在预期的 beyond-fifth-generation (B5G) 和 sixth-generation (6G) enario中，massive multiple-input multiple-output (mMIMO) 和高频通信在毫米波 (mmWave) 和teraHz (THz) 频率带中的效率在不断增长。为此，一种新的ISAC frameworkscalled "sparse codesigned communication and radar (SCCR)"系统被描述，该系统在资源领域和波形频谱领域进行了简化，从而提高了spectral和能量效率，但是附加了缺失 radar 频谱和不规则扫描 patrern，以及 Throughput 和多样性的减少。这些挑战可以通过不同的简单性robust signal processing技术，如简单 radar 重建和索引修饰 (IM)，进行整合。以上所述，这份白皮书的目的是提供一份概述和state-of-the-art (SotA) 方法的新分类，以及相关挑战的implications，然后提出一些新的SCCR frameworks。
</details></li>
</ul>
<hr>
<h2 id="Design-of-a-Single-User-RIS-Aided-MISO-System-Based-on-Statistical-Channel-Knowledge"><a href="#Design-of-a-Single-User-RIS-Aided-MISO-System-Based-on-Statistical-Channel-Knowledge" class="headerlink" title="Design of a Single-User RIS-Aided MISO System Based on Statistical Channel Knowledge"></a>Design of a Single-User RIS-Aided MISO System Based on Statistical Channel Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04341">http://arxiv.org/abs/2309.04341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sadaf Syed, Dominik Semmler, Donia Ben Amor, Michael Joham, Wolfgang Utschick</li>
<li>for: 提高5G网络的spectral和能量效率，降低成本</li>
<li>methods: 利用第二 Statistics of channels，降低培训过程的复杂性</li>
<li>results: 不需要CSI估计和RIS重新配置，提高系统的实用性<details>
<summary>Abstract</summary>
Reconfigurable intelligent surface (RIS) is considered a prospective technology for beyond fifth-generation (5G) networks to improve the spectral and energy efficiency at a low cost. Prior works on the RIS mainly rely on perfect channel state information (CSI), which imposes a huge computational complexity. This work considers a single-user RIS-assisted communication system, where the second-order statistical knowledge of the channels is exploited to reduce the training overhead. We present algorithms that do not require estimation of the CSI and reconfiguration of the RIS in every channel coherence interval, which constitutes one of the most critical practical issues in an RIS-aided system.
</details>
<details>
<summary>摘要</summary>
可重配置智能表面技术（RIS）被视为 fifth-generation（5G）网络以上的可能技术，以提高频率和能量效率，而且低成本。先前的RIS研究主要基于完美的通道状态信息（CSI），这会带来巨大的计算复杂度。本工作考虑了单用户RIS协助通信系统，利用通道的第二阶统计知识来减少培训负担。我们提出了不需要CSI估计和RIS重配置每个通道幂etime的算法，这是RIS协助系统中一个最重要的实践问题。
</details></li>
</ul>
<hr>
<h2 id="On-the-performance-of-an-integrated-communication-and-localization-system-an-analytical-framework"><a href="#On-the-performance-of-an-integrated-communication-and-localization-system-an-analytical-framework" class="headerlink" title="On the performance of an integrated communication and localization system: an analytical framework"></a>On the performance of an integrated communication and localization system: an analytical framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04335">http://arxiv.org/abs/2309.04335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Gao, Haonan Hu, Jiliang Zhang, Yanliang Jin, Shugong Xu, Xiaoli Chu</li>
<li>for: 这个论文是为了研究一个综合式位置和通信（ILAC）系统的性能 bound 和通信与定位性能之间的交易。</li>
<li>methods: 作者使用时域或频域资源分配来实现通信和定位，并提出了一个分析框架来计算时域和频域资源分配下的容量损失与定位CRB损失的关系。</li>
<li>results: 实验结果验证了分析模型，并显示在具有较少的antenna数和较大的UE与gNB之间距离的场景中，频域资源分配是更有优势的，而在具有较多的antenna数和较小的UE与gNB之间距离的场景中，时域资源分配是更有优势。<details>
<summary>Abstract</summary>
Quantifying the performance bound of an integrated localization and communication (ILAC) system and the trade-off between communication and localization performance is critical. In this letter, we consider an ILAC system that can perform communication and localization via time-domain or frequency-domain resource allocation. We develop an analytical framework to derive the closed-form expression of the capacity loss versus localization Cramer-Rao lower bound (CRB) loss via time-domain and frequency-domain resource allocation. Simulation results validate the analytical model and demonstrate that frequency-domain resource allocation is preferable in scenarios with a smaller number of antennas at the next generation nodeB (gNB) and a larger distance between user equipment (UE) and gNB, while time-domain resource allocation is preferable in scenarios with a larger number of antennas and smaller distance between UE and the gNB.
</details>
<details>
<summary>摘要</summary>
要量化整合本地化和通信系统（ILAC）的性能上限和通信和定位性能之间的交易是非常重要。在本封信中，我们考虑了一个可以通过时域或频域资源分配进行通信和定位的ILAC系统。我们开发了一个分析框架，以获得通过时域和频域资源分配得到的容量损失与定位Cramer-Rao下限损失的关闭式表达。实验结果证明了分析模型，并示出在具有较少的gNB天线数和较大的UE和gNB之间的距离的场景中，频域资源分配是更佳的选择，而在具有较多的天线数和较小的UE和gNB之间的距离的场景中，时域资源分配是更佳的选择。
</details></li>
</ul>
<hr>
<h2 id="Trade-Offs-in-Decentralized-Multi-Antenna-Architectures-Sparse-Combining-Modules-for-WAX-Decomposition"><a href="#Trade-Offs-in-Decentralized-Multi-Antenna-Architectures-Sparse-Combining-Modules-for-WAX-Decomposition" class="headerlink" title="Trade-Offs in Decentralized Multi-Antenna Architectures: Sparse Combining Modules for WAX Decomposition"></a>Trade-Offs in Decentralized Multi-Antenna Architectures: Sparse Combining Modules for WAX Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04297">http://arxiv.org/abs/2309.04297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Vidal Alegría, Fredrik Rusek</li>
<li>For: This paper focuses on finding decentralized receiver architectures for centralized multi-antenna systems, with the goal of reducing the interconnection bandwidth and processing complexity between the antennas and the central processing unit (CPU).* Methods: The paper proposes using the WAX decomposition, a newly defined matrix decomposition, to achieve information-lossless processing in decentralized architectures. The authors also present several constructions for linear combining modules that can be used in the WAX decomposition, and show how these structures can facilitate decentralized calculation of the WAX decomposition.* Results: The paper obtains an information-lossless trade-off between the level of decentralization and the decentralized processing complexity, and demonstrates the effectiveness of the proposed constructions for linear combining modules in achieving this trade-off. The results show that the proposed methods can be used to efficiently implement information-lossless processing in architectures with an arbitrary level of decentralization.Here is the same information in Simplified Chinese:* For: 这篇论文关注于中心化多天线系统中的分布式接收架构，以减少天线和中央处理器（CPU）之间的连接带宽和处理复杂度。* Methods: 论文提出使用WAX分解，一种新定义的矩阵分解，以实现分布式处理中的信息无损处理。作者们还提出了多种 linear combining module 的构造，并证明这些结构可以在WAX分解中实现分布式计算。* Results: 论文取得了信息无损处理与分布式处理复杂度之间的信息损失融合，并证明了提posed constructions 可以高效地实现分布式处理中的信息无损处理。结果显示，提posed methods 可以在任意水平的分布式化环境中实现信息无损处理。<details>
<summary>Abstract</summary>
With the increase in the number of antennas at base stations (BSs), centralized multi-antenna architectures have encountered scalability problems from excessive interconnection bandwidth to the central processing unit (CPU), as well as increased processing complexity. Thus, research efforts have been directed towards finding decentralized receiver architectures where a part of the processing is performed at the antenna end (or close to it). A recent paper put forth an information-lossless trade-off between level of decentralization (inputs to CPU) and decentralized processing complexity (multiplications per antenna). This trade-off was obtained by studying a newly defined matrix decomposition--the WAX decomposition--which is directly related to the information-lossless processing that should to be applied in a general framework to exploit the trade-off. {The general framework consists of three stages: a set of decentralized filters, a linear combining module, and a processing matrix applied at the CPU; these three stages are linear transformations which can be identified with the three constituent matrices of the WAX decomposition. The previous work was unable to provide explicit constructions for linear combining modules which are valid for WAX decomposition, while it remarked the importance of these modules being sparse with 1s and 0s so they could be efficiently implemented using hardware accelerators.} In this work we present a number of constructions, as well as possible variations of them, for effectively defining linear combining modules which can be used in the WAX decomposition. Furthermore, we show how these structures facilitate decentralized calculation of the WAX decomposition for applying information-lossless processing in architectures with an arbitrary level of decentralization.
</details>
<details>
<summary>摘要</summary>
随着基站antenna数量的增加，中央多antenna架构遇到了增加与CPU的连接带宽和处理复杂度的挑战。因此，研究者努力找到了分散式接收架构，其中一部分处理在天线端（或近它）进行。一篇最近发表的论文提出了关于分散式处理的信息产生的负担和分散式处理复杂度之间的信息产生负担至关重要的交易。这种交易是通过研究一种新的矩阵分解——WAX分解——来获得的。这个分解直接关系到应用在总体框架中的信息产生处理。在这篇论文中，我们提出了一些可以实现的构造，以及这些构造的可能的变化。此外，我们还证明了这些结构可以帮助实现分散式计算WAX分解，从而应用信息产生处理在不同水平的分散式架构中。
</details></li>
</ul>
<hr>
<h2 id="Modulation-and-Estimation-with-a-Helper"><a href="#Modulation-and-Estimation-with-a-Helper" class="headerlink" title="Modulation and Estimation with a Helper"></a>Modulation and Estimation with a Helper</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04277">http://arxiv.org/abs/2309.04277</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anatoly Khina, Neri Merhav<br>for: 本研究考虑了在添加白噪声（AWGN）通道上传输参数值的问题，其中助手可以不可预测地观察噪声，并提供有限率($R_\mathrm{h}$)的描述给发送器和接收器。methods: 我们 derive了最佳可能的 $\alpha$-次约束误差的 Achievable  bound，并证明它们在小 $\alpha$ 和低 SNR 值下协同存在。上限 bounds 基于最近提出的通道编码方案，可以有效地传输 $R_\mathrm{h}$ 位，并在同一个 AWGN 通道上传输剩下的 rate 无误损失。results: 我们then concentrate on具有发送能量限制的情况，并derive了可行性结果 для多种enario：助手只帮助发送器或接收器，并知道噪声；助手帮助发送器和接收器，并知道噪声和消息。在特定的情况下，我们证明了在通道编码任务中的错误概率会随着幂指数减少。最后，我们将这些结果翻译为关于连续时间的具有限制发送功率的AWGN通道的结果。<details>
<summary>Abstract</summary>
The problem of transmitting a parameter value over an additive white Gaussian noise (AWGN) channel is considered, where, in addition to the transmitter and the receiver, there is a helper that observes the noise non-causally and provides a description of limited rate $R_\mathrm{h}$ to the transmitter and/or the receiver. We derive upper and lower bounds on the optimal achievable $\alpha$-th moment of the estimation error and show that they coincide for small values of $\alpha$ and for low SNR values. The upper bound relies on a recently proposed channel-coding scheme that effectively conveys $R_\mathrm{h}$ bits essentially error-free and the rest of the rate - over the same AWGN channel without help, with the error-free bits allocated to the most significant bits of the quantized parameter. We then concentrate on the setting with a total transmit energy constraint, for which we derive achievability results for both channel coding and parameter modulation for several scenarios: when the helper assists only the transmitter or only the receiver and knows the noise, and when the helper assists the transmitter and/or the receiver and knows both the noise and the message. In particular, for the message-informed helper that assists both the receiver and the transmitter, it is shown that the error probability in the channel-coding task decays doubly exponentially. Finally, we translate these results to those for continuous-time power-limited AWGN channels with unconstrained bandwidth. As a byproduct, we show that the capacity with a message-informed helper that is available only at the transmitter can exceed the capacity of the same scenario when the helper knows only the noise but not the message.
</details>
<details>
<summary>摘要</summary>
问题是在加itive white Gaussian noise（AWGN）频道上传输参数值，其中助手可以不 causally 观察噪音并提供有限率 $R_\mathrm{h}$ 的描述给发送器和/或接收器。我们 deriv 最佳可能的 $\alpha$-次幂积分误差的上限和下限，并证明它们在小 $\alpha$ 和低 SNR 值时相同。上限基于最近提出的频道编码方案，可以准确地传输 $R_\mathrm{h}$ 位，并且其余的位量在同一个 AWGN 频道上无助而传输，即使是在静态频道条件下。然后，我们将注意力集中在具有总发送能力限制的情况下，并 deriv 适用于频道编码和参数模式的可行性结果。特别是，当助手协助发送器和接收器，并且知道噪音和消息时，显示了在频道编码任务中的误差概率呈双 exponential 衰减。最后，我们将这些结果翻译到连续时间的功率限制AWGN频道上的结果。作为一个副产品，我们显示了在发送器可以获得助手的情况下，容器的容量可以超过不具备消息助手的情况下的容量。
</details></li>
</ul>
<hr>
<h2 id="A-Reliable-and-Resilient-Framework-for-Multi-UAV-Mutual-Localization"><a href="#A-Reliable-and-Resilient-Framework-for-Multi-UAV-Mutual-Localization" class="headerlink" title="A Reliable and Resilient Framework for Multi-UAV Mutual Localization"></a>A Reliable and Resilient Framework for Multi-UAV Mutual Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04270">http://arxiv.org/abs/2309.04270</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Fang, Bin Han, Hans D. Schotten</li>
<li>for: 本文提出了一种可靠和安全的多无人航空器（UAV）系统对接确定方法，解决了精确定位和安全威胁的问题。</li>
<li>methods: 本文提出的解决方案包括两个关键 ком成分：移动适应梯度下降（MAGD）和时间演化异常探测（TAD）。MAGD适应gradient descent算法 Handle the configuration changes in the mutual localization system， Ensure accurate localization in dynamic scenarios。TAD 与声誉传播（RP）方案合作，探测和缓和可能的攻击，识别有恶待的UAV，提高安全性和抗击力。</li>
<li>results: numerical simulations show that the proposed solution can achieve accurate and reliable mutual localization in multiple UAV systems, even in dynamic scenarios with configuration changes. The MAGD algorithm adapts to the changes and ensures accurate localization, while the TAD and RP schemes detect and mitigate potential attacks, enhancing the security and resilience of the mutual localization.<details>
<summary>Abstract</summary>
This paper presents a robust and secure framework for achieving accurate and reliable mutual localization in multiple unmanned aerial vehicle (UAV) systems. Challenges of accurate localization and security threats are addressed and corresponding solutions are brought forth and accessed in our paper with numerical simulations. The proposed solution incorporates two key components: the Mobility Adaptive Gradient Descent (MAGD) and Time-evolving Anomaly Detectio (TAD). The MAGD adapts the gradient descent algorithm to handle the configuration changes in the mutual localization system, ensuring accurate localization in dynamic scenarios. The TAD cooperates with reputation propagation (RP) scheme to detect and mitigate potential attacks by identifying UAVs with malicious data, enhancing the security and resilience of the mutual localization
</details>
<details>
<summary>摘要</summary>
MAGD adapts the gradient descent algorithm to handle configuration changes in the mutual localization system, ensuring accurate localization in dynamic scenarios. TAD cooperates with a reputation propagation (RP) scheme to detect and mitigate potential attacks by identifying UAVs with malicious data, enhancing the security and resilience of the mutual localization.Numerical simulations are used to assess the performance of the proposed solution, demonstrating its effectiveness in achieving accurate and reliable mutual localization in multiple UAV systems. The proposed framework provides a robust and secure solution for a variety of applications, including search and rescue, environmental monitoring, and infrastructure inspection.
</details></li>
</ul>
<hr>
<h2 id="D2D-Assisted-Mobile-Edge-Computing-Optimal-Scheduling-under-Uncertain-Processing-Cycles-and-Intermittent-Communications"><a href="#D2D-Assisted-Mobile-Edge-Computing-Optimal-Scheduling-under-Uncertain-Processing-Cycles-and-Intermittent-Communications" class="headerlink" title="D2D-Assisted Mobile Edge Computing: Optimal Scheduling under Uncertain Processing Cycles and Intermittent Communications"></a>D2D-Assisted Mobile Edge Computing: Optimal Scheduling under Uncertain Processing Cycles and Intermittent Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04204">http://arxiv.org/abs/2309.04204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Deng, Zhanwei Yu, Di Yuan</li>
<li>for: 本文研究了在移动边缘计算（MEC）系统中进行任务负载卸载的协调策略，以适应实际中的不确定性和中断通信。</li>
<li>methods: 本文首先 derivates a closed-form表达式来表示在设备到设备协助下的MEC系统中任务负载成功率的平均值，然后提出了一个任务负载最大化问题（TOMP），并证明了这个问题是NP困难的。为解决这个问题，如果问题实例具有对称结构，我们提议一种基于动态计划（TSDP）的任务调度算法。对于一般情况，我们通过重新表述问题，提出了一种循环匹配算法（RMA）。</li>
<li>results: 经过性能评估，我们 validate了closed-form表达式的准确性，以及提出的算法的有效性。<details>
<summary>Abstract</summary>
Mobile edge computing (MEC) has been regarded as a promising approach to deal with explosive computation requirements by enabling cloud computing capabilities at the edge of networks. Existing models of MEC impose some strong assumptions on the known processing cycles and unintermittent communications. However, practical MEC systems are constrained by various uncertainties and intermittent communications, rendering these assumptions impractical. In view of this, we investigate how to schedule task offloading in MEC systems with uncertainties. First, we derive a closed-form expression of the average offloading success probability in a device-to-device (D2D) assisted MEC system with uncertain computation processing cycles and intermittent communications. Then, we formulate a task offloading maximization problem (TOMP), and prove that the problem is NP-hard. For problem solving, if the problem instance exhibits a symmetric structure, we propose a task scheduling algorithm based on dynamic programming (TSDP). By solving this problem instance, we derive a bound to benchmark sub-optimal algorithm. For general scenarios, by reformulating the problem, we propose a repeated matching algorithm (RMA). Finally, in performance evaluations, we validate the accuracy of the closed-form expression of the average offloading success probability by Monte Carlo simulations, as well as the effectiveness of the proposed algorithms.
</details>
<details>
<summary>摘要</summary>
Mobile edge computing (MEC) 被视为一种有前途的方法，以处理网络边缘的激增计算需求，通过在网络边缘提供云计算功能。现有的 MEC 模型假设了一些强制性的处理周期和不间断的通信，但实际的 MEC 系统受到各种不确定性和间歇性通信的限制，这些假设无法实现。为此，我们研究如何在 MEC 系统中进行任务负载卸载的调度，并对不确定性和间歇性通信进行考虑。首先，我们 deriv 一个关于 MEC 系统中设备间通信助け的 D2D 负载卸载的闭式表达式，该表达式表示设备之间的负载卸载成功率的平均值。然后，我们将任务负载卸载最大化问题（TOMP）进行形式化，并证明该问题是NP困难的。如果问题实例具有对称结构，我们提议一种基于动态编程的任务调度算法（TSDP）。通过解决这个问题实例，我们得到一个 bound 来评估不同算法的性能。对于一般场景，我们通过重新形式化问题，提议一种循环匹配算法（RMA）。最后，我们通过 Monte Carlo 仿真 validate 了关于负载卸载成功率的闭式表达式的准确性，以及我们提议的算法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Modulation-with-Energy-Detection-Diversity-Analysis-and-Experimental-Evaluation"><a href="#Spatial-Modulation-with-Energy-Detection-Diversity-Analysis-and-Experimental-Evaluation" class="headerlink" title="Spatial Modulation with Energy Detection: Diversity Analysis and Experimental Evaluation"></a>Spatial Modulation with Energy Detection: Diversity Analysis and Experimental Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04194">http://arxiv.org/abs/2309.04194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elio Faddoul, Ghassan M. Kraidy, Constantinos Psomas, Symeon Chatzinotas, Ioannis Krikidis</li>
<li>for: This paper proposes a non-coherent energy detection scheme for spatial modulation (SM) systems, which can be implemented with low complexity and is applicable for low-cost low-powered devices.</li>
<li>methods: The paper derives an energy detection metric for a multi-antenna receiver based on the maximum-likelihood (ML) criterion, and develops an analytical framework for the SM symbol error rate at high signal-to-noise ratios.</li>
<li>results: The paper shows that the proposed scheme outperforms the coherent ML receiver in certain scenarios, particularly when utilizing non-negative constellations, and provides experimental error rate measurements to validate the theoretical contribution.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文提出了一种非幂能检测方案 для空间调制（SM）系统，可以实现低复杂性并适用于低成本低功率设备。</li>
<li>methods: 论文基于最大 likelihood（ML） criterion derivation 了一种能量检测度量 для多天线接收器，并开发了一个分析性的 SM 符号错误率框架。</li>
<li>results: 论文显示，提案的方案在某些场景下比幂ML接收器更高效，特别是使用非负架构。同时，论文还提供了实验性的错误率测量来验证理论贡献。<details>
<summary>Abstract</summary>
In this paper, we present a non-coherent energy detection scheme for spatial modulation (SM) systems. In particular, the use of SM is motivated by its low-complexity implementation in comparison to multiple-input multiple-output (MIMO) systems, achieved through the activation of a single antenna during transmission. Moreover, energy detection-based communications restrict the channel state information to the magnitude of the fading gains. This consideration makes the design applicable for low-cost low-powered devices since phase estimation and its associated circuitry are avoided. We derive an energy detection metric for a multi-antenna receiver based on the maximum-likelihood (ML) criterion. By considering a biased pulse amplitude modulation, we develop an analytical framework for the SM symbol error rate at high signal-to-noise ratios. Numerical results show that the diversity order is proportional to half the number of receive antennas; this result stems from having partial receiver channel knowledge. In addition, we compare the performance of the proposed scheme with that of the coherent ML receiver and show that the SM energy detector outperforms its coherent counterpart in certain scenarios, particularly when utilizing non-negative constellations. Ultimately, we implement an SM testbed using software-defined radio devices and provide experimental error rate measurements that validate our theoretical contribution.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种非协调能量探测方案 для空间模拟（SM）系统。特别是，使用SM是因为它的实现复杂度较低于多输入多出力（MIMO）系统，通过在传输中活动单个天线来实现。此外，能量探测基于通信 restricts the channel state information to the magnitude of the fading gains，这使得设计适用于低成本低功率设备，因为 phases estimation和相关的电路都被避免。我们 derive an energy detection metric for a multi-antenna receiver based on the maximum-likelihood（ML） criterion。通过考虑偏振普朗 amplitude modulation，我们开发了一个分析框架，用于SM符号错误率的高信号噪声比例。数值结果表明，多antenna接收器的多样性顺序与接收天线数量的一半相关，这是因为它们只有部分接收器通道知识。此外，我们比较了提出的方案与协调ML接收器的性能，并显示SM能量探测器在某些场景下超过其协调对手，特别是使用非负 constellations。最后，我们使用软件定义广播设备实现SM测试床，并提供了实验性错误率测量，以 validate our theoretical contribution。
</details></li>
</ul>
<hr>
<h2 id="Double-RIS-Assisted-MIMO-Systems-Over-Spatially-Correlated-Rician-Fading-Channels-and-Finite-Scatterers"><a href="#Double-RIS-Assisted-MIMO-Systems-Over-Spatially-Correlated-Rician-Fading-Channels-and-Finite-Scatterers" class="headerlink" title="Double RIS-Assisted MIMO Systems Over Spatially Correlated Rician Fading Channels and Finite Scatterers"></a>Double RIS-Assisted MIMO Systems Over Spatially Correlated Rician Fading Channels and Finite Scatterers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04178">http://arxiv.org/abs/2309.04178</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ha An Le, Trinh Van Chien, Van Duc Nguyen, Wan Choi</li>
<li>for: 本研究探讨了双RIS协助MIMO通信系统在具有固定散射体、空间 correlate 和双折射链的情况下。</li>
<li>methods: 本研究使用了关键性信息驱动的closed form Statistical analysis，以及一种基于 Alternating Direction Method of Multipliers（ADMM）的高效 alternating optimization algorithm（AO）来解决问题。</li>
<li>results: 研究结果表明，通过jointly optimizing active precoding和combining matrices，以及passive beamforming at the double RISs，可以提高通信系统的容量和可靠性。同时，通过使用一种基于 neural network 的 end-to-end learning framework，可以控制transceiver和RISs的相位Shift，以提高符号错误率。<details>
<summary>Abstract</summary>
This paper investigates double RIS-assisted MIMO communication systems over Rician fading channels with finite scatterers, spatial correlation, and the existence of a double-scattering link between the transceiver. First, the statistical information is driven in closed form for the aggregated channels, unveiling various influences of the system and environment on the average channel power gains. Next, we study two active and passive beamforming designs corresponding to two objectives. The first problem maximizes channel capacity by jointly optimizing the active precoding and combining matrices at the transceivers and passive beamforming at the double RISs subject to the transmitting power constraint. In order to tackle the inherently non-convex issue, we propose an efficient alternating optimization algorithm (AO) based on the alternating direction method of multipliers (ADMM). The second problem enhances communication reliability by jointly training the encoder and decoder at the transceivers and the phase shifters at the RISs. Each neural network representing a system entity in an end-to-end learning framework is proposed to minimize the symbol error rate of the detected symbols by controlling the transceiver and the RISs phase shifts. Numerical results verify our analysis and demonstrate the superior improvements of phase shift designs to boost system performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Performance-Analysis-of-OTSM-under-Hardware-Impairments-in-Millimeter-Wave-Vehicular-Communication-Networks"><a href="#Performance-Analysis-of-OTSM-under-Hardware-Impairments-in-Millimeter-Wave-Vehicular-Communication-Networks" class="headerlink" title="Performance Analysis of OTSM under Hardware Impairments in Millimeter-Wave Vehicular Communication Networks"></a>Performance Analysis of OTSM under Hardware Impairments in Millimeter-Wave Vehicular Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04161">http://arxiv.org/abs/2309.04161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abed Doosti-Aref, Sapta Girish Neelam, P. R. Sahu, Xu Zhu, Ertugrul Basar, Sinem Coleri, Huseyin Arslan</li>
<li>for: 本文研究了基于orthogonal time sequency multiplexing（OTSM）的homodyne传输器在硬件障碍（HI）下的性能。</li>
<li>methods: 本文使用了Vector形式的不连续时间基准模型， derivated the system input-output relations in time、delay-time和delay-sequency（DS）domains，并 analyzed the effect of HIs on the system。</li>
<li>results: 研究结果表明，即使在HI下，OTSM仍可以与不做HICompensation（HIC）的SC波形相当，但需要HIC才能在mmWave和更高频率范围内运行。<details>
<summary>Abstract</summary>
Orthogonal time sequency multiplexing (OTSM) has been recently proposed as a single-carrier (SC) waveform offering similar bit error rate (BER) to multi-carrier orthogonal time frequency space (OTFS) modulation in doubly-spread channels under high mobilities; however, with much lower complexity making OTSM a promising candidate for low-power millimeter-wave (mmWave) vehicular communications in 6G wireless networks. In this paper, the performance of OTSM-based homodyne transceiver is explored under hardware impairments (HIs) including in-phase and quadrature imbalance (IQI), direct current offset (DCO), phase noise, power amplifier non-linearity, carrier frequency offset, and synchronization timing offset. First, the discrete-time baseband signal model is obtained in vector form under the mentioned HIs. Then, the system input-output relations are derived in time, delay-time, and delay-sequency (DS) domains in which the parameters of HIs are incorporated. Analytical studies demonstrate that noise stays white Gaussian and effective channel matrix is sparse in the DS domain under HIs. Also, DCO appears as a DC signal at receiver interfering with only the zero sequency over all delay taps in the DS domain; however, IQI redounds to self-conjugated fully-overlapping sequency interference. Simulation results reveal the fact that with no HI compensation (HIC), not only OTSM outperforms plain SC waveform but it performs close to uncompensated OTFS system; however, HIC is essentially needed for OTSM systems operating in mmWave and beyond frequency bands.
</details>
<details>
<summary>摘要</summary>
orthogonal time sequence multiplexing (OTSM) 已经被提议作为单载波形（SC）波形，在高速度频率域内提供类似的bit error rate（BER）与多载波形orthogonal time frequency space（OTFS）模ulation，但具有远低的复杂性，使其成为6G无线网络中低功率毫米波通信的有力候选人。在这篇论文中，我们研究了基于OTSM的同步receiver的性能，包括各种硬件障碍（HI）的影响，包括干扰相同和偏置（IQI）、直流偏置（DCO）、频率噪声、功率强度不对称和同步时间偏移。首先，我们获得了基于时分多谱的抽象时间基准信号模型。然后，我们 derive了系统的输入输出关系，包括时域、延迟时域和延迟序列（DS）域，并将HI参数纳入系统。分析研究表明，噪声保持白色高斯性，有效通道矩阵具有DS域中的稀疏性。此外，DCO会出现为接收器中的直流干扰，但IQI会导致自相关的完全重叠序列干扰。实验结果表明，在不进行HI修复（HIC）的情况下，OTSM不仅在干扰下超越普通SC波形，而且在HIC进行修复后，OTSM系统的性能与未修复OTFS系统几乎相同。
</details></li>
</ul>
<hr>
<h2 id="Sparse-DFT-and-WHT-Precoding-with-Iterative-Detection-for-Highly-Frequency-Selective-Channels"><a href="#Sparse-DFT-and-WHT-Precoding-with-Iterative-Detection-for-Highly-Frequency-Selective-Channels" class="headerlink" title="Sparse-DFT and WHT Precoding with Iterative Detection for Highly Frequency-Selective Channels"></a>Sparse-DFT and WHT Precoding with Iterative Detection for Highly Frequency-Selective Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04149">http://arxiv.org/abs/2309.04149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roberto Bomfin, Marwa Chafii</li>
<li>for: 这 paper 的目的是提出一种可以在高度 selecive 频率响应中提高性能和可扩展性的干扰抑制技术。</li>
<li>methods: 这 paper 使用了 Walsh-Hadamard  преобразова和 expectation propagation 接收器来解决干扰抑制问题。</li>
<li>results: 研究结果表明，提出的 SWH-Max-Log-MAP 方法在高度 selecive 频率响应中具有更好的性能和可扩展性，但对于更高的 QAM 编码器来说，其复杂性为退化。<details>
<summary>Abstract</summary>
Various precoders have been recently studied by the wireless community to combat the channel fading effects. Two prominent precoders are implemented with the discrete Fourier transform (DFT) and Walsh-Hadamard transform (WHT). The WHT precoder is implemented with less complexity since it does not need complex multiplications. Also, spreading can be applied sparsely to decrease the transceiver complexity, leading to sparse DFT (SDFT) and sparse Walsh-Hadamard (SWH). Another relevant topic is the design of iterative receivers that deal with inter-symbol-interference (ISI). In particular, many detectors based on expectation propagation (EP) have been proposed recently for channels with high levels of ISI. An alternative is the maximum a-posterior (MAP) detector, although it leads to unfeasible high complexity in many cases. In this paper, we provide a relatively low-complexity \textcolor{black}{computation} of the MAP detector for the SWH. We also propose two \textcolor{black}{feasible methods} based on the Log-MAP and Max-Log-MAP. Additionally, the DFT, SDFT and SWH precoders are compared using an EP-based receiver with one-tap FD equalization. Lastly, SWH-Max-Log-MAP is compared to the (S)DFT with EP-based receiver in terms of performance and complexity. The results show that the proposed SWH-Max-Log-MAP has a better performance and complexity trade-off for QPSK and 16-QAM under highly selective channels, but has unfeasible complexity for higher QAM orders.
</details>
<details>
<summary>摘要</summary>
各种预编码器在无线通信社区中最近被广泛研究，以抗衰变的频率响应。两种最具有优势的预编码器是使用离散傅里叶变换 (DFT) 和华尔什-哈达姆变换 (WHT)。WHT预编码器的实现更加简单，因为它不需要复杂的乘法运算。此外，可以在广播中进行稀疏扩散，从而降低传输器的复杂度，导致SDFT和SWH。另一个相关的话题是对干扰Symbol-Interference (ISI)的设计iterative接收器。特别是，许多基于期望传播 (EP) 的探测器在高度 seleктив 的通道上提出了多种方案。其中一个 altenative是最大 posterior (MAP) 探测器，尽管它在许多情况下会带来不可接受的高复杂度。在这篇文章中，我们提供了一种相对较低的计算复杂性的MAP探测器 для SWH。我们还提出了两种可行的方法，基于Log-MAP和Max-Log-MAP。此外，DFT、SDFT和SWH预编码器被EP基于接收器与一个FD平衡器进行比较。最后，SWH-Max-Log-MAP与(S)DFT和EP基于接收器的性能和复杂度进行比较。结果表明，我们提出的SWH-Max-Log-MAP在高度选择性的通道上有更好的性能和复杂度负担，但对更高的QAM频率来说，其复杂度是不可接受的。
</details></li>
</ul>
<hr>
<h2 id="Gabor-frames-and-higher-dimensional-boundaries-in-signal-analysis-on-manifolds"><a href="#Gabor-frames-and-higher-dimensional-boundaries-in-signal-analysis-on-manifolds" class="headerlink" title="Gabor frames and higher dimensional boundaries in signal analysis on manifolds"></a>Gabor frames and higher dimensional boundaries in signal analysis on manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04094">http://arxiv.org/abs/2309.04094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vasiliki Liontou, Matilde Marcolli</li>
<li>for: 该 paper 用于构造 Gabor 框架，用于检测在曲线略微流形上的信号，并且可以检测高维度边界的存在。</li>
<li>methods: 该 paper 使用 Gabor 筛子来检测信号中的高维度边界，并且可以应用于机器人配置空间中的精确约束。</li>
<li>results: 该 paper 提出了一种高维度扩展的 geometric 设置，用于研究信号分析的视觉系统中的应用。<details>
<summary>Abstract</summary>
We provide a construction of Gabor frames that encode local linearizations of a signal detected on a curved smooth manifold of arbitrary dimension, with Gabor filters that can detect the presence of higher-dimensional boundaries in the manifold signal. We describe an application in configuration spaces in robotics with sharp constrains. The construction is a higher-dimensional generalization of the geometric setting developed for the study of signal analysis in the visual cortex.
</details>
<details>
<summary>摘要</summary>
我们提供了一种构建卡波框架的方法，该框架可以编码抽象维度的流体信号在抽象维度的满意流体上的本地线性化。我们使用的卡波滤波器可以检测高维度边界的存在在流体信号中。我们描述了一种在机器人配置空间中的应用，具有锐度约束。该构建是高维度扩展的视觉系统中的 геометри Settings的更高维度扩展。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/eess.SP_2023_09_08/" data-id="closbrozl01a40g88323gf0ci" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/cs.SD_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T15:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/cs.SD_2023_09_07/">cs.SD - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Causal-Signal-Based-DCCRN-with-Overlapped-Frame-Prediction-for-Online-Speech-Enhancement"><a href="#Causal-Signal-Based-DCCRN-with-Overlapped-Frame-Prediction-for-Online-Speech-Enhancement" class="headerlink" title="Causal Signal-Based DCCRN with Overlapped-Frame Prediction for Online Speech Enhancement"></a>Causal Signal-Based DCCRN with Overlapped-Frame Prediction for Online Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03684">http://arxiv.org/abs/2309.03684</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julitta Bartolewska, Stanisław Kacprzak, Konrad Kowalczyk</li>
<li>for: 提高单频道speech干扰signal质量和理解度</li>
<li>methods: 使用signal基于的 causal DCCRN，减少look-ahead和网络参数数量</li>
<li>results: 实验结果表明，提posed模型可以与原始DCCRN相比或更好地提高speech干扰metric，同时减少缓存时间和网络参数数量约30%<details>
<summary>Abstract</summary>
The aim of speech enhancement is to improve speech signal quality and intelligibility from a noisy microphone signal. In many applications, it is crucial to enable processing with small computational complexity and minimal requirements regarding access to future signal samples (look-ahead). This paper presents signal-based causal DCCRN that improves online single-channel speech enhancement by reducing the required look-ahead and the number of network parameters. The proposed modifications include complex filtering of the signal, application of overlapped-frame prediction, causal convolutions and deconvolutions, and modification of the loss function. Results of performed experiments indicate that the proposed model with overlapped signal prediction and additional adjustments, achieves similar or better performance than the original DCCRN in terms of various speech enhancement metrics, while it reduces the latency and network parameter number by around 30%.
</details>
<details>
<summary>摘要</summary>
“Speech enhancement的目的是提高噪音干扰的语音信号质量和可理解度，从噪音抑制的 Microphone 信号中提取语音信号。在许多应用中，需要进行小型计算复杂性和未来信号样本访问的最小化处理。这篇论文提出了信号基于的 causal DCCRN，可以在线进行单 канал语音增强，从而降低了需要的 look-ahead 和网络参数数量。提议的修改包括信号复杂的滤波、重叠框预测、 causal 卷积和卷积，以及损失函数的修改。实验结果表明，提议的模型，带有重叠信号预测和其他调整，可以与原始 DCCRN 相比，在不同的语音增强指标上实现相似或更好的性能，同时降低了延迟和网络参数数量约30%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Topological-fingerprints-for-audio-identification"><a href="#Topological-fingerprints-for-audio-identification" class="headerlink" title="Topological fingerprints for audio identification"></a>Topological fingerprints for audio identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03516">http://arxiv.org/abs/2309.03516</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wreise/top_audio_id">https://github.com/wreise/top_audio_id</a></li>
<li>paper_authors: Wojciech Reise, Ximena Fernández, Maria Dominguez, Heather A. Harrington, Mariano Beguerisse-Díaz</li>
<li>for: 该研究提出了一种基于topological Audio fingerprinting的音频追踪方法，用于 Robustly 识别重复的音频轨迹。</li>
<li>methods: 该方法使用 persistente homology 对地方 spectral decompositions 的 audio signals 进行编码，使用 filtered cubical complexes 从 mel-spectrograms 计算。</li>
<li>results: 实验结果表明，该算法可以准确地检测时间对齐的音频匹配，并在 topological distortions 场景下表现出优于现有方法。<details>
<summary>Abstract</summary>
We present a topological audio fingerprinting approach for robustly identifying duplicate audio tracks. Our method applies persistent homology on local spectral decompositions of audio signals, using filtered cubical complexes computed from mel-spectrograms. By encoding the audio content in terms of local Betti curves, our topological audio fingerprints enable accurate detection of time-aligned audio matchings. Experimental results demonstrate the accuracy of our algorithm in the detection of tracks with the same audio content, even when subjected to various obfuscations. Our approach outperforms existing methods in scenarios involving topological distortions, such as time stretching and pitch shifting.
</details>
<details>
<summary>摘要</summary>
我们提出了一种适用于鲁棒识别相同音频轨的多尺度音频指纹方法。我们的方法使用稳定的多尺度空间来对音频信号进行本地特征分解，并使用缓冲的立方体复合来计算mel-spectrogram。通过将音频内容编码成本地比蒂曲线，我们的音频指纹可以准确地检测时间对齐的音频匹配。实验结果表明，我们的算法在受到不同类型的扭曲（如时间延迟和调高）的情况下仍然能够准确地识别相同的音频内容。我们的方法在多尺度扭曲场景下表现出优于现有方法。
</details></li>
</ul>
<hr>
<h2 id="Simulating-room-transfer-functions-between-transducers-mounted-on-audio-devices-using-a-modified-image-source-method"><a href="#Simulating-room-transfer-functions-between-transducers-mounted-on-audio-devices-using-a-modified-image-source-method" class="headerlink" title="Simulating room transfer functions between transducers mounted on audio devices using a modified image source method"></a>Simulating room transfer functions between transducers mounted on audio devices using a modified image source method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03486">http://arxiv.org/abs/2309.03486</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audiolabs/DEISM">https://github.com/audiolabs/DEISM</a></li>
<li>paper_authors: Zeyu Xu, Adrian Herzog, Alexander Lodermeyer, Emanuël A. P. Habets, Albert G. Prinn</li>
<li>for: 这个研究旨在扩展图像源方法（ISM），以包括对房间声学的扩散效应。</li>
<li>methods: 研究使用对elesbian harmonic directivity coefficients来扩展ISM，以包括源和接收器的对话装置所导致的声学扩散效应。</li>
<li>results: 研究显示，提案的方法可以更正确地模拟房间转换函数，并且可以考虑房间内设备的大小、形状、数量和位置。<details>
<summary>Abstract</summary>
The image source method (ISM) is often used to simulate room acoustics due to its ease of use and computational efficiency. The standard ISM is limited to simulations of room impulse responses between point sources and omnidirectional receivers. In this work, the ISM is extended using spherical harmonic directivity coefficients to include acoustic diffraction effects due to source and receiver transducers mounted on physical devices, which are typically encountered in practical situations. The proposed method is verified using finite element simulations of various loudspeaker and microphone configurations in a rectangular room. It is shown that the accuracy of the proposed method is related to the sizes, shapes, number, and positions of the devices inside a room. A simplified version of the proposed method, which can significantly reduce computational effort, is also presented. The proposed method and its simplified version can simulate room transfer functions more accurately than currently available image source methods and can aid the development and evaluation of speech and acoustic signal processing algorithms, including speech enhancement, acoustic scene analysis, and acoustic parameter estimation.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用图像源方法（ISM）模拟室内声学，由于其使用 convenienceliness 和计算效率，经常被使用。标准的ISM只能模拟室内冲击响应 между点源和全irectional接收器。在这种工作中，ISM被扩展使用球面幂直强度系数，以包括声学扩散效应，源和接收器适配器在实际情况下的 mounting 会导致的。提议的方法通过rectangular room的finite element simulations of various loudspeaker and microphone configurations进行验证。结果表明，提议的方法的准确性与房间内设备的大小、形状、数量和位置有关。一种简化版的提议方法，可以减少计算努力，也被提出。提议的方法和其简化版可以更准确地模拟室内传递函数，并且可以帮助开发和评估speech和声学信号处理算法，包括speech enhancement、声学场景分析和声学参数估计。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/cs.SD_2023_09_07/" data-id="closbrotj00w10g884389a3bm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/cs.CV_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T13:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/cs.CV_2023_09_07/">cs.CV - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="S-Adapter-Generalizing-Vision-Transformer-for-Face-Anti-Spoofing-with-Statistical-Tokens"><a href="#S-Adapter-Generalizing-Vision-Transformer-for-Face-Anti-Spoofing-with-Statistical-Tokens" class="headerlink" title="S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens"></a>S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04038">http://arxiv.org/abs/2309.04038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rizhao Cai, Zitong Yu, Chenqi Kong, Haoliang Li, Changsheng Chen, Yongjian Hu, Alex Kot</li>
<li>For: 检测面部识别系统中的恶意伪装 attempts (Face Anti-Spoofing, FAS)* Methods: 使用Efficient Parameter Transfer Learning (EPTL) paradigm，适应已经预训练的Vision Transformer模型，并在训练中插入 adapter modules，以便在不同频谱上进行恶意伪装检测。* Results: 提出了一种基于Statistical Adapter (S-Adapter)和Token Style Regularization (TSR)的方法，可以在零或几 shot cross-domain测试中提高检测性能，并且超过了现有方法在多个标准测试上的表现。<details>
<summary>Abstract</summary>
Face Anti-Spoofing (FAS) aims to detect malicious attempts to invade a face recognition system by presenting spoofed faces. State-of-the-art FAS techniques predominantly rely on deep learning models but their cross-domain generalization capabilities are often hindered by the domain shift problem, which arises due to different distributions between training and testing data. In this study, we develop a generalized FAS method under the Efficient Parameter Transfer Learning (EPTL) paradigm, where we adapt the pre-trained Vision Transformer models for the FAS task. During training, the adapter modules are inserted into the pre-trained ViT model, and the adapters are updated while other pre-trained parameters remain fixed. We find the limitations of previous vanilla adapters in that they are based on linear layers, which lack a spoofing-aware inductive bias and thus restrict the cross-domain generalization. To address this limitation and achieve cross-domain generalized FAS, we propose a novel Statistical Adapter (S-Adapter) that gathers local discriminative and statistical information from localized token histograms. To further improve the generalization of the statistical tokens, we propose a novel Token Style Regularization (TSR), which aims to reduce domain style variance by regularizing Gram matrices extracted from tokens across different domains. Our experimental results demonstrate that our proposed S-Adapter and TSR provide significant benefits in both zero-shot and few-shot cross-domain testing, outperforming state-of-the-art methods on several benchmark tests. We will release the source code upon acceptance.
</details>
<details>
<summary>摘要</summary>
面部反射防范（FAS）目的是检测面部识别系统中的恶意入侵尝试，包括提供伪造面部。现代FAS技术主要基于深度学习模型，但它们在不同数据频谱的问题上存在跨频道泛化能力的问题。在本研究中，我们开发了基于高效参数传播学习（EPTL）模型的通用FAS方法。在训练过程中，我们插入了适应器模块到预训练的ViT模型中，并在其他预训练参数固定下更新适应器。我们发现过去的纯Adapter在基于线性层的限制下，无法具备跨频道泛化能力。为了解决这个限制并实现跨频道泛化FAS，我们提出了一种新的统计适应器（S-Adapter），它可以从本地化的token历史中收集当地特征和统计信息。为了进一步提高统计token的泛化能力，我们还提出了一种新的Token样式规范（TSR），它计划通过对token在不同频谱上的Gram矩阵进行规范来减少频谱样式差异。我们的实验结果表明，我们的提出的S-Adapter和TSR在零shot和几shot跨频道测试中具有显著的优势，超过了现有的方法在多个标准测试中的表现。我们将在接受后发布源代码。
</details></li>
</ul>
<hr>
<h2 id="Algebra-and-Geometry-of-Camera-Resectioning"><a href="#Algebra-and-Geometry-of-Camera-Resectioning" class="headerlink" title="Algebra and Geometry of Camera Resectioning"></a>Algebra and Geometry of Camera Resectioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04028">http://arxiv.org/abs/2309.04028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erin Connelly, Timothy Duff, Jessie Loucks-Tavitas</li>
<li>for: 关于摄像机减掉问题的代数变量研究。</li>
<li>methods: 使用Gröbner基的技术来描述这些减掉变量的多度vanishing идеал。</li>
<li>results:  derivation and re-interpretation of well-known results in geometric computer vision related to camera-point duality, as well as clarification of relationships between classical problems of optimal resectioning and triangulation, and a conjectured formula for the Euclidean distance degree of the resectioning variety.<details>
<summary>Abstract</summary>
We study algebraic varieties associated with the camera resectioning problem. We characterize these resectioning varieties' multigraded vanishing ideals using Gr\"obner basis techniques. As an application, we derive and re-interpret celebrated results in geometric computer vision related to camera-point duality. We also clarify some relationships between the classical problems of optimal resectioning and triangulation, state a conjectural formula for the Euclidean distance degree of the resectioning variety, and discuss how this conjecture relates to the recently-resolved multiview conjecture.
</details>
<details>
<summary>摘要</summary>
我们研究关于摄像头重sectioning问题的代数变量。我们使用格罗本基技术来 caracterize这些重sectioning变量的多重度vanishing ideal。作为应用，我们得到并重新解释了在计算机视觉中知名的相机点对偶问题的结果。我们还清楚了经典的最优重sectioning和三角形问题之间的关系，提出了圆形距离度的重sectioning变量的投影式，并讲解了该投影式与最近解决的多视图问题之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Accuracy-of-Beauty-Product-Recommendations-by-Assessing-Face-Illumination-Quality"><a href="#Improving-the-Accuracy-of-Beauty-Product-Recommendations-by-Assessing-Face-Illumination-Quality" class="headerlink" title="Improving the Accuracy of Beauty Product Recommendations by Assessing Face Illumination Quality"></a>Improving the Accuracy of Beauty Product Recommendations by Assessing Face Illumination Quality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04022">http://arxiv.org/abs/2309.04022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parnian Afshar, Jenny Yeon, Andriy Levitskyy, Rahul Suresh, Amin Banitalebi-Dehkordi</li>
<li>for: 本研究旨在 Addressing the challenges in responsible beauty product recommendation, particularly when it involves comparing the product’s color with a person’s skin tone, such as for foundation and concealer products.</li>
<li>methods: We introduce a machine learning framework for illumination assessment which classifies images into having either good or bad illumination condition. We then build an automatic user guidance tool which informs a user holding their camera if their illumination condition is good or bad.</li>
<li>results: Our work improves the shade recommendation for various foundation products by using a diverse synthetic dataset and a Convolutional Neural Network (CNN) for illumination assessment.<details>
<summary>Abstract</summary>
We focus on addressing the challenges in responsible beauty product recommendation, particularly when it involves comparing the product's color with a person's skin tone, such as for foundation and concealer products. To make accurate recommendations, it is crucial to infer both the product attributes and the product specific facial features such as skin conditions or tone. However, while many product photos are taken under good light conditions, face photos are taken from a wide range of conditions. The features extracted using the photos from ill-illuminated environment can be highly misleading or even be incompatible to be compared with the product attributes. Hence bad illumination condition can severely degrade quality of the recommendation.   We introduce a machine learning framework for illumination assessment which classifies images into having either good or bad illumination condition. We then build an automatic user guidance tool which informs a user holding their camera if their illumination condition is good or bad. This way, the user is provided with rapid feedback and can interactively control how the photo is taken for their recommendation. Only a few studies are dedicated to this problem, mostly due to the lack of dataset that is large, labeled, and diverse both in terms of skin tones and light patterns. Lack of such dataset leads to neglecting skin tone diversity. Therefore, We begin by constructing a diverse synthetic dataset that simulates various skin tones and light patterns in addition to an existing facial image dataset. Next, we train a Convolutional Neural Network (CNN) for illumination assessment that outperforms the existing solutions using the synthetic dataset. Finally, we analyze how the our work improves the shade recommendation for various foundation products.
</details>
<details>
<summary>摘要</summary>
我们专注于处理美妆产品推荐中的挑战，特别是在比较产品的颜色与人们的皮肤颜色时。为确保精准的推荐，需要推算产品特性和产品具体的脸部特征，如皮肤状况或颜色。但是，许多产品照片在良好的照明条件下拍摄，而脸部照片则来自广泛的照明环境。由于撷取自不良照明环境的特征可能会导致极度错误或甚至无法与产品特性相比。因此，糟糕的照明环境可能会严重降低推荐质量。我们介绍了一个机器学习框架 для照明评估，可以区分具有好坏照明conditions的图像。然后，我们建立了一个自动用户指南工具，可以为用户提供快速的反馈，并让用户可以互动地控制他们拍摄的照片。只有几个研究对这个问题进行了研究，主要是因为缺乏大量、标注和多样化的皮肤颜色和照明模式的数据集。由于缺乏这种数据集，因此跳过了皮肤颜色多样性的问题。因此，我们开始了一个多样的人工数据集的建立，这个数据集模拟了不同的皮肤颜色和照明模式。接下来，我们使用这个数据集进行训练，并使用卷积神经网络（CNN）进行照明评估，以超越现有的解决方案。最后，我们分析了我们的工作如何改善不同的基调推荐。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Transformer-for-Material-Segmentation"><a href="#Multimodal-Transformer-for-Material-Segmentation" class="headerlink" title="Multimodal Transformer for Material Segmentation"></a>Multimodal Transformer for Material Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04001">http://arxiv.org/abs/2309.04001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Kaykobad Reza, Ashley Prater-Bennette, M. Salman Asif</li>
<li>for: 本研究的目的是提出一种新的多模态融合策略，以提高多模态分割 зада务的性能。</li>
<li>methods: 本研究提出了一种新的模型名为多模态分割变换器（MMSFormer），该模型包括一种新的融合策略，可以有效地融合不同组合的四种模式：RGB、Angular Linear Polarization（AoLP）、Degree of Linear Polarization（DoLP）和 Near-Infrared（NIR）模式。</li>
<li>results: 在MCubeS数据集上，MMSFormer模型达到了52.05%的mIoU，比现有状态的各种方法高出9.1%和10.4%。例如，我们的方法在检测gravel和人类类别上具有显著的提高（+10.4%和+9.1%）。<details>
<summary>Abstract</summary>
Leveraging information across diverse modalities is known to enhance performance on multimodal segmentation tasks. However, effectively fusing information from different modalities remains challenging due to the unique characteristics of each modality. In this paper, we propose a novel fusion strategy that can effectively fuse information from different combinations of four different modalities: RGB, Angle of Linear Polarization (AoLP), Degree of Linear Polarization (DoLP) and Near-Infrared (NIR). We also propose a new model named Multi-Modal Segmentation Transformer (MMSFormer) that incorporates the proposed fusion strategy to perform multimodal material segmentation. MMSFormer achieves 52.05% mIoU outperforming the current state-of-the-art on Multimodal Material Segmentation (MCubeS) dataset. For instance, our method provides significant improvement in detecting gravel (+10.4%) and human (+9.1%) classes. Ablation studies show that different modules in the fusion block are crucial for overall model performance. Furthermore, our ablation studies also highlight the capacity of different input modalities to improve performance in the identification of different types of materials. The code and pretrained models will be made available at https://github.com/csiplab/MMSFormer.
</details>
<details>
<summary>摘要</summary>
利用多modalities的信息融合可以提高多modalities segmentation任务的性能。然而，有效地融合不同modalities的信息仍然是一个挑战，因为每种modalities都有独特的特征。在这篇论文中，我们提出了一种新的融合策略，可以有效地融合不同组合的四种modalities：RGB、Angular Linear Polarization（AoLP）、Degree of Linear Polarization（DoLP）和 Near-Infrared（NIR）。我们还提出了一个新的模型名为多Modal Segmentation Transformer（MMSFormer），该模型包含了提出的融合策略，用于进行多modal material segmentation。MMSFormer在Multimodal Material Segmentation（MCubeS）数据集上 achieved 52.05% mIoU，比前一个状态的艺术性表现出色。例如，我们的方法在检测gravel (+10.4%)和human (+9.1%)类中提供了显著改进。精算研究表明，不同模块在融合块中的不同部分对整体模型性能具有重要作用。此外，我们的精算研究还表明了不同输入modalities在不同材料类型的标识中的不同作用。代码和预训练模型将在https://github.com/csiplab/MMSFormer上提供。
</details></li>
</ul>
<hr>
<h2 id="Adapting-Self-Supervised-Representations-to-Multi-Domain-Setups"><a href="#Adapting-Self-Supervised-Representations-to-Multi-Domain-Setups" class="headerlink" title="Adapting Self-Supervised Representations to Multi-Domain Setups"></a>Adapting Self-Supervised Representations to Multi-Domain Setups</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03999">http://arxiv.org/abs/2309.03999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha Kalibhat, Sam Sharpe, Jeremy Goodsitt, Bayan Bruss, Soheil Feizi</li>
<li>for: 提高多域自然语言处理模型的泛化能力（improve the generalization ability of multi-domain natural language processing models）</li>
<li>methods: 提出一种通用、轻量级的领域分离模块（propose a general-purpose, lightweight domain disentanglement module），可以适应任何自助学习编码器，以提高多域数据上的表示学习。在预训练期间，DDM对表示空间进行分解，从而实现领域分离。当领域标签不available时，DDM使用了一种可靠的聚类方法来发现 Pseudo-领域。</li>
<li>results: 与基eline比较，使用DDM预训练模型可以提高线性探测精度（linear probing accuracy）达3.5%，并且在多域测试集上显示了7.4%的泛化性能（generalization performance）提升。<details>
<summary>Abstract</summary>
Current state-of-the-art self-supervised approaches, are effective when trained on individual domains but show limited generalization on unseen domains. We observe that these models poorly generalize even when trained on a mixture of domains, making them unsuitable to be deployed under diverse real-world setups. We therefore propose a general-purpose, lightweight Domain Disentanglement Module (DDM) that can be plugged into any self-supervised encoder to effectively perform representation learning on multiple, diverse domains with or without shared classes. During pre-training according to a self-supervised loss, DDM enforces a disentanglement in the representation space by splitting it into a domain-variant and a domain-invariant portion. When domain labels are not available, DDM uses a robust clustering approach to discover pseudo-domains. We show that pre-training with DDM can show up to 3.5% improvement in linear probing accuracy on state-of-the-art self-supervised models including SimCLR, MoCo, BYOL, DINO, SimSiam and Barlow Twins on multi-domain benchmarks including PACS, DomainNet and WILDS. Models trained with DDM show significantly improved generalization (7.4%) to unseen domains compared to baselines. Therefore, DDM can efficiently adapt self-supervised encoders to provide high-quality, generalizable representations for diverse multi-domain data.
</details>
<details>
<summary>摘要</summary>
当前最新的自动教程方法，在个别领域上有效地训练，但在未经见过的领域上显示有限的泛化能力。我们发现这些模型在混合领域上训练时表现不佳，使其在实际世界中不适用。因此，我们提出一种通用、轻量级的领域分离模块（DDM），可以与任何自动教程Encoder结合使用，以有效地进行多个、多种领域的表示学习，无论具有共享类别或不具有。在预训练时，DDM通过对自我超vised损失进行 enforcement，在表示空间中提升了分离。当领域标签不可用时，DDM使用Robust Clustering方法来发现pseudo-领域。我们显示，使用DDM进行预训练可以与现有最新的自动教程模型，包括SimCLR、MoCo、BYOL、DINO、SimSiam和Barlow Twins在多个领域的多个benchmark上提高线性探测精度达3.5%。模型通过DDM进行预训练后，对未经见过的领域的泛化能力提高了7.4%。因此，DDM可以有效地适应自动教程Encoder，以提供高质量、泛化的表示，用于多个多种领域的数据。
</details></li>
</ul>
<hr>
<h2 id="CDFSL-V-Cross-Domain-Few-Shot-Learning-for-Videos"><a href="#CDFSL-V-Cross-Domain-Few-Shot-Learning-for-Videos" class="headerlink" title="CDFSL-V: Cross-Domain Few-Shot Learning for Videos"></a>CDFSL-V: Cross-Domain Few-Shot Learning for Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03989">http://arxiv.org/abs/2309.03989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarinda Samarasinghe, Mamshad Nayeem Rizve, Navid Kardan, Mubarak Shah</li>
<li>for: 这个论文是为了解决跨频道少量示例视频动作识别问题，而现有的方法都是基于大量标注的同频道数据集。</li>
<li>methods: 该论文提出了一种新的跨频道少量示例视频动作识别方法，该方法利用了自编码学习和课程学习来均衡源频道和目标频道的信息。具体来说，该方法使用了一个masked autoencoder-based自编码训练目标来从源和目标数据集中学习。然后，一个进步课程来均衡学习源数据集中的分类特征和目标频道特征。</li>
<li>results: 该论文在多个复杂的benchmark数据集上进行了评估，并证明了该方法可以超越现有的跨频道少量学习方法。代码可以在<a target="_blank" rel="noopener" href="https://github.com/Sarinda251/CDFSL-V%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Sarinda251/CDFSL-V中找到。</a><details>
<summary>Abstract</summary>
Few-shot video action recognition is an effective approach to recognizing new categories with only a few labeled examples, thereby reducing the challenges associated with collecting and annotating large-scale video datasets. Existing methods in video action recognition rely on large labeled datasets from the same domain. However, this setup is not realistic as novel categories may come from different data domains that may have different spatial and temporal characteristics. This dissimilarity between the source and target domains can pose a significant challenge, rendering traditional few-shot action recognition techniques ineffective. To address this issue, in this work, we propose a novel cross-domain few-shot video action recognition method that leverages self-supervised learning and curriculum learning to balance the information from the source and target domains. To be particular, our method employs a masked autoencoder-based self-supervised training objective to learn from both source and target data in a self-supervised manner. Then a progressive curriculum balances learning the discriminative information from the source dataset with the generic information learned from the target domain. Initially, our curriculum utilizes supervised learning to learn class discriminative features from the source data. As the training progresses, we transition to learning target-domain-specific features. We propose a progressive curriculum to encourage the emergence of rich features in the target domain based on class discriminative supervised features in the source domain. We evaluate our method on several challenging benchmark datasets and demonstrate that our approach outperforms existing cross-domain few-shot learning techniques. Our code is available at https://github.com/Sarinda251/CDFSL-V
</details>
<details>
<summary>摘要</summary>
新型几个shot视频动作识别方法可以快速地识别新类型，只需几个标注的示例，因此可以降低收集和标注大规模视频数据集的挑战。现有的视频动作识别方法依赖于同一个频谱中的大量标注数据。然而，这种设置不真实，因为新类型可能来自不同的数据频谱，这些频谱可能具有不同的空间和时间特征。这种差异会对传统的几个shot动作识别技术产生很大的挑战。为解决这个问题，在这项工作中，我们提出了一种新的跨频谱几个shot视频动作识别方法，该方法利用了自动生成学和课程学来均衡来源频谱和目标频谱的信息。具体来说，我们的方法使用了一个遮盖自动编码器基于的自动生成训练目标来学习来源和目标数据。然后，我们使用一个进步的课程来平衡学习来源数据中的分类特征与目标频谱中学习的通用特征。在训练过程中，我们首先使用了supervised学习来学习来源数据中的分类特征。随着训练的进行，我们转移到学习目标频谱特有的特征。我们提出了一种进步的课程，以便在目标频谱中促进特有的特征的出现，基于来源频谱中的分类特征。我们在多个挑战性 benchmark 数据集上评估了我们的方法，并证明了我们的方法在跨频谱几个shot学习中表现更好。我们的代码可以在 https://github.com/Sarinda251/CDFSL-V 上获取。
</details></li>
</ul>
<hr>
<h2 id="Separable-Self-and-Mixed-Attention-Transformers-for-Efficient-Object-Tracking"><a href="#Separable-Self-and-Mixed-Attention-Transformers-for-Efficient-Object-Tracking" class="headerlink" title="Separable Self and Mixed Attention Transformers for Efficient Object Tracking"></a>Separable Self and Mixed Attention Transformers for Efficient Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03979">http://arxiv.org/abs/2309.03979</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/goutamyg/smat">https://github.com/goutamyg/smat</a></li>
<li>paper_authors: Goutam Yelluru Gopal, Maria A. Amer</li>
<li>for: 这篇论文旨在提出一种高效的自我和混合注意力转换器基 Architecture  для轻量级目标跟踪。</li>
<li>methods: 该提案使用分解自我和混合注意力转换器来融合模板和搜索区域进行特征提取，并使用高效自注意力块进行全局Contextual模型化以提高目标状态估计的准确性。</li>
<li>results: 相比之下，该提案在GOT10k、TrackingNet、LaSOT、NfS30、UAV123和AVisT等 dataset上的表现都高于相关的轻量级跟踪器，而且在CPU上运行时速度达37帧，在GPU上运行时速度达158帧，参数数量为3.8亿。例如，在GOT10k-test上，它与E.T.Track和MixFormerV2-S的相似跟踪器相比，在AO metric上表现出了7.9%和5.8%的显著优势。<details>
<summary>Abstract</summary>
The deployment of transformers for visual object tracking has shown state-of-the-art results on several benchmarks. However, the transformer-based models are under-utilized for Siamese lightweight tracking due to the computational complexity of their attention blocks. This paper proposes an efficient self and mixed attention transformer-based architecture for lightweight tracking. The proposed backbone utilizes the separable mixed attention transformers to fuse the template and search regions during feature extraction to generate superior feature encoding. Our prediction head performs global contextual modeling of the encoded features by leveraging efficient self-attention blocks for robust target state estimation. With these contributions, the proposed lightweight tracker deploys a transformer-based backbone and head module concurrently for the first time. Our ablation study testifies to the effectiveness of the proposed combination of backbone and head modules. Simulations show that our Separable Self and Mixed Attention-based Tracker, SMAT, surpasses the performance of related lightweight trackers on GOT10k, TrackingNet, LaSOT, NfS30, UAV123, and AVisT datasets, while running at 37 fps on CPU, 158 fps on GPU, and having 3.8M parameters. For example, it significantly surpasses the closely related trackers E.T.Track and MixFormerV2-S on GOT10k-test by a margin of 7.9% and 5.8%, respectively, in the AO metric. The tracker code and model is available at https://github.com/goutamyg/SMAT
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese投入变换器对视图对象跟踪进行部署，显示了顶尖的结果。但是，基于变换器的模型在轻量级跟踪中受到计算复杂性的限制。这篇论文提出了一种高效的自我和混合注意力变换器-基于架构，用于轻量级跟踪。我们的提案中，使用分解式混合注意力变换器将模板和搜索区域 fusion 到特征提取过程中，以生成优化的特征编码。我们的预测头使用高效的自我注意力块进行全局Contextual 模型化，以提高目标状态估计的精度。通过这些贡献，我们的轻量级跟踪器首次同时使用变换器-基于架构和头模块。我们的ablation研究证明了我们的组合的后处和头模块的效果。实验显示，我们的分解自我和混合注意力基于跟踪器（SMAT）在GOT10k、TrackingNet、LaSOT、NfS30、UAV123和AVisT等数据集上表现出色，而且在CPU上运行时间为37帧，GPU上运行时间为158帧，参数数为3.8亿。例如，它在GOT10k-test上与相似的跟踪器E.T.Track和MixFormerV2-S的margin 7.9%和5.8%，分别。跟踪器代码和模型可以在https://github.com/goutamyg/SMAT 上下载。
</details></li>
</ul>
<hr>
<h2 id="Improving-Resnet-9-Generalization-Trained-on-Small-Datasets"><a href="#Improving-Resnet-9-Generalization-Trained-on-Small-Datasets" class="headerlink" title="Improving Resnet-9 Generalization Trained on Small Datasets"></a>Improving Resnet-9 Generalization Trained on Small Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03965">http://arxiv.org/abs/2309.03965</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/omarawad2/HAET2021_Huawei">https://github.com/omarawad2/HAET2021_Huawei</a></li>
<li>paper_authors: Omar Mohamed Awad, Habib Hajimolahoseini, Michael Lim, Gurpreet Gosal, Walid Ahmed, Yang Liu, Gordon Deng</li>
<li>for: 本文提出了一种方法，该方法在ICLR竞赛中获得了最高精度奖。目标是在 less than 10 分钟内达到 CIFAR-10 数据集上的图像分类任务最高精度。</li>
<li>methods: 本文使用了一系列技术来提高 ResNet-9 的通用性，包括：锐度敏感优化、标签平滑、梯度中心化、输入补丁白净化以及基于基本学习的训练。</li>
<li>results: 我们的实验表明，通过在 CIFAR-10 数据集上进行sharpness aware optimization、标签平滑、梯度中心化、输入补丁白净化以及基于基本学习的训练，ResNet-9 可以在 less than 10 分钟内达到 88% 的精度，而且只需训练在 CIFAR-10 数据集上的 10% 子集上。<details>
<summary>Abstract</summary>
This paper presents our proposed approach that won the first prize at the ICLR competition on Hardware Aware Efficient Training. The challenge is to achieve the highest possible accuracy in an image classification task in less than 10 minutes. The training is done on a small dataset of 5000 images picked randomly from CIFAR-10 dataset. The evaluation is performed by the competition organizers on a secret dataset with 1000 images of the same size. Our approach includes applying a series of technique for improving the generalization of ResNet-9 including: sharpness aware optimization, label smoothing, gradient centralization, input patch whitening as well as metalearning based training. Our experiments show that the ResNet-9 can achieve the accuracy of 88% while trained only on a 10% subset of CIFAR-10 dataset in less than 10 minuets
</details>
<details>
<summary>摘要</summary>
本文提出了我们的提议方法，在ICLR竞赛中获得首奖的硬件意识fficient Training中实现最高可能的准确率。挑战是在 less than 10 minutes 内完成一个图像分类任务。训练是基于小型的CIFAR-10数据集中随机选择的5000张图像。评估是由竞赛组织者在一个保密的数据集上进行，该数据集包含1000张同样大小的图像。我们的方法包括对ResNet-9进行一系列技巧以提高其泛化性，包括：锐度意识优化、标签平滑、梯度中心化、输入质patch白净以及基于学习的训练。我们的实验表明，ResNet-9可以在CIFAR-10数据集中训练只有10%的subset中的图像，在 less than 10 minutes 内达到88%的准确率。
</details></li>
</ul>
<hr>
<h2 id="REALM-Robust-Entropy-Adaptive-Loss-Minimization-for-Improved-Single-Sample-Test-Time-Adaptation"><a href="#REALM-Robust-Entropy-Adaptive-Loss-Minimization-for-Improved-Single-Sample-Test-Time-Adaptation" class="headerlink" title="REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation"></a>REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03964">http://arxiv.org/abs/2309.03964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skyler Seto, Barry-John Theobald, Federico Danieli, Navdeep Jaitly, Dan Busbridge</li>
<li>For: The paper is written to mitigate performance loss due to distribution shifts between train and test data in online fully-test-time adaptation (F-TTA) without access to the training data and without knowledge of the model training procedure.* Methods: The paper proposes a general framework called Robust Entropy Adaptive Loss Minimization (REALM) inspired by self-paced learning and robust loss functions to improve the robustness of F-TTA to noisy samples.* Results: The proposed approach achieves better adaptation accuracy than previous approaches throughout the adaptation process on corruptions of CIFAR-10 and ImageNet-1K, demonstrating its effectiveness.Here’s the simplified Chinese version:* For: 约束是为了 mitigate 在 train 和 test 数据之间的分布变化导致的性能下降，而不需要访问训练数据和模型训练过程的知识。* Methods: 提议了一种通用框架 called Robust Entropy Adaptive Loss Minimization (REALM)， Drawing inspiration from self-paced learning and robust loss functions to improve F-TTA 的 robustness to noisy samples。* Results: 比较 previous approaches 的 adaptation accuracy  superior throughout the adaptation process on corruptions of CIFAR-10 and ImageNet-1K, demonstrating its effectiveness.<details>
<summary>Abstract</summary>
Fully-test-time adaptation (F-TTA) can mitigate performance loss due to distribution shifts between train and test data (1) without access to the training data, and (2) without knowledge of the model training procedure. In online F-TTA, a pre-trained model is adapted using a stream of test samples by minimizing a self-supervised objective, such as entropy minimization. However, models adapted with online using entropy minimization, are unstable especially in single sample settings, leading to degenerate solutions, and limiting the adoption of TTA inference strategies. Prior works identify noisy, or unreliable, samples as a cause of failure in online F-TTA. One solution is to ignore these samples, which can lead to bias in the update procedure, slow adaptation, and poor generalization. In this work, we present a general framework for improving robustness of F-TTA to these noisy samples, inspired by self-paced learning and robust loss functions. Our proposed approach, Robust Entropy Adaptive Loss Minimization (REALM), achieves better adaptation accuracy than previous approaches throughout the adaptation process on corruptions of CIFAR-10 and ImageNet-1K, demonstrating its effectiveness.
</details>
<details>
<summary>摘要</summary>
全程测试时适应（F-TTA）可以减轻因数据分布变化而导致的性能下降（1）无需访问训练数据，以及（2）无需知道模型训练过程。在线上F-TTA中，一个预训练模型通过使用一批测试样本进行适应，以降低一种自我超级对象，如熵降低。然而，通过在线使用熵降低进行适应，特别是在单个样本设置下，可能会导致不稳定的解决方案，限制TTA的推理策略的采用。先前的研究表明，噪声或不可靠的样本是在线F-TTA失败的原因。一种解决方案是忽略这些样本，可能会导致更新过程中的偏见，慢化适应，和泛化性下降。在这种情况下，我们提出了一种抗噪声的框架，即稳定熵降低适应loss函数（REALM）。我们的提议方法在CIFAR-10和ImageNet-1K上进行了某些损害的适应过程，并且在整个适应过程中达到了更高的适应精度，这表明了它的有效性。
</details></li>
</ul>
<hr>
<h2 id="SimpleNeRF-Regularizing-Sparse-Input-Neural-Radiance-Fields-with-Simpler-Solutions"><a href="#SimpleNeRF-Regularizing-Sparse-Input-Neural-Radiance-Fields-with-Simpler-Solutions" class="headerlink" title="SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions"></a>SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03955">http://arxiv.org/abs/2309.03955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nagabhushan Somraj, Adithyan Karanayil, Rajiv Soundararajan</li>
<li>for: 这个论文主要研究了如何使用增强模型来训练几何投影场景中的NeRF，以实现 fewer-shot 渲染。</li>
<li>methods: 作者使用了增强模型来帮助训练NeRF，并在训练过程中添加了positional编码和视图依赖的采样来增强模型的简洁性。</li>
<li>results: 作者通过使用这些增强模型和采样方法，实现了在两个流行的数据集上的state-of-the-art 视角合成性能。Here’s the full text in Simplified Chinese:</li>
<li>for: 这个论文主要研究了如何使用增强模型来训练几何投影场景中的NeRF，以实现 fewer-shot 渲染。</li>
<li>methods: 作者使用了增强模型来帮助训练NeRF，并在训练过程中添加了positional编码和视图依赖的采样来增强模型的简洁性。</li>
<li>results: 作者通过使用这些增强模型和采样方法，实现了在两个流行的数据集上的state-of-the-art 视角合成性能。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) show impressive performance for the photorealistic free-view rendering of scenes. However, NeRFs require dense sampling of images in the given scene, and their performance degrades significantly when only a sparse set of views are available. Researchers have found that supervising the depth estimated by the NeRF helps train it effectively with fewer views. The depth supervision is obtained either using classical approaches or neural networks pre-trained on a large dataset. While the former may provide only sparse supervision, the latter may suffer from generalization issues. As opposed to the earlier approaches, we seek to learn the depth supervision by designing augmented models and training them along with the NeRF. We design augmented models that encourage simpler solutions by exploring the role of positional encoding and view-dependent radiance in training the few-shot NeRF. The depth estimated by these simpler models is used to supervise the NeRF depth estimates. Since the augmented models can be inaccurate in certain regions, we design a mechanism to choose only reliable depth estimates for supervision. Finally, we add a consistency loss between the coarse and fine multi-layer perceptrons of the NeRF to ensure better utilization of hierarchical sampling. We achieve state-of-the-art view-synthesis performance on two popular datasets by employing the above regularizations. The source code for our model can be found on our project page: https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html
</details>
<details>
<summary>摘要</summary>
神经闪光场（NeRF）可以实现高品质的自由视图渲染场景。然而，NeRF需要场景中的图像 dense sampling，而且在只有 sparse 的视图时，其性能会下降 significatively。研究人员发现，对 NeRF  depth 进行超vision 可以帮助它们在 fewer  views 上训练效果。这些超vision 可以来自 classical 方法或者 neural network 预训练大量数据。然而，前者可能只提供 sparse 的超vision，而后者可能会导致泛化问题。与之前的方法不同，我们尝试通过设计增强模型并与 NeRF 同时训练来学习 depth 超vision。我们设计了增强模型，这些模型通过 exploring 场景中的位置编码和视角依赖的闪光来培养简单的解决方案。这些简单模型中的深度被用来超vision NeRF 的深度估计。由于增强模型在某些区域可能不准确，我们设计了一种机制来选择可靠的深度估计来作为超vision。最后，我们添加了一种 hierarchical 整合损失，以确保更好地利用多层感知。我们通过使用以上 regularizations 实现了两个流行的数据集上的视图合成状态机器。我们的模型代码可以在我们项目页面中找到：<https://nagabhushansn95.github.io/publications/2023/SimpleNeRF.html>
</details></li>
</ul>
<hr>
<h2 id="A-Eval-A-Benchmark-for-Cross-Dataset-Evaluation-of-Abdominal-Multi-Organ-Segmentation"><a href="#A-Eval-A-Benchmark-for-Cross-Dataset-Evaluation-of-Abdominal-Multi-Organ-Segmentation" class="headerlink" title="A-Eval: A Benchmark for Cross-Dataset Evaluation of Abdominal Multi-Organ Segmentation"></a>A-Eval: A Benchmark for Cross-Dataset Evaluation of Abdominal Multi-Organ Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03906">http://arxiv.org/abs/2309.03906</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uni-medical/a-eval">https://github.com/uni-medical/a-eval</a></li>
<li>paper_authors: Ziyan Huang, Zhongying Deng, Jin Ye, Haoyu Wang, Yanzhou Su, Tianbin Li, Hui Sun, Junlong Cheng, Jianpin Chen, Junjun He, Yun Gu, Shaoting Zhang, Lixu Gu, Yu Qiao</li>
<li>for: 本研究旨在检验多个数据集上的 Abdomen 多器官分割模型是否能够通用，以及如何进一步提高其通用性。</li>
<li>methods: 本研究使用了四个大规模公共数据集：FLARE22、AMOS、WORD 和 TotalSegmentator，每个数据集都提供了丰富的 Abdomen 多器官分割标签。为了评估，我们将这些数据集的验证集与 BTCV 数据集的训练集组合成一个可靠的 Benchmark，包括五个不同的数据集。</li>
<li>results: 我们通过使用不同的数据使用场景（即在单个数据集上独立训练、使用 pseudo-labeling 技术、混合不同Modalities 和在所有可用数据集上进行联合训练）来评估不同的模型是否能够通用。此外，我们还研究了模型的大小对 cross-dataset 通用性的影响。通过这些分析，我们强调了有效地使用数据的重要性，并提供了训练策略的有价值指导。<details>
<summary>Abstract</summary>
Although deep learning have revolutionized abdominal multi-organ segmentation, models often struggle with generalization due to training on small, specific datasets. With the recent emergence of large-scale datasets, some important questions arise: \textbf{Can models trained on these datasets generalize well on different ones? If yes/no, how to further improve their generalizability?} To address these questions, we introduce A-Eval, a benchmark for the cross-dataset Evaluation ('Eval') of Abdominal ('A') multi-organ segmentation. We employ training sets from four large-scale public datasets: FLARE22, AMOS, WORD, and TotalSegmentator, each providing extensive labels for abdominal multi-organ segmentation. For evaluation, we incorporate the validation sets from these datasets along with the training set from the BTCV dataset, forming a robust benchmark comprising five distinct datasets. We evaluate the generalizability of various models using the A-Eval benchmark, with a focus on diverse data usage scenarios: training on individual datasets independently, utilizing unlabeled data via pseudo-labeling, mixing different modalities, and joint training across all available datasets. Additionally, we explore the impact of model sizes on cross-dataset generalizability. Through these analyses, we underline the importance of effective data usage in enhancing models' generalization capabilities, offering valuable insights for assembling large-scale datasets and improving training strategies. The code and pre-trained models are available at \href{https://github.com/uni-medical/A-Eval}{https://github.com/uni-medical/A-Eval}.
</details>
<details>
<summary>摘要</summary>
although deep learning has revolutionized abdominal multi-organ segmentation, models often struggle with generalization due to training on small, specific datasets. with the recent emergence of large-scale datasets, some important questions arise: �Can models trained on these datasets generalize well on different ones? if yes/no, how to further improve their generalizability? to address these questions, we introduce A-Eval, a benchmark for the cross-dataset evaluation of abdominal multi-organ segmentation. we employ training sets from four large-scale public datasets: flare22, amos, word, and totalsegmentator, each providing extensive labels for abdominal multi-organ segmentation. for evaluation, we incorporate the validation sets from these datasets along with the training set from the btcv dataset, forming a robust benchmark comprising five distinct datasets. we evaluate the generalizability of various models using the A-Eval benchmark, with a focus on diverse data usage scenarios: training on individual datasets independently, utilizing unlabeled data via pseudo-labeling, mixing different modalities, and joint training across all available datasets. additionally, we explore the impact of model sizes on cross-dataset generalizability. through these analyses, we underline the importance of effective data usage in enhancing models' generalization capabilities, offering valuable insights for assembling large-scale datasets and improving training strategies. the code and pre-trained models are available at https://github.com/uni-medical/A-Eval.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Sparse-MoE-in-GANs-for-Text-conditioned-Image-Synthesis"><a href="#Exploring-Sparse-MoE-in-GANs-for-Text-conditioned-Image-Synthesis" class="headerlink" title="Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis"></a>Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03904">http://arxiv.org/abs/2309.03904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhujiapeng/aurora">https://github.com/zhujiapeng/aurora</a></li>
<li>paper_authors: Jiapeng Zhu, Ceyuan Yang, Kecheng Zheng, Yinghao Xu, Zifan Shi, Yujun Shen</li>
<li>for: 文章旨在提出一种基于生成对抗网络（GAN）的文本决定图像生成模型，以便在大规模模型训练中减少计算资源的消耗。</li>
<li>methods: 该模型采用了一个集合专家来学习特征处理，并与一个稀有的路由器相结合，以选择最适合每个特征点的专家。路由器在考虑文本整体归一化代码的基础上进行动态决策，以确保准确地传递采样冲击和文本条件到最终生成图像中。</li>
<li>results: 在64x64图像分辨率下，使用LAION2B-en和COYO-700M训练集，模型达到了6.2 zero-shot FID在MS COCO上。<details>
<summary>Abstract</summary>
Due to the difficulty in scaling up, generative adversarial networks (GANs) seem to be falling from grace on the task of text-conditioned image synthesis. Sparsely-activated mixture-of-experts (MoE) has recently been demonstrated as a valid solution to training large-scale models with limited computational resources. Inspired by such a philosophy, we present Aurora, a GAN-based text-to-image generator that employs a collection of experts to learn feature processing, together with a sparse router to help select the most suitable expert for each feature point. To faithfully decode the sampling stochasticity and the text condition to the final synthesis, our router adaptively makes its decision by taking into account the text-integrated global latent code. At 64x64 image resolution, our model trained on LAION2B-en and COYO-700M achieves 6.2 zero-shot FID on MS COCO. We release the code and checkpoints to facilitate the community for further development.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:由于扩展困难，生成对抗网络（GAN）在文本条件下的图像生成任务上似乎在落叶。另一方面，卷积束激活的混合专家（MoE）在具有有限的计算资源的情况下被证明为有效的解决方案。我们启发于这种哲学，提出了 Aurora，一个基于 GAN 的文本到图像生成器，该生成器使用一群专家来学习特征处理，并且使用稀有的路由器来帮助选择最适合的专家 для每个特征点。为了准确地将抽样偏移和文本条件传递到最终合成，我们的路由器动态做出决策，并考虑文本集成的全局幂等码。在 64x64 像素分辨率下，我们使用 LAION2B-en 和 COYO-700M 训练的模型达到 6.2 个零shot FID 在 MS COCO 上。我们将代码和检查点发布，以便社区进一步开发。
</details></li>
</ul>
<hr>
<h2 id="Tracking-Anything-with-Decoupled-Video-Segmentation"><a href="#Tracking-Anything-with-Decoupled-Video-Segmentation" class="headerlink" title="Tracking Anything with Decoupled Video Segmentation"></a>Tracking Anything with Decoupled Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03903">http://arxiv.org/abs/2309.03903</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkchengrex/Tracking-Anything-with-DEVA">https://github.com/hkchengrex/Tracking-Anything-with-DEVA</a></li>
<li>paper_authors: Ho Kei Cheng, Seoung Wug Oh, Brian Price, Alexander Schwing, Joon-Young Lee</li>
<li>for: 这篇论文旨在解决视频分割任务中的数据缺乏问题，使得扩展到新的视频分割任务更加困难。</li>
<li>methods: 该论文提出了一种分离视频分割方法（DEVA），它包括任务特定的图像级别分割和任务和类型无关的双向时间卷积。</li>
<li>results: 作者在多个数据缺乏任务中表示了这种方法的优势，包括大词汇视频精确分割、开放世界视频分割、引用视频分割和无监督视频物体分割。<details>
<summary>Abstract</summary>
Training data for video segmentation are expensive to annotate. This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in large-vocabulary settings. To 'track anything' without training on video data for every individual task, we develop a decoupled video segmentation approach (DEVA), composed of task-specific image-level segmentation and class/task-agnostic bi-directional temporal propagation. Due to this design, we only need an image-level model for the target task (which is cheaper to train) and a universal temporal propagation model which is trained once and generalizes across tasks. To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion of segmentation hypotheses from different frames to generate a coherent segmentation. We show that this decoupled formulation compares favorably to end-to-end approaches in several data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video segmentation, referring video segmentation, and unsupervised video object segmentation. Code is available at: https://hkchengrex.github.io/Tracking-Anything-with-DEVA
</details>
<details>
<summary>摘要</summary>
训练数据 для视频分割昂贵annotate。这阻碍了扩展到新的视频分割任务，��pecially在大词汇设定下。为了“跟踪任何”而不需要每个任务的视频数据训练，我们开发了分离视频分割方法（DEVA），它由任务特定的图像级别分割和任务和类型不可知的bi-directional时间推进动作组成。由于这种设计，我们只需要目标任务的图像级别模型（更 cheap to train）和一个通用的时间推进动作模型，这个模型在不同任务上通过一次训练而泛化。为了有效地结合这两个模块，我们使用bi-directional推进来（semi-)在线混合不同帧中的 segmentation 假设，以生成一个准确的分割。我们表明，这种分离的形式与端到端方法在多个数据缺乏任务中相比较好。代码可以在：https://hkchengrex.github.io/Tracking-Anything-with-DEVA 获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-Continuous-Exposure-Value-Representations-for-Single-Image-HDR-Reconstruction"><a href="#Learning-Continuous-Exposure-Value-Representations-for-Single-Image-HDR-Reconstruction" class="headerlink" title="Learning Continuous Exposure Value Representations for Single-Image HDR Reconstruction"></a>Learning Continuous Exposure Value Representations for Single-Image HDR Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03900">http://arxiv.org/abs/2309.03900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Su-Kai Chen, Hung-Lin Yen, Yu-Lun Liu, Min-Hung Chen, Hou-Ning Hu, Wen-Hsiao Peng, Yen-Yu Lin</li>
<li>for: 实现高动态变化的图像重建（HDR reconstruction），使用深度学习方法将LDR图像构成为HDR图像。</li>
<li>methods: 使用隐藏函数生成LDR图像的 kontinuous exposure value representation（CEVR），并使用循环训练策略来监督模型生成 kontinuous EV LDR图像。</li>
<li>results: 与现有方法相比，CEVR模型能够实现更高质量的HDR reconstruction。<details>
<summary>Abstract</summary>
Deep learning is commonly used to reconstruct HDR images from LDR images. LDR stack-based methods are used for single-image HDR reconstruction, generating an HDR image from a deep learning-generated LDR stack. However, current methods generate the stack with predetermined exposure values (EVs), which may limit the quality of HDR reconstruction. To address this, we propose the continuous exposure value representation (CEVR), which uses an implicit function to generate LDR images with arbitrary EVs, including those unseen during training. Our approach generates a continuous stack with more images containing diverse EVs, significantly improving HDR reconstruction. We use a cycle training strategy to supervise the model in generating continuous EV LDR images without corresponding ground truths. Our CEVR model outperforms existing methods, as demonstrated by experimental results.
</details>
<details>
<summary>摘要</summary>
深度学习通常用于从LDR图像中重建HDR图像。现有的方法使用LDR堆栈来实现单个图像HDR重建，但是现有方法通常使用预先确定的曝光值（EV）来生成堆栈，这可能会限制HDR重建的质量。为解决这个问题，我们提出了连续曝光值表示（CEVR），它使用隐式函数生成LDR图像中的任意EV，包括训练过程中未看到的EV。我们的方法生成了更多包含多样EV的图像，Significantly Improving HDR重建。我们使用循环训练策略来监督模型在生成连续EV LDR图像时，无需对应的真实值。我们的CEVR模型在实验结果中胜过现有方法。
</details></li>
</ul>
<hr>
<h2 id="The-Making-and-Breaking-of-Camouflage"><a href="#The-Making-and-Breaking-of-Camouflage" class="headerlink" title="The Making and Breaking of Camouflage"></a>The Making and Breaking of Camouflage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03899">http://arxiv.org/abs/2309.03899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hala Lamdouar, Weidi Xie, Andrew Zisserman<br>for: 这项研究旨在解决camouflage效果的评估问题，提出三种评估指标，以评估和比较不同隐身数据集的效果。methods: 研究使用了背景和前景特征相似性和边界可见度来评估隐身的效果，并在生成模型中使用这些评估指标作为 auxillary loss，可以生成高质量的隐身图像和视频。results: 实验表明，使用这些评估指标可以实现State-of-the-art的隐身摘帽性能，并且可以在大规模的视频segmentation任务中提高性能。<details>
<summary>Abstract</summary>
Not all camouflages are equally effective, as even a partially visible contour or a slight color difference can make the animal stand out and break its camouflage. In this paper, we address the question of what makes a camouflage successful, by proposing three scores for automatically assessing its effectiveness. In particular, we show that camouflage can be measured by the similarity between background and foreground features and boundary visibility. We use these camouflage scores to assess and compare all available camouflage datasets. We also incorporate the proposed camouflage score into a generative model as an auxiliary loss and show that effective camouflage images or videos can be synthesised in a scalable manner. The generated synthetic dataset is used to train a transformer-based model for segmenting camouflaged animals in videos. Experimentally, we demonstrate state-of-the-art camouflage breaking performance on the public MoCA-Mask benchmark.
</details>
<details>
<summary>摘要</summary>
不 todas las formas de camuflaje son igual de efectivas, ya que incluso una contour parcialmente visible o un ligero cambio de color puede hacer que el animal se destaque y rompa su camuflaje. En este artículo, abordamos la pregunta de qué hace que un camuflaje sea exitoso, proponiendo tres puntuaciones para evaluar su eficacia de forma automática. En particular, mostramos que el camuflaje se puede medir por la similitud entre las características de fondo y del foreground, así como la visibilidad de la boundaria. Incorporamos las puntuaciones de camuflaje propuestas en un modelo generativo como una pérdida auxiliar y demostramos que se pueden synthetizar imágenes o videos de camuflaje efectivos de manera escalable. El conjunto de datos sintético generado se utiliza para entrenar un modelo basado en transformers para segmentar animales camuflados en videos. Experimentalmente, demostramos un rendimiento de clasificación de camuflaje de estado del arte en el benchmark público MoCA-Mask.
</details></li>
</ul>
<hr>
<h2 id="ProPainter-Improving-Propagation-and-Transformer-for-Video-Inpainting"><a href="#ProPainter-Improving-Propagation-and-Transformer-for-Video-Inpainting" class="headerlink" title="ProPainter: Improving Propagation and Transformer for Video Inpainting"></a>ProPainter: Improving Propagation and Transformer for Video Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03897">http://arxiv.org/abs/2309.03897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sczhou/propainter">https://github.com/sczhou/propainter</a></li>
<li>paper_authors: Shangchen Zhou, Chongyi Li, Kelvin C. K. Chan, Chen Change Loy</li>
<li>for: 提高视频填充性能（VI）中的Flow-based媒体和空间时间Transformer机制的效果。</li>
<li>methods: 提出了改进的框架，称为ProPainter，它包括改进的ProPagation和高效的Transformer。 specifically, dual-domain propagation combines the advantages of image and feature warping, reliably exploiting global correspondences. 另外，我们还提出了一种面Mask-guided sparse video Transformer，可以高效地抛弃无用和重复的Token。</li>
<li>results: ProPainter比优先艺术品在PSNR指标上增加1.46 dB，同时保持了适度的效率。<details>
<summary>Abstract</summary>
Flow-based propagation and spatiotemporal Transformer are two mainstream mechanisms in video inpainting (VI). Despite the effectiveness of these components, they still suffer from some limitations that affect their performance. Previous propagation-based approaches are performed separately either in the image or feature domain. Global image propagation isolated from learning may cause spatial misalignment due to inaccurate optical flow. Moreover, memory or computational constraints limit the temporal range of feature propagation and video Transformer, preventing exploration of correspondence information from distant frames. To address these issues, we propose an improved framework, called ProPainter, which involves enhanced ProPagation and an efficient Transformer. Specifically, we introduce dual-domain propagation that combines the advantages of image and feature warping, exploiting global correspondences reliably. We also propose a mask-guided sparse video Transformer, which achieves high efficiency by discarding unnecessary and redundant tokens. With these components, ProPainter outperforms prior arts by a large margin of 1.46 dB in PSNR while maintaining appealing efficiency.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用流基本域和时间特征转换器是视频填充（VI）的两种主流机制。尽管这两种组件都有一定的局限性，但它们仍然会受到一些限制，影响其性能。前一代的卷积基本方法是在图像或特征空间分开进行，全球图像卷积可能会导致空间不一致，因为估算的光学流不准确。此外，记忆或计算限制会限制特征卷积和视频转换器的时间范围，防止在远程帧中检索相关信息。为解决这些问题，我们提出了改进的框架，称为ProPainter，它包括提升的ProPagation和高效的Transformer。我们引入了双域卷积，将图像和特征卷积的优点结合起来，可靠地利用全球匹配。我们还提出了面Mask指导的稀疏视频Transformer，它可以高效地抛弃无用和重复的token。与此前的方法相比，ProPainter在PSNR指标上提高了1.46 dB，同时保持了 attractive的效率。
</details></li>
</ul>
<hr>
<h2 id="InstructDiffusion-A-Generalist-Modeling-Interface-for-Vision-Tasks"><a href="#InstructDiffusion-A-Generalist-Modeling-Interface-for-Vision-Tasks" class="headerlink" title="InstructDiffusion: A Generalist Modeling Interface for Vision Tasks"></a>InstructDiffusion: A Generalist Modeling Interface for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03895">http://arxiv.org/abs/2309.03895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zigang Geng, Binxin Yang, Tiankai Hang, Chen Li, Shuyang Gu, Ting Zhang, Jianmin Bao, Zheng Zhang, Han Hu, Dong Chen, Baining Guo</li>
<li>for: 这篇论文旨在提出一种统一和通用的框架，用于将计算机视觉任务与人类指令相对应。</li>
<li>methods: 这种方法基于协抽程序，并在用户指令中预测像素。</li>
<li>results: 这种方法可以处理多种计算机视觉任务，包括理解任务（如分割和关键点检测）和生成任务（如编辑和提高）。它还可以处理未看过的任务和超越先前方法在新数据集上的性能。<details>
<summary>Abstract</summary>
We present InstructDiffusion, a unifying and generic framework for aligning computer vision tasks with human instructions. Unlike existing approaches that integrate prior knowledge and pre-define the output space (e.g., categories and coordinates) for each vision task, we cast diverse vision tasks into a human-intuitive image-manipulating process whose output space is a flexible and interactive pixel space. Concretely, the model is built upon the diffusion process and is trained to predict pixels according to user instructions, such as encircling the man's left shoulder in red or applying a blue mask to the left car. InstructDiffusion could handle a variety of vision tasks, including understanding tasks (such as segmentation and keypoint detection) and generative tasks (such as editing and enhancement). It even exhibits the ability to handle unseen tasks and outperforms prior methods on novel datasets. This represents a significant step towards a generalist modeling interface for vision tasks, advancing artificial general intelligence in the field of computer vision.
</details>
<details>
<summary>摘要</summary>
我们介绍InstructDiffusion，一种普适和通用的框架，用于将计算机视觉任务与人类指令相对应。与现有方法不同，InstructDiffusion不需要将每个视觉任务的输出空间（例如，类别和坐标）预先定义，而是将多种视觉任务映射到一个人性化的图像修改过程中，其输出空间是一个可以互动的像素空间。具体来说，模型基于协振过程，并通过用户指令（如红色围绕男士左肩的框或蓝色涂抹到左车）预测像素。InstructDiffusion可以处理多种视觉任务，包括理解任务（如分割和关键点检测）和生成任务（如编辑和提高）。它甚至可以处理未看到的任务，并在新数据集上表现出excel。这表明InstructDiffusion可以作为计算机视觉领域的通用模型化接口，为人工通用智能领域带来重大进步。
</details></li>
</ul>
<hr>
<h2 id="BluNF-Blueprint-Neural-Field"><a href="#BluNF-Blueprint-Neural-Field" class="headerlink" title="BluNF: Blueprint Neural Field"></a>BluNF: Blueprint Neural Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03933">http://arxiv.org/abs/2309.03933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robin Courant, Xi Wang, Marc Christie, Vicky Kalogeiton</li>
<li>for: 这篇论文是关于Scene Novel View Synthesis的研究，旨在提供可观赏、精度、robust的隐式重建。</li>
<li>methods: 这篇论文使用Neural Radiance Fields（NeRFs）来实现Scene Novel View Synthesis，并提出了一种新的编辑方法，即Blueprint Neural Field（BluNF）。BluNF使用Implicit Neural Representation来构建场景的蓝图，以便INTUITIVE的场景编辑。</li>
<li>results: 这篇论文的实验结果表明，BluNF可以帮助人们INTUITIVE地编辑场景，包括对NeRF表示的3D形状和物理属性的修改。此外，BluNF还可以提供一种精度的3D manipulation方法，如场景的掩蔽、外观修改和物体的移除。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have revolutionized scene novel view synthesis, offering visually realistic, precise, and robust implicit reconstructions. While recent approaches enable NeRF editing, such as object removal, 3D shape modification, or material property manipulation, the manual annotation prior to such edits makes the process tedious. Additionally, traditional 2D interaction tools lack an accurate sense of 3D space, preventing precise manipulation and editing of scenes. In this paper, we introduce a novel approach, called Blueprint Neural Field (BluNF), to address these editing issues. BluNF provides a robust and user-friendly 2D blueprint, enabling intuitive scene editing. By leveraging implicit neural representation, BluNF constructs a blueprint of a scene using prior semantic and depth information. The generated blueprint allows effortless editing and manipulation of NeRF representations. We demonstrate BluNF's editability through an intuitive click-and-change mechanism, enabling 3D manipulations, such as masking, appearance modification, and object removal. Our approach significantly contributes to visual content creation, paving the way for further research in this area.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRFs) have revolutionized scene novel view synthesis, offering visually realistic, precise, and robust implicit reconstructions. while recent approaches enable NeRF editing, such as object removal, 3D shape modification, or material property manipulation, the manual annotation prior to such edits makes the process tedious. additionally, traditional 2D interaction tools lack an accurate sense of 3D space, preventing precise manipulation and editing of scenes. in this paper, we introduce a novel approach, called Blueprint Neural Field (BluNF), to address these editing issues. blunf provides a robust and user-friendly 2D blueprint, enabling intuitive scene editing. by leveraging implicit neural representation, blunf constructs a blueprint of a scene using prior semantic and depth information. the generated blueprint allows effortless editing and manipulation of NeRF representations. we demonstrate blunf's editability through an intuitive click-and-change mechanism, enabling 3D manipulations, such as masking, appearance modification, and object removal. our approach significantly contributes to visual content creation, paving the way for further research in this area.
</details></li>
</ul>
<hr>
<h2 id="ArtiGrasp-Physically-Plausible-Synthesis-of-Bi-Manual-Dexterous-Grasping-and-Articulation"><a href="#ArtiGrasp-Physically-Plausible-Synthesis-of-Bi-Manual-Dexterous-Grasping-and-Articulation" class="headerlink" title="ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation"></a>ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03891">http://arxiv.org/abs/2309.03891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Sammy Christen, Zicong Fan, Luocheng Zheng, Jemin Hwangbo, Jie Song, Otmar Hilliges</li>
<li>for: 这个论文的目的是提出一种新的手套控制方法，用于Synthesize bi-manual hand-object interactions，包括抓取和折叠动作。</li>
<li>methods: 该方法使用了强化学习和物理 simulations来训练一个控制全身姿势和精确的手指控制的政策。</li>
<li>results: 该方法可以在Dynamic Object Grasping and Articulation任务中提供高效的解决方案，并且可以适应不同的姿势和物体。<details>
<summary>Abstract</summary>
We present ArtiGrasp, a novel method to synthesize bi-manual hand-object interactions that include grasping and articulation. This task is challenging due to the diversity of the global wrist motions and the precise finger control that are necessary to articulate objects. ArtiGrasp leverages reinforcement learning and physics simulations to train a policy that controls the global and local hand pose. Our framework unifies grasping and articulation within a single policy guided by a single hand pose reference. Moreover, to facilitate the training of the precise finger control required for articulation, we present a learning curriculum with increasing difficulty. It starts with single-hand manipulation of stationary objects and continues with multi-agent training including both hands and non-stationary objects. To evaluate our method, we introduce Dynamic Object Grasping and Articulation, a task that involves bringing an object into a target articulated pose. This task requires grasping, relocation, and articulation. We show our method's efficacy towards this task. We further demonstrate that our method can generate motions with noisy hand-object pose estimates from an off-the-shelf image-based regressor.
</details>
<details>
<summary>摘要</summary>
我们提出了ArtiGrasp方法，用于生成双手手动对象互动，包括抓取和肢体运动。由于全球肘部运动的多样性和必要的精准指控来实现对象的肢体运动，这是一项挑战性的任务。ArtiGrasp利用了奖励学习和物理模拟来训练一个控制全球和局部手姿的策略。我们的框架将抓取和肢体运动团结在一个单一的策略下，即一个手姿参考。此外，为了帮助学习精准的指控，我们提供了一个学习课程，其中从单手操作静止物体开始，然后是多机器人培训，包括双手和不稳定的物体。为评估我们的方法，我们引入了动态物体抓取和肢体运动任务，这个任务需要抓取、重新定位和肢体运动。我们证明了我们的方法的有效性。此外，我们还示出了使用市场上的图像回归器获取噪音手姿估计后，我们的方法仍可生成有效的手动对象互动。
</details></li>
</ul>
<hr>
<h2 id="Better-Practices-for-Domain-Adaptation"><a href="#Better-Practices-for-Domain-Adaptation" class="headerlink" title="Better Practices for Domain Adaptation"></a>Better Practices for Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03879">http://arxiv.org/abs/2309.03879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linus Ericsson, Da Li, Timothy M. Hospedales<br>for: 本研究旨在 Addressing the challenge of domain shift in real-world machine learning applications, particularly the difficulty of performing hyperparameter optimization for domain adaptation algorithms without access to a labeled validation set.methods: The paper uses a suite of candidate validation criteria to benchmark popular adaptation algorithms and assess their performance.results: The results show that there are challenges across all three branches of domain adaptation methodology, including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). However, the paper also demonstrates that using proper validation splits and exploring new validation metrics can improve performance.<details>
<summary>Abstract</summary>
Distribution shifts are all too common in real-world applications of machine learning. Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels. However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set. The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available. This has resulted in over-optimism about DA research progress compared to reality. In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms. We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date. Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.
</details>
<details>
<summary>摘要</summary>
发布分布shift是现实世界应用机器学习中的普遍现象。领域适应（DA）目标是解决这个问题，提供不使用标签的方法来适应模型到部署数据。然而，领域转换场景带来一个更加细微的挑战：无法在无标签验证集上进行超参论调整。这在文献中存在坏习惯，如使用目标测试标签进行超参论调整，而在实际应用中，这些标签不可用。这导致了对DA研究进展的过度估计。在这篇论文中，我们分析了使用好的评估方式进行DA时的状态，并对一组候选验证标准进行比较。我们发现了领域适应方法学习的三个支序中的挑战，包括无监督领域适应（UDA）、源自由领域适应（SFDA）和测试时适应（TTA）。虽然结果表明实际可以达到的性能通常比预期更差，但是也表明使用正确的验证分割是有利的，同时也表明了一些未曾探索的验证指标可以提供最佳选择至今。总之，我们提出了一种新的严格的管道，包括数据、训练、验证和超参论调整，以改进DA研究的进程，并在这个重要领域内进行未来的进步。
</details></li>
</ul>
<hr>
<h2 id="Box-based-Refinement-for-Weakly-Supervised-and-Unsupervised-Localization-Tasks"><a href="#Box-based-Refinement-for-Weakly-Supervised-and-Unsupervised-Localization-Tasks" class="headerlink" title="Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks"></a>Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03874">http://arxiv.org/abs/2309.03874</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eyalgomel/box-based-refinement">https://github.com/eyalgomel/box-based-refinement</a></li>
<li>paper_authors: Eyal Gomel, Tal Shaharabany, Lior Wolf</li>
<li>for: 提高弱化监督和无监督方法的本地化性能</li>
<li>methods: 使用框架基于的检测网络，并在网络输出上训练检测器，采用适当的损失反propagation</li>
<li>results: 显著提高了“我们是哪里看到了什么”任务的表达精度，以及多种无监督物体发现方法<details>
<summary>Abstract</summary>
It has been established that training a box-based detector network can enhance the localization performance of weakly supervised and unsupervised methods. Moreover, we extend this understanding by demonstrating that these detectors can be utilized to improve the original network, paving the way for further advancements. To accomplish this, we train the detectors on top of the network output instead of the image data and apply suitable loss backpropagation. Our findings reveal a significant improvement in phrase grounding for the ``what is where by looking'' task, as well as various methods of unsupervised object discovery. Our code is available at https://github.com/eyalgomel/box-based-refinement.
</details>
<details>
<summary>摘要</summary>
已经证明，使用库型检测网络进行训练可以增强弱监督和无监督方法的地方化性能。此外，我们将这些检测器应用到原始网络上，以便进一步提高。我们在网络输出上训练这些检测器，并将损失传播 backwards。我们的研究发现，这些检测器可以帮助解决“我在哪里看到了什么”的任务，以及其他无监督物品发现方法。我们的代码可以在 GitHub 上找到：https://github.com/eyalgomel/box-based-refinement。
</details></li>
</ul>
<hr>
<h2 id="Text-to-feature-diffusion-for-audio-visual-few-shot-learning"><a href="#Text-to-feature-diffusion-for-audio-visual-few-shot-learning" class="headerlink" title="Text-to-feature diffusion for audio-visual few-shot learning"></a>Text-to-feature diffusion for audio-visual few-shot learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03869">http://arxiv.org/abs/2309.03869</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/explainableml/avdiff-gfsl">https://github.com/explainableml/avdiff-gfsl</a></li>
<li>paper_authors: Otniel-Bogdan Mercea, Thomas Hummel, A. Sophia Koepke, Zeynep Akata</li>
<li>for: 这 paper 的目的是提出一个 audio-visual 少量数据集，用于训练深度学习模型进行视频分类。</li>
<li>methods: 这 paper 使用了十种方法，包括 AV-DIFF，一个基于文本到特征扩散的框架，用于将多Modal特征拼接在一起。</li>
<li>results: 根据这 paper，使用 AV-DIFF 方法可以在 audio-visual 少量数据集上达到状态之 искусственный智能的性能。<details>
<summary>Abstract</summary>
Training deep learning models for video classification from audio-visual data commonly requires immense amounts of labeled training data collected via a costly process. A challenging and underexplored, yet much cheaper, setup is few-shot learning from video data. In particular, the inherently multi-modal nature of video data with sound and visual information has not been leveraged extensively for the few-shot video classification task. Therefore, we introduce a unified audio-visual few-shot video classification benchmark on three datasets, i.e. the VGGSound-FSL, UCF-FSL, ActivityNet-FSL datasets, where we adapt and compare ten methods. In addition, we propose AV-DIFF, a text-to-feature diffusion framework, which first fuses the temporal and audio-visual features via cross-modal attention and then generates multi-modal features for the novel classes. We show that AV-DIFF obtains state-of-the-art performance on our proposed benchmark for audio-visual (generalised) few-shot learning. Our benchmark paves the way for effective audio-visual classification when only limited labeled data is available. Code and data are available at https://github.com/ExplainableML/AVDIFF-GFSL.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>训练深度学习模型用于视频分类从audio-visual数据中需要巨大量的标注训练数据，这是一个昂贵的过程。一个挑战性和尚未得到充分开发的 setup 是几个shot学习从视频数据中。特别是，视频数据的内在多模式性，即声音和视觉信息，尚未得到广泛利用于几个shot视频分类任务。因此，我们引入一个统一的audio-visual几个shot视频分类标准benchmark，包括VGGSound-FSL、UCF-FSL和ActivityNet-FSL三个数据集，我们适应和比较了十种方法。此外，我们提出了AV-DIFF，一个文本到特征扩散框架，它首先将时间和音频-视觉特征 fusionvia Cross-modal注意力，然后生成多模式特征 для新的类。我们证明了AV-DIFF在我们提出的benchmark上实现了状态独一的性能，我们的benchmark为有限标注数据时的音频-视觉分类提供了一个有效的平台。代码和数据可以在https://github.com/ExplainableML/AVDIFF-GFSL上找到。
</details></li>
</ul>
<hr>
<h2 id="CenTime-Event-Conditional-Modelling-of-Censoring-in-Survival-Analysis"><a href="#CenTime-Event-Conditional-Modelling-of-Censoring-in-Survival-Analysis" class="headerlink" title="CenTime: Event-Conditional Modelling of Censoring in Survival Analysis"></a>CenTime: Event-Conditional Modelling of Censoring in Survival Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03851">http://arxiv.org/abs/2309.03851</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmedhshahin/CenTime">https://github.com/ahmedhshahin/CenTime</a></li>
<li>paper_authors: Ahmed H. Shahin, An Zhao, Alexander C. Whitehead, Daniel C. Alexander, Joseph Jacob, David Barber</li>
<li>for: 预测医疗机器学习模型中的时间到事件（time to event，TTE），以便更好地预测临床重要事件的发生时间。</li>
<li>methods: 提出了一种新的事件减少机制，可以在 censored 样本中实现稳定的 estimator ，并且可以与深度学习模型集成，不受批处大小或uncensored样本数量的限制。</li>
<li>results: 与标准生存分析方法，如科кс准则模型和 DeepHit，进行比较，得到了 state-of-the-art 的时间到死亡预测性能，同时维持了相似的排名性能。<details>
<summary>Abstract</summary>
Survival analysis is a valuable tool for estimating the time until specific events, such as death or cancer recurrence, based on baseline observations. This is particularly useful in healthcare to prognostically predict clinically important events based on patient data. However, existing approaches often have limitations; some focus only on ranking patients by survivability, neglecting to estimate the actual event time, while others treat the problem as a classification task, ignoring the inherent time-ordered structure of the events. Furthermore, the effective utilization of censored samples - training data points where the exact event time is unknown - is essential for improving the predictive accuracy of the model. In this paper, we introduce CenTime, a novel approach to survival analysis that directly estimates the time to event. Our method features an innovative event-conditional censoring mechanism that performs robustly even when uncensored data is scarce. We demonstrate that our approach forms a consistent estimator for the event model parameters, even in the absence of uncensored data. Furthermore, CenTime is easily integrated with deep learning models with no restrictions on batch size or the number of uncensored samples. We compare our approach with standard survival analysis methods, including the Cox proportional-hazard model and DeepHit. Our results indicate that CenTime offers state-of-the-art performance in predicting time-to-death while maintaining comparable ranking performance. Our implementation is publicly available at https://github.com/ahmedhshahin/CenTime.
</details>
<details>
<summary>摘要</summary>
生存分析是一种有用的工具，可以根据基线观察数据来预测特定事件的时间，如死亡或癌症复发。这特别有用在医疗领域，可以预测基于病人数据的临床重要事件。然而，现有的方法往往有限制，一些只能将患者排序按照生存可能性，而忽略实际事件时间的估计；另一些对事件问题进行分类处理，忽略事件的内在时间顺序结构。此外，利用 censored 样本的有效使用是必要的，以提高预测模型的准确性。在这篇论文中，我们介绍了 CenTime，一种新的生存分析方法，可以直接估计事件时间。我们的方法具有创新的事件 conditional 封闭机制，可以在缺失完整事件时间的情况下表现稳定。我们示示了我们的方法可以在缺失完整数据的情况下成为事件模型参数的一致 estimator。此外，CenTime 可以轻松地与深度学习模型结合使用，无需Restrictions on batch size 或无 censored 样本数量。我们与标准生存分析方法，包括 Cox 幂度模型和 DeepHit 进行比较，结果表明 CenTime 在预测时间到死亡的性能处于国际前列，同时保持与排序性能相对一致。我们的实现可以在 <https://github.com/ahmedhshahin/CenTime> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Random-Expert-Sampling-for-Deep-Learning-Segmentation-of-Acute-Ischemic-Stroke-on-Non-contrast-CT"><a href="#Random-Expert-Sampling-for-Deep-Learning-Segmentation-of-Acute-Ischemic-Stroke-on-Non-contrast-CT" class="headerlink" title="Random Expert Sampling for Deep Learning Segmentation of Acute Ischemic Stroke on Non-contrast CT"></a>Random Expert Sampling for Deep Learning Segmentation of Acute Ischemic Stroke on Non-contrast CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03930">http://arxiv.org/abs/2309.03930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sophie Ostmeier, Brian Axelrod, Benjamin Pulli, Benjamin F. J. Verhaaren, Abdelkader Mahammedi, Yongkai Liu, Christian Federau, Greg Zaharchuk, Jeremy J. Heit<br>for: The paper aims to develop and validate a deep learning method for automatically quantifying ischemic brain tissue on non-contrast CT scans in patients with acute ischemic stroke.methods: The authors used a benchmark U-Net model trained on reference annotations from three experienced neuroradiologists using two training schemes: majority vote and random expert sampling. They compared the performance of these schemes using a one-sided Wilcoxon signed-rank test and consistency analysis.results: The random expert sampling scheme led to a model that showed better agreement with the experts and better consistency than the majority-vote model. The model also predicted the final infarct volume and correlated better with the clinical outcome than CT perfusion.Here is the information in Simplified Chinese text:for: 这篇论文目的是开发和验证一种使用非对照CT成像的多专家深度学习方法，用于自动评估急性血液血管受损脑部病变。methods: 作者使用了一个参考U-Net模型，并使用了三名经验丰富的 neuroradiologists 的参考标注来训练这个模型。他们使用了一个一侧 Wilcoxon 签名rank 测试和一致性分析来比较这两种训练方案的表现。results: 随机专家采样方案导致了一个与专家更加一致的模型，并且与专家之间的一致性更高，并且与多数投票模型性能相比有61%的提升（Surface Dice 在快速识别精度5mm上提升了0.70+-0.03）和25%的提升（Dice 在0.50+-0.04）。这个模型可以准确预测急性血液血管受损脑部病变的总量，并且与临床结果相关性更高。<details>
<summary>Abstract</summary>
Purpose: Multi-expert deep learning training methods to automatically quantify ischemic brain tissue on Non-Contrast CT Materials and Methods: The data set consisted of 260 Non-Contrast CTs from 233 patients of acute ischemic stroke patients recruited in the DEFUSE 3 trial. A benchmark U-Net was trained on the reference annotations of three experienced neuroradiologists to segment ischemic brain tissue using majority vote and random expert sampling training schemes. We used a one-sided Wilcoxon signed-rank test on a set of segmentation metrics to compare bootstrapped point estimates of the training schemes with the inter-expert agreement and ratio of variance for consistency analysis. We further compare volumes with the 24h-follow-up DWI (final infarct core) in the patient subgroup with full reperfusion and we test volumes for correlation to the clinical outcome (mRS after 30 and 90 days) with the Spearman method. Results: Random expert sampling leads to a model that shows better agreement with experts than experts agree among themselves and better agreement than the agreement between experts and a majority-vote model performance (Surface Dice at Tolerance 5mm improvement of 61% to 0.70 +- 0.03 and Dice improvement of 25% to 0.50 +- 0.04). The model-based predicted volume similarly estimated the final infarct volume and correlated better to the clinical outcome than CT perfusion. Conclusion: A model trained on random expert sampling can identify the presence and location of acute ischemic brain tissue on Non-Contrast CT similar to CT perfusion and with better consistency than experts. This may further secure the selection of patients eligible for endovascular treatment in less specialized hospitals.
</details>
<details>
<summary>摘要</summary>
目的：使用多个专家深度学习训练方法自动评估非contrast CT中的血液脑部分量。方法：数据集包括260个非contrast CT图像，来自233名stroke患者，参与DEFUSE 3试验。我们使用一个benchmark U-Net模型，通过多个专家的参照注释来 segment非contrast CT中的血液脑部分。我们使用一个一侧Wilcoxon签名rank测试来比较各种训练方案的点估计与专家之间的一致性和差异分析。此外，我们还比较了患者 subgroup中的24小时后DWI（最终损伤核心）和临床结果（mRS after 30和90天）之间的相关性。结果：随机专家采样导致一个模型，与专家之间的一致性更高，并且与专家和多数投票模型的性能相比（Surface Dice at Tolerance 5mm改进率为61%，Dice改进率为25%）。该模型预测的量也准确地估计了最终损伤量，并且与临床结果更好地相关。结论：一个基于随机专家采样的模型可以在非contrast CT中准确地识别和定位急性血液脑部分，与CT perfusion相似，并且与专家之间的一致性更高。这可能会为eless specialized hospitals中选择患者渠道进行Endovascular treatment提供更安全的选择。
</details></li>
</ul>
<hr>
<h2 id="Cross-Task-Attention-Network-Improving-Multi-Task-Learning-for-Medical-Imaging-Applications"><a href="#Cross-Task-Attention-Network-Improving-Multi-Task-Learning-for-Medical-Imaging-Applications" class="headerlink" title="Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications"></a>Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03837">http://arxiv.org/abs/2309.03837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwook Kim, Thomas G. Purdie, Chris McIntosh<br>for:This paper aims to improve the performance of medical imaging tasks using a novel attention-based multi-task learning (MTL) framework.methods:The proposed framework is called Cross-Task Attention Network (CTAN), which utilizes cross-task attention mechanisms to incorporate information from multiple tasks and improve performance.results:Compared to standard single-task learning (STL) and two widely used MTL baselines, CTAN demonstrated a 4.67% improvement in performance and outperformed both baselines. Specifically, CTAN outperformed HPS by 3.22% and MTAN by 5.38%. These findings highlight the effectiveness of CTAN in improving the accuracy of medical imaging tasks across different domains.<details>
<summary>Abstract</summary>
Multi-task learning (MTL) is a powerful approach in deep learning that leverages the information from multiple tasks during training to improve model performance. In medical imaging, MTL has shown great potential to solve various tasks. However, existing MTL architectures in medical imaging are limited in sharing information across tasks, reducing the potential performance improvements of MTL. In this study, we introduce a novel attention-based MTL framework to better leverage inter-task interactions for various tasks from pixel-level to image-level predictions. Specifically, we propose a Cross-Task Attention Network (CTAN) which utilizes cross-task attention mechanisms to incorporate information by interacting across tasks. We validated CTAN on four medical imaging datasets that span different domains and tasks including: radiation treatment planning prediction using planning CT images of two different target cancers (Prostate, OpenKBP); pigmented skin lesion segmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19 diagnosis and severity prediction using chest CT scans (STOIC). Our study demonstrates the effectiveness of CTAN in improving the accuracy of medical imaging tasks. Compared to standard single-task learning (STL), CTAN demonstrated a 4.67% improvement in performance and outperformed both widely used MTL baselines: hard parameter sharing (HPS) with an average performance improvement of 3.22%; and multi-task attention network (MTAN) with a relative decrease of 5.38%. These findings highlight the significance of our proposed MTL framework in solving medical imaging tasks and its potential to improve their accuracy across domains.
</details>
<details>
<summary>摘要</summary>
多任务学习（MTL）是深度学习中的一种强大方法，利用多个任务的信息在训练中共享，以提高模型性能。在医疗影像领域，MTL已经实现了各种任务的解决。然而，现有的医疗影像MTL建 Architecture是有限的，它们在任务之间的信息共享上有所局限，从而减少了MTL的性能提升 potential.在本研究中，我们提出了一种新的注意力基于的MTL框架，以更好地利用多个任务之间的交互来提高各种任务的预测性能。具体来说，我们提出了一种交互式多任务注意力网络（CTAN），该网络通过交互式注意力机制来集成多个任务的信息。我们在四个医疗影像数据集上验证了CTAN，这些数据集包括了两种不同的目标肿瘤（肾癌和开口KBP）的规划计划预测、睫状皮肤损伤和诊断、以及COVID-19的诊断和严重程度预测。我们的研究表明，CTAN在医疗影像任务中的准确性得到了提高。相比于标准单任务学习（STL），CTAN在 average 上提高了4.67%的性能，并在多个MTL基线上超越了：硬件参数共享（HPS）的平均性能提升3.22%，以及多任务注意力网络（MTAN）的相对下降5.38%。这些发现表明了我们提出的MTL框架在解决医疗影像任务方面的重要性和其在不同领域中的可行性。
</details></li>
</ul>
<hr>
<h2 id="ArtHDR-Net-Perceptually-Realistic-and-Accurate-HDR-Content-Creation"><a href="#ArtHDR-Net-Perceptually-Realistic-and-Accurate-HDR-Content-Creation" class="headerlink" title="ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation"></a>ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03827">http://arxiv.org/abs/2309.03827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishav Bakul Barua, Ganesh Krishnasamy, KokSheik Wong, Kalin Stefanov, Abhinav Dhall</li>
<li>for: 这篇论文旨在探讨高动态范围（HDR）内容创建中，如何保持图像的艺术意义，即人类视觉对图像的感受。</li>
<li>methods: 该论文提出了一种基于卷积神经网络的Architecture，称为ArtHDR-Net，使用多张曝光LDR特征作为输入。</li>
<li>results: 实验结果表明，ArtHDR-Net可以达到状态的艺术意义水平（HDR-VDP-2分数），同时在PSNR和SSIM指标中实现竞争性的表现。<details>
<summary>Abstract</summary>
High Dynamic Range (HDR) content creation has become an important topic for modern media and entertainment sectors, gaming and Augmented/Virtual Reality industries. Many methods have been proposed to recreate the HDR counterparts of input Low Dynamic Range (LDR) images/videos given a single exposure or multi-exposure LDRs. The state-of-the-art methods focus primarily on the preservation of the reconstruction's structural similarity and the pixel-wise accuracy. However, these conventional approaches do not emphasize preserving the artistic intent of the images in terms of human visual perception, which is an essential element in media, entertainment and gaming. In this paper, we attempt to study and fill this gap. We propose an architecture called ArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR features as input. Experimental results show that ArtHDR-Net can achieve state-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean opinion score index) while reaching competitive performance in terms of PSNR and SSIM.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）内容创建已成为现代媒体和娱乐领域的重要话题，游戏和虚拟/增强现实领域。许多方法已经被提议，以便基于单张或多张抖动范围（LDR）图像/视频来重建HDR对应的Counterpart。当前的状态艺术方法主要关注重建结构的相似性和每个像素的准确率。然而，这些惯常的方法不强调保持图像的艺术意愿，即人类视觉的感知，这是媒体、娱乐和游戏领域的重要元素。在这篇论文中，我们尝试研究并填补这个空白。我们提出了一种 Architecture called ArtHDR-Net，基于卷积神经网络，使用多张抖动范围特征为输入。实验结果表明，ArtHDR-Net 可以达到当今最佳性能，而且与 PSNR 和 SSIM 的性能竞争。
</details></li>
</ul>
<hr>
<h2 id="T2IW-Joint-Text-to-Image-Watermark-Generation"><a href="#T2IW-Joint-Text-to-Image-Watermark-Generation" class="headerlink" title="T2IW: Joint Text to Image &amp; Watermark Generation"></a>T2IW: Joint Text to Image &amp; Watermark Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03815">http://arxiv.org/abs/2309.03815</a></li>
<li>repo_url: None</li>
<li>paper_authors: An-An Liu, Guokai Zhang, Yuting Su, Ning Xu, Yongdong Zhang, Lanjun Wang</li>
<li>for: 这个研究旨在提出一个新的文本背景下的图像生成模型，以满足traceability、隐私保护和其他安全需求。</li>
<li>methods: 本研究使用文本与水印（T2IW）任务，强制semantic feature和水印信号在像素层次保持compatibility，并运用信息理论和非合作游戏理论分离图像和水印。</li>
<li>results: 实验结果显示本方法可以实现优秀的图像质量、水印隐藏和水印Robustness，并提出了一个新的评估指标集。<details>
<summary>Abstract</summary>
Recent developments in text-conditioned image generative models have revolutionized the production of realistic results. Unfortunately, this has also led to an increase in privacy violations and the spread of false information, which requires the need for traceability, privacy protection, and other security measures. However, existing text-to-image paradigms lack the technical capabilities to link traceable messages with image generation. In this study, we introduce a novel task for the joint generation of text to image and watermark (T2IW). This T2IW scheme ensures minimal damage to image quality when generating a compound image by forcing the semantic feature and the watermark signal to be compatible in pixels. Additionally, by utilizing principles from Shannon information theory and non-cooperative game theory, we are able to separate the revealed image and the revealed watermark from the compound image. Furthermore, we strengthen the watermark robustness of our approach by subjecting the compound image to various post-processing attacks, with minimal pixel distortion observed in the revealed watermark. Extensive experiments have demonstrated remarkable achievements in image quality, watermark invisibility, and watermark robustness, supported by our proposed set of evaluation metrics.
</details>
<details>
<summary>摘要</summary>
最近的文本conditioned图像生成模型的发展，使得生成真实的结果变得更加容易。然而，这也导致了隐私泄露和假信息的扩散，需要Traceability、隐私保护和其他安全措施。然而，现有的文本到图像的思维方法缺乏技术能力，将可追溯的消息与图像生成相连。在这项研究中，我们介绍了一种新的文本到图像和水印（T2IW）任务。这种T2IW方案确保在生成复合图像时，Semantic feature和水印信号在像素级别保持Compatible。此外，通过利用信息理论和非合作游戏理论，我们可以将复合图像中的Revealed image和Revealed watermark分离开。此外，我们通过对复合图像进行不同类型的后处理攻击，保持了Minimal pixel distortion在Revealed watermark中。广泛的实验证明了我们提出的方法在图像质量、隐私性和隐私稳定性方面具有很好的表现，支持我们提出的评价指标集。
</details></li>
</ul>
<hr>
<h2 id="Panoramas-from-Photons"><a href="#Panoramas-from-Photons" class="headerlink" title="Panoramas from Photons"></a>Panoramas from Photons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03811">http://arxiv.org/abs/2309.03811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sacha Jungerman, Atul Ingle, Mohit Gupta</li>
<li>for: 能够在高速运动和低照度下重建场景，如果应用于虚拟现实、无人机导航和自动化机器人等领域。</li>
<li>methods: 使用聚合和排序框架，以 iteratively 提高运动估计。</li>
<li>results: 可以在高速运动和极低照度下创建高质量的全景图和超分辨率结果，使用自定义单 photon 摄像头原型。<details>
<summary>Abstract</summary>
Scene reconstruction in the presence of high-speed motion and low illumination is important in many applications such as augmented and virtual reality, drone navigation, and autonomous robotics. Traditional motion estimation techniques fail in such conditions, suffering from too much blur in the presence of high-speed motion and strong noise in low-light conditions. Single-photon cameras have recently emerged as a promising technology capable of capturing hundreds of thousands of photon frames per second thanks to their high speed and extreme sensitivity. Unfortunately, traditional computer vision techniques are not well suited for dealing with the binary-valued photon data captured by these cameras because these are corrupted by extreme Poisson noise. Here we present a method capable of estimating extreme scene motion under challenging conditions, such as low light or high dynamic range, from a sequence of high-speed image frames such as those captured by a single-photon camera. Our method relies on iteratively improving a motion estimate by grouping and aggregating frames after-the-fact, in a stratified manner. We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype. For code and supplemental material see our $\href{https://wisionlab.com/project/panoramas-from-photons/}{\text{project webpage}$.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we present a method that can estimate extreme scene motion under challenging conditions, such as low light or high dynamic range, from a sequence of high-speed image frames captured by a single-photon camera. Our method relies on iteratively improving a motion estimate by grouping and aggregating frames after-the-fact, in a stratified manner. We demonstrate the creation of high-quality panoramas under fast motion and extremely low light, and super-resolution results using a custom single-photon camera prototype. For more information and supplemental material, please visit our project webpage at $\href{https://wisionlab.com/project/panoramas-from-photons/}{\text{https://wisionlab.com/project/panoramas-from-photons/}$.
</details></li>
</ul>
<hr>
<h2 id="SimNP-Learning-Self-Similarity-Priors-Between-Neural-Points"><a href="#SimNP-Learning-Self-Similarity-Priors-Between-Neural-Points" class="headerlink" title="SimNP: Learning Self-Similarity Priors Between Neural Points"></a>SimNP: Learning Self-Similarity Priors Between Neural Points</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03809">http://arxiv.org/abs/2309.03809</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Wewer, Eddy Ilg, Bernt Schiele, Jan Eric Lenssen</li>
<li>for: 本研究旨在提高3D物体重建的 neural field 表示，特别是利用对象级别表示来提高物体的细节质量。</li>
<li>methods: 我们提出了 SimNP 方法，它将 neural point radiance fields 与对象级别自相似表示相结合，以获得更高质量的重建结果。我们首次在 neural point 中实现了类别级别自相似表示，从而保留了本地支持的物体区域的高级别细节。此外，我们还学习了 neural point 之间的信息共享方式，以便在重建过程中提取未见区域的信息。</li>
<li>results: SimNP 方法能够在重建 symmetric 的未见区域时，超越基于类别级别或像素对齐的 radiance fields 方法，同时提供 semantic 对应关系 между实例。我们的实验结果表明，SimNP 能够在不同的物体类别和观察角度下实现更高质量的重建结果。<details>
<summary>Abstract</summary>
Existing neural field representations for 3D object reconstruction either (1) utilize object-level representations, but suffer from low-quality details due to conditioning on a global latent code, or (2) are able to perfectly reconstruct the observations, but fail to utilize object-level prior knowledge to infer unobserved regions. We present SimNP, a method to learn category-level self-similarities, which combines the advantages of both worlds by connecting neural point radiance fields with a category-level self-similarity representation. Our contribution is two-fold. (1) We design the first neural point representation on a category level by utilizing the concept of coherent point clouds. The resulting neural point radiance fields store a high level of detail for locally supported object regions. (2) We learn how information is shared between neural points in an unconstrained and unsupervised fashion, which allows to derive unobserved regions of an object during the reconstruction process from given observations. We show that SimNP is able to outperform previous methods in reconstructing symmetric unseen object regions, surpassing methods that build upon category-level or pixel-aligned radiance fields, while providing semantic correspondences between instances
</details>
<details>
<summary>摘要</summary>
现有的神经场表示方法 для三维物体重建都是（1）使用物体级别表示，但是因为conditioning于全局归一化代码而导致细节质量低下，或者（2）能够完美地重建观察数据，但是不能利用物体级别知识来推断未观察到的区域。我们提出了SimNP方法，它将神经点频谱场与类别级自相似表示相结合，以便结合两者的优点。我们的贡献有两个方面：1. 我们设计了首次基于类别水平的神经点表示，通过利用coherent点云概念。神经点频谱场中的高级别细节可以在支持本地物体区域时被存储。2. 我们学习了在无约束和无监督的情况下，神经点之间的信息共享方式，以便在重建过程中从观察数据中推断未观察到的区域。我们展示了SimNP方法能够在重建不见的对称区域方面超过前一代方法，而且提供semantic对应关系 между实例。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Safety-Concerns-in-Automated-Driving-Perception"><a href="#Deep-Learning-Safety-Concerns-in-Automated-Driving-Perception" class="headerlink" title="Deep Learning Safety Concerns in Automated Driving Perception"></a>Deep Learning Safety Concerns in Automated Driving Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03774">http://arxiv.org/abs/2309.03774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephanie Abrecht, Alexander Hirsch, Shervin Raafatnia, Matthias Woehrle</li>
<li>for: 本研究旨在提高自动驾驶系统中深度学习的应用，以确保系统的安全性。</li>
<li>methods: 本研究使用了安全问题的概念，以系统atic和全面地考虑深度学习模型在自动驾驶系统中的安全性。</li>
<li>results: 本研究提出了一种新的安全问题分类方法，以便跨功能团队共同解决问题。此外，本研究还运用了ISO 21448（SOTIF）和ISO PAS 8800等标准，以确保安全性。<details>
<summary>Abstract</summary>
Recent advances in the field of deep learning and impressive performance of deep neural networks (DNNs) for perception have resulted in an increased demand for their use in automated driving (AD) systems. The safety of such systems is of utmost importance and thus requires to consider the unique properties of DNNs.   In order to achieve safety of AD systems with DNN-based perception components in a systematic and comprehensive approach, so-called safety concerns have been introduced as a suitable structuring element. On the one hand, the concept of safety concerns is -- by design -- well aligned to existing standards relevant for safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has already inspired several academic publications and upcoming standards on AI safety such as ISO PAS 8800.   While the concept of safety concerns has been previously introduced, this paper extends and refines it, leveraging feedback from various domain and safety experts in the field. In particular, this paper introduces an additional categorization for a better understanding as well as enabling cross-functional teams to jointly address the concerns.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="L-2-1-Norm-Regularized-Quaternion-Matrix-Completion-Using-Sparse-Representation-and-Quaternion-QR-Decomposition"><a href="#L-2-1-Norm-Regularized-Quaternion-Matrix-Completion-Using-Sparse-Representation-and-Quaternion-QR-Decomposition" class="headerlink" title="$L_{2,1}$-Norm Regularized Quaternion Matrix Completion Using Sparse Representation and Quaternion QR Decomposition"></a>$L_{2,1}$-Norm Regularized Quaternion Matrix Completion Using Sparse Representation and Quaternion QR Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03764">http://arxiv.org/abs/2309.03764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Han, Kit Ian Kou, Jifei Miao, Lizhi Liu, Haojiang Li</li>
<li>for: color image completion</li>
<li>methods: quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm (QLNM-QQR), iteratively reweighted quaternion $L_{2,1}$-norm minimization (IRQLNM-QQR), and quaternion $L_{2,1}$-norm with sparse regularization (QLNM-QQR-SR)</li>
<li>results: outperforms QLNM-QQR and superior to several state-of-the-art methods on natural color images and color medical images<details>
<summary>Abstract</summary>
Color image completion is a challenging problem in computer vision, but recent research has shown that quaternion representations of color images perform well in many areas. These representations consider the entire color image and effectively utilize coupling information between the three color channels. Consequently, low-rank quaternion matrix completion (LRQMC) algorithms have gained significant attention. We propose a method based on quaternion Qatar Riyal decomposition (QQR) and quaternion $L_{2,1}$-norm called QLNM-QQR. This new approach reduces computational complexity by avoiding the need to calculate the QSVD of large quaternion matrices. We also present two improvements to the QLNM-QQR method: an enhanced version called IRQLNM-QQR that uses iteratively reweighted quaternion $L_{2,1}$-norm minimization and a method called QLNM-QQR-SR that integrates sparse regularization. Our experiments on natural color images and color medical images show that IRQLNM-QQR outperforms QLNM-QQR and that the proposed QLNM-QQR-SR method is superior to several state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
图像颜色填充是计算机视觉领域的一个挑战，但最近的研究表明，使用四元数表示方法在许多领域表现良好。这些表示方法考虑整个颜色图像，并有效地利用三个颜色通道之间的相关信息。因此，低级四元数矩阵 completion（LRQMC）算法在获得了重要的注意力。我们提出了基于四元数卡塔瑞yal decompositon（QQR）和四元数L2,1-norm的方法QLNM-QQR。这种新的方法可以避免计算大四元数矩阵QSVD的需要，从而降低计算复杂性。我们还提出了两种改进QLNM-QQR方法：一种叫做IRQLNM-QQR，使用迭代重量四元数L2,1-norm最小化方法；另一种叫做QLNM-QQR-SR， integrate sparse regularization。我们对自然色图像和医疗颜色图像进行实验，发现IRQLNM-QQR方法比QLNM-QQR方法表现更好，而QLNM-QQR-SR方法在许多状态流行方法之上表现更出色。
</details></li>
</ul>
<hr>
<h2 id="dacl1k-Real-World-Bridge-Damage-Dataset-Putting-Open-Source-Data-to-the-Test"><a href="#dacl1k-Real-World-Bridge-Damage-Dataset-Putting-Open-Source-Data-to-the-Test" class="headerlink" title="dacl1k: Real-World Bridge Damage Dataset Putting Open-Source Data to the Test"></a>dacl1k: Real-World Bridge Damage Dataset Putting Open-Source Data to the Test</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03763">http://arxiv.org/abs/2309.03763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Flotzinger, Philipp J. Rösch, Norbert Oswald, Thomas Braml</li>
<li>for: 本研究旨在提高桥梁材料损害识别精度，以确保结构完整性、交通安全和持续使用性。</li>
<li>methods: 本研究使用多种开源数据集合（meta datasets）进行模型训练，并对模型在真实世界中的应用进行评估。</li>
<li>results: 研究发现，使用meta datasets进行训练后，模型在新的bridge损害识别任务中表现出了实用性，最佳模型的准确率达32%。此外，研究还发现模型学习的是否分类数据集或损害类型，而不是具体的bridge损害类型。<details>
<summary>Abstract</summary>
Recognising reinforced concrete defects (RCDs) is a crucial element for determining the structural integrity, traffic safety and durability of bridges. However, most of the existing datasets in the RCD domain are derived from a small number of bridges acquired in specific camera poses, lighting conditions and with fixed hardware. These limitations question the usability of models trained on such open-source data in real-world scenarios. We address this problem by testing such models on our "dacl1k" dataset, a highly diverse RCD dataset for multi-label classification based on building inspections including 1,474 images. Thereby, we trained the models on different combinations of open-source data (meta datasets) which were subsequently evaluated both extrinsically and intrinsically. During extrinsic evaluation, we report metrics on dacl1k and the meta datasets. The performance analysis on dacl1k shows practical usability of the meta data, where the best model shows an Exact Match Ratio of 32%. Additionally, we conduct an intrinsic evaluation by clustering the bottleneck features of the best model derived from the extrinsic evaluation in order to find out, if the model has learned distinguishing datasets or the classes (RCDs) which is the aspired goal. The dacl1k dataset and our trained models will be made publicly available, enabling researchers and practitioners to put their models to the real-world test.
</details>
<details>
<summary>摘要</summary>
识别强化混凝土缺陷（RCD）是bridge的结构完整性、交通安全和持续性的关键因素。然而，现有的RCD领域数据集大多来自少量桥梁，特定的摄像机位置和照明条件下获取的数据。这些限制问题在实际场景中使用模型的可用性。我们解决这个问题，通过在“dacl1k”数据集上测试这些模型，这是一个多标签分类的RCD数据集，包含1,474张图像。我们在不同的开源数据集（meta数据）上训练了模型，然后对这些meta数据进行了外部和内部评估。在外部评估中，我们对dacl1k和meta数据进行了度量。我们发现，使用meta数据可以实现实际场景中的实用性，最佳模型的准确匹配率达32%。此外，我们进行了内部评估，将最佳模型的瓶颈特征分组，以确定是否模型已经学习到了不同的数据集或RCD类别，这是我们的目标。dacl1k数据集和我们训练的模型将公开提供，allowing researchers和实践者可以在实际场景中测试他们的模型。
</details></li>
</ul>
<hr>
<h2 id="M-otion-mode-Based-Prediction-of-Ejection-Fraction-using-Echocardiograms"><a href="#M-otion-mode-Based-Prediction-of-Ejection-Fraction-using-Echocardiograms" class="headerlink" title="M(otion)-mode Based Prediction of Ejection Fraction using Echocardiograms"></a>M(otion)-mode Based Prediction of Ejection Fraction using Echocardiograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03759">http://arxiv.org/abs/2309.03759</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thomassutter/mmodeecho">https://github.com/thomassutter/mmodeecho</a></li>
<li>paper_authors: Ece Ozkan, Thomas M. Sutter, Yurong Hu, Sebastian Balzer, Julia E. Vogt</li>
<li>for: 早期检测心脏功能异常，通过常规检查是诊断心血管疾病的关键。心脏功能指数下降，是心肺病的重要指标。</li>
<li>methods: 我们使用M模式电子心图来估算心脏功能指数和诊断心肺病。我们生成了多个人工M模式图像，并将其组合使用商业化模型架构。此外，我们将对比学习（CL）应用于卡达着影像识别，从不标注数据中提取有意义的特征，以达到高精度。</li>
<li>results: 我们的实验表明，使用M模式图像和对比学习可以在只有10个模式下达到高精度，与基线方法相当，而且计算上 much more efficient。此外，CL使用M模式图像在有限数据 scenarios（例如，只有200个标注患者）中非常有用。<details>
<summary>Abstract</summary>
Early detection of cardiac dysfunction through routine screening is vital for diagnosing cardiovascular diseases. An important metric of cardiac function is the left ventricular ejection fraction (EF), where lower EF is associated with cardiomyopathy. Echocardiography is a popular diagnostic tool in cardiology, with ultrasound being a low-cost, real-time, and non-ionizing technology. However, human assessment of echocardiograms for calculating EF is time-consuming and expertise-demanding, raising the need for an automated approach. In this work, we propose using the M(otion)-mode of echocardiograms for estimating the EF and classifying cardiomyopathy. We generate multiple artificial M-mode images from a single echocardiogram and combine them using off-the-shelf model architectures. Additionally, we extend contrastive learning (CL) to cardiac imaging to learn meaningful representations from exploiting structures in unlabeled data allowing the model to achieve high accuracy, even with limited annotations. Our experiments show that the supervised setting converges with only ten modes and is comparable to the baseline method while bypassing its cumbersome training process and being computationally much more efficient. Furthermore, CL using M-mode images is helpful for limited data scenarios, such as having labels for only 200 patients, which is common in medical applications.
</details>
<details>
<summary>摘要</summary>
早期检测心脏功能不正常的 Routine 检查是诊断冠状病的关键。一个重要的心脏功能指标是左心室泵出率（EF），其中低EF 与心肺病有关。寿命成像是卡地里诊断工具中最受欢迎的一种，它是一种低成本、实时、不 ionizing 技术。然而，人类对成像进行 EF 计算是时间消耗和专业需求高的，从而需要自动化的方法。在这项工作中，我们提议使用 M（动作）模式成像来估算 EF 和诊断心肺病。我们生成多个人工 M-模式成像从单个成像，并将它们组合使用商业化的模型架构。此外，我们扩展了对比学习（CL）到卡地里成像，以学习有用的表示。我们的实验表明，在监督设定下，只需要使用十个模式，可以与基eline 方法相当，而且可以快速 converges。此外， CL 使用 M-模式成像在有限数据场景下是有帮助的，例如只有200个患者的标签。
</details></li>
</ul>
<hr>
<h2 id="PBP-Path-based-Trajectory-Prediction-for-Autonomous-Driving"><a href="#PBP-Path-based-Trajectory-Prediction-for-Autonomous-Driving" class="headerlink" title="PBP: Path-based Trajectory Prediction for Autonomous Driving"></a>PBP: Path-based Trajectory Prediction for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03750">http://arxiv.org/abs/2309.03750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepideh Afshar, Nachiket Deo, Akshay Bhagat, Titas Chakraborty, Yunming Shao, Balarama Raju Buddharaju, Adwait Deshpande, Henggang Cui</li>
<li>for: 提高自动驾驶栈中的路径预测精度，使自动驾驶车辆更好地预测周围agent的运动轨迹。</li>
<li>methods: 提出了Path-based prediction（PBP）方法，通过使用HD地图中的参考路径特征和路径相对尼采抽象框架来预测路径。</li>
<li>results: 在Argoverse数据集上应用PBP trajectory decoder，与标准路径预测指标具有竞争性表现，同时在map compliance方面显著超过了现有基eline。<details>
<summary>Abstract</summary>
Trajectory prediction plays a crucial role in the autonomous driving stack by enabling autonomous vehicles to anticipate the motion of surrounding agents. Goal-based prediction models have gained traction in recent years for addressing the multimodal nature of future trajectories. Goal-based prediction models simplify multimodal prediction by first predicting 2D goal locations of agents and then predicting trajectories conditioned on each goal. However, a single 2D goal location serves as a weak inductive bias for predicting the whole trajectory, often leading to poor map compliance, i.e., part of the trajectory going off-road or breaking traffic rules. In this paper, we improve upon goal-based prediction by proposing the Path-based prediction (PBP) approach. PBP predicts a discrete probability distribution over reference paths in the HD map using the path features and predicts trajectories in the path-relative Frenet frame. We applied the PBP trajectory decoder on top of the HiVT scene encoder and report results on the Argoverse dataset. Our experiments show that PBP achieves competitive performance on the standard trajectory prediction metrics, while significantly outperforming state-of-the-art baselines in terms of map compliance.
</details>
<details>
<summary>摘要</summary>
干线预测在自动驾驶栈中扮演着关键的角色，帮助自动车辆预测周围的agent的运动。目标基于预测模型在过去几年中得到了广泛应用，因为它可以简化未来轨迹的多样性。目标基于预测模型首先预测了 agent 的2D目标位置，然后预测了根据每个目标的轨迹。然而，单个2D目标位置通常是轨迹预测的弱 inductive bias，导致轨迹偏离路径，例如车辆离路或违反交通规则。在这篇论文中，我们提出了Path-based prediction（PBP）方法，该方法预测了HD地图中参考路径的抽象概率分布，然后预测了路径相对射线帧中的轨迹。我们在HiVT场景编码器之上应用了PBP轨迹解码器，并在Argoverse数据集上进行了实验。我们的实验结果显示，PBP在标准轨迹预测指标上达到了竞争性的表现，而与当前领先的基elines在地图兼容性方面表现出了显著优势。
</details></li>
</ul>
<hr>
<h2 id="Label-efficient-Contrastive-Learning-based-model-for-nuclei-detection-and-classification-in-3D-Cardiovascular-Immunofluorescent-Images"><a href="#Label-efficient-Contrastive-Learning-based-model-for-nuclei-detection-and-classification-in-3D-Cardiovascular-Immunofluorescent-Images" class="headerlink" title="Label-efficient Contrastive Learning-based model for nuclei detection and classification in 3D Cardiovascular Immunofluorescent Images"></a>Label-efficient Contrastive Learning-based model for nuclei detection and classification in 3D Cardiovascular Immunofluorescent Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03744">http://arxiv.org/abs/2309.03744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nazanin Moradinasab, Rebecca A. Deaton, Laura S. Shankman, Gary K. Owens, Donald E. Brown</li>
<li>for: 这个研究旨在开发一个 Label-efficient Contrastive learning-based (LECL) 模型，用于检测和类别各种类型的核lei在3D免疫染色图像中。</li>
<li>methods: 这个模型使用 Extended Maximum Intensity Projection (EMIP) 方法来解决多层对称投影问题，并使用 Supervised Contrastive Learning (SCL) 方法在弱监督情况下进行训练。</li>
<li>results: 在心血管数据集上进行实验，发现这个提案的框架具有高效和高精度地检测和类别各种类型的核lei在3D免疫染色图像中。<details>
<summary>Abstract</summary>
Recently, deep learning-based methods achieved promising performance in nuclei detection and classification applications. However, training deep learning-based methods requires a large amount of pixel-wise annotated data, which is time-consuming and labor-intensive, especially in 3D images. An alternative approach is to adapt weak-annotation methods, such as labeling each nucleus with a point, but this method does not extend from 2D histopathology images (for which it was originally developed) to 3D immunofluorescent images. The reason is that 3D images contain multiple channels (z-axis) for nuclei and different markers separately, which makes training using point annotations difficult. To address this challenge, we propose the Label-efficient Contrastive learning-based (LECL) model to detect and classify various types of nuclei in 3D immunofluorescent images. Previous methods use Maximum Intensity Projection (MIP) to convert immunofluorescent images with multiple slices to 2D images, which can cause signals from different z-stacks to falsely appear associated with each other. To overcome this, we devised an Extended Maximum Intensity Projection (EMIP) approach that addresses issues using MIP. Furthermore, we performed a Supervised Contrastive Learning (SCL) approach for weakly supervised settings. We conducted experiments on cardiovascular datasets and found that our proposed framework is effective and efficient in detecting and classifying various types of nuclei in 3D immunofluorescent images.
</details>
<details>
<summary>摘要</summary>
最近，深度学习基本方法在蛋白检测和分类应用中获得了可观的表现。然而，训练深度学习基本方法需要大量的像素级别标注数据，这是时间消耗和劳动密集的，特别是在3D图像上。一种代替方法是采用弱标注方法，如每个核体只需标注一点，但这种方法不能从2D histopathology图像（它原本是设计的）扩展到3D抗体图像。原因是3D图像包含多个通道（z轴），这些通道分别包含核体和不同的标签，因此使用点标注训练困难。为解决这个挑战，我们提出了 Label-efficient Contrastive learning-based (LECL) 模型，用于检测和分类3D抗体图像中的多种核体。以前的方法使用 Maximum Intensity Projection (MIP) 将多层抗体图像转换成2D图像，这可能会使得不同的z堆叠的信号错误地显示为相关的。为解决这个问题，我们开发了 Extended Maximum Intensity Projection (EMIP) 方法，解决了 MIP 中的问题。另外，我们采用了 Supervised Contrastive Learning (SCL) 方法在弱监督设定下进行训练。我们在循环系统数据集上进行了实验，发现我们提出的框架是有效和高效的，用于检测和分类3D抗体图像中的多种核体。
</details></li>
</ul>
<hr>
<h2 id="ClusterFusion-Leveraging-Radar-Spatial-Features-for-Radar-Camera-3D-Object-Detection-in-Autonomous-Vehicles"><a href="#ClusterFusion-Leveraging-Radar-Spatial-Features-for-Radar-Camera-3D-Object-Detection-in-Autonomous-Vehicles" class="headerlink" title="ClusterFusion: Leveraging Radar Spatial Features for Radar-Camera 3D Object Detection in Autonomous Vehicles"></a>ClusterFusion: Leveraging Radar Spatial Features for Radar-Camera 3D Object Detection in Autonomous Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03734">http://arxiv.org/abs/2309.03734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irfan Tito Kurniawan, Bambang Riyanto Trilaksono</li>
<li>for: 本研究探讨了如何使用射频测距仪的本地空间和点位特征，通过直接从射频点云中提取点云划分后的特征进行 радио-照相机三维物体探测方法的改进。</li>
<li>methods: 本方法使用了 clustering 技术将射频点云分割成不同的分割，然后对每个分割进行特征提取，最后将特征 проек onto 图像平面进行跨模态特征融合。</li>
<li>results: 该方法在 nuScenes 测试片上 achieved 48.7%  nuScenes 检测得分（NDS），在 радио-照相机三维物体探测方法中达到了状态之 arts 性能。<details>
<summary>Abstract</summary>
Thanks to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods may reliably produce accurate detections even in low-visibility conditions. This makes them preferable to use in autonomous vehicles' perception systems, especially as the combined cost of both sensors is cheaper than the cost of a lidar. Recent radar-camera methods commonly perform feature-level fusion which often involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities. While performing fusion on the image plane is generally simpler and faster, projecting radar points onto the image plane flattens the depth dimension of the point cloud which might lead to information loss and makes extracting the spatial features of the point cloud harder. We proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane. ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS). We also investigated the performance of different radar feature extraction strategies on point cloud clusters: a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance. The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane.
</details>
<details>
<summary>摘要</summary>
Due to the complementary nature of millimeter wave radar and camera, deep learning-based radar-camera 3D object detection methods can produce accurate detections even in low-visibility conditions. This makes them more suitable for use in autonomous vehicles' perception systems, as the combined cost of both sensors is lower than the cost of a lidar. Recent radar-camera methods commonly perform feature-level fusion, which involves projecting the radar points onto the same plane as the image features and fusing the extracted features from both modalities. However, projecting radar points onto the image plane flattens the depth dimension of the point cloud, which may lead to information loss and makes extracting the spatial features of the point cloud more difficult. To address this issue, we proposed ClusterFusion, an architecture that leverages the local spatial features of the radar point cloud by clustering the point cloud and performing feature extraction directly on the point cloud clusters before projecting the features onto the image plane. ClusterFusion achieved the state-of-the-art performance among all radar-monocular camera methods on the test slice of the nuScenes dataset with 48.7% nuScenes detection score (NDS). We also investigated the performance of different radar feature extraction strategies on point cloud clusters, including a handcrafted strategy, a learning-based strategy, and a combination of both, and found that the handcrafted strategy yielded the best performance. The main goal of this work is to explore the use of radar's local spatial and point-wise features by extracting them directly from radar point cloud clusters for a radar-monocular camera 3D object detection method that performs cross-modal feature fusion on the image plane.
</details></li>
</ul>
<hr>
<h2 id="Phasic-Content-Fusing-Diffusion-Model-with-Directional-Distribution-Consistency-for-Few-Shot-Model-Adaption"><a href="#Phasic-Content-Fusing-Diffusion-Model-with-Directional-Distribution-Consistency-for-Few-Shot-Model-Adaption" class="headerlink" title="Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption"></a>Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03729">http://arxiv.org/abs/2309.03729</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sjtuplayer/few-shot-diffusion">https://github.com/sjtuplayer/few-shot-diffusion</a></li>
<li>paper_authors: Teng Hu, Jiangning Zhang, Liang Liu, Ran Yi, Siqi Kou, Haokun Zhu, Xu Chen, Yabiao Wang, Chengjie Wang, Lizhuang Ma</li>
<li>for: 本研究的目的是提出一种基于几何扩展的几何扩展噪声模型，以解决具有有限样本的数据时，生成模型的训练问题。</li>
<li>methods: 本研究使用了phasic content fusion和directional distribution consistency loss两种新的学习目标，以帮助模型学习内容和样式信息，并且在不同的训练阶段学习不同的学习目标。</li>
<li>results: 实验表明，提出的方法可以在几何扩展中减少内容衰减，并且在几何扩展中增强结构一致性。此外，该方法在几何扩展中的训练效果也比PRIOR方法更好。<details>
<summary>Abstract</summary>
Training a generative model with limited number of samples is a challenging task. Current methods primarily rely on few-shot model adaption to train the network. However, in scenarios where data is extremely limited (less than 10), the generative network tends to overfit and suffers from content degradation. To address these problems, we propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, which targets different learning objectives at distinct training stages of the diffusion model. Specifically, we design a phasic training strategy with phasic content fusion to help our model learn content and style information when t is large, and learn local details of target domain when t is small, leading to an improvement in the capture of content, style and local details. Furthermore, we introduce a novel directional distribution consistency loss that ensures the consistency between the generated and source distributions more efficiently and stably than the prior methods, preventing our model from overfitting. Finally, we propose a cross-domain structure guidance strategy that enhances structure consistency during domain adaptation. Theoretical analysis, qualitative and quantitative experiments demonstrate the superiority of our approach in few-shot generative model adaption tasks compared to state-of-the-art methods. The source code is available at: https://github.com/sjtuplayer/few-shot-diffusion.
</details>
<details>
<summary>摘要</summary>
<font face="宋体">训练一个生成模型具有有限样本的任务是一项具有挑战性的任务。当前方法主要依靠几 shot 模型适应来训练网络。然而，在数据非常有限（ menos de 10）的场景下，生成网络往往遇到过拟合和内容下降的问题。为解决这些问题，我们提出了一种新的phasic content fusion few-shot diffusion model，具有方向分布一致损失，可以在不同的训练阶段对 diffusion model 进行不同的学习目标。具体来说，我们设计了phasic 训练策略，通过phasic content fusion来帮助我们的模型在 t 大的时候学习内容和风格信息，并在 t 小的时候学习目标频道的本地细节，从而改善内容、风格和本地细节的捕捉。此外，我们引入了一种新的方向分布一致损失，可以更有效和稳定地保证生成的结果与源分布的一致性，避免模型过拟合。最后，我们提出了一种跨频道结构引导策略，可以在适应频道中提高结构一致性。理论分析、质量和量测试表明，我们的方法在几 shot 生成模型适应任务中比 state-of-the-art 方法更高效。模型代码可以在 GitHub 上获取：https://github.com/sjtuplayer/few-shot-diffusion。</font>
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Visual-Question-Answering-via-Reasoning-Supervision"><a href="#Interpretable-Visual-Question-Answering-via-Reasoning-Supervision" class="headerlink" title="Interpretable Visual Question Answering via Reasoning Supervision"></a>Interpretable Visual Question Answering via Reasoning Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03726">http://arxiv.org/abs/2309.03726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Parelli, Dimitrios Mallis, Markos Diomataris, Vassilis Pitsikalis</li>
<li>for: 提高模型在视觉问答任务中的视觉固定能力，使其更好地理解问题和图像之间的关系。</li>
<li>methods: 使用常识逻辑作为监督信号，通过文本证明来提供Visual Common Sense Reasoning（VCR）数据集上已有的批注来帮助模型更好地理解问题和图像之间的关系。</li>
<li>results: 经验表明，提出的方法可以帮助模型更好地理解问题和图像之间的关系，不需要训练显式固定注解。<details>
<summary>Abstract</summary>
Transformer-based architectures have recently demonstrated remarkable performance in the Visual Question Answering (VQA) task. However, such models are likely to disregard crucial visual cues and often rely on multimodal shortcuts and inherent biases of the language modality to predict the correct answer, a phenomenon commonly referred to as lack of visual grounding. In this work, we alleviate this shortcoming through a novel architecture for visual question answering that leverages common sense reasoning as a supervisory signal. Reasoning supervision takes the form of a textual justification of the correct answer, with such annotations being already available on large-scale Visual Common Sense Reasoning (VCR) datasets. The model's visual attention is guided toward important elements of the scene through a similarity loss that aligns the learned attention distributions guided by the question and the correct reasoning. We demonstrate both quantitatively and qualitatively that the proposed approach can boost the model's visual perception capability and lead to performance increase, without requiring training on explicit grounding annotations.
</details>
<details>
<summary>摘要</summary>
带有转换器基础的架构在视觉问答任务中表现出了惊人的表现。然而，这些模型可能会忽略重要的视觉指示和依赖于多Modal短cut和语言modal的自然偏见来预测正确答案，这被称为视觉不归顺。在这项工作中，我们通过一种新的视觉问答架构来解决这个缺陷，该架构利用了通用理解作为监督信号。理解监督信号的形式是一个问题和正确答案的文本证明，这些注释已经在大规模的视觉通用理解（VCR）数据集上可以获得。我们的视觉注意力通过一种相似损失来引导，使得问题和正确答案的学习的视觉注意力 Distributions相似。我们示出了both量化和质量上的表述，表明我们的方法可以增强模型的视觉感知能力，不需要训练显式归顺注释。
</details></li>
</ul>
<hr>
<h2 id="A-boundary-aware-point-clustering-approach-in-Euclidean-and-embedding-spaces-for-roof-plane-segmentation"><a href="#A-boundary-aware-point-clustering-approach-in-Euclidean-and-embedding-spaces-for-roof-plane-segmentation" class="headerlink" title="A boundary-aware point clustering approach in Euclidean and embedding spaces for roof plane segmentation"></a>A boundary-aware point clustering approach in Euclidean and embedding spaces for roof plane segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03722">http://arxiv.org/abs/2309.03722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Li, Qingqing Li, Guozheng Xu, Pengwei Zhou, Jingmin Tu, Jie Li, Jian Yao</li>
<li>for: 本研究旨在提高空拍LiDAR点云数据中的瓦片面分割精度，提供更高精度的3D建筑模型重建。</li>
<li>methods: 本研究提出了一种边缘意识点云划分方法，包括三个分支网络：一个用于预测 semantic labels、点偏移和深度嵌入特征，第二个用于预测点偏移，第三个用于确保点云实例的嵌入特征相似。</li>
<li>results: 实验结果显示，提出的方法significantly outperforms 现有的状态之最方法。<details>
<summary>Abstract</summary>
Roof plane segmentation from airborne LiDAR point clouds is an important technology for 3D building model reconstruction. One of the key issues of plane segmentation is how to design powerful features that can exactly distinguish adjacent planar patches. The quality of point feature directly determines the accuracy of roof plane segmentation. Most of existing approaches use handcrafted features to extract roof planes. However, the abilities of these features are relatively low, especially in boundary area. To solve this problem, we propose a boundary-aware point clustering approach in Euclidean and embedding spaces constructed by a multi-task deep network for roof plane segmentation. We design a three-branch network to predict semantic labels, point offsets and extract deep embedding features. In the first branch, we classify the input data as non-roof, boundary and plane points. In the second branch, we predict point offsets for shifting each point toward its respective instance center. In the third branch, we constrain that points of the same plane instance should have the similar embeddings. We aim to ensure that points of the same plane instance are close as much as possible in both Euclidean and embedding spaces. However, although deep network has strong feature representative ability, it is still hard to accurately distinguish points near plane instance boundary. Therefore, we first group plane points into many clusters in the two spaces, and then we assign the rest boundary points to their closest clusters to generate final complete roof planes. In this way, we can effectively reduce the influence of unreliable boundary points. In addition, we construct a synthetic dataset and a real dataset to train and evaluate our approach. The experiments results show that the proposed approach significantly outperforms the existing state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
《顶面面Segmentation从空中LiDAR点云是重要的三维建筑模型重建技术。一个关键问题是如何设计强大的特征来准确分辨邻近的平面 patches。点云特征质量直接影响顶面面Segmentation的准确性。大多数现有方法使用手动设计的特征来抽取顶面平面。然而，这些特征的能力相对较低，特别是在边缘区域。为解决这个问题，我们提出了一种边缘意识点云 clustering方法，通过多任务深度网络进行顶面面Segmentation。我们设计了三枝网络， Predict semantic labels, point offsets和EXTRACT deep embedding features。在第一枝网络中，我们将输入数据分类为非顶面、边界和平面点。在第二枝网络中，我们预测每个点的偏移量，以将每个点向其实例中心偏移。在第三枝网络中，我们强制实例中心的点需要具有类似的嵌入特征。我们希望通过这种方式，实例中心的点可以在Euclidean和嵌入空间中保持最近。然而，虽然深度网络具有强大的特征表示能力，但是仍然困难准确分辨边缘区域的点。因此，我们首先将平面点 grouping到多个cluster中，然后将边缘点分配到最近的cluster中，以生成最终的完整的顶面面。这种方法可以有效地减少边缘点的影响。此外，我们还构建了一个 sintetic dataset和一个实际 dataset，以用于训练和评估我们的方法。实验结果表明，我们的方法在与现有状态作准的方法进行比较时，表现出了显著的优势。
</details></li>
</ul>
<hr>
<h2 id="DiffDefense-Defending-against-Adversarial-Attacks-via-Diffusion-Models"><a href="#DiffDefense-Defending-against-Adversarial-Attacks-via-Diffusion-Models" class="headerlink" title="DiffDefense: Defending against Adversarial Attacks via Diffusion Models"></a>DiffDefense: Defending against Adversarial Attacks via Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03702">http://arxiv.org/abs/2309.03702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hondamunigeprasannasilva/diffdefence">https://github.com/hondamunigeprasannasilva/diffdefence</a></li>
<li>paper_authors: Hondamunige Prasanna Silva, Lorenzo Seidenari, Alberto Del Bimbo</li>
<li>for: 保护机器学习分类器免受攻击</li>
<li>methods: 使用Diffusion Models进行增强防御</li>
<li>results: 提供了一种robust的防御方法，保持了清晰精度和可插入性，同时能够抵抗攻击。In English:</li>
<li>for: Protect machine learning classifiers from attacks</li>
<li>methods: Leveraging Diffusion Models for enhanced defense</li>
<li>results: Provides a robust defense method that preserves clarity and plug-and-play compatibility, while resisting attacks.<details>
<summary>Abstract</summary>
This paper presents a novel reconstruction method that leverages Diffusion Models to protect machine learning classifiers against adversarial attacks, all without requiring any modifications to the classifiers themselves. The susceptibility of machine learning models to minor input perturbations renders them vulnerable to adversarial attacks. While diffusion-based methods are typically disregarded for adversarial defense due to their slow reverse process, this paper demonstrates that our proposed method offers robustness against adversarial threats while preserving clean accuracy, speed, and plug-and-play compatibility. Code at: https://github.com/HondamunigePrasannaSilva/DiffDefence.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的重建方法，利用傅里叶模型来保护机器学习分类器免受抗击攻击，而无需对分类器本身进行任何修改。由于机器学习模型对输入小变化很敏感，因此它们面临着抗击攻击的威胁。尽管傅里叶基本方法通常不被视为对抗攻击的有效方法，但这篇论文表明，我们的提议方法可以提供对抗攻击的坚固性，保持清晰率、速度和插件兼容性。代码可以在 GitHub 上找到：https://github.com/HondamunigePrasannaSilva/DiffDefence。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Adaptive-Human-Object-Interaction-Detection-with-Concept-guided-Memory"><a href="#Efficient-Adaptive-Human-Object-Interaction-Detection-with-Concept-guided-Memory" class="headerlink" title="Efficient Adaptive Human-Object Interaction Detection with Concept-guided Memory"></a>Efficient Adaptive Human-Object Interaction Detection with Concept-guided Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03696">http://arxiv.org/abs/2309.03696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ltttpku/ada-cm">https://github.com/ltttpku/ada-cm</a></li>
<li>paper_authors: Ting Lei, Fabian Caba, Qingchao Chen, Hailin Jin, Yuxin Peng, Yang Liu</li>
<li>For: 本研究旨在提出一种可以快速准确地检测人对象互动（HOI）的方法，以解决在实际场景中HOI检测 task 的挑战，如质量下降和计算成本增加。* Methods: 该方法基于大量的视觉语言模型（VLM），并提出了两种操作模式：一是无需更新参数的培成模式，二是可以更新细化参数的实例感知适应器模式。* Results: 该方法在HICO-DET和V-COCO数据集上达到了与现有状态OF-the-art的竞争水平，而且具有训练时间较短的优势。<details>
<summary>Abstract</summary>
Human Object Interaction (HOI) detection aims to localize and infer the relationships between a human and an object. Arguably, training supervised models for this task from scratch presents challenges due to the performance drop over rare classes and the high computational cost and time required to handle long-tailed distributions of HOIs in complex HOI scenes in realistic settings. This observation motivates us to design an HOI detector that can be trained even with long-tailed labeled data and can leverage existing knowledge from pre-trained models. Inspired by the powerful generalization ability of the large Vision-Language Models (VLM) on classification and retrieval tasks, we propose an efficient Adaptive HOI Detector with Concept-guided Memory (ADA-CM). ADA-CM has two operating modes. The first mode makes it tunable without learning new parameters in a training-free paradigm. Its second mode incorporates an instance-aware adapter mechanism that can further efficiently boost performance if updating a lightweight set of parameters can be afforded. Our proposed method achieves competitive results with state-of-the-art on the HICO-DET and V-COCO datasets with much less training time. Code can be found at https://github.com/ltttpku/ADA-CM.
</details>
<details>
<summary>摘要</summary>
人物物体交互（HOI）检测的目标是确定人类和物体之间的位置和关系。然而，从头scratch开始训练超级vised模型 для此任务可能会遇到困难，主要是因为罕见的类型下的性能下降和复杂的HOI场景中的长尾分布。这个问题驱动我们设计一种可以很好地处理长尾分布的HOI检测器。我们提出了一种基于大型视力语言模型（VLM）的强大泛化能力的Adaptive HOI Detector with Concept-guided Memory（ADA-CM）。ADA-CM有两种运作模式。首先，它可以在没有学习新参数的情况下进行调整。其第二种运作模式包括一个实例特征感知机制，可以进一步提高性能，只要更新一些轻量级的参数。我们的提议方法在HICO-DET和V-COCO数据集上实现了与当前最佳的竞争力。代码可以在https://github.com/ltttpku/ADA-CM中找到。
</details></li>
</ul>
<hr>
<h2 id="MS-UNet-v2-Adaptive-Denoising-Method-and-Training-Strategy-for-Medical-Image-Segmentation-with-Small-Training-Data"><a href="#MS-UNet-v2-Adaptive-Denoising-Method-and-Training-Strategy-for-Medical-Image-Segmentation-with-Small-Training-Data" class="headerlink" title="MS-UNet-v2: Adaptive Denoising Method and Training Strategy for Medical Image Segmentation with Small Training Data"></a>MS-UNet-v2: Adaptive Denoising Method and Training Strategy for Medical Image Segmentation with Small Training Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03686">http://arxiv.org/abs/2309.03686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyuan Chen, Yufei Han, Pin Xu, Yanyi Li, Kuan Li, Jianping Yin</li>
<li>for: 这个研究旨在提高医疗影像分类 task 的性能，以及解决单层 U-Net 构造不足以掌握足够多信息的问题。</li>
<li>methods: 我们提出了一个名为 MS-UNet 的新型 U-Net 模型，使用了 Swin Transformer 嵌入式的多尺度嵌入式解oder，实现了Semantic feature mapping 的更好地学习。此外，我们也提出了一个 Edge loss 和一个可替换的 Denoising module，可以单独应用于其他模型中，并且可以优化 MS-UNet 的 segmentation 性能。</li>
<li>results: 实验结果显示，MS-UNet 能够具有更高效的特征学习能力，并且在小量训练数据情况下表现更出色，而且提出的 Edge loss 和 Denoising module 可以明显提高 MS-UNet 的 segmentation 性能。<details>
<summary>Abstract</summary>
Models based on U-like structures have improved the performance of medical image segmentation. However, the single-layer decoder structure of U-Net is too "thin" to exploit enough information, resulting in large semantic differences between the encoder and decoder parts. Things get worse if the number of training sets of data is not sufficiently large, which is common in medical image processing tasks where annotated data are more difficult to obtain than other tasks. Based on this observation, we propose a novel U-Net model named MS-UNet for the medical image segmentation task in this study. Instead of the single-layer U-Net decoder structure used in Swin-UNet and TransUnet, we specifically design a multi-scale nested decoder based on the Swin Transformer for U-Net. The proposed multi-scale nested decoder structure allows the feature mapping between the decoder and encoder to be semantically closer, thus enabling the network to learn more detailed features. In addition, we propose a novel edge loss and a plug-and-play fine-tuning Denoising module, which not only effectively improves the segmentation performance of MS-UNet, but could also be applied to other models individually. Experimental results show that MS-UNet could effectively improve the network performance with more efficient feature learning capability and exhibit more advanced performance, especially in the extreme case with a small amount of training data, and the proposed Edge loss and Denoising module could significantly enhance the segmentation performance of MS-UNet.
</details>
<details>
<summary>摘要</summary>
模型基于U字结构的表现在医学图像分割方面有所改善。然而，单层decoder结构的U字网络（Swin-UNet和TransUnet）太"瘦"，无法利用足够的信息，导致encoder和decoder部分之间的semantic差异较大。尤其是在医学图像处理任务中，缺乏足够的训练数据是常见的问题，这会使得模型的表现更加差。基于这一观察，我们在本研究中提出了一种名为MS-UNet的新的U字网络模型。相比单层decoder结构，我们专门设计了基于Swin Transformer的多尺度嵌套decoder结构。这种多尺度嵌套decoder结构使得feature mapping междуdecoder和encoder更加近似，从而让网络学习更加细腻的特征。此外，我们还提出了一种新的边缘损失和可插拔的精度调整Denosing模块，这不仅能够有效提高MS-UNet的分割性能，还可以应用于其他模型。实验结果表明，MS-UNet可以更好地利用训练数据，具有更高效的特征学习能力和更高级别的表现，特别是在训练数据量很少的极端情况下。此外，提出的边缘损失和Denosing模块可以明显提高MS-UNet的分割性能。
</details></li>
</ul>
<hr>
<h2 id="Prompt-based-Context-and-Domain-aware-Pretraining-for-Vision-and-Language-Navigation"><a href="#Prompt-based-Context-and-Domain-aware-Pretraining-for-Vision-and-Language-Navigation" class="headerlink" title="Prompt-based Context- and Domain-aware Pretraining for Vision and Language Navigation"></a>Prompt-based Context- and Domain-aware Pretraining for Vision and Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03661">http://arxiv.org/abs/2309.03661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting Liu, Wansen Wu, Yue Hu, Youkai Wang, Kai Xu, Quanjun Yin</li>
<li>for: 本研究旨在提高视觉语言Navigation（VLN）任务中的表达能力和模型适应能力，解决现有模型在VLN任务中的领域差距和Sequential alignment问题。</li>
<li>methods: 本文提出了一种新的Prompt-bAsed coNtext- and Domain-Aware（PANDA）预训练框架，通过两stage的提问方式，在领域意识阶段和上下文意识阶段，分别学习软视觉提示和硬上下文提示，以塑造模型在VLN任务中的跨模态对应性和上下文知识。</li>
<li>results: 实验结果表明，相比之前的状态态度方法，PANDA在R2R和REVERIE两个任务中具有明显的优势，能够更好地利用预训练模型，提高VLN任务的表达能力和模型适应能力。<details>
<summary>Abstract</summary>
With strong representation capabilities, pretrained vision-language models are widely used in vision and language navigation (VLN). However, most of them are trained on web-crawled general-purpose datasets, which incurs a considerable domain gap when used for VLN tasks. Another challenge for VLN is how the agent understands the contextual relations between actions on a trajectory and performs cross-modal alignment sequentially. In this paper, we propose a novel Prompt-bAsed coNtext- and Domain-Aware (PANDA) pretraining framework to address these problems. It performs prompting in two stages. In the domain-aware stage, we apply a low-cost prompt tuning paradigm to learn soft visual prompts from an in-domain dataset for equipping the pretrained models with object-level and scene-level cross-modal alignment in VLN tasks. Furthermore, in the context-aware stage, we design a set of hard context prompts to capture the sequence-level semantics and instill both out-of-context and contextual knowledge in the instruction into cross-modal representations. They enable further tuning of the pretrained models via contrastive learning. Experimental results on both R2R and REVERIE show the superiority of PANDA compared to previous state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
With strong representation capabilities, pretrained vision-language models are widely used in vision and language navigation (VLN). However, most of them are trained on web-crawled general-purpose datasets, which incurs a considerable domain gap when used for VLN tasks. Another challenge for VLN is how the agent understands the contextual relations between actions on a trajectory and performs cross-modal alignment sequentially. In this paper, we propose a novel Prompt-bAsed coNtext- and Domain-Aware (PANDA) pretraining framework to address these problems. It performs prompting in two stages. In the domain-aware stage, we apply a low-cost prompt tuning paradigm to learn soft visual prompts from an in-domain dataset for equipping the pretrained models with object-level and scene-level cross-modal alignment in VLN tasks. Furthermore, in the context-aware stage, we design a set of hard context prompts to capture the sequence-level semantics and instill both out-of-context and contextual knowledge in the instruction into cross-modal representations. They enable further tuning of the pretrained models via contrastive learning. Experimental results on both R2R and REVERIE show the superiority of PANDA compared to previous state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Spiking-Structured-State-Space-Model-for-Monaural-Speech-Enhancement"><a href="#Spiking-Structured-State-Space-Model-for-Monaural-Speech-Enhancement" class="headerlink" title="Spiking Structured State Space Model for Monaural Speech Enhancement"></a>Spiking Structured State Space Model for Monaural Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03641">http://arxiv.org/abs/2309.03641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Du, Xu Liu, Yansong Chua</li>
<li>for: 提高speech干扰率和计算成本，使用Spiking Structured State Space Model（Spiking-S4）。</li>
<li>methods: 使用Spiking Neural Networks（SNN）和Structured State Space Models（S4），结合能量效率和长距离序列模型能力。</li>
<li>results: 与现有Artificial Neural Network（ANN）方法相当，但计算资源减少，参数和浮点运算数（FLOPs）减少。<details>
<summary>Abstract</summary>
Speech enhancement seeks to extract clean speech from noisy signals. Traditional deep learning methods face two challenges: efficiently using information in long speech sequences and high computational costs. To address these, we introduce the Spiking Structured State Space Model (Spiking-S4). This approach merges the energy efficiency of Spiking Neural Networks (SNN) with the long-range sequence modeling capabilities of Structured State Space Models (S4), offering a compelling solution. Evaluation on the DNS Challenge and VoiceBank+Demand Datasets confirms that Spiking-S4 rivals existing Artificial Neural Network (ANN) methods but with fewer computational resources, as evidenced by reduced parameters and Floating Point Operations (FLOPs).
</details>
<details>
<summary>摘要</summary>
干扰除抽取干扰后的清晰语音。传统的深度学习方法面临两个挑战：高效地使用长 speech 序列中的信息，以及高计算成本。为解决这些问题，我们介绍了 Spiking Structured State Space Model（Spiking-S4）。这种方法将神经网络中的能量效率与结构化状态空间模型（S4）结合起来，提供了一个吸引人的解决方案。评估在 DNS 挑战和 VoiceBank+Demand 数据集上表明，Spiking-S4 与现有的人工神经网络（ANN）方法相当，但具有更少的计算资源，如参数和浮点运算（FLOPs）。
</details></li>
</ul>
<hr>
<h2 id="Context-Aware-3D-Object-Localization-from-Single-Calibrated-Images-A-Study-of-Basketballs"><a href="#Context-Aware-3D-Object-Localization-from-Single-Calibrated-Images-A-Study-of-Basketballs" class="headerlink" title="Context-Aware 3D Object Localization from Single Calibrated Images: A Study of Basketballs"></a>Context-Aware 3D Object Localization from Single Calibrated Images: A Study of Basketballs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03640">http://arxiv.org/abs/2309.03640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gabriel-vanzandycke/deepsport">https://github.com/gabriel-vanzandycke/deepsport</a></li>
<li>paper_authors: Marcello Davide Caio, Gabriel Van Zandycke, Christophe De Vleeschouwer</li>
<li>for: This paper is written for the task of 3D localization of objects in computer vision applications, specifically for basketball localization from a single calibrated image.</li>
<li>methods: The method used in this paper is to predict the object’s height in pixels in image space by estimating its projection onto the ground plane within the image, leveraging the image itself and the object’s location as inputs.</li>
<li>results: The paper demonstrates substantial accuracy improvements compared to recent work, offering effective 3D ball tracking and understanding. The source code is made publicly available at \url{<a target="_blank" rel="noopener" href="https://github.com/gabriel-vanzandycke/deepsport%7D">https://github.com/gabriel-vanzandycke/deepsport}</a>.<details>
<summary>Abstract</summary>
Accurately localizing objects in three dimensions (3D) is crucial for various computer vision applications, such as robotics, autonomous driving, and augmented reality. This task finds another important application in sports analytics and, in this work, we present a novel method for 3D basketball localization from a single calibrated image. Our approach predicts the object's height in pixels in image space by estimating its projection onto the ground plane within the image, leveraging the image itself and the object's location as inputs. The 3D coordinates of the ball are then reconstructed by exploiting the known projection matrix. Extensive experiments on the public DeepSport dataset, which provides ground truth annotations for 3D ball location alongside camera calibration information for each image, demonstrate the effectiveness of our method, offering substantial accuracy improvements compared to recent work. Our work opens up new possibilities for enhanced ball tracking and understanding, advancing computer vision in diverse domains. The source code of this work is made publicly available at \url{https://github.com/gabriel-vanzandycke/deepsport}.
</details>
<details>
<summary>摘要</summary>
三维空间中的物体准确地理解是计算机视觉应用中的关键，如 робо扮、自动驾驶和增强现实等。这种任务在体育分析中也具有重要的应用，在这篇论文中，我们介绍了一种基于单个投影图像的3D篮球定位方法。我们的方法在图像空间中预测物体的高度，利用图像本身和物体的位置作为输入，并且利用知道的投影矩阵来重建3D坐标。我们在公共的DeepSport数据集上进行了广泛的实验，该数据集提供了每个图像的摄像机准确的投影矩阵和3D球的位置的标注信息。我们的方法在相比之下提供了显著的精度提高，这些成果将开拓新的 возмож性，推动计算机视觉在多个领域的发展。我们的代码在 \url{https://github.com/gabriel-vanzandycke/deepsport} 上公开提供。
</details></li>
</ul>
<hr>
<h2 id="Chasing-Consistency-in-Text-to-3D-Generation-from-a-Single-Image"><a href="#Chasing-Consistency-in-Text-to-3D-Generation-from-a-Single-Image" class="headerlink" title="Chasing Consistency in Text-to-3D Generation from a Single Image"></a>Chasing Consistency in Text-to-3D Generation from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03599">http://arxiv.org/abs/2309.03599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Ouyang, Wenhao Chai, Jiayi Ye, Dapeng Tao, Yibing Zhan, Gaoang Wang</li>
<li>for: 提出了一种解决多视图图像Text-to-3D生成 task中的不一致问题的方法，包括semantic inconsistency、geometric inconsistency和saturation inconsistency。</li>
<li>methods: 提出了一种三stage框架，包括semantic encoding stage、geometric encoding stage和optimization stage，用于学习参数化的一致性 tokens，以提高Text-to-3D生成的一致性和可靠性。</li>
<li>results: 实验结果表明，Compared with前一个状态的方法，Consist3D可以生成更加一致、忠实和 фото真实的3D资产，同时也允许背景和对象编辑通过文本提示。<details>
<summary>Abstract</summary>
Text-to-3D generation from a single-view image is a popular but challenging task in 3D vision. Although numerous methods have been proposed, existing works still suffer from the inconsistency issues, including 1) semantic inconsistency, 2) geometric inconsistency, and 3) saturation inconsistency, resulting in distorted, overfitted, and over-saturated generations. In light of the above issues, we present Consist3D, a three-stage framework Chasing for semantic-, geometric-, and saturation-Consistent Text-to-3D generation from a single image, in which the first two stages aim to learn parameterized consistency tokens, and the last stage is for optimization. Specifically, the semantic encoding stage learns a token independent of views and estimations, promoting semantic consistency and robustness. Meanwhile, the geometric encoding stage learns another token with comprehensive geometry and reconstruction constraints under novel-view estimations, reducing overfitting and encouraging geometric consistency. Finally, the optimization stage benefits from the semantic and geometric tokens, allowing a low classifier-free guidance scale and therefore preventing oversaturation. Experimental results demonstrate that Consist3D produces more consistent, faithful, and photo-realistic 3D assets compared to previous state-of-the-art methods. Furthermore, Consist3D also allows background and object editing through text prompts.
</details>
<details>
<summary>摘要</summary>
文本到3D生成从单个图像是3D视图中受欢迎但具有挑战性的任务。虽然已有许多方法被提出，但现有的方法仍然受到不一致性问题的困扰，包括1）semantic不一致、2）geometry不一致和3）饱和不一致，导致生成的结果偏倾、适应度差和饱和。为了解决这些问题，我们提出了Consist3D，一个三个阶段框架，旨在从单个图像中实现semantic-, geometry-和饱和性Consistent文本到3D生成。在这三个阶段中，第一两个阶段的目标是学习参数化的一致性token，而第三个阶段是优化阶段。具体来说，semantic编码阶段学习一个独立于视图和估计的Token，Promoting semantic一致和Robustness。同时，geometry编码阶段学习另一个Token，旨在包括全面的几何和重建约束，降低过拟合和促进几何一致。最后，优化阶段利用semantic和geometry Token，允许低级别的类ifier-free导向缩放，因此避免饱和。实验结果表明，Consist3D生成的3D资产更加一致、忠实和真实的摄影图像。此外，Consist3D还允许背景和物体编辑通过文本提示。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Sample-Utilization-through-Sample-Adaptive-Augmentation-in-Semi-Supervised-Learning"><a href="#Enhancing-Sample-Utilization-through-Sample-Adaptive-Augmentation-in-Semi-Supervised-Learning" class="headerlink" title="Enhancing Sample Utilization through Sample Adaptive Augmentation in Semi-Supervised Learning"></a>Enhancing Sample Utilization through Sample Adaptive Augmentation in Semi-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03598">http://arxiv.org/abs/2309.03598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guangui-nju/saa">https://github.com/guangui-nju/saa</a></li>
<li>paper_authors: Guan Gui, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</li>
<li>for: 提高 semi-supervised learning 模型的性能</li>
<li>methods: 使用 sample adaptive augmentation (SAA) 技术，包括 sample selection module 和 sample augmentation module，以适应不同样本的需求</li>
<li>results: SAA 可以显著提高 FixMatch 和 FlexMatch 模型的准确率，例如，在 CIFAR-10 数据集上，SAA 帮助 FixMatch 模型的准确率从 92.50% 提高到 94.76%，并且帮助 FlexMatch 模型的准确率从 95.01% 提高到 95.31%<details>
<summary>Abstract</summary>
In semi-supervised learning, unlabeled samples can be utilized through augmentation and consistency regularization. However, we observed certain samples, even undergoing strong augmentation, are still correctly classified with high confidence, resulting in a loss close to zero. It indicates that these samples have been already learned well and do not provide any additional optimization benefits to the model. We refer to these samples as ``naive samples". Unfortunately, existing SSL models overlook the characteristics of naive samples, and they just apply the same learning strategy to all samples. To further optimize the SSL model, we emphasize the importance of giving attention to naive samples and augmenting them in a more diverse manner. Sample adaptive augmentation (SAA) is proposed for this stated purpose and consists of two modules: 1) sample selection module; 2) sample augmentation module. Specifically, the sample selection module picks out {naive samples} based on historical training information at each epoch, then the naive samples will be augmented in a more diverse manner in the sample augmentation module. Thanks to the extreme ease of implementation of the above modules, SAA is advantageous for being simple and lightweight. We add SAA on top of FixMatch and FlexMatch respectively, and experiments demonstrate SAA can significantly improve the models. For example, SAA helped improve the accuracy of FixMatch from 92.50% to 94.76% and that of FlexMatch from 95.01% to 95.31% on CIFAR-10 with 40 labels.
</details>
<details>
<summary>摘要</summary>
在半监督学习中，无标示样本可以通过扩充和一致性规范来利用。然而，我们观察到一些样本，即使经受了强大的扩充，仍然可以高度自信地分类，从而导致损失接近零。这表示这些样本已经很好地学习过，不会提供任何额外优化效果 для模型。我们称这些样本为“简单样本”。现有的SSL模型忽视了简单样本的特点，只是对所有样本应用同一种学习策略。为了进一步优化SSL模型，我们强调了简单样本的重要性，并提出了一种Sample Adaptive Augmentation（SAA）模型，包括以下两个模块：1）样本选择模块；2）样本扩充模块。具体来说，样本选择模块根据每 epoch 的历史训练信息选择简单样本，然后在样本扩充模块中对简单样本进行更加多样化的扩充。由于SAA的实现非常简单，因此SAA具有简单和轻量级的优势。我们在 FixMatch 和 FlexMatch 上加载 SAA，并进行了实验，结果表明，SAA可以显著提高模型的准确率。例如，SAA 在 CIFAR-10 上使 FixMatch 的准确率由 92.50% 提高到 94.76%，并在 FlexMatch 上使准确率由 95.01% 提高到 95.31%。
</details></li>
</ul>
<hr>
<h2 id="DropPos-Pre-Training-Vision-Transformers-by-Reconstructing-Dropped-Positions"><a href="#DropPos-Pre-Training-Vision-Transformers-by-Reconstructing-Dropped-Positions" class="headerlink" title="DropPos: Pre-Training Vision Transformers by Reconstructing Dropped Positions"></a>DropPos: Pre-Training Vision Transformers by Reconstructing Dropped Positions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03576">http://arxiv.org/abs/2309.03576</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haochen-wang409/droppos">https://github.com/haochen-wang409/droppos</a></li>
<li>paper_authors: Haochen Wang, Junsong Fan, Yuxi Wang, Kaiyou Song, Tong Wang, Zhaoxiang Zhang</li>
<li>for: 提高 ViT 的位置意识（location awareness）</li>
<li>methods: 提出 DropPos 自我超vised挑战任务，通过随机DropPositional embedding来增强模型的位置理解能力</li>
<li>results: DropPos 在各种下游任务上表现出色，超过了supervised预训练和当前自我超vised方法的表现，这表明 DropPos 可以帮助 ViT 提高其位置意识。<details>
<summary>Abstract</summary>
As it is empirically observed that Vision Transformers (ViTs) are quite insensitive to the order of input tokens, the need for an appropriate self-supervised pretext task that enhances the location awareness of ViTs is becoming evident. To address this, we present DropPos, a novel pretext task designed to reconstruct Dropped Positions. The formulation of DropPos is simple: we first drop a large random subset of positional embeddings and then the model classifies the actual position for each non-overlapping patch among all possible positions solely based on their visual appearance. To avoid trivial solutions, we increase the difficulty of this task by keeping only a subset of patches visible. Additionally, considering there may be different patches with similar visual appearances, we propose position smoothing and attentive reconstruction strategies to relax this classification problem, since it is not necessary to reconstruct their exact positions in these cases. Empirical evaluations of DropPos show strong capabilities. DropPos outperforms supervised pre-training and achieves competitive results compared with state-of-the-art self-supervised alternatives on a wide range of downstream benchmarks. This suggests that explicitly encouraging spatial reasoning abilities, as DropPos does, indeed contributes to the improved location awareness of ViTs. The code is publicly available at https://github.com/Haochen-Wang409/DropPos.
</details>
<details>
<summary>摘要</summary>
为了解决transformer眼见模型（ViT）对输入元素顺序的敏感性问题，我们提出了DropPos，一个新的自我超vised预备任务。DropPos的设计是简单的：我们首先随机选择大量的位置嵌入，然后让模型根据视觉特征来推断实际的位置。为了避免轻松解释，我们将只有一部分patch可视。此外，为了降低这个分类问题的难度，我们提出了position smoothing和专注重建构成技术。实验评估显示DropPos能够实现强大的表现，并且与现有的自我超vised替代方案相比，在广泛的下游评估中具有竞争力。这表明明确地强调空间推理能力，就像DropPos所做的一样，对ViT的位置意识 indeed有助益。代码可以在https://github.com/Haochen-Wang409/DropPos中找到。
</details></li>
</ul>
<hr>
<h2 id="Toward-High-Quality-Facial-Representation-Learning"><a href="#Toward-High-Quality-Facial-Representation-Learning" class="headerlink" title="Toward High Quality Facial Representation Learning"></a>Toward High Quality Facial Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03575">http://arxiv.org/abs/2309.03575</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nomewang/mcf">https://github.com/nomewang/mcf</a></li>
<li>paper_authors: Yue Wang, Jinlong Peng, Jiangning Zhang, Ran Yi, Liang Liu, Yabiao Wang, Chengjie Wang</li>
<li>for: 本研究旨在提高面部分析任务的性能，特别是面部表示性的提高。</li>
<li>methods: 本研究使用自适应预训练方法，包括使用面罩模型和对比策略，以提高面部表示性。</li>
<li>results: 本研究在多个下游任务中表现出色，包括AFLW-19面对齐和LaPa面分割等。模型在面部表示性方面提高了状态之arte的性能。<details>
<summary>Abstract</summary>
Face analysis tasks have a wide range of applications, but the universal facial representation has only been explored in a few works. In this paper, we explore high-performance pre-training methods to boost the face analysis tasks such as face alignment and face parsing. We propose a self-supervised pre-training framework, called \textbf{\it Mask Contrastive Face (MCF)}, with mask image modeling and a contrastive strategy specially adjusted for face domain tasks. To improve the facial representation quality, we use feature map of a pre-trained visual backbone as a supervision item and use a partially pre-trained decoder for mask image modeling. To handle the face identity during the pre-training stage, we further use random masks to build contrastive learning pairs. We conduct the pre-training on the LAION-FACE-cropped dataset, a variants of LAION-FACE 20M, which contains more than 20 million face images from Internet websites. For efficiency pre-training, we explore our framework pre-training performance on a small part of LAION-FACE-cropped and verify the superiority with different pre-training settings. Our model pre-trained with the full pre-training dataset outperforms the state-of-the-art methods on multiple downstream tasks. Our model achieves 0.932 NME$_{diag}$ for AFLW-19 face alignment and 93.96 F1 score for LaPa face parsing. Code is available at https://github.com/nomewang/MCF.
</details>
<details>
<summary>摘要</summary>
“面部分析任务有很广泛的应用，但universal面部表示只在一些研究中被探讨。在这篇论文中，我们探索高性能预训练方法来提升面部分析任务，如面对齐和面分解。我们提出了一个自我超级vised预训练框架，称为Mask Contrastive Face（MCF），它使用面照模型和特定适应于面域任务的对比策略。为提高面部表示质量，我们使用预训练的视觉后处理器的特征图作为监督项，并使用部分预训练的解码器进行面照模型。为了在预训练阶段处理面部标识，我们还使用随机mask来建立对比学习对。我们在LAION-FACE-cropped数据集上进行预训练，这是LAION-FACE 20M数据集的一个变种，它包含了互联网上超过20万张面像。为了提高效率，我们在不同的预训练设置下进行了探索。我们的模型在多个下游任务中表现出色，其中AFLW-19面对齐NME$_{diag}$达0.932，LaPa面分解F1分数达93.96。代码可以在https://github.com/nomewang/MCF上找到。”
</details></li>
</ul>
<hr>
<h2 id="Sparse-Federated-Training-of-Object-Detection-in-the-Internet-of-Vehicles"><a href="#Sparse-Federated-Training-of-Object-Detection-in-the-Internet-of-Vehicles" class="headerlink" title="Sparse Federated Training of Object Detection in the Internet of Vehicles"></a>Sparse Federated Training of Object Detection in the Internet of Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03569">http://arxiv.org/abs/2309.03569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luping Rao, Chuan Ma, Ming Ding, Yuwen Qian, Lu Zhou, Zhe Liu</li>
<li>for: 提高iot中的车辆检测精度，降低通信开销</li>
<li>methods: 基于联合学习的方法，包括在中央服务器上分享已经训练好的本地模型，以及在边缘设备上进行稀疏训练</li>
<li>results: 实验结果表明，提议的方案可以实现需要的车辆检测率，同时减少了许多通信成本<details>
<summary>Abstract</summary>
As an essential component part of the Intelligent Transportation System (ITS), the Internet of Vehicles (IoV) plays a vital role in alleviating traffic issues. Object detection is one of the key technologies in the IoV, which has been widely used to provide traffic management services by analyzing timely and sensitive vehicle-related information. However, the current object detection methods are mostly based on centralized deep training, that is, the sensitive data obtained by edge devices need to be uploaded to the server, which raises privacy concerns. To mitigate such privacy leakage, we first propose a federated learning-based framework, where well-trained local models are shared in the central server. However, since edge devices usually have limited computing power, plus a strict requirement of low latency in IoVs, we further propose a sparse training process on edge devices, which can effectively lighten the model, and ensure its training efficiency on edge devices, thereby reducing communication overheads. In addition, due to the diverse computing capabilities and dynamic environment, different sparsity rates are applied to edge devices. To further guarantee the performance, we propose, FedWeg, an improved aggregation scheme based on FedAvg, which is designed by the inverse ratio of sparsity rates. Experiments on the real-life dataset using YOLO show that the proposed scheme can achieve the required object detection rate while saving considerable communication costs.
</details>
<details>
<summary>摘要</summary>
作为智能交通系统（ITS）的重要组件，互联网imatics（IoV）在解决交通问题方面扮演着重要角色。对象检测是IoV中的关键技术之一，通过实时和敏感的车辆相关信息分析，提供交通管理服务。然而，当前的对象检测方法大多基于中央深度训练，即从边缘设备获取的敏感数据需要上传到服务器，这会导致隐私泄露。为了缓解这种隐私泄露，我们首先提议了一个基于联邦学习的框架，在中央服务器中分享已经训练好的本地模型。然而，边缘设备通常具有有限的计算能力， plus 因 IoV 的低延迟要求，我们进一步提议了一种稀疏训练过程在边缘设备上，可以有效减轻模型的计算负担，并在边缘设备上减少通信开销。此外，由于边缘设备的多样化计算能力和动态环境，我们采用不同的稀疏率来应对不同的边缘设备。为了进一步保证性能，我们提议了FedWeg，一种基于FedAvg的改进聚合方案，通过对稀疏率的反比进行调整，以保证聚合效果。实验结果表明，使用YOLO实际数据集时，我们的方案可以达到需要的对象检测率，同时减少了较大的通信成本。
</details></li>
</ul>
<hr>
<h2 id="Region-Generation-and-Assessment-Network-for-Occluded-Person-Re-Identification"><a href="#Region-Generation-and-Assessment-Network-for-Occluded-Person-Re-Identification" class="headerlink" title="Region Generation and Assessment Network for Occluded Person Re-Identification"></a>Region Generation and Assessment Network for Occluded Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03558">http://arxiv.org/abs/2309.03558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuting He, Weihua Chen, Kai Wang, Hao Luo, Fan Wang, Wei Jiang, Henghui Ding</li>
<li>for: 本研究主要针对人体重认定（ReID）问题，尤其是 Addressing the challenges of misalignment and occlusions in ReID.</li>
<li>methods: 提出了一种 Region Generation and Assessment Network (RGANet)，包括 Region Generation Module (RGM) 和 Region Assessment Module (RAM)，用于有效地检测人体区域和强调重要区域。</li>
<li>results: 对六个广泛使用的 benchmark 进行了EXTENSIVE experimental results，证明 RGANet 在比较方法中表现出色。<details>
<summary>Abstract</summary>
Person Re-identification (ReID) plays a more and more crucial role in recent years with a wide range of applications. Existing ReID methods are suffering from the challenges of misalignment and occlusions, which degrade the performance dramatically. Most methods tackle such challenges by utilizing external tools to locate body parts or exploiting matching strategies. Nevertheless, the inevitable domain gap between the datasets utilized for external tools and the ReID datasets and the complicated matching process make these methods unreliable and sensitive to noises. In this paper, we propose a Region Generation and Assessment Network (RGANet) to effectively and efficiently detect the human body regions and highlight the important regions. In the proposed RGANet, we first devise a Region Generation Module (RGM) which utilizes the pre-trained CLIP to locate the human body regions using semantic prototypes extracted from text descriptions. Learnable prompt is designed to eliminate domain gap between CLIP datasets and ReID datasets. Then, to measure the importance of each generated region, we introduce a Region Assessment Module (RAM) that assigns confidence scores to different regions and reduces the negative impact of the occlusion regions by lower scores. The RAM consists of a discrimination-aware indicator and an invariance-aware indicator, where the former indicates the capability to distinguish from different identities and the latter represents consistency among the images of the same class of human body regions. Extensive experimental results for six widely-used benchmarks including three tasks (occluded, partial, and holistic) demonstrate the superiority of RGANet against state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
人体重认（ReID）在最近几年变得越来越重要，它拥有广泛的应用领域。现有的ReID方法面临着异常匹配和遮挡的挑战，这些挑战会使得方法表现下降。大多数方法通过使用外部工具定位人体部分或者利用匹配策略来解决这些挑战。然而，实际的领域差值 между用于外部工具的数据集和ReID数据集，以及复杂的匹配过程，使得这些方法不可靠和敏感于噪声。在这篇论文中，我们提出了一种Region Generation and Assessment Network（RGANet），用于有效地和高效地检测人体部分并高亮重要区域。RGANet中首先设计了一种Region Generation Module（RGM），利用预训练的CLIP来定位人体部分使用语义词汇提取的文本描述。我们制定了可学习的提示，以消除领域差值 междуCLIP数据集和ReID数据集。然后，我们引入了一种Region Assessment Module（RAM），用于评估每个生成的区域的重要性。RAM包括一个排除噪声的指标和一个对称响应指标，其中前者表示可以分辨不同的人类标识，后者表示图像中同类人体部分的一致性。我们对六个广泛使用的标准 benchmark进行了广泛的实验，结果表明RGANet在比特率和泛化能力方面具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Text2Control3D-Controllable-3D-Avatar-Generation-in-Neural-Radiance-Fields-using-Geometry-Guided-Text-to-Image-Diffusion-Model"><a href="#Text2Control3D-Controllable-3D-Avatar-Generation-in-Neural-Radiance-Fields-using-Geometry-Guided-Text-to-Image-Diffusion-Model" class="headerlink" title="Text2Control3D: Controllable 3D Avatar Generation in Neural Radiance Fields using Geometry-Guided Text-to-Image Diffusion Model"></a>Text2Control3D: Controllable 3D Avatar Generation in Neural Radiance Fields using Geometry-Guided Text-to-Image Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03550">http://arxiv.org/abs/2309.03550</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deepshwang/text2control3d">https://github.com/deepshwang/text2control3d</a></li>
<li>paper_authors: Sungwon Hwang, Junha Hyung, Jaegul Choo</li>
<li>for: 这个论文旨在提供一种可控的文本到3D人物生成方法，可以通过提供一些控制视角的图像来控制人物的表情和外观。</li>
<li>methods: 该方法使用了ControlNet进行扩展，并使用了Neural Radiance Fields（NeRF）来构建3D人物。在生成视点控制图像时，使用了对 Referential的注意力来注入可控的表情和外观。此外，还进行了低通过滤波来缓解视点不同的文本问题。</li>
<li>results: 该方法可以生成高品质的3D人物，并可以控制人物的表情和外观。在实验中，我们发现了该方法可以在不同的视点下生成一致的3D人物，并且可以在不同的图像中控制人物的表情和外观。<details>
<summary>Abstract</summary>
Recent advances in diffusion models such as ControlNet have enabled geometrically controllable, high-fidelity text-to-image generation. However, none of them addresses the question of adding such controllability to text-to-3D generation. In response, we propose Text2Control3D, a controllable text-to-3D avatar generation method whose facial expression is controllable given a monocular video casually captured with hand-held camera. Our main strategy is to construct the 3D avatar in Neural Radiance Fields (NeRF) optimized with a set of controlled viewpoint-aware images that we generate from ControlNet, whose condition input is the depth map extracted from the input video. When generating the viewpoint-aware images, we utilize cross-reference attention to inject well-controlled, referential facial expression and appearance via cross attention. We also conduct low-pass filtering of Gaussian latent of the diffusion model in order to ameliorate the viewpoint-agnostic texture problem we observed from our empirical analysis, where the viewpoint-aware images contain identical textures on identical pixel positions that are incomprehensible in 3D. Finally, to train NeRF with the images that are viewpoint-aware yet are not strictly consistent in geometry, our approach considers per-image geometric variation as a view of deformation from a shared 3D canonical space. Consequently, we construct the 3D avatar in a canonical space of deformable NeRF by learning a set of per-image deformation via deformation field table. We demonstrate the empirical results and discuss the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
近期Diffusion模型如ControlNet的进步使得文本到图像生成中具有可控的高精度。然而，这些方法都没有考虑文本到3D生成中的可控性问题。为此，我们提出Text2Control3D方法，它可以通过控制Neural Radiance Fields（NeRF）中的3D人物表达来实现文本到3D人物生成。我们的主要策略是根据ControlNet生成的视角相关图像来构建NeRF，并通过交叉引用注意力来注入控制 facial expression和外观的 referential特征。此外，我们还应用低通 Filtering来改善我们观察到的视点缺失问题，这些问题是由于Diffusion模型生成的图像中存在同一个文本和外观的重复现象。最后，我们通过学习每个图像的特殊变换来训练NeRF，以便在不同视点下生成可控的3D人物。我们的实验结果表明，我们的方法可以生成高质量的3D人物，并且可以控制其 facial expression和外观。
</details></li>
</ul>
<hr>
<h2 id="Trash-to-Treasure-Low-Light-Object-Detection-via-Decomposition-and-Aggregation"><a href="#Trash-to-Treasure-Low-Light-Object-Detection-via-Decomposition-and-Aggregation" class="headerlink" title="Trash to Treasure: Low-Light Object Detection via Decomposition-and-Aggregation"></a>Trash to Treasure: Low-Light Object Detection via Decomposition-and-Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03548">http://arxiv.org/abs/2309.03548</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohan Cui, Long Ma, Tengyu Ma, Jinyuan Liu, Xin Fan, Risheng Liu</li>
<li>for: 提高对low-light环境的 объек检测精度</li>
<li>methods: 使用优化的扩充器+检测器组合，将废弃的照明减去作为检测器的助手，提取检测友好特征</li>
<li>results: 与其他状态艺法相比，实现了更高的检测精度<details>
<summary>Abstract</summary>
Object detection in low-light scenarios has attracted much attention in the past few years. A mainstream and representative scheme introduces enhancers as the pre-processing for regular detectors. However, because of the disparity in task objectives between the enhancer and detector, this paradigm cannot shine at its best ability. In this work, we try to arouse the potential of enhancer + detector. Different from existing works, we extend the illumination-based enhancers (our newly designed or existing) as a scene decomposition module, whose removed illumination is exploited as the auxiliary in the detector for extracting detection-friendly features. A semantic aggregation module is further established for integrating multi-scale scene-related semantic information in the context space. Actually, our built scheme successfully transforms the "trash" (i.e., the ignored illumination in the detector) into the "treasure" for the detector. Plenty of experiments are conducted to reveal our superiority against other state-of-the-art methods. The code will be public if it is accepted.
</details>
<details>
<summary>摘要</summary>
寻找 объек特点在低光照情况下已经吸引了一些注意力。主流和表现出名的方案是通过增强器作为普通探测器的预处理。然而，由于增强器和探测器之间的任务目标差异，这种方法无法发挥最大的能力。在这种工作中，我们尝试使增强器+探测器达到最佳效果。与现有的方法不同，我们将照明基于增强器（我们 newly 设计或现有的）作为场景分解模块，并将其中的照明除去作为探测器中EXTRACTING detection-friendly features的auxiliary。此外，我们还设立了 semantic aggregation module，用于在上下文空间中集成多尺度场景相关的semantic信息。实际上，我们建立的方案成功地将"垃圾"（即探测器中被忽略的照明）转化为"财富"。我们进行了大量的实验，并证明了我们对其他现状的方法有着超越性。如果接受，我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Scene-Graph-Generation-via-Triplet-Calibration-and-Reduction"><a href="#Zero-Shot-Scene-Graph-Generation-via-Triplet-Calibration-and-Reduction" class="headerlink" title="Zero-Shot Scene Graph Generation via Triplet Calibration and Reduction"></a>Zero-Shot Scene Graph Generation via Triplet Calibration and Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03542">http://arxiv.org/abs/2309.03542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jkli1998/T-CAR">https://github.com/jkli1998/T-CAR</a></li>
<li>paper_authors: Jiankai Li, Yunhong Wang, Weixin Li</li>
<li>for: 提高Scene Graph Generation（SGG）的下游任务表现，尤其是Zero-shot SGG。</li>
<li>methods: 提出Triplet Calibration and Reduction（T-CAR）框架，包括Triplet calibration loss和Unseen space reduction loss，以及Contextual encoder来提高无法见 triplets的泛化表现。</li>
<li>results: 实验表明，我们的方法可以在Zero-shot SGG中提供了一致的改进，超过了现有方法的表现。<details>
<summary>Abstract</summary>
Scene Graph Generation (SGG) plays a pivotal role in downstream vision-language tasks. Existing SGG methods typically suffer from poor compositional generalizations on unseen triplets. They are generally trained on incompletely annotated scene graphs that contain dominant triplets and tend to bias toward these seen triplets during inference. To address this issue, we propose a Triplet Calibration and Reduction (T-CAR) framework in this paper. In our framework, a triplet calibration loss is first presented to regularize the representations of diverse triplets and to simultaneously excavate the unseen triplets in incompletely annotated training scene graphs. Moreover, the unseen space of scene graphs is usually several times larger than the seen space since it contains a huge number of unrealistic compositions. Thus, we propose an unseen space reduction loss to shift the attention of excavation to reasonable unseen compositions to facilitate the model training. Finally, we propose a contextual encoder to improve the compositional generalizations of unseen triplets by explicitly modeling the relative spatial relations between subjects and objects. Extensive experiments show that our approach achieves consistent improvements for zero-shot SGG over state-of-the-art methods. The code is available at https://github.com/jkli1998/T-CAR.
</details>
<details>
<summary>摘要</summary>
Scene Graph Generation (SGG) 扮演着下游视语任务的重要角色。现有的 SGG 方法通常受到不好的compositional generalization的影响，即在未看过的 triplets 上的表现不佳。它们通常是在部分注解的Scene Graph中训练的，这些Scene Graph 中充满了主导的 triplets，导致在推理时偏向这些已经看过的 triplets。为解决这个问题，我们在这篇论文中提出了Triplet Calibration and Reduction（T-CAR）框架。在我们的框架中，首先提出了 triplet calibration loss，用于规范多元 triplets 的表现，同时挖掘在不完全注解的训练 Scene Graph 中的未看过的 triplets。此外，Scene Graph 的未看过空间通常比见过空间更大，因为它包含了庞大的不可能的组合。因此，我们提出了Scene Graph 的未看过空间减少损失，以Shift attention 到合理的未看过组合，以便模型训练。最后，我们提出了一种Contextual Encoder，用于提高未看过 triplets 的compositional generalizations，通过显式地模型主题和 объек 之间的相对空间关系。我们的方法在零shot SGG 上实现了广泛的实验室，和现有的方法相比，具有了一致的改进。代码可以在 https://github.com/jkli1998/T-CAR 上获取。
</details></li>
</ul>
<hr>
<h2 id="YOLO-series-target-detection-algorithms-for-underwater-environments"><a href="#YOLO-series-target-detection-algorithms-for-underwater-environments" class="headerlink" title="YOLO series target detection algorithms for underwater environments"></a>YOLO series target detection algorithms for underwater environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03539">http://arxiv.org/abs/2309.03539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenjie Zhang, Pengcheng Jiao</li>
<li>for: marine engineering applications (such as underwater structural health monitoring and underwater biological detection)</li>
<li>methods: improved YOLO algorithm for underwater environments (addressing challenges such as dim light and turbid water)</li>
<li>results: potential for increased accuracy and efficiency in underwater applications, but still facing challenges and limitations.<details>
<summary>Abstract</summary>
You Only Look Once (YOLO) algorithm is a representative target detection algorithm emerging in 2016, which is known for its balance of computing speed and accuracy, and now plays an important role in various fields of human production and life. However, there are still many limitations in the application of YOLO algorithm in underwater environments due to problems such as dim light and turbid water. With limited land area resources, the ocean must have great potential for future human development. In this paper, starting from the actual needs of marine engineering applications, taking underwater structural health monitoring (SHM) and underwater biological detection as examples, we propose improved methods for the application of underwater YOLO algorithms, and point out the problems that still exist.
</details>
<details>
<summary>摘要</summary>
你只需一看 (YOLO) 算法是2016年出现的一种代表性目标检测算法，知名于计算速度和准确率的平衡，现在在人类生产和生活中扮演着重要的角色。然而，在水下环境中应用YOLO算法还有许多限制，主要包括灰暗的照明和浑水等问题。由于海洋面积有限，海洋必须拥有未来人类发展的巨大潜在力量。在本文中，从marine工程应用实际需求出发，通过水下结构健康监测 (SHM) 和水下生物检测为例，提出改进了水下YOLO算法的应用方法，并指出仍有问题。
</details></li>
</ul>
<hr>
<h2 id="Feature-Enhancer-Segmentation-Network-FES-Net-for-Vessel-Segmentation"><a href="#Feature-Enhancer-Segmentation-Network-FES-Net-for-Vessel-Segmentation" class="headerlink" title="Feature Enhancer Segmentation Network (FES-Net) for Vessel Segmentation"></a>Feature Enhancer Segmentation Network (FES-Net) for Vessel Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03535">http://arxiv.org/abs/2309.03535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq M. Khan, Muhammad Arsalan, Shahzaib Iqbal, Imran Razzak, Erik Meijering</li>
<li>for: 预防和诊断视力减退疾病，如膳部病变和年轻人病变，需要精准地分类视网膜血管。</li>
<li>methods: 我们提出了一种新的特征增强分类网络（FES-Net），不需要额外的图像增强步骤，直接处理输入图像，并使用四个唤醒卷积块（PCB）进行下采样，以生成每类的 binary mask。</li>
<li>results: FES-Net 在四个公开可用的 state-of-the-art 数据集上（DRIVE、STARE、CHASE 和 HRF）表现出色，与现有文献中的其他竞争方法相比，显示出了明显的超越性。<details>
<summary>Abstract</summary>
Diseases such as diabetic retinopathy and age-related macular degeneration pose a significant risk to vision, highlighting the importance of precise segmentation of retinal vessels for the tracking and diagnosis of progression. However, existing vessel segmentation methods that heavily rely on encoder-decoder structures struggle to capture contextual information about retinal vessel configurations, leading to challenges in reconciling semantic disparities between encoder and decoder features. To address this, we propose a novel feature enhancement segmentation network (FES-Net) that achieves accurate pixel-wise segmentation without requiring additional image enhancement steps. FES-Net directly processes the input image and utilizes four prompt convolutional blocks (PCBs) during downsampling, complemented by a shallow upsampling approach to generate a binary mask for each class. We evaluate the performance of FES-Net on four publicly available state-of-the-art datasets: DRIVE, STARE, CHASE, and HRF. The evaluation results clearly demonstrate the superior performance of FES-Net compared to other competitive approaches documented in the existing literature.
</details>
<details>
<summary>摘要</summary>
疾病如糖尿病和年龄相关的macular degeneration会对视力造成重大威胁，因此精准的血管分 segmentation在跟踪和诊断进程中具有 paramount importance。然而，现有的血管分 segmentation方法，即基于encoder-decoder结构的方法，在capturing retinal vessel配置上下文信息方面存在挑战，这会导致encoder和decoder特征之间的semantic disparities困难于相互协调。为了解决这个问题，我们提出了一种新的特征增强分 segmentation网络（FES-Net），它可以在不需要额外图像增强步骤的情况下，准确地进行每个像素的分 segmentation。FES-Net直接处理输入图像，并在下降阶段使用四个推荐卷积核（PCB），并且采用浅层的 upsampling 方法生成每个类型的二进制掩蔽。我们对四个公开的 state-of-the-art 数据集进行了评估：DRIVE、STARE、CHASE 和 HRF。评估结果表明，FES-Net 与文献中已有的其他竞争方法相比，具有显著的性能优势。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Negative-Learning-Approach-to-Partial-Domain-Adaptation-Using-Source-Prototypes"><a href="#A-Robust-Negative-Learning-Approach-to-Partial-Domain-Adaptation-Using-Source-Prototypes" class="headerlink" title="A Robust Negative Learning Approach to Partial Domain Adaptation Using Source Prototypes"></a>A Robust Negative Learning Approach to Partial Domain Adaptation Using Source Prototypes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03531">http://arxiv.org/abs/2309.03531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandipan Choudhuri, Suli Adeniye, Arunabha Sen</li>
<li>for: This paper proposes a robust Partial Domain Adaptation (PDA) framework to mitigate the negative transfer problem by incorporating a robust target-supervision strategy.</li>
<li>methods: The proposed framework leverages ensemble learning and includes diverse, complementary label feedback, alleviating the effect of incorrect feedback and promoting pseudo-label refinement. It optimizes intra-class compactness and inter-class separation with the inferred source prototypes and highly-confident target samples in a domain-invariant fashion.</li>
<li>results: The proposed framework demonstrates enhanced robustness and generalization in a range of partial domain adaptation tasks, outperforming existing state-of-the-art PDA approaches.Here are the three points in Simplified Chinese:</li>
<li>for: 这篇论文提出了一种robust Partial Domain Adaptation（PDA）框架，以减少负转移问题，通过包含一种robust目标监督策略。</li>
<li>methods: 该框架利用ensemble学习和多元标签反馈，使得反馈错误的影响减少，并促进pseudo标签纠正。它在域无关的方式优化源类准确性和目标类分化度。</li>
<li>results: 该框架在多种partial domain adaptation任务中表现出了提高的Robustness和普遍性，超过了现有的state-of-the-art PDA方法。<details>
<summary>Abstract</summary>
This work proposes a robust Partial Domain Adaptation (PDA) framework that mitigates the negative transfer problem by incorporating a robust target-supervision strategy. It leverages ensemble learning and includes diverse, complementary label feedback, alleviating the effect of incorrect feedback and promoting pseudo-label refinement. Rather than relying exclusively on first-order moments for distribution alignment, our approach offers explicit objectives to optimize intra-class compactness and inter-class separation with the inferred source prototypes and highly-confident target samples in a domain-invariant fashion. Notably, we ensure source data privacy by eliminating the need to access the source data during the adaptation phase through a priori inference of source prototypes. We conducted a series of comprehensive experiments, including an ablation analysis, covering a range of partial domain adaptation tasks. Comprehensive evaluations on benchmark datasets corroborate our framework's enhanced robustness and generalization, demonstrating its superiority over existing state-of-the-art PDA approaches.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:这个工作提出了一种robust Partial Domain Adaptation（PDA）框架，用以 Mitigate the negative transfer problem by incorporating a robust target-supervision strategy. 它利用了ensemble learning和多元标签反馈，以提高pseudo-label的精度和多样性，从而降低了因为错误反馈而导致的影响。而不是仅仅依靠first-order moments for distribution alignment, our approach offers explicit objectives to optimize intra-class compactness and inter-class separation with the inferred source prototypes and highly-confident target samples in a domain-invariant fashion. 另外, we ensure source data privacy by eliminating the need to access the source data during the adaptation phase through a priori inference of source prototypes. We conducted a series of comprehensive experiments, including an ablation analysis, covering a range of partial domain adaptation tasks. Comprehensive evaluations on benchmark datasets corroborate our framework's enhanced robustness and generalization, demonstrating its superiority over existing state-of-the-art PDA approaches.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Single-Object-Detection-on-Image-Patches-with-Early-Exit-Enhanced-High-Precision-CNNs"><a href="#Efficient-Single-Object-Detection-on-Image-Patches-with-Early-Exit-Enhanced-High-Precision-CNNs" class="headerlink" title="Efficient Single Object Detection on Image Patches with Early Exit Enhanced High-Precision CNNs"></a>Efficient Single Object Detection on Image Patches with Early Exit Enhanced High-Precision CNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03530">http://arxiv.org/abs/2309.03530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arne Moos</li>
<li>for: 本研究旨在提出一种用于移动机器人检测物体的新方法，主要是检测球体。</li>
<li>methods: 本文提出了一种专门为计算约束限制的机器人平台设计的卷积神经网络架构，以高精度分类单个物体图像块并确定其准确的空间位置。</li>
<li>results: 本文的方法可以在静态和动态环境中，在不同的照明条件下，达到100%的准确率和大于87%的检测率，并且可以在约170微秒内完成每个假设。通过结合提出的方法和早退法，可以实现更 than 28%的运行时优化。<details>
<summary>Abstract</summary>
This paper proposes a novel approach for detecting objects using mobile robots in the context of the RoboCup Standard Platform League, with a primary focus on detecting the ball. The challenge lies in detecting a dynamic object in varying lighting conditions and blurred images caused by fast movements. To address this challenge, the paper presents a convolutional neural network architecture designed specifically for computationally constrained robotic platforms. The proposed CNN is trained to achieve high precision classification of single objects in image patches and to determine their precise spatial positions. The paper further integrates Early Exits into the existing high-precision CNN architecture to reduce the computational cost of easily rejectable cases in the background class. The training process involves a composite loss function based on confidence and positional losses with dynamic weighting and data augmentation. The proposed approach achieves a precision of 100% on the validation dataset and a recall of almost 87%, while maintaining an execution time of around 170 $\mu$s per hypotheses. By combining the proposed approach with an Early Exit, a runtime optimization of more than 28%, on average, can be achieved compared to the original CNN. Overall, this paper provides an efficient solution for an enhanced detection of objects, especially the ball, in computationally constrained robotic platforms.
</details>
<details>
<summary>摘要</summary>
The training process involves a composite loss function based on confidence and positional losses with dynamic weighting and data augmentation. The proposed approach achieves a precision of 100% on the validation dataset and a recall of almost 87%, while maintaining an execution time of around 170 microseconds per hypotheses. By combining the proposed approach with an Early Exit, a runtime optimization of more than 28%, on average, can be achieved compared to the original CNN.Overall, this paper provides an efficient solution for enhanced object detection, especially the ball, in computationally constrained robotic platforms.
</details></li>
</ul>
<hr>
<h2 id="BroadCAM-Outcome-agnostic-Class-Activation-Mapping-for-Small-scale-Weakly-Supervised-Applications"><a href="#BroadCAM-Outcome-agnostic-Class-Activation-Mapping-for-Small-scale-Weakly-Supervised-Applications" class="headerlink" title="BroadCAM: Outcome-agnostic Class Activation Mapping for Small-scale Weakly Supervised Applications"></a>BroadCAM: Outcome-agnostic Class Activation Mapping for Small-scale Weakly Supervised Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03509">http://arxiv.org/abs/2309.03509</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linjiatai/broadcam">https://github.com/linjiatai/broadcam</a></li>
<li>paper_authors: Jiatai Lin, Guoqiang Han, Xuemiao Xu, Changhong Liang, Tien-Tsin Wong, C. L. Philip Chen, Zaiyi Liu, Chu Han</li>
<li>for: 这个 paper 是为了解释 deep learning 模型的问题，特别是在弱化运算下进行 semantic segmentation 和 object localization。</li>
<li>methods: 这个 paper 使用了 outcome-agnostic CAM 方法，即 BroadCAM，以避免因为小规模训练而产生不可靠的 weights。</li>
<li>results: BroadCAM 在不同的 CNN 架构下显示出了较高的性能，特别是在小规模训练数据下（less than 5%）。它还达到了 SOTA 性能在大规模训练数据下。<details>
<summary>Abstract</summary>
Class activation mapping~(CAM), a visualization technique for interpreting deep learning models, is now commonly used for weakly supervised semantic segmentation~(WSSS) and object localization~(WSOL). It is the weighted aggregation of the feature maps by activating the high class-relevance ones. Current CAM methods achieve it relying on the training outcomes, such as predicted scores~(forward information), gradients~(backward information), etc. However, when with small-scale data, unstable training may lead to less effective model outcomes and generate unreliable weights, finally resulting in incorrect activation and noisy CAM seeds. In this paper, we propose an outcome-agnostic CAM approach, called BroadCAM, for small-scale weakly supervised applications. Since broad learning system (BLS) is independent to the model learning, BroadCAM can avoid the weights being affected by the unreliable model outcomes when with small-scale data. By evaluating BroadCAM on VOC2012 (natural images) and BCSS-WSSS (medical images) for WSSS and OpenImages30k for WSOL, BroadCAM demonstrates superior performance than existing CAM methods with small-scale data (less than 5\%) in different CNN architectures. It also achieves SOTA performance with large-scale training data. Extensive qualitative comparisons are conducted to demonstrate how BroadCAM activates the high class-relevance feature maps and generates reliable CAMs when with small-scale training data.
</details>
<details>
<summary>摘要</summary>
干净的类激活映射（CAM）现在广泛用于弱类标注 segmentation（WSSS）和物体 lokalisierung（WSOL）。它是通过活化高相关类的特征图的加权积sum来实现的。现有的CAM方法通过训练结果来实现，如预测得分（前向信息）、梯度（反向信息）等。然而，当 faced with small-scale data 时，不稳定的训练可能会导致模型的输出不稳定，最终导致错误的激活和噪音 CAM 种子。在这篇论文中，我们提出了不受训练结果影响的CAM方法，called BroadCAM， для small-scale weakly supervised 应用程序。由于 broad learning system（BLS）是独立于模型学习的，BroadCAM可以避免 weights 被模型的输出不稳定所影响。我们通过在 VOC2012（自然图像）和 BCSS-WSSS（医学图像）上进行 WSSS，以及在 OpenImages30k 上进行 WSOL，来评估 BroadCAM 的性能。我们发现 BroadCAM 在不同的 CNN 架构下对 small-scale 数据（less than 5%） exhibit 出色的性能，并且在大规模训练数据下也达到了 SOTA 性能。我们还进行了广泛的Qualitative comparison ，以示 BroadCAM 在 small-scale 训练数据下如何活化高相关类的特征图并生成可靠的 CAM。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Frame-Interpolation-in-Wavelet-Domain"><a href="#Dynamic-Frame-Interpolation-in-Wavelet-Domain" class="headerlink" title="Dynamic Frame Interpolation in Wavelet Domain"></a>Dynamic Frame Interpolation in Wavelet Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03508">http://arxiv.org/abs/2309.03508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ltkong218/waveletvfi">https://github.com/ltkong218/waveletvfi</a></li>
<li>paper_authors: Lingtong Kong, Boyuan Jiang, Donghao Luo, Wenqing Chu, Ying Tai, Chengjie Wang, Jie Yang</li>
<li>for: 提高视觉体验的frame rate，通过使用高级动态模型和合成网络。</li>
<li>methods: 提议一种基于wavelet synthesis网络的两stage框架，首先估计中间的湍流，然后使用流alignedContext特征预测多尺度wavelet含量。</li>
<li>results: 在常见高分辨率和动画框架 interpolate中，提议的WaveletVFI可以减少计算量达40%，保持相似的准确性，与其他状态静的方法相比更高效。<details>
<summary>Abstract</summary>
Video frame interpolation is an important low-level vision task, which can increase frame rate for more fluent visual experience. Existing methods have achieved great success by employing advanced motion models and synthesis networks. However, the spatial redundancy when synthesizing the target frame has not been fully explored, that can result in lots of inefficient computation. On the other hand, the computation compression degree in frame interpolation is highly dependent on both texture distribution and scene motion, which demands to understand the spatial-temporal information of each input frame pair for a better compression degree selection. In this work, we propose a novel two-stage frame interpolation framework termed WaveletVFI to address above problems. It first estimates intermediate optical flow with a lightweight motion perception network, and then a wavelet synthesis network uses flow aligned context features to predict multi-scale wavelet coefficients with sparse convolution for efficient target frame reconstruction, where the sparse valid masks that control computation in each scale are determined by a crucial threshold ratio. Instead of setting a fixed value like previous methods, we find that embedding a classifier in the motion perception network to learn a dynamic threshold for each sample can achieve more computation reduction with almost no loss of accuracy. On the common high resolution and animation frame interpolation benchmarks, proposed WaveletVFI can reduce computation up to 40% while maintaining similar accuracy, making it perform more efficiently against other state-of-the-arts. Code is available at https://github.com/ltkong218/WaveletVFI.
</details>
<details>
<summary>摘要</summary>
视频帧 interpolate 是一个重要的低级视觉任务，可以增加帧率，提供更流畅的视觉经验。现有方法通过使用先进的运动模型和合成网络来实现了很大的成功。然而，在合成目标帧时间 redundancy 未经探索，可能导致大量的不必要计算。同时，计算压缩度在帧 interpolate 中高度取决于输入帧对的文本分布和场景运动，需要对每个输入帧对的空间时间信息进行更好的理解，以选择更佳的压缩度。在这项工作中，我们提出了一种新的两个阶段框架，称为 WaveletVFI，以解决以上问题。它首先估计目标帧中间的激光流，然后使用流行alignedContext Features来预测多尺度波лет系数，并使用稀聚核来减少计算。而不是在前一些方法中设置固定值，我们在运动识别网络中嵌入一个类ifier，以学习每个样本的动态阈值，可以更好地减少计算，而无损失准确性。在高分辨率和动画帧 interpolate 的标准测试 benchmarks 上，我们的 WaveletVFI 可以减少计算时间40%，同时保持相似的准确性，与其他现状之前的方法相比，更高效。代码可以在 <https://github.com/ltkong218/WaveletVFI> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Stroke-based-Neural-Painting-and-Stylization-with-Dynamically-Predicted-Painting-Region"><a href="#Stroke-based-Neural-Painting-and-Stylization-with-Dynamically-Predicted-Painting-Region" class="headerlink" title="Stroke-based Neural Painting and Stylization with Dynamically Predicted Painting Region"></a>Stroke-based Neural Painting and Stylization with Dynamically Predicted Painting Region</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03504">http://arxiv.org/abs/2309.03504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sjtuplayer/compositional_neural_painter">https://github.com/sjtuplayer/compositional_neural_painter</a></li>
<li>paper_authors: Teng Hu, Ran Yi, Haokun Zhu, Liang Liu, Jinlong Peng, Yabiao Wang, Chengjie Wang, Lizhuang Ma</li>
<li>for: 这篇论文的目的是提出一种基于笔画的图像渲染方法，以解决现有方法中的边界不一致问题。</li>
<li>methods: 该方法使用了一种动态预测下一个笔画区域的compositor网络，以及一种基于WGAN探测器的画家网络，来预测笔画参数。</li>
<li>results: 对比现有方法，该方法在笔画基于图像渲染和笔画基于风格转换中表现出优异，并且可以保持输入图像的结构。<details>
<summary>Abstract</summary>
Stroke-based rendering aims to recreate an image with a set of strokes. Most existing methods render complex images using an uniform-block-dividing strategy, which leads to boundary inconsistency artifacts. To solve the problem, we propose Compositional Neural Painter, a novel stroke-based rendering framework which dynamically predicts the next painting region based on the current canvas, instead of dividing the image plane uniformly into painting regions. We start from an empty canvas and divide the painting process into several steps. At each step, a compositor network trained with a phasic RL strategy first predicts the next painting region, then a painter network trained with a WGAN discriminator predicts stroke parameters, and a stroke renderer paints the strokes onto the painting region of the current canvas. Moreover, we extend our method to stroke-based style transfer with a novel differentiable distance transform loss, which helps preserve the structure of the input image during stroke-based stylization. Extensive experiments show our model outperforms the existing models in both stroke-based neural painting and stroke-based stylization. Code is available at https://github.com/sjtuplayer/Compositional_Neural_Painter
</details>
<details>
<summary>摘要</summary>
stroke-based rendering targets to recreate an image with a set of strokes. Most existing methods use an uniform-block-dividing strategy, which leads to boundary inconsistency artifacts. To solve the problem, we propose Compositional Neural Painter, a novel stroke-based rendering framework which dynamically predicts the next painting region based on the current canvas, instead of dividing the image plane uniformly into painting regions. We start from an empty canvas and divide the painting process into several steps. At each step, a compositor network trained with a phasic RL strategy first predicts the next painting region, then a painter network trained with a WGAN discriminator predicts stroke parameters, and a stroke renderer paints the strokes onto the painting region of the current canvas. Moreover, we extend our method to stroke-based style transfer with a novel differentiable distance transform loss, which helps preserve the structure of the input image during stroke-based stylization. Extensive experiments show our model outperforms the existing models in both stroke-based neural painting and stroke-based stylization. Code is available at https://github.com/sjtuplayer/Compositional_Neural_Painter.Here's the word-for-word translation of the text into Simplified Chinese:roke-based rendering targets 图像重建 Set 的 strokes. 现有大多数方法使用 uniform-block-dividing 策略，这会导致 boundry inconsistency  artifacts. 为解决问题，我们提出 Compositional Neural Painter, a novel stroke-based rendering framework, which dynamically predicts the next painting region based on the current canvas, instead of dividing the image plane uniformly into painting regions. 我们从 empty canvas 开始，并将 painting 过程分成 several steps. At each step, a compositor network trained with a phasic RL strategy first predicts the next painting region, then a painter network trained with a WGAN discriminator predicts stroke parameters, and a stroke renderer paints the strokes onto the painting region of the current canvas. 其他，我们扩展我们的方法到 stroke-based style transfer with a novel differentiable distance transform loss, which helps preserve the structure of the input image during stroke-based stylization. 广泛 experiments 表明我们的模型在 stroke-based neural painting 和 stroke-based stylization 中都高于现有模型。 Code 可以在 https://github.com/sjtuplayer/Compositional_Neural_Painter 上获取.
</details></li>
</ul>
<hr>
<h2 id="Instance-Segmentation-of-Dislocations-in-TEM-Images"><a href="#Instance-Segmentation-of-Dislocations-in-TEM-Images" class="headerlink" title="Instance Segmentation of Dislocations in TEM Images"></a>Instance Segmentation of Dislocations in TEM Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03499">http://arxiv.org/abs/2309.03499</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kruzaeva/dislocation-segmentation">https://github.com/kruzaeva/dislocation-segmentation</a></li>
<li>paper_authors: Karina Ruzaeva, Kishan Govind, Marc Legros, Stefan Sandfeld</li>
<li>for: 这个论文的目的是用量子电子显微镜（TEM）进行实验室内压缩试验，以揭示杂点的运动。在材料科学领域，了解杂点的位置和运动非常重要，以创造新材料。</li>
<li>methods: 这篇论文使用了现状的实例分割方法，包括Mask R-CNN和YOLOv8，以提取杂点面积。这些杂点面积被转换为数学线段，以便对杂点的长度和几何特征进行量化分析。</li>
<li>results: 这篇论文的结果表明，使用量子电子显微镜进行实验室内压缩试验可以得到高精度的杂点分割结果，并且可以用Physics-based metric来评估网络性能。这些结果可以帮助创造新材料，并且可以用于各种领域的后期处理。<details>
<summary>Abstract</summary>
Quantitative Transmission Electron Microscopy (TEM) during in-situ straining experiment is able to reveal the motion of dislocations -- linear defects in the crystal lattice of metals. In the domain of materials science, the knowledge about the location and movement of dislocations is important for creating novel materials with superior properties. A long-standing problem, however, is to identify the position and extract the shape of dislocations, which would ultimately help to create a digital twin of such materials. In this work, we quantitatively compare state-of-the-art instance segmentation methods, including Mask R-CNN and YOLOv8. The dislocation masks as the results of the instance segmentation are converted to mathematical lines, enabling quantitative analysis of dislocation length and geometry -- important information for the domain scientist, which we then propose to include as a novel length-aware quality metric for estimating the network performance. Our segmentation pipeline shows a high accuracy suitable for all domain-specific, further post-processing. Additionally, our physics-based metric turns out to perform much more consistently than typically used pixel-wise metrics.
</details>
<details>
<summary>摘要</summary>
量子传输电子顺传显微镜（TEM）在实验室内受力试验中能够描述杂点的运动 -- 金属晶体结构中线性缺陷。在材料科学领域，了解杂点的位置和运动对创造新材料的性能具有重要意义。然而，长期存在的问题是如何确定杂点的位置并提取其形状，这将 ultimately 帮助创建材料的数字双。在这种工作中，我们对现有的实例 segmentation 方法进行了量化比较，包括 Mask R-CNN 和 YOLOv8。杂点面为实例 segmentation 的结果被转换为数学线，使得量化分析杂点的长度和几何 -- 对领域科学家而言是重要的信息。我们 then propose 将这些数学线作为新的长度意识质量指标，用于估计网络性能。我们的分 segmentation 管道表现高度准确，适用于所有领域专业人员进行进一步处理。此外，我们的物理基础指标在 Typically 使用像素精度指标之外表现了更一致。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Deep-Learning-based-Melanoma-Classification-using-Immunohistochemistry-and-Routine-Histology-A-Three-Center-Study"><a href="#Evaluating-Deep-Learning-based-Melanoma-Classification-using-Immunohistochemistry-and-Routine-Histology-A-Three-Center-Study" class="headerlink" title="Evaluating Deep Learning-based Melanoma Classification using Immunohistochemistry and Routine Histology: A Three Center Study"></a>Evaluating Deep Learning-based Melanoma Classification using Immunohistochemistry and Routine Histology: A Three Center Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03494">http://arxiv.org/abs/2309.03494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christoph Wies, Lucas Schneider, Sarah Haggenmueller, Tabea-Clara Bucher, Sarah Hobelsberger, Markus V. Heppt, Gerardo Ferrara, Eva I. Krieghoff-Henning, Titus J. Brinker</li>
<li>for: 本研究用于检测皮肤癌病理 slide 的自动识别，使用 Deep Learning (DL) 技术。</li>
<li>methods: 研究使用 ResNet  neural network 在 MelanA 和相应的 H&amp;E 染色 slide 上进行训练，并对 OOD 数据集进行评估。</li>
<li>results: 结果显示，DL 基于 MelanA 的识别系统可以达到同 H&amp;E 基准分类的水平（AUROC &#x3D; 0.81-0.85），并且可以通过多种染色结合分类来提高识别精度。<details>
<summary>Abstract</summary>
Pathologists routinely use immunohistochemical (IHC)-stained tissue slides against MelanA in addition to hematoxylin and eosin (H&E)-stained slides to improve their accuracy in diagnosing melanomas. The use of diagnostic Deep Learning (DL)-based support systems for automated examination of tissue morphology and cellular composition has been well studied in standard H&E-stained tissue slides. In contrast, there are few studies that analyze IHC slides using DL. Therefore, we investigated the separate and joint performance of ResNets trained on MelanA and corresponding H&E-stained slides. The MelanA classifier achieved an area under receiver operating characteristics curve (AUROC) of 0.82 and 0.74 on out of distribution (OOD)-datasets, similar to the H&E-based benchmark classification of 0.81 and 0.75, respectively. A combined classifier using MelanA and H&E achieved AUROCs of 0.85 and 0.81 on the OOD datasets. DL MelanA-based assistance systems show the same performance as the benchmark H&E classification and may be improved by multi stain classification to assist pathologists in their clinical routine.
</details>
<details>
<summary>摘要</summary>
PATHOLOGISTS 通常使用免疫染色技术（IHC）染色组织标本板，以提高诊断皮肤癌的准确性。使用基于 Deep Learning（DL）技术的诊断支持系统自动检查组织结构和细胞组成已经得到了广泛的研究，但对于 IHC 染色板的分析却有少量研究。因此，我们研究了使用 ResNet 在 MelanA 和相应的 H&E 染色板上训练的分类器。MelanA 分类器在 OOD 数据集上的面积下收操作Characteristic curve（AUROC）为 0.82 和 0.74，与 H&E 基准分类结果相似（AUROC 为 0.81 和 0.75）。将 MelanA 和 H&E 分类器合并使得 AUROC 在 OOD 数据集上为 0.85 和 0.81。DL 基于 MelanA 的诊断支持系统与 H&E 基准分类器的性能相同，并且可能通过多种染色分类来改进，以 помочь PATHOLOGISTS 在临床实践中。
</details></li>
</ul>
<hr>
<h2 id="SAM3D-Segment-Anything-Model-in-Volumetric-Medical-Images"><a href="#SAM3D-Segment-Anything-Model-in-Volumetric-Medical-Images" class="headerlink" title="SAM3D: Segment Anything Model in Volumetric Medical Images"></a>SAM3D: Segment Anything Model in Volumetric Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03493">http://arxiv.org/abs/2309.03493</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/DinhHieuHoang/SAM3D">https://github.com/DinhHieuHoang/SAM3D</a></li>
<li>paper_authors: Nhat-Tan Bui, Dinh-Hieu Hoang, Minh-Triet Tran, Ngan Le<br>for:这篇论文主要 targets at 3D volumetric medical images, aiming to provide accurate image segmentation for medical diagnosis.methods:基于Segment Anything Model（SAM）的SAM3D模型，使用预训练的SAM编码器提取输入图像的有意义表示。与其他现有的SAM基于volumetric segmentation方法不同，我们的模型直接将整个3D图像作为输入，简单地处理它，从而避免训练大量参数。results:我们在多个医疗图像数据集上进行了广泛的实验，并证明了我们的网络在3D医疗图像分割任务中具有竞争力，同时具有 significatively efficient 的参数。<details>
<summary>Abstract</summary>
Image segmentation is a critical task in medical image analysis, providing valuable information that helps to make an accurate diagnosis. In recent years, deep learning-based automatic image segmentation methods have achieved outstanding results in medical images. In this paper, inspired by the Segment Anything Model (SAM), a foundation model that has received much attention for its impressive accuracy and powerful generalization ability in 2D still image segmentation, we propose a SAM3D that targets at 3D volumetric medical images and utilizes the pre-trained features from the SAM encoder to capture meaningful representations of input images. Different from other existing SAM-based volumetric segmentation methods that perform the segmentation by dividing the volume into a set of 2D slices, our model takes the whole 3D volume image as input and processes it simply and effectively that avoids training a significant number of parameters. Extensive experiments are conducted on multiple medical image datasets to demonstrate that our network attains competitive results compared with other state-of-the-art methods in 3D medical segmentation tasks while being significantly efficient in terms of parameters.
</details>
<details>
<summary>摘要</summary>
医疗图像分割是医疗图像分析中的关键任务，它提供了诊断的重要信息。在最近的几年中，基于深度学习的自动图像分割方法在医疗图像中取得了出色的结果。在这篇论文中，我们受到Segment Anything Model（SAM）的启发，这是一个在2D静止图像分割中表现出色的基本模型，我们提出了一个名为SAM3D的模型，该模型针对3D医疗图像进行分割，并使用SAMencoder中的预训练特征来捕捉输入图像的有意义表示。与其他现有的SAM基于volumetric分割方法不同，我们的模型不需要将Volume分成多个2Dslice，而是直接处理整个3D图像，从而避免训练大量参数。我们在多个医疗图像数据集上进行了广泛的实验，以示我们的网络与其他状态的方法在3D医疗分 segmentation任务中具有竞争力，同时在参数上具有显著的效率。
</details></li>
</ul>
<hr>
<h2 id="DetermiNet-A-Large-Scale-Diagnostic-Dataset-for-Complex-Visually-Grounded-Referencing-using-Determiners"><a href="#DetermiNet-A-Large-Scale-Diagnostic-Dataset-for-Complex-Visually-Grounded-Referencing-using-Determiners" class="headerlink" title="DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners"></a>DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03483">http://arxiv.org/abs/2309.03483</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clarence-lee-sheng/determinet">https://github.com/clarence-lee-sheng/determinet</a></li>
<li>paper_authors: Clarence Lee, M Ganesh Kumar, Cheston Tan</li>
<li>for: 这个论文旨在提高视觉引用模型的表现，使其能够更好地 distinguishing 特定对象 versus 总体对象。</li>
<li>methods: 这篇论文使用了250,000个synthetically生成的图像和标题，基于25个determiner来制作了Dataset，任务是预测矩形框，以便识别对象关注的对象。</li>
<li>results: 现有的视觉引用模型在这个Dataset上表现不佳，这反映了现有模型在参照和量化任务上的局限性。<details>
<summary>Abstract</summary>
State-of-the-art visual grounding models can achieve high detection accuracy, but they are not designed to distinguish between all objects versus only certain objects of interest. In natural language, in order to specify a particular object or set of objects of interest, humans use determiners such as "my", "either" and "those". Determiners, as an important word class, are a type of schema in natural language about the reference or quantity of the noun. Existing grounded referencing datasets place much less emphasis on determiners, compared to other word classes such as nouns, verbs and adjectives. This makes it difficult to develop models that understand the full variety and complexity of object referencing. Thus, we have developed and released the DetermiNet dataset , which comprises 250,000 synthetically generated images and captions based on 25 determiners. The task is to predict bounding boxes to identify objects of interest, constrained by the semantics of the given determiner. We find that current state-of-the-art visual grounding models do not perform well on the dataset, highlighting the limitations of existing models on reference and quantification tasks.
</details>
<details>
<summary>摘要</summary>
现代视觉背景模型可以实现高的检测精度，但它们不是设计来分辨所有物体 versus 特定物体的 interests. 在自然语言中，为了指定特定的物体或 интересующий物体，人们使用 determiners such as "my", "either"和 "those"。 determiners 是自然语言中的一种 schema，用于指定名 animate 或 count nouns 的 reference 或 quantity。现有的场景 Referencing 数据集减少了 determiners 的重要性，相比其他单词类型如名动词、动词和形容词。这使得模型难以理解全面和复杂的物体引用。因此，我们开发了并发布了 DetermiNet 数据集，该数据集包括 250,000 个 sintethically 生成的图像和标签，基于 25 个 determiners。任务是预测矩形框，以标识 интересующий物体，受 determiners 的 semantics 约束。我们发现当前状态的最佳视觉背景模型在该数据集上不善于进行，这反映了现有模型在 Reference 和量化任务上的局限性。
</details></li>
</ul>
<hr>
<h2 id="TSI-Net-A-Timing-Sequence-Image-Segmentation-Network-for-Intracranial-Artery-Segmentation-in-Digital-Subtraction-Angiography"><a href="#TSI-Net-A-Timing-Sequence-Image-Segmentation-Network-for-Intracranial-Artery-Segmentation-in-Digital-Subtraction-Angiography" class="headerlink" title="TSI-Net: A Timing Sequence Image Segmentation Network for Intracranial Artery Segmentation in Digital Subtraction Angiography"></a>TSI-Net: A Timing Sequence Image Segmentation Network for Intracranial Artery Segmentation in Digital Subtraction Angiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03477">http://arxiv.org/abs/2309.03477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lemeng Wang, Wentao Liu, Weijin Xu, Haoyuan Li, Huihua Yang, Feng Gao</li>
<li>For:  automatic segmentation of intracranial artery (IA) in digital subtraction angiography (DSA) sequences* Methods:  incorporates a bi-directional ConvGRU module (BCM) in the encoder, which can input variable-length DSA sequences and retain past and future information, and introduces a sensitive detail branch (SDB) at the end for supervising fine vessels* Results:  significantly better than state-of-the-art networks in recent years, with a Sen evaluation metric of 0.797, a 3% improvement compared to other methods.<details>
<summary>Abstract</summary>
Cerebrovascular disease is one of the major diseases facing the world today. Automatic segmentation of intracranial artery (IA) in digital subtraction angiography (DSA) sequences is an important step in the diagnosis of vascular related diseases and in guiding neurointerventional procedures. While, a single image can only show part of the IA within the contrast medium according to the imaging principle of DSA technology. Therefore, 2D DSA segmentation methods are unable to capture the complete IA information and treatment of cerebrovascular diseases. We propose A timing sequence image segmentation network with U-shape, called TSI-Net, which incorporates a bi-directional ConvGRU module (BCM) in the encoder. The network incorporates a bi-directional ConvGRU module (BCM) in the encoder, which can input variable-length DSA sequences, retain past and future information, segment them into 2D images. In addition, we introduce a sensitive detail branch (SDB) at the end for supervising fine vessels. Experimented on the DSA sequence dataset DIAS, the method performs significantly better than state-of-the-art networks in recent years. In particular, it achieves a Sen evaluation metric of 0.797, which is a 3% improvement compared to other methods.
</details>
<details>
<summary>摘要</summary>
脑血管疾病是当今世界面临的一个重要疾病。自动分割整形动脉（IA）在数字抵消成像（DSA）序列中是诊断血管相关疾病和引导神经内部进行手术的重要步骤。然而，单个图像只能显示IA中的一部分，根据DSA技术的成像原理。因此，2D DSA分割方法无法捕捉IA完整的信息，对脑血管疾病的治疗造成限制。我们提出了一种名为TSI-Net的 timing sequence图像分割网络，该网络包含一个bi-directional ConvGRU模块（BCM）在编码器中。该网络可以输入变长的DSA序列，同时保留过去和未来信息，将其分割成2D图像。此外，我们还引入了一个敏感细节分支（SDB），用于监督细血管。在DIAS数据集上进行实验，该方法与当年最佳网络相比，表现出了显著的优势。尤其是，它实现了0.797的Sen评价指标，与其他方法相比，提高了3%。
</details></li>
</ul>
<hr>
<h2 id="Temporal-Collection-and-Distribution-for-Referring-Video-Object-Segmentation"><a href="#Temporal-Collection-and-Distribution-for-Referring-Video-Object-Segmentation" class="headerlink" title="Temporal Collection and Distribution for Referring Video Object Segmentation"></a>Temporal Collection and Distribution for Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03473">http://arxiv.org/abs/2309.03473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiajin Tang, Ge Zheng, Sibei Yang</li>
<li>for: 本研究旨在提高视频对象 segmentation 的精度，通过将自然语言表达与视频帧中对象的动态关系相结合。</li>
<li>methods: 我们提议同时维护全视频水平的 Referent 令和一个序列化的对象提问，其中 Referent 令负责根据语言表达捕捉视频水平的 Referent，而对象提问则用于更好地定位和分割每帧中的对象。此外，我们还提出了一种新的时间集合分布机制，用于在 Referent 令和对象提问之间进行交互。</li>
<li>results: 我们的方法在所有标准测试集上具有显著优势，与现状的方法相比具有更高的精度和更好的一致性。<details>
<summary>Abstract</summary>
Referring video object segmentation aims to segment a referent throughout a video sequence according to a natural language expression. It requires aligning the natural language expression with the objects' motions and their dynamic associations at the global video level but segmenting objects at the frame level. To achieve this goal, we propose to simultaneously maintain a global referent token and a sequence of object queries, where the former is responsible for capturing video-level referent according to the language expression, while the latter serves to better locate and segment objects with each frame. Furthermore, to explicitly capture object motions and spatial-temporal cross-modal reasoning over objects, we propose a novel temporal collection-distribution mechanism for interacting between the global referent token and object queries. Specifically, the temporal collection mechanism collects global information for the referent token from object queries to the temporal motions to the language expression. In turn, the temporal distribution first distributes the referent token to the referent sequence across all frames and then performs efficient cross-frame reasoning between the referent sequence and object queries in every frame. Experimental results show that our method outperforms state-of-the-art methods on all benchmarks consistently and significantly.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化中文。<</SYS>>对于视频对象 segmentation，我们目标是根据自然语言表达在视频序列中Segment a referent。这需要将自然语言表达与对象的运动和它们在全视频水平的动态关系进行对应，并在每帧 уров划分对象。为达到这个目标，我们提议同时维护一个全视频referent token和一个序列化的对象查询，其中前者负责通过语言表达捕捉视频水平的referent，而后者则用于在每帧级划分对象。此外，为了Explicitly capture对象的运动和空间时间跨模态关系，我们提议一种新的时间集合分布机制，用于在全视频referent token和对象查询之间互动。具体来说，时间集合机制在语言表达和对象查询之间收集全视频信息，然后在每帧级分布referent token，并在每帧级进行高效的交互 между referent sequence和对象查询。实验结果表明，我们的方法在所有benchmark上都具有显著优势，并且与之前的状态有所不同。
</details></li>
</ul>
<hr>
<h2 id="Perceptual-Quality-Assessment-of-360-circ-Images-Based-on-Generative-Scanpath-Representation"><a href="#Perceptual-Quality-Assessment-of-360-circ-Images-Based-on-Generative-Scanpath-Representation" class="headerlink" title="Perceptual Quality Assessment of 360$^\circ$ Images Based on Generative Scanpath Representation"></a>Perceptual Quality Assessment of 360$^\circ$ Images Based on Generative Scanpath Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03472">http://arxiv.org/abs/2309.03472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangjiesui/gsr">https://github.com/xiangjiesui/gsr</a></li>
<li>paper_authors: Xiangjie Sui, Hanwei Zhu, Xuelin Liu, Yuming Fang, Shiqi Wang, Zhou Wang</li>
<li>for: 提出了一种基于生成扫描路径表示（GSR）的高效的全息图质量评估方法，以满足人们在不同视图条件下对360度图像的质量评估。</li>
<li>methods: 使用了一种适合扫描路径生成器来生成基于多个假设用户的可见范围和探索时间的扫描路径集，并将这些扫描路径集转化为全息图的唯一GSR，以提高质量评估的准确性。</li>
<li>results: 经过实验 validate了该方法可以具有高度一致性，特别是在局部扭曲的360度图像下，以及在不同视图条件下。<details>
<summary>Abstract</summary>
Despite substantial efforts dedicated to the design of heuristic models for omnidirectional (i.e., 360$^\circ$) image quality assessment (OIQA), a conspicuous gap remains due to the lack of consideration for the diversity of viewing behaviors that leads to the varying perceptual quality of 360$^\circ$ images. Two critical aspects underline this oversight: the neglect of viewing conditions that significantly sway user gaze patterns and the overreliance on a single viewport sequence from the 360$^\circ$ image for quality inference. To address these issues, we introduce a unique generative scanpath representation (GSR) for effective quality inference of 360$^\circ$ images, which aggregates varied perceptual experiences of multi-hypothesis users under a predefined viewing condition. More specifically, given a viewing condition characterized by the starting point of viewing and exploration time, a set of scanpaths consisting of dynamic visual fixations can be produced using an apt scanpath generator. Following this vein, we use the scanpaths to convert the 360$^\circ$ image into the unique GSR, which provides a global overview of gazed-focused contents derived from scanpaths. As such, the quality inference of the 360$^\circ$ image is swiftly transformed to that of GSR. We then propose an efficient OIQA computational framework by learning the quality maps of GSR. Comprehensive experimental results validate that the predictions of the proposed framework are highly consistent with human perception in the spatiotemporal domain, especially in the challenging context of locally distorted 360$^\circ$ images under varied viewing conditions. The code will be released at https://github.com/xiangjieSui/GSR
</details>
<details>
<summary>摘要</summary>
尽管在三Sixty度图像质量评估（OIQA）领域投入了大量努力，但是存在一个明显的缺陷，即视觉行为多样性的不足，导致三Sixty度图像的质量评估不准确。两个关键因素描述这一问题：一是忽略了用户查看行为下的不同条件，二是依靠单个视窗序列来评估图像质量。为解决这些问题，我们提出了一种独特的生成扫描路径表示（GSR），用于有效地评估三Sixty度图像的质量，该表示者将多个假设用户的多种视觉经验进行综合汇总。更具体来说，给定一个视觉条件，包括查看开始点和探索时间，我们可以使用适合的扫描路径生成器生成一系列的扫描路径，包括动态视觉固定点。然后，我们将这些扫描路径转换为唯一的 GSR，该表示者提供了在扫描路径上查看和关注的内容的全局概述。因此，三Sixty度图像的质量评估快速转换为 GSR 的质量评估。我们然后提出了一种高效的 OIQA 计算框架，通过学习 GSR 的质量地图来进行评估。实验结果表明，我们的提议的框架预测与人类视觉在空间时间域的吻合度很高，尤其是在三Sixty度图像下的局部扭曲视觉下的多种视觉条件下。代码将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-Modality-Guidance-Network-For-Missing-Modality-Inference"><a href="#Multi-Modality-Guidance-Network-For-Missing-Modality-Inference" class="headerlink" title="Multi-Modality Guidance Network For Missing Modality Inference"></a>Multi-Modality Guidance Network For Missing Modality Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03452">http://arxiv.org/abs/2309.03452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuokai Zhao, Harish Palani, Tianyi Liu, Lena Evans, Ruth Toner</li>
<li>for: 提高大型系统中多模式处理的可行性</li>
<li>methods: 提案一个引导网络，通过训练时间对多模式表示进行知识共享，以提高单一模式模型的准确性</li>
<li>results: 实际验证显示，提案的框架可以训练单一模式模型，与传统训练方法相比，具有更高的准确性，并且保持相同的推断成本<details>
<summary>Abstract</summary>
Multimodal models have gained significant success in recent years. Standard multimodal approaches often assume unchanged modalities from training stage to inference stage. In practice, however, many scenarios fail to satisfy such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference cost.
</details>
<details>
<summary>摘要</summary>
多模态模型在最近几年内取得了 significiant 成功。标准的多模态方法frequently  assumes 不变的modalities从训练阶段到推理阶段。然而，在实践中，许多场景 Fail to Satisfy  such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference cost.Translated into Simplified Chinese:<<SYS>>多模态模型在最近几年内取得了 significiant 成功。标准的多模态方法frequently  assumes 不变的modalities从训练阶段到推理阶段。然而，在实践中，许多场景 Fail to Satisfy  such assumptions with missing modalities during inference, leading to limitations on where multimodal models can be applied. While existing methods mitigate the problem through reconstructing the missing modalities, it increases unnecessary computational cost, which could be just as critical, especially for large, deployed systems. To solve the problem from both sides, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models for inference. Real-life experiment in violence detection shows that our proposed framework trains single-modality models that significantly outperform its traditionally trained counterparts while maintaining the same inference cost.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Underwater-Image-Enhancement-by-Transformer-based-Diffusion-Model-with-Non-uniform-Sampling-for-Skip-Strategy"><a href="#Underwater-Image-Enhancement-by-Transformer-based-Diffusion-Model-with-Non-uniform-Sampling-for-Skip-Strategy" class="headerlink" title="Underwater Image Enhancement by Transformer-based Diffusion Model with Non-uniform Sampling for Skip Strategy"></a>Underwater Image Enhancement by Transformer-based Diffusion Model with Non-uniform Sampling for Skip Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03445">http://arxiv.org/abs/2309.03445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/piggy2009/dm_underwater">https://github.com/piggy2009/dm_underwater</a></li>
<li>paper_authors: Yi Tang, Takafumi Iwaguchi, Hiroshi Kawasaki</li>
<li>for: 这个论文是为了提出一种基于分布模型的海水下图像提高方法。</li>
<li>methods: 该方法使用了条件杂化滤波模型，将海水下图像和高斯噪声作为输入，生成相应的提高图像。此外，为了提高推理过程中的效率，该方法采用了两种不同的方法：一是使用轻量级的变换器网络，可以提高网络前进一步的时间；二是引入跳样Strategy，可以减少迭代次数。</li>
<li>results: 该方法在 widely 使用的海水下图像提高数据集上进行了相对评估，与现有的方法进行比较。实验结果表明，该方法可以 достичь同等或更高的性能，同时具有高效性。代码可以在 \href{mailto:<a target="_blank" rel="noopener" href="https://github.com/piggy2009/DM_underwater%7D%7B/color%7Bblue%7D%7Bhttps://github.com/piggy2009/DM/_underwater%7D">https://github.com/piggy2009/DM_underwater}{\color{blue}{https://github.com/piggy2009/DM\_underwater}</a> 上获取。<details>
<summary>Abstract</summary>
In this paper, we present an approach to image enhancement with diffusion model in underwater scenes. Our method adapts conditional denoising diffusion probabilistic models to generate the corresponding enhanced images by using the underwater images and the Gaussian noise as the inputs. Additionally, in order to improve the efficiency of the reverse process in the diffusion model, we adopt two different ways. We firstly propose a lightweight transformer-based denoising network, which can effectively promote the time of network forward per iteration. On the other hand, we introduce a skip sampling strategy to reduce the number of iterations. Besides, based on the skip sampling strategy, we propose two different non-uniform sampling methods for the sequence of the time step, namely piecewise sampling and searching with the evolutionary algorithm. Both of them are effective and can further improve performance by using the same steps against the previous uniform sampling. In the end, we conduct a relative evaluation of the widely used underwater enhancement datasets between the recent state-of-the-art methods and the proposed approach. The experimental results prove that our approach can achieve both competitive performance and high efficiency. Our code is available at \href{mailto:https://github.com/piggy2009/DM_underwater}{\color{blue}{https://github.com/piggy2009/DM\_underwater}.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种图像提升方法基于扩散模型在水下场景中。我们的方法利用条件抑制扩散概率模型，将水下图像和高斯噪声作为输入，生成相应的提升图像。此外，为了提高扩散模型的反向过程效率，我们采用了两种不同的方法。一是使用轻量级的变换器基于抑制网络，可以有效提高网络前进一步的时间。另一方面，我们引入了跳过采样策略，以减少迭代数。此外，基于跳过采样策略，我们还提出了两种非均匀采样方法，即分割采样和搜索采样。它们都能够有效地提高性能，并且可以使用同样的步长对抗前一个均匀采样。最后，我们对水下图像提升数据集进行了相对评估，并与当前状态艺术方法进行了比较。实验结果表明，我们的方法可以实现高效和竞争力强的图像提升。我们的代码可以在 \href{mailto:https://github.com/piggy2009/DM_underwater}{\color{blue}{https://github.com/piggy2009/DM\_underwater} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Punctate-White-Matter-Lesion-Segmentation-in-Preterm-Infants-Powered-by-Counterfactually-Generative-Learning"><a href="#Punctate-White-Matter-Lesion-Segmentation-in-Preterm-Infants-Powered-by-Counterfactually-Generative-Learning" class="headerlink" title="Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning"></a>Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03440">http://arxiv.org/abs/2309.03440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zehua Ren, Yongheng Sun, Miaomiao Wang, Yuying Feng, Xianjun Li, Chao Jin, Jian Yang, Chunfeng Lian, Fan Wang</li>
<li>for: 这个研究旨在提高脑瘫癫病变的准确分类，以便在疗法时间上获得早期诊断和治疗。</li>
<li>methods: 这个研究使用了对抗事实的思维和脑组织分类的副 задачу，以学习细部位置和形态的描述，从而提高了精确的脑瘫癫病变分类。</li>
<li>results: 这个研究使用了一个简单和易于实现的深度学习框架（即DeepPWML），融合了病变对抗地图和组织可能性地图，对于实际临床数据集的脑瘫癫病变分类表现出了国际顶尖的性能。<details>
<summary>Abstract</summary>
Accurate segmentation of punctate white matter lesions (PWMLs) are fundamental for the timely diagnosis and treatment of related developmental disorders. Automated PWMLs segmentation from infant brain MR images is challenging, considering that the lesions are typically small and low-contrast, and the number of lesions may dramatically change across subjects. Existing learning-based methods directly apply general network architectures to this challenging task, which may fail to capture detailed positional information of PWMLs, potentially leading to severe under-segmentations. In this paper, we propose to leverage the idea of counterfactual reasoning coupled with the auxiliary task of brain tissue segmentation to learn fine-grained positional and morphological representations of PWMLs for accurate localization and segmentation. A simple and easy-to-implement deep-learning framework (i.e., DeepPWML) is accordingly designed. It combines the lesion counterfactual map with the tissue probability map to train a lightweight PWML segmentation network, demonstrating state-of-the-art performance on a real-clinical dataset of infant T1w MR images. The code is available at \href{https://github.com/ladderlab-xjtu/DeepPWML}{https://github.com/ladderlab-xjtu/DeepPWML}.
</details>
<details>
<summary>摘要</summary>
精准 segmentation of punctate white matter lesions (PWMLs) 是诊断和治疗相关的发育障碍的基本步骤。自动从婴儿脑MR图像中提取PWMLs的自动化 segmentation 是一项挑战，因为lesions 通常很小并且对比度很低，同时Subject中lesions的数量可能会差异很大。现有的学习基本方法直接将通用网络架构应用到这个任务上，可能会miss detailed positional information of PWMLs，导致严重的下segmentation。在这篇论文中，我们提出使用counterfactual reasoning 和辅助任务脑组织 segmentation来学习PWMLs的细致位姿和形态表示，以实现精准的localization和segmentation。我们设计了一个简单易用的深度学习框架（i.e., DeepPWML），该框架结合lesion counterfactual map 和组织概率地图来训练一个轻量级PWML segmentation网络，并在实际临床数据上达到了现状前的性能。代码可以在 \href{https://github.com/ladderlab-xjtu/DeepPWML}{https://github.com/ladderlab-xjtu/DeepPWML} 中获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/cs.CV_2023_09_07/" data-id="closbrooq00hy0g887p4w6ekx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/cs.AI_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T12:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/cs.AI_2023_09_07/">cs.AI - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Evaluation-of-large-language-models-for-discovery-of-gene-set-function"><a href="#Evaluation-of-large-language-models-for-discovery-of-gene-set-function" class="headerlink" title="Evaluation of large language models for discovery of gene set function"></a>Evaluation of large language models for discovery of gene set function</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04019">http://arxiv.org/abs/2309.04019</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idekerlab/llm_evaluation_for_gene_set_interpretation">https://github.com/idekerlab/llm_evaluation_for_gene_set_interpretation</a></li>
<li>paper_authors: Mengzhou Hu, Sahar Alkhairy, Ingoo Lee, Rudolf T. Pillich, Robin Bachelder, Trey Ideker, Dexter Pratt</li>
<li>for: 这 paper 旨在评估 OpenAI 的 GPT-4 是否可以从嵌入的生物医学知识中提取共同的基因函数理论。</li>
<li>methods: 作者使用 GPT-4  pipeline 将基因集标记为概括其共谊功能的名称，并提供分析文本和参考文献支持。</li>
<li>results: GPT-4 在 Gene Ontology 中提供的名称与实际名称相似，并在 ‘omics 数据中提供了更加详细的基因集名称，并且支持语句和参考文献几乎全部得到了人工审查的 verify。<details>
<summary>Abstract</summary>
Gene set analysis is a mainstay of functional genomics, but it relies on manually curated databases of gene functions that are incomplete and unaware of biological context. Here we evaluate the ability of OpenAI's GPT-4, a Large Language Model (LLM), to develop hypotheses about common gene functions from its embedded biomedical knowledge. We created a GPT-4 pipeline to label gene sets with names that summarize their consensus functions, substantiated by analysis text and citations. Benchmarking against named gene sets in the Gene Ontology, GPT-4 generated very similar names in 50% of cases, while in most remaining cases it recovered the name of a more general concept. In gene sets discovered in 'omics data, GPT-4 names were more informative than gene set enrichment, with supporting statements and citations that largely verified in human review. The ability to rapidly synthesize common gene functions positions LLMs as valuable functional genomics assistants.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ConDA-Contrastive-Domain-Adaptation-for-AI-generated-Text-Detection"><a href="#ConDA-Contrastive-Domain-Adaptation-for-AI-generated-Text-Detection" class="headerlink" title="ConDA: Contrastive Domain Adaptation for AI-generated Text Detection"></a>ConDA: Contrastive Domain Adaptation for AI-generated Text Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03992">http://arxiv.org/abs/2309.03992</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amritabh/conda-gen-text-detection">https://github.com/amritabh/conda-gen-text-detection</a></li>
<li>paper_authors: Amrita Bhattacharjee, Tharindu Kumarage, Raha Moraffah, Huan Liu</li>
<li>for: 这篇论文旨在建立一个不需要标注训练数据的人工智能生成文本检测器，以应对伪信息的散播。</li>
<li>methods: 本文使用了一种叫做对比领域适应（ConDA）的框架，它结合了标准的领域适应技术和对比学习的表现力，从不标注目标资料中学习对应的领域不变表示，以便进行最终的无标注检测任务。</li>
<li>results: 实验结果显示，使用ConDA框架可以从最好的基eline中获得31.7%的性能提升，并且与全标注检测器之间的差距在0.8%之内。所有的代码和数据可以在<a target="_blank" rel="noopener" href="https://github.com/AmritaBh/ConDA-gen-text-detection%E4%B8%8A%E5%8F%96%E5%BE%97%E3%80%82">https://github.com/AmritaBh/ConDA-gen-text-detection上取得。</a><details>
<summary>Abstract</summary>
Large language models (LLMs) are increasingly being used for generating text in a variety of use cases, including journalistic news articles. Given the potential malicious nature in which these LLMs can be used to generate disinformation at scale, it is important to build effective detectors for such AI-generated text. Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck. However, there might be plenty of unlabeled text data available, without information on which generator it came from. In this work we tackle this data problem, in detecting AI-generated news text, and frame the problem as an unsupervised domain adaptation task. Here the domains are the different text generators, i.e. LLMs, and we assume we have access to only the labeled source data and unlabeled target data. We develop a Contrastive Domain Adaptation framework, called ConDA, that blends standard domain adaptation techniques with the representation power of contrastive learning to learn domain invariant representations that are effective for the final unsupervised detection task. Our experiments demonstrate the effectiveness of our framework, resulting in average performance gains of 31.7% from the best performing baselines, and within 0.8% margin of a fully supervised detector. All our code and data is available at https://github.com/AmritaBh/ConDA-gen-text-detection.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Noisy-Computing-of-the-mathsf-OR-and-mathsf-MAX-Functions"><a href="#Noisy-Computing-of-the-mathsf-OR-and-mathsf-MAX-Functions" class="headerlink" title="Noisy Computing of the $\mathsf{OR}$ and $\mathsf{MAX}$ Functions"></a>Noisy Computing of the $\mathsf{OR}$ and $\mathsf{MAX}$ Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03986">http://arxiv.org/abs/2309.03986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Banghua Zhu, Ziao Wang, Nadim Ghaddar, Jiantao Jiao, Lele Wang</li>
<li>For: The paper is written for computing a function of $n$ variables using noisy queries, where each query is incorrect with some fixed and known probability $p \in (0,1&#x2F;2)$.* Methods: The paper uses noisy queries to compute the $\mathsf{OR}$ function of $n$ bits and the $\mathsf{MAX}$ function of $n$ real numbers, with an expected number of queries of $(1 \pm o(1)) \frac{n\log \frac{1}{\delta}{D_{\mathsf{KL}(p | 1-p)}$.* Results: The paper shows that this expected number of queries is both sufficient and necessary to compute both functions with a vanishing error probability $\delta &#x3D; o(1)$, and tightens the dependence on $p$ in both the upper and lower bounds for the two functions.<details>
<summary>Abstract</summary>
We consider the problem of computing a function of $n$ variables using noisy queries, where each query is incorrect with some fixed and known probability $p \in (0,1/2)$. Specifically, we consider the computation of the $\mathsf{OR}$ function of $n$ bits (where queries correspond to noisy readings of the bits) and the $\mathsf{MAX}$ function of $n$ real numbers (where queries correspond to noisy pairwise comparisons). We show that an expected number of queries of \[ (1 \pm o(1)) \frac{n\log \frac{1}{\delta}{D_{\mathsf{KL}(p \| 1-p)} \] is both sufficient and necessary to compute both functions with a vanishing error probability $\delta = o(1)$, where $D_{\mathsf{KL}(p \| 1-p)$ denotes the Kullback-Leibler divergence between $\mathsf{Bern}(p)$ and $\mathsf{Bern}(1-p)$ distributions. Compared to previous work, our results tighten the dependence on $p$ in both the upper and lower bounds for the two functions.
</details>
<details>
<summary>摘要</summary>
我们考虑一个函数计算问题，其中有 $n$ 变量，每个变量的误差概率为 $p \in (0,1/2)$。我们考虑了计算 $\mathsf{OR}$ 函数和 $\mathsf{MAX}$ 函数的问题，其中每个变量的误差概率都是 $p$。我们显示出，需要 $\left(1 \pm o(1)\right) \frac{n \log \frac{1}{\delta}{D_{\mathsf{KL}(p \| 1-p)}$ 个查询，以达到误差概率 $\delta = o(1)$ 下降到零。这个结果比前一个研究更加紧凑，并且在上下限中都紧紧地依赖于 $p$。Here's the breakdown of the translation:* 我们考虑 (we consider)* 一个函数计算问题 (a function computation problem)* 其中有 $n$ 变量 (where there are $n$ variables)* 每个变量的误差概率为 $p$ (each variable has an error probability of $p$)* 我们考虑了计算 $\mathsf{OR}$ 函数和 $\mathsf{MAX}$ 函数的问题 (we consider the problem of computing the $\mathsf{OR}$ function and the $\mathsf{MAX}$ function)* 其中每个变量的误差概率都是 $p$ (where each variable has an error probability of $p$)* 我们显示出 (we show)* 需要 $\left(1 \pm o(1)\right) \frac{n \log \frac{1}{\delta}{D_{\mathsf{KL}(p \| 1-p)}$ 个查询 (need $\left(1 \pm o(1)\right) \frac{n \log \frac{1}{\delta}{D_{\mathsf{KL}(p \| 1-p)}$ queries)* 以达到误差概率 $\delta = o(1)$ 下降到零 (to reduce the error probability to zero)* 这个结果比前一个研究更加紧凑 (this result is tighter than previous studies)* 并且在上下限中都紧紧地依赖于 $p$ (and is tight in both the upper and lower bounds for $p$)
</details></li>
</ul>
<hr>
<h2 id="DiffusionEngine-Diffusion-Model-is-Scalable-Data-Engine-for-Object-Detection"><a href="#DiffusionEngine-Diffusion-Model-is-Scalable-Data-Engine-for-Object-Detection" class="headerlink" title="DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection"></a>DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03893">http://arxiv.org/abs/2309.03893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manlin Zhang, Jie Wu, Yuxi Ren, Ming Li, Jie Qin, Xuefeng Xiao, Wei Liu, Rui Wang, Min Zheng, Andy J. Ma</li>
<li>for: 这篇论文的目的是为了提出一个可扩展的数据引擎，以便实现物件探测中的训练。</li>
<li>methods: 这篇论文使用了一个名为DiffusionEngine的数据扩展引擎，该引擎包括一个预训练的数据模型和一个有效的探测适配器。这些元件可以在单一的过程中生成大量、多样化和可重复的探测训练 pairs。</li>
<li>results: 实验结果显示，这篇论文提出的DiffusionEngine可以在多种情况下取得显著的改善，例如不同的探测算法、自我指导预训练、数据缺乏、标签缺乏、跨领域和半指导学习等。例如，使用DiffusionEngine和DINO-based适配器将数据扩展，则在COCO、VOC和Clipart上的mAP分别提高了3.1%、7.6%和11.5%。<details>
<summary>Abstract</summary>
Data is the cornerstone of deep learning. This paper reveals that the recently developed Diffusion Model is a scalable data engine for object detection. Existing methods for scaling up detection-oriented data often require manual collection or generative models to obtain target images, followed by data augmentation and labeling to produce training pairs, which are costly, complex, or lacking diversity. To address these issues, we presentDiffusionEngine (DE), a data scaling-up engine that provides high-quality detection-oriented training pairs in a single stage. DE consists of a pre-trained diffusion model and an effective Detection-Adapter, contributing to generating scalable, diverse and generalizable detection data in a plug-and-play manner. Detection-Adapter is learned to align the implicit semantic and location knowledge in off-the-shelf diffusion models with detection-aware signals to make better bounding-box predictions. Additionally, we contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing detection benchmarks for facilitating follow-up research. Extensive experiments demonstrate that data scaling-up via DE can achieve significant improvements in diverse scenarios, such as various detection algorithms, self-supervised pre-training, data-sparse, label-scarce, cross-domain, and semi-supervised learning. For example, when using DE with a DINO-based adapter to scale up data, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.
</details>
<details>
<summary>摘要</summary>
“数据是深度学习的基础。这篇论文揭示了最近开发的扩散模型是一种可扩展的数据引擎 для物体检测。现有的方法 для扩大检测引导的数据经常需要手动收集或生成模型来获取目标图像，然后进行数据扩展和标注来生成训练对，这些过程昂贵、复杂或缺乏多样性。为解决这些问题，我们提出了DiffusionEngine（DE），一种可扩展的数据扩大引擎。DE包括一个预训练的扩散模型和一个有效的检测适配器，它可以在一个插入式的方式下生成高质量的检测引导数据。检测适配器是通过将偏振的含义和位置知识从存储在各种扩散模型中的含义和位置知识与检测意图相匹配，以提高矩形框预测的准确性。此外，我们还提供了COCO-DE和VOC-DE两个数据集，以扩大现有的检测benchmark，便于后续研究。广泛的实验表明，通过DE进行数据扩大可以在多种场景下实现显著的提升，包括不同的检测算法、自我主导的预训练、数据稀缺、标注缺乏、跨Domain、和半supervised学习。例如，当使用DE和DINO基于的适配器来扩大数据时，COCO上的mAP提高3.1%，VOC上提高7.6%，Clipart上提高11.5%。”
</details></li>
</ul>
<hr>
<h2 id="A-Function-Interpretation-Benchmark-for-Evaluating-Interpretability-Methods"><a href="#A-Function-Interpretation-Benchmark-for-Evaluating-Interpretability-Methods" class="headerlink" title="A Function Interpretation Benchmark for Evaluating Interpretability Methods"></a>A Function Interpretation Benchmark for Evaluating Interpretability Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03886">http://arxiv.org/abs/2309.03886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/multimodal-interpretability/find">https://github.com/multimodal-interpretability/find</a></li>
<li>paper_authors: Sarah Schwettmann, Tamar Rott Shaham, Joanna Materzynska, Neil Chowdhury, Shuang Li, Jacob Andreas, David Bau, Antonio Torralba</li>
<li>for: 这 paper 的目的是为了评估自动化解释方法的性能。</li>
<li>methods: 这 paper 使用了语言模型（LM）来生成代码和文本描述函数行为。</li>
<li>results: 研究发现，使用黑盒访问函数的LM可以做出一些科学家的推测和实验，但是它们通常只能捕捉全局函数行为，而不是地方腐化。这些结果表明，FIND 可以用于评估更复杂的解释方法的性能，以前置应用于实际模型。<details>
<summary>Abstract</summary>
Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors. To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor. Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically. Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc. How should we validate and compare open-ended labeling tools? This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks, and accompanying descriptions of the kind we seek to generate. The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias. We evaluate new and existing methods that use language models (LMs) to produce code-based and language descriptions of function behavior. We find that an off-the-shelf LM augmented with only black-box access to functions can sometimes infer their structure, acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data. However, LM-based descriptions tend to capture global function behavior and miss local corruptions. These results show that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models.
</details>
<details>
<summary>摘要</summary>
Labeling neural network submodules with human-legible descriptions是有用的downstream任务：这些描述可以暴露失败，导引 intervención，并可能 même explain important model behaviors。到目前为止，大多数机制性描述已经只是用小型模型、窄化的现象和大量的人工劳动。将所有人类可读的子计算机制 INTO models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically。Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc。How should we validate and compare open-ended labeling tools？This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods。FIND contains functions that resemble components of trained neural networks, and accompanying descriptions of the kind we seek to generate。The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias。We evaluate new and existing methods that use language models (LMs) to produce code-based and language descriptions of function behavior。We find that an off-the-shelf LM augmented with only black-box access to functions can sometimes infer their structure, acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data。However, LM-based descriptions tend to capture global function behavior and miss local corruptions。These results show that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models。
</details></li>
</ul>
<hr>
<h2 id="DoLa-Decoding-by-Contrasting-Layers-Improves-Factuality-in-Large-Language-Models"><a href="#DoLa-Decoding-by-Contrasting-Layers-Improves-Factuality-in-Large-Language-Models" class="headerlink" title="DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"></a>DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03883">http://arxiv.org/abs/2309.03883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/voidism/dola">https://github.com/voidism/dola</a></li>
<li>paper_authors: Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James Glass, Pengcheng He</li>
<li>for: 减少大语言模型（LLMs）的幻觉，即生成不符事实的内容。</li>
<li>methods: 提出了一种简单的解oding策略，不需要conditioning retrieved external knowledge nor additional fine-tuning，可以更好地浮现LLMs中的事实知识。</li>
<li>results: 对多个选择任务和开放式生成任务进行了改进，如提高了LLaMA家族模型在TruthfulQA任务的性能，提高约12-17%绝对点数。<details>
<summary>Abstract</summary>
Despite their impressive capabilities, large language models (LLMs) are prone to hallucinations, i.e., generating content that deviates from facts seen during pretraining. We propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning. Our approach obtains the next-token distribution by contrasting the differences in logits obtained from projecting the later layers versus earlier layers to the vocabulary space, exploiting the fact that factual knowledge in an LLMs has generally been shown to be localized to particular transformer layers. We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.
</details>
<details>
<summary>摘要</summary>
尽管它们具有印象的能力，大语言模型（LLM）仍然容易出现幻觉，即生成不符事实的内容。我们提议一种简单的解码策略可以减少LLM中的幻觉，不需要基于检索到的外部知识 nor 额外调整。我们的方法通过对 later层和earlier层的投影到 vocabulary space 进行对比，利用了 LLM 中的事实具有局部化特征。我们称之为 Decoding by Contrasting Layers（DoLa）方法。我们发现 DoLa 方法可以更好地把 фактиче知识浮现出来，降低生成错误的事实。DoLa 方法在多个选择任务和开放式生成任务中表现出色，例如提高了 LLaMA 家族模型在 TruthfulQA 中的表现，提高了 truthfulness 的表现约 12-17% 绝对点数，这表明 DoLa 方法可以使 LLM 可靠地生成真实的事实。
</details></li>
</ul>
<hr>
<h2 id="OpinionGPT-Modelling-Explicit-Biases-in-Instruction-Tuned-LLMs"><a href="#OpinionGPT-Modelling-Explicit-Biases-in-Instruction-Tuned-LLMs" class="headerlink" title="OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs"></a>OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03876">http://arxiv.org/abs/2309.03876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Haller, Ansar Aynetdinov, Alan Akbik</li>
<li>for: 这个论文的目的是为了使人们可以通过查看具有不同偏见的答案来了解语言模型中的偏见。</li>
<li>methods: 这个论文使用了特定偏见的文本数据来训练模型，然后通过在用户选择的偏见下提供答案来展示这些偏见。</li>
<li>results: 这个论文的结果是一个名为OpinionGPT的在线示例，可以让用户问题并选择想要调查的偏见，然后模型将根据这些偏见提供答案，从而使用户可以对偏见进行互动和比较。<details>
<summary>Abstract</summary>
Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable ability to generate fitting responses to natural language instructions. However, an open research question concerns the inherent biases of trained models and their responses. For instance, if the data used to tune an LLM is dominantly written by persons with a specific political bias, we might expect generated answers to share this bias. Current research work seeks to de-bias such models, or suppress potentially biased answers. With this demonstration, we take a different view on biases in instruction-tuning: Rather than aiming to suppress them, we aim to make them explicit and transparent. To this end, we present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, we identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. This paper presents OpinionGPT, illustrates how we trained the bias-aware model and showcases the web application (available at https://opiniongpt.informatik.hu-berlin.de).
</details>
<details>
<summary>摘要</summary>
很近期， instruction-tuned 大型自然语言模型（LLM）已经展现出了remarkable的适应能力，可以生成适应natural language instruction的回答。然而，一个打开的研究问题是训练模型内置的偏见。例如，如果用于训练 LLM 的数据主要由特定政治偏见的人员写成，那么生成的答案可能会带有这种偏见。现有的研究工作是想要减少或抑制这些偏见的模型。在这个示例中，我们采取了一种不同的视角，即不是减少偏见，而是使它们显示出来，并让用户可以选择想要调查的偏见。为此，我们提出了 OpinionGPT，一个网上示例，用户可以在这里提问问题，并选择想要调查的偏见。示例中的答案将使用基于每种选择的偏见进行模型细化，进行侧重比较。为了训练底层模型，我们identified 11种偏见（政治、地理、性别、年龄），并 derivated一个 instrucion-tuning 训练集，每个答案都是由不同的民族成员写成。这篇论文介绍了 OpinionGPT，详细介绍了我们如何训练偏见意识的模型，并展示了网上应用程序（可以在https://opiniongpt.informatik.hu-berlin.de 中查看）。
</details></li>
</ul>
<hr>
<h2 id="FLM-101B-An-Open-LLM-and-How-to-Train-It-with-100K-Budget"><a href="#FLM-101B-An-Open-LLM-and-How-to-Train-It-with-100K-Budget" class="headerlink" title="FLM-101B: An Open LLM and How to Train It with $100K Budget"></a>FLM-101B: An Open LLM and How to Train It with $100K Budget</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03852">http://arxiv.org/abs/2309.03852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Yiqun Yao, Xin Jiang, Xuezhi Fang, Xuying Meng, Siqi Fan, Peng Han, Jing Li, Li Du, Bowen Qin, Zheng Zhang, Aixin Sun, Yequan Wang</li>
<li>for: 这篇论文目标是提出一种减少大语言模型（LLM）训练成本的解决方案，并通过实验证明其效果。</li>
<li>methods: 该论文使用了一种增长策略来减少LLM训练成本，并在其基础上进行了一系列的IQ评价。</li>
<li>results: 实验结果显示，使用该增长策略训练的FLM-101B模型，可以与其他 poderful 和具有名声的模型相比，尤其是在IQ评价中表现出色。<details>
<summary>Abstract</summary>
Large language models (LLMs) have achieved remarkable success in NLP and multimodal tasks, among others. Despite these successes, two main challenges remain in developing LLMs: (i) high computational cost, and (ii) fair and objective evaluations. In this paper, we report a solution to significantly reduce LLM training cost through a growth strategy. We demonstrate that a 101B-parameter LLM with 0.31T tokens can be trained with a budget of 100K US dollars. Inspired by IQ tests, we also consolidate an additional range of evaluations on top of existing evaluations that focus on knowledge-oriented abilities. These IQ evaluations include symbolic mapping, rule understanding, pattern mining, and anti-interference. Such evaluations minimize the potential impact of memorization. Experimental results show that our model, named FLM-101B, trained with a budget of 100K US dollars, achieves performance comparable to powerful and well-known models, e.g., GPT-3 and GLM-130B, especially on the additional range of IQ evaluations. The checkpoint of FLM-101B is released at https://huggingface.co/CofeAI/FLM-101B.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在自然语言处理和多模态任务中备受推崇，其中两大挑战是：（一）高计算成本，（二）公正和 объектив的评估。本文报道了一种减少 LLM 训练成本的解决方案，我们示示了一个 101B 参数的 LLM 可以在 100K 美元预算下训练。受智商测试的 inspiration，我们还添加了一些以知识为导向的评估方法，包括符号映射、规则理解、模式挖掘和抗干扰。这些评估方法减少了可能的记忆效应。实验结果表明，我们名为 FLM-101B 的模型，训练预算为 100K 美元，与知名的 GPT-3 和 GLM-130B 模型相当，尤其是在其他评估方法上。FLM-101B 的检查点可以在 <https://huggingface.co/CofeAI/FLM-101B> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Uncovering-Drift-in-Textual-Data-An-Unsupervised-Method-for-Detecting-and-Mitigating-Drift-in-Machine-Learning-Models"><a href="#Uncovering-Drift-in-Textual-Data-An-Unsupervised-Method-for-Detecting-and-Mitigating-Drift-in-Machine-Learning-Models" class="headerlink" title="Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models"></a>Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03831">http://arxiv.org/abs/2309.03831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeed Khaki, Akhouri Abhinav Aditya, Zohar Karnin, Lan Ma, Olivia Pan, Samarth Marudheri Chandrashekar</li>
<li>For: 本研究旨在提出一种不需要人工标注的自动检测方法，以便在机器学习模型性能下降时提前发现和修复问题。* Methods: 我们采用了一种两步方法。第一步是将生产数据编码为目标分布，模型训练数据编码为参照分布。第二步是使用核函数基于最大均值差距（MMD）距离度量，比较参照和目标分布之间的差异，并估计任何可能的漂移。* Results: 我们的方法可以快速和准确地检测到生产数据中的漂移，并且可以识别出导致漂移的子集。 retrained 使用这些标识的高漂移样本表示在线客户体验质量指标上显著改善。<details>
<summary>Abstract</summary>
Drift in machine learning refers to the phenomenon where the statistical properties of data or context, in which the model operates, change over time leading to a decrease in its performance. Therefore, maintaining a constant monitoring process for machine learning model performance is crucial in order to proactively prevent any potential performance regression. However, supervised drift detection methods require human annotation and consequently lead to a longer time to detect and mitigate the drift. In our proposed unsupervised drift detection method, we follow a two step process. Our first step involves encoding a sample of production data as the target distribution, and the model training data as the reference distribution. In the second step, we employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift. Our method also identifies the subset of production data that is the root cause of the drift. The models retrained using these identified high drift samples show improved performance on online customer experience quality metrics.
</details>
<details>
<summary>摘要</summary>
In our proposed unsupervised drift detection method, we follow a two-step process:Step 1: Encode a sample of production data as the target distribution, and the model training data as the reference distribution.Step 2: Employ a kernel-based statistical test that utilizes the maximum mean discrepancy (MMD) distance metric to compare the reference and target distributions and estimate any potential drift.Our method also identifies the subset of production data that is the root cause of the drift. By retraining the models using these identified high drift samples, we observe improved performance on online customer experience quality metrics.
</details></li>
</ul>
<hr>
<h2 id="Training-Acceleration-of-Low-Rank-Decomposed-Networks-using-Sequential-Freezing-and-Rank-Quantization"><a href="#Training-Acceleration-of-Low-Rank-Decomposed-Networks-using-Sequential-Freezing-and-Rank-Quantization" class="headerlink" title="Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization"></a>Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03824">http://arxiv.org/abs/2309.03824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Habib Hajimolahoseini, Walid Ahmed, Yang Liu</li>
<li>for: 提高深度学习模型的训练和执行速度，而不需要采用小rank的约化</li>
<li>methods: 提出了两种加速低约数据模型的技术，包括约化优化和顺序冻结分解层</li>
<li>results: 实验表明，这两种技术可以在训练和执行过程中提高模型的吞吐量，最高可达60%和37%，同时保持模型的准确率与原始模型接近<details>
<summary>Abstract</summary>
Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60% during training and 37% during inference when combined together while preserving the accuracy close to that of the original models
</details>
<details>
<summary>摘要</summary>
低阶划分（LRD）是一种深度学习模型压缩技术，用于减少训练参数数量和计算复杂性。然而，由于LRD后加入的新层数量增加，可能无法导致高训练/推理加速，特别是使用小极值推理可能会导致准确性下降。在这篇论文中，我们提出了两种加速LRD模型无需使用小极值划分的技术。这些方法包括排序优化和顺序冻结分解层。我们在 convolutional 和 transformer 基于模型上进行了实验，实验结果表明，这些技术可以在训练和推理过程中提高模型吞吐量，最高可达 60%，并保持准确性接近原始模型。
</details></li>
</ul>
<hr>
<h2 id="AnthroNet-Conditional-Generation-of-Humans-via-Anthropometrics"><a href="#AnthroNet-Conditional-Generation-of-Humans-via-Anthropometrics" class="headerlink" title="AnthroNet: Conditional Generation of Humans via Anthropometrics"></a>AnthroNet: Conditional Generation of Humans via Anthropometrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03812">http://arxiv.org/abs/2309.03812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Unity-Technologies/AnthroNet">https://github.com/Unity-Technologies/AnthroNet</a></li>
<li>paper_authors: Francesco Picetti, Shrinath Deshpande, Jonathan Leban, Soroosh Shahtalebi, Jay Patel, Peifeng Jing, Chunpu Wang, Charles Metze III, Cameron Sun, Cera Laidlaw, James Warren, Kathy Huynh, River Page, Jonathan Hogins, Adam Crespi, Sujoy Ganguly, Salehe Erfanian Ebadi</li>
<li>for: The paper is written for the purpose of presenting a novel human body model that can generate a wide range of human body shapes and poses.</li>
<li>methods: The paper uses a deep generative architecture to train the model end-to-end using only synthetically generated data, which provides highly accurate human mesh representations and allows for precise anthropometry of the body.</li>
<li>results: The model is capable of producing humans in any arbitrary pose and can be used to generate millions of unique human identities and poses for non-commercial academic research purposes.Here is the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为了介绍一种新的人体模型，可以生成各种人体形态和姿势。</li>
<li>methods: 这篇论文使用深度生成架构来直接训练模型，只使用人工生成的数据进行训练，可以提供高度准确的人体三维模型和人体测量数据。</li>
<li>results: 模型可以生成任意姿势的人体，并且可以生成数百万个唯一的人体标示和姿势。<details>
<summary>Abstract</summary>
We present a novel human body model formulated by an extensive set of anthropocentric measurements, which is capable of generating a wide range of human body shapes and poses. The proposed model enables direct modeling of specific human identities through a deep generative architecture, which can produce humans in any arbitrary pose. It is the first of its kind to have been trained end-to-end using only synthetically generated data, which not only provides highly accurate human mesh representations but also allows for precise anthropometry of the body. Moreover, using a highly diverse animation library, we articulated our synthetic humans' body and hands to maximize the diversity of the learnable priors for model training. Our model was trained on a dataset of $100k$ procedurally-generated posed human meshes and their corresponding anthropometric measurements. Our synthetic data generator can be used to generate millions of unique human identities and poses for non-commercial academic research purposes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的人体模型，基于广泛的人体中心量测量，可以生成广泛的人体形态和姿势。我们的模型可以直接模拟特定的人类特征，通过深度生成架构来生成任意姿势的人类。这是首次使用只有生成的数据进行端到端训练的人体模型，不仅提供了高度准确的人体网格表示，还允许精确的人体 anthropometry 测量。此外，我们使用了高度多样化的动画库，将我们的 sintetic humans 的身体和手部动作塑造得更加多样化，以最大化学习 prior 的多样性。我们的模型在一个包含 100k 个生成的姿势人体网格和其对应的人体测量数据集上进行了训练。我们的 sintetic 数据生成器可以生成数百万个独特的人体形态和姿势，用于非商业学术研究 purposes。
</details></li>
</ul>
<hr>
<h2 id="Pareto-Frontiers-in-Neural-Feature-Learning-Data-Compute-Width-and-Luck"><a href="#Pareto-Frontiers-in-Neural-Feature-Learning-Data-Compute-Width-and-Luck" class="headerlink" title="Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck"></a>Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03800">http://arxiv.org/abs/2309.03800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin L. Edelman, Surbhi Goel, Sham Kakade, Eran Malach, Cyril Zhang</li>
<li>for: 这项研究探讨了深度学习中计算统计差距的细化算法设计选择。</li>
<li>methods: 本文考虑了离线稀疏偏好学习，这是一种超参数分类问题，具有一个统计查询下界，可以用来训练一个多层感知机。这个下界可以看作多种资源交易前ier：成功学习只能在一个具有足够财富（大型模型）、知识（大量数据）、耐心（多个训练轮次）或幸运（多个随机猜测）的情况下进行。</li>
<li>results: 我们通过理论和实验来证明，在这种设定下，稀疏初始化和增加网络宽度可以实现显著的样本效率提高。在这里，宽度扮演着平行搜索的角色：它增加了找到”彩礼奖”神经元的概率，这些神经元更加 sample-efficiently 学习稀疏特征。此外，我们还证明了使用宽、稀疏初始化的 MLP 模型可以在标准表格分类benchmark上实现更好的样本效率，这些网络在一些情况下even outperform了调参随机森林。<details>
<summary>Abstract</summary>
This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real problems requiring axis-aligned feature learning. We demonstrate improved sample efficiency on tabular classification benchmarks by using wide, sparsely-initialized MLP models; these networks sometimes outperform tuned random forests.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FisheyePP4AV-A-privacy-preserving-method-for-autonomous-vehicles-on-fisheye-camera-images"><a href="#FisheyePP4AV-A-privacy-preserving-method-for-autonomous-vehicles-on-fisheye-camera-images" class="headerlink" title="FisheyePP4AV: A privacy-preserving method for autonomous vehicles on fisheye camera images"></a>FisheyePP4AV: A privacy-preserving method for autonomous vehicles on fisheye camera images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03799">http://arxiv.org/abs/2309.03799</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linh Trinh, Bach Ha, Tu Tran</li>
<li>for: 保护自驾车摄像头拍摄的人脸和车牌号 Privacy Concerns in Autonomous Driving</li>
<li>methods: 提出了一种基于多种教师模型的面和车牌号识别框架，并使用变化和现实的 fisheye 变换将图像和标签转换为 fisheye-like 数据</li>
<li>results: 对于使用自驾车摄像头拍摄的 PP4AV  dataset，我们的模型比基eline方法高效，即使数据被软标签Here’s a breakdown of each point:1. for: The paper is focused on addressing privacy concerns in autonomous driving by protecting pedestrian faces and nearby car license plates in actual road-driving scenarios.2. methods: The proposed method uses a framework for extracting face and plate identification knowledge from multiple teacher models, and transforms both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation.3. results: The experimental findings demonstrated that the proposed model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled.<details>
<summary>Abstract</summary>
In many parts of the world, the use of vast amounts of data collected on public roadways for autonomous driving has increased. In order to detect and anonymize pedestrian faces and nearby car license plates in actual road-driving scenarios, there is an urgent need for effective solutions. As more data is collected, privacy concerns regarding it increase, including but not limited to pedestrian faces and surrounding vehicle license plates. Normal and fisheye cameras are the two common camera types that are typically mounted on collection vehicles. With complex camera distortion models, fisheye camera images were deformed in contrast to regular images. It causes computer vision tasks to perform poorly when using numerous deep learning models. In this work, we pay particular attention to protecting privacy while yet adhering to several laws for fisheye camera photos taken by driverless vehicles. First, we suggest a framework for extracting face and plate identification knowledge from several teacher models. Our second suggestion is to transform both the image and the label from a regular image to fisheye-like data using a varied and realistic fisheye transformation. Finally, we run a test using the open-source PP4AV dataset. The experimental findings demonstrated that our model outperformed baseline methods when trained on data from autonomous vehicles, even when the data were softly labeled. The implementation code is available at our github: https://github.com/khaclinh/FisheyePP4AV.
</details>
<details>
<summary>摘要</summary>
在多个国家和地区，自动驾驶技术的应用使用了大量公共道路上收集的数据，增加了面临挑战的需求。为了探测和隐私化行人脸和附近车辆号牌在实际道路驾驶场景中，隐私问题的关注也在不断增加，包括但不限于行人脸和周围车辆号牌。通常，自动驾驶车辆上会安装 Normal 和 fisheye 两种常见的摄像头类型。由于复杂的摄像头扭曲模型，fisheye 摄像头图像与常见图像不同，导致计算机视觉任务的表现不佳，需要许多深度学习模型来进行改进。在这种情况下，我们强调保护隐私的同时，遵循多个法律。我们的方法包括：一、从多个教师模型中提取面和号牌识别知识。二、将图像和标签从常见图像转换为 fisheye-like 数据，使用变化和实际的 fisheye 转换。最后，我们使用开源的 PP4AV 数据集进行测试。实验结果表明，我们的模型在使用自动驾驶车辆收集的数据进行训练时，能够超越基eline方法。代码可以在我们的 GitHub 上找到：https://github.com/khaclinh/FisheyePP4AV。
</details></li>
</ul>
<hr>
<h2 id="CPU-frequency-scheduling-of-real-time-applications-on-embedded-devices-with-temporal-encoding-based-deep-reinforcement-learning"><a href="#CPU-frequency-scheduling-of-real-time-applications-on-embedded-devices-with-temporal-encoding-based-deep-reinforcement-learning" class="headerlink" title="CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning"></a>CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03779">http://arxiv.org/abs/2309.03779</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/coladog/tinyagent">https://github.com/coladog/tinyagent</a></li>
<li>paper_authors: Ti Zhou, Man Lin</li>
<li>for: 这篇论文主要是关于开发小设备上Periodic任务的高效能源管理方法。</li>
<li>methods: 作者首先研究了小设备中Linux内置方法的限制，然后描述了三种常见的工作负荷&#x2F;系统模式，这些模式对Linux内置解决方案而言是挑战。然后，作者开发了一种基于强化学习的技术，使用时间编码，从而 derivate一个高效的DVFSGOVERNOR。这个GOVERNOR只需一个性能计数器，与Linux内置机制一样，并不需要显式任务模型。</li>
<li>results: 作者实现了一个基于Nvidia Jetson Nano板的原型系统，并对六个应用程序进行了实验，包括两个自定义应用程序和四个参考应用程序。在不同的截止时间限制下，我们的方法可以快速 derivate一个适应性能要求的DVFSGOVERNOR，并在能源储存方面高效于Linux内置机制。在Mibench工作负荷上，在性能潜伏范围为0.04s至0.4s时，提posed方法可以保存3%-11%的能源。AudioReg和FaceReg应用程序的能源储存改进率为5%-14%。作者已经开源了内核量化神经网络引擎的实现代码，代码库可以在以下链接中找到：<a target="_blank" rel="noopener" href="https://github.com/coladog/tinyagent%E3%80%82">https://github.com/coladog/tinyagent。</a><details>
<summary>Abstract</summary>
Small devices are frequently used in IoT and smart-city applications to perform periodic dedicated tasks with soft deadlines. This work focuses on developing methods to derive efficient power-management methods for periodic tasks on small devices. We first study the limitations of the existing Linux built-in methods used in small devices. We illustrate three typical workload/system patterns that are challenging to manage with Linux's built-in solutions. We develop a reinforcement-learning-based technique with temporal encoding to derive an effective DVFS governor even with the presence of the three system patterns. The derived governor uses only one performance counter, the same as the built-in Linux mechanism, and does not require an explicit task model for the workload. We implemented a prototype system on the Nvidia Jetson Nano Board and experimented with it with six applications, including two self-designed and four benchmark applications. Under different deadline constraints, our approach can quickly derive a DVFS governor that can adapt to performance requirements and outperform the built-in Linux approach in energy saving. On Mibench workloads, with performance slack ranging from 0.04 s to 0.4 s, the proposed method can save 3% - 11% more energy compared to Ondemand. AudioReg and FaceReg applications tested have 5%- 14% energy-saving improvement. We have open-sourced the implementation of our in-kernel quantized neural network engine. The codebase can be found at: https://github.com/coladog/tinyagent.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Extending-Transductive-Knowledge-Graph-Embedding-Models-for-Inductive-Logical-Relational-Inference"><a href="#Extending-Transductive-Knowledge-Graph-Embedding-Models-for-Inductive-Logical-Relational-Inference" class="headerlink" title="Extending Transductive Knowledge Graph Embedding Models for Inductive Logical Relational Inference"></a>Extending Transductive Knowledge Graph Embedding Models for Inductive Logical Relational Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03773">http://arxiv.org/abs/2309.03773</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tgebhart/sheaf_kg_transind">https://github.com/tgebhart/sheaf_kg_transind</a></li>
<li>paper_authors: Thomas Gebhart, John Cobb</li>
<li>for:  bridging the gap between transductive and inductive knowledge graph embedding methods</li>
<li>methods:  leveraging representations learned through transductive embedding methods to infer representations of new entities in the inductive setting</li>
<li>results:  competitive with or outperforming state-of-the-art models derived explicitly for inductive tasks in experiments on large-scale knowledge graph embedding benchmarks<details>
<summary>Abstract</summary>
Many downstream inference tasks for knowledge graphs, such as relation prediction, have been handled successfully by knowledge graph embedding techniques in the transductive setting. To address the inductive setting wherein new entities are introduced into the knowledge graph at inference time, more recent work opts for models which learn implicit representations of the knowledge graph through a complex function of a network's subgraph structure, often parametrized by graph neural network architectures. These come at the cost of increased parametrization, reduced interpretability and limited generalization to other downstream inference tasks. In this work, we bridge the gap between traditional transductive knowledge graph embedding approaches and more recent inductive relation prediction models by introducing a generalized form of harmonic extension which leverages representations learned through transductive embedding methods to infer representations of new entities introduced at inference time as in the inductive setting. This harmonic extension technique provides the best such approximation, can be implemented via an efficient iterative scheme, and can be employed to answer a family of conjunctive logical queries over the knowledge graph, further expanding the capabilities of transductive embedding methods. In experiments on a number of large-scale knowledge graph embedding benchmarks, we find that this approach for extending the functionality of transductive knowledge graph embedding models to perform knowledge graph completion and answer logical queries in the inductive setting is competitive with--and in some scenarios outperforms--several state-of-the-art models derived explicitly for such inductive tasks.
</details>
<details>
<summary>摘要</summary>
许多知识图embedding任务，如关系预测，已经由知识图嵌入技术在推uctive setting中成功处理。在 inductive setting中，新的实体被引入到知识图时，更新工作选择了模型学习知识图的隐式表示，通常通过图 neural network架构进行 parametrization。这些模型增加参数化，降低可解释性，并有限制其他下游任务的通用性。在这项工作中，我们将传统的推uctive知识图嵌入方法与更新的 inductive relation prediction模型相连接，通过一种通用的harmonic extension技术来推算新引入的实体的表示，这种技术可以实现高效的迭代方案，并可以用来回答 conjunctive logical queries sobre知识图，从而扩展传统的推uctive嵌入方法的能力。在一些大规模知识图嵌入benchmark上进行实验，我们发现这种方法可以在 inductive setting中完成知识图完成和回答逻辑查询任务，与一些状态对应的模型相比，在一些场景下even outperform。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-of-representation-learning-and-reinforcement-learning-for-dynamic-and-complex-robotic-motion-planning"><a href="#Hybrid-of-representation-learning-and-reinforcement-learning-for-dynamic-and-complex-robotic-motion-planning" class="headerlink" title="Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning"></a>Hybrid of representation learning and reinforcement learning for dynamic and complex robotic motion planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03758">http://arxiv.org/abs/2309.03758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengmin Zhou, Xin Lu, Jiapeng Dai, Bingding Huang, Xiaoxu Liu, Pasi Fränti</li>
<li>for: This paper proposes a hybrid algorithm for robotic motion planning that combines long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC).</li>
<li>methods: The proposed algorithm uses a graph network and attention network to interpret the environmental state, and integrates skip connection to mitigate overfitting and improve convergence speed.</li>
<li>results: The proposed LSA-DSAC algorithm outperforms the state-of-the-art in training and most evaluations, and is successfully implemented and tested on a physical robot in the real world.<details>
<summary>Abstract</summary>
Motion planning is the soul of robot decision making. Classical planning algorithms like graph search and reaction-based algorithms face challenges in cases of dense and dynamic obstacles. Deep learning algorithms generate suboptimal one-step predictions that cause many collisions. Reinforcement learning algorithms generate optimal or near-optimal time-sequential predictions. However, they suffer from slow convergence, suboptimal converged results, and overfittings. This paper introduces a hybrid algorithm for robotic motion planning: long short-term memory (LSTM) pooling and skip connection for attention-based discrete soft actor critic (LSA-DSAC). First, graph network (relational graph) and attention network (attention weight) interpret the environmental state for the learning of the discrete soft actor critic algorithm. The expressive power of attention network outperforms that of graph in our task by difference analysis of these two representation methods. However, attention based DSAC faces the overfitting problem in training. Second, the skip connection method is integrated to attention based DSAC to mitigate overfitting and improve convergence speed. Third, LSTM pooling is taken to replace the sum operator of attention weigh and eliminate overfitting by slightly sacrificing convergence speed at early-stage training. Experiments show that LSA-DSAC outperforms the state-of-the-art in training and most evaluations. The physical robot is also implemented and tested in the real world.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT运动规划是机器人决策的核心。经典的规划算法如搜索graph和反应型算法在受到紧密和动态障碍物时遇到问题。深度学习算法生成的一步预测通常会导致多次相撞。再强化学习算法则可以生成优化或近似优化的时间序列预测，但它们受到慢速度的转化和不佳的转化结果的影响。本文提出了机器人运动规划的гибри达算法：长Short-Term Memory（LSTM）混合和跳过连接 для注意力基于Discrete Soft Actor Critic（LSA-DSAC）。首先，图网络（关系图）和注意力网络（注意力权重）解释环境状态，以便学习Discrete Soft Actor Critic算法。对比这两种表示方法，注意力网络在我们的任务中表现出了更高的表达力。然而，注意力基于DSAC still faces the overfitting problem in training。其次，跳过连接方法被集成到注意力基于DSAC中，以mitigate overfitting和提高转化速度。最后，LSTM混合被用来取代注意力权重的 SUM 操作，以消除过拟合的问题，但是略微牺牲早期训练的速度。实验表明，LSA-DSAC在训练和评估中都能够超越状态 искус границы。physical robot也在实际世界中进行了测试。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the given text and may not reflect the exact nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="TSGBench-Time-Series-Generation-Benchmark"><a href="#TSGBench-Time-Series-Generation-Benchmark" class="headerlink" title="TSGBench: Time Series Generation Benchmark"></a>TSGBench: Time Series Generation Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03755">http://arxiv.org/abs/2309.03755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihao Ang, Qiang Huang, Yifan Bao, Anthony K. H. Tung, Zhiyong Huang</li>
<li>for: 本研究的目的是提供一个普遍和完整的TSG方法评估 benchmark，以扩展和改善现有的TSG方法。</li>
<li>methods: 本研究使用了10种先进的TSG方法，并使用了12个评估指标，包括标准的评估指标和新的距离基准。</li>
<li>results: 研究发现，\textsf{TSGBench} 能够提供一个统一和完整的TSG方法评估，并且能够给出不同测试集和评估指标下方法的性能差异，提供了更加精确的方法评估。<details>
<summary>Abstract</summary>
Synthetic Time Series Generation (TSG) is crucial in a range of applications, including data augmentation, anomaly detection, and privacy preservation. Although significant strides have been made in this field, existing methods exhibit three key limitations: (1) They often benchmark against similar model types, constraining a holistic view of performance capabilities. (2) The use of specialized synthetic and private datasets introduces biases and hampers generalizability. (3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison.   To overcome these limitations, we introduce \textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods. It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods. We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \textsf{TSGBench}. The results highlight its remarkable efficacy and consistency. More importantly, \textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method.
</details>
<details>
<summary>摘要</summary>
“人工时间序列生成（TSG）在许多应用中扮演重要角色，包括数据增强、异常检测和隐私保护。 Although significant strides have been made in this field, existing methods have three key limitations: (1) They often benchmark against similar model types, limiting a holistic view of performance capabilities. (2) The use of specialized synthetic and private datasets introduces biases and hinders generalizability. (3) Ambiguous evaluation measures, often tied to custom networks or downstream tasks, hinder consistent and fair comparison.  To overcome these limitations, we introduce \textsf{TSGBench}, the inaugural TSG Benchmark, designed for a unified and comprehensive assessment of TSG methods. It comprises three modules: (1) a curated collection of publicly available, real-world datasets tailored for TSG, together with a standardized preprocessing pipeline; (2) a comprehensive evaluation measures suite including vanilla measures, new distance-based assessments, and visualization tools; (3) a pioneering generalization test rooted in Domain Adaptation (DA), compatible with all methods. We have conducted extensive experiments across ten real-world datasets from diverse domains, utilizing ten advanced TSG methods and twelve evaluation measures, all gauged through \textsf{TSGBench}. The results highlight its remarkable efficacy and consistency. More importantly, \textsf{TSGBench} delivers a statistical breakdown of method rankings, illuminating performance variations across different datasets and measures, and offering nuanced insights into the effectiveness of each method.”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Pipeline-Based-Conversational-Agents-with-Large-Language-Models"><a href="#Enhancing-Pipeline-Based-Conversational-Agents-with-Large-Language-Models" class="headerlink" title="Enhancing Pipeline-Based Conversational Agents with Large Language Models"></a>Enhancing Pipeline-Based Conversational Agents with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03748">http://arxiv.org/abs/2309.03748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mina Foosherian, Hendrik Purwins, Purna Rathnayake, Touhidul Alam, Rui Teimao, Klaus-Dieter Thoben</li>
<li>for: 这篇论文旨在探讨如何使用大语言模型（LLM）来增强基于管道的对话代理人。</li>
<li>methods: 这篇论文在两个阶段 investigates LLMs’ capabilities: 在设计和开发阶段，LLMs 可以帮助生成训练数据、提取实体和同义词、本地化和人物设计；在运行阶段，LLMs 可以帮助 Contextualization、意图分类、避免对话堵塞和处理非法问题、自动修正语句、重塑回答、生成缓解 вопросы、总结和启用关闭问答能力。</li>
<li>results: 作者通过使用 GPT-4 在私人银行领域进行了实际实验，以示出上述场景。 由于隐私问题和替换既有的生态系统需要深度 интегра，因此公司可能会尽量保留其基于管道的代理人。一种混合方法，在基于管道的代理人中 интегра LLMs，可以让公司节省建立和运行代理人的时间和成本，同时保留现有系统的隐私和安全保障。<details>
<summary>Abstract</summary>
The latest advancements in AI and deep learning have led to a breakthrough in large language model (LLM)-based agents such as GPT-4. However, many commercial conversational agent development tools are pipeline-based and have limitations in holding a human-like conversation. This paper investigates the capabilities of LLMs to enhance pipeline-based conversational agents during two phases: 1) in the design and development phase and 2) during operations. In 1) LLMs can aid in generating training data, extracting entities and synonyms, localization, and persona design. In 2) LLMs can assist in contextualization, intent classification to prevent conversational breakdown and handle out-of-scope questions, auto-correcting utterances, rephrasing responses, formulating disambiguation questions, summarization, and enabling closed question-answering capabilities. We conducted informal experiments with GPT-4 in the private banking domain to demonstrate the scenarios above with a practical example. Companies may be hesitant to replace their pipeline-based agents with LLMs entirely due to privacy concerns and the need for deep integration within their existing ecosystems. A hybrid approach in which LLMs' are integrated into the pipeline-based agents allows them to save time and costs of building and running agents by capitalizing on the capabilities of LLMs while retaining the integration and privacy safeguards of their existing systems.
</details>
<details>
<summary>摘要</summary>
最新的人工智能和深度学习技术突破已经导致大型语言模型（LLM）基于代理人的突破，如GPT-4。然而，许多商业对话代理人开发工具是管道式的，它们在保持人类化对话方面有限制。这篇论文研究了LLM在两个阶段中对管道式对话代理人的增强：1）在设计和开发阶段，LLM可以帮助生成训练数据，提取实体和同义词，本地化，并设计人物。2）在运行阶段，LLM可以帮助Contextualization，意图类型分类，避免对话堵塞和处理外部问题，自动更正词语，重新推敲答案，形成杠词问题，摘要和启用关闭问题-答案功能。我们在private banking领域使用GPT-4进行了非正式的实验，以示上述场景。由于隐私问题和现有系统集成的需求，公司可能会尽量保留管道式代理人，而不是完全取代它们。一种混合方法，在管道式代理人中 integrate LLM，允许它们在利用LLM的能力的同时，保留现有系统的隐私和安全保障。
</details></li>
</ul>
<hr>
<h2 id="A-Natural-Gas-Consumption-Forecasting-System-for-Continual-Learning-Scenarios-based-on-Hoeffding-Trees-with-Change-Point-Detection-Mechanism"><a href="#A-Natural-Gas-Consumption-Forecasting-System-for-Continual-Learning-Scenarios-based-on-Hoeffding-Trees-with-Change-Point-Detection-Mechanism" class="headerlink" title="A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism"></a>A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03720">http://arxiv.org/abs/2309.03720</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rasvob/hoeffding-trees-with-cpd-multistep-forecasing">https://github.com/rasvob/hoeffding-trees-with-cpd-multistep-forecasing</a></li>
<li>paper_authors: Radek Svoboda, Sebastian Basterrech, Jędrzej Kozal, Jan Platoš, Michał Woźniak</li>
<li>for: 预测天然气消耗，考虑季节性和趋势，对于工业实体来说是非常重要的，以便规划生产和消耗天然气，最大化生产成本。同时，在供应威胁的情况下，也是社会能源安全的关键因素。</li>
<li>methods: 本文提出了一种新的多步前预测天然气消耗方法，integrating change point detection，用于数据流处理。使用Hoeffding树预测模型和Prune Exact Linear Time（PELT）算法进行变点检测。在实际应用中，使用了不同的变点检测方法来选择不同的模型集。</li>
<li>results: 我们的实验表明，具有变点检测功能的预测模型比无变点检测的基准方法更具有优势，尤其是在检测到更多变点的情况下。此外，使用简单的变点检测方法可以获得更加稳定和适合持续学习任务的预测模型。<details>
<summary>Abstract</summary>
Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Thus, three model collection selection procedures (with and without an error feedback loop) are defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Also, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.
</details>
<details>
<summary>摘要</summary>
预测天然气消耗，考虑季节性和趋势，是重要的在规划生产和消耗的天然气supply和cost optimization中。然而，在供应威胁时，也是一个关键的元素，确保这种原料的供应，以满足个人消耗者的需求，保障社会能源安全。本文介绍了一种新的多步 ahead forecasting天然气消耗方法， integrate change point detection for model collection selection with continual learning capabilities using data stream processing。 Forecasting models based on the proposed approach were evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model collection for successive time frames. Therefore, three model collection selection procedures (with and without an error feedback loop) were defined and evaluated for forecasting scenarios with various densities of detected change points. These models were compared with change point agnostic baseline approaches. Our experiments show that fewer change points result in a lower forecasting error regardless of the model collection selection procedure employed. Additionally, simpler model collection selection procedures omitting forecasting error feedback leads to more robust forecasting models suitable for continual learning tasks.
</details></li>
</ul>
<hr>
<h2 id="PyGraft-Configurable-Generation-of-Schemas-and-Knowledge-Graphs-at-Your-Fingertips"><a href="#PyGraft-Configurable-Generation-of-Schemas-and-Knowledge-Graphs-at-Your-Fingertips" class="headerlink" title="PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips"></a>PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03685">http://arxiv.org/abs/2309.03685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nicolas-hbt/pygraft">https://github.com/nicolas-hbt/pygraft</a></li>
<li>paper_authors: Nicolas Hubert, Pierre Monnin, Mathieu d’Aquin, Armelle Brun, Davy Monticolo</li>
<li>for: 本研究旨在提供一个可以生成对象 Oriented 的 Knowledge Graph (KG) 的工具，以便为 Graph-based Machine Learning (ML) 的模型进行更多的评估和测试。</li>
<li>methods: 本研究使用 Python 语言开发了一个名为 PyGraft 的工具，可以生成具有不同特性和规模的 Knowledge Graphs (KGs)，并且可以保证这些生成的资源的逻辑一致性。</li>
<li>results: 本研究透过 PyGraft 生成的 KGs，实现了对 Graph-based ML 模型的更多和更具体的评估和测试，并且获得了更好的结果。<details>
<summary>Abstract</summary>
Knowledge graphs (KGs) have emerged as a prominent data representation and management paradigm. Being usually underpinned by a schema (e.g. an ontology), KGs capture not only factual information but also contextual knowledge. In some tasks, a few KGs established themselves as standard benchmarks. However, recent works outline that relying on a limited collection of datasets is not sufficient to assess the generalization capability of an approach. In some data-sensitive fields such as education or medicine, access to public datasets is even more limited. To remedy the aforementioned issues, we release PyGraft, a Python-based tool that generates highly customized, domain-agnostic schemas and knowledge graphs. The synthesized schemas encompass various RDFS and OWL constructs, while the synthesized KGs emulate the characteristics and scale of real-world KGs. Logical consistency of the generated resources is ultimately ensured by running a description logic (DL) reasoner. By providing a way of generating both a schema and KG in a single pipeline, PyGraft's aim is to empower the generation of a more diverse array of KGs for benchmarking novel approaches in areas such as graph-based machine learning (ML), or more generally KG processing. In graph-based ML in particular, this should foster a more holistic evaluation of model performance and generalization capability, thereby going beyond the limited collection of available benchmarks. PyGraft is available at: https://github.com/nicolas-hbt/pygraft.
</details>
<details>
<summary>摘要</summary>
知识图（KG）已经成为数据表示和管理方法的一种显著的特点。通常受到 schema（例如ontology）的支持，KG 不仅记录了事实信息，还捕捉了 contextual knowledge。在某些任务中，一些 KG 已经成为了标准的参考基eline。然而， latest works 表明，仅仅靠用有限的数据集来评估一个方法的通用能力并不够。在一些数据敏感的领域，如教育或医学，对公共数据的访问也是有限的。为了解决以上问题，我们释放了 PyGraft，一个基于 Python 的工具，可以生成高度自定义、领域不依赖的 schema 和知识图。生成的 schema 包括 RDFS 和 OWL 结构体系，而生成的知识图 模拟了实际知识图的特点和规模。在整个过程中，我们使用描述逻辑（DL）理解器来保证生成的资源的逻辑一致性。通过在单个管道中生成 schema 和知识图，PyGraft 的目标是激励一种更多样的知识图的生成，以便对图基于机器学习（ML）或更一般的知识图处理方法进行更加全面的评估和性能评估。在图基于 ML 中，这应该激励模型的性能和通用能力的全面评估，从而超越现有的限定的 benchmark。PyGraft 可以在以下地址获取：https://github.com/nicolas-hbt/pygraft。
</details></li>
</ul>
<hr>
<h2 id="Dataset-Generation-and-Bonobo-Classification-from-Weakly-Labelled-Videos"><a href="#Dataset-Generation-and-Bonobo-Classification-from-Weakly-Labelled-Videos" class="headerlink" title="Dataset Generation and Bonobo Classification from Weakly Labelled Videos"></a>Dataset Generation and Bonobo Classification from Weakly Labelled Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03671">http://arxiv.org/abs/2309.03671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre-Etienne Martin</li>
<li>for: 本研究旨在开发一个基于常用机器学习方法的 bonobo 检测和分类管线，以便在无人协助的情况下，使用触摸屏设备测试 bonobo 在围栏中的行为。</li>
<li>methods: 本研究使用了一个新收集的 bonobo 录制数据集，并使用了手工特征和不同的分类算法以及深度学习方法，包括 ResNet 架构，进行 bonobo 识别。</li>
<li>results: 本研究的结果表明，通过meaningful数据分割和 fine-tuning ResNet 模型，可以达到75%的准确率。同时，研究还证明了数据预处理的重要性，并示出了 incorrect 数据分割可能导致 false 的好结果。<details>
<summary>Abstract</summary>
This paper presents a bonobo detection and classification pipeline built from the commonly used machine learning methods. Such application is motivated by the need to test bonobos in their enclosure using touch screen devices without human assistance. This work introduces a newly acquired dataset based on bonobo recordings generated semi-automatically. The recordings are weakly labelled and fed to a macaque detector in order to spatially detect the individual present in the video. Handcrafted features coupled with different classification algorithms and deep-learning methods using a ResNet architecture are investigated for bonobo identification. Performance is compared in terms of classification accuracy on the splits of the database using different data separation methods. We demonstrate the importance of data preparation and how a wrong data separation can lead to false good results. Finally, after a meaningful separation of the data, the best classification performance is obtained using a fine-tuned ResNet model and reaches 75% of accuracy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="How-adversarial-attacks-can-disrupt-seemingly-stable-accurate-classifiers"><a href="#How-adversarial-attacks-can-disrupt-seemingly-stable-accurate-classifiers" class="headerlink" title="How adversarial attacks can disrupt seemingly stable accurate classifiers"></a>How adversarial attacks can disrupt seemingly stable accurate classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03665">http://arxiv.org/abs/2309.03665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oliver J. Sutton, Qinghua Zhou, Ivan Y. Tyukin, Alexander N. Gorban, Alexander Bastounis, Desmond J. Higham</li>
<li>for: 这个论文主要针对的是防御性攻击，即使用一些微小的修改来让模型输出错误的输入数据。</li>
<li>methods: 这篇论文使用了一种简单的普适的框架，来解释实际系统中观察到的一些特性，如模型对小范围的攻击敏感，而对大范围的随机干扰免疫。</li>
<li>results: 这篇论文的结果表明，即使使用大量的随机干扰，模型仍然可能受到小范围的攻击，而且这种攻击可以轻松地构造。此外，研究还发现，使用随机干扰进行训练或测试可能不能探测出这种攻击，需要更加严格的对抗训练来解决这个问题。<details>
<summary>Abstract</summary>
Adversarial attacks dramatically change the output of an otherwise accurate learning system using a seemingly inconsequential modification to a piece of input data. Paradoxically, empirical evidence indicates that even systems which are robust to large random perturbations of the input data remain susceptible to small, easily constructed, adversarial perturbations of their inputs. Here, we show that this may be seen as a fundamental feature of classifiers working with high dimensional input data. We introduce a simple generic and generalisable framework for which key behaviours observed in practical systems arise with high probability -- notably the simultaneous susceptibility of the (otherwise accurate) model to easily constructed adversarial attacks, and robustness to random perturbations of the input data. We confirm that the same phenomena are directly observed in practical neural networks trained on standard image classification problems, where even large additive random noise fails to trigger the adversarial instability of the network. A surprising takeaway is that even small margins separating a classifier's decision surface from training and testing data can hide adversarial susceptibility from being detected using randomly sampled perturbations. Counterintuitively, using additive noise during training or testing is therefore inefficient for eradicating or detecting adversarial examples, and more demanding adversarial training is required.
</details>
<details>
<summary>摘要</summary>
敌对攻击可能导致学习系统的输出发生显著变化，只需要对输入数据进行微小的修改。尽管这些系统可以抵抗大量随机干扰输入数据，但它们却容易受到小型针对性的攻击。在这篇文章中，我们表明这可能是高维输入数据上的分类器工作的基本特点。我们提出了一个简单的通用的框架，可以解释在实际系统中观察到的一些重要行为，例如抗 Random Perturbations 的模型同时受到攻击和稳定性问题。我们验证了这些现象在实际的神经网络中也出现，即使添加大量随机干扰也无法触发神经网络的攻击不稳定性。一个意外的发现是， même 小的准确率差可以隐藏攻击的敏感性，因此使用随机干扰来检测或消除攻击是不够有效的。相反，需要更加严格的敌对训练来检测和消除攻击。
</details></li>
</ul>
<hr>
<h2 id="Towards-Comparable-Knowledge-Distillation-in-Semantic-Image-Segmentation"><a href="#Towards-Comparable-Knowledge-Distillation-in-Semantic-Image-Segmentation" class="headerlink" title="Towards Comparable Knowledge Distillation in Semantic Image Segmentation"></a>Towards Comparable Knowledge Distillation in Semantic Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03659">http://arxiv.org/abs/2309.03659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onno Niemann, Christopher Vox, Thorben Werner</li>
<li>for: 本研究目的是提出一种解决大型模型和慢速识别问题的方法，即知识塑化（KD）。</li>
<li>methods: 本研究使用了25种提出的塑化损失项，从14篇最近4年的论文中提取。</li>
<li>results: 研究发现，使用同样的模型和数据集时，SSTKD方法可以提高学生mIoU值4.54个百分点和最终性能29.19个百分点，而APD方法只提高学生性能2.06个百分点，但实现了39.25个百分点的最终性能。这种极大差异的原因通常是使用不优化的超参数，导致参照模型的性能下降。研究还发现，使用SKD和IFVD框架的塑化改进可以在超参数优化得到更好的性能。为了改善未来在这个领域的研究比较可读性，本研究提供了三个数据集和两个学生模型的固定基线，并提供了广泛的超参数优化信息。研究发现，只有两种技术可以与我们的简单基线相比肩，并且只有在ADE20K数据集上。<details>
<summary>Abstract</summary>
Knowledge Distillation (KD) is one proposed solution to large model sizes and slow inference speed in semantic segmentation. In our research we identify 25 proposed distillation loss terms from 14 publications in the last 4 years. Unfortunately, a comparison of terms based on published results is often impossible, because of differences in training configurations. A good illustration of this problem is the comparison of two publications from 2022. Using the same models and dataset, Structural and Statistical Texture Distillation (SSTKD) reports an increase of student mIoU of 4.54 and a final performance of 29.19, while Adaptive Perspective Distillation (APD) only improves student performance by 2.06 percentage points, but achieves a final performance of 39.25. The reason for such extreme differences is often a suboptimal choice of hyperparameters and a resulting underperformance of the student model used as reference point. In our work, we reveal problems of insufficient hyperparameter tuning by showing that distillation improvements of two widely accepted frameworks, SKD and IFVD, vanish when hyperparameters are optimized sufficiently. To improve comparability of future research in the field, we establish a solid baseline for three datasets and two student models and provide extensive information on hyperparameter tuning. We find that only two out of eight techniques can compete with our simple baseline on the ADE20K dataset.
</details>
<details>
<summary>摘要</summary>
知识塑化（KD）是一种提出来解决大型模型和慢速推理问题的方案，在我们的研究中，我们发现了25种提议的塑化损失项。 unfortunately，由于各个论文的训练配置不同，对于已发表结果进行比较是很困难的。以2022年的两篇论文为例，使用同样的模型和数据集，Structural and Statistical Texture Distillation（SSTKD） Reported an increase of student mIoU of 4.54 and a final performance of 29.19，而Adaptive Perspective Distillation（APD）只有2.06个百分点的提高，但是实现了39.25的最终性能。这种极大的差异的原因通常是模型参数的不佳选择和引用模型的下表性。在我们的工作中，我们发现了塑化过程中的不足hyperparameter tuning，并通过显示SKD和IFVD两种广泛accepted框架的塑化改进 vanish when hyperparameters are optimized sufficiently。为了提高未来的研究领域的比较可读性，我们建立了三个数据集和两个学生模型的固定基线，并提供了广泛的hyperparameter tuning信息。我们发现只有ADE20K数据集上的两个技术能够与我们的简单基线相比肩。
</details></li>
</ul>
<hr>
<h2 id="Anatomy-informed-Data-Augmentation-for-Enhanced-Prostate-Cancer-Detection"><a href="#Anatomy-informed-Data-Augmentation-for-Enhanced-Prostate-Cancer-Detection" class="headerlink" title="Anatomy-informed Data Augmentation for Enhanced Prostate Cancer Detection"></a>Anatomy-informed Data Augmentation for Enhanced Prostate Cancer Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03652">http://arxiv.org/abs/2309.03652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mic-dkfz/anatomy_informed_da">https://github.com/mic-dkfz/anatomy_informed_da</a></li>
<li>paper_authors: Balint Kovacs, Nils Netzer, Michael Baumgartner, Carolin Eith, Dimitrios Bounias, Clara Meinzer, Paul F. Jaeger, Kevin S. Zhang, Ralf Floca, Adrian Schrader, Fabian Isensee, Regula Gnirs, Magdalena Goertz, Viktoria Schuetz, Albrecht Stenzinger, Markus Hohenfellner, Heinz-Peter Schlemmer, Ivo Wolf, David Bonekamp, Klaus H. Maier-Hein</li>
<li>for: 这篇研究旨在提高医疗影像分析中的资料增强（DA）方法，以增强遗传统数据中的肿瘤标示精度。</li>
<li>methods: 本研究提出了一种新的生物学信息驱动的增强方法，利用邻近器官信息来模拟Typical的生物LOGICAL deformations of the prostate，实现不同的肿瘤形状和组织弹性。这个增强方法的计算成本轻量级，可以与常见的DA框架集成。</li>
<li>results: 本研究在774篇确诊检查中评估了一种常见的PCa检测方法，包括不同的增强设定。结果显示，这个新的增强方法可以增强PCa检测的精度和一致性。<details>
<summary>Abstract</summary>
Data augmentation (DA) is a key factor in medical image analysis, such as in prostate cancer (PCa) detection on magnetic resonance images. State-of-the-art computer-aided diagnosis systems still rely on simplistic spatial transformations to preserve the pathological label post transformation. However, such augmentations do not substantially increase the organ as well as tumor shape variability in the training set, limiting the model's ability to generalize to unseen cases with more diverse localized soft-tissue deformations. We propose a new anatomy-informed transformation that leverages information from adjacent organs to simulate typical physiological deformations of the prostate and generates unique lesion shapes without altering their label. Due to its lightweight computational requirements, it can be easily integrated into common DA frameworks. We demonstrate the effectiveness of our augmentation on a dataset of 774 biopsy-confirmed examinations, by evaluating a state-of-the-art method for PCa detection with different augmentation settings.
</details>
<details>
<summary>摘要</summary>
增强数据（DA）是医疗图像分析中关键因素，如抑阻肾癌（PCa）检测在磁共振图像中。现有的计算机支持诊断系统仍然依赖于简单的空间变换来保持疾病标签后转换。然而，这些扩展不会显著增加器官以及肿瘤形态变化的多样性在训练集中，限制模型的泛化能力。我们提议一种新的解剖学知识支持的变换，利用邻近器官信息来模拟Typical的生理性肿瘤变化，生成Unique的疾病形态而无需改变其标签。由于其轻量级的计算需求，它可以轻松地与常见的DA框架集成。我们在774例采取确认检查中证明了我们的扩展的有效性，通过评估一种state-of-the-art方法在不同的扩展设置下进行PCa检测。
</details></li>
</ul>
<hr>
<h2 id="Learning-of-Generalizable-and-Interpretable-Knowledge-in-Grid-Based-Reinforcement-Learning-Environments"><a href="#Learning-of-Generalizable-and-Interpretable-Knowledge-in-Grid-Based-Reinforcement-Learning-Environments" class="headerlink" title="Learning of Generalizable and Interpretable Knowledge in Grid-Based Reinforcement Learning Environments"></a>Learning of Generalizable and Interpretable Knowledge in Grid-Based Reinforcement Learning Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03651">http://arxiv.org/abs/2309.03651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manueleberhardinger/ec-rl">https://github.com/manueleberhardinger/ec-rl</a></li>
<li>paper_authors: Manuel Eberhardinger, Johannes Maucher, Setareh Maghsudi</li>
<li>for: 本文旨在理解深度强化学习训练的 Agent 之间的交互，以便在游戏或真实世界中部署 Agent。在游戏中，不合理的行为会让玩家感到困惑。在真实世界中，这种效果更加严重，因为不期望的行为可能会导致严重和长期的后果。</li>
<li>methods: 本文使用程序生成来模拟强化学习策略，以便更好地理解 Agent 的行为。程序具有可读性和可验证性，可以帮助我们更好地理解 Agent 学习的概念。我们使用 DreamCoder 系统，这是目前最佳的程序生成系统，在网格环境中进行学习概念，包括导航任务和两个小型的 Atari 游戏 Space Invaders 和 Asterix。</li>
<li>results: 我们通过观察生成的库来理解 Agent 学习的概念，并通过视觉化 Agent 决策过程来更好地理解 Agent 的行为。我们使用不同类型的程序生成器，包括搜索方法、神经网络引导搜索和语言模型精心调整代码，来评估我们的方法。<details>
<summary>Abstract</summary>
Understanding the interactions of agents trained with deep reinforcement learning is crucial for deploying agents in games or the real world. In the former, unreasonable actions confuse players. In the latter, that effect is even more significant, as unexpected behavior cause accidents with potentially grave and long-lasting consequences for the involved individuals. In this work, we propose using program synthesis to imitate reinforcement learning policies after seeing a trajectory of the action sequence. Programs have the advantage that they are inherently interpretable and verifiable for correctness. We adapt the state-of-the-art program synthesis system DreamCoder for learning concepts in grid-based environments, specifically, a navigation task and two miniature versions of Atari games, Space Invaders and Asterix. By inspecting the generated libraries, we can make inferences about the concepts the black-box agent has learned and better understand the agent's behavior. We achieve the same by visualizing the agent's decision-making process for the imitated sequences. We evaluate our approach with different types of program synthesizers based on a search-only method, a neural-guided search, and a language model fine-tuned on code.
</details>
<details>
<summary>摘要</summary>
理解深度强化学习模型训练后的交互是部署在游戏或实际世界中的关键。在前一种情况下，不合理的行为会让玩家感到困惑。在后一种情况下，这种效果更加严重，因为不期望的行为可能会导致严重和长期的后果，对参与者来说。在这项工作中，我们提议使用程序生成来模拟强化学习策略，以观察行为序列的轨迹。程序有利于因为它们是可解释的和可验证的。我们修改了当前的程序生成系统DreamCoder，以学习在网格环境中的概念，具体来说是一个导航任务和两个小型的Atari游戏Space Invaders和Asterix。通过检查生成的库，我们可以从拟合的序列中提取出黑obox模型学习的概念，并更好地理解模型的行为。我们还可以通过可视化模型决策过程来描述拟合序列。我们使用不同类型的程序生成器，包括搜索方法、神经网络引导搜索和语言模型在代码上进行微调，来评估我们的方法。
</details></li>
</ul>
<hr>
<h2 id="Large-Scale-Automatic-Audiobook-Creation"><a href="#Large-Scale-Automatic-Audiobook-Creation" class="headerlink" title="Large-Scale Automatic Audiobook Creation"></a>Large-Scale Automatic Audiobook Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03926">http://arxiv.org/abs/2309.03926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brendan Walsh, Mark Hamilton, Greg Newby, Xi Wang, Serena Ruan, Sheng Zhao, Lei He, Shaofei Zhang, Eric Dettinger, William T. Freeman, Markus Weimer</li>
<li>for:  This paper aims to improve the accessibility and engagement of literature by automatically generating high-quality audiobooks from online e-books.</li>
<li>methods:  The authors use recent advances in neural text-to-speech to create and release thousands of human-quality, open-license audiobooks from the Project Gutenberg e-book collection. They identify the proper subset of e-book content to read and can operate on hundreds of books in parallel, allowing users to customize the speaking speed, style, and emotional intonation of the audiobooks.</li>
<li>results:  The authors contributed over five thousand open-license audiobooks and an interactive demo that allows users to quickly create their own customized audiobooks. To listen to the audiobook collection, visit \url{<a target="_blank" rel="noopener" href="https://aka.ms/audiobook%7D">https://aka.ms/audiobook}</a>.<details>
<summary>Abstract</summary>
An audiobook can dramatically improve a work of literature's accessibility and improve reader engagement. However, audiobooks can take hundreds of hours of human effort to create, edit, and publish. In this work, we present a system that can automatically generate high-quality audiobooks from online e-books. In particular, we leverage recent advances in neural text-to-speech to create and release thousands of human-quality, open-license audiobooks from the Project Gutenberg e-book collection. Our method can identify the proper subset of e-book content to read for a wide collection of diversely structured books and can operate on hundreds of books in parallel. Our system allows users to customize an audiobook's speaking speed and style, emotional intonation, and can even match a desired voice using a small amount of sample audio. This work contributed over five thousand open-license audiobooks and an interactive demo that allows users to quickly create their own customized audiobooks. To listen to the audiobook collection visit \url{https://aka.ms/audiobook}.
</details>
<details>
<summary>摘要</summary>
audiobook可以大幅提高文学作品的可访问性和读者参与度。然而，制作audiobook需要数百个工作人员的努力来创建、编辑和发布。在这项工作中，我们介绍了一种系统，可以自动生成高质量的audiobook从在线电子书。特别是，我们利用了近期的神经网络文本读取技术来创建和发布数千个人质量高的开源audiobook从Project Gutenberg电子书集。我们的方法可以确定电子书内容的合适子集，并可以同时处理数百本书。我们的系统允许用户自定义audiobook的读音速度和风格，以及使用小量的示例音频来匹配所需的声音。这项工作已经提供了五千个开源audiobook以及一个互动 demo，允许用户快速创建自己的个性化audiobook。要听取音书集，请访问 \url{https://aka.ms/audiobook}.
</details></li>
</ul>
<hr>
<h2 id="Promoting-Fairness-in-GNNs-A-Characterization-of-Stability"><a href="#Promoting-Fairness-in-GNNs-A-Characterization-of-Stability" class="headerlink" title="Promoting Fairness in GNNs: A Characterization of Stability"></a>Promoting Fairness in GNNs: A Characterization of Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03648">http://arxiv.org/abs/2309.03648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaning Jia, Chunhui Zhang</li>
<li>for: 本研究旨在提出一种用于稳定 Graph Neural Networks（GNN）输出的方法，以满足在非欧几何数据上进行公平训练。</li>
<li>methods: 本研究使用了 Lipschitz 约束来限制 GNN 输出变动，并对输出变动进行分析，以确定输出变动的最大值。</li>
<li>results: 研究表明，使用 Lipschitz 约束可以有效地限制 GNN 输出变动，并且可以在训练过程中更好地平衡准确性和公平性。<details>
<summary>Abstract</summary>
The Lipschitz bound, a technique from robust statistics, can limit the maximum changes in the output concerning the input, taking into account associated irrelevant biased factors. It is an efficient and provable method for examining the output stability of machine learning models without incurring additional computation costs. Recently, Graph Neural Networks (GNNs), which operate on non-Euclidean data, have gained significant attention. However, no previous research has investigated the GNN Lipschitz bounds to shed light on stabilizing model outputs, especially when working on non-Euclidean data with inherent biases. Given the inherent biases in common graph data used for GNN training, it poses a serious challenge to constraining the GNN output perturbations induced by input biases, thereby safeguarding fairness during training. Recently, despite the Lipschitz constant's use in controlling the stability of Euclideanneural networks, the calculation of the precise Lipschitz constant remains elusive for non-Euclidean neural networks like GNNs, especially within fairness contexts. To narrow this gap, we begin with the general GNNs operating on an attributed graph, and formulate a Lipschitz bound to limit the changes in the output regarding biases associated with the input. Additionally, we theoretically analyze how the Lipschitz constant of a GNN model could constrain the output perturbations induced by biases learned from data for fairness training. We experimentally validate the Lipschitz bound's effectiveness in limiting biases of the model output. Finally, from a training dynamics perspective, we demonstrate why the theoretical Lipschitz bound can effectively guide the GNN training to better trade-off between accuracy and fairness.
</details>
<details>
<summary>摘要</summary>
“利普希茨范围”，一种从稳定统计学中的技术，可以限制输入变化所导致的输出变化，考虑到相关的无关偏调因素。这是一种有效和可证明的方法，可以无额外计算成本，检查机器学习模型的稳定性。最近，图 neural network（GNN），它们在非欧几何数据上运作，获得了很大的关注。然而，前一次的研究没有探讨GNN的利普希茨范围，对于稳定模型输出，尤其是在非欧几何数据上具有自然偏调的情况下。由于实际 graph 数据中的偏调，对于 GNN 的训练induced的输出干扰带来了严重的挑战，以保持公平性。虽然利普希茨常量在控制欧几何神经网络的稳定性中使用，但是非欧几何神经网络Like GNNs 的利普希茨常量的计算仍然是一个未解之处。为了填补这个 gap，我们从一般的 GNN 开始，定义一个利普希茨范围，以限制对于输入偏调的变化。此外，我们也进行了理论分析，该利普希茨常量如何对模型输出偏调带来的影响。我们还进行了实验 validate 利普希茨范围的有效性，限制模型输出偏调。最后，从训练动态的角度来看，我们显示了理论上的利普希茨范围可以有效地导引 GNN 训练，以更好地平衡精度和公平性。
</details></li>
</ul>
<hr>
<h2 id="VideolandGPT-A-User-Study-on-a-Conversational-Recommender-System"><a href="#VideolandGPT-A-User-Study-on-a-Conversational-Recommender-System" class="headerlink" title="VideolandGPT: A User Study on a Conversational Recommender System"></a>VideolandGPT: A User Study on a Conversational Recommender System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03645">http://arxiv.org/abs/2309.03645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mateo Gutierrez Granada, Dina Zilbershtein, Daan Odijk, Francesco Barile</li>
<li>for: 这个论文探讨了如何使用大语言模型（LLMs）提高推荐系统，特别是基于对话的推荐系统，该系统利用用户偏好和个性化候选选择来优化推荐结果。</li>
<li>methods: 该论文提出了一种基于ChatGPT的视频在线推荐系统，称为VideolandGPT，该系统使用ChatGPT选择 predetermined 集合中的内容，考虑用户与对话界面的互动提供的额外上下文。</li>
<li>results: 我们在用户研究中对两个版本的系统进行了比较，一个是个性化版本，另一个是非个性化版本。结果显示个性化版本在准确性和总体用户满意度方面表现出色，而两个版本都提高了不在推荐列表的ITEMS的可见性。然而，两个版本在公平性方面存在不一致的行为，系统可能生成不在Videoland上的推荐。<details>
<summary>Abstract</summary>
This paper investigates how large language models (LLMs) can enhance recommender systems, with a specific focus on Conversational Recommender Systems that leverage user preferences and personalised candidate selections from existing ranking models. We introduce VideolandGPT, a recommender system for a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select from a predetermined set of contents, considering the additional context indicated by users' interactions with a chat interface. We evaluate ranking metrics, user experience, and fairness of recommendations, comparing a personalised and a non-personalised version of the system, in a between-subject user study. Our results indicate that the personalised version outperforms the non-personalised in terms of accuracy and general user satisfaction, while both versions increase the visibility of items which are not in the top of the recommendation lists. However, both versions present inconsistent behavior in terms of fairness, as the system may generate recommendations which are not available on Videoland.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-XAI-Obstacles-Towards-Responsible-AI"><a href="#Beyond-XAI-Obstacles-Towards-Responsible-AI" class="headerlink" title="Beyond XAI:Obstacles Towards Responsible AI"></a>Beyond XAI:Obstacles Towards Responsible AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03638">http://arxiv.org/abs/2309.03638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulu Pi</li>
<li>for: 这篇论文主要是为了探讨Explainable Artificial Intelligence（XAI）领域的发展，并提出了一些用于使AI系统更加透明和理解的技术。</li>
<li>methods: 本论文使用了一些现有的解释性技术，并评估了这些技术在实际应用中的局限性。</li>
<li>results: 本论文发现了许多解释性技术和评估策略在实际应用中存在一些限制，并讨论了这些限制对负责任AI的扩展发展的影响。<details>
<summary>Abstract</summary>
The rapidly advancing domain of Explainable Artificial Intelligence (XAI) has sparked significant interests in developing techniques to make AI systems more transparent and understandable. Nevertheless, in real-world contexts, the methods of explainability and their evaluation strategies present numerous limitations.Moreover, the scope of responsible AI extends beyond just explainability. In this paper, we explore these limitations and discuss their implications in a boarder context of responsible AI when considering other important aspects, including privacy, fairness and contestability.
</details>
<details>
<summary>摘要</summary>
rapidly advancing domain of Explainable Artificial Intelligence (XAI) has sparked significant interests in developing techniques to make AI systems more transparent and understandable. Nevertheless, in real-world contexts, the methods of explainability and their evaluation strategies present numerous limitations.Moreover, the scope of responsible AI extends beyond just explainability. In this paper, we explore these limitations and discuss their implications in a boarder context of responsible AI when considering other important aspects, including privacy, fairness and contestability.Here's the word-for-word translation:快速发展的解释人工智能（XAI）领域引起了广泛的关注，旨在开发更加透明和理解的人工智能系统。然而，在实际应用场景中，解释方法和评估策略具有多种限制。此外，负责任人工智能的范围不仅包括解释性，还包括隐私、公平和竞争等重要方面。在本文中，我们探讨这些限制的影响，并在更广泛的负责任人工智能框架下讨论它们的意义。
</details></li>
</ul>
<hr>
<h2 id="NeuroCodeBench-a-plain-C-neural-network-benchmark-for-software-verification"><a href="#NeuroCodeBench-a-plain-C-neural-network-benchmark-for-software-verification" class="headerlink" title="NeuroCodeBench: a plain C neural network benchmark for software verification"></a>NeuroCodeBench: a plain C neural network benchmark for software verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03617">http://arxiv.org/abs/2309.03617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Manino, Rafael Sá Menezes, Fedor Shmarov, Lucas C. Cordeiro</li>
<li>for: 这篇论文是为了证明神经网络组件中的强制保证。</li>
<li>methods: 论文使用了平台C编程的神经网络代码进行验证。</li>
<li>results: 验证结果表明，现有的软件验证工具无法证明神经网络实现中的软件问题。<details>
<summary>Abstract</summary>
Safety-critical systems with neural network components require strong guarantees. While existing neural network verification techniques have shown great progress towards this goal, they cannot prove the absence of software faults in the network implementation. This paper presents NeuroCodeBench - a verification benchmark for neural network code written in plain C. It contains 32 neural networks with 607 safety properties divided into 6 categories: maths library, activation functions, error-correcting networks, transfer function approximation, probability density estimation and reinforcement learning. Our preliminary evaluation shows that state-of-the-art software verifiers struggle to provide correct verdicts, due to their incomplete support of the standard C mathematical library and the complexity of larger neural networks.
</details>
<details>
<summary>摘要</summary>
安全关键系统中的神经网络组件需要强大的保证。现有的神经网络验证技术已经取得了很大的进步，但它们无法证明神经网络实现中的软件问题。这篇文章介绍了NeuroCodeBench，一个用于神经网络代码中的权威验证标准。它包含32个神经网络，607个安全性特性，分为6个类别：数学库、激活函数、错误修复网络、传输函数近似、概率密度估计和奖励学习。我们的初步评估表明，现有的软件验证工具很难提供正确的判决，因为它们对标准C语言数学库的支持不够完善，大神经网络的复杂性也很高。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-ChatGPT-as-a-Recommender-System-A-Rigorous-Approach"><a href="#Evaluating-ChatGPT-as-a-Recommender-System-A-Rigorous-Approach" class="headerlink" title="Evaluating ChatGPT as a Recommender System: A Rigorous Approach"></a>Evaluating ChatGPT as a Recommender System: A Rigorous Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03613">http://arxiv.org/abs/2309.03613</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sisinflab/Recommender-ChatGPT">https://github.com/sisinflab/Recommender-ChatGPT</a></li>
<li>paper_authors: Dario Di Palma, Giovanni Maria Biancofiore, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia, Eugenio Di Sciascio</li>
<li>for: 这种研究旨在探索ChatGPT作为零次推荐系统的可能性，以评估其根据用户喜好进行推荐、重新排序现有推荐列表、利用类似用户的信息和冷启动情况下的表现。</li>
<li>methods: 该研究使用了MovieLens Small、Last.FM和Facebook Book三个数据集，对ChatGPT的表现进行了广泛的实验，并与标准推荐算法和其他大语言模型进行比较，如GPT-3.5和PaLM-2。用于评估推荐效果的评价指标包括MAP、Recall、Precision、F1、nDCG、Item Coverage、EPC、ACLT和ARP等。</li>
<li>results: 研究发现ChatGPT在推荐领域的表现很出色，具有较高的MAP、Recall和Precision值，同时也具有较好的 Item Coverage、EPC、ACLT和ARP值。与标准推荐算法和其他大语言模型进行比较，ChatGPT的表现也很出色。<details>
<summary>Abstract</summary>
Recent popularity surrounds large AI language models due to their impressive natural language capabilities. They contribute significantly to language-related tasks, including prompt-based learning, making them valuable for various specific tasks. This approach unlocks their full potential, enhancing precision and generalization. Research communities are actively exploring their applications, with ChatGPT receiving recognition. Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance against standard recommendation algorithms and other large language models, such as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ widely-used evaluation metrics like Mean Average Precision (MAP), Recall, Precision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage, Expected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT), Average Recommendation Popularity (ARP), and Popularity-based Ranking-based Equal Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in recommender systems, our study aims to contribute to the growing body of research on the versatility and potential applications of large language models. Our experiment code is available on the GitHub repository: https://github.com/sisinflab/Recommender-ChatGPT
</details>
<details>
<summary>摘要</summary>
现在，大型人工智能语言模型因其自然语言能力而受到广泛关注。它们在语言相关任务中发挥了重要作用，包括提示学习，使其在各种特定任务中成为了珍贵的资源。这种方法可以激活它们的潜力，提高精度和通用性。研究人员 aktif explore其应用，如ChatGPT receiving recognition。Despite extensive research on large language models, their potential in recommendation scenarios still needs to be explored. This study aims to fill this gap by investigating ChatGPT's capabilities as a zero-shot recommender system. Our goals include evaluating its ability to use user preferences for recommendations, reordering existing recommendation lists, leveraging information from similar users, and handling cold-start situations. We assess ChatGPT's performance through comprehensive experiments using three datasets (MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance against standard recommendation algorithms and other large language models, such as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ widely-used evaluation metrics like Mean Average Precision (MAP), Recall, Precision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage, Expected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT), Average Recommendation Popularity (ARP), and Popularity-based Ranking-based Equal Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in recommender systems, our study aims to contribute to the growing body of research on the versatility and potential applications of large language models. Our experiment code is available on the GitHub repository: <https://github.com/sisinflab/Recommender-ChatGPT>
</details></li>
</ul>
<hr>
<h2 id="Spatial-encoding-of-BOLD-fMRI-time-series-for-categorizing-static-images-across-visual-datasets-A-pilot-study-on-human-vision"><a href="#Spatial-encoding-of-BOLD-fMRI-time-series-for-categorizing-static-images-across-visual-datasets-A-pilot-study-on-human-vision" class="headerlink" title="Spatial encoding of BOLD fMRI time series for categorizing static images across visual datasets: A pilot study on human vision"></a>Spatial encoding of BOLD fMRI time series for categorizing static images across visual datasets: A pilot study on human vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03590">http://arxiv.org/abs/2309.03590</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kancharlavamshi/Spatial-encoding-of-BOLD-fmri-time-series-for-categorical-static-images-across-visual-dataset">https://github.com/kancharlavamshi/Spatial-encoding-of-BOLD-fmri-time-series-for-categorical-static-images-across-visual-dataset</a></li>
<li>paper_authors: Vamshi K. Kancharala, Debanjali Bhattacharya, Neelam Sinha</li>
<li>for: 这个研究用于了解人脑如何处理不同复杂度的图像，以便更好地理解视觉功能。</li>
<li>methods: 这个研究使用了功能磁共振成像（fMRI）时间序列（TS），使用类别幂angular field（GAF）和马尔可夫过渡场（MTF）进行空间编码，并使用了多层感知网络（CNN）进行分类。</li>
<li>results: 研究发现，并行的CNN模型在分类图像 across COCO、ImageNet和SUN三个标准计算机视觉数据集时表现出色，与其他网络模型相比，提高了7%的多类分类精度。<details>
<summary>Abstract</summary>
Functional MRI (fMRI) is widely used to examine brain functionality by detecting alteration in oxygenated blood flow that arises with brain activity. In this study, complexity specific image categorization across different visual datasets is performed using fMRI time series (TS) to understand differences in neuronal activities related to vision. Publicly available BOLD5000 dataset is used for this purpose, containing fMRI scans while viewing 5254 images of diverse categories, drawn from three standard computer vision datasets: COCO, ImageNet and SUN. To understand vision, it is important to study how brain functions while looking at different images. To achieve this, spatial encoding of fMRI BOLD TS has been performed that uses classical Gramian Angular Field (GAF) and Markov Transition Field (MTF) to obtain 2D BOLD TS, representing images of COCO, Imagenet and SUN. For classification, individual GAF and MTF features are fed into regular CNN. Subsequently, parallel CNN model is employed that uses combined 2D features for classifying images across COCO, Imagenet and SUN. The result of 2D CNN models is also compared with 1D LSTM and Bi-LSTM that utilizes raw fMRI BOLD signal for classification. It is seen that parallel CNN model outperforms other network models with an improvement of 7% for multi-class classification. Clinical relevance- The obtained result of this analysis establishes a baseline in studying how differently human brain functions while looking at images of diverse complexities.
</details>
<details>
<summary>摘要</summary>
Functional MRI (fMRI) 广泛用于评估大脑功能，通过检测大脑活动引起的氧游泡流变化。在这项研究中，使用 fMRI 时间序列（TS）来分类不同的视觉数据集，以了解与视觉相关的神经活动之间的差异。使用公共可用的 BOLD5000 数据集，包括在视觉 5254 个不同类别的图像上进行 fMRI 扫描，这些图像来自三个标准计算机视觉数据集：COCO、ImageNet 和 SUN。为了理解视觉，需要研究大脑如何在不同的图像上工作。为此，使用类传统的 Gramian Angular Field (GAF) 和 Markov Transition Field (MTF) 来获得 2D BOLD TS，表示 COCO、ImageNet 和 SUN 三个数据集中的图像。然后，使用各自 GAF 和 MTF 特征进行分类，并使用并行的 CNN 模型来结合这些 2D 特征进行图像分类。结果表明，并行 CNN 模型在多类分类中比其他网络模型提高了7%。临床相关性：这项分析的结果建立了对于研究人类大脑在不同复杂度的图像上如何工作的基线。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Hyperparameter-Optimization-in-Multi-Objective-Problems-via-Preference-Learning"><a href="#Interactive-Hyperparameter-Optimization-in-Multi-Objective-Problems-via-Preference-Learning" class="headerlink" title="Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning"></a>Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03581">http://arxiv.org/abs/2309.03581</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/automl/interactive-mo-ml">https://github.com/automl/interactive-mo-ml</a></li>
<li>paper_authors: Joseph Giovanelli, Alexander Tornede, Tanja Tornede, Marius Lindauer</li>
<li>for: 本文主要用于解决多目标机器学习（MO-ML）中的超参数优化问题，即在多个目标之间找到最佳的超参数配置。</li>
<li>methods: 本文提出了一种人类中心的交互式超参数优化方法，利用喜好学习提取用户需求，而不是让用户手动选择合适的指标。</li>
<li>results: 实验研究表明，该方法可以比用户手动选择的指标优化超参数，并且在高级用户知道选择哪个指标时表现相当。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Hyperparameter optimization (HPO) is important to leverage the full potential of machine learning (ML). In practice, users are often interested in multi-objective (MO) problems, i.e., optimizing potentially conflicting objectives, like accuracy and energy consumption. To tackle this, the vast majority of MO-ML algorithms return a Pareto front of non-dominated machine learning models to the user. Optimizing the hyperparameters of such algorithms is non-trivial as evaluating a hyperparameter configuration entails evaluating the quality of the resulting Pareto front. In literature, there are known indicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by quantifying different properties (e.g., volume, proximity to a reference point). However, choosing the indicator that leads to the desired Pareto front might be a hard task for a user. In this paper, we propose a human-centered interactive HPO approach tailored towards multi-objective ML leveraging preference learning to extract desiderata from users that guide the optimization. Instead of relying on the user guessing the most suitable indicator for their needs, our approach automatically learns an appropriate indicator. Concretely, we leverage pairwise comparisons of distinct Pareto fronts to learn such an appropriate quality indicator. Then, we optimize the hyperparameters of the underlying MO-ML algorithm towards this learned indicator using a state-of-the-art HPO approach. In an experimental study targeting the environmental impact of ML, we demonstrate that our approach leads to substantially better Pareto fronts compared to optimizing based on a wrong indicator pre-selected by the user, and performs comparable in the case of an advanced user knowing which indicator to pick.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们提出了一种人类中心的交互式 HPO 方法，适应多目标 ML 的需求。不同于基于用户的猜测来选择最适合的指标，我们的方法会自动学习一个适当的指标。具体来说，我们利用 Pareto 前纵之间的对比来学习这个适当的质量指标。然后，我们使用现有的 HPO 方法来优化超参数，以便以该学习的指标来评估 Pareto 前纵的质量。在针对机器学习的环境影响的实验研究中，我们示出了我们的方法可以相比于用户预先选择的指标来优化 Pareto 前纵，并且在用户了解哪个指标最适合的情况下，我们的方法可以与其相比。
</details></li>
</ul>
<hr>
<h2 id="DTW-S-Shape-based-Comparison-of-Time-series-with-Ordered-Local-Trend"><a href="#DTW-S-Shape-based-Comparison-of-Time-series-with-Ordered-Local-Trend" class="headerlink" title="DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend"></a>DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03579">http://arxiv.org/abs/2309.03579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scc-usc/DTW_S_apps">https://github.com/scc-usc/DTW_S_apps</a></li>
<li>paper_authors: Ajitesh Srivastava</li>
<li>for: 本研究旨在开发一种可以识别时间序列数据中相似的趋势的度量方法，用于应用领域中的分类和归类。</li>
<li>methods: 本研究使用DTW+S方法，该方法首先将时间序列数据转换为可读性好的“相似性保持”矩阵表示，其中每列表示当地趋势，然后应用动态时间戳匹配来计算这些矩阵之间的距离。</li>
<li>results: 研究表明，DTW+S方法可以更好地识别时间序列数据中的相似趋势，特别是当本地趋势比矩阵规模具有更大的重要性时。此外，DTW+S方法也可以在 ensemble 建立和时间序列数据的归类中得到更好的结果。<details>
<summary>Abstract</summary>
Measuring distance or similarity between time-series data is a fundamental aspect of many applications including classification and clustering. Existing measures may fail to capture similarities due to local trends (shapes) and may even produce misleading results. Our goal is to develop a measure that looks for similar trends occurring around similar times and is easily interpretable for researchers in applied domains. This is particularly useful for applications where time-series have a sequence of meaningful local trends that are ordered, such as in epidemics (a surge to an increase to a peak to a decrease). We propose a novel measure, DTW+S, which creates an interpretable "closeness-preserving" matrix representation of the time-series, where each column represents local trends, and then it applies Dynamic Time Warping to compute distances between these matrices. We present a theoretical analysis that supports the choice of this representation. We demonstrate the utility of DTW+S in ensemble building and clustering of epidemic curves. We also demonstrate that our approach results in better classification compared to Dynamic Time Warping for a class of datasets, particularly when local trends rather than scale play a decisive role.
</details>
<details>
<summary>摘要</summary>
We propose a novel measure, DTW+S, which creates an interpretable "closeness-preserving" matrix representation of the time-series, where each column represents local trends, and then applies Dynamic Time Warping to compute distances between these matrices. We present a theoretical analysis that supports the choice of this representation.We demonstrate the utility of DTW+S in ensemble building and clustering of epidemic curves. We also show that our approach results in better classification compared to Dynamic Time Warping for a class of datasets, particularly when local trends rather than scale play a decisive role.Translated into Simplified Chinese:时间序列数据的距离或相似性的评估是许多应用程序中的基本要求，包括分类和归类。现有的度量可能不能捕捉相似性，因为它们可能忽略地方趋势（形状），甚至生成错误的结果。我们的目标是开发一种度量，它搜寻在相似时间点上的相似趋势，并且能够让应用领域研究者更好地理解。这特别有用于具有意义的地方趋势的时间序列，例如疫病肆虐（增长到峰值到减少）。我们提出了一种新的度量方法，DTW+S，它创建了可解释的“亲缘性保持”矩阵表示时间序列，每列表示地方趋势，然后应用动态时间戳对这些矩阵进行计算距离。我们提供了理论分析，支持我们的选择。我们示出DTW+S在套件建立和时间序列归类中的实用性。我们还表明，当地方趋势而不是比例决定时，我们的方法比动态时间戳更好地分类。
</details></li>
</ul>
<hr>
<h2 id="Reuse-and-Diffuse-Iterative-Denoising-for-Text-to-Video-Generation"><a href="#Reuse-and-Diffuse-Iterative-Denoising-for-Text-to-Video-Generation" class="headerlink" title="Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation"></a>Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03549">http://arxiv.org/abs/2309.03549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Gu, Shicong Wang, Haoyu Zhao, Tianyi Lu, Xing Zhang, Zuxuan Wu, Songcen Xu, Wei Zhang, Yu-Gang Jiang, Hang Xu</li>
<li>for: 本研究旨在应用Latent Diffusion Models（LDM）于文本到视频生成，这是一项复杂的挑战，因为模型训练和推断过程中的计算和存储限制。</li>
<li>methods: 我们提出了一个名为“Reuse and Diffuse”的框架，称为$\textit{VidRD}$，用于生成更多的视频帧。我们conditioned on an initial video clip with a small number of frames，iteratively generate additional frames by reusing the original latent features and following the previous diffusion process。此外，我们还在权重网中添加了时间层，并对这些层进行了微调以提高时间一致性。</li>
<li>results: 我们的方法在量化和质量评估中都达到了良好的结果。我们的项目页面可以在 $\href{<a target="_blank" rel="noopener" href="https://anonymous0x233.github.io/ReuseAndDiffuse/%7D%7Bhere%7D$">https://anonymous0x233.github.io/ReuseAndDiffuse/}{here}$</a> 上找到。<details>
<summary>Abstract</summary>
Inspired by the remarkable success of Latent Diffusion Models (LDMs) for image synthesis, we study LDM for text-to-video generation, which is a formidable challenge due to the computational and memory constraints during both model training and inference. A single LDM is usually only capable of generating a very limited number of video frames. Some existing works focus on separate prediction models for generating more video frames, which suffer from additional training cost and frame-level jittering, however. In this paper, we propose a framework called "Reuse and Diffuse" dubbed $\textit{VidRD}$ to produce more frames following the frames already generated by an LDM. Conditioned on an initial video clip with a small number of frames, additional frames are iteratively generated by reusing the original latent features and following the previous diffusion process. Besides, for the autoencoder used for translation between pixel space and latent space, we inject temporal layers into its decoder and fine-tune these layers for higher temporal consistency. We also propose a set of strategies for composing video-text data that involve diverse content from multiple existing datasets including video datasets for action recognition and image-text datasets. Extensive experiments show that our method achieves good results in both quantitative and qualitative evaluations. Our project page is available $\href{https://anonymous0x233.github.io/ReuseAndDiffuse/}{here}$.
</details>
<details>
<summary>摘要</summary>
受 latent diffusion models (LDMs) 的成功启发，我们研究了 LDM 的文本到视频生成，这是一项具有计算和内存约束的挑战。通常情况下，一个 LDM 只能生成一个非常有限的数量的视频帧。一些现有的方法是通过分立预测模型来生成更多的视频帧，但这会增加训练成本和帧级抖动。在这篇论文中，我们提出了一个名为“Reuse and Diffuse”的框架，称为 $\textit{VidRD}$，用于生成更多的视频帧。基于一个初始的视频片段，我们通过重用原始的秘密特征和前一个扩散过程来生成更多的帧。此外，我们在干扰层中插入了时间层，并对这些层进行了精细调整，以提高时间一致性。我们还提出了一些组合视频-文本数据的策略，包括多个现有数据集的视频数据和图像-文本数据。我们的实验表明，我们的方法在量和质量两个方面都取得了良好的结果。我们的项目页面可以在 $\href{https://anonymous0x233.github.io/ReuseAndDiffuse/}{这里}$ 找到。
</details></li>
</ul>
<hr>
<h2 id="DGC-Training-Dynamic-Graphs-with-Spatio-Temporal-Non-Uniformity-using-Graph-Partitioning-by-Chunks"><a href="#DGC-Training-Dynamic-Graphs-with-Spatio-Temporal-Non-Uniformity-using-Graph-Partitioning-by-Chunks" class="headerlink" title="DGC: Training Dynamic Graphs with Spatio-Temporal Non-Uniformity using Graph Partitioning by Chunks"></a>DGC: Training Dynamic Graphs with Spatio-Temporal Non-Uniformity using Graph Partitioning by Chunks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03523">http://arxiv.org/abs/2309.03523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fahao Chen, Peng Li, Celimuge Wu</li>
<li>for: 这个研究旨在提高动态图神经网络（DGNN）的训练效率，建立一个分布式系统来加速DGNN训练。</li>
<li>methods: 本研究提出了一种基于图缩放的分割策略，将动态图分割成更小的块，以便更好地分配工作负荷到多个GPU上。此外，本研究还提出了一种粗略汇集和自适应停止汇集技术来提高训练效率。</li>
<li>results:  experiments 表明，与现有的状态OF-THE-ART系统相比，DGC可以在测试环境中 achieve 1.25x - 7.52x的速度提升。此外，DGC还具有高效的运行时，可以快速地处理大型图。<details>
<summary>Abstract</summary>
Dynamic Graph Neural Network (DGNN) has shown a strong capability of learning dynamic graphs by exploiting both spatial and temporal features. Although DGNN has recently received considerable attention by AI community and various DGNN models have been proposed, building a distributed system for efficient DGNN training is still challenging. It has been well recognized that how to partition the dynamic graph and assign workloads to multiple GPUs plays a critical role in training acceleration. Existing works partition a dynamic graph into snapshots or temporal sequences, which only work well when the graph has uniform spatio-temporal structures. However, dynamic graphs in practice are not uniformly structured, with some snapshots being very dense while others are sparse. To address this issue, we propose DGC, a distributed DGNN training system that achieves a 1.25x - 7.52x speedup over the state-of-the-art in our testbed. DGC's success stems from a new graph partitioning method that partitions dynamic graphs into chunks, which are essentially subgraphs with modest training workloads and few inter connections. This partitioning algorithm is based on graph coarsening, which can run very fast on large graphs. In addition, DGC has a highly efficient run-time, powered by the proposed chunk fusion and adaptive stale aggregation techniques. Extensive experimental results on 3 typical DGNN models and 4 popular dynamic graph datasets are presented to show the effectiveness of DGC.
</details>
<details>
<summary>摘要</summary>
“几何对应神经网络”（DGNN）有强大的能力学习动态图，利用图形空间和时间特征。 although DGNN 在艺术社群中获得了很大的关注，并提出了许多DGNN 模型，但是建立高效的DGNN 训练分布式系统仍然是挑战。 existing works 将动态图 partitioned  into snapshots or temporal sequences，这些方法只有在图形中具有均匀的空间-时间结构下可以实现高效。 然而，实际上的动态图不具有均匀的结构，有些快照是非常紧密的，而其他快照则是疏松的。 为了解决这个问题，我们提出了DGC，一个高效的分布式DGNN 训练系统，在我们的测试环境中实现了1.25x至7.52x的速度提升。 DGC 的成功从一种新的图形分割方法中获得，这种分割方法将动态图分成块，这些块是具有轻量级训练工作和少量的相互连接的子图。 这个分割算法基于图形缩小，可以在大型图上执行非常快速。 此外，DGC 还具有非常高效的执行时间，推动了我们提出的块融合和自适应统计聚合技术。 实际实验结果显示，DGC 在3种常见的 DGNN 模型和4种受欢迎的动态图dataset上具有很高的效果。”
</details></li>
</ul>
<hr>
<h2 id="Parameterized-Aspects-of-Distinct-Kemeny-Rank-Aggregation"><a href="#Parameterized-Aspects-of-Distinct-Kemeny-Rank-Aggregation" class="headerlink" title="Parameterized Aspects of Distinct Kemeny Rank Aggregation"></a>Parameterized Aspects of Distinct Kemeny Rank Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03517">http://arxiv.org/abs/2309.03517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Koustav De, Harshil Mittal, Palash Dey, Neeldhara Misra</li>
<li>for: 本文研究了使用基美方法进行排名聚合的计算问题，特别是在不同参数下的计算复杂性。</li>
<li>methods: 本文使用了参数化复杂性的概念，研究了不同参数下的计算复杂性，并提供了一系列的FPTP算法来解决这些问题。</li>
<li>results: 本文发现了在不同参数下，可以使用FPTP算法来计算基美排名，并且可以在Running time中得到满意的结果。此外，本文还提供了FPTPapproximation算法来解决基美排名聚合问题。<details>
<summary>Abstract</summary>
The Kemeny method is one of the popular tools for rank aggregation. However, computing an optimal Kemeny ranking is NP-hard. Consequently, the computational task of finding a Kemeny ranking has been studied under the lens of parameterized complexity with respect to many parameters. We first present a comprehensive relationship, both theoretical and empirical, among these parameters. Further, we study the problem of computing all distinct Kemeny rankings under the lens of parameterized complexity. We consider the target Kemeny score, number of candidates, average distance of input rankings, maximum range of any candidate, and unanimity width as our parameters. For all these parameters, we already have FPT algorithms. We find that any desirable number of Kemeny rankings can also be found without substantial increase in running time. We also present FPT approximation algorithms for Kemeny rank aggregation with respect to these parameters.
</details>
<details>
<summary>摘要</summary>
“凯曼尼方法是一种受欢迎的选举排名协调工具。然而，计算优化的凯曼尼排名是NP困难的。因此，计算找到凯曼尼排名的计算任务在参数化复杂性下被研究。我们首先提供了完整的关系，both theoretically和empirically， Among these parameters. Furthermore, we study the problem of computing all distinct Kemeny rankings under the lens of parameterized complexity. We consider the target Kemeny score, number of candidates, average distance of input rankings, maximum range of any candidate, and unanimity width as our parameters. For all these parameters, we already have FPT algorithms. We find that any desirable number of Kemeny rankings can also be found without substantial increase in running time. We also present FPT approximation algorithms for Kemeny rank aggregation with respect to these parameters.”Note: FPT stands for "parameterized tractable" and refers to the fact that the algorithm's running time is bounded by a function of the input size and the parameter, rather than the input size alone.
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Natural-Looking-Mammography-Lesion-Synthesis-on-Ipsilateral-Dual-Views-Breast-Cancer-Analysis"><a href="#Towards-Robust-Natural-Looking-Mammography-Lesion-Synthesis-on-Ipsilateral-Dual-Views-Breast-Cancer-Analysis" class="headerlink" title="Towards Robust Natural-Looking Mammography Lesion Synthesis on Ipsilateral Dual-Views Breast Cancer Analysis"></a>Towards Robust Natural-Looking Mammography Lesion Synthesis on Ipsilateral Dual-Views Breast Cancer Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03506">http://arxiv.org/abs/2309.03506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh-Huy Nguyen, Quang Hien Kha, Thai Ngoc Toan Truong, Ba Thinh Lam, Ba Hung Ngo, Quang Vinh Dinh, Nguyen Quoc Khanh Le</li>
<li>for: 提高癌症分类任务的精度和效率</li>
<li>methods: 利用多视图环境和简单且可靠的SynthMix框架，杜绝训练和测试阶段的分类器</li>
<li>results: 在VinDr-Mammo和CMMD数据集上实现了新方法的效果，比较前一代方法在实验设置中的表现<details>
<summary>Abstract</summary>
In recent years, many mammographic image analysis methods have been introduced for improving cancer classification tasks. Two major issues of mammogram classification tasks are leveraging multi-view mammographic information and class-imbalance handling. In the first problem, many multi-view methods have been released for concatenating features of two or more views for the training and inference stage. Having said that, most multi-view existing methods are not explainable in the meaning of feature fusion, and treat many views equally for diagnosing. Our work aims to propose a simple but novel method for enhancing examined view (main view) by leveraging low-level feature information from the auxiliary view (ipsilateral view) before learning the high-level feature that contains the cancerous features. For the second issue, we also propose a simple but novel malignant mammogram synthesis framework for upsampling minor class samples. Our easy-to-implement and no-training framework has eliminated the current limitation of the CutMix algorithm which is unreliable synthesized images with random pasted patches, hard-contour problems, and domain shift problems. Our results on VinDr-Mammo and CMMD datasets show the effectiveness of our two new frameworks for both multi-view training and synthesizing mammographic images, outperforming the previous conventional methods in our experimental settings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="InteractionNet-Joint-Planning-and-Prediction-for-Autonomous-Driving-with-Transformers"><a href="#InteractionNet-Joint-Planning-and-Prediction-for-Autonomous-Driving-with-Transformers" class="headerlink" title="InteractionNet: Joint Planning and Prediction for Autonomous Driving with Transformers"></a>InteractionNet: Joint Planning and Prediction for Autonomous Driving with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03475">http://arxiv.org/abs/2309.03475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawei Fu, Yanqing Shen, Zhiqiang Jian, Shitao Chen, Jingmin Xin, Nanning Zheng</li>
<li>for: 本研究旨在提高自动驾驶车辆的规划和预测模块，以便更好地处理交通场景中的互动和动态变化。</li>
<li>methods: 本研究使用 transformer 来共享全局上下文推理，并将规划和预测融合在一起，以实现联合推理。此外，模型还使用另一个 transformer 来增强对感知区域中的车辆的注意力。</li>
<li>results: 相比其他基线模型，InteractionNet 在多个测试 benchmark 中表现出色，特别是在安全性方面，这主要归功于规划和预测的联合考虑。模型的代码将于 GitHub 上公开。<details>
<summary>Abstract</summary>
Planning and prediction are two important modules of autonomous driving and have experienced tremendous advancement recently. Nevertheless, most existing methods regard planning and prediction as independent and ignore the correlation between them, leading to the lack of consideration for interaction and dynamic changes of traffic scenarios. To address this challenge, we propose InteractionNet, which leverages transformer to share global contextual reasoning among all traffic participants to capture interaction and interconnect planning and prediction to achieve joint. Besides, InteractionNet deploys another transformer to help the model pay extra attention to the perceived region containing critical or unseen vehicles. InteractionNet outperforms other baselines in several benchmarks, especially in terms of safety, which benefits from the joint consideration of planning and forecasting. The code will be available at https://github.com/fujiawei0724/InteractionNet.
</details>
<details>
<summary>摘要</summary>
《计划和预测两个重要模块在自动驾驶中受到了极大的提高。然而，大多数现有方法假设计划和预测是独立的，忽略了交通enario中参与者之间的交互关系和动态变化，导致缺乏考虑安全性。为解决这个挑战，我们提出了InteractionNet，它利用转换器来共享全局上下文推理，以捕捉交互和连接计划和预测，实现共同。此外，InteractionNet还部署了另一个转换器，使模型更注重感知区域中的重要或未经见过的车辆。InteractionNet在多个标准测试中表现出色，特别是在安全性方面，受到了计划和预测的共同考虑的启示。代码将在https://github.com/fujiawei0724/InteractionNet上公开。》Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Discern-Evidence-for-Scientific-Hypotheses-Case-Studies-in-the-Social-Sciences"><a href="#Can-Large-Language-Models-Discern-Evidence-for-Scientific-Hypotheses-Case-Studies-in-the-Social-Sciences" class="headerlink" title="Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences"></a>Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06578">http://arxiv.org/abs/2309.06578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Koneru, Jian Wu, Sarah Rajtmajer</li>
<li>for: 本研究的目的是使用大型自然语言模型（LLM）来探索科学Abstract中支持或驳斥特定假设的证据。</li>
<li>methods: 本研究使用了社会科学领域的社区驱动标注来创建了一个新的数据集，并对多种现有的状况标准比较LLM的表现。</li>
<li>results: 研究发现LLM可以准确地检测出科学Abstract中支持或驳斥特定假设的证据，并且可以与多种现有的状况标准进行比较。同时，研究还提出了未来研究的可能性，例如针对不同领域的研究和更多的数据集创建等。<details>
<summary>Abstract</summary>
Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Fast-FixMatch-Faster-Semi-Supervised-Learning-with-Curriculum-Batch-Size"><a href="#Fast-FixMatch-Faster-Semi-Supervised-Learning-with-Curriculum-Batch-Size" class="headerlink" title="Fast FixMatch: Faster Semi-Supervised Learning with Curriculum Batch Size"></a>Fast FixMatch: Faster Semi-Supervised Learning with Curriculum Batch Size</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03469">http://arxiv.org/abs/2309.03469</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Chen, Chen Dun, Anastasios Kyrillidis</li>
<li>for: 本研究的目的是提出一种名为快速匹配（Fast FixMatch）的新ssl算法，以提高 semi-supervised learning（ssl）的效率和性能。</li>
<li>methods: 本研究使用了一种名为batch size curriculum（CBS）的方法，即在训练过程中逐渐增加无标签批处理的大小，以便降低训练计算量。此外，本研究还使用了强制标签扩展（strong labeled augmentation）和pseudo标签生成（CPL）等技术。</li>
<li>results: 本研究的结果表明，使用CBS和强制标签扩展&#x2F;CPL可以 synergistically提高ssl的性能，同时降低训练计算量。具体来说，在CIFAR-10、CIFAR-100、SVHN和STL-10等 datasets上，快速匹配可以在所有 except 40、250和4000个标签 removed情况下实现2.1-3.4倍的训练计算量减少，而且与相同的参考状态得到同等的错误率。此外，快速匹配还可以在联合学习ssl任务和在线&#x2F;流式学习ssl任务中实现2.6-3.3倍的训练计算量减少。<details>
<summary>Abstract</summary>
Advances in Semi-Supervised Learning (SSL) have almost entirely closed the gap between SSL and Supervised Learning at a fraction of the number of labels. However, recent performance improvements have often come \textit{at the cost of significantly increased training computation}. To address this, we propose Curriculum Batch Size (CBS), \textit{an unlabeled batch size curriculum which exploits the natural training dynamics of deep neural networks.} A small unlabeled batch size is used in the beginning of training and is gradually increased to the end of training. A fixed curriculum is used regardless of dataset, model or number of epochs, and reduced training computations is demonstrated on all settings. We apply CBS, strong labeled augmentation, Curriculum Pseudo Labeling (CPL) \citep{FlexMatch} to FixMatch \citep{FixMatch} and term the new SSL algorithm Fast FixMatch. We perform an ablation study to show that strong labeled augmentation and/or CPL do not significantly reduce training computations, but, in synergy with CBS, they achieve optimal performance. Fast FixMatch also achieves substantially higher data utilization compared to previous state-of-the-art. Fast FixMatch achieves between $2.1\times$ - $3.4\times$ reduced training computations on CIFAR-10 with all but 40, 250 and 4000 labels removed, compared to vanilla FixMatch, while attaining the same cited state-of-the-art error rate \citep{FixMatch}. Similar results are achieved for CIFAR-100, SVHN and STL-10. Finally, Fast MixMatch achieves between $2.6\times$ - $3.3\times$ reduced training computations in federated SSL tasks and online/streaming learning SSL tasks, which further demonstrate the generializbility of Fast MixMatch to different scenarios and tasks.
</details>
<details>
<summary>摘要</summary>
SSL 技术的进步已经几乎完全将 semi-supervised learning (SSL) 和直接学习 (Supervised Learning) 的差距缩小到了一半，但是最近的性能改进通常是在增加训练计算的代价下得来的。为解决这个问题，我们提议了批处理大小学习纲（Curriculum Batch Size，CBS），它利用深度神经网络的自然训练dinamics来逐渐增加无标记批处理大小。我们在所有设置下使用了一个固定的学习纲，并且证明了它可以减少训练计算。我们将CBS、强大的标记增强、CURRICULUM PSEUDO LABELING（CPL）和 FixMatch 结合使用，并将其称为 Fast FixMatch。我们进行了一个ablation study，并证明了强大的标记增强和/或 CPL 不会减少训练计算，但是在协同作用下，它们可以达到最佳性能。 Fast FixMatch 还实现了较高的数据利用率，相比前一代 state-of-the-art。我们在 CIFAR-10、CIFAR-100、SVHN 和 STL-10 上进行了相似的实验，并得到了类似的结果。最后，Fast MixMatch 在 federated SSL 任务和在线/流式学习 SSL 任务中实现了 $2.6\times$ - $3.3\times$ 的减少训练计算，这再次证明了 Fast MixMatch 的通用性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Cross-Image-Context-Matters-for-Bongard-Problems"><a href="#Cross-Image-Context-Matters-for-Bongard-Problems" class="headerlink" title="Cross-Image Context Matters for Bongard Problems"></a>Cross-Image Context Matters for Bongard Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03468">http://arxiv.org/abs/2309.03468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nraghuraman/bongard-context">https://github.com/nraghuraman/bongard-context</a></li>
<li>paper_authors: Nikhil Raghuraman, Adam W. Harley, Leonidas Guibas</li>
<li>for: 本研究旨在解决现代机器学习方法在Bongard问题上的缺陷，Bongard问题是一种类型的智能测试，需要从一组正例和负例图像中抽出抽象的概念，并将新的查询图像分类为是否符合该概念。</li>
<li>methods: 本研究使用了一些简单的方法来考虑跨图像上下文信息，包括使用多个正例和负例图像来分别提取概念的特征，并将这些特征组合在一起以提高分类精度。</li>
<li>results: 本研究实现了substantial的提升，在Bongard-LOGO和Bongard-HOI上达到了新的状态码性能（75.3%和72.45%），并在原始Bongard问题集上实现了strong的性能（60.84%）。<details>
<summary>Abstract</summary>
Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract "concept" from a set of positive and negative "support" images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, existing methods have only reached 66% accuracy (where chance is 50%). Low accuracy is often attributed to neural nets' lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not incorporate information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because unlike in few-shot learning tasks concerning object classification, the "key concept" in a typical Bongard problem can only be distinguished using multiple positives and multiple negatives. We explore a variety of simple methods to take this cross-image context into account, and demonstrate substantial gains over prior methods, leading to new state-of-the-art performance on Bongard-LOGO (75.3%) and Bongard-HOI (72.45%) and strong performance on the original Bongard problem set (60.84%).
</details>
<details>
<summary>摘要</summary>
当前的机器学习方法难以解决博格ар问题，这种问题需要从一组正例和负例图像中推导抽象的概念，然后判断新的查询图像是否表示关键概念。在Bongard-HOIbenchmark上，现有的方法只达到66%的准确率（比例为50%）。低准确率常被归结于神经网络缺乏找到人类类似的 символиRule的能力。在这项工作中，我们指出了许多现有方法宁恶地丢失了准确性，因为它们不会将支持集中的信息全面地利用，而是仅仅从个别支持中提取信息。这是一个重要的问题，因为在典型的博格ар问题中，关键概念只能通过多个正例和多个负例来 отличи出来。我们探索了一些简单的方法来考虑这些跨图像上下文信息，并证明了substantial提高，达到了新的状态态Performance在Bongard-LOGO（75.3%）和Bongard-HOI（72.45%），以及在原始博格ар问题集上强性表现（60.84%）。
</details></li>
</ul>
<hr>
<h2 id="Autoregressive-Omni-Aware-Outpainting-for-Open-Vocabulary-360-Degree-Image-Generation"><a href="#Autoregressive-Omni-Aware-Outpainting-for-Open-Vocabulary-360-Degree-Image-Generation" class="headerlink" title="Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation"></a>Autoregressive Omni-Aware Outpainting for Open-Vocabulary 360-Degree Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03467">http://arxiv.org/abs/2309.03467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuqiang Lu, Kun Hu, Chaoyue Wang, Lei Bai, Zhiyong Wang<br>for:* 这篇论文旨在提出一种基于权重学习的方法，用于从窄视场（NFoV）图像中生成全景图像。methods:* 该方法使用了权重学习的 autoregressive omni-aware 生成网络（AOG-Net），通过逐步填充不完整的全景图像，使用 NFoV 图像和文本引用来进行指导。* 该方法还使用了全球-本地conditioning机制，将文本引用、全景视觉指示、NFoV输入和全景几何都编码并转化为一个全球流和一个本地流，并将其 integrate into a conditioned generative backbone model。results:* 对于两个常用的全景图像集，该方法在indoor和outdoor的场景中达到了当今最佳性能。* 该方法可以使用大规模的模型来激活大量的文本引用，从而提高生成的精度和一致性。<details>
<summary>Abstract</summary>
A 360-degree (omni-directional) image provides an all-encompassing spherical view of a scene. Recently, there has been an increasing interest in synthesising 360-degree images from conventional narrow field of view (NFoV) images captured by digital cameras and smartphones, for providing immersive experiences in various scenarios such as virtual reality. Yet, existing methods typically fall short in synthesizing intricate visual details or ensure the generated images align consistently with user-provided prompts. In this study, autoregressive omni-aware generative network (AOG-Net) is proposed for 360-degree image generation by out-painting an incomplete 360-degree image progressively with NFoV and text guidances joinly or individually. This autoregressive scheme not only allows for deriving finer-grained and text-consistent patterns by dynamically generating and adjusting the process but also offers users greater flexibility to edit their conditions throughout the generation process. A global-local conditioning mechanism is devised to comprehensively formulate the outpainting guidance in each autoregressive step. Text guidances, omni-visual cues, NFoV inputs and omni-geometry are encoded and further formulated with cross-attention based transformers into a global stream and a local stream into a conditioned generative backbone model. As AOG-Net is compatible to leverage large-scale models for the conditional encoder and the generative prior, it enables the generation to use extensive open-vocabulary text guidances. Comprehensive experiments on two commonly used 360-degree image datasets for both indoor and outdoor settings demonstrate the state-of-the-art performance of our proposed method. Our code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
《全景图像生成方法 based on Omni-aware Generative Network》Introduction:Recently, there has been an increasing interest in generating 360-degree images from narrow field of view (NFoV) images captured by digital cameras and smartphones, for providing immersive experiences in various scenarios such as virtual reality. However, existing methods often fall short in synthesizing intricate visual details or ensuring the generated images align consistently with user-provided prompts.Methodology:In this study, we propose an autoregressive omni-aware generative network (AOG-Net) for 360-degree image generation. The network uses an incomplete 360-degree image as input and progressively out-paints it with NFoV and text guidance. The autoregressive scheme allows for deriving finer-grained and text-consistent patterns by dynamically generating and adjusting the process, offering users greater flexibility to edit their conditions throughout the generation process.Key Components:1. Global-Local Conditioning Mechanism: We devise a global-local conditioning mechanism to comprehensively formulate the outpainting guidance in each autoregressive step. Text guidances, omni-visual cues, NFoV inputs, and omni-geometry are encoded and further formulated with cross-attention based transformers into a global stream and a local stream into a conditioned generative backbone model.2. Compatibility with Large-Scale Models: Our proposed method is compatible with large-scale models for the conditional encoder and the generative prior, enabling the generation to use extensive open-vocabulary text guidances.Experiments:We conduct comprehensive experiments on two commonly used 360-degree image datasets for both indoor and outdoor settings, demonstrating the state-of-the-art performance of our proposed method.Conclusion:In this study, we proposed an autoregressive omni-aware generative network (AOG-Net) for 360-degree image generation, which offers a more flexible and controllable approach to synthesizing high-quality 360-degree images from NFoV images. Our proposed method has the potential to be applied in various scenarios, such as virtual reality, panoramic imaging, and 3D reconstruction. The code will be made publicly available.
</details></li>
</ul>
<hr>
<h2 id="MIRA-Cracking-Black-box-Watermarking-on-Deep-Neural-Networks-via-Model-Inversion-based-Removal-Attacks"><a href="#MIRA-Cracking-Black-box-Watermarking-on-Deep-Neural-Networks-via-Model-Inversion-based-Removal-Attacks" class="headerlink" title="MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks"></a>MIRA: Cracking Black-box Watermarking on Deep Neural Networks via Model Inversion-based Removal Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03466">http://arxiv.org/abs/2309.03466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Lu, Wenxuan Li, Mi Zhang, Xudong Pan, Min Yang</li>
<li>for: 保护深度学习模型的知识产权，黑obox深度学习模型水印（black-box DNN watermarks）在学术和工业领域得到了广泛应用。</li>
<li>methods: 我们提出了一种名为模型反向攻击(\textsc{Mira})的新型攻击方法，可以对大多数主流黑obox深度学习模型水印进行有效的除法。</li>
<li>results: 我们在三个 benchmark 数据集和 DNN 架构上对 \textsc{Mira} 进行了广泛的评估，并证明了它在覆盖的水印上具有强大的除法效果，保留至少 90% 的盗取模型用途，并且不需要dataset的可用性。<details>
<summary>Abstract</summary>
To protect the intellectual property of well-trained deep neural networks (DNNs), black-box DNN watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. Recent studies empirically prove the robustness of most black-box watermarking schemes against known removal attempts.   In this paper, we propose a novel Model Inversion-based Removal Attack (\textsc{Mira}), which is watermark-agnostic and effective against most of mainstream black-box DNN watermarking schemes. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss caused by \textsc{Mira} and achieve data-free watermark removal on half of the watermarking schemes. We conduct comprehensive evaluation of \textsc{Mira} against ten mainstream black-box watermarks on three benchmark datasets and DNN architectures. Compared with six baseline removal attacks, \textsc{Mira} achieves strong watermark removal effects on the covered watermarks, preserving at least $90\%$ of the stolen model utility, under more relaxed or even no assumptions on the dataset availability.
</details>
<details>
<summary>摘要</summary>
保护深度神经网络（DNN）的知识产权，黑盒DNN水印（black-box DNN watermarking）已在学术和业界中得到广泛应用。水印Robustness通常是针对偷窃保护模型并尝试从 Parameters 中除掉水印的攻击者。现有研究证明大多数黑盒水印 schemes 的 Robustness 可以抵抗知悉的 removal 试验。在这篇论文中，我们提出了一种新的 Model Inversion-based Removal Attack（\textsc{Mira}，这是针对 most 主流黑盒 DNN water marking schemes 的 watermark-agnostic 和高效的攻击方法。总的来说，我们的攻击管道利用 protected 模型的内部来恢复和忘记水印信息。我们还设计了目标类检测和恢复样本分割算法，以降低由 \textsc{Mira} 引起的实用损失。我们对 ten 主流黑盒水印 schemes 进行了三个 benchmark 数据集和 DNN 架构的全面评估。相比于六个基eline removal 攻击，\textsc{Mira} 在覆盖的水印上实现了强大的水印除法效果，保留至少 90% 的偷窃模型实用性，在更放宽或甚至无 dataset 可用性的情况下。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Algorithm-Selection-for-Pseudo-Boolean-Optimization-with-Given-Computational-Time-Limits"><a href="#Automatic-Algorithm-Selection-for-Pseudo-Boolean-Optimization-with-Given-Computational-Time-Limits" class="headerlink" title="Automatic Algorithm Selection for Pseudo-Boolean Optimization with Given Computational Time Limits"></a>Automatic Algorithm Selection for Pseudo-Boolean Optimization with Given Computational Time Limits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03924">http://arxiv.org/abs/2309.03924</a></li>
<li>repo_url: None</li>
<li>paper_authors: Catalina Pezo, Dorit Hochbaum, Julio Godoy, Roberto Asin-Acha</li>
<li>for: 本研究旨在设计一个可靠的时间限制选择器，以解决NP困难优化问题中的 Pseudo-Boolean Optimization (PBO) 问题。</li>
<li>methods: 本研究使用了机器学习技术，特别是Anytime选择器，来自动选择最佳的解决方案。Anytime选择器会根据给定的时间限制，预测最佳的解决方案，并在该时间限制内执行该解决方案。</li>
<li>results: 研究表明，使用 Anytime 选择器可以大幅提高解决PBO问题的性能，比如在 Gurobi 优化软件失败时，我们的Anytime meta-solver可以为47%的情况提供可行的解决方案。<details>
<summary>Abstract</summary>
Machine learning (ML) techniques have been proposed to automatically select the best solver from a portfolio of solvers, based on predicted performance. These techniques have been applied to various problems, such as Boolean Satisfiability, Traveling Salesperson, Graph Coloring, and others.   These methods, known as meta-solvers, take an instance of a problem and a portfolio of solvers as input. They then predict the best-performing solver and execute it to deliver a solution. Typically, the quality of the solution improves with a longer computational time. This has led to the development of anytime selectors, which consider both the instance and a user-prescribed computational time limit. Anytime meta-solvers predict the best-performing solver within the specified time limit.   Constructing an anytime meta-solver is considerably more challenging than building a meta-solver without the "anytime" feature. In this study, we focus on the task of designing anytime meta-solvers for the NP-hard optimization problem of Pseudo-Boolean Optimization (PBO), which generalizes Satisfiability and Maximum Satisfiability problems. The effectiveness of our approach is demonstrated via extensive empirical study in which our anytime meta-solver improves dramatically on the performance of Mixed Integer Programming solver Gurobi, which is the best-performing single solver in the portfolio. For example, out of all instances and time limits for which Gurobi failed to find feasible solutions, our meta-solver identified feasible solutions for 47% of these.
</details>
<details>
<summary>摘要</summary>
机器学习（ML）技术已经提议用于自动选择一个竞争力最高的解决方案从一个 portefolio 中，基于预测性能。这些技术已经应用于各种问题，如布尔满足问题、旅行商问题、图色问题和其他问题。  这些方法，称为元解决方案，将一个问题和一个 portefolio 中的解决方案作为输入，然后预测最佳的解决方案并执行它来提供解决方案。通常，解决方案的质量随着计算时间的增加而提高。这导致了“任何时间”选择器的发展，它们考虑了问题和用户指定的计算时间限制。任何时间元解决方案预测在指定时间限制内最佳的解决方案。  在本研究中，我们关注了对 Pseudo-Boolean Optimization (PBO) 问题的任何时间元解决方案的设计任务。PBO 问题是推理问题的一种扩展，包括满足问题和最大满足问题。我们的任何时间元解决方案在广泛的实验研究中表现出色，对于 Gurobi 混合整数编程 solver，该 solver 是 portefolio 中最高性能的单个解决方案。例如，对于 Gurobi 无法找到可行解的所有实例和计算时间限制，我们的元解决方案可以提供可行解的 47%。
</details></li>
</ul>
<hr>
<h2 id="SyncDreamer-Generating-Multiview-consistent-Images-from-a-Single-view-Image"><a href="#SyncDreamer-Generating-Multiview-consistent-Images-from-a-Single-view-Image" class="headerlink" title="SyncDreamer: Generating Multiview-consistent Images from a Single-view Image"></a>SyncDreamer: Generating Multiview-consistent Images from a Single-view Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03453">http://arxiv.org/abs/2309.03453</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyuan-pal/SyncDreamer">https://github.com/liuyuan-pal/SyncDreamer</a></li>
<li>paper_authors: Yuan Liu, Cheng Lin, Zijiao Zeng, Xiaoxiao Long, Lingjie Liu, Taku Komura, Wenping Wang</li>
<li>for: 生成多视图图像 from 单视图图像</li>
<li>methods: 使用预训练大规模2D扩散模型和3D意识特征关注机制</li>
<li>results: 生成高一致性的多视图图像，适用于多种3D生成任务<details>
<summary>Abstract</summary>
In this paper, we present a novel diffusion model called that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation tasks such as novel-view-synthesis, text-to-3D, and image-to-3D.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的扩散模型，称为同视图一致图像生成模型。使用预训练的大规模2D扩散模型， Zero123 的最新研究表明了从单视图图像中生成可信度高的新视图图像的能力。然而，维护图像的几何学和颜色协调仍然是一大挑战。为解决这个问题，我们提议一种同步多视图扩散模型，该模型对多视图图像的联合概率分布进行了模型化，从而在单向过程中生成了协调的多视图图像。SyncDreamer 在每个反向过程的每个步骤中 synchronizes 所有生成的图像的中间状态通过一种3D-aware feature attention机制，相应地对不同视图的相关特征进行了相互协调。实验显示，SyncDreamer 能够生成具有高度一致性的多视图图像，因此适用于多种3D生成任务，如新视图合成、文本到3D和图像到3D。
</details></li>
</ul>
<hr>
<h2 id="XGen-7B-Technical-Report"><a href="#XGen-7B-Technical-Report" class="headerlink" title="XGen-7B Technical Report"></a>XGen-7B Technical Report</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03450">http://arxiv.org/abs/2309.03450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erik Nijkamp, Tian Xie, Hiroaki Hayashi, Bo Pang, Congying Xia, Chen Xing, Jesse Vig, Semih Yavuz, Philippe Laban, Ben Krause, Senthil Purushwalkam, Tong Niu, Wojciech Kryściński, Lidiya Murakhovs’ka, Prafulla Kumar Choubey, Alex Fabbri, Ye Liu, Rui Meng, Lifu Tu, Meghana Bhat, Chien-Sheng Wu, Silvio Savarese, Yingbo Zhou, Shafiq Joty, Caiming Xiong</li>
<li>for: 这个论文的目的是提高大语言模型（LLM）的性能和可用性，使其能够更好地支持各种任务和应用。</li>
<li>methods: 作者使用了一系列的7B参数模型，在8K字串长度和1.5T字符数下进行训练。他们还对这些模型进行了资料适应，创建了专门针对公共领域的指南数据进行训练的XGen-Inst模型。</li>
<li>results: 作者在标准的benchmark测试中发现，XGen模型可以与当前开源LLM相比或者更好地实现相同的结果。在长字串模型任务中，XGen-Inst模型也表现出了优势。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have become ubiquitous across various domains, transforming the way we interact with information and conduct research. However, most high-performing LLMs remain confined behind proprietary walls, hindering scientific progress. Most open-source LLMs, on the other hand, are limited in their ability to support longer sequence lengths, which is a key requirement for many tasks that require inference over an input context. To address this, we have trained XGen, a series of 7B parameter models on up to 8K sequence length for up to 1.5T tokens. We have also finetuned the XGen models on public-domain instructional data, creating their instruction-tuned counterparts (XGen-Inst). We open-source our models for both research advancements and commercial applications. Our evaluation on standard benchmarks shows that XGen models achieve comparable or better results when compared with state-of-the-art open-source LLMs. Our targeted evaluation on long sequence modeling tasks shows the benefits of our 8K-sequence models over 2K-sequence open-source LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-as-Optimizers"><a href="#Large-Language-Models-as-Optimizers" class="headerlink" title="Large Language Models as Optimizers"></a>Large Language Models as Optimizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03409">http://arxiv.org/abs/2309.03409</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, Xinyun Chen</li>
<li>for: 这篇论文的目的是提出一种使用大型自然语言模型（LLM）进行优化的简单和有效方法，以解决许多现实世界中缺乏导数的优化问题。</li>
<li>methods: 这篇论文使用的方法是使用大型自然语言模型（LLM）来生成新的解决方案，并在每一步优化过程中，将生成的解决方案与之前生成的解决方案一起作为描述符，以便在下一步优化过程中生成更优的解决方案。</li>
<li>results: 研究人员通过在线性回归和旅行售商问题上应用OPRO，并使用多种LLM，发现OPTRO可以比人类设计的提示更好地优化提示，在GSM8K和Big-Bench Hard任务上达到8%的提高和50%的提高。<details>
<summary>Abstract</summary>
Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.
</details>
<details>
<summary>摘要</summary>
优化是 ubique。而基于导数算法的优化方法在实际应用中存在很多挑战，因为导数缺失。在这项工作中，我们提出了优化通过PROmpting（OPRO），一种简单而有效的方法，使用大型自然语言模型（LLM）作为优化器，其中优化任务是通过自然语言描述的。在每次优化步骤中，LLM生成新的解决方案，这些解决方案基于先前生成的解决方案和其值，然后评估这些新的解决方案，并将其添加到下一次优化步骤中的描述中。我们首先应用OPRO在线性回归和旅行商问题上，然后转移到提示优化，其目标是找到可以最大化任务准确率的指令。使用不同的LLM，我们示出了OPRO最佳提示可以比人工设计的提示高达8%的提高在GSM8K上，以及比人工设计的提示高达50%的提高在Big-Bench Hard任务上。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/cs.AI_2023_09_07/" data-id="closbrokc003j0g887r819nes" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/cs.CL_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T11:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/cs.CL_2023_09_07/">cs.CL - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Evaluation-and-Mitigation-of-Agnosia-in-Multimodal-Large-Language-Models"><a href="#Evaluation-and-Mitigation-of-Agnosia-in-Multimodal-Large-Language-Models" class="headerlink" title="Evaluation and Mitigation of Agnosia in Multimodal Large Language Models"></a>Evaluation and Mitigation of Agnosia in Multimodal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04041">http://arxiv.org/abs/2309.04041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaying Lu, Jinmeng Rao, Kezhen Chen, Xiaoyuan Guo, Yawen Zhang, Baochen Sun, Carl Yang, Jie Yang</li>
<li>for: 本研究旨在评估和 Mitigate Multimodal Agnosia（agnosia in MLLMs），以提高MLLMs的视觉语言任务表现。</li>
<li>methods: 我们提出了一种名为EMMA（评估和 Mitigation of Multimodal Agnosia）的 frameworks，包括评估模块和修复模块。评估模块通过自动生成多样化的视觉问答示例来评估 MLLMs 中的agnosia的程度和方面。修复模块通过多模式 instrucion 调整来减少 MLLMs 中的agnosia。</li>
<li>results: 我们在七个state-of-the-art MLLMs 上进行了9K 个测试样本的评估，发现大多数模型具有不同程度和方面的agnosia。我们还开发了一个细化的 instrucion 集，并对 MLLMs 进行了调整，从而得到了明显的改进。<details>
<summary>Abstract</summary>
While Multimodal Large Language Models (MLLMs) are widely used for a variety of vision-language tasks, one observation is that they sometimes misinterpret visual inputs or fail to follow textual instructions even in straightforward cases, leading to irrelevant responses, mistakes, and ungrounded claims. This observation is analogous to a phenomenon in neuropsychology known as Agnosia, an inability to correctly process sensory modalities and recognize things (e.g., objects, colors, relations). In our study, we adapt this similar concept to define "agnosia in MLLMs", and our goal is to comprehensively evaluate and mitigate such agnosia in MLLMs. Inspired by the diagnosis and treatment process in neuropsychology, we propose a novel framework EMMA (Evaluation and Mitigation of Multimodal Agnosia). In EMMA, we develop an evaluation module that automatically creates fine-grained and diverse visual question answering examples to assess the extent of agnosia in MLLMs comprehensively. We also develop a mitigation module to reduce agnosia in MLLMs through multimodal instruction tuning on fine-grained conversations. To verify the effectiveness of our framework, we evaluate and analyze agnosia in seven state-of-the-art MLLMs using 9K test samples. The results reveal that most of them exhibit agnosia across various aspects and degrees. We further develop a fine-grained instruction set and tune MLLMs to mitigate agnosia, which led to notable improvement in accuracy.
</details>
<details>
<summary>摘要</summary>
While 多模态大语言模型（MLLM）广泛用于视觉语言任务，一种观察是它们在简单情况下也可能错误处理视觉输入或不遵循文本指令，导致无关回答、错误和未根据的声明。这种现象与神经科学中的识别障碍（Agnosia）类似，即不正确处理感官模式并识别物体（例如对象、颜色、关系）。在我们的研究中，我们采用了类似的概念，称之为“MLLM中的识别障碍”，我们的目标是全面评估并 Mitigate 这种障碍。受到神经科学诊断和治疗过程的启发，我们提出了一个新的框架EMMA（评估和 Mitigate 多模态识别障碍）。在EMMA框架中，我们开发了评估模块，可以自动生成多样化和细致的视觉问答示例，用于全面评估 MLMM 中的识别障碍。此外，我们还开发了修复模块，通过多模态指令调整，降低 MLMM 中的识别障碍。为证明我们的框架的有效性，我们使用了7个状态计算机最新的 MLMM，并对9K测试样本进行评估。结果表明，大多数 MLMM 具有不同方面和程度的识别障碍。我们进一步开发了细致的指令集，并对 MLMM 进行调整，这导致了显著的准确率提高。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Representation-Transfer-from-Large-Language-Models-to-End-to-End-ASR-Systems"><a href="#Multiple-Representation-Transfer-from-Large-Language-Models-to-End-to-End-ASR-Systems" class="headerlink" title="Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems"></a>Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04031">http://arxiv.org/abs/2309.04031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takuma Udagawa, Masayuki Suzuki, Gakuto Kurata, Masayasu Muraoka, George Saon</li>
<li>for: 将大语言模型（LLM）的知识融入到端到端自动语音识别系统（ASR）中</li>
<li>methods:  explore 多种方法来从不同层、上下文和模型中获取和传递多个 LLM 表示</li>
<li>results: 示出将多个 LLM 表示传递到扬声器基于 ASR 系统可以是一个有效的代替方案<details>
<summary>Abstract</summary>
Transferring the knowledge of large language models (LLMs) is a promising technique to incorporate linguistic knowledge into end-to-end automatic speech recognition (ASR) systems. However, existing works only transfer a single representation of LLM (e.g. the last layer of pretrained BERT), while the representation of a text is inherently non-unique and can be obtained variously from different layers, contexts and models. In this work, we explore a wide range of techniques to obtain and transfer multiple representations of LLMs into a transducer-based ASR system. While being conceptually simple, we show that transferring multiple representations of LLMs can be an effective alternative to transferring only a single representation.
</details>
<details>
<summary>摘要</summary>
通过传输大语言模型（LLM）的知识是一种可能的方法，以把语言知识 integrate 到端到端自动语音识别（ASR）系统中。然而，现有的工作只是将单个表示（例如，预训练BERT的最后一层）传输到 ASR 系统中，而文本表示的非唯一性意味着可以从不同的层、上下文和模型中获得不同的表示。在这个工作中，我们探讨了许多技术来获取和传输多个 LLM 的表示，并将其 integrate 到传感器基于 ASR 系统中。虽然概念简单，但我们发现传输多个 LLM 的表示可以是一种有效的替代方案。
</details></li>
</ul>
<hr>
<h2 id="TIDE-Textual-Identity-Detection-for-Evaluating-and-Augmenting-Classification-and-Language-Models"><a href="#TIDE-Textual-Identity-Detection-for-Evaluating-and-Augmenting-Classification-and-Language-Models" class="headerlink" title="TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models"></a>TIDE: Textual Identity Detection for Evaluating and Augmenting Classification and Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04027">http://arxiv.org/abs/2309.04027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research-datasets/TIDAL">https://github.com/google-research-datasets/TIDAL</a></li>
<li>paper_authors: Emmanuel Klu, Sameer Sethi</li>
<li>for: 这篇论文旨在提高文本分类器和自然语言处理模型中的公平性，尤其是在文本数据集中存在不公平和排斥的情况下。</li>
<li>methods: 这篇论文提出了一种新的标识词典（TIDAL），包括15,123个标识词和相关的感受上下文，以及一种用于提高标识上下文和机器学习公平性技术的注释和增强工具。</li>
<li>results: 对比之下，这种助手注释技术可以提高人工审核过程的可靠性和速度，而且在评估和修复过程中，这种方法可以检测更多的差距和生成更公平的模型。<details>
<summary>Abstract</summary>
Machine learning models can perpetuate unintended biases from unfair and imbalanced datasets. Evaluating and debiasing these datasets and models is especially hard in text datasets where sensitive attributes such as race, gender, and sexual orientation may not be available. When these models are deployed into society, they can lead to unfair outcomes for historically underrepresented groups. In this paper, we present a dataset coupled with an approach to improve text fairness in classifiers and language models. We create a new, more comprehensive identity lexicon, TIDAL, which includes 15,123 identity terms and associated sense context across three demographic categories. We leverage TIDAL to develop an identity annotation and augmentation tool that can be used to improve the availability of identity context and the effectiveness of ML fairness techniques. We evaluate our approaches using human contributors, and additionally run experiments focused on dataset and model debiasing. Results show our assistive annotation technique improves the reliability and velocity of human-in-the-loop processes. Our dataset and methods uncover more disparities during evaluation, and also produce more fair models during remediation. These approaches provide a practical path forward for scaling classifier and generative model fairness in real-world settings.
</details>
<details>
<summary>摘要</summary>
We create a new, more comprehensive identity lexicon, TIDAL, which includes 15,123 identity terms and associated sense context across three demographic categories. We leverage TIDAL to develop an identity annotation and augmentation tool that can be used to improve the availability of identity context and the effectiveness of ML fairness techniques. We evaluate our approaches using human contributors, and additionally run experiments focused on dataset and model debiasing.Results show our assistive annotation technique improves the reliability and velocity of human-in-the-loop processes. Our dataset and methods uncover more disparities during evaluation, and also produce more fair models during remediation. These approaches provide a practical path forward for scaling classifier and generative model fairness in real-world settings.
</details></li>
</ul>
<hr>
<h2 id="LanSER-Language-Model-Supported-Speech-Emotion-Recognition"><a href="#LanSER-Language-Model-Supported-Speech-Emotion-Recognition" class="headerlink" title="LanSER: Language-Model Supported Speech Emotion Recognition"></a>LanSER: Language-Model Supported Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03978">http://arxiv.org/abs/2309.03978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taesik Gong, Josh Belanich, Krishna Somandepalli, Arsha Nagrani, Brian Eoff, Brendan Jou</li>
<li>for: 用于替代人工标注数据，使得大量语音数据和复杂的情感分类器易于扩展</li>
<li>methods: 使用弱监督学习，通过大语言模型对未标注数据进行推理，推导出情感标签</li>
<li>results: 在标准语音感知 task 上表现出色，比基eline模型更高效，并且表现出模型可以模拟语音中的语音特征。<details>
<summary>Abstract</summary>
Speech emotion recognition (SER) models typically rely on costly human-labeled data for training, making scaling methods to large speech datasets and nuanced emotion taxonomies difficult. We present LanSER, a method that enables the use of unlabeled data by inferring weak emotion labels via pre-trained large language models through weakly-supervised learning. For inferring weak labels constrained to a taxonomy, we use a textual entailment approach that selects an emotion label with the highest entailment score for a speech transcript extracted via automatic speech recognition. Our experimental results show that models pre-trained on large datasets with this weak supervision outperform other baseline models on standard SER datasets when fine-tuned, and show improved label efficiency. Despite being pre-trained on labels derived only from text, we show that the resulting representations appear to model the prosodic content of speech.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。</SYS>> speech emotional recognition（SER）模型通常需要昂贵的人类标注数据进行训练，从而使得扩展方法到大量speech数据和细腻的情绪分类难以进行。我们介绍了LanSER，一种方法可以使用无标注数据进行训练，通过弱型学习进行启发。为了从文本中提取启发的情绪标签，我们使用文本排序approach，选择一个符合分类的情绪标签，通过自动语音识别获取speech脚本。我们的实验结果表明，在标准SER数据集上精化的模型，可以在标准SER数据集上超越其他基eline模型，并且显示改进的标签效率。即使只使用文本中 derivated的标签进行训练，我们发现模型 Apparently captured the prosody content of speech。
</details></li>
</ul>
<hr>
<h2 id="ImageBind-LLM-Multi-modality-Instruction-Tuning"><a href="#ImageBind-LLM-Multi-modality-Instruction-Tuning" class="headerlink" title="ImageBind-LLM: Multi-modality Instruction Tuning"></a>ImageBind-LLM: Multi-modality Instruction Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03905">http://arxiv.org/abs/2309.03905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/llama-adapter">https://github.com/opengvlab/llama-adapter</a></li>
<li>paper_authors: Jiaming Han, Renrui Zhang, Wenqi Shao, Peng Gao, Peng Xu, Han Xiao, Kaipeng Zhang, Chris Liu, Song Wen, Ziyu Guo, Xudong Lu, Shuai Ren, Yafei Wen, Xiaoxin Chen, Xiangyu Yue, Hongsheng Li, Yu Qiao</li>
<li>for: 图像和文本多模态指令调整方法</li>
<li>methods: 使用ImageBind进行图像编码器的学习绑定网络，并在LLaMA中进行语音和3D点云、视频等多模态指令注入。</li>
<li>results: 通过无需更多训练的方式，ImageBind-LLM可以响应多种模态指令，并且在语音、3D点云、视频等多种模态输入下展示出色的语言生成质量。<details>
<summary>Abstract</summary>
We present ImageBind-LLM, a multi-modality instruction tuning method of large language models (LLMs) via ImageBind. Existing works mainly focus on language and image instruction tuning, different from which, our ImageBind-LLM can respond to multi-modality conditions, including audio, 3D point clouds, video, and their embedding-space arithmetic by only image-text alignment training. During training, we adopt a learnable bind network to align the embedding space between LLaMA and ImageBind's image encoder. Then, the image features transformed by the bind network are added to word tokens of all layers in LLaMA, which progressively injects visual instructions via an attention-free and zero-initialized gating mechanism. Aided by the joint embedding of ImageBind, the simple image-text training enables our model to exhibit superior multi-modality instruction-following capabilities. During inference, the multi-modality inputs are fed into the corresponding ImageBind encoders, and processed by a proposed visual cache model for further cross-modal embedding enhancement. The training-free cache model retrieves from three million image features extracted by ImageBind, which effectively mitigates the training-inference modality discrepancy. Notably, with our approach, ImageBind-LLM can respond to instructions of diverse modalities and demonstrate significant language generation quality. Code is released at https://github.com/OpenGVLab/LLaMA-Adapter.
</details>
<details>
<summary>摘要</summary>
我们介绍ImageBind-LLM，一种基于ImageBind的多Modalities语言模型调教方法。现有工作主要集中在语言和图像指令调教上，与之不同的我们的ImageBind-LLM可以应对多Modalities条件，包括音频、3D点云、视频和它们的内存空间加法。在训练过程中，我们采用一个学习可 Bind 网络将 ImageBind 的图像编码器的嵌入空间与 LLaMA 的各层单词Token进行对齐。然后，通过 Bind 网络转换的图像特征被添加到 LLMA 的所有层单词Token中，逐渐注入视觉指令，无需注意力和初始值。帮助 joint embedding of ImageBind，简单的图像文本训练使我们的模型在多Modalities指令跟踪能力方面表现出色。在推理过程中，多Modalities输入被 feed 到对应的 ImageBind 编码器中，并被一种提议的视觉缓存模型进行进一步跨模态嵌入增强。这种培成模型通过从三百万个 ImageBind 提取出的图像特征进行重新调教，有效地减少了训练-推理模态差异。需要注意的是，我们的方法可以让 ImageBind-LLM在不同的模态上 respond 到指令，并且在语言生成质量方面表现出色。代码可以在 <https://github.com/OpenGVLab/LLaMA-Adapter> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Audio-Captioning-via-Audibility-Guidance"><a href="#Zero-Shot-Audio-Captioning-via-Audibility-Guidance" class="headerlink" title="Zero-Shot Audio Captioning via Audibility Guidance"></a>Zero-Shot Audio Captioning via Audibility Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03884">http://arxiv.org/abs/2309.03884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tal Shaharabany, Ariel Shaulov, Lior Wolf</li>
<li>For: The paper proposes a method for audio captioning, with the goal of generating fluent and faithful text descriptions of audio files.* Methods: The method uses a combination of three networks: a large language model (GPT-2), a multimodal matching network (ImageBind), and a text classifier. The method does not involve learning to perform captioning, but rather uses inference to generate text based on the input audio.* Results: The authors present results on the AudioCap dataset, showing that their method significantly enhances performance compared to a baseline lacking audibility guidance. Specifically, the method achieves high fluency, faithfulness to the input audio, and audibility.<details>
<summary>Abstract</summary>
The task of audio captioning is similar in essence to tasks such as image and video captioning. However, it has received much less attention. We propose three desiderata for captioning audio -- (i) fluency of the generated text, (ii) faithfulness of the generated text to the input audio, and the somewhat related (iii) audibility, which is the quality of being able to be perceived based only on audio. Our method is a zero-shot method, i.e., we do not learn to perform captioning. Instead, captioning occurs as an inference process that involves three networks that correspond to the three desired qualities: (i) A Large Language Model, in our case, for reasons of convenience, GPT-2, (ii) A model that provides a matching score between an audio file and a text, for which we use a multimodal matching network called ImageBind, and (iii) A text classifier, trained using a dataset we collected automatically by instructing GPT-4 with prompts designed to direct the generation of both audible and inaudible sentences. We present our results on the AudioCap dataset, demonstrating that audibility guidance significantly enhances performance compared to the baseline, which lacks this objective.
</details>
<details>
<summary>摘要</summary>
audio captioning的任务与图像和视频标题类似，但它得到了许多 menos attention。我们提出了三个愿景 для标题音频：（i）生成文本的流畅性，（ii）生成文本与输入音频的准确性，以及（iii）可见性，即基于 solely audio 可以被感知的质量。我们的方法是一种零截法方法，即不学习权值，而是通过三个网络来实现这三个愿景：（i）一个大语言模型，我们使用 GPT-2，（ii）一个用于对 audio 文件和文本进行匹配的多模态匹配网络，我们使用 ImageBind，（iii）一个用于分类文本的文本分类器，我们使用一个自动收集的数据集来训练。我们在 AudioCap 数据集上展示了我们的结果，表明可见导航对基准的性能有很大改善。
</details></li>
</ul>
<hr>
<h2 id="On-Large-Language-Models’-Selection-Bias-in-Multi-Choice-Questions"><a href="#On-Large-Language-Models’-Selection-Bias-in-Multi-Choice-Questions" class="headerlink" title="On Large Language Models’ Selection Bias in Multi-Choice Questions"></a>On Large Language Models’ Selection Bias in Multi-Choice Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03882">http://arxiv.org/abs/2309.03882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, Minlie Huang</li>
<li>for: 本研究探讨了大语言模型（LLM）在多选问题（MCQ）中的表现，发现LLM具有自然选择偏好（selection bias），即选择位置在特定位置（如选项C）的偏好。</li>
<li>methods: 我们提出了一种新方法 called PriDe，它可以减轻 LLM 的选择偏好。PriDe 首先将观测到的模型预测分布分解成内在预测和选择ID的 posterior distribution。然后，它使用一小数量的测试样本来估计 posterior，并使用这些估计来减轻后续测试样本。</li>
<li>results: 我们的实验表明，PriDe 可以更有效率地减轻 LLM 的选择偏好，并且可以在不同领域中进行广泛应用。此外，我们还发现了 PriDe 估计的 posterior 可以很好地泛化到不同领域。<details>
<summary>Abstract</summary>
Multi-choice questions (MCQs) serve as a common yet important task format in the research of large language models (LLMs). Our work shows that LLMs exhibit an inherent "selection bias" in MCQs, which refers to LLMs' preferences to select options located at specific positions (like "Option C"). This bias is prevalent across various LLMs, making their performance vulnerable to option position changes in MCQs. We identify that one primary cause resulting in selection bias is option numbering, i.e., the ID symbols A/B/C/D associated with the options. To mitigate selection bias, we propose a new method called PriDe. PriDe first decomposes the observed model prediction distribution into an intrinsic prediction over option contents and a prior distribution over option IDs. It then estimates the prior by permutating option contents on a small number of test samples, which is used to debias the subsequent test samples. We demonstrate that, as a label-free, inference-time method, PriDe achieves a more effective and computation-efficient debiasing than strong baselines. We further show that the priors estimated by PriDe generalize well across different domains, highlighting its practical potential in broader scenarios.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)LLMs 在多选问题 (MCQs) 中表现出一种内在的 "选择偏见"，即选择位置为特定位置 (如 "选项 C" ) 的偏好。这种偏见遍布于多种 LLMs，使其在 MCQs 中的性能易受选项位置的变化影响。我们认为选项编号 (A/B/C/D) 是主要的 causal factor。为了解决这种偏见，我们提出了一种新的方法 called PriDe。 PriDe 首先将观察到的模型预测分布 decomposes 为内在预测和选项 ID 的先验分布。然后，它使用一小量测试样本中的内容排序来估计先验，并用这些先验来减偏测试样本。我们示出，作为无标签、执行时的方法，PriDe 在减偏性和计算效率方面超过了强基elines。此外，我们还表明了 PriDe 在不同领域中的 praktische 潜力。
</details></li>
</ul>
<hr>
<h2 id="Introducing-“Forecast-Utterance”-for-Conversational-Data-Science"><a href="#Introducing-“Forecast-Utterance”-for-Conversational-Data-Science" class="headerlink" title="Introducing “Forecast Utterance” for Conversational Data Science"></a>Introducing “Forecast Utterance” for Conversational Data Science</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03877">http://arxiv.org/abs/2309.03877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Mahadi Hassan, Alex Knipper, Shubhra Kanti Karmaker</li>
<li>for: 预测任务的帮助，帮助用户通过自然语言交互，无需深入了解机器学习过程。</li>
<li>methods: 利用新概念“预测utterance”，自动和准确地理解用户预测目标，并将其转化为机器学习任务。 employed two zero-shot methods：1）实体提取（EE），2）问答技术（QA）。</li>
<li>results: 通过三组精心制作的数据集进行实验，证明了我们的目标的可能性，并证明了EE和QA技术在解释预测utterance中的效果。<details>
<summary>Abstract</summary>
Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, conducted with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances.
</details>
<details>
<summary>摘要</summary>
想像一个智能代理人，能够帮助用户进行预测任务，通过自然、直观的对话，无需深入了解下面机器学习（ML）过程。这个目标具有很大挑战，即准确理解用户预测目标，并因此形成精准的ML任务。在这篇论文中，我们采取了一项先锋的方法，即预测话语（Forecast Utterance）的概念，然后将用户预测目标的自动和准确理解归类为槽筛问题。每个槽都对应于特定的预测目标方面。我们然后使用了两种零容量解决槽筛问题的方法，即实体提取（EE）和问答技术（QA）。我们的实验，在三个精心制作的数据集上进行，证明了我们的目标的可行性，并证明了EE和QA技术在解释预测话语中的效果。
</details></li>
</ul>
<hr>
<h2 id="USA-Universal-Sentiment-Analysis-Model-Construction-of-Japanese-Sentiment-Text-Classification-and-Part-of-Speech-Dataset"><a href="#USA-Universal-Sentiment-Analysis-Model-Construction-of-Japanese-Sentiment-Text-Classification-and-Part-of-Speech-Dataset" class="headerlink" title="USA: Universal Sentiment Analysis Model &amp; Construction of Japanese Sentiment Text Classification and Part of Speech Dataset"></a>USA: Universal Sentiment Analysis Model &amp; Construction of Japanese Sentiment Text Classification and Part of Speech Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03787">http://arxiv.org/abs/2309.03787</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://huggingface.co/ganchengguang/USA-7B-instruction-incontext-learning">https://huggingface.co/ganchengguang/USA-7B-instruction-incontext-learning</a></li>
<li>paper_authors: Chengguang Gan, Qinghao Zhang, Tatsunori Mori</li>
<li>for: 这篇论文旨在提高情感分析的性能，通过利用文本中单词的复杂影响和总体文本的含义相互强制的效果。</li>
<li>methods: 该论文提出了一种基于大语言模型的新方法，通过利用单词的情感方向对整个文本的情感含义产生强制效应，从而提高情感分析的性能。</li>
<li>results: 实验结果表明，该方法可以在四个新的情感分类和PART OF SPEECH（SCPOS）数据集上达到比gpt-3.5-turbo更高的性能。<details>
<summary>Abstract</summary>
Sentiment analysis is a pivotal task in the domain of natural language processing. It encompasses both text-level sentiment polarity classification and word-level Part of Speech(POS) sentiment polarity determination. Such analysis challenges models to understand text holistically while also extracting nuanced information. With the rise of Large Language Models(LLMs), new avenues for sentiment analysis have opened. This paper proposes enhancing performance by leveraging the Mutual Reinforcement Effect(MRE) between individual words and the overall text. It delves into how word polarity influences the overarching sentiment of a passage. To support our research, we annotated four novel Sentiment Text Classification and Part of Speech(SCPOS) datasets, building upon existing sentiment classification datasets. Furthermore, we developed a Universal Sentiment Analysis(USA) model, with a 7-billion parameter size. Experimental results revealed that our model surpassed the performance of gpt-3.5-turbo across all four datasets, underscoring the significance of MRE in sentiment analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Daunting-Dilemma-with-Sentence-Encoders-Success-on-Standard-Benchmarks-Failure-in-Capturing-Basic-Semantic-Properties"><a href="#The-Daunting-Dilemma-with-Sentence-Encoders-Success-on-Standard-Benchmarks-Failure-in-Capturing-Basic-Semantic-Properties" class="headerlink" title="The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties"></a>The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03747">http://arxiv.org/abs/2309.03747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yash Mahajan, Naman Bansal, Shubhra Kanti Karmaker</li>
<li>for: 本研究旨在比较五种广泛使用的句子编码器，包括Sentence-BERT、Universal Sentence Encoder（USE）、LASER、InferSent和Doc2vec，以及他们在下游任务中的表现和捕捉基本Semantic property的能力。</li>
<li>methods: 本研究采用了Retrospective方法，对五种句子编码器进行了SentEvalbenchmark的评估，并设计了四个Semantic评估标准，包括Paraphrasing、Synonym Replacement、Antonym Replacement和Sentence Jumbling，以评估这些编码器的表现。</li>
<li>results: 结果显示，Sentence-BERT和USE模型在Paraphrasing标准上表现最佳，SBERT在这两个标准上表现更加出色。LASER在Synonym Replacement标准上表现最佳。 Interestingly，所有的句子编码器在Antonym Replacement和Jumbling标准上都失败了。这些结果表明，虽然这些句子编码器在SentEvalbenchmark上表现非常出色，但它们仍然努力捕捉一些基本Semantic property，从而存在一定的挑战。<details>
<summary>Abstract</summary>
In this paper, we adopted a retrospective approach to examine and compare five existing popular sentence encoders, i.e., Sentence-BERT, Universal Sentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their performance on downstream tasks versus their capability to capture basic semantic properties. Initially, we evaluated all five sentence encoders on the popular SentEval benchmark and found that multiple sentence encoders perform quite well on a variety of popular downstream tasks. However, being unable to find a single winner in all cases, we designed further experiments to gain a deeper understanding of their behavior. Specifically, we proposed four semantic evaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym Replacement, and Sentence Jumbling, and evaluated the same five sentence encoders using these criteria. We found that the Sentence-Bert and USE models pass the paraphrasing criterion, with SBERT being the superior between the two. LASER dominates in the case of the synonym replacement criterion. Interestingly, all the sentence encoders failed the antonym replacement and jumbling criteria. These results suggest that although these popular sentence encoders perform quite well on the SentEval benchmark, they still struggle to capture some basic semantic properties, thus, posing a daunting dilemma in NLP research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们采用了回顾方法来评估和比较五种流行的句子编码器，即 Sentence-BERT、全局句子编码器（USE）、LASER、InferSent和Doc2vec，它们在下游任务上的表现和捕捉基本Semantic Properties的能力之间的关系。我们首先对所有五种句子编码器在Popular SentEval benchmark上进行评估，发现它们在多种Popular downstream task上表现很好。然而，无法找到一个在所有情况下赢的单一赢家，我们设计了进一步的实验来深入了解它们的行为。特别是，我们提出了四个semantic评估标准，即Paraphrasing、Synonym Replacement、Antonym Replacement和Sentence Jumbling，并对五种句子编码器进行评估。我们发现，Sentence-Bert和USE模型通过Paraphrasing标准，SBERT在两者中表现更佳。LASER在Synonym Replacement标准上表现出色。另外，所有句子编码器在Antonym Replacement和Jumbling标准上都失败。这些结果表明，虽然这些流行的句子编码器在SentEval benchmark上表现很好，但它们仍然很难捕捉一些基本的Semantic Properties，这是NPRL研究所存在的一个棘手的问题。
</details></li>
</ul>
<hr>
<h2 id="Word-segmentation-granularity-in-Korean"><a href="#Word-segmentation-granularity-in-Korean" class="headerlink" title="Word segmentation granularity in Korean"></a>Word segmentation granularity in Korean</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03713">http://arxiv.org/abs/2309.03713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jungyeul Park, Mija Kim</li>
<li>for: 这篇论文关注韩语Word分 segmentation粒度的问题。</li>
<li>methods: 文章分析了不同粒度水平的Word分 segmentation，并提供了适用于特定语言处理和文献注释任务的多种不同粒度水平。</li>
<li>results: 研究发现，只分Functional morphemes，包括案例标记和词尾变化，而不分其他词形 derivation 的粒度可以获得最佳的结构分析性能。这与过去韩语处理的常见做法不同，该做法需要将所有 morphemes 分开。<details>
<summary>Abstract</summary>
This paper describes word {segmentation} granularity in Korean language processing. From a word separated by blank space, which is termed an eojeol, to a sequence of morphemes in Korean, there are multiple possible levels of word segmentation granularity in Korean. For specific language processing and corpus annotation tasks, several different granularity levels have been proposed and utilized, because the agglutinative languages including Korean language have a one-to-one mapping between functional morpheme and syntactic category. Thus, we analyze these different granularity levels, presenting the examples of Korean language processing systems for future reference. Interestingly, the granularity by separating only functional morphemes including case markers and verbal endings, and keeping other suffixes for morphological derivation results in the optimal performance for phrase structure parsing. This contradicts previous best practices for Korean language processing, which has been the de facto standard for various applications that require separating all morphemes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-an-LM-to-generate-Prolog-Predicates-from-Mathematics-Questions"><a href="#Exploring-an-LM-to-generate-Prolog-Predicates-from-Mathematics-Questions" class="headerlink" title="Exploring an LM to generate Prolog Predicates from Mathematics Questions"></a>Exploring an LM to generate Prolog Predicates from Mathematics Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03667">http://arxiv.org/abs/2309.03667</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaocheng Yang, Yik-Cheung Tam<br>for: 这个论文的目的是调查是否可以通过 fine-tuning 模型来提高逻辑推理能力，并发现 Prolog 代码生成模型在性能方面的优势。methods: 该论文使用了链条思维的技术来 fine-tune LLaMA7B 模型，并开发了不同的 fine-tuned LLaMA7B 模型，包括 Prolog 代码生成模型、Prolog 代码 + 链条思维模型和链条思维 + Prolog 代码模型。results: 结果显示，Prolog 代码生成模型在性能方面超过了基eline模型，而组合生成模型并不显示明显的改善。同时，基于 GSM8K 的 Prolog 词库和相应的 fine-tuned Prolog 代码生成模型也被发布到研究社区。<details>
<summary>Abstract</summary>
Recently, there has been a surge in interest in NLP driven by ChatGPT. ChatGPT, a transformer-based generative language model of substantial scale, exhibits versatility in performing various tasks based on natural language. Nevertheless, large language models often exhibit poor performance in solving mathematics questions that require reasoning. Prior research has demonstrated the effectiveness of chain-of-thought prompting in enhancing reasoning capabilities. Now, we aim to investigate whether fine-tuning a model for the generation of Prolog codes, a logic language, and subsequently passing these codes to a compiler can further improve accuracy. Consequently, we employ chain-of-thought to fine-tune LLaMA7B as a baseline model and develop other fine-tuned LLaMA7B models for the generation of Prolog code, Prolog code + chain-of-thought, and chain-of-thought + Prolog code, respectively. The results reveal that the Prolog generation model surpasses the baseline in performance, while the combination generation models do not yield significant improvements. The Prolog corpus based on GSM8K and the correspondingly finetuned Prolog generation model based on LLaMA7B are released to the research community.
</details>
<details>
<summary>摘要</summary>
最近，有一股关注NLP的兴趣，归功于ChatGPT。ChatGPT是一种基于变换器的生成语言模型，表现了对自然语言的多种任务的灵活性。然而，大型语言模型经常在解决需要推理的数学问题上表现不佳。先前的研究表明了链式思维提示的效iveness。因此，我们想 investigate whether fine-tuning a model for the generation of Prolog codes, a logic language, and subsequently passing these codes to a compiler can further improve accuracy。所以，我们使用链式思维来精度调整LLaMA7B基eline模型，并开发了LLaMA7B模型的其他精度调整版本，包括生成Prolog代码、Prolog代码+链式思维和链式思维+Prolog代码。结果表明，Prolog代码生成模型的性能高于基eline，而组合生成模型不带有显著改善。基于GSM8K的Prolog词库和相应地精度调整的Prolog代码生成模型是由LLaMA7B模型来解决研究社区发布。
</details></li>
</ul>
<hr>
<h2 id="BNS-Net-A-Dual-channel-Sarcasm-Detection-Method-Considering-Behavior-level-and-Sentence-level-Conflicts"><a href="#BNS-Net-A-Dual-channel-Sarcasm-Detection-Method-Considering-Behavior-level-and-Sentence-level-Conflicts" class="headerlink" title="BNS-Net: A Dual-channel Sarcasm Detection Method Considering Behavior-level and Sentence-level Conflicts"></a>BNS-Net: A Dual-channel Sarcasm Detection Method Considering Behavior-level and Sentence-level Conflicts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03658">http://arxiv.org/abs/2309.03658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liming Zhou, Xiaowei Xu, Xiaodong Wang</li>
<li>for: 本研究旨在开发一种能够有效地Identify sarcastic expressions in text的模型，以便在实际应用中提高人机交互的效果。</li>
<li>methods: 本研究使用了深度学习方法，包括用户profile、句子结构和情感词等特征来进行分类。同时，研究还提出了一种名为BNS-Net的双渠道干扰检测模型，该模型通过两个渠道来检测句子中的干扰信息，其中一个渠道是基于行为水平的干扰检测，另一个渠道是基于句子水平的干扰检测。</li>
<li>results: 经过多种比较和缺省实验，研究发现BNS-Net可以准确地识别句子中的干扰表达，并达到了当前领域的最佳性能。<details>
<summary>Abstract</summary>
Sarcasm detection is a binary classification task that aims to determine whether a given utterance is sarcastic. Over the past decade, sarcasm detection has evolved from classical pattern recognition to deep learning approaches, where features such as user profile, punctuation and sentiment words have been commonly employed for sarcasm detection. In real-life sarcastic expressions, behaviors without explicit sentimental cues often serve as carriers of implicit sentimental meanings. Motivated by this observation, we proposed a dual-channel sarcasm detection model named BNS-Net. The model considers behavior and sentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel reconstructs the text based on core verbs while leveraging the modified attention mechanism to highlight conflict information. Channel 2: Sentence-level Conflict Channel introduces external sentiment knowledge to segment the text into explicit and implicit sentences, capturing conflicts between them. To validate the effectiveness of BNS-Net, several comparative and ablation experiments are conducted on three public sarcasm datasets. The analysis and evaluation of experimental results demonstrate that the BNS-Net effectively identifies sarcasm in text and achieves the state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNSarcasm detection 是一个二分类任务，旨在判断给定的语句是否带有讽刺意味。过去十年，讽刺检测从经典的模式识别演化到深度学习方法，其中用户 profiling、标点符号和情感词等特征被广泛使用于讽刺检测。在实际生活中，讽刺表达中的行为常常没有显式的情感cue，因此我们提出了一种双通道讽刺检测模型，称为BNS-Net。该模型在两个通道中考虑行为和句子冲突。通道1：行为水平冲突通道，使用核心动词重建文本，同时利用修改注意机制来强调冲突信息。通道2：句子水平冲突通道，引入外部情感知识，将文本分解成显式和隐式句子，捕捉句子之间的冲突。为验证BNS-Net的有效性，我们进行了多种比较和减少实验，并对三个公共讽刺数据集进行了分析和评估。实验结果分析表明，BNS-Net能够有效地在文本中检测到讽刺，并达到了当前领域的state-of-the-art表现。
</details></li>
</ul>
<hr>
<h2 id="Loquacity-and-Visible-Emotion-ChatGPT-as-a-Policy-Advisor"><a href="#Loquacity-and-Visible-Emotion-ChatGPT-as-a-Policy-Advisor" class="headerlink" title="Loquacity and Visible Emotion: ChatGPT as a Policy Advisor"></a>Loquacity and Visible Emotion: ChatGPT as a Policy Advisor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03595">http://arxiv.org/abs/2309.03595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Claudia Biancotti, Carolina Camassa</li>
<li>for: 这个论文是用来评估 chatGPT 软件在复杂的写作任务中的潜力。</li>
<li>methods: 作者使用 chatGPT 软件来 compose a policy brief for the Board of the Bank of Italy，并对其生成的内容进行了评估。</li>
<li>results: 研究发现，使用 chatGPT 软件可以加速工作流程，提供结构化的内容建议，并在秒钟内生成大量、语言正确的文本。但是，需要专家指导，以避免生成的内容不正确、 superficiale 或 irrelevant。<details>
<summary>Abstract</summary>
ChatGPT, a software seeking to simulate human conversational abilities, is attracting increasing attention. It is sometimes portrayed as a groundbreaking productivity aid, including for creative work. In this paper, we run an experiment to assess its potential in complex writing tasks. We ask the software to compose a policy brief for the Board of the Bank of Italy. We find that ChatGPT can accelerate workflows by providing well-structured content suggestions, and by producing extensive, linguistically correct text in a matter of seconds. It does, however, require a significant amount of expert supervision, which partially offsets productivity gains. If the app is used naively, output can be incorrect, superficial, or irrelevant. Superficiality is an especially problematic limitation in the context of policy advice intended for high-level audiences.
</details>
<details>
<summary>摘要</summary>
chatgpt，一种软件尝试模拟人类对话能力，正在吸引越来越多的关注。它有时被描述为创新的产品ivity工具，包括创作工作。在这篇论文中，我们进行了一项实验，以评估它在复杂的写作任务中的潜力。我们问软件组织一份意大利银行董事会的政策报告。我们发现，chatgpt可以加速工作流程，提供结构良好的内容建议，并在几秒钟之内生成大量、语言正确的文本。但它需要较大的专家监督，这部分抵消了产生效益。如果应用不当，输出可能是错误的、 superficiale 或无关的。 superficiale 是特别问题在政策建议高级审批人群时。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Efficacy-of-Supervised-Learning-vs-Large-Language-Models-for-Identifying-Cognitive-Distortions-and-Suicidal-Risks-in-Chinese-Social-Media"><a href="#Evaluating-the-Efficacy-of-Supervised-Learning-vs-Large-Language-Models-for-Identifying-Cognitive-Distortions-and-Suicidal-Risks-in-Chinese-Social-Media" class="headerlink" title="Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media"></a>Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03564">http://arxiv.org/abs/2309.03564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/chatglm2-6b">https://github.com/thudm/chatglm2-6b</a></li>
<li>paper_authors: Hongzhi Qi, Qing Zhao, Changwei Song, Wei Zhai, Dan Luo, Shuo Liu, Yi Jing Yu, Fan Wang, Huijing Zou, Bing Xiang Yang, Jianqiang Li, Guanghui Fu</li>
<li>for: 本研究旨在探讨大语言模型在中国社交媒体平台上的应用前景，特别是在心理学领域。</li>
<li>methods: 本研究采用了supervised learning作为基础，对三种不同的大语言模型（零shot、少shot和精度调整）进行了比较。</li>
<li>results: 研究发现，大语言模型在中国社交媒体任务上表现明显差，主要是因为模型无法完全理解微分category。然而，GPT-4在多个场景中表现出优异，而GPT-3.5在精度调整后表现出显著提高在自杀风险分类中。<details>
<summary>Abstract</summary>
Large language models, particularly those akin to the rapidly progressing GPT series, are gaining traction for their expansive influence. While there is keen interest in their applicability within medical domains such as psychology, tangible explorations on real-world data remain scant. Concurrently, users on social media platforms are increasingly vocalizing personal sentiments; under specific thematic umbrellas, these sentiments often manifest as negative emotions, sometimes escalating to suicidal inclinations. Timely discernment of such cognitive distortions and suicidal risks is crucial to effectively intervene and potentially avert dire circumstances. Our study ventured into this realm by experimenting on two pivotal tasks: suicidal risk and cognitive distortion identification on Chinese social media platforms. Using supervised learning as a baseline, we examined and contrasted the efficacy of large language models via three distinct strategies: zero-shot, few-shot, and fine-tuning. Our findings revealed a discernible performance gap between the large language models and traditional supervised learning approaches, primarily attributed to the models' inability to fully grasp subtle categories. Notably, while GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows significant enhancement in suicide risk classification after fine-tuning. To our knowledge, this investigation stands as the maiden attempt at gauging large language models on Chinese social media tasks. This study underscores the forward-looking and transformative implications of using large language models in the field of psychology. It lays the groundwork for future applications in psychological research and practice.
</details>
<details>
<summary>摘要</summary>
大型语言模型，特别是快速进步的GPT系列，在医疗领域中获得了更多的关注，但实际应用在社交媒体平台上的探索仍然很少。同时，社交媒体上的用户对自己的情感表达越来越 vocal，经常表达负面情感，甚至有些情感可能会演变为自杀倾向。在时间上有效地识别这些认知扭曲和自杀风险是关键的，以便有效地干预并可能避免不良情况。我们的研究进入了这个领域，通过实验在中文社交媒体平台上进行了两项重要任务：自杀风险识别和认知扭曲识别。使用supervised learning作为基础，我们评估和比较了大型语言模型的三种不同策略：零shot、几shot和精度调整。我们发现了大型语言模型和传统supervised learning方法之间的明显性能差距，主要归因于模型无法完全理解细部类别。特别是GPT-4在多个场景中表现出色，而GPT-3.5在精度调整后表现出了自杀风险分类的明显改善。根据我们所知，这是中文社交媒体任务上首次使用大型语言模型进行探索。这些研究实践了大型语言模型在医学领域的前瞻性和转型性应用，奠定了未来在医学研究和实践中的基础。
</details></li>
</ul>
<hr>
<h2 id="All-Labels-Together-Low-shot-Intent-Detection-with-an-Efficient-Label-Semantic-Encoding-Paradigm"><a href="#All-Labels-Together-Low-shot-Intent-Detection-with-an-Efficient-Label-Semantic-Encoding-Paradigm" class="headerlink" title="All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm"></a>All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03563">http://arxiv.org/abs/2309.03563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangshu Du, Congying Xia, Wenpeng Yin, Tingting Liang, Philip S. Yu</li>
<li>for: 本文旨在提出一种综合利用意图标签的一对所有系统，以便对输入句子进行与所有标签候选者进行比较。</li>
<li>methods: 本文提出了一种终到端的一对所有系统，并使用了 indirect supervision from paraphrasing 进行预训练。</li>
<li>results: 实验表明，当训练资源极为稀少时，One-to-All 系统在 1-, 3- 和 5-shot 设置下表现出状态之 arts 性能。<details>
<summary>Abstract</summary>
In intent detection tasks, leveraging meaningful semantic information from intent labels can be particularly beneficial for few-shot scenarios. However, existing few-shot intent detection methods either ignore the intent labels, (e.g. treating intents as indices) or do not fully utilize this information (e.g. only using part of the intent labels). In this work, we present an end-to-end One-to-All system that enables the comparison of an input utterance with all label candidates. The system can then fully utilize label semantics in this way. Experiments on three few-shot intent detection tasks demonstrate that One-to-All is especially effective when the training resource is extremely scarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings. Moreover, we present a novel pretraining strategy for our model that utilizes indirect supervision from paraphrasing, enabling zero-shot cross-domain generalization on intent detection tasks. Our code is at https://github.com/jiangshdd/AllLablesTogether.
</details>
<details>
<summary>摘要</summary>
在意图探测任务中，利用意图标签中的有意义semantic信息可以对少量scenario非常有利。然而，现有的少量意图探测方法可能会忽略意图标签（例如，对意图视为索引）或者只使用一部分意图标签信息。在这种情况下，我们提出了一个端到端的One-to-All系统，允许输入语音与所有标签候选者进行比较。这种系统可以全面利用标签semantic信息。我们的实验表明，One-to-All在非常罕见的训练资源情况下表现非常出色，在1-, 3-和5-shot设置下达到了状态的最优性。此外，我们还提出了一种新的预训练策略，利用副本推导来启用零批次跨频域通用性。我们的代码可以在https://github.com/jiangshdd/AllLablesTogether中找到。
</details></li>
</ul>
<hr>
<h2 id="An-Anchor-Learning-Approach-for-Citation-Field-Learning"><a href="#An-Anchor-Learning-Approach-for-Citation-Field-Learning" class="headerlink" title="An Anchor Learning Approach for Citation Field Learning"></a>An Anchor Learning Approach for Citation Field Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03559">http://arxiv.org/abs/2309.03559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilin Yuan, Borun Chen, Yimeng Dai, Yinghui Li, Hai-Tao Zheng, Rui Zhang</li>
<li>for: 本研究旨在提高参引字段学习性能，提供一种基于锚学习的新算法CIFAL。</li>
<li>methods: 本研究使用了锚学习来帮助捕捉参与不同风格的参引模式，并在不同的参引资料上进行训练。</li>
<li>results: 实验结果表明，CIFAL比现有方法提高了2.83%的场景级F1分数，并且对质量评估也有了较好的表现。<details>
<summary>Abstract</summary>
Citation field learning is to segment a citation string into fields of interest such as author, title, and venue. Extracting such fields from citations is crucial for citation indexing, researcher profile analysis, etc. User-generated resources like academic homepages and Curriculum Vitae, provide rich citation field information. However, extracting fields from these resources is challenging due to inconsistent citation styles, incomplete sentence syntax, and insufficient training data. To address these challenges, we propose a novel algorithm, CIFAL (citation field learning by anchor learning), to boost the citation field learning performance. CIFAL leverages the anchor learning, which is model-agnostic for any Pre-trained Language Model, to help capture citation patterns from the data of different citation styles. The experiments demonstrate that CIFAL outperforms state-of-the-art methods in citation field learning, achieving a 2.83% improvement in field-level F1-scores. Extensive analysis of the results further confirms the effectiveness of CIFAL quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
<SYS>使用简化中文</SYS>文本：引用字段学习是将引用字符串分解成 интерес的字段，如作者、标题和会议地点。从引用中提取这些字段非常重要，以便引用索引、研究人员资料分析等。用户生成的资源，如学术主页和CV，提供了丰富的引用字段信息。然而，从这些资源中提取字段具有挑战，主要是因为引用风格的不一致，句子结构不完整，以及训练数据的不足。为解决这些挑战，我们提出了一种新的算法，称为CIFAL（引用字段学习 by anchor learning），以提高引用字段学习性能。CIFAL利用了锚学习，这是对任何预训练语言模型的模型无关的，来帮助捕捉不同引用风格的引用模式。实验表明，CIFAL在引用字段学习方面的表现明显超过了现有方法，提高了字段级F1分数2.83%。广泛的分析结果证明了CIFAL的有效性，并且证明了其量化和质量上的优势。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-for-Tangible-Effects-Natural-Language-Processing-for-Uncovering-the-Illicit-Massage-Industry-Computer-Vision-for-Tactile-Sensing"><a href="#Machine-Learning-for-Tangible-Effects-Natural-Language-Processing-for-Uncovering-the-Illicit-Massage-Industry-Computer-Vision-for-Tactile-Sensing" class="headerlink" title="Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry &amp; Computer Vision for Tactile Sensing"></a>Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry &amp; Computer Vision for Tactile Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03470">http://arxiv.org/abs/2309.03470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Ouyang</li>
<li>for: This thesis explores how computer science can be used to fight human trafficking, specifically in the illicit massage industry, and how computer vision can create a sense of touch.</li>
<li>methods: The thesis uses natural language processing (NLP) to monitor the industry and create datasets, and also considers the use of agent-based models to create synthetic financial data. Additionally, the thesis describes the development of a novel sensor, the Digger Finger, which adapts the Gelsight sensor to find objects in granular media, and a low-cost six-axis force-torque sensor using a webcam and printed reference marker.</li>
<li>results: The thesis shows how NLP can be used to derive insights into the labor pressures and language barriers faced by employees in the industry, as well as the income, demographics, and societal pressures affecting sex buyers. Additionally, the thesis reports on the development of a novel sensor that is up to a hundred times less expensive than commercial sensors, allowing for a wider range of applications.<details>
<summary>Abstract</summary>
I explore two questions in this thesis: how can computer science be used to fight human trafficking? And how can computer vision create a sense of touch?   I use natural language processing (NLP) to monitor the United States illicit massage industry (IMI), a multi-billion dollar industry that offers not just therapeutic massages but also commercial sexual services. Employees of this industry are often immigrant women with few job opportunities, leaving them vulnerable to fraud, coercion, and other facets of human trafficking. Monitoring spatiotemporal trends helps prevent trafficking in the IMI. By creating datasets with three publicly-accessible websites: Google Places, Rubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and Word2Vec, I show how to derive insights into the labor pressures and language barriers that employees face, as well as the income, demographics, and societal pressures affecting sex buyers. I include a call-to-action to other researchers given these datasets. I also consider how to creating synthetic financial data, which can aid with counter-trafficking in the banking sector. I use an agent-based model to create both tabular and payee-recipient graph data.   I then consider the role of computer vision in making tactile sensors. I report on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to finding objects in granular media. Changes include using a wedge shape to facilitate digging, replacing the internal lighting LEDs with fluorescent paint, and adding a vibrator motor to counteract jamming. Finally, I also show how to use a webcam and a printed reference marker, or fiducial, to create a low-cost six-axis force-torque sensor. This sensor is up to a hundred times less expensive than commercial sensors, allowing for a wider range of applications. For this and earlier chapters I release design files and code as open source.
</details>
<details>
<summary>摘要</summary>
我在这个论文中考察了两个问题：如何使用计算机科学来战击人口贩卖？以及如何使用计算机视觉创造一种触觉感？我使用自然语言处理（NLP）监测美国违法按摩业（IMI），这是一个多亿元的业务，提供了不仅按摩服务，还有商业性的性服务。该行业的员工多为移民女性，她们受到了诈骗、强迫和其他人贩卖的威胁。通过使用Google Places、Rubmaps和AMPReviews等三个公共可访问的网站，以及NLP技术如袋子模型和Word2Vec，我提取了员工面临的劳动压力和语言障碍，以及客户的收入、人口、社会压力等信息。我还采取了对其他研究人员的呼吁，并考虑了如何创建假金融数据，以便在银行业中应对贩卖。我使用代理模型创建了标题和付款人关系数据。然后，我考察了计算机视觉在创造触觉感方面的作用。我报告了一种新的感知器，即挖掘手指（Digger Finger），它将GELSight感知器改进为在粗粒媒体中找到物体。改进包括使用梯形尝试挖掘，取代内部照明LED的涂抹fluorescent paint，并添加震动电动机以防止堵塞。此外，我还显示了如何使用Webcam和印刷参照标记（fiducial）创建一个低成本的六个 степени力矩感知器。这个感知器比商业感知器便宜得多，可以扩展到更多的应用场景。为此和之前章节，我发布了设计文件和代码作为开源。
</details></li>
</ul>
<hr>
<h2 id="Improving-Open-Information-Extraction-with-Large-Language-Models-A-Study-on-Demonstration-Uncertainty"><a href="#Improving-Open-Information-Extraction-with-Large-Language-Models-A-Study-on-Demonstration-Uncertainty" class="headerlink" title="Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty"></a>Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03433">http://arxiv.org/abs/2309.03433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Ling, Xujiang Zhao, Xuchao Zhang, Yanchi Liu, Wei Cheng, Haoyu Wang, Zhengzhang Chen, Takao Osaki, Katsushi Matsuda, Haifeng Chen, Liang Zhao</li>
<li>for: 提高大语言模型（LLM）在开放信息提取任务（OIE）中的表现。</li>
<li>methods: 提出了多种在Context中学习策略和表现 uncertainty 量化模块，以提高 LLM 的 instruction-following 能力和生成关系准确性。</li>
<li>results: 在三个 OIE benchmark 数据集上进行了实验，并证明了我们的方法可以与现有的指导方法相比， both quantitatively and qualitatively。<details>
<summary>Abstract</summary>
Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach holds its own against established supervised methods, both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="From-Base-to-Conversational-Japanese-Instruction-Dataset-and-Tuning-Large-Language-Models"><a href="#From-Base-to-Conversational-Japanese-Instruction-Dataset-and-Tuning-Large-Language-Models" class="headerlink" title="From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models"></a>From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03412">http://arxiv.org/abs/2309.03412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/retarfi/jallm">https://github.com/retarfi/jallm</a></li>
<li>paper_authors: Masahiro Suzuki, Masanori Hirano, Hiroki Sakaji</li>
<li>for: 这个论文目的是为了证明大语言模型（LLM）的交互性需要进行调教。</li>
<li>methods: 这个论文使用了扩展和筛选现有数据集，并将其应用于日本预训练基模型。它还使用了低级别适应（LoRA）调教技术来调教日本和英语基模型。</li>
<li>results: 研究表明，日本指令集数据集的效iveness得到了证明。同时，通过指令调教，即使使用较小的LLM，在下游任务中的性能也会得到改善。研究的指令集、调教模型和实现都公开在线可用。<details>
<summary>Abstract</summary>
Instruction tuning is essential for large language models (LLMs) to become interactive. While many instruction tuning datasets exist in English, there is a noticeable lack in other languages. Also, their effectiveness has not been well verified in non-English languages. We construct a Japanese instruction dataset by expanding and filtering existing datasets and apply the dataset to a Japanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning on both Japanese and English existing models using our instruction dataset. We evaluated these models from both quantitative and qualitative perspectives. As a result, the effectiveness of Japanese instruction datasets is confirmed. The results also indicate that even with relatively small LLMs, performances in downstream tasks would be improved through instruction tuning. Our instruction dataset, tuned models, and implementation are publicly available online.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的指令调整是必要的，以使其成为互动型。然而，英语以外的语言的指令调整数据集尚缺乏，而且它们的效果尚未得到充分验证。我们使用扩展和筛选现有数据集，构建了一个日本语言指令数据集。我们使用这个数据集对日语预训练模型进行了低级别适应（LoRA）调整，并对英语和日语现有模型进行了相同的调整。我们从量化和质量两个角度进行了评估。结果表明，日语指令数据集的效果得到了证明，同时也表明，即使使用较小的LLM，在下游任务中的性能仍可以通过指令调整得到改进。我们的指令数据集、调整模型和实现在线公开可用。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/cs.CL_2023_09_07/" data-id="closbromf00at0g884jcc4ir5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/cs.LG_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T10:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/cs.LG_2023_09_07/">cs.LG - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Bayesian-Dynamic-DAG-Learning-Application-in-Discovering-Dynamic-Effective-Connectome-of-Brain"><a href="#Bayesian-Dynamic-DAG-Learning-Application-in-Discovering-Dynamic-Effective-Connectome-of-Brain" class="headerlink" title="Bayesian Dynamic DAG Learning: Application in Discovering Dynamic Effective Connectome of Brain"></a>Bayesian Dynamic DAG Learning: Application in Discovering Dynamic Effective Connectome of Brain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07080">http://arxiv.org/abs/2309.07080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdolmahdi Bagheri, Mohammad Pasande, Kevin Bello, Alireza Akhondi-Asl, Babak Nadjar Araabi</li>
<li>for: EXTRACTING THE DYNAMIC EFFECTIVE CONNECTOME (DEC)</li>
<li>methods: BAYESIAN DYNAMIC DAG LEARNING WITH M-MATRICES ACYCLICITY CHARACTERIZATION (BDyMA)</li>
<li>results: MORE ACCURATE AND RELIABLE DEC COMPARED TO STATE-OF-THE-ART AND BASELINE METHODS, IMPROVED RESULTS WHEN INCORPORATING DTI DATA AS PRIOR KNOWLEDGE<details>
<summary>Abstract</summary>
Understanding the complex mechanisms of the brain can be unraveled by extracting the Dynamic Effective Connectome (DEC). Recently, score-based Directed Acyclic Graph (DAG) discovery methods have shown significant improvements in extracting the causal structure and inferring effective connectivity. However, learning DEC through these methods still faces two main challenges: one with the fundamental impotence of high-dimensional dynamic DAG discovery methods and the other with the low quality of fMRI data. In this paper, we introduce Bayesian Dynamic DAG learning with M-matrices Acyclicity characterization \textbf{(BDyMA)} method to address the challenges in discovering DEC. The presented dynamic causal model enables us to discover bidirected edges as well. Leveraging an unconstrained framework in the BDyMA method leads to more accurate results in detecting high-dimensional networks, achieving sparser outcomes, making it particularly suitable for extracting DEC. Additionally, the score function of the BDyMA method allows the incorporation of prior knowledge into the process of dynamic causal discovery which further enhances the accuracy of results. Comprehensive simulations on synthetic data and experiments on Human Connectome Project (HCP) data demonstrate that our method can handle both of the two main challenges, yielding more accurate and reliable DEC compared to state-of-the-art and baseline methods. Additionally, we investigate the trustworthiness of DTI data as prior knowledge for DEC discovery and show the improvements in DEC discovery when the DTI data is incorporated into the process.
</details>
<details>
<summary>摘要</summary>
理解大脑的复杂机制可以通过提取动态有效连接oma（DEC）来解开。最近，使用分数基数 Directed Acyclic Graph（DAG）发现方法已经显示出了重要的改进，可以捕捉 causal structure 和生成有效连接。然而，通过这些方法学习 DEC 仍面临两个主要挑战：一是高维动态 DAG 发现方法的基础不足，二是 fMRI 数据质量低。在这篇文章中，我们介绍了 Bayesian 动态 DAG 学习方法（BDyMA），用于解决这两个挑战。BDyMA 方法使得我们可以发现拥有 bidirected 边的动态 causal模型。利用 BDyMA 方法不受限制的框架，可以更加准确地检测高维网络，从而更好地提取 DEC。此外，BDyMA 方法的分数函数允许我们在动态 causal发现过程中 incorporate 先前知识，进一步提高结果的准确性。在 synthetic 数据和 HCP 数据上进行的广泛的 simulate 和实验表明，我们的方法可以解决两个主要挑战，并且比基eline 和状态艺术方法更准确和可靠。此外，我们还 investigate DTI 数据的可靠性作为 DEC 发现的优先知识，并显示在 incorporate DTI 数据到发现过程中可以提高 DEC 的准确性。
</details></li>
</ul>
<hr>
<h2 id="SRN-SZ-Deep-Leaning-Based-Scientific-Error-bounded-Lossy-Compression-with-Super-resolution-Neural-Networks"><a href="#SRN-SZ-Deep-Leaning-Based-Scientific-Error-bounded-Lossy-Compression-with-Super-resolution-Neural-Networks" class="headerlink" title="SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression with Super-resolution Neural Networks"></a>SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression with Super-resolution Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04037">http://arxiv.org/abs/2309.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyang Liu, Sheng Di, Sian Jin, Kai Zhao, Xin Liang, Zizhong Chen, Franck Cappello</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的科学数据损失压缩器，以提高现有损失压缩器对困难压缩数据的压缩率。</li>
<li>methods: 这篇论文使用了基于超分解网络的嵌入式深度学习方法，以提高压缩率。</li>
<li>results: 对比各种现有压缩器，SRN-SZ实现了75%的压缩率提升，并且在同等PSNR下实现了80%的压缩率提升。<details>
<summary>Abstract</summary>
The fast growth of computational power and scales of modern super-computing systems have raised great challenges for the management of exascale scientific data. To maintain the usability of scientific data, error-bound lossy compression is proposed and developed as an essential technique for the size reduction of scientific data with constrained data distortion. Among the diverse datasets generated by various scientific simulations, certain datasets cannot be effectively compressed by existing error-bounded lossy compressors with traditional techniques. The recent success of Artificial Intelligence has inspired several researchers to integrate neural networks into error-bounded lossy compressors. However, those works still suffer from limited compression ratios and/or extremely low efficiencies. To address those issues and improve the compression on the hard-to-compress datasets, in this paper, we propose SRN-SZ, which is a deep learning-based scientific error-bounded lossy compressor leveraging the hierarchical data grid expansion paradigm implemented by super-resolution neural networks. SRN-SZ applies the most advanced super-resolution network HAT for its compression, which is free of time-costing per-data training. In experiments compared with various state-of-the-art compressors, SRN-SZ achieves up to 75% compression ratio improvements under the same error bound and up to 80% compression ratio improvements under the same PSNR than the second-best compressor.
</details>
<details>
<summary>摘要</summary>
现代超级计算机系统的快速增长和大规模数据管理带来了科学数据管理的大 Challenge。以保持科学数据的可用性，错误约束的损失压缩被提出和开发为科学数据的大小减少的关键技术。各种科学仿真数据中的数据不同，一些数据无法使用现有的错误约束损失压缩器进行有效压缩。人工智能的最近成功激发了一些研究人员将神经网络 integrate into error-bounded lossy compressors。然而，这些工作仍然受到有限的压缩比和/或非常低的效率的限制。为了解决这些问题并提高压缩硬度很大的数据集，在这篇论文中，我们提出了SRN-SZ，它是基于科学数据的深度学习损失约束压缩器。SRN-SZ利用了最先进的超分辨率网络HAT进行压缩，无需时间成本的每个数据点训练。在对比各种当前状态的压缩器时，SRN-SZ可以达到75%的压缩率提升，同时保持与第二最佳压缩器相同的PSNR。
</details></li>
</ul>
<hr>
<h2 id="Brief-technical-note-on-linearizing-recurrent-neural-networks-RNNs-before-vs-after-the-pointwise-nonlinearity"><a href="#Brief-technical-note-on-linearizing-recurrent-neural-networks-RNNs-before-vs-after-the-pointwise-nonlinearity" class="headerlink" title="Brief technical note on linearizing recurrent neural networks (RNNs) before vs after the pointwise nonlinearity"></a>Brief technical note on linearizing recurrent neural networks (RNNs) before vs after the pointwise nonlinearity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04030">http://arxiv.org/abs/2309.04030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marino Pagan, Adrian Valente, Srdjan Ostojic, Carlos D. Brody</li>
<li>for: study the properties of recurrent neural networks (RNNs)</li>
<li>methods: linearization of activation dynamics and activity dynamics</li>
<li>results: context-dependent effects are more apparent under linearization of activity dynamics than under linearization of activation dynamics<details>
<summary>Abstract</summary>
Linearization of the dynamics of recurrent neural networks (RNNs) is often used to study their properties. The same RNN dynamics can be written in terms of the ``activations" (the net inputs to each unit, before its pointwise nonlinearity) or in terms of the ``activities" (the output of each unit, after its pointwise nonlinearity); the two corresponding linearizations are different from each other. This brief and informal technical note describes the relationship between the two linearizations, between the left and right eigenvectors of their dynamics matrices, and shows that some context-dependent effects are readily apparent under linearization of activity dynamics but not linearization of activation dynamics.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Optimal-Transport-with-Tempered-Exponential-Measures"><a href="#Optimal-Transport-with-Tempered-Exponential-Measures" class="headerlink" title="Optimal Transport with Tempered Exponential Measures"></a>Optimal Transport with Tempered Exponential Measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04015">http://arxiv.org/abs/2309.04015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Amid, Frank Nielsen, Richard Nock, Manfred K. Warmuth</li>
<li>for: 这 paper 是关于最优运输问题的研究，具体来说是关于不 Regularized 最优运输和带有抽象 Regularization 的最优运输之间的比较。</li>
<li>methods: 这 paper 使用了一种基于温和凝聚推荐的方法，即使用温和凝聚推荐来对最优运输问题进行解决。</li>
<li>results: 这 paper 得到了一种中间点，即使用温和凝聚推荐可以获得非常快的近似算法和控制在某些程度上的稀疏性。此外，这种方法还适用于不均衡最优运输问题的设定中。<details>
<summary>Abstract</summary>
In the field of optimal transport, two prominent subfields face each other: (i) unregularized optimal transport, ``\`a-la-Kantorovich'', which leads to extremely sparse plans but with algorithms that scale poorly, and (ii) entropic-regularized optimal transport, ``\`a-la-Sinkhorn-Cuturi'', which gets near-linear approximation algorithms but leads to maximally un-sparse plans. In this paper, we show that a generalization of the latter to tempered exponential measures, a generalization of exponential families with indirect measure normalization, gets to a very convenient middle ground, with both very fast approximation algorithms and sparsity which is under control up to sparsity patterns. In addition, it fits naturally in the unbalanced optimal transport problem setting as well.
</details>
<details>
<summary>摘要</summary>
在优化运输领域，有两个主要子领域面对着：（i）不规则优化运输，“\`a-la-Kantorovich”，它会导致非常稀疏的计划，但算法扩展不好；（ii）尼科特-库图里的热力学减扰优化运输，“\`a-la-Sinkhorn-Cuturi”，它可以得到近线性approximation算法，但会导致最稀疏的计划。在这篇论文中，我们表明了一种扩展后者的概念，即对温和减扰度量的扩展，可以达到非常方便的中间点，具有非常快的approximation算法和控制在某些几何结构上的稀疏性。此外，它自然地适应了不平衡优化运输问题的设定。
</details></li>
</ul>
<hr>
<h2 id="An-Element-wise-RSAV-Algorithm-for-Unconstrained-Optimization-Problems"><a href="#An-Element-wise-RSAV-Algorithm-for-Unconstrained-Optimization-Problems" class="headerlink" title="An Element-wise RSAV Algorithm for Unconstrained Optimization Problems"></a>An Element-wise RSAV Algorithm for Unconstrained Optimization Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04013">http://arxiv.org/abs/2309.04013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiheng Zhang, Jiahao Zhang, Jie Shen, Guang Lin</li>
<li>for: 提出了一种新的优化算法，元素缓和帮助器（E-RSAV），满足不Conditional energy dissipation law，并且在修改后和原始能量之间存在更好的对齐。</li>
<li>methods: 该算法具有严格的线性收敛证明，并且在单变量情况下提出了一种简单的加速算法，以提高收敛率至超 linear。</li>
<li>results: 通过大量的数学实验，证明了算法的稳定性和快速收敛性。<details>
<summary>Abstract</summary>
We present a novel optimization algorithm, element-wise relaxed scalar auxiliary variable (E-RSAV), that satisfies an unconditional energy dissipation law and exhibits improved alignment between the modified and the original energy. Our algorithm features rigorous proofs of linear convergence in the convex setting. Furthermore, we present a simple accelerated algorithm that improves the linear convergence rate to super-linear in the univariate case. We also propose an adaptive version of E-RSAV with Steffensen step size. We validate the robustness and fast convergence of our algorithm through ample numerical experiments.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的优化算法，元素缓和Scalar副Variables（E-RSAV），它满足不受条件的能量耗散定律并且在修改后的能量与原始能量之间存在改进的对齐。我们的算法具有准确的线性增长证明在凸设定下。此外，我们还提出了一种简单的加速算法，可以在单变量情况下提高线性增长率到超线性级别。此外，我们还提出了基于E-RSAV的适应版本，使用Steffensen步长。我们通过丰富的数学实验证明了我们的算法的稳定性和快速增长。
</details></li>
</ul>
<hr>
<h2 id="Creating-a-Systematic-ESG-Environmental-Social-Governance-Scoring-System-Using-Social-Network-Analysis-and-Machine-Learning-for-More-Sustainable-Company-Practices"><a href="#Creating-a-Systematic-ESG-Environmental-Social-Governance-Scoring-System-Using-Social-Network-Analysis-and-Machine-Learning-for-More-Sustainable-Company-Practices" class="headerlink" title="Creating a Systematic ESG (Environmental Social Governance) Scoring System Using Social Network Analysis and Machine Learning for More Sustainable Company Practices"></a>Creating a Systematic ESG (Environmental Social Governance) Scoring System Using Social Network Analysis and Machine Learning for More Sustainable Company Practices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05607">http://arxiv.org/abs/2309.05607</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aarav Patel, Peter Gloor<br>for:This paper aims to create a data-driven ESG evaluation system that provides better guidance and more systemized scores by incorporating social sentiment.methods:The authors use Python web scrapers to collect data from Wikipedia, Twitter, LinkedIn, and Google News for S&amp;P 500 companies. They then clean and pass the data through NLP algorithms to obtain sentiment scores for ESG subcategories. Machine-learning algorithms are trained and calibrated to S&amp;P Global ESG Ratings to test their predictive capabilities.results:The Random-Forest model shows encouraging results, with a mean absolute error of 13.4% and a correlation of 26.1% (p-value 0.0372). The authors conclude that measuring ESG social sentiment across sub-categories can help executives focus efforts on areas people care about most, and that this data-driven methodology can provide ratings for companies without coverage, allowing more socially responsible firms to thrive.Here’s the simplified Chinese text:for:这篇论文目的是创建一个基于数据的ESG评估系统，以提供更好的指导和更系统化的评估结果，通过包括社交情绪。methods:作者使用Python网络抓取器收集Wikipedia、Twitter、LinkedIn和Google News上的S&amp;P 500公司数据，然后对数据进行清洁和NLP算法处理，以获取ESG子类别的情绪分数。他们使用机器学习算法和S&amp;P全球ESG评级calibration来测试预测能力。results:Random Forest模型表现很有挑战性， Mean Absolute Error为13.4%，Correlation为26.1%（p-value 0.0372）。作者认为，通过评估ESG社交情绪 across sub-categories可以帮助行政官员更加专注于人们关心的方面，并且这种数据驱动的方法ологи可以为没有评估的公司提供评估结果，让更多的社会责任公司得以发展。<details>
<summary>Abstract</summary>
Environmental Social Governance (ESG) is a widely used metric that measures the sustainability of a company practices. Currently, ESG is determined using self-reported corporate filings, which allows companies to portray themselves in an artificially positive light. As a result, ESG evaluation is subjective and inconsistent across raters, giving executives mixed signals on what to improve. This project aims to create a data-driven ESG evaluation system that can provide better guidance and more systemized scores by incorporating social sentiment. Social sentiment allows for more balanced perspectives which directly highlight public opinion, helping companies create more focused and impactful initiatives. To build this, Python web scrapers were developed to collect data from Wikipedia, Twitter, LinkedIn, and Google News for the S&P 500 companies. Data was then cleaned and passed through NLP algorithms to obtain sentiment scores for ESG subcategories. Using these features, machine-learning algorithms were trained and calibrated to S&P Global ESG Ratings to test their predictive capabilities. The Random-Forest model was the strongest model with a mean absolute error of 13.4% and a correlation of 26.1% (p-value 0.0372), showing encouraging results. Overall, measuring ESG social sentiment across sub-categories can help executives focus efforts on areas people care about most. Furthermore, this data-driven methodology can provide ratings for companies without coverage, allowing more socially responsible firms to thrive.
</details>
<details>
<summary>摘要</summary>
环境社会治理（ESG）是一个广泛使用的指标，用于衡量公司的可持续发展实践。目前，ESG是通过自我报告的公司签订，这使得公司可以 artificially 呈现出正面的形象。因此，ESG评估是主观的，不一致的评估人员给出的批评是混乱的，对于执行人来说是不明确的。这个项目的目标是创建一个数据驱动的 ESG 评估系统，可以提供更好的指导和更系统的分数，通过包含社会情绪的社会情绪。社会情绪可以提供更加均衡的视角，直接反映公众的意见，帮助公司制定更集中和有效的措施。为建立这个系统，我们使用 Python 网络抓取工具收集 Wikipedia、Twitter、LinkedIn 和 Google News 上的 S&P 500 公司数据。然后，我们清洁和处理数据，并通过自然语言处理（NLP）算法获得 ESG 子类别的情绪分数。使用这些特征，我们使用机器学习算法进行训练和调整，以测试其预测能力。Random Forest 模型是最强的模型，其 mean absolute error 为 13.4%， correlation 为 26.1%（p-value 0.0372），这表示有很好的结果。总的来说，通过社会情绪的 ESG 评估可以帮助执行人员更好地关注人们关心的方面。此外，这种数据驱动的方法ология可以为没有评估的公司提供评估分数，使更多的社会责任感的公司能够成功。
</details></li>
</ul>
<hr>
<h2 id="Derivation-of-Coordinate-Descent-Algorithms-from-Optimal-Control-Theory"><a href="#Derivation-of-Coordinate-Descent-Algorithms-from-Optimal-Control-Theory" class="headerlink" title="Derivation of Coordinate Descent Algorithms from Optimal Control Theory"></a>Derivation of Coordinate Descent Algorithms from Optimal Control Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03990">http://arxiv.org/abs/2309.03990</a></li>
<li>repo_url: None</li>
<li>paper_authors: I. M. Ross</li>
<li>for: 本文探讨了如何将不同优化算法合并到一起，并从优化控制理论中派生 coordinate descent 算法。</li>
<li>methods: 本文使用了最大原理和一组 max 函数作为 “控制” Lyapunov 函数，从而 derive 出基本的 coordinate descent 算法。</li>
<li>results: 研究发现，使用 Hessian 函数作为搜索向量的操作度量时，coordinate descent 算法的 converges 与 Lyapunov 函数的控制式衰减相关。<details>
<summary>Abstract</summary>
Recently, it was posited that disparate optimization algorithms may be coalesced in terms of a central source emanating from optimal control theory. Here we further this proposition by showing how coordinate descent algorithms may be derived from this emerging new principle. In particular, we show that basic coordinate descent algorithms can be derived using a maximum principle and a collection of max functions as "control" Lyapunov functions. The convergence of the resulting coordinate descent algorithms is thus connected to the controlled dissipation of their corresponding Lyapunov functions. The operational metric for the search vector in all cases is given by the Hessian of the convex objective function.
</details>
<details>
<summary>摘要</summary>
最近，有人提出了论点，即不同的优化算法可能可以从优化控制理论中汇集起来。我们在这里进一步发展这个提议，证明基本坐标降降算法可以从这种新的原理中 derivation。具体来说，我们证明了使用最大原理和一组 max 函数作为 "控制" Lyapunov 函数，可以 derivation 基本坐标降降算法。这些算法的 converge 因此与它们相应的 Lyapunov 函数的控制式耗散相连接。搜索向量的运算度量在所有情况下均给出为对称的 Hessian  Matrix。
</details></li>
</ul>
<hr>
<h2 id="DBsurf-A-Discrepancy-Based-Method-for-Discrete-Stochastic-Gradient-Estimation"><a href="#DBsurf-A-Discrepancy-Based-Method-for-Discrete-Stochastic-Gradient-Estimation" class="headerlink" title="DBsurf: A Discrepancy Based Method for Discrete Stochastic Gradient Estimation"></a>DBsurf: A Discrepancy Based Method for Discrete Stochastic Gradient Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03974">http://arxiv.org/abs/2309.03974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pau Mulet Arabi, Alec Flowers, Lukas Mauch, Fabien Cardinaux</li>
<li>for: 这篇论文是用于计算分布参数的梯度问题的研究，这个问题在科学和工程中都是非常重要的。</li>
<li>methods: 这篇论文使用了Reinforce方法来解决这个问题，但是Reinforce estimator具有较高的敏感度，即使在低抽样 régime下也会导致梯度估计不准确。因此，这篇论文提出了一种基于Reinforce的新采样方法，可以减少实际分布和抽样之间的差异。</li>
<li>results: 在各种任务上，DBsurf estimator在最小二乘问题中具有最低的方差，并在不同的数据集和抽样设置下训练VAEs时达到了最好的结果。此外，这篇论文还应用了DBsurf estimator来建立了一种简单而高效的神经网络架构搜索算法，实现了状态空间的最佳性能。<details>
<summary>Abstract</summary>
Computing gradients of an expectation with respect to the distributional parameters of a discrete distribution is a problem arising in many fields of science and engineering. Typically, this problem is tackled using Reinforce, which frames the problem of gradient estimation as a Monte Carlo simulation. Unfortunately, the Reinforce estimator is especially sensitive to discrepancies between the true probability distribution and the drawn samples, a common issue in low sampling regimes that results in inaccurate gradient estimates. In this paper, we introduce DBsurf, a reinforce-based estimator for discrete distributions that uses a novel sampling procedure to reduce the discrepancy between the samples and the actual distribution. To assess the performance of our estimator, we subject it to a diverse set of tasks. Among existing estimators, DBsurf attains the lowest variance in a least squares problem commonly used in the literature for benchmarking. Furthermore, DBsurf achieves the best results for training variational auto-encoders (VAE) across different datasets and sampling setups. Finally, we apply DBsurf to build a simple and efficient Neural Architecture Search (NAS) algorithm with state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
计算对分布参数的期望梯度问题在多个科学和工程领域中出现。通常，这种问题使用Reinforce来解决，它将问题定义为一个Monte Carlo simulation中的gradient estimation问题。然而，Reinforce estimator尤其容易受到真实分布和抽样分布之间的差异影响，这在低抽样范围下导致gradient estimate不准确。在这篇论文中，我们介绍了DBsurf，一种基于Reinforce的抽样方法，可以减少抽样与真实分布之间的差异。为评估我们的计算器的性能，我们将其应用到多个任务上。与现有的计算器相比，DBsurf在通用的least squares问题中具有最低的方差，并在不同的数据集和抽样设置下训练VAEs时达到最好的结果。最后，我们使用DBsurf构建了一个简单而高效的Neural Architecture Search（NAS）算法，并达到了当前最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Concept-Embedding-Model-ACEM-No-train-time-concepts-No-issue"><a href="#Automatic-Concept-Embedding-Model-ACEM-No-train-time-concepts-No-issue" class="headerlink" title="Automatic Concept Embedding Model (ACEM): No train-time concepts, No issue!"></a>Automatic Concept Embedding Model (ACEM): No train-time concepts, No issue!</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03970">http://arxiv.org/abs/2309.03970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Jain</li>
<li>for: 这篇论文的目的是提出一种自动学习概念嵌入模型（ACEMs），以便在大量数据集上学习概念嵌入模型，而不需要手动标注概念。</li>
<li>methods: 该论文使用的方法是自动学习概念嵌入模型（ACEMs），它可以自动学习概念 annotations，而不需要手动标注。</li>
<li>results: 论文的结果表明，ACEMs 可以在大量数据集上学习概念嵌入模型，并且可以提供高度可解释的模型。<details>
<summary>Abstract</summary>
Interpretability and explainability of neural networks is continuously increasing in importance, especially within safety-critical domains and to provide the social right to explanation. Concept based explanations align well with how humans reason, proving to be a good way to explain models. Concept Embedding Models (CEMs) are one such concept based explanation architectures. These have shown to overcome the trade-off between explainability and performance. However, they have a key limitation -- they require concept annotations for all their training data. For large datasets, this can be expensive and infeasible. Motivated by this, we propose Automatic Concept Embedding Models (ACEMs), which learn the concept annotations automatically.
</details>
<details>
<summary>摘要</summary>
neural networks的可解释性和可读性在不断增加的重要性，尤其在安全关键领域和提供社会的解释权。基于概念的解释方法align well with human reasoning，证明是一种好的解释模型。基于概念嵌入模型（CEMs）是一种这种基于概念的解释建筑。它们能够超越性能和解释之间的负面平衡。然而，它们需要全量的概念标注数据来训练。对于大量数据，这可能是昂贵和不可能的。motivated by这个问题，我们提议自动学习的概念嵌入模型（ACEMs），可以自动学习概念标注。
</details></li>
</ul>
<hr>
<h2 id="A-Tutorial-on-the-Non-Asymptotic-Theory-of-System-Identification"><a href="#A-Tutorial-on-the-Non-Asymptotic-Theory-of-System-Identification" class="headerlink" title="A Tutorial on the Non-Asymptotic Theory of System Identification"></a>A Tutorial on the Non-Asymptotic Theory of System Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03873">http://arxiv.org/abs/2309.03873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ingvar Ziemann, Anastasios Tsiamis, Bruce Lee, Yassir Jedra, Nikolai Matni, George J. Pappas</li>
<li>for: 这篇论文主要针对系统identification理论中的非假设方法，尤其是 Linear system identification 领域内的一些问题。</li>
<li>methods: 这篇论文使用了覆盖技术、汉森-温特不等式和自Normalized Martingales 等工具，以提供Least squares 基于估计器的性能分析。</li>
<li>results: 论文结束部分概述了如何将介绍的想法推广到某些非线性identification问题。<details>
<summary>Abstract</summary>
This tutorial serves as an introduction to recently developed non-asymptotic methods in the theory of -- mainly linear -- system identification. We emphasize tools we deem particularly useful for a range of problems in this domain, such as the covering technique, the Hanson-Wright Inequality and the method of self-normalized martingales. We then employ these tools to give streamlined proofs of the performance of various least-squares based estimators for identifying the parameters in autoregressive models. We conclude by sketching out how the ideas presented herein can be extended to certain nonlinear identification problems.
</details>
<details>
<summary>摘要</summary>
这个教程是非对称方法理论中线性系统识别的引入教程，我们强调这些工具在这个领域中特别有用，如覆盖技术、汉生-瑞特不等式和自正常马丁加尔方法。然后，我们使用这些工具来提供了直观的 proofs of 非对称基于最小二乘估计器在拟合 autoregressive 模型中的性能。最后，我们简要介绍了如何通过这些想法来扩展到某些非线性识别问题。
</details></li>
</ul>
<hr>
<h2 id="Mixtures-of-Gaussians-are-Privately-Learnable-with-a-Polynomial-Number-of-Samples"><a href="#Mixtures-of-Gaussians-are-Privately-Learnable-with-a-Polynomial-Number-of-Samples" class="headerlink" title="Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples"></a>Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03847">http://arxiv.org/abs/2309.03847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Afzali, Hassan Ashtiani, Christopher Liaw</li>
<li>for: 该研究问题是如何在具有权限私钥的情况下估算混合的高斯分布。</li>
<li>methods: 该研究使用了一种新的框架，它可能对其他任务也有用。具体来说，我们展示了如果一个分布类型（如高斯分布）满足两个条件：（1）可以列出decoding和（2）在总变量距离方面具有“本地小”的覆盖，则该分布的混合可以私下学习。</li>
<li>results: 我们的主要结果是，只需要$\tilde{O}(k^2 d^4 \log(1&#x2F;\delta) &#x2F; \alpha^2 \varepsilon)$个样本，就可以估算一个混合的高斯分布，保证总变量距离为α，并满足($\varepsilon$, $\delta$)-DP。这是首次没有任何结构假设的finite sample complexity上界。<details>
<summary>Abstract</summary>
We study the problem of estimating mixtures of Gaussians under the constraint of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a mixture of $k$ Gaussians up to total variation distance $\alpha$ while satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample complexity upper bound for the problem that does not make any structural assumptions on the GMMs.   To solve the problem, we devise a new framework which may be useful for other tasks. On a high level, we show that if a class of distributions (such as Gaussians) is (1) list decodable and (2) admits a "locally small'' cover [BKSW19] with respect to total variation distance, then the class of its mixtures is privately learnable. The proof circumvents a known barrier indicating that, unlike Gaussians, GMMs do not admit a locally small cover [AAL21].
</details>
<details>
<summary>摘要</summary>
我们研究了在对应条件下的数据隐私（DP）下预测混合的高斯分布的问题。我们的主要结果是，需要$\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$样本来预测$k$个高斯分布，到达条件下的差异量$\alpha$，并且满足$(\varepsilon, \delta)$-DP。这是首个不假设GMM的结构性质的终点复杂度上限。我们还提出了一个新的框架，可能对其他任务有用。高水平上，我们证明了如果一个分布集（如高斯分布）满足以下两个条件：一、可以列出decodable（如高斯分布），二、对于总差异量有"地方小"的覆盖（BKSW19），则这个分布集的混合是私有可学习的。证明绕过了已知的障碍，表明GMM不满足"地方小"的覆盖（AAL21）。
</details></li>
</ul>
<hr>
<h2 id="Gradient-Based-Feature-Learning-under-Structured-Data"><a href="#Gradient-Based-Feature-Learning-under-Structured-Data" class="headerlink" title="Gradient-Based Feature Learning under Structured Data"></a>Gradient-Based Feature Learning under Structured Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03843">http://arxiv.org/abs/2309.03843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alireza Mousavi-Hosseini, Denny Wu, Taiji Suzuki, Murat A. Erdogdu</li>
<li>for: 本文研究了单指数模型在带有峰值结构的输入数据上的学习复杂度，并发现了一些有趣的现象。</li>
<li>methods: 本文使用了各种方法，包括径向加速器和权重正规化，以处理带有峰值结构的输入数据。</li>
<li>results: 研究发现，在带有峰值结构的情况下，通常使用的径向加速器可能会导致错误的方向恢复，而适当的权重正规化可以解决这个问题。此外，通过利用输入峰值结构和目标之间的对齐，本文可以获得改进的样本复杂度和超越下界的 rotationally invariant kernel 方法。<details>
<summary>Abstract</summary>
Recent works have demonstrated that the sample complexity of gradient-based learning of single index models, i.e. functions that depend on a 1-dimensional projection of the input data, is governed by their information exponent. However, these results are only concerned with isotropic data, while in practice the input often contains additional structure which can implicitly guide the algorithm. In this work, we investigate the effect of a spiked covariance structure and reveal several interesting phenomena. First, we show that in the anisotropic setting, the commonly used spherical gradient dynamics may fail to recover the true direction, even when the spike is perfectly aligned with the target direction. Next, we show that appropriate weight normalization that is reminiscent of batch normalization can alleviate this issue. Further, by exploiting the alignment between the (spiked) input covariance and the target, we obtain improved sample complexity compared to the isotropic case. In particular, under the spiked model with a suitably large spike, the sample complexity of gradient-based training can be made independent of the information exponent while also outperforming lower bounds for rotationally invariant kernel methods.
</details>
<details>
<summary>摘要</summary>
近期研究显示，梯度基本学习单指数模型（即输入数据的1维投影函数）的样本复杂性被决定于其信息幂。但这些结果仅适用于各向同性数据，而在实际应用中输入数据通常具有附加的结构，这些结构可以通过梯度学习算法来导航。在这项工作中，我们调查了隐式协调结构的影响，并发现了一些有趣的现象。首先，我们发现在非各向同性设置下，通常使用的圆形梯度动力学可能无法回归真实方向，即使折射完全与目标方向一致。其次，我们发现适当的权重 нормализа可以解决这个问题。最后，通过利用输入协调矩阵和目标之间的对齐，我们获得了改进的样本复杂性，比如在隐式模型下，通过适当的权重 нормализа，梯度基本学习的样本复杂性可以独立于信息幂，同时超过了低界 для旋转不变kernel方法。
</details></li>
</ul>
<hr>
<h2 id="Early-warning-via-transitions-in-latent-stochastic-dynamical-systems"><a href="#Early-warning-via-transitions-in-latent-stochastic-dynamical-systems" class="headerlink" title="Early warning via transitions in latent stochastic dynamical systems"></a>Early warning via transitions in latent stochastic dynamical systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03842">http://arxiv.org/abs/2309.03842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingyu Feng, Ting Gao, Wang Xiao, Jinqiao Duan</li>
<li>for:  Early warnings for dynamical transitions in complex systems or high-dimensional observation data</li>
<li>methods:  Directed anisotropic diffusion map to capture latent evolutionary dynamics in low-dimensional manifold</li>
<li>results:  Successfully found appropriate effective coordinates and derived early warning signals capable of detecting tipping point during state transition, bridging latent dynamics with original dataset, validated as accurate and effective through numerical experiments.<details>
<summary>Abstract</summary>
Early warnings for dynamical transitions in complex systems or high-dimensional observation data are essential in many real world applications, such as gene mutation, brain diseases, natural disasters, financial crises, and engineering reliability. To effectively extract early warning signals, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in low-dimensional manifold. Applying the methodology to authentic electroencephalogram (EEG) data, we successfully find the appropriate effective coordinates, and derive early warning signals capable of detecting the tipping point during the state transition. Our method bridges the latent dynamics with the original dataset. The framework is validated to be accurate and effective through numerical experiments, in terms of density and transition probability. It is shown that the second coordinate holds meaningful information for critical transition in various evaluation metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>在复杂系统或高维观测数据中提供早期警示是许多实际应用中非常重要的，如基因变化、脑疾病、自然灾害、金融危机和工程可靠性。为了有效提取早期警示信号，我们开发了一种新的方法：指定方向的异otropic扩散地图，可以捕捉低维抽象 manifold 中的潜在演化动力学。通过应用这种方法，我们成功地找到了有效的坐标，并 derivation 出早期警示信号，可以检测状态过渡中的致点。我们的方法将潜在动力学与原始数据相连接。这种框架在数学实验中被证明是准确和有效的，在密度和过渡概率方面。结果显示，第二坐标包含了关键过渡中的有用信息。
</details></li>
</ul>
<hr>
<h2 id="Bootstrapping-Adaptive-Human-Machine-Interfaces-with-Offline-Reinforcement-Learning"><a href="#Bootstrapping-Adaptive-Human-Machine-Interfaces-with-Offline-Reinforcement-Learning" class="headerlink" title="Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning"></a>Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03839">http://arxiv.org/abs/2309.03839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jensen Gao, Siddharth Reddy, Glen Berseth, Anca D. Dragan, Sergey Levine<br>for:* 论文旨在帮助用户完成Sequential Decision-Making任务，如Robotic Teleoperation，使用含有噪音和维度的命令信号（例如从脑机器 interfaces）。methods:* 使用人类在循环机器学习中参与系统，以提高系统性能，但通常受到个人用户数据收集的限制。* 提出一种基于强化学习的算法，用于训练接口将原始命令信号映射到动作，使用线上预训练和线下细化。results:* 在12名参与者进行的模拟导航任务中，我们的方法能够更多地帮助用户完成目标，比基eline方向式接口更successful。* 在模拟的Sawyer推动任务和Lunar Lander游戏中，我们的方法也比基eline接口更好。* 对于模拟用户命令的杜氏实验表明，每个方法的组成部分均具有重要的作用。<details>
<summary>Abstract</summary>
Adaptive interfaces can help users perform sequential decision-making tasks like robotic teleoperation given noisy, high-dimensional command signals (e.g., from a brain-computer interface). Recent advances in human-in-the-loop machine learning enable such systems to improve by interacting with users, but tend to be limited by the amount of data that they can collect from individual users in practice. In this paper, we propose a reinforcement learning algorithm to address this by training an interface to map raw command signals to actions using a combination of offline pre-training and online fine-tuning. To address the challenges posed by noisy command signals and sparse rewards, we develop a novel method for representing and inferring the user's long-term intent for a given trajectory. We primarily evaluate our method's ability to assist users who can only communicate through noisy, high-dimensional input channels through a user study in which 12 participants performed a simulated navigation task by using their eye gaze to modulate a 128-dimensional command signal from their webcam. The results show that our method enables successful goal navigation more often than a baseline directional interface, by learning to denoise user commands signals and provide shared autonomy assistance. We further evaluate on a simulated Sawyer pushing task with eye gaze control, and the Lunar Lander game with simulated user commands, and find that our method improves over baseline interfaces in these domains as well. Extensive ablation experiments with simulated user commands empirically motivate each component of our method.
</details>
<details>
<summary>摘要</summary>
便捷 интерфейс可以帮助用户完成顺序决策任务，如机器人 теле操作，当 command signal 具有噪音和高维度特征时。现代人类在机器学习循环中的协作技术可以使这些系统进步，但它们通常受到个人用户数据收集的限制。在这篇论文中，我们提出了一种强化学习算法，用于训练 interface 将原始 command signal 映射到操作动作。为了解决噪音 command signal 和罕见奖励的挑战，我们开发了一种新的用户长期意图表示和推理方法。我们主要通过一个用户研究，在12名参与者通过眼睛移动控制128个command signal从webcam中获取的高维度指令信号中完成了一个模拟的导航任务，以证明我们的方法可以在噪音指令信号下帮助用户成功完成目标导航。此外，我们还在模拟的Sawyer推动任务和Lunar Lander游戏中使用眼睛控制，并发现我们的方法在这些领域中也超越基eline интерфей斯。我们还进行了大量的减少实验，以确认每个方法组件的实际效果。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Demonstration-via-Probabilistic-Diagrammatic-Teaching"><a href="#Learning-from-Demonstration-via-Probabilistic-Diagrammatic-Teaching" class="headerlink" title="Learning from Demonstration via Probabilistic Diagrammatic Teaching"></a>Learning from Demonstration via Probabilistic Diagrammatic Teaching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03835">http://arxiv.org/abs/2309.03835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiming Zhi, Tianyi Zhang, Matthew Johnson-Roberson</li>
<li>for: 本研究旨在开发一种新的示例教学（Diagrammatic Teaching）方法，以便让用户通过简单的图像示例来教育机器人新的技能。</li>
<li>methods: 该方法基于图像示例，用户可以通过简单地绘制2D图像来示例出想要教育机器人的动作轨迹。研究人员则使用了投影随机过程（RPTL）框架，将2D图像转化为3D空间中的动作轨迹。</li>
<li>results: 研究人员通过实验和实际应用 Validated the effectiveness of their proposed framework, showing that it can be used to teach new skills to both fixed-base and quadruped-mounted manipulators.<details>
<summary>Abstract</summary>
Learning for Demonstration (LfD) enables robots to acquire new skills by imitating expert demonstrations, allowing users to communicate their instructions in an intuitive manner. Recent progress in LfD often relies on kinesthetic teaching or teleoperation as the medium for users to specify the demonstrations. Kinesthetic teaching requires physical handling of the robot, while teleoperation demands proficiency with additional hardware. This paper introduces an alternative paradigm for LfD called Diagrammatic Teaching. Diagrammatic Teaching aims to teach robots novel skills by prompting the user to sketch out demonstration trajectories on 2D images of the scene, these are then synthesised as a generative model of motion trajectories in 3D task space. Additionally, we present the Ray-tracing Probabilistic Trajectory Learning (RPTL) framework for Diagrammatic Teaching. RPTL extracts time-varying probability densities from the 2D sketches, applies ray-tracing to find corresponding regions in 3D Cartesian space, and fits a probabilistic model of motion trajectories to these regions. New motion trajectories, which mimic those sketched by the user, can then be generated from the probabilistic model. We empirically validate our framework both in simulation and on real robots, which include a fixed-base manipulator and a quadruped-mounted manipulator.
</details>
<details>
<summary>摘要</summary>
学习示例（LfD）允许机器人学习新技能，通过复制专家示范，让用户通过直观的方式表达指令。现代进步通常基于手势教学或远程操作作为用户指定示范的媒体。手势教学需要机器人的物理执行，而远程操作需要额外硬件的熟悉。这篇论文介绍了一种替代方案called Diagrammatic Teaching。Diagrammatic Teaching的目标是通过让用户在2D场景图上绘制示范轨迹，并将其 sinthezied为3D任务空间的生成模型。此外，我们还提出了RAY-TRACING概率轨迹学（RPTL）框架。RPTL从2D绘制中提取时间变化的概率密度，应用RAY-TRACING找到相应的3D坐标空间中的区域，并适应一个概率性运动轨迹模型。新的运动轨迹可以通过这个模型来生成，这些轨迹与用户绘制的示范轨迹类似。我们在实验中Validation我们的框架，包括一个固定基 manipulator和一个四脚搭载 manipulator。
</details></li>
</ul>
<hr>
<h2 id="Prime-and-Modulate-Learning-Generation-of-forward-models-with-signed-back-propagation-and-environmental-cues"><a href="#Prime-and-Modulate-Learning-Generation-of-forward-models-with-signed-back-propagation-and-environmental-cues" class="headerlink" title="Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues"></a>Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03825">http://arxiv.org/abs/2309.03825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sama Daryanavard, Bernd Porr</li>
<li>for: 本研究旨在提出一种新的深度神经网络学习方法，以解决深度神经网络在误差反射传播学习过程中的扩散和消失梯度问题。</li>
<li>methods: 本研究使用了一种新的 Prime and Modulate 方法，它利用误差信号的正负pole来驱动学习，而不需要normalization技术或限制activation函数。</li>
<li>results: 实验结果表明， compared to conventional back-propagation方法， Prime and Modulate 方法可以快速提高学习的速度和稳定性。<details>
<summary>Abstract</summary>
Deep neural networks employing error back-propagation for learning can suffer from exploding and vanishing gradient problems. Numerous solutions have been proposed such as normalisation techniques or limiting activation functions to linear rectifying units. In this work we follow a different approach which is particularly applicable to closed-loop learning of forward models where back-propagation makes exclusive use of the sign of the error signal to prime the learning, whilst a global relevance signal modulates the rate of learning. This is inspired by the interaction between local plasticity and a global neuromodulation. For example, whilst driving on an empty road, one can allow for slow step-wise optimisation of actions, whereas, at a busy junction, an error must be corrected at once. Hence, the error is the priming signal and the intensity of the experience is a modulating factor in the weight change. The advantages of this Prime and Modulate paradigm is twofold: it is free from normalisation and it makes use of relevant cues from the environment to enrich the learning. We present a mathematical derivation of the learning rule in z-space and demonstrate the real-time performance with a robotic platform. The results show a significant improvement in the speed of convergence compared to that of the conventional back-propagation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Empirical-Risk-Minimization-for-Losses-without-Variance"><a href="#Empirical-Risk-Minimization-for-Losses-without-Variance" class="headerlink" title="Empirical Risk Minimization for Losses without Variance"></a>Empirical Risk Minimization for Losses without Variance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03818">http://arxiv.org/abs/2309.03818</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanhua Fang, Ping Li, Gennady Samorodnitsky<br>for: 这个论文考虑了一个Empirical Risk Minimization（ERM）问题在重 tailed 设置下，其数据没有固定方差，仅有 $p$-th moment，其中 $p \in (1,2)$。methods: 而不是使用 truncated 观察数据的估计过程，这个论文选择了使用 optimizer 来iminize 风险值。 Catoni 的方法 (Catoni, 2012) 可以帮助我们Robustly 估计风险值。通过 Catoni-type 影响函数的结构，我们可以通过 Generalized Generic Chaining 方法来确定过程溢出风险Upper Bounds。results: 我们在计算问题上进行了深入的理论研究，包括Robust Gradient Descent 算法和 Empirical Risk-based 方法。在广泛的数值研究中，我们发现optimizer 基于 Catoni-style 估计实际上在其他基线之上表现更好，这表明直接基于 truncated 数据进行估计可能会得到不满足的结果。<details>
<summary>Abstract</summary>
This paper considers an empirical risk minimization problem under heavy-tailed settings, where data does not have finite variance, but only has $p$-th moment with $p \in (1,2)$. Instead of using estimation procedure based on truncated observed data, we choose the optimizer by minimizing the risk value. Those risk values can be robustly estimated via using the remarkable Catoni's method (Catoni, 2012). Thanks to the structure of Catoni-type influence functions, we are able to establish excess risk upper bounds via using generalized generic chaining methods. Moreover, we take computational issues into consideration. We especially theoretically investigate two types of optimization methods, robust gradient descent algorithm and empirical risk-based methods. With an extensive numerical study, we find that the optimizer based on empirical risks via Catoni-style estimation indeed shows better performance than other baselines. It indicates that estimation directly based on truncated data may lead to unsatisfactory results.
</details>
<details>
<summary>摘要</summary>
这篇论文考虑了一个实际风险最小化问题，该问题在重 tailed 设定下进行，即数据不具有稳定 variance，仅仅具有 $p$-th 积分。而不是使用 truncated 观察数据的估计过程，我们选择了使用风险值来选择优化器。这些风险值可以通过 Catoni 方法 (Catoni, 2012) 进行可靠地估计。由于 Catoni-type 影响函数的结构，我们可以通过通用化 Generic Chaining 方法来确定过量风险上界。此外，我们还考虑了计算问题。我们特别是使用 robust 梯度下降算法和 empirical risk-based 方法进行优化。通过广泛的数值研究，我们发现了基于 empirical risks 的 Catoni-style 估计实际上比其他基准 mejor 的性能。这表明直接基于 truncated 数据进行估计可能会导致不满足的结果。
</details></li>
</ul>
<hr>
<h2 id="Improved-theoretical-guarantee-for-rank-aggregation-via-spectral-method"><a href="#Improved-theoretical-guarantee-for-rank-aggregation-via-spectral-method" class="headerlink" title="Improved theoretical guarantee for rank aggregation via spectral method"></a>Improved theoretical guarantee for rank aggregation via spectral method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03808">http://arxiv.org/abs/2309.03808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziliang Samuel Zhong, Shuyang Ling</li>
<li>for:  Ranking multiple items based on pairwise comparisons, with applications in sports, recommendation systems, and other web applications.</li>
<li>methods:  Spectral ranking algorithms based on unnormalized and normalized data matrices, with a focus on deriving entry-wise perturbation error bounds and an error bound on the maximum displacement for each item.</li>
<li>results:  Improved sample complexity and theoretical analysis of the eigenvectors and error bounds for the ranking problem, with confirmation from numerical experiments.<details>
<summary>Abstract</summary>
Given pairwise comparisons between multiple items, how to rank them so that the ranking matches the observations? This problem, known as rank aggregation, has found many applications in sports, recommendation systems, and other web applications. As it is generally NP-hard to find a global ranking that minimizes the mismatch (known as the Kemeny optimization), we focus on the Erd\"os-R\'enyi outliers (ERO) model for this ranking problem. Here, each pairwise comparison is a corrupted copy of the true score difference. We investigate spectral ranking algorithms that are based on unnormalized and normalized data matrices. The key is to understand their performance in recovering the underlying scores of each item from the observed data. This reduces to deriving an entry-wise perturbation error bound between the top eigenvectors of the unnormalized/normalized data matrix and its population counterpart. By using the leave-one-out technique, we provide a sharper $\ell_{\infty}$-norm perturbation bound of the eigenvectors and also derive an error bound on the maximum displacement for each item, with only $\Omega(n\log n)$ samples. Our theoretical analysis improves upon the state-of-the-art results in terms of sample complexity, and our numerical experiments confirm these theoretical findings.
</details>
<details>
<summary>摘要</summary>
In the ERO model, each pairwise comparison is a corrupted copy of the true score difference. We investigate spectral ranking algorithms that are based on unnormalized and normalized data matrices. The key is to understand their performance in recovering the underlying scores of each item from the observed data. This reduces to deriving an entry-wise perturbation error bound between the top eigenvectors of the unnormalized/normalized data matrix and its population counterpart.Using the leave-one-out technique, we provide a sharper $\ell_{\infty}$-norm perturbation bound of the eigenvectors and also derive an error bound on the maximum displacement for each item. Our theoretical analysis improves upon the state-of-the-art results in terms of sample complexity, and our numerical experiments confirm these theoretical findings.Here is the text in Simplified Chinese:给定多个对比的对象，如何将它们排序，以便与观测匹配？这个问题，称为排名聚合，在运动、推荐系统等领域都有广泛的应用。然而，找到一个全局排名，以最小化差异，是NP困难的，因此我们关注了 Erdős-Rényi 偏移（ERO）模型。在这个模型中，每个对比都是对真实分数差的损害版本。我们研究基于不归一化和归一化数据矩阵的spectral排名算法。关键在于理解它们在真实分数中还原数据的性能。这可以通过对数据矩阵的主 eigenvector 和人口矩阵的主 eigenvector 之间的入口级别偏差来解释。使用离散一个技术，我们提供了更加紧张的 $\ell _{\infty}$ 偏差 bound，以及每个对象的最大偏移 bound。我们的理论分析超过了当前最佳结果，并且我们的数值实验也证实了这些理论发现。
</details></li>
</ul>
<hr>
<h2 id="Conformal-Autoregressive-Generation-Beam-Search-with-Coverage-Guarantees"><a href="#Conformal-Autoregressive-Generation-Beam-Search-with-Coverage-Guarantees" class="headerlink" title="Conformal Autoregressive Generation: Beam Search with Coverage Guarantees"></a>Conformal Autoregressive Generation: Beam Search with Coverage Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03797">http://arxiv.org/abs/2309.03797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Deutschmann, Marvin Alberts, María Rodríguez Martínez</li>
<li>for: 这两个扩展都是为了使用幂搜索算法生成具有理论保证的序列集，以提高机器翻译和化学应用等领域的性能。</li>
<li>methods: 第一种方法是使用动态大小的子集 beam search 结果，但与传统的 CP  процедур不同，它的最高保证取决于后续调整度量。第二种算法则在解码过程中引入了具有可变宽度的幂集预测过程，该过程可以根据当前的不确定性来调整幂集宽度，并可以在先前选择保证。</li>
<li>results: 我们为每种方法提供了边缘保证 bound，并对其进行了实验评估，包括自然语言处理和化学等领域的任务。<details>
<summary>Abstract</summary>
We introduce two new extensions to the beam search algorithm based on conformal predictions (CP) to produce sets of sequences with theoretical coverage guarantees. The first method is very simple and proposes dynamically-sized subsets of beam search results but, unlike typical CP procedures, has an upper bound on the achievable guarantee depending on a post-hoc calibration measure. Our second algorithm introduces the conformal set prediction procedure as part of the decoding process, producing a variable beam width which adapts to the current uncertainty. While more complex, this procedure can achieve coverage guarantees selected a priori. We provide marginal coverage bounds for each method, and evaluate them empirically on a selection of tasks drawing from natural language processing and chemistry.
</details>
<details>
<summary>摘要</summary>
我们介绍两个基于对准预测（CP）的统计搜寻算法扩展，以生成具有理论覆盖保证的序列集。第一种方法非常简单，它在统计搜寻结果中动态地选择子集，但与传统CP程序不同，它的最高保证价随后续检测度量而定。我们的第二个算法则在解码过程中引入对准集预测程序，将统计搜寻结果中的宽度调整为目前的不确定程度。这个方法处理更加复杂，但可以预先选择保证。我们提供每方法的边界覆盖保证，并对其进行实验评估，包括自然语言处理和化学领域的任务。
</details></li>
</ul>
<hr>
<h2 id="Adversarially-Robust-Deep-Learning-with-Optimal-Transport-Regularized-Divergences"><a href="#Adversarially-Robust-Deep-Learning-with-Optimal-Transport-Regularized-Divergences" class="headerlink" title="Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences"></a>Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03791">http://arxiv.org/abs/2309.03791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeremiah Birrell, Mohammadreza Ebrahimi</li>
<li>For: The paper aims to enhance the adversarial robustness of deep learning models against various attacks, such as FGSM and PGD.* Methods: The paper proposes a novel approach called $ARMOR_D$, which uses optimal-transport-regularized divergences to enhance adversarial robustness. This approach involves maximizing the expected loss over a neighborhood of distributions, known as distributionally robust optimization.* Results: The paper demonstrates the effectiveness of $ARMOR_D$ on malware detection and image recognition applications, achieving higher robustness against adversarial attacks compared to prior methods. Specifically, $ARMOR_D$ yields a robustified accuracy of 98.29% against FGSM and 98.18% against PGD on the MNIST dataset, and improves the robustified accuracy in malware detection by 37.0% compared to previous best-performing methods.<details>
<summary>Abstract</summary>
We introduce the $ARMOR_D$ methods as novel approaches to enhancing the adversarial robustness of deep learning models. These methods are based on a new class of optimal-transport-regularized divergences, constructed via an infimal convolution between an information divergence and an optimal-transport (OT) cost. We use these as tools to enhance adversarial robustness by maximizing the expected loss over a neighborhood of distributions, a technique known as distributionally robust optimization. Viewed as a tool for constructing adversarial samples, our method allows samples to be both transported, according to the OT cost, and re-weighted, according to the information divergence. We demonstrate the effectiveness of our method on malware detection and image recognition applications and find that, to our knowledge, it outperforms existing methods at enhancing the robustness against adversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\%$ against $FGSM$ and $98.18\%$ against $PGD^{40}$ on the MNIST dataset, reducing the error rate by more than $19.7\%$ and $37.2\%$ respectively compared to prior methods. Similarly, in malware detection, a discrete (binary) data domain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack compared to the previous best-performing adversarial training methods by $37.0\%$ while lowering false negative and false positive rates by $51.1\%$ and $57.53\%$, respectively.
</details>
<details>
<summary>摘要</summary>
我们介绍$ARMOR_D$方法作为深度学习模型的攻击抗性增强方法。这些方法基于一种新的最佳运输规则化分散，通过infimal混合两种信息分散和最佳运输（OT）成本。我们使用这些工具增强攻击抗性，通过范围内的分布预期损失最大化，称为分布式准确估算。 viewed as a sample生成工具，我们的方法可以将样本运输 according to OT 成本，并重新权重 according to 信息分散。我们在这篇文章中证明了$ARMOR_D$ 的有效性，在运算系统识别和图像识别应用中，它可以比对现有方法提高抗性 against 攻击攻击。 $ARMOR_D$ 在 MNIST dataset 上获得了$98.29\%$ 的抗性精度，比对 $FGSM$ 和 $PGD^{40}$ 攻击下的最佳性能优化 $19.7\%$ 和 $37.2\%$ 。在运算系统识别中，一个简单的二进制数据领域，$ARMOR_D$ 可以比对先前最佳的对抗训练方法提高抗性精度 $37.0\%$，同时降低伪阳性和伪阴性的比率 $51.1\%$ 和 $57.53\%$。
</details></li>
</ul>
<hr>
<h2 id="Neural-lasso-a-unifying-approach-of-lasso-and-neural-networks"><a href="#Neural-lasso-a-unifying-approach-of-lasso-and-neural-networks" class="headerlink" title="Neural lasso: a unifying approach of lasso and neural networks"></a>Neural lasso: a unifying approach of lasso and neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03770">http://arxiv.org/abs/2309.03770</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Delgado, Ernesto Curbelo, Danae Carreras</li>
<li>for: 本文目的是将统计技术与机器学习技术结合使用，以获得两者之间的优点。</li>
<li>methods: 本文使用神经网络表示统计技术lasso的变量选择。两者的目标函数相同，但是它们的优化不同。神经网络版本通常在一步使用单个验证集进行优化，而统计方法则使用两步优化基于交叉验证。统计方法的更复杂的优化导致更准确的参数估计，特别是当训练集较小时。</li>
<li>results: 在开发修改后，一种新的优化算法 для标识重要变量出现了。使用 sintetic和实际数据集进行实验表明，这种新的优化算法在三种之前的优化方法中表现更好。<details>
<summary>Abstract</summary>
In recent years, there is a growing interest in combining techniques attributed to the areas of Statistics and Machine Learning in order to obtain the benefits of both approaches. In this article, the statistical technique lasso for variable selection is represented through a neural network. It is observed that, although both the statistical approach and its neural version have the same objective function, they differ due to their optimization. In particular, the neural version is usually optimized in one-step using a single validation set, while the statistical counterpart uses a two-step optimization based on cross-validation. The more elaborated optimization of the statistical method results in more accurate parameter estimation, especially when the training set is small. For this reason, a modification of the standard approach for training neural networks, that mimics the statistical framework, is proposed. During the development of the above modification, a new optimization algorithm for identifying the significant variables emerged. Experimental results, using synthetic and real data sets, show that this new optimization algorithm achieves better performance than any of the three previous optimization approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Convergence-Analysis-of-Decentralized-ASGD"><a href="#Convergence-Analysis-of-Decentralized-ASGD" class="headerlink" title="Convergence Analysis of Decentralized ASGD"></a>Convergence Analysis of Decentralized ASGD</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03754">http://arxiv.org/abs/2309.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mauro DL Tosi, Martin Theobald</li>
<li>for: 这个论文目的是提出了一种新的异步Stochastic Gradient Descent（DASGD）算法，以提高训练时间的效率。</li>
<li>methods: 这个论文使用了异步SGD算法，并提供了一种新的速度分析方法，不需要分布式参数服务器，可以在多个分布式进程之间进行异步计算。</li>
<li>results: 论文提出了一个新的速度分析方法，可以保证DASGD算法在不同网络拓扑和缓存环境下的 converges 速度为 $\mathcal{O}(\sigma\epsilon^{-2}) + \mathcal{O}(QS_{avg}\epsilon^{-3&#x2F;2}) + \mathcal{O}(S_{avg}\epsilon^{-1})$，其中 $S_{avg}$ 是模型之间的均值差，$Q$ 是惩罚函数的最大值，$\epsilon$ 是允许的误差。<details>
<summary>Abstract</summary>
Over the last decades, Stochastic Gradient Descent (SGD) has been intensively studied by the Machine Learning community. Despite its versatility and excellent performance, the optimization of large models via SGD still is a time-consuming task. To reduce training time, it is common to distribute the training process across multiple devices. Recently, it has been shown that the convergence of asynchronous SGD (ASGD) will always be faster than mini-batch SGD. However, despite these improvements in the theoretical bounds, most ASGD convergence-rate proofs still rely on a centralized parameter server, which is prone to become a bottleneck when scaling out the gradient computations across many distributed processes.   In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) which does not require partial synchronization among nodes nor restrictive network topologies. Specifically, we provide a bound of $\mathcal{O}(\sigma\epsilon^{-2}) + \mathcal{O}(QS_{avg}\epsilon^{-3/2}) + \mathcal{O}(S_{avg}\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\epsilon$ is a (small) error that is allowed within the bound. Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\mathcal{O}(\sigma\epsilon^{-2}) + \mathcal{O}(\sqrt{\hat{S}_{avg}\hat{S}_{max}\epsilon^{-1})$, with $\hat{S}_{max}$ and $\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively. Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function. We anticipate that our results will be of high relevance for the adoption of DASGD by a broad community of researchers and developers.
</details>
<details>
<summary>摘要</summary>
Over the past few decades, Stochastic Gradient Descent (SGD) has been extensively studied by the Machine Learning community. Despite its versatility and excellent performance, optimizing large models via SGD is still a time-consuming task. To reduce training time, it is common to distribute the training process across multiple devices. Recently, it has been shown that the convergence of asynchronous SGD (ASGD) is faster than mini-batch SGD. However, most ASGD convergence-rate proofs rely on a centralized parameter server, which can become a bottleneck when scaling out the gradient computations across many distributed processes.In this paper, we present a novel convergence-rate analysis for decentralized and asynchronous SGD (DASGD) that does not require partial synchronization among nodes nor restrictive network topologies. Specifically, we provide a bound of $\mathcal{O}(\sigma\epsilon^{-2}) + \mathcal{O}(QS_{avg}\epsilon^{-3/2}) + \mathcal{O}(S_{avg}\epsilon^{-1})$ for the convergence rate of DASGD, where $S_{avg}$ is the average staleness between models, $Q$ is a constant that bounds the norm of the gradients, and $\epsilon$ is a small error allowed within the bound. Furthermore, when gradients are not bounded, we prove the convergence rate of DASGD to be $\mathcal{O}(\sigma\epsilon^{-2}) + \mathcal{O}(\sqrt{\hat{S}_{avg}\hat{S}_{max}\epsilon^{-1})$, with $\hat{S}_{max}$ and $\hat{S}_{avg}$ representing a loose version of the average and maximum staleness, respectively. Our convergence proof holds for a fixed stepsize and any non-convex, homogeneous, and L-smooth objective function. We expect that our results will be highly relevant for the adoption of DASGD by a broad community of researchers and developers.
</details></li>
</ul>
<hr>
<h2 id="Medoid-Silhouette-clustering-with-automatic-cluster-number-selection"><a href="#Medoid-Silhouette-clustering-with-automatic-cluster-number-selection" class="headerlink" title="Medoid Silhouette clustering with automatic cluster number selection"></a>Medoid Silhouette clustering with automatic cluster number selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03751">http://arxiv.org/abs/2309.03751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lars Lenssen, Erich Schubert</li>
<li>For: The paper is written to discuss and improve the efficiency of the Silhouette method for clustering evaluation, specifically the medoid-based variant.* Methods: The paper uses the Silhouette method and combines it with the PAM algorithm to improve the efficiency of the clustering evaluation. The authors propose two fast versions of the algorithm and provide a theoretical analysis of its properties.* Results: The authors report a speedup of $O(k^2)$ compared to the original PAMMEDSIL algorithm on real data with 30000 samples and 100 clusters. They also provide a variant to choose the optimal number of clusters directly.<details>
<summary>Abstract</summary>
The evaluation of clustering results is difficult, highly dependent on the evaluated data set and the perspective of the beholder. There are many different clustering quality measures, which try to provide a general measure to validate clustering results. A very popular measure is the Silhouette. We discuss the efficient medoid-based variant of the Silhouette, perform a theoretical analysis of its properties, provide two fast versions for the direct optimization, and discuss the use to choose the optimal number of clusters. We combine ideas from the original Silhouette with the well-known PAM algorithm and its latest improvements FasterPAM. One of the versions guarantees equal results to the original variant and provides a run speedup of $O(k^2)$. In experiments on real data with 30000 samples and $k$=100, we observed a 10464$\times$ speedup compared to the original PAMMEDSIL algorithm. Additionally, we provide a variant to choose the optimal number of clusters directly.
</details>
<details>
<summary>摘要</summary>
evaluating clustering results 是一项困难的任务，具有数据集和观点的依赖性。有很多不同的归类质量指标，它们试图为归类结果提供一个通用的验证方法。Silhouette 是一个非常受欢迎的指标之一。我们讨论了基于 medoid 的 Silhouette 变体，进行了理论分析其属性，并提供了两种快速版本用于直接优化。我们还讨论了如何选择最佳归类数量。我们将原始 Silhouette 的想法与 Pam 算法和其最新改进 FasterPAM 结合，提供了一种可以保证结果相同性的版本，并且提供了 $O(k^2)$ 的运行速度提升。在实际数据上进行了30000个样本和 $k$ = 100 的实验，我们发现了一个10464倍的速度提升，相比原始 PAMMEDSIL 算法。此外，我们还提供了一种直接选择最佳归类数量的变体。
</details></li>
</ul>
<hr>
<h2 id="Learning-continuous-valued-treatment-effects-through-representation-balancing"><a href="#Learning-continuous-valued-treatment-effects-through-representation-balancing" class="headerlink" title="Learning continuous-valued treatment effects through representation balancing"></a>Learning continuous-valued treatment effects through representation balancing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03731">http://arxiv.org/abs/2309.03731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/christopher-br/cbrnet">https://github.com/christopher-br/cbrnet</a></li>
<li>paper_authors: Christopher Bockel-Rickermann, Toon Vanderschueren, Jeroen Berrevoets, Tim Verdonck, Wouter Verbeke</li>
<li>for: 估计在不同剂量下的治疗效果，以及剂量对结果的影响，是各种领域的重要问题，从医疗到商业、经济等。</li>
<li>methods: 该研究使用了 causal machine learning 方法来估计来自观察数据的个体剂量回应。该方法基于 Neyman-Rubin 潜在结果框架，并对连续型剂量进行了扩展，以确保缓解选择偏见。</li>
<li>results: 我们的实验表明，CBRNet 可以准确地估计剂量回应，并与其他当前状态的方法竞争。<details>
<summary>Abstract</summary>
Estimating the effects of treatments with an associated dose on an instance's outcome, the "dose response", is relevant in a variety of domains, from healthcare to business, economics, and beyond. Such effects, also known as continuous-valued treatment effects, are typically estimated from observational data, which may be subject to dose selection bias. This means that the allocation of doses depends on pre-treatment covariates. Previous studies have shown that conventional machine learning approaches fail to learn accurate individual estimates of dose responses under the presence of dose selection bias. In this work, we propose CBRNet, a causal machine learning approach to estimate an individual dose response from observational data. CBRNet adopts the Neyman-Rubin potential outcome framework and extends the concept of balanced representation learning for overcoming selection bias to continuous-valued treatments. Our work is the first to apply representation balancing in a continuous-valued treatment setting. We evaluate our method on a newly proposed benchmark. Our experiments demonstrate CBRNet's ability to accurately learn treatment effects under selection bias and competitive performance with respect to other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
估算干预对象的结果的影响，即“剂量响应”，在各种领域都是重要的，从医疗到商业、经济等等。这些影响通常从观察数据中被估算，但可能受到剂量选择偏见的影响。这意味着剂量分配取决于先前的 covariates。先前的研究表明，常规机器学习方法在存在剂量选择偏见的情况下不能准确地学习个体剂量响应。在这项工作中，我们提议CBRNet，一种 causal机器学习方法，用于从观察数据中估算个体剂量响应。CBRNet采用Neyman-Rubin potential outcome框架，并将权衡表现学习概念应用到连续型剂量上。我们的工作是首次在连续型剂量设置下应用表现权衡。我们对一个新提出的 benchmark进行了测试，并证明CBRNet可以准确地学习受选择偏见影响的剂量响应，并与其他现有的状态 искусственный智能方法竞争。
</details></li>
</ul>
<hr>
<h2 id="A-Causal-Perspective-on-Loan-Pricing-Investigating-the-Impacts-of-Selection-Bias-on-Identifying-Bid-Response-Functions"><a href="#A-Causal-Perspective-on-Loan-Pricing-Investigating-the-Impacts-of-Selection-Bias-on-Identifying-Bid-Response-Functions" class="headerlink" title="A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions"></a>A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03730">http://arxiv.org/abs/2309.03730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Bockel-Rickermann, Sam Verboven, Tim Verdonck, Wouter Verbeke</li>
<li>for: 这个论文的目的是研究个性化价格策略的实现，以及如何对 selección bias 的影响。</li>
<li>methods: 这篇论文使用了 causal 机器学习方法，包括 logistic regression 和 neural networks，以及 state-of-the-art 方法来抗 selección bias。</li>
<li>results: 研究发现， selección bias 会导致传统方法的准确率下降，但是使用 state-of-the-art 方法可以有效地抗 selección bias。<details>
<summary>Abstract</summary>
In lending, where prices are specific to both customers and products, having a well-functioning personalized pricing policy in place is essential to effective business making. Typically, such a policy must be derived from observational data, which introduces several challenges. While the problem of ``endogeneity'' is prominently studied in the established pricing literature, the problem of selection bias (or, more precisely, bid selection bias) is not. We take a step towards understanding the effects of selection bias by posing pricing as a problem of causal inference. Specifically, we consider the reaction of a customer to price a treatment effect. In our experiments, we simulate varying levels of selection bias on a semi-synthetic dataset on mortgage loan applications in Belgium. We investigate the potential of parametric and nonparametric methods for the identification of individual bid-response functions. Our results illustrate how conventional methods such as logistic regression and neural networks suffer adversely from selection bias. In contrast, we implement state-of-the-art methods from causal machine learning and show their capability to overcome selection bias in pricing data.
</details>
<details>
<summary>摘要</summary>
在贷款领域，因为价格对于客户和产品都是特定的，有效的个性化价格策略是非常重要。通常，这种策略需要基于观察数据来 derivation，这会带来一些挑战。而“内生性”问题在已有的价格理论中已经得到了广泛的研究，但是“投标偏见”问题却没有得到了相应的研究。我们在价格问题上采用 causal inference 的方法来解决这个问题。 Specifically, we consider the reaction of a customer to price as a treatment effect.在我们的实验中，我们使用 semi-synthetic 数据集来模拟不同水平的选择偏见。我们 investigate 了 parametric 和 nonparametric 方法在个bid-response函数的标识方面的潜力。我们的结果表明，使用常见的 logistic regression 和神经网络方法会受到选择偏见的害。相反，我们使用 state-of-the-art 的 causal machine learning 方法，并证明它们可以在价格数据中超越选择偏见。
</details></li>
</ul>
<hr>
<h2 id="DGSD-Dynamical-Graph-Self-Distillation-for-EEG-Based-Auditory-Spatial-Attention-Detection"><a href="#DGSD-Dynamical-Graph-Self-Distillation-for-EEG-Based-Auditory-Spatial-Attention-Detection" class="headerlink" title="DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial Attention Detection"></a>DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial Attention Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07147">http://arxiv.org/abs/2309.07147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cunhang Fan, Hongyu Zhang, Wei Huang, Jun Xue, Jianhua Tao, Jiangyan Yi, Zhao Lv, Xiaopei Wu</li>
<li>for: 这篇论文的目的是检测脑电声纳中的target speaker，以提高多个说话人环境中的听力注意力检测精度。</li>
<li>methods: 该论文提出了一种基于动态图自适应（DGSD）方法，不需要输入语音刺激。使用动态图 convolutional neural networks 表示 EEG 信号的图 структуры，可以提取关键与听力注意力相关的 EEG 信号特征。此外，该方法还应用了自适应策略，包括特征维度和层次维度的自适应策略，以提高听力注意力检测性能。</li>
<li>results: 该论文在 KUL 和 DTU 两个公共数据集上进行了实验，在 1 秒时间窗口内达到了 90.0% 和 79.6% 的检测精度。与比较方法相比，该方法的检测性能不仅高于最佳可重制基线，而且可以大幅减少 Trainable 参数的数量，约 100 倍。<details>
<summary>Abstract</summary>
Auditory Attention Detection (AAD) aims to detect target speaker from brain signals in a multi-speaker environment. Although EEG-based AAD methods have shown promising results in recent years, current approaches primarily rely on traditional convolutional neural network designed for processing Euclidean data like images. This makes it challenging to handle EEG signals, which possess non-Euclidean characteristics. In order to address this problem, this paper proposes a dynamical graph self-distillation (DGSD) approach for AAD, which does not require speech stimuli as input. Specifically, to effectively represent the non-Euclidean properties of EEG signals, dynamical graph convolutional networks are applied to represent the graph structure of EEG signals, which can also extract crucial features related to auditory spatial attention in EEG signals. In addition, to further improve AAD detection performance, self-distillation, consisting of feature distillation and hierarchical distillation strategies at each layer, is integrated. These strategies leverage features and classification results from the deepest network layers to guide the learning of shallow layers. Our experiments are conducted on two publicly available datasets, KUL and DTU. Under a 1-second time window, we achieve results of 90.0\% and 79.6\% accuracy on KUL and DTU, respectively. We compare our DGSD method with competitive baselines, and the experimental results indicate that the detection performance of our proposed DGSD method is not only superior to the best reproducible baseline but also significantly reduces the number of trainable parameters by approximately 100 times.
</details>
<details>
<summary>摘要</summary>
听觉注意点检测（AAD）目标是从脑电壳中检测目标说话人。尽管使用EEG信号的AAD方法在过去几年中获得了可观的成果，但现有方法主要依靠传统的卷积神经网络来处理Euclidean数据，这使得处理EEG信号变得困难。为了解决这个问题，本文提出了一种基于动态图自适应（DGSD）的AAD方法，不需要语音刺激作为输入。具体来说，使用动态图卷积网络来表示EEG信号的图 структуры，可以提取EEG信号中关键的听觉空间注意力特征。此外，为了进一步改善AAD检测性能，我们采用了自适应策略，包括特征退化和层次退化策略，这些策略可以在每层使用特征和分类结果来导引深层网络的学习。我们在KUL和DTU两个公共可用的数据集上进行实验，在1秒时间窗口内，我们达到了90.0%和79.6%的检测精度。我们与比较baseline方法进行比较，实验结果表明，我们提出的DGSD方法不仅在检测性能方面超过了最佳可重制baseline，而且可以降低大约100倍的训练参数数量。
</details></li>
</ul>
<hr>
<h2 id="A-State-Representation-for-Diminishing-Rewards"><a href="#A-State-Representation-for-Diminishing-Rewards" class="headerlink" title="A State Representation for Diminishing Rewards"></a>A State Representation for Diminishing Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03710">http://arxiv.org/abs/2309.03710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ted Moskovitz, Samo Hromadka, Ahmed Touati, Diana Borsa, Maneesh Sahani</li>
<li>for: 本研究旨在研究多任务动作学习中，agent需要快速适应不同的静态奖励函数。</li>
<li>methods: 本研究使用了Successor Representation（SR）框架，它可以快速评估策略的预期减少价值。然而，在自然世界中，继任任务 rarely是独立的，而是受到奖励刺激的可用性和主观感知的影响。</li>
<li>results: 本研究发现了递减偏好的现象，并提出了一种新的状态表示方法，即λ表示（λR），它可以替代SR并总结了一些从文献中提出的状态表示方法。我们证明了λR的正式性质，并考虑了其在机器学习中的 normative 优点以及其在研究自然行为中的实用性。<details>
<summary>Abstract</summary>
A common setting in multitask reinforcement learning (RL) demands that an agent rapidly adapt to various stationary reward functions randomly sampled from a fixed distribution. In such situations, the successor representation (SR) is a popular framework which supports rapid policy evaluation by decoupling a policy's expected discounted, cumulative state occupancies from a specific reward function. However, in the natural world, sequential tasks are rarely independent, and instead reflect shifting priorities based on the availability and subjective perception of rewarding stimuli. Reflecting this disjunction, in this paper we study the phenomenon of diminishing marginal utility and introduce a novel state representation, the $\lambda$ representation ($\lambda$R) which, surprisingly, is required for policy evaluation in this setting and which generalizes the SR as well as several other state representations from the literature. We establish the $\lambda$R's formal properties and examine its normative advantages in the context of machine learning, as well as its usefulness for studying natural behaviors, particularly foraging.
</details>
<details>
<summary>摘要</summary>
通常的多任务强化学习（RL）中，一个代理人需要快速适应不同的站立奖励函数的随机抽取。在这种情况下，继承表示（SR）是一种广泛使用的框架，它支持快速政策评估 by 分离一个政策的预期减少价值函数和特定奖励函数。然而，在自然世界中，序列任务很少是独立的，而是基于奖励刺激的可用性和主观感受的变化。为了反映这种分歧，在这篇论文中，我们研究了减少的边际效用现象，并引入了一种新的状态表示，即 $\lambda$ 表示（$\lambda$R），这种表示 surprisingly 需要为政策评估。我们证明了 $\lambda$R 的正式性质，并在机器学习中对其的正式优点进行了调研，以及在自然行为研究中的实用性。
</details></li>
</ul>
<hr>
<h2 id="Chat-Failures-and-Troubles-Reasons-and-Solutions"><a href="#Chat-Failures-and-Troubles-Reasons-and-Solutions" class="headerlink" title="Chat Failures and Troubles: Reasons and Solutions"></a>Chat Failures and Troubles: Reasons and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03708">http://arxiv.org/abs/2309.03708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manal Helal, Patrick Holthaus, Gabriella Lakatos, Farshid Amirabdollahian</li>
<li>for: 这种研究旨在解决人机交互（HRI）中常见的问题，导致聊天失败和困难。</li>
<li>methods: 该研究使用了适当的机器人和聊天模型，识别常见的问题并提出解决方案，并规划了持续改进。</li>
<li>results: 研究建议使用封闭控制算法，使用已经训练的人工智能（AI）预训练模型，提供词汇筛选、批处理新数据集、在数据流中学习、或者使用强化学习模型自动更新训练模型，以减少错误。<details>
<summary>Abstract</summary>
This paper examines some common problems in Human-Robot Interaction (HRI) causing failures and troubles in Chat. A given use case's design decisions start with the suitable robot, the suitable chatting model, identifying common problems that cause failures, identifying potential solutions, and planning continuous improvement. In conclusion, it is recommended to use a closed-loop control algorithm that guides the use of trained Artificial Intelligence (AI) pre-trained models and provides vocabulary filtering, re-train batched models on new datasets, learn online from data streams, and/or use reinforcement learning models to self-update the trained models and reduce errors.
</details>
<details>
<summary>摘要</summary>
这篇论文研究了人机交互（HRI）在聊天中出现的一些常见问题，导致故障和困难。这个用例的设计决策从适合的机器人、适合的聊天模型开始，并识别常见的故障原因、潜在的解决方案，以及不断改进计划。结论是使用封闭控制算法，使用已经训练的人工智能（AI）预训练模型进行 vocabulary 筛选、批处理新数据集来重新训练模型，在数据流中学习在线，以及使用奖励学习模型自动更新训练模型以减少错误。
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Semi-Supervised-Approach-with-Triplet-Markov-Chains"><a href="#A-Probabilistic-Semi-Supervised-Approach-with-Triplet-Markov-Chains" class="headerlink" title="A Probabilistic Semi-Supervised Approach with Triplet Markov Chains"></a>A Probabilistic Semi-Supervised Approach with Triplet Markov Chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03707">http://arxiv.org/abs/2309.03707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katherine Morales, Yohan Petetin</li>
<li>for: 这篇论文是用于描述一种基于变量 Bayesian 推理的半supervised triplet Markov chain模型训练方法。</li>
<li>methods: 该方法使用变量 Bayesian 推理来训练半supervised triplet Markov chain模型，并可以应用于多种逻辑 Bayesian 分类模型。</li>
<li>results: 该方法可以在半supervised情况下提高 triplet Markov chain模型的训练效果，并且可以应用于多种逻辑 Bayesian 分类模型。<details>
<summary>Abstract</summary>
Triplet Markov chains are general generative models for sequential data which take into account three kinds of random variables: (noisy) observations, their associated discrete labels and latent variables which aim at strengthening the distribution of the observations and their associated labels. However, in practice, we do not have at our disposal all the labels associated to the observations to estimate the parameters of such models. In this paper, we propose a general framework based on a variational Bayesian inference to train parameterized triplet Markov chain models in a semi-supervised context. The generality of our approach enables us to derive semi-supervised algorithms for a variety of generative models for sequential Bayesian classification.
</details>
<details>
<summary>摘要</summary>
三重马尔可夫链是一种通用的生成模型，用于处理序列数据，它考虑了三种随机变量：受损的观察值、其关联的整数标签以及隐藏的变量，以强化观察值和其关联的标签的分布。然而，在实践中，我们通常不 dispon�ible all the labels associated with the observations to estimate the parameters of such models。在这篇论文中，我们提出了一种基于变量 bayesian 推理的通用框架，用于在半指导下训练参数化的三重马尔可夫链模型。我们的方法的通用性使得我们可以 derivate 半指导的算法 для多种生成模型，用于随机分类。
</details></li>
</ul>
<hr>
<h2 id="Short-Term-Load-Forecasting-Using-A-Particle-Swarm-Optimized-Multi-Head-Attention-Augmented-CNN-LSTM-Network"><a href="#Short-Term-Load-Forecasting-Using-A-Particle-Swarm-Optimized-Multi-Head-Attention-Augmented-CNN-LSTM-Network" class="headerlink" title="Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head Attention-Augmented CNN-LSTM Network"></a>Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head Attention-Augmented CNN-LSTM Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03694">http://arxiv.org/abs/2309.03694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paapa Kwesi Quansah, Edwin Kwesi Ansah Tenkorang</li>
<li>for: 短期负载预测的重要性在电力系统中，因为它的自然非线性和动态性。</li>
<li>methods: 我们的方法使用Particle-Swarm Optimization算法来自动探索和优化参数，Multi-Head Attention机制来挑出精确预测的重要特征，以及一个减少Computational Overhead的框架。</li>
<li>results: 我们的方法在使用真实的电力需求数据进行评估中，表现出超过现有州际优秀方法的精度、可靠性和Computational Efficiency。特别是，我们的 Mean Absolute Percentage Error 为 1.9376，与现有方法相比，表明我们的方法开启了一个新的时代。<details>
<summary>Abstract</summary>
Short-term load forecasting is of paramount importance in the efficient operation and planning of power systems, given its inherent non-linear and dynamic nature. Recent strides in deep learning have shown promise in addressing this challenge. However, these methods often grapple with hyperparameter sensitivity, opaqueness in interpretability, and high computational overhead for real-time deployment. In this paper, I propose a novel solution that surmounts these obstacles. Our approach harnesses the power of the Particle-Swarm Optimization algorithm to autonomously explore and optimize hyperparameters, a Multi-Head Attention mechanism to discern the salient features crucial for accurate forecasting, and a streamlined framework for computational efficiency. Our method undergoes rigorous evaluation using a genuine electricity demand dataset. The results underscore its superiority in terms of accuracy, robustness, and computational efficiency. Notably, our Mean Absolute Percentage Error of 1.9376 marks a significant advancement over existing state-of-the-art approaches, heralding a new era in short-term load forecasting.
</details>
<details>
<summary>摘要</summary>
短期负载预测是电力系统的重要任务，因为它的本质具有非线性和动态特性。Recent advances in deep learning have shown promise in addressing this challenge. However, these methods often struggle with hyperparameter sensitivity, lack of interpretability, and high computational overhead for real-time deployment. In this paper, I propose a novel solution that overcomes these challenges. Our approach leverages the power of the Particle-Swarm Optimization algorithm to automatically explore and optimize hyperparameters, a Multi-Head Attention mechanism to identify the crucial features for accurate forecasting, and a streamlined framework for computational efficiency. Our method undergoes rigorous evaluation using a genuine electricity demand dataset. The results demonstrate its superiority in terms of accuracy, robustness, and computational efficiency. Notably, our Mean Absolute Percentage Error of 1.9376 represents a significant improvement over existing state-of-the-art approaches, marking a new era in short-term load forecasting.Here's the translation of the text into Traditional Chinese:短期负载预测是电力系统的重要任务，因为它的本质具有非线性和动态特性。Recent advances in deep learning have shown promise in addressing this challenge. However, these methods often struggle with hyperparameter sensitivity, lack of interpretability, and high computational overhead for real-time deployment. In this paper, I propose a novel solution that overcomes these challenges. Our approach leverages the power of the Particle-Swarm Optimization algorithm to automatically explore and optimize hyperparameters, a Multi-Head Attention mechanism to identify the crucial features for accurate forecasting, and a streamlined framework for computational efficiency. Our method undergoes rigorous evaluation using a genuine electricity demand dataset. The results demonstrate its superiority in terms of accuracy, robustness, and computational efficiency. Notably, our Mean Absolute Percentage Error of 1.9376 represents a significant improvement over existing state-of-the-art approaches, marking a new era in short-term load forecasting.
</details></li>
</ul>
<hr>
<h2 id="A-computationally-lightweight-safe-learning-algorithm"><a href="#A-computationally-lightweight-safe-learning-algorithm" class="headerlink" title="A computationally lightweight safe learning algorithm"></a>A computationally lightweight safe learning algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03672">http://arxiv.org/abs/2309.03672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Baumann, Krzysztof Kowalczyk, Koen Tiels, Paweł Wachel</li>
<li>for: 本研究旨在提供一种安全学习算法，可以在训练过程中提供概率性安全保证，而无需知道系统动力学模型。</li>
<li>methods: 本研究使用 Nadaraya-Watson 估计器，而不是 Gaussian 过程估计器，以实现很高效的计算。</li>
<li>results: 我们提供了理论保证，并将其嵌入到一种安全学习算法中，并通过对七度自由运动机械人模拟器进行数学实验来证明。<details>
<summary>Abstract</summary>
Safety is an essential asset when learning control policies for physical systems, as violating safety constraints during training can lead to expensive hardware damage. In response to this need, the field of safe learning has emerged with algorithms that can provide probabilistic safety guarantees without knowledge of the underlying system dynamics. Those algorithms often rely on Gaussian process inference. Unfortunately, Gaussian process inference scales cubically with the number of data points, limiting applicability to high-dimensional and embedded systems. In this paper, we propose a safe learning algorithm that provides probabilistic safety guarantees but leverages the Nadaraya-Watson estimator instead of Gaussian processes. For the Nadaraya-Watson estimator, we can reach logarithmic scaling with the number of data points. We provide theoretical guarantees for the estimates, embed them into a safe learning algorithm, and show numerical experiments on a simulated seven-degrees-of-freedom robot manipulator.
</details>
<details>
<summary>摘要</summary>
安全是控制系统学习的重要资产，因为违反安全约束 During training可能会导致设备损坏。为应对这一需求，安全学习领域出现了一些算法，可以提供概率安全保证而无需系统动力学知识。这些算法通常基于 Gaussian process 推理。可惜的是，Gaussian process 推理的计算复杂度随着数据点数的增加而呈 кубиック增长，因此对高维和嵌入系统不太适用。在这篇论文中，我们提出了一种安全学习算法，可以提供概率安全保证，但是使用 Nadaraya-Watson 估计器而不是 Gaussian processes。Nadaraya-Watson 估计器的计算复杂度与数据点数的增加相对较快，只有 logarithmic 增长。我们提供了对估计的理论保证，将其嵌入到安全学习算法中，并在一个模拟的七度自由机械 manipulate 器上进行了数学实验。
</details></li>
</ul>
<hr>
<h2 id="Alzheimer-Disease-Detection-from-Raman-Spectroscopy-of-the-Cerebrospinal-Fluid-via-Topological-Machine-Learning"><a href="#Alzheimer-Disease-Detection-from-Raman-Spectroscopy-of-the-Cerebrospinal-Fluid-via-Topological-Machine-Learning" class="headerlink" title="Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal Fluid via Topological Machine Learning"></a>Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal Fluid via Topological Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03664">http://arxiv.org/abs/2309.03664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Conti, Martina Banchelli, Valentina Bessi, Cristina Cecchi, Fabrizio Chiti, Sara Colantonio, Cristiano D’Andrea, Marella de Angelis, Davide Moroni, Benedetta Nacmias, Maria Antonietta Pascali, Sandro Sorbi, Paolo Matteini</li>
<li>for: 本研究用于确定阿尔茨曼病（AD）诊断的依据。</li>
<li>methods: 本研究使用了拉曼光谱（RS）测试19名阿尔茨曼病患者和5名病理控制人群的静脉液样本，并使用了标准机器学习（ML）方法和拓扑分析方法来分类。</li>
<li>results: 研究结果显示，使用拓扑分析方法可以准确地分类阿尔茨曼病和控制人群，并且分类精度高于87%。<details>
<summary>Abstract</summary>
The cerebrospinal fluid (CSF) of 19 subjects who received a clinical diagnosis of Alzheimer's disease (AD) as well as of 5 pathological controls have been collected and analysed by Raman spectroscopy (RS). We investigated whether the raw and preprocessed Raman spectra could be used to distinguish AD from controls. First, we applied standard Machine Learning (ML) methods obtaining unsatisfactory results. Then, we applied ML to a set of topological descriptors extracted from raw spectra, achieving a very good classification accuracy (>87%). Although our results are preliminary, they indicate that RS and topological analysis together may provide an effective combination to confirm or disprove a clinical diagnosis of AD. The next steps will include enlarging the dataset of CSF samples to validate the proposed method better and, possibly, to understand if topological data analysis could support the characterization of AD subtypes.
</details>
<details>
<summary>摘要</summary>
精神�生液（CSF）的19名病人和5名病理控制者的样本被收集和分析使用拉曼光谱（RS）。我们研究了使用标准机器学习（ML）方法来分别AD和控制者，但得到的结果不太理想。然后，我们使用ML方法对raw光谱中提取的 topological 特征进行分类，达到了非常好的分类精度（>87%）。虽然我们的结果只是初步的，但它们表明RS和 topological 分析可能是一种有效的组合，用于诊断AD。接下来的步骤将包括扩大CSF样本集，以更好地验证我们的方法，并可能地理解AD的多种类型是否可以通过 topological 数据分析来 caracterization。
</details></li>
</ul>
<hr>
<h2 id="Insights-Into-the-Inner-Workings-of-Transformer-Models-for-Protein-Function-Prediction"><a href="#Insights-Into-the-Inner-Workings-of-Transformer-Models-for-Protein-Function-Prediction" class="headerlink" title="Insights Into the Inner Workings of Transformer Models for Protein Function Prediction"></a>Insights Into the Inner Workings of Transformer Models for Protein Function Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03631">http://arxiv.org/abs/2309.03631</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/markuswenzel/xai-proteins">https://github.com/markuswenzel/xai-proteins</a></li>
<li>paper_authors: Markus Wenzel, Erik Grüner, Nils Strodthoff</li>
<li>for: 这个论文的目的是探讨用于蛋白质功能预测的神经网络模型中的解释性AI（XAI）方法，以推广已有的XAI方法，使得神经网络模型中的潜在表示可以被检视。</li>
<li>methods: 这个论文使用了扩展了已有XAI方法，以便可以 inspect神经网络模型中的潜在表示，并且使用了经过 fine-tuning 的 transformer 模型来预测蛋白质的 Gene Ontology  терMINology和 Enzyme Commission 号。</li>
<li>results: 这个论文的结果表明，使用这种 XAI 方法可以Identify蛋白质序列中特定的氨基酸 residues，并且这些相关序列部分与生物和化学预期符合，包括在 embedding layer 和模型中的 transformer 头部。此外，这种方法还可以为蛋白质序列中的某些部分分配权重，并且这些权重与实际的序列标注（例如膜蛋白和活性 сай）在多个蛋白质中具有 statistically significant 相关性。<details>
<summary>Abstract</summary>
Motivation: We explored how explainable AI (XAI) can help to shed light into the inner workings of neural networks for protein function prediction, by extending the widely used XAI method of integrated gradients such that latent representations inside of transformer models, which were finetuned to Gene Ontology term and Enzyme Commission number prediction, can be inspected too. Results: The approach enabled us to identify amino acids in the sequences that the transformers pay particular attention to, and to show that these relevant sequence parts reflect expectations from biology and chemistry, both in the embedding layer and inside of the model, where we identified transformer heads with a statistically significant correspondence of attribution maps with ground truth sequence annotations (e.g., transmembrane regions, active sites) across many proteins. Availability and Implementation: Source code can be accessed at https://github.com/markuswenzel/xai-proteins .
</details>
<details>
<summary>摘要</summary>
Motivation: 我们研究了如何使用可解释AI（XAI）来探索神经网络中用于蛋白功能预测的内部工作机制，通过扩展广泛使用XAI方法的集成梯度的扩展，以便可以查看转换器模型中的隐藏表示。结果：我们的方法可以 помо助我们identify在序列中特定的氨基酸，并显示这些相关的序列部分与生物和化学预期符合，不仅在嵌入层中，还在模型中，我们在多个转换器头中发现了 statistically significant的对应地图与实际序列注释（例如膜内部区域、活性位点）的相关性，在许多蛋白质中。可用性和实现：源代码可以通过https://github.com/markuswenzel/xai-proteins 访问。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Self-Supervised-Learning-of-Speech-Representation-via-Invariance-and-Redundancy-Reduction"><a href="#Understanding-Self-Supervised-Learning-of-Speech-Representation-via-Invariance-and-Redundancy-Reduction" class="headerlink" title="Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction"></a>Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03619">http://arxiv.org/abs/2309.03619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusuf Brima, Ulf Krumnack, Simone Pika, Gunther Heidemann</li>
<li>for:  investigates how different formulations of the Barlow Twins (BT) objective impact downstream task performance for speech data.</li>
<li>methods: proposes Modified Barlow Twins (MBT) with normalized latents to enforce scale-invariance and evaluates on speaker identification, gender recognition and keyword spotting tasks.</li>
<li>results: improves representation generalization over original BT, especially when fine-tuning with limited target data, highlighting the importance of designing objectives that encourage invariant and transferable representations.Here’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文 investigate 如何不同的 Barlow Twins（BT）目标函数对语音数据下的下游任务表现的影响。</li>
<li>methods: 该论文提出 Modified Barlow Twins（MBT），使用 норма化的特征来保证缩放性，并在 speaker identification、gender recognition 和 keyword spotting 任务上进行评估。</li>
<li>results: MBT 在原始 BT 上进行了改进，特别是在使用有限目标数据进行练习时，对下游任务的表现有所提高，这说明设计目标函数可以促进不变和可转移的表现。<details>
<summary>Abstract</summary>
The choice of the objective function is crucial in emerging high-quality representations from self-supervised learning. This paper investigates how different formulations of the Barlow Twins (BT) objective impact downstream task performance for speech data. We propose Modified Barlow Twins (MBT) with normalized latents to enforce scale-invariance and evaluate on speaker identification, gender recognition and keyword spotting tasks. Our results show MBT improves representation generalization over original BT, especially when fine-tuning with limited target data. This highlights the importance of designing objectives that encourage invariant and transferable representations. Our analysis provides insights into how the BT learning objective can be tailored to produce speech representations that excel when adapted to new downstream tasks. This study is an important step towards developing reusable self-supervised speech representations.
</details>
<details>
<summary>摘要</summary>
“选择目标函数的选择非常重要，以获得自动学习中的高质量表现。这篇论文探讨了不同形式的巴洛兄弟（BT）目标函数如何影响下游任务性能，特别是对于语音数据。我们提出了修改后的巴洛兄弟（MBT）目标函数，强制采用Normalized latents来保持尺度对称性，并评估了语音识别、性别识别和关键词搜寻任务。我们的结果显示MBT可以提高表现普遍化，特别是在有限目标数据下进行精致化。这诉求了设计目标函数，以导引不对称和可转移的表现。我们的分析提供了关于BT学习目标函数如何适应语音表现，以便在新的下游任务中进行适应。这个研究是发展可重用自动学习语音表现的重要一步。”
</details></li>
</ul>
<hr>
<h2 id="Filtration-Surfaces-for-Dynamic-Graph-Classification"><a href="#Filtration-Surfaces-for-Dynamic-Graph-Classification" class="headerlink" title="Filtration Surfaces for Dynamic Graph Classification"></a>Filtration Surfaces for Dynamic Graph Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03616">http://arxiv.org/abs/2309.03616</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aidos-lab/filtration_surfaces">https://github.com/aidos-lab/filtration_surfaces</a></li>
<li>paper_authors: Franz Srambical, Bastian Rieck</li>
<li>for: 本文为了解决动态图 classification 中的缺陷，提出了一种新的方法——筛选面。</li>
<li>methods: 本文使用的方法是基于筛选面的，具有扩展性和灵活性，可以解决现有基eline的缺陷。</li>
<li>results: 实验表明，筛选面方法可以超越现有的基eline，在具有边重量信息的数据集上达到最高效果，而且只需一个或者没有参数。<details>
<summary>Abstract</summary>
Existing approaches for classifying dynamic graphs either lift graph kernels to the temporal domain, or use graph neural networks (GNNs). However, current baselines have scalability issues, cannot handle a changing node set, or do not take edge weight information into account. We propose filtration surfaces, a novel method that is scalable and flexible, to alleviate said restrictions. We experimentally validate the efficacy of our model and show that filtration surfaces outperform previous state-of-the-art baselines on datasets that rely on edge weight information. Our method does so while being either completely parameter-free or having at most one parameter, and yielding the lowest overall standard deviation.
</details>
<details>
<summary>摘要</summary>
现有的方法对动态图进行分类 either 将图kernels升级到时间频谱中，或使用图神经网络（GNNs）。然而，现有的基线有可靠性问题，不能处理变化的节点集，或者不考虑边重要性信息。我们提出了筛选表面，一种可扩展和灵活的方法，以解决这些限制。我们通过实验证明了我们的模型的有效性，并证明了筛选表面在基于边重要性信息的数据集上表现出色，而且只需一个或者无参数，并且具有最低的总标准差。
</details></li>
</ul>
<hr>
<h2 id="Your-Battery-Is-a-Blast-Safeguarding-Against-Counterfeit-Batteries-with-Authentication"><a href="#Your-Battery-Is-a-Blast-Safeguarding-Against-Counterfeit-Batteries-with-Authentication" class="headerlink" title="Your Battery Is a Blast! Safeguarding Against Counterfeit Batteries with Authentication"></a>Your Battery Is a Blast! Safeguarding Against Counterfeit Batteries with Authentication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03607">http://arxiv.org/abs/2309.03607</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mhackiori/eisthentication">https://github.com/mhackiori/eisthentication</a></li>
<li>paper_authors: Francesco Marchiori, Mauro Conti</li>
<li>for: 提高Li-ion电池验证技术，以确保设备只使用合法电池，保证系统的操作状况和用户的安全。</li>
<li>methods: 提出了两种新的验证方法：DCAuth和EIS验证，通过机器学习模型利用电池内部特征进行自动验证，不需要外部设备，并能抵抗通行的大规模伪造技术。</li>
<li>results: 对20个数据集进行分析，实现了高精度的电池验证（最高达0.99）和模型识别（最高达0.96），同时提供了相对识别性。<details>
<summary>Abstract</summary>
Lithium-ion (Li-ion) batteries are the primary power source in various applications due to their high energy and power density. Their market was estimated to be up to 48 billion U.S. dollars in 2022. However, the widespread adoption of Li-ion batteries has resulted in counterfeit cell production, which can pose safety hazards to users. Counterfeit cells can cause explosions or fires, and their prevalence in the market makes it difficult for users to detect fake cells. Indeed, current battery authentication methods can be susceptible to advanced counterfeiting techniques and are often not adaptable to various cells and systems. In this paper, we improve the state of the art on battery authentication by proposing two novel methodologies, DCAuth and EISthentication, which leverage the internal characteristics of each cell through Machine Learning models. Our methods automatically authenticate lithium-ion battery models and architectures using data from their regular usage without the need for any external device. They are also resilient to the most common and critical counterfeit practices and can scale to several batteries and devices. To evaluate the effectiveness of our proposed methodologies, we analyze time-series data from a total of 20 datasets that we have processed to extract meaningful features for our analysis. Our methods achieve high accuracy in battery authentication for both architectures (up to 0.99) and models (up to 0.96). Moreover, our methods offer comparable identification performances. By using our proposed methodologies, manufacturers can ensure that devices only use legitimate batteries, guaranteeing the operational state of any system and safety measures for the users.
</details>
<details>
<summary>摘要</summary>
锂离子（Li-ion）电池是各种应用的主要能源来源，其市场估计在2022年可达480亿美元。然而，广泛采用锂离子电池的使用导致假电池的生产，这可能会对用户造成安全隐患。假电池可能会引起爆炸或火灾，并且在市场中充斥，使用户很难detect假电池。实际上，当前的电池认证方法可能会受到先进的假制技术的影响，并且不能适应不同的电池和系统。在这篇论文中，我们提出了两种新的方法，DCAuth和EIS authentication，它们利用每个电池的内部特征通过机器学习模型进行自动认证。我们的方法不需要任何外部设备，可以自动认证锂离子电池模型和架构，并且具有抗常见和最 kritical假制技术的能力。为评估我们提出的方法的效果，我们分析了20个数据集，并从中提取了有用的特征进行分析。我们的方法在锂离子电池模型和架构上达到了高精度的认证效果（达0.99），并且具有相当的标识表现。通过使用我们的方法，制造商可以确保设备只使用合法电池，保证系统的运行状态和用户的安全措施。
</details></li>
</ul>
<hr>
<h2 id="Beyond-attention-deriving-biologically-interpretable-insights-from-weakly-supervised-multiple-instance-learning-models"><a href="#Beyond-attention-deriving-biologically-interpretable-insights-from-weakly-supervised-multiple-instance-learning-models" class="headerlink" title="Beyond attention: deriving biologically interpretable insights from weakly-supervised multiple-instance learning models"></a>Beyond attention: deriving biologically interpretable insights from weakly-supervised multiple-instance learning models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03925">http://arxiv.org/abs/2309.03925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Willem Bonnaffé, CRUK ICGC Prostate Group, Freddie Hamdy, Yang Hu, Ian Mills, Jens Rittscher, Clare Verrill, Dan J. Woodcock</li>
<li>for: 本研究旨在提高多例学习（MIL）中模型对肿瘤病理图像的预测性能，并提供更好的解释性。</li>
<li>methods: 本研究使用了一种post-training分析方法，包括 combing tile-level attention和预测分数生成的精细编码器，以计算高吸引区域的预测贡献。此外，研究还引入了一种生物特征实现技术，通过与核体分割Masks进行集成，以提供与生物学意义相关的特征，并且可以与已知临床特征进行比较。</li>
<li>results: 研究发现，对于肿瘤诊断（i.e. 癌细胞存在的样本，381&#x2F;516组织样本）和诊断（i.e. 患者经受了手术后的生化倒退，98&#x2F;663组织样本）的预测结果，高吸引区域并不一定与肿瘤区域重叠，这表明需要研究非癌细胞when评估诊断。<details>
<summary>Abstract</summary>
Recent advances in attention-based multiple instance learning (MIL) have improved our insights into the tissue regions that models rely on to make predictions in digital pathology. However, the interpretability of these approaches is still limited. In particular, they do not report whether high-attention regions are positively or negatively associated with the class labels or how well these regions correspond to previously established clinical and biological knowledge. We address this by introducing a post-training methodology to analyse MIL models. Firstly, we introduce prediction-attention-weighted (PAW) maps by combining tile-level attention and prediction scores produced by a refined encoder, allowing us to quantify the predictive contribution of high-attention regions. Secondly, we introduce a biological feature instantiation technique by integrating PAW maps with nuclei segmentation masks. This further improves interpretability by providing biologically meaningful features related to the cellular organisation of the tissue and facilitates comparisons with known clinical features. We illustrate the utility of our approach by comparing PAW maps obtained for prostate cancer diagnosis (i.e. samples containing malignant tissue, 381/516 tissue samples) and prognosis (i.e. samples from patients with biochemical recurrence following surgery, 98/663 tissue samples) in a cohort of patients from the international cancer genome consortium (ICGC UK Prostate Group). Our approach reveals that regions that are predictive of adverse prognosis do not tend to co-locate with the tumour regions, indicating that non-cancer cells should also be studied when evaluating prognosis.
</details>
<details>
<summary>摘要</summary>
近期的注意力基本多例学习（MIL）技术进步，有助于我们更深入了解在数字 PATHOLOGY 中模型如何预测的组织区域。然而，这些方法的解释能力仍然有限。具体来说，它们不会报告高注意区域与类别标签之间的相关性是正向或负向的，也不会报告这些区域与已知的临床和生物学知识是如何对应的。我们解决这个问题，通过对 MIL 模型进行后处理分析方法。首先，我们引入预测注意重量（PAW）地图，通过将瓦片级别注意力和预测得分结果结合起来，以量化预测中高注意区域的预测贡献。其次，我们引入生物特征实例化技术，通过将 PAW 地图与核型分割mask 结合起来，进一步提高解释性，并提供生物学意义的特征，与已知临床特征进行比较。我们通过对抑肿癌诊断（i.e. 病理样本中含有恶性组织，381/516 组织样本）和诊断后发生 biochemical 回卷的患者群体（i.e. 来自国际癌基因组计划（ICGC） UK 频谱癌组）进行比较，我们的方法显示，预测不良结果的预测区域与肿瘤区域不常协同存在，这表明，在评估诊断时，也应该考虑非癌细胞。
</details></li>
</ul>
<hr>
<h2 id="Trinary-Decision-Trees-for-missing-value-handling"><a href="#Trinary-Decision-Trees-for-missing-value-handling" class="headerlink" title="Trinary Decision Trees for missing value handling"></a>Trinary Decision Trees for missing value handling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03561">http://arxiv.org/abs/2309.03561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henning Zakrisson</li>
<li>for: 提高决策树回归和分类器中处理缺失数据的性能</li>
<li>methods: 提出了一种新的三元决策树算法，不 assumptions 缺失值包含响应变量的信息</li>
<li>results: 对MCAR和IM两种缺失数据场景进行了 theoret  calculations 和实证 validate，与已有算法相比，三元树在MCAR场景下表现更好，特别是只缺失外样本时，而在IM场景下表现较差。一种混合模型三元MIA树，结合三元树和MIA方法，在所有缺失数据场景下表现稳定。<details>
<summary>Abstract</summary>
This paper introduces the Trinary decision tree, an algorithm designed to improve the handling of missing data in decision tree regressors and classifiers. Unlike other approaches, the Trinary decision tree does not assume that missing values contain any information about the response. Both theoretical calculations on estimator bias and numerical illustrations using real data sets are presented to compare its performance with established algorithms in different missing data scenarios (Missing Completely at Random (MCAR), and Informative Missingness (IM)). Notably, the Trinary tree outperforms its peers in MCAR settings, especially when data is only missing out-of-sample, while lacking behind in IM settings. A hybrid model, the TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes (MIA) approach, shows robust performance in all types of missingness. Despite the potential drawback of slower training speed, the Trinary tree offers a promising and more accurate method of handling missing data in decision tree algorithms.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了一种名为Trinary decision tree的算法，用于改进决策树回归和分类器中处理缺失数据的方法。与其他方法不同，Trinary decision tree不 assumptions 缺失值包含响应值的信息。在不同的缺失数据场景（MCAR和IM）中，对其性能进行了 theoretically 计算和使用实际数据进行 illustrate ，与已有算法进行比较。特别是在MCAR场景中，Trinary tree 在数据只缺失外样时表现出色，而在IM场景中则落后于其他算法。一种混合模型，TrinaryMIA tree，通过将Trinary tree 和Missing In Attributes（MIA）方法结合起来，在所有类型的缺失数据场景中表现稳定。尽管可能会增加训练速度的慢化，但Trinary tree 提供了一种更准确和有前途的缺失数据处理方法。
</details></li>
</ul>
<hr>
<h2 id="On-the-dynamics-of-multi-agent-nonlinear-filtering-and-learning"><a href="#On-the-dynamics-of-multi-agent-nonlinear-filtering-and-learning" class="headerlink" title="On the dynamics of multi agent nonlinear filtering and learning"></a>On the dynamics of multi agent nonlinear filtering and learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03557">http://arxiv.org/abs/2309.03557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayed Pouria Talebi, Danilo Mandic</li>
<li>for:  Multiagent systems aim to accomplish highly complex learning tasks through decentralized consensus seeking dynamics, and their use has garnered a great deal of attention in the signal processing and computational intelligence societies.</li>
<li>methods: The paper presents a general formulation for the actions of an agent in multiagent networked systems and conditions for achieving a cohesive learning behavior.</li>
<li>results: The paper applies the derived framework in distributed and federated learning scenarios.Here’s the same information in Traditional Chinese:</li>
<li>for:  Multiagent systems aim to accomplish highly complex learning tasks through decentralized consensus seeking dynamics, and their use has garnered a great deal of attention in the signal processing and computational intelligence societies.</li>
<li>methods: The paper presents a general formulation for the actions of an agent in multiagent networked systems and conditions for achieving a cohesive learning behavior.</li>
<li>results: The paper applies the derived framework in distributed and federated learning scenarios.<details>
<summary>Abstract</summary>
Multiagent systems aim to accomplish highly complex learning tasks through decentralised consensus seeking dynamics and their use has garnered a great deal of attention in the signal processing and computational intelligence societies. This article examines the behaviour of multiagent networked systems with nonlinear filtering/learning dynamics. To this end, a general formulation for the actions of an agent in multiagent networked systems is presented and conditions for achieving a cohesive learning behaviour is given. Importantly, application of the so derived framework in distributed and federated learning scenarios are presented.
</details>
<details>
<summary>摘要</summary>
多智能体系统目的是通过分散的同意决策方式实现高度复杂的学习任务，这在信号处理和计算智能学会中备受关注。这篇文章研究了多智能网络系统的非线性筛选/学习动态行为。为此，我们提供了多智能Agent的通用形式和各种学习情况下的凝结行为条件。更重要的是，我们在分布式和联邦学习场景中应用了所 derivation的框架。
</details></li>
</ul>
<hr>
<h2 id="MVD-A-Novel-Methodology-and-Dataset-for-Acoustic-Vehicle-Type-Classification"><a href="#MVD-A-Novel-Methodology-and-Dataset-for-Acoustic-Vehicle-Type-Classification" class="headerlink" title="MVD:A Novel Methodology and Dataset for Acoustic Vehicle Type Classification"></a>MVD:A Novel Methodology and Dataset for Acoustic Vehicle Type Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03544">http://arxiv.org/abs/2309.03544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohd Ashhad, Omar Ahmed, Sooraj K. Ambat, Zeeshan Ali Haq, Mansaf Alam</li>
<li>for: 本研究的目的是提供一种可靠的听音交通监测方法，以替代计算机视觉技术。</li>
<li>methods: 本研究使用了听音特征和多输入神经网络来分类汽车、摩托车、卡车和无车等四类听音信号。</li>
<li>results: 实验结果表明，我们的方法可以高度准确地分类听音信号，并且比前一些研究的基准值高出91.98%和96.66%。此外，我们还将模型部署到了Android应用程序中，以便演示其可用性。<details>
<summary>Abstract</summary>
Rising urban populations have led to a surge in vehicle use and made traffic monitoring and management indispensable. Acoustic traffic monitoring (ATM) offers a cost-effective and efficient alternative to more computationally expensive methods of monitoring traffic such as those involving computer vision technologies. In this paper, we present MVD and MVDA: two open datasets for the development of acoustic traffic monitoring and vehicle-type classification algorithms, which contain audio recordings of moving vehicles. The dataset contain four classes- Trucks, Cars, Motorbikes, and a No-vehicle class. Additionally, we propose a novel and efficient way to accurately classify these acoustic signals using cepstrum and spectrum based local and global audio features, and a multi-input neural network. Experimental results show that our methodology improves upon the established baselines of previous works and achieves an accuracy of 91.98% and 96.66% on MVD and MVDA Datasets, respectively. Finally, the proposed model was deployed through an Android application to make it accessible for testing and demonstrate its efficacy.
</details>
<details>
<summary>摘要</summary>
城市人口增长导致交通量的增加，使得交通监测和管理成为不可或缺的。鸣音交通监测（ATM）提供了一种可靠且高效的代替方案，而不是基于计算机视觉技术的更复杂和费力的监测方法。在这篇论文中，我们提供了两个开放的数据集，即MVD和MVDA数据集，用于开发鸣音交通监测和车辆类型分类算法。这两个数据集包含了四个类别：卡车、汽车、摩托车和无车类。此外，我们还提出了一种新的和高效的鸣音信号分类方法，使用cepstrum和spectrum基于本地和全球音频特征，以及多输入神经网络。实验结果表明，我们的方法超过了之前的基准值，并达到了MVD和MVDA数据集的准确率为91.98%和96.66%。最后，我们通过Android应用程序部署了我们的模型，以便进行测试和证明其可靠性。
</details></li>
</ul>
<hr>
<h2 id="Subgraph-based-Tight-Frames-on-Graphs-with-Compact-Supports-and-Vanishing-Moments"><a href="#Subgraph-based-Tight-Frames-on-Graphs-with-Compact-Supports-and-Vanishing-Moments" class="headerlink" title="Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments"></a>Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03537">http://arxiv.org/abs/2309.03537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruigang Zheng, Xiaosheng Zhuang</li>
<li>for: 这个论文是为了构建图像中的紧凑支持的新方法，以替代现有的基于分区树的方法。</li>
<li>methods: 该方法使用一系列层次分 partitions，并将subgraph Laplacians incorporated into its design，以便可以自由地调整(subgraph)vanishing moments和其他特性，如方向性，以便有效地表示图像信号。</li>
<li>results: 实验结果显示，提议的图像帧在非线性近似任务中表现出色。<details>
<summary>Abstract</summary>
In this work, we proposed a novel and general method to construct tight frames on graphs with compact supports based on a series of hierarchical partitions. Starting from our abstract construction that generalizes previous methods based on partition trees, we are able to flexibly incorporate subgraph Laplacians into our design of graph frames. Consequently, our general methods permit adjusting the (subgraph) vanishing moments of the framelets and extra properties, such as directionality, for efficiently representing graph signals with path-like supports. Several variants are explicitly defined and tested. Experimental results show our proposed graph frames perform superiorly in non-linear approximation tasks.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的和普遍的方法，用于在图上建立紧凑支持的图帧。我们从抽象构造起点，总结了之前基于分区树的方法，并可以自由地将子图 Laplacians  incorporated 到我们的帧设计中。因此，我们的通用方法允许调整（子图）消失时刻的帧谱和其他属性，如方向性，以高效地表示图示号 signals  with  path-like 支持。我们还明确定义了多种变体并进行测试。实验结果表明，我们的提议的图帧在非线性approximation任务中表现出色。Here's the translation breakdown:* "In this work" is translated as "在这项工作中" (在这项工作中).* "we proposed" is translated as "我们提出了" (我们提出了).* "a novel and general method" is translated as "一种新的和普遍的方法" (一种新的和普遍的方法).* "to construct tight frames on graphs with compact supports" is translated as "用于在图上建立紧凑支持的图帧" (用于在图上建立紧凑支持的图帧).* "Starting from our abstract construction that generalizes previous methods based on partition trees" is translated as "从抽象构造起点，总结了之前基于分区树的方法" (从抽象构造起点，总结了之前基于分区树的方法).* "we are able to flexibly incorporate subgraph Laplacians into our design of graph frames" is translated as "并可以自由地将子图 Laplacians  incorporated 到我们的帧设计中" (并可以自由地将子图 Laplacians  incorporated 到我们的帧设计中).* "Consequently, our general methods permit adjusting the (subgraph) vanishing moments of the framelets and extra properties, such as directionality" is translated as "因此，我们的通用方法允许调整（子图）消失时刻的帧谱和其他属性，如方向性" (因此，我们的通用方法允许调整（子图）消失时刻的帧谱和其他属性，如方向性).* "Several variants are explicitly defined and tested" is translated as "我们还明确定义了多种变体并进行测试" (我们还明确定义了多种变体并进行测试).* "Experimental results show our proposed graph frames perform superiorly in non-linear approximation tasks" is translated as "实验结果表明，我们的提议的图帧在非线性approximation任务中表现出色" (实验结果表明，我们的提议的图帧在非线性approximation任务中表现出色).
</details></li>
</ul>
<hr>
<h2 id="Privacy-preserving-Continual-Federated-Clustering-via-Adaptive-Resonance-Theory"><a href="#Privacy-preserving-Continual-Federated-Clustering-via-Adaptive-Resonance-Theory" class="headerlink" title="Privacy-preserving Continual Federated Clustering via Adaptive Resonance Theory"></a>Privacy-preserving Continual Federated Clustering via Adaptive Resonance Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03487">http://arxiv.org/abs/2309.03487</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Masuyama-lab/FCAC">https://github.com/Masuyama-lab/FCAC</a></li>
<li>paper_authors: Naoki Masuyama, Yusuke Nojima, Yuichiro Toda, Chu Kiong Loo, Hisao Ishibuchi, Naoyuki Kubota</li>
<li>for: 提高数据隐私保护的重要性，许多隐私保护机器学习方法被提出，在聚类领域，使用联邦学习框架（即联邦聚类）的各种算法已经广泛研究，表现出高聚类性能而保护数据隐私。</li>
<li>methods: 本文提出的隐私保护联邦聚类算法使用了适应振荡理论基于的聚类算法，具有自适应学习能力。</li>
<li>results: 实验结果表明，提出的算法在实验用 synthetic 和实际世界数据集上具有较高的聚类性能，同时实现了数据隐私保护和自适应学习能力。<details>
<summary>Abstract</summary>
With the increasing importance of data privacy protection, various privacy-preserving machine learning methods have been proposed. In the clustering domain, various algorithms with a federated learning framework (i.e., federated clustering) have been actively studied and showed high clustering performance while preserving data privacy. However, most of the base clusterers (i.e., clustering algorithms) used in existing federated clustering algorithms need to specify the number of clusters in advance. These algorithms, therefore, are unable to deal with data whose distributions are unknown or continually changing. To tackle this problem, this paper proposes a privacy-preserving continual federated clustering algorithm. In the proposed algorithm, an adaptive resonance theory-based clustering algorithm capable of continual learning is used as a base clusterer. Therefore, the proposed algorithm inherits the ability of continual learning. Experimental results with synthetic and real-world datasets show that the proposed algorithm has superior clustering performance to state-of-the-art federated clustering algorithms while realizing data privacy protection and continual learning ability. The source code is available at \url{https://github.com/Masuyama-lab/FCAC}.
</details>
<details>
<summary>摘要</summary>
随着数据隐私保护的重要性日益增加，各种隐私保护机器学习方法已经被提出。在聚类领域，使用联邦学习框架（即联邦聚类）的各种算法已经得到了广泛的研究和应用，其中大多数基本聚类算法（即聚类算法）需要在先 specify the number of clusters 的情况下进行设置。这些算法因此无法处理数据的分布是未知的或在变化的情况下。为解决这个问题，本文提出了一种隐私保护的 continual federated clustering 算法。在提出的算法中，使用 adaptive resonance theory 基于的聚类算法，可以实现 continual learning 的能力。实验结果表明，与州际顶尖的联邦聚类算法相比，提出的算法具有更高的聚类性能，同时实现了数据隐私保护和 continual learning 的能力。源代码可以在 \url{https://github.com/Masuyama-lab/FCAC} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Cross-domain-Sound-Recognition-for-Efficient-Underwater-Data-Analysis"><a href="#Cross-domain-Sound-Recognition-for-Efficient-Underwater-Data-Analysis" class="headerlink" title="Cross-domain Sound Recognition for Efficient Underwater Data Analysis"></a>Cross-domain Sound Recognition for Efficient Underwater Data Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03451">http://arxiv.org/abs/2309.03451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jeongsoo Park, Dong-Gyun Han, Hyoung Sul La, Sangmin Lee, Yoonchang Han, Eun-Jin Yang</li>
<li>for: 本研究は大量の海中响のデータ分析に novel deep learning アプローチを提案しています。</li>
<li>methods: 本研究では、非水中（エアリアル）音の识别モデルを使用したFeature vectorを使用して、海中データをPCAおよびUMAPVisualizationします。また、これらのクラスター内のポイントを选択し、それらの特徴を理解するために、労力的なラベル付けプロセスを加速します。</li>
<li>results: 本研究では、エアグン・サウンドの识别において、非水中データと海中データを使用したニューラルネットワークモデルをトレーニングしました。结果、 precision、recall、およびF1 Scoreの评価指标に基づいて、我々のモデルがエアグン・サウンドを识别するための效果的な方法です。<details>
<summary>Abstract</summary>
This paper presents a novel deep learning approach for analyzing massive underwater acoustic data by leveraging a model trained on a broad spectrum of non-underwater (aerial) sounds. Recognizing the challenge in labeling vast amounts of underwater data, we propose a two-fold methodology to accelerate this labor-intensive procedure.   The first part of our approach involves PCA and UMAP visualization of the underwater data using the feature vectors of an aerial sound recognition model. This enables us to cluster the data in a two dimensional space and listen to points within these clusters to understand their defining characteristics. This innovative method simplifies the process of selecting candidate labels for further training.   In the second part, we train a neural network model using both the selected underwater data and the non-underwater dataset. We conducted a quantitative analysis to measure the precision, recall, and F1 score of our model for recognizing airgun sounds, a common type of underwater sound. The F1 score achieved by our model exceeded 84.3%, demonstrating the effectiveness of our approach in analyzing underwater acoustic data.   The methodology presented in this paper holds significant potential to reduce the amount of labor required in underwater data analysis and opens up new possibilities for further research in the field of cross-domain data analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>PCA and UMAP visualization of underwater data using the feature vectors of an aerial sound recognition model. This enables clustering of the data in a two-dimensional space and allows for understanding the defining characteristics of points within these clusters.2. Training a neural network model using both the selected underwater data and the non-underwater dataset. The model achieved an F1 score of over 84.3% in recognizing airgun sounds, a common type of underwater sound.The proposed methodology has the potential to significantly reduce the amount of labor required in underwater data analysis and opens up new possibilities for cross-domain data analysis.</details></li>
</ol>
<hr>
<h2 id="Broadband-Ground-Motion-Synthesis-via-Generative-Adversarial-Neural-Operators-Development-and-Validation"><a href="#Broadband-Ground-Motion-Synthesis-via-Generative-Adversarial-Neural-Operators-Development-and-Validation" class="headerlink" title="Broadband Ground Motion Synthesis via Generative Adversarial Neural Operators: Development and Validation"></a>Broadband Ground Motion Synthesis via Generative Adversarial Neural Operators: Development and Validation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03447">http://arxiv.org/abs/2309.03447</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yzshi5/gm-gano">https://github.com/yzshi5/gm-gano</a></li>
<li>paper_authors: Yaozhong Shi, Grigorios Lavrentiadis, Domniki Asimaki, Zachary E. Ross, Kamyar Azizzadenesheli<br>for:* The paper is written for ground-motion synthesis using a Generative Adversarial Neural Operator (GANO) to generate three-component acceleration time histories.methods:* The paper uses Neural Operators, a resolution invariant architecture that guarantees the model training is independent of the data sampling frequency.* The authors use a conditional ground-motion synthesis algorithm (cGM-GANO) that combines recent advancements in machine learning and open access strong motion data sets.results:* The paper shows that cGM-GANO can recover the magnitude, distance, and $V_{S30}$ scaling of Fourier amplitude and pseudo-spectral accelerations.* The framework is evaluated through residual analysis with the empirical dataset and comparison with conventional Ground Motion Models (GMMs) for selected ground motion scenarios.* The results show that cGM-GANO produces consistent median scaling with the GMMs for the corresponding tectonic environments, with the largest misfit observed at short distances.<details>
<summary>Abstract</summary>
We present a data-driven model for ground-motion synthesis using a Generative Adversarial Neural Operator (GANO) that combines recent advancements in machine learning and open access strong motion data sets to generate three-component acceleration time histories conditioned on moment magnitude ($M$), rupture distance ($R_{rup}$), time-average shear-wave velocity at the top $30m$ ($V_{S30}$), and tectonic environment or style of faulting. We use Neural Operators, a resolution invariant architecture that guarantees that the model training is independent of the data sampling frequency. We first present the conditional ground-motion synthesis algorithm (referred to heretofore as cGM-GANO) and discuss its advantages compared to previous work. Next, we verify the cGM-GANO framework using simulated ground motions generated with the Southern California Earthquake Center (SCEC) Broadband Platform (BBP). We lastly train cGM-GANO on a KiK-net dataset from Japan, showing that the framework can recover the magnitude, distance, and $V_{S30}$ scaling of Fourier amplitude and pseudo-spectral accelerations. We evaluate cGM-GANO through residual analysis with the empirical dataset as well as by comparison with conventional Ground Motion Models (GMMs) for selected ground motion scenarios. Results show that cGM-GANO produces consistent median scaling with the GMMs for the corresponding tectonic environments. The largest misfit is observed at short distances due to the scarcity of training data. With the exception of short distances, the aleatory variability of the response spectral ordinates is also well captured, especially for subduction events due to the adequacy of training data. Applications of the presented framework include generation of risk-targeted ground motions for site-specific engineering applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一个基于数据驱动的模型，用于地震动的合成，使用生成各种推测运算（GANO），结合了最新的机器学习技术和公开存取的强震动数据集，以生成三维加速度时间历史，受到震内功率（M）、碰撞距离（Rrup）、震内速度（V_{S30）和地震类型或构造。我们使用神经操作员，一种解析独立的架构，使得模型训练不受数据采样频率的影响。我们首先介绍了增测地震动的条件Synthesis（cGM-GANO）algorithm，并详细讨论其优点相比前期工作。接着，我们验证了cGM-GANO框架，使用南加州地震中心（SCEC）的广泛频率平台（BBP）生成的模拟地震动。最后，我们将cGM-GANO框架训练在日本的KiK-net数据集上，显示了这个框架可以重建震内功率、距离和震内速度的数值对应。我们透过差异分析和与传统的地震模型（GMMs）进行比较，评估cGM-GANO的性能。结果显示，cGM-GANO在不同的地震类型下具有一致的中位数弹性，但短距离下存在较大的差异。对于不同的地震enario，aleatory variability of the response spectral ordinates是很好地捕捉，特别是在SUBDUCTION事件中，因为训练数据的充足。应用包括生成基于风险的地震动，供特定工程应用。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Tucker-Decomposition-Modeling-Commonality-and-Peculiarity-on-Tensor-Data"><a href="#Personalized-Tucker-Decomposition-Modeling-Commonality-and-Peculiarity-on-Tensor-Data" class="headerlink" title="Personalized Tucker Decomposition: Modeling Commonality and Peculiarity on Tensor Data"></a>Personalized Tucker Decomposition: Modeling Commonality and Peculiarity on Tensor Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03439">http://arxiv.org/abs/2309.03439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuyun Hu, Naichen Shi, Raed Al Kontar, Hao Yan</li>
<li>for: 用于捕捉不同数据集中的差异性，提高tensor分解方法的表达能力。</li>
<li>methods: 使用个性化Tucker分解（perTucker），分解tensor数据为共享全球组件和个性化本地组件。采用模式正交假设，开发了贝叶斯迭代降维算法，可确保收敛到站点点。</li>
<li>results: 通过在模拟研究和两个实际案例（太阳黑暴报警和船用信号分类）中证明perTucker的效果，包括异常检测、客户分类和封装。<details>
<summary>Abstract</summary>
We propose personalized Tucker decomposition (perTucker) to address the limitations of traditional tensor decomposition methods in capturing heterogeneity across different datasets. perTucker decomposes tensor data into shared global components and personalized local components. We introduce a mode orthogonality assumption and develop a proximal gradient regularized block coordinate descent algorithm that is guaranteed to converge to a stationary point. By learning unique and common representations across datasets, we demonstrate perTucker's effectiveness in anomaly detection, client classification, and clustering through a simulation study and two case studies on solar flare detection and tonnage signal classification.
</details>
<details>
<summary>摘要</summary>
我们提出个性化图cker decompositions（perTucker），以解决传统矩阵分解方法不能捕捉不同数据集之间的多样性的问题。perTucker将矩阵数据分解为共享全局组件和个性化本地组件。我们提出了一种方差归一化假设，并开发了一种距离正则化块坐标梯度下降算法，这个算法可以保证 converges to a stationary point。通过学习不同数据集之间的共同和特有表示，我们示出perTucker在异常检测、客户分类和聚类方面的效果，通过一个模拟研究和两个案例研究：太阳闪烁检测和吨位信号分类。
</details></li>
</ul>
<hr>
<h2 id="Byzantine-Robust-Federated-Learning-with-Variance-Reduction-and-Differential-Privacy"><a href="#Byzantine-Robust-Federated-Learning-with-Variance-Reduction-and-Differential-Privacy" class="headerlink" title="Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy"></a>Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03437">http://arxiv.org/abs/2309.03437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zikai Zhang, Rui Hu</li>
<li>for: 保护数据隐私和强化模型训练 robustness against Byzantine attacks</li>
<li>methods: 引入简化和动量驱动的差异性隐私机制，并在安全设计中保持客户端级别隐私保证</li>
<li>results: 在不同的异步 dataset和任务上进行了广泛的实验，并证明了我们的框架可以提高系统对恶意攻击的抵抗力，同时保持强大的隐私保证。<details>
<summary>Abstract</summary>
Federated learning (FL) is designed to preserve data privacy during model training, where the data remains on the client side (i.e., IoT devices), and only model updates of clients are shared iteratively for collaborative learning. However, this process is vulnerable to privacy attacks and Byzantine attacks: the local model updates shared throughout the FL network will leak private information about the local training data, and they can also be maliciously crafted by Byzantine attackers to disturb the learning. In this paper, we propose a new FL scheme that guarantees rigorous privacy and simultaneously enhances system robustness against Byzantine attacks. Our approach introduces sparsification- and momentum-driven variance reduction into the client-level differential privacy (DP) mechanism, to defend against Byzantine attackers. The security design does not violate the privacy guarantee of the client-level DP mechanism; hence, our approach achieves the same client-level DP guarantee as the state-of-the-art. We conduct extensive experiments on both IID and non-IID datasets and different tasks and evaluate the performance of our approach against different Byzantine attacks by comparing it with state-of-the-art defense methods. The results of our experiments show the efficacy of our framework and demonstrate its ability to improve system robustness against Byzantine attacks while achieving a strong privacy guarantee.
</details>
<details>
<summary>摘要</summary>
Federation Learning (FL) 是设计优先保护数据隐私，在模型训练过程中数据都留在客户端（即物联网设备），并且只有客户端的模型更新被共同学习。然而，这个过程受到隐私攻击和恶意攻击的威胁：本地模型更新在 FL 网络中传输的数据会泄露客户端的训练数据隐私信息，而且可以由恶意攻击者预制作假数据来干扰学习。在这篇论文中，我们提出了一种新的 FL 方案，保证了严格的隐私和同时增强了系统对恶意攻击的抗性。我们的方法通过在客户端级别的权限机制中引入缩减和动量驱动的减少方法，以防止恶意攻击者的干扰。我们的安全设计不违反客户端级别的隐私保证机制，因此我们的方法实现了同样的客户端级别隐私保证。我们进行了对不同的 dataset 和任务的广泛实验，并对不同的恶意攻击进行比较，以评估我们的方法的性能。实验结果表明我们的框架具有强大的隐私保证和系统抗性的能力，并且在不同的恶意攻击下都能够实现优秀的性能。
</details></li>
</ul>
<hr>
<h2 id="Equal-Long-term-Benefit-Rate-Adapting-Static-Fairness-Notions-to-Sequential-Decision-Making"><a href="#Equal-Long-term-Benefit-Rate-Adapting-Static-Fairness-Notions-to-Sequential-Decision-Making" class="headerlink" title="Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making"></a>Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03426">http://arxiv.org/abs/2309.03426</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuancheng-xu/elbert">https://github.com/yuancheng-xu/elbert</a></li>
<li>paper_authors: Yuancheng Xu, Chenghao Deng, Yanchao Sun, Ruijie Zheng, Xiyao Wang, Jieyu Zhao, Furong Huang</li>
<li>for: 本研究旨在提出一种长期公平性考虑的决策模型，以解决随机决策中的偏见问题。</li>
<li>methods: 本研究使用Markov决策过程（MDP）框架来形式化长期公平性考虑。它定义了长期偏见为每个时间步骤的偏见之和，但是这种方法可能会导致假的公平性感知，因为它不考虑不同时间步骤之间的重要性差异。本研究提出了一种新的长期公平性考虑方法called Equal Long-term Benefit Rate（ELBERT），它考虑了不同时间步骤之间的变化性，并将静止公平性原则应用到顺序设置中。</li>
<li>results: 实验结果表明，ELBERT-PO方法可以减少偏见并保持高效用。Code可以在<a target="_blank" rel="noopener" href="https://github.com/Yuancheng-Xu/ELBERT%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Yuancheng-Xu/ELBERT中下载。</a><details>
<summary>Abstract</summary>
Decisions made by machine learning models may have lasting impacts over time, making long-term fairness a crucial consideration. It has been shown that when ignoring the long-term effect, naively imposing fairness criterion in static settings can actually exacerbate bias over time. To explicitly address biases in sequential decision-making, recent works formulate long-term fairness notions in Markov Decision Process (MDP) framework. They define the long-term bias to be the sum of static bias over each time step. However, we demonstrate that naively summing up the step-wise bias can cause a false sense of fairness since it fails to consider the importance difference of different time steps during transition. In this work, we introduce a long-term fairness notion called Equal Long-term Benefit Rate (ELBERT), which explicitly considers varying temporal importance and adapts static fairness principles to the sequential setting. Moreover, we show that the policy gradient of Long-term Benefit Rate can be analytically reduced to standard policy gradient. This makes standard policy optimization methods applicable for reducing the bias, leading to our proposed bias mitigation method ELBERT-PO. Experiments on three sequential decision making environments show that ELBERT-PO significantly reduces bias and maintains high utility. Code is available at https://github.com/Yuancheng-Xu/ELBERT.
</details>
<details>
<summary>摘要</summary>
决策机器学习模型的决策可能会有持续的影响，因此长期公平是一项重要考虑因素。研究发现，在忽略长期效果的情况下，简单地在静态设置下应用公平准则可能会加剧偏见。为了显式地处理序列决策中的偏见，最近的研究在Markov决策过程（MDP）框架中表述了长期公平观。它定义了长期偏见为每个时间步骤的公平差异的总和。然而，我们展示了将每步骤的偏见相加可能会导致假的公平感，因为它不考虑不同时间步骤之间的重要性差异。在这种情况下，我们引入了一种长期公平观念called Equal Long-term Benefit Rate（ELBERT），它明确考虑了不同时间步骤之间的变化 temporal importance，并将静态公平原则应用到序列设置中。此外，我们还证明了Long-term Benefit Rate的政策梯度可以通过标准政策梯度来降低偏见，导致我们的偏见缓解方法ELBERT-PO。在三个序列决策环境中，ELBERT-PO显著减少了偏见，同时保持了高的用 utility。代码可以在https://github.com/Yuancheng-Xu/ELBERT中获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/cs.LG_2023_09_07/" data-id="closbror800p70g88glmk4lkf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/eess.IV_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T09:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/eess.IV_2023_09_07/">eess.IV - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Secure-Control-of-Networked-Inverted-Pendulum-Visual-Servo-System-with-Adverse-Effects-of-Image-Computation-Extended-Version"><a href="#Secure-Control-of-Networked-Inverted-Pendulum-Visual-Servo-System-with-Adverse-Effects-of-Image-Computation-Extended-Version" class="headerlink" title="Secure Control of Networked Inverted Pendulum Visual Servo System with Adverse Effects of Image Computation (Extended Version)"></a>Secure Control of Networked Inverted Pendulum Visual Servo System with Adverse Effects of Image Computation (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03556">http://arxiv.org/abs/2309.03556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dajun Du, Changda Zhang, Qianjiang Lu, Minrui Fei, Huiyu Zhou</li>
<li>for: 提高网络传输图像信息安全性，防止图像攻击导致系统性能下降或崩溃。</li>
<li>methods: 提出一种基于快速缩放选择图像加密（F2SIE）算法的新的网络倾斜镜视测系统（NIPVSS），不仅实现了实时要求，而且提高了安全性。</li>
<li>results: 通过实验结果，证明提出的方法可以实现网络倾斜镜视测系统的可靠稳定性和安全性。<details>
<summary>Abstract</summary>
When visual image information is transmitted via communication networks, it easily suffers from image attacks, leading to system performance degradation or even crash. This paper investigates secure control of networked inverted pendulum visual servo system (NIPVSS) with adverse effects of image computation. Firstly, the image security limitation of the traditional NIPVSS is revealed, where its stability will be destroyed by eavesdropping-based image attacks. Then, a new NIPVSS with the fast scaled-selective image encryption (F2SIE) algorithm is proposed, which not only meets the real-time requirement by reducing the computational complexity, but also improve the security by reducing the probability of valuable information being compromised by eavesdropping-based image attacks. Secondly, adverse effects of the F2SIE algorithm and image attacks are analysed, which will produce extra computational delay and errors. Then, a closed-loop uncertain time-delay model of the new NIPVSS is established, and a robust controller is designed to guarantee system asymptotic stability. Finally, experimental results of the new NIPVSS demonstrate the feasibility and effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
当视觉图像信息通过通信网络传输时，容易受到图像攻击，导致系统性能下降或甚至崩溃。这篇论文研究了安全控制的网络倒挺镜视服系统（NIPVSS），并对图像计算的副作用进行分析。首先，传统NIPVSS的图像安全限制被揭示，其稳定性会由侦测图像攻击而被破坏。然后，一种新的NIPVSS，即快速缩放选择图像加密算法（F2SIE），被提出，该算法不仅可以满足实时要求，还能够提高安全性。其次，F2SIE算法和图像攻击的副作用被分析，它们会产生额外的计算延迟和错误。然后，一个关闭环路不确定时延模型的新NIPVSS被建立，并设计了一个robust控制器，以确保系统 asymptotic stability。最后，新NIPVSS的实验结果证明了提posed方法的可行性和效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/eess.IV_2023_09_07/" data-id="closbroy6016j0g88e14u9mpo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/07/eess.SP_2023_09_07/" class="article-date">
  <time datetime="2023-09-07T08:00:00.000Z" itemprop="datePublished">2023-09-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/07/eess.SP_2023_09_07/">eess.SP - 2023-09-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Channel-Estimation-for-Quantized-Systems-based-on-Conditionally-Gaussian-Latent-Models"><a href="#Channel-Estimation-for-Quantized-Systems-based-on-Conditionally-Gaussian-Latent-Models" class="headerlink" title="Channel Estimation for Quantized Systems based on Conditionally Gaussian Latent Models"></a>Channel Estimation for Quantized Systems based on Conditionally Gaussian Latent Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04014">http://arxiv.org/abs/2309.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benedikt Fesl, Nurettin Turan, Benedikt Böck, Wolfgang Utschick</li>
<li>for: 这篇论文旨在开发一种适合粗量化系统的通道估计器。</li>
<li>methods: 这篇论文使用了条件 Gaussian 干扰模型，包括 Gaussian mixture models (GMMs)、mixture of factor analyzers (MFAs) 和 variational autoencoders (VAEs)，并将这些模型与实际的通道分布相映射。</li>
<li>results: 这篇论文透过实验示出了新的估计器的优越性，对于粗量化系统而言，它具有较低的平均方差误差 (MSE) 和可能的范围 (achievable rate) 等指标。<details>
<summary>Abstract</summary>
This work introduces a novel class of channel estimators tailored for coarse quantization systems. The proposed estimators are founded on conditionally Gaussian latent generative models, specifically Gaussian mixture models (GMMs), mixture of factor analyzers (MFAs), and variational autoencoders (VAEs). These models effectively learn the unknown channel distribution inherent in radio propagation scenarios, providing valuable prior information. Conditioning on the latent variable of these generative models yields a locally Gaussian channel distribution, thus enabling the application of the well-known Bussgang decomposition. By exploiting the resulting conditional Bussgang decomposition, we derive parameterized linear minimum mean square error (MMSE) estimators for the considered generative latent variable models. In this context, we explore leveraging model-based structural features to reduce memory and complexity overhead associated with the proposed estimators. Furthermore, we devise necessary training adaptations, enabling direct learning of the generative models from quantized pilot observations without requiring ground-truth channel samples during the training phase. Through extensive simulations, we demonstrate the superiority of our introduced estimators over existing state-of-the-art methods for coarsely quantized systems, as evidenced by significant improvements in mean square error (MSE) and achievable rate metrics.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HDR-Imaging-With-One-Bit-Quantization"><a href="#HDR-Imaging-With-One-Bit-Quantization" class="headerlink" title="HDR Imaging With One-Bit Quantization"></a>HDR Imaging With One-Bit Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03982">http://arxiv.org/abs/2309.03982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arian Eamaz, Farhang Yeganegi, Mojtaba Soltanalian</li>
<li>for: 这篇论文旨在探讨模ulo sampling和杂谱一比特量化框架的相互作用，并将其应用于非射频信号中。</li>
<li>methods: 该论文使用模ulo ADC和杂谱一比特量化来实现高分辨率和低功耗。</li>
<li>results: 数值结果表明，在HDR图像恢复方面，模ulo sampling在非射频信号中具有极高的效果。<details>
<summary>Abstract</summary>
Modulo sampling and dithered one-bit quantization frameworks have emerged as promising solutions to overcome the limitations of traditional analog-to-digital converters (ADCs) and sensors. Modulo sampling, with its high-resolution approach utilizing modulo ADCs, offers an unlimited dynamic range, while dithered one-bit quantization offers cost-efficiency and reduced power consumption while operating at elevated sampling rates. Our goal is to explore the synergies between these two techniques, leveraging their unique advantages, and to apply them to non-bandlimited signals within spline spaces. One noteworthy application of these signals lies in High Dynamic Range (HDR) imaging. In this paper, we expand upon the Unlimited One-Bit (UNO) sampling framework, initially conceived for bandlimited signals, to encompass non-bandlimited signals found in the context of HDR imaging. We present a novel algorithm rigorously examined for its ability to recover images from one-bit modulo samples. Additionally, we introduce a sufficient condition specifically designed for UNO sampling to perfectly recover non-bandlimited signals within spline spaces. Our numerical results vividly demonstrate the effectiveness of UNO sampling in the realm of HDR imaging.
</details>
<details>
<summary>摘要</summary>
幂等采样和杂音一比Quantization框架已经出现为超过传统分析数字转换器（ADC）和感测器的限制的有力解决方案。幂等采样使用高分辨率的模ulo ADC，可以实现无限的动态范围，而杂音一比Quantization可以提供Cost-efficient和降低能耗的优点，同时在提高采样率时运行。我们的目标是探索这两种技术之间的相互作用，利用它们独特的优点，并应用于非射频信号内spline空间。一个值得注意的应用之一是高动态范围（HDR）图像处理。在这篇论文中，我们扩展了由带宽限制的一比 sampling框架（UNO sampling），以包括非射频信号。我们提出了一个新的算法，并且对其进行了严格的分析，以确保该算法可以从一比模ulo 样本中恢复图像。此外，我们还提出了特定于 UNO sampling的 suficient condition，以确保在spline空间中完全回收非射频信号。我们的数值结果表现了 UNO sampling在HDR图像处理中的效果。
</details></li>
</ul>
<hr>
<h2 id="Multivariate-Multi-step-and-Spatiotemporal-Traffic-Prediction-for-NextG-Network-Slicing-under-SLA-Constraints"><a href="#Multivariate-Multi-step-and-Spatiotemporal-Traffic-Prediction-for-NextG-Network-Slicing-under-SLA-Constraints" class="headerlink" title="Multivariate, Multi-step, and Spatiotemporal Traffic Prediction for NextG Network Slicing under SLA Constraints"></a>Multivariate, Multi-step, and Spatiotemporal Traffic Prediction for NextG Network Slicing under SLA Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03898">http://arxiv.org/abs/2309.03898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evren Tuna, Alkan Soysal<br>for:这种研究旨在提出一种基于NextG移动网络的空间时间流量预测方法，以保证每个网络slice的服务级别协议(SLA)。methods:该方法是多变量、多步、空间时间的，利用20个无线接入网络(RAN)特征、峰值交通时间数据和移动性基于凝集来提出一个parametric SLA-based loss函数，以保证SLA违约率。results:我们的方法可以在单个维度、多个维度和slice级别进行流量预测，并对它们进行详细的比较分析。单个维度和多个维度训练架构的应用，单个维度训练可以提供单个维度级别的预测，而多个维度训练可以使用多个维度的交通数据进行预测。我们发现单个维度训练的方法可以在测试损失方面与基eline SLA-based和MAE-based模型相比，提供11.4%和38.1%的改进。此外，我们还探讨了slice级别的流量预测方法，并提出了单个slice和多个slice的方法。我们发现单个slice方法可以提供较高的测试损失改进，即28.2%, 36.4%和55.6%。<details>
<summary>Abstract</summary>
This study presents a spatiotemporal traffic prediction approach for NextG mobile networks, ensuring the service-level agreements (SLAs) of each network slice. Our approach is multivariate, multi-step, and spatiotemporal. Leveraging 20 radio access network (RAN) features, peak traffic hour data, and mobility-based clustering, we propose a parametric SLA-based loss function to guarantee an SLA violation rate. We focus on single-cell, multi-cell, and slice-based prediction approaches and present a detailed comparative analysis of their performances, strengths, and limitations.   First, we address the application of single-cell and multi-cell training architectures. While single-cell training offers individual cell-level prediction, multi-cell training involves training a model using traffic from multiple cells from the same or different base stations. We show that the single-cell approach outperforms the multi-cell approach and results in test loss improvements of 11.4% and 38.1% compared to baseline SLA-based and MAE-based models, respectively.   Next, we explore slice-based traffic prediction. We present single-slice and multi-slice methods for slice-based downlink traffic volume prediction, arguing that multi-slice prediction offers a more accurate forecast. The slice-based model we introduce offers substantial test loss improvements of 28.2%, 36.4%, and 55.6% compared to our cell-based model, the baseline SLA-based model, and the baseline MAE-based model, respectively.
</details>
<details>
<summary>摘要</summary>
本研究提出了下一代移动网络（NextG）的空间时间流量预测方法，以保证每个网络卷（slice）的服务水平协议（SLA）。我们的方法是多变量、多步、空间时间的。利用20个无线接入网络（RAN）特征、峰值流量时间数据和移动性基于的分群，我们提出了一个参数化的SLA基于的损失函数，以确保SLA违反率。我们关注单细胞、多细胞和卷基本预测方法，并进行了详细的比较分析其性能、优势和局限性。首先，我们讨论了单细胞和多细胞训练架构。单细胞训练提供了单细胞级别的预测，而多细胞训练则是使用多个细胞的流量来训练模型。我们发现单细胞方法比多细胞方法更高效，并在测试损失上提供了11.4%和38.1%的改进，相比基eline SLA基本模型和MAE基本模型。然后，我们探索了卷基本的流量预测。我们介绍了单卷和多卷方法 для卷基本下行流量量预测，并论证了多卷预测提供了更准确的预测。我们的卷基本模型在测试损失上提供了28.2%, 36.4%和55.6%的改进，相比我们的细胞基本模型、基eline SLA基本模型和基eline MAE基本模型。
</details></li>
</ul>
<hr>
<h2 id="Private-Membership-Aggregation"><a href="#Private-Membership-Aggregation" class="headerlink" title="Private Membership Aggregation"></a>Private Membership Aggregation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03872">http://arxiv.org/abs/2309.03872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Nomeir, Sajani Vithana, Sennur Ulukus<br>for:The paper addresses the problem of private membership aggregation (PMA), where a user wants to count the number of times an element is stored in a system of independent parties without learning which element is being counted or which party has the element.methods:The paper proposes achievable schemes for four variants of the PMA problem based on the concept of cross-subspace alignment (CSA), which achieves linear communication complexity.results:The proposed schemes achieve better privacy and security constraints than previous $K$-PSI schemes, which require exponential complexity.<details>
<summary>Abstract</summary>
We consider the problem of private membership aggregation (PMA), in which a user counts the number of times a certain element is stored in a system of independent parties that store arbitrary sets of elements from a universal alphabet. The parties are not allowed to learn which element is being counted by the user. Further, neither the user nor the other parties are allowed to learn the stored elements of each party involved in the process. PMA is a generalization of the recently introduced problem of $K$ private set intersection ($K$-PSI). The $K$-PSI problem considers a set of $M$ parties storing arbitrary sets of elements, and a user who wants to determine if a certain element is repeated at least at $K$ parties out of the $M$ parties without learning which party has the required element and which party does not. To solve the general problem of PMA, we dissect it into four categories based on the privacy requirement and the collusions among databases/parties. We map these problems into equivalent private information retrieval (PIR) problems. We propose achievable schemes for each of the four variants of the problem based on the concept of cross-subspace alignment (CSA). The proposed schemes achieve \emph{linear} communication complexity as opposed to the state-of-the-art $K$-PSI scheme that requires \emph{exponential} complexity even though our PMA problems contain more security and privacy constraints.
</details>
<details>
<summary>摘要</summary>
我们考虑private membership aggregation（PMA）问题，用户计算系统中的一个元素被多个独立点 storing 的次数。这些点不能学习用户计算的元素，也不能学习彼此的储存元素。PMA是$K$ private set intersection（$K$-PSI）问题的一般化。$K$-PSI问题中有$M$个点储存不同的元素集，并有一个用户想要找出特定元素在$M$个点中重复的至少$K$个点，而不需要学习哪个点有需要的元素和哪个点没有。为了解决PMA问题，我们将其分为四种类型根据隐私要求和数据库之间的协议。我们将这些问题转换为相应的private information retrieval（PIR）问题。我们提出了解决这四种问题的可行方案，基于横向对准（CSA）概念。我们的方案实现了线性通信复杂度，而不是现有的$K$-PSI方案，即当问题中包含更多的安全和隐私要求时，需要 exponential 复杂度。
</details></li>
</ul>
<hr>
<h2 id="Experimental-Study-of-Adversarial-Attacks-on-ML-based-xApps-in-O-RAN"><a href="#Experimental-Study-of-Adversarial-Attacks-on-ML-based-xApps-in-O-RAN" class="headerlink" title="Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN"></a>Experimental Study of Adversarial Attacks on ML-based xApps in O-RAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03844">http://arxiv.org/abs/2309.03844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naveen Naik Sapavath, Brian Kim, Kaushik Chowdhury, Vijay K Shah</li>
<li>For: This paper focuses on the vulnerability of ML models used in O-RAN to adversarial attacks, and the impact of such attacks on the performance of the entire O-RAN deployment.* Methods: The paper uses an example ML model for interference classification in near-real time (near-RT) RAN intelligent controllers (RIC), and demonstrates the vulnerability of this model to adversarial attacks through manipulation of data stored in a shared database inside the near-RT RIC.* Results: The paper shows that even small adversarial attacks can significantly decrease the accuracy of the interference classifier xApp using both clean and perturbed data, which can directly impact the performance of the entire O-RAN deployment.Here is the information in Simplified Chinese text:* For: 这篇论文关注了O-RAN中ML模型对抗 adversarial攻击的漏洞，以及这些攻击对整个O-RAN部署的影响。* Methods: 论文使用一个示例的ML模型来预测干扰类型，并在near-real time（near-RT）RAN智能控制器（RIC）中实际部署这个模型。* Results: 论文显示，же小的抗击攻击可以很快地降低ML应用程序的准确率，这直接影响整个O-RAN部署的性能。<details>
<summary>Abstract</summary>
Open Radio Access Network (O-RAN) is considered as a major step in the evolution of next-generation cellular networks given its support for open interfaces and utilization of artificial intelligence (AI) into the deployment, operation, and maintenance of RAN. However, due to the openness of the O-RAN architecture, such AI models are inherently vulnerable to various adversarial machine learning (ML) attacks, i.e., adversarial attacks which correspond to slight manipulation of the input to the ML model. In this work, we showcase the vulnerability of an example ML model used in O-RAN, and experimentally deploy it in the near-real time (near-RT) RAN intelligent controller (RIC). Our ML-based interference classifier xApp (extensible application in near-RT RIC) tries to classify the type of interference to mitigate the interference effect on the O-RAN system. We demonstrate the first-ever scenario of how such an xApp can be impacted through an adversarial attack by manipulating the data stored in a shared database inside the near-RT RIC. Through a rigorous performance analysis deployed on a laboratory O-RAN testbed, we evaluate the performance in terms of capacity and the prediction accuracy of the interference classifier xApp using both clean and perturbed data. We show that even small adversarial attacks can significantly decrease the accuracy of ML application in near-RT RIC, which can directly impact the performance of the entire O-RAN deployment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Novel-Power-Imbalanced-Dense-Codebooks-for-Reliable-Multiplexing-in-Nakagami-Channels"><a href="#Novel-Power-Imbalanced-Dense-Codebooks-for-Reliable-Multiplexing-in-Nakagami-Channels" class="headerlink" title="Novel Power-Imbalanced Dense Codebooks for Reliable Multiplexing in Nakagami Channels"></a>Novel Power-Imbalanced Dense Codebooks for Reliable Multiplexing in Nakagami Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03806">http://arxiv.org/abs/2309.03806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Gui, Zilong Liu, Lisu Yu, Chunlei Li, Pingzhi Fan</li>
<li>for: 这个论文研究了在Nakagami-$m$折叠渠道上下行传输中进行增强率密集代码访问系统的设计。</li>
<li>methods: 这个论文首先研究了DCMA对称错误概率（PEP）在Nakagami-$m$通道上，然后提出了一种新的设计指标called minimum logarithmic sum distance（MLSD）。</li>
<li>results: 对于提出的MLSD，我们引入了一种新的功率不均衡率密集代码库，通过删除特定的行来实现。 simulation results显示，我们的提出的率密集代码库可以提高 Nakagami-$m$折叠渠道下的错误性能，并且在不同的扩展因子下表现出优于现有的稀疏代码多访问和传统的unimodular DCMA方案。<details>
<summary>Abstract</summary>
This paper studies enhanced dense code multiple access (DCMA) system design for downlink transmission over the Nakagami-$m$ fading channels. By studying the DCMA pairwise error probability (PEP) in a Nakagami-$m$ channel, a novel design metric called minimum logarithmic sum distance (MLSD) is first derived. With respect to the proposed MLSD, we introduce a new family of power-imbalanced dense codebooks by deleting certain rows of a special non-unimodular circulant matrix. Simulation results demonstrate that our proposed dense codebooks lead to both larger minimum Euclidean distance and MLSD, thus yielding significant improvements of error performance over the existing sparse code multiple access and conventional unimodular DCMA schemes in Nakagami-$m$ fading channels under different overloading factors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Space-Time-Shift-Keying-Aided-OTFS-Modulation-for-Orthogonal-Multiple-Access"><a href="#Space-Time-Shift-Keying-Aided-OTFS-Modulation-for-Orthogonal-Multiple-Access" class="headerlink" title="Space-Time Shift Keying Aided OTFS Modulation for Orthogonal Multiple Access"></a>Space-Time Shift Keying Aided OTFS Modulation for Orthogonal Multiple Access</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03771">http://arxiv.org/abs/2309.03771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeping Sui, Hongming Zhang, Sumei Sun, Lie-Liang Yang, Lajos Hanzo</li>
<li>For: 提高高Doppler场景下的可靠上行传输* Methods: 使用Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA)系统* Results: 提高多用户干扰耐受性和编码增益，并且可以实现更好的误差检测复杂度与性能质量之间的trade-off。<details>
<summary>Abstract</summary>
Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA) is proposed for reliable uplink transmission in high-Doppler scenarios. As a beneficial feature of our STSK-OTFS-MA system, extra information bits are mapped onto the indices of the active dispersion matrices, which allows the system to enjoy the joint benefits of both STSK and OTFS signalling. Due to the fact that both the time-, space- and DD-domain degrees of freedom are jointly exploited, our STSK-OTFS-MA achieves increased diversity and coding gains. To mitigate the potentially excessive detection complexity, the sparse structure of the equivalent transmitted symbol vector is exploited, resulting in a pair of low-complexity near-maximum likelihood (ML) multiuser detection algorithms. Explicitly, we conceive a progressive residual check-based greedy detector (PRCGD) and an iterative reduced-space check-based detector (IRCD). Then, we derive both the unconditional single-user pairwise error probability (SU-UPEP) and a tight bit error ratio (BER) union-bound for our single-user STSK-OTFS-MA system employing the ML detector. Furthermore, the discrete-input continuous-output memoryless channel (DCMC) capacity of the proposed system is derived. The optimal dispersion matrices (DMs) are designed based on the maximum attainable diversity and coding gain metrics. Finally, it is demonstrated that our STSK-OTFS-MA system achieves both a lower BER and a higher DCMC capacity than its conventional spatial modulation (SM) {and its orthogonal frequency-division multiplexing (OFDM) counterparts. As a benefit, the proposed system strikes a compelling BER vs. system complexity as well as BER vs. detection complexity trade-offs.
</details>
<details>
<summary>摘要</summary>
Space-time shift keying-aided orthogonal time frequency space modulation-based multiple access (STSK-OTFS-MA) 是一种用于可靠的上行传输的高Doppler场景中的新系统。我们的STSK-OTFS-MA系统具有一个有利的特点，即在活动扩散矩阵上对额外信息位元进行映射，从而使系统能够同时享受STSK和OTFS信号的优点。由于系统同时利用了时间、空间和DD频域的自由度，因此我们的STSK-OTFS-MA系统可以获得更高的多样性和编码增益。为了避免可能的过分复杂的检测，我们利用了稀疏结构的等效传输符号向量，并提出了一对低复杂度的Near-Maximum Likelihood（ML）多用户检测算法：进步循环剩余检查基于的滥触检测器（PRCGD）和迭代减少空间检查基于的检测器（IRCD）。然后，我们 deriv了单用户STSK-OTFS-MA系统的无条件单用户对比误差率（SU-UPEP）和紧密的 bits错误率（BER）联合上限。此外，我们还 deriv了DCMC容量。最佳的扩散矩阵（DM）是根据最大可能的多样性和编码增益度量进行设计。最终，我们证明了我们的STSK-OTFS-MA系统在BER和DCMC容量方面都高于传统的空间模ulation（SM）和orthogonal frequency-division multiplexing（OFDM）对应系统。此外，我们的系统在BER vs. 系统复杂度和检测复杂度之间实现了惊喜的质量-精度负担。
</details></li>
</ul>
<hr>
<h2 id="Resource-Management-for-IRS-assisted-WP-MEC-Networks-with-Practical-Phase-Shift-Model"><a href="#Resource-Management-for-IRS-assisted-WP-MEC-Networks-with-Practical-Phase-Shift-Model" class="headerlink" title="Resource Management for IRS-assisted WP-MEC Networks with Practical Phase Shift Model"></a>Resource Management for IRS-assisted WP-MEC Networks with Practical Phase Shift Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03471">http://arxiv.org/abs/2309.03471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nana Li, Wanming Hao, Fuhui Zhou, Zheng Chu, Shouyi Yang, Pei Xiao</li>
<li>为：提高无线电力动力扩展计算能力和可持续能源供应 для低功率无线设备（WD）。* 方法：使用多个智能反射表面（IRS）来增强WP-MEC网络。jointly optimize downlink&#x2F;uplink IRSs passive beamforming, downlink energy beamforming, and uplink multi-user detection (MUD) vector at HAPs, task offloading power and local computing frequency of WDs, and time slot allocation.* 结果：对于WP-MEC网络，使用实际IRS相位偏移模型可以实现更高的总计算率，比基eline方案高。<details>
<summary>Abstract</summary>
Wireless powered mobile edge computing (WP-MEC) has been recognized as a promising solution to enhance the computational capability and sustainable energy supply for low-power wireless devices (WDs). However, when the communication links between the hybrid access point (HAP) and WDs are hostile, the energy transfer efficiency and task offloading rate are compromised. To tackle this problem, we propose to employ multiple intelligent reflecting surfaces (IRSs) to WP-MEC networks. Based on the practical IRS phase shift model, we formulate a total computation rate maximization problem by jointly optimizing downlink/uplink IRSs passive beamforming, downlink energy beamforming and uplink multi-user detection (MUD) vector at HAPs, task offloading power and local computing frequency of WDs, and the time slot allocation. Specifically, we first derive the optimal time allocation for downlink wireless energy transmission (WET) to IRSs and the corresponding energy beamforming. Next, with fixed time allocation for the downlink WET to WDs, the original optimization problem can be divided into two independent subproblems. For the WD charging subproblem, the optimal IRSs passive beamforming is derived by utilizing the successive convex approximation (SCA) method and the penalty-based optimization technique, and for the offloading computing subproblem, we propose a joint optimization framework based on the fractional programming (FP) method. Finally, simulation results validate that our proposed optimization method based on the practical phase shift model can achieve a higher total computation rate compared to the baseline schemes.
</details>
<details>
<summary>摘要</summary>
无线电力驱动边缘计算（WP-MEC）已被认为是提高无线设备（WD）的计算能力和可持续能源供应的有前途的解决方案。然而，当通信链路 между混合访问点（HAP）和WDs是敌对的时，能量传输效率和任务卸载率受到影响。为解决这个问题，我们提议使用多个智能反射表面（IRS）来加入WP-MEC网络。基于实际的IRS相位偏移模型，我们将最大化总计算率问题进行联合优化，包括下降链接IRSs的过分形成、下降能量形成和上降多用户检测（MUD）向量在HAPs、任务卸载电力和本地计算频率的WDs，以及时间槽分配。Specifically, we first derive the optimal time allocation for downlink wireless energy transmission（WET）to IRSs and the corresponding energy beamforming. Next, with fixed time allocation for the downlink WET to WDs, the original optimization problem can be divided into two independent subproblems. For the WD charging subproblem, the optimal IRSs passive beamforming is derived by utilizing the successive convex approximation（SCA）method and the penalty-based optimization technique, and for the offloading computing subproblem, we propose a joint optimization framework based on the fractional programming（FP）method. Finally, simulation results validate that our proposed optimization method based on the practical phase shift model can achieve a higher total computation rate compared to the baseline schemes.
</details></li>
</ul>
<hr>
<h2 id="RIS-Assisted-Wireless-Communications-Long-Term-versus-Short-Term-Phase-Shift-Designs"><a href="#RIS-Assisted-Wireless-Communications-Long-Term-versus-Short-Term-Phase-Shift-Designs" class="headerlink" title="RIS-Assisted Wireless Communications: Long-Term versus Short-Term Phase Shift Designs"></a>RIS-Assisted Wireless Communications: Long-Term versus Short-Term Phase Shift Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03436">http://arxiv.org/abs/2309.03436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Trinh Van Chien, Lam Thanh Tu, Waqas Khalid, Heejung Yu, Symeon Chatzinotas, Marco Di Renzo</li>
<li>for: 提高未来无线网络的覆盖可能性和性能</li>
<li>methods: 使用 RIS 技术和数学优化方法</li>
<li>results: 提高覆盖可能性和性能，比较好于几种优化方案和 benchmarkHere’s the full translation in Simplified Chinese:</li>
<li>for: 这篇论文是为了提高未来无线网络的覆盖可能性和性能而写的。</li>
<li>methods: 这篇论文使用了 RIS 技术和数学优化方法来解决这个问题。</li>
<li>results: 这篇论文的结果表明，使用 RIS 技术和数学优化方法可以提高覆盖可能性和性能，并且比较好于几种优化方案和 benchmark。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surface (RIS) has recently gained significant interest as an emerging technology for future wireless networks thanks to its potential for improving the coverage probability in challenging propagation environments. This paper studies an RIS-assisted propagation environment, where a source transmits data to a destination in the presence of a weak direct link. We analyze and compare RIS designs based on long-term and short-term channel statistics in terms of coverage probability and ergodic rate. For the considered optimization designs, we derive closed-form expressions for the coverage probability and ergodic rate, which explicitly unveil the impact of both the propagation environment and the RIS on the system performance. Besides the optimization of the RIS phase profile, we formulate an RIS placement optimization problem with the aim of maximizing the coverage probability by relying only on partial channel state information. An efficient algorithm is proposed based on the gradient ascent method. Simulation results are illustrated in order to corroborate the analytical framework and findings. The proposed RIS phase profile is shown to outperform several heuristic benchmarks in terms of outage probability and ergodic rate. In addition, the proposed RIS placement strategy provides an extra degree of freedom that remarkably improves system performance.
</details>
<details>
<summary>摘要</summary>
快速智能表面（RIS）在未来无线网络中已经吸引了广泛关注，因为它可以改善在困难媒体环境中的覆盖率。这篇论文研究了受助RIS的传输环境，source向目标传输数据，在弱直接链路的存在下。我们分析和比较了基于长期和短期频率统计的RIS设计，并计算了覆盖率和均衡速率。对考虑的优化设计，我们 derivated了closed-form表达式，这些表达式直接揭示了媒体环境和RIS对系统性能的影响。此外，我们提出了基于Gradient Ascent方法的RIS布局优化问题，以最大化覆盖率，只使用部分频率状态信息。实验结果表明，我们提出的RIS相位profile不仅在出入�pto�比较高，还可以在各种媒体环境下提供更好的系统性能。此外，我们的RIS布局策略提供了一个额外的自由度，可以很好地提高系统性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/07/eess.SP_2023_09_07/" data-id="closbrozj019z0g88gks7hlva" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/06/cs.SD_2023_09_06/" class="article-date">
  <time datetime="2023-09-06T15:00:00.000Z" itemprop="datePublished">2023-09-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/06/cs.SD_2023_09_06/">cs.SD - 2023-09-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Highly-Controllable-Diffusion-based-Any-to-Any-Voice-Conversion-Model-with-Frame-level-Prosody-Feature"><a href="#Highly-Controllable-Diffusion-based-Any-to-Any-Voice-Conversion-Model-with-Frame-level-Prosody-Feature" class="headerlink" title="Highly Controllable Diffusion-based Any-to-Any Voice Conversion Model with Frame-level Prosody Feature"></a>Highly Controllable Diffusion-based Any-to-Any Voice Conversion Model with Frame-level Prosody Feature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03364">http://arxiv.org/abs/2309.03364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyungguen Byun, Sunkuk Moon, Erik Visser</li>
<li>for: 这个论文的目的是提出一种可控的语音修饰系统，可以同时实现语音转换和语速调整。</li>
<li>methods: 该系统使用一个框架级别的语音特征来有效地传递框架级别的特性，包括投射和能量轨迹。这些特征被与说话者和内容嵌入一起feed到一个扩散型解码器中，生成一个已转换的语音干扰gram。另外，为了调整说话速度，系统还包括一个自我超vised模型后处理步骤，以提高可控性。</li>
<li>results: 该系统比一种现有的方法（SOTA）更有控制性和可读性，可以覆盖各种基频（F0）、能量和速度的变化，同时保持转换后的语音质量。<details>
<summary>Abstract</summary>
We propose a highly controllable voice manipulation system that can perform any-to-any voice conversion (VC) and prosody modulation simultaneously. State-of-the-art VC systems can transfer sentence-level characteristics such as speaker, emotion, and speaking style. However, manipulating the frame-level prosody, such as pitch, energy and speaking rate, still remains challenging. Our proposed model utilizes a frame-level prosody feature to effectively transfer such properties. Specifically, pitch and energy trajectories are integrated in a prosody conditioning module and then fed alongside speaker and contents embeddings to a diffusion-based decoder generating a converted speech mel-spectrogram. To adjust the speaking rate, our system includes a self-supervised model based post-processing step which allows improved controllability. The proposed model showed comparable speech quality and improved intelligibility compared to a SOTA approach. It can cover a varying range of fundamental frequency (F0), energy and speed modulation while maintaining converted speech quality.
</details>
<details>
<summary>摘要</summary>
我们提出了一种高度可控的语音修饰系统，可同时实现任意语音转换（VC）和语速修饰。现状的VC系统可以传递句子水平特征，如发音人、情感和说话风格。然而，修饰帧级别的语音特征，如抽象、能量和说话速度，仍然具有挑战性。我们的提议的模型利用帧级别的语音特征来有效地传递这些特性。具体来说，我们在语音修饰模块中将抽象和能量轨迹结合在一起，然后与发音人和内容嵌入一起传递给一个基于扩散的解码器生成转换后的语音mel-spectrogram。为了调整说话速度，我们的系统包括一个基于自我超vision的后处理步骤，以提高可控性。我们的模型与State-of-the-art方法相比，能够覆盖不同的基本频率（F0）、能量和速度修饰范围，而且保持转换后语音质量。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Geometrical-Acoustic-Simulations-of-Spatial-Room-Impulse-Responses-for-Improved-Sound-Event-Detection-and-Localization"><a href="#Leveraging-Geometrical-Acoustic-Simulations-of-Spatial-Room-Impulse-Responses-for-Improved-Sound-Event-Detection-and-Localization" class="headerlink" title="Leveraging Geometrical Acoustic Simulations of Spatial Room Impulse Responses for Improved Sound Event Detection and Localization"></a>Leveraging Geometrical Acoustic Simulations of Spatial Room Impulse Responses for Improved Sound Event Detection and Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03337">http://arxiv.org/abs/2309.03337</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ChrisIck/DCASE_Synth_Data">https://github.com/ChrisIck/DCASE_Synth_Data</a></li>
<li>paper_authors: Christopher Ick, Brian McFee</li>
<li>for: 实现声音事件地图（SELD）模型的训练，为了解决现有的资料匮乏问题。</li>
<li>methods: 使用几何学式的单簇声学模拟来生成新的声音空间响应（SRIR）数据集，并将其用于训练SELD模型。</li>
<li>results: 透过实验显示，使用几何学式的单簇声学模拟可以提供相似的性能，并且可以将现有的数据集进行增强。<details>
<summary>Abstract</summary>
As deeper and more complex models are developed for the task of sound event localization and detection (SELD), the demand for annotated spatial audio data continues to increase. Annotating field recordings with 360$^{\circ}$ video takes many hours from trained annotators, while recording events within motion-tracked laboratories are bounded by cost and expertise. Because of this, localization models rely on a relatively limited amount of spatial audio data in the form of spatial room impulse response (SRIR) datasets, which limits the progress of increasingly deep neural network based approaches. In this work, we demonstrate that simulated geometrical acoustics can provide an appealing solution to this problem. We use simulated geometrical acoustics to generate a novel SRIR dataset that can train a SELD model to provide similar performance to that of a real SRIR dataset. Furthermore, we demonstrate using simulated data to augment existing datasets, improving on benchmarks set by state of the art SELD models. We explore the potential and limitations of geometric acoustic simulation for localization and event detection. We also propose further studies to verify the limitations of this method, as well as further methods to generate synthetic data for SELD tasks without the need to record more data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Presenting-the-SWTC-A-Symbolic-Corpus-of-Themes-from-John-Williams’-Star-Wars-Episodes-I-IX"><a href="#Presenting-the-SWTC-A-Symbolic-Corpus-of-Themes-from-John-Williams’-Star-Wars-Episodes-I-IX" class="headerlink" title="Presenting the SWTC: A Symbolic Corpus of Themes from John Williams’ Star Wars Episodes I-IX"></a>Presenting the SWTC: A Symbolic Corpus of Themes from John Williams’ Star Wars Episodes I-IX</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03298">http://arxiv.org/abs/2309.03298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Claire Arthur, Frank Lehman, John McNamara</li>
<li>for: This paper presents a new symbolic corpus of musical themes from the complete Star Wars trilogies (Episodes I-IX) by John Williams.</li>
<li>methods: The corpus files are made available in multiple formats (.krn, .sib, and .musicxml) and include melodic, harmonic, and formal information. The authors also introduce a new humdrum standard for non-functional harmony encodings, **harte, based on Harte (2005, 2010).</li>
<li>results: The Star Wars Thematic Corpus (SWTC) contains a total of 64 distinctive, recurring, and symbolically meaningful themes and motifs, commonly referred to as leitmotifs. The authors provide some brief summary statistics and hope that the SWTC will provide insights into John Williams’ compositional style and be useful in comparisons against other thematic corpora from film and beyond.<details>
<summary>Abstract</summary>
This paper presents a new symbolic corpus of musical themes from the complete Star Wars trilogies (Episodes I-IX) by John Williams. The corpus files are made available in multiple formats (.krn, .sib, and .musicxml) and include melodic, harmonic, and formal information. The Star Wars Thematic Corpus (SWTC) contains a total of 64 distinctive, recurring, and symbolically meaningful themes and motifs, commonly referred to as leitmotifs. Through this corpus we also introduce a new humdrum standard for non-functional harmony encodings, **harte, based on Harte (2005, 2010). This report details the motivation, describes the transcription and encoding processes, and provides some brief summary statistics. While relatively small in scale, the SWTC represents a unified collection from one of the most prolific and influential composers of the 20th century, and the under-studied subset of film and multimedia musical material in general. We hope the SWTC will provide insights into John Williams' compositional style, as well as prove useful in comparisons against other thematic corpora from film and beyond.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Real-time-auralization-for-performers-on-virtual-stages"><a href="#Real-time-auralization-for-performers-on-virtual-stages" class="headerlink" title="Real-time auralization for performers on virtual stages"></a>Real-time auralization for performers on virtual stages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.03149">http://arxiv.org/abs/2309.03149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernesto Accolti, Lukas Aspöck, Manuj Yadav, Michael Vorländer</li>
<li>for: 这篇论文描述了一个互动系统，用于音乐表演实验室中的音响实验。</li>
<li>methods: 这个系统使用了一些考虑了听到自己和他人乐器的因素的实际化系统，以及考虑了视觉、模拟方法和振荡等因素。</li>
<li>results: 这篇论文提出了一种准确的听到自己和他人乐器的实际化系统，并且通过了对比实验和主观测试，证明了这种系统的可行性。<details>
<summary>Abstract</summary>
This article presents an interactive system for stage acoustics experimentation including considerations for hearing one's own and others' instruments. The quality of real-time auralization systems for psychophysical experiments on music performance depends on the system's calibration and latency, among other factors (e.g. visuals, simulation methods, haptics, etc). The presented system focuses on the acoustic considerations for laboratory implementations. The calibration is implemented as a set of filters accounting for the microphone-instrument distances and the directivity factors, as well as the transducers' frequency responses. Moreover, sources of errors are characterized using both state-of-the-art information and derivations from the mathematical definition of the calibration filter. In order to compensate for hardware latency without cropping parts of the simulated impulse responses, the virtual direct sound of musicians hearing themselves is skipped from the simulation and addressed by letting the actual direct sound reach the listener through open headphones. The required latency compensation of the interactive part (i.e. hearing others) meets the minimum distance requirement between musicians, which is 2 m for the implemented system. Finally, a proof of concept is provided that includes objective and subjective experiments, which give support to the feasibility of the proposed setup.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Self-Supervised-Disentanglement-of-Harmonic-and-Rhythmic-Features-in-Music-Audio-Signals"><a href="#Self-Supervised-Disentanglement-of-Harmonic-and-Rhythmic-Features-in-Music-Audio-Signals" class="headerlink" title="Self-Supervised Disentanglement of Harmonic and Rhythmic Features in Music Audio Signals"></a>Self-Supervised Disentanglement of Harmonic and Rhythmic Features in Music Audio Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02796">http://arxiv.org/abs/2309.02796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/WuYiming6526/HARD-DAFx2023">https://github.com/WuYiming6526/HARD-DAFx2023</a></li>
<li>paper_authors: Yiming Wu</li>
<li>for: 这个论文旨在推断音乐audiо生成过程中隐藏的多个有用特征表示，以实现可控的数据生成。</li>
<li>methods: 该论文提出了一种基于深度神经网络的自我超vised学习方法，用于推断音乐audiо生成过程中的rhythmic和harmonic表示。在训练阶段，该方法使用变换 autoencoder 将 mel-spectrogram 转换为两个隐藏特征，代表rhythmic和harmonic内容。在每次前向计算过程中，对一个隐藏特征应用了vector rotation操作，假设这些维度对应了抑制间隔。因此，在训练过程中，rotated隐藏特征表示mel-spectrogram中的抑制相关信息，而unrotated隐藏特征表示rhythmic内容。</li>
<li>results: 该方法被用predictor-based disentanglement metric来评估学习的结果，并应用于自动生成音乐remixes。<details>
<summary>Abstract</summary>
The aim of latent variable disentanglement is to infer the multiple informative latent representations that lie behind a data generation process and is a key factor in controllable data generation. In this paper, we propose a deep neural network-based self-supervised learning method to infer the disentangled rhythmic and harmonic representations behind music audio generation. We train a variational autoencoder that generates an audio mel-spectrogram from two latent features representing the rhythmic and harmonic content. In the training phase, the variational autoencoder is trained to reconstruct the input mel-spectrogram given its pitch-shifted version. At each forward computation in the training phase, a vector rotation operation is applied to one of the latent features, assuming that the dimensions of the feature vectors are related to pitch intervals. Therefore, in the trained variational autoencoder, the rotated latent feature represents the pitch-related information of the mel-spectrogram, and the unrotated latent feature represents the pitch-invariant information, i.e., the rhythmic content. The proposed method was evaluated using a predictor-based disentanglement metric on the learned features. Furthermore, we demonstrate its application to the automatic generation of music remixes.
</details>
<details>
<summary>摘要</summary>
“ latent variable disentanglement 的目标是推断数据生成过程中隐藏的多个有用特征表示，这是可控数据生成的关键因素。在这篇论文中，我们提议一种基于深度神经网络的自我超vised学习方法，用于推断音频数据生成过程中的分解特征。我们训练了一个变分自动编码器，该编码器从两个隐藏特征中生成了一个音频 mel-spectrogram，其中一个隐藏特征表示了 rhythmic 内容，另一个隐藏特征表示了 harmonic 内容。在训练阶段，变分自动编码器被训练来重建输入 mel-spectrogram，基于其滥 shift 版本。在每次前向计算中，我们对一个隐藏特征应用了一个向量旋转操作，假设这些特征维度与抑制间隔有关。因此，在训练后的变分自动编码器中，旋转隐藏特征表示音频中的抑制相关信息，而未旋转隐藏特征表示 rhythmic 内容。我们使用 predictor-based 分解度量评估学习的结果，并示出了它的应用于自动生成音乐重混。”
</details></li>
</ul>
<hr>
<h2 id="Simultaneous-Measurement-of-Multiple-Acoustic-Attributes-Using-Structured-Periodic-Test-Signals-Including-Music-and-Other-Sound-Materials"><a href="#Simultaneous-Measurement-of-Multiple-Acoustic-Attributes-Using-Structured-Periodic-Test-Signals-Including-Music-and-Other-Sound-Materials" class="headerlink" title="Simultaneous Measurement of Multiple Acoustic Attributes Using Structured Periodic Test Signals Including Music and Other Sound Materials"></a>Simultaneous Measurement of Multiple Acoustic Attributes Using Structured Periodic Test Signals Including Music and Other Sound Materials</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02767">http://arxiv.org/abs/2309.02767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hideki Kawahara, Kohei Yatabe, Ken-Ichi Sakakibara, Mitsunori Mizumachi, Tatsuya Kitamura</li>
<li>for: 这 paper 是用来测量音频特性的框架，包括常数时变 (LTI) 回响、信号依赖时变 (SDTI) 组成部分以及随机时变 (RTV) 部分。</li>
<li>methods: 这 paper 使用了结构化 periodic test signal 来测量音频特性，并且可以使用音乐作品和其他声音材料作为测试信号。</li>
<li>results: 这 paper 实现了一种可交互式、实时测量工具，并且开源了这些工具。此外， paper 还用这些工具对抽取器的性能进行了 объектив评估。<details>
<summary>Abstract</summary>
We introduce a general framework for measuring acoustic properties such as liner time-invariant (LTI) response, signal-dependent time-invariant (SDTI) component, and random and time-varying (RTV) component simultaneously using structured periodic test signals. The framework also enables music pieces and other sound materials as test signals by "safeguarding" them by adding slight deterministic "noise." Measurement using swept-sin, MLS (Maxim Length Sequence), and their variants are special cases of the proposed framework. We implemented interactive and real-time measuring tools based on this framework and made them open-source. Furthermore, we applied this framework to assess pitch extractors objectively.
</details>
<details>
<summary>摘要</summary>
我们提出了一个普遍适用的测量听音属性的框架，包括线性时不变（LTI）响应、固有时不变（SDTI）组件以及随机时变（RTV）组件，同时测量这些属性。这个框架还允许使用音乐作品和其他声音材料作为测试信号，通过添加一些稳定的随机噪声来"保护"它们。使用滚动窗口、MLS（最长长度序列）和其他变体的测量方法都是该框架的特殊情况。我们还实现了基于这个框架的交互式和实时测量工具，并将其开源。此外，我们使用这个框架对抽取器进行了 объекively 的评估。
</details></li>
</ul>
<hr>
<h2 id="MuLanTTS-The-Microsoft-Speech-Synthesis-System-for-Blizzard-Challenge-2023"><a href="#MuLanTTS-The-Microsoft-Speech-Synthesis-System-for-Blizzard-Challenge-2023" class="headerlink" title="MuLanTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2023"></a>MuLanTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02743">http://arxiv.org/abs/2309.02743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihang Xu, Shaofei Zhang, Xi Wang, Jiajun Zhang, Wenning Wei, Lei He, Sheng Zhao</li>
<li>for: 这项研究是为了提出一个基于Microsoft的端到端神经网络文本读取系统（TTS），旨在参加2023年Blizzard挑战。</li>
<li>methods: 该系统基于DelightfulTTS，采用了上下文和情感编码器来适应Audiobook数据，以提高长形句子和对话表达性。此外，还应用了采样除噪和长 audio处理等技术来提高录音质量。</li>
<li>results: 该系统在两个任务中获得了mean评分4.3和4.5，与自然语音 statistically comparable，同时保持了good similarity according to similarity assessment。这些结果表明该系统在两个任务中得到了优秀的效果。<details>
<summary>Abstract</summary>
In this paper, we present MuLanTTS, the Microsoft end-to-end neural text-to-speech (TTS) system designed for the Blizzard Challenge 2023. About 50 hours of audiobook corpus for French TTS as hub task and another 2 hours of speaker adaptation as spoke task are released to build synthesized voices for different test purposes including sentences, paragraphs, homographs, lists, etc. Building upon DelightfulTTS, we adopt contextual and emotion encoders to adapt the audiobook data to enrich beyond sentences for long-form prosody and dialogue expressiveness. Regarding the recording quality, we also apply denoise algorithms and long audio processing for both corpora. For the hub task, only the 50-hour single speaker data is used for building the TTS system, while for the spoke task, a multi-speaker source model is used for target speaker fine tuning. MuLanTTS achieves mean scores of quality assessment 4.3 and 4.5 in the respective tasks, statistically comparable with natural speech while keeping good similarity according to similarity assessment. The excellent and similarity in this year's new and dense statistical evaluation show the effectiveness of our proposed system in both tasks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了Microsoft的终端到终点神经语音识别系统MuLanTTS，用于2023年Blizzard挑战。我们发布了50小时的法语TTS Hub任务数据和2小时的说话人适应任务数据，用于建立不同测试目的的合成声音，包括句子、段落、同义词、列表等。基于DelightfulTTS，我们采用了上下文和情感编码器，以便对audiobook数据进行拓展，以增强长形层次和对话表达性。在录音质量方面，我们还应用了雷达处理和长 audio处理等技术。在Hub任务中，我们只使用单个说话人数据进行TTS系统建立，而在 Spoke任务中，我们使用多个说话人源模型进行目标说话人细化。MuLanTTS在两个任务中获得了4.3和4.5的平均评价分，与自然语音相比，保持了良好的相似性。这一年的新和紧密的统计评价结果表明我们提出的系统在两个任务中的效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/06/cs.SD_2023_09_06/" data-id="closbrotl00w50g8807280jyr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/45/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/44/">44</a><a class="page-number" href="/page/45/">45</a><span class="page-number current">46</span><a class="page-number" href="/page/47/">47</a><a class="page-number" href="/page/48/">48</a><span class="space">&hellip;</span><a class="page-number" href="/page/89/">89</a><a class="extend next" rel="next" href="/page/47/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
