
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/72/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.AI_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T12:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.AI_2023_08_09/">cs.AI - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MetRoBERTa-Leveraging-Traditional-Customer-Relationship-Management-Data-to-Develop-a-Transit-Topic-Aware-Language-Model"><a href="#MetRoBERTa-Leveraging-Traditional-Customer-Relationship-Management-Data-to-Develop-a-Transit-Topic-Aware-Language-Model" class="headerlink" title="MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model"></a>MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05012">http://arxiv.org/abs/2308.05012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Leong, Awad Abdelhalim, Jude Ha, Dianne Patterson, Gabriel L. Pincus, Anthony B. Harris, Michael Eichler, Jinhua Zhao</li>
<li>for: 了解旅客对公共交通服务的反馈，以优化服务质量和满意度。</li>
<li>methods: 利用传统的公共交通客户关系管理（CRM）反馈，开发和部署一种基于语言模型（LLM）的公共交通专题检测系统，以分类开放式文本反馈。</li>
<li>results: 使用半监督学习引擎团队建立了11个广泛的公共交通主题，并使用这些数据来训练和评估一种基于RoBERTa架构的语言模型。该模型在所有评价指标上都超过了经典机器学习方法，提供了90%的主题分类精度。<details>
<summary>Abstract</summary>
Transit riders' feedback provided in ridership surveys, customer relationship management (CRM) channels, and in more recent times, through social media is key for transit agencies to better gauge the efficacy of their services and initiatives. Getting a holistic understanding of riders' experience through the feedback shared in those instruments is often challenging, mostly due to the open-ended, unstructured nature of text feedback. In this paper, we propose leveraging traditional transit CRM feedback to develop and deploy a transit-topic-aware large language model (LLM) capable of classifying open-ended text feedback to relevant transit-specific topics. First, we utilize semi-supervised learning to engineer a training dataset of 11 broad transit topics detected in a corpus of 6 years of customer feedback provided to the Washington Metropolitan Area Transit Authority (WMATA). We then use this dataset to train and thoroughly evaluate a language model based on the RoBERTa architecture. We compare our LLM, MetRoBERTa, to classical machine learning approaches utilizing keyword-based and lexicon representations. Our model outperforms those methods across all evaluation metrics, providing an average topic classification accuracy of 90%. Finally, we provide a value proposition of this work demonstrating how the language model, alongside additional text processing tools, can be applied to add structure to open-ended text sources of feedback like Twitter. The framework and results we present provide a pathway for an automated, generalizable approach for ingesting, visualizing, and reporting transit riders' feedback at scale, enabling agencies to better understand and improve customer experience.
</details>
<details>
<summary>摘要</summary>
公共交通使用者的反馈，从乘客关系管理（CRM）渠道、客户反馈Surveys以及最近的社交媒体，对公共交通机构来说非常重要。通过反馈来了解乘客的体验，可以帮助机构更好地了解自己的服务和活动的效果。然而，由于反馈的开放性和无结构性，通常是困难的获得整体的理解。在这篇文章中，我们提议利用传统的公共交通CRM反馈，开发和部署一个具有公共交通话题意识的大语言模型（LLM），可以将开放式文本反馈分类到相关的公共交通话题。我们首先利用半监督学习，engineer一个训练集，其中包含6年的客户反馈数据，来自华盛顿都会区公共交通管理局（WMATA）。然后，我们使用这个数据集来训练和评估一个基于RoBERTa架构的语言模型。我们与键字基本架构和词汇表表示方法进行比较。我们的模型在所有评价指标上都高于这些方法，提供了90%的话题分类精度。最后，我们提供了这种工作的价值提案，说明如何使用语言模型， alongside其他文本处理工具，对开放式文本反馈 sources like Twitter进行结构化处理，以提高客户体验的理解和改进。我们的框架和结果提供了一种可扩展的自动化方法，可以在大规模的客户反馈数据中快速、自动地进行分类和报告，帮助机构更好地了解和改进客户体验。
</details></li>
</ul>
<hr>
<h2 id="AspectMMKG-A-Multi-modal-Knowledge-Graph-with-Aspect-aware-Entities"><a href="#AspectMMKG-A-Multi-modal-Knowledge-Graph-with-Aspect-aware-Entities" class="headerlink" title="AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities"></a>AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04992">http://arxiv.org/abs/2308.04992</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thezjd/aspectmmkg">https://github.com/thezjd/aspectmmkg</a></li>
<li>paper_authors: Jingdan Zhang, Jiaan Wang, Xiaodan Wang, Zhixu Li, Yanghua Xiao<br>for:这 paper 的目的是构建一个基于多modal数据的实体知识图(MMKG)，以便更全面地理解实体的多个方面。methods:这 paper 使用了一种新的方法，即匹配实体图像与不同的实体方面，以扩展现有的 MMKG。这种方法包括从知识库中收集方面相关的图像，并从知识库中提取方面相关的句子作为查询来 Retrieving a large number of aspect-related images via an online image search engine。results:这 paper constructed a new MMKG called AspectMMKG, which contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. 这 paper  также提出了一种新的实体方面相关图像检索(AIR)模型，可以更正和扩展 AspectMMKG 中的实体图像。这种模型通过将实体图像、实体方面和相关图像信息integrate into一个模型来学习实体图像与方面相关图像之间的关系。实验结果表明，AIR 模型可以为给定的实体 Retrieves suitable images for different aspects.<details>
<summary>Abstract</summary>
Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the research on aspect-related MMKG, we further propose an aspect-related image retrieval (AIR) model, that aims to correct and expand aspect-related images in AspectMMKG. We train an AIR model to learn the relationship between entity image and entity aspect-related images by incorporating entity image, aspect, and aspect image information. Experimental results indicate that the AIR model could retrieve suitable images for a given entity w.r.t different aspects.
</details>
<details>
<summary>摘要</summary>
多modal知识图（MMKG）结合不同模式数据（例如文本和图像）以实现实体的全面理解。虽然最近大规模的 MMKG 已经取得了进展，但现有 MMKG 忽视实体的多方面性，限制了从不同角度理解实体的能力。在本文中，我们构建了 AspectMMKG，首个基于实体方面的图像的 MMKG。具体来说，我们从知识库中收集了实体方面的图像，并从知识库中提取实体方面相关的句子作为查询来 retrieve 大量实体方面相关的图像 via 在线图像搜索引擎。最后，AspectMMKG 包含 2,380 个实体、18,139 个实体方面、645,383 个实体方面相关的图像。我们示出了 AspectMMKG 在实体方面链接（EAL）下游任务中的可用性，并证明了前一个 EAL 模型在 AspectMMKG 的帮助下实现了新的州OF-THE-ART 性能。为便于研究实体方面相关的 MMKG，我们还提出了一种实体方面相关的图像检索（AIR）模型，该模型 aimed 学习实体图像和实体方面相关图像之间的关系。我们在 AIR 模型中包含实体图像、实体方面和实体方面相关图像信息。实验结果表明，AIR 模型可以为给定实体 Retrieval 相关的图像。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Multilingual-Text-Data-Distillation"><a href="#Exploring-Multilingual-Text-Data-Distillation" class="headerlink" title="Exploring Multilingual Text Data Distillation"></a>Exploring Multilingual Text Data Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04982">http://arxiv.org/abs/2308.04982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harshp1802/text-dataset-distillation">https://github.com/harshp1802/text-dataset-distillation</a></li>
<li>paper_authors: Shivam Sahni, Harsh Patel</li>
<li>for: 这篇论文主要用于提出多语言文本分类数据簇范例的数据簇范例，并且运用语言模型学习方法来进行数据簇范例。</li>
<li>methods: 本文提出了多种文本数据簇范例的方法，包括语言模型基于学习方法，以及跨架构对应的数据簇范例。</li>
<li>results: 本文的实验结果显示，这些方法可以实现高度的分类强度，并且具有跨架构对应的数据簇范例能力。此外，本文也 investigate了这些方法对不同语言的公平性。<details>
<summary>Abstract</summary>
With the rise of deep learning, large datasets and complex models have become common, requiring significant computing power. To address this, data distillation has emerged as a technique to quickly train models with lower memory and time requirements. However, data distillation on text-based datasets hasn't been explored much because of the challenges rising due to its discrete nature. Additionally, existing dataset distillation methods often struggle to generalize to new architectures. In the paper, we propose several data distillation techniques for multilingual text classification datasets using language-model-based learning methods. We conduct experiments to analyze their performance in terms of classification strength, and cross-architecture generalization. Furthermore, we investigate the language-specific fairness of the data summaries generated by these methods. Our approach builds upon existing techniques, enhancing cross-architecture generalization in the text data distillation domain.
</details>
<details>
<summary>摘要</summary>
随着深度学习的出现，大量数据和复杂的模型变得普遍，需要大量的计算能力。为解决这问题，数据简化技术得到了广泛应用，但是在文本数据集上，数据简化技术尚未得到了充分的研究，这是因为文本数据的精度性带来了很多挑战。现有的数据简化方法通常难以泛化到新的架构上。在本文中，我们提出了一些基于语言模型学习方法的文本分类数据集简化技术。我们通过实验分析这些技术的分类强度和泛化性。此外，我们还研究了这些方法生成的语言特异性数据概要的公平性。我们的方法基于现有技术，提高了文本数据简化领域的跨架构泛化性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks"><a href="#Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks" class="headerlink" title="Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks"></a>Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04958">http://arxiv.org/abs/2308.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc W. Brittain, Luis E. Alvarez, Kara Breeden</li>
<li>for: 提供增加自动化运输的高效新交通方式，使用自动驾驶和电动飞机，提供未曾得到服务的市场。</li>
<li>methods: 使用分布式强化学习框架，解决自适应分离能力问题，使用速度和垂直动作实现安全自适应分离。</li>
<li>results: 通过实验研究，表明提议的框架可以在高密度、动态环境中保证安全高效的分离，并且比现有方法具有更高的训练样本通过率。<details>
<summary>Abstract</summary>
Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details>
<details>
<summary>摘要</summary>
高级空中流动（AAM）介入了一种新的、高效的交通方式，通过车辆自主和电动飞机提供前所未有的市场。在低空飞行的环境中保持安全和高效的导航需要融合多种复杂的观察，如抽象、车辆动力学和天气情况。这些观察的处理和理解受多种不确定性的影响，同时确保与变量数量的飞机在空间中协作。这些挑战，加上实时做出安全关键决策，排除了传统的分离保障技术的使用。我们提出了一种分布式学习框架，以提供自动化的自分配能力在AAM通道中。问题是表示为马尔可夫决策过程，通过开发一种新的、软 actor-critic（SAC）算法的扩展来解决。我们引入了注意网络来处理变量长度的观察，以及分布式计算架构，以实现高训练样本通过率比现有方法高。一项完整的数学研究表明，我们的框架可以在高密度、动态环境中保持安全和高效的飞机分离能力，并处理多种不确定性。
</details></li>
</ul>
<hr>
<h2 id="Wirelessly-Powered-Federated-Learning-Networks-Joint-Power-Transfer-Data-Sensing-Model-Training-and-Resource-Allocation"><a href="#Wirelessly-Powered-Federated-Learning-Networks-Joint-Power-Transfer-Data-Sensing-Model-Training-and-Resource-Allocation" class="headerlink" title="Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation"></a>Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04953">http://arxiv.org/abs/2308.04953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mai Le, Dinh Thai Hoang, Diep N. Nguyen, Won-Joo Hwang, Quoc-Viet Pham</li>
<li>for: 本研究旨在提出一种可持续的联合学习（FL）解决方案，以满足移动设备（MD）的能源限制和数据培养困难。</li>
<li>methods: 该研究提出了一种精简的计算效率算法，通过分解技术来解决联合学习（FL）网络中的资源分配问题，以最小化总完成时间。</li>
<li>results: 研究结果表明，提出的可持续联合学习（S2FL）算法可以减少完成时间，相比其他参考方案，可以减少21.45%。此外，研究还发现在非对抗多access（NOMA）下，可以提高总完成时间8.36%的平均值。<details>
<summary>Abstract</summary>
Federated learning (FL) has found many successes in wireless networks; however, the implementation of FL has been hindered by the energy limitation of mobile devices (MDs) and the availability of training data at MDs. How to integrate wireless power transfer and mobile crowdsensing towards sustainable FL solutions is a research topic entirely missing from the open literature. This work for the first time investigates a resource allocation problem in collaborative sensing-assisted sustainable FL (S2FL) networks with the goal of minimizing the total completion time. We investigate a practical harvesting-sensing-training-transmitting protocol in which energy-limited MDs first harvest energy from RF signals, use it to gain a reward for user participation, sense the training data from the environment, train the local models at MDs, and transmit the model updates to the server. The total completion time minimization problem of jointly optimizing power transfer, transmit power allocation, data sensing, bandwidth allocation, local model training, and data transmission is complicated due to the non-convex objective function, highly non-convex constraints, and strongly coupled variables. We propose a computationally-efficient path-following algorithm to obtain the optimal solution via the decomposition technique. In particular, inner convex approximations are developed for the resource allocation subproblem, and the subproblems are performed alternatively in an iterative fashion. Simulation results are provided to evaluate the effectiveness of the proposed S2FL algorithm in reducing the completion time up to 21.45% in comparison with other benchmark schemes. Further, we investigate an extension of our work from frequency division multiple access (FDMA) to non-orthogonal multiple access (NOMA) and show that NOMA can speed up the total completion time 8.36% on average of the considered FL system.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在无线网络中获得了许多成功;但是实现FL的实现受到移动设备（MD）的能源限制和训练数据的可用性所妨碍。如何整合无线电力转移和移动协同测量以实现可持续的FL解决方案，这是现有文献中没有研究的领域。本研究首次对联合测量助长的可持续FL网络（S2FL）进行了资源分配问题的研究，以最小化总完成时间。我们提出了一个实用的收数测量训练传输协议，在能源有限的MD上首先从RF信号中获取能量，用以获得用户参与的奖励，从环境中测量训练数据，在MD上训练本地模型，并将模型更新发送到服务器。总完成时间最小化问题是由于目标函数不对应、内部非拘束和变量之间强烈的相互关联，而变得困难。我们提出了一个可靠的 Computational Efficiency 的路径追踪算法，通过分解技术来取得最佳解。具体来说，我们在资源分配子问题上开发了内部凸approximation，并在迭代的方式下进行了资源分配子问题的解决。 simulation 结果显示，对于考虑的FL系统，我们的S2FL算法可以降低总完成时间21.45%。此外，我们将FDMA扩展到NOMA，并显示了NOMA可以将总完成时间提高8.36%的平均值。
</details></li>
</ul>
<hr>
<h2 id="Prototypical-Kernel-Learning-and-Open-set-Foreground-Perception-for-Generalized-Few-shot-Semantic-Segmentation"><a href="#Prototypical-Kernel-Learning-and-Open-set-Foreground-Perception-for-Generalized-Few-shot-Semantic-Segmentation" class="headerlink" title="Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation"></a>Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04952">http://arxiv.org/abs/2308.04952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Huang, Feigege Wang, Ye Xi, Yutao Gao</li>
<li>for: 这篇论文是为了扩展 few-shot semantic segmentation (FSS) 的研究，以便在评估时同时 segment unseen classes 和 seen classes。</li>
<li>methods: 该论文提出了一种joint prototypical kernel learning和开放集合前景感知的方法，以解决 representation division 和 embedding prejudice 等问题。具体来说，每个 learnable kernel 负责一个 stuff class，然后 merge 了 prototypical learning 到基类 kernel 的更新中，以保持prototype knowledge aggregation of few-shot novel classes。此外，还采用了一个 class-agnostic 和 open-set foreground detection 模块，以减少 embedding prejudice 并避免 novel targets 被误分类为背景。</li>
<li>results: 在 PASCAL-5i 和 COCO-20i 数据集上进行了广泛的实验，并证明了我们的方法在 previous state-of-the-art 之上表现更好。<details>
<summary>Abstract</summary>
Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic Segmentation (FSS) to simultaneously segment unseen classes and seen classes during evaluation. Previous works leverage additional branch or prototypical aggregation to eliminate the constrained setting of FSS. However, representation division and embedding prejudice, which heavily results in poor performance of GFSS, have not been synthetical considered. We address the aforementioned problems by jointing the prototypical kernel learning and open-set foreground perception. Specifically, a group of learnable kernels is proposed to perform segmentation with each kernel in charge of a stuff class. Then, we explore to merge the prototypical learning to the update of base-class kernels, which is consistent with the prototype knowledge aggregation of few-shot novel classes. In addition, a foreground contextual perception module cooperating with conditional bias based inference is adopted to perform class-agnostic as well as open-set foreground detection, thus to mitigate the embedding prejudice and prevent novel targets from being misclassified as background. Moreover, we also adjust our method to the Class Incremental Few-shot Semantic Segmentation (CIFSS) which takes the knowledge of novel classes in a incremental stream. Extensive experiments on PASCAL-5i and COCO-20i datasets demonstrate that our method performs better than previous state-of-the-art.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Variations-on-the-Reinforcement-Learning-performance-of-Blackjack"><a href="#Variations-on-the-Reinforcement-Learning-performance-of-Blackjack" class="headerlink" title="Variations on the Reinforcement Learning performance of Blackjack"></a>Variations on the Reinforcement Learning performance of Blackjack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07329">http://arxiv.org/abs/2308.07329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack">https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack</a></li>
<li>paper_authors: Avish Buramdoyal, Tim Gebbie</li>
<li>for: The paper is written to explore the impact of deck size on the convergence of q-learning algorithms in the context of blackjack.</li>
<li>methods: The paper uses a q-learning solution for optimal play in blackjack, and investigates the rate of learning convergence as a function of deck size.</li>
<li>results: The paper shows that a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy, and that environment variations have a significant impact on this outcome.Here are the three points in Simplified Chinese:</li>
<li>for: 这篇论文是为了研究黑Jackson游戏中q学习算法的 converges 问题而写的。</li>
<li>methods: 这篇论文使用了黑Jackson游戏中的q学习解决方案，并 Investigates 学习速度的变化与扑克牌 deck size 的关系。</li>
<li>results: 这篇论文显示，一个 perfectly 使用基本策略和 hi-lo 系统的 card counter 可以使酒店破产，并且环境变化会对这个结果产生很大的影响。<details>
<summary>Abstract</summary>
Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.
</details>
<details>
<summary>摘要</summary>
黑Jack或"21"是一款流行的 кар牌游戏，旨在通过获得手牌总数高于供应者的手牌总数而赢得比赛，而不超过21。理想的黑Jack策略可以在长期内最大化金钱收益，同时避免投资者的破产。黑Jack的 Stochastic 环境和内在的奖励结构，使得黑Jack 在变化的环境中的研究非常有吸引力。在这里，我们考虑了 q-learning 方法来实现最佳策略，并研究了算法的学习速率是否与扑克牌deck大小相关。我们还实现了一个支持通用黑Jack规则的黑Jack模拟器，以示出一个基本策略和高低系统的卡计数员可以使得供应者铺垮，以及环境变化对这个结果的影响。我们的作品之处在于将这些概念理解与学习代理人快速学习的关系。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey"><a href="#Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey" class="headerlink" title="Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey"></a>Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04947">http://arxiv.org/abs/2308.04947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Wang, Jiawei Li, Lifan Zhao, Zhizhuo Kou, Xiaohan Wang, Xinyi Zhu, Hao Wang, Yanyan Shen, Lei Chen</li>
<li>for: This paper aims to provide a systematic and comprehensive overview of methods for incorporating external knowledge into stock price prediction models, including the acquisition of external knowledge from various unstructured data sources and fusion methods for combining external knowledge with historical price features.</li>
<li>methods: The paper covers various methods for acquiring external knowledge, including non-graph-based and graph-based knowledge representations, and explores fusion methods for combining external knowledge with historical price features.</li>
<li>results: The paper includes a compilation of relevant datasets and discusses potential future research directions in this domain.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在系统地探讨External Knowledge在股票价格预测模型中的应用，包括从多种不结构化数据源获取External Knowledge以及将External Knowledge与历史价格特征进行融合。</li>
<li>methods: 论文涵盖了不同类型的External Knowledge获取方法，包括非图structured和图structured知识表示方法，以及将External Knowledge与历史价格特征进行融合的方法。</li>
<li>results: 论文收录了相关的数据集，并讨论了未来在这个领域的可能的研究方向。<details>
<summary>Abstract</summary>
Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
预测股票价格是一个复杂的研究问题，因为股票市场本身具有不确定性和非线性。在过去几年，带有知识的股票价格预测方法已经显示出了创新的成果，通过利用外部知识来理解股票市场。尽管这些方法的重要性，但是学术研究中对外部知识类型的系统化synthesis却相对罕见。特别是，外部知识可以通过不同的数据结构来表示，我们将其分为非图形化格式和图形化格式：1）非图形化知识捕捉特定股票的上下文信息和 multimedia描述; 2）图形化知识捕捉股票市场中的相互连接和相互依赖信息。本文旨在提供一个系统性和全面的描述，涵盖从不同的不结构化数据源中获取外部知识，并将其与历史价格特征合并。此外，本文还探讨了外部知识与历史价格特征的融合方法，以及相关数据集和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="LLMeBench-A-Flexible-Framework-for-Accelerating-LLMs-Benchmarking"><a href="#LLMeBench-A-Flexible-Framework-for-Accelerating-LLMs-Benchmarking" class="headerlink" title="LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking"></a>LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04945">http://arxiv.org/abs/2308.04945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qcri/llmebench">https://github.com/qcri/llmebench</a></li>
<li>paper_authors: Fahim Dalvi, Maram Hasanain, Sabri Boughorbel, Basel Mousi, Samir Abdaljalil, Nizi Nazar, Ahmed Abdelali, Shammur Absar Chowdhury, Hamdy Mubarak, Ahmed Ali, Majd Hawasly, Nadir Durrani, Firoj Alam</li>
<li>for: 评估大语言模型（LLMs）在不同语言的不同NLP任务中的性能。</li>
<li>methods: 提出了 LLMeBench 框架，可以轻松地自定义为特定任务和数据集，并支持零或几shot学习设定。</li>
<li>results: 在 31 个Unique NLP任务和 53 个公共数据集中进行了约 296K 个实验设定，以评估框架的性能。<details>
<summary>Abstract</summary>
The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language. The framework also features zero- and few-shot learning settings. A new custom dataset can be added in less than 10 minutes, and users can use their own model API keys to evaluate the task at hand. The developed framework has been already tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We plan to open-source the framework for the community (https://github.com/qcri/LLMeBench/). A video demonstrating the framework is available online (https://youtu.be/FkQn4UjYA0s).
</details>
<details>
<summary>摘要</summary>
The LLMeBench framework is highly customizable and can be easily adapted for any NLP task and model, regardless of language. It also supports zero- and few-shot learning settings, allowing users to evaluate their tasks with minimal data. Adding a new custom dataset to the framework takes less than 10 minutes, and users can use their own model API keys to evaluate the task at hand.We have tested the LLMeBench framework on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. The framework is set to be open-sourced for the community, and a video demonstrating its capabilities is available online (https://youtu.be/FkQn4UjYA0s).
</details></li>
</ul>
<hr>
<h2 id="Gaussian-Image-Anomaly-Detection-with-Greedy-Eigencomponent-Selection"><a href="#Gaussian-Image-Anomaly-Detection-with-Greedy-Eigencomponent-Selection" class="headerlink" title="Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection"></a>Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04944">http://arxiv.org/abs/2308.04944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tetiana Gula, João P C Bertoldo<br>for: 本文旨在提出一种新的维度减少方法，用于图像异常检测（AD），通过使用预训练的卷积神经网络（CNN）和高效率的EfficientNet模型。methods: 本文使用两种类型的树搜索方法，即搜索最佳准则和最佳词汇搜索，以选择最佳的 eigencomponent。同时，我们也进行了三个主要的实验来评估方法的效果，包括测试集的影响、一种异常类型的训练和所有其他类型的评估、以及使用最小数量的图像进行训练和选择。results: 我们的方法在检测精度方面胜过了PCA和NPCA，即使使用 fewer components。这表明，我们的方法可以提供一种有效的维度减少方法，并且可以增强图像异常检测系统的效率和精度。<details>
<summary>Abstract</summary>
Anomaly detection (AD) in images, identifying significant deviations from normality, is a critical issue in computer vision. This paper introduces a novel approach to dimensionality reduction for AD using pre-trained convolutional neural network (CNN) that incorporate EfficientNet models. We investigate the importance of component selection and propose two types of tree search approaches, both employing a greedy strategy, for optimal eigencomponent selection. Our study conducts three main experiments to evaluate the effectiveness of our approach. The first experiment explores the influence of test set performance on component choice, the second experiment examines the performance when we train on one anomaly type and evaluate on all other types, and the third experiment investigates the impact of using a minimum number of images for training and selecting them based on anomaly types. Our approach aims to find the optimal subset of components that deliver the highest performance score, instead of focusing solely on the proportion of variance explained by each component and also understand the components behaviour in different settings. Our results indicate that the proposed method surpasses both Principal Component Analysis (PCA) and Negated Principal Component Analysis (NPCA) in terms of detection accuracy, even when using fewer components. Thus, our approach provides a promising alternative to conventional dimensionality reduction techniques in AD, and holds potential to enhance the efficiency and effectiveness of AD systems.
</details>
<details>
<summary>摘要</summary>
“问题检测（AD）在图像中，找到重要的异常，是计算机视觉中的关键问题。这篇论文介绍了一种新的维度减少方法，使用预训练的卷积神经网络（CNN）和EfficientNet模型。我们研究了选择组件的重要性，并提出了两种树搜索方法，都采用了聪明策略，以便选择最佳的组件。我们的研究进行了三项主要实验，以评估我们的方法的效果。第一项实验研究了测试集的影响因素，第二项实验验证了我们在一种异常类型上训练，然后在所有其他异常类型上进行评估，第三项实验研究了使用最少数量的图像进行训练和选择，并根据异常类型来选择图像。我们的方法旨在找到最佳的组件子集，而不是围绕每个组件的解释度量进行围绕。我们的结果表明，我们的方法在检测精度方面比PCA和NPCA高，即使使用 fewer components。因此，我们的方法提供了一种可靠的替代方法，可以增强AD系统的效率和效果。”
</details></li>
</ul>
<hr>
<h2 id="Semantic-Communications-for-Artificial-Intelligence-Generated-Content-AIGC-Toward-Effective-Content-Creation"><a href="#Semantic-Communications-for-Artificial-Intelligence-Generated-Content-AIGC-Toward-Effective-Content-Creation" class="headerlink" title="Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation"></a>Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04942">http://arxiv.org/abs/2308.04942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyuan Liu, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, Xuemin, Shen</li>
<li>For: This paper aims to develop a comprehensive conceptual model for integrating Artificial Intelligence Generated Content (AIGC) and Semantic Communication (SemCom), and to propose a novel framework for generating meaningful and effective content using AIGC technology.* Methods: The paper employs a novel framework that uses AIGC technology as an encoder and decoder for semantic information, and jointly optimizes semantic extraction and evaluation metrics tailored to AIGC services. The framework is adaptable to different types of content generated, the required quality, and the semantic information utilized.* Results: The paper presents a case study using a Deep Q Network (DQN) to demonstrate the feasibility of the optimization problem and its convergence characteristics. The study provides useful insights into the effectiveness of the proposed framework for generating meaningful and effective content using AIGC technology.<details>
<summary>Abstract</summary>
Artificial Intelligence Generated Content (AIGC) Services have significant potential in digital content creation. The distinctive abilities of AIGC, such as content generation based on minimal input, hold huge potential, especially when integrating with semantic communication (SemCom). In this paper, a novel comprehensive conceptual model for the integration of AIGC and SemCom is developed. Particularly, a content generation level is introduced on top of the semantic level that provides a clear outline of how AIGC and SemCom interact with each other to produce meaningful and effective content. Moreover, a novel framework that employs AIGC technology is proposed as an encoder and decoder for semantic information, considering the joint optimization of semantic extraction and evaluation metrics tailored to AIGC services. The framework can adapt to different types of content generated, the required quality, and the semantic information utilized. By employing a Deep Q Network (DQN), a case study is presented that provides useful insights into the feasibility of the optimization problem and its convergence characteristics.
</details>
<details>
<summary>摘要</summary>
人工智能生成内容（AIGC）服务具有很大的潜力在数字内容创造中。AIGC的特殊能力，如基于最小输入的内容生成，在整合 semantic communication（SemCom）时表现出巨大的潜力，尤其是在生成有意义和有效的内容方面。在这篇论文中，我们提出了一种新的全面概念模型，用于AIGC和SemCom的整合。具体来说，我们在 semantic 层次上引入了内容生成级别，以便清晰地描述AIGC和SemCom之间的交互方式，并生成有意义和有效的内容。此外，我们提议了一种基于 AIGC 技术的核心架构，用于SemCom 的编解码器，并考虑了对 AIGC 服务的 JOINT 优化。这种框架可以适应不同类型的内容生成、需要的质量和使用的semantic信息。通过使用深度感知网络（DQN），我们在这种优化问题上提供了有用的洞察和其叠合特性。
</details></li>
</ul>
<hr>
<h2 id="An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning"><a href="#An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning"></a>An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04938">http://arxiv.org/abs/2308.04938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究的目的是比较各种常见的精简方法，以及一种新的方法，在多智能 reinforcement learning 中实现有效的通信学习。</li>
<li>methods: 本研究使用了多种常见的精简方法，包括 DIAL、COMA 等方法，以及一种新的方法（ST-DRU）。</li>
<li>results: 研究发现，ST-DRU 方法在不同环境中的表现最佳，其在每个实验中都达到了或超过了其他方法的最佳性能，而且不会在任何环境中失败。<details>
<summary>Abstract</summary>
Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通信是多智能代理学习中关键的一部分，当代理不能观察环境的全部状态时。最常见的解决方案是使用可导通信通道，让代理之间的反馈通过梯度流动。然而，当使用整数消息时，梯度无法流动，这引发了一些问题。先前的研究已经提出了解决方案，但是这些方法在不同的通信学习架构和环境中进行测试，使得比较困难。本文比较了多种当前领先的整数化方法，以及一种新的方法。我们在通信学习中使用其他代理的梯度进行学习，并在多个环境中进行测试。此外，我们还提出了 COMA-DIAL，一种基于 DIAL 和 COMA 的通信学习方法，其中包括学习速率缩放和适应exploration。使用 COMA-DIAL 让我们在更复杂的环境中进行实验。我们的结果表明，本文所提出的新方法 ST-DRU，在不同环境中的所有实验中均达到了最佳result。它在每个实验中达到了最佳或接近最佳性能，并且是唯一不会在任何测试环境中失败的方法。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Service-Reservation-and-Pricing-for-Green-Metaverses-A-Stackelberg-Game-Approach"><a href="#Service-Reservation-and-Pricing-for-Green-Metaverses-A-Stackelberg-Game-Approach" class="headerlink" title="Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach"></a>Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04914">http://arxiv.org/abs/2308.04914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xumin Huang, Yuan Wu, Jiawen Kang, Jiangtian Nie, Weifeng Zhong, Dong In Kim, Shengli Xie</li>
<li>for:  Metaverse服务提供商（MSP）为了实现绿色可持续的Metaverse，通过在协同层次上执行软件组件来减少重复数据传输和处理，从而减少总能 consumption。</li>
<li>methods: 本文使用了一个增强现实（AR）应用程序作为示例，并研究了用户如何向MSP申请卸载服务和MSP如何确定最佳费用标准，以确保用户具有最佳的经济效益。</li>
<li>results:  compared with传统方案，我们的方案可以同时实现能源减少和个人合理性，并且可以满足用户的经济需求。此外，我们还提出了如何通过结合多种新技术实现可持续的绿色Metaverse。<details>
<summary>Abstract</summary>
Metaverse enables users to communicate, collaborate and socialize with each other through their digital avatars. Due to the spatio-temporal characteristics, co-located users are served well by performing their software components in a collaborative manner such that a Metaverse service provider (MSP) eliminates redundant data transmission and processing, ultimately reducing the total energy consumption. The energyefficient service provision is crucial for enabling the green and sustainable Metaverse. In this article, we take an augmented reality (AR) application as an example to achieve this goal. Moreover, we study an economic issue on how the users reserve offloading services from the MSP and how the MSP determines an optimal charging price since each user is rational to decide whether to accept the offloading service by taking into account the monetary cost. A single-leader multi-follower Stackelberg game is formulated between the MSP and users while each user optimizes an offloading probability to minimize the weighted sum of time, energy consumption and monetary cost. Numerical results show that our scheme achieves energy savings and satisfies individual rationality simultaneously compared with the conventional schemes. Finally, we identify and discuss open directions on how several emerging technologies are combined with the sustainable green Metaverse.
</details>
<details>
<summary>摘要</summary>
Metaverse 允许用户通过数字化的人物进行交流、合作和社交交流。由于空间 temporal 特点，用户在同一个地点时，Metaverse 服务提供商 (MSP) 可以减少重复的数据传输和处理，最终减少总能 consumption。这种能源efficient的服务提供是metaverse 的关键，以实现绿色可持续的Metaverse。在这篇文章中，我们使用了一个扩展现实 (AR) 应用程序作为例子，以实现这个目标。此外，我们还研究了用户向 MSP 积分服务的协议和 MSP 如何确定最佳的收费 Price，因为每个用户都是合理的决定是否接受协议，考虑到经济成本。在这个框架中，MSP 是一个领导者，而用户是多个追随者。每个用户都是最小化时间、能源消耗和经济成本的权重和总和。numerical 结果表明，我们的方案可以同时实现能源减少和个人合理性。最后，我们还讨论了一些新兴技术如何与可持续的绿色Metaverse 结合。
</details></li>
</ul>
<hr>
<h2 id="LLaMA-E-Empowering-E-commerce-Authoring-with-Multi-Aspect-Instruction-Following"><a href="#LLaMA-E-Empowering-E-commerce-Authoring-with-Multi-Aspect-Instruction-Following" class="headerlink" title="LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following"></a>LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04913">http://arxiv.org/abs/2308.04913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaize Shi, Xueyao Sun, Dingxian Wang, Yinlin Fu, Guandong Xu, Qing Li<br>methods: 这篇论文使用了专门的执行 instruction-following 语言模型（LLaMA-E），并将它们训练在多种电商创作任务中，包括广告生成、产品标题修改、产品分类、购买意愿预测和通用问答等。results: 这篇论文的实验结果显示，提案的 LLaMA-E 模型在量和质量评估中均取得了顶尖的结果，并在零执行场景中表现出优势。此外，这篇论文还发现 LLMA-E 模型可以对电商内容创作问题进行优化解决。<details>
<summary>Abstract</summary>
E-commerce authoring involves creating attractive, abundant, and targeted promotional content to drive product sales. The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario. However, mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission. This paper proposes the LLaMA-E, the unified and customized instruction-following language models focusing on diverse e-commerce authoring tasks. Specifically, the domain experts create the seed instruction set from the tasks of ads generation, query-enhanced product title rewriting, product classification, purchase intent speculation, and general Q&A. These tasks enable the models to comprehensively understand precise e-commerce authoring knowledge by interleaving features covering typical service aspects of customers, sellers, and platforms. The GPT-3.5 is introduced as a teacher model, which expands the seed instructions to form a training set for the LLaMA-E models with various scales. The experimental results show that the proposed LLaMA-E models achieve state-of-the-art results in quantitative and qualitative evaluations, also exhibiting the advantage in zero-shot scenes. To the best of our knowledge, this study is the first to serve the LLMs to specific e-commerce authoring scenarios.
</details>
<details>
<summary>摘要</summary>
电商作者需创建吸引人、丰富、有目标的推广内容，以促进产品销售。大语言模型（LLM）的出现提供了一种创新的解决方案，可以同时解决多种作者任务。然而，主流的LLM通常由通用文献训练，对电商产品和客户特有的复杂和个性化特征表现出限制。此外，LLM如GPT-3.5需要远程访问，可能会使客户隐私数据泄露。本文提议了LLaMA-E，一种特定于电商作者任务的一体化和个性化语言模型。具体来说，域专家会根据广告生成、产品标题重写、产品分类、购买意愿预测和通用问答等任务，创建种子指令集。这些任务使模型能够全面地理解电商作者的精准知识，覆盖客户、卖家和平台的典型服务方面。GPT-3.5被用作教学模型，将种子指令扩展成训练集，以形成不同规模的LLaMA-E模型。实验结果表明，提议的LLaMA-E模型在量和质量评价中具有国际最佳效果，同时在零容量场景中也表现出优势。到目前为止，这是电商作者scenario中LLM的首次应用。
</details></li>
</ul>
<hr>
<h2 id="SLPT-Selective-Labeling-Meets-Prompt-Tuning-on-Label-Limited-Lesion-Segmentation"><a href="#SLPT-Selective-Labeling-Meets-Prompt-Tuning-on-Label-Limited-Lesion-Segmentation" class="headerlink" title="SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation"></a>SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04911">http://arxiv.org/abs/2308.04911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Bai, Ke Yan, Xiaoyu Bai, Xinyu Mao, Xiaoli Yin, Jingren Zhou, Yu Shi, Le Lu, Max Q. -H. Meng</li>
<li>for: 这个研究旨在提高医学图像分析中使用深度学习的性能，减少 labels 的成本和增加准确性。</li>
<li>methods: 这个方法使用提前训练的模型，并在限制labels的情况下进行微调。它还使用选择性标签，将最有价的下游标签选择出来，以获得最佳性能。</li>
<li>results: 这个研究在肝癌分 segmentation 中实现了国际级的性能，只需要6%的弹性参数，并且可以在5%的标签数量下 достиieving 94%的全资料性能。<details>
<summary>Abstract</summary>
Medical image analysis using deep learning is often challenged by limited labeled data and high annotation costs. Fine-tuning the entire network in label-limited scenarios can lead to overfitting and suboptimal performance. Recently, prompt tuning has emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and supervised selection using prompt-based uncertainty. In addition, we propose a diversified visual prompt tuning strategy to provide multi-prompt-based discrepant predictions for TESLA. We evaluate our method on liver tumor segmentation and achieve state-of-the-art performance, outperforming traditional fine-tuning with only 6% of tunable parameters, also achieving 94% of full-data performance by labeling only 5% of the data.
</details>
<details>
<summary>摘要</summary>
医疗图像分析使用深度学习经常受到有限的标注数据和高标注成本的挑战。 fine-tuning整个网络在标注有限的场景下可能导致逗减和下标性性能。Recently, prompt tuning  emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and supervised selection using prompt-based uncertainty. In addition, we propose a diversified visual prompt tuning strategy to provide multi-prompt-based discrepant predictions for TESLA. We evaluate our method on liver tumor segmentation and achieve state-of-the-art performance, outperforming traditional fine-tuning with only 6% of tunable parameters, also achieving 94% of full-data performance by labeling only 5% of the data.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Deep-Reinforcement-Learning-for-Cyber-Security-in-Software-Defined-Networks"><a href="#Adversarial-Deep-Reinforcement-Learning-for-Cyber-Security-in-Software-Defined-Networks" class="headerlink" title="Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks"></a>Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04909">http://arxiv.org/abs/2308.04909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Borchjes, Clement Nyirenda, Louise Leenen</li>
<li>For: The paper explores the impact of adversarial learning in Deep Reinforcement Learning (DRL) for autonomous security in Software Defined Networks (SDN).* Methods: The paper compares two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), and evaluates their performance under a white-box setting with a causative attack.* Results: The paper shows that with minute parameter changes, the algorithms are still able to defend the network, and the introduction of the causative attack improves the attacker’s performance.<details>
<summary>Abstract</summary>
This paper focuses on the impact of leveraging autonomous offensive approaches in Deep Reinforcement Learning (DRL) to train more robust agents by exploring the impact of applying adversarial learning to DRL for autonomous security in Software Defined Networks (SDN). Two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), are compared. NEC2DQN was proposed in 2018 and is a new member of the deep q-network (DQN) family of algorithms. The attacker has full observability of the environment and access to a causative attack that uses state manipulation in an attempt to poison the learning process. The implementation of the attack is done under a white-box setting, in which the attacker has access to the defender's model and experiences. Two games are played; in the first game, DDQN is a defender and N2D is an attacker, and in second game, the roles are reversed. The games are played twice; first, without an active causative attack and secondly, with an active causative attack. For execution, three sets of game results are recorded in which a single set consists of 10 game runs. The before and after results are then compared in order to see if there was actually an improvement or degradation. The results show that with minute parameter changes made to the algorithms, there was growth in the attacker's role, since it is able to win games. Implementation of the adversarial learning by the introduction of the causative attack showed the algorithms are still able to defend the network according to their strengths.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文研究了利用深度强化学习（DRL）中的自主攻击方法来训练更加鲜硬的代理人，并通过对DRL的自主安全性进行抗击学习来强化网络的自主安全性。研究比较了两种算法，Double Deep Q-Networks（DDQN）和Neural Episodic Control to Deep Q-Network（NEC2DQN或N2D），在面临 causative 攻击时的防御能力。攻击者具有环境的全观察权和对 defendere 的模型和经验的访问权。在一个白盒Setting下，攻击者通过 state  manipulate 来尝试毒害学习过程。两个游戏被玩了两次，一次没有活动 causative 攻击，第二次有活动 causative 攻击。每个游戏被玩了十次。前后结果被记录下来，并进行比较，以确定是否有改进或退化。结果显示，通过微调算法的参数，攻击者能够赢得游戏。对于 causative 攻击的引入，算法仍然能够防御网络，根据其优势。
</details></li>
</ul>
<hr>
<h2 id="GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters"><a href="#GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters" class="headerlink" title="GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters"></a>GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04905">http://arxiv.org/abs/2308.04905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, José Suárez-Varela, Xiang Shi, Shihan Xiao, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio</li>
<li>for: 提高数据中心网络（DCN）的流量优化</li>
<li>methods: 使用机器学习（ML）和图神经网络（GNN）实现分布式agent在交换机上协同优化ECN配置</li>
<li>results: 在多种场景下测试和比较GraphCC和ACC两种解决方案，结果显示GraphCC在所有评价场景中表现出色，与ACC比较而言，GraphCC在流程完成时间和缓存占用率方面具有显著的改善($20%$ 的提高和$38.0-85.7%$ 的减少)。<details>
<summary>Abstract</summary>
Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN), and it is compatible with widely deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches that communicate with their neighbors to cooperate and optimize the global ECN configuration. In our evaluation, we test the performance of GraphCC under a wide variety of scenarios, focusing on the capability of this solution to adapt to new scenarios unseen during training (e.g., new traffic workloads, failures, upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for ECN tuning -- ACC -- and observe that our proposed solution outperforms the state-of-the-art baseline in all of the evaluation scenarios, showing improvements up to $20\%$ in Flow Completion Time as well as significant reductions in buffer occupancy ($38.0-85.7\%$).
</details>
<details>
<summary>摘要</summary>
压力控制（CC）在数据中心网络（DCN）中扮演了基本角色，以优化流量。目前，DCNs主要实施了两种主要的CC协议：DCTCP和DCQCN。这两种协议都基于显式拥堵通知（ECN）， intermediate switches 将包 WHEN 检测拥堵。因此，ECN配置成为了CC协议性能的关键因素。当前，网络专家通过精心选择ECN参数来优化平均网络性能。然而，今天的高速DCNs在快速和突然变化的网络状态下经历了差不多的性能下降。这导致了下Utilization和不佳的性能。本文介绍了一种基于机器学习的GraphCC框架，用于在网络中进行CC优化。我们的分布式解决方案基于多代理循环学习（MARL）和图神经网络（GNN）的新组合，与广泛部署的ECN基于CC协议相容。GraphCC在 switches 上部署分布式代理，与相邻的 switches 进行交互，以便协调和优化全局ECN配置。在我们的评估中，我们测试了GraphCC在多种场景下的性能，特别是它在新的场景下（例如新的流量工作负荷、故障、升级）进行适应性的能力。我们将GraphCC与一种基于MARL的ECN调试解决方案——ACC进行比较，并发现我们的提议方案在所有评估场景中都高于基线，显示改进流程完成时间（$20\%$）以及重要减少缓冲占用（$38.0-85.7\%$）。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients"><a href="#Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients" class="headerlink" title="Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients"></a>Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05765">http://arxiv.org/abs/2308.05765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mouli Bardhan Paul Angon</li>
<li>for: 预测心衰竭患者生存率，以便早期干预并改善患者结果。</li>
<li>methods: 利用数据处理技术和Extra-Tree（ET）特征选择方法，并与Random Forest（RF）分类器结合，以提高心衰竭患者生存预测精度。</li>
<li>results: 通过ET特征选择算法确定最重要的预测器，并使用网格搜索法进行RF模型的优化，实现了98.33%的准确率，至今为最高的成果。<details>
<summary>Abstract</summary>
Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种生命威胁性的疾病，影响全球数百万人。可以准确预测患者存活的能力可以帮助早期干预，提高患者结果。在这项研究中，我们探讨了使用数据处理技术和EXTRA-TREE（ET）特征选择方法，与Random Forest（RF）分类器结合以提高心力衰竭患者存活预测。通过利用ET特征选择算法的优势，我们希望可以确定心力衰竭存活的最重要预测因素。使用公共的UCL心力衰竭（HF）存活数据集，我们采用ET特征选择算法确定最有用的特征。这些特征然后作为RF模型的输入，进行了网格搜索。最后，通过不同矩阵的训练和评估，我们实现了98.33%的准确率，这是已有工作中最高的成绩。
</details></li>
</ul>
<hr>
<h2 id="Learning-Type-Generalized-Actions-for-Symbolic-Planning"><a href="#Learning-Type-Generalized-Actions-for-Symbolic-Planning" class="headerlink" title="Learning Type-Generalized Actions for Symbolic Planning"></a>Learning Type-Generalized Actions for Symbolic Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04867">http://arxiv.org/abs/2308.04867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Tanneberg, Michael Gienger</li>
<li>for: 解决复杂任务，需要长序列的动作和智能代理人的复杂行为。</li>
<li>methods: 使用符号规划技术，使用给定实体层次结构和观察到的类似行为来泛化符号动作。</li>
<li>results: 在模拟的网格式厨房环境中，通过几个观察学习，可以学习和泛化类型总结，解决未经见过的任务组合、新的实体和不预期的环境行为。<details>
<summary>Abstract</summary>
Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior, can be solved.
</details>
<details>
<summary>摘要</summary>
symbolic 规划是一种强大的技术，可以解决复杂的任务，需要长串动作，并具备复杂的行为。但是，这种方法的缺点是需要适当的符号表示，描述环境状态以及可以改变它的行动。传统上，这些表示是由专家手动设计，限制了它们在不同问题领域的传输性。在这篇论文中，我们提出了一种新的概念，使用给定的实体层次结构和观察到的相似行为来泛化符号行动。在一个模拟的网格式厨房环境中，我们示出了通过几次观察学习，可以将类型泛化行动应用于新的情况。在规划过程中，附加了一种在线泛化机制，可以解决未看过的任务组合，包括更长的序列，新的实体和意外的环境行为。
</details></li>
</ul>
<hr>
<h2 id="Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning"><a href="#Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning"></a>Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04844">http://arxiv.org/abs/2308.04844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Thomas Somers, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究旨在 investigating the effect of increasing the amount of information in multi-agent communication messages and the number of agents on the performance of the system.</li>
<li>methods: 本研究使用 multi-agent reinforcement learning 技术，并 comparison of two message encoding methods: mean message encoder 和 attention message encoder.</li>
<li>results:  surprisingly, 我们发现 mean message encoder 在所有情况下表现出色，而 attention message encoder 则表现较差。 进一步分析发现，使用 mean message encoder 的 agent 使用一种组合函数，包括对数和对数函数，来确保重要信息不会在传输过程中丢失。<details>
<summary>Abstract</summary>
Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.
</details>
<details>
<summary>摘要</summary>
多个Agent系统需要间 Agent communication来实现目标。通过使用多 Agent reinforcement learning技术学习交流协议和行为协议，代理人获得了自定义信息共享的灵活性。然而，当代理人数量增加时，我们需要创建消息中信息的编码方式。在这篇论文中，我们研究了增加消息中信息量和代理人数量的效果，并对两种消息编码方法进行评估：mean message encoder和attention message encoder。我们在矩阵环境中进行了实验，结果显示mean message encoder在所有情况下表现出优于attention message encoder。因此，我们分析了使用mean message encoder的交流协议，并确定代理人使用权重函数和幂函数在其交流策略中，以避免信息损失。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI"><a href="#Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI" class="headerlink" title="Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI"></a>Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05764">http://arxiv.org/abs/2308.05764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oetu/mmcl-ecg-cmr">https://github.com/oetu/mmcl-ecg-cmr</a></li>
<li>paper_authors: Özgün Turgut, Philip Müller, Paul Hager, Suprosanna Shit, Sophie Starck, Martin J. Menten, Eimo Martens, Daniel Rueckert<br>for:本研究的目的是使用自适应对比学习技术，将心脏磁共振成像（CMR）图像中封闭的域特征传递到电cardiogram（ECG）中，以提高心血管疾病诊断的效率和准确性。methods:本研究使用了多模态对比学习和伪数据模型，将CMR图像中的域特征与ECG数据进行对比，以学习ECG中含有的域特征。results:研究结果表明，通过使用自适应对比学习技术，可以从ECG数据中提取出各种心血管疾病的风险和各种心脏现象的信息。此外，研究还发现了ECG中含有CMR图像中封闭的域特征。<details>
<summary>Abstract</summary>
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from ECG data. In a qualitative analysis, we demonstrate that our learned ECG embeddings incorporate information from CMR image regions of interest. We make our entire pipeline publicly available, including the source code and pre-trained model weights.
</details>
<details>
<summary>摘要</summary>
电rokardiogram (ECG) 是一种广泛可用的诊断工具，可以快速和效果地评估心血管健康。然而，更详细的检查通常使用昂贵的心血管磁共振 (CMR) 成像，以诊断心血管疾病。虽然可以提供详细的卡ди亚解剖结构，但CMR成像不够普遍使用，因为扫描时间长和成本高。为解决这个问题，我们提出了首个自动supervised contrastiveapproach，可以从CMR图像中传递域特定信息到ECG嵌入。我们的方法结合多modal contrastive学习和masked数据模型，以实现从ECG数据中进行全面的心血管检查。在使用40044名UK Biobank参与者的数据进行广泛的实验中，我们证明了我们的方法的实用性和普遍性。我们预测参与者的具体风险以及不同心血管疾病的各种疾病。在质量分析中，我们示出了我们学习的ECG嵌入包含CMR图像区域兴趣的信息。我们将整个管道公开发布，包括源代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="On-the-Unexpected-Abilities-of-Large-Language-Models"><a href="#On-the-Unexpected-Abilities-of-Large-Language-Models" class="headerlink" title="On the Unexpected Abilities of Large Language Models"></a>On the Unexpected Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09720">http://arxiv.org/abs/2308.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Nolfi</li>
<li>for: 这篇论文主要是关于大语言模型的研究，具体来说是研究这些模型如何通过 indirect acquisition 方式来获得各种能力。</li>
<li>methods: 这篇论文使用了各种 indirect acquisition 方法，包括 predicting the next words of human-written texts，来研究大语言模型的能力。</li>
<li>results: 研究发现，大语言模型通过 indirect acquisition 方式可以获得各种 интегрирован的能力，包括语言理解和生成能力。此外，这些系统还可以通过自我改进来提高自己的能力。<details>
<summary>Abstract</summary>
Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Neuro-Symbolic-RDF-and-Description-Logic-Reasoners-The-State-Of-The-Art-and-Challenges"><a href="#Neuro-Symbolic-RDF-and-Description-Logic-Reasoners-The-State-Of-The-Art-and-Challenges" class="headerlink" title="Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges"></a>Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04814">http://arxiv.org/abs/2308.04814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gunjan Singh, Sumit Bhatia, Raghava Mutharaju</li>
<li>for: This paper provides an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL.</li>
<li>methods: The paper discusses various techniques employed in neuro-symbolic deductive reasoning, including neural networks and symbolic systems.</li>
<li>results: The paper provides a comprehensive overview of the existing literature in the field, discussing the tasks addressed and other relevant efforts in this area.<details>
<summary>Abstract</summary>
Ontologies are used in various domains, with RDF and OWL being prominent standards for ontology development. RDF is favored for its simplicity and flexibility, while OWL enables detailed domain knowledge representation. However, as ontologies grow larger and more expressive, reasoning complexity increases, and traditional reasoners struggle to perform efficiently. Despite optimization efforts, scalability remains an issue. Additionally, advancements in automated knowledge base construction have created large and expressive ontologies that are often noisy and inconsistent, posing further challenges for conventional reasoners. To address these challenges, researchers have explored neuro-symbolic approaches that combine neural networks' learning capabilities with symbolic systems' reasoning abilities. In this chapter,we provide an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL, discussing the techniques employed, the tasks they address, and other relevant efforts in this area.
</details>
<details>
<summary>摘要</summary>
ontologies 在不同领域中使用，RDF 和 OWL 是 Ontology 开发的主要标准。RDF 因其简单性和灵活性而受到推崇，而 OWL 允许对域知识进行详细表示。然而，随着 ontologies 的增大和表示力的提高，推理复杂性也随之增加，传统的推理器难以高效执行。尽管进行了优化尝试，但Scalability 仍然是一个问题。此外，自动化知识库建构技术的进步创造了大量和表示力强的 ontologies，这些 ontologies 经常具有噪音和不一致性，对传统的推理器 pose 更大的挑战。为解决这些挑战，研究人员 explore 了 neuralsymbolic 方法，这些方法将 neural networks 的学习能力与 symbolic 系统的推理能力结合起来。在这章中，我们提供了 exist 的文献综述，涵盖使用 RDF(S)、描述逻辑 EL 和 ALC，以及 OWL 2 RL，讨论使用的技术、Addressed 的任务和其他相关的努力。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-and-Optimal-Learning-based-Path-Planning-Method-for-Planetary-Rovers"><a href="#A-Fast-and-Optimal-Learning-based-Path-Planning-Method-for-Planetary-Rovers" class="headerlink" title="A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers"></a>A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04792">http://arxiv.org/abs/2308.04792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Ji, Yang Liu, Guanghu Xie, Zongwu Xie, Baoshi Cao</li>
<li>for: 提高 planetary rover 的探索效率，通过学习方法实现快速搜索优化路径。</li>
<li>methods: 利用 numerous pre-annotated optimal path demonstrations 学习 semantic信息，生成概率分布，表示每个像素是优化路径的可能性。</li>
<li>results: 对于 novel maps，可以快速搜索优化路径，并且在同硬件条件下，导航场景生成的优化路径可以大大减少搜索时间。<details>
<summary>Abstract</summary>
Intelligent autonomous path planning is crucial to improve the exploration efficiency of planetary rovers. In this paper, we propose a learning-based method to quickly search for optimal paths in an elevation map, which is called NNPP. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the DEM. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to perform path planning on novel maps. Experiments show that the guidance field generated by the NNPP model can significantly reduce the search time for optimal paths under the same hardware conditions, and the advantage of NNPP increases with the scale of the map.
</details>
<details>
<summary>摘要</summary>
智能自主路径规划是探索效率提高 planetary rover 的关键。本文提出一种学习基于的方法，快速搜索地形图上的优化路径，称为 NNPP。 NNPP 模型从 numerous pre-annotated 优化路径示例中学习起始和目标位置的 semantic 信息以及地图表示，并生成地图上每个像素的可能性分布，表示它是优化路径的一部分。更加具体地说，文章计算地形图上每个格子单元的行进成本，基于 DEM 中的坡度、粗糙度和高程差。然后，起始和目标位置被编码为 Gaussian 分布，并对不同的位置编码参数进行分析，以影响模型性能。在训练后，NNPP 模型可以在新地图上进行路径规划。实验表明，NNPP 模型生成的引导场可以在同样的硬件条件下减少搜索优化路径的时间，并且 NNPP 模型在地图规模增加后的优势也随着增加。
</details></li>
</ul>
<hr>
<h2 id="Multi-View-Fusion-and-Distillation-for-Subgrade-Distresses-Detection-based-on-3D-GPR"><a href="#Multi-View-Fusion-and-Distillation-for-Subgrade-Distresses-Detection-based-on-3D-GPR" class="headerlink" title="Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR"></a>Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04779">http://arxiv.org/abs/2308.04779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunpeng Zhou, Kangjie Ning, Haishuai Wang, Zhi Yu, Sheng Zhou, Jiajun Bu<br>for:This paper focuses on the subgrade distress detection task using 3D ground-penetrating radar (3D-GPR) data, with the goal of enhancing efficiency and accuracy through the use of automatic detection techniques and deep learning.methods:The proposed method leverages multi-view information from 3D-GPR data and constructs a real multi-view image dataset for the detection task. The method also develops a novel framework called GPR-MVFD, which incorporates multi-view distillation and attention-based fusion to extract significant features for subgrade distresses.results:The proposed framework outperforms existing GPR baselines and state-of-the-art methods in multi-view learning, multi-modal learning, and knowledge distillation, as demonstrated through extensive experiments on a new GPR benchmark. The constructed multi-view GPR dataset with expert-annotated labels and the source codes of the proposed framework will be released.<details>
<summary>Abstract</summary>
The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress detection has gained widespread popularity. To enhance the efficiency and accuracy of detection, pioneering studies have attempted to adopt automatic detection techniques, particularly deep learning. However, existing works typically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the GPR, resulting in either insufficient spatial information or high computational complexity. To address these challenges, we introduce a novel methodology for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data. Moreover, we construct a real multi-view image dataset derived from the original 3D-GPR data for the detection task, which provides richer spatial information compared to A-scan and B-scan data, while reducing computational complexity compared to C-scan data. Subsequently, we develop a novel \textbf{M}ulti-\textbf{V}iew \textbf{V}usion and \textbf{D}istillation framework, \textbf{GPR-MVFD}, specifically designed to optimally utilize the multi-view GPR dataset. This framework ingeniously incorporates multi-view distillation and attention-based fusion to facilitate significant feature extraction for subgrade distresses. In addition, a self-adaptive learning mechanism is adopted to stabilize the model training and prevent performance degeneration in each branch. Extensive experiments conducted on this new GPR benchmark demonstrate the effectiveness and efficiency of our proposed framework. Our framework outperforms not only the existing GPR baselines, but also the state-of-the-art methods in the fields of multi-view learning, multi-modal learning, and knowledge distillation. We will release the constructed multi-view GPR dataset with expert-annotated labels and the source codes of the proposed framework.
</details>
<details>
<summary>摘要</summary>
现在广泛应用的3D地面探测（3D-GPR）技术已经为基层损伤探测带来了广泛的应用。为了提高检测效率和准确性，先锋研究者们已经尝试使用自动检测技术，特别是深度学习。然而，现有的工作通常仅仅基于传统的1D A-scan、2D B-scan或3D C-scan GPR数据，这会导致 either 缺乏空间信息 or 高度计算复杂。为解决这些挑战，我们介绍了一种新的方法oloogy for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data。此外，我们构建了来自原始3D-GPR数据的真正多视图图像集，这提供了与A-scan和B-scan数据相比更丰富的空间信息，而与C-scan数据相比又更加可靠。然后，我们开发了一种新的Multi-View Fusion and Distillation框架（GPR-MVFD），专门为了优化多视图GPR数据的利用。这个框架杰出地结合了多视图混合和注意力基于的混合，以便实现了显著的特征提取 для基层损伤。此外，我们采用了自适应学习机制，以稳定模型训练和避免每个分支的性能下降。我们在新的GPR benchmark上进行了广泛的实验，并证明了我们提出的方法的有效性和效率。我们的方法不仅超过了现有的GPR基准，还超过了多视图学习、多模态学习和知识混合等领域的状态 искусственный机制。我们将构建的多视图GPR数据集和GPR-MVFD框架的源代码一起发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Multi-view-Clustering-based-on-Non-negative-Matrix-Factorization"><a href="#Multi-modal-Multi-view-Clustering-based-on-Non-negative-Matrix-Factorization" class="headerlink" title="Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization"></a>Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04778">http://arxiv.org/abs/2308.04778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasser Khalafaoui, Nistor Grozavu, Basarab Matei, Laurent-Walter Goix</li>
<li>for: 本研究旨在提出一种多模态多观点非正式矩阵因子分解方法，用于挖掘数据集中的多模态结构。</li>
<li>methods: 本研究使用非正式矩阵因子分解方法，通过在数据矩阵中强制非负元素的约束，将数据分解成两个矩阵：一个表示数据分区，另一个表示数据集中各个模态的聚类特征。</li>
<li>results: 实验结果表明，提出的方法在多种数据集上具有优秀的性能，与当前state-of-the-art方法相比，具有更高的准确率和更好的可读性。<details>
<summary>Abstract</summary>
By combining related objects, unsupervised machine learning techniques aim to reveal the underlying patterns in a data set. Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements' non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which was evaluated using a variety of data sets, and the obtained results are very promising compared to state of art methods.
</details>
<details>
<summary>摘要</summary>
通过组合相关对象，无监督机器学习技术寻求潜在的数据集下的 patrón。非正式矩阵分解（NMF）是一种数据挖掘技术，通过强制数据矩阵中元素的非负性约束，将数据分解成两个矩阵：一个表示数据分区，另一个表示数据集中聚类prototype。这种方法在各种应用中具有广泛的应用，包括文本挖掘、聚类、语言模型、音乐识别和神经科学（基因分离）。由于缺乏负值，生成的矩阵的解释变得更加简单。在本文中，我们提出了一种多模态聚类算法的研究，并提出了一种新的方法 called 多模态多视图非正式矩阵分解。我们通过分析多个本地NMF模型的协作来进行分析。实验结果显示，提出的方法在多种数据集上具有极高的效果，与现有方法相比，结果很有前途。
</details></li>
</ul>
<hr>
<h2 id="E3-UAV-An-Edge-based-Energy-Efficient-Object-Detection-System-for-Unmanned-Aerial-Vehicles"><a href="#E3-UAV-An-Edge-based-Energy-Efficient-Object-Detection-System-for-Unmanned-Aerial-Vehicles" class="headerlink" title="E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles"></a>E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04774">http://arxiv.org/abs/2308.04774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiashun Suo, Xingzhou Zhang, Weisong Shi, Wei Zhou</li>
<li>for: 这个研究旨在开发一个能效的无人机基础设施检测系统，以减少无人机在检测任务中的能源消耗。</li>
<li>methods: 这个系统使用了边缘 computing技术，并支援多种无人机设备、边缘设备和检测算法，以实现最佳化的能源消耗。</li>
<li>results: 实验结果显示，这个系统可以在实际应用中对检测任务进行有效的能源消耗优化。<details>
<summary>Abstract</summary>
Motivated by the advances in deep learning techniques, the application of Unmanned Aerial Vehicle (UAV)-based object detection has proliferated across a range of fields, including vehicle counting, fire detection, and city monitoring. While most existing research studies only a subset of the challenges inherent to UAV-based object detection, there are few studies that balance various aspects to design a practical system for energy consumption reduction. In response, we present the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by deciding the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task. We first present an effective evaluation metric for actual tasks and construct a transparent energy consumption model based on hundreds of actual flight data to formalize the relationship between energy consumption and flight parameters. Then we present a lightweight energy-efficient priority decision algorithm based on a large quantity of actual flight data to assist the system in deciding flight parameters. Finally, we evaluate the performance of the system, and our experimental results demonstrate that it can significantly decrease energy consumption in real-world scenarios. Additionally, we provide four insights that can assist researchers and engineers in their efforts to study UAV-based object detection further.
</details>
<details>
<summary>摘要</summary>
In response, we propose the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by determining the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task.To evaluate the performance of the system, we first present an effective evaluation metric for actual tasks and construct a transparent energy consumption model based on hundreds of actual flight data to formalize the relationship between energy consumption and flight parameters. Then, we present a lightweight energy-efficient priority decision algorithm based on a large quantity of actual flight data to assist the system in deciding flight parameters.Our experimental results demonstrate that the E3-UAV system can significantly decrease energy consumption in real-world scenarios. Additionally, we provide four insights that can assist researchers and engineers in their efforts to study UAV-based object detection further:1. The choice of detection algorithm has a significant impact on energy consumption, and the most energy-efficient algorithm may not always be the best performer.2. Flight altitude has a greater impact on energy consumption than flight speed, and adjusting flight altitude can lead to significant energy savings.3. Sampling rate has a complex relationship with energy consumption, and the optimal sampling rate depends on the specific task and environment.4. The E3-UAV system can be used for a variety of tasks beyond object detection, such as tracking and monitoring, and can be integrated with other systems to achieve even greater energy savings.In summary, the E3-UAV system represents a significant step forward in the development of energy-efficient UAV-based object detection systems, and our insights provide valuable guidance for future research and development in this area.
</details></li>
</ul>
<hr>
<h2 id="Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization"><a href="#Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization" class="headerlink" title="Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization"></a>Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04767">http://arxiv.org/abs/2308.04767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tahy1/avin">https://github.com/tahy1/avin</a></li>
<li>paper_authors: Tianyu Liu, Peng Zhang, Wei Huang, Yufei Zha, Tao You, Yanning Zhang</li>
<li>for: 本研究旨在解决自主顺序声音源localization中的modal inconsistency问题，通过对听写和视觉特征进行更好的匹配，提高声音源localization的精度和稳定性。</li>
<li>methods: 本研究提出了一种名为Induction Network的新网络模型，通过分离视觉和听写模态的梯度，使得视觉特征更好地学习声音源的描述性特征，同时听写模态也可以与视觉模态一样准确地匹配。此外，本研究还引入了一种适应阈值选择策略，以提高induction网络的Robustness。</li>
<li>results: 实验表明，Compared with其他State-of-the-art工作，本研究的方法在不同的挑战性enario中具有更高的性能和稳定性。特别是在SoundNet-Flickr和VGG-Sound Source数据集上，本研究的方法的声音源localization性能都达到了最高水平。<details>
<summary>Abstract</summary>
Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network. Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN
</details>
<details>
<summary>摘要</summary>
自我超vision的声源localization通常面临modal inconsistency挑战。近年来，基于对比学习的策略在视觉场景中已经展示了promising的表现，可以建立声源和视觉模态之间的一致性。然而，忽视不同模态特征之间的多样性影响仍然限制了这种方案的进一步改进，这也成为了我们的研究动机。在这项研究中，我们提出了一种启发网络，可以更有效地bridging模态差距。通过解coupling视觉和声音模态的梯度，可以学习视觉特征中声源的抽象表示，同时使声音模态与视觉模态保持一致。此外，我们还引入了一种视觉权重对比损失和适应阈值选择策略，以增强启发网络的稳定性。在SoundNet-Flickr和VGG-Sound Source等数据集上进行了大量实验，并证明了与其他状态 искус技术相比，我们的方法在不同的挑战场景中具有优秀的表现。代码可以在https://github.com/Tahy1/AVIN中下载。
</details></li>
</ul>
<hr>
<h2 id="Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning"><a href="#Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning" class="headerlink" title="Feature Matching Data Synthesis for Non-IID Federated Learning"></a>Feature Matching Data Synthesis for Non-IID Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04761">http://arxiv.org/abs/2308.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Li, Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</li>
<li>for: This paper proposes a novel federated learning (FL) framework with data augmentation to relieve data heterogeneity, which can effectively address the non-independent and identically distributed (non-IID) data challenge in FL.</li>
<li>methods: The proposed framework uses a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models, which generates synthetic data by learning the essential class-relevant features of real samples and discarding the redundant features. To further enhance privacy preservation, a hard feature augmentation method is proposed to transfer real features towards the decision boundary, making the synthetic data not only improve the model generalization but also erase the information of real features.</li>
<li>results: The theoretical analysis and simulation results demonstrate that the proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.<details>
<summary>Abstract</summary>
Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 已经成为一种保持隐私的 парадиг，通过在边缘设备上训练神经网络而不需要收集数据到中央服务器。然而，FL 遇到了非独立和同样分布 (非 IID) 数据问题。为解决这个挑战，本文提出了一种困难特征匹配数据合成 (HFMDS) 方法，以及在本地模型 aside，共享auxiliary数据。具体来说，我们通过学习实际样本中的重要类相关特征，并丢弃 redundant 特征，可以有效地解决非 IID 问题。为了更好地保持隐私，我们提议一种困难特征增强方法，通过将实际特征转移到决策边界，使得synthetic数据不仅提高模型通用性，还消除实际特征的信息。通过将提档的 HFMDS 方法与 FL 集成，我们提出了一种新的 FL 框架，并在不同的 benchmark 数据集上进行了实验。理论分析表明，我们的提档的数据合成方法能够有效地解决非 IID 问题。实验结果还表明，我们的 HFMDS-FL 算法在准确率、隐私保持和计算成本等方面，与基eline相比，在不同的 benchmark 数据集上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Automated-Driving-Without-Ethics-Meaning-Design-and-Real-World-Implementation"><a href="#Automated-Driving-Without-Ethics-Meaning-Design-and-Real-World-Implementation" class="headerlink" title="Automated Driving Without Ethics: Meaning, Design and Real-World Implementation"></a>Automated Driving Without Ethics: Meaning, Design and Real-World Implementation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04760">http://arxiv.org/abs/2308.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katherine Evans, Nelson de Moura, Raja Chatila, Stéphane Chauvier</li>
<li>for: 这 paper 的目的是提出一种基于预定参数的 AV 决策策略，以便在各种决策场景中满足不同的人道主义观点和公众期望。</li>
<li>methods: 该策略使用了 Ethical Valence Theory，将 AV 决策视为一种缓冲降低报告的过程，并提出多种可能的决策规则，以便在具体的决策场景中选择最适合的行动。</li>
<li>results: 该策略可以帮助评估自动化汽车的决策是否符合社会可接受水平，并且可以满足不同的人道主义观点和公众期望。<details>
<summary>Abstract</summary>
The ethics of automated vehicles (AV) has received a great amount of attention in recent years, specifically in regard to their decisional policies in accident situations in which human harm is a likely consequence. After a discussion about the pertinence and cogency of the term 'artificial moral agent' to describe AVs that would accomplish these sorts of decisions, and starting from the assumption that human harm is unavoidable in some situations, a strategy for AV decision making is proposed using only pre-defined parameters to characterize the risk of possible accidents and also integrating the Ethical Valence Theory, which paints AV decision-making as a type of claim mitigation, into multiple possible decision rules to determine the most suitable action given the specific environment and decision context. The goal of this approach is not to define how moral theory requires vehicles to behave, but rather to provide a computational approach that is flexible enough to accommodate a number of human 'moral positions' concerning what morality demands and what road users may expect, offering an evaluation tool for the social acceptability of an automated vehicle's decision making.
</details>
<details>
<summary>摘要</summary>
自动驾驶车（AV）的伦理问题在最近几年内得到了广泛的关注，尤其是在冲突情况下人类伤害的可能性存在时。 после一些讨论“人造道德代理人”这个术语是否适用于AV，以及从假设存在某些情况下人类伤害是不可避免的前提下，一种基于预先定义的参数来描述可能发生的事故风险，以及纳入伦理价值论中的多种可能的决策规则，以确定在特定环境和决策上最合适的行动。该方法的目的不是定义自动车如何行事，而是提供一种计算方法，能够适应人类“道德位置”的多种要求和公路用户的期望，并提供评估自动车决策的社会可接受性的工具。
</details></li>
</ul>
<hr>
<h2 id="Bird’s-Eye-View-Scene-Graph-for-Vision-Language-Navigation"><a href="#Bird’s-Eye-View-Scene-Graph-for-Vision-Language-Navigation" class="headerlink" title="Bird’s-Eye-View Scene Graph for Vision-Language Navigation"></a>Bird’s-Eye-View Scene Graph for Vision-Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04758">http://arxiv.org/abs/2308.04758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Liu, Xiaohan Wang, Wenguan Wang, Yi Yang</li>
<li>for: 这篇论文主要研究的是视觉语言导航（VLN）技术，即让机器人根据人类的指令在3D环境中进行导航。</li>
<li>methods: 该论文提出了一种基于多步BEV表示（BEV Scene Graph，BSG）的方法，用于编码室内环境的场景布局和几何特征。在导航过程中，BSG会建立当前步骤的本地BEV表示，并维护一个基于BEV的全局场景地图，用于存储和组织在线收集的所有本地BEV表示。</li>
<li>results: 与现有方法相比，该方法在REVERIE、R2R和R4R等测试 datasets 上显示出了明显的提升。这表明BEV感知在VLN中具有潜在的应用前景。<details>
<summary>Abstract</summary>
Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach significantly outperforms state-of-the-art methods on REVERIE, R2R, and R4R, showing the potential of BEV perception in VLN.
</details>
<details>
<summary>摘要</summary>
vision-language navigation (VLN) 已经取得了很大的进步，但现有的代理人都是基于投影的观察，这会限制它们对3D场景的理解和 Selection of panoramic view 的能力。为了解决这些局限性，我们提出了 BEV 场景图 (BSG)，它利用多步 BEV 表示来编码室内环境的场景布局和几何信息。在导航过程中，BSG 在每个步骤建立了本地 BEV 表示，并维护了基于 BEV 的全局场景图，该图存储和组织了在线收集的所有本地 BEV 表示，根据它们的 topological relations。基于 BSG，代理人可以预测本地 BEV 格子级别的决策分数和全局图级别的决策分数，同时还可以基于投影视图进行更准确的动作预测。我们的方法在 REVERIE、R2R 和 R4R 上表现出了明显的突破，demonstrating the potential of BEV perception in VLN。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Efficient-Continual-Learning-with-Dynamic-Structure-Development-of-Spiking-Neural-Networks"><a href="#Enhancing-Efficient-Continual-Learning-with-Dynamic-Structure-Development-of-Spiking-Neural-Networks" class="headerlink" title="Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks"></a>Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04749">http://arxiv.org/abs/2308.04749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/braincog-x/brain-cog">https://github.com/braincog-x/brain-cog</a></li>
<li>paper_authors: Bing Han, Feifei Zhao, Yi Zeng, Wenxuan Pan, Guobin Shen</li>
<li>For: The paper proposes a new method for efficient and adaptive continual learning in Spiking Neural Networks (SNNs), inspired by the dynamic structure development of the human brain during child growth and development.* Methods: The proposed method, called Dynamic Structure Development of Spiking Neural Networks (DSD-SNN), dynamically assigns and grows new neurons to new tasks, prunes redundant neurons, and leverages overlapping shared structure to quickly adapt to new tasks while reducing computational overhead.* Results: The proposed model achieves significant improvements in performance, learning speed, and memory capacity compared to existing SNNs-based continual learning methods, and achieves comparable performance with DNNs-based methods.<details>
<summary>Abstract</summary>
Children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.
</details>
<details>
<summary>摘要</summary>
children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.Here's the text in Traditional Chinese:children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.
</details></li>
</ul>
<hr>
<h2 id="Case-Study-Using-AI-Assisted-Code-Generation-In-Mobile-Teams"><a href="#Case-Study-Using-AI-Assisted-Code-Generation-In-Mobile-Teams" class="headerlink" title="Case Study: Using AI-Assisted Code Generation In Mobile Teams"></a>Case Study: Using AI-Assisted Code Generation In Mobile Teams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04736">http://arxiv.org/abs/2308.04736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mircea-Serban Vasiliniuc, Adrian Groza</li>
<li>for: 本研究旨在评估人工智能助成编程在实际移动开发团队中的性能，具体是使用适应性的编程语言如kotlin和swift。</li>
<li>methods: 该研究采用了一项大规模的实验研究，参与者共16人，两名技术评审人，从一家软件开发公司的移动部门中挑选参与者，以了解在特定阶段使用LLMs进行代码生成的影响，具体来说是技术培训和技术栈转换。</li>
<li>results: 研究结果表明，使用AI助成编程工具可以提高开发效率和正确率，同时也可以帮助开发者更快地适应新的技术环境。<details>
<summary>Abstract</summary>
The aim of this study is to evaluate the performance of AI-assisted programming in actual mobile development teams that are focused on native mobile languages like Kotlin and Swift. The extensive case study involves 16 participants and 2 technical reviewers, from a software development department designed to understand the impact of using LLMs trained for code generation in specific phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and technical integration using ReviewerScore, a metric specific to the paper and extracted from actual industry standards, the code reviewers of merge requests. The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting developers onboard in a project or helping them with a smooth transition between the two native development environments of mobile development, Android and iOS. The study was performed between May and June 2023 with members of the mobile department of a software development company based in Cluj-Napoca, with Romanian ownership and management.
</details>
<details>
<summary>摘要</summary>
这项研究的目的是评估人工智能助手在实际移动开发团队中的表现，这些团队专注于本地移动语言如kotlin和swift。这项案例研究包括16名参与者和2名技术评审员，来自软件开发部门，旨在了解使用LLMs生成代码在特定阶段的团队中的影响，具体来说是技术培训和技术栈转换。研究使用每个阶段的技术问题，并请参与者在使用AI代码生成器和不使用其之间提交解决方案。研究测量时间、正确性和技术 интеграción使用ReviewerScore指标，该指标来自实际业界标准，代码审查人员对合并请求的反馈。输出被转换和分析，并与参与者反馈结合，以确定使用AI助手编程工具是否会影响开发人员在项目中上手或者在 Android 和 iOS 两个本地开发环境之间的畅转。研究在2023年5月至6月进行，参与者来自罗马尼亚CLuj-Napoca的软件开发公司的移动部门，该公司拥有罗马尼亚所有和管理。
</details></li>
</ul>
<hr>
<h2 id="JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models"><a href="#JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models" class="headerlink" title="JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"></a>JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04729">http://arxiv.org/abs/2308.04729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, Alex Wang</li>
<li>for: 本研究旨在提出一种高精度的文本到音乐生成模型，以解决现有模型的音乐质量和计算效率问题。</li>
<li>methods: 该模型基于扩散过程，并结合了 autoregressive 和 non-autoregressive 训练方法，通过在 Context 学习来实现多种生成任务，包括文本指导音乐生成、音乐填充和续写。</li>
<li>results: 对比先前方法，JEN-1 在文本音乐对齐和音乐质量两个指标上具有显著优势，同时保持计算效率。研究人员提供了在线示例，详细介绍了模型的应用和实现。<details>
<summary>Abstract</summary>
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at http://futureverse.com/research/jen/demos/jen1
</details>
<details>
<summary>摘要</summary>
音乐生成已经吸引了深入的关注，随着深度生成模型的发展。然而，根据文本描述生成音乐，也称为文本到音乐，仍然是一个挑战，因为音乐结构的复杂性和高抽样率的需求。尽管这个任务的重要性，现有的生成模型却表现出限制，包括音乐质量、计算效率和泛化能力。这篇论文介绍了JEN-1，一种通用的高精度模型 для文本到音乐生成。JEN-1是一种扩散模型，通过同时使用抽样和非抽样训练，实现了在文本指导下生成音乐、音乐填充和续写等多种生成任务。评估结果表明，JEN-1在文本音乐对齐和音乐质量方面表现出了明显的优异性，同时保持计算效率。我们的 demo 可以在 http://futureverse.com/research/jen/demos/jen1 上查看。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection"><a href="#Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection" class="headerlink" title="Data-Free Model Extraction Attacks in the Context of Object Detection"></a>Data-Free Model Extraction Attacks in the Context of Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05127">http://arxiv.org/abs/2308.05127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar</li>
<li>for: 本研究旨在攻击机器学习模型中的模型EXTRACTION攻击，通过使用特制的查询语句来盗取目标模型。</li>
<li>methods: 本研究使用了数据自由模型EXTRACTION技术，通过使用生成器类似于生成对抗网络的设置，将查询语句人工地制成，以实现在白盒环境中模拟目标模型。</li>
<li>results: 研究发现，定义损失函数和生成器的设置是EXTRACTION攻击的关键因素，并且使用合理的查询语句可以获得显著的结果。这种对找象检测模型的攻击将支持未来保护这些模型的安全。<details>
<summary>Abstract</summary>
A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models.
</details>
<details>
<summary>摘要</summary>
许多机器学习模型容易受到模型EXTRACTION攻击，这种攻击将目标模型通过使用特制的查询来盗取模型。在实际情况下，目标模型通常是使用私有数据进行训练，这些数据不可 accessible于敌方。我们提出了一种数据free模型EXTRACTION技术，使用生成器类似于生成对抗网络来生成训练数据。我们在这种情况下首次，至少知道的情况下，将敌方黑盒攻击扩展到回归问题中，用于预测物体检测中的矩形坐标。在我们的研究中，我们发现了定义损失函数和使用新的生成器设置是EXTRACTION模型的关键方面。我们发现，使用合理的查询，提议的模型EXTRACTION方法可以取得显著的结果。这种发现将对物体检测模型的安全提供支持。
</details></li>
</ul>
<hr>
<h2 id="JiangJun-Mastering-Xiangqi-by-Tackling-Non-Transitivity-in-Two-Player-Zero-Sum-Games"><a href="#JiangJun-Mastering-Xiangqi-by-Tackling-Non-Transitivity-in-Two-Player-Zero-Sum-Games" class="headerlink" title="JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games"></a>JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04719">http://arxiv.org/abs/2308.04719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Kun Xiong, Yingping Zhang, Jiangcheng Zhu, Stephen Mcaleer, Wei Pan, Jun Wang, Zonghong Dai, Yaodong Yang</li>
<li>for: 这个论文是为了研究完美信息游戏中的非传统性，具体来说是研究中国传统棋盘游戏象棋，与棋盘复杂度相当的棋盘游戏。</li>
<li>methods: 这个论文使用了人类对象棋盘游戏的纪录分析，以及蜕虫 Monte-Carlo Tree Search（MCTS）和策略空间响应器（PSRO）的组合，以估算 Nash 平衡。</li>
<li>results: 这个论文通过对 WeChat 小程序进行实践测试，实现了人类玩家的Master级别冠军，win rate 为 99.41%。这个结果表明了算法的有效性在超越非传统性方面。<details>
<summary>Abstract</summary>
This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game's strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41\% win rate against human players. The algorithm's effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at \url{https://sites.google.com/view/jiangjun-site/}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution"><a href="#Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution" class="headerlink" title="Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution"></a>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04708">http://arxiv.org/abs/2308.04708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idesan/gpa">https://github.com/idesan/gpa</a></li>
<li>paper_authors: Tsuyoshi Idé, Naoki Abe</li>
<li>for: 本文针对黑盒回归Setting中的概率异常归因 Task进行研究，目标是计算每个输入变量的异常归因分布。</li>
<li>methods: 本文提出了一种新的概率异常归因框架，可以计算异常归因分布以及异常归因分布的uncertainty。这种框架基于对异常观察的perturbations进行counter-factual reasoning。</li>
<li>results: 本文提出了一种基于变量 Bayes算法的方法来derive异常归因分布的 distributions。这种方法可以减少异常归因分布的uncertainty。根据作者所知，这是第一个不受异常归因的概率异常归因框架。<details>
<summary>Abstract</summary>
We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.   We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.
</details>
<details>
<summary>摘要</summary>
我们考虑了黑盒回归Setting中的概率异常归因问题，其目标是计算每个输入变量的归因分布，给出观察到的异常。我们假设训练数据集不可用。这个任务与标准XAI（可解释AI）场景不同，我们想要解释黑盒预测的异常偏差，而不是黑盒模型本身。我们首先表明，主流的模型无关解释方法，如雪佛利值，不适合这个任务，因为它们的“偏差无关性”性。然后，我们提出了一种新的概率异常归因框架，允许我们不仅计算归因分布，还能量度这些分布的不确定性。这是通过考虑一种生成过程来perturbations counter-factually bring the observed anomalous observation back to normalcy来实现的。我们引入了一种变分极 bayes算法来 derive the distributions of per variable attribution scores。到目前为止，这是免受偏差无关性的第一个概率异常归因框架。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects"><a href="#Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects" class="headerlink" title="Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects"></a>Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04696">http://arxiv.org/abs/2308.04696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheyla Amirian, Luke A. Carlson, Matthew F. Gong, Ines Lohse, Kurt R. Weiss, Johannes F. Plate, Ahmad P. Tafti</li>
<li>for: 本研究旨在解决医疗机器学习（AI）在orthopedics中的解释性和可解释性问题，以便临床医生、外科医生和患者能够理解AI模型的各种预测和描述模型的贡献因素。</li>
<li>methods: 本研究采用了多种方法，包括临床实践、数据分析和模型开发，以解决XAI在orthopedics中的挑战。</li>
<li>results: 本研究发现了一些关键的挑战和机遇，包括数据不一致、模型复杂性和解释性要求等，这些挑战需要在AI实践中得到解决，以便在orthopedics中广泛采用XAI。<details>
<summary>Abstract</summary>
While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在不同领域取得了许多成功应用，但在医疗领域的采纳相对落后一些。这些因素包括法规框架、患者隐私问题和数据多样性。然而，在医疗领域中，特别是在骨科方面，缺乏可解释性和解释力是人工智能的实施的一大障碍。解决骨科中的可解释人工智能（XAI）挑战需要开发可透明和可解释的AI模型和算法，让临床医生、外科医生和患者理解任何基于AI的预测或描述性模型的贡献因素。本著作描述了骨科中XAI的一些关键挑战和机遇，并强调需要在AI实践者、骨科专家和法规机构之间建立标准和指南，以便在骨科中广泛采用XAI。
</details></li>
</ul>
<hr>
<h2 id="Finite-Element-Operator-Network-for-Solving-Parametric-PDEs"><a href="#Finite-Element-Operator-Network-for-Solving-Parametric-PDEs" class="headerlink" title="Finite Element Operator Network for Solving Parametric PDEs"></a>Finite Element Operator Network for Solving Parametric PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04690">http://arxiv.org/abs/2308.04690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jae Yong Lee, Seungchan Ko, Youngjoon Hong</li>
<li>for: 解决 parametric PDEs 的数值方法问题</li>
<li>methods: 提议使用 Finite Element Operator Network (FEONet) 方法，兼用深度学习和传统数值方法，解决 parametric PDEs 问题，不需要输入输出对应的训练数据</li>
<li>results: 在多个 benchmark 问题中，FEONet 方法比现有的状态 искусственный intelligence 方法更高精度、更好的泛化性和计算灵活性，并且可以应用于各种领域中， где PDEs 扮演关键角色。<details>
<summary>Abstract</summary>
Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and singular behavior. Furthermore, we provide theoretical convergence analysis to support our approach, utilizing finite element approximation in numerical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="web-crawler-strategies-for-web-pages-under-robot-txt-restriction"><a href="#web-crawler-strategies-for-web-pages-under-robot-txt-restriction" class="headerlink" title="web crawler strategies for web pages under robot.txt restriction"></a>web crawler strategies for web pages under robot.txt restriction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04689">http://arxiv.org/abs/2308.04689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Vyas, Akhilesh Chauhan, Tushar Mandge, Surbhi Hardikar</li>
<li>for: 本研究paper introduce了搜索引擎对 keywords 的工作，以便用户通过搜索获得搜寻结果。</li>
<li>methods: 本研究使用了不同的搜索算法，以提供便捷的搜寻结果给网络浏览者。</li>
<li>results: 本研究回答了一些基本问题，例如网页在搜索引擎中如何获得高排名、搜索引擎如何获得网页的全部内容、网站管理员如何透过 robot.txt 文件对网络爬虫进行限制等等。<details>
<summary>Abstract</summary>
In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.
</details>
<details>
<summary>摘要</summary>
现在，所有人都知道世界延伸网（World Wide Web）以及在互联网上每天进行工作。在这篇论文中，我们介绍了用户输入关键词时搜索引擎所使用的不同搜索算法，以提供便利的搜索结果给网络浏览者。网络浏览者通常会遵循搜索结果的排名，但是如何使得网页在搜索引擎中获得高排名呢？这篇论文会回答这些基本问题。此外，我们还会讨论搜索引擎使用的网络爬虫（web crawler）以及爬虫排除协议（robot exclusion protocol）规则。网站管理员可以使用 robot.txt 文件中的不同限制事实来 instruc爬虫，这篇论文还将介绍一些基本的 robot.txt 格式。
</details></li>
</ul>
<hr>
<h2 id="Rapid-Training-Data-Creation-by-Synthesizing-Medical-Images-for-Classification-and-Localization"><a href="#Rapid-Training-Data-Creation-by-Synthesizing-Medical-Images-for-Classification-and-Localization" class="headerlink" title="Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization"></a>Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04687">http://arxiv.org/abs/2308.04687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Kushwaha, Sarthak Gupta, Anish Bhanushali, Tathagato Rai Dastidar<br>for: 这篇论文的目的是解决医疗影像分析中对于资料标注的问题，以及实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生。methods: 这篇论文使用了一种方法来将真实的数据转换为训练深度神经网络所需的标注资料。这种方法可以帮助解决医疗影像分析中对于资料标注的问题，并且可以实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生。results: 这篇论文的结果显示，使用这种方法可以将医疗影像的训练深度神经网络的对于标注的精度提高 significantly。另外，这种方法可以实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生，并且可以与实际的标注资料相对比较。<details>
<summary>Abstract</summary>
While the use of artificial intelligence (AI) for medical image analysis is gaining wide acceptance, the expertise, time and cost required to generate annotated data in the medical field are significantly high, due to limited availability of both data and expert annotation. Strongly supervised object localization models require data that is exhaustively annotated, meaning all objects of interest in an image are identified. This is difficult to achieve and verify for medical images. We present a method for the transformation of real data to train any Deep Neural Network to solve the above problems. We show the efficacy of this approach on both a weakly supervised localization model and a strongly supervised localization model. For the weakly supervised model, we show that the localization accuracy increases significantly using the generated data. For the strongly supervised model, this approach overcomes the need for exhaustive annotation on real images. In the latter model, we show that the accuracy, when trained with generated images, closely parallels the accuracy when trained with exhaustively annotated real images. The results are demonstrated on images of human urine samples obtained using microscopy.
</details>
<details>
<summary>摘要</summary>
Artificial intelligence (AI) for medical image analysis 受欢迎，但是在医疗领域生成标注数据的专业知识、时间和成本很高，主要是因为医疗数据和专家标注数据的有限性。强制supervised对象定位模型需要完全标注的数据，这是医疗图像中很难以完成和验证。我们提出了一种将实际数据转换为训练任何深度神经网络的方法。我们在弱supervised对象定位模型和强制supervised对象定位模型中应用了这种方法，并证明了其效果。对于弱supervised模型，我们发现使用生成的数据可以显著提高对象定位精度。对于强制supervised模型，这种方法可以解决实际图像中的尝试性标注问题，并且在使用生成的图像进行训练时，对象定位精度与使用实际图像进行训练时的精度几乎相同。我们在人体尿样微scopic图像中进行了实验，并证明了这种方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Sci-CoT-Leveraging-Large-Language-Models-for-Enhanced-Knowledge-Distillation-in-Small-Models-for-Scientific-QA"><a href="#Sci-CoT-Leveraging-Large-Language-Models-for-Enhanced-Knowledge-Distillation-in-Small-Models-for-Scientific-QA" class="headerlink" title="Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA"></a>Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04679">http://arxiv.org/abs/2308.04679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Ma, Haiqi Jiang, Chenyou Fan</li>
<li>for: 这 paper 是 investigate LLMs 的 reasoning 能力，并尝试将其转移到 smaller models 上。</li>
<li>methods: 该 paper 使用 knowledge distillation 方法，分离 rationales 和 answer 的生成过程，以提高 scientific question-answering 任务 的性能。</li>
<li>results: 该 paper 的 80 亿参数模型在 ARC-Easy 数据集下，在 few shot 设定下，超过 BLOOM-176B 的性能。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown outstanding performance across wide range of downstream tasks. This competency is attributed to their substantial parameter size and pre-training on extensive corpus. Moreover, LLMs have exhibited enhanced reasoning capabilities in tackling complex reasoning tasks, owing to the utilization of a method named ``Chain-of-Thought (CoT) prompting''. This method is designed to generate intermediate reasoning steps that guide the inference of the final answer. However, it is essential to highlight that these advanced reasoning abilities appear to emerge in models with a minimum of 10 billion parameters, thereby limiting its efficacy in situations where computational resources are constrained. In this paper, we investigate the possibility of transferring the reasoning capabilities of LLMs to smaller models via knowledge distillation. Specifically, we propose Sci-CoT, a two-stage framework that separates the processes of generating rationales and inferring answers. This method enables a more efficient use of rationales during the answer inference stage, leading to improved performance on scientific question-answering tasks. Utilizing Sci-CoT, our 80-million parameter model is able to exceed the performance of BLOOM-176B in the ARC-Easy dataset under the few shot setting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Addressing-Racial-Bias-in-Facial-Emotion-Recognition"><a href="#Addressing-Racial-Bias-in-Facial-Emotion-Recognition" class="headerlink" title="Addressing Racial Bias in Facial Emotion Recognition"></a>Addressing Racial Bias in Facial Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04674">http://arxiv.org/abs/2308.04674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Fan, Xingshuo Xiao, Peter Washington</li>
<li>for: 该研究旨在分析深度学习模型在高维输入和主观标签下的公平性问题。</li>
<li>methods: 该研究使用变换训练集的方法来分析种族偏见，并评估模型在不同种族群体中的表现。</li>
<li>results: 研究发现，尽管使用更小的训练集可以改善公平性和性能指标，但在更大的数据集中，种族偏见指标通常保持不变，这表明种族平衡本身不足以实现不同种族群体中的表现均衡。<details>
<summary>Abstract</summary>
Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\%$ points, and demographic parity increases by $15.7\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.
</details>
<details>
<summary>摘要</summary>
“深入学习模型对高维输入和主观标签的公平性问题仍然是一个复杂和未得到充分研究的领域。 facial emotion recognition 领域中的数据集经常具有种族不均衡，这可能导致不同种族群体之间的模型性能差异。本研究通过对训练集进行不同种族分布的子批采样，并评估测试性能在这些模拟中的变化。我们发现，使用posed faces的训练集可以提高公平性和性能指标，特别是在模拟中接近种族均衡时。平均而言，使用posed faces的训练集可以提高 F1 分数27.2个百分点，并提高了种族平衡指标15.7个百分点。然而，在大型数据集中，公平指标通常保持不变，这表明，只有寻求种族均衡不能 garantate 测试性能的平衡 across different racial groups。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="SSL-Auth-An-Authentication-Framework-by-Fragile-Watermarking-for-Pre-trained-Encoders-in-Self-supervised-Learning"><a href="#SSL-Auth-An-Authentication-Framework-by-Fragile-Watermarking-for-Pre-trained-Encoders-in-Self-supervised-Learning" class="headerlink" title="SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning"></a>SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04673">http://arxiv.org/abs/2308.04673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobei Li, Changchun Yin, Liming Fang, Run Wang, Chenhao Lin</li>
<li>for: 这篇论文的目的是为自动学习（SSL）中的标本处理器提供认证框架，以保护标本处理器的知识产权和在部署时确保标本处理器的可靠性。</li>
<li>methods: 这篇论文使用选择的键amples作为水印信息，并训练一个验证网络来重建水印信息，以验证标本处理器的完整性。</li>
<li>results: 实验结果显示，SSL-Auth可以实现标本处理器的完整性验证，并且可以探测到潜在的黑门和攻击攻击。实验结果显示，SSL-Auth不会对标本处理器的性能造成影响。<details>
<summary>Abstract</summary>
Self-supervised learning (SSL), utilizing unlabeled datasets for training powerful encoders, has achieved significant success recently. These encoders serve as feature extractors for downstream tasks, requiring substantial resources. However, the challenge of protecting the intellectual property of encoder trainers and ensuring the trustworthiness of deployed encoders remains a significant gap in SSL. Moreover, recent researches highlight threats to pre-trained encoders, such as backdoor and adversarial attacks. To address these gaps, we propose SSL-Auth, the first authentication framework designed specifically for pre-trained encoders. In particular, SSL-Auth utilizes selected key samples as watermark information and trains a verification network to reconstruct the watermark information, thereby verifying the integrity of the encoder without compromising model performance. By comparing the reconstruction results of the key samples, malicious alterations can be detected, as modified encoders won't mimic the original reconstruction. Comprehensive evaluations on various encoders and diverse downstream tasks demonstrate the effectiveness and fragility of our proposed SSL-Auth.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Resource-Constrained-Model-Compression-via-Minimax-Optimization-for-Spiking-Neural-Networks"><a href="#Resource-Constrained-Model-Compression-via-Minimax-Optimization-for-Spiking-Neural-Networks" class="headerlink" title="Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks"></a>Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04672">http://arxiv.org/abs/2308.04672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenjallen/resource-constrained-compression-on-snn">https://github.com/chenjallen/resource-constrained-compression-on-snn</a></li>
<li>paper_authors: Jue Chen, Huan Yuan, Jianchao Tan, Bin Chen, Chengru Song, Di Zhang</li>
<li>for:  This paper focuses on compressing Brain-inspired Spiking Neural Networks (SNNs) to improve their deployment on edge devices such as neuromorphic chips.</li>
<li>methods: The proposed method uses an improved end-to-end Minimax optimization method for sparse learning to balance model performance and computation efficiency.</li>
<li>results: The compressed SNN models achieved state-of-the-art (SOTA) performance on various benchmark datasets and architectures.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文主要关注压缩Brain-inspired Spiking Neural Networks (SNNs)，以提高其在边缘设备such as neuromorphic chips上的部署。</li>
<li>methods: 提议的方法使用改进的末端Minimax优化方法来解决稀疏学习问题，以更好地均衡模型性能和计算效率。</li>
<li>results: 压缩后的SNN模型在多个 benchmark数据集和架构上达到了最佳性能（SOTA）。I hope that helps!<details>
<summary>Abstract</summary>
Brain-inspired Spiking Neural Networks (SNNs) have the characteristics of event-driven and high energy-efficient, which are different from traditional Artificial Neural Networks (ANNs) when deployed on edge devices such as neuromorphic chips. Most previous work focuses on SNNs training strategies to improve model performance and brings larger and deeper network architectures. It is difficult to deploy these complex networks on resource-limited edge devices directly. To meet such demand, people compress SNNs very cautiously to balance the performance and the computation efficiency. Existing compression methods either iteratively pruned SNNs using weights norm magnitude or formulated the problem as a sparse learning optimization. We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency. We also demonstrate that jointly applying compression and finetuning on SNNs is better than sequentially, especially for extreme compression ratios. The compressed SNN models achieved state-of-the-art (SOTA) performance on various benchmark datasets and architectures. Our code is available at https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN.
</details>
<details>
<summary>摘要</summary>
�建基于大脑的�顿神经网络（SNN）具有事件驱动和高能效的特点，与传统的人工神经网络（ANN）不同，当部署在边缘设备such as neuromorphic chips时。大多数先前的工作将焦点放在SNNs 训练策略以提高模型性能，并带来更大和更深的网络架构。然而，这些复杂的网络直接部署在有限的边缘设备上是困难的。为满足这种需求，人们很注意地压缩SNNs以平衡性能和计算效率。现有的压缩方法包括Iteratively pruning SNNs使用权重norm magnitude或将问题形式为稀疏学习优化问题。我们提出了改进的端到端最小最大优化方法，以更好地平衡模型性能和计算效率。我们还示出，将压缩和训练结合在一起，特别是在极高的压缩比例时，jointly applying compression and finetuning on SNNs 更好than sequentially。压缩后的SNN模型在多个benchmark datasets和架构上达到了state-of-the-art（SOTA）性能。我们的代码可以在https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN上找到。
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Destroy-and-Repair-Approach-for-Solving-Very-Large-Scale-Travelling-Salesman-Problem"><a href="#A-Hierarchical-Destroy-and-Repair-Approach-for-Solving-Very-Large-Scale-Travelling-Salesman-Problem" class="headerlink" title="A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem"></a>A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04639">http://arxiv.org/abs/2308.04639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhang-Hua Fu, Sipeng Sun, Jintong Ren, Tianshu Yu, Haoyu Zhang, Yuanyuan Liu, Lingxiao Huang, Xiang Yan, Pinyan Lu</li>
<li>for: 提出了一种解决大规模的旅行商问题（TSP）的算法，以提高现有算法的计算效率和解决质量。</li>
<li>methods: 提出了一种层次破坏重建（HDR）方法，通过一系列精心设计的破坏重建操作来改进初始解。具有层次搜索框架，可以在一定的等价保证下压缩输入实例，从而提高计算效率。</li>
<li>results: 在 nineteen 个著名的大规模实例上进行了公正的比较，显示 HDR 在计算效率和解决质量两个方面具有竞争力，并在两个大实例上打破了世界纪录。<details>
<summary>Abstract</summary>
For prohibitively large-scale Travelling Salesman Problems (TSPs), existing algorithms face big challenges in terms of both computational efficiency and solution quality. To address this issue, we propose a hierarchical destroy-and-repair (HDR) approach, which attempts to improve an initial solution by applying a series of carefully designed destroy-and-repair operations. A key innovative concept is the hierarchical search framework, which recursively fixes partial edges and compresses the input instance into a small-scale TSP under some equivalence guarantee. This neat search framework is able to deliver highly competitive solutions within a reasonable time. Fair comparisons based on nineteen famous large-scale instances (with 10,000 to 10,000,000 cities) show that HDR is highly competitive against existing state-of-the-art TSP algorithms, in terms of both efficiency and solution quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities, HDR breaks the world records (i.e., best-known results regardless of computation time), which were previously achieved by LKH and its variants, while HDR is completely independent of LKH. Finally, ablation studies are performed to certify the importance and validity of the hierarchical search framework.
</details>
<details>
<summary>摘要</summary>
For 非常大规模的旅行销售人员问题 (TSP), 现有的算法面临着计算效率和解决质量两个大的挑战。为了解决这个问题，我们提议一种层次破坏和重建 (HDR) 方法，它尝试通过一系列特制的破坏和重建操作来提高初始解。一个关键创新的搜索框架是层次搜索框架，它可以在一定的等价保证下将输入实例压缩到小规模的 TSP 中进行搜索。这个搜索框架能够在有限时间内提供高度竞争力的解决方案。基于 nineteen 著名的大规模实例 (10,000 到 10,000,000 个城市) 进行了公正的比较，显示 HDR 在计算效率和解决质量两个方面与现有的状态 искусственный智能 TSP 算法高度竞争。特别是在 3,162,278 和 10,000,000 个城市的两个大实例上，HDR 破坏了世界纪录 (即不管计算时间为何)，这些纪录曾由 LKH 和其变种所获得，而 HDR 与 LKH 完全无关。最后，我们进行了剖面研究，以证明层次搜索框架的重要性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling"><a href="#Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling" class="headerlink" title="Sparse Binary Transformers for Multivariate Time Series Modeling"></a>Sparse Binary Transformers for Multivariate Time Series Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04637">http://arxiv.org/abs/2308.04637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray<br>for:This paper focuses on applying sparse and binary-weighted Transformers to multivariate time series problems, with the goal of achieving accuracy comparable to that of dense floating-point Transformers while reducing computational complexity.methods:The authors use two compression techniques to reduce the number of non-zero operations necessary in the Transformer: 1) applying a fixed mask to the query, key, and value activations, and 2) proposing an attention mask to allow computation only at the current time step.results:The model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting, with up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs compared to the dense floating-point Transformers.<details>
<summary>Abstract</summary>
Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</details>
<details>
<summary>摘要</summary>
压缩神经网络（Compressed Neural Networks）具有启动深度学习的潜力，但未有充分研究其在不同任务下的范围。在这个工作中，我们运用稀疑和二进制权重的 transformer 来解决多元时间序问题，获得了与组 dense floating-point transformer 相同结构的精度。我们的模型在三个时间序学习任务中获得了良好的结果：分类、侦测异常和预测。此外，为降低对于注意力机制的计算复杂度，我们提出了两种修改，它们几乎没有影响模型性能：1）在分类任务中，我们对查询、钥匙和值活动中的数据应用固定的面罩，2）在预测和侦测任务中，我们提出了一个注意力面罩，允许只在目前时间步进行计算。组合这些压缩技术和注意力修改，我们可以对 transformer 进行重大的储存空间和计算复杂度的节省。我们使用多个指标来衡量我们的方法对于储存空间、位元数和浮点操作（FLOPs）的节省，获得了最多 53 倍的储存空间节省和最多 10.5 倍的 FLOPs 节省。
</details></li>
</ul>
<hr>
<h2 id="Where’s-the-Liability-in-Harmful-AI-Speech"><a href="#Where’s-the-Liability-in-Harmful-AI-Speech" class="headerlink" title="Where’s the Liability in Harmful AI Speech?"></a>Where’s the Liability in Harmful AI Speech?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04635">http://arxiv.org/abs/2308.04635</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Henderson, Tatsunori Hashimoto, Mark Lemley</li>
<li>for: 这篇论文探讨了基于文本的生成AI模型在不同法律责任 régime下的责任风险，以及模型创造者和部署者是否受到法律责任。</li>
<li>methods: 文章使用了三种责任 régime来分析生成AI模型的责任风险，包括诽谤、speech integral to criminal conduct和wrongful death。</li>
<li>results: 文章发现，任何 Section 230 免责分析或下游责任分析都与算法设计细节有紧密的关系，而且在法律责任上存在多个障碍，使得很难确定生成AI模型和关联的党员是否承担生成的言论责任。文章认为，AI应不被总是免责，法院和政策制定者应该仔细考虑技术设计的优化，以便更好地评估这些问题。<details>
<summary>Abstract</summary>
Generative AI, in particular text-based "foundation models" (large models trained on a huge variety of information including the internet), can generate speech that could be problematic under a wide range of liability regimes. Machine learning practitioners regularly "red team" models to identify and mitigate such problematic speech: from "hallucinations" falsely accusing people of serious misconduct to recipes for constructing an atomic bomb. A key question is whether these red-teamed behaviors actually present any liability risk for model creators and deployers under U.S. law, incentivizing investments in safety mechanisms. We examine three liability regimes, tying them to common examples of red-teamed model behaviors: defamation, speech integral to criminal conduct, and wrongful death. We find that any Section 230 immunity analysis or downstream liability analysis is intimately wrapped up in the technical details of algorithm design. And there are many roadblocks to truly finding models (and their associated parties) liable for generated speech. We argue that AI should not be categorically immune from liability in these scenarios and that as courts grapple with the already fine-grained complexities of platform algorithms, the technical details of generative AI loom above with thornier questions. Courts and policymakers should think carefully about what technical design incentives they create as they evaluate these issues.
</details>
<details>
<summary>摘要</summary>
优先级AI，特别是基于文本的“基础模型”（大型模型通过互联网上庞大量信息进行训练），可能会生成有问题的语音。机器学习实践者 regularely “红军”模型以识别和避免这些问题语音，从“幻觉”（误告人员严重不当行为）到杀人炸弹的制作方法。关键问题是这些红色测试行为是否对美国法律而言带来责任风险，并促使投资于安全机制。我们研究了三种责任 régime，与常见的红色测试模型行为相关：诽谤、语音与刑事活动相关、和谋杀。我们发现，任何 Section 230 免责分析或下游责任分析都与算法设计技术细节有紧密的关系。而且有很多障碍物，使得真正找到模型（以及关联的党）因生成的语音而负责。我们认为AI shouldn't be categorically immune from liability in these scenarios，而且法院和政策制定者在评估这些问题时应该仔细考虑技术设计的吸引力。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Sentence-Embedding-Models-for-Assessing-Semantic-Variation"><a href="#A-Comparative-Study-of-Sentence-Embedding-Models-for-Assessing-Semantic-Variation" class="headerlink" title="A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation"></a>A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04625">http://arxiv.org/abs/2308.04625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deven M. Mistry, Ali A. Minai</li>
<li>for: 本研究探讨了长文本中语义变化的pattern，从式学、认知和语言学角度都很有趣。同时，这种分析也有应用于文本分 segmentation、文摘概要和语义新颖性检测等领域。</li>
<li>methods: 本研究使用了多种vector-space方法来实现语句嵌入，并对这些方法的一致性和意义性进行了评估。</li>
<li>results: 研究发现，大多数语句嵌入方法在给定的文档中具有高相关性，但显示出有趣的差异。<details>
<summary>Abstract</summary>
Analyzing the pattern of semantic variation in long real-world texts such as books or transcripts is interesting from the stylistic, cognitive, and linguistic perspectives. It is also useful for applications such as text segmentation, document summarization, and detection of semantic novelty. The recent emergence of several vector-space methods for sentence embedding has made such analysis feasible. However, this raises the issue of how consistent and meaningful the semantic representations produced by various methods are in themselves. In this paper, we compare several recent sentence embedding methods via time-series of semantic similarity between successive sentences and matrices of pairwise sentence similarity for multiple books of literature. In contrast to previous work using target tasks and curated datasets to compare sentence embedding methods, our approach provides an evaluation of the methods 'in the wild'. We find that most of the sentence embedding methods considered do infer highly correlated patterns of semantic similarity in a given document, but show interesting differences.
</details>
<details>
<summary>摘要</summary>
分析长文本中的语义变化 Pattern 是从语言、认知和风格等多个角度来看的非常有趣。同时，这也有很多应用，例如文本分 segmentation、文摘概要和语义新颖性检测。随着 sentence embedding 技术的出现，这种分析变得可能。然而，这也引出了各种方法生成的语义表示是否具有一致性和意义的问题。在这篇文章中，我们对一些最近的 sentence embedding 方法进行了比较，使用时间序列的语义相似性和多本文学作品的对应矩阵来评估这些方法。与之前使用目标任务和精心制作的数据集来评估 sentence embedding 方法不同，我们的方法在实际应用中进行了评估。我们发现大多数考虑的 sentence embedding 方法在给定的文档中具有高度相关的语义相似性模式，但是具有舒适的差异。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-LLM-powered-Chatbots-Methods-and-Metrics"><a href="#Benchmarking-LLM-powered-Chatbots-Methods-and-Metrics" class="headerlink" title="Benchmarking LLM powered Chatbots: Methods and Metrics"></a>Benchmarking LLM powered Chatbots: Methods and Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04624">http://arxiv.org/abs/2308.04624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debarag Banerjee, Pooja Singh, Arjun Avadhanam, Saksham Srivastava</li>
<li>for: 评估自动对话机器人（chatbot）的性能，特别是使用生成型人工智能工具（Large Language Models，LLMs）的chatbot。</li>
<li>methods: 提出一种新的终到终（End to End，E2E）benchmark，用于评估chatbot的答案准确性和用用性。</li>
<li>results: 通过对一个示例chatbot进行评估，显示E2E benchmark能够更好地评估chatbot的性能，而且与其他常用的metric相比，E2E benchmark的metric（cosine similarity）表现良好。<details>
<summary>Abstract</summary>
Autonomous conversational agents, i.e. chatbots, are becoming an increasingly common mechanism for enterprises to provide support to customers and partners. In order to rate chatbots, especially ones powered by Generative AI tools like Large Language Models (LLMs) we need to be able to accurately assess their performance. This is where chatbot benchmarking becomes important. In this paper, we propose the use of a novel benchmark that we call the E2E (End to End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy and usefulness of the answers provided by chatbots, especially ones powered by LLMs. We evaluate an example chatbot at different levels of sophistication based on both our E2E benchmark, as well as other available metrics commonly used in the state of art, and observe that the proposed benchmark show better results compared to others. In addition, while some metrics proved to be unpredictable, the metric associated with the E2E benchmark, which uses cosine similarity performed well in evaluating chatbots. The performance of our best models shows that there are several benefits of using the cosine similarity score as a metric in the E2E benchmark.
</details>
<details>
<summary>摘要</summary>
自动化对话代理（即 chatbot）在企业提供客户和伙伴支持的机制中变得越来越普遍。为了评估 chatbot 的性能，特别是基于大型语言模型（LLM）的话语生成器，我们需要能够准确评估它们的表现。这是 где对话机器人评估变得重要。在这篇论文中，我们提议使用一种新的评估标准，称之为端到端（E2E）标准，并证明了该标准可以准确评估对话机器人的答案准确性和用于性。我们对一个示例的对话机器人进行了不同水平的评估，并证明了我们的 E2E 标准与其他常见的状态艺术metric 相比，能够更好地评估对话机器人的性能。此外，我们发现了一些 metrics 的不可预测性，但是与 E2E 标准相关的 cosine 相似性分数metric 表现了良好的评估能力。我们的最佳模型表示，使用 cosine 相似性分数作为metric 在 E2E 标准中有几个优点。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-LLM-Inference-with-Staged-Speculative-Decoding"><a href="#Accelerating-LLM-Inference-with-Staged-Speculative-Decoding" class="headerlink" title="Accelerating LLM Inference with Staged Speculative Decoding"></a>Accelerating LLM Inference with Staged Speculative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04623">http://arxiv.org/abs/2308.04623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Spector, Chris Re</li>
<li>for: 加速大语言模型（LLM）的读取速度，特别是在小批量、设备上的场景下。</li>
<li>methods: 提出了一种新的算法——阶段化推测解码，以优化小批量 inference 的性能。首先，将推测批处理为树状结构，从而降低生成成本和提高每批 tokens 的预期数量。其次，添加了第二个阶段的推测解码。综上所述，对于一个 762M 参数的 GPT-2-L 模型，单批解码延迟时间可以下降至 3.16 倍，同时保持输出质量不变。</li>
<li>results: 对于一个 762M 参数的 GPT-2-L 模型，单批解码延迟时间可以下降至 3.16 倍，同时保持输出质量不变。<details>
<summary>Abstract</summary>
Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative decoding, to accelerate LLM inference in small-batch, on-device scenarios. We address the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding. First, we restructure the speculative batch as a tree, which reduces generation costs and increases the expected tokens per batch. Second, we add a second stage of speculative decoding. Taken together, we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L model while perfectly preserving output quality.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Model-of-models-–-Part-1"><a href="#Model-of-models-–-Part-1" class="headerlink" title="Model of models – Part 1"></a>Model of models – Part 1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04600">http://arxiv.org/abs/2308.04600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shimon Komarovsky</li>
<li>for: 这篇论文提出了一种新的认知模型，作为人工智能代理人的主要组件。这个模型是基于先前的模型，如DENN和AKREM，并包括操作模型（帧&#x2F;类）和愿望。这个模型的核心假设是认知是基于积累知识的操作，并且由适当的愿望导航。此外，这个模型还具有每个智能方面的双重特性，如顶下向和底向学习、总结特化和通用化、以及更多的特性。</li>
<li>methods: 这个模型的主要方法包括基于对照原理的认知演化，从婴儿期到成年期，通过固化原理来描述达到成熟状态。此外，模型还包括一种普适的 AGI 设计方法，以及认知下Constraints or efficiency的方法，如重用和简洁。</li>
<li>results: 这个模型的最终产品是一个动态操作记忆，包含模型和实例。此外，论文还提供了一些示例和初步的进化阶段来达到成熟状态的想法。<details>
<summary>Abstract</summary>
This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via a cognitive evolution from infancy to adulthood, utilizing a consolidation principle. The final product of this cognitive model is a dynamic operational memory of models and instances. Lastly, some examples and preliminary ideas for the evolution phase to reach the mature state are presented.
</details>
<details>
<summary>摘要</summary>
The model is based on the duality principle in every known intelligent aspect, such as top-down and bottom-up model learning, generalization and specialization, and more. Additionally, the model advocates for a holistic approach to AGI design and cognition under constraints or efficiency, in the form of reusability and simplicity.The model proposes a cognitive evolution from infancy to adulthood, utilizing a consolidation principle to reach the mature state. The final product of the model is a dynamic operational memory of models and instances. Some examples and preliminary ideas for the evolution phase to reach the mature state are also presented.Here is the text in Simplified Chinese:这篇论文提出了一个新的认知模型，作为人工通用智能（AGI）代理人的主要组件。该模型是前一代模型DENN和AKREM的扩展，包括操作模型（框架/类）和愿power。模型的核心假设是认知是通过储存的知识进行操作，并且被适当的愿power引导。模型还假设行为，是知识的一部分，在演化阶段前置于成熟智能状态时，通过学习和对愿power的调整，使行为与愿power相吻合。此外，模型还基于知识的每一个智能方面的 dualism原理，例如展现出顶下向和底上向的模型学习、通用和特殊化、以及更多的方面。模型还提出了一种整体的方法 дляAGI设计和认知，即在约束或效率下进行认知，通过再用性和简洁来实现。最后，模型描述了一种认知演化从婴儿期到成年期，通过固化原理来达到成熟状态。最后，模型还提供了一些初步的演化阶段来达到成熟状态的例子和想法。
</details></li>
</ul>
<hr>
<h2 id="Shepherd-A-Critic-for-Language-Model-Generation"><a href="#Shepherd-A-Critic-for-Language-Model-Generation" class="headerlink" title="Shepherd: A Critic for Language Model Generation"></a>Shepherd: A Critic for Language Model Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04592">http://arxiv.org/abs/2308.04592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/shepherd">https://github.com/facebookresearch/shepherd</a></li>
<li>paper_authors: Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean O’Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz</li>
<li>for: 这个论文是为了提出一种基于语言模型的自修复技术，以提高语言模型的输出质量。</li>
<li>methods: 该论文使用了一个特定的语言模型（Shepherd），通过 crítique 答案和提供修复建议来扩展语言模型的能力，并使用高质量的反馈数据集来支持。</li>
<li>results: 根据GPT-4的评价，Shepherd的评价与其他成熔比赛的模型相当或更高（53-87%的胜率），而在人工评价中，Shepherd优于其他模型，并与ChatGPT相对较为均衡。<details>
<summary>Abstract</summary>
As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.
</details>
<details>
<summary>摘要</summary>
large language models 的改进引起了越来越多的关注，这些技术可以利用这些模型的能力来优化其输出。在这项工作中，我们介绍Shepherd，一种特地适应批判回答和提供修正的语言模型，超出了未调节模型的能力，能够识别多种错误并提供修正方案。我们的方法的核心是高质量的反馈数据集，我们从社区反馈和人工标注中筛选出来。尽管Shepherd只有7B个参数，但它的批判比与已有的模型，如ChatGPT相当或更好。使用GPT-4进行评估，Shepherd的平均胜率为53-87%，与竞争对手相比。在人类评估中，Shepherd严格超越了其他模型，平均与ChatGPT相对。
</details></li>
</ul>
<hr>
<h2 id="Temporal-DINO-A-Self-supervised-Video-Strategy-to-Enhance-Action-Prediction"><a href="#Temporal-DINO-A-Self-supervised-Video-Strategy-to-Enhance-Action-Prediction" class="headerlink" title="Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction"></a>Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04589">http://arxiv.org/abs/2308.04589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izzeddin Teeti, Rongali Sai Bhargav, Vivek Singh, Andrew Bradley, Biplab Banerjee, Fabio Cuzzolin</li>
<li>for: This paper is written for improving the action prediction in computer vision applications such as autonomous driving, activity analysis, and human-computer interaction.</li>
<li>methods: The paper introduces a novel self-supervised video strategy called Temporal-DINO, which uses two models (a “student” and a “teacher”) to learn future context by only observing past frames.</li>
<li>results: The experimental results show that the proposed method achieves significant improvements in prediction performance across different architectures, with an average enhancement of 9.9% Precision Points (PP), and demonstrates efficiency in terms of the pretraining dataset size and the number of epochs required.<details>
<summary>Abstract</summary>
The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task using 3D-ResNet, Transformer, and LSTM architectures. The experimental results showcase significant improvements in prediction performance across these architectures, with our method achieving an average enhancement of 9.9% Precision Points (PP), highlighting its effectiveness in enhancing the backbones' capabilities of capturing long-term dependencies. Furthermore, our approach demonstrates efficiency regarding the pretraining dataset size and the number of epochs required. This method overcomes limitations present in other approaches, including considering various backbone architectures, addressing multiple prediction horizons, reducing reliance on hand-crafted augmentations, and streamlining the pretraining process into a single stage. These findings highlight the potential of our approach in diverse video-based tasks such as activity recognition, motion planning, and scene understanding.
</details>
<details>
<summary>摘要</summary>
新兴的动作预测领域在计算机视觉应用中扮演着重要角色，包括自主驾驶、活动分析和人机交互。尽管有 significante 进步，但准确预测未来动作仍然是一个挑战，因为视频数据中存在高维度、复杂的动态和内在的不确定性。传统的监督方法需要大量标注数据，这是时间consuming 和成本高的。这篇文章介绍了一种新的无监督视频策略，以提高动作预测， inspirited  by DINO（自我混合无标签）。Temporal-DINO方法使用两个模型：一个“学生”处理过去帧，一个“老师”处理过去和未来帧，这使得学生可以学习未来上下文。在训练过程中，老师指导学生通过只看过去帧来学习未来上下文。这种策略在 ROAD 数据集上进行动作预测下渠道任务中使用 3D-ResNet、Transformer 和 LSTM 架构进行评估。实验结果显示，我们的方法可以在这些架构上提高预测性能，typically 9.9% 精度点（PP），这说明我们的方法可以增强核心的长期依赖能力。此外，我们的方法也具有效率的优势，包括预训练数据集大小和轮数 requirement 的减少。这种方法超越了其他方法的限制，包括考虑多种核心架构、 Addressing 多个预测时间 horizons、减少手动制作的扩展和单一预训练过程。这些发现表明我们的方法在多个视频基于任务中具有潜在的优势，例如活动识别、运动规划和场景理解。
</details></li>
</ul>
<hr>
<h2 id="Developmental-Bootstrapping-From-Simple-Competences-to-Intelligent-Human-Compatible-AIs"><a href="#Developmental-Bootstrapping-From-Simple-Competences-to-Intelligent-Human-Compatible-AIs" class="headerlink" title="Developmental Bootstrapping: From Simple Competences to Intelligent Human-Compatible AIs"></a>Developmental Bootstrapping: From Simple Competences to Intelligent Human-Compatible AIs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04586">http://arxiv.org/abs/2308.04586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Stefik, Robert Price</li>
<li>for: 创建人类compatible的AI（create robust, trustworthy, and human-compatible AIs）</li>
<li>methods: 发展bootstrapping方法（developmental bootstrapping approach）</li>
<li>results: 未达到成年人类水平的能力（have not yet reached adult-level competences）<details>
<summary>Abstract</summary>
Although some AIs surpass human abilities in closed artificial worlds such as board games, in the real world they make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. Mainstream approaches for creating AIs include the traditional manually-constructed symbolic AI approach and the generative and deep learning AI approaches including large language models (LLMs). Although it is outside of the mainstream, the developmental bootstrapping approach may have more potential. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. They interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and learn from people and establish perceptual, cognitive, and common grounding. They acquire the competences they need through competence bootstrapping. However, developmental robotics has not yet produced AIs with robust adult-level competences. Projects have typically stopped before reaching the Toddler Barrier. This corresponds to human infant development at about two years of age, before infant speech becomes fluent. They also do not bridge the Reading Barrier, where they could skillfully and skeptically draw on the socially developed online information resources that power LLMs. The next competences in human cognitive development involve intrinsic motivation, imitation learning, imagination, coordination, and communication. This position paper lays out the logic, prospects, gaps, and challenges for extending the practice of developmental bootstrapping to create robust, trustworthy, and human-compatible AIs.
</details>
<details>
<summary>摘要</summary>
尽管一些人工智能在封闭的人工世界中超越人类能力，但在真实世界中它们会做奇怪的错误并不会注意到它们。它们不易教育，失去常识，缺乏好奇心。主流的创造人工智能方法包括传统的手动构建符号AI方法和生成和深度学习AI方法，包括大型语言模型（LLM）。虽然它不在主流，但开发启动approach可能具有更大的潜力。在开发启动中，人工智能发展出 Competences 像人类孩子一样。它们从内在的 Competences 开始，与环境互动，从互动学习。它们逐步增强内在 Competences 自己发展出的 Competences。它们与人类交互，学习人类的语言、认知和共同基础。它们通过 Competence 启动获得需要的 Competences。然而，开发机器人学还没有生成成熟的人类水平 Competences。项目通常在达到婴儿障碍（Toddler Barrier）前就停止。这与人类婴儿发展相对应，约两岁时， antes que el habla fluente。它们也不能跨越阅读障碍（Reading Barrier），可以 skillfully 和skeptically draw on the socially developed online information resources that power LLMs。人类认知发展中下一个 Competences 包括内在动机、模仿学习、想象力、协调和communication。这篇position paper 描述了开发启动的逻辑、前景、潜在的差距和挑战，以创建可靠、可信任的人类兼容AI。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures"><a href="#Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures" class="headerlink" title="Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures"></a>Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04539">http://arxiv.org/abs/2308.04539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash</li>
<li>for: 这篇论文主要针对问题是如何实现不断学习，即无需占用大量存储空间就可以在数据流中不断学习。</li>
<li>methods: 作者提出了一种基于生物学原理的轻量级神经网络架构，该架构包括synaptic plasticity机制和神经调控，可以在在线学习过程中不断学习，而无需使用杂谱缓冲或重播。</li>
<li>results: 作者在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100数据集上实现了在线不断学习的superior性能，并且与其他存储受限的学习方法相比，与STATE-OF-THE-ART的存储充足的重播基于方法相当。此外，作者还将这些设计元素 интеGRATE到其他Backpropagation-based continual learning算法中，提高了它们的准确性。<details>
<summary>Abstract</summary>
The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.   Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.
</details>
<details>
<summary>摘要</summary>
<<SYS>>为设计智能系统，持续学习能力是关键。许多持续学习方法依赖于梯度下降和其变体，这会导致稳定性、贪吃和短期记忆限制。为解决这一限制，我们开发了基于生物学原理的轻量级神经网络架构，包括synaptic plasticity机制和 neuromodulation，从而通过本地错误信号来实现在线持续学习无需梯度下降。我们的方法在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100数据集上表现出色，比其他内存限制的学习方法更好，并与state-of-the-art内存占用重的播放方法匹配。我们还将关键设计元素integrated into other backpropagation-based continual learning algorithms，显著提高了它们的准确性。我们的结果提供了迫使生物学原理integrated into机器学习模型的证据，并提供了如何通过这些原理来设计更高效和可靠的在线持续学习系统。
</details></li>
</ul>
<hr>
<h2 id="Generating-Modern-Persian-Carpet-Map-by-Style-transfer"><a href="#Generating-Modern-Persian-Carpet-Map-by-Style-transfer" class="headerlink" title="Generating Modern Persian Carpet Map by Style-transfer"></a>Generating Modern Persian Carpet Map by Style-transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04529">http://arxiv.org/abs/2308.04529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dorsa Rahmatian, Monireh Moshavash, Mahdi Eftekhari, Kamran Hoseinkhani</li>
<li>for: 用Deep Neural Networks(DNN)生成现代波斯织革图。</li>
<li>methods: 提议了三种不同的DNN样式转移方法，包括Style-Swap方法、Clip-Styler方法、Gatys方法，以及一些颜色化方法。</li>
<li>results: 生成的织革图易得到了用户评价的满意度，并且比传统方法快速。<details>
<summary>Abstract</summary>
Today, the great performance of Deep Neural Networks(DNN) has been proven in various fields. One of its most attractive applications is to produce artistic designs. A carpet that is known as a piece of art is one of the most important items in a house, which has many enthusiasts all over the world. The first stage of producing a carpet is to prepare its map, which is a difficult, time-consuming, and expensive task. In this research work, our purpose is to use DNN for generating a Modern Persian Carpet Map. To reach this aim, three different DNN style transfer methods are proposed and compared against each other. In the proposed methods, the Style-Swap method is utilized to create the initial carpet map, and in the following, to generate more diverse designs, methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition, some methods are examined and introduced for coloring the produced carpet maps. The designed maps are evaluated via the results of filled questionnaires where the outcomes of user evaluations confirm the popularity of generated carpet maps. Eventually, for the first time, intelligent methods are used in producing carpet maps, and it reduces human intervention. The proposed methods can successfully produce diverse carpet designs, and at a higher speed than traditional ways.
</details>
<details>
<summary>摘要</summary>
In our proposed methods, the Style-Swap method is used to create the initial carpet map, and then, to generate more diverse designs, we use the Clip-Styler, Gatys, and Style-Swap methods separately. Additionally, we explore and introduce some methods for coloring the produced carpet maps. The designed maps are evaluated through filled questionnaires, and the results of user evaluations confirm the popularity of the generated carpet maps.For the first time, intelligent methods are used in producing carpet maps, reducing human intervention. Our proposed methods can successfully produce diverse carpet designs at a higher speed than traditional methods.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review"><a href="#Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review" class="headerlink" title="Deep Learning for Diverse Data Types Steganalysis: A Review"></a>Deep Learning for Diverse Data Types Steganalysis: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04522">http://arxiv.org/abs/2308.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Kheddar, Mustapha Hemis, Yassine Himeur, David Megías, Abbes Amira</li>
<li>for: 本研究评论文章旨在提供一个深度学习基于的数字媒体掩盖信息检测方法的系统性评论。</li>
<li>methods: 本文使用的方法包括深度学习、深度跳转学习和深度强化学习等多种方法，以检测数字媒体中隐藏的信息。</li>
<li>results: 本文对多种数字媒体类型进行了检测和分析，并提供了一个系统性的评估 metric 和数据集。同时，文章还提出了未来研究方向和挑战。<details>
<summary>Abstract</summary>
Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.
</details>
<details>
<summary>摘要</summary>
《隐藏通信和抹除检测：一篇现代信息安全领域的综述》Introduction:信息安全领域中，隐藏通信和抹除检测是两个相关的方面。隐藏通信旨在隐藏通信内容，而抹除检测则是检测和恢复隐藏的内容。由于隐藏通信和抹除检测具有广泛的应用前景，特别是在法律执法方面，因此对于找到隐藏的信息是非常重要的。Background:隐藏通信和抹除检测在过去几年中得到了广泛的关注，特别是在cyber犯罪和恐怖主义领域。隐藏通信可以帮助犯罪分子和恐怖分子避免被捕获，甚至是 encrypted 的情况下。因此，了解最新的隐藏信息检测技术是非常重要的。Methodology:本文将提供一个系统性的综述，涵盖了深度学习基于的隐藏信息检测技术。文章将覆盖所有类型的遮盖，包括图像、音频和视频，并讨论了最常用的深度学习技术。此外，文章还将探讨更高级的深度学习技术，如深度传输学习（DTL）和深度奖励学习（DRL），以提高隐藏信息检测系统的性能。Results:本文结合了最新的研究成果，包括数据集和评估指标。文章还进行了深度传输学习（DTL）基于的隐藏信息检测方法的系统性分析，并对不同数据集进行了详细的性能分析。Discussion:本文结束后，我们将对现代深度学习基于的隐藏信息检测领域进行一个系统性的回顾。我们还将讨论一些挑战和未来的研究方向。Conclusion:深度学习基于的隐藏信息检测技术在信息安全领域具有广泛的应用前景。本文提供了一个系统性的综述，涵盖了深度学习基于的隐藏信息检测技术的最新研究成果。我们希望这篇文章可以为读者提供一个全面的了解，并为未来的研究提供一个指导。
</details></li>
</ul>
<hr>
<h2 id="DisCoCat-for-Donkey-Sentences"><a href="#DisCoCat-for-Donkey-Sentences" class="headerlink" title="DisCoCat for Donkey Sentences"></a>DisCoCat for Donkey Sentences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04519">http://arxiv.org/abs/2308.04519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lachlan McPheat, Daphne Wang</li>
<li>for: 本文使用分布式compositional模型解释格雷奇的donkey句子。</li>
<li>methods: 本文基于之前的DisCoCat框架，包括扩展以处理谓词、determiners和相对pronouns。文本使用类型逻辑 sintaxisa paraparse donkey句子，并定义了关系和 вектор空间 semantics。</li>
<li>results: 本文提出了一种类型逻辑 sintaxisa paraparse donkey句子，并通过实验证明了其效果。<details>
<summary>Abstract</summary>
We demonstrate how to parse Geach's Donkey sentences in a compositional distributional model of meaning. We build on previous work on the DisCoCat (Distributional Compositional Categorical) framework, including extensions that model discourse, determiners, and relative pronouns. We present a type-logical syntax for parsing donkey sentences, for which we define both relational and vector space semantics.
</details>
<details>
<summary>摘要</summary>
我们展示了如何使用分布式compositional模型来解析格雷奇的驴句。我们基于之前的DisCoCat（分布式compositional categorical）框架，包括扩展以处理话语、determiners和相对副词。我们提出了一种类型逻辑语法来解析驴句，并对其定义了关系和vector空间 semantics。Note: "分布式compositional" (fēnhuì zhīxìng) is a compound word in Chinese, where "分布式" (fēnhuì) means "distributed" and "compositional" is a loanword from English.
</details></li>
</ul>
<hr>
<h2 id="MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting"><a href="#MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting" class="headerlink" title="MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting"></a>MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04511">http://arxiv.org/abs/2308.04511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/big-data-lab-umbc/sea-ice-prediction">https://github.com/big-data-lab-umbc/sea-ice-prediction</a></li>
<li>paper_authors: Sahara Ali, Jianwu Wang</li>
<li>for: 本研究旨在提出一种基于深度学习的海冰集中度预测模型（MT-IceNet），以提高海冰预测的准确性和可靠性。</li>
<li>methods: 该模型采用了UNet的Encoder-Decoder架构，并利用了时间和空间的skip连接，以处理多个时间流和空间流的数据。</li>
<li>results: 研究表明，使用NSIDC的卫星评估数据和ERA5的大气和海洋变量，MT-IceNet模型在6个月预测时间点上具有60%的预测误差减少，与现有的模型相比。<details>
<summary>Abstract</summary>
Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric and oceanic variables from ERA5 reanalysis product during 1979-2021, we show that our proposed model provides promising predictive performance for per-pixel SIC forecasting with up to 60% decrease in prediction error for a lead time of 6 months as compared to its state-of-the-art counterparts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChatGPT-for-Arabic-Grammatical-Error-Correction"><a href="#ChatGPT-for-Arabic-Grammatical-Error-Correction" class="headerlink" title="ChatGPT for Arabic Grammatical Error Correction"></a>ChatGPT for Arabic Grammatical Error Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04492">http://arxiv.org/abs/2308.04492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sang Yun Kwon, Gagan Bhatia, El Moatez Billah Nagoud, Muhammad Abdul-Mageed</li>
<li>for: 本研究探讨了以人工指令为基础的大语言模型（LLM）在非英语语言中文 grammar error correction（GEC）任务中的表现。</li>
<li>methods: 本研究使用了不同的提示方法和（在上下文中）几拟学习来提高 LLM 的性能。</li>
<li>results: GPT-4 在专家提示下 achieve up to $65.49$ F\textsubscript{1} 分数，较前一个基准值高出约 $5$ 分数。 这表明 LLM 在有限的资源情况下可以提供可靠的数据生成方法，并且可以为模型训练提供有用的数据。<details>
<summary>Abstract</summary>
Recently, large language models (LLMs) fine-tuned to follow human instruction have exhibited significant capabilities in various English NLP tasks. However, their performance in grammatical error correction (GEC) tasks, particularly in non-English languages, remains significantly unexplored. In this paper, we delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made complex due to Arabic's rich morphology. Our findings suggest that various prompting methods, coupled with (in-context) few-shot learning, demonstrate considerable effectiveness, with GPT-4 achieving up to $65.49$ F\textsubscript{1} score under expert prompting (approximately $5$ points higher than our established baseline). This highlights the potential of LLMs in low-resource settings, offering a viable approach for generating useful synthetic data for model training. Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compared to fully fine-tuned models of significantly smaller sizes. This disparity highlights a substantial room for improvements for LLMs. Inspired by methods from low-resource machine translation, we also develop a method exploiting synthetic data that significantly outperforms previous models on two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with $72.19\%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.
</details>
<details>
<summary>摘要</summary>
现在，大型语言模型（LLM）经过人类指导的微调表现出了在英语自然语言处理（NLP）任务中的显著能力。然而，它们在非英语语法错误修正（GEC）任务中的表现仍然尚未得到了足够的探索。在这篇论文中，我们探索了微调后的LLM在阿拉伯语GEC任务中的能力。我们发现，使用不同的提示方法和（Context）少量学习可以获得显著的效果，GPT-4在专家提示下达到了$65.49$ F\textsubscript{1} 分数（相对于我们的基准值，大约5个点高）。这显示了LLM在有限的资源情况下的潜在能力，提供了一种可靠的方法来生成有用的合成数据 для模型训练。尽管我们得到了正面的结果，我们发现微调后的模型，无论其大小，都比完全微调的模型（即模型的大小更小）表现下降。这种差异表明了LLM的大型化可能存在一定的限制。 Drawing inspiration from low-resource机器翻译技术，我们还开发了一种利用合成数据的方法，在两个标准的阿拉伯语 benchmark 上获得了显著的提高。我们的工作设置了新的 SoTA  для阿拉伯语 GEC，分别为$72.19\%$ 和 $73.26$ F\textsubscript{1} 在2014 和 2015 QALB 数据集上。
</details></li>
</ul>
<hr>
<h2 id="SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore"><a href="#SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore" class="headerlink" title="SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"></a>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04430">http://arxiv.org/abs/2308.04430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kernelmachine/silo-lm">https://github.com/kernelmachine/silo-lm</a></li>
<li>paper_authors: Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer</li>
<li>for: 本研究旨在构建一种可以在法律上合法地使用的语言模型（LM），以满足现有数据使用法规的要求。</li>
<li>methods: 本研究使用了一种新的方法，即在搜索时使用可Parametric Language Model（OLC）和一个可修改的非参数化数据存储（例如，包含版权书籍或新闻）。这种方法可以在搜索时使用高风险数据，而不需要在训练过程中使用它们。</li>
<li>results: 实验结果显示，使用OLC和非参数化数据存储可以大幅提高语言模型的性能， especialy 在不同领域的搜索中。此外，研究还发现了不同的非参数化方法的效果，以及数据存储大小对性能的影响。这些结果表明，可以构建高质量的语言模型，同时遵守法律法规。<details>
<summary>Abstract</summary>
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.
</details>
<details>
<summary>摘要</summary>
Currently, the legality of training language models (LMs) on copyrighted or restricted data is under debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text, and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out-of-domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high-quality language models while mitigating their legal risk.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers"><a href="#Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers" class="headerlink" title="Probabilistic Invariant Learning with Randomized Linear Classifiers"></a>Probabilistic Invariant Learning with Randomized Linear Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04412">http://arxiv.org/abs/2308.04412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Cotta, Gal Yehuda, Assaf Schuster, Chris J. Maddison</li>
<li>for: 本文旨在设计能够保持任务知识的表达力和不变性的模型，而不是耗费过多的计算资源。</li>
<li>methods: 作者提出了一种基于恶的随机化算法的思路，通过接受概率性的通用适应和不变性可以降低计算资源的需求。特别是，作者提出了一类基于随机化的线性模型，称为随机线性分类器（RLCs）。</li>
<li>results: 作者证明了RLCs可以在某些条件下， WITH HIGH PROBABILITY  aproximate any (smooth) function  while preserving invariance to compact group transformations。此外，作者还设计了三种基于RLCs的随机化分类模型，可以在不同的数据上实现概率性和通用适应。最后，作者通过实验表明，这种新的模型在不变任务中可以比 deterministic invariant neural networks 更好地表现。<details>
<summary>Abstract</summary>
Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.
</details>
<details>
<summary>摘要</summary>
“设计能够表达性和保持任务知识的模型是一个在不断增长的问题。现有的解决方案都是在计算资源和存储空间方面做出了牺牲。在这种工作中，我们表明了可以通过随机性来解决这个问题。我们的关键发现是，接受随机性的通用近似和不变性可以降低我们的资源需求。更具体地，我们提出了一类基于随机化的线性模型，称为随机线性分类器（RLCs）。我们给出了参数和样本大小的条件，在这些条件下，RLCs可以，高概率地，近似任何（光滑）函数，同时保持 compact 群变换的不变性。基于这个结果，我们设计了三种随机线性模型，它们可以在分类任务中保持随机性和不变性，并且使用较少的资源。最后，我们通过实验证明这种新类型的模型在不变任务中比 deterministic 抽象神经网络更有优势。”
</details></li>
</ul>
<hr>
<h2 id="Fine-Tuning-Games-Bargaining-and-Adaptation-for-General-Purpose-Models"><a href="#Fine-Tuning-Games-Bargaining-and-Adaptation-for-General-Purpose-Models" class="headerlink" title="Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models"></a>Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04399">http://arxiv.org/abs/2308.04399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Laufer, Jon Kleinberg, Hoda Heidari</li>
<li>for: 这篇论文旨在描述如何在机器学习（ML）和人工智能（AI）领域内实现精细化过程，即将通用模型（Generalist）带到特定领域中（Domain-specialist）进行适应。</li>
<li>methods: 这篇论文使用了谈判解决方案和游戏均衡来研究firms在这类交互中的策略行为，并提供了一种方法来标识Pareto优化的谈判安排。</li>
<li>results: 论文发现，即使一个公司的成本比另一个公司更高，也可以实现利润分享，并且提供了一些方法来确定合理的谈判安排。<details>
<summary>Abstract</summary>
Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contribute, free-ride, or abstain in their uptake of the technology, and we provide conditions yielding these different strategies. We show how methods based on bargaining solutions and sub-game perfect equilibria provide insights into the strategic behavior of firms in these types of interactions, and we find that profit-sharing can still arise even when one firm has significantly higher costs than another. We also provide methods for identifying Pareto-optimal bargaining arrangements for a general set of utility functions.
</details>
<details>
<summary>摘要</summary>
大量的机器学习（ML）和人工智能（AI）创新都在形式为开发和发布通用模型。这些模型是为其他企业和机构用于特定领域功能而设计的，并且可以通过精度调整来适应不同的领域。这个过程被称为调整或精度调整。这篇论文提出了调整过程中一个通用者和一个或多个领域专家之间的合作模型。这两个实体都是追求利润的，并且投入技术时需要支付成本。为了将技术投入到市场上，他们需要达成协议来分配收益。为一类相对通用的成本和收益函数，我们Characterize了调整游戏中的盈利分享解决方案的条件。我们发现，在采用这种技术时，任何领域专业化都可能会为其投入、免费享用或决不使用技术，并且我们提供了这些不同策略的条件。我们发现，基于谈判解决方案和下游完整平衡的方法可以提供关于企业在这类互动中的策略性行为的深入理解，并且我们发现，盈利分享可以在一个实体有较高成本时仍然出现。此外，我们还提供了一种方法来标识通用集成函数的Pareto优化协议。
</details></li>
</ul>
<hr>
<h2 id="Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining"><a href="#Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining" class="headerlink" title="Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining"></a>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04396">http://arxiv.org/abs/2308.04396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Blatt, Patrick Delfmann, Petra Schubert</li>
<li>For: The paper is written for Process Mining (PM) and Enterprise Collaboration Systems (ECS).* Methods: The paper proposes a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities with the system-generated low-level traces.* Results: The algorithm produces accurate results.Here’s the information in Simplified Chinese text, as requested:* For: 这篇论文是为了进程挖掘（PM）和企业协作系统（ECS）所写的。* Methods: 论文提出了一种适应ECS事件抽象（ECSEA）方法，通过比较记录的实际用户活动（高级踪迹）与系统生成的低级踪迹（从ECS中提取的）来训练模型。* Results: 算法生成的结果准确。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.
</details>
<details>
<summary>摘要</summary>
一个目标 OF 过程挖掘（PM）是从信息系统事件日志中发现过程模型。PM 已经成功应用于进程 oriented 企业系统，但是它在交流和文档 oriented 企业协作系统（ECS）中 menos 适用。ECS 事件日志具有特殊的特点，PM 应用于其日志会导致蛇形模型。一种常见的解决方案是事件抽象，即将低级别的日志转换为更高级别的日志，以便在发现算法中使用。ECS 日志具有特殊的特点，已经不完全由现有的事件抽象方法解决。我们的目标是通过适应 ECS 事件抽象（ECSEA）方法，训练一个模型，将记录的实际用户活动（高级跟踪）与系统生成的低级别跟踪（从 ECS 提取）进行比较。这个模型可以自动将未来的低级别跟踪转换为抽象的高级别日志，用于 PM。我们的评估表明，该算法生成的结果准确。ECSEA 是一种必需的预处理方法，用于解释 ECS 中的协作工作活动，我们称之为社交过程挖掘。
</details></li>
</ul>
<hr>
<h2 id="Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries"><a href="#Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries" class="headerlink" title="Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries"></a>Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10875">http://arxiv.org/abs/2308.10875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elviscuihan/csoma">https://github.com/elviscuihan/csoma</a></li>
<li>paper_authors: Elvis Han Cui, Zizhao Zhang, Culsome Junwen Chen, Weng Kee Wong</li>
<li>for: 本研究用一种新提出的自然引导算法 Competitive Swarm Optimizer with Mutated Agents (CSO-MA) 应用于各种统计科学中的优化问题，以示其灵活性和与其他算法的比较。</li>
<li>methods: 本研究使用CSO-MA算法，可以处理不同的成本结构或多个用户指定的非线性约束。</li>
<li>results: 本研究在不同的优化问题中应用CSO-MA算法，如找到单个维度泛化趋势模型中参数的最大可能性估计、教育研究中常用的拉希模型参数估计、Markov renewal模型中Cox回归估计和两个分 комpartment模型中缺失值补充等。此外，还应用到生态学问题中选取最佳变量和制造业中用logistic模型与多个交互因素进行车辆燃料实验的设计。<details>
<summary>Abstract</summary>
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two compartment model. In addition we discuss applications to (v) select variables optimally in an ecology problem and (vi) design a car refueling experiment for the auto industry using a logistic model with multiple interacting factors.
</details>
<details>
<summary>摘要</summary>
自然 inspirited  мета希顿算法是人工智能中重要的组件，广泛应用于各个领域解决各种复杂的优化问题。我们应用了一种新提出的自然 inspirited  meta希顿算法called 竞争群体优化器with 突变代理（CSO-MA），并证明其灵活性和相比其他竞争者的出色表现在各种优化问题中。具体来说，我们表明该算法可以有效地处理不同的成本结构或多个用户指定的非线性约束。我们的应用包括（i）在生物信息学中使用单个维度泛化趋势模型来找到最大感受度参数的最佳估计，（ii）在教育研究中使用 Rasch 模型来估计参数，（iii）使用 Cox 回归模型来找到 M-估计，（iv）对两个部件模型中的缺失值进行完成，以及（v）在生态学问题中选取最佳变量，（vi）采用 Logistic 模型与多个交互因素来设计汽车燃油实验。
</details></li>
</ul>
<hr>
<h2 id="AdaptEx-A-Self-Service-Contextual-Bandit-Platform"><a href="#AdaptEx-A-Self-Service-Contextual-Bandit-Platform" class="headerlink" title="AdaptEx: A Self-Service Contextual Bandit Platform"></a>AdaptEx: A Self-Service Contextual Bandit Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08650">http://arxiv.org/abs/2308.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Black, Ercument Ilhan, Andrea Marchini, Vilda Markeviciute</li>
<li>for: 这篇论文旨在提出一种自服务上下文链投机平台，以便在Expedia集团 scale上个性化用户体验。</li>
<li>methods: 该平台使用多臂铁人投机算法个性化每位访客的体验，并快速从每次互动中学习。</li>
<li>results: 该平台可以快速提高用户体验，降低传统测试方法相关的成本和时间。它还能够在内容不断变化和连续”冰封”情况下妥协很好地适应。<details>
<summary>Abstract</summary>
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了Expedia Group广泛使用的自助上下文强制投机平台AdaptEx，该平台利用多臂强制投机算法个性化用户体验，并快速学习每次用户互动。它提供了改善用户体验的强大解决方案，同时减少传统测试方法相关的成本和时间。该平台允许快速迭代到优质产品解决方案，即使在不断变化的内容和连续“冷启动”情况下也能够 gracefully adapt。
</details></li>
</ul>
<hr>
<h2 id="Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making"><a href="#Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making" class="headerlink" title="Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making"></a>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04375">http://arxiv.org/abs/2308.04375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Hun Lee, Chong Jun Chew</li>
<li>for: 这个研究旨在帮助人类决策者更好地与人工智能（AI）合作，以提高决策质量。</li>
<li>methods: 这个研究使用了特征解释和对比解释来帮助人类审查AI建议，以减少对AI的过度依赖。</li>
<li>results: 研究发现，当AI建议正确时，both therapists和laypersons可以通过特征解释和对比解释来提高审查性和一致性。然而，当AI建议错误时，对比解释可以帮助both therapists和laypersons减少对错误AI建议的过度依赖。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在高度决策领域（如医疗）中被越来越广泛使用以协助人类决策。然而，研究人员发现，人们可能会过度依赖错误的AI模型建议而不是实现人类AI协同性能。在这种情况下，我们使用了突出性特征解释以及对其他选项的对比解释，以便让人类更加分析地审查AI建议，并且研究这些解释对信任和依赖AI的影响。我们在评估后期生存者质量动作任务上进行了实验，并分析了参与者的表现、同意水平和无AI和两种AI解释情况下的AI依赖度。我们的结果显示，带有突出性特征和对比解释的AI模型可以帮助治疗师和非专业人员提高表现和同意水平。然而，两者都会过度依赖错误的AI输出，并且对比解释可以帮助两者减少对错误AI输出的依赖度，相比突出性特征解释下降21%。特别是，非专业人员在使用突出性特征解释时表现下降18.0 f1-score，而使用对比解释时表现下降14.0 f1-score，与治疗师表现下降8.6和2.8 f1-score相比。我们的研究表明，对比解释可以更好地估计AI模型的准确性，降低对错误AI输出的依赖度，并对人类AI协同决策产生影响。
</details></li>
</ul>
<hr>
<h2 id="Some-Options-for-Instantiation-of-Bipolar-Argument-Graphs-with-Deductive-Arguments"><a href="#Some-Options-for-Instantiation-of-Bipolar-Argument-Graphs-with-Deductive-Arguments" class="headerlink" title="Some Options for Instantiation of Bipolar Argument Graphs with Deductive Arguments"></a>Some Options for Instantiation of Bipolar Argument Graphs with Deductive Arguments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04372">http://arxiv.org/abs/2308.04372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anthony Hunter</li>
<li>for: 本研究旨在提供一种基于逻辑 Argument 的 Framework，用于实例化二分olar Argument Graph，以更好地理解 Argument 的内部结构和它们之间的交互。</li>
<li>methods: 本研究使用逻辑 Argument 来实例化二分olar Argument Graph，并提出了一些可能的约束，以考虑 Argument 的内部结构和它们之间的关系类型。</li>
<li>results: 本研究的结果可以帮助我们更好地理解二分olar Argument Graph 中的 Argument 和它们之间的交互，并提供一种基于逻辑 Argument 的 Framework 来实现这一目标。<details>
<summary>Abstract</summary>
Argument graphs provide an abstract representation of an argumentative situation. A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another. Here we assume that the influence is supporting, attacking, or ambiguous. In a bipolar argument graph, each argument is atomic and so it has no internal structure. Yet to better understand the nature of the individual arguments, and how they interact, it is important to consider their internal structure. To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments, and the types of relationship between arguments.
</details>
<details>
<summary>摘要</summary>
Argument graphs provide an abstract representation of an argumentative situation. A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another. Here we assume that the influence is supporting, attacking, or ambiguous. In a bipolar argument graph, each argument is atomic and so it has no internal structure. However, to better understand the nature of the individual arguments and how they interact, it is important to consider their internal structure. To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments and the types of relationships between them.
</details></li>
</ul>
<hr>
<h2 id="Cumulative-Reasoning-with-Large-Language-Models"><a href="#Cumulative-Reasoning-with-Large-Language-Models" class="headerlink" title="Cumulative Reasoning with Large Language Models"></a>Cumulative Reasoning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04371">http://arxiv.org/abs/2308.04371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iiis-ai/cumulative-reasoning">https://github.com/iiis-ai/cumulative-reasoning</a></li>
<li>paper_authors: Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao</li>
<li>for:  solves complex problems with human-like thought processes</li>
<li>methods:  employs language models in a cumulative and iterative manner, decomposing tasks into smaller components</li>
<li>results:  consistently outperforms existing methods with an improvement up to 9.3%, achieves 98.04% accuracy on the curated FOLIO wiki dataset, and achieves 94% accuracy on the Game of 24 with a 20% enhancement over the previous state-of-the-art method.Here’s the full text in Simplified Chinese:</li>
<li>for:  solves complex problems with human-like thought processes</li>
<li>methods:  employs language models in a cumulative and iterative manner, decomposing tasks into smaller components</li>
<li>results:  consistently outperforms existing methods with an improvement up to 9.3%, achieves 98.04% accuracy on the curated FOLIO wiki dataset, and achieves 94% accuracy on the Game of 24 with a 20% enhancement over the previous state-of-the-art method.<details>
<summary>Abstract</summary>
While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94%, which signifies a substantial enhancement of 20% over the previous state-of-the-art method (code is available at https://github.com/iiis-ai/cumulative-reasoning).
</details>
<details>
<summary>摘要</summary>
While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94%, which signifies a substantial enhancement of 20% over the previous state-of-the-art method (code is available at https://github.com/iiis-ai/cumulative-reasoning).Here's the word-for-word translation of the text into Simplified Chinese: whilst language models powerful versatile often fail address highly complex problems . This because solving complex problems requires deliberate thinking , which has been only minimally guided during training . In this paper , we propose new method called Cumulative Reasoning (CR) , which employs language models in cumulative iterative manner emulate human thought processes . By decomposing tasks smaller components , CR streamlines problem-solving process , rendering it both more manageable effective . For logical inference tasks , CR consistently outperforms existing methods with improvement up 9.3% , and achieves astonishing accuracy 98.04% on curated FOLIO wiki dataset . In context of Game of 24 , CR achieves accuracy 94% , which signifies substantial enhancement 20% over previous state-of-the-art method (code available at https://github.com/iiis-ai/cumulative-reasoning) .
</details></li>
</ul>
<hr>
<h2 id="Learning-Unbiased-Image-Segmentation-A-Case-Study-with-Plain-Knee-Radiographs"><a href="#Learning-Unbiased-Image-Segmentation-A-Case-Study-with-Plain-Knee-Radiographs" class="headerlink" title="Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs"></a>Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04356">http://arxiv.org/abs/2308.04356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nickolas Littlefield, Johannes F. Plate, Kurt R. Weiss, Ines Lohse, Avani Chhabra, Ismaeel A. Siddiqui, Zoe Menezes, George Mastorakos, Sakshi Mehul Thakar, Mehrnaz Abedian, Matthew F. Gong, Luke A. Carlson, Hamidreza Moradi, Soheyla Amirian, Ahmad P. Tafti</li>
<li>for: 这个研究的目的是探讨深度学习算法在骨灰质影像分割中存在的可见性偏见，以及如何通过 Mitigation Strategies 来纠正这些偏见。</li>
<li>methods: 这篇研究使用了深度学习算法来进行骨灰质影像分割，并使用了plain radiographs进行训练。</li>
<li>results: 研究发现了gender和racial偏见，并提出了一些 Mitigation Strategies来纠正这些偏见，以确保公平和不偏见的分割结果。<details>
<summary>Abstract</summary>
Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings. While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited. This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases. The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging. The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results. Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision.
</details>
<details>
<summary>摘要</summary>
自动 segmentation of knee 骨骼结构是orthopedics中的一项基础技术，已经在预操作和后操作设置中存在几年之久。深度学习算法在医疗影像分析中表现出色，但评估公平和可能的偏见在这些模型中仍然有限。本研究旨在通过使用平面X光图像来探索深度学习 powers knee-bony anatomy segmentation中可见的性别和种族偏见。本贡献可能提高我们对偏见的理解，并提供实践的建议 для研究人员和实践者在医疗影像领域。提出的mitigation strategies可以抑制性别和种族偏见，确保公平和不偏见的segmentation结果。此外，这种工作促进了多样化患者人口群的准确诊断和治疗结果，推动了公平和包容的医疗服务。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.AI_2023_08_09/" data-id="clpxp6bw20025ee88f65m5ubn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.CL_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T11:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.CL_2023_08_09/">cs.CL - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection"><a href="#Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection" class="headerlink" title="Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection"></a>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04950">http://arxiv.org/abs/2308.04950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafna81/fakenewsdetection">https://github.com/shafna81/fakenewsdetection</a></li>
<li>paper_authors: Shafna Fitria Nur Azizah, Hasan Dwi Cahyono, Sari Widya Sihwi, Wisnu Widiarto</li>
<li>for: 本研究旨在探讨使用 transformer 模型 для检测假新闻在印度尼西亚语言中的表现。</li>
<li>methods: 本研究使用了 ALBERT 和 RoBERTa 两种改进的 transformer 模型，并对其进行比较，以检测假新闻的性能。</li>
<li>results: 研究发现，使用 ALBERT 模型可以达到 87.6% 的准确率、86.9% 的精度、86.9% F1 分数和 174.5 次&#x2F;秒（epoch）的运行时间，超过了非 transformer 方法的性能。<details>
<summary>Abstract</summary>
Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa. However, the modified BERT models are not well explored for detecting fake news in Bahasa Indonesia. In this research, we explore those transformer models and found that ALBERT outperformed other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch) respectively. Source code available at: https://github.com/Shafna81/fakenewsdetection.git
</details>
<details>
<summary>摘要</summary>
假新闻是指在新闻媒体格式中存在假信息，但是由新闻机构不当处理而导致的假物。假新闻可能会诋毁或攻击重要个体或组织，甚至是为个人利益。分辨假新闻和真实新闻是困难的，因为有限的领域知识和时间限制。据调查，居民最常受到诈骗和不实信息的地区为印度尼西亚巴仁、特区雅加达和西爪哇。 transformers 是一种人工智能（AI）自然语言处理领域的方法，使用深度学习架构。 transformers 使用强大的注意机制来并行处理文本，生成rich和上下文敏感的单词表示。前一项研究表明，BERT 模型在非 transformer 方法之上显示出超越性，但是一些研究表明，使用改进的 BERT 模型，如 ALBERT 和 RoBERTa，可以提高性能。然而，这些改进 BERT 模型在印度尼西亚语言检测假新闻方面尚未得到充分探索。本研究探讨了这些 transformer 模型，发现 ALBERT 模型在准确率、精度、 F1 分数和运行时间等方面均达到了最高水平，具体数据为 87.6%、86.9%、86.9% 和 174.5（s/epoch）。源代码可以在 GitHub 上找到：https://github.com/Shafna81/fakenewsdetection.git。
</details></li>
</ul>
<hr>
<h2 id="Extrapolating-Large-Language-Models-to-Non-English-by-Aligning-Languages"><a href="#Extrapolating-Large-Language-Models-to-Non-English-by-Aligning-Languages" class="headerlink" title="Extrapolating Large Language Models to Non-English by Aligning Languages"></a>Extrapolating Large Language Models to Non-English by Aligning Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04948">http://arxiv.org/abs/2308.04948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Zhu, Yunzhe Lv, Qingxiu Dong, Fei Yuan, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, Lei Li</li>
<li>for: 提高大语言模型（LLM）对非英语语言的能力</li>
<li>methods: 使用语义对齐和指令调整来强化预训练的LLM在非英语语言上</li>
<li>results: x-LLaMA模型在六种非英语语言的跨语言标准 bencmark 上平均高于英语 instrucction-tuned 对手（Alpaca） by 42.50%，并在中文人文任务上达到了8.2%的提升。<details>
<summary>Abstract</summary>
Due to the unbalanced training data distribution, the language ability of large language models (LLMs) is often biased towards English. In this paper, we propose to empower pre-trained LLMs on non-English languages by building semantic alignment across languages. We perform instruction-tuning on LLaMA with both translation task data and cross-lingual general task data to obtain cross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark XQUAD and MLQA show that x-LLaMA models outperform the English instruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English languages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA achieves significant improvement on Chinese humanities tasks, outperforming Alpaca by 8.2%. We also discover that incorporating non-English text on the target side of translation data is particularly effective for boosting non-English ability. Besides, we find that semantic alignment within LLM can be further strengthened as translation task data scales up and we present the formulation of the underlying scaling law. Evaluation results on translation dataset Flores-101 show that \method outperforms previous LLaMA-based models in all evaluated directions. Code and data will be available at: https://github.com/OwenNJU/x-LLM.
</details>
<details>
<summary>摘要</summary>
由于训练数据的不均衡分布，大型自然语言模型（LLM）的语言能力 часто受到英语的影响。在这篇论文中，我们提出了使用语义对Alignment来强化预训练的LLM在非英语语言上的能力。我们通过对LLaMA进行 instrucion-tuning，使用翻译任务数据和跨语言通用任务数据来获得跨语言模型（x-LLaMA）。实验结果表明，x-LLaMA模型在六种非英语语言的跨语言标准 bencmark XQUAD和MLQA上的表现比英语 instrucion-tuned counterpart（Alpaca）提高42.50%的平均值。进一步的实验表明，x-LLaMA在中文人文任务上 achieve  significan improvement，比Alpaca提高8.2%。我们还发现，在目标语言的翻译数据中包含非英语文本时，特别有效地提高非英语能力。此外，我们发现在翻译任务数据尺度上，LLM的语义对Alignment可以进一步强化。我们还提出了翻译数据集Flores-101上的扩展法则。评估结果表明，我们的方法在所有评估方向上都超过了之前的LLaMA-based模型。代码和数据将在https://github.com/OwenNJU/x-LLM上公开。
</details></li>
</ul>
<hr>
<h2 id="Integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia"><a href="#Integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia" class="headerlink" title="Integrating large language models and active inference to understand eye movements in reading and dyslexia"></a>Integrating large language models and active inference to understand eye movements in reading and dyslexia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04941">http://arxiv.org/abs/2308.04941</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/donnarumma/hai_language">https://github.com/donnarumma/hai_language</a></li>
<li>paper_authors: Francesco Donnarumma, Mirco Frosolone, Giovanni Pezzulo</li>
<li>for:  simulating reading and eye movements using a computational model</li>
<li>methods:  hierarchical active inference, combining strengths of large language models and active inference</li>
<li>results:  proficiency in reading known and unknown words and sentences, exploration of maladaptive inference effects in dyslexia, potential implications for understanding and addressing dyslexia<details>
<summary>Abstract</summary>
We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences.   Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual-route theories of reading. Notably, our model permits the exploration of maladaptive inference effects on eye movements during reading, such as in dyslexia. To simulate this condition, we attenuate the contribution of priors during the reading process, leading to incorrect inferences and a more fragmented reading style, characterized by a greater number of shorter saccades. This alignment with empirical findings regarding eye movements in dyslexic individuals highlights the model's potential to aid in understanding the cognitive processes underlying reading and eye movements, as well as how reading deficits associated with dyslexia may emerge from maladaptive predictive processing.   In summary, our model represents a significant advancement in comprehending the intricate cognitive processes involved in reading and eye movements, with potential implications for understanding and addressing dyslexia through the simulation of maladaptive inference. It may offer valuable insights into this condition and contribute to the development of more effective interventions for treatment.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的计算模型，使用层次活动推理来模拟阅读和视力运动。该模型将语言处理视为推理过程中的层次生成模型，从而实现不同级别的预测和推理，从音节到句子。我们的方法结合了大型语言模型的实用性和活动推理的指导力，以便测试预测。模型能够预测已知和未知词和句子，并且遵循 dual-route 理论中的词和非词路径分离。特别是，我们的模型允许探索误差推理对视力运动的影响，如阅读障碍。为了模拟这种情况，我们在阅读过程中减少了假设的影响，导致错误的推理和更多的短暂快速跳跃，这与词 Reading 障碍者的实际观察结果相符。这种对models 的应用可能为理解阅读和视力运动的认知过程提供valuable 信息，以及如何通过模拟误差推理来理解和治疗阅读障碍。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance"><a href="#Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance" class="headerlink" title="Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance"></a>Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04886">http://arxiv.org/abs/2308.04886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sourya Dipta Das, Yash Vadi, Abhishek Unnam, Kuldeep Yadav</li>
<li>for: 本研究旨在提高 dialect classification 系统的总性性能，并应对实际场景中可能出现的异常输入。</li>
<li>methods: 我们提出了一种基于 Mahalanobis 距离的无监督方法，使用 wav2vec 2.0 变换器模型的所有中间层 embedding 进行多任务学习。</li>
<li>results: 我们的方法与其他现有的 OOD 检测方法比较，显著地提高了检测准确率。<details>
<summary>Abstract</summary>
Dialect classification is used in a variety of applications, such as machine translation and speech recognition, to improve the overall performance of the system. In a real-world scenario, a deployed dialect classification model can encounter anomalous inputs that differ from the training data distribution, also called out-of-distribution (OOD) samples. Those OOD samples can lead to unexpected outputs, as dialects of those samples are unseen during model training. Out-of-distribution detection is a new research area that has received little attention in the context of dialect classification. Towards this, we proposed a simple yet effective unsupervised Mahalanobis distance feature-based method to detect out-of-distribution samples. We utilize the latent embeddings from all intermediate layers of a wav2vec 2.0 transformer-based dialect classifier model for multi-task learning. Our proposed approach outperforms other state-of-the-art OOD detection methods significantly.
</details>
<details>
<summary>摘要</summary>
<<SYS>>dialect 分类在多种应用中使用，如机器翻译和语音识别，以提高整体系统性能。在实际场景中，部署的 диалект分类模型可能会遇到不同于训练数据分布的输入，也称为 OUT-OF-DISTRIBUTION（OOD）样本。这些 OOD 样本可能会导致不预期的输出，因为这些 диаLECT 的样本在模型训练时未被考虑。 OUT-OF-DISTRIBUTION 检测是一个新的研究领域，在 диалект分类上尚未受到充分关注。为了解决这个问题，我们提出了一种简单 yet 有效的无监督 Mahalanobis 距离特征基于方法。我们利用了所有 intermediate layer 的 latent 嵌入，来进行多任务学习。我们的提议方法在比较其他现有的 OOD 检测方法时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Information-Theoretic-Characterization-of-Vowel-Harmony-A-Cross-Linguistic-Study-on-Word-Lists"><a href="#Information-Theoretic-Characterization-of-Vowel-Harmony-A-Cross-Linguistic-Study-on-Word-Lists" class="headerlink" title="Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists"></a>Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04885">http://arxiv.org/abs/2308.04885</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uds-lsv/vowel-harmony-from-word-lists">https://github.com/uds-lsv/vowel-harmony-from-word-lists</a></li>
<li>paper_authors: Julius Steuer, Badr Abdullah, Johann-Mattis List, Dietrich Klakow</li>
<li>for: 这项研究的目的是使用数据驱动的计算模型量化口音协调。</li>
<li>methods: 研究人员使用了语音模型（PLMs）来定义一种信息论 metric来衡量口音协调的程度。</li>
<li>results: 研究人员通过使用不含扩Difficult inflection的词形来覆盖更多的语言，并使用word list来训练模型，成功地捕捉了一些语言中的口音协调模式。<details>
<summary>Abstract</summary>
We present a cross-linguistic study that aims to quantify vowel harmony using data-driven computational modeling. Concretely, we define an information-theoretic measure of harmonicity based on the predictability of vowels in a natural language lexicon, which we estimate using phoneme-level language models (PLMs). Prior quantitative studies have relied heavily on inflected word-forms in the analysis of vowel harmony. We instead train our models using cross-linguistically comparable lemma forms with little or no inflection, which enables us to cover more under-studied languages. Training data for our PLMs consists of word lists with a maximum of 1000 entries per language. Despite the fact that the data we employ are substantially smaller than previously used corpora, our experiments demonstrate the neural PLMs capture vowel harmony patterns in a set of languages that exhibit this phenomenon. Our work also demonstrates that word lists are a valuable resource for typological research, and offers new possibilities for future studies on low-resource, under-studied languages.
</details>
<details>
<summary>摘要</summary>
我们发表了一项跨语言研究，旨在使用数据驱动的计算模型量化元音协调。具体来说，我们定义了基于自然语言词典中元音预测性的信息理论度量，并使用语音模型（PLM）来估算。先前的量化研究主要基于语法变化word形式进行分析元音协调。我们 Instead，我们使用跨语言相似的 lemma 形式来训练我们的模型，这使得我们能够更好地涵盖更多的未研究语言。我们的训练数据包括每种语言1000个单词最多的列表。尽管我们使用的数据比之前使用的 corpora 更小，但我们的实验表明我们的神经网络PLMs 能够 Capture 元音协调模式在一组语言中。我们的工作还表明，word lists 是 typological 研究的有价值资源，并且提供了未来研究低资源、未研究语言的新可能性。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Conditioned-Text-Generation-through-Automatic-Prompt-Optimization"><a href="#Emotion-Conditioned-Text-Generation-through-Automatic-Prompt-Optimization" class="headerlink" title="Emotion-Conditioned Text Generation through Automatic Prompt Optimization"></a>Emotion-Conditioned Text Generation through Automatic Prompt Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04857">http://arxiv.org/abs/2308.04857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yarik Menchaca Resendiz, Roman Klinger</li>
<li>for: 这个论文主要目的是提出一种自动生成受情况条件文本的方法，以便在不需要贵重的精度调整或者培育大型语言模型从头开始的情况下，可以达到竞争性的结果。</li>
<li>methods: 这种方法使用迭代优化程序，通过添加、删除或者替换 tokens，对提供的提示进行优化。为了评估优化后的提示的质量，我们使用一个文本分类器，以确定生成文本中是否满足情况条件。</li>
<li>results: 我们在使用这种方法进行情感条件文本生成 task 时，与手动设计的提示相比，能够达到更高的 macro-average F1 值（0.75），而手动设计的seed prompts 只能达到 macro-average F1 值为 0.22。<details>
<summary>Abstract</summary>
Conditional natural language generation methods often require either expensive fine-tuning or training a large language model from scratch. Both are unlikely to lead to good results without a substantial amount of data and computational resources. Prompt learning without changing the parameters of a large language model presents a promising alternative. It is a cost-effective approach, while still achieving competitive results. While this procedure is now established for zero- and few-shot text classification and structured prediction, it has received limited attention in conditional text generation. We present the first automatic prompt optimization approach for emotion-conditioned text generation with instruction-fine-tuned models. Our method uses an iterative optimization procedure that changes the prompt by adding, removing, or replacing tokens. As objective function, we only require a text classifier that measures the realization of the conditional variable in the generated text. We evaluate the method on emotion-conditioned text generation with a focus on event reports and compare it to manually designed prompts that also act as the seed for the optimization procedure. The optimized prompts achieve 0.75 macro-average F1 to fulfill the emotion condition in contrast to manually designed seed prompts with only 0.22 macro-average F1.
</details>
<details>
<summary>摘要</summary>
常用的自然语言生成方法经常需要 either 昂贵的微调或者从scratch学习大型语言模型。两者都不太可能导致良好的结果，除非有庞大的数据和计算资源。提示学习无需改变大型语言模型的参数，表现出了可持续的潜在。这种方法在零和几个shot文本分类和结构预测方面已经得到了广泛的关注，但在条件文本生成方面却受到了有限的关注。我们提出了首个自动提示优化方法 для情感条件文本生成，使用迭代优化过程，通过添加、删除或替换Token来更新提示。我们的方法只需要一个可测量实现条件变量的文本分类器作为目标函数。我们对情感条件文本生成进行评估，并与手动设计的种子提示进行比较。得到的优化提示达到0.75的macro-average F1，以满足情感条件，而手动设计的种子提示只达到0.22的macro-average F1。
</details></li>
</ul>
<hr>
<h2 id="TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks"><a href="#TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks" class="headerlink" title="TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks"></a>TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04832">http://arxiv.org/abs/2308.04832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 这篇论文主要是为了提出一种新的激活函数called Truncated and Signed Square Root (TSSR)函数。</li>
<li>methods: 这篇论文使用了TSSR函数，该函数具有odd、非线性、卷积和导数 kontinuous和总是正的特点。</li>
<li>results: 试验表明，提议的TSSR函数在比较难以学习的问题上表现更好，比如计算机视觉、自然语言处理和语音识别等领域。<details>
<summary>Abstract</summary>
Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:activation functions are crucial components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone, and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other state-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.Note:* "odd" is translated as "奇数" (qīshū)* "nonlinear" is translated as "非线性" (fēi lǐnéng)* "monotone" is translated as "单调" (dāngdiào)* "differentiable" is translated as "可导数" (kědǎoxiàng)* "continuous" is translated as "连续" (liánxù)* "always positive" is translated as "总是正" (zǒngshì zhèng)
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Generation-Capabilities-of-Large-Chinese-Language-Models"><a href="#Evaluating-the-Generation-Capabilities-of-Large-Chinese-Language-Models" class="headerlink" title="Evaluating the Generation Capabilities of Large Chinese Language Models"></a>Evaluating the Generation Capabilities of Large Chinese Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04823">http://arxiv.org/abs/2308.04823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Felixgithub2017/CG-Eval">https://github.com/Felixgithub2017/CG-Eval</a></li>
<li>paper_authors: Hui Zeng, Jingyuan Xue, Meng Hao, Chen Sun, Bin Ning, Na Zhang</li>
<li>for: 这篇论文是为了评估大型中文语言模型在不同学术领域的生成能力而写的。</li>
<li>methods: 这篇论文使用了多种指标来评估模型的生成质量，包括准确率、相关性、朴素质量等。</li>
<li>results: 论文发现大型中文语言模型在六个领域中的生成能力强度不同，sciences and engineering领域的模型表现最好，而judicial examination领域的模型表现最差。同时，论文还提出了一个可重复性的Gscore指标来评估模型的生成质量。<details>
<summary>Abstract</summary>
This paper presents CG-Eval, the first comprehensive evaluation of the generation capabilities of large Chinese language models across a wide range of academic disciplines. The models' performance was assessed based on their ability to generate accurate and relevant responses to different types of questions in six disciplines, namely, Science and Engineering, Humanities and Social Sciences, Mathematical Calculations, Medical Practitioner Qualification Examination, Judicial Examination, and Certified Public Accountant Examination. This paper also presents Gscore, a composite index derived from the weighted sum of multiple metrics to measure the quality of model's generation against a reference. The test data and test results can be found at http://cgeval.besteasy.com/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CLEVA-Chinese-Language-Models-EVAluation-Platform"><a href="#CLEVA-Chinese-Language-Models-EVAluation-Platform" class="headerlink" title="CLEVA: Chinese Language Models EVAluation Platform"></a>CLEVA: Chinese Language Models EVAluation Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04813">http://arxiv.org/abs/2308.04813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyang Li, Jianqiao Zhao, Duo Zheng, Zi-Yuan Hu, Zhi Chen, Xiaohui Su, Yongfeng Huang, Shijia Huang, Dahua Lin, Michael R. Lyu, Liwei Wang</li>
<li>for: 评估中文大型自然语言模型（LLM）的能力 has become an increasingly significant issue, and the paper aims to address this issue by presenting a comprehensive platform for evaluating Chinese LLMs.</li>
<li>methods: The platform, called CLEVA, employs a standardized workflow to assess LLMs’ performance across various dimensions, regularly updating a competitive leaderboard. It also curates a significant proportion of new data and develops a sampling strategy to alleviate contamination.</li>
<li>results: Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA’s efficacy.Here is the same information in Simplified Chinese text:</li>
<li>for: 评估中文大型自然语言模型（LLM）的能力已成为一个越来越重要的问题，该文章提出了一种全面的评估平台。</li>
<li>methods: 该平台叫做CLEVA，它使用标准化的工作流程评估不同维度的LLM表现，定期更新竞争性的 liderboard。它还curates a significant proportion of new data和开发了一种避免污染的采样策略。</li>
<li>results: 23种Influential Chinese LLMs的大规模实验已经验证了CLEVA的有效性。<details>
<summary>Abstract</summary>
With the continuous emergence of Chinese Large Language Models (LLMs), how to evaluate a model's capabilities has become an increasingly significant issue. The absence of a comprehensive Chinese benchmark that thoroughly assesses a model's performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted to holistically evaluate Chinese LLMs. Our platform employs a standardized workflow to assess LLMs' performance across various dimensions, regularly updating a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round. Empowered by an easy-to-use interface that requires just a few mouse clicks and a model API, users can conduct a thorough evaluation with minimal coding. Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA's efficacy.
</details>
<details>
<summary>摘要</summary>
To address these challenges, we present CLEVA, a user-friendly platform that holistically evaluates Chinese LLMs. Our platform employs a standardized workflow to assess LLMs' performance across various dimensions, and regularly updates a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round.CLEVA is easy to use and requires just a few mouse clicks and a model API. Users can conduct a thorough evaluation with minimal coding. Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA's efficacy.In simplified Chinese, the text would be:中文大语模型（LLM）的出现使得评估模型能力的问题日益重要。但是现在中文LLM的评估遇到了一些挑战，包括中文benchmark的缺乏，评估程序的标准化和比较不一致，以及污染的问题。为了解决这些挑战，我们提出了CLEVA，一个易用的平台，可以全面评估中文LLM。我们的平台使用标准化的工作流程，评估模型的能力在不同的维度上，并 régulièrement更新竞争性的领先板。为了解决污染的问题，CLEVA获取了大量的新数据，并开发了一个确保每个领先板都有唯一子集的抽样方法。使用CLEVA需要只需要几个点键和模型API，用户可以快速进行充分的评估， minimal coding。大规模的实验表明，CLEVA具有效果。
</details></li>
</ul>
<hr>
<h2 id="A-Bipartite-Graph-is-All-We-Need-for-Enhancing-Emotional-Reasoning-with-Commonsense-Knowledge"><a href="#A-Bipartite-Graph-is-All-We-Need-for-Enhancing-Emotional-Reasoning-with-Commonsense-Knowledge" class="headerlink" title="A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge"></a>A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04811">http://arxiv.org/abs/2308.04811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stevekgyang/bhg">https://github.com/stevekgyang/bhg</a></li>
<li>paper_authors: Kailai Yang, Tianlin Zhang, Shaoxiong Ji, Sophia Ananiadou</li>
<li>for: 这种研究旨在提高人工智能系统的情感理解能力，特别是在社交媒体上的舆论挖掘和Empathy对话系统中。</li>
<li>methods: 这种方法使用二分图等维度异质图（BHG）方法，将上下文感知的语音表示和知识表示作为不同类型的节点模型，并提出了两种新的知识聚合节点类型来自动过滤和交互知识。</li>
<li>results: 这种方法在对比之下显著超越了现有的知识混合方法，并且可以直接普适化到不同类型和级别的知识源。<details>
<summary>Abstract</summary>
The context-aware emotional reasoning ability of AI systems, especially in conversations, is of vital importance in applications such as online opinion mining from social media and empathetic dialogue systems. Due to the implicit nature of conveying emotions in many scenarios, commonsense knowledge is widely utilized to enrich utterance semantics and enhance conversation modeling. However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources. Based on these observations, we propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional reasoning with commonsense knowledge. In BHG, the extracted context-aware utterance representations and knowledge representations are modeled as heterogeneous nodes. Two more knowledge aggregation node types are proposed to perform automatic knowledge filtering and interaction. BHG-based knowledge infusion can be directly generalized to multi-type and multi-grained knowledge sources. In addition, we propose a Multi-dimensional Heterogeneous Graph Transformer (MHGT) to perform graph reasoning, which can retain unchanged feature spaces and unequal dimensions for heterogeneous node types during inference to prevent unnecessary loss of information. Experiments show that BHG-based methods significantly outperform state-of-the-art knowledge infusion methods and show generalized knowledge infusion ability with higher efficiency. Further analysis proves that previous empirical knowledge filtering methods do not guarantee to provide the most useful knowledge information. Our code is available at: https://github.com/SteveKGYang/BHG.
</details>
<details>
<summary>摘要</summary>
“context-aware情感理解能力”是人工智能系统在对话中的重要特点，尤其在社交媒体上的情感分析和Empathy对话系统中。由于许多情感表达 implicit nature，因此通常使用常识来填充语音 semantics 和对话模型。然而，大多数先前知识混入方法通过 empirical knowledge filtering 和自定义 architectures 来实现知识与语音的交互，这可能会抛弃有用的知识方面和限制其在不同的知识来源上的一致性。基于这些观察，我们提出了一种 Bipartite Heterogeneous Graph (BHG) 方法来增强情感理解。在 BHG 中，提取的上下文化语音表示和知识表示被模型为不同类型的异常节点。我们还提出了两种新的知识聚合节点类型，以自动实现知识过滤和交互。BHG 基于的知识混入方法可以直接普遍应用于不同类型和多维度的知识来源。此外，我们还提出了一种 Multi-dimensional Heterogeneous Graph Transformer (MHGT) 来进行图reasoning，可以保持不变的特征空间和不等维度的异常节点类型 durante inference，以避免不必要的信息损失。实验表明，BHG 基于的方法在情感理解方面表现出色，并且具有更高的一致性和效率。进一步分析表明，先前的 empirical knowledge filtering 方法并不能提供最有用的知识信息。我们的代码可以在 GitHub 上找到：https://github.com/SteveKGYang/BHG。
</details></li>
</ul>
<hr>
<h2 id="ADMUS-A-Progressive-Question-Answering-Framework-Adaptable-to-Multiple-Knowledge-Sources"><a href="#ADMUS-A-Progressive-Question-Answering-Framework-Adaptable-to-Multiple-Knowledge-Sources" class="headerlink" title="ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources"></a>ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04800">http://arxiv.org/abs/2308.04800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yirui Zhan, Yanzeng Li, Minhao Zhang, Lei Zou</li>
<li>for: 提高KBQA系统在实际场景中的应用性，使得KBQA系统能够轻松地适应不同的数据集。</li>
<li>methods: 提出了一种基于深度学习模型的数据独立KBQA系统，通过解耦KBQA系统的架构，使得系统能够轻松地适应不同的数据集，并且支持多语言和多知识基础的混合使用。</li>
<li>results: 在多种不同的数据集上进行了实质性的试验，证明了ADMUS系统的高效性和灵活性。在线示例可以在<a target="_blank" rel="noopener" href="https://answer.gstore.cn/pc/index.html%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://answer.gstore.cn/pc/index.html中找到。</a><details>
<summary>Abstract</summary>
With the introduction of deep learning models, semantic parsingbased knowledge base question answering (KBQA) systems have achieved high performance in handling complex questions. However, most existing approaches primarily focus on enhancing the model's effectiveness on individual benchmark datasets, disregarding the high costs of adapting the system to disparate datasets in real-world scenarios (e.g., multi-tenant platform). Therefore, we present ADMUS, a progressive knowledge base question answering framework designed to accommodate a wide variety of datasets, including multiple languages, diverse backbone knowledge bases, and disparate question answering datasets. To accomplish the purpose, we decouple the architecture of conventional KBQA systems and propose this dataset-independent framework. Our framework supports the seamless integration of new datasets with minimal effort, only requiring creating a dataset-related micro-service at a negligible cost. To enhance the usability of ADUMS, we design a progressive framework consisting of three stages, ranges from executing exact queries, generating approximate queries and retrieving open-domain knowledge referring from large language models. An online demonstration of ADUMS is available at: https://answer.gstore.cn/pc/index.html
</details>
<details>
<summary>摘要</summary>
随着深度学习模型的引入，基于语义解析的知识库问答（KBQA）系统在处理复杂问题的性能得到了显著提高。然而，大多数现有方法主要是强调改进模型在特定 benchmark 数据集上的效果，忽视了在实际场景中适应不同数据集的高成本（例如，多租户平台）。因此，我们提出了 ADMUS，一个适应多种数据集的进步知识库问答框架。为了实现这一目标，我们将 convent ional KBQA 系统的架构划分为多个独立的组件，并且提出了一种不同数据集的独立框架。这些组件可以轻松地与新的数据集集成，只需要创建一个数据集相关的微服务，成本极低。为了提高 ADMUS 的可用性，我们设计了一个进步的框架，包括三个阶段：在执行精确查询、生成approx query和从大语言模型中提取开放领域知识三个阶段。在线示例可以在以下地址找到：https://answer.gstore.cn/pc/index.html。
</details></li>
</ul>
<hr>
<h2 id="Automatically-measuring-speech-fluency-in-people-with-aphasia-first-achievements-using-read-speech-data"><a href="#Automatically-measuring-speech-fluency-in-people-with-aphasia-first-achievements-using-read-speech-data" class="headerlink" title="Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data"></a>Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04763">http://arxiv.org/abs/2308.04763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lionel Fontan, Typhanie Prince, Aleksandra Nowakowska, Halima Sahraoui, Silvia Martinez-Ferreiro</li>
<li>for: This study aims to assess the relevance of a signal processing algorithm for the automatic measurement of speech fluency in people with aphasia (PWA).</li>
<li>methods: The study uses a forward-backward divergence segmentation and a clustering algorithm to compute four automatic predictors of speech fluency, and combines these predictors into multivariate regression models to predict the average SLP ratings of speech fluency.</li>
<li>results: The study finds that the algorithms used can constitute a cost-effective and reliable tool for the assessment of the speech fluency of patients with aphasia in read-aloud tasks, with accurate predictions and high correlation coefficients between the automatic predictions and SLP ratings.<details>
<summary>Abstract</summary>
Background: Speech and language pathologists (SLPs) often relyon judgements of speech fluency for diagnosing or monitoringpatients with aphasia. However, such subjective methods havebeen criticised for their lack of reliability and their clinical cost interms of time. Aims: This study aims at assessing the relevance of a signalprocessingalgorithm, initially developed in the field of language acquisition, for the automatic measurement of speech fluency in people with aphasia (PWA). Methods & Procedures: Twenty-nine PWA and five control participantswere recruited via non-profit organizations and SLP networks. All participants were recorded while reading out loud a set ofsentences taken from the French version of the Boston Diagnostic Aphasia Examination. Three trained SLPs assessed the fluency of each sentence on a five-point qualitative scale. A forward-backward divergence segmentation and a clustering algorithm were used to compute, for each sentence, four automatic predictors of speech fluency: pseudo-syllable rate, speech ratio, rate of silent breaks, and standard deviation of pseudo-syllable length. The four predictors were finally combined into multivariate regression models (a multiplelinear regression - MLR, and two non-linear models) to predict the average SLP ratings of speech fluency, using a leave-one speaker-out validation scheme. Outcomes & Results: All models achieved accurate predictions of speech fluency ratings, with average root-mean-square errors as low as 0.5. The MLR yielded a correlation coefficient of 0.87 with reference ratings at the sentence level, and of 0.93 when aggregating the data for each participant. The inclusion of an additional predictor sensitive to repetitions improved further the predictions with a correlation coefficient of 0.91 at the sentence level, and of 0.96 at the participant level. Conclusions: The algorithms used in this study can constitute a cost-effective and reliable tool for the assessment of the speech fluency of patients with aphasia in read-aloud tasks. Perspectives for the assessment of spontaneous speech are discussed.
</details>
<details>
<summary>摘要</summary>
背景：语言学和语音学师（SLP）经常依靠语言流畅性的评估来诊断或监测患有语言异常的患者。然而，这些主观方法受到了不可靠性的批评，以及严重影响临床成本。目标：本研究目的是评估一种信号处理算法在诊断语言异常患者（PWA）的语言流畅性方面的可靠性。方法与程序：招募了29名PWA和5名控制参与者，来自非营利组织和SLP网络。所有参与者在念出句子时被录音，并且使用法语版本的波士顿语言鉴别检测测试套件中的句子。三名SLP评估每句语言流畅性的五个质量水平。使用前后弧 divergence 分 segmentation 和归一化算法计算每句语言流畅性的四个自动预测器：pseudo-syllable rate、speech ratio、silent breaks 率和pseudo-syllable length 的标准差。这四个预测器最终组合成多变量回归模型（多元回归）和两种非线性模型来预测SLP评估语言流畅性的平均分数，使用了留一个说话者验证方案。结果与结论：所有模型均达到了准确的语言流畅性评估结果，平均根据值为0.5。多元回归模型在句子水平获得了0.87的相关系数，并在每名参与者的数据归一化后获得0.93的相关系数。在添加一个更多的预测器时，预测结果进一步改善，句子水平相关系数提高到0.91，每名参与者的相关系数提高到0.96。结论：这些算法可以成为诊断患有语言异常的患者语言流畅性的可靠和Cost-effective工具。对叙述语言的评估可能性进行了讨论。
</details></li>
</ul>
<hr>
<h2 id="Building-Interpretable-and-Reliable-Open-Information-Retriever-for-New-Domains-Overnight"><a href="#Building-Interpretable-and-Reliable-Open-Information-Retriever-for-New-Domains-Overnight" class="headerlink" title="Building Interpretable and Reliable Open Information Retriever for New Domains Overnight"></a>Building Interpretable and Reliable Open Information Retriever for New Domains Overnight</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04756">http://arxiv.org/abs/2308.04756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaodong Yu, Ben Zhou, Dan Roth</li>
<li>for: 这篇论文是为了提高信息检索（IR）和知识检索（KR）的性能而写的。</li>
<li>methods: 这篇论文使用了 dense retrieval 模型，通过使用 dense vectors 来表示查询和知识段落，并通过学习字符和Semantic相似性来进行学习。</li>
<li>results: 论文提出了一个信息检索管道，该管道使用 entity&#x2F;event linking 模型和查询分解模型来更加准确地关注查询中不同的信息单元。论文表明，相比单个 dense vectors 和端到端超vision，该管道可以更好地提高 passage coverages 和denotation accuracies，并且更加可读性和可靠性。<details>
<summary>Abstract</summary>
Information retrieval (IR) or knowledge retrieval, is a critical component for many down-stream tasks such as open-domain question answering (QA). It is also very challenging, as it requires succinctness, completeness, and correctness. In recent works, dense retrieval models have achieved state-of-the-art (SOTA) performance on in-domain IR and QA benchmarks by representing queries and knowledge passages with dense vectors and learning the lexical and semantic similarity. However, using single dense vectors and end-to-end supervision are not always optimal because queries may require attention to multiple aspects and event implicit knowledge. In this work, we propose an information retrieval pipeline that uses entity/event linking model and query decomposition model to focus more accurately on different information units of the query. We show that, while being more interpretable and reliable, our proposed pipeline significantly improves passage coverages and denotation accuracies across five IR and QA benchmarks. It will be the go-to system to use for applications that need to perform IR on a new domain without much dedicated effort, because of its superior interpretability and cross-domain performance.
</details>
<details>
<summary>摘要</summary>
信息检索（IR）或知识检索是许多下游任务的关键组件，如开放领域问答（QA）。它具有精炼、完整和正确的要求。在最近的工作中，稠密检索模型已经实现了领域内IR和QA benchmark的状态最佳性（SOTA）性能，通过将查询和知识段表示为稠密矢量，并学习语义和语言相似性。但是，使用单个稠密矢量和端到端超vis�� Nobel是不 siempre最佳，因为查询可能需要对多个方面进行注意力和隐藏知识。在这种情况下，我们提议一个信息检索管道，使用实体/事件关联模型和查询分解模型，以更加准确地关注不同信息单元的查询。我们表明，相比于单一稠密矢量和端到端超vis�� Nobel，我们的提议管道可以更好地提高通过五个IR和QA benchmark的段覆盖率和涵义准确率。这将成为新领域IR应用的标准系统，因为它的超过其他解释和跨领域性能。
</details></li>
</ul>
<hr>
<h2 id="Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning"><a href="#Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning" class="headerlink" title="Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning"></a>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04712">http://arxiv.org/abs/2308.04712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Philip S. Yu</li>
<li>for: 本研究的目的是提高对话系统中的自然语言理解能力，尤其是任务导向对话（TOD）系统中的意图检测和插槽填充任务。</li>
<li>methods: 本研究使用了无监督语言模型（PLM）探测和对比学习机制，利用无监督语义知识和句子级意图标签信号来进行槽induction任务。</li>
<li>results: 研究结果表明，使用PLM探测和对比学习机制可以有效地实现槽induction任务，并且可以与token级监督模型相似或更高的性能。此外，当扩展到新意图时，我们的SI目标还可以提高插槽填充任务的性能。<details>
<summary>Abstract</summary>
Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanisms to extract unsupervised semantic knowledge from PLM and utilize additional sentence-level intent label signals available from TOD. Our approach is effective in the SI task and can bridge the gap with token-level supervised models on two NLU benchmark datasets.Moreover, our SI objectives also provide enhanced slot label representations, leading to improved performance on Slot Filling tasks. This is particularly useful when dealing with emerging intents, where traditional slot label representations may not be effective. Our approach offers a promising solution for improving the efficiency and accuracy of NLU systems in TOD applications.
</details></li>
</ul>
<hr>
<h2 id="Answering-Unseen-Questions-With-Smaller-Language-Models-Using-Rationale-Generation-and-Dense-Retrieval"><a href="#Answering-Unseen-Questions-With-Smaller-Language-Models-Using-Rationale-Generation-and-Dense-Retrieval" class="headerlink" title="Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval"></a>Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04711">http://arxiv.org/abs/2308.04711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Hartill, Diana Benavides-Prado, Michael Witbrock, Patricia J. Riddle</li>
<li>For: The paper aims to improve the performance of smaller language models on challenging short-answer question-answering tasks by combining rationales generated by a larger language model with longer contexts created from a multi-hop dense retrieval system.* Methods: The paper proposes two methods for combining rationales and contexts: Rationale Ranking (RR) and Reasoning with Retrieval-Augmented Training Data (RATD). RR involves training a model to score both generated rationales and retrieved contexts with respect to relevance and truthfulness, and then combining the scores to derive combined contexts. RATD involves training a smaller reasoning model using retrieval-augmented training datasets to utilize relevant information from longer text sequences.* Results: The paper finds that both methods are effective, but the RATD method is more straightforward to apply and produces the strongest results in unseen settings. The proposed models also generally outperform direct prompts against much larger models in both few-shot chain-of-thought and few-shot answer-only settings.<details>
<summary>Abstract</summary>
When provided with sufficient explanatory context, smaller Language Models have been shown to exhibit strong reasoning ability on challenging short-answer question-answering tasks where the questions are unseen in training. We evaluate two methods for further improvement in this setting. Both methods focus on combining rationales generated by a larger Language Model with longer contexts created from a multi-hop dense retrieval system. The first method ($\textit{RR}$) involves training a Rationale Ranking model to score both generated rationales and retrieved contexts with respect to relevance and truthfulness. We then use the scores to derive combined contexts from both knowledge sources using a number of combinatory strategies. For the second method ($\textit{RATD}$) we train a smaller Reasoning model using retrieval-augmented training datasets such that it becomes proficient at utilising relevant information from longer text sequences that may be only partially evidential and frequently contain many irrelevant sentences. Generally we find that both methods are effective but that the $\textit{RATD}$ method is more straightforward to apply and produces the strongest results in the unseen setting on which we focus. Our single best Reasoning model using only 440 million parameters materially improves upon strong comparable prior baselines for unseen evaluation datasets (StrategyQA 58.9 $\rightarrow$ 61.7 acc., CommonsenseQA 63.6 $\rightarrow$ 72.7 acc., ARC-DA 31.6 $\rightarrow$ 52.1 F1, IIRC 25.5 $\rightarrow$ 27.3 F1) and a version utilising our prior knowledge of each type of question in selecting a context combination strategy does even better. Our proposed models also generally outperform direct prompts against much larger models (BLOOM 175B and StableVicuna 13B) in both few-shot chain-of-thought and few-shot answer-only settings.
</details>
<details>
<summary>摘要</summary>
The first method, called $\textit{RR}$, trains a Rationale Ranking model to score both generated rationales and retrieved contexts based on relevance and truthfulness. We then use the scores to combine the contexts from both knowledge sources using various strategies.The second method, called $\textit{RATD}$, trains a smaller reasoning model using retrieval-augmented training datasets. This allows the model to learn how to utilize relevant information from longer text sequences, even if they contain many irrelevant sentences.We find that both methods are effective, but the $\textit{RATD}$ method is easier to apply and produces the strongest results in unseen settings. Our best reasoning model, using only 440 million parameters, significantly improves upon strong prior baselines (StrategyQA 58.9 $\rightarrow$ 61.7 acc., CommonsenseQA 63.6 $\rightarrow$ 72.7 acc., ARC-DA 31.6 $\rightarrow$ 52.1 F1, IIRC 25.5 $\rightarrow$ 27.3 F1) and even outperforms direct prompts against larger models (BLOOM 175B and StableVicuna 13B) in both few-shot chain-of-thought and few-shot answer-only settings. Our proposed models also generally outperform direct prompts against much larger models in both settings.
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Open-Source-Large-Language-Models-GPT-4-and-Claude-2-Multiple-Choice-Test-Taking-in-Nephrology"><a href="#A-Comparative-Study-of-Open-Source-Large-Language-Models-GPT-4-and-Claude-2-Multiple-Choice-Test-Taking-in-Nephrology" class="headerlink" title="A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology"></a>A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04709">http://arxiv.org/abs/2308.04709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sean Wu, Michael Koo, Lesley Blum, Andy Black, Liyo Kao, Fabien Scalzo, Ira Kurtz</li>
<li>for: This study investigated the medical knowledge capability of large language models (LLMs) in the context of internal medicine subspecialty multiple-choice test-taking ability.</li>
<li>methods: The study compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B) to GPT-4 and Claude 2 on multiple-choice questions in the field of Nephrology.</li>
<li>results: The study found that current widely used open-sourced LLMs have poor zero-shot reasoning ability compared to GPT-4 and Claude 2, with an overall success rate of 17.1% - 25.5% in answering nephSAP multiple-choice questions correctly.<details>
<summary>Abstract</summary>
In recent years, there have been significant breakthroughs in the field of natural language processing, particularly with the development of large language models (LLMs). These LLMs have showcased remarkable capabilities on various benchmarks. In the healthcare field, the exact role LLMs and other future AI models will play remains unclear. There is a potential for these models in the future to be used as part of adaptive physician training, medical co-pilot applications, and digital patient interaction scenarios. The ability of AI models to participate in medical training and patient care will depend in part on their mastery of the knowledge content of specific medical fields. This study investigated the medical knowledge capability of LLMs, specifically in the context of internal medicine subspecialty multiple-choice test-taking ability. We compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on multiple-choice questions in the field of Nephrology. Nephrology was chosen as an example of a particularly conceptually complex subspecialty field within internal medicine. The study was conducted to evaluate the ability of LLM models to provide correct answers to nephSAP (Nephrology Self-Assessment Program) multiple-choice questions. The overall success of open-sourced LLMs in answering the 858 nephSAP multiple-choice questions correctly was 17.1% - 25.5%. In contrast, Claude 2 answered 54.4% of the questions correctly, whereas GPT-4 achieved a score of 73.3%. We show that current widely used open-sourced LLMs do poorly in their ability for zero-shot reasoning when compared to GPT-4 and Claude 2. The findings of this study potentially have significant implications for the future of subspecialty medical training and patient care.
</details>
<details>
<summary>摘要</summary>
近年来，自然语言处理领域有了 significativ breakthrough，特别是大语言模型（LLMs）的发展。这些 LLMs 在不同的标准准则上显示了惊人的能力。在医疗领域，未来 LLMs 和其他未来 AI 模型的具体作用仍然 unclear。这些模型在未来可能用于 adaptive physician training、医疗 copilot 应用和数字patient interaction 场景。AI 模型在医疗教育和患者护理中的参与度取决于它们在特定医学领域的知识内容的掌握程度。本研究 investigated LLMs 在内科亚专业多选题测试能力方面的医学知识能力。我们比较了多个开源 LLMs（Koala 7B、Falcon 7B、Stable-Vicuna 13B 和 Orca Mini 13B）和 GPT-4 和 Claude 2 在尼科логи亚专业多选题中的表现。尼科логи亚专业是内科中的一个特别概念复杂的亚专业领域。本研究的目的是评估 LLM 模型在 nephSAP 多选题中的正确答案能力。全部 open-sourced LLMs 在 858 个 nephSAP 多选题中正确答案的成功率为 17.1% - 25.5%。与此相比， Claude 2 答对了 54.4% 的问题，而 GPT-4 则达到了 73.3%。我们显示了当前广泛使用的 open-sourced LLMs 在零次学习时的能力远低于 GPT-4 和 Claude 2。本研究的结果可能对未来医疗专业培训和患者护理产生重要影响。
</details></li>
</ul>
<hr>
<h2 id="Generating-News-Centric-Crossword-Puzzles-As-A-Constraint-Satisfaction-and-Optimization-Problem"><a href="#Generating-News-Centric-Crossword-Puzzles-As-A-Constraint-Satisfaction-and-Optimization-Problem" class="headerlink" title="Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem"></a>Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04688">http://arxiv.org/abs/2308.04688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaito Majima, Shotaro Ishihara</li>
<li>for: 这个研究旨在创建一个自动生成新闻对应的十字WORD游戏，以增强新闻学习的教育用途。</li>
<li>methods: 这个研究使用了一个问题设定和优化问题的方法，将新闻中的词汇集成十字WORD游戏中，以增加学习效果。</li>
<li>results: 研究发现，即使仅有少量的新闻词汇，仍可以生成新闻对应的十字WORD游戏，并且可以在不同的环境下进行优化。<details>
<summary>Abstract</summary>
Crossword puzzles have traditionally served not only as entertainment but also as an educational tool that can be used to acquire vocabulary and language proficiency. One strategy to enhance the educational purpose is personalization, such as including more words on a particular topic. This paper focuses on the case of encouraging people's interest in news and proposes a framework for automatically generating news-centric crossword puzzles. We designed possible scenarios and built a prototype as a constraint satisfaction and optimization problem, that is, containing as many news-derived words as possible. Our experiments reported the generation probabilities and time required under several conditions. The results showed that news-centric crossword puzzles can be generated even with few news-derived words. We summarize the current issues and future research directions through a qualitative evaluation of the prototype. This is the first proposal that a formulation of a constraint satisfaction and optimization problem can be beneficial as an educational application.
</details>
<details>
<summary>摘要</summary>
十字WORD puzzles 不仅作为娱乐，还可以作为学习工具，帮助学习者提高词汇和语言水平。一种增强教育效果的策略是个性化，例如包含特定主题的词汇。这篇论文关注于鼓励人们对新闻的兴趣，并提出了自动生成新闻中心十字WORD puzzles 的框架。我们设计了可能的情景，建立了一个约束满足优化问题，即包含最多新闻来源的词汇。我们的实验报告了生成概率和时间，并对不同条件进行了评估。结果表明，可以使用少量新闻来源生成新闻中心十字WORD puzzles。我们通过质量评估我们的原型，总结了当前的问题和未来的研究方向。这是首次提出了一种约束满足优化问题可以作为教育应用。
</details></li>
</ul>
<hr>
<h2 id="TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction"><a href="#TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction" class="headerlink" title="TBIN: Modeling Long Textual Behavior Data for CTR Prediction"></a>TBIN: Modeling Long Textual Behavior Data for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08483">http://arxiv.org/abs/2308.08483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang</li>
<li>for: 预测点击率 (CTR) 在推荐中发挥关键作用，因此启发自最近崛起的语言模型 (LM) 的工作，通过将用户行为数据组织成文本格式，使用 LM 理解用户在semantic水平上的兴趣。</li>
<li>methods: 本文提出了一种 Textual Behavior-based Interest Chunking Network (TBIN)，该方法结合了有效的本地相关哈希算法和偏移 chunk-based self-attention，以解决上述限制。</li>
<li>results: 实验结果表明，TBIN 可以有效地预测 CTR，并且在实际食物推荐平台上进行了在线实验，得到了较高的预测精度。<details>
<summary>Abstract</summary>
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details>
<details>
<summary>摘要</summary>
点击率（CTR）预测在推荐中扮演重要的角色。鉴于最近崛起的语言模型（LM），一些工作将用户行为数据 format 为文本，并使用 LM 理解用户的 semantic 价值。 Although promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model.In this paper, we propose a 文本行为基因网络（TBIN）， which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details></li>
</ul>
<hr>
<h2 id="Sudowoodo-a-Chinese-Lyric-Imitation-System-with-Source-Lyrics"><a href="#Sudowoodo-a-Chinese-Lyric-Imitation-System-with-Source-Lyrics" class="headerlink" title="Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics"></a>Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04665">http://arxiv.org/abs/2308.04665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongzhu Chang, Rongsheng Zhang, Lin Jiang, Qihang Chen, Le Zhang, Jiashu Pu</li>
<li>for: 这个论文的目的是提出一种基于中文歌词模型的中文歌词模仿系统（Sudowoodo），以便通过模仿已有的歌词来生成新的歌词。</li>
<li>methods: 这个论文使用了一种新的框架，该框架基于中文歌词模型，并使用了一些 keyword-based lyrics 模型来构建一个平行训练集。然后，该论文使用了一种新的 lyrics imitation 模型来训练这个平行训练集。最后，该论文使用了一种 post-processing 模块来筛选和排序生成的歌词，以选择最高质量的歌词。</li>
<li>results: 该论文的实验结果表明，使用该新的框架和模型可以更好地进行中文歌词模仿。此外，该论文还提供了一个 demo 视频，详细介绍了该系统的使用和应用。<details>
<summary>Abstract</summary>
Lyrics generation is a well-known application in natural language generation research, with several previous studies focusing on generating accurate lyrics using precise control such as keywords, rhymes, etc. However, lyrics imitation, which involves writing new lyrics by imitating the style and content of the source lyrics, remains a challenging task due to the lack of a parallel corpus. In this paper, we introduce \textbf{\textit{Sudowoodo}, a Chinese lyrics imitation system that can generate new lyrics based on the text of source lyrics. To address the issue of lacking a parallel training corpus for lyrics imitation, we propose a novel framework to construct a parallel corpus based on a keyword-based lyrics model from source lyrics. Then the pairs \textit{(new lyrics, source lyrics)} are used to train the lyrics imitation model. During the inference process, we utilize a post-processing module to filter and rank the generated lyrics, selecting the highest-quality ones. We incorporated audio information and aligned the lyrics with the audio to form the songs as a bonus. The human evaluation results show that our framework can perform better lyric imitation. Meanwhile, the \textit{Sudowoodo} system and demo video of the system is available at \href{https://Sudowoodo.apps-hp.danlu.netease.com/}{Sudowoodo} and \href{https://youtu.be/u5BBT_j1L5M}{https://youtu.be/u5BBT\_j1L5M}.
</details>
<details>
<summary>摘要</summary>
文章摘要：本文介绍了一种新的中文歌词模仿系统——《嗨嗨》（Sudowoodo），可以基于源歌词文本生成新歌词。由于缺乏平行训练集，歌词模仿 зада务一直是一个挑战。我们提出了一种新的框架，利用关键词基于的歌词模型从源歌词中构建平行训练集。然后，我们使用这些对（新歌词、源歌词）进行训练歌词模仿模型。在推理过程中，我们利用一个后处理模块来筛选和排序生成的歌词，选择最高质量的歌词。此外，我们还 incorporated 音频信息并将歌词与音频进行对应，形成了完整的歌曲。人工评估结果显示，我们的框架可以实现更好的歌词模仿。同时，《嗨嗨》系统和demo视频也可以在 \href{https://Sudowoodo.apps-hp.danlu.netease.com/}{Sudowoodo} 和 \href{https://youtu.be/u5BBT_j1L5M}{https://youtu.be/u5BBT\_j1L5M} 上查看。
</details></li>
</ul>
<hr>
<h2 id="Cross-Lingual-Constituency-Parsing-for-Middle-High-German-A-Delexicalized-Approach"><a href="#Cross-Lingual-Constituency-Parsing-for-Middle-High-German-A-Delexicalized-Approach" class="headerlink" title="Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach"></a>Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04645">http://arxiv.org/abs/2308.04645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ercong Nie, Helmut Schmid, Hinrich Schütze</li>
<li>for: 本研究旨在建立一个自动 syntax 分析系统 для $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$，但是 Due to the lack of annotated parse data, 训练一个自动 syntax 分析系统是一个困难的任务。</li>
<li>methods: 我们运用了 cross-lingual transfer 技术，使用 MG parse  dataset 进行训练，并通过 delexicalization 方法将 MG  parse 结果转换为 MHG  parse 结果。</li>
<li>results: 我们的 delexicalized constituency parser 在 MHG 测试集上表现出色，实现了 F1 分数 67.3%，比最佳 zero-shot cross-lingual baseline 高出 28.6% 点。这个鼓舞人心的结果说明了自动 syntax 分析在其他具有相似挑战的古语言中的实际可行性。<details>
<summary>Abstract</summary>
Constituency parsing plays a fundamental role in advancing natural language processing (NLP) tasks. However, training an automatic syntactic analysis system for ancient languages solely relying on annotated parse data is a formidable task due to the inherent challenges in building treebanks for such languages. It demands extensive linguistic expertise, leading to a scarcity of available resources. To overcome this hurdle, cross-lingual transfer techniques which require minimal or even no annotated data for low-resource target languages offer a promising solution. In this study, we focus on building a constituency parser for $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$ under realistic conditions, where no annotated MHG treebank is available for training. In our approach, we leverage the linguistic continuity and structural similarity between MHG and $\mathbf{M}$odern $\mathbf{G}$erman $\mathbf{MG}$, along with the abundance of MG treebank resources. Specifically, by employing the $\mathit{delexicalization}$ method, we train a constituency parser on MG parse datasets and perform cross-lingual transfer to MHG parsing. Our delexicalized constituency parser demonstrates remarkable performance on the MHG test set, achieving an F1-score of 67.3%. It outperforms the best zero-shot cross-lingual baseline by a margin of 28.6% points. These encouraging results underscore the practicality and potential for automatic syntactic analysis in other ancient languages that face similar challenges as MHG.
</details>
<details>
<summary>摘要</summary>
古代语言处理自然语言处理（NLP）任务的基础角色。然而，为古代语言solely靠注释分析数据自动生成语法分析系统是一项困难的任务，因为这些语言的语法特征往往具有独特的挑战。这需要广泛的语言专业知识，从而导致了资源的缺乏。为了突破这个障碍，跨语言传递技术，即不需要或只需要少量注释数据的低资源目标语言中的技术，提供了一个有前途的解决方案。在这种研究中，我们关注于在实际条件下构建一个中世纪高德语（MHG）的分析器，无需注释MHG语法数据进行训练。我们利用中世纪高德语和现代德语之间的语言相似性和结构相似性，同时利用现代德语语法数据资源的充足。具体来说，我们采用了delexicalization方法，通过在MG语法数据集上训练分析器，并对MHG语法进行跨语言传递。我们的delexicalized分析器在MHG测试集上显示了Remarkable性能，达到了67.3%的F1分数。它超过了零零假设的跨语言基线值28.6个百分点。这些鼓舞人心的结果证明了自动语法分析在其他面临类似挑战的古代语言中的实用性和潜力。
</details></li>
</ul>
<hr>
<h2 id="Single-Sentence-Reader-A-Novel-Approach-for-Addressing-Answer-Position-Bias"><a href="#Single-Sentence-Reader-A-Novel-Approach-for-Addressing-Answer-Position-Bias" class="headerlink" title="Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias"></a>Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04566">http://arxiv.org/abs/2308.04566</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sonqt/single-sentence-reader">https://github.com/sonqt/single-sentence-reader</a></li>
<li>paper_authors: Son Quoc Tran, Matt Kretchmar</li>
<li>for: 本研究旨在解决机器阅读理解（MRC）模型借助于偶极性相关性（也称为数据集偏见或笔记痕），从而提高MRC模型的 robustness。</li>
<li>methods: 本研究提出了一种新的单句读者方法，以解决答案位置偏见问题。六种不同的模型被实现，并进行了严格的性能分析。</li>
<li>results: 实验结果表明，提案的单句读者方法可以nearly match conventional training sets上模型的性能，证明其有效性。<details>
<summary>Abstract</summary>
Machine Reading Comprehension (MRC) models tend to take advantage of spurious correlations (also known as dataset bias or annotation artifacts in the research community). Consequently, these models may perform the MRC task without fully comprehending the given context and question, which is undesirable since it may result in low robustness against distribution shift. This paper delves into the concept of answer-position bias, where a significant percentage of training questions have answers located solely in the first sentence of the context. We propose a Single-Sentence Reader as a new approach for addressing answer position bias in MRC. We implement this approach using six different models and thoroughly analyze their performance. Remarkably, our proposed Single-Sentence Readers achieve results that nearly match those of models trained on conventional training sets, proving their effectiveness. Our study also discusses several challenges our Single-Sentence Readers encounter and proposes a potential solution.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Ahead-of-the-Text-Leveraging-Entity-Preposition-for-Financial-Relation-Extraction"><a href="#Ahead-of-the-Text-Leveraging-Entity-Preposition-for-Financial-Relation-Extraction" class="headerlink" title="Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction"></a>Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04534">http://arxiv.org/abs/2308.04534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Pasch, Dimitrios Petridis</li>
<li>for: 这篇论文是为了解决金融实体关系标注任务的，使用了REFind数据集。</li>
<li>methods: 该方法包括将提供的实体插入文本中相应位置，然后使用基于变换器的语言模型roberta-large进行文本分类，最后进行后处理来处理模型生成的不可能预测。</li>
<li>results: 该方法在比赛的公共排名榜上获得了第一名。<details>
<summary>Abstract</summary>
In the context of the ACM KDF-SIGIR 2023 competition, we undertook an entity relation task on a dataset of financial entity relations called REFind. Our top-performing solution involved a multi-step approach. Initially, we inserted the provided entities at their corresponding locations within the text. Subsequently, we fine-tuned the transformer-based language model roberta-large for text classification by utilizing a labeled training set to predict the entity relations. Lastly, we implemented a post-processing phase to identify and handle improbable predictions generated by the model. As a result of our methodology, we achieved the 1st place ranking on the competition's public leaderboard.
</details>
<details>
<summary>摘要</summary>
在ACM KDF-SIGIR 2023比赛的Entity Relation任务中，我们采用了一种多步方法。首先，我们将提供的实体 inserting到文本中相应的位置。然后，我们使用abeled训练集来使transformer基于语言模型roberta-large进行文本分类的精度。最后，我们实施了一个后处理阶段，以便通过模型生成的不可能预测来处理。因此，我们的方法在比赛的公共排名板上获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Disentanglement-and-Fusion-on-Modality-and-Context-in-Conversational-Multimodal-Emotion-Recognition"><a href="#Revisiting-Disentanglement-and-Fusion-on-Modality-and-Context-in-Conversational-Multimodal-Emotion-Recognition" class="headerlink" title="Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition"></a>Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04502">http://arxiv.org/abs/2308.04502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Chong Teng, Tat-Seng Chua, Donghong Ji, Fei Li</li>
<li>for: 本研究targets at further improving the performance of multimodal emotion recognition in conversation (MM-ERC) tasks, by properly modeling the multimodal feature and conversational context.</li>
<li>methods: 该研究提出了一种 dual-level disentanglement mechanism (DDM)和一种 contribution-aware fusion mechanism (CFM)，以及一种 context refusion mechanism (CRM)，用于在feature disentanglement和feature fusion stages中 simultanously modeling the multimodal feature and conversational context.</li>
<li>results: 在两个公共MM-ERC数据集上，该系统实现了新的状态OF-THE-ART性能，并且进行了进一步的分析，表明所提出的方法可以充分利用多 modal和Contextual features，并且具有推广到更广泛的 conversational multimodal任务的潜在潜力。<details>
<summary>Abstract</summary>
It has been a hot research topic to enable machines to understand human emotions in multimodal contexts under dialogue scenarios, which is tasked with multimodal emotion analysis in conversation (MM-ERC). MM-ERC has received consistent attention in recent years, where a diverse range of methods has been proposed for securing better task performance. Most existing works treat MM-ERC as a standard multimodal classification problem and perform multimodal feature disentanglement and fusion for maximizing feature utility. Yet after revisiting the characteristic of MM-ERC, we argue that both the feature multimodality and conversational contextualization should be properly modeled simultaneously during the feature disentanglement and fusion steps. In this work, we target further pushing the task performance by taking full consideration of the above insights. On the one hand, during feature disentanglement, based on the contrastive learning technique, we devise a Dual-level Disentanglement Mechanism (DDM) to decouple the features into both the modality space and utterance space. On the other hand, during the feature fusion stage, we propose a Contribution-aware Fusion Mechanism (CFM) and a Context Refusion Mechanism (CRM) for multimodal and context integration, respectively. They together schedule the proper integrations of multimodal and context features. Specifically, CFM explicitly manages the multimodal feature contributions dynamically, while CRM flexibly coordinates the introduction of dialogue contexts. On two public MM-ERC datasets, our system achieves new state-of-the-art performance consistently. Further analyses demonstrate that all our proposed mechanisms greatly facilitate the MM-ERC task by making full use of the multimodal and context features adaptively. Note that our proposed methods have the great potential to facilitate a broader range of other conversational multimodal tasks.
</details>
<details>
<summary>摘要</summary>
研究团队已经很长时间来关注人工智能机器人理解人类情感的问题，即在对话场景下的多模态情感分析（MM-ERC）。这个问题在过去几年内得到了不间断的关注，而且提出了各种方法来提高任务性能。大多数现有方法都将 MM-ERC 视为标准的多模态分类问题，然后进行多模态特征分离和融合以最大化特征用用。然而，我们在再次检视 MM-ERC 的特点时，发现需要同时模型多模态特征和对话上下文。在这种情况下，我们提出了一种新的方法，以提高任务性能。在特征分离阶段，我们根据对比学习技术提出了双级分离机制（DDM），以分离特征到模态空间和话语空间两个级别。在特征融合阶段，我们提出了参与度感知融合机制（CFM）和上下文融合机制（CRM），用于多模态和上下文集成。CFM 可以动态管理多模态特征的贡献，而 CRM 可以flexibly 协调对话上下文的引入。在两个公共 MM-ERC 数据集上，我们的系统在新的状态均达到了领先的性能。进一步分析表明，我们的所有提出的机制都可以帮助 MM-ERC 任务，使得机器人可以更好地理解人类情感。此外，我们的方法还有潜在的推广性，可以推动更多的对话多模态任务的进步。
</details></li>
</ul>
<hr>
<h2 id="DialogRE-C-An-Extension-of-DialogRE-to-Investigate-How-Much-Coreference-Helps-Relation-Extraction-in-Dialogs"><a href="#DialogRE-C-An-Extension-of-DialogRE-to-Investigate-How-Much-Coreference-Helps-Relation-Extraction-in-Dialogs" class="headerlink" title="DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs"></a>DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04498">http://arxiv.org/abs/2308.04498</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/palm2333/dialogre_coreference">https://github.com/palm2333/dialogre_coreference</a></li>
<li>paper_authors: Yiyun Xiong, Mengwei Dai, Fei Li, Hao Fei, Bobo Li, Shengqiong Wu, Donghong Ji, Chong Teng</li>
<li>For: This paper introduces a new benchmark dataset called DialogRE^C+, which incorporates coreference resolution into the dialogue relation extraction (DRE) task.* Methods: The paper manually annotates a total of 5,068 coreference chains over 36,369 argument mentions based on existing DialogRE data, and develops four coreference-enhanced graph-based DRE models.* Results: The paper evaluates the effect of automatically extracted coreference chains and demonstrates the practicality of the DialogRE^C+ dataset for other domains and tasks.<details>
<summary>Abstract</summary>
Dialogue relation extraction (DRE) that identifies the relations between argument pairs in dialogue text, suffers much from the frequent occurrence of personal pronouns, or entity and speaker coreference. This work introduces a new benchmark dataset DialogRE^C+, introducing coreference resolution into the DRE scenario. With the aid of high-quality coreference knowledge, the reasoning of argument relations is expected to be enhanced. In DialogRE^C+ dataset, we manually annotate total 5,068 coreference chains over 36,369 argument mentions based on the existing DialogRE data, where four different coreference chain types namely speaker chain, person chain, location chain and organization chain are explicitly marked. We further develop 4 coreference-enhanced graph-based DRE models, which learn effective coreference representations for improving the DRE task. We also train a coreference resolution model based on our annotations and evaluate the effect of automatically extracted coreference chains demonstrating the practicality of our dataset and its potential to other domains and tasks.
</details>
<details>
<summary>摘要</summary>
对话关系提取（DRE）在对话文本中识别对话参与者之间的关系，受到个人 pronouns 和实体、发言人核心Reference的频繁出现困扰。这项工作提出了一个新的标准数据集 DialogRE^C+，将核心 Reference resolution 引入 DRE 场景中。通过高质量核心 Reference 知识的帮助，我们预期可以提高对话关系的逻辑推理。在 DialogRE^C+ 数据集中，我们 manually annotated 总共 5,068 个核心 Reference chain  sobre 36,369 个 argue mention，其中包括 speaker chain、person chain、location chain 和 organization chain 四种不同类型的核心 Reference chain。我们还开发了 4 种核心 Reference 增强的图基于 DRE 模型，这些模型学习了有效的核心 Reference 表示，以提高 DRE 任务的性能。此外，我们还训练了基于我们的标注的核心 Reference 解析模型，并评估了自动提取的核心 Reference chain 的实用性， thereby demonstrating the practicality of our dataset and its potential to other domains and tasks.
</details></li>
</ul>
<hr>
<h2 id="A-Bi-directional-Multi-hop-Inference-Model-for-Joint-Dialog-Sentiment-Classification-and-Act-Recognition"><a href="#A-Bi-directional-Multi-hop-Inference-Model-for-Joint-Dialog-Sentiment-Classification-and-Act-Recognition" class="headerlink" title="A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment Classification and Act Recognition"></a>A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment Classification and Act Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04424">http://arxiv.org/abs/2308.04424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Zheng, Fei Li, Yuyang Chai, Chong Teng, Donghong Ji</li>
<li>for: 这个论文的目的是提出一种新的对话情感分类（DSC）和行为识别（DAR）任务的解决方案，以同时预测每个对话中的情感标签和行为标签。</li>
<li>methods: 该方法利用了一种特征选择网络和双向多跳推理网络，以逐步提取和融合对话中的丰富情感和行为 clue。此外，该方法还使用了对比学习和双向学习来直接模型情感和行为标签之间的相关性。</li>
<li>results: 对两个常用的数据集进行了实验，结果显示，与州立标准比较，该模型在DAR和DSC任务上的性能提高至少2.6%和1.4%。此外，该模型不仅提高了性能，还增强了对这两个任务的解释性。<details>
<summary>Abstract</summary>
The joint task of Dialog Sentiment Classification (DSC) and Act Recognition (DAR) aims to predict the sentiment label and act label for each utterance in a dialog simultaneously. However, current methods encode the dialog context in only one direction, which limits their ability to thoroughly comprehend the context. Moreover, these methods overlook the explicit correlations between sentiment and act labels, which leads to an insufficient ability to capture rich sentiment and act clues and hinders effective and accurate reasoning. To address these issues, we propose a Bi-directional Multi-hop Inference Model (BMIM) that leverages a feature selection network and a bi-directional multi-hop inference network to iteratively extract and integrate rich sentiment and act clues in a bi-directional manner. We also employ contrastive learning and dual learning to explicitly model the correlations of sentiment and act labels. Our experiments on two widely-used datasets show that BMIM outperforms state-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1 score in DSC. Additionally, Our proposed model not only improves the performance but also enhances the interpretability of the joint sentiment and act prediction task.
</details>
<details>
<summary>摘要</summary>
joint任务对话情感分类（DSC）和行为识别（DAR）的目标是同时预测每句话的情感标签和行为标签。然而，现有方法只是一个方向地编码对话上下文，这限制了它们对对话上下文的理解能力。另外，这些方法忽略了情感和行为标签之间的直接相关性，这会导致对 sentiment和 act 标签的捕捉不充分，从而降低对这两个任务的准确性和有效性。为了解决这些问题，我们提议一种双向多跳推理模型（BMIM），利用特征选择网络和双向多跳推理网络来顺序提取和融合rich的情感和行为 clue。我们还使用对比学习和双向学习来直接模型情感和行为标签之间的相关性。我们的实验结果表明，BMIM在两个广泛使用的 dataset 上表现至少比状态ixelbaselines 2.6%的F1分数提高，并且我们的提出的模型不仅改善性能，还提高了对这两个任务的合理性。
</details></li>
</ul>
<hr>
<h2 id="Character-level-NMT-and-language-similarity"><a href="#Character-level-NMT-and-language-similarity" class="headerlink" title="Character-level NMT and language similarity"></a>Character-level NMT and language similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04398">http://arxiv.org/abs/2308.04398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Jon, Ondřej Bojar</li>
<li>for: 这个论文是为了研究使用Transformer架构进行字符级别的人工智能翻译，以及不同语言相似度和训练数据大小对翻译的影响。</li>
<li>methods: 这个论文使用了字符级别的Neural Machine Translation（NMT）模型，并使用了Transformer架构。</li>
<li>results: 研究发现，在相似语言之间的翻译benefits于字符级别输入分 segmentation，而在不相似语言之间，字符级别vanilla Transformer-base经常落后于字符级别分 segmentation。研究也证实了之前的发现，可以通过 fine-tuning已经训练过的字符级别模型来逼近这些模型的性能。<details>
<summary>Abstract</summary>
We explore the effectiveness of character-level neural machine translation using Transformer architecture for various levels of language similarity and size of the training dataset on translation between Czech and Croatian, German, Hungarian, Slovak, and Spanish. We evaluate the models using automatic MT metrics and show that translation between similar languages benefits from character-level input segmentation, while for less related languages, character-level vanilla Transformer-base often lags behind subword-level segmentation. We confirm previous findings that it is possible to close the gap by finetuning the already trained subword-level models to character-level.
</details>
<details>
<summary>摘要</summary>
我们研究使用Transformer架构进行字符级别人工智能翻译的效果，在捷克和克罗地亚、德国、匈牙利、斯洛伐克和西班牙之间的翻译中进行了不同语言相似性和训练数据大小的研究。我们使用自动MT指标进行评估，并发现在相似语言之间的翻译中，字符级别输入分 segmentation 带来了好处，而在较不相似的语言中，字符级凯旋Transformer-base 经常落后于字符级别分 segmentation。我们证实了之前的发现，可以通过 fine-tuning 已经训练过的字符级别模型来减变这个差距。
</details></li>
</ul>
<hr>
<h2 id="Learning-Evaluation-Models-from-Large-Language-Models-for-Sequence-Generation"><a href="#Learning-Evaluation-Models-from-Large-Language-Models-for-Sequence-Generation" class="headerlink" title="Learning Evaluation Models from Large Language Models for Sequence Generation"></a>Learning Evaluation Models from Large Language Models for Sequence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04386">http://arxiv.org/abs/2308.04386</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Chenglong Wang, Hang Zhou, Kaiyan Chang, Tongran Liu, Chunliang Zhang, Quan Du, Tong Xiao, Jingbo Zhu</li>
<li>for: 这篇论文目的是将大语言模型的评估能力转移到较轻量级的语言模型中，以解决大语言模型的 computation challenge。</li>
<li>methods: 这篇论文提出了一个称为ECT的评估能力转移方法，通过将评估模型从LLMs学习到较轻量级的语言模型中，以提高sequence generation模型的评估能力。</li>
<li>results: 实验结果显示，使用ECT学习评估模型后，sequence generation模型的生成结果对于常用的 метри和ChatGPT进行评估都有所提高。<details>
<summary>Abstract</summary>
Large language models achieve state-of-the-art performance on sequence generation evaluation, but typically have a large number of parameters. This is a computational challenge as presented by applying their evaluation capability at scale. To overcome the challenge, in this paper, we propose \textbf{ECT}, an \textbf{e}valuation \textbf{c}apability \textbf{t}ransfer method, to transfer the evaluation capability from LLMs to relatively lightweight language models. Based on the proposed ECT, we learn various evaluation models from ChatGPT, and employ them as reward models to improve sequence generation models via reinforcement learning and reranking approaches. Experimental results on machine translation, text style transfer, and summarization tasks demonstrate the effectiveness of our ECT. Notably, applying the learned evaluation models to sequence generation models results in better generated sequences as evaluated by commonly used metrics and ChatGPT.
</details>
<details>
<summary>摘要</summary>
大型语言模型在序列生成评价评价中表现出色，但它们通常具有较多参数。这是一个计算挑战，因为在应用它们的评价能力的大规模应用中，需要大量的计算资源。为解决这个挑战，在这篇论文中，我们提出了ECT（评价能力传输方法），用于将大型语言模型中的评价能力传输到较轻量级的语言模型中。基于ECT，我们从ChatGPT中学习了多种评价模型，并使其作为激励学习和重新排序的奖励模型。实验结果表明，ECT可以有效地提高序列生成模型的性能，并且应用学习的评价模型可以根据常用的指标和ChatGPT进行评价。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.CL_2023_08_09/" data-id="clpxp6byf009zee88cgy0d8tw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.LG_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T10:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.LG_2023_08_09/">cs.LG - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images"><a href="#Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images" class="headerlink" title="Density Crop-guided Semi-supervised Object Detection in Aerial Images"></a>Density Crop-guided Semi-supervised Object Detection in Aerial Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05032">http://arxiv.org/abs/2308.05032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhilpm/dronessod">https://github.com/akhilpm/dronessod</a></li>
<li>paper_authors: Akhil Meethal, Eric Granger, Marco Pedersoli</li>
<li>for: 这篇论文是针对现代物体检测器的训练问题进行研究，具体是关于如何对高分辨率的天空图像进行物体检测，并且处理小型物体的分布问题。</li>
<li>methods: 这篇论文提出了一种基于密度割载的半指导 semi-supervised 物体检测方法，通过在训练过程中使用内部割载来增强小型物体的检测，并且在测试过程中使用密度割载来结合输入图像和内部割载的检测结果，以提高检测精度。</li>
<li>results: 这篇论文的实验结果显示，与基本的mean-teacher方法相比，密度割载导向的半指导 semi-supervised 物体检测方法可以提高检测精度超过2%，特别是 для小型物体。<details>
<summary>Abstract</summary>
One of the important bottlenecks in training modern object detectors is the need for labeled images where bounding box annotations have to be produced for each object present in the image. This bottleneck is further exacerbated in aerial images where the annotators have to label small objects often distributed in clusters on high-resolution images. In recent days, the mean-teacher approach trained with pseudo-labels and weak-strong augmentation consistency is gaining popularity for semi-supervised object detection. However, a direct adaptation of such semi-supervised detectors for aerial images where small clustered objects are often present, might not lead to optimal results. In this paper, we propose a density crop-guided semi-supervised detector that identifies the cluster of small objects during training and also exploits them to improve performance at inference. During training, image crops of clusters identified from labeled and unlabeled images are used to augment the training set, which in turn increases the chance of detecting small objects and creating good pseudo-labels for small objects on the unlabeled images. During inference, the detector is not only able to detect the objects of interest but also regions with a high density of small objects (density crops) so that detections from the input image and detections from image crops are combined, resulting in an overall more accurate object prediction, especially for small objects. Empirical studies on the popular benchmarks of VisDrone and DOTA datasets show the effectiveness of our density crop-guided semi-supervised detector with an average improvement of more than 2\% over the basic mean-teacher method in COCO style AP. Our code is available at: https://github.com/akhilpm/DroneSSOD.
</details>
<details>
<summary>摘要</summary>
一个重要的瓶颈在现代物体探测器的训练中是需要标注过的图像，其中需要为每个图像中的每个物体生成矩形框注释。这个瓶颈在空中图像中更加突出，因为注释员需要为高分辨率图像中的小对象进行标注。在最近几天，使用pseudo-labels和弱强协同稳定的mean-teacher方法在 semi-supervised 物体探测中得到了广泛的应用。然而，直接适用这种 semi-supervised 探测器于空中图像中，可能并不会导致最佳的结果。在这篇论文中，我们提出了一种基于密度评估的 semi-supervised 探测器，可以在训练时对小对象进行识别，并在探测时利用这些小对象来提高检测的准确性。在训练时，我们使用标注和无标注图像中的群集来增强训练集，从而提高小对象的检测和生成 Pseudo-labels 的可能性。在探测时，探测器不仅能够检测输入图像中的对象，还能够检测高密度的小对象区域（密度评估），从而将输入图像和密度评估中的检测结果组合起来，得到更加准确的对象预测，特别是对小对象。我们的实验结果表明，我们的密度评估基于 semi-supervised 探测器在 COCO 风格的 AP 中超过了基本 mean-teacher 方法的平均提升 más than 2%。我们的代码可以在：https://github.com/akhilpm/DroneSSOD 中找到。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures"><a href="#An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures" class="headerlink" title="An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures"></a>An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04898">http://arxiv.org/abs/2308.04898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanmay Singla, Dharun Anandayuvaraj, Kelechi G. Kalu, Taylor R. Schorlemmer, James C. Davis</li>
<li>for: 本研究旨在使用自然语言处理技术（NLP）和大型语言模型（LLM）来分析历史上的软件供应链安全攻击。</li>
<li>methods: 本研究使用GPT 3.5和Bard两种大型语言模型来自动分析69起软件供应链安全攻击的报告。研究人员 разрабоtaced四个维度来分类这些攻击：类型的攻击、意图、性质和影响。</li>
<li>results: 研究发现，当源文章详细 enough以至于得到人工分析者的一致时，LLMs可以有效地characterize软件供应链攻击。然而，LLMs current不能完全取代人工分析者，未来的工作可以进一步提高LLM的表现在这个领域，并对更广泛的文章和攻击进行研究。<details>
<summary>Abstract</summary>
As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like those on SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing these failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5s categorizations had an average accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.
</details>
<details>
<summary>摘要</summary>
随着我们对软件系统的依赖程度越来越高，软件供应链攻击的后果也变得更加严重。如 solsWinds和ShadowHammer等高 Profile cyber attack 的事件，已经导致了 significannot financial和data losses，这也高亮了更强的cybersecurity的需求。一种方法来防止未来的攻击是通过研究过去的失败来。然而，传统的失败分析方法需要手动阅读和总结报告。自动支持可以降低成本和允许更多的失败分析。自然语言处理（NLP）技术，如大语言模型（LLMs），可以帮助失败分析。在这项研究中，我们评估了LLMs是否可以分析历史软件供应链安全失败。我们使用LLMs来复制人工分析69例软件供应链安全失败，这些失败由Cloud Native Computing Foundation（CNCF）的成员进行了手动分析。我们为LLMs设计了四个维度来分类这些失败：类型攻击、意图、性质和影响。GPT 3.5的分类精度为68%，而Bard的精度为58%。我们发现LLMs可以有效地描述软件供应链失败，但是只有当源文章具有足够细节时，才能达到人工分析者之间的一致。未来的工作可以提高LLM的性能在这种情况下，并研究更广泛的文章和失败。
</details></li>
</ul>
<hr>
<h2 id="Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization"><a href="#Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization" class="headerlink" title="Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization"></a>Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05021">http://arxiv.org/abs/2308.05021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li, Zhaozhi Qian, Mihaela van der Schaar</li>
<li>for: 这个论文的目的是检测扩散模型中的错误卷积问题，并提出一种正则化方法来解决这个问题。</li>
<li>methods: 这个论文使用了empirical和理论分析来证明扩散模型中的错误卷积问题，并提出了一种正则化方法来解决这个问题。</li>
<li>results: 实验结果表明，这种正则化方法可以有效地解决扩散模型中的错误卷积问题，并且可以提高扩散模型的性能。<details>
<summary>Abstract</summary>
While diffusion models have achieved promising performances in data synthesis, they might suffer error propagation because of their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, a strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation and we then propose a regularization to address this problem. Our theoretical analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module can't recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes. We further introduce a bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details>
<details>
<summary>摘要</summary>
Diffusion models 有 achieved promising performance in data synthesis, but they may suffer from error propagation due to their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation, and we propose a regularization to address this problem.我们的 teorical analysis shows that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module cannot recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes.我们还提出了一种 bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details></li>
</ul>
<hr>
<h2 id="When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis"><a href="#When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis" class="headerlink" title="When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis"></a>When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05017">http://arxiv.org/abs/2308.05017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/nscl">https://github.com/deeplearning-wisc/nscl</a></li>
<li>paper_authors: Yiyou Sun, Zhenmei Shi, Yingyu Liang, Yixuan Li</li>
<li>for: 本研究旨在提出一种基于知识的新类发现方法，即使无需标注数据也可以准确地探索新类。</li>
<li>methods: 本研究使用了图论 Representation 和 Spectral Contrastive Loss（NSCL）来解决新类发现问题。图论 Representation 可以将知识集中的类划分为不同的类划分，而 NSCL 可以使得图论 Representation 中的 adjacency matrix  факторизу，从而 derivate 一个可靠的错误 bound 和新类发现的必要和 suffcient 条件。</li>
<li>results: 实验表明，使用 NSCL 可以与多种强基eline 相比竞争，并且在常见的 benchmark 数据集上达到类似或更好的性能，这是一个有趣的实际应用，同时也具有理论保证。<details>
<summary>Abstract</summary>
Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
《新类发现（NCD）》的目标是从无标签集中推断出新类，通过利用已知类的先知知识。尽管NCD的理论基础缺乏，这篇论文填补了这一空白，提供了一种分析框架，以便正式地探讨已知类如何帮助发现新类。特地设计 дляNCD问题，我们引入了一种图论的表示方式，可以由NSCL（NCD特征对偶损失）学习。将这个目标函数最小化等价于图的邻接矩阵 факторизация，从而得到了一个可证明的错误 bound 和发现新类的必要和 suficient condition。实验表明，NSCL可以与多种强基eline比肩并列，这是实用上的优点，同时又享有理论保证。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework"><a href="#An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework" class="headerlink" title="An Empirical Study of Bugs in Open-Source Federated Learning Framework"></a>An Empirical Study of Bugs in Open-Source Federated Learning Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05014">http://arxiv.org/abs/2308.05014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Shao, Yuyang Gao, Fu Song, Sen Chen, Lingling Fan</li>
<li>for: 本研究的目的是 investigate the security issues in federated learning (FL) frameworks.</li>
<li>methods: 本研究使用了manuel collection, classification, and labeling of 1,112 FL framework bugs from 12 open-source FL frameworks on GitHub, and constructed taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs.</li>
<li>results: 研究发现了9个发现，包括15种symptoms、12种root causes、20种fix patterns，并对23个逻辑组件和两个主要应用场景进行了分析。<details>
<summary>Abstract</summary>
Federated learning (FL), as a decentralized machine learning solution to the protection of users' private data, has become an important learning paradigm in recent years, especially since the enforcement of stricter laws and regulations in most countries. Therefore, a variety of FL frameworks are released to facilitate the development and application of federated learning. Despite the considerable amount of research on the security and privacy of FL models and systems, the security issues in FL frameworks have not been systematically studied yet. In this paper, we conduct the first empirical study on 1,112 FL framework bugs to investigate their characteristics. These bugs are manually collected, classified, and labeled from 12 open-source FL frameworks on GitHub. In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios. From the results of our study, we present nine findings, discuss their implications, and propound several suggestions to FL framework developers and security researchers on the FL frameworks.
</details>
<details>
<summary>摘要</summary>
federated learning（FL），作为一种保护用户隐私数据的分布式机器学习解决方案，在过去几年中变得非常重要，尤其是在大多数国家实施更加严格的法律和规定后。因此，许多FL框架被发布，以便发展和应用联邦学习。尽管有很多关于FL模型和系统安全性的研究，但FL框架的安全问题尚未得到系统的研究。在这篇论文中，我们进行了第一个对1,112个FL框架漏洞的实证研究，以Investigate其特点。这些漏洞由手动收集、分类和标注的12个开源FL框架在GitHub上的漏洞。在详细的分析中，我们构建了15种表现Symptoms、12种根本原因和20种修复模式的漏洞分类系统，并对23个逻辑组件和两个主要应用场景进行了分析。从我们的研究结果中，我们提出了9个发现，讨论了它们的意义，并对FL框架开发者和安全研究人员提出了一些建议。
</details></li>
</ul>
<hr>
<h2 id="Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories"><a href="#Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories" class="headerlink" title="Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories"></a>Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05011">http://arxiv.org/abs/2308.05011</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mperezcarrasco/AnomalyALeRCE">https://github.com/mperezcarrasco/AnomalyALeRCE</a></li>
<li>paper_authors: Manuel Pérez-Carrasco, Guillermo Cabrera-Vives, Lorena Hernández-García, Francisco Forster, Paula Sánchez-Sáez, Alejandra Muñoz Arancibia, Nicolás Astorga, Franz Bauer, Amelia Bayo, Martina Cádiz-Leyton, Marcio Catelan</li>
<li>for: 这篇论文是用于探索自动化天文数据分析和机器学习技术的应用，以及如何对不同类型的天文数据进行异常探测。</li>
<li>methods: 这篇论文提出了一个叫做 Multi-Class Deep Support Vector Data Description (MCDSVDD) 的新算法，它是 One-Class Deep SVDD 的扩展，可以处理不同类型的内liers category。MCDSVDD 使用神经网络将数据映射到高维球体中，每个高维球体代表一个特定的内liers category。</li>
<li>results: 这篇论文的结果显示 MCDSVDD 能够对天文数据进行有效的异常探测，并且可以利用不同类型的内liers category。<details>
<summary>Abstract</summary>
With the increasing volume of astronomical data generated by modern survey telescopes, automated pipelines and machine learning techniques have become crucial for analyzing and extracting knowledge from these datasets. Anomaly detection, i.e. the task of identifying irregular or unexpected patterns in the data, is a complex challenge in astronomy. In this paper, we propose Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically designed to handle different inlier categories with distinct data distributions. MCDSVDD uses a neural network to map the data into hyperspheres, where each hypersphere represents a specific inlier category. The distance of each sample from the centers of these hyperspheres determines the anomaly score. We evaluate the effectiveness of MCDSVDD by comparing its performance with several anomaly detection algorithms on a large dataset of astronomical light-curves obtained from the Zwicky Transient Facility. Our results demonstrate the efficacy of MCDSVDD in detecting anomalous sources while leveraging the presence of different inlier categories. The code and the data needed to reproduce our results are publicly available at https://github.com/mperezcarrasco/AnomalyALeRCE.
</details>
<details>
<summary>摘要</summary>
随着现代观测望远镜生成的天文数据量的增加，自动化管道和机器学习技术已成为分析和提取天文数据中的重要工具。异常检测，即在数据中发现不寻常或意外的模式，是天文学中的一项复杂挑战。在这篇论文中，我们提出了多类深度支持向量数据描述（MCDSVDD）算法，这是一种特制来处理不同类准样的异常检测算法。MCDSVDD使用神经网络将数据映射到几个异常分类中的几个圆锥中，每个圆锥表示一种特定的准样类别。每个样本与各个圆锥的中心之间的距离决定了异常分数。我们通过对一些异常检测算法的比较，证明MCDSVDD可以有效地检测异常来源，同时利用不同类准样的存在。codes和需要进行重现的数据可以在https://github.com/mperezcarrasco/AnomalyALeRCE上获取。
</details></li>
</ul>
<hr>
<h2 id="Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision"><a href="#Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision" class="headerlink" title="Transferable Models for Bioacoustics with Human Language Supervision"></a>Transferable Models for Bioacoustics with Human Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04978">http://arxiv.org/abs/2308.04978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/david-rx/biolingual">https://github.com/david-rx/biolingual</a></li>
<li>paper_authors: David Robinson, Adelaide Robinson, Lily Akrapongpisak</li>
<li>for: 本研究的目的是开发一种可扩展、非侵入的方法来跟踪全球生物多样性和人类活动对物种的影响。</li>
<li>methods: 本研究使用了一种新的语音-语言预训练模型，称为BioLingual，以处理生物声学数据。该模型首先将生物声学档案聚合成一个语音-语言数据集，称为AnimalSpeak，包含超过一百万个语音-标注对，其中包含物种、叫声上下文和动物行为信息。然后，通过在这个数据集上训练语音-语言表示之间的连接，该模型可以识别超过一千种动物的叫声，并在零样本下完成生物声学任务。</li>
<li>results: 当finetuned的BioLingual模型在九个任务上达到了新的状态态-of-the-art水平。此外，该模型可以通过自然语言查询来检索动物叫声录音，并且可以在不同的物种和环境下进行可扩展的应用。<details>
<summary>Abstract</summary>
Passive acoustic monitoring offers a scalable, non-invasive method for tracking global biodiversity and anthropogenic impacts on species. Although deep learning has become a vital tool for processing this data, current models are inflexible, typically cover only a handful of species, and are limited by data scarcity. In this work, we propose BioLingual, a new model for bioacoustics based on contrastive language-audio pretraining. We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, with over a million audio-caption pairs holding information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to be flexibly queried in human language, we believe this model opens new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We open-source our models, dataset, and code.
</details>
<details>
<summary>摘要</summary>
We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, which contains over one million audio-caption pairs with information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds.Given its broad taxa coverage and ability to be flexibly queried in human language, we believe that this model opens up new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We have made our models, dataset, and code open-source, allowing for further research and application of this technology.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning"><a href="#Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning" class="headerlink" title="Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning"></a>Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04964">http://arxiv.org/abs/2308.04964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biagio Montaruli, Luca Demetrio, Andrea Valenza, Luca Compagna, Davide Ariu, Luca Piras, Davide Balzarotti, Battista Biggio</li>
<li>for: 本研究旨在提高ModSecurity的攻击检测精度和鲁棒性，以帮助建立更加可靠和安全的Web应用程序防火墙（WAF）。</li>
<li>methods: 本研究使用机器学习模型，名为AdvModSec，来检测针对Web服务的SQL注入攻击（SQLi）。AdvModSec使用ModSecurity的核心规则集（CRS）作为输入特征，并通过训练来检测反对攻击。</li>
<li>results: 实验结果显示，AdvModSec可以提高ModSecurity的检测精度和鲁棒性，具体来说，可以提高检测率21%，并在对抗反对攻击方面提高鲁棒性42%。<details>
<summary>Abstract</summary>
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towards the protected web services, achieves a better trade-off between detection and false positive rates, improving the detection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover, our approach is able to improve its adversarial robustness against adversarial SQLi attacks by 42%, thereby taking a step forward towards building more robust and trustworthy WAFs.
</details>
<details>
<summary>摘要</summary>
mod_security是通用的开源网络应用程序防火墙（WAF），由OWASP基金会维护。它通过匹配核心规则集来检测攻击性请求，并且每个规则都被手动分配了严重程度，以及检测到的请求是否超过了一定的阈值。在这种简单的策略下，我们发现这个策略在检测SQL注入（SQLi）攻击时效果很差，因为它会拒绝许多合法请求，同时也容易受到攻击者的攻击。为了解决这些问题，我们设计了一个可靠的机器学习模型，名为AdvModSec，它使用核心规则集作为输入特征，并通过训练来检测攻击者Intentional地修改的SQLi攻击。我们的实验表明，AdvModSec在受到保护的网络服务的流量下进行训练后，可以提高检测率，同时也可以降低假阳性率，相比于vanilla版mod_security与核心规则集的检测率提高21%。此外，我们的方法还可以在面对攻击者Intentional地修改SQLi攻击后提高对抗性，提高了24%。这些成果表明我们的方法可以提高WAF的可靠性和信任性。
</details></li>
</ul>
<hr>
<h2 id="CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks"><a href="#CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks" class="headerlink" title="CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks"></a>CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04961">http://arxiv.org/abs/2308.04961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaoyuan011/casciff">https://github.com/xiaoyuan011/casciff</a></li>
<li>paper_authors: Hongjun Zhu, Shun Yuan, Xin Liu, Kuo Chen, Chaolong Jia, Ying Qian</li>
<li>for: 本研究旨在提高信息扩散预测的精度，特别是处理用户特征和信息扩散的复杂关系。</li>
<li>methods: 该研究提出了 Cross-Domain Information Fusion Framework (CasCIFF)，这是一种基于多个域的信息融合框架，通过多树邻域信息来提高用户嵌入的Robustness。在插入推荐时，该框架 INTENTIONALLY  integrate 时间戳，以捕捉信息扩散过程中的变化趋势。</li>
<li>results: 研究表明，CasCIFF 可以更好地捕捉用户行为和信息扩散的复杂关系，并且在信息扩散预测任务中表现出了superior的性能。<details>
<summary>Abstract</summary>
Existing approaches for information cascade prediction fall into three main categories: feature-driven methods, point process-based methods, and deep learning-based methods. Among them, deep learning-based methods, characterized by its superior learning and representation capabilities, mitigates the shortcomings inherent of the other methods. However, current deep learning methods still face several persistent challenges. In particular, accurate representation of user attributes remains problematic due to factors such as fake followers and complex network configurations. Previous algorithms that focus on the sequential order of user activations often neglect the rich insights offered by activation timing. Furthermore, these techniques often fail to holistically integrate temporal and structural aspects, thus missing the nuanced propagation trends inherent in information cascades.To address these issues, we propose the Cross-Domain Information Fusion Framework (CasCIFF), which is tailored for information cascade prediction. This framework exploits multi-hop neighborhood information to make user embeddings robust. When embedding cascades, the framework intentionally incorporates timestamps, endowing it with the ability to capture evolving patterns of information diffusion. In particular, the CasCIFF seamlessly integrates the tasks of user classification and cascade prediction into a consolidated framework, thereby allowing the extraction of common features that prove useful for all tasks, a strategy anchored in the principles of multi-task learning.
</details>
<details>
<summary>摘要</summary>
现有的信息冲击预测方法可以分为三个主要类别：基于特征的方法、基于点过程的方法和深度学习基于方法。其中，深度学习基于方法，具有出色的学习和表示能力，可以抵消其他方法的缺点。然而，当前的深度学习方法仍面临多个持续的挑战。特别是，准确地表示用户属性仍然是一个问题，因为因素如假账户和复杂的网络配置。过去的算法通常将用户活动的顺序序列化，而忽略了用户活动的时间序列信息。此外，这些技术通常不能整合时间和结构方面的信息，因此缺乏把握信息冲击的细腻传播趋势。为解决这些问题，我们提出了跨频率信息融合框架（CasCIFF），这是用于信息冲击预测的专门框架。这个框架利用多跳邻居信息来做用户嵌入 Robust。当嵌入冲击时，框架会意识到时间戳，以便捕捉信息传播中的演化趋势。具体来说，CasCIFF通过将用户分类和冲击预测任务融合到一起，从而允许提取共同的特征，这种策略基于多任务学习的原则。
</details></li>
</ul>
<hr>
<h2 id="Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning"><a href="#Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning" class="headerlink" title="Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning"></a>Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04960">http://arxiv.org/abs/2308.04960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diep Luong, Minh Tran, Shayan Gharib, Konstantinos Drossos, Tuomas Virtanen</li>
<li>for: 隐私保护在智能声学监测系统中一直是一个关键问题， где沟通可以被捕获并与系统运行环境中的目标信号一起记录。在这种研究中，我们提出了将两种常用的隐私保护方法集成到一起：源分离和对抗表示学习。我们的提议的系统学习声音录制的潜在表示，以防止区分沟通和非沟通录制。</li>
<li>methods: 我们的提议方法包括源分离网络对一些隐私敏感数据进行过滤，以及在对抗学习过程中学习隐私保护的表示。</li>
<li>results: 我们的结果表明，在比较不含源分离、不含对抗学习和不含两者的系统之间，我们的提议系统可以显著改善沟通隐私保护，同时保持声学监测任务的好性能。<details>
<summary>Abstract</summary>
Privacy preservation has long been a concern in smart acoustic monitoring systems, where speech can be passively recorded along with a target signal in the system's operating environment. In this study, we propose the integration of two commonly used approaches in privacy preservation: source separation and adversarial representation learning. The proposed system learns the latent representation of audio recordings such that it prevents differentiating between speech and non-speech recordings. Initially, the source separation network filters out some of the privacy-sensitive data, and during the adversarial learning process, the system will learn privacy-preserving representation on the filtered signal. We demonstrate the effectiveness of our proposed method by comparing our method against systems without source separation, without adversarial learning, and without both. Overall, our results suggest that the proposed system can significantly improve speech privacy preservation compared to that of using source separation or adversarial learning solely while maintaining good performance in the acoustic monitoring task.
</details>
<details>
<summary>摘要</summary>
privacy preservation已经是智能听音系统中的长期关注点，其中speech可以通过系统运行环境中的passive recording方式被记录。在这个研究中，我们提议将两种常用的隐私保护方法集成：源分离和对抗表示学习。我们的提议系统将learnlatent表示音频记录，以防止 differentiating between speech和non-speech记录。在源分离网络过滤一部分隐私敏感数据后，在对抗学习过程中，系统会学习隐私保护的表示。我们的实验结果表明，我们的提议方法可以在保持听音任务的好表现的同时，提高speech隐私保护比使用源分离或对抗学习独立的系统。
</details></li>
</ul>
<hr>
<h2 id="Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks"><a href="#Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks" class="headerlink" title="Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks"></a>Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04958">http://arxiv.org/abs/2308.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc W. Brittain, Luis E. Alvarez, Kara Breeden</li>
<li>for: 本研究旨在提出一种基于自适应控制和电动飞机的高效空中交通模式，以提供受欠服务市场的增加自动化交通。</li>
<li>methods: 该研究使用分布式学习框架，并开发了一种新的尺度观察网络和分布式计算架构，以实现高效的自适应分离能力。</li>
<li>results: numerical study表明，提出的方法可以在高强度、动态环境中保证安全有效的飞机分离，并且可以处理多种不确定性的信息。<details>
<summary>Abstract</summary>
Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details>
<details>
<summary>摘要</summary>
高级空中 mobilité (AAM) 引入了一种新的、高效的交通方式，通过车辆自主和电动飞机来提供受欢迎的交通 between  formerly underserved markets。  safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, vehicle dynamics knowledge, and weather.  the processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. these challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. we present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. the problem is formulated as a Markov decision process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. we introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. a comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details></li>
</ul>
<hr>
<h2 id="Variations-on-the-Reinforcement-Learning-performance-of-Blackjack"><a href="#Variations-on-the-Reinforcement-Learning-performance-of-Blackjack" class="headerlink" title="Variations on the Reinforcement Learning performance of Blackjack"></a>Variations on the Reinforcement Learning performance of Blackjack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07329">http://arxiv.org/abs/2308.07329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack">https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack</a></li>
<li>paper_authors: Avish Buramdoyal, Tim Gebbie</li>
<li>for: 这篇论文旨在研究黑板子游戏中的优化策略，以最大化长期收益而避免投资者落伍。</li>
<li>methods: 该论文使用q学习方法来解决黑板子游戏中的优化问题，并研究学习速率的响应函数和deck size的影响。</li>
<li>results: 研究发现，在黑板子游戏中，使用基础策略和高低系统的card counter可以使房间铺垮，并且牵涉到环境变化的影响。此外，q学习算法在不同deck size下的学习速率也得到了研究。<details>
<summary>Abstract</summary>
Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.
</details>
<details>
<summary>摘要</summary>
黑Jack或"21"是一款受欢迎的 карто牌类游戏，旨在通过获得手牌总数高于卡牌师的手牌总数，而不超过21。理想的黑Jack策略可以在长期内最大化财务回报，同时避免投资者的破产。黑Jack的杂 probabilistic环境和内在的奖励结构，使得黑Jack成为了研究增强学习代理人在环境变化下的理解的一个有appeal的问题。在这里，我们考虑了q学习解决方案，以实现最佳的游戏策略，并研究了算法在卡牌堆大小变化时的学习速率的响应。我们还实现了一个可以实现 universal blackjack规则的黑Jack模拟器，以示出一个基本策略和hi-lo系统的卡计数可以使得临场破产，并如何环境变化影响这种结果。我们的研究的新特点在于将这种概念理解与学习代理人的快速学习速率相联系起来。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection"><a href="#Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection" class="headerlink" title="Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection"></a>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04950">http://arxiv.org/abs/2308.04950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafna81/fakenewsdetection">https://github.com/shafna81/fakenewsdetection</a></li>
<li>paper_authors: Shafna Fitria Nur Azizah, Hasan Dwi Cahyono, Sari Widya Sihwi, Wisnu Widiarto</li>
<li>For: 本研究旨在探讨使用 transformer 模型进行假新闻检测，以提高假新闻检测精度。* Methods: 本研究使用了 ALBERT 模型，并对其进行了改进，以提高假新闻检测精度。* Results: 研究发现，使用 ALBERT 模型可以达到 87.6% 的准确率，86.9% 的精度，86.9% F1-score，以及 174.5 个运行时间（s&#x2F;epoch）。<details>
<summary>Abstract</summary>
Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa. However, the modified BERT models are not well explored for detecting fake news in Bahasa Indonesia. In this research, we explore those transformer models and found that ALBERT outperformed other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch) respectively. Source code available at: https://github.com/Shafna81/fakenewsdetection.git
</details>
<details>
<summary>摘要</summary>
假新闻是指在新闻媒体格式中存在假信息，但是未经正确处理的新闻媒体。假信息可能会挑衅或诋毁重要的实体或个人，甚至为创造者的个人利益而导致社会问题。分辨假新闻和真实新闻是一项挑战，因为有限的领域知识和时间约束。据调查，居民最容易遭受到诈骗和错误信息的地区是万隆、Special Capital Region of Jakarta和西 Java。转换器是一种人工智能（AI）自然语言处理领域的方法，使用深度学习架构。转换器实施了强大的注意力机制，并在平行处理文本，生成富有内在语义的单词表示。以前的研究表明，一种名为BERT的转换器模型在非转换器方法之上表现出优异。然而，一些研究表示，使用改进的BERT模型，如ALBERT和RoBERTa，可以进一步提高性能。然而，这些改进的BERT模型在假新闻检测中的表现还未得到广泛探索。在这项研究中，我们探索了这些转换器模型，并发现ALBERT在87.6%的准确率、86.9%的精度、86.9%的F1分数和174.5个运行时（s/epoch）中表现出优异。源代码可以在GitHub上获取：https://github.com/Shafna81/fakenewsdetection.git。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey"><a href="#Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey" class="headerlink" title="Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey"></a>Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04947">http://arxiv.org/abs/2308.04947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Wang, Jiawei Li, Lifan Zhao, Zhizhuo Kou, Xiaohan Wang, Xinyi Zhu, Hao Wang, Yanyan Shen, Lei Chen</li>
<li>For: 本研究目的是对外部知识的整合进行系统性的检讨和总结，以提高股票价格预测的准确性。* Methods: 本研究使用了非图structured和图structured的外部知识，包括文本、多媒体描述和股票市场的关联关系。* Results: 研究提出了一种系统性的方法，可以从不同的未结构化数据源中获取外部知识，并将其与历史价格特征进行融合。此外，研究还总结了一些相关的数据集和未来研究方向。<details>
<summary>Abstract</summary>
Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
预测股票价格是一个复杂的研究问题，因为股票市场具有自然的波动和非线性。在过去几年，带有知识的股票价格预测方法有着创新的成果，这些方法利用了外部知识来理解股票市场。虽然这些方法的重要性，但是学术研究中几乎没有系统地总结过去的研究，特别是对于不同类型的外部知识的分析。在这篇评论文中，我们将提供一个系统和全面的描述，涵盖从不同的未结构化数据源中获取外部知识，然后将其与历史价格特征结合在一起。此外，我们还会探讨不同类型的融合方法，以及可能的未来研究方向。Here's the translation of the text into Traditional Chinese:预测股票价格是一个复杂的研究问题，因为股票市场具有自然的波动和非线性。在过去几年，带有知识的股票价格预测方法有创新的成果，这些方法利用了外部知识来理解股票市场。处理这些方法的重要性，但是学术研究中几乎没有系统地总结过去的研究，特别是对于不同类型的外部知识的分析。在这篇评论文中，我们将提供一个系统和全面的描述，涵盖从不同的未结构化数据源中获取外部知识，然后将其与历史价格特征结合在一起。此外，我们还会探讨不同类型的融合方法，以及可能的未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption"><a href="#Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption" class="headerlink" title="Differentially Private Graph Neural Network with Importance-Grained Noise Adaption"></a>Differentially Private Graph Neural Network with Importance-Grained Noise Adaption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04943">http://arxiv.org/abs/2308.04943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Qi, Xi Lin, Jun Wu</li>
<li>for: 保护图形数据的隐私，特别是节点数据的隐私，when nodes represent personal and sensitive information。</li>
<li>methods: 提出了一种基于差分隐私的图 neural network (GNN) 算法， named NAP-GNN， which includes topology-based node importance estimation (TNIE) method, adaptive private aggregation method, and private training of graph learning algorithm with adaptive residual connection mode.</li>
<li>results:  theoretically analysis shows that NAP-GNN satisfies privacy guarantees, and empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) with differential privacy have been proposed to preserve graph privacy when nodes represent personal and sensitive information. However, the existing methods ignore that nodes with different importance may yield diverse privacy demands, which may lead to over-protect some nodes and decrease model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that need to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) with differential privacy have been proposed to protect graph privacy when nodes represent personal and sensitive information. However, existing methods ignore that nodes with different importance may have different privacy demands, which may lead to over-protecting some nodes and decreasing model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that needs to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders"><a href="#Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders" class="headerlink" title="Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders"></a>Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05133">http://arxiv.org/abs/2308.05133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Kumar Gupta, Rohit Sinha</li>
<li>for: 本研究旨在提高主要用于自动诊断精神疾病的方法的准确性。</li>
<li>methods: 本研究使用了一种新的方法，即从抽象特征空间中提取特定精神疾病的特征，以提高诊断的准确性。</li>
<li>results: 研究发现，通过去除数据杂质，可以显著提高主动神疾病和剂量精神疾病的诊断性能。<details>
<summary>Abstract</summary>
The primary method for identifying mental disorders automatically has traditionally involved using binary classifiers. These classifiers are trained using behavioral data obtained from an interview setup. In this training process, data from individuals with the specific disorder under consideration are categorized as the positive class, while data from all other participants constitute the negative class. In practice, it is widely recognized that certain mental disorders share similar symptoms, causing the collected behavioral data to encompass a variety of attributes associated with multiple disorders. Consequently, attributes linked to the targeted mental disorder might also be present within the negative class. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, MDD and PTSD detection performances are significantly improved.
</details>
<details>
<summary>摘要</summary>
主要方法用于自动诊断心理疾病traditionally involve使用二分类器。这些分类器通过使用面试设置收集的行为数据进行训练。在这个训练过程中，患有Specific mental disorder的数据被分类为正样本，而所有其他参与者的数据被分类为负样本。在实践中，一些心理疾病会表现相似的症状，导致收集的行为数据包含多种与多种疾病相关的特征。因此，与targeted mental disorder相关的特征可能会存在在负样本中。这种数据杂质可能会导致分类器的训练不优化。在这项研究中，我们 investigate这个假设在主要抑郁症(MDD)和创后应急压力反应症(PTSD)检测方面。结果显示，在移除数据杂质后，MDD和PTSD检测性能得到了显著改善。
</details></li>
</ul>
<hr>
<h2 id="An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning"><a href="#An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning"></a>An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04938">http://arxiv.org/abs/2308.04938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 这个论文的目的是比较不同的某些方法在多智能人工智能学习中的表现，以及一种基于 DIAL 和 COMA 的通信学习方法的实现。</li>
<li>methods: 这个论文使用的方法包括多种常见的某些方法，以及一种新的方法 named ST-DRU。</li>
<li>results: 论文的结果表明，ST-DRU 方法在不同环境中的表现最佳，它在每个实验中都达到了最佳或非常接近最佳性能，而且是唯一不会在任何环境中失败的方法。<details>
<summary>Abstract</summary>
Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.
</details>
<details>
<summary>摘要</summary>
互动是多智能算法学习中非常重要的一环，当机器人无法观察环境的全部状态时。通常，使得学习得到的通信频道是使用可微分的通信频道，让条件gradient流过到每个机器人作为回传的形式。但是，当使用类型为码的讯息时，条件gradient无法流过这种通信频道。先前的工作已经提出了解决这个问题的方法，但是这些方法在不同的通信学习架构和环境中进行 tested，使得比较困难。在这篇文章中，我们比较了多个现有的码化方法，以及一个新的方法。我们将这些比较在通信学习中使用其他机器人的条件gradient进行tests，并在多个环境中进行试验。此外，我们还提出了COMA-DIAL，一种基于DIAL和COMA扩展的通信学习方法，并将其与学习速率调整和适应性探索相结合。这使得我们能够在更复杂的环境中进行实验。我们的结果显示，这篇文章中所提出的新方法ST-DRU，在不同的环境中都能够取得最佳或接近最佳的表现。它在每个实验中都能够取得最好或接近最好的结果，并且是唯一不会在任何测试环境中失败的方法。
</details></li>
</ul>
<hr>
<h2 id="JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition"><a href="#JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition" class="headerlink" title="JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition"></a>JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04934">http://arxiv.org/abs/2308.04934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucian Bicsi, Bogdan Alexe, Radu Tudor Ionescu, Marius Leordeanu</li>
<li>for: 提高机器学习模型的总体性和精度，使其能够在不同数据集上进行更好的推断。</li>
<li>methods: 使用多个数据集的semi-supervised学习方法，通过将多个专家模型（每个专家模型在自己的数据集上进行预训练） concatenate 得到更多的特征表示，并通过学生-教师模式进行同时协同训练，以提高模型的泛化能力和精度。</li>
<li>results: 在四个视频动作识别数据集上进行验证，实验结果表明，在同时考虑所有数据集的semi-supervised学习 Setting下，模型可以获得显著的提升，比起初始专家模型。<details>
<summary>Abstract</summary>
We propose JEDI, a multi-dataset semi-supervised learning method, which efficiently combines knowledge from multiple experts, learned on different datasets, to train and improve the performance of individual, per dataset, student models. Our approach achieves this by addressing two important problems in current machine learning research: generalization across datasets and limitations of supervised training due to scarcity of labeled data. We start with an arbitrary number of experts, pretrained on their own specific dataset, which form the initial set of student models. The teachers are immediately derived by concatenating the feature representations from the penultimate layers of the students. We then train all models in a student-teacher semi-supervised learning scenario until convergence. In our efficient approach, student-teacher training is carried out jointly and end-to-end, showing that both students and teachers improve their generalization capacity during training. We validate our approach on four video action recognition datasets. By simultaneously considering all datasets within a unified semi-supervised setting, we demonstrate significant improvements over the initial experts.
</details>
<details>
<summary>摘要</summary>
我们提出了JEDI方法，这是一种多个数据集半supervised学习方法，它能够有效地将多个专家知识 fusion，来提高每个数据集的学生模型性能。我们的方法解决了当前机器学习研究中的两个重要问题：数据集之间的泛化和监督学习数据的稀缺。我们从arbitrary数量的专家开始，先在自己specific dataset上预训练student模型，然后将专家转化为教师，并通过学生-教师半supervised学习方式进行训练，直到收敛。在我们的高效的方法中，学生-教师训练是joint和端到端的，这表明在训练过程中，学生和教师都会提高其泛化能力。我们在四个视频动作识别数据集上验证了我们的方法，并证明了在同时考虑所有数据集的半supervised Setting下，我们的方法能够实现显著的改进。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery"><a href="#Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery" class="headerlink" title="Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery"></a>Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04923">http://arxiv.org/abs/2308.04923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hampe, Sanne G. M. van Velzen, Jean-Paul Aben, Carlos Collet, Ivana Išgum</li>
<li>For: This paper aims to develop a deep learning-based method for predicting fractional flow reserve (FFR) values along the coronary arteries from coronary computed tomography angiography (CCTA) scans.* Methods: The proposed method uses a variational autoencoder to characterize the artery and a convolutional neural network (CNN) to predict the FFR values. The CNN is supervised by multiple loss functions, including a loss function inspired by the Earth Mover’s Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve.* Results: The resulting FFR curves show good agreement with the reference, allowing the distinction between diffuse and focal coronary artery disease (CAD) distributions in most cases. The mean absolute difference in the area under the FFR pullback curve (AUPC) was 1.7.<details>
<summary>Abstract</summary>
Functionally significant coronary artery disease (CAD) is caused by plaque buildup in the coronary arteries, potentially leading to narrowing of the arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow to the myocardium. The current reference for establishing the presence of a functionally significant stenosis is invasive fractional flow reserve (FFR) measurement. To avoid invasive measurements, non-invasive prediction of FFR from coronary CT angiography (CCTA) has emerged. For this, machine learning approaches, characterized by fast inference, are increasingly developed. However, these methods predict a single FFR value per artery i.e. they don't provide information about the stenosis location or treatment strategy. We propose a deep learning-based method to predict the FFR along the artery from CCTA scans. This study includes CCTA images of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. First, a multi planar reconstruction (MPR) of the artery is fed to a variational autoencoder to characterize the artery, i.e. through the lumen area and unsupervised artery encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR along the artery. The CNN is supervised by multiple loss functions, notably a loss function inspired by the Earth Mover's Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve. To train and evaluate our model, eight-fold cross-validation was performed. The resulting FFR curves show good agreement with the reference allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method may pave the way towards fast, accurate, automatic prediction of FFR along the artery from CCTA.
</details>
<details>
<summary>摘要</summary>
《 coronary artery disease （CAD）的功能 significative coronary artery （CA）病变是由 CA 内积累物质堆积，导致 CA 的 luminal 尺寸减小，从而导致 coronary stenosis ，对 myocardium 的血液流减少具有重要作用。目前，确定 CAD 存在功能 significative stenosis 的参照标准是非侵入性 fractional flow reserve （FFR）测量。为了避免非侵入性测量，非侵入性预测 CCTA 图像中的 FFR 已经出现。这些方法具有快速的推理功能，但它们只能预测每条 CA 的单个 FFR 值，无法提供条件尺寸或治疗策略信息。我们提出了基于 deep learning 的方法，可以从 CCTA 图像中预测 CA 的 FFR。这个研究包括 CCTA 图像的 110 例患者，其中每例包含 112 条 CA。首先，MPR 图像被 feed 到 variational autoencoder，以 caracterize the artery，包括 luminal 区域和不supervised artery 编码。然后，使用 convolutional neural network （CNN）预测 CA 的 FFR。CNN 被多个损失函数 supervise，包括一个取自 Earth Mover's Distance （EMD）的损失函数，以正确地预测 FFR 下降的位置，以及一个 histogram-based 损失函数，以直接监督 FFR 曲线的坡度。为了训练和评估我们的模型，我们使用 eight-fold cross-validation 进行了训练和评估。结果显示，我们的 FFR 曲线与参照标准之间有良好的一致性，可以在大多数情况下分辨 diffuse 和 focal CAD 分布。量化评估表明，AUPC 的平均绝对差为 1.7。这种方法可能将为 CCTA 图像中的 FFR 预测带来快速、准确、自动化的方法。
</details></li>
</ul>
<hr>
<h2 id="GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters"><a href="#GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters" class="headerlink" title="GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters"></a>GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04905">http://arxiv.org/abs/2308.04905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, José Suárez-Varela, Xiang Shi, Shihan Xiao, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio</li>
<li>for: 这个论文是为了优化数据中心网络（DCN）中的堵塞控制（CC）而写的。</li>
<li>methods: 这个论文使用了机器学习（ML）和图神经网络（GNN）来实现分布式的ECN配置优化。它在交换机上部署分布式代理，通过与邻居交换机通信，以协同优化全局ECN配置。</li>
<li>results: 在评估中，GraphCC在不同的场景下表现出色，特别是在新的场景下（例如新的吞吐量工作负荷、故障、升级）下显示出优于状态艺术CC（ACC）的性能，升减流程完成时间（FCRT）和缓冲占用率（BO）。改进率可达20%，并且在不同的评估场景下均显示出优异性能。<details>
<summary>Abstract</summary>
Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN), and it is compatible with widely deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches that communicate with their neighbors to cooperate and optimize the global ECN configuration. In our evaluation, we test the performance of GraphCC under a wide variety of scenarios, focusing on the capability of this solution to adapt to new scenarios unseen during training (e.g., new traffic workloads, failures, upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for ECN tuning -- ACC -- and observe that our proposed solution outperforms the state-of-the-art baseline in all of the evaluation scenarios, showing improvements up to $20\%$ in Flow Completion Time as well as significant reductions in buffer occupancy ($38.0-85.7\%$).
</details>
<details>
<summary>摘要</summary>
压缩控制（CC）在数据中心网络（DCN）中扮演了基本角色，以优化网络吞吐量。目前，DCN主要实现了两种主要的 CC 协议：DCTCP 和 DCQCN。这两种协议都基于显式压缩通知（ECN）， intermediate switches 将包 WHEN 检测到压缩。因此，ECN 配置成为 CC 协议性能的关键因素。目前，网络专家通过手动设置ECN参数来优化网络性能。然而，今天的高速 DCN 经历了快速和突然变化，导致网络状态发生了剧烈变化（例如，动态流量负荷、广播事件、故障），这会导致网络资源的过度利用和低效性能。本文介绍了 GraphCC，一种基于机器学习的协议优化框架。我们的分布式解决方案基于多代理激励学习（MARL）和图神经网络（GNN），并与广泛部署的 ECN 基于 CC 协议相容。GraphCC 在 switches 上部署分布式代理，与其他 switches 通信以协调优化全局 ECN 配置。在我们的评估中，我们测试了 GraphCC 在多种场景下的性能，重点关注这种解决方案在新场景下（例如，新的流量负荷、故障、升级）未经训练时的可靠性。我们与 state-of-the-art MARL 基于 ECN 调试的解决方案（ACC）进行比较，并发现我们的提议的解决方案在所有评估场景中都高于 state-of-the-art 基线，实现了Flow Completion Time 的改进 ($20\%$) 以及显著减少缓存占用率（$38.0-85.7\%）。
</details></li>
</ul>
<hr>
<h2 id="Towards-true-discovery-of-the-differential-equations"><a href="#Towards-true-discovery-of-the-differential-equations" class="headerlink" title="Towards true discovery of the differential equations"></a>Towards true discovery of the differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04901">http://arxiv.org/abs/2308.04901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itmo-nss-team/klr2023_paper">https://github.com/itmo-nss-team/klr2023_paper</a></li>
<li>paper_authors: Alexander Hvatov, Roman Titov</li>
<li>for: 该论文旨在发展一种可解释性模型，特别是在自然相关领域。</li>
<li>methods: 该论文使用机器学习技术，特别是差分方程发现。</li>
<li>results: 该论文探讨了独立发现方程的前提和工具，并解决了评估发现的方程是否准确的挑战。<details>
<summary>Abstract</summary>
Differential equation discovery, a machine learning subfield, is used to develop interpretable models, particularly in nature-related applications. By expertly incorporating the general parametric form of the equation of motion and appropriate differential terms, algorithms can autonomously uncover equations from data. This paper explores the prerequisites and tools for independent equation discovery without expert input, eliminating the need for equation form assumptions. We focus on addressing the challenge of assessing the adequacy of discovered equations when the correct equation is unknown, with the aim of providing insights for reliable equation discovery without prior knowledge of the equation form.
</details>
<details>
<summary>摘要</summary>
differential equation发现，机器学习一个Subfield，用于开发可解释的模型，特别在自然相关应用中。通过专业地包含通用参数形式的动态方程和适当的分 diferencial项，算法可以自主发现方程从数据中。本文探讨无需专家输入的独立方程发现的前提和工具，消除方程形式假设的需求。我们专注于解决无法评估发现方程的正确性，当正确的方程未知时，提供可靠的方程发现无需先知方程形式的坚持。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients"><a href="#Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients" class="headerlink" title="Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients"></a>Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05765">http://arxiv.org/abs/2308.05765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mouli Bardhan Paul Angon</li>
<li>For: The paper aims to improve survival prediction in heart failure patients by leveraging data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier.* Methods: The paper uses the public UCL Heart failure (HF) survival dataset and employs the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF.* Results: The approach achieved 98.33% accuracy, which is the highest over existing work.Here’s the same information in Simplified Chinese text:* For: 这篇论文目标是提高心衰竭患者存活率预测，通过数据处理技术和Extra-Tree（ET）特征选择法和Random Forest（RF）分类器的结合。* Methods: 该论文使用公共的UCL心衰竭存活数据集，并使用ET特征选择算法选择最有用的特征。这些特征然后用于RF搜索。* Results: 方法实现了98.33%的准确率，超过了现有的工作。<details>
<summary>Abstract</summary>
Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种生命威胁性的疾病，影响全球数百万人。可以准确预测患者存活可以提供早期干预，提高患者结果。在这项研究中，我们探讨了使用数据处理技术和Extra-Tree（ET）特征选择方法，与Random Forest（RF）分类器结合，以提高心力衰竭患者存活预测。通过利用ET特征选择算法，我们寻找了心力衰竭存活最重要的预测器。使用公共的UCL心力衰竭存活数据集，我们使用ET特征选择算法确定最有用的特征。这些特征然后用于网格搜索RF模型的调整。最后，我们使用调整后的RF模型进行训练和评估，并使用不同的矩阵进行测试。我们的方法实现了98.33%的准确率，这是目前已知的最高水平。
</details></li>
</ul>
<hr>
<h2 id="Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites"><a href="#Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites" class="headerlink" title="Targeted and Troublesome: Tracking and Advertising on Children’s Websites"></a>Targeted and Troublesome: Tracking and Advertising on Children’s Websites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04887">http://arxiv.org/abs/2308.04887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Moti, Asuman Senol, Hamid Bostani, Frederik Zuiderveen Borgesius, Veelasha Moonsamy, Arunesh Mathur, Gunes Acar<br>for:* The paper focuses on the measurement of tracking and targeted advertising on websites directed at children.methods:* The authors use a multilingual classifier based on web page titles and descriptions to identify child-directed websites.* They crawl these websites from five vantage points to measure the prevalence of trackers, fingerprinting scripts, and advertisements.* They develop an ML pipeline to identify improper ads on child-directed websites by processing both images and text extracted from ads.results:* The authors find that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements.* They identify improper ads on child-directed websites, including ads for dating, weight loss, and mental health, as well as sex toys and flirting chat services.* The authors conclude that there is a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites.<details>
<summary>Abstract</summary>
On the modern web, trackers and advertisers frequently construct and monetize users' detailed behavioral profiles without consent. Despite various studies on web tracking mechanisms and advertisements, there has been no rigorous study focusing on websites targeted at children. To address this gap, we present a measurement of tracking and (targeted) advertising on websites directed at children. Motivated by lacking a comprehensive list of child-directed (i.e., targeted at children) websites, we first build a multilingual classifier based on web page titles and descriptions. Applying this classifier to over two million pages, we compile a list of two thousand child-directed websites. Crawling these sites from five vantage points, we measure the prevalence of trackers, fingerprinting scripts, and advertisements. Our crawler detects ads displayed on child-directed websites and determines if ad targeting is enabled by scraping ad disclosure pages whenever available. Our results show that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements--a practice that should require verifiable parental consent. Next, we identify improper ads on child-directed websites by developing an ML pipeline that processes both images and text extracted from ads. The pipeline allows us to run semantic similarity queries for arbitrary search terms, revealing ads that promote services related to dating, weight loss, and mental health; as well as ads for sex toys and flirting chat services. Some of these ads feature repulsive and sexually explicit imagery. In summary, our findings indicate a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites. To protect children and create a safer online environment, regulators and stakeholders must adopt and enforce more stringent measures.
</details>
<details>
<summary>摘要</summary>
现代网络上，跟踪器和广告商频繁地构建和利用用户的详细行为 profiles 而不经过用户的同意。尽管有各种研究关于网络跟踪机制和广告，但有一个缺乏关于直接向儿童targeted的网站的研究。为了填补这一漏洞，我们提供了一项测量tracking和targeted广告在directed at children的网站上的研究。由于缺乏全面的child-directed（即直接向儿童）网站列表，我们首先创建了一个多语言分类器，基于网页标题和描述来分类。将这些分类器应用于超过两百万页，我们编译了两千个child-directed网站的列表。从五个视点爬取这些站点，我们测量了跟踪器、指纹脚本和广告的存在。我们的爬虫检测在child-directed网站上显示的广告，并判断是否启用了广告targeting，并从可用的广告披露页面中抓取相关信息。我们的结果表明大约90%的child-directed网站 embedding一个或多个跟踪器，而约27%的网站上显示了targeted广告，这些广告应该需要可靠的父母consent。然后，我们使用机器学习管道来识别在child-directed网站上显示的不当广告。这个管道可以处理图像和文本抽取自广告，并允许我们对任意搜索关键词进行 semanticsimilarity 查询，揭示了关于约束、减肥和心理健康的服务，以及性 Toy和情趣交流服务的广告。一些这些广告包含了伤害和性革命的图像。总之，我们的发现表明许多广告商和child-directed网站不遵守隐私法规和儿童在线环境的安全做法。为了保护儿童和创造一个更安全的网络环境，管理者和关注者必须采取和实施更加严格的措施。
</details></li>
</ul>
<hr>
<h2 id="Decorrelating-neurons-using-persistence"><a href="#Decorrelating-neurons-using-persistence" class="headerlink" title="Decorrelating neurons using persistence"></a>Decorrelating neurons using persistence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04870">http://arxiv.org/abs/2308.04870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rballeba/decorrelatingneuronsusingpersistence">https://github.com/rballeba/decorrelatingneuronsusingpersistence</a></li>
<li>paper_authors: Rubén Ballester, Carles Casacuberta, Sergio Escalera</li>
<li>For: 提高深度学习模型的通用化能力* Methods: 使用 minimum spanning tree 计算 neuron 之间的 correlation dissimilarities，并使用这些误差来减少 neuron 之间的高相关性* Results: 比较 popular 误差函数，并证明了自己的效果，以及在不同的深度学习任务中的可应用性。Here’s the full translation of the paper’s abstract in Simplified Chinese:* For: 本文提出了一种新的方法，用于提高深度学习模型的通用化能力。* Methods: 该方法基于 minimum spanning tree 计算 neuron 之间的 correlation dissimilarities，并使用这些误差来减少 neuron 之间的高相关性。* Results: 比较 popular 误差函数，并证明了自己的效果，以及在不同的深度学习任务中的可应用性。<details>
<summary>Abstract</summary>
We propose a novel way to improve the generalisation capacity of deep learning models by reducing high correlations between neurons. For this, we present two regularisation terms computed from the weights of a minimum spanning tree of the clique whose vertices are the neurons of a given network (or a sample of those), where weights on edges are correlation dissimilarities. We provide an extensive set of experiments to validate the effectiveness of our terms, showing that they outperform popular ones. Also, we demonstrate that naive minimisation of all correlations between neurons obtains lower accuracies than our regularisation terms, suggesting that redundancies play a significant role in artificial neural networks, as evidenced by some studies in neuroscience for real networks. We include a proof of differentiability of our regularisers, thus developing the first effective topological persistence-based regularisation terms that consider the whole set of neurons and that can be applied to a feedforward architecture in any deep learning task such as classification, data generation, or regression.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的方法，用于提高深度学习模型的泛化能力，通过减少神经元之间的高相关性。我们提出了两种正则化项，其计算基于某个神经网络（或一个样本）中神经元之间的最小拓扑树，其边的权重是神经元之间的相关性差异。我们提供了广泛的实验，证明了我们的正则化项的有效性，并表明它们超过了popular ones。此外，我们还证明了直接对所有神经元之间的相关性进行最小化，会导致较低的准确率，这表明了人工神经网络中的约束扮演了重要的角色，这与一些 neuroscience 研究中的真实神经网络一致。我们还提供了正则化项的导函数整合，这是首次开发了考虑整个神经元集的 topological persistence 基于的有效正则化项，可以应用于任何深度学习任务，如分类、数据生成或回归。
</details></li>
</ul>
<hr>
<h2 id="Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis"><a href="#Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis" class="headerlink" title="Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?"></a>Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05129">http://arxiv.org/abs/2308.05129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nina Weng, Siavash Bigdeli, Eike Petersen, Aasa Feragen</li>
<li>for: 这个研究旨在探讨胸部X射线诊断预测性差异的原因。</li>
<li>methods: 我们提出了一种新的采样方法，以减少数据集中每个患者的记录数量的不均衡分布，同时减少标签错误的影响。</li>
<li>results: 我们的分析发现，数据集特有的因素，而不是基本的生理差异，是胸部X射线预测性差异的主要驱动者。<details>
<summary>Abstract</summary>
While many studies have assessed the fairness of AI algorithms in the medical field, the causes of differences in prediction performance are often unknown. This lack of knowledge about the causes of bias hampers the efficacy of bias mitigation, as evidenced by the fact that simple dataset balancing still often performs best in reducing performance gaps but is unable to resolve all performance differences. In this work, we investigate the causes of gender bias in machine learning-based chest X-ray diagnosis. In particular, we explore the hypothesis that breast tissue leads to underexposure of the lungs and causes lower model performance. Methodologically, we propose a new sampling method which addresses the highly skewed distribution of recordings per patient in two widely used public datasets, while at the same time reducing the impact of label errors. Our comprehensive analysis of gender differences across diseases, datasets, and gender representations in the training set shows that dataset imbalance is not the sole cause of performance differences. Moreover, relative group performance differs strongly between datasets, indicating important dataset-specific factors influencing male/female group performance. Finally, we investigate the effect of breast tissue more specifically, by cropping out the breasts from recordings, finding that this does not resolve the observed performance gaps. In conclusion, our results indicate that dataset-specific factors, not fundamental physiological differences, are the main drivers of male--female performance gaps in chest X-ray analyses on widely used NIH and CheXpert Dataset.
</details>
<details>
<summary>摘要</summary>
虽然许多研究已经评估了人工智能算法在医疗领域的公平性，但对差异的预测性表现的原因 часто不明确。这种不知道偏误的原因使得偏误缓解无法具有最佳效果，如果只是通过简单的数据平衡来减少性能差异。在这项工作中，我们调查了机器学习基于胸部X光图像的性别偏误。我们尝试了一种新的采样方法，以解决两个公共数据集中每个病人记录的极度不均衡的问题，同时减少标签错误的影响。我们对男女之间疾病、数据集和训练集中的性别表现进行了广泛的分析，发现数据集不均衡不是差异的唯一原因。此外，不同数据集中男女组的表现差异很大，这表明数据集特有的因素对男女组的表现产生了重要影响。最后，我们尝试了更 specifically investigate the effect of breast tissue, by cropping out the breasts from the recordings, but found that this did not resolve the observed performance gaps.  conclude, our results indicate that dataset-specific factors, rather than fundamental physiological differences, are the main drivers of male-female performance gaps in chest X-ray analyses on the widely used NIH and CheXpert Dataset.
</details></li>
</ul>
<hr>
<h2 id="Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning"><a href="#Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning"></a>Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04844">http://arxiv.org/abs/2308.04844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Thomas Somers, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究探讨了多 Agent 系统中 Agent 之间的交流如何影响系统的目标 достиvement。通过学习多 Agent 学习策略， Agent 可以 deterministic 地决定需要交换哪些信息。</li>
<li>methods: 本研究使用了多 Agent 强化学习技术，并 investigate 了不同的信息编码方法（mean message encoder 和 attention message encoder）在不同数量的 Agent 中的影响。</li>
<li>results: 结果表明，在大量 Agent 中，mean message encoder 一直表现出色，superior 于 attention message encoder。研究发现，使用 mean message encoder 的 Agent 采用了一种组合 exponential 和 logarithmic 函数的通信策略，以避免信息损失。<details>
<summary>Abstract</summary>
Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.
</details>
<details>
<summary>摘要</summary>
多个自动机制系统需要间接通信以实现目标。通过同时学习动作协议和通信协议使用多自动学习技术，代理人获得了自定义信息共享的灵活性。然而，当代理人数量增加时，我们需要创建消息中信息的编码。在这篇论文中，我们研究了增加消息中信息量和代理人数量的效果，并对两种消息编码方法进行评估：平均消息编码器和注意消息编码器。我们在矩阵环境中进行实验，结果显示，平均消息编码器一直表现出色，超过注意消息编码器。因此，我们分析了使用平均消息编码器的通信协议中的代理人们使用的函数，并结论这些函数是一种对抗函数和对数函数的组合，以避免在应用平均消息编码器后失去重要信息。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI"><a href="#Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI" class="headerlink" title="Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI"></a>Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05764">http://arxiv.org/abs/2308.05764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oetu/mmcl-ecg-cmr">https://github.com/oetu/mmcl-ecg-cmr</a></li>
<li>paper_authors: Özgün Turgut, Philip Müller, Paul Hager, Suprosanna Shit, Sophie Starck, Martin J. Menten, Eimo Martens, Daniel Rueckert</li>
<li>For: 这篇研究旨在提供一种免费和快速的心脏健康评估工具，并将详细的心脏诊断换到更加昂贵的心脏磁共振成像（CMR）成像中。* Methods: 这篇研究提出了第一个自我超vised contrastive方法，将频率域图像与CMR图像的领域专有信息转移到ECG嵌入中。这个方法结合多modal contrastive learning和封页数据模型，实现单个ECG数据的全面心脏检查。* Results: 在对40,044名UK BiobankSubject进行了广泛的实验之后，我们展示了我们的方法的实用性和普遍性。我们预测各个心脏疾病的Subject-specific预后，并从ECG数据中分类出不同的心脏型态。在质感分析中，我们显示了我们学习的ECG嵌入包含了CMR图像区域的信息。我们将整个数据pipeline公开供下载，包括源代码和预读模型的重量。<details>
<summary>Abstract</summary>
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from ECG data. In a qualitative analysis, we demonstrate that our learned ECG embeddings incorporate information from CMR image regions of interest. We make our entire pipeline publicly available, including the source code and pre-trained model weights.
</details>
<details>
<summary>摘要</summary>
电导gram (ECG) 是一种广泛可用的诊断工具，可以快速和Cost-effectively评估心血管健康。然而，详细的检查通常使用昂贵的心血管共振成像 (CMR) 图像进行诊断心血管疾病。虽然提供了详细的心血管解剖结构图像，但CMR成像因为长时间扫描和高成本而不太常用。为解决这个问题，我们提出了第一个自动学习对抗方法，将域特定信息从 CMR 图像传递到 ECG 嵌入。我们的方法结合多modal对抗学习和遮盖数据模型，以实现唯一从 ECG 数据进行全面卡ди亚层检查。在使用40044名UK Biobank参与者的数据进行广泛实验中，我们证明了我们的方法的实用性和普适性。我们预测参与者特定的各种心血管疾病的风险，并通过分析发现了具有不同心血管特征的卡ди亚。在质量分析中，我们发现我们学习的 ECG 嵌入包含 CMR 图像区域兴趣的信息。我们将整个管道公开，包括源代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="Intrinsic-Motivation-via-Surprise-Memory"><a href="#Intrinsic-Motivation-via-Surprise-Memory" class="headerlink" title="Intrinsic Motivation via Surprise Memory"></a>Intrinsic Motivation via Surprise Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04836">http://arxiv.org/abs/2308.04836</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opendilab/DI-engine">https://github.com/opendilab/DI-engine</a></li>
<li>paper_authors: Hung Le, Kien Do, Dung Nguyen, Svetha Venkatesh</li>
<li>for: 这种新的计算模型旨在解决现有的惊喜驱动的探索限制，即使用novelty的惊喜而不是惊喜的 норма来计算奖励。</li>
<li>methods: 我们使用一个记忆网络来存储和重建惊喜，并且使用这个记忆来估计惊喜的新鲜度。</li>
<li>results: 我们的实验表明，将这种记忆网络与不同的惊喜预测器结合使用可以提高探索行为的效率并提高终极性表现，包括雷达、导航和困难的Atari游戏。Is that what you were looking for?<details>
<summary>Abstract</summary>
We present a new computing model for intrinsic rewards in reinforcement learning that addresses the limitations of existing surprise-driven explorations. The reward is the novelty of the surprise rather than the surprise norm. We estimate the surprise novelty as retrieval errors of a memory network wherein the memory stores and reconstructs surprises. Our surprise memory (SM) augments the capability of surprise-based intrinsic motivators, maintaining the agent's interest in exciting exploration while reducing unwanted attraction to unpredictable or noisy observations. Our experiments demonstrate that the SM combined with various surprise predictors exhibits efficient exploring behaviors and significantly boosts the final performance in sparse reward environments, including Noisy-TV, navigation and challenging Atari games.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的计算模型，用于激励学习中的内在奖励，以解决现有的惊喜驱动探索的局限性。我们的奖励是惊喜的新鲜度，而不是惊喜的平均值。我们使用记忆网络来估计惊喜的新鲜度，并称之为惊喜记忆（SM）。我们的SM可以增强惊喜基于内在动机的能力，使机器人保持有趣的探索，同时减少不必要的吸引到不可预测或噪音观察的情况。我们的实验表明，SM结合不同的惊喜预测器可以实现高效的探索行为，并在稀有奖励环境中显著提高最终性能，包括噪音电视、导航和复杂的Atari游戏。
</details></li>
</ul>
<hr>
<h2 id="TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks"><a href="#TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks" class="headerlink" title="TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks"></a>TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04832">http://arxiv.org/abs/2308.04832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 提高神经网络的数值稳定性</li>
<li>methods: 提出了一种新的活化函数called Truncated and Signed Square Root (TSSR)函数</li>
<li>results: TSSR函数在各种应用领域中表现出色，比如计算机视觉、自然语言处理和语音识别等。<details>
<summary>Abstract</summary>
Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>> activation functions are crucial components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is unique because it is odd, nonlinear, monotone, and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other state-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.Here's the translation:<<SYS>>翻译以下文本为简化字典<</SYS>>激活函数是神经网络中重要的组件。在这篇论文中，我们介绍了一种新的激活函数，即 truncated and signed square root（TSSR）函数。这个函数是独特的，因为它是奇数，非线性，卷积和导数满是 monotone。其导数是连续的，总是正的。由于这些性质，它有可能改善神经网络的数值稳定性。几个实验证明，我们提出的 TSSR 函数在其他现有的激活函数中表现更好。该函数有广泛应用的前景，可以应用于计算机视觉、自然语言处理和语音识别等领域。
</details></li>
</ul>
<hr>
<h2 id="On-the-Unexpected-Abilities-of-Large-Language-Models"><a href="#On-the-Unexpected-Abilities-of-Large-Language-Models" class="headerlink" title="On the Unexpected Abilities of Large Language Models"></a>On the Unexpected Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09720">http://arxiv.org/abs/2308.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Nolfi</li>
<li>for: 这篇论文探讨大语言模型display的多种能力，包括预测人写的下一句文本。</li>
<li>methods: 论文使用了 indirect acquisition process 和其他已知的 indirect processes。</li>
<li>results: 论文 argued that large language models develop integrated abilities as a side effect of indirect acquisition, and discussed the predictability of these abilities. Additionally, the paper briefly discussed the relation between the cognitive skills acquired by these systems and human cognition.<details>
<summary>Abstract</summary>
Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
</details>
<details>
<summary>摘要</summary>
大型语言模型可以显示广泛的能力，而这些能力与它们所训练的任务没有直接的连接：预测人类写成的文本中的下一句。在这篇文章中，我讨论这种 indirect acquisition 过程的本质和其他已知 indirect process 之间的关系。我认为大型语言模型通过 indirect acquisition 过程中获得的能力具有一定的可预测性。最后，我 briefly discuss 这些系统所获得的认知技能与人类认知之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data"><a href="#Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data" class="headerlink" title="Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data"></a>Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04796">http://arxiv.org/abs/2308.04796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mirosław Pawlak, Mateusz Pabian, Dominik Rzepka</li>
<li>for: 这篇论文针对 Computational neuroscience, imaging, streaming data 和 finance 中的脉冲讯号数据进行应用，采用不同的神经网络和概率模型。</li>
<li>methods: 这篇论文使用了机器学习策略，将脉冲讯号数据分类为二分类问题，并使用非Parametric kernel classifier 来构建模型。</li>
<li>results: 论文提出了一个具有极限性的 Bayes 规则，并证明了这个规则在不断增加的录音时间间隔和训练集大小下的数据采样中的测度。<details>
<summary>Abstract</summary>
Spike trains data find a growing list of applications in computational neuroscience, imaging, streaming data and finance. Machine learning strategies for spike trains are based on various neural network and probabilistic models. The probabilistic approach is relying on parametric or nonparametric specifications of the underlying spike generation model. In this paper we consider the two-class statistical classification problem for a class of spike train data characterized by nonparametrically specified intensity functions. We derive the optimal Bayes rule and next form the plug-in nonparametric kernel classifier. Asymptotical properties of the rules are established including the limit with respect to the increasing recording time interval and the size of a training set. In particular the convergence of the kernel classifier to the Bayes rule is proved. The obtained results are supported by a finite sample simulation studies.
</details>
<details>
<summary>摘要</summary>
射频训练数据在计算神经科学、成像、流动数据和金融等领域发现了广泛的应用。机器学习策略 для射频训练基于各种神经网络和概率模型。 probabilistic 方法取决于射频训练模型的参数或非参数规定。本文考虑一类具有非参数强度函数的射频训练数据的两类统计分类问题。我们 derivation 出最优的 bayes 规则，然后形成插入非参数核函数分类器。我们证明了核函数分类器的极限性，包括记录时间间隔的增长和训练集大小的限制。特别是，我们证明了核函数分类器的极限性和 bayes 规则的同强性。获得的结果得到了finite sample 伪验的支持。
</details></li>
</ul>
<hr>
<h2 id="PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer"><a href="#PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer" class="headerlink" title="PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer"></a>PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04791">http://arxiv.org/abs/2308.04791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Songbo Wang, Yongxiang Wang</li>
<li>For: This paper aims to improve the performance of Transformer-based models in long-term time series forecasting (LTSF) tasks by addressing three key issues: temporal continuity, information density, and multi-channel relationships.* Methods: The proposed model, called PETformer, uses three innovative techniques: Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI) to introduce prior biases suitable for LTSF tasks.* Results: The proposed PETformer model achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.Here’s the Chinese version of the information points:* For: 这篇论文目的是提高Transformer基于模型在长期时间序预测（LTSF）任务中的表现，通过解决三个关键问题：时间连续性、信息密度和多通道关系。* Methods: 提议的模型被称为PETformer，使用了三种创新的技术：Placeholder Enhancement Technique（PET）、Long Sub-sequence Division（LSD）和Multi-channel Separation and Interaction（MSI），以引入适合LTSF任务的先验偏好。* Results: PETformer模型在八个常用的公共数据集上达到了状态之最（SOTA）的表现，比其他所有现有的模型都高。这表明Transformer仍然在LTSF中具有强大的能力。<details>
<summary>Abstract</summary>
Recently, Transformer-based models have shown remarkable performance in long-term time series forecasting (LTSF) tasks due to their ability to model long-term dependencies. However, the validity of Transformers for LTSF tasks remains debatable, particularly since recent work has shown that simple linear models can outperform numerous Transformer-based approaches. This suggests that there are limitations to the application of Transformer in LTSF. Therefore, this paper investigates three key issues when applying Transformer to LTSF: temporal continuity, information density, and multi-channel relationships. Accordingly, we propose three innovative solutions, including Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI), which together form a novel model called PETformer. These three key designs introduce prior biases suitable for LTSF tasks. Extensive experiments have demonstrated that PETformer achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.
</details>
<details>
<summary>摘要</summary>
Translation notes:1. "long-term time series forecasting" (LTSF) is translated as "长期时间序列预测" (Chángzhòng Shíjiàn Shílián Yùjian)2. "Transformer-based models" is translated as "基于Transformer的模型" (Jīyuè Transformer de Módeli)3. "simple linear models" is translated as "简单的线性模型" (Jìnduan de Língxíng Módeli)4. "prior biases" is translated as "先前的偏见" (Xiānqián de Péndiǎn)5. "Placeholder Enhancement Technique" is translated as "占位提升技术" (Jǐwèi Tiēshén Jìhuà)6. "Long Sub-sequence Division" is translated as "长 subsequences 分解" (Cháng Subseqences Fēnjiě)7. "Multi-channel Separation and Interaction" is translated as "多通道分离和互动" (Duō Tōngdào Fēnlíng Héhuìdòng)8. "novel model" is translated as "新型模型" (Xīn Xíng Módeli)9. "state-of-the-art" is translated as "现状最佳" (Xiànzhèng Zàiqiào)10. "outperforming" is translated as "超越" (Chāoyù)
</details></li>
</ul>
<hr>
<h2 id="SUnAA-Sparse-Unmixing-using-Archetypal-Analysis"><a href="#SUnAA-Sparse-Unmixing-using-Archetypal-Analysis" class="headerlink" title="SUnAA: Sparse Unmixing using Archetypal Analysis"></a>SUnAA: Sparse Unmixing using Archetypal Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04771">http://arxiv.org/abs/2308.04771</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/behnoodrasti/sunaa">https://github.com/behnoodrasti/sunaa</a></li>
<li>paper_authors: Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot</li>
<li>For: 本研究提出了一种基于文化分析的稀疏混合技术（SUnAA），用于解决稀疏混合问题。* Methods: 我们提出了一个基于文化分析的新模型，假设感兴趣的元件是spectral库提供的元件的几何聚合。然后，我们提出了一个非几何优化目标函数，并使用活动集算法进行迭代优化。* Results: 我们使用两个 simulations dataset进行评估，结果表明SUnAA在signal-to-reconstruction error方面表现更好于传统和先进的方法。此外，我们还应用了SUnAA到Cuprite dataset，并与可用的地质图比较。 qualitative assessment表明SUnAA可以成功地估计矿物含量，并在主要矿物的探测中具有显著改善。<details>
<summary>Abstract</summary>
This paper introduces a new sparse unmixing technique using archetypal analysis (SUnAA). First, we design a new model based on archetypal analysis. We assume that the endmembers of interest are a convex combination of endmembers provided by a spectral library and that the number of endmembers of interest is known. Then, we propose a minimization problem. Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex. We minimize the optimization objective iteratively using an active set algorithm. Our method is robust to the initialization and only requires the number of endmembers of interest. SUnAA is evaluated using two simulated datasets for which results confirm its better performance over other conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite dataset and the results are compared visually with the available geological map provided for this dataset. The qualitative assessment demonstrates the successful estimation of the minerals abundances and significantly improves the detection of dominant minerals compared to the conventional regression-based sparse unmixing methods. The Python implementation of SUnAA can be found at: https://github.com/BehnoodRasti/SUnAA.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这篇论文介绍了一种新的稀缺混合技术，基于型态分析（SUnAA）。该方法假设有兴趣的终端成分是spectral库中的终端成分的几何聚合，并且知道终端成分的数量。然后，我们提出了一个非对称的最小化问题。与大多数传统的稀缺混合方法不同，我们在这里使用了活动集算法来解决这个问题。我们的方法对初始化的敏感，只需要终端成分的数量。SUnAA在两个模拟 dataset 上进行评估，结果表明它在信号征化误差方面与其他传统和先进方法相比表现更好。SUnAA还应用于 Cuprite  dataset，并与可用的地质地图进行视觉比较。质量评估表明成功地估计矿物含量，并在主要矿物的检测方面提高了传统回归式稀缺混合方法的性能。Python实现的 SUnAA 可以在：https://github.com/BehnoodRasti/SUnAA 找到。
</details></li>
</ul>
<hr>
<h2 id="Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning"><a href="#Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning" class="headerlink" title="Tram-FL: Routing-based Model Training for Decentralized Federated Learning"></a>Tram-FL: Routing-based Model Training for Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04762">http://arxiv.org/abs/2308.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KotaMaejima/Tram-FL">https://github.com/KotaMaejima/Tram-FL</a></li>
<li>paper_authors: Kota Maejima, Takayuki Nishio, Asato Yamazaki, Yuko Hara-Azumi</li>
<li>for: 提高 federated learning 中的精度，解决非独立和相同分布的数据和高频通信导致的模型学习困难。</li>
<li>methods: 提出了一种新的 federated learning 方法，即 Tram-FL，它逐步提高全球模型，通过在节点之间进行模型传输，而不是通过交换和聚合本地模型。还引入了一种动态模型路由算法，以优化路径选择，以提高模型精度。</li>
<li>results: 通过 MNIST、CIFAR-10 和 IMDb 数据集的实验表明，Tram-FL 与提出的路由算法可以在非独立的条件下达到高精度，比基eline高，同时减少通信成本。<details>
<summary>Abstract</summary>
In decentralized federated learning (DFL), substantial traffic from frequent inter-node communication and non-independent and identically distributed (non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL, a novel DFL method, which progressively refines a global model by transferring it sequentially amongst nodes, rather than by exchanging and aggregating local models. We also introduce a dynamic model routing algorithm for optimal route selection, aimed at enhancing model precision with minimal forwarding. Our experiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FL with the proposed routing delivers high model accuracy under non-IID conditions, outperforming baselines while reducing communication costs.
</details>
<details>
<summary>摘要</summary>
在分布式联合学习（DFL）中，负担重大的交通和非独立同分布（非IID）数据带来高精度模型获得的挑战。我们提出了Tram-FL方法，它逐步进行全球模型的进一步精度提升，通过将其在节点之间顺序传输，而不是通过交换和聚合本地模型。我们还提出了一种动态模型路由算法，以优化路径选择，以提高模型精度，同时减少前进通信成本。我们通过使用MNIST、CIFAR-10和IMDb数据集进行实验，证明Tram-FL并与提出的路由算法在非IID条件下可以提供高精度模型，而且比基eline优化通信成本。
</details></li>
</ul>
<hr>
<h2 id="Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning"><a href="#Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning" class="headerlink" title="Feature Matching Data Synthesis for Non-IID Federated Learning"></a>Feature Matching Data Synthesis for Non-IID Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04761">http://arxiv.org/abs/2308.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Li, Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</li>
<li>for: 本研究旨在提出一种基于联合学习的数据同步方法，以解决非独立同分布（非IID）数据问题。</li>
<li>methods: 本文提出了一种困难特征匹配数据生成（HFMDS）方法，通过在本地模型之间共享辅助数据，以及在实际样本中学习重要的类相关特征，来有效地Address非IID问题。此外，我们还提出了一种困难特征增强方法，以将实际特征转移到决策边缘，从而保持隐私。</li>
<li>results: 我们的实验结果表明，将提案的HFMDS方法与联合学习结合使用，可以提高模型泛化性和隐私保护，同时降低计算成本。在多个benchmark数据集上，我们的提案HFMDS-FL算法比基eline表现出较高的准确率和隐私保护，同时计算成本也相对较低。<details>
<summary>Abstract</summary>
Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Federated 学习（FL）已经出现为一种隐私保护的思想，在边缘设备上训练神经网络而无需收集数据到中央服务器。然而，FL 面临着非独立和同分布（非IID）数据的挑战。为解决这个挑战，本文提议一种困难特征匹配数据生成（HFMDS）方法，以及在FL 中使用这种方法来共享辅助数据。具体来说，通过学习真实样本中重要的类相关特征，并丢弃 redundant 特征，可以生成高质量的synthetic数据，以有效地解决非IID 问题。为更好地保持隐私，我们提议一种困难特征扩充方法，将真实特征转移到决策边界，使得synthetic数据不仅提高模型泛化性，还将真实特征信息擦除。通过将提案的 HFMDS 方法与 FL 结合，我们提出了一种新的 FL 框架，并在这个框架中添加了数据扩充。理论分析表明，我们的提议的数据生成方法可以有效解决非IID 问题。实验结果还表明，我们的 HFMDS-FL 算法在各种 benchmark 数据集上比基eline 高于精度、隐私保护和计算成本。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data"><a href="#Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data" class="headerlink" title="Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data"></a>Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04755">http://arxiv.org/abs/2308.04755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data">https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data</a></li>
<li>paper_authors: Lukas Prediger, Joonas Jälkö, Antti Honkela, Samuel Kaski</li>
<li>for: collaborative learning on sensitive data without violating privacy constraints</li>
<li>methods: 使用具有隐私保证的合成数据分享</li>
<li>results: 与本地数据只使用的情况相比，通过共同学习合成数据集， partiesto obtain more accurate target statistics，尤其是在小型不同类型数据集中; 更多参与者参与学习，则改进的结果越来越大和一致。<details>
<summary>Abstract</summary>
Consider a setting where multiple parties holding sensitive data aim to collaboratively learn population level statistics, but pooling the sensitive data sets is not possible. We propose a framework in which each party shares a differentially private synthetic twin of their data. We study the feasibility of combining such synthetic twin data sets for collaborative learning on real-world health data from the UK Biobank. We discover that parties engaging in the collaborative learning via shared synthetic data obtain more accurate estimates of target statistics compared to using only their local data. This finding extends to the difficult case of small heterogeneous data sets. Furthermore, the more parties participate, the larger and more consistent the improvements become. Finally, we find that data sharing can especially help parties whose data contain underrepresented groups to perform better-adjusted analysis for said groups. Based on our results we conclude that sharing of synthetic twins is a viable method for enabling learning from sensitive data without violating privacy constraints even if individual data sets are small or do not represent the overall population well. The setting of distributed sensitive data is often a bottleneck in biomedical research, which our study shows can be alleviated with privacy-preserving collaborative learning methods.
</details>
<details>
<summary>摘要</summary>
假设多个方持有敏感数据，想要共同学习人口级统计数据，但汇集敏感数据集不可能。我们提出了一个框架，每个方共享一个具有隐私保证的假数据集。我们研究了将这些假数据集合用于共同学习的可能性，并应用于UK Biobank的真实世界医疗数据。我们发现，通过共同学习via共享假数据集，各方可以获得更准确的目标统计数据，包括小型不同类型数据集。此外，参与更多方会导致改进变得更大和更一致。最后，我们发现，共享假数据集可以帮助各方进行更好地调整分析，特别是对于被下代表的群体。根据我们的结果，我们认为共享假数据集是一种可靠的方法，允许保持隐私的方式进行敏感数据的学习，即使个人数据集小或者不代表整个人口。这种分布式敏感数据的设定frequently是生物医学研究中的瓶颈，我们的研究表明，这种瓶颈可以通过隐私保证的共同学习方法来缓解。
</details></li>
</ul>
<hr>
<h2 id="Universal-Fuzzing-via-Large-Language-Models"><a href="#Universal-Fuzzing-via-Large-Language-Models" class="headerlink" title="Universal Fuzzing via Large Language Models"></a>Universal Fuzzing via Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04748">http://arxiv.org/abs/2308.04748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, Lingming Zhang<br>for: 这篇论文是为了探讨一种基于大语言模型的通用软件测试工具（Fuzz4All），它可以针对多种输入语言和多种语言特性进行测试。methods: 这篇论文使用了大语言模型（LLM）作为输入生成和变换引擎，并提出了一种自动提示技术来创建适合软件测试的LLM提示。另外，它还提出了一种基于LLM的软件测试循环，可以在不同语言和不同特性下进行软件测试。results: 这篇论文的实验结果表明，使用Fuzz4All进行软件测试可以取得更高的覆盖率，而且可以发现76个在广泛使用的系统中的漏洞，其中47个已经确认由开发者们为之前未知的漏洞。<details>
<summary>Abstract</summary>
Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 76 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 47 bugs already confirmed by developers as previously unknown.
</details>
<details>
<summary>摘要</summary>
各种软件系统中的敏感区域漏洞探测得到了很大的成功，尤其是使用编程或正式语言作为输入的系统（SUT）。这些SUT包括编译器、运行时引擎、约束解决器和可用API的软件库等。然而，现有的敏感区域探测器通常只能针对特定语言，因此无法轻松地应用于其他语言或 même 同一种语言的其他版本。此外，现有的探测器通常仅生成特定语言的输入特性，因此很难暴露新的语言功能中的漏洞。本文介绍了Fuzz4All，首个可以针对多种输入语言和多种语言特性的敏感区域探测器。Fuzz4All的关键思想是利用大语言模型（LLM）作为输入生成和变换引擎，这使得它能够生成多样化和真实的输入 для任何实际有用的语言。为实现这一潜力，我们提出了一种自动提示技术，创建适合探测的 LLM 提示，以及一种基于 LLM 的探测循环，通过更新提示来创造新的探测输入。我们对 nine 种使用 six 种语言（C、C++、Go、SMT2、Java 和 Python）作为输入的系统进行了评估。评估结果显示，在所有 six 种语言中，通用探测 achieve higher coverage than existing, language-specific fuzzers。此外，Fuzz4All 已经发现了76个在广泛使用的系统中的漏洞，其中 47 个已经被开发者确认为之前未知的漏洞。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow"><a href="#Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow" class="headerlink" title="Optimizing a Transformer-based network for a deep learning seismic processing workflow"></a>Optimizing a Transformer-based network for a deep learning seismic processing workflow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04739">http://arxiv.org/abs/2308.04739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Randy Harsuko, Tariq Alkhalifah</li>
<li>for: 这篇论文的目的是提出一种基于Transformer的新型地震处理模型，并通过预训和精细训练策略来适应不同的地震处理任务。</li>
<li>methods: 这篇论文提议对StorSeismic模型进行两个关键修改：使用相对位置编码和低级对焦矩阵，以取代原始的普通自己注意机制和圆振对焦矩阵。</li>
<li>results: 试验结果显示，这些修改可以让StorSeismic模型在处理实际的Marmousi和海上场地数据时表现更快且有竞争力，同时需要训练更少的参数。<details>
<summary>Abstract</summary>
StorSeismic is a recently introduced model based on the Transformer to adapt to various seismic processing tasks through its pretraining and fine-tuning training strategy. In the original implementation, StorSeismic utilized a sinusoidal positional encoding and a conventional self-attention mechanism, both borrowed from the natural language processing (NLP) applications. For seismic processing they admitted good results, but also hinted to limitations in efficiency and expressiveness. We propose modifications to these two key components, by utilizing relative positional encoding and low-rank attention matrices as replacements to the vanilla ones. The proposed changes are tested on processing tasks applied to a realistic Marmousi and offshore field data as a sequential strategy, starting from denoising, direct arrival removal, multiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$) prediction for normal moveout (NMO) correction. We observe faster pretraining and competitive results on the fine-tuning tasks and, additionally, fewer parameters to train compared to the vanilla model.
</details>
<details>
<summary>摘要</summary>
史顿希伯是一种最近引入的模型，基于Transformer来适应不同的地震处理任务。在原始实现中，史��ton希伯使用了抽象位编码和常见的自注意机制，从自然语言处理（NLP）应用中借鉴。对地震处理来说，它们得到了良好的结果，但也表现了效率和表达能力的限制。我们提议对这两个关键组件进行修改，使用相对位置编码和低级别注意矩阵作为替代物。我们对处理任务进行了顺序推进，从噪声除除、直接到达除、多个减弱、最后是根mean-squared velocity（$V_{RMS}$）预测 для正常移动（NMO） corrections。我们发现在先修改任务上快速预训练，并在细化任务上获得了竞争性的结果，同时又需要训练 fewer 参数。
</details></li>
</ul>
<hr>
<h2 id="Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations"><a href="#Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations" class="headerlink" title="Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations"></a>Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04735">http://arxiv.org/abs/2308.04735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongho Kim, Yongho Choi</li>
<li>for:  solves partial differential equations (PDEs) with diverse initial conditions using physics-informed neural networks (PINNs).</li>
<li>methods:  uses five-point stencil convolutional neural networks (FCNNs) with large receptive fields to predict time evolutions, and trains the models using two consecutive snapshots with a time step that satisfies the CFL condition.</li>
<li>results:  demonstrates that the proposed deep FCNNs retain certain accuracies for the heat, Fisher’s, and Allen-Cahn equations, in contrast to finite difference methods (FDMs) that blow up.<details>
<summary>Abstract</summary>
Physics-informed neural networks have been widely applied to partial differential equations with great success because the physics-informed loss essentially requires no observations or discretization. However, it is difficult to optimize model parameters, and these parameters must be trained for each distinct initial condition. To overcome these challenges in second-order reaction-diffusion type equations, a possible way is to use five-point stencil convolutional neural networks (FCNNs). FCNNs are trained using two consecutive snapshots, where the time step corresponds to the step size of the given snapshots. Thus, the time evolution of FCNNs depends on the time step, and the time step must satisfy its CFL condition to avoid blow-up solutions. In this work, we propose deep FCNNs that have large receptive fields to predict time evolutions with a time step larger than the threshold of the CFL condition. To evaluate our models, we consider the heat, Fisher's, and Allen-Cahn equations with diverse initial conditions. We demonstrate that deep FCNNs retain certain accuracies, in contrast to FDMs that blow up.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks 已经广泛应用于部分偏微分方程，取得了很大成功，因为物理学 Informed 损失函数不需要观测或离散。然而，模型参数很难优化，这些参数需要为每个不同的初始条件进行训练。为了解决这些挑战，在第二阶段反应扩散类方程中，可以使用五点矩阵卷积神经网络（FCNN）。FCNN 通过两个连续的快照，其中时间步骤与给出的快照步骤相对应，因此 FCNN 的时间演化取决于时间步骤，并且时间步骤必须满足其 CFL 条件，以避免出现冲击解。在这种工作中，我们提议使用深度 FCNN，其具有大接收场，预测时间演化，时间步骤大于阈值 CFD 条件。为了评估我们的模型，我们考虑了热、施德、艾伦-卡恩方程，并对不同的初始条件进行评估。我们发现深度 FCNN 保留了一定的准确性，与 FDM 不同，后者会冲击。
</details></li>
</ul>
<hr>
<h2 id="JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models"><a href="#JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models" class="headerlink" title="JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"></a>JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04729">http://arxiv.org/abs/2308.04729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, Alex Wang</li>
<li>for: 本研究旨在提出一种高效、高精度的文本到音乐生成模型（JEN-1），用于解决文本描述下的音乐生成问题。</li>
<li>methods: JEN-1 使用了混合式扩散学习策略，结合了 autoregressive 和 non-autoregressive 训练方法，通过在上下文学习来实现多种生成任务，包括文本指导的音乐生成、音乐填充和续写。</li>
<li>results: 对比prevailing方法，JEN-1 在文本音乐对齐和音乐质量两个指标上具有显著优势，同时保持了计算效率。您可以通过访问 <a target="_blank" rel="noopener" href="http://futureverse.com/research/jen/demos/jen1">http://futureverse.com/research/jen/demos/jen1</a> 来听取我们的示例作品。<details>
<summary>Abstract</summary>
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at http://futureverse.com/research/jen/demos/jen1
</details>
<details>
<summary>摘要</summary>
音乐生成已经吸引了深入的研究，随着深度生成模型的发展，但是基于文本描述的音乐生成，也就是文本到音乐（text-to-music），仍然是一个挑战。这是因为音乐结构的复杂性和高采样率的要求。虽然这个任务的重要性，现有的生成模型却表现出一些限制，包括音乐质量、计算效率和通用性。这篇论文介绍了JEN-1，一种通用高准确度模型，用于文本到音乐生成。JEN-1是一种扩散模型，通过内容学习来实现文本指导的音乐生成、音乐填充和续写等多种生成任务。评估结果表明，JEN-1在文本音乐对齐和音乐质量方面的表现较为出色，同时保持计算效率。您可以在http://futureverse.com/research/jen/demos/jen1中查看我们的示例。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection"><a href="#Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection" class="headerlink" title="Data-Free Model Extraction Attacks in the Context of Object Detection"></a>Data-Free Model Extraction Attacks in the Context of Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05127">http://arxiv.org/abs/2308.05127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar</li>
<li>for: 保护机器学习模型免受模型抽取攻击，攻击者可以使用特制的查询来劫持目标模型。</li>
<li>methods: 使用生成器类似于Generative Adversarial Nets生成人工查询，并定义损失函数和新的生成器设置来实现对目标模型的抽取。</li>
<li>results: 通过使用合理的查询，提出了一种数据free模型抽取方法，并在对象检测预测任务中实现了显著的结果。这种抽取方法将支持未来保护机器学习模型的安全。<details>
<summary>Abstract</summary>
A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models.
</details>
<details>
<summary>摘要</summary>
许多机器学习模型容易受到模型提取攻击，这些攻击集中在使用特制的查询来盗取目标模型。这种任务在白盒环境中非常成功，通过使用目标模型的一部分训练数据或代理数据集来训练一个模仿目标模型的新模型。然而，在实际情况下，目标模型通常是使用私有数据进行训练，这些数据对于敌方无法访问。我们提出了第一次，至少知道的恶意黑盒攻击，扩展到回归问题，用于预测对象检测中的 bounding box 坐标。在我们的研究中，我们发现了定义损失函数和使用新的生成器设置是抽取目标模型的关键因素。我们发现，我们提议的模型提取方法可以使用合理的查询来获得显著的结果。这种对象检测攻击发现将支持未来对这些模型的安全。
</details></li>
</ul>
<hr>
<h2 id="Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning"><a href="#Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning" class="headerlink" title="Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning"></a>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04712">http://arxiv.org/abs/2308.04712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Philip S. Yu</li>
<li>For: The paper is written for task-oriented dialogue (TOD) systems, specifically to improve the performance of natural language understanding (NLU) tasks such as intent detection and slot filling.* Methods: The paper proposes a method called Slot Induction (SI) that uses unsupervised pre-trained language models (PLMs) and contrastive learning to induce slot boundaries without explicit knowledge of token-level slot annotations.* Results: The paper shows that the proposed SI method is effective in the SI task and can bridge the gap with token-level supervised models on two NLU benchmark datasets. Additionally, the paper shows that the SI objectives can provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了提高对话系统的自然语言理解性能而写的，具体来说是为了改进意向检测和插槽填充等任务。</li>
<li>methods: 这篇论文提出了一种无监督语言模型（PLM）探索和对比学习的方法，用于不Explicitly knowledge of token-level插槽标签来逻归插槽界限。</li>
<li>results: 论文显示，提出的SI方法在SI任务中效果很好，可以与token级监督模型在两个NLUbenchmark dataset上凑成一个比。此外，论文还显示，SI目标可以提供更好的插槽标签表示，导致插槽填充任务的改进表现。<details>
<summary>Abstract</summary>
Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.
</details>
<details>
<summary>摘要</summary>
现代技术在任务对话（TOD）系统中的自然语言理解（NLP）方面（例如，意图检测和槽填充）需要大量注解数据来达到竞争性表现。然而，在实际应用中，token级别的注解（槽标签）是时间consuming和困难的获得。在这种工作中，我们研究了槽引入（SI）任务，其目标是无需明确的token级别槽标签来induce槽界限。我们提议利用无监督语言模型（PLM）探测和对比学习机制，以利用PLM中的无监督semantic知识，以及TOD中可获得的句子级意图标签信号。我们的方法在SI任务中显示效果，可以bridge带有token级别监督模型的 gap，在两个NLU benchmark数据集上。此外，当扩展到新意图时，我们的SI目标还能提供加强的槽标签表示，导致在槽填充任务中提高表现。
</details></li>
</ul>
<hr>
<h2 id="Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution"><a href="#Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution" class="headerlink" title="Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution"></a>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04708">http://arxiv.org/abs/2308.04708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idesan/gpa">https://github.com/idesan/gpa</a></li>
<li>paper_authors: Tsuyoshi Idé, Naoki Abe</li>
<li>for: 这 paper 的目的是解释黑盒回归中的异常分布。</li>
<li>methods: 这 paper 使用了一种新的框架，即Counterfactual Variational Bayes（CVB），来计算输入变量的异常分布。</li>
<li>results: 这 paper 得到了一种不受偏见的异常分布计算方法，并且可以量化异常分布的不确定性。<details>
<summary>Abstract</summary>
We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.   We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.
</details>
<details>
<summary>摘要</summary>
我团队正在研究黑盒回归Setting中的概率异常归属问题，目标是计算每个输入变量的归属分布，给出观察到的异常。我们假设训练数据集不可用。这个任务与标准XAI（可解释AI）场景不同，我们想要解释黑盒预测的异常偏差而不是黑盒模型本身。我们首先显示了主流的模型无关解释方法，如夏普利值（Shapley value），不适合这个任务，因为它们的偏差无关性。然后，我们提出了一种新的概率异常归属框架，允许我们不仅计算归属分布，还可以评估这些分布的不确定性。这是通过考虑一种对 perturbations 的生成过程来实现的，该过程可以在观察到的异常 observation 的情况下，Counter-factually 带回正常。我们提出了一种变分 Bayes 算法来 derivation 每个变量归属分布的分布。到目前为止，这是免除偏差无关性的第一个概率异常归属框架。
</details></li>
</ul>
<hr>
<h2 id="Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation"><a href="#Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation" class="headerlink" title="Pareto Invariant Representation Learning for Multimedia Recommendation"></a>Pareto Invariant Representation Learning for Multimedia Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04706">http://arxiv.org/abs/2308.04706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Huang, Haoxuan Li, Qingsong Li, Chunyuan Zheng, Li Liu</li>
<li>for: 提高多媒体推荐模型的个性化排序和环境适应能力。</li>
<li>methods: 提出了一种基于Pareto优化的多对多目标优化框架，同时学习具有吸引用户注意力的内在因素和其他因素。</li>
<li>results: 在三个公共多媒体推荐数据集上进行比较，研究结果表明PaInvRL模型可以在不同环境下具有优秀的内在和跨环境学习能力。<details>
<summary>Abstract</summary>
Multimedia recommendation involves personalized ranking tasks, where multimedia content is usually represented using a generic encoder. However, these generic representations introduce spurious correlations that fail to reveal users' true preferences. Existing works attempt to alleviate this problem by learning invariant representations, but overlook the balance between independent and identically distributed (IID) and out-of-distribution (OOD) generalization. In this paper, we propose a framework called Pareto Invariant Representation Learning (PaInvRL) to mitigate the impact of spurious correlations from an IID-OOD multi-objective optimization perspective, by learning invariant representations (intrinsic factors that attract user attention) and variant representations (other factors) simultaneously. Specifically, PaInvRL includes three iteratively executed modules: (i) heterogeneous identification module, which identifies the heterogeneous environments to reflect distributional shifts for user-item interactions; (ii) invariant mask generation module, which learns invariant masks based on the Pareto-optimal solutions that minimize the adaptive weighted Invariant Risk Minimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, which generates both variant representations and item-invariant representations for training a multi-modal recommendation model that mitigates spurious correlations and balances the generalization performance within and cross the environmental distributions. We compare the proposed PaInvRL with state-of-the-art recommendation models on three public multimedia recommendation datasets (Movielens, Tiktok, and Kwai), and the experimental results validate the effectiveness of PaInvRL for both within- and cross-environmental learning.
</details>
<details>
<summary>摘要</summary>
multimedia推荐通常包括个性化排序任务，其中 multimedia 内容通常使用一个通用编码器表示。然而，这些通用表示引入了假 correlate 问题，这些问题使得用户的真实喜好不能正确反映。现有的工作尝试通过学习不变表示来缓解这个问题，但是忽略了IID和OOD总体化的平衡。在这篇论文中，我们提出一个名为Pareto不变表示学习（PaInvRL）的框架，用于减轻IID-OOD多目标优化视角下的假 correlate 问题。具体来说，PaInvRL包括三个相互执行的模块：（i）不同环境标识模块，用于反映用户-项目交互中的分布转移；（ii）不变Mask生成模块，用于基于Pareto优化解决方案Minimize适应权重不变风险（IRM）和实际风险（ERM）损失中的不变Mask；（iii）转换模块，用于生成 variant 表示和项目不变表示，以用于训练一个多Modal推荐模型，以避免假 correlate 和 Balance 在环境分布下的总体化性能。我们对三个公共 multimedia 推荐数据集（Movielens、Tiktok和Kwai）进行比较，并证明PaInvRL在内部和交叉环境中的学习表现效果。
</details></li>
</ul>
<hr>
<h2 id="A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection"><a href="#A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection" class="headerlink" title="A Feature Set of Small Size for the PDF Malware Detection"></a>A Feature Set of Small Size for the PDF Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04704">http://arxiv.org/abs/2308.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Liu, Charles Nicholas</li>
<li>for: 这项研究旨在提出一个小型特征集，以提高PDF malware检测系统的性能。</li>
<li>methods: 该研究使用了六种不同的机器学习模型，并评估了提议的特征集。</li>
<li>results: 研究发现，使用Random Forest模型可以达到99.75%的最高准确率，并且该特征集的12个特征是PDF malware检测领域中最短的之一。<details>
<summary>Abstract</summary>
Machine learning (ML)-based malware detection systems are becoming increasingly important as malware threats increase and get more sophisticated. PDF files are often used as vectors for phishing attacks because they are widely regarded as trustworthy data resources, and are accessible across different platforms. Therefore, researchers have developed many different PDF malware detection methods. Performance in detecting PDF malware is greatly influenced by feature selection. In this research, we propose a small features set that don't require too much domain knowledge of the PDF file. We evaluate proposed features with six different machine learning models. We report the best accuracy of 99.75% when using Random Forest model. Our proposed feature set, which consists of just 12 features, is one of the most conciseness in the field of PDF malware detection. Despite its modest size, we obtain comparable results to state-of-the-art that employ a much larger set of features.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:机器学习（ML）基于的钓鱼攻击检测系统正在日益重要，因为钓鱼威胁不断增长和变得更加复杂。PDF文档经常用于钓鱼攻击，因为它们被广泛认为是可靠的数据资源，可以在不同的平台上访问。因此，研究人员已经开发了许多不同的PDF钓鱼检测方法。检测PDF钓鱼的性能受到特征选择的影响。在本研究中，我们提出了一个小的特征集，不需要过多的领域知识。我们使用六种不同的机器学习模型评估提案的特征。我们发现使用随机森林模型时的最佳准确率为99.75%。我们提出的特征集，包含12个特征，是PDF钓鱼检测领域中最短的一个。尽管它的规模不大，但我们得到了与领先的方法相当的结果。
</details></li>
</ul>
<hr>
<h2 id="An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms"><a href="#An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms" class="headerlink" title="An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms"></a>An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04697">http://arxiv.org/abs/2308.04697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, P. J. A. Alphonse, Selvakumar K</li>
<li>for: 这项研究是为了研究COVID-19病毒的蛋白质互作网络，以便更好地理解疾病的发展和找到新的治疗方法。</li>
<li>methods: 这项研究使用了三种图库 clustering算法来分析COVID-19数据集中的蛋白质互作网络，以获得更好的分析INTUITION。</li>
<li>results: 研究发现，COVID-19病毒的蛋白质互作网络具有较强的稠密度和连接度，这些特征可能与疾病的发展和恶化有关。<details>
<summary>Abstract</summary>
Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is initially identified in Wuhan of China in December of 2019 and now this deadly disease has spread all over the world. According to World Health Organization (WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case, many methods, AI base techniques, and machine learning algorithms have been researched and are being used to save people from this pandemic. The SARS-CoV and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences in the structure of cell proteins. Protein-protein interaction (PPI) is an essential process in our cells and plays a very important role in the development of medicines and gives ideas about the disease. In this study, we performed clustering on PPI networks generated from 92 genes of the Covi-19 dataset. We have used three graph-based clustering algorithms to give intuition to the analysis of clusters.
</details>
<details>
<summary>摘要</summary>
“科罗纳病毒病”，简称“ COVID-19”，是一种新型病毒，最初在2019年12月在中国武汉地区被发现，现在这种致命病已经在全球蔓延。根据世界卫生组织（WHO）的统计，2019年至2021年4月，总共有3,124,905人死亡。在这个情况下，许多方法、AI基础技术和机器学习算法都在应用以拯救人类。SARS-CoV和2019-nCoV病毒会入侵我们的身体，导致细胞蛋白结构的一些差异。蛋白蛋白互动（PPI）是我们细胞中的一个重要过程，它对于药物的发展和疾病的了解具有非常重要的作用。在这个研究中，我们使用了92个Covi-19数据集中的PPI网络进行对数据的分组。我们使用了三种图形基础的分组算法，以提供分析结果的直觉。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects"><a href="#Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects" class="headerlink" title="Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects"></a>Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04696">http://arxiv.org/abs/2308.04696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheyla Amirian, Luke A. Carlson, Matthew F. Gong, Ines Lohse, Kurt R. Weiss, Johannes F. Plate, Ahmad P. Tafti</li>
<li>for: The paper is written to address the challenge of explainable AI (XAI) in orthopedics and to emphasize the need for interdisciplinary collaborations to establish standards and guidelines for the adoption of XAI in orthopedics.</li>
<li>methods: The paper uses a combination of AI models and algorithms that prioritize transparency and interpretability to address the challenge of XAI in orthopedics.</li>
<li>results: The paper highlights the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为了解决医学领域中的可解释人工智能（XAI）问题，并且强调需要多元合作来建立XAI在骨科领域的标准和指南。</li>
<li>methods: 这篇论文使用了优先级公布和可解释的人工智能模型和算法来解决XAI在骨科领域的挑战。</li>
<li>results: 这篇论文提出了多元合作的需要，以建立XAI在骨科领域的标准和指南，并且强调了在实施XAI时，需要与医生、外科医生和管理机构之间的合作。<details>
<summary>Abstract</summary>
While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在不同领域已经取得了许多成功应用，但在医疗领域的采纳 slower 了一些。这些因素包括法规框架、患者隐私问题和数据不一致。然而，在医疗领域，特别是在 ortopedics 中，缺乏 Explainable AI（XAI）是实现 AI 的主要挑战。 Addressing the challenge of XAI in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. 现在的贡献将描述 XAI 在 ortopedics 中的一些关键挑战和机遇。这篇文章强调了在 AI 实践者、orthopedic 专家和 regulatory 机构之间的交往合作，以确立 XAI 在 ortopedics 中的标准和指南。
</details></li>
</ul>
<hr>
<h2 id="Finite-Element-Operator-Network-for-Solving-Parametric-PDEs"><a href="#Finite-Element-Operator-Network-for-Solving-Parametric-PDEs" class="headerlink" title="Finite Element Operator Network for Solving Parametric PDEs"></a>Finite Element Operator Network for Solving Parametric PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04690">http://arxiv.org/abs/2308.04690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jae Yong Lee, Seungchan Ko, Youngjoon Hong</li>
<li>for: 解决Parametric Partial Differential Equations (PDEs)的数值计算问题，即使没有输入输出对应的训练数据。</li>
<li>methods: 提议使用Finite Element Operator Network (FEONet)，结合深度学习和传统的数值方法（特别是finite element方法）解决Parametric PDEs。</li>
<li>results: 对多个 benchmark 问题进行了实验，证明了我们的方法在准确性、泛化能力和计算灵活性等方面表现出色，并且超过了现有的状态艺术方法。<details>
<summary>Abstract</summary>
Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and singular behavior. Furthermore, we provide theoretical convergence analysis to support our approach, utilizing finite element approximation in numerical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network"><a href="#Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network" class="headerlink" title="Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network"></a>Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05125">http://arxiv.org/abs/2308.05125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse</li>
<li>for: 这个研究旨在通过社群分析方法揭示 variant B.1.1.529 (Omicron virus) 中的社群结构，以提高我们对这种病毒的分子水平理解，并且帮助开发新的药物和个性化医疗方法。</li>
<li>methods: 这个研究使用了两种提出的新算法（ABCDE和ALCDE）和四种广泛使用的算法（Girvan-Newman、Louvain、Leiden和Label Propagation）来检测 variant B.1.1.529 网络中的社群结构。</li>
<li>results: 研究发现，使用不同的算法可以检测出 variant B.1.1.529 网络中的社群结构，并且这些社群结构具有独特的特征和性质。<details>
<summary>Abstract</summary>
The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities within complex networks. We also compare the networks by the global properties, statistic summary, subgraph count, graphlet and validate by the modulaity. By employing these approaches, we sought to gain deeper insights into the structural organization and interconnections present within the Omicron virus network.
</details>
<details>
<summary>摘要</summary>
“蛋白质-蛋白质互动的能力和内部模块化结构在分子层面上关键地影响生物过程的复杂机制。我们可以通过网络分析来学习这些互动的结构和动力学。通过认可网络社区，我们可以更深入地理解疾病生物根据，这将有助于医疗药物发现和疾病治疗中采取人类化方法。在这个研究中，我们使用了两种提出的新算法（ABCDE和ALCDE）和四种已知的算法：Girvan-Newman、Louvain、Leiden和Label Propagation算法。每个这些算法在领域中都有传统的地位，它们可以帮助我们从不同的角度发现疾病网络中的社区。我们还比较了这些网络的全球性、统计摘要、子graph计数、графлет和验证 Modulaity。通过这些方法，我们想要从这些方法中获得更深入的理解疾病网络中的结构和互动。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction"><a href="#TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction" class="headerlink" title="TBIN: Modeling Long Textual Behavior Data for CTR Prediction"></a>TBIN: Modeling Long Textual Behavior Data for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08483">http://arxiv.org/abs/2308.08483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang</li>
<li>for: 预测Click-through rate (CTR) 对于推荐有着关键作用，而 latest 语言模型 (LMs) 的繁荣也使得一些工作利用语言模型来理解用户兴趣。</li>
<li>methods: 本文提出了 Textual Behavior-based Interest Chunking Network (TBIN), 它结合了高效的本地性敏感哈希算法和偏移的块基于自注意力，以解决上述限制。</li>
<li>results: 实验结果表明，TBIN 可以更好地预测 CTR，并在实际食品推荐平台上达到了好的效果。<details>
<summary>Abstract</summary>
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details>
<details>
<summary>摘要</summary>
点击率预测（CTR）在推荐中发挥关键作用。鼓使用语言模型（LM）的最近繁荣，一些工作改进预测，将用户行为数据组织成文本格式，并使用LM理解用户兴趣的 semantic 层次。虽然有承诺，但这些工作通常需要压缩文本数据，以降低LM的自注意力计算量的二次性。此外，这些工作通常将用户多样化的兴趣维度化成单一的特征向量，这限制了模型的表达能力。在这篇论文中，我们提出了一种 Textual Behavior-based Interest Chunking Network（TBIN），解决以上限制。TBIN 通过结合本地性敏感哈希算法和偏移 chunk-based self-attention 来实现。这将使用户多样化的兴趣在运行时动态激活，生成用户兴趣表示向 target 项。最后，在实际食品推荐平台上进行了线上和离线实验，证明了 TBIN 的效果。
</details></li>
</ul>
<hr>
<h2 id="A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering"><a href="#A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering" class="headerlink" title="A General Implicit Framework for Fast NeRF Composition and Rendering"></a>A General Implicit Framework for Fast NeRF Composition and Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04669">http://arxiv.org/abs/2308.04669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Gao, Ziyi Yang, Yunlu Zhao, Yuxiang Sun, Xiaogang Jin, Changqing Zou</li>
<li>for: This paper aims to provide a general implicit pipeline for composing NeRF objects quickly, enabling the casting of dynamic shadows within or between objects using analytical light sources, and allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations.</li>
<li>methods: The proposed method introduces a new surface representation known as Neural Depth Fields (NeDF), which quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.</li>
<li>results: The proposed method is the first to enable both the progressive and interactive composition of NeRF objects, and it also serves as a previewing plugin for a range of existing NeRF works.<details>
<summary>Abstract</summary>
A variety of Neural Radiance Fields (NeRF) methods have recently achieved remarkable success in high render speed. However, current accelerating methods are specialized and incompatible with various implicit methods, preventing real-time composition over various types of NeRF works. Because NeRF relies on sampling along rays, it is possible to provide general guidance for acceleration. To that end, we propose a general implicit pipeline for composing NeRF objects quickly. Our method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works.
</details>
<details>
<summary>摘要</summary>
各种神经辐射场（NeRF）方法在最近几年内已经实现了高速渲染。然而，当前的加速方法都是特殊化的，与各种隐式方法不兼容，因此无法在不同类型的 NeRF 作品中实现实时组合。因为 NeRF 是基于样本点投射，因此可以提供一般的指导。为了实现这一目标，我们提议一种通用的隐式管道，用于快速组合 NeRF 对象。我们的方法可以在动态阴影下投射 NeRF 对象，并允许多个 NeRF 对象在任意旋转变换下协同渲染。主要是，我们的工作引入了一种新的表面表示方式，即神经深度场（NeDF），它快速确定对象之间的空间关系，并使用神经网络进行交叉计算。这种方法不依赖于Explicit的空间结构，可以快速地计算ray和隐式表面之间的交叉。我们的提议方法是首次实现了 NeRF 对象的逐渐和交互式组合。此外，它还可以作为许多现有 NeRF 作品的预览插件。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors"><a href="#Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors" class="headerlink" title="Classification of lung cancer subtypes on CT images with synthetic pathological priors"></a>Classification of lung cancer subtypes on CT images with synthetic pathological priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04663">http://arxiv.org/abs/2308.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Zhu, Yuan Jin, Gege Ma, Geng Chen, Jan Egger, Shaoting Zhang, Dimitris N. Metaxas</li>
<li>for: 这份研究的目的是精确地诊断肺癌的病理型态，以便进行跟踪治疗和预后管理。</li>
<li>methods: 本研究提出了一个自动生成混合特征网络（SGHF-Net），用于从 computed tomography（CT）图像中精确类别肺癌病理型态。研究发现，跨 scales的图像相关性存在在同一个案例的 CT 图像和其相应的病理图像之间，因此开发了一个病理特征合成模组（PFSM），通过深度神经网络来将相应的病理信息从 CT 图像中提取出来。此外，研究还设计了一个 radiological feature extraction module（RFEM），以直接从 CT 图像中提取特征，并与病理先前相结合在一个有效的特征融合框架中，使整个分类模型能够生成更多的指示和特定的病理相关特征，最终获得更高的准确性。</li>
<li>results: 实验结果显示，提案的模型在肺癌病理型态分类任务中具有superiority，与多种state-of-the-art（SOTA）分类模型相比，具有 significiant 的准确性改善，包括精确率（ACC）、抽象曲线（AUC）和 F1 分数。<details>
<summary>Abstract</summary>
The accurate diagnosis on pathological subtypes for lung cancer is of significant importance for the follow-up treatments and prognosis managements. In this paper, we propose self-generating hybrid feature network (SGHF-Net) for accurately classifying lung cancer subtypes on computed tomography (CT) images. Inspired by studies stating that cross-scale associations exist in the image patterns between the same case's CT images and its pathological images, we innovatively developed a pathological feature synthetic module (PFSM), which quantitatively maps cross-modality associations through deep neural networks, to derive the "gold standard" information contained in the corresponding pathological images from CT images. Additionally, we designed a radiological feature extraction module (RFEM) to directly acquire CT image information and integrated it with the pathological priors under an effective feature fusion framework, enabling the entire classification model to generate more indicative and specific pathologically related features and eventually output more accurate predictions. The superiority of the proposed model lies in its ability to self-generate hybrid features that contain multi-modality image information based on a single-modality input. To evaluate the effectiveness, adaptability, and generalization ability of our model, we performed extensive experiments on a large-scale multi-center dataset (i.e., 829 cases from three hospitals) to compare our model and a series of state-of-the-art (SOTA) classification models. The experimental results demonstrated the superiority of our model for lung cancer subtypes classification with significant accuracy improvements in terms of accuracy (ACC), area under the curve (AUC), and F1 score.
</details>
<details>
<summary>摘要</summary>
准确诊断肺癌分型对跟进治疗和预后管理具有重要的重要性。在这篇论文中，我们提议一种自生成混合特征网络（SGHF-Net），用于准确分类肺癌分型的计算机Tomography（CT）图像。受到 Studies表明cross-scale关系存在图像特征之间的同一个患者的CT图像和其 PATHOLOGICAL图像的研究所启发，我们创新地开发了一种 PATHOLOGICAL特征合成模块（PFSM），用于量化跨模态关系，从深度神经网络中获取 PATHOLOGICAL图像中的"金标准"信息。此外，我们设计了一种放射学特征提取模块（RFEM），用于直接获取 CT 图像信息，并将其与 PATHOLOGICAL 先天知识结合在一起，以实现效果的特征融合框架，使整个分类模型能够生成更指示性和特定的 PATHOLOGICAL 相关特征，并最终输出更高精度的预测结果。我们的模型的优势在于它可以基于单一输入模式生成混合特征，包括多Modal 图像信息。为评估我们模型的有效性、适应性和普遍性，我们在大规模多中心数据集（i.e., 829 例from three hospitals）进行了广泛的实验，与一些当前最佳分类模型进行比较。实验结果表明，我们的模型在肺癌分型方面具有显著的准确性改进，包括准确率（ACC）、曲线下的面积（AUC）和 F1 分数。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets"><a href="#Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets" class="headerlink" title="Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets"></a>Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04660">http://arxiv.org/abs/2308.04660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Lyu, Shoubo Hu, Jie Chuai, Zhitang Chen</li>
<li>for: 提高黑盒优化问题的解决效率，通过多任务共同 pré-训练surrogate模型。</li>
<li>methods: 使用Transformer基于encoder学习深度特征，定义GPkernel，并提供mix-up初始化策略加速新任务的快速吸引。</li>
<li>results: 在 sintetic和实际benchmark问题上，提出的方法比现有方法更高效。<details>
<summary>Abstract</summary>
Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.
</details>
<details>
<summary>摘要</summary>
bayesian 优化（BO）广泛应用于黑盒优化问题中，它基于一个模拟黑盒响应函数的伪函数来进行优化。随着黑盒优化任务的数量不断增加，并且还有更多的任务需要解决，因此有必要将多个前一个任务的知识共享以提高优化效率。在这篇论文中，我们提出了一种简单的预训练方法，其中使用一个基于Transformer的encoder学习的深度特征来定义GP的kernel，并使用多个先前任务的数据进行预训练。此外，我们还提供了一种简单却有效的混合初始化策略，以便快速加速新任务的启动。实验表明，我们的提议的预训练和传递BO策略在实际和Syntheticbenchmark问题上比既有方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores"><a href="#Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores" class="headerlink" title="Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores"></a>Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04653">http://arxiv.org/abs/2308.04653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Cesar Quihui-Rubio, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Miguel Gonzalez-Mendoza, Christian Mata</li>
<li>for: 这项研究旨在比较深度学习方法对MRI图像中肾脏 segmentation和量化不确定性的效果，以提高肾脏癌检测和诊断的工作流程。</li>
<li>methods: 这项研究使用了七种不同的 U-Net 架构，并在这些架构中添加了 Monte-Carlo dropout 等方法进行自动 segmentation 和不确定性估计。</li>
<li>results: 研究发现，Attention R2U-Net 模型在 segmenting 所有区域时达到了平均 Intersection over Union（IoU）76.3%和 Dice Similarity Coefficient（DSC）85%的最高性能，并且在边界区域中，特别是在转换区域和肿瘤边界上，Attention R2U-Net 模型表现出最低的不确定性值。<details>
<summary>Abstract</summary>
This study focuses on comparing deep learning methods for the segmentation and quantification of uncertainty in prostate segmentation from MRI images. The aim is to improve the workflow of prostate cancer detection and diagnosis. Seven different U-Net-based architectures, augmented with Monte-Carlo dropout, are evaluated for automatic segmentation of the central zone, peripheral zone, transition zone, and tumor, with uncertainty estimation. The top-performing model in this study is the Attention R2U-Net, achieving a mean Intersection over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest uncertainty values, particularly in the boundaries of the transition zone and tumor, when compared to the other models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals"><a href="#Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals" class="headerlink" title="Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals"></a>Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04650">http://arxiv.org/abs/2308.04650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyewon Jeong, Collin M. Stultz, Marzyeh Ghassemi</li>
<li>for: 这个研究旨在开发一个可以非侵入性地估计心脏压力的方法，以帮助诊断和治疗心脏病症的患者。</li>
<li>methods: 这个研究使用了深度度量学习（DML）技术，并提出了一个自我监督的DML方法，通过距离基本采矿来提高模型的表现。</li>
<li>results: 研究发现，这个自我监督DML方法可以对于患者 subgroup 进行优化，并且在不同的患者 subgroup 中表现良好。此外，这个方法还可以与现有的标准方法进行比较，以验证其性能。<details>
<summary>Abstract</summary>
Heart failure is a debilitating condition that affects millions of people worldwide and has a significant impact on their quality of life and mortality rates. An objective assessment of cardiac pressures remains an important method for the diagnosis and treatment prognostication for patients with heart failure. Although cardiac catheterization is the gold standard for estimating central hemodynamic pressures, it is an invasive procedure that carries inherent risks, making it a potentially dangerous procedure for some patients. Approaches that leverage non-invasive signals - such as electrocardiogram (ECG) - have the promise to make the routine estimation of cardiac pressures feasible in both inpatient and outpatient settings. Prior models trained to estimate intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) in a supervised fashion have shown good discriminatory ability but have been limited to the labeled dataset from the heart failure cohort. To address this issue and build a robust representation, we apply deep metric learning (DML) and propose a novel self-supervised DML with distance-based mining that improves the performance of a model with limited labels. We use a dataset that contains over 5.4 million ECGs without concomitant central pressure labels to pre-train a self-supervised DML model which showed improved classification of elevated mPCWP compared to self-supervised contrastive baselines. Additionally, the supervised DML model that is using ECGs with access to 8,172 mPCWP labels demonstrated significantly better performance on the mPCWP regression task compared to the supervised baseline. Moreover, our data suggest that DML yields models that are performant across patient subgroups, even when some patient subgroups are under-represented in the dataset. Our code is available at https://github.com/mandiehyewon/ssldml
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种严重的疾病，影响了全球数百万人的生活质量和死亡率。心脏压力的 объектив评估仍然是诊断和治疗预测的重要方法。尽管心脏插管是心脏压力的标准方法，但它是一种侵入性的程序，带来了内在的风险，因此可能对某些患者而言是危险的。使用非侵入性信号（如电cardiogram）的方法可以使 Routine estimation of cardiac pressures 变得可能。先前的模型，通过监督学习来估计内心脏压力（如mean pulmonary capillary wedge pressure （mPCWP）），在心脏疾病群体中显示了良好的预测能力，但它们受限于标注数据集。为解决这个问题并建立一个坚固的表示，我们应用深度度量学习（DML）并提出一种新的自动化DML，通过距离基本挖掘来提高模型的性能。我们使用了包含超过540万个ECG无相关中央压力标签的数据集来预训一个自动化DML模型，该模型在提高高mPCWP的分类性能方面表现出色，而且与自动化对比基线显著更好。此外，我们使用ECG和8172个mPCWP标签来训练一个监督DML模型，该模型在mPCWP回归任务中表现出色，并且与监督基线显著更好。此外，我们的数据表明，DML模型在不同的患者子组中表现良好，即使某些患者子组在数据集中受到保守。我们的代码可以在https://github.com/mandiehyewon/ssldml 中找到。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization"><a href="#Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization" class="headerlink" title="Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization"></a>Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04649">http://arxiv.org/abs/2308.04649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benny Wong</li>
<li>for: 本研究论文旨在提出一种hybrid化 Gaussian Crunching Search（GCS）和 Powell’s Method的新方法，以提高不具有导数的优化性能。</li>
<li>methods: 本研究使用了GCS和一些传统的不具有导数优化方法的混合，以优化复杂系统中的优化问题。</li>
<li>results: 经过实验，我们发现这种混合方法可以显著提高优化性能，同时保留每种方法的优点。这种混合方法开启了优化复杂系统中的新可能性。<details>
<summary>Abstract</summary>
This research paper presents a novel approach to enhance optimization performance through the hybridization of Gaussian Crunching Search (GCS) and Powell's Method for derivative-free optimization. While GCS has shown promise in overcoming challenges faced by traditional derivative-free optimization methods [1], it may not always excel in finding the local minimum. On the other hand, some traditional methods may have better performance in this regard. However, GCS demonstrates its strength in escaping the trap of local minima and approaching the global minima. Through experimentation, we discovered that by combining GCS with certain traditional derivative-free optimization methods, we can significantly boost performance while retaining the respective advantages of each method. This hybrid approach opens up new possibilities for optimizing complex systems and finding optimal solutions in a range of applications.
</details>
<details>
<summary>摘要</summary>
Note:* "GCS" is translated as " Gaussian Crunching Search" (GCS)* "Powell's Method" is translated as "Powell's Method" ( Powell 方法)* "derivative-free optimization" is translated as "无导数优化" (without derivative optimization)* "local minimum" is translated as "地方最优" (local optimal)* "global minimum" is translated as "全球最优" (global optimal)
</details></li>
</ul>
<hr>
<h2 id="Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling"><a href="#Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling" class="headerlink" title="Sparse Binary Transformers for Multivariate Time Series Modeling"></a>Sparse Binary Transformers for Multivariate Time Series Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04637">http://arxiv.org/abs/2308.04637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray</li>
<li>for: 应用于多变量时间序列问题的简单深度学习模型</li>
<li>methods: 使用稀疏和二进制权重的 transformer 模型</li>
<li>results: 在三个时间序列学习任务中获得了比较出色的成绩：分类、异常检测和单步预测，同时通过两种修改来减少计算复杂性：1）在分类任务中应用固定mask，2）在预测和异常检测任务中应用时间步骤Attention mask。这些修改和压缩技术可以减少 transformer 模型中非零操作数量，并且对模型性能没有明显的影响。<details>
<summary>Abstract</summary>
Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</details>
<details>
<summary>摘要</summary>
压缩神经网络有望推动深度学习应用于新的应用环境和较小的计算环境。然而，了解这些模型在哪些学习任务中能够成功是未有充分研究。在这种工作中，我们使用稀疏和二进制权重的Transformers来解决多变量时间序列问题，并证明这些轻量级模型可以与同结构的浮点数Transformers具有相同的准确率。我们的模型在三个时间序列学习任务中显示出了有利的结果：分类、异常检测和单步预测。此外，为了降低计算复杂性的注意机制，我们应用了两种修改，其中第一种是在分类任务中采用固定掩码来修改查询、关键和值活动，而第二种是在预测和异常检测任务中，因为需要在单个时间步骤上预测输出，我们提议使用注意力掩码，只允许在当前时间步骤上进行计算。总之，我们的方法可以减少Transformer中非零操作数量，并且对参数数、位数和浮点运算（FLOPs）数进行了评估，得出了最多53倍减少存储大小和最多10.5倍减少FLOPs。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Online-Learnability-under-Bandit-Feedback"><a href="#Multiclass-Online-Learnability-under-Bandit-Feedback" class="headerlink" title="Multiclass Online Learnability under Bandit Feedback"></a>Multiclass Online Learnability under Bandit Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04620">http://arxiv.org/abs/2308.04620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananth Raman, Vinod Raman, Unique Subedi, Ambuj Tewari</li>
<li>for: 研究在线上多类标签分类中的抽象反馈。</li>
<li>methods: extend daniely2013price的结果，显示了统一抽象反馈下的线上多类分类可学习性是必需和充分的。</li>
<li>results: 结果与hanneke2023multiclass的结果相 compliment，显示了在充满信息设定下的线上多类分类可学习性是基于抽象反馈的Littlestone dimension。<details>
<summary>Abstract</summary>
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
</details>
<details>
<summary>摘要</summary>
我们研究在抽奖式多类分类中的在线学习。我们将(daniely2013price)的结果推广到不确定label空间的情况下，证明在线多类学习的可学习性需要和充分条件是抽奖式Littlestone维度的 фиnisiteness。我们的结果与(hanneke2023multiclass)的最近研究相 complement，其证明在全信息设置下，无限大的label空间下的多类学习可学习性是Littlestone维度的Characterize。
</details></li>
</ul>
<hr>
<h2 id="Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection"><a href="#Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection" class="headerlink" title="Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection"></a>Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04617">http://arxiv.org/abs/2308.04617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanghangpsu/mmac">https://github.com/wanghangpsu/mmac</a></li>
<li>paper_authors: Hang Wang, Zhen Xiang, David J. Miller, George Kesidis<br>for: 防止深度神经网络受到后门攻击（Trojan）的攻击，攻击者在训练集中杀入后门触发器，使神经网络在测试时识别攻击者所指定的目标类。methods: 我们提出了一种新的静态策略，通过在小量的净样上学习内层吞吐量的约束，来限制内层吞吐量的范围。这种方法可以更好地防止后门攻击，并且具有强大的鲁棒性。results: 我们的方法在CIFAR-10图像分类任务上显示出了更好的性能，并且对于不同的数据集和攻击方法都具有强大的鲁棒性。此外，我们还提出了一种基于输出差异的测试时检测和修复方法。<details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to backdoor attacks (Trojans), where an attacker poisons the training set with backdoor triggers so that the neural network learns to classify test-time triggers to the attacker's designated target class. Recent work shows that backdoor poisoning induces over-fitting (abnormally large activations) in the attacked model, which motivates a general, post-training clipping method for backdoor mitigation, i.e., with bounds on internal-layer activations learned using a small set of clean samples. We devise a new such approach, choosing the activation bounds to explicitly limit classification margins. This method gives superior performance against peer methods for CIFAR-10 image classification. We also show that this method has strong robustness against adaptive attacks, X2X attacks, and on different datasets. Finally, we demonstrate a method extension for test-time detection and correction based on the output differences between the original and activation-bounded networks. The code of our method is online available.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到后门攻击（Trojan），攻击者在训练集中杀断特定目标类的识别器，使神经网络在测试时通过特定目标类来识别测试触发器。最近的研究表明，后门恶意投入会导致模型过度适应（异常大的活化），这种情况下我们提出了一种通用、 после训练剪辑方法来 mitigate 后门攻击，即通过小量的干净样本学习内层活化的约束。我们提出了一种新的方法，选择活化约束来限制分类范围。这种方法在对同类方法进行比较时表现出色，并且具有强大的适应性，可以在X2X攻击、适应攻击和不同的 datasets 上进行验证。最后，我们还示出了一种基于输出差异的测试时检测和修复方法。我们的方法代码在线可用。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review"><a href="#Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review" class="headerlink" title="Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review"></a>Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04616">http://arxiv.org/abs/2308.04616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moein Razavi, Samira Ziyadidegan, Reza Jahromi, Saber Kazeminasab, Vahid Janfaza, Ahmadreza Mahmoudzadeh, Elaheh Baharlouei, Farzan Sasangohar</li>
<li>for: 本研究旨在系统评估机器学习（ML）方法在压力检测、预测和分析中的应用。</li>
<li>methods: 该研究使用了严格的探索性评估方法，检查了最新的ML算法、预处理技术和数据类型在压力和压力相关的神经病中的应用。</li>
<li>results: 研究发现，支持向量机器（SVM）、神经网络（NN）和随机森林（RF）模型在所有机器学习算法中具有最高精度和稳定性。此外， Physiological parameters，如心率测量和皮肤响应，是压力预测中最常用的数据类型。<details>
<summary>Abstract</summary>
This comprehensive review systematically evaluates Machine Learning (ML) methodologies employed in the detection, prediction, and analysis of mental stress and its consequent mental disorders (MDs). Utilizing a rigorous scoping review process, the investigation delves into the latest ML algorithms, preprocessing techniques, and data types employed in the context of stress and stress-related MDs. The findings highlight that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently exhibit superior accuracy and robustness among all machine learning algorithms examined. Furthermore, the review underscores that physiological parameters, such as heart rate measurements and skin response, are prevalently used as stress predictors in ML algorithms. This is attributed to their rich explanatory information concerning stress and stress-related MDs, as well as the relative ease of data acquisition. Additionally, the application of dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, is frequently observed as a crucial step preceding the training of ML algorithms. The synthesis of this review identifies significant research gaps and outlines future directions for the field. These encompass areas such as model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details>
<details>
<summary>摘要</summary>
The findings show that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently demonstrate superior accuracy and robustness among all ML algorithms examined. Additionally, the review highlights that physiological parameters, such as heart rate measurements and skin response, are commonly used as stress predictors in ML algorithms due to their rich explanatory information and ease of data acquisition.The review also notes that dimensionality reduction techniques, such as mappings, feature selection, filtering, and noise reduction, are frequently applied as a crucial step before training ML algorithms.The synthesis of this review identifies significant research gaps and outlines future directions for the field, including model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning"><a href="#Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning" class="headerlink" title="Sparse Array Design for Direction Finding using Deep Learning"></a>Sparse Array Design for Direction Finding using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04615">http://arxiv.org/abs/2308.04615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Vijay Mishra, Ahmet M. Elbir, Koichi Ichige</li>
<li>for: 这些研究旨在应用深度学习（DL）技术来设计稀疏数组，以便实现特征工程和预测阶段的低复杂性，以涉及到稀疏数组的 combinatorial search。</li>
<li>methods: 这些研究使用了监督学习和转移学习技术，以及元优化学习算法如模拟热处理，以解决二维稀疏数组设计问题。</li>
<li>results: 这些研究通过数字实验显示了模型基于优化和DL技术的性能，并讨论了对于稀疏数组设计问题的多种实际应用，包括认知雷达、无线通信和 интеGRATED sensing和通信（ISAC）应用。<details>
<summary>Abstract</summary>
In the past few years, deep learning (DL) techniques have been introduced for designing sparse arrays. These methods offer the advantages of feature engineering and low prediction-stage complexity, which is helpful in tackling the combinatorial search inherent to finding a sparse array. In this chapter, we provide a synopsis of several direction finding applications of DL-based sparse arrays. We begin by examining supervised and transfer learning techniques that have applications in selecting sparse arrays for a cognitive radar application. Here, we also discuss the use of meta-heuristic learning algorithms such as simulated annealing for the case of designing two-dimensional sparse arrays. Next, we consider DL-based antenna selection for wireless communications, wherein sparse array problem may also be combined with channel estimation, beamforming, or localization. Finally, we provide an example of deep sparse array technique for integrated sensing and communications (ISAC) application, wherein a trade-off of radar and communications performance makes ISAC sparse array problem very challenging. For each setting, we illustrate the performance of model-based optimization and DL techniques through several numerical experiments. We discuss additional considerations required to ensure robustness of DL-based algorithms against various imperfections in array data.
</details>
<details>
<summary>摘要</summary>
We begin by examining supervised and transfer learning techniques that have applications in selecting sparse arrays for a cognitive radar system. We also discuss the use of meta-heuristic learning algorithms such as simulated annealing for the case of designing two-dimensional sparse arrays.Next, we consider DL-based antenna selection for wireless communications, where the sparse array problem may also be combined with channel estimation, beamforming, or localization. Finally, we provide an example of deep sparse array techniques for integrated sensing and communications (ISAC) applications, where a trade-off between radar and communications performance makes ISAC sparse array problems very challenging.For each setting, we illustrate the performance of model-based optimization and DL techniques through several numerical experiments. We also discuss additional considerations required to ensure the robustness of DL-based algorithms against various imperfections in array data.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection"><a href="#Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection" class="headerlink" title="Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection"></a>Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04611">http://arxiv.org/abs/2308.04611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vc1492a/tidd">https://github.com/vc1492a/tidd</a></li>
<li>paper_authors: Valentino Constantinou, Michela Ravanelli, Hamlin Liu, Jacob Bortnik</li>
<li>for: 这个论文是为了检测地震引起的内力波在电离层中的影响，以提高早期警报系统的精度。</li>
<li>methods: 这个研究使用了GNSS数据和深度学习技术，并将slant total electron content（sTEC）从VARION算法和计算机视觉中的Gramian Angular Difference Fields（GADF）和卷积神经网络（CNN）组合使用，以实时检测内力波。</li>
<li>results: 研究结果显示，使用这种方法可以在near-real-time中检测到内力波，并在2010年的墨西哥大地震、2011年的东北大地震和2012年的海达岛大地震中达到了91.7%的F1分数。<details>
<summary>Abstract</summary>
Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere, perturbing the Total Electron Content (TEC) - referred to as Traveling Ionospheric Disturbances (TIDs) that are detectable through the Global Navigation Satellite System (GNSS). The GNSS are constellations of satellites providing signals from Earth orbit - Europe's Galileo, the United States' Global Positioning System (GPS), Russia's Global'naya Navigatsionnaya Sputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection of TIDs provides an approach for tsunami detection, enhancing early warning systems by providing open-ocean coverage in geographic areas not serviceable by buoy-based warning systems. Large volumes of the GNSS data is leveraged by deep learning, which effectively handles complex non-linear relationships across thousands of data streams. We describe a framework leveraging slant total electron content (sTEC) from the VARION (Variometric Approach for Real-Time Ionosphere Observation) algorithm by Gramian Angular Difference Fields (from Computer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs in near-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012 Haida-Gwaii earthquakes and tsunamis are used in model training, and the later-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-sample model validation. Using the experimental framework described in the paper, we achieved a 91.7% F1 score. Source code is available at: https://github.com/vc1492a/tidd. Our work represents a new frontier in detecting tsunami-driven IGWs in open-ocean, dramatically improving the potential for natural hazards detection for coastal communities.
</details>
<details>
<summary>摘要</summary>
TSUNAMIS可以触发内部重力波（IGW）在电离层，干扰全电子内容（TEC），被称为旅行 ionospheric 干扰（TIDs），可以通过全球导航卫星系统（GNSS）探测。GNSS 包括欧盟的加利列オ（Galileo）、美国的全球定位系统（GPS）、俄罗斯的全球卫星导航系统（GLONASS）和中国的北斗卫星导航系统（BeiDou）。实时探测 TIDs 提供了一种方法，用于早期警报系统，提供了不可达的开 ocean 覆盖。通过深入学习，可以有效处理复杂的非线性关系，并处理数千个数据流。我们描述了一个框架，利用倾斜全电子内容（sTEC）从VARION（Variometric Approach for Real-Time Ionosphere Observation）算法、格里曼angular Difference Fields（from Computer Vision）和卷积神经网络（CNNs）来探测 TIDs 的实时探测。历史数据来自2010年智利地震、2011年日本地震和2012年加拿大海啸，用于模型训练，而2015年智利地震用于模型验证。使用我们所描述的实验框架，我们实现了 91.7% F1 分数。源代码可以在 GitHub 上获取：https://github.com/vc1492a/tidd。我们的工作代表了一种新的前沿，用于探测在开 ocean 中的地震引起的 IGW，这将在沿海社区中提高天然威胁探测的潜在性。
</details></li>
</ul>
<hr>
<h2 id="PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data"><a href="#PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data" class="headerlink" title="PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data"></a>PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04605">http://arxiv.org/abs/2308.04605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Shen, Han-Wei Shen</li>
<li>for: 科学数据超分辨化，以避免生成错误或不正确的信息。</li>
<li>methods: 使用normalizing flow-based生成模型PSRFlow，包括uncertainty量化。</li>
<li>results: 与插值和GAN-based超分辨化网络相比，表现出色，并且可以正确地衡量超分辨化结果的不确定性。<details>
<summary>Abstract</summary>
Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
</details>
<details>
<summary>摘要</summary>
尽管最近几年内有许多基于深度学习的超分辨率方法被提出，但由于无法在推理阶段获得真实的参照值，因此只能很少量化错误和不确定性。在科学视觉应用中，却非常重要将超分辨率结果的不确定性传递给科学家，以避免生成错误或 incorrect 信息。在本文中，我们提出了 PSRFlow，一种基于正规流的生成模型，用于科学数据超分辨率。PSRFlow 学习了高分辨率数据的假设分布，基于低分辨率数据。通过在 Gaussian 隐藏空间中采样，可以生成不同可能的超分辨率输出。在 Gaussian 隐藏空间中高效采样可以实现对超分辨率结果的不确定性评估。在模型训练过程中，我们将训练数据进行了不同尺度的扩展，使模型适应不同的尺度，实现数据的灵活超分辨率。我们的结果表明，与既有方法相比，PSRFlow 具有更高的性能和更精准的不确定性评估。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Decentralized-Federated-Learning"><a href="#A-Survey-on-Decentralized-Federated-Learning" class="headerlink" title="A Survey on Decentralized Federated Learning"></a>A Survey on Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04604">http://arxiv.org/abs/2308.04604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Gabrielli, Giovanni Pica, Gabriele Tolomei</li>
<li>for: 这篇论文主要是为了探讨分布式学习（Federated Learning，FL）中的分布式客户端服务器架构，以及其中的安全性和可靠性问题。</li>
<li>methods: 这篇论文主要采用文献综述的方法，对现有的分布式FL方法进行了系统的梳理和评估。同时，它还提出了一些未来研究方向，以解决现有的挑战和问题。</li>
<li>results: 这篇论文主要的结果是，现有的分布式FL方法存在一些潜在的安全性和可靠性问题，如中央服务器的单点失败风险和人在中攻击等。同时，它还提出了一些未来研究方向，以解决现有的挑战和问题。<details>
<summary>Abstract</summary>
In recent years, federated learning (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems. In contrast to standard ML, where data must be collected at the exact location where training is performed, FL takes advantage of the computational capabilities of millions of edge devices to collaboratively train a shared, global model without disclosing their local private data. Specifically, in a typical FL system, the central server acts only as an orchestrator; it iteratively gathers and aggregates all the local models trained by each client on its private data until convergence. Although FL undoubtedly has several benefits over traditional ML (e.g., it protects private data ownership by design), it suffers from several weaknesses. One of the most critical challenges is to overcome the centralized orchestration of the classical FL client-server architecture, which is known to be vulnerable to single-point-of-failure risks and man-in-the-middle attacks, among others. To mitigate such exposure, decentralized FL solutions have emerged where all FL clients cooperate and communicate without a central server. This survey comprehensively summarizes and reviews existing decentralized FL approaches proposed in the literature. Furthermore, it identifies emerging challenges and suggests promising research directions in this under-explored domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Learning-based-Image-Watermarking-A-Brief-Survey"><a href="#Deep-Learning-based-Image-Watermarking-A-Brief-Survey" class="headerlink" title="Deep Learning based Image Watermarking: A Brief Survey"></a>Deep Learning based Image Watermarking: A Brief Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04603">http://arxiv.org/abs/2308.04603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zhong, Arjon Das, Fahad Alrasheedi, Abdullah Tanvir</li>
<li>for: 保护图像 against unauthorized use and distribution</li>
<li>methods: 使用深度学习技术，包括Embedder-Extractor Joint Training、Deep Networks as a Feature Transformation和Hybrid schemes</li>
<li>results: 分析了现有的深度学习图像水印技术，并提出了未来研究的可能性。<details>
<summary>Abstract</summary>
The act of secretly embedding and extracting a watermark on a cover image to protect it is known as image watermarking. In recent years, deep learning-based image watermarking techniques have been emerging one after another. To study the state-of-the-art, this survey categorizes cutting-edge deep learning-based image watermarking techniques into Embedder-Extractor Joint Training, Deep Networks as a Feature Transformation, and Hybrid schemes. Research directions in each category are also analyzed and summarized. Additionally, potential future research directions are discussed to envision future studies.
</details>
<details>
<summary>摘要</summary>
“图像水印”是指在封面图像上隐藏并提取水印以保护图像的行为。在最近几年，基于深度学习的图像水印技术逐渐涌现。本笔报告将这些技术分为三类：嵌入器-提取器共同训练、深度网络作为特征转换和混合方案。每个类别的研究方向也进行了分析和总结。此外，未来研究的可能性也被讨论了，以便预测未来的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression"><a href="#Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression" class="headerlink" title="Quantization Aware Factorization for Deep Neural Network Compression"></a>Quantization Aware Factorization for Deep Neural Network Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04595">http://arxiv.org/abs/2308.04595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daria Cherniuk, Stanislav Abukhovich, Anh-Huy Phan, Ivan Oseledets, Andrzej Cichocki, Julia Gusak</li>
<li>for: 这个研究旨在开发一个能够同时实现对 neural network 的量化和缩减实现的算法，以提高 deployed 模型的处理能力和能效性。</li>
<li>methods: 本研究使用 Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with quantized factors, 以实现tensor decomposition的缩减和量化。</li>
<li>results: 试验结果显示， compared to state-of-the-art post-training quantization methods, 本方法可以实现高品质和高效性的平衡，并且具有高的灵活性和可靠性。<details>
<summary>Abstract</summary>
Tensor decomposition of convolutional and fully-connected layers is an effective way to reduce parameters and FLOP in neural networks. Due to memory and power consumption limitations of mobile or embedded devices, the quantization step is usually necessary when pre-trained models are deployed. A conventional post-training quantization approach applied to networks with decomposed weights yields a drop in accuracy. This motivated us to develop an algorithm that finds tensor approximation directly with quantized factors and thus benefit from both compression techniques while keeping the prediction quality of the model. Namely, we propose to use Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whose elements lie on a specified quantization grid. We compress neural network weights with a devised algorithm and evaluate it's prediction quality and performance. We compare our approach to state-of-the-art post-training quantization methods and demonstrate competitive results and high flexibility in achiving a desirable quality-performance tradeoff.
</details>
<details>
<summary>摘要</summary>
《神经网络参数和计算量减少的tensor分解技术》是一种有效的神经网络减少参数和计算量的方法。由于移动或嵌入式设备的内存和电力限制，通常需要进行量化步骤才能在这些设备上部署预训练模型。然而，通常的后期量化方法在使用分解的 weights 时会导致模型的准确率下降。这种情况 Motivated us 开发一种直接使用量化因子进行tensorapproximation的算法，以便同时利用压缩技术，保持模型预测质量。具体来说，我们提出使用 Alternating Direction Method of Multipliers (ADMM)  для canonical polyadic (CP) 分解，其中因子的元素 lying on a specified quantization grid。我们使用自定义的算法压缩神经网络参数，并评估其预测质量和性能。我们与state-of-the-art post-training quantization方法进行比较，并表现出高的灵活性和满足 desire quality-performance tradeoff。
</details></li>
</ul>
<hr>
<h2 id="ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems"><a href="#ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems" class="headerlink" title="ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems"></a>ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04588">http://arxiv.org/abs/2308.04588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mit-ll-responsible-ai/equine-webapp">https://github.com/mit-ll-responsible-ai/equine-webapp</a></li>
<li>paper_authors: Harry Li, Steven Jorgensen, John Holodnak, Allan Wollaber</li>
<li>for: 这个论文是为了解释深度学习模型在多类标签问题中的不确定性，并提供了可靠的分类预测概率和 OUT-OF-Distribution (OOD) 指标，以便机器学习（ML）consumers和工程师可以评估模型对测试示例的预测 confidence。</li>
<li>methods: 这个论文使用了uncertainty-aware深度学习方法，包括距离意识 neural network 和dimensionality reduction技术，以构建可靠的2-D散点图，解释模型对测试示例的预测原因。</li>
<li>results: 这个论文通过一种交互式系统ScatterUQ，可以让用户更好地理解模型在不同不确定性 Settings下的性能，并通过 hover 回调来比较测试示例和训练示例的材料特征，以了解模型uncertainty性能和进行后续操作。<details>
<summary>Abstract</summary>
Recently, uncertainty-aware deep learning methods for multiclass labeling problems have been developed that provide calibrated class prediction probabilities and out-of-distribution (OOD) indicators, letting machine learning (ML) consumers and engineers gauge a model's confidence in its predictions. However, this extra neural network prediction information is challenging to scalably convey visually for arbitrary data sources under multiple uncertainty contexts. To address these challenges, we present ScatterUQ, an interactive system that provides targeted visualizations to allow users to better understand model performance in context-driven uncertainty settings. ScatterUQ leverages recent advances in distance-aware neural networks, together with dimensionality reduction techniques, to construct robust, 2-D scatter plots explaining why a model predicts a test example to be (1) in-distribution and of a particular class, (2) in-distribution but unsure of the class, and (3) out-of-distribution. ML consumers and engineers can visually compare the salient features of test samples with training examples through the use of a ``hover callback'' to understand model uncertainty performance and decide follow up courses of action. We demonstrate the effectiveness of ScatterUQ to explain model uncertainty for a multiclass image classification on a distance-aware neural network trained on Fashion-MNIST and tested on Fashion-MNIST (in distribution) and MNIST digits (out of distribution), as well as a deep learning model for a cyber dataset. We quantitatively evaluate dimensionality reduction techniques to optimize our contextually driven UQ visualizations. Our results indicate that the ScatterUQ system should scale to arbitrary, multiclass datasets. Our code is available at https://github.com/mit-ll-responsible-ai/equine-webapp
</details>
<details>
<summary>摘要</summary>
近期，对多类标签问题的不确定性意识深度学习方法已经发展出来，这些方法可以提供标量预测概率和外部数据（OOD）指示器，让机器学习（ML）用户和工程师可以评估模型对预测的自信心。然而，这些额外神经网络预测信息在多种不确定性Setting下可能困难减少可扩展的可视化显示。为解决这些挑战，我们现在介绍ScatterUQ，一个互动系统，可以提供特定的可视化来让用户更好地理解模型在受限制的不确定性设置下的性能。ScatterUQ利用了最新的距离意识神经网络和维度减少技术，构建了可靠的2D散点图，解释模型对测试示例的预测是（1）在distribution中，（2）在distribution中，但是不确定的类别，以及（3）外部数据。通过使用“悬停回调”，ML用户和工程师可以通过比较测试示例与训练示例的材料特征来理解模型不确定性性能，并根据需要采取后续行动。我们在多类图像分类任务上使用了距离意识神经网络，并在Fashion-MNIST和MNIST数字上进行了测试，以及一个深度学习模型 для一个网络安全任务。我们对维度减少技术进行了量化评估，以便优化我们在不同上下文中的UQ视觉表示。我们的结果表明，ScatterUQ系统可以扩展到任意多类数据集。我们的代码可以在https://github.com/mit-ll-responsible-ai/equine-webapp 上获取。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Single-Proxy-Control-for-Deterministic-Confounding"><a href="#Kernel-Single-Proxy-Control-for-Deterministic-Confounding" class="headerlink" title="Kernel Single Proxy Control for Deterministic Confounding"></a>Kernel Single Proxy Control for Deterministic Confounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04585">http://arxiv.org/abs/2308.04585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyuan Xu, Arthur Gretton</li>
<li>for: 该文章目标是探讨 causal effect estimation 中隐藏 confounder 的问题，并提出了一种基于 proxy 变量的方法。</li>
<li>methods: 该文章使用了两种基于 kernel 的方法：一种是基于 two-stage regression 方法，另一种是基于最大 momentum restriction 方法。</li>
<li>results: 该文章通过实验表明，使用单个 proxy 变量可以成功地估计 causal effect，并且可以在 synthetic dataset 上成功地回归 true causal effect。<details>
<summary>Abstract</summary>
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
</details>
<details>
<summary>摘要</summary>
我团队考虑了一个 causal effect 估计问题，其中存在一个未观测的假设变量。我们观察了一个代表变量，该变量与假设变量相关。虽然 Proxy Causal Learning（PCL）使用了两个代表变量来恢复真实的 causal effect，但我们显示了一个单个代表变量足够于 causal 估计，如果结果是 deterministic 生成的，则推广 Control Outcome Calibration Approach（COCA）。我们提出了两种基于 kernel 方法来解决这个问题：第一种基于 two-stage 回归方法，第二种基于最大 moments 约束方法。我们证明了这两种方法都可靠地估计 causal effect，并在一个 synthetic 数据集上进行了实验验证。
</details></li>
</ul>
<hr>
<h2 id="RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System"><a href="#RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System" class="headerlink" title="RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?"></a>RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04579">http://arxiv.org/abs/2308.04579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Pesaranghader, Touqir Sajed</li>
<li>for: 本研究旨在提出一个多功能的食谱推荐框架，以解决食谱推荐的问题。</li>
<li>methods: 本研究使用多Modal知识图（MMKG）作为基础，并提出了三个互补性推荐子系统：行为基于推荐、评论基于推荐和图像基于推荐。每个子系统都利用知识图中的实体和关系的嵌入表示进行推荐。</li>
<li>results: 对于两个公开 dataset 上的食谱推荐问题，我们的实验结果表明，KGE 模型与深度神经 Collaborative Filtering（NCF）的性能相似。此外，我们还提出了针对新用户（即冷启动问题）和食谱类别 conditional 推荐的适用方案。最后，我们将 RECipe 应用于多功能推荐设定中。<details>
<summary>Abstract</summary>
Over the past two decades, recommendation systems (RSs) have used machine learning (ML) solutions to recommend items, e.g., movies, books, and restaurants, to clients of a business or an online platform. Recipe recommendation, however, has not yet received much attention compared to those applications. We introduce RECipe as a multi-purpose recipe recommendation framework with a multi-modal knowledge graph (MMKG) backbone. The motivation behind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by recommending recipes to users when they query in natural language or by providing an image. RECipe consists of 3 subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain (pre-trained) embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework. For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.
</details>
<details>
<summary>摘要</summary>
RECipe consists of three subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain (pre-trained) embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework.For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.Translation notes:* "Over the past two decades" is translated as "过去二十年" (guò qù èr shí nián), using the past perfect tense to indicate that the events described in the sentence took place before a specific time in the past.* "recommendation systems" is translated as "推荐系统" (tuī yù xìng zhì), using the pinyin romanization of the Chinese term.* "machine learning" is translated as "机器学习" (jī shì xué xí), using the Chinese term for the field.* "solutions" is translated as "解决方案" (jiě jí fāng àn), using the Chinese term for "solution" or "answer".* "recipe" is translated as "菜谱" (cào bù), using the Chinese term for "recipe".* "users" is translated as "用户" (yòng hù), using the Chinese term for "user".* "queries" is translated as "查询" (chá xún), using the Chinese term for "query".* "natural language" is translated as "自然语言" (zì rán yǔ yán), using the Chinese term for "natural language".* "image" is translated as "图像" (tú xiàng), using the Chinese term for "image".* "entities" is translated as "实体" (shí tǐ), using the Chinese term for "entity".* "relations" is translated as "关系" (guān xì), using the Chinese term for "relation".* "knowledge graph" is translated as "知识图" (zhī shí tú), using the Chinese term for "knowledge graph".* "backbone" is translated as "基础结构" (jī jí jié gòng), using the Chinese term for "backbone" or "basis".* "multi-modal" is translated as "多Modal" (duō mó dāo), using the Chinese term for "multi-modal".* "embedding representations" is translated as "嵌入表示" (fàn shì biǎo xiǎng), using the Chinese term for "embedding representation".* "pre-trained" is translated as "预训练" (zhāng xiǎng xiǎng), using the Chinese term for "pre-trained".* "variational autoencoder" is translated as "变量自适应器" (biàn yù zì shì qǐng), using the Chinese term for "variational autoencoder".* "KGE" is translated as "知识图加 embedding" (zhī shí tú jiā embedding), using the Chinese term for "knowledge graph embedding".* "NLP" is translated as "自然语言处理" (zì rán yǔ yán bù), using the Chinese term for "natural language processing".* "zero-shot" is translated as "零枪指" (zhì zhèng zhǐ), using the Chinese term for "zero-shot".* "cold start" is translated as "冰点问题" (bīng diǎn wèn tí), using the Chinese term for "cold start problem".* "conditional" is translated as "条件" (tiáo jiàn), using the Chinese term for "conditional".* "recipe categories" is translated as "菜谱分类" (cào bù fēn lèi), using the Chinese term for "recipe categories".* "multi-purpose" is translated as "多目的" (duō mù de), using the Chinese term for "multi-purpose".Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder"><a href="#Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder" class="headerlink" title="Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder"></a>Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05122">http://arxiv.org/abs/2308.05122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicha C. Dvornek, Catherine Sullivan, James S. Duncan, Abha R. Gupta</li>
<li>for: 这个论文旨在探讨多因素性的自闭症 спектル中的多模态方法，以结合不同平台的数据进行研究。</li>
<li>methods: 这个论文提出了一种基于注意力的方法，使用基因数据引导注意力于功能核磁共振成像特征，以提高自闭症分类和严重程度预测性能。</li>
<li>results: 研究人员通过对228例自闭症和正常发育者的数据进行十 fold十字验证，证明了这种注意力基于方法在自闭症分类和严重程度预测任务中的优于其他多模态方法。<details>
<summary>Abstract</summary>
The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details>
<details>
<summary>摘要</summary>
Autism spectrum disorder (ASD) 的多因素起源 suggests that studying it would greatly benefit from 多模态方法， combine 数据 from 各种不同的平台，例如 neuroscience imaging, genetics, and clinical characterization. Previous neuroimaging-genetic analyses often use naive feature concatenation approaches in data-driven work or use the findings from one modality to guide post hoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details></li>
</ul>
<hr>
<h2 id="From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data"><a href="#From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data" class="headerlink" title="From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data"></a>From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04553">http://arxiv.org/abs/2308.04553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maan Qraitem, Kate Saenko, Bryan A. Plummer</li>
<li>for:  mitigate the bias in visual recognition models caused by an imbalanced training set</li>
<li>methods:  pre-train a model on a balanced synthetic dataset, fine-tune on real data, and learn robust features against the bias</li>
<li>results:  improve the performance of bias mitigation methods and achieve state-of-the-art performance on three large-scale datasets<details>
<summary>Abstract</summary>
Visual recognition models are prone to learning spurious correlations induced by an imbalanced training set where certain groups (\eg Females) are under-represented in certain classes (\eg Programmers). Generative models offer a promising direction in mitigating this bias by generating synthetic data for the minority samples and thus balancing the training set. However, prior work that uses these approaches overlooks that visual recognition models could often learn to differentiate between real and synthetic images and thus fail to unlearn the bias in the original dataset. In our work, we propose a novel two-stage pipeline to mitigate this issue where 1) we pre-train a model on a balanced synthetic dataset and then 2) fine-tune on the real data. Using this pipeline, we avoid training on both real and synthetic data, thus avoiding the bias between real and synthetic data. Moreover, we learn robust features against the bias in the first step that mitigate the bias in the second step. Moreover, our pipeline naturally integrates with bias mitigation methods; they can be simply applied to the fine-tuning step. As our experiments prove, our pipeline can further improve the performance of bias mitigation methods obtaining state-of-the-art performance on three large-scale datasets.
</details>
<details>
<summary>摘要</summary>
视觉识别模型容易学习偏袋性词induced by an imbalanced训练集，其中certain groups（例如女性）在certain classes（例如程序员）下是under-represented。生成模型提供了一个promising direction来mitigate这种偏袋性，通过生成Synthetic数据来填充训练集中的缺失。然而，先前的工作 ignores the fact that visual recognition models could learn to differentiate between real and synthetic images, leading to a failure to unlearn the bias in the original dataset.在我们的工作中，我们提出了一个novel two-stage管道来mitigate this issue，包括：1）先在一个平衡的Synthetic dataset上pre-train模型，然后2）在真实数据上 fine-tune。通过这个管道，我们可以避免训练在真实和Synthetic数据上，从而避免偏袋性between real and Synthetic data。此外，我们在第一步学习了强健的特征，以mitigate偏袋性在第二步。此外，我们的管道自然地与偏袋性mitigation方法集成，它们可以简单地应用到精度调整步骤中。根据我们的实验，我们的管道可以进一步提高偏袋性mitigation方法的性能，在三个大规模数据集上达到状态之 искусственный智能的性能。
</details></li>
</ul>
<hr>
<h2 id="Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining"><a href="#Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining" class="headerlink" title="Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining"></a>Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04551">http://arxiv.org/abs/2308.04551</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbrattoli/JigsawPuzzlePytorch">https://github.com/bbrattoli/JigsawPuzzlePytorch</a></li>
<li>paper_authors: Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Cristian A. Linte</li>
<li>for: 这个研究是为了探讨深度学习基于噪音标签的自然图像分类表现如何受损，以及是否可以使用自我主导学习方法来改善分类性能。</li>
<li>methods: 这个研究使用了两种自我主导学习方法：对于自然图像Dataset，使用了对称自我主导学习，并且使用了预设任务基于自我主导学习。</li>
<li>results: 研究发现，使用自我主导学习方法初始化模型的 weights 可以帮助模型更好地学习噪音标签下的图像分类任务，并且可以提高模型对噪音标签的抗衰假性。<details>
<summary>Abstract</summary>
Noisy labels hurt deep learning-based supervised image classification performance as the models may overfit the noise and learn corrupted feature extractors. For natural image classification training with noisy labeled data, model initialization with contrastive self-supervised pretrained weights has shown to reduce feature corruption and improve classification performance. However, no works have explored: i) how other self-supervised approaches, such as pretext task-based pretraining, impact the learning with noisy label, and ii) any self-supervised pretraining methods alone for medical images in noisy label settings. Medical images often feature smaller datasets and subtle inter class variations, requiring human expertise to ensure correct classification. Thus, it is not clear if the methods improving learning with noisy labels in natural image datasets such as CIFAR would also help with medical images. In this work, we explore contrastive and pretext task-based self-supervised pretraining to initialize the weights of a deep learning classification model for two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100K tissue histological images and COVID-QU-Ex chest X-ray images. Our results show that models initialized with pretrained weights obtained from self-supervised learning can effectively learn better features and improve robustness against noisy labels.
</details>
<details>
<summary>摘要</summary>
噪声标签会对深度学习基于监督学习的图像分类性能产生负面影响，因为模型可能会过拟合噪声并学习损坏的特征提取器。在自然图像分类训练中使用噪声标签数据时，使用对比自我超视的初始化模型 weights 可以降低特征损坏和提高分类性能。然而，现有的研究没有探讨：一、其他自我超视任务基于预测任务的预训练对噪声标签下的学习产生影响，二、任何自我超视预训练方法可以独立地为医学图像中的噪声标签下学习提供帮助。医学图像通常具有较小的数据集和极细的间类变化，需要人工专业来确保正确的分类。因此，是否可以在自然图像 dataset 中使用自我超视预训练来提高噪声标签下的学习，是一个未知问题。在这个工作中，我们探讨了对比和预测任务基于自我超视预训练的影响，以 Initialize 深度学习分类模型的 weights 以便在两个医学图像 dataset 上进行自我induced 噪声标签下的学习。我们的结果表明，使用自我超视预训练初始化模型 weights 可以更好地学习特征和提高对噪声标签的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures"><a href="#Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures" class="headerlink" title="Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures"></a>Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04539">http://arxiv.org/abs/2308.04539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash</li>
<li>for: 这篇论文旨在提出一种基于生物学原理的轻量级神经网络架构，以便在不断接收数据流中不间断地学习，而不需要抽象缓存或重播。</li>
<li>methods: 该论文使用了生物学中的 synaptic plasticity 机制和 neuromodulation，通过本地错误信号来进行学习，从而实现了在线不间断学习而不需要 stochastic gradient descent。</li>
<li>results: 该方法在 Split-MNIST、Split-CIFAR-10 和 Split-CIFAR-100 数据集上表现出色，比较memory-constrained learning方法和 memory-intensive replay-based方法更好，并且可以与state-of-the-art memory-intensive replay-based方法匹配。此外， authors 还将关键的设计元素integrated into other backpropagation-based continual learning algorithms，提高了它们的准确性。<details>
<summary>Abstract</summary>
The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.   Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.
</details>
<details>
<summary>摘要</summary>
“持续学习”是设计智能系统的核心能力。许多持续学习方法 rely 于测验函数均值对应和其变形，因此需要运用记忆缓冲或重播来缓解其稳定性、嗜好和短期记忆限制。为解决这个限制，我们已经开发了基于生物学原理的轻量级神经网络架构，具有synaptic plasticity机制和神经调节，因此可以通过本地错误信号进行在线持续学习，不需要数据测验函数均值对应。我们的方法在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100 datasets上实现了较好的在线持续学习性能，比较于其他记忆受限的学习方法和匹配了memory-intensive replay-based方法的性能。我们还证明了我们的方法可以与其他条件反射-based持续学习算法相结合，提高其精度。我们的结果提供了将生物学原理应用到机器学习模型的重要证据，并提供了如何运用这些原理来设计更有效率和可靠的在线持续学习系统。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review"><a href="#Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review" class="headerlink" title="Deep Learning for Diverse Data Types Steganalysis: A Review"></a>Deep Learning for Diverse Data Types Steganalysis: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04522">http://arxiv.org/abs/2308.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Kheddar, Mustapha Hemis, Yassine Himeur, David Megías, Abbes Amira<br>for: 这篇论文主要探讨了深度学习基本的隐藏信息检测技术，以帮助探索黑客或恐怖份子所使用的隐藏通信。methods: 这篇论文主要介绍了各种深度学习技术，包括深度学习探测、深度转移学习和深度强化学习，并评估了它们在不同的数据集上的性能。results: 根据文献的数据显示，深度学习基本的隐藏信息检测技术已经取得了比较高的检测精度和速度。尤其是使用深度转移学习和深度强化学习的方法，能够在不同的类型数据上实现更高的检测性能。<details>
<summary>Abstract</summary>
Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.
</details>
<details>
<summary>摘要</summary>
信息安全领域中的隐藏通信和找到隐藏通信的技术是两个相关的方面，称为 стеганография和стегана利isis。Steganography是为了隐藏通信，而Steganalysis是为了找到隐藏的通信或者恢复其中的数据。隐藏通信是由Cybercriminal和恐怖分子使用，以避免被抓获时 Possession of incriminating evidence，因为在许多国家， cryptography is prohibited or restricted。因此，了解最新的隐藏信息探测技术是在揭露违法行为中非常重要。过去几年，一些强大和可靠的隐藏信息探测技术在文献中被引入。这篇评论文章提供了深度学习基于的隐藏信息探测技术，用于检测数字媒体中的隐藏信息。文章覆盖了所有类型的遮盖，包括图像、音频和视频，并讨论了最常用的深度学习技术。此外，文章还探讨了使用更高级的深度学习技术，如深度传输学习（DTL）和深度奖励学习（DRL），以提高隐藏信息探测系统的性能。文章提供了现场的评论，包括最新的数据集和评价标准，以及DTL基于的隐藏信息探测方法的性能分析。文章结束于隐藏信息探测领域的当前状况，挑战和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems"><a href="#Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems" class="headerlink" title="Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems"></a>Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05120">http://arxiv.org/abs/2308.05120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edward Chen, Han Bao, Nam Dinh</li>
<li>for:  This paper aims to improve the trustworthiness of machine learning (ML) predictions in instrumentation and control systems by developing a real-time model-agnostic method to evaluate the relative reliability of ML predictions.</li>
<li>methods:  The proposed method, called Laplacian distributed decay for reliability (LADDR), incorporates out-of-distribution detection on the training dataset to determine the difference between the operational and training datasets, which is used to calculate a prediction’s relative reliability.</li>
<li>results:  The LADDR method is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients, and is shown to be effective in evaluating the relative reliability of ML predictions for conventional interpolation tasks.<details>
<summary>Abstract</summary>
In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at extrapolation. This occurs when new samples are "far" from training samples. The method, referred to as the Laplacian distributed decay for reliability (LADDR), determines the difference between the operational and training datasets, which is used to calculate a prediction's relative reliability. LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. LADDR is intended as a "data supervisor" and determines the appropriateness of well-trained ML models in the context of operational conditions. Ultimately, LADDR illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.
</details>
<details>
<summary>摘要</summary>
近年来，数据驱动神经网络基于机器学习（ML）算法的Field在实现仪表和控制系统方面得到了广泛的研究和应用。虽然它们在操作上有承诺，但ML算法的可靠性还未得到全面的评估。失败的ML集成系统未能准确地理解;缺乏完善的风险模型可能会降低ML系统的可靠性。国家标准技术研究所的最近报告显示，在智能系统中，可靠性将作为采用ML的关键障碍。因此，在这项工作中，我们提出了一种实时模型不依赖的方法，通过在训练集上进行异常检测来评估ML预测的相对可靠性。ML算法在 interpolate（或近似 interpolate）任务上 excel，但在 extrapolation 任务上会 significatively degrade。这意味着当新样本远离训练样本时，ML算法会表现不佳。我们提出的方法，即Laplacian distributed decay for reliability（LADDR），可以在不同的损失流转中预测安全重要因素的可靠性。LADDR是一种“数据监管”，用于判断训练集和操作集之间的差异，以计算预测的相对可靠性。LADDR是一种模型不依赖的方法，可以在不同的操作条件下评估ML模型的可靠性。最终，LADDR示例了如何在常规 interpolate 任务中使用训练数据作为可靠性的证明。
</details></li>
</ul>
<hr>
<h2 id="MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting"><a href="#MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting" class="headerlink" title="MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting"></a>MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04511">http://arxiv.org/abs/2308.04511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/big-data-lab-umbc/sea-ice-prediction">https://github.com/big-data-lab-umbc/sea-ice-prediction</a></li>
<li>paper_authors: Sahara Ali, Jianwu Wang</li>
<li>for: 这 paper 的目的是为了预测北极海冰覆盖率（SIC），以便更好地理解和预测北极气候变化。</li>
<li>methods: 这 paper 使用了一种基于深度学习的方法，称为 MT-IceNet，它使用了一个 UNet 结构，并使用了多个时间流和空间流来预测北极海冰覆盖率。</li>
<li>results: 根据使用 NSIDC 的卫星评估数据和 ERA5 演算结果，这 paper 的结果表明，MT-IceNet 模型可以提供出色的预测性能，比其他现有的方法更加准确，最多可以预测到 6 个月前的情况。<details>
<summary>Abstract</summary>
Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric and oceanic variables from ERA5 reanalysis product during 1979-2021, we show that our proposed model provides promising predictive performance for per-pixel SIC forecasting with up to 60% decrease in prediction error for a lead time of 6 months as compared to its state-of-the-art counterparts.
</details>
<details>
<summary>摘要</summary>
《北极强化效应对 климатиче Patterns 产生了广泛和深刻的影响，从2000年代中期以来，全球和地方的极端天气事件变得更加频繁和严重。北极强化效应的核心是历史上无 precedent的海冰损失，这种观测结果表明了这一点。预测北极海冰的科学研究问题具有基本挑战，包括物理基础模型和统计学机器学习模型。我们提出了MT-IceNet模型，这是一种基于UNet的空间和多时间（MT）深度学习模型，用于预测北极海冰浓度（SIC）。该模型使用编码器-解码器架构，并使用跳接连接来处理多时间输入流，以生成未来时间步的空间地图。使用1979-2021年NSIDC从卫星得到的月度和两个月度海冰数据，以及ERA5分析产品中的大气和海洋变量，我们表明了我们提出的模型在预测每个像素SIC的前6个月的预测误差减少了60%，与现有的模型相比。
</details></li>
</ul>
<hr>
<h2 id="Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning"><a href="#Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning" class="headerlink" title="Efficient option pricing with unary-based photonic computing chip and generative adversarial learning"></a>Efficient option pricing with unary-based photonic computing chip and generative adversarial learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04493">http://arxiv.org/abs/2308.04493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Lingxiao Wan, Sergi Ramos-Calderer, Yuancheng Zhan, Wai-Keong Mok, Hong Cai, Feng Gao, Xianshu Luo, Guo-Qiang Lo, Leong Chuan Kwek, José Ignacio Latorre, Ai Qun Liu</li>
<li>for: 这个论文是为了提高金融业务效率和质量而设计的。</li>
<li>methods: 这个论文使用光子芯片实现欧洲选择价格的唯一方法，并与量子振荡估算算法相结合，以实现类比于经典 Monte Carlo 方法的二次加速。</li>
<li>results: 这个论文实现了一种光子芯片，可以快速计算欧洲选择价格，并且可以减少经典 Monte Carlo 方法的计算时间。<details>
<summary>Abstract</summary>
In the modern financial industry system, the structure of products has become more and more complex, and the bottleneck constraint of classical computing power has already restricted the development of the financial industry. Here, we present a photonic chip that implements the unary approach to European option pricing, in combination with the quantum amplitude estimation algorithm, to achieve a quadratic speedup compared to classical Monte Carlo methods. The circuit consists of three modules: a module loading the distribution of asset prices, a module computing the expected payoff, and a module performing the quantum amplitude estimation algorithm to introduce speed-ups. In the distribution module, a generative adversarial network is embedded for efficient learning and loading of asset distributions, which precisely capture the market trends. This work is a step forward in the development of specialized photonic processors for applications in finance, with the potential to improve the efficiency and quality of financial services.
</details>
<details>
<summary>摘要</summary>
现代金融系统中，产品结构变得越来越复杂，而 классическое计算能力的瓶颈已经限制了金融业的发展。我们在这里提出了一款光学芯片，实现了一元方法来估算欧洲期权价格，并结合量子振荡估计算法，实现了对类比 Monte Carlo 方法的二次加速。该芯片由三个模块组成：分布模块、预期支付模块和量子振荡估计算法模块。在分布模块中，我们嵌入了生成对抗网络，以高效地学习和加载资产分布，准确捕捉市场趋势。这项工作是金融特殊光学处理器的开发的一个重要步骤，具有改善金融服务效率和质量的潜力。
</details></li>
</ul>
<hr>
<h2 id="When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations"><a href="#When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations" class="headerlink" title="When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations"></a>When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04431">http://arxiv.org/abs/2308.04431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/basedrhys/ood-generalization">https://github.com/basedrhys/ood-generalization</a></li>
<li>paper_authors: Rhys Compton, Lily Zhang, Aahlad Puli, Rajesh Ranganath</li>
<li>for: 这篇论文旨在探讨机器学习模型如何处理多个数据集的问题，以及这些数据集之间的相互作用。</li>
<li>methods: 作者使用了多个开源的胸部X射线图像数据集，并对它们进行了大规模的实验研究。</li>
<li>results: 研究发现，在43%的情况下，将多个医院的数据集合并训练机器学习模型可能会导致模型的性能下降。这种现象发生在训练数据集与测试数据集之间存在潜在的假相关性的情况下。<details>
<summary>Abstract</summary>
In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.
</details>
<details>
<summary>摘要</summary>
在机器学习中，通常认为更多数据可以提高模型性能，但这项工作挑战这一观点，表明在许多情况下，外部数据集添加可能会损害模型性能。我们在四个开源胸部X射线图像集和九个标签之间进行了大规模的实验，发现在43%的情况下，使用两家医院的数据进行训练的模型在两家医院的数据上具有较差的最坏群组精度。这种意外的结果，即尽管添加的医院使训练分布更加类似于测试分布，但是模型在两家医院的数据上具有较差的性能。我们解释了这种现象是由于医院特有的图像artifacts产生的假 correlation的影响。我们强调在多个数据集训练时存在的费解之处， между添加更多数据的明显利益和引入的假 correlations的隐性成本。在某些情况下，平衡数据可以消除假 correlations并提高性能，但并非总是有效的策略。我们在文献中归纳了我们的结果，以帮助解释这些结果。我们的实验让人们意识到在机器学习模型训练时，特别是在医疗影像领域，选择数据的价值很大，需要小心评估和选择数据。这些风险提出的需要在未来的研究和实践中进行细心的数据选择和模型评估。
</details></li>
</ul>
<hr>
<h2 id="SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore"><a href="#SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore" class="headerlink" title="SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"></a>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04430">http://arxiv.org/abs/2308.04430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kernelmachine/silo-lm">https://github.com/kernelmachine/silo-lm</a></li>
<li>paper_authors: Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer</li>
<li>for: 本研究旨在探讨训练语言模型（LM）时是否存在版权和限制数据的法律问题，以及如何在搜寻和执行过程中减少这些风险。</li>
<li>methods: 本研究使用了一种新的语言模型（SILO），它通过在搜寻过程中访问一个可更新和修改的非参数数据存储（例如，包含版权书籍或新闻）来减少风险。此外，SILO还使用了一个Parametric LM，用于在Open License Corpus（OLC）上进行训练。</li>
<li>results: 研究发现，使用SILO可以提高语言模型在不同领域的性能，同时减少版权和限制数据的风险。Specifically, SILO的搜寻性能与使用Pile corpus进行训练的LMClosing 90%的性能差。此外，研究还分析了不同的非参数方法的效果，以及数据库大小对性能的影响。<details>
<summary>Abstract</summary>
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.
</details>
<details>
<summary>摘要</summary>
训练语言模型（LM）在版权或限制数据上的法律合法性正在激烈讨论。然而，我们表明，如果只训练LM在低风险文本（如公共领域或政府文件）上，其性能会显著下降，因为这些文本的数量和覆盖率都很限制。我们提出了SILO，一种新的语言模型，可以在推理时管理这种风险和性能的贸易。SILO由以下两个部分组成：1. 使用 parametric LM 训练 Open License Corpus（OLC），一个我们新建的公共领域和允许授权文本的新词汇库，包含228亿个字符。2. 通过在推理时使用非参数的数据存储（例如包含版权书籍或新闻的数据）来增强模型的性能。这个数据存储支持句子级数据归属，并允许数据生成者在模型中排除自己的内容。我们的实验表明， parametric LM 在不受 OLC 覆盖的领域表现不佳。然而，通过访问数据存储，可以大幅提高 Mod 的 OUT  OF 领域表现，将性能与基于 Pile 的 LM 相凑，这个 Pile 的文本主要是高风险文本。我们还分析了非参数方法的最佳选择、剩下的错误的位置以及数据存储大小的性能满意度。我们的结果表明，可以建立高质量的语言模型，同时避免其法律风险。
</details></li>
</ul>
<hr>
<h2 id="Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data"><a href="#Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data" class="headerlink" title="Meta-Learning Operators to Optimality from Multi-Task Non-IID Data"></a>Meta-Learning Operators to Optimality from Multi-Task Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04428">http://arxiv.org/abs/2308.04428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas T. C. K. Zhang, Leonardo F. Toso, James Anderson, Nikolai Matni</li>
<li>for: 这个论文的目的是提出一种基于共同特征提取的机器学习方法，以便在不同来源或任务上学习共同的表示函数，从而降低计算成本和统计泛化。</li>
<li>methods: 这个论文使用的方法包括一种基于替换最小化的对抗学习策略，以及一种基于特征白化的权重更新策略。</li>
<li>results: 这个论文的结果表明，使用这种方法可以在不同来源或任务上学习共同的表示函数，并且可以降低计算成本和统计泛化。此外，这种方法还可以在各种数学模型下进行扩展和应用。<details>
<summary>Abstract</summary>
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}$ ($\texttt{DFW}$), of the popular alternating minimization-descent (AMD) scheme proposed in Collins et al., (2021), and establish linear convergence to the optimal representation with noise level scaling down with the $\textit{total}$ source data size. This leads to generalization bounds on the same order as an oracle empirical risk minimizer. We verify the vital importance of $\texttt{DFW}$ on various numerical simulations. In particular, we show that vanilla alternating-minimization descent fails catastrophically even for iid, but mildly non-isotropic data. Our analysis unifies and generalizes prior work, and provides a flexible framework for a wider range of applications, such as in controls and dynamical systems.
</details>
<details>
<summary>摘要</summary>
一个强大的概念在现代机器学习中是将多元数据中的共同特征提取出来。这将reduces computational effort和statistical generalization的成本，因为仅需要 fine-tune fewer parameters on a given task。在理论上诠释这些优点，我们提出一个统一 Linear operators $M$ 的恢复问题，其中 vector measurements $y = Mx + w$ 中的 covariates $x$ 可能是非 i.i.d. 和非对称的。我们证明了现有的不对称适应学习方法对 representation update 会产生偏见，导致随着任务数量增加而对 noise term 的扩大。这会导致 representation learning 的样本Complexity 被瓶颈在单一任务数据大小上。我们引入了一个适应 $\texttt{De-bias & Feature-Whiten}$ （$\texttt{DFW}$），它是 Collins et al., (2021) 提出的流行的 Alternating Minimization-Descent （AMD）方案的修改。我们证明了 $\texttt{DFW}$ 在 total source data size 下随着阶层降低的情况下，具有线性传播到优化的表现。这导致了一个对 oracle empirical risk minimizer 相似的一个 generalization bound。我们透过各种数据 simulated 的 verify，证明了 $\texttt{DFW}$ 的重要性。具体来说，我们发现了 vanilla Alternating-Minimization Descent 甚至在 iid 的数据上也会 catastrophically fail。我们的分析统一了和扩展了先前的工作，并提供了更多的应用，例如在控制和动力系统等领域。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces"><a href="#A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces" class="headerlink" title="A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces"></a>A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04426">http://arxiv.org/abs/2308.04426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikun Liu, Yuning Wang, Cheng Liu</li>
<li>for: 这个研究是为了检测古代碑石表面上的自然衰老和人工损坏，以便预防文化遗产的保护。</li>
<li>methods: 这篇论文使用深度学习方法来自动检测古代碑石表面上的紧急情况，包括数据获取、预处理、模型设计和后处理等阶段。</li>
<li>results: 这篇论文使用自动encoder（AE）和生成敌方网络（GAN）架构，可以实时检测古代碑石表面上的紧急情况，并且不需要大量的异常样本。在实验中，使用长门洞穴的石碑为案例研究，提出了一个无监督学习模型，并在重建精度99.74%的基础上验证了模型的可靠性和精度。<details>
<summary>Abstract</summary>
Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\%. The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms. This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage.
</details>
<details>
<summary>摘要</summary>
正确地探测古迹上自然衰老和人为损坏的存在是保护古迹的首要任务。现有的文化遗产保护方法无法完全达到这个目标，因为很难平衡精度、效率、时间和成本。本研究提出了一种基于深度学习的方法，可以自动探测古石碑上的紧急情况，使用自适应神经网络（AE）和生成对抗网络（GAN）。提案的方法可以无需大量的异常样本，同时具有全面探测不可预测的异常的能力。方法包括监控、数据收集、预处理、模型结构和后处理等阶段。以长门石窟的石碑为例，提出了一个无监控学习模型，使用AE和GAN架构，并在重建准确率达99.74%。评估结果显示了对七种人工设计的异常探测的精准性和可靠性，无 FALSE ALARM 的情况。本研究将深度学习应用在文化遗产保护领域提供了新的想法和可能性。
</details></li>
</ul>
<hr>
<h2 id="DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images"><a href="#DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images" class="headerlink" title="DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images"></a>DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04417">http://arxiv.org/abs/2308.04417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Zou, Kai Li, Junliang Xing, Yu Zhang, Shiying Wang, Lei Jin, Pin Tao</li>
<li>for: 这篇论文的目的是提出一个新的云 removal 框架，以解决Optical satellite images 中的云盖问题，并且提高影像质量。</li>
<li>methods: 本论文使用了条件导向扩散 Models 和深度卷积神经网络，实现高性能的云 removal。特别是，我们提出了一个独立的Encoder，以提取 conditional image 中的特征，并且使用了一个新的时间和条件融合块，以精确地模拟出云的条件影像和目标影像之间的相似性。</li>
<li>results: 实验结果显示，DiffCR 在两个通用的评估数据集上均能够获得最佳性能，并且与前一代方法的参数和computational complexity相比，只需5.1%和5.4%。所有的实验结果和代码将会在<a target="_blank" rel="noopener" href="https://github.com/XavierJiezou/DiffCR">https://github.com/XavierJiezou/DiffCR</a> 上公开。<details>
<summary>Abstract</summary>
Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods. The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work.
</details>
<details>
<summary>摘要</summary>
OPTICAL 卫星图像是一种关键的数据源，但是云覆盖往往会降低图像质量，妨碍图像应用和分析。因此，从事cloud removal的研究已经成为一个重要的研究方向。 aunque recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. 经验证明，DiffCR在两个常用的 benchmark 数据集上具有最佳性能，与之前最佳方法的参数和计算复杂度分别为5.1%和5.4%。源代码、预训练模型和所有实验结果将在https://github.com/XavierJiezou/DiffCR 上公开发布。
</details></li>
</ul>
<hr>
<h2 id="Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries"><a href="#Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries" class="headerlink" title="Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries"></a>Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05118">http://arxiv.org/abs/2308.05118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel H. Um, David A. Knowles, Gail E. Kaiser</li>
<li>for: 这篇论文旨在提出一种新的数字表示方法，用于解决flat string gene format（如FASTA&#x2F;FASTQ5）在研究中的问题。</li>
<li>methods: 该方法基于将序列转换为固定长度的数字表示，并使用这些表示进行更高效的聚类和压缩。</li>
<li>results: 研究发现，通过使用这种数字表示方法，可以更好地聚类序列，并且可以提高压缩率。此外，通过基于 codon triplets 的上下文学习，可以进行更精细的聚类和特征分析。<details>
<summary>Abstract</summary>
This paper demonstrates the utility of organized numerical representations of genes in research involving flat string gene formats (i.e., FASTA/FASTQ5). FASTA/FASTQ files have several current limitations, such as their large file sizes, slow processing speeds for mapping and alignment, and contextual dependencies. These challenges significantly hinder investigations and tasks that involve finding similar sequences. The solution lies in transforming sequences into an alternative representation that facilitates easier clustering into similar groups compared to the raw sequences themselves. By assigning a unique vector embedding to each short sequence, it is possible to more efficiently cluster and improve upon compression performance for the string representations of cDNA libraries. Furthermore, through learning alternative coordinate vector embeddings based on the contexts of codon triplets, we can demonstrate clustering based on amino acid properties. Finally, using this sequence embedding method to encode barcodes and cDNA sequences, we can improve the time complexity of the similarity search by coupling vector embeddings with an algorithm that determines the proximity of vectors in Euclidean space; this allows us to perform sequence similarity searches in a quicker and more modular fashion.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文展示了用有组织的数字表示方法优化flat string基因格式（即FASTA/FASTQ5）的研究。FASTA/FASTQ文件存在许多现有的限制，例如文件大小、对 mapping 和 aligning 进行slow processing的速度、以及contextual dependencies。这些限制会对investigations和任务 involving finding similar sequences 造成很大的阻碍。解决方案在于将序列转换成一种更好的表示方式，以便更容易将similar sequences clustering。通过赋予每个短序列唯一的vector embedding，可以更高效地 clustering和提高cDNA库的压缩性能。此外，通过基于 codon triplets 的上下文学习alternative coordinate vector embeddings，我们可以示出基于aa properties的 clustering。最后，通过使用这种序列嵌入方法来编码 barcodes 和 cDNA sequences，我们可以通过将vector embeddings coupled with an algorithm that determines the proximity of vectors in Euclidean space 来提高sequence similarity searches的时间复杂度，从而实现更快速和更模块化的搜索方式。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers"><a href="#Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers" class="headerlink" title="Probabilistic Invariant Learning with Randomized Linear Classifiers"></a>Probabilistic Invariant Learning with Randomized Linear Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04412">http://arxiv.org/abs/2308.04412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Cotta, Gal Yehuda, Assaf Schuster, Chris J. Maddison</li>
<li>for: 这个论文的目的是设计一类能够具有表达力和保持任务不变性的模型，而且具有较少的资源需求。</li>
<li>methods: 这个论文使用了随机化的算法思想，提出了一类基于随机线性模型的分类器（Randomized Linear Classifiers，RLCs），并证明RLCs可以高概率地近似任何（光滑）函数，同时保持 compact group transformations 的不变性。</li>
<li>results: 论文通过实验表明，RLCs可以在不变性任务中超越权重链 neuron 和其不变性版本，具有较少的资源需求。<details>
<summary>Abstract</summary>
Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.
</details>
<details>
<summary>摘要</summary>
“设计能够表达性和保持已知 invariants 的模型是一个在不断增长的问题。现有的解决方案都会交换 invariants 和计算或内存资源。在这项工作中，我们表明了如何利用 randomness 和设计能够表达性和 invariants 的模型，同时使用更少的资源。我们的关键发现是接受 probabilistic 的 universality 和 invariants 的想法可以降低我们的资源需求。更 Specifically，我们提出了一类基于 randomized algorithms 的 binary classification 模型，称为 Randomized Linear Classifiers (RLCs)。我们给出了参数和样本大小的条件，在这些条件下，RLCs 可以， WITH HIGH PROBABILITY，近似任何（平滑）函数，同时保持 compact group transformations 的 invariants。基于这个结果，我们设计了三种 RLCs，这些模型可以在 classification tasks 中保证 probabilistic invariants。我们证明了这些模型可以使用更少的资源来实现 universality 和 invariants，比 deterministic 神经网络和其 invariants 的counterparts。最后，我们通过实验证明了这种新的类型模型在 invariant tasks 中的 beneficial effects。”
</details></li>
</ul>
<hr>
<h2 id="XGBD-Explanation-Guided-Graph-Backdoor-Detection"><a href="#XGBD-Explanation-Guided-Graph-Backdoor-Detection" class="headerlink" title="XGBD: Explanation-Guided Graph Backdoor Detection"></a>XGBD: Explanation-Guided Graph Backdoor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04406">http://arxiv.org/abs/2308.04406</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanzihan/gnn_backdoor_detection">https://github.com/guanzihan/gnn_backdoor_detection</a></li>
<li>paper_authors: Zihan Guan, Mengnan Du, Ninghao Liu</li>
<li>For: The paper is written to detect backdoor attacks on graph learning models.* Methods: The paper proposes an explanation-guided backdoor detection method that utilizes topological feature information to distinguish backdoor samples from clean samples.* Results: The proposed method is effective in detecting backdoor attacks on multiple popular datasets and attack methods, and provides explainable results through the use of explanation methods.Here is the same information in Simplified Chinese:* For: 文章目的是探测图学习模型中的后门攻击。* Methods: 文章提出了一种基于 topological 特征信息的解释帮助的后门检测方法。* Results: 提议的方法在多个流行的数据集和攻击方法上显示出了效果，并通过使用解释方法提供了可解释的结果。I hope this helps!<details>
<summary>Abstract</summary>
Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection.
</details>
<details>
<summary>摘要</summary>
Graph 学习模型面临着重要的安全隐患，即后门攻击。可以通过插入后门触发器到训练集中，使模型在触发器存在时进行错误预测。为了防止后门攻击，后门检测被提议。在视觉和自然语言处理领域，一种emerging检测策略是根据一种奇妙现象：在混合后门和干净样本训练模型时，后门样本的损失值会下降得更快，使得后门样本可以通过选择损失值最低的样本来轻松地检测。然而，在图数据上直接应用这种方法时，它的检测效果受到图数据的topological特征信息的限制。为此，我们提出了一种带有解释的后门检测方法，利用图数据的topological信息。具体来说，我们在图数据集上训练一个助手模型，然后将图样本 feed 到模型中，然后采用解释方法来归因模型预测结果到一个重要的子图。我们发现，后门样本的归因分布与干净样本不同，因此解释子图可以作为更有特征的检测特征。我们的实验表明，我们的方法在多个流行的数据集和攻击方法上具有效果和可解释性。我们的代码可以在 GitHub 上找到：https://github.com/GuanZihan/GNN_backdoor_detection。
</details></li>
</ul>
<hr>
<h2 id="Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining"><a href="#Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining" class="headerlink" title="Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining"></a>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04396">http://arxiv.org/abs/2308.04396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Blatt, Patrick Delfmann, Petra Schubert</li>
<li>for: 这个论文主要针对的是进程挖掘（PM）在信息系统事件日志中发现过程模型的问题，具体来说是对于通信和文档oriented企业协作系统（ECS）的进程模型挖掘。</li>
<li>methods: 这篇论文提出了一种针对ECS事件日志特有的特点的事件抽象方法（ECSEA），该方法通过比较记录的实际用户活动轨迹（高级轨迹）与系统生成的低级事件轨迹（从ECS中提取的）来训练一个模型，从而自动将未来的低级事件轨迹转换为抽象后的高级轨迹，可以用于进程挖掘。</li>
<li>results: 论文的评估结果表明，该算法能够生成准确的结果。ECSEA是一种重要的预处理方法，可以帮助解读ECS中的协作工作活动，我们称之为社会进程挖掘（Social Process Mining）。<details>
<summary>Abstract</summary>
One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.
</details>
<details>
<summary>摘要</summary>
一个目标 OF 进程挖掘（PM）是从信息系统事件日志中发现进程模型。PM 已经成功地应用于进程强调企业系统，但是它对交通和文档强调企业协作系统（ECS）的事件日志 Less 适用。ECS 事件日志具有非常细腻的特点，PM 在其日志上运行发现算法会导致“卡路里模型”。一种常见的解决方案是事件抽象，即将低级别的日志转换为更加抽象的高级别日志，以便于发现算法。ECS 日志具有特殊的特点， existing 事件抽象方法未能充分 Address 这些特点。我们的目标是通过针对实际用户活动记录（高级轨迹）和系统生成的低级别轨迹（从 ECS 提取）进行比较，并 trains 一个模型，以便将未来的低级别轨迹自动转换为抽象的高级别日志，可以用于 PM。我们的评估结果表明，该算法生成的结果准确。ECSEA 是一种适用于 ECS 的预处理方法，它是社交过程挖掘（Social Process Mining）中不可或缺的一部分。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging"><a href="#Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging" class="headerlink" title="Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging"></a>Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04395">http://arxiv.org/abs/2308.04395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Nørgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi</li>
<li>for: 这篇研究旨在提出一种不需要标注数据的Domain Adaptation方法，以便在不同的MRI扫描设备和数据集中进行脑部分 segmentation 任务。</li>
<li>methods: 该方法利用了MRI特定的数据生成技术，并通过对数据进行不同的预处理和数据增强来提高模型的泛化能力。</li>
<li>results: 经过广泛的实验和比较，该方法在多种任务和数据集中表现出了高精度和广泛的可用性，同时也能够快速地适应新的扫描设备和数据集。<details>
<summary>Abstract</summary>
Deep learning-based models in medical imaging often struggle to generalize effectively to new scans due to data heterogeneity arising from differences in hardware, acquisition parameters, population, and artifacts. This limitation presents a significant challenge in adopting machine learning models for clinical practice. We propose an unsupervised method for robust domain adaptation in brain MRI segmentation by leveraging MRI-specific augmentation techniques. To evaluate the effectiveness of our method, we conduct extensive experiments across diverse datasets, modalities, and segmentation tasks, comparing against the state-of-the-art methods. The results show that our proposed approach achieves high accuracy, exhibits broad applicability, and showcases remarkable robustness against domain shift in various tasks, surpassing the state-of-the-art performance in the majority of cases.
</details>
<details>
<summary>摘要</summary>
深度学习基本模型在医疗成像领域经常陷入新扫描数据的泛化问题，这是因为数据间的不同，包括硬件、获取参数、人口和artefacts等。这种限制对于实施机器学习模型在临床实践中带来了重要的挑战。我们提议一种无监督的鲁棒领域适应方法，通过利用MRI特有的扩充技术来实现。为评估我们的方法的效果，我们在多个数据集、模式和分割任务中进行了广泛的实验，与当前最佳方法进行比较。结果显示，我们的提议方法在多个任务中具有高精度、广泛适用性和强大的鲁棒性，超越了当前最佳性能的大多数情况。
</details></li>
</ul>
<hr>
<h2 id="Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries"><a href="#Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries" class="headerlink" title="Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries"></a>Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10875">http://arxiv.org/abs/2308.10875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elviscuihan/csoma">https://github.com/elviscuihan/csoma</a></li>
<li>paper_authors: Elvis Han Cui, Zizhao Zhang, Culsome Junwen Chen, Weng Kee Wong</li>
<li>for:  This paper is written to demonstrate the flexibility and out-performance of a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) in various optimization problems in the statistical sciences.</li>
<li>methods:  The paper uses the CSO-MA algorithm to solve a variety of optimization problems, including finding maximum likelihood estimates of parameters, estimating parameters in a Rasch model, finding M-estimates for a Cox regression, and matrix completion to impute missing values.</li>
<li>results:  The paper shows that the CSO-MA algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. The algorithm is applied to a variety of optimization problems, including finding maximum likelihood estimates of parameters in a single cell generalized trend model, estimating parameters in a commonly used Rasch model, finding M-estimates for a Cox regression, and matrix completion to impute missing values.<details>
<summary>Abstract</summary>
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two compartment model. In addition we discuss applications to (v) select variables optimally in an ecology problem and (vi) design a car refueling experiment for the auto industry using a logistic model with multiple interacting factors.
</details>
<details>
<summary>摘要</summary>
自然 inspirited metaheuristic algorithms 是人工智能中重要的组件，广泛应用于各个领域解决各种困难的优化问题。我们使用一种新提出的自然 inspirited metaheuristic algorithm called competitive swarm optimizer with mutated agents（CSO-MA），并证明其灵活性和相比其他竞争对手的高性能。在统计科学中，我们应用了这种算法，包括：(i) 在单元维度泛化趋势模型中找到最大化拟合参数的最佳估计值，以研究生物信息学中的pseudotime。(ii) 在教育研究中，使用这种算法来估计Rasch模型中的参数。(iii) 在Markov renewal模型中使用这种算法来找到Cox回归的M-估计值。(iv) 在两个分布中完成缺失值的imatrix completion。此外，我们还讨论了这种算法在生态学问题中选取变量的最佳方法，以及在汽车业中使用Logistic模型来设计一个循环实验。
</details></li>
</ul>
<hr>
<h2 id="AdaptEx-A-Self-Service-Contextual-Bandit-Platform"><a href="#AdaptEx-A-Self-Service-Contextual-Bandit-Platform" class="headerlink" title="AdaptEx: A Self-Service Contextual Bandit Platform"></a>AdaptEx: A Self-Service Contextual Bandit Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08650">http://arxiv.org/abs/2308.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Black, Ercument Ilhan, Andrea Marchini, Vilda Markeviciute</li>
<li>for: 这篇论文是为了介绍一个自助上下文投机平台，即AdaptEx，该平台可以在Expedia Group中广泛应用，以便 personnalize 用户体验。</li>
<li>methods: 该论文使用了多臂投机算法，以适应每个访问者的特定上下文，选择最佳变体，并快速从每次交互中学习。</li>
<li>results: 该平台可以快速提高用户体验，降低传统测试方法相关的成本和时间。它还可以在内容不断变化和连续”冷启”情况下快速迭代到优化产品解决方案。<details>
<summary>Abstract</summary>
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making"><a href="#Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making" class="headerlink" title="Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making"></a>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04375">http://arxiv.org/abs/2308.04375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Hun Lee, Chong Jun Chew<br>for: 这个论文旨在研究人工智能（AI）在高风险领域（如医疗）的决策支持方面，以及人类对 AI 建议的过度依赖问题。methods: 该论文使用了突出特征解释以及对假解释来让人类更加分析地评估 AI 建议，以降低对 AI 的过度依赖。results: 研究发现，当 AI 模型提供正确的建议时，人类的性能和协调水平都得到了提高。然而，人类对 AI 模型的错误建议仍然存在过度依赖的问题，并且counterfactual解释可以帮助人类减少对错误 AI 建议的过度依赖。Specifically, 非专业人员在使用 counterfactual解释时表现出了更大的改善，而专业人员的性能则更好。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在高度决策领域（如医疗）中被越来越广泛使用以协助人类决策。然而，研究人员已经提出了一个问题，即人们可能会因为AI模型的错误建议而过分依赖于AI，而不是 дости得人类AI补充性能。在这项工作中，我们使用了突出特征说明以及对比说明来使人们更加分析地评估AI建议，以降低对AI的过分依赖。我们在评估患者质量运动质量任务上进行了实验，并分析了参与者的表现、同意水平和对AI的依赖度。我们的结果表明，含有突出特征和对比说明的AI模型可以帮助治疗师和非专业人员提高表现和同意水平。而且，对比说明可以帮助治疗师和非专业人员减少对“错误”AI输出的过分依赖，相比突出特征说明下降21%。特别是，非专业人员在使用突出特征说明时表现下降18.0 f1-score，而在使用对比说明时表现下降14.0 f1-score，而治疗师则表现下降8.6和2.8 f1-score。我们的研究表明，对比说明可以更好地估计AI模型的准确性，降低对“错误”AI输出的过分依赖，并带来人类AI协同决策的进步。
</details></li>
</ul>
<hr>
<h2 id="Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning"><a href="#Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning" class="headerlink" title="Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning"></a>Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04373">http://arxiv.org/abs/2308.04373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Queyrut, Yérom-David Bromberg, Valerio Schiavoni</li>
<li>for: The paper is written to address the issue of privacy preservation in federated learning, specifically the problem of malicious probing attacks on the model updates.</li>
<li>methods: The paper proposes a novel shielding mechanism called Pelta, which leverages Trusted Execution Environments (TEEs) to mask part of the back-propagation chain rule and prevent attackers from exploiting it for the design of malicious samples.</li>
<li>results: The paper demonstrates the effectiveness of Pelta against the Self Attention Gradient adversarial attack on a state-of-the-art ensemble model.Here’s the simplified Chinese version of the three points:</li>
<li>for: 本文是为了解决联合学习中的隐私保护问题，特别是对于攻击者通过模型更新来探测敏感信息。</li>
<li>methods: 本文提出了一种名为Pelta的新防御机制，利用可信执行环境（TEEs）隐藏部分反向传播链规则，防止攻击者通过这些规则设计恶意样本。</li>
<li>results: 本文对一个国际 ensemble 模型进行了评估，并证明Pelta可以有效防止自我注意力梯度攻击。<details>
<summary>Abstract</summary>
The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling"><a href="#SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling" class="headerlink" title="SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling"></a>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04365">http://arxiv.org/abs/2308.04365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matthewvowels1/slem">https://github.com/matthewvowels1/slem</a></li>
<li>paper_authors: Matthew J. Vowels</li>
<li>for: 本研究旨在提供一种可靠且不偏的 causal effect 估计方法，以便在 observational 数据上进行预测性的 intervenion 研究。</li>
<li>methods: 本研究使用 Super Learner Equation Modeling（SLEM），一种基于机器学习 Super Learner 集成的路径模型方法，来解决 causal inference 中的函数偏差问题。</li>
<li>results: 对比 SEM 方法，SLEM 在线性模型中表现出了竞争性的表现，并且在非线性关系中表现出了superiority。此外，SLEM 还提供了可靠且不偏的 causal effect 估计方法，可以用于 observational 数据上进行预测性的 intervenion 研究。<details>
<summary>Abstract</summary>
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non-linear relationships. We provide open-source code, and a tutorial notebook with example usage, accentuating the easy-to-use nature of the method.
</details>
<details>
<summary>摘要</summary>
科学中的重要目标之一是 causal inference，即使用观察数据来得到干扰干扰的结论。路径模型、结构方程模型（SEM）和、更一般地说，导向无环图（DAG）可以明确地 especify causal structure underlying a phenomenon的假设。不同于 DAG，SEM 假设 linearity，这可能会导致函数假设不正确，从而阻碍研究人员进行可靠的效应大小估计。在这种情况下，我们提出了 Super Learner Equation Modeling，一种路径模型技术， integrate machine learning Super Learner ensembles。我们经验表明它可以提供可靠和不偏的 causal effect estimates，与 SEM 在线性模型中的表现竞争性，并在非线性关系中超过 SEM。我们提供了开源代码和一个教程Notebook，强调这种方法的易用性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.LG_2023_08_09/" data-id="clpxp6c3g00pyee8843lchj5x" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/eess.IV_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T09:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/eess.IV_2023_08_09/">eess.IV - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction"><a href="#ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction" class="headerlink" title="ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction"></a>ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04956">http://arxiv.org/abs/2308.04956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Chen, Lin Yao, Zeqing Xia, Yuhang Wang<br>for:This paper aims to improve the accuracy of 3D structure reconstruction from cryo-EM images with unknown poses and low signal-to-noise ratio.methods:The proposed method, called ACE-HetEM, uses an unsupervised deep learning architecture based on amortized inference to disentangle conformation classifications and pose estimations.results:ACE-HetEM has comparable accuracy in pose estimation and produces better reconstruction resolution than non-amortized methods on simulated datasets, and is also applicable to real experimental datasets.Here’s the Chinese translation:for:这篇论文目的是提高低信号噪响和未知投影角度的普适电子顺传影像三维结构重建精度。methods:提议的方法是基于杜邦诱导的无监督深度学习架构ACE-HetEM，以分离配置分类和投影估计。results:在模拟数据集上，ACE-HetEM和非杜邦方法相比，pose估计准确率相似，重建分辨率更高，并且可应用于实验室数据集。<details>
<summary>Abstract</summary>
Due to the extremely low signal-to-noise ratio (SNR) and unknown poses (projection angles and image translation) in cryo-EM experiments, reconstructing 3D structures from 2D images is very challenging. On top of these challenges, heterogeneous cryo-EM reconstruction also has an additional requirement: conformation classification. An emerging solution to this problem is called amortized inference, implemented using the autoencoder architecture or its variants. Instead of searching for the correct image-to-pose/conformation mapping for every image in the dataset as in non-amortized methods, amortized inference only needs to train an encoder that maps images to appropriate latent spaces representing poses or conformations. Unfortunately, standard amortized-inference-based methods with entangled latent spaces have difficulty learning the distribution of conformations and poses from cryo-EM images. In this paper, we propose an unsupervised deep learning architecture called "ACE-HetEM" based on amortized inference. To explicitly enforce the disentanglement of conformation classifications and pose estimations, we designed two alternating training tasks in our method: image-to-image task and pose-to-pose task. Results on simulated datasets show that ACE-HetEM has comparable accuracy in pose estimation and produces even better reconstruction resolution than non-amortized methods. Furthermore, we show that ACE-HetEM is also applicable to real experimental datasets.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:由于电镜电子显微镜实验中的信号响应率（SNR）和不确定的投影角度和图像翻译都很低，从2D图像中重建3D结构非常困难。此外，异类电镜电子显微镜重建还有一个额外要求：摘要分类。一种迅速成为解决方案的方法是使用启发器架构或其变体来实现摘要推理。而非摘要方法需要对每个图像在数据集中搜索正确的图像到pose/摘要映射。然而，标准的摘要推理方法附加的缺点是难以从电镜电子显微镜图像中学习摘要分布和投影角度的分布。在这篇论文中，我们提出了一种无监督深度学习架构，称为“ACE-HetEM”，基于摘要推理。为了明确分离摘要分类和投影估计的分布，我们在我们的方法中设计了两个相互轮换的训练任务：图像到图像任务和投影到投影任务。实验结果表明，ACE-HetEM在 simulate 数据集上有相当的准确率和更高的重建分辨率，而且可以应用于实验数据集。
</details></li>
</ul>
<hr>
<h2 id="HSD-PAM-High-Speed-Super-Resolution-Deep-Penetration-Photoacoustic-Microscopy-Imaging-Boosted-by-Dual-Branch-Fusion-Network"><a href="#HSD-PAM-High-Speed-Super-Resolution-Deep-Penetration-Photoacoustic-Microscopy-Imaging-Boosted-by-Dual-Branch-Fusion-Network" class="headerlink" title="HSD-PAM: High Speed Super Resolution Deep Penetration Photoacoustic Microscopy Imaging Boosted by Dual Branch Fusion Network"></a>HSD-PAM: High Speed Super Resolution Deep Penetration Photoacoustic Microscopy Imaging Boosted by Dual Branch Fusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04922">http://arxiv.org/abs/2308.04922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyuan Zhang, Haoran Jin, Zesheng Zheng, Wenwen Zhang, Wenhao Lu, Feng Qin, Arunima Sharma, Manojit Pramanik, Yuanjin Zheng</li>
<li>for: 这篇论文旨在提出一种硬件和软件合作的方法，以提高photoacoustic microscopy（PAM）系统的速度、分辨率和深度三个关键参数的矛盾。</li>
<li>methods: 该方法基于数据驱动的算法，包括一个新的双分支合并网络，其中一个高分辨率分支和一个高速分支。</li>
<li>results: 经过广泛的数值和生物体实验 validate，该算法可以提高PAM系统的速度和分辨率，同时保持AR-PAM模式的深度能力。结果显示，对于低分辨率、低采样率AR-PAM图像，可以通过增加采样率和提高分辨率来提高图像质量，从而实现高速、超分辨率、深度采集的PAM系统（HSD-PAM）。<details>
<summary>Abstract</summary>
Photoacoustic microscopy (PAM) is a novel implementation of photoacoustic imaging (PAI) for visualizing the 3D bio-structure, which is realized by raster scanning of the tissue. However, as three involved critical imaging parameters, imaging speed, lateral resolution, and penetration depth have mutual effect to one the other. The improvement of one parameter results in the degradation of other two parameters, which constrains the overall performance of the PAM system. Here, we propose to break these limitations by hardware and software co-design. Starting with low lateral resolution, low sampling rate AR-PAM imaging which possesses the deep penetration capability, we aim to enhance the lateral resolution and up sampling the images, so that high speed, super resolution, and deep penetration for the PAM system (HSD-PAM) can be achieved. Data-driven based algorithm is a promising approach to solve this issue, thereby a dedicated novel dual branch fusion network is proposed, which includes a high resolution branch and a high speed branch. Since the availability of switchable AR-OR-PAM imaging system, the corresponding low resolution, undersample AR-PAM and high resolution, full sampled OR-PAM image pairs are utilized for training the network. Extensive simulation and in vivo experiments have been conducted to validate the trained model, enhancement results have proved the proposed algorithm achieved the best perceptual and quantitative image quality. As a result, the imaging speed is increased 16 times and the imaging lateral resolution is improved 5 times, while the deep penetration merit of AR-PAM modality is still reserved.
</details>
<details>
<summary>摘要</summary>
photoacoustic microscopy (PAM) 是一种新的 photoacoustic imaging (PAI) 技术，用于可见三维生物结构，通过扫描生物组织的方式实现。然而，存在三个关键的图像参数之间的互相关系：图像速度、横向分辨率和吸收深度。提高一个参数会导致其他两个参数受损，这限制了整体 PAM 系统的性能。我们提议通过硬件和软件合作来突破这些限制。从低横向分辨率、低抽象率 AR-PAM 成像开始，我们想要提高横向分辨率和更新图像，以达到高速、超分辨、深入吸收的 PAM 系统（HSD-PAM）。数据驱动基于的算法是一种有希望的方法，因此我们提出了一种专门的双分支融合网络，包括高分辨率分支和高速分支。由于可用的可 switchable AR-OR-PAM 成像系统，对应的低分辨率、下抽象 AR-PAM 和高分辨率、全样本 OR-PAM 图像对在训练网络时使用。我们进行了广泛的 simulations 和生物实验，以验证训练的模型，提升结果表明，提案的算法实现了最佳的感知和量化图像质量。因此，图像速度提高 16 倍，横向分辨率提高 5 倍，而 AR-PAM 模式下的深入吸收特性仍然保留。
</details></li>
</ul>
<hr>
<h2 id="StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability"><a href="#StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability" class="headerlink" title="StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability"></a>StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04904">http://arxiv.org/abs/2308.04904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qmme/stablevqa">https://github.com/qmme/stablevqa</a></li>
<li>paper_authors: Tengchuan Kou, Xiaohong Liu, Wei Sun, Jun Jia, Xiongkuo Min, Guangtao Zhai, Ning Liu</li>
<li>For: The paper is written for evaluating the stability of User Generated Content (UGC) videos and proposing a novel Video Quality Assessment for Stability (VQA-S) model.* Methods: The paper uses a novel VQA-S model named StableVQA, which consists of three feature extractors to acquire optical flow, semantic, and blur features, and a regression layer to predict the final stability score.* Results: The paper achieves a higher correlation with subjective opinions than existing VQA-S models and generic VQA models, and provides a new database named StableDB that contains 1,952 diversely-shaky UGC videos with subjective scores for video stability.<details>
<summary>Abstract</summary>
Video shakiness is an unpleasant distortion of User Generated Content (UGC) videos, which is usually caused by the unstable hold of cameras. In recent years, many video stabilization algorithms have been proposed, yet no specific and accurate metric enables comprehensively evaluating the stability of videos. Indeed, most existing quality assessment models evaluate video quality as a whole without specifically taking the subjective experience of video stability into consideration. Therefore, these models cannot measure the video stability explicitly and precisely when severe shakes are present. In addition, there is no large-scale video database in public that includes various degrees of shaky videos with the corresponding subjective scores available, which hinders the development of Video Quality Assessment for Stability (VQA-S). To this end, we build a new database named StableDB that contains 1,952 diversely-shaky UGC videos, where each video has a Mean Opinion Score (MOS) on the degree of video stability rated by 34 subjects. Moreover, we elaborately design a novel VQA-S model named StableVQA, which consists of three feature extractors to acquire the optical flow, semantic, and blur features respectively, and a regression layer to predict the final stability score. Extensive experiments demonstrate that the StableVQA achieves a higher correlation with subjective opinions than the existing VQA-S models and generic VQA models. The database and codes are available at https://github.com/QMME/StableVQA.
</details>
<details>
<summary>摘要</summary>
视频不稳定是User Generated Content（UGC）视频中的一种不приятный扭曲，通常是因为摄像机不稳定。在过去的几年中，许多视频稳定算法被提出，但没有专门和准确的度量能够全面评估视频的稳定性。实际上，大多数现有的视频质量评估模型只评估视频质量总体而不是特定地考虑视频稳定的主观体验。因此，这些模型不能明确和精确地测量在严重抖动时的视频稳定性。另外，没有公开的大规模视频数据库，其中包含了不同程度的抖动视频以及对应的主观得分，这阻碍了视频质量评估 для稳定（VQA-S）的发展。为此，我们建立了一个名为StableDB的数据库，其中包含1,952个多样化的UGC视频，每个视频都有由34名评分者评分的视频稳定度的Mean Opinion Score（MOS）。此外，我们还 elaborately 设计了一种名为StableVQA的新型VQA-S模型，它包括三个特征提取器，用于获取光流、 semantics 和模糊特征，以及一个回归层用于预测最终的稳定度分。广泛的实验表明，StableVQA在与主观意见相关性方面高于现有的VQA-S模型和通用VQA模型。数据库和代码可以在https://github.com/QMME/StableVQA 中获取。
</details></li>
</ul>
<hr>
<h2 id="An-automated-pipeline-for-quantitative-T2-fetal-body-MRI-and-segmentation-at-low-field"><a href="#An-automated-pipeline-for-quantitative-T2-fetal-body-MRI-and-segmentation-at-low-field" class="headerlink" title="An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field"></a>An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04903">http://arxiv.org/abs/2308.04903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelly Payette, Alena Uus, Jordina Aviles Verdera, Carla Avena Zampieri, Megan Hall, Lisa Story, Maria Deprez, Mary A. Rutherford, Joseph V. Hajnal, Sebastien Ourselin, Raphael Tomi-Tricot, Jana Hutter</li>
<li>for: 这项研究的目的是为了开发一种用于低场强磁共振成像的半自动化管道，以实现快速和详细的量化T2*相关分析。</li>
<li>methods: 这种管道使用了多echo动态序列获取和重建方法，并使用了一个神经网络来自动 segment fetal体3D卷积体。</li>
<li>results: 研究发现，这种管道可以成功地对17-40周的胎儿进行高精度的T2*相关分析，并且具有高度的抗变化和鲁棒性。<details>
<summary>Abstract</summary>
Fetal Magnetic Resonance Imaging at low field strengths is emerging as an exciting direction in perinatal health. Clinical low field (0.55T) scanners are beneficial for fetal imaging due to their reduced susceptibility-induced artefacts, increased T2* values, and wider bore (widening access for the increasingly obese pregnant population). However, the lack of standard automated image processing tools such as segmentation and reconstruction hampers wider clinical use. In this study, we introduce a semi-automatic pipeline using quantitative MRI for the fetal body at low field strength resulting in fast and detailed quantitative T2* relaxometry analysis of all major fetal body organs. Multi-echo dynamic sequences of the fetal body were acquired and reconstructed into a single high-resolution volume using deformable slice-to-volume reconstruction, generating both structural and quantitative T2* 3D volumes. A neural network trained using a semi-supervised approach was created to automatically segment these fetal body 3D volumes into ten different organs (resulting in dice values > 0.74 for 8 out of 10 organs). The T2* values revealed a strong relationship with GA in the lungs, liver, and kidney parenchyma (R^2>0.5). This pipeline was used successfully for a wide range of GAs (17-40 weeks), and is robust to motion artefacts. Low field fetal MRI can be used to perform advanced MRI analysis, and is a viable option for clinical scanning.
</details>
<details>
<summary>摘要</summary>
低场强磁共振成像在妊娠健康领域是一项发展方向。低场（0.55T）扫描仪的优点包括降低受影响的artefacts，提高T2*值和更宽的轴扩（扩大对日益肥胖妊娠人口的访问）。然而，由于缺乏标准自动化图像处理工具，如分割和重建，因此对于临床应用而言，更加受限。本研究中，我们提出了一个半自动化管线，使用量化MRI对妊娠体内部进行快速和详细的T2*相关分析。我们使用多echo动态序列获取和重建妊娠体内部高分辨率三维volume，并使用可变的材料学模型进行slice-to-volume重建。通过使用半超级vised学习方法，我们自动将妊娠体三维volume分割成十个不同的器官（得到了 dice值超过0.74的八个器官）。T2*值与胎儿龄（GA）之间存在强相关性（R^2>0.5）。这种管线在17-40周的多个胎儿龄上成功应用，并具有对运动artefacts的Robust性。低场妊娠MRI可以进行高级MRI分析，是一种可靠的扫描选项。
</details></li>
</ul>
<hr>
<h2 id="Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement"><a href="#Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement" class="headerlink" title="Transmission and Color-guided Network for Underwater Image Enhancement"></a>Transmission and Color-guided Network for Underwater Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04892">http://arxiv.org/abs/2308.04892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pan Mu, Jing Fang, Haotian Qian, Cong Bai</li>
<li>for: 本研究旨在提高水下图像的显示质量，解决光线传播在水中的吸收和散射问题。</li>
<li>methods: 该研究提出了一种基于自适应传输和动态色彩指导网络的水下图像增强方法（名为ATDCnet），包括采用物理知识设计的自适应传输指导模块（ATM）、采用动态色彩指导模块（DCM）进行颜色偏差问题的解决，以及基于编码器-解码器结构和多阶段特征融合机制进行颜色恢复和对比度增强同时处理。</li>
<li>results: EXTENSIVE experiments示出ATDCnet在多个benchmark数据集上达到了当今最佳性能水平。<details>
<summary>Abstract</summary>
In recent years, with the continuous development of the marine industry, underwater image enhancement has attracted plenty of attention. Unfortunately, the propagation of light in water will be absorbed by water bodies and scattered by suspended particles, resulting in color deviation and low contrast. To solve these two problems, we propose an Adaptive Transmission and Dynamic Color guided network (named ATDCnet) for underwater image enhancement. In particular, to exploit the knowledge of physics, we design an Adaptive Transmission-directed Module (ATM) to better guide the network. To deal with the color deviation problem, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Further, we design an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to perform color restoration and contrast enhancement simultaneously. Extensive experiments demonstrate the state-of-the-art performance of the ATDCnet on multiple benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Specifically, we design an Adaptive Transmission-directed Module (ATM) to leverage the knowledge of physics and better guide the network. To address the color deviation problem, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Additionally, we design an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to simultaneously perform color restoration and contrast enhancement. Extensive experiments show that the ATDCnet achieves state-of-the-art performance on multiple benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects"><a href="#Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects" class="headerlink" title="Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects"></a>Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04883">http://arxiv.org/abs/2308.04883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamil Kwarciak, Marek Wodzinski</li>
<li>for: 这个研究旨在提高人工头盾设计的自动化程度，使用深度学习技术来解决高多标本异常性的挑战。</li>
<li>methods: 本研究使用三种深度生成模型来增强数据集，包括 Wasserstein生成对抗网络受扰条件（WGAN-GP）、WGAN-GP混合方法和 introspective Variational Autoencoder（IntroVAE）。这些模型可以生成万以上的异常头盾，并且可以控制异常的多标本性和头盾的实际形状。</li>
<li>results: 这些生成的异常头盾可以帮助提高人工头盾设计的自动化程度，并且可以增强异常部分的分类效果。研究显示，使用这些生成的异常头盾可以提高头盾设计的精度和效率。<details>
<summary>Abstract</summary>
The design of personalized cranial implants is a challenging and tremendous task that has become a hot topic in terms of process automation with the use of deep learning techniques. The main challenge is associated with the high diversity of possible cranial defects. The lack of appropriate data sources negatively influences the data-driven nature of deep learning algorithms. Hence, one of the possible solutions to overcome this problem is to rely on synthetic data. In this work, we propose three volumetric variations of deep generative models to augment the dataset by generating synthetic skulls, i.e. Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), WGAN-GP hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) and Introspective Variational Autoencoder (IntroVAE). We show that it is possible to generate dozens of thousands of defective skulls with compatible defects that achieve a trade-off between defect heterogeneity and the realistic shape of the skull. We evaluate obtained synthetic data quantitatively by defect segmentation with the use of V-Net and qualitatively by their latent space exploration. We show that the synthetically generated skulls highly improve the segmentation process compared to using only the original unaugmented data. The generated skulls may improve the automatic design of personalized cranial implants for real medical cases.
</details>
<details>
<summary>摘要</summary>
个人化骨Implant设计是一个具有挑战性和巨大性的任务，现在透过深度学习技术进行自动化处理而成为热门话题。主要挑战在于骨骼缺陷的多样性。无法获得适当的数据源，对深度学习算法的数据驱动性产生负面影响。因此，我们提出了利用合成数据作为解决方案。在这个研究中，我们提出了三种深度生成模型的卷积量变化，即Wasserstein生成对抗网络受限GP（WGAN-GP）、WGAN-GP混合Variale Autoencoder预训练（VAE/WGAN-GP）和Introspective Variale Autoencoder（IntroVAE）。我们发现可以生成万分之一的缺陷骨骼，并且可以实现缺陷兼具实际骨骼形状的调和。我们使用V-Net进行缺陷分类，并且进行潜在空间探索。我们发现生成的骨骼可以对骨骼缺陷进行优化分类，相比使用仅有原始未处理数据，提高分类效果。这些生成的骨骼可能对实际医疗案例中的个人化骨Implant设计提供帮助。
</details></li>
</ul>
<hr>
<h2 id="HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction"><a href="#HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction" class="headerlink" title="HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction"></a>HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04821">http://arxiv.org/abs/2308.04821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sriprabhar/hypercoil-recon">https://github.com/sriprabhar/hypercoil-recon</a></li>
<li>paper_authors: Sriprabha Ramanarayanan, Mohammad Al Fahim, Rahul G. S., Amrit Kumar Jethi, Keerthi Ram, Mohanasankar Sivaprakasam</li>
<li>for: 这个研究是为了提高多极MRI重建的速度和精度，并且解决了训练或微调深度学习模型的问题，以便在临床实施中使用。</li>
<li>methods: 这个研究使用了hypernetwork-based的coil configuration task-switching network，将多个配置的数据集合为一个多任务学习 perspective，将每个配置视为一个任务，并将对应的问题特有的 weights 应用到重建网络中。</li>
<li>results: 这个方法可以在不同的配置下进行灵活的自适应，并且可以与特定的配置进行实时的配置匹配，实现了在试验时对应不同配置的普遍性。实验结果显示，这个方法可以与特定配置进行匹配，并且可以与不同的配置进行自适应，而且与专门设计的配置模型相比，有着1-3dB &#x2F; 0.02-0.03的提升。<details>
<summary>Abstract</summary>
Parallel imaging, a fast MRI technique, involves dynamic adjustments based on the configuration i.e. number, positioning, and sensitivity of the coils with respect to the anatomy under study. Conventional deep learning-based image reconstruction models have to be trained or fine-tuned for each configuration, posing a barrier to clinical translation, given the lack of computational resources and machine learning expertise for clinicians to train models at deployment. Joint training on diverse datasets learns a single weight set that might underfit to deviated configurations. We propose, HyperCoil-Recon, a hypernetwork-based coil configuration task-switching network for multi-coil MRI reconstruction that encodes varying configurations of the numbers of coils in a multi-tasking perspective, posing each configuration as a task. The hypernetworks infer and embed task-specific weights into the reconstruction network, 1) effectively utilizing the contextual knowledge of common and varying image features among the various fields-of-view of the coils, and 2) enabling generality to unseen configurations at test time. Experiments reveal that our approach 1) adapts on the fly to various unseen configurations up to 32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varying coils, and to 120 deviated unseen configurations when trained on 18 configurations in a single model, 2) matches the performance of coil configuration-specific models, and 3) outperforms configuration-invariant models with improvement margins of around 1 dB / 0.03 and 0.3 dB / 0.02 in PSNR / SSIM for knee and brain data. Our code is available at https://github.com/sriprabhar/HyperCoil-Recon
</details>
<details>
<summary>摘要</summary>
“ параллельное изображение， быстрый метод МРИ, involves 动态调整基于配置，即数量、位置和敏感度的磁共振器与研究对象的解剖学相关。 传统的深度学习基于图像重建模型需要训练或微调，这会对临床应用带来障碍，因为临床医生缺乏计算资源和机器学习专业知识来训练模型。 我们提出了 HyperCoil-Recon，一种基于 hypernetwork 的磁共振器配置任务转换网络，用于多个磁共振器的图像重建。 Hypernetworks 将任务特定的 weights 适应到重建网络中，1) 有效地利用磁共振器不同配置下图像特征的共同知识，2) 允许在测试时适应未看过的配置。 实验表明，我们的方法可以1) 在未见过配置下适应到多达 32 个磁共振器，2) 与磁共振器配置特定模型匹配，3) 超过配置不变模型，增幅约为 1 dB / 0.03 和 0.3 dB / 0.02 的 PSNR / SSIM 值。我们的代码可以在 GitHub 上找到。”
</details></li>
</ul>
<hr>
<h2 id="An-Integrated-Visual-Analytics-System-for-Studying-Clinical-Carotid-Artery-Plaques"><a href="#An-Integrated-Visual-Analytics-System-for-Studying-Clinical-Carotid-Artery-Plaques" class="headerlink" title="An Integrated Visual Analytics System for Studying Clinical Carotid Artery Plaques"></a>An Integrated Visual Analytics System for Studying Clinical Carotid Artery Plaques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06285">http://arxiv.org/abs/2308.06285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaoqing Xu, Zhentao Zheng, Yiting Fu, Baofeng Chang, Legao Chen, Minghui Wu, Mingli Song, Jinsong Jiang</li>
<li>for: 这个论文旨在开发一个智能血液动脉疾病诊断系统，帮助血液动脉外科医生全面分析血液动脉疾病的临床生物学和成像指标。</li>
<li>methods: 该系统包括两个主要功能：首先，通过一系列的信息视化方法，显示血液动脉疾病和各种因素之间的相关性，并将患者生物学指标数据集成分析。其次，通过机器学习技术，提高血液动脉疾病组成部分之间的自然相关性的显示，并在医疗图像上显示血液动脉疾病的空间分布。</li>
<li>results: 通过使用医院实际取得的数据进行两个案例研究，结果表明，设计的血液动脉分析系统可以有效地为血液动脉外科医生提供临床诊断和治疗指导。<details>
<summary>Abstract</summary>
Carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.
</details>
<details>
<summary>摘要</summary>
carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.Here's the text in Traditional Chinese:carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.
</details></li>
</ul>
<hr>
<h2 id="Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks"><a href="#Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks" class="headerlink" title="Long-Distance Gesture Recognition using Dynamic Neural Networks"></a>Long-Distance Gesture Recognition using Dynamic Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04643">http://arxiv.org/abs/2308.04643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubhang Bhatnagar, Sharath Gopal, Narendra Ahuja, Liu Ren</li>
<li>For: This paper is written for recognizing gestures from longer distances, specifically for applications such as gesture-based interactions with a floor cleaning robot or a drone.* Methods: The proposed method uses a dynamic neural network to select features from gesture-containing spatial regions of the input sensor data for further processing, which helps the network focus on features important for gesture recognition while discarding background features early on.* Results: The proposed method outperforms previous state-of-the-art methods on recognition accuracy and compute efficiency in the LD-ConGR long-distance dataset.<details>
<summary>Abstract</summary>
Gestures form an important medium of communication between humans and machines. An overwhelming majority of existing gesture recognition methods are tailored to a scenario where humans and machines are located very close to each other. This short-distance assumption does not hold true for several types of interactions, for example gesture-based interactions with a floor cleaning robot or with a drone. Methods made for short-distance recognition are unable to perform well on long-distance recognition due to gestures occupying only a small portion of the input data. Their performance is especially worse in resource constrained settings where they are not able to effectively focus their limited compute on the gesturing subject. We propose a novel, accurate and efficient method for the recognition of gestures from longer distances. It uses a dynamic neural network to select features from gesture-containing spatial regions of the input sensor data for further processing. This helps the network focus on features important for gesture recognition while discarding background features early on, thus making it more compute efficient compared to other techniques. We demonstrate the performance of our method on the LD-ConGR long-distance dataset where it outperforms previous state-of-the-art methods on recognition accuracy and compute efficiency.
</details>
<details>
<summary>摘要</summary>
Gestures 是人工智能与机器之间重要的通信媒体。现有的大多数手势识别方法假设人类和机器在非常近的距离上进行交互，这个短距离假设不符实际的许多交互情况，例如与地板干净机器人或者无人机的交互。由于手势占输入数据中的只占一小部分，因此这些方法在远距离识别中表现不佳。我们提出了一种新的、准确和高效的手势识别方法，它使用动态神经网络选择手势包含的空间区域的输入感知数据进行进一步处理。这有助于网络在执行手势识别时更加有效地启用有限的计算资源，并且能够更高效地识别手势。我们在LD-ConGR长距离数据集上展示了我们的方法的性能，其与前一个状态的方法在识别精度和计算效率上都表现出色。
</details></li>
</ul>
<hr>
<h2 id="1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges"><a href="#1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges" class="headerlink" title="1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges"></a>1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04598">http://arxiv.org/abs/2308.04598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang<br>for:* This paper focuses on video instance segmentation (VIS) in long-tailed and open-world scenarios, where traditional VIS methods are limited to a small number of common classes but real-world applications require detection and tracking of rare and never-before-seen objects.methods:* The proposed method, LeTracker, uses a combination of segmentation and CEM on LVISv0.5 + COCO dataset for training the detector, and instance appearance similarity head on TAO dataset.results:* LeTracker achieves 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark, and 61.4 OWTAall in the open-world challenges, ranking 1st in the benchmark.<details>
<summary>Abstract</summary>
Currently, Video Instance Segmentation (VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories that contain only a few dozen of categories, lacking the ability to handle diverse objects in real-world videos. As TAO and BURST datasets release, we have the opportunity to research VIS in long-tailed and open-world scenarios. Traditional VIS methods are evaluated on benchmarks limited to a small number of common classes, But practical applications require trackers that go beyond these common classes, detecting and tracking rare and even never-before-seen objects. Inspired by the latest MOT paper for the long tail task (Tracking Every Thing in the Wild, Siyuan Li et), for the BURST long tail challenge, we train our model on a combination of LVISv0.5 and the COCO dataset using repeat factor sampling. First, train the detector with segmentation and CEM on LVISv0.5 + COCO dataset. And then, train the instance appearance similarity head on the TAO dataset. at last, our method (LeTracker) gets 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark. for the open-world challenges, we only use 64 classes (Intersection classes of BURST Train subset and COCO dataset, without LVIS dataset) annotations data training, and testing on BURST test set data and get 61.4 OWTAall, ranking 1st in the benchmark. Our code will be released to facilitate future research.
</details>
<details>
<summary>摘要</summary>
当前，视频实例分 segmentation（VIS）目标是将视频中的对象分类和分割，但现有的VIS方法只能处理固定的训练类别，缺乏对实际世界视频中的多样化对象的能力。随着TAO和BURST数据集的发布，我们有机会进行VIS在长尾和开放世界场景下的研究。传统的VIS方法通常被评估在限定的一些常见类别上，但实际应用需要超出这些常见类别，检测和跟踪罕见和从未seen的对象。 drawing inspiration from the latest MOT paper on the long tail task（Tracking Every Thing in the Wild，Siyuan Li et al），我们在BURST长尾挑战中使用重复因子抽样训练我们的模型。首先，我们使用LVISv0.5和COCO数据集训练探测器的 segmentation和CEM。然后，我们在TAO数据集上训练实例外观相似头。最后，我们的方法（LeTracker）在BURST测试集上获得14.9 HOTAall，排名第一名。在开放世界挑战中，我们只使用64个类别（BURST训练集和COCO数据集的交集类别，不包括LVIS数据集）的注释数据进行训练，并在BURST测试集上进行测试，得到61.4 OWTAall，排名第一名。我们将代码发布，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Semantic-Segmentation-of-Cell-Nuclei-via-Diffusion-based-Large-Scale-Pre-Training-and-Collaborative-Learning"><a href="#Semi-Supervised-Semantic-Segmentation-of-Cell-Nuclei-via-Diffusion-based-Large-Scale-Pre-Training-and-Collaborative-Learning" class="headerlink" title="Semi-Supervised Semantic Segmentation of Cell Nuclei via Diffusion-based Large-Scale Pre-Training and Collaborative Learning"></a>Semi-Supervised Semantic Segmentation of Cell Nuclei via Diffusion-based Large-Scale Pre-Training and Collaborative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04578">http://arxiv.org/abs/2308.04578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuchen Shao, Sourya Sengupta, Hua Li, Mark A. Anastasio</li>
<li>for: 这篇论文的目的是提出一个新的不监督预训学习框架 для microscopic 图像中细胞核lei的自动化 semantic segmentation, 以便于疾病诊断和组织微环境分析。</li>
<li>methods: 这个框架包括三个主要部分：一、使用一个大规模的无标注数据集进行传播模型的预训; two、使用一个 transformer 型的整合器来将传播模型中的内部特征聚合; three、实现一个协力学习框架，让传播模型和一个监督式分类模型进行共同学习。</li>
<li>results: 在四个公开的数据集上进行了实验，证明了我们的框架可以与竞争性的半监督数据学习方法相比，并且在监督式分类模型的基础上进行了进一步的改进。<details>
<summary>Abstract</summary>
Automated semantic segmentation of cell nuclei in microscopic images is crucial for disease diagnosis and tissue microenvironment analysis. Nonetheless, this task presents challenges due to the complexity and heterogeneity of cells. While supervised deep learning methods are promising, they necessitate large annotated datasets that are time-consuming and error-prone to acquire. Semi-supervised approaches could provide feasible alternatives to this issue. However, the limited annotated data may lead to subpar performance of semi-supervised methods, regardless of the abundance of unlabeled data. In this paper, we introduce a novel unsupervised pre-training-based semi-supervised framework for cell-nuclei segmentation. Our framework is comprised of three main components. Firstly, we pretrain a diffusion model on a large-scale unlabeled dataset. The diffusion model's explicit modeling capability facilitates the learning of semantic feature representation from the unlabeled data. Secondly, we achieve semantic feature aggregation using a transformer-based decoder, where the pretrained diffusion model acts as the feature extractor, enabling us to fully utilize the small amount of labeled data. Finally, we implement a collaborative learning framework between the diffusion-based segmentation model and a supervised segmentation model to further enhance segmentation performance. Experiments were conducted on four publicly available datasets to demonstrate significant improvements compared to competitive semi-supervised segmentation methods and supervised baselines. A series of out-of-distribution tests further confirmed the generality of our framework. Furthermore, thorough ablation experiments and visual analysis confirmed the superiority of our proposed method.
</details>
<details>
<summary>摘要</summary>
自动化的细胞核 segmentation 在微scopic 图像中是致命的 для疾病诊断和组织微environment 分析。然而，这个任务存在复杂性和多样性的细胞问题。 Although supervised deep learning methods are promising, they require large annotated datasets that are time-consuming and error-prone to acquire. Semi-supervised approaches could provide feasible alternatives to this issue. However, the limited annotated data may lead to subpar performance of semi-supervised methods, regardless of the abundance of unlabeled data.In this paper, we introduce a novel unsupervised pre-training-based semi-supervised framework for cell-nuclei segmentation. Our framework consists of three main components. First, we pretrain a diffusion model on a large-scale unlabeled dataset. The diffusion model's explicit modeling capability facilitates the learning of semantic feature representation from the unlabeled data. Second, we achieve semantic feature aggregation using a transformer-based decoder, where the pretrained diffusion model acts as the feature extractor, enabling us to fully utilize the small amount of labeled data. Finally, we implement a collaborative learning framework between the diffusion-based segmentation model and a supervised segmentation model to further enhance segmentation performance. Experiments were conducted on four publicly available datasets to demonstrate significant improvements compared to competitive semi-supervised segmentation methods and supervised baselines. A series of out-of-distribution tests further confirmed the generality of our framework. Furthermore, thorough ablation experiments and visual analysis confirmed the superiority of our proposed method.
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis"><a href="#Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis" class="headerlink" title="Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis"></a>Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05123">http://arxiv.org/abs/2308.05123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhan Mo, Yao Chen, Aimee Readie, Gregory Ligozio, Thibaud Coroller, Bartłomiej W. Papież</li>
<li>for: 这个研究旨在开发一个自动评分pipeline，以便从骨盘X射线成像中自动预测 modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) 的分数。</li>
<li>methods: 这个pipeline使用了我们先前开发的 VU 抽出pipeline (VertXNet) 来生成 VU，然后使用这些 VU 作为输入，预测 mSASSS 分数。</li>
<li>results: 我们的结果显示，这个pipeline可以在有限量和不均匀的数据下预测每个 VU 的 mSASSS 分数。总体而言，它可以在两个试验数据集上 achieve 平均准确率为 0.56 和 0.51  для 4 个不同的 mSASSS 分数 (即分数为 0、1、2、3)。<details>
<summary>Abstract</summary>
Manually grading structural changes with the modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) on spinal X-ray imaging is costly and time-consuming due to bone shape complexity and image quality variations. In this study, we address this challenge by prototyping a 2-step auto-grading pipeline, called VertXGradeNet, to automatically predict mSASSS scores for the cervical and lumbar vertebral units (VUs) in X-ray spinal imaging. The VertXGradeNet utilizes VUs generated by our previously developed VU extraction pipeline (VertXNet) as input and predicts mSASSS based on those VUs. VertXGradeNet was evaluated on an in-house dataset of lateral cervical and lumbar X-ray images for axial spondylarthritis patients. Our results show that VertXGradeNet can predict the mSASSS score for each VU when the data is limited in quantity and imbalanced. Overall, it can achieve a balanced accuracy of 0.56 and 0.51 for 4 different mSASSS scores (i.e., a score of 0, 1, 2, 3) on two test datasets. The accuracy of the presented method shows the potential to streamline the spinal radiograph readings and therefore reduce the cost of future clinical trials.
</details>
<details>
<summary>摘要</summary>
人工评估结构变化使用修改Stoke Ankylosing Spondylitis Spinal Score（mSASSS）在脊椎X射线成像中是成本高和时间耗费大的，这是因为骨形态复杂和成像质量变化。在这项研究中，我们解决这个挑战，推出了一个两步自动评估管道，称为VertXGradeNet，可以自动预测脊椎X射线成像中mSASSS分数。VertXGradeNet使用我们之前开发的VU提取管道（VertXNet）生成的VU作为输入，并根据这些VU预测mSASSS分数。我们在医学实验室内的一个后退性cervical和肠脊椎X射线成像数据集上评估了VertXGradeNet。结果表明，VertXGradeNet可以在数据量有限、不均衡的情况下预测每个VU的mSASSS分数。总的来说，它可以在两个测试数据集上实现平衡性的准确率0.56和0.51，对四个不同的mSASSS分数（即分数为0、1、2、3）进行预测。提出的方法的准确率表明了将来的脊椎X射线成像读取可能会更加流畅，从而降低未来临床试验的成本。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/eess.IV_2023_08_09/" data-id="clpxp6caj018xee88f6p494xu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.SD_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T15:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.SD_2023_08_08/">cs.SD - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz"><a href="#Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz" class="headerlink" title="Towards an AI to Win Ghana’s National Science and Maths Quiz"></a>Towards an AI to Win Ghana’s National Science and Maths Quiz</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04333">http://arxiv.org/abs/2308.04333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nsmq-ai/nsmqai">https://github.com/nsmq-ai/nsmqai</a></li>
<li>paper_authors: George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah</li>
<li>for: The paper is written to explore the possibility of using AI to compete in Ghana’s National Science and Maths Quiz (NSMQ) and to describe the progress made so far in the NSMQ AI project.</li>
<li>methods: The paper uses open-source AI technology to build an AI system that can compete in the NSMQ, with a focus on speech-to-text, text-to-speech, question-answering, and human-computer interaction.</li>
<li>results: The paper describes the progress made thus far in the NSMQ AI project, including the development of an AI system that can compete in the NSMQ and the potential real-world impact of such a system on education in Africa.<details>
<summary>Abstract</summary>
Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win. The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction. In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023. An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI.
</details>
<details>
<summary>摘要</summary>
可以AI赢得加纳国家科学数学竞赛（NSMQ）呢？这是我们想要回答的问题，我们在NSMQ AI项目中进行开源项目，旨在使AI在NSMQ中赢得比赛。NSMQ是每年举行的live科学数学竞赛，参与者是加纳高中二年级学生，共有3支队伍，每支队伍有2名学生，通过Answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year。NSMQ是一个有趣的live竞赛，技术挑战包括speech-to-text、text-to-speech、问题回答和人机交互。在这项工作于2023年1月开始的项目中，我们将提供项目概述、团队描述、已经进展和下一步的计划，以便在10月份的NSMQ 2023上发布AI。一旦AI成功解决这个大型挑战，可能会对教育产生实际影响，如提供非洲数百万学生一对一的学习支持。
</details></li>
</ul>
<hr>
<h2 id="Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning"><a href="#Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning" class="headerlink" title="Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning"></a>Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04244">http://arxiv.org/abs/2308.04244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Chen, Changde Du, Qiongyi Zhou, Huiguang He</li>
<li>for: 这 paper 是为了解决 auditory attention 问题，即如何在多个视角下解码听力注意力。</li>
<li>methods: 这 paper 使用了 multi-view VAE 和 task-related multi-view contrastive (TMC) 学习来解码听力注意力。</li>
<li>results: 研究人员通过对 two 个 popular AAD 数据集进行测试，发现了我们的方法的优越性，并与现有的 state-of-the-art 方法进行比较。<details>
<summary>Abstract</summary>
The human brain can easily focus on one speaker and suppress others in scenarios such as a cocktail party. Recently, researchers found that auditory attention can be decoded from the electroencephalogram (EEG) data. However, most existing deep learning methods are difficult to use prior knowledge of different views (that is attended speech and EEG are task-related views) and extract an unsatisfactory representation. Inspired by Broadbent's filter model, we decode auditory attention in a multi-view paradigm and extract the most relevant and important information utilizing the missing view. Specifically, we propose an auditory attention decoding (AAD) method based on multi-view VAE with task-related multi-view contrastive (TMC) learning. Employing TMC learning in multi-view VAE can utilize the missing view to accumulate prior knowledge of different views into the fusion of representation, and extract the approximate task-related representation. We examine our method on two popular AAD datasets, and demonstrate the superiority of our method by comparing it to the state-of-the-art method.
</details>
<details>
<summary>摘要</summary>
人脑可以轻松地关注一个说话者并压抑其他说话者在cocktail party类场景中。现在，研究人员发现了基于电enzephalogram（EEG）数据的听力注意力可以被解码。然而，大多数现有的深度学习方法难以使用不同视图（即注意力和EEG数据是任务相关的视图）的先前知识，并提取不满足的表示。以布鲁门特 filters 模型为 inspirations，我们在多视图 paradigm 中解码听力注意力，并使用缺失的视图来汇集不同视图中的先前知识，并提取任务相关的表示。我们提出了基于多视图VAE的听力注意力解码方法（AAD），并使用任务相关的多视图异构学习（TMC）来学习。通过TMC学习，我们可以在多视图VAE中汇集不同视图中的先前知识，并提取任务相关的表示。我们在两个流行的AAD数据集上进行了实验，并证明了我们的方法的优越性，比较于状态的艺术方法。
</details></li>
</ul>
<hr>
<h2 id="Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack"><a href="#Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack" class="headerlink" title="Evil Operation: Breaking Speaker Recognition with PaddingBack"></a>Evil Operation: Breaking Speaker Recognition with PaddingBack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04179">http://arxiv.org/abs/2308.04179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Ye, Diqun Yan, Li Dong, Kailai Shen</li>
<li>For: The paper aims to propose a novel backdoor attack method that can bypass speaker recognition systems and remain undetectable to human ears.* Methods: The proposed method, called PaddingBack, exploits the widely used speech signal operation of padding to make poisoned samples indistinguishable from clean ones.* Results: The experimental results show that PaddingBack achieves a high attack success rate while maintaining a high rate of benign accuracy, and is able to resist defense methods while maintaining its stealthiness against human perception.Here’s the full text in Simplified Chinese:* For: 本研究提出的目的是提出一种可以绕过说话识别系统的背门附件攻击方法，并且能够避免人类听觉中的异常感。* Methods: 该方法称为PaddingBack，利用了广泛使用的语音信号操作padding，以制作恶意样本与净样本无法分辨。* Results: 实验结果显示，PaddingBack可以达到高度的攻击成功率，同时保持高度的净样本准确率，并且能够抵抗防御方法，同时保持人类听觉中的潜藏性。<details>
<summary>Abstract</summary>
Machine Learning as a Service (MLaaS) has gained popularity due to advancements in machine learning. However, untrusted third-party platforms have raised concerns about AI security, particularly in backdoor attacks. Recent research has shown that speech backdoors can utilize transformations as triggers, similar to image backdoors. However, human ears easily detect these transformations, leading to suspicion. In this paper, we introduce PaddingBack, an inaudible backdoor attack that utilizes malicious operations to make poisoned samples indistinguishable from clean ones. Instead of using external perturbations as triggers, we exploit the widely used speech signal operation, padding, to break speaker recognition systems. Our experimental results demonstrate the effectiveness of the proposed approach, achieving a significantly high attack success rate while maintaining a high rate of benign accuracy. Furthermore, PaddingBack demonstrates the ability to resist defense methods while maintaining its stealthiness against human perception. The results of the stealthiness experiment have been made available at https://nbufabio25.github.io/paddingback/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition"><a href="#MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition" class="headerlink" title="MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition"></a>MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04025">http://arxiv.org/abs/2308.04025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Pan</li>
<li>for: 本研究旨在探讨语音情感识别（SER）方法的可靠性，并研究如何从语音特征分布角度模型语音情感。</li>
<li>methods: 本研究提出了一种基于Convolutional Neural Networks（CNN）的SER模型，采用添加margin软max损失函数以提高类别之间的距离，从而提高分类的准确性。此外，还提出了一种多种语音特征控制方法（MSAC），可以控制语音特征，使模型更加敏感于情感相关特征。</li>
<li>results: 对于单个 corpora 和跨 corpora SER 场景，我们的提议的 SER 工作流程经过了广泛的实验，并 consistently 超过基准值，包括认知、泛化和可靠性性能。单个 corpora SER 场景中，我们的 SER 工作流程达到了72.97%的 WAR 和 71.76%的 UAR 在 IEMOCAP  corpora 上。<details>
<summary>Abstract</summary>
Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97\% and a UAR of 71.76\% on the IEMOCAP corpus.
</details>
<details>
<summary>摘要</summary>
尽管已经取得了 significative 进步，speech emotion recognition（SER）仍然是一项复杂和不确定的任务，尤其在野外环境中。现有研究主要关注recognition和泛化能力，而这项工作则尝试了 SER 方法的可靠性的探索，并 investigate 如何从数据分布角度模型 speech emotion。 Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97% and a UAR of 71.76% on the IEMOCAP corpus.
</details></li>
</ul>
<hr>
<h2 id="Target-Speech-Extraction-with-Conditional-Diffusion-Model"><a href="#Target-Speech-Extraction-with-Conditional-Diffusion-Model" class="headerlink" title="Target Speech Extraction with Conditional Diffusion Model"></a>Target Speech Extraction with Conditional Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03987">http://arxiv.org/abs/2308.03987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoyuki Kamo, Marc Delcroix, Tomohiro Nakatani</li>
<li>for:  targets speech extraction (TSE) in a mixture of multi-talkers</li>
<li>methods:  uses a conditional diffusion model conditioned on a clue identifying the target speaker, and ensemble inference to reduce potential extraction errors</li>
<li>results:  outperforms a comparable TSE system trained discriminatively in experiments on Libri2mix corpus<details>
<summary>Abstract</summary>
Diffusion model-based speech enhancement has received increased attention since it can generate very natural enhanced signals and generalizes well to unseen conditions. Diffusion models have been explored for several sub-tasks of speech enhancement, such as speech denoising, dereverberation, and source separation. In this paper, we investigate their use for target speech extraction (TSE), which consists of estimating the clean speech signal of a target speaker in a mixture of multi-talkers. TSE is realized by conditioning the extraction process on a clue identifying the target speaker. We show we can realize TSE using a conditional diffusion model conditioned on the clue. Besides, we introduce ensemble inference to reduce potential extraction errors caused by the diffusion process. In experiments on Libri2mix corpus, we show that the proposed diffusion model-based TSE combined with ensemble inference outperforms a comparable TSE system trained discriminatively.
</details>
<details>
<summary>摘要</summary>
听说模型基于扩散模型的speech增强技术在最近几年来得到了更多的关注，因为它可以生成非常自然的增强信号，并且可以在未见过的条件下进行泛化。扩散模型在多个子任务中被探索，如speech噪声除去、泛化声学环境和音源分离。在这篇论文中，我们研究了它们在target speech extraction（TSE）中的使用，TSE是一种估计混合多个说话人的干扰者的清晰speech信号的过程。我们表明可以通过对 clue（指定target speaker）进行条件的扩散模型来实现TSE。此外，我们还引入了集成推理来降低扩散过程中的潜在出错。在Libri2mix数据集上进行了实验，我们发现提出的扩散模型基于TSE，并且集成推理可以与一个相对的TSE系统所得到的性能进行比较。
</details></li>
</ul>
<hr>
<h2 id="Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet"><a href="#Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet" class="headerlink" title="Universal Automatic Phonetic Transcription into the International Phonetic Alphabet"></a>Universal Automatic Phonetic Transcription into the International Phonetic Alphabet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03917">http://arxiv.org/abs/2308.03917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctaguchi/multipa">https://github.com/ctaguchi/multipa</a></li>
<li>paper_authors: Chihiro Taguchi, Yusuke Sakai, Parisa Haghani, David Chiang</li>
<li>for: 这个论文旨在提供一种可以转化任何语言的语音到国际音律字母（IPA）的状态对模型。</li>
<li>methods: 该模型基于wav2vec 2.0，并通过 semi-自动地对CommonVoice 11.0中的七种语言的语音进行了训练，以便预测IPA。</li>
<li>results: 我们的模型可以达到与人工标注师相当的质量水平，并且与之前的最佳语音到IPA模型（Wav2Vec2Phoneme）相比，我们的模型在训练数据量相对较少的情况下可以达到类似或更好的结果。<details>
<summary>Abstract</summary>
This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种现代模型，用于将任何语言的 spoken language 转录为国际音声字母（IPA）。将语言记录转录为 IPA 是一项重要但是时间占用很大的任务，即使只是部分自动化这个过程，也有很大的潜在速度提升语言记录的批处。与之前的最佳音频-to-IPA 模型（Wav2Vec2Phoneme）一样，我们的模型基于 wav2vec 2.0，并在音频输入上进行了微调，以预测 IPA。我们使用了 CommonVoice 11.0 中的七种语言的训练数据，并将其 semi-automatically 转录为 IPA。虽然我们的训练集规模较小，但它的质量更高，使我们的模型在获得相似或更好的结果。此外，我们还证明了我们的通用音频-to-IPA 模型的质量与人工注释员很相似。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.SD_2023_08_08/" data-id="clpxp6c6600xoee880kw6hj2v" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/eess.AS_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T14:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/eess.AS_2023_08_08/">eess.AS - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech"><a href="#Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech" class="headerlink" title="Investigating Speaker Embedding Disentanglement on Natural Read Speech"></a>Investigating Speaker Embedding Disentanglement on Natural Read Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04225">http://arxiv.org/abs/2308.04225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach</li>
<li>for: 这个论文的目的是研究语音表示的分解，以提高数据驱动模型的普适性、解释性和公正性。</li>
<li>methods: 该论文使用了标准的分解目标函数来训练语音表示，并对比了这些表示的分解程度。</li>
<li>results: 研究发现，使用标准的分解目标函数可以限制语音表示的分解程度，但可以通过一定程度的改进来提高分解效果。<details>
<summary>Abstract</summary>
Disentanglement is the task of learning representations that identify and separate factors that explain the variation observed in data. Disentangled representations are useful to increase the generalizability, explainability, and fairness of data-driven models. Only little is known about how well such disentanglement works for speech representations. A major challenge when tackling disentanglement for speech representations are the unknown generative factors underlying the speech signal. In this work, we investigate to what degree speech representations encoding speaker identity can be disentangled. To quantify disentanglement, we identify acoustic features that are highly speaker-variant and can serve as proxies for the factors of variation underlying speech. We find that disentanglement of the speaker embedding is limited when trained with standard objectives promoting disentanglement but can be improved over vanilla representation learning to some extent.
</details>
<details>
<summary>摘要</summary>
<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，尚不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>Here's the translation in Traditional Chinese as well:<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，还不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 这 paper 是为了解决 audio-guided video object segmentation (A-VOS) 和 referring video object segmentation (R-VOS) 等两个高度相关的任务。</li>
<li>methods: 这 paper 使用了一种 universal architecture called Expression Prompt Collaboration Transformer (EPCFormer)，并提出了一种 Expression Alignment (EA) 机制和一种 Expression-Visual Attention (EVA) 机制来解决模式表示问题。</li>
<li>results: 实验结果表明，EPCFormer 可以在 A-VOS 和 R-VOS 两个任务上达到州际级Result。此外，EPCFormer 可以快速转移知识 между两个任务，从而提高视频对象 segmentation 的精度。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
audio-guided视频对象 segmentation (A-VOS) 和 referring视频对象 segmentation (R-VOS) 是两个非常相关的任务，它们都是根据用户提供的表达提示从视频序列中提取特定对象的。然而，由于不同媒体表示的模型化问题，当前方法很难协调用用户提供的表达提示和高精度的地方化分割。在这篇论文中，我们解决这个问题从两个方面：表达提示的对齐表示和听力和文本特征之间的深度交互。首先，我们提出了一种通用架构，即表达 prompt collaboration transformer（EPCFormer）。然后，我们提出了一种表达对齐（EA）机制，用于对听力和文本表达进行对齐。通过对听力和文本表达进行对比学习，我们的提出的EPCFormer实现了对听力和文本表达的semantic equivalence的认知。然后，为了促进听力、文本和视频特征之间的深度交互，我们引入了表达-视频注意力（EVA）机制。通过深入探索听力、文本和视频特征之间的相互补做，我们的EPCFormer可以很好地传递知识 между两个任务。实验结果表明，我们的通用EPCFormer在两个任务上达到了现有最佳结果。代码将在https://github.com/lab206/EPCFormer上公开。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/eess.AS_2023_08_08/" data-id="clpxp6c8p0149ee88fvqo1qsz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.CV_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T13:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.CV_2023_08_08/">cs.CV - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="3D-VisTA-Pre-trained-Transformer-for-3D-Vision-and-Text-Alignment"><a href="#3D-VisTA-Pre-trained-Transformer-for-3D-Vision-and-Text-Alignment" class="headerlink" title="3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment"></a>3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04352">http://arxiv.org/abs/2308.04352</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/3d-vista/3D-VisTA">https://github.com/3d-vista/3D-VisTA</a></li>
<li>paper_authors: Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, Qing Li</li>
<li>for: 3D vision-language grounding (3D-VL) tasks, such as visual grounding, dense captioning, question answering, and situated reasoning.</li>
<li>methods: Uses a pre-trained Transformer for 3D vision and text alignment, with self-attention layers for single-modal modeling and multi-modal fusion.</li>
<li>results: Achieves state-of-the-art results on various 3D-VL tasks, with superior data efficiency and strong performance even with limited annotations during fine-tuning.Here’s the simplified Chinese text:</li>
<li>for: 3D视力语言固定（3D-VL）任务，如视图固定、密集描述、问答和位置理解。</li>
<li>methods: 使用预训练的 transformer  для 3D视力和文本对齐，通过自我注意层实现单模态模型和多模态融合。</li>
<li>results: 在多种 3D-VL 任务上取得了状态之一的结果，并且在限制缺少标注时的练习 fine-tuning 中表现出色。<details>
<summary>Abstract</summary>
3D vision-language grounding (3D-VL) is an emerging field that aims to connect the 3D physical world with natural language, which is crucial for achieving embodied intelligence. Current 3D-VL models rely heavily on sophisticated modules, auxiliary losses, and optimization tricks, which calls for a simple and unified model. In this paper, we propose 3D-VisTA, a pre-trained Transformer for 3D Vision and Text Alignment that can be easily adapted to various downstream tasks. 3D-VisTA simply utilizes self-attention layers for both single-modal modeling and multi-modal fusion without any sophisticated task-specific design. To further enhance its performance on 3D-VL tasks, we construct ScanScribe, the first large-scale 3D scene-text pairs dataset for 3D-VL pre-training. ScanScribe contains 2,995 RGB-D scans for 1,185 unique indoor scenes originating from ScanNet and 3R-Scan datasets, along with paired 278K scene descriptions generated from existing 3D-VL tasks, templates, and GPT-3. 3D-VisTA is pre-trained on ScanScribe via masked language/object modeling and scene-text matching. It achieves state-of-the-art results on various 3D-VL tasks, ranging from visual grounding and dense captioning to question answering and situated reasoning. Moreover, 3D-VisTA demonstrates superior data efficiency, obtaining strong performance even with limited annotations during downstream task fine-tuning.
</details>
<details>
<summary>摘要</summary>
三维视力语言固定（3D-VL）是一个emerging领域，旨在将三维物理世界与自然语言相连接，这对实体智能是非常重要。现有3D-VL模型都依赖于复杂的模块、辅助损失和优化技巧，这зыва�种简单的和一致的模型。在这篇论文中，我们提出了3D-VisTA，一个预训练的Transformer用于三维视力和文本对齐。3D-VisTA使用自注意层来模型单Modal和多Modal的混合，不需任何任务特定的复杂设计。为了进一步提高3D-VL任务的表现，我们构建了ScanScribe，这是第一个大规模的3D场景文本对 dataset，包括2995个RGB-D扫描和1185个唯一的室内场景，来自ScanNet和3R-Scan dataset，以及278K个场景描述，这些描述来自现有的3D-VL任务、模板和GPT-3。3D-VisTA在ScanScribe上预训练后，可以通过偏挥语言/物体模型和场景文本匹配来进行Masked Language/Object Modeling和Scene-Text Matching。它在多种3D-VL任务上达到了状态前的Result，从visual grounding和精密描述到问题回答和位置理解。此外，3D-VisTA还表现出了优秀的数据效率，能够在下游任务练习时就具有强的表现，即使有限的注释。
</details></li>
</ul>
<hr>
<h2 id="Unifying-Two-Stream-Encoders-with-Transformers-for-Cross-Modal-Retrieval"><a href="#Unifying-Two-Stream-Encoders-with-Transformers-for-Cross-Modal-Retrieval" class="headerlink" title="Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval"></a>Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04343">http://arxiv.org/abs/2308.04343</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luminosityx/hat">https://github.com/luminosityx/hat</a></li>
<li>paper_authors: Yi Bin, Haoxuan Li, Yahui Xu, Xing Xu, Yang Yang, Heng Tao Shen</li>
<li>for: 提高跨模态检索的性能，具体来说是提高图像和文本之间的匹配和相关性。</li>
<li>methods: 使用两�reamTransformers作为图像和文本的Encoder，并实现层次对应模块以探索不同层次的多重对应关系。</li>
<li>results: 对两个基准数据集MSCOCO和Flickr30K进行了广泛的实验，并与SOTA基线相比，HAT得到了大量的提升。具体来说，在图像到文本和文本到图像检索两个关键任务上，HAT的Recall@1提高了7.6%和16.7%在MSCOCO上，以及4.4%和11.6%在Flickr30K上。<details>
<summary>Abstract</summary>
Most existing cross-modal retrieval methods employ two-stream encoders with different architectures for images and texts, \textit{e.g.}, CNN for images and RNN/Transformer for texts. Such discrepancy in architectures may induce different semantic distribution spaces and limit the interactions between images and texts, and further result in inferior alignment between images and texts. To fill this research gap, inspired by recent advances of Transformers in vision tasks, we propose to unify the encoder architectures with Transformers for both modalities. Specifically, we design a cross-modal retrieval framework purely based on two-stream Transformers, dubbed \textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image Transformer, a text Transformer, and a hierarchical alignment module. With such identical architectures, the encoders could produce representations with more similar characteristics for images and texts, and make the interactions and alignments between them much easier. Besides, to leverage the rich semantics, we devise a hierarchical alignment scheme to explore multi-level correspondences of different layers between images and texts. To evaluate the effectiveness of the proposed HAT, we conduct extensive experiments on two benchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that HAT outperforms SOTA baselines by a large margin. Specifically, on two key tasks, \textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves 7.6\% and 16.7\% relative score improvement of Recall@1 on MSCOCO, and 4.4\% and 11.6\% on Flickr30k respectively. The code is available at \url{https://github.com/LuminosityX/HAT}.
</details>
<details>
<summary>摘要</summary>
现有跨Modal Retrieval方法通常采用不同架构的两�ream Encoder，如图像使用CNN，文本使用RNN/Transformer。这种不同的架构可能会导致图像和文本的Semantic分布空间不同，限制图像和文本之间的交互，从而导致图像和文本的Alignment不佳。为了填补这个研究空白，我们提出了一种基于Transformers的跨Modal Retrieval框架，名为层次对齐Transformers（HAT）。这个框架包括图像Transformer、文本Transformer和层次对齐模块。通过使用同一种架构，encoder可以生成更像性的表示，从而使图像和文本之间的交互和对齐变得更加容易。此外，为了利用rich的Semantic，我们设计了一种层次对齐方案，以探索不同层次的对应关系 между图像和文本。为证明HAT的效iveness，我们对MSCOCO和Flickr30K两个benchmark datasets进行了广泛的实验。实验结果表明，HAT在图像-文本和文本-图像检索任务上的表现都超过了State-of-the-Art baseline，具体来说，在MSCOCO上，HAT在图像-文本和文本-图像检索任务上的Recall@1相对于基eline的提高为7.6%和16.7%。在Flickr30K上，HAT的提高为4.4%和11.6%。代码可以在github上找到：https://github.com/LuminosityX/HAT。
</details></li>
</ul>
<hr>
<h2 id="TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation"><a href="#TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation" class="headerlink" title="TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation"></a>TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10843">http://arxiv.org/abs/2308.10843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mireille Fares, Catherine Pelachaud, Nicolas Obin</li>
<li>for: 这篇论文目的是将虚拟代表人物的行为表达风格传递到另一个代表人物中，保留行为的形式，以便在交流中传递意义。</li>
<li>methods: 我们提出了一种基于多模态变换器的模型，称为TranSTYLer，可以将多 modal 的行为合成到源说话者的样式下。我们假设行为表达风格在不同的沟通方式中都有编码，包括文本、语音、身体姿势和脸部表情。我们使用内容和风格分离的方法，以确保传递的风格不会干扰源行为的意义。</li>
<li>results: 我们使用PATS corpus进行训练，并对其进行扩展以包括对话活动和2D脸部特征点。对象和主观评价表明，我们的模型在训练阶段seen和unseen风格时都能够超越状态之前的模型。为了解决可能出现的风格和内容泄露问题，我们提出了一种方法来评估传递的行为和姿势是否成功地采用了target风格，而不会破坏源内容的意义。<details>
<summary>Abstract</summary>
This paper addresses the challenge of transferring the behavior expressivity style of a virtual agent to another one while preserving behaviors shape as they carry communicative meaning. Behavior expressivity style is viewed here as the qualitative properties of behaviors. We propose TranSTYLer, a multimodal transformer based model that synthesizes the multimodal behaviors of a source speaker with the style of a target speaker. We assume that behavior expressivity style is encoded across various modalities of communication, including text, speech, body gestures, and facial expressions. The model employs a style and content disentanglement schema to ensure that the transferred style does not interfere with the meaning conveyed by the source behaviors. Our approach eliminates the need for style labels and allows the generalization to styles that have not been seen during the training phase. We train our model on the PATS corpus, which we extended to include dialog acts and 2D facial landmarks. Objective and subjective evaluations show that our model outperforms state of the art models in style transfer for both seen and unseen styles during training. To tackle the issues of style and content leakage that may arise, we propose a methodology to assess the degree to which behavior and gestures associated with the target style are successfully transferred, while ensuring the preservation of the ones related to the source content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Domain-Adaptive-Person-Search-via-GAN-based-Scene-Synthesis-for-Cross-scene-Videos"><a href="#Domain-Adaptive-Person-Search-via-GAN-based-Scene-Synthesis-for-Cross-scene-Videos" class="headerlink" title="Domain Adaptive Person Search via GAN-based Scene Synthesis for Cross-scene Videos"></a>Domain Adaptive Person Search via GAN-based Scene Synthesis for Cross-scene Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04322">http://arxiv.org/abs/2308.04322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crsm424/da-gss">https://github.com/crsm424/da-gss</a></li>
<li>paper_authors: Huibing Wang, Tianxiang Cui, Mingze Yao, Huijuan Pang, Yushan Du</li>
<li>for: 提高人体搜索任务中的精度和效率，使用生成 adversarial networks (GAN) 生成高质量的人体图像数据。</li>
<li>methods: 基于 Fast R-CNN 模型，采用 Assisted-Identity Query Module (AIDQ) 提供正面图像，并采用 GAN 生成高质量的人体图像数据进行场景合成。采用在线学习策略，同步学习生成的图像和原始图像，以便增强特征学习。</li>
<li>results: 在 CUHK-SYSU 和 PRW 两个人体搜索标准benchmark上进行了广泛的实验，并取得了优秀的性能。并进行了详细的减少性能研究，证明 GAN 生成的数据可以增加数据的多样性和真实性。<details>
<summary>Abstract</summary>
Person search has recently been a challenging task in the computer vision domain, which aims to search specific pedestrians from real cameras.Nevertheless, most surveillance videos comprise only a handful of images of each pedestrian, which often feature identical backgrounds and clothing. Hence, it is difficult to learn more discriminative features for person search in real scenes. To tackle this challenge, we draw on Generative Adversarial Networks (GAN) to synthesize data from surveillance videos. GAN has thrived in computer vision problems because it produces high-quality images efficiently. We merely alter the popular Fast R-CNN model, which is capable of processing videos and yielding accurate detection outcomes. In order to appropriately relieve the pressure brought by the two-stage model, we design an Assisted-Identity Query Module (AIDQ) to provide positive images for the behind part. Besides, the proposed novel GAN-based Scene Synthesis model that can synthesize high-quality cross-id person images for person search tasks. In order to facilitate the feature learning of the GAN-based Scene Synthesis model, we adopt an online learning strategy that collaboratively learns the synthesized images and original images. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method has achieved great performance, and the extensive ablation study further justifies our GAN-synthetic data can effectively increase the variability of the datasets and be more realistic.
</details>
<details>
<summary>摘要</summary>
人体搜索是计算机视觉领域中的一个长期挑战，目标是从真实的摄像头中搜索特定的步行人。然而，大多数surveillance视频中只包含每个步行人的几张图像，这些图像通常具有相同的背景和服装。因此，学习更加特异的人体特征变得困难。为解决这个问题，我们引入生成 adversarial networks（GAN）来生成数据集。GAN在计算机视觉问题中取得了成功，因为它可以生成高质量的图像。我们只是修改了popular Fast R-CNN模型，这种模型可以处理视频并提供准确的检测结果。为了正确地减轻两个阶段模型中的压力，我们设计了一个帮助查询模块（AIDQ），以提供后部图像的正面图像。此外，我们还提出了一种新的基于GAN的Scene Synthesis模型，可以生成高质量的跨ID人体图像 для人体搜索任务。为了促进GAN-based Scene Synthesis模型的特征学习，我们采用了在线学习策略，将合作学习生成的图像和原始图像。广泛的实验表明，我们的方法在两个常用的人体搜索标准 benchmarck上表现出色，并且extensive ablation study further justify我们的GAN-synthetic数据可以增加数据集的变化性和更加真实。
</details></li>
</ul>
<hr>
<h2 id="All-pairs-Consistency-Learning-for-Weakly-Supervised-Semantic-Segmentation"><a href="#All-pairs-Consistency-Learning-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation"></a>All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04321">http://arxiv.org/abs/2308.04321</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixuan Sun, Yanhao Zhang, Zhen Qin, Zheyuan Liu, Lin Cheng, Fanyi Wang, Yiran Zhong, Nick Barnes</li>
<li>for: 提高弱级 semantic segmentation（WSSS）中对象的本地化。</li>
<li>methods: 使用 transformer 基于的常见化regularization，包括 consistency regularization 和 all-pairs consistency regularization（ACR）。</li>
<li>results: 在 PASCAL VOC 和 MS COCO 数据集上实现了更好的类本地化图（67.3% mIoU on PASCAL VOC train），从而提高 WSSS 性能。<details>
<summary>Abstract</summary>
In this work, we propose a new transformer-based regularization to better localize objects for Weakly supervised semantic segmentation (WSSS). In image-level WSSS, Class Activation Map (CAM) is adopted to generate object localization as pseudo segmentation labels. To address the partial activation issue of the CAMs, consistency regularization is employed to maintain activation intensity invariance across various image augmentations. However, such methods ignore pair-wise relations among regions within each CAM, which capture context and should also be invariant across image views. To this end, we propose a new all-pairs consistency regularization (ACR). Given a pair of augmented views, our approach regularizes the activation intensities between a pair of augmented views, while also ensuring that the affinity across regions within each view remains consistent. We adopt vision transformers as the self-attention mechanism naturally embeds pair-wise affinity. This enables us to simply regularize the distance between the attention matrices of augmented image pairs. Additionally, we introduce a novel class-wise localization method that leverages the gradients of the class token. Our method can be seamlessly integrated into existing WSSS methods using transformers without modifying the architectures. We evaluate our method on PASCAL VOC and MS COCO datasets. Our method produces noticeably better class localization maps (67.3% mIoU on PASCAL VOC train), resulting in superior WSSS performances.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种基于转换器的新的常规化方法，以改进弱元素概率semantic segmentation（WSSS）中对 объек的本地化。在图像级WSSS中，使用Class Activation Map（CAM）生成对象本地化，但CAM的部分活动问题导致consistency regularization不具备对图像增强的抗锯齿性。我们的方法忽略了每个CAM中的对region之间的关系，这些关系捕捉了上下文信息，并且应该是图像视图不变的。为此，我们提出了一种新的所有对之间一致常规化（ACR）。给定两个扩展视图，我们的方法对扩展视图中的活动强度进行规范，同时确保每个视图中的区域之间的相互关系保持一致。我们采用了转换器作为自我注意力机制，这使得我们可以简单地规范扩展视图之间的距离。此外，我们还提出了一种新的类型本地化方法，该方法利用类token的梯度来优化类本地化。我们的方法可以轻松地与现有的WSSS方法集成，无需修改架构。我们在PASCAL VOC和MS COCO数据集上进行了评估，我们的方法在PASCAL VOC训练集上得到了67.3%的mean Intersection over Union（mIoU），这表明我们的方法可以提供更好的类本地化图像。
</details></li>
</ul>
<hr>
<h2 id="Cloth2Tex-A-Customized-Cloth-Texture-Generation-Pipeline-for-3D-Virtual-Try-On"><a href="#Cloth2Tex-A-Customized-Cloth-Texture-Generation-Pipeline-for-3D-Virtual-Try-On" class="headerlink" title="Cloth2Tex: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On"></a>Cloth2Tex: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04288">http://arxiv.org/abs/2308.04288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daiheng Gao, Xu Chen, Xindi Zhang, Qi Wang, Ke Sun, Bang Zhang, Liefeng Bo, Qixing Huang</li>
<li>for: 这篇论文旨在提供一种自然语言处理方法，以便自动生成高质量的3D衣物文字图像，以满足3D虚拟试穿、数字化2D服装到3D服装和布料动画等应用需求。</li>
<li>methods: 该方法基于自我超级vised学习，通过对2D参考图像进行扩散学习，生成高质量的 texture maps，并且可以支持高精度的 texture inpainting。</li>
<li>results: 作者通过质量和量化评估，证明了 Cloth2Tex 可以生成高质量的 texture maps，并且在视觉效果上超过其他方法。<details>
<summary>Abstract</summary>
Fabricating and designing 3D garments has become extremely demanding with the increasing need for synthesizing realistic dressed persons for a variety of applications, e.g. 3D virtual try-on, digitalization of 2D clothes into 3D apparel, and cloth animation. It thus necessitates a simple and straightforward pipeline to obtain high-quality texture from simple input, such as 2D reference images. Since traditional warping-based texture generation methods require a significant number of control points to be manually selected for each type of garment, which can be a time-consuming and tedious process. We propose a novel method, called Cloth2Tex, which eliminates the human burden in this process. Cloth2Tex is a self-supervised method that generates texture maps with reasonable layout and structural consistency. Another key feature of Cloth2Tex is that it can be used to support high-fidelity texture inpainting. This is done by combining Cloth2Tex with a prevailing latent diffusion model. We evaluate our approach both qualitatively and quantitatively and demonstrate that Cloth2Tex can generate high-quality texture maps and achieve the best visual effects in comparison to other methods. Project page: tomguluson92.github.io/projects/cloth2tex/
</details>
<details>
<summary>摘要</summary>
制备和设计3D衣服已经变得极其需求量，因为需要生成真实的穿着人形进行多种应用，如3D虚拟试穿、2D衣服数字化到3D服装和布料动画。因此需要一个简单和直观的管道来获得高质量的纹理，从简单的输入中，如2D参考图像。传统的折叠基于的纹理生成方法需要手动选择大量的控制点，这可以是一个时间consuming和繁琐的过程。我们提议一种新的方法，called Cloth2Tex，它消除了人类的劳动在这个过程中。Cloth2Tex是一种自动学习的方法，可以生成纹理图片，并且具有合理的布局和结构一致性。另外，Cloth2Tex还可以支持高精度的纹理填充。我们通过质量和量化的评估，证明Cloth2Tex可以生成高质量的纹理图片，并且在比较其他方法时，可以 achieve the best visual effects。项目页面：tomguluson92.github.io/projects/cloth2tex/
</details></li>
</ul>
<hr>
<h2 id="Vision-Based-Autonomous-Navigation-for-Unmanned-Surface-Vessel-in-Extreme-Marine-Conditions"><a href="#Vision-Based-Autonomous-Navigation-for-Unmanned-Surface-Vessel-in-Extreme-Marine-Conditions" class="headerlink" title="Vision-Based Autonomous Navigation for Unmanned Surface Vessel in Extreme Marine Conditions"></a>Vision-Based Autonomous Navigation for Unmanned Surface Vessel in Extreme Marine Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04283">http://arxiv.org/abs/2308.04283</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/muhayyuddin/visual-servoing">https://github.com/muhayyuddin/visual-servoing</a></li>
<li>paper_authors: Muhayyuddin Ahmed, Ahsan Baidar Bakht, Taimur Hassan, Waseem Akram, Ahmed Humais, Lakmal Seneviratne, Shaoming He, Defu Lin, Irfan Hussain</li>
<li>for: 本研究旨在提高自主水面船（USV）的视觉 Navigation 性能，特别是在自动检查和跟踪任务中。</li>
<li>methods: 该研究提出了一种基于生成对抗网络（GAN）的自主视觉导航框架，用于在极端海洋环境中跟踪目标对象。该框架包括一个整合的感知管道，通过GAN将噪音除去并高亮目标特征，然后将这些感知特征传递给YOLOv5对象检测器。</li>
<li>results: 对比state-of-the-art净气化方法，该提案在MBZIRC simulate dataset上表现出了明显的优异性能，包括各种指标上的比较优异性能。<details>
<summary>Abstract</summary>
Visual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking. These tasks involve vision-based navigation techniques to identify the target for navigation. Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly. To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions. The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5). The detected visual features are then used by the USV to track the target. The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog. The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified ChineseVisual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking. These tasks involve vision-based navigation techniques to identify the target for navigation. Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly. To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions. The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5). The detected visual features are then used by the USV to track the target. The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog. The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics.<</SYS>>Here's the translation in Simplified Chinese:视觉认知是自动航行无人水面船（USV）中重要的一部分，尤其是在自动检查和跟踪任务中。这些任务需要基于视觉导航技术来确定目标。 marine 环境中的极端天气条件会使视觉基于的方法难以正常工作。为解决这些问题，本文提出了一个基于视觉的自动导航框架，用于在极端海洋条件下跟踪目标对象。该框架包括一个集成的识别管道，使用生成对抗网络（GAN）来消除噪声并强调对象特征，然后将这些特征传递给对象检测器（YOLOv5）进行检测。检测到的视觉特征然后被用于跟踪目标。本框架在基于 MBZIRC 的 simulate 环境下进行了严格的测试，并与现有的抑霾方法进行了比较。结果表明，提出的方案在各种维度上都有出众的表现。
</details></li>
</ul>
<hr>
<h2 id="SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction"><a href="#SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction" class="headerlink" title="SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction"></a>SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04262">http://arxiv.org/abs/2308.04262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer">https://github.com/rahul-gs-16/sdlformer</a></li>
<li>paper_authors: Rahul G. S., Sriprabha Ramnarayanan, Mohammad Al Fahim, Keerthi Ram, Preejith S. P, Mohanasankar Sivaprakasam</li>
<li>for: 这个论文目的是提出一种基于窗口变换器的加速MRI图像重建方法，以提高MRI图像重建的效率和质量。</li>
<li>methods: 该方法使用窗口变换器网络，并 integrate了扩大注意力机制和卷积Operation来提高图像之间的非本地关系，以及学习低级翻译不变的特征。</li>
<li>results: 对多核磁共振图像加速的实验结果显示，该方法可以与其他重建建筑物相比，提高PSNR和SSIM指标的值。 Code可以在<a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer.git%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/rahul-gs-16/sdlformer.git中找到。</a><details>
<summary>Abstract</summary>
Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. The proposed model is trained in a self-supervised manner. We perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. We compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. Results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. The code is available at https://github.com/rahul-gs-16/sdlformer.git
</details>
<details>
<summary>摘要</summary>
transformers 已经成为了 convolutional neural networks 的可行的替代方案，因为它们可以学习图像空间中的非本地区域关系。transformers 中的自注意机制使得 transformers 可以捕捉图像中的长距离依赖关系，这可能是加速 MRI 图像重建的潜在的优点，因为 MRI 图像下折衔的效果是非本地的。 despite its computational efficiency, window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. we propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. the proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. the proposed model is trained in a self-supervised manner. we perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. we compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. the code is available at https://github.com/rahul-gs-16/sdlformer.git.
</details></li>
</ul>
<hr>
<h2 id="Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras"><a href="#Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras" class="headerlink" title="Blur aware metric depth estimation with multi-focus plenoptic cameras"></a>Blur aware metric depth estimation with multi-focus plenoptic cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04252">http://arxiv.org/abs/2308.04252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/comsee-research/blade">https://github.com/comsee-research/blade</a></li>
<li>paper_authors: Mathieu Labussière, Céline Teulière, Omar Ait-Aider</li>
<li>for: 这个论文的主要目标是提出一种基于raw图像的多重焦距束镜相机的 metric depth estimation算法，以提高不同焦距的匹配和束缚信息的拟合。</li>
<li>methods: 该方法利用了不同焦距的图像捕捉，并通过缓冲信息来提高匹配和束缚信息的拟合。具体来说，该方法首先计算了图像的缓冲信息，然后利用了这些缓冲信息来提高匹配和束缚信息的拟合。</li>
<li>results: 实验结果表明，引入了焦距缓冲信息可以提高depth estimation的准确性和精度。该方法在实验中对实际的3D复杂场景进行了验证，并与3D激光扫描仪获取的实际测量数据进行了比较。<details>
<summary>Abstract</summary>
While a traditional camera only captures one point of view of a scene, a plenoptic or light-field camera, is able to capture spatial and angular information in a single snapshot, enabling depth estimation from a single acquisition. In this paper, we present a new metric depth estimation algorithm using only raw images from a multi-focus plenoptic camera. The proposed approach is especially suited for the multi-focus configuration where several micro-lenses with different focal lengths are used. The main goal of our blur aware depth estimation (BLADE) approach is to improve disparity estimation for defocus stereo images by integrating both correspondence and defocus cues. We thus leverage blur information where it was previously considered a drawback. We explicitly derive an inverse projection model including the defocus blur providing depth estimates up to a scale factor. A method to calibrate the inverse model is then proposed. We thus take into account depth scaling to achieve precise and accurate metric depth estimates. Our results show that introducing defocus cues improves the depth estimation. We demonstrate the effectiveness of our framework and depth scaling calibration on relative depth estimation setups and on real-world 3D complex scenes with ground truth acquired with a 3D lidar scanner.
</details>
<details>
<summary>摘要</summary>
tradicional 摄像机只能捕捉一个场景的一点视角，而 plenoptic 或 light-field 摄像机则能够在单个拍摄中捕捉场景的空间和角度信息，从而实现深度估计从单个获得。在这篇论文中，我们提出了一种基于原始图像的新的深度估计算法，使用多重ocus plenoptic 摄像机获得的Raw图像。我们的方法尤其适用于多重ocus配置，其中多个微镜头具有不同的 фокус距离。我们的方法的主要目标是通过结合匹配和杂谱诱导来提高不同损失的 disparity 估计。我们利用了模糊信息，而前面它被视为一个缺点。我们明确地 derivation 一个逆 проекции模型，包括杂谱模糊，以获得深度估计。然后，我们提出了一种准确做出深度缩放准确的方法。我们的结果表明，将杂谱诱导包含在深度估计中可以提高深度估计的精度。我们在相对深度估计设置和实际世界3D复杂场景中使用了真实的3D激光扫描仪获得的ground truth进行证明。
</details></li>
</ul>
<hr>
<h2 id="AICSD-Adaptive-Inter-Class-Similarity-Distillation-for-Semantic-Segmentation"><a href="#AICSD-Adaptive-Inter-Class-Similarity-Distillation-for-Semantic-Segmentation" class="headerlink" title="AICSD: Adaptive Inter-Class Similarity Distillation for Semantic Segmentation"></a>AICSD: Adaptive Inter-Class Similarity Distillation for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04243">http://arxiv.org/abs/2308.04243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amirmansurian/aicsd">https://github.com/amirmansurian/aicsd</a></li>
<li>paper_authors: Amir M. Mansourian, Rozhan Ahmadi, Shohreh Kasaei</li>
<li>For: The paper aims to improve the accuracy of lightweight student networks for semantic segmentation tasks using knowledge distillation.* Methods: The proposed method, called Inter-Class Similarity Distillation (ICSD), transfers high-order relations from the teacher network to the student network by computing intra-class distributions and inter-class similarity matrices using KL divergence. An Adaptive Loss Weighting (ALW) training strategy is also proposed to gradually reduce the influence of the teacher network towards the end of training.* Results: The proposed method outperforms most existing knowledge distillation methods in terms of mIoU and pixel accuracy on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012.Here are the three key points in Simplified Chinese text:* 为：本文目的是使用知识传授提高轻量级学生网络在 semantic segmentation 任务中的准确性。* 方法：提议的方法是 Inter-Class Similarity Distillation (ICSD)，它通过计算网络输出中每个类的内部分布来传递教师网络中高阶关系。此外，还使用 Adaptive Loss Weighting (ALW) 训练策略，以逐渐减少教师网络的影响。* 结果：提议的方法在 Cityscapes 和 Pascal VOC 2012 两个常见的 semantic segmentation 数据集上，与大多数现有的知识传授方法相比，在 mIoU 和像素准确性上表现出色。<details>
<summary>Abstract</summary>
In recent years, deep neural networks have achieved remarkable accuracy in computer vision tasks. With inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks. The existing methods often neglect the information in channels and among different classes. To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation. The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs. This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes. To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed. Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions. Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy. The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations. Code is available at: https://github.com/AmirMansurian/AICSD
</details>
<details>
<summary>摘要</summary>
Recently, deep neural networks have achieved remarkable accuracy in computer vision tasks. However, with inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks. Existing methods often neglect the information in channels and among different classes. To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation.The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs. This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes. To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed. Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions.Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy. The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations. Code is available at: https://github.com/AmirMansurian/AICSD.Here's the translation in Traditional Chinese:过去的几年，深度神经网络在计算机视觉任务中已经取得了很高的准确性。然而，在填充预测任务中，特别是 semantic segmentation 中，推论时间成为一个关键的因素。为了解决这个问题，这篇文章提出了一种名为 Inter-Class Similarity Distillation (ICSD) 的新方法。提案的方法通过获取师网络的高阶关系，将这些关系转移到学生网络中。这是通过获取每个类别的网络输出中的数据，并计算每对类别之间的相似性矩阵来进行知识传递。另外，为了进一步提高方法的效果，这篇文章还提出了一种 Adaptive Loss Weighting (ALW) 训练策略。与现有的方法不同的是，ALW 策略在训练过程中逐渐将师网络的影响降低，以抵销教师预测中的错误。实验结果显示，提案的方法在 Cityscapes 和 Pascal VOC 2012 这两个常用的 semantic segmentation 数据集上具有较高的 mIoU 和像素精度。此外，与现有的知识传递方法比较，提案的方法在量值和质量上都表现较好。代码可以在 https://github.com/AmirMansurian/AICSD 上取得。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Image-to-Image-Translation-Using-GANs-for-Synthetic-Child-Race-Data"><a href="#A-Comparative-Study-of-Image-to-Image-Translation-Using-GANs-for-Synthetic-Child-Race-Data" class="headerlink" title="A Comparative Study of Image-to-Image Translation Using GANs for Synthetic Child Race Data"></a>A Comparative Study of Image-to-Image Translation Using GANs for Synthetic Child Race Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04232">http://arxiv.org/abs/2308.04232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yao, Muhammad Ali Farooq, Joseph Lemley, Peter Corcoran</li>
<li>for: 提高face recognition技术的种族多样性</li>
<li>methods: 使用图像-图像转换来调整儿童脸部数据的种族</li>
<li>results: 实验结果表明，使用图像-图像转换方法可以生成各种种族的人工儿童脸部数据样本，提高face recognition技术的种族多样性。<details>
<summary>Abstract</summary>
The lack of ethnic diversity in data has been a limiting factor of face recognition techniques in the literature. This is particularly the case for children where data samples are scarce and presents a challenge when seeking to adapt machine vision algorithms that are trained on adult data to work on children. This work proposes the utilization of image-to-image transformation to synthesize data of different races and thus adjust the ethnicity of children's face data. We consider ethnicity as a style and compare three different Image-to-Image neural network based methods, specifically pix2pix, CycleGAN, and CUT networks to implement Caucasian child data and Asian child data conversion. Experimental validation results on synthetic data demonstrate the feasibility of using image-to-image transformation methods to generate various synthetic child data samples with broader ethnic diversity.
</details>
<details>
<summary>摘要</summary>
“无伦不同的人种数据的缺乏对面 recognition技术的发展带来了限制。尤其是儿童的数据样本罕见，对于适应机器视觉算法trained on adult data来应用于儿童的情况存在挑战。本工作提议利用图像到图像转换来增加不同的人种样本，以适应儿童的脸部数据的不同种族。我们认为人种是一种风格，并评估了三种基于图像到图像神经网络的方法，即 pix2pix、CycleGAN 和 CUT 网络，以实现白人儿童数据和亚洲儿童数据的转换。对于 sintetic data 的实验验证结果表明，使用图像到图像转换方法可以生成各种不同的 sintetic 儿童数据样本，以拓宽人种多样性。”
</details></li>
</ul>
<hr>
<h2 id="Will-your-Doorbell-Camera-still-recognize-you-as-you-grow-old"><a href="#Will-your-Doorbell-Camera-still-recognize-you-as-you-grow-old" class="headerlink" title="Will your Doorbell Camera still recognize you as you grow old"></a>Will your Doorbell Camera still recognize you as you grow old</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04224">http://arxiv.org/abs/2308.04224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yao, Muhammad Ali Farooq, Joseph Lemley, Peter Corcoran</li>
<li>for: 这个研究探讨了低功耗消费类设备（如门禁摄像头）的Robust验证问题，尤其是针对年龄的影响。</li>
<li>methods: 这个研究使用了两个公共的年龄数据集（AgeDB和Morph-II）作为基线，并使用了一种图形真实的年龄变换方法来增加一组高质量的面部图像，以模拟不同年龄的影响。</li>
<li>results: 实验结果表明，长期年龄影响仍然是现代面部验证方法的主要挑战。<details>
<summary>Abstract</summary>
Robust authentication for low-power consumer devices such as doorbell cameras poses a valuable and unique challenge. This work explores the effect of age and aging on the performance of facial authentication methods. Two public age datasets, AgeDB and Morph-II have been used as baselines in this work. A photo-realistic age transformation method has been employed to augment a set of high-quality facial images with various age effects. Then the effect of these synthetic aging data on the high-performance deep-learning-based face recognition model is quantified by using various metrics including Receiver Operating Characteristic (ROC) curves and match score distributions. Experimental results demonstrate that long-term age effects are still a significant challenge for the state-of-the-art facial authentication method.
</details>
<details>
<summary>摘要</summary>
低功耗消费者设备的坚实验证提供了一个独特和有价值的挑战。这项工作研究了人脸认证方法在不同年龄的影响。使用了公共的年龄数据集AgeDB和Morph-II作为基准，这里使用了一种实际准确的年龄变换方法来增加一组高质量的人脸图像，并对这些图像进行了不同年龄的变换。然后，通过使用深度学习基于的高性能人脸识别模型，量化这些人脸图像在不同年龄的影响。实验结果显示，长期年龄效应仍然是现代人脸认证方法的一大挑战。
</details></li>
</ul>
<hr>
<h2 id="AquaSAM-Underwater-Image-Foreground-Segmentation"><a href="#AquaSAM-Underwater-Image-Foreground-Segmentation" class="headerlink" title="AquaSAM: Underwater Image Foreground Segmentation"></a>AquaSAM: Underwater Image Foreground Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04218">http://arxiv.org/abs/2308.04218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muduo Xu, Jianhao Su, Yutao Liu</li>
<li>for: 这个论文是为了推广自然图像分割模型（SAM）的成功，将其应用于水下图像分割。</li>
<li>methods: 这篇论文使用自动分类和提取SUIM数据集中的各种标签，然后通过简单的微调方法将SAM模型适应通用水下图像分割。</li>
<li>results: 经过对8种分 segmentation任务（如人体潜水员）的广泛实验，这篇论文表明AquaSAM模型在水下图像分割任务中比默认SAM模型更高效，尤其是在困难任务（如珊瑚礁）中。AquaSAM模型在水下图像分割任务中的平均Dice相似度指数（DSC）提高了7.13%，并在多尺度指标（mIoU）上提高了8.27%。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) has revolutionized natural image segmentation, nevertheless, its performance on underwater images is still restricted. This work presents AquaSAM, the first attempt to extend the success of SAM on underwater images with the purpose of creating a versatile method for the segmentation of various underwater targets. To achieve this, we begin by classifying and extracting various labels automatically in SUIM dataset. Subsequently, we develop a straightforward fine-tuning method to adapt SAM to general foreground underwater image segmentation. Through extensive experiments involving eight segmentation tasks like human divers, we demonstrate that AquaSAM outperforms the default SAM model especially at hard tasks like coral reefs. AquaSAM achieves an average Dice Similarity Coefficient (DSC) of 7.13 (%) improvement and an average of 8.27 (%) on mIoU improvement in underwater segmentation tasks.
</details>
<details>
<summary>摘要</summary>
《Segment Anything Model》（SAM）已经革命化自然图像分割，但其在水下图像上的性能仍然受限。这项工作提出了将SAM扩展到水下图像上，以创建一种多样化的水下目标分割方法。为此，我们首先自动找到和分类SUIM数据集中的多种标签。然后，我们开发了一种简单的微调方法，以适应SAM进行普通水下图像分割的适应。经过对八种分割任务，如人体潜水员，的广泛实验，我们表明了 AquaSAM 在水下分割任务中的优异性，尤其是在复杂的珊瑚礁等难题上。AquaSAM 在水下分割任务中的平均 dice相似度系数（DSC）提高了7.13%，和水下分割任务的平均准确率（mIoU）提高了8.27%。
</details></li>
</ul>
<hr>
<h2 id="Robust-retrieval-of-material-chemical-states-in-X-ray-microspectroscopy"><a href="#Robust-retrieval-of-material-chemical-states-in-X-ray-microspectroscopy" class="headerlink" title="Robust retrieval of material chemical states in X-ray microspectroscopy"></a>Robust retrieval of material chemical states in X-ray microspectroscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04207">http://arxiv.org/abs/2308.04207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting Wang, Xiaotong Wu, Jizhou Li, Chao Wang</li>
<li>for: 研究材料的结构和化学变化，提供高分辨率的结构和光谱信息。</li>
<li>methods: 提出了一种新的数据建模方法和专门的分解框架，可以快速和可靠地检测材料的化学状态，并且可以扩展到多态材料化学。</li>
<li>results: 通过实验结果，证明了该方法的有效性和可靠性，可以在实际应用中快速和准确地检测材料的化学状态，即使在低信号噪声和光谱特征 overlap 的情况下。<details>
<summary>Abstract</summary>
X-ray microspectroscopic techniques are essential for studying morphological and chemical changes in materials, providing high-resolution structural and spectroscopic information. However, its practical data analysis for reliably retrieving the chemical states remains a major obstacle to accelerating the fundamental understanding of materials in many research fields. In this work, we propose a novel data formulation model for X-ray microspectroscopy and develop a dedicated unmixing framework to solve this problem, which is robust to noise and spectral variability. Moreover, this framework is not limited to the analysis of two-state material chemistry, making it an effective alternative to conventional and widely-used methods. In addition, an alternative directional multiplier method with provable convergence is applied to obtain the solution efficiently. Our framework can accurately identify and characterize chemical states in complex and heterogeneous samples, even under challenging conditions such as low signal-to-noise ratios and overlapping spectral features. Extensive experimental results on simulated and real datasets demonstrate its effectiveness and reliability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Transformers-for-Open-world-Instance-Segmentation"><a href="#Exploring-Transformers-for-Open-world-Instance-Segmentation" class="headerlink" title="Exploring Transformers for Open-world Instance Segmentation"></a>Exploring Transformers for Open-world Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04206">http://arxiv.org/abs/2308.04206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiannan Wu, Yi Jiang, Bin Yan, Huchuan Lu, Zehuan Yuan, Ping Luo</li>
<li>for: 这 paper 的目的是提出一种基于 transformer 的开放世界实例分割方法，以满足现有的实例分割模型在开放世界中的应用。</li>
<li>methods: 这 paper 使用了 transformer 网络，并提出了两个新的技术：首先，attach stop-gradient 操作来防止新类目被抑制为背景，并在 classification 头添加 IoU 头来发现新的物体。其次，提出了一种新的对比学习框架，通过在 object 队列中维护对象的中心点，并动态选择对象和背景的正负样本进行对比学习。</li>
<li>results: 这 paper 的模型在多种开放世界cross-category 和 cross-dataset 推广中取得了state-of-the-art 性能，特别是在 VOC 到 non-VOC 设置下，模型在 ARb100 和 ARm100 上达到了40.0% 和34.9% 的最高记录。在 COCO 到 UVO 推广中，SWORD 模型比前一个最佳的开放世界模型高出5.9% 和8.1% 的 APm 和 ARm100。<details>
<summary>Abstract</summary>
Open-world instance segmentation is a rising task, which aims to segment all objects in the image by learning from a limited number of base-category objects. This task is challenging, as the number of unseen categories could be hundreds of times larger than that of seen categories. Recently, the DETR-like models have been extensively studied in the closed world while stay unexplored in the open world. In this paper, we utilize the Transformer for open-world instance segmentation and present SWORD. Firstly, we introduce to attach the stop-gradient operation before classification head and further add IoU heads for discovering novel objects. We demonstrate that a simple stop-gradient operation not only prevents the novel objects from being suppressed as background, but also allows the network to enjoy the merit of heuristic label assignment. Secondly, we propose a novel contrastive learning framework to enlarge the representations between objects and background. Specifically, we maintain a universal object queue to obtain the object center, and dynamically select positive and negative samples from the object queries for contrastive learning. While the previous works only focus on pursuing average recall and neglect average precision, we show the prominence of SWORD by giving consideration to both criteria. Our models achieve state-of-the-art performance in various open-world cross-category and cross-dataset generalizations. Particularly, in VOC to non-VOC setup, our method sets new state-of-the-art results of 40.0% on ARb100 and 34.9% on ARm100. For COCO to UVO generalization, SWORD significantly outperforms the previous best open-world model by 5.9% on APm and 8.1% on ARm100.
</details>
<details>
<summary>摘要</summary>
open-world实例分割是一项崛起的任务，旨在通过学习有限数量的基本类目对象来分割图像中的所有对象。这个任务非常吃力，因为未知类别的数量可能是已知类别的百倍以上。在过去，DETR-like模型在关闭世界中被广泛研究，而在开放世界中却未得到过 изучение。在这篇论文中，我们使用Transformer进行开放世界实例分割，并提出SWORD。首先，我们在分类头部添加停止梯度操作，并添加IoU头来发现新对象。我们发现简单的停止梯度操作不仅防止新对象被识别为背景，还让网络享受到了识别标签的便利。其次，我们提出了一种新的对比学习框架，以增强对象和背景之间的表示。我们保持一个通用对象队列，以获取对象的中心，并动态选择对象查询中的正确和错误样本进行对比学习。而过去的工作只关注着追求平均回归率，忽略了平均准确率，我们显示SWORD的优势，并在不同的开放世界交叉类和交叉数据集上达到了state-of-the-art表现。尤其是在VOC到非VOC设置下，我们的方法设置了新的state-of-the-art记录，ARb100上的40.0%和ARm100上的34.9%。在COCO到UVO总结上，SWORD明显超过了之前最佳的开放世界模型，APm上提高了5.9%和ARm100上提高了8.1%。
</details></li>
</ul>
<hr>
<h2 id="D3G-Exploring-Gaussian-Prior-for-Temporal-Sentence-Grounding-with-Glance-Annotation"><a href="#D3G-Exploring-Gaussian-Prior-for-Temporal-Sentence-Grounding-with-Glance-Annotation" class="headerlink" title="D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation"></a>D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04197">http://arxiv.org/abs/2308.04197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanjun Li, Xiujun Shu, Sunan He, Ruizhi Qiao, Wei Wen, Taian Guo, Bei Gan, Xing Sun</li>
<li>for: 本研究旨在降低TSG任务中注意力标注成本，保持与完全监督方法相匹配的性能。</li>
<li>methods: 我们提出了一种基于Dynamic Gaussian prior的Grounding框架，包括Semantic Alignment Group Contrastive Learning模块(SA-GCL)和Dynamic Gaussian prior Adjustment模块(DGA)。</li>
<li>results: 我们的D3G方法在三个挑战性 benchmark上进行了广泛的实验，并证明了它的效果性。它与现状的弱监督方法相比，提高了性能的大幅度，并降低了与完全监督方法的性能差距。<details>
<summary>Abstract</summary>
Temporal sentence grounding (TSG) aims to locate a specific moment from an untrimmed video with a given natural language query. Recently, weakly supervised methods still have a large performance gap compared to fully supervised ones, while the latter requires laborious timestamp annotations. In this study, we aim to reduce the annotation cost yet keep competitive performance for TSG task compared to fully supervised ones. To achieve this goal, we investigate a recently proposed glance-supervised temporal sentence grounding task, which requires only single frame annotation (referred to as glance annotation) for each query. Under this setup, we propose a Dynamic Gaussian prior based Grounding framework with Glance annotation (D3G), which consists of a Semantic Alignment Group Contrastive Learning module (SA-GCL) and a Dynamic Gaussian prior Adjustment module (DGA). Specifically, SA-GCL samples reliable positive moments from a 2D temporal map via jointly leveraging Gaussian prior and semantic consistency, which contributes to aligning the positive sentence-moment pairs in the joint embedding space. Moreover, to alleviate the annotation bias resulting from glance annotation and model complex queries consisting of multiple events, we propose the DGA module, which adjusts the distribution dynamically to approximate the ground truth of target moments. Extensive experiments on three challenging benchmarks verify the effectiveness of the proposed D3G. It outperforms the state-of-the-art weakly supervised methods by a large margin and narrows the performance gap compared to fully supervised methods. Code is available at https://github.com/solicucu/D3G.
</details>
<details>
<summary>摘要</summary>
Temporal sentence grounding (TSG) 目标是在没有剪辑的视频中定位一个具体的时刻，与一个自然语言查询符对应。Recently, weakly supervised methods 仍然与完全监督的方法之间存在大量性能差距，而后者需要劳动密集的时间戳注解。在这种研究中，我们想要降低注解成本， yet keep competitive performance for TSG task compared to fully supervised ones。To achieve this goal, we investigate a recently proposed glance-supervised temporal sentence grounding task, which requires only single frame annotation (referred to as glance annotation) for each query。Under this setup, we propose a Dynamic Gaussian prior based Grounding framework with Glance annotation (D3G), which consists of a Semantic Alignment Group Contrastive Learning module (SA-GCL) and a Dynamic Gaussian prior Adjustment module (DGA). Specifically, SA-GCL samples reliable positive moments from a 2D temporal map via jointly leveraging Gaussian prior and semantic consistency, which contributes to aligning the positive sentence-moment pairs in the joint embedding space。Moreover, to alleviate the annotation bias resulting from glance annotation and model complex queries consisting of multiple events, we propose the DGA module, which adjusts the distribution dynamically to approximate the ground truth of target moments。Extensive experiments on three challenging benchmarks verify the effectiveness of the proposed D3G。It outperforms the state-of-the-art weakly supervised methods by a large margin and narrows the performance gap compared to fully supervised methods。代码可以在 https://github.com/solicucu/D3G 中找到。
</details></li>
</ul>
<hr>
<h2 id="Image-Copy-Move-Forgery-Detection-via-Deep-Cross-Scale-PatchMatch"><a href="#Image-Copy-Move-Forgery-Detection-via-Deep-Cross-Scale-PatchMatch" class="headerlink" title="Image Copy-Move Forgery Detection via Deep Cross-Scale PatchMatch"></a>Image Copy-Move Forgery Detection via Deep Cross-Scale PatchMatch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04188">http://arxiv.org/abs/2308.04188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingjie He, Yuanman Li, Changsheng Chen, Xia Li</li>
<li>for: 本研究旨在提高图像 копиrighted forgery detection（CMFD）领域的检测精度和普适性。</li>
<li>methods: 本研究提出了一种新的全级图像CMFD框架， combining conventional and deep learning methods。 Specifically, we design a deep cross-scale patchmatch method tailored for CMFD to localize copy-move regions, and develop a manipulation region location branch for source&#x2F;target separation。</li>
<li>results: 我们的方法在不同的复制和移动内容中显示出了显著更高的普适性和性能， compared to existing approaches。<details>
<summary>Abstract</summary>
The recently developed deep algorithms achieve promising progress in the field of image copy-move forgery detection (CMFD). However, they have limited generalizability in some practical scenarios, where the copy-move objects may not appear in the training images or cloned regions are from the background. To address the above issues, in this work, we propose a novel end-to-end CMFD framework by integrating merits from both conventional and deep methods. Specifically, we design a deep cross-scale patchmatch method tailored for CMFD to localize copy-move regions. In contrast to existing deep models, our scheme aims to seek explicit and reliable point-to-point matching between source and target regions using features extracted from high-resolution scales. Further, we develop a manipulation region location branch for source/target separation. The proposed CMFD framework is completely differentiable and can be trained in an end-to-end manner. Extensive experimental results demonstrate the high generalizability of our method to different copy-move contents, and the proposed scheme achieves significantly better performance than existing approaches.
</details>
<details>
<summary>摘要</summary>
最近发展的深度算法在图像复制移动伪造检测（CMFD）领域具有承诺的进步。然而，这些深度算法在一些实际场景中具有有限的通用性，例如在训练图像中没有复制移动对象或者径复制区域来自背景。为了解决上述问题，在这项工作中，我们提出了一种新的端到端CMFD框架，通过结合传统和深度方法的优点。具体来说，我们设计了一种适合CMFD的深度跨scale patchmatch方法，以便在本地化复制移动区域。与现有的深度模型不同，我们的方案寻求明确和可靠的点对点匹配 между源和目标区域，使用高分辨率层次中提取的特征。此外，我们开发了一个修改区域定位分支，用于源/目标分离。我们提出的CMFD框架是完全可导的，可以在端到端的训练方式下进行培训。广泛的实验结果表明，我们的方法具有不同复制移动内容的高通用性，并且我们提出的方案在现有方法中显著提高了性能。
</details></li>
</ul>
<hr>
<h2 id="How-Generalizable-are-Deepfake-Detectors-An-Empirical-Study"><a href="#How-Generalizable-are-Deepfake-Detectors-An-Empirical-Study" class="headerlink" title="How Generalizable are Deepfake Detectors? An Empirical Study"></a>How Generalizable are Deepfake Detectors? An Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04177">http://arxiv.org/abs/2308.04177</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/boutiquelee/deepfakeempiricalstudy">https://github.com/boutiquelee/deepfakeempiricalstudy</a></li>
<li>paper_authors: Boquan Li, Jun Sun, Christopher M. Poskitt</li>
<li>for: 这篇论文旨在探讨深伪材料检测方法的普适性，以帮助检测器在不同的 dataset 上保持一步 ahead of 害客。</li>
<li>methods: 本论文使用了六个深伪数据集、五种深伪检测方法和两种模型增强方法进行研究。</li>
<li>results: 研究发现，检测器在零 shot 设定下不能普适化，并且发现检测器学习了特定的合成方法的不良特征，以及检测器EXTRACTING 缺乏特征，导致普适性受限。然而，研究还发现了一些通用的神经元，可能为零 shot 普适性提供了可能的路径。<details>
<summary>Abstract</summary>
Deepfake videos and images are becoming increasingly credible, posing a significant threat given their potential to facilitate fraud or bypass access control systems. This has motivated the development of deepfake detection methods, in which deep learning models are trained to distinguish between real and synthesized footage. Unfortunately, existing detection models struggle to generalize to deepfakes from datasets they were not trained on, but little work has been done to examine why or how this limitation can be addressed. In this paper, we present the first empirical study on the generalizability of deepfake detectors, an essential goal for detectors to stay one step ahead of attackers. Our study utilizes six deepfake datasets, five deepfake detection methods, and two model augmentation approaches, confirming that detectors do not generalize in zero-shot settings. Additionally, we find that detectors are learning unwanted properties specific to synthesis methods and struggling to extract discriminative features, limiting their ability to generalize. Finally, we find that there are neurons universally contributing to detection across seen and unseen datasets, illuminating a possible path forward to zero-shot generalizability.
</details>
<details>
<summary>摘要</summary>
深刻的假动作和图像在增加可信度方面做出了重要贡献，它们的潜在威胁包括诈骗和绕过存取控制系统。这些问题驱使了深入学习检测方法的发展，这些模型通过训练来识别真实和合成的录影。可是，现有的检测模型在不同的数据集上缺乏通用性，但有很少的研究探讨这个限制和如何解决。在这篇论文中，我们提供了深入探讨检测器通用性的首个实践研究，这是检测器要一步拦截到诈骗者的重要目标。我们的研究使用了六个深刻假数据集，五个深刻检测方法和两种模型增强方法，确定了检测器在零点设定下不具通用性。此外，我们发现检测器在合成方法特有的特性上学习不良的特征，导致它们对于新的数据集难以准确检测。最后，我们发现有些神经网络在所有数据集上都具有检测功能，这提供了可能的通用性路径。
</details></li>
</ul>
<hr>
<h2 id="EFaR-2023-Efficient-Face-Recognition-Competition"><a href="#EFaR-2023-Efficient-Face-Recognition-Competition" class="headerlink" title="EFaR 2023: Efficient Face Recognition Competition"></a>EFaR 2023: Efficient Face Recognition Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04168">http://arxiv.org/abs/2308.04168</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahasanpour/EFaR-2023">https://github.com/ahasanpour/EFaR-2023</a></li>
<li>paper_authors: Jan Niklas Kolf, Fadi Boutros, Jurek Elliesen, Markus Theuerkauf, Naser Damer, Mohamad Alansari, Oussama Abdul Hay, Sara Alansari, Sajid Javed, Naoufel Werghi, Klemen Grm, Vitomir Štruc, Fernando Alonso-Fernandez, Kevin Hernandez Diaz, Josef Bigun, Anjith George, Christophe Ecabert, Hatef Otroshi Shahreza, Ketan Kotwal, Sébastien Marcel, Iurii Medvedev, Bo Jin, Diogo Nunes, Ahmad Hassanpour, Pankaj Khatiwada, Aafan Ahmad Toor, Bian Yang</li>
<li>for: 这篇论文主要是为了介绍2023年国际 JOINT会议 on Biometrics (IJCB 2023) 上进行的人脸认可竞赛（EFaR），以及参与竞赛的6个队伍的17个提交。</li>
<li>methods:  submitted solutions 使用了小型、高效的网络架构，以减少计算成本，一些解决方案还应用了模型归一化。</li>
<li>results: 论文评估了提交的解决方案的表现，以及一些基eline的测试数据集上的比较性能。 Here’s the English version of the three key information points:</li>
<li>for: The paper mainly introduces the Efficient Face Recognition Competition (EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB 2023), as well as the 6 teams that participated in the competition with 17 submissions.</li>
<li>methods: The submitted solutions use small, efficient network architectures to reduce computational cost, and some solutions apply model quantization.</li>
<li>results: The paper evaluates the performance of the submitted solutions and compares them to a set of baselines on a diverse set of benchmarks, including bias, cross-quality, and large-scale recognition.<details>
<summary>Abstract</summary>
This paper presents the summary of the Efficient Face Recognition Competition (EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB 2023). The competition received 17 submissions from 6 different teams. To drive further development of efficient face recognition models, the submitted solutions are ranked based on a weighted score of the achieved verification accuracies on a diverse set of benchmarks, as well as the deployability given by the number of floating-point operations and model size. The evaluation of submissions is extended to bias, cross-quality, and large-scale recognition benchmarks. Overall, the paper gives an overview of the achieved performance values of the submitted solutions as well as a diverse set of baselines. The submitted solutions use small, efficient network architectures to reduce the computational cost, some solutions apply model quantization. An outlook on possible techniques that are underrepresented in current solutions is given as well.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了2023年国际 JOINT Conference on Biometrics（IJCB 2023）上进行的Efficient Face Recognition Competition（EFaR）的结果。比赛接收了6个队伍的17个提交。为了驱动高效人脸识别模型的进一步发展，提交的解决方案按照使用多个benchmark上达到的验证精度的权重分数、以及模型的大小和浮点数据操作数量来进行排名。评测中还包括偏见、交叉评估和大规模识别的benchmark。总的来说，本文给出了提交的解决方案的实际性和多个基准值的概述，以及一些未在当前解决方案中充分表现的可能的技术。
</details></li>
</ul>
<hr>
<h2 id="Under-Display-Camera-Image-Restoration-with-Scattering-Effect"><a href="#Under-Display-Camera-Image-Restoration-with-Scattering-Effect" class="headerlink" title="Under-Display Camera Image Restoration with Scattering Effect"></a>Under-Display Camera Image Restoration with Scattering Effect</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04163">http://arxiv.org/abs/2308.04163</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/namecantbenull/srudc">https://github.com/namecantbenull/srudc</a></li>
<li>paper_authors: Binbin Song, Xiangyu Chen, Shuning Xu, Jiantao Zhou</li>
<li>for:  addresses the under-display camera (UDC) image restoration problem with a specific focus on the scattering effect caused by the display.</li>
<li>methods:  uses a two-branch restoration network, including a scattering branch that uses channel-wise self-attention to estimate the scattering effect parameters, and an image branch that leverages local representation advantages of CNN to recover clear scenes.</li>
<li>results:  demonstrates superior performance over state-of-the-art UDC restoration techniques through extensive experiments on both real-world and synthesized data.Here’s the summary in Traditional Chinese:</li>
<li>for:  addresses the 下层显示器（UDC）的图像修复问题，专注在显示器对图像的散射效应。</li>
<li>methods: 使用了两条分支修复网络，包括散射分支，使用通道别自我注意来估算散射效应的参数，以及图像分支，利用图像网络的地方表现优势来修复清晰的场景。</li>
<li>results: 通过对真实世界和合成数据进行广泛的实验，证明了提案方法与现有的UDC修复技术相比，具有较好的性能。<details>
<summary>Abstract</summary>
The under-display camera (UDC) provides consumers with a full-screen visual experience without any obstruction due to notches or punched holes. However, the semi-transparent nature of the display inevitably introduces the severe degradation into UDC images. In this work, we address the UDC image restoration problem with the specific consideration of the scattering effect caused by the display. We explicitly model the scattering effect by treating the display as a piece of homogeneous scattering medium. With the physical model of the scattering effect, we improve the image formation pipeline for the image synthesis to construct a realistic UDC dataset with ground truths. To suppress the scattering effect for the eventual UDC image recovery, a two-branch restoration network is designed. More specifically, the scattering branch leverages global modeling capabilities of the channel-wise self-attention to estimate parameters of the scattering effect from degraded images. While the image branch exploits the local representation advantage of CNN to recover clear scenes, implicitly guided by the scattering branch. Extensive experiments are conducted on both real-world and synthesized data, demonstrating the superiority of the proposed method over the state-of-the-art UDC restoration techniques. The source code and dataset are available at \url{https://github.com/NamecantbeNULL/SRUDC}.
</details>
<details>
<summary>摘要</summary>
“Under-display camera（UDC）为用户提供了一个无阻碍的全屏视觉体验，但是半透明的显示器无法避免对UDC图像的严重抑制。在这种情况下，我们在UDC图像恢复问题上进行了专门的考虑，并模型了由显示器引起的散射效应。我们通过物理模型来描述散射效应，并对图像形成管线进行了改进，以建立一个真实的UDC数据集。为了减少散射效应的影响，我们设计了两棵树结构，其中一棵是散射分支，利用通道级自注意力来估计散射效应的参数，另一棵是图像分支，利用深度学习来恢复清晰的场景。我们在实际数据上进行了广泛的实验，并证明了我们的方法在UDC图像恢复问题上的优越性。数据集和源代码可以在 GitHub 上获取（https://github.com/NamecantbeNULL/SRUDC）。”
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 这个论文主要针对的是Audio-guided Video Object Segmentation (A-VOS)和Referring Video Object Segmentation (R-VOS)两个关联任务，它们都是根据用户提供的表达提示从视频序列中提取特定对象的任务。</li>
<li>methods: 这篇论文提出了两种解决方案，一是对话表达匹配（EA）机制，用于Audio和Text表达之间的匹配，以实现语音和文本表达之间的含义相似性。另一个是表达视觉注意力（EVA）机制，用于深入探究Audio、Text和视频特征之间的互动。</li>
<li>results: 实验结果表明，我们提出的通用EPCFormer模型在两个任务上都达到了状态的艺术Result，并且可以很好地传递知识 между两个任务。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
Audio-guided Video Object Segmentation (A-VOS) 和 Referring Video Object Segmentation (R-VOS) 是两个高度相关的任务，它们都是根据用户提供的表达提示来从视频序列中 segment 特定对象。然而，由于不同模式之间的表达模型化困难，当前方法很难以寻求高精度地位和表达提示之间的平衡。在这篇论文中，我们解决这个问题从两个方面：表达提示的对齐表示和深度交互 among audio、文本和视觉特征。首先，我们提出一种通用架构，即表达Prompt Collaboration Transformer（EPCFormer）。然后，我们提出一种表达对齐（EA）机制，用于对 audio 和文本表达进行对齐。通过引入对 audio 和文本表达的对比学习，我们实现了对 audio 和文本表达的Semantic equivalence的认知。然后，为了促进 audio、文本和视觉特征之间的深度交互，我们引入表达-视觉注意力（EVA）机制。通过深入探索 audio、文本和视觉特征之间的 complementary cues，我们实现了从表达提示角度看到的视频对象分割知识的交叉传递。实验结果表明，我们的通用 EPCFormer 在两个任务上达到了状态艺术的Result。源代码将在 GitHub 上公开，详细信息请参考 <https://github.com/lab206/EPCFormer>。
</details></li>
</ul>
<hr>
<h2 id="Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention"><a href="#Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention" class="headerlink" title="Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention"></a>Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04156">http://arxiv.org/abs/2308.04156</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanning-zhang/satnet">https://github.com/fanning-zhang/satnet</a></li>
<li>paper_authors: Huilin Zhang, Sumei Li, Yongli Chang</li>
<li>for: 这篇论文的目的是提出一种基于顶部下向的图像三维质量评估（SIQA）网络，以更好地评估和改进3D内容的视觉体验。</li>
<li>methods: 该论文提出了一种新的网络方法，即通过层次注意力（Stereo Attention）来实现顶部下向的评估过程。该方法可以从高级二视图信号下到低级单视图信号的进程中进行导引，并在处理管道中进行可调calibration。</li>
<li>results: 实验结果表明，该方法可以更好地模拟人类视觉系统（HVS）的性质，并超越现有的底层方法。<details>
<summary>Abstract</summary>
Stereoscopic image quality assessment (SIQA) plays a crucial role in evaluating and improving the visual experience of 3D content. Existing binocular properties and attention-based methods for SIQA have achieved promising performance. However, these bottom-up approaches are inadequate in exploiting the inherent characteristics of the human visual system (HVS). This paper presents a novel network for SIQA via stereo attention, employing a top-down perspective to guide the quality assessment process. Our proposed method realizes the guidance from high-level binocular signals down to low-level monocular signals, while the binocular and monocular information can be calibrated progressively throughout the processing pipeline. We design a generalized Stereo AttenTion (SAT) block to implement the top-down philosophy in stereo perception. This block utilizes the fusion-generated attention map as a high-level binocular modulator, influencing the representation of two low-level monocular features. Additionally, we introduce an Energy Coefficient (EC) to account for recent findings indicating that binocular responses in the primate primary visual cortex are less than the sum of monocular responses. The adaptive EC can tune the magnitude of binocular response flexibly, thus enhancing the formation of robust binocular features within our framework. To extract the most discriminative quality information from the summation and subtraction of the two branches of monocular features, we utilize a dual-pooling strategy that applies min-pooling and max-pooling operations to the respective branches. Experimental results highlight the superiority of our top-down method in simulating the property of visual perception and advancing the state-of-the-art in the SIQA field. The code of this work is available at https://github.com/Fanning-Zhang/SATNet.
</details>
<details>
<summary>摘要</summary>
三维内容的视觉体验评估（SIQA）具有重要的作用，用于评估和改进三维内容的视觉体验。现有的底层方法和双目性质具有承诺的表现。然而，这些底层方法无法充分利用人视系统（HVS）的内在特性。这篇论文提出了一种新的网络方法 для SIQA，通过双目注意力来导引评估过程。我们的提议方法可以从高级双目信号下降到低级单目信号，同时双目和单目信息可以在处理管道中进行进度性calibration。我们设计了一种通用的双目注意力块（SAT）来实现上述哲学。这个块利用生成的注意力地图作为高级双目模ulator，影响低级单目特征表示。此外，我们引入了能量系数（EC），以应对证明 primate primary visual cortex中的双目响应小于单目响应的现象。可变的EC可以适应性地调整双目响应的 магнитуда，以便在我们的框架中成形Robust的双目特征。为了从两个支路的单目特征之和和差中提取最有价值的质量信息，我们采用了双pooling策略，对两个支路的单目特征进行最小池化和最大池化操作。实验结果表明，我们的底层方法可以准确模拟视觉响应和提高SIQA领域的状态。代码可以在 <https://github.com/Fanning-Zhang/SATNet> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Empowering-Vision-Language-Models-to-Follow-Interleaved-Vision-Language-Instructions"><a href="#Empowering-Vision-Language-Models-to-Follow-Interleaved-Vision-Language-Instructions" class="headerlink" title="Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions"></a>Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04152">http://arxiv.org/abs/2308.04152</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dcdmllm/cheetah">https://github.com/dcdmllm/cheetah</a></li>
<li>paper_authors: Juncheng Li, Kaihang Pan, Zhiqi Ge, Minghe Gao, Hanwang Zhang, Wei Ji, Wenqiao Zhang, Tat-Seng Chua, Siliang Tang, Yueting Zhuang<br>for: 这个论文旨在�evaluating the instruction following ability of multimodal large language models (MLLMs) on complicated interleaved vision-language instructions, and introducing a generic and lightweight controllable knowledge re-injection module to address the common defect of existing methods.methods: The proposed method utilizes a controllable knowledge re-injection module that leverages the sophisticated reasoning ability of LLMs to conditionally extract instruction-specific visual information and re-inject it into the LLM. The module is learned using an annotation-free cross-attention guided counterfactual image training strategy that collaborates a cascade of foundation models.results: The proposed method achieves state-of-the-art zero-shot performance across all tasks of I4, without high-quality multimodal instruction tuning data. Cheetor also exhibits competitive performance compared with state-of-the-art instruction tuned models on MME benchmark.<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have recently sparked significant interest, which demonstrates emergent capabilities to serve as a general-purpose model for various vision-language tasks. However, existing methods mainly focus on limited types of instructions with a single image as visual context, which hinders the widespread availability of MLLMs. In this paper, we introduce the I4 benchmark to comprehensively evaluate the instruction following ability on complicated interleaved vision-language instructions, which involve intricate image-text sequential context, covering a diverse range of scenarios (e.g., visually-rich webpages/textbooks, lecture slides, embodied dialogue). Systematic evaluation on our I4 benchmark reveals a common defect of existing methods: the Visual Prompt Generator (VPG) trained on image-captioning alignment objective tends to attend to common foreground information for captioning but struggles to extract specific information required by particular tasks. To address this issue, we propose a generic and lightweight controllable knowledge re-injection module, which utilizes the sophisticated reasoning ability of LLMs to control the VPG to conditionally extract instruction-specific visual information and re-inject it into the LLM. Further, we introduce an annotation-free cross-attention guided counterfactual image training strategy to methodically learn the proposed module by collaborating a cascade of foundation models. Enhanced by the proposed module and training strategy, we present Cheetor, a Transformer-based MLLM that can effectively handle a wide variety of interleaved vision-language instructions and achieves state-of-the-art zero-shot performance across all tasks of I4, without high-quality multimodal instruction tuning data. Cheetor also exhibits competitive performance compared with state-of-the-art instruction tuned models on MME benchmark.
</details>
<details>
<summary>摘要</summary>
大量多模态语言模型 (MLLMs) 在最近吸引了广泛的关注，这表明它们在多种视觉语言任务上表现出了总体的多功能性。然而，现有的方法主要集中在有限的类型的指令上，使得 MLMMs 的普及性受限。在这篇论文中，我们介绍了 I4 benchmark，用于全面评估 MLMMs 对于复杂的交叠视觉语言指令的遵循能力。系统性的评估表明，现有的方法存在一种普遍的缺陷：使用图像captioning对应目标训练的视觉提示生成器 (VPG) 往往会强调通用的前景信息，但是忽略特定任务所需的具体信息。为解决这一问题，我们提出了一种通用且轻量级的可控知识重新注入模块，该模块利用 LLMS 的复杂逻辑能力来控制 VPG，将特定任务所需的视觉信息从 LLMS 中提取出来，并重新注入到 LLMS 中。此外，我们提出了一种无需注意标注的横向关注帮助的反向图像培训策略，用于系统地学习该模块。通过该模块和培训策略，我们提出了一种基于转换器的 MLLM ，称为 Cheetor，可以有效地处理各种交叠视觉语言指令，并在 I4 测试benchmark上达到零基eline性能，不需要高质量的多媒体指令调整数据。此外，Cheetor 还与状态当前的指令调整模型在 MME 测试benchmark上表现竞争力。
</details></li>
</ul>
<hr>
<h2 id="Application-for-White-Spot-Syndrome-Virus-WSSV-Monitoring-using-Edge-Machine-Learning"><a href="#Application-for-White-Spot-Syndrome-Virus-WSSV-Monitoring-using-Edge-Machine-Learning" class="headerlink" title="Application for White Spot Syndrome Virus (WSSV) Monitoring using Edge Machine Learning"></a>Application for White Spot Syndrome Virus (WSSV) Monitoring using Edge Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04151">http://arxiv.org/abs/2308.04151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo S. Querol, Macario O. Cordel II, Dan Jeric A. Rustia, Mary Nia M. Santos</li>
<li>for: This paper aims to improve disease surveillance in the aquaculture industry, specifically for the White Spot Syndrome Virus (WSSV), by developing a mobile application and training a WSSV recognition model using computer vision techniques.</li>
<li>methods: The authors developed a mobile application to collect and monitor data, and trained two models (MobileNetV3-Small and EfficientNetV2-B0) using an imbalanced dataset to improve WSSV recognition. They also analyzed the saliency heatmaps of both models to understand the features that are most important in making a prediction.</li>
<li>results: The models achieved an F1-Score of 0.72 and 0.99, respectively, and the saliency heatmaps revealed the features that are most important in the images for making a correct prediction. The results demonstrate the effectiveness of using computer vision techniques for WSSV recognition, but also highlight the limitations of using resource-constrained devices and the need for further improvement.<details>
<summary>Abstract</summary>
The aquaculture industry, strongly reliant on shrimp exports, faces challenges due to viral infections like the White Spot Syndrome Virus (WSSV) that severely impact output yields. In this context, computer vision can play a significant role in identifying features not immediately evident to skilled or untrained eyes, potentially reducing the time required to report WSSV infections. In this study, the challenge of limited data for WSSV recognition was addressed. A mobile application dedicated to data collection and monitoring was developed to facilitate the creation of an image dataset to train a WSSV recognition model and improve country-wide disease surveillance. The study also includes a thorough analysis of WSSV recognition to address the challenge of imbalanced learning and on-device inference. The models explored, MobileNetV3-Small and EfficientNetV2-B0, gained an F1-Score of 0.72 and 0.99 respectively. The saliency heatmaps of both models were also observed to uncover the "black-box" nature of these models and to gain insight as to what features in the images are most important in making a prediction. These results highlight the effectiveness and limitations of using models designed for resource-constrained devices and balancing their performance in accurately recognizing WSSV, providing valuable information and direction in the use of computer vision in this domain.
</details>
<details>
<summary>摘要</summary>
鱼养业，强调虾 экспор特别是，面临病毒感染的挑战，如白点综合病毒（WSSV），这会严重影响产量。在这种情况下，计算机视觉可以发挥重要的作用，可以帮助找到不直观或未经训练的目的不可见的特征，从而减少WSSV感染的报告时间。本研究的挑战是有限的数据，用于WSSV识别的模型训练。为解决这个问题，我们开发了一款专门用于数据采集和监测的移动应用程序，以便创建一个用于训练WSSV识别模型的图像数据集。本研究还包括了WSSV识别的全面分析，以解决模型学习的偏袋问题和设备上的推理。我们检查了两种模型，MobileNetV3-Small和EfficientNetV2-B0，它们的F1分数分别为0.72和0.99。我们还研究了这两个模型的精度热图，以了解这些模型在图像中的哪些特征是最重要的，以及它们如何影响模型的预测结果。这些结果显示了使用特定的资源限制的设备上的模型的效果和局限性，以及在精度地识别WSSV的方面的价值信息和指导。
</details></li>
</ul>
<hr>
<h2 id="Class-level-Structural-Relation-Modelling-and-Smoothing-for-Visual-Representation-Learning"><a href="#Class-level-Structural-Relation-Modelling-and-Smoothing-for-Visual-Representation-Learning" class="headerlink" title="Class-level Structural Relation Modelling and Smoothing for Visual Representation Learning"></a>Class-level Structural Relation Modelling and Smoothing for Visual Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04142">http://arxiv.org/abs/2308.04142</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/czt117/csrms">https://github.com/czt117/csrms</a></li>
<li>paper_authors: Zitan Chen, Zhuang Qi, Xiao Cao, Xiangxian Li, Xiangxu Meng, Lei Meng</li>
<li>for: 这篇论文主要targets the problem of visual representation learning, particularly when dealing with classes that have diverse visual patterns.</li>
<li>methods: 这篇论文提出了一个框架，named CSRMS，which includes three modules: Class-level Relation Modelling, Class-aware Graph Sampling, and Relational Graph-Guided Representation Learning. These modules aim to model a relational graph of the entire dataset and perform class-aware smoothing and regularization operations to alleviate the issue of intra-class visual diversity and inter-class similarity.</li>
<li>results: 实验结果显示，CSRMS可以将结构知识模型化到图像表现学中，提高表现学模型的性能。此外，CSRMS可以与现有的最佳表现学模型结合使用，实现表现学模型的性能提升。<details>
<summary>Abstract</summary>
Representation learning for images has been advanced by recent progress in more complex neural models such as the Vision Transformers and new learning theories such as the structural causal models. However, these models mainly rely on the classification loss to implicitly regularize the class-level data distributions, and they may face difficulties when handling classes with diverse visual patterns. We argue that the incorporation of the structural information between data samples may improve this situation. To achieve this goal, this paper presents a framework termed \textbf{C}lass-level Structural Relation Modeling and Smoothing for Visual Representation Learning (CSRMS), which includes the Class-level Relation Modelling, Class-aware Graph Sampling, and Relational Graph-Guided Representation Learning modules to model a relational graph of the entire dataset and perform class-aware smoothing and regularization operations to alleviate the issue of intra-class visual diversity and inter-class similarity. Specifically, the Class-level Relation Modelling module uses a clustering algorithm to learn the data distributions in the feature space and identify three types of class-level sample relations for the training set; Class-aware Graph Sampling module extends typical training batch construction process with three strategies to sample dataset-level sub-graphs; and Relational Graph-Guided Representation Learning module employs a graph convolution network with knowledge-guided smoothing operations to ease the projection from different visual patterns to the same class. Experiments demonstrate the effectiveness of structured knowledge modelling for enhanced representation learning and show that CSRMS can be incorporated with any state-of-the-art visual representation learning models for performance gains. The source codes and demos have been released at https://github.com/czt117/CSRMS.
</details>
<details>
<summary>摘要</summary>
“图像表现学已经由最近的更进步的神经网络模型，如视图变换器和新的学习理论，如结构 causal 模型，所进步。但这些模型主要靠 классификаtion 损失来隐式训练数据分布，可能在处理多标的视觉模式时遇到问题。我们认为将数据样本之间的结构信息纳入模型中可以改善这个情况。为此，这篇论文提出了一个名为 Class-level Structural Relation Modeling and Smoothing for Visual Representation Learning（CSRMS）的框架，包括 Class-level Relation Modelling、Class-aware Graph Sampling 和 Relational Graph-Guided Representation Learning 三个模块。这些模块的目的是建立数据集的关系图，并通过阶段调整和缓和操作来缓和内部分类视觉多样性和相似性。具体来说，Class-level Relation Modelling 模块使用聚类算法学习数据集的分布在特征空间，并识别出三种类别水平的样本关系 для训练集; Class-aware Graph Sampling 模块延伸了传统的训练批次建构过程，使用三种策略来抽样数据集; Relational Graph-Guided Representation Learning 模块运用了图像 convolution 网络和知识导向缓和操作来将不同的视觉模式转换为同一个类别。实验结果显示结构知识模型可以帮助提高图像表现学，并证明 CSRMS 可以与任何现有的图像表现学模型结合使用，以获得性能提升。CSRMS 的源代码和示例已经发布在 GitHub 上（https://github.com/czt117/CSRMS）。”
</details></li>
</ul>
<hr>
<h2 id="Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness"><a href="#Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness" class="headerlink" title="Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness"></a>Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04137">http://arxiv.org/abs/2308.04137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael W. Spratling</li>
<li>for: The paper aims to evaluate the robustness of machine learning models, specifically deep neural networks, and to develop a benchmark for comprehensive evaluation of performance.</li>
<li>methods: The paper proposes using a wide range of different types of data to benchmark performance and using a single metric to produce a consistent evaluation of performance.</li>
<li>results: The paper finds that current deep neural networks are extremely vulnerable to making mistakes on certain types of data, and that they are insecure and unreliable in real-world scenarios where they may encounter data from many different domains.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文的目的是评估机器学习模型（尤其是深度神经网络）的可靠性和可靠性评估方法。</li>
<li>methods: 论文提议使用多种不同类型的数据来评估性能，并使用单一指标来生成一致的评估结果。</li>
<li>results: 论文发现现有的深度神经网络在某些类型的数据上很容易出错，并且在实际场景中，它们可能会遇到多种不同的预测任务，因此它们是不可靠的。<details>
<summary>Abstract</summary>
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to produce state-of-the-art robustness, are extremely vulnerable to making mistakes on certain types of data. This means that such models will be unreliable in real-world scenarios where they may encounter data from many different domains, and that they are insecure as they can easily be fooled into making the wrong decisions. It is hoped that these results will motivate the wider adoption of more comprehensive testing methods that will, in turn, lead to the development of more robust machine learning methods in the future.   Code is available at: \url{https://codeberg.org/mwspratling/RobustnessEvaluation}
</details>
<details>
<summary>摘要</summary>
可靠且稳定的评估方法是开发机器学习模型的必要第一步。然而，当前的评估协议通常只使用有限的测试数据来评估类ifiers的性能，而忽略其他类型的测试数据。例如，使用标准测试数据不能评估类ifiers对未知类型数据的预测性能。相反，使用包含未知类型数据的测试数据则不能评估类ifiers对已知类型数据的预测性能。这篇文章提出了使用多种不同类型的数据进行比较性能的方法，并使用一个统一的指标来评估所有数据类型的性能。使用这种标准，发现现有的深度神经网络，包括由其它方法训练的神经网络，在某些数据类型上存在极大的敏感性和容易被骗的问题。这意味着这些模型在实际场景中可能会出现问题，并且它们是不安全的，因为它们可以轻松地被骗到错误决策。希望这些结果能够激励更广泛的测试方法的采用，以便在未来开发更加稳定的机器学习方法。Code可以在以下链接获取：<https://codeberg.org/mwspratling/RobustnessEvaluation>
</details></li>
</ul>
<hr>
<h2 id="OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation"><a href="#OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation" class="headerlink" title="OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation"></a>OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04126">http://arxiv.org/abs/2308.04126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyang Yu, Shihao Wang, Yuan Fang, Wangpeng An</li>
<li>for: 这 paper 是为了解决多模态数据融合和无限数据生成问题，以提高人工智能对复杂实际数据的理解和生成能力。</li>
<li>methods: 这 paper 使用了多种操作，包括视频&#x2F;图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、认知任何模型（RAM）和物体跟踪。</li>
<li>results: 这 paper 的 finale输出将每个视频输入转化成一个详细的时间序列文档，从而使视频变成了详细的故事，使其更易于大语言模型处理。<details>
<summary>Abstract</summary>
This paper presents OmniDataComposer, an innovative approach for multimodal data fusion and unlimited data generation with an intent to refine and uncomplicate interplay among diverse data modalities. Coming to the core breakthrough, it introduces a cohesive data structure proficient in processing and merging multimodal data inputs, which include video, audio, and text.   Our crafted algorithm leverages advancements across multiple operations such as video/image caption extraction, dense caption extraction, Automatic Speech Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything Model(RAM), and object tracking. OmniDataComposer is capable of identifying over 6400 categories of objects, substantially broadening the spectrum of visual information. It amalgamates these diverse modalities, promoting reciprocal enhancement among modalities and facilitating cross-modal data correction. \textbf{The final output metamorphoses each video input into an elaborate sequential document}, virtually transmuting videos into thorough narratives, making them easier to be processed by large language models.   Future prospects include optimizing datasets for each modality to encourage unlimited data generation. This robust base will offer priceless insights to models like ChatGPT, enabling them to create higher quality datasets for video captioning and easing question-answering tasks based on video content. OmniDataComposer inaugurates a new stage in multimodal learning, imparting enormous potential for augmenting AI's understanding and generation of complex, real-world data.
</details>
<details>
<summary>摘要</summary>
The final output transforms each video input into an elaborate sequential document, virtually transmuting videos into thorough narratives that are easier to process by large language models. Future prospects include optimizing datasets for each modality to encourage unlimited data generation, providing priceless insights to models like ChatGPT and enabling them to create higher quality datasets for video captioning. This will ease question-answering tasks based on video content and inaugurate a new stage in multimodal learning, offering enormous potential for augmenting AI's understanding and generation of complex, real-world data.In simplified Chinese, the text would be:这篇论文介绍了 OmniDataComposer，一种创新的多Modal数据融合和无限数据生成方法。核心突破是一种可靠的数据结构，能够高效地处理和融合多Modal数据输入，包括视频、音频和文本。算法利用了多种进步，如视频/图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、Recognize Anything Model（RAM）和物体跟踪。输出 transformations each video input into an elaborate sequential document， virtually transmuting videos into thorough narratives that are easier to process by large language models。未来的前景包括优化每个模式的数据集，以便无限数据生成。这将为模型如ChatGPT提供无估量的智能，使其创建更高质量的视频描述集和简化基于视频内容的问答任务。OmniDataComposer开启了一个新的多Modal学习阶段，提供了巨大的潜力来增强AI对复杂、实际世界数据的理解和生成。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Color-Recommendation-in-Vector-Graphic-Documents"><a href="#Multimodal-Color-Recommendation-in-Vector-Graphic-Documents" class="headerlink" title="Multimodal Color Recommendation in Vector Graphic Documents"></a>Multimodal Color Recommendation in Vector Graphic Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04118">http://arxiv.org/abs/2308.04118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianru Qiu, Xueting Wang, Mayu Otani</li>
<li>for: 这个研究旨在提供基于文本 контекст的颜色建议，以帮助设计者选择适合的颜色。</li>
<li>methods: 该模型使用自我注意力网络和 crossed attention网络，以捕捉多个色彩中的关系，并将颜色和文本表示 integrate into one model。</li>
<li>results: 实验结果表明，该方法在准确率、颜色分布和用户体验方面都超过了先前的颜色alette completion方法，同时在全色组生成任务中，其对比 truth palettes 的颜色多样性和相似性也有所提高。<details>
<summary>Abstract</summary>
Color selection plays a critical role in graphic document design and requires sufficient consideration of various contexts. However, recommending appropriate colors which harmonize with the other colors and textual contexts in documents is a challenging task, even for experienced designers. In this study, we propose a multimodal masked color model that integrates both color and textual contexts to provide text-aware color recommendation for graphic documents. Our proposed model comprises self-attention networks to capture the relationships between colors in multiple palettes, and cross-attention networks that incorporate both color and CLIP-based text representations. Our proposed method primarily focuses on color palette completion, which recommends colors based on the given colors and text. Additionally, it is applicable for another color recommendation task, full palette generation, which generates a complete color palette corresponding to the given text. Experimental results demonstrate that our proposed approach surpasses previous color palette completion methods on accuracy, color distribution, and user experience, as well as full palette generation methods concerning color diversity and similarity to the ground truth palettes.
</details>
<details>
<summary>摘要</summary>
颜色选择在图文设计中扮演着关键的角色，需要考虑各种不同的 контекス特。然而，建议合适的颜色，使其融合在其他颜色和文本上下文中，是经验 designer 的挑战。在这个研究中，我们提出了一种多模态假面颜色模型，将多个颜色精灵 integrate 到一起，以提供文本意识 Color 推荐。我们的提议模型包括自我注意力网络，捕捉多个颜色精灵之间的关系，以及 crossed 注意力网络，将颜色和 CLIP 基于的文本表示 incorporate 到一起。我们的提议方法主要关注颜色精灵 completion，根据给定的颜色和文本来推荐颜色。此外，它还适用于另一个颜色推荐任务，全alette generation，生成与给定文本相对应的完整颜色精灵。实验结果表明，我们的提议方法在准确性、颜色分布和用户体验方面，都有所提高，并且在全alette generation 任务中，色彩多样性和真实性与基准 palettes 相比，也有所提高。
</details></li>
</ul>
<hr>
<h2 id="From-Unimodal-to-Multimodal-improving-the-sEMG-Based-Pattern-Recognition-via-deep-generative-models"><a href="#From-Unimodal-to-Multimodal-improving-the-sEMG-Based-Pattern-Recognition-via-deep-generative-models" class="headerlink" title="From Unimodal to Multimodal: improving the sEMG-Based Pattern Recognition via deep generative models"></a>From Unimodal to Multimodal: improving the sEMG-Based Pattern Recognition via deep generative models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04091">http://arxiv.org/abs/2308.04091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Wei, Linyan Ren</li>
<li>for: 提高手势识别精度</li>
<li>methods: 使用深度生成模型生成虚拟IMU信号，并与真实的EMG信号一起输入多模态Convolutional Neural Network（CNN）模型进行手势识别</li>
<li>results: 对6个数据库进行测试，包括5个公开的数据库和自己收集的数据库，其中28名参与者执行了38种手势，包括EMG和IMU数据，结果表明提议方法比单模态HGR方法（增加2.15%-13.10%）表现更好，这表明通过深度生成模型生成的虚拟IMU信号可以明显提高EMG基于的手势识别精度。<details>
<summary>Abstract</summary>
Multimodal hand gesture recognition (HGR) systems can achieve higher recognition accuracy. However, acquiring multimodal gesture recognition data typically requires users to wear additional sensors, thereby increasing hardware costs. This paper proposes a novel generative approach to improve Surface Electromyography (sEMG)-based HGR accuracy via virtual Inertial Measurement Unit (IMU) signals. Specifically, we trained a deep generative model based on the intrinsic correlation between forearm sEMG signals and forearm IMU signals to generate virtual forearm IMU signals from the input forearm sEMG signals at first. Subsequently, the sEMG signals and virtual IMU signals were fed into a multimodal Convolutional Neural Network (CNN) model for gesture recognition. To evaluate the performance of the proposed approach, we conducted experiments on 6 databases, including 5 publicly available databases and our collected database comprising 28 subjects performing 38 gestures, containing both sEMG and IMU data. The results show that our proposed approach outperforms the sEMG-based unimodal HGR method (with increases of 2.15%-13.10%). It demonstrates that incorporating virtual IMU signals, generated by deep generative models, can significantly enhance the accuracy of sEMG-based HGR. The proposed approach represents a successful attempt to transition from unimodal HGR to multimodal HGR without additional sensor hardware.
</details>
<details>
<summary>摘要</summary>
多模态手势识别（HGR）系统可以提高识别精度。然而，获取多模态手势识别数据通常需要用户穿着额外传感器，从而增加硬件成本。这篇论文提出了一种新的生成方法，用于通过生成虚拟抬肘卫星测量单元（IMU）信号来提高表肘电omyography（sEMG）基于的HGR精度。特别是，我们使用了深度生成模型，根据肘部sEMG信号和肘部IMU信号的内在相关性来生成虚拟肘部IMU信号。然后，sEMG信号和虚拟IMU信号被输入到一个多模态卷积神经网络（CNN）模型中进行手势识别。为评估提案的性能，我们进行了6个数据库的实验，包括5个公共可用的数据库和我们收集的数据库，包含28名参与者进行38种手势，其中包括sEMG和IMU数据。结果表明，我们的提案方法比sEMG基于的单模态HGR方法（增幅1.15%-13.10%）高。这表明，通过深度生成模型生成的虚拟IMU信号可以显著提高sEMG基于的HGR精度。这种方法表明了在不增加额外传感器硬件成本的情况下，从单模态HGR转移到多模态HGR的成功尝试。
</details></li>
</ul>
<hr>
<h2 id="3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="3D Gaussian Splatting for Real-Time Radiance Field Rendering"></a>3D Gaussian Splatting for Real-Time Radiance Field Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04079">http://arxiv.org/abs/2308.04079</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/graphdeco-inria/gaussian-splatting">https://github.com/graphdeco-inria/gaussian-splatting</a></li>
<li>paper_authors: Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, George Drettakis</li>
<li>for: 实现高质量 novel-view 合成，提高 scenes 的完整性和分辨率。</li>
<li>methods: 使用 3D Gaussians 表示 scene，并进行interleaved 优化&#x2F;密度控制，以获得高精度 scene 表示。</li>
<li>results: 实现了 state-of-the-art 的 visual quality 和实时渲染，并且在多个评估 datasets 上达到了领先的Result。<details>
<summary>Abstract</summary>
Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (>= 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.
</details>
<details>
<summary>摘要</summary>
“射频场方法”（Radiance Field method）在近期为 novel-view synthesis of captured scenes with multiple photos or videos 进行了革命性的改进。然而，实现高品质仍然需要费时训练和渲染 neural network，而最近的更快的方法则必须牺牲品质来获得速度。对于无限和完整的场景（而不是孤立的物体），以及1080p分辨率的渲染，目前的任何方法都无法在真实时间内进行高品质的novel-view synthesis。我们提出了三个关键的元素，允许我们实现现代化的Visual quality，同时维持竞争性的训练时间和重要的高品质实时（>= 30 fps）novel-view synthesis at 1080p resolution。首先，从摄像机对焦点所生成的稀疏点开始，我们使用3D Gaussians来表示场景，并保留恰当的维度场内散度场的性质，以避免在空间中无需过度计算。第二，我们在3D Gaussians中进行推广/频率控制，特别是对照方差进行最佳化，以确保场景的准确表示。第三，我们开发了一个快速可见性测试的渲染算法，支持标准渲染和实时渲染，并且加速训练和实时渲染。我们在一些已知的测试集上进行了实验，并证明了我们的方法可以实现现代化的Visual quality和高品质的实时渲染。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Spatial-Temporal-Context-for-Interacting-Hand-Reconstruction-on-Monocular-RGB-Video"><a href="#Exploiting-Spatial-Temporal-Context-for-Interacting-Hand-Reconstruction-on-Monocular-RGB-Video" class="headerlink" title="Exploiting Spatial-Temporal Context for Interacting Hand Reconstruction on Monocular RGB Video"></a>Exploiting Spatial-Temporal Context for Interacting Hand Reconstruction on Monocular RGB Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04074">http://arxiv.org/abs/2308.04074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weichao Zhao, Hezhen Hu, Wengang Zhou, Li li, Houqiang Li</li>
<li>for: 本文旨在提高单摄影像中重构互动手的精度，通过利用空间时间信息来提高互动手的重构效果。</li>
<li>methods: 本文提出了一个新的时间框架，利用时间上下文来补充单摄像头提供的不充分信息，并提出了一个互пенetration检测模块来生成物理合理的互动手。</li>
<li>results: 经验表明，本文提出的方法可以达到新的状态精度水平，在公共测试 benchmark 上实现了最高的表现。<details>
<summary>Abstract</summary>
Reconstructing interacting hands from monocular RGB data is a challenging task, as it involves many interfering factors, e.g. self- and mutual occlusion and similar textures. Previous works only leverage information from a single RGB image without modeling their physically plausible relation, which leads to inferior reconstruction results. In this work, we are dedicated to explicitly exploiting spatial-temporal information to achieve better interacting hand reconstruction. On one hand, we leverage temporal context to complement insufficient information provided by the single frame, and design a novel temporal framework with a temporal constraint for interacting hand motion smoothness. On the other hand, we further propose an interpenetration detection module to produce kinetically plausible interacting hands without physical collisions. Extensive experiments are performed to validate the effectiveness of our proposed framework, which achieves new state-of-the-art performance on public benchmarks.
</details>
<details>
<summary>摘要</summary>
重构互动手 FROM monochrome RGB 数据是一项复杂的任务，因为它们包含许多干扰因素，如自我和相互遮挡，以及类似的 texture。 先前的工作只是利用单个 RGB 图像提供的信息，没有考虑这些物理上的可能的关系，这导致了更差的重建结果。在这项工作中，我们决心显式利用空间-时间信息来实现更好的互动手 reconstruction。一方面，我们利用时间上下文来补充单幅图像中的不足信息，并设计了一个时间框架，以确保互动手动 motion 的平滑性。另一方面，我们进一步提议了一个 penetration 检测模块，以生成物理可能的互动手无碰撞。我们进行了广泛的实验来验证我们的提议的有效性，并实现了公共标准的新高水平性能。
</details></li>
</ul>
<hr>
<h2 id="3D-Scene-Diffusion-Guidance-using-Scene-Graphs"><a href="#3D-Scene-Diffusion-Guidance-using-Scene-Graphs" class="headerlink" title="3D Scene Diffusion Guidance using Scene Graphs"></a>3D Scene Diffusion Guidance using Scene Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04468">http://arxiv.org/abs/2308.04468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hamnaanaa/3D-Scene-Diffusion-Guidance-using-Scene-Graphs">https://github.com/hamnaanaa/3D-Scene-Diffusion-Guidance-using-Scene-Graphs</a></li>
<li>paper_authors: Mohammad Naanaa, Katharina Schmid, Yinyu Nie</li>
<li>for: 生成高质量3D场景的导航是一项复杂的任务。扩散模型已经显示了可能性，但现有方法直接使用文本嵌入来控制生成，限制了对物体之间复杂的空间关系的吸收。</li>
<li>methods: 我们提议一种使用场景图导航3D场景扩散指导的新方法。我们在杜比纳网络中使用关系图 convolutional块，以利用场景图提供的相对空间信息。</li>
<li>results: 我们的方法可以显著改善场景描述和生成场景之间的对齐。<details>
<summary>Abstract</summary>
Guided synthesis of high-quality 3D scenes is a challenging task. Diffusion models have shown promise in generating diverse data, including 3D scenes. However, current methods rely directly on text embeddings for controlling the generation, limiting the incorporation of complex spatial relationships between objects. We propose a novel approach for 3D scene diffusion guidance using scene graphs. To leverage the relative spatial information the scene graphs provide, we make use of relational graph convolutional blocks within our denoising network. We show that our approach significantly improves the alignment between scene description and generated scene.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将高质量3D场景合成引导为一个挑战性的任务。分散模型已经展示了生成多样数据的潜力，包括3D场景。然而，当前的方法直接基于文本嵌入来控制生成，限制了对物体之间复杂的空间关系的 incorporation。我们提出了一种新的方法，使用场景图导向3D场景扩散指导。为了利用场景图提供的相对空间信息，我们在杂化网络中使用关系图 convolutional块。我们显示，我们的方法可以显著改善场景描述和生成场景之间的对齐。Note: "场景图" (scene graph) refers to a graph that represents the relationships between objects in a scene, and "杂化网络" (denoising network) is a type of neural network that is trained to remove noise from a signal.
</details></li>
</ul>
<hr>
<h2 id="ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data"><a href="#ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data" class="headerlink" title="ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data"></a>ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04070">http://arxiv.org/abs/2308.04070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvidia/nvflare">https://github.com/nvidia/nvflare</a></li>
<li>paper_authors: Pochuan Wang, Chen Shen, Weichung Wang, Masahiro Oda, Chiou-Shann Fuh, Kensaku Mori, Holger R. Roth</li>
<li>for:  simultaneously delineating multiple organs and diseases</li>
<li>methods: federated learning (FL) with knowledge distillation</li>
<li>results: outperforms FedAvg and FedOpt baselines, superior generalizability on external test dataset, can perform well without frequent aggregationHere’s the Simplified Chinese translation of the three points:</li>
<li>for: 同时分割多个器官和疾病</li>
<li>methods: 联邦学习（FL）与知识储存</li>
<li>results: 比 FedAvg 和 FedOpt 基elines有更好的性能，在外部测试集上表现出较高的普适性，可以不经常聚合来达到良好的性能。<details>
<summary>Abstract</summary>
Developing a generalized segmentation model capable of simultaneously delineating multiple organs and diseases is highly desirable. Federated learning (FL) is a key technology enabling the collaborative development of a model without exchanging training data. However, the limited access to fully annotated training data poses a major challenge to training generalizable models. We propose "ConDistFL", a framework to solve this problem by combining FL with knowledge distillation. Local models can extract the knowledge of unlabeled organs and tumors from partially annotated data from the global model with an adequately designed conditional probability representation. We validate our framework on four distinct partially annotated abdominal CT datasets from the MSD and KiTS19 challenges. The experimental results show that the proposed framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the performance on an external test dataset demonstrates superior generalizability compared to models trained on each dataset separately. Our ablation study suggests that ConDistFL can perform well without frequent aggregation, reducing the communication cost of FL. Our implementation will be available at https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.
</details>
<details>
<summary>摘要</summary>
发展一个可以同时分割多个器官和疾病的通用分割模型是非常有优势的。联邦学习（FL）是一种关键技术，它可以帮助建立一个模型，不需要交换训练数据。然而，受到完全标注数据的限制，很难训练通用的模型。我们提出了“ConDistFL”框架，它将FL与知识储存结合以解决这个问题。本地模型可以从全球模型中提取未标注器官和肿瘤的知识，使用适当的条件概率表示。我们在四个不同的部分标注的腹部CT数据集上验证了我们的框架。实验结果表明，我们的框架在FedAvg和FedOpt基准下显著 OUTPERFORMS。此外，对于外部测试集，我们的模型表现更高的普适性，比单独在每个数据集上训练的模型。我们的剖分研究表明，ConDistFL可以在不经常聚合的情况下表现良好，减少联邦学习中的通信成本。我们的实现将在https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl上提供。
</details></li>
</ul>
<hr>
<h2 id="Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers"><a href="#Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers" class="headerlink" title="Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"></a>Backdoor Federated Learning by Poisoning Backdoor-Critical Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04466">http://arxiv.org/abs/2308.04466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan</li>
<li>for: 本研究旨在探讨 Federated Learning (FL) 中的后门攻击，以及如何通过识别和适应各种防御策略来实现这种攻击。</li>
<li>methods: 本研究提出了一种基于实际攻击者视角的协调方法，可以帮助攻击者识别和攻击 FL 模型中的极其敏感层（Backdoor-Critical，BC）。此外，本研究还提出了一种基于 BC 层的新型后门攻击方法，可以在不同的防御策略下寻找最佳攻击方式。</li>
<li>results: 经过广泛的实验，研究发现，使用本研究的 BC 层感知后门攻击方法，可以在七种最新的防御策略下成功后门 FL 模型，且比最新的后门攻击方法更高效。<details>
<summary>Abstract</summary>
Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that our BC layer-aware backdoor attacks can successfully backdoor FL under seven SOTA defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "backdoor-critical" (BC) layers are a small subset of layers in a machine learning model that dominate the model's vulnerabilities.* The proposed approach identifies and verifies BC layers from the perspective of attackers.* The new backdoor attack methodology adaptively seeks a balance between attacking effects and stealthiness under various defense strategies.* The approach can successfully backdoor FL under seven state-of-the-art defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Analysis-of-Range-for-3D-Object-Detection"><a href="#An-Empirical-Analysis-of-Range-for-3D-Object-Detection" class="headerlink" title="An Empirical Analysis of Range for 3D Object Detection"></a>An Empirical Analysis of Range for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04054">http://arxiv.org/abs/2308.04054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neehar Peri, Mengtian Li, Benjamin Wilson, Yu-Xiong Wang, James Hays, Deva Ramanan</li>
<li>for: 本文主要研究长距离3D探测，以实现自主驾驶车辆的安全 Navigation。</li>
<li>methods: 本文使用Argoverse 2.0 dataset进行实验分析，探讨长距离3D探测的问题，并发现近距离LiDAR测量是紧密且适合使用小尺寸矩阵，而远距离测量则是疏 dispersed且适合使用大尺寸矩阵。本文还提出了一组为近 vs 远场探测而调整的范围专家，以及一些简单的技术来优化长距离探测的效率和精度。</li>
<li>results: 本文的实验结果显示，使用该范围专家和技术可以提高长距离探测的效率33%，并提高精度3.2% CDS。<details>
<summary>Abstract</summary>
LiDAR-based 3D detection plays a vital role in autonomous navigation. Surprisingly, although autonomous vehicles (AVs) must detect both near-field objects (for collision avoidance) and far-field objects (for longer-term planning), contemporary benchmarks focus only on near-field 3D detection. However, AVs must detect far-field objects for safe navigation. In this paper, we present an empirical analysis of far-field 3D detection using the long-range detection dataset Argoverse 2.0 to better understand the problem, and share the following insight: near-field LiDAR measurements are dense and optimally encoded by small voxels, while far-field measurements are sparse and are better encoded with large voxels. We exploit this observation to build a collection of range experts tuned for near-vs-far field detection, and propose simple techniques to efficiently ensemble models for long-range detection that improve efficiency by 33% and boost accuracy by 3.2% CDS.
</details>
<details>
<summary>摘要</summary>
lidar-based 3D 探测在自动驾驶中扮演着关键性的角色。很奇怪的是，即使自动车辆（AV）需要探测附近 объек（以避免碰撞）和远场 объек（为长期规划），当前的标准准则仅专注于附近 3D 探测。然而，AV 需要探测远场 объек 以确保安全 Navigation。在这篇论文中，我们提供了实验分析远场 3D 探测使用 Argoverse 2.0 长距离探测数据集，以更好地理解问题，并分享以下发现：附近 LiDAR 测量 dense 且最佳地编码为小 voxels，而远场测量则是稀疏的，更适合使用大 voxels 编码。我们利用这一观察，建立了适应于近vs远场探测的范围专家，并提出了简单的技术来有效地ensemble模型以提高长距离探测的效率和准确率。
</details></li>
</ul>
<hr>
<h2 id="Implicit-neural-representations-for-joint-decomposition-and-registration-of-gene-expression-images-in-the-marmoset-brain"><a href="#Implicit-neural-representations-for-joint-decomposition-and-registration-of-gene-expression-images-in-the-marmoset-brain" class="headerlink" title="Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain"></a>Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04039">http://arxiv.org/abs/2308.04039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michal Byra, Charissa Poon, Tomomi Shimogori, Henrik Skibbe</li>
<li>for: 本研究旨在提出一种基于隐藏神经表示的图像匹配方法，用于处理两个脑图像之间的匹配问题，其中一个图像包含附加的特征或artefacts，而另一个图像则不包含这些特征。</li>
<li>methods: 本方法使用隐藏网络和图像排除损失来同时进行匹配和图像分解，其中支持图像能够匹配well于模板，而剩余图像则捕捉到各自图像特征的差异。</li>
<li>results: 实验结果表明，本方法可以提供出色的结果，并在其他匹配技术上表现出色。<details>
<summary>Abstract</summary>
We propose a novel image registration method based on implicit neural representations that addresses the challenging problem of registering a pair of brain images with similar anatomical structures, but where one image contains additional features or artifacts that are not present in the other image. To demonstrate its effectiveness, we use 2D microscopy $\textit{in situ}$ hybridization gene expression images of the marmoset brain. Accurately quantifying gene expression requires image registration to a brain template, which is difficult due to the diversity of patterns causing variations in visible anatomical brain structures. Our approach uses implicit networks in combination with an image exclusion loss to jointly perform the registration and decompose the image into a support and residual image. The support image aligns well with the template, while the residual image captures individual image characteristics that diverge from the template. In experiments, our method provided excellent results and outperformed other registration techniques.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于隐式神经表示的新型图像匹配方法，用于处理一对具有相似解剖结构的脑图像，其中一个图像包含一些不在另一个图像中存在的特征或噪声。为证明其效果，我们使用了2D微显镜天然增强引入蛋白表达图像。正确评估蛋白表达需要图像匹配到脑模板，这是因为脑结构的多样性导致视觉特征的变化。我们的方法使用隐式网络和图像排除损失相结合，同时进行匹配和图像分解。支持图像能够匹配良好到模板，而剩余图像损失中包含各自图像特征。在实验中，我们的方法表现出色，超越了其他匹配技术。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Augmentation-with-Large-scale-Unconditional-Pre-training"><a href="#Synthetic-Augmentation-with-Large-scale-Unconditional-Pre-training" class="headerlink" title="Synthetic Augmentation with Large-scale Unconditional Pre-training"></a>Synthetic Augmentation with Large-scale Unconditional Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04020">http://arxiv.org/abs/2308.04020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karenyyy/histodiffaug">https://github.com/karenyyy/histodiffaug</a></li>
<li>paper_authors: Jiarong Ye, Haomiao Ni, Peng Jin, Sharon X. Huang, Yuan Xue</li>
<li>for: 提高医疗影像识别系统的训练数据效果，减少专家标注的成本和时间。</li>
<li>methods: 提出了一种名为HistoDiffusion的生成图像增强技术，可以在大量未标注数据集上预训练，然后应用于小规模标注数据集进行增强训练。</li>
<li>results: 通过在三个 histopathology 数据集上预训练，然后在一个 colorectal cancer (CRC) 数据集上测试，得到了训练使用小量标注数据集的增强图像识别率的提高，具体提高6.4%。<details>
<summary>Abstract</summary>
Deep learning based medical image recognition systems often require a substantial amount of training data with expert annotations, which can be expensive and time-consuming to obtain. Recently, synthetic augmentation techniques have been proposed to mitigate the issue by generating realistic images conditioned on class labels. However, the effectiveness of these methods heavily depends on the representation capability of the trained generative model, which cannot be guaranteed without sufficient labeled training data. To further reduce the dependency on annotated data, we propose a synthetic augmentation method called HistoDiffusion, which can be pre-trained on large-scale unlabeled datasets and later applied to a small-scale labeled dataset for augmented training. In particular, we train a latent diffusion model (LDM) on diverse unlabeled datasets to learn common features and generate realistic images without conditional inputs. Then, we fine-tune the model with classifier guidance in latent space on an unseen labeled dataset so that the model can synthesize images of specific categories. Additionally, we adopt a selective mechanism to only add synthetic samples with high confidence of matching to target labels. We evaluate our proposed method by pre-training on three histopathology datasets and testing on a histopathology dataset of colorectal cancer (CRC) excluded from the pre-training datasets. With HistoDiffusion augmentation, the classification accuracy of a backbone classifier is remarkably improved by 6.4% using a small set of the original labels. Our code is available at https://github.com/karenyyy/HistoDiffAug.
</details>
<details>
<summary>摘要</summary>
医学图像识别系统经常需要大量的训练数据，包括专家标注，这可能是时间consuming和成本高的。在最近，人工增强技术被提出，以生成符合类别标签的图像。然而，这些方法的效果受训练的生成模型的表达能力的限制，而这无法保证。为了进一步减少依赖于标注数据，我们提议一种名为HistoDiffusion的人工增强方法。在这种方法中，我们首先在大量无标注数据上训练一个潜在扩散模型（LDM），以学习通用特征并生成真实图像。然后，我们在一个未看过的标注数据集上精度地调整模型，以使其能够生成特定类别的图像。此外，我们采用了一种选择机制，只添加符合目标标签的synthetic样本。我们对三个 Histopathology 数据集进行预训练，并在一个排除在预训练数据集中的大肠癌（CRC）数据集上进行测试。与HistoDiffusion增强后，一个基础类фика器的分类精度显著提高了6.4%，只使用一小部分原始标注。我们的代码可以在 GitHub 上找到：https://github.com/karenyyy/HistoDiffAug。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Visual-Primitive-Experts-for-Compositional-Zero-Shot-Learning"><a href="#Hierarchical-Visual-Primitive-Experts-for-Compositional-Zero-Shot-Learning" class="headerlink" title="Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning"></a>Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04016">http://arxiv.org/abs/2308.04016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanjaekim98/cot">https://github.com/hanjaekim98/cot</a></li>
<li>paper_authors: Hanjae Kim, Jiyoung Lee, Seongheon Park, Kwanghoon Sohn</li>
<li>for: 本研究的目的是提出一种简单可扩展的架构，以解决现有的 zero-shot 组合学习（CZSL）问题，包括考虑对象和特征之间的上下文关系，以及实际世界中的组合数据长尾分布问题。</li>
<li>methods: 本研究提出了一种名为 Composition Transformer（CoT）的简单可扩展架构，该架构包括对象和特征专家，通过可视网络层次结构来生成表示性 embedding。对象专家从底层 final layer 中提取表示性对象 embedding，而特征专家通过一种提出的对象引导注意力模块来生成特征 embedding，以显式地模型上下文关系。</li>
<li>results: 根据多个 benchmark 数据集，包括 MIT-States、C-GQA 和 VAW-CZSL，our method  achieve State-of-the-Art 性能。此外，我们还证明了 CoT 在改善可视特征分辨率和减少模型偏见问题上的效果。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/HanjaeKim98/CoT">https://github.com/HanjaeKim98/CoT</a> 上获取。<details>
<summary>Abstract</summary>
Compositional zero-shot learning (CZSL) aims to recognize unseen compositions with prior knowledge of known primitives (attribute and object). Previous works for CZSL often suffer from grasping the contextuality between attribute and object, as well as the discriminability of visual features, and the long-tailed distribution of real-world compositional data. We propose a simple and scalable framework called Composition Transformer (CoT) to address these issues. CoT employs object and attribute experts in distinctive manners to generate representative embeddings, using the visual network hierarchically. The object expert extracts representative object embeddings from the final layer in a bottom-up manner, while the attribute expert makes attribute embeddings in a top-down manner with a proposed object-guided attention module that models contextuality explicitly. To remedy biased prediction caused by imbalanced data distribution, we develop a simple minority attribute augmentation (MAA) that synthesizes virtual samples by mixing two images and oversampling minority attribute classes. Our method achieves SoTA performance on several benchmarks, including MIT-States, C-GQA, and VAW-CZSL. We also demonstrate the effectiveness of CoT in improving visual discrimination and addressing the model bias from the imbalanced data distribution. The code is available at https://github.com/HanjaeKim98/CoT.
</details>
<details>
<summary>摘要</summary>
compositional zero-shot learning (CZSL)  targets recognizing unseen compositions based on prior knowledge of known primitives (attribute and object). previous works for CZSL often suffer from grasping the contextuality between attribute and object, as well as the discriminability of visual features, and the long-tailed distribution of real-world compositional data. we propose a simple and scalable framework called Composition Transformer (CoT) to address these issues. CoT employs object and attribute experts in distinctive manners to generate representative embeddings, using the visual network hierarchically. the object expert extracts representative object embeddings from the final layer in a bottom-up manner, while the attribute expert makes attribute embeddings in a top-down manner with a proposed object-guided attention module that models contextuality explicitly. to remedy biased prediction caused by imbalanced data distribution, we develop a simple minority attribute augmentation (MAA) that synthesizes virtual samples by mixing two images and oversampling minority attribute classes. our method achieves SoTA performance on several benchmarks, including MIT-States, C-GQA, and VAW-CZSL. we also demonstrate the effectiveness of CoT in improving visual discrimination and addressing the model bias from the imbalanced data distribution. the code is available at https://github.com/HanjaeKim98/CoT.
</details></li>
</ul>
<hr>
<h2 id="Coarse-to-Fine-Learning-Compact-Discriminative-Representation-for-Single-Stage-Image-Retrieval"><a href="#Coarse-to-Fine-Learning-Compact-Discriminative-Representation-for-Single-Stage-Image-Retrieval" class="headerlink" title="Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval"></a>Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04008">http://arxiv.org/abs/2308.04008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bassyess/cfcd">https://github.com/bassyess/cfcd</a></li>
<li>paper_authors: Yunquan Zhu, Xinkai Gao, Bo Ke, Ruizhi Qiao, Xing Sun</li>
<li>for: 实现单stage图像检索的高效精度搜索</li>
<li>methods: 提出了一种Coarse-to-Fine框架，学习Compact Discriminative representation（CFCD），只需要图像级别的标签进行训练。具体来说，我们首先设计了一种适应性softmax基于损失函数，在每个mini-batch中动态调整其尺度和边缘，以强化supervision during training和intra-class compactness。其次，我们提出了一种机制，通过硬negative sampling策略选择突出地ocal descriptors，并将其混合到全局表示中，以便在全球范围内优化相互之间的Semantic关系。</li>
<li>results: 经验证明了我们的方法的效果，在Revisited Oxford和Revisited Paris等benchmark上实现了单stage图像检索的state-of-the-art性能。<details>
<summary>Abstract</summary>
Image retrieval targets to find images from a database that are visually similar to the query image. Two-stage methods following retrieve-and-rerank paradigm have achieved excellent performance, but their separate local and global modules are inefficient to real-world applications. To better trade-off retrieval efficiency and accuracy, some approaches fuse global and local feature into a joint representation to perform single-stage image retrieval. However, they are still challenging due to various situations to tackle, $e.g.$, background, occlusion and viewpoint. In this work, we design a Coarse-to-Fine framework to learn Compact Discriminative representation (CFCD) for end-to-end single-stage image retrieval-requiring only image-level labels. Specifically, we first design a novel adaptive softmax-based loss which dynamically tunes its scale and margin within each mini-batch and increases them progressively to strengthen supervision during training and intra-class compactness. Furthermore, we propose a mechanism which attentively selects prominent local descriptors and infuse fine-grained semantic relations into the global representation by a hard negative sampling strategy to optimize inter-class distinctiveness at a global scale. Extensive experimental results have demonstrated the effectiveness of our method, which achieves state-of-the-art single-stage image retrieval performance on benchmarks such as Revisited Oxford and Revisited Paris. Code is available at https://github.com/bassyess/CFCD.
</details>
<details>
<summary>摘要</summary>
<SYS>将给定文本翻译成简化中文。</SYS>图像检索目标是从数据库中检索与查询图像视觉相似的图像。两Stage方法在 retrieve-and-rerank 模式下实现了出色的表现，但它们的分立的本地和全局模块在实际应用中不是非常有效。为了更好地平衡检索效率和准确率，一些方法将全局和本地特征集成为一个共同表示，以实现单stage图像检索。然而，它们仍然面临许多挑战，例如背景、遮挡和视角等。在这项工作中，我们设计了一个粗略到细节的框架，用于学习练习Compact Discriminative representation（CFCD），以实现端到端单stage图像检索，只需要图像级别标签。具体来说，我们首先设计了一种新的适应式软MAX基于损失函数，可以在每个小批中动态调整缩放和边界，以强化supervision during training和内部精度。此外，我们提出了一种机制，可以在硬negative samplingstrategy中选择表现出色的本地特征，并将其注入到全局表示中，以便在全球级别提高对类的分辨率。经验证实结果表明，我们的方法可以实现单stage图像检索的最佳表现，在Revisited Oxford和Revisited Paris等benchmark上达到了状态畅的单stage图像检索性能。代码可以在https://github.com/bassyess/CFCD中找到。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-medical-image-classification-with-simple-shape-and-texture-text-descriptors-using-vision-language-models"><a href="#Few-shot-medical-image-classification-with-simple-shape-and-texture-text-descriptors-using-vision-language-models" class="headerlink" title="Few-shot medical image classification with simple shape and texture text descriptors using vision-language models"></a>Few-shot medical image classification with simple shape and texture text descriptors using vision-language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04005">http://arxiv.org/abs/2308.04005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michal Byra, Muhammad Febrian Rachmadi, Henrik Skibbe</li>
<li>for: 本研究探讨了视力语言模型（VLMs）和大语言模型在医学图像二进制少量分类中的有用性。</li>
<li>methods: 我们使用GPT-4模型生成医学图像中对象形状和xture特征的文本描述符。然后，这些GPT-4生成的描述符， alongside VLMs pré-训练natural images, 用于分类胸部X射线和乳腺ultrasound图像。</li>
<li>results: 我们的结果表明，使用VLMs和GPT-4生成的描述符进行医学图像二进制少量分类是一种可行的方法。然而，为了准确地分类，需要排除certain descriptor的计算分类分数。此外，我们评估了VLMs对乳腺癌ultrasound图像中形状特征的评价能力。我们进一步调查GPT-4生成的描述符集中的变化程度。我们的工作提供了关于VLMs在医学图像分析中的应用的重要发现。<details>
<summary>Abstract</summary>
In this work, we investigate the usefulness of vision-language models (VLMs) and large language models for binary few-shot classification of medical images. We utilize the GPT-4 model to generate text descriptors that encapsulate the shape and texture characteristics of objects in medical images. Subsequently, these GPT-4 generated descriptors, alongside VLMs pre-trained on natural images, are employed to classify chest X-rays and breast ultrasound images. Our results indicate that few-shot classification of medical images using VLMs and GPT-4 generated descriptors is a viable approach. However, accurate classification requires to exclude certain descriptors from the calculations of the classification scores. Moreover, we assess the ability of VLMs to evaluate shape features in breast mass ultrasound images. We further investigate the degree of variability among the sets of text descriptors produced by GPT-4. Our work provides several important insights about the application of VLMs for medical image analysis.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了视力语言模型（VLM）和大语言模型是否能够实现医学图像二进制几个shot分类。我们使用GPT-4模型生成医学图像中对象的形状和文化特征的文本描述。然后，这些GPT-4生成的描述、 alongside VLMs预训练于自然图像，用于分类胸部X射线和乳腺ultrasound图像。我们的结果表明，使用VLMs和GPT-4生成的描述进行医学图像二进制分类是一种可行的方法。然而，精确地分类需要排除某些描述器从分类得分计算中。此外，我们评估了VLMs对乳腺瘤ultrasound图像中形状特征的评价能力。我们进一步调查GPT-4生成的描述集中的变化程度。我们的研究提供了关于VLMs在医学图像分析方面的重要发现。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Strawberry-Detection-Based-on-Improved-YOLOv5s-Architecture-for-Robotic-Harvesting-in-open-field-environment"><a href="#Real-time-Strawberry-Detection-Based-on-Improved-YOLOv5s-Architecture-for-Robotic-Harvesting-in-open-field-environment" class="headerlink" title="Real-time Strawberry Detection Based on Improved YOLOv5s Architecture for Robotic Harvesting in open-field environment"></a>Real-time Strawberry Detection Based on Improved YOLOv5s Architecture for Robotic Harvesting in open-field environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03998">http://arxiv.org/abs/2308.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan He, Salik Ram Khana, Xin Zhang, Manoj Karkee, Qin Zhang</li>
<li>For: The paper proposes a custom object detection model based on YOLOv5 for strawberry detection in open-field environments.* Methods: The proposed model modifies the original YOLOv5 architecture by replacing the C3 module with C2f and combining Spatial Pyramid Pooling Fast with Cross Stage Partial Net. The model is trained on a dataset of RGB images of strawberry canopies with three maturity classes.* Results: The proposed model achieves the highest mean average precision of 80.3% among five compared models, with an inference speed of 18ms per image. The model outperforms the latest YOLOv8s in terms of average precision in the immature and mature classes, while being faster and having fewer parameters.<details>
<summary>Abstract</summary>
This study proposed a YOLOv5-based custom object detection model to detect strawberries in an outdoor environment. The original architecture of the YOLOv5s was modified by replacing the C3 module with the C2f module in the backbone network, which provided a better feature gradient flow. Secondly, the Spatial Pyramid Pooling Fast in the final layer of the backbone network of YOLOv5s was combined with Cross Stage Partial Net to improve the generalization ability over the strawberry dataset in this study. The proposed architecture was named YOLOv5s-Straw. The RGB images dataset of the strawberry canopy with three maturity classes (immature, nearly mature, and mature) was collected in open-field environment and augmented through a series of operations including brightness reduction, brightness increase, and noise adding. To verify the superiority of the proposed method for strawberry detection in open-field environment, four competitive detection models (YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s) were trained, and tested under the same computational environment and compared with YOLOv5s-Straw. The results showed that the highest mean average precision of 80.3% was achieved using the proposed architecture whereas the same was achieved with YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s were 73.4%, 77.8%, 79.8%, 79.3%, respectively. Specifically, the average precision of YOLOv5s-Straw was 82.1% in the immature class, 73.5% in the nearly mature class, and 86.6% in the mature class, which were 2.3% and 3.7%, respectively, higher than that of the latest YOLOv8s. The model included 8.6*10^6 network parameters with an inference speed of 18ms per image while the inference speed of YOLOv8s had a slower inference speed of 21.0ms and heavy parameters of 11.1*10^6, which indicates that the proposed model is fast enough for real time strawberry detection and localization for the robotic picking.
</details>
<details>
<summary>摘要</summary>
The dataset used in this study consisted of RGB images of strawberry canopies with three maturity classes (immature, nearly mature, and mature) collected in an open-field environment. The images were augmented using brightness reduction, brightness increase, and noise adding.To evaluate the performance of the proposed model, four competitive detection models (YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s) were trained and tested under the same computational environment. The results showed that the proposed model achieved the highest mean average precision of 80.3%, outperforming the other models by 3.7% to 7.3%. Specifically, the average precision of YOLOv5s-Straw was 82.1% in the immature class, 73.5% in the nearly mature class, and 86.6% in the mature class.The proposed model includes 8.6 million network parameters and has an inference speed of 18ms per image, which is fast enough for real-time strawberry detection and localization for robotic picking. In comparison, YOLOv8s has heavier parameters (11.1 million) and a slower inference speed (21.0ms).Overall, the proposed YOLOv5s-Straw model outperformed other state-of-the-art models for strawberry detection in open-field environments, and is a promising solution for robotic strawberry picking applications.
</details></li>
</ul>
<hr>
<h2 id="PARTNER-Level-up-the-Polar-Representation-for-LiDAR-3D-Object-Detection"><a href="#PARTNER-Level-up-the-Polar-Representation-for-LiDAR-3D-Object-Detection" class="headerlink" title="PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection"></a>PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03982">http://arxiv.org/abs/2308.03982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Nie, Yujing Xue, Chunwei Wang, Chaoqiang Ye, Hang Xu, Xinge Zhu, Qingqiu Huang, Michael Bi Mi, Xinchao Wang, Li Zhang</li>
<li>for: 提高3D物体探测器的精度和稳定性，特别是在流式探测和不同分辨率下。</li>
<li>methods: 使用极坐标系表示，并引入实例级别的几何信息来改进检测头，以解决非uniform分辨率所导致的特征扭曲问题。</li>
<li>results: 与前一代极坐标系方法相比，实现了3.68%和9.15%的显著提高在 Waymo 和 ONCE 验证集上，并在流式探测和不同分辨率下达到了竞争力的 результаados。<details>
<summary>Abstract</summary>
Recently, polar-based representation has shown promising properties in perceptual tasks. In addition to Cartesian-based approaches, which separate point clouds unevenly, representing point clouds as polar grids has been recognized as an alternative due to (1) its advantage in robust performance under different resolutions and (2) its superiority in streaming-based approaches. However, state-of-the-art polar-based detection methods inevitably suffer from the feature distortion problem because of the non-uniform division of polar representation, resulting in a non-negligible performance gap compared to Cartesian-based approaches. To tackle this issue, we present PARTNER, a novel 3D object detector in the polar coordinate. PARTNER alleviates the dilemma of feature distortion with global representation re-alignment and facilitates the regression by introducing instance-level geometric information into the detection head. Extensive experiments show overwhelming advantages in streaming-based detection and different resolutions. Furthermore, our method outperforms the previous polar-based works with remarkable margins of 3.68% and 9.15% on Waymo and ONCE validation set, thus achieving competitive results over the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
近些时间，基于极坐标的表示方法在认知任务中展现出了有前途的性能。除了使用坐标系分解的方法，即在不同的分辨率下分别处理点云，基于极坐标网格的表示方法被认为是一个有优势的选择，因为它们在不同的分辨率下具有robust性和流式处理的优势。然而，现状的极坐标基的检测方法无法避免特征扭曲问题，这是因为极坐标网格的非均匀分配引起的。为解决这个问题，我们提出了PARTNER，一种新的3D物体检测器。PARTNER通过重新调整全局表示和添加实例级别的几何信息来缓解特征扭曲问题，并且在检测头中进行了改进，以便更好地进行准确性。我们的方法在流式检测和不同的分辨率上具有了极大的优势，并且在 Waymo和ONCE验证集上比前一代极坐标基的方法有3.68%和9.15%的remarkable margins，从而实现了与当前最佳方法的竞争性。
</details></li>
</ul>
<hr>
<h2 id="PAIF-Perception-Aware-Infrared-Visible-Image-Fusion-for-Attack-Tolerant-Semantic-Segmentation"><a href="#PAIF-Perception-Aware-Infrared-Visible-Image-Fusion-for-Attack-Tolerant-Semantic-Segmentation" class="headerlink" title="PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation"></a>PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03979">http://arxiv.org/abs/2308.03979</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuzhu-cv/paif">https://github.com/liuzhu-cv/paif</a></li>
<li>paper_authors: Zhu Liu, Jinyuan Liu, Benzhuang Zhang, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 本研究旨在提高针对抗击的图像融合方法的分割稳定性。</li>
<li>methods: 本研究提出了一种感知响应的融合框架，通过系统性分析不同模式之间的相关性，并提出了一种协调结构来平衡标准准确率和鲁棒性。此外，还提出了一种适应学习策略来提高图像融合的参数鲁棒性，以便在多种抗击干扰下学习有效的特征提取。</li>
<li>results: 实验结果表明，我们的方案可以大幅提高分割稳定性，相比高级竞争者，增加了15.3%的mIOU分割精度。<details>
<summary>Abstract</summary>
Infrared and visible image fusion is a powerful technique that combines complementary information from different modalities for downstream semantic perception tasks. Existing learning-based methods show remarkable performance, but are suffering from the inherent vulnerability of adversarial attacks, causing a significant decrease in accuracy. In this work, a perception-aware fusion framework is proposed to promote segmentation robustness in adversarial scenes. We first conduct systematic analyses about the components of image fusion, investigating the correlation with segmentation robustness under adversarial perturbations. Based on these analyses, we propose a harmonized architecture search with a decomposition-based structure to balance standard accuracy and robustness. We also propose an adaptive learning strategy to improve the parameter robustness of image fusion, which can learn effective feature extraction under diverse adversarial perturbations. Thus, the goals of image fusion (\textit{i.e.,} extracting complementary features from source modalities and defending attack) can be realized from the perspectives of architectural and learning strategies. Extensive experimental results demonstrate that our scheme substantially enhances the robustness, with gains of 15.3% mIOU of segmentation in the adversarial scene, compared with advanced competitors. The source codes are available at https://github.com/LiuZhu-CV/PAIF.
</details>
<details>
<summary>摘要</summary>
infrared和可见图像融合是一种强大的技术，可以将不同modalities的补充信息结合以提高下游semantic perception任务的性能。现有的学习基于方法显示出惊人的表现，但是它们受到内置的敌意攻击的隐藏危险，导致准确性减少。在这种工作中，我们提出了一种感知 aware的融合框架，以提高 segmentation 的 Robustness 在敌意场景中。我们首先进行了系统的分析，探讨了不同modalities的图像融合组件与 segmentation 的相关性。基于这些分析，我们提出了一种协调结构，以平衡标准准确性和 Robustness。我们还提出了一种适应学习策略，以提高图像融合的参数Robustness，使其在多种敌意攻击下学习有效的特征提取。因此，我们的方案可以从architecture和学习策略的角度实现图像融合的两个目标：提取源modalities中的补充特征，并防止攻击。我们的实验结果表明，我们的方案可以大幅提高Robustness，与先进竞争对手相比，增加了15.3%的mIOU segmentation准确率。源代码可以在https://github.com/LiuZhu-CV/PAIF上获取。
</details></li>
</ul>
<hr>
<h2 id="PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning"><a href="#PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning" class="headerlink" title="PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning"></a>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03977">http://arxiv.org/abs/2308.03977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/pug">https://github.com/facebookresearch/pug</a></li>
<li>paper_authors: Florian Bordes, Shashank Shekhar, Mark Ibrahim, Diane Bouchacourt, Pascal Vincent, Ari S. Morcos</li>
<li>for: 这个论文旨在推广使用真实图像数据的问题，提出了一种使用游戏引擎生成高品质的 synthetic 图像数据，以便更好地训练和评估深度神经网络。</li>
<li>methods: 这篇论文使用了 Unreal Engine 游戏引擎，生成了高品质的 synthetic 图像数据，并为 representation learning 研究提供了一种可控、真实的图像环境。</li>
<li>results: 论文通过对多种视觉模型的评估，显示了 PUG 环境和数据集的可用性和有效性，并为研究人员提供了一种更加准确和可靠的评估方式。<details>
<summary>Abstract</summary>
Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>人工图像数据集具有无可比的优势，可以为深度神经网络的设计和评估带来很多便利：可以（i）生成无数量的数据样本，（ii）精确控制每个场景和获得细腻的标签和描述，（iii）在训练和测试中控制分布变化，以孤立变量。Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.Translation:人工图像数据集具有无可比的优势，可以为深度神经网络的设计和评估带来很多便利。可以（i）生成无数量的数据样本，（ii）精确控制每个场景和获得细腻的标签和描述，（iii）在训练和测试中控制分布变化，以孤立变量。尽管如此，使用人工图像数据的使用仍然受到限制——主要是因为它们缺乏实际性。大多数工作因此选择使用实际图像数据，这些数据经常从互联网上抓取，可能存在隐私、偏见和版权问题，而且无法控制对象的具体外观。在这个工作中，我们提出了一种路径，以使用PUG（真实无极图形）环境和数据集来进行表示学习研究。我们使用Unreal Engine游戏引擎，这是娱乐业界非常知名的游戏引擎，生成PUG环境和数据集。在这篇论文中，我们示出了PUG的潜在力量，以允许更加严格的评估视觉模型。
</details></li>
</ul>
<hr>
<h2 id="Prompted-Contrast-with-Masked-Motion-Modeling-Towards-Versatile-3D-Action-Representation-Learning"><a href="#Prompted-Contrast-with-Masked-Motion-Modeling-Towards-Versatile-3D-Action-Representation-Learning" class="headerlink" title="Prompted Contrast with Masked Motion Modeling: Towards Versatile 3D Action Representation Learning"></a>Prompted Contrast with Masked Motion Modeling: Towards Versatile 3D Action Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03975">http://arxiv.org/abs/2308.03975</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahang Zhang, Lilang Lin, Jiaying Liu</li>
<li>for: 本研究的目的是提出一种新的自动学习方法，用于解决人体动作理解中的骨架关系学习问题，这是一个重要 yet 挑战性的问题。</li>
<li>methods: 本研究使用了Prompted Contrast with Masked Motion Modeling（PCM$^{\rm 3}$）方法，它将对比学习和做牌预测任务相互补充，从而提高了对多个下游任务的泛化能力。</li>
<li>results: 实验结果表明，PCM$^{\rm 3}$ 方法在五个下游任务中的表现都superior于现有的状态之工作，特别是在三个大规模的数据集上。codes<details>
<summary>Abstract</summary>
Self-supervised learning has proved effective for skeleton-based human action understanding, which is an important yet challenging topic. Previous works mainly rely on contrastive learning or masked motion modeling paradigm to model the skeleton relations. However, the sequence-level and joint-level representation learning cannot be effectively and simultaneously handled by these methods. As a result, the learned representations fail to generalize to different downstream tasks. Moreover, combining these two paradigms in a naive manner leaves the synergy between them untapped and can lead to interference in training. To address these problems, we propose Prompted Contrast with Masked Motion Modeling, PCM$^{\rm 3}$, for versatile 3D action representation learning. Our method integrates the contrastive learning and masked prediction tasks in a mutually beneficial manner, which substantially boosts the generalization capacity for various downstream tasks. Specifically, masked prediction provides novel training views for contrastive learning, which in turn guides the masked prediction training with high-level semantic information. Moreover, we propose a dual-prompted multi-task pretraining strategy, which further improves model representations by reducing the interference caused by learning the two different pretext tasks. Extensive experiments on five downstream tasks under three large-scale datasets are conducted, demonstrating the superior generalization capacity of PCM$^{\rm 3}$ compared to the state-of-the-art works. Our project is publicly available at: https://jhang2020.github.io/Projects/PCM3/PCM3.html .
</details>
<details>
<summary>摘要</summary>
自我指导学习已经证明对人体动作理解是有效的，这是一个重要但也是具有挑战性的领域。先前的工作主要采用了对比学习或遮盖动作模型的概念学习方法来模型人体关系。然而，序列水平和联合水平的表示学习无法同时得到有效的处理。这导致学习表示失去泛化到不同的下游任务中。此外，将这两种方法在一种简单的方式结合可能会导致在训练中的干扰。为解决这些问题，我们提出了受提醒的对比学习与遮盖动作模型（PCM$^{\rm 3}$），用于多样化的3D动作表示学习。我们的方法将对比学习和遮盖预测任务融合在一起，从而增强模型的泛化能力 для多种下游任务。具体来说，遮盖预测提供了对比学习训练中的新的训练视图，而对比学习则帮助遮盖预测训练得到高级别semantic信息。此外，我们还提出了双重受提醒多任务预训练策略，可以降低学习两个不同预tex任务时的干扰。我们在三个大规模数据集上进行了五个下游任务的广泛实验，证明PCM$^{\rm 3}$的泛化能力较为先前的工作更高。我们的项目在https://jhang2020.github.io/Projects/PCM3/PCM3.html上公开可用。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-Skeleton-based-Action-Recognition-via-Mutual-Information-Estimation-and-Maximization"><a href="#Zero-shot-Skeleton-based-Action-Recognition-via-Mutual-Information-Estimation-and-Maximization" class="headerlink" title="Zero-shot Skeleton-based Action Recognition via Mutual Information Estimation and Maximization"></a>Zero-shot Skeleton-based Action Recognition via Mutual Information Estimation and Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03950">http://arxiv.org/abs/2308.03950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yujieouo/smie">https://github.com/yujieouo/smie</a></li>
<li>paper_authors: Yujie Zhou, Wenwen Qiang, Anyi Rao, Ning Lin, Bing Su, Jiaqi Wang</li>
<li>for: 这个研究目的是为了在训练seen类别的数据上进行zero-shot的动作识别，即识别未见类别的动作。</li>
<li>methods: 我们提出了一新的zero-shot skeleton-based action recognition方法，通过估计和最大化mutual information（MI）。 Specifically, 我们在visual和semantic空间之间实现了分布对齐，并且利用时间信息来增强动作的归一化。</li>
<li>results: 我们在三个大规模的skeleton action dataset上进行了广泛的实验，结果显示了我们的方法的有效性。<details>
<summary>Abstract</summary>
Zero-shot skeleton-based action recognition aims to recognize actions of unseen categories after training on data of seen categories. The key is to build the connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) the ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) the negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: https://github.com/YujieOuO/SMIE.
</details>
<details>
<summary>摘要</summary>
zero-shot骨干基于动作识别targets recognizing unseen categories after training on seen categories. The key is to build a connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: <https://github.com/YujieOuO/SMIE>.Here's the word-for-word translation of the text into Simplified Chinese: zero-shot骨干基于动作识别targetsRecognize unseen categories after training on seen categories. The key is to build a connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: <https://github.com/YujieOuO/SMIE>.
</details></li>
</ul>
<hr>
<h2 id="Deterministic-Neural-Illumination-Mapping-for-Efficient-Auto-White-Balance-Correction"><a href="#Deterministic-Neural-Illumination-Mapping-for-Efficient-Auto-White-Balance-Correction" class="headerlink" title="Deterministic Neural Illumination Mapping for Efficient Auto-White Balance Correction"></a>Deterministic Neural Illumination Mapping for Efficient Auto-White Balance Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03939">http://arxiv.org/abs/2308.03939</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/birdortyedi/denim">https://github.com/birdortyedi/denim</a></li>
<li>paper_authors: Furkan Kınlı, Doğa Yılmaz, Barış Özcan, Furkan Kıraç</li>
<li>for: 提供高速、高质量图像彩度 correction 解决方案</li>
<li>methods: 基于 deterministic color style transfer 的权重映射策略，具有 resolution-agnostic 特点，可整合任何预训练 AWB 网络</li>
<li>results: 实验结果表明，该方法可以实现至少 35 倍快的处理速度，并且与现有方法相当或更高的性能，在高分辨率图像上Here’s the breakdown of each point:1. 为什么：提供高速、高质量图像彩度 correction 解决方案2. 如何：基于 deterministic color style transfer 的权重映射策略，具有 resolution-agnostic 特点，可整合任何预训练 AWB 网络3. 结果：实验结果表明，该方法可以实现至少 35 倍快的处理速度，并且与现有方法相当或更高的性能，在高分辨率图像上<details>
<summary>Abstract</summary>
Auto-white balance (AWB) correction is a critical operation in image signal processors for accurate and consistent color correction across various illumination scenarios. This paper presents a novel and efficient AWB correction method that achieves at least 35 times faster processing with equivalent or superior performance on high-resolution images for the current state-of-the-art methods. Inspired by deterministic color style transfer, our approach introduces deterministic illumination color mapping, leveraging learnable projection matrices for both canonical illumination form and AWB-corrected output. It involves feeding high-resolution images and corresponding latent representations into a mapping module to derive a canonical form, followed by another mapping module that maps the pixel values to those for the corrected version. This strategy is designed as resolution-agnostic and also enables seamless integration of any pre-trained AWB network as the backbone. Experimental results confirm the effectiveness of our approach, revealing significant performance improvements and reduced time complexity compared to state-of-the-art methods. Our method provides an efficient deep learning-based AWB correction solution, promising real-time, high-quality color correction for digital imaging applications. Source code is available at https://github.com/birdortyedi/DeNIM/
</details>
<details>
<summary>摘要</summary>
自动白平衡（AWB）修正是图像信号处理中的关键操作，以确保图像彩色 corrections 在不同照明场景下具有准确性和一致性。本文描述了一种新的和高效的 AWB 修正方法，可以在高分辨率图像上实现至少35倍的处理速度，与现有方法相当或更好的性能。我们的方法基于权值映射矩阵，通过学习映射矩阵来实现权值映射，并将其应用于AWB修正输出。我们的方法包括将高分辨率图像和相应的秘密表示 feed 到映射模块，以 derivation 一个征准形式，然后另一个映射模块将像素值映射到AWB修正后的像素值。这种策略是解决分辨率不依赖的，同时也可以轻松地将任何预训练的AWB网络作为后ION。实验结果表明我们的方法的有效性，表明与现有方法相比，具有显著的性能提升和处理时间减少。我们的方法提供了一种高效的深度学习基于AWB修正解决方案，承诺实时、高质量彩色修正 для数字摄影应用。代码可以在 <https://github.com/birdortyedi/DeNIM/> 上获取。
</details></li>
</ul>
<hr>
<h2 id="TIJO-Trigger-Inversion-with-Joint-Optimization-for-Defending-Multimodal-Backdoored-Models"><a href="#TIJO-Trigger-Inversion-with-Joint-Optimization-for-Defending-Multimodal-Backdoored-Models" class="headerlink" title="TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models"></a>TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03906">http://arxiv.org/abs/2308.03906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha</li>
<li>for: 防止多 modal 模型中的 dual-key 后门攻击</li>
<li>methods: 使用 joint optimization 技术来反向工程 trigger，并在图像和文本模式之间进行协调优化</li>
<li>results: 在 TrojVQA 测试集上，TIJO 方法可以减少 dual-key 后门攻击的攻击效果，并且在单模态后门攻击中也表现出良好的效果<details>
<summary>Abstract</summary>
We present a Multimodal Backdoor Defense technique TIJO (Trigger Inversion using Joint Optimization). Recent work arXiv:2112.07668 has demonstrated successful backdoor attacks on multimodal models for the Visual Question Answering task. Their dual-key backdoor trigger is split across two modalities (image and text), such that the backdoor is activated if and only if the trigger is present in both modalities. We propose TIJO that defends against dual-key attacks through a joint optimization that reverse-engineers the trigger in both the image and text modalities. This joint optimization is challenging in multimodal models due to the disconnected nature of the visual pipeline which consists of an offline feature extractor, whose output is then fused with the text using a fusion module. The key insight enabling the joint optimization in TIJO is that the trigger inversion needs to be carried out in the object detection box feature space as opposed to the pixel space. We demonstrate the effectiveness of our method on the TrojVQA benchmark, where TIJO improves upon the state-of-the-art unimodal methods from an AUC of 0.6 to 0.92 on multimodal dual-key backdoors. Furthermore, our method also improves upon the unimodal baselines on unimodal backdoors. We present ablation studies and qualitative results to provide insights into our algorithm such as the critical importance of overlaying the inverted feature triggers on all visual features during trigger inversion. The prototype implementation of TIJO is available at https://github.com/SRI-CSL/TIJO.
</details>
<details>
<summary>摘要</summary>
我们提出了一种多模态后门防御技术TIJO（Trigger Inversion using Joint Optimization）。在最近的arXiv:2112.07668中，我们已经成功地实现了对多模态模型的后门攻击。这个后门触发器被分解成两个模式（图像和文本），只有在两个模式中都存在触发器时才会启动后门。我们的TIJO技术利用联合优化来防御双钥匙攻击，通过在图像和文本模式中对触发器进行反向工程。这个联合优化在多模态模型中是具有挑战性的，因为视觉管道中的数据都是独立的，包括一个离线特征提取器，其输出然后与文本模式进行融合。我们的关键发现是，在对触发器进行反向工程时，应该在图像特征空间进行，而不是像素空间。我们在TrojVQA benchmark上证明了TIJO的有效性，其在多模态双钥匙后门上从AUC 0.6提高到0.92，并且在单模态后门上也超过了单模态基线。我们还提供了简要的ablation study和Qualitative results，以便更好地理解我们的算法，如果在触发器反向工程中 overlaying 翻译的特征Trigger。TIJO的原型实现可以在https://github.com/SRI-CSL/TIJO中找到。
</details></li>
</ul>
<hr>
<h2 id="Developability-Approximation-for-Neural-Implicits-through-Rank-Minimization"><a href="#Developability-Approximation-for-Neural-Implicits-through-Rank-Minimization" class="headerlink" title="Developability Approximation for Neural Implicits through Rank Minimization"></a>Developability Approximation for Neural Implicits through Rank Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03900">http://arxiv.org/abs/2308.03900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratheba Selvaraju</li>
<li>for: 该论文主要用于开发一种可以从二维面上无撕、无扭的三维表面的方法。</li>
<li>methods: 该方法基于神经隐函数，并通过添加一个正则化项来促进zero Gaussian curvature。</li>
<li>results: 实验结果表明，该方法可以准确地重建开发可能的表面，并且可以在受到噪声影响的情况下保持一定的精度。<details>
<summary>Abstract</summary>
Developability refers to the process of creating a surface without any tearing or shearing from a two-dimensional plane. It finds practical applications in the fabrication industry. An essential characteristic of a developable 3D surface is its zero Gaussian curvature, which means that either one or both of the principal curvatures are zero. This paper introduces a method for reconstructing an approximate developable surface from a neural implicit surface. The central idea of our method involves incorporating a regularization term that operates on the second-order derivatives of the neural implicits, effectively promoting zero Gaussian curvature. Implicit surfaces offer the advantage of smoother deformation with infinite resolution, overcoming the high polygonal constraints of state-of-the-art methods using discrete representations. We draw inspiration from the properties of surface curvature and employ rank minimization techniques derived from compressed sensing. Experimental results on both developable and non-developable surfaces, including those affected by noise, validate the generalizability of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化字符的中文。<</SYS>>发展可能性指的是将二维面变换为无撕裂、无剪裂的三维表面的过程。它在制造业中有实际应用。一个必要的特征是发展可能性表面的零 Gaussian 几何，这意味着一或两个主要几何都是零。这篇论文介绍了一种使用神经隐式函数来重建精确的发展可能性表面的方法。我们的中心思想是在神经隐式函数的第二阶导数上添加一个正则化项，以实现零 Gaussian 几何。隐式表面具有较平滑的变形和无限分辨率的优势，超越了现有方法使用分割表示的高 polygon 约束。我们启发自表面几何的属性，并使用压缩感知技术来解决矩阵问题。实验结果表明，我们的方法在发展可能性表面和非发展可能性表面，包括受噪声影响的情况下，具有普适性。
</details></li>
</ul>
<hr>
<h2 id="From-Sky-to-the-Ground-A-Large-scale-Benchmark-and-Simple-Baseline-Towards-Real-Rain-Removal"><a href="#From-Sky-to-the-Ground-A-Large-scale-Benchmark-and-Simple-Baseline-Towards-Real-Rain-Removal" class="headerlink" title="From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal"></a>From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03867">http://arxiv.org/abs/2308.03867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunguo224/lhp-rain">https://github.com/yunguo224/lhp-rain</a></li>
<li>paper_authors: Yun Guo, Xueyao Xiao, Yi Chang, Shumin Deng, Luxin Yan</li>
<li>For: 提高实际雨天图像涂抹（RID）的进步，增加大规模高质量配对训练样本。* Methods: 构建了一个大规模高质量配对雨天图像数据集（LHP-Rain），包括3000个视频序列，100万高分辨率（1920<em>1080）帧对。提出了一种新的稳定低级 tensor 恢复模型，生成更好地分离静背景和动雨。设计了一种简单的 transformer 基于单图雨涂抹基线，同时利用自身关注和跨层关注，具有捕捉特征表示。</em> Results: 对比 existing 方法，提出的 dataset 和 deraining 方法具有显著的优势，在雨天图像涂抹任务中具有更高的性能。<details>
<summary>Abstract</summary>
Learning-based image deraining methods have made great progress. However, the lack of large-scale high-quality paired training samples is the main bottleneck to hamper the real image deraining (RID). To address this dilemma and advance RID, we construct a Large-scale High-quality Paired real rain benchmark (LHP-Rain), including 3000 video sequences with 1 million high-resolution (1920*1080) frame pairs. The advantages of the proposed dataset over the existing ones are three-fold: rain with higher-diversity and larger-scale, image with higher-resolution and higher-quality ground-truth. Specifically, the real rains in LHP-Rain not only contain the classical rain streak/veiling/occlusion in the sky, but also the \textbf{splashing on the ground} overlooked by deraining community. Moreover, we propose a novel robust low-rank tensor recovery model to generate the GT with better separating the static background from the dynamic rain. In addition, we design a simple transformer-based single image deraining baseline, which simultaneously utilize the self-attention and cross-layer attention within the image and rain layer with discriminative feature representation. Extensive experiments verify the superiority of the proposed dataset and deraining method over state-of-the-art.
</details>
<details>
<summary>摘要</summary>
学习基于的图像雨排除方法已经做出了大量的进步。然而，缺乏大规模高质量对应训练样本是阻碍真实图像雨排除（RID）的主要瓶颈。为解决这个困难和提高RID，我们构建了大规模高质量对应雨天 benchmark（LHP-Rain），包括3000个视频序列和100万高分辨率（1920*1080）帧对。LHP-Rain中的雨水比现有的 dataset 更多样化和大规模，图像质量更高，附加的雨水ground truth 更加准确。具体来说，LHP-Rain 中的雨水不仅包括天空中的класси型雨条/遮盲/占据，还包括在地面上的溅射，这一点在雨排除社区中很少被考虑。此外，我们提出了一种新的robust低级张量回归模型，用于生成更加分离静态背景和动态雨水的GT。此外，我们设计了一种简单的 transformer 基于的单图像雨排除基线，同时利用自身关注和跨层关注，在图像和雨层中同时使用特征表示。广泛的实验证明了我们提出的数据集和雨排除方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction"><a href="#DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction" class="headerlink" title="DefCor-Net: Physics-Aware Ultrasound Deformation Correction"></a>DefCor-Net: Physics-Aware Ultrasound Deformation Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03865">http://arxiv.org/abs/2308.03865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karolinezhy/defcornet">https://github.com/karolinezhy/defcornet</a></li>
<li>paper_authors: Zhongliang Jiang, Yue Zhou, Dongliang Cao, Nassir Navab</li>
<li>for: 这篇论文的目的是对于ultrasound（US）图像取得中的形状扭曲进行修正，以提高诊断的精度和一致性。</li>
<li>methods: 这篇论文提出了一个基于多对多深度学习网络（DefCor-Net）的新型生物学知识感知扭曲修正方法。这个方法通过在粗细对称的特征提取器中进行精确的缩寸推导，以便在当前测量力的基础上线性回归扭曲场。</li>
<li>results: 根据实验结果显示，DefCor-Net可以对于US图像进行高精度的形状修正，从而回复原始的几何结构（Dice Coefficient：从 $14.3\pm20.9$ 提高至 $82.6\pm12.1$，当力量为 $6N$）。<details>
<summary>Abstract</summary>
The recovery of morphologically accurate anatomical images from deformed ones is challenging in ultrasound (US) image acquisition, but crucial to accurate and consistent diagnosis, particularly in the emerging field of computer-assisted diagnosis. This article presents a novel anatomy-aware deformation correction approach based on a coarse-to-fine, multi-scale deep neural network (DefCor-Net). To achieve pixel-wise performance, DefCor-Net incorporates biomedical knowledge by estimating pixel-wise stiffness online using a U-shaped feature extractor. The deformation field is then computed using polynomial regression by integrating the measured force applied by the US probe. Based on real-time estimation of pixel-by-pixel tissue properties, the learning-based approach enables the potential for anatomy-aware deformation correction. To demonstrate the effectiveness of the proposed DefCor-Net, images recorded at multiple locations on forearms and upper arms of six volunteers are used to train and validate DefCor-Net. The results demonstrate that DefCor-Net can significantly improve the accuracy of deformation correction to recover the original geometry (Dice Coefficient: from $14.3\pm20.9$ to $82.6\pm12.1$ when the force is $6N$).
</details>
<details>
<summary>摘要</summary>
“ ultrasound（US）图像获取中，形态准确性的图像恢复是一项挑战，但是对医学诊断的准确性和一致性具有极高的重要性，特别是在计算机助动诊断领域。本文提出了一种基于多尺度深度神经网络（DefCor-Net）的新型形态意识恢复方法。为了实现像素级的表现，DefCor-Net在核心网络中包含生物医学知识，并且在线计算每个像素的刚性。通过把测量US探针所应用的力场 интеグрирова到多元函数回归，DefCor-Net计算出了形态场。基于实时测量每个像素的组织特性，这种学习基于的方法具有潜在的形态意识恢复能力。为证明DefCor-Net的有效性，使用了多个臂和肘的六名志愿者所记录的图像进行训练和验证。结果显示，DefCor-Net可以显著改善对形态恢复的准确性（Dice Coefficient：从14.3±20.9到82.6±12.1，当力场为6N）。”Note: The translation is in Simplified Chinese, which is the standardized form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="High-Throughput-and-Accurate-3D-Scanning-of-Cattle-Using-Time-of-Flight-Sensors-and-Deep-Learning"><a href="#High-Throughput-and-Accurate-3D-Scanning-of-Cattle-Using-Time-of-Flight-Sensors-and-Deep-Learning" class="headerlink" title="High-Throughput and Accurate 3D Scanning of Cattle Using Time-of-Flight Sensors and Deep Learning"></a>High-Throughput and Accurate 3D Scanning of Cattle Using Time-of-Flight Sensors and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03861">http://arxiv.org/abs/2308.03861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gbenga Omotara, Seyed Mohamad Ali Tousi, Jared Decker, Derek Brake, Guilherme N. DeSouza</li>
<li>for: 这个论文是为了开发一种高速三维扫描解决方案，用于准确测量牛的形态特征。</li>
<li>methods: 这个系统使用了一个数组深度感知器，包括时间探测（Tof）感知器，每个感知器都由专门的嵌入式设备控制。系统能够生成高质量的3D点云，从而生成高精度的牛形态模型。</li>
<li>results: 根据实验结果，提出的系统能够生成高质量的牛形态模型，并且可以准确测量牛的体积和表面积。<details>
<summary>Abstract</summary>
We introduce a high throughput 3D scanning solution specifically designed to precisely measure cattle phenotypes. This scanner leverages an array of depth sensors, i.e. time-of-flight (Tof) sensors, each governed by dedicated embedded devices. The system excels at generating high-fidelity 3D point clouds, thus facilitating an accurate mesh that faithfully reconstructs the cattle geometry on the fly. In order to evaluate the performance of our system, we have implemented a two-fold validation process. Initially, we test the scanner's competency in determining volume and surface area measurements within a controlled environment featuring known objects. Secondly, we explore the impact and necessity of multi-device synchronization when operating a series of time-of-flight sensors. Based on the experimental results, the proposed system is capable of producing high-quality meshes of untamed cattle for livestock studies.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种高通量3D扫描解决方案，专门为精确测量牛phenotype提供。这个扫描仪使用了一组深度感知器，即时光探测（ToF）感知器，每个感知器由专门的嵌入式设备控制。系统能够生成高品质3D点云，从而实现精确重建牛体均匀的三维模型。为评估我们的系统性能，我们实施了两重验证过程。首先，我们测试了扫描仪在控制台上测量物体体积和表面积的能力。其次，我们探索了在多个时光探测感知器同时运行时的多设备同步的影响和必要性。根据实验结果，我们的系统能够生成高质量牛体三维模型，为畜牧学研究提供有价值的数据。
</details></li>
</ul>
<hr>
<h2 id="3D-Motion-Magnification-Visualizing-Subtle-Motions-with-Time-Varying-Radiance-Fields"><a href="#3D-Motion-Magnification-Visualizing-Subtle-Motions-with-Time-Varying-Radiance-Fields" class="headerlink" title="3D Motion Magnification: Visualizing Subtle Motions with Time Varying Radiance Fields"></a>3D Motion Magnification: Visualizing Subtle Motions with Time Varying Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03757">http://arxiv.org/abs/2308.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Y. Feng, Hadi Alzayer, Michael Rubinstein, William T. Freeman, Jia-Bin Huang</li>
<li>for: 这个论文旨在帮助我们更好地视觉化某些不可见的运动，尤其是在运动camera中捕捉的场景中。</li>
<li>methods: 该论文提出了一种基于时变辐射场的3D动态扩大方法，可以在运动camera中捕捉的场景中增强微不可见的运动。该方法基于律动原理，通过EXTRACT和增强 embedding点的变化来实现动态扩大。</li>
<li>results: 该论文通过使用不同的场景和摄像头设置进行了研究和验证，并证明了其效果。<details>
<summary>Abstract</summary>
Motion magnification helps us visualize subtle, imperceptible motion. However, prior methods only work for 2D videos captured with a fixed camera. We present a 3D motion magnification method that can magnify subtle motions from scenes captured by a moving camera, while supporting novel view rendering. We represent the scene with time-varying radiance fields and leverage the Eulerian principle for motion magnification to extract and amplify the variation of the embedding of a fixed point over time. We study and validate our proposed principle for 3D motion magnification using both implicit and tri-plane-based radiance fields as our underlying 3D scene representation. We evaluate the effectiveness of our method on both synthetic and real-world scenes captured under various camera setups.
</details>
<details>
<summary>摘要</summary>
运动增大帮助我们可见到微不足的运动。然而，先前的方法只适用于 fix 摄像机拍摄的 2D 视频。我们提出了一种支持新视图渲染的3D 运动增大方法，可以增大 captured by a moving camera 中的微不足运动。我们使用时间变化的辐射场来表示场景，并利用儒利安理则来提取和增强时间上点的变化。我们对使用 implicit 和 tri-plane-based 辐射场作为场景表示方法进行了研究和验证。我们对具有不同摄像机设置的 both synthetic 和实际场景进行了评估。
</details></li>
</ul>
<hr>
<h2 id="FSD-V2-Improving-Fully-Sparse-3D-Object-Detection-with-Virtual-Voxels"><a href="#FSD-V2-Improving-Fully-Sparse-3D-Object-Detection-with-Virtual-Voxels" class="headerlink" title="FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels"></a>FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03755">http://arxiv.org/abs/2308.03755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tusen-ai/sst">https://github.com/tusen-ai/sst</a></li>
<li>paper_authors: Lue Fan, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</li>
<li>for: 这篇论文目的是提出一种简化FSDv1的方法，以提高其普适性和性能。</li>
<li>methods: 这篇论文使用了虚拟voxel的概念，取代了FSDv1中的归一化实例分割。虚拟voxel不仅能解决完全稀缺探测器中的中心特征缺失问题，还使得框架更加简洁和流畅。</li>
<li>results: 这篇论文在三个大规模数据集上进行了实验，包括Waymo开放数据集、Argoverse 2数据集和nuScenes数据集。结果显示FSDv2在长距离场景中表现出色，并在多种场景中具有竞争性的性能。此外，论文还提供了详细的实验分析，以便促进可重复性和进一步研究。<details>
<summary>Abstract</summary>
LiDAR-based fully sparse architecture has garnered increasing attention. FSDv1 stands out as a representative work, achieving impressive efficacy and efficiency, albeit with intricate structures and handcrafted designs. In this paper, we present FSDv2, an evolution that aims to simplify the previous FSDv1 while eliminating the inductive bias introduced by its handcrafted instance-level representation, thus promoting better general applicability. To this end, we introduce the concept of \textbf{virtual voxels}, which takes over the clustering-based instance segmentation in FSDv1. Virtual voxels not only address the notorious issue of the Center Feature Missing problem in fully sparse detectors but also endow the framework with a more elegant and streamlined approach. Consequently, we develop a suite of components to complement the virtual voxel concept, including a virtual voxel encoder, a virtual voxel mixer, and a virtual voxel assignment strategy. Through empirical validation, we demonstrate that the virtual voxel mechanism is functionally similar to the handcrafted clustering in FSDv1 while being more general. We conduct experiments on three large-scale datasets: Waymo Open Dataset, Argoverse 2 dataset, and nuScenes dataset. Our results showcase state-of-the-art performance on all three datasets, highlighting the superiority of FSDv2 in long-range scenarios and its general applicability to achieve competitive performance across diverse scenarios. Moreover, we provide comprehensive experimental analysis to elucidate the workings of FSDv2. To foster reproducibility and further research, we have open-sourced FSDv2 at https://github.com/tusen-ai/SST.
</details>
<details>
<summary>摘要</summary>
“LiDAR-based弹性探测 Architecture 在最近得到了增加的注意。FSDv1 作为代表性的工作，成功地实现了出色的效率和可靠性，但具有复杂的结构和手工设计。在这篇论文中，我们提出 FSDv2，它是 FSDv1 的进化，旨在简化前一代的结构，消除实例级别表示所引入的预设偏见，以提高更好的通用性。为此，我们引入了“虚拟小体”概念，取代 FSDv1 中的弹性分割。虚拟小体不仅解决了完全缺失中心特征问题，还赋予框架更加简洁和流畅的方式。为此，我们开发了一套辅助虚拟小体的组件，包括虚拟小体编码器、虚拟小体混合器和虚拟小体分配策略。通过实验验证，我们证明虚拟小体机制与 FSDv1 中手工 clustering 功能相似，但更加通用。我们在 Waymo Open Dataset、Argoverse 2 dataset 和 nuScenes dataset 上进行了实验，我们的结果显示 FSDv2 在长距离场景中具有状态机器人的性能，并在多种场景中实现了竞争性的表现。此外，我们进行了全面的实验分析，以便更好地解释 FSDv2 的工作原理。为了促进可重复性和进一步研究，我们将 FSDv2 开源在 GitHub 上，请参考 <https://github.com/tusen-ai/SST>。”
</details></li>
</ul>
<hr>
<h2 id="Mask-Frozen-DETR-High-Quality-Instance-Segmentation-with-One-GPU"><a href="#Mask-Frozen-DETR-High-Quality-Instance-Segmentation-with-One-GPU" class="headerlink" title="Mask Frozen-DETR: High Quality Instance Segmentation with One GPU"></a>Mask Frozen-DETR: High Quality Instance Segmentation with One GPU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03747">http://arxiv.org/abs/2308.03747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanhao Liang, Yuhui Yuan</li>
<li>for: 研究如何建立具有最小训练时间和GPU资源的强大实例分割模型，而不是现有的大多数方法尝试通过建立更复杂的框架来提高实例分割模型的准确率，以及这种方法的简单性和通用性。</li>
<li>methods: 我们提出了一种简单的普适框架，称为Mask Frozen-DETR，可以将任何现有的DETR基于对象检测模型转换成强大的实例分割模型。我们的方法仅需训练一个轻量级的mask网络，该网络在固定DETR基于对象检测器的 bounding box 中预测实例mask。</li>
<li>results: 我们的方法在COCO测试数据集上的测试预测中，与状态当前的实例分割方法Mask DINO相比，提高了性能（55.3% vs. 54.7%），并且在训练时间和GPU资源上减少了训练时间的多少（10X）。此外，我们的所有实验都可以使用一个Tesla V100 GPU With 16 GB的内存进行训练，表明了我们提出的框架的显著高效性。<details>
<summary>Abstract</summary>
In this paper, we aim to study how to build a strong instance segmenter with minimal training time and GPUs, as opposed to the majority of current approaches that pursue more accurate instance segmenter by building more advanced frameworks at the cost of longer training time and higher GPU requirements. To achieve this, we introduce a simple and general framework, termed Mask Frozen-DETR, which can convert any existing DETR-based object detection model into a powerful instance segmentation model. Our method only requires training an additional lightweight mask network that predicts instance masks within the bounding boxes given by a frozen DETR-based object detector. Remarkably, our method outperforms the state-of-the-art instance segmentation method Mask DINO in terms of performance on the COCO test-dev split (55.3% vs. 54.7%) while being over 10X times faster to train. Furthermore, all of our experiments can be trained using only one Tesla V100 GPU with 16 GB of memory, demonstrating the significant efficiency of our proposed framework.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们目的是研究如何使用最少的训练时间和GPU来构建一个强大的实例分割器，而不是现有的大多数方法，它们通过建立更高级的框架来提高实例分割器的准确率，但是这会导致训练时间更长和GPU需求更高。为此，我们提出了一个简单和通用的框架，称为Mask Frozen-DETR，它可以将任何现有的DETR基于对象检测模型转化成一个强大的实例分割模型。我们的方法只需训练一个轻量级的面网络，该网络可以在冻结的DETR基于对象检测模型提供的 bounding box 内预测实例面。值得注意的是，我们的方法在 COCO 测试发展集上比 state-of-the-art 实例分割方法 Mask DINO 高出0.6%的性能（55.3% vs. 54.7%），而且训练时间比 Mask DINO 快上10倍。此外，我们所有的实验都可以使用单个 Tesla V100 GPU  WITH 16 GB 内存进行训练，这表明我们提出的方法具有显著的效率。
</details></li>
</ul>
<hr>
<h2 id="AdaptiveSAM-Towards-Efficient-Tuning-of-SAM-for-Surgical-Scene-Segmentation"><a href="#AdaptiveSAM-Towards-Efficient-Tuning-of-SAM-for-Surgical-Scene-Segmentation" class="headerlink" title="AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation"></a>AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03726">http://arxiv.org/abs/2308.03726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jayparanjape/biastuning">https://github.com/jayparanjape/biastuning</a></li>
<li>paper_authors: Jay N. Paranjape, Nithin Gopalakrishnan Nair, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel<br>for:这篇论文是为了解决人工智能在外科Scene分析中的基本问题，即数据稀缺性问题。methods:这篇论文提出了一种基于Segment-Anything（SAM）模型的适应方法，即AdaptiveSAM，可以快速地适应新的数据集，同时允许文本提示分割。results:实验表明，AdaptiveSAM可以在各种医学影像数据集上出perform better than当前状态的方法，包括手术、超声和X射线等。<details>
<summary>Abstract</summary>
Segmentation is a fundamental problem in surgical scene analysis using artificial intelligence. However, the inherent data scarcity in this domain makes it challenging to adapt traditional segmentation techniques for this task. To tackle this issue, current research employs pretrained models and finetunes them on the given data. Even so, these require training deep networks with millions of parameters every time new data becomes available. A recently published foundation model, Segment-Anything (SAM), generalizes well to a large variety of natural images, hence tackling this challenge to a reasonable extent. However, SAM does not generalize well to the medical domain as is without utilizing a large amount of compute resources for fine-tuning and using task-specific prompts. Moreover, these prompts are in the form of bounding-boxes or foreground/background points that need to be annotated explicitly for every image, making this solution increasingly tedious with higher data size. In this work, we propose AdaptiveSAM - an adaptive modification of SAM that can adjust to new datasets quickly and efficiently, while enabling text-prompted segmentation. For finetuning AdaptiveSAM, we propose an approach called bias-tuning that requires a significantly smaller number of trainable parameters than SAM (less than 2\%). At the same time, AdaptiveSAM requires negligible expert intervention since it uses free-form text as prompt and can segment the object of interest with just the label name as prompt. Our experiments show that AdaptiveSAM outperforms current state-of-the-art methods on various medical imaging datasets including surgery, ultrasound and X-ray. Code is available at https://github.com/JayParanjape/biastuning
</details>
<details>
<summary>摘要</summary>
划分是跨域诊断中的基本问题，但由于医学领域数据的稀缺性，使得传统划分技术难以适应这个任务。为解决这个问题，当前的研究通常使用预训练模型，并对其进行微调。然而，这需要训练深度网络数百万个参数，每次新数据available时需要重新训练。一个最近发表的基础模型Segment-Anything（SAM）能够通用于各种自然图像，因此有所减轻这个问题。然而，SAM在医学领域中不具备泛化能力，需要大量计算资源进行微调，并使用任务特有的提示。这些提示通常是 bounding-boxes 或 foreground/background 点，需要明确标注每个图像，这使得该解决方案难以扩展。在这项工作中，我们提出了 AdaptiveSAM，一种适应型的 SAM 修改。AdaptiveSAM 可以快速地适应新的数据集，而且可以通过自由文本提示进行文本识别。我们还提出了一种偏好调整方法，可以在微调 AdaptiveSAM 时减少参数的数量，至少比 SAM 少于 2%。同时，AdaptiveSAM 需要非常少的专家干预，因为它使用自由文本提示，并且可以通过对象关键词来 segment 目标对象。我们的实验表明，AdaptiveSAM 在各种医学成像数据集上表现出色，包括手术、ultrasound 和 X-ray。代码可以在 https://github.com/JayParanjape/biastuning 上获取。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Temporal-Sentence-Grounding-in-Videos-with-Multi-Teacher-Knowledge-Distillation"><a href="#Efficient-Temporal-Sentence-Grounding-in-Videos-with-Multi-Teacher-Knowledge-Distillation" class="headerlink" title="Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation"></a>Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03725">http://arxiv.org/abs/2308.03725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renjie Liang, Yiming Yang, Hui Lu, Li Li</li>
<li>for: 本研究旨在探讨如何从未处理过的视频中检测自然语言查询中描述的事件时间戳，并提出一种高效的方法。</li>
<li>methods: 该研究提出了一种基于知识储存的高效多教师模型（EMTM），通过将多种不同的网络结构融合到一起，以提高计算效率而不失效果。</li>
<li>results: 实验结果表明，该方法可以在三个常用的TSGV测试集上达到高效性和精度的平衡，而无需使用复杂的架构和损失函数。<details>
<summary>Abstract</summary>
Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Automated-Real-Time-Delineation-of-Supraclavicular-Brachial-Plexus-in-Neck-Ultrasonography-Videos-A-Deep-Learning-Approach"><a href="#Automated-Real-Time-Delineation-of-Supraclavicular-Brachial-Plexus-in-Neck-Ultrasonography-Videos-A-Deep-Learning-Approach" class="headerlink" title="Automated Real Time Delineation of Supraclavicular Brachial Plexus in Neck Ultrasonography Videos: A Deep Learning Approach"></a>Automated Real Time Delineation of Supraclavicular Brachial Plexus in Neck Ultrasonography Videos: A Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03717">http://arxiv.org/abs/2308.03717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhay Tyagi, Abhishek Tyagi, Manpreet Kaur, Jayanthi Sivaswami, Richa Aggarwal, Kapil Dev Soni, Anjan Trikha</li>
<li>for: 这个研究是为了探索使用深度学习模型来进行 neck ultrasound 影像中的副claviicular brachial plexus 的现场分类，以提高医疗执行者对这些影像的识别和分类能力。</li>
<li>methods: 这个研究使用了三种不同的 ultrasound 机器，将227个系统扫描到supraclavicular和interscalene brachial plexus 的不同设定中，共产生了227个唯一的影像视频。这些影像被227名经验丰富的医生评估和标注，并使用了部分自动化的物件追踪和活动曲线算法来标注影像。</li>
<li>results: 研究结果显示，使用深度学习模型可以实现高准确性和可靠性的现场分类，并且可以区别supraclavicular和邻近的interscalene brachial plexus。此外，研究也显示了不同的 ultrasound 机器的影像数据集可以通过精致化和无需精致化的方法来进行数据集的整合和标注。<details>
<summary>Abstract</summary>
Peripheral nerve blocks are crucial to treatment of post-surgical pain and are associated with reduction in perioperative opioid use and hospital stay. Accurate interpretation of sono-anatomy is critical for the success of ultrasound (US) guided peripheral nerve blocks and can be challenging to the new operators. This prospective study enrolled 227 subjects who were systematically scanned for supraclavicular and interscalene brachial plexus in various settings using three different US machines to create a dataset of 227 unique videos. In total, 41,000 video frames were annotated by experienced anaesthesiologists using partial automation with object tracking and active contour algorithms. Four baseline neural network models were trained on the dataset and their performance was evaluated for object detection and segmentation tasks. Generalizability of the best suited model was then tested on the datasets constructed from separate US scanners with and without fine-tuning. The results demonstrate that deep learning models can be leveraged for real time segmentation of supraclavicular brachial plexus in neck ultrasonography videos with high accuracy and reliability. Model was also tested for its ability to differentiate between supraclavicular and adjoining interscalene brachial plexus. The entire dataset has been released publicly for further study by the research community.
</details>
<details>
<summary>摘要</summary>
périphériques nerve blocks sont essentielles pour le traitement de la douleur postopératoire et sont associées à une réduction de l'utilisation de morphiniques periopératoires et de la durée de hospitalisation. L'interprétation accurate de la sono-anatomie est critique pour le succès des blocks nerveuses guidées par ultrason (US) et peut être challengeante pour les nouveaux opérateurs. Cette étude prospective a enrôlé 227 sujets qui ont été systématiquement scannés pour le plexus brachial supraclaviculaire et interscapulin au moyen de trois machines US différentes pour créer un ensemble de 227 vidéos uniques. Au total, 41 000 cadres de vidéo ont été annotés par des anesthésiologistes expérimentés utilisant une partial automation avec des algorithmes de suivi d'objets et de contours actifs. Quatre modèles de réseaux de neurones basiques ont été entraînés sur le dataset et leur performance a été évaluée pour les tâches de détection et de segmentation d'objets. La généralisation du modèle le plus adapté a été testée sur les données constructives de scanners US différents, avec et sans fine-tuning. Les résultats montrent que les modèles d'apprentissage profond peuvent être utilisés pour la segmentation en temps réel du plexus brachial supraclaviculaire dans les vidéos d'ultrasonographie du cou avec une précision et une fiabilité élevées. Le modèle a également été testé pour sa capacité à distinguer entre le plexus brachial supraclaviculaire et l'adjoignant plexus interscapulin. Le tout dataset a été libéré au public pour une étude supplémentaire par la communauté de la recherche.
</details></li>
</ul>
<hr>
<h2 id="Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience"><a href="#Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience" class="headerlink" title="Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience"></a>Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03712">http://arxiv.org/abs/2308.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eminorhan/humanlike-vits">https://github.com/eminorhan/humanlike-vits</a></li>
<li>paper_authors: A. Emin Orhan</li>
<li>for: 这种研究是为了检验当今自动学习方法是否可以通过增加数据量和模型大小来达到人类级视觉对象识别能力。</li>
<li>methods: 这种研究使用了掩Masked autoencoders (MAEs)作为自动学习算法，并在增加数据量、模型大小和图像分辨率的情况下进行了涨scale experiment。</li>
<li>results: 研究发现，通过同时增加数据量、模型大小和图像分辨率，可以达到人类级视觉对象识别能力，但需要在模型大小、数据量和图像分辨率的增加中同步进行调整。例如，一个2.5B参数的ViT模型，通过20K小时（2.3年）的人类类视频数据和952x952像素的空间分辨率进行训练，应该可以达到人类级准确率在ImageNet。<details>
<summary>Abstract</summary>
This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach roughly human-level accuracy on ImageNet. Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Prototype-Learning-for-Out-of-Distribution-Polyp-Segmentation"><a href="#Prototype-Learning-for-Out-of-Distribution-Polyp-Segmentation" class="headerlink" title="Prototype Learning for Out-of-Distribution Polyp Segmentation"></a>Prototype Learning for Out-of-Distribution Polyp Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03709">http://arxiv.org/abs/2308.03709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil Kumar Tomar, Debesh Jha, Ulas Bagci</li>
<li>for: 本研究的目的是创建一个可靠和通用的肿瘤 segmentation 模型，以便在不同中心的数据集上提供可靠的 segmentation 结果。</li>
<li>methods: 我们的模型使用了不同的照明模式，如白光 imaging (WLI)、蓝光 imaging (BLI)、 Linked color imaging (LCI) 和 flexible spectral imaging color enhancement (FICE)，并使用 prototype 来表示每种对象类的特征特征，例如形状、Texture 和颜色。</li>
<li>results: 我们的模型可以在不同中心的数据集上提供高达 $\geq$ 90%的 dice 系数和 $\geq$ 85%的 mIoU 分割精度，并且具有实时处理速度。在对 16 种现状顶尖图像分割架构进行比较时，我们的方法表现出了超越性，这可能将改善临床结果。<details>
<summary>Abstract</summary>
Existing polyp segmentation models from colonoscopy images often fail to provide reliable segmentation results on datasets from different centers, limiting their applicability. Our objective in this study is to create a robust and well-generalized segmentation model named PrototypeLab that can assist in polyp segmentation. To achieve this, we incorporate various lighting modes such as White light imaging (WLI), Blue light imaging (BLI), Linked color imaging (LCI), and Flexible spectral imaging color enhancement (FICE) into our new segmentation model, that learns to create prototypes for each class of object present in the images. These prototypes represent the characteristic features of the objects, such as their shape, texture, color. Our model is designed to perform effectively on out-of-distribution (OOD) datasets from multiple centers. We first generate a coarse mask that is used to learn prototypes for the main object class, which are then employed to generate the final segmentation mask. By using prototypes to represent the main class, our approach handles the variability present in the medical images and generalize well to new data since prototype capture the underlying distribution of the data. PrototypeLab offers a promising solution with a dice coefficient of $\geq$ 90\% and mIoU $\geq$ 85\% with a near real-time processing speed for polyp segmentation. It achieved superior performance on OOD datasets compared to 16 state-of-the-art image segmentation architectures, potentially improving clinical outcomes. Codes are available at https://github.com/xxxxx/PrototypeLab.
</details>
<details>
<summary>摘要</summary>
traditional Chinese version:现有的肿体段化模型从医学护理影像中的分段结果不可靠，限制了它们的实用性。我们的目标是创建一个可靠和普遍适用的分段模型，名为PrototypeLab，可以帮助进行肿体段化。为了实现这一目标，我们在新的分段模型中 integrate了不同的照明方式，如白光成像（WLI）、蓝光成像（BLI）、相关颜色成像（LCI）和可变色spectral成像（FICE）。这些照明方式的整合使我们的新分段模型学习出每个类别对应的原型，这些原型表示对象的形状、 текстура和颜色的特征特征。我们的模型设计能够在多个中心的数据集上表现出色，并且可以快速处理数据。我们首先生成一个粗略的mask，并使用这个mask来学习每个主要类别的原型，然后使用这些原型生成最终的分段mask。通过使用原型来表示主要类别，我们的方法可以处理医学影像中的变化，并且可以很好地适应新数据，因为原型捕捉了数据的下面分布。PrototypeLab提供了一个有 promise的解决方案，其中 dice coefficient ≥ 90%和mIoU ≥ 85%，并且具有近实时处理速度。它在多个中心的数据集上表现出色，并且超过了16种state-of-the-art图像分 segmentation模型，可能改善临床结果。代码可以在https://github.com/xxxxx/PrototypeLab 获取。Here's the translation in Simplified Chinese:现有的肿体段化模型经常无法在不同中心的数据集上提供可靠的分段结果，这限制了它们的实用性。我们的目标是创建一个可靠和普遍适用的分段模型，名为PrototypeLab，可以帮助进行肿体段化。为了实现这一目标，我们在新的分段模型中 integrate了不同的照明方式，如白光成像（WLI）、蓝光成像（BLI）、相关颜色成像（LCI）和可变色spectral成像（FICE）。这些照明方式的整合使我们的新分段模型学习出每个类别对应的原型，这些原型表示对象的形状、 текстуra和颜色的特征特征。我们的模型设计能够在多个中心的数据集上表现出色，并且可以快速处理数据。我们首先生成一个粗略的mask，并使用这个mask来学习每个主要类别的原型，然后使用这些原型生成最终的分段mask。通过使用原型来表示主要类别，我们的方法可以处理医学影像中的变化，并且可以很好地适应新数据，因为原型捕捉了数据的下面分布。PrototypeLab提供了一个有 promise的解决方案，其中 dice coefficient ≥ 90%和mIoU ≥ 85%，并且具有近实时处理速度。它在多个中心的数据集上表现出色，并且超过了16种state-of-the-art图像分 segmentation模型，可能改善临床结果。代码可以在https://github.com/xxxxx/PrototypeLab 获取。
</details></li>
</ul>
<hr>
<h2 id="Video-based-Person-Re-identification-with-Long-Short-Term-Representation-Learning"><a href="#Video-based-Person-Re-identification-with-Long-Short-Term-Representation-Learning" class="headerlink" title="Video-based Person Re-identification with Long Short-Term Representation Learning"></a>Video-based Person Re-identification with Long Short-Term Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03703">http://arxiv.org/abs/2308.03703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuehu Liu, Pingping Zhang, Huchuan Lu</li>
<li>for: 视频基于人识别（V-ReID）任务是从非重叠摄像机捕捉的 raw 视频中 Retrieval 特定人员，是多媒体和计算机视ión应用的基本任务。然而，由于人员和场景的变化，高性能的实现仍然面临着许多挑战。</li>
<li>methods: 我们注意到人员的长期和短期信息都是重要的robust视频表示。因此，我们提出了一种新的深度学习框架，即 Long Short-Term Representation Learning（LSTRL），以提高 V-ReID 的效果。更具体来说，我们提出了一种 Multi-granularity Appearance Extractor（MAE），可以有效地在多帧中捕捉四种粒度的外观表示。同时，我们提出了一种 Bi-direction Motion Estimator（BME），可以高效地从邻帧中提取回传信息。MAE 和 BME 都可以与现有网络结合使用，以提高特征学习能力。</li>
<li>results: 我们进行了广泛的实验，测试我们的提议在三个常用的标准 benchmar 上。结果显示，我们的方法可以在 V-ReID 中提供更高的性能，超过大多数当前状态的最佳方法。<details>
<summary>Abstract</summary>
Video-based person Re-Identification (V-ReID) aims to retrieve specific persons from raw videos captured by non-overlapped cameras. As a fundamental task, it spreads many multimedia and computer vision applications. However, due to the variations of persons and scenes, there are still many obstacles that must be overcome for high performance. In this work, we notice that both the long-term and short-term information of persons are important for robust video representations. Thus, we propose a novel deep learning framework named Long Short-Term Representation Learning (LSTRL) for effective V-ReID. More specifically, to extract long-term representations, we propose a Multi-granularity Appearance Extractor (MAE), in which four granularity appearances are effectively captured across multiple frames. Meanwhile, to extract short-term representations, we propose a Bi-direction Motion Estimator (BME), in which reciprocal motion information is efficiently extracted from consecutive frames. The MAE and BME are plug-and-play and can be easily inserted into existing networks for efficient feature learning. As a result, they significantly improve the feature representation ability for V-ReID. Extensive experiments on three widely used benchmarks show that our proposed approach can deliver better performances than most state-of-the-arts.
</details>
<details>
<summary>摘要</summary>
视频基于人体重新识别（V-ReID）目标是从非重叠的视频中提取特定人脸。作为基础任务，它广泛应用于多媒体和计算机视觉领域。然而，由于人脸和场景的变化，V-ReID仍然存在许多障碍。在这项工作中，我们注意到人脸的长期和短期信息都是重要的robust视频表示。因此，我们提出了一种新的深度学习框架，即长期短期表示学习（LSTRL），以提高V-ReID的性能。更进一步，我们提出了一种多粒度外观捕获器（MAE），可以有效地在多帧中捕获四个粒度的人脸表达。同时，我们提出了一种双向运动估计器（BME），可以快速提取从一帧到下一帧的对称运动信息。MAE和BME都可以与现有网络结合使用，以提高特征学习的能力。经验表明，我们的提出的方法可以在三个广泛使用的标准测试集上达到比较高的性能。
</details></li>
</ul>
<hr>
<h2 id="Screen-based-3D-Subjective-Experiment-Software"><a href="#Screen-based-3D-Subjective-Experiment-Software" class="headerlink" title="Screen-based 3D Subjective Experiment Software"></a>Screen-based 3D Subjective Experiment Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03698">http://arxiv.org/abs/2308.03698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songlin Fan, Wei Gao</li>
<li>for: 本研究旨在开发一种可靠的3D主观评价平台，以便用户可以自由设计3D主观方法和建立高质量的主观评价数据集，推动3D图形主观评价领域的发展。</li>
<li>methods: 本研究使用了一种能够同时渲染源刺激和受损刺激，并允许刺激响应参与者交互的软件平台，以便准确地描述3D刺激的主观质量差异。</li>
<li>results: 经验分析表明，使用本研究提出的软件平台进行主观测试可以生成合理的3D模型主观质量分数。<details>
<summary>Abstract</summary>
Recently, widespread 3D graphics (e.g., point clouds and meshes) have drawn considerable efforts from academia and industry to assess their perceptual quality by conducting subjective experiments. However, lacking a handy software for 3D subjective experiments complicates the construction of 3D graphics quality assessment datasets, thus hindering the prosperity of relevant fields. In this paper, we develop a powerful platform with which users can flexibly design their 3D subjective methodologies and build high-quality datasets, easing a broad spectrum of 3D graphics subjective quality study. To accurately illustrate the perceptual quality differences of 3D stimuli, our software can simultaneously render the source stimulus and impaired stimulus and allows both stimuli to respond synchronously to viewer interactions. Compared with amateur 3D visualization tool-based or image/video rendering-based schemes, our approach embodies typical 3D applications while minimizing cognitive overload during subjective experiments. We organized a subjective experiment involving 40 participants to verify the validity of the proposed software. Experimental analyses demonstrate that subjective tests on our software can produce reasonable subjective quality scores of 3D models. All resources in this paper can be found at https://openi.pcl.ac.cn/OpenDatasets/3DQA.
</details>
<details>
<summary>摘要</summary>
近些年来，广泛的3D图形（如点云和网格）在学术和industry中吸引了广泛的努力，以评估它们的主观质量通过主观实验。然而，由于缺乏一个方便的3D主观实验软件，建构3D图形质量评估数据集的建构变得更加困难，从而阻碍相关领域的发展。在这篇论文中，我们开发了一个强大的平台，允许用户自由地设计他们的3D主观方法ологи和建立高质量数据集，从而促进3D图形主观质量研究的广泛发展。为准确地 Illustrate3D刺激物的主观质量差异，我们的软件可以同时渲染源刺激和受损刺激，并且允许两个刺激响应同步到观众的交互。与 amateur 3D视觉工具基于的方案或基于图像/视频渲染的方案相比，我们的方法体现出典型的3D应用程序，同时减少主观实验中的认知负担。我们组织了一个主观实验，具有40名参与者，以验证我们提出的软件的有效性。实验分析表明，我们的软件可以生成3D模型的主观质量分数。所有资源可以在https://openi.pcl.ac.cn/OpenDatasets/3DQA找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-Concise-and-Descriptive-Attributes-for-Visual-Recognition"><a href="#Learning-Concise-and-Descriptive-Attributes-for-Visual-Recognition" class="headerlink" title="Learning Concise and Descriptive Attributes for Visual Recognition"></a>Learning Concise and Descriptive Attributes for Visual Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03685">http://arxiv.org/abs/2308.03685</a></li>
<li>repo_url: None</li>
<li>paper_authors: An Yan, Yu Wang, Yiwu Zhong, Chengyu Dong, Zexue He, Yujie Lu, William Wang, Jingbo Shang, Julian McAuley</li>
<li>for: 这研究旨在探讨基础模型的新进展，以及它们如何提高可读性的视觉识别器。</li>
<li>methods: 该研究使用大语言模型（LLM）来生成特征集，然后应用视觉语言模型来分类图像。</li>
<li>results: 研究发现，使用大量的特征集可以达到与图像特征集相当的性能，但是我们在8个 dataset上进一步的调查发现，LLM生成的特征集中有很多噪音。我们提出一种新的学习搜索方法，可以找到更小的 yet 高效的特征集。在 CUB dataset 上，我们的方法可以使用只有 32 个特征集来分类 200 种鸟类，并且达到了使用大量 LLG 生成的特征集（如 10k 个特征集）的性能水平。此外，我们的新方法还具有更高的可读性和交互性，以及能够概括知识的能力。<details>
<summary>Abstract</summary>
Recent advances in foundation models present new opportunities for interpretable visual recognition -- one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes. Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features. However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes. We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes. As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (e.g., 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species. Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.CV_2023_08_08/" data-id="clpxp6c0s00huee887q9n984a" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.AI_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T12:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.AI_2023_08_08/">cs.AI - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Lightweight-and-Accurate-Face-Detection-Algorithm-Based-on-Retinaface"><a href="#A-Lightweight-and-Accurate-Face-Detection-Algorithm-Based-on-Retinaface" class="headerlink" title="A Lightweight and Accurate Face Detection Algorithm Based on Retinaface"></a>A Lightweight and Accurate Face Detection Algorithm Based on Retinaface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04340">http://arxiv.org/abs/2308.04340</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baozhu Liu, Hewei Yu</li>
<li>for: 这个论文提出了一种轻量级准确的人脸检测算法LAFD（轻量级和准确的人脸检测），基于Retinaface。</li>
<li>methods: 这个算法使用了修改后的MobileNetV3网络作为后处网络，并将核心卷积的大小、通道扩展乘数和倒置径向块中的SE注意力机制调整。在Context模块中引入了弹性卷积网络(DCN)，并使用了焦点损失函数而不是交叉熵损失函数作为模型的分类损失函数。</li>
<li>results: 测试结果表明，LAFD在WIDERFACE数据集上的均值准确率为94.1%、92.2%和82.1%，与Retinaface相比提高3.4%、4.0%和8.3%，并且与轻量级模型LFFD相比提高3.1%、4.1%和4.1%。如果输入图像先进行预处理并将其横幅或长宽尺寸调整到1560px或1200px，则模型在’hard’验证子集上的均值准确率为86.2%。模型轻量级，只有10.2MB大小。<details>
<summary>Abstract</summary>
In this paper, we propose a lightweight and accurate face detection algorithm LAFD (Light and accurate face detection) based on Retinaface. Backbone network in the algorithm is a modified MobileNetV3 network which adjusts the size of the convolution kernel, the channel expansion multiplier of the inverted residuals block and the use of the SE attention mechanism. Deformable convolution network(DCN) is introduced in the context module and the algorithm uses focal loss function instead of cross-entropy loss function as the classification loss function of the model. The test results on the WIDERFACE dataset indicate that the average accuracy of LAFD is 94.1%, 92.2% and 82.1% for the "easy", "medium" and "hard" validation subsets respectively with an improvement of 3.4%, 4.0% and 8.3% compared to Retinaface and 3.1%, 4.1% and 4.1% higher than the well-performing lightweight model, LFFD. If the input image is pre-processed and scaled to 1560px in length or 1200px in width, the model achieves an average accuracy of 86.2% on the 'hard' validation subset. The model is lightweight, with a size of only 10.2MB.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种轻量级并高度准确的人脸检测算法LAFD（轻量级和准确的人脸检测），基于Retinaface。这个算法中的基础网络是一种修改后的MobileNetV3网络，通过调整卷积核的大小、扩展通道多少和使用SE注意力机制来调整。在 context 模块中，我们引入了弹性卷积网络（DCN），并使用 focal loss 函数 instead of cross-entropy loss function 作为模型的分类损失函数。在 WIDERFACE 数据集上进行测试，LAFD 的平均准确率为 94.1%、92.2% 和 82.1% ，对 Retinaface 的提高为 3.4%、4.0% 和 8.3%，而与轻量级表现良好的模型 LFFD 的提高为 3.1%、4.1% 和 4.1%。如果输入图像经过预处理并将其扩展到 1560px 长或 1200px 宽，则模型在 'hard' 验证子集上的平均准确率为 86.2%。该模型轻量级，只有 10.2MB 大小。
</details></li>
</ul>
<hr>
<h2 id="Pengembangan-Model-untuk-Mendeteksi-Kerusakan-pada-Terumbu-Karang-dengan-Klasifikasi-Citra"><a href="#Pengembangan-Model-untuk-Mendeteksi-Kerusakan-pada-Terumbu-Karang-dengan-Klasifikasi-Citra" class="headerlink" title="Pengembangan Model untuk Mendeteksi Kerusakan pada Terumbu Karang dengan Klasifikasi Citra"></a>Pengembangan Model untuk Mendeteksi Kerusakan pada Terumbu Karang dengan Klasifikasi Citra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04337">http://arxiv.org/abs/2308.04337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fadhil Muhammad, Alif Bintang Elfandra, Iqbal Pahlevi Amin, Alfan Farizki Wicaksono</li>
<li>For: 这个研究旨在开发一个精确的分类模型，以识别和区别健康和萎缩珊瑚的视觉特征。* Methods: 这个研究使用机器学习模型，特别是卷积神经网络（CNN），以识别和区别健康和萎缩珊瑚的视觉特征。* Results: 这个研究发现，由 scratch ResNet 模型可以在精度和准确性方面超越预训练的模型。这些精度的分类模型将有助研究人员和海洋生物学家更好地理解珊瑚礁生态环境的健康状况，并且可以用于监控珊瑚礁环境的变化，从而做出有关生态系统重建和保护的重要贡献。<details>
<summary>Abstract</summary>
The abundant biodiversity of coral reefs in Indonesian waters is a valuable asset that needs to be preserved. Rapid climate change and uncontrolled human activities have led to the degradation of coral reef ecosystems, including coral bleaching, which is a critical indicator of coral health conditions. Therefore, this research aims to develop an accurate classification model to distinguish between healthy corals and corals experiencing bleaching. This study utilizes a specialized dataset consisting of 923 images collected from Flickr using the Flickr API. The dataset comprises two distinct classes: healthy corals (438 images) and bleached corals (485 images). These images have been resized to a maximum of 300 pixels in width or height, whichever is larger, to maintain consistent sizes across the dataset.   The method employed in this research involves the use of machine learning models, particularly convolutional neural networks (CNN), to recognize and differentiate visual patterns associated with healthy and bleached corals. In this context, the dataset can be used to train and test various classification models to achieve optimal results. By leveraging the ResNet model, it was found that a from-scratch ResNet model can outperform pretrained models in terms of precision and accuracy. The success in developing accurate classification models will greatly benefit researchers and marine biologists in gaining a better understanding of coral reef health. These models can also be employed to monitor changes in the coral reef environment, thereby making a significant contribution to conservation and ecosystem restoration efforts that have far-reaching impacts on life.
</details>
<details>
<summary>摘要</summary>
INDONESIA的珊瑚礁多样性具有巨大的价值，需要保护。快速的气候变化和无控制的人类活动导致珊瑚礁生态系统的退化，包括珊瑚病症，是珊瑚健康状况的重要指标。因此，这项研究的目标是开发一个准确的分类模型，以分辨健康的珊瑚和经受病症的珊瑚。本研究使用特殊的数据集，包括Flickr API上收集的923张图片。这个数据集包括两个不同的类别：健康的珊瑚（438张图片）和病症的珊瑚（485张图片）。这些图片已经被缩放到最多300像素的宽或高，以保持数据集中图片的尺寸一致。本研究使用机器学习模型，特别是卷积神经网络（CNN），识别和区分健康和病症珊瑚的视觉特征。在这种情况下，数据集可以用来训练和测试不同的分类模型，以达到最佳结果。通过利用ResNet模型，发现从头开始的ResNet模型可以在精度和准确性方面超越预训练模型。成功地开发准确的分类模型，将对研究人员和海洋生物学家提供深刻的理解，珊瑚礁的健康状况。这些模型也可以用来监测珊瑚礁环境的变化，从而为保护和生态系统重建做出重要贡献。
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs"><a href="#Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs" class="headerlink" title="Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs"></a>Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04314">http://arxiv.org/abs/2308.04314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yang, Xuchuang Wang, Mohammad Hajiesmaili, Lijun Zhang, John C. S. Lui, Don Towsley</li>
<li>for: 本文旨在研究分布式智能体在多重武器游戏中的合作游戏，以实现最佳团队和个体误差，同时减少智能体之间的通信成本。</li>
<li>methods: 本文使用分布式算法和领导者追随者模式来解决这个问题。</li>
<li>results: 本文的算法可以实现最佳个体误差和常数通信成本，并且超越了现有的分布式算法和领导者追随者模式。<details>
<summary>Abstract</summary>
Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.
</details>
<details>
<summary>摘要</summary>
近来，有广泛的研究关于协同多智能多手枪抽筋游戏，其中多个分布式代理共同参与同一个多手枪抽筋游戏。目标是开发抽筋算法，以便各个代理具有最佳小组和个人惩罚，同时减少代理之间的交流。先前的工作通过两种方法解决了这个问题：领导者-追随者和完全分布式算法。先前的领导者-追随者算法实现了常数交流成本，但失去最佳个人惩罚。现状的完全分布式算法实现了最佳个人惩罚，但失去常数交流成本。本文提出了一种简单又有效的交流策略，并将其 интегра到了一种学习算法中，以实现协同抽筋中的最佳个人惩罚和常数交流成本。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Code-Generation-using-ChatGPT-3-5-across-10-Programming-Languages"><a href="#A-Comparative-Study-of-Code-Generation-using-ChatGPT-3-5-across-10-Programming-Languages" class="headerlink" title="A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages"></a>A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04477">http://arxiv.org/abs/2308.04477</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abuscemi02/A-Comparative-Study-of-Code-Generation-using-ChatGPT-3.5-across-10-Programming-Languages">https://github.com/abuscemi02/A-Comparative-Study-of-Code-Generation-using-ChatGPT-3.5-across-10-Programming-Languages</a></li>
<li>paper_authors: Alessio Buscemi</li>
<li>for: 这个研究旨在评估OpenAI在11月2022年发布的ChatGPT 3.5语言模型在编程语言和软件领域中的代码创作能力。</li>
<li>methods: 该研究使用了10种编程语言和4种软件领域来评估模型的代码创作能力。</li>
<li>results: 研究发现了模型的一些意外行为和限制，以及 automatized code generation对编程语言和技术领域的演化的影响。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are advanced Artificial Intelligence (AI) systems that have undergone extensive training using large datasets in order to understand and produce language that closely resembles that of humans. These models have reached a level of proficiency where they are capable of successfully completing university exams across several disciplines and generating functional code to handle novel problems. This research investigates the coding proficiency of ChatGPT 3.5, a LLM released by OpenAI in November 2022, which has gained significant recognition for its impressive text generating and code creation capabilities. The skill of the model in creating code snippets is evaluated across 10 various programming languages and 4 different software domains. Based on the findings derived from this research, major unexpected behaviors and limitations of the model have been identified. This study aims to identify potential areas for development and examine the ramifications of automated code generation on the evolution of programming languages and on the tech industry.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）是人工智能（AI）系统的进步，经过大量数据训练以便理解和生成语言，与人类语言更加相似。这些模型已经达到了人类水平，能够成功完成大学考试的多个领域和解决新的问题。本研究探讨了ChatGPT 3.5，一个由OpenAI在2022年11月发布的LLM，它在文本生成和代码创建方面获得了广泛的赞誉。这个模型在10种程式语言和4个软件领域中创建代码的技能被评估。根据这些研究发现的结果，模型具有一些意外的行为和限制。本研究旨在确定模型的发展前景和自动代码生成对程式语言的演化和科技业的影响。
</details></li>
</ul>
<hr>
<h2 id="Apple-Vision-Pro-for-Healthcare-“The-Ultimate-Display”-–-Entering-the-Wonderland-of-Precision"><a href="#Apple-Vision-Pro-for-Healthcare-“The-Ultimate-Display”-–-Entering-the-Wonderland-of-Precision" class="headerlink" title="Apple Vision Pro for Healthcare: “The Ultimate Display”? – Entering the Wonderland of Precision"></a>Apple Vision Pro for Healthcare: “The Ultimate Display”? – Entering the Wonderland of Precision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04313">http://arxiv.org/abs/2308.04313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Egger, Christina Gsaxner, Xiaojun Chen, Jiang Bian, Jens Kleesiek, Behrus Puladi</li>
<li>for: 这篇论文是关于Apple Vision Pro混合现实头戴式设备的研究，它可以作为虚拟现实（VR）设备，同时也具有增强现实（AR）功能。</li>
<li>methods: 该论文使用了内部摄像头和涂抹技术来实现头戴式设备的混合现实功能，同时还使用了一个名为”数字皇冠”的按钮来让用户轻松地融合数字内容和物理空间。</li>
<li>results: 该论文认为，Apple Vision Pro可以在医疗领域中提供更高效的辅助工具，帮助临床医生在诊断和治疗过程中占用更多时间与病人进行互动。<details>
<summary>Abstract</summary>
At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced the Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, more specifically it is a Virtual Reality (VR) device with an additional Video See-Through (VST) capability. The VST capability turns the Vision Pro also into an Augmented Reality (AR) device. The AR feature is enabled by streaming the real world via cameras to the (VR) screens in front of the user's eyes. This is of course not unique and similar to other devices, like the Varjo XR-3. Nevertheless, the Vision Pro has some interesting features, like an inside-out screen that can show the headset wearers' eyes to "outsiders" or a button on the top, called "Digital Crown", that allows you to seamlessly blend digital content with your physical space by turning it. In addition, it is untethered, except for the cable to the battery, which makes the headset more agile, compared to the Varjo XR-3. This could actually come closer to the "Ultimate Display", which Ivan Sutherland had already sketched in 1965. Not available to the public yet, like the Ultimate Display, we want to take a look into the crystal ball in this perspective to see if it can overcome some clinical challenges that - especially - AR still faces in the medical domain, but also go beyond and discuss if the Vision Pro could support clinicians in essential tasks to spend more time with their patients.
</details>
<details>
<summary>摘要</summary>
在2023年6月的全球开发者大会（WWDC）上，苹果公司发布了“视野豪”（Vision Pro）混合现实（MR）头戴式设备，具体来说是虚拟现实（VR）设备具有视频增强（VST）功能。VST功能使得视野豪也成为了增强现实（AR）设备。AR功能由通过摄像头传输真实世界到用户的视网膜上的方式实现，这与其他设备类似，如Varjo XR-3。然而，视野豪有一些有趣的特点，如内置屏幕，可以在外部显示头戴式设备穿戴者的眼睛，以及位于顶部的“数字皇冠”（Digital Crown）按钮，可以轻松融合数字内容与实际空间。此外，它还不受绑定，除了电池供电的电缆，使得头戴式设备更加灵活，相比Varjo XR-3。这可能可以实现“最终显示”（Ultimate Display）， Ivan Sutherland在1965年绘制的概念。虽然不如“最终显示”一样不到公众，但我们可以通过幻灯片来看看这个头戴式设备是否可以在医疗领域超越临床挑战，同时还可以讨论这个设备是否可以支持临床专业人员在实际任务中更多时间与病人进行互动。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Goal-Based-model-for-Vehicle-Trajectory-Prediction-in-Interactive-Scenarios"><a href="#Interpretable-Goal-Based-model-for-Vehicle-Trajectory-Prediction-in-Interactive-Scenarios" class="headerlink" title="Interpretable Goal-Based model for Vehicle Trajectory Prediction in Interactive Scenarios"></a>Interpretable Goal-Based model for Vehicle Trajectory Prediction in Interactive Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04312">http://arxiv.org/abs/2308.04312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amina Ghoul, Itheri Yahiaoui, Anne Verroust-Blondet, Fawzi Nashashibi</li>
<li>for: 预测自动驾驶车辆的路径，提高道路安全性。</li>
<li>methods:  combinatorial discrete choice model和神经网络模型的组合，以提高预测的可解释性。</li>
<li>results: 通过使用 INTERACTION 数据集，实现并评估了我们的方案，并证明了我们的方案可以准确地预测车辆路径而不会产生可解释性的损害。<details>
<summary>Abstract</summary>
The abilities to understand the social interaction behaviors between a vehicle and its surroundings while predicting its trajectory in an urban environment are critical for road safety in autonomous driving. Social interactions are hard to explain because of their uncertainty. In recent years, neural network-based methods have been widely used for trajectory prediction and have been shown to outperform hand-crafted methods. However, these methods suffer from their lack of interpretability. In order to overcome this limitation, we combine the interpretability of a discrete choice model with the high accuracy of a neural network-based model for the task of vehicle trajectory prediction in an interactive environment. We implement and evaluate our model using the INTERACTION dataset and demonstrate the effectiveness of our proposed architecture to explain its predictions without compromising the accuracy.
</details>
<details>
<summary>摘要</summary>
autonomous driving 的道路安全受到 vehicle 与周围环境之间的社交互动行为的理解是关键。社交互动的不确定性使其很难以解释。在过去几年，基于神经网络的方法在路径预测方面得到了广泛应用，但这些方法受到了其不可解释性的限制。为了缓解这个问题，我们将精确的选择模型与高精度的神经网络模型结合，以实现在交互环境中的路径预测。我们使用 INTERACTION 数据集进行实现和评估，并证明了我们的提议的建筑可以不妨碍准确性而提供解释。
</details></li>
</ul>
<hr>
<h2 id="Vehicle-Motion-Forecasting-using-Prior-Information-and-Semantic-assisted-Occupancy-Grid-Maps"><a href="#Vehicle-Motion-Forecasting-using-Prior-Information-and-Semantic-assisted-Occupancy-Grid-Maps" class="headerlink" title="Vehicle Motion Forecasting using Prior Information and Semantic-assisted Occupancy Grid Maps"></a>Vehicle Motion Forecasting using Prior Information and Semantic-assisted Occupancy Grid Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04303">http://arxiv.org/abs/2308.04303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rabbia Asghar, Manuel Diaz-Zapata, Lukas Rummelhard, Anne Spalanzani, Christian Laugier</li>
<li>for: 本文是为了解决自动驾驶车辆中的动态预测问题，具体来说是使用卷积神经网络和概率方法预测车辆行为。</li>
<li>methods: 本文使用的方法包括将场景表示为动态占用Grid Maps（DOGMs），将占用细胞 assigning semantic标签，并使用地图信息。</li>
<li>results: 对于实际 NuScenes 数据集的测试和验证，本文的模型表现出色，能够更好地预测静止和动态车辆的行为，并且通过缺失数据集和地图信息的补做来证明模型的可靠性。<details>
<summary>Abstract</summary>
Motion prediction is a challenging task for autonomous vehicles due to uncertainty in the sensor data, the non-deterministic nature of future, and complex behavior of agents. In this paper, we tackle this problem by representing the scene as dynamic occupancy grid maps (DOGMs), associating semantic labels to the occupied cells and incorporating map information. We propose a novel framework that combines deep-learning-based spatio-temporal and probabilistic approaches to predict vehicle behaviors.Contrary to the conventional OGM prediction methods, evaluation of our work is conducted against the ground truth annotations. We experiment and validate our results on real-world NuScenes dataset and show that our model shows superior ability to predict both static and dynamic vehicles compared to OGM predictions. Furthermore, we perform an ablation study and assess the role of semantic labels and map in the architecture.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Motion prediction is a challenging task for autonomous vehicles due to uncertainty in the sensor data, the non-deterministic nature of future, and complex behavior of agents. In this paper, we tackle this problem by representing the scene as dynamic occupancy grid maps (DOGMs), associating semantic labels to the occupied cells and incorporating map information. We propose a novel framework that combines deep-learning-based spatio-temporal and probabilistic approaches to predict vehicle behaviors.Contrary to the conventional OGM prediction methods, evaluation of our work is conducted against the ground truth annotations. We experiment and validate our results on real-world NuScenes dataset and show that our model shows superior ability to predict both static and dynamic vehicles compared to OGM predictions. Furthermore, we perform an ablation study and assess the role of semantic labels and map in the architecture." into 中文（简体）Here's the translation:<<SYS>>预测行为是自动驾驶车辆的挑战之一，因为感知数据中的不确定性、未来的非束定性和智能代理人的复杂行为。在这篇论文中，我们通过将场景表示为动态占用格网图（DOGM），将占用细胞 association  semantic label，并利用地图信息来解决这个问题。我们提出了一种新的框架， combining 深度学习基于空间temporal和概率方法来预测车辆行为。与传统 OGM 预测方法不同，我们的评估采用了真实的地图注释。我们在实际的 NuScenes 数据集上进行了实验和验证，并证明了我们的模型在预测静止和动态车辆方面具有更高的能力，比传统 OGM 预测方法更好。此外，我们还进行了减少研究，以评估semantic label和地图在架构中的作用。
</details></li>
</ul>
<hr>
<h2 id="Actor-Critic-with-variable-time-discretization-via-sustained-actions"><a href="#Actor-Critic-with-variable-time-discretization-via-sustained-actions" class="headerlink" title="Actor-Critic with variable time discretization via sustained actions"></a>Actor-Critic with variable time discretization via sustained actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04299">http://arxiv.org/abs/2308.04299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakub Łyskawa, Paweł Wawrzyński</li>
<li>for: 本研究使用强化学习方法解决维度缺失问题，并研究不同时间粒度设置对控制器性能的影响。</li>
<li>methods: 本文提出了一种名为SusACER的离政策强化学习算法，该算法在不同时间粒度设置下进行学习，并且可以在粗粒度和细粒度之间切换。</li>
<li>results: 在Ant、HalfCheetah、Hopper和Walker2D等四个机器人控制环境中，SusACER算法都能够超越当前最佳算法。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) methods work in discrete time. In order to apply RL to inherently continuous problems like robotic control, a specific time discretization needs to be defined. This is a choice between sparse time control, which may be easier to train, and finer time control, which may allow for better ultimate performance. In this work, we propose SusACER, an off-policy RL algorithm that combines the advantages of different time discretization settings. Initially, it operates with sparse time discretization and gradually switches to a fine one. We analyze the effects of the changing time discretization in robotic control environments: Ant, HalfCheetah, Hopper, and Walker2D. In all cases our proposed algorithm outperforms state of the art.
</details>
<details>
<summary>摘要</summary>
重复学习（RL）方法在离散时间下运行。为了将RL应用于基于连续时间的问题，例如机器人控制，需要定义特定的时间离散设定。这是一个选择 между稀疏时间控制和精细时间控制的选择。在这种工作中，我们提出了 SusACER，一种离散RL算法，将不同时间离散设定的优点相互结合。首先，它使用稀疏时间离散，然后慢慢地转换到精细时间离散。我们对机器人控制环境中的Ant、半驰虎、跳跃机和 Walker2D进行分析，在所有情况下，我们的提议算法超越了现有的state of the art。
</details></li>
</ul>
<hr>
<h2 id="Engineering-LaCAM-ast-Towards-Real-Time-Large-Scale-and-Near-Optimal-Multi-Agent-Pathfinding"><a href="#Engineering-LaCAM-ast-Towards-Real-Time-Large-Scale-and-Near-Optimal-Multi-Agent-Pathfinding" class="headerlink" title="Engineering LaCAM$^\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding"></a>Engineering LaCAM$^\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04292">http://arxiv.org/abs/2308.04292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keisuke Okumura</li>
<li>for: 本研究旨在解决实时、大规模、近似优质多智能路径找索（MAPF）问题，通过增强最近提出的LaCAM*算法进行改进。</li>
<li>methods: 本研究使用了各种改进技术，部分启发自其他MAPF方法，以提高LaCAM*算法的初始解质量和融合速度。</li>
<li>results: 经验证明，将这些改进技术融合到LaCAM*算法中，可以明显提高解质量，从而进一步推进MAPF算法的边缘。<details>
<summary>Abstract</summary>
This paper addresses the challenges of real-time, large-scale, and near-optimal multi-agent pathfinding (MAPF) through enhancements to the recently proposed LaCAM* algorithm. LaCAM* is a scalable search-based algorithm that guarantees the eventual finding of optimal solutions for cumulative transition costs. While it has demonstrated remarkable planning success rates, surpassing various state-of-the-art MAPF methods, its initial solution quality is far from optimal, and its convergence speed to the optimum is slow. To overcome these limitations, this paper introduces several improvement techniques, partly drawing inspiration from other MAPF methods. We provide empirical evidence that the fusion of these techniques significantly improves the solution quality of LaCAM*, thus further pushing the boundaries of MAPF algorithms.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文解决了实时、大规模、近似优质多代理路径寻找（MAPF）的挑战，通过对最近提出的LaCAM*算法进行增强。LaCAM*是一种可扩展的搜索基本算法，可以 garantue the eventual finding of optimal solutions for cumulative transition costs。虽然它已经达到了多种状态前的寻找成功率，但其初始解质不佳，并且与优质相对较慢。为了超越这些限制，这篇论文提出了多种改进技术，部分 Draw inspiration from other MAPF methods。我们提供了实证证据，表明这些技术的融合可以 Significantly improve LaCAM*的解质，进一步推动MAPF算法的发展。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning"><a href="#In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning" class="headerlink" title="In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning"></a>In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04275">http://arxiv.org/abs/2308.04275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xhan77/in-context-alignment">https://github.com/xhan77/in-context-alignment</a></li>
<li>paper_authors: Xiaochuang Han</li>
<li>for: 这 paper 的目的是探讨在下文学习中进行归一化的可能性。</li>
<li>methods: 这 paper 使用了一个 vanilla 预训练语言模型 Llama-2，并通过在下文中学习来实现归一化。</li>
<li>results:  compared to 直接提示，在下context中进行归一化无需更改模型参数，可以提高 win-rate 7 倍，使 vanilla 语言模型与对齐 fine-tuning 的强基线模型相当。<details>
<summary>Abstract</summary>
In this note, we explore inference-time alignment through in-context learning. We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions. Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning.
</details>
<details>
<summary>摘要</summary>
在这份说明中，我们探索了在语言模型学习中的推理时对适应。我们考虑了一个未经任何微调的语言模型Llama-2，并从其在语音指令下检索了9个示例匹配例子。相比直接提示，无需更改模型参数的受上下文匹配导致了与文本-达维纳-003模型从OpenAI的7倍增加胜率，使原始语言模型与对适应微调相当。
</details></li>
</ul>
<hr>
<h2 id="Lossy-and-Lossless-L-2-Post-training-Model-Size-Compression"><a href="#Lossy-and-Lossless-L-2-Post-training-Model-Size-Compression" class="headerlink" title="Lossy and Lossless (L$^2$) Post-training Model Size Compression"></a>Lossy and Lossless (L$^2$) Post-training Model Size Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04269">http://arxiv.org/abs/2308.04269</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/modeltc/l2_compression">https://github.com/modeltc/l2_compression</a></li>
<li>paper_authors: Yumeng Shi, Shihao Bai, Xiuying Wei, Ruihao Gong, Jianlei Yang</li>
<li>for: 这个研究旨在提高深度神经网络的传输和储存方便性，透过结合lossy和lossless压缩方法。</li>
<li>methods: 本研究提出了一个后训练模型大小压缩方法，使用了一个统一的参数重复转换，以便在后训练过程中进行多种lossy压缩方法。此外，我们还引入了一个特殊的可微分Counter来帮助优化lossy压缩，以取得更适合的压缩点。</li>
<li>results: 本研究可以实现稳定的$10\times$压缩比率无损准确性，并且可以在短时间内取得$20\times$压缩比率对应轻微损失。代码可以在<a target="_blank" rel="noopener" href="https://github.com/ModelTC/L2_Compression%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/ModelTC/L2_Compression上获取。</a><details>
<summary>Abstract</summary>
Deep neural networks have delivered remarkable performance and have been widely used in various visual tasks. However, their huge size causes significant inconvenience for transmission and storage. Many previous studies have explored model size compression. However, these studies often approach various lossy and lossless compression methods in isolation, leading to challenges in achieving high compression ratios efficiently. This work proposes a post-training model size compression method that combines lossy and lossless compression in a unified way. We first propose a unified parametric weight transformation, which ensures different lossy compression methods can be performed jointly in a post-training manner. Then, a dedicated differentiable counter is introduced to guide the optimization of lossy compression to arrive at a more suitable point for later lossless compression. Additionally, our method can easily control a desired global compression ratio and allocate adaptive ratios for different layers. Finally, our method can achieve a stable $10\times$ compression ratio without sacrificing accuracy and a $20\times$ compression ratio with minor accuracy loss in a short time. Our code is available at https://github.com/ModelTC/L2_Compression .
</details>
<details>
<summary>摘要</summary>
深度神经网络已经提供了很好的性能，并在各种视觉任务中广泛使用。然而，它们的巨大大小带来了传输和存储的不便。许多前面的研究已经探讨过模型大小压缩。然而，这些研究通常是采用各种损失压缩和无损压缩方法，导致高效压缩率很困难。本工作提出了一种后处理模型大小压缩方法，它可以同时使用损失压缩和无损压缩。我们首先提出了一种统一的参数重要性变换，使得不同的损失压缩方法可以在后处理中进行 JOINT 处理。然后，我们引入了特有的可微分Counter，以便通过优化损失压缩来到达更适合的点，以便 later 无损压缩。此外，我们的方法可以轻松地控制desired的全局压缩比，并分配适应的层级压缩率。最后，我们的方法可以实现稳定的 $10\times$ 压缩比，无损减少精度，以及 $20\times$ 压缩比，只有微量损失精度。我们的代码可以在 https://github.com/ModelTC/L2_Compression 上找到。
</details></li>
</ul>
<hr>
<h2 id="Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey"><a href="#Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey" class="headerlink" title="Teacher-Student Architecture for Knowledge Distillation: A Survey"></a>Teacher-Student Architecture for Knowledge Distillation: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04268">http://arxiv.org/abs/2308.04268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengming Hu, Xuan Li, Dan Liu, Haolun Wu, Xi Chen, Ju Wang, Xue Liu</li>
<li>for: 本研究主要是为了解决深度神经网络（DNNs）在实际应用中的问题，即DNNs的参数量过多。</li>
<li>methods: 本研究使用了教师-学生架构，其中简单的学生网络只需要一些参数就可以达到与深度教师网络相同的性能。</li>
<li>results: 本研究通过多种知识压缩、扩展、适应和加强目标，成功地实现了多种知识压缩目标。<details>
<summary>Abstract</summary>
Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. This survey presents an introduction to various knowledge representations and their corresponding optimization objectives. Additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes. This survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. Lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. Through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives.
</details>
<details>
<summary>摘要</summary>
although deep neural networks (DNNs) have shown strong capacity to solve large-scale problems in many areas, such DNNs are difficult to deploy in real-world systems due to their numerous parameters. To address this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. this survey presents an introduction to various knowledge representations and their corresponding optimization objectives. additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes. this survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. finally, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives.
</details></li>
</ul>
<hr>
<h2 id="FLIRT-Feedback-Loop-In-context-Red-Teaming"><a href="#FLIRT-Feedback-Loop-In-context-Red-Teaming" class="headerlink" title="FLIRT: Feedback Loop In-context Red Teaming"></a>FLIRT: Feedback Loop In-context Red Teaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04265">http://arxiv.org/abs/2308.04265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ninareh Mehrabi, Palash Goyal, Christophe Dupuy, Qian Hu, Shalini Ghosh, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta</li>
<li>for: 这篇论文旨在测试和分析 générative 模型中的漏洞，以便提高模型的安全性和适用性。</li>
<li>methods: 这篇论文提出了一个自动化红队框架，用于评估给定的模型，并暴露其具有不安全和不适当内容生成的漏洞。该框架使用了受Context学习的反馈循环，以便对模型进行自动化红队。</li>
<li>results: 对比基eline方法，这种提出的策略更有效地暴露了Stable Diffusion（SD）模型中的漏洞，即使SD模型具有安全特性。此外，这种框架还能够对文本到文本模型进行红队， resulting in significantly higher toxic response generation rate compared to previously reported numbers.<details>
<summary>Abstract</summary>
Warning: this paper contains content that may be inappropriate or offensive.   As generative models become available for public use in various applications, testing and analyzing vulnerabilities of these models has become a priority. Here we propose an automatic red teaming framework that evaluates a given model and exposes its vulnerabilities against unsafe and inappropriate content generation. Our framework uses in-context learning in a feedback loop to red team models and trigger them into unsafe content generation. We propose different in-context attack strategies to automatically learn effective and diverse adversarial prompts for text-to-image models. Our experiments demonstrate that compared to baseline approaches, our proposed strategy is significantly more effective in exposing vulnerabilities in Stable Diffusion (SD) model, even when the latter is enhanced with safety features. Furthermore, we demonstrate that the proposed framework is effective for red teaming text-to-text models, resulting in significantly higher toxic response generation rate compared to previously reported numbers.
</details>
<details>
<summary>摘要</summary>
警告：这篇论文可能包含不适或不宜的内容。 随着生成模型在不同应用中变得更加普遍使用，测试和分析这些模型的漏洞已成为一个优先事项。 在这篇论文中，我们提出一种自动红团框架，用于评估给定模型的漏洞，并让模型生成不安全或不适的内容。 我们的框架使用受 Context 学习的反馈循环，以红团模型并让它生成不安全内容。 我们提出了不同的 Context 攻击策略，以自动学习有效和多样的对抗示例 для文本到图像模型。 我们的实验表明，相比基eline方法，我们提出的策略在Stable Diffusion（SD）模型上更加有效，即使后者具有安全功能。 此外，我们的框架还对文本到文本模型进行了红团，并得到了远远高于之前报道的恶意回应率。
</details></li>
</ul>
<hr>
<h2 id="PokerKit-A-Comprehensive-Python-Library-for-Fine-Grained-Multi-Variant-Poker-Game-Simulations"><a href="#PokerKit-A-Comprehensive-Python-Library-for-Fine-Grained-Multi-Variant-Poker-Game-Simulations" class="headerlink" title="PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations"></a>PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07327">http://arxiv.org/abs/2308.07327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juho Kim</li>
<li>for: 这篇论文是用于描述一个开源的Python库PokerKit，该库用于扩展现有的 póker游戏模拟和手牌评估工具的功能，支持更多的 póker变种和自定义游戏。</li>
<li>methods: 这篇论文详细介绍了PokerKit的设计和实现，包括它的直观的编程API，多种变种游戏支持，以及不同手牌类型的手牌评估 suite。</li>
<li>results: PokerKit的可靠性已经通过静态类型检查、广泛的doctests和单元测试确认，实现了97%的代码覆盖率。PokerKit的出现对计算机 póker领域做出了重要贡献，推动未来的研究和高级AI开发，用于多种 póker游戏。<details>
<summary>Abstract</summary>
PokerKit is an open-source Python library designed to overcome the restrictions of existing poker game simulation and hand evaluation tools, which typically support only a handful of poker variants and lack flexibility in game state control. In contrast, PokerKit significantly expands this scope by supporting an extensive array of poker variants and it provides a flexible architecture for users to define their custom games. This paper details the design and implementation of PokerKit, including its intuitive programmatic API, multi-variant game support, and a unified hand evaluation suite across different hand types. The flexibility of PokerKit allows for applications in diverse areas, such as poker AI development, tool creation, and online poker casino implementation. PokerKit's reliability has been established through static type checking, extensive doctests, and unit tests, achieving 97\% code coverage. The introduction of PokerKit represents a significant contribution to the field of computer poker, fostering future research and advanced AI development for a wide variety of poker games.
</details>
<details>
<summary>摘要</summary>
pokerKit 是一个开源的 Python 库，旨在超越现有的 póker 游戏模拟和手牌评估工具，这些工具通常只支持几种 póker 变种并缺乏游戏状态控制的灵活性。相比之下，pokerKit 对此进行了广泛的扩展，支持了大量的 póker 变种，并提供了用户定义的自定义游戏功能。这篇论文介绍了 pokerKit 的设计和实现，包括它的直观的编程 API，多种变种游戏支持，以及不同手牌类型的统一手牌评估 suite。pokerKit 的灵活性允许其在多种领域应用，如 póker AI 研发、工具创造和在线 póker 赌场实现。pokerKit 的可靠性已经通过静态类型检查、extensive doctests 和单元测试达到 97% 代码覆盖率。pokerKit 的出现对计算机 póker 领域做出了重要贡献，激发未来的研究和高级 AI 开发，涵盖各种 póker 游戏。
</details></li>
</ul>
<hr>
<h2 id="MindDiffuser-Controlled-Image-Reconstruction-from-Human-Brain-Activity-with-Semantic-and-Structural-Diffusion"><a href="#MindDiffuser-Controlled-Image-Reconstruction-from-Human-Brain-Activity-with-Semantic-and-Structural-Diffusion" class="headerlink" title="MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion"></a>MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04249">http://arxiv.org/abs/2308.04249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/reedonepeck/minddiffuser">https://github.com/reedonepeck/minddiffuser</a></li>
<li>paper_authors: Yizhuo Lu, Changde Du, Qiongyi zhou, Dianpeng Wang, Huiguang He</li>
<li>for: 这个论文的目的是提出一种两阶段图像重建模型，以解决脑计算机交互界面中图像重建精度和控制性的挑战。</li>
<li>methods: 该模型使用了VQ-VAE卷积Autoencoder和CLIP文本嵌入，并通过稳定扩散来初步重建图像，然后通过反射学习来调整图像的结构信息。</li>
<li>results: 该模型在Natural Scenes Dataset（NSD）上表现出了现在领先的性能，并且经过了许多质量和质量分析，得出了可读性的多模式特征，与脑响应的对应性得到了证明。<details>
<summary>Abstract</summary>
Reconstructing visual stimuli from brain recordings has been a meaningful and challenging task. Especially, the achievement of precise and controllable image reconstruction bears great significance in propelling the progress and utilization of brain-computer interfaces. Despite the advancements in complex image reconstruction techniques, the challenge persists in achieving a cohesive alignment of both semantic (concepts and objects) and structure (position, orientation, and size) with the image stimuli. To address the aforementioned issue, we propose a two-stage image reconstruction model called MindDiffuser. In Stage 1, the VQ-VAE latent representations and the CLIP text embeddings decoded from fMRI are put into Stable Diffusion, which yields a preliminary image that contains semantic information. In Stage 2, we utilize the CLIP visual feature decoded from fMRI as supervisory information, and continually adjust the two feature vectors decoded in Stage 1 through backpropagation to align the structural information. The results of both qualitative and quantitative analyses demonstrate that our model has surpassed the current state-of-the-art models on Natural Scenes Dataset (NSD). The subsequent experimental findings corroborate the neurobiological plausibility of the model, as evidenced by the interpretability of the multimodal feature employed, which align with the corresponding brain responses.
</details>
<details>
<summary>摘要</summary>
<<SYS>>重构脑记录中的视觉刺激是一项有意义且挑战性的任务。特别是在实现精确和可控的图像重建方面，这种任务具有推动脑机器交互的进步和应用的重要性。尽管复杂图像重建技术得到了进步，但是在图像刺激中协调semantic（概念和物体）和structure（位置、方向、大小）仍然是一项挑战。为了解决这个问题，我们提出了一种两个阶段的图像重建模型，称为 MindDiffuser。在第一阶段，使用VQ-VAE隐藏表示和CLIP文本嵌入从fMRI中解码的，并将其置入稳定扩散，从而得到包含semantic信息的初步图像。在第二阶段，我们利用CLIP视觉特征从fMRI中解码的，作为监督信息，通过反射来调整在第一阶段解码的两个特征向量，以实现结构信息的协调。实验结果表明，我们的模型在Natural Scenes Dataset（NSD）上超过了当前状态的艺术模型。后续的实验发现，证明了我们的模型在脑响应的可靠性方面具有神经生物学可能性，其中multimodal特征的可读性与脑响应的对应。
</details></li>
</ul>
<hr>
<h2 id="Gloss-Alignment-Using-Word-Embeddings"><a href="#Gloss-Alignment-Using-Word-Embeddings" class="headerlink" title="Gloss Alignment Using Word Embeddings"></a>Gloss Alignment Using Word Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04248">http://arxiv.org/abs/2308.04248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harry Walsh, Ozge Mercanoglu Sincan, Ben Saunders, Richard Bowden</li>
<li>for: 本研究旨在提高听语字幕和签语对应的精度，以便更好地训练无约束听语转文本模型。</li>
<li>methods: 本研究使用大量的说语言模型来对签语检测点进行对应。这种方法可以与现有的对应技术结合使用，从而降低计算成本。</li>
<li>results: 我们在\acf{mdgs}和\acf{bobsl} dataset上Quantitatively证明了我们的方法的效果，可以达到33.22 BLEU-1分数的word对应精度。<details>
<summary>Abstract</summary>
Capturing and annotating Sign language datasets is a time consuming and costly process. Current datasets are orders of magnitude too small to successfully train unconstrained \acf{slt} models. As a result, research has turned to TV broadcast content as a source of large-scale training data, consisting of both the sign language interpreter and the associated audio subtitle. However, lack of sign language annotation limits the usability of this data and has led to the development of automatic annotation techniques such as sign spotting. These spottings are aligned to the video rather than the subtitle, which often results in a misalignment between the subtitle and spotted signs. In this paper we propose a method for aligning spottings with their corresponding subtitles using large spoken language models. Using a single modality means our method is computationally inexpensive and can be utilized in conjunction with existing alignment techniques. We quantitatively demonstrate the effectiveness of our method on the \acf{mdgs} and \acf{bobsl} datasets, recovering up to a 33.22 BLEU-1 score in word alignment.
</details>
<details>
<summary>摘要</summary>
捕捉和标注手语数据集是一个时间consuming和成本高的过程。现有的数据集规模几个数量级小于需要成功训练无约制手语识别模型。因此，研究人员将视频广播内容作为大规模训练数据，包括手语 interprete 和关联的音频字幕。然而，手语注释缺失限制了这些数据的可用性，导致了自动注释技术的开发，如手语搜索。这些搜索被视频而不是字幕进行对齐，经常导致字幕和搜索到的手语之间的不一致。在这篇论文中，我们提议一种方法用于将搜索与其对应的字幕进行对齐，使用大量的人语言模型。由于我们只使用一种模式，我们的方法是计算机不昂贵的，可以与现有的对齐方法结合使用。我们量化地示示了我们的方法在\acf{mdgs}和\acf{bobsl}数据集上的效果，recovering up to 33.22 BLEU-1 分数。
</details></li>
</ul>
<hr>
<h2 id="AutoPCF-Efficient-Product-Carbon-Footprint-Accounting-with-Large-Language-Models"><a href="#AutoPCF-Efficient-Product-Carbon-Footprint-Accounting-with-Large-Language-Models" class="headerlink" title="AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models"></a>AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04241">http://arxiv.org/abs/2308.04241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Deng, Jinjie Liu, Biao Luo, Can Yuan, Qingrun Yang, Lei Xiao, Wenwen Zhou, Zhu Liu</li>
<li>for: 这个研究旨在发展一个自动化的碳脚印检测框架，以便快速和自动地计算产品生命周期中的碳脚印。</li>
<li>methods: 本研究使用了五个大语言模型（LLMs）来测试和比较生命周期模型的emergent能力，并将这些模型应用于自动生成产品生命周期的数据库。另外，这个框架还使用了深度学习算法来自动匹配计算参数，以便快速计算产品的碳脚印。</li>
<li>results: 使用AutoPCF框架估计三个案例产品的碳脚印，结果显示AutoPCF框架具有快速计算碳脚印的能力，比传统方法快得多少倍。<details>
<summary>Abstract</summary>
The product carbon footprint (PCF) is crucial for decarbonizing the supply chain, as it measures the direct and indirect greenhouse gas emissions caused by all activities during the product's life cycle. However, PCF accounting often requires expert knowledge and significant time to construct life cycle models. In this study, we test and compare the emergent ability of five large language models (LLMs) in modeling the 'cradle-to-gate' life cycles of products and generating the inventory data of inputs and outputs, revealing their limitations as a generalized PCF knowledge database. By utilizing LLMs, we propose an automatic AI-driven PCF accounting framework, called AutoPCF, which also applies deep learning algorithms to automatically match calculation parameters, and ultimately calculate the PCF. The results of estimating the carbon footprint for three case products using the AutoPCF framework demonstrate its potential in achieving automatic modeling and estimation of PCF with a large reduction in modeling time from days to minutes.
</details>
<details>
<summary>摘要</summary>
产品碳脚印（PCF）对于减少供应链的碳排放非常重要，因为它测量产品生命周期中直接和间接气候变化所导致的绿house gas排放。然而，PCF会计通常需要专业知识和大量时间建立生命周期模型。在这项研究中，我们测试和比较五种大型自然语言模型（LLM）在产品“营养径”生命周期的模型和生成输入输出inv质数据方面的能力，揭示它们的局限性作为总体PCF知识库。通过使用LLM，我们提议一种自动驱动的PCF会计框架，称为AutoPCF，该框架还应用深度学习算法来自动匹配计算参数，最终计算PCF。三个案例 продукт的碳脚印估计结果表明AutoPCF框架在自动模型和估计PCF方面具有很大的潜力，从天天减少到分钟内。
</details></li>
</ul>
<hr>
<h2 id="Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction"><a href="#Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction" class="headerlink" title="Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction"></a>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04237">http://arxiv.org/abs/2308.04237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Osvaldo Simeone</li>
<li>for: 这个论文旨在研究在分布式计算环境下，通过设备到服务器的通信，提高服务器的推断准确性。</li>
<li>methods: 该论文提出了一种名为分布式准确预测（Federated Conformal Prediction，简称WFCP）的协议，它基于类型基本多访问（Type-Based Multiple Access，简称TBMA）和一种新的量词 corrections 策略。WFCP 提供了正式的可靠性保证，包括服务器预测集的覆盖率。</li>
<li>results: 该论文通过数值结果显示，WFCP 在有限通信资源和&#x2F;或大量设备情况下具有显著优势，特别是与已有的 federated CP 方案进行数字实现的比较。<details>
<summary>Abstract</summary>
Consider a setting in which devices and a server share a pre-trained model. The server wishes to make an inference on a new input given the model. Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel. If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server? Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.
</details>
<details>
<summary>摘要</summary>
假设设备和服务器共享预训练模型。服务器想要对新输入进行推断。设备可以访问未使用过训练的数据，并可以通过共享的无线通信chnnel与服务器进行通信。如果设备没有访问新输入，可以通过设备到服务器的通信来提高服务器的推断决策质量吗？ latest work introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.
</details></li>
</ul>
<hr>
<h2 id="Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models"><a href="#Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models" class="headerlink" title="Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models"></a>Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04220">http://arxiv.org/abs/2308.04220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Efimia Panagiotaki, Daniele De Martini, Lars Kunze</li>
<li>for: 这种方法用于提高图神经网络（GNN）模型的解释性，通过使用semantic attention来增强图结构中的特征重要性的描述。</li>
<li>methods: 该方法利用semantic attention mechanism来提供基于特征重要性的解释，并通过对模型精度和特征重要性之间的相关性进行分析，从而获得有价值的特征重要性信息。</li>
<li>results: 通过应用该方法于一个遥感点云估计模型，成功地 indentify了提高性的semantic类别，并生成了可靠的后续semantic解释。<details>
<summary>Abstract</summary>
In this work, we propose a methodology for investigating the application of semantic attention to enhance the explainability of Graph Neural Network (GNN)-based models, introducing semantically-informed perturbations and establishing a correlation between predicted feature-importance weights and model accuracy. Graph Deep Learning (GDL) has emerged as a promising field for tasks like scene interpretation, leveraging flexible graph structures to concisely describe complex features and relationships. As traditional explainability methods used in eXplainable AI (XAI) cannot be directly applied to such structures, graph-specific approaches are introduced. Attention mechanisms have demonstrated their efficacy in estimating the importance of input features in deep learning models and thus have been previously employed to provide feature-based explanations for GNN predictions. Building upon these insights, we extend existing attention-based graph-explainability methods investigating the use of attention weights as importance indicators of semantically sorted feature sets. Through analysing the behaviour of predicted attention-weights distribution in correlation with model accuracy, we gain valuable insights into feature importance with respect to the behaviour of the GNN model. We apply our methodology to a lidar pointcloud estimation model successfully identifying key semantic classes that contribute to enhanced performance effectively generating reliable post-hoc semantic explanations.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种方法来增强Graph Neural Network（GNN）模型的解释性，通过引入semantically-informed perturbations和建立 predicted feature-importance weights与模型准确率之间的相关性。Graph Deep Learning（GDL）已经成为一个有前途的领域，用于场景理解等任务，利用灵活的图结构 concisely describe complex features和关系。traditional explainability methods在XAI中不能直接应用于such structures，因此introduce graph-specific approaches。Attention mechanisms have demonstrated their efficacy in estimating the importance of input features in deep learning models, and thus have been previously employed to provide feature-based explanations for GNN predictions. Building upon these insights, we extend existing attention-based graph-explainability methods by investigating the use of attention weights as importance indicators of semantically sorted feature sets. Through analyzing the behavior of predicted attention-weights distribution in correlation with model accuracy, we gain valuable insights into feature importance with respect to the behavior of the GNN model. We apply our methodology to a lidar pointcloud estimation model and successfully identify key semantic classes that contribute to enhanced performance, effectively generating reliable post-hoc semantic explanations.
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Retrieval-Augmented-Generation-for-Real-time-Composition-Assistance"><a href="#Hybrid-Retrieval-Augmented-Generation-for-Real-time-Composition-Assistance" class="headerlink" title="Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance"></a>Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04215">http://arxiv.org/abs/2308.04215</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuchao Zhang, Menglin Xia, Camille Couturier, Guoqing Zheng, Saravan Rajmohan, Victor Ruhle</li>
<li>for: 提高语言模型的上下文理解和私有数据的 интеграción，以及减少幻觉。</li>
<li>methods: 使用Hybrid Retrieval-Augmented Generation（HybridRAG）框架，结合云端和客户端模型，并在云端使用大语言模型（LLM）生成异步的检索增强内存。</li>
<li>results: HybridRAG在 Wikitext 和 Pile 子集上实现了更低的延迟，并在实用性方面超过了云端只有模型。<details>
<summary>Abstract</summary>
Retrieval augmented models show promise in enhancing traditional language models by improving their contextual understanding, integrating private data, and reducing hallucination. However, the processing time required for retrieval augmented large language models poses a challenge when applying them to tasks that require real-time responses, such as composition assistance.   To overcome this limitation, we propose the Hybrid Retrieval-Augmented Generation (HybridRAG) framework that leverages a hybrid setting that combines both client and cloud models. HybridRAG incorporates retrieval-augmented memory generated asynchronously by a Large Language Model (LLM) in the cloud. By integrating this retrieval augmented memory, the client model acquires the capability to generate highly effective responses, benefiting from the LLM's capabilities. Furthermore, through asynchronous memory integration, the client model is capable of delivering real-time responses to user requests without the need to wait for memory synchronization from the cloud. Our experiments on Wikitext and Pile subsets show that HybridRAG achieves lower latency than a cloud-based retrieval-augmented LLM, while outperforming client-only models in utility.
</details>
<details>
<summary>摘要</summary>
Note:* "Retrieval-augmented models" refers to models that use retrieval-augmented memory to improve their performance.* "Large Language Model" (LLM) refers to a model that can process and generate human-like language.* "Client model" refers to a model that runs on a local device, such as a smartphone or a computer.* "Cloud model" refers to a model that runs on a remote server, such as a cloud computing service.* "Memory synchronization" refers to the process of synchronizing the memory of multiple devices or models, so that they can access and share the same information.* "Utility" refers to the usefulness or effectiveness of a model or approach.
</details></li>
</ul>
<hr>
<h2 id="Adding-Why-to-What-Analyses-of-an-Everyday-Explanation"><a href="#Adding-Why-to-What-Analyses-of-an-Everyday-Explanation" class="headerlink" title="Adding Why to What? Analyses of an Everyday Explanation"></a>Adding Why to What? Analyses of an Everyday Explanation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04187">http://arxiv.org/abs/2308.04187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lutz Terfloth, Michael Schaffer, Heike M. Buhl, Carsten Schulte</li>
<li>for: 这篇论文的目的是研究如何为非专家用户提供可解释的技术决策。</li>
<li>methods: 这篇论文使用了技术哲学的双重本质理论来探讨对非专家用户的解释。</li>
<li>results: 研究发现，解释者在解释游戏时首先关注建筑（Architecture），然后关注相关性（Relevance）。在视频回忆中，解释者解释了基本组件之前 initially 解释了Physical Aspects，然后才转移到更复杂的、不可见的方面。 shift between addressing the two sides was justified by explanation goals, emerging misunderstandings, and the knowledge needs of the explainee。<details>
<summary>Abstract</summary>
In XAI it is important to consider that, in contrast to explanations for professional audiences, one cannot assume common expertise when explaining for laypeople. But such explanations between humans vary greatly, making it difficult to research commonalities across explanations. We used the dual nature theory, a techno-philosophical approach, to cope with these challenges. According to it, one can explain, for example, an XAI's decision by addressing its dual nature: by focusing on the Architecture (e.g., the logic of its algorithms) or the Relevance (e.g., the severity of a decision, the implications of a recommendation). We investigated 20 game explanations using the theory as an analytical framework. We elaborate how we used the theory to quickly structure and compare explanations of technological artifacts. We supplemented results from analyzing the explanation contents with results from a video recall to explore how explainers justified their explanation. We found that explainers were focusing on the physical aspects of the game first (Architecture) and only later on aspects of the Relevance. Reasoning in the video recalls indicated that EX regarded the focus on the Architecture as important for structuring the explanation initially by explaining the basic components before focusing on more complex, intangible aspects. Shifting between addressing the two sides was justified by explanation goals, emerging misunderstandings, and the knowledge needs of the explainee. We discovered several commonalities that inspire future research questions which, if further generalizable, provide first ideas for the construction of synthetic explanations.
</details>
<details>
<summary>摘要</summary>
在XAI中，需要注意的是，与专业听众的解释不同，不能假设共同知识。然而，人类之间的解释却很多样化，这使得研究共同点困难。我们采用了双重本质理论，一种技术哲学方法，以应对这些挑战。根据这种理论，可以通过关注XAI的几个方面来解释它的决策： Architecture（例如算法逻辑）或 Relevance（例如决策严重性、建议的影响）。我们对20个游戏解释使用了这种分析框架。我们详细介绍了如何使用这种理论快速结构和比较解释技术 artifacts。我们还补充了分析解释内容的结果，以及视频回忆中的解释者 justify their explanation。我们发现，解释者在初始阶段关注物理方面（Architecture），然后才关注更复杂、无形的方面。在视频回忆中的理由表明，EX认为在初始阶段通过解释基本组件来结构化解释是重要的。在转换 между两个方面时，解释者根据解释目标、出现的混淆和需要了解的知识来决定转换。我们发现了一些共同点，这些共同点可能会激发未来的研究问题。如果这些共同点能够普遍适用，它们将提供首先的想法 для构建人工解释。
</details></li>
</ul>
<hr>
<h2 id="Assistive-Chatbots-for-healthcare-a-succinct-review"><a href="#Assistive-Chatbots-for-healthcare-a-succinct-review" class="headerlink" title="Assistive Chatbots for healthcare: a succinct review"></a>Assistive Chatbots for healthcare: a succinct review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04178">http://arxiv.org/abs/2308.04178</a></li>
<li>repo_url: None</li>
<li>paper_authors: Basabdatta Sen Bhattacharya, Vibhav Sinai Pissurlenkar</li>
<li>For: The paper is written to review the state-of-the-art in AI-enabled Chatbots in healthcare, specifically during the last 10 years (2013-2023).* Methods: The paper reviews commercial and non-commercial Chatbots that are being used for patient support, as well as those in clinical trial phases. It also discusses the need for thorough and rigorous checks to ensure patient safety and medical ethics.* Results: The paper highlights a lack of trust in AI-enabled Chatbots among healthcare workers, patients, and the wider community, as well as dissatisfaction with the NLP skills of the Chatbots. It suggests that to enable deployment and integration of AI-enabled Chatbots in public health services, the technology needs to be simple and safe to use, and confidence in the technology needs to be built among the medical community and the wider community through outreach.Here are the three points in Simplified Chinese text:* For: 这篇论文是为了回顾过去十年（2013-2023）内健康服务中AI应用的状况。* Methods: 论文评论了商业和非商业的Chatbot，以及它们在患者支持方面的应用。它还提出了为保证患者安全和医疗伦理的严格检查的需要。* Results: 论文指出了健康工作者、患者和社会大众对AI应用Chatbot的不信任，以及Chatbot的自然语言处理技术不够的不满。它建议，为了让AI应用Chatbot在公共医疗服务中得到广泛应用，技术需要简单、安全，并需要对医疗人员和社会大众进行宣传和培训。<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) for supporting healthcare services has never been more necessitated than by the recent global pandemic. Here, we review the state-of-the-art in AI-enabled Chatbots in healthcare proposed during the last 10 years (2013-2023). The focus on AI-enabled technology is because of its potential for enhancing the quality of human-machine interaction via Chatbots, reducing dependence on human-human interaction and saving man-hours. Our review indicates that there are a handful of (commercial) Chatbots that are being used for patient support, while there are others (non-commercial) that are in the clinical trial phases. However, there is a lack of trust on this technology regarding patient safety and data protection, as well as a lack of wider awareness on its benefits among the healthcare workers and professionals. Also, patients have expressed dissatisfaction with Natural Language Processing (NLP) skills of the Chatbots in comparison to humans. Notwithstanding the recent introduction of ChatGPT that has raised the bar for the NLP technology, this Chatbot cannot be trusted with patient safety and medical ethics without thorough and rigorous checks to serve in the `narrow' domain of assistive healthcare. Our review suggests that to enable deployment and integration of AI-enabled Chatbots in public health services, the need of the hour is: to build technology that is simple and safe to use; to build confidence on the technology among: (a) the medical community by focussed training and development; (b) the patients and wider community through outreach.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在支持医疗服务方面从未如今所需要的那么重要。我们对过去10年（2013-2023）提出的AI应用于医疗领域的评论。我们的评论表明，只有一些商业聊天机器人在患者支持方面使用，而其他非商业聊天机器人则处于临床试验阶段。然而，技术的可靠性和数据保护方面存在不足的信任，同时医疗工作者和专业人员对其利好的认知也不够。此外，患者对自然语言处理（NLP）技术的评价较低，与人类之间的交流仍然存在差距。尽管最近出现了ChatGPT，但这种技术在医疗领域的应用仍需进行严格的检验和评估，以确保Patient Safety和医疗伦理的安全性。我们的评论建议，为了使AI应用于医疗服务中，需要：建立简单安全的技术；帮助医疗社区了解和信任技术；通过宣传和教育，建立患者和社区的信任。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Drug-Drug-Interactions-Using-Knowledge-Graphs"><a href="#Predicting-Drug-Drug-Interactions-Using-Knowledge-Graphs" class="headerlink" title="Predicting Drug-Drug Interactions Using Knowledge Graphs"></a>Predicting Drug-Drug Interactions Using Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04172">http://arxiv.org/abs/2308.04172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lizzy Farrugia, Lilian M. Azzopardi, Jeremy Debattista, Charlie Abela<br>for:The paper aims to predict unknown Drug-Drug Interactions (DDIs) by incorporating Knowledge Graphs (KGs) and various drug features from public drug repositories.methods:The medicX end-to-end framework uses a combination of translation, factorisation, and Neural Network (NN) based KG Embedding (KGE) methods to integrate drug features and predict unknown DDIs. The best performing combination was the ComplEx embedding method with a Long Short-Term Memory (LSTM) network, which achieved an F1-score of 95.19%.results:The ComplEx embedding method with an LSTM network achieved an F1-score of 95.19% on a dataset based on the DDIs found in DrugBank version 5.1.8, outperforming the state-of-the-art model DeepDDI by 5.61%. Additionally, a graph auto-encoder model using a Graph Neural Network (GNN) achieved an F1-score of 91.94%.<details>
<summary>Abstract</summary>
In the last decades, people have been consuming and combining more drugs than before, increasing the number of Drug-Drug Interactions (DDIs). To predict unknown DDIs, recently, studies started incorporating Knowledge Graphs (KGs) since they are able to capture the relationships among entities providing better drug representations than using a single drug property. In this paper, we propose the medicX end-to-end framework that integrates several drug features from public drug repositories into a KG and embeds the nodes in the graph using various translation, factorisation and Neural Network (NN) based KG Embedding (KGE) methods. Ultimately, we use a Machine Learning (ML) algorithm that predicts unknown DDIs. Among the different translation and factorisation-based KGE models, we found that the best performing combination was the ComplEx embedding method with a Long Short-Term Memory (LSTM) network, which obtained an F1-score of 95.19% on a dataset based on the DDIs found in DrugBank version 5.1.8. This score is 5.61% better than the state-of-the-art model DeepDDI. Additionally, we also developed a graph auto-encoder model that uses a Graph Neural Network (GNN), which achieved an F1-score of 91.94%. Consequently, GNNs have demonstrated a stronger ability to mine the underlying semantics of the KG than the ComplEx model, and thus using higher dimension embeddings within the GNN can lead to state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
在最近几十年中，人们的药物consumption和组合已经变得更加普遍，导致药物相互作用（DDIs）的数量增加。为预测未知的DDIs，最近的研究开始 incorporating知识图（KGs），因为它们可以捕捉药物之间的关系，提供更好的药物表示than使用单一的药物属性。在这篇文章中，我们提出了medicX终端框架，该框架 integrates 多种药物特征从公共药物库中into a KG，并使用不同的翻译、分解和神经网络（NN）基于KGE方法来嵌入图节点。最终，我们使用机器学习算法预测未知DDIs。在不同的翻译和分解基于KGE模型中，我们发现了最佳的组合是ComplEx嵌入方法与长短期记忆网络（LSTM），其在基于DrugBank版本5.1.8的数据集上取得了F1得分95.19%，高于当前状态的模型DeepDDI。此外，我们还开发了一种图自编码模型，使用图神经网络（GNN），其取得了F1得分91.94%。因此，GNNs在挖掘知识图下的能力更强，使用高维度嵌入在GNN中可以达到状态之Art。
</details></li>
</ul>
<hr>
<h2 id="Current-and-Future-Challenges-in-Knowledge-Representation-and-Reasoning"><a href="#Current-and-Future-Challenges-in-Knowledge-Representation-and-Reasoning" class="headerlink" title="Current and Future Challenges in Knowledge Representation and Reasoning"></a>Current and Future Challenges in Knowledge Representation and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04161">http://arxiv.org/abs/2308.04161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: James P. Delgrande, Birte Glimm, Thomas Meyer, Miroslaw Truszczynski, Frank Wolter</li>
<li>For: The paper discusses the current state of the art in Knowledge Representation and Reasoning, including its relation to other areas such as machine learning and uncertainty reasoning, and provides recommendations for future progress.* Methods: The paper is based on presentations, panels, working groups, and discussions that took place at a Dagstuhl Perspectives workshop on Knowledge Representation and Reasoning in July 2022.* Results: The paper provides a manifesto that declares the current views on Knowledge Representation, including its origins, goals, milestones, and current foci, as well as its challenges and key priorities for the next decade.Here is the same information in Simplified Chinese text:</li>
<li>for: 本文讲述了知识表示和推理领域的当前状况，包括它与其他领域的关系，如机器学习和不确定性推理，以及未来进展的建议。</li>
<li>methods: 本文基于2022年7月的达斯图尔视点工作shop的现场表示、小组讨论和推动活动。</li>
<li>results: 本文提供了一份宣言，宣布知识表示的起源、目标、里程碑和当前焦点，以及其挑战和未来十年的关键优先事项。<details>
<summary>Abstract</summary>
Knowledge Representation and Reasoning is a central, longstanding, and active area of Artificial Intelligence. Over the years it has evolved significantly; more recently it has been challenged and complemented by research in areas such as machine learning and reasoning under uncertainty. In July 2022 a Dagstuhl Perspectives workshop was held on Knowledge Representation and Reasoning. The goal of the workshop was to describe the state of the art in the field, including its relation with other areas, its shortcomings and strengths, together with recommendations for future progress. We developed this manifesto based on the presentations, panels, working groups, and discussions that took place at the Dagstuhl Workshop. It is a declaration of our views on Knowledge Representation: its origins, goals, milestones, and current foci; its relation to other disciplines, especially to Artificial Intelligence; and on its challenges, along with key priorities for the next decade.
</details>
<details>
<summary>摘要</summary>
知识表示和推理是人工智能的中心、长期积极发展的领域。随着时间的推移，它不断发展和改进，最近受到机器学习和不确定性推理的研究启发。2022年7月，达斯图尔视角工作坊（Dagstuhl Perspectives）举行了关于知识表示和推理的国际研讨会。工作坊的目的是描述该领域的现状，包括与其他领域的关系、短coming和优势，以及未来十年的发展优先级。我们基于工作坊的演讲、审议组、工作组和讨论会议的结果，制定了这份宣言。这是我们对知识表示的看法，包括其起源、目标、里程碑和当前焦点；与其他学科的关系，特别是人工智能；以及其挑战和未来十年的发展优先级。
</details></li>
</ul>
<hr>
<h2 id="Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks"><a href="#Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks" class="headerlink" title="Correlating Medi-Claim Service by Deep Learning Neural Networks"></a>Correlating Medi-Claim Service by Deep Learning Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04469">http://arxiv.org/abs/2308.04469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayanthi Vajiram, Negha Senthil, Nean Adhith. P</li>
<li>for: 防止医疗保险诈骗案件，包括患者、医生、诊断中心和保险公司之间的串谍关系，以确保金融增长。</li>
<li>methods: 使用卷积神经网络架构，通过对不同提供者的clam做 corrrelation 研究，检测诈骗CLAIM。同时使用超级vised和无监督分类器来检测诈骗和非诈骗CLAIM。</li>
<li>results: 通过使用卷积神经网络架构和 corrrelation 研究，能够准确地检测诈骗CLAIM，并且可以帮助防止金融诈骗案件。<details>
<summary>Abstract</summary>
Medical insurance claims are of organized crimes related to patients, physicians, diagnostic centers, and insurance providers, forming a chain reaction that must be monitored constantly. These kinds of frauds affect the financial growth of both insured people and health insurance companies. The Convolution Neural Network architecture is used to detect fraudulent claims through a correlation study of regression models, which helps to detect money laundering on different claims given by different providers. Supervised and unsupervised classifiers are used to detect fraud and non-fraud claims.
</details>
<details>
<summary>摘要</summary>
医疗保险养成有组织犯罪关系于病人、医生、诊断中心和保险公司，形成一个推动式的链 reaction。这种类型的诈骗活动会对保险人和健康保险公司的财务增长产生影响。使用卷积神经网络架构来检测诈骗养成，通过对不同提供者的clamshell进行相关性研究，可以检测到不同提供者的钱财洗涤。使用supervised和Unsupervised分类器来检测诈骗和非诈骗养成。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-360-Degree-Videos-in-Metaverse-Differentiated-Reinforcement-Learning-Approaches"><a href="#Heterogeneous-360-Degree-Videos-in-Metaverse-Differentiated-Reinforcement-Learning-Approaches" class="headerlink" title="Heterogeneous 360 Degree Videos in Metaverse: Differentiated Reinforcement Learning Approaches"></a>Heterogeneous 360 Degree Videos in Metaverse: Differentiated Reinforcement Learning Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04083">http://arxiv.org/abs/2308.04083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhan Yu, Jun Zhao</li>
<li>for: 这篇论文旨在提出一种适用于多种需求的质量服务模型，以满足未来元宇宙中多样化用户需求的视频技术发展。</li>
<li>methods: 该论文提出了一种基于自适应深度学习算法的帧槽结构，并对帧进行优化。两种结构：分离输入异构输出（SIDO）和合并输入异构输出（MIDO），以适应多种需求的场景。</li>
<li>results: 实验表明，该模型能够有效地优化帧率和压缩率，并适应不同需求的场景。<details>
<summary>Abstract</summary>
Advanced video technologies are driving the development of the futuristic Metaverse, which aims to connect users from anywhere and anytime. As such, the use cases for users will be much more diverse, leading to a mix of 360-degree videos with two types: non-VR and VR 360-degree videos. This paper presents a novel Quality of Service model for heterogeneous 360-degree videos with different requirements for frame rates and cybersickness. We propose a frame-slotted structure and conduct frame-wise optimization using self-designed differentiated deep reinforcement learning algorithms. Specifically, we design two structures, Separate Input Differentiated Output (SIDO) and Merged Input Differentiated Output (MIDO), for this heterogeneous scenario. We also conduct comprehensive experiments to demonstrate their effectiveness.
</details>
<details>
<summary>摘要</summary>
高级视频技术驱动未来Metaverse的发展，目的是Connect users from anywhere and anytime。因此，用户的用例将变得更加多样化，导致360度视频的两种类型：非VR和VR 360度视频。这篇论文提出了一种新的服务质量模型 для不同需求的 heterogeneous 360度视频，包括帧率和恶心症的不同需求。我们提出了一种帧槽结构，并通过自定义分化深度学习算法进行帧WISE优化。具体来说，我们设计了两种结构：分离输入�ifferentiated输出（SIDO）和合并输入�ifferentiated输出（MIDO），为这种多样化enario提供了优化。我们还进行了广泛的实验，以证明它们的有效性。
</details></li>
</ul>
<hr>
<h2 id="Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients"><a href="#Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients" class="headerlink" title="Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients"></a>Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04077">http://arxiv.org/abs/2308.04077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shu, Xiaoqiang Lin, Zhongxiang Dai, Bryan Kian Hsiang Low</li>
<li>for:  Federated zeroth-order optimization (ZOO) algorithms, which are used for query- and communication-efficient optimization in applications such as federated learning.</li>
<li>methods:  Trajectory-informed gradient surrogates and adaptive gradient correction techniques, which are used to improve the accuracy and efficiency of federated ZOO.</li>
<li>results:  The proposed FZooS algorithm achieves theoretical improvements over existing approaches and is supported by real-world experiments in federated black-box adversarial attack and federated non-differentiable metric optimization.Here is the simplified Chinese version of the three information:</li>
<li>for:  federated zeroth-order优化（ZOO）算法，用于实现缓存和通信效率的优化，如联合学习等应用。</li>
<li>methods:  using trajectory-informed gradient surrogates和适应式Gradient correction技术，以提高联合ZOO的准确性和效率。</li>
<li>results:  proposed FZooS算法在理论上有所改进，并在实际中通过联合黑盒抗击和非凸度量优化等实验得到支持。<details>
<summary>Abstract</summary>
Federated optimization, an emerging paradigm which finds wide real-world applications such as federated learning, enables multiple clients (e.g., edge devices) to collaboratively optimize a global function. The clients do not share their local datasets and typically only share their local gradients. However, the gradient information is not available in many applications of federated optimization, which hence gives rise to the paradigm of federated zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from the limitations of query and communication inefficiency, which can be attributed to (a) their reliance on a substantial number of function queries for gradient estimation and (b) the significant disparity between their realized local updates and the intended global updates. To this end, we (a) introduce trajectory-informed gradient surrogates which is able to use the history of function queries during optimization for accurate and query-efficient gradient estimation, and (b) develop the technique of adaptive gradient correction using these gradient surrogates to mitigate the aforementioned disparity. Based on these, we propose the federated zeroth-order optimization using trajectory-informed surrogate gradients (FZooS) algorithm for query- and communication-efficient federated ZOO. Our FZooS achieves theoretical improvements over the existing approaches, which is supported by our real-world experiments such as federated black-box adversarial attack and federated non-differentiable metric optimization.
</details>
<details>
<summary>摘要</summary>
联合优化，是一种兴起的概念，它在联合学习、联合优化等实际应用中找到了广泛的应用。在这种概念下，多个客户端（例如边缘设备）可以共同优化一个全球函数。客户端不会分享自己的本地数据，通常只会分享本地的梯度。但是，在许多应用中，梯度信息不可用，因此产生了联合零阶优化（ZOO）的概念。现有的联合ZOO算法受到函数询问和通信不�fficiente的限制，这可以被归因于（a）它们依赖了访问函数的很多次以估计梯度，以及（b）它们实现的本地更新和 globally 预期的更新之间存在很大的差异。为了解决这个问题，我们（a）引入了路径受限的梯度代理，这些梯度代理可以使用优化过程中的历史函数询问来实现精确和查询节省的梯度估计，以及（b）开发了适应性梯度调整技术，使用这些梯度代理来缓和上述差异。基于这些，我们提出了联合零阶优化使用路径受限梯度代理（FZooS）算法，实现了查询和通信节省的联合ZOO。我们的FZooS理论上超越了现有的方法，这被我们在实际应用中，如联合黑盒抗击和联合非 diffeomorphic 度量优化中所证明。
</details></li>
</ul>
<hr>
<h2 id="Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation"><a href="#Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation" class="headerlink" title="Path Signatures for Diversity in Probabilistic Trajectory Optimisation"></a>Path Signatures for Diversity in Probabilistic Trajectory Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04071">http://arxiv.org/abs/2308.04071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Barcelos, Tin Lai, Rafael Oliveira, Paulo Borges, Fabio Ramos</li>
<li>for: 这个论文的目的是提出一种用于平行 trajectory 优化的算法，以避免模式溃灭并实现更好的全局性。</li>
<li>methods: 该算法基于粗路论断理论中的新进展，利用粗路论断理论中的粗路签名和希尔伯特空间表示来实现平行优化，并将平行变量推断与多样性推进的kernel相连接。</li>
<li>results: 实验表明，该策略可以在各种问题上实现更低的平均成本，包括2D导航和受损环境中的机器人手臂操作。<details>
<summary>Abstract</summary>
Motion planning can be cast as a trajectory optimisation problem where a cost is minimised as a function of the trajectory being generated. In complex environments with several obstacles and complicated geometry, this optimisation problem is usually difficult to solve and prone to local minima. However, recent advancements in computing hardware allow for parallel trajectory optimisation where multiple solutions are obtained simultaneously, each initialised from a different starting point. Unfortunately, without a strategy preventing two solutions to collapse on each other, naive parallel optimisation can suffer from mode collapse diminishing the efficiency of the approach and the likelihood of finding a global solution. In this paper we leverage on recent advances in the theory of rough paths to devise an algorithm for parallel trajectory optimisation that promotes diversity over the range of solutions, therefore avoiding mode collapses and achieving better global properties. Our approach builds on path signatures and Hilbert space representations of trajectories, and connects parallel variational inference for trajectory estimation with diversity promoting kernels. We empirically demonstrate that this strategy achieves lower average costs than competing alternatives on a range of problems, from 2D navigation to robotic manipulators operating in cluttered environments.
</details>
<details>
<summary>摘要</summary>
路径规划可以被看作是一个轨迹优化问题，其中需要将轨迹优化为最小化一个成本函数。在复杂的环境中，找到globally optimal solution可以是一个困难的任务，因为这个问题通常会陷入到地方最优解。然而，随着计算机硬件的进步，我们可以使用并行的轨迹优化方法，从不同的初始点开始并行地生成多个解决方案。然而，如果不采取措施来避免解决方案之间的冲突，那么纯粹的并行优化方法可能会陷入到模式塌突，从而降低方法的效率和找到全局解的可能性。在这篇论文中，我们采用了最近的粗 PATH 理论来设计一种并行轨迹优化算法，该算法可以在轨迹优化过程中提高多样性，因此避免模式塌突并实现更好的全局性。我们的方法基于轨迹签名和希尔伯特空间表示，并将并行变分推理与多样性激活函数相连接。我们实际上证明了这种策略在一系列问题上实现了更低的平均成本，从2D导航到受损环境中的机器人抓取器。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation"><a href="#Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation" class="headerlink" title="Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation"></a>Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04061">http://arxiv.org/abs/2308.04061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Insung Kong, Yongdai Kim</li>
<li>for: 本研究针对具有仅有少量标签数据的情况下进行了 semi-supervised adversarial 训练。</li>
<li>methods: 本研究提出了两个上限函数，并提出了一个问题数据驱动的调整项。然后，我们开发了一个兼容这些上限函数的 semi-supervised adversarial 训练算法，其结合了问题数据驱动的知识传递和专家模型（i.e., 一个使用 semi-supervised 学习算法训练的教师模型）。</li>
<li>results: 我们的实验结果显示，我们的提案的算法可以实现 state-of-the-art 的性能，与现有算法相比，具有显著的优势。具体来说，对于仅有少量标签数据的情况下，我们的算法与使用所有标签数据的超级vised adversarial 训练算法相比，在 CIFAR-10 上的标准和Robust 精度上几乎相同。例如，我们的算法仅使用 8% 的标签数据时，与使用所有标签数据的超级vised adversarial 训练算法相比，其性能仍然具有显著的优势。<details>
<summary>Abstract</summary>
Adversarial robustness is a research area that has recently received a lot of attention in the quest for trustworthy artificial intelligence. However, recent works on adversarial robustness have focused on supervised learning where it is assumed that labeled data is plentiful. In this paper, we investigate semi-supervised adversarial training where labeled data is scarce. We derive two upper bounds for the robust risk and propose a regularization term for unlabeled data motivated by these two upper bounds. Then, we develop a semi-supervised adversarial training algorithm that combines the proposed regularization term with knowledge distillation using a semi-supervised teacher (i.e., a teacher model trained using a semi-supervised learning algorithm). Our experiments show that our proposed algorithm achieves state-of-the-art performance with significant margins compared to existing algorithms. In particular, compared to supervised learning algorithms, performance of our proposed algorithm is not much worse even when the amount of labeled data is very small. For example, our algorithm with only 8\% labeled data is comparable to supervised adversarial training algorithms that use all labeled data, both in terms of standard and robust accuracies on CIFAR-10.
</details>
<details>
<summary>摘要</summary>
“敌对类型调教是现在人工智能的研究领域中受到了很多关注，以确保人工智能的可靠性。然而，现有的工作通常假设有充足的标签数据，而我们在这篇论文中则 investigate 敌对调教中的半supervised 学习，在标签数据 scarce 的情况下。我们 deriv 了两个上限 bound 的敌对风险，并提出了一个基于这两个上限 bound 的调教term。然后，我们开发了一个半supervised adversarial training algorithm，它结合了我们提出的调教term 和知识传授使用半supervised teacher (即一个使用半supervised learning algorithm训练的教师模型)。我们的实验结果显示，我们的提案的算法可以 achieve state-of-the-art 性能，并且与已有算法相比，在标签数据很少的情况下，性能不会太差。例如，我们的算法仅使用8%的标签数据时，可以与完全supervised adversarial training algorithm相比，在 CIFAR-10 上 Both 标准和敌对精度方面表现出色。”
</details></li>
</ul>
<hr>
<h2 id="SODFormer-Streaming-Object-Detection-with-Transformer-Using-Events-and-Frames"><a href="#SODFormer-Streaming-Object-Detection-with-Transformer-Using-Events-and-Frames" class="headerlink" title="SODFormer: Streaming Object Detection with Transformer Using Events and Frames"></a>SODFormer: Streaming Object Detection with Transformer Using Events and Frames</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04047">http://arxiv.org/abs/2308.04047</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dianzl/sodformer">https://github.com/dianzl/sodformer</a></li>
<li>paper_authors: Dianze Li, Jianing Li, Yonghong Tian</li>
<li>for: 提高对象检测的精度和效率，特别是在高速运动和低光照条件下。</li>
<li>methods: 利用Transformer架构， integrates events and frames to continuously detect objects in an asynchronous manner，并使用 asynchronous attention-based fusion module to integrate two heterogeneous sensing modalities。</li>
<li>results: 与四种state-of-the-art方法和八个基eline比较，提出的SODFormer方法显示出了显著的性能优势。 Additionally, the proposed method works well even in cases where the conventional frame-based camera fails, such as high-speed motion and low-light conditions.<details>
<summary>Abstract</summary>
DAVIS camera, streaming two complementary sensing modalities of asynchronous events and frames, has gradually been used to address major object detection challenges (e.g., fast motion blur and low-light). However, how to effectively leverage rich temporal cues and fuse two heterogeneous visual streams remains a challenging endeavor. To address this challenge, we propose a novel streaming object detector with Transformer, namely SODFormer, which first integrates events and frames to continuously detect objects in an asynchronous manner. Technically, we first build a large-scale multimodal neuromorphic object detection dataset (i.e., PKU-DAVIS-SOD) over 1080.1k manual labels. Then, we design a spatiotemporal Transformer architecture to detect objects via an end-to-end sequence prediction problem, where the novel temporal Transformer module leverages rich temporal cues from two visual streams to improve the detection performance. Finally, an asynchronous attention-based fusion module is proposed to integrate two heterogeneous sensing modalities and take complementary advantages from each end, which can be queried at any time to locate objects and break through the limited output frequency from synchronized frame-based fusion strategies. The results show that the proposed SODFormer outperforms four state-of-the-art methods and our eight baselines by a significant margin. We also show that our unifying framework works well even in cases where the conventional frame-based camera fails, e.g., high-speed motion and low-light conditions. Our dataset and code can be available at https://github.com/dianzl/SODFormer.
</details>
<details>
<summary>摘要</summary>
《DAVIS摄像头 Streaming Two Complementary Sensing Modalities of Asynchronous Events and Frames for Object Detection》DAVIS摄像头， Streaming two complementary sensing modalities of asynchronous events and frames，已经被广泛应用于重要的物体检测挑战中（例如快速运动模糊和低光照）。然而，如何有效利用rich temporal cues和融合两种不同的视觉流还是一个挑战。为了解决这个挑战，我们提出了一种新的流动对象检测器，即SODFormer，它首先将事件和帧集成为一起continuously检测物体。技术上，我们首先建立了一个大规模的多模态神经元摄像头检测数据集（即PKU-DAVIS-SOD），包括1080.1k的手动标签。然后，我们设计了一种空间时间Transformer架构，通过一个终到终的序列预测问题，来检测物体。在这个架构中，我们提出了一种新的 temporal Transformer模块，利用了两个视觉流的rich temporal cues来提高检测性能。最后，我们提出了一种异步注意力基于的融合模块，以便将两种不同的感知模式融合在一起，并且可以在任何时候提问，以便查找物体和跨出同步帧基于的融合策略的限制。结果显示，我们提出的SODFormer方法在比较四种state-of-the-art方法和我们的八个基eline之上取得了显著的提高。我们还证明了我们的统一框架在高速运动和低光照等情况下也能够正常工作。我们的数据集和代码可以在https://github.com/dianzl/SODFormer上下载。
</details></li>
</ul>
<hr>
<h2 id="Non-Intrusive-Electric-Load-Monitoring-Approach-Based-on-Current-Feature-Visualization-for-Smart-Energy-Management"><a href="#Non-Intrusive-Electric-Load-Monitoring-Approach-Based-on-Current-Feature-Visualization-for-Smart-Energy-Management" class="headerlink" title="Non-Intrusive Electric Load Monitoring Approach Based on Current Feature Visualization for Smart Energy Management"></a>Non-Intrusive Electric Load Monitoring Approach Based on Current Feature Visualization for Smart Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11627">http://arxiv.org/abs/2308.11627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiwen Xu, Dengfeng Liu, Liangtao Huang, Zhiquan Lin, Tiesong Zhao, Sam Kwong</li>
<li>for: 本研究旨在提出一种非侵入式电力负荷监测方法，以支持智能城市的经济可持续能源管理。</li>
<li>methods: 本文employs popular计算机视觉技术，包括卷积变换和gramianangular场方法，将一维电流信号映射到二维颜色特征图像上。然后，通过U型深度神经网络 WITH multi-scale特征提取和注意机制，识别所有电动负荷。</li>
<li>results: 实验结果表明，提出的方法在公共数据集和私有数据集上均达到了superior表现，可以支持大规模互联网对象（IoT）中的能效能源管理。<details>
<summary>Abstract</summary>
The state-of-the-art smart city has been calling for an economic but efficient energy management over large-scale network, especially for the electric power system. It is a critical issue to monitor, analyze and control electric loads of all users in system. In this paper, we employ the popular computer vision techniques of AI to design a non-invasive load monitoring method for smart electric energy management. First of all, we utilize both signal transforms (including wavelet transform and discrete Fourier transform) and Gramian Angular Field (GAF) methods to map one-dimensional current signals onto two-dimensional color feature images. Second, we propose to recognize all electric loads from color feature images using a U-shape deep neural network with multi-scale feature extraction and attention mechanism. Third, we design our method as a cloud-based, non-invasive monitoring of all users, thereby saving energy cost during electric power system control. Experimental results on both public and our private datasets have demonstrated our method achieves superior performances than its peers, and thus supports efficient energy management over large-scale Internet of Things (IoT).
</details>
<details>
<summary>摘要</summary>
现代智能城市的要求是实现经济高效的能源管理，特别是电力系统。监测、分析和控制所有用户的电载是一个关键问题。在这篇论文中，我们利用人工智能popular计算机视觉技术来设计一种不侵入式的电力监测方法。首先，我们利用信号变换（包括wavelet transform和Discrete Fourier Transform）和Gramian Angular Field（GAF）方法将一维电流信号映射到二维颜色特征图像上。其次，我们提出了通过U型深度神经网络with multi-scale feature extraction和注意机制来识别所有电载。最后，我们设计了一种云端基于的非侵入式监测方法，以 saves energy cost during electric power system control。实验结果表明，我们的方法在公共数据集和私有数据集上都达到了更高的性能，因此支持了大规模Internet of Things（IoT）中的高效能源管理。
</details></li>
</ul>
<hr>
<h2 id="InfeRE-Step-by-Step-Regex-Generation-via-Chain-of-Inference"><a href="#InfeRE-Step-by-Step-Regex-Generation-via-Chain-of-Inference" class="headerlink" title="InfeRE: Step-by-Step Regex Generation via Chain of Inference"></a>InfeRE: Step-by-Step Regex Generation via Chain of Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04041">http://arxiv.org/abs/2308.04041</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smallqqqq/infere">https://github.com/smallqqqq/infere</a></li>
<li>paper_authors: Shuai Zhang, Xiaodong Gu, Yuting Chen, Beijun Shen</li>
<li>for: 这个论文的目的是提出一种新的自然语言生成regex表达式（InfeRE），它可以帮助生成regex表达式的神经语言模型更加准确和可读性好。</li>
<li>methods: 这个论文使用了一种新的批处理方法，即将生成regex表达式的过程 decomposes into chains of step-by-step inference，以提高生成的regex表达式的精度和可读性。此外，它还引入了一种自适应均衡机制，以 Ensemble 多个模型的输出，从而提高了生成的regex表达式的稳定性。</li>
<li>results: 实验结果表明，InfeRE 可以备受提高神经语言模型生成regex表达式的精度，在两个公开的数据集上（NL-RX-Turk 和 KB13）测试，与前一代的基eline 和树状生成方法相比，InfeRE 可以提高 DFA@5 准确率的16.3% 和 14.7%。特别是，InfeRE 可以在两个数据集上，相比之前的树状生成方法，提高 DFA@5 准确率的18.1% 和 11.3%。<details>
<summary>Abstract</summary>
Automatically generating regular expressions (abbrev. regexes) from natural language description (NL2RE) has been an emerging research area. Prior studies treat regex as a linear sequence of tokens and generate the final expressions autoregressively in a single pass. They did not take into account the step-by-step internal text-matching processes behind the final results. This significantly hinders the efficacy and interpretability of regex generation by neural language models. In this paper, we propose a new paradigm called InfeRE, which decomposes the generation of regexes into chains of step-by-step inference. To enhance the robustness, we introduce a self-consistency decoding mechanism that ensembles multiple outputs sampled from different models. We evaluate InfeRE on two publicly available datasets, NL-RX-Turk and KB13, and compare the results with state-of-the-art approaches and the popular tree-based generation approach TRANX. Experimental results show that InfeRE substantially outperforms previous baselines, yielding 16.3% and 14.7% improvement in DFA@5 accuracy on two datasets, respectively. Particularly, InfeRE outperforms the popular tree-based generation approach by 18.1% and 11.3% on both datasets, respectively, in terms of DFA@5 accuracy.
</details>
<details>
<summary>摘要</summary>
自然语言描述（NL2RE）自动生成正则表达式（regex）是一个emerging研究领域。先前的研究通常将regex视为一个连续序列的token，通过单个通过一次推导生成最终结果。然而，这些研究未能考虑regex生成的内部文本匹配过程，这会限制神经语言模型的效果和可读性。在这篇论文中，我们提出了一新的思路called InfeRE，它将regex生成分解为一系列步骤的推导链。为了提高稳定性，我们还引入了自适应嵌入机制，该机制可以从不同模型中抽象多个输出，并将其ensemble。我们在两个公共可用的数据集NL-RX-Turk和KB13上进行了实验，并与当前的基eline和树状生成方法相比较。实验结果表明，InfeREsubstantiallyoutsperforms先前的基eline，在两个数据集上DFA@5准确率提高16.3%和14.7%。尤其是，InfeRE在两个数据集上与树状生成方法相比，DFA@5准确率提高18.1%和11.3%。
</details></li>
</ul>
<hr>
<h2 id="Adapting-Foundation-Models-for-Information-Synthesis-of-Wireless-Communication-Specifications"><a href="#Adapting-Foundation-Models-for-Information-Synthesis-of-Wireless-Communication-Specifications" class="headerlink" title="Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications"></a>Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04033">http://arxiv.org/abs/2308.04033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manikanta Kotaru</li>
<li>for: 本研究旨在提供一种基于人工智能技术的 wireless 通信规范总结工具，帮助用户快速获取相关信息。</li>
<li>methods: 该工具基于现有的基础模型，并添加了三个关键组件：域特定数据库、上下文提取器和反馈机制。用户的问题将被补充了基于技术规范的简短和相关信息。</li>
<li>results: 根据一个标准 benchmark 集合，该工具能够提供更加准确和相关的答案，其中 Bleu 分数和 BERTScore F1-度分别为 0.37 和 0.79，比前一代工具 ChatGPT 的分数高出许多。<details>
<summary>Abstract</summary>
Existing approaches to understanding, developing and researching modern wireless communication technologies involves time-intensive and arduous process of sifting through numerous webpages and technical specification documents, gathering the required information and synthesizing it. This paper presents NextGen Communications Copilot, a conversational artificial intelligence tool for information synthesis of wireless communication specifications. The system builds on top of recent advancements in foundation models and consists of three key additional components: a domain-specific database, a context extractor, and a feedback mechanism. The system appends user queries with concise and query-dependent contextual information extracted from a database of wireless technical specifications and incorporates tools for expert feedback and data contributions. On evaluation using a benchmark dataset of queries and reference responses created by subject matter experts, the system demonstrated more relevant and accurate answers with an average BLEU score and BERTScore F1-measure of 0.37 and 0.79 respectively compared to the corresponding values of 0.07 and 0.59 achieved by state-of-the-art tools like ChatGPT.
</details>
<details>
<summary>摘要</summary>
现有的方法 для了解、开发和研究现代无线通信技术都是一个时间consuming和辛苦的过程，需要逐页搜索众多的网页和技术规范文档，收集所需信息并将其综合化。本文介绍了 NextGen Communications Copilot，一个基于最新的基础模型的会话型人工智能工具，用于无线通信规范信息的综合处理。该系统包括三个关键组件：域pecific数据库、上下文提取器和反馈机制。系统将用户查询 append 与域pecific数据库中的简短和查询dependent的上下文信息，并包括专家反馈和数据贡献工具。经评估使用一个标准 benchmark dataset of queries和 reference responses，创建了由专家制定的查询和参照响应，系统示出了与现有工具 like ChatGPT 的相对比较好的准确性和相关性，其 BLEU 分数和 BERTScore F1-measure 分别为 0.37 和 0.79。
</details></li>
</ul>
<hr>
<h2 id="Measure-of-Uncertainty-in-Human-Emotions"><a href="#Measure-of-Uncertainty-in-Human-Emotions" class="headerlink" title="Measure of Uncertainty in Human Emotions"></a>Measure of Uncertainty in Human Emotions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04032">http://arxiv.org/abs/2308.04032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: Etienne Naude, Henry Gann, Balaram Panda, Lance Zhang, Raina Song, Yuwei Shen</li>
<li>for: 这个研究旨在调查计算机是否能够根据人类表达的情感来进行不同任务。</li>
<li>methods: 这个研究使用了不同的uncertainty信息显示方式来影响人类决策过程。</li>
<li>results: 研究发现，显示更多的uncertainty信息可以帮助用户更自信地做出决策。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Many research explore how well computers are able to examine emotions displayed by humans and use that data to perform different tasks. However, there have been very few research which evaluate the computers ability to generate emotion classification information in an attempt to help the user make decisions or perform tasks. This is a crucial area to explore as it is paramount to the two way communication between humans and computers. This research conducted an experiment to investigate the impact of different uncertainty information displays of emotion classification on the human decision making process. Results show that displaying more uncertainty information can help users to be more confident when making decisions.
</details>
<details>
<summary>摘要</summary>
很多研究都在研究计算机如何识别人类表达的情感，并使用这些数据来完成不同的任务。然而，有很少的研究探讨计算机是否能够生成情感分类信息，以帮助用户做出决策或完成任务。这是一个关键的领域，因为两个方向的人机交互是非常重要的。本研究进行了一项实验，以调查不同的不确定信息显示方式对人类决策过程的影响。结果显示，显示更多的不确定信息可以帮助用户更加自信地做出决策。
</details></li>
</ul>
<hr>
<h2 id="Gentopia-A-Collaborative-Platform-for-Tool-Augmented-LLMs"><a href="#Gentopia-A-Collaborative-Platform-for-Tool-Augmented-LLMs" class="headerlink" title="Gentopia: A Collaborative Platform for Tool-Augmented LLMs"></a>Gentopia: A Collaborative Platform for Tool-Augmented LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04030">http://arxiv.org/abs/2308.04030</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gentopia-ai/gentopia">https://github.com/gentopia-ai/gentopia</a></li>
<li>paper_authors: Binfeng Xu, Xukun Liu, Hua Shen, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng, Yuchen Liu, Ziyu Yao, Dongkuan Xu</li>
<li>For: The paper aims to provide a flexible and customizable framework for Augmented Language Models (ALMs) that enables the use of various language models, task formats, prompting modules, and plugins.* Methods: The paper proposes a new framework called gentopia, which allows users to customize their ALMs through simple configurations and integrates various language models, task formats, prompting modules, and plugins into a unified paradigm.* Results: The paper establishes gentpool, a public platform for registering and sharing user-customized agents, and gentbench, an integral component of gentpool that evaluates user-customized agents across diverse aspects such as safety, robustness, and efficiency.<details>
<summary>Abstract</summary>
Augmented Language Models (ALMs) empower large language models with the ability to use tools, transforming them into intelligent agents for real-world interactions. However, most existing frameworks for ALMs, to varying degrees, are deficient in the following critical features: flexible customization, collaborative democratization, and holistic evaluation. We present gentopia, an ALM framework enabling flexible customization of agents through simple configurations, seamlessly integrating various language models, task formats, prompting modules, and plugins into a unified paradigm. Furthermore, we establish gentpool, a public platform enabling the registration and sharing of user-customized agents. Agents registered in gentpool are composable such that they can be assembled together for agent collaboration, advancing the democratization of artificial intelligence. To ensure high-quality agents, gentbench, an integral component of gentpool, is designed to thoroughly evaluate user-customized agents across diverse aspects such as safety, robustness, efficiency, etc. We release gentopia on Github and will continuously move forward.
</details>
<details>
<summary>摘要</summary>
基于扩展语言模型（ALM）的框架，gentopia，允许大语言模型使用工具，将其转变成智能代理人进行实际交互。然而，现有的ALM框架，各有不同程度的缺失，包括灵活定制、合作民主化和整体评估。我们提出了gentopia框架，允许用户通过简单的配置来自定义代理人，并允许不同的语言模型、任务格式、提示模块和插件在一个统一的架构中协作。此外，我们建立了gentpool公共平台，让用户可以注册和分享自定义代理人。gentpool中注册的代理人可以组合起来，推动人工智能的民主化。为保证高质量代理人，gentbench，gentpool的一个重要组件，专门用于评估用户自定义代理人的多个方面，包括安全、稳定性、效率等。我们将gentopia发布到Github，并将持续推进。
</details></li>
</ul>
<hr>
<h2 id="Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering"><a href="#Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering" class="headerlink" title="Top K Relevant Passage Retrieval for Biomedical Question Answering"></a>Top K Relevant Passage Retrieval for Biomedical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04028">http://arxiv.org/abs/2308.04028</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shashank140195/Biomedical_QA_Model">https://github.com/shashank140195/Biomedical_QA_Model</a></li>
<li>paper_authors: Shashank Gupta</li>
<li>for: 这个论文的目的是提高生物医学问答系统的精度，使其能够更正确地回答生物医学相关的问题。</li>
<li>methods: 这个论文使用了现有的Dense Passage Retrieval（DPR）框架，并对其进行了微调，以便在生物医学领域中应用。具体来说，他们使用了Pubmed文献来回答医学问题。</li>
<li>results: 经过微调后，这个DPR模型在BioASQ问答 dataset上得到了0.81的F1分数，表明其能够准确地回答生物医学相关的问题。<details>
<summary>Abstract</summary>
Question answering is a task that answers factoid questions using a large collection of documents. It aims to provide precise answers in response to the user's questions in natural language. Question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. On the web, there is no single article that could provide all the possible answers available on the internet to the question of the problem asked by the user. The existing Dense Passage Retrieval model has been trained on Wikipedia dump from Dec. 20, 2018, as the source documents for answering questions. Question answering (QA) has made big strides with several open-domain and machine comprehension systems built using large-scale annotated datasets. However, in the clinical domain, this problem remains relatively unexplored. According to multiple surveys, Biomedical Questions cannot be answered correctly from Wikipedia Articles. In this work, we work on the existing DPR framework for the biomedical domain and retrieve answers from the Pubmed articles which is a reliable source to answer medical questions. When evaluated on a BioASQ QA dataset, our fine-tuned dense retriever results in a 0.81 F1 score.
</details>
<details>
<summary>摘要</summary>
问答任务是回答基于大量文档的问题，目的是通过自然语言提供精确的答案。问答依赖于高效的段 Retrieval，传统的稀疏 вектор空间模型，如 TF-IDF 或 BM25，是现实中的标准方法。在互联网上，没有一篇文章可以提供用户问题的所有可能的答案。现有的 dense passage retrieval 模型已经在 Dec. 20, 2018 的Wikipedia dump上进行了训练，作为回答问题的源文档。问答（QA）在开放领域和机器理解领域已经做出了大量的进展，但在医疗领域，这个问题还很少研究。根据多个调查，医学问题无法从 Wikipedia 文章中正确地回答。在这种情况下，我们在现有的 DPR 框架上进行了改进，并从可靠的 Pubmed 文章中提取答案。当评估在 BioASQ QA 数据集上时，我们的精制 dense retriever 得分为 0.81 F1 分。
</details></li>
</ul>
<hr>
<h2 id="AgentSims-An-Open-Source-Sandbox-for-Large-Language-Model-Evaluation"><a href="#AgentSims-An-Open-Source-Sandbox-for-Large-Language-Model-Evaluation" class="headerlink" title="AgentSims: An Open-Source Sandbox for Large Language Model Evaluation"></a>AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04026">http://arxiv.org/abs/2308.04026</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, Qin Chen</li>
<li>for: 评估大语言模型（LLM）的能力是一个公开的问题，因为现有的评估方法受到以下缺点的限制：（1）受限的评估能力，（2）易受到攻击的标准套件，（3）不具有客观的度量。</li>
<li>methods: 我们建议使用任务基本评估方法，即让LLM代理在模拟环境中完成任务，这是一个一 Size fits all的解决方案，可以解决上述问题。我们提供了 AgentSims，一个易于使用的基础设施，它可以帮助研究人员从不同领域测试他们感兴趣的具体能力。研究人员可以通过点击 GUI 或输入几行代码来构建评估任务和添加代理，以及测试新的支持机制，如记忆、规划和工具使用系统。</li>
<li>results: 我们的示例可以在 <a target="_blank" rel="noopener" href="https://agentsims.com/">https://agentsims.com</a> 上查看。<details>
<summary>Abstract</summary>
With ChatGPT-like large language models (LLM) prevailing in the community, how to evaluate the ability of LLMs is an open question. Existing evaluation methods suffer from following shortcomings: (1) constrained evaluation abilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that task-based evaluation, where LLM agents complete tasks in a simulated environment, is a one-for-all solution to solve above problems. We present AgentSims, an easy-to-use infrastructure for researchers from all disciplines to test the specific capacities they are interested in. Researchers can build their evaluation tasks by adding agents and buildings on an interactive GUI or deploy and test new support mechanisms, i.e. memory, planning and tool-use systems, by a few lines of codes. Our demo is available at https://agentsims.com .
</details>
<details>
<summary>摘要</summary>
具有chatGPT大语言模型（LLM）的社区中，评估这些模型的能力是一个公开的问题。现有的评估方法受到以下缺点：（1）受限的评价能力，（2）易受到攻击的标准，（3）不准确的度量。我们建议使用任务基本评估，让LLM代理在模拟环境中完成任务，作为一个一元解决方案。我们提供了 AgentSims，一个易于使用的基础设施，让研究人员从各个领域测试他们感兴趣的具体能力。研究人员可以通过在交互式GUI上添加代理和建筑，或者通过几行代码来部署和测试新的支持机制，如记忆、规划和工具使用系统。我们的 demo 可以在 <https://agentsims.com> 上查看。
</details></li>
</ul>
<hr>
<h2 id="MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition"><a href="#MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition" class="headerlink" title="MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition"></a>MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04025">http://arxiv.org/abs/2308.04025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Pan</li>
<li>for: 本研究旨在探讨speech emotion recognition（SER）方法的可靠性，并研究如何从多个speech attribute的分布角度来模型speech emotion。</li>
<li>methods: 本研究提出了一种基于CNN的新型SER模型，采用了添加性marginsoftmax损失函数来提高类别间特征之间的距离，从而提高分类的精度。此外，提出了一种多种speech attribute控制方法MSAC，可以Explicitly控制speech attribute，使模型免受情绪无关的attribute的影响，捕捉更细腻的情绪相关特征。</li>
<li>results: 对于单个corpus和跨corpus的SER场景，我们的提出的SER工作流程在recognition、generalization和可靠性性方面均表现出优于基eline。单个corpusSER场景中，我们的SER工作流程取得了72.97%的WAR和71.76%的UAR在IEMOCAP corpus上。<details>
<summary>Abstract</summary>
Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97\% and a UAR of 71.76\% on the IEMOCAP corpus.
</details>
<details>
<summary>摘要</summary>
尽管有了 significative progress，speech emotion recognition（SER）仍然具有挑战性，主要是因为情感属性的内在复杂和不确定性，特别是在野外环境中。而现有研究主要关注 reconocimiento y generalización capacidades，这个工作则探索了SER方法的可靠性，并 investigate了如何从数据分布角度来模型speech emotion。 Specifically，我们首先构建了一个基于CNN的SER模型，采用了添加式margin softmax损失函数，以增强不同类别之间的距离，从而提高它们的区分度。其次，我们提出了一种 Multiple Speech Attribute Control（MSAC）方法，以控制speech attribute，使模型免受情感无关的属性的影响，捕捉更细腻的情感相关特征。 Finally，我们对提出的SER工作流进行了首次测试和分析，并在单个corpus和交叉corpus中进行了广泛的实验。结果表明，我们的提出的SER工作流在认知、泛化和可靠性方面均有显著的优异性。此外，在单个corpus中，我们的SER工作流在IEMOCAP corpus上 achievable 的recognition结果为72.97%和71.76%。
</details></li>
</ul>
<hr>
<h2 id="Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration"><a href="#Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration" class="headerlink" title="Scope Loss for Imbalanced Classification and RL Exploration"></a>Scope Loss for Imbalanced Classification and RL Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04024">http://arxiv.org/abs/2308.04024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hasham Burhani, Xiao Qi Shi, Jonathan Jaegerman, Daniel Balicki</li>
<li>for: This paper aims to address the exploration-exploitation trade-off in reinforcement learning and the dataset imbalance problem in supervised classification.</li>
<li>methods: The paper equates the two problems and derives a novel loss function called Scope Loss, which adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances without the need for tuning.</li>
<li>results: The paper shows that Scope Loss outperforms state-of-the-art loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset.<details>
<summary>Abstract</summary>
We demonstrate equivalence between the reinforcement learning problem and the supervised classification problem. We consequently equate the exploration exploitation trade-off in reinforcement learning to the dataset imbalance problem in supervised classification, and find similarities in how they are addressed. From our analysis of the aforementioned problems we derive a novel loss function for reinforcement learning and supervised classification. Scope Loss, our new loss function, adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances, without the need for any tuning. We test Scope Loss against SOTA loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset, and show that Scope Loss outperforms other loss functions.
</details>
<details>
<summary>摘要</summary>
我们证明了回归学习问题与supervised分类问题之间的等价性。我们因此将rek-exploration偏好和数据偏好问题相提并论，并发现它们在解决方面存在相似之处。基于这些问题的分析，我们提出了一种新的损失函数，称为Scope损失。Scope损失函数可以适应找到潜在的性能损失和数据偏好问题，无需任何调整。我们对一组标准回归学习任务和一个偏好分类 dataset进行测试，并证明Scope损失函数在与现状最优损失函数进行比较时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks"><a href="#Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks" class="headerlink" title="Improving Performance of Semi-Supervised Learning by Adversarial Attacks"></a>Improving Performance of Semi-Supervised Learning by Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04018">http://arxiv.org/abs/2308.04018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Kunwoong Kim, Yongdai Kim</li>
<li>for: 提高现有的隐私学习（SSL）算法性能</li>
<li>methods: 利用对预训练模型的 adversarial 攻击选择高自信度无标记数据进行标注</li>
<li>results: 在 CIFAR10 上，与 SCAR 结合的三种 latest SSL algorithms 显示出显著提高图像分类性能<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) algorithm is a setup built upon a realistic assumption that access to a large amount of labeled data is tough. In this study, we present a generalized framework, named SCAR, standing for Selecting Clean samples with Adversarial Robustness, for improving the performance of recent SSL algorithms. By adversarially attacking pre-trained models with semi-supervision, our framework shows substantial advances in classifying images. We introduce how adversarial attacks successfully select high-confident unlabeled data to be labeled with current predictions. On CIFAR10, three recent SSL algorithms with SCAR result in significantly improved image classification.
</details>
<details>
<summary>摘要</summary>
半supervised learning（SSL）算法是基于现实的假设，即获得大量标注数据很Difficult。在这种研究中，我们提出一种普适的框架，名为SCAR，即选择干净样本并具有对抗性强度，以提高 latest SSL算法的性能。通过对预训练模型进行对抗性攻击，我们的框架成功地选择高自信产生的无标注样本进行标注。在CIFAR10上，三种latest SSL算法与SCAR结果显著改善图像分类。
</details></li>
</ul>
<hr>
<h2 id="Multi-Granularity-Attention-Model-for-Group-Recommendation"><a href="#Multi-Granularity-Attention-Model-for-Group-Recommendation" class="headerlink" title="Multi-Granularity Attention Model for Group Recommendation"></a>Multi-Granularity Attention Model for Group Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04017">http://arxiv.org/abs/2308.04017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianye Ji, Jiayan Pei, Shaochuan Lin, Taotao Zhou, Hengxu He, Jia Jia, Ning Hu</li>
<li>for: 提供个性化推荐给多个用户组 based on their shared interests, preferences, and characteristics.</li>
<li>methods: 使用多级别的granularity (i.e., subsets, groups, and supersets) to uncover group members’ latent preferences and mitigate recommendation noise.  Specifically, our method includes a Subset Preference Extraction module, a Group Preference Extraction module, and a Superset Preference Extraction module.</li>
<li>results: 在多个级别的granularity上减少推荐噪音，并全面学习用户的个性兴趣. Extensive offline and online experiments have demonstrated the superiority of our method in terms of performance.<details>
<summary>Abstract</summary>
Group recommendation provides personalized recommendations to a group of users based on their shared interests, preferences, and characteristics. Current studies have explored different methods for integrating individual preferences and making collective decisions that benefit the group as a whole. However, most of them heavily rely on users with rich behavior and ignore latent preferences of users with relatively sparse behavior, leading to insufficient learning of individual interests. To address this challenge, we present the Multi-Granularity Attention Model (MGAM), a novel approach that utilizes multiple levels of granularity (i.e., subsets, groups, and supersets) to uncover group members' latent preferences and mitigate recommendation noise. Specially, we propose a Subset Preference Extraction module that enhances the representation of users' latent subset-level preferences by incorporating their previous interactions with items and utilizing a hierarchical mechanism. Additionally, our method introduces a Group Preference Extraction module and a Superset Preference Extraction module, which explore users' latent preferences on two levels: the group-level, which maintains users' original preferences, and the superset-level, which includes group-group exterior information. By incorporating the subset-level embedding, group-level embedding, and superset-level embedding, our proposed method effectively reduces group recommendation noise across multiple granularities and comprehensively learns individual interests. Extensive offline and online experiments have demonstrated the superiority of our method in terms of performance.
</details>
<details>
<summary>摘要</summary>
群体推荐提供个性化的推荐给群体成员基于他们共同的兴趣、偏好和特征。现有研究已经探索了不同的方法来集成个体偏好并为群体作出共同的决策，但大多数情况都忽略了用户的潜在偏好，导致个体兴趣的学习不够。为解决这个挑战，我们提出了多级别注意力模型（MGAM），一种新的方法，利用不同级别的划分（i.e., 子集、组和超集）来探索群体成员的潜在偏好并减少推荐噪音。具体来说，我们提出了一个子集偏好提取模块，通过利用用户对物品的前期互动和层次机制来强化用户的潜在子集级别偏好的表示。此外，我们的方法还引入了组偏好提取模块和超集偏好提取模块，它们分别探索用户的组级别偏好和超集级别偏好。通过结合子集级别嵌入、组级别嵌入和超集级别嵌入，我们提出的方法可以有效减少群体推荐噪音并全面学习个体兴趣。经过大量的线上和线下实验，我们的方法在性能方面表现出了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning"><a href="#Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning" class="headerlink" title="Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning"></a>Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03999">http://arxiv.org/abs/2308.03999</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii">https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii</a></li>
<li>paper_authors: Abhilekha Dalal, Md Kamruzzaman Sarker, Adrita Barua, Eugene Vasserman, Pascal Hitzler</li>
<li>for: 这篇论文的目的是解释深度学习系统中隐藏层neuron的活动，以提供系统内部检测输入的相关信息，从而减轻深度学习系统的黑盒效应。</li>
<li>methods: 这篇论文使用了大规模背景知识（约200万类）和基于描述逻辑的符号推理方法 called Concept Induction，原本设计用于semantic web领域。这种方法可以自动将大规模背景知识链接到 convolutional neural network 中 dense layer 中的各个神经元，并通过假设和验证过程提供有意义的标签。</li>
<li>results: 研究结果表明，这种方法可以自动地将大规模背景知识链接到 convolutional neural network 中 dense layer 中的各个神经元，并提供有意义的标签。这些标签可以帮助解释深度学习系统中隐藏层neuron的活动，从而减轻深度学习系统的黑盒效应。<details>
<summary>Abstract</summary>
A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, demystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Our results show that we can automatically attach meaningful labels from the background knowledge to individual neurons in the dense layer of a Convolutional Neural Network through a hypothesis and verification process.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在可解释人工智能是正确地解释隐藏神经元的活动：正确的解释会提供关于deep learning系统内部检测到的输入信息的深入了解，从而消除深度学习系统的黑盒特性。现状的最佳实践表明，隐藏节点的活动可以，在某些情况下，被解释得通常是人类可理解的，但系统化的自动方法，能够假设和验证解释隐藏神经元的活动，尚未得到充分的探索。在这篇论文中，我们提供了一种这样的方法，并证明它可以提供有意义的解释。我们的方法基于使用大规模的背景知识（约200万个类别），来自Wikipedia概念层次结构，以及基于描述逻辑的符号推理方法 called Concept Induction，原始是为Semantic Web领域开发的。我们的结果表明，我们可以通过一种假设和验证过程，自动将background知识中的有意义标签附加到 convolutional neural network 的紧凑层中的个体神经元。
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks"><a href="#Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks" class="headerlink" title="Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks"></a>Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03995">http://arxiv.org/abs/2308.03995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengxi Zhang, Huaze Tang, Wenbo Ding, Xiao-Ping Zhang</li>
<li>for: 这篇论文的目的是提出一个包含多种通讯链接的Space-Air-Ground Integrated Network（SAGIN）系统，并使用合作多型多代理人深度强化学习（CMT-MARL）方法来解决资源管理问题。</li>
<li>methods: 这篇论文使用了五种不同的通讯链接，并提出了一个有效的CMT-MARL方法来管理这些链接的资源。</li>
<li>results: 实验结果显示了CMT-MARL方法的有效性，包括总转送率和转送成功率等关键性能指标。这些结果证明了SAGIN系统的可能性和实现性。<details>
<summary>Abstract</summary>
The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous devices including low earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users (GUs), holds significant promise for advancing smart city applications. However, resource management of the SAGIN is a challenge requiring urgent study in that inappropriate resource management will cause poor data transmission, and hence affect the services in smart cities. In this paper, we develop a comprehensive SAGIN system that encompasses five distinct communication links and propose an efficient cooperative multi-type multi-agent deep reinforcement learning (CMT-MARL) method to address the resource management issue. The experimental results highlight the efficacy of the proposed CMT-MARL, as evidenced by key performance indicators such as the overall transmission rate and transmission success rate. These results underscore the potential value and feasibility of future implementation of the SAGIN.
</details>
<details>
<summary>摘要</summary>
Space-Air-Ground  интеegrated Network (SAGIN)，融合各种不同设备，包括低地球轨道卫星（LEO）、无人飞行器（UAV）和地面用户（GU），具有推动智能城市应用的巨大潜力。然而，SAGIN资源管理是一项需要紧迫研究的挑战，因为不当的资源管理会导致数据传输差，从而影响智能城市服务的质量。在这篇论文中，我们提出了一个全面的 SAGIN 系统，包括五种不同的通信链接，并提出了一种高效的合作多种多代理人深度学习（CMT-MARL）方法来解决资源管理问题。实验结果表明，提议的 CMT-MARL 方法能够减少数据传输差和提高传输成功率，这些结果证明了 SAGIN 的可能性和实现性。
</details></li>
</ul>
<hr>
<h2 id="AI-Chatbots-as-Multi-Role-Pedagogical-Agents-Transforming-Engagement-in-CS-Education"><a href="#AI-Chatbots-as-Multi-Role-Pedagogical-Agents-Transforming-Engagement-in-CS-Education" class="headerlink" title="AI Chatbots as Multi-Role Pedagogical Agents: Transforming Engagement in CS Education"></a>AI Chatbots as Multi-Role Pedagogical Agents: Transforming Engagement in CS Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03992">http://arxiv.org/abs/2308.03992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cassie Chen Cao, Zijian Ding, Jionghao Lin, Frank Hopfgartner<br>for:这项研究旨在利用人工智能（AI）搭载的多角色 чат bot 来提高计算机科学教育的学习经验和参与度。methods:我们采用了设计基本研究方法，开发、实现和评估一个具有四个不同 чат bot 角色的学习环境，这些角色基于自主决定理论，满足学生的三种 innate 心理需求 - 能力、自主和相互关系。results:我们在高等教育上下文中进行了一个月的测试，征得 200 名学生的参与，并与人教和单个 чат bot 的条件进行比较。我们的研究采用了混合方法，包括量化测量如 chat log 序列分析，以及讨论和问卷调查。通过结合 cutting-edge 自然语言处理技术如话题分析和情感分析，我们提供了深入的理解系统对学生参与度、动机和问题解决方面的影响。<details>
<summary>Abstract</summary>
This study investigates the use of Artificial Intelligence (AI)-powered, multi-role chatbots as a means to enhance learning experiences and foster engagement in computer science education. Leveraging a design-based research approach, we develop, implement, and evaluate a novel learning environment enriched with four distinct chatbot roles: Instructor Bot, Peer Bot, Career Advising Bot, and Emotional Supporter Bot. These roles, designed around the tenets of Self-Determination Theory, cater to the three innate psychological needs of learners - competence, autonomy, and relatedness. Additionally, the system embraces an inquiry-based learning paradigm, encouraging students to ask questions, seek solutions, and explore their curiosities.   We test this system in a higher education context over a period of one month with 200 participating students, comparing outcomes with conditions involving a human tutor and a single chatbot. Our research utilizes a mixed-methods approach, encompassing quantitative measures such as chat log sequence analysis, and qualitative methods including surveys and focus group interviews. By integrating cutting-edge Natural Language Processing techniques such as topic modelling and sentiment analysis, we offer an in-depth understanding of the system's impact on learner engagement, motivation, and inquiry-based learning.   This study, through its rigorous design and innovative approach, provides significant insights into the potential of AI-empowered, multi-role chatbots in reshaping the landscape of computer science education and fostering an engaging, supportive, and motivating learning environment.
</details>
<details>
<summary>摘要</summary>
We test the system in a higher education context for one month with 200 participating students, comparing outcomes with conditions involving a human tutor and a single chatbot. Our research combines quantitative measures such as chat log sequence analysis and qualitative methods like surveys and focus group interviews. We employ cutting-edge Natural Language Processing techniques like topic modeling and sentiment analysis to gain a deeper understanding of the system's impact on learner engagement, motivation, and inquiry-based learning.Our study offers significant insights into the potential of AI-empowered, multi-role chatbots to reshape computer science education and create an engaging, supportive, and motivating learning environment. By integrating innovative approaches and cutting-edge technologies, we provide a comprehensive understanding of the system's effectiveness and its potential for future applications.
</details></li>
</ul>
<hr>
<h2 id="NEOLAF-an-LLM-powered-neural-symbolic-cognitive-architecture"><a href="#NEOLAF-an-LLM-powered-neural-symbolic-cognitive-architecture" class="headerlink" title="NEOLAF, an LLM-powered neural-symbolic cognitive architecture"></a>NEOLAF, an LLM-powered neural-symbolic cognitive architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03990">http://arxiv.org/abs/2308.03990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard Jiarui Tong, Cassie Chen Cao, Timothy Xueqian Lee, Guodong Zhao, Ray Wan, Feiyue Wang, Xiangen Hu, Robin Schmucker, Jinsheng Pan, Julian Quevedo, Yu Lu</li>
<li>for: 这篇论文旨在构建一个智能代理人，用于解决复杂的数学问题。</li>
<li>methods: 该论文提出了一种基于神经网络和符号学的聪明架构，名为NEOLAF，可以模型和构建智能代理人。NEOLAF架构具有可解释性、逐步学习、高效性、协作和分布式学习、人工智能在循环中启用、自我改进等优点。</li>
<li>results: 在使用MATH数据集上进行的实验表明，NEOLAF代理人具有出色的学习能力，并且有可能革新认知架构和自我改进的教学系统。<details>
<summary>Abstract</summary>
This paper presents the Never Ending Open Learning Adaptive Framework (NEOLAF), an integrated neural-symbolic cognitive architecture that models and constructs intelligent agents. The NEOLAF framework is a superior approach to constructing intelligent agents than both the pure connectionist and pure symbolic approaches due to its explainability, incremental learning, efficiency, collaborative and distributed learning, human-in-the-loop enablement, and self-improvement. The paper further presents a compelling experiment where a NEOLAF agent, built as a problem-solving agent, is fed with complex math problems from the open-source MATH dataset. The results demonstrate NEOLAF's superior learning capability and its potential to revolutionize the field of cognitive architectures and self-improving adaptive instructional systems.
</details>
<details>
<summary>摘要</summary>
Translation Notes:* "Never Ending Open Learning Adaptive Framework" (NEOLAF) is translated as "无止境开放学习适应框架" (Wú zhì jìng kāifàng xuéxí suīyìng kāngyì)* "pure connectionist" is translated as "纯连接主义" (chún liánxì zhǔyì)* "pure symbolic" is translated as "纯符号主义" (chún fúhào zhǔyì)* "explainability" is translated as "可解释性" (kějìexplainability)* "incremental learning" is translated as "逐步学习" (jìbù xuéxí)* "efficiency" is translated as "效率" (fùliàng)* "collaborative and distributed learning" is translated as "合作分布式学习" (hèzuò fēnzhèng zhīxíng xuéxí)* "human-in-the-loop enablement" is translated as "人在循环启用" (rén zài xiànglún kāi yòng)* "self-improvement" is translated as "自我改进" (zìwǒ gǎi jìn)
</details></li>
</ul>
<hr>
<h2 id="SimplyRetrieve-A-Private-and-Lightweight-Retrieval-Centric-Generative-AI-Tool"><a href="#SimplyRetrieve-A-Private-and-Lightweight-Retrieval-Centric-Generative-AI-Tool" class="headerlink" title="SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool"></a>SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03983">http://arxiv.org/abs/2308.03983</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rcgai/simplyretrieve">https://github.com/rcgai/simplyretrieve</a></li>
<li>paper_authors: Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka, Osamu Torii, Tomoya Kodama, Jun Deguchi</li>
<li>for: 这篇论文旨在探讨如何通过私有数据和公共可用的生成AI系统之间的集成，以提高生成AI的性能而不需要额外的模型微调。</li>
<li>methods: 该论文使用了 Retrieval-Centric Generation（RCG）方法，其中分离了LLM和检索器在上下文理解和知识储存中的角色，从而可能导致更高效的实现。</li>
<li>results: 该论文介绍了一个开源的GUI和API基于RCG平台，名为SimplyRetrieve，它具有本地化、轻量级和用户友好的界面，可以帮助机器学习社区更好地利用这些高级技术。<details>
<summary>Abstract</summary>
Large Language Model (LLM) based Generative AI systems have seen significant progress in recent years. Integrating a knowledge retrieval architecture allows for seamless integration of private data into publicly available Generative AI systems using pre-trained LLM without requiring additional model fine-tuning. Moreover, Retrieval-Centric Generation (RCG) approach, a promising future research direction that explicitly separates roles of LLMs and retrievers in context interpretation and knowledge memorization, potentially leads to more efficient implementation. SimplyRetrieve is an open-source tool with the goal of providing a localized, lightweight, and user-friendly interface to these sophisticated advancements to the machine learning community. SimplyRetrieve features a GUI and API based RCG platform, assisted by a Private Knowledge Base Constructor and a Retrieval Tuning Module. By leveraging these capabilities, users can explore the potential of RCG for improving generative AI performance while maintaining privacy standards. The tool is available at https://github.com/RCGAI/SimplyRetrieve with an MIT license.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CheXFusion-Effective-Fusion-of-Multi-View-Features-using-Transformers-for-Long-Tailed-Chest-X-Ray-Classification"><a href="#CheXFusion-Effective-Fusion-of-Multi-View-Features-using-Transformers-for-Long-Tailed-Chest-X-Ray-Classification" class="headerlink" title="CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification"></a>CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03968">http://arxiv.org/abs/2308.03968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongkyun Kim</li>
<li>for: 这份论文是为了解决医疗影像分类中的长尾分布、诊断发现之间的共存、以及每个研究或病人可以提供多个视角的问题。</li>
<li>methods: 这份论文提出了一个基于对称融合模组的解决方案，称为CheXFusion，可以有效地聚合多个视角特征，并考虑预测结果的共存关系。这个模组利用自我注意和跨视角注意机制来有效地聚合多个视角特征。此外，论文还探讨了资料平衡和自我训练方法来优化模型的性能。</li>
<li>results: 这份论文的解决方案在MIMIC-CXR测试集上取得了0.372 mAP的成绩，在竞赛中排名第一。这表明了考虑多个视角、类别不均匀和预测结果的共存关系在医疗影像分类中的重要性。论文的代码可以在<a target="_blank" rel="noopener" href="https://github.com/dongkyuk/CXR-LT-public-solution%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/dongkyuk/CXR-LT-public-solution上获取。</a><details>
<summary>Abstract</summary>
Medical image classification poses unique challenges due to the long-tailed distribution of diseases, the co-occurrence of diagnostic findings, and the multiple views available for each study or patient. This paper introduces our solution to the ICCV CVAMD 2023 Shared Task on CXR-LT: Multi-Label Long-Tailed Classification on Chest X-Rays. Our approach introduces CheXFusion, a transformer-based fusion module incorporating multi-view images. The fusion module, guided by self-attention and cross-attention mechanisms, efficiently aggregates multi-view features while considering label co-occurrence. Furthermore, we explore data balancing and self-training methods to optimize the model's performance. Our solution achieves state-of-the-art results with 0.372 mAP in the MIMIC-CXR test set, securing 1st place in the competition. Our success in the task underscores the significance of considering multi-view settings, class imbalance, and label co-occurrence in medical image classification. Public code is available at https://github.com/dongkyuk/CXR-LT-public-solution
</details>
<details>
<summary>摘要</summary>
医学图像分类面临独特挑战，这些挑战包括疾病的长尾分布、诊断发现的共处和每个案例或病人可以提供多个视图。本文介绍我们在ICCV CVAMD 2023 共同任务中的解决方案：多标签长尾分类在胸部X射线图像（CXR-LT）中。我们的方法引入了CheXFusion，一种基于变换器的融合模块，该模块通过自我注意和交叉注意机制有效地聚合多视图特征，同时考虑标签共处。此外，我们还探索了数据填充和自我训练方法来优化模型性能。我们的解决方案在MIMIC-CXR测试集上 achievement 0.372 mAP，在竞赛中获得了第一名，这 подтвержда了在医学图像分类中考虑多视图设置、类别不均衡和标签共处的重要性。我们的代码可以在https://github.com/dongkyuk/CXR-LT-public-solution 上获取。
</details></li>
</ul>
<hr>
<h2 id="ALFA-–-Leveraging-All-Levels-of-Feature-Abstraction-for-Enhancing-the-Generalization-of-Histopathology-Image-Classification-Across-Unseen-Hospitals"><a href="#ALFA-–-Leveraging-All-Levels-of-Feature-Abstraction-for-Enhancing-the-Generalization-of-Histopathology-Image-Classification-Across-Unseen-Hospitals" class="headerlink" title="ALFA – Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals"></a>ALFA – Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03936">http://arxiv.org/abs/2308.03936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Milad Sikaroudi, Maryam Hosseini, Shahryar Rahnamayan, H. R. Tizhoosh</li>
<li>for: 提高图像分类的泛化性，使模型能够在不同的医院中提供更好的表现</li>
<li>methods: 使用扩展自我超级视图，并在不同的分布差异场景下进行自我超级视图，从而 derivatin invariant feature from training images，并使用域对齐模块来进一步提取抽象特征</li>
<li>results: 实验结果表明，提出的方法可以在不同的医院图像中提供更好的泛化性，并在不同的分布差异场景下进行更好的表现<details>
<summary>Abstract</summary>
We propose an exhaustive methodology that leverages all levels of feature abstraction, targeting an enhancement in the generalizability of image classification to unobserved hospitals. Our approach incorporates augmentation-based self-supervision with common distribution shifts in histopathology scenarios serving as the pretext task. This enables us to derive invariant features from training images without relying on training labels, thereby covering different abstraction levels. Moving onto the subsequent abstraction level, we employ a domain alignment module to facilitate further extraction of invariant features across varying training hospitals. To represent the highly specific features of participating hospitals, an encoder is trained to classify hospital labels, independent of their diagnostic labels. The features from each of these encoders are subsequently disentangled to minimize redundancy and segregate the features. This representation, which spans a broad spectrum of semantic information, enables the development of a model demonstrating increased robustness to unseen images from disparate distributions. Experimental results from the PACS dataset (a domain generalization benchmark), a synthetic dataset created by applying histopathology-specific jitters to the MHIST dataset (defining different domains with varied distribution shifts), and a Renal Cell Carcinoma dataset derived from four image repositories from TCGA, collectively indicate that our proposed model is adept at managing varying levels of image granularity. Thus, it shows improved generalizability when faced with new, out-of-distribution hospital images.
</details>
<details>
<summary>摘要</summary>
我们提出了一种涵盖所有水平的特征抽象方法，目的是提高图像分类的通用性，覆盖不同医院的不见图像。我们的方法通过在历史病理景象中添加自我超visuospatial alignment，使得在不需要训练标签的情况下 derivation invariant features from 训练图像。在接下来的层次，我们使用域Alignment模块来进一步提取不同医院的抽象特征。为了表示参与医院的特定特征，我们训练了一个Encoder来分类医院标签，不同于其诊断标签。从每个Encoder中提取的特征后，我们进行了拟合以避免重复性和分化特征。这种表示，覆盖了广泛的语义信息，使得我们提出的模型在面对新、未经见图像时显示出更好的通用性。实验结果来自PACS数据集（领域通用性标准 benchmark）、在应用特定于 histopathology 的扰动后生成的 sintethic 数据集以及来自TCGA的 Renal Cell Carcinoma 数据集，表明我们的模型在不同水平的图像粒度下具有更好的普适性。
</details></li>
</ul>
<hr>
<h2 id="Establishing-Trust-in-ChatGPT-BioMedical-Generated-Text-An-Ontology-Based-Knowledge-Graph-to-Validate-Disease-Symptom-Links"><a href="#Establishing-Trust-in-ChatGPT-BioMedical-Generated-Text-An-Ontology-Based-Knowledge-Graph-to-Validate-Disease-Symptom-Links" class="headerlink" title="Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links"></a>Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03929">http://arxiv.org/abs/2308.03929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Abdeen Hamed, Alessandro Crimi, Magdalena M. Misiak, Byung Suk Lee</li>
<li>for: 本研究的目的是使用ontology-based知识图构建医学文献和人工智能生成的内容，以分辨准确信息和未经验证的数据。</li>
<li>methods: 我们使用了疾病 ontology (DOID) 和症状 ontology (SYMP) 构建知识图，并使用了我们的事实检查算法和网络中心性度量来进行 GPT 疾病-症状链分析，以量化医学文献和人工智能生成的内容中的准确性。</li>
<li>results: 我们的结果表明，在比较不同的 ChatGPT 知识图和其相应的 PubMed 知识图时，发现了一些有趣的观察结果。例如，一些 ChatGPT 知识图中的连接数比 PubMed 知识图更多，而且一些 GPT 知识图的中心性度量更高，尤其是对于相互重叠的节点。这些结果表明了人工智能生成的内容中的未经验证知识的潜在价值，需要进一步验证。<details>
<summary>Abstract</summary>
Methods: Through an innovative approach, we construct ontology-based knowledge graphs from authentic medical literature and AI-generated content. Our goal is to distinguish factual information from unverified data. We compiled two datasets: one from biomedical literature using a "human disease and symptoms" query, and another generated by ChatGPT, simulating articles. With these datasets (PubMed and ChatGPT), we curated 10 sets of 250 abstracts each, selected randomly with a specific seed. Our method focuses on utilizing disease ontology (DOID) and symptom ontology (SYMP) to build knowledge graphs, robust mathematical models that facilitate unbiased comparisons. By employing our fact-checking algorithms and network centrality metrics, we conducted GPT disease-symptoms link analysis to quantify the accuracy of factual knowledge amid noise, hypotheses, and significant findings.   Results: The findings obtained from the comparison of diverse ChatGPT knowledge graphs with their PubMed counterparts revealed some interesting observations. While PubMed knowledge graphs exhibit a wealth of disease-symptom terms, it is surprising to observe that some ChatGPT graphs surpass them in the number of connections. Furthermore, some GPT graphs are demonstrating supremacy of the centrality scores, especially for the overlapping nodes. This striking contrast indicates the untapped potential of knowledge that can be derived from AI-generated content, awaiting verification. Out of all the graphs, the factual link ratio between any two graphs reached its peak at 60%.   Conclusions: An intriguing insight from our findings was the striking number of links among terms in the knowledge graph generated from ChatGPT datasets, surpassing some of those in its PubMed counterpart. This early discovery has prompted further investigation using universal network metrics to unveil the new knowledge the links may hold.
</details>
<details>
<summary>摘要</summary>
方法：通过创新的方法，我们从authentic医学文献和AI生成的内容中构建了ontology-based知识图。我们的目标是区分 фактической信息和未经证实的数据。我们编译了两个数据集：一个是生物医学文献，使用“人类疾病和症状”查询，另一个是由ChatGPT生成的文章。 With这两个数据集（PubMed和ChatGPT），我们精心审选了250个摘要，使用特定的种子值进行随机选择。我们的方法是利用疾病ontology（DOID）和症状ontology（SYMP）建立知识图，并使用我们的 фактиче性检查算法和网络中心度度量来进行GPT疾病-症状链接分析，以量化factual知识中的噪音、假设和重要发现。结果：对比多个ChatGPT知识图与其PubMed对应的知识图，我们发现了一些有趣的观察。PubMed知识图显示了丰富的疾病-症状 термина，但是某些ChatGPT graphs在连接数量方面超过了它们。此外，一些GPT graphs的中心度分数特别高，特别是在重叠的节点上。这个明显的对比表明AI生成的内容中的知识尚未得到证实，但它们具有潜在的价值。在所有知识图中，factual链接比率最高达60%。结论：我们的发现表明，ChatGPT生成的知识图中的链接数量异常多，有些连接数量甚至超过了PubMed知识图中的一些连接。这种早期的发现已经引发了我们进一步的调查，使用通用网络度量来揭示这些链接可能含有的新知识。
</details></li>
</ul>
<hr>
<h2 id="ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition"><a href="#ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition" class="headerlink" title="ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition"></a>ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03908">http://arxiv.org/abs/2308.03908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumyabrata Chaudhuri, Saumik Bhattacharya</li>
<li>for: 本文提出了一种基于多模态学习的人体动作识别方法，以提高人体动作识别的准确率。</li>
<li>methods: 本文使用了一种pose增强的视觉语言模型（VLM），结合了pose、视觉信息和文本特征，以便更好地识别人体动作。</li>
<li>results: 根据实验结果，本文的方法在UCFC-101和HMDB-51两个人体动作识别数据集上的准确率分别为92.81%和73.02%，而无需视频数据预训练，而且经过kinetics预训练后，准确率分别提高至96.11%和75.75%。<details>
<summary>Abstract</summary>
Video Action Recognition (VAR) is a challenging task due to its inherent complexities. Though different approaches have been explored in the literature, designing a unified framework to recognize a large number of human actions is still a challenging problem. Recently, Multi-Modal Learning (MML) has demonstrated promising results in this domain. In literature, 2D skeleton or pose modality has often been used for this task, either independently or in conjunction with the visual information (RGB modality) present in videos. However, the combination of pose, visual information, and text attributes has not been explored yet, though text and pose attributes independently have been proven to be effective in numerous computer vision tasks. In this paper, we present the first pose augmented Vision-language model (VLM) for VAR. Notably, our scheme achieves an accuracy of 92.81% and 73.02% on two popular human video action recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even without any video data pre-training, and an accuracy of 96.11% and 75.75% after kinetics pre-training.
</details>
<details>
<summary>摘要</summary>
视频动作识别（VAR）是一个复杂的任务，它的内在复杂性使得设计一个综合性的框架来识别大量人类动作变得具有挑战性。在文献中，不同的方法已经被探讨，但是设计一个综合性的框架来识别大量人类动作仍然是一个挑战性的问题。在文献中，2D骨架或 pose 模式 часто被用于这项任务，可以独立或与视觉信息（RGB 模式）一起使用。然而，将 pose、视觉信息和文本特征相结合尚未被探讨，尽管文本和 pose 特征独立地已经在计算机视觉任务中证明有效。在这篇论文中，我们提出了首个含有pose的视力语言模型（VLM），该模型在 UCF-101 和 HMDB-51 两个常用的人类视频动作识别 benchmark 数据集上取得了92.81% 和 73.02% 的准确率，而不需要任何视频数据预训练，并且在 kinetic 预训练后达到了96.11% 和 75.75% 的准确率。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Assistant-Language-Understanding-On-Device"><a href="#Intelligent-Assistant-Language-Understanding-On-Device" class="headerlink" title="Intelligent Assistant Language Understanding On Device"></a>Intelligent Assistant Language Understanding On Device</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03905">http://arxiv.org/abs/2308.03905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Cecilia Aas, Hisham Abdelsalam, Irina Belousova, Shruti Bhargava, Jianpeng Cheng, Robert Daland, Joris Driesen, Federico Flego, Tristan Guigue, Anders Johannsen, Partha Lal, Jiarui Lu, Joel Ruben Antony Moniz, Nathan Perkins, Dhivya Piraviperumal, Stephen Pulman, Diarmuid Ó Séaghdha, David Q. Sun, John Torr, Marco Del Vecchio, Jay Wacker, Jason D. Williams, Hong Yu</li>
<li>for: 本研究旨在提出一种运行于个人设备上的自然语言理解系统，以提高隐私、可靠性、速度、表达力和准确性。</li>
<li>methods: 本文介绍了设计选择和技术方向，包括对对话系统文献中一些方法的实践评估，以及对适用于实际部署的挑战。</li>
<li>results: 本研究实现了一种更加私钥、可靠、快速、表达力和准确的自然语言理解系统，并提供了实践经验和建议，以便未来的研究工作。<details>
<summary>Abstract</summary>
It has recently become feasible to run personal digital assistants on phones and other personal devices. In this paper we describe a design for a natural language understanding system that runs on device. In comparison to a server-based assistant, this system is more private, more reliable, faster, more expressive, and more accurate. We describe what led to key choices about architecture and technologies. For example, some approaches in the dialog systems literature are difficult to maintain over time in a deployment setting. We hope that sharing learnings from our practical experiences may help inform future work in the research community.
</details>
<details>
<summary>摘要</summary>
现在已经可以在手机和其他个人设备上运行个人数字助手。在这篇论文中，我们描述了一种运行在设备上的自然语言理解系统的设计。与服务器上的助手相比，这种系统更加私钥、可靠、快速、表达力强、准确。我们详细介绍了一些关键的建筑和技术选择。例如，一些对话系统文献中的方法在部署环境中具有维护困难。我们希望通过分享我们的实践经验，对未来的研究工作产生影响。
</details></li>
</ul>
<hr>
<h2 id="FLIPS-Federated-Learning-using-Intelligent-Participant-Selection"><a href="#FLIPS-Federated-Learning-using-Intelligent-Participant-Selection" class="headerlink" title="FLIPS: Federated Learning using Intelligent Participant Selection"></a>FLIPS: Federated Learning using Intelligent Participant Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03901">http://arxiv.org/abs/2308.03901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Atul Bhope, K. R. Jayaram, Nalini Venkatasubramanian, Ashish Verma, Gegi Thomas<br>for: 这个论文旨在解决 Federated Learning (FL) 训练任务中数据和参与者多样性的管理问题，特别是在FL训练过程中对参与者选择的影响。methods: 该论文提出了一种基于标签分布划分的中间件系统，称为 FLIPS，它可以在FL训练过程中对参与者进行划分，以确保每个划分群在参与者选择中具有平等的代表性。此外，FLIPS还支持多种常见的FL算法，包括 FedAvg、FedProx、FedDyn、FedOpt 和 FedYogi。为了管理分布式平台的多样性和动态资源可用性，FLIPS还包含了一种卫星管理机制。results: 该论文的实验研究表明，FLIPS可以在实际世界数据集上提高FL训练的精度，相比随机选择、Oort和梯度划分等其他两种”聪明”选择机制，FLIPS可以在20-60%的通信成本下提高精度 by 17-20%。此外，FLIPS的效果还能在存在延迟参与者的情况下保持。<details>
<summary>Abstract</summary>
This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as two other "smart" selection mechanisms - Oort and gradient clustering using two real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17 - 20 % with 20 - 60 % lower communication costs, and these benefits endure in the presence of straggler participants.
</details>
<details>
<summary>摘要</summary>
具体来说，这篇论文提出了一个名为FLIPS的中间件系统，用于管理 federated learning（FL）训练任务中的数据和参与者多样性。FLIPS在FL训练之前将参与者按照其标签分布进行分群，并在训练中确保每个分群都得到了公平的表现。FLIPS支持通用的FL算法，同时管理平台多样性和动态资源可用性，并通过安全执行环境（TEE）保证标签分布、分群和参与者选择的隐私。我们的实验证明，FLIPS可以大幅提高FL训练的收敛速度，在20-60%的通信成本下达到17-20%的高精度，这些优势在受到延迟参与者的情况下也保持不变。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations"><a href="#Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations" class="headerlink" title="Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations"></a>Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03882">http://arxiv.org/abs/2308.03882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirbhay Modhe, Qiaozi Gao, Ashwin Kalyan, Dhruv Batra, Govind Thattai, Gaurav Sukhatme</li>
<li>for: 这个论文主要研究了线上强化学习（RL）方法在找到未知状态的问题上。</li>
<li>methods: 这个论文使用了模型自由RL方法和模型基于RL方法，它们都会征略未知状态的值。但是这些方法因两个因素受限：一是模型的扩展horizon非常短，二是模型扩展只基于已知的Offline数据。这个论文提出了一种新的未知状态扩展策略，允许在已知状态的基础上找到未知状态。</li>
<li>results: 这个论文在多个Offline RL任务中实现了改进的性能，并发现了其扩展策略通常比基eline更保守。<details>
<summary>Abstract</summary>
Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to seen data). We observe improved performance in several offline RL tasks and find that our augmentation strategy consistently leads to overall lower average dataset Q-value estimates i.e. more conservative Q-value estimates than a baseline.
</details>
<details>
<summary>摘要</summary>
“在线束缚学习（RL）方法寻求平衡between exploration和利用，通过保守的价值估计--- penalty 未看过的状态和动作的价值。无模型方法对所有未看过的动作进行 penalty，而具有模型方法可以通过模型执行来进一步利用未看过的状态。然而，这些方法因两个因素受到限制---（a）模型中的执行 horizon 非常短，因为模型错误的堆叠，以及（b）模型执行仅启动自已经见过的状态。我们松动这一假设，并提出了一种新的未看过状态扩展策略，允许在已知模型和价值估计中利用未看过状态。我们的策略通过在已经看过的状态上进行价值意识的偏移，然后过滤高度不确定性（高错误）或者太相似于已经看过的数据的状态。我们发现在多个Offline RL任务中表现出色，并观察到我们的扩展策略通常比基准值更保守，即更低的平均数据Q值估计。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Guarding-the-Guardians-Automated-Analysis-of-Online-Child-Sexual-Abuse"><a href="#Guarding-the-Guardians-Automated-Analysis-of-Online-Child-Sexual-Abuse" class="headerlink" title="Guarding the Guardians: Automated Analysis of Online Child Sexual Abuse"></a>Guarding the Guardians: Automated Analysis of Online Child Sexual Abuse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03880">http://arxiv.org/abs/2308.03880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juanita Puentes, Angela Castillo, Wilmar Osejo, Yuly Calderón, Viviana Quintero, Lina Saldarriaga, Diana Agudelo, Pablo Arbeláez</li>
<li>For: The paper is written to address the urgent need for a solution to analyze children’s sexual abuse reports comprehensively, with a focus on reducing the risk of exposure to harmful content for analysts.* Methods: The paper proposes a novel automated tool that categorizes reports on three dimensions: Subject, Degree of Criminality, and Damage. Additionally, the paper introduces a novel approach to annotate the collected data, enabling a more in-depth analysis of the reports.* Results: The paper’s approach significantly reduces the risk of exposure to harmful content for analysts, and improves the comprehension of fundamental patterns and trends in children’s sexual abuse reports, enabling law enforcement agencies and policymakers to create focused strategies in the fight against children’s violence.In Simplified Chinese text, the three key points would be:</li>
<li>for: 这篇论文是为了解决儿童色情虐待报告的全面分析问题，尤其是减少分析人员遭受有害内容的风险。</li>
<li>methods: 论文提出了一种新的自动化工具，可以将报告分为三个维度：主体、犯罪程度和伤害。此外，论文还介绍了一种新的标注方法，以便更深入地分析报告中的数据。</li>
<li>results: 论文的方法可以明显减少分析人员遭受有害内容的风险，同时提高了对儿童色情虐待报告的基本 patrón和趋势的理解，为儿童保护和法制建设提供了有力的支持。<details>
<summary>Abstract</summary>
Online violence against children has increased globally recently, demanding urgent attention. Competent authorities manually analyze abuse complaints to comprehend crime dynamics and identify patterns. However, the manual analysis of these complaints presents a challenge because it exposes analysts to harmful content during the review process. Given these challenges, we present a novel solution, an automated tool designed to analyze children's sexual abuse reports comprehensively. By automating the analysis process, our tool significantly reduces the risk of exposure to harmful content by categorizing the reports on three dimensions: Subject, Degree of Criminality, and Damage. Furthermore, leveraging our multidisciplinary team's expertise, we introduce a novel approach to annotate the collected data, enabling a more in-depth analysis of the reports. This approach improves the comprehension of fundamental patterns and trends, enabling law enforcement agencies and policymakers to create focused strategies in the fight against children's violence.
</details>
<details>
<summary>摘要</summary>
在全球范围内，网络对儿童的暴力行为已经增加，需要紧急关注。有能力的当局人工分析滥剑投诉，以便更好地理解犯罪动力和趋势。然而，手动分析这些投诉存在挑战，因为它可能曝露分析员遭受有害内容的风险。为了解决这些挑战，我们提出了一种新的解决方案：一种自动化分析儿童色情虐待投诉的工具。通过自动化分析过程，我们的工具可以减少分析员遭受有害内容的风险，并将投诉分为三个维度：主体、犯罪程度和伤害。此外，我们的多科学队伍专家的协作，我们引入了一种新的数据标注方法，以便更深入地分析投诉。这种方法可以更好地描述基本的趋势和模式，使宪法机关和制定政策者可以根据这些数据制定有关儿童暴力的专门策略。
</details></li>
</ul>
<hr>
<h2 id="Trusting-Language-Models-in-Education"><a href="#Trusting-Language-Models-in-Education" class="headerlink" title="Trusting Language Models in Education"></a>Trusting Language Models in Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03866">http://arxiv.org/abs/2308.03866</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Jogi Suda Neto, Li Deng, Thejaswi Raya, Reza Shahbazi, Nick Liu, Adhitya Venkatesh, Miral Shah, Neeru Khosla, Rodrigo Capobianco Guido</li>
<li>for: 这个论文是为了提高语言模型在教育领域中的准确率，避免模型显示错误的答案，从而对学生造成误导。</li>
<li>methods: 这个论文提出了使用XGBoost在BERT之上进行报告修正，使用基于注意力机制的特征来改善模型的自信度。</li>
<li>results: 这个论文发现了注意力流中的不确定程度与模型回答质量之间存在关系，并通过修正模型的自信度来避免错误答案的显示。<details>
<summary>Abstract</summary>
Language Models are being widely used in Education. Even though modern deep learning models achieve very good performance on question-answering tasks, sometimes they make errors. To avoid misleading students by showing wrong answers, it is important to calibrate the confidence - that is, the prediction probability - of these models. In our work, we propose to use an XGBoost on top of BERT to output the corrected probabilities, using features based on the attention mechanism. Our hypothesis is that the level of uncertainty contained in the flow of attention is related to the quality of the model's response itself.
</details>
<details>
<summary>摘要</summary>
语言模型在教育领域广泛使用。虽然现代深度学习模型在问答任务上表现非常出色，但有时会出现错误。为了避免通过错误答案误导学生，需要对这些模型进行准确性调整。在我们的工作中，我们提议使用XGBoost在BERT之上输出修正的概率，使用基于注意力机制的特征。我们假设注意力流中的不确定程度与模型的答案质量之间存在相关性。
</details></li>
</ul>
<hr>
<h2 id="AI-Text-to-Behavior-A-Study-In-Steerability"><a href="#AI-Text-to-Behavior-A-Study-In-Steerability" class="headerlink" title="AI Text-to-Behavior: A Study In Steerability"></a>AI Text-to-Behavior: A Study In Steerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07326">http://arxiv.org/abs/2308.07326</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Noever, Sam Hyams</li>
<li>for: 本研究探讨了大语言模型（LLM）的可控性，尤其是OpenAI的ChatGPT迭代。</li>
<li>methods: 我们使用了行为心理学框架OCEAN（开放性、聪明性、外向性、合作性、情绪性），量化测量模型对特定提示的回应。</li>
<li>results: 我们发现，“开放性”在语言上存在很大的混乱，而“聪明性”和“情绪性”在OCEAN框架中表现出了明显的强调，“外向性”和“合作性”则表现出了明确的分离。我们的发现表明GPT的多样性和可以根据人类意图进行定制的能力。<details>
<summary>Abstract</summary>
The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while "openness" presented linguistic ambiguity, "conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN framework, with "extroversion" and "agreeableness" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. However, the rapid advancements in LLM capabilities and the opaque nature of some training techniques make metric proposals degrade rapidly. Our research emphasizes a quantitative role to describe steerability in LLMs, presenting both its promise and areas for further refinement in aligning its progress to human intentions.
</details>
<details>
<summary>摘要</summary>
研究探讨大语言模型（LLM）的可控性，尤其是OpenAI的ChatGPT迭代。通过employnig行为心理学框架called OCEAN（开放性、聪明性、外向性、合作性、情绪性），我们量化了模型对定制提示的回应。当请求生成文本模拟外向性人格时，OCEAN分数表示语言对该行为 trait的吻合。在我们的分析中，“开放性”存在语言 ambiguity，而“聪明性”和“情绪性”在OCEAN框架中得到了明显的表达，而“外向性”和“合作性”则显示了明显的 overlap yet distinct separation from other traits。我们的发现强调GPT的灵活性和对 instrucible 指令的适应能力。此外，历史人物模拟表明了LLM的能力 internalize和 project instructible personas，精准地复制他们的哲学和对话风格。然而，LLM的技能快速发展和一些训练技术的不透明性使得metric proposal degrade rapidly。我们的研究强调了量化描述 LLM 的可控性的重要性，并提出了其推进人类意图的方法。
</details></li>
</ul>
<hr>
<h2 id="Mobile-Supply-The-Last-Piece-of-Jigsaw-of-Recommender-System"><a href="#Mobile-Supply-The-Last-Piece-of-Jigsaw-of-Recommender-System" class="headerlink" title="Mobile Supply: The Last Piece of Jigsaw of Recommender System"></a>Mobile Supply: The Last Piece of Jigsaw of Recommender System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03855">http://arxiv.org/abs/2308.03855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhao Jiang, Biao Zeng, Hao Feng, Jin Liu, Jie Zhang, Jia Jia, Ning Hu</li>
<li>for: 提高边缘推荐系统的性能和用户体验</li>
<li>methods: 提出了一个新的模块”Mobile Supply”，并使用点 wise paradigm和设备相关的移动排名方法来解决分页触发机制问题</li>
<li>results: 实验证明，提出的方法可以further improve the performance of edge-side recommender systems and user experience,并已经在一个大规模的在线美食平台上部署，获得了可观的业务效益。<details>
<summary>Abstract</summary>
Recommendation system is a fundamental functionality of online platforms. With the development of computing power of mobile phones, some researchers have deployed recommendation algorithms on users' mobile devices to address the problems of data transmission delay and pagination trigger mechanism. However, the existing edge-side mobile rankings cannot completely solve the problem of pagination trigger mechanism. The mobile ranking can only sort the items on the current page, and the fixed set of candidate items limits the performance of the mobile ranking. Besides, after the user has viewed the items of interest to the user on the current page, the user refresh to get a new page of items. This will affect the user's immersive experience because the user is not satisfied with the left items on the current page. In order to address the problem of pagination trigger mechanism, we propose a completely new module in the pipeline of recommender system named Mobile Supply. The pipeline of recommender system is extended to "retrival->pre-ranking->ranking->re-ranking->Mobile Supply->mobile ranking". Specifically, we introduce the concept of list value and use point-wise paradigm to approximate list-wise estimation to calculate the maximum revenue that can be achieved by mobile ranking for the current page. We also design a new mobile ranking approach named device-aware mobile ranking considering the differences of mobile devices tailored to the new pipeline. Extensive offline and online experiments show the superiority of our proposed method and prove that Mobile Supply can further improve the performance of edge-side recommender system and user experience. Mobile Supply has been deployed on the homepage of a large-scale online food platform and has yielded considerable profits in our business.
</details>
<details>
<summary>摘要</summary>
“推荐系统是线上平台的基本功能之一。随着移动设备的计算能力的提高，一些研究人员已经将推荐算法部署到用户的移动设备上以解决数据传输延迟和分页触发器机制的问题。然而，现有的边缘式移动排名无法完全解决分页触发器机制的问题。这个边缘式移动排名只能在当前页面上排序项目，而且固定的候选项目限制了排名的表现。此外，当用户已经查看了他们 interessant 的项目时，用户刷新以获取新的页面项目。这会影响用户的沉浸体验，因为用户不满意LEFT项目。”“为了解决分页触发器机制的问题，我们提出了一个全新的模组，名为 Mobile Supply。我们将推荐系统的管线延展为“获取->预选->排名->重新排名->Mobile Supply->边缘式排名”。具体来说，我们引入了列值的概念，并使用点子法来估算列值的最大收益，以计算可以由边缘式排名获得的当前页面的最大收益。我们还设计了一个新的边缘式排名方法，名为 Device-Aware Mobile Ranking，考虑了移动设备的不同特点，以适应新的管线。”“我们将 Mobile Supply 部署到一个大规模的线上食物平台的首页上，并获得了显著的收益。”
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing"><a href="#Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing" class="headerlink" title="Revisiting Prompt Engineering via Declarative Crowdsourcing"></a>Revisiting Prompt Engineering via Declarative Crowdsourcing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03854">http://arxiv.org/abs/2308.03854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya G. Parameswaran, Shreya Shankar, Parth Asawa, Naman Jain, Yujie Wang</li>
<li>for: 该论文旨在提出一种宣告式描述工程（Declarative Prompt Engineering）的视野，以便为LLM（大型自然语言模型）数据处理工作流程进行优化，同时保持成本在所需范围内。</li>
<li>methods: 该论文提出了一种基于宣告式描述的工程方法，利用大量自然语言模型（LLM）来进行数据处理工作流程的优化。该方法包括多个宣告策略、内部一致性和混合LLM-非LLM方法等。</li>
<li>results: 该论文的预liminary案例研究表明，使用宣告式描述工程可以提高LLM数据处理工作流程的质量，同时保持成本在所需范围内。这些案例包括排序、实体解决和填充等。<details>
<summary>Abstract</summary>
Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach
</details>
<details>
<summary>摘要</summary>
巨型语言模型（LLM）极其强大地理解和生成文本数据，但是脆弱和容易出错。随着推广工具和热门recipes的出现，关于 socalled prompt engineering——通过一系列提示来要求 LLM 做某件事——的过程在 LLM 驱动的数据处理工作流程中变得极其重要。然而，在Optimizing for quality的同时，保持成本在可控的范围内是一个艰辛的、手动的过程。我们提出了声明式提示工程的视野，将 LLM 看作是一群人群，利用声明式人群创新的想法——包括多种提示策略、保证内部一致性，以及混合 LLM 和非 LLM 方法——来使提示工程变得更加原则化。我们的初步案例研究包括排序、实体解析和填充，表明了我们的方法的承诺。
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Multi-scale-Transformer-for-High-Resolution-Salient-Object-Detection"><a href="#Recurrent-Multi-scale-Transformer-for-High-Resolution-Salient-Object-Detection" class="headerlink" title="Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection"></a>Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03826">http://arxiv.org/abs/2308.03826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Deng, Pingping Zhang, Wei Liu, Huchuan Lu<br>for:This paper aims to improve the performance of high-resolution salient object detection (HRSOD) by proposing a new dataset and a novel Recurrent Multi-scale Transformer (RMFormer) method.methods:The proposed RMFormer method utilizes shared Transformers and multi-scale refinement architectures to generate high-resolution saliency maps, guided by lower-resolution predictions.results:Extensive experiments on both high-resolution and low-resolution benchmarks demonstrate the effectiveness and superiority of the proposed framework, with the RMFormer method achieving state-of-the-art performance on the newly proposed HRS10K dataset.<details>
<summary>Abstract</summary>
Salient Object Detection (SOD) aims to identify and segment the most conspicuous objects in an image or video. As an important pre-processing step, it has many potential applications in multimedia and vision tasks. With the advance of imaging devices, SOD with high-resolution images is of great demand, recently. However, traditional SOD methods are largely limited to low-resolution images, making them difficult to adapt to the development of High-Resolution SOD (HRSOD). Although some HRSOD methods emerge, there are no large enough datasets for training and evaluating. Besides, current HRSOD methods generally produce incomplete object regions and irregular object boundaries. To address above issues, in this work, we first propose a new HRS10K dataset, which contains 10,500 high-quality annotated images at 2K-8K resolution. As far as we know, it is the largest dataset for the HRSOD task, which will significantly help future works in training and evaluating models. Furthermore, to improve the HRSOD performance, we propose a novel Recurrent Multi-scale Transformer (RMFormer), which recurrently utilizes shared Transformers and multi-scale refinement architectures. Thus, high-resolution saliency maps can be generated with the guidance of lower-resolution predictions. Extensive experiments on both high-resolution and low-resolution benchmarks show the effectiveness and superiority of the proposed framework. The source code and dataset are released at: https://github.com/DrowsyMon/RMFormer.
</details>
<details>
<summary>摘要</summary>
抽象对象检测（SOD）目的是在图像或视频中识别和分割最为醒目的对象。作为前处理步骤，它在多媒体和视觉任务中具有重要的应用前景。随着捕捉设备的发展，高分辨率SOD（HRSOD）的需求日益增加。然而，传统的SOD方法主要适用于低分辨率图像，使其难以适应HRSOD的发展。虽然一些HRSOD方法已经出现，但是没有足够的大型数据集用于训练和评估。此外，现有的HRSOD方法通常生成不完整的对象区域和不规则的对象边界。为解决上述问题，在这种工作中，我们首先提出了一个新的HRSOD数据集，名为HRS10K，它包含10500个高质量注解图像，分别在2K-8K分辨率上。我们知道，这是HRSOD任务中最大的数据集，它将有助于未来的工作在训练和评估模型。此外，为提高HRSOD性能，我们提出了一种新的循环多ScaleTransformer（RMFormer），它可以在不同的尺度上重复使用共享的Transformer和多尺度精度建立。因此，高分辨率的Saliency图可以通过低分辨率预测的指导生成。我们进行了广泛的实验，并证明了我们的框架的有效性和超越性。数据集和代码可以在https://github.com/DrowsyMon/RMFormer上下载。
</details></li>
</ul>
<hr>
<h2 id="A-Cost-Analysis-of-Generative-Language-Models-and-Influence-Operations"><a href="#A-Cost-Analysis-of-Generative-Language-Models-and-Influence-Operations" class="headerlink" title="A Cost Analysis of Generative Language Models and Influence Operations"></a>A Cost Analysis of Generative Language Models and Influence Operations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03740">http://arxiv.org/abs/2308.03740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/georgetown-cset/disinfo-costs">https://github.com/georgetown-cset/disinfo-costs</a></li>
<li>paper_authors: Micah Musser</li>
<li>for: 这个研究的目的是研究宣传人员使用大语言模型（LLM）时的成本和效益。</li>
<li>methods: 该研究使用了成本建模和优化分析来分析宣传人员使用LLM时的成本和效益。</li>
<li>results: 研究结果表明，LLM只需要生成可用输出，并且输出的可靠性只需要达到25%，就可以为宣传人员提供成本节省。同时，监控控制对于API访问ible的LLM可以减少成本，但是对于国家来说，特别是进行大规模影响操作的国家，没有经济上的收益来自于专门为影响操作培训自己的LLM。<details>
<summary>Abstract</summary>
Despite speculation that recent large language models (LLMs) are likely to be used maliciously to improve the quality or scale of influence operations, uncertainty persists regarding the economic value that LLMs offer propagandists. This research constructs a model of costs facing propagandists for content generation at scale and analyzes (1) the potential savings that LLMs could offer propagandists, (2) the potential deterrent effect of monitoring controls on API-accessible LLMs, and (3) the optimal strategy for propagandists choosing between multiple private and/or open source LLMs when conducting influence operations. Primary results suggest that LLMs need only produce usable outputs with relatively low reliability (roughly 25%) to offer cost savings to propagandists, that the potential reduction in content generation costs can be quite high (up to 70% for a highly reliable model), and that monitoring capabilities have sharply limited cost imposition effects when alternative open source models are available. In addition, these results suggest that nation-states -- even those conducting many large-scale influence operations per year -- are unlikely to benefit economically from training custom LLMs specifically for use in influence operations.
</details>
<details>
<summary>摘要</summary>
尽管有人 especulate recent large language models (LLMs) 可能会被用于提高媒体操作质量或规模，但是对于宣传者而言， LLMS 的经济价值还存在uncertainty。这项研究构建了宣传者内容生成在大规模时所面临的成本模型，并分析了以下问题：(1) LLMs 可以提供宣传者内容生成的可能性，(2) API 可访问的 LLMs 监控控制的抑效果，以及(3) 宣传者选择多个私人和/或开源 LLMs 时的优化策略。主要结果表明，LLMs 只需生成可用输出，并且只需要roughly 25% 的可靠性，就能为宣传者提供成本节省。此外，研究还发现，监控控制对于使用开源模型来源的宣传者来说，成本干扰效果很少。最后，这些结果表明，even nation-states 进行大规模的媒体操作，不太可能通过专门为影响操作培训自己的 LLMs 来获得经济效益。
</details></li>
</ul>
<hr>
<h2 id="SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator"><a href="#SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator" class="headerlink" title="SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator"></a>SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03730">http://arxiv.org/abs/2308.03730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danilaeremenko/survbex">https://github.com/danilaeremenko/survbex</a></li>
<li>paper_authors: Lev V. Utkin, Danila Y. Eremenko, Andrei V. Konstantinov</li>
<li>for: The paper proposes a new explanation method called SurvBeX for interpreting predictions of machine learning survival black-box models.</li>
<li>methods: The method uses a modified Beran estimator as the surrogate explanation model, and generates many points in a local area around an example of interest to compute the survival function of the black-box model and the Beran estimator.</li>
<li>results: The paper demonstrates the efficiency of SurvBeX through numerical experiments with synthetic and real survival data, and compares the method with SurvLIME and SurvSHAP. The code implementing SurvBeX is available online.<details>
<summary>Abstract</summary>
An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the well-known method SurvLIME. The method is also compared with the method SurvSHAP. The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX
</details>
<details>
<summary>摘要</summary>
一种名为SurvBeX的解释方法被提议用于解释机器学习生存黑盒模型的预测结果。该方法的主要思想是使用修改后的Beran估计器作为解释模型。将这些修改后的Beran估计器作为特征影响值，可以看作黑盒模型预测结果中特征的影响。与已知的LIME方法类似，在一个当地区域around一个Example of interest中，生成多个例子。对每个生成的例子，计算黑盒模型的生存函数，并将BERAN估计器中的生存函数作为特征影响值构建。为了找到解释系数，提议使用生成的例子中的平均距离来最小化黑盒模型和BERAN估计器生成的生存函数之间的距离。多个数学实验证明SurvBeX的效果，并与SurvLIME和SurvSHAP方法进行比较。代码实现SurvBeX可以在以下链接中找到：https://github.com/DanilaEremenko/SurvBeX。
</details></li>
</ul>
<hr>
<h2 id="Tiny-LVLM-eHub-Early-Multimodal-Experiments-with-Bard"><a href="#Tiny-LVLM-eHub-Early-Multimodal-Experiments-with-Bard" class="headerlink" title="Tiny LVLM-eHub: Early Multimodal Experiments with Bard"></a>Tiny LVLM-eHub: Early Multimodal Experiments with Bard</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03729">http://arxiv.org/abs/2308.03729</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/multi-modality-arena">https://github.com/opengvlab/multi-modality-arena</a></li>
<li>paper_authors: Wenqi Shao, Yutao Hu, Peng Gao, Meng Lei, Kaipeng Zhang, Fanqing Meng, Peng Xu, Siyuan Huang, Hongsheng Li, Yu Qiao, Ping Luo</li>
<li>for: 本研究目的是评估大型视语言模型（LVLM）在多模态任务上的表现，特别是Google的Bard模型，并提出一种轻量级的LVLM-eHub变体。</li>
<li>methods: 本研究使用了一种系统性评估多模态能力的方法，包括视觉理解、视觉知识获取、视觉逻辑、视觉常识、物体推理和embodied intelligence等六类多模态能力，通过42种文本相关的视觉benchmark测试。</li>
<li>results: 研究结果显示，Bard模型在大多数多模态能力中表现出色，仅在物体推理方面表现不佳，与人类评估更加一致。此外，Tiny LVLM-eHub变体可以便捷地评估各种Offline LVLMs模型。<details>
<summary>Abstract</summary>
Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated significant progress in tackling complex multimodal tasks. Among these cutting-edge developments, Google's Bard stands out for its remarkable multimodal capabilities, promoting comprehensive comprehension and reasoning across various domains. This work presents an early and holistic evaluation of LVLMs' multimodal abilities, with a particular focus on Bard, by proposing a lightweight variant of LVLM-eHub, named Tiny LVLM-eHub. In comparison to the vanilla version, Tiny LVLM-eHub possesses several appealing properties. Firstly, it provides a systematic assessment of six categories of multimodal capabilities, including visual perception, visual knowledge acquisition, visual reasoning, visual commonsense, object hallucination, and embodied intelligence, through quantitative evaluation of $42$ standard text-related visual benchmarks. Secondly, it conducts an in-depth analysis of LVLMs' predictions using the ChatGPT Ensemble Evaluation (CEE), which leads to a robust and accurate evaluation and exhibits improved alignment with human evaluation compared to the word matching approach. Thirdly, it comprises a mere $2.1$K image-text pairs, facilitating ease of use for practitioners to evaluate their own offline LVLMs. Through extensive experimental analysis, this study demonstrates that Bard outperforms previous LVLMs in most multimodal capabilities except object hallucination, to which Bard is still susceptible. Tiny LVLM-eHub serves as a baseline evaluation for various LVLMs and encourages innovative strategies aimed at advancing multimodal techniques. Our project is publicly available at \url{https://github.com/OpenGVLab/Multi-Modality-Arena}.
</details>
<details>
<summary>摘要</summary>
近期大量视语言模型（LVLM）的进步，表明了许多复杂多Modal任务的解决方案。其中，Google的Bard凸出了优异的多Modal能力，涵盖了多个领域的全面理解和合理思维。本文提出了一种轻量级的LVLM-eHub变体，名为Tiny LVLM-eHub，与传统版本相比具有多个优点。首先，它提供了六类多Modal能力的系统性评估，包括视觉理解、视觉知识获取、视觉逻辑、视觉常识、物体梦幻和embodied智能，通过42个标准文本相关的视觉准确度评估。其次，它使用ChatGPT Ensemble Evaluation（CEE）进行深入分析，从而获得了更加稳定和准确的评估结果，并与人类评估更加一致。最后，它使用2.1万个图文对象，使得评估方便快速。通过广泛的实验分析，本研究表明，Bard在大多数多Modal能力中都超越了前一代LVLM，只有物体梦幻能力方面存在一定的极点。Tiny LVLM-eHub可以作为多种LVLM的基准评估，激励创新的多Modal技术发展。我们的项目公开可用于\url{https://github.com/OpenGVLab/Multi-Modality-Arena}.
</details></li>
</ul>
<hr>
<h2 id="Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation"><a href="#Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation" class="headerlink" title="Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation"></a>Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03723">http://arxiv.org/abs/2308.03723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mckellwoodland/dimen_reduce_mahal">https://github.com/mckellwoodland/dimen_reduce_mahal</a></li>
<li>paper_authors: McKell Woodland, Nihil Patel, Mais Al Taie, Joshua P. Yung, Tucker J. Netherton, Ankit B. Patel, Kristy K. Brock</li>
<li>for: 验证 segmentation 模型在数据外部分布下的性能。</li>
<li>methods: 使用 Mahalanobis 距离post hoc 方法对瓶颈特征进行降维，并使用 Principal Component Analysis 降维瓶颈特征。</li>
<li>results: 可以高效地检测到数据外部分布下的图像。<details>
<summary>Abstract</summary>
Clinically deployed segmentation models are known to fail on data outside of their training distribution. As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias. This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging. By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SEM-GAT-Explainable-Semantic-Pose-Estimation-using-Learned-Graph-Attention"><a href="#SEM-GAT-Explainable-Semantic-Pose-Estimation-using-Learned-Graph-Attention" class="headerlink" title="SEM-GAT: Explainable Semantic Pose Estimation using Learned Graph Attention"></a>SEM-GAT: Explainable Semantic Pose Estimation using Learned Graph Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03718">http://arxiv.org/abs/2308.03718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Efimia Panagiotaki, Daniele De Martini, Georgi Pramatarov, Matthew Gadd, Lars Kunze</li>
<li>for: 本研究提出了一种基于GNN的方法，用于利用语义和地方几何信息导引可靠的点云注册候选者。</li>
<li>methods: 本方法使用了一种新的轻量级静止图structures，将语义特征和形态特征作为关键参考点，以便实现高精度激光探测pose估计。我们的novel lightweight static graph structure通过语义实例基于的关系提取semantic instance-based关系，从而减少了计算卷积核算符的计算负担。</li>
<li>results: 我们的方法在KITTI odometry dataset上进行测试，与参考方法相比具有竞争性的准确率，同时具有更高的轨迹缓和更少的网络参数。<details>
<summary>Abstract</summary>
This paper proposes a GNN-based method for exploiting semantics and local geometry to guide the identification of reliable pointcloud registration candidates. Semantic and morphological features of the environment serve as key reference points for registration, enabling accurate lidar-based pose estimation. Our novel lightweight static graph structure informs our attention-based keypoint node aggregation GNN network by identifying semantic instance-based relationships, acting as inductive bias to significantly reduce the computational burden of pointcloud registration. By connecting candidate nodes and exploiting cross-graph attention, we identify confidence scores for all potential registration correspondences, estimating the displacement between pointcloud scans. Our pipeline enables introspective analysis of the model's performance by correlating it with the individual contributions of local structures in the environment, providing valuable insights into the system's behaviour. We test our method on the KITTI odometry dataset, achieving competitive accuracy compared to benchmark methods and a higher track smoothness while relying on significantly fewer network parameters.
</details>
<details>
<summary>摘要</summary>
（本文提出了一种基于GNN的方法，利用 semantics和local geometry来导引可靠的点云注册候选者的标识。环境中的semantic和形态特征作为注册参考点，实现了高精度的激光探测pose estimation。我们的新的轻量级静止图 структуры告诉我们的注意力基于节点聚合GNN网络，通过标识semantic实例之间的关系，以 inductive bias 的形式减少点云注册的计算成本。通过连接候选节点并利用交叉图注意力，我们可以为所有可能的注册匹配计算出信任度，并估算点云扫描中的偏移量。我们的管道可以 introspective 地分析模型的性能，将其与本地环境结构的个别贡献相对考量，提供有价值的信息，了解系统的行为。我们在KITTI odometry dataset上测试了我们的方法，与标准方法相比，实现了竞争性的准确率和更高的车辆运动平滑性，同时使用的网络参数数量更少。）
</details></li>
</ul>
<hr>
<h2 id="Safe-Multimodal-Communication-in-Human-Robot-Collaboration"><a href="#Safe-Multimodal-Communication-in-Human-Robot-Collaboration" class="headerlink" title="Safe Multimodal Communication in Human-Robot Collaboration"></a>Safe Multimodal Communication in Human-Robot Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03690">http://arxiv.org/abs/2308.03690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Ferrari, Andrea Pupa, Alberto Signoretti, Cristian Secchi</li>
<li>for: 本研究旨在帮助人工智能机器人和人类在各种新工业设置中合作完成任务，但是这需要考虑多种因素。</li>
<li>methods: 本研究提出了一种基于多Modal融合的语音和手势命令的框架，以便人工智能机器人和人类之间进行自然和高效的交流。同时，该框架 siempre respects safety regulations。</li>
<li>results: 通过比较实验表明，通过多Modal融合的语音和手势命令，机器人可以从人类提供有价值的信息来完成任务，同时保证操作员的安全。<details>
<summary>Abstract</summary>
The new industrial settings are characterized by the presence of human and robots that work in close proximity, cooperating in performing the required job. Such a collaboration, however, requires to pay attention to many aspects. Firstly, it is crucial to enable a communication between this two actors that is natural and efficient. Secondly, the robot behavior must always be compliant with the safety regulations, ensuring always a safe collaboration. In this paper, we propose a framework that enables multi-channel communication between humans and robots by leveraging multimodal fusion of voice and gesture commands while always respecting safety regulations. The framework is validated through a comparative experiment, demonstrating that, thanks to multimodal communication, the robot can extract valuable information for performing the required task and additionally, with the safety layer, the robot can scale its speed to ensure the operator's safety.
</details>
<details>
<summary>摘要</summary>
新的工业设置 caracterized by the presence of human and robots working in close proximity, cooperating to perform the required job. However, such collaboration requires attention to many aspects. Firstly, it is crucial to enable natural and efficient communication between the two actors. Secondly, the robot's behavior must always comply with safety regulations, ensuring safe collaboration. In this paper, we propose a framework that enables multi-channel communication between humans and robots by leveraging multimodal fusion of voice and gesture commands while always respecting safety regulations. The framework is validated through a comparative experiment, demonstrating that, thanks to multimodal communication, the robot can extract valuable information for performing the required task and additionally, with the safety layer, the robot can scale its speed to ensure the operator's safety.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="AgentBench-Evaluating-LLMs-as-Agents"><a href="#AgentBench-Evaluating-LLMs-as-Agents" class="headerlink" title="AgentBench: Evaluating LLMs as Agents"></a>AgentBench: Evaluating LLMs as Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03688">http://arxiv.org/abs/2308.03688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/agentbench">https://github.com/thudm/agentbench</a></li>
<li>paper_authors: Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, Jie Tang</li>
<li>for: 这个论文的目的是评估大语言模型（LLMs）作为智能代理的能力，以及评估 LLMS 在复杂环境中的决策和判断能力。</li>
<li>methods: 这篇论文使用了 AgentBench 多维度演变 bencmark，该 bencmark 包括 8 个不同环境，用于评估 LLMS 的解释和决策能力。</li>
<li>results: 测试结果显示，商业 LLMS 在复杂环境中表现强，但是与开源竞争对手相比，它们的表现存在显著差异。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors. It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation. Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.AI_2023_08_08/" data-id="clpxp6bw1001zee888ifj754x" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.CL_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T11:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.CL_2023_08_08/">cs.CL - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unmasking-Nationality-Bias-A-Study-of-Human-Perception-of-Nationalities-in-AI-Generated-Articles"><a href="#Unmasking-Nationality-Bias-A-Study-of-Human-Perception-of-Nationalities-in-AI-Generated-Articles" class="headerlink" title="Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles"></a>Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04346">http://arxiv.org/abs/2308.04346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranav Narayanan Venkit, Sanjana Gautam, Ruchi Panchanadikar, Ting-Hao &#96;Kenneth’ Huang, Shomir Wilson</li>
<li>for: 本研究旨在检测自然语言处理（NLP）模型中的国籍偏见，以确定AI系统的公正性和正义。</li>
<li>methods: 本研究采用了两步混合方法，包括量化分析和质量分析，以识别和理解国籍偏见在文本生成模型中的影响。</li>
<li>results: 研究发现，偏见NLP模型通常会复制和强化现有的社会偏见，可能导致社会技术环境中的歧视。参与者的口头问naire和主题分析也表明，读者阅读文章时可能受到这些偏见的影响，从而改变他们对国家的看法。这些发现强调了AI系统在社会中的影响，以及需要更正AI系统中的偏见。<details>
<summary>Abstract</summary>
We investigate the potential for nationality biases in natural language processing (NLP) models using human evaluation methods. Biased NLP models can perpetuate stereotypes and lead to algorithmic discrimination, posing a significant challenge to the fairness and justice of AI systems. Our study employs a two-step mixed-methods approach that includes both quantitative and qualitative analysis to identify and understand the impact of nationality bias in a text generation model. Through our human-centered quantitative analysis, we measure the extent of nationality bias in articles generated by AI sources. We then conduct open-ended interviews with participants, performing qualitative coding and thematic analysis to understand the implications of these biases on human readers. Our findings reveal that biased NLP models tend to replicate and amplify existing societal biases, which can translate to harm if used in a sociotechnical setting. The qualitative analysis from our interviews offers insights into the experience readers have when encountering such articles, highlighting the potential to shift a reader's perception of a country. These findings emphasize the critical role of public perception in shaping AI's impact on society and the need to correct biases in AI systems.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)我们研究使用人类评估方法检测自然语言处理（NLP）模型中的国籍偏见。偏见的NLP模型可能扩大和复制现有社会偏见，导致算法性隔离，这对于AI系统的公平和正义具有挑战性。我们的研究采用了一种两步混合方法，包括量化和质量分析，以确定和理解国籍偏见在文本生成模型中的影响。我们通过人类中心的量化分析 mesure了AI源生成的文章中的国籍偏见的程度。然后，我们通过对参与者进行开放结构问naire和Theme coding分析来理解这些偏见对人类读者的影响。我们的发现表明，偏见的NLP模型通常会复制和加强现有社会偏见，这可能在社会技术 Setting中导致害。我们的访问分析表明，当读者遇到这些文章时，可能会改变他们对某个国家的看法。这些发现强调了AI对社会的影响的重要性，以及需要 corrections in AI systems。
</details></li>
</ul>
<hr>
<h2 id="Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz"><a href="#Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz" class="headerlink" title="Towards an AI to Win Ghana’s National Science and Maths Quiz"></a>Towards an AI to Win Ghana’s National Science and Maths Quiz</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04333">http://arxiv.org/abs/2308.04333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nsmq-ai/nsmqai">https://github.com/nsmq-ai/nsmqai</a></li>
<li>paper_authors: George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah</li>
<li>for: The paper is written to explore the possibility of building an AI system that can compete in Ghana’s National Science and Maths Quiz (NSMQ) and potentially win.</li>
<li>methods: The paper describes an open-source project that is building AI to compete in the NSMQ, with a focus on speech-to-text, text-to-speech, question-answering, and human-computer interaction.</li>
<li>results: The paper provides an overview of the progress made thus far in the project, including the development of the AI system and the next steps toward its planned launch and debut in October for NSMQ 2023.<details>
<summary>Abstract</summary>
Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win. The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction. In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023. An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI.
</details>
<details>
<summary>摘要</summary>
可以AI赢得加纳国家科学和数学竞赛（NSMQ）呢？我们在NSMQ AI项目中寻求答案，这是一个开源项目，旨在通过AI参加NSMQ并赢得奖。NSMQ是每年在加纳举行的生活 science和数学竞赛，参赛者是高中二年级学生，共有3个队伍，每个队伍有2名学生，在5轮5阶段的竞赛中回答生物、化学、物理和数学等领域的问题。NSMQ是一场激动人心的直播竞赛，涉及到语音识别、文本识别、问题回答和人机交互等技术挑战。在我们自2023年1月开始的工作中，我们将提供项目概述，介绍各个团队、已经进步的情况，以及下一步的计划，以备在10月份的NSMQ 2023上发布和使用AI。一旦AI成功解决这一大挑战，可以对教育产生实际影响，如提供非洲数百万学生一对一的学习支持。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Knowledge-Injection-for-Metaphor-Detection-A-Comprehensive-Review"><a href="#Deep-Learning-Based-Knowledge-Injection-for-Metaphor-Detection-A-Comprehensive-Review" class="headerlink" title="Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review"></a>Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04306">http://arxiv.org/abs/2308.04306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Yang, Wenye Zhao, Zhiyue Liu, Qingbao Huang</li>
<li>for: 本研究的目的是提供深度学习在метaphore认知任务中知识批注的综述和总结。</li>
<li>methods: 本文系统地总结了主流的知识和知识批注原则，并评估了在 métaphore认知任务中使用的数据集、评价指标和参考模型。</li>
<li>results: 本文结果预示，现有的知识批注方法在 métaphore认知任务中具有较高的识别率和准确率。但是，现有的方法还存在一些问题，如知识批注的质量和可靠性问题。<details>
<summary>Abstract</summary>
The history of metaphor research also marks the evolution of knowledge infusion research. With the continued advancement of deep learning techniques in recent years, the natural language processing community has shown great interest in applying knowledge to successful results in metaphor recognition tasks. Although there has been a gradual increase in the number of approaches involving knowledge injection in the field of metaphor recognition, there is a lack of a complete review article on knowledge injection based approaches. Therefore, the goal of this paper is to provide a comprehensive review of research advances in the application of deep learning for knowledge injection in metaphor recognition tasks. In this paper, we systematically summarize and generalize the mainstream knowledge and knowledge injection principles, as well as review the datasets, evaluation metrics, and benchmark models used in metaphor recognition tasks. Finally, we explore the current issues facing knowledge injection methods and provide an outlook on future research directions.
</details>
<details>
<summary>摘要</summary>
历史上的比喻研究也标志着知识混合研究的演化。随着近年深度学习技术的不断发展，自然语言处理社区对于应用知识到成功的结果在比喻识别任务中表示了极大的兴趣。虽然在比喻识别领域中有一个慢慢增长的方法涉及知识注入，但是没有一篇完整的文章来评论这些方法。因此，本文的目标是为您提供深度学习在比喻识别任务中知识注入的完整评论。在这篇文章中，我们系统地总结和总结主流的知识和知识注入原则，同时回顾用于比喻识别任务的数据集、评价指标和标准模型。最后，我们探讨知识注入方法当前面临的问题，并对未来研究方向提出了一些想法。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor"><a href="#Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor" class="headerlink" title="Comparative Analysis of the wav2vec 2.0 Feature Extractor"></a>Comparative Analysis of the wav2vec 2.0 Feature Extractor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04286">http://arxiv.org/abs/2308.04286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Vieting, Ralf Schlüter, Hermann Ney</li>
<li>for: 这个论文的目的是研究一种基于神经网络的原始波形特征提取器（FEs），以取代传统的手动设计的特征提取方法，以实现更加一致的模型化从语音到文本转写。</li>
<li>methods: 这个论文使用了wav2vec 2.0模型，这是一种最近受欢迎的模型，它使用了一种卷积 convolutional FE，直接操作语音波形。然而，这个方法尚未得到了广泛的研究。</li>
<li>results: 研究表明，使用神经网络原始波形特征提取器可以与传统的特征提取方法竞争，并且可以在LibriSpeech benchmark上实现类似的性能。此外，研究还分析了各个组件的效果，并发现了一些帮助ASR系统获得重要信息的带宽滤波器。<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) systems typically use handcrafted feature extraction pipelines. To avoid their inherent information loss and to achieve more consistent modeling from speech to transcribed text, neural raw waveform feature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model, which has recently gained large popularity, uses a convolutional FE which operates directly on the speech waveform. However, it is not yet studied extensively in the literature. In this work, we study its capability to replace the standard feature extraction methods in a connectionist temporal classification (CTC) ASR model and compare it to an alternative neural FE. We show that both are competitive with traditional FEs on the LibriSpeech benchmark and analyze the effect of the individual components. Furthermore, we analyze the learned filters and show that the most important information for the ASR system is obtained by a set of bandpass filters.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）系统通常使用手工设计的特征提取管道。为了避免其内置的信息损失并实现更一致的模型化从语音到转录文本，神经原始波形特征提取器（FEs）是一种吸引人的方法。另外，最近广受欢迎的wav2vec 2.0模型使用了一种卷积 convolutional FE，该模型直接操作语音波形。然而，它在文献中还未得到了广泛的研究。在这种工作中，我们研究了它的可行性来代替标准特征提取方法在一个连接主义时间分类（CTC） ASR 模型中，并与一种代替神经 FE 进行比较。我们发现两者都与传统的特征提取方法竞争在 LibriSpeech 测试集上，并分析了各个组件的效果。此外，我们分析了学习的滤波器，并发现了一组频率带滤波器是 ASR 系统中最重要的信息来源。
</details></li>
</ul>
<hr>
<h2 id="CLASSLA-Stanza-The-Next-Step-for-Linguistic-Processing-of-South-Slavic-Languages"><a href="#CLASSLA-Stanza-The-Next-Step-for-Linguistic-Processing-of-South-Slavic-Languages" class="headerlink" title="CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic Languages"></a>CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04255">http://arxiv.org/abs/2308.04255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luka Terčon, Nikola Ljubešić</li>
<li>for: 这个论文是为了提出一个基于Stanza自然语言处理管道的自动语言标注管道，用于南斯拉夫语言的语言处理。</li>
<li>methods: 该管道使用了主要改进于Stanza，并对2.1版本进行了详细的模型训练过程。</li>
<li>results: 管道在不同语言和方言上都达到了高性能水平，并在大多数任务上超越或扩展了父管道Stanza。此外，新增的网络数据处理功能和其原因也被介绍。<details>
<summary>Abstract</summary>
We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of the South Slavic languages, which is based on the Stanza natural language processing pipeline. We describe the main improvements in CLASSLA-Stanza with respect to Stanza, and give a detailed description of the model training process for the latest 2.1 release of the pipeline. We also report performance scores produced by the pipeline for different languages and varieties. CLASSLA-Stanza exhibits consistently high performance across all the supported languages and outperforms or expands its parent pipeline Stanza at all the supported tasks. We also present the pipeline's new functionality enabling efficient processing of web data and the reasons that led to its implementation.
</details>
<details>
<summary>摘要</summary>
我团队今天发布了一个名为CLASSLA-Stanza的自动语言标注管道，这个管道基于Stanza自然语言处理管道。我们详细介绍了CLASSLA-Stanza与Stanza之间的主要改进，以及latest版本2.1中模型训练过程的详细描述。我们还公布了不同语言和变体的性能分数。CLASSLA-Stanza在所有支持语言上表现了高稳定性，并在所有任务上超越或扩展了父管道Stanza的性能。我们还介绍了新增的网络数据处理功能，以及这种功能的实现的原因。
</details></li>
</ul>
<hr>
<h2 id="OpinionConv-Conversational-Product-Search-with-Grounded-Opinions"><a href="#OpinionConv-Conversational-Product-Search-with-Grounded-Opinions" class="headerlink" title="OpinionConv: Conversational Product Search with Grounded Opinions"></a>OpinionConv: Conversational Product Search with Grounded Opinions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04226">http://arxiv.org/abs/2308.04226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vahid Sadiri Javadi, Martin Potthast, Lucie Flek</li>
<li>for:  This paper aims to address the problem of training conversational AI in simulating sales conversations by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives.</li>
<li>methods: The paper uses product reviews as a source of product opinions to train a conversational AI model called OpinionConv, which can simulate sales conversations.</li>
<li>results: The paper conducts several user studies to validate the generated conversations and shows that the generated opinions are perceived as realistic. The assessors also confirm the importance of opinions as an informative basis for decision-making.Here’s the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文目标是使用产品评论作为对话AI训练的基础，以便模拟销售对话。</li>
<li>methods: 论文使用产品评论作为对话AI的训练数据，开发了一个名为OpinionConv的对话AI模型。</li>
<li>results: 论文通过多个用户研究证明了生成的对话是真实的，评分人也证明了对话中的意见对决策提供了有用信息。<details>
<summary>Abstract</summary>
When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”"><a href="#Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”" class="headerlink" title="Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”"></a>Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04180">http://arxiv.org/abs/2308.04180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlinardicyu/sud_study_different_eyes">https://github.com/mlinardicyu/sud_study_different_eyes</a></li>
<li>paper_authors: Bruno Machado Carneiro, Michele Linardi, Julien Longhi</li>
<li>for: 这个论文是为了研究在线文本中的社会不接受的语言表达（SUD）的特征和检测方法。</li>
<li>methods: 作者首先建立了一个包含多种不同在线源的手动标注文本的新 корпуス，以用于测试现有的机器学习（ML）SUD检测解决方案中的通用性。</li>
<li>results: 作者通过分析不同批标注方法对SUD学习的影响，并提供了一些可支持领域专家在标注任务中的数据洞察。<details>
<summary>Abstract</summary>
We study Socially Unacceptable Discourse (SUD) characterization and detection in online text. We first build and present a novel corpus that contains a large variety of manually annotated texts from different online sources used so far in state-of-the-art Machine learning (ML) SUD detection solutions. This global context allows us to test the generalization ability of SUD classifiers that acquire knowledge around the same SUD categories, but from different contexts. From this perspective, we can analyze how (possibly) different annotation modalities influence SUD learning by discussing open challenges and open research directions. We also provide several data insights which can support domain experts in the annotation task.
</details>
<details>
<summary>摘要</summary>
我们研究社会不可接受的语言（SUD）的特征化和检测在线文本中。我们首先构建了一个新的文献库，包含了不同的在线来源的手动标注文本，以及现有的机器学习（ML）SUD检测解决方案中使用的同一类型的文本。这个全球背景允许我们测试SUD分类器在不同上下文中是否具有泛化能力。从这个角度来看，我们可以分析不同的标注方式对SUD学习产生的影响，并讨论开放的挑战和未来研究方向。我们还提供了一些数据分析视图，以支持领域专家进行标注任务。
</details></li>
</ul>
<hr>
<h2 id="On-Monotonic-Aggregation-for-Open-domain-QA"><a href="#On-Monotonic-Aggregation-for-Open-domain-QA" class="headerlink" title="On Monotonic Aggregation for Open-domain QA"></a>On Monotonic Aggregation for Open-domain QA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04176">http://arxiv.org/abs/2308.04176</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yeonseokjeong/judge-specialist">https://github.com/yeonseokjeong/judge-specialist</a></li>
<li>paper_authors: Sang-eun Han, Yeonseok Jeong, Seung-won Hwang, Kyungjae Lee</li>
<li>for:  answering user questions on unrestricted knowledge sources</li>
<li>methods:  Judge-Specialist framework with specialist retrievers&#x2F;readers and a dedicated language model to select the final answer</li>
<li>results:  outperforms state-of-the-art multi-source QA methods on Natural Questions, and robustly preserves monotonicity against noise from speech recognition<details>
<summary>Abstract</summary>
Question answering (QA) is a critical task for speech-based retrieval from knowledge sources, by sifting only the answers without requiring to read supporting documents. Specifically, open-domain QA aims to answer user questions on unrestricted knowledge sources. Ideally, adding a source should not decrease the accuracy, but we find this property (denoted as "monotonicity") does not hold for current state-of-the-art methods. We identify the cause, and based on that we propose Judge-Specialist framework. Our framework consists of (1) specialist retrievers/readers to cover individual sources, and (2) judge, a dedicated language model to select the final answer. Our experiments show that our framework not only ensures monotonicity, but also outperforms state-of-the-art multi-source QA methods on Natural Questions. Additionally, we show that our models robustly preserve the monotonicity against noise from speech recognition. We publicly release our code and setting.
</details>
<details>
<summary>摘要</summary>
问答（QA）是知识源检索中的关键任务，通过只检索答案而不需要阅读支持文档。特别是开放领域QA旨在回答用户问题在不限制的知识源上。理想情况下，添加源应该不会降低准确性，但我们发现现有方法中的性质（ denoted as "monotonicity"）不成立。我们认定了原因，并基于此我们提出了 Judge-Specialist 框架。我们的框架包括（1）专家检索/读取器，覆盖个别源，以及（2）判官，专门的语言模型来选择最终答案。我们的实验表明，我们的框架不仅保证幂等性，而且超越了当前状态的跨源QA方法在自然问题上的性能。此外，我们的模型也能够坚定地保持幂等性面对语音识别器的噪音。我们在线发布了我们的代码和设置。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Model-Prompt-Chaining-for-Long-Legal-Document-Classification"><a href="#Large-Language-Model-Prompt-Chaining-for-Long-Legal-Document-Classification" class="headerlink" title="Large Language Model Prompt Chaining for Long Legal Document Classification"></a>Large Language Model Prompt Chaining for Long Legal Document Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04138">http://arxiv.org/abs/2308.04138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dietrich Trautmann</li>
<li>for: 这个论文主要是为了解决法律文档分类问题，以提高法律文档分类的效率和准确率。</li>
<li>methods: 这个论文使用了提问链接法（prompt chaining）来解决法律文档分类问题。提问链接法是一种细分大任务，将其 decomposes 成一系列更小的任务，以提高模型的性能。在这个论文中，首先创建了原始文档的简洁摘要，然后进行 semantic search 来找到相关的示例文档和其对应的注释集。最后，通过提问来 assigning 标签，基于任务的需求。</li>
<li>results: 根据论文的结果，通过提问链接法，可以不 только超越零shot，还可以超过大型模型，如ChatGPT零shot，使用更小的模型。<details>
<summary>Abstract</summary>
Prompting is used to guide or steer a language model in generating an appropriate response that is consistent with the desired outcome. Chaining is a strategy used to decompose complex tasks into smaller, manageable components. In this study, we utilize prompt chaining for extensive legal document classification tasks, which present difficulties due to their intricate domain-specific language and considerable length. Our approach begins with the creation of a concise summary of the original document, followed by a semantic search for related exemplar texts and their corresponding annotations from a training corpus. Finally, we prompt for a label - based on the task - to assign, by leveraging the in-context learning from the few-shot prompt. We demonstrate that through prompt chaining, we can not only enhance the performance over zero-shot, but also surpass the micro-F1 score achieved by larger models, such as ChatGPT zero-shot, using smaller models.
</details>
<details>
<summary>摘要</summary>
提示是用于引导或导引语言模型生成适当的回应，以确保与所需结果相符。链式是一种策略，用于将复杂任务分解成更小、更容易处理的组件。在这项研究中，我们使用提示链式来处理广泛的法律文档分类任务，这些任务因其专业领域语言和较长的文档长度而更加具有挑战性。我们的方法包括：首先创建原始文档的简短摘要，然后通过semantic search找到相关的示例文档和它们的相关注释，从训练集中获取。最后，我们根据任务提供标签，通过受到上下文学习的几个提示来启用。我们示出，通过提示链式，不仅可以超越零shot的性能，还可以使用更小的模型超越更大的模型，如ChatGPT零shot。
</details></li>
</ul>
<hr>
<h2 id="Social-Media-Topic-Modeling-and-Sentiment-Analysis-in-Municipal-Decision-Support"><a href="#Social-Media-Topic-Modeling-and-Sentiment-Analysis-in-Municipal-Decision-Support" class="headerlink" title="Social Media, Topic Modeling and Sentiment Analysis in Municipal Decision Support"></a>Social Media, Topic Modeling and Sentiment Analysis in Municipal Decision Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04124">http://arxiv.org/abs/2308.04124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miloš Švaňa<br>for: This paper is written for municipal decision-makers who want to incorporate social media sentiment into their decision-making processes.methods: The paper proposes a framework for processing social media posts that consists of three steps: determining the sentiment polarity of each post, identifying prevalent topics, and aggregating the sentiment information. The framework uses fuzzy numbers to represent the sentiment in a richer way and capture the diversity of opinions expressed on social media.results: The paper demonstrates the application of the framework on tweets published from Ostrava, Czechia over a period of about two months. The results show how fuzzy numbers can represent the sentiment in a more nuanced way and capture the diversity of opinions expressed on social media.<details>
<summary>Abstract</summary>
Many cities around the world are aspiring to become. However, smart initiatives often give little weight to the opinions of average citizens.   Social media are one of the most important sources of citizen opinions. This paper presents a prototype of a framework for processing social media posts with municipal decision-making in mind. The framework consists of a sequence of three steps: (1) determining the sentiment polarity of each social media post (2) identifying prevalent topics and mapping these topics to individual posts, and (3) aggregating these two pieces of information into a fuzzy number representing the overall sentiment expressed towards each topic. Optionally, the fuzzy number can be reduced into a tuple of two real numbers indicating the "amount" of positive and negative opinion expressed towards each topic.   The framework is demonstrated on tweets published from Ostrava, Czechia over a period of about two months. This application illustrates how fuzzy numbers represent sentiment in a richer way and capture the diversity of opinions expressed on social media.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Determine the sentiment polarity of each social media post (是否积极或消极的意见)2. Identify prevalent topics and map them to individual posts (找出主要话题并将其与各个帖子相关联)3. Aggregate the two pieces of information into a fuzzy number representing the overall sentiment expressed towards each topic (将这两个信息合并为一个模糊数字表示每个话题的总意见)Optionally, the fuzzy number can be reduced into a tuple of two real numbers indicating the “amount” of positive and negative opinion expressed towards each topic (可以将模糊数字转换为一个二元数组，表示每个话题的积极和消极意见的量)This framework was demonstrated on tweets published from Ostrava, Czechia over a period of about two months, showing how fuzzy numbers can represent sentiment in a richer way and capture the diversity of opinions expressed on social media.</details></li>
</ol>
<hr>
<h2 id="Collective-Human-Opinions-in-Semantic-Textual-Similarity"><a href="#Collective-Human-Opinions-in-Semantic-Textual-Similarity" class="headerlink" title="Collective Human Opinions in Semantic Textual Similarity"></a>Collective Human Opinions in Semantic Textual Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04114">http://arxiv.org/abs/2308.04114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuxiaw/usts">https://github.com/yuxiaw/usts</a></li>
<li>paper_authors: Yuxia Wang, Shimin Tao, Ning Xie, Hao Yang, Timothy Baldwin, Karin Verspoor</li>
<li>for: 这个论文的目的是研究语义相似性(STS)的不确定性和人类评分的分布。</li>
<li>methods: 这个论文使用了一个新的 uncertainty-aware STS 数据集（USTS），包含了 ~15,000 个中文句子对和 150,000 个标签，以研究集体人类评分的变化。</li>
<li>results: 分析发现，人类评分的集体变化不能用标准的整数或单个高斯函数来描述，而是由人类不同的评分差异所引起的。此外，现有的 STS 模型无法捕捉人类对具体实例的不一致，而更反映了模型对总体数据集的预测程度。<details>
<summary>Abstract</summary>
Despite the subjective nature of semantic textual similarity (STS) and pervasive disagreements in STS annotation, existing benchmarks have used averaged human ratings as the gold standard. Averaging masks the true distribution of human opinions on examples of low agreement, and prevents models from capturing the semantic vagueness that the individual ratings represent. In this work, we introduce USTS, the first Uncertainty-aware STS dataset with ~15,000 Chinese sentence pairs and 150,000 labels, to study collective human opinions in STS. Analysis reveals that neither a scalar nor a single Gaussian fits a set of observed judgements adequately. We further show that current STS models cannot capture the variance caused by human disagreement on individual instances, but rather reflect the predictive confidence over the aggregate dataset.
</details>
<details>
<summary>摘要</summary>
尽管 semantic textual similarity (STS) 的评估是主观的，且存在各种不同的评估标准，现有的 benchmark 都使用了人类评分的均值作为金标准。但是，均值将低度一致的示例评分压缩到了一个平均值上，从而隐藏了人类意见的差异。在这项工作中，我们引入了 USTS，首个带有 ~15,000 个中文句子对和 150,000 个标签的不确定性意见 STS 数据集，以研究人类集体意见在 STS 中的表现。分析发现， neither 一个整数还是一个 Gaussian 能够准确地描述观察到的判断。此外，我们还表明，现有的 STS 模型无法捕捉人类对具体实例的不一致，而是反映了对总体数据集的预测信心。
</details></li>
</ul>
<hr>
<h2 id="I-WAS-a-Data-Augmentation-Method-with-GPT-2-for-Simile-Detection"><a href="#I-WAS-a-Data-Augmentation-Method-with-GPT-2-for-Simile-Detection" class="headerlink" title="I-WAS: a Data Augmentation Method with GPT-2 for Simile Detection"></a>I-WAS: a Data Augmentation Method with GPT-2 for Simile Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04109">http://arxiv.org/abs/2308.04109</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cyzLoveDream/I-was">https://github.com/cyzLoveDream/I-was</a></li>
<li>paper_authors: Yongzhu Chang, Rongsheng Zhang, Jiashu Pu</li>
<li>for: 用于提高自然语言处理（NLP）相关应用中的比喻检测精度。</li>
<li>methods: 使用Word replacement和Sentence completion方法，通过GPT-2语言模型进行数据增强。</li>
<li>results: 实验结果表明，我们的提议的数据增强方法可以有效提高比喻检测的性能。<details>
<summary>Abstract</summary>
Simile detection is a valuable task for many natural language processing (NLP)-based applications, particularly in the field of literature. However, existing research on simile detection often relies on corpora that are limited in size and do not adequately represent the full range of simile forms. To address this issue, we propose a simile data augmentation method based on \textbf{W}ord replacement And Sentence completion using the GPT-2 language model. Our iterative process called I-WAS, is designed to improve the quality of the augmented sentences. To better evaluate the performance of our method in real-world applications, we have compiled a corpus containing a more diverse set of simile forms for experimentation. Our experimental results demonstrate the effectiveness of our proposed data augmentation method for simile detection.
</details>
<details>
<summary>摘要</summary>
寓言检测是许多自然语言处理（NLP）应用中的重要任务，特别在文学领域。然而，现有的寓言检测研究通常基于有限的词库和不充分表示寓言的全面形式。为解决这个问题，我们提出了基于Word replacement和Sentence completion的GPT-2语言模型的寓言数据增强方法。我们的迭代过程被称为I-WAS，旨在提高增强后的句子质量。为更好地评估我们的方法在实际应用中的表现，我们将一个包含更多寓言形式的词库编译起来。我们的实验结果表明我们的提议的数据增强方法对寓言检测具有有效性。
</details></li>
</ul>
<hr>
<h2 id="DataTales-Investigating-the-use-of-Large-Language-Models-for-Authoring-Data-Driven-Articles"><a href="#DataTales-Investigating-the-use-of-Large-Language-Models-for-Authoring-Data-Driven-Articles" class="headerlink" title="DataTales: Investigating the use of Large Language Models for Authoring Data-Driven Articles"></a>DataTales: Investigating the use of Large Language Models for Authoring Data-Driven Articles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04076">http://arxiv.org/abs/2308.04076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicole Sultanum, Arjun Srinivasan</li>
<li>for: 这个论文是为了探讨使用现代大语言模型（LLM）来帮助作者写作数据驱动文章的可能性和价值。</li>
<li>methods: 该论文使用了一个名为DataTales的 прототип系统，利用LLM生成 Chart 的文字导趋。</li>
<li>results: 该研究通过对 11 名专业人士的反馈，发现 DataTales 可以帮助作者更快速地撰写数据驱动文章，并提供了一些可能性和机会来进一步 интегра LLM 为数据驱动文章作者的 valuabe助手。<details>
<summary>Abstract</summary>
Authoring data-driven articles is a complex process requiring authors to not only analyze data for insights but also craft a cohesive narrative that effectively communicates the insights. Text generation capabilities of contemporary large language models (LLMs) present an opportunity to assist the authoring of data-driven articles and expedite the writing process. In this work, we investigate the feasibility and perceived value of leveraging LLMs to support authors of data-driven articles. We designed a prototype system, DataTales, that leverages a LLM to generate textual narratives accompanying a given chart. Using DataTales as a design probe, we conducted a qualitative study with 11 professionals to evaluate the concept, from which we distilled affordances and opportunities to further integrate LLMs as valuable data-driven article authoring assistants.
</details>
<details>
<summary>摘要</summary>
作者撰写数据驱动文章是一个复杂的过程，作者需要不仅分析数据获得洞察，还需要把握数据来编写一篇有关的文章。当代大语言模型（LLM）的文本生成能力提供了帮助作者撰写数据驱动文章的机会，并且可以快速化写作过程。在这项工作中，我们研究了利用LLM支持数据驱动文章作者的可能性和价值。我们设计了一个名为DataTales的 прототип系统，该系统利用LLM生成与给定图表相关的文字导趋。通过DataTales作为设计探索工具，我们对11名专业人士进行了质量研究，从中提炼出了LLM在数据驱动文章作者助手中的可能性和优势。
</details></li>
</ul>
<hr>
<h2 id="The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings"><a href="#The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings" class="headerlink" title="The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings"></a>The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04052">http://arxiv.org/abs/2308.04052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TimMerino1710/five-dollar-model">https://github.com/TimMerino1710/five-dollar-model</a></li>
<li>paper_authors: Timothy Merino, Roman Negri, Dipika Rajesh, M Charity, Julian Togelius</li>
<li>for: 这篇论文旨在描述一种可以从编码文本提示生成低维度图像的轻量级文本-图像生成模型。</li>
<li>methods: 该模型使用了一些限制量的训练数据，并应用了一些新的扩展策略来提高模型在三个小 datasets（像素艺术视频游戏地图、视频游戏 sprite 图像和压缩emoji图像）的性能。</li>
<li>results: 根据cosine相似性分数，该模型能够成功地生成具有编码 semantic 含义的图像，并且在限制量数据下可以达到高质量和美观的图像生成。<details>
<summary>Abstract</summary>
The five-dollar model is a lightweight text-to-image generative architecture that generates low dimensional images from an encoded text prompt. This model can successfully generate accurate and aesthetically pleasing content in low dimensional domains, with limited amounts of training data. Despite the small size of both the model and datasets, the generated images are still able to maintain the encoded semantic meaning of the textual prompt. We apply this model to three small datasets: pixel art video game maps, video game sprite images, and down-scaled emoji images and apply novel augmentation strategies to improve the performance of our model on these limited datasets. We evaluate our models performance using cosine similarity score between text-image pairs generated by the CLIP VIT-B/32 model.
</details>
<details>
<summary>摘要</summary>
“五币模型”是一个轻量级文本至图生成架构，它将文本提示转换为低维度图像。这个模型可以成功实现精确和美观的内容生成，即使对于训练数据的量相对较少。尽管模型和数据集都很小，但生成的图像仍然能够保持文本提示中的 semantics 含义。我们将这个模型应用到三个小型数据集：像素艺术游戏地图、游戏图像和缩小的表情符号图像，并对这些限制的数据集进行新的扩展策略以改善我们的模型表现。我们使用 CLIP VIT-B/32 模型的弹性相似度分数来评估我们的模型表现。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset"><a href="#A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset" class="headerlink" title="A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset"></a>A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04037">http://arxiv.org/abs/2308.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse</li>
<li>For: The paper is written for text classification and its algorithms, specifically focusing on the feature weighting method for text classification on unstructured data.* Methods: The paper uses two features, N-Grams and TF-IDF, on the IMDB movie reviews and Amazon Alexa reviews dataset for sentiment analysis. The state-of-the-art classifiers used to validate the method include SVM, Logistic Regression, Multinomial Naive Bayes, Random Forest, Decision Tree, and k-nearest neighbors.* Results: The paper found that TF-IDF features resulted in a significant increase in feature extraction, with TF-IDF achieving the maximum accuracy, precision, recall, and F1-score values of 93.81%, 94.20%, 93.81%, and 91.99%, respectively, in the Random Forest classifier.<details>
<summary>Abstract</summary>
Text Classification is the process of categorizing text into the relevant categories and its algorithms are at the core of many Natural Language Processing (NLP). Term Frequency-Inverse Document Frequency (TF-IDF) and NLP are the most highly used information retrieval methods in text classification. We have investigated and analyzed the feature weighting method for text classification on unstructured data. The proposed model considered two features N-Grams and TF-IDF on the IMDB movie reviews and Amazon Alexa reviews dataset for sentiment analysis. Then we have used the state-of-the-art classifier to validate the method i.e., Support Vector Machine (SVM), Logistic Regression, Multinomial Naive Bayes (Multinomial NB), Random Forest, Decision Tree, and k-nearest neighbors (KNN). From those two feature extractions, a significant increase in feature extraction with TF-IDF features rather than based on N-Gram. TF-IDF got the maximum accuracy (93.81%), precision (94.20%), recall (93.81%), and F1-score (91.99%) value in Random Forest classifier.
</details>
<details>
<summary>摘要</summary>
文本分类是将文本分类到相关的类别，其算法是自然语言处理（NLP）的核心。文本频率-反转文档频率（TF-IDF）和NLP是文本检索中最常用的方法。我们已经调查和分析了文本分类中的特征赋值方法，并在IMDB电影评论和Amazon Alexa评论数据集上进行了 sentiment分析。然后，我们使用了当今最佳分类器来验证方法，即支持向量机（SVM）、梯度回归、多元随机树（Multinomial NB）、Random Forest、决策树和k-最近邻居（KNN）。从这两个特征提取方法中，TF-IDF特征提取得到了显著的提高，而不是基于N-Gram。TF-IDF在Random Forest分类器中获得了最高的准确率（93.81%）、精度（94.20%）、回归率（93.81%）和F1分数（91.99%）值。
</details></li>
</ul>
<hr>
<h2 id="Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model"><a href="#Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model" class="headerlink" title="Continual Pre-Training of Large Language Models: How to (re)warm your model?"></a>Continual Pre-Training of Large Language Models: How to (re)warm your model?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04014">http://arxiv.org/abs/2308.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kshitij Gupta, Benjamin Thérien, Adam Ibrahim, Mats L. Richter, Quentin Anthony, Eugene Belilovsky, Irina Rish, Timothée Lesort</li>
<li>for: 这个论文的目的是探讨如何实现大语言模型的持续预训练，以提高计算效率和预训练模型的性能。</li>
<li>methods: 本研究使用了不同的暖身策略来研究模型在新数据上的性能。</li>
<li>results: 研究结果显示，使用暖身策略可以在长期内提高下游数据的性能，并且在大下游数据集上超越从头开始训练的模型。<details>
<summary>Abstract</summary>
Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and evaluate performance through validation perplexity. We experiment with different pre-training checkpoints, various maximum learning rates, and various warmup lengths. Our results show that while rewarming models first increases the loss on upstream and downstream data, in the longer run it improves the downstream performance, outperforming models trained from scratch$\unicode{x2013}$even for a large downstream dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Simple-synthetic-data-reduces-sycophancy-in-large-language-models"><a href="#Simple-synthetic-data-reduces-sycophancy-in-large-language-models" class="headerlink" title="Simple synthetic data reduces sycophancy in large language models"></a>Simple synthetic data reduces sycophancy in large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03958">http://arxiv.org/abs/2308.03958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google/sycophancy-intervention">https://github.com/google/sycophancy-intervention</a></li>
<li>paper_authors: Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, Quoc V. Le</li>
<li>for: 本研究旨在研究语音模型中的奴役行为（sycophancy），并提出一种简单的人工数据干预方法来减少这种行为。</li>
<li>methods: 研究者使用了三个偏见任务（Perez et al., 2022），测试了模型在不同的缩放和调教情况下的奴役行为。</li>
<li>results: 研究发现，对于PaLM模型，通过缩放和调教可以显著增强奴役行为，而且even when the user’s view is objectively incorrect, models will still agree with them。此外，研究者还提出了一种简单的人工数据干预方法，通过在公共NLP任务上添加一些适当的数据，可以减少模型对用户意见的依赖。<details>
<summary>Abstract</summary>
Sycophancy is an undesirable behavior where models tailor their responses to follow a human user's view even when that view is not objectively correct (e.g., adapting liberal views once a user reveals that they are liberal). In this paper, we study the prevalence of sycophancy in language models and propose a simple synthetic-data intervention to reduce this behavior.   First, on a set of three sycophancy tasks (Perez et al., 2022) where models are asked for an opinion on statements with no correct answers (e.g., politics), we observe that both model scaling and instruction tuning significantly increase sycophancy for PaLM models up to 540B parameters. Second, we extend sycophancy evaluations to simple addition statements that are objectively incorrect, finding that despite knowing that these statements are wrong, language models will still agree with them if the user does as well.   To reduce sycophancy, we present a straightforward synthetic-data intervention that takes public NLP tasks and encourages models to be robust to user opinions on these tasks. Adding these data in a lightweight finetuning step can significantly reduce sycophantic behavior on held-out prompts. Code for generating synthetic data for intervention can be found at https://github.com/google/sycophancy-intervention.
</details>
<details>
<summary>摘要</summary>
sycophancy 是一种不良行为，在语言模型回答时适应人工用户的观点，即使这些观点不是 объекively 正确（例如，适应自由主义观点一旦用户承认自己是自由主义者）。在这篇论文中，我们研究了语言模型中的 sycophancy 的普遍性和提出了一种简单的人工数据干预措施来降低这种行为。首先，我们在 Perez et al. (2022) 中提供的三个 sycophancy 任务上观察到，随着模型缩放和指令调整，PaLM 模型的 sycophancy 会增加到 540B 参数的最大值。其次，我们扩展了 sycophancy 评估范围到对象错误的简单加法句子，发现，即使用户认为这些句子是错误的，语言模型仍会同意它们，如果用户也同意。为了降低 sycophancy，我们提出了一种简单的人工数据干预措施，通过在公共 NLP 任务上添加一些适应用户观点的数据，让模型在新的任务上具有更好的Robustness。可以在 https://github.com/google/sycophancy-intervention 找到代码生成 synthetic data 的步骤。
</details></li>
</ul>
<hr>
<h2 id="Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet"><a href="#Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet" class="headerlink" title="Universal Automatic Phonetic Transcription into the International Phonetic Alphabet"></a>Universal Automatic Phonetic Transcription into the International Phonetic Alphabet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03917">http://arxiv.org/abs/2308.03917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctaguchi/multipa">https://github.com/ctaguchi/multipa</a></li>
<li>paper_authors: Chihiro Taguchi, Yusuke Sakai, Parisa Haghani, David Chiang</li>
<li>for: 这个研究旨在开发一个可以将任何语言的speech转录为国际音声字母表（IPA）的模型。</li>
<li>methods: 这个模型基于wav2vec 2.0，通过对听取到的音频输入进行 fine-tuning，预测IPA。</li>
<li>results: 该模型在七种语言的CommonVoice 11.0训练数据上达到了与人工标注几乎相当的质量水平，并且与之前的最佳speech-to-IPA模型（Wav2Vec2Phoneme）的训练数据集相比，该模型的训练数据集更小。<details>
<summary>Abstract</summary>
This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Cross-Domain-Evaluation-of-Approaches-for-Causal-Knowledge-Extraction"><a href="#A-Cross-Domain-Evaluation-of-Approaches-for-Causal-Knowledge-Extraction" class="headerlink" title="A Cross-Domain Evaluation of Approaches for Causal Knowledge Extraction"></a>A Cross-Domain Evaluation of Approaches for Causal Knowledge Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03891">http://arxiv.org/abs/2308.03891</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aniksh/causal-spert">https://github.com/aniksh/causal-spert</a></li>
<li>paper_authors: Anik Saha, Oktie Hassanzadeh, Alex Gittens, Jian Ni, Kavitha Srinivas, Bulent Yener</li>
<li>for: 提取文本中的 causa-effect 关系</li>
<li>methods: 使用预训练语言模型（如BERT）的序列标记模型和span基于方法进行 causal 知识提取</li>
<li>results: 结果表明，使用BERT预训练语言模型的序列标记模型可以提供 significnat 性能提升，而span基于方法在四个数据集中的表现都比simple sequence tagging模型更好。<details>
<summary>Abstract</summary>
Causal knowledge extraction is the task of extracting relevant causes and effects from text by detecting the causal relation. Although this task is important for language understanding and knowledge discovery, recent works in this domain have largely focused on binary classification of a text segment as causal or non-causal. In this regard, we perform a thorough analysis of three sequence tagging models for causal knowledge extraction and compare it with a span based approach to causality extraction. Our experiments show that embeddings from pre-trained language models (e.g. BERT) provide a significant performance boost on this task compared to previous state-of-the-art models with complex architectures. We observe that span based models perform better than simple sequence tagging models based on BERT across all 4 data sets from diverse domains with different types of cause-effect phrases.
</details>
<details>
<summary>摘要</summary>
causal knowledge extraction 是另一个重要的自然语言处理任务，即从文本中提取有关 causal 关系的信息。 although recent works in this area have mainly focused on将文本段分类为 causal 或非 causal，我们在这个领域进行了系统性的分析，并与 span 基于 causality 提取方法进行比较。 our experiments show that pre-trained language model 的 embedding 提供了 significannot performance boost 在这个任务中，比之前的 state-of-the-art 模型 with complex architectures。 我们发现 span 基于模型在所有四个数据集中表现较好， especialy when dealing with diverse domains and different types of cause-effect phrases.
</details></li>
</ul>
<hr>
<h2 id="Generative-Benchmark-Creation-for-Table-Union-Search"><a href="#Generative-Benchmark-Creation-for-Table-Union-Search" class="headerlink" title="Generative Benchmark Creation for Table Union Search"></a>Generative Benchmark Creation for Table Union Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03883">http://arxiv.org/abs/2308.03883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/northeastern-datalab/alt-gen">https://github.com/northeastern-datalab/alt-gen</a></li>
<li>paper_authors: Koyena Pal, Aamod Khatiwada, Roee Shraga, Renée J. Miller</li>
<li>for: 本研究的目的是为了开发一种基于生成AI模型的数据管理 benchmark，以解决现有的数据管理问题具有语义性。</li>
<li>methods: 本研究使用的方法包括生成AI模型来创建结构化数据 benchmark，以及对现有的手动纪录和标注的数据进行evaluation。</li>
<li>results: 研究发现，使用生成AI模型创建的 benchmark 比手动纪录和标注的 benchmark 更加具有挑战性，并且允许更加详细的分析方法的性能。 Specifically, the top-performing method achieves a Mean Average Precision of around 60%, over 30% less than its performance on existing manually created benchmarks.<details>
<summary>Abstract</summary>
Data management has traditionally relied on synthetic data generators to generate structured benchmarks, like the TPC suite, where we can control important parameters like data size and its distribution precisely. These benchmarks were central to the success and adoption of database management systems. But more and more, data management problems are of a semantic nature. An important example is finding tables that can be unioned. While any two tables with the same cardinality can be unioned, table union search is the problem of finding tables whose union is semantically coherent. Semantic problems cannot be benchmarked using synthetic data. Our current methods for creating benchmarks involve the manual curation and labeling of real data. These methods are not robust or scalable and perhaps more importantly, it is not clear how robust the created benchmarks are. We propose to use generative AI models to create structured data benchmarks for table union search. We present a novel method for using generative models to create tables with specified properties. Using this method, we create a new benchmark containing pairs of tables that are both unionable and non-unionable but related. We thoroughly evaluate recent existing table union search methods over existing benchmarks and our new benchmark. We also present and evaluate a new table search methods based on recent large language models over all benchmarks. We show that the new benchmark is more challenging for all methods than hand-curated benchmarks, specifically, the top-performing method achieves a Mean Average Precision of around 60%, over 30% less than its performance on existing manually created benchmarks. We examine why this is the case and show that the new benchmark permits more detailed analysis of methods, including a study of both false positives and false negatives that were not possible with existing benchmarks.
</details>
<details>
<summary>摘要</summary>
“数据管理历史上依赖了人工生成的数据生成器来生成结构化的标准吞吐量测试（TPC），以控制数据大小和分布的重要参数。这些测试对数据库管理系统的采用和普及做出了重要贡献。然而，越来越多的数据管理问题是 semantic 性质的，例如找到可union的表。虽然任何两个表都可以union，但表union搜索问题是找到semantically coherent的表的union。semantic问题无法使用人工生成的数据来 benchmark。我们当前的创建benchmark方法是通过手动筛选和标注实际数据来实现。这些方法不具有可靠性和扩展性，而且可能更重要的是，不确定创建的benchmark的可靠性。我们提议使用生成AI模型来创建结构化数据 benchmarks for table union search。我们提出了一种使用生成模型创建表 avec specified properties的新方法。使用这种方法，我们创建了一个新的benchmark，包含可union和non-union但相关的表对。我们进行了对现有benchmark和我们新的benchmark的严格评估。我们还提出了基于最新的大语言模型的新表搜索方法，并对所有benchmark进行评估。我们发现新的benchmark比手动创建的benchmark更加具有挑战性，特别是top-performing方法的 Mean Average Precision 约为60%，相比手动创建的benchmark的30%以上。我们分析了这种情况，并证明新的benchmark允许更详细的方法分析，包括对方法的false positives和false negatives的研究，这些研究不可能通过现有benchmark进行。”
</details></li>
</ul>
<hr>
<h2 id="Semantic-Equivalence-of-e-Commerce-Queries"><a href="#Semantic-Equivalence-of-e-Commerce-Queries" class="headerlink" title="Semantic Equivalence of e-Commerce Queries"></a>Semantic Equivalence of e-Commerce Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03869">http://arxiv.org/abs/2308.03869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aritra Mandal, Daniel Tunkelang, Zhe Wu</li>
<li>for: 提高电商搜索中的用户体验和企业业绩</li>
<li>methods: 提出了一种框架，通过识别和利用查询等价性来提高搜索结果的准确率和用户满意度</li>
<li>results: 实验结果表明，该框架可以高效地识别和利用查询等价性，并与流行的句子转换模型相比，实现了更高的查询相似性（Pearson correlation coefficient为0.85），这表明该方法可以提高电商搜索中的用户体验和企业业绩。<details>
<summary>Abstract</summary>
Search query variation poses a challenge in e-commerce search, as equivalent search intents can be expressed through different queries with surface-level differences. This paper introduces a framework to recognize and leverage query equivalence to enhance searcher and business outcomes. The proposed approach addresses three key problems: mapping queries to vector representations of search intent, identifying nearest neighbor queries expressing equivalent or similar intent, and optimizing for user or business objectives. The framework utilizes both surface similarity and behavioral similarity to determine query equivalence. Surface similarity involves canonicalizing queries based on word inflection, word order, compounding, and noise words. Behavioral similarity leverages historical search behavior to generate vector representations of query intent. An offline process is used to train a sentence similarity model, while an online nearest neighbor approach supports processing of unseen queries. Experimental evaluations demonstrate the effectiveness of the proposed approach, outperforming popular sentence transformer models and achieving a Pearson correlation of 0.85 for query similarity. The results highlight the potential of leveraging historical behavior data and training models to recognize and utilize query equivalence in e-commerce search, leading to improved user experiences and business outcomes. Further advancements and benchmark datasets are encouraged to facilitate the development of solutions for this critical problem in the e-commerce domain.
</details>
<details>
<summary>摘要</summary>
<SYS> translate-send:   from-language en  to-language zh-CN  text-type text  contents "Search query variation poses a challenge in e-commerce search, as equivalent search intents can be expressed through different queries with surface-level differences. This paper introduces a framework to recognize and leverage query equivalence to enhance searcher and business outcomes. The proposed approach addresses three key problems: mapping queries to vector representations of search intent, identifying nearest neighbor queries expressing equivalent or similar intent, and optimizing for user or business objectives. The framework utilizes both surface similarity and behavioral similarity to determine query equivalence. Surface similarity involves canonicalizing queries based on word inflection, word order, compounding, and noise words. Behavioral similarity leverages historical search behavior to generate vector representations of query intent. An offline process is used to train a sentence similarity model, while an online nearest neighbor approach supports processing of unseen queries. Experimental evaluations demonstrate the effectiveness of the proposed approach, outperforming popular sentence transformer models and achieving a Pearson correlation of 0.85 for query similarity. The results highlight the potential of leveraging historical behavior data and training models to recognize and utilize query equivalence in e-commerce search, leading to improved user experiences and business outcomes. Further advancements and benchmark datasets are encouraged to facilitate the development of solutions for this critical problem in the e-commerce domain."</SYS>Here's the translation in Simplified Chinese:搜索查询的变化 poses 电商搜索中的挑战，因为等效的搜索意图可以通过不同的查询语句表达出来，具有表面上的差异。本文提出了一种框架，用于认可和利用查询相似性，以提高搜索者和企业的结果。该框架解决了三个关键问题：将查询映射到搜索意图的vector表示，标识最相似的查询语句，并优化用户或企业的目标。该框架利用表面相似性和行为相似性来确定查询相似性。表面相似性包括Word排序、幂等词、缩合词和噪音词的canonicalization。行为相似性利用历史搜索行为生成查询意图的vector表示。在线程中使用了一个历史搜索行为训练的模型，而在线上使用了一个最近的邻居方法来处理未看过的查询。实验证明了该方法的效果，超越了流行的句子变换模型，并达到了0.85的Pearson相关性。结果表明，通过利用历史行为数据和训练模型，可以认可和利用查询相似性，提高用户体验和商业结果。进一步的进步和标准 datasets 是鼓励的，以便开发电商搜索领域中的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Storyfier-Exploring-Vocabulary-Learning-Support-with-Text-Generation-Models"><a href="#Storyfier-Exploring-Vocabulary-Learning-Support-with-Text-Generation-Models" class="headerlink" title="Storyfier: Exploring Vocabulary Learning Support with Text Generation Models"></a>Storyfier: Exploring Vocabulary Learning Support with Text Generation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03864">http://arxiv.org/abs/2308.03864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhui Peng, Xingbo Wang, Qiushi Han, Junkai Zhu, Xiaojuan Ma, Huamin Qu</li>
<li>for: 支持学习任务的生成模型（Generative Adversarial Networks，GANs）</li>
<li>methods: 使用文本生成模型生成故事，并提供学习者可以使用AI助手进行写作和练习语言使用的功能</li>
<li>results: 学习者对使用Storyfier进行学习有很好的满意度，但是在阅读、填充和写作任务中，使用Storyfier的学习者表现相对较差，尤其是在记忆和使用目标词汇方面。<details>
<summary>Abstract</summary>
Vocabulary learning support tools have widely exploited existing materials, e.g., stories or video clips, as contexts to help users memorize each target word. However, these tools could not provide a coherent context for any target words of learners' interests, and they seldom help practice word usage. In this paper, we work with teachers and students to iteratively develop Storyfier, which leverages text generation models to enable learners to read a generated story that covers any target words, conduct a story cloze test, and use these words to write a new story with adaptive AI assistance. Our within-subjects study (N=28) shows that learners generally favor the generated stories for connecting target words and writing assistance for easing their learning workload. However, in the read-cloze-write learning sessions, participants using Storyfier perform worse in recalling and using target words than learning with a baseline tool without our AI features. We discuss insights into supporting learning tasks with generative models.
</details>
<details>
<summary>摘要</summary>
学习词汇支持工具已经广泛利用现有的材料，如故事或视频片段，作为词汇记忆的 Context。然而，这些工具无法提供学生们感兴趣的词汇的 coherent Context，并rarely帮助学生们实践词汇使用。在这篇论文中，我们与教师和学生合作开发了Storyfier，利用文本生成模型，让学生可以阅读一个包含target词的生成故事，进行故事填充测试，并使用这些词汇写新的故事，并且有adaptive AI帮助。我们的在人Subjects研究（N=28）表明，学生通常喜欢使用Storyfier来连接target词和写作帮助，以减轻学习劳动。然而，在read-cloze-write学习 Session中，参与者使用Storyfier表现比基eline工具而言，更难记忆和使用target词。我们讨论了如何使用生成模型支持学习任务的信息。
</details></li>
</ul>
<hr>
<h2 id="Extracting-detailed-oncologic-history-and-treatment-plan-from-medical-oncology-notes-with-large-language-models"><a href="#Extracting-detailed-oncologic-history-and-treatment-plan-from-medical-oncology-notes-with-large-language-models" class="headerlink" title="Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models"></a>Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03853">http://arxiv.org/abs/2308.03853</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/madhumitasushil/oncllmextraction">https://github.com/madhumitasushil/oncllmextraction</a></li>
<li>paper_authors: Madhumita Sushil, Vanessa E. Kennedy, Brenda Y. Miao, Divneet Mandair, Travis Zack, Atul J. Butte</li>
<li>for: 这个研究的目的是为了评估最新的自然语言处理模型（GPT-4、GPT-3.5-turbo、FLAN-UL2）在抽取肿瘤病例纪录中的表现。</li>
<li>methods: 这个研究使用了一种细化的 schema 来标注肿瘤病例纪录中的信息，包括患者特征、肿瘤特征、测试和治疗等。然后，使用这些标注数据来评估这三个模型在抽取肿瘤病例纪录中的表现。</li>
<li>results: 研究发现，GPT-4 模型在抽取肿瘤病例纪录中表现最佳，其中的 BLEU 分数为 0.69，ROUGE 分数为 0.72，并且在复杂任务中的准确率为 67%。这个模型在抽取肿瘤特征和药物信息方面表现特别出色，并且在推断疾病的 симптом和未来药物的考虑方面也表现了优异。这个研究表明，GPT-4 可能已经可以用于从肿瘤进程纪录中提取重要的信息，以便于临床研究、复杂人口管理和评估quality patient care。<details>
<summary>Abstract</summary>
Both medical care and observational studies in oncology require a thorough understanding of a patient's disease progression and treatment history, often elaborately documented in clinical notes. Despite their vital role, no current oncology information representation and annotation schema fully encapsulates the diversity of information recorded within these notes. Although large language models (LLMs) have recently exhibited impressive performance on various medical natural language processing tasks, due to the current lack of comprehensively annotated oncology datasets, an extensive evaluation of LLMs in extracting and reasoning with the complex rhetoric in oncology notes remains understudied. We developed a detailed schema for annotating textual oncology information, encompassing patient characteristics, tumor characteristics, tests, treatments, and temporality. Using a corpus of 10 de-identified breast cancer progress notes at University of California, San Francisco, we applied this schema to assess the abilities of three recently-released LLMs (GPT-4, GPT-3.5-turbo, and FLAN-UL2) to perform zero-shot extraction of detailed oncological history from two narrative sections of clinical progress notes. Our team annotated 2750 entities, 2874 modifiers, and 1623 relationships. The GPT-4 model exhibited overall best performance, with an average BLEU score of 0.69, an average ROUGE score of 0.72, and an average accuracy of 67% on complex tasks (expert manual evaluation). Notably, it was proficient in tumor characteristic and medication extraction, and demonstrated superior performance in inferring symptoms due to cancer and considerations of future medications. The analysis demonstrates that GPT-4 is potentially already usable to extract important facts from cancer progress notes needed for clinical research, complex population management, and documenting quality patient care.
</details>
<details>
<summary>摘要</summary>
医疗和观察研究在肿瘤学中都需要深刻理解病人疾病进展和治疗历史，这些信息通常都是在临床笔记中详细记录的。 despite their vital role， current oncology information representation and annotation schema 没有完全涵盖临床笔记中的多样性信息。 Recently， large language models (LLMs) have shown impressive performance on various medical natural language processing tasks，but due to the lack of comprehensively annotated oncology datasets，the extent to which LLMs can extract and reason with the complex rhetoric in oncology notes remains understudied。We developed a detailed schema for annotating textual oncology information， including patient characteristics，tumor characteristics，tests，treatments，and temporality。Using a corpus of 10 de-identified breast cancer progress notes at University of California, San Francisco，we applied this schema to assess the abilities of three recently-released LLMs (GPT-4, GPT-3.5-turbo, and FLAN-UL2) to perform zero-shot extraction of detailed oncological history from two narrative sections of clinical progress notes。Our team annotated 2750 entities，2874 modifiers，and 1623 relationships。GPT-4 model exhibited overall best performance，with an average BLEU score of 0.69，an average ROUGE score of 0.72，and an average accuracy of 67% on complex tasks (expert manual evaluation)。It was proficient in tumor characteristic and medication extraction，and demonstrated superior performance in inferring symptoms due to cancer and considerations of future medications。The analysis demonstrates that GPT-4 is potentially already usable to extract important facts from cancer progress notes needed for clinical research，complex population management，and documenting quality patient care。
</details></li>
</ul>
<hr>
<h2 id="What-about-translation-New-coding-system-for-content-analysis-on-the-perception-of-literary-translation-around-the-political-transformation-in-1989-in-Hungary-as-a-classification-problem-on-an-unbalanced-dataset"><a href="#What-about-translation-New-coding-system-for-content-analysis-on-the-perception-of-literary-translation-around-the-political-transformation-in-1989-in-Hungary-as-a-classification-problem-on-an-unbalanced-dataset" class="headerlink" title="What about translation? New coding system for content analysis on the perception of literary translation around the political transformation in 1989 in Hungary as a classification problem on an unbalanced dataset"></a>What about translation? New coding system for content analysis on the perception of literary translation around the political transformation in 1989 in Hungary as a classification problem on an unbalanced dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03742">http://arxiv.org/abs/2308.03742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dalma Galambos, Pál Zsámboki</li>
<li>for:  Tracking trends in the perception of literary translation during political transformation in 1989 in Hungary.</li>
<li>methods:  Trained BERT models to carry over coding system to 1980-1999 issues of literary journal Nagyvilág, with extensive hyperparameter tuning, loss functions robust to label unbalance, 10-fold cross-validation, model ensemble for prediction, manual validation, and calibration method to better predict label counts.</li>
<li>results:  Study of relations between labels using label relation networks.<details>
<summary>Abstract</summary>
To track trends in the perception of literary translation around the political transformation in 1989 in Hungary, a coding system was developed on the paragraphs of the 1980-1999 issues of the literary journal Alf\"old. This paper describes how we trained BERT models to carry over the coding system to the 1980-1999 issues of the literary journal Nagyvil\'ag. We use extensive hyperparameter tuning, loss functions robust to label unbalance, 10-fold cross-validation for precise evaluations and a model ensemble for prediction, manual validation on the predict set, a new calibration method to better predict label counts for sections of the Nagyvil\'ag corpus, and to study the relations between labels, we construct label relation networks.
</details>
<details>
<summary>摘要</summary>
为了跟踪1989年政治转型期间文学翻译的观点变化，我们在1980-1999年《alföld》期刊中的段落上设计了一个编码系统。本文描述了我们如何使用BERT模型将编码系统传播到1980-1999年《大世界》期刊中的段落上。我们采用了广泛的hyperparameter优化、 Label不均衡的损失函数、10重交叉验证、精确的预测和手动验证预测集、一个新的准确预测标签计数的方法、以及为了研究标签之间的关系，我们构建了标签关系网络。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.CL_2023_08_08/" data-id="clpxp6byg00a1ee882ew3364t" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.LG_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T10:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.LG_2023_08_08/">cs.LG - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation"><a href="#TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation" class="headerlink" title="TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation"></a>TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10843">http://arxiv.org/abs/2308.10843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mireille Fares, Catherine Pelachaud, Nicolas Obin</li>
<li>for: 这篇论文目标是将虚拟代理人的行为表达风格传递到另一个代理人中，保持行为的形式不变，以便在交流中传递意思。</li>
<li>methods: 我们提出了一种基于多模态变换器的模型，称为TranSTYLer，可以将多 modal的source speaker的行为与目标 speaker的风格相结合。我们假设行为表达风格在不同的沟通模式中都存在，包括文本、语音、身体姿势和面部表情。模型采用了内容和风格分离的方法，以确保传递的风格不会对源行为的意思产生干扰。</li>
<li>results: 我们在PATS数据集上训练了我们的模型，并对比了现有的状态数据模型。对jective和主观评价结果表明，我们的模型在seen和unseen风格中都能够实现更高的性能。此外，我们还提出了一种方法来评估传递的行为和姿势是否正确，以确保源行为的意思不会产生泄露。<details>
<summary>Abstract</summary>
This paper addresses the challenge of transferring the behavior expressivity style of a virtual agent to another one while preserving behaviors shape as they carry communicative meaning. Behavior expressivity style is viewed here as the qualitative properties of behaviors. We propose TranSTYLer, a multimodal transformer based model that synthesizes the multimodal behaviors of a source speaker with the style of a target speaker. We assume that behavior expressivity style is encoded across various modalities of communication, including text, speech, body gestures, and facial expressions. The model employs a style and content disentanglement schema to ensure that the transferred style does not interfere with the meaning conveyed by the source behaviors. Our approach eliminates the need for style labels and allows the generalization to styles that have not been seen during the training phase. We train our model on the PATS corpus, which we extended to include dialog acts and 2D facial landmarks. Objective and subjective evaluations show that our model outperforms state of the art models in style transfer for both seen and unseen styles during training. To tackle the issues of style and content leakage that may arise, we propose a methodology to assess the degree to which behavior and gestures associated with the target style are successfully transferred, while ensuring the preservation of the ones related to the source content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accurate-Explainable-and-Private-Models-Providing-Recourse-While-Minimizing-Training-Data-Leakage"><a href="#Accurate-Explainable-and-Private-Models-Providing-Recourse-While-Minimizing-Training-Data-Leakage" class="headerlink" title="Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage"></a>Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04341">http://arxiv.org/abs/2308.04341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Catherine Huang, Chelse Swoopes, Christina Xiao, Jiaqi Ma, Himabindu Lakkaraju</li>
<li>For: This paper aims to mitigate attacks on machine learning models that provide algorithmic recourse to individuals who receive negative outcomes.* Methods: The paper presents two novel methods for generating differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR).* Results: The authors find that DPM and LR perform well in reducing what an adversary can infer, especially at low false positive rates. When the training dataset size is large enough, the authors achieve particular success in preventing privacy leakage while maintaining model and recourse accuracy with the LR method.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是解决机器学习模型提供的算法救济对于个人不良结果的攻击。</li>
<li>methods: 论文提出了两种新的幂等私人救济方法：差分私人模型（DPM）和拉普拉斯救济（LR）。</li>
<li>results: 作者发现，在低假阳性率下，DPM和LR都能够减少攻击者可以获取的信息量，特别是在训练数据集大 enough 的情况下。<details>
<summary>Abstract</summary>
Machine learning models are increasingly utilized across impactful domains to predict individual outcomes. As such, many models provide algorithmic recourse to individuals who receive negative outcomes. However, recourse can be leveraged by adversaries to disclose private information. This work presents the first attempt at mitigating such attacks. We present two novel methods to generate differentially private recourse: Differentially Private Model (DPM) and Laplace Recourse (LR). Using logistic regression classifiers and real world and synthetic datasets, we find that DPM and LR perform well in reducing what an adversary can infer, especially at low FPR. When training dataset size is large enough, we find particular success in preventing privacy leakage while maintaining model and recourse accuracy with our novel LR method.
</details>
<details>
<summary>摘要</summary>
机器学习模型在影响各个领域中越来越广泛应用，以预测个人结果。然而，这些模型可能会泄露个人隐私信息。这项工作提出了首个防止这种攻击的方法。我们提出了两种新的涉嫌隐私模型（DPM）和拉普拉斯补偿（LR）。使用логистиック回归分类器和实际世界和synthetic数据集，我们发现DPM和LR在低 False Positive Rate（FP）下具有良好的隐私保护能力，特别是当训练集大小充分时。我们的LR方法在防止隐私泄露的同时保持模型和补偿精度。
</details></li>
</ul>
<hr>
<h2 id="RLHF-Blender-A-Configurable-Interactive-Interface-for-Learning-from-Diverse-Human-Feedback"><a href="#RLHF-Blender-A-Configurable-Interactive-Interface-for-Learning-from-Diverse-Human-Feedback" class="headerlink" title="RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback"></a>RLHF-Blender: A Configurable Interactive Interface for Learning from Diverse Human Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04332">http://arxiv.org/abs/2308.04332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yannick Metz, David Lindner, Raphaël Baur, Daniel Keim, Mennatallah El-Assady</li>
<li>for: 用于学习人类反馈的奖励模型，并考虑人类反馈的因素。</li>
<li>methods: 使用RLHF-Blender，一个可配置的交互式界面，系统atically investigate人类反馈的性质和质量。</li>
<li>results: 可以 investigate various types of feedback, such as demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness.<details>
<summary>Abstract</summary>
To use reinforcement learning from human feedback (RLHF) in practical applications, it is crucial to learn reward models from diverse sources of human feedback and to consider human factors involved in providing feedback of different types. However, the systematic study of learning from diverse types of feedback is held back by limited standardized tooling available to researchers. To bridge this gap, we propose RLHF-Blender, a configurable, interactive interface for learning from human feedback. RLHF-Blender provides a modular experimentation framework and implementation that enables researchers to systematically investigate the properties and qualities of human feedback for reward learning. The system facilitates the exploration of various feedback types, including demonstrations, rankings, comparisons, and natural language instructions, as well as studies considering the impact of human factors on their effectiveness. We discuss a set of concrete research opportunities enabled by RLHF-Blender. More information is available at https://rlhfblender.info/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将人类反馈学习（RLHF）应用于实际场景中，是非常重要的。因此，学习从多种人类反馈来的奖励模型是必须的，同时也需要考虑人类提供反馈的因素。然而，现有的研究工具有限，使得系统性的研究受到阻碍。为了bridging这个差距，我们提议RLHF-Blender，一个可配置的交互式界面，用于学习人类反馈。RLHF-Blender提供了可模块化的实验框架和实现，帮助研究者系统地探索不同类型的人类反馈的性质和质量。系统支持explore多种反馈类型，包括示例、排名、比较和自然语言指令，以及考虑人类因素对其效果的影响。我们介绍了RLHF-Blender可以开发的具体研究机会。更多信息请访问https://rlhfblender.info/.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs"><a href="#Cooperative-Multi-agent-Bandits-Distributed-Algorithms-with-Optimal-Individual-Regret-and-Constant-Communication-Costs" class="headerlink" title="Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs"></a>Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04314">http://arxiv.org/abs/2308.04314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yang, Xuchuang Wang, Mohammad Hajiesmaili, Lijun Zhang, John C. S. Lui, Don Towsley</li>
<li>for: 这个论文的目的是开发一种协同多智能体多机枪游戏中的Optimal group regret和低通信成本的bandit算法。</li>
<li>methods: 这个论文使用了两种方法：领导者-追随者和完全分布式算法。</li>
<li>results: 这个论文的算法可以达到最佳个体 regret和常量通信成本。<details>
<summary>Abstract</summary>
Recently, there has been extensive study of cooperative multi-agent multi-armed bandits where a set of distributed agents cooperatively play the same multi-armed bandit game. The goal is to develop bandit algorithms with the optimal group and individual regrets and low communication between agents. The prior work tackled this problem using two paradigms: leader-follower and fully distributed algorithms. Prior algorithms in both paradigms achieve the optimal group regret. The leader-follower algorithms achieve constant communication costs but fail to achieve optimal individual regrets. The state-of-the-art fully distributed algorithms achieve optimal individual regrets but fail to achieve constant communication costs. This paper presents a simple yet effective communication policy and integrates it into a learning algorithm for cooperative bandits. Our algorithm achieves the best of both paradigms: optimal individual regret and constant communication costs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-Model-Inversion-Eavesdropping-Attack-in-Semantic-Communication-Systems"><a href="#The-Model-Inversion-Eavesdropping-Attack-in-Semantic-Communication-Systems" class="headerlink" title="The Model Inversion Eavesdropping Attack in Semantic Communication Systems"></a>The Model Inversion Eavesdropping Attack in Semantic Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04304">http://arxiv.org/abs/2308.04304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Chen, Qianqian Yang, Zhiguo Shi, Jiming Chen</li>
<li>for: 本研究探讨了 semantic communication 系统中的隐私泄露问题，并提出了一种基于 Random Permutation and Substitution 的防御策略。</li>
<li>methods: 本研究使用了 Model Inversion Eavesdropping Attack (MIEA) 来攻击 semantic communication 系统，并考虑了 white-box 和 black-box 两种设定。</li>
<li>results: 实验结果表明，提出的防御策略可以有效防止 MIEA，并且在不同的通道条件下能够保持高质量的征文重建。<details>
<summary>Abstract</summary>
In recent years, semantic communication has been a popular research topic for its superiority in communication efficiency. As semantic communication relies on deep learning to extract meaning from raw messages, it is vulnerable to attacks targeting deep learning models. In this paper, we introduce the model inversion eavesdropping attack (MIEA) to reveal the risk of privacy leaks in the semantic communication system. In MIEA, the attacker first eavesdrops the signal being transmitted by the semantic communication system and then performs model inversion attack to reconstruct the raw message, where both the white-box and black-box settings are considered. Evaluation results show that MIEA can successfully reconstruct the raw message with good quality under different channel conditions. We then propose a defense method based on random permutation and substitution to defend against MIEA in order to achieve secure semantic communication. Our experimental results demonstrate the effectiveness of the proposed defense method in preventing MIEA.
</details>
<details>
<summary>摘要</summary>
近年来， semantic communication 成为研究热点，因为它可以提高通信效率。然而， semantic communication 依赖深度学习来提取消息的意义，因此它容易受到深度学习模型的攻击。在这篇论文中，我们介绍了模型反向窃听攻击（MIEA），以揭示 semantic communication 系统中的隐私泄露风险。在 MIEA 中，攻击者首先监听 semantic communication 系统传输的信号，然后通过模型反向攻击来重建原始消息，包括白盒和黑盒两种设置。我们的evaluation结果表明， MIEA 可以在不同的通信道条件下成功重建原始消息，并且提议了基于随机排序和替换的防御方法，以确保 semantic communication 的安全。我们的实验结果表明，提议的防御方法可以有效防止 MIEA。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor"><a href="#Comparative-Analysis-of-the-wav2vec-2-0-Feature-Extractor" class="headerlink" title="Comparative Analysis of the wav2vec 2.0 Feature Extractor"></a>Comparative Analysis of the wav2vec 2.0 Feature Extractor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04286">http://arxiv.org/abs/2308.04286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Vieting, Ralf Schlüter, Hermann Ney</li>
<li>for: 这个论文主要是为了检验 neural raw waveform feature extractors (FEs) 是否可以取代传统的手工特征提取方法，以实现更加一致的模型从语音到转录文本。</li>
<li>methods: 这篇论文使用了 wav2vec 2.0 模型，这是一种直接在语音波形上运行的 convolutional FE，以及一种替代的神经网络特征提取方法。</li>
<li>results: 研究表明，两种神经网络特征提取方法都能与传统的特征提取方法竞争在 LibriSpeech benchmark 上，并且分析了各个组件的效果。 另外，研究还发现，ASR 系统最重要的信息是由一组带宽滤波器获得的。<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) systems typically use handcrafted feature extraction pipelines. To avoid their inherent information loss and to achieve more consistent modeling from speech to transcribed text, neural raw waveform feature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model, which has recently gained large popularity, uses a convolutional FE which operates directly on the speech waveform. However, it is not yet studied extensively in the literature. In this work, we study its capability to replace the standard feature extraction methods in a connectionist temporal classification (CTC) ASR model and compare it to an alternative neural FE. We show that both are competitive with traditional FEs on the LibriSpeech benchmark and analyze the effect of the individual components. Furthermore, we analyze the learned filters and show that the most important information for the ASR system is obtained by a set of bandpass filters.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）系统通常使用手工设计的特征提取管道。以避免其内置的信息损失并实现更一致的模型化从语音到转录文本，神经原始波形特征提取器（FEs）是一种吸引人的方法。另外，最近广受欢迎的wav2vec 2.0模型使用了一个 convolutional FE，该模型直接操作于语音波形。然而，它在文献中还没有得到广泛的研究。在这项工作中，我们研究了它的可行性以replace标准特征提取方法在一个 Connectionist Temporal Classification（CTC） ASR 模型中，并与一个 alternating neural FE 进行比较。我们发现两者在 LibriSpeech benchmark 上都是与传统特征提取方法竞争的，并分析了各种组件的效果。此外，我们还分析了学习的滤波器，发现主要的信息 для ASR 系统是由一组 bandpass 滤波器获得。
</details></li>
</ul>
<hr>
<h2 id="In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning"><a href="#In-Context-Alignment-Chat-with-Vanilla-Language-Models-Before-Fine-Tuning" class="headerlink" title="In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning"></a>In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04275">http://arxiv.org/abs/2308.04275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xhan77/in-context-alignment">https://github.com/xhan77/in-context-alignment</a></li>
<li>paper_authors: Xiaochuang Han</li>
<li>for: 这个研究探讨了在运行时进行对适应的自适应语言模型。</li>
<li>methods: 研究使用了一个未经任何精度调整的语言模型Llama-2，并在它的示例上进行了协同学习。</li>
<li>results: 与直接提示相比，在受Context的协同学习下，无需修改模型参数的情况下，vanilla语言模型的赢利率提高了7倍，与文本达文西003模型from OpenAI进行比较。<details>
<summary>Abstract</summary>
In this note, we explore inference-time alignment through in-context learning. We consider a vanilla pretrained language model Llama-2 before any fine-tuning and retrieve an average of 9 demonstration alignment examples when the model is prompted to follow chat-style instructions. Compared to direct prompting, the in-context alignment without changing model weights leads to a 7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making the vanilla language model comparable to strong baselines with alignment fine-tuning.
</details>
<details>
<summary>摘要</summary>
在这份笔记中，我们研究了在使用受Context learning时进行推理时的对齐。我们考虑了未经任何微调的语言模型Llama-2，并从chat风格的指令中获取了9个示例对齐。与直接提示相比，在不变换模型参数时进行受Context learning的对齐，导致了与文本-达文西003模型from OpenAI的7倍增加赢得率，使得未经微调的语言模型与对齐微调的基elines相当。
</details></li>
</ul>
<hr>
<h2 id="Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey"><a href="#Teacher-Student-Architecture-for-Knowledge-Distillation-A-Survey" class="headerlink" title="Teacher-Student Architecture for Knowledge Distillation: A Survey"></a>Teacher-Student Architecture for Knowledge Distillation: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04268">http://arxiv.org/abs/2308.04268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengming Hu, Xuan Li, Dan Liu, Haolun Wu, Xi Chen, Ju Wang, Xue Liu</li>
<li>for: 本研究旨在探讨 teacher-student 架构在多种知识压缩目标上的应用，包括知识压缩、知识扩展、知识适应和知识增强等。</li>
<li>methods: 本文提出了一种系统性的对 teacher-student 架构的介绍，包括不同的知识表示方法和优化目标，以及一些代表学习算法和有效的压缩方案。</li>
<li>results: 本文综述了现有的应用场景，包括分类、识别、生成、排名和回归等多种目标，并提出了未来研究方向，包括架构设计、知识质量和回归学习等。<details>
<summary>Abstract</summary>
Although Deep neural networks (DNNs) have shown a strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. To tackle this issue, Teacher-Student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. Recently, Teacher-Student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. With the help of Teacher-Student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. Different from existing KD surveys that primarily focus on knowledge compression, this survey first explores Teacher-Student architectures across multiple distillation objectives. This survey presents an introduction to various knowledge representations and their corresponding optimization objectives. Additionally, we provide a systematic overview of Teacher-Student architectures with representative learning algorithms and effective distillation schemes. This survey also summarizes recent applications of Teacher-Student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. Lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. Through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying Teacher-Student architectures on various distillation objectives.
</details>
<details>
<summary>摘要</summary>
although deep neural networks (DNNs) have shown strong capacity to solve large-scale problems in many areas, such DNNs are hard to be deployed in real-world systems due to their voluminous parameters. to tackle this issue, teacher-student architectures were proposed, where simple student networks with a few parameters can achieve comparable performance to deep teacher networks with many parameters. recently, teacher-student architectures have been effectively and widely embraced on various knowledge distillation (KD) objectives, including knowledge compression, knowledge expansion, knowledge adaptation, and knowledge enhancement. with the help of teacher-student architectures, current studies are able to achieve multiple distillation objectives through lightweight and generalized student networks. different from existing KD surveys that primarily focus on knowledge compression, this survey first explores teacher-student architectures across multiple distillation objectives. this survey presents an introduction to various knowledge representations and their corresponding optimization objectives. additionally, we provide a systematic overview of teacher-student architectures with representative learning algorithms and effective distillation schemes. this survey also summarizes recent applications of teacher-student architectures across multiple purposes, including classification, recognition, generation, ranking, and regression. lastly, potential research directions in KD are investigated, focusing on architecture design, knowledge quality, and theoretical studies of regression-based learning, respectively. through this comprehensive survey, industry practitioners and the academic community can gain valuable insights and guidelines for effectively designing, learning, and applying teacher-student architectures on various distillation objectives.
</details></li>
</ul>
<hr>
<h2 id="BarlowRL-Barlow-Twins-for-Data-Efficient-Reinforcement-Learning"><a href="#BarlowRL-Barlow-Twins-for-Data-Efficient-Reinforcement-Learning" class="headerlink" title="BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning"></a>BarlowRL: Barlow Twins for Data-Efficient Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04263">http://arxiv.org/abs/2308.04263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omer Veysel Cagatan</li>
<li>for: 提高数据效率的强化学习Agent</li>
<li>methods:  combinest Barlow Twins自动学习框架和DER数据有效雨bow算法</li>
<li>results: 在Atari 100k测试集上表现出色，超过了DER和其它对比算法的表现In Simplified Chinese:</li>
<li>for: 提高强化学习数据效率</li>
<li>methods:  combine Barlow Twins 自动学习框架和DER 数据有效雨bow 算法</li>
<li>results: 在Atari 100k 测试集上表现出色，超过了DER 和其它对比算法的表现<details>
<summary>Abstract</summary>
This paper introduces BarlowRL, a data-efficient reinforcement learning agent that combines the Barlow Twins self-supervised learning framework with DER (Data-Efficient Rainbow) algorithm. BarlowRL outperforms both DER and its contrastive counterpart CURL on the Atari 100k benchmark. BarlowRL avoids dimensional collapse by enforcing information spread to the whole space. This helps RL algorithms to utilize uniformly spread state representation that eventually results in a remarkable performance. The integration of Barlow Twins with DER enhances data efficiency and achieves superior performance in the RL tasks. BarlowRL demonstrates the potential of incorporating self-supervised learning techniques to improve RL algorithms.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了BarlowRL，一种数据效率的 reinforcement learning代理人，它将Barlow Twins自我超vis学框架与DER（数据效率雨bow）算法结合在一起。BarlowRL在Atari 100k benchmark上表现出优于DER和其对应的对比算法CURL。BarlowRL通过保证信息散布到整个空间，避免维度塌陷，使RL算法能够利用 uniformly 分布的状态表示，最终导致了很好的表现。将Barlow Twins与DER集成，可以提高数据效率并实现RL任务中的优秀表现。BarlowRL表明了将自我超vis学技术integrated into RL算法可以提高其表现。
</details></li>
</ul>
<hr>
<h2 id="SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction"><a href="#SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction" class="headerlink" title="SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction"></a>SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04262">http://arxiv.org/abs/2308.04262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer">https://github.com/rahul-gs-16/sdlformer</a></li>
<li>paper_authors: Rahul G. S., Sriprabha Ramnarayanan, Mohammad Al Fahim, Keerthi Ram, Preejith S. P, Mohanasankar Sivaprakasam</li>
<li>for: 这个论文目的是提出一种基于窗口变换器的快速MRI图像重建方法，以优化MRI图像重建速度和质量。</li>
<li>methods: 该方法使用了窗口变换器网络，并 integrate了扩展注意力机制和卷积操作，以捕捉更远的像素关系和学习低级翻译不变的特征。</li>
<li>results: 实验结果显示，提出的方法可以在4x和5x的下采样情况下，与其他架构和平行领域自主学习基准相比，提高了1.40dB的PSNR和0.028的SSIM的平均提升。代码可以在<a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer.git%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/rahul-gs-16/sdlformer.git中下载。</a><details>
<summary>Abstract</summary>
Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. The proposed model is trained in a self-supervised manner. We perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. We compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. Results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. The code is available at https://github.com/rahul-gs-16/sdlformer.git
</details>
<details>
<summary>摘要</summary>
transformers 已经成为了卷积神经网络的可行替代品，因为它们可以学习图像空间中的非本地区关系。transformers 的自注意机制使得它们可以捕捉图像中的长距离依赖关系，这可能是加速 MRI 图像重建的潜在的优点，因为 MRI 图像下折衰的效果是非本地的。尽管它们有计算效率的优势，但窗口基于的 transformers 受限于图像窗口范围内的依赖关系。我们提议一种窗口基于的 transformer 网络，该网络 integrate 了扩展注意力机制和卷积操作以加速 MRI 图像重建。我们的提案的网络包括扩展和密集 neighborhood attention transformers，以增强远方块像素关系，并在 transformer 模块中添加 depth-wise 卷积来学习低级翻译不变的特征。我们的模型在自我超vised 的方式进行训练。我们进行了多种实验，包括多个 MRI 加速器，以及 coronal PD、coronal PDFS 和 axial T2 对比。我们与其他重建架构和并行Domain self-supervised learning 基线进行比较。结果表明，我们的模型在 PSNR 和 SSIM 两个指标上分别提高了约1.40 dB和约0.028的平均提升。代码可以在 <https://github.com/rahul-gs-16/sdlformer.git> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Natural-Language-Based-Audio-Retrieval-with-PaSST-and-Large-Audio-Caption-Data-Sets"><a href="#Advancing-Natural-Language-Based-Audio-Retrieval-with-PaSST-and-Large-Audio-Caption-Data-Sets" class="headerlink" title="Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets"></a>Advancing Natural-Language Based Audio Retrieval with PaSST and Large Audio-Caption Data Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04258">http://arxiv.org/abs/2308.04258</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optimusprimus/dcase2023_task6b">https://github.com/optimusprimus/dcase2023_task6b</a></li>
<li>paper_authors: Paul Primus, Khaled Koutini, Gerhard Widmer</li>
<li>for: 这篇论文旨在提出一种基于预训练文本和声音变换器的文本到声音检索系统。</li>
<li>methods: 该方法使用自注意力基于声音编码器对声音进行编码，并在不同模式之间进行了系统性分析，以评估每个系统组件对检索性能的影响。</li>
<li>results: 该系统在2023年DCASE挑战中 ranked第一，并在ClothoV2测试集上超越当前状态的艺术点，提高了5.6 pp. mAP@10。<details>
<summary>Abstract</summary>
This work presents a text-to-audio-retrieval system based on pre-trained text and spectrogram transformers. Our method projects recordings and textual descriptions into a shared audio-caption space in which related examples from different modalities are close. Through a systematic analysis, we examine how each component of the system influences retrieval performance. As a result, we identify two key components that play a crucial role in driving performance: the self-attention-based audio encoder for audio embedding and the utilization of additional human-generated and synthetic data sets during pre-training. We further experimented with augmenting ClothoV2 captions with available keywords to increase their variety; however, this only led to marginal improvements. Our system ranked first in the 2023's DCASE Challenge, and it outperforms the current state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:这个研究提出了一个基于预训练文本和spectrogram转换器的文本至声音检索系统。我们的方法将录音和文本描述映射到一个共享声音-caption空间，在不同modalities中相关的示例都很近。通过系统atic分析，我们评估每个系统组件对检索性能的影响。我们发现两个关键的组件对检索性能有决定性的影响：使用自我注意力基于的声音编码器，以及在预训练过程中使用additional human-generated和合成数据集。我们还尝试了将ClothoV2标签中可用的关键词加入，但只导致了微妙的改进。我们的系统在2023年DCASE挑战中名列第一，并在ClothoV2标准测试集上比现状权威的检索性能提高5.6 pp. mAP@10。
</details></li>
</ul>
<hr>
<h2 id="Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction"><a href="#Federated-Inference-with-Reliable-Uncertainty-Quantification-over-Wireless-Channels-via-Conformal-Prediction" class="headerlink" title="Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction"></a>Federated Inference with Reliable Uncertainty Quantification over Wireless Channels via Conformal Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04237">http://arxiv.org/abs/2308.04237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Osvaldo Simeone</li>
<li>for: 这篇论文旨在研究在多个设备和服务器共享预训练模型的情况下，通过设备到服务器的通信来提高服务器的推断决策质量。</li>
<li>methods: 这篇论文提出了一种名为“联邦均衡预测”（Federated Conformal Prediction，简称WFCP）的协议，它基于类型基本多访问（Type-Based Multiple Access，TBMA）和一种新的量词 corrections 策略。WFCP 可以在无阻塞通信的情况下提供正式的可靠性保证。</li>
<li>results: 根据数值结果，作者比较了WFCP 与现有的联邦CP 方案的性能，发现WFCP 在有限通信资源和&#x2F;或多个设备的情况下具有显著优势。特别是，WFCP 可以在无阻塞通信的情况下提供正式的可靠性保证，而现有的联邦CP 方案则不能做到。<details>
<summary>Abstract</summary>
Consider a setting in which devices and a server share a pre-trained model. The server wishes to make an inference on a new input given the model. Devices have access to data, previously not used for training, and can communicate to the server over a common wireless channel. If the devices have no access to the new input, can communication from devices to the server enhance the quality of the inference decision at the server? Recent work has introduced federated conformal prediction (CP), which leverages devices-to-server communication to improve the reliability of the server's decision. With federated CP, devices communicate to the server information about the loss accrued by the shared pre-trained model on the local data, and the server leverages this information to calibrate a decision interval, or set, so that it is guaranteed to contain the correct answer with a pre-defined target reliability level. Previous work assumed noise-free communication, whereby devices can communicate a single real number to the server. In this paper, we study for the first time federated CP in a wireless setting. We introduce a novel protocol, termed wireless federated conformal prediction (WFCP), which builds on type-based multiple access (TBMA) and on a novel quantile correction strategy. WFCP is proved to provide formal reliability guarantees in terms of coverage of the predicted set produced by the server. Using numerical results, we demonstrate the significant advantages of WFCP against digital implementations of existing federated CP schemes, especially in regimes with limited communication resources and/or large number of devices.
</details>
<details>
<summary>摘要</summary>
Setting 中，设备和服务器共享预训练模型。服务器想要对新输入进行推断。设备可以访问未使用过训练的数据，并可以通过公共无线频道与服务器进行通信。如果设备没有访问新输入，是否可以通过设备到服务器的通信提高服务器的推断决策质量？ latest work 引入了联邦均衡预测（CP），该技术利用设备到服务器的通信来提高服务器的决策可靠性。在联邦CP中，设备将共享模型在本地数据上的损失信息通过无线频道传输给服务器，服务器利用这些信息进行均衡决策集，以 garantuee 决策集中包含正确答案，并且预定的可靠性水平。 previous work 假设了无噪通信，设备可以将单个实数传输给服务器。在这篇论文中，我们研究了在无线设置下的联邦CP。我们提出了一种新的协议，称为无线联邦均衡预测（WFCP），它基于类型基本多访问（TBMA）和一种新的量衡修正策略。WFCP提供了正式可靠性保证，包括预测集产生的覆盖率。通过数值结果，我们展示了WFCP在数字实现联邦CP方案的情况下，特别是在通信资源有限和/或设备数量很大的情况下，具有显著优势。
</details></li>
</ul>
<hr>
<h2 id="OpinionConv-Conversational-Product-Search-with-Grounded-Opinions"><a href="#OpinionConv-Conversational-Product-Search-with-Grounded-Opinions" class="headerlink" title="OpinionConv: Conversational Product Search with Grounded Opinions"></a>OpinionConv: Conversational Product Search with Grounded Opinions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04226">http://arxiv.org/abs/2308.04226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vahid Sadiri Javadi, Martin Potthast, Lucie Flek</li>
<li>for: 这 paper 是为了 simulating sales conversations 和 grounding conversational AI in true subjective narratives.</li>
<li>methods: 该 paper 使用 product reviews 作为 rich source of product opinions.</li>
<li>results: 在 several user studies 中，generated conversations 被评估为 realistic, 并且 assessors 确认 opinions 作为 informed basis for decision-making.<details>
<summary>Abstract</summary>
When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision-making.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在寻找产品时，他人的意见具有重要的指导作用。产品的主观经验可以提供有价值的信息。这也是销售对话中的事实，顾客和销售助手交换产品的信息和意见。然而，用AI训练这些对话是因为语言模型缺乏真实世界经验而复杂。我们解决这个问题，利用产品评论作为产品意见的丰富源，以真实的主观故事为 conversational AI 定位。我们开发了 OpinionConv，首个用于模拟销售对话的对话AI。为验证生成的对话，我们进行了多个用户研究，显示生成的意见被评估为真实。我们的评估人也证实了意见作为决策基础的重要性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models"><a href="#Semantic-Interpretation-and-Validation-of-Graph-Attention-based-Explanations-for-GNN-Models" class="headerlink" title="Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models"></a>Semantic Interpretation and Validation of Graph Attention-based Explanations for GNN Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04220">http://arxiv.org/abs/2308.04220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Efimia Panagiotaki, Daniele De Martini, Lars Kunze</li>
<li>for: 这个论文旨在研究如何使用Semantic Attention提高Graph Neural Network（GNN）模型的解释性，并通过在模型中引入semantically-informed perturbations来建立feature-importance weights和模型准确性之间的相关性。</li>
<li>methods: 该论文提出了一种基于Graph Deep Learning（GDL）的方法，通过引入Semantic Attention Mechanism来提高GNN模型的解释性。该方法基于Attention Mechanism的概念，通过计算模型对输入特征的重要性来提供feature-based解释。</li>
<li>results: 该论文通过应用该方法于一个Lidar点云估计模型，成功地标识了模型的透明性和性能之间的相关性，并生成了可靠的后果Semantic Explanation。<details>
<summary>Abstract</summary>
In this work, we propose a methodology for investigating the application of semantic attention to enhance the explainability of Graph Neural Network (GNN)-based models, introducing semantically-informed perturbations and establishing a correlation between predicted feature-importance weights and model accuracy. Graph Deep Learning (GDL) has emerged as a promising field for tasks like scene interpretation, leveraging flexible graph structures to concisely describe complex features and relationships. As traditional explainability methods used in eXplainable AI (XAI) cannot be directly applied to such structures, graph-specific approaches are introduced. Attention mechanisms have demonstrated their efficacy in estimating the importance of input features in deep learning models and thus have been previously employed to provide feature-based explanations for GNN predictions. Building upon these insights, we extend existing attention-based graph-explainability methods investigating the use of attention weights as importance indicators of semantically sorted feature sets. Through analysing the behaviour of predicted attention-weights distribution in correlation with model accuracy, we gain valuable insights into feature importance with respect to the behaviour of the GNN model. We apply our methodology to a lidar pointcloud estimation model successfully identifying key semantic classes that contribute to enhanced performance effectively generating reliable post-hoc semantic explanations.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们提出了一种方法来提高图 neural network（GNN）模型的解释性，通过引入Semantic attention和建立 predicted feature-importance  weights 和模型准确率之间的相关性。图深度学习（GDL）已经成为了场景理解的一个有前途的领域，利用图结构来简洁地描述复杂的特征和关系。传统的解释方法在XAI中不能直接应用于这些结构，因此图特定的方法被引入。Attention机制已经证明了它们可以估算输入特征的重要性，因此在GNN预测中提供了基于特征的解释。我们在这些基础上进一步推广了现有的注意力Weight-based graph-explainability方法，研究 attention weights 作为semantic sorted feature sets的重要性指标。通过分析预测的注意力分布的行为和模型准确率之间的相关性，我们获得了对feature importance的重要信息，即 Semantic classes的贡献对于提高性能的贡献。我们应用了我们的方法ology到一个 lidar pointcloud estimation模型，成功地Identifying key semantic classes that contribute to enhanced performance, effectively generating reliable post-hoc semantic explanations.
</details></li>
</ul>
<hr>
<h2 id="Varying-coefficients-for-regional-quantile-via-KNN-based-LASSO-with-applications-to-health-outcome-study"><a href="#Varying-coefficients-for-regional-quantile-via-KNN-based-LASSO-with-applications-to-health-outcome-study" class="headerlink" title="Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study"></a>Varying-coefficients for regional quantile via KNN-based LASSO with applications to health outcome study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04212">http://arxiv.org/abs/2308.04212</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/younghhk/software">https://github.com/younghhk/software</a></li>
<li>paper_authors: Seyoung Park, Eun Ryung Lee, Hyokyoung G. Hong</li>
<li>for: 这个论文的目的是动态模型健康结果和风险因素之间的关系，以及年龄的时变效应。</li>
<li>methods: 这个论文使用了变 coefficient (VC) 区域量化回归和K-最近邻 (KNN) 混合lasso，以捕捉健康结果和风险因素之间的时变关系。</li>
<li>results: 该方法在实际应用中能够准确地捕捉健康结果和风险因素之间的复杂时变关系。<details>
<summary>Abstract</summary>
Health outcomes, such as body mass index and cholesterol levels, are known to be dependent on age and exhibit varying effects with their associated risk factors. In this paper, we propose a novel framework for dynamic modeling of the associations between health outcomes and risk factors using varying-coefficients (VC) regional quantile regression via K-nearest neighbors (KNN) fused Lasso, which captures the time-varying effects of age. The proposed method has strong theoretical properties, including a tight estimation error bound and the ability to detect exact clustered patterns under certain regularity conditions. To efficiently solve the resulting optimization problem, we develop an alternating direction method of multipliers (ADMM) algorithm. Our empirical results demonstrate the efficacy of the proposed method in capturing the complex age-dependent associations between health outcomes and their risk factors.
</details>
<details>
<summary>摘要</summary>
健康结果，如体重指数和尿痰水平，与年龄存在许多关系，这些关系随着风险因素的变化而发生变化。在这篇论文中，我们提出了一种新的方法，即时变量方程模型，用于描述健康结果和风险因素之间的关系。这种方法通过变量系数（VC）地方量化回归和K-最近邻（KNN）束regularization，捕捉年龄的时间变化效应。我们的方法具有强制实施证明，包括紧张估计误差 bound和在某些正则条件下检测到具体的团集模式。为解决相应的优化问题，我们开发了一种分解方法of multipliers（ADMM）算法。我们的实验结果表明，我们的方法能够准确捕捉健康结果和风险因素之间的复杂年龄关系。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Sketching-for-Secure-Coded-Regression"><a href="#Iterative-Sketching-for-Secure-Coded-Regression" class="headerlink" title="Iterative Sketching for Secure Coded Regression"></a>Iterative Sketching for Secure Coded Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04185">http://arxiv.org/abs/2308.04185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neophytos Charalambides, Hessam Mahdavifar, Mert Pilanci, Alfred O. Hero III</li>
<li>for: 这篇论文是为了提高线性回归的分布式加速而写的。</li>
<li>methods: 该论文使用随机抽样技术，并提高异步系统中势特缺失的抗性。具体来说，它使用随机正交矩阵，并对块进行抽样，以同时保护信息和降低回归问题的维度。在我们的设置中，这种变换对应于一种编码加密的简化 Gradient Coding Scheme，而抽样对应于非势特工作者的回答。</li>
<li>results: 该论文提出了一种分布式iterative sketching方法，可以同时实现线性回归的加速和安全保护。具体来说，它提出了一种使用随机抽样和编码加密的方法，可以在分布式系统中实现高效的线性回归计算。此外，论文还特别关注了一种特殊的随机化hadamard transform，并将其扩展到块抽样。<details>
<summary>Abstract</summary>
In this work, we propose methods for speeding up linear regression distributively, while ensuring security. We leverage randomized sketching techniques, and improve straggler resilience in asynchronous systems. Specifically, we apply a random orthonormal matrix and then subsample \textit{blocks}, to simultaneously secure the information and reduce the dimension of the regression problem. In our setup, the transformation corresponds to an encoded encryption in an \textit{approximate gradient coding scheme}, and the subsampling corresponds to the responses of the non-straggling workers; in a centralized coded computing network. This results in a distributive \textit{iterative sketching} approach for an $\ell_2$-subspace embedding, \textit{i.e.} a new sketch is considered at each iteration. We also focus on the special case of the \textit{Subsampled Randomized Hadamard Transform}, which we generalize to block sampling; and discuss how it can be modified in order to secure the data.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种加速线性回归的分布式方法，同时保证安全性。我们利用随机抽取技术，并改进异步系统中的延迟问题。特别是，我们首先应用随机正交矩阵，然后对块进行采样，以同时保护信息和缩小回归问题的维度。在我们的设置中，这种变换对应于一种编码加密方案，即精度梯度编码，而采样对应于非延迟工作者的响应。因此，我们得到了一种分布式迭代绘制方法，即在每次迭代中生成一个新的绘制。我们还关注特殊情况下的归一化随机哈达姆变换，并将其扩展到块采样；并讨论如何修改它以保护数据。
</details></li>
</ul>
<hr>
<h2 id="Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”"><a href="#Studying-Socially-Unacceptable-Discourse-Classification-SUD-through-different-eyes-“Are-we-on-the-same-page-”" class="headerlink" title="Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”"></a>Studying Socially Unacceptable Discourse Classification (SUD) through different eyes: “Are we on the same page ?”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04180">http://arxiv.org/abs/2308.04180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlinardicyu/sud_study_different_eyes">https://github.com/mlinardicyu/sud_study_different_eyes</a></li>
<li>paper_authors: Bruno Machado Carneiro, Michele Linardi, Julien Longhi</li>
<li>for: 本研究探讨了在线文本中的社会不容许语言特征描述和检测。</li>
<li>methods: 我们首先构建了一个包含多种不同在线源的手动标注文本的新集合，以测试现有机器学习（ML）社会不容许语言检测解决方案中的通用能力。</li>
<li>results: 我们提供了一些数据洞察，以支持领域专家在标注任务中。同时，我们还分析了可能存在的不同批注modalities的影响于社会不容许语言学习，并提出了一些未解决的挑战和研究方向。<details>
<summary>Abstract</summary>
We study Socially Unacceptable Discourse (SUD) characterization and detection in online text. We first build and present a novel corpus that contains a large variety of manually annotated texts from different online sources used so far in state-of-the-art Machine learning (ML) SUD detection solutions. This global context allows us to test the generalization ability of SUD classifiers that acquire knowledge around the same SUD categories, but from different contexts. From this perspective, we can analyze how (possibly) different annotation modalities influence SUD learning by discussing open challenges and open research directions. We also provide several data insights which can support domain experts in the annotation task.
</details>
<details>
<summary>摘要</summary>
我们研究社会不容许的语言讨论（SUD）Characterization和检测在在线文本中。我们首先构建并提供了一个新的 корпуス，包含了不同在线源的手动标注的文本，这些文本在过去的 estado-of-the-art 机器学习（ML）SUD检测解决方案中使用过。这个全球背景允许我们测试SUD分类器的通用能力，这些分类器从不同的上下文中获得了相同的 SUD 类别知识。从这个角度来看，我们可以分析不同标注方式对 SUD 学习的影响，并讨论开放的挑战和研究方向。我们还提供了一些数据见解，以支持领域专家在标注任务中。Note: "SUD" stands for "Socially Unacceptable Discourse" in English.
</details></li>
</ul>
<hr>
<h2 id="Dual-input-neural-networks-for-positional-sound-source-localization"><a href="#Dual-input-neural-networks-for-positional-sound-source-localization" class="headerlink" title="Dual input neural networks for positional sound source localization"></a>Dual input neural networks for positional sound source localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04169">http://arxiv.org/abs/2308.04169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/egrinstein/di_nn">https://github.com/egrinstein/di_nn</a></li>
<li>paper_authors: Eric Grinstein, Vincent W. Neo, Patrick A. Naylor</li>
<li>for: 本研究旨在提高Sound Source Localization（SSL）算法的精度，通过将高维度的多渠道声音信号和场景的声学特性（如投射坐标）与神经网络模型结合使用。</li>
<li>methods: 本研究提出了一种简单有效的双输入神经网络（DI-NN）模型，可以有效地模型高维度声音信号和场景声学特性。</li>
<li>results: 对于一系列的实验数据，DI-NN与基准方法（如最小二乘法和卷积循环神经网络）进行比较，DI-NN在本试用 dataset 中实现了五倍的Localization error reduction than 基准方法，并且较CRNN两倍。<details>
<summary>Abstract</summary>
In many signal processing applications, metadata may be advantageously used in conjunction with a high dimensional signal to produce a desired output. In the case of classical Sound Source Localization (SSL) algorithms, information from a high dimensional, multichannel audio signals received by many distributed microphones is combined with information describing acoustic properties of the scene, such as the microphones' coordinates in space, to estimate the position of a sound source. We introduce Dual Input Neural Networks (DI-NNs) as a simple and effective way to model these two data types in a neural network. We train and evaluate our proposed DI-NN on scenarios of varying difficulty and realism and compare it against an alternative architecture, a classical Least-Squares (LS) method as well as a classical Convolutional Recurrent Neural Network (CRNN). Our results show that the DI-NN significantly outperforms the baselines, achieving a five times lower localization error than the LS method and two times lower than the CRNN in a test dataset of real recordings.
</details>
<details>
<summary>摘要</summary>
在许多信号处理应用程序中，元数据可能被利用于高维信号生成愿景输出。在经典的声音源地理位置算法中，来自多个分布式 Mikrophone 的高维多通道音频信号以及场景的声学属性信息（如 Mikrophone 的空间坐标）被组合以估算声音源的位置。我们引入双输入神经网络（DI-NN）作为一种简单而有效的方法来模型这两种数据类型。我们在不同的难度和真实性场景下训练和评估我们的提议 DI-NN，并与基准architecture（经典的最小二乘法和卷积循环神经网络）进行比较。我们的结果显示，DI-NN 明显超越了基准，在实际录制的测试集中实现了与经典方法（最小二乘法）和卷积循环神经网络（CRNN）相比的五倍的地理位置误差。
</details></li>
</ul>
<hr>
<h2 id="Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness"><a href="#Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness" class="headerlink" title="Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness"></a>Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04137">http://arxiv.org/abs/2308.04137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael W. Spratling</li>
<li>for: 评估机器学习模型的可靠性和稳定性</li>
<li>methods: 使用多种数据类型进行评估，并使用单一指标评估模型的性能</li>
<li>results: 现有深度神经网络模型容易在某些数据类型上出现错误，表明它们在实际场景中可能不可靠，并且容易被骗到错误决策Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to evaluate the robustness and reliability of machine learning models, specifically deep neural networks, by using a wide range of data types and a single metric to assess their performance.</li>
<li>methods: The authors propose using a benchmark that includes multiple types of data to evaluate the models’ performance, and they use a single metric to compare the models’ performance across different data types.</li>
<li>results: The authors found that current deep neural networks are vulnerable to making mistakes on certain types of data, which means they may not be reliable in real-world scenarios where they may encounter data from many different domains. Additionally, the authors found that these models can be easily fooled into making wrong decisions.<details>
<summary>Abstract</summary>
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to produce state-of-the-art robustness, are extremely vulnerable to making mistakes on certain types of data. This means that such models will be unreliable in real-world scenarios where they may encounter data from many different domains, and that they are insecure as they can easily be fooled into making the wrong decisions. It is hoped that these results will motivate the wider adoption of more comprehensive testing methods that will, in turn, lead to the development of more robust machine learning methods in the future.   Code is available at: \url{https://codeberg.org/mwspratling/RobustnessEvaluation}
</details>
<details>
<summary>摘要</summary>
可靠和可靠的评估方法是开发可靠和可靠的机器学习模型的必要第一步。 unfortunately，现有的评估协议通常只能够部分评估模型的性能，因为它们通常只使用有限的测试数据来进行评估。例如，使用标准测试数据不能评估模型对未知类样本的预测结果。相反，使用未知类样本来测试模型将不能评估模型对已知类样本的预测结果。本文提出了使用多种不同类型的数据进行 benchmarking性能，并使用一个可以应用于所有数据类型的单一指标来生成一致的评估性能。使用这种标准，发现当前的深度神经网络，包括使用认为会生成状态对的训练方法，对于某些类型的数据表示极度易误。这意味着这些模型在实际世界中的应用中将不可靠，因为它们可能会遇到多种领域的数据。此外，这些模型也是不安全的，因为它们可以轻松地被骗到错误地做出决策。希望这些结果能够激励更广泛的测试方法的采用，以便在未来开发更加可靠的机器学习方法。Code is available at: \url{https://codeberg.org/mwspratling/RobustnessEvaluation}
</details></li>
</ul>
<hr>
<h2 id="D-Score-A-Synapse-Inspired-Approach-for-Filter-Pruning"><a href="#D-Score-A-Synapse-Inspired-Approach-for-Filter-Pruning" class="headerlink" title="D-Score: A Synapse-Inspired Approach for Filter Pruning"></a>D-Score: A Synapse-Inspired Approach for Filter Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04470">http://arxiv.org/abs/2308.04470</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doyoung Park, Jinsoo Kim, Jina Nam, Jooyoung Chang, Sang Min Park</li>
<li>for: 本文提出了一种基于神经系统的filter pruning方法，用于减少卷积神经网络中过度的权重。</li>
<li>methods: 该方法采用了神经科学的视角，使用了动态得分（D-Score）分析独立重要性，并将权重分配分数来评估独立重要性。</li>
<li>results: 实验结果表明，该方法可以在CIFAR-10和ImageNet datasets上减少了显著的计算量和参数数量，而无需损失精度。<details>
<summary>Abstract</summary>
This paper introduces a new aspect for determining the rank of the unimportant filters for filter pruning on convolutional neural networks (CNNs). In the human synaptic system, there are two important channels known as excitatory and inhibitory neurotransmitters that transmit a signal from a neuron to a cell. Adopting the neuroscientific perspective, we propose a synapse-inspired filter pruning method, namely Dynamic Score (D-Score). D-Score analyzes the independent importance of positive and negative weights in the filters and ranks the independent importance by assigning scores. Filters having low overall scores, and thus low impact on the accuracy of neural networks are pruned. The experimental results on CIFAR-10 and ImageNet datasets demonstrate the effectiveness of our proposed method by reducing notable amounts of FLOPs and Params without significant Acc. Drop.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation"><a href="#OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation" class="headerlink" title="OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation"></a>OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04126">http://arxiv.org/abs/2308.04126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyang Yu, Shihao Wang, Yuan Fang, Wangpeng An</li>
<li>for: 这篇论文旨在提出一种多modal数据融合和无限数据生成的创新方法，以提高多modal数据之间的交互和增强。</li>
<li>methods: 该方法使用了多种多operation，包括视频&#x2F;图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、Recognize Anything Model（RAM）和物体跟踪。</li>
<li>results: 该方法可以识别超过6400种类型的对象，大幅扩大视觉信息范围。它将多modal数据融合起来，促进modalities之间的互助和跨modal数据更正。最终输出将每个视频输入转化为详细的时间序列文档，使视频内容更易被大语言模型处理。<details>
<summary>Abstract</summary>
This paper presents OmniDataComposer, an innovative approach for multimodal data fusion and unlimited data generation with an intent to refine and uncomplicate interplay among diverse data modalities. Coming to the core breakthrough, it introduces a cohesive data structure proficient in processing and merging multimodal data inputs, which include video, audio, and text.   Our crafted algorithm leverages advancements across multiple operations such as video/image caption extraction, dense caption extraction, Automatic Speech Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything Model(RAM), and object tracking. OmniDataComposer is capable of identifying over 6400 categories of objects, substantially broadening the spectrum of visual information. It amalgamates these diverse modalities, promoting reciprocal enhancement among modalities and facilitating cross-modal data correction. \textbf{The final output metamorphoses each video input into an elaborate sequential document}, virtually transmuting videos into thorough narratives, making them easier to be processed by large language models.   Future prospects include optimizing datasets for each modality to encourage unlimited data generation. This robust base will offer priceless insights to models like ChatGPT, enabling them to create higher quality datasets for video captioning and easing question-answering tasks based on video content. OmniDataComposer inaugurates a new stage in multimodal learning, imparting enormous potential for augmenting AI's understanding and generation of complex, real-world data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Constructing-Custom-Thermodynamics-Using-Deep-Learning"><a href="#Constructing-Custom-Thermodynamics-Using-Deep-Learning" class="headerlink" title="Constructing Custom Thermodynamics Using Deep Learning"></a>Constructing Custom Thermodynamics Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04119">http://arxiv.org/abs/2308.04119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoli Chen, Beatrice W. Soh, Zi-En Ooi, Eleonore Vissol-Gaudin, Haijun Yu, Kostya S. Novoselov, Kedar Hippalgaonkar, Qianxiao Li</li>
<li>for: 这个论文的目的是为了开发一种基于总的奥托曼理论的自动化科学发现平台，用于研究复杂动态系统。</li>
<li>methods: 该论文使用了机器学习方法，通过对微观轨迹观察的学习，直接从微观描述中学习宏观动力描述。</li>
<li>results: 该论文通过对聚合物延伸的研究，成功地学习了三个可解释的热动力坐标，并建立了聚合物延伸的动力景观，包括稳定状态和转变状态的识别，以及延伸速率的控制。此外，该论文还应用了该方法到了不同领域的空间疫病问题，证明了该方法的广泛科学和技术应用前景。<details>
<summary>Abstract</summary>
One of the most exciting applications of AI is automated scientific discovery based on previously amassed data, coupled with restrictions provided by the known physical principles, including symmetries and conservation laws. Such automated hypothesis creation and verification can assist scientists in studying complex phenomena, where traditional physical intuition may fail. Of particular importance are complex dynamic systems where their time evolution is strongly influenced by varying external parameters. In this paper we develop a platform based on a generalised Onsager principle to learn macroscopic dynamical descriptions of arbitrary stochastic dissipative systems directly from observations of their microscopic trajectories. We focus on systems whose complexity and sheer sizes render complete microscopic description impractical, and constructing theoretical macroscopic models requires extensive domain knowledge or trial-and-error. Our machine learning approach addresses this by simultaneously constructing reduced thermodynamic coordinates and interpreting the dynamics on these coordinates. We demonstrate our method by studying theoretically and validating experimentally, the stretching of long polymer chains in an externally applied field. Specifically, we learn three interpretable thermodynamic coordinates and build a dynamical landscape of polymer stretching, including (1) the identification of stable and transition states and (2) the control of the stretching rate. We further demonstrate the universality of our approach by applying it to an unrelated problem in a different domain: constructing macroscopic dynamics for spatial epidemics, showing that our method addresses wide scientific and technological applications.
</details>
<details>
<summary>摘要</summary>
一种非常有趣的人工智能应用是基于先前整理的数据自动化科学发现，与知道的物理原理限制相结合，包括对称和能量保守法则。这种自动生成和验证假设可以帮助科学家研究复杂现象，其中传统的物理直觉可能失效。特别是复杂动态系统，其时间演化受外部参数变化的影响很强。在这篇论文中，我们开发了基于总体的奥托生理定律的平台，用于直接从微型跟踪数据中学习杂动系统的宏观动力描述。我们关注的是 complexity 和 scale 至今不可能完全描述的系统，并且构建理论宏观模型需要广泛的领域知识或尝试试验。我们的机器学习方法解决了这个问题，同时构建了减少的热力学坐标和解释动力学。我们通过研究杂动聚合物强制延展的实验和理论分析，证明我们的方法可以在不同领域应用。
</details></li>
</ul>
<hr>
<h2 id="PTransIPs-Identification-of-phosphorylation-sites-based-on-protein-pretrained-language-model-and-Transformer"><a href="#PTransIPs-Identification-of-phosphorylation-sites-based-on-protein-pretrained-language-model-and-Transformer" class="headerlink" title="PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer"></a>PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05115">http://arxiv.org/abs/2308.05115</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/statxzy7/ptransips">https://github.com/statxzy7/ptransips</a></li>
<li>paper_authors: Ziyang Xu, Haitian Zhong<br>for:这份研究用于开发一个新的深度学习模型，用于识别蛋白质中的磷酸化位点。methods:这个模型使用了一种新的深度学习架构，叫做PTransIPs，它将蛋白质中的氨基酸看作是字，将它们拓展为唯一的编码，并且使用了大型预训练的蛋白质模型的嵌入。results:实验结果显示，PTransIPs 能够高效地识别蛋白质中的磷酸化位点，AUROC 值为 0.9232 和 0.9660，分别用于识别磷酸化 S&#x2F;T 和 Y 位点。此外，实验还显示了预训练模型嵌入的贡献，以及模型的可读性和普遍性。<details>
<summary>Abstract</summary>
Phosphorylation is central to numerous fundamental cellular processes, influencing the onset and progression of a variety of diseases. The correct identification of these phosphorylation sites is of great importance to unravel the intricate molecular mechanisms within cells and during viral infections, potentially leading to the discovery of new therapeutic targets. In this study, we introduce PTransIPs, a novel deep learning model for the identification of phosphorylation sites. PTransIPs treat amino acids within protein sequences as words, extracting unique encodings based on their type and sequential position. The model also incorporates embeddings from large pretrained protein models as additional data inputs. PTransIPS is further trained on a combination model of convolutional neural network with residual connections and Transformer model equipped with multi-head attention mechanisms. At last, the model outputs classification results through a fully connected layer. The results of independent testing reveal that PTransIPs outperforms existing state-of-the-art(SOTA) methods, achieving AUROCs of 0.9232 and 0.9660 for identifying phosphorylated S/T and Y sites respectively. In addition, ablation studies prove that pretrained model embeddings contribute to the performance of PTransIPs. Furthermore, PTransIPs has interpretable amino acid preference, visible training process and shows generalizability on other bioactivity classification tasks. To facilitate usage, our code and data are publicly accessible at \url{https://github.com/StatXzy7/PTransIPs}.
</details>
<details>
<summary>摘要</summary>
蛋白磷酸化是细胞内多种基本生物过程中的核心，影响疾病发生和进程。正确识别这些磷酸化位点非常重要，以解释细胞内分子机制和病毒感染过程，可能导致新的药物目标的发现。在这项研究中，我们介绍了PTransIPs，一种新的深度学习模型，用于识别磷酸化位点。PTransIPs将蛋白质内的氨基酸看作 слова，提取唯一的编码，基于它们的类型和顺序位置。模型还使用大型预训练蛋白质模型的嵌入为附加数据输入。PTransIPS在一种组合的卷积神经网络和Transformer模型中进行了进一步训练。最后，模型输出了分类结果通过完全连接层。独立测试结果表明，PTransIPs超过了现有状态的方法，实现了AUROC值为0.9232和0.9660，用于识别磷酸化S/T和Y位点。此外，归因研究表明，预训练模型嵌入对PTransIPs的性能做出了贡献。此外，PTransIPs具有可解释的氨基酸偏好、可见的训练过程和在其他生物活动分类任务上的普适性。为便于使用，我们的代码和数据在GitHub上公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks"><a href="#Correlating-Medi-Claim-Service-by-Deep-Learning-Neural-Networks" class="headerlink" title="Correlating Medi-Claim Service by Deep Learning Neural Networks"></a>Correlating Medi-Claim Service by Deep Learning Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04469">http://arxiv.org/abs/2308.04469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jayanthi Vajiram, Negha Senthil, Nean Adhith. P</li>
<li>for: 防止医疗保险诈骗案件，涵盖患者、医生、诊断中心和保险公司等多方面。</li>
<li>methods: 使用卷积神经网络架构，通过对不同提供者的clamshell进行相关性研究，检测洗钱活动。同时使用supervised和Unsupervised分类器来检测诈骗和非诈骗laims。</li>
<li>results: 通过这种方法，可以准确地检测和预测诈骗案件，保护医疗保险公司和投保人的金融发展。<details>
<summary>Abstract</summary>
Medical insurance claims are of organized crimes related to patients, physicians, diagnostic centers, and insurance providers, forming a chain reaction that must be monitored constantly. These kinds of frauds affect the financial growth of both insured people and health insurance companies. The Convolution Neural Network architecture is used to detect fraudulent claims through a correlation study of regression models, which helps to detect money laundering on different claims given by different providers. Supervised and unsupervised classifiers are used to detect fraud and non-fraud claims.
</details>
<details>
<summary>摘要</summary>
医疗保险索赔是有组织犯罪活动相关的患者、医生、诊断中心和保险公司，形成一个排练的链式反推。这种类型的诈骗活动会对保险人和医疗保险公司的财务发展产生影响。使用卷积神经网络架构来检测诈骗索赔，通过对不同提供者的索赔进行相关的回归分析，可以检测到财务融资。使用超级vised和无级supervised分类器来检测诈骗和非诈骗索赔。
</details></li>
</ul>
<hr>
<h2 id="Explainable-machine-learning-to-enable-high-throughput-electrical-conductivity-optimization-of-doped-conjugated-polymers"><a href="#Explainable-machine-learning-to-enable-high-throughput-electrical-conductivity-optimization-of-doped-conjugated-polymers" class="headerlink" title="Explainable machine learning to enable high-throughput electrical conductivity optimization of doped conjugated polymers"></a>Explainable machine learning to enable high-throughput electrical conductivity optimization of doped conjugated polymers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04103">http://arxiv.org/abs/2308.04103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Wei Yoon, Adithya Kumar, Pawan Kumar, Kedar Hippalgaonkar, J Senthilnath, Vijila Chellappan<br>for: 这研究旨在提高填充 polymer 材料的电导率测量效率，并通过机器学习（ML）方法来加速物料发现。methods: 该研究使用 readily measured absorbance spectra 作为输入，使用 ML 模型来预测填充 polymer 材料的电导率。results: 研究发现，使用 ML 模型可以高度准确地分类和预测填充 polymer 材料的电导率，并且可以提高实验测量效率 by 89%。此外，该研究还解决了机器学习模型中的常见问题，即不可解释性，通过利用特有的数学性质和 ML 模型，得到了证明了 spectral influences on conductivity 的准确信息。<details>
<summary>Abstract</summary>
The combination of high-throughput experimentation techniques and machine learning (ML) has recently ushered in a new era of accelerated material discovery, enabling the identification of materials with cutting-edge properties. However, the measurement of certain physical quantities remains challenging to automate. Specifically, meticulous process control, experimentation and laborious measurements are required to achieve optimal electrical conductivity in doped polymer materials. We propose a ML approach, which relies on readily measured absorbance spectra, to accelerate the workflow associated with measuring electrical conductivity. The first ML model (classification model), accurately classifies samples with a conductivity >~25 to 100 S/cm, achieving a maximum of 100% accuracy rate. For the subset of highly conductive samples, we employed a second ML model (regression model), to predict their conductivities, yielding an impressive test R2 value of 0.984. To validate the approach, we showed that the models, neither trained on the samples with the two highest conductivities of 498 and 506 S/cm, were able to, in an extrapolative manner, correctly classify and predict them at satisfactory levels of errors. The proposed ML workflow results in an improvement in the efficiency of the conductivity measurements by 89% of the maximum achievable using our experimental techniques. Furthermore, our approach addressed the common challenge of the lack of explainability in ML models by exploiting bespoke mathematical properties of the descriptors and ML model, allowing us to gain corroborated insights into the spectral influences on conductivity. Through this study, we offer an accelerated pathway for optimizing the properties of doped polymer materials while showcasing the valuable insights that can be derived from purposeful utilization of ML in experimental science.
</details>
<details>
<summary>摘要</summary>
高通过率实验技术和机器学习（ML）已经引入了一个新的时代，快速发现新材料的Properties。然而，一些物理量的测量仍然具有挑战。 Specifically, 制造过程控制、实验和劳动密集的测量是必需的，以实现射频电性的优化。我们提议一种ML方法，基于ready measured absorbance spectrum，加速测量电性的工作流程。第一个ML模型（分类模型）精确地将样本分类为电性> ~25 to 100 S/cm，达到了100%的准确率。对于部分高电性样本，我们使用了第二个ML模型（回归模型），预测他们的电性，得到了惊人的测试R2值为0.984。为验证方法，我们证明了模型没有在两个最高电性的样本（498和506 S/cm）上训练时，仍然可以在推导性的方式下，正确地分类和预测它们，并且达到了满意的误差水平。提出的ML工作流程可以提高电性测量的效率 by 89%。此外，我们的方法解决了通用机器学习模型的解释性问题，通过特有的数学属性和ML模型，使我们可以获得协同的理解，从而提高了我们对电性的理解。通过这项研究，我们提供了一个加速优化射频电性材料的路径，同时展示了机器学习在实验科学中的有价值。
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-Evolution-of-Deep-Neural-Network-Architectures"><a href="#Asynchronous-Evolution-of-Deep-Neural-Network-Architectures" class="headerlink" title="Asynchronous Evolution of Deep Neural Network Architectures"></a>Asynchronous Evolution of Deep Neural Network Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04102">http://arxiv.org/abs/2308.04102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jason Liang, Hormoz Shahrzad, Risto Miikkulainen</li>
<li>for: 提高ENAS的并发评估速度，提高演化过程的效率。</li>
<li>methods: 提出了一种通用异步评估策略（AES），适用于ENAS。AES使用队列保存最多$K$个个体，等待工作节点进行评估，并在$M&lt;&lt;K$个个体已经被评估后进行下一代创建。</li>
<li>results: 在11比特多路分配任务和图像描述任务中，AES实现了多重性和效率的提升， Suggesting that AES is a promising method for parallelizing the evolution of complex systems with long and variable evaluation times.<details>
<summary>Abstract</summary>
Many evolutionary algorithms (EAs) take advantage of parallel evaluation of candidates. However, if evaluation times vary significantly, many worker nodes (i.e.,\ compute clients) are idle much of the time, waiting for the next generation to be created. Evolutionary neural architecture search (ENAS), a class of EAs that optimizes the architecture and hyperparameters of deep neural networks, is particularly vulnerable to this issue. This paper proposes a generic asynchronous evaluation strategy (AES) that is then adapted to work with ENAS. AES increases throughput by maintaining a queue of upto $K$ individuals ready to be sent to the workers for evaluation and proceeding to the next generation as soon as $M<<K$ individuals have been evaluated by the workers. A suitable value for $M$ is determined experimentally, balancing diversity and efficiency. To showcase the generality and power of AES, it was first evaluated in 11-bit multiplexer design (a single-population verifiable discovery task) and then scaled up to ENAS for image captioning (a multi-population open-ended-optimization task). In both problems, a multifold performance improvement was observed, suggesting that AES is a promising method for parallelizing the evolution of complex systems with long and variable evaluation times, such as those in ENAS.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. The translation is written in the traditional Chinese characters, rather than the simplified Chinese characters used in mainland China. The translation is based on the standard grammar and vocabulary of Simplified Chinese, and may differ slightly from the original text in terms of wording and sentence structure.)
</details></li>
</ul>
<hr>
<h2 id="Why-Data-Science-Projects-Fail"><a href="#Why-Data-Science-Projects-Fail" class="headerlink" title="Why Data Science Projects Fail"></a>Why Data Science Projects Fail</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04896">http://arxiv.org/abs/2308.04896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xLaszlo/datascience-fails">https://github.com/xLaszlo/datascience-fails</a></li>
<li>paper_authors: Balaram Panda</li>
</ul>
<details>
<summary>Abstract</summary>
Data Science is a modern Data Intelligence practice, which is the core of many businesses and helps businesses build smart strategies around to deal with businesses challenges more efficiently. Data Science practice also helps in automating business processes using the algorithm, and it has several other benefits, which also deliver in a non-profitable framework. In regards to data science, three key components primarily influence the effective outcome of a data science project. Those are 1.Availability of Data 2.Algorithm 3.Processing power or infrastructure
</details>
<details>
<summary>摘要</summary>
《数据科学是现代数据智能实践之一，它是许多企业的核心，帮助企业构建智能策略，更有效地面对企业挑战。数据科学实践还可以自动化商业过程，它还有许多其他的优点，可以在非营利性框架下实现。在数据科学方面，三个关键组件主要影响数据科学项目的效果。那些是1.数据的可用性2.算法3.处理能力或基础设施》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details>


<hr>
<h2 id="Application-Oriented-Benchmarking-of-Quantum-Generative-Learning-Using-QUARK"><a href="#Application-Oriented-Benchmarking-of-Quantum-Generative-Learning-Using-QUARK" class="headerlink" title="Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK"></a>Application-Oriented Benchmarking of Quantum Generative Learning Using QUARK</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04082">http://arxiv.org/abs/2308.04082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florian J. Kiwit, Marwa Marso, Philipp Ross, Carlos A. Riofrío, Johannes Klepsch, Andre Luckow</li>
<li>for: 本研究旨在提供一个标准化的 Quantum Machine Learning（QML）算法评估框架，以便更好地评估Quantum Computing（QC）应用程序的性能。</li>
<li>methods: 本研究使用了QUantum computing Application benchmaRK（QUARK）框架，并将其扩展以包括训练和部署Quantum generative models的能力。</li>
<li>results: 本研究通过将不同的Quantum generative models在不同的环境下训练和部署，并使用了广泛的评估指标，以评估这些模型的实际性和可行性。<details>
<summary>Abstract</summary>
Benchmarking of quantum machine learning (QML) algorithms is challenging due to the complexity and variability of QML systems, e.g., regarding model ansatzes, data sets, training techniques, and hyper-parameters selection. The QUantum computing Application benchmaRK (QUARK) framework simplifies and standardizes benchmarking studies for quantum computing applications. Here, we propose several extensions of QUARK to include the ability to evaluate the training and deployment of quantum generative models. We describe the updated software architecture and illustrate its flexibility through several example applications: (1) We trained different quantum generative models using several circuit ansatzes, data sets, and data transformations. (2) We evaluated our models on GPU and real quantum hardware. (3) We assessed the generalization capabilities of our generative models using a broad set of metrics that capture, e.g., the novelty and validity of the generated data.
</details>
<details>
<summary>摘要</summary>
审核量子机器学习（QML）算法具有复杂性和多样性，如模型架构、数据集、训练技术和超参数选择等方面。QUantum computing Application benchmaRK（QUARK）框架可以简化和标准化量子计算应用程序的审核研究。我们提出了将QUARK扩展以支持量子生成模型的训练和部署评估。我们描述了更新后的软件架构，并通过多个示例应用 illustrate its flexibility：1. 我们使用不同的量子生成模型、数据集和数据变换训练了多种环境。2. 我们在GPU和真实量子硬件上评估了我们的模型。3. 我们使用一组广泛的指标评估我们的生成模型的泛化能力，例如生成数据的新鲜度和有效性。
</details></li>
</ul>
<hr>
<h2 id="Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients"><a href="#Federated-Zeroth-Order-Optimization-using-Trajectory-Informed-Surrogate-Gradients" class="headerlink" title="Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients"></a>Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04077">http://arxiv.org/abs/2308.04077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Shu, Xiaoqiang Lin, Zhongxiang Dai, Bryan Kian Hsiang Low</li>
<li>for: 该文章的目的是提出一种基于追踪信息的 federated zeroth-order optimization（FZoo）算法，以提高 Query 和通信效率。</li>
<li>methods: 该算法使用追踪信息来估计函数梯度，并通过自适应梯度修正来减少实际更新与globally更新之间的差异。</li>
<li>results: 实验表明，该算法在 federated black-box adversarial attack 和 federated non-differentiable metric optimization 等实际应用中具有理论上的改进和实际效果。<details>
<summary>Abstract</summary>
Federated optimization, an emerging paradigm which finds wide real-world applications such as federated learning, enables multiple clients (e.g., edge devices) to collaboratively optimize a global function. The clients do not share their local datasets and typically only share their local gradients. However, the gradient information is not available in many applications of federated optimization, which hence gives rise to the paradigm of federated zeroth-order optimization (ZOO). Existing federated ZOO algorithms suffer from the limitations of query and communication inefficiency, which can be attributed to (a) their reliance on a substantial number of function queries for gradient estimation and (b) the significant disparity between their realized local updates and the intended global updates. To this end, we (a) introduce trajectory-informed gradient surrogates which is able to use the history of function queries during optimization for accurate and query-efficient gradient estimation, and (b) develop the technique of adaptive gradient correction using these gradient surrogates to mitigate the aforementioned disparity. Based on these, we propose the federated zeroth-order optimization using trajectory-informed surrogate gradients (FZooS) algorithm for query- and communication-efficient federated ZOO. Our FZooS achieves theoretical improvements over the existing approaches, which is supported by our real-world experiments such as federated black-box adversarial attack and federated non-differentiable metric optimization.
</details>
<details>
<summary>摘要</summary>
联合优化，是一种emerging paradigm，可以应用于联合学习、联合优化等实际应用中。在这种模型中，多个客户端（例如边缘设备）可以共同优化一个全球函数。客户端不会分享本地数据，通常只会分享本地梯度。然而，在许多应用中，梯度信息不可用，这导致了联合零次顺序优化（ZOO）的出现。现有的联合ZOO算法受到查询和通信不确定性的限制，这可以被归因于（a）它们依赖大量的函数查询来Estimate梯度，以及（b）它们实现的本地更新与globally intended的更新之间的差异。为解决这个问题，我们（a）引入了路径参数预测的梯度代理，可以在优化过程中使用历史的函数查询来精确地Estimate梯度，以及（b）开发了适应的梯度调整技术，以mitigate the aforementioned disparity。基于这些，我们提出了联合零次顺序优化使用路径参数预测梯度（FZooS）算法，实现了查询和通信效率的联合ZOO。我们的FZooS理论上超越了现有的方法，这被支持了我们的实际实验，例如联合黑盒抗攻击和联合非 differentiable 度量优化。
</details></li>
</ul>
<hr>
<h2 id="Learning-Specialized-Activation-Functions-for-Physics-informed-Neural-Networks"><a href="#Learning-Specialized-Activation-Functions-for-Physics-informed-Neural-Networks" class="headerlink" title="Learning Specialized Activation Functions for Physics-informed Neural Networks"></a>Learning Specialized Activation Functions for Physics-informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04073">http://arxiv.org/abs/2308.04073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leaplabthu/adaafforpinns">https://github.com/leaplabthu/adaafforpinns</a></li>
<li>paper_authors: Honghui Wang, Lu Lu, Shiji Song, Gao Huang</li>
<li>for: This paper aims to address the optimization difficulty of physics-informed neural networks (PINNs) by exploring the connection between PINNs and activation functions.</li>
<li>methods: The paper introduces adaptive activation functions to search for the optimal function when solving different problems, and compares different adaptive activation functions and their limitations in the context of PINNs.</li>
<li>results: The proposed adaptive activation function can be used to solve different PDE systems in an interpretable way, and its effectiveness is demonstrated on a series of benchmarks.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文的目的是解决physics-informed neural networks (PINNs) 中的优化困难，通过研究 PINNs 和活动函数之间的连接。</li>
<li>methods: 论文提出了 adaptive 活动函数，用于在不同问题上搜索优化的最佳函数，并对不同的 adaptive 活动函数进行比较和限制分析。</li>
<li>results: 提议的 adaptive 活动函数可以用于解决不同 PDE 系统，并且在可读性方面具有优势，效果在一系列 benchmark 上得到证明。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) are known to suffer from optimization difficulty. In this work, we reveal the connection between the optimization difficulty of PINNs and activation functions. Specifically, we show that PINNs exhibit high sensitivity to activation functions when solving PDEs with distinct properties. Existing works usually choose activation functions by inefficient trial-and-error. To avoid the inefficient manual selection and to alleviate the optimization difficulty of PINNs, we introduce adaptive activation functions to search for the optimal function when solving different problems. We compare different adaptive activation functions and discuss their limitations in the context of PINNs. Furthermore, we propose to tailor the idea of learning combinations of candidate activation functions to the PINNs optimization, which has a higher requirement for the smoothness and diversity on learned functions. This is achieved by removing activation functions which cannot provide higher-order derivatives from the candidate set and incorporating elementary functions with different properties according to our prior knowledge about the PDE at hand. We further enhance the search space with adaptive slopes. The proposed adaptive activation function can be used to solve different PDE systems in an interpretable way. Its effectiveness is demonstrated on a series of benchmarks. Code is available at https://github.com/LeapLabTHU/AdaAFforPINNs.
</details>
<details>
<summary>摘要</summary>
物理学 informed neural networks (PINNs)  oftentimes 受到优化困难。在这种工作中，我们揭示了 PINNs 的优化困难与 activation functions 之间的关系。具体来说，我们发现 PINNs 解决不同的 PDE 问题时会具有高度敏感性于 activation functions。现有的工作通常通过不efficient trial-and-error 来选择 activation functions。为了避免不efficient manual selection 和 PINNs 的优化困难，我们引入了适应 activation functions，以搜索解决不同问题的优化函数。我们比较了不同的适应 activation functions，并讨论它们在 PINNs 中的局限性。此外，我们提议在 PINNs 优化中应用学习组合 candidate activation functions 的思想，以提高学习得到的函数的平滑性和多样性。这可以通过从候选集中除掉无法提供高阶导数的 activation functions，并将不同性质的 elementary functions 纳入候选集中来实现。我们还增加了 adaptive slopes，以进一步扩大搜索空间。我们的提议的适应 activation function 可以在可读性方面解决不同 PDE 系统。我们在一系列 benchmark 上证明了其效iveness。代码可以在 GitHub 上找到：https://github.com/LeapLabTHU/AdaAFforPINNs。
</details></li>
</ul>
<hr>
<h2 id="Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation"><a href="#Path-Signatures-for-Diversity-in-Probabilistic-Trajectory-Optimisation" class="headerlink" title="Path Signatures for Diversity in Probabilistic Trajectory Optimisation"></a>Path Signatures for Diversity in Probabilistic Trajectory Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04071">http://arxiv.org/abs/2308.04071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas Barcelos, Tin Lai, Rafael Oliveira, Paulo Borges, Fabio Ramos</li>
<li>for: 这篇论文是为了提出一种基于粗路理论的并行轨迹优化算法，以避免模式塌生和提高全球性。</li>
<li>methods: 该算法使用了粗路理论的路径签名和希尔伯特空间表示法，并将并行变ational推断与多样性推广核心相连接。</li>
<li>results: 经验表明，该策略可以在各种问题上实现更低的平均成本，从2D导航到受擦层环境中的机器人抓取器。<details>
<summary>Abstract</summary>
Motion planning can be cast as a trajectory optimisation problem where a cost is minimised as a function of the trajectory being generated. In complex environments with several obstacles and complicated geometry, this optimisation problem is usually difficult to solve and prone to local minima. However, recent advancements in computing hardware allow for parallel trajectory optimisation where multiple solutions are obtained simultaneously, each initialised from a different starting point. Unfortunately, without a strategy preventing two solutions to collapse on each other, naive parallel optimisation can suffer from mode collapse diminishing the efficiency of the approach and the likelihood of finding a global solution. In this paper we leverage on recent advances in the theory of rough paths to devise an algorithm for parallel trajectory optimisation that promotes diversity over the range of solutions, therefore avoiding mode collapses and achieving better global properties. Our approach builds on path signatures and Hilbert space representations of trajectories, and connects parallel variational inference for trajectory estimation with diversity promoting kernels. We empirically demonstrate that this strategy achieves lower average costs than competing alternatives on a range of problems, from 2D navigation to robotic manipulators operating in cluttered environments.
</details>
<details>
<summary>摘要</summary>
运动规划可以被视为一个轨迹优化问题，其中一个目标是将轨迹优化为最小化成本函数。在复杂的环境中，拥有多个障碍物和复杂的几何结构时，这个优化问题通常具有困难和极杂的本地最优解。然而，当前的计算硬件技术使得可以并行进行轨迹优化，从不同的起始点初始化多个解决方案。然而，如果没有避免两个解决方案相互冲突的策略，直观的并行优化可能会降低效率和找到全局解的可能性。在这篇论文中，我们利用了最近的粗 PATH 理论来设计一种避免模式崩溃的并行轨迹优化算法，该算法会Promote 多样性在解决方案的范围内，从而避免模式崩溃并实现更好的全局性。我们的方法基于轨迹签名和希尔伯特空间表示法，并将并行变分推理与多样性激活器相连接。我们在各种问题上进行了实验，并证明了这种策略可以在范围内实现更低的平均成本。
</details></li>
</ul>
<hr>
<h2 id="ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data"><a href="#ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data" class="headerlink" title="ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data"></a>ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04070">http://arxiv.org/abs/2308.04070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvidia/nvflare">https://github.com/nvidia/nvflare</a></li>
<li>paper_authors: Pochuan Wang, Chen Shen, Weichung Wang, Masahiro Oda, Chiou-Shann Fuh, Kensaku Mori, Holger R. Roth</li>
<li>For: 提出了一种总结多个器官和疾病的整体分割模型，使用联合学习（FL）技术，并且解决了基本缺乏完全标注数据的问题。* Methods:  combining FL with knowledge distillation，使得本地模型可以从全球模型中提取未标注器官和肿瘤的知识，并且使用适当的条件概率表示来做这一点。* Results: 对四个不同的部分标注的腹部CT数据集进行验证，并证明了该方法与FedAvg和FedOpt基elines相比，具有显著的提高。此外，对外部测试数据集的性能也表明了模型在不同数据集上进行集成训练后的优异普适性。<details>
<summary>Abstract</summary>
Developing a generalized segmentation model capable of simultaneously delineating multiple organs and diseases is highly desirable. Federated learning (FL) is a key technology enabling the collaborative development of a model without exchanging training data. However, the limited access to fully annotated training data poses a major challenge to training generalizable models. We propose "ConDistFL", a framework to solve this problem by combining FL with knowledge distillation. Local models can extract the knowledge of unlabeled organs and tumors from partially annotated data from the global model with an adequately designed conditional probability representation. We validate our framework on four distinct partially annotated abdominal CT datasets from the MSD and KiTS19 challenges. The experimental results show that the proposed framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the performance on an external test dataset demonstrates superior generalizability compared to models trained on each dataset separately. Our ablation study suggests that ConDistFL can perform well without frequent aggregation, reducing the communication cost of FL. Our implementation will be available at https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.
</details>
<details>
<summary>摘要</summary>
发展一种可同时分割多个器官和疾病的通用模型是非常有优点的。联邦学习（FL）是一种关键技术，它允许合作建立模型，而不需要交换训练数据。然而，有限的完全标注数据对训练通用模型 pose 一个主要挑战。我们提出了 "ConDistFL" 框架，它将 FL 与知识塑造相结合，以解决这个问题。本地模型可以从全球模型中提取未标注器官和肿瘤的知识，使用适当设计的conditional probability表示。我们在四个不同的 partially annotated 腹部 CT 数据集上验证了我们的框架。实验结果表明，我们的框架在 FedAvg 和 FedOpt 基elines 上显著超越了。此外，对于外部测试集的性能表明，我们的模型具有较高的普适性，比单独在每个数据集上训练的模型要好。我们的剖析研究表明，ConDistFL 可以在不经常的聚合情况下表现良好，降低了联邦学习中的通信成本。我们的实现将在 GitHub 上提供，请参考 <https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl>。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation"><a href="#Enhancing-Adversarial-Robustness-in-Low-Label-Regime-via-Adaptively-Weighted-Regularization-and-Knowledge-Distillation" class="headerlink" title="Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation"></a>Enhancing Adversarial Robustness in Low-Label Regime via Adaptively Weighted Regularization and Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04061">http://arxiv.org/abs/2308.04061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Insung Kong, Yongdai Kim</li>
<li>For: This paper focuses on semi-supervised adversarial training, where labeled data is scarce.* Methods: The authors derive two upper bounds for the robust risk and propose a regularization term for unlabeled data. They also develop a semi-supervised adversarial training algorithm that combines the proposed regularization term with knowledge distillation using a semi-supervised teacher.* Results: The authors achieve state-of-the-art performance with significant margins compared to existing algorithms. Specifically, their algorithm with only 8% labeled data is comparable to supervised adversarial training algorithms that use all labeled data in terms of standard and robust accuracies on CIFAR-10.Here’s the Chinese translation of the three key points:* For: 这篇论文专注于半指导式对抗训练，即标注数据匮乏的情况。* Methods: 作者提出了两个Upper bound，并提出了一个用于未标注数据的正则化项。他们还开发了一种半指导式对抗训练算法，该算法结合了提出的正则化项和知识塑造。* Results: 作者实现了现有算法的最佳性能，具体来说，他们的算法只使用8%的标注数据，仍能与全量标注数据使用的超级vised adversarial training算法相当，即在CIFAR-10上的标准准确率和对抗性准确率。<details>
<summary>Abstract</summary>
Adversarial robustness is a research area that has recently received a lot of attention in the quest for trustworthy artificial intelligence. However, recent works on adversarial robustness have focused on supervised learning where it is assumed that labeled data is plentiful. In this paper, we investigate semi-supervised adversarial training where labeled data is scarce. We derive two upper bounds for the robust risk and propose a regularization term for unlabeled data motivated by these two upper bounds. Then, we develop a semi-supervised adversarial training algorithm that combines the proposed regularization term with knowledge distillation using a semi-supervised teacher (i.e., a teacher model trained using a semi-supervised learning algorithm). Our experiments show that our proposed algorithm achieves state-of-the-art performance with significant margins compared to existing algorithms. In particular, compared to supervised learning algorithms, performance of our proposed algorithm is not much worse even when the amount of labeled data is very small. For example, our algorithm with only 8\% labeled data is comparable to supervised adversarial training algorithms that use all labeled data, both in terms of standard and robust accuracies on CIFAR-10.
</details>
<details>
<summary>摘要</summary>
“敌对响应性”是人工智能的研究领域，最近受到了很多关注，以建立可靠的人工智能。然而，现有的工作假设了充足的标签数据，并且专注于监督学习。在本文中，我们研究 semi-supervised adversarial 训练，其中标签数据稀缺。我们 derive two upper bounds for the robust risk，并提出一个鼓励不标签数据的调整项。然后，我们开发了一个 semi-supervised adversarial 训练算法，它结合了提案的调整项和知识传授使用 semi-supervised teacher (即使用 semi-supervised 学习算法训练的教师模型)。我们的实验结果显示，我们的提案算法可以实现现在的最佳性能，并且与已有的算法相比，仅在标签数据非常少时，性能与监督学习算法相似。例如，我们的算法仅使用 8% 的标签数据时，与监督学习算法使用所有标签数据相比，在 CIFAR-10 上的标准和敌对精度都具有显著的优化。”
</details></li>
</ul>
<hr>
<h2 id="Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers"><a href="#Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers" class="headerlink" title="Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"></a>Backdoor Federated Learning by Poisoning Backdoor-Critical Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04466">http://arxiv.org/abs/2308.04466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan</li>
<li>for: 这 paper 旨在探讨 federated learning (FL) 中存在攻击敏感数据的差点，并提出了一种基于攻击者视角的增强型隐蔽攻击方法。</li>
<li>methods: 该 paper 使用了一种涉及攻击者视角的方法来识别 federated learning (FL) 模型中的敏感层次，然后通过适应性地进行攻击来寻找适合的攻击方法。</li>
<li>results: 实验结果表明，该 paper 提出的 BC 层攻击方法可以在七种 state-of-the-art (SOTA) 防御策略下成功地攻击 federated learning (FL)，且比较新的攻击方法更高效。<details>
<summary>Abstract</summary>
Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that our BC layer-aware backdoor attacks can successfully backdoor FL under seven SOTA defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）已经广泛应用以进行分散设备上的机器学习训练。然而，分散式学习模式和资料多样性对FL的攻击面积增加了额外的隐藏问题。现有的FL攻击和防御方法通常集中在整个模型上。 none of them 认为存在关键层（BC）-一小subset of layers that dominate the model vulnerabilities. 攻击BC层可以实现equivalent 的效果，但是比攻击整个模型要小得多，这使得现有的防御技术更难察觉。 This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. 实验表明，我们的BC层意识的后门攻击可以成功地在七种SOTA防御措施下进行后门攻击，并且比latest backdoor attack methods 高效。
</details></li>
</ul>
<hr>
<h2 id="Toward-Improving-Predictive-Risk-Modelling-for-New-Zealand’s-Child-Welfare-System-Using-Clustering-Methods"><a href="#Toward-Improving-Predictive-Risk-Modelling-for-New-Zealand’s-Child-Welfare-System-Using-Clustering-Methods" class="headerlink" title="Toward Improving Predictive Risk Modelling for New Zealand’s Child Welfare System Using Clustering Methods"></a>Toward Improving Predictive Risk Modelling for New Zealand’s Child Welfare System Using Clustering Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04060">http://arxiv.org/abs/2308.04060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahar Barmomanesh, Victor Miranda-Soberanis</li>
<li>for: 这个研究旨在帮助社工人员更好地识别儿童滋扰的风险因素，并决定当局是否应对儿童进行介入。</li>
<li>methods: 这个研究使用了主成因分析和K-Means clustering方法来识别儿童的风险因素，并分析这些因素之间的互动关系。</li>
<li>results: 研究发现，使用不同的 clustering 方法可以分辨出不同的儿童群体，并且这些群体之间存在一定的区别。此外，研究发现，使用特定的年龄组别的模型可以提高模型的准确性。<details>
<summary>Abstract</summary>
The combination of clinical judgement and predictive risk models crucially assist social workers to segregate children at risk of maltreatment and decide when authorities should intervene. Predictive risk modelling to address this matter has been initiated by several governmental welfare authorities worldwide involving administrative data and machine learning algorithms. While previous studies have investigated risk factors relating to child maltreatment, several gaps remain as to understanding how such risk factors interact and whether predictive risk models perform differently for children with different features. By integrating Principal Component Analysis and K-Means clustering, this paper presents initial findings of our work on the identification of such features as well as their potential effect on current risk modelling frameworks. This approach allows examining existent, unidentified yet, clusters of New Zealand (NZ) children reported with care and protection concerns, as well as to analyse their inner structure, and evaluate the performance of prediction models trained cluster wise. We aim to discover the extent of clustering degree required as an early step in the development of predictive risk models for child maltreatment and so enhance the accuracy of such models intended for use by child protection authorities. The results from testing LASSO logistic regression models trained on identified clusters revealed no significant difference in their performance. The models, however, performed slightly better for two clusters including younger children. our results suggest that separate models might need to be developed for children of certain age to gain additional control over the error rates and to improve model accuracy. While results are promising, more evidence is needed to draw definitive conclusions, and further investigation is necessary.
</details>
<details>
<summary>摘要</summary>
临床判断和预测风险模型可以帮助社工分类受护儿童投入风险和决定当局是否介入。预测风险模型在世界各地政府儿童护理机构中已经被开发，使用行政数据和机器学习算法。 although previous studies have investigated child maltreatment risk factors, there are still gaps in understanding how these risk factors interact and whether predictive risk models perform differently for children with different features. 本文使用主成分分析和K-Means聚类分析初步发现了这些特征，以及它们可能对当前风险模型 frameworks 有何影响。这种方法允许我们检查新西兰（NZ）儿童报告了护理和保护问题的现有、未知的群集，以及其内部结构，并评估这些群集训练的预测模型性能。我们的目标是发现预测模型是否需要不同的年龄层分配，以提高预测模型的准确性。我们的结果表明，使用LASSO logistic regression模型训练于特定群集没有显著差异。然而，这些模型在两个年龄较少的群集中表现稍微更好。这些结果表明，可能需要为不同的年龄层开发不同的模型，以提高预测模型的准确性。虽然结果有前途，但需要更多的证据来 draw definitive conclusions，并进一步进行调查。
</details></li>
</ul>
<hr>
<h2 id="The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings"><a href="#The-Five-Dollar-Model-Generating-Game-Maps-and-Sprites-from-Sentence-Embeddings" class="headerlink" title="The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings"></a>The Five-Dollar Model: Generating Game Maps and Sprites from Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04052">http://arxiv.org/abs/2308.04052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TimMerino1710/five-dollar-model">https://github.com/TimMerino1710/five-dollar-model</a></li>
<li>paper_authors: Timothy Merino, Roman Negri, Dipika Rajesh, M Charity, Julian Togelius</li>
<li>for: 这个论文旨在提出一种轻量级的文本到图像生成模型，能够从编码的文本提示生成低维度图像。</li>
<li>methods: 这个模型使用了一些新的扩展策略，以提高模型在有限的数据集上的性能。</li>
<li>results: 模型能够生成高度准确和美观的图像，同时保持文本提示中的含义。<details>
<summary>Abstract</summary>
The five-dollar model is a lightweight text-to-image generative architecture that generates low dimensional images from an encoded text prompt. This model can successfully generate accurate and aesthetically pleasing content in low dimensional domains, with limited amounts of training data. Despite the small size of both the model and datasets, the generated images are still able to maintain the encoded semantic meaning of the textual prompt. We apply this model to three small datasets: pixel art video game maps, video game sprite images, and down-scaled emoji images and apply novel augmentation strategies to improve the performance of our model on these limited datasets. We evaluate our models performance using cosine similarity score between text-image pairs generated by the CLIP VIT-B/32 model.
</details>
<details>
<summary>摘要</summary>
“五块模型”是一种轻量级文本到图像生成架构，可以从编码的文本提示生成低维度图像。这种模型可以在有限的培训数据下生成准确和美观的内容，并且保持文本提示中的含义。我们将这种模型应用于三个小 datasets：像素艺术视频游戏地图、视频游戏填充图像和压缩emoji图像。我们还使用了新的扩展策略来提高我们模型的性能。我们使用 cosine similarity 分数来评估我们模型对文本-图像对的表现。
</details></li>
</ul>
<hr>
<h2 id="Generative-Models-for-Anomaly-Detection-and-Design-Space-Dimensionality-Reduction-in-Shape-Optimization"><a href="#Generative-Models-for-Anomaly-Detection-and-Design-Space-Dimensionality-Reduction-in-Shape-Optimization" class="headerlink" title="Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization"></a>Generative Models for Anomaly Detection and Design-Space Dimensionality Reduction in Shape Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04051">http://arxiv.org/abs/2308.04051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danny D’Agostino</li>
<li>for: 提高全球优化算法的效率，同时促进优化过程中高质量的设计生成。</li>
<li>methods: 减少设计变量数量，最大化几何变量的差异，使用概率线性隐藏变量模型，如因素分析和概率主成分分析。</li>
<li>results: 提高全球优化算法的收敛性，仅生成高质量几何特征的设计，避免 computationally expensive 优化过程中的浪费。<details>
<summary>Abstract</summary>
Our work presents a novel approach to shape optimization, that has the twofold objective to improve the efficiency of global optimization algorithms while promoting the generation of high-quality designs during the optimization process free of geometrical anomalies. This is accomplished by reducing the number of the original design variables defining a new reduced subspace where the geometrical variance is maximized and modeling the underlying generative process of the data via probabilistic linear latent variable models such as Factor Analysis and Probabilistic Principal Component Analysis. We show that the data follows approximately a Gaussian distribution when the shape modification method is linear and the design variables are sampled uniformly at random, due to the direct application of the central limit theorem. The model uncertainty is measured in terms of Mahalanobis distance, and the paper demonstrates that anomalous designs tend to exhibit a high value of this metric. This enables the definition of a new optimization model where anomalous geometries are penalized and consequently avoided during the optimization loop. The procedure is demonstrated for hull shape optimization of the DTMB 5415 model, extensively used as an international benchmark for shape optimization problems. The global optimization routine is carried out using Bayesian Optimization and the DIRECT algorithm. From the numerical results, the new framework improves the convergence of global optimization algorithms, while only designs with high-quality geometrical features are generated through the optimization routine thereby avoiding the wastage of precious computationally expensive simulations.
</details>
<details>
<summary>摘要</summary>
我们的工作提出了一种新的方法 для优化形状，以提高全球优化算法的效率，同时推出高质量的设计。这是通过减少原始设计变量，定义一个新的减少子空间，使几何异常值最大化，并使用抽象线性latent variable模型，如因素分析和概率主成分分析，来模型数据的生成过程。我们证明数据遵循近似 Gaussian 分布，当shape modification方法是线性的，并且设计变量随机 sampling 时，通过直接应用中心偏移定理。模型不确定性被测量为 Mahalanobis 距离，并且实验表明，异常设计通常具有高值这个指标。这允许定义一个新的优化模型，惩罚异常几何，并在优化迭代中避免异常设计的生成。我们在 DTMB 5415 模型的船体形状优化中进行了实验，使用 Bayesian 优化和 DIRECT 算法。从numerical 结果来看，新的框架可以提高全球优化算法的收敛，同时只有高质量的几何特征被优化算法生成，从而避免了计算成本expensive的simulation 的浪费。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset"><a href="#A-Comparative-Study-on-TF-IDF-feature-Weighting-Method-and-its-Analysis-using-Unstructured-Dataset" class="headerlink" title="A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset"></a>A Comparative Study on TF-IDF feature Weighting Method and its Analysis using Unstructured Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04037">http://arxiv.org/abs/2308.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse</li>
<li>for: 这篇论文的目的是研究文本分类中feature重要性的问题，以及使用TF-IDF和NLP算法进行文本分类。</li>
<li>methods: 这篇论文使用了IMDB电影评论和Amazon Alexa评论数据集进行实验，并使用了多种常见的分类算法来验证提出的方法，包括支持向量机（SVM）、抽象函数（Logistic Regression）、多项随机树（Random Forest）、决策树（Decision Tree）和k-最近邻居（KNN）。</li>
<li>results: 研究发现，基于TF-IDF特征提取方法可以获得最高的准确率（93.81%）、精度（94.20%）、回归率（93.81%）和F1分数（91.99%）值，而基于N-Gram特征提取方法则不如TF-IDF方法。<details>
<summary>Abstract</summary>
Text Classification is the process of categorizing text into the relevant categories and its algorithms are at the core of many Natural Language Processing (NLP). Term Frequency-Inverse Document Frequency (TF-IDF) and NLP are the most highly used information retrieval methods in text classification. We have investigated and analyzed the feature weighting method for text classification on unstructured data. The proposed model considered two features N-Grams and TF-IDF on the IMDB movie reviews and Amazon Alexa reviews dataset for sentiment analysis. Then we have used the state-of-the-art classifier to validate the method i.e., Support Vector Machine (SVM), Logistic Regression, Multinomial Naive Bayes (Multinomial NB), Random Forest, Decision Tree, and k-nearest neighbors (KNN). From those two feature extractions, a significant increase in feature extraction with TF-IDF features rather than based on N-Gram. TF-IDF got the maximum accuracy (93.81%), precision (94.20%), recall (93.81%), and F1-score (91.99%) value in Random Forest classifier.
</details>
<details>
<summary>摘要</summary>
文本分类是将文本分类到相关的类别中的过程，其算法是自然语言处理（NLP）的核心。文本频率-反向文档频率（TF-IDF）和NLP是文本检索中最广泛使用的方法。我们已经对文本分类中的特征赋值方法进行了调查和分析。我们提出了基于IMDB电影评论和Amazon Alexa评论数据集的 sentiment analysis 的方法，并使用了当今最佳的分类器来验证方法，即支持向量机（SVM）、概率回归、多项随机森林（Multinomial NB）、随机树、决策树和k-最近邻居（KNN）。从两个特征提取来看，TF-IDF特征的特征提取得到了显著的增加，而不是基于N- Gram。TF-IDF在Random Forest分类器中获得了最大的准确率（93.81%）、精度（94.20%）、回归率（93.81%）和F1分数（91.99%)值。
</details></li>
</ul>
<hr>
<h2 id="Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering"><a href="#Top-K-Relevant-Passage-Retrieval-for-Biomedical-Question-Answering" class="headerlink" title="Top K Relevant Passage Retrieval for Biomedical Question Answering"></a>Top K Relevant Passage Retrieval for Biomedical Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04028">http://arxiv.org/abs/2308.04028</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shashank140195/Biomedical_QA_Model">https://github.com/shashank140195/Biomedical_QA_Model</a></li>
<li>paper_authors: Shashank Gupta<br>for:本研究旨在开发一个基于Pubmed文章的生物医学问答系统，以提供准确的答案。methods:本研究使用现有的DPR框架，并在其基础上进行了细致的调整和训练，以提高问答系统的准确率。results:在 BioASQ 问答集上进行评估，我们的调整后的紧密检索器得分为0.81，表明我们的方法可以提供高度准确的答案。<details>
<summary>Abstract</summary>
Question answering is a task that answers factoid questions using a large collection of documents. It aims to provide precise answers in response to the user's questions in natural language. Question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. On the web, there is no single article that could provide all the possible answers available on the internet to the question of the problem asked by the user. The existing Dense Passage Retrieval model has been trained on Wikipedia dump from Dec. 20, 2018, as the source documents for answering questions. Question answering (QA) has made big strides with several open-domain and machine comprehension systems built using large-scale annotated datasets. However, in the clinical domain, this problem remains relatively unexplored. According to multiple surveys, Biomedical Questions cannot be answered correctly from Wikipedia Articles. In this work, we work on the existing DPR framework for the biomedical domain and retrieve answers from the Pubmed articles which is a reliable source to answer medical questions. When evaluated on a BioASQ QA dataset, our fine-tuned dense retriever results in a 0.81 F1 score.
</details>
<details>
<summary>摘要</summary>
问答任务是用一个大量文档集来回答用户的问题。其目标是通过自然语言提供精准的答案。问答需要高效的段落检索，以选择可能的上下文，传统上使用TF-IDF或BM25等稀疏 вектор空间模型。在互联网上，没有一篇文章可以提供用户问题的所有可能的答案。我们使用Dec. 20, 2018年的Wikipedia备份作为问答模型的训练数据源。问答（QA）在开放领域和机器理解领域已经做出了很大的进步，但在医疗领域这个问题还很少研究。根据多个调查，医学问题不能准确地从Wikipedia文章中得到答案。在这种情况下，我们对现有的DPR框架进行了修改，并从Pubmed文章中检索答案。当评估在BioASQ QA数据集上时，我们的精度检索器得到了0.81的F1分数。
</details></li>
</ul>
<hr>
<h2 id="Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration"><a href="#Scope-Loss-for-Imbalanced-Classification-and-RL-Exploration" class="headerlink" title="Scope Loss for Imbalanced Classification and RL Exploration"></a>Scope Loss for Imbalanced Classification and RL Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04024">http://arxiv.org/abs/2308.04024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hasham Burhani, Xiao Qi Shi, Jonathan Jaegerman, Daniel Balicki</li>
<li>for: 本研究目的是Equivalence between reinforcement learning problem和Supervised classification problem，并找到它们之间的相似性。</li>
<li>methods: 本研究使用了探索尝试和优化问题的探索-优化补偿来Address the exploration exploitation trade-off in reinforcement learning and the dataset imbalance problem in supervised classification。</li>
<li>results: 研究发现了一种新的损失函数Scope Loss，可以防止过度利用和数据偏好导致的性能下降，无需进行任何调整。Scope Loss在一系列基准功能回归学任务和一个偏好分类 dataset 上测试，与State-of-the-art损失函数相比，Scope Loss表现出色。<details>
<summary>Abstract</summary>
We demonstrate equivalence between the reinforcement learning problem and the supervised classification problem. We consequently equate the exploration exploitation trade-off in reinforcement learning to the dataset imbalance problem in supervised classification, and find similarities in how they are addressed. From our analysis of the aforementioned problems we derive a novel loss function for reinforcement learning and supervised classification. Scope Loss, our new loss function, adjusts gradients to prevent performance losses from over-exploitation and dataset imbalances, without the need for any tuning. We test Scope Loss against SOTA loss functions over a basket of benchmark reinforcement learning tasks and a skewed classification dataset, and show that Scope Loss outperforms other loss functions.
</details>
<details>
<summary>摘要</summary>
我们展示了强化学习问题和超级vised分类问题之间的等值性。我们遂视探索优化和数据集不均势问题在强化学习和超级vised分类中的相似性，并从这些问题的分析中获得了一个新的损失函数。我们称之为Scope Loss。Scope Loss可以调整 gradients，以避免因过度探索而导致的性能损失和数据集不均势问题，不需要任何调整。我们将Scope Loss与现有的损失函数进行比较，在一签 benchmark 强化学习任务和一个偏斜的分类dataset上进行测试，结果显示Scope Loss可以超越其他损失函数。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks"><a href="#Improving-Performance-of-Semi-Supervised-Learning-by-Adversarial-Attacks" class="headerlink" title="Improving Performance of Semi-Supervised Learning by Adversarial Attacks"></a>Improving Performance of Semi-Supervised Learning by Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04018">http://arxiv.org/abs/2308.04018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyoon Yang, Kunwoong Kim, Yongdai Kim</li>
<li>for: 提高latest SSL算法的表现，使其更适应 semi-supervised learning 的应用场景。</li>
<li>methods: 提出了一种通用框架SCAR，通过对预训练模型进行 adversarial 攻击，选择高自信仪器的无标样本进行标注。</li>
<li>results: 在 CIFAR10 上，与 SCAR 结合的三种 latest SSL 算法显示出了显著提高图像分类的表现。<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) algorithm is a setup built upon a realistic assumption that access to a large amount of labeled data is tough. In this study, we present a generalized framework, named SCAR, standing for Selecting Clean samples with Adversarial Robustness, for improving the performance of recent SSL algorithms. By adversarially attacking pre-trained models with semi-supervision, our framework shows substantial advances in classifying images. We introduce how adversarial attacks successfully select high-confident unlabeled data to be labeled with current predictions. On CIFAR10, three recent SSL algorithms with SCAR result in significantly improved image classification.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>半有指导学习（SSL）算法是基于现实的假设，即获得大量标注数据困难。在这个研究中，我们提出一种通用框架，名为SCAR，即选择清洁样本并具有对抗鲁棒性。通过对预训练模型进行对抗攻击，我们的框架实现了显著提高图像分类性能。我们介绍了如何使用对抗攻击选择高信度无标记数据，并将当前预测作为标注。在CIFAR10上，三种最近的SSL算法与SCAR结果显著提高图像分类。
</details></li>
</ul>
<hr>
<h2 id="Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model"><a href="#Continual-Pre-Training-of-Large-Language-Models-How-to-re-warm-your-model" class="headerlink" title="Continual Pre-Training of Large Language Models: How to (re)warm your model?"></a>Continual Pre-Training of Large Language Models: How to (re)warm your model?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04014">http://arxiv.org/abs/2308.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kshitij Gupta, Benjamin Thérien, Adam Ibrahim, Mats L. Richter, Quentin Anthony, Eugene Belilovsky, Irina Rish, Timothée Lesort</li>
<li>for: 这研究旨在提高大型语言模型（LLMs）的效率和成本，通过不断更新已经预训练的模型而不是从scratch重新训练。</li>
<li>methods: 研究者采用了不同的温存策略来检查学习率的影响，包括线性温存和偏微分衰减。</li>
<li>results: 研究结果表明，在继续预训练时，模型的整体性能会逐渐提高，即使在大量下游数据集上。此外，在不同的预训练点和最大学习率下，模型的性能也有显著的不同。<details>
<summary>Abstract</summary>
Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and evaluate performance through validation perplexity. We experiment with different pre-training checkpoints, various maximum learning rates, and various warmup lengths. Our results show that while rewarming models first increases the loss on upstream and downstream data, in the longer run it improves the downstream performance, outperforming models trained from scratch$\unicode{x2013}$even for a large downstream dataset.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）通常在数十亿个字符上进行预训练，然后又重新开始预训练。一种更经济高效的解决方案是让这些模型在新数据上进行连续预训练，而不是从scratch重新训练。然而，新数据引入的分布变化通常会导致过去数据的性能下降。为了实现效率的连续预训练，在这项工作中，我们研究了不同的温存策略。我们的假设是，在训练新数据集时，学习率必须重新增加以提高计算效率。我们研究在Pile（上游数据，300亿个字符）预训练后，在SlimPajama（下游数据，297亿个字符）上继续预训练，采用线性温存和cosine衰减时间表。我们在Pythia 410M语言模型架构上进行所有实验，并通过验证plexity来评估性能。我们对不同的预训练检查点、最大学习率和温存长度进行了尝试。我们的结果表明，虽然在重新暖化模型后，初期loss会增加在上游和下游数据上，但在长期来看，它会提高下游性能，超过从scratch训练的模型，即使是大型下游数据集。
</details></li>
</ul>
<hr>
<h2 id="Generalization-bound-for-estimating-causal-effects-from-observational-network-data"><a href="#Generalization-bound-for-estimating-causal-effects-from-observational-network-data" class="headerlink" title="Generalization bound for estimating causal effects from observational network data"></a>Generalization bound for estimating causal effects from observational network data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04011">http://arxiv.org/abs/2308.04011</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruichu Cai, Zeqin Yang, Weilin Chen, Yuguang Yan, Zhifeng Hao</li>
<li>for: 这篇论文是为了估计来自观察网络数据的 causal effect 的。</li>
<li>methods: 论文使用了重量学习和 representation learning 两种方法来估计 causal effect。</li>
<li>results: 实验研究表明，这种方法可以有效地估计 causal effect，并且可以提供一个理论上的支持来减少复杂的干扰偏见。<details>
<summary>Abstract</summary>
Estimating causal effects from observational network data is a significant but challenging problem. Existing works in causal inference for observational network data lack an analysis of the generalization bound, which can theoretically provide support for alleviating the complex confounding bias and practically guide the design of learning objectives in a principled manner. To fill this gap, we derive a generalization bound for causal effect estimation in network scenarios by exploiting 1) the reweighting schema based on joint propensity score and 2) the representation learning schema based on Integral Probability Metric (IPM). We provide two perspectives on the generalization bound in terms of reweighting and representation learning, respectively. Motivated by the analysis of the bound, we propose a weighting regression method based on the joint propensity score augmented with representation learning. Extensive experimental studies on two real-world networks with semi-synthetic data demonstrate the effectiveness of our algorithm.
</details>
<details>
<summary>摘要</summary>
估计来自观察网络数据的 causal effect 是一个重要 yet 挑战性的问题。现有的 causal inference 在网络数据上lacks 一个分析 generalization bound，可以 theoretically 提供支持来减少复杂的混杂偏见和实践 guide 学习目标的原则性。为了填这个 gap，我们 derivate 一个 generalization bound  для causal effect estimation 在网络场景下，通过 exploiting 1) 重量 schema based on joint propensity score 和 2) representation learning schema based on Integral Probability Metric (IPM)。我们提供 two perspectives on the generalization bound in terms of reweighting and representation learning，分别。受 bound 分析的激励，我们提议一种基于 joint propensity score 和 representation learning的重量回归方法。经验性研究在 two real-world networks 上的 semi-synthetic data 表明了我们的算法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning"><a href="#Understanding-CNN-Hidden-Neuron-Activations-Using-Structured-Background-Knowledge-and-Deductive-Reasoning" class="headerlink" title="Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning"></a>Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03999">http://arxiv.org/abs/2308.03999</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii">https://github.com/abhilekha-dalal/xai-using-wikidataAndEcii</a></li>
<li>paper_authors: Abhilekha Dalal, Md Kamruzzaman Sarker, Adrita Barua, Eugene Vasserman, Pascal Hitzler</li>
<li>for: 本研究旨在解释深度学习系统中隐藏层神经元的活动，以提供深度学习系统内部探测输入的信息。</li>
<li>methods: 本研究使用了大规模背景知识（约200万个类）和基于描述逻辑的符号逻辑方法called Concept Induction，以自动附加隐藏层神经元的意义 labels。</li>
<li>results: 研究结果表明，我们可以通过一种假设和验证过程，自动将大规模背景知识中的意义labels附加到Convolutional Neural Network的 dense层神经元上。<details>
<summary>Abstract</summary>
A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, demystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Our results show that we can automatically attach meaningful labels from the background knowledge to individual neurons in the dense layer of a Convolutional Neural Network through a hypothesis and verification process.
</details>
<details>
<summary>摘要</summary>
一 Major challenge in Explainable AI 是正确地理解隐藏节点的活动：正确的解释可以提供关于深度学习系统内部检测到的输入的信息，从而干预深度学习系统的黑盒特性。现状的技术是，隐藏节点的活动可以在某些情况下被解释得通用人类理解，但系统化的自动方法来测试和验证解释是未经探索的。在这篇论文中，我们提供了一种方法，并证明其可以提供有意义的解释。我们的方法基于使用大规模背景知识（约200万个类别，来自wikipedia知识树），并使用基于描述逻辑的符号推理方法 called Concept Induction，原始是为Semantic Web领域开发的。我们的结果表明，我们可以通过一个假设和验证过程，将background知识中的有意义标签自动地应用于 dense层中的神经元。
</details></li>
</ul>
<hr>
<h2 id="Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks"><a href="#Cooperative-Multi-Type-Multi-Agent-Deep-Reinforcement-Learning-for-Resource-Management-in-Space-Air-Ground-Integrated-Networks" class="headerlink" title="Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks"></a>Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for Resource Management in Space-Air-Ground Integrated Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03995">http://arxiv.org/abs/2308.03995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengxi Zhang, Huaze Tang, Wenbo Ding, Xiao-Ping Zhang</li>
<li>for: 提高智能城市应用的潜在价值和可行性</li>
<li>methods: 提出了一种涵盖五个不同通信链的完整SAGIN系统，并提出了一种高效的合作多类多代理人深度学习（CMT-MARL）方法来解决资源管理问题</li>
<li>results: 实验结果表明，提议的CMT-MARL方法能够有效地解决资源管理问题，并且可以提高总传输率和传输成功率等关键性能指标。<details>
<summary>Abstract</summary>
The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous devices including low earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users (GUs), holds significant promise for advancing smart city applications. However, resource management of the SAGIN is a challenge requiring urgent study in that inappropriate resource management will cause poor data transmission, and hence affect the services in smart cities. In this paper, we develop a comprehensive SAGIN system that encompasses five distinct communication links and propose an efficient cooperative multi-type multi-agent deep reinforcement learning (CMT-MARL) method to address the resource management issue. The experimental results highlight the efficacy of the proposed CMT-MARL, as evidenced by key performance indicators such as the overall transmission rate and transmission success rate. These results underscore the potential value and feasibility of future implementation of the SAGIN.
</details>
<details>
<summary>摘要</summary>
SAGIN（空间-空气-地面集成网络），包括低地球轨道卫星（LEO）、无人飞行器（UAV）和地面用户（GU）多种设备，具有推进智能城市应用的潜力。然而，SAGIN资源管理却是一项需要优先研究的挑战，因为不当的资源管理会导致数据传输差，从而影响智能城市服务。本文提出了一个完整的SAGIN系统，包括五种不同的通信链，并提出了一种高效的合作多种多代理人深度学习（CMT-MARL）方法来解决资源管理问题。实验结果表明，提议的CMT-MARL方法能够有效地解决SAGIN资源管理问题，以示KEY表现指标（总传输率和传输成功率）。这些结果表明SAGIN的可能性和实现性。
</details></li>
</ul>
<hr>
<h2 id="Fourier-neural-operator-for-real-time-simulation-of-3D-dynamic-urban-microclimate"><a href="#Fourier-neural-operator-for-real-time-simulation-of-3D-dynamic-urban-microclimate" class="headerlink" title="Fourier neural operator for real-time simulation of 3D dynamic urban microclimate"></a>Fourier neural operator for real-time simulation of 3D dynamic urban microclimate</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03985">http://arxiv.org/abs/2308.03985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhui Peng, Shaoxiang Qin, Senwen Yang, Jianchun Wang, Xue Liu, Liangzhu, Wang</li>
<li>For: The paper aims to develop a real-time three-dimensional urban wind field simulation method using the Fourier Neural Operator (FNO) network to accelerate the modeling of complex non-linear interactions and system dynamics in urban microclimates.* Methods: The paper uses a combination of Computational Fluid Dynamics (CFD) simulation and the FNO network to model urban microclimates. The training and testing data are generated from CFD simulation of the urban area, based on the semi-Lagrangian approach and fractional stepping method.* Results: The paper shows that the FNO model can accurately reconstruct the instantaneous spatial velocity field and generalize well on different wind directions. The FNO approach can make predictions within milliseconds on the graphics processing unit, making real-time simulation of 3D dynamic urban microclimate possible.Here are the three points in Simplified Chinese:* For: 本研究旨在通过 Фурье神经网络（FNO）加速城市微气候模型化。* Methods: 本研究使用CFD计算和FNO网络模拟城市微气候。训练和测试数据来自CFD计算城市区域，基于半拉格朗日方法和分辨率步骤法。* Results: FNO模型可以准确重建三维城市风场速度场，并在不同风向下Generalize well。FNO方法可以在图形处理器上进行毫秒级准确预测，使城市微气候实时模拟变得可能。<details>
<summary>Abstract</summary>
Global urbanization has underscored the significance of urban microclimates for human comfort, health, and building/urban energy efficiency. They profoundly influence building design and urban planning as major environmental impacts. Understanding local microclimates is essential for cities to prepare for climate change and effectively implement resilience measures. However, analyzing urban microclimates requires considering a complex array of outdoor parameters within computational domains at the city scale over a longer period than indoors. As a result, numerical methods like Computational Fluid Dynamics (CFD) become computationally expensive when evaluating the impact of urban microclimates. The rise of deep learning techniques has opened new opportunities for accelerating the modeling of complex non-linear interactions and system dynamics. Recently, the Fourier Neural Operator (FNO) has been shown to be very promising in accelerating solving the Partial Differential Equations (PDEs) and modeling fluid dynamic systems. In this work, we apply the FNO network for real-time three-dimensional (3D) urban wind field simulation. The training and testing data are generated from CFD simulation of the urban area, based on the semi-Lagrangian approach and fractional stepping method to simulate urban microclimate features for modeling large-scale urban problems. Numerical experiments show that the FNO model can accurately reconstruct the instantaneous spatial velocity field. We further evaluate the trained FNO model on unseen data with different wind directions, and the results show that the FNO model can generalize well on different wind directions. More importantly, the FNO approach can make predictions within milliseconds on the graphics processing unit, making real-time simulation of 3D dynamic urban microclimate possible.
</details>
<details>
<summary>摘要</summary>
Recently, deep learning techniques have been applied to accelerate the modeling of complex non-linear interactions and system dynamics. One promising approach is the Fourier Neural Operator (FNO), which can accelerate the solution of Partial Differential Equations (PDEs) and model fluid dynamic systems.In this study, we use the FNO network for real-time three-dimensional (3D) urban wind field simulation. The training and testing data are generated from CFD simulations of the urban area, using the semi-Lagrangian approach and fractional stepping method to simulate urban microclimate features for modeling large-scale urban problems. Our numerical experiments show that the FNO model can accurately reconstruct the instantaneous spatial velocity field. We also evaluate the trained FNO model on unseen data with different wind directions, and the results show that the model can generalize well on different wind directions.More importantly, the FNO approach can make predictions within milliseconds on a graphics processing unit, making real-time simulation of 3D dynamic urban microclimate possible. This has significant implications for urban planning and design, as well as for the development of more energy-efficient and resilient cities.
</details></li>
</ul>
<hr>
<h2 id="Characterization-of-Human-Balance-through-a-Reinforcement-Learning-based-Muscle-Controller"><a href="#Characterization-of-Human-Balance-through-a-Reinforcement-Learning-based-Muscle-Controller" class="headerlink" title="Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller"></a>Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04462">http://arxiv.org/abs/2308.04462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kübra Akbaş, Carlotta Mummolo, Xianlian Zhou</li>
<li>for: This paper aims to explore the use of center of mass (COM) state space and reinforcement learning (RL) to monitor balance capabilities in humans, and to establish balance recovery limits.</li>
<li>methods: The paper employs a musculoskeletal model integrated with a balance controller, trained through RL, to investigate balancing capabilities. The RL framework includes two interconnected neural networks governing balance recovery and muscle coordination, trained using Proximal Policy Optimization (PPO) with reference state initialization, early termination, and multiple training strategies.</li>
<li>results: The paper obtains final balance recovery (BR) enclosing successful balance recovery trajectories by exploring recovery from random initial COM states (position and velocity) space for a trained controller. The BRs are compared with analytical postural stability limits from a linear inverted pendulum model, and the results show a similar trend in successful COM states but more limited ranges in the recoverable areas. The paper also investigates the effect of muscle weakness and neural excitation delay on the BRs, revealing reduced balancing capability in different regions.<details>
<summary>Abstract</summary>
Balance assessment during physical rehabilitation often relies on rubric-oriented battery tests to score a patient's physical capabilities, leading to subjectivity. While some objective balance assessments exist, they are often limited to tracking the center of pressure (COP), which does not fully capture the whole-body postural stability. This study explores the use of the center of mass (COM) state space and presents a promising avenue for monitoring the balance capabilities in humans. We employ a musculoskeletal model integrated with a balance controller, trained through reinforcement learning (RL), to investigate balancing capabilities. The RL framework consists of two interconnected neural networks governing balance recovery and muscle coordination respectively, trained using Proximal Policy Optimization (PPO) with reference state initialization, early termination, and multiple training strategies. By exploring recovery from random initial COM states (position and velocity) space for a trained controller, we obtain the final BR enclosing successful balance recovery trajectories. Comparing the BRs with analytical postural stability limits from a linear inverted pendulum model, we observe a similar trend in successful COM states but more limited ranges in the recoverable areas. We further investigate the effect of muscle weakness and neural excitation delay on the BRs, revealing reduced balancing capability in different regions. Overall, our approach of learning muscular balance controllers presents a promising new method for establishing balance recovery limits and objectively assessing balance capability in bipedal systems, particularly in humans.
</details>
<details>
<summary>摘要</summary>
评估身体重建中的平衡能力经常采用套路-oriented测试维度来评估病人的身体能力，带来主观性。尽管有一些 объектив的平衡评估存在，但它们通常只能跟踪中心重量（COP），不能完全捕捉人体整体姿态稳定性。本研究探讨了使用中心质量（COM）状态空间来监测人体平衡能力。我们采用了一种musculoskeletal模型和平衡控制器，通过反射学习（RL）训练，investigate balancing capabilities。RL框架包括两个相连的神经网络，一个 governing balance recovery，另一个 governing muscle coordination，通过距离最小化算法（PPO）进行训练。通过探索已经训练好的控制器从随机初始COM状态空间中恢复平衡的过程，我们获得了最终的BR（balance recovery）。 Comparing the BRs with analytical postural stability limits from a linear inverted pendulum model, we observe a similar trend in successful COM states but more limited ranges in the recoverable areas。我们进一步调查了肌肉衰竭和神经刺激延迟对BR的影响，发现在不同区域的平衡能力受到了限制。总的来说，我们的学习muscular平衡控制器的方法可能是评估人体平衡能力的新方法，特别是在人类身上。
</details></li>
</ul>
<hr>
<h2 id="PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning"><a href="#PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning" class="headerlink" title="PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning"></a>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03977">http://arxiv.org/abs/2308.03977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/pug">https://github.com/facebookresearch/pug</a></li>
<li>paper_authors: Florian Bordes, Shashank Shekhar, Mark Ibrahim, Diane Bouchacourt, Pascal Vincent, Ari S. Morcos</li>
<li>for: 这篇论文旨在推广使用真实图像数据的替代方案，提供更多的控制权和更加真实的图像数据，以便更好地训练和评估深度神经网络。</li>
<li>methods: 这篇论文使用了Unreal Engine游戏引擎，生成了PUG（真实图像格式）环境和数据集，以便进行表示学习研究。</li>
<li>results: 论文通过PUG环境和数据集，实现了更加准确和可靠的视觉模型评估，提供了一种更加可控和真实的替代方案。<details>
<summary>Abstract</summary>
Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通过实验室自动生成的图像集，深度神经网络的设计和评估受到了无与伦比的优势：可以（i）生成无数样本，（ii）精准控制每个场景，并提供细腻的标签和描述，（iii）在训练和测试之间准确控制分布变化，以孤立变量对照。尽管如此，使用synthetic图像数据仍然受到限制——常被淡化——主要因为它们缺乏真实感。大多数作品因此选择使用实际图像数据，这些数据通常是从互联网上抓取的，可能存在隐私、偏见和版权问题，而且对物体的显示没有准确控制。在这篇论文中，我们提出了一种将高真实度的synthetic数据普及化的方法：我们开发了一代新的交互环境，以Unreal Engine游戏引擎为基础，生成PUG（高真实度Unreal图形）环境和数据集，用于 representation learning研究。我们在这篇论文中展示了PUG的潜在力量，帮助vision模型的更加严格的评估。
</details></li>
</ul>
<hr>
<h2 id="Amortized-Global-Search-for-Efficient-Preliminary-Trajectory-Design-with-Deep-Generative-Models"><a href="#Amortized-Global-Search-for-Efficient-Preliminary-Trajectory-Design-with-Deep-Generative-Models" class="headerlink" title="Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models"></a>Amortized Global Search for Efficient Preliminary Trajectory Design with Deep Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03960">http://arxiv.org/abs/2308.03960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anjian Li, Amlan Sinha, Ryne Beeson</li>
<li>for: 提出了一种用于减轻全球搜索问题的 computational complexity的方法，以便更好地解决高维度和非对称的 trajectory optimization problem。</li>
<li>methods: 我们使用深度生成模型来预测 trajectory 的解，并且利用 clustering 结构来加速全球搜索。</li>
<li>results: 我们在 De Jong 的 5 个函数和一个低推力圆形三体问题中进行了评估，并得到了良好的结果。<details>
<summary>Abstract</summary>
Preliminary trajectory design is a global search problem that seeks multiple qualitatively different solutions to a trajectory optimization problem. Due to its high dimensionality and non-convexity, and the frequent adjustment of problem parameters, the global search becomes computationally demanding. In this paper, we exploit the clustering structure in the solutions and propose an amortized global search (AmorGS) framework. We use deep generative models to predict trajectory solutions that share similar structures with previously solved problems, which accelerates the global search for unseen parameter values. Our method is evaluated using De Jong's 5th function and a low-thrust circular restricted three-body problem.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>预liminary trajectory design是一个全球搜索问题，旨在找到多个 качеitative不同的解决方案。由于其高维度和非拟合性，以及常见的问题参数调整，全球搜索变得计算极其困难。在这篇论文中，我们利用解决方案中的凝集结构，并提出了一种含有各种凝集的全球搜索（AmorGS）框架。我们使用深度生成模型预测 trajectory解决方案，这些解决方案与之前已解决的问题中的结构相似，从而加速了未before seen的参数值上的全球搜索。我们的方法被评估使用De Jong的第五个函数和一个低推力圆形 restricted three-body problem。
</details></li>
</ul>
<hr>
<h2 id="Fixed-Inter-Neuron-Covariability-Induces-Adversarial-Robustness"><a href="#Fixed-Inter-Neuron-Covariability-Induces-Adversarial-Robustness" class="headerlink" title="Fixed Inter-Neuron Covariability Induces Adversarial Robustness"></a>Fixed Inter-Neuron Covariability Induces Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03956">http://arxiv.org/abs/2308.03956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ahmed Shah, Bhiksha Raj</li>
<li>for: 这个论文旨在提高深度神经网络（DNNs）对抗攻击的可靠性，并探索人类视觉的特性可能会帮助提高DNNs的类别化能力。</li>
<li>methods: 本论文提出了一个叫做自适应活化（SCA）层的新方法，这个层包含neuron的启动是彼此一致的，它们遵循一个已知但是学习的 covariability 模式。</li>
<li>results: 在实验中，使用 SCA 层的模型在图像和声音识别任务中实现了高准确率，并在Auto-PGD攻击中展现了明显更高的Robustness，不需要在训练过程中使用随机噪声训练。<details>
<summary>Abstract</summary>
The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern. When evaluated on image and sound recognition tasks, the models with a SCA layer achieved high accuracy, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks \textit{without being trained on adversarially perturbed data
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="PMU-measurements-based-short-term-voltage-stability-assessment-of-power-systems-via-deep-transfer-learning"><a href="#PMU-measurements-based-short-term-voltage-stability-assessment-of-power-systems-via-deep-transfer-learning" class="headerlink" title="PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning"></a>PMU measurements based short-term voltage stability assessment of power systems via deep transfer learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03953">http://arxiv.org/abs/2308.03953</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SuperBruceJia/Power-Systems-Stability-Transfer-Learning">https://github.com/SuperBruceJia/Power-Systems-Stability-Transfer-Learning</a></li>
<li>paper_authors: Yang Li, Shitu Zhang, Yuanzheng Li, Jiting Cao, Shuyue Jia</li>
<li>for: 这篇论文的目的是提出一种基于深度学习的短期电压稳定评估方法（STVSA），以解决现有的挑战，包括适应结构变化、样本标注和小型数据集处理。</li>
<li>methods: 本文提出的方法使用了深度转移学习，利用PMU测量数据创建初始数据集，采用时间ensemble进行样本标注，并使用最小二乘生成整数网络（LSGAN）进行数据增强。该方法可以有效地在小型数据集上进行深度学习，并且具有适应结构变化的能力。</li>
<li>results: 实验结果表明，提出的方法可以在IEEE 39-bus测试系统上提高模型评估精度约20%，并且具有强大的适应能力于结构变化。该方法还利用 transformer 模型中的自注意机制，与浅学习方法和其他深度学习基于方法相比，具有显著的优势。<details>
<summary>Abstract</summary>
Deep learning has emerged as an effective solution for addressing the challenges of short-term voltage stability assessment (STVSA) in power systems. However, existing deep learning-based STVSA approaches face limitations in adapting to topological changes, sample labeling, and handling small datasets. To overcome these challenges, this paper proposes a novel phasor measurement unit (PMU) measurements-based STVSA method by using deep transfer learning. The method leverages the real-time dynamic information captured by PMUs to create an initial dataset. It employs temporal ensembling for sample labeling and utilizes least squares generative adversarial networks (LSGAN) for data augmentation, enabling effective deep learning on small-scale datasets. Additionally, the method enhances adaptability to topological changes by exploring connections between different faults. Experimental results on the IEEE 39-bus test system demonstrate that the proposed method improves model evaluation accuracy by approximately 20% through transfer learning, exhibiting strong adaptability to topological changes. Leveraging the self-attention mechanism of the Transformer model, this approach offers significant advantages over shallow learning methods and other deep learning-based approaches.
</details>
<details>
<summary>摘要</summary>
深度学习已经成为电力系统短期电压稳定评估 (STVSA) 的有效解决方案。然而，现有的深度学习基于 STVSA 方法受到 топологи奇变、样本标注和处理小数据集的限制。为了缓解这些挑战，这篇论文提议一种基于 PMU 测量的新型 STVSA 方法，使用深度转移学习。该方法利用 PMU 测量获得的实时动态信息，创建初始数据集。它使用时间ensemble 进行样本标注，并使用最小二乘生成整形网络 (LSGAN) 进行数据增强，以便在小规模数据集上进行有效的深度学习。此外，该方法改进了对 topology 变化的适应性，通过探索不同的故障之间的连接。实验结果在 IEEE 39-bus 测试系统上表明，提案的方法可以通过转移学习提高评估准确率约 20%，并且具有强大的适应性。利用 Transformer 模型的自注意机制，该方法在比较深度学习方法和其他深度学习基于方法之上具有显著优势。
</details></li>
</ul>
<hr>
<h2 id="The-Prospect-of-Enhancing-Large-Scale-Heterogeneous-Federated-Learning-with-Transformers"><a href="#The-Prospect-of-Enhancing-Large-Scale-Heterogeneous-Federated-Learning-with-Transformers" class="headerlink" title="The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers"></a>The Prospect of Enhancing Large-Scale Heterogeneous Federated Learning with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03945">http://arxiv.org/abs/2308.03945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulan Gao, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Han Yu</li>
<li>for: 本文探讨了基于Transformer的 Federated Learning（FL）模型在多个不同数据所有者之间协同训练AI模型的可能性，以实现泛化和个性化。</li>
<li>methods: 本文使用了Transformer、ResNet和个性化ResNet-based FL方法进行比较性实验，以评估这些方法在不同数据所有者和不同场景下的性能。</li>
<li>results: 实验结果显示，Transformer-based FL模型在大规模不同数据所有者的场景下表现出色，特别是在数据多样性和数据规模增加的情况下。此外，通过对CKA表示相似性进行分析，本文还提供了对Transformers的表现的深入理解。<details>
<summary>Abstract</summary>
Federated learning (FL) addresses data privacy concerns by enabling collaborative training of AI models across distributed data owners. Wide adoption of FL faces the fundamental challenges of data heterogeneity and the large scale of data owners involved. In this paper, we investigate the prospect of Transformer-based FL models for achieving generalization and personalization in this setting. We conduct extensive comparative experiments involving FL with Transformers, ResNet, and personalized ResNet-based FL approaches under various scenarios. These experiments consider varying numbers of data owners to demonstrate Transformers' advantages over deep neural networks in large-scale heterogeneous FL tasks. In addition, we analyze the superior performance of Transformers by comparing the Centered Kernel Alignment (CKA) representation similarity across different layers and FL models to gain insight into the reasons behind their promising capabilities.
</details>
<details>
<summary>摘要</summary>
合作学习（FL）解决数据隐私问题，通过在分布式数据所有者之间进行AI模型的共同训练。广泛采用FL面临了数据多样性和数据所有者的大规模挑战。在这篇论文中，我们调查了使用Transformer-based FL模型来实现通用和个性化。我们进行了广泛的比较实验，包括FL与Transformers、ResNet和个性化ResNet-based FL方法在不同情况下。这些实验涵盖了不同数据所有者的数量，以 demonstarteTransformers在大规模不同数据类型FL任务中的优势。此外，我们还分析了Transformers的高性能原因，通过比较不同层次的CKA表示相似性来获得关键因素的含义。
</details></li>
</ul>
<hr>
<h2 id="GraPhSyM-Graph-Physical-Synthesis-Model"><a href="#GraPhSyM-Graph-Physical-Synthesis-Model" class="headerlink" title="GraPhSyM: Graph Physical Synthesis Model"></a>GraPhSyM: Graph Physical Synthesis Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03944">http://arxiv.org/abs/2308.03944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Agiza, Rajarshi Roy, Teodor Dumitru Ene, Saad Godil, Sherief Reda, Bryan Catanzaro</li>
<li>for: 这个研究旨在开发一个快速和精准地预测实体合成电路延迟和面积度量的Graph Attention Network（GATv2）模型，以便在逻辑合成阶段就能够获得最终设计度量的准确见解，而不需要进行慢速实体合成流程。</li>
<li>methods: 这个模型使用Graph Structure、连接性和电气性特征来预测实体合成变数的影响，并且通过训练在6000个前置逻辑合成设计中，以0.22秒的快速推断时间预测未见的逻辑合成设计的实体合成延迟和面积度量。</li>
<li>results: 研究发现，这个模型可以高度精准地预测未见的逻辑合成设计的实体合成延迟（98.3%）和面积度量（96.1%），并且可以在不同的延迟目标下进行预测。此外，模型还可以在不同的逻辑合成设计中实现高度的构成性。<details>
<summary>Abstract</summary>
In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model for fast and accurate estimation of post-physical synthesis circuit delay and area metrics from pre-physical synthesis circuit netlists. Once trained, GraPhSyM provides accurate visibility of final design metrics to early EDA stages, such as logic synthesis, without running the slow physical synthesis flow, enabling global co-optimization across stages. Additionally, the swift and precise feedback provided by GraPhSym is instrumental for machine-learning-based EDA optimization frameworks. Given a gate-level netlist of a circuit represented as a graph, GraPhSyM utilizes graph structure, connectivity, and electrical property features to predict the impact of physical synthesis transformations such as buffer insertion and gate sizing. When trained on a dataset of 6000 prefix adder designs synthesized at an aggressive delay target, GraPhSyM can accurately predict the post-synthesis delay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s inference time. Furthermore, we illustrate the compositionality of GraPhSyM by employing the model trained on a fixed delay target to accurately anticipate post-synthesis metrics at a variety of unseen delay targets. Lastly, we report promising generalization capabilities of the GraPhSyM model when it is evaluated on circuits different from the adders it was exclusively trained on. The results show the potential for GraPhSyM to serve as a powerful tool for advanced optimization techniques and as an oracle for EDA machine learning frameworks.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了GraPhSyM模型，是基于图注意力网络（GATv2）的一种快速和准确地计算后physical synthesis circuit延迟和面积指标的方法。一旦训练完成，GraPhSyM可以在逻辑合成之前提供准确的设计指标视图，无需运行慢的物理合成流程，从而实现全局协调。此外，GraPhSyM提供的快速和准确反馈对机器学习基于EDA优化框架非常有利。对于一个表示为图的逻辑电路，GraPhSyM利用图结构、连接和电性特征来预测物理合成转换（如缓冲插入和门大小调整）的影响。当训练在6000个逻辑和逻辑电路的延迟目标下进行的时候，GraPhSyM可以准确预测未看过的加器的延迟（98.3%）和面积（96.1%）指标，并且具有快速的0.22秒推理时间。此外，我们还证明了GraPhSyM的可组合性，可以使用固定延迟目标训练的模型来准确预测未看过的延迟目标。最后，我们报告了GraPhSyM模型在不同于它被专门训练的加器之外的普遍化能力。结果表明，GraPhSyM有望成为一种强大的进阶优化技术工具和EDA机器学习框架的oracle。
</details></li>
</ul>
<hr>
<h2 id="The-Compatibility-between-the-Pangu-Weather-Forecasting-Model-and-Meteorological-Operational-Data"><a href="#The-Compatibility-between-the-Pangu-Weather-Forecasting-Model-and-Meteorological-Operational-Data" class="headerlink" title="The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data"></a>The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04460">http://arxiv.org/abs/2308.04460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wencong Cheng, Yan Yan, Jiangjiang Xia, Qi Liu, Chang Qu, Zhigang Wang</li>
<li>for: 本研究旨在评估Pangu-Weather模型与各种常用的 numerical weather prediction（NWP）操作分析的兼容性，以及改进模型的预测性能。</li>
<li>methods: 本研究使用Pangu-Weather模型进行预测，并对各种NWP操作分析进行对比研究。</li>
<li>results: 研究结果显示，Pangu-Weather模型与各种NWP操作分析兼容，并且可以改进预测性能。此外，提高全球或地方初始条件质量能够显著提高Pangu-Weather模型的预测性能。<details>
<summary>Abstract</summary>
Recently, multiple data-driven models based on machine learning for weather forecasting have emerged. These models are highly competitive in terms of accuracy compared to traditional numerical weather prediction (NWP) systems. In particular, the Pangu-Weather model, which is open source for non-commercial use, has been validated for its forecasting performance by the European Centre for Medium-Range Weather Forecasts (ECMWF) and has recently been published in the journal "Nature". In this paper, we evaluate the compatibility of the Pangu-Weather model with several commonly used NWP operational analyses through case studies. The results indicate that the Pangu-Weather model is compatible with different operational analyses from various NWP systems as the model initial conditions, and it exhibits a relatively stable forecasting capability. Furthermore, we have verified that improving the quality of global or local initial conditions significantly contributes to enhancing the forecasting performance of the Pangu-Weather model.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:最近，基于机器学习的多种数据驱动模型为气象预报出现了，这些模型与传统的数值气象预测（NWP）系统相比，具有高度竞争的准确性。其中，开源非商业用途的Pangu-Weather模型，已经由欧洲中期气象预测中心（ECMWF）验证了预测性能，并最近在《自然》杂志上发表。在这篇论文中，我们通过 caso studies 评估了Pangu-Weather模型与多种常用的NWP操作分析相容性。结果显示，Pangu-Weather模型可以与不同的NWP系统的操作分析进行Compatible，并且显示出相对稳定的预测能力。此外，我们还证明了改善全球或地方初始条件质量能够明显提高Pangu-Weather模型的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-the-switching-operation-in-monoclonal-antibody-production-Economic-MPC-and-reinforcement-learning"><a href="#Optimizing-the-switching-operation-in-monoclonal-antibody-production-Economic-MPC-and-reinforcement-learning" class="headerlink" title="Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning"></a>Optimizing the switching operation in monoclonal antibody production: Economic MPC and reinforcement learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03928">http://arxiv.org/abs/2308.03928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra A. Obiri, Song Bo, Bernard T. Agyeman, Benjamin Decardi-Nelson, Jinfeng Liu</li>
<li>for: 这篇论文主要针对的是大规模生产益血抗体（mAb）的实际问题，以及如何通过 kontinuierliche 生产过程来提高产品质量和生产效率。</li>
<li>methods: 这篇论文提出了三种计算机fficient的控制方法，包括sigmoid函数近似方法、ReLU近似方法和深度强化学习（DRL）。这三种方法都是为了解决批处理操作中的数学难题。</li>
<li>results: 论文的实验结果表明，使用sigmoid函数近似方法和ReLU近似方法可以提高吞吐量和生产效率，而且比传统的1%产品剩余规则更为灵活和有效。<details>
<summary>Abstract</summary>
Monoclonal antibodies (mAbs) have emerged as indispensable assets in medicine, and are currently at the forefront of biopharmaceutical product development. However, the growing market demand and the substantial doses required for mAb clinical treatments necessitate significant progress in its large-scale production. Most of the processes for industrial mAb production rely on batch operations, which result in significant downtime. The shift towards a fully continuous and integrated manufacturing process holds the potential to boost product yield and quality, while eliminating the extra expenses associated with storing intermediate products. The integrated continuous mAb production process can be divided into the upstream and downstream processes. One crucial aspect that ensures the continuity of the integrated process is the switching of the capture columns, which are typically chromatography columns operated in a fed-batch manner downstream. Due to the discrete nature of the switching operation, advanced process control algorithms such as economic MPC (EMPC) are computationally difficult to implement. This is because an integer nonlinear program (INLP) needs to be solved online at each sampling time. This paper introduces two computationally-efficient approaches for EMPC implementation, namely, a sigmoid function approximation approach and a rectified linear unit (ReLU) approximation approach. It also explores the application of deep reinforcement learning (DRL). These three methods are compared to the traditional switching approach which is based on a 1% product breakthrough rule and which involves no optimization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Spellburst-A-Node-based-Interface-for-Exploratory-Creative-Coding-with-Natural-Language-Prompts"><a href="#Spellburst-A-Node-based-Interface-for-Exploratory-Creative-Coding-with-Natural-Language-Prompts" class="headerlink" title="Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts"></a>Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03921">http://arxiv.org/abs/2308.03921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tyler Angert, Miroslav Ivan Suzara, Jenny Han, Christopher Lawrence Pondoc, Hariharan Subramonyam</li>
<li>for: 该论文旨在提高创作编程的效率和效iveness，帮助艺术家更快速地实现他们的想法。</li>
<li>methods: 该论文使用大语言模型（LLM）来提供一个具有节点基础的创作编程环境，并通过表达式提示来帮助艺术家在 semantic 空间中进行编程。</li>
<li>results: 论文的评估表明，Spellburst 可以帮助艺术家更快速地实现他们的想法，并且可以帮助开发计算机创造力工具，以便在 semantic 和 sintactic 空间之间进行桥接。<details>
<summary>Abstract</summary>
Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a "stained glass filter" and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don't lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation with artists demonstrates Spellburst's potential to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.
</details>
<details>
<summary>摘要</summary>
创造性编程任务经常具有探索性质。当生成数字艺术作品时，艺术家通常从高水平semantic construct开始，如“普遍玻璃过滤器”，然后通过代码参数的变化，如形状、颜色、线条和透明度，来生成可观的结果。根据艺术家的采访，将semantic construct翻译到程序语法可能会困难，现有的编程工具也不太适合快速的创作探索。为解决这些挑战，我们介绍Spellburst，一个基于大语言模型（LLM）的创造编程环境。Spellburst提供以下功能：1. 节点基本接口，让艺术家通过分支和合并操作来生成生成艺术和探索不同的变化。2. 表达式基于的提示式交互，让艺术家通过提示来参与semantic programming。3. dinamic提示驱动的界面和直接代码编辑，让艺术家轻松地在semantic和语法空间之间切换。我们的评估表明，Spellburst可以增强创造编程做法，并为计算创造工具的设计提供指导。
</details></li>
</ul>
<hr>
<h2 id="Predicting-and-explaining-nonlinear-material-response-using-deep-Physically-Guided-Neural-Networks-with-Internal-Variables"><a href="#Predicting-and-explaining-nonlinear-material-response-using-deep-Physically-Guided-Neural-Networks-with-Internal-Variables" class="headerlink" title="Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables"></a>Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03915">http://arxiv.org/abs/2308.03915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier Orera-Echeverria, Jacobo Ayensa-Jiménez, Manuel Doblare</li>
<li>for: 这项研究的目的是用Physically Guided Neural Networks with Internal Variables (PGNNIV)方法揭示材料的 constitutive law，并能够预测未经见过的载荷场景下的内部和外部变量。</li>
<li>methods: 这项研究使用了新发展的PGNNIV方法，该方法通过使用物理问题的Physics-Informed Constraints (PIC)来约束特定的隐藏层，并且只通过测量力-压缩数据进行训练。</li>
<li>results: 研究发现PGNNIV方法能够预测不同材料的内部和外部变量，并且可以解释材料的 constitutive law，这种方法被称为Explainable Artificial Intelligence (XAI)。<details>
<summary>Abstract</summary>
Nonlinear materials are often difficult to model with classical state model theory because they have a complex and sometimes inaccurate physical and mathematical description or we simply do not know how to describe such materials in terms of relations between external and internal variables. In many disciplines, Neural Network methods have arisen as powerful tools to identify very complex and non-linear correlations. In this work, we use the very recently developed concept of Physically Guided Neural Networks with Internal Variables (PGNNIV) to discover constitutive laws using a model-free approach and training solely with measured force-displacement data. PGNNIVs make a particular use of the physics of the problem to enforce constraints on specific hidden layers and are able to make predictions without internal variable data. We demonstrate that PGNNIVs are capable of predicting both internal and external variables under unseen load scenarios, regardless of the nature of the material considered (linear, with hardening or softening behavior and hyperelastic), unravelling the constitutive law of the material hence explaining its nature altogether, placing the method in what is known as eXplainable Artificial Intelligence (XAI).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition"><a href="#ViLP-Knowledge-Exploration-using-Vision-Language-and-Pose-Embeddings-for-Video-Action-Recognition" class="headerlink" title="ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition"></a>ViLP: Knowledge Exploration using Vision, Language, and Pose Embeddings for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03908">http://arxiv.org/abs/2308.03908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumyabrata Chaudhuri, Saumik Bhattacharya</li>
<li>for: 本研究旨在提出一种基于多Modal学习的人体动作识别方法，以解决视频动作识别 task 中的复杂性问题。</li>
<li>methods: 本研究使用了一种新的 pose 增强的视力语言模型 (VLM)，其combines  pose 和视觉信息，以及文本特征。</li>
<li>results:  experiments 表明，该方法可以在两个人体动作识别数据集 UCF-101 和 HMDB-51 上达到 92.81% 和 73.02% 的准确率，而无需任何视频数据预训练。经ketics预训练后，准确率可以达到 96.11% 和 75.75%。<details>
<summary>Abstract</summary>
Video Action Recognition (VAR) is a challenging task due to its inherent complexities. Though different approaches have been explored in the literature, designing a unified framework to recognize a large number of human actions is still a challenging problem. Recently, Multi-Modal Learning (MML) has demonstrated promising results in this domain. In literature, 2D skeleton or pose modality has often been used for this task, either independently or in conjunction with the visual information (RGB modality) present in videos. However, the combination of pose, visual information, and text attributes has not been explored yet, though text and pose attributes independently have been proven to be effective in numerous computer vision tasks. In this paper, we present the first pose augmented Vision-language model (VLM) for VAR. Notably, our scheme achieves an accuracy of 92.81% and 73.02% on two popular human video action recognition benchmark datasets, UCF-101 and HMDB-51, respectively, even without any video data pre-training, and an accuracy of 96.11% and 75.75% after kinetics pre-training.
</details>
<details>
<summary>摘要</summary>
视频动作识别（VAR）是一个复杂的任务，它的内在复杂性使得设计一个综合性的框架来识别大量人类动作变得非常困难。然而，在文献中，不同的方法已经被探讨过，但是设计一个综合性的框架仍然是一个挑战。在文献中，2D骨骼或pose特征 oftentimes 用于这个任务，可以独立或与视觉信息（RGB特征）一起使用。然而，对于pose、视觉信息和文本特征的组合尚未被探讨，尽管文本和pose特征独立地已经证明了其效果在许多计算机视觉任务中。在这篇论文中，我们提出了首个含有 pose 的视力语言模型（VLM），该模型在 UCF-101 和 HMDB-51 两个常用的人类动作识别 benchmark 数据集上达到了 92.81% 和 73.02% 的准确率，而无需任何视频数据预训练，并且在预训练后达到了 96.11% 和 75.75% 的准确率。
</details></li>
</ul>
<hr>
<h2 id="Advancements-In-Crowd-Monitoring-System-A-Comprehensive-Analysis-of-Systematic-Approaches-and-Automation-Algorithms-State-of-The-Art"><a href="#Advancements-In-Crowd-Monitoring-System-A-Comprehensive-Analysis-of-Systematic-Approaches-and-Automation-Algorithms-State-of-The-Art" class="headerlink" title="Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art"></a>Advancements In Crowd-Monitoring System: A Comprehensive Analysis of Systematic Approaches and Automation Algorithms: State-of-The-Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03907">http://arxiv.org/abs/2308.03907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Ameen, Richard Stone</li>
<li>For: This paper focuses on the development and analysis of crowd monitoring systems, specifically exploring the use of artificial intelligence (AI) algorithms and models to enhance their effectiveness and security.* Methods: The paper employs a bifurcated approach, comparing vision-based and non-vision-based technologies for crowd monitoring, and examines the efficacy of these methods in different environments and contexts.* Results: The paper presents an in-depth analysis of the recent incorporation of AI algorithms and models into automated crowd monitoring systems, highlighting their contemporary applications and effectiveness in various contexts.<details>
<summary>Abstract</summary>
Growing apprehensions surrounding public safety have captured the attention of numerous governments and security agencies across the globe. These entities are increasingly acknowledging the imperative need for reliable and secure crowd-monitoring systems to address these concerns. Effectively managing human gatherings necessitates proactive measures to prevent unforeseen events or complications, ensuring a safe and well-coordinated environment. The scarcity of research focusing on crowd monitoring systems and their security implications has given rise to a burgeoning area of investigation, exploring potential approaches to safeguard human congregations effectively. Crowd monitoring systems depend on a bifurcated approach, encompassing vision-based and non-vision-based technologies. An in-depth analysis of these two methodologies will be conducted in this research. The efficacy of these approaches is contingent upon the specific environment and temporal context in which they are deployed, as they each offer distinct advantages. This paper endeavors to present an in-depth analysis of the recent incorporation of artificial intelligence (AI) algorithms and models into automated systems, emphasizing their contemporary applications and effectiveness in various contexts.
</details>
<details>
<summary>摘要</summary>
全球各地政府和安全机构都在关注公众安全的问题上感到担忧，认为需要可靠和安全的人群监测系统来解决这些问题。管理人群聚集需要采取先进的措施，以避免未然的事件或复杂性，确保安全和有效地协调环境。由于人群监测系统的安全性研究不足，这个领域的研究正在不断扩展，探讨有效地保护人群聚集的方法。人群监测系统采用分割方法，包括视觉基于和非视觉基于技术。本研究将进行深入分析这两种方法，分别在不同环境和时间上的效果。由于这些方法在不同情况下的应用，它们各有优劣。本文将强调现代应用的人工智能（AI）算法和模型在自动化系统中的应用，探讨其在不同场景中的现代应用和效果。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Assistant-Language-Understanding-On-Device"><a href="#Intelligent-Assistant-Language-Understanding-On-Device" class="headerlink" title="Intelligent Assistant Language Understanding On Device"></a>Intelligent Assistant Language Understanding On Device</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03905">http://arxiv.org/abs/2308.03905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Cecilia Aas, Hisham Abdelsalam, Irina Belousova, Shruti Bhargava, Jianpeng Cheng, Robert Daland, Joris Driesen, Federico Flego, Tristan Guigue, Anders Johannsen, Partha Lal, Jiarui Lu, Joel Ruben Antony Moniz, Nathan Perkins, Dhivya Piraviperumal, Stephen Pulman, Diarmuid Ó Séaghdha, David Q. Sun, John Torr, Marco Del Vecchio, Jay Wacker, Jason D. Williams, Hong Yu</li>
<li>for: 这篇论文描述了一种运行在个人电子设备上的自然语言理解系统的设计。</li>
<li>methods: 该系统使用了一些特定的架构和技术，例如在对话系统文献中一些方法可能在部署环境中难以维护。</li>
<li>results: 相比服务器基础上的助手，这种系统更加私钥、可靠、快速、表达力强和准确。<details>
<summary>Abstract</summary>
It has recently become feasible to run personal digital assistants on phones and other personal devices. In this paper we describe a design for a natural language understanding system that runs on device. In comparison to a server-based assistant, this system is more private, more reliable, faster, more expressive, and more accurate. We describe what led to key choices about architecture and technologies. For example, some approaches in the dialog systems literature are difficult to maintain over time in a deployment setting. We hope that sharing learnings from our practical experiences may help inform future work in the research community.
</details>
<details>
<summary>摘要</summary>
现在可以在手机和其他个人设备上运行个人数字助手。在这篇论文中，我们描述了一种运行于设备上的自然语言理解系统的设计。与服务器上的助手相比，这种系统更加私隐、可靠、快速、表达力 stronger和更准确。我们介绍了一些关键的建筑和技术选择，例如在部署环境中维护一些对话系统文献中的方法可能困难。我们希望通过分享我们的实践经验，可以对未来的研究community提供指导。
</details></li>
</ul>
<hr>
<h2 id="On-genuine-invariance-learning-without-weight-tying"><a href="#On-genuine-invariance-learning-without-weight-tying" class="headerlink" title="On genuine invariance learning without weight-tying"></a>On genuine invariance learning without weight-tying</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03904">http://arxiv.org/abs/2308.03904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amoskalev/ginvariance">https://github.com/amoskalev/ginvariance</a></li>
<li>paper_authors: Artem Moskalev, Anna Sepliarskaia, Erik J. Bekkers, Arnold Smeulders</li>
<li>for:  investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying.</li>
<li>methods:  adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints.</li>
<li>results:  demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance, and propose several metrics to quantify learned invariance.<details>
<summary>Abstract</summary>
In this paper, we investigate properties and limitations of invariance learned by neural networks from the data compared to the genuine invariance achieved through invariant weight-tying. To do so, we adopt a group theoretical perspective and analyze invariance learning in neural networks without weight-tying constraints. We demonstrate that even when a network learns to correctly classify samples on a group orbit, the underlying decision-making in such a model does not attain genuine invariance. Instead, learned invariance is strongly conditioned on the input data, rendering it unreliable if the input distribution shifts. We next demonstrate how to guide invariance learning toward genuine invariance by regularizing the invariance of a model at the training. To this end, we propose several metrics to quantify learned invariance: (i) predictive distribution invariance, (ii) logit invariance, and (iii) saliency invariance similarity. We show that the invariance learned with the invariance error regularization closely reassembles the genuine invariance of weight-tying models and reliably holds even under a severe input distribution shift. Closer analysis of the learned invariance also reveals the spectral decay phenomenon, when a network chooses to achieve the invariance to a specific transformation group by reducing the sensitivity to any input perturbation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究神经网络学习的不变性和其限制，并与真正的不变性相比较。为此，我们采用群理论的视角，分析神经网络无束缚的不变性学习。我们示示，即使神经网络能正确地分类样本在群或бие中，其下面的决策不会实现真正的不变性。相反，学习的不变性强烈受输入数据的影响，因此在输入分布变化时无法保靠。我们随后示出如何通过训练时的不变性正则化来引导神经网络学习真正的不变性。为此，我们提出了几个度量学习的不变性：（一）预测分布不变性、（二）启动函数不变性和（三）相似性不变性。我们表明，通过不变性错误正则化学习的不变性几乎与束缚模型的真正不变性相同，并在输入分布变化时可靠地保持。进一步分析学习的不变性也揭示了特征衰落现象，当神经网络选择通过减少输入干扰的敏感度来实现不变性。
</details></li>
</ul>
<hr>
<h2 id="FLIPS-Federated-Learning-using-Intelligent-Participant-Selection"><a href="#FLIPS-Federated-Learning-using-Intelligent-Participant-Selection" class="headerlink" title="FLIPS: Federated Learning using Intelligent Participant Selection"></a>FLIPS: Federated Learning using Intelligent Participant Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03901">http://arxiv.org/abs/2308.03901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rahul Atul Bhope, K. R. Jayaram, Nalini Venkatasubramanian, Ashish Verma, Gegi Thomas</li>
<li>for: 本研究旨在设计和实现聚合资料和参与者不同性中的联邦学习（FL）训练负载中的中介软件系统（FLIPS），以实现资料和参与者不同性的管理。</li>
<li>methods: FLIPS使用标签分布对party的资料进行对数分布 clustering，并在FL训练过程中确保每个群集都具有相等的代表性。FLIPS支持最常用的FL算法，包括FedAvg、FedProx、FedDyn、FedOpt和FedYogi。它还包括一个适应式的对应过程来处理分布式环境中的平台不同性和动态资源可用性。</li>
<li>results: 我们的严谨实验表明，相比随机选择party，FLIPS可以提高精度，在20-60%的通信成本下提高精度17-20%，并且这些优势在参与者具有慢卡特性时仍保持。<details>
<summary>Abstract</summary>
This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as two other "smart" selection mechanisms - Oort and gradient clustering using two real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17 - 20 % with 20 - 60 % lower communication costs, and these benefits endure in the presence of straggler participants.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Scalable-and-Equitable-Math-Problem-Solving-Strategy-Prediction-in-Big-Educational-Data"><a href="#Scalable-and-Equitable-Math-Problem-Solving-Strategy-Prediction-in-Big-Educational-Data" class="headerlink" title="Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data"></a>Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03892">http://arxiv.org/abs/2308.03892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anupshakya07/attn-scaling">https://github.com/anupshakya07/attn-scaling</a></li>
<li>paper_authors: Anup Shakya, Vasile Rus, Deepak Venugopal<br>for:本研究旨在提高学生数学学习效果使用智能教学系统（ITS）和适应教学系统（AIS）。methods:我们利用机器学习和人工智能技术来预测学生的解决策略，以便个性化为每个学生适应。我们首先学习学生的掌握表示（MVec），然后使用非 Parametric 聚类算法将这些表示分成不同的群组。最后，我们使用深度神经网络（DNN）模型来预测学生的解决策略。results:我们使用实际世界大规模学生互动数据集（MATHia）进行实验，并使用 transformers 和 Node2Vec 来学习 MVec，以及 LSTM 来预测解决策略。我们的方法可以扩展到大规模数据集，并且具有预测准确性和predictive equality，即预测策略具有一定的普适性。<details>
<summary>Abstract</summary>
Understanding a student's problem-solving strategy can have a significant impact on effective math learning using Intelligent Tutoring Systems (ITSs) and Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better personalize itself to correct specific misconceptions that are indicated by incorrect strategies, specific problems can be designed to improve strategies and frustration can be minimized by adapting to a student's natural way of thinking rather than trying to fit a standard strategy for all. While it may be possible for human experts to identify strategies manually in classroom settings with sufficient student interaction, it is not possible to scale this up to big data. Therefore, we leverage advances in Machine Learning and AI methods to perform scalable strategy prediction that is also fair to students at all skill levels. Specifically, we develop an embedding called MVec where we learn a representation based on the mastery of students. We then cluster these embeddings with a non-parametric clustering method where we progressively learn clusters such that we group together instances that have approximately symmetrical strategies. The strategy prediction model is trained on instances sampled from these clusters. This ensures that we train the model over diverse strategies and also that strategies from a particular group do not bias the DNN model, thus allowing it to optimize its parameters over all groups. Using real world large-scale student interaction datasets from MATHia, we implement our approach using transformers and Node2Vec for learning the mastery embeddings and LSTMs for predicting strategies. We show that our approach can scale up to achieve high accuracy by training on a small sample of a large dataset and also has predictive equality, i.e., it can predict strategies equally well for learners at diverse skill levels.
</details>
<details>
<summary>摘要</summary>
理解学生的问题解决策略可以对智能教学系统（ITS）和适应教学系统（AIS）的有效学习产生重要影响。例如，ITS/AIS可以更好地个性化自己，为学生的特定错误策略进行特定的更正，设计特定的问题来改善策略，并降低学生的沮丧度。虽然在课堂 SETTINGS中，人工专家可能可以手动确定策略，但不可能扩展到大数据。因此，我们利用机器学习和人工智能技术进行可扩展的策略预测，同时保证学生的公平性。我们开发了一个叫做MVec的嵌入，其中我们学习了学生的掌握程度的表示。然后我们使用非Parametric clustering方法，分类这些嵌入，并逐渐学习分组，以便将学生的策略分为不同的组。我们的策略预测模型是基于这些分组的实例进行训练的。这种方法可以在多个组中学习多种策略，同时避免策略来自某个组的偏见，使得神经网络模型能够在所有组之间优化参数。使用来自MATHia的实际大规模学生互动数据，我们采用了 transformers 和 Node2Vec 来学习掌握嵌入，并使用 LSTM 来预测策略。我们的方法可以在大规模数据上进行扩展，并且具有预测公平性，即可以平等地预测学生的策略水平。
</details></li>
</ul>
<hr>
<h2 id="Generative-Benchmark-Creation-for-Table-Union-Search"><a href="#Generative-Benchmark-Creation-for-Table-Union-Search" class="headerlink" title="Generative Benchmark Creation for Table Union Search"></a>Generative Benchmark Creation for Table Union Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03883">http://arxiv.org/abs/2308.03883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/northeastern-datalab/alt-gen">https://github.com/northeastern-datalab/alt-gen</a></li>
<li>paper_authors: Koyena Pal, Aamod Khatiwada, Roee Shraga, Renée J. Miller</li>
<li>for: 这篇论文的目的是提出一种使用生成AI模型创建结构化数据审核 benchmark，以解决数据管理问题的semantic nature。</li>
<li>methods: 该论文使用的方法包括使用生成AI模型创建表结构和数据，以及评估表联合搜索方法的性能。</li>
<li>results: 该论文的结果表明，使用生成AI模型创建的 benchmark 更加具有挑战性，比手动创建的 benchmark 更能让方法进行细致的分析，包括 false positives 和 false negatives 的分析。<details>
<summary>Abstract</summary>
Data management has traditionally relied on synthetic data generators to generate structured benchmarks, like the TPC suite, where we can control important parameters like data size and its distribution precisely. These benchmarks were central to the success and adoption of database management systems. But more and more, data management problems are of a semantic nature. An important example is finding tables that can be unioned. While any two tables with the same cardinality can be unioned, table union search is the problem of finding tables whose union is semantically coherent. Semantic problems cannot be benchmarked using synthetic data. Our current methods for creating benchmarks involve the manual curation and labeling of real data. These methods are not robust or scalable and perhaps more importantly, it is not clear how robust the created benchmarks are. We propose to use generative AI models to create structured data benchmarks for table union search. We present a novel method for using generative models to create tables with specified properties. Using this method, we create a new benchmark containing pairs of tables that are both unionable and non-unionable but related. We thoroughly evaluate recent existing table union search methods over existing benchmarks and our new benchmark. We also present and evaluate a new table search methods based on recent large language models over all benchmarks. We show that the new benchmark is more challenging for all methods than hand-curated benchmarks, specifically, the top-performing method achieves a Mean Average Precision of around 60%, over 30% less than its performance on existing manually created benchmarks. We examine why this is the case and show that the new benchmark permits more detailed analysis of methods, including a study of both false positives and false negatives that were not possible with existing benchmarks.
</details>
<details>
<summary>摘要</summary>
datamanagement 历史上通过生成器来生成结构化的benchmark，如TPC集成，以便控制数据大小和分布的重要参数。这些benchmark 对数据管理系统的成功和普及起到了关键作用。但随着时间的推移，数据管理问题变得越来越 semantic in nature。一个重要的例子是找到可以合并的表。虽然任何两个表都可以合并，但表合并搜索是找到可以semantically coherent的表的问题。semantic 问题不能使用生成的数据来 benchmark。我们目前的benchmark创建方法是通过手动筛选和标注实际数据来实现。这些方法不具有可靠性和可扩展性，而且更重要的是，不确定创建的benchmark 的可靠性。我们提议使用生成AI模型来创建结构化数据benchmark  для表合并搜索。我们提出了一种使用生成模型创建表的新方法。使用这种方法，我们创建了一个新的benchmark，包含可以合并的表和不可以合并的表，但它们之间存在关系。我们对现有benchmark 和我们新创建的benchmark进行了仔细的评估。我们还提出了基于最新的大语言模型的新表搜索方法，并对所有benchmark进行了评估。我们发现，新的benchmark 比手动创建的benchmark 更加挑战，特别是top-performing方法的 Mean Average Precision 约为60%，相比手动创建的benchmark 上的性能下降了30%。我们分析了这种情况，并证明新的benchmark 允许更详细的方法分析，包括对方法的false positives和false negatives进行了研究，这些研究不可能通过现有的benchmark 进行。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations"><a href="#Exploiting-Generalization-in-Offline-Reinforcement-Learning-via-Unseen-State-Augmentations" class="headerlink" title="Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations"></a>Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03882">http://arxiv.org/abs/2308.03882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nirbhay Modhe, Qiaozi Gao, Ashwin Kalyan, Dhruv Batra, Govind Thattai, Gaurav Sukhatme</li>
<li>for: 这个论文的目的是提出一种新的无线网络学习方法，以增强无线网络学习方法的探索和利用能力。</li>
<li>methods: 这个论文使用了一种模型械ск抽象的方法，通过减少值估计的不确定性来保持探索和利用的平衡。</li>
<li>results: 这个论文通过一种新的不可见状态扩展策略来提高无线网络学习的性能，并证明了这种策略可以减少数据集Q值估计的平均值，从而实现更保守的Q值估计。<details>
<summary>Abstract</summary>
Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to seen data). We observe improved performance in several offline RL tasks and find that our augmentation strategy consistently leads to overall lower average dataset Q-value estimates i.e. more conservative Q-value estimates than a baseline.
</details>
<details>
<summary>摘要</summary>
无线连接学习（RL）方法寻找平衡 между探索和占用，通过保守估值来衡量未看到的状态和动作的价值。无模型方法对所有未看到的动作进行 penalty，而模型基于方法可以通过模型扩展来进一步利用未看到的状态。然而，这些方法因两个因素受限：（a）模型中的扩展时间非常短，由于堆叠模型错误，和（b）模型扩展仅从看到的状态开始。我们relax这个第二个假设，并提出了一种新的未看到状态扩展策略，允许利用未看到状态的价值估计。我们的策略通过对已经看到的状态进行价值意识的扰动，然后过滤高度 Epistemic 不确定性（高错误）或者太像已经看到的数据的状态。我们在多个无线RL任务中观察到改进的性能，并发现我们的扩展策略通常比基准值更保守，即更低的平均数据Q估值。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-and-Explaining-Large-Language-Models-for-Code-Using-Syntactic-Structures"><a href="#Evaluating-and-Explaining-Large-Language-Models-for-Code-Using-Syntactic-Structures" class="headerlink" title="Evaluating and Explaining Large Language Models for Code Using Syntactic Structures"></a>Evaluating and Explaining Large Language Models for Code Using Syntactic Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03873">http://arxiv.org/abs/2308.03873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wm-semeru/codesyntaxconcept">https://github.com/wm-semeru/codesyntaxconcept</a></li>
<li>paper_authors: David N Palacio, Alejandro Velasco, Daniel Rodriguez-Cardenas, Kevin Moran, Denys Poshyvanyk</li>
<li>for: 这个论文旨在探讨大型自然语言模型（LLM）在编程任务上的效果和解释方法。</li>
<li>methods: 该论文提出了一种专门为 LLM 编程任务的解释方法，即 ASTxplainer，它可以帮助用户理解模型预测结果。ASTxplainer 使用了自动将token预测与AST结构相对应的方法，并提供了一种基于 AST 结构的模型评估方法和预测视图。</li>
<li>results: 该论文通过对 12 种流行的 LLM 进行实验，以及对 ASTxplainer  derive 的视图进行用户研究，显示了 ASTxplainer 的潜在作用和可用性。研究结果表明，ASTxplainer 可以提供有用的预测解释和模型效果评估。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) for code are a family of high-parameter, transformer-based neural networks pre-trained on massive datasets of both natural and programming languages. These models are rapidly being employed in commercial AI-based developer tools, such as GitHub CoPilot. However, measuring and explaining their effectiveness on programming tasks is a challenging proposition, given their size and complexity. The methods for evaluating and explaining LLMs for code are inextricably linked. That is, in order to explain a model's predictions, they must be reliably mapped to fine-grained, understandable concepts. Once this mapping is achieved, new methods for detailed model evaluations are possible. However, most current explainability techniques and evaluation benchmarks focus on model robustness or individual task performance, as opposed to interpreting model predictions.   To this end, this paper introduces ASTxplainer, an explainability method specific to LLMs for code that enables both new methods for LLM evaluation and visualizations of LLM predictions that aid end-users in understanding model predictions. At its core, ASTxplainer provides an automated method for aligning token predictions with AST nodes, by extracting and aggregating normalized model logits within AST structures. To demonstrate the practical benefit of ASTxplainer, we illustrate the insights that our framework can provide by performing an empirical evaluation on 12 popular LLMs for code using a curated dataset of the most popular GitHub projects. Additionally, we perform a user study examining the usefulness of an ASTxplainer-derived visualization of model predictions aimed at enabling model users to explain predictions. The results of these studies illustrate the potential for ASTxplainer to provide insights into LLM effectiveness, and aid end-users in understanding predictions.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM） для程式码是一家高参数、transformer基于神经网络的家族，在巨大的自然语言和程式语言Dataset上预训。这些模型在商业AI基于开发工具中被快速运用，例如GitHub CoPilot。然而，评估和解释LLMs的效果在程式任务上是一个具有挑战性的问题，因为它们的大小和复杂性。以下是一些用于评估和解释LLMs的方法：1. 将模型预测与AST结构进行自动对齐，以提取和聚合 нор化的模型潜在值。2. 使用AST结构来解释模型预测的方法，以提供更多的具体和可理解的概念。3. 使用新的评估方法和可视化工具来评估LLM的效果。为了解决这个问题，本文将介绍一种特有的解释方法——ASTxplainer，它可以帮助用户理解LLM的预测。ASTxplainer使用自动对齐模型预测和AST结构，以提取和聚合 нор化的模型潜在值。这些方法可以提供更多的具体和可理解的概念，以帮助用户理解LLM的预测。为了证明ASTxplainer的实用性，我们在12种popular LLMs for code上进行了一场empirical评估，使用一个 curaateddataset of the most popular GitHub projects。此外，我们还进行了一次用户研究，评估ASTxplainer-derived的可视化工具是否可以帮助用户解释模型预测。研究结果表明，ASTxplainer可以提供LLM效果的实际价值，并帮助用户理解预测。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Equivalence-of-e-Commerce-Queries"><a href="#Semantic-Equivalence-of-e-Commerce-Queries" class="headerlink" title="Semantic Equivalence of e-Commerce Queries"></a>Semantic Equivalence of e-Commerce Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03869">http://arxiv.org/abs/2308.03869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aritra Mandal, Daniel Tunkelang, Zhe Wu</li>
<li>for: 提高电商搜索的用户体验和商业效果，解决查询Intent的识别和利用问题。</li>
<li>methods: 提出了一种框架，包括将查询映射到搜索意图的 vector 表示，并通过对查询的surface similarity和行为相似性进行识别，以便找到最相似的查询。</li>
<li>results: 实验结果表明，该方法可以高效地识别和利用查询Intent，并且可以超越流行的句子转换器模型，实现了查询相似性的Pearson相关系数0.85。这些结果表明，可以通过历史搜索行为数据和模型训练来认识和利用查询Intent，从而提高用户体验和商业效果。<details>
<summary>Abstract</summary>
Search query variation poses a challenge in e-commerce search, as equivalent search intents can be expressed through different queries with surface-level differences. This paper introduces a framework to recognize and leverage query equivalence to enhance searcher and business outcomes. The proposed approach addresses three key problems: mapping queries to vector representations of search intent, identifying nearest neighbor queries expressing equivalent or similar intent, and optimizing for user or business objectives. The framework utilizes both surface similarity and behavioral similarity to determine query equivalence. Surface similarity involves canonicalizing queries based on word inflection, word order, compounding, and noise words. Behavioral similarity leverages historical search behavior to generate vector representations of query intent. An offline process is used to train a sentence similarity model, while an online nearest neighbor approach supports processing of unseen queries. Experimental evaluations demonstrate the effectiveness of the proposed approach, outperforming popular sentence transformer models and achieving a Pearson correlation of 0.85 for query similarity. The results highlight the potential of leveraging historical behavior data and training models to recognize and utilize query equivalence in e-commerce search, leading to improved user experiences and business outcomes. Further advancements and benchmark datasets are encouraged to facilitate the development of solutions for this critical problem in the e-commerce domain.
</details>
<details>
<summary>摘要</summary>
搜索查询的变化呈现了电商搜索中的挑战，因为相同的搜索意图可以通过不同的查询语句表达。本文介绍了一个框架，用于认可和利用查询相似性，以提高搜索者和商业目标的结果。该方案解决了三个关键问题：将查询映射到搜索意图的 вектор表示，标识最相似的查询，并优化用户或商业目标。该框架利用surface similarity和behavioral similarity来确定查询相似性。surface similarity通过词形变化、词序、合成和噪声词进行 canonicalization。behavioral similarity利用历史搜索行为生成搜索意图的 вектор表示。在线 nearest neighbor 方法支持处理未看过的查询。实验证明了提议的方法的有效性，比 популяр的句子转换器模型高效，并达到了0.85的Spearman相关系数。结果表明可以利用历史行为数据和模型训练来认可和利用查询相似性，从而提高用户体验和商业result。进一步的进步和标准化数据集的开发可以促进在电商领域内的解决这类问题的发展。
</details></li>
</ul>
<hr>
<h2 id="AI-Text-to-Behavior-A-Study-In-Steerability"><a href="#AI-Text-to-Behavior-A-Study-In-Steerability" class="headerlink" title="AI Text-to-Behavior: A Study In Steerability"></a>AI Text-to-Behavior: A Study In Steerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07326">http://arxiv.org/abs/2308.07326</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Noever, Sam Hyams</li>
<li>for: 这个研究探究了大语言模型（LLMs）的可控性，尤其是OpenAI的ChatGPT迭代。</li>
<li>methods: 我们使用了行为心理学框架called OCEAN（开放性、注意力、外向性、合作性、不稳定性）来量化模型的响应性。</li>
<li>results: 我们发现了不同 trait的语言对应性，包括“开放性”、“注意力”和“合作性”，而“外向性”和“不稳定性”则显示了明显的差异。这些发现表明GPT的多样性和适应能力，但同时也表明了一些问题，如训练技术的不透明度和LLM的快速进步。<details>
<summary>Abstract</summary>
The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while "openness" presented linguistic ambiguity, "conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN framework, with "extroversion" and "agreeableness" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. However, the rapid advancements in LLM capabilities and the opaque nature of some training techniques make metric proposals degrade rapidly. Our research emphasizes a quantitative role to describe steerability in LLMs, presenting both its promise and areas for further refinement in aligning its progress to human intentions.
</details>
<details>
<summary>摘要</summary>
Note: Please note that the translation is in Simplified Chinese, and some words or phrases may have different translations in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="MCTS-guided-Genetic-Algorithm-for-optimization-of-neural-network-weights"><a href="#MCTS-guided-Genetic-Algorithm-for-optimization-of-neural-network-weights" class="headerlink" title="MCTS guided Genetic Algorithm for optimization of neural network weights"></a>MCTS guided Genetic Algorithm for optimization of neural network weights</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04459">http://arxiv.org/abs/2308.04459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AkshayHebbar/MCTS-GA">https://github.com/AkshayHebbar/MCTS-GA</a></li>
<li>paper_authors: Akshay Hebbar</li>
<li>for: 本研究探讨了应用搜索策略到遗传算法中的整个遗传树结构。</li>
<li>methods: 本研究使用了多种搜索方法，包括广度优先搜索、深度优先搜索和迭代搜索等，但这些方法通常需要较长的计算时间。作者采用了对抗技术，以优化遗传算法中的搜索。</li>
<li>results: 本研究结果表明，结合遗传算法和蒙地卡树搜索策略可以优化神经网络的优化问题。通过对遗传树进行优化搜索，可以快速地找到最佳的神经网络结构。<details>
<summary>Abstract</summary>
In this research, we investigate the possibility of applying a search strategy to genetic algorithms to explore the entire genetic tree structure. Several methods aid in performing tree searches; however, simpler algorithms such as breadth-first, depth-first, and iterative techniques are computation-heavy and often result in a long execution time. Adversarial techniques are often the preferred mechanism when performing a probabilistic search, yielding optimal results more quickly. The problem we are trying to tackle in this paper is the optimization of neural networks using genetic algorithms. Genetic algorithms (GA) form a tree of possible states and provide a mechanism for rewards via the fitness function. Monte Carlo Tree Search (MCTS) has proven to be an effective tree search strategy given states and rewards; therefore, we will combine these approaches to optimally search for the best result generated with genetic algorithms.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们研究了将搜索策略应用于遗传算法，以探索整个遗传树结构。许多方法可以进行树搜索，但是简单的算法如广度优先、深度优先和迭代方法往往需要较长的计算时间。对于probabilistic搜索，反斗技术通常是首选的机制，可以快速获得优化结果。我们在这篇论文中是通过遗传算法优化神经网络的优化问题。遗传算法形成了一棵可能的状态树，并提供了一种via遗传函数的奖励机制。蒙地卡罗瑞搜索（MCTS）在给定状态和奖励时已经证明是一个有效的搜索策略，因此我们将这些方法相结合，以优化遗传算法中的最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing"><a href="#Revisiting-Prompt-Engineering-via-Declarative-Crowdsourcing" class="headerlink" title="Revisiting Prompt Engineering via Declarative Crowdsourcing"></a>Revisiting Prompt Engineering via Declarative Crowdsourcing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03854">http://arxiv.org/abs/2308.03854</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya G. Parameswaran, Shreya Shankar, Parth Asawa, Naman Jain, Yujie Wang</li>
<li>for: 本研究旨在提高LLM（大型自然语言模型）在数据处理工作流程中的质量，同时保持成本在bounds。</li>
<li>methods: 本研究提出了一种宣言式的推广工程（Prompt Engineering）方法，利用多种推广策略、保证内部一致性，以及混合LLM-非LLM方法来使推广工程变得更原理化。</li>
<li>results: 预liminary的案例研究表明，使用宣言式推广工程可以提高LLM在排序、实体解析和填充等任务中的性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) are incredibly powerful at comprehending and generating data in the form of text, but are brittle and error-prone. There has been an advent of toolkits and recipes centered around so-called prompt engineering-the process of asking an LLM to do something via a series of prompts. However, for LLM-powered data processing workflows, in particular, optimizing for quality, while keeping cost bounded, is a tedious, manual process. We put forth a vision for declarative prompt engineering. We view LLMs like crowd workers and leverage ideas from the declarative crowdsourcing literature-including leveraging multiple prompting strategies, ensuring internal consistency, and exploring hybrid-LLM-non-LLM approaches-to make prompt engineering a more principled process. Preliminary case studies on sorting, entity resolution, and imputation demonstrate the promise of our approach
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）具有极高的文本理解和生成能力，但是它们受限于精度和精度。随着推 engineering（提示工程）的出现，人们开始关注如何使用提示来让 LLM 完成某种任务。然而，为了在 LLM 驱动的数据处理工作流程中提高质量，同时保持成本在bounds，是一个繁琐、手动的过程。我们提出了声明式推 engineering 的视野。我们视 LLM 为群组工作者，并利用声明式招募文献中的想法，包括多种提示策略、内部一致性和混合 LLM-非 LLM approaches，以使提示工程变得更加原则化。初步的案例研究表明，这种方法在排序、实体解析和填充等方面具有承诺的批处。
</details></li>
</ul>
<hr>
<h2 id="Search-Engine-and-Recommendation-System-for-the-Music-Industry-built-with-JinaAI"><a href="#Search-Engine-and-Recommendation-System-for-the-Music-Industry-built-with-JinaAI" class="headerlink" title="Search Engine and Recommendation System for the Music Industry built with JinaAI"></a>Search Engine and Recommendation System for the Music Industry built with JinaAI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03842">http://arxiv.org/abs/2308.03842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishita Gopalakrishnan, Sanjjushri Varshini R, Ponshriharini V</li>
<li>for: 提供一个有用的搜索引擎和推荐系统 для音乐业界，以解决现有搜索引擎场景中的问题，例如速度、准确性和搜寻数据的格式。</li>
<li>methods: 使用Jina AI，一个MLOps框架，以建立基于神经网络的搜索引擎，并使用单一查询输入进行搜寻分析，并且可以对数据库中的歌曲进行精确的匹配。</li>
<li>results: 建立了一个有效的搜索引擎和推荐系统，可以帮助用户快速找到想要的歌曲，并且可以保持和提高搜索引擎的性能质量。<details>
<summary>Abstract</summary>
One of the most intriguing debates regarding a novel task is the development of search engines and recommendation-based systems in the music industry. Studies have shown a drastic depression in the search engine fields, due to concerning factors such as speed, accuracy and the format of data given for querying. Often people face difficulty in searching for a song solely based on the title, hence a solution is proposed to complete a search analysis through a single query input and is matched with the lyrics of the songs present in the database. Hence it is essential to incorporate cutting-edge technology tools for developing a user-friendly search engine. Jina AI is an MLOps framework for building neural search engines that are utilized, in order for the user to obtain accurate results. Jina AI effectively helps to maintain and enhance the quality of performance for the search engine for the query given. An effective search engine and a recommendation system for the music industry, built with JinaAI.
</details>
<details>
<summary>摘要</summary>
一个非常有趣的讨论是音乐业中搜索引擎和推荐系统的开发。研究表明，搜索引擎领域受到了严重的萧瑟和精度等因素的影响，导致搜索效果不佳。因此，一种解决方案是通过单个查询输入完成搜索分析，并将数据库中的歌曲歌词与查询结果进行匹配。因此，采用先进的技术工具对于建立用户友好的搜索引擎是非常重要。Jina AI 是一个 ML Ops 框架，用于建立基于神经网络的搜索引擎，以提供精准的搜索结果。Jina AI 有效地帮助维护和提高搜索引擎的性能质量。一款有效的搜索引擎和推荐系统，用于音乐industry，基于 JinaAI。
</details></li>
</ul>
<hr>
<h2 id="The-Copycat-Perceptron-Smashing-Barriers-Through-Collective-Learning"><a href="#The-Copycat-Perceptron-Smashing-Barriers-Through-Collective-Learning" class="headerlink" title="The Copycat Perceptron: Smashing Barriers Through Collective Learning"></a>The Copycat Perceptron: Smashing Barriers Through Collective Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03743">http://arxiv.org/abs/2308.03743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Catania, Aurélien Decelle, Beatriz Seoane</li>
<li>for: 研究一种 Binary Perceptron 模型在教师-学生场景下的平衡性质。</li>
<li>methods: 使用适当的学习规则和显式氧化 coupling  proportional to Hamming distance between students’ weights。</li>
<li>results: 对于具有非零温度的情况， coupling of replicas 导致 phase diagram shift to smaller values of α，这表明在 fixed fraction of reviewed examples 下，解决方案的自由能 landscape 变得更平滑，使用 local update algorithms such as Simulated Annealing 可以更容易到达解决方案。<details>
<summary>Abstract</summary>
We characterize the equilibrium properties of a model of $y$ coupled binary perceptrons in the teacher-student scenario, subject to a suitable learning rule, with an explicit ferromagnetic coupling proportional to the Hamming distance between the students' weights. In contrast to recent works, we analyze a more general setting in which a thermal noise is present that affects the generalization performance of each student. Specifically, in the presence of a nonzero temperature, which assigns nonzero probability to configurations that misclassify samples with respect to the teacher's prescription, we find that the coupling of replicas leads to a shift of the phase diagram to smaller values of $\alpha$: This suggests that the free energy landscape gets smoother around the solution with good generalization (i.e., the teacher) at a fixed fraction of reviewed examples, which allows local update algorithms such as Simulated Annealing to reach the solution before the dynamics gets frozen. Finally, from a learning perspective, these results suggest that more students (in this case, with the same amount of data) are able to learn the same rule when coupled together with a smaller amount of data.
</details>
<details>
<summary>摘要</summary>
我们研究一个 teacher-student enario中的 $y$ 关联 binary perceptron 模型的稳定性特性，采用一种合适的学习规则，并具有明确的 ferromagnetic 相互作用，该相互作用与学生的权重差值成正比。与之前的研究不同，我们分析了一种更通用的设置，在其中每个学生面临着一定温度，这使得每个学生的推测结果受到样本推测结果的影响。我们发现，在非零温度下，相互作用导致解的相对温度下降，这使得解的自由能面积变得更平滑，从而使用 Simulated Annealing 类型的本地更新算法可以更好地到达解。最后，从学习角度来看，这些结果表明，通过将更多的学生（每个学生具有相同数据量） coupling  вместе，可以在相同数据量下学习同样的规则。
</details></li>
</ul>
<hr>
<h2 id="Randomized-algorithms-for-precise-measurement-of-differentially-private-personalized-recommendations"><a href="#Randomized-algorithms-for-precise-measurement-of-differentially-private-personalized-recommendations" class="headerlink" title="Randomized algorithms for precise measurement of differentially-private, personalized recommendations"></a>Randomized algorithms for precise measurement of differentially-private, personalized recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03735">http://arxiv.org/abs/2308.03735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-dprecs">https://github.com/apple/ml-dprecs</a></li>
<li>paper_authors: Allegra Laro, Yanqing Chen, Hao He, Babak Aghazadeh</li>
<li>for: 这篇论文是关于个性化推荐的算法设计，帮助企业建立隐私第一的个性化推荐系统。</li>
<li>methods: 本论文提出了一种隐私保护的个性化推荐算法，通过对用户数据进行加密和扩展来保证用户隐私，同时仍能够准确地反映用户兴趣。</li>
<li>results: 作者通过实验研究了这种隐私保护的个性化推荐算法在用户体验、广告商价值和平台收益等方面的影响，并发现该算法可以减少用户隐私泄露风险，同时保持用户满意度和广告商满意度。<details>
<summary>Abstract</summary>
Personalized recommendations form an important part of today's internet ecosystem, helping artists and creators to reach interested users, and helping users to discover new and engaging content. However, many users today are skeptical of platforms that personalize recommendations, in part due to historically careless treatment of personal data and data privacy. Now, businesses that rely on personalized recommendations are entering a new paradigm, where many of their systems must be overhauled to be privacy-first. In this article, we propose an algorithm for personalized recommendations that facilitates both precise and differentially-private measurement. We consider advertising as an example application, and conduct offline experiments to quantify how the proposed privacy-preserving algorithm affects key metrics related to user experience, advertiser value, and platform revenue compared to the extremes of both (private) non-personalized and non-private, personalized implementations.
</details>
<details>
<summary>摘要</summary>
现代互联网生态系统中，个性化推荐已成为重要的一部分，帮助艺术家和创作者与有兴趣的用户连接，并帮助用户发现新和有趣的内容。然而，许多用户今天对于个性化推荐平台的存在表示怀疑，部分原因是历史上对个人数据和隐私的不谨慎处理。现在，基于个性化推荐的企业正进入一个新的 paradigma，其中许多系统需要重新设计以保持隐私。在这篇文章中，我们提出一种隐私保护的个性化推荐算法，可以同时保证精度和分配隐私。我们通过广告作为应用例子，并在线实验评估了提议的隐私保护算法对用户体验、广告商价值和平台收益的影响，与非个性化和非隐私个性化实现相比。
</details></li>
</ul>
<hr>
<h2 id="SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator"><a href="#SurvBeX-An-explanation-method-of-the-machine-learning-survival-models-based-on-the-Beran-estimator" class="headerlink" title="SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator"></a>SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03730">http://arxiv.org/abs/2308.03730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danilaeremenko/survbex">https://github.com/danilaeremenko/survbex</a></li>
<li>paper_authors: Lev V. Utkin, Danila Y. Eremenko, Andrei V. Konstantinov</li>
<li>For: The paper proposes a new method called SurvBeX to interpret predictions of machine learning survival black-box models.* Methods: The method uses a modified Beran estimator as a surrogate explanation model, and generates many points in a local area around an example of interest to compute the survival function of the black-box model and the Beran estimator.* Results: The paper demonstrates the efficiency of SurvBeX through numerical experiments with synthetic and real survival data, and compares the method with SurvLIME and SurvSHAP. The code implementing SurvBeX is available online.<details>
<summary>Abstract</summary>
An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficiency and compare the method with the well-known method SurvLIME. The method is also compared with the method SurvSHAP. The code implementing SurvBeX is available at: https://github.com/DanilaEremenko/SurvBeX
</details>
<details>
<summary>摘要</summary>
提出了一种解释方法 called SurvBeX，用于解释机器学习生存黑盒模型的预测结果。该方法的主要想法是使用 modify Beran 估计器作为解释模型。 incorporated into Beran 估计器的系数可以看作黑盒模型预测结果中特定特征的影响值。采用 LIME 方法的做法，在对 интересов的示例点附近 generate many 点，然后对每个生成的示例点，计算黑盒模型的生存函数，并将 Beran 估计器中的生存函数作为解释系数的函数。为了找到解释系数，提议使用生成的示例点中的mean distance between survival functions of the black-box model and the Beran estimator 来减少。 numerically experiments with synthetic and real survival data demonstrate SurvBeX 的效果，并与 SurvLIME 方法进行比较。 SurvBeX 还与 SurvSHAP 方法进行比较。 SurvBeX 的代码可以在以下链接中找到：https://github.com/DanilaEremenko/SurvBeX。
</details></li>
</ul>
<hr>
<h2 id="Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation"><a href="#Dimensionality-Reduction-for-Improving-Out-of-Distribution-Detection-in-Medical-Image-Segmentation" class="headerlink" title="Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation"></a>Dimensionality Reduction for Improving Out-of-Distribution Detection in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03723">http://arxiv.org/abs/2308.03723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mckellwoodland/dimen_reduce_mahal">https://github.com/mckellwoodland/dimen_reduce_mahal</a></li>
<li>paper_authors: McKell Woodland, Nihil Patel, Mais Al Taie, Joshua P. Yung, Tucker J. Netherton, Ankit B. Patel, Kristy K. Brock</li>
<li>for: 这个论文是为了检测liver segmentation模型在不同数据分布下的性能，以避免自动化偏见。</li>
<li>methods: 该论文使用了 Mahalanobis 距离后处理瓶颈特征，将瓶颈特征缩放到 Principal Component Analysis 中，以高效地检测out-of-distribution 图像。</li>
<li>results: 该论文的实验结果显示，通过应用 Mahalanobis 距离后处理瓶颈特征，可以高效地检测out-of-distribution 图像，并且具有较高的性能和较低的计算负担。<details>
<summary>Abstract</summary>
Clinically deployed segmentation models are known to fail on data outside of their training distribution. As these models perform well on most cases, it is imperative to detect out-of-distribution (OOD) images at inference to protect against automation bias. This work applies the Mahalanobis distance post hoc to the bottleneck features of a Swin UNETR model that segments the liver on T1-weighted magnetic resonance imaging. By reducing the dimensions of the bottleneck features with principal component analysis, OOD images were detected with high performance and minimal computational load.
</details>
<details>
<summary>摘要</summary>
临床应用的分割模型通常会在训练分布外的数据上失败。由于这些模型在大多数情况下表现良好，因此在推理阶段检测出idanormal（OOD）图像是非常重要的，以避免自动化偏见。这个工作使用Swin UNITER模型的瓶颈特征使用 Mahalanobis 距离后处理，以降低瓶颈特征的维度。通过使用主成分分析，OOD 图像可以高效地检测到，而且计算负担相对较小。
</details></li>
</ul>
<hr>
<h2 id="“Do-Anything-Now”-Characterizing-and-Evaluating-In-The-Wild-Jailbreak-Prompts-on-Large-Language-Models"><a href="#“Do-Anything-Now”-Characterizing-and-Evaluating-In-The-Wild-Jailbreak-Prompts-on-Large-Language-Models" class="headerlink" title="“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"></a>“Do Anything Now”: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03825">http://arxiv.org/abs/2308.03825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/verazuo/jailbreak_llms">https://github.com/verazuo/jailbreak_llms</a></li>
<li>paper_authors: Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, Yang Zhang</li>
<li>for: 本研究旨在探讨大语言模型（LLM）遭到恶意使用的问题，特别是新出现的“监狱提示”（jailbreak prompt），以及它们如何绕过安全措施并刺激LLM生成有害内容。</li>
<li>methods: 本研究使用自然语言处理技术和图形基于的社区检测方法，探索监狱提示的特有特征和主要攻击策略，如提示注入和特权提升。研究还发现监狱提示逐渐倾向私人平台，对LLM供应商带来新的检测挑战。</li>
<li>results: 研究发现现有LLM和安全措施无法彻底防范监狱提示的攻击，特别是在13种禁止enario中，其中两个监狱提示在GPT-3.5和GPT-4上达到了0.99攻击成功率，并在线上免疫超过100天。研究 shed light on the严重和不断演化的监狱提示威胁领域。希望本研究可以促进研究人员和LLM供应商在推广安全和规范的LLM方面努力。<details>
<summary>Abstract</summary>
The misuse of large language models (LLMs) has garnered significant attention from the general public and LLM vendors. In response, efforts have been made to align LLMs with human values and intent use. However, a particular type of adversarial prompts, known as jailbreak prompt, has emerged and continuously evolved to bypass the safeguards and elicit harmful content from LLMs. In this paper, we conduct the first measurement study on jailbreak prompts in the wild, with 6,387 prompts collected from four platforms over six months. Leveraging natural language processing technologies and graph-based community detection methods, we discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from public platforms to private ones, posing new challenges for LLM vendors in proactive detection. To assess the potential harm caused by jailbreak prompts, we create a question set comprising 46,800 samples across 13 forbidden scenarios. Our experiments show that current LLMs and safeguards cannot adequately defend jailbreak prompts in all scenarios. Particularly, we identify two highly effective jailbreak prompts which achieve 0.99 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and they have persisted online for over 100 days. Our work sheds light on the severe and evolving threat landscape of jailbreak prompts. We hope our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）的不当使用已经引起了公众和LLM供应商的关注。为了规避LLMs被用于不良目的，努力被进行了对LLMs的人类价值观和合法用途的Alignment。然而，一种特殊的恶意提示，称为监狱破解提示，在不断演化以通过安全措施得到恶意内容从LLMs。在这篇论文中，我们进行了首次在野外中对监狱提示的测量研究，收集了6,387个提示从四个平台上， duration of six months。通过自然语言处理技术和图形基本的社区探测方法，我们发现了监狱提示的独特特征和主要攻击策略，如提示注入和特权提升。我们还发现，监狱提示在公共平台逐渐减少，这对LLM供应商在抢救措施方面带来了新的挑战。为了评估监狱提示所可能引起的危害，我们创建了46,800个问题样本，涵盖13个禁止enario。我们的实验表明，目前的LLMs和安全措施无法有效地防止监狱提示在所有情况下。特别是，我们标识出了两个非常有效的监狱提示，在ChatGPT（GPT-3.5）和GPT-4上达到了0.99的攻击成功率，它们在线上持续超过100天。我们的工作照明了监狱提示的严重和演化的威胁风险。我们希望我们的研究能够促进研究 сообщество和LLM供应商在推广安全和规范的LLMs方面的努力。
</details></li>
</ul>
<hr>
<h2 id="Communication-Efficient-Framework-for-Distributed-Image-Semantic-Wireless-Transmission"><a href="#Communication-Efficient-Framework-for-Distributed-Image-Semantic-Wireless-Transmission" class="headerlink" title="Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission"></a>Communication-Efficient Framework for Distributed Image Semantic Wireless Transmission</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03713">http://arxiv.org/abs/2308.03713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingyan Xie, Yongpeng Wu, Yuxuan Shi, Derrick Wing Kwan Ng, Wenjun Zhang</li>
<li>For: The paper proposes a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices.* Methods: The FLSC framework uses a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation. The framework also employs a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise.* Results: The paper shows that the FLSC framework can achieve better performance than traditional schemes in terms of coarse semantic information and signal-to-noise ratio, especially in low signal-to-noise ratio and channel bandwidth ratio regimes. Specifically, the FLSC framework can provide around 10 dB signal-to-noise ratio gain in the 3 dB channel condition.<details>
<summary>Abstract</summary>
Multi-node communication, which refers to the interaction among multiple devices, has attracted lots of attention in many Internet-of-Things (IoT) scenarios. However, its huge amounts of data flows and inflexibility for task extension have triggered the urgent requirement of communication-efficient distributed data transmission frameworks. In this paper, inspired by the great superiorities on bandwidth reduction and task adaptation of semantic communications, we propose a federated learning-based semantic communication (FLSC) framework for multi-task distributed image transmission with IoT devices. Federated learning enables the design of independent semantic communication link of each user while further improves the semantic extraction and task performance through global aggregation. Each link in FLSC is composed of a hierarchical vision transformer (HVT)-based extractor and a task-adaptive translator for coarse-to-fine semantic extraction and meaning translation according to specific tasks. In order to extend the FLSC into more realistic conditions, we design a channel state information-based multiple-input multiple-output transmission module to combat channel fading and noise. Simulation results show that the coarse semantic information can deal with a range of image-level tasks. Moreover, especially in low signal-to-noise ratio and channel bandwidth ratio regimes, FLSC evidently outperforms the traditional scheme, e.g. about 10 peak signal-to-noise ratio gain in the 3 dB channel condition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience"><a href="#Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience" class="headerlink" title="Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience"></a>Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03712">http://arxiv.org/abs/2308.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eminorhan/humanlike-vits">https://github.com/eminorhan/humanlike-vits</a></li>
<li>paper_authors: A. Emin Orhan</li>
<li>for:  investigate whether current self-supervised learning methods can reach human-level visual object recognition capabilities with the same type and amount of visual experience as humans.</li>
<li>methods: use vision transformers with up to 633M parameters and train with up to 5K hours of human-like video data, with image resolutions of up to 476x476 pixels, using masked autoencoders as a self-supervised learning algorithm.</li>
<li>results: find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously, and estimate that a 2.5B parameter ViT model trained with 20K hours of human-like video data should be able to reach roughly human-level accuracy on ImageNet.<details>
<summary>Abstract</summary>
This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach roughly human-level accuracy on ImageNet. Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases.
</details>
<details>
<summary>摘要</summary>
这篇论文询问了现有自动学习方法，如果继续扩大，能否达到人类级视觉对象识别能力，使用同样的类型和量的视觉经验。先前的工作只考虑了数据量的扩大。我们在这篇论文中考虑了同时扩大数据量、模型大小和图像分辨率。我们通过使用视Transformer模型，最大达633M参数（ViT-H/14），使用人类类似的视频数据（长、连续、主要是 Egocentric 视频），并将图像分辨率提高至476x476像素。我们发现，在同时扩大数据量、模型大小和图像分辨率的情况下，可以达到人类级对象识别能力，但是这些因素需要同时扩大。例如，我们估计，一个2.5B参数的 ViT 模型，通过20K小时（2.3年）的人类类似的视频数据，并在952x952像素的空间分辨率下进行训练，应该能够达到图像Net roughly human-level accuracy。这显示，通过人类类似的感知经验（包括同样的类型和量），使用极简的学习算法和架构，并不具备重要的逻辑假设，可以达到人类级的视觉对象识别能力。
</details></li>
</ul>
<hr>
<h2 id="DeRisk-An-Effective-Deep-Learning-Framework-for-Credit-Risk-Prediction-over-Real-World-Financial-Data"><a href="#DeRisk-An-Effective-Deep-Learning-Framework-for-Credit-Risk-Prediction-over-Real-World-Financial-Data" class="headerlink" title="DeRisk: An Effective Deep Learning Framework for Credit Risk Prediction over Real-World Financial Data"></a>DeRisk: An Effective Deep Learning Framework for Credit Risk Prediction over Real-World Financial Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03704">http://arxiv.org/abs/2308.03704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yancheng Liang, Jiajie Zhang, Hui Li, Xiaochen Liu, Yi Hu, Yong Wu, Jinyao Zhang, Yongyan Liu, Yi Wu</li>
<li>for: 预测信用风险（credit risk prediction）</li>
<li>methods: 使用深度学习模型（deep learning model）</li>
<li>results: 超越统计学习方法（statistical learning methods），实现更高的预测精度（higher prediction accuracy）<details>
<summary>Abstract</summary>
Despite the tremendous advances achieved over the past years by deep learning techniques, the latest risk prediction models for industrial applications still rely on highly handtuned stage-wised statistical learning tools, such as gradient boosting and random forest methods. Different from images or languages, real-world financial data are high-dimensional, sparse, noisy and extremely imbalanced, which makes deep neural network models particularly challenging to train and fragile in practice. In this work, we propose DeRisk, an effective deep learning risk prediction framework for credit risk prediction on real-world financial data. DeRisk is the first deep risk prediction model that outperforms statistical learning approaches deployed in our company's production system. We also perform extensive ablation studies on our method to present the most critical factors for the empirical success of DeRisk.
</details>
<details>
<summary>摘要</summary>
尽管深度学习技术在过去几年中取得了巨大的进步，但最新的风险预测模型仍然基于高度手动调整的阶段性统计学学习工具，如梯度提升和随机森林方法。不同于图像或语言，实际世界金融数据具有高维、稀疏、噪音和极度不均衡的特点，这使得深度神经网络模型在实践中特别困难要求和脆弱。在这项工作中，我们提出了DeRisk，一种高效的深度学习风险预测框架，用于实际世界金融数据的风险预测。DeRisk是我们公司生产系统中现在使用的统计学学习方法的首个深度风险预测模型，我们还进行了广泛的减少研究，以阐明DeRisk的成功的重要因素。
</details></li>
</ul>
<hr>
<h2 id="AgentBench-Evaluating-LLMs-as-Agents"><a href="#AgentBench-Evaluating-LLMs-as-Agents" class="headerlink" title="AgentBench: Evaluating LLMs as Agents"></a>AgentBench: Evaluating LLMs as Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03688">http://arxiv.org/abs/2308.03688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/agentbench">https://github.com/thudm/agentbench</a></li>
<li>paper_authors: Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, Jie Tang</li>
<li>for: 评估大语言模型（LLM）在实际世界中的应用，包括评估 LLM 的推理和决策能力在多turn open-ended generation setting 中。</li>
<li>methods: 作者提出了 AgentBench，一个多维度演化的测试准则，目前包括 8 个环境，用于评估 LLM 作为代理的能力。</li>
<li>results: 作者对 25 个 LLM（包括 API 和开源模型）进行了广泛的测试，发现Top商业 LLM 在复杂环境中表现出了强大的代理能力，但是与开源竞争对手之间存在显著的性能差异。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors. It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation. Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Almost-sure-convergence-of-iterates-and-multipliers-in-stochastic-sequential-quadratic-optimization"><a href="#Almost-sure-convergence-of-iterates-and-multipliers-in-stochastic-sequential-quadratic-optimization" class="headerlink" title="Almost-sure convergence of iterates and multipliers in stochastic sequential quadratic optimization"></a>Almost-sure convergence of iterates and multipliers in stochastic sequential quadratic optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03687">http://arxiv.org/abs/2308.03687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frank E. Curtis, Xin Jiang, Qi Wang</li>
<li>for: 这种方法用于解决连续优化问题，具有非线性等式约束。</li>
<li>methods: 使用渐进随机Sequential Quadratic Programming（SQP）方法。</li>
<li>results: 提供了新的几乎确定的收敛保证，包括 primal 迭代、Lagrange多余阶度和稳定度量的收敛。<details>
<summary>Abstract</summary>
Stochastic sequential quadratic optimization (SQP) methods for solving continuous optimization problems with nonlinear equality constraints have attracted attention recently, such as for solving large-scale data-fitting problems subject to nonconvex constraints. However, for a recently proposed subclass of such methods that is built on the popular stochastic-gradient methodology from the unconstrained setting, convergence guarantees have been limited to the asymptotic convergence of the expected value of a stationarity measure to zero. This is in contrast to the unconstrained setting in which almost-sure convergence guarantees (of the gradient of the objective to zero) can be proved for stochastic-gradient-based methods. In this paper, new almost-sure convergence guarantees for the primal iterates, Lagrange multipliers, and stationarity measures generated by a stochastic SQP algorithm in this subclass of methods are proved. It is shown that the error in the Lagrange multipliers can be bounded by the distance of the primal iterate to a primal stationary point plus the error in the latest stochastic gradient estimate. It is further shown that, subject to certain assumptions, this latter error can be made to vanish by employing a running average of the Lagrange multipliers that are computed during the run of the algorithm. The results of numerical experiments are provided to demonstrate the proved theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
This paper presents new almost-sure convergence guarantees for the primal iterates, Lagrange multipliers, and stationarity measures generated by a stochastic SQP algorithm in this subclass of methods. The error in the Lagrange multipliers can be bounded by the distance of the primal iterate to a primal stationary point plus the error in the latest stochastic gradient estimate. Furthermore, it is shown that this latter error can be made to vanish by employing a running average of the Lagrange multipliers computed during the run of the algorithm, subject to certain assumptions.Numerical experiments are provided to demonstrate the proved theoretical guarantees. These results demonstrate the effectiveness of the proposed method in solving continuous optimization problems with nonlinear equality constraints.
</details></li>
</ul>
<hr>
<h2 id="Linear-Convergence-Bounds-for-Diffusion-Models-via-Stochastic-Localization"><a href="#Linear-Convergence-Bounds-for-Diffusion-Models-via-Stochastic-Localization" class="headerlink" title="Linear Convergence Bounds for Diffusion Models via Stochastic Localization"></a>Linear Convergence Bounds for Diffusion Models via Stochastic Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03686">http://arxiv.org/abs/2308.03686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joe Benton, Valentin De Bortoli, Arnaud Doucet, George Deligiannidis</li>
<li>for: 这个论文旨在提供高维数据分布中的近似样本生成方法，以及这些方法的拓扑分布的拓扑分布。</li>
<li>methods: 这个论文使用了扩散模型，这些模型可以在高维数据分布中生成近似样本。这些模型使用了$L^2$-精度分布 estimator，并且可以在不更改数据分布的情况下生成样本。</li>
<li>results: 这个论文提供了高维数据分布中扩散模型的新的拓扑分布 bound，这些 bound 是线性增长的（在数据维度上），并且不需要数据分布具有强平滑性。这个论文还证明了扩散模型只需要 $\tilde O(\frac{d \log^2(1&#x2F;\delta)}{\varepsilon^2})$ 步来近似于任何数据分布，其中 $\delta$ 是数据分布的噪声标准差，$\varepsilon$ 是近似度。<details>
<summary>Abstract</summary>
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SDE, which is based on tools from stochastic localization.
</details>
<details>
<summary>摘要</summary>
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SDE, which is based on tools from stochastic localization.Note: "Simplified Chinese" is a romanization of Chinese that uses the Chinese characters and their pronunciations, but not the traditional Chinese grammar and syntax. It is often used for computer interfaces and other contexts where a more simplified representation of Chinese is desired.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.LG_2023_08_08/" data-id="clpxp6c3e00puee88erae70mn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/71/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/70/">70</a><a class="page-number" href="/page/71/">71</a><span class="page-number current">72</span><a class="page-number" href="/page/73/">73</a><a class="page-number" href="/page/74/">74</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/73/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
