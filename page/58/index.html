
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/58/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.SD_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T15:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.SD_2023_09_03/">cs.SD - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NADiffuSE-Noise-aware-Diffusion-based-Model-for-Speech-Enhancement"><a href="#NADiffuSE-Noise-aware-Diffusion-based-Model-for-Speech-Enhancement" class="headerlink" title="NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement"></a>NADiffuSE: Noise-aware Diffusion-based Model for Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01212">http://arxiv.org/abs/2309.01212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wen Wang, Dongchao Yang, Qichen Ye, Bowen Cao, Yuexian Zou</li>
<li>for: 这种paper的目的是提高干扰除 noise 的speech增强技术。</li>
<li>methods: 这种paper使用的方法包括 diffusion models (DM) 和 generator-plus-conditioner (GPC) 结构，以及多stage frameworks。</li>
<li>results: 实验结果表明，这种 noise-aware diffusion-based speech enhancement 模型（NADiffuSE）可以提高干扰除 noise 的性能，并且可以在不同的干扰环境下保持良好的声音质量。<details>
<summary>Abstract</summary>
The goal of speech enhancement (SE) is to eliminate the background interference from the noisy speech signal. Generative models such as diffusion models (DM) have been applied to the task of SE because of better generalization in unseen noisy scenes. Technical routes for the DM-based SE methods can be summarized into three types: task-adapted diffusion process formulation, generator-plus-conditioner (GPC) structures and the multi-stage frameworks. We focus on the first two approaches, which are constructed under the GPC architecture and use the task-adapted diffusion process to better deal with the real noise. However, the performance of these SE models is limited by the following issues: (a) Non-Gaussian noise estimation in the task-adapted diffusion process. (b) Conditional domain bias caused by the weak conditioner design in the GPC structure. (c) Large amount of residual noise caused by unreasonable interpolation operations during inference. To solve the above problems, we propose a noise-aware diffusion-based SE model (NADiffuSE) to boost the SE performance, where the noise representation is extracted from the noisy speech signal and introduced as a global conditional information for estimating the non-Gaussian components. Furthermore, the anchor-based inference algorithm is employed to achieve a compromise between the speech distortion and noise residual. In order to mitigate the performance degradation caused by the conditional domain bias in the GPC framework, we investigate three model variants, all of which can be viewed as multi-stage SE based on the preprocessing networks for Mel spectrograms. Experimental results show that NADiffuSE outperforms other DM-based SE models under the GPC infrastructure. Audio samples are available at: https://square-of-w.github.io/NADiffuSE-demo/.
</details>
<details>
<summary>摘要</summary>
目标是减少背景干扰，使得听写 speech 信号中的干扰消失。生成模型如扩散模型（DM）已经应用于干扰消除任务，因为它们在未看到的干扰场景中更好地泛化。技术 Routes 可以概括为三种：任务适应扩散过程的形ulation，生成器+条件器（GPC）结构和多Stage 框架。我们主要关注前两种方法，它们在 GPC 架构下使用任务适应扩散过程来更好地处理实际的干扰。然而，这些干扰消除模型的性能受以下问题的限制：(a) 任务适应扩散过程中的非高斯噪声估计。(b) GPC 结构中弱条件器设计引起的 conditional 领域偏见。(c) 推理过程中不合理的插值操作导致的大量剩余噪声。为解决以上问题，我们提出了一种噪声意识 diffusion-based SE 模型（NADiffuSE），其中噪声表示被提取自听写 speech 信号，并作为全局条件信息来估计非高斯噪声成分。此外，我们采用了 anchor-based 推理算法以实现权衡 speech 损害和剩余噪声。为了 Mitigate GPC 框架中的 conditional 领域偏见问题，我们进行了三种模型变体的研究，它们都可以视为基于 Mel spectrograms 的多Stage SE。实验结果表明，NADiffuSE 在 GPC 结构下的性能明显超越了其他 DM-based SE 模型。听写样本可以在以下网站上找到：https://square-of-w.github.io/NADiffuSE-demo/。
</details></li>
</ul>
<hr>
<h2 id="MSM-VC-High-fidelity-Source-Style-Transfer-for-Non-Parallel-Voice-Conversion-by-Multi-scale-Style-Modeling"><a href="#MSM-VC-High-fidelity-Source-Style-Transfer-for-Non-Parallel-Voice-Conversion-by-Multi-scale-Style-Modeling" class="headerlink" title="MSM-VC: High-fidelity Source Style Transfer for Non-Parallel Voice Conversion by Multi-scale Style Modeling"></a>MSM-VC: High-fidelity Source Style Transfer for Non-Parallel Voice Conversion by Multi-scale Style Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01142">http://arxiv.org/abs/2309.01142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Wang, Xinsheng Wang, Qicong Xie, Tao Li, Lei Xie, Qiao Tian, Yuping Wang</li>
<li>for: 这篇论文主要针对的是voice conversion（VC）任务中保持源语音的发音风格，并且实现高质量的转换。</li>
<li>methods: 该论文提出了一种多级风格模型法（MSM-VC），该法利用不同级别的特征来模型源语音的发音风格。具体来说，该法使用了不同级别的特征，包括末尾特征、本地特征和全局特征，来模型语音的帧级、本地级和全局级风格。此外，该法还引入了一个Explicit Constraint Module，以确保源语音的风格模型和目标说话人的特征 preserved。</li>
<li>results: 实验表明，MSM-VC方法可以高效地模型源语音的风格，同时保持高质量的语音转换和说话人相似性。<details>
<summary>Abstract</summary>
In addition to conveying the linguistic content from source speech to converted speech, maintaining the speaking style of source speech also plays an important role in the voice conversion (VC) task, which is essential in many scenarios with highly expressive source speech, such as dubbing and data augmentation. Previous work generally took explicit prosodic features or fixed-length style embedding extracted from source speech to model the speaking style of source speech, which is insufficient to achieve comprehensive style modeling and target speaker timbre preservation. Inspired by the style's multi-scale nature of human speech, a multi-scale style modeling method for the VC task, referred to as MSM-VC, is proposed in this paper. MSM-VC models the speaking style of source speech from different levels. To effectively convey the speaking style and meanwhile prevent timbre leakage from source speech to converted speech, each level's style is modeled by specific representation. Specifically, prosodic features, pre-trained ASR model's bottleneck features, and features extracted by a model trained with a self-supervised strategy are adopted to model the frame, local, and global-level styles, respectively. Besides, to balance the performance of source style modeling and target speaker timbre preservation, an explicit constraint module consisting of a pre-trained speech emotion recognition model and a speaker classifier is introduced to MSM-VC. This explicit constraint module also makes it possible to simulate the style transfer inference process during the training to improve the disentanglement ability and alleviate the mismatch between training and inference. Experiments performed on the highly expressive speech corpus demonstrate that MSM-VC is superior to the state-of-the-art VC methods for modeling source speech style while maintaining good speech quality and speaker similarity.
</details>
<details>
<summary>摘要</summary>
在voice conversion（VC）任务中，保持源语音的说话风格也非常重要，特别在高度表情化的源语音中，如重 lip-sync 和数据增强。先前的工作通常使用源语音中的显式 просодические特征或固定长度的风格嵌入来模拟源语音的说话风格，但这并不能实现完整的风格模型化和目标 speaker timbre 保持。受到人类语音的风格多尺度性的启发，本文提出了一种多尺度风格模型化方法（MSM-VC）。MSM-VC 模拟源语音的说话风格从不同的水平，以达到更好的风格模型化和目标 speaker timbre 保持。具体来说，在不同水平上，采用不同的表示方式来模拟风格。例如，在帧水平上采用抑制特征、在本地水平上采用预训练 ASR 模型的瓶颈特征，在全局水平上采用通过自我超VI的方法提取的特征。此外，为了平衡源风格模型化和目标 speaker timbre 保持，我们引入了一个explicit constraint module，包括一个预训练的语音情感认知模型和一个 speaker classifier。这个explicit constraint module 也使得在训练过程中可以模拟风格传递INFERENCE进程，以提高分离度和减少训练和测试之间的差异。实验表明，在高度表情化语音库中，MSM-VC 比状态之前的VC方法更好地模拟源语音的说话风格，同时保持良好的语音质量和 speaker similarity。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.SD_2023_09_03/" data-id="clpxp044m00yxfm881n33gd47" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.CV_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T13:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.CV_2023_09_03/">cs.CV - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MAP-Domain-Generalization-via-Meta-Learning-on-Anatomy-Consistent-Pseudo-Modalities"><a href="#MAP-Domain-Generalization-via-Meta-Learning-on-Anatomy-Consistent-Pseudo-Modalities" class="headerlink" title="MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"></a>MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01286">http://arxiv.org/abs/2309.01286</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dewei Hu, Hao Li, Han Liu, Xing Yao, Jiacheng Wang, Ipek Oguz</li>
<li>for: 提高深度模型的 клиниче应用性，即增强模型对未经见的领域的泛化能力。</li>
<li>methods: 我们提出了一种名为Meta learning on Anatomy-consistent Pseudo-modalities（MAP）的方法，该方法通过学习结构特征来提高模型的泛化能力。我们首先使用特征提取网络生成了三种不同的 Pseudo-modalities，然后使用 episodic learning 模式，选择一个 Pseudo-modalities 作为元训练集，并在一个通过 Dirichlet mixup 生成的连续变换图像空间中进行元测试。此外，我们还引入了两种捕捉形态信息的损失函数，以便模型更好地关注形态特征。</li>
<li>results: 我们在七个公共 datasets 上进行了测试，并证明了 MAP 在不同的Retinal imaging modalities上有substantially better的泛化能力。<details>
<summary>Abstract</summary>
Deep models suffer from limited generalization capability to unseen domains, which has severely hindered their clinical applicability. Specifically for the retinal vessel segmentation task, although the model is supposed to learn the anatomy of the target, it can be distracted by confounding factors like intensity and contrast. We propose Meta learning on Anatomy-consistent Pseudo-modalities (MAP), a method that improves model generalizability by learning structural features. We first leverage a feature extraction network to generate three distinct pseudo-modalities that share the vessel structure of the original image. Next, we use the episodic learning paradigm by selecting one of the pseudo-modalities as the meta-train dataset, and perform meta-testing on a continuous augmented image space generated through Dirichlet mixup of the remaining pseudo-modalities. Further, we introduce two loss functions that facilitate the model's focus on shape information by clustering the latent vectors obtained from images featuring identical vasculature. We evaluate our model on seven public datasets of various retinal imaging modalities and we conclude that MAP has substantially better generalizability. Our code is publically available at https://github.com/DeweiHu/MAP.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FOR-instance-a-UAV-laser-scanning-benchmark-dataset-for-semantic-and-instance-segmentation-of-individual-trees"><a href="#FOR-instance-a-UAV-laser-scanning-benchmark-dataset-for-semantic-and-instance-segmentation-of-individual-trees" class="headerlink" title="FOR-instance: a UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees"></a>FOR-instance: a UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01279">http://arxiv.org/abs/2309.01279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Puliti, Grant Pearse, Peter Surový, Luke Wallace, Markus Hollaus, Maciej Wielgosz, Rasmus Astrup</li>
<li>for: 这个论文是为了提高 dense airborne laser scanning 数据的Instance和Semantic segmentation技术而写的。</li>
<li>methods: 该论文使用了 UAV 上的激光扫描数据，并对其进行手动标注，以获得不同类别的树实体和 semantic classes。</li>
<li>results: 该论文提供了一个标准化的 benchmarking 数据集，用于提高Instance和Semantic segmentation技术的发展，并且可以适应不同的深度学习框架和 segmentation 策略。<details>
<summary>Abstract</summary>
The FOR-instance dataset (available at https://doi.org/10.5281/zenodo.8287792) addresses the challenge of accurate individual tree segmentation from laser scanning data, crucial for understanding forest ecosystems and sustainable management. Despite the growing need for detailed tree data, automating segmentation and tracking scientific progress remains difficult. Existing methodologies often overfit small datasets and lack comparability, limiting their applicability. Amid the progress triggered by the emergence of deep learning methodologies, standardized benchmarking assumes paramount importance in these research domains. This data paper introduces a benchmarking dataset for dense airborne laser scanning data, aimed at advancing instance and semantic segmentation techniques and promoting progress in 3D forest scene segmentation. The FOR-instance dataset comprises five curated and ML-ready UAV-based laser scanning data collections from diverse global locations, representing various forest types. The laser scanning data were manually annotated into individual trees (instances) and different semantic classes (e.g. stem, woody branches, live branches, terrain, low vegetation). The dataset is divided into development and test subsets, enabling method advancement and evaluation, with specific guidelines for utilization. It supports instance and semantic segmentation, offering adaptability to deep learning frameworks and diverse segmentation strategies, while the inclusion of diameter at breast height data expands its utility to the measurement of a classic tree variable. In conclusion, the FOR-instance dataset contributes to filling a gap in the 3D forest research, enhancing the development and benchmarking of segmentation algorithms for dense airborne laser scanning data.
</details>
<details>
<summary>摘要</summary>
《FOR-instance数据集》（可在https://doi.org/10.5281/zenodo.8287792中获取）是一个关键性的三维森林景象分割数据集，用于提高受众树 segmentation 技术的精度。despite the growing need for detailed tree data, automating segmentation and tracking scientific progress remains difficult. Existing methodologies often overfit small datasets and lack comparability, limiting their applicability. With the emergence of deep learning methodologies, standardized benchmarking assumes paramount importance in these research domains. This data paper introduces a benchmarking dataset for dense airborne laser scanning data, aimed at advancing instance and semantic segmentation techniques and promoting progress in 3D forest scene segmentation.The FOR-instance dataset includes five curated and ML-ready UAV-based laser scanning data collections from diverse global locations, representing various forest types. The laser scanning data were manually annotated into individual trees (instances) and different semantic classes (e.g. stem, woody branches, live branches, terrain, low vegetation). The dataset is divided into development and test subsets, enabling method advancement and evaluation, with specific guidelines for utilization. It supports instance and semantic segmentation, offering adaptability to deep learning frameworks and diverse segmentation strategies, while the inclusion of diameter at breast height data expands its utility to the measurement of a classic tree variable. In conclusion, the FOR-instance dataset contributes to filling a gap in the 3D forest research, enhancing the development and benchmarking of segmentation algorithms for dense airborne laser scanning data.
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-with-Deterministic-Normalizing-Flow-Priors"><a href="#Diffusion-Models-with-Deterministic-Normalizing-Flow-Priors" class="headerlink" title="Diffusion Models with Deterministic Normalizing Flow Priors"></a>Diffusion Models with Deterministic Normalizing Flow Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01274">http://arxiv.org/abs/2309.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mohsenzand/dinof">https://github.com/mohsenzand/dinof</a></li>
<li>paper_authors: Mohsen Zand, Ali Etemad, Michael Greenspan</li>
<li>for: 提高样本质量和采样速度</li>
<li>methods: 使用normalizing flows和diffusion模型</li>
<li>results: 在标准图像生成数据集上达到了比较出色的表现，包括FID和inception分数<details>
<summary>Abstract</summary>
For faster sampling and higher sample quality, we propose DiNof ($\textbf{Di}$ffusion with $\textbf{No}$rmalizing $\textbf{f}$low priors), a technique that makes use of normalizing flows and diffusion models. We use normalizing flows to parameterize the noisy data at any arbitrary step of the diffusion process and utilize it as the prior in the reverse diffusion process. More specifically, the forward noising process turns a data distribution into partially noisy data, which are subsequently transformed into a Gaussian distribution by a nonlinear process. The backward denoising procedure begins with a prior created by sampling from the Gaussian distribution and applying the invertible normalizing flow transformations deterministically. To generate the data distribution, the prior then undergoes the remaining diffusion stochastic denoising procedure. Through the reduction of the number of total diffusion steps, we are able to speed up both the forward and backward processes. More importantly, we improve the expressive power of diffusion models by employing both deterministic and stochastic mappings. Experiments on standard image generation datasets demonstrate the advantage of the proposed method over existing approaches. On the unconditional CIFAR10 dataset, for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method also demonstrates competitive performance on CelebA-HQ-256 dataset as it obtains an FID score of 7.11. Code is available at https://github.com/MohsenZand/DiNof.
</details>
<details>
<summary>摘要</summary>
For faster sampling and higher sample quality, we propose DiNof (diffusion with normalizing flow priors), a technique that combines normalizing flows and diffusion models. We use normalizing flows to parameterize the noisy data at any arbitrary step of the diffusion process and use it as the prior in the reverse diffusion process. Specifically, the forward noising process converts a data distribution into partially noisy data, which are then transformed into a Gaussian distribution through a nonlinear process. The backward denoising process starts with a prior created by sampling from the Gaussian distribution and applying invertible normalizing flow transformations deterministically. The prior then undergoes the remaining diffusion stochastic denoising procedure to generate the data distribution. By reducing the number of total diffusion steps, we can speed up both the forward and backward processes. Moreover, we improve the expressive power of diffusion models by using both deterministic and stochastic mappings. Experimental results on standard image generation datasets show the advantage of our proposed method over existing approaches. On the unconditional CIFAR10 dataset, for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method also demonstrates competitive performance on the CelebA-HQ-256 dataset, with an FID score of 7.11. Code is available at https://github.com/MohsenZand/DiNof.Here's the translation in Traditional Chinese:为了更快速的抽样和提高抽样质量，我们提出了DiNof（diffusion with normalizing flow priors）技术，该技术结合了normalizing flows和diffusion models。我们使用normalizing flows来对任意步骤的diffusion проце程中的噪声数据进行参数化，并将其用作反diffusion проце程中的假设。具体来说，前向噪声过程将数据分布转换成部分噪声的数据，然后通过非线性过程将其转换为Gaussian分布。反对噪声过程从Gaussian分布中随机抽样获得一个假设，并通过实现可逆的normalizing flow对应映射来确定性地将其转换为数据分布。通过缩减总diffusion步骤数量，我们可以快速化前向和反对噪声过程。更重要的是，我们通过使用deterministic和stochastic mapping来提高diffusion模型的表达力。实验结果显示，我们在标准的图像生成 dataset上比较其他方法表现出色，例如在CIFAR10 dataset上，我们获得了FID值为2.01和inception值为9.96。我们的方法也在CelebA-HQ-256 dataset上表现出色，FID值为7.11。相关的代码可以在https://github.com/MohsenZand/DiNof上获取。
</details></li>
</ul>
<hr>
<h2 id="SOAR-Scene-debiasing-Open-set-Action-Recognition"><a href="#SOAR-Scene-debiasing-Open-set-Action-Recognition" class="headerlink" title="SOAR: Scene-debiasing Open-set Action Recognition"></a>SOAR: Scene-debiasing Open-set Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01265">http://arxiv.org/abs/2309.01265</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yhZhai/SOAR">https://github.com/yhZhai/SOAR</a></li>
<li>paper_authors: Yuanhao Zhai, Ziyi Liu, Zhenyu Wu, Yi Wu, Chunluan Zhou, David Doermann, Junsong Yuan, Gang Hua</li>
<li>for:  mitigating the risk of utilizing spurious clues in open-set action recognition</li>
<li>methods:  adversarial scene reconstruction module, adaptive adversarial scene classification module</li>
<li>results:  better mitigation of scene bias, outperformance of state-of-the-art methodsHere’s the simplified Chinese text:</li>
<li>for: 开普设置动作识别中减少背景信息</li>
<li>methods:  adversarial scene reconstruction module, adaptive adversarial scene classification module</li>
<li>results: 更好地减少场景偏见, 超过当前最佳方法表现I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Deep learning models have a risk of utilizing spurious clues to make predictions, such as recognizing actions based on the background scene. This issue can severely degrade the open-set action recognition performance when the testing samples have different scene distributions from the training samples. To mitigate this problem, we propose a novel method, called Scene-debiasing Open-set Action Recognition (SOAR), which features an adversarial scene reconstruction module and an adaptive adversarial scene classification module. The former prevents the decoder from reconstructing the video background given video features, and thus helps reduce the background information in feature learning. The latter aims to confuse scene type classification given video features, with a specific emphasis on the action foreground, and helps to learn scene-invariant information. In addition, we design an experiment to quantify the scene bias. The results indicate that the current open-set action recognizers are biased toward the scene, and our proposed SOAR method better mitigates such bias. Furthermore, our extensive experiments demonstrate that our method outperforms state-of-the-art methods, and the ablation studies confirm the effectiveness of our proposed modules.
</details>
<details>
<summary>摘要</summary>
深度学习模型可能会利用干扰信号来做预测，如recognize动作基于背景场景。这个问题可能会严重降低开集动作认识性能，因为测试样本的场景分布与训练样本不同。为了解决这个问题，我们提出了一种新方法，叫做Scene-debiasing Open-set Action Recognition（SOAR），它包括一个对抗场景重建模块和一个适应对抗场景分类模块。前者防止解码器基于视频特征重建视频背景，从而减少视频背景的影响。后者强调动作前景，尝试使场景类型分类不分化，以学习场景不变的信息。此外，我们设计了一个测量场景偏见的实验。结果表明，当前的开集动作认识器偏向场景，而我们提出的SOAR方法更好地 mitigates such bias。此外，我们的广泛实验表明，我们的方法高效地超过了当前的状态实验，而ablation studies也证明了我们的提出的模块的效果。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Contrastive-Learning-with-Hard-Negative-Sampling-for-Human-Activity-Recognition"><a href="#Multimodal-Contrastive-Learning-with-Hard-Negative-Sampling-for-Human-Activity-Recognition" class="headerlink" title="Multimodal Contrastive Learning with Hard Negative Sampling for Human Activity Recognition"></a>Multimodal Contrastive Learning with Hard Negative Sampling for Human Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01262">http://arxiv.org/abs/2309.01262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeongju Choi, Apoorva Beedu, Irfan Essa</li>
<li>for: 这种研究旨在提高人员活动识别（HAR）系统的性能，特别是在日常生活中使用自助学习方法，以减少 annotated data 的成本和困难。</li>
<li>methods: 我们提出了一种基于强负样本选择的自助学习方法，使用硬负样本损失函数，并在 Camera 和 IMU 感知器数据集上进行实验。</li>
<li>results: 我们的方法在两个标准 benchmark 数据集上（UTD-MHAD 和 MMAct）表现出色，在有限数据设置下学习强的特征表示，并在下游活动识别任务中超过了所有现有的状态艺术方法。<details>
<summary>Abstract</summary>
Human Activity Recognition (HAR) systems have been extensively studied by the vision and ubiquitous computing communities due to their practical applications in daily life, such as smart homes, surveillance, and health monitoring.   Typically, this process is supervised in nature and the development of such systems requires access to large quantities of annotated data.   However, the higher costs and challenges associated with obtaining good quality annotations have rendered the application of self-supervised methods an attractive option and contrastive learning comprises one such method.   However, a major component of successful contrastive learning is the selection of good positive and negative samples.   Although positive samples are directly obtainable, sampling good negative samples remain a challenge.   As human activities can be recorded by several modalities like camera and IMU sensors, we propose a hard negative sampling method for multimodal HAR with a hard negative sampling loss for skeleton and IMU data pairs.   We exploit hard negatives that have different labels from the anchor but are projected nearby in the latent space using an adjustable concentration parameter.   Through extensive experiments on two benchmark datasets: UTD-MHAD and MMAct, we demonstrate the robustness of our approach forlearning strong feature representation for HAR tasks, and on the limited data setting.   We further show that our model outperforms all other state-of-the-art methods for UTD-MHAD dataset, and self-supervised methods for MMAct: Cross session, even when uni-modal data are used during downstream activity recognition.
</details>
<details>
<summary>摘要</summary>
人工活动识别（HAR）系统在视觉和无限计算领域得到了广泛的研究，因为它在日常生活中有很多实际应用，如智能家居、监测和健康监测。 Typically, this process is supervised in nature, and the development of such systems requires access to large amounts of annotated data. However, the higher costs and challenges associated with obtaining good quality annotations have made self-supervised methods an attractive option. Contrastive learning is one such method, but selecting good positive and negative samples is a major challenge. Although positive samples are directly obtainable, sampling good negative samples remains a challenge.为解决这个问题，我们提出了一种困难的负样本选择方法 для多modal HAR，并使用一个可调的集中参数来选择硬负样本。 We exploit hard negatives that have different labels from the anchor but are projected nearby in the latent space. Through extensive experiments on two benchmark datasets: UTD-MHAD and MMAct, we demonstrate the robustness of our approach for learning strong feature representations for HAR tasks, and on limited data settings. We further show that our model outperforms all other state-of-the-art methods for UTD-MHAD dataset, and self-supervised methods for MMAct: Cross session, even when uni-modal data are used during downstream activity recognition.
</details></li>
</ul>
<hr>
<h2 id="S2RF-Semantically-Stylized-Radiance-Fields"><a href="#S2RF-Semantically-Stylized-Radiance-Fields" class="headerlink" title="S2RF: Semantically Stylized Radiance Fields"></a>S2RF: Semantically Stylized Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01252">http://arxiv.org/abs/2309.01252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dishani Lahiri, Neeraj Panse, Moneish Kumar</li>
<li>for: 提供一种将任意图像中的风格传递到3D场景中的对象上的方法。</li>
<li>methods: 提议一种 nearest neighborhood-based loss 的新方法，以实现更好的3D场景重建和灵活的风格定制，同时保证多视角准确性。</li>
<li>results: 方法可以实现自由的3D场景重建和灵活的风格定制，并保证多视角准确性。<details>
<summary>Abstract</summary>
We present our method for transferring style from any arbitrary image(s) to object(s) within a 3D scene. Our primary objective is to offer more control in 3D scene stylization, facilitating the creation of customizable and stylized scene images from arbitrary viewpoints. To achieve this, we propose a novel approach that incorporates nearest neighborhood-based loss, allowing for flexible 3D scene reconstruction while effectively capturing intricate style details and ensuring multi-view consistency.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，可以将任意图像中的风格传递到3D场景中的对象上。我们的主要目标是为3D场景增加个性化风格控制，以便从任意视角创建个性化和风格化的场景图像。为 достичь这个目标，我们提议一种新的方法，该方法包括最近邻域基于的损失函数，可以在3D场景重建中 flexible 地捕捉细节，同时保证多视角一致性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Generic-Image-Manipulation-Detection-with-Weakly-Supervised-Self-Consistency-Learning"><a href="#Towards-Generic-Image-Manipulation-Detection-with-Weakly-Supervised-Self-Consistency-Learning" class="headerlink" title="Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning"></a>Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01246">http://arxiv.org/abs/2309.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yhZhai/WSCL">https://github.com/yhZhai/WSCL</a></li>
<li>paper_authors: Yuanhao Zhai, Tianyu Luan, David Doermann, Junsong Yuan<br>for: 本文主要针对于强制性较低的图像修饰检测问题，以便利用更多的训练图像和快速适应新的修饰技术。methods: 本文提出了一种弱类supervised自适应学习方法，仅需要图像水平的二分类标签（真实或修饰）进行训练。该方法利用了多种内容无关的信息，通过在线pseudo标签生成和优化过程实现了跨源学习。此外，本文还提出了一种inter-patch consistency（IPC）方法，可以找到整个修饰区域。results: 实验表明，even though our方法是弱类supervised的，它在受检测图像是否修饰的情况下，与完全supervised方法相比，具有竞争性的性能，并且可以准确地找到修饰区域。<details>
<summary>Abstract</summary>
As advanced image manipulation techniques emerge, detecting the manipulation becomes increasingly important. Despite the success of recent learning-based approaches for image manipulation detection, they typically require expensive pixel-level annotations to train, while exhibiting degraded performance when testing on images that are differently manipulated compared with training images. To address these limitations, we propose weakly-supervised image manipulation detection, such that only binary image-level labels (authentic or tampered with) are required for training purpose. Such a weakly-supervised setting can leverage more training images and has the potential to adapt quickly to new manipulation techniques. To improve the generalization ability, we propose weakly-supervised self-consistency learning (WSCL) to leverage the weakly annotated images. Specifically, two consistency properties are learned: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits different content-agnostic information and enables cross-source learning via an online pseudo label generation and refinement process. IPC performs global pair-wise patch-patch relationship reasoning to discover a complete region of manipulation. Extensive experiments validate that our WSCL, even though is weakly supervised, exhibits competitive performance compared with fully-supervised counterpart under both in-distribution and out-of-distribution evaluations, as well as reasonable manipulation localization ability.
</details>
<details>
<summary>摘要</summary>
As advanced image manipulation techniques emerge, detecting the manipulation becomes increasingly important. Despite the success of recent learning-based approaches for image manipulation detection, they typically require expensive pixel-level annotations to train, while exhibiting degraded performance when testing on images that are differently manipulated compared with training images. To address these limitations, we propose weakly-supervised image manipulation detection, such that only binary image-level labels (authentic or tampered with) are required for training purpose. Such a weakly-supervised setting can leverage more training images and has the potential to adapt quickly to new manipulation techniques. To improve the generalization ability, we propose weakly-supervised self-consistency learning (WSCL) to leverage the weakly annotated images. Specifically, two consistency properties are learned: multi-source consistency (MSC) and inter-patch consistency (IPC). MSC exploits different content-agnostic information and enables cross-source learning via an online pseudo label generation and refinement process. IPC performs global pair-wise patch-patch relationship reasoning to discover a complete region of manipulation. Extensive experiments validate that our WSCL, even though is weakly supervised, exhibits competitive performance compared with fully-supervised counterpart under both in-distribution and out-of-distribution evaluations, as well as reasonable manipulation localization ability.Here's the translation in Traditional Chinese:为了应对进阶图像修饰技术的出现，检测修饰成本日益重要。 despite recent learning-based approaches for image manipulation detection的成功，它们通常需要高昂的像素级标注来训练，而且在训练和测试图像不同的修饰方法时，表现会下降。为了解决这些限制，我们提出了弱型图像修饰检测，仅需要图像水平标注（真实或伪造）来训练。这样的弱型设定可以对更多的训练图像进行学习，并且具有适应新修饰技术的潜力。为了提高普遍性，我们提出了弱型自适应学习（WSCL），以利用弱型标注图像。具体来说，我们学习了两种一致性属性：多源一致性（MSC）和间接图像一致性（IPC）。MSC 利用不同内容不相关的信息，并允许跨源学习 via 线上 pseudo 标签生成和修正过程。IPC 执行全域对 patch-patch 关系的全球推理，以发现修饰区域。实验显示，我们的 WSCL ，即使是弱型学习，在两个分布中的评估中表现竞争性好，以及修饰地域的实际能力。
</details></li>
</ul>
<hr>
<h2 id="BodySLAM-Fast-and-Tightly-Coupled-Visual-Inertial-Camera-and-Human-Motion-Tracking"><a href="#BodySLAM-Fast-and-Tightly-Coupled-Visual-Inertial-Camera-and-Human-Motion-Tracking" class="headerlink" title="BodySLAM++: Fast and Tightly-Coupled Visual-Inertial Camera and Human Motion Tracking"></a>BodySLAM++: Fast and Tightly-Coupled Visual-Inertial Camera and Human Motion Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01236">http://arxiv.org/abs/2309.01236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dorian F. Henning, Christopher Choi, Simon Schaefer, Stefan Leutenegger</li>
<li>for: 这篇论文是为了解决人体状态估计问题，尤其是在实际应用中需要实时估计人体状态的情况下。</li>
<li>methods: 该论文使用了视觉感知和自适应器来实现人体和摄像头状态估计，并将现有的视觉感知状态估计框架OKVIS2扩展到同时解决人体和摄像头状态估计的双重任务。</li>
<li>results: 相比基准方法，该方法可以提高人体状态估计的准确性和摄像头状态估计的准确性，并在Intel i7-模型CPU上实现15+帧每秒的实时性。<details>
<summary>Abstract</summary>
Robust, fast, and accurate human state - 6D pose and posture - estimation remains a challenging problem. For real-world applications, the ability to estimate the human state in real-time is highly desirable. In this paper, we present BodySLAM++, a fast, efficient, and accurate human and camera state estimation framework relying on visual-inertial data. BodySLAM++ extends an existing visual-inertial state estimation framework, OKVIS2, to solve the dual task of estimating camera and human states simultaneously. Our system improves the accuracy of both human and camera state estimation with respect to baseline methods by 26% and 12%, respectively, and achieves real-time performance at 15+ frames per second on an Intel i7-model CPU. Experiments were conducted on a custom dataset containing both ground truth human and camera poses collected with an indoor motion tracking system.
</details>
<details>
<summary>摘要</summary>
Robust、快速、精确的人体状态估算——6D姿态和姿态——仍然是一个挑战性的问题。在实际应用中，可以在实时中估算人体状态是非常感兴趣的。在这篇论文中，我们提出了BodySLAM++，一种基于视觉-陀螺数据的人体和摄像头状态估算框架。BodySLAM++在OKVIS2视觉-陀螺状态估算框架的基础上进行了扩展，同时解决了同时估算摄像头和人体状态的两个任务。我们的系统相比基准方法提高了人体和摄像头状态估算的准确性，增加了26%和12%，并在Intel i7-型CPU上实现了15+帧每秒的实时性。我们在一个自定义的人体和摄像头pose的数据集上进行了实验。
</details></li>
</ul>
<hr>
<h2 id="Generalizability-and-Application-of-the-Skin-Reflectance-Estimate-Based-on-Dichromatic-Separation-SREDS"><a href="#Generalizability-and-Application-of-the-Skin-Reflectance-Estimate-Based-on-Dichromatic-Separation-SREDS" class="headerlink" title="Generalizability and Application of the Skin Reflectance Estimate Based on Dichromatic Separation (SREDS)"></a>Generalizability and Application of the Skin Reflectance Estimate Based on Dichromatic Separation (SREDS)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01235">http://arxiv.org/abs/2309.01235</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/josephdrahos/sreds">https://github.com/josephdrahos/sreds</a></li>
<li>paper_authors: Joseph Drahos, Richard Plesh, Keivan Bahmani, Mahesh Banavar, Stephanie Schuckers</li>
<li>for: 本研究旨在提供一种可靠的皮肤颜色度量，以便在面 recognition系统中减少因皮肤颜色而导致的性能差异。</li>
<li>methods: 本研究使用了基于 dichromatic separation 的皮肤颜色度量（SREDS），并对其进行了进一步的分析和评估。</li>
<li>results: 研究发现，SREDS 能够创造一个具有较低差异的皮肤颜色度量，并且可以作为自我报告的种族标签的替代方案。此外，研究还提供了一个开源的 SREDS 实现，以帮助研究人员。<details>
<summary>Abstract</summary>
Face recognition (FR) systems have become widely used and readily available in recent history. However, differential performance between certain demographics has been identified within popular FR models. Skin tone differences between demographics can be one of the factors contributing to the differential performance observed in face recognition models. Skin tone metrics provide an alternative to self-reported race labels when such labels are lacking or completely not available e.g. large-scale face recognition datasets. In this work, we provide a further analysis of the generalizability of the Skin Reflectance Estimate based on Dichromatic Separation (SREDS) against other skin tone metrics and provide a use case for substituting race labels for SREDS scores in a privacy-preserving learning solution. Our findings suggest that SREDS consistently creates a skin tone metric with lower variability within each subject and SREDS values can be utilized as an alternative to the self-reported race labels at minimal drop in performance. Finally, we provide a publicly available and open-source implementation of SREDS to help the research community. Available at https://github.com/JosephDrahos/SREDS
</details>
<details>
<summary>摘要</summary>
人脸识别（FR）系统在近代历史中广泛使用和可用。然而， differential performance between certain demographics 在流行的 FR 模型中被识别出来。skin tone differences between demographics can be one of the factors contributing to the differential performance observed in face recognition models。skin tone metrics provide an alternative to self-reported race labels when such labels are lacking or completely not available, for example, large-scale face recognition datasets.在这项工作中，我们进一步分析了Skin Reflectance Estimate based on Dichromatic Separation（SREDS）与其他皮肤颜色指标的一致性，并提供了使用 SREDS  scores substitute for race labels in a privacy-preserving learning solution的用例。我们发现，SREDS  consistently creates a skin tone metric with lower variability within each subject, and SREDS values can be used as an alternative to self-reported race labels at minimal drop in performance。最后，我们提供了一个公共可用的和开源的 SREDS 实现，以帮助研究社区。可以在 <https://github.com/JosephDrahos/SREDS> 查看。
</details></li>
</ul>
<hr>
<h2 id="Spectral-Adversarial-MixUp-for-Few-Shot-Unsupervised-Domain-Adaptation"><a href="#Spectral-Adversarial-MixUp-for-Few-Shot-Unsupervised-Domain-Adaptation" class="headerlink" title="Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation"></a>Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01207">http://arxiv.org/abs/2309.01207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/RPIDIAL/SAMix">https://github.com/RPIDIAL/SAMix</a></li>
<li>paper_authors: Jiajin Zhang, Hanqing Chao, Amit Dhurandhar, Pin-Yu Chen, Ali Tajer, Yangyang Xu, Pingkun Yan</li>
<li>for: 本研究旨在 Addressing the challenging problem of few-shot unsupervised domain adaptation (FSUDA) in clinical applications, where only a limited number of unlabeled target domain samples are available for training.</li>
<li>methods: 我们提出了一种新的方法，即 spectral sensitivity map 和 sensitivity-guided spectral adversarial mixup (SAMix) 方法，以强化模型在目标频谱中的一致性和模型通用性。</li>
<li>results: 我们在多个任务和数据集上进行了严谨的评估，并证明了我们的方法可以有效地提高模型在目标频谱中的一致性和模型通用性。<details>
<summary>Abstract</summary>
Domain shift is a common problem in clinical applications, where the training images (source domain) and the test images (target domain) are under different distributions. Unsupervised Domain Adaptation (UDA) techniques have been proposed to adapt models trained in the source domain to the target domain. However, those methods require a large number of images from the target domain for model training. In this paper, we propose a novel method for Few-Shot Unsupervised Domain Adaptation (FSUDA), where only a limited number of unlabeled target domain samples are available for training. To accomplish this challenging task, first, a spectral sensitivity map is introduced to characterize the generalization weaknesses of models in the frequency domain. We then developed a Sensitivity-guided Spectral Adversarial MixUp (SAMix) method to generate target-style images to effectively suppresses the model sensitivity, which leads to improved model generalizability in the target domain. We demonstrated the proposed method and rigorously evaluated its performance on multiple tasks using several public datasets.
</details>
<details>
<summary>摘要</summary>
域名转换是在医疗应用中的一个常见问题，source domain 和 target domain 的图像分布不同。不supervised Domain Adaptation（UDA）技术已经被提议，以适应source domain 中训练的模型到 target domain。然而，这些方法需要大量的target domain图像来训练模型。在这篇论文中，我们提出了一种新的方法：Few-Shot Unsupervised Domain Adaptation（FSUDA），只需要有限量的target domain样本进行训练。为了实现这个复杂的任务，我们首先引入了一个spectral sensitivity map来描述模型在频率域的泛化弱点。然后，我们开发了一种Sensitivity-guided Spectral Adversarial MixUp（SAMix）方法，可以生成target-style图像，以有效地减少模型的敏感性，从而提高模型在target domain的泛化性。我们证明了我们的方法的可行性和对多个任务的精心评估。
</details></li>
</ul>
<hr>
<h2 id="MAGMA-Music-Aligned-Generative-Motion-Autodecoder"><a href="#MAGMA-Music-Aligned-Generative-Motion-Autodecoder" class="headerlink" title="MAGMA: Music Aligned Generative Motion Autodecoder"></a>MAGMA: Music Aligned Generative Motion Autodecoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01202">http://arxiv.org/abs/2309.01202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sohan Anisetty, Amit Raj, James Hays</li>
<li>for: 这 paper 的目的是解决将乐曲映射到舞蹈中的问题，以实现空间和时间协调，同时与乐曲的进程保持同步。</li>
<li>methods: 作者使用 Vector Quantized-Variational Autoencoder (VQ-VAE) 和 Transformer 解码器，将动作划分成基本 primitives，并通过对音乐表示的比较来评估音乐表示的重要性。</li>
<li>results: 作者的方法可以实现州际最佳的音乐到动作生成效果，并可以生成较长的动作序列，易于自定义动作序列以满足风格要求。<details>
<summary>Abstract</summary>
Mapping music to dance is a challenging problem that requires spatial and temporal coherence along with a continual synchronization with the music's progression. Taking inspiration from large language models, we introduce a 2-step approach for generating dance using a Vector Quantized-Variational Autoencoder (VQ-VAE) to distill motion into primitives and train a Transformer decoder to learn the correct sequencing of these primitives. We also evaluate the importance of music representations by comparing naive music feature extraction using Librosa to deep audio representations generated by state-of-the-art audio compression algorithms. Additionally, we train variations of the motion generator using relative and absolute positional encodings to determine the effect on generated motion quality when generating arbitrarily long sequence lengths. Our proposed approach achieve state-of-the-art results in music-to-motion generation benchmarks and enables the real-time generation of considerably longer motion sequences, the ability to chain multiple motion sequences seamlessly, and easy customization of motion sequences to meet style requirements.
</details>
<details>
<summary>摘要</summary>
将音乐映射到舞蹈是一个挑战性的问题，需要空间和时间协调以及 continual 同步音乐的进程。引用大语言模型，我们提出了一种 two-step 方法，使用 вектор量化-自适应编码器（VQ-VAE）来压缩动作并训练 transformer 解码器来学习正确的动作顺序。我们还评估音乐表示的重要性，比较 naive 音乐特征提取使用 Librosa 和深度音频表示生成器生成的音频特征。此外，我们在不同的 poz 编码器和绝对 poz 编码器进行训练，以确定在生成长序列时的影响。我们的提出方法在音乐到动作生成标准准则中实现了状态顶峰的结果，可以实时生成较长的动作序列，链接多个动作序列，以及根据风格要求自由定制动作序列。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Dynamic-Frequency-Transformer-for-Image-Fusion-and-Exposure-Correction"><a href="#Holistic-Dynamic-Frequency-Transformer-for-Image-Fusion-and-Exposure-Correction" class="headerlink" title="Holistic Dynamic Frequency Transformer for Image Fusion and Exposure Correction"></a>Holistic Dynamic Frequency Transformer for Image Fusion and Exposure Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01183">http://arxiv.org/abs/2309.01183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoke Shang, Gehui Li, Zhiying Jiang, Shaomin Zhang, Nai Ding, Jinyuan Liu</li>
<li>for: 提高图像质量，解决曝光相关问题</li>
<li>methods: 利用频域回归，替代传统的相关计算，使用全息频域注意力和动态频域前向网络来提取全息信息，并使用拉普拉斯 pyramid  decomposes 图像为不同频率带信息，然后使用多个修复器来恢复特定频率带信息</li>
<li>results: 实现了主流数据集上的最佳Result，为曝光 corrections 等computer vision任务提供了更加细致和协调的解决方案<details>
<summary>Abstract</summary>
The correction of exposure-related issues is a pivotal component in enhancing the quality of images, offering substantial implications for various computer vision tasks. Historically, most methodologies have predominantly utilized spatial domain recovery, offering limited consideration to the potentialities of the frequency domain. Additionally, there has been a lack of a unified perspective towards low-light enhancement, exposure correction, and multi-exposure fusion, complicating and impeding the optimization of image processing. In response to these challenges, this paper proposes a novel methodology that leverages the frequency domain to improve and unify the handling of exposure correction tasks. Our method introduces Holistic Frequency Attention and Dynamic Frequency Feed-Forward Network, which replace conventional correlation computation in the spatial-domain. They form a foundational building block that facilitates a U-shaped Holistic Dynamic Frequency Transformer as a filter to extract global information and dynamically select important frequency bands for image restoration. Complementing this, we employ a Laplacian pyramid to decompose images into distinct frequency bands, followed by multiple restorers, each tuned to recover specific frequency-band information. The pyramid fusion allows a more detailed and nuanced image restoration process. Ultimately, our structure unifies the three tasks of low-light enhancement, exposure correction, and multi-exposure fusion, enabling comprehensive treatment of all classical exposure errors. Benchmarking on mainstream datasets for these tasks, our proposed method achieves state-of-the-art results, paving the way for more sophisticated and unified solutions in exposure correction.
</details>
<details>
<summary>摘要</summary>
correction of exposure-related issues 是图像质量进步的关键组件，具有广泛的计算机视觉应用场景。历史上，大多数方法ologies 都是在空间领域进行恢复，忽略了频率领域的潜在优势。此外，对于低光照修复、曝光修复和多曝光融合，缺乏一个统一的视角，使得图像处理优化受到妨碍。为了解决这些挑战，本文提出了一种新的方法，利用频率领域来改善和统一曝光修复任务。我们的方法引入全局频率注意力和动态频率预测网络，取代了传统的空间领域相关计算。它们组成了基本建构块，使得U-形全局动态频率变换器作为筛选器，以EXTRACT全局信息和动态选择重要的频率带width。此外，我们采用拉普拉斯 pyramid  decomposed 图像到不同的频率带width，然后使用多个恢复器，每个恢复器都是针对特定频率带width 的信息恢复。pyramid 融合allowing 更加细致和细腻的图像修复过程。最终，我们的结构统一了三个任务：低光照修复、曝光修复和多曝光融合，使得全面地处理所有传统曝光错误。在主流数据集上 benchmarking，我们提出的方法实现了状态之前的成绩，开启了更加复杂和统一的曝光修复解决方案。
</details></li>
</ul>
<hr>
<h2 id="Deep-Unfolding-Convolutional-Dictionary-Model-for-Multi-Contrast-MRI-Super-resolution-and-Reconstruction"><a href="#Deep-Unfolding-Convolutional-Dictionary-Model-for-Multi-Contrast-MRI-Super-resolution-and-Reconstruction" class="headerlink" title="Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction"></a>Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01171">http://arxiv.org/abs/2309.01171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lpcccc-cv/mc-cdic">https://github.com/lpcccc-cv/mc-cdic</a></li>
<li>paper_authors: Pengcheng Lei, Faming Fang, Guixu Zhang, Ming Xu</li>
<li>for: 这个论文主要是为了提出一个基于深度学习的多测量MRI超解析和重建方法，以探索多测量图像之间的联乘关系。</li>
<li>methods: 本文提出了一个叫做多测量 convolutional dictionary（MC-CDic）模型，利用优化算法和构造资料实际关系来实现多测量图像之间的联乘。MC-CDic模型包括建立观察模型、构造多测量字典和使用 proximal 算法来优化模型。</li>
<li>results: 实验结果显示，MC-CDic模型在多测量MRI超解析和重建任务中具有较高的性能，较以前的State-of-the-Art方法。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) tasks often involve multiple contrasts. Recently, numerous deep learning-based multi-contrast MRI super-resolution (SR) and reconstruction methods have been proposed to explore the complementary information from the multi-contrast images. However, these methods either construct parameter-sharing networks or manually design fusion rules, failing to accurately model the correlations between multi-contrast images and lacking certain interpretations. In this paper, we propose a multi-contrast convolutional dictionary (MC-CDic) model under the guidance of the optimization algorithm with a well-designed data fidelity term. Specifically, we bulid an observation model for the multi-contrast MR images to explicitly model the multi-contrast images as common features and unique features. In this way, only the useful information in the reference image can be transferred to the target image, while the inconsistent information will be ignored. We employ the proximal gradient algorithm to optimize the model and unroll the iterative steps into a deep CDic model. Especially, the proximal operators are replaced by learnable ResNet. In addition, multi-scale dictionaries are introduced to further improve the model performance. We test our MC-CDic model on multi-contrast MRI SR and reconstruction tasks. Experimental results demonstrate the superior performance of the proposed MC-CDic model against existing SOTA methods. Code is available at https://github.com/lpcccc-cv/MC-CDic.
</details>
<details>
<summary>摘要</summary>
magnetic resonance imaging (MRI) 任务 oftentimes involve multiple contrasts. Recently, numerous deep learning-based multi-contrast MRI super-resolution (SR) and reconstruction methods have been proposed to explore the complementary information from the multi-contrast images. However, these methods either construct parameter-sharing networks or manually design fusion rules, failing to accurately model the correlations between multi-contrast images and lacking certain interpretations.In this paper, we propose a multi-contrast convolutional dictionary (MC-CDic) model under the guidance of the optimization algorithm with a well-designed data fidelity term. Specifically, we bulid an observation model for the multi-contrast MR images to explicitly model the multi-contrast images as common features and unique features. In this way, only the useful information in the reference image can be transferred to the target image, while the inconsistent information will be ignored.We employ the proximal gradient algorithm to optimize the model and unroll the iterative steps into a deep CDic model. Especially, the proximal operators are replaced by learnable ResNet. In addition, multi-scale dictionaries are introduced to further improve the model performance.We test our MC-CDic model on multi-contrast MRI SR and reconstruction tasks. Experimental results demonstrate the superior performance of the proposed MC-CDic model against existing state-of-the-art (SOTA) methods. Code is available at https://github.com/lpcccc-cv/MC-CDic.
</details></li>
</ul>
<hr>
<h2 id="An-Asynchronous-Linear-Filter-Architecture-for-Hybrid-Event-Frame-Cameras"><a href="#An-Asynchronous-Linear-Filter-Architecture-for-Hybrid-Event-Frame-Cameras" class="headerlink" title="An Asynchronous Linear Filter Architecture for Hybrid Event-Frame Cameras"></a>An Asynchronous Linear Filter Architecture for Hybrid Event-Frame Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01159">http://arxiv.org/abs/2309.01159</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ziweiwwang/event-asynchronous-filter">https://github.com/ziweiwwang/event-asynchronous-filter</a></li>
<li>paper_authors: Ziwei Wang, Yonhon Ng, Cedric Scheerlinck, Robert Mahony</li>
<li>for: 这篇论文是为了描述一种基于事件和帧camera数据的协同筛选框架，用于重建HDR视频和空间卷积。</li>
<li>methods: 该框架使用了 asynchronous linear filter architecture，将事件和帧camera数据 fusion，以优化HDR视频重建和空间卷积。</li>
<li>results: 对于公共的 datasets，该方法与其他状态艺法比较，在灰度误差率（69.4%减少）和图像相似性指标（均提高35.5%）中表现出色。此外，该框架还可以将图像卷积与线性空间核积合并应用。<details>
<summary>Abstract</summary>
Event cameras are ideally suited to capture High Dynamic Range (HDR) visual information without blur but provide poor imaging capability for static or slowly varying scenes. Conversely, conventional image sensors measure absolute intensity of slowly changing scenes effectively but do poorly on HDR or quickly changing scenes. In this paper, we present an asynchronous linear filter architecture, fusing event and frame camera data, for HDR video reconstruction and spatial convolution that exploits the advantages of both sensor modalities. The key idea is the introduction of a state that directly encodes the integrated or convolved image information and that is updated asynchronously as each event or each frame arrives from the camera. The state can be read-off as-often-as and whenever required to feed into subsequent vision modules for real-time robotic systems. Our experimental results are evaluated on both publicly available datasets with challenging lighting conditions and fast motions, along with a new dataset with HDR reference that we provide. The proposed AKF pipeline outperforms other state-of-the-art methods in both absolute intensity error (69.4% reduction) and image similarity indexes (average 35.5% improvement). We also demonstrate the integration of image convolution with linear spatial kernels Gaussian, Sobel, and Laplacian as an application of our architecture.
</details>
<details>
<summary>摘要</summary>
The key idea is to introduce a state that encodes the integrated or convolved image information and is updated asynchronously as each event or frame arrives from the camera. This state can be read off as often as required to feed into subsequent vision modules for real-time robotic systems. Our experimental results are evaluated on publicly available datasets with challenging lighting conditions and fast motions, as well as a new dataset with HDR reference that we provide.Compared to other state-of-the-art methods, our proposed asynchronous kernel filter (AKF) pipeline achieves a 69.4% reduction in absolute intensity error and an average 35.5% improvement in image similarity indexes. We also demonstrate the integration of image convolution with linear spatial kernels, such as Gaussian, Sobel, and Laplacian, as an application of our architecture.
</details></li>
</ul>
<hr>
<h2 id="LoGoPrompt-Synthetic-Text-Images-Can-Be-Good-Visual-Prompts-for-Vision-Language-Models"><a href="#LoGoPrompt-Synthetic-Text-Images-Can-Be-Good-Visual-Prompts-for-Vision-Language-Models" class="headerlink" title="LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models"></a>LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01155">http://arxiv.org/abs/2309.01155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 提高预训练模型在下游任务中的性能，尤其是图像识别领域</li>
<li>methods: 使用生成的文本图像作为视觉提示，并解决了鸡蛋问题</li>
<li>results: 在16个 datasets上，方法 consistently outperforms 州际方法，包括几个shot学习、基础到新的泛化和领域泛化<details>
<summary>Abstract</summary>
Prompt engineering is a powerful tool used to enhance the performance of pre-trained models on downstream tasks. For example, providing the prompt ``Let's think step by step" improved GPT-3's reasoning accuracy to 63% on MutiArith while prompting ``a photo of" filled with a class name enables CLIP to achieve $80$\% zero-shot accuracy on ImageNet. While previous research has explored prompt learning for the visual modality, analyzing what constitutes a good visual prompt specifically for image recognition is limited. In addition, existing visual prompt tuning methods' generalization ability is worse than text-only prompting tuning. This paper explores our key insight: synthetic text images are good visual prompts for vision-language models! To achieve that, we propose our LoGoPrompt, which reformulates the classification objective to the visual prompt selection and addresses the chicken-and-egg challenge of first adding synthetic text images as class-wise visual prompts or predicting the class first. Without any trainable visual prompt parameters, experimental results on 16 datasets demonstrate that our method consistently outperforms state-of-the-art methods in few-shot learning, base-to-new generalization, and domain generalization.
</details>
<details>
<summary>摘要</summary>
Prompt engineering是一种强大的工具，可以提高预训练模型在下游任务中表现。例如，提供“思考步骤”的提示可以提高GPT-3的逻辑准确率到63%在MutiArith上，而提示“一张”filled with类名可以使CLIP achieve ImageNet上零基本精度80%。而前期研究已经探索了文本模式下的提示学习，但是对于图像识别领域的视觉提示特别是有限的研究。此外，现有的视觉提示调整方法的通用能力比文本只提示调整更差。这篇论文探讨了我们的关键发现：Synthetic text images是良好的视觉提示 для视觉语言模型！为实现这一点，我们提出了LoGoPrompt，它将类型化目标重新定义为视觉提示选择，并解决了鸡蛋问题，即首先添加synthetic text images为类别视觉提示或预测类型。无需任何可训练的视觉提示参数，我们的方法在16个数据集上实验表明， consistently outperform了当前状态的方法在少shot学习、基础到新的泛化和频率泛化上。
</details></li>
</ul>
<hr>
<h2 id="EdaDet-Open-Vocabulary-Object-Detection-Using-Early-Dense-Alignment"><a href="#EdaDet-Open-Vocabulary-Object-Detection-Using-Early-Dense-Alignment" class="headerlink" title="EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment"></a>EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01151">http://arxiv.org/abs/2309.01151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 提高开放词汇物体检测性能，使检测器在基础类别上训练， yet 能够检测新类别。</li>
<li>methods: 使用 CLIP 强大的零上shot认知能力对象级别的嵌入进行对应。</li>
<li>results: 比如，使用 CLIP 对象级别对接 resulted in overfitting to base categories, i.e., novel categories most similar to base categories have particularly poor performance as they are recognized as similar base categories。 In this paper, we propose Early Dense Alignment (EDA) to bridge the gap between generalizable local semantics and object-level prediction.<details>
<summary>Abstract</summary>
Vision-language models such as CLIP have boosted the performance of open-vocabulary object detection, where the detector is trained on base categories but required to detect novel categories. Existing methods leverage CLIP's strong zero-shot recognition ability to align object-level embeddings with textual embeddings of categories. However, we observe that using CLIP for object-level alignment results in overfitting to base categories, i.e., novel categories most similar to base categories have particularly poor performance as they are recognized as similar base categories. In this paper, we first identify that the loss of critical fine-grained local image semantics hinders existing methods from attaining strong base-to-novel generalization. Then, we propose Early Dense Alignment (EDA) to bridge the gap between generalizable local semantics and object-level prediction. In EDA, we use object-level supervision to learn the dense-level rather than object-level alignment to maintain the local fine-grained semantics. Extensive experiments demonstrate our superior performance to competing approaches under the same strict setting and without using external training resources, i.e., improving the +8.4% novel box AP50 on COCO and +3.9% rare mask AP on LVIS.
</details>
<details>
<summary>摘要</summary>
现代视力语言模型，如CLIP，已经提高了开放词汇物体检测的性能，其中检测器在基本类别上训练，但需要检测新类别。现有方法利用CLIP强大的零shot识别能力将对象级别的嵌入与文本类别嵌入相对 alignment。然而，我们发现使用CLIP进行对象级别对 alignment 会导致基本类别最 Similar novel categories 的表现特别差，即基本类别最 Similar novel categories 的表现特别差。在这篇论文中，我们首先发现了现有方法无法具备强大的基础-to-新泛化的能力，因为loss of critical fine-grained local image semantics 阻碍了现有方法的提升。然后，我们提出了 Early Dense Alignment (EDA) 方法，用于补做这个障碍。在 EDA 中，我们使用对象级别的超级vised learning 来学习 dense-level 的对ignment，以保持本地细致的 semantics。我们的实验表明，我们在同样的严格设定下，不使用外部训练资源，可以提高 COCO 上的 +8.4% novel box AP50 和 LVIS 上的 +3.9% rare mask AP。
</details></li>
</ul>
<hr>
<h2 id="VGDiffZero-Text-to-image-Diffusion-Models-Can-Be-Zero-shot-Visual-Grounders"><a href="#VGDiffZero-Text-to-image-Diffusion-Models-Can-Be-Zero-shot-Visual-Grounders" class="headerlink" title="VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders"></a>VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01141">http://arxiv.org/abs/2309.01141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuyang Liu, Siteng Huang, Yachen Kang, Honggang Chen, Donglin Wang</li>
<li>for: 这个研究的目的是寻找一个可以实现零shot visual grounding的方法，不需要任何调整和额外的训练数据。</li>
<li>methods: 这个方法基于文本与图像散射模型，并提出了一个简单又有效的零shot visual grounding框架，另外还设计了一个考虑全局和局部 контекст的区域评分方法。</li>
<li>results: 实验结果显示，这个方法在RefCOCO、RefCOCO+和RefCOCOg上实现了优秀的零shot visual grounding性能。<details>
<summary>Abstract</summary>
Large-scale text-to-image diffusion models have shown impressive capabilities across various generative tasks, enabled by strong vision-language alignment obtained through pre-training. However, most vision-language discriminative tasks require extensive fine-tuning on carefully-labeled datasets to acquire such alignment, with great cost in time and computing resources. In this work, we explore directly applying a pre-trained generative diffusion model to the challenging discriminative task of visual grounding without any fine-tuning and additional training dataset. Specifically, we propose VGDiffZero, a simple yet effective zero-shot visual grounding framework based on text-to-image diffusion models. We also design a comprehensive region-scoring method considering both global and local contexts of each isolated proposal. Extensive experiments on RefCOCO, RefCOCO+, and RefCOCOg show that VGDiffZero achieves strong performance on zero-shot visual grounding.
</details>
<details>
<summary>摘要</summary>
大规模文本到图像扩散模型已经在多种生成任务中展现出了吸引人的能力，得益于在预训练中获得的强视语对应性。然而，大多数视语识别任务需要大量的时间和计算资源进行精心 Labeling 数据集来获得这种对应性。在这种情况下，我们研究直接将预训练的生成扩散模型应用到挑战性的视觉识别任务中，无需任何 fine-tuning 和额外的训练数据集。特别是，我们提出了一种简单 yet effective 的零shot 视觉定位框架，称为 VGDiffZero。我们还设计了一种全面的区域分配方法，考虑了每个隔离提案的全局和地方上下文。广泛的实验表明，VGDiffZero 在 RefCOCO、RefCOCO+ 和 RefCOCOg 上达到了零shot 视觉定位的强性表现。
</details></li>
</ul>
<hr>
<h2 id="RSDiff-Remote-Sensing-Image-Generation-from-Text-Using-Diffusion-Model"><a href="#RSDiff-Remote-Sensing-Image-Generation-from-Text-Using-Diffusion-Model" class="headerlink" title="RSDiff: Remote Sensing Image Generation from Text Using Diffusion Model"></a>RSDiff: Remote Sensing Image Generation from Text Using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02455">http://arxiv.org/abs/2309.02455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Sebaq, Mohamed ElHelw</li>
<li>for: This paper is written for remote sensing tasks that require high-quality, detailed satellite images for accurate analysis and decision-making.</li>
<li>methods: The paper proposes an innovative and lightweight approach that employs two-stage diffusion models to generate high-resolution satellite images purely based on text prompts. The approach consists of two interconnected diffusion models: a Low-Resolution Generation Diffusion Model (LR-GDM) and a Super-Resolution Diffusion Model (SRDM).</li>
<li>results: The approach outperforms existing state-of-the-art (SoTA) models in generating satellite images with realistic geographical features, weather conditions, and land structures while achieving remarkable super-resolution results for increased spatial precision.Here’s the Chinese version of the information points:</li>
<li>for: 这篇论文是为Remote Sensing任务而写的，需要高质量、细节准确的卫星图像进行准确分析和决策。</li>
<li>methods: 这篇论文提出了一种创新的、轻量级的方法，使用两个阶段的扩散模型来基于文本提示生成高分辨率卫星图像。该方法包括两个相连的扩散模型：一个低分辨率生成扩散模型（LR-GDM）和一个超分辨率扩散模型（SRDM）。</li>
<li>results: 该方法比现有的State-of-the-Art（SoTA）模型在生成卫星图像方面更高效，能够实现更高的地理特征、天气条件和土地结构的准确描述，同时实现了显著的超分辨率效果以提高空间精度。<details>
<summary>Abstract</summary>
Satellite imagery generation and super-resolution are pivotal tasks in remote sensing, demanding high-quality, detailed images for accurate analysis and decision-making. In this paper, we propose an innovative and lightweight approach that employs two-stage diffusion models to gradually generate high-resolution Satellite images purely based on text prompts. Our innovative pipeline comprises two interconnected diffusion models: a Low-Resolution Generation Diffusion Model (LR-GDM) that generates low-resolution images from text and a Super-Resolution Diffusion Model (SRDM) conditionally produced. The LR-GDM effectively synthesizes low-resolution by (computing the correlations of the text embedding and the image embedding in a shared latent space), capturing the essential content and layout of the desired scenes. Subsequently, the SRDM takes the generated low-resolution image and its corresponding text prompts and efficiently produces the high-resolution counterparts, infusing fine-grained spatial details and enhancing visual fidelity. Experiments are conducted on the commonly used dataset, Remote Sensing Image Captioning Dataset (RSICD). Our results demonstrate that our approach outperforms existing state-of-the-art (SoTA) models in generating satellite images with realistic geographical features, weather conditions, and land structures while achieving remarkable super-resolution results for increased spatial precision.
</details>
<details>
<summary>摘要</summary>
卫星图像生成和超解像是远程感知领域的关键任务，需要高质量、详细的图像 для准确的分析和决策。在这篇论文中，我们提出了一种创新的和轻量级的方法，使用两个链接的扩散模型来逐渐生成高分辨率的卫星图像， purely based on text prompts。我们的创新管道包括两个相连的扩散模型：一个低分辨率生成扩散模型（LR-GDM），通过（计算文本嵌入和图像嵌入在共享尺度空间中的相关性）来有效地生成低分辨率图像，捕捉整个场景的主要内容和布局。然后，SRDM模型会使用生成的低分辨率图像和其相应的文本提示，生成高分辨率对应的图像，注入细致的空间细节，提高视觉准确性。我们在Remote Sensing Image Captioning Dataset（RSICD）上进行了实验，我们的方法比现有的SoTA模型在生成卫星图像的realistic geographical features、天气条件和地形结构方面表现出色，同时实现了很高的超分辨率效果，提高了空间精度。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Supervised-Dual-Search-Leveraging-Automatic-Learning-for-Loss-free-Multi-Exposure-Image-Fusion"><a href="#Hybrid-Supervised-Dual-Search-Leveraging-Automatic-Learning-for-Loss-free-Multi-Exposure-Image-Fusion" class="headerlink" title="Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for Loss-free Multi-Exposure Image Fusion"></a>Hybrid-Supervised Dual-Search: Leveraging Automatic Learning for Loss-free Multi-Exposure Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01113">http://arxiv.org/abs/2309.01113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanyao Wu, Hongming Fu, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 本研究目的是解决多 expose 图像融合中的限制，提高图像的Authentic Representation。</li>
<li>methods: 本文提出了一种 Hybrid-Supervised Dual-Search 方法（HSDS-MEF），它使用自动化设计网络结构和损失函数的双级优化搜索算法。</li>
<li>results: 对比Various competitive schemes，本文实现了state-of-the-art表现，在Visual Information Fidelity（VIF）指标上提高10.61%和4.38%，并提供高对比度、丰富细节和颜色的结果。<details>
<summary>Abstract</summary>
Multi-exposure image fusion (MEF) has emerged as a prominent solution to address the limitations of digital imaging in representing varied exposure levels. Despite its advancements, the field grapples with challenges, notably the reliance on manual designs for network structures and loss functions, and the constraints of utilizing simulated reference images as ground truths. Consequently, current methodologies often suffer from color distortions and exposure artifacts, further complicating the quest for authentic image representation. In addressing these challenges, this paper presents a Hybrid-Supervised Dual-Search approach for MEF, dubbed HSDS-MEF, which introduces a bi-level optimization search scheme for automatic design of both network structures and loss functions. More specifically, we harnesses a unique dual research mechanism rooted in a novel weighted structure refinement architecture search. Besides, a hybrid supervised contrast constraint seamlessly guides and integrates with searching process, facilitating a more adaptive and comprehensive search for optimal loss functions. We realize the state-of-the-art performance in comparison to various competitive schemes, yielding a 10.61% and 4.38% improvement in Visual Information Fidelity (VIF) for general and no-reference scenarios, respectively, while providing results with high contrast, rich details and colors.
</details>
<details>
<summary>摘要</summary>
多曝光图像融合（MEF）已成为现代图像捕捉技术的一个主要解决方案，以 Addressing the limitations of digital imaging in representing varied exposure levels. Despite its advancements, the field is still facing challenges, such as the reliance on manual designs for network structures and loss functions, and the constraints of using simulated reference images as ground truths. As a result, current methodologies often suffer from color distortions and exposure artifacts, further complicating the quest for authentic image representation.To address these challenges, this paper proposes a Hybrid-Supervised Dual-Search approach for MEF, called HSDS-MEF, which introduces a bi-level optimization search scheme for automatic design of both network structures and loss functions. Specifically, we leverage a unique dual research mechanism rooted in a novel weighted structure refinement architecture search. Moreover, a hybrid supervised contrast constraint seamlessly guides and integrates with the searching process, facilitating a more adaptive and comprehensive search for optimal loss functions.We demonstrate the state-of-the-art performance of HSDS-MEF compared to various competitive schemes, with a 10.61% and 4.38% improvement in Visual Information Fidelity (VIF) for general and no-reference scenarios, respectively. The results show high contrast, rich details, and vivid colors.
</details></li>
</ul>
<hr>
<h2 id="ArSDM-Colonoscopy-Images-Synthesis-with-Adaptive-Refinement-Semantic-Diffusion-Models"><a href="#ArSDM-Colonoscopy-Images-Synthesis-with-Adaptive-Refinement-Semantic-Diffusion-Models" class="headerlink" title="ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models"></a>ArSDM: Colonoscopy Images Synthesis with Adaptive Refinement Semantic Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01111">http://arxiv.org/abs/2309.01111</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/duyooho/arsdm">https://github.com/duyooho/arsdm</a></li>
<li>paper_authors: Yuhao Du, Yuncheng Jiang, Shuangyi Tan, Xusheng Wu, Qi Dou, Zhen Li, Guanbin Li, Xiang Wan</li>
<li>For: 协助临床诊断和治疗，提高残渣检测和识别精度。* Methods: 利用扩展的Diffusion模型，根据扩展的数据分布进行数据生成，并在训练过程中使用基于预训练的分割模型进行纠正。* Results: 对残渣检测和识别任务进行了广泛的实验，发现生成的数据可以显著提高基eline方法的性能。<details>
<summary>Abstract</summary>
Colonoscopy analysis, particularly automatic polyp segmentation and detection, is essential for assisting clinical diagnosis and treatment. However, as medical image annotation is labour- and resource-intensive, the scarcity of annotated data limits the effectiveness and generalization of existing methods. Although recent research has focused on data generation and augmentation to address this issue, the quality of the generated data remains a challenge, which limits the contribution to the performance of subsequent tasks. Inspired by the superiority of diffusion models in fitting data distributions and generating high-quality data, in this paper, we propose an Adaptive Refinement Semantic Diffusion Model (ArSDM) to generate colonoscopy images that benefit the downstream tasks. Specifically, ArSDM utilizes the ground-truth segmentation mask as a prior condition during training and adjusts the diffusion loss for each input according to the polyp/background size ratio. Furthermore, ArSDM incorporates a pre-trained segmentation model to refine the training process by reducing the difference between the ground-truth mask and the prediction mask. Extensive experiments on segmentation and detection tasks demonstrate the generated data by ArSDM could significantly boost the performance of baseline methods.
</details>
<details>
<summary>摘要</summary>
colonoscopy分析，特别是自动复合体划分和检测，对诊断和治疗提供了重要支持。然而，医疗图像注释是劳动和资源浪费的，缺乏注释数据限制了现有方法的效iveness和泛化。尽管最近的研究将着眼于数据生成和扩展来解决这一问题，但生成的数据质量仍然是挑战，这限制了后续任务的贡献。 inspirited by diffuse models的优势在适应数据分布和生成高质量数据，在这篇论文中，我们提出了一种适应改进 semantic diffusion model（ArSDM），用于生成帮助下游任务的colonoscopy图像。具体来说，ArSDM在训练过程中使用了真实分 segmentation mask作为假设条件，并根据复合体/背景大小比进行了diffusion损失的调整。此外，ArSDM还 integrate了预训练分 segmentation模型，以减少真实分 mask和预测 mask之间的差异。对于分 segmentation和检测任务进行了广泛的实验， demonstrate that ArSDM生成的数据可以对基eline方法提供显著的提高。
</details></li>
</ul>
<hr>
<h2 id="AdvMono3D-Advanced-Monocular-3D-Object-Detection-with-Depth-Aware-Robust-Adversarial-Training"><a href="#AdvMono3D-Advanced-Monocular-3D-Object-Detection-with-Depth-Aware-Robust-Adversarial-Training" class="headerlink" title="AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training"></a>AdvMono3D: Advanced Monocular 3D Object Detection with Depth-Aware Robust Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01106">http://arxiv.org/abs/2309.01106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyuan Li, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 增强monocular 3D对象检测模型的鲁棒性，以应对针对这些模型的攻击。</li>
<li>methods: 我们提出了一种深度意识 adversarial training 方法，包括设计了一种基于 IDP 的攻击，以及一种基于uncertainty的征还学习方法。</li>
<li>results: 我们在 KITTI 3D 数据集上进行了广泛的实验，发现 DART3D 在对抗攻击时比直接对抗训练（最流行的方法）提高了 $AP_{R40}$ 的车类分类表现，升准4.415%、4.112% 和 3.195%。<details>
<summary>Abstract</summary>
Monocular 3D object detection plays a pivotal role in the field of autonomous driving and numerous deep learning-based methods have made significant breakthroughs in this area. Despite the advancements in detection accuracy and efficiency, these models tend to fail when faced with such attacks, rendering them ineffective. Therefore, bolstering the adversarial robustness of 3D detection models has become a crucial issue that demands immediate attention and innovative solutions. To mitigate this issue, we propose a depth-aware robust adversarial training method for monocular 3D object detection, dubbed DART3D. Specifically, we first design an adversarial attack that iteratively degrades the 2D and 3D perception capabilities of 3D object detection models(IDP), serves as the foundation for our subsequent defense mechanism. In response to this attack, we propose an uncertainty-based residual learning method for adversarial training. Our adversarial training approach capitalizes on the inherent uncertainty, enabling the model to significantly improve its robustness against adversarial attacks. We conducted extensive experiments on the KITTI 3D datasets, demonstrating that DART3D surpasses direct adversarial training (the most popular approach) under attacks in 3D object detection $AP_{R40}$ of car category for the Easy, Moderate, and Hard settings, with improvements of 4.415%, 4.112%, and 3.195%, respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>三元射顶3D物体探测在自动驾驶领域扮演重要角色，许多深度学习基础方法在这个领域中获得了重要突破。然而，这些模型对于这些攻击时往往会失败，导致它们无效。因此，增强3D物体探测模型的敌意耐袭性成为了一个紧要的问题，需要获得优先顾及和创新解决方案。为了解决这个问题，我们提出了一个深度感知敌意耐袭训练方法，名为DART3D。具体来说，我们首先设计了一个攻击，逐步对3D物体探测模型（IDP）进行损害， serve as the foundation for our subsequent defense mechanism。对于这个攻击，我们提出了一种不确定性基于的剩余学习方法 для adversarial training。我们的对抗训练方法利用模型的不确定性，使模型能够在攻击下提高其 robustness。我们对KITTI 3D数据集进行了广泛的实验，结果显示，DART3D 在3D物体探测 $AP_{R40}$ 的车辆类别下，在Easy、Moderate和Hard设定下，与直接对抗训练（最受欢迎的方法）相比，增加了4.415%, 4.112%, 3.195%。
</details></li>
</ul>
<hr>
<h2 id="Turn-Fake-into-Real-Adversarial-Head-Turn-Attacks-Against-Deepfake-Detection"><a href="#Turn-Fake-into-Real-Adversarial-Head-Turn-Attacks-Against-Deepfake-Detection" class="headerlink" title="Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection"></a>Turn Fake into Real: Adversarial Head Turn Attacks Against Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01104">http://arxiv.org/abs/2309.01104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Wang, Zhengyu Zhao, Nicu Sebe, Bruno Lepri</li>
<li>for: 评估深伪检测器的可靠性，检测到深伪视频中的人脸变化。</li>
<li>methods: 基于单个假图像Synthesize face view的方法，实现3D对抗性评估。</li>
<li>results: 对多种检测器进行了广泛的实验， validate了攻击者可以通过AdvHeat在真实场景下取得高攻击成功率（96.8%），并且可以降低步骤数到50。<details>
<summary>Abstract</summary>
Malicious use of deepfakes leads to serious public concerns and reduces people's trust in digital media. Although effective deepfake detectors have been proposed, they are substantially vulnerable to adversarial attacks. To evaluate the detector's robustness, recent studies have explored various attacks. However, all existing attacks are limited to 2D image perturbations, which are hard to translate into real-world facial changes. In this paper, we propose adversarial head turn (AdvHeat), the first attempt at 3D adversarial face views against deepfake detectors, based on face view synthesis from a single-view fake image. Extensive experiments validate the vulnerability of various detectors to AdvHeat in realistic, black-box scenarios. For example, AdvHeat based on a simple random search yields a high attack success rate of 96.8% with 360 searching steps. When additional query access is allowed, we can further reduce the step budget to 50. Additional analyses demonstrate that AdvHeat is better than conventional attacks on both the cross-detector transferability and robustness to defenses. The adversarial images generated by AdvHeat are also shown to have natural looks. Our code, including that for generating a multi-view dataset consisting of 360 synthetic views for each of 1000 IDs from FaceForensics++, is available at https://github.com/twowwj/AdvHeaT.
</details>
<details>
<summary>摘要</summary>
恶意使用深度模仿导致公众对数字媒体的信任减退。虽然有效的深度模仿检测器已经提出，但它们却容易受到反对攻击。为评估检测器的可靠性，latest studies have explored various attacks。然而，所有的攻击都是基于二维图像干扰，这些干扰难以在真实的人脸变化中翻译。在这篇论文中，我们提出了第一个基于三维面视 synthesis的深度模仿攻击方法——对深度模仿检测器的反抗头部攻击（AdvHeat）。我们进行了广泛的实验，证明了各种检测器对AdvHeat的攻击成功率在真实的黑盒enario中很高，例如，基于随机搜索的AdvHeat可以达到96.8%的攻击成功率，只需360步。当允许更多的查询访问时，我们可以进一步降低步数到50。additional analyses表明，AdvHeat比传统攻击更好地在跨检测器的转移性和防御机制上。生成的反对图像也被证明为具有自然的外观。我们的代码，包括生成360个视图的多视图数据集，可以在https://github.com/twowwj/AdvHeaT上下载。
</details></li>
</ul>
<hr>
<h2 id="Dual-Adversarial-Resilience-for-Collaborating-Robust-Underwater-Image-Enhancement-and-Perception"><a href="#Dual-Adversarial-Resilience-for-Collaborating-Robust-Underwater-Image-Enhancement-and-Perception" class="headerlink" title="Dual Adversarial Resilience for Collaborating Robust Underwater Image Enhancement and Perception"></a>Dual Adversarial Resilience for Collaborating Robust Underwater Image Enhancement and Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01102">http://arxiv.org/abs/2309.01102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zengxi Zhang, Zhiying Jiang, Zeru Shi, Jinyuan Liu, Risheng Liu</li>
<li>for: 提高水下图像的可见度和色彩稳定性，并且提高后续识别任务的精度。</li>
<li>methods: 提出了一种协同对抗鲁棒网络（CARNet），包括一个可逆网络、一种同步进行攻击训练和攻击检测、以及一个攻击模式识别器，以提高图像增强和识别任务的Robustness。</li>
<li>results: 实验结果表明，提出的方法可以输出高质量的增强图像，并且与前STATE-OF-THE-ART方法相比，其识别精度提高了6.71%。<details>
<summary>Abstract</summary>
Due to the uneven scattering and absorption of different light wavelengths in aquatic environments, underwater images suffer from low visibility and clear color deviations. With the advancement of autonomous underwater vehicles, extensive research has been conducted on learning-based underwater enhancement algorithms. These works can generate visually pleasing enhanced images and mitigate the adverse effects of degraded images on subsequent perception tasks. However, learning-based methods are susceptible to the inherent fragility of adversarial attacks, causing significant disruption in results. In this work, we introduce a collaborative adversarial resilience network, dubbed CARNet, for underwater image enhancement and subsequent detection tasks. Concretely, we first introduce an invertible network with strong perturbation-perceptual abilities to isolate attacks from underwater images, preventing interference with image enhancement and perceptual tasks. Furthermore, we propose a synchronized attack training strategy with both visual-driven and perception-driven attacks enabling the network to discern and remove various types of attacks. Additionally, we incorporate an attack pattern discriminator to heighten the robustness of the network against different attacks. Extensive experiments demonstrate that the proposed method outputs visually appealing enhancement images and perform averagely 6.71% higher detection mAP than state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a collaborative adversarial resilience network (CARNet) for underwater image enhancement and detection tasks. The key idea is to use an invertible network with strong perturbation-perceptual abilities to isolate attacks from underwater images, preventing interference with image enhancement and perceptual tasks. Additionally, we propose a synchronized attack training strategy that incorporates both visual-driven and perception-driven attacks, allowing the network to distinguish and remove various types of attacks. To further enhance the robustness of the network, we also incorporate an attack pattern discriminator.Experimental results show that the proposed method outputs visually appealing enhancement images and achieves an average detection mAP of 6.71% higher than state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Infrared-Small-Target-Detection-Robustness-with-Bi-Level-Adversarial-Framework"><a href="#Enhancing-Infrared-Small-Target-Detection-Robustness-with-Bi-Level-Adversarial-Framework" class="headerlink" title="Enhancing Infrared Small Target Detection Robustness with Bi-Level Adversarial Framework"></a>Enhancing Infrared Small Target Detection Robustness with Bi-Level Adversarial Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01099">http://arxiv.org/abs/2309.01099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Liu, Zihang Chen, Jinyuan Liu, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 提高小型红外目标检测 against 模糊和干扰背景的稳定性。</li>
<li>methods: 提出了一种 би低级对抗框架，包括learnable生成干扰并 Maximize losses as lower-level objective，以及提高检测器的Robustness promotion as upper-level objective。还提出了一种层次强化学习策略，以发现最有害的干扰并均衡性能和稳定性。</li>
<li>results: 在各种干扰下，提高了21.96% IOU，并在总benchmark上提高了4.97% IOU。I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
The detection of small infrared targets against blurred and cluttered backgrounds has remained an enduring challenge. In recent years, learning-based schemes have become the mainstream methodology to establish the mapping directly. However, these methods are susceptible to the inherent complexities of changing backgrounds and real-world disturbances, leading to unreliable and compromised target estimations. In this work, we propose a bi-level adversarial framework to promote the robustness of detection in the presence of distinct corruptions. We first propose a bi-level optimization formulation to introduce dynamic adversarial learning. Specifically, it is composited by the learnable generation of corruptions to maximize the losses as the lower-level objective and the robustness promotion of detectors as the upper-level one. We also provide a hierarchical reinforced learning strategy to discover the most detrimental corruptions and balance the performance between robustness and accuracy. To better disentangle the corruptions from salient features, we also propose a spatial-frequency interaction network for target detection. Extensive experiments demonstrate our scheme remarkably improves 21.96% IOU across a wide array of corruptions and notably promotes 4.97% IOU on the general benchmark. The source codes are available at https://github.com/LiuZhu-CV/BALISTD.
</details>
<details>
<summary>摘要</summary>
探测小型红外目标在杂乱背景下是一个长期不断挑战。在最近几年，学习基于的方法成为了主流方法来建立映射。然而，这些方法容易受到变化背景和真实世界干扰的影响，导致目标估计不可靠和妥协。在这种情况下，我们提出了一种bi-level对抗框架，以提高探测中的Robustness。我们首先提出了bi-level优化形式来引入动态对抗学习。具体来说，它由learnable生成损害来最大化损害作为下一级目标，并且通过提高检测器的Robustness来作为上一级目标。我们还提供了层次强化学习策略，以发现最有害的损害和平衡性能和准确性。为了更好地分离损害和突出特征，我们还提出了一种空间频率交互网络 для目标探测。广泛的实验表明，我们的方案可以remarkably提高21.96% IOU在各种损害下，并且明显提高4.97% IOU在总benchmark上。源代码可以在https://github.com/LiuZhu-CV/BALISTD中下载。
</details></li>
</ul>
<hr>
<h2 id="CoTDet-Affordance-Knowledge-Prompting-for-Task-Driven-Object-Detection"><a href="#CoTDet-Affordance-Knowledge-Prompting-for-Task-Driven-Object-Detection" class="headerlink" title="CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection"></a>CoTDet: Affordance Knowledge Prompting for Task Driven Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01093">http://arxiv.org/abs/2309.01093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiajin Tang, Ge Zheng, Jingyi Yu, Sibei Yang</li>
<li>for: 本研究旨在检测图像中适合完成任务的对象实例，挑战在于对象类型过多，不能仅仅依据传统对象检测中的Category列表。</li>
<li>methods: 我们提出了基于基本可行性（Fundamental Affordances）而不是对象类型的方法，即从大量语言模型中提取可行知识，并使用多层链式思维（MLCoT）提取可行知识。</li>
<li>results: 我们的CoTDet方法在比较性评价中表现出色，与状态前方法相比，提高了15.6个盒子AP和14.8个面积AP，并能够生成对象检测的合理理由。<details>
<summary>Abstract</summary>
Task driven object detection aims to detect object instances suitable for affording a task in an image. Its challenge lies in object categories available for the task being too diverse to be limited to a closed set of object vocabulary for traditional object detection. Simply mapping categories and visual features of common objects to the task cannot address the challenge. In this paper, we propose to explore fundamental affordances rather than object categories, i.e., common attributes that enable different objects to accomplish the same task. Moreover, we propose a novel multi-level chain-of-thought prompting (MLCoT) to extract the affordance knowledge from large language models, which contains multi-level reasoning steps from task to object examples to essential visual attributes with rationales. Furthermore, to fully exploit knowledge to benefit object recognition and localization, we propose a knowledge-conditional detection framework, namely CoTDet. It conditions the detector from the knowledge to generate object queries and regress boxes. Experimental results demonstrate that our CoTDet outperforms state-of-the-art methods consistently and significantly (+15.6 box AP and +14.8 mask AP) and can generate rationales for why objects are detected to afford the task.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose exploring fundamental affordances rather than object categories. Affordances are common attributes that enable different objects to accomplish the same task. We also propose a novel multi-level chain-of-thought prompting (MLCoT) to extract affordance knowledge from large language models. This contains multiple levels of reasoning steps from the task to object examples to essential visual attributes with rationales.Furthermore, to fully utilize knowledge to benefit object recognition and localization, we propose a knowledge-conditional detection framework, named CoTDet. This framework conditions the detector based on the knowledge to generate object queries and regress boxes. Experimental results show that our CoTDet outperforms state-of-the-art methods by a consistent and significant margin (+15.6 box AP and +14.8 mask AP) and can generate rationales for why objects are detected to afford the task.
</details></li>
</ul>
<hr>
<h2 id="Face-Clustering-for-Connection-Discovery-from-Event-Images"><a href="#Face-Clustering-for-Connection-Discovery-from-Event-Images" class="headerlink" title="Face Clustering for Connection Discovery from Event Images"></a>Face Clustering for Connection Discovery from Event Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01092">http://arxiv.org/abs/2309.01092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Cheung</li>
<li>for: 这篇论文旨在提出一种基于事件图像的社交连接发现系统，以便无需在线社交图像上获取数据。</li>
<li>methods: 该论文提出了一种基于面 clustering的方法，通过分析事件图像中的人脸印象，找到社交连接。</li>
<li>results: 经过实验， authors 发现可以使用事件图像中的人脸印象来构建社交图，并且可以达到 80% 的 F1 分数。<details>
<summary>Abstract</summary>
Social graphs are very useful for many applications, such as recommendations and community detections. However, they are only accessible to big social network operators due to both data availability and privacy concerns. Event images also capture the interactions among the participants, from which social connections can be discovered to form a social graph. Unlike online social graphs, social connections carried by event images can be extracted without user inputs, and hence many social graph-based applications become possible, even without access to online social graphs. This paper proposes a system to discover social connections from event images. By utilizing the social information from even images, such as co-occurrence, a face clustering method is proposed and implemented, and connections can be discovered without the identity of the event participants. By collecting over 40000 faces from over 3000 participants, it is shown that the faces can be well clustered with 80% in F1 score, and social graphs can be constructed. Utilizing offline event images may create a long-term impact on social network analytics.
</details>
<details>
<summary>摘要</summary>
社交图是非常有用于多种应用程序，如推荐和社群检测。然而，它们只能被大型社交网络运营商访问，因为数据可用性和隐私问题。事件图像也捕捉参与者之间的互动，从而可以构建社交图。与在线社交图不同，基于事件图像的社交连接可以无需用户输入抽象，因此许多基于社交图应用程序变得可能，甚至无需访问在线社交图。这篇论文提议一种基于事件图像的社交连接发现系统。通过使用事件图像中的社交信息，如共处，一种面 clustering 方法被提出并实现，并可以无需参与者身份信息发现社交连接。通过收集超过 40000 张面和超过 3000 名参与者，显示可以很好地将面 clustering 得到 80% 的 F1 分数，并构建社交图。使用离线事件图像可能会对社交网络分析产生长期影响。
</details></li>
</ul>
<hr>
<h2 id="MILA-Memory-Based-Instance-Level-Adaptation-for-Cross-Domain-Object-Detection"><a href="#MILA-Memory-Based-Instance-Level-Adaptation-for-Cross-Domain-Object-Detection" class="headerlink" title="MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection"></a>MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01086">http://arxiv.org/abs/2309.01086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onkar Krishna, Hiroki Ohashi, Saptarshi Sinha</li>
<li>for: 这种论文是为了解决跨Domain对象检测中的困难问题，特别是对于不同领域之间的对应关系的建立。</li>
<li>methods: 这种方法使用了对抗学习来对像级和实例级的特征进行对齐。具体来说，它使用了一个内存模块来存储所有标注源实例的卷积特征，并使用一个简单 yet effective的内存检索模块来为目标实例检索最相似的源实例。</li>
<li>results: 这种方法在不同领域之间的对应关系建立方面具有显著的优势，比如在不同领域的对象检测任务中，它的性能都高于非内存基于的方法。<details>
<summary>Abstract</summary>
Cross-domain object detection is challenging, and it involves aligning labeled source and unlabeled target domains. Previous approaches have used adversarial training to align features at both image-level and instance-level. At the instance level, finding a suitable source sample that aligns with a target sample is crucial. A source sample is considered suitable if it differs from the target sample only in domain, without differences in unimportant characteristics such as orientation and color, which can hinder the model's focus on aligning the domain difference. However, existing instance-level feature alignment methods struggle to find suitable source instances because their search scope is limited to mini-batches. Mini-batches are often so small in size that they do not always contain suitable source instances. The insufficient diversity of mini-batches becomes problematic particularly when the target instances have high intra-class variance. To address this issue, we propose a memory-based instance-level domain adaptation framework. Our method aligns a target instance with the most similar source instance of the same category retrieved from a memory storage. Specifically, we introduce a memory module that dynamically stores the pooled features of all labeled source instances, categorized by their labels. Additionally, we introduce a simple yet effective memory retrieval module that retrieves a set of matching memory slots for target instances. Our experiments on various domain shift scenarios demonstrate that our approach outperforms existing non-memory-based methods significantly.
</details>
<details>
<summary>摘要</summary>
域外对象检测是一项挑战性任务，需要对来源和目标域进行对齐。先前的方法通过对抗学习来实现对像水平和实例水平的对齐。在实例水平上，找到一个适合的来源实例是关键。一个来源实例被视为适合的，只要它与目标实例在域之间差异，而不是在不重要的特征如旋转和颜色上差异，这些特征可能会使模型忽略对域差异的对齐。然而，现有的实例级别的特征对齐方法很难找到适合的来源实例，因为它们的搜索范围仅限于 мини-批。 мини-批通常很小，因此不一定包含适合的来源实例。这种缺乏多样性的问题特别是在目标实例具有高内类变异时变得更加突出。为解决这个问题，我们提出了一种带有内存的实例级别域适应框架。我们的方法将目标实例与同类标签的最相似来源实例进行对齐，而不是通过搜索 mini-批中的来源实例。具体来说，我们引入了一个内存模块，该模块在 Label 分类下将所有标注源实例的归一化特征存储在内存中。此外，我们还引入了一个简单 yet effective的内存检索模块，该模块可以将目标实例与内存中的匹配记录进行对比。我们的实验表明，我们的方法在不同的域转移enario中与非带内存的方法相比显著性能更高。
</details></li>
</ul>
<hr>
<h2 id="Chinese-Text-Recognition-with-A-Pre-Trained-CLIP-Like-Model-Through-Image-IDS-Aligning"><a href="#Chinese-Text-Recognition-with-A-Pre-Trained-CLIP-Like-Model-Through-Image-IDS-Aligning" class="headerlink" title="Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning"></a>Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01083">http://arxiv.org/abs/2309.01083</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Yu, Xiaocong Wang, Bin Li, Xiangyang Xue</li>
<li>for: 提高中文文本识别精度和普适性</li>
<li>methods: 使用人工智能模型进行中文字符预训练，并将学习的表示映射到文本识别模型中进行优化</li>
<li>results: 在中文字符识别和文本识别任务中表现出色，超过了之前的方法在大多数场景下Translation:</li>
<li>for: 提高中文文本识别精度和普适性</li>
<li>methods: 使用人工智能模型进行中文字符预训练，并将学习的表示映射到文本识别模型中进行优化</li>
<li>results: 在中文字符识别和文本识别任务中表现出色，超过了之前的方法在大多数场景下<details>
<summary>Abstract</summary>
Scene text recognition has been studied for decades due to its broad applications. However, despite Chinese characters possessing different characteristics from Latin characters, such as complex inner structures and large categories, few methods have been proposed for Chinese Text Recognition (CTR). Particularly, the characteristic of large categories poses challenges in dealing with zero-shot and few-shot Chinese characters. In this paper, inspired by the way humans recognize Chinese texts, we propose a two-stage framework for CTR. Firstly, we pre-train a CLIP-like model through aligning printed character images and Ideographic Description Sequences (IDS). This pre-training stage simulates humans recognizing Chinese characters and obtains the canonical representation of each character. Subsequently, the learned representations are employed to supervise the CTR model, such that traditional single-character recognition can be improved to text-line recognition through image-IDS matching. To evaluate the effectiveness of the proposed method, we conduct extensive experiments on both Chinese character recognition (CCR) and CTR. The experimental results demonstrate that the proposed method performs best in CCR and outperforms previous methods in most scenarios of the CTR benchmark. It is worth noting that the proposed method can recognize zero-shot Chinese characters in text images without fine-tuning, whereas previous methods require fine-tuning when new classes appear. The code is available at https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR.
</details>
<details>
<summary>摘要</summary>
scene文本识别已经受到了多年的研究，因为它有广泛的应用场景。然而，尽管中文字体具有不同的特点，如复杂的内部结构和大量的类别，但只有少数方法被提出来用于中文文本识别（CTR）。特别是，大类划分带来了对零Instance和少Instance中文字体的挑战。在这篇论文中，我们提出了一个基于人类识别中文文本的两stage框架。首先，我们通过对印刷字体图像和意图描述序列（IDS）进行对齐，预训练一个类似于CLIP的模型。这个预训练阶段模拟了人类识别中文字体，并从图像和IDS获得了每个字体的征识性表示。然后，学习的表示被用来监督CTR模型，以改进传统的单个字体识别，并将其扩展到文本图像与IDS匹配。为评估提案的效果，我们进行了广泛的实验，包括中文字体识别（CCR）和CTR。实验结果显示，提案的方法在CCR中表现最佳，并在大多数CTR标准各种场景中超过了先前的方法。值得注意的是，提案的方法可以在文本图像中识别零Instance中文字体，而不需要调整。相比之下，先前的方法在新类型出现时需要调整。代码可以在https://github.com/FudanVI/FudanOCR/tree/main/image-ids-CTR中找到。
</details></li>
</ul>
<hr>
<h2 id="Orientation-Independent-Chinese-Text-Recognition-in-Scene-Images"><a href="#Orientation-Independent-Chinese-Text-Recognition-in-Scene-Images" class="headerlink" title="Orientation-Independent Chinese Text Recognition in Scene Images"></a>Orientation-Independent Chinese Text Recognition in Scene Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01081">http://arxiv.org/abs/2309.01081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Yu, Xiaocong Wang, Bin Li, Xiangyang Xue</li>
<li>for: 本文是为了提高自然场景中的中文文本识别精度而提出的。</li>
<li>methods: 本文使用了一种新的Character Image Reconstruction Network（CIRN）来提取文本图像中的 orientation-independent 视觉特征，以便在自然场景中Robustly 识别水平和垂直文本。</li>
<li>results: 实验结果表明，在一个场景集上，提取Content和orientation信息的方法可以提高文本识别性能，而且在特制的Vertical Chinese Text Recognition（VCTR）集上，该方法可以提高45.63%。<details>
<summary>Abstract</summary>
Scene text recognition (STR) has attracted much attention due to its broad applications. The previous works pay more attention to dealing with the recognition of Latin text images with complex backgrounds by introducing language models or other auxiliary networks. Different from Latin texts, many vertical Chinese texts exist in natural scenes, which brings difficulties to current state-of-the-art STR methods. In this paper, we take the first attempt to extract orientation-independent visual features by disentangling content and orientation information of text images, thus recognizing both horizontal and vertical texts robustly in natural scenes. Specifically, we introduce a Character Image Reconstruction Network (CIRN) to recover corresponding printed character images with disentangled content and orientation information. We conduct experiments on a scene dataset for benchmarking Chinese text recognition, and the results demonstrate that the proposed method can indeed improve performance through disentangling content and orientation information. To further validate the effectiveness of our method, we additionally collect a Vertical Chinese Text Recognition (VCTR) dataset. The experimental results show that the proposed method achieves 45.63% improvement on VCTR when introducing CIRN to the baseline model.
</details>
<details>
<summary>摘要</summary>
Scene文本识别（STR）在广泛应用领域中受到了广泛关注。先前的研究更多地关注了处理复杂背景的拉丁文本图像的识别，通过语言模型或其他辅助网络。与拉丁文本不同，自然场景中存在许多垂直的中文文本，这带来了当前状态的STR方法的困难。在这篇论文中，我们首次尝试提取不受方向影响的视觉特征，通过分离内容和方向信息来识别自然场景中的垂直和水平文本。我们引入了Character Image Reconstruction Network（CIRN）来重建相应的打印字符图像，并提取了内容和方向信息的分离。我们对一个场景集进行了测试，并得到了提高性的结果。为了进一步验证我们的方法的有效性，我们还收集了一个垂直中文文本识别（VCTR）集。实验结果表明，当我们将CIRN添加到基eline模型时，提高了45.63%的性能。
</details></li>
</ul>
<hr>
<h2 id="Robust-Adversarial-Defense-by-Tensor-Factorization"><a href="#Robust-Adversarial-Defense-by-Tensor-Factorization" class="headerlink" title="Robust Adversarial Defense by Tensor Factorization"></a>Robust Adversarial Defense by Tensor Factorization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01077">http://arxiv.org/abs/2309.01077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manish Bhattarai, Mehmet Cagri Kaymak, Ryan Barron, Ben Nebgen, Kim Rasmussen, Boian Alexandrov</li>
<li>for: 防御机器学习模型受到敌意攻击的难题，这种攻击可能会导致模型的性能下降或甚至失败。</li>
<li>methods: 我们的方法利用输入数据的矩阵化和神经网络参数的矩阵化，并将其组合成一种强大的防御策略。</li>
<li>results: 我们的方法能够保持高度的鲁棒性，即使面临最强大的自动攻击也能够维持Robust性。对比已有的防御策略，我们的结果不仅与之匹配，而且还超过了它们。这个研究证明了将矩阵化和低级别分解结合使用的可能性。<details>
<summary>Abstract</summary>
As machine learning techniques become increasingly prevalent in data analysis, the threat of adversarial attacks has surged, necessitating robust defense mechanisms. Among these defenses, methods exploiting low-rank approximations for input data preprocessing and neural network (NN) parameter factorization have shown potential. Our work advances this field further by integrating the tensorization of input data with low-rank decomposition and tensorization of NN parameters to enhance adversarial defense. The proposed approach demonstrates significant defense capabilities, maintaining robust accuracy even when subjected to the strongest known auto-attacks. Evaluations against leading-edge robust performance benchmarks reveal that our results not only hold their ground against the best defensive methods available but also exceed all current defense strategies that rely on tensor factorizations. This study underscores the potential of integrating tensorization and low-rank decomposition as a robust defense against adversarial attacks in machine learning.
</details>
<details>
<summary>摘要</summary>
随着机器学习技术在数据分析中的普及，对抗攻击的威胁也在不断增加，需要开发有力的防御机制。在这些防御机制中，利用输入数据的低级别拟合和神经网络（NN）参数的因式分解方法已经显示出了潜在的可能性。我们的工作将这些方法进一步推广，通过将输入数据的维度化和NN参数的维度化结合使用，以增强对抗攻击的防御能力。我们的提案方法在面对最强大的自动攻击时仍能保持坚固的准确率，并在与现有的防御策略相比表现出色。这一研究表明，将维度化和低级别拟合结合使用可以成为机器学习中对抗攻击的有力防御策略。
</details></li>
</ul>
<hr>
<h2 id="Muti-Stage-Hierarchical-Food-Classification"><a href="#Muti-Stage-Hierarchical-Food-Classification" class="headerlink" title="Muti-Stage Hierarchical Food Classification"></a>Muti-Stage Hierarchical Food Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01075">http://arxiv.org/abs/2309.01075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Pan, Jiangpeng He, Fengqing Zhu</li>
<li>for: 本研究旨在提高食品图像分类的精度，以便从捕捉的食品图像中提取营养成分信息。</li>
<li>methods: 我们提出了一种多stage层次结构的方法，通过Iteratively clustering和合并食品项目 during the training process，使深度模型能够提取图像特征，这些特征在不同的标签之间具有很好的拟合度。</li>
<li>results: 我们在VFN-nutrient数据集上进行了测试，并获得了与现有工作相比的出色的结果，包括食品类别和食品项目分类。<details>
<summary>Abstract</summary>
Food image classification serves as a fundamental and critical step in image-based dietary assessment, facilitating nutrient intake analysis from captured food images. However, existing works in food classification predominantly focuses on predicting 'food types', which do not contain direct nutritional composition information. This limitation arises from the inherent discrepancies in nutrition databases, which are tasked with associating each 'food item' with its respective information. Therefore, in this work we aim to classify food items to align with nutrition database. To this end, we first introduce VFN-nutrient dataset by annotating each food image in VFN with a food item that includes nutritional composition information. Such annotation of food items, being more discriminative than food types, creates a hierarchical structure within the dataset. However, since the food item annotations are solely based on nutritional composition information, they do not always show visual relations with each other, which poses significant challenges when applying deep learning-based techniques for classification. To address this issue, we then propose a multi-stage hierarchical framework for food item classification by iteratively clustering and merging food items during the training process, which allows the deep model to extract image features that are discriminative across labels. Our method is evaluated on VFN-nutrient dataset and achieve promising results compared with existing work in terms of both food type and food item classification.
</details>
<details>
<summary>摘要</summary>
We introduce the VFN-nutrient dataset, annotating each food image in VFN with a food item including nutritional composition information. This hierarchical structure allows for more discriminative annotation of food items. However, the nutritional composition information does not always correspond to visual relations, posing challenges for deep learning-based classification.To address this, we propose a multi-stage hierarchical framework for food item classification. We iteratively cluster and merge food items during training, allowing the deep model to extract image features that are discriminative across labels. Our method is evaluated on the VFN-nutrient dataset and achieves promising results compared to existing works in terms of both food type and food item classification.
</details></li>
</ul>
<hr>
<h2 id="Spatial-and-Visual-Perspective-Taking-via-View-Rotation-and-Relation-Reasoning-for-Embodied-Reference-Understanding"><a href="#Spatial-and-Visual-Perspective-Taking-via-View-Rotation-and-Relation-Reasoning-for-Embodied-Reference-Understanding" class="headerlink" title="Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding"></a>Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01073">http://arxiv.org/abs/2309.01073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ChengShiest/REP-ERU">https://github.com/ChengShiest/REP-ERU</a></li>
<li>paper_authors: Cheng Shi, Sibei Yang</li>
<li>for: 本研究的目的是研究语言和姿势的参照理解，即接受者需要根据发送者的语言和姿势在共享物理环境中找到target对象。</li>
<li>methods: 本研究提出了一种基于自己视角的参照理解方法，称为REasoning from your Perspective（REP），该方法通过建立发送者和接受者之间的关系和对象与发送者之间的关系来解决主要挑战。</li>
<li>results: 实验结果表明，REP方法在YouRefIt上的精度达到+5.22%，与所有现有的状态 искусственный智能算法相比，占据了大幅度的优势。<details>
<summary>Abstract</summary>
Embodied Reference Understanding studies the reference understanding in an embodied fashion, where a receiver is required to locate a target object referred to by both language and gesture of the sender in a shared physical environment. Its main challenge lies in how to make the receiver with the egocentric view access spatial and visual information relative to the sender to judge how objects are oriented around and seen from the sender, i.e., spatial and visual perspective-taking. In this paper, we propose a REasoning from your Perspective (REP) method to tackle the challenge by modeling relations between the receiver and the sender and the sender and the objects via the proposed novel view rotation and relation reasoning. Specifically, view rotation first rotates the receiver to the position of the sender by constructing an embodied 3D coordinate system with the position of the sender as the origin. Then, it changes the orientation of the receiver to the orientation of the sender by encoding the body orientation and gesture of the sender. Relation reasoning models the nonverbal and verbal relations between the sender and the objects by multi-modal cooperative reasoning in gesture, language, visual content, and spatial position. Experiment results demonstrate the effectiveness of REP, which consistently surpasses all existing state-of-the-art algorithms by a large margin, i.e., +5.22% absolute accuracy in terms of Prec0.5 on YouRefIt.
</details>
<details>
<summary>摘要</summary>
“人体参照理解”研究者强调在与另一个人共享的物理环境中，语言和手势都指向某个目标物件，并且需要接受者对 sender 的 egocentric 视角进行诠释。这个挑战在于如何让接受者获取 sender 的位置和方向信息，以便对于 sender 所看到的物品进行诠释。在这篇论文中，我们提出了一种基于你的视角（REP）方法，以解决这个挑战。REP 方法包括两个主要步骤：一、使用视角转换来让接受者视角与 sender 的视角进行对接，并且将接受者的视角转换为 sender 的视角。二、使用多modal 协同理解来模型非语言和语言之间的关系，以及物品和接受者之间的关系。实验结果显示，REP 方法能够优于所有现有的州际算法，具体而言，在 YouRefIt 上的 Prec0.5 上提高了 +5.22% 的绝对精度。
</details></li>
</ul>
<hr>
<h2 id="Channel-Attention-Separable-Convolution-Network-for-Skin-Lesion-Segmentation"><a href="#Channel-Attention-Separable-Convolution-Network-for-Skin-Lesion-Segmentation" class="headerlink" title="Channel Attention Separable Convolution Network for Skin Lesion Segmentation"></a>Channel Attention Separable Convolution Network for Skin Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01072">http://arxiv.org/abs/2309.01072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changlu Guo, Jiangyan Dai, Marton Szemenyei, Yugen Yi</li>
<li>for: 静观皮肤恶性肿瘤早期诊断，提高检测精度和效率。</li>
<li>methods: 基于U-Net、DenseNet、分割核、通道注意力和离散尺度 pyramid pooling（ASPP）的新网络：通道注意力分割卷积网络（CASCN）。</li>
<li>results: 在PH2数据集上进行了评估，没有过多预&#x2F;后处理图像，CASCN实现了PH2数据集的最佳性能，Dice相似度0.9461，准确率0.9645。<details>
<summary>Abstract</summary>
Skin cancer is a frequently occurring cancer in the human population, and it is very important to be able to diagnose malignant tumors in the body early. Lesion segmentation is crucial for monitoring the morphological changes of skin lesions, extracting features to localize and identify diseases to assist doctors in early diagnosis. Manual de-segmentation of dermoscopic images is error-prone and time-consuming, thus there is a pressing demand for precise and automated segmentation algorithms. Inspired by advanced mechanisms such as U-Net, DenseNet, Separable Convolution, Channel Attention, and Atrous Spatial Pyramid Pooling (ASPP), we propose a novel network called Channel Attention Separable Convolution Network (CASCN) for skin lesions segmentation. The proposed CASCN is evaluated on the PH2 dataset with limited images. Without excessive pre-/post-processing of images, CASCN achieves state-of-the-art performance on the PH2 dataset with Dice similarity coefficient of 0.9461 and accuracy of 0.9645.
</details>
<details>
<summary>摘要</summary>
皮肤癌是人类常见的癌症，早期诊断非常重要。 lesion segmentation 是监测皮肤损害的重要步骤，提取特征以地址和诊断疾病，帮助医生早期诊断。 手动减少 dermoscopic 图像的步骤是时间consuming 和 error-prone，因此需要精准和自动化的分 segmentation 算法。  Drawing inspiration from advanced mechanisms such as U-Net, DenseNet, Separable Convolution, Channel Attention, and Atrous Spatial Pyramid Pooling (ASPP), we propose a novel network called Channel Attention Separable Convolution Network (CASCN) for skin lesions segmentation. The proposed CASCN is evaluated on the PH2 dataset with limited images. Without excessive pre-/post-processing of images, CASCN achieves state-of-the-art performance on the PH2 dataset with Dice similarity coefficient of 0.9461 and accuracy of 0.9645.Here's the breakdown of the translation:* "皮肤癌" (pí shèi gān) - skin cancer* "常见" (cháng jiàn) - frequently occurring* "早期诊断" (zhāo qiér xiǎng dài) - early diagnosis* "lesion segmentation" (lé shion segmenation) - segmentation of lesions* "重要步骤" (zhòng yào bù shè) - crucial step* "提取特征" (tixiāo tè xíng) - extract features* "地址和诊断" (dì yì yè shì) - localize and identify diseases* "帮助医生" (bāng zhù yī shēng) - assist doctors* "早期诊断" (zhāo qiér xiǎng dài) - early diagnosis* "精准和自动化" (jīn chūn yǔ zì zhì) - precise and automated* "分 segmentation" (fēn biao) - segmentation* "算法" (suān fǎ) - algorithm* "Channel Attention Separable Convolution Network" (CHannel Attention Separable Convolution Network) - proposed network* "PH2 dataset" (PH2 dataset) - dataset used for evaluation* "limited images" (liù yǐng) - limited number of images* "without excessive pre-/post-processing" (yīn wèi zhèng yǐn yǐn) - without extensive pre-/post-processing* "achieves state-of-the-art performance" (dào zhèng yì yì) - achieves state-of-the-art performance* "Dice similarity coefficient" (Dice similarity coefficient) - evaluation metric* "accuracy" ( accuracy) - evaluation metric
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-3D-Video-Information-Retrieval-with-Deep-Neural-Network-and-Bi-directional-Dynamic-time-Warping-Algorithm"><a href="#Semi-supervised-3D-Video-Information-Retrieval-with-Deep-Neural-Network-and-Bi-directional-Dynamic-time-Warping-Algorithm" class="headerlink" title="Semi-supervised 3D Video Information Retrieval with Deep Neural Network and Bi-directional Dynamic-time Warping Algorithm"></a>Semi-supervised 3D Video Information Retrieval with Deep Neural Network and Bi-directional Dynamic-time Warping Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01063">http://arxiv.org/abs/2309.01063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yintai Ma, Diego Klabjan</li>
<li>for: 本研究提出了一种基于视觉内容的半监督深度学习算法，用于检索相似的2D和3D视频。</li>
<li>methods: 该方法结合深度卷积神经网络和循环神经网络，并使用动态时间戳对相似度进行评估。</li>
<li>results: 该方法在多个公共数据集上进行测试，并与状态元深度学习模型进行比较，结果显示该方法在视频检索任务中具有良好的性能。<details>
<summary>Abstract</summary>
This paper presents a novel semi-supervised deep learning algorithm for retrieving similar 2D and 3D videos based on visual content. The proposed approach combines the power of deep convolutional and recurrent neural networks with dynamic time warping as a similarity measure. The proposed algorithm is designed to handle large video datasets and retrieve the most related videos to a given inquiry video clip based on its graphical frames and contents. We split both the candidate and the inquiry videos into a sequence of clips and convert each clip to a representation vector using an autoencoder-backed deep neural network. We then calculate a similarity measure between the sequences of embedding vectors using a bi-directional dynamic time-warping method. This approach is tested on multiple public datasets, including CC\_WEB\_VIDEO, Youtube-8m, S3DIS, and Synthia, and showed good results compared to state-of-the-art. The algorithm effectively solves video retrieval tasks and outperforms the benchmarked state-of-the-art deep learning model.
</details>
<details>
<summary>摘要</summary>
To implement the algorithm, we split both the candidate and the inquiry videos into a sequence of clips and convert each clip to a representation vector using an autoencoder-backed deep neural network. We then calculate a similarity measure between the sequences of embedding vectors using a bi-directional dynamic time-warping method.We test the algorithm on multiple public datasets, including CC\_WEB\_VIDEO, Youtube-8m, S3DIS, and Synthia, and show that it outperforms state-of-the-art deep learning models. The algorithm effectively solves video retrieval tasks and demonstrates good performance.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Curriculum-based-Continual-Learning-with-Informative-Subset-Selection-for-Remote-Sensing-Scene-Classification"><a href="#Efficient-Curriculum-based-Continual-Learning-with-Informative-Subset-Selection-for-Remote-Sensing-Scene-Classification" class="headerlink" title="Efficient Curriculum based Continual Learning with Informative Subset Selection for Remote Sensing Scene Classification"></a>Efficient Curriculum based Continual Learning with Informative Subset Selection for Remote Sensing Scene Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01050">http://arxiv.org/abs/2309.01050</a></li>
<li>repo_url: None</li>
<li>paper_authors: S Divakar Bhat, Biplab Banerjee, Subhasis Chaudhuri, Avik Bhattacharya</li>
<li>for: 这个论文探讨了从光学远程测量图像中的地面分类问题，并提出了一个基于现有数据的类别增cremental learning（CIL）框架。</li>
<li>methods: 本文提出了一个独特的CIL方法，据建立了一个专门的curriculum来学习新的类别，并采用了一种对于旧的流程进行选择的sample选择策略来减少错误的影响。</li>
<li>results: 实验结果显示，提出的方法可以提高CIL性能，并且比过去的方法更好地调节稳定性和柔软性的贡献。<details>
<summary>Abstract</summary>
We tackle the problem of class incremental learning (CIL) in the realm of landcover classification from optical remote sensing (RS) images in this paper. The paradigm of CIL has recently gained much prominence given the fact that data are generally obtained in a sequential manner for real-world phenomenon. However, CIL has not been extensively considered yet in the domain of RS irrespective of the fact that the satellites tend to discover new classes at different geographical locations temporally. With this motivation, we propose a novel CIL framework inspired by the recent success of replay-memory based approaches and tackling two of their shortcomings. In order to reduce the effect of catastrophic forgetting of the old classes when a new stream arrives, we learn a curriculum of the new classes based on their similarity with the old classes. This is found to limit the degree of forgetting substantially. Next while constructing the replay memory, instead of randomly selecting samples from the old streams, we propose a sample selection strategy which ensures the selection of highly confident samples so as to reduce the effects of noise. We observe a sharp improvement in the CIL performance with the proposed components. Experimental results on the benchmark NWPU-RESISC45, PatternNet, and EuroSAT datasets confirm that our method offers improved stability-plasticity trade-off than the literature.
</details>
<details>
<summary>摘要</summary>
我们在这篇论文中处理了Remote Sensing（RS）图像中的类增长学习（CIL）问题。CIL的概念在真实世界中的数据采集中变得越来越重要，因为数据通常是在序列化的方式获取的。然而，CIL在RS领域还没有得到广泛的考虑，即使卫星在不同的地理位置上发现新的类型。为了解决这个问题，我们提出了一种基于最近的replay-memory基本方法的新CIL框架，并解决了两个缺点。首先，我们学习新类的curriculum，基于其与旧类的相似性，以限制淘汰旧类的影响。我们发现这可以减少淘汰的影响。然后，在构建replay内存时，而不是随机选择旧流中的样本，我们提议一种样本选择策略，以确保选择高度确定的样本，以降低噪声的影响。我们发现这些组件对CIL性能带来了明显的改善。实验结果表明，我们的方法在NWPU-RESISC45、PatternNet和EuroSAT数据集上提供了与文献中的稳定- пластично性质量Trade-off更好的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.CV_2023_09_03/" data-id="clpxp03z900j9fm88ay981duq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.AI_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T12:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.AI_2023_09_03/">cs.AI - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Generative-Social-Choice"><a href="#Generative-Social-Choice" class="headerlink" title="Generative Social Choice"></a>Generative Social Choice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01291">http://arxiv.org/abs/2309.01291</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/babatundeibukun/simple-social-learning-environment">https://github.com/babatundeibukun/simple-social-learning-environment</a></li>
<li>paper_authors: Sara Fish, Paul Gölz, David C. Parkes, Ariel D. Procaccia, Gili Rusak, Itai Shapira, Manuel Wüthrich</li>
<li>for: 这篇论文是为了探讨人工智能在民主过程中的应用，具体来说是如何使用自然语言处理技术来实现民主选举。</li>
<li>methods: 这篇论文使用了社会选择理论的数学严谨性和大自然语言模型的文本生成能力，提出了一个生成社会选择框架，可以帮助解决复杂的民主选举问题。</li>
<li>results: 通过应用这个框架，可以生成一个代表民意的评论文本，例如在在线审议过程中。<details>
<summary>Abstract</summary>
Traditionally, social choice theory has only been applicable to choices among a few predetermined alternatives but not to more complex decisions such as collectively selecting a textual statement. We introduce generative social choice, a framework that combines the mathematical rigor of social choice theory with large language models' capability to generate text and extrapolate preferences. This framework divides the design of AI-augmented democratic processes into two components: first, proving that the process satisfies rigorous representation guarantees when given access to oracle queries; second, empirically validating that these queries can be approximately implemented using a large language model. We illustrate this framework by applying it to the problem of generating a slate of statements that is representative of opinions expressed as free-form text, for instance in an online deliberative process.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版本）传统上，社会选择理论只适用于一些已经预先确定的选项之间的选择，而不适用于更复杂的决策，如通过人工智能支持的民主过程中的 коллектив选择文本声明。我们介绍了生成社会选择框架，这个框架将社会选择理论的数学严谨性与大自然语言模型的文本生成能力相结合，以便更好地满足民主过程中的多样化需求。这个框架将民主过程的设计分为两个组成部分：首先，证明过程满足严谨的表达保证，当给定询问 oracle 时；其次，通过实际验证来证明这些询问可以使用大自然语言模型来近似实现。我们通过应用这个框架来解决在 он线协商过程中收集和代表表达出的意见的问题，例如生成一份代表多种意见的文本声明。
</details></li>
</ul>
<hr>
<h2 id="Traveling-Waves-Encode-the-Recent-Past-and-Enhance-Sequence-Learning"><a href="#Traveling-Waves-Encode-the-Recent-Past-and-Enhance-Sequence-Learning" class="headerlink" title="Traveling Waves Encode the Recent Past and Enhance Sequence Learning"></a>Traveling Waves Encode the Recent Past and Enhance Sequence Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08045">http://arxiv.org/abs/2309.08045</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anon-neurips-2023/wave-rnn">https://github.com/anon-neurips-2023/wave-rnn</a></li>
<li>paper_authors: T. Anderson Keller, Lyle Muller, Terrence Sejnowski, Max Welling</li>
<li>for: 这个论文的目的是解释 cortical sheet 中的 neural activity 是如何实现短期记忆的。</li>
<li>methods: 这个论文使用了一种简单的 recurrent neural network 模型，称为 Wave-RNN (wRNN)，来实现wave-like dynamics。</li>
<li>results: 研究发现，使用 wRNN 模型可以快速地学习并表现出优于不含wave的模型，并且在更复杂的序列模型任务中也表现出类似的性能。<details>
<summary>Abstract</summary>
Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically grounded hypothesis suggests that the cortical sheet may act like a wave-field capable of storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both connectivity constraints and initialization play a crucial role in the emergence of wave-like dynamics. We then empirically show how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and perform significantly better than wave-free counterparts. Finally, we explore the implications of this memory storage system on more complex sequence modeling tasks such as sequential image classification and find that wave-based models not only again outperform comparable wave-free RNNs while using significantly fewer parameters, but additionally perform comparably to more complex gated architectures such as LSTMs and GRUs. We conclude with a discussion of the implications of these results for both neuroscience and machine learning.
</details>
<details>
<summary>摘要</summary>
旅行波的神经活动已在脑部多个区域和尺度上观察到;然而，它们的具体计算作用仍在讨论中。一种物理上基础的假设是，质神经层可能 acts like a wave-field，可以在启发了扩散的 cortical surface 上存储短期内存。然而，这个想法的计算影响仍然是假设，因为没有一个简单的循环神经网络架构可以实现这种波动。在这种工作中，我们提出了一种模型，我们称之为 wave-RNN（wRNN），并证明了连接约束和初始化对波动的出现具有关键作用。然后，我们employmultiple synthetic memory tasks to demonstrate that wRNNs learn faster and perform significantly better than wave-free counterparts。最后，我们探讨了这种内存存储系统在更复杂的序列模型任务中的表现，并发现波动基本模型不仅在相对较少的参数下比wave-free RNNs快速学习，而且与更复杂的闭合架构，如LSTMs和GRUs，相当。我们 conclude with a discussion of the implications of these results for both neuroscience and machine learning.
</details></li>
</ul>
<hr>
<h2 id="Bayesian-inference-of-composition-dependent-phase-diagrams"><a href="#Bayesian-inference-of-composition-dependent-phase-diagrams" class="headerlink" title="Bayesian inference of composition-dependent phase diagrams"></a>Bayesian inference of composition-dependent phase diagrams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01271">http://arxiv.org/abs/2309.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timofei Miryashkin, Olga Klimanova, Vladimir Ladygin, Alexander Shapeev</li>
<li>for: This paper was written to develop a method for constructing temperature-concentration phase diagrams for materials using Bayesian inference and molecular dynamics simulations.</li>
<li>methods: The paper uses Bayesian inference to combine thermodynamic data from molecular dynamics simulations, melting point simulations, and phonon calculations, and to extrapolate the results to the infinite-atom limit.</li>
<li>results: The paper reports the development of an algorithm that can be used to construct temperature-concentration phase diagrams for materials with a high degree of accuracy and precision, and demonstrates the effectiveness of the algorithm on two binary systems, Ge-Si and K-Na.<details>
<summary>Abstract</summary>
Phase diagrams serve as a highly informative tool for materials design, encapsulating information about the phases that a material can manifest under specific conditions. In this work, we develop a method in which Bayesian inference is employed to combine thermodynamic data from molecular dynamics (MD), melting point simulations, and phonon calculations, process these data, and yield a temperature-concentration phase diagram. The employed Bayesian framework yields us not only the free energies of different phases as functions of temperature and concentration but also the uncertainties of these free energies originating from statistical errors inherent to finite-length MD trajectories. Furthermore, it extrapolates the results of the finite-atom calculations to the infinite-atom limit and facilitates the choice of temperature, chemical potentials, and the number of atoms conducting the next simulation with which will be the most efficient in reducing the uncertainty of the phase diagram. The developed algorithm was successfully tested on two binary systems, Ge-Si and K-Na, in the full range of concentrations and temperatures.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版）phas diagrams serve as a highly informative tool for materials design, encapsulating information about the phases that a material can manifest under specific conditions. In this work, we develop a method in which Bayesian inference is employed to combine thermodynamic data from molecular dynamics (MD), melting point simulations, and phonon calculations, process these data, and yield a temperature-concentration phase diagram. The employed Bayesian framework yields us not only the free energies of different phases as functions of temperature and concentration but also the uncertainties of these free energies originating from statistical errors inherent to finite-length MD trajectories. Furthermore, it extrapolates the results of the finite-atom calculations to the infinite-atom limit and facilitates the choice of temperature, chemical potentials, and the number of atoms conducting the next simulation with which will be the most efficient in reducing the uncertainty of the phase diagram. The developed algorithm was successfully tested on two binary systems, Ge-Si and K-Na, in the full range of concentrations and temperatures.
</details></li>
</ul>
<hr>
<h2 id="COMEDIAN-Self-Supervised-Learning-and-Knowledge-Distillation-for-Action-Spotting-using-Transformers"><a href="#COMEDIAN-Self-Supervised-Learning-and-Knowledge-Distillation-for-Action-Spotting-using-Transformers" class="headerlink" title="COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers"></a>COMEDIAN: Self-Supervised Learning and Knowledge Distillation for Action Spotting using Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01270">http://arxiv.org/abs/2309.01270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/juliendenize/eztorch">https://github.com/juliendenize/eztorch</a></li>
<li>paper_authors: Julien Denize, Mykola Liashuha, Jaonary Rabarisoa, Astrid Orcesi, Romain Hérault</li>
<li>for: 这 paper 是为了提出一种用于动作检测的 Initialization 管道，即 COMEDIAN，该管道包括自动学习和知识储存两个 initialization 阶段。</li>
<li>methods: 该 paper 使用了两个 initialization 阶段，首先是使用短视频作为输入进行自动学习初始化 spatial transformer，然后是通过知识储存来增强 spatial transformer 的输出，并在最后一步进行 fine-tuning。</li>
<li>results: 实验结果表明，COMEDIAN 的预训练方法可以在 SoccerNet-v2 数据集上达到状态作卷积的性能，并且比非预训练模型更快地 converges。这些结果表明 COMEDIAN 的预训练管道的有效性。<details>
<summary>Abstract</summary>
We present COMEDIAN, a novel pipeline to initialize spatio-temporal transformers for action spotting, which involves self-supervised learning and knowledge distillation. Action spotting is a timestamp-level temporal action detection task. Our pipeline consists of three steps, with two initialization stages. First, we perform self-supervised initialization of a spatial transformer using short videos as input. Additionally, we initialize a temporal transformer that enhances the spatial transformer's outputs with global context through knowledge distillation from a pre-computed feature bank aligned with each short video segment. In the final step, we fine-tune the transformers to the action spotting task. The experiments, conducted on the SoccerNet-v2 dataset, demonstrate state-of-the-art performance and validate the effectiveness of COMEDIAN's pretraining paradigm. Our results highlight several advantages of our pretraining pipeline, including improved performance and faster convergence compared to non-pretrained models.
</details>
<details>
<summary>摘要</summary>
我们提出了COMEDIAN，一个新的 Initialize Pipeline，用于时间action spotting任务的spatio-temporal transformer的初始化。action spotting是一个时间戳级的动作检测任务。我们的管道包括三个步骤，其中有两个初始化阶段。首先，我们使用短视频作为输入进行自我超vised学习初始化一个空间变换器。其次，我们使用知识填充学习增强空间变换器的输出，通过对每个短视频分段预计算的特征库进行知识填充。最后，我们精度调整transformer到动作检测任务。我们在SoccerNet-v2数据集上进行了实验，并证明了COMEDIAN的预训练方案的效iveness。我们的结果显示了预训练模型的性能提高和更快的收敛速度。
</details></li>
</ul>
<hr>
<h2 id="Learning-Aware-Safety-for-Interactive-Autonomy"><a href="#Learning-Aware-Safety-for-Interactive-Autonomy" class="headerlink" title="Learning-Aware Safety for Interactive Autonomy"></a>Learning-Aware Safety for Interactive Autonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01267">http://arxiv.org/abs/2309.01267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haimin Hu, Zixu Zhang, Kensuke Nakamura, Andrea Bajcsy, Jaime F. Fisac</li>
<li>for: 本研究旨在提供一种新的关闭Loop方法，以确保机器人系统在实时学习和适应的情况下保持安全交互。</li>
<li>methods: 该方法使用反抗搅ء深度学习来规避未来可能的enario，并同时考虑机器人学习算法的内部信念的变化。</li>
<li>results: 研究人员使用这种方法可以 tractable safety analysis，并且可以处理高维度的情况。此外，他们还能够证明这种方法可以与 bayesian belief propagation和大型预训练神经轨迹预测器结合使用。<details>
<summary>Abstract</summary>
One of the outstanding challenges for the widespread deployment of robotic systems like autonomous vehicles is ensuring safe interaction with humans without sacrificing efficiency. Existing safety analysis methods often neglect the robot's ability to learn and adapt at runtime, leading to overly conservative behavior. This paper proposes a new closed-loop paradigm for synthesizing safe control policies that explicitly account for the system's evolving uncertainty under possible future scenarios. The formulation reasons jointly about the physical dynamics and the robot's learning algorithm, which updates its internal belief over time. We leverage adversarial deep reinforcement learning (RL) for scaling to high dimensions, enabling tractable safety analysis even for implicit learning dynamics induced by state-of-the-art prediction models. We demonstrate our framework's ability to work with both Bayesian belief propagation and the implicit learning induced by a large pre-trained neural trajectory predictor.
</details>
<details>
<summary>摘要</summary>
一个现代化的挑战是在广泛部署自动化系统时确保安全地与人类交互，不会牺牲效率。现有的安全分析方法经常忽略机器人的学习和运行时 adaptability，导致行为过于保守。这篇论文提出了一种新的封闭循环方案，用于生成安全控制策略，并且考虑了系统的演变不确定性。我们利用对抗式深度学习来扩展到高维度，使得安全分析可以承受大数据量，并且可以 tractable 地分析隐式学习动力，即使使用现代预测模型。我们示例中使用了 bayesian belief propagation 和大型预训练神经网络轨迹预测器来演示我们的框架的可行性。
</details></li>
</ul>
<hr>
<h2 id="Large-AI-Model-Empowered-Multimodal-Semantic-Communications"><a href="#Large-AI-Model-Empowered-Multimodal-Semantic-Communications" class="headerlink" title="Large AI Model Empowered Multimodal Semantic Communications"></a>Large AI Model Empowered Multimodal Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01249">http://arxiv.org/abs/2309.01249</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You</li>
<li>for: 提供一个具有低延迟和高质量的Semantic Communication（SC）体验，使用多Modal Signal（文本、音频、图像和视频）。</li>
<li>methods: 利用大AI模型，具体是Multimodal Language Model（MLM）和Large Language Model（LLM）来解决数据不一致性、semantic ambiguity和信号抖动等问题。</li>
<li>results: 提出一个基于大AI模型的多Modal SC（LAM-MSC）框架，包括MLM-based Multimodal Alignment（MMA）、个性化的LKB和Conditional Generative Adversarial Networks-based Channel Estimation（CGE）等技术，可以有效地提高SC的性能。<details>
<summary>Abstract</summary>
Multimodal signals, including text, audio, image and video, can be integrated into Semantic Communication (SC) for providing an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal fading. Recent advancements in large AI models, particularly in Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential solutions for these issues. To this end, we propose a Large AI Model-based Multimodal SC (LAM-MSC) framework, in which we first present the MLM-based Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery through the LLM. This effectively addresses the semantic ambiguity. Finally, we apply the Conditional Generative adversarial networks-based channel Estimation (CGE) to obtain Channel State Information (CSI). This approach effectively mitigates the impact of fading channels in SC. Finally, we conduct simulations that demonstrate the superior performance of the LAM-MSC framework.
</details>
<details>
<summary>摘要</summary>
多模式信号（包括文本、音频、图像和视频）可以在semantic Communication（SC）中集成，以提供具有低延迟和高质量的 immerse 体验。然而，多模式SC 存在许多挑战，包括数据不一致、semantic 抽象和信号衰减。最近的大AI模型，特别是多模式语言模型（MLM）和大语言模型（LLM），提供了解决这些问题的可能性。为此，我们提出了基于大AI模型的多模式SC 框架（LAM-MSC），其中我们首先提出了基于 MLM 的多模式对应（MMA），使得在多模式和单模式数据之间进行转换，保持 semantic 一致性。然后，我们提出了基于 LLM 的个性化知识库（LKB），允许用户进行个性化semantic 提取或恢复，从而有效解决semantic 抽象问题。最后，我们应用Conditional Generative Adversarial Networks（CGE）来获取通道状态信息（CSI），这种方法有效地减轻了混叠通道的影响。我们进行了实验，并证明了 LAM-MSC 框架的超越性。
</details></li>
</ul>
<hr>
<h2 id="Representations-Matter-Embedding-Modes-of-Large-Language-Models-using-Dynamic-Mode-Decomposition"><a href="#Representations-Matter-Embedding-Modes-of-Large-Language-Models-using-Dynamic-Mode-Decomposition" class="headerlink" title="Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition"></a>Representations Matter: Embedding Modes of Large Language Models using Dynamic Mode Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01245">http://arxiv.org/abs/2309.01245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Akrout</li>
<li>for: 本研究旨在检测大型自然语言模型（LLM）生成的“妄想”内容，即不基础的文本内容。</li>
<li>methods: 本研究使用动态模式分解（DMD）工具分析生成文本的词嵌入空间的模式演化。</li>
<li>results: 研究发现，生成文本的词嵌入spectrum随着句子的排序逐渐降低，与真实文本的词嵌入spectrum不同。此外，评估 случа件中存在LLM妄想时，真实文本的词嵌入模式具有更多的模式被LLM嵌入模式不好地拟合。这表明，妄想结果归因于生成技术和基础表示。<details>
<summary>Abstract</summary>
Existing large language models (LLMs) are known for generating "hallucinated" content, namely a fabricated text of plausibly looking, yet unfounded, facts. To identify when these hallucination scenarios occur, we examine the properties of the generated text in the embedding space. Specifically, we draw inspiration from the dynamic mode decomposition (DMD) tool in analyzing the pattern evolution of text embeddings across sentences. We empirically demonstrate how the spectrum of sentence embeddings over paragraphs is constantly low-rank for the generated text, unlike that of the ground-truth text. Importantly, we find that evaluation cases having LLM hallucinations correspond to ground-truth embedding patterns with a higher number of modes being poorly approximated by the few modes associated with LLM embedding patterns. In analogy to near-field electromagnetic evanescent waves, the embedding DMD eigenmodes of the generated text with hallucinations vanishes quickly across sentences as opposed to those of the ground-truth text. This suggests that the hallucinations result from both the generation techniques and the underlying representation.
</details>
<details>
<summary>摘要</summary>
现有大型语言模型（LLM）已知能生成“幻想”内容，即fabricated文本中的虚假信息。为了识别这些幻想场景，我们研究生成文本在嵌入空间的属性。 Specifically, we draw inspiration from动态模式分解（DMD）工具来分析文本嵌入的模式进化。我们实际示例中，生成文本的句子嵌入spectrum across paragraphs是常 Low-rank的，与真实文本的嵌入spectrum不同。进一步，我们发现评测 случа件具有LLM幻想的情况与真实文本的嵌入模式数量更高，但这些模式与LLM嵌入模式之间的相似性较低。在近场电磁波的类比中，生成文本幻想的嵌入DMD eigenmodes在句子之间变得越来越小，与真实文本的嵌入DMD eigenmodes不同。这表明幻想的结果来自生成技术和下面的表示。
</details></li>
</ul>
<hr>
<h2 id="Saturn-An-Optimized-Data-System-for-Large-Model-Deep-Learning-Workloads"><a href="#Saturn-An-Optimized-Data-System-for-Large-Model-Deep-Learning-Workloads" class="headerlink" title="Saturn: An Optimized Data System for Large Model Deep Learning Workloads"></a>Saturn: An Optimized Data System for Large Model Deep Learning Workloads</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01226">http://arxiv.org/abs/2309.01226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knagrecha/saturn">https://github.com/knagrecha/saturn</a></li>
<li>paper_authors: Kabir Nagrecha, Arun Kumar</li>
<li>for: 本研究旨在帮助深度学习（DL）用户更好地选择并运行大型模型，解决DL用户面临的三大负担：并行选择、资源分配和任务调度。</li>
<li>methods: 本研究提出了一种新的信息系统架构，用于解决DL用户面临的三大负担。该架构包括一种可编程的实验室 Profiler，一种MILP（分配优化问题）模型，以及一种自适应调度策略。</li>
<li>results: 实验结果表明，使用MILP解决器可以significantly reduces model selection runtimes（39-49%），而且可以进一步 optimize system runtime through introspective scheduling approach。这些技术在一个新的数据系统中被实现，称为Saturn。<details>
<summary>Abstract</summary>
Large language models such as GPT-3 & ChatGPT have transformed deep learning (DL), powering applications that have captured the public's imagination. These models are rapidly being adopted across domains for analytics on various modalities, often by finetuning pre-trained base models. Such models need multiple GPUs due to both their size and computational load, driving the development of a bevy of "model parallelism" techniques & tools. Navigating such parallelism choices, however, is a new burden for end users of DL such as data scientists, domain scientists, etc. who may lack the necessary systems knowhow. The need for model selection, which leads to many models to train due to hyper-parameter tuning or layer-wise finetuning, compounds the situation with two more burdens: resource apportioning and scheduling. In this work, we tackle these three burdens for DL users in a unified manner by formalizing them as a joint problem that we call SPASE: Select a Parallelism, Allocate resources, and SchedulE. We propose a new information system architecture to tackle the SPASE problem holistically, representing a key step toward enabling wider adoption of large DL models. We devise an extensible template for existing parallelism schemes and combine it with an automated empirical profiler for runtime estimation. We then formulate SPASE as an MILP.   We find that direct use of an MILP-solver is significantly more effective than several baseline heuristics. We optimize the system runtime further with an introspective scheduling approach. We implement all these techniques into a new data system we call Saturn. Experiments with benchmark DL workloads show that Saturn achieves 39-49% lower model selection runtimes than typical current DL practice.
</details>
<details>
<summary>摘要</summary>
大型语言模型如GPT-3和ChatGPT已经改变深度学习（DL），推动了许多应用程序，吸引了大众的注意。这些模型在不同领域中被快速适用，通常是通过调整预训模型来进行调整。这些模型需要多个GPU，因为它们的大小和计算负载，这驱使了模型平行化技术和工具的发展。但是，为DL使用者如数据科学家和领域科学家等选择和管理这些平行化方案，则增加了新的负担。因为模型选择和层级调整导致了多个模型需要训练，这个问题更加复杂。在这个研究中，我们将这三个负担视为一个共同问题，我们统称为SPASE：选择平行、分配资源和安排。我们提出了一个新的资讯系统架构，来解决SPASE问题。我们创建了一个可扩展的平行方案模板，并与一个自动化的实验性质估计器结合。我们将SPASE视为一个MILP（内置搜索）。我们发现，直接使用MILP解决方案比基eline变数估计法更有效。我们进一步优化系统执行时间使用一种自我反思的安排方法。我们实现了这些技术在我们的新数据系统Saturn上。实验结果显示，Saturn在常用DL工作负载上降低了39-49%的模型选择执行时间。
</details></li>
</ul>
<hr>
<h2 id="Siren’s-Song-in-the-AI-Ocean-A-Survey-on-Hallucination-in-Large-Language-Models"><a href="#Siren’s-Song-in-the-AI-Ocean-A-Survey-on-Hallucination-in-Large-Language-Models" class="headerlink" title="Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models"></a>Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01219">http://arxiv.org/abs/2309.01219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hillzhang1999/llm-hallucination-survey">https://github.com/hillzhang1999/llm-hallucination-survey</a></li>
<li>paper_authors: Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, Shuming Shi</li>
<li>for: 本研究旨在探讨大语言模型（LLM）在实际应用中的可靠性问题，即 LLM  occasional hallucination 问题。</li>
<li>methods: 本研究对现有的检测、解释和缓解 LLM  hallucination 方法进行了检视和分析，并讨论了未来研究的可能方向。</li>
<li>results: 研究发现了 LLM  hallucination 现象的多种类型和评价指标，分析了现有的缓解方法的效果，并提出了未来研究的潜在方向。<details>
<summary>Abstract</summary>
While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种下游任务中表现出色，但也存在一定的问题：LLM occasional generation content diverges from user input, contradicts previously generated context, or misaligns with established world knowledge。这种现象对 LLM 在实际应用场景中的可靠性带来了极大的挑战。在这篇论文中，我们对 LLM 幻觉现象进行了检测、解释和避免的各种尝试，并分析了现有的避免方法，以及未来研究的可能性。Here's the text with some notes on the translation:* "大型语言模型" (LLM) is translated as "大型语言模型" (also known as "large language models" or "LLMs").* "幻觉" (hallucination) is translated as "幻觉" (also known as "hallucination" or "LLM hallucination").* " contradicts" is translated as " contradicts" (同义词).* "misaligns" is translated as "misaligns" (同义词).* "established world knowledge" is translated as "已知世界知识" (also known as "common knowledge" or "established knowledge").Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Physics-inspired-Neural-Networks-for-Parameter-Learning-of-Adaptive-Cruise-Control-Systems"><a href="#Physics-inspired-Neural-Networks-for-Parameter-Learning-of-Adaptive-Cruise-Control-Systems" class="headerlink" title="Physics-inspired Neural Networks for Parameter Learning of Adaptive Cruise Control Systems"></a>Physics-inspired Neural Networks for Parameter Learning of Adaptive Cruise Control Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01211">http://arxiv.org/abs/2309.01211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Theocharis Apostolakis, Konstantinos Ampountolas</li>
<li>for: 本研究提出了一种基于物理学的神经网络（PiNN），用于学习商业实施的自适应速度控制系统（ACC）的参数。</li>
<li>methods: 本研究使用了多层人工神经网络作为通用函数approximator，并采用了常数时间头额策略（CTHP）来模拟ACC系统的长向 Dynamics。</li>
<li>results: 研究结果表明，提出的PiNN可以高效地学习未知ACC系统的参数，并且对于不同的汽车制造商的ACC系统进行了严格的评估。结果还表明，ACC系统的设计参数不是$L_2$也不是$L_\infty$的 string stable。<details>
<summary>Abstract</summary>
This paper proposes and develops a physics-inspired neural network (PiNN) for learning the parameters of commercially implemented adaptive cruise control (ACC) systems in automotive industry. To emulate the core functionality of stock ACC systems, which have proprietary control logic and undisclosed parameters, the constant time-headway policy (CTHP) is adopted. Leveraging the multi-layer artificial neural networks as universal approximators, the developed PiNN serves as a surrogate model for the longitudinal dynamics of ACC-engaged vehicles, efficiently learning the unknown parameters of the CTHP. The ability of the PiNN to infer the unknown ACC parameters is meticulous evaluated using both synthetic and high-fidelity empirical data of space-gap and relative velocity involving ACC-engaged vehicles in platoon formation. The results have demonstrated the superior predictive ability of the proposed PiNN in learning the unknown design parameters of stock ACC systems from different car manufacturers. The set of ACC model parameters obtained from the PiNN revealed that the stock ACC systems of the considered vehicles in three experimental campaigns are neither $L_2$ nor $L_\infty$ string stable.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "stock ACC systems" is translated as "商业实现的适应速度控制系统" (shāngchǎng jítuō de suīyìng yìjīng zhìxīng zhì)* "proprietary control logic" is translated as "专有控制逻辑" (zhuān yǒu kòng zhì lógí)* "undisclosed parameters" is translated as "未公开的参数" (wèi gōngkāi de ciàngxiàng)* "constant time-headway policy" is translated as "常数时间间隔策略" (chángshuō shíjiān jiāngrá zhùlü)* "multi-layer artificial neural networks" is translated as "多层人工神经网络" (duōcéng rénshēng jīngxīn wǎngwǎng)* "surrogate model" is translated as "代理模型" (dài lǐ móde)* "longitudinal dynamics" is translated as "长度动力学" (chángduō dònglì xué)* "ACC-engaged vehicles" is translated as "适应速度控制车辆" (suīyìng yìjīng chēliàng)* "platoon formation" is translated as "队列形式" (duì liè xíngshì)* "high-fidelity empirical data" is translated as "高准确的实验数据" (gāo zhèngqì de shíyàn shùdà)* "string stability" is translated as "串稳定" (chuī jìdìng)
</details></li>
</ul>
<hr>
<h2 id="A-Visual-Interpretation-Based-Self-Improved-Classification-System-Using-Virtual-Adversarial-Training"><a href="#A-Visual-Interpretation-Based-Self-Improved-Classification-System-Using-Virtual-Adversarial-Training" class="headerlink" title="A Visual Interpretation-Based Self-Improved Classification System Using Virtual Adversarial Training"></a>A Visual Interpretation-Based Self-Improved Classification System Using Virtual Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01196">http://arxiv.org/abs/2309.01196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Jiang, Sayaka Kamei, Chen Li, Shengzhe Hou, Yasuhiko Morimoto<br>for: 这篇论文旨在提出一个可以实现Visual Interpretation-based Self-Improving Classification的模型，以解决BERT模型在自然语言处理中的黑盒问题。methods: 本文提出的方法包括：使用精进BERT模型作为文本类别器，然后使用这些预测的类别标签来在另一个BERT模型中进行类别训练，同时使用VAT技术进行自适应训练。results: 实验结果显示，提出的模型在Twitter的短讯数据集上实现了高效的类别性能。此外，ablation study结果显示不同模型的Component对于类别结果的影响。<details>
<summary>Abstract</summary>
The successful application of large pre-trained models such as BERT in natural language processing has attracted more attention from researchers. Since the BERT typically acts as an end-to-end black box, classification systems based on it usually have difficulty in interpretation and low robustness. This paper proposes a visual interpretation-based self-improving classification model with a combination of virtual adversarial training (VAT) and BERT models to address the above problems. Specifically, a fine-tuned BERT model is used as a classifier to classify the sentiment of the text. Then, the predicted sentiment classification labels are used as part of the input of another BERT for spam classification via a semi-supervised training manner using VAT. Additionally, visualization techniques, including visualizing the importance of words and normalizing the attention head matrix, are employed to analyze the relevance of each component to classification accuracy. Moreover, brand-new features will be found in the visual analysis, and classification performance will be improved. Experimental results on Twitter's tweet dataset demonstrate the effectiveness of the proposed model on the classification task. Furthermore, the ablation study results illustrate the effect of different components of the proposed model on the classification results.
</details>
<details>
<summary>摘要</summary>
成功应用大型预训模型，如BERT，在自然语言处理中吸引了更多研究者的注意。由于BERT通常作为终端黑盒模型，因此基于它的分类系统通常具有低可解释性和低Robustness。本文提出了基于可见解释的自我改进分类模型，通过结合虚拟对抗训练（VAT）和BERT模型来解决上述问题。具体来说，一个精度调整后的BERT模型被用作文本情感分类器。然后，预测的情感分类标签被用作另一个BERT模型的敏感训练数据，通过semi-supervised的方式使用VAT进行训练。此外，使用视觉化技术，包括Word的重要性可见化和注意头矩阵的 норmalizaition，以分析每个组件对分类精度的 relevance。此外，Visual分析还可以找到新的特征。实验结果表明，提议的模型在Twitter tweet数据集上对分类任务具有效果。此外，ablation study结果表明不同组件对分类结果的影响。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Service-Route-and-Time-Prediction-in-Instant-Delivery-Taxonomy-Progress-and-Prospects"><a href="#A-Survey-on-Service-Route-and-Time-Prediction-in-Instant-Delivery-Taxonomy-Progress-and-Prospects" class="headerlink" title="A Survey on Service Route and Time Prediction in Instant Delivery: Taxonomy, Progress, and Prospects"></a>A Survey on Service Route and Time Prediction in Instant Delivery: Taxonomy, Progress, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01194">http://arxiv.org/abs/2309.01194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Wen, Youfang Lin, Lixia Wu, Xiaowei Mao, Tianyue Cai, Yunfeng Hou, Shengnan Guo, Yuxuan Liang, Guangyin Jin, Yiji Zhao, Roger Zimmermann, Jieping Ye, Huaiyu Wan</li>
<li>for: 这篇论文的目的是为服务平台的路由和时间预测（RTP）提供一个系统性的概述，帮助研究人员更好地了解这个领域。</li>
<li>methods: 这篇论文使用了一种新的分类方法，将RTP方法分为三类：任务类型、模型架构和学习态度。这些方法包括单路预测、单时预测和共同路径时间预测等。</li>
<li>results: 这篇论文提供了一个全面的概述，把现有的RTP方法分类和总结，并指出了当前研究的局限性和未来可能的发展方向。<details>
<summary>Abstract</summary>
Instant delivery services, such as food delivery and package delivery, have achieved explosive growth in recent years by providing customers with daily-life convenience. An emerging research area within these services is service Route\&Time Prediction (RTP), which aims to estimate the future service route as well as the arrival time of a given worker. As one of the most crucial tasks in those service platforms, RTP stands central to enhancing user satisfaction and trimming operational expenditures on these platforms. Despite a plethora of algorithms developed to date, there is no systematic, comprehensive survey to guide researchers in this domain. To fill this gap, our work presents the first comprehensive survey that methodically categorizes recent advances in service route and time prediction. We start by defining the RTP challenge and then delve into the metrics that are often employed. Following that, we scrutinize the existing RTP methodologies, presenting a novel taxonomy of them. We categorize these methods based on three criteria: (i) type of task, subdivided into only-route prediction, only-time prediction, and joint route\&time prediction; (ii) model architecture, which encompasses sequence-based and graph-based models; and (iii) learning paradigm, including Supervised Learning (SL) and Deep Reinforcement Learning (DRL). Conclusively, we highlight the limitations of current research and suggest prospective avenues. We believe that the taxonomy, progress, and prospects introduced in this paper can significantly promote the development of this field.
</details>
<details>
<summary>摘要</summary>
快速配送服务，如食物配送和快递服务，在最近几年内取得了极大的增长，提供了日常生活的便利。一个快速发展的研究领域是服务路径预测（RTP），旨在预测未来服务路径以及工作者的到达时间。作为服务平台中最重要的任务之一，RTP对于提高用户满意度和降低运营成本具有重要意义。然而，迄今为止，没有一份系统性、全面的评论指导研究人员在这个领域。为了填补这一空白，我们的工作提供了首次的全面评论，系统地分类了最新的服务路径预测方法。我们首先定义RTP挑战，然后详细介绍使用的指标。接着，我们仔细检查现有的RTP方法，并对其进行新的分类。我们根据三个 критери予分类这些方法：（一）任务类型，分为单独的路径预测、时间预测和路径\&时间预测；（二）模型结构，包括序列基的和图基的模型；（三）学习思想，包括超级学习（SL）和深度优化学习（DRL）。最后，我们强调现有研究的局限性，并建议未来的方向。我们认为这种分类、进步和前瞻在这篇论文中具有重要的促进作用，可以推动这个领域的发展。
</details></li>
</ul>
<hr>
<h2 id="LogGPT-Exploring-ChatGPT-for-Log-Based-Anomaly-Detection"><a href="#LogGPT-Exploring-ChatGPT-for-Log-Based-Anomaly-Detection" class="headerlink" title="LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection"></a>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01189">http://arxiv.org/abs/2309.01189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Qi, Shaohan Huang, Zhongzhi Luan, Carol Fung, Hailong Yang, Depei Qian</li>
<li>for: 这个研究旨在提出一个基于 ChatGPT 的传统系统logs 异常检测方法，以解决高维度和噪音 logs 资料的分析问题。</li>
<li>methods: 本研究使用了 ChatGPT 的语言解释能力，实现了将大规模文本库中的知识转移到 logs 异常检测中。</li>
<li>results: 我们的实验结果显示，LogGPT 可以获得良好的效果，并且具有良好的解释性。这个研究提供了对传统系统logs 异常检测任务中 prompt-based 模型的初步探索。<details>
<summary>Abstract</summary>
The increasing volume of log data produced by software-intensive systems makes it impractical to analyze them manually. Many deep learning-based methods have been proposed for log-based anomaly detection. These methods face several challenges such as high-dimensional and noisy log data, class imbalance, generalization, and model interpretability. Recently, ChatGPT has shown promising results in various domains. However, there is still a lack of study on the application of ChatGPT for log-based anomaly detection. In this work, we proposed LogGPT, a log-based anomaly detection framework based on ChatGPT. By leveraging the ChatGPT's language interpretation capabilities, LogGPT aims to explore the transferability of knowledge from large-scale corpora to log-based anomaly detection. We conduct experiments to evaluate the performance of LogGPT and compare it with three deep learning-based methods on BGL and Spirit datasets. LogGPT shows promising results and has good interpretability. This study provides preliminary insights into prompt-based models, such as ChatGPT, for the log-based anomaly detection task.
</details>
<details>
<summary>摘要</summary>
随着软件敏感系统中的日志数据量的增加，手动分析变得不切实际。许多深度学习基本方法已经为日志异常检测提出了多种方案。这些方法面临着高维度和噪声的日志数据、类别不均衡、泛化和模型解释性等挑战。最近，ChatGPT已经在不同领域展示了有前途的成绩。然而，针对日志异常检测的ChatGPT的应用研究仍然缺乏。本文提出了基于ChatGPT的日志异常检测框架——LogGPT。通过利用ChatGPT的语言解释能力，LogGPT希望能够利用大规模文献中的知识传递到日志异常检测中。我们对LogGPT进行了实验，并与三种深度学习基本方法进行比较。LogGPT显示了良好的性能和解释性。这项研究提供了推特模型（如ChatGPT）在日志异常检测任务中的初步洞察。
</details></li>
</ul>
<hr>
<h2 id="Pre-trained-Neural-Recommenders-A-Transferable-Zero-Shot-Framework-for-Recommendation-Systems"><a href="#Pre-trained-Neural-Recommenders-A-Transferable-Zero-Shot-Framework-for-Recommendation-Systems" class="headerlink" title="Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems"></a>Pre-trained Neural Recommenders: A Transferable Zero-Shot Framework for Recommendation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01188">http://arxiv.org/abs/2309.01188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junting Wang, Adit Krishnan, Hari Sundaram, Yunzhe Li</li>
<li>for: 该研究旨在开发一种基于现代神经网络的协同推荐技术，以满足电商、社交媒体和内容分享平台的成功。</li>
<li>methods: 该研究使用了预训练的视觉和语言模型，并explores the possibility of pre-trained recommender models that支持在新领域建立推荐系统，无需重新训练或使用auxiliary user或item信息。</li>
<li>results: 研究表明，通过利用用户-项目交互矩阵的统计特征，可以学习不需要用户或项目 auxillary信息的零式推荐模型，并且这些模型可以在不同领域和数据集上进行适应。<details>
<summary>Abstract</summary>
Modern neural collaborative filtering techniques are critical to the success of e-commerce, social media, and content-sharing platforms. However, despite technical advances -- for every new application domain, we need to train an NCF model from scratch. In contrast, pre-trained vision and language models are routinely applied to diverse applications directly (zero-shot) or with limited fine-tuning. Inspired by the impact of pre-trained models, we explore the possibility of pre-trained recommender models that support building recommender systems in new domains, with minimal or no retraining, without the use of any auxiliary user or item information. Zero-shot recommendation without auxiliary information is challenging because we cannot form associations between users and items across datasets when there are no overlapping users or items. Our fundamental insight is that the statistical characteristics of the user-item interaction matrix are universally available across different domains and datasets. Thus, we use the statistical characteristics of the user-item interaction matrix to identify dataset-independent representations for users and items. We show how to learn universal (i.e., supporting zero-shot adaptation without user or item auxiliary information) representations for nodes and edges from the bipartite user-item interaction graph. We learn representations by exploiting the statistical properties of the interaction data, including user and item marginals, and the size and density distributions of their clusters.
</details>
<details>
<summary>摘要</summary>
现代神经网络合作推荐技术对电商、社交媒体和内容分享平台的成功起到了关键作用。然而，尽管技术上有所进步，但为每个新应用领域，我们仍需要从零开始训练NCF模型。相比之下，预训练视觉和语言模型可以直接应用于多个应用领域，或者只需要限定的微调。受预训练模型的影响启发了我们，我们试图开发预训练推荐模型，以支持在新领域建立推荐系统，无需重新训练，无需使用任何辅助用户或者物品信息。零shot推荐 без辅助信息是一项挑战，因为在不同的用户和物品之间没有共同的用户或者物品。我们的基本想法是，用户-物品交互矩阵的统计特征是透传的，可以在不同的领域和数据集之间形成共同的表征。因此，我们使用用户-物品交互矩阵的统计特征来定义数据集独立的用户和物品表征。我们展示了如何从二分图中学习universal（即无需用户或物品辅助信息进行适应）的表征。我们利用交互数据的统计特征，包括用户和物品的独立分布、以及用户和物品的尺寸和密度分布，来学习表征。
</details></li>
</ul>
<hr>
<h2 id="Cognition-Mode-Aware-Variational-Representation-Learning-Framework-for-Knowledge-Tracing"><a href="#Cognition-Mode-Aware-Variational-Representation-Learning-Framework-for-Knowledge-Tracing" class="headerlink" title="Cognition-Mode Aware Variational Representation Learning Framework for Knowledge Tracing"></a>Cognition-Mode Aware Variational Representation Learning Framework for Knowledge Tracing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01179">http://arxiv.org/abs/2309.01179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zmy-9/CMVF">https://github.com/zmy-9/CMVF</a></li>
<li>paper_authors: Moyu Zhang, Xinning Zhu, Chunhong Zhang, Feng Pan, Wenchen Qian, Hui Zhao</li>
<li>for: 这篇论文的目的是帮助学生Personalized Learning中的知识追踪（KT）任务，解决该任务的资料罕见问题，以及将学生的实际状态转换为更加Robust的表现。</li>
<li>methods: 这篇论文提出了一个Cognition-Mode Aware Variational Representation Learning Framework（CMVF），可以直接应用于现有的KT方法。CMVF使用一个几率模型来生成每个学生的分布，考虑到有限实践记录的不确定性，并使用variational inference（VI）估计学生的分布。此外，我们还引入了一个认知模式意识的多元分布作为专家知识，以避免学生对于有限实践记录的过度个性化。</li>
<li>results: 实验结果显示，CMVF可以有效地帮助现有的KT方法学习更加Robust的学生表现。<details>
<summary>Abstract</summary>
The Knowledge Tracing (KT) task plays a crucial role in personalized learning, and its purpose is to predict student responses based on their historical practice behavior sequence. However, the KT task suffers from data sparsity, which makes it challenging to learn robust representations for students with few practice records and increases the risk of model overfitting. Therefore, in this paper, we propose a Cognition-Mode Aware Variational Representation Learning Framework (CMVF) that can be directly applied to existing KT methods. Our framework uses a probabilistic model to generate a distribution for each student, accounting for uncertainty in those with limited practice records, and estimate the student's distribution via variational inference (VI). In addition, we also introduce a cognition-mode aware multinomial distribution as prior knowledge that constrains the posterior student distributions learning, so as to ensure that students with similar cognition modes have similar distributions, avoiding overwhelming personalization for students with few practice records. At last, extensive experimental results confirm that CMVF can effectively aid existing KT methods in learning more robust student representations. Our code is available at https://github.com/zmy-9/CMVF.
</details>
<details>
<summary>摘要</summary>
知识跟踪（KT）任务在个性化学习中扮演着关键角色，其目的是预测学生的回答基于他们历史实践行为序列。然而，KT任务受到数据稀缺的影响，这使得学习 robust 的学生表示变得更加挑战，同时增加了模型适应过拟合的风险。因此，在这篇论文中，我们提出了一种基于变量学习框架（CMVF），可以直接应用于现有的 KT 方法。我们的框架使用一种 probabilistic 模型来生成每个学生的分布，考虑到有限实践记录下的不确定性，并通过变量推理（VI）来估计学生的分布。此外，我们还引入了认知模式意识的多omial分布作为先验知识，以避免学生具有少量实践记录的情况下过度个性化。最后，我们进行了广泛的实验研究，证明CMVF可以有效地帮助现有的 KT 方法学习更加 robust 的学生表示。我们的代码可以在 https://github.com/zmy-9/CMVF 上获取。
</details></li>
</ul>
<hr>
<h2 id="Logic-of-subjective-probability"><a href="#Logic-of-subjective-probability" class="headerlink" title="Logic of subjective probability"></a>Logic of subjective probability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01173">http://arxiv.org/abs/2309.01173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vladimir Vovk</li>
<li>for: 本文研究对主观概率的 sintax和 semantics。</li>
<li>methods: 本文使用多种方法来测试概率陈述，包括间subjective概率和不人性概率。</li>
<li>results: 本文 argue that已经被测试过的不人性概率具有对象概率的特征，并采用 Jeffreys’s law来支持这一想法。<details>
<summary>Abstract</summary>
In this paper I discuss both syntax and semantics of subjective probability. The semantics determines ways of testing probability statements. Among important varieties of subjective probabilities are intersubjective probabilities and impersonal probabilities, and I will argue that well-tested impersonal probabilities acquire features of objective probabilities. Jeffreys's law, my next topic, states that two successful probability forecasters must issue forecasts that are close to each other, thus supporting the idea of objective probabilities. Finally, I will discuss connections between subjective and frequentist probability.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我讨论了主观概率的语法和 semantics。 semantics 确定了概率声明的测试方法。重要的主观概率包括 между人共识概率和无人共识概率，我会 argue 这些经过测试的无人共识概率具有目的对象概率的特征。 Jeffreys's law 是我下一个话题，它表明两个成功的概率预测人必须发布的预测结果几乎相同，从而支持目的对象概率的想法。最后，我会讨论主观概率和频率主义概率之间的关系。
</details></li>
</ul>
<hr>
<h2 id="FusionAI-Decentralized-Training-and-Deploying-LLMs-with-Massive-Consumer-Level-GPUs"><a href="#FusionAI-Decentralized-Training-and-Deploying-LLMs-with-Massive-Consumer-Level-GPUs" class="headerlink" title="FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs"></a>FusionAI: Decentralized Training and Deploying LLMs with Massive Consumer-Level GPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01172">http://arxiv.org/abs/2309.01172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenheng Tang, Yuxin Wang, Xin He, Longteng Zhang, Xinglin Pan, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Bingsheng He, Xiaowen Chu</li>
<li>for: 这篇论文旨在解决大型自然语言模型（LLM）的内存和计算需求快速增长，对于没有大规模高端GPU的人员而言，训练或部署LLM受到阻碍。但是，consumer-level GPU却通常被LLM忽略，因为它们的计算能力较弱，储存容量较小，并且通信带宽较低。此外，用户可能有隐私问题在与远端LLM进行互动。</li>
<li>methods: 这篇论文提出了一个分散式系统，以解开consumer-level GPU的潜力在预训、推导和精度调整 LLM 中。但是，这个系统面临了重要挑战，包括CPU和GPU内存有限，低网络带宽，节点和设备多样性。</li>
<li>results: 我们的系统设计包括：1）一个中继处理器，以实现动态加入和退出计算提供者；2）任务排程，以提高系统效率；3）将机器学习过程抽象为指向无顺序图（DAG），以实现模型和任务通用性。我们的性能分析显示，50个RTX 3080 GPU可以 дости持比4个H100 GPU，它们都是许多更昂贵的。<details>
<summary>Abstract</summary>
The rapid growth of memory and computation requirements of large language models (LLMs) has outpaced the development of hardware, hindering people who lack large-scale high-end GPUs from training or deploying LLMs. However, consumer-level GPUs, which constitute a larger market share, are typically overlooked in LLM due to their weaker computing performance, smaller storage capacity, and lower communication bandwidth. Additionally, users may have privacy concerns when interacting with remote LLMs. In this paper, we envision a decentralized system unlocking the potential vast untapped consumer-level GPUs in pre-training, inference and fine-tuning of LLMs with privacy protection. However, this system faces critical challenges, including limited CPU and GPU memory, low network bandwidth, the variability of peer and device heterogeneity. To address these challenges, our system design incorporates: 1) a broker with backup pool to implement dynamic join and quit of computing providers; 2) task scheduling with hardware performance to improve system efficiency; 3) abstracting ML procedures into directed acyclic graphs (DAGs) to achieve model and task universality; 4) abstracting intermediate represention and execution planes to ensure compatibility of various devices and deep learning (DL) frameworks. Our performance analysis demonstrates that 50 RTX 3080 GPUs can achieve throughputs comparable to those of 4 H100 GPUs, which are significantly more expensive.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的快速增长对于硬件的开发落后，使得没有大规模高端GPU的人员无法训练或部署LLM。然而，consumer-level GPU占了更大的市场份额，但它们通常在LLM中被忽略因为它们的计算性能较弱、存储容量较小、通信带宽较低。此外，用户可能有隐私问题在与远程LLM互动。本文描述了一个分布式系统，让consumer-level GPU在预训、处理和精确化LLM中发挥潜力，并提供隐私保护。然而，这个系统面临着重要的挑战，包括CPU和GPU内存有限、低网络带宽、执行环境和设备多样性。为解决这些挑战，我们的系统设计包括：1. 中介人员伙伴库，以进行动态加入和退出计算提供者的实现。2. 根据硬件性能进行任务调度，以提高系统效率。3. 将机器学习过程抽象为指向的无向 graphs（DAGs），以实现模型和任务通用性。4. 将中间表示和执行计划抽象为保证不同设备和深度学习（DL）框架的相容性。我们的性能分析显示，50个RTX 3080 GPU可以 achievable throughputs comparable to those of 4个H100 GPU，这些 GPU 的成本很高。
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Learning-on-Multimodal-Knowledge-Graphs"><a href="#End-to-End-Learning-on-Multimodal-Knowledge-Graphs" class="headerlink" title="End-to-End Learning on Multimodal Knowledge Graphs"></a>End-to-End Learning on Multimodal Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01169">http://arxiv.org/abs/2309.01169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/wxwilcke/mrgcn">https://gitlab.com/wxwilcke/mrgcn</a></li>
<li>paper_authors: W. X. Wilcke, P. Bloem, V. de Boer, R. H. van t Veer</li>
<li>for:  This paper aims to enable data scientists to learn end-to-end on heterogeneous knowledge by proposing a multimodal message passing network that can learn from the structure of graphs and multimodal node features.</li>
<li>methods:  The proposed model uses dedicated neural encoders to learn embeddings for node features belonging to five different types of modalities, which are then projected into a joint representation space together with their relational information.</li>
<li>results:  The authors implement and demonstrate their model on node classification and link prediction for artificial and real-world datasets, and conduct an inverse ablation study to evaluate the effect that each modality has on the overall performance. The results show that end-to-end multimodal learning from any arbitrary knowledge graph is possible, and that including multimodal information can significantly affect performance, but much depends on the characteristics of the data.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文目的是帮助数据科学家通过多Modal的消息传递网络来学习综合知识。</li>
<li>methods: 提议的模型使用专门的神经网络编码器来学习节点特征所属不同类型的多Modalities，然后将其投影到共同表示空间中。</li>
<li>results: 作者实现并在人工和实际世界数据集上进行节点分类和链接预测，并进行反归消除研究来评估每种Modalities对总性能的影响。结果表明，任意知识图Multimodal端到端学习是可能的，并且包含多Modal信息可以对性能产生显著影响，但是这取决于数据的特点。<details>
<summary>Abstract</summary>
Knowledge graphs enable data scientists to learn end-to-end on heterogeneous knowledge. However, most end-to-end models solely learn from the relational information encoded in graphs' structure: raw values, encoded as literal nodes, are either omitted completely or treated as regular nodes without consideration for their values. In either case we lose potentially relevant information which could have otherwise been exploited by our learning methods. We propose a multimodal message passing network which not only learns end-to-end from the structure of graphs, but also from their possibly divers set of multimodal node features. Our model uses dedicated (neural) encoders to naturally learn embeddings for node features belonging to five different types of modalities, including numbers, texts, dates, images and geometries, which are projected into a joint representation space together with their relational information. We implement and demonstrate our model on node classification and link prediction for artificial and real-worlds datasets, and evaluate the effect that each modality has on the overall performance in an inverse ablation study. Our results indicate that end-to-end multimodal learning from any arbitrary knowledge graph is indeed possible, and that including multimodal information can significantly affect performance, but that much depends on the characteristics of the data.
</details>
<details>
<summary>摘要</summary>
知识 graphs 启用数据科学家学习终端到不同类型的知识。然而，大多数终端模型只学习图structure中的关系信息，Raw values 作为literal nodes被完全 omitted 或者 treated as regular nodes without consideration for their values。在这种情况下，我们可能会产生可以利用我们学习方法的潜在信息。我们提议一种多modal message passing network，不仅学习终端从图structure，还从图中可能多样化的多modal node features。我们的模型使用专门（神经网络）编码器来自然学习节点特征的嵌入，包括数字、文本、日期、图像和几何特征，这些特征被投影到共同表示空间中，与关系信息一起。我们实现并示cases on node classification和链接预测任务上，并通过反向减少研究来评估每个模式对总性能的影响。我们的结果表明，从任何arbitrary知识图中进行终端多modal学习是可能的，并且包含多modal信息可以对性能产生重要影响，但是具体取决于数据的特点。
</details></li>
</ul>
<hr>
<h2 id="Spatial-temporal-Vehicle-Re-identification"><a href="#Spatial-temporal-Vehicle-Re-identification" class="headerlink" title="Spatial-temporal Vehicle Re-identification"></a>Spatial-temporal Vehicle Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01166">http://arxiv.org/abs/2309.01166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Zhongdao/VehicleReIDKeyPointData">https://github.com/Zhongdao/VehicleReIDKeyPointData</a></li>
<li>paper_authors: Hye-Geun Kim, YouKyoung Na, Hae-Won Joe, Yong-Hyuk Moon, Yeong-Jun Cho</li>
<li>for: 解决大规模摄像头网络中的车辆重新识别问题，提高公共安全、交通管理和安全性。</li>
<li>methods: 基于可适应Parzen窗法估算相机网络拓扑，并将相机空间temporal相似性和外观相似性合理地融合，使用协调网络进行组合。</li>
<li>results: 在公共数据集（VeRi776）上实现了99.64%的排名1准确率，表明利用空间和时间信息可以提高外观基于方法的准确率，有效地处理车辆外观模糊问题。<details>
<summary>Abstract</summary>
Vehicle re-identification (ReID) in a large-scale camera network is important in public safety, traffic control, and security. However, due to the appearance ambiguities of vehicle, the previous appearance-based ReID methods often fail to track vehicle across multiple cameras. To overcome the challenge, we propose a spatial-temporal vehicle ReID framework that estimates reliable camera network topology based on the adaptive Parzen window method and optimally combines the appearance and spatial-temporal similarities through the fusion network. Based on the proposed methods, we performed superior performance on the public dataset (VeRi776) by 99.64% of rank-1 accuracy. The experimental results support that utilizing spatial and temporal information for ReID can leverage the accuracy of appearance-based methods and effectively deal with appearance ambiguities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-for-Generative-Recommendation-A-Survey-and-Visionary-Discussions"><a href="#Large-Language-Models-for-Generative-Recommendation-A-Survey-and-Visionary-Discussions" class="headerlink" title="Large Language Models for Generative Recommendation: A Survey and Visionary Discussions"></a>Large Language Models for Generative Recommendation: A Survey and Visionary Discussions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01157">http://arxiv.org/abs/2309.01157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Li, Yongfeng Zhang, Dugang Liu, Li Chen</li>
<li>for: 这篇论文主要是为了探讨大语言模型（LLM）在推荐系统（RS）中的应用和发展。</li>
<li>methods: 这篇论文使用了大量的文献研究和分析，探讨了LLM在RS中的应用，包括直接从整个item池中生成推荐。</li>
<li>results: 论文发现，LLM可以在RS中提供更加准确和个性化的推荐，同时也可以简化推荐过程，从而提高推荐系统的效率和可靠性。<details>
<summary>Abstract</summary>
Recent years have witnessed the wide adoption of large language models (LLM) in different fields, especially natural language processing and computer vision. Such a trend can also be observed in recommender systems (RS). However, most of related work treat LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor) which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that the survey can provide the context and guidance needed to explore this interesting and emerging topic.
</details>
<details>
<summary>摘要</summary>
近年来，大语言模型（LLM）在不同领域得到广泛应用，特别是自然语言处理和计算机视觉。这种趋势也可以在推荐系统（RS）中见到。然而，大多数相关工作都将 LLM 视为传统推荐管道的一部分（例如特征提取器），这可能无法充分利用 LLM 的生成能力。相反，可以将推荐过程简化为一个阶段， directly generating recommendations from the complete pool of items，而不是将推荐过程分解为多个阶段，如分数计算和重新排序。本文将评查 LLM 基于生成推荐的进步、方法和未来发展方向。 Specifically, we will examine three questions: 1) What is generative recommendation, 2) Why should RS advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that this survey can provide the necessary context and guidance to explore this interesting and emerging topic.
</details></li>
</ul>
<hr>
<h2 id="FedFwd-Federated-Learning-without-Backpropagation"><a href="#FedFwd-Federated-Learning-without-Backpropagation" class="headerlink" title="FedFwd: Federated Learning without Backpropagation"></a>FedFwd: Federated Learning without Backpropagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01150">http://arxiv.org/abs/2309.01150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seonghwan Park, Dahun Shin, Jinseok Chung, Namhoon Lee</li>
<li>for: 降低 federated learning（FL）中客户端的资源限制，提高训练效率。</li>
<li>methods: 利用 Hinton（2022）提出的 recent BP-free method，即 Forward Forward algorithm，在本地训练过程中进行 layer-wise 地本地更新参数。</li>
<li>results: 在标准dataset上进行了多种实验，如 MNIST 和 CIFAR-10，并显示 FedFwd 与其他 BP-dependent FL 方法相当竞争。<details>
<summary>Abstract</summary>
In federated learning (FL), clients with limited resources can disrupt the training efficiency. A potential solution to this problem is to leverage a new learning procedure that does not rely on backpropagation (BP). We present a novel approach to FL called FedFwd that employs a recent BP-free method by Hinton (2022), namely the Forward Forward algorithm, in the local training process. FedFwd can reduce a significant amount of computations for updating parameters by performing layer-wise local updates, and therefore, there is no need to store all intermediate activation values during training. We conduct various experiments to evaluate FedFwd on standard datasets including MNIST and CIFAR-10, and show that it works competitively to other BP-dependent FL methods.
</details>
<details>
<summary>摘要</summary>
在联合学习（FL）中，客户端具有有限资源可能会干扰训练效率。我们提出一种新的学习方法，不依赖于反卷推（BP）。我们称之为FedFwd，它利用截止往返算法（Hinton，2022），在本地训练过程中进行层次分解更新参数。因此，无需在训练过程中存储所有中间活动值。我们在标准数据集上进行了多种实验，包括MNIST和CIFAR-10，并证明FedFwd与其他依赖于BP的FL方法相当竞争。
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Sequence-Clustering"><a href="#Interpretable-Sequence-Clustering" class="headerlink" title="Interpretable Sequence Clustering"></a>Interpretable Sequence Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01140">http://arxiv.org/abs/2309.01140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jd445/Interpretable-Sequence-Clustering-Tree">https://github.com/jd445/Interpretable-Sequence-Clustering-Tree</a></li>
<li>paper_authors: Junjie Dong, Xinyi Yang, Mudi Jiang, Lianyu Hu, Zengyou He</li>
<li>for: 解决 categorical sequence clustering 中 interpretability 问题，提供一种可解释的树结构。</li>
<li>methods:  combinatorial patterns 和 boosting-based construction strategy，first project sequences into random subspaces, then use k-means algorithm to obtain initial cluster assignments, and construct a pattern-based decision tree.</li>
<li>results: 实验结果表明，提posed method 可以提供可解释的树结构，同时具有快速和准确的cluster assignments。<details>
<summary>Abstract</summary>
Categorical sequence clustering plays a crucial role in various fields, but the lack of interpretability in cluster assignments poses significant challenges. Sequences inherently lack explicit features, and existing sequence clustering algorithms heavily rely on complex representations, making it difficult to explain their results. To address this issue, we propose a method called Interpretable Sequence Clustering Tree (ISCT), which combines sequential patterns with a concise and interpretable tree structure. ISCT leverages k-1 patterns to generate k leaf nodes, corresponding to k clusters, which provides an intuitive explanation on how each cluster is formed. More precisely, ISCT first projects sequences into random subspaces and then utilizes the k-means algorithm to obtain high-quality initial cluster assignments. Subsequently, it constructs a pattern-based decision tree using a boosting-based construction strategy in which sequences are re-projected and re-clustered at each node before mining the top-1 discriminative splitting pattern. Experimental results on 14 real-world data sets demonstrate that our proposed method provides an interpretable tree structure while delivering fast and accurate cluster assignments.
</details>
<details>
<summary>摘要</summary>
Note:* "可解释" (可解释) in Chinese means "interpretable" or "explainable".* "序列" (序列) in Chinese means "sequence".* "划分" (划分) in Chinese means "clustering" or "partitioning".* "树" (树) in Chinese means "tree".
</details></li>
</ul>
<hr>
<h2 id="Financial-Fraud-Detection-using-Quantum-Graph-Neural-Networks"><a href="#Financial-Fraud-Detection-using-Quantum-Graph-Neural-Networks" class="headerlink" title="Financial Fraud Detection using Quantum Graph Neural Networks"></a>Financial Fraud Detection using Quantum Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01127">http://arxiv.org/abs/2309.01127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nouhaila Innan, Abhishek Sawaika, Ashim Dhor, Siddhant Dutta, Sairupa Thota, Husayn Gokal, Nandan Patel, Muhammad Al-Zafar Khan, Ioannis Theodonis, Mohamed Bennai</li>
<li>for: 防止金融欺诈和保持金融机构的声誉</li>
<li>methods: 使用量子图 neural network (QGNN) 和变量量子电路 (VQC)</li>
<li>results: 在实际金融欺诈检测数据集上，QGNN 的 AUC 为 0.85，高于 classical GNNHere’s the full translation of the abstract in Simplified Chinese:防止金融欺诈和保持金融机构的声誉是非常重要的。然而，现有的金融欺诈检测方法有限制性，需要新的方法来提高检测率。在这篇论文中，我们提出了一种使用量子图 neural network (QGNN) 和变量量子电路 (VQC) 的新方法，用于检测金融欺诈。我们使用了一个实际的金融欺诈检测数据集，并将 QGNN 与 classical GNN 进行比较。结果显示，QGNN 的 AUC 为 0.85，高于 classical GNN。这些研究表明了 QGNN 的潜在优势，并建议 QGNN 作为改进金融欺诈检测的新方法。<details>
<summary>Abstract</summary>
Financial fraud detection is essential for preventing significant financial losses and maintaining the reputation of financial institutions. However, conventional methods of detecting financial fraud have limited effectiveness, necessitating the need for new approaches to improve detection rates. In this paper, we propose a novel approach for detecting financial fraud using Quantum Graph Neural Networks (QGNNs). QGNNs are a type of neural network that can process graph-structured data and leverage the power of Quantum Computing (QC) to perform computations more efficiently than classical neural networks. Our approach uses Variational Quantum Circuits (VQC) to enhance the performance of the QGNN. In order to evaluate the efficiency of our proposed method, we compared the performance of QGNNs to Classical Graph Neural Networks using a real-world financial fraud detection dataset. The results of our experiments showed that QGNNs achieved an AUC of $0.85$, which outperformed classical GNNs. Our research highlights the potential of QGNNs and suggests that QGNNs are a promising new approach for improving financial fraud detection.
</details>
<details>
<summary>摘要</summary>
财务欺诈检测是预防重大财务损失和保持金融机构声誉的关键。然而，传统的金融欺诈检测方法有限制，需要新的方法来提高检测率。在这篇论文中，我们提出了一种使用量子图神经网络（QGNN）来检测金融欺诈的新方法。QGNN是一种可以处理图 струкured 数据的神经网络，并且可以利用量子计算（QC）来进行计算，比 классические神经网络更高效。我们的方法使用变量量子电路（VQC）来增强QGNN的性能。为了评估我们的提议的效果，我们比较了QGNN和经典的图神经网络（GNN）在一个真实的金融欺诈检测数据集上的性能。实验结果表明，QGNN达到了 AUC 的 $0.85$，高于经典 GNN。我们的研究表明了 QGNN 的潜在优势，并建议 QGNN 是一种有前途的新方法，可以改善金融欺诈检测。
</details></li>
</ul>
<hr>
<h2 id="MedChatZH-a-Better-Medical-Adviser-Learns-from-Better-Instructions"><a href="#MedChatZH-a-Better-Medical-Adviser-Learns-from-Better-Instructions" class="headerlink" title="MedChatZH: a Better Medical Adviser Learns from Better Instructions"></a>MedChatZH: a Better Medical Adviser Learns from Better Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01114">http://arxiv.org/abs/2309.01114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tyang816/medchatzh">https://github.com/tyang816/medchatzh</a></li>
<li>paper_authors: Yang Tan, Mingchen Li, Zijie Huang, Huiqun Yu, Guisheng Fan</li>
<li>for: 这个研究是为了提高特殊领域的中医Question Answering（QA）系统，使用Generative大型自然语言模型（LLMs）。</li>
<li>methods: 我们使用了特定领域的中医书籍进行预训，并与精心挑选的医疗指令集进行微调。</li>
<li>results: 我们的模型在一个真实的医疗对话数据集上表现出色，超过了几个固定基准的模型。我们释出了我们的模型、代码和数据集，并且鼓励更多的研究者参与这个领域的研究。<details>
<summary>Abstract</summary>
Generative large language models (LLMs) have shown great success in various applications, including question-answering (QA) and dialogue systems. However, in specialized domains like traditional Chinese medical QA, these models may perform unsatisfactorily without fine-tuning on domain-specific datasets. To address this, we introduce MedChatZH, a dialogue model designed specifically for traditional Chinese medical QA. Our model is pre-trained on Chinese traditional medical books and fine-tuned with a carefully curated medical instruction dataset. It outperforms several solid baselines on a real-world medical dialogue dataset. We release our model, code, and dataset on https://github.com/tyang816/MedChatZH to facilitate further research in the domain of traditional Chinese medicine and LLMs.
</details>
<details>
<summary>摘要</summary>
大型生成语言模型（LLMs）在不同应用领域中表现出色，包括问答（QA）和对话系统。然而，在专门的中文传统医学问答领域中，这些模型可能无法达到预期的性能，需要进行域pecific的 fine-tuning。为解决这个问题，我们介绍了MedChatZH，一种专门为中文传统医学问答设计的对话模型。我们的模型在中文传统医学书籍上进行预训练，并与仔细编辑的医学指导数据集进行了精度调整。与几个固定基eline相比，我们的模型在真实的医学对话数据集上表现出色。我们将我们的模型、代码和数据集发布到https://github.com/tyang816/MedChatZH，以便进一步的研究在中文传统医学领域和LLMs之间的关系。
</details></li>
</ul>
<hr>
<h2 id="A-Study-on-the-Implementation-of-Generative-AI-Services-Using-an-Enterprise-Data-Based-LLM-Application-Architecture"><a href="#A-Study-on-the-Implementation-of-Generative-AI-Services-Using-an-Enterprise-Data-Based-LLM-Application-Architecture" class="headerlink" title="A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture"></a>A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01105">http://arxiv.org/abs/2309.01105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheonsu Jeong</li>
<li>for: 本研究旨在提供一种基于大语言模型（LLM）应用架构的生成AI服务实现方法。</li>
<li>methods: 本研究使用精度调整技术和直接文档 интеграción来缓解数据缺乏问题，并开发了一种名为Retrieval-Augmented Generation（RAG）模型，以提高信息存储和检索过程，从而改善内容生成。</li>
<li>results: 研究表明，RAG模型能够有效地缓解数据缺乏问题，并且可以在实际应用中提高LLM服务的可用性。<details>
<summary>Abstract</summary>
This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insufficiency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings.
</details>
<details>
<summary>摘要</summary>
The study introduces a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges by enhancing information storage and retrieval processes. The RAG model is carefully designed to improve content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model, and a comprehensive analysis of these steps is undertaken to emphasize their significance in addressing data scarcity.The study demonstrates the efficacy of the proposed method through illustrative instances, showcasing its applicability within enterprises utilizing LLMs. By implementing the RAG model for information storage and retrieval, the research contributes to a deeper understanding of generative AI technology and facilitates its practical usability within corporate settings. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services.
</details></li>
</ul>
<hr>
<h2 id="M2HGCL-Multi-Scale-Meta-Path-Integrated-Heterogeneous-Graph-Contrastive-Learning"><a href="#M2HGCL-Multi-Scale-Meta-Path-Integrated-Heterogeneous-Graph-Contrastive-Learning" class="headerlink" title="M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive Learning"></a>M2HGCL: Multi-Scale Meta-Path Integrated Heterogeneous Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01101">http://arxiv.org/abs/2309.01101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Guo, Yu Xia, Rui Wang, Rongcheng Duan, Lu Li, Jiangmeng Li</li>
<li>for:  This paper focuses on improving the performance of heterogeneous graph contrastive learning models by proposing a new multi-scale meta-path integrated model (M2HGCL) that captures discriminative information from various types of meta-paths.</li>
<li>methods:  The proposed M2HGCL model discards the conventional heterogeneity-homogeneity transformation and performs graph contrastive learning in a joint manner, aggregating direct neighbor information, initial meta-path neighbor information, and expanded meta-path neighbor information to capture sufficient discriminative information.</li>
<li>results:  The proposed M2HGCL model outperforms current state-of-the-art baseline models on three real-world datasets through extensive experiments, demonstrating its effectiveness in improving the performance of heterogeneous graph contrastive learning models.<details>
<summary>Abstract</summary>
Inspired by the successful application of contrastive learning on graphs, researchers attempt to impose graph contrastive learning approaches on heterogeneous information networks. Orthogonal to homogeneous graphs, the types of nodes and edges in heterogeneous graphs are diverse so that specialized graph contrastive learning methods are required. Most existing methods for heterogeneous graph contrastive learning are implemented by transforming heterogeneous graphs into homogeneous graphs, which may lead to ramifications that the valuable information carried by non-target nodes is undermined thereby exacerbating the performance of contrastive learning models. Additionally, current heterogeneous graph contrastive learning methods are mainly based on initial meta-paths given by the dataset, yet according to our deep-going exploration, we derive empirical conclusions: only initial meta-paths cannot contain sufficiently discriminative information; and various types of meta-paths can effectively promote the performance of heterogeneous graph contrastive learning methods. To this end, we propose a new multi-scale meta-path integrated heterogeneous graph contrastive learning (M2HGCL) model, which discards the conventional heterogeneity-homogeneity transformation and performs the graph contrastive learning in a joint manner. Specifically, we expand the meta-paths and jointly aggregate the direct neighbor information, the initial meta-path neighbor information and the expanded meta-path neighbor information to sufficiently capture discriminative information. A specific positive sampling strategy is further imposed to remedy the intrinsic deficiency of contrastive learning, i.e., the hard negative sample sampling issue. Through extensive experiments on three real-world datasets, we demonstrate that M2HGCL outperforms the current state-of-the-art baseline models.
</details>
<details>
<summary>摘要</summary>
研究人员受到同化学习在图上的成功应用的启发，尝试将同化学习方法应用于不同类型节点和边的异质图。与同质图不同的是，异质图中节点和边的类型多样化，因此需要特化的同化学习方法。现有的异质图同化学习方法大多是通过将异质图转化为同质图来实现，这可能会导致非目标节点上的有价信息被抑制，从而降低同化学习模型的性能。另外，现有的异质图同化学习方法主要基于数据集提供的初始元PATH，但根据我们的深入探索，我们得出了实证结论：只有初始元PATH不能含有足够的分化信息；而不同类型的元PATH可以有效提高异质图同化学习模型的性能。为此，我们提出了一种新的多级元PATH集成的异质图同化学习（M2HGCL）模型，该模型不需要将异质图转化为同质图，而是直接在异质图上进行同化学习。具体来说，我们将元PATH扩展，并同时对直接邻居信息、初始元PATH邻居信息和扩展元PATH邻居信息进行联合聚合，以足够捕捉分化信息。此外，我们还采用了一种特定的正样本采样策略，以解决对异质图同化学习的内在缺陷，即困难的负样本采样问题。通过对三个实际数据集进行广泛的实验，我们证明了M2HGCL模型比现状之最先进基eline模型具有更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Stabilize-to-Act-Learning-to-Coordinate-for-Bimanual-Manipulation"><a href="#Stabilize-to-Act-Learning-to-Coordinate-for-Bimanual-Manipulation" class="headerlink" title="Stabilize to Act: Learning to Coordinate for Bimanual Manipulation"></a>Stabilize to Act: Learning to Coordinate for Bimanual Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01087">http://arxiv.org/abs/2309.01087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jennifer Grannen, Yilin Wu, Brandon Vu, Dorsa Sadigh</li>
<li>for: 这篇论文旨在提供一种解决高维控制问题的策略，以便在两手控制系统中实现高级别的掌控能力。</li>
<li>methods: 该策略基于人类的启发，提出了一种新的角色分配框架，其中一个稳定臂用于保持物品不变，而另一个执行臂用于完成任务。该框架使用一个学习的稳定 repositing 类型来 alternate между维护稳定位置和执行任务。</li>
<li>results: 在四种不同复杂度的双手任务上，BUDS 使用 20 个示例并达到 76.9% 的任务成功率，并能够在不同类型的对象上进行扩展。相比之下，不结构化基线方法只能达到 43.3% 的成功率。<details>
<summary>Abstract</summary>
Key to rich, dexterous manipulation in the real world is the ability to coordinate control across two hands. However, while the promise afforded by bimanual robotic systems is immense, constructing control policies for dual arm autonomous systems brings inherent difficulties. One such difficulty is the high-dimensionality of the bimanual action space, which adds complexity to both model-based and data-driven methods. We counteract this challenge by drawing inspiration from humans to propose a novel role assignment framework: a stabilizing arm holds an object in place to simplify the environment while an acting arm executes the task. We instantiate this framework with BimanUal Dexterity from Stabilization (BUDS), which uses a learned restabilizing classifier to alternate between updating a learned stabilization position to keep the environment unchanged, and accomplishing the task with an acting policy learned from demonstrations. We evaluate BUDS on four bimanual tasks of varying complexities on real-world robots, such as zipping jackets and cutting vegetables. Given only 20 demonstrations, BUDS achieves 76.9% task success across our task suite, and generalizes to out-of-distribution objects within a class with a 52.7% success rate. BUDS is 56.0% more successful than an unstructured baseline that instead learns a BC stabilizing policy due to the precision required of these complex tasks. Supplementary material and videos can be found at https://sites.google.com/view/stabilizetoact .
</details>
<details>
<summary>摘要</summary>
针对实际世界中的灵活操作，关键是在两手之间协调控制。然而，建立双手自主系统的控制策略具有内在的挑战。一个这样的挑战是双手动作空间的高维度，这会使模型基于方法和数据驱动方法都变得复杂。我们从人类的经验中着想出一种新的角色分配框架：一个稳定化手持物体以简化环境，而另一个执行手执行任务。我们实现了这种框架，并命名为BUDS（双手稳定到行动），它使用一个学习的稳定化分类器来 alternate между更新一个学习的稳定化位置，以保持环境不变，并使用一个学习来自示例的行动策略来完成任务。我们在四个不同复杂度的双手任务上进行了实验，包括zip Jackets和切 vegetables，并只需20个示例来 achieve 76.9%的任务成功率。此外，BUDS还能够在不同类型的物体上generalize，并在不同的环境中保持52.7%的成功率。相比之下，不结构化的基准模型只能达到56.0%的成功率。详细的材料和视频可以在https://sites.google.com/view/stabilizetoact找到。
</details></li>
</ul>
<hr>
<h2 id="UnsMOT-Unified-Framework-for-Unsupervised-Multi-Object-Tracking-with-Geometric-Topology-Guidance"><a href="#UnsMOT-Unified-Framework-for-Unsupervised-Multi-Object-Tracking-with-Geometric-Topology-Guidance" class="headerlink" title="UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with Geometric Topology Guidance"></a>UnsMOT: Unified Framework for Unsupervised Multi-Object Tracking with Geometric Topology Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01078">http://arxiv.org/abs/2309.01078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Son Tran, Cong Tran, Anh Tran, Cuong Pham</li>
<li>for: 提高无监督多目标跟踪（MOT）方法的性能，避免高昂的数据标注成本。</li>
<li>methods: 提出了一种名为UnsMOT的新框架，其将视觉特征和动作特征与几何信息结合，以提供更准确的跟踪。</li>
<li>results: 实验结果表明，与现有方法相比，UnsMOT方法在HOTA、IDF1和MOTA指标上表现出色。<details>
<summary>Abstract</summary>
Object detection has long been a topic of high interest in computer vision literature. Motivated by the fact that annotating data for the multi-object tracking (MOT) problem is immensely expensive, recent studies have turned their attention to the unsupervised learning setting. In this paper, we push forward the state-of-the-art performance of unsupervised MOT methods by proposing UnsMOT, a novel framework that explicitly combines the appearance and motion features of objects with geometric information to provide more accurate tracking. Specifically, we first extract the appearance and motion features using CNN and RNN models, respectively. Then, we construct a graph of objects based on their relative distances in a frame, which is fed into a GNN model together with CNN features to output geometric embedding of objects optimized using an unsupervised loss function. Finally, associations between objects are found by matching not only similar extracted features but also geometric embedding of detections and tracklets. Experimental results show remarkable performance in terms of HOTA, IDF1, and MOTA metrics in comparison with state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
We first extract object appearance features using a convolutional neural network (CNN) and motion features using a recurrent neural network (RNN). Then, we create a graph of objects based on their relative distances in a frame, which is fed into a graph neural network (GNN) together with CNN features. The GNN outputs geometric embeddings of objects that are optimized using an unsupervised loss function. Finally, we use both feature extraction and geometric embedding to associate objects, by matching not only similar extracted features but also the geometric embeddings of detections and tracklets.Our experimental results show impressive performance in terms of HOTA, IDF1, and MOTA metrics, outperforming state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Multidomain-transformer-based-deep-learning-for-early-detection-of-network-intrusion"><a href="#Multidomain-transformer-based-deep-learning-for-early-detection-of-network-intrusion" class="headerlink" title="Multidomain transformer-based deep learning for early detection of network intrusion"></a>Multidomain transformer-based deep learning for early detection of network intrusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01070">http://arxiv.org/abs/2309.01070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinxin Liu, Murat Simsek, Michele Nogueira, Burak Kantarci</li>
<li>For: This paper aims to improve the timeliness of Network Intrusion Detection Systems (NIDS) by using Multivariate Time Series (MTS) early detection to identify malicious flows before they reach their target systems.* Methods: The paper proposes a novel feature extractor called Time Series Network Flow Meter (TS-NFM) to represent network flows as MTS with explainable features. It also introduces a new deep learning-based early detection model called Multi-Domain Transformer (MDT) that incorporates the frequency domain into Transformer, and a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve feature extraction.* Results: The proposed methodology improves the earliness of conventional NIDS by 5x10^4 times and duration-based earliness by a factor of 60, resulting in a 84.1% macro F1 score (31% higher than Transformer) on the SCVIC-TS-2022 dataset. The proposed MDT also outperforms state-of-the-art early detection methods by 5% and 6% on ECG and Wafer datasets, respectively.<details>
<summary>Abstract</summary>
Timely response of Network Intrusion Detection Systems (NIDS) is constrained by the flow generation process which requires accumulation of network packets. This paper introduces Multivariate Time Series (MTS) early detection into NIDS to identify malicious flows prior to their arrival at target systems. With this in mind, we first propose a novel feature extractor, Time Series Network Flow Meter (TS-NFM), that represents network flow as MTS with explainable features, and a new benchmark dataset is created using TS-NFM and the meta-data of CICIDS2017, called SCVIC-TS-2022. Additionally, a new deep learning-based early detection model called Multi-Domain Transformer (MDT) is proposed, which incorporates the frequency domain into Transformer. This work further proposes a Multi-Domain Multi-Head Attention (MD-MHA) mechanism to improve the ability of MDT to extract better features. Based on the experimental results, the proposed methodology improves the earliness of the conventional NIDS (i.e., percentage of packets that are used for classification) by 5x10^4 times and duration-based earliness (i.e., percentage of duration of the classified packets of a flow) by a factor of 60, resulting in a 84.1% macro F1 score (31% higher than Transformer) on SCVIC-TS-2022. Additionally, the proposed MDT outperforms the state-of-the-art early detection methods by 5% and 6% on ECG and Wafer datasets, respectively.
</details>
<details>
<summary>摘要</summary>
timely response of Network Intrusion Detection Systems (NIDS) 是受流生成过程的限制，需要accumulation of network packets。这篇论文介绍了Multivariate Time Series (MTS) early detection into NIDS，以识别恶意流之前到达目标系统。为此，我们首先提出了一种新的特征提取器，Time Series Network Flow Meter (TS-NFM)，它将网络流转换为MTS，并提取可解释的特征。此外，我们还创建了一个新的benchmark dataset，使用TS-NFM和CICIDS2017的元数据，称为SCVIC-TS-2022。此外，我们还提出了一种新的深度学习基于Transformer的早期检测模型，即Multi-Domain Transformer (MDT)，它在频率频谱中包含Transformer。此外，我们还提出了一种Multi-Domain Multi-Head Attention (MD-MHA)机制，以提高MTD的特征提取能力。根据实验结果，我们的方法提高了传统NIDS的早期响应（即流经过核心率）5x10^4倍，并提高了持续时间基于的早期响应（即分类后的流 duration）的因子60，从而达到了84.1%的macro F1分数（31%高于Transformer）。此外，我们的MTD还超过了当前早期检测方法的状态。
</details></li>
</ul>
<hr>
<h2 id="Separable-Hamiltonian-Neural-Networks"><a href="#Separable-Hamiltonian-Neural-Networks" class="headerlink" title="Separable Hamiltonian Neural Networks"></a>Separable Hamiltonian Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01069">http://arxiv.org/abs/2309.01069</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zykhoo/separablenns">https://github.com/zykhoo/separablenns</a></li>
<li>paper_authors: Zi-Yu Khoo, Jonathan Sze Choong Low, Stéphane Bressan</li>
<li>for: 用于透过确定数据库中的问题，推断汉密尔数据的问题。</li>
<li>methods: 使用汉密尔神经网络，将汉密尔系统的问题转化为确定的数据库中的问题，并将问题转化为确定的数据库中的问题。</li>
<li>results: 透过将问题转化为确定的数据库中的问题，使得汉密尔神经网络可以更好地预测汉密尔系统的问题。<details>
<summary>Abstract</summary>
The modelling of dynamical systems from discrete observations is a challenge faced by modern scientific and engineering data systems. Hamiltonian systems are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian neural networks are state-of-the-art models that unsupervised-ly regress the Hamiltonian of a dynamical system from discrete observations of its vector field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics are often complicated, especially in higher dimensions where the state space of the Hamiltonian system is large relative to the number of samples. A recently discovered remedy to alleviate the complexity between state variables in the state space is to leverage the additive separability of the Hamiltonian system and embed that additive separability into the Hamiltonian neural network. Following the nomenclature of physics-informed machine learning, we propose three separable Hamiltonian neural networks. These models embed additive separability within Hamiltonian neural networks. The first model uses additive separability to quadratically scale the amount of data for training Hamiltonian neural networks. The second model embeds additive separability within the loss function of the Hamiltonian neural network. The third model embeds additive separability through the architecture of the Hamiltonian neural network using conjoined multilayer perceptions. We empirically compare the three models against state-of-the-art Hamiltonian neural networks, and demonstrate that the separable Hamiltonian neural networks, which alleviate complexity between the state variables, are more effective at regressing the Hamiltonian and its vector field.
</details>
<details>
<summary>摘要</summary>
现代科学和工程数据系统中模拟动力系统从离散观察数据是一个挑战。哈密顿系统是这种基本和普遍的动力系统之一。哈密顿神经网络是目前的状态艺术模型，可以无监督地将哈密顿系统的劳动量从离散观察数据的向量场中预测。然而，哈密顿动力学在更高维度时可能会变得复杂，特别是当状态空间的维度远大于样本数时。为了缓解状态变量之间的复杂性，我们提出了利用哈密顿系统的添加性分解性来附加到哈密顿神经网络中。根据物理学教育机器学习的命名，我们提出了三种分解哈密顿神经网络。这些模型在哈密顿神经网络中嵌入添加性分解性。第一个模型通过添加性来幂等增加训练哈密顿神经网络的数据量。第二个模型在哈密顿神经网络的损失函数中嵌入添加性。第三个模型通过哈密顿神经网络的建筑嵌入添加性，使用共同多层感知。我们对现有的哈密顿神经网络进行了比较，并证明了分解哈密顿神经网络在预测哈密顿和其向量场方面更有效。
</details></li>
</ul>
<hr>
<h2 id="AB2CD-AI-for-Building-Climate-Damage-Classification-and-Detection"><a href="#AB2CD-AI-for-Building-Climate-Damage-Classification-and-Detection" class="headerlink" title="AB2CD: AI for Building Climate Damage Classification and Detection"></a>AB2CD: AI for Building Climate Damage Classification and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01066">http://arxiv.org/abs/2309.01066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Nitsche, S. Karthik Mukkavilli, Niklas Kühl, Thomas Brunschwiler</li>
<li>for: 本研究旨在应用深度学习技术精确评估自然灾害中的建筑物损坏，使用遥测数据。</li>
<li>methods: 我们使用了不同的深度学习模型，包括差分径等径网络、内部对称网络和双路网络，以及ensemble技术，并评估了不同对应的测试集。</li>
<li>results: 我们的研究结果显示，使用3米以下的卫星影像分辨率可以实现高精度的建筑物损坏推断，并且使用不同的深度学习模型可以实现不同程度的准确性。<details>
<summary>Abstract</summary>
We explore the implementation of deep learning techniques for precise building damage assessment in the context of natural hazards, utilizing remote sensing data. The xBD dataset, comprising diverse disaster events from across the globe, serves as the primary focus, facilitating the evaluation of deep learning models. We tackle the challenges of generalization to novel disasters and regions while accounting for the influence of low-quality and noisy labels inherent in natural hazard data. Furthermore, our investigation quantitatively establishes that the minimum satellite imagery resolution essential for effective building damage detection is 3 meters and below 1 meter for classification using symmetric and asymmetric resolution perturbation analyses. To achieve robust and accurate evaluations of building damage detection and classification, we evaluated different deep learning models with residual, squeeze and excitation, and dual path network backbones, as well as ensemble techniques. Overall, the U-Net Siamese network ensemble with F-1 score of 0.812 performed the best against the xView2 challenge benchmark. Additionally, we evaluate a Universal model trained on all hazards against a flood expert model and investigate generalization gaps across events, and out of distribution from field data in the Ahr Valley. Our research findings showcase the potential and limitations of advanced AI solutions in enhancing the impact assessment of climate change-induced extreme weather events, such as floods and hurricanes. These insights have implications for disaster impact assessment in the face of escalating climate challenges.
</details>
<details>
<summary>摘要</summary>
我们探讨了深度学习技术的应用于精准建筑损害评估中，利用遥感数据，在自然灾害背景下。xBD数据集，包括全球各地不同类型灾害事件，作为主要关注对象，以评估深度学习模型。我们解决了对新灾害和地区总结的挑战，同时考虑了自然灾害数据中的低质量和噪音标签的影响。进一步，我们发现了卫星遥感分辨率最低为3米以下，以下1米为类型分类使用对称和非对称分辨率扰动分析。为实现Robust和准确的建筑损害检测和分类，我们评估了不同的深度学习模型，包括剩余、挤压和激活、双路网络框架。综合来说，U-Net Siamese网络集成 Ensemble架构，F-1分数0.812，在xView2挑战benchmark中表现最佳。此外，我们还评估了对所有灾害的通用模型，并 investigate了不同事件之间的总结差和场景数据外部的差异。我们的研究发现，高级AI解决方案在气候变化引起的极端天气事件的影响评估中具有潜力，但同时也存在局限性。这些发现对气候变化的挑战下的灾害影响评估产生了重要的意义。
</details></li>
</ul>
<hr>
<h2 id="Generative-Data-Augmentation-using-LLMs-improves-Distributional-Robustness-in-Question-Answering"><a href="#Generative-Data-Augmentation-using-LLMs-improves-Distributional-Robustness-in-Question-Answering" class="headerlink" title="Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering"></a>Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06358">http://arxiv.org/abs/2309.06358</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Ghosh Chowdhury, Aman Chadha</li>
<li>for:  investigate the influence of generated datasets on the performance of QA models under natural distribution shifts</li>
<li>methods:  two-step generation approach, generating both contexts and QA pairs to augment existing datasets</li>
<li>results:  augmenting reading comprehension datasets with generated data leads to better robustness towards natural distribution shifts<details>
<summary>Abstract</summary>
Robustness in Natural Language Processing continues to be a pertinent issue, where state of the art models under-perform under naturally shifted distributions. In the context of Question Answering, work on domain adaptation methods continues to be a growing body of research. However, very little attention has been given to the notion of domain generalization under natural distribution shifts, where the target domain is unknown. With drastic improvements in the quality and access to generative models, we answer the question: How do generated datasets influence the performance of QA models under natural distribution shifts? We perform experiments on 4 different datasets under varying amounts of distribution shift, and analyze how "in-the-wild" generation can help achieve domain generalization. We take a two-step generation approach, generating both contexts and QA pairs to augment existing datasets. Through our experiments, we demonstrate how augmenting reading comprehension datasets with generated data leads to better robustness towards natural distribution shifts.
</details>
<details>
<summary>摘要</summary>
natural language processing 的 robustness 仍然是一个有问题的issue, 现代模型在自然地shifted distributions下表现不佳。在问答领域中, 关于领域适应方法的研究继续增长。然而, 很少注意到target domain是未知的情况下的领域普遍化。随着生成模型的提高和生成数据的可用性的提高, 我们回答了 Question Answering 模型在自然分布shift下的性能如何受到生成数据的影响。我们在4个不同的 dataset上进行了不同量的分布shift的实验，并分析了如何在�nit-in-the-wild�生成数据的帮助下实现领域普遍化。我们采用了two-step generation方法，首先生成了上下文，然后生成了问题和答案的对。通过我们的实验，我们证明了增强阅读理解dataset的可Generated data可以提高模型对自然分布shift的 Robustness。
</details></li>
</ul>
<hr>
<h2 id="Integration-of-Vision-based-Object-Detection-and-Grasping-for-Articulated-Manipulator-in-Lunar-Conditions"><a href="#Integration-of-Vision-based-Object-Detection-and-Grasping-for-Articulated-Manipulator-in-Lunar-Conditions" class="headerlink" title="Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions"></a>Integration of Vision-based Object Detection and Grasping for Articulated Manipulator in Lunar Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01055">http://arxiv.org/abs/2309.01055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Camille Boucher, Gustavo H. Diaz, Shreya Santra, Kentaro Uno, Kazuya Yoshida</li>
<li>for: 这篇论文是为了开发 lunar robot 应用程序而写的。</li>
<li>methods: 这篇论文使用了视觉基础框架，包括物体检测、实例分割和抓取检测，以实现不同应用程序的 integrate。</li>
<li>results: 在具有不平面表面和困难照明条件的情况下，这篇论文达到了92%的成功率，并实现了使用视觉系统结果进行不同应用程序的 assemble 任务。<details>
<summary>Abstract</summary>
The integration of vision-based frameworks to achieve lunar robot applications faces numerous challenges such as terrain configuration or extreme lighting conditions. This paper presents a generic task pipeline using object detection, instance segmentation and grasp detection, that can be used for various applications by using the results of these vision-based systems in a different way. We achieve a rock stacking task on a non-flat surface in difficult lighting conditions with a very good success rate of 92%. Eventually, we present an experiment to assemble 3D printed robot components to initiate more complex tasks in the future.
</details>
<details>
<summary>摘要</summary>
具有视觉基础框架的月球机器人应用面临许多挑战，如地形配置和极端照明条件。本文提出了一个通用任务管道，使用物体检测、实例分割和抓取检测来实现多种应用。我们在非平面表面下实现了一个石堆任务，并在困难的照明条件下达到了92%的成功率。最后，我们展示了将3D打印机器人组件 assembling 以实现更复杂的任务。Note: Please keep in mind that the translation is Simplified Chinese, and some words or phrases may have different translations in Traditional Chinese.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.AI_2023_09_03/" data-id="clpxp03ue003afm88auyj1fv0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.CL_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T11:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.CL_2023_09_03/">cs.CL - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="BDC-Adapter-Brownian-Distance-Covariance-for-Better-Vision-Language-Reasoning"><a href="#BDC-Adapter-Brownian-Distance-Covariance-for-Better-Vision-Language-Reasoning" class="headerlink" title="BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning"></a>BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01256">http://arxiv.org/abs/2309.01256</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rambo-coder/BDC-Adapter">https://github.com/rambo-coder/BDC-Adapter</a></li>
<li>paper_authors: Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He</li>
<li>for: 本研究旨在开发轻量级 fine-tuning 技术，以适应下游视觉任务。</li>
<li>methods: 本研究提出了 Brownian Distance Covariance (BDC)  метри克，用于度量视觉语言理解中的特征相依关系。基于该 metric，我们提出了一种名为 BDC-Adapter 的新方法，该方法通过组合 BDC  прототипы相似预测和多模态预测网络来实现分类任务。</li>
<li>results: 我们的实验结果表明，BDC-Adapter 可以自由处理非线性关系，全面捕捉独立性，与当前状态的方法相比，具有大幅度的提升。<details>
<summary>Abstract</summary>
Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP and ALIGN, have introduced a new paradigm for learning transferable visual representations. Recently, there has been a surge of interest among researchers in developing lightweight fine-tuning techniques to adapt these models to downstream visual tasks. We recognize that current state-of-the-art fine-tuning methods, such as Tip-Adapter, simply consider the covariance between the query image feature and features of support few-shot training samples, which only captures linear relations and potentially instigates a deceptive perception of independence. To address this issue, in this work, we innovatively introduce Brownian Distance Covariance (BDC) to the field of vision-language reasoning. The BDC metric can model all possible relations, providing a robust metric for measuring feature dependence. Based on this, we present a novel method called BDC-Adapter, which integrates BDC prototype similarity reasoning and multi-modal reasoning network prediction to perform classification tasks. Our extensive experimental results show that the proposed BDC-Adapter can freely handle non-linear relations and fully characterize independence, outperforming the current state-of-the-art methods by large margins.
</details>
<details>
<summary>摘要</summary>
大规模预训练视语模型（VLM），如CLIP和ALIGN，已经引入了学习可转移的视觉表示的新 paradigm。最近，研究人员对下游视觉任务适应这些模型的轻量级练习技术表示了很大的兴趣。我们认为现今最佳练习方法，如Tip-Adapter，只考虑了查询图像特征和支持几个少量训练样本的特征之间的covariance，这只captures linear relations,可能导致误导性的独立性概念。为解决这个问题，在这项工作中，我们创新地引入了浮动距离covariance（BDC）到视觉语言理解领域。BDC指标可以模型所有可能的关系，提供一种可靠的指标来衡量特征相互关系。基于这，我们提出了一种新方法called BDC-Adapter，它通过组合BDC原型相似性逻辑和多模态逻辑网络预测来实现分类任务。我们的广泛实验结果表明，我们的提议的BDC-Adapter可以自由地处理非线性关系，具有完全characterize独立性的优势，在与当前状态艺术方法比较大的差异。
</details></li>
</ul>
<hr>
<h2 id="Attention-Where-It-Matters-Rethinking-Visual-Document-Understanding-with-Selective-Region-Concentration"><a href="#Attention-Where-It-Matters-Rethinking-Visual-Document-Understanding-with-Selective-Region-Concentration" class="headerlink" title="Attention Where It Matters: Rethinking Visual Document Understanding with Selective Region Concentration"></a>Attention Where It Matters: Rethinking Visual Document Understanding with Selective Region Concentration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01131">http://arxiv.org/abs/2309.01131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Cao, Changcun Bao, Chaohu Liu, Huang Chen, Kun Yin, Hao Liu, Yinsong Liu, Deqiang Jiang, Xing Sun</li>
<li>for: 提高文档理解效率和精度</li>
<li>methods: 使用选择性区域理解模型（SeRum），该模型将文档图像理解和识别任务转化为地图上的本地解码过程，使模型更加注意力集中于Query解码器生成的区域关键。</li>
<li>results: 实验结果表明，SeRum在文档理解任务中达到了国际级性能，并在文本检索任务中获得了竞争力。<details>
<summary>Abstract</summary>
We propose a novel end-to-end document understanding model called SeRum (SElective Region Understanding Model) for extracting meaningful information from document images, including document analysis, retrieval, and office automation.   Unlike state-of-the-art approaches that rely on multi-stage technical schemes and are computationally expensive,   SeRum converts document image understanding and recognition tasks into a local decoding process of the visual tokens of interest, using a content-aware token merge module.   This mechanism enables the model to pay more attention to regions of interest generated by the query decoder, improving the model's effectiveness and speeding up the decoding speed of the generative scheme.   We also designed several pre-training tasks to enhance the understanding and local awareness of the model.   Experimental results demonstrate that SeRum achieves state-of-the-art performance on document understanding tasks and competitive results on text spotting tasks.   SeRum represents a substantial advancement towards enabling efficient and effective end-to-end document understanding.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的综合型文档理解模型，叫做SeRum（选择区域理解模型），用于从文档图像中提取有意义信息，包括文档分析、检索和办公自动化。 unlike现有的方法，SeRum不仅通过多个阶段技术实现，而且计算成本较高。 SeRum将文档图像理解和识别任务转化为当地解码过程，使用内容相关的字符串融合模块。这种机制使得模型更加注重查询解码器生成的区域兴趣，从而提高模型的效果和加速生成方案的解码速度。我们还设计了一些预训练任务，以增强模型的理解和地方意识。实验结果表明，SeRum在文档理解任务上达到了现有最佳性能，并在文本检索任务上获得了竞争性的成绩。SeRum代表了综合型文档理解的重要进步，它可以帮助实现高效、高效的文档理解。
</details></li>
</ul>
<hr>
<h2 id="Business-Process-Text-Sketch-Automation-Generation-Using-Large-Language-Model"><a href="#Business-Process-Text-Sketch-Automation-Generation-Using-Large-Language-Model" class="headerlink" title="Business Process Text Sketch Automation Generation Using Large Language Model"></a>Business Process Text Sketch Automation Generation Using Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01071">http://arxiv.org/abs/2309.01071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Zhu, Quanzhou Hu, Wenxin Li, Honghao Xiao, Chaogang Wang, Zixin Zhou<br>for: This paper aims to address the challenge of business process document generation in the absence of datasets, and to provide a solution for improving the correctness of data-driven deep learning techniques in this domain.methods: The authors propose an approach that transforms Conditional Process Trees (CPTs) into Business Process Text Sketches (BPTSs) using Large Language Models (LLMs). They also introduce a divide-and-conquer strategy to break down difficult CPTs into smaller, more manageable parts.results: The authors report a correct rate of 93.42% using their proposed method, which is 45.17% better than traditional prompting methods. Their approach has the potential to provide a large number of datasets for the process model extraction (PME) domain.<details>
<summary>Abstract</summary>
Business Process Management (BPM) is gaining increasing attention as it has the potential to cut costs while boosting output and quality. Business process document generation is a crucial stage in BPM. However, due to a shortage of datasets, data-driven deep learning techniques struggle to deliver the expected results. We propose an approach to transform Conditional Process Trees (CPTs) into Business Process Text Sketches (BPTSs) using Large Language Models (LLMs). The traditional prompting approach (Few-shot In-Context Learning) tries to get the correct answer in one go, and it can find the pattern of transforming simple CPTs into BPTSs, but for close-domain and CPTs with complex hierarchy, the traditional prompts perform weakly and with low correctness. We suggest using this technique to break down a difficult CPT into a number of basic CPTs and then solve each one in turn, drawing inspiration from the divide-and-conquer strategy. We chose 100 process trees with depths ranging from 2 to 5 at random, as well as CPTs with many nodes, many degrees of selection, and cyclic nesting. Experiments show that our method can achieve a correct rate of 93.42%, which is 45.17% better than traditional prompting methods. Our proposed method provides a solution for business process document generation in the absence of datasets, and secondly, it becomes potentially possible to provide a large number of datasets for the process model extraction (PME) domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.CL_2023_09_03/" data-id="clpxp03wo00b4fm888y50flgl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/cs.LG_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T10:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/cs.LG_2023_09_03/">cs.LG - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Federated-Orthogonal-Training-Mitigating-Global-Catastrophic-Forgetting-in-Continual-Federated-Learning"><a href="#Federated-Orthogonal-Training-Mitigating-Global-Catastrophic-Forgetting-in-Continual-Federated-Learning" class="headerlink" title="Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning"></a>Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01289">http://arxiv.org/abs/2309.01289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yavuz Faruk Bakman, Duygu Nur Yaldiz, Yahya H. Ezzeldin, Salman Avestimehr</li>
<li>for: 本文探讨了隐私保护训练在分布式数据上的 Federated Learning (FL) 中的持续学习问题，具体来说是 Continual Federated Learning (CFL) 问题。</li>
<li>methods: 本文提出了一种新的方法 called Federated Orthogonal Training (FOT)，它利用层的全球输入子空间来避免全球忘记现象，并通过对新任务的聚合更新进行修正，使其与老任务的全球主方向 orthogonal。</li>
<li>results: 实验表明，FOT 方法可以在 CFL  Setting 中超过现有状态的持续学习方法，实现了最高的准确率提升（最高达 15%），同时具有较低的计算和通信成本（27% 下降），而且不违反隐私原则。<details>
<summary>Abstract</summary>
Federated Learning (FL) has gained significant attraction due to its ability to enable privacy-preserving training over decentralized data. Current literature in FL mostly focuses on single-task learning. However, over time, new tasks may appear in the clients and the global model should learn these tasks without forgetting previous tasks. This real-world scenario is known as Continual Federated Learning (CFL). The main challenge of CFL is Global Catastrophic Forgetting, which corresponds to the fact that when the global model is trained on new tasks, its performance on old tasks decreases. There have been a few recent works on CFL to propose methods that aim to address the global catastrophic forgetting problem. However, these works either have unrealistic assumptions on the availability of past data samples or violate the privacy principles of FL. We propose a novel method, Federated Orthogonal Training (FOT), to overcome these drawbacks and address the global catastrophic forgetting in CFL. Our algorithm extracts the global input subspace of each layer for old tasks and modifies the aggregated updates of new tasks such that they are orthogonal to the global principal subspace of old tasks for each layer. This decreases the interference between tasks, which is the main cause for forgetting. We empirically show that FOT outperforms state-of-the-art continual learning methods in the CFL setting, achieving an average accuracy gain of up to 15% with 27% lower forgetting while only incurring a minimal computation and communication cost.
</details>
<details>
<summary>摘要</summary>
受到隐私保护训练 Decentralized 数据的 Federated Learning (FL) 技术在最近得到了广泛关注，因为它可以实现隐私保护训练。然而，目前的文献主要关注单任务学习。然而，随着时间的推移，客户端上可能会出现新的任务，global model需要学习这些任务而不是忘记之前的任务。这种real-world scenario被称为 Continual Federated Learning (CFL)。CFL 的主要挑战是全球性衰减，即当全球模型在新任务上训练时，其对于旧任务的性能下降。有些最近的工作在 CFL 中提出了方法，以解决全球性衰减问题，但这些方法 either 假设了过去数据样本的可用性或者违反了 Federated Learning 的隐私原则。我们提出了一种新的方法，即 Federated Orthogonal Training (FOT)，以解决这些挑战。我们的算法从旧任务中提取每层的全球输入子空间，并将新任务的聚合更新修改为在每层上保持垂直于旧任务的全球主成分空间。这种方法降低了任务之间的干扰，这是主要的忘记原因。我们实验表明，FOT 可以在 CFL 设置中击败当前状态的 continual learning 方法，实现了最多15%的准确率提升，同时减少了27%的忘记水平，只占了最小的计算和通信成本。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Evaluation-of-FedAvg-and-Per-FedAvg-Algorithms-for-Dirichlet-Distributed-Heterogeneous-Data"><a href="#A-Comparative-Evaluation-of-FedAvg-and-Per-FedAvg-Algorithms-for-Dirichlet-Distributed-Heterogeneous-Data" class="headerlink" title="A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for Dirichlet Distributed Heterogeneous Data"></a>A Comparative Evaluation of FedAvg and Per-FedAvg Algorithms for Dirichlet Distributed Heterogeneous Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01275">http://arxiv.org/abs/2309.01275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Reguieg, Mohammed El Hanjri, Mohamed El Kamili, Abdellatif Kobbane</li>
<li>for:  investigate Federated Learning (FL) and compare two strategies within this paradigm: Federated Averaging (FedAvg) and Personalized Federated Averaging (Per-FedAvg)</li>
<li>methods:  use Non-Identically and Independently Distributed (Non-IID) data to evaluate the performance of both strategies</li>
<li>results:  Per-FedAvg shows superior robustness in conditions of high data heterogeneity, and our results provide insights into the development of more effective and efficient machine learning strategies in a decentralized setting.Here’s the full translation in Simplified Chinese:</li>
<li>for: 本研究 investigate Federated Learning (FL)，并比较这种 paradigm 中两种策略：Federated Averaging (FedAvg) 和 Personalized Federated Averaging (Per-FedAvg)。</li>
<li>methods: 使用 Non-Identically and Independently Distributed (Non-IID) 数据来评估这两种策略的性能。</li>
<li>results: Per-FedAvg 在高度不同数据中显示出更高的 Robustness，而我们的结果可以帮助开发更有效和高效的机器学习策略在分布式环境中。<details>
<summary>Abstract</summary>
In this paper, we investigate Federated Learning (FL), a paradigm of machine learning that allows for decentralized model training on devices without sharing raw data, there by preserving data privacy. In particular, we compare two strategies within this paradigm: Federated Averaging (FedAvg) and Personalized Federated Averaging (Per-FedAvg), focusing on their performance with Non-Identically and Independently Distributed (Non-IID) data. Our analysis shows that the level of data heterogeneity, modeled using a Dirichlet distribution, significantly affects the performance of both strategies, with Per-FedAvg showing superior robustness in conditions of high heterogeneity. Our results provide insights into the development of more effective and efficient machine learning strategies in a decentralized setting.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了联邦学习（Federated Learning，FL），这是一种机器学习的平台，允许在设备上进行分布式模型训练，而不需要共享原始数据，从而保持数据隐私。我们特别比较了两种策略在这个平台上：联邦平均（FedAvg）和个性化联邦平均（Per-FedAvg），并将注重在非同一样分布（Non-IID）数据上的性能。我们的分析表明，数据不同程度的不同，使用 Dirichlet 分布来模型，对两种策略的性能产生了显著影响，Per-FedAvg 在高度不同程度下表现出了更高的鲁棒性。我们的结果提供了开发更有效率的机器学习策略在分布式环境下的指导。
</details></li>
</ul>
<hr>
<h2 id="Modified-Step-Size-for-Enhanced-Stochastic-Gradient-Descent-Convergence-and-Experiments"><a href="#Modified-Step-Size-for-Enhanced-Stochastic-Gradient-Descent-Convergence-and-Experiments" class="headerlink" title="Modified Step Size for Enhanced Stochastic Gradient Descent: Convergence and Experiments"></a>Modified Step Size for Enhanced Stochastic Gradient Descent: Convergence and Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01248">http://arxiv.org/abs/2309.01248</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shamaeem/lnsqrtstepsize">https://github.com/shamaeem/lnsqrtstepsize</a></li>
<li>paper_authors: M. Soheil Shamaee, S. Fathi Hafshejani</li>
<li>for: 提高 Stochastic Gradient Descent（SGD）算法的性能</li>
<li>methods: 使用修改后的衰减步长，其中包括对 Logarithmic 函数的 интегра</li>
<li>results: 在 Smooth 非 convex 函数上达到 $O(\frac{\ln T}{\sqrt{T})$ 的 converge 速率，并通过数据集的实验表明了该方法的效果。Here’s the breakdown of each point:1. for: The paper is written to enhance the performance of the SGD algorithm.2. methods: The paper proposes a modified decay step size based on $\frac{1}{\sqrt{t}$ with a logarithmic term, which leads to the selection of smaller values in the final iterations.3. results: The paper achieves a convergence rate of $O(\frac{\ln T}{\sqrt{T})$ for smooth non-convex functions without the Polyak-{\L}ojasiewicz condition, and the numerical experiments on image classification tasks demonstrate significant improvements in accuracy compared to the traditional $\frac{1}{\sqrt{t}$ step size.<details>
<summary>Abstract</summary>
This paper introduces a novel approach to enhance the performance of the stochastic gradient descent (SGD) algorithm by incorporating a modified decay step size based on $\frac{1}{\sqrt{t}$. The proposed step size integrates a logarithmic term, leading to the selection of smaller values in the final iterations. Our analysis establishes a convergence rate of $O(\frac{\ln T}{\sqrt{T})$ for smooth non-convex functions without the Polyak-{\L}ojasiewicz condition. To evaluate the effectiveness of our approach, we conducted numerical experiments on image classification tasks using the FashionMNIST, and CIFAR10 datasets, and the results demonstrate significant improvements in accuracy, with enhancements of $0.5\%$ and $1.4\%$ observed, respectively, compared to the traditional $\frac{1}{\sqrt{t}$ step size. The source code can be found at \\\url{https://github.com/Shamaeem/LNSQRTStepSize}.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的方法，用于提高泛率下降（SGD）算法的性能。该方法基于$\frac{1}{\sqrt{t}$的修改步长，其中包含了对数函数，从而选择小于最终迭代的值。我们的分析表明，对于非 convex 函数，该方法可以达到$O(\frac{\ln T}{\sqrt{T})$的 converges 速率，而不需要波佳-{\L}ojasiewicz 条件。为证明该方法的有效性，我们在图像分类任务上进行了数值实验，使用了 FashionMNIST 和 CIFAR10 数据集，结果显示，与传统 $\frac{1}{\sqrt{t}$ 步长相比，该方法可以提高准确率，具体提高了 $0.5\%$ 和 $1.4\%$。源代码可以在 \url{https://github.com/Shamaeem/LNSQRTStepSize} 找到。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Utility-Tradeoff-of-OLS-with-Random-Projections"><a href="#Privacy-Utility-Tradeoff-of-OLS-with-Random-Projections" class="headerlink" title="Privacy-Utility Tradeoff of OLS with Random Projections"></a>Privacy-Utility Tradeoff of OLS with Random Projections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01243">http://arxiv.org/abs/2309.01243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Lu, Malik Magdon-Ismail, Yu Wei, Vassilis Zikas</li>
<li>for: 本研究探讨了Linear Ordinary Least Squares（OLS）问题的分布式隐私（DP）性。</li>
<li>methods: 本研究使用了Sarlos（2006）提出的Approximate LS Algorithm（ALS），以及Dwork et al.（2014）的标准 Gaussian Mechanism。我们还提出了一种新的DP分析方法，以及一些可能是独立有用的工具。</li>
<li>results: 我们的研究结果表明，ALS算法可以保持隐私，而无需修改或噪声加工。我们还提供了第一个精确的DP分析方法，以及一些改进的DP分析工具。此外，我们还证明了，在大规模数据集中，计算DP级别可能是不可能的。因此，需要开发黑obox DP估计器，以便在实际应用中 empirically  estimating 数据中的隐私级别。<details>
<summary>Abstract</summary>
We study the differential privacy (DP) of a core ML problem, linear ordinary least squares (OLS), a.k.a. $\ell_2$-regression. Our key result is that the approximate LS algorithm (ALS) (Sarlos, 2006), a randomized solution to the OLS problem primarily used to improve performance on large datasets, also preserves privacy. ALS achieves a better privacy/utility tradeoff, without modifications or further noising, when compared to alternative private OLS algorithms which modify and/or noise OLS. We give the first {\em tight} DP-analysis for the ALS algorithm and the standard Gaussian mechanism (Dwork et al., 2014) applied to OLS. Our methodology directly improves the privacy analysis of (Blocki et al., 2012) and (Sheffet, 2019)) and introduces new tools which may be of independent interest: (1) the exact spectrum of $(\epsilon, \delta)$-DP parameters (``DP spectrum") for mechanisms whose output is a $d$-dimensional Gaussian, and (2) an improved DP spectrum for random projection (compared to (Blocki et al., 2012) and (Sheffet, 2019)).   All methods for private OLS (including ours) assume, often implicitly, restrictions on the input database, such as bounds on leverage and residuals. We prove that such restrictions are necessary. Hence, computing the privacy of mechanisms such as ALS must estimate these database parameters, which can be infeasible in big datasets. For more complex ML models, DP bounds may not even be tractable. There is a need for blackbox DP-estimators (Lu et al., 2022) which empirically estimate a data-dependent privacy. We demonstrate the effectiveness of such a DP-estimator by empirically recovering a DP-spectrum that matches our theory for OLS. This validates the DP-estimator in a nontrivial ML application, opening the door to its use in more complex nonlinear ML settings where theory is unavailable.
</details>
<details>
<summary>摘要</summary>
我们研究了线性最小二乘（OLS）问题中的分数隐私（DP）。我们的关键结论是，偏相对最小二乘（ALS）算法（Sarlos，2006），一种用于提高大型数据集的性能的随机解决方案，同时也保持隐私。相比于其他修改和噪声OLS算法，ALS实现了更好的隐私/用途质量比，无需进一步修改或噪声。我们提供了首个紧密的DP分析 дляALS算法和标准 Gaussian机制（Dwork等，2014）应用于OLS问题。我们的方法直接改进了（Blocki等，2012）和（Sheffet，2019）中的隐私分析，并 introduce了新的工具：（1）DP分布的准确谱（DP spectrum），其中输出是一个$d$-维 Gaussian 分布，以及（2）改进的DP分布 для随机投影。所有私有OLS（包括我们的）都假设了输入数据库中的约束，例如，约束在输入数据中的倾斜和差异。我们证明了这些约束是必需的。因此，计算私有OLS的隐私必须估计这些数据库参数，这可能是大型数据集中的不可能任务。为更复杂的机器学习模型，DP bound可能无法可读。这需要黑盒DP估计器（Lu等，2022），它可以在数据中使用随机方法来估计数据依赖的隐私。我们证明了这种DP估计器的有效性，通过 empirically recovering a DP spectrum that matches our theory for OLS。这将开启黑盒DP估计器的使用在更复杂的非线性机器学习设置中，where theory is unavailable。
</details></li>
</ul>
<hr>
<h2 id="lfads-torch-A-modular-and-extensible-implementation-of-latent-factor-analysis-via-dynamical-systems"><a href="#lfads-torch-A-modular-and-extensible-implementation-of-latent-factor-analysis-via-dynamical-systems" class="headerlink" title="lfads-torch: A modular and extensible implementation of latent factor analysis via dynamical systems"></a>lfads-torch: A modular and extensible implementation of latent factor analysis via dynamical systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01230">http://arxiv.org/abs/2309.01230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arsedler9/lfads-torch">https://github.com/arsedler9/lfads-torch</a></li>
<li>paper_authors: Andrew R. Sedler, Chethan Pandarinath</li>
<li>for: 这篇论文是为了减少高维度神经活动中的噪音，以便在科学和工程领域中使用。</li>
<li>methods: 这篇论文使用了一种名为“Latent Factor Analysis via Dynamical Systems”的Variational Sequential Autoencoder（RNN-based），以解决高维度神经活动中的噪音问题。</li>
<li>results: 这篇论文的结果显示，这种方法可以实现高度的表现，并且可以应用到许多 neuroscience 中的问题上。<details>
<summary>Abstract</summary>
Latent factor analysis via dynamical systems (LFADS) is an RNN-based variational sequential autoencoder that achieves state-of-the-art performance in denoising high-dimensional neural activity for downstream applications in science and engineering. Recently introduced variants and extensions continue to demonstrate the applicability of the architecture to a wide variety of problems in neuroscience. Since the development of the original implementation of LFADS, new technologies have emerged that use dynamic computation graphs, minimize boilerplate code, compose model configuration files, and simplify large-scale training. Building on these modern Python libraries, we introduce lfads-torch -- a new open-source implementation of LFADS that unifies existing variants and is designed to be easier to understand, configure, and extend. Documentation, source code, and issue tracking are available at https://github.com/arsedler9/lfads-torch .
</details>
<details>
<summary>摘要</summary>
Latent Factor Analysis via Dynamical Systems（LFADS）是一种基于RNN的变量序列自动编码器，可以在科学和工程领域中实现高级别噪声去除神经活动数据。最近的变体和扩展继续证明了该架构在神经科学中的广泛应用。自LFADS原始实现以来，新的技术出现了，包括动态计算图、最小化boilerplate代码、组合模型配置文件和大规模训练。基于这些现代Python库，我们介绍lfads-torch---一个新的开源实现，它将 существующие变体集成起来，并设计为更容易理解、配置和扩展。文档、源代码和问题跟踪可以在https://github.com/arsedler9/lfads-torch 上找到。
</details></li>
</ul>
<hr>
<h2 id="Implicit-regularization-of-deep-residual-networks-towards-neural-ODEs"><a href="#Implicit-regularization-of-deep-residual-networks-towards-neural-ODEs" class="headerlink" title="Implicit regularization of deep residual networks towards neural ODEs"></a>Implicit regularization of deep residual networks towards neural ODEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01213">http://arxiv.org/abs/2309.01213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pierre Marion, Yu-Han Wu, Michael E. Sander, Gérard Biau<br>for: 这篇论文的目的是为了建立深度学习模型之间的数学基础，具体来说是将残留神经网络与神经� differential equations（ODEs）之间的连接固化。methods: 这篇论文使用了一种叫做偏微分流的方法来训练深度学习模型，并且证明了如果初始化了一个神经网络为一个残留神经网络的离散化，那么这个离散化会在训练过程中保持不变。results: 这篇论文的结果表明，如果神经网络满足一个Polyak-Lojasiewicz条件，那么 gradient flow 会收敛到一个全局最小值。此外，这个条件适用于一家 residual networks，其中每层的偏微分是一个二层感知器，并且它们在宽度方向上有一定的过度参数。numerical experiments 验证了这些结果。<details>
<summary>Abstract</summary>
Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to a global minimum. Numerical experiments illustrate our results.
</details>
<details>
<summary>摘要</summary>
深度学习模型中的剩余神经网络是当前最佳实践。它们的连续深度类型，神经 diferencial equations（ODEs）也广泛使用。尽管它们的成功，但是这两种模型之间的数学基础仍然缺乏固定的连接。在这篇文章中，我们向这个方向致力于建立深度神经网络向神经ODE的隐式规范，对非线性网络进行梯度流训练。我们证明，如果网络在训练开始时初始化为神经ODE的离散化，那么这种离散化会在训练过程中保持不变。我们的结果适用于有限的训练时间和训练时间趋于无穷大，只要网络满足一个Polyak-Lojasiewicz条件。这个条件适用于一家具有线性增强的二层感知机的残差神经网络，并且 garantía 梯度流 converges to a global minimum。实验证明了我们的结果。
</details></li>
</ul>
<hr>
<h2 id="Symbolically-integrating-tensor-networks-over-various-random-tensors-by-the-second-version-of-Python-RTNI"><a href="#Symbolically-integrating-tensor-networks-over-various-random-tensors-by-the-second-version-of-Python-RTNI" class="headerlink" title="Symbolically integrating tensor networks over various random tensors by the second version of Python RTNI"></a>Symbolically integrating tensor networks over various random tensors by the second version of Python RTNI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01167">http://arxiv.org/abs/2309.01167</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/motohisafukuda/pyrtni2">https://github.com/motohisafukuda/pyrtni2</a></li>
<li>paper_authors: Motohisa Fukuda</li>
<li>for: 这个论文是为了介绍PyRTNI2库的升级版本，该库可以 симвоlic integrate tensor networks over Haar-distributed unitary matrices。</li>
<li>methods: 这篇论文使用了element-wise moment calculus的方法，以及将tensor network diagrams和delta functions相关联的方法。</li>
<li>results: PyRTNI2可以处理Haar-distributed orthogonal matrices和实数和复数正态分布tensor，并可以导出tensor networks的格式为TensorNetwork，以便进行进一步的计算，包括低维度的情况，where Weingarten functions differ from high-dimensional cases。<details>
<summary>Abstract</summary>
We are upgrading the Python-version of RTNI, which symbolically integrates tensor networks over the Haar-distributed unitary matrices. Now, PyRTNI2 can treat the Haar-distributed orthogonal matrices and the real and complex normal Gaussian tensors as well. Moreover, it can export tensor networks in the format of TensorNetwork so that one can make further calculations with concrete tensors, even for low dimensions, where the Weingarten functions differ from the ones for high dimensions. The tutorial notebooks are found at GitHub: https://github.com/MotohisaFukuda/PyRTNI2. In this paper, we explain maths behind the program and show what kind of tensor network calculations can be made with it. For the former, we interpret the element-wise moment calculus of the above random matrices and tensors in terms of tensor network diagrams, and argue that the view is natural, relating delta functions in the calculus to edges in tensor network diagrams.
</details>
<details>
<summary>摘要</summary>
我们正在升级Python版本的RTNI，这个symbolically组合了tensor network的程式。现在PyRTNI2可以处理哈aar分布的对称矩阵和实部和复部的正 Gaussian 网络，并且可以将网络出口到TensorNetwork格式，以便进一步计算具体的网络，甚至低维度的网络，其中Weingarten函数与高维度不同。教程 Notebook可以在GitHub上找到：https://github.com/MotohisaFukuda/PyRTNI2。在这篇论文中，我们解释了软件的数学基础和展示了它可以进行哪些网络计算。对于前者，我们将元素级数律calculus of the above random matrices and tensors interpreting as tensor network diagrams, and argue that the view is natural, relating delta functions in the calculus to edges in tensor network diagrams.
</details></li>
</ul>
<hr>
<h2 id="Noise-robust-speech-emotion-recognition-with-signal-to-noise-ratio-adapting-speech-enhancement"><a href="#Noise-robust-speech-emotion-recognition-with-signal-to-noise-ratio-adapting-speech-enhancement" class="headerlink" title="Noise robust speech emotion recognition with signal-to-noise ratio adapting speech enhancement"></a>Noise robust speech emotion recognition with signal-to-noise ratio adapting speech enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01164">http://arxiv.org/abs/2309.01164</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wen Chen, Julia Hirschberg, Yu Tsao</li>
<li>for: 提高Speech Emotion Recognition（SER）系统的防噪性能。</li>
<li>methods: 提出了一种听力噪声降低（SE）技术，并使用了Signal-to-Noise-Ratio（SNR）水平检测结构和波形重建策略来减少噪声降低对语音信号的负面影响。</li>
<li>results: 实验结果表明，NRSER可以有效地提高SER系统的防噪性能，包括防止系统对完全背景噪声的识别。此外，提出的SNR水平检测结构可以独立地用于数据选择等任务。<details>
<summary>Abstract</summary>
Speech emotion recognition (SER) often experiences reduced performance due to background noise. In addition, making a prediction on signals with only background noise could undermine user trust in the system. In this study, we propose a Noise Robust Speech Emotion Recognition system, NRSER. NRSER employs speech enhancement (SE) to effectively reduce the noise in input signals. Then, the signal-to-noise-ratio (SNR)-level detection structure and waveform reconstitution strategy are introduced to reduce the negative impact of SE on speech signals with no or little background noise. Our experimental results show that NRSER can effectively improve the noise robustness of the SER system, including preventing the system from making emotion recognition on signals consisting solely of background noise. Moreover, the proposed SNR-level detection structure can be used individually for tasks such as data selection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本翻译成简化中文。<</SYS>>听话情感识别（SER）经常受到背景噪声的影响，这会导致系统的性能下降。此外，基于背景噪声的预测可能会使用户对系统失去信任。在这种情况下，我们提出了一种防止噪声的Speech Emotion Recognition系统（NRSER）。NRSER使用了Speech Enhancement（SE）技术来有效地减少输入信号中的噪声。然后，我们引入了信号噪声比（SNR）水平检测结构和波形重建策略，以降低SE对无或少背景噪声的语音信号的负面影响。我们的实验结果表明，NRSER可以有效地提高噪声鲁棒性，包括避免系统对背景噪声只作出情感识别。此外，我们提出的SNR水平检测结构可以独立地应用于数据选择等任务。
</details></li>
</ul>
<hr>
<h2 id="An-Accurate-Graph-Generative-Model-with-Tunable-Features"><a href="#An-Accurate-Graph-Generative-Model-with-Tunable-Features" class="headerlink" title="An Accurate Graph Generative Model with Tunable Features"></a>An Accurate Graph Generative Model with Tunable Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01158">http://arxiv.org/abs/2309.01158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takahiro Yokoyama, Yoshiki Sato, Sho Tsugawa, Kohei Watabe</li>
<li>for: 这 paper 是为了提高 GraphTune 模型中 graph 特征的调整精度而写的。</li>
<li>methods: 这 paper 使用了一种新的Feedback Error Mechanism，将错误反馈到 GraphTune 模型中，并在独立地进行 Alternate Training，以提高 graph 特征的调整精度。</li>
<li>results: 实验结果表明，使用新的Feedback Error Mechanism 可以准确地调整 GraphTune 模型中的 graph 特征，比 conventinal models 更高精度。<details>
<summary>Abstract</summary>
A graph is a very common and powerful data structure used for modeling communication and social networks. Models that generate graphs with arbitrary features are important basic technologies in repeated simulations of networks and prediction of topology changes. Although existing generative models for graphs are useful for providing graphs similar to real-world graphs, graph generation models with tunable features have been less explored in the field. Previously, we have proposed GraphTune, a generative model for graphs that continuously tune specific graph features of generated graphs while maintaining most of the features of a given graph dataset. However, the tuning accuracy of graph features in GraphTune has not been sufficient for practical applications. In this paper, we propose a method to improve the accuracy of GraphTune by adding a new mechanism to feed back errors of graph features of generated graphs and by training them alternately and independently. Experiments on a real-world graph dataset showed that the features in the generated graphs are accurately tuned compared with conventional models.
</details>
<details>
<summary>摘要</summary>
一个图是非常常见和有力的数据结构，用于模型交流和社交网络。生成图模型是重要的基础技术，可以重复 simulate 网络和预测网络结构变化。虽然现有的生成图模型很有用，但是可调特征的图生成模型在领域中尚未得到充分发掘。我们之前已经提出了 GraphTune，一种可生成图模型，可以在生成图时连续调整特定图特征，保持大多数图集特征。但是，GraphTune 中的调整精度并没有达到实际应用中的需求。在这篇论文中，我们提出了一种方法来提高 GraphTune 的调整精度，通过添加一种反馈错误图特征的机制，并在独立地训练它们。实验表明，对实际图集进行生成后，图中的特征都能够准确地调整，比较于传统模型更加精准。
</details></li>
</ul>
<hr>
<h2 id="Advances-in-machine-learning-based-sampling-motivated-by-lattice-quantum-chromodynamics"><a href="#Advances-in-machine-learning-based-sampling-motivated-by-lattice-quantum-chromodynamics" class="headerlink" title="Advances in machine-learning-based sampling motivated by lattice quantum chromodynamics"></a>Advances in machine-learning-based sampling motivated by lattice quantum chromodynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01156">http://arxiv.org/abs/2309.01156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Cranmer, Gurtej Kanwar, Sébastien Racanière, Danilo J. Rezende, Phiala E. Shanahan</li>
<li>for: 这篇论文旨在探讨机器学习（ML）模型在计算物理学中的应用，尤其是在凝聚态场论中。</li>
<li>methods: 论文使用了特定的机器学习算法来采样概率分布，并利用了超级计算机来实现大规模的计算。</li>
<li>results: 论文的结果表明，使用机器学习模型可以有效地采样凝聚态场论中的结构和交互，并且可以实现first-principles的物理计算。<details>
<summary>Abstract</summary>
Sampling from known probability distributions is a ubiquitous task in computational science, underlying calculations in domains from linguistics to biology and physics. Generative machine-learning (ML) models have emerged as a promising tool in this space, building on the success of this approach in applications such as image, text, and audio generation. Often, however, generative tasks in scientific domains have unique structures and features -- such as complex symmetries and the requirement of exactness guarantees -- that present both challenges and opportunities for ML. This Perspective outlines the advances in ML-based sampling motivated by lattice quantum field theory, in particular for the theory of quantum chromodynamics. Enabling calculations of the structure and interactions of matter from our most fundamental understanding of particle physics, lattice quantum chromodynamics is one of the main consumers of open-science supercomputing worldwide. The design of ML algorithms for this application faces profound challenges, including the necessity of scaling custom ML architectures to the largest supercomputers, but also promises immense benefits, and is spurring a wave of development in ML-based sampling more broadly. In lattice field theory, if this approach can realize its early promise it will be a transformative step towards first-principles physics calculations in particle, nuclear and condensed matter physics that are intractable with traditional approaches.
</details>
<details>
<summary>摘要</summary>
伪乱分布的抽样是计算科学中的一项普遍任务，从语言学到生物和物理等领域都有广泛的应用。生成机器学习（ML）模型在这个领域得到了成功，基于图像、文本和音频生成等应用的成功。然而，在科学领域的生成任务中有独特的结构和特点，例如复杂的对称和精确性保证的要求，这对ML技术提出了挑战和机遇。这篇观点文章描述了基于ML的抽样技术的进步，特别是基于粒子物理学的假想场论。通过实现对物质结构和互动的计算，假想场论成为了物理学界最大的开源超级计算的主要用户。设计为这种应用的ML算法面临着巨大挑战，包括扩展自定义ML架构到最大超级计算机上的必要性，但也承诺巨大的利益，并在ML基于抽样技术的开发中促进了广泛的进步。在粒子物理学中，如果这种方法能实现早期的承诺，那么将是对first-principles物理计算的一个转变步骤，包括粒子、核和 condensed matter 物理的计算，这些计算是使用传统方法不可能完成的。
</details></li>
</ul>
<hr>
<h2 id="AutoML-GPT-Large-Language-Model-for-AutoML"><a href="#AutoML-GPT-Large-Language-Model-for-AutoML" class="headerlink" title="AutoML-GPT: Large Language Model for AutoML"></a>AutoML-GPT: Large Language Model for AutoML</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01125">http://arxiv.org/abs/2309.01125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun-Da Tsai, Yu-Che Tsai, Bo-Wei Huang, Chun-Pai Yang, Shou-De Lin</li>
<li>For: The paper is written for users who want to perform machine learning tasks but do not have deep domain knowledge. The paper aims to provide a framework called AutoML-GPT that simplifies the machine learning pipeline and reduces the time and effort required for these tasks.* Methods: The paper uses a conversational interface to allow users to specify their requirements, constraints, and evaluation metrics. The system employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance.* Results: The paper demonstrates through experimental results on diverse datasets that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. The system’s ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.<details>
<summary>Abstract</summary>
With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.
</details>
<details>
<summary>摘要</summary>
With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.Here's the translation in Traditional Chinese:With the emerging trend of GPT models, we have established a framework called AutoML-GPT that integrates a comprehensive set of tools and libraries. This framework grants users access to a wide range of data preprocessing techniques, feature engineering methods, and model selection algorithms. Through a conversational interface, users can specify their requirements, constraints, and evaluation metrics. Throughout the process, AutoML-GPT employs advanced techniques for hyperparameter optimization and model selection, ensuring that the resulting model achieves optimal performance. The system effectively manages the complexity of the machine learning pipeline, guiding users towards the best choices without requiring deep domain knowledge. Through our experimental results on diverse datasets, we have demonstrated that AutoML-GPT significantly reduces the time and effort required for machine learning tasks. Its ability to leverage the vast knowledge encoded in large language models enables it to provide valuable insights, identify potential pitfalls, and suggest effective solutions to common challenges faced during model training.
</details></li>
</ul>
<hr>
<h2 id="AI-driven-B-cell-Immunotherapy-Design"><a href="#AI-driven-B-cell-Immunotherapy-Design" class="headerlink" title="AI driven B-cell Immunotherapy Design"></a>AI driven B-cell Immunotherapy Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01122">http://arxiv.org/abs/2309.01122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bruna Moreira da Silva, David B. Ascher, Nicholas Geard, Douglas E. V. Pires</li>
<li>for: 本文旨在探讨人工智能和机器学习方法在B细胞免疫疗法设计方面的进步，包括线性和 conformational 蛋白结构预测、蛋白质预测、抗体设计等方面。</li>
<li>methods: 本文使用的方法包括线性和 conformational 蛋白结构预测、蛋白质预测、抗体设计等，以支持免疫疗法设计。</li>
<li>results: 本文结合了多种数据源、评估指标和方法，对Machine learning-based 工具和框架在B细胞免疫疗法设计方面的进步进行了评估和检验，并描述了主要挑战和未来发展的方向。<details>
<summary>Abstract</summary>
Antibodies, a prominent class of approved biologics, play a crucial role in detecting foreign antigens. The effectiveness of antigen neutralisation and elimination hinges upon the strength, sensitivity, and specificity of the paratope-epitope interaction, which demands resource-intensive experimental techniques for characterisation. In recent years, artificial intelligence and machine learning methods have made significant strides, revolutionising the prediction of protein structures and their complexes. The past decade has also witnessed the evolution of computational approaches aiming to support immunotherapy design. This review focuses on the progress of machine learning-based tools and their frameworks in the domain of B-cell immunotherapy design, encompassing linear and conformational epitope prediction, paratope prediction, and antibody design. We mapped the most commonly used data sources, evaluation metrics, and method availability and thoroughly assessed their significance and limitations, discussing the main challenges ahead.
</details>
<details>
<summary>摘要</summary>
抗体，一种已批准的生物药物，在检测外源抗原方面发挥重要作用。抗体中和降解的效果取决于蛋白质-蛋白质复合物之间的强度、敏感性和特异性，这些特性需要资源充沛的实验技术进行Characterization。在最近几年，人工智能和机器学习方法在蛋白质结构预测和其复合物预测方面做出了重要进步，对免疫疗法设计提供了支持。本文将关注使用机器学习技术支持B细胞免疫疗法设计的进展，包括线性和 conformational 抗体蛋白质预测、蛋白质预测和抗体设计。我们将最常用的数据源、评价指标和方法可用性进行映射，并且详细评估了它们的重要性和局限性，讨论了未来的主要挑战。
</details></li>
</ul>
<hr>
<h2 id="Double-Clipping-Less-Biased-Variance-Reduction-in-Off-Policy-Evaluation"><a href="#Double-Clipping-Less-Biased-Variance-Reduction-in-Off-Policy-Evaluation" class="headerlink" title="Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation"></a>Double Clipping: Less-Biased Variance Reduction in Off-Policy Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01120">http://arxiv.org/abs/2309.01120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Malte Lichtenberg, Alexander Buchholz, Giuseppe Di Benedetto, Matteo Ruffini, Ben London</li>
<li>for: 本研究旨在提出一种简单的扩展，以减少 clipping  estimator 的偏差，保持 variance 减少性能。</li>
<li>methods: 本研究使用的方法是 double clipping，它是一种基于 clipping 的 variance-reduction 技术，可以减少偏差，同时保持 variance 减少性能。</li>
<li>results: 研究表明，double clipping 可以减少 estimator 的偏差，同时保持 variance 减少性能，提高计算效率。<details>
<summary>Abstract</summary>
"Clipping" (a.k.a. importance weight truncation) is a widely used variance-reduction technique for counterfactual off-policy estimators. Like other variance-reduction techniques, clipping reduces variance at the cost of increased bias. However, unlike other techniques, the bias introduced by clipping is always a downward bias (assuming non-negative rewards), yielding a lower bound on the true expected reward. In this work we propose a simple extension, called $\textit{double clipping}$, which aims to compensate this downward bias and thus reduce the overall bias, while maintaining the variance reduction properties of the original estimator.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Carbon-Emission-Prediction-and-Clean-Industry-Transformation-Based-on-Machine-Learning-A-Case-Study-of-Sichuan-Province"><a href="#Carbon-Emission-Prediction-and-Clean-Industry-Transformation-Based-on-Machine-Learning-A-Case-Study-of-Sichuan-Province" class="headerlink" title="Carbon Emission Prediction and Clean Industry Transformation Based on Machine Learning: A Case Study of Sichuan Province"></a>Carbon Emission Prediction and Clean Industry Transformation Based on Machine Learning: A Case Study of Sichuan Province</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01115">http://arxiv.org/abs/2309.01115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanming Zhang, Xiaoxue Wang, Yonghang Chen</li>
<li>For: 本研究使用矩阵正常化处理2000-2019年四川省46个键盘产业的能源消耗数据，使用DBSCAN封顶分析 objective 分类行业。* Methods: 本研究使用DBSCAN封顶分析 objective 分类行业，并使用罚款回归模型来控制过采样、处理高维数据和选择特征。* Results: 研究发现第二个群around coal有最高排放，这主要归结于生产需求。 gasoline-focused和coke-focused 群也有显著的排放。根据这些结果，提出了使用清洁煤矿技术、交通管理、钢铁行业电力取代煤炭、行业标准化等减排策略。<details>
<summary>Abstract</summary>
This study preprocessed 2000-2019 energy consumption data for 46 key Sichuan industries using matrix normalization. DBSCAN clustering identified 16 feature classes to objectively group industries. Penalized regression models were then applied for their advantages in overfitting control, high-dimensional data processing, and feature selection - well-suited for the complex energy data. Results showed the second cluster around coal had highest emissions due to production needs. Emissions from gasoline-focused and coke-focused clusters were also significant. Based on this, emission reduction suggestions included clean coal technologies, transportation management, coal-electricity replacement in steel, and industry standardization. The research introduced unsupervised learning to objectively select factors and aimed to explore new emission reduction avenues. In summary, the study identified industry groupings, assessed emissions drivers, and proposed scientific reduction strategies to better inform decision-making using algorithms like DBSCAN and penalized regression models.
</details>
<details>
<summary>摘要</summary>
这个研究对2000-2019年四川46个重点产业的能源消耗数据进行了归一化处理。使用DBSCAN划分 clustering 方法对行业进行了 объектив分类。然后，对高维数据进行了惩罚回归模型的应用，以便控制过拟合、处理高维数据和选择特征。研究结果显示，第二个群组织煤矿产业占据了最高排出水平，这是因为生产需要。汽油和焦炭专注的群组也有显著的排出水平。根据这些结果，提出了清洁煤技术、交通管理、钢铁产业煤电replace和产业标准化等减排策略。这项研究通过不监督学习方法选择因素，探索了新的减排途径，以更好地 Inform 决策。In summary, the study used unsupervised learning techniques like DBSCAN clustering and penalized regression models to identify industry groupings, assess emissions drivers, and propose scientific reduction strategies for better decision-making. The research aimed to explore new emission reduction avenues by introducing unsupervised learning to objectively select factors.
</details></li>
</ul>
<hr>
<h2 id="Acoustic-to-articulatory-inversion-for-dysarthric-speech-Are-pre-trained-self-supervised-representations-favorable"><a href="#Acoustic-to-articulatory-inversion-for-dysarthric-speech-Are-pre-trained-self-supervised-representations-favorable" class="headerlink" title="Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?"></a>Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01108">http://arxiv.org/abs/2309.01108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarthak Kumar Maharana, Krishna Kamal Adidam, Shoumik Nandi, Ajitesh Srivastava</li>
<li>for: 这个研究旨在用自动学习模型（SSL）来实现声学到词语运动的映射（AAI），并研究不同的训练方案对于慢性肢骨疾病（dysarthria）的影响。</li>
<li>methods: 研究使用了不同的SSL模型，包括wav2vec、APC和DeCoAR，并使用了x-vector来训练一个BLSTM网络。不同的训练方案包括subject-specific、pooled和精度调整。</li>
<li>results: 研究发现，在seen和unseen情况下，使用SSL模型对于dysarthria患者的词语运动预测具有显著改善，相比MFCC。DeCoAR在精度调整方案下，对于健康人和患者都显示了${\sim}1.81%}$和${\sim}4.56%}$的Relative Improvement of Pearson Correlation Coefficient（CC）。<details>
<summary>Abstract</summary>
$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the acoustic space to the articulatory space. Signal-processing features like the MFCCs, have been widely used for the AAI task. For subjects with dysarthric speech, AAI is challenging because of an imprecise and indistinct pronunciation. In this work, we perform AAI for dysarthric speech using representations from pre-trained self-supervised learning (SSL) models. We demonstrate the impact of different pre-trained features on this challenging AAI task, at low-resource conditions. In addition, we also condition x-vectors to the extracted SSL features to train a BLSTM network. In the seen case, we experiment with three AAI training schemes (subject-specific, pooled, and fine-tuned). The results, consistent across training schemes, reveal that DeCoAR, in the fine-tuned scheme, achieves a relative improvement of the Pearson Correlation Coefficient (CC) by ${\sim}$1.81\% and ${\sim}$4.56\% for healthy controls and patients, respectively, over MFCCs. In the unseen case, we observe similar average trends for different SSL features. Overall, SSL networks like wav2vec, APC, and DeCoAR, which are trained with feature reconstruction or future timestep prediction tasks, perform well in predicting dysarthric articulatory trajectories.
</details>
<details>
<summary>摘要</summary>
$ $音律-语音映射（AAI）是将音律空间映射到语音空间。信号处理特征如MFCCs，已广泛用于AAI任务。对于具有异常语音的主题而言，AAI是一项挑战，因为它们的发音不准确和模糊。在这项工作中，我们使用预训练的自然语言学习（SSL）模型来实现AAI。我们表明了不同预训练特征对于这项具有挑战性的AAI任务的影响。此外，我们还将x-vector conditioning到提取的SSL特征来训练BLSTM网络。在可见情况下，我们尝试了三种AAI训练方案（主体特定、混合和细化）。结果显示，在细化方案下，DeCoAR achieved relative improvement of Pearson Correlation Coefficient (CC) by approximately 1.81% and 4.56% for healthy controls and patients, respectively, over MFCCs.在未见情况下，我们观察到了不同的SSL特征对于不同的语音特征的平均趋势。总的来说，SSL网络如wav2vec、APC和DeCoAR，通过特征重建或未来时间步预测任务进行训练，在预测异常语音的语音映射方面表现良好。
</details></li>
</ul>
<hr>
<h2 id="Solving-Non-Rectangular-Reward-Robust-MDPs-via-Frequency-Regularization"><a href="#Solving-Non-Rectangular-Reward-Robust-MDPs-via-Frequency-Regularization" class="headerlink" title="Solving Non-Rectangular Reward-Robust MDPs via Frequency Regularization"></a>Solving Non-Rectangular Reward-Robust MDPs via Frequency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01107">http://arxiv.org/abs/2309.01107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uri Gadot, Esther Derman, Navdeep Kumar, Maxence Mohamed Elfatihi, Kfir Levy, Shie Mannor</li>
<li>for: 本文研究了强化环境中的回报 Markov 决策过程（RMDP），具体来说是研究在固定转移核函数下，回报函数在一定范围内变化的情况下的 RMDP。</li>
<li>methods: 本文提出了一种基于策略访问频率规范化的方法，并证明其 converges。</li>
<li>results: 数值实验表明，该方法可以学习出一个更加稳健和 menos conservative 的策略，与传统的 rectangular uncertainty 相比。<details>
<summary>Abstract</summary>
In robust Markov decision processes (RMDPs), it is assumed that the reward and the transition dynamics lie in a given uncertainty set. By targeting maximal return under the most adversarial model from that set, RMDPs address performance sensitivity to misspecified environments. Yet, to preserve computational tractability, the uncertainty set is traditionally independently structured for each state. This so-called rectangularity condition is solely motivated by computational concerns. As a result, it lacks a practical incentive and may lead to overly conservative behavior. In this work, we study coupled reward RMDPs where the transition kernel is fixed, but the reward function lies within an $\alpha$-radius from a nominal one. We draw a direct connection between this type of non-rectangular reward-RMDPs and applying policy visitation frequency regularization. We introduce a policy-gradient method, and prove its convergence. Numerical experiments illustrate the learned policy's robustness and its less conservative behavior when compared to rectangular uncertainty.
</details>
<details>
<summary>摘要</summary>
在robust markov decision processes（RMDPs）中，假设奖励和转移动力在给定的不确定集中。通过targeting最大返回在最敌对模型下，RMDPs  Address performance sensitivity to misspecified environments.然而，为保持计算 tractability，不确定集通常是独立结构的每个状态。这种called rectangularity condition 仅由计算问题所衍生，而且缺乏实践驱动力，可能会导致过度保守的行为。在这项工作中，我们研究了奖励RMDPs，其中转移函数固定，但奖励函数在一个α-距离 nominated one 内。我们 drew a direct connection between这种非正方形奖励-RMDPs 和应用策略访问频率规范化。我们介绍了一种策略梯度法，并证明其 convergence。numerical experiments 表明学习策略的 robustness 和与矩形不确定相比较保守的行为。
</details></li>
</ul>
<hr>
<h2 id="Tropical-Geometric-Tools-for-Machine-Learning-the-TML-package"><a href="#Tropical-Geometric-Tools-for-Machine-Learning-the-TML-package" class="headerlink" title="Tropical Geometric Tools for Machine Learning: the TML package"></a>Tropical Geometric Tools for Machine Learning: the TML package</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01082">http://arxiv.org/abs/2309.01082</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/barnhilldave/tml">https://github.com/barnhilldave/tml</a></li>
<li>paper_authors: David Barnhill, Ruriko Yoshida, Georges Aliatimis, Keiji Miura</li>
<li>for: 该论文主要用于描述一个基于 тропикаль几何的R包（TML包），该包包含了基本的 tropos 计算、视觉化 tropos 几何体以及基于 max-plus 代数的超vised 和无关 learn 模型。</li>
<li>methods: 该论文使用 Hit and Run Markov chain Monte Carlo 采样器和 тропи metric 进行统计推断。此外，论文还介绍了一些基于 tropos 的超vised 和无关 learn 方法，包括 tropos 主成分分析、 tropos 逻辑回归和 tropos 核密度估计。</li>
<li>results: 论文的结果主要表明，使用 tropically 的 HAR 采样器可以有效地进行统计推断，并且可以应用于多种超vised 和无关 learn 问题。此外，论文还提出了一些基于 tropos 的新的方法和应用，例如 tropos 主成分分析和 tropos 核密度估计。<details>
<summary>Abstract</summary>
In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
</details>
<details>
<summary>摘要</summary>
在过去一个十年中， тропическая геометрия的发展已经为统计学学习带来了许多直接适用的应用。TML包是R包中的第一个包含涵盖тропические几何基本计算、视觉化 тропически几何集以及使用极大加法代数下的极大值推论的完整工具集。主要地，TML包使用 тропи metric来进行统计推论，使用射击和逃跑Markov链式 Monte Carlo抽样法。此外，TML包还包括了一些基本计算和各种应用，如тропические主成分分析、тропические逻辑回归和 тропические核密度估计。
</details></li>
</ul>
<hr>
<h2 id="Federated-Few-shot-Learning-for-Cough-Classification-with-Edge-Devices"><a href="#Federated-Few-shot-Learning-for-Cough-Classification-with-Edge-Devices" class="headerlink" title="Federated Few-shot Learning for Cough Classification with Edge Devices"></a>Federated Few-shot Learning for Cough Classification with Edge Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01076">http://arxiv.org/abs/2309.01076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngandh/F2LCough">https://github.com/ngandh/F2LCough</a></li>
<li>paper_authors: Ngan Dao Hoang, Dat Tran-Anh, Manh Luong, Cong Tran, Cuong Pham</li>
<li>for: 这份研究的目的是为了开发一个能够有效地分类喀丙 зву频的框架，并且在没有庞大量标注数据的情况下进行分类，同时也考虑到隐私问题。</li>
<li>methods: 这份研究使用了少数据学和联合学来设计一个称为F2LCough的新框架，以解决这个新的问题。</li>
<li>results: 我们的结果显示，F2LCough在COVID-19 Thermal Face &amp; Cough数据集上取得了86%的F1-Score，较其他方法为高。这显示了几据学和联合学可以在数据缺乏情况下建立一个分类模型，并且维护了隐私性。<details>
<summary>Abstract</summary>
Automatically classifying cough sounds is one of the most critical tasks for the diagnosis and treatment of respiratory diseases. However, collecting a huge amount of labeled cough dataset is challenging mainly due to high laborious expenses, data scarcity, and privacy concerns. In this work, our aim is to develop a framework that can effectively perform cough classification even in situations when enormous cough data is not available, while also addressing privacy concerns. Specifically, we formulate a new problem to tackle these challenges and adopt few-shot learning and federated learning to design a novel framework, termed F2LCough, for solving the newly formulated problem. We illustrate the superiority of our method compared with other approaches on COVID-19 Thermal Face & Cough dataset, in which F2LCough achieves an average F1-Score of 86%. Our results show the feasibility of few-shot learning combined with federated learning to build a classification model of cough sounds. This new methodology is able to classify cough sounds in data-scarce situations and maintain privacy properties. The outcomes of this work can be a fundamental framework for building support systems for the detection and diagnosis of cough-related diseases.
</details>
<details>
<summary>摘要</summary>
自动分类咳声是肺病诊断和治疗中最关键的任务之一，但收集庞大量标注咳数据却具有高度劳动成本、数据缺乏和隐私问题。在这种情况下，我们的目标是开发一个能够有效地进行咳类型分类的框架，同时解决隐私问题。我们将问题重新定义为新的问题，并采用少量学习和联合学习来设计一个名为F2LCough的新框架。我们在COVID-19 thermal face & cough数据集上进行了比较，发现F2LCough在average F1-Score方面达到86%。这些结果表明了少量学习与联合学习的可行性，可以在数据缺乏情况下分类咳声并保持隐私性。这种新的方法可以为诊断咳病提供支持。
</details></li>
</ul>
<hr>
<h2 id="Towards-Efficient-Modeling-and-Inference-in-Multi-Dimensional-Gaussian-Process-State-Space-Models"><a href="#Towards-Efficient-Modeling-and-Inference-in-Multi-Dimensional-Gaussian-Process-State-Space-Models" class="headerlink" title="Towards Efficient Modeling and Inference in Multi-Dimensional Gaussian Process State-Space Models"></a>Towards Efficient Modeling and Inference in Multi-Dimensional Gaussian Process State-Space Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01074">http://arxiv.org/abs/2309.01074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhidilin/gpssmproj">https://github.com/zhidilin/gpssmproj</a></li>
<li>paper_authors: Zhidi Lin, Juan Maroñas, Ying Li, Feng Yin, Sergios Theodoridis</li>
<li>for: 用于模型复杂非线性动力系统</li>
<li>methods: 使用高效变换 Gaussian 过程（ETGP）和相应的变量推断算法</li>
<li>results: 实验结果表明，提议方法可以减少参数数量和计算复杂性，同时可以与现有方法相比做出类似的推断性能。<details>
<summary>Abstract</summary>
The Gaussian process state-space model (GPSSM) has attracted extensive attention for modeling complex nonlinear dynamical systems. However, the existing GPSSM employs separate Gaussian processes (GPs) for each latent state dimension, leading to escalating computational complexity and parameter proliferation, thus posing challenges for modeling dynamical systems with high-dimensional latent states. To surmount this obstacle, we propose to integrate the efficient transformed Gaussian process (ETGP) into the GPSSM, which involves pushing a shared GP through multiple normalizing flows to efficiently model the transition function in high-dimensional latent state space. Additionally, we develop a corresponding variational inference algorithm that surpasses existing methods in terms of parameter count and computational complexity. Experimental results on diverse synthetic and real-world datasets corroborate the efficiency of the proposed method, while also demonstrating its ability to achieve similar inference performance compared to existing methods. Code is available at \url{https://github.com/zhidilin/gpssmProj}.
</details>
<details>
<summary>摘要</summary>
Gaussian  процесс状态空间模型 (GPSSM) 已经吸引了广泛的关注，用于模型复杂非线性动力系统。然而，现有的 GPSSM 使用每个隐藏状态维度之间的分离 Gaussian 过程 (GP)，导致计算复杂性和参数增加，从而对高维隐藏状态系统的模型 pose 了挑战。为了缓解这个困难，我们提议将高效转换 Gaussian 过程 (ETGP) 集成到 GPSSM 中，该方法涉及将共享 GP Push 多个 normalizing flows，以高效地模型高维隐藏状态空间中的过渡函数。此外，我们还开发了相应的变量推理算法，它在参数计数和计算复杂性方面超过了现有方法。实验结果表明，提议的方法在多种 sintetic 和实际世界数据上具有高效性，同时也能够达到与现有方法相似的推理性能。代码可以在 \url{https://github.com/zhidilin/gpssmProj} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MQENet-A-Mesh-Quality-Evaluation-Neural-Network-Based-on-Dynamic-Graph-Attention"><a href="#MQENet-A-Mesh-Quality-Evaluation-Neural-Network-Based-on-Dynamic-Graph-Attention" class="headerlink" title="MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph Attention"></a>MQENet: A Mesh Quality Evaluation Neural Network Based on Dynamic Graph Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01067">http://arxiv.org/abs/2309.01067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoxuan Zhang, Haisheng Li, Nan Li, Xiaochuan Wang</li>
<li>for: 这个论文的目的是提出一种基于动态图注意力的结构网格质量评估神经网络（MQENet），以便评估计算流体力学应用中的网格质量。</li>
<li>methods: 该论文使用了两种新的结构网格处理算法，以提高结构网格数据的转换效率。它还将网格评估任务定义为一种图分类任务，以 классифици�ayerStructured mesh quality evaluation task.</li>
<li>results: 实验结果表明，MQENet可以有效地评估结构网格的质量，并且在NACA-Market benchmark dataset上达到了高度的评估精度。<details>
<summary>Abstract</summary>
With the development of computational fluid dynamics, the requirements for the fluid simulation accuracy in industrial applications have also increased. The quality of the generated mesh directly affects the simulation accuracy. However, previous mesh quality metrics and models cannot evaluate meshes comprehensively and objectively. To this end, we propose MQENet, a structured mesh quality evaluation neural network based on dynamic graph attention. MQENet treats the mesh evaluation task as a graph classification task for classifying the quality of the input structured mesh. To make graphs generated from structured meshes more informative, MQENet introduces two novel structured mesh preprocessing algorithms. These two algorithms can also improve the conversion efficiency of structured mesh data. Experimental results on the benchmark structured mesh dataset NACA-Market show the effectiveness of MQENet in the mesh quality evaluation task.
</details>
<details>
<summary>摘要</summary>
随着计算流体动力学的发展，工业应用中流体模拟精度的要求也在不断提高。mesh质量直接影响模拟精度。然而，过去的网格质量指标和模型无法全面、 объектив地评估网格质量。为此，我们提出MQENet，一种基于动态图注意力的结构化网格质量评估神经网络。MQENet将网格评估任务视为一种图分类任务，用于评估输入结构网格的质量。为了使结构网格生成的图更加有用，MQENet引入了两种新的结构网格预处理算法。这两种算法还可以提高结构网格数据的转换效率。实验结果表明，MQENet在标准网格数据集NACA-Market上得到了较高的评估精度。
</details></li>
</ul>
<hr>
<h2 id="Distribution-learning-via-neural-differential-equations-a-nonparametric-statistical-perspective"><a href="#Distribution-learning-via-neural-differential-equations-a-nonparametric-statistical-perspective" class="headerlink" title="Distribution learning via neural differential equations: a nonparametric statistical perspective"></a>Distribution learning via neural differential equations: a nonparametric statistical perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01043">http://arxiv.org/abs/2309.01043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youssef Marzouk, Zhi Ren, Sven Wang, Jakob Zech</li>
<li>for: 这篇论文的目的是研究几何 diffeomorphism 模型在机器学习中的统计性质。</li>
<li>methods: 这篇论文使用了 likelihood 最大化 方法来训练几何 diffeomorphism 模型，并提出了一个通用的非Parametric 统计收敛分析方法。</li>
<li>results: 这篇论文提出了一个普适的统计收敛分析方法，并在 $C^k$ 平滑目标分布和神经网络类型中实现了nearly minimax-optimal 的收敛率。<details>
<summary>Abstract</summary>
Ordinary differential equations (ODEs), via their induced flow maps, provide a powerful framework to parameterize invertible transformations for the purpose of representing complex probability distributions. While such models have achieved enormous success in machine learning, particularly for generative modeling and density estimation, little is known about their statistical properties. This work establishes the first general nonparametric statistical convergence analysis for distribution learning via ODE models trained through likelihood maximization. We first prove a convergence theorem applicable to arbitrary velocity field classes $\mathcal{F}$ satisfying certain simple boundary constraints. This general result captures the trade-off between approximation error (`bias') and the complexity of the ODE model (`variance'). We show that the latter can be quantified via the $C^1$-metric entropy of the class $\mathcal F$. We then apply this general framework to the setting of $C^k$-smooth target densities, and establish nearly minimax-optimal convergence rates for two relevant velocity field classes $\mathcal F$: $C^k$ functions and neural networks. The latter is the practically important case of neural ODEs.   Our proof techniques require a careful synthesis of (i) analytical stability results for ODEs, (ii) classical theory for sieved M-estimators, and (iii) recent results on approximation rates and metric entropies of neural network classes. The results also provide theoretical insight on how the choice of velocity field class, and the dependence of this choice on sample size $n$ (e.g., the scaling of width, depth, and sparsity of neural network classes), impacts statistical performance.
</details>
<details>
<summary>摘要</summary>
ordinary differential equations (ODEs) 通过它们引入的流动图，提供了一个强大的框架来Parameterize invertible transformations，以便表示复杂的概率分布。而这些模型在机器学习中已经取得了巨大的成功，特别是在生成模型和概率预测方面。然而，对这些模型的统计性质所知之少。这个工作首次提供了对ODE模型通过最大化likelihood进行学习的统计收敛分析。我们首先证明了适用于任何速度场类$\mathcal{F}$满足某些简单的边界约束的收敛定理。这个总体结果捕捉了在approximation error('bias')和ODE模型('variance')之间的负责任。我们表明了后者可以通过$\mathcal{F}$的$C^1$度量 entropy来衡量。然后，我们将这个总体框架应用于$C^k$平滑目标分布的设置，并确定了相对迫近最优的收敛率。其中，$C^k$函数和神经网络是两个有实际意义的速度场类。我们的证明技术需要结合(i) ODEs的分析稳定性结果，(ii) Sieved M-estimators的经典理论，以及(iii)近期关于应用率和度量Entropy的神经网络类的结果。结果还提供了对速度场类选择和样本大小 $n$（例如，宽度、深度和稀疏性的神经网络类的依赖关系）的统计性能的理论启示。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/cs.LG_2023_09_03/" data-id="clpxp041s00r6fm887g60dub6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/03/eess.IV_2023_09_03/" class="article-date">
  <time datetime="2023-09-03T09:00:00.000Z" itemprop="datePublished">2023-09-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/03/eess.IV_2023_09_03/">eess.IV - 2023-09-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Breast-MRI-radiomics-and-machine-learning-radiomics-based-predictions-of-response-to-neoadjuvant-chemotherapy-–-how-are-they-affected-by-variations-in-tumour-delineation"><a href="#Breast-MRI-radiomics-and-machine-learning-radiomics-based-predictions-of-response-to-neoadjuvant-chemotherapy-–-how-are-they-affected-by-variations-in-tumour-delineation" class="headerlink" title="Breast MRI radiomics and machine learning radiomics-based predictions of response to neoadjuvant chemotherapy – how are they affected by variations in tumour delineation?"></a>Breast MRI radiomics and machine learning radiomics-based predictions of response to neoadjuvant chemotherapy – how are they affected by variations in tumour delineation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01210">http://arxiv.org/abs/2309.01210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepideh Hatamikia, Geevarghese George, Florian Schwarzhans, Amirreza Mahbod, Ramona Woitek<br>for: 这个研究的目的是为了evaluating the impact of variations in manual delineations of volumes of interest (VOIs) on the performance of radiomics predictors in breast cancer subtypes.methods: 这个研究使用了contrast-enhanced magnetic resonance imaging (MRI) acquired prior to treatment (baseline MRI scans)，并使用了不同的mathematical operations such as erosion, smoothing, dilation, randomization, and ellipse fitting to simulate variations of segmentation masks.results: 研究发现，使用不同的VOI delineation methods can significantly affect the number of robust features and prediction performance in radiomics analysis. Specifically, smoothing and erosion yielded the highest number of robust features and the best prediction performance, while ellipse fitting and dilation led to the lowest robustness and prediction performance for both breast cancer subtypes. Additionally, the study found that at most 28% of the selected features were similar to manual VOIs when different VOI delineation data were used.<details>
<summary>Abstract</summary>
Manual delineation of volumes of interest (VOIs) by experts is considered the gold-standard method in radiomics analysis. However, it suffers from inter- and intra-operator variability. A quantitative assessment of the impact of variations in these delineations on the performance of the radiomics predictors is required to develop robust radiomics based prediction models. In this study, we developed radiomics models for the prediction of pathological complete response to neoadjuvant chemotherapy in patients with two different breast cancer subtypes based on contrast-enhanced magnetic resonance imaging acquired prior to treatment (baseline MRI scans). Different mathematical operations such as erosion, smoothing, dilation, randomization, and ellipse fitting were applied to the original VOIs delineated by experts to simulate variations of segmentation masks. The effects of such VOI modifications on various steps of the radiomics workflow, including feature extraction, feature selection, and prediction performance, were evaluated. Using manual tumor VOIs and radiomics features extracted from baseline MRI scans, an AUC of up to 0.96 and 0.89 was achieved for human epidermal growth receptor 2 positive and triple-negative breast cancer, respectively. For smoothing and erosion, VOIs yielded the highest number of robust features and the best prediction performance, while ellipse fitting and dilation lead to the lowest robustness and prediction performance for both breast cancer subtypes. At most 28% of the selected features were similar to manual VOIs when different VOI delineation data were used. Differences in VOI delineation affects different steps of radiomics analysis, and their quantification is therefore important for development of standardized radiomics research.
</details>
<details>
<summary>摘要</summary>
临床验证是验证分析的标准方法，但它受到Operator variability的影响。为了开发可靠的验证模型，我们需要评估随着分割masks的变化而导致的预测器性能的影响。我们在基线MRI扫描前进行了针对不同乳腺癌分型的预后化学治疗的预测，并使用不同的数学操作来模拟分割masks的变化。我们评估了这些变化对验证过程中的特征提取、特征选择和预测性能的影响。使用手动肿瘤分割和基线MRI扫描中提取的验证特征，我们可以达到0.96和0.89的AUC，分别为人类肿瘤抑制剂2阳性和三重阴性乳腺癌。对于平滑和减小操作，分割masks具有最高的Robust特征数和最好的预测性能，而 для�elia和扩大操作，分割masks具有最低的Robust特征数和预测性能。最多28%的选择特征与手动分割数据相同。不同的分割masks导致不同的预测过程中的不同步骤受到影响，因此其量化对于开发标准化验证研究非常重要。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/03/eess.IV_2023_09_03/" data-id="clpxp049001a3fm8858n69tjr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.SD_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T15:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.SD_2023_09_02/">cs.SD - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Timbre-reserved-Adversarial-Attack-in-Speaker-Identification"><a href="#Timbre-reserved-Adversarial-Attack-in-Speaker-Identification" class="headerlink" title="Timbre-reserved Adversarial Attack in Speaker Identification"></a>Timbre-reserved Adversarial Attack in Speaker Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00929">http://arxiv.org/abs/2309.00929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qing Wang, Jixun Yao, Li Zhang, Pengcheng Guo, Lei Xie</li>
<li>for: 本研究旨在使SID系统遭受攻击时，不仅利用攻击者模型的漏洞，而且保留目标话者的时变特征。</li>
<li>methods: 本研究使用了voice conversion（VC）模型的不同训练阶段来生成具有攻击者识别label的对抗攻击音频。具体来说，在VC模型的训练过程中，透过将攻击者识别label加入模型训练，以便控制VC模型生成的音频具有目标话者的时变特征。</li>
<li>results: 本研究发现，透过将攻击者识别label加入VC模型训练，可以生成timbre-reserved的对抗攻击音频，具有目标话者的时变特征。这些对抗攻击音频可以让SID系统错误识别攻击者，并且保留目标话者的时变特征。<details>
<summary>Abstract</summary>
As a type of biometric identification, a speaker identification (SID) system is confronted with various kinds of attacks. The spoofing attacks typically imitate the timbre of the target speakers, while the adversarial attacks confuse the SID system by adding a well-designed adversarial perturbation to an arbitrary speech. Although the spoofing attack copies a similar timbre as the victim, it does not exploit the vulnerability of the SID model and may not make the SID system give the attacker's desired decision. As for the adversarial attack, despite the SID system can be led to a designated decision, it cannot meet the specified text or speaker timbre requirements for the specific attack scenarios. In this study, to make the attack in SID not only leverage the vulnerability of the SID model but also reserve the timbre of the target speaker, we propose a timbre-reserved adversarial attack in the speaker identification. We generate the timbre-reserved adversarial audios by adding an adversarial constraint during the different training stages of the voice conversion (VC) model. Specifically, the adversarial constraint is using the target speaker label to optimize the adversarial perturbation added to the VC model representations and is implemented by a speaker classifier joining in the VC model training. The adversarial constraint can help to control the VC model to generate the speaker-wised audio. Eventually, the inference of the VC model is the ideal adversarial fake audio, which is timbre-reserved and can fool the SID system.
</details>
<details>
<summary>摘要</summary>
为了使骗谋攻击（SID）系统不仅利用骗谋模型的漏洞，还保留目标说话人的时征特征，我们在这种研究中提出了一种具有时征保留的敌意攻击。我们在不同的训练阶段中添加了一个敌意约束，以控制VC模型生成说话人级别的声音。具体来说，我们使用目标说话人标签来优化骗谋模型表示中的敌意干扰，通过一个说话人分类器参与VC模型训练。这种敌意约束可以帮助控制VC模型生成说话人级别的声音，最终得到骗谋模型的恶意假声音，这个声音保留了目标说话人的时征特征。
</details></li>
</ul>
<hr>
<h2 id="DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin"><a href="#DiCLET-TTS-Diffusion-Model-based-Cross-lingual-Emotion-Transfer-for-Text-to-Speech-–-A-Study-between-English-and-Mandarin" class="headerlink" title="DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin"></a>DiCLET-TTS: Diffusion Model based Cross-lingual Emotion Transfer for Text-to-Speech – A Study between English and Mandarin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00883">http://arxiv.org/abs/2309.00883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Li, Chenxu Hu, Jian Cong, Xinfa Zhu, Jingbei Li, Qiao Tian, Yuping Wang, Lei Xie</li>
<li>for: 这篇研究旨在提高cross-lingual TTS的自然度和情感表达能力。</li>
<li>methods: 提出了一个基于传播过程的Diffusion model based Cross-Lingual Emotion Transfer方法（DiCLET-TTS），通过将情感从源语言 speaker 转移到内部和跨语言目标 speaker 上，以提高语言转移后的自然度和情感表达能力。</li>
<li>results: 试验结果显示DiCLET-TTS 比较优秀于多种竞争模型，并且OP-EDM 能够学习 speaker-irrelevant yet emotion-discriminative embedding。<details>
<summary>Abstract</summary>
While the performance of cross-lingual TTS based on monolingual corpora has been significantly improved recently, generating cross-lingual speech still suffers from the foreign accent problem, leading to limited naturalness. Besides, current cross-lingual methods ignore modeling emotion, which is indispensable paralinguistic information in speech delivery. In this paper, we propose DiCLET-TTS, a Diffusion model based Cross-Lingual Emotion Transfer method that can transfer emotion from a source speaker to the intra- and cross-lingual target speakers. Specifically, to relieve the foreign accent problem while improving the emotion expressiveness, the terminal distribution of the forward diffusion process is parameterized into a speaker-irrelevant but emotion-related linguistic prior by a prior text encoder with the emotion embedding as a condition. To address the weaker emotional expressiveness problem caused by speaker disentanglement in emotion embedding, a novel orthogonal projection based emotion disentangling module (OP-EDM) is proposed to learn the speaker-irrelevant but emotion-discriminative embedding. Moreover, a condition-enhanced DPM decoder is introduced to strengthen the modeling ability of the speaker and the emotion in the reverse diffusion process to further improve emotion expressiveness in speech delivery. Cross-lingual emotion transfer experiments show the superiority of DiCLET-TTS over various competitive models and the good design of OP-EDM in learning speaker-irrelevant but emotion-discriminative embedding.
</details>
<details>
<summary>摘要</summary>
Traditional cross-lingual TTS methods based on monolingual corpora have made significant progress in recent years, but they still suffer from the problem of foreign accents, which limits the naturalness of the speech. Moreover, current methods ignore the modeling of emotion, which is essential paralinguistic information in speech delivery. In this paper, we propose DiCLET-TTS, a diffusion model-based cross-lingual emotion transfer method that can transfer emotion from a source speaker to the intra- and cross-lingual target speakers. To address the foreign accent problem and improve emotion expressiveness, we use a prior text encoder with an emotion embedding as a condition to parameterize the terminal distribution of the forward diffusion process. To further improve emotion expressiveness, we propose a novel orthogonal projection-based emotion disentangling module (OP-EDM) to learn speaker-irrelevant but emotion-discriminative embeddings. In addition, we introduce a condition-enhanced DPM decoder to strengthen the modeling ability of the speaker and the emotion in the reverse diffusion process. Cross-lingual emotion transfer experiments show that DiCLET-TTS outperforms various competitive models and demonstrates the effectiveness of OP-EDM in learning speaker-irrelevant but emotion-discriminative embeddings.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.SD_2023_09_02/" data-id="clpxp044n00yzfm888y44ew8h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.CV_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T13:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.CV_2023_09_02/">cs.CV - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SEPAL-Spatial-Gene-Expression-Prediction-from-Local-Graphs"><a href="#SEPAL-Spatial-Gene-Expression-Prediction-from-Local-Graphs" class="headerlink" title="SEPAL: Spatial Gene Expression Prediction from Local Graphs"></a>SEPAL: Spatial Gene Expression Prediction from Local Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01036">http://arxiv.org/abs/2309.01036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcv-uniandes/sepal">https://github.com/bcv-uniandes/sepal</a></li>
<li>paper_authors: Gabriel Mejia, Paula Cárdenas, Daniela Ruiz, Angela Castillo, Pablo Arbeláez</li>
<li>for: 这项研究旨在开发一种新的模型，以便从视觉组织形态中预测基因表达 Profiling。</li>
<li>methods: 该方法利用生物学上的偏好，直接使用相对均值对表达进行超级视觉上的预测，并在每个坐标上使用图神经网络利用本地视觉上下文进行预测。</li>
<li>results: 研究表明，SEPAL模型在两个人类乳腺癌数据集中表现出色，超过了之前的州OF-the-art方法和其他包含空间上下文的机制。<details>
<summary>Abstract</summary>
Spatial transcriptomics is an emerging technology that aligns histopathology images with spatially resolved gene expression profiling. It holds the potential for understanding many diseases but faces significant bottlenecks such as specialized equipment and domain expertise. In this work, we present SEPAL, a new model for predicting genetic profiles from visual tissue appearance. Our method exploits the biological biases of the problem by directly supervising relative differences with respect to mean expression, and leverages local visual context at every coordinate to make predictions using a graph neural network. This approach closes the gap between complete locality and complete globality in current methods. In addition, we propose a novel benchmark that aims to better define the task by following current best practices in transcriptomics and restricting the prediction variables to only those with clear spatial patterns. Our extensive evaluation in two different human breast cancer datasets indicates that SEPAL outperforms previous state-of-the-art methods and other mechanisms of including spatial context.
</details>
<details>
<summary>摘要</summary>
《空间转录组学是一种emerging技术，可以将组织学图像与空间地定的蛋白表达 profiling进行对应。它有很大的潜力用于理解多种疾病，但面临着重要的瓶颈，例如专业设备和领域专业知识。在这项工作中，我们提出了一种新的模型，可以从视觉组织表现中预测基因谱。我们的方法利用生物学上的偏见，直接监督表达差异相对于平均表达水平，并利用每个坐标点的本地视觉上下文来进行预测，使用图 neural network。这种方法可以在当前方法中关闭完全地方性和完全全球性之间的差距。此外，我们还提出了一个新的标准测试，以更好地定义任务，并且只Predicting variables with clear spatial patterns。我们对两个不同的人乳癌组织数据集进行了广泛的评估，结果显示，SEPAL在前一个状态的方法和其他包含空间上下文的机制上表现出色。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Grouping-with-Transformer-for-Referring-Image-Segmentation"><a href="#Contrastive-Grouping-with-Transformer-for-Referring-Image-Segmentation" class="headerlink" title="Contrastive Grouping with Transformer for Referring Image Segmentation"></a>Contrastive Grouping with Transformer for Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01017">http://arxiv.org/abs/2309.01017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/toneyaya/cgformer">https://github.com/toneyaya/cgformer</a></li>
<li>paper_authors: Jiajin Tang, Ge Zheng, Cheng Shi, Sibei Yang</li>
<li>for: 本研究旨在提高图像分割中的参照语言表达的准确率，使用mask classification方法和token-based查询 grouping策略来捕捉 объек级信息。</li>
<li>methods: 本研究提出了一种名为Contrastive Grouping with Transformer network（CGFormer）的掩码分类方法，该方法通过学习可变的查询токен来表示 объек，然后在每两层之间交叉升级查询语言特征和视觉特征，以实现对象感知的跨模态理解。此外，CGFormer还应用了对比学习策略来识别查询Token和其掩码。</li>
<li>results: 实验结果表明，CGFormer在分割和泛化设定下都能够具有州元的性能，与现有的一阶方法相比，CGFormer在对象分割任务中具有显著的优势。<details>
<summary>Abstract</summary>
Referring image segmentation aims to segment the target referent in an image conditioning on a natural language expression. Existing one-stage methods employ per-pixel classification frameworks, which attempt straightforwardly to align vision and language at the pixel level, thus failing to capture critical object-level information. In this paper, we propose a mask classification framework, Contrastive Grouping with Transformer network (CGFormer), which explicitly captures object-level information via token-based querying and grouping strategy. Specifically, CGFormer first introduces learnable query tokens to represent objects and then alternately queries linguistic features and groups visual features into the query tokens for object-aware cross-modal reasoning. In addition, CGFormer achieves cross-level interaction by jointly updating the query tokens and decoding masks in every two consecutive layers. Finally, CGFormer cooperates contrastive learning to the grouping strategy to identify the token and its mask corresponding to the referent. Experimental results demonstrate that CGFormer outperforms state-of-the-art methods in both segmentation and generalization settings consistently and significantly.
</details>
<details>
<summary>摘要</summary>
传统的一个阶段方法使用每个像素的分类框架，直接将视觉和语言对齐到像素级别，因此无法捕捉关键的物体水平信息。在这篇论文中，我们提出了一种面Mask分类框架，即对比集成Transformers网络（CGFormer），它显式地捕捉物体水平信息，通过启用可学习的查询令和分组策略。具体来说，CGFormer首先引入了可学习的查询令，用于表示物体，然后在每两层交替地查询语言特征和视觉特征，并将视觉特征分组到查询令中进行对应的横向推理。此外，CGFormer实现了交叉层交互，在每两层中同时更新查询令和推理mask。最后，CGFormer与对比学习结合分组策略，以确定查询令和其对应的推理mask。实验结果表明，CGFormer在 segmentation 和通用设定下能够一直高效地和稳定地 exceed 状态元方法。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Deep-Learning-Architectures-for-Breast-Cancer-Diagnosis-Using-the-BreaKHis-Dataset"><a href="#Comparative-Analysis-of-Deep-Learning-Architectures-for-Breast-Cancer-Diagnosis-Using-the-BreaKHis-Dataset" class="headerlink" title="Comparative Analysis of Deep Learning Architectures for Breast Cancer Diagnosis Using the BreaKHis Dataset"></a>Comparative Analysis of Deep Learning Architectures for Breast Cancer Diagnosis Using the BreaKHis Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01007">http://arxiv.org/abs/2309.01007</a></li>
<li>repo_url: None</li>
<li>paper_authors: İrem Sayın, Muhammed Ali Soydaş, Yunus Emre Mert, Arda Yarkataş, Berk Ergun, Selma Sözen Yeh, Hüseyin Üvet</li>
<li>for: 评估深度学习模型在识别乳腺癌中的表现</li>
<li>methods: 使用和比较五种知名的深度学习模型进行诊断：VGG、ResNet、Xception、Inception和InceptionResNet</li>
<li>results: Xception模型在F1分数方面达到了0.9，准确率达到了89%，而Inception和InceptionResNet模型均达到了87%的准确率，但Inception模型的F1分数为87，而InceptionResNet模型的F1分数为86。这些结果表明深度学习方法在诊断乳腺癌中的重要性，并且有助于提供更好的诊断服务给患者。<details>
<summary>Abstract</summary>
Cancer is an extremely difficult and dangerous health problem because it manifests in so many different ways and affects so many different organs and tissues. The primary goal of this research was to evaluate deep learning models' ability to correctly identify breast cancer cases using the BreakHis dataset. The BreakHis dataset covers a wide range of breast cancer subtypes through its huge collection of histopathological pictures. In this study, we use and compare the performance of five well-known deep learning models for cancer classification: VGG, ResNet, Xception, Inception, and InceptionResNet. The results placed the Xception model at the top, with an F1 score of 0.9 and an accuracy of 89%. At the same time, the Inception and InceptionResNet models both hit accuracy of 87% . However, the F1 score for the Inception model was 87, while that for the InceptionResNet model was 86. These results demonstrate the importance of deep learning methods in making correct breast cancer diagnoses. This highlights the potential to provide improved diagnostic services to patients. The findings of this study not only improve current methods of cancer diagnosis, but also make significant contributions to the creation of new and improved cancer treatment strategies. In a nutshell, the results of this study represent a major advancement in the direction of achieving these vital healthcare goals.
</details>
<details>
<summary>摘要</summary>
乳癌是一种极其困难和危险的健康问题，因为它可以出现在多种不同的形式和影响多种不同的器官和组织。本研究的主要目标是评估深度学习模型在识别乳癌案例方面的性能，使用BreakHis数据集。BreakHis数据集包括多种乳癌Subtype的历史病理图像，因此我们可以使用和比较五种常见的深度学习模型对于肿瘤分类的性能：VGG、ResNet、Xception、Inception和InceptionResNet。结果显示，Xception模型在F1分数方面得分为0.9，准确率为89%。同时，Inception和InceptionResNet模型都达到了87%的准确率。但是，Inception模型的F1分数为87，而InceptionResNet模型的F1分数为86。这些结果表明深度学习方法在识别乳癌案例中的重要性，这也提供了改善临床诊断服务的可能性。这些发现不仅改进了当前肿瘤诊断方法，还为创造新的和改进的肿瘤治疗策略做出了重要贡献。总之，本研究的结果代表了肿瘤诊断领域的一大突破。
</details></li>
</ul>
<hr>
<h2 id="RevColV2-Exploring-Disentangled-Representations-in-Masked-Image-Modeling"><a href="#RevColV2-Exploring-Disentangled-Representations-in-Masked-Image-Modeling" class="headerlink" title="RevColV2: Exploring Disentangled Representations in Masked Image Modeling"></a>RevColV2: Exploring Disentangled Representations in Masked Image Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01005">http://arxiv.org/abs/2309.01005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/megvii-research/revcol">https://github.com/megvii-research/revcol</a></li>
<li>paper_authors: Qi Han, Yuxuan Cai, Xiangyu Zhang</li>
<li>for: 这个研究目的是提出一个新的架构，RevColV2，来解决现有的掩护图像模型（MIM）方法中驱逐decoder网络的问题，以提高下游任务的表现。</li>
<li>methods: RevColV2架构包含底部Column和顶部Column，这两种Column之间的信息是逆向传递和慢态分解的。这种设计使得RevColV2架构保持了掩护图像模型中的独立低阶和semantic信息。</li>
<li>results: 实验结果显示，使用RevColV2架构的基础模型可以在多个下游视觉任务中实现竞争性的表现，例如图像分类、semantic segmentation和物件检测。例如，在ImageNet-22K dataset上进行中途精通的finetuning后，RevColV2-L可以实现88.4%的top-1准确率和58.6 mIoU的semantic segmentation准确率。<details>
<summary>Abstract</summary>
Masked image modeling (MIM) has become a prevalent pre-training setup for vision foundation models and attains promising performance. Despite its success, existing MIM methods discard the decoder network during downstream applications, resulting in inconsistent representations between pre-training and fine-tuning and can hamper downstream task performance. In this paper, we propose a new architecture, RevColV2, which tackles this issue by keeping the entire autoencoder architecture during both pre-training and fine-tuning. The main body of RevColV2 contains bottom-up columns and top-down columns, between which information is reversibly propagated and gradually disentangled. Such design enables our architecture with the nice property: maintaining disentangled low-level and semantic information at the end of the network in MIM pre-training. Our experimental results suggest that a foundation model with decoupled features can achieve competitive performance across multiple downstream vision tasks such as image classification, semantic segmentation and object detection. For example, after intermediate fine-tuning on ImageNet-22K dataset, RevColV2-L attains 88.4% top-1 accuracy on ImageNet-1K classification and 58.6 mIoU on ADE20K semantic segmentation. With extra teacher and large scale dataset, RevColv2-L achieves 62.1 box AP on COCO detection and 60.4 mIoU on ADE20K semantic segmentation. Code and models are released at https://github.com/megvii-research/RevCol
</details>
<details>
<summary>摘要</summary>
受预训练掩模型（MIM）的普遍使用，已经取得了领先的表现。然而，现有的MIM方法在下游应用中抛弃了解码器网络，导致预训练和细化 phases的表现不一致，从而降低下游任务的表现。在本文中，我们提出了一种新的架构——RevColV2，以解决这个问题。RevColV2架构包括底层列和顶层列，这两个列之间的信息在反向传播的过程中被恰当地传递和慢慢分离。这种设计使得RevColV2架构保持了预训练和细化 phases中的独立特征，从而实现了维持低级别特征和 semantic 信息的优良性。我们的实验结果表明，一个基于RevColV2架构的基础模型可以在多个下游视觉任务上达到竞争性的表现，如图像分类、semantic segmentation和物体检测。例如，在ImageNet-22K数据集上进行中间细化训练后，RevColV2-L模型可以达到88.4%的顶层准确率和58.6 mIoU的semantic segmentation精度。另外，通过添加教师和大规模数据集，RevColV2-L模型可以达到62.1个box AP和60.4 mIoU的semantic segmentation精度。代码和模型可以在https://github.com/megvii-research/RevCol 上下载。
</details></li>
</ul>
<hr>
<h2 id="Constrained-CycleGAN-for-Effective-Generation-of-Ultrasound-Sector-Images-of-Improved-Spatial-Resolution"><a href="#Constrained-CycleGAN-for-Effective-Generation-of-Ultrasound-Sector-Images-of-Improved-Spatial-Resolution" class="headerlink" title="Constrained CycleGAN for Effective Generation of Ultrasound Sector Images of Improved Spatial Resolution"></a>Constrained CycleGAN for Effective Generation of Ultrasound Sector Images of Improved Spatial Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00995">http://arxiv.org/abs/2309.00995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xfsun99/ccyclegan-tf2">https://github.com/xfsun99/ccyclegan-tf2</a></li>
<li>paper_authors: Xiaofei Sun, He Li, Wei-Ning Lee<br>for: 这个研究的目的是将多普勒超声图像（US）的空间分辨率改善，以提高心脏动态运动的评估质量。methods: 这个研究使用了一种名为CCycleGAN的新型的循环GAN模型，该模型直接使用不同的超声探针所获取的无对对的US图像进行生成。此外，CCycleGAN还引入了一种新的束约条件，以保证生成图像的结构一致性和吸收信号特征的一致性。results: 实验结果表明，CCycleGAN可以成功地生成高空间分辨率的US图像，同时也提高了图像的峰信号噪声比（PSNR）和结构相似度（SSIM）。此外，CCycleGAN生成的US图像在人体内部的心脏运动评估中也有更高的质量，特别是在深部区域。<details>
<summary>Abstract</summary>
Objective. A phased or a curvilinear array produces ultrasound (US) images with a sector field of view (FOV), which inherently exhibits spatially-varying image resolution with inferior quality in the far zone and towards the two sides azimuthally. Sector US images with improved spatial resolutions are favorable for accurate quantitative analysis of large and dynamic organs, such as the heart. Therefore, this study aims to translate US images with spatially-varying resolution to ones with less spatially-varying resolution. CycleGAN has been a prominent choice for unpaired medical image translation; however, it neither guarantees structural consistency nor preserves backscattering patterns between input and generated images for unpaired US images. Approach. To circumvent this limitation, we propose a constrained CycleGAN (CCycleGAN), which directly performs US image generation with unpaired images acquired by different ultrasound array probes. In addition to conventional adversarial and cycle-consistency losses of CycleGAN, CCycleGAN introduces an identical loss and a correlation coefficient loss based on intrinsic US backscattered signal properties to constrain structural consistency and backscattering patterns, respectively. Instead of post-processed B-mode images, CCycleGAN uses envelope data directly obtained from beamformed radio-frequency signals without any other non-linear postprocessing. Main Results. In vitro phantom results demonstrate that CCycleGAN successfully generates images with improved spatial resolution as well as higher peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) compared with benchmarks. Significance. CCycleGAN-generated US images of the in vivo human beating heart further facilitate higher quality heart wall motion estimation than benchmarks-generated ones, particularly in deep regions.
</details>
<details>
<summary>摘要</summary>
目标：使用phasized或curvilinear array生成ultrasound（US）图像，图像具有锐度场视野（FOV），这些图像自然而然地在远区和两侧扫描方向展现空间不均匀的图像解析质量。锐度US图像有助于准确地量化大小和动态的器官，如心脏。因此，本研究的目标是将US图像中的空间不均匀的图像解析转换为更少的空间不均匀的图像解析。方法：我们提出了一种受限制的CycleGAN（CCycleGAN），该模型直接使用不同ultrasound array探针获取的无对应图像来生成US图像。除了传统的对抗学习和循环一致性损失外，CCycleGAN还引入了基于US回射信号特性的相同损失和相关系数损失，以确保结构一致性和回射特征的保持。而不是使用后处理的B模式图像，CCycleGAN使用直接从Radio frequency信号中得到的封包数据，无需其他非线性后处理。主要结果：在医学实验室中，我们使用了医学实验室中的人工胚膜模型，对CCycleGAN进行了测试。结果表明，CCycleGAN成功地生成了高分辨率的US图像，同时具有更高的PSNR和SSIM值，比benchmarks更高。意义：CCycleGAN生成的US图像可以更好地估计人体心脏墙运动，特别是在深部区域。这些结果表明，CCycleGAN可以成为一种有用的医学图像翻译工具，可以帮助医生更好地诊断和治疗各种疾病。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Framework-for-Optimal-Selection-of-Soil-Sampling-Sites"><a href="#Deep-Learning-Framework-for-Optimal-Selection-of-Soil-Sampling-Sites" class="headerlink" title="Deep-Learning Framework for Optimal Selection of Soil Sampling Sites"></a>Deep-Learning Framework for Optimal Selection of Soil Sampling Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00974">http://arxiv.org/abs/2309.00974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tan-Hanh Pham, Praneel Acharya, Sravanthi Bachina, Kristopher Osterloh, Kim-Doang Nguyen</li>
<li>for: 本研究使用深度学习技术来找到适合挖取样本的场地。</li>
<li>methods: 本研究使用了两种方法：一是使用现有的state-of-the-art模型，二是开发了一种基于转换器和自注意的深度学习设计。</li>
<li>results: 研究结果表明，我们提出的模型在测试数据集上达到了99.52%的准确率，57.35%的交集 overlap（IoU）和71.47%的 dice相似度，而现有的CNN模型的性能指标分别为66.08%、3.85%和1.98%。这表明我们的模型在土壤抽样数据集上表现出了优异性。<details>
<summary>Abstract</summary>
This work leverages the recent advancements of deep learning in image processing to find optimal locations that present the important characteristics of a field. The data for training are collected at different fields in local farms with five features: aspect, flow accumulation, slope, NDVI (normalized difference vegetation index), and yield. The soil sampling dataset is challenging because the ground truth is highly imbalanced binary images. Therefore, we approached the problem with two methods, the first approach involves utilizing a state-of-the-art model with the convolutional neural network (CNN) backbone, while the second is to innovate a deep-learning design grounded in the concepts of transformer and self-attention. Our framework is constructed with an encoder-decoder architecture with the self-attention mechanism as the backbone. In the encoder, the self-attention mechanism is the key feature extractor, which produces feature maps. In the decoder, we introduce atrous convolution networks to concatenate, fuse the extracted features, and then export the optimal locations for soil sampling. Currently, the model has achieved impressive results on the testing dataset, with a mean accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean Dice Coefficient of 71.47%, while the performance metrics of the state-of-the-art CNN-based model are 66.08%, 3.85%, and 1.98%, respectively. This indicates that our proposed model outperforms the CNN-based method on the soil-sampling dataset. To the best of our knowledge, our work is the first to provide a soil-sampling dataset with multiple attributes and leverage deep learning techniques to enable the automatic selection of soil-sampling sites. This work lays a foundation for novel applications of data science and machine-learning technologies to solve other emerging agricultural problems.
</details>
<details>
<summary>摘要</summary>
The team tested their model on a challenging dataset and achieved impressive results, with a mean accuracy of 99.52%, a mean Intersection over Union (IoU) of 57.35%, and a mean Dice Coefficient of 71.47%. These results are significantly better than those achieved by a state-of-the-art CNN-based model, which had a mean accuracy of 66.08%, a mean IoU of 3.85%, and a mean Dice Coefficient of 1.98%.This work is the first to provide a soil-sampling dataset with multiple attributes and use deep learning techniques to automatically select soil-sampling sites. The team believes that their approach could be used to solve other emerging agricultural problems and lay the foundation for novel applications of data science and machine learning in agriculture.
</details></li>
</ul>
<hr>
<h2 id="AdLER-Adversarial-Training-with-Label-Error-Rectification-for-One-Shot-Medical-Image-Segmentation"><a href="#AdLER-Adversarial-Training-with-Label-Error-Rectification-for-One-Shot-Medical-Image-Segmentation" class="headerlink" title="AdLER: Adversarial Training with Label Error Rectification for One-Shot Medical Image Segmentation"></a>AdLER: Adversarial Training with Label Error Rectification for One-Shot Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00971">http://arxiv.org/abs/2309.00971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hsiangyuzhao/adler">https://github.com/hsiangyuzhao/adler</a></li>
<li>paper_authors: Xiangyu Zhao, Sheng Wang, Zhiyun Song, Zhenrong Shen, Linlin Yao, Haolei Yuan, Qian Wang, Lichi Zhang</li>
<li>for: 这个研究的目的是提高医疗图像自动分类的精度，特别是在丑化训练数据的情况下。</li>
<li>methods: 这个方法使用了学习变数的一对一分类（OSSLT），包括不断变数注册、学习注册和注册变数的分类。</li>
<li>results: 这个研究的结果显示，这个新的一对一分类方法（AdLER）可以提高分类性能，并且在没有足够训练数据的情况下具有更好的一致性和更高的精度。<details>
<summary>Abstract</summary>
Accurate automatic segmentation of medical images typically requires large datasets with high-quality annotations, making it less applicable in clinical settings due to limited training data. One-shot segmentation based on learned transformations (OSSLT) has shown promise when labeled data is extremely limited, typically including unsupervised deformable registration, data augmentation with learned registration, and segmentation learned from augmented data. However, current one-shot segmentation methods are challenged by limited data diversity during augmentation, and potential label errors caused by imperfect registration. To address these issues, we propose a novel one-shot medical image segmentation method with adversarial training and label error rectification (AdLER), with the aim of improving the diversity of generated data and correcting label errors to enhance segmentation performance. Specifically, we implement a novel dual consistency constraint to ensure anatomy-aligned registration that lessens registration errors. Furthermore, we develop an adversarial training strategy to augment the atlas image, which ensures both generation diversity and segmentation robustness. We also propose to rectify potential label errors in the augmented atlas images by estimating segmentation uncertainty, which can compensate for the imperfect nature of deformable registration and improve segmentation authenticity. Experiments on the CANDI and ABIDE datasets demonstrate that the proposed AdLER outperforms previous state-of-the-art methods by 0.7% (CANDI), 3.6% (ABIDE "seen"), and 4.9% (ABIDE "unseen") in segmentation based on Dice scores, respectively. The source code will be available at https://github.com/hsiangyuzhao/AdLER.
</details>
<details>
<summary>摘要</summary>
通常，医疗图像自动分割需要大量高质量标注数据，因此在临床设置下采用自动分割是更加困难的。一旦分割基于学习的变换（OSSLT）已经展示了在有限的标注数据下可以取得满意的结果，包括不supervised deformable registration、数据增强通过学习 registration以及基于增强数据进行分割学习。然而，当数据多样性很低时，当前一旦分割方法会受到多样性不足的限制，以及可能的标签错误引起的registration错误。为了解决这些问题，我们提出了一种基于对抗学习和标签修正的新一代医疗图像分割方法（AdLER），以提高分割性能。具体来说，我们实现了一种双重一致性约束，以降低注射错误。此外，我们开发了一种对抗训练策略，以增强生成数据的多样性和分割的Robustness。此外，我们还提出了一种纠正可能存在的标签错误的方法，通过估算分割不确定性，可以补偿杂论注射和提高分割的authenticity。实验结果表明，提案的AdLER方法在CANDI和ABIDE datasets上比前一代方法提高0.7%（CANDI）、3.6%（ABIDE "seen")和4.9%（ABIDE "unseen")的分割基于dice scores，分别。源代码将在https://github.com/hsiangyuzhao/AdLER上提供。
</details></li>
</ul>
<hr>
<h2 id="NTU4DRadLM-4D-Radar-centric-Multi-Modal-Dataset-for-Localization-and-Mapping"><a href="#NTU4DRadLM-4D-Radar-centric-Multi-Modal-Dataset-for-Localization-and-Mapping" class="headerlink" title="NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and Mapping"></a>NTU4DRadLM: 4D Radar-centric Multi-Modal Dataset for Localization and Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00962">http://arxiv.org/abs/2309.00962</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junzhang2016/NTU4DRadLM">https://github.com/junzhang2016/NTU4DRadLM</a></li>
<li>paper_authors: Jun Zhang, Huayang Zhuge, Yiyao Liu, Guohao Peng, Zhenyu Wu, Haoyuan Zhang, Qiyang Lyu, Heshan Li, Chunyang Zhao, Dogan Kircali, Sanat Mharolkar, Xun Yang, Su Yi, Yuanzhe Wang, Danwei Wang</li>
<li>for:  This paper is written for researchers and developers who are interested in Simultaneous Localization and Mapping (SLAM) using 4D radar, thermal camera, and Inertial Measurement Unit (IMU).</li>
<li>methods: The paper presents a new dataset called NTU4DRadLM, which includes all 6 sensors (4D radar, thermal camera, IMU, 3D LiDAR, visual camera, and RTK GPS) and is specifically designed for SLAM tasks.</li>
<li>results: The paper evaluates three types of SLAM algorithms using the NTU4DRadLM dataset and reports the results, which include the accuracy of the algorithms in various environments.Here’s the simplified Chinese version:</li>
<li>for: 这篇论文是为了帮助关注同时定位和地图建模（SLAM）领域的研究人员和开发者。</li>
<li>methods: 这篇论文提出了一个新的数据集called NTU4DRadLM，该数据集包含了所有6种感知器（4D radar、热成像、IMU、3D LiDAR、视频相机和RTK GPS），并且特意设计用于SLAM任务。</li>
<li>results: 这篇论文使用NTU4DRadLM数据集评估了三种SLAM算法的性能，并报告了结果，其中包括不同环境下的算法准确性。<details>
<summary>Abstract</summary>
Simultaneous Localization and Mapping (SLAM) is moving towards a robust perception age. However, LiDAR- and visual- SLAM may easily fail in adverse conditions (rain, snow, smoke and fog, etc.). In comparison, SLAM based on 4D Radar, thermal camera and IMU can work robustly. But only a few literature can be found. A major reason is the lack of related datasets, which seriously hinders the research. Even though some datasets are proposed based on 4D radar in past four years, they are mainly designed for object detection, rather than SLAM. Furthermore, they normally do not include thermal camera. Therefore, in this paper, NTU4DRadLM is presented to meet this requirement. The main characteristics are: 1) It is the only dataset that simultaneously includes all 6 sensors: 4D radar, thermal camera, IMU, 3D LiDAR, visual camera and RTK GPS. 2) Specifically designed for SLAM tasks, which provides fine-tuned ground truth odometry and intentionally formulated loop closures. 3) Considered both low-speed robot platform and fast-speed unmanned vehicle platform. 4) Covered structured, unstructured and semi-structured environments. 5) Considered both middle- and large- scale outdoor environments, i.e., the 6 trajectories range from 246m to 6.95km. 6) Comprehensively evaluated three types of SLAM algorithms. Totally, the dataset is around 17.6km, 85mins, 50GB and it will be accessible from this link: https://github.com/junzhang2016/NTU4DRadLM
</details>
<details>
<summary>摘要</summary>
《同时地位和地图Localization（SLAM）正在迈向一个强大的感知年代。然而，雷达和视觉SLAM可能在不利的条件下（雨、雪、烟雾等）容易失败。相比之下，基于4D雷达、热成像和IMU的SLAM可以工作稳定。然而，相关的数据集很少，这使得研究受到了严重的阻碍。尽管过去四年有一些基于4D雷达的数据集被提出，但是它们主要是为了对象检测而不是SLAM。此外，它们通常不包括热成像。因此，本文提出了NTU4DRadLM数据集。NTU4DRadLM的主要特点包括：1. 同时包含6种感知器：4D雷达、热成像、IMU、3D雷达、视觉摄像头和RTK GPS。2. 专门为SLAM任务设计，提供精度调整的地理位置轨迹和故意设计的循环关闭。3. 考虑了中速和快速无人车平台。4. 覆盖结构化、无结构化和半结构化环境。5. 考虑了中型和大型的外部环境，即6个轨迹的距离从246米到6.95公里。6. 全面评估了三种SLAM算法。总的来说，数据集约为17.6公里，85分钟，50GB，可以从以下链接获取：https://github.com/junzhang2016/NTU4DRadLM。
</details></li>
</ul>
<hr>
<h2 id="ASF-Net-Robust-Video-Deraining-via-Temporal-Alignment-and-Online-Adaptive-Learning"><a href="#ASF-Net-Robust-Video-Deraining-via-Temporal-Alignment-and-Online-Adaptive-Learning" class="headerlink" title="ASF-Net: Robust Video Deraining via Temporal Alignment and Online Adaptive Learning"></a>ASF-Net: Robust Video Deraining via Temporal Alignment and Online Adaptive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00956">http://arxiv.org/abs/2309.00956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinwei Xue, Jia He, Long Ma, Xiangyu Meng, Wenlin Li, Risheng Liu</li>
<li>for: 本研究旨在解决视频雨几何学习方法中的两个关键挑战：利用邻帧的时间相关性和适应未知实际场景。</li>
<li>methods: 我们提出了一种新的计算模式——归一化偏移网络（ASF-Net），它包括一个时间偏移模块，可以更深入探索邻帧的时间信息，并在特征空间内进行通道级别信息交换。</li>
<li>results: 我们在基于新建的 dataset 上进行了参数学习过程，并开发了一种创新的恢复学习策略，该策略可以将 sintetic 和实际场景之间的差异bridged，从而提高场景适应性。我们的提出方法在三个标准准点上表现出优于常见方法，并在实际场景中具有惊喜的视觉质量。<details>
<summary>Abstract</summary>
In recent times, learning-based methods for video deraining have demonstrated commendable results. However, there are two critical challenges that these methods are yet to address: exploiting temporal correlations among adjacent frames and ensuring adaptability to unknown real-world scenarios. To overcome these challenges, we explore video deraining from a paradigm design perspective to learning strategy construction. Specifically, we propose a new computational paradigm, Alignment-Shift-Fusion Network (ASF-Net), which incorporates a temporal shift module. This module is novel to this field and provides deeper exploration of temporal information by facilitating the exchange of channel-level information within the feature space. To fully discharge the model's characterization capability, we further construct a LArge-scale RAiny video dataset (LARA) which also supports the development of this community. On the basis of the newly-constructed dataset, we explore the parameters learning process by developing an innovative re-degraded learning strategy. This strategy bridges the gap between synthetic and real-world scenes, resulting in stronger scene adaptability. Our proposed approach exhibits superior performance in three benchmarks and compelling visual quality in real-world scenarios, underscoring its efficacy. The code is available at https://github.com/vis-opt-group/ASF-Net.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Tracking-without-Label-Unsupervised-Multiple-Object-Tracking-via-Contrastive-Similarity-Learning"><a href="#Tracking-without-Label-Unsupervised-Multiple-Object-Tracking-via-Contrastive-Similarity-Learning" class="headerlink" title="Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning"></a>Tracking without Label: Unsupervised Multiple Object Tracking via Contrastive Similarity Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00942">http://arxiv.org/abs/2309.00942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sha Meng, Dian Shao, Jiacheng Guo, Shan Gao</li>
<li>for: 这篇论文的目的是提出一种无监督学习方法，以增强多对象跟踪（MOT）任务中对象的识别和跟踪。</li>
<li>methods: 该方法利用样本特征的共同性，包括自我协同、跨帧协同和歧义协同三种冲突模块，从而提取特征表示。</li>
<li>results: 该方法在现有的标准测试集上比既有的无监督方法和部分监督方法提供更高的准确率，并且与完全监督方法相当或甚至超过。<details>
<summary>Abstract</summary>
Unsupervised learning is a challenging task due to the lack of labels. Multiple Object Tracking (MOT), which inevitably suffers from mutual object interference, occlusion, etc., is even more difficult without label supervision. In this paper, we explore the latent consistency of sample features across video frames and propose an Unsupervised Contrastive Similarity Learning method, named UCSL, including three contrast modules: self-contrast, cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses intra-frame direct and inter-frame indirect contrast to obtain discriminative representations by maximizing self-similarity. ii) Cross-contrast aligns cross- and continuous-frame matching results, mitigating the persistent negative effect caused by object occlusion. And iii) ambiguity contrast matches ambiguous objects with each other to further increase the certainty of subsequent object association through an implicit manner. On existing benchmarks, our method outperforms the existing unsupervised methods using only limited help from ReID head, and even provides higher accuracy than lots of fully supervised methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Unsupervised learning is a challenging task due to the lack of labels. Multiple Object Tracking (MOT), which inevitably suffers from mutual object interference, occlusion, etc., is even more difficult without label supervision. In this paper, we explore the latent consistency of sample features across video frames and propose an Unsupervised Contrastive Similarity Learning method, named UCSL, including three contrast modules: self-contrast, cross-contrast, and ambiguity contrast. Specifically, i) self-contrast uses intra-frame direct and inter-frame indirect contrast to obtain discriminative representations by maximizing self-similarity. ii) Cross-contrast aligns cross- and continuous-frame matching results, mitigating the persistent negative effect caused by object occlusion. And iii) ambiguity contrast matches ambiguous objects with each other to further increase the certainty of subsequent object association through an implicit manner. On existing benchmarks, our method outperforms the existing unsupervised methods using only limited help from ReID head, and even provides higher accuracy than lots of fully supervised methods."into Simplified Chinese.以下是文章中的简化中文翻译：Unsupervised learning是一项复杂的任务，因为缺乏标签。多个对象跟踪（MOT），它无法避免互相干扰、遮挡等问题，更加困难无标签指导。在这篇文章中，我们探索视频帧中样本特征的潜在一致性，并提出了无监督相似性学习方法（UCSL），包括三种对比模块：自我对比、相互对比和抽象对比。特别是：i) 自我对比使用内帧直接和间帧间接对比，以获得特征表示，充分发挥自我相似性。ii) 相互对比将相互匹配和连续帧匹配结果对齐，解决对象遮挡的持续性负面影响。iii) 抽象对比将抽象对象相互对应，进一步增加后续对象关联的确定性。在现有的benchmark上，我们的方法比现有的无监督方法使用更少的ReID头的帮助，甚至提供了高于许多全监督方法的准确率。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Robustness-of-Human-Parsers-Towards-Common-Corruptions"><a href="#Exploring-the-Robustness-of-Human-Parsers-Towards-Common-Corruptions" class="headerlink" title="Exploring the Robustness of Human Parsers Towards Common Corruptions"></a>Exploring the Robustness of Human Parsers Towards Common Corruptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00938">http://arxiv.org/abs/2309.00938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanyi Zhang, Xiaochun Cao, Rui Wang, Guo-Jun Qi, Jie Zhou</li>
<li>for: 提高人像分割模型的 robustness，使其能够更好地处理各种图像损害。</li>
<li>methods: 构建了三个损害robustness benchmark，并提出了一种基于多视图增强的异质增强机制，通过将两种不同视图的数据增强综合在一起，以适应常见的图像损害。</li>
<li>results: 实验结果表明，提出的方法可以提高人像分割模型的robustness，并且可以在不同的图像损害情况下保持相对的表现。<details>
<summary>Abstract</summary>
Human parsing aims to segment each pixel of the human image with fine-grained semantic categories. However, current human parsers trained with clean data are easily confused by numerous image corruptions such as blur and noise. To improve the robustness of human parsers, in this paper, we construct three corruption robustness benchmarks, termed LIP-C, ATR-C, and Pascal-Person-Part-C, to assist us in evaluating the risk tolerance of human parsing models. Inspired by the data augmentation strategy, we propose a novel heterogeneous augmentation-enhanced mechanism to bolster robustness under commonly corrupted conditions. Specifically, two types of data augmentations from different views, i.e., image-aware augmentation and model-aware image-to-image transformation, are integrated in a sequential manner for adapting to unforeseen image corruptions. The image-aware augmentation can enrich the high diversity of training images with the help of common image operations. The model-aware augmentation strategy that improves the diversity of input data by considering the model's randomness. The proposed method is model-agnostic, and it can plug and play into arbitrary state-of-the-art human parsing frameworks. The experimental results show that the proposed method demonstrates good universality which can improve the robustness of the human parsing models and even the semantic segmentation models when facing various image common corruptions. Meanwhile, it can still obtain approximate performance on clean data.
</details>
<details>
<summary>摘要</summary>
人类分割目标是将每个人像像Pixel segmentation with fine-grained semantic categories. However, current human parsers trained with clean data are easily confused by numerous image corruptions such as blur and noise. To improve the robustness of human parsers, in this paper, we construct three corruption robustness benchmarks, termed LIP-C, ATR-C, and Pascal-Person-Part-C, to assist us in evaluating the risk tolerance of human parsing models. Inspired by the data augmentation strategy, we propose a novel heterogeneous augmentation-enhanced mechanism to bolster robustness under commonly corrupted conditions. Specifically, two types of data augmentations from different views, i.e., image-aware augmentation and model-aware image-to-image transformation, are integrated in a sequential manner for adapting to unforeseen image corruptions. The image-aware augmentation can enrich the high diversity of training images with the help of common image operations. The model-aware augmentation strategy that improves the diversity of input data by considering the model's randomness. The proposed method is model-agnostic, and it can plug and play into arbitrary state-of-the-art human parsing frameworks. The experimental results show that the proposed method demonstrates good universality which can improve the robustness of the human parsing models and even the semantic segmentation models when facing various image common corruptions. Meanwhile, it can still obtain approximate performance on clean data.
</details></li>
</ul>
<hr>
<h2 id="Two-in-One-Depth-Bridging-the-Gap-Between-Monocular-and-Binocular-Self-supervised-Depth-Estimation"><a href="#Two-in-One-Depth-Bridging-the-Gap-Between-Monocular-and-Binocular-Self-supervised-Depth-Estimation" class="headerlink" title="Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation"></a>Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00933">http://arxiv.org/abs/2309.00933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengming Zhou, Qiulei Dong</li>
<li>for: 提出了一种能够同时处理单目和双目深度估计任务的 Two-in-One自主学习深度估计网络（TiO-Depth），以提高估计精度。</li>
<li>methods: 使用了一种SIAMESE架构，每个子网络可以作为单目深度估计模型，而为双目深度估计，提出了一种单目特征匹配模块，将两个图像之间的stereo知识integrated进模型中。</li>
<li>results: 实验结果表明，TiO-Depth在KITTI、Cityscapes和DDAD datasets上大多数情况下都能够超过单目和双目现有方法的性能，并证明了一种两个任务合一的网络可以为单目和双目深度估计提供更高的精度。<details>
<summary>Abstract</summary>
Monocular and binocular self-supervised depth estimations are two important and related tasks in computer vision, which aim to predict scene depths from single images and stereo image pairs respectively. In literature, the two tasks are usually tackled separately by two different kinds of models, and binocular models generally fail to predict depth from single images, while the prediction accuracy of monocular models is generally inferior to binocular models. In this paper, we propose a Two-in-One self-supervised depth estimation network, called TiO-Depth, which could not only compatibly handle the two tasks, but also improve the prediction accuracy. TiO-Depth employs a Siamese architecture and each sub-network of it could be used as a monocular depth estimation model. For binocular depth estimation, a Monocular Feature Matching module is proposed for incorporating the stereo knowledge between the two images, and the full TiO-Depth is used to predict depths. We also design a multi-stage joint-training strategy for improving the performances of TiO-Depth in both two tasks by combining the relative advantages of them. Experimental results on the KITTI, Cityscapes, and DDAD datasets demonstrate that TiO-Depth outperforms both the monocular and binocular state-of-the-art methods in most cases, and further verify the feasibility of a two-in-one network for monocular and binocular depth estimation. The code is available at https://github.com/ZM-Zhou/TiO-Depth_pytorch.
</details>
<details>
<summary>摘要</summary>
眼镜和双眼自助深度估计是计算机视觉中两个重要和相关的任务，它们目标是从单个图像和双图像对中预测场景的深度。在文献中，这两个任务通常由两种不同的模型来解决，而双眼模型通常无法从单个图像中预测深度，而眼镜模型的预测精度通常落后于双眼模型。在这篇论文中，我们提出了一个名为 TiO-Depth 的 Two-in-One 自助深度估计网络，可以同时处理这两个任务，并提高预测精度。TiO-Depth 使用了同构网络，并且每个子网络可以作为眼镜深度估计模型使用。对于双眼深度估计，我们提出了一个名为 Monocular Feature Matching 的单眼特征匹配模块，以利用双图像之间的相似性，并使用全 TiO-Depth 来预测深度。我们还设计了一种多阶段联合培训策略，以提高 TiO-Depth 在这两个任务中的性能。实验结果表明，TiO-Depth 在 KITTI、Cityscapes 和 DDAD 数据集上的表现都较为出色，大多数情况下超过了眼镜和双眼状态的目标方法，并证明了 Two-in-One 网络的可行性。代码可以在 GitHub 上找到：https://github.com/ZM-Zhou/TiO-Depth_pytorch。
</details></li>
</ul>
<hr>
<h2 id="S-3-MonoDETR-Supervised-Shape-Scale-perceptive-Deformable-Transformer-for-Monocular-3D-Object-Detection"><a href="#S-3-MonoDETR-Supervised-Shape-Scale-perceptive-Deformable-Transformer-for-Monocular-3D-Object-Detection" class="headerlink" title="S$^3$-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for Monocular 3D Object Detection"></a>S$^3$-MonoDETR: Supervised Shape&amp;Scale-perceptive Deformable Transformer for Monocular 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00928">http://arxiv.org/abs/2309.00928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan He, Kailun Yang, Junwei Zheng, Jin Yuan, Luis M. Bergasa, Hui Zhang, Zhiyong Li</li>
<li>for: 提高单目3D物体检测的准确率，特别是对多类目物体的检测。</li>
<li>methods: 提出了一种新的“超级visedShape&amp;Scale-perceptive Deformable Attention”（S$^3$-DA）模块，利用视觉和深度特征生成多种形态和比例的多样化本地特征，并同时预测匹配分布，以强制每个查询点拥有有价值的形态&amp;比例识别。</li>
<li>results: 对KITTI和Waymo开放 dataset进行了广泛的实验，显示S$^3$-DA可以显著提高检测精度，在单一训练过程中实现单类和多类3D物体检测的州际最佳性能。<details>
<summary>Abstract</summary>
Recently, transformer-based methods have shown exceptional performance in monocular 3D object detection, which can predict 3D attributes from a single 2D image. These methods typically use visual and depth representations to generate query points on objects, whose quality plays a decisive role in the detection accuracy. However, current unsupervised attention mechanisms without any geometry appearance awareness in transformers are susceptible to producing noisy features for query points, which severely limits the network performance and also makes the model have a poor ability to detect multi-category objects in a single training process. To tackle this problem, this paper proposes a novel "Supervised Shape&Scale-perceptive Deformable Attention" (S$^3$-DA) module for monocular 3D object detection. Concretely, S$^3$-DA utilizes visual and depth features to generate diverse local features with various shapes and scales and predict the corresponding matching distribution simultaneously to impose valuable shape&scale perception for each query. Benefiting from this, S$^3$-DA effectively estimates receptive fields for query points belonging to any category, enabling them to generate robust query features. Besides, we propose a Multi-classification-based Shape$\&$Scale Matching (MSM) loss to supervise the above process. Extensive experiments on KITTI and Waymo Open datasets demonstrate that S$^3$-DA significantly improves the detection accuracy, yielding state-of-the-art performance of single-category and multi-category 3D object detection in a single training process compared to the existing approaches. The source code will be made publicly available at https://github.com/mikasa3lili/S3-MonoDETR.
</details>
<details>
<summary>摘要</summary>
最近，基于transformer的方法在单视图3D物体检测中表现出色，可以从单个2D图像中预测3D特征。这些方法通常使用视觉和深度表示来生成查询点对象， whose quality具有决定性的影响于检测精度。然而，当前无supervised attention机制，无法考虑对象的几何外观，这会使transformer中的网络性能受到严重的限制，同时也使得模型无法在单一训练过程中检测多类对象。为解决这个问题，本文提出了一种novel的“Supervised Shape&Scale-perceptive Deformable Attention”（S$^3$-DA）模块。具体来说，S$^3$-DA利用视觉和深度特征来生成多样的本地特征，同时预测匹配分布，以便为每个查询点强制实施有价值的形状&比例见解。这使得S$^3$-DA可以efficiently估计查询点所属类别的接受领域，从而生成Robust查询特征。此外，我们提出了一种Multi-classification-based Shape$\&$Scale Matching（MSM）损失函数来监督上述过程。广泛的实验表明，S$^3$-DA可以显著提高检测精度，在单个训练过程中实现单类和多类3D物体检测的state-of-the-art性能。网站将在https://github.com/mikasa3lili/S3-MonoDETR中公开源代码。
</details></li>
</ul>
<hr>
<h2 id="GBE-MLZSL-A-Group-Bi-Enhancement-Framework-for-Multi-Label-Zero-Shot-Learning"><a href="#GBE-MLZSL-A-Group-Bi-Enhancement-Framework-for-Multi-Label-Zero-Shot-Learning" class="headerlink" title="GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning"></a>GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00923">http://arxiv.org/abs/2309.00923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziming Liu, Jingcai Guo, Xiaocheng Lu, Song Guo, Peiran Dong, Jiewei Zhang</li>
<li>for: 这个论文 investigate了零shot学习在多标签场景（MLZSL）中的挑战问题，即在一个样本（如图像）中识别多个未经训练的类，基于已经训练的类和 auxillary knowledge，如semantic information。</li>
<li>methods: 该论文提出了一种新的并有效的集群强化框架（GBE-MLZSL），以全面利用图像的本地和全局特征，并提高预测精度和稳定性。特别是，该框架将特征地图分成多个特征组，每个特征组可以独立地在Local Information Distinguishing Module（LID）中进行训练，以保证唯一性。同时，Global Enhancement Module（GEM）是设计来保持图像的主要方向。此外，还设计了一个静止图 Structured 构建本地特征之间的相关性。</li>
<li>results: 实验表明，提出的GBE-MLZSL方法在大规模的MLZSL benchmark数据集NUS-WIDE和Open-Images-v4上，与其他当前state-of-the-art方法之间的margin比较大。<details>
<summary>Abstract</summary>
This paper investigates a challenging problem of zero-shot learning in the multi-label scenario (MLZSL), wherein, the model is trained to recognize multiple unseen classes within a sample (e.g., an image) based on seen classes and auxiliary knowledge, e.g., semantic information. Existing methods usually resort to analyzing the relationship of various seen classes residing in a sample from the dimension of spatial or semantic characteristics, and transfer the learned model to unseen ones. But they ignore the effective integration of local and global features. That is, in the process of inferring unseen classes, global features represent the principal direction of the image in the feature space, while local features should maintain uniqueness within a certain range. This integrated neglect will make the model lose its grasp of the main components of the image. Relying only on the local existence of seen classes during the inference stage introduces unavoidable bias. In this paper, we propose a novel and effective group bi-enhancement framework for MLZSL, dubbed GBE-MLZSL, to fully make use of such properties and enable a more accurate and robust visual-semantic projection. Specifically, we split the feature maps into several feature groups, of which each feature group can be trained independently with the Local Information Distinguishing Module (LID) to ensure uniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to preserve the principal direction. Besides, a static graph structure is designed to construct the correlation of local features. Experiments on large-scale MLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the proposed GBE-MLZSL outperforms other state-of-the-art methods with large margins.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a novel and effective group bi-enhancement framework for MLZSL, called GBE-MLZSL, to fully utilize such properties and enable more accurate and robust visual-semantic projections. Specifically, we split the feature maps into several feature groups, each of which can be trained independently with the Local Information Distinguishing Module (LID) to ensure uniqueness. Additionally, a Global Enhancement Module (GEM) is designed to preserve the principal direction. Furthermore, a static graph structure is designed to construct the correlation of local features. Experiments on large-scale MLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the proposed GBE-MLZSL outperforms other state-of-the-art methods with large margins.Translated into Simplified Chinese, the text would be:这篇论文研究了多类零例学习（MLZSL）问题，即在一个样本（例如一张图像）中识别多个未经见过的类，基于已经见过的类和auxiliary知识，如semantic信息。现有的方法通常是分析样本中不同类的关系，从空间或semantic特征的角度来转移已经学习的模型到未经见过的类。但它们忽略了Integrate Local and Global Features的效果。即在推断未经见过的类时，global feature在特征空间中表示样本的主要方向，而local feature在某些范围内保持uniqueness。这种总体忽略会使模型失去样本的主要组成部分。只靠基于seen类的local存在来进行推断会引入不可避免的偏见。在这篇论文中，我们提出了一种新的和有效的集群强化框架，名为GBE-MLZSL，以便充分利用这些特性并实现更加准确和可靠的视semantic投影。具体来说，我们将特征图分成多个特征组，每个特征组可以独立地通过Local Information Distinguishing Module（LID）来确保uniqueness。同时，我们设计了Global Enhancement Module（GEM）来保持主要方向。此外，我们还设计了一个静态图Structured Graph来建立本地特征之间的相关性。实验结果表明，提出的GBE-MLZSL在大规模MLZSL benchmark数据集NUS-WIDE和Open-Images-v4上舜拓了其他状态的方法。
</details></li>
</ul>
<hr>
<h2 id="A-novel-framework-employing-deep-multi-attention-channels-network-for-the-autonomous-detection-of-metastasizing-cells-through-fluorescence-microscopy"><a href="#A-novel-framework-employing-deep-multi-attention-channels-network-for-the-autonomous-detection-of-metastasizing-cells-through-fluorescence-microscopy" class="headerlink" title="A novel framework employing deep multi-attention channels network for the autonomous detection of metastasizing cells through fluorescence microscopy"></a>A novel framework employing deep multi-attention channels network for the autonomous detection of metastasizing cells through fluorescence microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00911">http://arxiv.org/abs/2309.00911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michail Mamalakis, Sarah C. Macfarlane, Scott V. Notley, Annica K. B Gad, George Panoutsos</li>
<li>for: distinguishing between normal and metastasizing human cells</li>
<li>methods: combines multi-attention channels network and global explainable techniques using fluorescence microscopy images of actin and vimentin filaments</li>
<li>results: unprecedented understanding of cytoskeletal changes accompanying oncogenic transformation, and potential spatial biomarker for diagnostic tools against metastasis (spatial distribution of vimentin)Here is the same information in Simplified Chinese text:</li>
<li>for: 分辨normal和转移性人类细胞</li>
<li>methods: 结合多通道注意力网络和全球可解释技术，使用 fluorescence microscopy 图像显示 actin 和 vimentin 纤维蛋白的空间组织</li>
<li>results: 未曾有的细胞变化理解，并可能提供将来的诊断工具 против转移细胞 (细胞分布的 vimentin)<details>
<summary>Abstract</summary>
We developed a transparent computational large-scale imaging-based framework that can distinguish between normal and metastasizing human cells. The method relies on fluorescence microscopy images showing the spatial organization of actin and vimentin filaments in normal and metastasizing single cells, using a combination of multi-attention channels network and global explainable techniques. We test a classification between normal cells (Bj primary fibroblast), and their isogenically matched, transformed and invasive counterpart (BjTertSV40TRasV12). Manual annotation is not trivial to automate due to the intricacy of the biologically relevant features. In this research, we utilized established deep learning networks and our new multi-attention channel architecture. To increase the interpretability of the network - crucial for this application area - we developed an interpretable global explainable approach correlating the weighted geometric mean of the total cell images and their local GradCam scores. The significant results from our analysis unprecedently allowed a more detailed, and biologically relevant understanding of the cytoskeletal changes that accompany oncogenic transformation of normal to invasive and metastasizing cells. We also paved the way for a possible spatial micrometre-level biomarker for future development of diagnostic tools against metastasis (spatial distribution of vimentin).
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MagicProp-Diffusion-based-Video-Editing-via-Motion-aware-Appearance-Propagation"><a href="#MagicProp-Diffusion-based-Video-Editing-via-Motion-aware-Appearance-Propagation" class="headerlink" title="MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation"></a>MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00908">http://arxiv.org/abs/2309.00908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanshu Yan, Jun Hao Liew, Long Mai, Shanchuan Lin, Jiashi Feng</li>
<li>for: 修改视频的视觉外观 while preserving its motion.</li>
<li>methods: 提议一种新的框架 MagicProp，包括两个阶段：外观编辑和动作感知外观升级。在第一个阶段，MagicProp 选择输入视频中一帧，并应用图像修饰技术来修改内容和&#x2F;或风格。在第二个阶段，MagicProp 使用编辑后的帧作为外观参考，并使用一种泛化生成模型来生成剩下的帧。</li>
<li>results:  MagicProp 结合了图像修饰技术的灵活性和泛化生成模型的高效性，可以在输入视频中任意地区进行对象类型和艺术风格的修改，同时保持视频帧之间的 temporal consistency。广泛的实验表明 MagicProp 有效。<details>
<summary>Abstract</summary>
This paper addresses the issue of modifying the visual appearance of videos while preserving their motion. A novel framework, named MagicProp, is proposed, which disentangles the video editing process into two stages: appearance editing and motion-aware appearance propagation. In the first stage, MagicProp selects a single frame from the input video and applies image-editing techniques to modify the content and/or style of the frame. The flexibility of these techniques enables the editing of arbitrary regions within the frame. In the second stage, MagicProp employs the edited frame as an appearance reference and generates the remaining frames using an autoregressive rendering approach. To achieve this, a diffusion-based conditional generation model, called PropDPM, is developed, which synthesizes the target frame by conditioning on the reference appearance, the target motion, and its previous appearance. The autoregressive editing approach ensures temporal consistency in the resulting videos. Overall, MagicProp combines the flexibility of image-editing techniques with the superior temporal consistency of autoregressive modeling, enabling flexible editing of object types and aesthetic styles in arbitrary regions of input videos while maintaining good temporal consistency across frames. Extensive experiments in various video editing scenarios demonstrate the effectiveness of MagicProp.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Generic-Fundus-Image-Enhancement-Network-Boosted-by-Frequency-Self-supervised-Representation-Learning"><a href="#A-Generic-Fundus-Image-Enhancement-Network-Boosted-by-Frequency-Self-supervised-Representation-Learning" class="headerlink" title="A Generic Fundus Image Enhancement Network Boosted by Frequency Self-supervised Representation Learning"></a>A Generic Fundus Image Enhancement Network Boosted by Frequency Self-supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00885">http://arxiv.org/abs/2309.00885</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liamheng/Annotation-free-Fundus-Image-Enhancement">https://github.com/liamheng/Annotation-free-Fundus-Image-Enhancement</a></li>
<li>paper_authors: Heng Li, Haofeng Liu, Huazhu Fu, Yanwu Xu, Hui Shu, Ke Niu, Yan Hu, Jiang Liu</li>
<li>for: 本研究旨在开发一种能够Robustly Correct unknown fundus images的基本图像增强网络（GFE-Net），以便在低质量图像下进行诊断和智能系统的临床应用。</li>
<li>methods: 该研究使用了自我监督学习来学习不supervised的图像信息，并将图像增强和表征学习融合在一起，以实现高质量图像增强和结构保持。</li>
<li>results: 对比state-of-the-art算法，GFE-Net在数据依赖度、增强性能、部署效率和扩展可用性等方面表现出优异，并且可以方便进行后续的基本图像分析。<details>
<summary>Abstract</summary>
Fundus photography is prone to suffer from image quality degradation that impacts clinical examination performed by ophthalmologists or intelligent systems. Though enhancement algorithms have been developed to promote fundus observation on degraded images, high data demands and limited applicability hinder their clinical deployment. To circumvent this bottleneck, a generic fundus image enhancement network (GFE-Net) is developed in this study to robustly correct unknown fundus images without supervised or extra data. Levering image frequency information, self-supervised representation learning is conducted to learn robust structure-aware representations from degraded images. Then with a seamless architecture that couples representation learning and image enhancement, GFE-Net can accurately correct fundus images and meanwhile preserve retinal structures. Comprehensive experiments are implemented to demonstrate the effectiveness and advantages of GFE-Net. Compared with state-of-the-art algorithms, GFE-Net achieves superior performance in data dependency, enhancement performance, deployment efficiency, and scale generalizability. Follow-up fundus image analysis is also facilitated by GFE-Net, whose modules are respectively verified to be effective for image enhancement.
</details>
<details>
<summary>摘要</summary>
血液照片容易受到影像质量下降的影响，这会对眼科医生或智能系统进行临床诊断带来困难。虽然有增强算法可以提高血液图像质量，但这些算法具有高数据需求和局限性，使其在临床应用中受到限制。为了绕过这个瓶颈，本研究提出了一种通用血液图像增强网络（GFE-Net），可以不需要指导或额外数据，强制约束血液图像中的结构。GFE-Net 利用图像频率信息，自我指导学习来学习血液图像中的结构，然后通过将 representation learning 和图像增强结合在一起，GFE-Net 可以准确地 corrections 血液图像，同时保持血液结构。我们进行了全面的实验，以证明 GFE-Net 的有效性和优势。相比之前的算法，GFE-Net 在数据依赖、增强性、部署效率和扩展可行性等方面具有显著优势。此外，GFE-Net 的模块也在不同的应用中进行了验证，其中每个模块都能够准确地进行图像增强。
</details></li>
</ul>
<hr>
<h2 id="Fearless-Luminance-Adaptation-A-Macro-Micro-Hierarchical-Transformer-for-Exposure-Correction"><a href="#Fearless-Luminance-Adaptation-A-Macro-Micro-Hierarchical-Transformer-for-Exposure-Correction" class="headerlink" title="Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer for Exposure Correction"></a>Fearless Luminance Adaptation: A Macro-Micro-Hierarchical Transformer for Exposure Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00872">http://arxiv.org/abs/2309.00872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gehui Li, Jinyuan Liu, Long Ma, Zhiying Jiang, Xin Fan, Risheng Liu</li>
<li>for: 本文旨在提高图像曝光误差的correltion，以提高图像质量。</li>
<li>methods: 本文提出了一种Macro-Micro-Hierarchical transformer，包括macro注意力、micro注意力和层次结构，以实现均衡global和local特征的捕捉。</li>
<li>results: 实验表明，本方法可以提供更加吸引人的图像修复结果，并且在low-light face recognition和low-light semantic segmentation中表现出色。<details>
<summary>Abstract</summary>
Photographs taken with less-than-ideal exposure settings often display poor visual quality. Since the correction procedures vary significantly, it is difficult for a single neural network to handle all exposure problems. Moreover, the inherent limitations of convolutions, hinder the models ability to restore faithful color or details on extremely over-/under- exposed regions. To overcome these limitations, we propose a Macro-Micro-Hierarchical transformer, which consists of a macro attention to capture long-range dependencies, a micro attention to extract local features, and a hierarchical structure for coarse-to-fine correction. In specific, the complementary macro-micro attention designs enhance locality while allowing global interactions. The hierarchical structure enables the network to correct exposure errors of different scales layer by layer. Furthermore, we propose a contrast constraint and couple it seamlessly in the loss function, where the corrected image is pulled towards the positive sample and pushed away from the dynamically generated negative samples. Thus the remaining color distortion and loss of detail can be removed. We also extend our method as an image enhancer for low-light face recognition and low-light semantic segmentation. Experiments demonstrate that our approach obtains more attractive results than state-of-the-art methods quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
照片拍摄时使用不理想的曝光设置通常会导致视觉质量差。由于修正方法之间差异很大，因此单一神经网络难以处理所有曝光问题。另外，卷积的内在限制，阻碍模型恢复 faithful 的颜色或细节在极度过曝光或 Underexposed 区域。为了缓解这些限制，我们提议了一种宏微层次 transformer，它包括一个宏注意力来捕捉长距离依赖关系，一个微注意力来提取本地特征，以及一个层次结构来进行粗细修正。具体来说，宏微注意力的补做设计可以提高地方性，同时允许全局交互。层次结构使得网络可以层次修正不同的曝光错误。此外，我们还提出了一种对比约束，并将其灵活地添加到损失函数中，使 corrected 图像被pull towards 正样本，并被push away  FROM 动态生成的负样本。因此，剩下的颜色扭曲和细节损失可以被去除。我们还扩展了我们的方法，用于低光照人脸识别和低光照 semantic segmentation。实验表明，我们的方法可以比 estado-of-the-art 方法更加吸引人地得到结果， both quantitatively and qualitatively。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Weakly-Supervised-Image-Segmentation-via-Representation-Transform-and-Compensator"><a href="#Boosting-Weakly-Supervised-Image-Segmentation-via-Representation-Transform-and-Compensator" class="headerlink" title="Boosting Weakly-Supervised Image Segmentation via Representation, Transform, and Compensator"></a>Boosting Weakly-Supervised Image Segmentation via Representation, Transform, and Compensator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00871">http://arxiv.org/abs/2309.00871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyan Wang, Dong Zhang, Rui Yan</li>
<li>for: 本研究旨在提出一种单 Stage weakly-supervised image segmentation (WSIS) 方法，以提高 pseudo-mask 质量，从而实现更高的 segmentation 精度。</li>
<li>methods: 我们提出了一种使用 siamese network 和对比学习的方法，通过改进类活图 (CAM) 的质量，实现自我反复过程。我们还引入了交叉表示反复 module，以学习 robust 类型抽象和捕捉全局上下文信息，以便反复 CAMs。</li>
<li>results: 我们在 PASCAL VOC 2012 数据集上进行了实验，并证明了我们的方法可以准确地 segment 图像。我们在 PASCAL VOC 2012 验证集上达到了 67.2% 和 68.76% mIoU，在测试集上达到了 68.76% mIoU。此外，我们还扩展了我们的方法到弱地监督对象定位任务，并实验表明我们的方法在这个任务中仍然能够获得非常竞争力的结果。<details>
<summary>Abstract</summary>
Weakly-supervised image segmentation (WSIS) is a critical task in computer vision that relies on image-level class labels. Multi-stage training procedures have been widely used in existing WSIS approaches to obtain high-quality pseudo-masks as ground-truth, resulting in significant progress. However, single-stage WSIS methods have recently gained attention due to their potential for simplifying training procedures, despite often suffering from low-quality pseudo-masks that limit their practical applications. To address this issue, we propose a novel single-stage WSIS method that utilizes a siamese network with contrastive learning to improve the quality of class activation maps (CAMs) and achieve a self-refinement process. Our approach employs a cross-representation refinement method that expands reliable object regions by utilizing different feature representations from the backbone. Additionally, we introduce a cross-transform regularization module that learns robust class prototypes for contrastive learning and captures global context information to feed back rough CAMs, thereby improving the quality of CAMs. Our final high-quality CAMs are used as pseudo-masks to supervise the segmentation result. Experimental results on the PASCAL VOC 2012 dataset demonstrate that our method significantly outperforms other state-of-the-art methods, achieving 67.2% and 68.76% mIoU on PASCAL VOC 2012 val set and test set, respectively. Furthermore, our method has been extended to weakly supervised object localization task, and experimental results demonstrate that our method continues to achieve very competitive results.
</details>
<details>
<summary>摘要</summary>
弱样指导图像分割（WSIS）是计算机视觉中的关键任务，它基于图像级别的类标签。现有的WSIS方法多使用多个阶段训练过程来获得高质量的假标签，从而取得了显著的进步。然而，单阶段WSIS方法在最近受到了关注，因为它们可能简化训练过程，尽管经常受到低质量假标签的限制，使其在实际应用中具有局限性。为解决这个问题，我们提出了一种新的单阶段WSIS方法，该方法使用对称网络和对比学习来提高类激活图（CAM）的质量，并实现自我调整过程。我们的方法使用跨表示反复增强方法，将不同的特征表示从后向扩展可靠的物体区域，并 introduce a cross-transform regularization module，该模块学习强健的类范例，以便对比学习，并捕捉全局信息，以帮助改善CAM的质量。最终，我们的高质量CAM被用作假标签，以便监督分割结果。实验结果表明，我们的方法在PASCAL VOC 2012数据集上与其他状态对照方法相比，显著超越了它们，达到了67.2%和68.76%的mIoU在PASCAL VOC 2012验证集和测试集上，分别。此外，我们的方法还被扩展到弱有指导物体定位任务，实验结果表明，我们的方法在这个任务上仍然实现了非常竞争力的结果。
</details></li>
</ul>
<hr>
<h2 id="Big-model-Driven-Few-shot-Continual-Learning"><a href="#Big-model-Driven-Few-shot-Continual-Learning" class="headerlink" title="Big-model Driven Few-shot Continual Learning"></a>Big-model Driven Few-shot Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00862">http://arxiv.org/abs/2309.00862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Gu, Chunyan Xu, Zihan Lu, Xin Liu, Anbo Dai, Zhen Cui</li>
<li>for: 提高 few-shot continual learning (FSCL) 的精度和稳定性。</li>
<li>methods: 使用 big-model 驱动的转移学习，采用 adaptive decision 机制，并实施 adaptive distillation 来提高模型的性能。</li>
<li>results: 在三个popular dataset上（包括 CIFAR100、minilmageNet 和 CUB200），提出的 B-FSCL 方法完全超越了所有现有的 FSCL 方法。<details>
<summary>Abstract</summary>
Few-shot continual learning (FSCL) has attracted intensive attention and achieved some advances in recent years, but now it is difficult to again make a big stride in accuracy due to the limitation of only few-shot incremental samples. Inspired by distinctive human cognition ability in life learning, in this work, we propose a novel Big-model driven Few-shot Continual Learning (B-FSCL) framework to gradually evolve the model under the traction of the world's big-models (like human accumulative knowledge). Specifically, we perform the big-model driven transfer learning to leverage the powerful encoding capability of these existing big-models, which can adapt the continual model to a few of newly added samples while avoiding the over-fitting problem. Considering that the big-model and the continual model may have different perceived results for the identical images, we introduce an instance-level adaptive decision mechanism to provide the high-level flexibility cognitive support adjusted to varying samples. In turn, the adaptive decision can be further adopted to optimize the parameters of the continual model, performing the adaptive distillation of big-model's knowledge information. Experimental results of our proposed B-FSCL on three popular datasets (including CIFAR100, minilmageNet and CUB200) completely surpass all state-of-the-art FSCL methods.
</details>
<details>
<summary>摘要</summary>
Recently, few-shot continual learning (FSCL) has received extensive attention and achieved some advances, but it has become difficult to make further significant improvements in accuracy due to the limited number of few-shot incremental samples. Inspired by human cognitive abilities in life learning, we propose a novel Big-model driven Few-shot Continual Learning (B-FSCL) framework to gradually evolve the model under the guidance of the world's big-models (like human accumulative knowledge). Specifically, we perform big-model driven transfer learning to leverage the powerful encoding capabilities of these existing big-models, which can adapt the continual model to a few newly added samples while avoiding the overfitting problem. Considering that the big-model and the continual model may have different perceptions of the same images, we introduce an instance-level adaptive decision mechanism to provide high-level flexibility cognitive support adjusted to varying samples. In turn, the adaptive decision can be further adopted to optimize the parameters of the continual model, performing adaptive distillation of big-model's knowledge information. Experimental results of our proposed B-FSCL on three popular datasets (including CIFAR100, minilmageNet, and CUB200) completely surpass all state-of-the-art FSCL methods.
</details></li>
</ul>
<hr>
<h2 id="Correlated-and-Multi-frequency-Diffusion-Modeling-for-Highly-Under-sampled-MRI-Reconstruction"><a href="#Correlated-and-Multi-frequency-Diffusion-Modeling-for-Highly-Under-sampled-MRI-Reconstruction" class="headerlink" title="Correlated and Multi-frequency Diffusion Modeling for Highly Under-sampled MRI Reconstruction"></a>Correlated and Multi-frequency Diffusion Modeling for Highly Under-sampled MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00853">http://arxiv.org/abs/2309.00853</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqx7150/cm-dm">https://github.com/yqx7150/cm-dm</a></li>
<li>paper_authors: Yu Guan, Chuanming Yu, Shiyu Lu, Zhuoxu Cui, Dong Liang, Qiegen Liu</li>
<li>for: 提高MRI重建精度和加速抽象过程</li>
<li>methods: 利用多频率优先和吸引过程对各种细胞膜进行精细Texture detail重建</li>
<li>results: 实验结果表明，提出的方法可以更高精度地重建MRI图像，并且可以加速抽象过程。<details>
<summary>Abstract</summary>
Most existing MRI reconstruction methods perform tar-geted reconstruction of the entire MR image without tak-ing specific tissue regions into consideration. This may fail to emphasize the reconstruction accuracy on im-portant tissues for diagnosis. In this study, leveraging a combination of the properties of k-space data and the diffusion process, our novel scheme focuses on mining the multi-frequency prior with different strategies to pre-serve fine texture details in the reconstructed image. In addition, a diffusion process can converge more quickly if its target distribution closely resembles the noise distri-bution in the process. This can be accomplished through various high-frequency prior extractors. The finding further solidifies the effectiveness of the score-based gen-erative model. On top of all the advantages, our method improves the accuracy of MRI reconstruction and accel-erates sampling process. Experimental results verify that the proposed method successfully obtains more accurate reconstruction and outperforms state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
大多数现有MRI重建方法都是对整个MRI图像进行targeted重建，不考虑特定组织区域的重建精度。这可能导致重建精度不够，特别是在诊断中需要准确的组织区域。在本研究中，我们提出了一种新的方法，利用k空间数据的性质和扩散过程，将多频率优先级与不同策略相结合，以保留重建图像中细节的细腻 texture。此外，扩散过程可以更快地 converges，如果target分布和噪声分布在过程中很相似。这可以通过多种高频率优先级抽取器来实现。这些发现进一步证明了Score-based生成模型的效iveness。此外，我们的方法还提高了MRI重建的精度和采样速度。实验结果证明，我们提出的方法可以更好地重建MRI图像，并且超过了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="A-Post-Processing-Based-Bengali-Document-Layout-Analysis-with-YOLOV8"><a href="#A-Post-Processing-Based-Bengali-Document-Layout-Analysis-with-YOLOV8" class="headerlink" title="A Post-Processing Based Bengali Document Layout Analysis with YOLOV8"></a>A Post-Processing Based Bengali Document Layout Analysis with YOLOV8</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00848">http://arxiv.org/abs/2309.00848</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nazmus Sakib Ahmed, Saad Sakib Noor, Ashraful Islam Shanto Sikder, Abhijit Paul</li>
<li>for: 这 paper 的目的是提高孟加拉文档格式分析 (DLA)，使用 YOLOv8 模型和创新的后处理技术。</li>
<li>methods: 这 paper 使用数据增强来提高模型的鲁棒性，并使用两个阶段预测策略来实现准确的元素分 segmentation。</li>
<li>results: 这 paper 的结果表明， ensemble 模型和后处理技术可以超越基础模型，解决在 BaDLAD 数据集中存在的问题。<details>
<summary>Abstract</summary>
This paper focuses on enhancing Bengali Document Layout Analysis (DLA) using the YOLOv8 model and innovative post-processing techniques. We tackle challenges unique to the complex Bengali script by employing data augmentation for model robustness. After meticulous validation set evaluation, we fine-tune our approach on the complete dataset, leading to a two-stage prediction strategy for accurate element segmentation. Our ensemble model, combined with post-processing, outperforms individual base architectures, addressing issues identified in the BaDLAD dataset. By leveraging this approach, we aim to advance Bengali document analysis, contributing to improved OCR and document comprehension and BaDLAD serves as a foundational resource for this endeavor, aiding future research in the field. Furthermore, our experiments provided key insights to incorporate new strategies into the established solution.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文关注使用YOLOv8模型和创新的后处理技术进行增强孟加拉文档布局分析（DLA）。我们利用数据增强来提高模型的可靠性，并在完整的数据集上精心调整方法，实现了两stage预测策略以确定精确的元素分割。我们的集成模型，结合后处理，超越了基础模型，解决了在BaDLAD数据集中 Identified的问题。通过这种方法，我们希望推进孟加拉文档分析，提高OCR和文档理解。BaDLAD serves as a foundational resource for this endeavor, aiding future research in the field.此外，我们的实验提供了关键的思路，可以在已有的解决方案中添加新策略。
</details></li>
</ul>
<hr>
<h2 id="pSTarC-Pseudo-Source-Guided-Target-Clustering-for-Fully-Test-Time-Adaptation"><a href="#pSTarC-Pseudo-Source-Guided-Target-Clustering-for-Fully-Test-Time-Adaptation" class="headerlink" title="pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation"></a>pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00846">http://arxiv.org/abs/2309.00846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manogna Sreenivas, Goirik Chakrabarty, Soma Biswas</li>
<li>for: 本文旨在提出一种新的测试时适应（TTA）方法，以便在实际场景中，模型能够很好地表现。</li>
<li>methods: 本方法叫做 Pseudo Source guided Target Clustering（pSTarC），它是在实际领域变换下的TTA领域中相对未曾研究的。这种方法 Draws inspiration from target clustering techniques and exploits the source classifier for generating pseudo-source samples。</li>
<li>results: 实验表明，pSTarC可以减轻计算需求，同时提高预测精度。此外，我们还证明了pSTarC的普适性，并在连续TTA框架中表现出色。<details>
<summary>Abstract</summary>
Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling models to perform well in real-world scenarios, where test data distribution differs from training. In this work, we propose a novel approach called pseudo Source guided Target Clustering (pSTarC) addressing the relatively unexplored area of TTA under real-world domain shifts. This method draws inspiration from target clustering techniques and exploits the source classifier for generating pseudo-source samples. The test samples are strategically aligned with these pseudo-source samples, facilitating their clustering and thereby enhancing TTA performance. pSTarC operates solely within the fully test-time adaptation protocol, removing the need for actual source data. Experimental validation on a variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126, CIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant improvements in prediction accuracy along with efficient computational requirements. Furthermore, we also demonstrate the universality of the pSTarC framework by showing its effectiveness for the continuous TTA framework.
</details>
<details>
<summary>摘要</summary>
测试时适应（TTA）是机器学习中的一个重要概念，它允许模型在真实世界中表现良好，其测试数据分布与训练数据分布不同。在这种情况下，我们提出了一种新的方法called pseudo Source guided Target Clustering（pSTarC），用于解决真实世界域转移下的TTA。这种方法 Draws inspiration from 目标划分技术，利用源分类器来生成pseudo-source样本。测试样本被策略性地与这些pseudo-source样本相对应，从而提高了TTA性能。pSTarC在完全测试时适应协议下运行，不需要实际的源数据。在多个域转移数据集上，包括VisDA、Office-Home、DomainNet-126和CIFAR-100C，我们进行了实验 validate pSTarC的效果。这种方法在预测精度和计算需求方面具有显著改进。此外，我们还证明了pSTarC框架的通用性，其在连续TTA框架中也表现出了效果。
</details></li>
</ul>
<hr>
<h2 id="ObjectLab-Automated-Diagnosis-of-Mislabeled-Images-in-Object-Detection-Data"><a href="#ObjectLab-Automated-Diagnosis-of-Mislabeled-Images-in-Object-Detection-Data" class="headerlink" title="ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection Data"></a>ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00832">http://arxiv.org/abs/2309.00832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cleanlab/cleanlab">https://github.com/cleanlab/cleanlab</a></li>
<li>paper_authors: Ulyana Tkachenko, Aditya Thyagarajan, Jonas Mueller</li>
<li>for: 本研究旨在提高物体检测模型的训练数据质量，以提高模型的检测精度和稳定性。</li>
<li>methods: 本研究提出了一种名为ObjectLab的简单而直观的算法，用于检测物体检测标签中的多种错误，包括：漏掉 bounding box、位置错误和类别标签错误。ObjectLab 使用任何已经训练过物体检测模型来评估每个图像的标签质量，以便自动优先级检查和修正涉及到错误的图像。</li>
<li>results: 对于多个物体检测数据集（包括 COCO）和多种模型（包括 Detectron-X101 和 Faster-RCNN），ObjectLab 能够准确地检测标签错误，与其他标签质量分数相比，具有更高的准确率&#x2F;回归率。<details>
<summary>Abstract</summary>
Despite powering sensitive systems like autonomous vehicles, object detection remains fairly brittle in part due to annotation errors that plague most real-world training datasets. We propose ObjectLab, a straightforward algorithm to detect diverse errors in object detection labels, including: overlooked bounding boxes, badly located boxes, and incorrect class label assignments. ObjectLab utilizes any trained object detection model to score the label quality of each image, such that mislabeled images can be automatically prioritized for label review/correction. Properly handling erroneous data enables training a better version of the same object detection model, without any change in existing modeling code. Across different object detection datasets (including COCO) and different models (including Detectron-X101 and Faster-RCNN), ObjectLab consistently detects annotation errors with much better precision/recall compared to other label quality scores.
</details>
<details>
<summary>摘要</summary>
尽管它用于感知系统如自动驾驶汽车的识别系统，但对象检测仍然比较脆弱，其中一个主要原因是训练数据中的注释错误。我们提议ObjectLab，一种简单的算法，用于检测对象检测标签中的多种错误，包括：被忽略的 bounding box、 incorrect 的位置和类别标签分配错误。ObjectLab 使用任何已经训练过的对象检测模型来评估每个图像的标签质量，以便自动优先级化需要更正的标签。正确处理错误数据可以训练一个更好的同样的对象检测模型，无需更改现有的代码。在不同的对象检测 dataset （包括 COCO）和不同的模型（包括 Detectron-X101 和 Faster-RCNN）中，ObjectLab  invariably  detects 注释错误的精度/回归比例远高于其他标签质量分数。
</details></li>
</ul>
<hr>
<h2 id="Multi-scale-Data-driven-and-Anatomically-Constrained-Deep-Learning-Image-Registration-for-Adult-and-Fetal-Echocardiography"><a href="#Multi-scale-Data-driven-and-Anatomically-Constrained-Deep-Learning-Image-Registration-for-Adult-and-Fetal-Echocardiography" class="headerlink" title="Multi-scale, Data-driven and Anatomically Constrained Deep Learning Image Registration for Adult and Fetal Echocardiography"></a>Multi-scale, Data-driven and Anatomically Constrained Deep Learning Image Registration for Adult and Fetal Echocardiography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00831">http://arxiv.org/abs/2309.00831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kamruleee51/ddc-ac-dlir">https://github.com/kamruleee51/ddc-ac-dlir</a></li>
<li>paper_authors: Md. Kamrul Hasan, Haobo Zhu, Guang Yang, Choon Hwai Yap</li>
<li>for: 这个研究的目的是提高电子医学图像匹配的精度和稳定性，以便在临床中更 accurately 评估心脏运动和肌体弹性。</li>
<li>methods: 这个研究使用了深度学习图像匹配（DLIR）技术，并提出了一种将形态编码损失、数据驱动损失和多 scales 训练方法相结合的框架。</li>
<li>results: 测试结果表明，这种方法可以提高图像匹配的精度和稳定性，并且可以在成人和胎儿电子医学图像中达到优秀的结果。<details>
<summary>Abstract</summary>
Temporal echocardiography image registration is a basis for clinical quantifications such as cardiac motion estimation, myocardial strain assessments, and stroke volume quantifications. In past studies, deep learning image registration (DLIR) has shown promising results and is consistently accurate and precise, requiring less computational time. We propose that a greater focus on the warped moving image's anatomic plausibility and image quality can support robust DLIR performance. Further, past implementations have focused on adult echocardiography, and there is an absence of DLIR implementations for fetal echocardiography. We propose a framework that combines three strategies for DLIR in both fetal and adult echo: (1) an anatomic shape-encoded loss to preserve physiological myocardial and left ventricular anatomical topologies in warped images; (2) a data-driven loss that is trained adversarially to preserve good image texture features in warped images; and (3) a multi-scale training scheme of a data-driven and anatomically constrained algorithm to improve accuracy. Our tests show that good anatomical topology and image textures are strongly linked to shape-encoded and data-driven adversarial losses. They improve different aspects of registration performance in a non-overlapping way, justifying their combination. Despite fundamental distinctions between adult and fetal echo images, we show that these strategies can provide excellent registration results in both adult and fetal echocardiography using the publicly available CAMUS adult echo dataset and our private multi-demographic fetal echo dataset. Our approach outperforms traditional non-DL gold standard registration approaches, including Optical Flow and Elastix. Registration improvements could be translated to more accurate and precise clinical quantification of cardiac ejection fraction, demonstrating a potential for translation.
</details>
<details>
<summary>摘要</summary>
医学影像协调是基础 для临床量化，如心脏运动评估、肌肉弹性评估和心脏血量评估。过去的研究表明，深度学习图像协调（DLIR）有扎实的结果和精度，需要较少的计算时间。我们提议更重视卷积动图像的 анатомиче可能性和图像质量，以支持Robust DLIR表现。此外，过去的实施都是成人echo，而 absence of DLIR实现 для胎儿echo。我们提议一种框架，该框架结合以下三种策略：（1）一种适应Physiological myocardial和左心脏的生物学特征的形状编码损失；（2）一种通过对图像特征进行反向学习来保持好的图像特征；（3）一种多尺度训练的数据驱动和生物学特征驱动的算法，以提高准确性。我们的测试表明，良好的生物学特征和图像特征是强相关的，这些损失可以不同方面提高协调性能。尽管成人echo和胎儿echo图像具有基本不同的特征，我们的策略可以在两者上提供出色的协调结果。我们的方法超过了传统的非深度学习标准注册方法，包括折射流和Elastix。更好的协调可能可以翻译到更准确和精度的临床量化，表明了我们的方法的潜在应用。
</details></li>
</ul>
<hr>
<h2 id="When-3D-Bounding-Box-Meets-SAM-Point-Cloud-Instance-Segmentation-with-Weak-and-Noisy-Supervision"><a href="#When-3D-Bounding-Box-Meets-SAM-Point-Cloud-Instance-Segmentation-with-Weak-and-Noisy-Supervision" class="headerlink" title="When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision"></a>When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00828">http://arxiv.org/abs/2309.00828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingtao Yu, Heming Du, Chen Liu, Xin Yu</li>
<li>for: 提高弱监督3D点云实例分割的性能，使用矩形框筛选的粗糙标注。</li>
<li>methods: 利用预训练的2D基础模型SAM和3D几何诊断来从矩形框筛选获得准确的点云实例标签。</li>
<li>results: 在ScanNet-v2和S3DIS测试集上实现高质量的3D点云实例标签，并在噪音矩形框筛选情况下显示了高效性和稳定性。<details>
<summary>Abstract</summary>
Learning from bounding-boxes annotations has shown great potential in weakly-supervised 3D point cloud instance segmentation. However, we observed that existing methods would suffer severe performance degradation with perturbed bounding box annotations. To tackle this issue, we propose a complementary image prompt-induced weakly-supervised point cloud instance segmentation (CIP-WPIS) method. CIP-WPIS leverages pretrained knowledge embedded in the 2D foundation model SAM and 3D geometric prior to achieve accurate point-wise instance labels from the bounding box annotations. Specifically, CP-WPIS first selects image views in which 3D candidate points of an instance are fully visible. Then, we generate complementary background and foreground prompts from projections to obtain SAM 2D instance mask predictions. According to these, we assign the confidence values to points indicating the likelihood of points belonging to the instance. Furthermore, we utilize 3D geometric homogeneity provided by superpoints to decide the final instance label assignments. In this fashion, we achieve high-quality 3D point-wise instance labels. Extensive experiments on both Scannet-v2 and S3DIS benchmarks demonstrate that our method is robust against noisy 3D bounding-box annotations and achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
学习封包注解可以提高弱相关3D点云实例分割的潜力。然而，我们发现现有方法对受到扰动 boundING box注解时会表现出严重的性能下降。为解决这个问题，我们提出了补充图 prompt-induced 弱相关3D点云实例分割（CIP-WPIS）方法。CIP-WPIS 利用预训练在2D基础模型 SAM 中嵌入的知识和3D几何规范来实现从 bounding box 注解中获取高质量点云实例标签。具体来说，CIP-WPIS 首先选择在实例中3D候选点完全可见的图像视图。然后，我们生成补充背景和前景投影以获得 SAM 2D实例幕标注。根据这些标注，我们将点Cloud中的点分配确idence值，以表示点是否属于实例。此外，我们利用 superpoints 提供的3D几何一致性来决定实例标签分配。这种方法可以实现高质量点云实例标签。我们在 Scannet-v2 和 S3DIS benchmark上进行了广泛的实验，并证明了我们的方法对受到扰动 bounding box 注解的Robustness和性能具有状态的某些表现。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-font-generation-via-transferring-similarity-guided-global-style-and-quantization-local-style"><a href="#Few-shot-font-generation-via-transferring-similarity-guided-global-style-and-quantization-local-style" class="headerlink" title="Few shot font generation via transferring similarity guided global style and quantization local style"></a>Few shot font generation via transferring similarity guided global style and quantization local style</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00827">http://arxiv.org/abs/2309.00827</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/awei669/VQ-Font">https://github.com/awei669/VQ-Font</a></li>
<li>paper_authors: Wei Pan, Anna Zhu, Xinyu Zhou, Brian Kenji Iwana, Shilin Li</li>
<li>for: 这种研究旨在实现自动化少量字体生成（AFFG），以便通过只需要几个字形参考来生成新的字体，从而降低手动设计字体的劳动成本。</li>
<li>methods: 该方法采用了字符相似性指导的全局特征归一化和精细组件水平表示，并通过跨注意力基本样式传递模块来传递参考字形的风格。无需手动定义特定的字形组件，如笔画和基本元素。</li>
<li>results: 实验结果表明，该方法可以获得完整的组件级风格表示，并控制全局字形特征。与其他当前状态顶尖方法相比，该方法在不同的语言书写系统上表现出了更高的效果和普适性。代码可以在 GitHub 上找到：<a target="_blank" rel="noopener" href="https://github.com/awei669/VQ-Font%E3%80%82">https://github.com/awei669/VQ-Font。</a><details>
<summary>Abstract</summary>
Automatic few-shot font generation (AFFG), aiming at generating new fonts with only a few glyph references, reduces the labor cost of manually designing fonts. However, the traditional AFFG paradigm of style-content disentanglement cannot capture the diverse local details of different fonts. So, many component-based approaches are proposed to tackle this problem. The issue with component-based approaches is that they usually require special pre-defined glyph components, e.g., strokes and radicals, which is infeasible for AFFG of different languages. In this paper, we present a novel font generation approach by aggregating styles from character similarity-guided global features and stylized component-level representations. We calculate the similarity scores of the target character and the referenced samples by measuring the distance along the corresponding channels from the content features, and assigning them as the weights for aggregating the global style features. To better capture the local styles, a cross-attention-based style transfer module is adopted to transfer the styles of reference glyphs to the components, where the components are self-learned discrete latent codes through vector quantization without manual definition. With these designs, our AFFG method could obtain a complete set of component-level style representations, and also control the global glyph characteristics. The experimental results reflect the effectiveness and generalization of the proposed method on different linguistic scripts, and also show its superiority when compared with other state-of-the-art methods. The source code can be found at https://github.com/awei669/VQ-Font.
</details>
<details>
<summary>摘要</summary>
自动几个字体生成（AFFG），目的是通过只需几个字形引用来生成新字体，从而减少手动设计字体的劳动成本。然而，传统的AFFG模式中的风格内容分离无法捕捉不同字体的地方细节。因此，许多组件化方法被提议。然而，这些组件化方法通常需要特定的预定义字形组件，例如笔画和基本元素，这是不适用于不同语言的AFFG。在这篇论文中，我们提出了一种新的字体生成方法，通过将风格特征从类似性指导的全局特征和精细组件水平表示相乘。我们在目标字形和参考样本之间计算相似性分数，并将其作为全局风格特征的权重进行相乘。为更好地捕捉地方风格，我们采用了交叉注意力基于的风格传输模块，将参考字形的风格传输到组件水平，其中组件是通过量化Vector без manual定义得到的自适应积分码。通过这些设计，我们的AFFG方法可以获得完整的组件级别风格表示，同时控制全局字形特征。实验结果表明了我们的方法在不同的文字系统中的效果和普遍性，以及与其他当前领域的方法相比的优势。详细代码可以在 <https://github.com/awei669/VQ-Font> 找到。
</details></li>
</ul>
<hr>
<h2 id="Soil-Image-Segmentation-Based-on-Mask-R-CNN"><a href="#Soil-Image-Segmentation-Based-on-Mask-R-CNN" class="headerlink" title="Soil Image Segmentation Based on Mask R-CNN"></a>Soil Image Segmentation Based on Mask R-CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00817">http://arxiv.org/abs/2309.00817</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YidaMyth/Mask-RCNN_QtGui">https://github.com/YidaMyth/Mask-RCNN_QtGui</a></li>
<li>paper_authors: Yida Chen, Kang Liu, Yi Xin, Xinru Zhao</li>
<li>for: 本研究是为了开发一种可以在自然环境下实时 segmentation 和检测土壤图像的机器视觉方法。</li>
<li>methods: 本研究使用了深度学习的Mask R-CNN模型来实现土壤图像实例分割。首先，构建了一个基于收集的土壤图像集，并使用EISeg注解工具将土壤区域标注为土壤。然后，使用了GPU加速来训练Mask R-CNN模型，并在训练集和验证集上进行了评估。</li>
<li>results: 训练后，Mask R-CNN模型可以准确地 segmentation 土壤图像，并在不同环境下收集的图像上表现良好。训练集的损失值为0.1999，验证集的mAP值（IoU&#x3D;0.5）为0.8804，并且只需0.06秒的时间来完成图像 segmentation。<details>
<summary>Abstract</summary>
The complex background in the soil image collected in the field natural environment will affect the subsequent soil image recognition based on machine vision. Segmenting the soil center area from the soil image can eliminate the influence of the complex background, which is an important preprocessing work for subsequent soil image recognition. For the first time, the deep learning method was applied to soil image segmentation, and the Mask R-CNN model was selected to complete the positioning and segmentation of soil images. Construct a soil image dataset based on the collected soil images, use the EISeg annotation tool to mark the soil area as soil, and save the annotation information; train the Mask R-CNN soil image instance segmentation model. The trained model can obtain accurate segmentation results for soil images, and can show good performance on soil images collected in different environments; the trained instance segmentation model has a loss value of 0.1999 in the training set, and the mAP of the validation set segmentation (IoU=0.5) is 0.8804, and it takes only 0.06s to complete image segmentation based on GPU acceleration, which can meet the real-time segmentation and detection of soil images in the field under natural conditions. You can get our code in the Conclusions. The homepage is https://github.com/YidaMyth.
</details>
<details>
<summary>摘要</summary>
在自然环境中采集的土壤图像中的复杂背景将影响后续的土壤图像认知基于机器视觉。 segmenting 土壤中心区域从土壤图像中可以消除复杂背景的影响，这是土壤图像认知前置处理的重要步骤。 这是首次应用深度学习方法进行土壤图像分割，选择了Mask R-CNN模型来完成位置和分割土壤图像。 根据收集的土壤图像构建了土壤图像数据集，使用EISeg注意力工具标记土壤区域为土壤，并保存注意力信息。 训练Mask R-CNN土壤图像实例分割模型。 训练后的模型可以在不同环境中获得高精度的分割结果，并且在0.06秒钟内完成图像分割基于GPU加速，可以满足在自然条件下的实时分割和检测土壤图像。 可以在结论中获取我们的代码。 主页是https://github.com/YidaMyth。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Video-Transformers-for-Isolated-Sign-Language-Recognition"><a href="#Self-Supervised-Video-Transformers-for-Isolated-Sign-Language-Recognition" class="headerlink" title="Self-Supervised Video Transformers for Isolated Sign Language Recognition"></a>Self-Supervised Video Transformers for Isolated Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.02450">http://arxiv.org/abs/2309.02450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcelo Sandoval-Castaneda, Yanhong Li, Diane Brentari, Karen Livescu, Gregory Shakhnarovich</li>
<li>for: 本研究是一篇关于孤立手语识别（ISLR）自我超级vised学习方法的深入分析文章。</li>
<li>methods: 我们考虑了四种最近引入的 transformer 基于方法，以及四种预训练数据模式，并在 WLASL2000 数据集上研究了所有组合。</li>
<li>results: 我们发现，MaskFeat 可以超过 pose-based 和监督视频模型，在 gloss-based WLASL2000 上达到 79.02% 的top-1 准确率。此外，我们还分析了这些模型对 ASL 手语表示的能力，并通过 linear probing 分析表示的多样性。这个研究证明了 ISLR 中 architecture 和预训练任务的选择对性的重要性。<details>
<summary>Abstract</summary>
This paper presents an in-depth analysis of various self-supervision methods for isolated sign language recognition (ISLR). We consider four recently introduced transformer-based approaches to self-supervised learning from videos, and four pre-training data regimes, and study all the combinations on the WLASL2000 dataset. Our findings reveal that MaskFeat achieves performance superior to pose-based and supervised video models, with a top-1 accuracy of 79.02% on gloss-based WLASL2000. Furthermore, we analyze these models' ability to produce representations of ASL signs using linear probing on diverse phonological features. This study underscores the value of architecture and pre-training task choices in ISLR. Specifically, our results on WLASL2000 highlight the power of masked reconstruction pre-training, and our linear probing results demonstrate the importance of hierarchical vision transformers for sign language representation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AttT2M-Text-Driven-Human-Motion-Generation-with-Multi-Perspective-Attention-Mechanism"><a href="#AttT2M-Text-Driven-Human-Motion-Generation-with-Multi-Perspective-Attention-Mechanism" class="headerlink" title="AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism"></a>AttT2M: Text-Driven Human Motion Generation with Multi-Perspective Attention Mechanism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00796">http://arxiv.org/abs/2309.00796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZcyMonkey/AttT2M">https://github.com/ZcyMonkey/AttT2M</a></li>
<li>paper_authors: Chongyang Zhong, Lei Hu, Zihao Zhang, Shihong Xia</li>
<li>for: 本研究的目的是提出一种基于文本描述的三维人体运动生成方法，以便生成自然、多样化的人体运动。</li>
<li>methods: 该方法使用了两个阶段的方法，包括body-part attention和global-local motion-text attention。body-part attention通过引入人体部分空间编码器来学习更表达性的精度矩阵空间，而global-local motion-text attention则是从cross-modal角度学习文本和运动之间的关系。</li>
<li>results: 对于HumanML3D和KIT-ML两个数据集，该方法在质量和量化评估中几乎所有超过当前状态的方法，并实现了细腻的生成和action2motion。<details>
<summary>Abstract</summary>
Generating 3D human motion based on textual descriptions has been a research focus in recent years. It requires the generated motion to be diverse, natural, and conform to the textual description. Due to the complex spatio-temporal nature of human motion and the difficulty in learning the cross-modal relationship between text and motion, text-driven motion generation is still a challenging problem. To address these issues, we propose \textbf{AttT2M}, a two-stage method with multi-perspective attention mechanism: \textbf{body-part attention} and \textbf{global-local motion-text attention}. The former focuses on the motion embedding perspective, which means introducing a body-part spatio-temporal encoder into VQ-VAE to learn a more expressive discrete latent space. The latter is from the cross-modal perspective, which is used to learn the sentence-level and word-level motion-text cross-modal relationship. The text-driven motion is finally generated with a generative transformer. Extensive experiments conducted on HumanML3D and KIT-ML demonstrate that our method outperforms the current state-of-the-art works in terms of qualitative and quantitative evaluation, and achieve fine-grained synthesis and action2motion. Our code is in https://github.com/ZcyMonkey/AttT2M
</details>
<details>
<summary>摘要</summary>
师MAIN RESEARCH FOCUS IN RECENT YEARS HAS BEEN GENERATING 3D HUMAN MOTION BASED ON TEXTUAL DESCRIPTIONS. THIS REQUIRES THE GENERATED MOTION TO BE DIVERSE, NATURAL, AND CONFORM TO THE TEXTUAL DESCRIPTION. DUE TO THE COMPLEX SPATIO-TEMPORAL NATURE OF HUMAN MOTION AND THE DIFFICULTY IN LEARNING THE CROSS-MODAL RELATIONSHIP BETWEEN TEXT AND MOTION, TEXT-DRIVEN MOTION GENERATION IS STILL A CHALLENGING PROBLEM. TO ADDRESS THESE ISSUES, WE PROPOSE ATT2M, A TWO-STAGE METHOD WITH MULTI-PERSPECTIVE ATTENTION MECHANISM. THE FORMER FOCUSES ON THE MOTION EMBEDDING PERSPECTIVE, WHICH MEANS INTRODUCING A BODY-PART SPATIO-TEMPORAL ENCODER INTO VQ-VAE TO LEARN A MORE EXPRESSIVE DISCRETE LATENT SPACE. THE LATTER IS FROM THE CROSS-MODAL PERSPECTIVE, WHICH IS USED TO LEARN THE SENTENCE-LEVEL AND WORD-LEVEL MOTION-TEXT CROSS-MODAL RELATIONSHIP. THE TEXT-DRIVEN MOTION IS FINALLY GENERATED WITH A GENERATIVE TRANSFORMER. EXTENSIVE EXPERIMENTS CONDUCTED ON HUMANML3D AND KIT-ML DEMONSTRATE THAT OUR METHOD OUTPERFORMS THE CURRENT STATE-OF-THE-ART WORKS IN TERMS OF QUALITATIVE AND QUANTITATIVE EVALUATION, AND ACHIEVE FINE-GRAINED SYNTHESIS AND ACTION2MOTION. OUR CODE IS AVAILABLE AT https://github.com/ZcyMonkey/AttT2M.
</details></li>
</ul>
<hr>
<h2 id="FastPoseGait-A-Toolbox-and-Benchmark-for-Efficient-Pose-based-Gait-Recognition"><a href="#FastPoseGait-A-Toolbox-and-Benchmark-for-Efficient-Pose-based-Gait-Recognition" class="headerlink" title="FastPoseGait: A Toolbox and Benchmark for Efficient Pose-based Gait Recognition"></a>FastPoseGait: A Toolbox and Benchmark for Efficient Pose-based Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00794">http://arxiv.org/abs/2309.00794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bnu-ivc/fastposegait">https://github.com/bnu-ivc/fastposegait</a></li>
<li>paper_authors: Shibei Meng, Yang Fu, Saihui Hou, Chunshui Cao, Xu Liu, Yongzhen Huang</li>
<li>for: 这个研究旨在提供一个开源的 pose-based gait recognition 工具箱，以便研究人员可以快速进行 pose-based gait recognition 的研究。</li>
<li>methods: 这个工具箱支持多种现代 pose-based gait recognition 算法，包括多种 SOTA 算法和最新的进步。此外，这个工具箱还提供了许多预训模型和详细的 benchmark 结果，对未来的研究提供了宝贵的参考和对照。</li>
<li>results: 这个研究提供了一个高度可调的 pose-based gait recognition 工具箱，可以快速地进行 pose-based gait recognition 的研究。此外，这个工具箱还提供了许多预训模型和详细的 benchmark 结果，对未来的研究提供了宝贵的参考和对照。<details>
<summary>Abstract</summary>
We present FastPoseGait, an open-source toolbox for pose-based gait recognition based on PyTorch. Our toolbox supports a set of cutting-edge pose-based gait recognition algorithms and a variety of related benchmarks. Unlike other pose-based projects that focus on a single algorithm, FastPoseGait integrates several state-of-the-art (SOTA) algorithms under a unified framework, incorporating both the latest advancements and best practices to ease the comparison of effectiveness and efficiency. In addition, to promote future research on pose-based gait recognition, we provide numerous pre-trained models and detailed benchmark results, which offer valuable insights and serve as a reference for further investigations. By leveraging the highly modular structure and diverse methods offered by FastPoseGait, researchers can quickly delve into pose-based gait recognition and promote development in the field. In this paper, we outline various features of this toolbox, aiming that our toolbox and benchmarks can further foster collaboration, facilitate reproducibility, and encourage the development of innovative algorithms for pose-based gait recognition. FastPoseGait is available at https://github.com//BNU-IVC/FastPoseGait and is actively maintained. We will continue updating this report as we add new features.
</details>
<details>
<summary>摘要</summary>
我们现在推出 FastPoseGait，一个开源工具箱 для pose-based 步态识别基于 PyTorch。我们的工具箱支持一系列当今最先进的 pose-based 步态识别算法以及一些相关的benchmark。与其他 pose-based 项目不同，FastPoseGait 集成了多种最新的SOTA算法，并在一个统一的框架下集成了最新的技术和最佳实践，以便方便比较效果和效率。此外，为促进未来的pose-based 步态识别研究，我们提供了多个预训练模型和详细的benchmark结果，这些结果对于进一步的调查提供了 ценные信息，并作为参考来供其他研究人员参考。通过 FastPoseGait 的高度可模块化结构和多种方法，研究人员可以快速探索 pose-based 步态识别领域，并促进该领域的发展。在这篇文章中，我们详细介绍了 FastPoseGait 的各种特点，希望通过我们的工具箱和benchmark，推动合作、促进复制性和激发 pose-based 步态识别领域的创新算法的发展。FastPoseGait 可以在 <https://github.com//BNU-IVC/FastPoseGait> 上下载，并且 actively 维护。我们将继续更新这份报告，添加新的特性。
</details></li>
</ul>
<hr>
<h2 id="Towards-High-Frequency-Tracking-and-Fast-Edge-Aware-Optimization"><a href="#Towards-High-Frequency-Tracking-and-Fast-Edge-Aware-Optimization" class="headerlink" title="Towards High-Frequency Tracking and Fast Edge-Aware Optimization"></a>Towards High-Frequency Tracking and Fast Edge-Aware Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00777">http://arxiv.org/abs/2309.00777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akash Bapat<br>for:* 这个论文目标是提高AR&#x2F;VR跟踪系统的状态 искусственный智能，提高跟踪频率至数个命令的频率。methods:* 该论文提出了一种利用多个商业摄像头的方法，利用摄像头的滚动屏和圆形扭曲来实现高频跟踪。results:* 实验表明，该方法可以在不同的运动范围内实现高精度的跟踪，并且可以与现有的状态 искусственный智能系统进行综合比较。<details>
<summary>Abstract</summary>
This dissertation advances the state of the art for AR/VR tracking systems by increasing the tracking frequency by orders of magnitude and proposes an efficient algorithm for the problem of edge-aware optimization.   AR/VR is a natural way of interacting with computers, where the physical and digital worlds coexist. We are on the cusp of a radical change in how humans perform and interact with computing. Humans are sensitive to small misalignments between the real and the virtual world, and tracking at kilo-Hertz frequencies becomes essential. Current vision-based systems fall short, as their tracking frequency is implicitly limited by the frame-rate of the camera. This thesis presents a prototype system which can track at orders of magnitude higher than the state-of-the-art methods using multiple commodity cameras. The proposed system exploits characteristics of the camera traditionally considered as flaws, namely rolling shutter and radial distortion. The experimental evaluation shows the effectiveness of the method for various degrees of motion.   Furthermore, edge-aware optimization is an indispensable tool in the computer vision arsenal for accurate filtering of depth-data and image-based rendering, which is increasingly being used for content creation and geometry processing for AR/VR. As applications increasingly demand higher resolution and speed, there exists a need to develop methods that scale accordingly. This dissertation proposes such an edge-aware optimization framework which is efficient, accurate, and algorithmically scales well, all of which are much desirable traits not found jointly in the state of the art. The experiments show the effectiveness of the framework in a multitude of computer vision tasks such as computational photography and stereo.
</details>
<details>
<summary>摘要</summary>
Furthermore, edge-aware optimization is an indispensable tool in the computer vision arsenal for accurate filtering of depth-data and image-based rendering, which is increasingly being used for content creation and geometry processing for AR/VR.  As applications increasingly demand higher resolution and speed, there exists a need to develop methods that scale accordingly.  This dissertation proposes such an edge-aware optimization framework which is efficient, accurate, and algorithmically scales well, all of which are much desirable traits not found jointly in the state of the art.  The experiments show the effectiveness of the framework in a multitude of computer vision tasks such as computational photography and stereo.
</details></li>
</ul>
<hr>
<h2 id="Full-Reference-Video-Quality-Assessment-for-Machine-Learning-Based-Video-Codecs"><a href="#Full-Reference-Video-Quality-Assessment-for-Machine-Learning-Based-Video-Codecs" class="headerlink" title="Full Reference Video Quality Assessment for Machine Learning-Based Video Codecs"></a>Full Reference Video Quality Assessment for Machine Learning-Based Video Codecs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00769">http://arxiv.org/abs/2309.00769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abrar Majeedi, Babak Naderi, Yasaman Hosseinkashi, Juhee Cho, Ruben Alvarez Martinez, Ross Cutler</li>
<li>for: 本研究旨在提供一个准确评估metric以便评估机器学习（ML）基于的影像压缩器，因为现有的评估metric在ML影像压缩器上不具有高相关性。</li>
<li>methods: 本研究使用了一个新的 dataset，其中包含了已精准地标注的质量标准。此外，研究者还提出了一个全参照影像质量评估（FRVQA）模型，它具有0.99的彭森相関系数（PCC）和0.99的施普曼排名相关系数（SRCC）。</li>
<li>results: 研究结果显示，新的评估metric 具有高相关性，并且可以帮助加速机器学习影像压缩器的研究。此外，研究者还将dataset和FRVQA模型开源，以便其他人可以进一步改进FRVQA模型。<details>
<summary>Abstract</summary>
Machine learning-based video codecs have made significant progress in the past few years. A critical area in the development of ML-based video codecs is an accurate evaluation metric that does not require an expensive and slow subjective test. We show that existing evaluation metrics that were designed and trained on DSP-based video codecs are not highly correlated to subjective opinion when used with ML video codecs due to the video artifacts being quite different between ML and video codecs. We provide a new dataset of ML video codec videos that have been accurately labeled for quality. We also propose a new full reference video quality assessment (FRVQA) model that achieves a Pearson Correlation Coefficient (PCC) of 0.99 and a Spearman's Rank Correlation Coefficient (SRCC) of 0.99 at the model level. We make the dataset and FRVQA model open source to help accelerate research in ML video codecs, and so that others can further improve the FRVQA model.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we have created a new dataset of ML video codec videos that have been accurately labeled for quality. We also propose a new full reference video quality assessment (FRVQA) model that achieves a Pearson Correlation Coefficient (PCC) of 0.99 and a Spearman's Rank Correlation Coefficient (SRCC) of 0.99 at the model level.To help accelerate research in ML video codecs, we are making the dataset and FRVQA model open source. We hope that others will use and build upon our work to further improve the FRVQA model and advance the field of ML video codecs.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.CV_2023_09_02/" data-id="clpxp03z700j3fm88ahuv0tgi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.AI_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T12:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.AI_2023_09_02/">cs.AI - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Neurosymbolic-Reinforcement-Learning-and-Planning-A-Survey"><a href="#Neurosymbolic-Reinforcement-Learning-and-Planning-A-Survey" class="headerlink" title="Neurosymbolic Reinforcement Learning and Planning: A Survey"></a>Neurosymbolic Reinforcement Learning and Planning: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01038">http://arxiv.org/abs/2309.01038</a></li>
<li>repo_url: None</li>
<li>paper_authors: K. Acharya, W. Raza, C. M. J. M. Dourado Jr, A. Velasquez, H. Song<br>for: 本研究的目的是对 neurosymbolic 人工智能（Neurosymbolic AI）领域的发展进行文献综述，特别是 neurosymbolic deep learning（Neurosymbolic DL）和 neurosymbolic reinforcement learning（Neurosymbolic RL）这两个子领域。methods: 本研究使用文献综述的方法，对 neurosymbolic RL 领域的研究进行分类和概括。三种分类方法是：学习 для理解、理解 для学习和学习-理解。这些分类方法再次细分为各个应用领域。results: 本研究发现 neurosymbolic RL 领域的研究主要集中在三个方面：学习、理解和决策。学习方面包括对于不同应用领域的学习方法和技术的研究，例如 image recognition 和自然语言处理。理解方面包括对于不同应用领域的理解方法和技术的研究，例如知识 Graph 和 Semantic Reasoning。决策方面包括对于不同应用领域的决策方法和技术的研究，例如 deep reinforcement learning 和 Transfer Learning。<details>
<summary>Abstract</summary>
The area of Neurosymbolic Artificial Intelligence (Neurosymbolic AI) is rapidly developing and has become a popular research topic, encompassing sub-fields such as Neurosymbolic Deep Learning (Neurosymbolic DL) and Neurosymbolic Reinforcement Learning (Neurosymbolic RL). Compared to traditional learning methods, Neurosymbolic AI offers significant advantages by simplifying complexity and providing transparency and explainability. Reinforcement Learning(RL), a long-standing Artificial Intelligence(AI) concept that mimics human behavior using rewards and punishment, is a fundamental component of Neurosymbolic RL, a recent integration of the two fields that has yielded promising results. The aim of this paper is to contribute to the emerging field of Neurosymbolic RL by conducting a literature survey. Our evaluation focuses on the three components that constitute Neurosymbolic RL: neural, symbolic, and RL. We categorize works based on the role played by the neural and symbolic parts in RL, into three taxonomies:Learning for Reasoning, Reasoning for Learning and Learning-Reasoning. These categories are further divided into sub-categories based on their applications. Furthermore, we analyze the RL components of each research work, including the state space, action space, policy module, and RL algorithm. Additionally, we identify research opportunities and challenges in various applications within this dynamic field.
</details>
<details>
<summary>摘要</summary>
neural 符号 人工智能（Neurosymbolic AI）领域在迅速发展，已成为研究热点，涵盖子领域 such as Neurosymbolic Deep Learning（Neurosymbolic DL）和Neurosymbolic Reinforcement Learning（Neurosymbolic RL）。相比传统学习方法，Neurosymbolic AI 提供了 significan advantages，例如简化复杂性和提供透明性和解释性。人工智能（AI）概念，模拟人类行为使用奖励和惩罚的 Reinforcement Learning（RL），是 Neurosymbolic RL 的基础组件，是一种最近 integrate 两个领域的成果，并产生了有前途的结果。本文的目标是为emerging 的 Neurosymbolic RL 领域进行文献综述。我们的评估将关注Neurosymbolic RL 中的三个组件：神经、符号和RL。我们根据这三个组件在 RL 中的角色，将工作分为三类：学习为理解、理解为学习和学习-理解。这些类别进一步分为应用的子类别。此外，我们还分析了每个研究作品中的 RL 组件，包括状态空间、动作空间、策略模块和RL算法。此外，我们还识别了在不同应用场景中的研究机会和挑战。
</details></li>
</ul>
<hr>
<h2 id="Deep-Deformable-Models-Learning-3D-Shape-Abstractions-with-Part-Consistency"><a href="#Deep-Deformable-Models-Learning-3D-Shape-Abstractions-with-Part-Consistency" class="headerlink" title="Deep Deformable Models: Learning 3D Shape Abstractions with Part Consistency"></a>Deep Deformable Models: Learning 3D Shape Abstractions with Part Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01035">http://arxiv.org/abs/2309.01035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Liu, Long Zhao, Qilong Zhangli, Yunhe Gao, Ting Liu, Dimitris N. Metaxas</li>
<li>for: 本研究旨在提出一种能够精准抽象自然物体形状的深度学习方法，以提高形状理解和应用。</li>
<li>methods: 本方法基于深度学习的Deep Deformable Models (DDMs)，它使用全局变换和 diffeomorphic 本地变换来描述物体形状，并可以学习到精准的部件相对位置和尺寸。</li>
<li>results: 在ShapeNet数据集上进行了广泛的实验，并证明了DDMs可以在形状抽象中具有更高的精度和部件一致性，并且超过了现有的状态场方法。<details>
<summary>Abstract</summary>
The task of shape abstraction with semantic part consistency is challenging due to the complex geometries of natural objects. Recent methods learn to represent an object shape using a set of simple primitives to fit the target. \textcolor{black}{However, in these methods, the primitives used do not always correspond to real parts or lack geometric flexibility for semantic interpretation.} In this paper, we investigate salient and efficient primitive descriptors for accurate shape abstractions, and propose \textit{Deep Deformable Models (DDMs)}. DDM employs global deformations and diffeomorphic local deformations. These properties enable DDM to abstract complex object shapes with significantly fewer primitives that offer broader geometry coverage and finer details. DDM is also capable of learning part-level semantic correspondences due to the differentiable and invertible properties of our primitive deformation. Moreover, DDM learning formulation is based on dynamic and kinematic modeling, which enables joint regularization of each sub-transformation during primitive fitting. Extensive experiments on \textit{ShapeNet} demonstrate that DDM outperforms the state-of-the-art in terms of reconstruction and part consistency by a notable margin.
</details>
<details>
<summary>摘要</summary>
shape abstraction with semantic part consistency是一项复杂的任务，因为自然物体的geometry是多样的。现有的方法通过使用一组简单的基本元素来表示物体形状，但这些基本元素并不总是真实的部分或者缺乏地理学灵活性。在这篇论文中，我们调查了突出的和高效的基本描述符，并提出了深度可变模型（DDM）。DDM使用全局变形和 diffeomorphic 地方变形，这些特性使得 DDM 可以准确抽象复杂的物体形状，并且只需要 fewer primitives，可以更好地覆盖各种geometry和细节。此外，DDM 可以学习部分 semantics 的匹配，因为我们的基本描述符具有可微和反函数性。此外，我们的学习框架基于动态和静态模型，可以同时规范每个子转换的定制。我们的实验表明，DDM 在 ShapeNet 上的重建和部件一致性方面，与状态对比明显提高。
</details></li>
</ul>
<hr>
<h2 id="Explainability-for-Large-Language-Models-A-Survey"><a href="#Explainability-for-Large-Language-Models-A-Survey" class="headerlink" title="Explainability for Large Language Models: A Survey"></a>Explainability for Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01029">http://arxiv.org/abs/2309.01029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/Other-sources">https://github.com/Aryia-Behroziuan/Other-sources</a></li>
<li>paper_authors: Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Mengnan Du</li>
<li>for: 本研究旨在掌握和解释大型自然语言处理模型（LLMs）的内部机制，以便了解其行为、局限性和社会影响。</li>
<li>methods: 本文提出了一种分类法，用于描述和解释基于Transformer架构的语言模型。该分类法基于语言模型的训练方法，包括传统的精度训练方法和提示方法。</li>
<li>results: 本文提供了一个结构化的概述，描述了基于Transformer架构的语言模型的解释技术。还介绍了评估生成的解释 metric，以及如何使用解释来调试模型和提高性能。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional machine learning models.
</details>
<details>
<summary>摘要</summary>
In this paper, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations, and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional machine learning models. Traditional fine-tuning-based paradigm:1. Local explanations:	* feature importance analysis	* saliency maps	* attention visualization2. Global explanations:	* model interpretability techniques	* knowledge distillationPrompting-based paradigm:1. Local explanations:	* prompt-based attention analysis	* prompt-based feature importance analysis2. Global explanations:	* prompt-based knowledge distillationEvaluation metrics:1. accuracy2. F1-score3. ROUGE score4. BLEU scoreChallenges and opportunities:1. interpretability of complex models2. lack of transparency in decision-making processes3. potential biases and ethical considerations4. opportunities for improving model performance and trustworthiness5. potential applications in natural language processing and beyond.
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Recommendations-with-Pre-Trained-Large-Language-Models-for-Multimodal-Nudging"><a href="#Zero-Shot-Recommendations-with-Pre-Trained-Large-Language-Models-for-Multimodal-Nudging" class="headerlink" title="Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging"></a>Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01026">http://arxiv.org/abs/2309.01026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paxnea/wain23">https://github.com/paxnea/wain23</a></li>
<li>paper_authors: Rachel Harrison, Anton Dereventsov, Anton Bibin</li>
<li>for: 这篇论文旨在提出一种针对多Modal非站点内容的零shot推荐方法，利用最新的生成AI技术。</li>
<li>methods: 该方法提议将不同Modal的输入描述为文本描述，使用预训练的LLM获取它们的数字表示，并计算它们之间的相似度来进行推荐。</li>
<li>results: 在一个synthetic多Modal推动环境中，该方法可以准确地推荐多Modal的内容项，不需要额外学习。<details>
<summary>Abstract</summary>
We present a method for zero-shot recommendation of multimodal non-stationary content that leverages recent advancements in the field of generative AI. We propose rendering inputs of different modalities as textual descriptions and to utilize pre-trained LLMs to obtain their numerical representations by computing semantic embeddings. Once unified representations of all content items are obtained, the recommendation can be performed by computing an appropriate similarity metric between them without any additional learning. We demonstrate our approach on a synthetic multimodal nudging environment, where the inputs consist of tabular, textual, and visual data.
</details>
<details>
<summary>摘要</summary>
我们提出了一种零shot推荐多Modal非站点内容的方法，利用最新的生成AI技术进行实现。我们提议将不同模式的输入描述为文本描述，并使用预训练的LLM来获得它们的数字表示。一旦所有内容项的统一表示 obten得到， then recommendation可以通过计算相应的相似度 metric来进行，无需进行额外学习。我们在一个Synthetic多Modal拖延环境中进行了示例，输入包括表格、文本和视觉数据。Note:* "零shot" (zero-shot) refers to the fact that the recommendation is done without any additional training or learning of the model.* "多Modal" (multimodal) refers to the fact that the inputs consist of multiple modalities, such as tabular, textual, and visual data.* "非站点" (non-stationary) refers to the fact that the inputs are not stationary, meaning that they are not fixed and can change over time.
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Motion-Blur-for-Robust-3D-Baseball-Player-Pose-Modeling-for-Pitch-Analysis"><a href="#Mitigating-Motion-Blur-for-Robust-3D-Baseball-Player-Pose-Modeling-for-Pitch-Analysis" class="headerlink" title="Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for Pitch Analysis"></a>Mitigating Motion Blur for Robust 3D Baseball Player Pose Modeling for Pitch Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.01010">http://arxiv.org/abs/2309.01010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jerrin Bright, Yuhao Chen, John Zelek</li>
<li>for: 用于 baseball 投手的分析和减少伤病风险</li>
<li>methods: 使用计算机视觉基于pose分析，并利用Synthetic数据增强模型对快速动作的处理能力</li>
<li>results: 提高 pose 估计模型对运动人体动作的处理能力，并在不同的实际场景和摄像头位置下保持模型的稳定性<details>
<summary>Abstract</summary>
Using videos to analyze pitchers in baseball can play a vital role in strategizing and injury prevention. Computer vision-based pose analysis offers a time-efficient and cost-effective approach. However, the use of accessible broadcast videos, with a 30fps framerate, often results in partial body motion blur during fast actions, limiting the performance of existing pose keypoint estimation models. Previous works have primarily relied on fixed backgrounds, assuming minimal motion differences between frames, or utilized multiview data to address this problem. To this end, we propose a synthetic data augmentation pipeline to enhance the model's capability to deal with the pitcher's blurry actions. In addition, we leverage in-the-wild videos to make our model robust under different real-world conditions and camera positions. By carefully optimizing the augmentation parameters, we observed a notable reduction in the loss by 54.2% and 36.2% on the test dataset for 2D and 3D pose estimation respectively. By applying our approach to existing state-of-the-art pose estimators, we demonstrate an average improvement of 29.2%. The findings highlight the effectiveness of our method in mitigating the challenges posed by motion blur, thereby enhancing the overall quality of pose estimation.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:使用视频分析投手可以发挥重要作用，帮助战略和伤害预防。计算机视觉基于姿势分析提供了时间效益和成本效益的方法。然而，使用可 accessible 的广播视频，30fps 帧率，常常导致快速动作中人体部分动作模糊，限制现有的姿势关键点估计模型的性能。先前的工作主要依赖于固定背景，假设动作变化少，或者使用多视图数据来解决这个问题。为此，我们提议一种人工数据增强管道，以提高模型对投手模糊动作的处理能力。此外，我们利用野外视频，使我们的模型在不同的实际情况和摄像机位置下成为更加可靠。通过精心优化增强参数，我们观察到了测试数据集上的损失下降54.2%和36.2%，对2D和3D姿势估计模型进行了平均改进29.2%。通过应用我们的方法到现有的状态态arter-of-the-art姿势估计器，我们实现了平均改进29.2%。这些发现表明了我们的方法在对动作模糊的挑战下减轻影响，从而提高总体姿势估计质量。
</details></li>
</ul>
<hr>
<h2 id="Sequential-Dexterity-Chaining-Dexterous-Policies-for-Long-Horizon-Manipulation"><a href="#Sequential-Dexterity-Chaining-Dexterous-Policies-for-Long-Horizon-Manipulation" class="headerlink" title="Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation"></a>Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00987">http://arxiv.org/abs/2309.00987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanpei Chen, Chen Wang, Li Fei-Fei, C. Karen Liu</li>
<li>for: 这个研究旨在解决复杂长期任务中手部运动空间高维度和复合动力学性的挑战，提出了一个基于循环学习（RL）的总体系统，可以链接多个细致政策以实现长期任务目标。</li>
<li>methods: 这个系统使用了循环学习（RL），搭配了一个过程可行性函数，逐渐精致化子政策以提高链接成功率，同时允许自动政策调整以复原自失败和避免重复阶段。</li>
<li>results: 这个系统在实验中仅使用了几个任务物品进行训练，但能够实现zero-shot转移到真实世界中的机器人，并且能够对不同的物品进行适应和自动调整。更多细节和视频结果可以在<a target="_blank" rel="noopener" href="https://sequential-dexterity.github.io获取./">https://sequential-dexterity.github.io获取。</a><details>
<summary>Abstract</summary>
Many real-world manipulation tasks consist of a series of subtasks that are significantly different from one another. Such long-horizon, complex tasks highlight the potential of dexterous hands, which possess adaptability and versatility, capable of seamlessly transitioning between different modes of functionality without the need for re-grasping or external tools. However, the challenges arise due to the high-dimensional action space of dexterous hand and complex compositional dynamics of the long-horizon tasks. We present Sequential Dexterity, a general system based on reinforcement learning (RL) that chains multiple dexterous policies for achieving long-horizon task goals. The core of the system is a transition feasibility function that progressively finetunes the sub-policies for enhancing chaining success rate, while also enables autonomous policy-switching for recovery from failures and bypassing redundant stages. Despite being trained only in simulation with a few task objects, our system demonstrates generalization capability to novel object shapes and is able to zero-shot transfer to a real-world robot equipped with a dexterous hand. More details and video results could be found at https://sequential-dexterity.github.io
</details>
<details>
<summary>摘要</summary>
多个真实世界操作任务通常是一系列不同的子任务，这些长期任务表明了人工手的可靠性和多样性，可以无需重新抓取或使用外部工具，快速适应不同的模式功能。然而，由于高维动作空间和复杂的compositional dynamics，这些任务具有挑战。我们提出了Sequential Dexterity，一种基于奖励学习（RL）的通用系统，可以串行多个灵活策略以实现长期任务目标。系统的核心是一个过程可行性函数，逐渐细化子策略以提高串行成功率，同时允许自主的策略交换以恢复失败和绕过冗余阶段。尽管只在 simulate 环境中培养了几个任务对象，我们的系统仍然可以通过 Zero-shot 转移到真实世界中的 робоット，装备了灵活的手。更多细节和视频结果可以在 <https://sequential-dexterity.github.io> 找到。
</details></li>
</ul>
<hr>
<h2 id="Compositional-Diffusion-Based-Continuous-Constraint-Solvers"><a href="#Compositional-Diffusion-Based-Continuous-Constraint-Solvers" class="headerlink" title="Compositional Diffusion-Based Continuous Constraint Solvers"></a>Compositional Diffusion-Based Continuous Constraint Solvers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00966">http://arxiv.org/abs/2309.00966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/diffusion-ccsp/diffusion-ccsp.github.io">https://github.com/diffusion-ccsp/diffusion-ccsp.github.io</a></li>
<li>paper_authors: Zhutian Yang, Jiayuan Mao, Yilun Du, Jiajun Wu, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</li>
<li>for: 这篇论文是为了解决机器人智能和规划中的连续约束满足问题 (CCSP) 的学习方法。</li>
<li>methods: 这篇论文使用了compositional diffusion continuous constraint solver (Diffusion-CCSP) 模型，将 CCSP 表示为因子图，并将各种约束类型的能量结合起来，从而获得全局解决方案。</li>
<li>results: Diffusion-CCSP 模型能够强大地泛化到新的约束组合中，并可以与任务和运动规划结合，以生成包含整数和连续参数的长期计划。Here’s the English version of the three key points for reference:</li>
<li>for: This paper proposes a method for learning to solve continuous constraint satisfaction problems (CCSP) in robotic reasoning and planning.</li>
<li>methods: The proposed method uses a compositional diffusion continuous constraint solver (Diffusion-CCSP) model, which represents CCSPs as factor graphs and combines the energies of diffusion models trained to sample for individual constraint types.</li>
<li>results: The Diffusion-CCSP model demonstrates strong generalization to novel combinations of known constraints, and can be integrated into a task and motion planner to devise long-horizon plans that include actions with both discrete and continuous parameters.<details>
<summary>Abstract</summary>
This paper introduces an approach for learning to solve continuous constraint satisfaction problems (CCSP) in robotic reasoning and planning. Previous methods primarily rely on hand-engineering or learning generators for specific constraint types and then rejecting the value assignments when other constraints are violated. By contrast, our model, the compositional diffusion continuous constraint solver (Diffusion-CCSP) derives global solutions to CCSPs by representing them as factor graphs and combining the energies of diffusion models trained to sample for individual constraint types. Diffusion-CCSP exhibits strong generalization to novel combinations of known constraints, and it can be integrated into a task and motion planner to devise long-horizon plans that include actions with both discrete and continuous parameters. Project site: https://diffusion-ccsp.github.io/
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种用于解决连续约束满意问题（CCSP）的机器学习方法。先前的方法主要依靠手工设计或学习生成器特定约束类型，然后拒绝其他约束被违反。而我们的模型——复杂度分析 kontinuous constraint solver（Diffusion-CCSP）——通过将约束类型表示为因子图并将各类约束的能量组合起来，以 derivation global solution to CCSPs。Diffusion-CCSP具有强大的泛化能力，可以适应新的约束组合，并且可以与任务和运动规划结合，以生成长期规划，包括绝对和连续参数的动作。项目网站：https://diffusion-ccsp.github.io/
</details></li>
</ul>
<hr>
<h2 id="eDKM-An-Efficient-and-Accurate-Train-time-Weight-Clustering-for-Large-Language-Models"><a href="#eDKM-An-Efficient-and-Accurate-Train-time-Weight-Clustering-for-Large-Language-Models" class="headerlink" title="eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models"></a>eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00964">http://arxiv.org/abs/2309.00964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsik Cho, Keivan A. Vahid, Qichen Fu, Saurabh Adya, Carlo C Del Mundo, Mohammad Rastegari, Devang Naik, Peter Zatloukal</li>
<li>for: 这个论文的目的是提出一种可以实现高效对称质量调整的轻量级语言模型压缩方法，以便在储存限制的移动设备上实现更快的响应和更好的隐私保护。</li>
<li>methods: 这个方法使用了一种名为“Weight-Clustering”的非线性量化技术，并且使用了一些新的技术来实现可读性和可靠性。</li>
<li>results: 实验结果显示，这个方法可以将预训模型压缩到2.5GB（3bit&#x2F;weight），并且在较宽的语言模型测试 benchmark 上保持了良好的准确性（例如PIQA的准确度为77.7%，Winograde的准确度为66.1%等）。<details>
<summary>Abstract</summary>
Since Large Language Models or LLMs have demonstrated high-quality performance on many complex language tasks, there is a great interest in bringing these LLMs to mobile devices for faster responses and better privacy protection. However, the size of LLMs (i.e., billions of parameters) requires highly effective compression to fit into storage-limited devices. Among many compression techniques, weight-clustering, a form of non-linear quantization, is one of the leading candidates for LLM compression, and supported by modern smartphones. Yet, its training overhead is prohibitively significant for LLM fine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown the state-of-the-art trade-off between compression ratio and accuracy regression, but its large memory complexity makes it nearly impossible to apply to train-time LLM compression. In this paper, we propose a memory-efficient DKM implementation, eDKM powered by novel techniques to reduce the memory footprint of DKM by orders of magnitudes. For a given tensor to be saved on CPU for the backward pass of DKM, we compressed the tensor by applying uniquification and sharding after checking if there is no duplicated tensor previously copied to CPU. Our experimental results demonstrate that \prjname can fine-tune and compress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with the Alpaca dataset by reducing the train-time memory footprint of a decoder layer by 130$\times$, while delivering good accuracy on broader LLM benchmarks (i.e., 77.7% for PIQA, 66.1% for Winograde, and so on).
</details>
<details>
<summary>摘要</summary>
自 Large Language Models (LLMs) 在许多复杂语言任务上表现出色，因此有很大的兴趣将这些 LLMs 带到移动设备上进行更快的响应和更好的隐私保护。然而，LLMs 的大小（即数十亿参数）需要非常有效的压缩以适应存储有限的设备。许多压缩技术之一是 weight-clustering，它是一种非线性量化，并且由现代智能手机支持。然而，它的训练负担是 LLM 精度调整的瓶颈。特别是 Differentiable KMeans Clustering (DKM) 表现出了状态码的质量与精度回归的最佳平衡，但它的内存复杂度使其几乎不可能应用于训练时 LLM 压缩。在这篇论文中，我们提出了一种内存高效的 DKM 实现，即 eDKM，通过新的技术减少 DKM 的内存占用量。为一个给定的矩阵在 CPU 上进行 backwards 的 DKM，我们将矩阵压缩通过应用 uniquification 和 sharding，并且只有在检查到矩阵没有已经被复制到 CPU 的情况下进行压缩。我们的实验结果表明，我们可以使用 eDKM 将预训练的 LLaMA 7B 模型从 12.6 GB 压缩到 2.5 GB (3bit/weight)，在 Alpaca 数据集上进行精度调整，同时在更广泛的 LLM 标准准则（例如 PIQA 77.7%、Winograde 66.1% 等）上保持良好的准确率。
</details></li>
</ul>
<hr>
<h2 id="Visual-Kinematics-Graph-Learning-for-Procedure-agnostic-Instrument-Tip-Segmentation-in-Robotic-Surgeries"><a href="#Visual-Kinematics-Graph-Learning-for-Procedure-agnostic-Instrument-Tip-Segmentation-in-Robotic-Surgeries" class="headerlink" title="Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip Segmentation in Robotic Surgeries"></a>Visual-Kinematics Graph Learning for Procedure-agnostic Instrument Tip Segmentation in Robotic Surgeries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00957">http://arxiv.org/abs/2309.00957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Liu, Yonghao Long, Kai Chen, Cheuk Hei Leung, Zerui Wang, Qi Dou</li>
<li>for:  precisely segmenting surgical instrument tips to enable downstream applications in robotic surgery, such as skill assessment, tool-tissue interaction, and deformation modeling, as well as surgical autonomy.</li>
<li>methods:  a novel visual-kinematics graph learning framework that encodes relational features of instrument parts from both image and kinematics, and a cross-modal contrastive loss to incorporate robust geometric prior from kinematics to image for tip segmentation.</li>
<li>results:  the proposed multi-modal segmentation method significantly outperformed current image-based state-of-the-art approaches, exceeding averagely 11.2% on Dice, on a private paired visual-kinematics dataset including multiple procedures.<details>
<summary>Abstract</summary>
Accurate segmentation of surgical instrument tip is an important task for enabling downstream applications in robotic surgery, such as surgical skill assessment, tool-tissue interaction and deformation modeling, as well as surgical autonomy. However, this task is very challenging due to the small sizes of surgical instrument tips, and significant variance of surgical scenes across different procedures. Although much effort has been made on visual-based methods, existing segmentation models still suffer from low robustness thus not usable in practice. Fortunately, kinematics data from the robotic system can provide reliable prior for instrument location, which is consistent regardless of different surgery types. To make use of such multi-modal information, we propose a novel visual-kinematics graph learning framework to accurately segment the instrument tip given various surgical procedures. Specifically, a graph learning framework is proposed to encode relational features of instrument parts from both image and kinematics. Next, a cross-modal contrastive loss is designed to incorporate robust geometric prior from kinematics to image for tip segmentation. We have conducted experiments on a private paired visual-kinematics dataset including multiple procedures, i.e., prostatectomy, total mesorectal excision, fundoplication and distal gastrectomy on cadaver, and distal gastrectomy on porcine. The leave-one-procedure-out cross validation demonstrated that our proposed multi-modal segmentation method significantly outperformed current image-based state-of-the-art approaches, exceeding averagely 11.2% on Dice.
</details>
<details>
<summary>摘要</summary>
importante任务是正确分 segmentation of surgical instrument tip 是为 robotic surgery 下的下游应用，如技能评估、工具与组织之间的互动和变形模型，以及自动手术。然而，这项任务很有挑战性，因为外科工具的小小大小，以及不同手术过程中的重要差异。虽然很多努力已经在可见基于方法上，但现有的分 segmentation 模型仍然受到低稳定性的影响，因此在实践中不可用。幸好，机械系统的遥感数据可以提供可靠的前提，即工具的位置信息，这些信息不受不同手术类型的影响。为了利用这些多Modal信息，我们提议了一种新的可见-遥感图学学习框架，确定外科工具的末端部分。特别是，我们提出了一种图学学习框架，用于编码外科工具的关系特征从图像和机械数据中。接着，我们设计了一种交叉模式对比损失函数，以实现从机械数据中获得稳定的几何先验。我们在私人的对应视觉-机械数据集上进行了实验，包括多种手术类型，例如肾脏摘除、全部肠脏除、肠脏嵌入和胃部摘除。我们使用了留下一个手术类型的交叉验证，并显示了我们提议的多Modal分 segmentation 方法在对比现有图像基于状态先验的方法时，平均性能提高了11.2%的Dice。
</details></li>
</ul>
<hr>
<h2 id="Bridge-Diffusion-Model-bridge-non-English-language-native-text-to-image-diffusion-model-with-English-communities"><a href="#Bridge-Diffusion-Model-bridge-non-English-language-native-text-to-image-diffusion-model-with-English-communities" class="headerlink" title="Bridge Diffusion Model: bridge non-English language-native text-to-image diffusion model with English communities"></a>Bridge Diffusion Model: bridge non-English language-native text-to-image diffusion model with English communities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00952">http://arxiv.org/abs/2309.00952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanyuan Liu, Dawei Leng, Yuhui Yin</li>
<li>for: 本研究旨在提出一种能够兼顾非英语语言本土特征和英语TTI社区的新型模型结构，以解决英语世界中心训练数据带来的模型偏见问题。</li>
<li>methods: 该模型结构称为“桥接干扰模型”（BDM），具有脊梁支网络结构，能够同时学习非英语语言 semantics 和英语 TTI 社区的 latent space 兼容性。</li>
<li>results: 经验表明，BDM 可以不仅生成准确表达非英语语言 semantics 的图像，还可以与多种英语 TTI 插件相容，如不同的检查点、LoRA、ControlNet、Dreambooth 等等。此外，BDM 还可以同时生成 combine 非英语 native 和英语 native  semantics 的内容，促进文化交流。<details>
<summary>Abstract</summary>
Text-to-Image generation (TTI) technologies are advancing rapidly, especially in the English language communities. However, English-native TTI models inherently carry biases from English world centric training data, which creates a dilemma for development of other language-native TTI models. One common choice is fine-tuning the English-native TTI model with translated samples from non-English communities. It falls short of fully addressing the model bias problem. Alternatively, training non-English language native models from scratch can effectively resolve the English world bias, but diverges from the English TTI communities, thus not able to utilize the strides continuously gaining in the English TTI communities any more. To build non-English language native TTI model meanwhile keep compatability with the English TTI communities, we propose a novel model structure referred as "Bridge Diffusion Model" (BDM). The proposed BDM employs a backbone-branch network structure to learn the non-English language semantics while keep the latent space compatible with the English-native TTI backbone, in an end-to-end manner. The unique advantages of the proposed BDM are that it's not only adept at generating images that precisely depict non-English language semantics, but also compatible with various English-native TTI plugins, such as different checkpoints, LoRA, ControlNet, Dreambooth, and Textual Inversion, etc. Moreover, BDM can concurrently generate content seamlessly combining both non-English native and English-native semantics within a single image, fostering cultural interaction. We verify our method by applying BDM to build a Chinese-native TTI model, whereas the method is generic and applicable to any other language.
</details>
<details>
<summary>摘要</summary>
文本到图像生成（TTI）技术在英语社区中进步快速，但英语原生TTI模型带有英语世界中心训练数据的偏见问题。一种常见的选择是使用翻译后的非英语样本来微调英语原生TTI模型，但这并不能完全解决模型偏见问题。 Alternatively, 从scratch来训练非英语语言原生TTI模型可以有效解决英语世界偏见问题，但是这会与英语TTI社区分离，无法再利用英语TTI社区的成果。为建立非英语语言原生TTI模型，同时保持与英语TTI社区的兼容性，我们提出了一种新的模型结构， referred to as "Bridge Diffusion Model" (BDM)。我们的提议的BDM模型采用了后脊架-分支网络结构，通过练习非英语语言 semantics 来学习非英语语言 semantics，并保持与英语原生TTI脊架兼容的粒子空间，从而实现了端到端的学习。BDM模型具有以下优点：一是能够准确地描述非英语语言 semantics，二是可以与英语原生TTI插件（如不同的检查点、LoRA、ControlNet、Dreambooth、Textual Inversion等）兼容，三是能够同时生成 combining both non-English native and English-native semantics within a single image，激发文化交流。我们验证了我们的方法，通过应用BDM模型来建立一个中文原生TTI模型，而这种方法是通用的，可以应用于任何其他语言。
</details></li>
</ul>
<hr>
<h2 id="From-Specific-to-Generic-Learned-Sorted-Set-Dictionaries-A-Theoretically-Sound-Paradigm-Yelding-Competitive-Data-Structural-Boosters-in-Practice"><a href="#From-Specific-to-Generic-Learned-Sorted-Set-Dictionaries-A-Theoretically-Sound-Paradigm-Yelding-Competitive-Data-Structural-Boosters-in-Practice" class="headerlink" title="From Specific to Generic Learned Sorted Set Dictionaries: A Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in Practice"></a>From Specific to Generic Learned Sorted Set Dictionaries: A Theoretically Sound Paradigm Yelding Competitive Data Structural Boosters in Practice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00946">http://arxiv.org/abs/2309.00946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/globosco/An-implementation-of-Generic-Learned-Static-Sorted-Sets-Dictionaries">https://github.com/globosco/An-implementation-of-Generic-Learned-Static-Sorted-Sets-Dictionaries</a></li>
<li>paper_authors: Domenico Amato, Giosué Lo Bosco, Raffaele Giancarlo</li>
<li>for: 这项研究关注学习数据结构，即机器学习和经典数据结构的交叉领域中的新领域。它有方法学上的重要性和实践上的强大影响。</li>
<li>methods: 我们专注于学习排序字典，即学习排序集合。现有的提议都是特定的，它们可以提高表格搜索过程的时间性能，但只适用于排序的布局，如二分搜索。我们提出了一新的方法，可以补充现有的专门方法，将任何排序集合转化为学习版本。</li>
<li>results: 我们 obtiained several interesting results，包括（a）首个学习优质二分搜索森林，其 mean access time bounded by  Entropy 的概率分布下的访问 Dictionary。（b）首个学习排序集合，在动态情况下，在权衡分析设置下，与经典字典匹配的时间上限。这后者在广泛接受的宇宙大小下。实验部分，软件开发相对复杂，显示了非常有趣的发现，即我们的总结可以生成有效竞争力的学习数据结构加速器，即使与特定的benchmark模型相比。<details>
<summary>Abstract</summary>
This research concerns Learned Data Structures, a recent area that has emerged at the crossroad of Machine Learning and Classic Data Structures. It is methodologically important and with a high practical impact. We focus on Learned Indexes, i.e., Learned Sorted Set Dictionaries. The proposals available so far are specific in the sense that they can boost, indeed impressively, the time performance of Table Search Procedures with a sorted layout only, e.g., Binary Search. We propose a novel paradigm that, complementing known specialized ones, can produce Learned versions of any Sorted Set Dictionary, for instance, Balanced Binary Search Trees or Binary Search on layouts other that sorted, i.e., Eytzinger. Theoretically, based on it, we obtain several results of interest, such as (a) the first Learned Optimum Binary Search Forest, with mean access time bounded by the Entropy of the probability distribution of the accesses to the Dictionary; (b) the first Learned Sorted Set Dictionary that, in the Dynamic Case and in an amortized analysis setting, matches the same time bounds known for Classic Dictionaries. This latter under widely accepted assumptions regarding the size of the Universe. The experimental part, somewhat complex in terms of software development, clearly indicates the nonobvious finding that the generalization we propose can yield effective and competitive Learned Data Structural Booster, even with respect to specific benchmark models.
</details>
<details>
<summary>摘要</summary>
Theoretically, we obtain several interesting results based on this paradigm. For example, we develop the first learned optimum binary search forest, with a mean access time bounded by the entropy of the probability distribution of the accesses to the dictionary. Additionally, we create the first learned sorted set dictionary that, in the dynamic case and in an amortized analysis setting, matches the same time bounds as classic dictionaries, under widely accepted assumptions about the size of the universe.The experimental part of our research, which involved complex software development, surprisingly found that our generalization can yield effective and competitive learned data structural boosters, even compared to specific benchmark models.
</details></li>
</ul>
<hr>
<h2 id="Pressmatch-Automated-journalist-recommendation-for-media-coverage-with-Nearest-Neighbor-search"><a href="#Pressmatch-Automated-journalist-recommendation-for-media-coverage-with-Nearest-Neighbor-search" class="headerlink" title="Pressmatch: Automated journalist recommendation for media coverage with Nearest Neighbor search"></a>Pressmatch: Automated journalist recommendation for media coverage with Nearest Neighbor search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00944">http://arxiv.org/abs/2309.00944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumya Parekh, Jay Patel</li>
<li>for: 这个研究旨在帮助公司发布产品时更好地推广和获得媒体推广，以增加产品的普及度和观众的互动。</li>
<li>methods: 这个研究使用自然语言处理和机器学习技术，推荐适合产品新闻发布的记者，以减少公司需要运作媒体联系和筛选记者的时间和努力。</li>
<li>results: 这借研究发现，使用自然语言处理和机器学习技术可以快速和准确地推荐适合产品新闻发布的记者，从而提高公司发布产品的媒体推广效果。<details>
<summary>Abstract</summary>
Slating a product for release often involves pitching journalists to run stories on your press release. Good media coverage often ensures greater product reach and drives audience engagement for those products. Hence, ensuring that those releases are pitched to the right journalists with relevant interests is crucial, since they receive several pitches daily. Keeping up with journalist beats and curating a media contacts list is often a huge and time-consuming task. This study proposes a model to automate and expedite the process by recommending suitable journalists to run media coverage on the press releases provided by the user.
</details>
<details>
<summary>摘要</summary>
平时发布产品 often involves pitching 新闻工作者来讲述产品的新闻稿。好的媒体报道通常会提高产品的报道覆盖率和驱动产品的听众参与度。因此，确保向正确的新闻工作者发送 pitches 是非常重要的，因为他们每天收到很多 pitches。维护新闻工作者的 beat 和建立媒体联系人名单可以是一项巨大和耗时的任务。这个研究提出了一个模型，用于自动化和加速这个过程，并对用户提供的新闻稿进行推荐适合的新闻工作者。
</details></li>
</ul>
<hr>
<h2 id="Content-Prompting-Modeling-Content-Provider-Dynamics-to-Improve-User-Welfare-in-Recommender-Ecosystems"><a href="#Content-Prompting-Modeling-Content-Provider-Dynamics-to-Improve-User-Welfare-in-Recommender-Ecosystems" class="headerlink" title="Content Prompting: Modeling Content Provider Dynamics to Improve User Welfare in Recommender Ecosystems"></a>Content Prompting: Modeling Content Provider Dynamics to Improve User Welfare in Recommender Ecosystems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00940">http://arxiv.org/abs/2309.00940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddharth Prasad, Martin Mladenov, Craig Boutilier</li>
<li>for: 这篇论文旨在解决信息不均衡问题，帮助内容提供者更好地了解用户需求，并适应用户需求提供内容。</li>
<li>methods: 该论文采用了提示策略，即向内容提供者提供启示或建议，以便他们可以提供满足用户需求的新内容。同时，论文还提出了一种Sequential Prompting Policy，即在提供者的信念、技能和激励下采取一系列的提示策略。</li>
<li>results: 论文通过一种抽象模型和数学分析，证明了这种提示策略可以优化用户社会利益，同时尊重提供者的激励。此外，论文还通过简单的实验证明了这种策略可以提高生态系统的健康度和用户满意度。<details>
<summary>Abstract</summary>
Users derive value from a recommender system (RS) only to the extent that it is able to surface content (or items) that meet their needs/preferences. While RSs often have a comprehensive view of user preferences across the entire user base, content providers, by contrast, generally have only a local view of the preferences of users that have interacted with their content. This limits a provider's ability to offer new content to best serve the broader population. In this work, we tackle this information asymmetry with content prompting policies. A content prompt is a hint or suggestion to a provider to make available novel content for which the RS predicts unmet user demand. A prompting policy is a sequence of such prompts that is responsive to the dynamics of a provider's beliefs, skills and incentives. We aim to determine a joint prompting policy that induces a set of providers to make content available that optimizes user social welfare in equilibrium, while respecting the incentives of the providers themselves. Our contributions include: (i) an abstract model of the RS ecosystem, including content provider behaviors, that supports such prompting; (ii) the design and theoretical analysis of sequential prompting policies for individual providers; (iii) a mixed integer programming formulation for optimal joint prompting using path planning in content space; and (iv) simple, proof-of-concept experiments illustrating how such policies improve ecosystem health and user welfare.
</details>
<details>
<summary>摘要</summary>
用户只有在推荐系统（RS）能够浮现符合他们需求和偏好的内容时，才能获得价值。而RS通常有用户基本库的全面视图，而内容提供者只有与他们内容的用户交互的本地视图。这限制了提供者对整个人口的新内容供应的能力。在这种情况下，我们使用内容提醒策略来缓解信息不均衡。内容提醒是一个提醒或建议，让提供者为RS预测的用户需求而提供新的内容。提醒策略是一个针对提供者的信念、技能和利益的回应序列。我们的目标是找到一个共同的提醒策略，使提供者在均衡下为用户社会福祉产生最佳内容，同时尊重提供者自己的利益。我们的贡献包括：1. RS生态系统抽象模型，包括内容提供者行为，支持内容提醒策略。2. 针对个体提供者的sequential提醒策略的设计和理论分析。3. 内容空间探索路径规划法，用于优化共同提醒策略。4. 简单的证明性实验，说明如何实施内容提醒策略，提高生态系统健康和用户福祉。
</details></li>
</ul>
<hr>
<h2 id="Deep-supervised-hashing-for-fast-retrieval-of-radio-image-cubes"><a href="#Deep-supervised-hashing-for-fast-retrieval-of-radio-image-cubes" class="headerlink" title="Deep supervised hashing for fast retrieval of radio image cubes"></a>Deep supervised hashing for fast retrieval of radio image cubes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00932">http://arxiv.org/abs/2309.00932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Steven Ndung’u, Trienko Grobler, Stefan J. Wijnholds, Dimka Karastoyanova, George Azzopardi</li>
<li>for:  Next-generation radio surveys will result in a large number of serendipitous discoveries, and deep hashing algorithms can be used to efficiently search and retrieve similar images in a large database.</li>
<li>methods:  The paper uses deep hashing algorithms for image retrieval tasks in astronomy, specifically using the Hamming distance between the binary hash of the query image and those of the reference images in the database.</li>
<li>results:  The experimental results achieved a precision of 88.5% using the mean average precision (mAP) metric, demonstrating the capability to search and retrieve similar radio images efficiently and at scale.<details>
<summary>Abstract</summary>
The shear number of sources that will be detected by next-generation radio surveys will be astronomical, which will result in serendipitous discoveries. Data-dependent deep hashing algorithms have been shown to be efficient at image retrieval tasks in the fields of computer vision and multimedia. However, there are limited applications of these methodologies in the field of astronomy. In this work, we utilize deep hashing to rapidly search for similar images in a large database. The experiment uses a balanced dataset of 2708 samples consisting of four classes: Compact, FRI, FRII, and Bent. The performance of the method was evaluated using the mean average precision (mAP) metric where a precision of 88.5\% was achieved. The experimental results demonstrate the capability to search and retrieve similar radio images efficiently and at scale. The retrieval is based on the Hamming distance between the binary hash of the query image and those of the reference images in the database.
</details>
<details>
<summary>摘要</summary>
“Future radio surveys will detect an enormous number of sources, leading to unexpected discoveries. Deep hashing algorithms have been proven efficient in image retrieval tasks in computer vision and multimedia, but their applications in astronomy are limited. In this study, we utilize deep hashing to quickly search for similar images in a large database. The experiment uses a balanced dataset of 2708 samples, including four classes: Compact, FRI, FRII, and Bent. The performance of the method was evaluated using the mean average precision (mAP) metric, achieving a precision of 88.5%. The results demonstrate the ability to efficiently search and retrieve similar radio images at scale, based on the Hamming distance between the binary hash of the query image and those of the reference images in the database.”Here's the breakdown of the translation:* "shear number" 的 Simplified Chinese translation is "巨大的数量" (jùdà de shùliàng)* "next-generation radio surveys" 的 Simplified Chinese translation is "次代 радио探测" (cìdài ràdìo tàncè)* "serendipitous discoveries" 的 Simplified Chinese translation is "偶然发现" (òujiān fāxìan)* "data-dependent deep hashing algorithms" 的 Simplified Chinese translation is "基于数据的深度哈希算法" (jīyú shuòyǔ de shēngrán hǎixī算法)* "computer vision and multimedia" 的 Simplified Chinese translation is "计算机视觉和多媒体" (jìsuànjī zhìguān yǔ duōmédiā)* "limited applications in astronomy" 的 Simplified Chinese translation is "在天文学中的应用受限" (zài tiānwén xué zhī yǐ jí)* "utilize deep hashing to rapidly search for similar images" 的 Simplified Chinese translation is "使用深度哈希快速搜索相似图像" (shǐyòu shēngrán hǎixī suōsòu xiàngsi túxìng)* "balanced dataset of 2708 samples" 的 Simplified Chinese translation is "2708个样本的均衡数据集" (2708 ge yàngbèi de jìngbìng shùliàng)* "four classes: Compact, FRI, FRII, and Bent" 的 Simplified Chinese translation is "四类：紧凑、FRI、FRII、拐型" (sì lèi: jǐnchōng, FRI, FRII, gōngyì)* "mean average precision (mAP) metric" 的 Simplified Chinese translation is "平均精度 (mAP) 指标" (píngjìn jīngdé (mAP) zhǐbǐ)* "achieving a precision of 88.5%" 的 Simplified Chinese translation is "达到88.5%的精度" (dàtuō 88.5% de jīngdé)* "the retrieval is based on the Hamming distance between the binary hash of the query image and those of the reference images in the database" 的 Simplified Chinese translation is "搜索基于图像查询图像的二进制哈希距离" (suōsòu jīyú túxìng túxìng de èrjìn bìngxī hǎixī yuèlü)
</details></li>
</ul>
<hr>
<h2 id="Studying-the-impacts-of-pre-training-using-ChatGPT-generated-text-on-downstream-tasks"><a href="#Studying-the-impacts-of-pre-training-using-ChatGPT-generated-text-on-downstream-tasks" class="headerlink" title="Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks"></a>Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05668">http://arxiv.org/abs/2309.05668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarthak Anand</li>
<li>for: 本研究的目的是调查人工文本在语言模型预训练阶段的影响。</li>
<li>methods: 我们使用了RoBERTa和ChatGPT两个语言模型，对这两个模型进行了比较分析，并对其在三个下游任务中的表现进行评估，同时也对模型的性别偏见进行了评估。</li>
<li>results: 我们的实验结果表明，在预训练阶段使用人工文本不会对语言模型在下游任务中的表现产生显著影响，也不会导致模型的性别偏见增加。<details>
<summary>Abstract</summary>
In recent times, significant advancements have been witnessed in the field of language models, particularly with the emergence of Large Language Models (LLMs) that are trained on vast amounts of data extracted from internet archives. These LLMs, such as ChatGPT, have become widely accessible, allowing users to generate text for various purposes including articles, essays, jokes, and poetry. Given that LLMs are trained on a diverse range of text sources, encompassing platforms like Reddit and Twitter, it is foreseeable that future training datasets will also incorporate text generated by previous iterations of the models themselves. In light of this development, our research aims to investigate the influence of artificial text in the pre-training phase of language models. Specifically, we conducted a comparative analysis between a language model, RoBERTa, pre-trained using CNN/DailyMail news articles, and ChatGPT, which employed the same articles for its training and evaluated their performance on three downstream tasks as well as their potential gender bias, using sentiment analysis as a metric. Through a series of experiments, we demonstrate that the utilization of artificial text during pre-training does not have a significant impact on either the performance of the models in downstream tasks or their gender bias. In conclusion, our findings suggest that the inclusion of text generated by LLMs in their own pre-training process does not yield substantial effects on the subsequent performance of the models in downstream tasks or their potential gender bias.
</details>
<details>
<summary>摘要</summary>
In light of this development, our research aims to investigate the influence of artificial text in the pre-training phase of language models. Specifically, we conducted a comparative analysis between a language model, RoBERTa, pre-trained using CNN/DailyMail news articles, and ChatGPT, which employed the same articles for its training, and evaluated their performance on three downstream tasks as well as their potential gender bias, using sentiment analysis as a metric.Through a series of experiments, we found that the utilization of artificial text during pre-training does not have a significant impact on either the performance of the models in downstream tasks or their gender bias. In conclusion, our findings suggest that the inclusion of text generated by LLMs in their own pre-training process does not yield substantial effects on the subsequent performance of the models in downstream tasks or their potential gender bias.
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Graph-Embeddings-for-Multi-Lingual-Structured-Representations-of-Radiology-Reports"><a href="#Knowledge-Graph-Embeddings-for-Multi-Lingual-Structured-Representations-of-Radiology-Reports" class="headerlink" title="Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports"></a>Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00917">http://arxiv.org/abs/2309.00917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tjvsonsbeek/knowledge_graphs_for_radiology_reports">https://github.com/tjvsonsbeek/knowledge_graphs_for_radiology_reports</a></li>
<li>paper_authors: Tom van Sonsbeek, Xiantong Zhen, Marcel Worring</li>
<li>for: 这个研究旨在开发一个轻量级的图形基于嵌入方法，以便更好地理解并分析医疗报告。</li>
<li>methods: 这个方法利用医疗报告的结构和成分，并与多种语言的医疗词汇知识库（SNOMED CT）进行连结。从而生成一个具有更好的理解和跨语言传递能力的图形嵌入。</li>
<li>results: 研究表明，这个图形嵌入可以更好地捕捉医疗报告中的关系性，并且在疾病分类和影像分类任务中表现出色，比BERT模型更好，且具有较小的模型大小和训练数据需求。此外，这个方法还可以跨语言进行应用。<details>
<summary>Abstract</summary>
The way we analyse clinical texts has undergone major changes over the last years. The introduction of language models such as BERT led to adaptations for the (bio)medical domain like PubMedBERT and ClinicalBERT. These models rely on large databases of archived medical documents. While performing well in terms of accuracy, both the lack of interpretability and limitations to transfer across languages limit their use in clinical setting. We introduce a novel light-weight graph-based embedding method specifically catering radiology reports. It takes into account the structure and composition of the report, while also connecting medical terms in the report through the multi-lingual SNOMED Clinical Terms knowledge base. The resulting graph embedding uncovers the underlying relationships among clinical terms, achieving a representation that is better understandable for clinicians and clinically more accurate, without reliance on large pre-training datasets. We show the use of this embedding on two tasks namely disease classification of X-ray reports and image classification. For disease classification our model is competitive with its BERT-based counterparts, while being magnitudes smaller in size and training data requirements. For image classification, we show the effectiveness of the graph embedding leveraging cross-modal knowledge transfer and show how this method is usable across different languages.
</details>
<details>
<summary>摘要</summary>
医学文本分析方法在最近几年内经历了重大变革。BERT语言模型的引入对医学领域的PubMedBERT和ClinicalBERT进行了适应。这些模型依靠大量储存的医学文献库。虽然在准确性方面表现良好，但lack of interpretability和语言转移限制使其在临床设置中无法使用。我们介绍了一种新的轻量级图 embedding方法，专门针对医学报告。该方法考虑报告的结构和组成，同时通过多语言的SNOMED临床术语知识库连接医学术语。得到的图 embedding揭示了临床术语之间的下面关系，实现了更好的可读性和临床准确性，不需要大量的预训练数据。我们在疾病分类和图像分类两个任务上使用了这种embedding，并证明了它的效果。在疾病分类任务中，我们的模型与BERT基于模型相比竞争，而且它的大小和训练数据要求都比BERT要小得多。在图像分类任务中，我们利用了图 embedding在不同语言之间的交叉模式知识传递，并证明了这种方法在不同语言上的可用性。
</details></li>
</ul>
<hr>
<h2 id="A-3D-explainability-framework-to-uncover-learning-patterns-and-crucial-sub-regions-in-variable-sulci-recognition"><a href="#A-3D-explainability-framework-to-uncover-learning-patterns-and-crucial-sub-regions-in-variable-sulci-recognition" class="headerlink" title="A 3D explainability framework to uncover learning patterns and crucial sub-regions in variable sulci recognition"></a>A 3D explainability framework to uncover learning patterns and crucial sub-regions in variable sulci recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00903">http://arxiv.org/abs/2309.00903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michail Mamalakis, Heloise de Vareilles, Atheer AI-Manea, Samantha C. Mitchell, Ingrid Arartz, Lynn Egeland Morch-Johnsen, Jane Garrison, Jon Simons, Pietro Lio, John Suckling, Graham Murray</li>
<li>for: 本研究旨在提高人脑MRI图像中的皮层 Sulcal 特征的准确性，以及深度学习网络的解释能力。</li>
<li>methods: 该研究使用了一种新的3D解释框架，将本地解释技术GradCam和SHAP综合使用，并结合维度减少方法。该解释框架为深度学习网络提供了本地和全局的解释，以及类别结果的准确性。</li>
<li>results: 研究发现，在使用TOP-OSLO dataset中的MRI图像中，左半球比右半球更有可能正确地检测皮层 Sulcus（存在或不存在），并且发现了特定但广泛的子区域对每个类别结果做出了重要贡献。此外，研究还启示了不偏袋注意力的注意事项对网络性能的影响。该方法不仅提供了自动化、公正的皮层 Sulcus annotations，还为脑科学领域的进一步探索和调查提供了新的思路。<details>
<summary>Abstract</summary>
Precisely identifying sulcal features in brain MRI is made challenging by the variability of brain folding. This research introduces an innovative 3D explainability frame-work that validates outputs from deep learning networks in their ability to detect the paracingulate sulcus, an anatomical feature that may or may not be present on the frontal medial surface of the human brain. This study trained and tested two networks, amalgamating local explainability techniques GradCam and SHAP with a dimensionality reduction method. The explainability framework provided both localized and global explanations, along with accuracy of classification results, revealing pertinent sub-regions contributing to the decision process through a post-fusion transformation of explanatory and statistical features. Leveraging the TOP-OSLO dataset of MRI acquired from patients with schizophrenia, greater accuracies of paracingulate sulcus detection (presence or absence) were found in the left compared to right hemispheres with distinct, but extensive sub-regions contributing to each classification outcome. The study also inadvertently highlighted the critical role of an unbiased annotation protocol in maintaining network performance fairness. Our proposed method not only offers automated, impartial annotations of a variable sulcus but also provides insights into the broader anatomical variations associated with its presence throughout the brain. The adoption of this methodology holds promise for instigating further explorations and inquiries in the field of neuroscience.
</details>
<details>
<summary>摘要</summary>
通过准确地识别大脑磁共振图像中的 Sulcal 特征，这种研究推出了一个创新的3D解释框架。该框架验证了深度学习网络的输出是否能够检测人脑前 медиаль面上的 paracingulate sulcus，这是一个可能或可能不存在的 анатомиче特征。本研究用了两个网络，其中一个是 GradCam 和 SHAP 的 мест解释技术，另一个是一种维度减少方法。该解释框架提供了 both localized 和 global 解释，以及分类结果的准确性，揭示了在决策过程中重要的相关子区域。使用 TOP-OSLO 数据集，该研究发现在左半球比右半球更高的准确率检测 paracingulate sulcus（存在或缺失）。此外，研究还意外地发现了在左半球和右半球之间的区域差异对于每个分类结果的重要性。此方法不仅提供了自动化、不偏的 sulcus Variable 的注释，还为其存在的各个部分提供了深入的解释。该方法的采用拥有推动更多的 Neuroscience 领域的探索和问题。
</details></li>
</ul>
<hr>
<h2 id="Large-Process-Models-Business-Process-Management-in-the-Age-of-Generative-AI"><a href="#Large-Process-Models-Business-Process-Management-in-the-Age-of-Generative-AI" class="headerlink" title="Large Process Models: Business Process Management in the Age of Generative AI"></a>Large Process Models: Business Process Management in the Age of Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00900">http://arxiv.org/abs/2309.00900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timotheus Kampik, Christian Warmuth, Adrian Rebmann, Ron Agam, Lukas N. P. Egger, Andreas Gerber, Johannes Hoffart, Jonas Kolk, Philipp Herzig, Gero Decker, Han van der Aa, Artem Polyvyanyy, Stefanie Rinderle-Ma, Ingo Weber, Matthias Weidlich</li>
<li>for: 这个论文是为了探讨基于大语言模型（LLM）和其他生成人工智能技术的潜在优势和局限性，以及如何结合这些技术以提高企业转型的效率和深度。</li>
<li>methods: 论文提出了一种基于大语言模型（LLM）和知识基本模型（KBM）的大过程模型（LPM），该模型结合了LLM的相关力和KBM的分析精度和可靠性，以提供更加Context-specific（适应）的过程和商业模型，深入分析和提供改进建议。</li>
<li>results: 论文认为，实施LPM可以减少企业转型所需的时间和努力，同时提供更加深入、更加有效和更加可行的业务转型建议，相比之下传统的 Symbolic 模型。然而，论文也提出了实施LPM的限制和研究挑战。<details>
<summary>Abstract</summary>
The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness. As a framework for contextualizing the potential, as well as the limitations of LLMs and other foundation model-based technologies, we propose the concept of a Large Process Model (LPM) that combines the correlation power of LLMs with the analytical precision and reliability of knowledge-based systems and automated reasoning approaches. LPMs are envisioned to directly utilize the wealth of process management experience that experts have accumulated, as well as process performance data of organizations with diverse characteristics, e.g., regarding size, region, or industry. In this vision, the proposed LPM would allow organizations to receive context-specific (tailored) process and other business models, analytical deep-dives, and improvement recommendations. As such, they would allow to substantially decrease the time and effort required for business transformation, while also allowing for deeper, more impactful, and more actionable insights than previously possible. We argue that implementing an LPM is feasible, but also highlight limitations and research challenges that need to be solved to implement particular aspects of the LPM vision.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）和其他生成人工智能方法的继续成功，强调了大量信息库对于固定符号模型的优势，但也 serves as a proof-point of 隐性和可靠性问题。作为 LLM 和其他基础模型技术的框架，我们提出了大量处理模型（LPM）的概念，该模型结合了 LLM 的相关力和知识基础系统和自动化推理方法的分析精度和可靠性。LPM 可以直接利用专家们积累的过程管理经验和不同特征的组织过程性能数据，例如大小、地区、行业等，以提供Context-specific（特定）的过程和商业模型、深入分析和改进建议。因此，LPM 可以减少企业转型所需的时间和努力，同时提供更深入、更有影响和更可行的发现。我们认为实施 LPM 是可能的，但也存在实现特定方面的限制和研究挑战。
</details></li>
</ul>
<hr>
<h2 id="Regularly-Truncated-M-estimators-for-Learning-with-Noisy-Labels"><a href="#Regularly-Truncated-M-estimators-for-Learning-with-Noisy-Labels" class="headerlink" title="Regularly Truncated M-estimators for Learning with Noisy Labels"></a>Regularly Truncated M-estimators for Learning with Noisy Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00894">http://arxiv.org/abs/2309.00894</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaoboxia/rtm_lnl">https://github.com/xiaoboxia/rtm_lnl</a></li>
<li>paper_authors: Xiaobo Xia, Pengqian Lu, Chen Gong, Bo Han, Jun Yu, Jun Yu, Tongliang Liu</li>
<li>for: 提高学习 WITH 噪音标签的精度和稳定性。</li>
<li>methods: 提出了一种名为Regularly Truncated M-estimators（RTME）的新方法，该方法可以同时解决两个问题：（a）不考虑噪音标签在选择小损失示例中的不良影响；（b）不利用抛弃大损失示例中的可能有用信息。</li>
<li>results: 理论上显示了方法的抗噪音特性，实验结果表明我们的方法可以超越多个基eline，并在各种噪音类型和水平下表现稳定和可靠。<details>
<summary>Abstract</summary>
The sample selection approach is very popular in learning with noisy labels. As deep networks learn pattern first, prior methods built on sample selection share a similar training procedure: the small-loss examples can be regarded as clean examples and used for helping generalization, while the large-loss examples are treated as mislabeled ones and excluded from network parameter updates. However, such a procedure is arguably debatable from two folds: (a) it does not consider the bad influence of noisy labels in selected small-loss examples; (b) it does not make good use of the discarded large-loss examples, which may be clean or have meaningful information for generalization. In this paper, we propose regularly truncated M-estimators (RTME) to address the above two issues simultaneously. Specifically, RTME can alternately switch modes between truncated M-estimators and original M-estimators. The former can adaptively select small-losses examples without knowing the noise rate and reduce the side-effects of noisy labels in them. The latter makes the possibly clean examples but with large losses involved to help generalization. Theoretically, we demonstrate that our strategies are label-noise-tolerant. Empirically, comprehensive experimental results show that our method can outperform multiple baselines and is robust to broad noise types and levels.
</details>
<details>
<summary>摘要</summary>
“ selección de muestras es muy popular en aprendizaje con etiquetas ruidosas. Como las redes profundas aprenden patrones primero, los métodos previos basados en selección de muestras comparten un procedimiento de entrenamiento similar: los ejemplos de pérdida pequeña pueden ser considerados como ejemplos limpios y utilizados para ayudar en la generalización, mientras que los ejemplos de pérdida grande son excluidos de actualizaciones de parámetros de la red. Sin embargo, tal procedimiento es objeto de debate desde dos ángulos: (a) no tiene en cuenta la mala influencia de las etiquetas ruidosas en los ejemplos de pérdida pequeña seleccionados; (b) no utiliza adecuadamente los ejemplos de pérdida grande descartados, que pueden ser limpios o tener información significativa para la generalización. En este artículo, propongo regularmente truncated M-estimators (RTME) para abordar los problemas anteriores de manera simultánea. De manera específica, RTME puede alternar entre modes de estimadores truncados y estimadores originales. Los primeros pueden adaptativamente seleccionar ejemplos de pérdida pequeña sin conocer la tasa de ruido y reducir los efectos colaterales de las etiquetas ruidosas en ellos. Los segundos involucran posibles ejemplos limpios pero con pérdidas grandes para ayudar en la generalización. Teóricamente, demostramos que nuestras estrategias son tolerantes al ruido de etiquetas. Empíricamente, resultados exhaustivos y robustos muestran que nuestro método puede superar multiple baselines y es resistente a tipos y niveles de ruido de etiquetas amplios.”
</details></li>
</ul>
<hr>
<h2 id="Equitable-FL-Federated-Learning-with-Sparsity-for-Resource-Constrained-Environment"><a href="#Equitable-FL-Federated-Learning-with-Sparsity-for-Resource-Constrained-Environment" class="headerlink" title="Equitable-FL: Federated Learning with Sparsity for Resource-Constrained Environment"></a>Equitable-FL: Federated Learning with Sparsity for Resource-Constrained Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00864">http://arxiv.org/abs/2309.00864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indrajeet Kumar Sinha, Shekhar Verma, Krishna Pratap Singh</li>
<li>for: 该论文旨在提出一种适用于有限资源环境的联合学习方法，以便在客户端缺乏资源时仍可进行学习。</li>
<li>methods: 该方法基于lottery ticket假设，逐渐减少模型参数数量，以鼓励有限资源的客户端参与联合学习。</li>
<li>results: 实验结果表明，该方法可以在不同的数据集和环境下减少模型大小，同时保持模型的准确性，并且可以适应不同的客户端资源具有不同的缺省值。<details>
<summary>Abstract</summary>
In Federated Learning, model training is performed across multiple computing devices, where only parameters are shared with a common central server without exchanging their data instances. This strategy assumes abundance of resources on individual clients and utilizes these resources to build a richer model as user's models. However, when the assumption of the abundance of resources is violated, learning may not be possible as some nodes may not be able to participate in the process. In this paper, we propose a sparse form of federated learning that performs well in a Resource Constrained Environment. Our goal is to make learning possible, regardless of a node's space, computing, or bandwidth scarcity. The method is based on the observation that model size viz a viz available resources defines resource scarcity, which entails that reduction of the number of parameters without affecting accuracy is key to model training in a resource-constrained environment. In this work, the Lottery Ticket Hypothesis approach is utilized to progressively sparsify models to encourage nodes with resource scarcity to participate in collaborative training. We validate Equitable-FL on the $MNIST$, $F-MNIST$, and $CIFAR-10$ benchmark datasets, as well as the $Brain-MRI$ data and the $PlantVillage$ datasets. Further, we examine the effect of sparsity on performance, model size compaction, and speed-up for training. Results obtained from experiments performed for training convolutional neural networks validate the efficacy of Equitable-FL in heterogeneous resource-constrained learning environment.
</details>
<details>
<summary>摘要</summary>
在联合学习中，模型训练在多个计算设备之间进行，只是共享参数而不是数据实例。这种策略假设每个客户端都有充足的资源，并利用这些资源建立更加丰富的模型。然而，当假设丰富资源的假设不成立时，学习可能无法进行，因为一些节点可能无法参与过程中。在这篇论文中，我们提出了一种缺省形式的联合学习方法，可以在资源受限环境中进行学习。我们的目标是让学习无论节点的空间、计算或带宽scarce都可以进行。该方法基于参数数量与可用资源的关系，即模型大小与可用资源的定义资源缺乏问题。在这种情况下，我们采用了抽奖票假设方法，以逐步减少模型参数，以鼓励有资源缺乏的节点参与合作训练。我们在$MNIST$, $F-MNIST$, $CIFAR-10$benchmark数据集和$Brain-MRI$数据集以及$PlantVillage$数据集进行了验证。此外，我们还研究了缺省对性能、模型大小压缩和训练速度的影响。实验结果表明，Equitable-FL在多种不同资源环境下进行联合学习时具有有效性。
</details></li>
</ul>
<hr>
<h2 id="Domain-Generalization-via-Balancing-Training-Difficulty-and-Model-Capability"><a href="#Domain-Generalization-via-Balancing-Training-Difficulty-and-Model-Capability" class="headerlink" title="Domain Generalization via Balancing Training Difficulty and Model Capability"></a>Domain Generalization via Balancing Training Difficulty and Model Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00844">http://arxiv.org/abs/2309.00844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xueying Jiang, Jiaxing Huang, Sheng Jin, Shijian Lu</li>
<li>for: 这个研究旨在为 domain generalization (DG) 学习一个可以在未知目标领域中表现良好的模型，并且解决了训练过程中模型和样本的对错问题。</li>
<li>methods: 这个研究使用了两个新的设计，即 MoDify-based Data Augmentation 和 MoDify-based Network Optimization，它们协力地对抗了训练过程中的对错问题，以获得更好的预测性。</li>
<li>results: 这个研究获得了多个 benchark 上的 superior performance，并且可以与现有的方法整合，并且可以在不同的视觉识别任务中使用。<details>
<summary>Abstract</summary>
Domain generalization (DG) aims to learn domain-generalizable models from one or multiple source domains that can perform well in unseen target domains. Despite its recent progress, most existing work suffers from the misalignment between the difficulty level of training samples and the capability of contemporarily trained models, leading to over-fitting or under-fitting in the trained generalization model. We design MoDify, a Momentum Difficulty framework that tackles the misalignment by balancing the seesaw between the model's capability and the samples' difficulties along the training process. MoDify consists of two novel designs that collaborate to fight against the misalignment while learning domain-generalizable models. The first is MoDify-based Data Augmentation which exploits an RGB Shuffle technique to generate difficulty-aware training samples on the fly. The second is MoDify-based Network Optimization which dynamically schedules the training samples for balanced and smooth learning with appropriate difficulty. Without bells and whistles, a simple implementation of MoDify achieves superior performance across multiple benchmarks. In addition, MoDify can complement existing methods as a plug-in, and it is generic and can work for different visual recognition tasks.
</details>
<details>
<summary>摘要</summary>
域名泛化（DG）目标是从一个或多个源领域学习到能够在未看过的目标领域表现好的模型。虽然最近得到了进步，但大多数现有的工作受到模型在训练过程中样本难度与模型能力的不同而受到偏移，导致过拟合或者下降在训练的泛化模型。我们提出了MoDify，一个带动力度的框架，解决这个问题。MoDify包括两个新的设计，协作以适应不同难度水平的样本，从训练过程中学习域名泛化模型。首先是MoDify基于数据增强的设计，利用RGB混淆技术在训练过程中生成适度考虑的训练样本。其次是MoDify基于网络优化的设计，通过动态安排训练样本来保持平稳的学习，适应不同难度水平。无需辉煌的简单实现，MoDify可以在多个 benchmark 上 achieve 优秀表现。此外，MoDify可以补充现有方法，作为插件，并且可以对不同的视觉识别任务进行应用。
</details></li>
</ul>
<hr>
<h2 id="LeanContext-Cost-Efficient-Domain-Specific-Question-Answering-Using-LLMs"><a href="#LeanContext-Cost-Efficient-Domain-Specific-Question-Answering-Using-LLMs" class="headerlink" title="LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs"></a>LeanContext: Cost-Efficient Domain-Specific Question Answering Using LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00841">http://arxiv.org/abs/2309.00841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Adnan Arefeen, Biplob Debnath, Srimat Chakradhar</li>
<li>for: 本研究旨在提高小型企业对大语言模型（LLM）的应用，以提高聊天机器人的能力。</li>
<li>methods: 本研究使用leansContext方法，该方法可以快速提取适用于查询的$k$个关键句。</li>
<li>results: 与基eline相比，leansContext方法可以减少Context的成本，同时保持ROUGE-1分数的稳定性。如果使用免费预训练的LLM-基于摘要器，leansContext还可以进一步提高准确性。<details>
<summary>Abstract</summary>
Question-answering (QA) is a significant application of Large Language Models (LLMs), shaping chatbot capabilities across healthcare, education, and customer service. However, widespread LLM integration presents a challenge for small businesses due to the high expenses of LLM API usage. Costs rise rapidly when domain-specific data (context) is used alongside queries for accurate domain-specific LLM responses. One option is to summarize the context by using LLMs and reduce the context. However, this can also filter out useful information that is necessary to answer some domain-specific queries. In this paper, we shift from human-oriented summarizers to AI model-friendly summaries. Our approach, LeanContext, efficiently extracts $k$ key sentences from the context that are closely aligned with the query. The choice of $k$ is neither static nor random; we introduce a reinforcement learning technique that dynamically determines $k$ based on the query and context. The rest of the less important sentences are reduced using a free open source text reduction method. We evaluate LeanContext against several recent query-aware and query-unaware context reduction approaches on prominent datasets (arxiv papers and BBC news articles). Despite cost reductions of $37.29\%$ to $67.81\%$, LeanContext's ROUGE-1 score decreases only by $1.41\%$ to $2.65\%$ compared to a baseline that retains the entire context (no summarization). Additionally, if free pretrained LLM-based summarizers are used to reduce context (into human consumable summaries), LeanContext can further modify the reduced context to enhance the accuracy (ROUGE-1 score) by $13.22\%$ to $24.61\%$.
</details>
<details>
<summary>摘要</summary>
帮助机器人回答问题（Question-answering，QA）是大型自然语言模型（Large Language Models，LLMs）的重要应用，涵盖医疗、教育和客户服务等领域。然而，广泛的 LLM 集成对小型企业而言是一大挑战，因为 LLM API 使用成本高涨。当用于精度的域pecific数据（context）时，成本会快速增加。一种选择是使用 LLM  SUMMARIZE Context，从而减少context。然而，这也可能会过滤出一些具有响应域pecific queries 的有用信息。在这篇论文中，我们弃用人类SUMMARIZER，转而使用 AI 模型友好的SUMMARY。我们的方法LeanContext，高效地提取了 $k$ 个关键句子，与查询高度相关。 $k$ 的选择不是静态也不是随机的，我们引入了一种强化学习技术，动态确定 $k$ 基于查询和 context。剩下的部分使用一种免费开源的文本减少方法减少。我们对多个最新的查询 aware 和查询无关的context减少方法进行评估，并发现LeanContext可以在成本下降 $37.29\%$ 到 $67.81\%$ 的情况下，ROUGE-1 分数下降只有 $1.41\%$ 到 $2.65\%$ 相比于基线（无 summarization）。此外，如果使用免费预训练 LLM 基于 SUMMARIZER 减少 context（转换为人类可读的摘要），LeanContext 可以进一步修改减少后的 context，提高精度（ROUGE-1 分数） by $13.22\%$ 到 $24.61\%$。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Semi-Supervised-Graph-Learning-for-Enhanced-Diabetic-Retinopathy-Detection"><a href="#Leveraging-Semi-Supervised-Graph-Learning-for-Enhanced-Diabetic-Retinopathy-Detection" class="headerlink" title="Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic Retinopathy Detection"></a>Leveraging Semi-Supervised Graph Learning for Enhanced Diabetic Retinopathy Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00824">http://arxiv.org/abs/2309.00824</a></li>
<li>repo_url: None</li>
<li>paper_authors: D. Dhinakaran, L. Srinivasan, D. Selvaraj, S. M. Udhaya Sankar</li>
<li>for: 这项研究旨在提高 диабетичеRetinopathy（DR）的早期检测和治疗，使用机器学习（ML）技术。</li>
<li>methods: 该研究提出了一种新的半监督图像学习（SSGL）算法，利用标注和无标注数据之间的关系来提高准确性。</li>
<li>results: 研究表明，该算法可以在两个公共可用的数据集上获得显著改进的分类精度、特异性和敏感性，并且具有鲁棒性 against 噪音和异常值。<details>
<summary>Abstract</summary>
Diabetic Retinopathy (DR) is a significant cause of blindness globally, highlighting the urgent need for early detection and effective treatment. Recent advancements in Machine Learning (ML) techniques have shown promise in DR detection, but the availability of labeled data often limits their performance. This research proposes a novel Semi-Supervised Graph Learning SSGL algorithm tailored for DR detection, which capitalizes on the relationships between labelled and unlabeled data to enhance accuracy. The work begins by investigating data augmentation and preprocessing techniques to address the challenges of image quality and feature variations. Techniques such as image cropping, resizing, contrast adjustment, normalization, and data augmentation are explored to optimize feature extraction and improve the overall quality of retinal images. Moreover, apart from detection and diagnosis, this work delves into applying ML algorithms for predicting the risk of developing DR or the likelihood of disease progression. Personalized risk scores for individual patients are generated using comprehensive patient data encompassing demographic information, medical history, and retinal images. The proposed Semi-Supervised Graph learning algorithm is rigorously evaluated on two publicly available datasets and is benchmarked against existing methods. Results indicate significant improvements in classification accuracy, specificity, and sensitivity while demonstrating robustness against noise and outlie rs.Notably, the proposed algorithm addresses the challenge of imbalanced datasets, common in medical image analysis, further enhancing its practical applicability.
</details>
<details>
<summary>摘要</summary>
糖尿病视网膜病 (DR) 是全球主要导致盲视的重要原因，强调了早期发现和有效治疗的急需。 recent advancements in Machine Learning (ML) techniques have shown promise in DR detection, but the availability of labeled data often limits their performance. This research proposes a novel Semi-Supervised Graph Learning (SSGL) algorithm tailored for DR detection, which capitalizes on the relationships between labeled and unlabeled data to enhance accuracy.首先，这项研究 investigate data augmentation and preprocessing techniques to address the challenges of image quality and feature variations. techniques such as image cropping, resizing, contrast adjustment, normalization, and data augmentation are explored to optimize feature extraction and improve the overall quality of retinal images.此外，这项研究不仅仅是 DR 的检测和诊断，还探讨了使用 ML 算法预测糖尿病的发展风险或疾病进程的可能性。通过对患者的全面数据，包括人口统计信息、医疗历史和视网膜图像，生成个性化的风险分数。提出的 Semi-Supervised Graph learning 算法在两个公共可用的数据集上进行了严格的评估，并与现有方法进行了比较。结果表明该算法在分类精度、特异性和敏感性方面具有显著提高，并且在噪音和异常值的情况下具有坚定的稳定性。值得一提的是，提出的算法可以有效地处理医学图像分析中常见的不均衡数据集，进一步提高了其实际应用性。
</details></li>
</ul>
<hr>
<h2 id="Bypassing-the-Simulator-Near-Optimal-Adversarial-Linear-Contextual-Bandits"><a href="#Bypassing-the-Simulator-Near-Optimal-Adversarial-Linear-Contextual-Bandits" class="headerlink" title="Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits"></a>Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00814">http://arxiv.org/abs/2309.00814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haolin Liu, Chen-Yu Wei, Julian Zimmert</li>
<li>for: 解决 adversarial linear contextual bandit problem，loss vectors 完全 adversarially 选择，per-round action set 从固定分布中随机选择。</li>
<li>methods: 不需要 simulator，直接使用 adversarial 搜索，实现 $\widetilde{O}(\sqrt{T})$  regret，同时保持小action set 的计算效率。</li>
<li>results: 在 sleeping bandits 中，解决 Saha et al. [2020] 的开问，存在 $poly(d)\sqrt{T}$ regret 的 polynomials-time 算法，并且可以处理 linear loss 的 additive misspecification error。<details>
<summary>Abstract</summary>
We consider the adversarial linear contextual bandit problem, where the loss vectors are selected fully adversarially and the per-round action set (i.e. the context) is drawn from a fixed distribution. Existing methods for this problem either require access to a simulator to generate free i.i.d. contexts, achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-optimal dependence on the magnitude of the error.
</details>
<details>
<summary>摘要</summary>
我们考虑了对抗线性上下文竞争问题，其中损失 вектор被完全对抗选择，并且每轮动作集（即上下文）是从固定分布中抽出的。现有的方法 either需要 Access to a simulator to generate free i.i.d. contexts, or achieve a sub-optimal regret no better than $\widetilde{O}(T^{\frac{5}{6})$, or are computationally inefficient. We greatly improve these results by achieving a regret of $\widetilde{O}(\sqrt{T})$ without a simulator, while maintaining computational efficiency when the action set in each round is small. In the special case of sleeping bandits with adversarial loss and stochastic arm availability, our result answers affirmatively the open question by Saha et al. [2020] on whether there exists a polynomial-time algorithm with $poly(d)\sqrt{T}$ regret. Our approach naturally handles the case where the loss is linear up to an additive misspecification error, and our regret shows near-optimal dependence on the magnitude of the error.
</details></li>
</ul>
<hr>
<h2 id="RenAIssance-A-Survey-into-AI-Text-to-Image-Generation-in-the-Era-of-Large-Model"><a href="#RenAIssance-A-Survey-into-AI-Text-to-Image-Generation-in-the-Era-of-Large-Model" class="headerlink" title="RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model"></a>RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00810">http://arxiv.org/abs/2309.00810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fengxiang Bie, Yibo Yang, Zhongzhu Zhou, Adam Ghanem, Minjia Zhang, Zhewei Yao, Xiaoxia Wu, Connor Holmes, Pareesa Golnari, David A. Clifton, Yuxiong He, Dacheng Tao, Shuaiwen Leon Song</li>
<li>For: This paper focuses on text-to-image generation (TTI) models that use neural networks to generate high-fidelity images based on text descriptions.* Methods: The paper discusses various types of generative models used for TTI, including diffusion models, which have been shown to be effective in image synthesis and have become the major image decoder used by TTI models. The paper also explores the integration of large language models with TTI models to improve performance.* Results: The paper reports that TTI models have made significant progress in recent years, with the generation results nearly indistinguishable from real-world images. The paper argues that further improvements could be made through the combination of innovative model architectures and prediction enhancement techniques.<details>
<summary>Abstract</summary>
Text-to-image generation (TTI) refers to the usage of models that could process text input and generate high fidelity images based on text descriptions. Text-to-image generation using neural networks could be traced back to the emergence of Generative Adversial Network (GAN), followed by the autoregressive Transformer. Diffusion models are one prominent type of generative model used for the generation of images through the systematic introduction of noises with repeating steps. As an effect of the impressive results of diffusion models on image synthesis, it has been cemented as the major image decoder used by text-to-image models and brought text-to-image generation to the forefront of machine-learning (ML) research. In the era of large models, scaling up model size and the integration with large language models have further improved the performance of TTI models, resulting the generation result nearly indistinguishable from real-world images, revolutionizing the way we retrieval images. Our explorative study has incentivised us to think that there are further ways of scaling text-to-image models with the combination of innovative model architectures and prediction enhancement techniques. We have divided the work of this survey into five main sections wherein we detail the frameworks of major literature in order to delve into the different types of text-to-image generation methods. Following this we provide a detailed comparison and critique of these methods and offer possible pathways of improvement for future work. In the future work, we argue that TTI development could yield impressive productivity improvements for creation, particularly in the context of the AIGC era, and could be extended to more complex tasks such as video generation and 3D generation.
</details>
<details>
<summary>摘要</summary>
文本到图像生成（TTI）是指使用模型可以从文本输入中生成高效精度的图像描述。使用神经网络进行文本到图像生成可以追溯到生成对抗网络的出现，然后是推理转换器。扩散模型是一种广泛使用的生成模型，用于通过系统性地引入噪声来生成图像。由于扩散模型在图像生成方面的出色表现，因此成为了主要的图像解码器，并使文本到图像生成成为机器学习（ML）研究的先锋。在大模型时代，通过增大模型大小和与大语言模型的集成，有效提高了TTI模型的性能，使得生成结果几乎与实际图像无法分辨，革命化了图像检索方式。我们的探索研究让我们认为，可以通过创新的模型架构和预测增强技术来进一步扩展文本到图像模型。我们在这篇评论中分为五个主要部分，详细介绍了主要的文献框架，以便深入探讨不同类型的文本到图像生成方法。接着，我们对这些方法进行了详细比较和批判，并提出了未来工作的可能的改进方向。在未来工作中，我们 argue that TTI的发展可以带来很大的产出效益，特别在AIGC时代，并可以扩展到更复杂的任务，如视频生成和3D生成。
</details></li>
</ul>
<hr>
<h2 id="Value-Kaleidoscope-Engaging-AI-with-Pluralistic-Human-Values-Rights-and-Duties"><a href="#Value-Kaleidoscope-Engaging-AI-with-Pluralistic-Human-Values-Rights-and-Duties" class="headerlink" title="Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties"></a>Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00779">http://arxiv.org/abs/2309.00779</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsor13/kaleido">https://github.com/tsor13/kaleido</a></li>
<li>paper_authors: Taylor Sorensen, Liwei Jiang, Jena Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, John Tasioulas, Yejin Choi</li>
<li>for: The paper aims to improve AI systems’ ability to reflect value pluralism, which is the view that multiple correct values may be held in tension with one another.</li>
<li>methods: The authors introduce ValuePrism, a large-scale dataset of human-written values, rights, and duties, and use GPT-4 to generate contextualized values. They also build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context.</li>
<li>results: The authors show that Kaleido outperforms the teacher GPT-4 in terms of accuracy and broader coverage, and can help explain variability in human decision-making by outputting contrasting values. Additionally, they demonstrate that Kaleido’s representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism.<details>
<summary>Abstract</summary>
Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction.   We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented.   With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.
</details>
<details>
<summary>摘要</summary>
人类价值观是人类决策中不可或缺的一部分。价值多元观是指人们可能同时保持多个正确的价值观（例如，当考虑到为朋友保持好感而做出谎言时，如何均衡诚实和友谊？）。作为统计学学习者，AI系统默认会按照平均值进行适应，这可能会抹平人类价值观的可能性。为了改进AI系统，以更好地反映价值多元观，我们的首要挑战是探索AI系统是否可以模拟人类多元价值观、权利和义务，以及它们之间的交互。我们介绍了ValuePrism，一个大规模的数据集，包含218万个价值观、权利和义务，与31万个人类写作的情况相连。ValuePrism的受过Contextualization的价值观是由GPT-4生成的，并被人类评分员评为高质量91%的时间。我们进行了大规模的研究，邀请来自多个社会和民族背景的 annotators，以了解价值观 representation的多样性。基于ValuePrism，我们构建了Kaleido，一个开源、轻量级、结构化的语言基于多任务模型，可以生成、解释和评估人类价值观、权利和义务在特定情况下的 relevance 和 valence（即支持或反对）。人类更喜欢我们的系统输出的价值观集，认为它们更准确，覆盖率更广。此外，我们还证明了Kaleido可以帮助解释人类决策的变化，输出相互矛盾的价值观。最后，我们表明了Kaleido的表示可以跨越不同的哲学框架和数据集，证明了明确、模块化和可解释的方法对价值多元观具有优势。我们希望通过让人类价值观变得更加明确，使AI系统做出更符合人类价值观的决策。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Feature-Masking-Open-Vocabulary-Vision-Transformer"><a href="#Contrastive-Feature-Masking-Open-Vocabulary-Vision-Transformer" class="headerlink" title="Contrastive Feature Masking Open-Vocabulary Vision Transformer"></a>Contrastive Feature Masking Open-Vocabulary Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00775">http://arxiv.org/abs/2309.00775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dahun Kim, Anelia Angelova, Weicheng Kuo</li>
<li>for: 这篇论文旨在提出一种基于对比特征压缩视Transformer（CFM-ViT）的图像文本预训练方法，用于实现开放词汇对象检测（OVD）中的同时学习图像和区域水平表示。</li>
<li>methods: 该方法结合了压缩隐藏层（MAE）目标到对比学习目标中，以改进表示的地方semantics。此外，我们还引入了随机dropoutPositional Embedding（PED）来 Address scale variation between image-text pretraining and detection finetuning。</li>
<li>results: 在LVIS开放词汇检测标准benchmark上，CFM-ViT实现了33.9 AP$r$的最佳记录，比最佳方法高7.6分。此外，CFM-ViT还实现了更好的零aser检测传递性和图像水平表示。<details>
<summary>Abstract</summary>
We present Contrastive Feature Masking Vision Transformer (CFM-ViT) - an image-text pretraining methodology that achieves simultaneous learning of image- and region-level representation for open-vocabulary object detection (OVD). Our approach combines the masked autoencoder (MAE) objective into the contrastive learning objective to improve the representation for localization tasks. Unlike standard MAE, we perform reconstruction in the joint image-text embedding space, rather than the pixel space as is customary with the classical MAE method, which causes the model to better learn region-level semantics. Moreover, we introduce Positional Embedding Dropout (PED) to address scale variation between image-text pretraining and detection finetuning by randomly dropping out the positional embeddings during pretraining. PED improves detection performance and enables the use of a frozen ViT backbone as a region classifier, preventing the forgetting of open-vocabulary knowledge during detection finetuning. On LVIS open-vocabulary detection benchmark, CFM-ViT achieves a state-of-the-art 33.9 AP$r$, surpassing the best approach by 7.6 points and achieves better zero-shot detection transfer. Finally, CFM-ViT acquires strong image-level representation, outperforming the state of the art on 8 out of 12 metrics on zero-shot image-text retrieval benchmarks.
</details>
<details>
<summary>摘要</summary>
我们提出了对比特征掩码视TRANSFORMER（CFM-ViT）方法，用于开放词汇 объек检测（OVD）的图像-文本预训练。我们的方法将掩码自动编码（MAE）目标函数与对比学习目标函数结合在一起，以提高定位任务的表示。与标准MAE不同的是，我们在图像-文本嵌入空间进行重建，而不是在像素空间进行重建，这使得模型更好地学习区域水平 semantics。此外，我们引入了随机dropout的位置嵌入（PED）来解决图像-文本预训练和检测finetuning之间的尺度变化问题。PED通过随机dropout位置嵌入来提高检测性能，并使得使用冻结的ViT背景作为区域分类器，以避免在检测finetuning过程中忘记开放词汇知识。在LVIS开放词汇检测数据集上，CFM-ViT实现了33.9 AP$r$的状态ethe-art成绩，比最佳方法提高7.6个点，并在零配置检测转移中实现了更好的检测性能。此外，CFM-ViT获得了图像水平表示的强大表示能力，在零配置图像-文本检索数据集上超过了状态艺术的8个 из 12个维度。
</details></li>
</ul>
<hr>
<h2 id="Bias-and-Fairness-in-Large-Language-Models-A-Survey"><a href="#Bias-and-Fairness-in-Large-Language-Models-A-Survey" class="headerlink" title="Bias and Fairness in Large Language Models: A Survey"></a>Bias and Fairness in Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00770">http://arxiv.org/abs/2309.00770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/i-gallegos/fair-llm-benchmark">https://github.com/i-gallegos/fair-llm-benchmark</a></li>
<li>paper_authors: Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, Nesreen K. Ahmed</li>
<li>for: 这 paper 的目的是提供一个完整的survey of bias evaluation and mitigation techniques for large language models (LLMs), 以便研究者和实践者可以更好地理解和防止 LLMS 中的偏见的传播。</li>
<li>methods: 这 paper 使用了三种分类法来描述 bias evaluation 和 mitigation techniques：一种是 metrics 的分类，另一种是 datasets 的分类，第三种是 mitigation techniques 的分类。这些分类法可以帮助研究者和实践者更好地理解和选择适合的方法。</li>
<li>results: 这 paper 的结果是一个完整的survey of recent research on bias evaluation and mitigation techniques for LLMs，包括了不同类型的 metrics、datasets 和 mitigation techniques，以及它们之间的关系和交互。这个survey 可以帮助研究者和实践者更好地理解和防止 LLMS 中的偏见。<details>
<summary>Abstract</summary>
Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this paper, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly-available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLMs）的快速进步使得处理、理解和生成人类语言的能力得到了进一步的提高，并在社会圈中得到了加强。然而，这些模型可以学习、延续和增强社会偏见。在这篇论文中，我们提供了大语言模型偏见评估和降低技术的全面评论。我们首先将社会偏见和公平在自然语言处理中进行了整合、正式化和扩展，并定义了不同类型的危害和公平的多种要求。然后，我们提出了三种直观的分类，即评估метри克和数据集分类，以及降低技术分类。我们的第一个分类是评估метри克分类，它将评估数据集和模型之间的关系解决，并将评估 метри克分为模型层次、字符级别和生成文本层次。我们的第二个分类是数据集分类，它将数据集分为对称输入或提示，并标识目标危害和社会群体。我们还发布了一份总结公共可用数据集的文件，以便更好地访问。我们的第三个分类是降低技术分类，它将降低方法分为预处理、训练、内部处理和后处理，并在每个子类别中列出了研究趋势。最后，我们 indentified了未来工作中的一些问题和挑战。通过汇总一系列最近的研究成果，我们希望通过这篇文章，为研究人员和实践者提供一份清晰的指南，以便更好地理解和预防 LLMS 中的偏见传播。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.AI_2023_09_02/" data-id="clpxp03ud0038fm882ecq50w9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/02/cs.CL_2023_09_02/" class="article-date">
  <time datetime="2023-09-02T11:00:00.000Z" itemprop="datePublished">2023-09-02</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/02/cs.CL_2023_09_02/">cs.CL - 2023-09-02</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ModelScope-Agent-Building-Your-Customizable-Agent-System-with-Open-source-Large-Language-Models"><a href="#ModelScope-Agent-Building-Your-Customizable-Agent-System-with-Open-source-Large-Language-Models" class="headerlink" title="ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models"></a>ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00986">http://arxiv.org/abs/2309.00986</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/modelscope/modelscope-agent">https://github.com/modelscope/modelscope-agent</a></li>
<li>paper_authors: Chenliang Li, Hehong Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji Zhang, Fei Huang, Jingren Zhou</li>
<li>for: 这种研究的目的是为了开发一种通用的智能代理框架，让大型自然语言模型（LLMs）具备工具使用能力，以完成复杂任务。</li>
<li>methods: 该研究使用了开源的 LLMs 作为控制器，并提供了一个用户友好的系统库，可以自定义引擎设计以支持模型训练在多个开源 LLMs 上，同时允许在一起融合模型 API 和常见 API。</li>
<li>results: 研究提出了一个涵盖工具使用数据收集、工具检索、工具注册、内存控制、自定义模型训练和评估的框架，以帮助 LLMs 具备工具使用能力。此外，还展示了一个基于 ModelScope-Agent 框架的实际应用程序——ModelScopeGPT，可以连接多个开源 LLMs 和上千个公共 AI 模型，以及本地化社区知识。<details>
<summary>Abstract</summary>
Large language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior. To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent framework that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs. In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers. It provides a user-friendly system library, with customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way. To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning over tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications. Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope. The ModelScope-Agent library\footnote{https://github.com/modelscope/modelscope-agent} and online demo\footnote{https://modelscope.cn/studios/damo/ModelScopeGPT/summary} are now publicly available.
</details>
<details>
<summary>摘要</summary>
带有强大语言模型（LLM）的大型语言模型在最近的几年内已经展现出了人类意图理解、逻辑推理和规划行为的强大能力。为了更好地利用LLM完成复杂任务，现在有一个增长的趋势是建立一个具有工具使用能力的代理框架，将LLM与大量外部API集成起来。在这项工作中，我们介绍了ModelScope-Agent，一个通用和可定制的代理框架，基于开源LLM控制器。它提供了用户友好的系统库，可以自定义引擎设计，以支持模型训练在多个开源LLM上，同时也可以快速集成模型API和常见API。为了让LLM具备工具使用能力，我们提出了一个涵盖工具使用数据收集、工具检索、工具注册、内存控制、定制化模型训练和评估的框架。最后，我们展示了ModelScopeGPT，一个基于ModelScope-Agent框架的现实世界智能助手，可以连接多个开源LLM和超过1000个公共AI模型，并将本地化社区知识集成到ModelScope中。ModelScope-Agent库（<https://github.com/modelscope/modelscope-agent>）和在线示例（<https://modelscope.cn/studios/damo/ModelScopeGPT/summary>）现在都已经公开available。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Text-Representation"><a href="#Multilingual-Text-Representation" class="headerlink" title="Multilingual Text Representation"></a>Multilingual Text Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00949">http://arxiv.org/abs/2309.00949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TheBauwssss/TimeInWords">https://github.com/TheBauwssss/TimeInWords</a></li>
<li>paper_authors: Fahim Faisal</li>
<li>for: 本研究旨在探讨现代自然语言处理（NLP）技术的发展，尤其是大量多语言模型在100种语言以上执行任务的可能性。</li>
<li>methods: 本研究使用了现代语言模型，从一元化表示法开始，能够实现自然语言理解、通用常识逻辑和问答等任务，同时捕捉文本语法和 semantics。</li>
<li>results: 研究发现，现代语言模型可以在低资源 диаLECTS 上进行竞争性的表现，并且可以拓展到未知语言边界。然而，要确保文本的一致表示，还需要解决一些问题，以实现语言和 Speakers 之间的一致模型空间。<details>
<summary>Abstract</summary>
Modern NLP breakthrough includes large multilingual models capable of performing tasks across more than 100 languages. State-of-the-art language models came a long way, starting from the simple one-hot representation of words capable of performing tasks like natural language understanding, common-sense reasoning, or question-answering, thus capturing both the syntax and semantics of texts. At the same time, language models are expanding beyond our known language boundary, even competitively performing over very low-resource dialects of endangered languages. However, there are still problems to solve to ensure an equitable representation of texts through a unified modeling space across language and speakers. In this survey, we shed light on this iterative progression of multilingual text representation and discuss the driving factors that ultimately led to the current state-of-the-art. Subsequently, we discuss how the full potential of language democratization could be obtained, reaching beyond the known limits and what is the scope of improvement in that space.
</details>
<details>
<summary>摘要</summary>
现代NLP技术发展包括大量多语言模型，可以在多于100种语言上进行任务。当前的语言模型已经很 longue distance，从简单的一个热点表示单词开始，可以完成自然语言理解、常识逻辑和问答等任务，同时捕捉文本的语法和 semantics。然而，还有很多问题需要解决，以确保文本在多语言空间中具有一致的表示空间，并且让所有语言和发音者都有平等的表达机会。在这份报告中，我们将详细介绍这一趋势的迭代发展，并讨论驱动这一进步的因素。后续，我们将讨论如何实现语言 демокра化的全部潜力，超越已知的限制，以及这一空间中的可进步范围。
</details></li>
</ul>
<hr>
<h2 id="BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing"><a href="#BLSP-Bootstrapping-Language-Speech-Pre-training-via-Behavior-Alignment-of-Continuation-Writing" class="headerlink" title="BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing"></a>BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00916">http://arxiv.org/abs/2309.00916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwang621/blsp">https://github.com/cwang621/blsp</a></li>
<li>paper_authors: Chen Wang, Minpeng Liao, Zhongqiang Huang, Jinliang Lu, Junhong Wu, Yuchen Liu, Chengqing Zong, Jiajun Zhang</li>
<li>for: 该论文旨在扩展大语言模型（LLM）的语言能力到语音频谱上，解决模态对齐问题。</li>
<li>methods: 该论文提出了一种基于行为对齐的语音频谱预训练方法（BLSP），通过学习一个轻量级的模态适配器，使LLM在语音和文本两个模式下 exhibit 同样的生成行为。</li>
<li>results: 该论文实现了将 LLM 的语言能力扩展到语音频谱上，可以实现语音识别、语音翻译、语音理解和语音对话，甚至在零shot cross-lingual scenarios 下。<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) has sparked significant interest in extending their remarkable language capabilities to speech. However, modality alignment between speech and text still remains an open problem. Current solutions can be categorized into two strategies. One is a cascaded approach where outputs (tokens or states) of a separately trained speech recognition system are used as inputs for LLMs, which limits their potential in modeling alignment between speech and text. The other is an end-to-end approach that relies on speech instruction data, which is very difficult to collect in large quantities. In this paper, we address these issues and propose the BLSP approach that Bootstraps Language-Speech Pre-training via behavior alignment of continuation writing. We achieve this by learning a lightweight modality adapter between a frozen speech encoder and an LLM, ensuring that the LLM exhibits the same generation behavior regardless of the modality of input: a speech segment or its transcript. The training process can be divided into two steps. The first step prompts an LLM to generate texts with speech transcripts as prefixes, obtaining text continuations. In the second step, these continuations are used as supervised signals to train the modality adapter in an end-to-end manner. We demonstrate that this straightforward process can extend the capabilities of LLMs to speech, enabling speech recognition, speech translation, spoken language understanding, and speech conversation, even in zero-shot cross-lingual scenarios.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的出现引起了很大的关注，它们的语言能力可以扩展到语音领域。然而，语音和文本之间的模式匹配仍然是一个开放的问题。现有的解决方案可以分为两种策略：一种是采用分解approach，在 separately 训练的语音识别系统输出（token或状态）作为 LLMS 的输入，这会限制其在模式匹配方面的潜力。另一种是以端到端方式进行，它 rely 于语音指令数据，但这些数据难以在大量收集。在这篇论文中，我们解决这些问题，并提出了 BLSP 方法，即通过行为对齐来启动语言-语音预训练。我们通过学习一个轻量级的模式适配器，使 LLMS 在语音段和其转录之间 exhibit 同样的生成行为。训练过程可以分为两步。第一步是让 LLMS 使用语音转录作为前缀，生成文本。第二步是使用这些文本继续进行练习，以train 模式适配器。我们示示这个简单的过程可以扩展 LLMS 的能力到语音领域，实现语音识别、语音翻译、语音理解和语音对话，甚至在零aser 跨语言enario 中。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Transformer’s-Ability-to-Learn-Mildly-Context-Sensitive-Languages"><a href="#Evaluating-Transformer’s-Ability-to-Learn-Mildly-Context-Sensitive-Languages" class="headerlink" title="Evaluating Transformer’s Ability to Learn Mildly Context-Sensitive Languages"></a>Evaluating Transformer’s Ability to Learn Mildly Context-Sensitive Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00857">http://arxiv.org/abs/2309.00857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunjie Wang, Shane Steinert-Threlkeld</li>
<li>for: 这些研究检验了Transformer模型在模型自然语言方面的能力，以及它们是否能够学习一些轻度上下文敏感的语言。</li>
<li>methods: 这些研究使用了Transformer模型，并测试了它们在不同复杂度的语言上的能力。</li>
<li>results: 研究发现，Transformer模型在已经看过的数据上能够泛化良好，但在长串上的推断能力较差，而LSTM模型在这个方面表现更好。分析还显示，Transformer模型学习了自我关注 patrerns和表示，这些 patrerns和表示可能帮助模型解决语言。<details>
<summary>Abstract</summary>
Despite that Transformers perform well in NLP tasks, recent studies suggest that self-attention is theoretically limited in learning even some regular and context-free languages. These findings motivated us to think about their implications in modeling natural language, which is hypothesized to be mildly context-sensitive. We test Transformer's ability to learn a variety of mildly context-sensitive languages of varying complexities, and find that they generalize well to unseen in-distribution data, but their ability to extrapolate to longer strings is worse than that of LSTMs. Our analyses show that the learned self-attention patterns and representations modeled dependency relations and demonstrated counting behavior, which may have helped the models solve the languages.
</details>
<details>
<summary>摘要</summary>
尽管变换器在自然语言处理（NLP）任务中表现良好，但 latest studies 表明自注意力在学习一些常见和 context-free 语言方面存在理论上的限制。这些发现使我们思考自然语言模型化的可能性，自然语言被假设为有些 context-sensitive。我们测试 transformer 能够学习不同复杂程度的 mildly context-sensitive 语言，并发现它们在未seen 数据上具有良好的泛化能力，但在更长的字串上具有更差的推理能力，与 LSTM 模型相比。我们的分析表明 transformer 模型中学习的自注意力模式和表示方式可以模型依赖关系和 counting 行为，可能有助于模型解决语言。
</details></li>
</ul>
<hr>
<h2 id="LinkTransformer-A-Unified-Package-for-Record-Linkage-with-Transformer-Language-Models"><a href="#LinkTransformer-A-Unified-Package-for-Record-Linkage-with-Transformer-Language-Models" class="headerlink" title="LinkTransformer: A Unified Package for Record Linkage with Transformer Language Models"></a>LinkTransformer: A Unified Package for Record Linkage with Transformer Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.00789">http://arxiv.org/abs/2309.00789</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dell-research-harvard/linktransformer">https://github.com/dell-research-harvard/linktransformer</a></li>
<li>paper_authors: Abhishek Arora, Melissa Dell</li>
<li>For: The paper aims to improve record linkage in noisy datasets using large language models (LLMs) and make it more accessible to users who are familiar with popular string matching packages like R and Stata.* Methods: The paper proposes an open-source package called LinkTransformer that treats record linkage as a text retrieval problem and uses transformer LLMs to perform record linkage. The package includes a rich repository of pre-trained transformer semantic similarity models for multiple languages and supports easy integration of any transformer language model from Hugging Face or OpenAI.* Results: The paper claims that LinkTransformer can perform record linkage with high accuracy and supports standard functionality such as blocking and linking on multiple noisy fields. It also includes comprehensive tools for efficient model tuning and makes it easy for users to contribute their custom-trained models to its model hub.<details>
<summary>Abstract</summary>
Linking information across sources is fundamental to a variety of analyses in social science, business, and government. While large language models (LLMs) offer enormous promise for improving record linkage in noisy datasets, in many domains approximate string matching packages in popular softwares such as R and Stata remain predominant. These packages have clean, simple interfaces and can be easily extended to a diversity of languages. Our open-source package LinkTransformer aims to extend the familiarity and ease-of-use of popular string matching methods to deep learning. It is a general purpose package for record linkage with transformer LLMs that treats record linkage as a text retrieval problem. At its core is an off-the-shelf toolkit for applying transformer models to record linkage with four lines of code. LinkTransformer contains a rich repository of pre-trained transformer semantic similarity models for multiple languages and supports easy integration of any transformer language model from Hugging Face or OpenAI. It supports standard functionality such as blocking and linking on multiple noisy fields. LinkTransformer APIs also perform other common text data processing tasks, e.g., aggregation, noisy de-duplication, and translation-free cross-lingual linkage. Importantly, LinkTransformer also contains comprehensive tools for efficient model tuning, to facilitate different levels of customization when off-the-shelf models do not provide the required accuracy. Finally, to promote reusability, reproducibility, and extensibility, LinkTransformer makes it easy for users to contribute their custom-trained models to its model hub. By combining transformer language models with intuitive APIs that will be familiar to many users of popular string matching packages, LinkTransformer aims to democratize the benefits of LLMs among those who may be less familiar with deep learning frameworks.
</details>
<details>
<summary>摘要</summary>
连结资讯 Across ources 是社会科学、商业和政府中许多分析的基本步骤。 although large language models (LLMs) 在复杂数据中提供了巨大的推荐，在许多领域中， approximate string matching 套件在 популяр的软件such as R 和 Stata 中仍然占主导地位。这些套件有clean、简单的接口，并可以轻松扩展到多种语言。我们的开源套件 LinkTransformer 目标是将受欢迎的字串匹配方法和深度学习结合在一起，以提供一个易用的字串匹配解决方案。它的核心是一个可以在四行程式码中应用transformer模型的工具组。LinkTransformer 包含了多种语言的预训transformer对偶性模型，并支持轻松地 интеграble任何transformer语言模型。它支持标准的功能，例如封页和联结多个噪音字段。LinkTransformer API 还可以进行其他常见的文本数据处理任务，例如聚合、噪音除除损和无需翻译的跨语言联结。更重要的是，LinkTransformer 还包含了详细的模型调整工具，以便在不同的粒度上进行自定义，当Off-the-shelf模型不提供所需的精度时。最后，为了促进再利用、重现性和扩展性，LinkTransformer 让用户可以轻松地发布自己的自定义模型。通过结合transformer语言模型和对多数使用 string matching 套件的用户而且 familier的 APIs，LinkTransformer 目标是将LLMs 的好处传播到那些可能不熟悉深度学习框架的人。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/02/cs.CL_2023_09_02/" data-id="clpxp03wn00b2fm88gaet1wtu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/57/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><a class="page-number" href="/page/57/">57</a><span class="page-number current">58</span><a class="page-number" href="/page/59/">59</a><a class="page-number" href="/page/60/">60</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/59/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
