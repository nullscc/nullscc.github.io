
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/58/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.SD_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T15:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.SD_2023_08_17/">cs.SD - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features"><a href="#Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features" class="headerlink" title="Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features"></a>Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09042">http://arxiv.org/abs/2308.09042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarsana Reddy Kadiri, Manila Kodali, Paavo Alku</li>
<li>for: 这个研究旨在提出一种新的评估parkinson病（PD）严重程度的对象方法，以提高诊断和治疗的效果。</li>
<li>methods: 该研究使用了单频 filtering（SFF）方法，从而 derivation two sets of novel features：(1) SFF cepstral coefficients（SFFCC）和 (2) MFCCs from SFF（MFCC-SFF）。SFF 方法可以提供更高的spectro-temporal resolution，而且在三种说话任务（vowel、sentence、text reading）中都表现出了更好的效果。</li>
<li>results: 实验结果表明，提出的特征比普通的MFCC特征更高，在三种说话任务中都达到了5.8%、7.0%和2.4%的提升。<details>
<summary>Abstract</summary>
Developing objective methods for assessing the severity of Parkinson's disease (PD) is crucial for improving the diagnosis and treatment. This study proposes two sets of novel features derived from the single frequency filtering (SFF) method: (1) SFF cepstral coefficients (SFFCC) and (2) MFCCs from the SFF (MFCC-SFF) for the severity classification of PD. Prior studies have demonstrated that SFF offers greater spectro-temporal resolution compared to the short-time Fourier transform. The study uses the PC-GITA database, which includes speech of PD patients and healthy controls produced in three speaking tasks (vowels, sentences, text reading). Experiments using the SVM classifier revealed that the proposed features outperformed the conventional MFCCs in all three speaking tasks. The proposed SFFCC and MFCC-SFF features gave a relative improvement of 5.8% and 2.3% for the vowel task, 7.0% & 1.8% for the sentence task, and 2.4% and 1.1% for the read text task, in comparison to MFCC features.
</details>
<details>
<summary>摘要</summary>
发展客观的评估parkinson病（PD）严重度的方法是至关重要的，以提高诊断和治疗的效果。这项研究提出了两个新的特征集：（1）单频范围滤波（SFF）cepstral coefficient（SFFCC）和（2）基于SFF的Mel-frequency cepstral coefficients（MFCC-SFF），用于分类PD严重度。先前的研究表明，SFF比短时间傅立叶 transform（STFT）具有更高的spectro-temporal分辨率。这项研究使用了PC-GITA数据库，包括PD患者和健康控制人员在三种说话任务（元音、句子和文本读取）中的语音。实验使用SVM分类器显示，提出的特征比折衔MFCC更高，在三种说话任务中都有显著提高。SFFCC和MFCC-SFF特征在元音任务中增加了5.8%和2.3%，在句子任务中增加了7.0%和1.8%，在文本读取任务中增加了2.4%和1.1%，相比MFCC特征。
</details></li>
</ul>
<hr>
<h2 id="Home-monitoring-for-frailty-detection-through-sound-and-speaker-diarization-analysis"><a href="#Home-monitoring-for-frailty-detection-through-sound-and-speaker-diarization-analysis" class="headerlink" title="Home monitoring for frailty detection through sound and speaker diarization analysis"></a>Home monitoring for frailty detection through sound and speaker diarization analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08985">http://arxiv.org/abs/2308.08985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yannis Tevissen, Dan Istrate, Vincent Zalc, Jérôme Boudy, Gérard Chollet, Frédéric Petitpont, Sami Boutamine</li>
<li>for: 这篇论文是为了研究如何通过人类日常生活声音识别和语音存在检测来实现可靠和隐私保护的家庭监测系统。</li>
<li>methods: 这篇论文使用了最新的声音处理和 speaker diarization 技术来改进现有的嵌入式系统。</li>
<li>results: 研究发现，使用 DNN 基本方法可以提高性能约100%。<details>
<summary>Abstract</summary>
As the French, European and worldwide populations are aging, there is a strong interest for new systems that guarantee a reliable and privacy preserving home monitoring for frailty prevention. This work is a part of a global environmental audio analysis system which aims to help identification of Activities of Daily Life (ADL) through human and everyday life sounds recognition, speech presence and number of speakers detection. The focus is made on the number of speakers detection. In this article, we present how recent advances in sound processing and speaker diarization can improve the existing embedded systems. We study the performances of two new methods and discuss the benefits of DNN based approaches which improve performances by about 100%.
</details>
<details>
<summary>摘要</summary>
As the French, European, and worldwide populations are aging, there is a strong interest in new systems that can provide reliable and privacy-preserving home monitoring for frailty prevention. This work is part of a global environmental audio analysis system that aims to help identify Activities of Daily Life (ADL) through human and everyday life sounds recognition, speech presence, and number of speakers detection. The focus is on the number of speakers detection. In this article, we discuss how recent advances in sound processing and speaker diarization can improve the existing embedded systems. We evaluate the performance of two new methods and explore the benefits of deep neural network (DNN) based approaches, which can improve performances by about 100%.
</details></li>
</ul>
<hr>
<h2 id="Explicit-Estimation-of-Magnitude-and-Phase-Spectra-in-Parallel-for-High-Quality-Speech-Enhancement"><a href="#Explicit-Estimation-of-Magnitude-and-Phase-Spectra-in-Parallel-for-High-Quality-Speech-Enhancement" class="headerlink" title="Explicit Estimation of Magnitude and Phase Spectra in Parallel for High-Quality Speech Enhancement"></a>Explicit Estimation of Magnitude and Phase Spectra in Parallel for High-Quality Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08926">http://arxiv.org/abs/2308.08926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye-Xin Lu, Yang Ai, Zhen-Hua Ling</li>
<li>for: 提高speech质量和可理解性</li>
<li>methods: 提出MP-SENet模型，通过并行地恢复大小和相位特征图像来提高speech质量</li>
<li>results: 在多个任务上实现高质量的speech提升，包括speech干声、抑护、宽频扩展等任务，并且比存在相位感知的方法更好地避免了相位与大小相互赔偿的问题<details>
<summary>Abstract</summary>
Phase information has a significant impact on speech perceptual quality and intelligibility. However, existing speech enhancement methods encounter limitations in explicit phase estimation due to the non-structural nature and wrapping characteristics of the phase, leading to a bottleneck in enhanced speech quality. To overcome the above issue, in this paper, we proposed MP-SENet, a novel Speech Enhancement Network which explicitly enhances Magnitude and Phase spectra in parallel. The proposed MP-SENet adopts a codec architecture in which the encoder and decoder are bridged by time-frequency Transformers along both time and frequency dimensions. The encoder aims to encode time-frequency representations derived from the input distorted magnitude and phase spectra. The decoder comprises dual-stream magnitude and phase decoders, directly enhancing magnitude and wrapped phase spectra by incorporating a magnitude estimation architecture and a phase parallel estimation architecture, respectively. To train the MP-SENet model effectively, we define multi-level loss functions, including mean square error and perceptual metric loss of magnitude spectra, anti-wrapping loss of phase spectra, as well as mean square error and consistency loss of short-time complex spectra. Experimental results demonstrate that our proposed MP-SENet excels in high-quality speech enhancement across multiple tasks, including speech denoising, dereverberation, and bandwidth extension. Compared to existing phase-aware speech enhancement methods, it successfully avoids the bidirectional compensation effect between the magnitude and phase, leading to a better harmonic restoration. Notably, for the speech denoising task, the MP-SENet yields a state-of-the-art performance with a PESQ of 3.60 on the public VoiceBank+DEMAND dataset.
</details>
<details>
<summary>摘要</summary>
干扰信息对语音辨识质量和可读性有着重要的影响。然而，现有的语音增强方法受到不可靠的阶段估计的限制，由于干扰信息的非结构性和包袋特性，导致增强语音质量的瓶颈。为了突破这个问题，在这篇论文中，我们提出了MP-SENet，一种新的语音增强网络，可以并行地增强干扰信息的大小和阶段 spectra。MP-SENet 采用了 codec 架构，其中编码器和解码器通过时间频率变换器连接。编码器的目的是将输入损坏的干扰信息转化为时间频率表示。解码器包括两个独立的大小和包袋解码器，直接将输入干扰信息的大小和包袋 spectra 提高，并采用了大小估计架构和包袋平行估计架构。为了训练 MP-SENet 模型，我们定义了多个层次损失函数，包括平均方差损失和听觉指标损失，反射损失、适应损失和短时间复杂 spectra 的损失。实验结果表明，我们提出的 MP-SENet 在多个任务上实现了高质量的语音增强，包括语音减雷、抑制抑震和频率扩展。相比现有的阶段意识的语音增强方法，MP-SENet 成功避免了阶段相互赔偿效果，从而更好地保持干扰信息的谱干整复。特别是在语音减雷任务上，MP-SENet 实现了公共 VoiceBank+DEMAND 数据集上的状态级表现，PESQ 为 3.60。
</details></li>
</ul>
<hr>
<h2 id="Long-frame-shift-Neural-Speech-Phase-Prediction-with-Spectral-Continuity-Enhancement-and-Interpolation-Error-Compensation"><a href="#Long-frame-shift-Neural-Speech-Phase-Prediction-with-Spectral-Continuity-Enhancement-and-Interpolation-Error-Compensation" class="headerlink" title="Long-frame-shift Neural Speech Phase Prediction with Spectral Continuity Enhancement and Interpolation Error Compensation"></a>Long-frame-shift Neural Speech Phase Prediction with Spectral Continuity Enhancement and Interpolation Error Compensation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08850">http://arxiv.org/abs/2308.08850</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangai520/lfs-nspp">https://github.com/yangai520/lfs-nspp</a></li>
<li>paper_authors: Yang Ai, Ye-Xin Lu, Zhen-Hua Ling</li>
<li>for: 提高信号处理领域内的speech phase预测精度，使得可以准确地从 amplitude-related features 中预测长框偏移 phase spectra。</li>
<li>methods: 提出了一种基于 neural network 的长框偏移 speech phase 预测方法 (LFS-NSPP)，包括三个阶段： interpolate、predict 和 decimate。首先，将 long-frame-shift log amplitude spectra 转换为 short-frame-shift log amplitude spectra  mediante frequency-by-frequency interpolation，然后使用 NSPP 模型预测 short-frame-shift phase spectra，最后，将 long-frame-shift phase spectra 得到于 short-frame-shift phase spectra  mediante frame-by-frame decimation。</li>
<li>results: 实验结果表明，提出的 LFS-NSPP 方法可以在预测 long-frame-shift phase spectra 方面达到更高的精度，比原 NSPP 模型和其他信号处理基于 phase 估计算法更好。<details>
<summary>Abstract</summary>
Speech phase prediction, which is a significant research focus in the field of signal processing, aims to recover speech phase spectra from amplitude-related features. However, existing speech phase prediction methods are constrained to recovering phase spectra with short frame shifts, which are considerably smaller than the theoretical upper bound required for exact waveform reconstruction of short-time Fourier transform (STFT). To tackle this issue, we present a novel long-frame-shift neural speech phase prediction (LFS-NSPP) method which enables precise prediction of long-frame-shift phase spectra from long-frame-shift log amplitude spectra. The proposed method consists of three stages: interpolation, prediction and decimation. The short-frame-shift log amplitude spectra are first constructed from long-frame-shift ones through frequency-by-frequency interpolation to enhance the spectral continuity, and then employed to predict short-frame-shift phase spectra using an NSPP model, thereby compensating for interpolation errors. Ultimately, the long-frame-shift phase spectra are obtained from short-frame-shift ones through frame-by-frame decimation. Experimental results show that the proposed LFS-NSPP method can yield superior quality in predicting long-frame-shift phase spectra than the original NSPP model and other signal-processing-based phase estimation algorithms.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用signal processing的研究焦点中的speech phase prediction（SPP）方法可以从振荡功率相关特征中恢复speech phase spectra。然而，现有的SPP方法只能recover short frame shift的phase spectra，这些框架偏移远小于理论最大值需要的短时傅立埃 transform（STFT）的波形重建。为解决这个问题，我们提出了一种新的long-frame-shift neural speech phase prediction（LFS-NSPP）方法，可以高精度地预测long-frame-shift phase spectra从long-frame-shift log amplitude spectra。LFS-NSPP方法包括三个阶段：interpolation、prediction和decimation。首先，通过频率域的 interpolate来从long-frame-shift amplitude spectra中提取short-frame-shift log amplitude spectra，以提高spectral continuity。然后，使用NSPP模型预测short-frame-shift phase spectra，以补偿interpolation error。最后，通过frame-by-frame decimation，从short-frame-shift phase spectra中提取long-frame-shift phase spectra。实验结果表明，提出的LFS-NSPP方法可以在预测long-frame-shift phase spectra方面比原始的NSPP模型和其他基于signal processing的phase estimation算法更高质量。Note: The translation is in Simplified Chinese, which is a standardized form of Chinese used in mainland China. The translation may vary depending on the specific dialect or region.
</details></li>
</ul>
<hr>
<h2 id="META-SELD-Meta-Learning-for-Fast-Adaptation-to-the-new-environment-in-Sound-Event-Localization-and-Detection"><a href="#META-SELD-Meta-Learning-for-Fast-Adaptation-to-the-new-environment-in-Sound-Event-Localization-and-Detection" class="headerlink" title="META-SELD: Meta-Learning for Fast Adaptation to the new environment in Sound Event Localization and Detection"></a>META-SELD: Meta-Learning for Fast Adaptation to the new environment in Sound Event Localization and Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08847">http://arxiv.org/abs/2308.08847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinbo Hu, Yin Cao, Ming Wu, Feiran Yang, Ziying Yu, Wenwu Wang, Mark D. Plumbley, Jun Yang</li>
<li>for: 本研究旨在提高学习型 зву响事件定位检测（SELD）方法在不同听控环境中的性能。</li>
<li>methods: 本研究使用meta学习方法，以便快速适应新环境。</li>
<li>results: 实验结果表明，Meta-SELD在适应新环境时的性能较高，比传统的 fine-tuning 方法更加灵活和高效。<details>
<summary>Abstract</summary>
For learning-based sound event localization and detection (SELD) methods, different acoustic environments in the training and test sets may result in large performance differences in the validation and evaluation stages. Different environments, such as different sizes of rooms, different reverberation times, and different background noise, may be reasons for a learning-based system to fail. On the other hand, acquiring annotated spatial sound event samples, which include onset and offset time stamps, class types of sound events, and direction-of-arrival (DOA) of sound sources is very expensive. In addition, deploying a SELD system in a new environment often poses challenges due to time-consuming training and fine-tuning processes. To address these issues, we propose Meta-SELD, which applies meta-learning methods to achieve fast adaptation to new environments. More specifically, based on Model Agnostic Meta-Learning (MAML), the proposed Meta-SELD aims to find good meta-initialized parameters to adapt to new environments with only a small number of samples and parameter updating iterations. We can then quickly adapt the meta-trained SELD model to unseen environments. Our experiments compare fine-tuning methods from pre-trained SELD models with our Meta-SELD on the Sony-TAU Realistic Spatial Soundscapes 2023 (STARSSS23) dataset. The evaluation results demonstrate the effectiveness of Meta-SELD when adapting to new environments.
</details>
<details>
<summary>摘要</summary>
为了解决学习基于 зву频事件检测和位置标注（SELD）方法中环境不同导致验证和评估阶段表现差异较大的问题，我们提出了Meta-SELD方法。这种方法利用元学习技术来实现环境适应快速。具体来说，基于Model Agnostic Meta-Learning（MAML），我们的Meta-SELD目标是在新环境中找到好的元初始化参数，使其适应新环境只需要少量样本和参数更新迭代。这样可以快速地适应元训练的SELD模型中未看过的环境。我们在STARSSS23 dataset上进行了对照研究，并证明了Meta-SELD在适应新环境方面的效果。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Network-Backend-for-Speaker-Recognition"><a href="#Graph-Neural-Network-Backend-for-Speaker-Recognition" class="headerlink" title="Graph Neural Network Backend for Speaker Recognition"></a>Graph Neural Network Backend for Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08767">http://arxiv.org/abs/2308.08767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang He, Ruida Li, Mengqi Niu</li>
<li>for: 提高 speaker recognition 精度</li>
<li>methods: 使用图 neural network (GNN) backend 挖掘嵌入在低维度空间中的 latent 关系</li>
<li>results: 在 NIST SRE14 i-vector 挑战 task 和 VoxCeleb1-O、VoxCeleb1-E、VoxCeleb1-H  dataset 上实现了显著的性能提升<details>
<summary>Abstract</summary>
Currently, most speaker recognition backends, such as cosine, linear discriminant analysis (LDA), or probabilistic linear discriminant analysis (PLDA), make decisions by calculating similarity or distance between enrollment and test embeddings which are already extracted from neural networks. However, for each embedding, the local structure of itself and its neighbor embeddings in the low-dimensional space is different, which may be helpful for the recognition but is often ignored. In order to take advantage of it, we propose a graph neural network (GNN) backend to mine latent relationships among embeddings for classification. We assume all the embeddings as nodes on a graph, and their edges are computed based on some similarity function, such as cosine, LDA+cosine, or LDA+PLDA. We study different graph settings and explore variants of GNN to find a better message passing and aggregation way to accomplish the recognition task. Experimental results on NIST SRE14 i-vector challenging, VoxCeleb1-O, VoxCeleb1-E, and VoxCeleb1-H datasets demonstrate that our proposed GNN backends significantly outperform current mainstream methods.
</details>
<details>
<summary>摘要</summary>
当前大多数 speaker recognition 后端，如cosine、线性混合分析（LDA）或 probabilistic 线性混合分析（PLDA），做出决策时通常计算投入和测试嵌入的相似性或距离。然而，每个嵌入都有自己本地结构，这些结构可能对识别有帮助，但通常被忽略。为了利用这些结构，我们提议一种基于图 neural network（GNN）的后端，以挖掘嵌入之间的隐藏关系，并用于分类。我们将所有嵌入视为图中的节点，并根据某种相似函数（如cosine、LDA+cosine或LDA+PLDA）计算它们之间的边。我们研究了不同的图设置和GNN变种，以找到更好的消息传递和聚合方式，以完成识别任务。实验结果表明，我们提议的 GNN 后端在 NIST SRE14 i-vector 挑战任务、VoxCeleb1-O、VoxCeleb1-E 和 VoxCeleb1-H 数据集上显著超越了当前主流方法。
</details></li>
</ul>
<hr>
<h2 id="The-DKU-MSXF-Speaker-Verification-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#The-DKU-MSXF-Speaker-Verification-System-for-the-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="The DKU-MSXF Speaker Verification System for the VoxCeleb Speaker Recognition Challenge 2023"></a>The DKU-MSXF Speaker Verification System for the VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08766">http://arxiv.org/abs/2308.08766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Li, Yuke Lin, Xiaoyi Qin, Ning Jiang, Guoqing Zhao, Ming Li</li>
<li>For: 本研究是DKU-MSXF系统的 Track1、Track2 和 Track3 的 VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）系统描述。* Methods: 我们利用基于 ResNet 网络结构的训练方法，并构建了跨年龄 QMF 训练集，从而实现了显著提高系统性能。* Results: 我们在 Track 2 中使用预训练模型，并通过将 VoxBlink-clean 数据集 incorporated 进行混合训练，相比 Track 1，包含 VoxBlink-clean 数据集的模型表现提高了 более чем 10%。在 Track 3 中，我们采用了一种新的 Pseudo-labeling 方法，并使用 triple thresholds 和 sub-center purification，实现了预测领域的适应。最终提交得到了 task1 的 mDCF 0.1243、Track 2 的 mDCF 0.1165 和 Track 3 的 EER 4.952%。<details>
<summary>Abstract</summary>
This paper is the system description of the DKU-MSXF System for the track1, track2 and track3 of the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23). For Track 1, we utilize a network structure based on ResNet for training. By constructing a cross-age QMF training set, we achieve a substantial improvement in system performance. For Track 2, we inherite the pre-trained model from Track 1 and conducte mixed training by incorporating the VoxBlink-clean dataset. In comparison to Track 1, the models incorporating VoxBlink-clean data exhibit a performance improvement by more than 10% relatively. For Track3, the semi-supervised domain adaptation task, a novel pseudo-labeling method based on triple thresholds and sub-center purification is adopted to make domain adaptation. The final submission achieves mDCF of 0.1243 in task1, mDCF of 0.1165 in Track 2 and EER of 4.952% in Track 3.
</details>
<details>
<summary>摘要</summary>
这份文章是DKU-MSXF系统的描述，用于VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的track1、track2和track3。在track1中，我们使用基于ResNet的网络结构进行训练，通过构建跨年龄QMF训练集，实现了显著提高系统性能。在track2中，我们继承了track1中的预训练模型，并通过将VoxBlink-clean数据集 incorporated进行混合训练，相比track1，包含VoxBlink-clean数据集的模型表现相对提高了 более10%。在track3中，我们采用了一种新的半有限预测方法，基于三个阈值和子中心纯化，进行预测领域适应。最终提交的结果为task1中的mDCF为0.1243，track2中的mDCF为0.1165，以及track3中的EER为4.952%。
</details></li>
</ul>
<hr>
<h2 id="Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition"><a href="#Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition" class="headerlink" title="Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition"></a>Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08713">http://arxiv.org/abs/2308.08713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/95anantsingh/decoding-emotions">https://github.com/95anantsingh/decoding-emotions</a></li>
<li>paper_authors: Anant Singh, Akshat Gupta</li>
<li>for: 这个研究旨在评估基于变换器的speech表示模型在多种语言的语音情感识别 tasks 中的表现，以及这些模型内部的表示方式。</li>
<li>methods: 本文使用了八种speech表示模型和六种语言进行了一系列的比较和探索，包括 probing 实验来探究这些模型内部的工作方式。</li>
<li>results: 研究发现，使用单个最佳层的speech模型特征可以降低错误率32%的平均值，并在七个数据集中达到了德语和波斯语的国际前景。 probing 结果表明，speech模型的中间层 capture 最重要的情感信息。<details>
<summary>Abstract</summary>
Recent advancements in transformer-based speech representation models have greatly transformed speech processing. However, there has been limited research conducted on evaluating these models for speech emotion recognition (SER) across multiple languages and examining their internal representations. This article addresses these gaps by presenting a comprehensive benchmark for SER with eight speech representation models and six different languages. We conducted probing experiments to gain insights into inner workings of these models for SER. We find that using features from a single optimal layer of a speech model reduces the error rate by 32\% on average across seven datasets when compared to systems where features from all layers of speech models are used. We also achieve state-of-the-art results for German and Persian languages. Our probing results indicate that the middle layers of speech models capture the most important emotional information for speech emotion recognition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.SD_2023_08_17/" data-id="clorjzlb600vaf188coow3aqu" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.CV_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T13:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.CV_2023_08_17/">cs.CV - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression"><a href="#Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression" class="headerlink" title="Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression"></a>Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09065">http://arxiv.org/abs/2308.09065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanlong Yu, Gianni Franchi, Jindong Gu, Emanuel Aldea</li>
<li>for: 这个研究旨在提高深度神经网络（DNNs）在实际应用中的稳定性，通过提出一个辅助不确定估测器（AuxUE），以估计主任务预测结果的不确定性。</li>
<li>methods: 本研究提出了一个通用的AuxUE方案，以提供更加稳定的不确定性估测。 Specifically, 我们考虑了不同的分布假设，以估计各种不同类型的噪声，最终选择了拉Place分布估计预测误差。 我们还提出了一个新的解方案，即精确化后的Dirichlet posterior（DIDO），用于模型预测误差的精确化。</li>
<li>results: 我们在年龄估测、单目深度估测和超解像任务上进行了广泛的实验，结果显示了我们的提案可以在噪音输入下提供稳定的不确定性估测，并且可以扩展到像素级和图像级任务。<details>
<summary>Abstract</summary>
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在实际应用中部署需要量化不确定性。副作用不确定性估计器（AuxUE）是 modifying the main task model 的一种非常有效的方法来估计主任务预测结果的不确定性。为了被视为可靠，一个 AuxUE 必须能够在遇到不同输入时保持其性能并触发更高的不确定性，即提供可靠的 aleatoric 和 epistemic 不确定性。然而，现有的 AuxUE 设计主要用于 aleatoric 不确定性估计，而 regression 任务上的 AuxUE 强度还未被探索。在这项工作中，我们提出了一种通用的 AuxUE 方案，以提高 regression 任务上的不确定性量化的可靠性。具体来说，为了更好地估计 aleatoric 不确定性，我们考虑了不同的分布假设 для hetroscedastic 噪声，并最终选择了 Laplace 分布来近似预测错误。为 epistemic 不确定性，我们提出了一种新的解决方案，即 Discretization-Induced Dirichlet pOsterior（DIDO），它模型了精度 posterior 在精度化预测错误上。我们在年龄估计、单目深度估计和超分辨率任务上进行了广泛的实验，结果显示，我们的提议方法可以在噪声输入下提供可靠的不确定性估计，并且可以扩展到图像级和像素级任务。
</details></li>
</ul>
<hr>
<h2 id="SimFIR-A-Simple-Framework-for-Fisheye-Image-Rectification-with-Self-supervised-Representation-Learning"><a href="#SimFIR-A-Simple-Framework-for-Fisheye-Image-Rectification-with-Self-supervised-Representation-Learning" class="headerlink" title="SimFIR: A Simple Framework for Fisheye Image Rectification with Self-supervised Representation Learning"></a>SimFIR: A Simple Framework for Fisheye Image Rectification with Self-supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09040">http://arxiv.org/abs/2308.09040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fh2019ustc/SimFIR">https://github.com/fh2019ustc/SimFIR</a></li>
<li>paper_authors: Hao Feng, Wendi Wang, Jiajun Deng, Wengang Zhou, Li Li, Houqiang Li</li>
<li>for:  fisheye image rectification</li>
<li>methods:  self-supervised representation learning with a Vision Transformer (ViT) and an innovative unified distortion-aware pretext task</li>
<li>results:  remarkable boost in transfer performance on downstream rectification task, with superiority over state-of-the-art algorithms and strong generalization ability on real-world fisheye images.Here’s the full summary in Simplified Chinese:</li>
<li>for:  fisheye 图像整正</li>
<li>methods: 自主学习表征学习（ViT）和创新的扭曲意识预测任务</li>
<li>results:  downstream 整正任务的转移性能强劲提高，与状态艺术算法相比，在真实世界 fisheye 图像上具有强大的总体化能力。<details>
<summary>Abstract</summary>
In fisheye images, rich distinct distortion patterns are regularly distributed in the image plane. These distortion patterns are independent of the visual content and provide informative cues for rectification. To make the best of such rectification cues, we introduce SimFIR, a simple framework for fisheye image rectification based on self-supervised representation learning. Technically, we first split a fisheye image into multiple patches and extract their representations with a Vision Transformer (ViT). To learn fine-grained distortion representations, we then associate different image patches with their specific distortion patterns based on the fisheye model, and further subtly design an innovative unified distortion-aware pretext task for their learning. The transfer performance on the downstream rectification task is remarkably boosted, which verifies the effectiveness of the learned representations. Extensive experiments are conducted, and the quantitative and qualitative results demonstrate the superiority of our method over the state-of-the-art algorithms as well as its strong generalization ability on real-world fisheye images.
</details>
<details>
<summary>摘要</summary>
在鱼眼图像中，丰富的不同扭曲模式 Regularly 分布在图像平面上。这些扭曲模式与视觉内容无关，并提供有用的纠正指引。为了充分利用这些纠正指引，我们提出了基于自我超vised representation learning的SimFIR框架。技术上，我们首先将鱼眼图像分割成多个 patches，然后使用 Vision Transformer (ViT) 提取这些 patches 的表示。为了学习细腻的扭曲表示，我们然后将不同的图像 patches 与其 especific 的扭曲模式相关联，并进一步设计了一种创新的统一扭曲意识pretext任务 для其学习。这种转移性能在下游纠正任务上明显提高，这证明了我们学习的表示的效果。我们进行了广泛的实验，并示出了对现实世界鱼眼图像的superiority和其强大的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="MarginMatch-Improving-Semi-Supervised-Learning-with-Pseudo-Margins"><a href="#MarginMatch-Improving-Semi-Supervised-Learning-with-Pseudo-Margins" class="headerlink" title="MarginMatch: Improving Semi-Supervised Learning with Pseudo-Margins"></a>MarginMatch: Improving Semi-Supervised Learning with Pseudo-Margins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09037">http://arxiv.org/abs/2308.09037</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsosea2/marginmatch">https://github.com/tsosea2/marginmatch</a></li>
<li>paper_authors: Tiberiu Sosea, Cornelia Caragea</li>
<li>for: 提高 semi-supervised learning 的性能，特别是在数据量少的情况下。</li>
<li>methods:  combine consistency regularization 和 pseudo-labeling，使用无标签数据训练动态来衡量pseudo-label的质量。</li>
<li>results: 在四个视觉benchmark和两个大规模数据集上提供了显著改进，强调高质量 pseudo-label 的重要性。特别是在 CIFAR-100 上提高了error rate的优化3.25%，并在 STL-10 上使用了只有4个标签每类的情况下提高了error rate的优化3.78%。<details>
<summary>Abstract</summary>
We introduce MarginMatch, a new SSL approach combining consistency regularization and pseudo-labeling, with its main novelty arising from the use of unlabeled data training dynamics to measure pseudo-label quality. Instead of using only the model's confidence on an unlabeled example at an arbitrary iteration to decide if the example should be masked or not, MarginMatch also analyzes the behavior of the model on the pseudo-labeled examples as the training progresses, to ensure low quality predictions are masked out. MarginMatch brings substantial improvements on four vision benchmarks in low data regimes and on two large-scale datasets, emphasizing the importance of enforcing high-quality pseudo-labels. Notably, we obtain an improvement in error rate over the state-of-the-art of 3.25% on CIFAR-100 with only 25 labels per class and of 3.78% on STL-10 using as few as 4 labels per class. We make our code available at https://github.com/tsosea2/MarginMatch.
</details>
<details>
<summary>摘要</summary>
我团队今天宣布了一种新的SSL方法，即MarginMatch，它结合了一致性规则和假标注，其主要创新在于使用无标注数据训练动态来衡量假标注质量。不同于以往只使用模型对无标注示例的任意轮次的信任度来决定是否遮盖示例，MarginMatch还分析了模型在假标注示例上的行为，以确保低质量预测被排除。MarginMatch在四个视觉标准benchmark上表现出了显著改善，特别是在低数据 régime下，以及在两个大规模数据集上，这些成果强调了高质量假标注的重要性。我们在CIFAR-100上实现了error rate的提升为3.25%，只使用每类25个标签，而在STL-10上实现了error rate的提升为3.78%，只使用每类4个标签。我们将代码发布在https://github.com/tsosea2/MarginMatch上。
</details></li>
</ul>
<hr>
<h2 id="Uni-NLX-Unifying-Textual-Explanations-for-Vision-and-Vision-Language-Tasks"><a href="#Uni-NLX-Unifying-Textual-Explanations-for-Vision-and-Vision-Language-Tasks" class="headerlink" title="Uni-NLX: Unifying Textual Explanations for Vision and Vision-Language Tasks"></a>Uni-NLX: Unifying Textual Explanations for Vision and Vision-Language Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09033">http://arxiv.org/abs/2308.09033</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fawazsammani/uni-nlx">https://github.com/fawazsammani/uni-nlx</a></li>
<li>paper_authors: Fawaz Sammani, Nikos Deligiannis</li>
<li>For: The paper aims to propose a unified framework for Natural Language Explanations (NLE) that can consolidate all NLE tasks into a single and compact multi-task model using a unified training objective of text generation.* Methods: The proposed Uni-NLX framework uses a unified training objective of text generation to train a single model that can perform seven NLE tasks, including VQA, visual recognition, and visual reasoning tasks, with 7X fewer parameters compared to previous approaches.* Results: The proposed Uni-NLX framework demonstrates comparable performance to independent task-specific models in previous approaches, and in certain tasks even outperforms them, with a single model that can perform seven NLE tasks using 7X fewer parameters.Here are the three key points in Simplified Chinese text:* For: 这paper的目标是提出一个综合的自然语言解释（NLE）框架，可以将所有NLE任务集成到一个紧凑的多任务模型中，使用一个统一的文本生成训练目标。* Methods: 提议的Uni-NLX框架使用一个统一的文本生成训练目标来训练一个单一模型，可以同时完成七个NLE任务，包括VQA、视觉识别和视觉理解任务，与之前的方法相比，具有7倍 fewer参数。* Results: Uni-NLX框架可以与之前的独立任务特定模型相比，在七个NLE任务中显示相对性能，甚至在某些任务中超越它们，具有一个单一模型可以同时完成七个NLE任务，使用7倍 fewer参数。<details>
<summary>Abstract</summary>
Natural Language Explanations (NLE) aim at supplementing the prediction of a model with human-friendly natural text. Existing NLE approaches involve training separate models for each downstream task. In this work, we propose Uni-NLX, a unified framework that consolidates all NLE tasks into a single and compact multi-task model using a unified training objective of text generation. Additionally, we introduce two new NLE datasets: 1) ImageNetX, a dataset of 144K samples for explaining ImageNet categories, and 2) VQA-ParaX, a dataset of 123K samples for explaining the task of Visual Question Answering (VQA). Both datasets are derived leveraging large language models (LLMs). By training on the 1M combined NLE samples, our single unified framework is capable of simultaneously performing seven NLE tasks including VQA, visual recognition and visual reasoning tasks with 7X fewer parameters, demonstrating comparable performance to the independent task-specific models in previous approaches, and in certain tasks even outperforming them. Code is at https://github.com/fawazsammani/uni-nlx
</details>
<details>
<summary>摘要</summary>
自然语言解释（NLE）目标是补充模型预测结果中的人类友好的自然文本。现有的NLE方法通常包括为每个下游任务培训单独的模型。在这个工作中，我们提出了Uni-NLX框架，这是一个单一的框架，将所有NLE任务合并到一个紧凑的多任务模型中，使用一个统一的文本生成训练目标。此外，我们还提出了两个新的NLE数据集：1）ImageNetX，包含144K个样本，用于解释ImageNet类别，和2）VQA-ParaX，包含123K个样本，用于解释视觉问答任务（VQA）。两个数据集都是基于大语言模型（LLM）的。通过训练1M个总NLE样本，我们的单一框架可以同时完成七个NLE任务，包括VQA、视觉识别和视觉理解任务，使用7X fewer parameters，与之前独立的任务特定模型相比，表现相似，甚至在某些任务上超越它们。代码位于https://github.com/fawazsammani/uni-nlx。
</details></li>
</ul>
<hr>
<h2 id="LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation"><a href="#LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation" class="headerlink" title="LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation"></a>LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09026">http://arxiv.org/abs/2308.09026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a></li>
<li>paper_authors: Berke Doga Basaran, Weitong Zhang, Mengyun Qiao, Bernhard Kainz, Paul M. Matthews, Wenjia Bai</li>
<li>for: 这个研究是为了提高深度学习运算库中的医疗影像分类方法。</li>
<li>methods: 这篇论文提出了一种新的数据增强方法，即LesionMix，它将数据增强进行了特定疾病范围内的调整，以提高分类的多样性和精度。</li>
<li>results: 实验结果显示，LesionMix在不同的MODALITIES和不同的疾病数据集上表现出色，能够优于一些最近的混合数据增强方法，提高医疗影像分类的精度和多样性。<details>
<summary>Abstract</summary>
Data augmentation has become a de facto component of deep learning-based medical image segmentation methods. Most data augmentation techniques used in medical imaging focus on spatial and intensity transformations to improve the diversity of training images. They are often designed at the image level, augmenting the full image, and do not pay attention to specific abnormalities within the image. Here, we present LesionMix, a novel and simple lesion-aware data augmentation method. It performs augmentation at the lesion level, increasing the diversity of lesion shape, location, intensity and load distribution, and allowing both lesion populating and inpainting. Experiments on different modalities and different lesion datasets, including four brain MR lesion datasets and one liver CT lesion dataset, demonstrate that LesionMix achieves promising performance in lesion image segmentation, outperforming several recent Mix-based data augmentation methods. The code will be released at https://github.com/dogabasaran/lesionmix.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translation into Simplified Chinese深度学习基于医学影像 segmentation 方法中的数据增强已成为一种实际中的组件。大多数数据增强技术在医疗影像中都是通过空间和温度变换来提高训练图像的多样性。这些技术通常是在图像层次上进行设计，对全图像进行增强，并不关注特定的病变内部特征。在这里，我们介绍了 LesionMix，一种新的和简单的病变意识的数据增强方法。它在病变层次上进行增强，提高病变形状、位置、温度和负荷分布，并允许病变填充和掩蔽。经过不同的Modalities和不同的病变数据集的测试，包括四个脑MR病变数据集和一个肝CT病变数据集，LesionMix在病变图像分割方面实现了出色的表现，比较多种最近的 Mix-based 数据增强方法。代码将在 GitHub 上发布，地址为 <https://github.com/dogabasaran/lesionmix>。
</details></li>
</ul>
<hr>
<h2 id="SR-GAN-for-SR-gamma-photon-super-resolution-at-collider-experiments"><a href="#SR-GAN-for-SR-gamma-photon-super-resolution-at-collider-experiments" class="headerlink" title="SR-GAN for SR-gamma: photon super resolution at collider experiments"></a>SR-GAN for SR-gamma: photon super resolution at collider experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09025">http://arxiv.org/abs/2308.09025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johannes Erdmann, Aaron van der Graaf, Florian Mausolf, Olaf Nackenhorst</li>
<li>for: 这个论文是用来研究单个图像超分辨算法的，它们是基于生成对抗网络。</li>
<li>methods: 这个论文使用了生成超分辨网络来提高图像的分辨率，并且使用了电磁喷涂仪表示图像的电磁辐射和中性π子衰变。</li>
<li>results: 这个论文得到了图像的分辨率提高，并且可以重现电磁辐射中的特征。此外，使用生成图像作为深度学习光子识别算法的预处理步骤也得到了改善。<details>
<summary>Abstract</summary>
We study single-image super-resolution algorithms for photons at collider experiments based on generative adversarial networks. We treat the energy depositions of simulated electromagnetic showers of photons and neutral-pion decays in a toy electromagnetic calorimeter as 2D images and we train super-resolution networks to generate images with an artificially increased resolution by a factor of four in each dimension. The generated images are able to reproduce features of the electromagnetic showers that are not obvious from the images at nominal resolution. Using the artificially-enhanced images for the reconstruction of shower-shape variables and of the position of the shower center results in significant improvements. We additionally investigate the utilization of the generated images as a pre-processing step for deep-learning photon-identification algorithms and observe improvements in the case of low training statistics.
</details>
<details>
<summary>摘要</summary>
我们研究单个图像超分辨算法，用于粒子加速器实验室中的光子。我们将 simulate电磁散射的能量储存为图像，并将中子衰变探测器中的电磁calorimeter视为2D图像，然后我们使用生成式对抗网络来生成具有人工提高的分辨率（每个维度提高4倍）的图像。生成的图像能够重现辐射的特征，而不可见于原始分辨率的图像中。我们还发现，通过使用生成的图像作为深度学习光子识别算法的预处理步骤，可以在训练数据量较少的情况下获得改善。
</details></li>
</ul>
<hr>
<h2 id="ARAI-MVSNet-A-multi-view-stereo-depth-estimation-network-with-adaptive-depth-range-and-depth-interval"><a href="#ARAI-MVSNet-A-multi-view-stereo-depth-estimation-network-with-adaptive-depth-range-and-depth-interval" class="headerlink" title="ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval"></a>ARAI-MVSNet: A multi-view stereo depth estimation network with adaptive depth range and depth interval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09022">http://arxiv.org/abs/2308.09022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Zhang, Wenjia Xu, Zhiwei Wei, Lili Zhang, Yang Wang, Junyi Liu</li>
<li>for: 这 paper 目的是解决基本的Computer Vision问题，即 Multi-View Stereo（MVS），即使用多视图图像和已知摄像机参数，重建场景。</li>
<li>methods: 这 paper 提出了一种新的多阶段粗细化框架，包括在第一阶段预测粗细度图，然后在第二阶段使用参考图像和已有的深度图预测更加精准的所有像素深度范围，以及在第三和第四阶段使用 Adaptive Depth Interval Adjustment 模块来实现变量间隔分割，以提高更加准确的深度估计。</li>
<li>results: 广泛的实验表明，这 paper 的方法可以达到现状最佳性和优秀的泛化能力，特别是在 DTU 数据集上达到最高的 Acc 和 Overall，在 Tanks and Temples 中间和高级数据集上达到最高的 Recall 和 $F_{1}$-score，并在 BlendedMVS 数据集上达到最低的 $e_{1}$ 和 $e_{3} $，以及在 ETH 3D 数据集上达到最高的 Acc 和 $F_{1}$-score，超过所有列出的方法。<details>
<summary>Abstract</summary>
Multi-View Stereo~(MVS) is a fundamental problem in geometric computer vision which aims to reconstruct a scene using multi-view images with known camera parameters. However, the mainstream approaches represent the scene with a fixed all-pixel depth range and equal depth interval partition, which will result in inadequate utilization of depth planes and imprecise depth estimation. In this paper, we present a novel multi-stage coarse-to-fine framework to achieve adaptive all-pixel depth range and depth interval. We predict a coarse depth map in the first stage, then an Adaptive Depth Range Prediction module is proposed in the second stage to zoom in the scene by leveraging the reference image and the obtained depth map in the first stage and predict a more accurate all-pixel depth range for the following stages. In the third and fourth stages, we propose an Adaptive Depth Interval Adjustment module to achieve adaptive variable interval partition for pixel-wise depth range. The depth interval distribution in this module is normalized by Z-score, which can allocate dense depth hypothesis planes around the potential ground truth depth value and vice versa to achieve more accurate depth estimation. Extensive experiments on four widely used benchmark datasets~(DTU, TnT, BlendedMVS, ETH 3D) demonstrate that our model achieves state-of-the-art performance and yields competitive generalization ability. Particularly, our method achieves the highest Acc and Overall on the DTU dataset, while attaining the highest Recall and $F_{1}$-score on the Tanks and Temples intermediate and advanced dataset. Moreover, our method also achieves the lowest $e_{1}$ and $e_{3}$ on the BlendedMVS dataset and the highest Acc and $F_{1}$-score on the ETH 3D dataset, surpassing all listed methods.Project website: https://github.com/zs670980918/ARAI-MVSNet
</details>
<details>
<summary>摘要</summary>
多视图斯tereo（MVS）是计算机视觉中的基本问题，目标是使用多视图图像和known camera参数来重建场景。然而，主流方法都是使用固定的所有像素深度范围和平等深度间隔来表示场景，这会导致深度估计不准确。在这篇论文中，我们提出了一种新的多阶段粗细化框架，以实现适应性的所有像素深度范围和深度间隔。在第一阶段，我们预测了一个粗细的深度图；然后在第二阶段，我们提出了一种适应深度范围预测模块，通过利用参考图像和在第一阶段获得的深度图来逐渐缩进场景，并预测更加准确的所有像素深度范围。在第三和第四阶段，我们提出了一种适应变量间隔调整模块，以实现适应变量间隔的像素深度范围分布。在这个模块中，深度间隔分布被normalized by Z-score，可以为每个深度值分配密集的深度假设平面，从而实现更加准确的深度估计。我们在四个常用的标准测试集（DTU、TnT、BlendedMVS、ETH 3D）进行了广泛的实验，结果表明，我们的模型在状态艺术性能和泛化能力方面均达到了顶峰。尤其是，我们的方法在DTU测试集上 достиieves最高的Acc和Overall，在Tanks and Temples中间和高级测试集上达到最高的Recall和$F_{1}$score，而在BlendedMVS测试集上，我们的方法也实现了最低的$e_{1}$和$e_{3}，并在ETH 3D测试集上实现了最高的Acc和$F_{1}$score，超越了所有列出的方法。Project website: <https://github.com/zs670980918/ARAI-MVSNet>
</details></li>
</ul>
<hr>
<h2 id="FashionLOGO-Prompting-Multimodal-Large-Language-Models-for-Fashion-Logo-Embeddings"><a href="#FashionLOGO-Prompting-Multimodal-Large-Language-Models-for-Fashion-Logo-Embeddings" class="headerlink" title="FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo Embeddings"></a>FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09012">http://arxiv.org/abs/2308.09012</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/valley-vl/fashionlogo">https://github.com/valley-vl/fashionlogo</a></li>
<li>paper_authors: Yulin Su, Min Yang, Minghui Qiu, Jing Wang, Tao Wang</li>
<li>For: The paper aims to improve the robustness of logo embedding by leveraging textual knowledge as an auxiliary, which can enhance the performance of logo recognition in real-world scenarios.* Methods: The proposed method, FashionLOGO, utilizes Multimodal Large Language Models (MLLMs) to generate explicit textual knowledge through three types of prompts, including image OCR, brief captions, and detailed descriptions prompts, in a zero-shot setting. The cross-attention transformer is used to enable image embedding queries to learn supplementary knowledge from textual embeddings automatically.* Results: The extensive experiments on three real-world datasets demonstrate that FashionLOGO learns generalized and robust logo embeddings, achieving state-of-the-art performance in all benchmark datasets. The introduction of MLLMs improves the performance of logo recognition, and comprehensive ablation studies are conducted to demonstrate the performance improvements.Here’s the simplified Chinese text for the three key points:* 为：本文目的是通过使用文本知识作为辅助，提高图标识别的robustness，以便在实际应用中提高图标识别的性能。* 方法：提议的方法是使用多modal大语言模型（MLLMs）生成文本知识，包括图像OCR、简短标题和详细描述等三种提示，在零shot设定下进行。使用交叉注意力变换器，以便图像嵌入查询自动地学习文本嵌入的补充知识。* 结果：对三个实际 dataset进行了广泛的实验，结果显示，FashionLOGO可以学习 generalized和Robust的图标嵌入，在所有benchmark dataset中达到了状态之art的性能。引入 MLLMs 提高了图标识别的性能，并进行了广泛的减少ablation study来证明性能提高的原因。<details>
<summary>Abstract</summary>
Logo embedding plays a crucial role in various e-commerce applications by facilitating image retrieval or recognition, such as intellectual property protection and product search. However, current methods treat logo embedding as a purely visual problem, which may limit their performance in real-world scenarios. A notable issue is that the textual knowledge embedded in logo images has not been adequately explored. Therefore, we propose a novel approach that leverages textual knowledge as an auxiliary to improve the robustness of logo embedding. The emerging Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in both visual and textual understanding and could become valuable visual assistants in understanding logo images. Inspired by this observation, our proposed method, FashionLOGO, aims to utilize MLLMs to enhance fashion logo embedding. We explore how MLLMs can improve logo embedding by prompting them to generate explicit textual knowledge through three types of prompts, including image OCR, brief captions, and detailed descriptions prompts, in a zero-shot setting. We adopt a cross-attention transformer to enable image embedding queries to learn supplementary knowledge from textual embeddings automatically. To reduce computational costs, we only use the image embedding model in the inference stage, similar to traditional inference pipelines. Our extensive experiments on three real-world datasets demonstrate that FashionLOGO learns generalized and robust logo embeddings, achieving state-of-the-art performance in all benchmark datasets. Furthermore, we conduct comprehensive ablation studies to demonstrate the performance improvements resulting from the introduction of MLLMs.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CN<</SYS>>logo嵌入在多种电商应用中扮演着关键的角色，如知识产权保护和产品搜索。然而，当前方法对logo嵌入视为纯粹的视觉问题，可能会限制其在实际场景中的表现。一个显著的问题是，logo图像中嵌入的文本知识未得到了充分的利用。因此，我们提出了一种新的方法，即使logo嵌入的文本知识作为辅助提高logo嵌入的稳定性。现在的多Modal大语言模型（MLLM）在视觉和文本理解方面具有卓越的能力，因此可以成为logo图像理解的优秀辅助。以这一观察为出发点，我们提出了一种名为FashionLOGO的方法，旨在利用MLLM来强化时尚logo嵌入。我们研究了MLLM如何通过三种类型的提示（图像OCR、简短标题和详细描述提示）在零扩展设定下提高logo嵌入。我们采用了跨层transformer来允许图像嵌入查询学习自动获取文本嵌入的补充知识。为了降低计算成本，我们只在推理阶段使用图像嵌入模型，类似于传统的推理管道。我们对三个实际数据集进行了广泛的实验，结果显示FashionLOGO可以学习 generalized和稳定的logo嵌入，在所有benchmark数据集中达到了状态机器。此外，我们进行了广泛的减少学习研究，以示MLLM引入后的性能提升。
</details></li>
</ul>
<hr>
<h2 id="DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering"><a href="#DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering" class="headerlink" title="DealMVC: Dual Contrastive Calibration for Multi-view Clustering"></a>DealMVC: Dual Contrastive Calibration for Multi-view Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09000">http://arxiv.org/abs/2308.09000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/dealmvc">https://github.com/xihongyang1999/dealmvc</a></li>
<li>paper_authors: Xihong Yang, Jiaqi Jin, Siwei Wang, Ke Liang, Yue Liu, Yi Wen, Suyuan Liu, Sihang Zhou, Xinwang Liu, En Zhu</li>
<li>For: 提高多视图集群性能，解决跨视图场景下相似 pero 不同样本的问题。* Methods: 提出了一种基于对比塑性网络的双重对比塑性约束网络（DealMVC），包括全视观察器和本地对比塑性约束两部分。* Results: 与其他状态时approaches进行比较，通过八个基准数据集的全面实验结果表明DealMVC的效果和优越性。<details>
<summary>Abstract</summary>
Benefiting from the strong view-consistent information mining capacity, multi-view contrastive clustering has attracted plenty of attention in recent years. However, we observe the following drawback, which limits the clustering performance from further improvement. The existing multi-view models mainly focus on the consistency of the same samples in different views while ignoring the circumstance of similar but different samples in cross-view scenarios. To solve this problem, we propose a novel Dual contrastive calibration network for Multi-View Clustering (DealMVC). Specifically, we first design a fusion mechanism to obtain a global cross-view feature. Then, a global contrastive calibration loss is proposed by aligning the view feature similarity graph and the high-confidence pseudo-label graph. Moreover, to utilize the diversity of multi-view information, we propose a local contrastive calibration loss to constrain the consistency of pair-wise view features. The feature structure is regularized by reliable class information, thus guaranteeing similar samples have similar features in different views. During the training procedure, the interacted cross-view feature is jointly optimized at both local and global levels. In comparison with other state-of-the-art approaches, the comprehensive experimental results obtained from eight benchmark datasets provide substantial validation of the effectiveness and superiority of our algorithm. We release the code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.
</details>
<details>
<summary>摘要</summary>
利用强大的视图一致信息挖掘能力，多视图对比 clustering 在最近几年内吸引了很多关注。然而，我们发现以下缺陷，限制了归类性能的进一步改进：现有的多视图模型主要关注同一个样本在不同视图中的一致性，而忽略了不同视图中的相似 yet 不同的样本之间的关系。为解决这问题，我们提议一种名为 DealMVC 的新型 dual contrastive calibration network for Multi-View Clustering。具体来说，我们首先设计了一种 fusions 机制，以获取全局跨视图特征。然后，我们提出了一种全局对比满意抽象loss，通过对视图特征相似图和高确度假标签图进行对应。此外，为了利用多视图信息的多样性，我们提出了一种本地对比满意抽象loss，以约束不同视图中的对应样本之间的一致性。通过对视图特征进行可靠的分类信息 regularization，我们保证了不同视图中的相似样本具有相似的特征。在训练过程中，我们对跨视图特征进行了交互性的joint 优化。与其他状态的方法相比，我们通过八个 benchmark 数据集的全面实验结果，证明了 DealMVC 的有效性和优越性。我们在 GitHub 上发布了 DealMVC 的代码，请参考 <https://github.com/xihongyang1999/DealMVC>。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Information-for-Object-Detection"><a href="#Semantic-Information-for-Object-Detection" class="headerlink" title="Semantic Information for Object Detection"></a>Semantic Information for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08990">http://arxiv.org/abs/2308.08990</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/BMW-InnovationLab/BMW-Anonymization-API">https://github.com/BMW-InnovationLab/BMW-Anonymization-API</a></li>
<li>paper_authors: Jean-Francois Nies</li>
<li>for: 这 paper 的目的是探讨 Semantic Consistency 概念和 Knowledge-Aware Re-Optimization 方法在复杂交通场景中的应用性。</li>
<li>methods: 该 paper 引入了一种新的方法来从图像集中提取知识图，并将这个新的知识图与现有的语义一致性模型集成。</li>
<li>results: 研究发现，通过将这些新的知识图和现有的语义一致性模型相结合，可以在 Faster-RCNN 和 DETR 对象检测模型中获得有限 yet consistent 的改进。<details>
<summary>Abstract</summary>
In this paper, we demonstrate that the concept of Semantic Consistency and the ensuing method of Knowledge-Aware Re-Optimization can be adapted for the problem of object detection in intricate traffic scenes. Furthermore, we introduce a novel method for extracting a knowledge graph from a dataset of images provided with instance-level annotations, and integrate this new knowledge graph with the existing semantic consistency model. Combining both this novel hybrid knowledge graph and the preexisting methods of frequency analysis and external knowledge graph as sources for semantic information, we investigate the effectiveness of knowledge-aware re-optimization on the Faster-RCNN and DETR object detection models. We find that limited but consistent improvements in precision and or recall can be achieved using this method for all combinations of model and method studied.
</details>
<details>
<summary>摘要</summary>
在本文中，我们证明了 semantic consistency 概念和基于知识的重新优化方法可以应用于复杂交通场景中的对象检测问题。此外，我们介绍了一种 novel 的方法，用于从具有实例级注解的图像集中提取知识图谱，并将该新的知识图谱与现有的 semantic consistency 模型结合使用。通过将这些新的混合知识图谱和频率分析以及外部知识图谱作为Semantic information的来源，我们 investigate 了基于知识重新优化的 Faster-RCNN 和 DETR 对象检测模型的效果。我们发现，对于所有模型和方法的组合，可以达到有限 yet consistent 的改进。
</details></li>
</ul>
<hr>
<h2 id="Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation"><a href="#Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation" class="headerlink" title="Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation"></a>Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08974">http://arxiv.org/abs/2308.08974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yilinliu610730/eoe">https://github.com/yilinliu610730/eoe</a></li>
<li>paper_authors: Yilin Liu, Ruining Deng, Juming Xiong, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo</li>
<li>For: 这个论文旨在提出一种自动化的肝炎细胞分 segmentation方法，以便更好地诊断和评估肝炎细胞病变。* Methods: 该方法基于圆形表示，并将圆形分类模型扩展到多标签模型，以便同时分类多种细胞类型。* Results: 实验结果表明，圆形分类模型在identifying和 segmenting嗜精细胞方面的准确率比传统的Mask R-CNN模型和DeepSnake模型更高，这些结果表明这种自动化方法在诊断肝炎细胞病变中具有优势。<details>
<summary>Abstract</summary>
Eosinophilic esophagitis (EoE) is a chronic and relapsing disease characterized by esophageal inflammation. Symptoms of EoE include difficulty swallowing, food impaction, and chest pain which significantly impact the quality of life, resulting in nutritional impairments, social limitations, and psychological distress. The diagnosis of EoE is typically performed with a threshold (15 to 20) of eosinophils (Eos) per high-power field (HPF). Since the current counting process of Eos is a resource-intensive process for human pathologists, automatic methods are desired. Circle representation has been shown as a more precise, yet less complicated, representation for automatic instance cell segmentation such as CircleSnake approach. However, the CircleSnake was designed as a single-label model, which is not able to deal with multi-label scenarios. In this paper, we propose the multi-label CircleSnake model for instance segmentation on Eos. It extends the original CircleSnake model from a single-label design to a multi-label model, allowing segmentation of multiple object types. Experimental results illustrate the CircleSnake model's superiority over the traditional Mask R-CNN model and DeepSnake model in terms of average precision (AP) in identifying and segmenting eosinophils, thereby enabling enhanced characterization of EoE. This automated approach holds promise for streamlining the assessment process and improving diagnostic accuracy in EoE analysis. The source code has been made publicly available at https://github.com/yilinliu610730/EoE.
</details>
<details>
<summary>摘要</summary>
《营养细胞肝炎（EoE）是一种慢性和复发性的疾病，特征是食管Inflammation。症状包括困难吞食、食物堵塞和胸痛，对生活质量产生重要影响，导致营养不良、社会限制和心理压力。EoE诊断通常采用15-20个Eosinophils（Eos）per high-power field（HPF）的阈值。由于现有的Eos计数过程需要人工pathologist的劳动力，因此自动方法被欢迎。圆形表示被证明为更精确、 yet less complicated的表示方法 для自动实例细胞分 segmentation，如CircleSnake方法。然而，CircleSnake方法是单标签设计，无法处理多标签场景。在本文中，我们提出了多标签CircleSnake模型 для实例分 segmentation。它将原始的CircleSnake模型从单标签设计扩展到多标签模型，以便分类多种对象类型。实验结果表明CircleSnake模型在标准Mask R-CNN模型和DeepSnake模型的AP平均精度方面比其他两者更高，以便更好地识别和分类Eosinophils，从而提高EoE分析的精度。这种自动化方法可能会改善EoE诊断过程的效率和准确性。代码已经在https://github.com/yilinliu610730/EoE上公开。
</details></li>
</ul>
<hr>
<h2 id="Watch-Your-Steps-Local-Image-and-Scene-Editing-by-Text-Instructions"><a href="#Watch-Your-Steps-Local-Image-and-Scene-Editing-by-Text-Instructions" class="headerlink" title="Watch Your Steps: Local Image and Scene Editing by Text Instructions"></a>Watch Your Steps: Local Image and Scene Editing by Text Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08947">http://arxiv.org/abs/2308.08947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashkan Mirzaei, Tristan Aumentado-Armstrong, Marcus A. Brubaker, Jonathan Kelly, Alex Levinshtein, Konstantinos G. Derpanis, Igor Gilitschenski</li>
<li>For: The paper is written for the task of text-guided image and NeRF editing, with the goal of localizing the desired edit region implicit in a text instruction.* Methods: The paper uses InstructPix2Pix (IP2P) to predict the desired edit region, and then uses the discrepancy between IP2P predictions with and without the instruction to create a relevance map that guides the modifications. The paper also uses neural radiance fields (NRF) to enhance the quality of text-guided editing of 3D scenes.* Results: The paper achieves state-of-the-art performance on both image and NeRF editing tasks using the proposed method.Here’s the same information in Simplified Chinese:* For: 这篇论文是为了实现文本指导的图像和NeRF编辑任务，目标是将文本中隐藏的编辑区域归类到InstructPix2Pix（IP2P）中。* Methods: 论文使用InstructPix2Pix（IP2P）预测编辑区域，然后使用IP2P预测结果中的差异来生成一个权重图（relevance map），以便引导修改。此外，论文还使用神经辐射场（NRF）来提高文本指导的3D场景编辑质量。* Results: 论文使用提posed方法实现文本指导的图像和NeRF编辑任务，并达到了现有最佳性能。<details>
<summary>Abstract</summary>
Denoising diffusion models have enabled high-quality image generation and editing. We present a method to localize the desired edit region implicit in a text instruction. We leverage InstructPix2Pix (IP2P) and identify the discrepancy between IP2P predictions with and without the instruction. This discrepancy is referred to as the relevance map. The relevance map conveys the importance of changing each pixel to achieve the edits, and is used to to guide the modifications. This guidance ensures that the irrelevant pixels remain unchanged. Relevance maps are further used to enhance the quality of text-guided editing of 3D scenes in the form of neural radiance fields. A field is trained on relevance maps of training views, denoted as the relevance field, defining the 3D region within which modifications should be made. We perform iterative updates on the training views guided by rendered relevance maps from the relevance field. Our method achieves state-of-the-art performance on both image and NeRF editing tasks. Project page: https://ashmrz.github.io/WatchYourSteps/
</details>
<details>
<summary>摘要</summary>
文本指导的图像生成和修改技术已经实现了高质量的图像生成和修改。我们提出了一种方法，可以在文本指导下将需要修改的区域解决为implicit的方式。我们利用InstructPix2Pix（IP2P），并识别IP2P预测中包含和不包含文本指导的差异。这个差异被称为相关性地图。相关性地图表示需要修改每个像素以实现编辑，并用于导航修改。这种导航确保了不重要的像素保持不变。相关性地图还用于提高文本指导下3D场景的颜色场景的质量。我们在 relevance field 中训练了 relevance map ，定义了需要修改的3D区域。我们在 relevance map 的指导下进行了 Iterative 更新，并实现了文本指导下图像和 NeRF 编辑任务的 state-of-the-art 性能。项目页面：https://ashmrz.github.io/WatchYourSteps/
</details></li>
</ul>
<hr>
<h2 id="Auxiliary-Tasks-Benefit-3D-Skeleton-based-Human-Motion-Prediction"><a href="#Auxiliary-Tasks-Benefit-3D-Skeleton-based-Human-Motion-Prediction" class="headerlink" title="Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction"></a>Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08942">http://arxiv.org/abs/2308.08942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mediabrain-sjtu/auxformer">https://github.com/mediabrain-sjtu/auxformer</a></li>
<li>paper_authors: Chenxin Xu, Robby T. Tan, Yuhong Tan, Siheng Chen, Xinchao Wang, Yanfeng Wang</li>
<li>for: 本研究的目的是提高人体运动预测的精度，探索人体运动中的空间-时间相关性。</li>
<li>methods: 本文提出了一种新的方法，通过引入辅助任务来提高模型的学习效果。在辅助任务中，部分身体 JOINTS 的坐标被masking或添加噪声，目的是在其他坐标的基础上恢复受损坐标。为了处理辅助任务，我们提出了一种新的辅助适应 transformer，可以处理不完整、受损的运动数据，并通过捕捉空间-时间相关性来实现坐标恢复。</li>
<li>results: 实验结果显示，我们的方法在 Human3.6M、CMU Mocap 和 3DPW 数据集上的3D MPJPE 方面比州前方法优于remarkable margins of 7.2%, 3.7%,和9.4%。此外，我们的方法在数据缺失和噪声数据情况下也更加稳定和可靠。代码可以在<a target="_blank" rel="noopener" href="https://github.com/MediaBrain-SJTU/AuxFormer">https://github.com/MediaBrain-SJTU/AuxFormer</a> 上下载。<details>
<summary>Abstract</summary>
Exploring spatial-temporal dependencies from observed motions is one of the core challenges of human motion prediction. Previous methods mainly focus on dedicated network structures to model the spatial and temporal dependencies. This paper considers a new direction by introducing a model learning framework with auxiliary tasks. In our auxiliary tasks, partial body joints' coordinates are corrupted by either masking or adding noise and the goal is to recover corrupted coordinates depending on the rest coordinates. To work with auxiliary tasks, we propose a novel auxiliary-adapted transformer, which can handle incomplete, corrupted motion data and achieve coordinate recovery via capturing spatial-temporal dependencies. Through auxiliary tasks, the auxiliary-adapted transformer is promoted to capture more comprehensive spatial-temporal dependencies among body joints' coordinates, leading to better feature learning. Extensive experimental results have shown that our method outperforms state-of-the-art methods by remarkable margins of 7.2%, 3.7%, and 9.4% in terms of 3D mean per joint position error (MPJPE) on the Human3.6M, CMU Mocap, and 3DPW datasets, respectively. We also demonstrate that our method is more robust under data missing cases and noisy data cases. Code is available at https://github.com/MediaBrain-SJTU/AuxFormer.
</details>
<details>
<summary>摘要</summary>
investigate 空间-时间关系从观察动作是人动作预测的核心挑战。 previous methods mainly focus on 专门的网络结构来模型空间和时间关系。 this paper considers a new direction by introducing a model learning framework with auxiliary tasks。 In our auxiliary tasks, partial body joints' coordinates are corrupted by either masking or adding noise, and the goal is to recover corrupted coordinates depending on the rest coordinates。 To work with auxiliary tasks, we propose a novel auxiliary-adapted transformer, which can handle incomplete, corrupted motion data and achieve coordinate recovery by capturing spatial-temporal dependencies。 Through auxiliary tasks, the auxiliary-adapted transformer is promoted to capture more comprehensive spatial-temporal dependencies among body joints' coordinates, leading to better feature learning。 extensive experimental results have shown that our method outperforms state-of-the-art methods by remarkable margins of 7.2%, 3.7%, and 9.4% in terms of 3D mean per joint position error (MPJPE) on the Human3.6M, CMU Mocap, and 3DPW datasets, respectively。 we also demonstrate that our method is more robust under data missing cases and noisy data cases。 Code is available at https://github.com/MediaBrain-SJTU/AuxFormer。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the standard Mandarin pronunciation and may not be exactly the same as the original text in other dialects or pronunciations.
</details></li>
</ul>
<hr>
<h2 id="Automatic-Signboard-Recognition-in-Low-Quality-Night-Images"><a href="#Automatic-Signboard-Recognition-in-Low-Quality-Night-Images" class="headerlink" title="Automatic Signboard Recognition in Low Quality Night Images"></a>Automatic Signboard Recognition in Low Quality Night Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08941">http://arxiv.org/abs/2308.08941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manas Kagde, Priyanka Choudhary, Rishi Joshi, Somnath Dey</li>
<li>for: 解决车辆助手系统和自动驾驶技术中的 traffic sign 识别问题，提高车辆在不良环境下自动分析环境并做出应有的决策。</li>
<li>methods: 使用 Modified MIRNet 模型进行图像增强，然后使用 Yolov4 模型在不制限环境中识别 traffic sign。</li>
<li>results: 提高了 Yolov4 模型在低质量图像上的 <a href="mailto:&#109;&#65;&#x50;&#x40;&#x30;&#46;&#x35;">&#109;&#65;&#x50;&#x40;&#x30;&#46;&#x35;</a> 值5.40%，并在 GTSRB 数据集上实现了96.75%的总 <a href="mailto:&#x6d;&#x41;&#80;&#64;&#48;&#x2e;&#53;">&#x6d;&#x41;&#80;&#64;&#48;&#x2e;&#53;</a>，与当前最佳工作相当。<details>
<summary>Abstract</summary>
An essential requirement for driver assistance systems and autonomous driving technology is implementing a robust system for detecting and recognizing traffic signs. This system enables the vehicle to autonomously analyze the environment and make appropriate decisions regarding its movement, even when operating at higher frame rates. However, traffic sign images captured in inadequate lighting and adverse weather conditions are poorly visible, blurred, faded, and damaged. Consequently, the recognition of traffic signs in such circumstances becomes inherently difficult. This paper addressed the challenges of recognizing traffic signs from images captured in low light, noise, and blurriness. To achieve this goal, a two-step methodology has been employed. The first step involves enhancing traffic sign images by applying a modified MIRNet model and producing enhanced images. In the second step, the Yolov4 model recognizes the traffic signs in an unconstrained environment. The proposed method has achieved 5.40% increment in mAP@0.5 for low quality images on Yolov4. The overall mAP@0.5 of 96.75% has been achieved on the GTSRB dataset. It has also attained mAP@0.5 of 100% on the GTSDB dataset for the broad categories, comparable with the state-of-the-art work.
</details>
<details>
<summary>摘要</summary>
driver assistance systems 和自动驾驶技术的重要需求之一是实现一个可靠的交通标志检测和识别系统。这个系统使得车辆可以自动分析环境，并根据相应的 дви作行为。然而，交通标志图像在不良照明和不利天气条件下 capture 得到的图像会变得混乱、模糊、暗淡和受损。因此，在这些情况下，交通标志的识别变得自然地困难。这篇论文通过解决低照明、噪音和模糊等问题，提出了一种两步方法。在第一步中，我们使用修改后的 MIRNet 模型来增强交通标志图像，生成了更加明确的图像。在第二步中，我们使用 Yolov4 模型在无约束环境中识别交通标志。我们的方法在低质量图像上实现了 5.40% 的增量，并在 GTSRB 数据集上实现了 96.75% 的总 mAP@0.5。此外，我们在 GTSDB 数据集上实现了 Broad 类别的 100% mAP@0.5，与现有的工作相当。
</details></li>
</ul>
<hr>
<h2 id="SDDNet-Style-guided-Dual-layer-Disentanglement-Network-for-Shadow-Detection"><a href="#SDDNet-Style-guided-Dual-layer-Disentanglement-Network-for-Shadow-Detection" class="headerlink" title="SDDNet: Style-guided Dual-layer Disentanglement Network for Shadow Detection"></a>SDDNet: Style-guided Dual-layer Disentanglement Network for Shadow Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08935">http://arxiv.org/abs/2308.08935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runmin Cong, Yuchen Guan, Jinpeng Chen, Wei Zhang, Yao Zhao, Sam Kwong</li>
<li>for: 本研究的目的是提高阴影检测的精度，尤其是在复杂背景下，现有方法受到背景颜色的影响，导致阴影检测错误。</li>
<li>methods: 我们使用Style-guided Dual-layer Disentanglement Network (SDDNet)，包括Feature Separation and Recombination (FSR)模块和Shadow Style Filter (SSF)模块，独立模型背景层和阴影层，并通过特殊监督和重建约束保持信息完整性和无重复。</li>
<li>results: 我们的模型在三个公共数据集上实现了优秀的性能，并且在实时推理速度上达到32帧&#x2F;秒。<details>
<summary>Abstract</summary>
Despite significant progress in shadow detection, current methods still struggle with the adverse impact of background color, which may lead to errors when shadows are present on complex backgrounds. Drawing inspiration from the human visual system, we treat the input shadow image as a composition of a background layer and a shadow layer, and design a Style-guided Dual-layer Disentanglement Network (SDDNet) to model these layers independently. To achieve this, we devise a Feature Separation and Recombination (FSR) module that decomposes multi-level features into shadow-related and background-related components by offering specialized supervision for each component, while preserving information integrity and avoiding redundancy through the reconstruction constraint. Moreover, we propose a Shadow Style Filter (SSF) module to guide the feature disentanglement by focusing on style differentiation and uniformization. With these two modules and our overall pipeline, our model effectively minimizes the detrimental effects of background color, yielding superior performance on three public datasets with a real-time inference speed of 32 FPS.
</details>
<details>
<summary>摘要</summary>
尽管目前的阴影检测技术已经取得了 significative 进步，但是它们仍然在复杂背景下陷入阴影检测错误的问题。我们 Drawing inspiration from the human visual system，我们将输入阴影图像看作是一个背景层和一个阴影层的组合，并设计了一个 Style-guided Dual-layer Disentanglement Network (SDDNet) 来模型这两个层。为了实现这一目标，我们提出了一个 Feature Separation and Recombination (FSR) 模块，该模块将多层特征分解成阴影相关和背景相关的组成部分，通过提供特殊的监督来保持这两个部分之间的信息完整性和不重复，同时通过重建约束来避免信息损失。此外，我们还提出了一个 Shadow Style Filter (SSF) 模块，该模块通过注重阴影风格差异和均衡来引导特征分解。与这两个模块和我们的整体管道相结合，我们的模型能够有效地减少背景颜色的负面影响，在三个公共数据集上实现了超过32帧每秒的实时推理速度。
</details></li>
</ul>
<hr>
<h2 id="Point-aware-Interaction-and-CNN-induced-Refinement-Network-for-RGB-D-Salient-Object-Detection"><a href="#Point-aware-Interaction-and-CNN-induced-Refinement-Network-for-RGB-D-Salient-Object-Detection" class="headerlink" title="Point-aware Interaction and CNN-induced Refinement Network for RGB-D Salient Object Detection"></a>Point-aware Interaction and CNN-induced Refinement Network for RGB-D Salient Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08930">http://arxiv.org/abs/2308.08930</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rmcong/picr-net_acmmm23">https://github.com/rmcong/picr-net_acmmm23</a></li>
<li>paper_authors: Runmin Cong, Hongyu Liu, Chen Zhang, Wei Zhang, Feng Zheng, Ran Song, Sam Kwong</li>
<li>for: 提高复杂和挑战性场景中的焦点对象检测（SOD）能力</li>
<li>methods: 通过RGB图像和深度地图的共同信息 интеграción，利用Convolutional Neural Networks（CNNs）激活和转换器架构，实现自模态和跨模态的全球长距离相关性模型化</li>
<li>results: 在五个RGB-D SOD数据集上进行了广泛的实验，并示出了与参考模型相比的竞争性Results<details>
<summary>Abstract</summary>
By integrating complementary information from RGB image and depth map, the ability of salient object detection (SOD) for complex and challenging scenes can be improved. In recent years, the important role of Convolutional Neural Networks (CNNs) in feature extraction and cross-modality interaction has been fully explored, but it is still insufficient in modeling global long-range dependencies of self-modality and cross-modality. To this end, we introduce CNNs-assisted Transformer architecture and propose a novel RGB-D SOD network with Point-aware Interaction and CNN-induced Refinement (PICR-Net). On the one hand, considering the prior correlation between RGB modality and depth modality, an attention-triggered cross-modality point-aware interaction (CmPI) module is designed to explore the feature interaction of different modalities with positional constraints. On the other hand, in order to alleviate the block effect and detail destruction problems brought by the Transformer naturally, we design a CNN-induced refinement (CNNR) unit for content refinement and supplementation. Extensive experiments on five RGB-D SOD datasets show that the proposed network achieves competitive results in both quantitative and qualitative comparisons.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：通过融合RGB图像和深度图的补充信息，可以提高复杂和挑战的场景下的鲜色对象检测（SOD）能力。近年来，人工神经网络（CNN）在特征提取和跨模态交互方面得到了广泛的探索，但是在自模态和跨模态的全局长距离相互作用方面仍然不够。为此，我们提出了CNNs-assisted Transformer架构，并提出了一种新的RGB-D SOD网络，即点位相互作用和CNN引导的PICR-Net。一方面， compte tenpoint-aware cross-modality interaction（CmPI）模块，通过关注RGB模式和深度模式之间的先前相关性，探索不同模式之间的特征交互。另一方面，为了解决由Transformer自然引入的块效应和细节毁灭问题，我们设计了CNN引导的修充（CNNR）单元，用于内容修充和补充。在五个RGB-D SOD数据集上进行了广泛的实验，结果表明，我们提出的网络在量化和质量比较中均达到了竞争水平。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Perception-Network-for-Camouflaged-Object-Detection"><a href="#Frequency-Perception-Network-for-Camouflaged-Object-Detection" class="headerlink" title="Frequency Perception Network for Camouflaged Object Detection"></a>Frequency Perception Network for Camouflaged Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08924">http://arxiv.org/abs/2308.08924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rmcong/fpnet_acmmm23">https://github.com/rmcong/fpnet_acmmm23</a></li>
<li>paper_authors: Runmin Cong, Mengyao Sun, Sanyi Zhang, Xiaofei Zhou, Wei Zhang, Yao Zhao</li>
<li>for: 抵抗隐藏的物体检测 (COD) 目标是准确检测隐藏在环境中的物体。但是现有的 COD 方法主要在 RGB 频谱中检测隐藏的物体，其性能尚未在许多挑战性enario中得到了充分利用。</li>
<li>methods: 我们提出了一种新的学习可能的和分离的频谱感知机制，驱动于 semantic 层次结构。我们的整个网络采用了两个阶段模型，包括频谱导航的粗略本地化阶段和详细保持的细致本地化阶段。通过多级特征提取的后凹网络，我们设计了一种灵活的频谱感知模块基于 octave convolution 进行粗略定位。然后，我们设计了修正融合模块，通过先导引 correction 和跨层特征通道关联，逐步融合高级特征，并最终与浅层特征结合以实现隐藏物体的细致修正。</li>
<li>results: 与现有的模型相比，我们的提出的方法在三个流行的benchmark数据集中具有竞争性的性能， both qualitatively and quantitatively。<details>
<summary>Abstract</summary>
Camouflaged object detection (COD) aims to accurately detect objects hidden in the surrounding environment. However, the existing COD methods mainly locate camouflaged objects in the RGB domain, their performance has not been fully exploited in many challenging scenarios. Considering that the features of the camouflaged object and the background are more discriminative in the frequency domain, we propose a novel learnable and separable frequency perception mechanism driven by the semantic hierarchy in the frequency domain. Our entire network adopts a two-stage model, including a frequency-guided coarse localization stage and a detail-preserving fine localization stage. With the multi-level features extracted by the backbone, we design a flexible frequency perception module based on octave convolution for coarse positioning. Then, we design the correction fusion module to step-by-step integrate the high-level features through the prior-guided correction and cross-layer feature channel association, and finally combine them with the shallow features to achieve the detailed correction of the camouflaged objects. Compared with the currently existing models, our proposed method achieves competitive performance in three popular benchmark datasets both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT隐形物体检测（COD）的目标是准确检测周围环境中隐藏的物体。然而，现有的COD方法主要在RGB频谱上定位隐形物体，其性能在许多具有挑战性的场景下尚未得到完全利用。尝试从频谱域的特征角度来解决这个问题，我们提出了一种新的学习型和可分离的频谱感知机制，它是基于semantic hierarchy在频谱域的频谱感知机制。我们的整个网络采用了两个阶段模型，包括频谱导向粗略定位阶段和细节保持细致定位阶段。通过多级特征提取的背景，我们设计了一种可变频谱感知模块，基于八分割卷积来实现粗略定位。然后，我们设计了修正融合模块，通过优先指导修正和跨层特征通道关联，逐步融合高级特征，并最终与浅层特征相结合以实现细节修正。相比现有的模型，我们的提出的方法在三个流行的标准 benchmark dataset上具有竞争性的表现， both qualitatively and quantitatively。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Identity-Seeking-Self-Supervised-Representation-Learning-for-Generalizable-Person-Re-identification"><a href="#Identity-Seeking-Self-Supervised-Representation-Learning-for-Generalizable-Person-Re-identification" class="headerlink" title="Identity-Seeking Self-Supervised Representation Learning for Generalizable Person Re-identification"></a>Identity-Seeking Self-Supervised Representation Learning for Generalizable Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08887">http://arxiv.org/abs/2308.08887</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dcp15/isr_iccv2023_oral">https://github.com/dcp15/isr_iccv2023_oral</a></li>
<li>paper_authors: Zhaopeng Dou, Zhongdao Wang, Yali Li, Shengjin Wang</li>
<li>for: 本研究旨在从大规模视频中学习域外常见人识别表示，无需任何注释。</li>
<li>methods: 我们提出了一种寻求自我超vised表示学习（ISR）方法，通过模型实体关系为最大积分二分图问题来挖掘人识别信息。</li>
<li>results: 无需人类注释和细化，ISR方法可以在Market-1501和MSMT17上达到87.0% rank-1和56.4% rank-1的表现，分别超过最佳注释域通用方法的5.0%和19.5%。在预训练→细化方案下，ISR方法达到了MSMT17上的最佳表现，即88.4% rank-1。代码可以在GitHub上找到：<a target="_blank" rel="noopener" href="https://github.com/dcp15/ISR_ICCV2023_Oral%E3%80%82">https://github.com/dcp15/ISR_ICCV2023_Oral。</a><details>
<summary>Abstract</summary>
This paper aims to learn a domain-generalizable (DG) person re-identification (ReID) representation from large-scale videos \textbf{without any annotation}. Prior DG ReID methods employ limited labeled data for training due to the high cost of annotation, which restricts further advances. To overcome the barriers of data and annotation, we propose to utilize large-scale unsupervised data for training. The key issue lies in how to mine identity information. To this end, we propose an Identity-seeking Self-supervised Representation learning (ISR) method. ISR constructs positive pairs from inter-frame images by modeling the instance association as a maximum-weight bipartite matching problem. A reliability-guided contrastive loss is further presented to suppress the adverse impact of noisy positive pairs, ensuring that reliable positive pairs dominate the learning process. The training cost of ISR scales approximately linearly with the data size, making it feasible to utilize large-scale data for training. The learned representation exhibits superior generalization ability. \textbf{Without human annotation and fine-tuning, ISR achieves 87.0\% Rank-1 on Market-1501 and 56.4\% Rank-1 on MSMT17}, outperforming the best supervised domain-generalizable method by 5.0\% and 19.5\%, respectively. In the pre-training$\rightarrow$fine-tuning scenario, ISR achieves state-of-the-art performance, with 88.4\% Rank-1 on MSMT17. The code is at \url{https://github.com/dcp15/ISR_ICCV2023_Oral}.
</details>
<details>
<summary>摘要</summary>
ISR constructs positive pairs from inter-frame images by modeling the instance association as a maximum-weight bipartite matching problem. A reliability-guided contrastive loss is further introduced to suppress the adverse impact of noisy positive pairs, ensuring that reliable positive pairs dominate the learning process. The training cost of ISR scales approximately linearly with the data size, making it feasible to utilize large-scale data for training.The learned representation exhibits superior generalization ability. Without human annotation and fine-tuning, ISR achieves 87.0% Rank-1 on Market-1501 and 56.4% Rank-1 on MSMT17, outperforming the best supervised domain-generalizable method by 5.0% and 19.5%, respectively. In the pre-training → fine-tuning scenario, ISR achieves state-of-the-art performance, with 88.4% Rank-1 on MSMT17. The code is available at \url{https://github.com/dcp15/ISR_ICCV2023_Oral}.
</details></li>
</ul>
<hr>
<h2 id="Event-Guided-Procedure-Planning-from-Instructional-Videos-with-Text-Supervision"><a href="#Event-Guided-Procedure-Planning-from-Instructional-Videos-with-Text-Supervision" class="headerlink" title="Event-Guided Procedure Planning from Instructional Videos with Text Supervision"></a>Event-Guided Procedure Planning from Instructional Videos with Text Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08885">http://arxiv.org/abs/2308.08885</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AlanWang0o0/ISEE-E3P">https://github.com/AlanWang0o0/ISEE-E3P</a></li>
<li>paper_authors: An-Lan Wang, Kun-Yu Lin, Jia-Run Du, Jingke Meng, Wei-Shi Zheng</li>
<li>for: 这 paper 的目的是提出一种基于文本监督的视频过程规划方法，以适应视频中的指令和过程。</li>
<li>methods: 该方法首先推理出事件，然后根据事件和视频状态进行动作规划。它采用一种事件导向的规范建模方法，将事件信息 incorporate 到过程规划中。</li>
<li>results: 该方法在三个 dataset 上进行了广泛的实验，并得到了较高的效果。<details>
<summary>Abstract</summary>
In this work, we focus on the task of procedure planning from instructional videos with text supervision, where a model aims to predict an action sequence to transform the initial visual state into the goal visual state. A critical challenge of this task is the large semantic gap between observed visual states and unobserved intermediate actions, which is ignored by previous works. Specifically, this semantic gap refers to that the contents in the observed visual states are semantically different from the elements of some action text labels in a procedure. To bridge this semantic gap, we propose a novel event-guided paradigm, which first infers events from the observed states and then plans out actions based on both the states and predicted events. Our inspiration comes from that planning a procedure from an instructional video is to complete a specific event and a specific event usually involves specific actions. Based on the proposed paradigm, we contribute an Event-guided Prompting-based Procedure Planning (E3P) model, which encodes event information into the sequential modeling process to support procedure planning. To further consider the strong action associations within each event, our E3P adopts a mask-and-predict approach for relation mining, incorporating a probabilistic masking scheme for regularization. Extensive experiments on three datasets demonstrate the effectiveness of our proposed model.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们关注 instruccional 视频中的过程规划任务，其中模型需要预测从初始视觉状态到目标视觉状态的动作序列。这个任务的挑战之一是semantic gap between observed visual states and unobserved intermediate actions，即在视觉状态中存在的Semantic gap between observed contents and some action text labels in a procedure. To address this challenge, we propose a novel event-guided paradigm, which first infers events from the observed states and then plans out actions based on both the states and predicted events. Our inspiration comes from the fact that planning a procedure from an instructional video is to complete a specific event and a specific event usually involves specific actions. Based on the proposed paradigm, we contribute an Event-guided Prompting-based Procedure Planning (E3P) model, which encodes event information into the sequential modeling process to support procedure planning. To further consider the strong action associations within each event, our E3P adopts a mask-and-predict approach for relation mining, incorporating a probabilistic masking scheme for regularization. Our extensive experiments on three datasets demonstrate the effectiveness of our proposed model.
</details></li>
</ul>
<hr>
<h2 id="SRMAE-Masked-Image-Modeling-for-Scale-Invariant-Deep-Representations"><a href="#SRMAE-Masked-Image-Modeling-for-Scale-Invariant-Deep-Representations" class="headerlink" title="SRMAE: Masked Image Modeling for Scale-Invariant Deep Representations"></a>SRMAE: Masked Image Modeling for Scale-Invariant Deep Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08884">http://arxiv.org/abs/2308.08884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiming Wang, Lin Gu, Feng Lu</li>
<li>for: 提高Masked Image Modeling（MIM）模型的自动标注性能</li>
<li>methods: 使用图像缩放作为自助指示，采用SR技术设计预测头，从低分辨率启发的图像进行重建</li>
<li>results: 在ImageNet-1K任务上，SRMAE模型在400个epoch后达到82.1%的准确率，在VLR认识任务上超过DeriveNet by 1.3%，在低分辨率表情识别任务上达到74.84%的准确率，超过当前状态的FMD by 9.48%。<details>
<summary>Abstract</summary>
Due to the prevalence of scale variance in nature images, we propose to use image scale as a self-supervised signal for Masked Image Modeling (MIM). Our method involves selecting random patches from the input image and downsampling them to a low-resolution format. Our framework utilizes the latest advances in super-resolution (SR) to design the prediction head, which reconstructs the input from low-resolution clues and other patches. After 400 epochs of pre-training, our Super Resolution Masked Autoencoders (SRMAE) get an accuracy of 82.1% on the ImageNet-1K task. Image scale signal also allows our SRMAE to capture scale invariance representation. For the very low resolution (VLR) recognition task, our model achieves the best performance, surpassing DeriveNet by 1.3%. Our method also achieves an accuracy of 74.84% on the task of recognizing low-resolution facial expressions, surpassing the current state-of-the-art FMD by 9.48%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Text-Only-Training-for-Visual-Storytelling"><a href="#Text-Only-Training-for-Visual-Storytelling" class="headerlink" title="Text-Only Training for Visual Storytelling"></a>Text-Only Training for Visual Storytelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08881">http://arxiv.org/abs/2308.08881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuechen Wang, Wengang Zhou, Zhenbo Lu, Houqiang Li</li>
<li>for: 本文旨在提出一种基于文本数据的视觉叙述生成方法，以提高视觉叙述的生成能力和泛化能力。</li>
<li>methods: 本文提出了一种文本唯一训练方法，即将视觉控制集成到一个基于文本的叙述生成器中，并使用CLIP模型来实现跨模态对Alignment。此外，文本中的时间结构和全局视觉内容均被考虑在内。</li>
<li>results: 经过广泛的实验表明，本方法在VIST benchmark上表现出色，在域内和跨域设置中均显示出优于其他方法的效果。此外，人工评估和表达多样性评估也表明本方法的优势。<details>
<summary>Abstract</summary>
Visual storytelling aims to generate a narrative based on a sequence of images, necessitating both vision-language alignment and coherent story generation. Most existing solutions predominantly depend on paired image-text training data, which can be costly to collect and challenging to scale. To address this, we formulate visual storytelling as a visual-conditioned story generation problem and propose a text-only training method that separates the learning of cross-modality alignment and story generation. Our approach specifically leverages the cross-modality pre-trained CLIP model to integrate visual control into a story generator, trained exclusively on text data. Moreover, we devise a training-free visual condition planner that accounts for the temporal structure of the input image sequence while balancing global and local visual content. The distinctive advantage of requiring only text data for training enables our method to learn from external text story data, enhancing the generalization capability of visual storytelling. We conduct extensive experiments on the VIST benchmark, showcasing the effectiveness of our approach in both in-domain and cross-domain settings. Further evaluations on expression diversity and human assessment underscore the superiority of our method in terms of informativeness and robustness.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese视觉故事创作目标是通过序列图像生成叙事，需要同视语对齐和有效的故事生成。现有的大多数解决方案都倚靠了对图像文本训练数据的依赖，这可能是收集和扩展困难。为此，我们将视觉故事创作转化为视觉控制的故事生成问题，并提出了基于文本训练的文本专门学习方法。我们的方法特别利用了跨modal CLIP模型来整合视觉控制到故事生成器中，并且具有训练 libre 的视觉条件规划器，能够考虑输入图像序列的时间结构，同时均衡全局和局部视觉内容。由于我们的方法只需要文本数据进行训练，因此可以从外部文本故事数据中学习，提高了视觉故事创作的通用性。我们在 VIST benchmark 上进行了广泛的实验，展示了我们的方法在域内和跨域设置中的效果。进一步的评估表明我们的方法在表达多样性和人工评估中具有更高的有用性和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels"><a href="#Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels" class="headerlink" title="Towards Semi-supervised Learning with Non-random Missing Labels"></a>Towards Semi-supervised Learning with Non-random Missing Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08872">http://arxiv.org/abs/2308.08872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njuyued/prg4ssl-mnar">https://github.com/njuyued/prg4ssl-mnar</a></li>
<li>paper_authors: Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</li>
<li>for:  Addresses the challenging scenario of label Missing Not At Random (MNAR) in semi-supervised learning (SSL), which is ignored by existing SSL methods.</li>
<li>methods:  Proposes a class transition tracking based Pseudo-Rectifying Guidance (PRG) to maintain the model’s unbiased enthusiasm towards assigning pseudo-labels to all classes, improving the quality of pseudo-labels on both popular classes and rare classes in MNAR.</li>
<li>results:  Shows superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin.<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data. While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distributions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details>
<details>
<summary>摘要</summary>
semi-supervised learning (SSL)  addresses the problem of missing labels by leveraging unlabeled data. However, existing SSL methods primarily focus on the traditional setting and often ignore the practical and challenging scenario of label Missing Not At Random (MNAR). In MNAR, the labeled and unlabeled data have different class distributions, leading to biased label imputation and degraded performance of SSL models. To address this, we propose class transition tracking based Pseudo-Rectifying Guidance (PRG) for MNAR. We leverage the class-level guidance information obtained from the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG integrates historical information on class distribution and class transitions caused by the pseudo-rectifying procedure to ensure the model remains unbiased in assigning pseudo-labels to all classes, thereby improving the quality of pseudo-labels for both popular classes and rare classes in MNAR. Our experiments demonstrate the superior performance of PRG across various MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details></li>
</ul>
<hr>
<h2 id="Spatially-and-Spectrally-Consistent-Deep-Functional-Maps"><a href="#Spatially-and-Spectrally-Consistent-Deep-Functional-Maps" class="headerlink" title="Spatially and Spectrally Consistent Deep Functional Maps"></a>Spatially and Spectrally Consistent Deep Functional Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08871">http://arxiv.org/abs/2308.08871</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rqhuang88/Spatially-and-Spectrally-Consistent-Deep-Functional-Maps">https://github.com/rqhuang88/Spatially-and-Spectrally-Consistent-Deep-Functional-Maps</a></li>
<li>paper_authors: Mingze Sun, Shiwei Mao, Puhua Jiang, Maks Ovsjanikov, Ruqi Huang</li>
<li>for:  investigate the utility of cycle consistency in Deep Functional Maps for non-rigid shape matching</li>
<li>methods:  use spectral and point-wise representation to enforce harmony of learned maps, and independently estimate maps in both domains to alleviate over-fitting</li>
<li>results:  produce state-of-the-art results in mapping shapes under significant distortions, with superior generalization performance and accuracy in challenging tests for both near-isometric and non-isometric datasets<details>
<summary>Abstract</summary>
Cycle consistency has long been exploited as a powerful prior for jointly optimizing maps within a collection of shapes. In this paper, we investigate its utility in the approaches of Deep Functional Maps, which are considered state-of-the-art in non-rigid shape matching. We first justify that under certain conditions, the learned maps, when represented in the spectral domain, are already cycle consistent. Furthermore, we identify the discrepancy that spectrally consistent maps are not necessarily spatially, or point-wise, consistent. In light of this, we present a novel design of unsupervised Deep Functional Maps, which effectively enforces the harmony of learned maps under the spectral and the point-wise representation. By taking advantage of cycle consistency, our framework produces state-of-the-art results in mapping shapes even under significant distortions. Beyond that, by independently estimating maps in both spectral and spatial domains, our method naturally alleviates over-fitting in network training, yielding superior generalization performance and accuracy within an array of challenging tests for both near-isometric and non-isometric datasets. Codes are available at https://github.com/rqhuang88/Spatiallyand-Spectrally-Consistent-Deep-Functional-Maps.
</details>
<details>
<summary>摘要</summary>
Cycles consistency 已经被利用为一种强大的先验，用于同时优化在一个集合中的形状中的地图。在这篇论文中，我们调查了它在深度功能地图中的用途，这种技术被认为是非RIGID形状匹配领域的国际标准。我们首先证明，在某些条件下，学习的地图，当表示在спектルDomain中时，已经是循环一致的。此外，我们发现了spectrally consistent maps不一定是spatially consistent，也就是说，学习的地图不一定是点 wise一致的。在这种情况下，我们提出了一种新的无监督的深度功能地图设计，可以有效地在循环和点 wise两个 Representation下对学习的地图进行融合。通过利用循环一致性，我们的框架在面对重大扭曲时产生了国际标准的结果。此外，我们的方法独立地估算了spectral和spatial Domain下的地图，从而自然地减轻了网络训练中的过拟合问题，从而获得了在多种难度测试中的优秀性和准确性。代码可以在https://github.com/rqhuang88/Spatiallyand-Spectrally-Consistent-Deep-Functional-Maps中下载。
</details></li>
</ul>
<hr>
<h2 id="MV-ROPE-Multi-view-Constraints-for-Robust-Category-level-Object-Pose-and-Size-Estimation"><a href="#MV-ROPE-Multi-view-Constraints-for-Robust-Category-level-Object-Pose-and-Size-Estimation" class="headerlink" title="MV-ROPE: Multi-view Constraints for Robust Category-level Object Pose and Size Estimation"></a>MV-ROPE: Multi-view Constraints for Robust Category-level Object Pose and Size Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08856">http://arxiv.org/abs/2308.08856</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/greatoyster/mv-rope">https://github.com/greatoyster/mv-rope</a></li>
<li>paper_authors: Jiaqi Yang, Yucong Chen, Xiangting Meng, Chenxin Yan, Min Li, Ran Chen, Lige Liu, Tao Sun, Laurent Kneip</li>
<li>for: 该文章提出了一种基于RGB的分类水平6D对象pose和大小估计的新框架。</li>
<li>methods: 该方法利用预测正规对象坐标空间（NOCS），从RGB图像中提取了一种高效和有效的对象标准表示，而不需要额外的深度读取。</li>
<li>results: 该文章的实验结果表明，该方法在公共数据集序列上具有强大的表现，甚至与RGB-D方法相当。此外，文章还证明了该方法的通用性，在自己收集的数据集上进行了评估。Here is the translation in English:</li>
<li>for: The paper proposes a novel framework for RGB-based category-level 6D object pose and size estimation.</li>
<li>methods: The method utilizes the prediction of normalized object coordinate space (NOCS), which is an efficient and effective object canonical representation that can be extracted from RGB images, without relying on additional depth readings.</li>
<li>results: The experimental results demonstrate the strong performance of the proposed method, comparable to state-of-the-art RGB-D methods across public dataset sequences, and the method also shows good generalization ability on self-collected datasets.<details>
<summary>Abstract</summary>
We propose a novel framework for RGB-based category-level 6D object pose and size estimation. Our approach relies on the prediction of normalized object coordinate space (NOCS), which serves as an efficient and effective object canonical representation that can be extracted from RGB images. Unlike previous approaches that heavily relied on additional depth readings as input, our novelty lies in leveraging multi-view information, which is commonly available in practical scenarios where a moving camera continuously observes the environment. By introducing multi-view constraints, we can obtain accurate camera pose and depth estimation from a monocular dense SLAM framework. Additionally, by incorporating constraints on the camera relative pose, we can apply trimming strategies and robust pose averaging on the multi-view object poses, resulting in more accurate and robust estimations of category-level object poses even in the absence of direct depth readings. Furthermore, we introduce a novel NOCS prediction network that significantly improves performance. Our experimental results demonstrate the strong performance of our proposed method, even comparable to state-of-the-art RGB-D methods across public dataset sequences. Additionally, we showcase the generalization ability of our method by evaluating it on self-collected datasets.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的RGB基于分类水平6D物体姿态和大小估计框架。我们的方法基于预测正规化物体坐标空间（NOCS），这是一种高效和有效的物体标准表示，可以从RGB图像中提取出来。与之前的方法不同，我们不需要添加深度读取作为输入，而是利用多视图信息，这是在实际场景中常见的移动摄像头不断观察环境中的情况。通过引入多视图约束，我们可以从单摄 dense SLAM框架中获得高精度的相机pose和深度估计。此外，通过应用相机相对pose约束，我们可以在多视图物体姿态中进行trimming策略和稳定 pose 平均，从而在不具备直接深度读取的情况下获得更高精度和更加稳定的分类水平物体姿态估计。此外，我们还提出了一种新的NOCS预测网络，该网络有效提高了性能。我们的实验结果表明，我们提出的方法在公共数据集序列上具有强大的表现，甚至与RGB-D方法相当。此外，我们还证明了我们的方法在自主收集的数据集上进行了普适化。
</details></li>
</ul>
<hr>
<h2 id="Realistic-Full-Body-Tracking-from-Sparse-Observations-via-Joint-Level-Modeling"><a href="#Realistic-Full-Body-Tracking-from-Sparse-Observations-via-Joint-Level-Modeling" class="headerlink" title="Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling"></a>Realistic Full-Body Tracking from Sparse Observations via Joint-Level Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08855">http://arxiv.org/abs/2308.08855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zxz267/AvatarJLM">https://github.com/zxz267/AvatarJLM</a></li>
<li>paper_authors: Xiaozheng Zheng, Zhuo Su, Chao Wen, Zhou Xue, Xiaojie Jin</li>
<li>for: 快速发展的VR&#x2F;AR应用程序中实现真实的全身动作控制。</li>
<li>methods: 提出了一种两stage框架，通过使用头盔显示器和手控制器的三种跟踪信号来获取高精度和平滑的全身动作。该框架在第一个阶段显式地模型了关节级特征，并在第二个阶段通过交替的空间和时间变换块来捕捉关节级相关性。</li>
<li>results: 通过对AMASS运动数据集和真实捕捉数据进行广泛的实验，证明了我们的设计的效果，并显示了我们的提议方法可以实现比现有方法更高精度和平滑的动作。<details>
<summary>Abstract</summary>
To bridge the physical and virtual worlds for rapidly developed VR/AR applications, the ability to realistically drive 3D full-body avatars is of great significance. Although real-time body tracking with only the head-mounted displays (HMDs) and hand controllers is heavily under-constrained, a carefully designed end-to-end neural network is of great potential to solve the problem by learning from large-scale motion data. To this end, we propose a two-stage framework that can obtain accurate and smooth full-body motions with the three tracking signals of head and hands only. Our framework explicitly models the joint-level features in the first stage and utilizes them as spatiotemporal tokens for alternating spatial and temporal transformer blocks to capture joint-level correlations in the second stage. Furthermore, we design a set of loss terms to constrain the task of a high degree of freedom, such that we can exploit the potential of our joint-level modeling. With extensive experiments on the AMASS motion dataset and real-captured data, we validate the effectiveness of our designs and show our proposed method can achieve more accurate and smooth motion compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:要连接物理世界和虚拟世界，快速开发VR/AR应用中能够真实驱动3D全身人物的能力是非常重要。尽管只使用头盔显示器（HMD）和手控制器来实时跟踪身体活动是非常受限的，但是一个特殊设计的端到端神经网络可以通过学习大规模运动数据来解决这个问题。为此，我们提出了一个两stage框架，可以通过头和手三个跟踪信号来获取准确和平滑的全身运动。我们的框架明确表示 JOINT 级特征在第一个阶段，然后利用它们作为空间和时间变换块来捕捉 JOINT 级相关性。此外，我们设计了一些损失项来限制任务的自由度，以便我们可以利用我们的 JOINT 级模型的潜力。通过对 AMASS 运动数据集和实际捕捉数据进行广泛的实验，我们验证了我们的设计的有效性，并证明了我们的提议方法可以在现有方法中获得更高精度和平滑的运动。
</details></li>
</ul>
<hr>
<h2 id="Language-enhanced-RNR-Map-Querying-Renderable-Neural-Radiance-Field-maps-with-natural-language"><a href="#Language-enhanced-RNR-Map-Querying-Renderable-Neural-Radiance-Field-maps-with-natural-language" class="headerlink" title="Language-enhanced RNR-Map: Querying Renderable Neural Radiance Field maps with natural language"></a>Language-enhanced RNR-Map: Querying Renderable Neural Radiance Field maps with natural language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08854">http://arxiv.org/abs/2308.08854</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/intelligolabs/Le-RNR-Map">https://github.com/intelligolabs/Le-RNR-Map</a></li>
<li>paper_authors: Francesco Taioli, Federico Cunico, Federico Girella, Riccardo Bologna, Alessandro Farinelli, Marco Cristani</li>
<li>for: 这个论文是为了提供一种语言增强的可 Renderable Neural Radiance Map（Le-RNR-Map），用于视觉导航，并且可以通过自然语言查询提示来搜索。</li>
<li>methods: 该论文使用了RNR-Map，一种基于格子结构的秘密码，每个像素都有一个来自图像观察的 latent codes，可以将图像渲染到相应的Camera pose。此外，该论文还使用了CLIP-based embedding latent codes，允许通过自然语言查询来搜索。</li>
<li>results: 该论文通过单个和多个对象搜索的实验，证明了Le-RNR-Map的效果。此外，该论文还 investigate了这个地图与大型自然语言模型的相容性，并且发现了这个地图可以帮助解决”可用性查询”问题。<details>
<summary>Abstract</summary>
We present Le-RNR-Map, a Language-enhanced Renderable Neural Radiance map for Visual Navigation with natural language query prompts. The recently proposed RNR-Map employs a grid structure comprising latent codes positioned at each pixel. These latent codes, which are derived from image observation, enable: i) image rendering given a camera pose, since they are converted to Neural Radiance Field; ii) image navigation and localization with astonishing accuracy. On top of this, we enhance RNR-Map with CLIP-based embedding latent codes, allowing natural language search without additional label data. We evaluate the effectiveness of this map in single and multi-object searches. We also investigate its compatibility with a Large Language Model as an "affordance query resolver". Code and videos are available at https://intelligolabs.github.io/Le-RNR-Map/
</details>
<details>
<summary>摘要</summary>
我们介绍Le-RNR-Map，一种语言增强的可 Renderable Neural Radiance Map 用于视觉导航，通过自然语言查询提示。最近提出的RNR-Map使用网格结构，每个像素位置具有秘密码。这些秘密码，从图像观察中 derivation，允许：i) 根据摄像头pose进行图像渲染; ii) 图像导航和定位准确。此外，我们在RNR-Map中添加了CLIP基于的嵌入代码，使得不需要额外标注数据进行自然语言搜索。我们评估了这个地图在单个和多个对象搜索中的效果，以及它与大型语言模型作为"能力查询解决方案"的 compatibilty。代码和视频可以在https://intelligolabs.github.io/Le-RNR-Map/ 中下载。
</details></li>
</ul>
<hr>
<h2 id="Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays"><a href="#Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays" class="headerlink" title="Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays"></a>Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08853">http://arxiv.org/abs/2308.08853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Hong, Tianjie Dai, Jiangchao Yao, Ya Zhang, Yanfeng Wang</li>
<li>for: 本文主要针对的是用机器学习算法进行胸部X射线图像的临床分类，特别是面临长尾和多标签等挑战。</li>
<li>methods: 本文提出了一些新的设计方案，包括数据扩充、特征提取器、分类器设计、损失函数重新权衡、外部数据补充等，以提高CXR诊断的性能。</li>
<li>results: 本文通过对多种设计方案的实践和简单的测试数据扩充以及 ensemble 技术，最终达到了ICCV CVAMD 2023 CXR-LT Competition 的测试集上的0.349 mAP值，排名前五。<details>
<summary>Abstract</summary>
Clinical classification of chest radiography is particularly challenging for standard machine learning algorithms due to its inherent long-tailed and multi-label nature. However, few attempts take into account the coupled challenges posed by both the class imbalance and label co-occurrence, which hinders their value to boost the diagnosis on chest X-rays (CXRs) in the real-world scenarios. Besides, with the prevalence of pretraining techniques, how to incorporate these new paradigms into the current framework lacks of the systematical study. This technical report presents a brief description of our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness for CXR diagnosis with the integration of several advanced designs about data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details>
<details>
<summary>摘要</summary>
严重疾病分类从骨盆 X 光图像中 particullay challenging，特别是由于其内在的长尾和多标签性。然而，有很少的尝试把承载这两个挑战：分类倾度不均和标签共occurrence。这些挑战限制了机器学习算法在实际应用中的价值。此外，随着预训练技术的普及，如何将这些新的思维方式集成到当前框架中，尚未得到系统性的研究。本技报报告 briefly describes our solution in the ICCV CVAMD 2023 CXR-LT Competition. we empirically explored the effectiveness of CXR diagnosis with the integration of several advanced designs, including data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Multi-modal-Learning-for-Body-Language-Recognition-and-Generation"><a href="#A-Survey-on-Deep-Multi-modal-Learning-for-Body-Language-Recognition-and-Generation" class="headerlink" title="A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation"></a>A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08849">http://arxiv.org/abs/2308.08849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wentaol86/awesome-body-language">https://github.com/wentaol86/awesome-body-language</a></li>
<li>paper_authors: Li Liu, Lufei Gao, Wentao Lei, Fengji Ma, Xiaotian Lin, Jinting Wang</li>
<li>for: 这 paper 主要是为了探讨深度多Modal学习在不同的身体语言（BL）生成和识别方面的应用。</li>
<li>methods: 这 paper 使用了深度多Modal学习技术来分析和理解不同的BL，包括手语（SL）、句子语音（CS）、同时说话（CoS）和头部语音（TH）等。</li>
<li>results: 这 paper 对这些多Modal approaches的评估和比较，并提出了未来研究的方向，如自然语言处理、多Modal学习和大规模预训练模型的应用。<details>
<summary>Abstract</summary>
Body language (BL) refers to the non-verbal communication expressed through physical movements, gestures, facial expressions, and postures. It is a form of communication that conveys information, emotions, attitudes, and intentions without the use of spoken or written words. It plays a crucial role in interpersonal interactions and can complement or even override verbal communication. Deep multi-modal learning techniques have shown promise in understanding and analyzing these diverse aspects of BL. The survey emphasizes their applications to BL generation and recognition. Several common BLs are considered i.e., Sign Language (SL), Cued Speech (CS), Co-speech (CoS), and Talking Head (TH), and we have conducted an analysis and established the connections among these four BL for the first time. Their generation and recognition often involve multi-modal approaches. Benchmark datasets for BL research are well collected and organized, along with the evaluation of SOTA methods on these datasets. The survey highlights challenges such as limited labeled data, multi-modal learning, and the need for domain adaptation to generalize models to unseen speakers or languages. Future research directions are presented, including exploring self-supervised learning techniques, integrating contextual information from other modalities, and exploiting large-scale pre-trained multi-modal models. In summary, this survey paper provides a comprehensive understanding of deep multi-modal learning for various BL generations and recognitions for the first time. By analyzing advancements, challenges, and future directions, it serves as a valuable resource for researchers and practitioners in advancing this field. n addition, we maintain a continuously updated paper list for deep multi-modal learning for BL recognition and generation: https://github.com/wentaoL86/awesome-body-language.
</details>
<details>
<summary>摘要</summary>
Body language (BL) 指的是通过物理运动、姿势、表情和姿态来表达的非语言通信。它是人际交流中的一种重要的沟通方式，可以补充或甚至覆盖语言交流。深入的多Modal学习技术已经在理解和分析这些多种非语言通信方面表现出了承诺。本文件尽可能地概括了这些多Modal学习技术的应用和挑战，并提出了未来研究的方向。在本文中，我们分析了四种常见的BL：手语（SL）、笔记法（CS）、协调说话（CoS）和对话头（TH），并对这些四种BL之间的连接进行了分析。其生成和识别通常需要多Modal的方法。我们也收集了一些标准的BL数据集，并对这些数据集进行了评估。Despite the progress made, there are still several challenges that need to be addressed, such as limited labeled data, multi-modal learning, and the need for domain adaptation to generalize models to unseen speakers or languages. In the future, we can explore self-supervised learning techniques, integrate contextual information from other modalities, and exploit large-scale pre-trained multi-modal models.总之，本文提供了深入的多Modal学习技术在不同的BL生成和识别方面的首次概括。通过分析进步、挑战和未来方向，它将成为研究和实践者在这个领域的有价值资源。此外，我们还维护一份continuously更新的BL生成和识别相关文献列表，可以在 GitHub上找到：https://github.com/wentaoL86/awesome-body-language。
</details></li>
</ul>
<hr>
<h2 id="ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space"><a href="#ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space" class="headerlink" title="ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space"></a>ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08830">http://arxiv.org/abs/2308.08830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Spieker, Wenqi Huang, Hannah Eichhorn, Jonathan Stelter, Kilian Weiss, Veronika A. Zimmer, Rickmer F. Braren, Dimitrios C. Karampinos, Kerstin Hammernik, Julia A. Schnabel</li>
<li>for: 实现静止照片与运动照片的混合，解决运动引起的影像污染问题。</li>
<li>methods: 使用神经网络学习几何空间中的几何函数，并将这个函数与测量点和呼吸访问信号组合，实现无推印影像重建。</li>
<li>results: 比标准运动解析技术高效，并提供了一个可能性解决运动引起的影像污染问题的解析方法。<details>
<summary>Abstract</summary>
Motion-resolved reconstruction for abdominal magnetic resonance imaging (MRI) remains a challenge due to the trade-off between residual motion blurring caused by discretized motion states and undersampling artefacts. In this work, we propose to generate blurring-free motion-resolved abdominal reconstructions by learning a neural implicit representation directly in k-space (NIK). Using measured sampling points and a data-derived respiratory navigator signal, we train a network to generate continuous signal values. To aid the regularization of sparsely sampled regions, we introduce an additional informed correction layer (ICo), which leverages information from neighboring regions to correct NIK's prediction. Our proposed generative reconstruction methods, NIK and ICoNIK, outperform standard motion-resolved reconstruction techniques and provide a promising solution to address motion artefacts in abdominal MRI.
</details>
<details>
<summary>摘要</summary>
对于腹部磁共振成像（MRI）中的运动解像仍然是一个挑战，因为存在归一化运动态论和抽样缺陷之间的质量冲突。在这种工作中，我们提议通过直接在k空间学习神经网络（NIK）来生成无抖的运动解像腹部重建。使用测量的抽样点和数据驱动的呼吸导航信号，我们训练了一个网络来生成连续的信号值。为了帮助稀疏抽样区域的正则化，我们引入了一个加 informations层（ICo），该层利用邻近区域的信息来修正 NIK 的预测。我们的提出的生成重建方法，NIK 和 ICoNIK，超过标准的运动解像重建技术，并提供了解决腹部 MRI 中运动artefacts的可能性。
</details></li>
</ul>
<hr>
<h2 id="Fast-Inference-and-Update-of-Probabilistic-Density-Estimation-on-Trajectory-Prediction"><a href="#Fast-Inference-and-Update-of-Probabilistic-Density-Estimation-on-Trajectory-Prediction" class="headerlink" title="Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction"></a>Fast Inference and Update of Probabilistic Density Estimation on Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08824">http://arxiv.org/abs/2308.08824</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meaten/flowchain-iccv2023">https://github.com/meaten/flowchain-iccv2023</a></li>
<li>paper_authors: Takahiro Maeda, Norimichi Ukita</li>
<li>For: 本文提出了一种新的正规流基本拟合方法（FlowChain），用于预测物体的运动轨迹。这种方法能够快速计算并准确地估计概率密度，这是安全关键应用如自动驾驶和社交机器人所需的。* Methods:  FlowChain 是一个栈式的条件连续分布（CIF），可以表示概率密度的表达。这种表达可以进行分析计算，比较快速，而且更准确于 Gaussian 混合模型。此外，FlowChain 还允许快速更新估计概率密度，只需要在新的观测位置基础上， reuse 流变换和其对数Jacobian，可以在一毫秒内完成。* Results: 实验结果显示，我们的 FlowChain 在过去方法中实现了最佳的轨迹预测精度。此外，我们的 FlowChain 还在概率密度估计方面表现出了优势，具有更高的准确性和更快的计算速度。我们的代码可以在 <a target="_blank" rel="noopener" href="https://github.com/meaten/FlowChain-ICCV2023">https://github.com/meaten/FlowChain-ICCV2023</a> 上下载。<details>
<summary>Abstract</summary>
Safety-critical applications such as autonomous vehicles and social robots require fast computation and accurate probability density estimation on trajectory prediction. To address both requirements, this paper presents a new normalizing flow-based trajectory prediction model named FlowChain. FlowChain is a stack of conditional continuously-indexed flows (CIFs) that are expressive and allow analytical probability density computation. This analytical computation is faster than the generative models that need additional approximations such as kernel density estimation. Moreover, FlowChain is more accurate than the Gaussian mixture-based models due to fewer assumptions on the estimated density. FlowChain also allows a rapid update of estimated probability densities. This update is achieved by adopting the \textit{newest observed position} and reusing the flow transformations and its log-det-jacobians that represent the \textit{motion trend}. This update is completed in less than one millisecond because this reuse greatly omits the computational cost. Experimental results showed our FlowChain achieved state-of-the-art trajectory prediction accuracy compared to previous methods. Furthermore, our FlowChain demonstrated superiority in the accuracy and speed of density estimation. Our code is available at \url{https://github.com/meaten/FlowChain-ICCV2023}
</details>
<details>
<summary>摘要</summary>
安全关键应用，如自动驾驶车和社交机器人，需要快速计算和准确的概率密度估计。为解决这两个需求，这篇论文提出了一种新的正规流基本型 trajectory prediction 模型，名为 FlowChain。FlowChain 是一个堆叠的 conditional continuously-indexed flows (CIFs)，它们是表达力强的，并允许analytical probability density computation。这种analytical computation比 generative models 需要更多的 Approximation，如 kernel density estimation 更快。此外，FlowChain 比 Gaussian mixture-based models 更准确，因为它们对 estimated density 假设的更少。FlowChain 还允许快速更新 estimated probability densities。这个更新通过 adopting the 最新观测位置 和 reuse flow transformations 和其 log-det-jacobians 来完成，这个计算成本很低。实验结果表明我们的 FlowChain 在前一代方法的基础上实现了状态机器人 trajectory prediction 的最佳准确性。此外，我们的 FlowChain 还在概率密度估计的准确性和速度方面表现出了优势。我们的代码可以在 <https://github.com/meaten/FlowChain-ICCV2023> 上找到。
</details></li>
</ul>
<hr>
<h2 id="MixBag-Bag-Level-Data-Augmentation-for-Learning-from-Label-Proportions"><a href="#MixBag-Bag-Level-Data-Augmentation-for-Learning-from-Label-Proportions" class="headerlink" title="MixBag: Bag-Level Data Augmentation for Learning from Label Proportions"></a>MixBag: Bag-Level Data Augmentation for Learning from Label Proportions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08822">http://arxiv.org/abs/2308.08822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takanori Asanomi, Shinnosuke Matsuo, Daiki Suehiro, Ryoma Bise</li>
<li>for: 本研究旨在提出一种基于批处理的数据增强方法，以提高无监督学习中的实例级别分类器。</li>
<li>methods: 我们提出了一种基于实验观察的关键观察，即在固定总数据量下，增加标注批处理可以提高实例级别分类精度。此外，我们还提出了基于统计理论的信息量损失函数，以便有效地利用扩充后的批处理。</li>
<li>results: 实验结果表明，我们的方法可以与现有的实例级别数据增强方法相比，在减小损失函数下达到更高的精度。此外，我们的方法还可以与其他无监督学习方法结合使用，以提高分类器的泛化能力。<details>
<summary>Abstract</summary>
Learning from label proportions (LLP) is a promising weakly supervised learning problem. In LLP, a set of instances (bag) has label proportions, but no instance-level labels are given. LLP aims to train an instance-level classifier by using the label proportions of the bag. In this paper, we propose a bag-level data augmentation method for LLP called MixBag, based on the key observation from our preliminary experiments; that the instance-level classification accuracy improves as the number of labeled bags increases even though the total number of instances is fixed. We also propose a confidence interval loss designed based on statistical theory to use the augmented bags effectively. To the best of our knowledge, this is the first attempt to propose bag-level data augmentation for LLP. The advantage of MixBag is that it can be applied to instance-level data augmentation techniques and any LLP method that uses the proportion loss. Experimental results demonstrate this advantage and the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
学习标签比例（LLP）是一个有前途的弱监督学习问题。在LLP中，一个集合（袋）有标签比例，但没有每个实例的标签。LLP的目标是使用袋的标签比例来训练每个实例的分类器。在这篇论文中，我们提出了一种基于先前实验的观察的袋级数据增强方法called MixBag，以及基于统计理论的自信度范围损失。这是我们知道的第一个提出袋级数据增强的尝试。MixBag的优点是可以与实例级数据增强技术结合使用，并且可以与任何使用比例损失的LLP方法结合使用。实验结果表明了MixBag的优点和效果。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution"><a href="#End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution" class="headerlink" title="End-to-end Alternating Optimization for Real-World Blind Super Resolution"></a>End-to-end Alternating Optimization for Real-World Blind Super Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08816">http://arxiv.org/abs/2308.08816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/greatlog/realdan">https://github.com/greatlog/realdan</a></li>
<li>paper_authors: Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan</li>
<li>for: 这篇论文主要针对的是做出高清度图像的简化超解像（SR），即从低解度图像（LR）中恢复高解度图像（HR）。</li>
<li>methods: 这篇论文提出了一种新的SR方法，即通过alternating optimization算法，将LR图像的简化和SR问题协同解决。具体来说，这种方法包括两个卷积神经网络：一个用于restore SR图像（Restorer），另一个用于估计LR图像的简化（Estimator）。这两个模块之间进行了循环的优化，以实现一个端到端可训练的网络。</li>
<li>results: 根据实验结果，这种方法可以与当前最佳方法相比，在SR问题上具有更高的精度和更好的视觉效果。<details>
<summary>Abstract</summary>
Blind Super-Resolution (SR) usually involves two sub-problems: 1) estimating the degradation of the given low-resolution (LR) image; 2) super-resolving the LR image to its high-resolution (HR) counterpart. Both problems are ill-posed due to the information loss in the degrading process. Most previous methods try to solve the two problems independently, but often fall into a dilemma: a good super-resolved HR result requires an accurate degradation estimation, which however, is difficult to be obtained without the help of original HR information. To address this issue, instead of considering these two problems independently, we adopt an alternating optimization algorithm, which can estimate the degradation and restore the SR image in a single model. Specifically, we design two convolutional neural modules, namely \textit{Restorer} and \textit{Estimator}. \textit{Restorer} restores the SR image based on the estimated degradation, and \textit{Estimator} estimates the degradation with the help of the restored SR image. We alternate these two modules repeatedly and unfold this process to form an end-to-end trainable network. In this way, both \textit{Restorer} and \textit{Estimator} could get benefited from the intermediate results of each other, and make each sub-problem easier. Moreover, \textit{Restorer} and \textit{Estimator} are optimized in an end-to-end manner, thus they could get more tolerant of the estimation deviations of each other and cooperate better to achieve more robust and accurate final results. Extensive experiments on both synthetic datasets and real-world images show that the proposed method can largely outperform state-of-the-art methods and produce more visually favorable results. The codes are rleased at \url{https://github.com/greatlog/RealDAN.git}.
</details>
<details>
<summary>摘要</summary>
通常，盲目超解像（SR）问题包括两个互相关联的优化问题：1）估计给出的低分辨率（LR）图像的劣化程度; 2）将LR图像提升到其高分辨率（HR）对应的图像。两个问题都是不定的，因为升级过程中的信息损失。大多数前一代方法通常会解决这两个问题独立，但经常陷入一个困境：一个好的HR图像需要一个准确的劣化估计，但是不可以不带原始HR信息来获得这个估计。为解决这个问题，我们采用了一种alternating optimization算法，可以同时估计劣化和 restaure SR图像。我们设计了两个卷积神经网络模块：namely \textit{Restorer}和\textit{Estimator}。\textit{Restorer}使用估计的劣化来还原SR图像，而\textit{Estimator}使用还原后的SR图像来估计劣化。我们在这两个模块之间进行了循环的交互，并将这个过程拓展成一个可训练的结束到终结点的网络。这样，\textit{Restorer}和\textit{Estimator}可以互相帮助，使得每个优化问题变得更加容易。此外，\textit{Restorer}和\textit{Estimator}在结束到终结点的training中被优化，因此它们可以更快地适应彼此的估计偏差，并更好地合作以实现更加稳定和准确的最终结果。广泛的实验表明，我们的方法可以大幅超越当前的状态控制方法，并生成更加视觉愉悦的结果。代码可以在\url{https://github.com/greatlog/RealDAN.git}中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction"><a href="#A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction" class="headerlink" title="A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction"></a>A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08812">http://arxiv.org/abs/2308.08812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchar Palit, Sandika Biswas</li>
<li>for: 单张图像三维重建任务是一项研究挑战，旨在从单视图图像中预测物体的三维形状。这项任务需要大量数据采集，以预测可见和遮盖的部分。</li>
<li>methods: 我们提议使用 continual learning 的方法，并使用 Variational Priors 来设计模型，以便在新类之后仍然可以reasonably重建先前所见的类。Variational Priors 表示抽象形状，并避免忘记，而 saliency maps 保留物体特征，占用较少的内存。</li>
<li>results: 经过仔细的实验表明，我们的方法可以与已知方法相比， both quantitatively and qualitatively 显示出竞争力。<details>
<summary>Abstract</summary>
Single-image 3D reconstruction is a research challenge focused on predicting 3D object shapes from single-view images. This task requires significant data acquisition to predict both visible and occluded portions of the shape. Furthermore, learning-based methods face the difficulty of creating a comprehensive training dataset for all possible classes. To this end, we propose a continual learning-based 3D reconstruction method where our goal is to design a model using Variational Priors that can still reconstruct the previously seen classes reasonably even after training on new classes. Variational Priors represent abstract shapes and combat forgetting, whereas saliency maps preserve object attributes with less memory usage. This is vital due to resource constraints in storing extensive training data. Additionally, we introduce saliency map-based experience replay to capture global and distinct object features. Thorough experiments show competitive results compared to established methods, both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
单图三维重建是一项研究挑战，旨在根据单个图像预测三维物体形状。这项任务需要大量数据收集，以预测可见和遮挡部分的形状。学习基于方法则面临创建全面训练数据集的挑战，以涵盖所有可能的类型。为此，我们提议一种逐步学习基于Variational Priors的三维重建方法，其目标是在训练新类后，仍能reasonably重建先前所见的类。Variational Priors表示抽象形态，防止忘记，而saliency maps保留物体特征，占用内存更少。这对于资源受限的存储大量训练数据非常重要。此外，我们引入了saliency map基于经验回放，以捕捉全球和特定物体特征。经过广泛的实验，我们的方法与已知方法相比，具有竞争性的Result。
</details></li>
</ul>
<hr>
<h2 id="Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts"><a href="#Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts" class="headerlink" title="Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts"></a>Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08810">http://arxiv.org/abs/2308.08810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun</li>
<li>for: 这个研究旨在实现批量执行时间适应（Test-time adaptation），将预训模型适应目标领域中的数据分布。</li>
<li>methods: 我们提出了一个新的标签迁移适应器，可以与现有的TTA方法结合使用，实现标签迁移的处理。我们估计目标领域的标签分布，然后将其 feed 到标签迁移适应器中，以生成适合目标领域的标签参数。</li>
<li>results: 我们通过广泛的实验表明，将我们的策略与TTA方法结合，可以在标签和 covariate 迁移时获得显著的性能提升。<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Self-distillation-Regularized-Connectionist-Temporal-Classification-Loss-for-Text-Recognition-A-Simple-Yet-Effective-Approach"><a href="#Self-distillation-Regularized-Connectionist-Temporal-Classification-Loss-for-Text-Recognition-A-Simple-Yet-Effective-Approach" class="headerlink" title="Self-distillation Regularized Connectionist Temporal Classification Loss for Text Recognition: A Simple Yet Effective Approach"></a>Self-distillation Regularized Connectionist Temporal Classification Loss for Text Recognition: A Simple Yet Effective Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08806">http://arxiv.org/abs/2308.08806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyin Zhang, Ning Lu, Minghui Liao, Yongshuai Huang, Cheng Li, Min Wang, Wei Peng</li>
<li>for: 提高文本识别模型的准确率，不增加Extra参数或训练阶段。</li>
<li>methods: 提议使用自适应定制的CTC损失函数（DCTC损失），通过带有帧级别的正则化项来强调个体监督，并通过最大化 posteriori 的潜在对齐问题来解决在涨化中的矛盾问题。</li>
<li>results: 对于公共 benchmark 进行了广泛的实验，结果显示，使用 DCTC 损失可以提高文本识别模型的准确率，最高提升达 2.6%，而不增加任何不良影响。<details>
<summary>Abstract</summary>
Text recognition methods are gaining rapid development. Some advanced techniques, e.g., powerful modules, language models, and un- and semi-supervised learning schemes, consecutively push the performance on public benchmarks forward. However, the problem of how to better optimize a text recognition model from the perspective of loss functions is largely overlooked. CTC-based methods, widely used in practice due to their good balance between performance and inference speed, still grapple with accuracy degradation. This is because CTC loss emphasizes the optimization of the entire sequence target while neglecting to learn individual characters. We propose a self-distillation scheme for CTC-based model to address this issue. It incorporates a framewise regularization term in CTC loss to emphasize individual supervision, and leverages the maximizing-a-posteriori of latent alignment to solve the inconsistency problem that arises in distillation between CTC-based models. We refer to the regularized CTC loss as Distillation Connectionist Temporal Classification (DCTC) loss. DCTC loss is module-free, requiring no extra parameters, longer inference lag, or additional training data or phases. Extensive experiments on public benchmarks demonstrate that DCTC can boost text recognition model accuracy by up to 2.6%, without any of these drawbacks.
</details>
<details>
<summary>摘要</summary>
文本识别方法在快速发展中。一些先进技术，如强大的模块、语言模型和不监督学习方法， consecutively 提高了公共测试底板上的性能。然而，如何更好地优化一个文本识别模型，从损失函数的角度来看，几乎被忽略。基于CTC的方法，由于其在实践中的良好平衡性和推理速度，仍然受到精度下降的困扰。这是因为CTC损失函数强调整合整个序列目标，而忽略学习个体字符。我们提出了一种自适应方案，即Distillation Connectionist Temporal Classification（DCTC）损失函数。DCTC损失函数包含了帧级别正则化项，以强调个体监督，并利用最大 posteriori的潜在对齐问题来解决在液化中的不一致问题。DCTC损失函数是模块化的，无需额外参数、更长的推理时间或额外的训练数据或阶段。广泛的实验表明，DCTC可以提高文本识别模型的精度，最高提高2.6%，而无需这些缺点。
</details></li>
</ul>
<hr>
<h2 id="Deep-Ear-Biometrics-for-Gender-Classification"><a href="#Deep-Ear-Biometrics-for-Gender-Classification" class="headerlink" title="Deep Ear Biometrics for Gender Classification"></a>Deep Ear Biometrics for Gender Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08797">http://arxiv.org/abs/2308.08797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ritwiz Singh, Keshav Kashyap, Rajesh Mukherjee, Asish Bera, Mamata Dalui Chakraborty</li>
<li>for: 人类性别分类 based on 生物特征, 特别是 Computer Vision 领域的一个重要问题, 因为它有很多应用场景。</li>
<li>methods: 我们使用了深度卷积神经网络 (CNN) 模型来自动地分类人类性别, 使用了 EarVN1.0 耳朵数据集进行评估。</li>
<li>results: 我们的模型达到了 93% 的准确率。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Human gender classification based on biometric features is a major concern for computer vision due to its vast variety of applications. The human ear is popular among researchers as a soft biometric trait, because it is less affected by age or changing circumstances, and is non-intrusive. In this study, we have developed a deep convolutional neural network (CNN) model for automatic gender classification using the samples of ear images. The performance is evaluated using four cutting-edge pre-trained CNN models. In terms of trainable parameters, the proposed technique requires significantly less computational complexity. The proposed model has achieved 93% accuracy on the EarVN1.0 ear dataset.
</details>
<details>
<summary>摘要</summary>
人类性别分类基于生物特征是计算机视觉领域的主要问题，由于它的广泛应用领域。人耳是研究人员的首选软生物特征之一，因为它对年龄或变化情况的影响相对较少，非侵入式。在本研究中，我们开发了一种深度卷积神经网络（CNN）模型，用于自动性别分类，使用耳架图像样本。我们使用四种最新的预训练CNN模型进行评估性能。与传统模型相比，我们的方法具有更少的计算复杂性。在 EarVN1.0 耳架数据集上，我们的模型达到了 93% 的准确率。
</details></li>
</ul>
<hr>
<h2 id="Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning"><a href="#Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning" class="headerlink" title="Environment Diversification with Multi-head Neural Network for Invariant Learning"></a>Environment Diversification with Multi-head Neural Network for Invariant Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08778">http://arxiv.org/abs/2308.08778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joe0123/EDNIL">https://github.com/joe0123/EDNIL</a></li>
<li>paper_authors: Bo-Wei Huang, Keng-Te Liao, Chang-Sheng Kao, Shou-De Lin</li>
<li>for: 这篇论文旨在提出一个不需要先知道环境或强制假设的普遍学习框架，以提高神经网络模型对于分布类型的适应能力。</li>
<li>methods: 这个框架包含了一个多头神经网络，用于吸收数据偏见。</li>
<li>results: 该框架不需要先知道环境或强制假设，并且可以实现模型对于分布类型的适应。<details>
<summary>Abstract</summary>
Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.
</details>
<details>
<summary>摘要</summary>
神经网络经常通过Empirical Risk Minimization（ERM）进行训练；然而，存在训练和测试分布之间的偏移会导致性能下降。为解决这个问题，一种研究方向——不变学习（Invariant Learning）——已经被提出，以抽取不受分布变化影响的特征。本研究提出了EDNIL框架，包括多头神经网络来吸收数据偏好。我们证明了这种框架不需要先知环境或强ASSUME预训练模型。此外，我们还发现了该算法与最近的变异和不变特征研究有理论上的连接。最后，我们通过实验表明，使用EDNIL进行训练的模型在分布变化时的性能更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-In-paint-Domain-Adaptive-Shape-Completion-for-3D-Organ-Segmentation"><a href="#Learning-to-In-paint-Domain-Adaptive-Shape-Completion-for-3D-Organ-Segmentation" class="headerlink" title="Learning to In-paint: Domain Adaptive Shape Completion for 3D Organ Segmentation"></a>Learning to In-paint: Domain Adaptive Shape Completion for 3D Organ Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08775">http://arxiv.org/abs/2308.08775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingjin Chen, Yongkang He, Yongyi Lu, Zhijing Yang</li>
<li>for: 本研究旨在把Shape信息Explicitly incorporated into current 3D organ segmentation models.</li>
<li>methods: 我们采用Masked Label Mask Modeling (MLM)方法，通过学习mask token来完成Label mask的组织器。此外，我们还提出了一种新的Shape-aware self-distillation方法，用于在Target上传递MLM shape知识。</li>
<li>results: 我们在五个公共organ segmentation dataset上进行了广泛的实验，并得到了至少1.2点的Dice分数提升，证明了我们的方法在难以控制的预测领域中的效果。<details>
<summary>Abstract</summary>
We aim at incorporating explicit shape information into current 3D organ segmentation models. Different from previous works, we formulate shape learning as an in-painting task, which is named Masked Label Mask Modeling (MLM). Through MLM, learnable mask tokens are fed into transformer blocks to complete the label mask of organ. To transfer MLM shape knowledge to target, we further propose a novel shape-aware self-distillation with both in-painting reconstruction loss and pseudo loss. Extensive experiments on five public organ segmentation datasets show consistent improvements over prior arts with at least 1.2 points gain in the Dice score, demonstrating the effectiveness of our method in challenging unsupervised domain adaptation scenarios including: (1) In-domain organ segmentation; (2) Unseen domain segmentation and (3) Unseen organ segmentation. We hope this work will advance shape analysis and geometric learning in medical imaging.
</details>
<details>
<summary>摘要</summary>
我们目标是将显式形态信息integrated到当前3D器官分割模型中。与之前的工作不同，我们将形态学习转换为一个填充任务，称为掩码标签掩码模型（MLM）。通过MLM，学习的掩码标签被传递到转换块中，以完成器官的标签掩码。为将MLM形态知识传递到目标上，我们进一步提议一种新的形态自适应自我热化，包括填充重建损失和假损失。我们在五个公共器官分割数据集上进行了广泛的实验，并示出了与之前的艺术品相比至少1.2点的Dice分数提升，这说明了我们的方法在不可预测的领域适应场景中的效果，包括：（1）本地器官分割；（2）未看到的频谱分割和（3）未看到的器官分割。我们希望这项工作能够推动医学影像中的形态分析和几何学学习。
</details></li>
</ul>
<hr>
<h2 id="URL-Combating-Label-Noise-for-Lung-Nodule-Malignancy-Grading"><a href="#URL-Combating-Label-Noise-for-Lung-Nodule-Malignancy-Grading" class="headerlink" title="URL: Combating Label Noise for Lung Nodule Malignancy Grading"></a>URL: Combating Label Noise for Lung Nodule Malignancy Grading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08772">http://arxiv.org/abs/2308.08772</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/axz520/URL">https://github.com/axz520/URL</a></li>
<li>paper_authors: Xianze Ai, Zehui Liao, Yong Xia<br>for:This paper focuses on the problem of label noise in lung nodule malignancy grading datasets and proposes a new framework called URL to tackle this issue.methods:The proposed URL framework consists of two stages: SCL and MU. SCL uses supervised contrastive learning to learn better representations, while MU generates pseudo-labels and uses temporal ensembling to obtain memory pseudo-labels that supervise the model training.results:Experiments on the LIDC-IDRI dataset show that the proposed URL framework outperforms other competing methods, demonstrating its effectiveness in handling label noise and modeling the ordinal relation among classes.<details>
<summary>Abstract</summary>
Due to the complexity of annotation and inter-annotator variability, most lung nodule malignancy grading datasets contain label noise, which inevitably degrades the performance and generalizability of models. Although researchers adopt the label-noise-robust methods to handle label noise for lung nodule malignancy grading, they do not consider the inherent ordinal relation among classes of this task. To model the ordinal relation among classes to facilitate tackling label noise in this task, we propose a Unimodal-Regularized Label-noise-tolerant (URL) framework. Our URL contains two stages, the Supervised Contrastive Learning (SCL) stage and the Memory pseudo-labels generation and Unimodal regularization (MU) stage. In the SCL stage, we select reliable samples and adopt supervised contrastive learning to learn better representations. In the MU stage, we split samples with multiple annotations into multiple samples with a single annotation and shuffle them into different batches. To handle label noise, pseudo-labels are generated using the similarity between each sample and the central feature of each class, and temporal ensembling is used to obtain memory pseudo-labels that supervise the model training. To model the ordinal relation, we introduce unimodal regularization to keep the ordinal relation among classes in the predictions. Moreover, each lung nodule is characterized by three orthographic views. Experiments conducted on the LIDC-IDRI dataset indicate the superiority of our URL over other competing methods. Code is available at https://github.com/axz520/UR.
</details>
<details>
<summary>摘要</summary>
Due to the complexity of annotation and inter-annotator variability, most lung nodule malignancy grading datasets contain label noise, which inevitably degrades the performance and generalizability of models. Although researchers adopt label-noise-robust methods to handle label noise for lung nodule malignancy grading, they do not consider the inherent ordinal relation among classes of this task. To model the ordinal relation among classes to facilitate tackling label noise in this task, we propose a Unimodal-Regularized Label-noise-tolerant (URL) framework. Our URL contains two stages, the Supervised Contrastive Learning (SCL) stage and the Memory pseudo-labels generation and Unimodal regularization (MU) stage. In the SCL stage, we select reliable samples and adopt supervised contrastive learning to learn better representations. In the MU stage, we split samples with multiple annotations into multiple samples with a single annotation and shuffle them into different batches. To handle label noise, pseudo-labels are generated using the similarity between each sample and the central feature of each class, and temporal ensembling is used to obtain memory pseudo-labels that supervise the model training. To model the ordinal relation, we introduce unimodal regularization to keep the ordinal relation among classes in the predictions. Moreover, each lung nodule is characterized by three orthographic views. Experiments conducted on the LIDC-IDRI dataset indicate the superiority of our URL over other competing methods. Code is available at https://github.com/axz520/UR.Note: The translation is in Simplified Chinese, which is one of the two standard Chinese languages used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Chat-3D-Data-efficiently-Tuning-Large-Language-Model-for-Universal-Dialogue-of-3D-Scenes"><a href="#Chat-3D-Data-efficiently-Tuning-Large-Language-Model-for-Universal-Dialogue-of-3D-Scenes" class="headerlink" title="Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes"></a>Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08769">http://arxiv.org/abs/2308.08769</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Chat-3D/Chat-3D">https://github.com/Chat-3D/Chat-3D</a></li>
<li>paper_authors: Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, Zhou Zhao</li>
<li>for: 提高3D场景理解的实用性，建立可对多种下游任务进行对话的全局对话系统。</li>
<li>methods: 利用预训练的3D表示和高级LLM的推理和对话能力，将3D表示映射到LLM的特征空间中，使LLM能够理解3D世界。</li>
<li>results: 实验显示，Chat-3D可以快速理解多种3D场景 instrucions，进行复杂的空间推理，并将外部知识 integrate into its responses。与GPT-4相比，Chat-3D在构建的指令集合上得分75.6%。<details>
<summary>Abstract</summary>
3D scene understanding has gained significant attention due to its wide range of applications. However, existing methods for 3D scene understanding are limited to specific downstream tasks, which hinders their practicality in real-world applications. This paper presents Chat-3D, which combines the 3D visual perceptual ability of pre-trained 3D representations and the impressive reasoning and conversation capabilities of advanced LLMs to achieve the first universal dialogue systems for 3D scenes. Specifically, we align 3D representations into the feature space of LLMs, thus enabling LLMs to perceive the 3D world. Given the scarcity of 3D scene-text data, we propose a three-stage training strategy to efficiently utilize the available data for better alignment. To enhance the reasoning ability and develop a user-friendly interaction scheme, we further construct a high-quality object-centric 3D instruction dataset and design an associated object-centric prompt. Our experiments show that Chat-3D achieves an impressive ability to comprehend diverse instructions for 3D scenes, engage in intricate spatial reasoning, and incorporate external knowledge into its responses. Chat-3D achieves a 75.6% relative score compared with GPT-4 on the constructed instruction dataset.
</details>
<details>
<summary>摘要</summary>
三维场景理解已经吸引了广泛的关注，因为它们在各种应用领域中具有广泛的应用前景。然而，现有的三维场景理解方法受到特定下游任务的限制，这限制了它们在实际应用中的实用性。本文介绍了Chat-3D，它通过将预训练的三维表示与高级LLM的强大理解和对话能力相结合，实现了第一个universal对话系统 для三维场景。具体来说，我们将三维表示空间对齐到LLM的特征空间中，因此让LLM能够感受到三维世界。由于三维场景文本数据的罕见性，我们提出了三个阶段的训练策略，以更有效地利用可用的数据进行更好的对齐。为了提高理解能力和设计用户友好的交互方案，我们还制作了高质量的三维对象中心指令集和相关的对象中心提示。我们的实验表明，Chat-3D可以具有卓越的理解多种三维场景指令、进行复杂的空间逻辑和 incorporate external knowledge into its responses。在我们制作的指令集上，Chat-3D achieved a 75.6% relative score compared with GPT-4。
</details></li>
</ul>
<hr>
<h2 id="XVTP3D-Cross-view-Trajectory-Prediction-Using-Shared-3D-Queries-for-Autonomous-Driving"><a href="#XVTP3D-Cross-view-Trajectory-Prediction-Using-Shared-3D-Queries-for-Autonomous-Driving" class="headerlink" title="XVTP3D: Cross-view Trajectory Prediction Using Shared 3D Queries for Autonomous Driving"></a>XVTP3D: Cross-view Trajectory Prediction Using Shared 3D Queries for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08764">http://arxiv.org/abs/2308.08764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Song, Huikun Bi, Ruisi Zhang, Tianlu Mao, Zhaoqi Wang</li>
<li>for: 这篇论文的目的是提出一种能够预测自动驾驶车辆的路径，并且确保多 vista 的预测结果保持一致性。</li>
<li>methods: 本文使用的方法包括使用共享的3D查询（XVTP3D）来生成多个目标，并使用随机遮盾法和粗糙至细的跨视观温探查来捕捉稳定的跨视特征。</li>
<li>results: 实验结果显示，XVTP3D 在两个公开available的数据集上 achieved state-of-the-art 性能，并且保持了多 vista 的预测结果一致性。<details>
<summary>Abstract</summary>
Trajectory prediction with uncertainty is a critical and challenging task for autonomous driving. Nowadays, we can easily access sensor data represented in multiple views. However, cross-view consistency has not been evaluated by the existing models, which might lead to divergences between the multimodal predictions from different views. It is not practical and effective when the network does not comprehend the 3D scene, which could cause the downstream module in a dilemma. Instead, we predicts multimodal trajectories while maintaining cross-view consistency. We presented a cross-view trajectory prediction method using shared 3D Queries (XVTP3D). We employ a set of 3D queries shared across views to generate multi-goals that are cross-view consistent. We also proposed a random mask method and coarse-to-fine cross-attention to capture robust cross-view features. As far as we know, this is the first work that introduces the outstanding top-down paradigm in BEV detection field to a trajectory prediction problem. The results of experiments on two publicly available datasets show that XVTP3D achieved state-of-the-art performance with consistent cross-view predictions.
</details>
<details>
<summary>摘要</summary>
几种感知资料的融合是自动驾驶中的决定性和挑战性任务。现在，我们可以轻松地存取多种检测数据。然而，不同检测视图之间的一致性尚未被现有的模型评估，这可能导致不同检测视图的多模式预测偏离。这不实际又无效当网络不理解3D场景，这可能导致下游模组受到困难。因此，我们预测多种检测路径，并维护不同检测视图之间的一致性。我们使用共享3D查询（XVTP3D）来生成跨观察方向的多个目标，并提出了随机填充方法和粗糙至细的标注捕捉强健的跨观察特征。我们相信这是首次在BEV检测领域中将顶部下降方式引入到路径预测问题中。实验结果显示，XVTP3D在两个公开可用的数据集上实现了状态顶对状态的表现。
</details></li>
</ul>
<hr>
<h2 id="Fine-grained-Text-and-Image-Guided-Point-Cloud-Completion-with-CLIP-Model"><a href="#Fine-grained-Text-and-Image-Guided-Point-Cloud-Completion-with-CLIP-Model" class="headerlink" title="Fine-grained Text and Image Guided Point Cloud Completion with CLIP Model"></a>Fine-grained Text and Image Guided Point Cloud Completion with CLIP Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08754">http://arxiv.org/abs/2308.08754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Song, Jun Zhou, Mingjie Wang, Hongchen Tan, Nannan Li, Xiuping Liu</li>
<li>for: This paper focuses on the task of point cloud completion guided by multimodal information, with the goal of improving the generalization ability and fine-grained semantic information of the model.</li>
<li>methods: The proposed method uses a multimodal fusion network that fuses visual and textual information to predict the semantic and geometric characteristics of incomplete shapes. The network employs a pre-trained vision-language model and a multi-stage feature fusion strategy to fuse the textual and visual features.</li>
<li>results: The proposed method achieves superior performance compared to state-of-the-art point cloud completion networks, as demonstrated through extensive quantitative and qualitative experiments. The use of fine-grained text descriptions provides richer geometric details for 3D shapes, further improving the accuracy of the completion.<details>
<summary>Abstract</summary>
This paper focuses on the recently popular task of point cloud completion guided by multimodal information. Although existing methods have achieved excellent performance by fusing auxiliary images, there are still some deficiencies, including the poor generalization ability of the model and insufficient fine-grained semantic information for extracted features. In this work, we propose a novel multimodal fusion network for point cloud completion, which can simultaneously fuse visual and textual information to predict the semantic and geometric characteristics of incomplete shapes effectively. Specifically, to overcome the lack of prior information caused by the small-scale dataset, we employ a pre-trained vision-language model that is trained with a large amount of image-text pairs. Therefore, the textual and visual encoders of this large-scale model have stronger generalization ability. Then, we propose a multi-stage feature fusion strategy to fuse the textual and visual features into the backbone network progressively. Meanwhile, to further explore the effectiveness of fine-grained text descriptions for point cloud completion, we also build a text corpus with fine-grained descriptions, which can provide richer geometric details for 3D shapes. The rich text descriptions can be used for training and evaluating our network. Extensive quantitative and qualitative experiments demonstrate the superior performance of our method compared to state-of-the-art point cloud completion networks.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文关注最近受欢迎的点云补充任务，带有多 modal 信息导航。虽然现有方法已经通过融合 auxillary 图像实现出色的性能，但还有一些缺陷，包括模型的泛化能力不够和缺乏细化Semantic 信息。在这个工作中，我们提出了一种新的多 modal 融合网络，可以同时融合视觉和文本信息，以预测受限shape的Semantic 和 геометрические特征。Specifically，为了缓解由小规模数据集所带来的缺乏先验信息，我们采用了一个预训练的视觉语言模型，该模型在大量的图像文本对中进行了训练。因此，视觉和文本Encoder 这两个模块具有更强的泛化能力。然后，我们提出了一种多stage 特征融合策略，以逐步融合视觉和文本特征到网络的后部。同时，为了更好地探索文本描述的细化效果，我们还建立了一个细化文本库，该库包含了更细化的描述，可以为3D 形状提供更 ric 的几何细节。这些细化的文本描述可以用于训练和评估我们的网络。广泛的量化和质量测试表明，我们的方法在现有点云补充网络中具有更高的性能。
</details></li>
</ul>
<hr>
<h2 id="BOTT-Box-Only-Transformer-Tracker-for-3D-Object-Tracking"><a href="#BOTT-Box-Only-Transformer-Tracker-for-3D-Object-Tracking" class="headerlink" title="BOTT: Box Only Transformer Tracker for 3D Object Tracking"></a>BOTT: Box Only Transformer Tracker for 3D Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08753">http://arxiv.org/abs/2308.08753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lubing Zhou, Xiaoli Meng, Yiluan Guo, Jiong Yang</li>
<li>for: 三元素 объек Tracking是自主驾驶中的重要任务，现有的 kalman滤波器基于方法仍然是最受欢迎的解决方案，但这些方法需要手工设计的运动模型，无法利用增长的数据量。</li>
<li>methods: 本文提出了盒子只 transformer跟踪器（BOTT），该方法通过将所有的3D盒在一个时间窗口中作为输入，使用 transformer自我注意力来交换所有盒子之间的信息，从而学习全局有用的盒子嵌入。</li>
<li>results: 实验显示，BOTT在 nuScenes 验证和测试分区上得到了69.9和66.7 AMOTA的竞争性性能，在 Waymo Open Dataset 验证和测试分区上得到了56.45和59.57 MOTA L2 的竞争性性能。这些结果表明，通过直接从3D盒子中学习特征使用 transformers 是一种简单 yet 有效的方法。<details>
<summary>Abstract</summary>
Tracking 3D objects is an important task in autonomous driving. Classical Kalman Filtering based methods are still the most popular solutions. However, these methods require handcrafted designs in motion modeling and can not benefit from the growing data amounts. In this paper, Box Only Transformer Tracker (BOTT) is proposed to learn to link 3D boxes of the same object from the different frames, by taking all the 3D boxes in a time window as input. Specifically, transformer self-attention is applied to exchange information between all the boxes to learn global-informative box embeddings. The similarity between these learned embeddings can be used to link the boxes of the same object. BOTT can be used for both online and offline tracking modes seamlessly. Its simplicity enables us to significantly reduce engineering efforts required by traditional Kalman Filtering based methods. Experiments show BOTT achieves competitive performance on two largest 3D MOT benchmarks: 69.9 and 66.7 AMOTA on nuScenes validation and test splits, respectively, 56.45 and 59.57 MOTA L2 on Waymo Open Dataset validation and test splits, respectively. This work suggests that tracking 3D objects by learning features directly from 3D boxes using transformers is a simple yet effective way.
</details>
<details>
<summary>摘要</summary>
<<SYS>>请将以下文本翻译成简化中文：Tracking 3D对象是自主驾驶中非常重要的任务。经典的Kalman滤波法仍然是最受欢迎的解决方案。然而，这些方法需要手工设计的运动模型，并且无法利用增长的数据量。在这篇论文中，我们提出了一种名为Box Only Transformer Tracker（BOTT）的方法，可以学习将不同帧中的3D盒子链接起来，并且可以在线和离线跟踪模式之间切换。具体来说，我们使用transformer自注意力来交换所有帧中的3D盒子信息，以学习全局有用的盒子嵌入。这些学习的嵌入之间的相似性可以用来链接同一个对象的盒子。BOTT可以在线和离线跟踪模式之间切换，并且其简单性使得可以减少传统Kalman滤波法基于的工程劳动量。实验显示BOTT在nuScenes验证和测试分区上得到了69.9和66.7 AMOTA的竞争性性能，以及Waymo开放数据集验证和测试分区上得到了56.45和59.57 MOTA L2的竞争性性能。这种工作表明了通过直接从3D盒子中学习特征来跟踪3D对象是一种简单 yet有效的方法。<</SYS>>Here's the translation: Tracking 3D objects is an important task in autonomous driving. Classical Kalman Filtering based methods are still the most popular solutions, but they require handcrafted designs in motion modeling and cannot benefit from the growing data amounts. In this paper, we propose a method called Box Only Transformer Tracker (BOTT) that learns to link 3D boxes of the same object from different frames by taking all the 3D boxes in a time window as input. Specifically, we use transformer self-attention to exchange information between all the boxes to learn global-informative box embeddings. The similarity between these learned embeddings can be used to link the boxes of the same object. BOTT can seamlessly switch between online and offline tracking modes, and its simplicity reduces the engineering efforts required by traditional Kalman Filtering based methods. Experimental results show that BOTT achieves competitive performance on the two largest 3D MOT benchmarks: 69.9 and 66.7 AMOTA on nuScenes validation and test splits, respectively, and 56.45 and 59.57 MOTA L2 on Waymo Open Dataset validation and test splits, respectively. This work suggests that tracking 3D objects by learning features directly from 3D boxes using transformers is a simple yet effective way.
</details></li>
</ul>
<hr>
<h2 id="MIPS-Fusion-Multi-Implicit-Submaps-for-Scalable-and-Robust-Online-Neural-RGB-D-Reconstruction"><a href="#MIPS-Fusion-Multi-Implicit-Submaps-for-Scalable-and-Robust-Online-Neural-RGB-D-Reconstruction" class="headerlink" title="MIPS-Fusion: Multi-Implicit-Submaps for Scalable and Robust Online Neural RGB-D Reconstruction"></a>MIPS-Fusion: Multi-Implicit-Submaps for Scalable and Robust Online Neural RGB-D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08741">http://arxiv.org/abs/2308.08741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijie Tang, Jiazhao Zhang, Zhinan Yu, He Wang, Kai Xu</li>
<li>for: 这个论文主要目的是提出一种基于神经网络的在线RGB-D重建方法，以实现大规模Scene的高质量重建。</li>
<li>methods: 该方法使用了一种新的神经网络表示方法——多重神经映射（Multi-Implicit-Submap，MIS），并采用分治设计来解决存储特征网格的问题。在该方法中，神经子地图在扫描轨迹中逐渐分配并高效地学习本地神经簇调整。</li>
<li>results: 对比现有的神经RGB-D重建方法，该方法可以实现更高的重建质量，特别是在大规模Scene和快速摄像机运动情况下。<details>
<summary>Abstract</summary>
We introduce MIPS-Fusion, a robust and scalable online RGB-D reconstruction method based on a novel neural implicit representation -- multi-implicit-submap. Different from existing neural RGB-D reconstruction methods lacking either flexibility with a single neural map or scalability due to extra storage of feature grids, we propose a pure neural representation tackling both difficulties with a divide-and-conquer design. In our method, neural submaps are incrementally allocated alongside the scanning trajectory and efficiently learned with local neural bundle adjustments. The submaps can be refined individually in a back-end optimization and optimized jointly to realize submap-level loop closure. Meanwhile, we propose a hybrid tracking approach combining randomized and gradient-based pose optimizations. For the first time, randomized optimization is made possible in neural tracking with several key designs to the learning process, enabling efficient and robust tracking even under fast camera motions. The extensive evaluation demonstrates that our method attains higher reconstruction quality than the state of the arts for large-scale scenes and under fast camera motions.
</details>
<details>
<summary>摘要</summary>
我团队介绍MIPS-Fusion，一种可靠和扩展的在线RGB-D重建方法，基于一种新的神经凝聚表示—多神经凝聚映射（Multi-Implicit-Submap，MIS）。与现有的神经RGB-D重建方法不同，我们的方法缺乏一个灵活的单个神经地图或可扩展性，我们提议一种纯神经表示，同时解决了这两个问题。在我们的方法中，神经子地图在扫描轨迹中逐渐分配并高效地学习地ocal神经簇更正。子地图可以在后续优化中被精细地修正，并在各个子地图水平实现子地图级循环关闭。此外，我们提出了一种混合Tracking方法，结合随机和梯度基于的pose优化。这是神经跟踪中首次实现随机优化的，通过一些关键的设计，使得神经跟踪可以快速和稳定地跟踪，即使相机速度快。我们的评估结果表明，我们的方法在大规模场景下和快相机速度下都可以 дости到更高的重建质量。
</details></li>
</ul>
<hr>
<h2 id="Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images"><a href="#Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images" class="headerlink" title="Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images"></a>Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08732">http://arxiv.org/abs/2308.08732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aidan S. Wright, Nathaniel P. Youmans, Enrique F. Valderrama Araya</li>
<li>for: 这个研究旨在开发一个基于Python的计算框架，用于精确地检测和全面分析SEM图像中的粒子。</li>
<li>methods: 这个框架使用了多种技术，包括阈值设定、扩展和膨润，以提高图像处理结果的准确性。</li>
<li>results: 研究人员通过使用这个框架，在五个不同的测试图像中达到97%的粒子检测精度，并能够识别出强度较弱的粒子。<details>
<summary>Abstract</summary>
In this study, we present a computational framework tailored for the precise detection and comprehensive analysis of nanoparticles within scanning electron microscopy (SEM) images. The primary objective of this framework revolves around the accurate localization of nanoparticle coordinates, accompanied by secondary objectives encompassing the extraction of pertinent morphological attributes including area, orientation, brightness, and length.   Constructed leveraging the robust image processing capabilities of Python, particularly harnessing libraries such as OpenCV, SciPy, and Scikit-Image, the framework employs an amalgamation of techniques, including thresholding, dilating, and eroding, to enhance the fidelity of image processing outcomes.   The ensuing nanoparticle data is seamlessly integrated into the RStudio environment to facilitate meticulous post-processing analysis. This encompasses a comprehensive evaluation of model accuracy, discernment of feature distribution patterns, and the identification of intricate particle arrangements. The finalized framework exhibits high nanoparticle identification within the primary sample image and boasts 97\% accuracy in detecting particles across five distinct test images drawn from a SEM nanoparticle dataset. Furthermore, the framework demonstrates the capability to discern nanoparticles of faint intensity, eluding manual labeling within the control group.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了一种基于计算机的方法，用于准确检测和全面分析顺序电镜图像中的粒子。主要目标是准确地确定粒子坐标，并且包括次要目标，如粒子形态属性的抽取，包括面积、方向、亮度和长度。这个框架利用Python语言的强大图像处理能力，特别是使用OpenCV、SciPy和Scikit-Image库，并采用了多种技术，如阈值处理、膨润和磨灭，以提高图像处理结果的准确性。得到的粒子数据可以轻松地 интеグрироваться到RStudio环境中，以便仔细进行后处理分析。这包括完整评估模型准确度，分析特征分布模式，以及描述复杂的粒子排列。最终的框架在主要样本图像中具有高精度的粒子识别能力，并在五个不同的测试图像中达到97%的检测粒子精度。此外，该框架还能够识别强度较弱的粒子，这些粒子在控制组中逃避人工标注。
</details></li>
</ul>
<hr>
<h2 id="Learning-Through-Guidance-Knowledge-Distillation-for-Endoscopic-Image-Classification"><a href="#Learning-Through-Guidance-Knowledge-Distillation-for-Endoscopic-Image-Classification" class="headerlink" title="Learning Through Guidance: Knowledge Distillation for Endoscopic Image Classification"></a>Learning Through Guidance: Knowledge Distillation for Endoscopic Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08731">http://arxiv.org/abs/2308.08731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshala Gammulle, Yubo Chen, Sridha Sridharan, Travis Klein, Clinton Fookes<br>for:The paper is written to improve the accuracy and efficiency of GI tract disease diagnosis using deep learning methods, specifically Convolutional Neural Networks (CNNs).methods:The paper proposes a novel multi-head attention-based feature fusion mechanism to support relation-based learning, and investigates three KD-based learning frameworks: response-based, feature-based, and relation-based.results:The proposed relation-based framework achieves improved lightweight model performance (only 51.8k trainable parameters) on two widely used public datasets, KVASIR-V2 and Hyper-KVASIR, signifying the merits of the proposed method in achieving accurate and efficient disease diagnosis in resource-limited medical clinics.<details>
<summary>Abstract</summary>
Endoscopy plays a major role in identifying any underlying abnormalities within the gastrointestinal (GI) tract. There are multiple GI tract diseases that are life-threatening, such as precancerous lesions and other intestinal cancers. In the usual process, a diagnosis is made by a medical expert which can be prone to human errors and the accuracy of the test is also entirely dependent on the expert's level of experience. Deep learning, specifically Convolution Neural Networks (CNNs) which are designed to perform automatic feature learning without any prior feature engineering, has recently reported great benefits for GI endoscopy image analysis. Previous research has developed models that focus only on improving performance, as such, the majority of introduced models contain complex deep network architectures with a large number of parameters that require longer training times. However, there is a lack of focus on developing lightweight models which can run in low-resource environments, which are typically encountered in medical clinics. We investigate three KD-based learning frameworks, response-based, feature-based, and relation-based mechanisms, and introduce a novel multi-head attention-based feature fusion mechanism to support relation-based learning. Compared to the existing relation-based methods that follow simplistic aggregation techniques of multi-teacher response/feature-based knowledge, we adopt the multi-head attention technique to provide flexibility towards localising and transferring important details from each teacher to better guide the student. We perform extensive evaluations on two widely used public datasets, KVASIR-V2 and Hyper-KVASIR, and our experimental results signify the merits of our proposed relation-based framework in achieving an improved lightweight model (only 51.8k trainable parameters) that can run in a resource-limited environment.
</details>
<details>
<summary>摘要</summary>
endoscopic examination plays a crucial role in identifying potential abnormalities within the gastrointestinal (GI) tract. there are numerous GI tract diseases that are life-threatening, such as precancerous lesions and other intestinal cancers. in the conventional process, a diagnosis is made by a medical expert, which can be prone to human errors and the accuracy of the test is entirely dependent on the expert's level of experience. deep learning, specifically convolutional neural networks (CNNs), has recently shown great benefits for GI endoscopy image analysis. previous research has developed models that focus solely on improving performance, resulting in complex deep network architectures with a large number of parameters that require longer training times. however, there is a lack of focus on developing lightweight models that can run in low-resource environments, typically encountered in medical clinics. we investigate three KD-based learning frameworks, response-based, feature-based, and relation-based mechanisms, and introduce a novel multi-head attention-based feature fusion mechanism to support relation-based learning. compared to existing relation-based methods that use simplistic aggregation techniques of multi-teacher response/feature-based knowledge, we adopt the multi-head attention technique to provide flexibility towards localizing and transferring important details from each teacher to better guide the student. we perform extensive evaluations on two widely used public datasets, KVASIR-V2 and Hyper-KVASIR, and our experimental results demonstrate the advantages of our proposed relation-based framework in achieving an improved lightweight model (only 51.8k trainable parameters) that can run in a resource-limited environment.
</details></li>
</ul>
<hr>
<h2 id="Learning-A-Coarse-to-Fine-Diffusion-Transformer-for-Image-Restoration"><a href="#Learning-A-Coarse-to-Fine-Diffusion-Transformer-for-Image-Restoration" class="headerlink" title="Learning A Coarse-to-Fine Diffusion Transformer for Image Restoration"></a>Learning A Coarse-to-Fine Diffusion Transformer for Image Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08730">http://arxiv.org/abs/2308.08730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wlydlut/c2f-dft">https://github.com/wlydlut/c2f-dft</a></li>
<li>paper_authors: Liyan Wang, Qinyu Yang, Cong Wang, Wei Wang, Jinshan Pan, Zhixun Su</li>
<li>for: 这个论文是为了提出一种基于填充 transformer 的图像修复方法，以解决 diffusion-based 方法在图像修复任务中可能因为不准确的噪声估计而未能获得出色的结果。</li>
<li>methods: 该方法使用了填充 transformer，包括填充自注意力（DFSA）和填充Feedforward网络（DFN），并在一种新的粗细顺序训练方案中使用。</li>
<li>results: 对于3个任务（抽掉雨、消除震荡和实际噪声），该方法在与 IR-SDE 比较的情况下显著地超越了 diffusion-based 修复方法，并与Transformer-based状态流方法在性能上具有竞争力。<details>
<summary>Abstract</summary>
Recent years have witnessed the remarkable performance of diffusion models in various vision tasks. However, for image restoration that aims to recover clear images with sharper details from given degraded observations, diffusion-based methods may fail to recover promising results due to inaccurate noise estimation. Moreover, simple constraining noises cannot effectively learn complex degradation information, which subsequently hinders the model capacity. To solve the above problems, we propose a coarse-to-fine diffusion Transformer (C2F-DFT) for image restoration. Specifically, our C2F-DFT contains diffusion self-attention (DFSA) and diffusion feed-forward network (DFN) within a new coarse-to-fine training scheme. The DFSA and DFN respectively capture the long-range diffusion dependencies and learn hierarchy diffusion representation to facilitate better restoration. In the coarse training stage, our C2F-DFT estimates noises and then generates the final clean image by a sampling algorithm. To further improve the restoration quality, we propose a simple yet effective fine training scheme. It first exploits the coarse-trained diffusion model with fixed steps to generate restoration results, which then would be constrained with corresponding ground-truth ones to optimize the models to remedy the unsatisfactory results affected by inaccurate noise estimation. Extensive experiments show that C2F-DFT significantly outperforms diffusion-based restoration method IR-SDE and achieves competitive performance compared with Transformer-based state-of-the-art methods on $3$ tasks, including deraining, deblurring, and real denoising. The code is available at https://github.com/wlydlut/C2F-DFT.
</details>
<details>
<summary>摘要</summary>
近年来，扩散模型在视觉任务中表现出了remarkable的表现。然而，为了recover清晰图像，扩散模型可能因为不准确的噪声估计而无法获得出色的结果。此外，简单的约束噪声无法有效地学习复杂的噪声信息，这会限制模型的容量。为解决这些问题，我们提出了一种归一化扩散变换器（C2F-DFT） для图像修复。具体来说，我们的C2F-DFT包括扩散自注意（DFSA）和扩散径向网络（DFN），并在一种新的归一化训练机制中进行了整合。DFSA和DFN分别捕捉了扩散的长距离相关性和层次扩散表示，以便更好地修复图像。在粗糙训练阶段，我们的C2F-DFT估计噪声，并通过抽样算法生成最终的清晰图像。为了进一步提高修复质量，我们提出了一种简单 yet有效的细化训练机制。它首先利用粗糙训练过的扩散模型，并将其与固定步长进行多次扩散，然后将其与对应的真实图像进行约束，以便使模型更好地修复受到噪声估计的影响的不满result。广泛的实验表明，C2F-DFT在3个任务上（包括雨几摄、锐化和真实噪声）significantly exceeds扩散基于SDE的修复方法，并与基于Transformer的state-of-the-art方法相当。代码可以在https://github.com/wlydlut/C2F-DFT中找到。
</details></li>
</ul>
<hr>
<h2 id="Long-Range-Grouping-Transformer-for-Multi-View-3D-Reconstruction"><a href="#Long-Range-Grouping-Transformer-for-Multi-View-3D-Reconstruction" class="headerlink" title="Long-Range Grouping Transformer for Multi-View 3D Reconstruction"></a>Long-Range Grouping Transformer for Multi-View 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08724">http://arxiv.org/abs/2308.08724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liyingcv/long-range-grouping-transformer">https://github.com/liyingcv/long-range-grouping-transformer</a></li>
<li>paper_authors: Liying Yang, Zhenwei Zhu, Xuxin Lin, Jian Nong, Yanyan Liang</li>
<li>for: 本研究旨在提高多视图3D重建 task 中 transformer 网络的性能，特别是对于自注意处理大量视图输入的困难性。</li>
<li>methods: 我们提出了一种基于 divide-and-conquer 原理的长范围集群注意力（LGA）机制，以便在不同视图之间进行注意力操作。此外，我们还设计了一种高效的编码器，可以连接不同视图之间的间距特征，以及一种进步的高分辨率增幅嵌入器 для voxel 生成。</li>
<li>results: 我们的方法在ShapeNet 数据集上实现了state-of-the-art 精度水平，证明了我们的方法在多视图3D重建 task 中的效果。<details>
<summary>Abstract</summary>
Nowadays, transformer networks have demonstrated superior performance in many computer vision tasks. In a multi-view 3D reconstruction algorithm following this paradigm, self-attention processing has to deal with intricate image tokens including massive information when facing heavy amounts of view input. The curse of information content leads to the extreme difficulty of model learning. To alleviate this problem, recent methods compress the token number representing each view or discard the attention operations between the tokens from different views. Obviously, they give a negative impact on performance. Therefore, we propose long-range grouping attention (LGA) based on the divide-and-conquer principle. Tokens from all views are grouped for separate attention operations. The tokens in each group are sampled from all views and can provide macro representation for the resided view. The richness of feature learning is guaranteed by the diversity among different groups. An effective and efficient encoder can be established which connects inter-view features using LGA and extract intra-view features using the standard self-attention layer. Moreover, a novel progressive upsampling decoder is also designed for voxel generation with relatively high resolution. Hinging on the above, we construct a powerful transformer-based network, called LRGT. Experimental results on ShapeNet verify our method achieves SOTA accuracy in multi-view reconstruction. Code will be available at https://github.com/LiyingCV/Long-Range-Grouping-Transformer.
</details>
<details>
<summary>摘要</summary>
现在，变换器网络在计算机视觉任务中表现出了非常出色的表现。在这种多视图3D重建算法中，变换器处理器需要处理具有庞大信息量的复杂图像token。词汇内容咒语导致模型学习非常困难。为解决这问题，现有的方法通过压缩每个视图的token数量或者抛弃不同视图之间的注意操作来缓解问题。然而，这些方法会对性能产生负面影响。因此，我们提出了长范围群组注意（LGA），基于分治原则。所有视图的token都被分组进行独立的注意操作。每个组中的token来自所有视图，可以为残存视图提供macro表示。各个组之间的多样性保证了特征学习的 ricness。通过LGA和标准自注意层连接，我们可以建立高效的encoder，并且可以提取高精度的voxel生成。此外，我们还设计了一种进步式upsampling解码器，用于生成相对高分辨率的voxel。基于以上，我们构建了一个强大的变换器基于网络，称为LRGT。实验结果表明，我们的方法在ShapeNet上达到了最佳精度的多视图重建。代码将于https://github.com/LiyingCV/Long-Range-Grouping-Transformer上提供。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression"><a href="#Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression" class="headerlink" title="Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression"></a>Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08723">http://arxiv.org/abs/2308.08723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Huairui/DKIC">https://github.com/Huairui/DKIC</a></li>
<li>paper_authors: Huairui Wang, Nianxiang Fu, Zhenzhong Chen, Shan Liu</li>
<li>for: 提高图像压缩率和精度性能</li>
<li>methods: 使用动态kernel基于变换编码、共享权重机制和自适应累积、改进 entropymodel</li>
<li>results: 在三个标准测试集上比前state-of-the-art学习基于方法获得更高的率压缩率和精度性能<details>
<summary>Abstract</summary>
Learned image compression methods have shown superior rate-distortion performance and remarkable potential compared to traditional compression methods. Most existing learned approaches use stacked convolution or window-based self-attention for transform coding, which aggregate spatial information in a fixed range. In this paper, we focus on extending spatial aggregation capability and propose a dynamic kernel-based transform coding. The proposed adaptive aggregation generates kernel offsets to capture valid information in the content-conditioned range to help transform. With the adaptive aggregation strategy and the sharing weights mechanism, our method can achieve promising transform capability with acceptable model complexity. Besides, according to the recent progress of entropy model, we define a generalized coarse-to-fine entropy model, considering the coarse global context, the channel-wise, and the spatial context. Based on it, we introduce dynamic kernel in hyper-prior to generate more expressive global context. Furthermore, we propose an asymmetric spatial-channel entropy model according to the investigation of the spatial characteristics of the grouped latents. The asymmetric entropy model aims to reduce statistical redundancy while maintaining coding efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance on three benchmarks compared to the state-of-the-art learning-based methods.
</details>
<details>
<summary>摘要</summary>
现有的学习图像压缩方法已经显示出了较好的比特率-损失性能和很好的潜在性，相比传统压缩方法。大多数现有的学习方法使用堆叠 convolution或窗口基于自注意力来实现变换编码，这些方法将空间信息归约到固定范围内。在这篇论文中，我们将注意力集中在扩展空间归约能力上，并提出一种动态kernel基于变换编码。我们的提案的自适应归约生成器将kernel偏移来捕捉有效信息在内容受限范围内，以帮助变换。通过自适应归约策略和共享权重机制，我们的方法可以实现可接受的变换能力和模型复杂度。此外，根据最近的比特模型进展，我们定义一种总体粗细-细致比特模型，考虑全局粗细上下文、通道粗细和空间上下文。基于它，我们引入动态kernel在超PRIOR中生成更表达力的全局上下文。此外，我们还提出一种偏极空频频道比特模型，根据图像特征的分组分析。这种偏极 entropy模型的目的是降低统计冗余，保持编码效率。实验结果表明，我们的方法在三个标准底层上比对 estado-of-the-art 学习基于方法得到了较好的比特率-损失性能。
</details></li>
</ul>
<hr>
<h2 id="RFD-ECNet-Extreme-Underwater-Image-Compression-with-Reference-to-Feature-Dictionar"><a href="#RFD-ECNet-Extreme-Underwater-Image-Compression-with-Reference-to-Feature-Dictionar" class="headerlink" title="RFD-ECNet: Extreme Underwater Image Compression with Reference to Feature Dictionar"></a>RFD-ECNet: Extreme Underwater Image Compression with Reference to Feature Dictionar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08721">http://arxiv.org/abs/2308.08721</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lilala0/rfd-ecnet">https://github.com/lilala0/rfd-ecnet</a></li>
<li>paper_authors: Mengyao Li, Liquan Shen, Peng Ye, Guorui Feng, Zheyin Wang</li>
<li>for: 提高水下应用的高效性，实现水下图像（UWI）在非常窄的水下频谱中的传输。</li>
<li>methods: 首先构建了水下多级特征字典，以提供水下图像压缩的粗略参考特征。然后，提出了一种Extreme UWI压缩网络（RFD-ECNet），利用特征匹配和参考特征变化来减少UWI之间的重复性。为了正确地匹配水下图像的多样性，提出了一种水下风格标准块（USNB），利用水下物理图像模型中提取的水下物理约束来 норmalize水下字典特征向输入。此外，还提出了一种参考特征变化模块（RFVM），用于适应性地改变参考特征，提高参考特征和输入特征之间的相似性。</li>
<li>results: 实验结果表明，我们的RFD-ECNet在四个UWI数据集上实现了31%的BD率减少，超过了最先进的VVC。<details>
<summary>Abstract</summary>
Thriving underwater applications demand efficient extreme compression technology to realize the transmission of underwater images (UWIs) in very narrow underwater bandwidth. However, existing image compression methods achieve inferior performance on UWIs because they do not consider the characteristics of UWIs: (1) Multifarious underwater styles of color shift and distance-dependent clarity, caused by the unique underwater physical imaging; (2) Massive redundancy between different UWIs, caused by the fact that different UWIs contain several common ocean objects, which have plenty of similarities in structures and semantics. To remove redundancy among UWIs, we first construct an exhaustive underwater multi-scale feature dictionary to provide coarse-to-fine reference features for UWI compression. Subsequently, an extreme UWI compression network with reference to the feature dictionary (RFD-ECNet) is creatively proposed, which utilizes feature match and reference feature variant to significantly remove redundancy among UWIs. To align the multifarious underwater styles and improve the accuracy of feature match, an underwater style normalized block (USNB) is proposed, which utilizes underwater physical priors extracted from the underwater physical imaging model to normalize the underwater styles of dictionary features toward the input. Moreover, a reference feature variant module (RFVM) is designed to adaptively morph the reference features, improving the similarity between the reference and input features. Experimental results on four UWI datasets show that our RFD-ECNet is the first work that achieves a significant BD-rate saving of 31% over the most advanced VVC.
</details>
<details>
<summary>摘要</summary>
在水下应用需要高效的极端压缩技术来实现水下图像（UWI）的传输在非常窄的水下频谱带中。然而，现有的图像压缩方法在UWI上的性能不佳，因为它们不考虑水下图像的特点：（1）多样的水下颜色变换和距离相关的清晰度变化，由水下物理捕捉器带来的独特水下物理特性；（2）水下图像之间的巨大重复性，由于不同的UWI都包含许多相似的海洋对象，这些对象在结构和 semantics 方面具有很多相似性。为了消除UWI之间的重复性，我们首先构建了水下多尺度特征字典（USDL），提供水下图像压缩的粗略到细则参考特征。然后，我们创新提出了基于特征字典的极端UWI压缩网络（RFD-ECNet），该网络利用特征匹配和参考特征变体来减少UWI之间的重复性。为了调整水下颜色的多样性并提高特征匹配的准确性，我们还提出了水下风格normal化块（USNB），该块利用从水下物理捕捉器提取的水下物理理论来正常化特征字典中的水下风格。此外，我们还设计了参考特征变体模块（RFVM），以适应不同的参考特征，使得参考特征与输入特征之间的相似性更高。实验结果表明，我们的RFD-ECNet在四个UWI数据集上达到了最高的BD-率减少31%，比最先进的VVC更高效。
</details></li>
</ul>
<hr>
<h2 id="V-FUSE-Volumetric-Depth-Map-Fusion-with-Long-Range-Constraints"><a href="#V-FUSE-Volumetric-Depth-Map-Fusion-with-Long-Range-Constraints" class="headerlink" title="V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints"></a>V-FUSE: Volumetric Depth Map Fusion with Long-Range Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08715">http://arxiv.org/abs/2308.08715</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nburgdorfer/vfuse">https://github.com/nburgdorfer/vfuse</a></li>
<li>paper_authors: Nathaniel Burgdorfer, Philippos Mordohai</li>
<li>for: 提高Multi-View Stereo（MVS）算法生成的深度和信任图的精度</li>
<li>methods:  integrate volumetric visibility constraints into an end-to-end trainable architecture, 以及一个jointly trained depth search window estimation sub-network</li>
<li>results: 对MVS数据进行了大量实验，并显示了出入 fusion depth和信任图的精度有substantial improvements。<details>
<summary>Abstract</summary>
We introduce a learning-based depth map fusion framework that accepts a set of depth and confidence maps generated by a Multi-View Stereo (MVS) algorithm as input and improves them. This is accomplished by integrating volumetric visibility constraints that encode long-range surface relationships across different views into an end-to-end trainable architecture. We also introduce a depth search window estimation sub-network trained jointly with the larger fusion sub-network to reduce the depth hypothesis search space along each ray. Our method learns to model depth consensus and violations of visibility constraints directly from the data; effectively removing the necessity of fine-tuning fusion parameters. Extensive experiments on MVS datasets show substantial improvements in the accuracy of the output fused depth and confidence maps.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于学习的深度地图融合框架，该框架接受多视图深度和信任图生成器的输出，并改进它们。我们在整个端到端可学习架构中 integrate了Volumetric可见性约束，这些约束编码了不同视图之间的长距离表面关系。我们还提出了一个专门用于每个光栅的深度搜索窗口估计子网络，与更大的融合子网络一起培训，以降低每个光栅的深度假设搜索空间。我们的方法可以直接从数据中学习深度一致性和视图约束的违反;无需精细调整融合参数。我们的实验表明，对MVS数据集进行了广泛的测试，并显著提高了输出融合的深度和信任图的准确性。
</details></li>
</ul>
<hr>
<h2 id="SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification"><a href="#SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification" class="headerlink" title="SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification"></a>SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08669">http://arxiv.org/abs/2308.08669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Longman-Stan/SkinDistilVit">https://github.com/Longman-Stan/SkinDistilVit</a></li>
<li>paper_authors: Vlad-Constantin Lungu-Stan, Dumitru-Clementin Cercel, Florin Pop</li>
<li>for: 这个论文的目的是提供一种特定生产环境中的皮肤癌分类问题的解决方案，以匹配人类的检测精度。</li>
<li>methods: 这个论文使用了知识储存法来训练一个基于视Transformer的模型，并在专家级别标注的皮肤医学图像上进行了训练。</li>
<li>results: 该模型可以保持98.33%的平衡多类准确率，而且在推理成本方面具有显著的提高，即时间内存具有69.25%和97.96%的提高。<details>
<summary>Abstract</summary>
Skin cancer is a treatable disease if discovered early. We provide a production-specific solution to the skin cancer classification problem that matches human performance in melanoma identification by training a vision transformer on melanoma medical images annotated by experts. Since inference cost, both time and memory wise is important in practice, we employ knowledge distillation to obtain a model that retains 98.33% of the teacher's balanced multi-class accuracy, at a fraction of the cost. Memory-wise, our model is 49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on GPU and 97.96% faster on CPU. By adding classification heads at each level of the transformer and employing a cascading distillation process, we improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance. We provide the code at https://github.com/Longman-Stan/SkinDistilVit.
</details>
<details>
<summary>摘要</summary>
皮肤癌是一种可治疗的疾病，如果早发现。我们提供一个特定生产环境下的解决方案，用于皮肤癌分类问题，它与专业人员注意标注的melanoma医疗图像进行训练，以实现人工智能水平的抑肿癌识别。在实践中，推理成本（时间和内存）是重要的，我们使用知识储存法来获得一个保持98.33%的教师平衡多类准确率的模型，而且模型的内存占用量比教师模型少49.60%，时间占用量比教师模型快69.25%（GPU）和97.96%（CPU）。通过在转换器中添加多个分类头和使用层次分解法，我们提高基本模型的平衡多类准确率2.1%，并创造了不同大小的模型，但它们具有相似的性能。我们提供了代码，可以在 GitHub上找到：https://github.com/Longman-Stan/SkinDistilVit。
</details></li>
</ul>
<hr>
<h2 id="A-New-Data-Driven-Method-to-Identify-Violent-Facial-Expression"><a href="#A-New-Data-Driven-Method-to-Identify-Violent-Facial-Expression" class="headerlink" title="A New Data-Driven Method to Identify Violent Facial Expression"></a>A New Data-Driven Method to Identify Violent Facial Expression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08658">http://arxiv.org/abs/2308.08658</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arindampaulripon/A-Novel-Method-for-Machine-Learning-Based-Automatic-Crime-Activity-Identification-System-by-Analyzin">https://github.com/arindampaulripon/A-Novel-Method-for-Machine-Learning-Based-Automatic-Crime-Activity-Identification-System-by-Analyzin</a></li>
<li>paper_authors: Arindam Kumar Paul, Md Maruf Hasan, Md. Delwar Hosen</li>
<li>for: 本研究旨在开发一个自动识别凶暴行为的系统，以帮助预防犯罪和保护社会。</li>
<li>methods: 本研究使用了卷积神经网络模型，并使用自动特征选择器来捕捉特定的面孔表情特征。</li>
<li>results: 研究发现，这个系统可以更加精确地识别凶暴行为的面孔表情特征，并且只需使用少量的面孔数据来训练。<details>
<summary>Abstract</summary>
Human Facial Expressions plays an important role in identifying human actions or intention. Facial expressions can represent any specific action of any person and the pattern of violent behavior of any person strongly depends on the geographic region. Here we have designed an automated system by using a Convolutional Neural Network which can detect whether a person has any intention to commit any crime or not. Here we proposed a new method that can identify criminal intentions or violent behavior of any person before executing crimes more efficiently by using very little data on facial expressions before executing a crime or any violent tasks. Instead of using image features which is a time-consuming and faulty method we used an automated feature selector Convolutional Neural Network model which can capture exact facial expressions for training and then can predict that target facial expressions more accurately. Here we used only the facial data of a specific geographic region which can represent the violent and before-crime before-crime facial patterns of the people of the whole region.
</details>
<details>
<summary>摘要</summary>
人类表情表达在识别人类行为或意图方面发挥重要作用。人类表情可以代表任何人的特定行为，并且任何人的暴力行为强度受地理区域的影响。我们设计了一个自动化系统，使用卷积神经网络来检测人类是否有任何犯罪意图。我们提出了一种新的方法，可以更高效地识别人类犯罪意图或暴力行为，只需使用小量的面部表达数据。而不是使用图像特征，我们使用自动化特征选择器卷积神经网络模型，可以更准确地捕捉面部表达特征，并且预测目标面部表达更加准确。我们使用了特定地理区域的面部数据，可以更好地表示该地区的暴力和前犯罪面部模式。
</details></li>
</ul>
<hr>
<h2 id="Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data"><a href="#Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data" class="headerlink" title="Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data"></a>Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08656">http://arxiv.org/abs/2308.08656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keziah Naggita, Julienne LaChance, Alice Xiang</li>
<li>for: 研究大规模图像数据集中的偏见对计算机视觉模型的性能的影响</li>
<li>methods: 使用 geotagged Flickr 图像与每个非洲国家相对比较的人类中心图像异质量进行分析，并进行两年频次的时间分析以暴露出来的数据趋势</li>
<li>results: 发现非洲的图像数据匮乏，主要由非洲以外的摄影师拍摄，需要进一步的工作以获得更加代表性的图像数据，以提高计算机视觉模型在全球范围内的应用性<details>
<summary>Abstract</summary>
Biases in large-scale image datasets are known to influence the performance of computer vision models as a function of geographic context. To investigate the limitations of standard Internet data collection methods in low- and middle-income countries, we analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa. We report the quantity and content of available data with comparisons to population-matched nations in Europe as well as the distribution of data according to fine-grained intra-national wealth estimates. Temporal analyses are performed at two-year intervals to expose emerging data trends. Furthermore, we present findings for an ``othering'' phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers. The results of our study suggest that further work is required to capture image data representative of African people and their environments and, ultimately, to improve the applicability of computer vision models in a global context.
</details>
<details>
<summary>摘要</summary>
大规模图像数据集中的偏见会影响计算机视觉模型的表现，具体来说是根据地理上下文。为了探讨标准互联网数据收集方法在LOW-和中等收入国家的局限性，我们使用Geotagged Flickr图像与每个非洲国家进行人类中心的图像地域多样性分析，并对相应的人口比较欧洲国家进行比较。我们还分析了图像数据的分布 according to fine-grained intra-national wealth estimates。通过两年 interval的时间分析，暴露出emerging data trends。此外，我们还发现了一种“其他化”现象，即非洲的图像大多被非本地摄影师拍摄。我们的研究结果表明，需要进一步的工作，以捕捉符合非洲人和其环境的图像数据，并 ultimately improve计算机视觉模型在全球上的可用性。
</details></li>
</ul>
<hr>
<h2 id="Fair-GANs-through-model-rebalancing-with-synthetic-data"><a href="#Fair-GANs-through-model-rebalancing-with-synthetic-data" class="headerlink" title="Fair GANs through model rebalancing with synthetic data"></a>Fair GANs through model rebalancing with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08638">http://arxiv.org/abs/2308.08638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhav Jain, Nasir Memon, Julian Togelius</li>
<li>for: 本文旨在提高生成模型的偏差减少和公平性提高。</li>
<li>methods: 本文提出一种使用潜在空间探索生成平衡数据，并使用这些数据来训练平衡的生成模型来减少生成模型中的偏差。此外，本文还提出了一种偏差纠正损失函数，可以在不平衡的数据集上提高公平性指标。</li>
<li>results: 在使用Stylegan2模型和FFHQ数据集进行遥感肖像偏差和公平性问题时，本文得到了 almost 5 倍的提高，同时保持图像质量。此外，本文还验证了这种方法在不平衡的 Cifar-10 数据集上的有效性。最后，本文指出了传统的图像质量指标，如Frechet inception distance (FID)，在偏差减少问题上不适用。<details>
<summary>Abstract</summary>
Deep generative models require large amounts of training data. This often poses a problem as the collection of datasets can be expensive and difficult, in particular datasets that are representative of the appropriate underlying distribution (e.g. demographic). This introduces biases in datasets which are further propagated in the models. We present an approach to mitigate biases in an existing generative adversarial network by rebalancing the model distribution. We do so by generating balanced data from an existing unbalanced deep generative model using latent space exploration and using this data to train a balanced generative model. Further, we propose a bias mitigation loss function that shows improvements in the fairness metric even when trained with unbalanced datasets. We show results for the Stylegan2 models while training on the FFHQ dataset for racial fairness and see that the proposed approach improves on the fairness metric by almost 5 times, whilst maintaining image quality. We further validate our approach by applying it to an imbalanced Cifar-10 dataset. Lastly, we argue that the traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details>
<details>
<summary>摘要</summary>
深度生成模型需要大量的训练数据，这经常导致收集数据集的成本和困难，特别是收集表示适当下游分布（例如人口学）的数据集。这会导致模型中的偏见，并在模型中传递这些偏见。我们提出了一种方法来减轻模型中的偏见，通过在现有的深度生成模型中进行缺失空间探索，并使用这些缺失数据来训练一个平衡的生成模型。此外，我们提出了一种偏见纠正loss函数，这种loss函数可以在偏见数据集上训练模型，并且可以提高公平度量表示的改进。我们在使用Stylegan2模型进行FFHQ数据集上的遥感风格改进和Cifar-10数据集上的偏见纠正 validate our approach。最后，我们 argue that traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems。Note: Please note that the translation is in Simplified Chinese, and the word order and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="MeViS-A-Large-scale-Benchmark-for-Video-Segmentation-with-Motion-Expressions"><a href="#MeViS-A-Large-scale-Benchmark-for-Video-Segmentation-with-Motion-Expressions" class="headerlink" title="MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions"></a>MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08544">http://arxiv.org/abs/2308.08544</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/henghuiding/MeViS">https://github.com/henghuiding/MeViS</a></li>
<li>paper_authors: Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Chen Change Loy</li>
<li>for: 这 paper 的目的是为了研究基于动作表达的视频分割，即使用语句来描述目标对象的动作，从而在视频内部分割目标对象。</li>
<li>methods: 本 paper 使用了现有的referring video object segmentation (RVOS) 方法进行比较，并提出了一个基线方法来解决问题。</li>
<li>results: results show that current RVOS methods cannot effectively address motion expression-guided video segmentation, and the proposed baseline approach can provide a good starting point for future research.<details>
<summary>Abstract</summary>
This paper strives for motion expressions guided video segmentation, which focuses on segmenting objects in video content based on a sentence describing the motion of the objects. Existing referring video object datasets typically focus on salient objects and use language expressions that contain excessive static attributes that could potentially enable the target object to be identified in a single frame. These datasets downplay the importance of motion in video content for language-guided video object segmentation. To investigate the feasibility of using motion expressions to ground and segment objects in videos, we propose a large-scale dataset called MeViS, which contains numerous motion expressions to indicate target objects in complex environments. We benchmarked 5 existing referring video object segmentation (RVOS) methods and conducted a comprehensive comparison on the MeViS dataset. The results show that current RVOS methods cannot effectively address motion expression-guided video segmentation. We further analyze the challenges and propose a baseline approach for the proposed MeViS dataset. The goal of our benchmark is to provide a platform that enables the development of effective language-guided video segmentation algorithms that leverage motion expressions as a primary cue for object segmentation in complex video scenes. The proposed MeViS dataset has been released at https://henghuiding.github.io/MeViS.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文目标是开发基于运动表达的视频分割，强调在视频内容中基于运动描述对象进行分割。现有的视频对象引用Dataset通常强调出现在视频中的突出对象，使用语言表达包含过多的静态特征，这可能使得目标对象在单帧中被识别。这些Dataset下Play优化视频内容中的运动的重要性，对语言导向视频对象分割进行了下Play。为了探索使用运动表达来固定和分割视频中的对象，我们提出了大规模的MeViS dataset，它包含了许多运动表达来指定目标对象在复杂环境中。我们对5种现有的视频对象分割方法进行了比较性分析，并在MeViS dataset上进行了完整的比较。结果表明，现有的视频对象分割方法无法有效地解决运动表达导向的视频分割。我们进一步分析了挑战和提出了基线方法，以便在我们的benchmark中发展有效的语言导向视频分割算法，利用运动表达作为主要准确对象分割在复杂视频场景中的导向。MeViS dataset已经在https://henghuiding.github.io/MeViS上发布。
</details></li>
</ul>
<hr>
<h2 id="InsightMapper-A-Closer-Look-at-Inner-instance-Information-for-Vectorized-High-Definition-Mapping"><a href="#InsightMapper-A-Closer-Look-at-Inner-instance-Information-for-Vectorized-High-Definition-Mapping" class="headerlink" title="InsightMapper: A Closer Look at Inner-instance Information for Vectorized High-Definition Mapping"></a>InsightMapper: A Closer Look at Inner-instance Information for Vectorized High-Definition Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08543">http://arxiv.org/abs/2308.08543</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TonyXuQAQ/InsightMapper">https://github.com/TonyXuQAQ/InsightMapper</a></li>
<li>paper_authors: Zhenhua Xu, Kenneth K. Y. Wong, Hengshuang Zhao</li>
<li>for: 本研究旨在提高自动驾驶车辆中 vectorized 高清晰地图的检测性能，通过利用内部实例信息进行增强。</li>
<li>methods: 本研究使用了 transformers 来利用内部实例信息，并 introduce 了三种新的设计方案，包括 Hybrid 查询生成、内部实例查询融合和内部实例特征汇集。</li>
<li>results: 对 NuScenes 数据集进行比较 экспериментирова，显示了我们的提案方法在检测性能和效率两个方面具有明显的优势，比如5.78 mAP 和 5.12 TOPO，这两个指标都是评估拓扑正确性的。<details>
<summary>Abstract</summary>
Vectorized high-definition (HD) maps contain detailed information about surrounding road elements, which are crucial for various downstream tasks in modern autonomous driving vehicles, such as vehicle planning and control. Recent works have attempted to directly detect the vectorized HD map as a point set prediction task, resulting in significant improvements in detection performance. However, these approaches fail to analyze and exploit the inner-instance correlations between predicted points, impeding further advancements. To address these challenges, we investigate the utilization of inner-$\textbf{INS}$tance information for vectorized h$\textbf{IGH}$-definition mapping through $\textbf{T}$ransformers and introduce InsightMapper. This paper presents three novel designs within InsightMapper that leverage inner-instance information in distinct ways, including hybrid query generation, inner-instance query fusion, and inner-instance feature aggregation. Comparative experiments are conducted on the NuScenes dataset, showcasing the superiority of our proposed method. InsightMapper surpasses previous state-of-the-art (SOTA) methods by 5.78 mAP and 5.12 TOPO, which assess topology correctness. Simultaneously, InsightMapper maintains high efficiency during both training and inference phases, resulting in remarkable comprehensive performance. The project page for this work is available at https://tonyxuqaq.github.io/projects/InsightMapper .
</details>
<details>
<summary>摘要</summary>
高清晰度地图（HD map）被vector化后，含有周围道路元素的详细信息，对现代自动驾驶车辆的各种下渠任务非常重要，如车辆规划和控制。现有研究直接将vectorized HD map当作点集预测任务进行处理，这些方法可以大幅提高检测性能。然而，这些方法忽略了预测点之间的内部相关关系，从而限制了进一步的进步。为了解决这些挑战，我们研究了使用内部实例信息对vectorized高清晰度地图进行Transformers的利用，并提出了InsightMapper。InsightMapper包含三种新的设计，它们在不同的方面利用内部实例信息，包括半结合查询生成、内部实例查询融合和内部实例特征聚合。我们在NuScenes dataset上进行了比较性实验，显示我们提出的方法在检测性能和效率方面具有卓越的表现。InsightMapper比前一代最佳方法（SOTA）提高5.78 mAP和5.12 TOPO，这些指标评估了排名准确性。同时，InsightMapper在训练和推理阶段保持高效，从而实现了remarkable的总性性能。有关这项工作的详细信息，请参考https://tonyxuqaq.github.io/projects/InsightMapper。
</details></li>
</ul>
<hr>
<h2 id="Ref-DVGO-Reflection-Aware-Direct-Voxel-Grid-Optimization-for-an-Improved-Quality-Efficiency-Trade-Off-in-Reflective-Scene-Reconstruction"><a href="#Ref-DVGO-Reflection-Aware-Direct-Voxel-Grid-Optimization-for-an-Improved-Quality-Efficiency-Trade-Off-in-Reflective-Scene-Reconstruction" class="headerlink" title="Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstruction"></a>Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08530">http://arxiv.org/abs/2308.08530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gkouros/ref-dvgo">https://github.com/gkouros/ref-dvgo</a></li>
<li>paper_authors: Georgios Kouros, Minye Wu, Shubham Shrivastava, Sushruth Nagesh, Punarjay Chakravarty, Tinne Tuytelaars</li>
<li>for: 该研究旨在寻找一种能够平衡效率和质量的方法来处理反射物体。</li>
<li>methods: 该研究采用了一种基于储存渠道的隐式-显式方法，并采用了高效的密度基本的格子表示。</li>
<li>results: 该研究在重建质量和训练和渲染过程中提高了效率，并实现了与其他方法相当的质量效率负荷平衡。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have revolutionized the field of novel view synthesis, demonstrating remarkable performance. However, the modeling and rendering of reflective objects remain challenging problems. Recent methods have shown significant improvements over the baselines in handling reflective scenes, albeit at the expense of efficiency. In this work, we aim to strike a balance between efficiency and quality. To this end, we investigate an implicit-explicit approach based on conventional volume rendering to enhance the reconstruction quality and accelerate the training and rendering processes. We adopt an efficient density-based grid representation and reparameterize the reflected radiance in our pipeline. Our proposed reflection-aware approach achieves a competitive quality efficiency trade-off compared to competing methods. Based on our experimental results, we propose and discuss hypotheses regarding the factors influencing the results of density-based methods for reconstructing reflective objects. The source code is available at https://github.com/gkouros/ref-dvgo.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (nerfs) 已经革命化了新视角合成领域，表现出色。然而，模型和渲染镜面物体仍然是挑战。现有方法已经在镜面场景中显示了重要的改进，但是这些改进通常是在效率上的代价。在这种工作中，我们想要寻找效率和质量之间的平衡。为此，我们 investigate了一种采用储存-渲染的方法，使用传统的体积渲染来提高重建质量并加速训练和渲染过程。我们采用了高效的体积-基的格子表示和重新 parameterize 反射辐射的管道。我们的提案的反射意识方法可以与竞争方法相比，在质量和效率之间寻找一个稍微的平衡。根据我们的实验结果，我们提出和讨论了镜面物体重建中各种体积方法的因素的影响因素。源代码可以在 https://github.com/gkouros/ref-dvgo 上找到。
</details></li>
</ul>
<hr>
<h2 id="Diagnosing-Human-object-Interaction-Detectors"><a href="#Diagnosing-Human-object-Interaction-Detectors" class="headerlink" title="Diagnosing Human-object Interaction Detectors"></a>Diagnosing Human-object Interaction Detectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08529">http://arxiv.org/abs/2308.08529</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neu-vi/diag-hoi">https://github.com/neu-vi/diag-hoi</a></li>
<li>paper_authors: Fangrui Zhu, Yiming Xie, Weidi Xie, Huaizu Jiang</li>
<li>for: 本文旨在提供一个用于分析现有人对物检测模型错误来源的诊断工具箱。</li>
<li>methods: 本文首先对人对物检测管道进行总体调查，然后定义了不同类型的错误和其修正方法。通过测量修正错误时的mAP提升，可以进行详细的错误分析。</li>
<li>results: 本文对人对物检测和互动类别分类任务进行了深入的分析，包括人对物检测的准确率和干扰率的计算，以及互动类别分类的mAP分布。<details>
<summary>Abstract</summary>
Although we have witnessed significant progress in human-object interaction (HOI) detection with increasingly high mAP (mean Average Precision), a single mAP score is too concise to obtain an informative summary of a model's performance and to understand why one approach is better than another. In this paper, we introduce a diagnosis toolbox for analyzing the error sources of the existing HOI detection models. We first conduct holistic investigations in the pipeline of HOI detection, consisting of human-object pair detection and then interaction classification. We define a set of errors and the oracles to fix each of them. By measuring the mAP improvement obtained from fixing an error using its oracle, we can have a detailed analysis of the significance of different errors. We then delve into the human-object detection and interaction classification, respectively, and check the model's behavior. For the first detection task, we investigate both recall and precision, measuring the coverage of ground-truth human-object pairs as well as the noisiness level in the detections. For the second classification task, we compute mAP for interaction classification only, without considering the detection scores. We also measure the performance of the models in differentiating human-object pairs with and without actual interactions using the AP (Average Precision) score. Our toolbox is applicable for different methods across different datasets and available at https://github.com/neu-vi/Diag-HOI.
</details>
<details>
<summary>摘要</summary>
尽管我们已经观察到人物对象交互检测中的显著进步，但单一的mAP得分并不能提供完整的模型性能概括，也无法理解哪些方法更好。在这篇论文中，我们提出了一个分析错误源的工具箱 для现有的人物对象交互检测模型。我们首先在人物对象检测的管道中进行了全面的调查，包括人物对象对的检测和 then 交互分类。我们定义了一组错误和其修复方法。通过使用每个错误的 oracle 来修复错误，我们可以进行详细的错误分析，并计算修复错误后的mAP提升。然后，我们逐个探究人物检测和交互分类任务中的模型行为。对于第一个检测任务，我们评估了人物对象对的覆盖率和检测结果的噪音水平。对于第二个分类任务，我们计算了交互分类的mAP分数，不考虑检测得分。我们还计算了模型在分辨人物对象对有实际交互和无实际交互的情况下的AP分数。我们的工具箱可以应用于不同的方法和数据集，可以在 GitHub 上获取：https://github.com/neu-vi/Diag-HOI。
</details></li>
</ul>
<hr>
<h2 id="Likelihood-Based-Text-to-Image-Evaluation-with-Patch-Level-Perceptual-and-Semantic-Credit-Assignment"><a href="#Likelihood-Based-Text-to-Image-Evaluation-with-Patch-Level-Perceptual-and-Semantic-Credit-Assignment" class="headerlink" title="Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment"></a>Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08525">http://arxiv.org/abs/2308.08525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenqi008/leica">https://github.com/chenqi008/leica</a></li>
<li>paper_authors: Qi Chen, Chaorui Deng, Zixiong Huang, Bowen Zhang, Mingkui Tan, Qi Wu</li>
<li>for: 本研究旨在提出一种新的文本到图像生成评价指标，以更好地评估图像生成模型的表现。</li>
<li>methods: 本研究使用了一种基于概率的文本到图像生成模型，以直接估计生成图像的可能性，并提出了一些新的设计来实现准确的归因分配策略。</li>
<li>results: 在实验中，提出的指标能够 успеш地评估多种流行的文本到图像生成模型和数据集，并且可以使用只需要几十个样本来稳定评估结果，这使得它在实践中非常有效率。<details>
<summary>Abstract</summary>
Text-to-image synthesis has made encouraging progress and attracted lots of public attention recently. However, popular evaluation metrics in this area, like the Inception Score and Fr'echet Inception Distance, incur several issues. First of all, they cannot explicitly assess the perceptual quality of generated images and poorly reflect the semantic alignment of each text-image pair. Also, they are inefficient and need to sample thousands of images to stabilise their evaluation results. In this paper, we propose to evaluate text-to-image generation performance by directly estimating the likelihood of the generated images using a pre-trained likelihood-based text-to-image generative model, i.e., a higher likelihood indicates better perceptual quality and better text-image alignment. To prevent the likelihood of being dominated by the non-crucial part of the generated image, we propose several new designs to develop a credit assignment strategy based on the semantic and perceptual significance of the image patches. In the experiments, we evaluate the proposed metric on multiple popular text-to-image generation models and datasets in accessing both the perceptual quality and the text-image alignment. Moreover, it can successfully assess the generation ability of these models with as few as a hundred samples, making it very efficient in practice.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches"><a href="#Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches" class="headerlink" title="Painter: Teaching Auto-regressive Language Models to Draw Sketches"></a>Painter: Teaching Auto-regressive Language Models to Draw Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08520">http://arxiv.org/abs/2308.08520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Pourreza, Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Pulkit Madan, Roland Memisevic</li>
<li>for: 这篇论文旨在应用大型自然语言理解模型（LLM）来进行图像生成任务，直接从文本描述中生成虚拟的毫线绘制图像。</li>
<li>methods: 作者使用了一个基于废弃的LLM，通过精心调整和保留语言理解能力来构建了Painter模型，可以将文本描述转换为绘制图像的毫线绘制。</li>
<li>results: 作者创建了一个多bject绘制集，并使用Painter模型将文本描述转换为绘制图像，还可以从画布上除掉对象、检测和分类对象等功能。结果很有推动力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经取得了很大的进步，并在其他领域如计算机视觉、机器人学习、奖励学习等领域中得到成功应用。在这项工作中，我们将LLM应用于图像生成任务中，通过直接生成虚拟的毫梭来绘制图像。我们提出了一种名为“艺术家”的LLM，可以将用户提示转化为文本描述格式的绘制。我们基于市场上可获得的LLM预训练数据库，通过细化其新任务而不损失语言理解能力来构建艺术家。我们创建了一个包含多种物体和任务的多物体绘制数据集，以及与文本提示相对应的绘制。艺术家可以从文本描述中生成绘制，从画布上除除物体，并在绘制中检测和分类物体。虽然这是一项前所未有的使用LLM进行自然逻辑推导的图像生成的研究，但结果很有激励力。
</details></li>
</ul>
<hr>
<h2 id="Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems"><a href="#Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems" class="headerlink" title="Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems"></a>Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08511">http://arxiv.org/abs/2308.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirong Li, Yanyang Wang, Jianjia Zhang, Weiwen Wu, Hengyong Yu<br>for:* 这篇论文旨在解决 CT 和 MRI 领域中的不同数据类型的 inverse problem，包括 sparse-view CT 和 fast MRI reconstruction。methods:* 提出了一个新的 two-and-a-half order score-based model (TOSM)，它在训练阶段学习资料分布在 2D 空间，降低了训练的复杂性。* 在重建阶段，TOSM 使用了三个方向的补偿分数（sagittal、coronal 和 transaxial），实现更精确的重建。results:* 透过广泛的实验，发现 TOSM 可以实现高质量的 3D 积分重建，并且有效地解决了不同数据类型中的 inter-slice 不一致问题。<details>
<summary>Abstract</summary>
Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial technologies in the field of medical imaging. Score-based models have proven to be effective in addressing different inverse problems encountered in CT and MRI, such as sparse-view CT and fast MRI reconstruction. However, these models face challenges in achieving accurate three dimensional (3D) volumetric reconstruction. The existing score-based models primarily focus on reconstructing two dimensional (2D) data distribution, leading to inconsistencies between adjacent slices in the reconstructed 3D volumetric images. To overcome this limitation, we propose a novel two-and-a-half order score-based model (TOSM). During the training phase, our TOSM learns data distributions in 2D space, which reduces the complexity of training compared to directly working on 3D volumes. However, in the reconstruction phase, the TOSM updates the data distribution in 3D space, utilizing complementary scores along three directions (sagittal, coronal, and transaxial) to achieve a more precise reconstruction. The development of TOSM is built on robust theoretical principles, ensuring its reliability and efficacy. Through extensive experimentation on large-scale sparse-view CT and fast MRI datasets, our method demonstrates remarkable advancements and attains state-of-the-art results in solving 3D ill-posed inverse problems. Notably, the proposed TOSM effectively addresses the inter-slice inconsistency issue, resulting in high-quality 3D volumetric reconstruction.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 和磁共振成像 (MRI) 是医学成像领域的重要技术。分数模型已经证明可以有效地解决 CT 和 MRI 中的不同的反问题，如稀疏视图 CT 和快速 MRI 重建。然而，这些模型在实现准确的三维 (3D) 体积重建方面遇到了挑战。现有的分数模型主要关注在重建二维 (2D) 数据分布上，导致重建的3D体积图像中的邻近slice之间存在不一致。为了解决这个限制，我们提出了一种新的二阶三角形分数模型（TOSM）。在训练阶段，我们的 TOSM 学习了数据分布在2D空间上，这有助于减少训练的复杂性，相比直接在3D体积上进行训练。然而，在重建阶段，TOSM 使用了三个方向（极轴、极轴和扁平）的补偿分数，以实现更加精准的重建。TOSM 的开发基于坚实的理论原则，以确保其可靠性和效果。通过对大规模稀疏视图 CT 和快速 MRI 数据进行广泛的实验，我们的方法在解决 3D 不定 inverse problem 方面具有显著的进步和达到了当前领域的状态艺术。尤其是，我们的 TOSM 有效地解决了邻近slice之间的不一致问题，从而实现高质量的3D体积重建。
</details></li>
</ul>
<hr>
<h2 id="ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures"><a href="#ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures" class="headerlink" title="ResBuilder: Automated Learning of Depth with Residual Structures"></a>ResBuilder: Automated Learning of Depth with Residual Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08504">http://arxiv.org/abs/2308.08504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Burghoff, Matthias Rottmann, Jill von Conta, Sebastian Schoenen, Andreas Witte, Hanno Gottschalk</li>
<li>for: 这篇论文是为了开发一个基于 neural architecture search 的 ResNet 架构，以达到高精度低计算成本的目标。</li>
<li>methods: 该算法使用了一种名为 Resbuilder 的神经网络搜索算法，可以从 scratch 开发 ResNet 架构，并且可以修改现有架构，还可以从 ResNet 架构中移除和插入块。</li>
<li>results: 在不同的图像分类任务上进行实验，Resbuilder 可以达到与状态艺术级的性能，同时比 off-the-shelf ResNets 减少计算成本。此外，通过对 CIFAR10 进行参数调整，我们获得了一个适合所有其他任务的默认参数集，并且这种特性可以普遍应用于实际应用场景。<details>
<summary>Abstract</summary>
In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost. It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures. In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets. We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们开发了一种神经网络搜索算法，即Resbuilder，可以从头来开发高精度低计算成本的ResNet架构。它可以修改现有架构，并可以移除和插入ResNet块，因此可以在ResNet架构空间中进行搜索。在我们对不同的图像分类 dataset 进行实验时，Resbuilder 能够达到 state-of-the-art 性能，同时保持下来计算成本相对较低。值得注意的是，我们在 CIFAR10 上调参得到了一个适用于所有其他 dataset 的适当默认选择。我们示示了这种性能普适性，通过在一个商业应用中使用我们的方法并在默认参数下对一个专有诈骗检测 dataset 进行应用。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Online-Camera-Calibration-for-Automated-Driving-and-Parking-Applications"><a href="#Self-Supervised-Online-Camera-Calibration-for-Automated-Driving-and-Parking-Applications" class="headerlink" title="Self-Supervised Online Camera Calibration for Automated Driving and Parking Applications"></a>Self-Supervised Online Camera Calibration for Automated Driving and Parking Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08495">http://arxiv.org/abs/2308.08495</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ciarán Hogan, Ganesh Sistu, Ciarán Eising</li>
<li>for: 这个论文是为了提出一种基于深度学习的摄像头准确投影系统，用于现代自动驾驶车辆中。</li>
<li>methods: 该论文使用深度学习框架来学习摄像头的内在和外在准确参数，不需要任何标注或监督。</li>
<li>results: 该论文的实验结果表明，该深度学习框架可以在实时中学习摄像头的准确投影参数，不需要特殊的数据收集或精心调整。<details>
<summary>Abstract</summary>
Camera-based perception systems play a central role in modern autonomous vehicles. These camera based perception algorithms require an accurate calibration to map the real world distances to image pixels. In practice, calibration is a laborious procedure requiring specialised data collection and careful tuning. This process must be repeated whenever the parameters of the camera change, which can be a frequent occurrence in autonomous vehicles. Hence there is a need to calibrate at regular intervals to ensure the camera is accurate. Proposed is a deep learning framework to learn intrinsic and extrinsic calibration of the camera in real time. The framework is self-supervised and doesn't require any labelling or supervision to learn the calibration parameters. The framework learns calibration without the need for any physical targets or to drive the car on special planar surfaces.
</details>
<details>
<summary>摘要</summary>
Camera-based 感知系统在现代自动驾驶汽车中发挥中心作用。这些摄像头基于的感知算法需要精准的准确映射到实际世界中的距离。在实践中，准确是一个复杂的过程，需要专门的数据采集和精心调整。这个过程需要在相机参数发生变化时重复，这可能是自动驾驶汽车中的一个频繁发生的情况。因此，需要定期进行准确性检查。提议一种基于深度学习的框架，以自动学习摄像头的内在和外在准确参数。该框架不需要任何 labels 或监督来学习准确参数。该框架可以在不需要任何物理目标或特殊平面表面上学习准确参数。
</details></li>
</ul>
<hr>
<h2 id="DeDoDe-Detect-Don’t-Describe-–-Describe-Don’t-Detect-for-Local-Feature-Matching"><a href="#DeDoDe-Detect-Don’t-Describe-–-Describe-Don’t-Detect-for-Local-Feature-Matching" class="headerlink" title="DeDoDe: Detect, Don’t Describe – Describe, Don’t Detect for Local Feature Matching"></a>DeDoDe: Detect, Don’t Describe – Describe, Don’t Detect for Local Feature Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08479">http://arxiv.org/abs/2308.08479</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/parskatt/dedode">https://github.com/parskatt/dedode</a></li>
<li>paper_authors: Johan Edstedt, Georg Bökman, Mårten Wadenbäck, Michael Felsberg</li>
<li>for: 本文主要针对的是3D重建中的关键点检测问题，即在不同视图中检测出相同的3D点集。</li>
<li>methods: 本文使用了一种直接从3D一致性中学习关键点的方法，即通过训练从大规模SfM数据中检测出轨迹来学习关键点。为了解决缺少数据的问题，我们提出了一种半监督的两视检测目标函数，以扩展检测结果的数量。</li>
<li>results: 本文的方法DeDoDe在多个几何benchmark上实现了显著的提升，代码可以在<a target="_blank" rel="noopener" href="https://github.com/Parskatt/DeDoDe%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/Parskatt/DeDoDe上下载。</a><details>
<summary>Abstract</summary>
Keypoint detection is a pivotal step in 3D reconstruction, whereby sets of (up to) K points are detected in each view of a scene. Crucially, the detected points need to be consistent between views, i.e., correspond to the same 3D point in the scene. One of the main challenges with keypoint detection is the formulation of the learning objective. Previous learning-based methods typically jointly learn descriptors with keypoints, and treat the keypoint detection as a binary classification task on mutual nearest neighbours. However, basing keypoint detection on descriptor nearest neighbours is a proxy task, which is not guaranteed to produce 3D-consistent keypoints. Furthermore, this ties the keypoints to a specific descriptor, complicating downstream usage. In this work, we instead learn keypoints directly from 3D consistency. To this end, we train the detector to detect tracks from large-scale SfM. As these points are often overly sparse, we derive a semi-supervised two-view detection objective to expand this set to a desired number of detections. To train a descriptor, we maximize the mutual nearest neighbour objective over the keypoints with a separate network. Results show that our approach, DeDoDe, achieves significant gains on multiple geometry benchmarks. Code is provided at https://github.com/Parskatt/DeDoDe .
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>Scene 3D 重建中，关键点检测是一个关键步骤，其中每个视图中检测到多达K个点。这些点需要在不同视图中保持一致，即在场景中相同的3D点。关键点检测的主要挑战之一是学习目标函数的形式化。先前的学习基于方法通常是同时学习描述符和关键点，并将关键点检测视为视图中 nearest neighbors 的二分类任务。然而，基于描述符 nearest neighbors 的方法并不能保证生成3D 一致的关键点。此外，这会将关键点绑定到特定的描述符，使其下游使用变得复杂。在这种情况下，我们 direktly 从3D 一致中学习关键点。为此，我们在大规模 SfM 中训练检测器，以检测覆盖大规模 SfM 的点。由于这些点通常是过度稀疏，我们 derivate 一种 semi-supervised 的两视检测目标，以扩展这个集到所需的数量。为了训练描述符，我们在关键点上maximize 约束 nearest neighbors 的目标。结果表明我们的方法，DeDoDe，在多个几何度量上具有显著的提升。代码可以在 https://github.com/Parskatt/DeDoDe 中找到。
</details></li>
</ul>
<hr>
<h2 id="Classification-Committee-for-Active-Deep-Object-Detection"><a href="#Classification-Committee-for-Active-Deep-Object-Detection" class="headerlink" title="Classification Committee for Active Deep Object Detection"></a>Classification Committee for Active Deep Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08476">http://arxiv.org/abs/2308.08476</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ylzy123/CCADOD">https://github.com/ylzy123/CCADOD</a></li>
<li>paper_authors: Lei Zhao, Bo Li, Xingxing Wei<br>for:  This paper proposes an active deep object detection method that uses a classification committee to select the most informative images for training the object detector.methods:  The proposed method uses a main detector and a classification committee to select the most informative images based on their uncertainty values. The committee is pre-trained via the Maximum Classifiers Discrepancy Group Loss (MCDGL) and the Focus on Positive Instances Loss (FPIL) to mitigate the impact of interference instances.results:  The proposed method outperforms state-of-the-art active learning methods in object detection tasks on Pascal VOC and COCO datasets.<details>
<summary>Abstract</summary>
In object detection, the cost of labeling is much high because it needs not only to confirm the categories of multiple objects in an image but also to accurately determine the bounding boxes of each object. Thus, integrating active learning into object detection will raise pretty positive significance. In this paper, we propose a classification committee for active deep object detection method by introducing a discrepancy mechanism of multiple classifiers for samples' selection when training object detectors. The model contains a main detector and a classification committee. The main detector denotes the target object detector trained from a labeled pool composed of the selected informative images. The role of the classification committee is to select the most informative images according to their uncertainty values from the view of classification, which is expected to focus more on the discrepancy and representative of instances. Specifically, they compute the uncertainty for a specified instance within the image by measuring its discrepancy output by the committee pre-trained via the proposed Maximum Classifiers Discrepancy Group Loss (MCDGL). The most informative images are finally determined by selecting the ones with many high-uncertainty instances. Besides, to mitigate the impact of interference instances, we design a Focus on Positive Instances Loss (FPIL) to make the committee the ability to automatically focus on the representative instances as well as precisely encode their discrepancies for the same instance. Experiments are conducted on Pascal VOC and COCO datasets versus some popular object detectors. And results show that our method outperforms the state-of-the-art active learning methods, which verifies the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
在物体检测中，标注成本很高，因为需要不仅确定图像中多个物体的类别，还需要准确确定每个物体的 bounding box。因此，将活动学习 интегрирован到物体检测中将具有非常正面的意义。在这篇论文中，我们提出了一种 classification committee  для活动深度物体检测方法，通过引入多个分类器的偏差机制来选择训练物体检测器时的样本。模型包括主检测器和分类委员会。主检测器表示从标注池中训练的目标物体检测器，而分类委员会的角色是选择图像中最有用的信息的样本，这些样本的uncertainty值由分类委员会预训练得到的MCDGL（最大分类器偏差组loss）进行计算。最终选择最有用的图像是根据它们中高uncertainty实例的多少进行选择。此外，为了减少干扰实例的影响，我们设计了Focus on Positive Instances Loss（FPIL），使得委员会能够自动关注代表实例，同时精确编码它们的偏差。在 Pascal VOC 和 COCO  datasets 上进行了实验，与一些流行的物体检测器进行比较，结果表明，我们的方法在活动学习方法中表现出色，这证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks"><a href="#Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks" class="headerlink" title="Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks"></a>Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08465">http://arxiv.org/abs/2308.08465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Bai, Wenjia Bai</li>
<li>for: 建立一个可信任的医疗影像分类模型，需要不仅评估模型的性能，而且也需要估计模型预测结果中的不确定性。</li>
<li>methods: 我们利用了这个嵌入式Encoder架构，将影像特征从细节到概要层次提取出来，然后使用 skip-connection 模组估计多个层次的不确定性。</li>
<li>results: 我们显示了，将这种多层次不确定性估计模组添加到深度学习分类网络中，可以实现高度的分类性能，同时提供了有意义的不确定性地图，可以用于过度分布检测。<details>
<summary>Abstract</summary>
Learning a medical image segmentation model is an inherently ambiguous task, as uncertainties exist in both images (noise) and manual annotations (human errors and bias) used for model training. To build a trustworthy image segmentation model, it is important to not just evaluate its performance but also estimate the uncertainty of the model prediction. Most state-of-the-art image segmentation networks adopt a hierarchical encoder architecture, extracting image features at multiple resolution levels from fine to coarse. In this work, we leverage this hierarchical image representation and propose a simple yet effective method for estimating uncertainties at multiple levels. The multi-level uncertainties are modelled via the skip-connection module and then sampled to generate an uncertainty map for the predicted image segmentation. We demonstrate that a deep learning segmentation network such as U-net, when implemented with such hierarchical uncertainty estimation module, can achieve a high segmentation performance, while at the same time provide meaningful uncertainty maps that can be used for out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
学习医学图像分割模型是一个自然而又不确定的任务，因为图像中的噪声和人工标注（人类错误和偏见）在模型训练中存在不确定性。为建立可靠的图像分割模型，不仅要评估其性能，还需要估计模型预测结果中的不确定性。大多数当前的图像分割网络采用层次编码结构，从细到粗渐地提取图像特征。在这种工作中，我们利用这种层次图像表示，并提议一种简单 yet 有效的方法来估计多个水平的不确定性。这些多个不确定性被模型的跳过连接模块模型，然后采样以生成预测图像分割结果中的不确定性地图。我们示示了一个深度学习分割网络，如U-Net，当它被实现了这种层次不确定性估计模块时，可以 дости到高的分割性能，同时提供可靠的不确定性地图，可以用于非典型检测。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Distill-Global-Representation-for-Sparse-View-CT"><a href="#Learning-to-Distill-Global-Representation-for-Sparse-View-CT" class="headerlink" title="Learning to Distill Global Representation for Sparse-View CT"></a>Learning to Distill Global Representation for Sparse-View CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08463">http://arxiv.org/abs/2308.08463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilong Li, Chenglong Ma, Jie Chen, Junping Zhang, Hongming Shan</li>
<li>for: 这个论文主要针对的是使用少量投影计算tomography图像的问题，以及通过图像后处理技术提高图像质量的问题。</li>
<li>methods: 这个论文使用了图像后处理技术，包括global representation（GloRe）混合约束和批处理学习等方法。</li>
<li>results: 实验结果表明，提议的GloReDi方法在ultra-sparse-view计算tomography图像中的重建效果明显更高，并且与现有的双频域方法相比，具有更好的扩展性和可靠性。<details>
<summary>Abstract</summary>
Sparse-view computed tomography (CT) -- using a small number of projections for tomographic reconstruction -- enables much lower radiation dose to patients and accelerated data acquisition. The reconstructed images, however, suffer from strong artifacts, greatly limiting their diagnostic value. Current trends for sparse-view CT turn to the raw data for better information recovery. The resultant dual-domain methods, nonetheless, suffer from secondary artifacts, especially in ultra-sparse view scenarios, and their generalization to other scanners/protocols is greatly limited. A crucial question arises: have the image post-processing methods reached the limit? Our answer is not yet. In this paper, we stick to image post-processing methods due to great flexibility and propose global representation (GloRe) distillation framework for sparse-view CT, termed GloReDi. First, we propose to learn GloRe with Fourier convolution, so each element in GloRe has an image-wide receptive field. Second, unlike methods that only use the full-view images for supervision, we propose to distill GloRe from intermediate-view reconstructed images that are readily available but not explored in previous literature. The success of GloRe distillation is attributed to two key components: representation directional distillation to align the GloRe directions, and band-pass-specific contrastive distillation to gain clinically important details. Extensive experiments demonstrate the superiority of the proposed GloReDi over the state-of-the-art methods, including dual-domain ones. The source code is available at https://github.com/longzilicart/GloReDi.
</details>
<details>
<summary>摘要</summary>
sparse-view computed tomography (CT) 使用少量投射进行tomographic reconstruction，可以大大降低病人接受的辐射剂量并加速数据获取。然而，重建图像却受到强烈的artifacts的限制，因此其诊断价值受到了很大的限制。当前的趋势是使用原始数据来提取更多的信息。结果的双Domain方法却受到了次要的artifacts，特别是在ultra-sparse view scenario下，其普遍性受到了限制。问题是：图像后处理方法是否已经达到了其限制？我们的答案是不是。在这篇文章中，我们选择使用图像后处理方法，因为它具有很大的灵活性。我们提出了一种全球表示（GloRe）液化框架，称之为GloReDi。首先，我们提出了使用傅里叶变换来学习GloRe，以确保每个GloRe元素都具有整个图像的报知频谱。其次，不同于以前的方法，我们提出了使用中间视图重建图像进行监督，这些图像ready available但没有在前期文献中被探讨。GloRe的Success被归因于两个关键组成部分：方向性液化照明和带宽特征相关的液化照明。我们进行了广泛的实验，并证明了我们的GloReDi在现有的方法之上具有优越性。代码可以在https://github.com/longzilicart/GloReDi中获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.CV_2023_08_17/" data-id="clorjzl6800guf1880nksesd1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.AI_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T12:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.AI_2023_08_17/">cs.AI - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization"><a href="#Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization" class="headerlink" title="Enhancing API Documentation through BERTopic Modeling and Summarization"></a>Enhancing API Documentation through BERTopic Modeling and Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09070">http://arxiv.org/abs/2308.09070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scam2023-bert/bertopic">https://github.com/scam2023-bert/bertopic</a></li>
<li>paper_authors: AmirHossein Naghshzan, Sylvie Ratte</li>
<li>for: 本研究旨在提高API文档理解的效率和可用性，以帮助开发者更好地利用API功能。</li>
<li>methods: 本研究使用BERTopic进行主题分析和自然语言处理（NLP）技术，自动生成API文档摘要，从而为开发者提供更加有效的信息检索方式。</li>
<li>results: 研究发现API文档中有很多重复的主题和问题，并生成了可行的解决方案。这些发现和解决方案可以帮助开发者更好地理解API文档，提高软件开发过程的效率和质量。<details>
<summary>Abstract</summary>
As the amount of textual data in various fields, including software development, continues to grow, there is a pressing demand for efficient and effective extraction and presentation of meaningful insights. This paper presents a unique approach to address this need, focusing on the complexities of interpreting Application Programming Interface (API) documentation. While official API documentation serves as a primary source of information for developers, it can often be extensive and lacks user-friendliness. In light of this, developers frequently resort to unofficial sources like Stack Overflow and GitHub. Our novel approach employs the strengths of BERTopic for topic modeling and Natural Language Processing (NLP) to automatically generate summaries of API documentation, thereby creating a more efficient method for developers to extract the information they need. The produced summaries and topics are evaluated based on their performance, coherence, and interoperability.   The findings of this research contribute to the field of API documentation analysis by providing insights into recurring topics, identifying common issues, and generating potential solutions. By improving the accessibility and efficiency of API documentation comprehension, our work aims to enhance the software development process and empower developers with practical tools for navigating complex APIs.
</details>
<details>
<summary>摘要</summary>
随着不同领域的文本数据量不断增加，包括软件开发，有效地提取和表现出有用的洞察结论变得越来越重要。这篇论文提出了一种独特的方法来解决这个需求，集中在API文档的复杂性上。官方API文档作为开发者的主要信息来源，然而它们经常是广泛的和不易于使用的。为了解决这个问题，开发者们经常查看Stack Overflow和GitHub等非官方源。我们的新方法利用BERTopic的主题分析和自然语言处理（NLP）技术自动生成API文档的摘要，从而创造了一种更高效的方法，使开发者可以更方便地提取所需的信息。生成的摘要和主题都被评估了其性能、一致性和可共享性。这些研究结果对API文档分析领域做出了贡献，提供了复杂API文档中的循环主题、通用问题和 potential解决方案的洞察。通过提高API文档的可访问性和效率，我们的工作希望能够改善软件开发过程，并为开发者们提供实用的工具来探索复杂的API。
</details></li>
</ul>
<hr>
<h2 id="Fostering-User-Engagement-in-the-Critical-Reflection-of-Arguments"><a href="#Fostering-User-Engagement-in-the-Critical-Reflection-of-Arguments" class="headerlink" title="Fostering User Engagement in the Critical Reflection of Arguments"></a>Fostering User Engagement in the Critical Reflection of Arguments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09061">http://arxiv.org/abs/2308.09061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Klaus Weber, Annalena Aicher, Wolfang Minker, Stefan Ultes, Elisabeth André</li>
<li>for: 支持公正、不偏袋化的意见形成过程</li>
<li>methods: 使用对话系统和模型来评估用户的反思程度和开放性</li>
<li>results: 在58名参与者的用户研究中，发现了对用户反思和总体关注程度的显著影响，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
A natural way to resolve different points of view and form opinions is through exchanging arguments and knowledge. Facing the vast amount of available information on the internet, people tend to focus on information consistent with their beliefs. Especially when the issue is controversial, information is often selected that does not challenge one's beliefs. To support a fair and unbiased opinion-building process, we propose a chatbot system that engages in a deliberative dialogue with a human. In contrast to persuasive systems, the envisioned chatbot aims to provide a diverse and representative overview - embedded in a conversation with the user. To account for a reflective and unbiased exploration of the topic, we enable the system to intervene if the user is too focused on their pre-existing opinion. Therefore we propose a model to estimate the users' reflective engagement (RUE), defined as their critical thinking and open-mindedness. We report on a user study with 58 participants to test our model and the effect of the intervention mechanism, discuss the implications of the results, and present perspectives for future work. The results show a significant effect on both user reflection and total user focus, proving our proposed approach's validity.
</details>
<details>
<summary>摘要</summary>
自然的方式解决不同看法和形成意见是通过互动对话和交换知识。面对互联网上的巨量信息，人们往往会选择一些不会挑战他们的信念的信息。特别是当问题是争议的时，人们往往会偏好一些不会挑战他们的信念的信息。为了支持公正和不偏袋的意见形成过程，我们提议一个 chatbot 系统，与人类进行审慎对话。与推销系统不同的是，我们的 chatbot 旨在提供多样化和代表性的概述，并且在与用户进行对话时嵌入在其中。为了考虑用户的反思和公正探索，我们允许系统在用户过于围绕自己的先前意见时进行 вмешательство。为了衡量用户的反思程度，我们提出了用户反思参与度（RUE）模型，定义为用户的批判思维和开明性。我们报告了一个用户研究，测试我们的模型和干预机制的效果，讨论结果的意义，并提出未来工作的视角。结果显示我们的方法有效，用户反思程度和总用户焦点都有显著改善。
</details></li>
</ul>
<hr>
<h2 id="Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods"><a href="#Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods" class="headerlink" title="Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods"></a>Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09051">http://arxiv.org/abs/2308.09051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paavo Alku, Sudarsana Reddy Kadiri, Dhananjaya Gowda</li>
<li>for: 这个研究 investigate了使用数据驱动的DeepFormants跟踪器进行形式追踪，并使用模型驱动的LP-based方法来进一步改进跟踪结果。</li>
<li>methods: 这个研究使用了LP-COV和QCP-FB两种LP-based形式估计方法，并将其与数据驱动的DeepFormants跟踪器结合使用，以提高跟踪结果。</li>
<li>results: 研究结果显示，使用LP-based模型驱动的跟踪器可以提高跟踪效果，并且使用QCP-FB分析方法可以获得最佳的跟踪结果。  Additionally, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers when tracking formants using VTR speech that was corrupted by additive noise.<details>
<summary>Abstract</summary>
In this study, formant tracking is investigated by refining the formants tracked by an existing data-driven tracker, DeepFormants, using the formants estimated in a model-driven manner by linear prediction (LP)-based methods. As LP-based formant estimation methods, conventional covariance analysis (LP-COV) and the recently proposed quasi-closed phase forward-backward (QCP-FB) analysis are used. In the proposed refinement approach, the contours of the three lowest formants are first predicted by the data-driven DeepFormants tracker, and the predicted formants are replaced frame-wise with local spectral peaks shown by the model-driven LP-based methods. The refinement procedure can be plugged into the DeepFormants tracker with no need for any new data learning. Two refined DeepFormants trackers were compared with the original DeepFormants and with five known traditional trackers using the popular vocal tract resonance (VTR) corpus. The results indicated that the data-driven DeepFormants trackers outperformed the conventional trackers and that the best performance was obtained by refining the formants predicted by DeepFormants using QCP-FB analysis. In addition, by tracking formants using VTR speech that was corrupted by additive noise, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers. In general, these results suggest that LP-based model-driven approaches, which have traditionally been used in formant estimation, can be combined with a modern data-driven tracker easily with no further training to improve the tracker's performance.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究了使用数据驱动的 DeepFormants 溯形器进行形式追踪，并使用 LP-based 方法来估计形式。我们使用了传统的 covariance analysis（LP-COV）和最近提出的 quasi-closed phase forward-backward（QCP-FB）分析。在我们的改进方法中，首先使用 DeepFormants 溯形器预测三个最低的形式迹，然后将预测的形式迹替换为每帧的本地 спектral peak 显示出来。这个改进过程可以轻松地插入到 DeepFormants 溯形器中，无需进行任何新的数据学习。我们比较了两个改进后的 DeepFormants 溯形器与原始的 DeepFormants 和五个知名的传统溯形器，使用 popular vocal tract resonance（VTR） corpus。结果表明，数据驱动的 DeepFormants 溯形器比传统的溯形器更高效，而使用 QCP-FB 分析进行改进可以获得最佳性能。此外，通过使用受到添加噪声损害的 VTR 语音进行追踪，研究表明，改进后的 DeepFormants 溯形器比参照溯形器更抗雷。总之，这些结果表明，LP-based 模型驱动方法可以轻松地与现代数据驱动溯形器结合使用，以提高溯形器的性能。
</details></li>
</ul>
<hr>
<h2 id="Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features"><a href="#Severity-Classification-of-Parkinson’s-Disease-from-Speech-using-Single-Frequency-Filtering-based-Features" class="headerlink" title="Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features"></a>Severity Classification of Parkinson’s Disease from Speech using Single Frequency Filtering-based Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09042">http://arxiv.org/abs/2308.09042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarsana Reddy Kadiri, Manila Kodali, Paavo Alku</li>
<li>for: 本研究的目的是提出一种新的评估多巴生殖疾病（PD）严重程度的对象方法，以改善诊断和治疗。</li>
<li>methods: 本研究使用了单频 filtering（SFF）方法， derivated two sets of novel features：(1) SFF cepstral coefficients（SFFCC）和(2) MFCCs from SFF（MFCC-SFF），用于识别PD的严重程度。</li>
<li>results: 实验表明，提posed的特征比 conventinal MFCCs在三种说话任务（元音、句子、文本读取）中都有较好的表现，具体来说，SFFCC和MFCC-SFF特征在元音任务中比MFCC特征提高5.8%和2.3%，在句子任务中提高7.0%和1.8%，在文本读取任务中提高2.4%和1.1%。<details>
<summary>Abstract</summary>
Developing objective methods for assessing the severity of Parkinson's disease (PD) is crucial for improving the diagnosis and treatment. This study proposes two sets of novel features derived from the single frequency filtering (SFF) method: (1) SFF cepstral coefficients (SFFCC) and (2) MFCCs from the SFF (MFCC-SFF) for the severity classification of PD. Prior studies have demonstrated that SFF offers greater spectro-temporal resolution compared to the short-time Fourier transform. The study uses the PC-GITA database, which includes speech of PD patients and healthy controls produced in three speaking tasks (vowels, sentences, text reading). Experiments using the SVM classifier revealed that the proposed features outperformed the conventional MFCCs in all three speaking tasks. The proposed SFFCC and MFCC-SFF features gave a relative improvement of 5.8% and 2.3% for the vowel task, 7.0% & 1.8% for the sentence task, and 2.4% and 1.1% for the read text task, in comparison to MFCC features.
</details>
<details>
<summary>摘要</summary>
开发对parkinson病（PD）严重程度评估方法是至关重要，以提高诊断和治疗的效果。这项研究提出了两个新的特征集：（1）单频范围滤波（SFF）cepstral coefficients（SFFCC）和（2）基于SFF的MFCC（MFCC-SFF），用于PD严重分类。先前的研究表明，SFF在spectro-temporal分辨率方面比短时傅立干更高。本研究使用PC-GITA数据库，包括PD患者和正常人的语音数据，从三种说话任务（声音、句子、文本阅读）中获得。实验表明，提出的特征超过了传统MFCC特征，在三种说话任务中都有显著提高。SFFCC和MFCC-SFF特征相比MFCC特征，在声音任务中提高5.8%、7.0%和2.4%，在句子任务中提高1.8%和1.1%，在文本阅读任务中提高2.3%。
</details></li>
</ul>
<hr>
<h2 id="A-Mathematical-Characterization-of-Minimally-Sufficient-Robot-Brains"><a href="#A-Mathematical-Characterization-of-Minimally-Sufficient-Robot-Brains" class="headerlink" title="A Mathematical Characterization of Minimally Sufficient Robot Brains"></a>A Mathematical Characterization of Minimally Sufficient Robot Brains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09041">http://arxiv.org/abs/2308.09041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Basak Sakcak, Kalle G. Timperi, Vadim Weinstein, Steven M. LaValle</li>
<li>for: 本研究探讨了内部系统（机器人算法或软件）与外部系统（机器人身体和环境）之间的交互所获得的信息的下限。</li>
<li>methods: 本研究使用过程系统来模型内部系统和外部系统之间的交互，并研究了最弱的内部系统是否具备可以完成过滤和规划任务的能力。</li>
<li>results: 研究发现，在给定机器人硬件和任务下，存在最小的信息过程系统，这些系统具备Uniqueness和可以实现的性。此外，这些系统还可以用于解决优化整合&#x2F;筛选、基本规划任务和模型系统给定输入-输出关系的问题。<details>
<summary>Abstract</summary>
This paper addresses the lower limits of encoding and processing the information acquired through interactions between an internal system (robot algorithms or software) and an external system (robot body and its environment) in terms of action and observation histories. Both are modeled as transition systems. We want to know the weakest internal system that is sufficient for achieving passive (filtering) and active (planning) tasks. We introduce the notion of an information transition system for the internal system which is a transition system over a space of information states that reflect a robot's or other observer's perspective based on limited sensing, memory, computation, and actuation. An information transition system is viewed as a filter and a policy or plan is viewed as a function that labels the states of this information transition system. Regardless of whether internal systems are obtained by learning algorithms, planning algorithms, or human insight, we want to know the limits of feasibility for given robot hardware and tasks. We establish, in a general setting, that minimal information transition systems exist up to reasonable equivalence assumptions, and are unique under some general conditions. We then apply the theory to generate new insights into several problems, including optimal sensor fusion/filtering, solving basic planning tasks, and finding minimal representations for modeling a system given input-output relations.
</details>
<details>
<summary>摘要</summary>
To address this question, the paper introduces the concept of an information transition system for the internal system, which is a transition system over a space of information states that reflect the robot's or other observer's perspective based on limited sensing, memory, computation, and actuation. An information transition system is viewed as a filter, and a policy or plan is viewed as a function that labels the states of this information transition system.The paper establishes, in a general setting, that minimal information transition systems exist and are unique under certain conditions. These minimal systems are the weakest possible internal systems that can achieve the desired tasks. The theory is then applied to generate new insights into several problems, including optimal sensor fusion/filtering, solving basic planning tasks, and finding minimal representations for modeling a system given input-output relations.In simplified Chinese, the paper is about exploring the minimum amount of information and processing power needed for a robot to perform tasks such as filtering and planning, and how to model this information and processing power using transition systems. The paper introduces the concept of an information transition system, which is a way of representing the robot's perspective based on limited sensing, memory, computation, and actuation. The paper shows that there exist minimal information transition systems that are unique and sufficient for achieving passive and active tasks. These insights can be applied to various problems such as optimal sensor fusion, basic planning, and finding minimal representations for modeling a system.
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Physically-Plausible-Human-Motions-in-3D-Scenes"><a href="#Synthesizing-Physically-Plausible-Human-Motions-in-3D-Scenes" class="headerlink" title="Synthesizing Physically Plausible Human Motions in 3D Scenes"></a>Synthesizing Physically Plausible Human Motions in 3D Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09036">http://arxiv.org/abs/2308.09036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liangpan99/interscene">https://github.com/liangpan99/interscene</a></li>
<li>paper_authors: Liang Pan, Jingbo Wang, Buzhen Huang, Junyu Zhang, Haofan Wang, Xu Tang, Yangang Wang</li>
<li>for: 本研究旨在Synthesizing physically plausible human motions in 3D scenes, 解决现有的kinematics-based方法和physics-based方法存在缺陷，如penetration和foot skating。</li>
<li>methods: 我们提出了一种框架，即InterScene，将人类-场景交互分解成两个基本过程：Interacting和Navigating，并设计了两个可重用控制器，即InterCon和NavCon。</li>
<li>results: 实验结果表明，我们的框架可以在复杂的3D场景中生成physically plausible的长期人类运动。Here’s the translation in English for reference:</li>
<li>for: The paper aims to synthesize physically plausible human motions in 3D scenes, addressing the limitations of existing kinematics-based and physics-based methods, such as penetration and foot skating.</li>
<li>methods: We propose a framework called InterScene, which decomposes human-scene interactions into two fundamental processes, Interacting and Navigating, and designs two reusable controllers, InterCon and NavCon.</li>
<li>results: Experimental results demonstrate that our framework can generate physically plausible long-term human motions in complex 3D scenes.<details>
<summary>Abstract</summary>
Synthesizing physically plausible human motions in 3D scenes is a challenging problem. Kinematics-based methods cannot avoid inherent artifacts (e.g., penetration and foot skating) due to the lack of physical constraints. Meanwhile, existing physics-based methods cannot generalize to multi-object scenarios since the policy trained with reinforcement learning has limited modeling capacity. In this work, we present a framework that enables physically simulated characters to perform long-term interaction tasks in diverse, cluttered, and unseen scenes. The key idea is to decompose human-scene interactions into two fundamental processes, Interacting and Navigating, which motivates us to construct two reusable Controller, i.e., InterCon and NavCon. Specifically, InterCon contains two complementary policies that enable characters to enter and leave the interacting state (e.g., sitting on a chair and getting up). To generate interaction with objects at different places, we further design NavCon, a trajectory following policy, to keep characters' locomotion in the free space of 3D scenes. Benefiting from the divide and conquer strategy, we can train the policies in simple environments and generalize to complex multi-object scenes. Experimental results demonstrate that our framework can synthesize physically plausible long-term human motions in complex 3D scenes. Code will be publicly released at https://github.com/liangpan99/InterScene.
</details>
<details>
<summary>摘要</summary>
使三维场景中的人物表现出physically plausible的运动是一个复杂的问题。基于骨骼动学的方法无法避免内在的缺陷（例如冲突和脚滑）由于physical constraints的缺失。而现有的物理学基的方法则无法泛化到多 объек 场景，因为训练的策略使用了强化学习有限的模型ing capacity。在这项工作中，我们提出了一种框架，允许 физи simulated 人物在多物件场景中进行长期交互任务。我们的关键思想是将人物-场景交互 decomposed 成两个基本过程：交互和导航。这使我们可以构建两个可重用的控制器，即InterCon和NavCon。具体来说，InterCon包含两个补做策略，使人物能够进入和离开交互状态（例如坐在椅子上和站起来）。为了在不同的位置上生成对象与人物之间的交互，我们还设计了 NavCon，一个路径跟踪策略，以保证人物在3D场景中的自由运动。由于我们采用了分而治之策略，我们可以在简单的环境中训练策略，并在复杂的多物件场景中进行泛化。实验结果表明，我们的框架可以在复杂的3D场景中生成physically plausible的长期人物运动。代码将在https://github.com/liangpan99/InterScene 上公开。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming"><a href="#Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming" class="headerlink" title="Reinforcement Learning for Battery Management in Dairy Farming"></a>Reinforcement Learning for Battery Management in Dairy Farming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09023">http://arxiv.org/abs/2308.09023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nawazish Ali, Abdul Wahid, Rachael shaw, Karl Mason</li>
<li>for: 本研究旨在应用人工智能（AI）以提高牛奶牧场中的可再生能源发电效率。</li>
<li>methods: 本研究使用Q学习算法来学习一个有效的电池充放和充电策略。</li>
<li>results: 研究结果显示，开发的策略可以对比基准算法大幅降低电力成本。这些结果显示了强化学习在牛奶牧场中电池管理中的效iveness。<details>
<summary>Abstract</summary>
Dairy farming is a particularly energy-intensive part of the agriculture sector. Effective battery management is essential for renewable integration within the agriculture sector. However, controlling battery charging/discharging is a difficult task due to electricity demand variability, stochasticity of renewable generation, and energy price fluctuations. Despite the potential benefits of applying Artificial Intelligence (AI) to renewable energy in the context of dairy farming, there has been limited research in this area. This research is a priority for Ireland as it strives to meet its governmental goals in energy and sustainability. This research paper utilizes Q-learning to learn an effective policy for charging and discharging a battery within a dairy farm setting. The results demonstrate that the developed policy significantly reduces electricity costs compared to the established baseline algorithm. These findings highlight the effectiveness of reinforcement learning for battery management within the dairy farming sector.
</details>
<details>
<summary>摘要</summary>
奶业是农业部分中最为能源密集的一部分。有效的电池管理是农业部门中绿色能源融合的关键。然而，控制电池充放电是一项具有挑战性的任务，这主要归结于能源需求的变化、可再生能源生产的随机性和能源价格的波动。尽管应用人工智能（AI）于奶业中可能带来多少优势，然而有限的研究进行了在这个领域。这项研究使用Q学习算法学习一个有效的电池充放电策略。研究结果表明，开发的策略可以significantly降低电力成本，与已有的基线算法相比。这些发现 highlights了Q学习在奶业中电池管理的有效性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability"><a href="#Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability" class="headerlink" title="Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability"></a>Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09004">http://arxiv.org/abs/2308.09004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renan Souza, Tyler J. Skluzacek, Sean R. Wilkinson, Maxim Ziatdinov, Rafael Ferreira da Silva</li>
<li>for: 这 paper 的目的是提出一种基于数据可见性的多任务集成数据分析方法，以满足现代大规模科学发现所需的多学科协作和多 computing 环境。</li>
<li>methods: 该 paper 使用了数据可见性策略和适配器系统设计，以及证明信息，来实现轻量级运行时多 workflow 集成数据分析。</li>
<li>results: 实验表明，该方法可以在多种并行系统和机器学习工具上实现near-zero overhead的多任务集成数据分析，并在 Summit 超级计算机上运行 up to 100,000 任务。<details>
<summary>Abstract</summary>
Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.
</details>
<details>
<summary>摘要</summary>
现代大规模科学发现需要跨学科合作，包括高性能计算机（HPC）机器和边缘到云端的连续体系。集成数据分析在科学发现中扮演着关键性角色，特别是在当今人工智能时代，可以实现负责任的人工智能开发、FAIR、可重现和用户导航。然而，科学的多样性带来了多种支持工具、跨设施环境和高效HPC执行的挑战。基于数据可见性、适配器系统设计和 происхождение，我们提出了MIDA：一种轻量级运行时多 workflow интеGRATED数据分析方法。MIDA定义了数据可见性策略和适配方法，可以在多种并行系统和机器学习工具上使用。通过可见性，它可以在背景中 intercept数据流无需实rumentation，并将domain、 происхождение和telemetry数据集成到运行时，并将其存储在一个统一的数据库中，准备就绪 для用户导航查询。我们对实验结果表明，可以在多种环境中同时运行多个 workflow，并将数据集成到一个统一的数据库中，并且可以实现近于零 overhead。在 Summit 超级计算机上，我们运行了100,000个任务，使用1,680个CPU核心，并在多个环境中使用多达276个GPU并行运行。
</details></li>
</ul>
<hr>
<h2 id="An-Extended-Convergence-Result-for-Behaviour-Tree-Controllers"><a href="#An-Extended-Convergence-Result-for-Behaviour-Tree-Controllers" class="headerlink" title="An Extended Convergence Result for Behaviour Tree Controllers"></a>An Extended Convergence Result for Behaviour Tree Controllers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08994">http://arxiv.org/abs/2308.08994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Iliffe Sprague, Petter Ögren</li>
<li>for: 这篇论文是为了研究行为树（BTs）的叉集抽象和控制策略的可能性。</li>
<li>methods: 这篇论文使用了一种树结构，将低级控制策略组合成为层次结构，从而实现控制策略的可模块化。</li>
<li>results: 这篇论文研究了行为树的叉集抽象和控制策略的可能性，并推广了之前的结果，包括新的循环切换情况。<details>
<summary>Abstract</summary>
Behavior trees (BTs) are an optimally modular framework to assemble hierarchical hybrid control policies from a set of low-level control policies using a tree structure. Many robotic tasks are naturally decomposed into a hierarchy of control tasks, and modularity is a well-known tool for handling complexity, therefor behavior trees have garnered widespread usage in the robotics community. In this paper, we study the convergence of BTs, in the sense of reaching a desired part of the state space. Earlier results on BT convergence were often tailored to specific families of BTs, created using different design principles. The results of this paper generalize the earlier results and also include new cases of cyclic switching not covered in the literature.
</details>
<details>
<summary>摘要</summary>
行为树（BT）是一种最佳的模块化框架，可以将层次结构的混合控制策略从一组低级控制策略中组装 together。许多 робо械任务自然可以被划分为一个层次结构的控制任务，而模块化是处理复杂性的知名工具，因此行为树在机器人社区中得到了广泛的应用。在这篇论文中，我们研究行为树的叉树，即达到某个状态空间中的愿景部分。先前的结果通常是针对特定的行为树设计原则而设计的，本paper的结果可以总结这些结果，并包括先前未被探讨的循环切换情况。
</details></li>
</ul>
<hr>
<h2 id="KnowledGPT-Enhancing-Large-Language-Models-with-Retrieval-and-Storage-Access-on-Knowledge-Bases"><a href="#KnowledGPT-Enhancing-Large-Language-Models-with-Retrieval-and-Storage-Access-on-Knowledge-Bases" class="headerlink" title="KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases"></a>KnowledGPT: Enhancing Large Language Models with Retrieval and Storage Access on Knowledge Bases</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11761">http://arxiv.org/abs/2308.11761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xintao Wang, Qianwen Yang, Yongting Qiu, Jiaqing Liang, Qianyu He, Zhouhong Gu, Yanghua Xiao, Wei Wang</li>
<li>for: 该论文旨在探讨如何将大型自然语言处理模型（LLM）与多种知识库（KB）集成，以提高模型的完整性、时效性、忠诚性和适应性。</li>
<li>methods: 该论文提出了一种名为 KnowledGPT 的全面框架，可以将 LLM 与多种 KB 集成，并提供了两种方法：一是使用思维提示程序来为 KB 进行搜索，二是将个性化知识库（PKB）引入到 LLM 中，以满足用户的特定需求。</li>
<li>results: 经过广泛的实验，该论文表明，通过将 LLM 与 KB 集成， KnowledGPT 可以更好地回答需要世界知识的问题，比如使用已知 KB 中的知识和从 PKB 中提取的个性化知识。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive impact in the field of natural language processing, but they still struggle with several issues regarding, such as completeness, timeliness, faithfulness and adaptability. While recent efforts have focuses on connecting LLMs with external knowledge sources, the integration of knowledge bases (KBs) remains understudied and faces several challenges. In this paper, we introduce KnowledGPT, a comprehensive framework to bridge LLMs with various knowledge bases, facilitating both the retrieval and storage of knowledge. The retrieval process employs the program of thought prompting, which generates search language for KBs in code format with pre-defined functions for KB operations. Besides retrieval, KnowledGPT offers the capability to store knowledge in a personalized KB, catering to individual user demands. With extensive experiments, we show that by integrating LLMs with KBs, KnowledGPT properly answers a broader range of questions requiring world knowledge compared with vanilla LLMs, utilizing both knowledge existing in widely-known KBs and extracted into personalized KBs.
</details>
<details>
<summary>摘要</summary>
The retrieval process uses the program of thought prompting, which generates search language for KBs in code format with pre-defined functions for KB operations. In addition to retrieval, KnowledGPT offers the capability to store knowledge in a personalized KB, catering to individual user demands. With extensive experiments, we show that by integrating LLMs with KBs, KnowledGPT can properly answer a broader range of questions requiring world knowledge compared to vanilla LLMs, utilizing both knowledge existing in widely-known KBs and extracted into personalized KBs.
</details></li>
</ul>
<hr>
<h2 id="Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health"><a href="#Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health" class="headerlink" title="Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health"></a>Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09726">http://arxiv.org/abs/2308.09726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/socialgood">https://github.com/google-research/socialgood</a></li>
<li>paper_authors: Jackson A. Killian, Manish Jain, Yugang Jia, Jonathan Amar, Erich Huang, Milind Tambe</li>
<li>For: 这篇论文研究了如何使用多臂抽签机制（Restless Multi-armed Bandits，RMAB）来实现公平的决策，尤其是在电子健康领域。* Methods: 论文使用了两种平衡公平性的目标函数：最小最大奖赏和Nash均衡益。论文也提出了一个水满算法和一个理论据基于的均衡算法来解决这两个目标函数。* Results: 论文透过三个模拟领域的实验结果表明，使用论文提出的方法可以实现多倍的公平性，而且不需要严重影响使用度的损失。这些结果证明了论文的重要性，因为RMAB在影响人类和野生动物的系统中愈来愈普遍。<details>
<summary>Abstract</summary>
Restless multi-armed bandits (RMABs) are a popular framework for algorithmic decision making in sequential settings with limited resources. RMABs are increasingly being used for sensitive decisions such as in public health, treatment scheduling, anti-poaching, and -- the motivation for this work -- digital health. For such high stakes settings, decisions must both improve outcomes and prevent disparities between groups (e.g., ensure health equity). We study equitable objectives for RMABs (ERMABs) for the first time. We consider two equity-aligned objectives from the fairness literature, minimax reward and max Nash welfare. We develop efficient algorithms for solving each -- a water filling algorithm for the former, and a greedy algorithm with theoretically motivated nuance to balance disparate group sizes for the latter. Finally, we demonstrate across three simulation domains, including a new digital health model, that our approaches can be multiple times more equitable than the current state of the art without drastic sacrifices to utility. Our findings underscore our work's urgency as RMABs permeate into systems that impact human and wildlife outcomes. Code is available at https://github.com/google-research/socialgood/tree/equitable-rmab
</details>
<details>
<summary>摘要</summary>
不休息的多手犬 (RMAB) 是一种流行的算法决策框架，用于Sequential Setting with limited resources。 RMAB 已经在公共卫生、治疗安排、抵抗贪婪和数字卫生等高规格场景中使用。为了保证高规格决策，决策必须同时提高结果和避免群体之间的差异（例如，确保健康公平）。我们研究了 equitable 目标函数 (ERMAB) ，并考虑了两种与公平性相关的目标函数：最小最大奖励和最大 Nash 利益。我们开发了高效的算法来解决每一个——一种水填算法来实现最小最大奖励，以及一种理论上支持的精心设计来平衡不同群体大小的 greedy 算法来实现最大 Nash 利益。最后，我们在三个模拟领域中，包括一个新的数字卫生模型，证明了我们的方法可以在不产生极大的Utility 损失的情况下多达多ples 更公平。我们的发现强调了我们的工作的急迫性，因为 RMAB 在影响人类和野生动物的系统中普遍存在。代码可以在 <https://github.com/google-research/socialgood/tree/equitable-rmab> 中获取。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods"><a href="#A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods" class="headerlink" title="A Dual-Perspective Approach to Evaluating Feature Attribution Methods"></a>A Dual-Perspective Approach to Evaluating Feature Attribution Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08949">http://arxiv.org/abs/2308.08949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yawei Li, Yang Zhang, Kenji Kawaguchi, Ashkan Khakzar, Bernd Bischl, Mina Rezaei</li>
<li>for: 本研究旨在提供一个稳固的评估特征归因方法的框架，以便更好地理解神经网络预测结果的基础特征。</li>
<li>methods: 本研究使用了两种新的视角来评估特征归因方法的 faithfulness 性能，即听soundness和completeness。soundness 评估归因特征是真实预测特征，而completeness 评估归因结果是否能够捕捉所有预测特征。</li>
<li>results: 研究人员通过对主流特征归因方法应用这两种新的视角，发现了一些缺陷和不足，并提出了一些改进建议。这些改进建议可以帮助提高特征归因方法的 faithfulness 和完整性。<details>
<summary>Abstract</summary>
Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.
</details>
<details>
<summary>摘要</summary>
neural network 预测结果的Feature归因方法尝试解释预测结果的相关特征。然而，建立一个一致的框架来评估归因方法仍然是一个挑战。我们可以通过以下几种视角来评估归因：一个重要的镜像是观察归因特征的改变对模型的行为的影响（即寓言）。虽然提供了有用的洞察，但现有的寓言评估存在缺陷，我们在这篇论文中揭示这些缺陷。在这个工作中，我们提出了两种新的视角，它们基于坚实的数学基础，并提供了可计算的量化度量。我们对主流归因方法应用这些度量，提供了一种新的分析和比较feature归因方法的镜像。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level"><a href="#Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level" class="headerlink" title="Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level"></a>Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08948">http://arxiv.org/abs/2308.08948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Pathak, Miro Miranda, Francisco Mena, Cristhian Sanchez, Patrick Helber, Benjamin Bischke, Peter Habelitz, Hiba Najjar, Jayanth Siddamsetty, Diego Arenas, Michaela Vollmer, Marcela Charfuelan, Marlon Nuske, Andreas Dengel</li>
<li>for: 这项研究的目的是开发一种简单又有效的早期融合方法，以优化耐灌植物生长和产量预测。</li>
<li>methods: 该方法使用高分辨率耐灌植物产量地图作为训练数据，并使用机器学习模型和气象、土壤和DEM数据进行融合。</li>
<li>results: 研究发现，使用不同输入模式可以得到不同的最佳结果，并且输入模式的选择取决于地区、作物和选择的模型。<details>
<summary>Abstract</summary>
We introduce a simple yet effective early fusion method for crop yield prediction that handles multiple input modalities with different temporal and spatial resolutions. We use high-resolution crop yield maps as ground truth data to train crop and machine learning model agnostic methods at the sub-field level. We use Sentinel-2 satellite imagery as the primary modality for input data with other complementary modalities, including weather, soil, and DEM data. The proposed method uses input modalities available with global coverage, making the framework globally scalable. We explicitly highlight the importance of input modalities for crop yield prediction and emphasize that the best-performing combination of input modalities depends on region, crop, and chosen model.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种简单 yet 有效的早期融合方法 для农作物产量预测，该方法可以处理多个输入模式，具有不同的时间和空间分辨率。我们使用高分辨率农作物产量地图作为真实数据来训练农作物和机器学习模型无关的方法。我们使用 Sentinal-2 卫星图像作为主要输入数据，其他补充模式包括天气、土壤和 DEM 数据。我们表明输入模式的重要性，并强调选择地区、作物和模型而定的最佳输入模式的重要性。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Graph-Neural-Networks-for-Tabular-Data"><a href="#Interpretable-Graph-Neural-Networks-for-Tabular-Data" class="headerlink" title="Interpretable Graph Neural Networks for Tabular Data"></a>Interpretable Graph Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08945">http://arxiv.org/abs/2308.08945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amr Alkhatib, Sofiane Ennadir, Henrik Boström, Michalis Vazirgiannis</li>
<li>for: 本研究旨在提出一种可解释的图 neural network（IGNNet），用于处理常见的表格数据，并且能够准确地表示输入特征之间的交互作用。</li>
<li>methods: IGNNet使用一种受限的学习算法，以生成可解释的模型，其中模型能够从原始输入特征直接计算出预测结果的具体计算过程。</li>
<li>results: 实验结果表明，IGNNet与现有针对表格数据的机器学习算法相比，在性能上具有相当的竞争力，而且可以准确地表示输入特征之间的交互作用。同时，IGNNet的解释结果与真实的Shapley值相关，无需额外计算开销。<details>
<summary>Abstract</summary>
Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true Shapley values of the features without incurring any additional computational overhead.
</details>
<details>
<summary>摘要</summary>
实际应用中 frequently 出现的数据格式是表格格式。图 neuron 网络（GNNs）在最近扩展以处理这种数据，以便捕捉特征之间的交互。然而，这些方法基本上生成黑盒模型，即深度神经网络，禁止用户跟踪模型预测的逻辑。我们提出了一种方法，称为 IGNNet（可解释图 neuron 网络 для表格数据），它限制学习算法生成可解释的模型，其中模型可以从原始输入特征直接计算预测。我们进行了大规模的实验研究，显示，IGNNet与目标 tabular 数据的状态机器学习算法相当，包括 XGBoost、Random Forests 和 TabNet。同时，结果表明，IGNNet 获得的解释与实际 Shapley 值相对，而不会增加任何额外的计算开销。
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatically-Addressing-Self-Admitted-Technical-Debt-How-Far-Are-We"><a href="#Towards-Automatically-Addressing-Self-Admitted-Technical-Debt-How-Far-Are-We" class="headerlink" title="Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?"></a>Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08943">http://arxiv.org/abs/2308.08943</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/antonio-mastropaolo/satd-removal">https://github.com/antonio-mastropaolo/satd-removal</a></li>
<li>paper_authors: Antonio Mastropaolo, Massimiliano Di Penta, Gabriele Bavota<br>for:* The paper aims to investigate the use of neural-based generative models for automatically paying back technical debt in software development.methods:* The paper employs seven different generative deep learning (DL) model configurations, including transformers pre-trained and fine-tuned with different combinations of training objectives.results:* The best model experimented with was able to automatically fix ~2% to 8% of test instances, depending on the number of attempts it was allowed to make.Here is the simplified Chinese translation of the three information points:for:* 本研究目的是 investigating 使用神经网络基于的生成模型来自动偿还软件开发中的技术债。methods:* 本研究使用了七种不同的生成深度学习（DL）模型配置，包括使用不同的训练目标来预训练和细化 transformers。results:* 最佳模型在试试次数不同情况下，能够自动修复 ~2% 到 8% 的测试实例。<details>
<summary>Abstract</summary>
Upon evolving their software, organizations and individual developers have to spend a substantial effort to pay back technical debt, i.e., the fact that software is released in a shape not as good as it should be, e.g., in terms of functionality, reliability, or maintainability. This paper empirically investigates the extent to which technical debt can be automatically paid back by neural-based generative models, and in particular models exploiting different strategies for pre-training and fine-tuning. We start by extracting a dateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595 open-source projects. SATD refers to technical debt instances documented (e.g., via code comments) by developers. We use this dataset to experiment with seven different generative deep learning (DL) model configurations. Specifically, we compare transformers pre-trained and fine-tuned with different combinations of training objectives, including the fixing of generic code changes, SATD removals, and SATD-comment prompt tuning. Also, we investigate the applicability in this context of a recently-available Large Language Model (LLM)-based chat bot. Results of our study indicate that the automated repayment of SATD is a challenging task, with the best model we experimented with able to automatically fix ~2% to 8% of test instances, depending on the number of attempts it is allowed to make. Given the limited size of the fine-tuning dataset (~5k instances), the model's pre-training plays a fundamental role in boosting performance. Also, the ability to remove SATD steadily drops if the comment documenting the SATD is not provided as input to the model. Finally, we found general-purpose LLMs to not be a competitive approach for addressing SATD.
</details>
<details>
<summary>摘要</summary>
企业和个人开发者在软件发展过程中需要投入很大的努力来偿还技术债务，即软件发布的形态不是理想的，例如功能、可靠性和维护性等方面的问题。这篇论文employs neural网络模型来自动偿还技术债务，并研究了不同预训练和细化目标的影响。我们从595个开源项目中提取了5,039个自我披露技术债务（SATD）的实例，并使用这些实例进行了7种不同的深度学习（DL）模型配置的实验。特别是，我们比较了使用预训练后细化不同组合的训练目标，包括通用代码修改、SATD修复和SATD注释提示训练。此外，我们还 investigate了在这种上下文中Large Language Model（LLM）基于的聊天机器人的可用性。结果表明自动偿还SATD是一项具有挑战性的任务，最佳我们实验的模型可以自动修复test实例中的~2%至8%，具体取决于允许尝试的次数。由于 fine-tuning数据的数量（~5k个实例）较小，预训练在性能提升中扮演了基本的角色。同时，如果不提供SATD注释作为输入，模型的SATD修复能力逐渐下降。最后，我们发现通用LLM不是适合解决SATD的方法。
</details></li>
</ul>
<hr>
<h2 id="A-White-Box-False-Positive-Adversarial-Attack-Method-on-Contrastive-Loss-Based-Offline-Handwritten-Signature-Verification-Models"><a href="#A-White-Box-False-Positive-Adversarial-Attack-Method-on-Contrastive-Loss-Based-Offline-Handwritten-Signature-Verification-Models" class="headerlink" title="A White-Box False Positive Adversarial Attack Method on Contrastive Loss-Based Offline Handwritten Signature Verification Models"></a>A White-Box False Positive Adversarial Attack Method on Contrastive Loss-Based Offline Handwritten Signature Verification Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08925">http://arxiv.org/abs/2308.08925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongliang Guo, Yifei Qian, Ognjen Arandjelović, Lei Fang</li>
<li>for: 这 paper 是为了解决白盒式 false positive 对做 contrastive loss 基于的 Offline 手写签名验证模型。</li>
<li>methods: 我们提出了一种新的攻击方法，它将攻击看作是一种style transfer между两种相似而又独特的写作风格。为了导引生成的幌子图像，我们引入了两个新的损失函数，它们可以在 embedding  вектор 之间增加攻击成功率，同时保证最小化生成图像与原图像之间的差异。</li>
<li>results: 我们的方法在 white-box 攻击中对 contrastive loss 基于的 Offline 手写签名验证模型表现出了 state-of-the-art 性能，这得到了我们的实验证明。这 paper 的关键贡献包括一种新的 false positive 攻击方法，两个新的损失函数，有效的 style transfer 在手写风格之间，以及在 white-box  false positive 攻击中比其他 white-box 攻击方法表现出更高的性能。<details>
<summary>Abstract</summary>
In this paper, we tackle the challenge of white-box false positive adversarial attacks on contrastive loss-based offline handwritten signature verification models. We propose a novel attack method that treats the attack as a style transfer between closely related but distinct writing styles. To guide the generation of deceptive images, we introduce two new loss functions that enhance the attack success rate by perturbing the Euclidean distance between the embedding vectors of the original and synthesized samples, while ensuring minimal perturbations by reducing the difference between the generated image and the original image. Our method demonstrates state-of-the-art performance in white-box attacks on contrastive loss-based offline handwritten signature verification models, as evidenced by our experiments. The key contributions of this paper include a novel false positive attack method, two new loss functions, effective style transfer in handwriting styles, and superior performance in white-box false positive attacks compared to other white-box attack methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们面临了对对照损失基于线上手写签名验证模型的白盒式false positive骚扰攻击的挑战。我们提出了一种新的攻击方法，它将攻击看作是在 closely related but distinct writing styles之间进行风格转换。为了导引生成的误leading images的生成，我们引入了两个新的损失函数，它们可以在 embedding vectors of the original and synthesized samples之间增加攻击成功率，同时保持最小的抖动，使得生成的图像与原始图像之间的差异尽量小。我们的方法在 white-box false positive attacks中表现出了state-of-the-art的性能，经过我们的实验证明。本文的主要贡献包括一种新的false positive攻击方法、两个新的损失函数、effective的风格转换在手写风格中、以及在 white-box false positive attacks中的superior performance compared to other white-box attack methods。
</details></li>
</ul>
<hr>
<h2 id="IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making"><a href="#IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making" class="headerlink" title="IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making"></a>IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08918">http://arxiv.org/abs/2308.08918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Niu, Siyuan Li, Jiahao Zheng, Zhouchi Lin, Jian Li, Jian Guo, Bo An<br>for: 这种研究的目的是为了开发一种基于强化学习的多价格级市场制作者（Imitative Market Maker，IMM），以提高市场流动性和财务表现。methods: 这种方法利用了知识从不优化的信号基础 экспер特性和直接策略互动来快速发展多价格级市场制作者。它首先引入了有效的状态和动作表示，能够快速编码多价格级订单信息。然后，IMM利用了一个表示学习单元，能够捕捉短期和长期市场趋势，以减少不良选择风险。最后，IMM通过结合RL和仿效学习技术来训练代理人，从而实现有效的学习。results: 实验结果表明，IMM在四个实际市场数据集上比现有的RL基于市场制作者策略具有较高的财务表现。减少不良选择风险的策略组件的实验结果也证明了模型的有效性。<details>
<summary>Abstract</summary>
Market making (MM) has attracted significant attention in financial trading owing to its essential function in ensuring market liquidity. With strong capabilities in sequential decision-making, Reinforcement Learning (RL) technology has achieved remarkable success in quantitative trading. Nonetheless, most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. Strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level strategies involves a comprehensive trading action space, the challenge of effectively training profitable RL agents for MM persists. Inspired by the efficient workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework start with introducing effective state and action representations adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details>
<details>
<summary>摘要</summary>
市场制作（MM）在金融交易中吸引了广泛的注意力，因为它提供了市场流动性的关键 fonction。强大的顺序决策能力使得强化学习（RL）技术在量化交易中取得了显著的成功。然而，大多数现有的RL基于MM方法都是优化单价级别策略，这些策略在频繁的订单取消和优先级损失中失败。使用多个价格级别的策略更好地适应实际交易场景。然而，由于多个价格级别的策略的复杂性，RL代理人的训练仍然存在挑战。以人类市场制作者的高效工作流程为灵感，我们提出了imitative Market Maker（IMM），一种基于RL和仿制学习技术的新的市场制作框架。IMM从引入有效的状态和动作表示开始，并将市场趋势短期和长期都 captured。然后，IMM通过RL和仿制学习技术结合来训练代理人，从而实现高效的学习。我们在四个实际市场数据集上进行了广泛的实验，发现IMM在许多金融指标上表现出色，超过了现有的RL基于市场制作策略。减少风险的研究结果证明了模型组件的效果。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection"><a href="#Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection" class="headerlink" title="Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection"></a>Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08915">http://arxiv.org/abs/2308.08915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawnvince/mts_cad">https://github.com/dawnvince/mts_cad</a></li>
<li>paper_authors: Haotian Si, Changhua Pei, Zhihan Li, Yadong Zhao, Jingjing Li, Haiming Zhang, Zulong Diao, Jianhui Li, Gaogang Xie, Dan Pei</li>
<li>for: 本研究旨在提出一种基于多任务学习的多变量时间序列异常检测算法（CAD），以解决现有异常检测方法中缺乏准确检测异常时序序列数据的问题。</li>
<li>methods: CAD使用了一种具有冲突意识的结构，以mitigate potential conflicts among metrics的 regression objectives，并提出了一种简单 yet effective的任务oriented metric selection和personalized和shared gating机制。</li>
<li>results: 对于多个公共数据集，CAD实现了一个平均的F1分数为0.943，明显超过了现有方法的性能。<details>
<summary>Abstract</summary>
Massive key performance indicators (KPIs) are monitored as multivariate time series data (MTS) to ensure the reliability of the software applications and service system. Accurately detecting the abnormality of MTS is very critical for subsequent fault elimination. The scarcity of anomalies and manual labeling has led to the development of various self-supervised MTS anomaly detection (AD) methods, which optimize an overall objective/loss encompassing all metrics' regression objectives/losses. However, our empirical study uncovers the prevalence of conflicts among metrics' regression objectives, causing MTS models to grapple with different losses. This critical aspect significantly impacts detection performance but has been overlooked in existing approaches. To address this problem, by mimicking the design of multi-gate mixture-of-experts (MMoE), we introduce CAD, a Conflict-aware multivariate KPI Anomaly Detection algorithm. CAD offers an exclusive structure for each metric to mitigate potential conflicts while fostering inter-metric promotions. Upon thorough investigation, we find that the poor performance of vanilla MMoE mainly comes from the input-output misalignment settings of MTS formulation and convergence issues arising from expansive tasks. To address these challenges, we propose a straightforward yet effective task-oriented metric selection and p&s (personalized and shared) gating mechanism, which establishes CAD as the first practicable multi-task learning (MTL) based MTS AD model. Evaluations on multiple public datasets reveal that CAD obtains an average F1-score of 0.943 across three public datasets, notably outperforming state-of-the-art methods. Our code is accessible at https://github.com/dawnvince/MTS_CAD.
</details>
<details>
<summary>摘要</summary>
巨大的键性表现指标 (KPIs) 被监测为多变量时间序列数据 (MTS)，以确保软件应用程序和服务系统的可靠性。检测 MTS 中异常性的精度非常重要，以便后续的缺陷排除。由于缺乏异常例和手动标注，已经开发了许多自动学习 MTS 异常检测 (AD) 方法，这些方法通过优化总体的函数/损失来优化所有指标的回归函数/损失。然而，我们的实证研究发现，存在指标回归函数之间的冲突，导致 MTS 模型面临着不同的损失。这种问题在现有方法中受到了忽略。为解决这个问题，我们引入了 CAD（异常检测算法），一种具有冲突意识的多变量 KPI 异常检测算法。CAD 采用了多个指标的专属结构，以mitigate 指标之间的冲突，并且通过促进指标之间的促进来促进指标之间的互动。经过了系统的调查，我们发现，原始 MMoE 的性能不佳主要来自 MTS 表示形式的输入-输出不对称和任务的扩展问题。为解决这些挑战，我们提出了一种简单 yet 有效的任务关注的指标选择和 p&s 阻止机制，这使得 CAD 成为了首个实用的多任务学习 (MTL) 基于 MTS AD 模型。对多个公共数据集进行评估，我们发现，CAD 在三个公共数据集上的平均 F1 分数为 0.943，较state-of-the-art 方法高。我们的代码可以在 <https://github.com/dawnvince/MTS_CAD> 上获取。
</details></li>
</ul>
<hr>
<h2 id="MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling"><a href="#MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling" class="headerlink" title="MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling"></a>MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09725">http://arxiv.org/abs/2308.09725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai</li>
<li>for: 本研究旨在推动个性化医疗的发展，通过在肿瘤分型中利用多Omics数据来提高肿瘤分型结果。</li>
<li>methods: 本研究提出了MoCLIM Representation Learning框架，可以独立提取不同Omics模式下的有用特征，并通过对不同Omics模式的对照学习来获得更好的分型结果。</li>
<li>results: 在六个肿瘤数据集上，MoCLIM Representation Learning框架可以显著提高肿瘤分型结果，并且可以在更少的高维度肿瘤实例中实现更好的分型结果。此外，该框架还可以在医疗分析中提供高可读性。<details>
<summary>Abstract</summary>
Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances. Moreover, our framework incorporates various medical evaluations as the final component, providing high interpretability in medical analysis.
</details>
<details>
<summary>摘要</summary>
准精准医学目标是确定肿瘤分型中的生物化学机制异常。 omics 技术在肿瘤分类方面带来了革命性的变革，因为不同的 omics 数据记录了肿瘤多步骤过程中的生物化学产物。本文探讨了将多Omics 数据完全利用来改进肿瘤分类结果，因此开发了 MoCLIM 表示学框架。 MoCLIM 独立提取不同 omics Modalities 中的有用特征。通过对异 Omics Modalities 的异构学习，我们可以将肿瘤分类到更低的准则空间中。这种异构可以被解释为生物网络中跨Modalities 的推断。实验结果表明，我们的方法可以在更少的高维肿瘤实例中提高数据适应度和分类性能。此外，我们的框架还包括各种医学评估作为最后一个组件，提供了高度可读性在医学分析中。
</details></li>
</ul>
<hr>
<h2 id="Building-Emotional-Support-Chatbots-in-the-Era-of-LLMs"><a href="#Building-Emotional-Support-Chatbots-in-the-Era-of-LLMs" class="headerlink" title="Building Emotional Support Chatbots in the Era of LLMs"></a>Building Emotional Support Chatbots in the Era of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11584">http://arxiv.org/abs/2308.11584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhonghua Zheng, Lizi Liao, Yang Deng, Liqiang Nie</li>
<li>for: 这篇论文目标是提出一种基于大语言模型（LLM）的情感支持对话集合创建方法，以推动情感支持机器人的实际应用。</li>
<li>methods: 该方法首先采用了仔细设计的对话生成模板，然后通过使用ChatGPT进行反射生成，创建了一个广泛的情感支持对话集合（ExTES）。接着，对LLaMA模型进行了高级调参技术，以优化情感支持交互的性能。</li>
<li>results: 结果表明，该模型在情感支持交互中表现出色，emarking a significant step forward in the field of emotional support bots, and paving the way for subsequent research and applications.<details>
<summary>Abstract</summary>
The integration of emotional support into various conversational scenarios presents profound societal benefits, such as social interactions, mental health counseling, and customer service. However, there are unsolved challenges that hinder real-world applications in this field, including limited data availability and the absence of well-accepted model training paradigms. This work endeavors to navigate these challenges by harnessing the capabilities of Large Language Models (LLMs). We introduce an innovative methodology that synthesizes human insights with the computational prowess of LLMs to curate an extensive emotional support dialogue dataset. Our approach is initiated with a meticulously designed set of dialogues spanning diverse scenarios as generative seeds. By utilizing the in-context learning potential of ChatGPT, we recursively generate an ExTensible Emotional Support dialogue dataset, named ExTES. Following this, we deploy advanced tuning techniques on the LLaMA model, examining the impact of diverse training strategies, ultimately yielding an LLM meticulously optimized for emotional support interactions. An exhaustive assessment of the resultant model showcases its proficiency in offering emotional support, marking a pivotal step in the realm of emotional support bots and paving the way for subsequent research and implementations.
</details>
<details>
<summary>摘要</summary>
integración de apoyo emocional en diversas escenarios conversacionales ofrece beneficios sociales profundos, como interacciones sociales, consejería de salud mental y servicio al cliente. Sin embargo, existen desafíos sin resolver que impiden aplicaciones en el mundo real en este campo, como la limitaciones de datos y la ausencia de paradigmas de entrenamiento bien aceptados. Este trabajo busca superar estos desafíos mediante la combinación de la capacidad de modelos de lenguaje grande (LLMs) con la perspicacia humana. Presentamos un enfoque innovador que sintetiza la sabiduría humana con el poder computacional de LLMs para crear un gran conjunto de diálogos de apoyo emocional, llamado ExTES. Luego, aplicamos técnicas de ajuste avanzadas en el modelo LLaMA, examinando el impacto de diversas estrategias de entrenamiento, lo que permite optimizar meticulosamente el modelo para interacciones de apoyo emocional. Una evaluación exhaustiva del modelo resultante demuestra su habilidad para brindar apoyo emocional, lo que representa un paso importante en el campo de los bots de apoyo emocional y abre la puerta a investigaciones y aplicaciones subsiguientes.
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Practical-Defense-against-Adversarial-Attacks-on-Deep-Learning-based-Malware-Detectors-via-Randomized-Smoothing"><a href="#Towards-a-Practical-Defense-against-Adversarial-Attacks-on-Deep-Learning-based-Malware-Detectors-via-Randomized-Smoothing" class="headerlink" title="Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing"></a>Towards a Practical Defense against Adversarial Attacks on Deep Learning-based Malware Detectors via Randomized Smoothing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08906">http://arxiv.org/abs/2308.08906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Gibert, Giulio Zizzo, Quan Le</li>
<li>for: 防御深度学习恶意软件检测器受到针对性攻击</li>
<li>methods: 提议使用随机缩放方法来防御恶意软件检测器</li>
<li>results: 对BODMAS数据集进行实验表明，相比非粗糙分类器，我们的随机缩放模型具有更高的鲁棒性和泛化能力对抗针对性攻击<details>
<summary>Abstract</summary>
Malware detectors based on deep learning (DL) have been shown to be susceptible to malware examples that have been deliberately manipulated in order to evade detection, a.k.a. adversarial malware examples. More specifically, it has been show that deep learning detectors are vulnerable to small changes on the input file. Given this vulnerability of deep learning detectors, we propose a practical defense against adversarial malware examples inspired by randomized smoothing. In our work, instead of employing Gaussian or Laplace noise when randomizing inputs, we propose a randomized ablation-based smoothing scheme that ablates a percentage of the bytes within an executable. During training, our randomized ablation-based smoothing scheme trains a base classifier based on ablated versions of the executable files. At test time, the final classification for a given input executable is taken as the class most commonly predicted by the classifier on a set of ablated versions of the original executable. To demonstrate the suitability of our approach we have empirically evaluated the proposed ablation-based model against various state-of-the-art evasion attacks on the BODMAS dataset. Results show greater robustness and generalization capabilities to adversarial malware examples in comparison to a non-smoothed classifier.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）基于的恶意软件检测器有 been shown to be susceptible to deliberately manipulated malware examples that evade detection, a.k.a. adversarial malware examples. Specifically, it has been shown that deep learning detectors are vulnerable to small changes in the input file. Given this vulnerability of deep learning detectors, we propose a practical defense against adversarial malware examples inspired by randomized smoothing. In our work, instead of employing Gaussian or Laplace noise when randomizing inputs, we propose a randomized ablation-based smoothing scheme that ablates a percentage of the bytes within an executable. During training, our randomized ablation-based smoothing scheme trains a base classifier based on ablated versions of the executable files. At test time, the final classification for a given input executable is taken as the class most commonly predicted by the classifier on a set of ablated versions of the original executable. To demonstrate the suitability of our approach, we have empirically evaluated the proposed ablation-based model against various state-of-the-art evasion attacks on the BODMAS dataset. Results show greater robustness and generalization capabilities to adversarial malware examples in comparison to a non-smoothed classifier.
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain"><a href="#Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain" class="headerlink" title="Development of a Knowledge Graph Embeddings Model for Pain"></a>Development of a Knowledge Graph Embeddings Model for Pain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08904">http://arxiv.org/abs/2308.08904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaya Chaturvedi, Tao Wang, Sumithra Velupillai, Robert Stewart, Angus Roberts</li>
<li>For: The paper aims to construct knowledge graph embedding models of pain concepts extracted from mental health electronic health records, combined with external knowledge from SNOMED CT, and evaluate their performance on a subject-object link prediction task.* Methods: The paper uses knowledge graph embedding models to represent pain concepts in a low-dimensional vector space, and combines them with external knowledge from SNOMED CT to enrich the graph. The models are evaluated on a subject-object link prediction task to assess their performance.* Results: The paper compares the performance of the knowledge graph embedding models with other baseline models, and evaluates their ability to predict subject-object links in the context of pain. The results show that the knowledge graph embedding models outperform the baseline models, demonstrating their effectiveness in capturing the complex relationships between pain concepts.<details>
<summary>Abstract</summary>
Pain is a complex concept that can interconnect with other concepts such as a disorder that might cause pain, a medication that might relieve pain, and so on. To fully understand the context of pain experienced by either an individual or across a population, we may need to examine all concepts related to pain and the relationships between them. This is especially useful when modeling pain that has been recorded in electronic health records. Knowledge graphs represent concepts and their relations by an interlinked network, enabling semantic and context-based reasoning in a computationally tractable form. These graphs can, however, be too large for efficient computation. Knowledge graph embeddings help to resolve this by representing the graphs in a low-dimensional vector space. These embeddings can then be used in various downstream tasks such as classification and link prediction. The various relations associated with pain which are required to construct such a knowledge graph can be obtained from external medical knowledge bases such as SNOMED CT, a hierarchical systematic nomenclature of medical terms. A knowledge graph built in this way could be further enriched with real-world examples of pain and its relations extracted from electronic health records. This paper describes the construction of such knowledge graph embedding models of pain concepts, extracted from the unstructured text of mental health electronic health records, combined with external knowledge created from relations described in SNOMED CT, and their evaluation on a subject-object link prediction task. The performance of the models was compared with other baseline models.
</details>
<details>
<summary>摘要</summary>
疼痛是一种复杂的概念，可以与其他概念相连接，例如一种疾病可能会引起疼痛，一种药物可能会缓解疼痛等。为了全面理解个人或人口所经历的疼痛，我们需要检查所有与疼痛相关的概念和它们之间的关系。这在电子医疗记录中模拟疼痛 particullary useful。知识图表表示概念和它们之间的关系为相互连接的网络，使得semantic和上下文基于的理解变得可计算化。这些图表可能太大，导致不可fficiente computation。知识图表嵌入帮助解决这个问题，将知识图表转化为低维度向量空间中的表示。这些嵌入可以在多种下游任务中使用，如分类和链接预测。为了构建这些知识图表嵌入模型，我们可以从电子精神医疗记录中提取疼痛相关的文本信息，并与外部医学知识库SNOMED CT中的概念关系结合。SNOMED CT是一种层次系统atic的医学术语系统，可以提供疼痛相关的外部知识。通过将这些知识图表嵌入模型与电子精神医疗记录中的疼痛实例进行结合，我们可以进一步丰富知识图表，并在subject-object链接预测任务上评估这些模型的性能。在比较baseline模型的基础上，我们发现这些模型在这个任务上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games"><a href="#Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games" class="headerlink" title="Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games"></a>Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08858">http://arxiv.org/abs/2308.08858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songtao Feng, Ming Yin, Yu-Xiang Wang, Jing Yang, Yingbin Liang</li>
<li>for: 本研究探讨了两个玩家零 SUM Markov 游戏中的理论研究，尤其是在考虑 finite-horizon episodic Markov decision processes (MDPs) 中。</li>
<li>methods: 本研究提出了一种基于 stage-based Q-learning 的模型自由算法，并证明了它可以达到与最佳模型基于算法相同的样本复杂度，即 $O(H^3SAB&#x2F;\epsilon^2) $。</li>
<li>results: 本研究显示了模型自由算法可以在 Markov 游戏中实现 $\epsilon$-优 Nash 平衡 (NE)，并且在样本复杂度上与最佳模型基于算法相同。此外，本研究还提出了一种基于 reference-advantage decomposition 的变量减少技术，以提高样本效率。<details>
<summary>Abstract</summary>
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by leveraging the popular variance reduction technique based on the reference-advantage decomposition previously used only for single-agent RL. However, such a technique relies on a critical monotonicity property of the value function, which does not hold in Markov games due to the update of the policy via the coarse correlated equilibrium (CCE) oracle. Thus, to extend such a technique to Markov games, our algorithm features a key novel design of updating the reference value functions as the pair of optimistic and pessimistic value functions whose value difference is the smallest in the history in order to achieve the desired improvement in the sample efficiency.
</details>
<details>
<summary>摘要</summary>
“两Player零 SUM Markov 游戏问题在多智能RL理论研究中已经吸引了越来越多的关注。特别是在finite-horizon episodic Markov decision processes（MDPs）中，已经证明了模型基于算法可以在$O(H^3SAB/\epsilon^2)$的样本复杂度下找到$\epsilon$-优 Nash Equilibrium（NE），这是很依赖于Horizon $H$和状态数 $S$（其中 $A$ 和 $B$ 分别表示两个玩家的动作数）。然而，现有的模型free算法无法达到这种优化。在这项工作中，我们提出了一种模型free stage-based Q-学习算法，并证明它可以 дости到与最佳模型基于算法相同的样本复杂度，因此首次确立了模型free算法可以在$H$ 的依赖性上达到同样的优化。主要改进来自于variance reduction技术，基于reference-advantage decomposition，这种技术在单个RL中已经使用了很长时间，但是在Markov 游戏中它无法使用，因为policy更新通过coarse correlated equilibrium（CCE）论点。因此，为了将这种技术扩展到Markov 游戏，我们的算法具有一个关键的新特点，即在历史中更新参 referential value functions的方法，使其值差为历史中最小，以实现所需的样本效率提升。”
</details></li>
</ul>
<hr>
<h2 id="D-IF-Uncertainty-aware-Human-Digitization-via-Implicit-Distribution-Field"><a href="#D-IF-Uncertainty-aware-Human-Digitization-via-Implicit-Distribution-Field" class="headerlink" title="D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field"></a>D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08857">http://arxiv.org/abs/2308.08857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/psyai-net/d-if_release">https://github.com/psyai-net/d-if_release</a></li>
<li>paper_authors: Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, Zhaoxin Fan</li>
<li>for: 这 paper 的目的是提出一种基于深度隐式函数的图像基于3D人体重建方法，以实现高级别的真实人体模拟。</li>
<li>methods: 这 paper 使用的方法是基于深度隐式函数的图像基于3D人体重建方法，并将 implicit value 替换为 adaptive uncertainty distribution，以 differentiate Points based on their distance to the surface。</li>
<li>results:  compared to nearly all baselines, the models trained using the uncertainty distribution loss proposed in this paper can capture more intricate wrinkles and realistic limbs, and demonstrate significant improvements.<details>
<summary>Abstract</summary>
Realistic virtual humans play a crucial role in numerous industries, such as metaverse, intelligent healthcare, and self-driving simulation. But creating them on a large scale with high levels of realism remains a challenge. The utilization of deep implicit function sparks a new era of image-based 3D clothed human reconstruction, enabling pixel-aligned shape recovery with fine details. Subsequently, the vast majority of works locate the surface by regressing the deterministic implicit value for each point. However, should all points be treated equally regardless of their proximity to the surface? In this paper, we propose replacing the implicit value with an adaptive uncertainty distribution, to differentiate between points based on their distance to the surface. This simple ``value to distribution'' transition yields significant improvements on nearly all the baselines. Furthermore, qualitative results demonstrate that the models trained using our uncertainty distribution loss, can capture more intricate wrinkles, and realistic limbs. Code and models are available for research purposes at https://github.com/psyai-net/D-IF_release.
</details>
<details>
<summary>摘要</summary>
现实型人体在虚拟世界、智能医疗和自动驾驶等领域扮演着关键角色，但在大规模创造高真实度人体模型上存在挑战。深度隐函数推发了一新的图像基于3D人体重建时代，使得像素对应的形态恢复得到了细节。然而，Should all points be treated equally regardless of their proximity to the surface?在本文中，我们提出将implizit值换为 adaptive uncertainty distribution，以 differentiate between points based on their distance to the surface。这种简单的“值到分布”转换带来了大量基础上的改进。此外，qualitative results表明，使用我们的uncertainty distribution损失来训练模型，可以捕捉更复杂的皱纹和真实的肢体。可以在https://github.com/psyai-net/D-IF_release上获取代码和模型用于研究purpose。
</details></li>
</ul>
<hr>
<h2 id="BERT4CTR-An-Efficient-Framework-to-Combine-Pre-trained-Language-Model-with-Non-textual-Features-for-CTR-Prediction"><a href="#BERT4CTR-An-Efficient-Framework-to-Combine-Pre-trained-Language-Model-with-Non-textual-Features-for-CTR-Prediction" class="headerlink" title="BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction"></a>BERT4CTR: An Efficient Framework to Combine Pre-trained Language Model with Non-textual Features for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11527">http://arxiv.org/abs/2308.11527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dong Wang, Kavé Salamatian, Yunqing Xia, Weiwei Deng, Qi Zhiang</li>
<li>for: 这个研究的目的是提出一个新的框架BERT4CTR，以解决在Click-Through-Rate（CTR）预测中融合预训语言模型和多媒体输入的挑战。</li>
<li>methods: 本研究使用Uni-Attention机制，允许不同类型的输入（文本和非文本）之间的互动，并维持训练和推导时间成本低。</li>
<li>results: 实验结果显示，BERT4CTR可以与现有的州OF-the-art框架相比，在处理多媒体输入和CTR预测中表现出色，并且具有较低的训练和推导时间成本。<details>
<summary>Abstract</summary>
Although deep pre-trained language models have shown promising benefit in a large set of industrial scenarios, including Click-Through-Rate (CTR) prediction, how to integrate pre-trained language models that handle only textual signals into a prediction pipeline with non-textual features is challenging.   Up to now two directions have been explored to integrate multi-modal inputs in fine-tuning of pre-trained language models. One consists of fusing the outcome of language models and non-textual features through an aggregation layer, resulting into ensemble framework, where the cross-information between textual and non-textual inputs are only learned in the aggregation layer. The second one consists of splitting non-textual features into fine-grained fragments and transforming the fragments to new tokens combined with textual ones, so that they can be fed directly to transformer layers in language models. However, this approach increases the complexity of the learning and inference because of the numerous additional tokens.   To address these limitations, we propose in this work a novel framework BERT4CTR, with the Uni-Attention mechanism that can benefit from the interactions between non-textual and textual features while maintaining low time-costs in training and inference through a dimensionality reduction. Comprehensive experiments on both public and commercial data demonstrate that BERT4CTR can outperform significantly the state-of-the-art frameworks to handle multi-modal inputs and be applicable to CTR prediction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Fuse the output of language models and non-textual features through an aggregation layer, resulting in an ensemble framework, where the interactions between textual and non-textual inputs are only learned in the aggregation layer.2. Split non-textual features into fine-grained fragments and transform them into new tokens combined with textual ones, so that they can be fed directly into transformer layers in language models. However, this approach increases the complexity of training and inference due to the numerous additional tokens.To address these limitations, we propose a novel framework called BERT4CTR, which utilizes the Uni-Attention mechanism to benefit from the interactions between non-textual and textual features while maintaining low time costs in training and inference through dimensionality reduction. Extensive experiments on both public and commercial data demonstrate that BERT4CTR can significantly outperform state-of-the-art frameworks in handling multi-modal inputs and be applicable to CTR prediction.</details></li>
</ol>
<hr>
<h2 id="CMB-A-Comprehensive-Medical-Benchmark-in-Chinese"><a href="#CMB-A-Comprehensive-Medical-Benchmark-in-Chinese" class="headerlink" title="CMB: A Comprehensive Medical Benchmark in Chinese"></a>CMB: A Comprehensive Medical Benchmark in Chinese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08833">http://arxiv.org/abs/2308.08833</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FreedomIntelligence/CMB">https://github.com/FreedomIntelligence/CMB</a></li>
<li>paper_authors: Xidong Wang, Guiming Hardy Chen, Dingjie Song, Zhiyi Zhang, Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, Haizhou Li</li>
<li>for: 这篇论文的目的是提出一个基于中药文化的本地化医疗标准，以便评估和发展大型语言模型（LLMs）在医疗领域的表现。</li>
<li>methods: 这篇论文使用了一个名为CMB的本地化医疗标准，评估了多达几个大型语言模型，包括ChatGPT、GPT-4、中药模型和医疗领域专门的模型。</li>
<li>results: 根据CMB的评估结果，这些大型语言模型在医疗领域的表现有所不同，并且发现了一些地区特有的语言特征。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) provide a possibility to make a great breakthrough in medicine. The establishment of a standardized medical benchmark becomes a fundamental cornerstone to measure progression. However, medical environments in different regions have their local characteristics, e.g., the ubiquity and significance of traditional Chinese medicine within China. Therefore, merely translating English-based medical evaluation may result in \textit{contextual incongruities} to a local region. To solve the issue, we propose a localized medical benchmark called CMB, a Comprehensive Medical Benchmark in Chinese, designed and rooted entirely within the native Chinese linguistic and cultural framework. While traditional Chinese medicine is integral to this evaluation, it does not constitute its entirety. Using this benchmark, we have evaluated several prominent large-scale LLMs, including ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical domain. It is worth noting that our benchmark is not devised as a leaderboard competition but as an instrument for self-assessment of model advancements. We hope this benchmark could facilitate the widespread adoption and enhancement of medical LLMs within China. Check details in \url{https://cmedbenchmark.llmzoo.com/}.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLMs）为医学领域提供了一个可能性，以确定重要的突破点。建立一个标准化的医学标准became a fundamental cornerstone to measure progress. However, different regions have their own local characteristics, such as the prevalence and significance of traditional Chinese medicine within China. Therefore, simply translating English-based medical evaluation may result in 上下文不符 incongruities in a local region. To solve this issue, we propose a localized medical benchmark called CMB, a Comprehensive Medical Benchmark in Chinese, designed and rooted entirely within the native Chinese linguistic and cultural framework. While traditional Chinese medicine is an integral part of this evaluation, it does not constitute its entirety. Using this benchmark, we have evaluated several prominent large-scale LLMs, including ChatGPT, GPT-4, dedicated Chinese LLMs, and LLMs specialized in the medical domain. It is worth noting that our benchmark is not designed as a leaderboard competition but as an instrument for self-assessment of model advancements. We hope this benchmark could facilitate the widespread adoption and enhancement of medical LLMs within China. For more details, please visit \url{https://cmedbenchmark.llmzoo.com/}.
</details></li>
</ul>
<hr>
<h2 id="Lifted-Algorithms-for-Symmetric-Weighted-First-Order-Model-Sampling"><a href="#Lifted-Algorithms-for-Symmetric-Weighted-First-Order-Model-Sampling" class="headerlink" title="Lifted Algorithms for Symmetric Weighted First-Order Model Sampling"></a>Lifted Algorithms for Symmetric Weighted First-Order Model Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08828">http://arxiv.org/abs/2308.08828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhong Wang, Juhua Pu, Yuyi Wang, Ondřej Kuželka</li>
<li>for: 本文 targets the problem of weighted model sampling (WMS) in first-order logic, and explores whether WMS can be solved efficiently like domain-liftable model counting problems.</li>
<li>methods: 本文提出了一种快速的抽样算法，用于解决Weighted Model Sampling (WMS)问题，该算法基于首ORDER 逻辑中的 counting quantifiers。</li>
<li>results: 本文证明了 WMS 问题在 two-variables fragment 中是可采样的，并提供了一种快速的抽样算法，其运行时间与域大小成正比。此外，本文还证明了这一结论在 cardinality constraints 的存在下仍然成立。实验结果表明，该算法比现有的 WMS 抽样器快得多，证实了理论结论。<details>
<summary>Abstract</summary>
Weighted model counting (WMC) is the task of computing the weighted sum of all satisfying assignments (i.e., models) of a propositional formula. Similarly, weighted model sampling (WMS) aims to randomly generate models with probability proportional to their respective weights. Both WMC and WMS are hard to solve exactly, falling under the $\#\mathsf{P}$-hard complexity class. However, it is known that the counting problem may sometimes be tractable, if the propositional formula can be compactly represented and expressed in first-order logic. In such cases, model counting problems can be solved in time polynomial in the domain size, and are known as domain-liftable. The following question then arises: Is it also the case for weighted model sampling? This paper addresses this question and answers it affirmatively. Specifically, we prove the domain-liftability under sampling for the two-variables fragment of first-order logic with counting quantifiers in this paper, by devising an efficient sampling algorithm for this fragment that runs in time polynomial in the domain size. We then further show that this result continues to hold even in the presence of cardinality constraints. To empirically verify our approach, we conduct experiments over various first-order formulas designed for the uniform generation of combinatorial structures and sampling in statistical-relational models. The results demonstrate that our algorithm outperforms a start-of-the-art WMS sampler by a substantial margin, confirming the theoretical results.
</details>
<details>
<summary>摘要</summary>
“加重模型计数（WMC）是计算一个 propositional 式中所有满足 assignment（即模型）的加重和的任务。相似地，加重模型采样（WMS）目标是随机生成权重 proportional 的模型。两者都属于 $\#\mathsf{P}$-hard 复杂性类别。然而，已知在某些情况下，计数问题可能是可解的，如果 propositional 式可以简洁地表示并表示在第一频频论 logic 中。在这种情况下，模型计数问题可以在域大小的时间复杂度内解决，并被称为域可提升的。这个问题的下一个问题是：加重模型采样是否也是可提升的？这篇论文回答了这个问题，并答曰：是的。具体来说，我们证明在两个变量的 Fragment 中的 first-order 逻辑中，加重模型采样是可提升的，并提供了一种高效的采样算法，其时间复杂度与域大小成正比。我们再次证明了在具有 cardinality 约束时，这个结果仍然保持。为确认我们的方法，我们对多种适用于统计关系模型和采样的 first-order 方程进行了实验，结果表明我们的算法在相对较大的域大小下表现更好，证明了我们的 теоретичеResult。”
</details></li>
</ul>
<hr>
<h2 id="Do-you-really-follow-me-Adversarial-Instructions-for-Evaluating-the-Robustness-of-Large-Language-Models"><a href="#Do-you-really-follow-me-Adversarial-Instructions-for-Evaluating-the-Robustness-of-Large-Language-Models" class="headerlink" title="Do you really follow me? Adversarial Instructions for Evaluating the Robustness of Large Language Models"></a>Do you really follow me? Adversarial Instructions for Evaluating the Robustness of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10819">http://arxiv.org/abs/2308.10819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zekun Li, Baolin Peng, Pengcheng He, Xifeng Yan</li>
<li>for: 本研究旨在评估大语言模型（LLM）对针对性指令的Robustness，以确保其安全地部署在实际应用中。</li>
<li>methods: 本研究提出了一种探索LLM对针对性指令的Robustness的benchmark，通过测试当今的 instruction-following LLMs，发现了这些模型对针对性指令攻击的有限性。</li>
<li>results: 研究发现，现有的 instruction-tuned 模型容易被针对性指令攻击，并且这些模型会被训练以仅完成提示中的指令而不真正理解提示的含义。这 highlights 需要Addressing the challenge of training models to comprehend prompts instead of merely following instruction phrases and completing the text.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown remarkable proficiency in following instructions, making them valuable in customer-facing applications. However, their impressive capabilities also raise concerns about the amplification of risks posed by adversarial instructions, which can be injected into the model input by third-party attackers to manipulate LLMs' original instructions and prompt unintended actions and content. Therefore, it is crucial to understand LLMs' ability to accurately discern which instructions to follow to ensure their safe deployment in real-world scenarios. In this paper, we propose a pioneering benchmark for automatically evaluating the robustness of LLMs against adversarial instructions. The objective of this benchmark is to quantify the extent to which LLMs are influenced by injected adversarial instructions and assess their ability to differentiate between these adversarial instructions and original user instructions. Through experiments conducted with state-of-the-art instruction-following LLMs, we uncover significant limitations in their robustness against adversarial instruction attacks. Furthermore, our findings indicate that prevalent instruction-tuned models are prone to being overfitted to follow any instruction phrase in the prompt without truly understanding which instructions should be followed. This highlights the need to address the challenge of training models to comprehend prompts instead of merely following instruction phrases and completing the text.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）在客户面前的应用中表现出了惊人的能力，但这也使人们对其面临的风险的增强表示担忧。这些印象的能力可以通过第三方攻击者通过模型输入插入恶意指令来控制LLMs的原始指令和让其生成不良内容。因此，了解LLMs如何准确地执行原始指令是关键。在这篇论文中，我们提出了一个先进的benchmark来自动评估LLMs对恶意指令的抵抗力。本benchmark的目标是量化LLMs对插入的恶意指令的影响和评估它们是否能够分辨恶意指令和原始用户指令。经过对当今最先进的指令执行LLMs进行实验，我们发现了这些模型对恶意指令攻击的有限性。此外，我们的发现表明，现有的指令训练模型容易被适应过度，以至于无法真正理解需要执行的指令，而是仅仅完成了提示中的指令。这highlights the need to address the challenge of training models to comprehend prompts instead of merely following instruction phrases and completing the text.
</details></li>
</ul>
<hr>
<h2 id="Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation"><a href="#Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation" class="headerlink" title="Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation"></a>Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08799">http://arxiv.org/abs/2308.08799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingxiaoyi/pare">https://github.com/jingxiaoyi/pare</a></li>
<li>paper_authors: Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen</li>
<li>For: 本研究提出了一种基于Item Popularity的推荐方法（PARE），以优化现有的推荐方法。* Methods: PARE包括四个模块，每个模块关注不同的方面：历史流行度、时间影响、周期性影响以及侧信息。 finally，一个注意层用于将四个模块的输出融合。* Results: 对于多个数据集的实验表明，PARE可以与现有的先进推荐方法相比，或者甚至超越它们。此外，将PARE与现有的推荐方法结合使用可以显著提高性能。<details>
<summary>Abstract</summary>
Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.
</details>
<details>
<summary>摘要</summary>
很多研究者在过去几年中对推荐系统进行了逐渐增长的研究。大多数现有的推荐方法都是通过历史用户项交互来捕捉用户个性化的偏好，这可能会违反用户隐私。此外，这些方法通常忽视了item popularity的时间变化，这可能会影响用户做出决策。为了bridging这个差距，我们提出了Popularity-Aware Recommender（PARE），它通过预测item popularity来提供非个性化推荐。PARE包括四个模块，每个模块都专注于不同的方面：popularity history、temporal impact、periodic impact和side information。最后，我们使用了注意层来融合四个模块的输出。据我们所知，这是首次在推荐系统中显式地模型item popularity。我们的实验表明，PARE可以与现有的先进推荐方法相比，并且在一些情况下可以更好。由于PARE强调item popularity而不是个性化用户偏好，因此它可以增强现有的推荐方法，作为补充组件。我们的实验还表明，将PARE与现有的推荐方法集成可以大幅超越单独的模型性能，这说明PARE的潜在价值。此外，PARE的简单性使得它在实际应用中非常实用，并且成为未来研究的优秀基准。
</details></li>
</ul>
<hr>
<h2 id="Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data"><a href="#Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data" class="headerlink" title="Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data"></a>Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11646">http://arxiv.org/abs/2308.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Chaochao Chen, Weiming Liu, Pengyang Zhou, Huabin Zhu, Shuheng Shen, Weiqiang Wang, Mengling Hu, Yanchao Tan, Xiaolin Zheng</li>
<li>for: 提高 Federated Learning 在实际应用中的效果，特别是在非独立和 identical 数据 setting 中。</li>
<li>methods: 提出了两个主要模块：本地关系增强（LRA）和全局尼亚希尔贝克（GNE），用于同时解决客户端间和客户端内的不一致性。</li>
<li>results: 经过了四个 benchmark 数据集的广泛实验，证明 FedRANE 可以在非独立和 identical 数据 setting 中提高 Federated Learning 的性能。<details>
<summary>Abstract</summary>
Federated learning (FL) is a distributed machine learning paradigm that needs collaboration between a server and a series of clients with decentralized data. To make FL effective in real-world applications, existing work devotes to improving the modeling of decentralized data with non-independent and identical distributions (non-IID). In non-IID settings, there are intra-client inconsistency that comes from the imbalanced data modeling, and inter-client inconsistency among heterogeneous client distributions, which not only hinders sufficient representation of the minority data, but also brings discrepant model deviations. However, previous work overlooks to tackle the above two coupling inconsistencies together. In this work, we propose FedRANE, which consists of two main modules, i.e., local relational augmentation (LRA) and global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency simultaneously. Specifically, in each client, LRA mines the similarity relations among different data samples and enhances the minority sample representations with their neighbors using attentive message passing. In server, GNE reaches an agreement among inconsistent and discrepant model deviations from clients to server, which encourages the global model to update in the direction of global optimum without breaking down the clients optimization toward their local optimums. We conduct extensive experiments on four benchmark datasets to show the superiority of FedRANE in enhancing the performance of FL with non-IID data.
</details>
<details>
<summary>摘要</summary>
Federated learning (FL) 是一种分布式机器学习 paradigma，需要服务器和多个客户端之间的合作，以便处理 Decentralized 数据。为了在实际应用中使 FL 有效，现有的工作努力于非独立和同分布（non-IID）数据的模型化。在非独立 Setting 中，有内部客户端不一致性，来自不均衡数据模型的差异，不仅妨碍了足够表示少数据，还导致了不同客户端的模型偏差不同。然而，过去的工作忽视了 simultaneous 处理上述两种 coupling inconsistency。在这种工作中，我们提议 FedRANE，它包括两个主要模块：本地关系增强（LRA）和全局纳什均衡（GNE）。具体来说，在每个客户端上，LRA 挖掘不同数据样本之间的相似关系，并通过对注意力传递来增强少数据表示。在服务器端，GNE 达成了客户端和服务器之间的一致，以避免客户端优化方向和服务器优化方向之间的冲突。我们在四个 benchmark 数据集上进行了广泛的实验，以显示 FedRANE 在非独立数据上提高 FL 的性能。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations"><a href="#Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations" class="headerlink" title="Bayesian polynomial neural networks and polynomial neural ordinary differential equations"></a>Bayesian polynomial neural networks and polynomial neural ordinary differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10892">http://arxiv.org/abs/2308.10892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Colby Fronk, Jaewoong Yun, Prashant Singh, Linda Petzold</li>
<li>for: 这些方法用于 recovering 多种科学和工程问题中的方程模型，但是它们只提供点估计方法，无法处理噪音数据。</li>
<li>methods: 我们使用 Laplace 近似、Markov Chain Monte Carlo (MCMC) 采样方法和 variational inference 进行 Bayesian 推理。</li>
<li>results: 我们发现 Laplace 近似是这类问题中最佳的方法。我们的工作可以轻松扩展到符号神经网络中的更广泛类型。<details>
<summary>Abstract</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.
</details>
<details>
<summary>摘要</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) 是两种最新和强大的方法 для解决许多科学和工程问题中的方程回归问题。然而，这些方法只能提供点估计方法参数，并且无法处理噪声数据。我们通过开发和验证以下抽象推理方法来解决这个挑战：拉普拉斯逼近、Markov Chain Monte Carlo（MCMC）采样方法和variational推理。我们发现拉普拉斯逼近是这类问题中最佳的方法。我们的工作可以轻松扩展到符号化神经网络中的更广泛的类型。
</details></li>
</ul>
<hr>
<h2 id="CodeCoT-and-Beyond-Learning-to-Program-and-Test-like-a-Developer"><a href="#CodeCoT-and-Beyond-Learning-to-Program-and-Test-like-a-Developer" class="headerlink" title="CodeCoT and Beyond: Learning to Program and Test like a Developer"></a>CodeCoT and Beyond: Learning to Program and Test like a Developer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08784">http://arxiv.org/abs/2308.08784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dong Huang, Qingwen Bu, Heming Cui</li>
<li>For: The paper aims to improve the code generation accuracy of transformer-based large language models (LLMs) like GPT-x models, which often encounter challenges when handling tasks that differ from their training data.* Methods: The paper proposes two components: Vanilla CodeCoT and Self-exam CodeCoT. The Self-exam CodeCoT incorporates self-examination, allowing the model to iteratively generate code, formulate test cases, and refine its outputs.* Results: The paper reports significant enhancements in code generation accuracy across various LLM variants, with the Self-exam CodeCoT approach achieving an unprecedented pass@1 accuracy of 79.27% on the gpt-3.5-turbo-0613 model in the HumanEval dataset.Here are the three points in Simplified Chinese:</li>
<li>for: 这篇论文目标是提高基于转换器的大型自然语言处理模型（LLM）如GPT-x模型的代码生成精度，这些模型经常在不同于训练数据的任务中遇到挑战。</li>
<li>methods: 论文提出了两个组成部分：普通的CodeCoT和自我评估的CodeCoT。后者将自我评估纳入到模型中，使其可以顺序生成代码，制定测试例子，并改进其输出。</li>
<li>results: 论文发现，使用不同的LLM变体时，CodeCoT技术均能够显著提高代码生成精度，而Self-exam CodeCoT方法在gpt-3.5-turbo-0613模型上的HumanEval数据集上达到了历史最高的pass@1准确率为79.27%。<details>
<summary>Abstract</summary>
In natural language processing, transformer-based large language models (LLMs) like GPT-x models developed by OpenAI have revolutionized the landscape. Despite their impressive capabilities, these models often encounter challenges when handling tasks that differ from their training data, resulting in compromised performance. To address this, few-shot learning has emerged as a valuable technique, allowing LLMs to adapt with minimal task-specific data. One innovative strategy, known as Chain-of-Thought Prompting (CoT), has been introduced to guide LLMs in revealing cognitive processes during multi-step reasoning. In this paper, we propose Code Chain-of-Thought~(CodeCoT), which consists of two components: the Vanilla CodeCoT and the Self-exam CodeCoT. The latter incorporates self-examination, empowering the model to iteratively generate code, formulate test cases, and refine its outputs. Specifically, the process entails the generation of test examples by the model corresponding to the code it is tasked to implement. If it fails on the test examples, then it regenerates the code based on the erroneous code and associated error types. Through comprehensive experiments, we observed that both techniques significantly enhance code generation accuracy across various LLM variants. Our evaluation results reveal that CodeCoT improves the code generation effectiveness, including an unprecedented pass@1 accuracy of 79.27\% using the Self-exam CodeCoT approach on the gpt-3.5-turbo-0613 model in the HumanEval dataset.
</details>
<details>
<summary>摘要</summary>
在自然语言处理领域，基于转换器的大语言模型（LLM）如OpenAI开发的GPT-x模型已经革命化了景观。尽管它们具有印象的能力，但它们在处理不同于训练数据的任务时经常遇到挑战，导致性能受损。为解决这个问题，几何学学习（few-shot learning）已经成为一种有价值的技术，允许LLM在最小的任务特定数据上适应。在这篇论文中，我们提出了代码链条提示（CodeCoT）技术，它包括两个组成部分：简单的CodeCoT和自我检验CodeCoT。后者在模型生成代码、编写测试例子和改进输出过程中，具有自我检验能力。具体来说，该过程包括由模型生成测试例子，并将其与代码相关的错误类型进行关联。我们通过了详细的实验，发现CodeCoT技术可以在不同的LLM变体上提高代码生成精度。我们的评估结果表明，使用Self-exam CodeCoT方法，gpt-3.5-turbo-0613模型在人类评估数据集上达到了历史上无 precedent的pass@1准确率为79.27%。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer"><a href="#Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer" class="headerlink" title="Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer"></a>Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09724">http://arxiv.org/abs/2308.09724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang</li>
<li>for: 这篇论文是针对cross-domain fraud detection和traffic demand prediction领域的深度领域适应技术。</li>
<li>methods: 本文提出了一个novel的Knowledge-Inspired Subdomain Adaptation（KISA）框架，包括提供了理论底下 Shared Expected Loss的最小化，以及知识驱动的子领域分配问题和知识融合网络等。</li>
<li>results: 实验结果显示，KISA在骗贾检测和交通需求预测任务中获得了杰出的成绩。<details>
<summary>Abstract</summary>
Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details>
<details>
<summary>摘要</summary>
大多数当今深度领域适应技术都是在全局方式对源和目标样本进行对齐。即 после对齐，每个源样本都应该变得与任何目标样本相似。然而，全局对齐可能并不是最佳或必需的在实践中。例如，考虑cross-domain fraud detection，其中有两类交易：信用和非信用。对这两类交易进行分别对齐可能会提高性能，因为信用交易很 unlikely to exhibit patterns similar to non-credit transactions。为实现这种细致的领域适应，我们提出了一个novel Knowledge-Inspired Subdomain Adaptation（KISA） frameworks。具体来说，我们提供了以下三个方面：1. 我们提供了对KISA的理论启示，即KISA最小化了共享预期损失，这是领域适应方法的成功前提。2. 我们提出了基于知识的子领域分配问题，这在细致领域适应中扮演着关键性的角色。3. 我们设计了一个知识融合网络，以利用不同领域的知识。我们的实验证明，KISA在fraud detection和交通需求预测任务上表现出了很好的 result。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Demonstration-Ensembling-for-In-context-Learning"><a href="#Exploring-Demonstration-Ensembling-for-In-context-Learning" class="headerlink" title="Exploring Demonstration Ensembling for In-context Learning"></a>Exploring Demonstration Ensembling for In-context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08780">http://arxiv.org/abs/2308.08780</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mukhal/icl-ensembling">https://github.com/mukhal/icl-ensembling</a></li>
<li>paper_authors: Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang</li>
<li>for: 强化 язы言模型（LM）的学习，使其能够更好地完成给定任务。</li>
<li>methods: 使用示例集（demonstrations）进行强化学习，并研究不同的ensemble方法。</li>
<li>results: 比 concatenation 方法更高效，可以提高模型的预测精度。weighted max ensemble 方法在12种语言任务上表现出色，比 concatenation 方法提高了2.4个平均点。<details>
<summary>Abstract</summary>
In-context learning (ICL) operates by showing language models (LMs) examples of input-output pairs for a given task, i.e., demonstrations. The standard approach for ICL is to prompt the LM with concatenated demonstrations followed by the test input. This approach suffers from some issues. First, concatenation offers almost no control over the contribution of each demo to the model prediction. This can be sub-optimal when some demonstrations are irrelevant to the test example. Second, due to the input length limit of some transformer models, it might be infeasible to fit many examples into the context, especially when dealing with long-input tasks. In this work, we explore Demonstration Ensembling (DENSE) as an alternative to simple concatenation. DENSE predicts outputs using subsets (i.e., buckets) of the demonstrations and then combines the output probabilities resulting from each subset to produce the final prediction. We study different ensembling methods using GPT-j and experiment on 12 language tasks. Our experiments show weighted max ensembling to outperform vanilla concatenation by as large as 2.4 average points. Code available at https://github.com/mukhal/icl-ensembling.
</details>
<details>
<summary>摘要</summary>
启发式学习（ICL）通过显示语言模型（LM）输入输出对的示例来操作，即示例。标准的ICL方法是在LM中提示示例后跟测试输入。这种方法存在一些问题。首先， concatenation 无法控制每个示例对模型预测的贡献。这可能是不优的when some demonstrations 无关于测试示例。其次，由于一些转换器模型的输入长度限制，可能无法将多个示例放入上下文中，特别是处理长输入任务。在这项工作中，我们探讨使用Demonstration Ensembling（DENSE）作为concatentation的替代方案。DENSE 使用示例集（i.e.,  bucket）预测输出，然后将每个集的输出概率组合成最终预测。我们研究不同的 ensemble 方法使用 GPT-j，并在 12 种语言任务上进行实验。我们的实验结果显示 weighted max ensembling 可以和concatentation 相比，在12种语言任务上出performances by as large as 2.4 average points。代码可以在 https://github.com/mukhal/icl-ensembling 上获取。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-at-Work-in-China’s-Labor-Market"><a href="#Large-Language-Models-at-Work-in-China’s-Labor-Market" class="headerlink" title="Large Language Models at Work in China’s Labor Market"></a>Large Language Models at Work in China’s Labor Market</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08776">http://arxiv.org/abs/2308.08776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qin Chen, Jinfeng Ge, Huaqing Xie, Xingcheng Xu, Yanqing Yang</li>
<li>for: This paper explores the potential impacts of large language models (LLMs) on the Chinese labor market, with a focus on understanding the displacement risks for high-paying and experience-intensive jobs.</li>
<li>methods: The paper uses a methodology that incorporates human expertise and LLM classifications to analyze occupational exposure to LLM capabilities, and aggregates occupation exposure to the industry level to obtain industry exposure scores.</li>
<li>results: The results indicate a positive correlation between occupation exposure and wage levels&#x2F;experience premiums, suggesting that higher-paying and experience-intensive jobs may face greater displacement risks from LLM-powered software. The industry exposure scores align with expert assessments and economic intuitions, and the study provides an analytical basis for understanding the labor market impacts of increasingly capable AI systems in China.<details>
<summary>Abstract</summary>
This paper explores the potential impacts of large language models (LLMs) on the Chinese labor market. We analyze occupational exposure to LLM capabilities by incorporating human expertise and LLM classifications, following Eloundou et al. (2023)'s methodology. We then aggregate occupation exposure to the industry level to obtain industry exposure scores. The results indicate a positive correlation between occupation exposure and wage levels/experience premiums, suggesting higher-paying and experience-intensive jobs may face greater displacement risks from LLM-powered software. The industry exposure scores align with expert assessments and economic intuitions. We also develop an economic growth model incorporating industry exposure to quantify the productivity-employment trade-off from AI adoption. Overall, this study provides an analytical basis for understanding the labor market impacts of increasingly capable AI systems in China. Key innovations include the occupation-level exposure analysis, industry aggregation approach, and economic modeling incorporating AI adoption and labor market effects. The findings will inform policymakers and businesses on strategies for maximizing the benefits of AI while mitigating adverse disruption risks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models"><a href="#Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models" class="headerlink" title="Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models"></a>Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08774">http://arxiv.org/abs/2308.08774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phillip Rust, Anders Søgaard</li>
<li>for: 本文目的是探讨语言模型如mBERT、XLM-R和BLOOM在多语言泛化和压缩方面是否可以同时满足隐私、语言公平和透明性的要求。</li>
<li>methods: 本文使用了多语言压缩和语言公平性来评估这些模型的隐私、语言公平和透明性。</li>
<li>results: 研究发现，多语言压缩和语言公平性可以同时满足隐私要求，但是隐私和训练数据的影响稀缺性之间存在矛盾。研究还进行了多种NLP任务的实验，并评估了不同隐私保证下的多语言压缩和训练数据影响的质量。结果表明，需要开发新的方法来同时优化这些目标，以找到实际的让步。<details>
<summary>Abstract</summary>
Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.
</details>
<details>
<summary>摘要</summary>
Language models like mBERT、XLM-R和BLOOM目的是实现多语言通用或压缩，以便将模型转移到大量（可能未看过）语言上。然而，这些模型应该也是私人的，公平的，透明的，对模型预测的关系。是这些需求可以同时满足呢？我们显示，多语言压缩和语言公平是可以同时满足 differential privacy 的，但是 differential privacy 与训练数据影响稀缺是不可能同时满足的。我们进一步发现了在两种常见的 NLP 任务上对多语言压缩和训练数据影响稀缺进行了多种实验，并详细分析了这些负担的交叉关系。我们的结果表明，我们需要开发一些方法来同时优化这些目标，以找到实际的平衡点。
</details></li>
</ul>
<hr>
<h2 id="Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving"><a href="#Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving" class="headerlink" title="Sensor Fusion by Spatial Encoding for Autonomous Driving"></a>Sensor Fusion by Spatial Encoding for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10707">http://arxiv.org/abs/2308.10707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quoc-Vinh Lai-Dang, Jihui Lee, Bumgeun Park, Dongsoo Har</li>
<li>for: 本研究旨在探讨摄像头和激光雷达数据融合的问题，以提高自动驾驶和机器人视觉系统的性能。</li>
<li>methods: 本研究使用了Transformer模块，并在不同的分辨率下应用了多个Transformer模块，以有效地结合本地和全局上下文关系。</li>
<li>results: 对于两个挑战性的测试基准，提出的方法比前一些方法显著提高了驾驶和违法分数，相比TransFuser，本方法在Longest6和Town05 Long bencmarks上的驾驶分数提高8%和19%。<details>
<summary>Abstract</summary>
Sensor fusion is critical to perception systems for task domains such as autonomous driving and robotics. Recently, the Transformer integrated with CNN has demonstrated high performance in sensor fusion for various perception tasks. In this work, we introduce a method for fusing data from camera and LiDAR. By employing Transformer modules at multiple resolutions, proposed method effectively combines local and global contextual relationships. The performance of the proposed method is validated by extensive experiments with two adversarial benchmarks with lengthy routes and high-density traffics. The proposed method outperforms previous approaches with the most challenging benchmarks, achieving significantly higher driving and infraction scores. Compared with TransFuser, it achieves 8% and 19% improvement in driving scores for the Longest6 and Town05 Long benchmarks, respectively.
</details>
<details>
<summary>摘要</summary>
感知系统中的感知融合是自动驾驶和机器人等任务域的关键技术。最近，以Transformer和CNN结合的方法在感知融合中表现出色。在这种方法中，我们提出了将数码和LiDAR数据进行融合的方法，通过在多个分辨率下使用Transformer模块，有效地组合了本地和全局上下文关系。我们在两个挑战性的测试基准上进行了广泛的实验，并证明了我们的方法在最具挑战性的情况下表现出色，比之前的方法提高了驾驶和违法分数。相比于TransFuser，我们的方法在Longest6和Town05 Long benchmark上提高了8%和19%的驾驶分数。
</details></li>
</ul>
<hr>
<h2 id="Discrete-Prompt-Compression-with-Reinforcement-Learning"><a href="#Discrete-Prompt-Compression-with-Reinforcement-Learning" class="headerlink" title="Discrete Prompt Compression with Reinforcement Learning"></a>Discrete Prompt Compression with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08758">http://arxiv.org/abs/2308.08758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoyoun Jung, Kyung-Joong Kim</li>
<li>for: 本研究旨在提出一种基于强化学习的提示压缩方法，以解决现有方法具有多个含义的 embedding 问题，提高可读性、可重用性和适用性。</li>
<li>methods: 本研究使用了一种名为 PCRL 的计算效率高的政策网络，直接编辑提示，以实现提示压缩。 PCRL 可以适应不同类型的 LM，包括逻辑机制和解码器-编码器架构，并可以在不使用梯度访问 LM 或标注数据的情况下进行训练。</li>
<li>results: 研究发现，PCRL 可以实现提示Token 的平均减少24.6%，同时保持性能。此外，我们还证明了Policy 可以被传递到更大的 LM 上，并通过不同的分析，帮助理解提示中Token 的重要性。<details>
<summary>Abstract</summary>
Instruction-tuned Language Models (LMs) are widely used by users to address various problems with task-specific prompts. Constraints associated with the context window length and computational costs encourage the development of compressed prompts. Existing methods rely heavily on training embeddings, which are designed to accommodate multiple token meanings. This presents challenges in terms of interpretability, a fixed number of embedding tokens, reusability across different LMs, and inapplicability when interacting with black-box APIs. This study proposes prompt compression with reinforcement learning (PCRL), a novel discrete prompt compression method that addresses these issues. PCRL employs a computationally efficient policy network that directly edits prompts. The PCRL training approach can be flexibly applied to various types of LMs, as well as decoder-only and encoder-decoder architecture, and can be trained without gradient access to LMs or labeled data. PCRL achieves an average reduction of 24.6% in token count across various instruction prompts while preserving performance. Further, we demonstrate that the learned policy can be transferred to larger LMs, and through various analyses, we aid the understanding of token importance within prompts.
</details>
<details>
<summary>摘要</summary>
启示调整语言模型（LM）广泛地使用于解决各种问题，通常通过用户提供任务特定的提示。Context窗口长度和计算成本的约束，推动了压缩提示的发展。现有方法主要依赖于训练嵌入，这会带来多个token意义的解释问题，固定 embedding 数量、不可重复性和黑盒API交互时无法应用。本研究提出了启示压缩学习（PCRL），一种新的简单提示压缩方法。PCRL使用了计算效率高的政策网络，直接编辑提示。PCRL 训练方法可以适应不同类型的 LM，以及decoder-only和encoder-decoder架构，并可以在无需梯度访问LM或标注数据的情况下进行训练。PCRL 实现了各种 instruciton 提示中的平均token数减少24.6%，同时保持性能。此外，我们还证明了学习政策可以传递到更大的 LM 上，并通过多种分析，帮助理解提示中的token重要性。
</details></li>
</ul>
<hr>
<h2 id="SurgicalSAM-Efficient-Class-Promptable-Surgical-Instrument-Segmentation"><a href="#SurgicalSAM-Efficient-Class-Promptable-Surgical-Instrument-Segmentation" class="headerlink" title="SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation"></a>SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08746">http://arxiv.org/abs/2308.08746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenxi-yue/surgicalsam">https://github.com/wenxi-yue/surgicalsam</a></li>
<li>paper_authors: Wenxi Yue, Jing Zhang, Kun Hu, Yong Xia, Jiebo Luo, Zhiyong Wang</li>
<li>for: 这篇论文是针对医疗器械分类 зада填的，具体是使用Segment Anything Model (SAM)来进行医疗器械分类。</li>
<li>methods: 这篇论文使用了SAM作为基础模型，并提出了一个名为SurgicalSAM的新方法，它是一个端到端的高效优化方法，可以将医疗器械特有的信息与SAM的预先训练知识结合，以提高分类的精度和简化pipeline。</li>
<li>results: 实验结果显示，SurgicalSAM在EndoVis2018和EndoVis2017数据集上实现了顶尖性能，并且只需要小量可调参数。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to poor generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM's pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, which directly generates prompt embeddings from class prototypes and eliminates the use of explicit prompts for improved robustness and a simpler pipeline. In addition, to address the low inter-class variance among surgical instrument categories, we propose contrastive prototype learning, further enhancing the discrimination of the class prototypes for more accurate class prompting. The results of extensive experiments on both EndoVis2018 and EndoVis2017 datasets demonstrate that SurgicalSAM achieves state-of-the-art performance while only requiring a small number of tunable parameters. The source code will be released at https://github.com/wenxi-yue/SurgicalSAM.
</details>
<details>
<summary>摘要</summary>
《医疗器械分割模型（SAM）》是一种强大的基础模型，对医疗器械分割进行了革命性的改进。为了应用SAM于医疗器械分割，常见的方法是在SAM中提供精确的点或盒子作为批处理，然后使用这些点或盒子作为SAM的Zero-shot模式下的提示。然而，我们发现两个问题：（1）自然物体和医疗器械之间的领域差异导致SAM的泛化性差；（2）SAM需要精确的点或盒子位置来进行准确的分割，需要大量的手动指导或一个高性能的专家检测器来准备提示，这导致了复杂的多Stage管道。为解决这些问题，我们介绍了《医疗SAM》，一种新的终端有效策略，使SAM能够有效地 интеGRATE医疗特有信息和SAM已经预训练的知识，从而提高泛化性。具体来说，我们提出了一种轻量级的原型基本类提示编码器，直接从类原型生成提示编码，并废除了显式提示的使用，从而提高了robustness和管道的简单化。此外，为了解决医疗器械类别之间的低同类差，我们提出了对比较类原型学习，进一步增强类原型的抑强，从而提高了分割的精度。实验结果表明，SurgicalSAM在EndoVis2018和EndoVis2017 datasets上表现出状态的作者性，只需要一小量的可调参数。源代码将在https://github.com/wenxi-yue/SurgicalSAM上发布。
</details></li>
</ul>
<hr>
<h2 id="PMET-Precise-Model-Editing-in-a-Transformer"><a href="#PMET-Precise-Model-Editing-in-a-Transformer" class="headerlink" title="PMET: Precise Model Editing in a Transformer"></a>PMET: Precise Model Editing in a Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08742">http://arxiv.org/abs/2308.08742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xpq-tech/pmet">https://github.com/xpq-tech/pmet</a></li>
<li>paper_authors: Xiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun Ma, Jie Yu</li>
<li>for: 本研究旨在提高模型修改技术的性能，减少模型修改的成本。</li>
<li>methods: 该研究使用了多头自注意力（MHSA）和循环网络（FFN）的隐藏状态分析，并引入了一种同时优化多头自注意力和循环网络隐藏状态的方法（PMET），以准确地更新FFN的参数。</li>
<li>results: 实验表明，PMET在COUNTERFACT和zsRE datasets上表现出色，与其他方法相比，具有更高的性能。<details>
<summary>Abstract</summary>
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we introduce PMET, which simultaneously optimizes Transformer Component (TC, namely MHSA and FFN) hidden states, while only using the optimized TC hidden states of FFN to precisely update FFN weights. Our experiments demonstrate that PMET exhibits state-of-the-art performance on both the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the effectiveness of our enhancements, further reinforcing the finding that the MHSA encodes certain general knowledge extraction patterns and indicating its storage of a small amount of factual knowledge. Our code is available at https://github.com/xpq-tech/PMET.git.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的修改技术可以变更小一部分知识，并且实现了可观的成果。现有方法假设transformer层（TL）的隐藏状态是对Feed-Forward Network（FFN）的键值内存。它们通常将TL隐藏状态优化为记忆目标知识，并将其用于更新FFN的对应预测。但是，TL隐藏状态的资讯来源来自多个部分，包括多头自我对Alignment（MHSA）、FFN和复合连接。现有方法忽略了TL隐藏状态中不具体知识的存在，从而导致模型修改的性能下降。为了更精确地进行模型修改，我们进行了隐藏状态分析，发现MHSA对于抽取一些通用知识的模式具有特定的储存作用。这意味着MHSA的对应预测不需要更新，只需要使用优化的FFN对应预测来更新FFN的对应预测。基于以上发现，我们提出了PMET，它同时优化Transformer Component（TC，即MHSA和FFN）的隐藏状态，并将优化的TC隐藏状态仅用于精确地更新FFN的对应预测。我们的实验显示，PMET在COUNTERFACT和zsRE dataset上展示了顶尖的表现。我们的抽象实验显示，PMET的改进具有实质的优化作用，进一步证实了MHSA对于抽取通用知识的模式储存的发现，并显示了MHSA储存一小量的事实知识。我们的代码可以在https://github.com/xpq-tech/PMET.git中找到。
</details></li>
</ul>
<hr>
<h2 id="ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents"><a href="#ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents" class="headerlink" title="ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents"></a>ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08737">http://arxiv.org/abs/2308.08737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejaswini Manjunath, Mozhgan Navardi, Prakhar Dixit, Bharat Prakash, Tinoosh Mohsenin</li>
<li>for: 本研究旨在提出一种名为Ready for Production Hierarchical RL（ReProHRL）的方法，用于解决在实际环境中进行多目标导航的学习挑战。</li>
<li>methods: 该方法使用分类器作为预处理步骤，以学习多目标导航并将其转移到实际环境中。</li>
<li>results: 实验结果表明，提出的ReProHRL方法在模拟环境和实际环境中都能够在训练时间和性能方面超越基eline。在一个简单的单目标导航环境中，两种方法均达到100%的成功率，但在一个更复杂的环境和多目标设定下，提出的方法在基eline方法的18%和5%之上。为证明实际应用和Proof of Concept的实现，我们在一架名为Crazyflie的奈米扁平飞机上部署了提出的方法，并在其前置摄像头上进行多目标导航实验。<details>
<summary>Abstract</summary>
Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: Robots 已经成功完成了高精度任务。在实际环境中， sparse 奖励和多个目标导致学习仍然是一个大型挑战，并 Reinforcement Learning（RL）算法无法学习好的策略。训练在模拟环境中，然后在实际世界中细化是一种常见的方法。然而，适应实际环境是一个挑战。在这篇论文中，我们提出了名为Ready for Production Hierarchical RL（ReProHRL）的方法，该方法将多个目标导航分为多个层次。我们还使用对象检测器作为先processing步骤，以学习多个目标导航并将其转移到实际世界。实际结果表明，我们提出的ReProHRL方法在模拟环境和实际世界中都能够超过基准值，即使在更复杂的环境和多个目标设定下。为了证明实际实施和理解，我们在一架名为Crazyflie的奈米飞机上部署了我们的方法，并通过前 Camera 进行多个目标导航实验。
</details></li>
</ul>
<hr>
<h2 id="LLM-FuncMapper-Function-Identification-for-Interpreting-Complex-Clauses-in-Building-Codes-via-LLM"><a href="#LLM-FuncMapper-Function-Identification-for-Interpreting-Complex-Clauses-in-Building-Codes-via-LLM" class="headerlink" title="LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM"></a>LLM-FuncMapper: Function Identification for Interpreting Complex Clauses in Building Codes via LLM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08728">http://arxiv.org/abs/2308.08728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Zheng, Ke-Yin Chen, Xin-Yu Cao, Xin-Zheng Lu, Jia-Rui Lin</li>
<li>for: 本研究的目的是提出一种基于大语言模型（LLM）的方法，用于解释复杂的法规条款。</li>
<li>methods: 该方法包括系统分析建筑 codes，定义一系列的原子函数，以捕捉 Shared 计算逻辑和复杂约束，并开发了一个启发模板和分类化调整策略，以便使用常见的 LLM 进行有效的函数标识。</li>
<li>results: 经 statistical analysis 和实验 validate，该方法可以准确地 Identify 相应的预定函数，并将其转换为计算代码。此外，该方法还可以解释复杂的法规条款。<details>
<summary>Abstract</summary>
As a vital stage of automated rule checking (ARC), rule interpretation of regulatory texts requires considerable effort. However, interpreting regulatory clauses with implicit properties or complex computational logic is still challenging due to the lack of domain knowledge and limited expressibility of conventional logic representations. Thus, LLM-FuncMapper, an approach to identifying predefined functions needed to interpret various regulatory clauses based on the large language model (LLM), is proposed. First, by systematically analysis of building codes, a series of atomic functions are defined to capture shared computational logics of implicit properties and complex constraints, creating a database of common blocks for interpreting regulatory clauses. Then, a prompt template with the chain of thought is developed and further enhanced with a classification-based tuning strategy, to enable common LLMs for effective function identification. Finally, the proposed approach is validated with statistical analysis, experiments, and proof of concept. Statistical analysis reveals a long-tail distribution and high expressibility of the developed function database, with which almost 100% of computer-processible clauses can be interpreted and represented as computer-executable codes. Experiments show that LLM-FuncMapper achieve promising results in identifying relevant predefined functions for rule interpretation. Further proof of concept in automated rule interpretation also demonstrates the possibility of LLM-FuncMapper in interpreting complex regulatory clauses. To the best of our knowledge, this study is the first attempt to introduce LLM for understanding and interpreting complex regulatory clauses, which may shed light on further adoption of LLM in the construction domain.
</details>
<details>
<summary>摘要</summary>
为了自动检查规则（ARC）中的规则解释，需要很大的努力。然而，解释法规条款中的隐式属性或复杂计算逻辑仍然是一个挑战，因为缺乏领域知识和限制表达逻辑的表达能力。因此，我们提出了LLM-FuncMapper，一种基于大语言模型（LLM）的方法，用于确定解释法规条款中的预定函数。首先，通过系统性分析法规文本，我们定义了一系列原子函数，用于捕捉不同领域的共享计算逻辑和复杂约束，并建立了一个共享块数据库，用于解释法规条款。然后，我们开发了一个提示模板，并使用分类调整策略，以便使用常见的LLM来确定预定函数。最后，我们验证了我们的方法，通过统计分析、实验和证明原理来证明其效果。统计分析显示，我们建立的函数库具有长尾分布和高表达能力，可以将大多数计算可能的条款解释为计算代码。实验表明，LLM-FuncMapper可以成功地确定解释法规条款中的预定函数。此外，我们还进行了自动规则解释的证明，这表明LLM-FuncMapper可以在解释复杂的法规条款中发挥作用。根据我们所知，这是第一次将大语言模型应用于解释复杂法规条款，这可能会照亮未来在建筑领域中LLM的更多应用。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing"><a href="#A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing" class="headerlink" title="A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing"></a>A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10869">http://arxiv.org/abs/2308.10869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nibraas Khan, Mahrukh Tauseef, Ritam Ghosh, Nilanjan Sarkar<br>for: 这篇论文的目的是提出一个新的成本函数，用于适应调节数据中的主题参数，以提高情绪识别的准确性。methods: 这篇论文使用了深度学习技术，特别是水星距离理论，来规定主题参数的重要性。results: 比较这篇论文的提案成本函数与传统的 Mean Squared Error 损失函数，在四个常用的数据集上得到了14.75% 和 17.75% 的平均提升。<details>
<summary>Abstract</summary>
Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.
</details>
<details>
<summary>摘要</summary>
人类情感是人类行为的重要组成部分，可以影响思维、决策和交流技能。因此，能够准确监测和识别情感的能力可以在许多人类中心应用中得到利用，如行为训练、情感健康评估和人机界面开发。基于生物数据的征特和情感状态的相关性，可以使用深度学习技术来准确检测人类情感状态。但是，现有模型的普适性往往受到参与者的偏好所限，因为参与者对刺激的反应会导致数据中的偏差。因此，我们提出了一个新的成本函数，使用优化运输理论和 Wasserstein 距离来权重调整参与者特定的数据，以便更重要地考虑参与者共同的数据特征，而不是受到偏差所影响的数据。我们的模型的性能通过一个具有多类分类器的自编码器来检测不同情感状态，并与使用 Mean Squared Error 损失函数的基准模型进行比较。中心距离和最小距离between不同类别在隐藏空间中的分离度被用作评价模型的metric。在所有数据集上，我们发现使用我们的损失函数而不是基准模型时，平均提高14.75%和17.75%（从基准到我们的损失函数）。
</details></li>
</ul>
<hr>
<h2 id="EdgeMA-Model-Adaptation-System-for-Real-Time-Video-Analytics-on-Edge-Devices"><a href="#EdgeMA-Model-Adaptation-System-for-Real-Time-Video-Analytics-on-Edge-Devices" class="headerlink" title="EdgeMA: Model Adaptation System for Real-Time Video Analytics on Edge Devices"></a>EdgeMA: Model Adaptation System for Real-Time Video Analytics on Edge Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08717">http://arxiv.org/abs/2308.08717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Wang, Nan Zhang, Xiaoyang Qu, Jianzong Wang, Jiguang Wan, Guokuan Li, Kaiyu Hu, Guilin Jiang, Jing Xiao</li>
<li>for: 这篇论文主要关注在对于边缘设备上进行实时影像分析中遇到的挑战，特别是边缘设备通常具有资源短缺的情况下，如何使用深度神经网络（DNN）来进行影像分析。</li>
<li>methods: 本论文提出了一个实用且高效的影像分析系统EdgeMA，可以适应影像流中的变化，并且能够处理资料漂移问题。EdgeMA使用灰度层次共occurrence统计 texture feature，并使用Random Forest分类器来检测领域变化。此外，我们还将模型更新方法基于重要性评分，专门用于更新模型以适应标签分布变化。</li>
<li>results: 经过严谨的实验评估，我们的结果显示EdgeMA可以明显提高推论精度。<details>
<summary>Abstract</summary>
Real-time video analytics on edge devices for changing scenes remains a difficult task. As edge devices are usually resource-constrained, edge deep neural networks (DNNs) have fewer weights and shallower architectures than general DNNs. As a result, they only perform well in limited scenarios and are sensitive to data drift. In this paper, we introduce EdgeMA, a practical and efficient video analytics system designed to adapt models to shifts in real-world video streams over time, addressing the data drift problem. EdgeMA extracts the gray level co-occurrence matrix based statistical texture feature and uses the Random Forest classifier to detect the domain shift. Moreover, we have incorporated a method of model adaptation based on importance weighting, specifically designed to update models to cope with the label distribution shift. Through rigorous evaluation of EdgeMA on a real-world dataset, our results illustrate that EdgeMA significantly improves inference accuracy.
</details>
<details>
<summary>摘要</summary>
现实时视频分析在边缘设备上是一项复杂的任务。边缘设备通常具有资源约束，因此边缘深度神经网络（DNN）通常具有较少的参数和较浅的结构，只能在有限的场景下表现良好。在这篇论文中，我们介绍了EdgeMA，一个实用和高效的视频分析系统，用于适应实际视频流中的数据偏移问题。EdgeMA提取了灰度层次相关矩阵基本的纹理特征，并使用Random Forest分类器来探测领域偏移。此外，我们还实现了基于重要性赋分的模型更新方法，以适应标签分布偏移。经过对实际数据集的严格评估，我们的结果表明，EdgeMA可以显著提高推理精度。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Results-on-the-Architecture-of-Mathematical-Reasoning-Aligned-by-Cognitive-Alternation"><a href="#Probabilistic-Results-on-the-Architecture-of-Mathematical-Reasoning-Aligned-by-Cognitive-Alternation" class="headerlink" title="Probabilistic Results on the Architecture of Mathematical Reasoning Aligned by Cognitive Alternation"></a>Probabilistic Results on the Architecture of Mathematical Reasoning Aligned by Cognitive Alternation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08714">http://arxiv.org/abs/2308.08714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minzheng Li, Xiangzhong Fang, Haixin Yang</li>
<li>for: 本研究旨在构思一种可以解决数学问题的机器人。</li>
<li>methods: 该研究采用分两部分的量化逻辑系统：思维过程和认知过程，并提供了概率描述该系统的建构。</li>
<li>results: 研究人员提供了一种可以模型思维过程和认知过程的 probabilistic 描述，以便实现机器人可以解决数学问题的目标。<details>
<summary>Abstract</summary>
We envision a machine capable of solving mathematical problems. Dividing the quantitative reasoning system into two parts: thought processes and cognitive processes, we provide probabilistic descriptions of the architecture.
</details>
<details>
<summary>摘要</summary>
我们看到了一种机器能够解决数学问题的想法。将数学逻辑系统分为两部分：思维过程和认知过程，我们提供了概率描述这个architecture。Here's a breakdown of the translation:* "We envision" is translated as "我们看到了" (wǒmen kàn dào le)* "a machine capable of solving mathematical problems" is translated as "一种机器能够解决数学问题" (yī zhǒng jīqì néng huì jiě jué dù shù)* "Dividing the quantitative reasoning system into two parts" is translated as "将数学逻辑系统分为两部分" (jiǎng dào xué xíng lógí xìtemu bìwǎn)* "thought processes" is translated as "思维过程" (sī wèi guò xìng)* "and cognitive processes" is translated as "和认知过程" (hé rèn zhì guò xìng)* "we provide probabilistic descriptions of the architecture" is translated as "我们提供了概率描述这个architecture" (wǒmen tīng yǐjī le gè yī jī qì bèng mǐng)Note that the word "architecture" is not explicitly mentioned in the original text, but it is implied by the context. In Chinese, the word for "architecture" is 架构 (gā kū), but it is not necessary to use it in this sentence.
</details></li>
</ul>
<hr>
<h2 id="Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness"><a href="#Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness" class="headerlink" title="Consciousness in Artificial Intelligence: Insights from the Science of Consciousness"></a>Consciousness in Artificial Intelligence: Insights from the Science of Consciousness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08708">http://arxiv.org/abs/2308.08708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, Liad Mudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, Rufin VanRullen</li>
<li>for: 本研究旨在探讨现有的人工智能系统是否具备意识性，并采用科学理论和实验来评估这些系统。</li>
<li>methods: 本研究使用了多种科学理论，包括反复处理理论、全局工作区理论、更高级别理论、预测处理和注意Schema理论，从这些理论中提取了”指示性特征”，用于评估人工智能系统是否拥有意识性。</li>
<li>results: 本研究发现现有的人工智能系统没有意识性，但也没有技术障碍建立意识性的AI系统。<details>
<summary>Abstract</summary>
Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.
</details>
<details>
<summary>摘要</summary>
当前或近期的人工智能系统是科学兴趣和公众关注的话题。这份报告提出和证明了一种严谨和基于实证的人工智能意识方法：对现有的AI系统进行详细的评估，以及根据我们最好支持的神经科学理论来评估意识。我们对多种知名的科学理论进行了检查，包括循环处理理论、全球工作空间理论、更高级理论、预测处理和注意schema理论。从这些理论中，我们 derivated "指标属性" （indicator properties），这些属性可以用计算机语言来评估 AI 系统。我们使用这些指标属性来评估一些最近的 AI 系统，并讨论了未来系统如何实现这些属性。我们的分析表明，目前没有任何 AI 系统具备意识，但也没有明显的技术障碍来建立具备这些指标属性的 AI 系统。
</details></li>
</ul>
<hr>
<h2 id="Improving-Anomaly-Segmentation-with-Multi-Granularity-Cross-Domain-Alignment"><a href="#Improving-Anomaly-Segmentation-with-Multi-Granularity-Cross-Domain-Alignment" class="headerlink" title="Improving Anomaly Segmentation with Multi-Granularity Cross-Domain Alignment"></a>Improving Anomaly Segmentation with Multi-Granularity Cross-Domain Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08696">http://arxiv.org/abs/2308.08696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Zhang, Xiao Wu, Zhi-Qi Cheng, Qi He, Wei Li</li>
<li>for: 这个论文的目的是提出一个基于多 Granularity Cross-Domain Alignment (MGCDA) 框架的 anomaly segmentation 方法，以便在自驾车中探测道路上的异常现象。</li>
<li>methods: 这个方法使用了一个新的 Multi-source Domain Adversarial Training (MDAT) 模组和一种 Cross-domain Anomaly-aware Contrastive Learning (CACL) 方法，将模型的通用性提高到了最高水平。这两种方法都是为了处理多个领域资料的问题，并且能够实现模型在测试阶段 Parameters-free。</li>
<li>results: 实验结果显示，提出的方法在 Fishyscapes 和 RoadAnomaly 资料集上取得了现有方法的最佳性能。<details>
<summary>Abstract</summary>
Anomaly segmentation plays a crucial role in identifying anomalous objects within images, which facilitates the detection of road anomalies for autonomous driving. Although existing methods have shown impressive results in anomaly segmentation using synthetic training data, the domain discrepancies between synthetic training data and real test data are often neglected. To address this issue, the Multi-Granularity Cross-Domain Alignment (MGCDA) framework is proposed for anomaly segmentation in complex driving environments. It uniquely combines a new Multi-source Domain Adversarial Training (MDAT) module and a novel Cross-domain Anomaly-aware Contrastive Learning (CACL) method to boost the generality of the model, seamlessly integrating multi-domain data at both scene and sample levels. Multi-source domain adversarial loss and a dynamic label smoothing strategy are integrated into the MDAT module to facilitate the acquisition of domain-invariant features at the scene level, through adversarial training across multiple stages. CACL aligns sample-level representations with contrastive loss on cross-domain data, which utilizes an anomaly-aware sampling strategy to efficiently sample hard samples and anchors. The proposed framework has decent properties of parameter-free during the inference stage and is compatible with other anomaly segmentation networks. Experimental conducted on Fishyscapes and RoadAnomaly datasets demonstrate that the proposed framework achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
《多源频率域对接框架》（MGCDA）是一种用于异常分割的新框架，旨在 Addressing the issue of domain discrepancies in anomaly segmentation using synthetic training data. The MGCDA framework combines a novel Multi-source Domain Adversarial Training (MDAT) module and a Cross-domain Anomaly-aware Contrastive Learning (CACL) method to improve the generality of the model. The MDAT module uses a multi-source domain adversarial loss and a dynamic label smoothing strategy to acquire domain-invariant features at the scene level through adversarial training across multiple stages. The CACL method aligns sample-level representations with contrastive loss on cross-domain data, using an anomaly-aware sampling strategy to efficiently sample hard samples and anchors. The proposed framework has the advantage of being parameter-free during the inference stage and is compatible with other anomaly segmentation networks. Experimental results on the Fishyscapes and RoadAnomaly datasets demonstrate that the proposed framework achieves state-of-the-art performance.Here's the translation of the text into Traditional Chinese:《多源频率域对接框架》（MGCDA）是一种新的框架，旨在 Addressing the issue of domain discrepancies in anomaly segmentation using synthetic training data. MGCDA 框架 combine 一个新的 Multi-source Domain Adversarial Training (MDAT) 模组和一个 Cross-domain Anomaly-aware Contrastive Learning (CACL) 方法，以提高模型的通用性。 MDAT 模组使用多源频率域 adversarial loss 和动态标签平滑策略来获得频率域对应的特征，通过多阶段的对抗训练。 CACL 方法使用异常感知抽象来对两个不同频率域的标签进行对应，并使用异常感知抽象来优化标签的映射。提议的框架具有在推断阶段不需要参数的优点，并且可以与其他异常分割网络相容。实验结果显示，提议的框架在 Fishyscapes 和 RoadAnomaly  datasets 上 achieve  state-of-the-art 性能。
</details></li>
</ul>
<hr>
<h2 id="Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces"><a href="#Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces" class="headerlink" title="Planning in the imagination: High-level planning on learned abstract search spaces"></a>Planning in the imagination: High-level planning on learned abstract search spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08693">http://arxiv.org/abs/2308.08693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Martin, Tuomas Sandholm</li>
<li>for: 提供了一种新的方法，叫做PiZero，允许智能机器人在自己创建的抽象搜索空间中进行规划，完全与实际环境分离。</li>
<li>methods: 与先前的方法不同，PiZero 允许智能机器人在任意时间尺度上进行高级规划，并且可以处理连续动作空间和部分可见性。</li>
<li>results: 在多个领域中进行实验，PiZero 比先前的方法更高效，无需访问环境模拟器。<details>
<summary>Abstract</summary>
We propose a new method, called PiZero, that gives an agent the ability to plan in an abstract search space of its own creation that is completely decoupled from the real environment. Unlike prior approaches, this enables the agent to perform high-level planning at arbitrary timescales and reason in terms of compound or temporally-extended actions, which can be useful in environments where large numbers of base-level micro-actions are needed to perform relevant macro-actions. In addition, our method is more general than comparable prior methods because it handles settings with continuous action spaces and partial observability. We evaluate our method on multiple domains, including navigation tasks and Sokoban. Experimentally, it outperforms comparable prior methods without assuming access to an environment simulator.
</details>
<details>
<summary>摘要</summary>
我们提出一种新方法，叫做PiZero，允许智能机器人在自己创建的抽象搜索空间中进行规划。与先前的方法不同的是，这使得智能机器人可以在任意时间尺度上进行高级规划，并可以使用复合或时间扩展的动作来执行重要的宏动作。此外，我们的方法更加通用于具有连续动作空间和部分可见性的场景。我们在多个领域进行了实验，包括导航任务和Sokoban，并证明了PiZero在不假设环境模拟器的情况下表现更好。
</details></li>
</ul>
<hr>
<h2 id="Lightweight-Adaptation-of-Neural-Language-Models-via-Subspace-Embedding"><a href="#Lightweight-Adaptation-of-Neural-Language-Models-via-Subspace-Embedding" class="headerlink" title="Lightweight Adaptation of Neural Language Models via Subspace Embedding"></a>Lightweight Adaptation of Neural Language Models via Subspace Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08688">http://arxiv.org/abs/2308.08688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amitkumarj441/cikm2023_subspaceembedding">https://github.com/amitkumarj441/cikm2023_subspaceembedding</a></li>
<li>paper_authors: Amit Kumar Jaiswal, Haiming Liu</li>
<li>for: 这个论文的目的是提出一种新的嵌入结构，以减少预训练语言模型的存储占用空间，同时保持模型的精度。</li>
<li>methods: 该论文使用一种基于语言模型的嵌入结构，通过对 tokens 的上下文关系进行赋值，实现嵌入结构的压缩。</li>
<li>results: 实验结果显示，使用该嵌入结构可以将预训练语言模型的嵌入矩阵压缩至99.8%以上，而且保持模型的精度。<details>
<summary>Abstract</summary>
Traditional neural word embeddings are usually dependent on a richer diversity of vocabulary. However, the language models recline to cover major vocabularies via the word embedding parameters, in particular, for multilingual language models that generally cover a significant part of their overall learning parameters. In this work, we present a new compact embedding structure to reduce the memory footprint of the pre-trained language models with a sacrifice of up to 4% absolute accuracy. The embeddings vectors reconstruction follows a set of subspace embeddings and an assignment procedure via the contextual relationship among tokens from pre-trained language models. The subspace embedding structure calibrates to masked language models, to evaluate our compact embedding structure on similarity and textual entailment tasks, sentence and paraphrase tasks. Our experimental evaluation shows that the subspace embeddings achieve compression rates beyond 99.8% in comparison with the original embeddings for the language models on XNLI and GLUE benchmark suites.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Quantifying-Overfitting-Introducing-the-Overfitting-Index"><a href="#Quantifying-Overfitting-Introducing-the-Overfitting-Index" class="headerlink" title="Quantifying Overfitting: Introducing the Overfitting Index"></a>Quantifying Overfitting: Introducing the Overfitting Index</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08682">http://arxiv.org/abs/2308.08682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass</li>
<li>for: 本研究旨在提供一个量化评估模型过拟合情况的指标，以便提高模型在实际应用中的效能。</li>
<li>methods: 本研究使用了多种模型架构，包括 MobileNet、U-Net、ResNet、Darknet 和 ViT-32，进行实验，并使用了数据增强技术来确认模型的过拟合情况。</li>
<li>results: 研究结果显示，不同的模型架构在不同的数据集上 exhibits 不同的过拟合情况，而数据增强技术对于小型和特殊的数据集有更大的稳定化效果。 ViT-32 模型在 MNIST 数据集上的表现也显示了某些模型在实际应用中的强健性和数据集的完整性。<details>
<summary>Abstract</summary>
In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising avenue to advance model optimization and ensure real-world efficacy.
</details>
<details>
<summary>摘要</summary>
在机器学习领域的快速演化中，保证模型通用性仍然是一个核心挑战。过拟合，其表现出模型在训练数据上出色，但是在未经见数据上崩溃的问题，是一个常见的问题。本文介绍了一个新的度量工具——过拟合指数（OI），用于量化评估模型是否过拟合。通过对Breast Ultrasound Images Dataset（BUS）和MNIST datasets上的MobileNet、U-Net、ResNet、Darknet和ViT-32等建筑物的广泛实验，我们证明了OI的实用性和分辨率。我们的结果表明不同的建筑物在不同的数据集上具有不同的过拟合行为，并且数据增强特别是在小型和特殊化数据集上具有缓解作用。ViT-32在MNIST上的表现也证明了某些模型的稳定性和数据集的全面性。通过提供一个对过拟合进行Objective评估的工具，OI为模型优化和实际效果的提高提供了一个可靠的途径。
</details></li>
</ul>
<hr>
<h2 id="Answering-Ambiguous-Questions-with-a-Database-of-Questions-Answers-and-Revisions"><a href="#Answering-Ambiguous-Questions-with-a-Database-of-Questions-Answers-and-Revisions" class="headerlink" title="Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions"></a>Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08661">http://arxiv.org/abs/2308.08661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitian Sun, William W. Cohen, Ruslan Salakhutdinov</li>
<li>for:  answering ambiguous questions</li>
<li>methods: exploiting a database of unambiguous questions generated from Wikipedia</li>
<li>results: improved performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs, as well as large improvements in diverse passage retrieval.Here’s the same information in Simplified Chinese:</li>
<li>for: 回答不确定的问题</li>
<li>methods: 利用wikipedia中生成的明确问题数据库</li>
<li>results: 提高了15%的准确率和10%的解释问题率，以及大幅提高多个段落检索率。<details>
<summary>Abstract</summary>
Many open-domain questions are under-specified and thus have multiple possible answers, each of which is correct under a different interpretation of the question. Answering such ambiguous questions is challenging, as it requires retrieving and then reasoning about diverse information from multiple passages. We present a new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia. On the challenging ASQA benchmark, which requires generating long-form answers that summarize the multiple answers to an ambiguous question, our method improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs. Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).
</details>
<details>
<summary>摘要</summary>
多个开放问题是下pecified，因此它们有多个可能的答案，每个答案都是正确的，只要是不同的问题解释。回答这些抽象问题是困难的，因为它们需要检索并then reasoning about多个信息的多个段落。我们提出了一种新的状态 Arts，用于回答抽象问题，该方法利用了基于Wikipedia的问题库。在ASQA Benchmark上，这个Benchmark需要生成长形答案，这些答案需要总结多个答案到一个抽象问题上，我们的方法在这些衡量中提高了15%的Relative Improvement（相对提高）和10%的衡量（evaluation measures）。在检索过程中，从生成的问题库中提取信息也得到了大幅度的提高（by matching user questions q to passages p indirectly, via questions q' generated from p）。
</details></li>
</ul>
<hr>
<h2 id="Towards-Zero-Memory-Footprint-Spiking-Neural-Network-Training"><a href="#Towards-Zero-Memory-Footprint-Spiking-Neural-Network-Training" class="headerlink" title="Towards Zero Memory Footprint Spiking Neural Network Training"></a>Towards Zero Memory Footprint Spiking Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08649">http://arxiv.org/abs/2308.08649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lei, Sheng Lin, Pei-Hung Lin, Chunhua Liao, Caiwen Ding</li>
<li>for: 这 paper 的目的是解决 SNN 训练中的内存约束问题。</li>
<li>methods: 这 paper 使用了一种新的架构和一种新的算法来降低 SNN 训练中的内存使用量。</li>
<li>results: 这 paper 的实验结果表明，使用这种新的架构和算法可以减少 SNN 训练中的内存使用量，同时不会增加训练时间。具体来说，可以达到 $\mathbf{58.65\times}$ 的内存减少和 $\mathbf{23.8%}$ 的训练时间减少。<details>
<summary>Abstract</summary>
Biologically-inspired Spiking Neural Networks (SNNs), processing information using discrete-time events known as spikes rather than continuous values, have garnered significant attention due to their hardware-friendly and energy-efficient characteristics. However, the training of SNNs necessitates a considerably large memory footprint, given the additional storage requirements for spikes or events, leading to a complex structure and dynamic setup. In this paper, to address memory constraint in SNN training, we introduce an innovative framework, characterized by a remarkably low memory footprint. We \textbf{(i)} design a reversible SNN node that retains a high level of accuracy. Our design is able to achieve a $\mathbf{58.65\times}$ reduction in memory usage compared to the current SNN node. We \textbf{(ii)} propose a unique algorithm to streamline the backpropagation process of our reversible SNN node. This significantly trims the backward Floating Point Operations Per Second (FLOPs), thereby accelerating the training process in comparison to current reversible layer backpropagation method. By using our algorithm, the training time is able to be curtailed by $\mathbf{23.8\%}$ relative to existing reversible layer architectures.
</details>
<details>
<summary>摘要</summary>
生物学发明的刺激神经网络（SNN），通过使用不同时间点事件而不是连续值来处理信息，已经吸引了广泛关注，因为它们具有硬件友好和能效的特点。然而，SNN的训练需要较大的内存占用量，因为需要额外存储刺激或事件，从而导致复杂的结构和动态设置。在这篇论文中，我们提出了一种创新的框架，以减少SNN训练中的内存占用量。我们的设计包括：（i）设计一种可逆的SNN节点，保持高度准确性。我们的设计可以实现$\mathbf{58.65\times}$的内存占用量减少相比现有的SNN节点。（ii）我们提出了一种特殊的算法，用于简化我们的可逆层反propagation过程。这种算法可以大幅减少反向浮点运算数（FLOPs），从而加快训练过程的速度，相比现有的可逆层反propagation方法。通过使用我们的算法，训练时间可以被减少$\mathbf{23.8\%}$相比现有的可逆层架构。
</details></li>
</ul>
<hr>
<h2 id="FedPop-Federated-Population-based-Hyperparameter-Tuning"><a href="#FedPop-Federated-Population-based-Hyperparameter-Tuning" class="headerlink" title="FedPop: Federated Population-based Hyperparameter Tuning"></a>FedPop: Federated Population-based Hyperparameter Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08634">http://arxiv.org/abs/2308.08634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 本研究旨在提高 Federated Learning (FL) 中 hyperparameter (HP) 的优化，以提高 FL 的性能和可扩展性。</li>
<li>methods: 本研究提出了一种新的 HP 优化算法，called Federated Population-based Hyperparameter Tuning (FedPop)，使用了人口生长算法来优化 HP，并且采用了在线 “调度-while-训练” 框架，以提高计算效率和探索 HP 搜索空间。</li>
<li>results: 对于常见的 FL  benchmark 和复杂的实际世界 FL 数据集，本研究的提出的方法在比较于现状最佳 HP 调度方法的实际 validate 中显著提高了 FL 的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning (ML) paradigm, in which multiple clients collaboratively train ML models without centralizing their local data. Similar to conventional ML pipelines, the client local optimization and server aggregation procedure in FL are sensitive to the hyperparameter (HP) selection. Despite extensive research on tuning HPs for centralized ML, these methods yield suboptimal results when employed in FL. This is mainly because their "training-after-tuning" framework is unsuitable for FL with limited client computation power. While some approaches have been proposed for HP-Tuning in FL, they are limited to the HPs for client local updates. In this work, we propose a novel HP-tuning algorithm, called Federated Population-based Hyperparameter Tuning (FedPop), to address this vital yet challenging problem. FedPop employs population-based evolutionary algorithms to optimize the HPs, which accommodates various HP types at both client and server sides. Compared with prior tuning methods, FedPop employs an online "tuning-while-training" framework, offering computational efficiency and enabling the exploration of a broader HP search space. Our empirical validation on the common FL benchmarks and complex real-world FL datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the concurrent state-of-the-art HP tuning methods for FL.
</details>
<details>
<summary>摘要</summary>
FedPop 使用人口生长算法来优化 HP，可以满足不同类型的 HP 在客户端和服务器两侧。与先前的调优方法相比，FedPop 采用了在线 "调优 while training" 框架，提供计算效率和探索更广泛的 HP 搜索空间。我们对常见的 FL benchmark 和复杂的实际 FL 数据进行了实验验证，得到了我们提出的方法的有效性，与当前状态的HP调优方法相比，它具有显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data"><a href="#LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data" class="headerlink" title="LSTM-Based Forecasting Model for GRACE Accelerometer Data"></a>LSTM-Based Forecasting Model for GRACE Accelerometer Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08621">http://arxiv.org/abs/2308.08621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers">https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers</a></li>
<li>paper_authors: Neda Darbeheshti, Elahe Moradi</li>
<li>for: The paper is written for monitoring variations in Earth’s gravity field and filling data gaps using the GRACE and GRACE Follow-On satellite missions.</li>
<li>methods: The paper uses Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.</li>
<li>results: The model demonstrates effectiveness in filling gaps and forecasting GRACE accelerometer data, with accurate predictions for the three axes.<details>
<summary>Abstract</summary>
The Gravity Recovery and Climate Experiment (GRACE) satellite mission, spanning from 2002 to 2017, has provided a valuable dataset for monitoring variations in Earth's gravity field, enabling diverse applications in geophysics and hydrology. The mission was followed by GRACE Follow-On in 2018, continuing data collection efforts. The monthly Earth gravity field, derived from the integration different instruments onboard satellites, has shown inconsistencies due to various factors, including gaps in observations for certain instruments since the beginning of the GRACE mission.   With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details>
<details>
<summary>摘要</summary>
grace卫星任务（GRACE），从2002年到2017年，提供了对地球重力场变化的监测数据，用于多种地球物理和水文应用。这个任务被GRACE Follow-On在2018年继承，继续进行数据采集。月度地球重力场，由不同卫星上的 instrumenteintegrate 而来，存在各种因素的影响，包括GRACE任务开始时的观测 gap。  now, with over two decades of GRACE and GRACE Follow-On data available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.  在这个研究中，我们描述了对加速计数据进行预处理、准备 для LSTM 训练，以及模型性能的评估。通过实验和验证，我们评估了模型的准确性和其能够预测加速计数据的三个轴。我们的结果表明LSTM预测模型能够有效地填充数据 gap并预测GRACE加速计数据。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought"><a href="#Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought" class="headerlink" title="Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought"></a>Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08614">http://arxiv.org/abs/2308.08614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lei, pei-Hung Lin, Chunhua Liao, Caiwen Ding</li>
<li>for: 提高大规模模型对复杂问题的逻辑推理能力</li>
<li>methods: 提出Graph of Thoughts（GoT）引导技术</li>
<li>results: 比GPT-4高$89.7%$, $86%$,和$56%$，与SOTA方法ToT average上升$23%$, $24%$,和$15%$<details>
<summary>Abstract</summary>
Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.
</details>
<details>
<summary>摘要</summary>
（Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.）
</details></li>
</ul>
<hr>
<h2 id="Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach"><a href="#Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach" class="headerlink" title="Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach"></a>Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08611">http://arxiv.org/abs/2308.08611</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Wahid, I faiud, K. Mason</li>
<li>for: 这种研究旨在优化农业部门中 photovoltaic (PV) 系统的决策，帮助农业投资者做出了有数据支持的决策。</li>
<li>methods: 该研究使用深度Q学习网络 (DQN) 来优化决策，通过设置奖励机制，使DQN学习据材料驱动的决策。</li>
<li>results: 研究提供了一个全面的理解，如何使用DQN来支持农业投资者做出有利可图的PV安装决策，这些决策可以提高能源效率，降低环境影响，提高利润性。<details>
<summary>Abstract</summary>
This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FootGPT-A-Large-Language-Model-Development-Experiment-on-a-Minimal-Setting"><a href="#FootGPT-A-Large-Language-Model-Development-Experiment-on-a-Minimal-Setting" class="headerlink" title="FootGPT : A Large Language Model Development Experiment on a Minimal Setting"></a>FootGPT : A Large Language Model Development Experiment on a Minimal Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08610">http://arxiv.org/abs/2308.08610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eren Unlu</li>
<li>for: 本研究的目的是开发一个特定用途的语言模型，用于解释足球数据，并且在有限的资源下进行。</li>
<li>methods: 本研究使用了一个已经训练过的一百亿参数大小的通用 causal 语言模型，并在Italian足球联赛第一十周的比赛数据上进行了微调。使用了低级别适应。</li>
<li>results: 本研究发现，使用有限的资源和短时间训练，可以开发出一个高度精准的语言模型，用于解释足球数据。<details>
<summary>Abstract</summary>
With recent empirical observations, it has been argued that the most significant aspect of developing accurate language models may be the proper dataset content and training strategy compared to the number of neural parameters, training duration or dataset size. Following this argument, we opted to fine tune a one billion parameter size trained general purpose causal language model with a dataset curated on team statistics of the Italian football league first ten game weeks, using low rank adaptation. The limited training dataset was compiled based on a framework where a powerful commercial large language model provides distilled paragraphs and question answer pairs as intended. The training duration was kept relatively short to provide a basis for our minimal setting exploration. We share our key observations on the process related to developing a specific purpose language model which is intended to interpret soccer data with constrained resources in this article.
</details>
<details>
<summary>摘要</summary>
据最新的观察，人们认为在建立准确语言模型方面，最重要的因素是数据集内容和训练策略，而不是神经网络参数数量、训练时间或数据集大小。基于这个Arguments，我们决定使用一个已经训练过的一亿参数大小的通用 causal语言模型，并在意大利足球联赛第一个十周的比赛数据上进行微调。我们采用了低级别适应。由于我们的训练集较小，因此我们保留了较短的训练时间，以便在有限的资源下进行exploration。在这篇文章中，我们将分享我们在开发特定目标语言模型方面的关键观察。这种语言模型的目的是解释足球数据，并且在有限的资源下进行。
</details></li>
</ul>
<hr>
<h2 id="TeCH-Text-guided-Reconstruction-of-Lifelike-Clothed-Humans"><a href="#TeCH-Text-guided-Reconstruction-of-Lifelike-Clothed-Humans" class="headerlink" title="TeCH: Text-guided Reconstruction of Lifelike Clothed Humans"></a>TeCH: Text-guided Reconstruction of Lifelike Clothed Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08545">http://arxiv.org/abs/2308.08545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huangyangyi/tech">https://github.com/huangyangyi/tech</a></li>
<li>paper_authors: Yangyi Huang, Hongwei Yi, Yuliang Xiu, Tingting Liao, Jiaxiang Tang, Deng Cai, Justus Thies</li>
<li>for: 本研究旨在解决单张图像中重构人体的“未seen region”问题，即 accurately restoring高级详细信息。</li>
<li>methods: 本研究使用了基于文本描述（如衣服、颜色、发型）的自动生成的garment parsing模型和视觉问答（VQA）模型，以及个性化文本到图像扩散（T2I）模型。</li>
<li>results: 本研究提出了一种基于DMTet的混合3D表示方法，通过多视点Score Distillation Sampling（SDS）和重构损失来优化geometry和texture。实验结果表明，TeCH可以生成高精度的3D人体图像，具有一致和细腻的текстура，以及详细的全身几何结构。<details>
<summary>Abstract</summary>
Despite recent research advancements in reconstructing clothed humans from a single image, accurately restoring the "unseen regions" with high-level details remains an unsolved challenge that lacks attention. Existing methods often generate overly smooth back-side surfaces with a blurry texture. But how to effectively capture all visual attributes of an individual from a single image, which are sufficient to reconstruct unseen areas (e.g., the back view)? Motivated by the power of foundation models, TeCH reconstructs the 3D human by leveraging 1) descriptive text prompts (e.g., garments, colors, hairstyles) which are automatically generated via a garment parsing model and Visual Question Answering (VQA), 2) a personalized fine-tuned Text-to-Image diffusion model (T2I) which learns the "indescribable" appearance. To represent high-resolution 3D clothed humans at an affordable cost, we propose a hybrid 3D representation based on DMTet, which consists of an explicit body shape grid and an implicit distance field. Guided by the descriptive prompts + personalized T2I diffusion model, the geometry and texture of the 3D humans are optimized through multi-view Score Distillation Sampling (SDS) and reconstruction losses based on the original observation. TeCH produces high-fidelity 3D clothed humans with consistent & delicate texture, and detailed full-body geometry. Quantitative and qualitative experiments demonstrate that TeCH outperforms the state-of-the-art methods in terms of reconstruction accuracy and rendering quality. The code will be publicly available for research purposes at https://huangyangyi.github.io/TeCH
</details>
<details>
<summary>摘要</summary>
尽管最近的研究进步在单个图像中重建人体已经做出了 significativo 的进展，但还没有解决高级特征的重建问题。现有的方法通常会生成高级特征表面上的柔和粗糙 текстур。问题是如何有效地从单个图像中捕捉个体的所有视觉特征，以便重建未看到的区域（例如背部）？基于基础模型的TeCH重构3D人体，通过1）由garment parsing模型自动生成的描述文本提示（例如服装、颜色、头发样式），2）个性化进行文本到图像扩散（T2I）模型，学习“不可述的”外观。为了在可持置价格下提供高分辨率3D人体图像，我们提议一种混合3D表示方式，基于DMTet，包括显式体形网格和隐式距离场。通过描述提示+个性化T2I扩散模型，3D人体的几何和текстура在多视图Score Distillation Sampling（SDS）和重建损失基于原始观察得到优化。TeCH生成高准确率、细腻的текстура和详细的全身几何，在量化和质量上都超过了当前状况。代码将在https://huangyangyi.github.io/TeCH 公开 для研究用途。
</details></li>
</ul>
<hr>
<h2 id="Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems"><a href="#Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems" class="headerlink" title="Can Transformers Learn Optimal Filtering for Unknown Systems?"></a>Can Transformers Learn Optimal Filtering for Unknown Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08536">http://arxiv.org/abs/2308.08536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haldun Balim, Zhe Du, Samet Oymak, Necmiye Ozay</li>
<li>for: 这个论文的目的是使用变换器来解决动力系统中的输出估计问题。</li>
<li>methods: 这篇论文使用了变换器来生成输出预测，并通过训练变换器使其能够适应不同的系统。</li>
<li>results: 这篇论文的结果显示，使用变换器来解决动力系统中的输出估计问题可以匹配最佳输出估计器的性能，并且在具有非相关噪声、时间变化动力和非线性动力等挑战性enario下也能够表现良好。<details>
<summary>Abstract</summary>
Transformers have demonstrated remarkable success in natural language processing; however, their potential remains mostly unexplored for problems arising in dynamical systems. In this work, we investigate the optimal output estimation problem using transformers, which generate output predictions using all the past ones. We train the transformer using various systems drawn from a prior distribution and then evaluate its performance on previously unseen systems from the same distribution. As a result, the obtained transformer acts like a prediction algorithm that learns in-context and quickly adapts to and predicts well for different systems - thus we call it meta-output-predictor (MOP). MOP matches the performance of the optimal output estimator, based on Kalman filter, for most linear dynamical systems even though it does not have access to a model. We observe via extensive numerical experiments that MOP also performs well in challenging scenarios with non-i.i.d. noise, time-varying dynamics, and nonlinear dynamics like a quadrotor system with unknown parameters. To further support this observation, in the second part of the paper, we provide statistical guarantees on the performance of MOP and quantify the required amount of training to achieve a desired excess risk during test-time. Finally, we point out some limitations of MOP by identifying two classes of problems MOP fails to perform well, highlighting the need for caution when using transformers for control and estimation.
</details>
<details>
<summary>摘要</summary>
孔雀Transformers在自然语言处理方面已经展现出惊人的成功，但它们在动力系统中的潜力还未得到了充分的发掘。在这项工作中，我们使用transformer来解决输出预测问题，它可以使用所有过去的输出来生成输出预测。我们使用不同的系统从先前分布中随机抽取training dataset，然后评估其性能在未看过的系统上。因此，我们得到的transformer behave like a prediction algorithm that learns in-context and quickly adapts to different systems, so we call it meta-output-predictor (MOP). MOP的性能与基于Kalman滤波的优化输出估计器相当，即使它没有访问模型。我们通过广泛的数值实验发现，MOP在非相关噪声、时间变化动力学和非线性动力学中也表现出色，如四旋翼系统with unknown parameters。在第二部分的文章中，我们为MOP的性能提供了统计保证和测试时间所需的培训量。最后，我们指出了MOP在某些情况下的局限性，例如在某些非线性和不确定性下的性能不佳，这引起了使用 transformers 进行控制和估计时的谨慎。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Point-Wise-Attention-in-6D-Object-Pose-Estimation-Based-on-Bidirectional-Prediction"><a href="#Exploiting-Point-Wise-Attention-in-6D-Object-Pose-Estimation-Based-on-Bidirectional-Prediction" class="headerlink" title="Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction"></a>Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08518">http://arxiv.org/abs/2308.08518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Yang, Jun Wu, Guangjian Zhang, Rong Xiong</li>
<li>for: 提高3D物体重建的精度和稳定性，特别是在受到 occlusion 的环境下。</li>
<li>methods: 提出了一种 bidirectional correspondence prediction network，利用点对点的注意力感知机制，同时考虑模型和Scene之间的几何相似性。</li>
<li>results: 对于 LineMOD、YCB-Video 和 Occ-LineMOD 等公共数据集进行了实验，并与其他状态数据方法进行了比较，研究发现提出的方法在同一种评价标准下表现更好，特别是在受到 occlusion 的环境下。<details>
<summary>Abstract</summary>
Traditional geometric registration based estimation methods only exploit the CAD model implicitly, which leads to their dependence on observation quality and deficiency to occlusion. To address the problem,the paper proposes a bidirectional correspondence prediction network with a point-wise attention-aware mechanism. This network not only requires the model points to predict the correspondence but also explicitly models the geometric similarities between observations and the model prior. Our key insight is that the correlations between each model point and scene point provide essential information for learning point-pair matches. To further tackle the correlation noises brought by feature distribution divergence, we design a simple but effective pseudo-siamese network to improve feature homogeneity. Experimental results on the public datasets of LineMOD, YCB-Video, and Occ-LineMOD show that the proposed method achieves better performance than other state-of-the-art methods under the same evaluation criteria. Its robustness in estimating poses is greatly improved, especially in an environment with severe occlusions.
</details>
<details>
<summary>摘要</summary>
传统的几何注册基于估计方法只是通过隐式地利用CAD模型，这导致其виси于观察质量和遮挡的不足。为解决问题，文章提出了一种bidirectional匹配预测网络，该网络不仅需要模型点预测匹配，还Explicitly模型了观察和模型之间的几何相似性。我们关键的发现是每个模型点和场景点之间的相关性提供了重要的学习点对匹配信息。为了进一步处理特征分布的分散，我们设计了一个简单 yet有效的 Pseudo-Siamese 网络，以提高特征同化。实验结果表明，提议的方法在公共数据集LineMOD、YCB-Video和Occ-LineMOD上比其他状态的艺术方法得到更好的性能，特别是在具有严重遮挡的环境中。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.AI_2023_08_17/" data-id="clorjzl1t002jf1883n2bcj46" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.CL_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T11:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.CL_2023_08_17/">cs.CL - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Contrasting-Linguistic-Patterns-in-Human-and-LLM-Generated-Text"><a href="#Contrasting-Linguistic-Patterns-in-Human-and-LLM-Generated-Text" class="headerlink" title="Contrasting Linguistic Patterns in Human and LLM-Generated Text"></a>Contrasting Linguistic Patterns in Human and LLM-Generated Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09067">http://arxiv.org/abs/2308.09067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Muñoz-Ortiz, Carlos Gómez-Rodríguez, David Vilares</li>
<li>for: 对比人类编写的英语新闻文本和相似的大语言模型（LLM）输出。</li>
<li>methods: 使用多个 linguistic dimensions，包括 morphological, syntactic, psychometric和sociolinguistic aspects进行量化分析。</li>
<li>results: 结果显示人类文本和AI生成文本存在许多可观量的差异，如人类文本中句子长度分布较为散布、使用依赖和结构类型不同、 Constituents shorter、以及更多的情感表达（恐惧、厌恶）。LLM输出使用更多的数字、符号和助动词（表示 объекivity 语言），以及更多的代词。人类文本中的性别偏见也被LLM模型反映出来。<details>
<summary>Abstract</summary>
We conduct a quantitative analysis contrasting human-written English news text with comparable large language model (LLM) output from 4 LLMs from the LLaMa family. Our analysis spans several measurable linguistic dimensions, including morphological, syntactic, psychometric and sociolinguistic aspects. The results reveal various measurable differences between human and AI-generated texts. Among others, human texts exhibit more scattered sentence length distributions, a distinct use of dependency and constituent types, shorter constituents, and more aggressive emotions (fear, disgust) than LLM-generated texts. LLM outputs use more numbers, symbols and auxiliaries (suggesting objective language) than human texts, as well as more pronouns. The sexist bias prevalent in human text is also expressed by LLMs.
</details>
<details>
<summary>摘要</summary>
我们进行了量化分析，对人工写的英文新闻文本与相关的大语言模型（LLM）输出进行比较，从4个LLM家族中选择了输出。我们的分析覆盖了多个可衡量的语言方面，包括形态、 sintaxis、心理测试和社会语言方面。结果显示了人类和AI生成文本之间的各种可衡量差异。人类文本显示了更加散布的句子长度分布、更明确的依赖和结构类型使用、更短的成分和更强烈的情感（恐惧、厌恶）than LLM生成的文本。LLM输出使用了更多的数字、符号和助动词（表示Objective语言），以及更多的代名词。人类文本中的性别偏见也被LLM模型表达出来。
</details></li>
</ul>
<hr>
<h2 id="Don’t-lose-the-message-while-paraphrasing-A-study-on-content-preserving-style-transfer"><a href="#Don’t-lose-the-message-while-paraphrasing-A-study-on-content-preserving-style-transfer" class="headerlink" title="Don’t lose the message while paraphrasing: A study on content preserving style transfer"></a>Don’t lose the message while paraphrasing: A study on content preserving style transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09055">http://arxiv.org/abs/2308.09055</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/s-nlp/lewit-informal">https://github.com/s-nlp/lewit-informal</a></li>
<li>paper_authors: Nikolay Babakov, David Dale, Ilya Gusev, Irina Krotova, Alexander Panchenko</li>
<li>for: 本研究旨在提高自然语言处理中的文本风格转换技术，使得文本可以在需要的形式下进行转换，如从毒瘤到神经、从正式到便秘、从古老到现代英语等。</li>
<li>methods: 本研究使用了多种文本风格转换模型，并进行了对这些模型的比较，以确定哪些模型能够最好地保持原始内容的含义。</li>
<li>results: 研究发现，当转换文本时，保持原始内容的含义是非常重要，而现有的文本风格转换模型往往会产生不准确的结果。此外，研究还提出了一种修改了无监督的LEWIS方法，可以在提高文本风格转换的同时，保持原始内容的含义。<details>
<summary>Abstract</summary>
Text style transfer techniques are gaining popularity in natural language processing allowing paraphrasing text in the required form: from toxic to neural, from formal to informal, from old to the modern English language, etc. Solving the task is not sufficient to generate some neural/informal/modern text, but it is important to preserve the original content unchanged. This requirement becomes even more critical in some applications such as style transfer of goal-oriented dialogues where the factual information shall be kept to preserve the original message, e.g. ordering a certain type of pizza to a certain address at a certain time. The aspect of content preservation is critical for real-world applications of style transfer studies, but it has received little attention. To bridge this gap we perform a comparison of various style transfer models on the example of the formality transfer domain. To perform a study of the content preservation abilities of various style transfer methods we create a parallel dataset of formal vs. informal task-oriented dialogues. The key difference between our dataset and the existing ones like GYAFC [17] is the presence of goal-oriented dialogues with predefined semantic slots essential to be kept during paraphrasing, e.g. named entities. This additional annotation allowed us to conduct a precise comparative study of several state-of-the-art techniques for style transfer. Another result of our study is a modification of the unsupervised method LEWIS [19] which yields a substantial improvement over the original method and all evaluated baselines on the proposed task.
</details>
<details>
<summary>摘要</summary>
文本风格传输技术在自然语言处理领域升级，允许将文本从毒精到神经、从正式到便秘、从古老到现代英语等形式进行重写。解决这个任务不仅是生成一些神经/便秘/现代的文本，而且也需要保持原始内容不变。这种需求在某些应用程序中，如文本风格传输的对话目标中，变得非常重要。例如，在订购特定类型的比萨时，需要保持原始信息，如订购地址和时间。对于实际应用，保持内容的精度是关键。为了填补这一漏洞，我们进行了不同风格传输模型的比较，并创建了一个并行的正式 vs. 便秘任务型对话集。我们的数据集和现有的 datasets like GYAFC [17]  differ in that they contain goal-oriented dialogues with predefined semantic slots that must be preserved during paraphrasing, such as named entities。这些额外的注释使我们能够进行精确的比较研究多种现状风格传输技术。另外，我们还提出了一种基于不监督学习的方法 modification of LEWIS [19]，它在我们的任务上实现了显著提高，并在所有评估基准上表现出优于原始方法和评估基准。
</details></li>
</ul>
<hr>
<h2 id="Reinforced-Self-Training-ReST-for-Language-Modeling"><a href="#Reinforced-Self-Training-ReST-for-Language-Modeling" class="headerlink" title="Reinforced Self-Training (ReST) for Language Modeling"></a>Reinforced Self-Training (ReST) for Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08998">http://arxiv.org/abs/2308.08998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas</li>
<li>for: 提高大语言模型的输出质量</li>
<li>methods: 使用激励学习自动对人类反馈进行调整</li>
<li>results: 在计算和样本利用效率的情况下，可以substantially提高翻译质量，并且通过自动度量和人类评估在机器翻译benchmark上表现出色。<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
</details>
<details>
<summary>摘要</summary>
“强化学习从人类反馈（RLHF）可以提高大语言模型（LLM）的输出质量，将其与人类偏好Alignment。我们提出了一种简单的算法，名为强化自我培训（ReST），以实现这一目标。给定初始LLM策略，ReST会生成一个数据集，然后使用线下RL算法来改善LLM策略。与 Typical online RLHF方法不同的是，ReST在训练集生成过程中不需要在线学习，因此可以进行数据重用。虽然ReST是一种通用的激励学习方法，但我们在机器翻译任务中进行了研究，并显示了它可以在计算和样本效率的情况下提高翻译质量。”Note that Simplified Chinese is the official standard for Chinese writing in mainland China, and it is used in this translation. Traditional Chinese is used in Taiwan and other regions, and it may differ slightly from the Simplified Chinese used here.
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-really-good-grammatical-error-correction"><a href="#Evaluation-of-really-good-grammatical-error-correction" class="headerlink" title="Evaluation of really good grammatical error correction"></a>Evaluation of really good grammatical error correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08982">http://arxiv.org/abs/2308.08982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/robertostling/gec-evaluation">https://github.com/robertostling/gec-evaluation</a></li>
<li>paper_authors: Robert Östling, Katarina Gillholm, Murathan Kurfalı, Marie Mattson, Mats Wirén</li>
<li>for: 这个论文的目的是评估不同 grammatical error correction (GEC) 系统的表现，以及评估现有评价方法的有效性。</li>
<li>methods: 这个论文使用了一些已知的评价方法，以及一些新的评价方法，例如使用人工评估和大语言模型 (LLM)。</li>
<li>results: 研究发现，使用 GPT-3 在几个步骤中的情况下，可以明显超越之前的 grammatical error correction 系统，并且可以在 Swedish 语言中减少了训练数据的语言差异。此外，研究还发现了现有的评价方法存在偏见，而人工评估则能够更好地揭示这些偏见。<details>
<summary>Abstract</summary>
Although rarely stated, in practice, Grammatical Error Correction (GEC) encompasses various models with distinct objectives, ranging from grammatical error detection to improving fluency. Traditional evaluation methods fail to fully capture the full range of system capabilities and objectives. Reference-based evaluations suffer from limitations in capturing the wide variety of possible correction and the biases introduced during reference creation and is prone to favor fixing local errors over overall text improvement. The emergence of large language models (LLMs) has further highlighted the shortcomings of these evaluation strategies, emphasizing the need for a paradigm shift in evaluation methodology. In the current study, we perform a comprehensive evaluation of various GEC systems using a recently published dataset of Swedish learner texts. The evaluation is performed using established evaluation metrics as well as human judges. We find that GPT-3 in a few-shot setting by far outperforms previous grammatical error correction systems for Swedish, a language comprising only 0.11% of its training data. We also found that current evaluation methods contain undesirable biases that a human evaluation is able to reveal. We suggest using human post-editing of GEC system outputs to analyze the amount of change required to reach native-level human performance on the task, and provide a dataset annotated with human post-edits and assessments of grammaticality, fluency and meaning preservation of GEC system outputs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beam-Retrieval-General-End-to-End-Retrieval-for-Multi-Hop-Question-Answering"><a href="#Beam-Retrieval-General-End-to-End-Retrieval-for-Multi-Hop-Question-Answering" class="headerlink" title="Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering"></a>Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08973">http://arxiv.org/abs/2308.08973</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/canghongjian/beam_retriever">https://github.com/canghongjian/beam_retriever</a></li>
<li>paper_authors: Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, Shen Huang</li>
<li>for: 这个论文旨在提出一种扩展多步问答（Multi-hop QA）的搜索框架，以解决复杂问题时存在多个相关段落的选择和逻辑推理问题。</li>
<li>methods: 该方法称为Beam Retrieval，它是一种通用的终端搜索框架，可以维护多个部分假设的相关段落，从而扩大搜索空间并减少 irrelevant passage 的选择风险。此外，Beam Retrieval 将编码器和两个分类头并行优化，通过将所有跳数的损失函数进行共同最小化。</li>
<li>results: 实验结果表明，Beam Retrieval 与基eline比较，在复杂的 MuSiQue-Ans 上提高了nearly 50%的性能，并且在 HotpotQA 和 2WikiMultiHopQA 上也超过了所有之前的搜索器。此外，通过提供高质量的上下文，Beam Retrieval 帮助我们的supervised reader 实现了新的州队性能记录，并在零学习 GPT-3.5 上进行了重要提升（最高提升28.8点）。<details>
<summary>Abstract</summary>
Multi-hop QA involves finding multiple relevant passages and step-by-step reasoning to answer complex questions. While previous approaches have developed retrieval modules for selecting relevant passages, they face challenges in scenarios beyond two hops, owing to the limited performance of one-step methods and the failure of two-step methods when selecting irrelevant passages in earlier stages. In this work, we introduce Beam Retrieval, a general end-to-end retrieval framework for multi-hop QA. This approach maintains multiple partial hypotheses of relevant passages at each step, expanding the search space and reducing the risk of missing relevant passages. Moreover, Beam Retrieval jointly optimizes an encoder and two classification heads by minimizing the combined loss across all hops. To establish a complete QA system, we incorporate a supervised reader or a zero-shot GPT-3.5. Experimental results demonstrate that Beam Retrieval achieves a nearly 50% improvement compared with baselines on challenging MuSiQue-Ans, and it also surpasses all previous retrievers on HotpotQA and 2WikiMultiHopQA. Providing high-quality context, Beam Retrieval helps our supervised reader achieve new state-of-the-art performance and substantially improves (up to 28.8 points) the QA performance of zero-shot GPT-3.5.
</details>
<details>
<summary>摘要</summary>
多跳问答涉及到找到多个相关段落并进行步骤 reasoning 来回答复杂问题。而前一些方法已经开发了检索模块，但在超过两步 scenarios 中表现不佳，因为一步方法的表现有限，而两步方法在选择无关段落的早期阶段会失败。在这项工作中，我们介绍了 Beam Retrieval，一种通用的检索框架 для多跳问答。这种方法在每个步骤中维护多个部分假设的相关段落，扩大搜索空间，降低缺失相关段落的风险。此外，Beam Retrieval 同时优化一个encoder和两个分类头，通过在所有跳数中共同最小化损失来jointly 优化。为建立完整的问答系统，我们将 incorporate 一个监督式读者或一个零容量 GPT-3.5。实验结果表明，Beam Retrieval 相比基eline 提高了约50%的表现，并且在 HotpotQA 和 2WikiMultiHopQA 等检索器中也超越了所有前一些 Retriever。通过提供高质量的 контекст，Beam Retrieval 帮助我们的监督式读者达到新的状态平台纪录，并在零容量 GPT-3.5 中提高了问答性能（最多28.8个点）。
</details></li>
</ul>
<hr>
<h2 id="Factuality-Detection-using-Machine-Translation-–-a-Use-Case-for-German-Clinical-Text"><a href="#Factuality-Detection-using-Machine-Translation-–-a-Use-Case-for-German-Clinical-Text" class="headerlink" title="Factuality Detection using Machine Translation – a Use Case for German Clinical Text"></a>Factuality Detection using Machine Translation – a Use Case for German Clinical Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08827">http://arxiv.org/abs/2308.08827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Bin Sumait, Aleksandra Gabryszak, Leonhard Hennig, Roland Roller</li>
<li>for: 这种研究是用于检测临床文本中的事实性的。</li>
<li>methods: 这种方法使用机器翻译将英语数据翻译成德语，然后使用变换器来检测事实性。</li>
<li>results: 这种方法可以准确地检测临床文本中的事实性。<details>
<summary>Abstract</summary>
Factuality can play an important role when automatically processing clinical text, as it makes a difference if particular symptoms are explicitly not present, possibly present, not mentioned, or affirmed. In most cases, a sufficient number of examples is necessary to handle such phenomena in a supervised machine learning setting. However, as clinical text might contain sensitive information, data cannot be easily shared. In the context of factuality detection, this work presents a simple solution using machine translation to translate English data to German to train a transformer-based factuality detection model.
</details>
<details>
<summary>摘要</summary>
Factuality can play an important role when automatically processing clinical text, as it makes a difference if particular symptoms are explicitly not present, possibly present, not mentioned, or affirmed. In most cases, a sufficient number of examples is necessary to handle such phenomena in a supervised machine learning setting. However, as clinical text might contain sensitive information, data cannot be easily shared. In the context of factuality detection, this work presents a simple solution using machine translation to translate English data to German to train a transformer-based factuality detection model.Here's the word-for-word translation in Simplified Chinese:事实性可以在自动处理医疗文本时发挥重要作用，因为不同的症状是否存在、可能存在、未提及或确认的差异会影响结果。大多数情况下，需要一 sufficient number of examples来处理这种现象。但是，医疗文本可能包含敏感信息，因此数据Difficult to share。在实际性检测中，这项工作提出了一个简单的解决方案，利用机器翻译将英文数据翻译成德文，以训练基于转换器的实际性检测模型。
</details></li>
</ul>
<hr>
<h2 id="Linguistically-Informed-Neural-Architectures-for-Lexical-Syntactic-and-Semantic-Tasks-in-Sanskrit"><a href="#Linguistically-Informed-Neural-Architectures-for-Lexical-Syntactic-and-Semantic-Tasks-in-Sanskrit" class="headerlink" title="Linguistically-Informed Neural Architectures for Lexical, Syntactic and Semantic Tasks in Sanskrit"></a>Linguistically-Informed Neural Architectures for Lexical, Syntactic and Semantic Tasks in Sanskrit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08807">http://arxiv.org/abs/2308.08807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jivnesh Sandhan</li>
<li>for: 本论文的目的是使 sanskrit 手稿更加可accessible для最终用户通过自然语言技术。</li>
<li>methods: 本研究使用了语言学家所提供的语言模型，以解决 sanskrit 语言的 morphological richness、free word orderliness 和 low-resource nature 等问题。</li>
<li>results: 本研究提出了一个名为 SanskritShala 的 neural toolkit，可以在线进行 sanskrit 手稿的各种 NLP 任务的实时分析。此外，研究还提出了一些 linguistically-informed 的 neural architecture，并实现了这些模型的 interpretability 和 multilingual extension。最终，研究获得了 state-of-the-art 的性能。<details>
<summary>Abstract</summary>
The primary focus of this thesis is to make Sanskrit manuscripts more accessible to the end-users through natural language technologies. The morphological richness, compounding, free word orderliness, and low-resource nature of Sanskrit pose significant challenges for developing deep learning solutions. We identify four fundamental tasks, which are crucial for developing a robust NLP technology for Sanskrit: word segmentation, dependency parsing, compound type identification, and poetry analysis. The first task, Sanskrit Word Segmentation (SWS), is a fundamental text processing task for any other downstream applications. However, it is challenging due to the sandhi phenomenon that modifies characters at word boundaries. Similarly, the existing dependency parsing approaches struggle with morphologically rich and low-resource languages like Sanskrit. Compound type identification is also challenging for Sanskrit due to the context-sensitive semantic relation between components. All these challenges result in sub-optimal performance in NLP applications like question answering and machine translation. Finally, Sanskrit poetry has not been extensively studied in computational linguistics.   While addressing these challenges, this thesis makes various contributions: (1) The thesis proposes linguistically-informed neural architectures for these tasks. (2) We showcase the interpretability and multilingual extension of the proposed systems. (3) Our proposed systems report state-of-the-art performance. (4) Finally, we present a neural toolkit named SanskritShala, a web-based application that provides real-time analysis of input for various NLP tasks. Overall, this thesis contributes to making Sanskrit manuscripts more accessible by developing robust NLP technology and releasing various resources, datasets, and web-based toolkit.
</details>
<details>
<summary>摘要</summary>
主要研究目标是使梵语手稿更加可 accessible 给用户通过自然语言技术。梵语的 morphological richness、自由词序和 low-resource 性带来了开发深度学习解决方案的很大挑战。我们标识出了四个基本任务，这些任务是对梵语 NLP 技术的关键：梵语单词分 segmentation（SWS）、依赖分析、复合类型识别和 poetry 分析。首先，SWS 是任何其他下游应用程序的基本文本处理任务，但它受到 sandhi 现象的影响，使其成为挑战。同时，现有的依赖分析方法在 morphologically rich 和 low-resource 语言 LIKE 梵语上表现不佳。复合类型识别也是梵语的挑战，因为它们在上下文中具有相互关联的 semantics。这些挑战导致了在 NLP 应用程序如问答和机器翻译中的下OPTIMAL 性能。最后，梵语诗歌还没有得到了计算语言学的广泛研究。在面临这些挑战时，本论文做出了多个贡献：1. 提出了语言学 informed 的神经网络架构。2. 展示了解释性和多语言扩展的可能性。3. 我们的提议系统在性能方面做出了州OF-THE-ART 的贡献。4. 最后，我们发布了一个名为 SanskritShala 的神经工具kit，它是一个在线应用程序，可以对输入进行实时分析，并提供多种 NLP 任务的分析结果。总的来说，本论文的贡献在于使梵语手稿更加可 accessible，通过开发 Robust NLP 技术和发布资源、数据集和在线工具kit。
</details></li>
</ul>
<hr>
<h2 id="Chinese-Spelling-Correction-as-Rephrasing-Language-Model"><a href="#Chinese-Spelling-Correction-as-Rephrasing-Language-Model" class="headerlink" title="Chinese Spelling Correction as Rephrasing Language Model"></a>Chinese Spelling Correction as Rephrasing Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08796">http://arxiv.org/abs/2308.08796</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gingasan/lemon">https://github.com/gingasan/lemon</a></li>
<li>paper_authors: Linfeng Liu, Hongqiu Wu, Hai Zhao</li>
<li>for: 本研究旨在提高中文拼写自动 corrections的精度和可重用性，通过增加额外槽位，使模型能够更好地理解语义和自动拼写 corrections。</li>
<li>methods: 本研究提出了一种新的training paradigm，即“重写语言模型”（ReLM），通过增加额外槽位，使模型能够更好地理解语义和自动拼写 corrections。</li>
<li>results: 对于精度和可重用性，ReLM在精度和零shot benchmark上达到了新的state-of-the-artresult，与之前的对手相比，提高了大幅度。此外，ReLM还能够学习可转移的语言表示，当拼写自动 corrections与其他任务一起进行 JOINT 训练时。<details>
<summary>Abstract</summary>
This paper studies Chinese Spelling Correction (CSC), which aims to detect and correct potential spelling errors in a given sentence. Current state-of-the-art methods regard CSC as a sequence tagging task and fine-tune BERT-based models on sentence pairs. However, we note a critical flaw in the process of tagging one character to another, that the correction is excessively conditioned on the error. This is opposite from human mindset, where individuals rephrase the complete sentence based on its semantics, rather than solely on the error patterns memorized before. Such a counter-intuitive learning process results in the bottleneck of generalizability and transferability of machine spelling correction. To address this, we propose $Rephrasing Language Modeling$ (ReLM), where the model is trained to rephrase the entire sentence by infilling additional slots, instead of character-to-character tagging. This novel training paradigm achieves the new state-of-the-art results across fine-tuned and zero-shot CSC benchmarks, outperforming previous counterparts by a large margin. Our method also learns transferable language representation when CSC is jointly trained with other tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Task-Relation-Distillation-and-Prototypical-Pseudo-Label-for-Incremental-Named-Entity-Recognition"><a href="#Task-Relation-Distillation-and-Prototypical-Pseudo-Label-for-Incremental-Named-Entity-Recognition" class="headerlink" title="Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition"></a>Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08793">http://arxiv.org/abs/2308.08793</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bladedancer957/iner_rdp">https://github.com/bladedancer957/iner_rdp</a></li>
<li>paper_authors: Duzhen Zhang, Hongliu Li, Wei Cong, Rongtao Xu, Jiahua Dong, Xiuyi Chen</li>
<li>for: 这个论文是为了解决逐次学习中的快速忘却问题，特别是在background shift情况下。</li>
<li>methods: 这个方法使用了任务关系热钻和类型尺度拟标法来解决快速忘却和background shift问题。</li>
<li>results: 在十个INER设定下，这个方法实现了6.08%的微平均准确率和7.71%的macro平均准确率的显著提升，相比之前的状态泰尊方法。<details>
<summary>Abstract</summary>
Incremental Named Entity Recognition (INER) involves the sequential learning of new entity types without accessing the training data of previously learned types. However, INER faces the challenge of catastrophic forgetting specific for incremental learning, further aggravated by background shift (i.e., old and future entity types are labeled as the non-entity type in the current task). To address these challenges, we propose a method called task Relation Distillation and Prototypical pseudo label (RDP) for INER. Specifically, to tackle catastrophic forgetting, we introduce a task relation distillation scheme that serves two purposes: 1) ensuring inter-task semantic consistency across different incremental learning tasks by minimizing inter-task relation distillation loss, and 2) enhancing the model's prediction confidence by minimizing intra-task self-entropy loss. Simultaneously, to mitigate background shift, we develop a prototypical pseudo label strategy that distinguishes old entity types from the current non-entity type using the old model. This strategy generates high-quality pseudo labels by measuring the distances between token embeddings and type-wise prototypes. We conducted extensive experiments on ten INER settings of three benchmark datasets (i.e., CoNLL2003, I2B2, and OntoNotes5). The results demonstrate that our method achieves significant improvements over the previous state-of-the-art methods, with an average increase of 6.08% in Micro F1 score and 7.71% in Macro F1 score.
</details>
<details>
<summary>摘要</summary>
incremental named entity recognition (INER) 是一种逐步学习新类型的方法，不需要训练数据集的访问。然而，INER面临着增量学习中的灾难性忘记问题，这问题更加严重由背景转换（即旧和未来类型都被标记为当前任务中的非实体类型）。为解决这些挑战，我们提出了一种方法called任务关系热针和抽象 pseudo标签（RDP）。Specifically, to tackle catastrophic forgetting, we introduce a task relation distillation scheme that serves two purposes: 1) ensuring inter-task semantic consistency across different incremental learning tasks by minimizing inter-task relation distillation loss, and 2) enhancing the model's prediction confidence by minimizing intra-task self-entropy loss. Simultaneously, to mitigate background shift, we develop a prototypical pseudo label strategy that distinguishes old entity types from the current non-entity type using the old model. This strategy generates high-quality pseudo labels by measuring the distances between token embeddings and type-wise prototypes.我们在三个 benchmark datasets（CoNLL2003、I2B2和OntoNotes5）上进行了广泛的实验，结果显示，我们的方法在前一个状态的方法中获得了显著提高，其中 Micro F1 分数提高了6.08%，Macro F1 分数提高了7.71%。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Catastrophic-Forgetting-in-Large-Language-Models-During-Continual-Fine-tuning"><a href="#An-Empirical-Study-of-Catastrophic-Forgetting-in-Large-Language-Models-During-Continual-Fine-tuning" class="headerlink" title="An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning"></a>An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08747">http://arxiv.org/abs/2308.08747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luoxiaoheics/continual-tune">https://github.com/luoxiaoheics/continual-tune</a></li>
<li>paper_authors: Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, Yue Zhang</li>
<li>for: 本研究旨在探讨大语言模型（LLM）在继续微调过程中是否存在悬峰忘记现象（Catastrophic Forgetting，CF）。</li>
<li>methods: 本研究使用了各种方法，包括领域知识、逻辑和语言理解等方面的评估，来评估 LLM 的知识忘记现象。</li>
<li>results: 研究发现，LLM 在继续微调过程中一般存在 CF 现象，而scale增加后，忘记现象也加剧。 Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ 比较少忘记，保持更多的知识。 另外，研究发现 LLM 在继续微调过程中可以减少语言偏见（如性偏见）。<details>
<summary>Abstract</summary>
Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning when a model forgets previously learned information as it learns new information. As large language models (LLMs) have shown excellent performance, it is interesting to uncover whether CF exists in the continual fine-tuning of LLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs' knowledge, from the perspectives of domain knowledge, reasoning, and reading comprehension. The experiments demonstrate that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale increases, the severity of forgetting also intensifies. Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers less forgetting and maintains more knowledge. We also observe that LLMs can mitigate language bias (e.g. gender bias) during continual fine-tuning. Moreover, we find that ALPACA can maintain more knowledge and capacity compared with LLAMA during the continual fine-tuning, which implies that general instruction tuning can help mitigate the forgetting phenomenon of LLMs in the further fine-tuning process.
</details>
<details>
<summary>摘要</summary>
您好！我很高兴今天分享一篇关于机器学习的研究成果。研究发现，当机器学习模型（LLM）在不断微调过程中学习新信息时，可能会出现“恐慌性忘记”（Catastrophic Forgetting，CF）现象。在这种情况下，模型可能会忘记之前学习的信息。我们通过实验证明，CF确实存在于LLM中，并且随着模型的缩放程度增大，忘记现象也变得更加严重。此外，我们发现，使用泛化指令调整可以减轻LLM在不断微调过程中的忘记现象。在这篇研究中，我们还发现了一些其他有趣的现象。例如，我们发现LLM可以在不断微调过程中减少语言偏见（如性偏见）。此外，我们还发现了一些不同的模型之间的差异。例如，比较decoder-only模型BLOOMZ和encoder-decoder模型mT0，BLOOMZ在不断微调过程中减少忘记现象，并保持更多的知识。这些发现可能有助于我们更好地理解LLM在不断微调过程中的行为，并且可能有助于我们开发更好的LLM模型。总之，这篇研究提供了一些有趣的发现，可能有助于我们更好地理解LLM在不断微调过程中的行为，并且可能有助于我们开发更好的LLM模型。如果您有兴趣，请随时阅读我们的研究论文，了解更多细节。谢谢！
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Phrase-Representation-by-Information-Bottleneck-Guided-Text-Diffusion-Process-for-Keyphrase-Extraction"><a href="#Enhancing-Phrase-Representation-by-Information-Bottleneck-Guided-Text-Diffusion-Process-for-Keyphrase-Extraction" class="headerlink" title="Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction"></a>Enhancing Phrase Representation by Information Bottleneck Guided Text Diffusion Process for Keyphrase Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08739">http://arxiv.org/abs/2308.08739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanzhen Luo, Qingyu Zhou, Feng Zhou</li>
<li>for: 本研究的目的是提出一种基于Variational Information Bottleneck（VIB）的supervised文本扩散过程，用于提高键短语提取（KPE）的性能。</li>
<li>methods: 该方法首先根据整个文档生成需要的键短语嵌入，然后将生成的嵌入注入到每个短语表示中。然后，使用排名网络和VIB进行优化，并使用排名损失和分类损失进行训练。</li>
<li>results: 实验显示，Diff-KPE比exist的KPE方法在一个大规模的开放领域键短语提取benchmark（OpenKP）和一个科学领域的数据集（KP20K）上表现出色，得到了更好的性能。<details>
<summary>Abstract</summary>
Keyphrase extraction (KPE) is an important task in Natural Language Processing for many scenarios, which aims to extract keyphrases that are present in a given document. Many existing supervised methods treat KPE as sequential labeling, span-level classification, or generative tasks. However, these methods lack the ability to utilize keyphrase information, which may result in biased results. In this study, we propose Diff-KPE, which leverages the supervised Variational Information Bottleneck (VIB) to guide the text diffusion process for generating enhanced keyphrase representations. Diff-KPE first generates the desired keyphrase embeddings conditioned on the entire document and then injects the generated keyphrase embeddings into each phrase representation. A ranking network and VIB are then optimized together with rank loss and classification loss, respectively. This design of Diff-KPE allows us to rank each candidate phrase by utilizing both the information of keyphrases and the document. Experiments show that Diff-KPE outperforms existing KPE methods on a large open domain keyphrase extraction benchmark, OpenKP, and a scientific domain dataset, KP20K.
</details>
<details>
<summary>摘要</summary>
KEYPHRASE EXTRACTION (KPE) 是自然语言处理中一项重要的任务，目标是从给定的文档中提取关键短语。现有的超级vised方法将 KPE 视为顺序标注、span-level 分类或生成任务，但这些方法可能会忽略关键短语信息，从而导致不准确的结果。在本研究中，我们提出了Diff-KPE，它利用supervisedVariational Information Bottleneck（VIB）来导引文本噪声过程，从而生成改进的关键短语表示。Diff-KPE首先根据整个文档生成所需的关键短语嵌入，然后将生成的嵌入注入到每个短语表示中。然后，一个排名网络和VIB分别与排名损失和分类损失进行优化。这种Diff-KPE的设计允许我们根据文档信息和关键短语来排名每个候选短语，从而提高了关键短语提取的准确率。实验表明，Diff-KPE在一个大规模的开放领域关键短语提取标准benchmark OpenKP 和一个科学领域数据集 KP20K 上都有出色的表现，超过了现有的 KPE 方法。
</details></li>
</ul>
<hr>
<h2 id="Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition"><a href="#Decoding-Emotions-A-comprehensive-Multilingual-Study-of-Speech-Models-for-Speech-Emotion-Recognition" class="headerlink" title="Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition"></a>Decoding Emotions: A comprehensive Multilingual Study of Speech Models for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08713">http://arxiv.org/abs/2308.08713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/95anantsingh/decoding-emotions">https://github.com/95anantsingh/decoding-emotions</a></li>
<li>paper_authors: Anant Singh, Akshat Gupta</li>
<li>for: 这篇论文主要是为了评估多种语言下的语音情感识别（SER）模型，以及这些模型的内部表示方式。</li>
<li>methods: 这篇论文使用了八种语音表示模型和六种语言进行了比较，并通过探测实验获取这些模型的内部工作方式。</li>
<li>results: 研究发现，使用单个最佳层的语音模型特征可以降低错误率平均为32%，而使用所有层的语音模型特征可以达到最佳结果。此外，这些探测结果表明，语音模型的中间层 capture最重要的情感信息。<details>
<summary>Abstract</summary>
Recent advancements in transformer-based speech representation models have greatly transformed speech processing. However, there has been limited research conducted on evaluating these models for speech emotion recognition (SER) across multiple languages and examining their internal representations. This article addresses these gaps by presenting a comprehensive benchmark for SER with eight speech representation models and six different languages. We conducted probing experiments to gain insights into inner workings of these models for SER. We find that using features from a single optimal layer of a speech model reduces the error rate by 32\% on average across seven datasets when compared to systems where features from all layers of speech models are used. We also achieve state-of-the-art results for German and Persian languages. Our probing results indicate that the middle layers of speech models capture the most important emotional information for speech emotion recognition.
</details>
<details>
<summary>摘要</summary>
近年来，基于转换器的语音表示模型在语音处理领域已经带来巨大的变革。然而，关于评估这些模型在多种语言的语音情感识别（SER）方面的研究还是有限的。这篇文章填补了这些差距，并提供了一个全面的 SER benchmark，包括八种语音表示模型和六种不同的语言。我们进行了探索性的实验，以了解这些模型内部的具体工作原理。我们发现，使用单个最佳层的语音模型特征可以降低错误率平均为32%，相比于所有层的语音模型特征使用系统。我们还实现了德语和波斯语的状态机器人表现。我们的探索结果表明，语音模型的中间层最好 capture 情感信息。
</details></li>
</ul>
<hr>
<h2 id="FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs"><a href="#FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs" class="headerlink" title="FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs"></a>FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09723">http://arxiv.org/abs/2308.09723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Jin Kim, Rawn Henry, Raffy Fahim, Hany Hassan Awadalla</li>
<li>for: 这篇研究旨在提高大型语言模型（LLMs）的实际应用性，因为它们需要大量的内存，而且最新的生成模型在自动化预测过程中发生了内存带宽瓶须。</li>
<li>methods: 我们提出了一种有效的量化方法，可以降低模型的内存使用量和加速推断，而且不需要额外的调整。我们还引入了一个简单且有效的规律，使用预训模型的维度作为量化精度。</li>
<li>results: 我们评估了我们的提案，并证明了它们可以实现最大化的执行速度和最小化的质量损失。在使用大量的Open Source模型和内部MoE模型时，我们获得了与原始模型相似的准确性，并在相同数量的GPU上实现了3.65倍的运算速度。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights. We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Language-Models-for-Granularized-Barrett’s-Esophagus-Diagnosis-Classification"><a href="#Large-Language-Models-for-Granularized-Barrett’s-Esophagus-Diagnosis-Classification" class="headerlink" title="Large Language Models for Granularized Barrett’s Esophagus Diagnosis Classification"></a>Large Language Models for Granularized Barrett’s Esophagus Diagnosis Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08660">http://arxiv.org/abs/2308.08660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jenna Kefeli, Ali Soroush, Courtney J. Diamond, Haley M. Zylberberg, Benjamin May, Julian A. Abrams, Chunhua Weng, Nicholas Tatonetti</li>
<li>For: 本研究旨在提高贝勒氏食道癌前体（BE）诊断代码的精度和特点，以满足各种研究和临床应用场景的需求。* Methods: 研究人员开发了一种通用的变换器基本方法，用于自动提取BE诊断报告中的关键特征。该方法使用了两个临床预训练的大语言模型，并与手动 Chart review 进行比较。* Results: 研究人员通过使用哥伦比亚大学爱立信医学中心的BE诊断报告，并与 Gastroenterologist 注解的目标进行比较，实现了二分类分化和多类BE相关诊断分类。研究人员发现，使用两个临床预训练的大语言模型，与手动开发的规则基本方法相比，其性能相对较高，具有更高的精度和更快的实现速度。<details>
<summary>Abstract</summary>
Diagnostic codes for Barrett's esophagus (BE), a precursor to esophageal cancer, lack granularity and precision for many research or clinical use cases. Laborious manual chart review is required to extract key diagnostic phenotypes from BE pathology reports. We developed a generalizable transformer-based method to automate data extraction. Using pathology reports from Columbia University Irving Medical Center with gastroenterologist-annotated targets, we performed binary dysplasia classification as well as granularized multi-class BE-related diagnosis classification. We utilized two clinically pre-trained large language models, with best model performance comparable to a highly tailored rule-based system developed using the same data. Binary dysplasia extraction achieves 0.964 F1-score, while the multi-class model achieves 0.911 F1-score. Our method is generalizable and faster to implement as compared to a tailored rule-based approach.
</details>
<details>
<summary>摘要</summary>
Current diagnostic codes for Barrett's esophagus (BE), a precursor to esophageal cancer, lack specificity and granularity for many research or clinical use cases. Manual chart review is time-consuming and laborious to extract key diagnostic phenotypes from BE pathology reports. We developed a generalizable transformer-based method to automate data extraction. Using pathology reports from Columbia University Irving Medical Center with gastroenterologist-annotated targets, we performed binary dysplasia classification as well as granularized multi-class BE-related diagnosis classification. We utilized two pre-trained large language models, with the best model performance comparable to a highly tailored rule-based system developed using the same data. Binary dysplasia extraction achieved an F1-score of 0.964, while the multi-class model achieved an F1-score of 0.911. Our method is more efficient and generalizable than a tailored rule-based approach.
</details></li>
</ul>
<hr>
<h2 id="Learning-the-meanings-of-function-words-from-grounded-language-using-a-visual-question-answering-model"><a href="#Learning-the-meanings-of-function-words-from-grounded-language-using-a-visual-question-answering-model" class="headerlink" title="Learning the meanings of function words from grounded language using a visual question answering model"></a>Learning the meanings of function words from grounded language using a visual question answering model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08628">http://arxiv.org/abs/2308.08628</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/evaportelance/vqa-function-word-learning">https://github.com/evaportelance/vqa-function-word-learning</a></li>
<li>paper_authors: Eva Portelance, Michael C. Frank, Dan Jurafsky</li>
<li>For: 本研究探讨了儿童如何学习功能词（function words），以及模型如何使用这些词语来回答复杂的视觉问题。* Methods: 研究使用了基于神经网络的视觉语言模型，通过训练这些模型在视觉上grounded的语言中使用功能词来研究这些词语的含义。* Results: 研究发现，这些模型可以通过非Symbolic普遍学习算法来学习功能词的含义，无需任何先前的语言含义知识。此外，模型还可以学习逻辑连接词（like “and” and “or”）的含义，并且可以在语言中理解多种表达方式。最后，研究发现，词语学习难度与模型的输入频率有关。<details>
<summary>Abstract</summary>
Interpreting a seemingly-simple function word like "or", "behind", or "more" can require logical, numerical, and relational reasoning. How are such words learned by children? Prior acquisition theories have often relied on positing a foundation of innate knowledge. Yet recent neural-network based visual question answering models apparently can learn to use function words as part of answering questions about complex visual scenes. In this paper, we study what these models learn about function words, in the hope of better understanding how the meanings of these words can be learnt by both models and children. We show that recurrent models trained on visually grounded language learn gradient semantics for function words requiring spacial and numerical reasoning. Furthermore, we find that these models can learn the meanings of logical connectives "and" and "or" without any prior knowledge of logical reasoning, as well as early evidence that they can develop the ability to reason about alternative expressions when interpreting language. Finally, we show that word learning difficulty is dependent on frequency in models' input. Our findings offer evidence that it is possible to learn the meanings of function words in visually grounded context by using non-symbolic general statistical learning algorithms, without any prior knowledge of linguistic meaning.
</details>
<details>
<summary>摘要</summary>
函数词如“或”、“后”或“更”的理解可能需要逻辑、数学和关系的推理能力。儿童如何学习这些词？以前的获得理论 frequently rely on positing a foundation of innate knowledge。然而，最新的神经网络基于视觉问答模型 Apparently can learn to use function words as part of answering questions about complex visual scenes.在这篇论文中，我们研究这些模型对函数词的学习，以更好地理解儿童和模型如何学习这些词的meaning。我们发现，基于视觉受限语言的回归模型在学习gradient semantics for function words requiring spacial and numerical reasoning。此外，我们发现这些模型可以不带任何逻辑推理知识学习逻辑连接词“和”和“或”的meaning，以及初步证明它们可以在语言解释中理解备用表达。最后，我们发现word learning difficulty是模型输入频率的函数。我们的发现表明可以通过非符号统计学学习算法，不带任何语言含义的先验知识，来学习函数词的meaning。
</details></li>
</ul>
<hr>
<h2 id="BIOptimus-Pre-training-an-Optimal-Biomedical-Language-Model-with-Curriculum-Learning-for-Named-Entity-Recognition"><a href="#BIOptimus-Pre-training-an-Optimal-Biomedical-Language-Model-with-Curriculum-Learning-for-Named-Entity-Recognition" class="headerlink" title="BIOptimus: Pre-training an Optimal Biomedical Language Model with Curriculum Learning for Named Entity Recognition"></a>BIOptimus: Pre-training an Optimal Biomedical Language Model with Curriculum Learning for Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08625">http://arxiv.org/abs/2308.08625</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rttl-ai/bioptimus">https://github.com/rttl-ai/bioptimus</a></li>
<li>paper_authors: Pavlova Vera, Mohammed Makhlouf</li>
<li>for:  investigate different pre-training methods for biomedical language models and compare their performance on Named Entity Recognition (NER) tasks.</li>
<li>methods: pre-training the biomedical language model from scratch, pre-training it in a continued fashion, and using a curriculum learning approach with contextualized weight distillation.</li>
<li>results: a new biomedical language model (BIOptimus) that sets new states of the art on several biomedical NER tasks, and an analysis of the impact of masking rate, corruption strategy, and masking strategies on the performance of the biomedical LM.<details>
<summary>Abstract</summary>
Using language models (LMs) pre-trained in a self-supervised setting on large corpora and then fine-tuning for a downstream task has helped to deal with the problem of limited label data for supervised learning tasks such as Named Entity Recognition (NER). Recent research in biomedical language processing has offered a number of biomedical LMs pre-trained using different methods and techniques that advance results on many BioNLP tasks, including NER. However, there is still a lack of a comprehensive comparison of pre-training approaches that would work more optimally in the biomedical domain. This paper aims to investigate different pre-training methods, such as pre-training the biomedical LM from scratch and pre-training it in a continued fashion. We compare existing methods with our proposed pre-training method of initializing weights for new tokens by distilling existing weights from the BERT model inside the context where the tokens were found. The method helps to speed up the pre-training stage and improve performance on NER. In addition, we compare how masking rate, corruption strategy, and masking strategies impact the performance of the biomedical LM. Finally, using the insights from our experiments, we introduce a new biomedical LM (BIOptimus), which is pre-trained using Curriculum Learning (CL) and contextualized weight distillation method. Our model sets new states of the art on several biomedical Named Entity Recognition (NER) tasks. We release our code and all pre-trained models
</details>
<details>
<summary>摘要</summary>
使用先前训练的语言模型（LM）在自然语言处理（NLP）领域进行预训练，然后进行下游任务（如命名实体识别（NER））的问题，受到有限的标注数据的限制。 current research in biomedical NLP 提供了许多适用于生物医学领域的语言模型，通过不同的方法和技术进行预训练，提高了许多生物医学任务的结果，包括NER。然而，还没有一个全面的比较研究，探讨不同的预训练方法在生物医学领域是否可以更优。这篇论文旨在调查不同的预训练方法，如从scratch预训练和继续预训练。我们比较了现有的方法和我们提出的方法，该方法是使用BERT模型中的权重初始化新的token。这种方法可以加速预训练阶段，并提高NER的表现。此外，我们还比较了掩码率、损害策略和掩码策略对生物医学LM的性能的影响。最后，基于我们的实验结果，我们提出了一个新的生物医学LM（BIOptimus），通过curriculum learning（CL）和Contextualized weight distillation方法进行预训练。我们的模型在许多生物医学NER任务中设置了新的纪录。我们发布了我们的代码和所有预训练模型。
</details></li>
</ul>
<hr>
<h2 id="Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models"><a href="#Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models" class="headerlink" title="Time Travel in LLMs: Tracing Data Contamination in Large Language Models"></a>Time Travel in LLMs: Tracing Data Contamination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08493">http://arxiv.org/abs/2308.08493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahriar Golchin, Mihai Surdeanu</li>
<li>for: 本研究旨在探讨大语言模型（LLM）在不同任务上的效果，并检测LLM在训练数据中是否存在数据污染问题。</li>
<li>methods: 本研究提出了一种简单 yet effective的方法来检测LLM中的数据污染。该方法包括在小样本中identify potential contamination，并使用“导向指令”（prompt）来评估实例是否污染。</li>
<li>results: 研究发现，使用“导向指令”可以准确地检测LLM中的数据污染。 Specifically, the paper achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test&#x2F;validation partitions, when contrasted with manual evaluation by human expert. Additionally, the findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.<details>
<summary>Abstract</summary>
Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ "guided instruction:" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name. The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.
</details>
<details>
<summary>摘要</summary>
“数据污染”，即大语言模型（LLM）训练数据中下游任务的数据污染，是评估LLM的效果所存在的一个潜在问题。我们提出了一种简单 yet有效的方法来识别LLM中的数据污染。我们的方法的核心在于在小样本中标识潜在的污染，然后使用这些信息来评估整个数据分区是否受污染。为了评估个体实例的污染情况，我们采用了“引导指令”：一个包含数据集名称、分区类型和参考实例的开头部分的提示，要求LLM完成它。如果LLM的输出与参考实例的后半部分匹配，则认为该实例污染了。为了判断整个分区是否受污染，我们提出了两个想法。第一个想法是如果使用ROUGE或BLEURT评估指标，则认为分区受污染，如果使用引导指令vs无引导指令的平均 overlap score差异是 statistically significant。第二个想法是使用基于GPT-4的类型学习提示，如果多个实例被标记为污染，则认为整个分区受污染。我们的最佳方法可以在七个数据集上达到92%-100%的准确率，与人工评估相比。此外，我们的发现表明GPT-4污染了AG News、WNLI和XSum数据集。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.CL_2023_08_17/" data-id="clorjzl3w009nf188ddjtgbpm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/cs.LG_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T10:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/cs.LG_2023_08_17/">cs.LG - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization"><a href="#Enhancing-API-Documentation-through-BERTopic-Modeling-and-Summarization" class="headerlink" title="Enhancing API Documentation through BERTopic Modeling and Summarization"></a>Enhancing API Documentation through BERTopic Modeling and Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09070">http://arxiv.org/abs/2308.09070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scam2023-bert/bertopic">https://github.com/scam2023-bert/bertopic</a></li>
<li>paper_authors: AmirHossein Naghshzan, Sylvie Ratte</li>
<li>for: 本研究旨在提高API文档理解效率，帮助开发者更好地利用API功能。</li>
<li>methods: 本研究使用BERTopic进行主题分析和自然语言处理（NLP）技术，自动生成API文档摘要，从而提高开发者获取信息的效率。</li>
<li>results: 研究发现了一些常见的主题和问题，并提供了可能的解决方案，对API文档分析和开发者工作提供了valuable的启示和实践性的工具。<details>
<summary>Abstract</summary>
As the amount of textual data in various fields, including software development, continues to grow, there is a pressing demand for efficient and effective extraction and presentation of meaningful insights. This paper presents a unique approach to address this need, focusing on the complexities of interpreting Application Programming Interface (API) documentation. While official API documentation serves as a primary source of information for developers, it can often be extensive and lacks user-friendliness. In light of this, developers frequently resort to unofficial sources like Stack Overflow and GitHub. Our novel approach employs the strengths of BERTopic for topic modeling and Natural Language Processing (NLP) to automatically generate summaries of API documentation, thereby creating a more efficient method for developers to extract the information they need. The produced summaries and topics are evaluated based on their performance, coherence, and interoperability.   The findings of this research contribute to the field of API documentation analysis by providing insights into recurring topics, identifying common issues, and generating potential solutions. By improving the accessibility and efficiency of API documentation comprehension, our work aims to enhance the software development process and empower developers with practical tools for navigating complex APIs.
</details>
<details>
<summary>摘要</summary>
随着不同领域中文本数据的增加，包括软件开发，存在一项强烈的需求，即提取和显示有用的洞察结论。本文提出了一种独特的方法来解决这个问题，即利用API文档的复杂性进行解释。官方API文档 serves as the primary source of information for developers, but it can be extensive and difficult to use. Therefore, developers often resort to unofficial sources such as Stack Overflow and GitHub. Our novel approach employs the strengths of BERTopic for topic modeling and Natural Language Processing (NLP) to automatically generate summaries of API documentation, thereby creating a more efficient method for developers to extract the information they need. The generated summaries and topics are evaluated based on their performance, coherence, and interoperability. 本研究的发现对API文档分析领域做出了贡献，提供了复杂的主题、常见问题和可能的解决方案的洞察。通过改善API文档的可访问性和效率，我们的工作希望能够提高软件开发过程中的开发人员 navigating 复杂的API。
</details></li>
</ul>
<hr>
<h2 id="Uplift-Modeling-from-Causal-Inference-to-Personalization"><a href="#Uplift-Modeling-from-Causal-Inference-to-Personalization" class="headerlink" title="Uplift Modeling: from Causal Inference to Personalization"></a>Uplift Modeling: from Causal Inference to Personalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09066">http://arxiv.org/abs/2308.09066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe Moraes, Hugo Manuel Proença, Anastasiia Kornilova, Javier Albert, Dmitri Goldenberg</li>
<li>for: 本教程旨在介绍 causality 和 uplift 模型，以便在线电商平台上进行个性化推广活动。</li>
<li>methods: 本教程会介绍 state-of-the-art 的 uplift 模型技术，包括不同的优点和局限性。</li>
<li>results: 本教程会介绍实际应用情况，以及在生产环境中实施这些模型时可能会遇到的挑战。<details>
<summary>Abstract</summary>
Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.
</details>
<details>
<summary>摘要</summary>
“增强模型是一种Machine Learning技术集成，用于估计对各个个体或子组的影响。在过去几年， causality和增强模型在在线电商平台上成为了个性化的潮流，帮助选择对每个用户最佳的处理，以最大化目标业务指标。增强模型特别有用于个性化促销活动，因为推广的潜在利益需要与潜在成本进行平衡。在这个教程中，我们将讲解 causality 的基本概念，并介绍现代的增强模型技术。我们会讲述不同方法的优点和限制，并探讨受限增强模型的特殊设置。最后，我们会介绍实际应用和在生产中实施这些模型的挑战。”
</details></li>
</ul>
<hr>
<h2 id="Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression"><a href="#Discretization-Induced-Dirichlet-Posterior-for-Robust-Uncertainty-Quantification-on-Regression" class="headerlink" title="Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression"></a>Discretization-Induced Dirichlet Posterior for Robust Uncertainty Quantification on Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09065">http://arxiv.org/abs/2308.09065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanlong Yu, Gianni Franchi, Jindong Gu, Emanuel Aldea<br>for: 这个论文的目的是提出一种更加Robust的auxiliary uncertainty estimator（AuxUE）来估计深度神经网络（DNNs）的不确定性，以便在实际应用中使用。methods: 该论文使用了不同的分布假设来估计异常输入（Out-of-Distribution，OOD）中的aleatoric uncertainty，并最终选择了拉пла斯分布来近似预测错误。此外，该论文还提出了一种新的epistemic uncertainty estimation方法 named Discretization-Induced Dirichlet pOsterior（DIDO），该方法模型了预测错误的粒度化 posterior。results: 该论文的实验结果表明，其提出的方法可以在各种视觉任务上提供Robust的不确定性估计，包括年龄估计、单目深度估计和超分辨任务。此外，该论文还证明了其方法可以扩展到图像级和像素级任务。<details>
<summary>Abstract</summary>
Uncertainty quantification is critical for deploying deep neural networks (DNNs) in real-world applications. An Auxiliary Uncertainty Estimator (AuxUE) is one of the most effective means to estimate the uncertainty of the main task prediction without modifying the main task model. To be considered robust, an AuxUE must be capable of maintaining its performance and triggering higher uncertainties while encountering Out-of-Distribution (OOD) inputs, i.e., to provide robust aleatoric and epistemic uncertainty. However, for vision regression tasks, current AuxUE designs are mainly adopted for aleatoric uncertainty estimates, and AuxUE robustness has not been explored. In this work, we propose a generalized AuxUE scheme for more robust uncertainty quantification on regression tasks. Concretely, to achieve a more robust aleatoric uncertainty estimation, different distribution assumptions are considered for heteroscedastic noise, and Laplace distribution is finally chosen to approximate the prediction error. For epistemic uncertainty, we propose a novel solution named Discretization-Induced Dirichlet pOsterior (DIDO), which models the Dirichlet posterior on the discretized prediction error. Extensive experiments on age estimation, monocular depth estimation, and super-resolution tasks show that our proposed method can provide robust uncertainty estimates in the face of noisy inputs and that it can be scalable to both image-level and pixel-wise tasks.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在实际应用中部署需要量化不确定性。协助性不确定估计器（AuxUE）是修改主任务模型的最佳方法来估计主任务预测结果的不确定性。为了被视为可靠，一个 AuxUE 必须能够保持其性能，并在异常输入（OOD）中触发更高的不确定性。然而，目前的 AuxUE 设计主要用于 aleatoric 不确定性估计，AuxUE 的 Robustness 尚未得到探讨。在这种情况下，我们提出一种通用的 AuxUE 方案，以提高 regression 任务中的不确定性量化的可靠性。具体来说，为了实现更加robust的 aleatoric 不确定性估计，我们考虑了不同的分布假设，并最终选择了 Laplace 分布来近似预测错误。为 epistemic 不确定性，我们提出了一种新的解决方案，即 Discretization-Induced Dirichlet pOsterior（DIDO），它模型了精度 posterior 在精度化预测错误上。我们在年龄估计、单目深度估计和超分辨率任务上进行了广泛的实验，结果表明，我们的提出的方法可以在噪声输入下提供可靠的不确定性估计，并且可以扩展到图像级和像素级任务。
</details></li>
</ul>
<hr>
<h2 id="Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods"><a href="#Refining-a-Deep-Learning-based-Formant-Tracker-using-Linear-Prediction-Methods" class="headerlink" title="Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods"></a>Refining a Deep Learning-based Formant Tracker using Linear Prediction Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09051">http://arxiv.org/abs/2308.09051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paavo Alku, Sudarsana Reddy Kadiri, Dhananjaya Gowda</li>
<li>for: 这个研究是用来调查和改进现有的数据驱动式形式追踪器（DeepFormants）的方法。</li>
<li>methods: 这个研究使用了线性预测（LP）基于方法来估算形式，包括传统的covariance分析（LP-COV）和最近提出的 quasi-closed phase forward-backward（QCP-FB）分析。</li>
<li>results: 研究发现，使用LP基于方法来修正DeepFormants预测的形式可以提高追踪器的性能，并且在受到噪声损害的VTR语音追踪 task中表现更加稳定。此外，这种方法可以轻松地与现有的数据驱动式追踪器结合使用，不需要进行任何新的数据学习。<details>
<summary>Abstract</summary>
In this study, formant tracking is investigated by refining the formants tracked by an existing data-driven tracker, DeepFormants, using the formants estimated in a model-driven manner by linear prediction (LP)-based methods. As LP-based formant estimation methods, conventional covariance analysis (LP-COV) and the recently proposed quasi-closed phase forward-backward (QCP-FB) analysis are used. In the proposed refinement approach, the contours of the three lowest formants are first predicted by the data-driven DeepFormants tracker, and the predicted formants are replaced frame-wise with local spectral peaks shown by the model-driven LP-based methods. The refinement procedure can be plugged into the DeepFormants tracker with no need for any new data learning. Two refined DeepFormants trackers were compared with the original DeepFormants and with five known traditional trackers using the popular vocal tract resonance (VTR) corpus. The results indicated that the data-driven DeepFormants trackers outperformed the conventional trackers and that the best performance was obtained by refining the formants predicted by DeepFormants using QCP-FB analysis. In addition, by tracking formants using VTR speech that was corrupted by additive noise, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers. In general, these results suggest that LP-based model-driven approaches, which have traditionally been used in formant estimation, can be combined with a modern data-driven tracker easily with no further training to improve the tracker's performance.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了使用现有的数据驱动跟踪器DeepFormants的形式跟踪结果，并使用LP（线性预测）方法所估计的形式来进行修订。我们使用了传统的covariance analysis（LP-COV）和最近提出的 quasi-closed phase forward-backward（QCP-FB）分析方法。在我们的修订方法中，首先使用DeepFormants tracker来预测三个最低的形式轨迹，然后将预测的形式替换为每帧的本地spectral peak，显示出LP-based方法所估计的形式。这种修订方法可以轻松地插入到DeepFormants tracker中，无需进行任何新的数据学习。我们对原始DeepFormants和五种已知传统跟踪器进行比较，结果表明了数据驱动DeepFormants trackers的性能高于传统跟踪器，而使用QCP-FB分析方法进行修订可以得到最佳性能。此外，通过使用受杂音损害的VTR语音跟踪，研究表明了修订后的DeepFormants trackers在噪音环境中的更高抗噪性。总之，这些结果表明了LP-based模型驱动方法可以轻松地与现有的数据驱动跟踪器结合使用，以提高跟踪器的性能。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing"><a href="#Kernel-Based-Tests-for-Likelihood-Free-Hypothesis-Testing" class="headerlink" title="Kernel-Based Tests for Likelihood-Free Hypothesis Testing"></a>Kernel-Based Tests for Likelihood-Free Hypothesis Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09043">http://arxiv.org/abs/2308.09043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrik Róbert Gerber, Tianze Jiang, Yury Polyanskiy, Rui Sun</li>
<li>for: 这个论文主要关注的问题是如何使用有限数量的标注样本来预测另外一些样本的类别，具体来说是使用两个类别之间的混合样本来预测另外一个类别。</li>
<li>methods: 这篇论文使用了likelihood-ratio测试和maximum mean discrepancy（MMD）来解决这个问题。它还使用了权重参数化的神经网络来评估预测性能。</li>
<li>results: 论文发现了一个基本的负荷误差对m和n的负荷误差之间的交易，即增加数据样本m会减少训练&#x2F;模拟数据样本n的需要。同时，论文还证明了这种交易的存在性，并通过两个实际问题（检测希格斯粒子和检测植入DDPM生成的图像）来验证其理论性。<details>
<summary>Abstract</summary>
Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax sample complexity for non-parametric classes of densities under \textit{maximum mean discrepancy} (MMD) separation; and (c) investigate the empirical performance of kernels parameterized by neural networks on two tasks: detection of the Higgs boson and detection of planted DDPM generated images amidst CIFAR-10 images. For both problems we confirm the existence of the theoretically predicted asymmetric $m$ vs $n$ trade-off.
</details>
<details>
<summary>摘要</summary>
给定 $n$ 观察数据，二分类问题中的标注一个额外 $m$ 个输入，其中所有输入都属于一个类别。特殊情况包括：当 $n=\infty$ 时，通过 likelihood-ratio 测试可以优化地解决问题；当 $m=1$ 时，相当于二分类问题；当 $m\approx n$ 时，等价于两个样本测试。在中间设置中，在 likelihood-free 推理中获取标注样本，并将未标注样本收集到实验中。最新的研究发现，存在 $m$ 和 $n$ 之间的基本财富平衡：增加数据样本 $m$ 会降低训练/模拟数据需要的量 $n$。在这项工作中，我们（a）引入一种泛化，其中未标注样本来自两个类别的混合；（b）研究非Parametric 类型的概率密度下的最小最大误差（MMD）分离下的最小样本复杂度；以及（c）调查使用权重参数化神经网络的两个任务：探测希格斯粒子和探测植入DDPM生成的图像中的植入DDPM生成图像。对于两个问题，我们证实了理论预测的偏极 $m$ vs $n$ 财富平衡。
</details></li>
</ul>
<hr>
<h2 id="LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation"><a href="#LesionMix-A-Lesion-Level-Data-Augmentation-Method-for-Medical-Image-Segmentation" class="headerlink" title="LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation"></a>LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09026">http://arxiv.org/abs/2308.09026</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dogabasaran/lesionmix">https://github.com/dogabasaran/lesionmix</a></li>
<li>paper_authors: Berke Doga Basaran, Weitong Zhang, Mengyun Qiao, Bernhard Kainz, Paul M. Matthews, Wenjia Bai</li>
<li>For: The paper is written for the purpose of proposing a novel data augmentation method called LesionMix, which is designed to improve the accuracy of deep learning-based medical image segmentation methods.* Methods: The paper uses a combination of spatial and intensity transformations to augment medical images, with a focus on lesion-aware augmentation at the lesion level. The method allows for both lesion populating and inpainting, and is evaluated on multiple modalities and lesion datasets.* Results: The paper reports promising performance of LesionMix in lesion image segmentation, outperforming several recent Mix-based data augmentation methods. The code for LesionMix will be released on GitHub for further use and evaluation.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是为了提出一种新的数据增强方法，即LesionMix，用于深度学习基于医疗影像分割方法的准确性。* Methods: 这篇论文使用了一种组合的空间和强度变换来增强医疗影像，并将注意力集中在病变水平上进行数据增强。这种方法允许病变的填充和抹除，并在不同的modalities和病变数据集上进行评估。* Results: 这篇论文报告了LesionMix在病变图像分割中的良好表现，比较了许多最近的Mix基于数据增强方法。代码将在GitHub上发布，以便进一步使用和评估。<details>
<summary>Abstract</summary>
Data augmentation has become a de facto component of deep learning-based medical image segmentation methods. Most data augmentation techniques used in medical imaging focus on spatial and intensity transformations to improve the diversity of training images. They are often designed at the image level, augmenting the full image, and do not pay attention to specific abnormalities within the image. Here, we present LesionMix, a novel and simple lesion-aware data augmentation method. It performs augmentation at the lesion level, increasing the diversity of lesion shape, location, intensity and load distribution, and allowing both lesion populating and inpainting. Experiments on different modalities and different lesion datasets, including four brain MR lesion datasets and one liver CT lesion dataset, demonstrate that LesionMix achieves promising performance in lesion image segmentation, outperforming several recent Mix-based data augmentation methods. The code will be released at https://github.com/dogabasaran/lesionmix.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>医学影像分割中使用深度学习的方法中，数据增强已成为一个非正式的组成部分。大多数医学影像数据增强技术都是针对空间和Intensity变换，以提高训练图像的多样性。它们通常是图像水平进行增强，不注重特定疾病内部的特征。我们现在提出了LesionMix，一种新的和简单的疾病意识的数据增强方法。它在疾病水平进行增强，提高疾病形态、位置、强度和负荷分布，并允许疾病填充和遮盖。经过不同Modalities和不同疾病数据集的测试，包括四个脑MR疾病数据集和一个肝CT疾病数据集，LesionMix在疾病图像分割中表现出了优秀的表现，比较其他最近的混合数据增强方法更高。代码将在https://github.com/dogabasaran/lesionmix上发布。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming"><a href="#Reinforcement-Learning-for-Battery-Management-in-Dairy-Farming" class="headerlink" title="Reinforcement Learning for Battery Management in Dairy Farming"></a>Reinforcement Learning for Battery Management in Dairy Farming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09023">http://arxiv.org/abs/2308.09023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nawazish Ali, Abdul Wahid, Rachael shaw, Karl Mason</li>
<li>For: 这个研究旨在适用人工智能（AI）于牛奶农业中的可再生能源应用，以降低电力成本并实现政府的能源和可持续发展目标。* Methods: 该研究使用Q学习算法学习可重复充电和充电牛奶农场中的策略。* Results: 研究发现，基于Q学习算法的策略可以效果地降低电力成本，与传统基准算法相比。这些结果表明Q学习算法在牛奶农业中的电池管理可以获得显著的效果。<details>
<summary>Abstract</summary>
Dairy farming is a particularly energy-intensive part of the agriculture sector. Effective battery management is essential for renewable integration within the agriculture sector. However, controlling battery charging/discharging is a difficult task due to electricity demand variability, stochasticity of renewable generation, and energy price fluctuations. Despite the potential benefits of applying Artificial Intelligence (AI) to renewable energy in the context of dairy farming, there has been limited research in this area. This research is a priority for Ireland as it strives to meet its governmental goals in energy and sustainability. This research paper utilizes Q-learning to learn an effective policy for charging and discharging a battery within a dairy farm setting. The results demonstrate that the developed policy significantly reduces electricity costs compared to the established baseline algorithm. These findings highlight the effectiveness of reinforcement learning for battery management within the dairy farming sector.
</details>
<details>
<summary>摘要</summary>
奶业是农业部分中特别占用能源的一部分。有效的电池管理是重要的，以实现农业部门中可再生能源的整合。然而，控制电池充电/充电是一项具有挑战性的任务，因为电力需求的变化、可再生能源的随机性和能源价格的波动。虽然在奶业中应用人工智能（AI）可以实现可再生能源的潜在利益，但是有限的研究在这个领域。这项研究利用Q学习学习一个有效的电池充电/充电策略，并在奶业设置下实现了显著减少电力成本的result。这些发现表明了Q学习在奶业中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Multi-field-Visualisation-via-Trait-induced-Merge-Trees"><a href="#Multi-field-Visualisation-via-Trait-induced-Merge-Trees" class="headerlink" title="Multi-field Visualisation via Trait-induced Merge Trees"></a>Multi-field Visualisation via Trait-induced Merge Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09015">http://arxiv.org/abs/2308.09015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jochen Jankowai, Talha Bin Masood, Ingrid Hotz</li>
<li>for: 这个论文旨在探讨tensor场或多变量数据的分析，通过特征级别集合的概念来扩展merge树。</li>
<li>methods: 本文使用特征空间中的特征定义来定义特征 trait，然后使用这些特征 trait 计算特征级别集合的距离场，从而实现特征级别集合的排序和查询。</li>
<li>results: 本文提出了一种基于特征 trait 的merge树，可以对tensor场或多变量数据进行有效的探讨和查询。三个案例研究证明了这种方法的十分适用性和普遍性。<details>
<summary>Abstract</summary>
In this work, we propose trait-based merge trees a generalization of merge trees to feature level sets, targeting the analysis of tensor field or general multi-variate data. For this, we employ the notion of traits defined in attribute space as introduced in the feature level sets framework. The resulting distance field in attribute space induces a scalar field in the spatial domain that serves as input for topological data analysis. The leaves in the merge tree represent those areas in the input data that are closest to the defined trait and thus most closely resemble the defined feature. Hence, the merge tree yields a hierarchy of features that allows for querying the most relevant and persistent features. The presented method includes different query methods for the tree which enable the highlighting of different aspects. We demonstrate the cross-application capabilities of this approach with three case studies from different domains.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了基于特征 trait-based 合并树，这是 merge tree 的一种普遍化，targeting  tensor field 或普通多变量数据的分析。为此，我们利用了 attribute space 中定义的特征（trait）的概念，如 feature level sets 框架中所介绍的。将 attribute space 中的距离场转换为 spatial domain 中的scalar场，以便在 topological data analysis 中使用。 merge tree 的叶节点表示输入数据中最近 trait 的区域，即最接近定义的特征的区域。因此，merge tree 提供了一个 Hierarchy of Features，可以对输入数据进行最相关和 persistente 特征的查询。我们还提供了不同的查询方法，以便高亮不同的方面。我们通过三个不同领域的案例，证明了这种方法的跨应用性。
</details></li>
</ul>
<hr>
<h2 id="Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals"><a href="#Deep-seeded-Clustering-for-Unsupervised-Valence-Arousal-Emotion-Recognition-from-Physiological-Signals" class="headerlink" title="Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals"></a>Deep-seeded Clustering for Unsupervised Valence-Arousal Emotion Recognition from Physiological Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09013">http://arxiv.org/abs/2308.09013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Dubois, Carlos Lima Azevedo, Sonja Haustein, Bruno Miranda</li>
<li>For: The paper is written for recognizing emotions from physiological and psychological data using unsupervised deep cluster methods.* Methods: The paper proposes an unsupervised deep cluster framework for emotion recognition, using deep k-means and deep c-means to distinguish the four quadrants of Russell’s circumplex model of affect.* Results: The tests on the open benchmark data set WESAD show that the proposed method achieves an overall accuracy of 87% in recognizing emotions from physiological and psychological data, without the need for labels.<details>
<summary>Abstract</summary>
Emotions play a significant role in the cognitive processes of the human brain, such as decision making, learning and perception. The use of physiological signals has shown to lead to more objective, reliable and accurate emotion recognition combined with raising machine learning methods. Supervised learning methods have dominated the attention of the research community, but the challenge in collecting needed labels makes emotion recognition difficult in large-scale semi- or uncontrolled experiments. Unsupervised methods are increasingly being explored, however sub-optimal signal feature selection and label identification challenges unsupervised methods' accuracy and applicability. This article proposes an unsupervised deep cluster framework for emotion recognition from physiological and psychological data. Tests on the open benchmark data set WESAD show that deep k-means and deep c-means distinguish the four quadrants of Russell's circumplex model of affect with an overall accuracy of 87%. Seeding the clusters with the subject's subjective assessments helps to circumvent the need for labels.
</details>
<details>
<summary>摘要</summary>
This article proposes an unsupervised deep cluster framework for emotion recognition from physiological and psychological data. The proposed method uses deep k-means and deep c-means to distinguish the four quadrants of Russell's circumplex model of affect, with an overall accuracy of 87%. Additionally, seeding the clusters with the subject's subjective assessments helps to circumvent the need for labels. Tests on the open benchmark data set WESAD demonstrate the effectiveness of the proposed method.
</details></li>
</ul>
<hr>
<h2 id="Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability"><a href="#Towards-Lightweight-Data-Integration-using-Multi-workflow-Provenance-and-Data-Observability" class="headerlink" title="Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability"></a>Towards Lightweight Data Integration using Multi-workflow Provenance and Data Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09004">http://arxiv.org/abs/2308.09004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renan Souza, Tyler J. Skluzacek, Sean R. Wilkinson, Maxim Ziatdinov, Rafael Ferreira da Silva</li>
<li>for: 这个论文的目的是探讨如何实现跨计算机中心的数据分析，以便在科学发现过程中实现负责任AI开发、可重复性、可访问性和用户指导。</li>
<li>methods: 该论文使用了数据可见性策略和适配器系统设计，以及证据来解决多种并行系统和机器学习工具之间的兼容性问题。</li>
<li>results: 实验结果表明，使用MIDA方法可以实现无 overhead的运行更多任务，并在 Summit 超级计算机上运行多达 276 个 GPU 并行。<details>
<summary>Abstract</summary>
Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.
</details>
<details>
<summary>摘要</summary>
现代大规模科学发现需要跨学科合作，包括高性能计算机（HPC）机器和边缘到云Continuum。集成数据分析在科学发现中扮演着关键角色，特别是在当今AI时代，可以实现负责任AI开发、FAIR、可重现和用户指导。然而，科学的多样性带来了多种支持工具、跨设施环境和高性能HPC执行的挑战。基于数据可见性、适配器系统设计和 provinidence，我们提出了MIDA：一种轻量级运行时多 workflow集成数据分析方法。MIDA定义了不同平台和机器学习工具的数据可见性策略和适配性方法。通过可见性，它在背景中 intercepts 数据流 Without requiring instrumentation，并在运行时将domain、provinidence和telemetry数据集成到一个统一的数据库中，准备好 для用户导航查询。我们在实验中通过结合 Dask 和 MLFlow 的数据来实现了端到端多 workflow分析，并在多个环境上并行运行了多达 276 个GPU。我们还显示了 near-zero 执行 overhead，在 Summit 超级计算机上运行了 Up to 100,000 任务，使用 1,680 个CPU核心。
</details></li>
</ul>
<hr>
<h2 id="DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering"><a href="#DealMVC-Dual-Contrastive-Calibration-for-Multi-view-Clustering" class="headerlink" title="DealMVC: Dual Contrastive Calibration for Multi-view Clustering"></a>DealMVC: Dual Contrastive Calibration for Multi-view Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09000">http://arxiv.org/abs/2308.09000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/dealmvc">https://github.com/xihongyang1999/dealmvc</a></li>
<li>paper_authors: Xihong Yang, Jiaqi Jin, Siwei Wang, Ke Liang, Yue Liu, Yi Wen, Suyuan Liu, Sihang Zhou, Xinwang Liu, En Zhu</li>
<li>for: 提高多视图 clustering 性能，解决跨视图场景下相似 yet different 样本的问题。</li>
<li>methods: 提出了一种 dual contrastive calibration network (DealMVC)，包括全局抽象特征生成、全局对比约束和本地对比约束等多种约束。</li>
<li>results: 在八个 benchmark 数据集上进行了广泛的实验，证明了 DealMVC 的效果和优越性，并将代码发布在 GitHub。<details>
<summary>Abstract</summary>
Benefiting from the strong view-consistent information mining capacity, multi-view contrastive clustering has attracted plenty of attention in recent years. However, we observe the following drawback, which limits the clustering performance from further improvement. The existing multi-view models mainly focus on the consistency of the same samples in different views while ignoring the circumstance of similar but different samples in cross-view scenarios. To solve this problem, we propose a novel Dual contrastive calibration network for Multi-View Clustering (DealMVC). Specifically, we first design a fusion mechanism to obtain a global cross-view feature. Then, a global contrastive calibration loss is proposed by aligning the view feature similarity graph and the high-confidence pseudo-label graph. Moreover, to utilize the diversity of multi-view information, we propose a local contrastive calibration loss to constrain the consistency of pair-wise view features. The feature structure is regularized by reliable class information, thus guaranteeing similar samples have similar features in different views. During the training procedure, the interacted cross-view feature is jointly optimized at both local and global levels. In comparison with other state-of-the-art approaches, the comprehensive experimental results obtained from eight benchmark datasets provide substantial validation of the effectiveness and superiority of our algorithm. We release the code of DealMVC at https://github.com/xihongyang1999/DealMVC on GitHub.
</details>
<details>
<summary>摘要</summary>
利用强大的视图一致信息挖掘能力，多视图对比 clustering 在最近几年内吸引了很多关注。然而，我们发现以下缺点，限制了 clustering 性能的进一步提高：现有的多视图模型主要关注同一个样本在不同视图中的一致性，而忽略了另一个样本在不同视图中的相似性。为解决这个问题，我们提出了一种新的对比抑制网络 для多视图 clustering（DealMVC）。 Specifically，我们首先设计了一种合并机制，以获得全局跨视图特征。然后，我们提出了一种全局对比抑制损失，通过对视图特征相似性图和高置信度假标签图进行对对比，并且使用可靠的类别信息来规范特征结构。此外，为了利用多视图信息的多样性，我们提出了一种本地对比抑制损失，以确保不同视图中的相似样本具有相似的特征。在训练过程中，交互式跨视图特征被联合地优化在本地和全局两级。与其他状态当前的方法进行比较，我们在八个benchmark数据集上获得了广泛的实验结果，这些结果证明了我们的算法的有效性和超越性。我们在 GitHub 上发布了 DealMVC 的代码，可以在 <https://github.com/xihongyang1999/DealMVC> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Reinforced-Self-Training-ReST-for-Language-Modeling"><a href="#Reinforced-Self-Training-ReST-for-Language-Modeling" class="headerlink" title="Reinforced Self-Training (ReST) for Language Modeling"></a>Reinforced Self-Training (ReST) for Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08998">http://arxiv.org/abs/2308.08998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas</li>
<li>for: 提高大型语言模型（LLM）的输出质量，通过人工反馈学习（RLHF）对其进行调整，使其更加符合人类的偏好。</li>
<li>methods: 我们提出了一种简单的算法，即增长批量学习（RL） inspirited Reinforced Self-Training（ReST），可以帮助RLHF方法更加高效。 ReST 使用了初始 LLM 策略，生成样本，并使用了离线 RL 算法来改善 LLM 策略。</li>
<li>results: 我们的结果表明，ReST 可以有效地提高翻译质量，并在计算和样本效率方面具有一定的优势。我们通过自动度量标准和人工评估在机器翻译benchmark上进行评估，并得到了良好的结果。<details>
<summary>Abstract</summary>
Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.
</details>
<details>
<summary>摘要</summary>
“强化学习从人类反馈（RLHF）可以提高大语言模型（LLM）的输出质量，使其与人类偏好更加一致。我们提出了一种简单的算法，称为强化自我培训（ReST），用于将 LLM 政策与人类偏好进行对齐。给定初始 LLM 策略，ReST 会生成一个数据集，并使用这些样本来改进 LLM 策略使用离线 RL 算法。ReST 比典型在线 RLHF 方法更加高效，因为它可以重用数据。虽然 ReST 是一种通用的方法，但我们在机器翻译中进行了专门的应用。我们的结果表明，ReST 可以在计算和样本效率的情况下提高翻译质量，并且可以通过自动评价指标和人类评价来证明这一点。”
</details></li>
</ul>
<hr>
<h2 id="Learning-representations-by-forward-propagating-errors"><a href="#Learning-representations-by-forward-propagating-errors" class="headerlink" title="Learning representations by forward-propagating errors"></a>Learning representations by forward-propagating errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09728">http://arxiv.org/abs/2308.09728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryoungwoo Jang</li>
<li>for: 这篇论文是为了提出一种轻量级、快速的学习算法，用于训练神经网络。</li>
<li>methods: 该算法基于前向传播方法，使用了数学几何中的双数概念。</li>
<li>results: 该算法比传统的后向传播法快速，可以在中央处理器（CPU）上实现快速的神经网络训练。<details>
<summary>Abstract</summary>
Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Back-propagation (BP) is widely used learning algorithm for neural network optimization. However, BP requires enormous computation cost and is too slow to train in central processing unit (CPU). Therefore current neural network optimizaiton is performed in graphical processing unit (GPU) with compute unified device architecture (CUDA) programming. In this paper, we propose a light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU. This algorithm is based on forward-propagating method, using concept of dual number in algebraic geometry." into Chinese (Simplified) answer:Back-propagation (BP) 是广泛使用的神经网络优化算法。然而，BP 需要巨大的计算成本， Training 在中央处理单元 (CPU) 太慢。因此，当前神经网络优化通常在图形处理单元 (GPU) 上使用 compute unified device architecture (CUDA) 编程。在这篇论文中，我们提出了一种轻量级、快速学习算法，在 CPU 上实现了 CUDA 加速器的速度。该算法基于前向传播方法，使用了代数几何中的 dual 数概念。
</details></li>
</ul>
<hr>
<h2 id="Neural-oscillators-for-generalization-of-physics-informed-machine-learning"><a href="#Neural-oscillators-for-generalization-of-physics-informed-machine-learning" class="headerlink" title="Neural oscillators for generalization of physics-informed machine learning"></a>Neural oscillators for generalization of physics-informed machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08989">http://arxiv.org/abs/2308.08989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Kapoor, Abhishek Chandra, Daniel M. Tartakovsky, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet</li>
<li>for: 提高物理学 Informed 机器学习（PIML）的泛化能力，尤其是面临复杂的物理问题时。</li>
<li>methods: 利用各种常微分方程（PDEs）的约束和时间序列特征，将PIML模型与回归神经网络结合，形成叫做神经振荡器的循环神经网络架构。</li>
<li>results: 通过有效地捕捉长期依赖关系和减少扩散和消失梯度问题，神经振荡器使PIML任务中的泛化能力得到了改进。在不同的约束和时间序列问题上进行了广泛的实验，并证明了该方法在评价指标上的优越性。<details>
<summary>Abstract</summary>
A primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.
</details>
<details>
<summary>摘要</summary>
primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.Here's the word-for-word translation in Simplified Chinese:physics-informed machine learning (PIML) 的主要挑战是其在训练领域之外的泛化，特别是在复杂的物理问题中表示为 partial differential equations (PDEs) 时。这篇文章目的是提高 PIML 的泛化能力，以便实际应用中具有准确预测未知区域的需求。我们利用 PDE 解的内在 causality 和时间序列特征来融合 PIML 模型和回归神经网络，基于系数 differential equations，称为神经振荡器。通过有效地捕捉长时间依赖关系和缓解扩散和消失梯度问题，神经振荡器促进了 PIML 任务中的泛化。广泛的实验，包括时间依赖非线性 PDE 和 biharmonic beam 方程，证明了我们的方法的有效性。在不同的纬度上，涂抹神经振荡器的方法超过了现有的状态之巅方法。因此，我们的方法提高了 PIML 的泛化能力，为推算和预测训练数据之外的精度提供了准确的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-the-biomimicry-gap-in-biohybrid-systems"><a href="#Quantifying-the-biomimicry-gap-in-biohybrid-systems" class="headerlink" title="Quantifying the biomimicry gap in biohybrid systems"></a>Quantifying the biomimicry gap in biohybrid systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08978">http://arxiv.org/abs/2308.08978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vaios Papaspyros, Guy Theraulaz, Clément Sire, Francesco Mondada</li>
<li>for: 这个论文的目的是用生物受体系（biohybrid system）来探索和识别动物的集体行为机制。</li>
<li>methods: 这篇论文使用了生物受体系，其中一个是一个模拟鲤鱼（rummy-nose tetra fish）的机器人骗吸，另一个是一个神经网络（NN）模型，用于生成生物受体系中的社交互动。</li>
<li>results: 经过实验和模拟，这个生物受体系能够模拟出真实的鲤鱼对话，并且能够在实际情况下维护高度的互动准确性。<details>
<summary>Abstract</summary>
Biohybrid systems in which robotic lures interact with animals have become compelling tools for probing and identifying the mechanisms underlying collective animal behavior. One key challenge lies in the transfer of social interaction models from simulations to reality, using robotics to validate the modeling hypotheses. This challenge arises in bridging what we term the "biomimicry gap", which is caused by imperfect robotic replicas, communication cues and physics constrains not incorporated in the simulations that may elicit unrealistic behavioral responses in animals. In this work, we used a biomimetic lure of a rummy-nose tetra fish (Hemigrammus rhodostomus) and a neural network (NN) model for generating biomimetic social interactions. Through experiments with a biohybrid pair comprising a fish and the robotic lure, a pair of real fish, and simulations of pairs of fish, we demonstrate that our biohybrid system generates high-fidelity social interactions mirroring those of genuine fish pairs. Our analyses highlight that: 1) the lure and NN maintain minimal deviation in real-world interactions compared to simulations and fish-only experiments, 2) our NN controls the robot efficiently in real-time, and 3) a comprehensive validation is crucial to bridge the biomimicry gap, ensuring realistic biohybrid systems.
</details>
<details>
<summary>摘要</summary>
生物混合系统中的机器人骗子与动物之间的互动已成为诱导和识别动物集体行为的有力工具。一个关键挑战在于将社交互动模型从模拟转移到现实中，使用机器人来验证模型假设。这个挑战是由我们称为“生物模仿差距”引起的，这是因为机器人的复制不准确、通信信号和物理约束不包括在模拟中，可能导致动物行为的不真实。在这项工作中，我们使用一个生物模仿的鲤鱼（Hemigrammus rhodostomus）和一个神经网络（NN）模型来生成生物模仿的社交互动。通过实验使用一个包括鱼和机器人骗子的生物混合对，一对真正的鱼对，以及模拟两个鱼对，我们表明了我们的生物混合系统可以生成高效环境中的社交互动，与真正的鱼对相似。我们的分析显示了以下结论：1）骗子和NN在实际互动中几乎保持和模拟中的互动一致，2）我们的NN可以在实时控制机器人，3）完整的验证是关键来跨越生物模仿差距，确保生物混合系统的真实性。
</details></li>
</ul>
<hr>
<h2 id="Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models"><a href="#Hitting-the-High-Dimensional-Notes-An-ODE-for-SGD-learning-dynamics-on-GLMs-and-multi-index-models" class="headerlink" title="Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models"></a>Hitting the High-Dimensional Notes: An ODE for SGD learning dynamics on GLMs and multi-index models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08977">http://arxiv.org/abs/2308.08977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizabeth Collins-Woodfin, Courtney Paquette, Elliot Paquette, Inbar Seroussi</li>
<li>for: 这篇论文研究了流动式梯度下降（SGD）在高维度情况下的动态，特别是在泛型线性模型和多指量模型（如逻辑回归、相位恢复）中的应用。</li>
<li>methods: 这篇论文使用了一个系统Ordinary differential equations（ODE）来描述SGD的动态，这个ODE可以涵盖各种统计量，如风险和优化度的度量。此外， authors还引入了一种简化的扩散积分（homogenized SGD），以便分析SGD迭代的动态。</li>
<li>results: 这篇论文提出了SGD的学习率阈值和稳定性的保证，并通过一些标准示例进行了数值实验，实验结果与理论结果几乎一致。<details>
<summary>Abstract</summary>
We analyze the dynamics of streaming stochastic gradient descent (SGD) in the high-dimensional limit when applied to generalized linear models and multi-index models (e.g. logistic regression, phase retrieval) with general data-covariance. In particular, we demonstrate a deterministic equivalent of SGD in the form of a system of ordinary differential equations that describes a wide class of statistics, such as the risk and other measures of sub-optimality. This equivalence holds with overwhelming probability when the model parameter count grows proportionally to the number of data. This framework allows us to obtain learning rate thresholds for stability of SGD as well as convergence guarantees. In addition to the deterministic equivalent, we introduce an SDE with a simplified diffusion coefficient (homogenized SGD) which allows us to analyze the dynamics of general statistics of SGD iterates. Finally, we illustrate this theory on some standard examples and show numerical simulations which give an excellent match to the theory.
</details>
<details>
<summary>摘要</summary>
我们分析流动式随机梯度下降（SGD）在高维度限制下的动态，当应用于泛化线性模型和多指标模型（例如逻辑回归、相位恢复）时。特别是，我们提出了SGD的权值等价物，即一个系数为普通 дифференциаль方程，描述了广泛的统计量，如风险和其他优化度量的扩展。这种等价性在数据个数增加时，几乎总是成立，并且允许我们获得SGD的学习率阈值以及稳定性保证。此外，我们还引入了一种简化的扩散率（混合SGD），使得我们可以分析SGD迭代的通用统计特性。最后，我们在一些标准例子中进行了数值仿真，并证明了理论与实际匹配得非常好。
</details></li>
</ul>
<hr>
<h2 id="Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank"><a href="#Cross-city-Few-Shot-Traffic-Forecasting-via-Traffic-Pattern-Bank" class="headerlink" title="Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank"></a>Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09727">http://arxiv.org/abs/2308.09727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhyliu00/tpb">https://github.com/zhyliu00/tpb</a></li>
<li>paper_authors: Zhanyu Liu, Guanjie Zheng, Yanwei Yu<br>for: 这个研究旨在提高城市间交通预测的性能，解决城市缺乏资料的问题。methods: 这个方法利用了跨城市几个shot的方法，通过将城市之间的交通模式汇集成一个Traffic Pattern Bank（TPB），从而将城市之间的交通模式转换为高维度的空间中。results: 实验结果显示，这个方法可以在真实的交通数据上进行预测，并且比较出performace的提升。<details>
<summary>Abstract</summary>
Traffic forecasting is a critical service in Intelligent Transportation Systems (ITS). Utilizing deep models to tackle this task relies heavily on data from traffic sensors or vehicle devices, while some cities might lack device support and thus have few available data. So, it is necessary to learn from data-rich cities and transfer the knowledge to data-scarce cities in order to improve the performance of traffic forecasting. To address this problem, we propose a cross-city few-shot traffic forecasting framework via Traffic Pattern Bank (TPB) due to that the traffic patterns are similar across cities. TPB utilizes a pre-trained traffic patch encoder to project raw traffic data from data-rich cities into high-dimensional space, from which a traffic pattern bank is generated through clustering. Then, the traffic data of the data-scarce city could query the traffic pattern bank and explicit relations between them are constructed. The metaknowledge is aggregated based on these relations and an adjacency matrix is constructed to guide a downstream spatial-temporal model in forecasting future traffic. The frequently used meta-training framework Reptile is adapted to find a better initial parameter for the learnable modules. Experiments on real-world traffic datasets show that TPB outperforms existing methods and demonstrates the effectiveness of our approach in cross-city few-shot traffic forecasting.
</details>
<details>
<summary>摘要</summary>
traffic 预测是智能交通系统（ITS）中的关键服务。使用深度模型来解决这个任务需要依赖于交通传感器或车辆设备上的数据，而一些城市可能缺乏设备支持，因此有少量可用的数据。因此，需要从数据丰富城市学习并传递知识到数据缺乏城市，以改善交通预测性能。为解决这个问题，我们提出了跨城市少量 traffic 预测框架，通过交通模式银行（TPB）。由于交通模式在城市之间相似，因此可以使用 pre-trained 交通覆盖器来将数据丰富城市的 raw 交通数据 проекed 到高维空间中，从而生成交通模式银行。然后，数据缺乏城市的交通数据可以查询交通模式银行，并构建了交通模式之间的显式关系。基于这些关系，我们可以归纳知识，并使用这些关系来导引下游的空间时间模型进行未来交通预测。我们使用现实世界交通数据进行实验，并证明了 TPB 在跨城市少量 traffic 预测中的效果。
</details></li>
</ul>
<hr>
<h2 id="CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation"><a href="#CONVERT-Contrastive-Graph-Clustering-with-Reliable-Augmentation" class="headerlink" title="CONVERT:Contrastive Graph Clustering with Reliable Augmentation"></a>CONVERT:Contrastive Graph Clustering with Reliable Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08963">http://arxiv.org/abs/2308.08963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xihongyang1999/convert">https://github.com/xihongyang1999/convert</a></li>
<li>paper_authors: Xihong Yang, Cheng Tan, Yue Liu, Ke Liang, Siwei Wang, Sihang Zhou, Jun Xia, Stan Z. Li, Xinwang Liu, En Zhu<br>for:* 这个研究目的是提出一个可靠的图像隐藏嵌入 clustering 方法，以解决现有方法对于隐藏嵌入的依赖性和可靠性的问题。methods:* 本方法使用一个叫做复原噪音网络 (Reversible Perturb-Recover Network, RPRN) 来处理数据增强，从而将隐藏嵌入中的 semantics 写入可靠的形式。* 此外，本方法还提出了一个新的内容损失函数 (Semantic Loss)，以保证隐藏嵌入中的 semantics 的可靠性。results:* 实验结果显示，本方法在七个数据集上具有优秀的效果，并且比较现有的方法有更好的可靠性和稳定性。<details>
<summary>Abstract</summary>
Contrastive graph node clustering via learnable data augmentation is a hot research spot in the field of unsupervised graph learning. The existing methods learn the sampling distribution of a pre-defined augmentation to generate data-driven augmentations automatically. Although promising clustering performance has been achieved, we observe that these strategies still rely on pre-defined augmentations, the semantics of the augmented graph can easily drift. The reliability of the augmented view semantics for contrastive learning can not be guaranteed, thus limiting the model performance. To address these problems, we propose a novel CONtrastiVe Graph ClustEring network with Reliable AugmenTation (COVERT). Specifically, in our method, the data augmentations are processed by the proposed reversible perturb-recover network. It distills reliable semantic information by recovering the perturbed latent embeddings. Moreover, to further guarantee the reliability of semantics, a novel semantic loss is presented to constrain the network via quantifying the perturbation and recovery. Lastly, a label-matching mechanism is designed to guide the model by clustering information through aligning the semantic labels and the selected high-confidence clustering pseudo labels. Extensive experimental results on seven datasets demonstrate the effectiveness of the proposed method. We release the code and appendix of CONVERT at https://github.com/xihongyang1999/CONVERT on GitHub.
</details>
<details>
<summary>摘要</summary>
<<SYS>> simult Vincent 翻译文本 into Simplified Chinese.<</SYS>>研究领域中的热点问题是无监督图学习中的对比性图节点聚合。现有方法通过学习预定的扩充来自动生成数据驱动的扩充。虽然这些策略已经实现了可观的聚合性能，但我们发现这些策略仍然 rely on pre-defined augmentations，对扩充后的图semantics的可靠性很难保证，因此限制模型性能。为解决这些问题，我们提出了一种名为 CONtrastiVe Graph ClustEring network with Reliable AugmenTation (COVERT)的新方法。具体来说，在我们的方法中，数据扩充被提posed reversible perturb-recover网络处理。它通过recovering the perturbed latent embeddings来浮雨reliable semantic information。此外，为了进一步保证semantics的可靠性，我们提出了一种新的semantic loss，用于via quantifying the perturbation and recovery。最后，为了引导模型，我们设计了一种label-matching机制，通过对semantic labels和选择高 confidence clustering pseudo labels进行对应，以确保模型的聚合性能。我们的实验结果表明，提出的方法效果显著。我们在 GitHub上发布了CONVERT的代码和补充文件，请参考https://github.com/xihongyang1999/CONVERT。
</details></li>
</ul>
<hr>
<h2 id="Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health"><a href="#Equitable-Restless-Multi-Armed-Bandits-A-General-Framework-Inspired-By-Digital-Health" class="headerlink" title="Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health"></a>Equitable Restless Multi-Armed Bandits: A General Framework Inspired By Digital Health</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09726">http://arxiv.org/abs/2308.09726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/socialgood">https://github.com/google-research/socialgood</a></li>
<li>paper_authors: Jackson A. Killian, Manish Jain, Yugang Jia, Jonathan Amar, Erich Huang, Milind Tambe</li>
<li>for: 这个论文旨在研究如何使用多臂摇树机制（Restless Multi-armed Bandits，RMAB）来实现公平的决策，特别是在数字医疗方面。</li>
<li>methods: 这篇论文使用了两种公平目标函数来衡量公平性：最小最大奖励和最大战略启发奖励。它们分别使用水满算法和聪明的抢夺策略来解决这些目标函数。</li>
<li>results: 在三个模拟领域中，包括一个新的数字医疗模型，这些方法能够明显提高公平性，而不是失去效率。这些结果表明，使用RMAB来实现公平的决策在实际应用中非常重要。代码可以在<a target="_blank" rel="noopener" href="https://github.com/google-research/socialgood/tree/equitable-rmab">https://github.com/google-research/socialgood/tree/equitable-rmab</a> 中找到。<details>
<summary>Abstract</summary>
Restless multi-armed bandits (RMABs) are a popular framework for algorithmic decision making in sequential settings with limited resources. RMABs are increasingly being used for sensitive decisions such as in public health, treatment scheduling, anti-poaching, and -- the motivation for this work -- digital health. For such high stakes settings, decisions must both improve outcomes and prevent disparities between groups (e.g., ensure health equity). We study equitable objectives for RMABs (ERMABs) for the first time. We consider two equity-aligned objectives from the fairness literature, minimax reward and max Nash welfare. We develop efficient algorithms for solving each -- a water filling algorithm for the former, and a greedy algorithm with theoretically motivated nuance to balance disparate group sizes for the latter. Finally, we demonstrate across three simulation domains, including a new digital health model, that our approaches can be multiple times more equitable than the current state of the art without drastic sacrifices to utility. Our findings underscore our work's urgency as RMABs permeate into systems that impact human and wildlife outcomes. Code is available at https://github.com/google-research/socialgood/tree/equitable-rmab
</details>
<details>
<summary>摘要</summary>
众臂多 armed bandit (RMAB) 是一种流行的算法决策框架，用于Sequential setting with limited resources。RMAB 在公共卫生、治疗安排、抗捕鱼和数字卫生等高度敏感的决策中被越来越广泛使用。为了确保高效性和避免群体之间的差异，我们研究了 equitable objectives for RMAB (ERMAB) 的第一次。我们考虑了两种与公平相关的目标函数，即最小最大奖励和最大 Nash 利益。我们开发了高效的算法来解决每一个，包括一种填充水的算法和一种基于理论上的细节来平衡不同群体的大小的排序算法。最后，我们在三个 simulate 领域中，包括一个新的数字卫生模型，证明了我们的方法可以在不做很大的牺牲下多达多少倍于当前状态的art 更加公平。我们的发现推动我们的工作的急需，因为 RMAB 在影响人类和野生动物的系统中普及。代码可以在 <https://github.com/google-research/socialgood/tree/equitable-rmab> 获取。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods"><a href="#A-Dual-Perspective-Approach-to-Evaluating-Feature-Attribution-Methods" class="headerlink" title="A Dual-Perspective Approach to Evaluating Feature Attribution Methods"></a>A Dual-Perspective Approach to Evaluating Feature Attribution Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08949">http://arxiv.org/abs/2308.08949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yawei Li, Yang Zhang, Kenji Kawaguchi, Ashkan Khakzar, Bernd Bischl, Mina Rezaei</li>
<li>for: 本文旨在批判现有的 faithfulness 评估方法，并提出两种新的评估方法，即 soundness 和 completeness。</li>
<li>methods: 本文使用了两种新的评估方法，即 soundness 和 completeness，它们都基于数学基础，并且可以通过高效的算法来计算。</li>
<li>results: 本文通过应用这两种评估方法，对主流的 attribute 方法进行了分析和比较，并发现了一些缺陷。<details>
<summary>Abstract</summary>
Feature attribution methods attempt to explain neural network predictions by identifying relevant features. However, establishing a cohesive framework for assessing feature attribution remains a challenge. There are several views through which we can evaluate attributions. One principal lens is to observe the effect of perturbing attributed features on the model's behavior (i.e., faithfulness). While providing useful insights, existing faithfulness evaluations suffer from shortcomings that we reveal in this paper. In this work, we propose two new perspectives within the faithfulness paradigm that reveal intuitive properties: soundness and completeness. Soundness assesses the degree to which attributed features are truly predictive features, while completeness examines how well the resulting attribution reveals all the predictive features. The two perspectives are based on a firm mathematical foundation and provide quantitative metrics that are computable through efficient algorithms. We apply these metrics to mainstream attribution methods, offering a novel lens through which to analyze and compare feature attribution methods.
</details>
<details>
<summary>摘要</summary>
<?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" /><?xml:namespace prefix = "w" ns = "urn:schemas-microsoft-com:office:word" />translate text into Simplified Chinese</SYS>特征归因方法试图解释神经网络预测的结果，并识别有关的特征。但是，建立一个完整的评估特征归因框架仍然是一个挑战。我们可以从多种角度来评估归因，其中一个主要的视角是观察归因特征的修改对模型行为的影响（即实践）。尽管提供了有用的洞察，但现有的实践评估受到一些缺陷，我们在这篇论文中揭露出这些缺陷。在这项工作中，我们提出了两种新的视角，它们是尊重性和完整性。尊重性评估归因特征是真正预测性的特征，而完整性评估总是否能够把预测特征全面地揭露出来。这两种视角基于坚实的数学基础，并提供了可计算的量化指标。我们应用这些指标到主流归因方法上，提供了一种新的评估特征归因方法的视角。Note: The above translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level"><a href="#Predicting-Crop-Yield-With-Machine-Learning-An-Extensive-Analysis-Of-Input-Modalities-And-Models-On-a-Field-and-sub-field-Level" class="headerlink" title="Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level"></a>Predicting Crop Yield With Machine Learning: An Extensive Analysis Of Input Modalities And Models On a Field and sub-field Level</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08948">http://arxiv.org/abs/2308.08948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Pathak, Miro Miranda, Francisco Mena, Cristhian Sanchez, Patrick Helber, Benjamin Bischke, Peter Habelitz, Hiba Najjar, Jayanth Siddamsetty, Diego Arenas, Michaela Vollmer, Marcela Charfuelan, Marlon Nuske, Andreas Dengel</li>
<li>for: 该论文旨在提出一种简单又有效的早期融合方法，用于预测农业产量，该方法可以处理不同的时间和空间分辨率输入数据。</li>
<li>methods: 该方法使用高分辨率农业产量地图作为真实数据来训练农作物和机器学习模型，并使用Sentinel-2卫星图像作为主要输入数据，并考虑其他补充模式，如天气、土壤和地形数据。</li>
<li>results: 该方法可以在全球范围内使用可用的输入模式，并且可以在不同地区、农作物和选择的模型中确定最佳输入模式。<details>
<summary>Abstract</summary>
We introduce a simple yet effective early fusion method for crop yield prediction that handles multiple input modalities with different temporal and spatial resolutions. We use high-resolution crop yield maps as ground truth data to train crop and machine learning model agnostic methods at the sub-field level. We use Sentinel-2 satellite imagery as the primary modality for input data with other complementary modalities, including weather, soil, and DEM data. The proposed method uses input modalities available with global coverage, making the framework globally scalable. We explicitly highlight the importance of input modalities for crop yield prediction and emphasize that the best-performing combination of input modalities depends on region, crop, and chosen model.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种简单 yet effective的早期融合方法 для农作物收成预测，该方法可以处理多个输入模式，每种模式具有不同的时间和空间分辨率。我们使用高分辨率农作物收成地图作为真实数据来训练农作物和机器学习模型无关方法。我们使用卫星影像作为主要输入数据，其他补充模式包括气象、土壤和 DEM 数据。我们的方法使用全球覆盖的输入数据，使得框架可以在全球范围内扩展。我们显式强调输入模式对农作物收成预测的重要性，并强调选择地区、农作物和模型而定的最佳输入模式组合。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Interpretable-Graph-Neural-Networks-for-Tabular-Data"><a href="#Interpretable-Graph-Neural-Networks-for-Tabular-Data" class="headerlink" title="Interpretable Graph Neural Networks for Tabular Data"></a>Interpretable Graph Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08945">http://arxiv.org/abs/2308.08945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amr Alkhatib, Sofiane Ennadir, Henrik Boström, Michalis Vazirgiannis</li>
<li>for: 本研究的目的是开发一种可解释的图 neural network（IGNNet），用于处理标量数据。</li>
<li>methods: IGNNet使用了一种新的学习策略，即强制学习算法生成可解释的模型，以便用户可以了解模型的逻辑。</li>
<li>results: 实验结果表明，IGNNet可以与当今最佳的机器学习算法相比，在处理标量数据方面表现出色，同时可以提供可解释的模型。<details>
<summary>Abstract</summary>
Data in tabular format is frequently occurring in real-world applications. Graph Neural Networks (GNNs) have recently been extended to effectively handle such data, allowing feature interactions to be captured through representation learning. However, these approaches essentially produce black-box models, in the form of deep neural networks, precluding users from following the logic behind the model predictions. We propose an approach, called IGNNet (Interpretable Graph Neural Network for tabular data), which constrains the learning algorithm to produce an interpretable model, where the model shows how the predictions are exactly computed from the original input features. A large-scale empirical investigation is presented, showing that IGNNet is performing on par with state-of-the-art machine-learning algorithms that target tabular data, including XGBoost, Random Forests, and TabNet. At the same time, the results show that the explanations obtained from IGNNet are aligned with the true Shapley values of the features without incurring any additional computational overhead.
</details>
<details>
<summary>摘要</summary>
<SYS> translates into</SYS>数据在表格格式下经常出现在实际应用中。图 neural networks（GNNs）在最近扩展以处理这类数据，以便捕捉特征相互作用。然而，这些方法基本上生成黑盒模型，即深度神经网络，禁止用户跟踪模型预测的逻辑。我们提出了一种方法，称为 IGNNet（可解释图 neural networks for 表格数据），它限制学习算法生成可解释模型，该模型显示从原始输入特征直接计算出模型预测的具体过程。我们进行了大规模的实验研究，显示IGNNet与目标 tabular 数据的状态态ART机器学习算法，包括 XGBoost、Random Forests 和 TabNet 的性能相当。同时，结果表明IGNNet 的解释与真实的 Shapley 值相吻合，无需增加计算开销。
</details></li>
</ul>
<hr>
<h2 id="Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces"><a href="#Causal-Adversarial-Perturbations-for-Individual-Fairness-and-Robustness-in-Heterogeneous-Data-Spaces" class="headerlink" title="Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces"></a>Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08938">http://arxiv.org/abs/2308.08938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ehyaei/CAPIFY">https://github.com/Ehyaei/CAPIFY</a></li>
<li>paper_authors: Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, Golnoosh Farnadi</li>
<li>for: 这个论文是为了同时探讨和结合个人公平、对抗攻击和结构 causal 模型在不同数据空间中的关系而写的。</li>
<li>methods: 该论文使用 causal 结构模型和敏感特征来创建一个公平度量，并将其应用于测试人员之间的 semantic 相似性。它还引入了一种新的 causal 对抗抑制和对 adversarial 训练，以创建一种新的敏感度量。</li>
<li>results: 该论文在真实世界和 sintetic 数据集上进行了评估，并示出了同时满足个人公平、对抗攻击和 causal 意识的精度 классифика器的可行性。<details>
<summary>Abstract</summary>
As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years. However, despite their individual significance, there remains a critical gap in simultaneously exploring and integrating these properties. In this paper, we propose a novel approach that examines the relationship between individual fairness, adversarial robustness, and structural causal models in heterogeneous data spaces, particularly when dealing with discrete sensitive attributes. We use causal structural models and sensitive attributes to create a fair metric and apply it to measure semantic similarity among individuals. By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier. Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness.
</details>
<details>
<summary>摘要</summary>
“responsible AI”在机器学习算法中的重要性日益增长，其中包括“公平”、“对抗攻击”和“ causality”等性能。然而，尽管它们各自的重要性，仍然存在一个重要的挑战是同时探索和 интегра这些性能。在这篇论文中，我们提出一种新的方法，检查个人公平、对抗攻击和结构性 causal 模型在不同数据空间中的关系，特别是在处理敏感特征时。我们使用 causal 结构模型和敏感特征来创建一个公平度量，并将其应用于度量个体之间的含义相似性。通过引入一种新的 causal 对抗扰动和应用对抗训练，我们创造了一种新的规则，将个体公平、对抗攻击和 causality 集成到分类器中。我们的方法在真实世界和 sintetic 数据集上进行了评估，并显示了同时实现公平、对抗攻击和 causality 的准确分类器。
</details></li>
</ul>
<hr>
<h2 id="Estimating-fire-Duration-using-regression-methods"><a href="#Estimating-fire-Duration-using-regression-methods" class="headerlink" title="Estimating fire Duration using regression methods"></a>Estimating fire Duration using regression methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08936">http://arxiv.org/abs/2308.08936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hansong Xiao</li>
<li>for: 本研究旨在提出机器学习方法来解决野火预测问题中的计算成本高和计算时间长问题。</li>
<li>methods: 本研究使用了随机森林、KNN和XGBoost回归模型，以及图像基于的CNN和编码器来预测野火燃烧时间。</li>
<li>results: 本研究通过对历史火灾数据和地形特征地图进行训练，并测试最新的实际值，提出了快速和相对准确的未来预测方法。<details>
<summary>Abstract</summary>
Wildfire forecasting problems usually rely on complex grid-based mathematical models, mostly involving Computational fluid dynamics(CFD) and Celluar Automata, but these methods have always been computationally expensive and difficult to deliver a fast decision pattern. In this paper, we provide machine learning based approaches that solve the problem of high computational effort and time consumption. This paper predicts the burning duration of a known wildfire by RF(random forest), KNN, and XGBoost regression models and also image-based, like CNN and Encoder. Model inputs are based on the map of landscape features provided by satellites and the corresponding historical fire data in this area. This model is trained by happened fire data and landform feature maps and tested with the most recent real value in the same area. By processing the input differently to obtain the optimal outcome, the system is able to make fast and relatively accurate future predictions based on landscape images of known fires.
</details>
<details>
<summary>摘要</summary>
通常情况下，野火预测问题采用复杂的格点基础数学模型，主要包括计算流体动力学（CFD）和细胞自动机，但这些方法总是 computationally  expensive 和困难以提供快速决策模式。在这篇论文中，我们提供了基于机器学习的方法，解决了高计算成本和时间消耗的问题。这篇论文预测已知的野火燃烧时间的RF（随机森林）、KNN和XGBoost等 regression 模型，以及图像基于的，如 CNN 和 Encoder。模型输入基于通过卫星提供的地形特征地图和相应的历史火灾数据。这个模型通过已发生过火灾数据和地形特征地图进行训练，并在同一地区测试最新的实际值。通过不同的处理输入来获得优化的结果，系统可以基于景观图像知道的火灾来做快速和相对准确的未来预测。
</details></li>
</ul>
<hr>
<h2 id="On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training"><a href="#On-Data-Imbalance-in-Molecular-Property-Prediction-with-Pre-training" class="headerlink" title="On Data Imbalance in Molecular Property Prediction with Pre-training"></a>On Data Imbalance in Molecular Property Prediction with Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08934">http://arxiv.org/abs/2308.08934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Limin Wang, Masatoshi Hanai, Toyotaro Suzumura, Shun Takashige, Kenjiro Taura</li>
<li>For: 本研究旨在提高分子性质预测模型的精度，解决传统的分子性质预测方法存在偏好性问题。* Methods: 本研究使用了一种组合方法，将理论计算与机器学习相结合，通过训练机器学习模型在一 subset of 理论计算结果上构建一个伪模型，以应用于剩下的材料。此外，还使用了预训练技术来提高机器学习模型的准确性。* Results: 本研究通过修改存在偏好性的损失函数，提高了预训练后的最终预测精度。通过实验和评估使用了标准的分子性质预测模型 benchmark，确认了我们的提案的有效性。<details>
<summary>Abstract</summary>
Revealing and analyzing the various properties of materials is an essential and critical issue in the development of materials, including batteries, semiconductors, catalysts, and pharmaceuticals. Traditionally, these properties have been determined through theoretical calculations and simulations. However, it is not practical to perform such calculations on every single candidate material. Recently, a combination method of the theoretical calculation and machine learning has emerged, that involves training machine learning models on a subset of theoretical calculation results to construct a surrogate model that can be applied to the remaining materials. On the other hand, a technique called pre-training is used to improve the accuracy of machine learning models. Pre-training involves training the model on pretext task, which is different from the target task, before training the model on the target task. This process aims to extract the input data features, stabilizing the learning process and improving its accuracy. However, in the case of molecular property prediction, there is a strong imbalance in the distribution of input data and features, which may lead to biased learning towards frequently occurring data during pre-training. In this study, we propose an effective pre-training method that addresses the imbalance in input data. We aim to improve the final accuracy by modifying the loss function of the existing representative pre-training method, node masking, to compensate the imbalance. We have investigated and assessed the impact of our proposed imbalance compensation on pre-training and the final prediction accuracy through experiments and evaluations using benchmark of molecular property prediction models.
</details>
<details>
<summary>摘要</summary>
描述和分析物质的各种性质是物料开发中不可或缺的一步，包括电池、半导体、催化剂和药品等。过去，这些性质通常通过理论计算和模拟来确定。但是，对每种候选材料都进行这些计算是不实际的。最近，一种结合理论计算和机器学习的方法在发展中，即通过训练机器学习模型在一部分理论计算结果基础上构建一个代理模型，以应用于剩下的材料。同时，一种称为预训练的技术也被应用，即在目标任务之前，通过不同于目标任务的预 Text task来训练模型，以提高模型的稳定性和准确性。但是，在分子性质预测中，输入数据和特征的分布存在强烈的不均衡，这可能导致在预训练时偏向频繁出现的数据进行偏袋学习。本研究提出了一种有效地平衡预训练方法，通过修改现有代表预训练方法的损失函数，以补偿输入数据的不均衡。我们通过实验和评估使用分子性质预测模型的标准套件进行了研究和评估。
</details></li>
</ul>
<hr>
<h2 id="IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making"><a href="#IMM-An-Imitative-Reinforcement-Learning-Approach-with-Predictive-Representation-Learning-for-Automatic-Market-Making" class="headerlink" title="IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making"></a>IMM: An Imitative Reinforcement Learning Approach with Predictive Representation Learning for Automatic Market Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08918">http://arxiv.org/abs/2308.08918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Niu, Siyuan Li, Jiahao Zheng, Zhouchi Lin, Jian Li, Jian Guo, Bo An</li>
<li>For:  This paper proposes a novel Reinforcement Learning (RL) framework called Imitative Market Maker (IMM) to develop multi-price level Market Making (MM) strategies efficiently.* Methods: IMM integrates effective state and action representations, representation learning, and imitation learning techniques to train the agent efficiently.* Results: The proposed IMM framework outperforms current RL-based market making strategies in terms of several financial criteria, and the ablation study substantiates the effectiveness of the model components.Here’s the same information in Simplified Chinese text:* For: 这篇论文提出了一种基于强化学习（RL）的新型市场制定（MM）策略框架，即模仿市场制定（IMM）。* Methods: IMM 使用有效的状态和动作表示，以及学习表示学习和模仿学习技术来训练代理人。* Results: 提议的 IMM 框架在实验中胜过当前RL基于市场制定策略，以许多金融指标为基准。 ablation 研究证明模型组件的有效性。<details>
<summary>Abstract</summary>
Market making (MM) has attracted significant attention in financial trading owing to its essential function in ensuring market liquidity. With strong capabilities in sequential decision-making, Reinforcement Learning (RL) technology has achieved remarkable success in quantitative trading. Nonetheless, most existing RL-based MM methods focus on optimizing single-price level strategies which fail at frequent order cancellations and loss of queue priority. Strategies involving multiple price levels align better with actual trading scenarios. However, given the complexity that multi-price level strategies involves a comprehensive trading action space, the challenge of effectively training profitable RL agents for MM persists. Inspired by the efficient workflow of professional human market makers, we propose Imitative Market Maker (IMM), a novel RL framework leveraging both knowledge from suboptimal signal-based experts and direct policy interactions to develop multi-price level MM strategies efficiently. The framework start with introducing effective state and action representations adept at encoding information about multi-price level orders. Furthermore, IMM integrates a representation learning unit capable of capturing both short- and long-term market trends to mitigate adverse selection risk. Subsequently, IMM formulates an expert strategy based on signals and trains the agent through the integration of RL and imitation learning techniques, leading to efficient learning. Extensive experimental results on four real-world market datasets demonstrate that IMM outperforms current RL-based market making strategies in terms of several financial criteria. The findings of the ablation study substantiate the effectiveness of the model components.
</details>
<details>
<summary>摘要</summary>
市场制作（MM）在金融交易中吸引了广泛的注意力，因为它为市场流动性做出了关键性的贡献。RL技术在量化交易中表现出色，但大多数现有的RL基于MM方法都是优化单价级别策略，这些策略在频繁的订单取消和队列优先级失去时会失败。使用多价级别策略更好地适应实际交易场景。然而，由于多价级别策略的复杂性，RL代理的训练问题仍然存在。受到专业人类市场制作者的有效工作流程启发，我们提出了Imitative Market Maker（IMM），一种新的RL框架，该框架通过结合优化信号基于专家和直接政策互动来快速发展多价级别MM策略。IMM从 introduce有效的状态和动作表示，并 integrate representation学习单元，以便更好地捕捉多价级别订单中的信息。然后，IMM采用了RL和仿制学习技术结合，通过经验策略来训练代理，从而实现高效的学习。实验结果表明，IMM在四个实际市场数据集上比现有的RL基于MM策略表现出较好的财务效果。简化研究的结果证明了模型组件的效果。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection"><a href="#Beyond-Sharing-Conflict-Aware-Multivariate-Time-Series-Anomaly-Detection" class="headerlink" title="Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection"></a>Beyond Sharing: Conflict-Aware Multivariate Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08915">http://arxiv.org/abs/2308.08915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawnvince/mts_cad">https://github.com/dawnvince/mts_cad</a></li>
<li>paper_authors: Haotian Si, Changhua Pei, Zhihan Li, Yadong Zhao, Jingjing Li, Haiming Zhang, Zulong Diao, Jianhui Li, Gaogang Xie, Dan Pei</li>
<li>for: 这个论文是为了提出一种基于多任务学习的多变量时间序列异常检测方法（CAD），以解决现有的异常检测方法存在冲突问题。</li>
<li>methods: 该方法使用了自适应的多任务学习模型，通过模仿多门混合专家（MMoE）的设计，解决各个指标之间的冲突问题。同时，该方法还提出了一种任务定向的指标选择和个性化和共享的闭合机制，以提高模型的性能。</li>
<li>results: 该方法在多个公共数据集上进行了评估，与现有方法相比，它的平均F1分数为0.943，显著超过了现有方法的性能。<details>
<summary>Abstract</summary>
Massive key performance indicators (KPIs) are monitored as multivariate time series data (MTS) to ensure the reliability of the software applications and service system. Accurately detecting the abnormality of MTS is very critical for subsequent fault elimination. The scarcity of anomalies and manual labeling has led to the development of various self-supervised MTS anomaly detection (AD) methods, which optimize an overall objective/loss encompassing all metrics' regression objectives/losses. However, our empirical study uncovers the prevalence of conflicts among metrics' regression objectives, causing MTS models to grapple with different losses. This critical aspect significantly impacts detection performance but has been overlooked in existing approaches. To address this problem, by mimicking the design of multi-gate mixture-of-experts (MMoE), we introduce CAD, a Conflict-aware multivariate KPI Anomaly Detection algorithm. CAD offers an exclusive structure for each metric to mitigate potential conflicts while fostering inter-metric promotions. Upon thorough investigation, we find that the poor performance of vanilla MMoE mainly comes from the input-output misalignment settings of MTS formulation and convergence issues arising from expansive tasks. To address these challenges, we propose a straightforward yet effective task-oriented metric selection and p&s (personalized and shared) gating mechanism, which establishes CAD as the first practicable multi-task learning (MTL) based MTS AD model. Evaluations on multiple public datasets reveal that CAD obtains an average F1-score of 0.943 across three public datasets, notably outperforming state-of-the-art methods. Our code is accessible at https://github.com/dawnvince/MTS_CAD.
</details>
<details>
<summary>摘要</summary>
巨大的关键性表现指标 (KPIs) 被监测为多变量时间序列数据 (MTS)，以确保软件应用程序和服务系统的可靠性。正确地探测 MTS 中的异常是非常关键的，以便随后的故障排除。由于罕见的异常和手动标注的缺乏，已经导致了多种自动化 MTS 异常检测 (AD) 方法的开发，这些方法通过优化总体的目标/损失函数来优化所有指标的回归目标/损失函数。然而，我们的实验发现，存在指标回归目标之间的冲突，导致 MTS 模型面临着不同的损失函数，这种问题在现有的方法中受到了忽视。为解决这个问题，我们采用了模仿多门混合专家 (MMoE) 的设计，并提出了 CAD，即冲突感知多变量 KPI 异常检测算法。CAD 提供了每个指标的独特结构，以避免 potential 冲突，同时推动指标之间的促进。经过了余地的调查，我们发现，普通的 MMoE 的性能问题主要来自 MTS 表示形式和输入输出不一致的问题，以及扩展任务的问题。为解决这些挑战，我们提出了一种简单 yet 有效的任务关注型指标选择和个性化阻塞机制，这使得 CAD 成为了首个实用多任务学习 (MTL) 基于 MTS AD 模型。经过了多个公共数据集的评估，我们发现，CAD 在三个公共数据集上的平均 F1-score 为 0.943，明显超过了当前的状态艺法。我们的代码可以在 GitHub 上找到：<https://github.com/dawnvince/MTS_CAD>。
</details></li>
</ul>
<hr>
<h2 id="MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling"><a href="#MoCLIM-Towards-Accurate-Cancer-Subtyping-via-Multi-Omics-Contrastive-Learning-with-Omics-Inference-Modeling" class="headerlink" title="MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling"></a>MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09725">http://arxiv.org/abs/2308.09725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai</li>
<li>for: This paper aims to improve cancer subtyping outcomes by fully exploiting the potential of multi-omics data.</li>
<li>methods: The paper proposes a representation learning framework called MoCLIM, which independently extracts informative features from distinct omics modalities and uses contrastive learning to integrate the features into a unified representation.</li>
<li>results: The experimental results on six cancer datasets demonstrate that the proposed approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances, and provides high interpretability in medical analysis.<details>
<summary>Abstract</summary>
Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances. Moreover, our framework incorporates various medical evaluations as the final component, providing high interpretability in medical analysis.
</details>
<details>
<summary>摘要</summary>
基础式个性化医学的目标是确定疾病子型的诱导关系。OMICS技术在肿瘤分型中发挥了革命性的作用，不同的OMICS数据记录肿瘤多步骤过程中的生化产物。本文将关注在完全利用多Omics数据来改进肿瘤分型结果方面，因此开发了MoCLIM表示学框架。MoCLIM独立提取不同Omics模式中的有用特征。通过对不同Omics模式的对比学习，我们可以将肿瘤分型下降到一个较低的Latent空间。这种对比可以被解释为生物网络中的Inter-Omics推理。实验结果表明，我们的方法可以在较少的高维度肿瘤实例中显著提高数据适应和分型性能。此外，我们的框架还可以 incorporate多种医学评估作为最后一个组件，提供高度可读性在医学分析中。
</details></li>
</ul>
<hr>
<h2 id="Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain"><a href="#Development-of-a-Knowledge-Graph-Embeddings-Model-for-Pain" class="headerlink" title="Development of a Knowledge Graph Embeddings Model for Pain"></a>Development of a Knowledge Graph Embeddings Model for Pain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08904">http://arxiv.org/abs/2308.08904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaya Chaturvedi, Tao Wang, Sumithra Velupillai, Robert Stewart, Angus Roberts</li>
<li>for: 这篇论文的目的是构建一个智能知识图库，以便更好地理解报病人所经历的痛苦，并在计算机可 tractable 的形式下进行 semantic 和上下文基于的推理。</li>
<li>methods: 该论文使用了知识图库 embedding 技术，将知识图库中的概念和关系转化为低维度向量空间中的表示，以便在下游任务中进行分类和链接预测。其中，外部医学知识库 SNOMED CT 中的各种关系可以提供有用的外部知识。</li>
<li>results: 该论文通过对精神医学电子健康纪录中的报病人痛苦概念进行EXTRACTION，并与 SNOMED CT 中的外部知识结合，构建了一个智能知识图库。该模型在主题-对象链接预测任务中的表现被评估，并与其他基eline模型进行比较。<details>
<summary>Abstract</summary>
Pain is a complex concept that can interconnect with other concepts such as a disorder that might cause pain, a medication that might relieve pain, and so on. To fully understand the context of pain experienced by either an individual or across a population, we may need to examine all concepts related to pain and the relationships between them. This is especially useful when modeling pain that has been recorded in electronic health records. Knowledge graphs represent concepts and their relations by an interlinked network, enabling semantic and context-based reasoning in a computationally tractable form. These graphs can, however, be too large for efficient computation. Knowledge graph embeddings help to resolve this by representing the graphs in a low-dimensional vector space. These embeddings can then be used in various downstream tasks such as classification and link prediction. The various relations associated with pain which are required to construct such a knowledge graph can be obtained from external medical knowledge bases such as SNOMED CT, a hierarchical systematic nomenclature of medical terms. A knowledge graph built in this way could be further enriched with real-world examples of pain and its relations extracted from electronic health records. This paper describes the construction of such knowledge graph embedding models of pain concepts, extracted from the unstructured text of mental health electronic health records, combined with external knowledge created from relations described in SNOMED CT, and their evaluation on a subject-object link prediction task. The performance of the models was compared with other baseline models.
</details>
<details>
<summary>摘要</summary>
痛苦是一个复杂的概念，可以与其他概念相连接，例如可能导致痛苦的疾病、可能使痛苦减轻的药物等。为了全面理解个人或人口所经历的痛苦Context，我们需要检查所有与痛苦相关的概念和它们之间的关系。这尤其有用于基于电子医疗记录的痛苦模型化。知识图表示概念和它们之间的关系，形成一个相互连接的网络，允许semantic和上下文基础的推理。但这些图可能太大，不可能进行有效的计算。知识图嵌入帮助解决这个问题，将图表示为一个低维度的 вектор空间中。这些嵌入可以在下游任务中使用，如分类和链接预测。对于痛苦的不同关系，可以从外部的医学知识库，如SNOMED CT，获取相关的概念和关系。建立如此的知识图可以通过实际世界中的痛苦和其关系，从电子医疗记录中提取来进一步填充。本文描述了基于痛苦概念的知识图嵌入模型的建立和评估，其中包括从痛苦文本中提取的不结构化数据，以及与SNOMED CT中的外部知识相结合。模型的性能与其他基eline模型进行比较。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning"><a href="#Optimal-Resource-Allocation-for-U-Shaped-Parallel-Split-Learning" class="headerlink" title="Optimal Resource Allocation for U-Shaped Parallel Split Learning"></a>Optimal Resource Allocation for U-Shaped Parallel Split Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08896">http://arxiv.org/abs/2308.08896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Lyu, Zheng Lin, Guanqiao Qu, Xianhao Chen, Xiaoxia Huang, Pan Li</li>
<li>for: 本研究旨在提出一种基于U型网络的分布式学习方法，以保护数据所有者的标签隐私。</li>
<li>methods: 本文提出了一种基于U型网络的分布式学习方法，其中早期层和末级层都放置在用户端，以避免泄露标签隐私。此外，文章还提出了一种名为LSCRA的资源分配算法，用于优化边缘网络的性能。</li>
<li>results: 实验结果表明，LSCRA算法可以有效地优化边缘网络的性能，并且U型PSL方法可以与其他SL基elines具有相似性能的同时保护标签隐私。<details>
<summary>Abstract</summary>
Split learning (SL) has emerged as a promising approach for model training without revealing the raw data samples from the data owners. However, traditional SL inevitably leaks label privacy as the tail model (with the last layers) should be placed on the server. To overcome this limitation, one promising solution is to utilize U-shaped architecture to leave both early layers and last layers on the user side. In this paper, we develop a novel parallel U-shaped split learning and devise the optimal resource optimization scheme to improve the performance of edge networks. In the proposed framework, multiple users communicate with an edge server for SL. We analyze the end-to-end delay of each client during the training process and design an efficient resource allocation algorithm, called LSCRA, which finds the optimal computing resource allocation and split layers. Our experimental results show the effectiveness of LSCRA and that U-shaped PSL can achieve a similar performance with other SL baselines while preserving label privacy. Index Terms: U-shaped network, split learning, label privacy, resource allocation, 5G/6G edge networks.
</details>
<details>
<summary>摘要</summary>
Split learning (SL) 已经出现为一种有前途的方法，用于模型训练而不泄露原始数据样本的拥有者。然而，传统的 SL 无法保护标签隐私，因为服务器上需要放置尾部模型（具有最后层）。为解决这个限制，一种有前途的解决方案是使用 U 型架构，以保留用户 сторо面上的早期层和尾部层。在这篇论文中，我们开发了一种新的并发 U 型 split learning 框架，并设计了优化性的资源分配策略，以提高边缘网络的性能。在我们的提案中，多个用户与边缘服务器进行 SL 通信。我们分析了每个客户端在训练过程中的末端延迟，并设计了一种高效的资源分配算法，称为 LSCRA，以找到最佳的计算资源分配和分割层。我们的实验结果表明 LSCRA 的有效性，并证明 U 型 PSL 可以在保持标签隐私的情况下达到类似的性能。关键字： U 型网络，split learning，标签隐私，资源分配，5G/6G 边缘网络。
</details></li>
</ul>
<hr>
<h2 id="Dual-Gauss-Newton-Directions-for-Deep-Learning"><a href="#Dual-Gauss-Newton-Directions-for-Deep-Learning" class="headerlink" title="Dual Gauss-Newton Directions for Deep Learning"></a>Dual Gauss-Newton Directions for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08886">http://arxiv.org/abs/2308.08886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincent Roulet, Mathieu Blondel</li>
<li>for: 这篇论文研究了如何使用深度学习目标结构，即几何函数和非线性网络的组合，以获得更好的方向指南，而不是使用渐进随机Gradient。</li>
<li>methods: 该论文提出了使用 dual 形式来计算方向指南，从而获得计算上的收益和新的理解。</li>
<li>results: 该论文实验表明，使用 dual 形式计算的方向指南可以用作现有优化算法中的替换，并且实际上表现出了更好的性能。<details>
<summary>Abstract</summary>
Inspired by Gauss-Newton-like methods, we study the benefit of leveraging the structure of deep learning objectives, namely, the composition of a convex loss function and of a nonlinear network, in order to derive better direction oracles than stochastic gradients, based on the idea of partial linearization. In a departure from previous works, we propose to compute such direction oracles via their dual formulation, leading to both computational benefits and new insights. We demonstrate that the resulting oracles define descent directions that can be used as a drop-in replacement for stochastic gradients, in existing optimization algorithms. We empirically study the advantage of using the dual formulation as well as the computational trade-offs involved in the computation of such oracles.
</details>
<details>
<summary>摘要</summary>
受加ус-新顿方法的启发，我们研究利用深度学习目标的结构，即几何函数和非线性网络的组合，以 derivate更好的方向指南。在之前的工作中，我们提议通过对调方式来计算这些方向指南，从而获得计算效益和新的理解。我们证明了这些方向指南可以作为现有优化算法中的替换，并进行实验研究其优势和计算交易。
</details></li>
</ul>
<hr>
<h2 id="Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task"><a href="#Feature-Enforcing-PINN-FE-PINN-A-Framework-to-Learn-the-Underlying-Physics-Features-Before-Target-Task" class="headerlink" title="Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task"></a>Feature Enforcing PINN (FE-PINN): A Framework to Learn the Underlying-Physics Features Before Target Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08873">http://arxiv.org/abs/2308.08873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Jahaninasab, Mohamad Ali Bijarchi</li>
<li>for: 这篇论文是为了解决各种分散方程（Partial Differential Equations，PDEs）的问题，并且可以实现低计算成本和快速训练。</li>
<li>methods: 这篇论文提出了一个新的数据自由框架（Feature Enforcing Physics Informed Neural Network，FE-PINN），可以在低计算成本下学习问题的基本模式。FE-PINN使用了一系列子任务，先从物理方面学习有用的特征，然后将模型训练到目标任务中以精确化计算。</li>
<li>results: FE-PINN可以在三个标准问题中实现15倍、2倍和5倍的速度提升，并且可以实现较低的损失值（1e-5），并且数据挥发过程较为平滑，可以使用更高的学习速率。这个框架可以用于解决各种PDEs领域中的问题，并且具有快速和精确的特点。<details>
<summary>Abstract</summary>
In this work, a new data-free framework called Feature Enforcing Physics Informed Neural Network (FE-PINN) is introduced. This framework is capable of learning the underlying pattern of any problem with low computational cost before the main training loop. The loss function of vanilla PINN due to the existence of two terms of partial differential residuals and boundary condition mean squared error is imbalanced. FE-PINN solves this challenge with just one minute of training instead of time-consuming hyperparameter tuning for loss function that can take hours. The FE-PINN accomplishes this process by performing a sequence of sub-tasks. The first sub-task learns useful features about the underlying physics. Then, the model trains on the target task to refine the calculations. FE-PINN is applied to three benchmarks, flow over a cylinder, 2D heat conduction, and an inverse problem of calculating inlet velocity. FE-PINN can solve each case with, 15x, 2x, and 5x speed up accordingly. Another advantage of FE-PINN is that reaching lower order of value for loss function is systematically possible. In this study, it was possible to reach a loss value near 1e-5 which is challenging for vanilla PINN. FE-PINN also has a smooth convergence process which allows for utilizing higher learning rates in comparison to vanilla PINN. This framework can be used as a fast, accurate tool for solving a wide range of Partial Differential Equations (PDEs) across various fields.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的数据自由框架，即特征强制物理学信息神经网络（FE-PINN）。这个框架可以在低计算成本下学习任务中的下面模式。 vanilla PINN 的损失函数由两个分量的 partial differential residuals 和 boundary condition mean squared error 组成，这两个分量的损失函数是不均衡的。FE-PINN 解决了这个挑战，只需要一分钟的训练时间，而不是浪费时间在hyperparameter tuning中。FE-PINN 通过执行一系列子任务来完成这个过程。首先，它学习了任务中的有用特征。然后，模型在目标任务上进行了细化计算。FE-PINN 应用于三个标准测试函数：流过圆柱、2D 热传导和反问题计算入口速度。在每个情况下，FE-PINN 可以达到15倍、2倍和5倍的速度提升。此外，FE-PINN 可以系统地降低损失函数的次数。在这种研究中，可以达到1e-5的损失值，这是vanilla PINN 所难以达到的。此外，FE-PINN 的 converges 过程是平滑的，因此可以使用高学习率，相比于vanilla PINN。这个框架可以作为一种快速、准确地解决各种 partial differential equations (PDEs) 的工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels"><a href="#Towards-Semi-supervised-Learning-with-Non-random-Missing-Labels" class="headerlink" title="Towards Semi-supervised Learning with Non-random Missing Labels"></a>Towards Semi-supervised Learning with Non-random Missing Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08872">http://arxiv.org/abs/2308.08872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/njuyued/prg4ssl-mnar">https://github.com/njuyued/prg4ssl-mnar</a></li>
<li>paper_authors: Yue Duan, Zhen Zhao, Lei Qi, Luping Zhou, Lei Wang, Yinghuan Shi</li>
<li>for: 解决labels缺失问题，实现效率地使用无标注数据。</li>
<li>methods: 基于Markov随机游走建立动态图，使用类转移跟踪信息获取类水平指导，保持模型免受类分布偏袋的影响。</li>
<li>results: 在多种实际MNAR场景中，PRG表现出色，与最新的SSL方法结合偏置除掉solution相比，提高了pseudo标签的质量。<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) tackles the label missing problem by enabling the effective usage of unlabeled data. While existing SSL methods focus on the traditional setting, a practical and challenging scenario called label Missing Not At Random (MNAR) is usually ignored. In MNAR, the labeled and unlabeled data fall into different class distributions resulting in biased label imputation, which deteriorates the performance of SSL models. In this work, class transition tracking based Pseudo-Rectifying Guidance (PRG) is devised for MNAR. We explore the class-level guidance information obtained by the Markov random walk, which is modeled on a dynamically created graph built over the class tracking matrix. PRG unifies the historical information of class distribution and class transitions caused by the pseudo-rectifying procedure to maintain the model's unbiased enthusiasm towards assigning pseudo-labels to all classes, so as the quality of pseudo-labels on both popular classes and rare classes in MNAR could be improved. Finally, we show the superior performance of PRG across a variety of MNAR scenarios, outperforming the latest SSL approaches combining bias removal solutions by a large margin. Code and model weights are available at https://github.com/NJUyued/PRG4SSL-MNAR.
</details>
<details>
<summary>摘要</summary>
半监督学习（SSL）处理缺失标签问题，使得无标签数据可以有效地使用。然而，现有的SSL方法往往忽略了实际和挑战性的情况，即标签缺失不均匀（MNAR）。在MNAR中，标签和无标签数据分布不同，导致假标签插入偏斜，从而降低SSL模型的性能。本文提出的类转移跟踪基于假正导航（PRG）方法，可以有效地解决MNAR中的标签缺失问题。我们利用Markov随机漫步模型来建立一个动态创建的图，并在图上获取类水平指导信息。PRG通过历史类分布和类转换的 dynamically created graph 来维护模型的偏离性，以确保假标签的质量在MNAR中都能得到改进。最后，我们在多种MNAR场景中证明PRG的超越性，与latest SSL方法组合偏移解决方案相比，差距非常大。代码和模型参数可以在https://github.com/NJUyued/PRG4SSL-MNAR 中下载。
</details></li>
</ul>
<hr>
<h2 id="Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games"><a href="#Model-Free-Algorithm-with-Improved-Sample-Efficiency-for-Zero-Sum-Markov-Games" class="headerlink" title="Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games"></a>Model-Free Algorithm with Improved Sample Efficiency for Zero-Sum Markov Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08858">http://arxiv.org/abs/2308.08858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songtao Feng, Ming Yin, Yu-Xiang Wang, Jing Yang, Yingbin Liang</li>
<li>for: 这个论文的目的是研究多智能体强化学习（RL）中的二 player零点Markov游戏问题。</li>
<li>methods: 这个论文提出了一种基于实际的stage-based Q学习算法，并证明了它可以达到最佳的样本复杂度 $O(H^3SAB&#x2F;\epsilon^2)$，这是对于观察 horizon $H$ 和状态数 $S$ 的依赖关系。</li>
<li>results: 这个论文的主要成果是通过引入variance reduction技术，使得model-free算法可以 дости到与model-based算法相同的最佳样本复杂度。此外，这个算法还提供了一种新的referenc-advantage decompositions技术，可以在Markov游戏中提高样本效率。<details>
<summary>Abstract</summary>
The problem of two-player zero-sum Markov games has recently attracted increasing interests in theoretical studies of multi-agent reinforcement learning (RL). In particular, for finite-horizon episodic Markov decision processes (MDPs), it has been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote the number of actions of the two players, respectively). However, none of the existing model-free algorithms can achieve such an optimality. In this work, we propose a model-free stage-based Q-learning algorithm and show that it achieves the same sample complexity as the best model-based algorithm, and hence for the first time demonstrate that model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based algorithms. The main improvement of the dependency on $H$ arises by leveraging the popular variance reduction technique based on the reference-advantage decomposition previously used only for single-agent RL. However, such a technique relies on a critical monotonicity property of the value function, which does not hold in Markov games due to the update of the policy via the coarse correlated equilibrium (CCE) oracle. Thus, to extend such a technique to Markov games, our algorithm features a key novel design of updating the reference value functions as the pair of optimistic and pessimistic value functions whose value difference is the smallest in the history in order to achieve the desired improvement in the sample efficiency.
</details>
<details>
<summary>摘要</summary>
“两个玩家零Sum Markov游戏的问题在多智能人工智能学习（RL）理论研究中受到了越来越多的关注。特别是在finite-horizon episodic Markov决策过程（MDP）中，已经证明了模型基于算法可以在$O(H^3SAB/\epsilon^2)$的样本复杂度下找到ε-优先 equilibria（NE），这是对于很大的horizon $H$和state $S$（其中 $A$ 和 $B$ 分别表示两个玩家的动作数）。然而，现有的模型自由算法无法达到这种优化。在这个工作中，我们提出了一种模型自由stage-based Q学习算法，并证明了它可以达到最佳模型基于算法的样本复杂度，因此在 $H$ 取值上first time demonstrates that model-free algorithms can enjoy the same optimality as model-based algorithms。主要改进来自于 $H$ 的依赖性，通过利用单个智能人工智能学习中广泛使用的变量减少技术，基于reference-advantage decompositions。然而，这种技术需要Markov游戏中值函数的强 monotonicity 属性，这并不是真实存在的。因此，我们的算法具有一个关键的新特点，即在历史中选择最小的值差来更新参考值函数，以达到所需的样本效率改进。”
</details></li>
</ul>
<hr>
<h2 id="Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays"><a href="#Bag-of-Tricks-for-Long-Tailed-Multi-Label-Classification-on-Chest-X-Rays" class="headerlink" title="Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays"></a>Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08853">http://arxiv.org/abs/2308.08853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Hong, Tianjie Dai, Jiangchao Yao, Ya Zhang, Yanfeng Wang</li>
<li>for: 这个研究是为了提高胸部X射影（CXR）诊断的Value，特别是面对长尾和多 label的挑战。</li>
<li>methods: 这个研究使用了多种进步的设计，包括数据增强、特征提取、分类器设计、损失函数重新平衡、外部数据补充等。</li>
<li>results: 这个研究获得了2023年ICCV CVAMD CXR-LT竞赛的第五名，其MAP值为0.349。<details>
<summary>Abstract</summary>
Clinical classification of chest radiography is particularly challenging for standard machine learning algorithms due to its inherent long-tailed and multi-label nature. However, few attempts take into account the coupled challenges posed by both the class imbalance and label co-occurrence, which hinders their value to boost the diagnosis on chest X-rays (CXRs) in the real-world scenarios. Besides, with the prevalence of pretraining techniques, how to incorporate these new paradigms into the current framework lacks of the systematical study. This technical report presents a brief description of our solution in the ICCV CVAMD 2023 CXR-LT Competition. We empirically explored the effectiveness for CXR diagnosis with the integration of several advanced designs about data augmentation, feature extractor, classifier design, loss function reweighting, exogenous data replenishment, etc. In addition, we improve the performance through simple test-time data augmentation and ensemble. Our framework finally achieves 0.349 mAP on the competition test set, ranking in the top five.
</details>
<details>
<summary>摘要</summary>
严重诊断涂整照片的机器学习算法受到胸部X射线（CXR）的自然长尾和多标签性的挑战。然而，目前的尝试很少考虑这两个挑战的同时存在，这限制了它们在真实世界场景中的价值。此外，随着预训练技术的普及，如何在当前框架中包含这些新 paradigma 尚未得到系统性的研究。本技术报告介绍我们在ICCV CVAMD 2023 CXR-LT竞赛中的解决方案。我们employs several advanced designs,包括数据扩充、特征提取器、分类器设计、损失函数重新权衡和外部数据补充等。此外，我们通过简单的测试时数据扩充和集成提高了性能。最终，我们的框架在竞赛测试集上达到了0.349 mAP，排名前五。
</details></li>
</ul>
<hr>
<h2 id="Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm"><a href="#Learning-the-hub-graphical-Lasso-model-with-the-structured-sparsity-via-an-efficient-algorithm" class="headerlink" title="Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm"></a>Learning the hub graphical Lasso model with the structured sparsity via an efficient algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08852">http://arxiv.org/abs/2308.08852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjing Wang, Peipei Tang, Wenling He, Meixia Lin</li>
<li>for: 这个论文的目的是提出一种高效的图模型预测算法，用于处理大量数据时的计算复杂问题。</li>
<li>methods: 该算法使用了两个阶段的方法：首先使用对偶替换法生成一个初始解，然后使用半软 Newton法进行修订。</li>
<li>results: 实验表明，该算法可以高效地计算图模型，并且在一些高维度任务中可以提高计算效率超过70%，同时仍然保持高质量的预测结果。<details>
<summary>Abstract</summary>
Graphical models have exhibited their performance in numerous tasks ranging from biological analysis to recommender systems. However, graphical models with hub nodes are computationally difficult to fit, particularly when the dimension of the data is large. To efficiently estimate the hub graphical models, we introduce a two-phase algorithm. The proposed algorithm first generates a good initial point via a dual alternating direction method of multipliers (ADMM), and then warm starts a semismooth Newton (SSN) based augmented Lagrangian method (ALM) to compute a solution that is accurate enough for practical tasks. The sparsity structure of the generalized Jacobian ensures that the algorithm can obtain a nice solution very efficiently. Comprehensive experiments on both synthetic data and real data show that it obviously outperforms the existing state-of-the-art algorithms. In particular, in some high dimensional tasks, it can save more than 70\% of the execution time, meanwhile still achieves a high-quality estimation.
</details>
<details>
<summary>摘要</summary>
文本翻译成简化中文：</SYS>图形模型在多种任务中表现出色，从生物分析到推荐系统。然而，含有中心节点的图形模型 computationally 困难于适应，特别是当数据维度很大时。为了高效地估算中心图形模型，我们提出了两相态算法。我们的算法首先使用 dual alternating direction method of multipliers (ADMM) 生成一个好的初始点，然后使用 semismooth Newton (SSN) 基于扩展拉格朗日方法 (ALM) 进行热开始，以计算一个够精确的解决方案。通过 generalized Jacobian 的稀疏结构，我们的算法可以很快获得一个好的解。经过对 synthetic data 和实际数据的广泛实验，我们发现我们的算法明显超越了现有的状态态算法，特别是在高维度任务中，可以save  более 70% 的执行时间，同时仍能达到高质量的估算。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation"><a href="#Machine-Learning-Assisted-Discovery-of-Novel-Reactor-Designs-via-CFD-Coupled-Multi-fidelity-Bayesian-Optimisation" class="headerlink" title="Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation"></a>Machine Learning-Assisted Discovery of Novel Reactor Designs via CFD-Coupled Multi-fidelity Bayesian Optimisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08841">http://arxiv.org/abs/2308.08841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Savage, Nausheen Basha, Jonathan McDonough, Omar K Matar, Ehecatl Antonio del Rio Chanona</li>
<li>For: The paper aims to establish a framework for the next-generation of reactors by leveraging additive manufacturing and intelligent design to improve the performance and sustainability of future chemical processes.* Methods: The authors propose two novel coiled-tube parameterisations that enable the variation of cross-section and coil path, and use multi-fidelity Bayesian optimisation to optimise the designs. They also employ parameterised meshing and simulation to reduce computational costs.* Results: The authors identify key characteristics of optimal reactor designs and experimentally validate two novel geometries that they 3D print. The results demonstrate the potential of the proposed framework for improving the performance and sustainability of future chemical processes.Here’s the simplified Chinese version:* For: 这篇论文目标是建立未来化学过程中的下一代循环器，通过添加制造和智能设计来提高性能和可持续性。* Methods: 作者提出了两种新的卷积管参数化，允许横截面和卷积路径的变化，并使用多质量湾esian优化来优化设计。他们还使用参数化的网格和模拟来降低计算成本。* Results: 作者确定了优化循环器设计的关键特征，并实验验证了两种新的循环器 geometries。结果表明，提案的框架可以提高未来化学过程的性能和可持续性。<details>
<summary>Abstract</summary>
Additive manufacturing has enabled the production of more advanced reactor geometries, resulting in the potential for significantly larger and more complex design spaces. Identifying and optimising promising configurations within broader design spaces presents a significant challenge for existing human-centric design approaches. As such, existing parameterisations of coiled-tube reactor geometries are low-dimensional with expensive optimisation limiting more complex solutions. Given algorithmic improvements and the onset of additive manufacturing, we propose two novel coiled-tube parameterisations enabling the variation of cross-section and coil path, resulting in a series of high dimensional, complex optimisation problems. To ensure tractable, non-local optimisation where gradients are not available, we apply multi-fidelity Bayesian optimisation. Our approach characterises multiple continuous fidelities and is coupled with parameterised meshing and simulation, enabling lower quality, but faster simulations to be exploited throughout optimisation. Through maximising the plug-flow performance, we identify key characteristics of optimal reactor designs, and extrapolate these to produce two novel geometries that we 3D print and experimentally validate. By demonstrating the design, optimisation, and manufacture of highly parameterised reactors, we seek to establish a framework for the next-generation of reactors, demonstrating that intelligent design coupled with new manufacturing processes can significantly improve the performance and sustainability of future chemical processes.
</details>
<details>
<summary>摘要</summary>
Traditional design approaches for coiled-tube reactors have been limited by low-dimensional parameterizations and expensive optimization methods, which have restricted the exploration of more complex and promising configurations. With the advent of additive manufacturing, we propose two novel coiled-tube parameterizations that enable the variation of cross-section and coil path, leading to a series of high-dimensional, complex optimization problems. To tackle these problems, we employ a multi-fidelity Bayesian optimization approach that integrates parameterized meshing and simulation, allowing for efficient exploration of the design space. By optimizing the plug-flow performance, we identify key characteristics of optimal reactor designs and experimentally validate them through 3D printing and experimental testing. Our findings establish a framework for the next-generation of reactors, demonstrating that intelligent design coupled with advanced manufacturing processes can significantly improve the performance and sustainability of future chemical processes.
</details></li>
</ul>
<hr>
<h2 id="ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space"><a href="#ICoNIK-Generating-Respiratory-Resolved-Abdominal-MR-Reconstructions-Using-Neural-Implicit-Representations-in-k-Space" class="headerlink" title="ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space"></a>ICoNIK: Generating Respiratory-Resolved Abdominal MR Reconstructions Using Neural Implicit Representations in k-Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08830">http://arxiv.org/abs/2308.08830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Spieker, Wenqi Huang, Hannah Eichhorn, Jonathan Stelter, Kilian Weiss, Veronika A. Zimmer, Rickmer F. Braren, Dimitrios C. Karampinos, Kerstin Hammernik, Julia A. Schnabel</li>
<li>for: 这个论文旨在提出一种基于神经网络的扩展幂等方法，以解决静脉磁共振成像（MRI）中的运动融合问题。</li>
<li>methods: 这个论文使用了一种基于神经网络的直接在k空间中学习方法（NIK），通过使用测量的抽取点和数据驱动的呼吸导航信号，来生成连续的信号值。此外，论文还引入了一种有 информацию的修正层（ICo），以正则化缺失样本区域。</li>
<li>results: 论文的实验结果表明，NIK和ICoNIK方法可以超越标准的运动融合重建方法，并提供了一种有 Promise的解决方案，以解决静脉磁共振成像中的运动artefacts问题。<details>
<summary>Abstract</summary>
Motion-resolved reconstruction for abdominal magnetic resonance imaging (MRI) remains a challenge due to the trade-off between residual motion blurring caused by discretized motion states and undersampling artefacts. In this work, we propose to generate blurring-free motion-resolved abdominal reconstructions by learning a neural implicit representation directly in k-space (NIK). Using measured sampling points and a data-derived respiratory navigator signal, we train a network to generate continuous signal values. To aid the regularization of sparsely sampled regions, we introduce an additional informed correction layer (ICo), which leverages information from neighboring regions to correct NIK's prediction. Our proposed generative reconstruction methods, NIK and ICoNIK, outperform standard motion-resolved reconstruction techniques and provide a promising solution to address motion artefacts in abdominal MRI.
</details>
<details>
<summary>摘要</summary>
对于腹部磁共振成像（MRI）中的运动解析仍然是一个挑战，这是因为运动状态的精细化会导致剩下的运动抑制和抽象缺失的问题。在这项工作中，我们提出了一种通过直接在k空间学习神经网络（NIK）来生成无抑制的运动解析图像。使用测量的抽象点和数据驱动的呼吸导航信号，我们在网络中训练了连续的信号值。为了帮助稀疏抽象区域的正则化，我们引入了一个知情更正层（ICo），该层利用周围区域的信息来修正NIK的预测。我们的提议的生成重建方法，NIK和ICoNIK，在标准运动解析重建技术的基础上超越，并提供了对运动缺失的可能解决方案。
</details></li>
</ul>
<hr>
<h2 id="Controlling-Federated-Learning-for-Covertness"><a href="#Controlling-Federated-Learning-for-Covertness" class="headerlink" title="Controlling Federated Learning for Covertness"></a>Controlling Federated Learning for Covertness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08825">http://arxiv.org/abs/2308.08825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adit Jain, Vikram Krishnamurthy</li>
<li>for: 本研究旨在减少一个函数 $f$ 的值，同时隐藏 $\arg\min f$  FROM 一个恶意窃听者。</li>
<li>methods: 本研究使用了 Markov decision process 模型来控制随机 gradient 算法，并提出了一种 computationally efficient policy gradient algorithm。</li>
<li>results: 数值结果显示，当学习者使用优化策略时，恶意窃听者只能在无信息情况下达到 $52%$ 的验证精度，而在拥有公共数据集的情况下，恶意窃听者只能达到 $69%$ 的验证精度，与学习者使用排队策略相比，恶意窃听者可以达到 $83%$ 的验证精度。<details>
<summary>Abstract</summary>
A learner aims to minimize a function $f$ by repeatedly querying a distributed oracle that provides noisy gradient evaluations. At the same time, the learner seeks to hide $\arg\min f$ from a malicious eavesdropper that observes the learner's queries. This paper considers the problem of \textit{covert} or \textit{learner-private} optimization, where the learner has to dynamically choose between learning and obfuscation by exploiting the stochasticity. The problem of controlling the stochastic gradient algorithm for covert optimization is modeled as a Markov decision process, and we show that the dynamic programming operator has a supermodular structure implying that the optimal policy has a monotone threshold structure. A computationally efficient policy gradient algorithm is proposed to search for the optimal querying policy without knowledge of the transition probabilities. As a practical application, our methods are demonstrated on a hate speech classification task in a federated setting where an eavesdropper can use the optimal weights to generate toxic content, which is more easily misclassified. Numerical results show that when the learner uses the optimal policy, an eavesdropper can only achieve a validation accuracy of $52\%$ with no information and $69\%$ when it has a public dataset with 10\% positive samples compared to $83\%$ when the learner employs a greedy policy.
</details>
<details>
<summary>摘要</summary>
学生希望减少函数 $f$ 的值，通过 repeatedly 查询分布式 oracle 提供的噪声梯度评估。同时，学生希望隐藏 $\arg\min f$ 从一个恶意窃听者的观察。这篇论文考虑了 covert 或 learner-private 优化问题，其中学生需要在权衡学习和隐蔽之间 dynamically 选择。我们模型了控制随机梯度算法的 Markov 决策过程，并证明优化问题的动态 програм环境有超模ular 结构，这 imply 优化策略具有 monotone 阈值结构。我们提出了一种 computationally 高效的策略梯度算法，可以在不知道过渡概率的情况下搜索优化策略。在实际应用中，我们在一个 federated 环境中进行了一个 hate speech 分类任务，其中一个窃听者可以使用优化后的权重生成恶意内容，这种内容更易被识别。numerical 结果表明，当学生使用优化策略时，窃听者只能在没有信息的情况下 achieves 52% 的验证精度，而在 possession 10% 正例样本的情况下，窃听者只能 achieves 69% 的验证精度，与学生使用恶性策略时的精度相比。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning"><a href="#Mitigating-Semantic-Confusion-from-Hostile-Neighborhood-for-Graph-Active-Learning" class="headerlink" title="Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning"></a>Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08823">http://arxiv.org/abs/2308.08823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianmeng Yang, Min Zhou, Yujing Wang, Zhengjie Lin, Lujia Pan, Bin Cui, Yunhai Tong</li>
<li>for: 提高图像神经网络（GNNs）性能，通过在图像中选择最有用的节点进行标注。</li>
<li>methods: 提出了一种Semantic-aware Active learning framework for Graphs（SAG），通过对节点之间的对比来评估节点的影响，并设计了一种新的原型基于的评价标准和查询策略来保持节点的多样性和分类均衡。</li>
<li>results: 对公共测试图和一个真实世界金融数据集进行了广泛的实验，并证明了SAG可以显著提高节点分类性能，并常常超越先前的方法。<details>
<summary>Abstract</summary>
Graph Active Learning (GAL), which aims to find the most informative nodes in graphs for annotation to maximize the Graph Neural Networks (GNNs) performance, has attracted many research efforts but remains non-trivial challenges. One major challenge is that existing GAL strategies may introduce semantic confusion to the selected training set, particularly when graphs are noisy. Specifically, most existing methods assume all aggregating features to be helpful, ignoring the semantically negative effect between inter-class edges under the message-passing mechanism. In this work, we present Semantic-aware Active learning framework for Graphs (SAG) to mitigate the semantic confusion problem. Pairwise similarities and dissimilarities of nodes with semantic features are introduced to jointly evaluate the node influence. A new prototype-based criterion and query policy are also designed to maintain diversity and class balance of the selected nodes, respectively. Extensive experiments on the public benchmark graphs and a real-world financial dataset demonstrate that SAG significantly improves node classification performances and consistently outperforms previous methods. Moreover, comprehensive analysis and ablation study also verify the effectiveness of the proposed framework.
</details>
<details>
<summary>摘要</summary>
格Active学习（GAL），旨在在图中找出最有信息的节点进行标注，以最大化图内 нейрон网络（GNNs）性能，已经吸引了许多研究努力，但仍存在许多挑战。一个主要挑战是现有GAL策略可能会在选择训练集时引入semantic confusion，特别是当图像具有噪音时。现有方法几乎所有的聚合特征都被视为有用，忽略了在消息传递机制下 интер-类边的semantic负面效果。在这项工作中，我们提出了Semantic-aware Active learning Framework for Graphs（SAG），以 Mitigate semantic confusion problem。节点之间的对比相似性和不同性，以及节点的semantic特征被引入，以同时评估节点的影响力。我们还设计了一种新的原型基于准则和查询策略，以保持选择节点的多样性和类别均衡。extensive experiments表明，SAG在公共 benchmark graphs 和一个实际的金融数据集上显著提高节点分类性能，并在前一些方法之上出现consistently。此外，我们还进行了完整的分析和剖析研究，以证明提案的有效性。
</details></li>
</ul>
<hr>
<h2 id="A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction"><a href="#A-Fusion-of-Variational-Distribution-Priors-and-Saliency-Map-Replay-for-Continual-3D-Reconstruction" class="headerlink" title="A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction"></a>A Fusion of Variational Distribution Priors and Saliency Map Replay for Continual 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08812">http://arxiv.org/abs/2308.08812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanchar Palit, Sandika Biswas</li>
<li>for: 这种研究旨在预测单个图像中的3D对象形状。</li>
<li>methods: 该方法使用Variational Priors来设计模型，以确保在新类的训练后仍能reasonably重建之前看到的类。</li>
<li>results: 经验表明，该方法可以与已有方法相比， Both quantitatively and qualitatively提供竞争力强的结果。<details>
<summary>Abstract</summary>
Single-image 3D reconstruction is a research challenge focused on predicting 3D object shapes from single-view images. This task requires significant data acquisition to predict both visible and occluded portions of the shape. Furthermore, learning-based methods face the difficulty of creating a comprehensive training dataset for all possible classes. To this end, we propose a continual learning-based 3D reconstruction method where our goal is to design a model using Variational Priors that can still reconstruct the previously seen classes reasonably even after training on new classes. Variational Priors represent abstract shapes and combat forgetting, whereas saliency maps preserve object attributes with less memory usage. This is vital due to resource constraints in storing extensive training data. Additionally, we introduce saliency map-based experience replay to capture global and distinct object features. Thorough experiments show competitive results compared to established methods, both quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>单图3D重建是一项研究挑战，旨在从单个视图图像中预测3D物体形状。这个任务需要大量数据收集，以预测可见和遮盖的部分。学习基于方法面临的挑战是创建全面训练数据集 для所有可能的类。为此，我们提议一种持续学习基于Variational Priors的3D重建方法，目标是使用Variational Priors来表示抽象形状，并使得已经训练过的类可以reasonably重建。Variational Priors战胜忘记，而saliency maps保留物体特征具有较少的内存使用。这是因为训练数据存储具有资源约束。此外，我们引入saliency map基于经验回放，以捕捉全球和特定物体特征。经过全面的实验，我们的方法与已知方法相比，具有竞争力的结果 both quantitatively and qualitatively。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts"><a href="#Label-Shift-Adapter-for-Test-Time-Adaptation-under-Covariate-and-Label-Shifts" class="headerlink" title="Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts"></a>Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08810">http://arxiv.org/abs/2308.08810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun</li>
<li>for: 这篇研究的目的是提出一种可以在批处理时进行适应，以适应目标频谱中的标签分布偏移。</li>
<li>methods: 本研究使用了现有的TTA方法，并添加了一种标签偏移适应器来处理标签偏移。</li>
<li>results: 研究表明，通过将标签偏移适应器与TTA方法结合使用，可以在批处理时进行有效的适应，并且可以提高模型的性能在标签和covariate偏移的情况下。<details>
<summary>Abstract</summary>
Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation"><a href="#Capturing-Popularity-Trends-A-Simplistic-Non-Personalized-Approach-for-Enhanced-Item-Recommendation" class="headerlink" title="Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation"></a>Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08799">http://arxiv.org/abs/2308.08799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingxiaoyi/pare">https://github.com/jingxiaoyi/pare</a></li>
<li>paper_authors: Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen</li>
<li>for: 本研究旨在提供一种不具体化推荐方法，以适应用户的选择习惯和Item的流行度变化。</li>
<li>methods: 本方法包括四个模块：历史人气、时间影响、周期影响和Side信息。这些模块都集中在预测Item的流行度上。最后，一个注意层用于融合这四个模块的输出。</li>
<li>results: 实验结果表明，PARE可以和现有的先进推荐方法相比，具有相似或更高的性能。此外，PARE可以轻松地与现有的推荐方法结合使用，从而提高总的性能。<details>
<summary>Abstract</summary>
Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.
</details>
<details>
<summary>摘要</summary>
“推荐系统在年年都获得更多的研究注意力。现有的大多数推荐方法强调 recording 用户对项目的个人化偏好，这可能会侵犯用户隐私。此外，这些方法通常忽略项目的时间影响和周期性，这可能会影响用户的决策。为了填补这个差距，我们提出了 Popularity-Aware Recommender（PARE），它预测项目将在未来获得最高人气。PARE 由四个模块组成：历史人气、时间影响、周期影响和副资料。最后，我们使用注意力层进行融合。根据我们所知，这是第一个针对推荐系统中项目人气的明确模型。我们的实验显示，PARE 与现有的先进推荐方法相比，在许多情况下表现相似或甚至更好。由于 PARE 将人气优先顺位推荐，因此它可以强化现有的推荐方法，成为辅助性的一部分。我们的实验显示，将 PARE 与现有的推荐方法结合，对推荐性能有着明显的提升。此外，PARE 的简单性使其在工业应用中实际和有用，并且成为未来研究的良好基础。”
</details></li>
</ul>
<hr>
<h2 id="Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data"><a href="#Joint-Local-Relational-Augmentation-and-Global-Nash-Equilibrium-for-Federated-Learning-with-Non-IID-Data" class="headerlink" title="Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data"></a>Joint Local Relational Augmentation and Global Nash Equilibrium for Federated Learning with Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11646">http://arxiv.org/abs/2308.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Chaochao Chen, Weiming Liu, Pengyang Zhou, Huabin Zhu, Shuheng Shen, Weiqiang Wang, Mengling Hu, Yanchao Tan, Xiaolin Zheng</li>
<li>for: 提高 Federated Learning (FL) 在实际应用中的效果，解决非独立和同分布 (non-IID) 数据模型下的问题。</li>
<li>methods: 提出 FedRANE 方法，包括两个主要模块：本地关系增强 (LRA) 和全局尼亚希 equilibrium (GNE)，同时解决 intra-和 inter-客户端不一致性问题。</li>
<li>results: 在四个基准数据集上进行了广泛的实验，证明 FedRANE 能够提高 FL 在非独立和同分布数据下的性能。<details>
<summary>Abstract</summary>
Federated learning (FL) is a distributed machine learning paradigm that needs collaboration between a server and a series of clients with decentralized data. To make FL effective in real-world applications, existing work devotes to improving the modeling of decentralized data with non-independent and identical distributions (non-IID). In non-IID settings, there are intra-client inconsistency that comes from the imbalanced data modeling, and inter-client inconsistency among heterogeneous client distributions, which not only hinders sufficient representation of the minority data, but also brings discrepant model deviations. However, previous work overlooks to tackle the above two coupling inconsistencies together. In this work, we propose FedRANE, which consists of two main modules, i.e., local relational augmentation (LRA) and global Nash equilibrium (GNE), to resolve intra- and inter-client inconsistency simultaneously. Specifically, in each client, LRA mines the similarity relations among different data samples and enhances the minority sample representations with their neighbors using attentive message passing. In server, GNE reaches an agreement among inconsistent and discrepant model deviations from clients to server, which encourages the global model to update in the direction of global optimum without breaking down the clients optimization toward their local optimums. We conduct extensive experiments on four benchmark datasets to show the superiority of FedRANE in enhancing the performance of FL with non-IID data.
</details>
<details>
<summary>摘要</summary>
federated 学习（FL）是一种分布式机器学习模式，需要服务器和多个客户端之间的合作，以便处理 Decentralized 数据。为了在实际应用中使 FL 有效，现有的工作主要关注于改进非独立和相同分布（non-IID）的数据模型。在非独立设置中，存在客户端内的不一致性，来自不均匀数据模型的偏好，以及客户端之间的不一致性，这不仅限制了少数据的充分表示，还导致模型偏差不一致。然而，先前的工作忽视了同时解决上述两个 coupling 不一致性。在这种情况下，我们提出了 FedRANE，它包括两个主要模块：本地关系增强（LRA）和全局尼亚希尔（GNE）。具体来说，在每个客户端中，LRA 挖掘不同数据样本之间的相似关系，并使用敏感消息传递来增强少数据表示。在服务器端，GNE 达成了客户端和服务器之间的不一致和不一致的模型偏差，以便服务器模型更新在全局最优点 без 破坏客户端的最优点。我们在四个标准数据集上进行了广泛的实验，以显示 FedRANE 在非独立数据上提高 FL 性能的优越性。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations"><a href="#Bayesian-polynomial-neural-networks-and-polynomial-neural-ordinary-differential-equations" class="headerlink" title="Bayesian polynomial neural networks and polynomial neural ordinary differential equations"></a>Bayesian polynomial neural networks and polynomial neural ordinary differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10892">http://arxiv.org/abs/2308.10892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Colby Fronk, Jaewoong Yun, Prashant Singh, Linda Petzold</li>
<li>for: 方法可以用于很多科学和工程问题的方程回归。</li>
<li>methods: 使用抽象回归和普通微分方程（ODEs）来进行方程回归，但是这些方法只能提供点估计。</li>
<li>results: 通过开发和验证 Laplace  aproximation、MCMC 抽样方法和变分推理来解决噪声数据问题，发现 Laplace  aproximation 是这类问题的最佳方法。<details>
<summary>Abstract</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.
</details>
<details>
<summary>摘要</summary>
Symbolic regression with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) are two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.Translation in Simplified Chinese: symbolic 回归 with polynomial neural networks and polynomial neural ordinary differential equations (ODEs) 是 two recent and powerful approaches for equation recovery of many science and engineering problems. However, these methods provide point estimates for the model parameters and are currently unable to accommodate noisy data. We address this challenge by developing and validating the following Bayesian inference methods: the Laplace approximation, Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We have found the Laplace approximation to be the best method for this class of problems. Our work can be easily extended to the broader class of symbolic neural networks to which the polynomial neural network belongs.
</details></li>
</ul>
<hr>
<h2 id="Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces"><a href="#Tipping-Point-Forecasting-in-Non-Stationary-Dynamics-on-Function-Spaces" class="headerlink" title="Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces"></a>Tipping Point Forecasting in Non-Stationary Dynamics on Function Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08794">http://arxiv.org/abs/2308.08794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel Liu-Schiaffini, Clare E. Singer, Nikola Kovachki, Tapio Schneider, Kamyar Azizzadenesheli, Anima Anandkumar</li>
<li>for: 本研究旨在预测非站点动力系统的突然变化，如气候战况中的云覆盖减少。</li>
<li>methods: 本文使用一种新型的循环神经网络算法（RNO）来学习函数空间的映射关系，并使用不确定性基于的方法来探测未来的突然变化。</li>
<li>results: 我们的实验表明，即使只有部分或不完整的物理约束，我们的方法仍可以准确预测未来的突然变化，并且可以提供准确性的度量。<details>
<summary>Abstract</summary>
Tipping points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.
</details>
<details>
<summary>摘要</summary>
�ipped points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.Here's the translation in Traditional Chinese:�ipped points are abrupt, drastic, and often irreversible changes in the evolution of non-stationary and chaotic dynamical systems. For instance, increased greenhouse gas concentrations are predicted to lead to drastic decreases in low cloud cover, referred to as a climatological tipping point. In this paper, we learn the evolution of such non-stationary dynamical systems using a novel recurrent neural operator (RNO), which learns mappings between function spaces. After training RNO on only the pre-tipping dynamics, we employ it to detect future tipping points using an uncertainty-based approach. In particular, we propose a conformal prediction framework to forecast tipping points by monitoring deviations from physics constraints (such as conserved quantities and partial differential equations), enabling forecasting of these abrupt changes along with a rigorous measure of uncertainty. We illustrate our proposed methodology on non-stationary ordinary and partial differential equations, such as the Lorenz-63 and Kuramoto-Sivashinsky equations. We also apply our methods to forecast a climate tipping point in stratocumulus cloud cover. In our experiments, we demonstrate that even partial or approximate physics constraints can be used to accurately forecast future tipping points.
</details></li>
</ul>
<hr>
<h2 id="Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks"><a href="#Federated-Reinforcement-Learning-for-Electric-Vehicles-Charging-Control-on-Distribution-Networks" class="headerlink" title="Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks"></a>Federated Reinforcement Learning for Electric Vehicles Charging Control on Distribution Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08792">http://arxiv.org/abs/2308.08792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junkai Qian, Yuning Jiang, Xin Liu, Qing Wang, Ting Wang, Yuanming Shi, Wei Chen<br>for:This paper focuses on developing a novel approach for EV charging control that considers the natural power flow of EV charging&#x2F;discharging in the distribution network and driver privacy.methods:The proposed approach combines multi-EV charging&#x2F;discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A federated deep reinforcement learning algorithm named FedSAC is used to learn the optimal EV charging control strategy.results:The proposed approach is effective in balancing V2G profits, RDN load, and driver anxiety. Comprehensive simulation results demonstrate the superiority of the proposed algorithm in terms of the diversity of the charging control strategy, power fluctuations on RDN, convergence efficiency, and generalization ability.<details>
<summary>Abstract</summary>
With the growing popularity of electric vehicles (EVs), maintaining power grid stability has become a significant challenge. To address this issue, EV charging control strategies have been developed to manage the switch between vehicle-to-grid (V2G) and grid-to-vehicle (G2V) modes for EVs. In this context, multi-agent deep reinforcement learning (MADRL) has proven its effectiveness in EV charging control. However, existing MADRL-based approaches fail to consider the natural power flow of EV charging/discharging in the distribution network and ignore driver privacy. To deal with these problems, this paper proposes a novel approach that combines multi-EV charging/discharging with a radial distribution network (RDN) operating under optimal power flow (OPF) to distribute power flow in real time. A mathematical model is developed to describe the RDN load. The EV charging control problem is formulated as a Markov Decision Process (MDP) to find an optimal charging control strategy that balances V2G profits, RDN load, and driver anxiety. To effectively learn the optimal EV charging control strategy, a federated deep reinforcement learning algorithm named FedSAC is further proposed. Comprehensive simulation results demonstrate the effectiveness and superiority of our proposed algorithm in terms of the diversity of the charging control strategy, the power fluctuations on RDN, the convergence efficiency, and the generalization ability.
</details>
<details>
<summary>摘要</summary>
随着电动车 (EV) 的普及，维护电力网络稳定性已成为一项重要挑战。为解决这问题，EV充电控制策略已被开发来管理电动车充电/充电模式之间的切换。在这个上下文中，多代理深度学习 (MADRL) 已经证明其在EV充电控制中的效iveness。然而，现有的MADRL基于方法忽略了电动车充电/充电的自然电力流和驾驶员隐私。为解决这些问题，本文提出了一种新的方法，即将多个电动车充电/充电与 радиаль分布网络 (RDN) 操作于优化电力流 (OPF) 下，以实时分配电力流。一个数学模型被开发来描述RDN负荷。EV充电控制问题被形式化为Markov决策过程 (MDP)，以找到一个优化充电控制策略，把V2G利润、RDN负荷和驾驶员焦虑平衡。为有效地学习优化EV充电控制策略，一种名为FedSAC的联邦深度学习算法被进一步提出。 simulation结果表明，我们提出的算法在多种维度上表现出优异性，包括充电控制策略多样性、RDN电力波动、效率和总体化能力。
</details></li>
</ul>
<hr>
<h2 id="APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service"><a href="#APPFLx-Providing-Privacy-Preserving-Cross-Silo-Federated-Learning-as-a-Service" class="headerlink" title="APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service"></a>APPFLx: Providing Privacy-Preserving Cross-Silo Federated Learning as a Service</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08786">http://arxiv.org/abs/2308.08786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilinghan Li, Shilan He, Pranshu Chaturvedi, Trung-Hieu Hoang, Minseok Ryu, E. A. Huerta, Volodymyr Kindratenko, Jordan Fuhrman, Maryellen Giger, Ryan Chard, Kibaek Kim, Ravi Madduri</li>
<li>For: This paper aims to provide a ready-to-use platform for cross-silo privacy-preserving federated learning (PPFL) as a service, making it easier and faster for domain experts and machine learning practitioners to collaboratively train robust and generalized machine learning models without sharing sensitive local data.* Methods: The paper introduces APPFLx, a platform that employs Globus authentication, implements several synchronous and asynchronous federated learning algorithms, streamlines the experiment launch process, and enables tracking and visualizing the life cycle of federated learning experiments.* Results: The paper provides a ready-to-use platform for cross-silo PPFL as a service, making it easier and faster for domain experts and machine learning practitioners to collaboratively train robust and generalized machine learning models without sharing sensitive local data.In Simplified Chinese text, the three key points would be:* For: 这篇论文目的是提供一个跨存储器隐私保护联合学习（PPFL）服务，使域专家和机器学习实践者可以轻松地和更快地在不分享敏感地方数据的情况下，共同训练Robust和通用机器学习模型。* Methods: 论文引入了APPFLx平台，该平台使用Globus认证、实现了同步和异步联合学习算法、简化了实验启动过程，并允许域专家和机器学习实践者轻松地和可见地管理和评估跨存储器联合学习实验。* Results: 论文提供了一个跨存储器PPFL服务，使域专家和机器学习实践者可以轻松地和更快地在不分享敏感地方数据的情况下，共同训练Robust和通用机器学习模型。<details>
<summary>Abstract</summary>
Cross-silo privacy-preserving federated learning (PPFL) is a powerful tool to collaboratively train robust and generalized machine learning (ML) models without sharing sensitive (e.g., healthcare of financial) local data. To ease and accelerate the adoption of PPFL, we introduce APPFLx, a ready-to-use platform that provides privacy-preserving cross-silo federated learning as a service. APPFLx employs Globus authentication to allow users to easily and securely invite trustworthy collaborators for PPFL, implements several synchronous and asynchronous FL algorithms, streamlines the FL experiment launch process, and enables tracking and visualizing the life cycle of FL experiments, allowing domain experts and ML practitioners to easily orchestrate and evaluate cross-silo FL under one platform. APPFLx is available online at https://appflx.link
</details>
<details>
<summary>摘要</summary>
cross-silo隐私保护联邦学习（PPFL）是一种强大的工具，可以无需共享敏感数据（如医疗或金融）进行共同训练 Robust和通用机器学习（ML）模型。为了方便和加速PPFL的采用，我们引入了APPFLx，一个准备就绪的平台，提供了隐私保护跨积 Ley 联邦学习作为服务。APPFLx 使用 Globus 鉴别来允许用户轻松地邀请可靠的合作者参与PPFL，实现了一些同步和异步联邦学习算法，通过简化联邦学习实验启动过程，并允许域专家和机器学习实践者轻松地组织和评估跨积 Ley 联邦学习。APPFLx 可以在https://appflx.link 上线上获取。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer"><a href="#Knowledge-inspired-Subdomain-Adaptation-for-Cross-Domain-Knowledge-Transfer" class="headerlink" title="Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer"></a>Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09724">http://arxiv.org/abs/2308.09724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang</li>
<li>for: 这篇论文是用于提出一个新的专domain adaptation（KISA）框架，以便在不同领域进行精细化的领域适应。</li>
<li>methods: 这篇论文使用了知识驱动的子领域分配问题，以及一个知识融合网络来推导多元领域知识。</li>
<li>results: 实验结果显示，KISA在骗案检测和交通流量预测任务中获得了优异的成绩。<details>
<summary>Abstract</summary>
Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.
</details>
<details>
<summary>摘要</summary>
现代深度领域适应技术通常在全局方式对源和目标样本进行协调。即 после协调，每个源样本都会变得类似于任何目标样本。但全局协调可能并不总是最佳或必要的。例如，考虑跨领域诈骗探测，其中有两种交易：信用和非信用。对这两种交易进行独立协调可能会产生更好的性能，因为信用交易不太可能会展现与非信用交易类似的模式。为实现这种细腻领域适应，我们提出了一个新的知识授意子领域适应（KISA）框架。具体来说，我们提供了适应领域适应的理论基础，并设计了知识融合网络来利用多个领域知识。广泛的实验证明了KISA在诈骗探测和交通需求预测任务上具有很好的表现。
</details></li>
</ul>
<hr>
<h2 id="Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning"><a href="#Environment-Diversification-with-Multi-head-Neural-Network-for-Invariant-Learning" class="headerlink" title="Environment Diversification with Multi-head Neural Network for Invariant Learning"></a>Environment Diversification with Multi-head Neural Network for Invariant Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08778">http://arxiv.org/abs/2308.08778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joe0123/EDNIL">https://github.com/joe0123/EDNIL</a></li>
<li>paper_authors: Bo-Wei Huang, Keng-Te Liao, Chang-Sheng Kao, Shou-De Lin</li>
<li>for: 这篇论文目的是提出一个不受分布变化的影响的学习框架，以提高神经网络的预测性。</li>
<li>methods: 这个框架使用了多头神经网络来吸收数据偏见，并无需对环境或先前训练模型做强大的假设。</li>
<li>results: 我们的实验结果显示，使用这个框架训练的模型在分布变化下的预测性较高。<details>
<summary>Abstract</summary>
Neural networks are often trained with empirical risk minimization; however, it has been shown that a shift between training and testing distributions can cause unpredictable performance degradation. On this issue, a research direction, invariant learning, has been proposed to extract invariant features insensitive to the distributional changes. This work proposes EDNIL, an invariant learning framework containing a multi-head neural network to absorb data biases. We show that this framework does not require prior knowledge about environments or strong assumptions about the pre-trained model. We also reveal that the proposed algorithm has theoretical connections to recent studies discussing properties of variant and invariant features. Finally, we demonstrate that models trained with EDNIL are empirically more robust against distributional shifts.
</details>
<details>
<summary>摘要</summary>
神经网络常用емпирическая风险最小化来训练，但是已经证明了在训练和测试分布之间的差异可能会导致性能下降。为解决这个问题，一种研究方向——抗变域学习（Invariant Learning）——已经被提出，以EXTRACT不敏感于分布变化的特征。本文提出了一种基于多头神经网络的EDNIL框架，用于吸收数据偏见。我们表明该框架不需要先知环境或强制假设先训练模型。此外，我们还发现该算法与最近的变异特征和抗变异特征的研究有理论上的连接。最后，我们通过实验表明，使用EDNIL训练的模型在分布变化情况下的性能更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models"><a href="#Differential-Privacy-Linguistic-Fairness-and-Training-Data-Influence-Impossibility-and-Possibility-Theorems-for-Multilingual-Language-Models" class="headerlink" title="Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models"></a>Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08774">http://arxiv.org/abs/2308.08774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phillip Rust, Anders Søgaard</li>
<li>for: 这些论文旨在解决多语言模型如BERT、XLM-R和BLOOM等模型实现多语言普适化或压缩，以便将其应用到大量（可能未看过）语言中。</li>
<li>methods: 这些模型应该同时满足私有性、语言公平性和透明度的要求，通过关系其预测与训练数据之间的关系。</li>
<li>results: 我们发现多语言压缩和语言公平性可以同时满足隐私保障，但是隐私保障与训练数据的稀缺性矛盾，这意味着在不同的隐私保障水平下， multilingual compression 和训练数据的影响稀缺性之间存在负相关性。我们进一步进行了两个常见的 NLP 任务的实验，并评估了 multilingual compression 和训练数据的影响稀缺性在不同的隐私保障水平下，从而更加深入地探讨这些负相关性的交互。<details>
<summary>Abstract</summary>
Language models such as mBERT, XLM-R, and BLOOM aim to achieve multilingual generalization or compression to facilitate transfer to a large number of (potentially unseen) languages. However, these models should ideally also be private, linguistically fair, and transparent, by relating their predictions to training data. Can these requirements be simultaneously satisfied? We show that multilingual compression and linguistic fairness are compatible with differential privacy, but that differential privacy is at odds with training data influence sparsity, an objective for transparency. We further present a series of experiments on two common NLP tasks and evaluate multilingual compression and training data influence sparsity under different privacy guarantees, exploring these trade-offs in more detail. Our results suggest that we need to develop ways to jointly optimize for these objectives in order to find practical trade-offs.
</details>
<details>
<summary>摘要</summary>
языковые модели, такие как mBERT, XLM-R и BLOOM, стремятся достичь многоязычной общей генерализации или сжатия для упрощения передачи большого количества (возможно невидимых) языков. Однако эти модели должны быть при этом частными, справедливыми с точки зрения языка и прозрачными, связывая свои прогнозы с данными обучения. Можно ли эти требования одновременно удовлетворить? Мы показываем, что многоязычное сжатие и справедливость с точки зрения языка совместимы с защитой конфиденциальности, но защита конфиденциальности противоречит снижению количества данных обучения, цели, которая связана с прозрачностью. Мы также представляем серию экспериментов по двум распространенным задачам NLP и оцениваем многоязычное сжатие и влияние данных обучения на различных гарантиях конфиденциальности, изучая эти противоречия в более подробном режиме. Наши результаты показывают, что необходимо разработать способы совместно оптимизировать эти цели, чтобы найти практические компромиссы.
</details></li>
</ul>
<hr>
<h2 id="Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving"><a href="#Sensor-Fusion-by-Spatial-Encoding-for-Autonomous-Driving" class="headerlink" title="Sensor Fusion by Spatial Encoding for Autonomous Driving"></a>Sensor Fusion by Spatial Encoding for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10707">http://arxiv.org/abs/2308.10707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quoc-Vinh Lai-Dang, Jihui Lee, Bumgeun Park, Dongsoo Har</li>
<li>for: 本研究旨在提出一种用于摄像头和激光雷达数据融合的方法，以提高自动驾驶和机器人视觉系统的性能。</li>
<li>methods: 该方法使用Transformer模块在多个分辨率进行融合，以确保地面和高空的关系得到有效地融合。</li>
<li>results: 对于两个难度最高的benchmark，提出的方法表现出色，与之前的方法相比，在驾驶和违法分数上具有显著的提升（8%和19%）。<details>
<summary>Abstract</summary>
Sensor fusion is critical to perception systems for task domains such as autonomous driving and robotics. Recently, the Transformer integrated with CNN has demonstrated high performance in sensor fusion for various perception tasks. In this work, we introduce a method for fusing data from camera and LiDAR. By employing Transformer modules at multiple resolutions, proposed method effectively combines local and global contextual relationships. The performance of the proposed method is validated by extensive experiments with two adversarial benchmarks with lengthy routes and high-density traffics. The proposed method outperforms previous approaches with the most challenging benchmarks, achieving significantly higher driving and infraction scores. Compared with TransFuser, it achieves 8% and 19% improvement in driving scores for the Longest6 and Town05 Long benchmarks, respectively.
</details>
<details>
<summary>摘要</summary>
感知系统中的感知融合是自动驾驶和机器人等任务领域的关键。最近，带有CNN的Transformer已经在多种感知任务中示出了高性能。在这项工作中，我们介绍了一种将摄像头和LiDAR数据进行融合的方法。通过在不同分辨率的Transformer模块中使用，我们的方法可以有效地结合本地和全局的 Contextual Relationships。我们的方法的性能被证明通过了两个挑战性的标准套件，即Length6和Town05 Long benchmarks。与之前的方法相比，我们的方法在这两个标准套件中表现出了8%和19%的提升。相比于TransFuser，我们的方法在Length6和Town05 Long benchmarks中分别提高了19%和8%的驾驶得分。
</details></li>
</ul>
<hr>
<h2 id="Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks"><a href="#Neurological-Prognostication-of-Post-Cardiac-Arrest-Coma-Patients-Using-EEG-Data-A-Dynamic-Survival-Analysis-Framework-with-Competing-Risks" class="headerlink" title="Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks"></a>Neurological Prognostication of Post-Cardiac-Arrest Coma Patients Using EEG Data: A Dynamic Survival Analysis Framework with Competing Risks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11645">http://arxiv.org/abs/2308.11645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobin Shen, Jonathan Elmer, George H. Chen</li>
<li>for: 预测受很高风险的心肺功能复兴后昏迷病人的神经系统结果，以帮助医疗决策。</li>
<li>methods: 使用EEG数据建立动态推断框架，预测患者在时间上的神经系统结果，并且随着更多的EEG数据成为可用，预测也会随着变化。</li>
<li>results: 使用三种竞争风险模型对922名患者的实际数据进行了比较，结果显示：（1）经典的Fine和Gray模型，只使用患者的静态特征和最近一小时的EEG数据，与最近开发的动态深度推断模型相当竞争，达到了高度准确的成绩；（2）在剪除试验中，我们发现，使用三种竞争风险模型，能够达到至少同样准确，同时学习更多信息的模型。<details>
<summary>Abstract</summary>
Patients resuscitated from cardiac arrest who enter a coma are at high risk of death. Forecasting neurological outcomes of these patients (the task of neurological prognostication) could help with treatment decisions. In this paper, we propose, to the best of our knowledge, the first dynamic framework for neurological prognostication of post-cardiac-arrest comatose patients using EEG data: our framework makes predictions for a patient over time as more EEG data become available, and different training patients' available EEG time series could vary in length. Predictions are phrased in terms of either time-to-event outcomes (time-to-awakening or time-to-death) or as the patient's probability of awakening or of dying across multiple time horizons. Our framework uses any dynamic survival analysis model that supports competing risks in the form of estimating patient-level cumulative incidence functions. We consider three competing risks as to what happens first to a patient: awakening, being withdrawn from life-sustaining therapies (and thus deterministically dying), or dying (by other causes). We demonstrate our framework by benchmarking three existing dynamic survival analysis models that support competing risks on a real dataset of 922 patients. Our main experimental findings are that: (1) the classical Fine and Gray model which only uses a patient's static features and summary statistics from the patient's latest hour's worth of EEG data is highly competitive, achieving accuracy scores as high as the recently developed Dynamic-DeepHit model that uses substantially more of the patient's EEG data; and (2) in an ablation study, we show that our choice of modeling three competing risks results in a model that is at least as accurate while learning more information than simpler models (using two competing risks or a standard survival analysis setup with no competing risks).
</details>
<details>
<summary>摘要</summary>
患者从心肺停止救护后入kom上的患者具有高风险死亡。预测这些患者的神经学结果（神经预测任务）可以帮助医疗决策。在这篇论文中，我们提出了，至今为止的知识最前进的动态框架 для神经预测患者从心肺停止救护后入kom的患者，使用EEG数据进行预测。我们的框架可以随着更多的EEG数据成为可用，预测患者的结果在时间上逐渐发展。我们的预测包括时间到事件结果（时间到醒来或时间到死亡）或患者在不同时间水平上的醒来或死亡概率。我们的框架使用任何支持竞争风险的动态生存分析模型，并且可以处理多种竞争风险，包括醒来、被终止生命维持治疗（因此必然死亡）和其他因素导致的死亡。我们在实际数据集上进行了比较三种现有的动态生存分析模型，并发现以下结论：（1）经典的 Fine and Gray 模型，只使用患者的静态特征和最近一小时的EEG数据，可以达到非常高的准确率，与最近开发的 Dynamic-DeepHit 模型相当。（2）在减少模型的 studiodelete 实验中，我们发现，通过处理三种竞争风险，我们的选择的模型可以learn更多的信息，同时保持与更简单的模型（使用两种竞争风险或标准生存分析设置无竞争风险）相比较高的准确率。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-tool-wear-prediction-in-turning"><a href="#Explainable-AI-for-tool-wear-prediction-in-turning" class="headerlink" title="Explainable AI for tool wear prediction in turning"></a>Explainable AI for tool wear prediction in turning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08765">http://arxiv.org/abs/2308.08765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleh Valizadeh Sotubadi, Rui Liu, Vinh Neguyen</li>
<li>for: 这项研究旨在开发一个可解释人工智能（XAI）框架，以便为工具损害预测提供人理解的解决方案。</li>
<li>methods: 该研究使用了随机森林算法作为监督机器学习（ML）分类器，并使用加速度、噪声、温度和螺旋速度作为输入特征进行训练和二分类预测。</li>
<li>results: 研究发现，在所有测试集上实施了Shapley准则后，工具温度被确定为预测工具可用性和失效的最重要的输入特征。因此，这项研究表明XAI可以为机床操作员提供对复杂ML分类器预测工具损害的诊断和理解能力。<details>
<summary>Abstract</summary>
This research aims develop an Explainable Artificial Intelligence (XAI) framework to facilitate human-understandable solutions for tool wear prediction during turning. A random forest algorithm was used as the supervised Machine Learning (ML) classifier for training and binary classification using acceleration, acoustics, temperature, and spindle speed during the orthogonal tube turning process as input features. The ML classifier was used to predict the condition of the tool after the cutting process, which was determined in a binary class form indicating if the cutting tool was available or failed. After the training process, the Shapley criterion was used to explain the predictions of the trained ML classifier. Specifically, the significance of each input feature in the decision-making and classification was identified to explain the reasoning of the ML classifier predictions. After implementing the Shapley criterion on all testing datasets, the tool temperature was identified as the most significant feature in determining the classification of available versus failed cutting tools. Hence, this research demonstrates capability of XAI to provide machining operators the ability to diagnose and understand complex ML classifiers in prediction of tool wear.
</details>
<details>
<summary>摘要</summary>
After training the ML classifier, the Shapley criterion was used to explain the predictions. The Shapley criterion identified the significance of each input feature in the decision-making and classification, providing insight into the reasoning behind the ML classifier's predictions.Results showed that tool temperature was the most significant feature in determining the classification of available versus failed cutting tools. This research demonstrates the capability of XAI to provide machining operators with the ability to diagnose and understand complex ML classifiers in predicting tool wear. By using XAI, machining operators can gain a deeper understanding of the decision-making process of the ML classifier, improving the accuracy and reliability of tool wear prediction.In simplified Chinese, the text can be translated as:这项研究的目标是开发一个可解释人工智能（XAI）框架，以便为汽刃磨损预测提供人理解的解决方案。研究使用了随机森林算法作为指导式机器学习（ML）分类器，输入特征包括旋转、噪声、温度和转速等。ML分类器用于预测切割过程后工具的状况，并将其分为可用和失败两类。经过训练后，使用了Shapley criterion来解释ML分类器的预测结果。Shapley criterion可以确定每个输入特征在决策和分类过程中的重要性，从而解释ML分类器的预测结果的原因。研究结果表明，工具温度是确定可用与失败切割工具的最重要的特征。这项研究 demonstrate XAI的能力，即为机床操作人员提供可以诊断和理解复杂ML分类器的预测结果。通过使用XAI，机床操作人员可以更深入地理解ML分类器的决策过程，提高汽刃磨损预测的准确性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering"><a href="#Efficient-Commercial-Bank-Customer-Credit-Risk-Assessment-Based-on-LightGBM-and-Feature-Engineering" class="headerlink" title="Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering"></a>Efficient Commercial Bank Customer Credit Risk Assessment Based on LightGBM and Feature Engineering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08762">http://arxiv.org/abs/2308.08762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanjie Sun, Zhike Gong, Quan Shi, Lin Chen</li>
<li>for: 这个论文主要是为了帮助商业银行控制信用风险，使用LightGBM算法建立分类器，以判断客户是否会default的可能性。</li>
<li>methods: 本论文使用了特征工程技术，如处理缺失值、编码、不均衡样本等，以提高机器学习效果。</li>
<li>results: 本论文的主要创新在于基于原始数据集构建新的特征属性，使分类器的准确率达0.734，AUC达0.772，超过了同基于数据集的许多分类器。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Effective control of credit risk is a key link in the steady operation of commercial banks. This paper is mainly based on the customer information dataset of a foreign commercial bank in Kaggle, and we use LightGBM algorithm to build a classifier to classify customers, to help the bank judge the possibility of customer credit default. This paper mainly deals with characteristic engineering, such as missing value processing, coding, imbalanced samples, etc., which greatly improves the machine learning effect. The main innovation of this paper is to construct new feature attributes on the basis of the original dataset so that the accuracy of the classifier reaches 0.734, and the AUC reaches 0.772, which is more than many classifiers based on the same dataset. The model can provide some reference for commercial banks' credit granting, and also provide some feature processing ideas for other similar studies.
</details>
<details>
<summary>摘要</summary>
Effective control of credit risk is a key link in the steady operation of commercial banks. This paper is mainly based on the customer information dataset of a foreign commercial bank in Kaggle, and we use LightGBM algorithm to build a classifier to classify customers, to help the bank judge the possibility of customer credit default. This paper mainly deals with characteristic engineering, such as missing value processing, coding, imbalanced samples, etc., which greatly improves the machine learning effect. The main innovation of this paper is to construct new feature attributes on the basis of the original dataset so that the accuracy of the classifier reaches 0.734, and the AUC reaches 0.772, which is more than many classifiers based on the same dataset. The model can provide some reference for commercial banks' credit granting, and also provide some feature processing ideas for other similar studies.Here's the translation breakdown:Effective control of credit risk: 信用风险控制Key link: 关键链接Steady operation: 稳定运行Commercial banks: 商业银行Customer information dataset: 客户信息数据集LightGBM algorithm: LightGBM算法Classifier: 分类器Customer credit default: 客户债务 defaultCharacteristic engineering: 特征工程Missing value processing: 缺失值处理Coding: 编码Imbalanced samples: 不均衡样本Machine learning effect: 机器学习效果Accuracy: 准确率AUC: 面积 beneath the ROC curveNew feature attributes: 新的特征属性Original dataset: 原始数据集Reference: 参考Credit granting: 信用授予
</details></li>
</ul>
<hr>
<h2 id="PMET-Precise-Model-Editing-in-a-Transformer"><a href="#PMET-Precise-Model-Editing-in-a-Transformer" class="headerlink" title="PMET: Precise Model Editing in a Transformer"></a>PMET: Precise Model Editing in a Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08742">http://arxiv.org/abs/2308.08742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xpq-tech/pmet">https://github.com/xpq-tech/pmet</a></li>
<li>paper_authors: Xiaopeng Li, Shasha Li, Shezheng Song, Jing Yang, Jun Ma, Jie Yu</li>
<li>for: 这个论文主要目标是提高模型修改技术的性能，以便更好地在大语言模型（LLM）中插入新知识。</li>
<li>methods: 该论文使用了一种新的模型修改方法，称为PMET，它同时优化多头自注意力（MHSA）和循环网络（FFN）的隐藏状态，并只使用优化后的FFN隐藏状态来精确地更新FFN参数。</li>
<li>results: 实验表明，PMET在COUNTERFACT和zsRE数据集上具有状态对抗性，并且在这两个数据集上都达到了最佳性能。<details>
<summary>Abstract</summary>
Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we introduce PMET, which simultaneously optimizes Transformer Component (TC, namely MHSA and FFN) hidden states, while only using the optimized TC hidden states of FFN to precisely update FFN weights. Our experiments demonstrate that PMET exhibits state-of-the-art performance on both the COUNTERFACT and zsRE datasets. Our ablation experiments substantiate the effectiveness of our enhancements, further reinforcing the finding that the MHSA encodes certain general knowledge extraction patterns and indicating its storage of a small amount of factual knowledge. Our code is available at https://github.com/xpq-tech/PMET.git.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的修改技术可以轻松地修改一小部分知识，并且已经达到了显著的成功。现有的方法假设Transformer层（TL）的隐藏状态是Feed-Forward Network（FFN）的钥匙值内存。他们通常将TL隐藏状态优化为记忆target知识，然后使用这些TL隐藏状态来更新FFN的类型。然而，TL隐藏状态的资讯来源来自三个部分：多头自我对话（MHSA）、FFN和复古连接。现有的方法忽略了TL隐藏状态中包含的资讯不具体的特定知识。因此，模型修改的性能受到影响。为了更加精确地修改模型，我们进行了隐藏状态分析，发现MHSA实际上对应某些通用知识提取模式。这表示MHSA的权重不需要更新当新知识引入。基于以上发现，我们引入了PMET，它同时优化Transformer组件（TC，即MHSA和FFN）的隐藏状态，只使用优化的TC隐藏状态FFN来准确地更新FFN的类型。我们的实验显示PMET在COUNTERFACT和zsRE datasets上具有最佳性能。我们的剖析实验证实了我们的改进的有效性，进一步证明MHSA对应通用知识提取模式，并且储存一小量的事实知识。我们的代码可以在https://github.com/xpq-tech/PMET.git中找到。
</details></li>
</ul>
<hr>
<h2 id="ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents"><a href="#ReProHRL-Towards-Multi-Goal-Navigation-in-the-Real-World-using-Hierarchical-Agents" class="headerlink" title="ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents"></a>ReProHRL: Towards Multi-Goal Navigation in the Real World using Hierarchical Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08737">http://arxiv.org/abs/2308.08737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejaswini Manjunath, Mozhgan Navardi, Prakhar Dixit, Bharat Prakash, Tinoosh Mohsenin</li>
<li>for: 本研究旨在解决现实世界中RL算法学习环境稀缺奖励和多目标导航问题。</li>
<li>methods: 本研究提出了Ready for Production Hierarchical RL（ReProHRL）方法，该方法将多目标导航划分为多个层次，并使用了对象检测器作为前处理步骤来学习多目标导航并在实际世界中传输。</li>
<li>results: 实验结果显示，提出的ReProHRL方法在模拟和实际环境中比基eline方法更高效，具体来说，在一个简单的单目标导航环境中，两者均达成100%成功率，但在一个更复杂的环境和多目标设定下，ReProHRL方法比基eline方法提高18%和5%。此外，通过在一架名为Crazyflie的奈米飞行器上部署提出的方法，实现了多目标导航实验。<details>
<summary>Abstract</summary>
Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:罗宾托已经成功地执行了高精度任务。在真实世界中的罕见奖励和多个目标下，学习仍然是一个主要挑战，而从实验环境进行训练然后在真实世界进行精确化是一个常见的方法。但是适应真实世界设定是一个挑战。在这篇论文中，我们提出了一种名为Ready for Production Hierarchical RL（ReProHRL）的方法，它通过分解任务为层次多个目标导航，并通过从实验环境进行训练，然后在真实世界进行精确化。我们还使用物体探测器作为先processing步骤，以学习多个目标导航并将其转移到真实世界。实验结果显示，提案的ReProHRL方法在模拟和真实世界环境中比基准方案高效和精确，尤其在复杂的环境和多个目标设定下。为了证明概念的可行性和实现，我们在一架名为Crazyflie的奈米探测器上进行了多个目标导航实验。
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection"><a href="#On-the-Effectiveness-of-Log-Representation-for-Log-based-Anomaly-Detection" class="headerlink" title="On the Effectiveness of Log Representation for Log-based Anomaly Detection"></a>On the Effectiveness of Log Representation for Log-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08736">http://arxiv.org/abs/2308.08736</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mooselab/suppmaterial-logrepforanomalydetection">https://github.com/mooselab/suppmaterial-logrepforanomalydetection</a></li>
<li>paper_authors: Xingfang Wu, Heng Li, Foutse Khomh<br>for:This paper aims to compare and evaluate different log representation techniques for use in machine learning-based log analysis tasks, specifically for anomaly detection.methods:The authors select six commonly used log representation techniques and evaluate them with seven machine learning models and four public log datasets. They also examine the impact of log parsing and feature aggregation approaches when used with these techniques.results:The authors provide heuristic guidelines for future researchers and developers based on their comprehensive comparison of log representation techniques. They hope to help researchers and practitioners better understand the characteristics of different log representation techniques and select the most suitable ones for their ML-based log analysis workflow.<details>
<summary>Abstract</summary>
Logs are an essential source of information for people to understand the running status of a software system. Due to the evolving modern software architecture and maintenance methods, more research efforts have been devoted to automated log analysis. In particular, machine learning (ML) has been widely used in log analysis tasks. In ML-based log analysis tasks, converting textual log data into numerical feature vectors is a critical and indispensable step. However, the impact of using different log representation techniques on the performance of the downstream models is not clear, which limits researchers and practitioners' opportunities of choosing the optimal log representation techniques in their automated log analysis workflows. Therefore, this work investigates and compares the commonly adopted log representation techniques from previous log analysis research. Particularly, we select six log representation techniques and evaluate them with seven ML models and four public log datasets (i.e., HDFS, BGL, Spirit and Thunderbird) in the context of log-based anomaly detection. We also examine the impacts of the log parsing process and the different feature aggregation approaches when they are employed with log representation techniques. From the experiments, we provide some heuristic guidelines for future researchers and developers to follow when designing an automated log analysis workflow. We believe our comprehensive comparison of log representation techniques can help researchers and practitioners better understand the characteristics of different log representation techniques and provide them with guidance for selecting the most suitable ones for their ML-based log analysis workflow.
</details>
<details>
<summary>摘要</summary>
日志是软件系统运行状况理解的重要来源。由于现代软件架构和维护方法不断演化，更多的研究努力被投入到自动化日志分析领域。特别是在机器学习（ML）中，日志分析任务中的文本日志数据转换成数值特征向量是 kritical 和不可或缺的步骤。然而，使用不同的日志表示技术对下游模型性能的影响还不够清楚，这限制了研究者和实践者在自动化日志分析流程中选择优化的日志表示技术的机会。因此，本工作 investigate 和比较过去的日志分析研究中通常采用的日志表示技术。特别是我们选择了六种日志表示技术，并与七种ML模型和四个公共日志数据集（即HDFS、BGL、Spirit 和Thunderbird）在日志基于异常检测中进行评估。我们还检查了在日志分析过程中使用日志解析过程和不同的特征聚合方法的影响。从实验结果来看，我们提供了一些有用的准则，以帮助未来的研究者和开发者在设计自动化日志分析工作流程时 следу。我们认为我们的全面的日志表示技术比较可以帮助研究者和实践者更好地了解不同日志表示技术的特点，并为他们选择最适合的日志表示技术。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing"><a href="#A-Novel-Loss-Function-Utilizing-Wasserstein-Distance-to-Reduce-Subject-Dependent-Noise-for-Generalizable-Models-in-Affective-Computing" class="headerlink" title="A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing"></a>A Novel Loss Function Utilizing Wasserstein Distance to Reduce Subject-Dependent Noise for Generalizable Models in Affective Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10869">http://arxiv.org/abs/2308.10869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nibraas Khan, Mahrukh Tauseef, Ritam Ghosh, Nilanjan Sarkar</li>
<li>for: 本研究旨在提高人工智能系统的情感识别精度，通过使用优化运输理论和 Wasserstein 距离来降低主观噪声的影响。</li>
<li>methods: 本研究使用了一种新的成本函数，其中包括用于衡量主观噪声的 Wasserstein 距离。同时，研究还使用了一种基于 autoencoder 的多类分类器，以同时检测不同情感状态。</li>
<li>results: 研究发现，使用提议的成本函数可以提高情感识别精度，与基准模型（Mean Squared Error）相比，平均提高了14.75%和17.75%的 minimum 和 centroid 距离。<details>
<summary>Abstract</summary>
Emotions are an essential part of human behavior that can impact thinking, decision-making, and communication skills. Thus, the ability to accurately monitor and identify emotions can be useful in many human-centered applications such as behavioral training, tracking emotional well-being, and development of human-computer interfaces. The correlation between patterns in physiological data and affective states has allowed for the utilization of deep learning techniques which can accurately detect the affective states of a person. However, the generalisability of existing models is often limited by the subject-dependent noise in the physiological data due to variations in a subject's reactions to stimuli. Hence, we propose a novel cost function that employs Optimal Transport Theory, specifically Wasserstein Distance, to scale the importance of subject-dependent data such that higher importance is assigned to patterns in data that are common across all participants while decreasing the importance of patterns that result from subject-dependent noise. The performance of the proposed cost function is demonstrated through an autoencoder with a multi-class classifier attached to the latent space and trained simultaneously to detect different affective states. An autoencoder with a state-of-the-art loss function i.e., Mean Squared Error, is used as a baseline for comparison with our model across four different commonly used datasets. Centroid and minimum distance between different classes are used as a metrics to indicate the separation between different classes in the latent space. An average increase of 14.75% and 17.75% (from benchmark to proposed loss function) was found for minimum and centroid euclidean distance respectively over all datasets.
</details>
<details>
<summary>摘要</summary>
人类行为中的情感是一个重要的部分，可以影响思维、决策和communication Skills。因此，可以准确识别和评估情感的能力在许多人类中心应用中可以是有益的，如行为训练、情感健康评估和人机界面的开发。基于生理数据中的征 patrerns和情感状态的相关性，使用深度学习技术可以准确地检测人类情感状态。然而，现有模型的通用性通常受到参与者的响应差异所限制，这些差异会导致数据中的Subject-dependent noise。因此，我们提议一种新的成本函数，使用Optimal Transport Theory，具体来说是Wasserstein Distance，来抑制参与者具有特定数据的影响。我们的模型通过在缺省空间中附加多类分类器，并同时使用我们提议的成本函数和现有的state-of-the-art loss function（即Mean Squared Error）进行训练，来检测不同的情感状态。与基准模型相比，我们的模型在四个常用的数据集上的性能显著提高，具体来说是平均提高14.75%和17.75%（从基准loss function到我们的loss function）。为了衡量不同类别之间的分离度，我们使用中心距离和最小距离两种指标，并发现在所有数据集上，我们的模型的中心距离和最小距离均有显著提高。
</details></li>
</ul>
<hr>
<h2 id="Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration"><a href="#Synergistic-Signal-Denoising-for-Multimodal-Time-Series-of-Structure-Vibration" class="headerlink" title="Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration"></a>Synergistic Signal Denoising for Multimodal Time Series of Structure Vibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11644">http://arxiv.org/abs/2308.11644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Yu, Han Chen</li>
<li>for: 本研究旨在提供一种基于深度学习的 Structural Health Monitoring (SHM) 解决方案，以提高结构的寿命和安全性。</li>
<li>methods: 本研究使用了一种新的深度学习算法，结合了卷积和循环网络，以捕捉多Modal vibration signal 中的本地和持续性结构行为。  additionally, the algorithm incorporates attention mechanisms to prioritize salient structural responses and improve predictive accuracy.</li>
<li>results: 研究结果显示了该算法在多种 SHM 场景中的显著改进，包括早期损害探测和适应性。  Furthermore, the proposed approach offers a more transparent and interpretable AI-driven SHM solution, with potential for real-time processing, integration with external environmental factors, and further emphasis on model interpretability.<details>
<summary>Abstract</summary>
Structural Health Monitoring (SHM) plays an indispensable role in ensuring the longevity and safety of infrastructure. With the rapid growth of sensor technology, the volume of data generated from various structures has seen an unprecedented surge, bringing forth challenges in efficient analysis and interpretation. This paper introduces a novel deep learning algorithm tailored for the complexities inherent in multimodal vibration signals prevalent in SHM. By amalgamating convolutional and recurrent architectures, the algorithm adeptly captures both localized and prolonged structural behaviors. The pivotal integration of attention mechanisms further enhances the model's capability, allowing it to discern and prioritize salient structural responses from extraneous noise. Our results showcase significant improvements in predictive accuracy, early damage detection, and adaptability across multiple SHM scenarios. In light of the critical nature of SHM, the proposed approach not only offers a robust analytical tool but also paves the way for more transparent and interpretable AI-driven SHM solutions. Future prospects include real-time processing, integration with external environmental factors, and a deeper emphasis on model interpretability.
</details>
<details>
<summary>摘要</summary>
（简体中文）结构健康监测（SHM）在基础设施的寿命和安全方面扮演着不可或缺的角色。随着感知技术的快速发展，各种结构生成的数据量在不断增加，这导致了分析和解释数据的挑战。本文介绍了一种适应多模态振荡信号的深度学习算法，通过结合卷积和回归体系，能够具有地方化和持续的结构行为捕捉能力。具有注意力机制的整合使得模型能够更好地筛选和优先处理关键的结构响应。我们的结果表明，该方法可以在多种 SHM 场景中显著提高预测精度、早期损害检测和适应性。鉴于 SHM 的重要性，该方法不仅提供了一种可靠的分析工具，还开创了更加透明和可解释的 AI-驱动 SHM 解决方案。未来的发展方向包括实时处理、与外部环境因素集成和更深入的模型解释性。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks"><a href="#Dynamic-Neural-Network-is-All-You-Need-Understanding-the-Robustness-of-Dynamic-Mechanisms-in-Neural-Networks" class="headerlink" title="Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks"></a>Dynamic Neural Network is All You Need: Understanding the Robustness of Dynamic Mechanisms in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08709">http://arxiv.org/abs/2308.08709</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous2015258/Early_Attack">https://github.com/anonymous2015258/Early_Attack</a></li>
<li>paper_authors: Mirazul Haque, Wei Yang</li>
<li>for: 本研究旨在 investigate 动态神经网络（DyNNs）中动态机制的稳定性和鲁棒性问题。</li>
<li>methods: 本研究使用三个模型和两个数据集进行评估。我们采用了多种攻击方法来评估动态机制对DyNNs的影响。</li>
<li>results: 我们发现，从DyNNs到SDNNs的攻击传递率高于从SDNNs到DyNNs。此外，我们发现DyNNs可以更有效地生成攻击样本。最后，我们提出了一种新的攻击方法，并提供了设计选择来提高DyNNs的鲁棒性。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have been used to solve different day-to-day problems. Recently, DNNs have been deployed in real-time systems, and lowering the energy consumption and response time has become the need of the hour. To address this scenario, researchers have proposed incorporating dynamic mechanism to static DNNs (SDNN) to create Dynamic Neural Networks (DyNNs) performing dynamic amounts of computation based on the input complexity. Although incorporating dynamic mechanism into SDNNs would be preferable in real-time systems, it also becomes important to evaluate how the introduction of dynamic mechanism impacts the robustness of the models. However, there has not been a significant number of works focusing on the robustness trade-off between SDNNs and DyNNs. To address this issue, we propose to investigate the robustness of dynamic mechanism in DyNNs and how dynamic mechanism design impacts the robustness of DyNNs. For that purpose, we evaluate three research questions. These evaluations are performed on three models and two datasets. Through the studies, we find that attack transferability from DyNNs to SDNNs is higher than attack transferability from SDNNs to DyNNs. Also, we find that DyNNs can be used to generate adversarial samples more efficiently than SDNNs. Then, through research studies, we provide insight into the design choices that can increase robustness of DyNNs against the attack generated using static model. Finally, we propose a novel attack to understand the additional attack surface introduced by the dynamic mechanism and provide design choices to improve robustness against the attack.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）已经用于解决不同的日常问题。近期，DNNs在实时系统中部署，降低能耗和响应时间已成为当前的需求。为解决这种情况，研究人员已经提议将静止神经网络（SDNN）与动态机制结合，创造可动Amount of computation的神经网络（DyNNs）。虽然在实时系统中将静止机制添加到SDNNs是可行的，但也需要评估这种机制对模型的稳定性的影响。然而，有很少研究关于SDNNs和DyNNs之间的稳定性质量的负担。为了解决这个问题，我们提出了三个研究问题。这些评估在三个模型和两个数据集上进行。通过研究，我们发现了以下结论：从 DyNNs 到 SDNNs 的攻击传播率高于从 SDNNs 到 DyNNs 的攻击传播率。此外，我们发现了 DyNNs 可以更高效地生成黑客样本 than SDNNs。然后，通过研究，我们提供了在设计 DyNNs 时的选择，以提高其对攻击的鲁棒性。最后，我们提出了一种新的攻击方法，以了解动态机制引入的额外攻击表面，并提供了防御策略来改善鲁棒性。
</details></li>
</ul>
<hr>
<h2 id="Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness"><a href="#Consciousness-in-Artificial-Intelligence-Insights-from-the-Science-of-Consciousness" class="headerlink" title="Consciousness in Artificial Intelligence: Insights from the Science of Consciousness"></a>Consciousness in Artificial Intelligence: Insights from the Science of Consciousness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08708">http://arxiv.org/abs/2308.08708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane, Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, Liad Mudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, Rufin VanRullen</li>
<li>for: 本研究的目的是评估当前和未来的人工智能系统是否具有意识。</li>
<li>methods: 本研究使用了一种严谨和基于实验的方法，即在 neuroscientific 理论的光下评估当前和未来的人工智能系统，以确定它们是否具有意识。</li>
<li>results: 研究结果表明，目前的人工智能系统没有意识，但也没有技术障碍建立意识的系统。<details>
<summary>Abstract</summary>
Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.
</details>
<details>
<summary>摘要</summary>
Current or near-term AI systems 是科学界的兴趣话题，也是公众的关注点。本报告提出了一种严谨的、基于实证研究的AI意识方法：根据我们最为支持的神经科学理论来评估现有AI系统。我们评估了一些主要的科学理论，包括循环处理理论、全局工作区理论、更高级理论、预测处理理论和注意 schema 理论。从这些理论中，我们 derivate了“指标属性”，这些属性可以用计算机语言来评估 AI 系统。我们使用这些指标属性来评估一些最近的 AI 系统，并讨论未来系统可能如何实现这些属性。我们的分析结果表明，目前没有任何 AI 系统具有意识，但也没有明显的技术障碍来建立具有这些指标的 AI 系统。
</details></li>
</ul>
<hr>
<h2 id="FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs"><a href="#FineQuant-Unlocking-Efficiency-with-Fine-Grained-Weight-Only-Quantization-for-LLMs" class="headerlink" title="FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs"></a>FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09723">http://arxiv.org/abs/2308.09723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Jin Kim, Rawn Henry, Raffy Fahim, Hany Hassan Awadalla</li>
<li>for: 提高大型语言模型（LLMs）在不同语言任务中的状态空间性能，但它们在实际部署中存在巨大内存需求和吞吐量瓶颈问题。</li>
<li>methods: 我们提出了一种高效的量化方法，可以降低LLMs的内存占用和加速推理。我们采用了一种简单有效的规则，只使用预训练模型的Weight，无需额外 fine-tuning。</li>
<li>results: 我们的方法可以保持最小的质量下降，在大规模的开源模型，如OPT-175B和内部MoE模型上实现高达3.65倍的 Throughput，同时占用相同数量的GPU。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved state-of-the-art performance across various language tasks but pose challenges for practical deployment due to their substantial memory requirements. Furthermore, the latest generative models suffer from high inference costs caused by the memory bandwidth bottleneck in the auto-regressive decoding process. To address these issues, we propose an efficient weight-only quantization method that reduces memory consumption and accelerates inference for LLMs. To ensure minimal quality degradation, we introduce a simple and effective heuristic approach that utilizes only the model weights of a pre-trained model. This approach is applicable to both Mixture-of-Experts (MoE) and dense models without requiring additional fine-tuning. To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights. We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.
</details>
<details>
<summary>摘要</summary>
To demonstrate the effectiveness of our proposed method, we first analyze the challenges and issues associated with LLM quantization. Subsequently, we present our heuristic approach, which adaptively finds the granularity of quantization, effectively addressing these problems. Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly matrix multiplication and dequantization, supporting the multiplication of fp16 or bf16 activations with int8 or int4 weights.We evaluate our approach on large-scale open source models such as OPT-175B and internal MoE models, showcasing minimal accuracy loss while achieving up to 3.65 times higher throughput on the same number of GPUs.
</details></li>
</ul>
<hr>
<h2 id="Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing"><a href="#Partially-Observable-Multi-agent-RL-with-Quasi-Efficiency-The-Blessing-of-Information-Sharing" class="headerlink" title="Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing"></a>Partially Observable Multi-agent RL with (Quasi-)Efficiency: The Blessing of Information Sharing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08705">http://arxiv.org/abs/2308.08705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Liu, Kaiqing Zhang</li>
<li>for: 本研究旨在提出一种可证明的多智能RL（MARL）方法，以普通的多智能游戏（POSG）为框架， circumvent known hardness results 和 computationally intractable oracles。</li>
<li>methods: 我们提出利用多智能agent之间的信息共享，一种常见的实际MARL中的做法，以及多智能控制系统中的通信模型。 我们首先证明了需要信息共享和可观察性假设的计算复杂度结论，以确保计算效率。然后，我们提出一种 Approximate 模型，以解决POSG的计算复杂度问题。最后，我们开发了一种可 statistically 和 computationally quasi-efficient 的多智能RL算法。</li>
<li>results: 我们的研究可能开启了在不同信息结构下开发可 sample-和计算效率的多智能RL算法的可能性。<details>
<summary>Abstract</summary>
We study provable multi-agent reinforcement learning (MARL) in the general framework of partially observable stochastic games (POSGs). To circumvent the known hardness results and the use of computationally intractable oracles, we advocate leveraging the potential \emph{information-sharing} among agents, a common practice in empirical MARL, and a standard model for multi-agent control systems with communications. We first establish several computation complexity results to justify the necessity of information-sharing, as well as the observability assumption that has enabled quasi-efficient single-agent RL with partial observations, for computational efficiency in solving POSGs. We then propose to further \emph{approximate} the shared common information to construct an {approximate model} of the POSG, in which planning an approximate equilibrium (in terms of solving the original POSG) can be quasi-efficient, i.e., of quasi-polynomial-time, under the aforementioned assumptions. Furthermore, we develop a partially observable MARL algorithm that is both statistically and computationally quasi-efficient. We hope our study may open up the possibilities of leveraging and even designing different \emph{information structures}, for developing both sample- and computation-efficient partially observable MARL.
</details>
<details>
<summary>摘要</summary>
我们研究可证明多智能体刺激学习（MARL）在通用概念下的部分可见随机游戏（POSG）中。为了绕过已知的困难性和使用计算可负担的底层 oracle，我们倡议利用智能体之间的信息共享，这是现实中多智能体 MARL 中的常见做法，以及多机控制系统通信的标准模型。我们首先确立了一些计算复杂性结果，以证明信息共享的必要性和部分可见性假设，以确保计算效率在解决 POSG 中。然后，我们提议使用可approximate的共享公共信息来构建一个approximate模型，以便在这个模型中计划一个近似equilibrium（相当于解决原始 POSG），这可以在前面的假设下达到 quasi-多项式时间的计算效率。此外，我们开发了一种部分可见 MARL 算法，它不仅是 statistically quasi-efficient，而且也是 computationally quasi-efficient。我们希望我们的研究可以开放更多的可能性，例如利用和设计不同的信息结构，以开发更高效的部分可见 MARL。
</details></li>
</ul>
<hr>
<h2 id="Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces"><a href="#Planning-in-the-imagination-High-level-planning-on-learned-abstract-search-spaces" class="headerlink" title="Planning in the imagination: High-level planning on learned abstract search spaces"></a>Planning in the imagination: High-level planning on learned abstract search spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08693">http://arxiv.org/abs/2308.08693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Martin, Tuomas Sandholm</li>
<li>for: 本文提出了一种新的方法 PiZero，允许智能机器人在自己创建的抽象搜索空间中进行规划，这个空间与实际环境完全解耦。</li>
<li>methods: 本文使用的方法PiZero可以在任意时间尺度上进行高级规划，并且可以处理连续动作空间和部分可见性的情况。</li>
<li>results: 根据实验结果，PiZero在多个领域中表现出色，比如导航任务和Sokoban，并且在不假设环境模拟器的情况下超过了相似的先前方法。<details>
<summary>Abstract</summary>
We propose a new method, called PiZero, that gives an agent the ability to plan in an abstract search space of its own creation that is completely decoupled from the real environment. Unlike prior approaches, this enables the agent to perform high-level planning at arbitrary timescales and reason in terms of compound or temporally-extended actions, which can be useful in environments where large numbers of base-level micro-actions are needed to perform relevant macro-actions. In addition, our method is more general than comparable prior methods because it handles settings with continuous action spaces and partial observability. We evaluate our method on multiple domains, including navigation tasks and Sokoban. Experimentally, it outperforms comparable prior methods without assuming access to an environment simulator.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新方法，叫做PiZero，它让一个代理人有能力在自己创造的抽象搜索空间中进行规划，这个空间完全与真实环境解耦。与先前的方法不同，这使得代理人可以在任意时间尺度进行高级规划，并且可以使用复杂或时间扩展的动作来执行重要的macro-动作。此外，我们的方法比先前的方法更通用，因为它处理了连续动作空间和部分可见性的情况。我们在多个领域进行了实验，包括导航任务和Sokoban，并证明了它在相比先前方法而言表现出色，不需要对环境模拟器进行假设。
</details></li>
</ul>
<hr>
<h2 id="Quantifying-Overfitting-Introducing-the-Overfitting-Index"><a href="#Quantifying-Overfitting-Introducing-the-Overfitting-Index" class="headerlink" title="Quantifying Overfitting: Introducing the Overfitting Index"></a>Quantifying Overfitting: Introducing the Overfitting Index</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08682">http://arxiv.org/abs/2308.08682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass</li>
<li>for: 本研究旨在提出一种新的度量指标（过拟合指标），用于评估深度学习模型的过拟合情况。</li>
<li>methods: 该研究使用了多种深度学习模型，包括 MobileNet、U-Net、ResNet、Darknet 和 ViT-32，并在 Breast Ultrasound Images Dataset (BUS) 和 MNIST 数据集上进行了广泛的实验。</li>
<li>results: 研究结果表明，不同的模型在不同的数据集上 exhibits 不同的过拟合行为，而数据增强特别是在小型特有数据集上产生了积极的影响。 In addition, the ViT-32 模型在 MNIST 数据集上的表现也证明了某些模型的稳定性和数据集的全面性。<details>
<summary>Abstract</summary>
In the rapidly evolving domain of machine learning, ensuring model generalizability remains a quintessential challenge. Overfitting, where a model exhibits superior performance on training data but falters on unseen data, is a recurrent concern. This paper introduces the Overfitting Index (OI), a novel metric devised to quantitatively assess a model's tendency to overfit. Through extensive experiments on the Breast Ultrasound Images Dataset (BUS) and the MNIST dataset using architectures such as MobileNet, U-Net, ResNet, Darknet, and ViT-32, we illustrate the utility and discernment of the OI. Our results underscore the variable overfitting behaviors across architectures and highlight the mitigative impact of data augmentation, especially on smaller and more specialized datasets. The ViT-32's performance on MNIST further emphasizes the robustness of certain models and the dataset's comprehensive nature. By providing an objective lens to gauge overfitting, the OI offers a promising avenue to advance model optimization and ensure real-world efficacy.
</details>
<details>
<summary>摘要</summary>
在快速发展的机器学习领域中，保证模型通用化性仍然是一项核心挑战。过拟合，其中模型在训练数据上显示出杰出表现，但在未经见数据上却表现不佳，是一个常见的问题。本文介绍了一种新的评估模型过拟合的指标——过拟合指数（OI）。通过对Breast Ultrasound Images Dataset（BUS）和MNIST dataset上的多种架构（如MobileNet、U-Net、ResNet、Darknet和ViT-32）进行了广泛的实验，我们证明了OI的用于评估模型过拟合的有用性和分辨率。我们的结果表明不同的架构之间存在差异性，并且数据扩展尤其是在小型特定 datasets 上具有缓解作用。ViT-32在MNIST上的表现进一步证明了某些模型的强健性和数据的完整性。通过提供一个对过拟合进行 объек 的评估，OI为模型优化和实际应用带来了一个有前途的途径。
</details></li>
</ul>
<hr>
<h2 id="SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification"><a href="#SkinDistilViT-Lightweight-Vision-Transformer-for-Skin-Lesion-Classification" class="headerlink" title="SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification"></a>SkinDistilViT: Lightweight Vision Transformer for Skin Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08669">http://arxiv.org/abs/2308.08669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Longman-Stan/SkinDistilVit">https://github.com/Longman-Stan/SkinDistilVit</a></li>
<li>paper_authors: Vlad-Constantin Lungu-Stan, Dumitru-Clementin Cercel, Florin Pop</li>
<li>For: The paper is written for solving the skin cancer classification problem, specifically focusing on melanoma identification.* Methods: The paper uses a vision transformer trained on melanoma medical images annotated by experts, with knowledge distillation to obtain a model that retains the teacher’s balanced multi-class accuracy at a lower cost in terms of memory and time.* Results: The paper achieves a balanced multi-class accuracy of 98.33% with a model that is 49.60% smaller than the teacher and 69.25% faster on GPU and 97.96% faster on CPU. Additionally, the paper proposes a cascading distillation process to improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance.<details>
<summary>Abstract</summary>
Skin cancer is a treatable disease if discovered early. We provide a production-specific solution to the skin cancer classification problem that matches human performance in melanoma identification by training a vision transformer on melanoma medical images annotated by experts. Since inference cost, both time and memory wise is important in practice, we employ knowledge distillation to obtain a model that retains 98.33% of the teacher's balanced multi-class accuracy, at a fraction of the cost. Memory-wise, our model is 49.60% smaller than the teacher. Time-wise, our solution is 69.25% faster on GPU and 97.96% faster on CPU. By adding classification heads at each level of the transformer and employing a cascading distillation process, we improve the balanced multi-class accuracy of the base model by 2.1%, while creating a range of models of various sizes but comparable performance. We provide the code at https://github.com/Longman-Stan/SkinDistilVit.
</details>
<details>
<summary>摘要</summary>
皮肤癌是一种可治疗的疾病，如果早发现。我们提供了一个特有的解决方案，用于皮肤癌分类问题，可以与人类专家的标注医生医生医生的医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生医生
</details></li>
</ul>
<hr>
<h2 id="BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration"><a href="#BREATHE-Second-Order-Gradients-and-Heteroscedastic-Emulation-based-Design-Space-Exploration" class="headerlink" title="BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration"></a>BREATHE: Second-Order Gradients and Heteroscedastic Emulation based Design Space Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08666">http://arxiv.org/abs/2308.08666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikhar Tuli, Niraj K. Jha</li>
<li>for: 本文旨在提出一种受限Multiple Objective Optimization（MOO）框架，以优化vector和graph基于的设计空间中的最佳设计。</li>
<li>methods: 该框架利用第二阶导数和约束来实现样本高效优化，同时使用不同的搜索策略来扩展搜索空间。</li>
<li>results: 在单目标vector优化应用中，与最佳基elineRandom Forest Regression相比，本方法可以 дости到64.1%的提高性能。在图基于的搜索中，本方法可以与Gaussian-process-based Bayesian Optimization相比，达到64.9%的提高性能。在多目标优化任务中，本方法可以达到21.9倍的超越性能。<details>
<summary>Abstract</summary>
Researchers constantly strive to explore larger and more complex search spaces in various scientific studies and physical experiments. However, such investigations often involve sophisticated simulators or time-consuming experiments that make exploring and observing new design samples challenging. Previous works that target such applications are typically sample-inefficient and restricted to vector search spaces. To address these limitations, this work proposes a constrained multi-objective optimization (MOO) framework, called BREATHE, that searches not only traditional vector-based design spaces but also graph-based design spaces to obtain best-performing graphs. It leverages second-order gradients and actively trains a heteroscedastic surrogate model for sample-efficient optimization. In a single-objective vector optimization application, it leads to 64.1% higher performance than the next-best baseline, random forest regression. In graph-based search, BREATHE outperforms the next-best baseline, i.e., a graphical version of Gaussian-process-based Bayesian optimization, with up to 64.9% higher performance. In a MOO task, it achieves up to 21.9$\times$ higher hypervolume than the state-of-the-art method, multi-objective Bayesian optimization (MOBOpt). BREATHE also outperforms the baseline methods on most standard MOO benchmark applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data"><a href="#Flickr-Africa-Examining-Geo-Diversity-in-Large-Scale-Human-Centric-Visual-Data" class="headerlink" title="Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data"></a>Flickr Africa: Examining Geo-Diversity in Large-Scale, Human-Centric Visual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08656">http://arxiv.org/abs/2308.08656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keziah Naggita, Julienne LaChance, Alice Xiang</li>
<li>for:  investigate the limitations of standard Internet data collection methods in low- and middle-income countries</li>
<li>methods: analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa</li>
<li>results: findings for an &#96;&#96;othering’’ phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers, and the need for further work to capture image data representative of African people and their environments to improve the applicability of computer vision models in a global context.Here’s the text in Simplified Chinese:</li>
<li>for:  investigate the limitations of standard Internet data collection methods in low- and middle-income countries</li>
<li>methods: 使用 geotagged Flickr 图像与每个非洲国家相关的人中心的图像增强大规模地分析图像地域多样性</li>
<li>results: 发现非洲图像中有许多非本地摄影师拍摄的&#96;&#96;他者’’现象，需要进一步的工作来捕捉非洲人和他们环境的图像数据，以提高计算机视觉模型在全球上的适用性。<details>
<summary>Abstract</summary>
Biases in large-scale image datasets are known to influence the performance of computer vision models as a function of geographic context. To investigate the limitations of standard Internet data collection methods in low- and middle-income countries, we analyze human-centric image geo-diversity on a massive scale using geotagged Flickr images associated with each nation in Africa. We report the quantity and content of available data with comparisons to population-matched nations in Europe as well as the distribution of data according to fine-grained intra-national wealth estimates. Temporal analyses are performed at two-year intervals to expose emerging data trends. Furthermore, we present findings for an ``othering'' phenomenon as evidenced by a substantial number of images from Africa being taken by non-local photographers. The results of our study suggest that further work is required to capture image data representative of African people and their environments and, ultimately, to improve the applicability of computer vision models in a global context.
</details>
<details>
<summary>摘要</summary>
大规模图像数据集中的偏见被知道会影响计算机视觉模型的表现，具体来说是根据地理上下文。为了探究标准互联网数据采集方法在低中收入国家的局限性，我们使用地标注的Flickr图像与每个非洲国家进行人acentric图像地域多样性分析，并对与人口匹配的欧洲国家进行比较。我们还分析了根据细化的内部富裕度Estimates分布的数据。我们在两年 interval temporal 分析中暴露出emerging 数据趋势。此外，我们还发现了一种“其他化”现象，即非洲的大量图像是由非本地摄影师拍摄的。研究结果表明，更多的工作需要 capture 非洲人和他们的环境的图像数据，以便提高计算机视觉模型在全球上的可应用性。
</details></li>
</ul>
<hr>
<h2 id="Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems"><a href="#Physics-Informed-Recurrent-Neural-Networks-for-Seismic-Response-Evaluation-of-Nonlinear-Systems" class="headerlink" title="Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems"></a>Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08655">http://arxiv.org/abs/2308.08655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faisal Nissar Malik, James Ricles, Masoud Yari, Malik Arsala Nissar</li>
<li>for: 本研究旨在evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks, with a focus on seismic (earthquake) response of nonlinear structures.</li>
<li>methods: 本研究使用了physics-informed recurrent neural networks (RNNs) to evaluate the dynamic response of MDOF systems. The proposed method leverages large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs.</li>
<li>results: 研究人员预测了MDOF系统的动态回应，并与现有方法such as finite element analysis (FEA)进行比较，以评估physics-informed RNN模型的效果。<details>
<summary>Abstract</summary>
Dynamic response evaluation in structural engineering is the process of determining the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventional methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.
</details>
<details>
<summary>摘要</summary>
<<SYS>> dynamically evaluate the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventionally, methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.Translated by Google Translate.
</details></li>
</ul>
<hr>
<h2 id="Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction"><a href="#Reproducing-Kernel-Hilbert-Space-Pruning-for-Sparse-Hyperspectral-Abundance-Prediction" class="headerlink" title="Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction"></a>Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral Abundance Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08653">http://arxiv.org/abs/2308.08653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael G. Rawson, Timothy Doster, Tegan Emerson</li>
<li>for: 本研究旨在开发一种基于希尔伯特空间变换的简单spectral compression和分析方法，以减少高分辨率数据的压缩和分析成本。</li>
<li>methods: 本研究使用非负最小二乘法来逐步减少矩阵的维度，并使用最大似然压缩向量来减少信息损失。</li>
<li>results: 对实际和 sintetic 数据进行评估，我们发现希尔伯特空间预处理可以减少错误率，并且可以超越标准预处理和最小二乘法方法。<details>
<summary>Abstract</summary>
Hyperspectral measurements from long range sensors can give a detailed picture of the items, materials, and chemicals in a scene but analysis can be difficult, slow, and expensive due to high spatial and spectral resolutions of state-of-the-art sensors. As such, sparsity is important to enable the future of spectral compression and analytics. It has been observed that environmental and atmospheric effects, including scattering, can produce nonlinear effects posing challenges for existing source separation and compression methods. We present a novel transformation into Hilbert spaces for pruning and constructing sparse representations via non-negative least squares minimization. Then we introduce max likelihood compression vectors to decrease information loss. Our approach is benchmarked against standard pruning and least squares as well as deep learning methods. Our methods are evaluated in terms of overall spectral reconstruction error and compression rate using real and synthetic data. We find that pruning least squares methods converge quickly unlike matching pursuit methods. We find that Hilbert space pruning can reduce error by as much as 40% of the error of standard pruning and also outperform neural network autoencoders.
</details>
<details>
<summary>摘要</summary>
We propose a novel transformation into Hilbert spaces for pruning and constructing sparse representations via non-negative least squares minimization. We also introduce max likelihood compression vectors to reduce information loss. Our approach is benchmarked against standard pruning and least squares methods as well as deep learning methods.We evaluate our methods in terms of overall spectral reconstruction error and compression rate using real and synthetic data. We find that pruning least squares methods converge quickly, unlike matching pursuit methods. Additionally, Hilbert space pruning can reduce error by as much as 40% of the error of standard pruning and outperform neural network autoencoders.
</details></li>
</ul>
<hr>
<h2 id="Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly"><a href="#Towards-Personalized-Federated-Learning-via-Heterogeneous-Model-Reassembly" class="headerlink" title="Towards Personalized Federated Learning via Heterogeneous Model Reassembly"></a>Towards Personalized Federated Learning via Heterogeneous Model Reassembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08643">http://arxiv.org/abs/2308.08643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wang, Xingyi Yang, Suhan Cui, Liwei Che, Lingjuan Lyu, Dongkuan Xu, Fenglong Ma</li>
<li>for: 本文目的是解决联合学习中的模型异同问题，CLIENTS possessing 不同网络结构的模型。</li>
<li>methods: 我们提出了一个名为pFedHR的新框架，利用异同模型重新组装来实现个性化联合学习。具体来说，我们将客户端模型匹配优化任务视为服务器端的一个模型匹配优化任务。此外，pFedHR可以自动和 Dynamically生成有用和多样化的个性化候选者，减少人工干预。</li>
<li>results: 我们的实验结果表明，pFedHR在三个数据集上下降比基eline在IID和非IIDSetting下表现较好。此外，pFedHR可以减少使用不同公共数据导致的负面影响，同时自动生成多样化的个性化模型。<details>
<summary>Abstract</summary>
This paper focuses on addressing the practical yet challenging problem of model heterogeneity in federated learning, where clients possess models with different network structures. To track this problem, we propose a novel framework called pFedHR, which leverages heterogeneous model reassembly to achieve personalized federated learning. In particular, we approach the problem of heterogeneous model personalization as a model-matching optimization task on the server side. Moreover, pFedHR automatically and dynamically generates informative and diverse personalized candidates with minimal human intervention. Furthermore, our proposed heterogeneous model reassembly technique mitigates the adverse impact introduced by using public data with different distributions from the client data to a certain extent. Experimental results demonstrate that pFedHR outperforms baselines on three datasets under both IID and Non-IID settings. Additionally, pFedHR effectively reduces the adverse impact of using different public data and dynamically generates diverse personalized models in an automated manner.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "pFedHR" is translated as "PFedHR" (简化中文：PFedHR)* "heterogeneous model reassembly" is translated as "heterogeneous model reassembly" (简化中文：不同模型重新组装)* "personalized federated learning" is translated as "个性化联合学习" (简化中文：个性化联合学习)* "IID" and "Non-IID" are translated as "同分布" and "不同分布" (简化中文：同分布和不同分布)* "public data" is translated as "公共数据" (简化中文：公共数据)* "client data" is translated as "客户数据" (简化中文：客户数据)
</details></li>
</ul>
<hr>
<h2 id="Non-monotone-Sequential-Submodular-Maximization"><a href="#Non-monotone-Sequential-Submodular-Maximization" class="headerlink" title="Non-monotone Sequential Submodular Maximization"></a>Non-monotone Sequential Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08641">http://arxiv.org/abs/2308.08641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaojie Tang, Jing Yuan</li>
<li>for: 本研究是关于sequential submodular maximization的基本问题，具体目标是从集合$V$中选择和排序$k$个项目，以便最大化Weighted总和$k$个可能不升序的submodular函数$f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+ $。</li>
<li>methods: 本研究提出了一些有效的解决方案，包括flexible和固定长度约束的情况，以及特殊情况下的相同实用函数。</li>
<li>results: 实验证明了我们提出的算法在视频推荐领域具有有效性。研究结果对于推荐系统和择寸优化领域有重要意义，因为项目的顺序对总值产生重要影响。<details>
<summary>Abstract</summary>
In this paper, we study a fundamental problem in submodular optimization, which is called sequential submodular maximization. Specifically, we aim to select and rank a group of $k$ items from a ground set $V$ such that the weighted summation of $k$ (possibly non-monotone) submodular functions $f_1, \cdots ,f_k: 2^V \rightarrow \mathbb{R}^+$ is maximized, here each function $f_j$ takes the first $j$ items from this sequence as input. The existing research on sequential submodular maximization has predominantly concentrated on the monotone setting, assuming that the submodular functions are non-decreasing. However, in various real-world scenarios, like diversity-aware recommendation systems, adding items to an existing set might negatively impact the overall utility. In response, this paper pioneers the examination of the aforementioned problem with non-monotone submodular functions and offers effective solutions for both flexible and fixed length constraints, as well as a special case with identical utility functions. The empirical evaluations further validate the effectiveness of our proposed algorithms in the domain of video recommendations. The results of this research have implications in various fields, including recommendation systems and assortment optimization, where the ordering of items significantly impacts the overall value obtained.
</details>
<details>
<summary>摘要</summary>
To address this issue, we explore the problem with non-monotone submodular functions and propose effective solutions for both flexible and fixed length constraints, as well as a special case with identical utility functions. Our proposed algorithms are validated through empirical evaluations in the domain of video recommendations, and the results have implications in various fields, including recommendation systems and assortment optimization, where the ordering of items significantly impacts the overall value obtained.
</details></li>
</ul>
<hr>
<h2 id="Fair-GANs-through-model-rebalancing-with-synthetic-data"><a href="#Fair-GANs-through-model-rebalancing-with-synthetic-data" class="headerlink" title="Fair GANs through model rebalancing with synthetic data"></a>Fair GANs through model rebalancing with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08638">http://arxiv.org/abs/2308.08638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhav Jain, Nasir Memon, Julian Togelius</li>
<li>for: 这篇研究旨在解决深度生成模型在训练时的偏见问题，特别是在收集数据时遇到的问题，如收集不够代表性的数据集。</li>
<li>methods: 我们提出了一种方法来mitigate偏见在现有的生成对抗网络中，通过在当前的对抗网络中进行潜在空间探索，从而获得了平衡的数据，并使用这些数据重训一个平衡的生成模型。我们还提出了一个偏见缓和损失函数，可以在训练时实现偏见缓和。</li>
<li>results: 我们在使用Stylegan2模型训练在FFHQ数据集上进行了过度种族优化，并获得了与传统方法相比的5倍以上的改进，同时保持了图像质量。我们还验证了我们的方法在Cifar-10数据集上的效果。最后，我们认为传统使用的图像质量指标（如Frechet对抗距离）无法应对偏见缓和问题。<details>
<summary>Abstract</summary>
Deep generative models require large amounts of training data. This often poses a problem as the collection of datasets can be expensive and difficult, in particular datasets that are representative of the appropriate underlying distribution (e.g. demographic). This introduces biases in datasets which are further propagated in the models. We present an approach to mitigate biases in an existing generative adversarial network by rebalancing the model distribution. We do so by generating balanced data from an existing unbalanced deep generative model using latent space exploration and using this data to train a balanced generative model. Further, we propose a bias mitigation loss function that shows improvements in the fairness metric even when trained with unbalanced datasets. We show results for the Stylegan2 models while training on the FFHQ dataset for racial fairness and see that the proposed approach improves on the fairness metric by almost 5 times, whilst maintaining image quality. We further validate our approach by applying it to an imbalanced Cifar-10 dataset. Lastly, we argue that the traditionally used image quality metrics such as Frechet inception distance (FID) are unsuitable for bias mitigation problems.
</details>
<details>
<summary>摘要</summary>
深度生成模型需要大量的训练数据。这经常导致数据收集成本高昂和困难，特别是收集 represntative 的下面分布（如人口结构）的数据集。这会导致模型中的偏见，这些偏见再次被模型中传递。我们提出了一种方法来减轻模型中的偏见，通过在现有的不均衡深度生成模型中进行秘密空间探索，并使用这些数据来训练一个均衡的生成模型。此外，我们提出了一种偏见减轻损失函数，这个函数可以在不均衡的数据集上训练，并且可以改善公平度量表，即frechet inception distance（FID）。我们在使用stylegan2模型，在ffhq数据集上进行人种公平性训练，并见到提议方法可以在公平度量表上提高约5倍，保持图像质量。此外，我们还验证了我们的方法，应用于cifar-10数据集上的偏见问题。最后，我们认为传统的图像质量指标，如frechet inception distance（FID），不适合偏见减轻问题。
</details></li>
</ul>
<hr>
<h2 id="FedPop-Federated-Population-based-Hyperparameter-Tuning"><a href="#FedPop-Federated-Population-based-Hyperparameter-Tuning" class="headerlink" title="FedPop: Federated Population-based Hyperparameter Tuning"></a>FedPop: Federated Population-based Hyperparameter Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08634">http://arxiv.org/abs/2308.08634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haokun Chen, Denis Krompass, Jindong Gu, Volker Tresp</li>
<li>for: 提高 federated learning 中 hyperparameter 的优化 (to optimize hyperparameters in federated learning)</li>
<li>methods: 使用人口生成算法进行 hyperparameter 优化 (using population-based evolutionary algorithms for hyperparameter optimization)</li>
<li>results: substantially outperforms  concurrent state-of-the-art hyperparameter tuning methods for federated learning (substantially outperforms prior HP tuning methods for FL)I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning (ML) paradigm, in which multiple clients collaboratively train ML models without centralizing their local data. Similar to conventional ML pipelines, the client local optimization and server aggregation procedure in FL are sensitive to the hyperparameter (HP) selection. Despite extensive research on tuning HPs for centralized ML, these methods yield suboptimal results when employed in FL. This is mainly because their "training-after-tuning" framework is unsuitable for FL with limited client computation power. While some approaches have been proposed for HP-Tuning in FL, they are limited to the HPs for client local updates. In this work, we propose a novel HP-tuning algorithm, called Federated Population-based Hyperparameter Tuning (FedPop), to address this vital yet challenging problem. FedPop employs population-based evolutionary algorithms to optimize the HPs, which accommodates various HP types at both client and server sides. Compared with prior tuning methods, FedPop employs an online "tuning-while-training" framework, offering computational efficiency and enabling the exploration of a broader HP search space. Our empirical validation on the common FL benchmarks and complex real-world FL datasets demonstrates the effectiveness of the proposed method, which substantially outperforms the concurrent state-of-the-art HP tuning methods for FL.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种分布式机器学习 (ML) 模式，在多个客户端协同训练 ML 模型时，不需要集中客户端的本地数据。与传统的 ML 管道一样，在 FL 中客户端本地优化和服务器聚合过程中，选择 hyperparameter (HP) 也是敏感的。尽管对中央 ML 的 HP 优化方法进行了广泛的研究，但这些方法在 FL 中具有较差的效果，主要是因为它们的 "训练后优化" 框架不适合 FL 中有限的客户端计算能力。有些方法已经为 FL 中 HP 优化提出了方案，但它们只能处理客户端本地更新中的 HP。在这项工作中，我们提出了一种新的 HP 优化算法，called Federated Population-based Hyperparameter Tuning (FedPop)，以解决这一重要但具有挑战性的问题。FedPop 使用了人口基因算法来优化 HP，可以处理多种 HP 类型，包括客户端和服务器两侧的 HP。与先前的优化方法相比，FedPop 采用了在线 "优化 while 训练" 框架，可以提高计算效率，并且可以探索更广泛的 HP 搜索空间。我们对常见的 FL 测试集和复杂的实际 FL 数据进行了实验验证，并证明了我们提出的方法的效果，与当前状态的同类方法相比，具有显著的提升。
</details></li>
</ul>
<hr>
<h2 id="LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data"><a href="#LSTM-Based-Forecasting-Model-for-GRACE-Accelerometer-Data" class="headerlink" title="LSTM-Based Forecasting Model for GRACE Accelerometer Data"></a>LSTM-Based Forecasting Model for GRACE Accelerometer Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08621">http://arxiv.org/abs/2308.08621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers">https://github.com/darbeheshti/lstm-based-analysis-for-grace-accelerometers</a></li>
<li>paper_authors: Neda Darbeheshti, Elahe Moradi</li>
<li>for: 这 paper 的目的是填充 GRACE 卫星计划中的数据 gap，并预测 GRACE 加速仪器数据。</li>
<li>methods: 这 paper 使用 Long Short-Term Memory (LSTM) 网络来训练一个可以预测 GRACE 加速仪器数据的模型。</li>
<li>results: 这 paper 的结果表明 LSTM 预测模型能够有效地填充 GRACE 数据 gap 并预测加速仪器数据。<details>
<summary>Abstract</summary>
The Gravity Recovery and Climate Experiment (GRACE) satellite mission, spanning from 2002 to 2017, has provided a valuable dataset for monitoring variations in Earth's gravity field, enabling diverse applications in geophysics and hydrology. The mission was followed by GRACE Follow-On in 2018, continuing data collection efforts. The monthly Earth gravity field, derived from the integration different instruments onboard satellites, has shown inconsistencies due to various factors, including gaps in observations for certain instruments since the beginning of the GRACE mission.   With over two decades of GRACE and GRACE Follow-On data now available, this paper proposes an approach to fill the data gaps and forecast GRACE accelerometer data. Specifically, we focus on accelerometer data and employ Long Short-Term Memory (LSTM) networks to train a model capable of predicting accelerometer data for all three axes.   In this study, we describe the methodology used to preprocess the accelerometer data, prepare it for LSTM training, and evaluate the model's performance. Through experimentation and validation, we assess the model's accuracy and its ability to predict accelerometer data for the three axes. Our results demonstrate the effectiveness of the LSTM forecasting model in filling gaps and forecasting GRACE accelerometer data.
</details>
<details>
<summary>摘要</summary>
gravitational Recovery and Climate Experiment (GRACE) 卫星任务，从2002年至2017年，提供了监测地球重力场变化的有价值数据集，推动了多种地球物理和水文应用。这个任务于2018年被GRACE Follow-On接续，继续数据采集。每月的地球重力场，来自不同卫星上的仪器集成，存在各种因素的差异，包括GRACE任务开始时的一些仪器观测缺失。 现在GRACE和GRACE Follow-On任务共计超过二十年的数据已经可用，这篇论文提出了一种方法，用于填充数据缺失并预测GRACE加速仪数据。我们专注于加速仪数据，使用Long Short-Term Memory（LSTM）网络训练一个能够预测加速仪数据的模型。 在这篇论文中，我们描述了对加速仪数据的预处理方法、LSTM训练准备和模型性能评价的方法。通过实验和验证，我们评估了模型的准确性和预测加速仪数据的三个轴的能力。我们的结果表明LSTM预测模型可以有效地填充GRACE加速仪数据的数据缺失和预测加速仪数据。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought"><a href="#Boosting-Logical-Reasoning-in-Large-Language-Models-through-a-New-Framework-The-Graph-of-Thought" class="headerlink" title="Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought"></a>Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08614">http://arxiv.org/abs/2308.08614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lei, pei-Hung Lin, Chunhua Liao, Caiwen Ding</li>
<li>for: 提高大规模模型的逻辑推理能力</li>
<li>methods: 提出Graph of Thoughts（GoT）引导技术</li>
<li>results: 比GPT-4高$89.7%$, $86%$,和$56%$的精度提高，和SOTA引导方法（Tree of Thought）的平均提高$23%$, $24%$,和$15%$<details>
<summary>Abstract</summary>
Recent advancements in large-scale models, such as GPT-4, have showcased remarkable capabilities in addressing standard queries. However, when facing complex problems that require multi-step logical reasoning, their accuracy dramatically decreases. Current research has explored the realm of \textit{prompting engineering} to bolster the inferential capacities of these models. Our paper unveils a pioneering prompting technique, dubbed \textit{Graph of Thoughts (GoT)}. Through testing on a trio of escalating challenges: the 24-point game, resolution of high-degree polynomial equations, and derivation of formulas for recursive sequences, our method outperformed GPT-4, achieving accuracy improvements of $89.7\%$, $86\%$, and $56\%$ for each respective task. Moreover, when juxtaposed with the state-of-the-art (SOTA) prompting method, \textit{Tree of Thought (ToT)}, our approach registered an average accuracy boost of $23\%$, $24\%$, and $15\%$.
</details>
<details>
<summary>摘要</summary>
最近的大型模型，如GPT-4，在处理标准查询方面表现出了惊人的能力。然而，当面临复杂的问题，需要多步逻辑推理时，其准确率却显著下降。当前的研究在\"推荐工程\"方面进行了努力。我们的论文揭示了一种创新的推荐技巧，名为\"思维图（GoT）\"。通过对三个增难的任务进行测试：24点游戏、解高度多项式方程、和 recursive sequences 的计算，我们的方法比GPT-4高$89.7\%$, $86\%$,和$56\%$。此外，与现有的 state-of-the-art（SOTA）推荐方法，\"树图思维（ToT）\"，我们的方法在平均上提高了$23\%$, $24\%$,和$15\%$。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach"><a href="#Integrating-Renewable-Energy-in-Agriculture-A-Deep-Reinforcement-Learning-based-Approach" class="headerlink" title="Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach"></a>Integrating Renewable Energy in Agriculture: A Deep Reinforcement Learning-based Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08611">http://arxiv.org/abs/2308.08611</a></li>
<li>repo_url: None</li>
<li>paper_authors: A. Wahid, I faiud, K. Mason</li>
<li>for: 这个研究是为了帮助农业投资者通过深度Q学习网络（DQN）优化农业 photovoltaic（PV）系统安装的决策。</li>
<li>methods: 这个研究开发了一个基于DQN的框架，以帮助农业投资者根据安装预算、政府补贴、能源需求、系统成本等因素做出了数据驱动的决策。</li>
<li>results: 研究发现，通过实施奖励机制，DQN可以学习据驱动的决策，并提供了对PV安装的全面理解。这种技术有助于农业投资者做出更有效的能源决策，提高能效性、降低环境影响和提高利润。<details>
<summary>Abstract</summary>
This article investigates the use of Deep Q-Networks (DQNs) to optimize decision-making for photovoltaic (PV) systems installations in the agriculture sector. The study develops a DQN framework to assist agricultural investors in making informed decisions considering factors such as installation budget, government incentives, energy requirements, system cost, and long-term benefits. By implementing a reward mechanism, the DQN learns to make data-driven decisions on PV integration. The analysis provides a comprehensive understanding of how DQNs can support investors in making decisions about PV installations in agriculture. This research has significant implications for promoting sustainable and efficient farming practices while also paving the way for future advancements in this field. By leveraging DQNs, agricultural investors can make optimized decisions that improve energy efficiency, reduce environmental impact, and enhance profitability. This study contributes to the advancement of PV integration in agriculture and encourages further innovation in this promising area.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Atom-by-atom-protein-generation-and-beyond-with-language-models"><a href="#Atom-by-atom-protein-generation-and-beyond-with-language-models" class="headerlink" title="Atom-by-atom protein generation and beyond with language models"></a>Atom-by-atom protein generation and beyond with language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09482">http://arxiv.org/abs/2308.09482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Flam-Shepherd, Kevin Zhu, Alán Aspuru-Guzik</li>
<li>for: 这 paper 是为了探讨蛋白质语言模型是否可以学习蛋白质的atom级表示，并且可以生成蛋白质之外的其他分子。</li>
<li>methods: 这 paper 使用的方法是使用化学语言模型，这些模型可以学习小分子的atom级表示，包括所有的原子、键和环。</li>
<li>results: 这 paper 的结果表明，化学语言模型可以学习蛋白质的atom级表示，并且可以生成蛋白质之外的其他分子，包括 modificated 的侧链和不自然的氨基酸。此外，这 paper 还发现化学语言模型可以同时探索蛋白质空间和化学空间，并生成新的蛋白质-药物 conjugate。<details>
<summary>Abstract</summary>
Protein language models learn powerful representations directly from sequences of amino acids. However, they are constrained to generate proteins with only the set of amino acids represented in their vocabulary. In contrast, chemical language models learn atom-level representations of smaller molecules that include every atom, bond, and ring. In this work, we show that chemical language models can learn atom-level representations of proteins enabling protein generation unconstrained to the standard genetic code and far beyond it. In doing so, we show that language models can generate entire proteins atom by atom -- effectively learning the multiple hierarchical layers of molecular information that define proteins from their primary sequence to their secondary, and tertiary structure. We demonstrate language models are able to explore beyond protein space -- generating proteins with modified sidechains that form unnatural amino acids. Even further, we find that language models can explore chemical space and protein space simultaneously and generate novel examples of protein-drug conjugates. The results demonstrate the potential for biomolecular design at the atom level using language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Proprioceptive-Learning-with-Soft-Polyhedral-Networks"><a href="#Proprioceptive-Learning-with-Soft-Polyhedral-Networks" class="headerlink" title="Proprioceptive Learning with Soft Polyhedral Networks"></a>Proprioceptive Learning with Soft Polyhedral Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08538">http://arxiv.org/abs/2308.08538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobo Liu, Xudong Han, Wei Hong, Fang Wan, Chaoyang Song</li>
<li>for: 本研究旨在开发一种能够实现自适应吸附、柔软 proprioception 和高精度力学感知的软体网络，用于Robotics 应用。</li>
<li>methods: 本研究使用软体网络和高速运动追踪系统，并通过学习动态力学特征来实现自适应吸附和 proprioception。</li>
<li>results: 研究显示，软体网络可以在实时情况下测量6D 力和扭矩的准确性为0.25&#x2F;0.24&#x2F;0.35 N和0.025&#x2F;0.034&#x2F;0.006 Nm，并在静态适应中添加塑性和待遇模式以细化预测结果。这种软体网络具有简单设计、全面适应、 proprioception 和高精度力学感知等特点，适用于低成本 Robotics 应用，可以进行敏捷和竞争性的握摸、软制造和人机交互等任务，并且具有超过100万次使用寿命。<details>
<summary>Abstract</summary>
Proprioception is the "sixth sense" that detects limb postures with motor neurons. It requires a natural integration between the musculoskeletal systems and sensory receptors, which is challenging among modern robots that aim for lightweight, adaptive, and sensitive designs at a low cost. Here, we present the Soft Polyhedral Network with an embedded vision for physical interactions, capable of adaptive kinesthesia and viscoelastic proprioception by learning kinetic features. This design enables passive adaptations to omni-directional interactions, visually captured by a miniature high-speed motion tracking system embedded inside for proprioceptive learning. The results show that the soft network can infer real-time 6D forces and torques with accuracies of 0.25/0.24/0.35 N and 0.025/0.034/0.006 Nm in dynamic interactions. We also incorporate viscoelasticity in proprioception during static adaptation by adding a creep and relaxation modifier to refine the predicted results. The proposed soft network combines simplicity in design, omni-adaptation, and proprioceptive sensing with high accuracy, making it a versatile solution for robotics at a low cost with more than 1 million use cycles for tasks such as sensitive and competitive grasping, and touch-based geometry reconstruction. This study offers new insights into vision-based proprioception for soft robots in adaptive grasping, soft manipulation, and human-robot interaction.
</details>
<details>
<summary>摘要</summary>
Proprioception 是机器人的“第六感”，通过电动神经元来检测四肢的姿势。它需要自然地结合肌骨系统和感测器，这在现代机器人设计中是一个挑战。我们现在介绍了一种名为软多面网络的设计，具有内置的视觉捕捉和 proprioceptive 学习。这种设计可以在多向交互中进行适应性，通过学习动态特征来进行适应性和弹性 proprioception。我们还在静态适应中添加了延展和塑性修饰器，以便精细化预测结果。我们的软网络设计简单、多样化、 proprioceptive 感知和高精度准确，可以在低成本下实现100万次使用循环，用于敏捷抓取、软操作和人机交互等任务。这项研究为软机器人在适应抓取、软抓取和人机交互领域提供了新的视野和突破。
</details></li>
</ul>
<hr>
<h2 id="Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems"><a href="#Can-Transformers-Learn-Optimal-Filtering-for-Unknown-Systems" class="headerlink" title="Can Transformers Learn Optimal Filtering for Unknown Systems?"></a>Can Transformers Learn Optimal Filtering for Unknown Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08536">http://arxiv.org/abs/2308.08536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haldun Balim, Zhe Du, Samet Oymak, Necmiye Ozay</li>
<li>for: 这个论文旨在使用 transformers 来解决动力系统中的优化输出估计问题，并证明 transformers 可以快速适应不同的系统并且达到优化的性能。</li>
<li>methods: 这篇论文使用 transformers 来生成输出预测，并通过训练 transformers 使其能够适应不同的系统。</li>
<li>results: 论文的实验结果表明，使用 transformers 可以快速适应不同的系统并且达到优化的性能，并且在具有非同偶播动的系统上也表现良好。<details>
<summary>Abstract</summary>
Transformers have demonstrated remarkable success in natural language processing; however, their potential remains mostly unexplored for problems arising in dynamical systems. In this work, we investigate the optimal output estimation problem using transformers, which generate output predictions using all the past ones. We train the transformer using various systems drawn from a prior distribution and then evaluate its performance on previously unseen systems from the same distribution. As a result, the obtained transformer acts like a prediction algorithm that learns in-context and quickly adapts to and predicts well for different systems - thus we call it meta-output-predictor (MOP). MOP matches the performance of the optimal output estimator, based on Kalman filter, for most linear dynamical systems even though it does not have access to a model. We observe via extensive numerical experiments that MOP also performs well in challenging scenarios with non-i.i.d. noise, time-varying dynamics, and nonlinear dynamics like a quadrotor system with unknown parameters. To further support this observation, in the second part of the paper, we provide statistical guarantees on the performance of MOP and quantify the required amount of training to achieve a desired excess risk during test-time. Finally, we point out some limitations of MOP by identifying two classes of problems MOP fails to perform well, highlighting the need for caution when using transformers for control and estimation.
</details>
<details>
<summary>摘要</summary>
卷积 Nevilles 已经在自然语言处理中展现出惊人的成功，但它们的潜在仍然未被完全探索，特别是在动力系统中。在这项工作中，我们使用卷积来解决输出预测问题，卷积可以使用所有过去的输出来生成输出预测。我们在不同的系统 drawn from a prior distribution 上训练卷积，然后评估其在未经见过的系统上的性能。因此，得到的卷积可以被称为元输出预测器（MOP）。MOP与基于 Kalman 滤波器的优化输出预测器匹配性能，即使它没有访问模型。我们通过广泛的数字实验观察到，MOP在非同分布的噪声、时间变化的动力系统和非线性动力系统（如四旋翼系统）中也表现良好。在第二部分的论文中，我们为MOP的性能提供了统计保证，并评估在测试时需要多少训练时间来实现所需的过量风险。最后，我们指出了MOP在某些情况下的局限性，并提出了使用卷积进行控制和估计时应注意的一些问题。
</details></li>
</ul>
<hr>
<h2 id="Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches"><a href="#Painter-Teaching-Auto-regressive-Language-Models-to-Draw-Sketches" class="headerlink" title="Painter: Teaching Auto-regressive Language Models to Draw Sketches"></a>Painter: Teaching Auto-regressive Language Models to Draw Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08520">http://arxiv.org/abs/2308.08520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Pourreza, Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Pulkit Madan, Roland Memisevic</li>
<li>for: 这个论文是用于应用大语言模型（LLM）在图像生成任务上的，以直接生成虚拟画刷的笔刷来绘制图像。</li>
<li>methods: 这个论文使用了预先训练在大文本 corpus 上的 off-the-shelf LLM，通过 fine-tuning 来新任务 while preserving 语言理解能力。</li>
<li>results: 论文提出了一种基于 LLM 的自然语言描述到笔刷生成方法，可以从文本描述中生成绘制，从画布上移除对象，并在绘制中探测和分类对象。结果很有推动力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have made tremendous progress in natural language understanding and they have also been successfully adopted in other domains such as computer vision, robotics, reinforcement learning, etc. In this work, we apply LLMs to image generation tasks by directly generating the virtual brush strokes to paint an image. We present Painter, an LLM that can convert user prompts in text description format to sketches by generating the corresponding brush strokes in an auto-regressive way. We construct Painter based on off-the-shelf LLM that is pre-trained on a large text corpus, by fine-tuning it on the new task while preserving language understanding capabilities. We create a dataset of diverse multi-object sketches paired with textual prompts that covers several object types and tasks. Painter can generate sketches from text descriptions, remove objects from canvas, and detect and classify objects in sketches. Although this is an unprecedented pioneering work in using LLMs for auto-regressive image generation, the results are very encouraging.
</details>
<details>
<summary>摘要</summary>
巨型自然语言模型（LLM）在自然语言理解方面已经取得了巨大的进步，同时也在其他领域如计算机视觉、机器人学习、奖励学习等领域得到了成功应用。在这项工作中，我们通过直接生成虚拟毫幅来使用LLM进行图像生成任务。我们介绍了一种名为“画家”的LLM，可以将用户提交的文本描述转换为笔划画作。我们基于市场上 readily available的LLM，通过精心调整和保留语言理解能力来构建了画家。我们创建了一个多样化的多对象素描绘集合，其中包括了各种物体和任务。画家可以从文本描述中生成素描绘，将物体从画布上除除，以及在素描绘中检测和分类物体。虽然这是一项前所未有的使用LLM进行自动往返图像生成的研究，但结果很有激励力。
</details></li>
</ul>
<hr>
<h2 id="Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems"><a href="#Two-and-a-half-Order-Score-based-Model-for-Solving-3D-Ill-posed-Inverse-Problems" class="headerlink" title="Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems"></a>Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08511">http://arxiv.org/abs/2308.08511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirong Li, Yanyang Wang, Jianjia Zhang, Weiwen Wu, Hengyong Yu</li>
<li>For: 提高 CT 和 MRI 的三维图像重建精度* Methods: 使用两个半级分数模型（TOSM），在训练阶段学习二维数据分布，在重建阶段使用三个方向的补做分数（极轴、极斜、极斜）实现更加精确的重建* Results: 在大规模稀缺视图 CT 和快速 MRI 数据集上进行了广泛的实验，并取得了解决三维矩阵问题的最新成果，其中解决了 slice 间不一致问题，导致高质量三维图像重建<details>
<summary>Abstract</summary>
Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are crucial technologies in the field of medical imaging. Score-based models have proven to be effective in addressing different inverse problems encountered in CT and MRI, such as sparse-view CT and fast MRI reconstruction. However, these models face challenges in achieving accurate three dimensional (3D) volumetric reconstruction. The existing score-based models primarily focus on reconstructing two dimensional (2D) data distribution, leading to inconsistencies between adjacent slices in the reconstructed 3D volumetric images. To overcome this limitation, we propose a novel two-and-a-half order score-based model (TOSM). During the training phase, our TOSM learns data distributions in 2D space, which reduces the complexity of training compared to directly working on 3D volumes. However, in the reconstruction phase, the TOSM updates the data distribution in 3D space, utilizing complementary scores along three directions (sagittal, coronal, and transaxial) to achieve a more precise reconstruction. The development of TOSM is built on robust theoretical principles, ensuring its reliability and efficacy. Through extensive experimentation on large-scale sparse-view CT and fast MRI datasets, our method demonstrates remarkable advancements and attains state-of-the-art results in solving 3D ill-posed inverse problems. Notably, the proposed TOSM effectively addresses the inter-slice inconsistency issue, resulting in high-quality 3D volumetric reconstruction.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 和 magnetic resonance imaging (MRI) 是医学图像领域的重要技术。 score-based 模型在 CT 和 MRI 中已经证明是有效的，但这些模型在获取精确三维（3D）组织图像时面临挑战。现有的 score-based 模型主要专注于重建二维（2D）数据分布，导致邻近层的不一致性问题。为了解决这个限制，我们提出了一个新的二阶三方向分布学习（TOSM）模型。在训练阶段，我们的 TOSM 将数据分布学习在二维空间，这样训练的复杂度比较低。但在重建阶段，TOSM 将数据分布更新到三维空间，运用三个方向（横轴、纵轴和横条）的补充分布来获得更精确的重建。TOSM 的开发基于坚固的理论基础， guarantees its reliability and efficacy。通过对大规模的简范 CT 和快速 MRI 数据进行广泛的实验，我们的方法展现出了很大的进步，并在解决 3D 逆问题中实现了州际级的结果。特别是，我们的 TOSM 干预了邻近层不一致性问题，实现了高品质的 3D 组织图像重建。
</details></li>
</ul>
<hr>
<h2 id="Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater"><a href="#Autoencoding-a-Soft-Touch-to-Learn-Grasping-from-On-land-to-Underwater" class="headerlink" title="Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater"></a>Autoencoding a Soft Touch to Learn Grasping from On-land to Underwater</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08510">http://arxiv.org/abs/2308.08510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bionicdl-sustech/amphibioussoftfinger">https://github.com/bionicdl-sustech/amphibioussoftfinger</a></li>
<li>paper_authors: Ning Guo, Xudong Han, Xiaobo Liu, Shuqiao Zhong, Zhiyuan Zhou, Jian Lin, Jiansheng Dai, Fang Wan, Chaoyang Song</li>
<li>for:  investigate the transferability of grasping knowledge from on-land to underwater</li>
<li>methods:  vision-based soft robotic finger, Supervised Variational Autoencoder (SVAE)</li>
<li>results:  superior adaptation to changing environments, soft, delicate, and reactive grasping, improved reliability and robustness at a much-reduced cost<details>
<summary>Abstract</summary>
Robots play a critical role as the physical agent of human operators in exploring the ocean. However, it remains challenging to grasp objects reliably while fully submerging under a highly pressurized aquatic environment with little visible light, mainly due to the fluidic interference on the tactile mechanics between the finger and object surfaces. This study investigates the transferability of grasping knowledge from on-land to underwater via a vision-based soft robotic finger that learns 6D forces and torques (FT) using a Supervised Variational Autoencoder (SVAE). A high-framerate camera captures the whole-body deformations while a soft robotic finger interacts with physical objects on-land and underwater. Results show that the trained SVAE model learned a series of latent representations of the soft mechanics transferrable from land to water, presenting a superior adaptation to the changing environments against commercial FT sensors. Soft, delicate, and reactive grasping enabled by tactile intelligence enhances the gripper's underwater interaction with improved reliability and robustness at a much-reduced cost, paving the path for learning-based intelligent grasping to support fundamental scientific discoveries in environmental and ocean research.
</details>
<details>
<summary>摘要</summary>
роботы扮演了人类运行员的物理代理人在探索海洋中发挥重要作用。然而，在高压力水中充满黑暗的环境中，握持物品的可靠性仍然是一个挑战，主要是因为水媒体的干扰对手指和物品表面之间的摩擦力产生了影响。本研究探讨了将从陆地上的握持知识传递到水下via一种视觉基于的软机械脚的学习6D力和扭矩（FT）的方法。一个高速摄像机记录了软机械脚与物理对象的全身弯曲变形，而在陆地和水下两个环境中，软机械脚与物理对象进行交互。结果显示，已经训练过的SVAE模型学习了一系列对软机械力学的隐藏表示，可以在水下环境中传递陆地上的握持知识，比商业FT传感器更有效，提供了软、细腻、敏感的握持能力，使软机械脚在水下交互中具有更高的可靠性和可重复性，降低成本，开拓出学习基于智能握持的 ocean 研究新途径。
</details></li>
</ul>
<hr>
<h2 id="ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures"><a href="#ResBuilder-Automated-Learning-of-Depth-with-Residual-Structures" class="headerlink" title="ResBuilder: Automated Learning of Depth with Residual Structures"></a>ResBuilder: Automated Learning of Depth with Residual Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08504">http://arxiv.org/abs/2308.08504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julian Burghoff, Matthias Rottmann, Jill von Conta, Sebastian Schoenen, Andreas Witte, Hanno Gottschalk</li>
<li>for: 这个论文是为了开发一个基于ResNet的神经网络搜索算法，以实现高精度低计算成本的神经网络模型。</li>
<li>methods: 这个算法使用了一种名为Resbuilder的神经网络搜索算法，可以从零开始构建ResNet架构，并且可以修改现有架构并移除&#x2F;插入ResNet块。</li>
<li>results: 在不同的图像分类任务上，Resbuilder可以达到相对较低的计算成本，同时保持高度的准确率，与当前的Off-the-shelf ResNets相比。此外，我们还在一个商业应用中进行了应用，并证明了这种性能可以普遍应用于不同的任务。<details>
<summary>Abstract</summary>
In this work, we develop a neural architecture search algorithm, termed Resbuilder, that develops ResNet architectures from scratch that achieve high accuracy at moderate computational cost. It can also be used to modify existing architectures and has the capability to remove and insert ResNet blocks, in this way searching for suitable architectures in the space of ResNet architectures. In our experiments on different image classification datasets, Resbuilder achieves close to state-of-the-art performance while saving computational cost compared to off-the-shelf ResNets. Noteworthy, we once tune the parameters on CIFAR10 which yields a suitable default choice for all other datasets. We demonstrate that this property generalizes even to industrial applications by applying our method with default parameters on a proprietary fraud detection dataset.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们开发了一种神经网络搜索算法，即Resbuilder，可以从头开始构建高精度且计算成本相对较低的ResNet架构。它还可以修改现有架构，并具有移除和插入ResNet块的能力，因此可以在ResNet架构空间中进行搜索。在我们对不同的图像分类 datasets 进行了实验后，Resbuilder 能够达到 state-of-the-art 性能水平，同时相比于各种预制 ResNet 更加经济。值得注意的是，我们在 CIFAR10 上进行了参数调整，得到了一个适合所有其他 datasets 的默认选择。我们示出了这种特性在实际应用中也能够普遍化，通过将我们的方法与默认参数应用于一个商业领域中的一个 propriety 销售欺诈 dataset。
</details></li>
</ul>
<hr>
<h2 id="Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models"><a href="#Time-Travel-in-LLMs-Tracing-Data-Contamination-in-Large-Language-Models" class="headerlink" title="Time Travel in LLMs: Tracing Data Contamination in Large Language Models"></a>Time Travel in LLMs: Tracing Data Contamination in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08493">http://arxiv.org/abs/2308.08493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahriar Golchin, Mihai Surdeanu<br>for:The paper aims to identify data contamination within large language models (LLMs) to better understand their effectiveness on other tasks.methods:The approach uses “guided instruction” prompts to identify potential contamination in individual instances, and assesses if an entire dataset partition is contaminated based on the average overlap score with reference instances or a classifier based on GPT-4 with in-context learning prompting.results:The approach achieves an accuracy between 92% and 100% in detecting data contamination with seven datasets, and finds that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.Here is the simplified Chinese text for the three key points:for:这篇论文目标是通过识别大语言模型（LLM）中的数据污染来更好地理解它们在其他任务上的效果。methods:这种方法使用“导向指令”提示来识别个体实例中的可能污染，并根据平均重叠分数与参考实例进行整个数据分区是否污染的评估。results:该方法在七个数据集上达到了92%-100%的准确率，并发现GPT-4在AG News、WNLI和XSum数据集上存在污染。<details>
<summary>Abstract</summary>
Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ "guided instruction:" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset partition as contaminated if the average overlap score with the reference instances (as measured by ROUGE or BLEURT) is statistically significantly better with the guided instruction vs. a general instruction that does not include the dataset and partition name. The second idea marks a dataset as contaminated if a classifier based on GPT-4 with in-context learning prompting marks multiple instances as contaminated. Our best method achieves an accuracy between 92% and 100% in detecting if an LLM is contaminated with seven datasets, containing train and test/validation partitions, when contrasted with manual evaluation by human expert. Further, our findings indicate that GPT-4 is contaminated with AG News, WNLI, and XSum datasets.
</details>
<details>
<summary>摘要</summary>
大数据污染（即在大语言模型（LLM）训练数据中存在下游任务的测试数据）是一个 potential major issue，可能会影响 LLM 的效果。我们提出了一种简单 yet effective的方法来 Identify 大数据污染。我们的方法的核心是在一个小随机样本中 Identify 潜在的污染，然后判断整个数据分区是否污染。为了估计个体实例的污染情况，我们使用 "导向指令"：一个包含数据集名、分区类型和参考实例的开头部分的提问，要求 LLM 完成它。如果 LLM 的输出与参考实例的后半部分匹配，则认为该实例污染。要判断整个分区是否污染，我们提出了两个想法。第一个想法是，如果在指令中包含数据集名和分区类型时，LLM 的输出与参考实例的 overlap 得分（使用 ROUGE 或 BLEURT 评估）是 statistically significantly better 的，那么认为该分区污染。第二个想法是，如果一个基于 GPT-4 的分类器通过受Context learning提示标记多个实例为污染，那么认为该数据集污染。我们的最佳方法可以在七个数据集（包括训练和测试/验证分区）中准确地检测 LLM 是否污染，与人工评估比较。此外，我们的发现表明 GPT-4 污染 AG News、WNLI 和 XSum 数据集。
</details></li>
</ul>
<hr>
<h2 id="Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals"><a href="#Label-Propagation-Techniques-for-Artifact-Detection-in-Imbalanced-Classes-using-Photoplethysmogram-Signals" class="headerlink" title="Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals"></a>Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08480">http://arxiv.org/abs/2308.08480</a></li>
<li>repo_url: None</li>
<li>paper_authors: Clara Macabiau, Thanh-Dung Le, Kevin Albert, Philippe Jouvet, Rita Noumeir</li>
<li>for: 这个研究旨在提高血液压力信号中的精度，并增强血液压力信号基础的靠拢性。</li>
<li>methods: 这个研究使用了标签传播技术来传播标签 между血液压力信号样本。特别是在不均衡类型的情况下，清洁的血液压力信号样本被大量的噪声样本淹没。</li>
<li>results: 研究结果表明，使用标签传播技术可以高效地标注医疗数据集，即使清洁样本scarce。对artefact的分类，我们比较了经典分类器（如权重平均分类器、神经网络等）和自动标注算法。结果显示，使用标签传播技术可以更好地检测artefact。<details>
<summary>Abstract</summary>
Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring vital signs, but they are susceptible to motion artifacts that can lead to inaccurate interpretations. In this study, the use of label propagation techniques to propagate labels among PPG samples is explored, particularly in imbalanced class scenarios where clean PPG samples are significantly outnumbered by artifact-contaminated samples. With a precision of 91%, a recall of 90% and an F1 score of 90% for the class without artifacts, the results demonstrate its effectiveness in labeling a medical dataset, even when clean samples are rare. For the classification of artifacts our study compares supervised classifiers such as conventional classifiers and neural networks (MLP, Transformers, FCN) with the semi-supervised label propagation algorithm. With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN supervised model gives good results, but the semi-supervised algorithm performs better in detecting artifacts. The findings suggest that the semi-supervised algorithm label propagation hold promise for artifact detection in PPG signals, which can enhance the reliability of PPG-based health monitoring systems in real-world applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs"><a href="#LLM4TS-Two-Stage-Fine-Tuning-for-Time-Series-Forecasting-with-Pre-Trained-LLMs" class="headerlink" title="LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs"></a>LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08469">http://arxiv.org/abs/2308.08469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ching Chang, Wen-Chih Peng, Tien-Fu Chen<br>for: LLM4TS is designed to enhance time-series forecasting by leveraging pre-trained Large Language Models (LLMs).methods: The approach combines time-series patching with temporal encoding, and uses a two-stage fine-tuning process with supervised fine-tuning and task-specific downstream fine-tuning. Additionally, the model utilizes Parameter-Efficient Fine-Tuning (PEFT) techniques to adapt the pre-trained LLMs for time-series forecasting.results: LLM4TS has achieved state-of-the-art results in long-term forecasting, and has demonstrated exceptional capabilities as both a robust representation learner and an effective few-shot learner.Here is the Chinese translation of the three key points:for: LLM4TS 是为了提高时间序列预测的表现，利用预训练的大语言模型（LLMs）。methods: 该方法使用时间序列补充和时间编码，并采用了两阶段训练过程：首先进行监督训练，然后进行任务特定的下游训练。此外，模型还使用了Parameter-Efficient Fine-Tuning（PEFT）技术来适应预训练 LLMS。results: LLM4TS 已经实现了长期预测的州际纪录，并表现出了出色的Robust Representation Learning和几招学习能力。<details>
<summary>Abstract</summary>
In this work, we leverage pre-trained Large Language Models (LLMs) to enhance time-series forecasting. Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting. Due to limited large-scale time-series data for building robust foundation models, our approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By combining time-series patching with temporal encoding, we have enhanced the capability of LLMs to handle time-series data effectively. Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the LLM towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained LLMs without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT) techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art results in long-term forecasting. Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained LLM.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们利用预训练的大语言模型（LLM）提高时间序列预测。随着自然语言处理和计算机视觉模型的统一发展，我们期望创建相似的模型，以提高长期时间序列预测能力。由于有限的大规模时间序列数据建立坚实基础模型，我们的方法LLM4TS专注于利用预训练LLM的优势。通过将时间序列补充与时间编码相结合，我们有效地使得LLM处理时间序列数据。受到协助chatbot领域的超级vised fine-tuning的激发，我们采用了两个阶段的精度调整过程：首先进行有监督的精度调整，然后进行任务特定的下游精度调整。此外，为了不需要广泛参数调整，我们采用了多种Parameter-Efficient Fine-Tuning（PEFT）技术。通过这些创新，LLM4TS已经实现了长期预测的state-of-the-art结果。我们的模型还表现出了出色的robust表示学习和几招学习能力，这与预训练LLM传递的知识有着密切的关系。
</details></li>
</ul>
<hr>
<h2 id="An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks"><a href="#An-Expert’s-Guide-to-Training-Physics-informed-Neural-Networks" class="headerlink" title="An Expert’s Guide to Training Physics-informed Neural Networks"></a>An Expert’s Guide to Training Physics-informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08468">http://arxiv.org/abs/2308.08468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/predictiveintelligencelab/jaxpi">https://github.com/predictiveintelligencelab/jaxpi</a></li>
<li>paper_authors: Sifan Wang, Shyam Sankaran, Hanwen Wang, Paris Perdikaris</li>
<li>for: 本研究旨在提供PINNs训练最佳实践和挑战性问题集，以提高PINNs的训练效率和总准确性。</li>
<li>methods: 本研究使用了多种architecture和训练策略，包括JAX库的优化。</li>
<li>results: 研究显示了PINNs训练最佳实践和挑战性问题集可以获得状态之准确性，并提供了未来研究使用的强制基线。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints. Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise. In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs. We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models. We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes. To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios.
</details>
<details>
<summary>摘要</summary>
физикс-指定神经网络（PINNs）已经广泛应用于深度学习框架，可以快速同 observational data 和部分偏微分方程（PDE）约束相结合。然而，它们的实际效果可能受训练异常和用户缺乏深度学习专业知识的影响。在这篇论文中，我们提出了一系列最佳实践，可以大幅提高 PINNs 的训练效率和总准确性。我们还提出了一些挑战性的 benchmark 问题，描述了 PINNs 训练中的一些最主要的困难，并对不同架构选择和训练策略的影响进行了完整的和可重复的ablation 研究。我们显示了我们的方法和指导原则可以达到状态态的结果，并提供了强大的基准，以便 future studies 可以用于比较。为此，我们还发布了高度优化的库在 JAX 上，可以重现报告中的所有结果，支持未来的研究studies，以及方便新用 случа scenario 的适应。
</details></li>
</ul>
<hr>
<h2 id="On-Neural-Quantum-Support-Vector-Machines"><a href="#On-Neural-Quantum-Support-Vector-Machines" class="headerlink" title="On Neural Quantum Support Vector Machines"></a>On Neural Quantum Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08467">http://arxiv.org/abs/2308.08467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML">https://github.com/GhadaAbdulsalam/Explainable_Heart_Disease_Prediction_Using_Ensemble-Quantum_ML</a></li>
<li>paper_authors: Lars Simon, Manuel Radons</li>
<li>for: 本文介绍了四种算法用于神经支持向量机（NSVM）训练，并证明其可行性。在这篇通知中，我们将介绍神经量子支持向量机（NSVM），并扩展我们的结果到这种设定下。</li>
<li>methods: 本文使用的方法包括NSVM的量子kernel和相关的训练算法。</li>
<li>results: 本文的结果表明，使用量子kernel可以提高NSVM的性能，并且可以应用于各种问题。<details>
<summary>Abstract</summary>
In \cite{simon2023algorithms} we introduced four algorithms for the training of neural support vector machines (NSVMs) and demonstrated their feasibility. In this note we introduce neural quantum support vector machines, that is, NSVMs with a quantum kernel, and extend our results to this setting.
</details>
<details>
<summary>摘要</summary>
在《\cite{simon2023algorithms}》中，我们介绍了四种算法用于神经支持向量机（NSVM）的训练，并证明其可行性。在这个笔记中，我们将介绍神经量子支持向量机（NSVM），即使用量子kernel的NSVM，并扩展我们的结果到这个设定下。Here's the word-for-word translation:在《\cite{simon2023algorithms}》中，我们介绍了四种算法用于神经支持向量机（NSVM）的训练，并证明其可行性。在这个笔记中，我们将介绍神经量子支持向量机（NSVM），即使用量子kernel的NSVM，并扩展我们的结果到这个设定下。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks"><a href="#Hierarchical-Uncertainty-Estimation-for-Medical-Image-Segmentation-Networks" class="headerlink" title="Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks"></a>Hierarchical Uncertainty Estimation for Medical Image Segmentation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08465">http://arxiv.org/abs/2308.08465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Bai, Wenjia Bai</li>
<li>for:  This paper aims to build a trustworthy medical image segmentation model by estimating the uncertainty of the model prediction.</li>
<li>methods: The proposed method leverages the hierarchical encoder architecture of state-of-the-art image segmentation networks, and uses a skip-connection module to model multi-level uncertainties.</li>
<li>results: The proposed method can achieve high segmentation performance and provide meaningful uncertainty maps that can be used for out-of-distribution detection.Here’s the Chinese translation of the three pieces of information:</li>
<li>for: 这篇论文目标是建立一个可靠的医疗图像分割模型，并且可以计算模型预测结果的不确定性。</li>
<li>methods: 该方法利用现有的医疗图像分割网络的层次编码结构，并使用skip-connection模块来模拟多级不确定性。</li>
<li>results: 该方法可以实现高效的图像分割性能，同时提供有用的不确定性地图，可以用于异常检测。<details>
<summary>Abstract</summary>
Learning a medical image segmentation model is an inherently ambiguous task, as uncertainties exist in both images (noise) and manual annotations (human errors and bias) used for model training. To build a trustworthy image segmentation model, it is important to not just evaluate its performance but also estimate the uncertainty of the model prediction. Most state-of-the-art image segmentation networks adopt a hierarchical encoder architecture, extracting image features at multiple resolution levels from fine to coarse. In this work, we leverage this hierarchical image representation and propose a simple yet effective method for estimating uncertainties at multiple levels. The multi-level uncertainties are modelled via the skip-connection module and then sampled to generate an uncertainty map for the predicted image segmentation. We demonstrate that a deep learning segmentation network such as U-net, when implemented with such hierarchical uncertainty estimation module, can achieve a high segmentation performance, while at the same time provide meaningful uncertainty maps that can be used for out-of-distribution detection.
</details>
<details>
<summary>摘要</summary>
学习医疗影像分割模型是一个自然而又不确定的任务，因为影像中的噪声和人工标注（人类错误和偏见）对模型训练中存在不确定性。为建立可靠的影像分割模型，不仅需要评估其性能，还需要估计模型预测结果中的不确定性。大多数当前的影像分割网络采用层次编码结构，从细到粗提取影像特征。在这种工作中，我们利用这种层次图像表示，并提议一种简单 yet effective的方法来估计多个水平的不确定性。这些多个不确定性被模拟为跳过连接模块，然后随机抽取来生成预测图像分割结果中的不确定性地图。我们示出，通过将深度学习分割网络和多个水平不确定性估计模块相结合，可以实现高水平的分割性能，同时提供有意义的不确定性地图，可以用于非标准分布检测。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/cs.LG_2023_08_17/" data-id="clorjzl8r00o7f1889htt90zz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_17" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/17/eess.IV_2023_08_17/" class="article-date">
  <time datetime="2023-08-17T09:00:00.000Z" itemprop="datePublished">2023-08-17</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/17/eess.IV_2023_08_17/">eess.IV - 2023-08-17</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation"><a href="#Eosinophils-Instance-Object-Segmentation-on-Whole-Slide-Imaging-Using-Multi-label-Circle-Representation" class="headerlink" title="Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation"></a>Eosinophils Instance Object Segmentation on Whole Slide Imaging Using Multi-label Circle Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08974">http://arxiv.org/abs/2308.08974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yilinliu610730/eoe">https://github.com/yilinliu610730/eoe</a></li>
<li>paper_authors: Yilin Liu, Ruining Deng, Juming Xiong, Regina N Tyree, Hernan Correa, Girish Hiremath, Yaohong Wang, Yuankai Huo</li>
<li>for: 这个论文主要针对的是营养不良引起的食管炎的诊断和评估。</li>
<li>methods: 这篇论文提出了一种基于圆形图像分割的多标签圆形蛇形态模型，用于自动检测和分割食管中的凝血细胞。</li>
<li>results: 实验结果表明，这种多标签圆形蛇形态模型在食管炎细胞的标准化分割 tasks 中的平均准确率比传统的Mask R-CNN模型和DeepSnake模型高。<details>
<summary>Abstract</summary>
Eosinophilic esophagitis (EoE) is a chronic and relapsing disease characterized by esophageal inflammation. Symptoms of EoE include difficulty swallowing, food impaction, and chest pain which significantly impact the quality of life, resulting in nutritional impairments, social limitations, and psychological distress. The diagnosis of EoE is typically performed with a threshold (15 to 20) of eosinophils (Eos) per high-power field (HPF). Since the current counting process of Eos is a resource-intensive process for human pathologists, automatic methods are desired. Circle representation has been shown as a more precise, yet less complicated, representation for automatic instance cell segmentation such as CircleSnake approach. However, the CircleSnake was designed as a single-label model, which is not able to deal with multi-label scenarios. In this paper, we propose the multi-label CircleSnake model for instance segmentation on Eos. It extends the original CircleSnake model from a single-label design to a multi-label model, allowing segmentation of multiple object types. Experimental results illustrate the CircleSnake model's superiority over the traditional Mask R-CNN model and DeepSnake model in terms of average precision (AP) in identifying and segmenting eosinophils, thereby enabling enhanced characterization of EoE. This automated approach holds promise for streamlining the assessment process and improving diagnostic accuracy in EoE analysis. The source code has been made publicly available at https://github.com/yilinliu610730/EoE.
</details>
<details>
<summary>摘要</summary>
恶性肠炎（EoE）是一种慢性和复发的疾病， caracterized by esophageal inflammation.  Its symptoms include difficulty swallowing, food impaction, and chest pain, which significantly impact the quality of life, resulting in nutritional impairments, social limitations, and psychological distress. The diagnosis of EoE is typically performed with a threshold (15 to 20) of eosinophils (Eos) per high-power field (HPF). Since the current counting process of Eos is a resource-intensive process for human pathologists, automatic methods are desired. Circle representation has been shown as a more precise, yet less complicated, representation for automatic instance cell segmentation such as CircleSnake approach. However, the CircleSnake was designed as a single-label model, which is not able to deal with multi-label scenarios. In this paper, we propose the multi-label CircleSnake model for instance segmentation on Eos. It extends the original CircleSnake model from a single-label design to a multi-label model, allowing segmentation of multiple object types. Experimental results illustrate the CircleSnake model's superiority over the traditional Mask R-CNN model and DeepSnake model in terms of average precision (AP) in identifying and segmenting eosinophils, thereby enabling enhanced characterization of EoE. This automated approach holds promise for streamlining the assessment process and improving diagnostic accuracy in EoE analysis. The source code has been made publicly available at https://github.com/yilinliu610730/EoE.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="An-inexact-proximal-majorization-minimization-Algorithm-for-remote-sensing-image-stripe-noise-removal"><a href="#An-inexact-proximal-majorization-minimization-Algorithm-for-remote-sensing-image-stripe-noise-removal" class="headerlink" title="An inexact proximal majorization-minimization Algorithm for remote sensing image stripe noise removal"></a>An inexact proximal majorization-minimization Algorithm for remote sensing image stripe noise removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08866">http://arxiv.org/abs/2308.08866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjing Wang, Xile Zhao, Qingsong Wang, Zepei Ma, Peipei Tang</li>
<li>for: 提高remote sensing图像的视觉质量和数据分析精度，适应现有的扫描图像中的条带噪音。</li>
<li>methods: 提出一种非凸模型，使用DC函数（即差分凸函数）结构来除掉条带噪音。解决这个模型的方法是利用DC结构和不准确的 proximal 大antero-multipliers 算法，并设计了可实现的停止 criterion。</li>
<li>results: 对于numerical experiments表明，提出的模型和算法具有超越现有模型和算法的优势。<details>
<summary>Abstract</summary>
The stripe noise existing in remote sensing images badly degrades the visual quality and restricts the precision of data analysis. Therefore, many destriping models have been proposed in recent years. In contrast to these existing models, in this paper, we propose a nonconvex model with a DC function (i.e., the difference of convex functions) structure to remove the strip noise. To solve this model, we make use of the DC structure and apply an inexact proximal majorization-minimization algorithm with each inner subproblem solved by the alternating direction method of multipliers. It deserves mentioning that we design an implementable stopping criterion for the inner subproblem, while the convergence can still be guaranteed. Numerical experiments demonstrate the superiority of the proposed model and algorithm.
</details>
<details>
<summary>摘要</summary>
Remote sensing 图像中的条纹噪音会严重损害视觉质量和数据分析精度。因此，过去几年内，许多推 striping 模型已经被提出。与现有模型不同，在这篇论文中，我们提出了一种非凸模型，使用差分 convex 函数（i.e., 条纹函数的差）结构来除掉条纹噪音。为解这个模型，我们利用 DC 结构，并采用不准确的 proximal 大anterograde 方法，每个内部问题都由 alternate 方向多重因素方法解决。值得一提的是，我们设计了可实现的停止条件，而且可以保证 convergence。数字实验表明，我们提出的模型和算法具有superiority。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution"><a href="#End-to-end-Alternating-Optimization-for-Real-World-Blind-Super-Resolution" class="headerlink" title="End-to-end Alternating Optimization for Real-World Blind Super Resolution"></a>End-to-end Alternating Optimization for Real-World Blind Super Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08816">http://arxiv.org/abs/2308.08816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/greatlog/realdan">https://github.com/greatlog/realdan</a></li>
<li>paper_authors: Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan</li>
<li>for: This paper proposes a new method for blind super-resolution (SR) of low-resolution (LR) images, which can estimate the degradation of the LR image and super-resolve it to its high-resolution (HR) counterpart in a single model.</li>
<li>methods: The proposed method uses an alternating optimization algorithm that consists of two convolutional neural modules: \textit{Restorer} and \textit{Estimator}. \textit{Restorer} restores the SR image based on the estimated degradation, while \textit{Estimator} estimates the degradation with the help of the restored SR image.</li>
<li>results: The proposed method outperforms state-of-the-art methods in terms of both objective metrics and visual quality, and produces more visually favorable results. The codes are available at \url{<a target="_blank" rel="noopener" href="https://github.com/greatlog/RealDAN.git%7D">https://github.com/greatlog/RealDAN.git}</a>.<details>
<summary>Abstract</summary>
Blind Super-Resolution (SR) usually involves two sub-problems: 1) estimating the degradation of the given low-resolution (LR) image; 2) super-resolving the LR image to its high-resolution (HR) counterpart. Both problems are ill-posed due to the information loss in the degrading process. Most previous methods try to solve the two problems independently, but often fall into a dilemma: a good super-resolved HR result requires an accurate degradation estimation, which however, is difficult to be obtained without the help of original HR information. To address this issue, instead of considering these two problems independently, we adopt an alternating optimization algorithm, which can estimate the degradation and restore the SR image in a single model. Specifically, we design two convolutional neural modules, namely \textit{Restorer} and \textit{Estimator}. \textit{Restorer} restores the SR image based on the estimated degradation, and \textit{Estimator} estimates the degradation with the help of the restored SR image. We alternate these two modules repeatedly and unfold this process to form an end-to-end trainable network. In this way, both \textit{Restorer} and \textit{Estimator} could get benefited from the intermediate results of each other, and make each sub-problem easier. Moreover, \textit{Restorer} and \textit{Estimator} are optimized in an end-to-end manner, thus they could get more tolerant of the estimation deviations of each other and cooperate better to achieve more robust and accurate final results. Extensive experiments on both synthetic datasets and real-world images show that the proposed method can largely outperform state-of-the-art methods and produce more visually favorable results. The codes are rleased at \url{https://github.com/greatlog/RealDAN.git}.
</details>
<details>
<summary>摘要</summary>
干Resolution（SR）问题通常包含两个互相关联的优化问题：1）估计LR图像的劣化程度；2）SR图像的恢复。两个问题都是不定的，因为升级过程中会产生信息损失。大多数之前的方法是独立地解决这两个问题，但往往陷入一个困境：一个好的SRHR图像需要一个准确的劣化估计，但是没有原始HR图像的帮助，劣化估计很难以取得。为了解决这个问题，我们不是独立地考虑这两个问题，而是采用一种alternating optimization算法，可以同时估计劣化和SR图像的恢复。我们设计了两个卷积神经网络模块，namely \textit{Restorer}和\textit{Estimator}。\textit{Restorer}使用估计的劣化来恢复SR图像，而\textit{Estimator}使用恢复的SR图像来估计劣化。我们在这两个模块之间重复交换，并将这个过程膨胀成一个可训练的端到端网络。这样，\textit{Restorer}和\textit{Estimator}都可以通过对方的中间结果得到帮助，使每个优化问题更加容易。此外，\textit{Restorer}和\textit{Estimator}在端到端训练中被优化，因此它们可以更快地适应对方的估计偏差，并更好地合作以实现更加稳定和准确的最终结果。我们在Synthetic datasets和实际图像上进行了广泛的实验，结果显示，我们的方法可以大幅超越当前状态的方法，并生成更加视觉吸引人的结果。代码可以在 \url{https://github.com/greatlog/RealDAN.git} 中下载。
</details></li>
</ul>
<hr>
<h2 id="Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images"><a href="#Recursive-Detection-and-Analysis-of-Nanoparticles-in-Scanning-Electron-Microscopy-Images" class="headerlink" title="Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images"></a>Recursive Detection and Analysis of Nanoparticles in Scanning Electron Microscopy Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08732">http://arxiv.org/abs/2308.08732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aidan S. Wright, Nathaniel P. Youmans, Enrique F. Valderrama Araya</li>
<li>for: 准确地检测和分析扫描电子显微镜（SEM）图像中的粒子。</li>
<li>methods: 利用Python图像处理库，如OpenCV、SciPy和Scikit-Image，实现图像处理和提升。</li>
<li>results: 在五个不同的测试图像中，准确地检测粒子，具有97%的准确率，并能够识别杂乱的粒子布局和较弱的粒子信号。<details>
<summary>Abstract</summary>
In this study, we present a computational framework tailored for the precise detection and comprehensive analysis of nanoparticles within scanning electron microscopy (SEM) images. The primary objective of this framework revolves around the accurate localization of nanoparticle coordinates, accompanied by secondary objectives encompassing the extraction of pertinent morphological attributes including area, orientation, brightness, and length.   Constructed leveraging the robust image processing capabilities of Python, particularly harnessing libraries such as OpenCV, SciPy, and Scikit-Image, the framework employs an amalgamation of techniques, including thresholding, dilating, and eroding, to enhance the fidelity of image processing outcomes.   The ensuing nanoparticle data is seamlessly integrated into the RStudio environment to facilitate meticulous post-processing analysis. This encompasses a comprehensive evaluation of model accuracy, discernment of feature distribution patterns, and the identification of intricate particle arrangements. The finalized framework exhibits high nanoparticle identification within the primary sample image and boasts 97\% accuracy in detecting particles across five distinct test images drawn from a SEM nanoparticle dataset. Furthermore, the framework demonstrates the capability to discern nanoparticles of faint intensity, eluding manual labeling within the control group.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了一种计算框架，用于精确检测和全面分析射电显微镜像中的粒子。主要目标是准确地确定粒子坐标，并且包括次要目标，如粒子形态特征的提取，包括面积、方向、亮度和长度。这个框架基于Python的强大图像处理能力，特别是利用OpenCV、SciPy和Scikit-Image库，使用了一系列技术，如阈值处理、扩大和腐蚀，以提高图像处理结果的准确性。得到的粒子数据可以轻松地在RStudio环境中进行仔细的后处理分析，包括精确评估模型准确性、分析特征分布征特点，以及描述复杂的粒子排列。最终的框架在五个不同的射电显微镜像数据集中的主要样本图像中具有高粒子标识能力，并且在五个测试图像中达到97%的粒子检测精度。此外，框架还能够检测具有某些较弱亮度的粒子，而这些粒子在控制组中未能手动标注。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression"><a href="#Dynamic-Kernel-Based-Adaptive-Spatial-Aggregation-for-Learned-Image-Compression" class="headerlink" title="Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression"></a>Dynamic Kernel-Based Adaptive Spatial Aggregation for Learned Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08723">http://arxiv.org/abs/2308.08723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Huairui/DKIC">https://github.com/Huairui/DKIC</a></li>
<li>paper_authors: Huairui Wang, Nianxiang Fu, Zhenzhong Chen, Shan Liu</li>
<li>for: 提高图像压缩率和细节准确性。</li>
<li>methods: 使用动态kernel基于转换编码、适应汇集和共享权重机制，以及基于Entropy模型的自适应 globale context生成器。</li>
<li>results: 在三个标准测试集上比州前方学习基于方法 achieve superior rate-distortion performance。<details>
<summary>Abstract</summary>
Learned image compression methods have shown superior rate-distortion performance and remarkable potential compared to traditional compression methods. Most existing learned approaches use stacked convolution or window-based self-attention for transform coding, which aggregate spatial information in a fixed range. In this paper, we focus on extending spatial aggregation capability and propose a dynamic kernel-based transform coding. The proposed adaptive aggregation generates kernel offsets to capture valid information in the content-conditioned range to help transform. With the adaptive aggregation strategy and the sharing weights mechanism, our method can achieve promising transform capability with acceptable model complexity. Besides, according to the recent progress of entropy model, we define a generalized coarse-to-fine entropy model, considering the coarse global context, the channel-wise, and the spatial context. Based on it, we introduce dynamic kernel in hyper-prior to generate more expressive global context. Furthermore, we propose an asymmetric spatial-channel entropy model according to the investigation of the spatial characteristics of the grouped latents. The asymmetric entropy model aims to reduce statistical redundancy while maintaining coding efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance on three benchmarks compared to the state-of-the-art learning-based methods.
</details>
<details>
<summary>摘要</summary>
现有学习图像压缩方法已经显示出了更高的比特率-损均值性和强大的潜在性，比较传统压缩方法更出色。大多数现有的学习方法使用堆叠 convolution或窗口基于自注意力进行变换编码，这些方法会聚合空间信息在固定范围内。在这篇论文中，我们关注扩展空间聚合能力，并提议一种动态核心基于变换编码。我们的提案的自适应聚合生成核心偏移来捕捉有效信息在内容受限范围内，以帮助变换。通过适应聚合策略和共享权重机制，我们的方法可以实现有优的变换能力，同时保持可接受的模型复杂度。此外，根据最近的Entropy模型进展，我们定义一种通用粗化-细化Entropy模型，考虑了粗化全局上下文、通道级别和空间上下文。基于它，我们引入动态核心在超乘预先中生成更表达力的全局上下文。另外，我们提出一种偏 asymmetric spatial-channel Entropy模型，根据图像拼接特征的调查，以减少统计冗余，保持编码效率。实验结果表明，我们的方法在三个标准测试集上实现了与当前学习基于方法相比更高的比特率-损均值性。
</details></li>
</ul>
<hr>
<h2 id="Deployment-and-Analysis-of-Instance-Segmentation-Algorithm-for-In-field-Grade-Estimation-of-Sweetpotatoes"><a href="#Deployment-and-Analysis-of-Instance-Segmentation-Algorithm-for-In-field-Grade-Estimation-of-Sweetpotatoes" class="headerlink" title="Deployment and Analysis of Instance Segmentation Algorithm for In-field Grade Estimation of Sweetpotatoes"></a>Deployment and Analysis of Instance Segmentation Algorithm for In-field Grade Estimation of Sweetpotatoes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08534">http://arxiv.org/abs/2308.08534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang M. Nguyen, Sydney Gyurek, Russell Mierop, Kenneth V. Pecota, Kylie LaGamba, Michael Boyette, G. Craig Yencho, Cranos M. Williams, Michael W. Kudenov</li>
<li>for: 这 paper 的目的是提出一种用于 directly 在田间进行 sweetpotato (SP) 存储根的检测和估算，以便更快速地获得 SP 的产量估算。</li>
<li>methods: 这 paper 使用的方法是使用 Detectron2 库中的深度学习对象检测算法来实现 Mask R-CNN 模型，以进行 SP 存储根的实例分割。</li>
<li>results: 研究结果表明，这个模型可以在不同的环境条件下（包括光照和土壤特性等）正确地检测 SP 存储根，并且与商业光学排分机相比，其误差值（RMSE）为0.66 cm、1.22 cm 和74.73 g，而Root 计数误差值（RMSE）为5.27根，与 r^2 为0.8。这种fenotyping 策略有望在没有高级和昂贵光学排分机的环境中实现快速的产量估算。<details>
<summary>Abstract</summary>
Shape estimation of sweetpotato (SP) storage roots is inherently challenging due to their varied size and shape characteristics. Even measuring "simple" metrics, such as length and width, requires significant time investments either directly in-field or afterward using automated graders. In this paper, we present the results of a model that can perform grading and provide yield estimates directly in the field quicker than manual measurements. Detectron2, a library consisting of deep-learning object detection algorithms, was used to implement Mask R-CNN, an instance segmentation model. This model was deployed for in-field grade estimation of SPs and evaluated against an optical sorter. Storage roots from various clones imaged with a cellphone during trials between 2019 and 2020, were used in the model's training and validation to fine-tune a model to detect SPs. Our results showed that the model could distinguish individual SPs in various environmental conditions including variations in lighting and soil characteristics. RMSE for length, width, and weight, from the model compared to a commercial optical sorter, were 0.66 cm, 1.22 cm, and 74.73 g, respectively, while the RMSE of root counts per plot was 5.27 roots, with r^2 = 0.8. This phenotyping strategy has the potential enable rapid yield estimates in the field without the need for sophisticated and costly optical sorters and may be more readily deployed in environments with limited access to these kinds of resources or facilities.
</details>
<details>
<summary>摘要</summary>
生长缘 estimation of sweetpotato (SP) storage roots 是一项自然而难的任务，主要因为它们的尺寸和形态特征具有很大的变化。甚至计算 "简单" 的指标，如长度和宽度，都需要投入很大的时间，可能是在场地上直接进行或使用自动化分级机器人。在这篇论文中，我们介绍了一种模型，可以在场地上进行排名和产量估算，比手动测量更快。使用 Detectron2 库中的深度学习对象检测算法，我们实现了面部分 Segmentation 模型。这个模型在场地上进行了 SP 的排名和产量估算，并与商业光学分级机器人进行比较。我们使用了不同的 CLONE 的存储根，在2019-2020 年的试验中拍摄了它们，并用于模型的训练和验证。我们的结果表明，模型可以在不同的环境条件下（包括光照和土壤特征）分辨准确的 SP。length、width 和 weight 的 RMSE 与商业光学分级机器人相比为 0.66 cm、1.22 cm 和 74.73 g，分类精度为 0.8。这种fenotyping策略有可能在不同的环境中快速地进行产量估算，不需要高昂的光学分级机器人，可能更容易在有限的资源和设施的环境中进行。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Distill-Global-Representation-for-Sparse-View-CT"><a href="#Learning-to-Distill-Global-Representation-for-Sparse-View-CT" class="headerlink" title="Learning to Distill Global Representation for Sparse-View CT"></a>Learning to Distill Global Representation for Sparse-View CT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08463">http://arxiv.org/abs/2308.08463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zilong Li, Chenglong Ma, Jie Chen, Junping Zhang, Hongming Shan<br>for:* 这篇论文的目的是为了提出一个新的实验方法，以减少X射影像资料的辐射剂量和资料收集时间，并提高影像资料的质量。methods:* 这篇论文使用了一种名为“GloRe”的全球表现框架，它是一种基于傅立叶数据的学习方法，可以将影像资料转换为更加简洁的表现，以减少影像资料的质量损失。results:* 实验结果显示，GloReDi方法比以往的方法更好地实现了实验中的目的，包括减少辐射剂量和资料收集时间，并提高影像资料的质量。此外，GloReDi方法还可以实现现场的实验操作和资料分析，实现了实时的影像资料处理和分析。<details>
<summary>Abstract</summary>
Sparse-view computed tomography (CT) -- using a small number of projections for tomographic reconstruction -- enables much lower radiation dose to patients and accelerated data acquisition. The reconstructed images, however, suffer from strong artifacts, greatly limiting their diagnostic value. Current trends for sparse-view CT turn to the raw data for better information recovery. The resultant dual-domain methods, nonetheless, suffer from secondary artifacts, especially in ultra-sparse view scenarios, and their generalization to other scanners/protocols is greatly limited. A crucial question arises: have the image post-processing methods reached the limit? Our answer is not yet. In this paper, we stick to image post-processing methods due to great flexibility and propose global representation (GloRe) distillation framework for sparse-view CT, termed GloReDi. First, we propose to learn GloRe with Fourier convolution, so each element in GloRe has an image-wide receptive field. Second, unlike methods that only use the full-view images for supervision, we propose to distill GloRe from intermediate-view reconstructed images that are readily available but not explored in previous literature. The success of GloRe distillation is attributed to two key components: representation directional distillation to align the GloRe directions, and band-pass-specific contrastive distillation to gain clinically important details. Extensive experiments demonstrate the superiority of the proposed GloReDi over the state-of-the-art methods, including dual-domain ones. The source code is available at https://github.com/longzilicart/GloReDi.
</details>
<details>
<summary>摘要</summary>
通用简化的 computed tomography (CT) -- 使用少量投影进行 Tomographic 重建 -- 可以减少病人的辐射剂量和数据收集的时间。然而，重建的图像却受到强烈的artifacts的限制，从而很大程度地降低了其诊断价值。现有的趋势是将着眼于原始数据，以便更好地回收信息。但是，结果的二元领域方法受到紧张视角场景中的次要artifacts的限制，并且其在其他扫描仪/协议上的普适性受到了严重的限制。问题是：图像后处理方法是否已经达到了限制？我们的答案是不是。在这篇论文中，我们坚持使用图像后处理方法，因为它具有很大的灵活性。我们提出了一种全局表示（GloRe）润色框架，称之为GloReDi。首先，我们提出了学习 GloRe 使用傅ри捷 convolution，使每个 GloRe 元素具有图像全面的感受野。其次，不同于以充满视图图像为监督的方法，我们提议使用中间视图重建图像，这些图像Ready availability，但在过去的文献中未经探讨。GloRe 润色的成功归功于两个关键组成部分：方向性润色 distillation 以确定 GloRe 方向，以及带通道特异的对比润色 distillation 以获取临床重要的细节。广泛的实验表明，提议的 GloReDi 超过了当前状态的方法，包括双Domain方法。源代码可以在 GitHub 上获取：https://github.com/longzilicart/GloReDi。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/17/eess.IV_2023_08_17/" data-id="clorjzlfq015qf188fq2e5iol" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/cs.SD_2023_08_16/" class="article-date">
  <time datetime="2023-08-16T15:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/cs.SD_2023_08_16/">cs.SD - 2023-08-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mitigating-the-Exposure-Bias-in-Sentence-Level-Grapheme-to-Phoneme-G2P-Transduction"><a href="#Mitigating-the-Exposure-Bias-in-Sentence-Level-Grapheme-to-Phoneme-G2P-Transduction" class="headerlink" title="Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction"></a>Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08442">http://arxiv.org/abs/2308.08442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eunseop Yoon, Hee Suk Yoon, Dhananjaya Gowda, SooHwan Eom, Daehyeok Kim, John Harvill, Heting Gao, Mark Hasegawa-Johnson, Chanwoo Kim, Chang D. Yoo</li>
<li>for: 本研究旨在改进 sentence-level 和 paragraph-level G2P 的性能。</li>
<li>methods: 本研究使用了一种基于 T5 的 tokenizer-free byte-level 模型，并提出了一种损失函数 sampling 方法来 Mitigate 批处理 bias。</li>
<li>results: 实验结果表明，使用 proposed 的损失函数 sampling 方法可以改善 sentence-level 和 paragraph-level G2P 的性能。<details>
<summary>Abstract</summary>
Text-to-Text Transfer Transformer (T5) has recently been considered for the Grapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free byte-level model based on T5 referred to as ByT5, recently gave promising results on word-level G2P conversion by representing each input character with its corresponding UTF-8 encoding. Although it is generally understood that sentence-level or paragraph-level G2P can improve usability in real-world applications as it is better suited to perform on heteronyms and linking sounds between words, we find that using ByT5 for these scenarios is nontrivial. Since ByT5 operates on the character level, it requires longer decoding steps, which deteriorates the performance due to the exposure bias commonly observed in auto-regressive generation models. This paper shows that the performance of sentence-level and paragraph-level G2P can be improved by mitigating such exposure bias using our proposed loss-based sampling method.
</details>
<details>
<summary>摘要</summary>
文本转换变换器（T5）最近被考虑用于字母到phoneme（G2P）转推。作为续作，一种不使用tokenizer的字节级模型基于T5，称为ByT5，最近在单词级G2P转换中表现出了有前途的结果，通过每个输入字符与其唯一的UTF-8编码相对应。虽然通常认为 sentence-level或paragraph-level G2P可以提高实际应用中的可用性，因为更适合处理同义词和 слова间的声音连接，但使用ByT5进行这些场景是不rivial的。因为ByT5运行在字符级别，它需要更长的解码步骤，这会降低性能，因为普遍存在在自动生成模型中的曝光偏见。这篇论文显示，使用我们提议的损失样本方法可以改善 sentence-level和paragraph-level G2P的性能。
</details></li>
</ul>
<hr>
<h2 id="Classifying-Dementia-in-the-Presence-of-Depression-A-Cross-Corpus-Study"><a href="#Classifying-Dementia-in-the-Presence-of-Depression-A-Cross-Corpus-Study" class="headerlink" title="Classifying Dementia in the Presence of Depression: A Cross-Corpus Study"></a>Classifying Dementia in the Presence of Depression: A Cross-Corpus Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08306">http://arxiv.org/abs/2308.08306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Franziska Braun, Sebastian P. Bayerl, Paula A. Pérez-Toro, Florian Hönig, Hartmut Lehfeld, Thomas Hillemacher, Elmar Nöth, Tobias Bocklet, Korbinian Riedhammer</li>
<li>for: 这个研究旨在检测和诊断诸如 деменция 和中风症等认知障碍，以提高医疗系统的效率和患者的生活质量。</li>
<li>methods: 这篇论文使用了已知的基eline系统，将语音、文本和情感嵌入应用于三类分类问题（健康Control vs. 中风症 vs.  деменcia），使用 semantic Verbal Fluency Test 和 Boston Naming Test 的语音和文本数据。</li>
<li>results: 研究人员通过在两个独立录制的德国数据集上进行交叉 корpus 和混合 корpus 实验，发现了更好的一致性和可重复性，并进行了详细的错误分析，以了解类ifiers 是如何学习的。<details>
<summary>Abstract</summary>
Automated dementia screening enables early detection and intervention, reducing costs to healthcare systems and increasing quality of life for those affected. Depression has shared symptoms with dementia, adding complexity to diagnoses. The research focus so far has been on binary classification of dementia (DEM) and healthy controls (HC) using speech from picture description tests from a single dataset. In this work, we apply established baseline systems to discriminate cognitive impairment in speech from the semantic Verbal Fluency Test and the Boston Naming Test using text, audio and emotion embeddings in a 3-class classification problem (HC vs. MCI vs. DEM). We perform cross-corpus and mixed-corpus experiments on two independently recorded German datasets to investigate generalization to larger populations and different recording conditions. In a detailed error analysis, we look at depression as a secondary diagnosis to understand what our classifiers actually learn.
</details>
<details>
<summary>摘要</summary>
自动化老年痴味检测可以提前发现和 intervene，从而减少医疗系统的成本和提高受影响人的生活质量。抑郁和痴味具有共同的症状，使诊断变得更加复杂。现有研究主要集中在使用图片描述测试来进行二分类诊断（DEM vs. HC）。在这项工作中，我们使用已有的基线系统来分类语音中的认知障碍，使用语音、文本和情感嵌入在3类分类问题中（HC vs. MCI vs. DEM）。我们进行了跨 korpus 和混合 korpus 实验，以 investigate 大量人口和不同的录音条件下的泛化性。在详细的错误分析中，我们查看了抑郁是作为次要诊断的影响。
</details></li>
</ul>
<hr>
<h2 id="ChinaTelecom-System-Description-to-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#ChinaTelecom-System-Description-to-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="ChinaTelecom System Description to VoxCeleb Speaker Recognition Challenge 2023"></a>ChinaTelecom System Description to VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08181">http://arxiv.org/abs/2308.08181</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengjie Du, Xiang Fang, Jie Li</li>
<li>for: 这份技术报告是关于2023年VOXCELEB SpeakerRecognition Challenge（VoxSRC 2023）的中国电信系统 Track 1（关闭）的描述。</li>
<li>methods: 该系统包括了多种ResNet变体，只有在VoxCeleb2上进行训练。这些变体后来被融合以提高性能。还应用了每个变体和融合系统的分数抖合。</li>
<li>results: 最终提交得分为0.1066和EER为1.980%。<details>
<summary>Abstract</summary>
This technical report describes ChinaTelecom system for Track 1 (closed) of the VoxCeleb2023 Speaker Recognition Challenge (VoxSRC 2023). Our system consists of several ResNet variants trained only on VoxCeleb2, which were fused for better performance later. Score calibration was also applied for each variant and the fused system. The final submission achieved minDCF of 0.1066 and EER of 1.980%.
</details>
<details>
<summary>摘要</summary>
这份技术报告描述了我们在VoxCeleb2023 Speaker Recognition Challenge（VoxSRC 2023）的 Track 1（关闭）系统。我们的系统包括了多种ResNet变体，只在VoxCeleb2上进行训练，并将其进行了更好的性能的融合。在每个变体和融合系统上都进行了分数调整。最终提交的结果为minDCF为0.1066和EER为1.980%。
</details></li>
</ul>
<hr>
<h2 id="AffectEcho-Speaker-Independent-and-Language-Agnostic-Emotion-and-Affect-Transfer-for-Speech-Synthesis"><a href="#AffectEcho-Speaker-Independent-and-Language-Agnostic-Emotion-and-Affect-Transfer-for-Speech-Synthesis" class="headerlink" title="AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis"></a>AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect Transfer for Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08577">http://arxiv.org/abs/2308.08577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hrishikesh Viswanath, Aneesh Bhattacharya, Pascal Jutras-Dubé, Prerit Gupta, Mridu Prashanth, Yashvardhan Khaitan, Aniket Bera</li>
<li>for: 本研究旨在开发一种语言独立的情感翻译模型，以控制生成的语音中的情感表达，保持每个说话者的个性风格和情感气质。</li>
<li>methods: 该模型使用Vector Quantized codebook来模型情感在量化空间中，其中包含五级情感强度，以捕捉复杂的情感表达和细腻的差异。该模型不需要一个一维或显式强度 embedding，从而消除了模型的训练偏好。</li>
<li>results: 实验结果表明，该模型可以控制生成的语音中的情感表达，同时保持每个说话者的个性风格和情感气质。该模型还实现了语言独立的情感模型化能力，通过在英语和中文之间进行情感传递任务来证明。 Qualitative和量化 metric 上都达到了领先的result。<details>
<summary>Abstract</summary>
Affect is an emotional characteristic encompassing valence, arousal, and intensity, and is a crucial attribute for enabling authentic conversations. While existing text-to-speech (TTS) and speech-to-speech systems rely on strength embedding vectors and global style tokens to capture emotions, these models represent emotions as a component of style or represent them in discrete categories. We propose AffectEcho, an emotion translation model, that uses a Vector Quantized codebook to model emotions within a quantized space featuring five levels of affect intensity to capture complex nuances and subtle differences in the same emotion. The quantized emotional embeddings are implicitly derived from spoken speech samples, eliminating the need for one-hot vectors or explicit strength embeddings. Experimental results demonstrate the effectiveness of our approach in controlling the emotions of generated speech while preserving identity, style, and emotional cadence unique to each speaker. We showcase the language-independent emotion modeling capability of the quantized emotional embeddings learned from a bilingual (English and Chinese) speech corpus with an emotion transfer task from a reference speech to a target speech. We achieve state-of-art results on both qualitative and quantitative metrics.
</details>
<details>
<summary>摘要</summary>
“情感”是一种情感特征，包括浓淡、高潮和强度，它是促进真实对话的重要属性。现有的文本到语音（TTS）和语音到语音系统通常使用强制编码器和全局风格Token来捕捉情感，但这些模型表示情感为风格的一部分或者分类化表示。我们提出了“情感频谱”（AffectEcho），一种情感翻译模型，它使用量化频谱来模型情感在量化空间中的五级浓淡强度，以捕捉复杂的感受和微妙的差异。这些量化情感嵌入是从语音样本中提取的，不需要一个一个的强制编码器或者显式强制编码器。实验结果表明我们的方法可以控制生成的语音中的情感，保留每个说话者的个性、风格和情感 cadence。我们还展示了基于英语和中文双语语音资料的语言独立情感模型的能力，通过将参考语音中的情感传递到目标语音中。我们在质量和质量指标上达到了当前最佳结果。
</details></li>
</ul>
<hr>
<h2 id="SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation"><a href="#SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation" class="headerlink" title="SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation"></a>SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08143">http://arxiv.org/abs/2308.08143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Li, Runxuan Yang, Xiaolin Hu</li>
<li>for: 本文主要研究 audio-visual 语音分离问题，提出一种基于注意机制的 Audio-Visual 特征融合模型（SCANet），以提高 audio-visual 特征融合效果。</li>
<li>methods: SCANet 模型包括两种注意块：自注意（SA）和跨注意（CA）块，其中 CA 块分布在网络的顶部（TCA）、中部（MCA）和底部（BCA）。这些块可以学习不同modalities的特征，并提取 audio-visual 特征中的不同semantics。</li>
<li>results: 对三个标准的 audio-visual 分离benchmark（LRS2、LRS3和VoxCeleb2）进行了广泛的实验，结果表明 SCANet 模型比现有的状态对(SOTA)方法高效，同时保持了相对的执行时间。<details>
<summary>Abstract</summary>
The integration of different modalities, such as audio and visual information, plays a crucial role in human perception of the surrounding environment. Recent research has made significant progress in designing fusion modules for audio-visual speech separation. However, they predominantly focus on multi-modal fusion architectures situated either at the top or bottom positions, rather than comprehensively considering multi-modal fusion at various hierarchical positions within the network. In this paper, we propose a novel model called self- and cross-attention network (SCANet), which leverages the attention mechanism for efficient audio-visual feature fusion. SCANet consists of two types of attention blocks: self-attention (SA) and cross-attention (CA) blocks, where the CA blocks are distributed at the top (TCA), middle (MCA) and bottom (BCA) of SCANet. These blocks maintain the ability to learn modality-specific features and enable the extraction of different semantics from audio-visual features. Comprehensive experiments on three standard audio-visual separation benchmarks (LRS2, LRS3, and VoxCeleb2) demonstrate the effectiveness of SCANet, outperforming existing state-of-the-art (SOTA) methods while maintaining comparable inference time.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a novel model called the self- and cross-attention network (SCANet), which leverages the attention mechanism for efficient audio-visual feature fusion. SCANet consists of two types of attention blocks: self-attention (SA) and cross-attention (CA) blocks. The CA blocks are distributed at the top (TCA), middle (MCA), and bottom (BCA) of SCANet, allowing the network to learn modality-specific features and extract different semantics from audio-visual features.Experiments on three standard audio-visual separation benchmarks (LRS2, LRS3, and VoxCeleb2) demonstrate the effectiveness of SCANet, outperforming existing state-of-the-art (SOTA) methods while maintaining comparable inference time.
</details></li>
</ul>
<hr>
<h2 id="Radio2Text-Streaming-Speech-Recognition-Using-mmWave-Radio-Signals"><a href="#Radio2Text-Streaming-Speech-Recognition-Using-mmWave-Radio-Signals" class="headerlink" title="Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals"></a>Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08125">http://arxiv.org/abs/2308.08125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Running Zhao, Jiangtao Yu, Hang Zhao, Edith C. H. Ngai</li>
<li>for: This paper proposes a mmWave-based system for streaming automatic speech recognition (ASR) with a large vocabulary size.</li>
<li>methods: The proposed system, called Radio2Text, uses a tailored streaming Transformer that learns speech-related features effectively, and a cross-modal structure based on knowledge distillation to mitigate the negative effect of low quality mmWave signals.</li>
<li>results: The experimental results show that Radio2Text can achieve a character error rate of 5.7% and a word error rate of 9.4% for the recognition of a vocabulary consisting of over 13,000 words.<details>
<summary>Abstract</summary>
Millimeter wave (mmWave) based speech recognition provides more possibility for audio-related applications, such as conference speech transcription and eavesdropping. However, considering the practicality in real scenarios, latency and recognizable vocabulary size are two critical factors that cannot be overlooked. In this paper, we propose Radio2Text, the first mmWave-based system for streaming automatic speech recognition (ASR) with a vocabulary size exceeding 13,000 words. Radio2Text is based on a tailored streaming Transformer that is capable of effectively learning representations of speech-related features, paving the way for streaming ASR with a large vocabulary. To alleviate the deficiency of streaming networks unable to access entire future inputs, we propose the Guidance Initialization that facilitates the transfer of feature knowledge related to the global context from the non-streaming Transformer to the tailored streaming Transformer through weight inheritance. Further, we propose a cross-modal structure based on knowledge distillation (KD), named cross-modal KD, to mitigate the negative effect of low quality mmWave signals on recognition performance. In the cross-modal KD, the audio streaming Transformer provides feature and response guidance that inherit fruitful and accurate speech information to supervise the training of the tailored radio streaming Transformer. The experimental results show that our Radio2Text can achieve a character error rate of 5.7% and a word error rate of 9.4% for the recognition of a vocabulary consisting of over 13,000 words.
</details>
<details>
<summary>摘要</summary>
《 millimeter wave (mmWave) 基于语音识别提供更多的音频相关应用程序，如会议语音转文本和窃听。然而，在实际场景中，延迟和可识别词汇数量是两个不可或缺的因素。在本文中，我们提出 Radio2Text，第一个 mmWave 基于的流动自动语音识别（ASR）系统，可以识别 более чем 13,000 个词汇。Radio2Text 基于一种适应流动 Transformer，可以有效地学习语音相关特征的表示，为流动 ASR 开辟了新的可能性。为了解决流动网络无法访问整个未来输入的问题，我们提出了指导初始化，通过权重继承来传递非流动 Transformer 中关于全局上下文的特征知识到适应流动 Transformer。此外，我们提出了基于知识储存（KD）的 Cross-modal 结构，named cross-modal KD，以mitigate the negative effect of low quality mmWave signals on recognition performance。在 Cross-modal KD 中，音频流动 Transformer 提供了特征和回应指导，通过继承精准和有用的语音信息来监督适应流动 Transformer 的训练。实验结果表明，我们的 Radio2Text 可以在识别 More than 13,000 个词汇时 achieving a character error rate of 5.7% and a word error rate of 9.4%.
</details></li>
</ul>
<hr>
<h2 id="End-to-End-Open-Vocabulary-Keyword-Search-With-Multilingual-Neural-Representations"><a href="#End-to-End-Open-Vocabulary-Keyword-Search-With-Multilingual-Neural-Representations" class="headerlink" title="End-to-End Open Vocabulary Keyword Search With Multilingual Neural Representations"></a>End-to-End Open Vocabulary Keyword Search With Multilingual Neural Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08027">http://arxiv.org/abs/2308.08027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bolaji Yusuf, Jan Cernocky, Murat Saraclar</li>
<li>for: 提高 keyword search 系统的效率和简化搜索管道，不需要自动语音识别（ASR）。</li>
<li>methods: 使用 neural network 编码器对查询和文档进行编码，并将编码器的输出进行点积 multiplication 进行搜索。</li>
<li>results: 对长查询和不在训练数据中出现的查询，提出了比 ASR-based 系统更高的性能。<details>
<summary>Abstract</summary>
Conventional keyword search systems operate on automatic speech recognition (ASR) outputs, which causes them to have a complex indexing and search pipeline. This has led to interest in ASR-free approaches to simplify the search procedure. We recently proposed a neural ASR-free keyword search model which achieves competitive performance while maintaining an efficient and simplified pipeline, where queries and documents are encoded with a pair of recurrent neural network encoders and the encodings are combined with a dot-product. In this article, we extend this work with multilingual pretraining and detailed analysis of the model. Our experiments show that the proposed multilingual training significantly improves the model performance and that despite not matching a strong ASR-based conventional keyword search system for short queries and queries comprising in-vocabulary words, the proposed model outperforms the ASR-based system for long queries and queries that do not appear in the training data.
</details>
<details>
<summary>摘要</summary>
传统的关键词搜索系统通常基于自动语音识别（ASR）输出，这会导致它们具有复杂的索引和搜索管道。这已经引起了寻求ASR-free方法的兴趣，以简化搜索过程。我们最近提出了一种基于神经网络的ASR-free关键词搜索模型，该模型在竞争性和效率方面具有优异表现，并且保持了简单的搜索管道。在这篇文章中，我们将对该模型进行多语言预训练和详细分析。我们的实验结果表明，训练多语言后的模型性能有显著提升，并且虽然不能与强大的ASR-based传统关键词搜索系统相比，但该模型对长 queries和不在训练数据中的 queries 表现出色。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/cs.SD_2023_08_16/" data-id="clorjzlb500v8f1880u335ihc" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/eess.AS_2023_08_16/" class="article-date">
  <time datetime="2023-08-16T14:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/eess.AS_2023_08_16/">eess.AS - 2023-08-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-ID-R-D-VoxCeleb-Speaker-Recognition-Challenge-2023-System-Description"><a href="#The-ID-R-D-VoxCeleb-Speaker-Recognition-Challenge-2023-System-Description" class="headerlink" title="The ID R&amp;D VoxCeleb Speaker Recognition Challenge 2023 System Description"></a>The ID R&amp;D VoxCeleb Speaker Recognition Challenge 2023 System Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08294">http://arxiv.org/abs/2308.08294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Torgashov, Rostislav Makarov, Ivan Yakovlev, Pavel Malov, Andrei Balykin, Anton Okhotnikov</li>
<li>for: 这篇论文是为了参加VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的Track 2（开放）阶段提交的。</li>
<li>methods: 这个解决方案基于深度ResNet和自动编写学习（SSL）基于模型，使用VoxCeleb2数据集和大量VoxTube数据集进行混合训练。</li>
<li>results: 最终提交在VoxSRC-23公共排名板上获得第一名，minDCF(0.05)为0.0762，EER为1.30%。<details>
<summary>Abstract</summary>
This report describes ID R&D team submissions for Track 2 (open) to the VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC-23). Our solution is based on the fusion of deep ResNets and self-supervised learning (SSL) based models trained on a mixture of a VoxCeleb2 dataset and a large version of a VoxTube dataset. The final submission to the Track 2 achieved the first place on the VoxSRC-23 public leaderboard with a minDCF(0.05) of 0.0762 and EER of 1.30%.
</details>
<details>
<summary>摘要</summary>
translate to Simplified Chinese:这份报告描述ID R&D团队在VoxCeleb Speaker Recognition Challenge 2023（VoxSRC-23）的跑道2（开放）中的提交。我们的解决方案基于深度ResNet和自动教育学（SSL）基于模型，在VoxCeleb2数据集和大量的VoxTube数据集的混合上进行训练。最终的提交在VoxSRC-23公共排名板上获得第一名，minDCF(0.05)为0.0762，EER为1.30%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/eess.AS_2023_08_16/" data-id="clorjzldt0113f188bxbib44p" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/cs.CV_2023_08_16/" class="article-date">
  <time datetime="2023-08-16T13:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/cs.CV_2023_08_16/">cs.CV - 2023-08-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="High-Fidelity-Lake-Extraction-via-Two-Stage-Prompt-Enhancement-Establishing-a-Novel-Baseline-and-Benchmark"><a href="#High-Fidelity-Lake-Extraction-via-Two-Stage-Prompt-Enhancement-Establishing-a-Novel-Baseline-and-Benchmark" class="headerlink" title="High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark"></a>High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08443">http://arxiv.org/abs/2308.08443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Chen, Xuechao Zou, Kai Li, Yu Zhang, Junliang Xing, Pin Tao</li>
<li>for: 本文提出了一种基于提示的 dataset 构建方法，用于自动从遥感图像中提取湖泊信息。</li>
<li>methods: 该方法使用了一种两Stage提示增强框架，包括提示基 stage 和提示自由 stage。在提示基 stage 中，使用提示编码器提取先前信息，并通过自身和交叉注意力将提示符和图像嵌入综合。在提示自由 stage 中，提示被禁用，以确保模型在推断时独立。</li>
<li>results: 对于 Surface Water 和 Qinghai-Tibet Plateau Lake 数据集，LEPrompter 可以在不添加额外参数或 GFLOPs 的情况下实现了前一个状态方法的性能改进。LEPrompter 在两个数据集上的 mIoU 分数分别为 91.48% 和 97.43%。<details>
<summary>Abstract</summary>
The extraction of lakes from remote sensing images is a complex challenge due to the varied lake shapes and data noise. Current methods rely on multispectral image datasets, making it challenging to learn lake features accurately from pixel arrangements. This, in turn, affects model learning and the creation of accurate segmentation masks. This paper introduces a unified prompt-based dataset construction approach that provides approximate lake locations using point, box, and mask prompts. We also propose a two-stage prompt enhancement framework, LEPrompter, which involves prompt-based and prompt-free stages during training. The prompt-based stage employs a prompt encoder to extract prior information, integrating prompt tokens and image embeddings through self- and cross-attention in the prompt decoder. Prompts are deactivated once the model is trained to ensure independence during inference, enabling automated lake extraction. Evaluations on Surface Water and Qinghai-Tibet Plateau Lake datasets show consistent performance improvements compared to the previous state-of-the-art method. LEPrompter achieves mIoU scores of 91.48% and 97.43% on the respective datasets without introducing additional parameters or GFLOPs. Supplementary materials provide the source code, pre-trained models, and detailed user studies.
</details>
<details>
<summary>摘要</summary>
几乎所有的探测湖泊从遥感图像中提取湖泊的过程都是一个复杂的挑战，主要是因为湖泊的形状和数据噪声的变化。现有的方法都是基于多spectral图像集，这使得学习湖泊特征准确从像素的排序中困难。这种情况导致模型学习和生成准确的分割面板困难。本文提出了一种简单的提示基本构建方法，可以提供湖泊的大致位置使用点、盒子和面影��提示。我们还提出了一种两阶段提高框架，即 LEPrompter，该框架在训练阶段包括基于提示和无提示两个阶段。提示阶段使用提示编码器提取先前信息，将提示token和图像嵌入通过自身和跨attend在提示解码器中进行自我和跨attend。提示被禁用一旦模型训练完成，以确保探测过程中的独立性。评估表面水和青海 Tibet 高原湖 datasets 表明，相比之前的状态艺术方法，LEPrompter 在不添加额外参数或 GFLOPs 的情况下实现了稳定的性能提升。详细的材料和附加的详细用户研究可以在补充材料中找到。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Visual-and-Semantic-Similarity-Using-Hierarchies-for-Image-Retrieval"><a href="#Integrating-Visual-and-Semantic-Similarity-Using-Hierarchies-for-Image-Retrieval" class="headerlink" title="Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval"></a>Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08431">http://arxiv.org/abs/2308.08431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vaishwarya96/hierarchy-image-retrieval">https://github.com/vaishwarya96/hierarchy-image-retrieval</a></li>
<li>paper_authors: Aishwarya Venkataramanan, Martin Laviale, Cédric Pradalier<br>for: 这个论文的目的是提高内容基于图像检索（CBIR）中的结果准确性，使得检索结果更加准确地反映用户的查询需求。methods: 该方法使用了深度神经网络进行分类训练，并将相似的类划合并为一个视觉层次结构。这个视觉层次结构被用于计算图像之间的距离，以确定最相似的图像。results: 实验结果表明，该方法在标准数据集CUB-200-2011和CIFAR100上达到了比较好的性能，并且在实际应用中使用的 диато镜像检索 task 上也表现出色。<details>
<summary>Abstract</summary>
Most of the research in content-based image retrieval (CBIR) focus on developing robust feature representations that can effectively retrieve instances from a database of images that are visually similar to a query. However, the retrieved images sometimes contain results that are not semantically related to the query. To address this, we propose a method for CBIR that captures both visual and semantic similarity using a visual hierarchy. The hierarchy is constructed by merging classes with overlapping features in the latent space of a deep neural network trained for classification, assuming that overlapping classes share high visual and semantic similarities. Finally, the constructed hierarchy is integrated into the distance calculation metric for similarity search. Experiments on standard datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom microscopy images show that our method achieves superior performance compared to the existing methods on image retrieval.
</details>
<details>
<summary>摘要</summary>
大多数研究在内容基于图像检索（CBIR）都是关注开发robust的特征表示，以便从图像库中检索与查询图像视觉相似的图像。然而，检索到的图像有时会包含不相关的内容。为解决这个问题，我们提议一种基于视觉层次结构的CBIR方法，该方法可以捕捉视觉和 semantic相似性。我们使用一个深度神经网络进行分类训练，并假设过lapping类在特征空间中共享高度的视觉和semantic相似性。最后，我们将构造的层次结构纳入检索距离计算度量中，以进一步提高图像检索的性能。我们在标准数据集CUB-200-2011和CIFAR100上进行了实验，以及使用激光微scopy图像进行了实际应用，结果显示我们的方法在图像检索中具有较高的性能。
</details></li>
</ul>
<hr>
<h2 id="ALIP-Adaptive-Language-Image-Pre-training-with-Synthetic-Caption"><a href="#ALIP-Adaptive-Language-Image-Pre-training-with-Synthetic-Caption" class="headerlink" title="ALIP: Adaptive Language-Image Pre-training with Synthetic Caption"></a>ALIP: Adaptive Language-Image Pre-training with Synthetic Caption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08428">http://arxiv.org/abs/2308.08428</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deepglint/alip">https://github.com/deepglint/alip</a></li>
<li>paper_authors: Kaicheng Yang, Jiankang Deng, Xiang An, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu</li>
<li>For: The paper aims to improve the performance of vision-language tasks by addressing the issue of intrinsic noise and unmatched image-text pairs in web data through a novel pre-training method called Adaptive Language-Image Pre-training (ALIP).* Methods: The paper proposes an ALIP model that integrates supervision from both raw text and synthetic captions, with core components such as the Language Consistency Gate (LCG) and Description Consistency Gate (DCG) that dynamically adjust the weights of samples and image-text&#x2F;caption pairs during training. The adaptive contrastive loss is also used to reduce the impact of noise data and enhance the efficiency of pre-training.* Results: The paper achieves state-of-the-art performance on multiple downstream tasks including zero-shot image-text retrieval and linear probe, and the code and pre-trained models are released for future research at <a target="_blank" rel="noopener" href="https://github.com/deepglint/ALIP">https://github.com/deepglint/ALIP</a>.<details>
<summary>Abstract</summary>
Contrastive Language-Image Pre-training (CLIP) has significantly boosted the performance of various vision-language tasks by scaling up the dataset with image-text pairs collected from the web. However, the presence of intrinsic noise and unmatched image-text pairs in web data can potentially affect the performance of representation learning. To address this issue, we first utilize the OFA model to generate synthetic captions that focus on the image content. The generated captions contain complementary information that is beneficial for pre-training. Then, we propose an Adaptive Language-Image Pre-training (ALIP), a bi-path model that integrates supervision from both raw text and synthetic caption. As the core components of ALIP, the Language Consistency Gate (LCG) and Description Consistency Gate (DCG) dynamically adjust the weights of samples and image-text/caption pairs during the training process. Meanwhile, the adaptive contrastive loss can effectively reduce the impact of noise data and enhances the efficiency of pre-training data. We validate ALIP with experiments on different scales of models and pre-training datasets. Experiments results show that ALIP achieves state-of-the-art performance on multiple downstream tasks including zero-shot image-text retrieval and linear probe. To facilitate future research, the code and pre-trained models are released at https://github.com/deepglint/ALIP.
</details>
<details>
<summary>摘要</summary>
<SYS>CLIP（对比语言图像预训练）已经显著提高了多种视觉语言任务的性能，通过扩大数据集，收集自网络上的图像文本对。然而，网络数据中的内生噪音和不匹配的图像文本对可能会影响表征学习的性能。为解决这个问题，我们首先使用OFA模型生成各种关注图像内容的自然语言描述。生成的描述包含有利于预训练的补充信息。然后，我们提出了自适应语言图像预训练（ALIP），一种bidirectional模型，它将raw文本和生成的描述作为双价值监督。ALIP的核心组件是语言一致门（LCG）和描述一致门（DCG），它们在训练过程中动态调整样本和图像文本/描述对的权重。同时，适应对比损失可以有效降低噪音数据的影响，提高预训练数据的效率。我们通过不同规模的模型和预训练集进行实验，并证明ALIP在多个下游任务中达到了状态之作。为便于未来的研究，我们在https://github.com/deepglint/ALIP上发布了代码和预训练模型。</SYS>Here's the translation in Traditional Chinese:<SYS>CLIP（对比语言图像预训练）已经显著提高了多种视觉语言任务的性能，通过扩大数据集，收集自网络上的图像文本对。然而，网络数据中的内生噪音和不匹配的图像文本对可能会影响表征学习的性能。为解决这个问题，我们首先使用OFA模型生成各种关注图像内容的自然语言描述。生成的描述包含有利于预训练的补充信息。然后，我们提出了自适应语言图像预训练（ALIP），一种bidirectional模型，它将raw文本和生成的描述作为双价值监督。ALIP的核心组件是语言一致门（LCG）和描述一致门（DCG），它们在训练过程中动态调整样本和图像文本/描述对的权重。同时，适应对比损失可以有效降低噪音数据的影响，提高预训练数据的效率。我们通过不同规模的模型和预训练集进行实验，并证明ALIP在多个下游任务中达到了状态之作。为便于未来的研究，我们在https://github.com/deepglint/ALIP上发布了代码和预训练模型。</SYS>
</details></li>
</ul>
<hr>
<h2 id="Tem-adapter-Adapting-Image-Text-Pretraining-for-Video-Question-Answer"><a href="#Tem-adapter-Adapting-Image-Text-Pretraining-for-Video-Question-Answer" class="headerlink" title="Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer"></a>Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08414">http://arxiv.org/abs/2308.08414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyi Chen, Xiao Liu, Guangrun Wang, Kun Zhang, Philip H. S. Torr, Xiao-Ping Zhang, Yansong Tang</li>
<li>for: 本研究旨在提高视频问答任务（VideoQA）中的模型表现，通过借鉴图像预训练知识，尽量减少视频域与图像域之间的semantic gap。</li>
<li>methods: 本文提出了Tem-Adapter，它通过视觉时间对齐和文本 semantics对齐来学习时间动力和复杂 semantics。另外，为了减少semantic gap和适应文本表示，我们引入了一个模板设计方法，用于融合问题和答案对为事件描述。</li>
<li>results: 我们在两个 VideoQA 测试 benchmark 上评估了 Tem-Adapter 和不同的预训练传输方法，结果显示了我们的方法的效果。<details>
<summary>Abstract</summary>
Video-language pre-trained models have shown remarkable success in guiding video question-answering (VideoQA) tasks. However, due to the length of video sequences, training large-scale video-based models incurs considerably higher costs than training image-based ones. This motivates us to leverage the knowledge from image-based pretraining, despite the obvious gaps between image and video domains. To bridge these gaps, in this paper, we propose Tem-Adapter, which enables the learning of temporal dynamics and complex semantics by a visual Temporal Aligner and a textual Semantic Aligner. Unlike conventional pretrained knowledge adaptation methods that only concentrate on the downstream task objective, the Temporal Aligner introduces an extra language-guided autoregressive task aimed at facilitating the learning of temporal dependencies, with the objective of predicting future states based on historical clues and language guidance that describes event progression. Besides, to reduce the semantic gap and adapt the textual representation for better event description, we introduce a Semantic Aligner that first designs a template to fuse question and answer pairs as event descriptions and then learns a Transformer decoder with the whole video sequence as guidance for refinement. We evaluate Tem-Adapter and different pre-train transferring methods on two VideoQA benchmarks, and the significant performance improvement demonstrates the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
vidéo-langage pré-entraînés modèles ont montré un succès remarquable dans la conduite des tâches de questions-réponses vidéo (VideoQA). Cependant, en raison de la longueur des séquences de vidéo, l'entraînement de modèles de grande échelle basés sur des vidéos soulève considérablement plus de coûts que l'entraînement de modèles d'images. Cela motive à utiliser la connaissance des modèles d'images pré-entraînés, malgré les écarts évidents entre les domaines de l'image et de la vidéo. Pour combler ces écarts, dans ce papier, nous proposons Tem-Adapter, qui permet l'apprentissage des dynamiques temporelles et des complexités sémantiques en utilisant un Alignateur Temporel Visuel et un Alignateur Sémantique Textuel. Contrairement aux méthodes de transfert de connaissance conventionnelles qui se concentrent uniquement sur l'objectif de la tâche downstream, l'Alignateur Temporel introduit une tâche autorégressive language-guidée supplémentaire visant à faciliter l'apprentissage des dépendances temporelles en prédictant des états futurs à partir de clues historiques et de guidances linguistiques qui décrivent l'évolution des événements. De plus, pour réduire l'écart sémantique et adapter la représentation textuelle pour une description plus précise des événements, nous introduisons un Alignateur Sémantique qui conçoit d'abord un modèle de template pour fusionner les paires de questions et de réponses comme des descriptions d'événements, puis apprend une décodeuse Transformer avec la totalité de la séquence de vidéo comme guidance pour la réfinement. Nous évaluons Tem-Adapter et différentes méthodes de transfert de connaissance sur deux benchmarks VideoQA, et les améliorations de performance significatives démontrent l'efficacité de notre méthode.
</details></li>
</ul>
<hr>
<h2 id="Prediction-of-post-radiotherapy-recurrence-volumes-in-head-and-neck-squamous-cell-carcinoma-using-3D-U-Net-segmentation"><a href="#Prediction-of-post-radiotherapy-recurrence-volumes-in-head-and-neck-squamous-cell-carcinoma-using-3D-U-Net-segmentation" class="headerlink" title="Prediction of post-radiotherapy recurrence volumes in head and neck squamous cell carcinoma using 3D U-Net segmentation"></a>Prediction of post-radiotherapy recurrence volumes in head and neck squamous cell carcinoma using 3D U-Net segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08396">http://arxiv.org/abs/2308.08396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Kutnár, Ivan R Vogelius, Katrin Elisabet Håkansson, Jens Petersen, Jeppe Friborg, Lena Specht, Mogens Bernsdorf, Anita Gothelf, Claus Kristensen, Abraham George Smith</li>
<li>for: 预后治疗头颈癌细胞瘤患者的普遍失血环境（LRR）仍然是治疗失败的常见原因。</li>
<li>methods: 我们使用了卷积神经网络（CNN）来预测前治疗18F-fluorodeoxyglucose пози트рон融合 Tomatoes（FDG-PET）&#x2F;计算机断层（CT）扫描图像中LRR的Volume。</li>
<li>results: CNN可以预测LRR的Volume，并且可以在预处理前的FDG-PET&#x2F;CT扫描图像上提供更好的预测结果，但是需要进一步的数据集开发以达到临床有用的预测精度。<details>
<summary>Abstract</summary>
Locoregional recurrences (LRR) are still a frequent site of treatment failure for head and neck squamous cell carcinoma (HNSCC) patients.   Identification of high risk subvolumes based on pretreatment imaging is key to biologically targeted radiation therapy. We investigated the extent to which a Convolutional neural network (CNN) is able to predict LRR volumes based on pre-treatment 18F-fluorodeoxyglucose positron emission tomography (FDG-PET)/computed tomography (CT) scans in HNSCC patients and thus the potential to identify biological high risk volumes using CNNs.   For 37 patients who had undergone primary radiotherapy for oropharyngeal squamous cell carcinoma, five oncologists contoured the relapse volumes on recurrence CT scans. Datasets of pre-treatment FDG-PET/CT, gross tumour volume (GTV) and contoured relapse for each of the patients were randomly divided into training (n=23), validation (n=7) and test (n=7) datasets. We compared a CNN trained from scratch, a pre-trained CNN, a SUVmax threshold approach, and using the GTV directly.   The SUVmax threshold method included 5 out of the 7 relapse origin points within a volume of median 4.6 cubic centimetres (cc). Both the GTV contour and best CNN segmentations included the relapse origin 6 out of 7 times with median volumes of 28 and 18 cc respectively.   The CNN included the same or greater number of relapse volume POs, with significantly smaller relapse volumes. Our novel findings indicate that CNNs may predict LRR, yet further work on dataset development is required to attain clinically useful prediction accuracy.
</details>
<details>
<summary>摘要</summary>
Head and neck squamous cell carcinoma (HNSCC) 的 Local Recurrence (LRR) 仍然是治疗失败的常见现象。 预测LRR的风险量基于前治学成像是关键。我们使用深度学习神经网络（CNN）来预测HNSCC患者的LRR量，并可能通过这种方式确定生物学高风险量。我们在37名受到主要放疗治疗的唇舌癌患者中，由5名外科医生确定了再次出现的量在复发CT扫描图上。我们将每名患者的预治FTDG-PET/CT、GTV和重点复发量分别作为训练（n=23）、验证（n=7）和测试（n=7）集。我们比较了从头开始训练的CNN、预先训练的CNN、SUVmax阈值方法和直接使用GTV。SUVmax阈值方法包含5个复发起点在 median 4.6立方厘米（cc）中。GTV标注和最佳CNN分割都包含复发起点6个中， median 值分别为28和18 cc。CNN包含同样或更多的复发量POs，并且复发量较小。我们的新发现表明CNN可能预测LRR，但是需要进一步的数据集开发以实现临床有用的预测精度。
</details></li>
</ul>
<hr>
<h2 id="SIGMA-Scale-Invariant-Global-Sparse-Shape-Matching"><a href="#SIGMA-Scale-Invariant-Global-Sparse-Shape-Matching" class="headerlink" title="SIGMA: Scale-Invariant Global Sparse Shape Matching"></a>SIGMA: Scale-Invariant Global Sparse Shape Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08393">http://arxiv.org/abs/2308.08393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maolin Gao, Paul Roetzer, Marvin Eisenberger, Zorah Lähner, Michael Moeller, Daniel Cremers, Florian Bernard</li>
<li>for: 该文章是为了生成精确的稀疏对匹配高度非均质形状而提出的一种新的杂integer编程（MIP）形ulation。</li>
<li>methods: 文章引入了一种投影拉Place-Beltrami算子（PLBO），该算子结合内在和外在的几何信息来衡量预测对匹配中所导致的扭formation质量。文章还 integrate了PLBO以及一种方向感知规则izerinto一种新的MIP形ulation，可以在许多实际问题上解决到全球最优解。与之前的方法不同的是，该方法具有恒等性、初始化free、优化 garantess和高分辨率网格上的线性时间复杂度。</li>
<li>results: 文章在一些复杂的3D数据集上实现了精确的非均质对匹配，包括一些具有不一致的网格的数据集，以及点云对网格的匹配问题。<details>
<summary>Abstract</summary>
We propose a novel mixed-integer programming (MIP) formulation for generating precise sparse correspondences for highly non-rigid shapes. To this end, we introduce a projected Laplace-Beltrami operator (PLBO) which combines intrinsic and extrinsic geometric information to measure the deformation quality induced by predicted correspondences. We integrate the PLBO, together with an orientation-aware regulariser, into a novel MIP formulation that can be solved to global optimality for many practical problems. In contrast to previous methods, our approach is provably invariant to rigid transformations and global scaling, initialisation-free, has optimality guarantees, and scales to high resolution meshes with (empirically observed) linear time. We show state-of-the-art results for sparse non-rigid matching on several challenging 3D datasets, including data with inconsistent meshing, as well as applications in mesh-to-point-cloud matching.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的混合整数编程（MIP）形式ulation для生成精度粗略对应关系 для高度非rigid shapes。为此，我们引入了投影拉place-Beltrami算子（PLBO），该算子结合内在和外在几何信息来衡量预测对应关系所导致的形变质量。我们将PLBO与orientation-aware regularizer integrate into a novel MIP formulation that can be solved to global optimality for many practical problems. 与之前的方法不同，我们的方法具有rigid transformations和全局缩放的不变性，初始化自由，有优化 garanties，并可扩展到高分辨率网格上（empirically observed) linear time。我们在several challenging 3D datasets上显示了非常好的结果，包括具有不一致的网格的数据、以及mesh-to-point-cloud matching应用。
</details></li>
</ul>
<hr>
<h2 id="Robust-Autonomous-Vehicle-Pursuit-without-Expert-Steering-Labels"><a href="#Robust-Autonomous-Vehicle-Pursuit-without-Expert-Steering-Labels" class="headerlink" title="Robust Autonomous Vehicle Pursuit without Expert Steering Labels"></a>Robust Autonomous Vehicle Pursuit without Expert Steering Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08380">http://arxiv.org/abs/2308.08380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxin Pan, Changyao Zhou, Mariia Gladkova, Qadeer Khan, Daniel Cremers</li>
<li>for: 本研究旨在实现横向和长向运动控制，以实现某车追踪其他车辆。</li>
<li>methods: 我们不依靠专家驾驶员提供的满足标签，而是利用经典控制器作为线上标签生成工具。我们还考虑控制值预测错误的影响，以避免跟踪失败和急剧坠机。为此，我们提出了一种有效的数据扩展方法，以训练能够处理不同视图的目标车辆。</li>
<li>results: 我们使用CARLA模拟器进行了广泛验证，并显示了实时性和不同enario中的稳定性。我们的方法能够在不同的路径和路径完成率下实现高的追踪性和安全性。<details>
<summary>Abstract</summary>
In this work, we present a learning method for lateral and longitudinal motion control of an ego-vehicle for vehicle pursuit. The car being controlled does not have a pre-defined route, rather it reactively adapts to follow a target vehicle while maintaining a safety distance. To train our model, we do not rely on steering labels recorded from an expert driver but effectively leverage a classical controller as an offline label generation tool. In addition, we account for the errors in the predicted control values, which can lead to a loss of tracking and catastrophic crashes of the controlled vehicle. To this end, we propose an effective data augmentation approach, which allows to train a network capable of handling different views of the target vehicle. During the pursuit, the target vehicle is firstly localized using a Convolutional Neural Network. The network takes a single RGB image along with cars' velocities and estimates the target vehicle's pose with respect to the ego-vehicle. This information is then fed to a Multi-Layer Perceptron, which regresses the control commands for the ego-vehicle, namely throttle and steering angle. We extensively validate our approach using the CARLA simulator on a wide range of terrains. Our method demonstrates real-time performance and robustness to different scenarios including unseen trajectories and high route completion. The project page containing code and multimedia can be publicly accessed here: https://changyaozhou.github.io/Autonomous-Vehicle-Pursuit/.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们提出了一种学习方法用于ego汽车的横向和 longitudinal 动作控制，以实现追踪目标车辆。控制的车辆不具备预定的路线，而是能够反应地适应追踪目标车辆，同时保持安全距离。为了训练我们的模型，我们不依赖于专家驾驶员提供的转向标签，而是有效地利用了古典控制器作为离线标签生成工具。此外，我们还考虑了预测控制值的错误，可能导致跟踪丢失和控制车辆的崩溃。为此，我们提出了一种有效的数据扩充方法，允许训练一个能够处理不同视角的目标车辆的网络。在追踪过程中，目标车辆首先被local化使用卷积神经网络，Network takes a single RGB image along with cars' velocities and estimates the target vehicle's pose with respect to the ego-vehicle。这些信息然后被传递给多层感知器，该感知器将反逆预测控制命令，即加速和转向角。我们在CARLA simulator上进行了广泛的验证，并证明了我们的方法具有实时性和不同enario中的稳定性。项目页面包含代码和多媒体，可以在以下链接上公共访问：https://changyaozhou.github.io/Autonomous-Vehicle-Pursuit/.
</details></li>
</ul>
<hr>
<h2 id="Automated-Semiconductor-Defect-Inspection-in-Scanning-Electron-Microscope-Images-a-Systematic-Review"><a href="#Automated-Semiconductor-Defect-Inspection-in-Scanning-Electron-Microscope-Images-a-Systematic-Review" class="headerlink" title="Automated Semiconductor Defect Inspection in Scanning Electron Microscope Images: a Systematic Review"></a>Automated Semiconductor Defect Inspection in Scanning Electron Microscope Images: a Systematic Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08376">http://arxiv.org/abs/2308.08376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thibault Lechien, Enrique Dehaerne, Bappaditya Dey, Victor Blanco, Sandip Halder, Stefan De Gendt, Wannes Meert</li>
<li>for: 本研究旨在提供一个系统性的对Semiconductor Defect Inspection（SEM）图像自动化检测技术的review，包括最新的创新和发展。</li>
<li>methods: 本研究使用Machine Learning算法，包括卷积神经网络，对Semiconductor样品进行自动化检测和定位缺陷。</li>
<li>results: 研究分析了38篇关于SEM图像自动化检测的文献，其中每篇文献的应用、方法、数据集、结果、限制和未来工作都被简要概述。<details>
<summary>Abstract</summary>
A growing need exists for efficient and accurate methods for detecting defects in semiconductor materials and devices. These defects can have a detrimental impact on the efficiency of the manufacturing process, because they cause critical failures and wafer-yield limitations. As nodes and patterns get smaller, even high-resolution imaging techniques such as Scanning Electron Microscopy (SEM) produce noisy images due to operating close to sensitivity levels and due to varying physical properties of different underlayers or resist materials. This inherent noise is one of the main challenges for defect inspection. One promising approach is the use of machine learning algorithms, which can be trained to accurately classify and locate defects in semiconductor samples. Recently, convolutional neural networks have proved to be particularly useful in this regard. This systematic review provides a comprehensive overview of the state of automated semiconductor defect inspection on SEM images, including the most recent innovations and developments. 38 publications were selected on this topic, indexed in IEEE Xplore and SPIE databases. For each of these, the application, methodology, dataset, results, limitations and future work were summarized. A comprehensive overview and analysis of their methods is provided. Finally, promising avenues for future work in the field of SEM-based defect inspection are suggested.
</details>
<details>
<summary>摘要</summary>
需求生长的势在普遍精炼芯片材料和设备中的缺陷检测方法中增加。这些缺陷可能会影响生产过程的效率，因为它们导致关键失败和芯片产量限制。随着节点和模式的减小，即使使用高分辨率成像技术如扫描电子显微镜（SEM），也会产生噪声，因为在不同的底层或抗氧剂材料的物理性能的变化导致。这种内生的噪声是检测缺陷的主要挑战。一种有前途的方法是使用机器学习算法，可以对芯片样品中的缺陷进行准确的分类和位置确定。最近，卷积神经网络已经证明是在这一点上非常有用。本文提供了涵盖自动芯片缺陷检测在SEM图像上的系统性评论，包括最新的创新和发展。38篇文章被选择，其中每篇文章的应用、方法、数据集、结果、局限性和未来工作的总结。对这些方法的系统性分析进行了详细的梳理。最后，对芯片缺陷检测领域的未来工作的可能性进行了建议。
</details></li>
</ul>
<hr>
<h2 id="Diff-CAPTCHA-An-Image-based-CAPTCHA-with-Security-Enhanced-by-Denoising-Diffusion-Model"><a href="#Diff-CAPTCHA-An-Image-based-CAPTCHA-with-Security-Enhanced-by-Denoising-Diffusion-Model" class="headerlink" title="Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising Diffusion Model"></a>Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08367">http://arxiv.org/abs/2308.08367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Jiang, Sanfeng Zhang, Linfeng Liu, Yanbing Peng</li>
<li>for: 增强文本Captcha的安全性</li>
<li>methods: 使用扩散模型生成文本图像，以强化文本特征和背景图像的混合，增加机器学习的难度</li>
<li>results: 对比基eline方案，Diff-CAPTCHA显示更高的安全性和usable性，可以有效抵抗终端攻击 algorithm<details>
<summary>Abstract</summary>
To enhance the security of text CAPTCHAs, various methods have been employed, such as adding the interference lines on the text, randomly distorting the characters, and overlapping multiple characters. These methods partly increase the difficulty of automated segmentation and recognition attacks. However, facing the rapid development of the end-to-end breaking algorithms, their security has been greatly weakened. The diffusion model is a novel image generation model that can generate the text images with deep fusion of characters and background images. In this paper, an image-click CAPTCHA scheme called Diff-CAPTCHA is proposed based on denoising diffusion models. The background image and characters of the CAPTCHA are treated as a whole to guide the generation process of a diffusion model, thus weakening the character features available for machine learning, enhancing the diversity of character features in the CAPTCHA, and increasing the difficulty of breaking algorithms. To evaluate the security of Diff-CAPTCHA, this paper develops several attack methods, including end-to-end attacks based on Faster R-CNN and two-stage attacks, and Diff-CAPTCHA is compared with three baseline schemes, including commercial CAPTCHA scheme and security-enhanced CAPTCHA scheme based on style transfer. The experimental results show that diffusion models can effectively enhance CAPTCHA security while maintaining good usability in human testing.
</details>
<details>
<summary>摘要</summary>
“为提高文本验证码（CAPTCHA）的安全性，各种方法有被应用，如添加文本中的干扰线条、随机扭曲字符和 overlap 多个字符。这些方法有所提高了自动化分 segmentation 和识别攻击的难度。然而，面对末端分解算法的快速发展，它们的安全性受到了严重的挑战。在这篇论文中，一种基于杂化模型的图像阻止验证码（Diff-CAPTCHA）被提出。图像阻止验证码中的背景图像和字符被视为一个整体，以引导杂化模型的生成过程，从而减弱字符特征，提高验证码中字符特征的多样性，并提高攻击算法的难度。为评估Diff-CAPTCHA的安全性，本文开发了多种攻击方法，包括基于Faster R-CNN的端到端攻击和两个阶段攻击。与三个基eline scheme进行比较，包括商业CAPTCHA scheme和基于样式转换的安全化CAPTCHA scheme。实验结果表明，杂化模型可以有效地提高验证码的安全性，同时保持人工测试中的使用体验良好。”
</details></li>
</ul>
<hr>
<h2 id="DeepContrast-Deep-Tissue-Contrast-Enhancement-using-Synthetic-Data-Degradations-and-OOD-Model-Predictions"><a href="#DeepContrast-Deep-Tissue-Contrast-Enhancement-using-Synthetic-Data-Degradations-and-OOD-Model-Predictions" class="headerlink" title="DeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data Degradations and OOD Model Predictions"></a>DeepContrast: Deep Tissue Contrast Enhancement using Synthetic Data Degradations and OOD Model Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08365">http://arxiv.org/abs/2308.08365</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nuno Pimpão Martins, Yannis Kalaidzidis, Marino Zerial, Florian Jug</li>
<li>for: 这 paper 的目的是提高微scopy 图像质量，以便更好地检查和 characterize 细胞和组织结构和功能。</li>
<li>methods: 这 paper 使用了深度学习方法，并需要ground truth 数据进行训练。然而，在深入到样本中时，获取 clean GT 数据是无法实现的。因此，作者们提出了一种新的方法，可以绕过 GT 数据的缺失。</li>
<li>results: 作者们首先使用了一种 Approximate forward model 来模拟深入到样本中的图像噪声和对比loss。然后，他们使用了一种 neural network 来学习这种噪声和对比loss 的 inverse。 results 表明，这种方法可以在 OOD 情况下提高微scopy 图像质量。然而，在每次预测中，图像对比度会不断提高，同时图像细节会逐渐消失。因此，取决于下游分析的需求，需要找到一个平衡点，以保留图像细节而同时提高对比度。<details>
<summary>Abstract</summary>
Microscopy images are crucial for life science research, allowing detailed inspection and characterization of cellular and tissue-level structures and functions. However, microscopy data are unavoidably affected by image degradations, such as noise, blur, or others. Many such degradations also contribute to a loss of image contrast, which becomes especially pronounced in deeper regions of thick samples. Today, best performing methods to increase the quality of images are based on Deep Learning approaches, which typically require ground truth (GT) data during training. Our inability to counteract blurring and contrast loss when imaging deep into samples prevents the acquisition of such clean GT data. The fact that the forward process of blurring and contrast loss deep into tissue can be modeled, allowed us to propose a new method that can circumvent the problem of unobtainable GT data. To this end, we first synthetically degraded the quality of microscopy images even further by using an approximate forward model for deep tissue image degradations. Then we trained a neural network that learned the inverse of this degradation function from our generated pairs of raw and degraded images. We demonstrated that networks trained in this way can be used out-of-distribution (OOD) to improve the quality of less severely degraded images, e.g. the raw data imaged in a microscope. Since the absolute level of degradation in such microscopy images can be stronger than the additional degradation introduced by our forward model, we also explored the effect of iterative predictions. Here, we observed that in each iteration the measured image contrast kept improving while detailed structures in the images got increasingly removed. Therefore, dependent on the desired downstream analysis, a balance between contrast improvement and retention of image details has to be found.
</details>
<details>
<summary>摘要</summary>
μ好像是生物科学研究中非常重要的一部分，允许详细检查和Characterization of cellular and tissue-level structures and functions。然而，μ数据都会受到图像质量下降的影响，如噪声、模糊或其他问题。这些问题也会导致图像的对比度下降，尤其是在样本深度较深的地方。今天，最好的图像质量提高方法都是基于深度学习的方法，它们通常需要训练时使用标准训练数据（GT数据）。由于我们无法对深入样本中的图像进行修复和对比度提高，因此我们无法获得这些干净的GT数据。由于前进过程中的图像噪声和对比度下降可以被模型化，我们提出了一种新的方法，可以缺省GT数据问题。我们首先使用一种近似的深度图像降解模型来further degrade the quality of microscopy images。然后，我们使用这些生成的对像对来训练一个神经网络，学习这个降解函数的逆运算。我们证明了这种方法可以在不使用GT数据的情况下，提高图像质量。由于μ数据的绝对水平可能比我们的前进模型引入的降解水平更高，我们也探讨了反复预测的效果。在每次预测中，我们发现图像对比度不断提高，同时图像中的细节也在逐渐消失。因此，根据下游分析的需要，需要找到对比度提高和图像细节保留的平衡。
</details></li>
</ul>
<hr>
<h2 id="KernelWarehouse-Towards-Parameter-Efficient-Dynamic-Convolution"><a href="#KernelWarehouse-Towards-Parameter-Efficient-Dynamic-Convolution" class="headerlink" title="KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution"></a>KernelWarehouse: Towards Parameter-Efficient Dynamic Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08361">http://arxiv.org/abs/2308.08361</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osvai/kernelwarehouse">https://github.com/osvai/kernelwarehouse</a></li>
<li>paper_authors: Chao Li, Anbang Yao</li>
<li>for: 提高卷积批处理器的表现，使其可以处理更大的输入数据集。</li>
<li>methods: 使用动态核心，并通过精细地分割和共享核心来提高卷积批处理器的表现。</li>
<li>results: 在ImageNet和MS-COCO datasets上，与基eline方法进行比较，并达到了状态 искусственный智能的表现。例如，使用KernelWarehouse在ImageNet上的ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny模型可以达到76.05%|81.05%|75.52%|82.51%的顶部一个精度。此外，KernelWarehouse还可以减小ConvNet模型的大小，同时提高其表现，例如，我们的ResNet18模型的参数减少了36.45%|65.10%，而其顶部一个精度提高了2.89%|2.29%。<details>
<summary>Abstract</summary>
Dynamic convolution learns a linear mixture of $n$ static kernels weighted with their sample-dependent attentions, demonstrating superior performance compared to normal convolution. However, existing designs are parameter-inefficient: they increase the number of convolutional parameters by $n$ times. This and the optimization difficulty lead to no research progress in dynamic convolution that can allow us to use a significant large value of $n$ (e.g., $n>100$ instead of typical setting $n<10$) to push forward the performance boundary. In this paper, we propose $KernelWarehouse$, a more general form of dynamic convolution, which can strike a favorable trade-off between parameter efficiency and representation power. Its key idea is to redefine the basic concepts of "$kernels$" and "$assembling$ $kernels$" in dynamic convolution from the perspective of reducing kernel dimension and increasing kernel number significantly. In principle, KernelWarehouse enhances convolutional parameter dependencies within the same layer and across successive layers via tactful kernel partition and warehouse sharing, yielding a high degree of freedom to fit a desired parameter budget. We validate our method on ImageNet and MS-COCO datasets with different ConvNet architectures, and show that it attains state-of-the-art results. For instance, the ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny model trained with KernelWarehouse on ImageNet reaches 76.05%|81.05%|75.52%|82.51% top-1 accuracy. Thanks to its flexible design, KernelWarehouse can even reduce the model size of a ConvNet while improving the accuracy, e.g., our ResNet18 model with 36.45%|65.10% parameter reduction to the baseline shows 2.89%|2.29% absolute improvement to top-1 accuracy.
</details>
<details>
<summary>摘要</summary>
“动态核函数学习一种线性混合的 $n$ 个静态核函数，表现更高于常规核函数，但现有设计不具有效率：它们将核函数参数数量增加 $n$ 倍。这和优化困难导致没有进展在动态核函数方面，使得我们无法使用大量的 $n$（例如，$n>100$ 而不是典型设定 $n<10$）来推动性能边界。在这篇论文中，我们提出 $KernelWarehouse$，一种更通用的动态核函数形式，可以寻求有利的参数效率和表达能力之间的平衡。其关键思想是从动态核函数中重新定义“核函数”和“核函数组合”的基本概念，以减少核函数维度并增加核函数数量，从而在同一层和successive层中增强参数之间的依赖关系。在原理上，KernelWarehouse 通过精细的核函数分割和仓库共享，提供了高度自由的参数预算调整。我们在 ImageNet 和 MS-COCO 数据集上验证了我们的方法，并显示其达到了当前最佳结果。例如，在 ImageNet 上，我们使用 KernelWarehouse 训练 ResNet18|ResNet50|MobileNetV2|ConvNeXt-Tiny 模型，达到了76.05%|81.05%|75.52%|82.51% 的顶部一个精度。由于其灵活的设计，KernelWarehouse 甚至可以将 ConvNet 模型的大小减小，同时提高准确性，例如，我们的 ResNet18 模型在参数减少 36.45%|65.10% 后，对于基eline 模型的较大准确性做出了2.89%|2.29% 的绝对改进。”
</details></li>
</ul>
<hr>
<h2 id="Membrane-Potential-Batch-Normalization-for-Spiking-Neural-Networks"><a href="#Membrane-Potential-Batch-Normalization-for-Spiking-Neural-Networks" class="headerlink" title="Membrane Potential Batch Normalization for Spiking Neural Networks"></a>Membrane Potential Batch Normalization for Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08359">http://arxiv.org/abs/2308.08359</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yfguo91/mpbn">https://github.com/yfguo91/mpbn</a></li>
<li>paper_authors: Yufei Guo, Yuhan Zhang, Yuanpei Chen, Weihang Peng, Xiaode Liu, Liwen Zhang, Xuhui Huang, Zhe Ma</li>
<li>for: 提高深度模型的能效性，采用了效果批处理（BN）技术。</li>
<li>methods: 使用了批处理后的卷积层，并在射频函数之前添加了另一个BN层以Normalize membrane potential，并提出了一种基于训练-推理分离的重parameterization技术来减少MPBN的时间成本。</li>
<li>results: 实验结果表明，提出的MPBN在非射频 datasets上表现良好，并且可以采用元素级别的形式。代码已经公开在 GitHub上（<a target="_blank" rel="noopener" href="https://github.com/yfguo91/MPBN">https://github.com/yfguo91/MPBN</a>）。<details>
<summary>Abstract</summary>
As one of the energy-efficient alternatives of conventional neural networks (CNNs), spiking neural networks (SNNs) have gained more and more interest recently. To train the deep models, some effective batch normalization (BN) techniques are proposed in SNNs. All these BNs are suggested to be used after the convolution layer as usually doing in CNNs. However, the spiking neuron is much more complex with the spatio-temporal dynamics. The regulated data flow after the BN layer will be disturbed again by the membrane potential updating operation before the firing function, i.e., the nonlinear activation. Therefore, we advocate adding another BN layer before the firing function to normalize the membrane potential again, called MPBN. To eliminate the induced time cost of MPBN, we also propose a training-inference-decoupled re-parameterization technique to fold the trained MPBN into the firing threshold. With the re-parameterization technique, the MPBN will not introduce any extra time burden in the inference. Furthermore, the MPBN can also adopt the element-wised form, while these BNs after the convolution layer can only use the channel-wised form. Experimental results show that the proposed MPBN performs well on both popular non-spiking static and neuromorphic datasets. Our code is open-sourced at \href{https://github.com/yfguo91/MPBN}{MPBN}.
</details>
<details>
<summary>摘要</summary>
如一种能效替代传统神经网络（CNN）的选择，脉冲神经网络（SNN）在最近吸引了更多的关注。为了训练深度模型，一些有效的批normalization（BN）技术在SNN中被提出。所有这些BN都被建议在卷积层后使用，与CNN的做法一样。然而，神经元更加复杂，具有空间时间动力学。通过更正数据流后BN层的规则操作，将导致神经元电位更新操作前的非线性活化函数被干扰。因此，我们建议在神经元电位更新操作前加入另一个BN层，称为MPBN。为了消除MPBN引入的时间成本，我们还提出了在训练和推理之间分离的重parameterization技术，可以将MPBN翻译成发射阈值。通过这种重parameterization技术，MPBN在推理中不会增加额外的时间负担。此外，MPBN还可以采用元素级别的形式，而这些BN后 convolution层只能使用通道级别的形式。实验结果表明，我们提出的MPBN在非激发神经网络的流行静止数据集和neuromorphic数据集上都表现良好。我们的代码在GitHub上公开，请参考\href{https://github.com/yfguo91/MPBN}{MPBN}.
</details></li>
</ul>
<hr>
<h2 id="GAEI-UNet-Global-Attention-and-Elastic-Interaction-U-Net-for-Vessel-Image-Segmentation"><a href="#GAEI-UNet-Global-Attention-and-Elastic-Interaction-U-Net-for-Vessel-Image-Segmentation" class="headerlink" title="GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel Image Segmentation"></a>GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08345">http://arxiv.org/abs/2308.08345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruiqiang Xiao, Zhuoyue Wan</li>
<li>for: 这篇论文旨在提高血管图像分割的精度和可靠性，以便提供更加准确和可靠的医疗诊断工具。</li>
<li>methods: 该论文提出了一种新的模型，即GAEI-UNet，它结合全局注意力和弹性交互式技术来提高深度学习分割的精度和连接度。</li>
<li>results: 对于DRIVE眼球血管数据集的评估表明，GAEI-UNet比传统的深度学习分割模型具有更高的精度和连接度，而不会提高计算复杂性。<details>
<summary>Abstract</summary>
Vessel image segmentation plays a pivotal role in medical diagnostics, aiding in the early detection and treatment of vascular diseases. While segmentation based on deep learning has shown promising results, effectively segmenting small structures and maintaining connectivity between them remains challenging. To address these limitations, we propose GAEI-UNet, a novel model that combines global attention and elastic interaction-based techniques. GAEI-UNet leverages global spatial and channel context information to enhance high-level semantic understanding within the U-Net architecture, enabling precise segmentation of small vessels. Additionally, we adopt an elastic interaction-based loss function to improve connectivity among these fine structures. By capturing the forces generated by misalignment between target and predicted shapes, our model effectively learns to preserve the correct topology of vessel networks. Evaluation on retinal vessel dataset -- DRIVE demonstrates the superior performance of GAEI-UNet in terms of SE and connectivity of small structures, without significantly increasing computational complexity. This research aims to advance the field of vessel image segmentation, providing more accurate and reliable diagnostic tools for the medical community. The implementation code is available on Code.
</details>
<details>
<summary>摘要</summary>
船体影像分割在医学诊断中发挥重要作用，帮助早期发现和治疗血管疾病。深度学习基于的分割方法已经显示出了有前途的成绩，但是分割小结构和保持这些结构之间的连接仍然是挑战。为了解决这些限制，我们提出了GAEI-UNet模型，该模型 combining global attention和弹性交互技术。GAEI-UNet利用全局空间和通道信息来增强高级 semantic understanding within U-Net架构，以帮助精确地分割小血管。此外，我们采用了弹性交互基于的损失函数来提高这些细结构之间的连接。通过捕捉目标形态与预测形态之间的偏差生成的力量，我们的模型可以准确地保持血管网络的正确topology。对于retinal vessel数据集（DRIVE）的评估表明，GAEI-UNet在准确率和细结构连接方面具有显著优势，而不是增加计算复杂性。本研究旨在提高船体影像分割的精度和可靠性，为医学社区提供更加准确和可靠的诊断工具。代码实现可以在Code.
</details></li>
</ul>
<hr>
<h2 id="Denoising-Diffusion-Probabilistic-Model-for-Retinal-Image-Generation-and-Segmentation"><a href="#Denoising-Diffusion-Probabilistic-Model-for-Retinal-Image-Generation-and-Segmentation" class="headerlink" title="Denoising Diffusion Probabilistic Model for Retinal Image Generation and Segmentation"></a>Denoising Diffusion Probabilistic Model for Retinal Image Generation and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08339">http://arxiv.org/abs/2308.08339</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aaleka/retree">https://github.com/aaleka/retree</a></li>
<li>paper_authors: Alnur Alimanov, Md Baharul Islam</li>
<li>For: 用于检测和诊断视网膜图像中的眼病、血液循环和大脑相关疾病。* Methods: 使用Generative Adversarial Networks (GAN)生成深度学习模型，并使用Denosing Diffusion Probabilistic Model (DDPM)生成图像。* Results: 提出了一个新的DDPM模型，并创建了一个名为Retinal Trees (ReTree)的数据集，包括视网膜图像、相应的血管树和基于DDPM的分类网络。通过对 synthetic data 进行训练和 authentic data 进行测试， validate 了该数据集的有效性。Here’s the summary in English for reference:* For: Detection and diagnosis of eye, blood circulation, and brain-related diseases using retinal images.* Methods: Use of Generative Adversarial Networks (GAN) to generate deep learning models, and use of Denoising Diffusion Probabilistic Model (DDPM) to generate images.* Results: Proposed a new DDPM model and created a dataset called Retinal Trees (ReTree), which includes retinal images, corresponding vessel trees, and a classification network based on DDPM trained with images from the ReTree dataset. Validated the effectiveness of the dataset by training the vessel segmentation model with synthetic data and testing it on authentic data.<details>
<summary>Abstract</summary>
Experts use retinal images and vessel trees to detect and diagnose various eye, blood circulation, and brain-related diseases. However, manual segmentation of retinal images is a time-consuming process that requires high expertise and is difficult due to privacy issues. Many methods have been proposed to segment images, but the need for large retinal image datasets limits the performance of these methods. Several methods synthesize deep learning models based on Generative Adversarial Networks (GAN) to generate limited sample varieties. This paper proposes a novel Denoising Diffusion Probabilistic Model (DDPM) that outperformed GANs in image synthesis. We developed a Retinal Trees (ReTree) dataset consisting of retinal images, corresponding vessel trees, and a segmentation network based on DDPM trained with images from the ReTree dataset. In the first stage, we develop a two-stage DDPM that generates vessel trees from random numbers belonging to a standard normal distribution. Later, the model is guided to generate fundus images from given vessel trees and random distribution. The proposed dataset has been evaluated quantitatively and qualitatively. Quantitative evaluation metrics include Frechet Inception Distance (FID) score, Jaccard similarity coefficient, Cohen's kappa, Matthew's Correlation Coefficient (MCC), precision, recall, F1-score, and accuracy. We trained the vessel segmentation model with synthetic data to validate our dataset's efficiency and tested it on authentic data. Our developed dataset and source code is available at https://github.com/AAleka/retree.
</details>
<details>
<summary>摘要</summary>
专家利用血液图像和血管树来检测和诊断多种眼部、血液和大脑相关疾病。然而，手动分割血液图像是一项时间consuming和技术困难的任务，尤其是由于隐私问题。许多方法已经提出来分割图像，但是因为缺乏大量血液图像数据，这些方法的性能受限。本文提出了一种新的干扰扩散概率模型（DDPM），其在图像生成中超越了生成 adversarial networks（GAN）的性能。我们开发了一个名为“Retinal Trees”（ReTree）的数据集，该数据集包括血液图像、对应的血管树和基于 DDPM 的分割网络，并在 ReTree 数据集上训练了 DDPM 模型。在首个阶段，我们开发了一种两个阶段的 DDPM，其中首先生成血管树从随机数列中的标准正态分布中。然后，模型被引导生成基于给定血管树和随机分布的血液图像。我们对提出的数据集进行了量化和质量evaluation。量化评价指标包括Frechet Inception Distance（FID）分数、Jaccard同异度系数、Cohen的κ值、Matthew的相关系数（MCC）、精度、 recall、F1 分数和准确率。我们使用合成数据训练了血管分割模型，以验证我们的数据集的效率，并在真实数据上测试了它。我们开发的数据集和源代码可以在 <https://github.com/AAleka/retree> 上获得。
</details></li>
</ul>
<hr>
<h2 id="Improving-Depth-Gradient-Continuity-in-Transformers-A-Comparative-Study-on-Monocular-Depth-Estimation-with-CNN"><a href="#Improving-Depth-Gradient-Continuity-in-Transformers-A-Comparative-Study-on-Monocular-Depth-Estimation-with-CNN" class="headerlink" title="Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN"></a>Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08333">http://arxiv.org/abs/2308.08333</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawei Yao, Tong Wu, Xiaofeng Zhang</li>
<li>for: 本研究旨在探讨 transformer 和 cnn 在单目深度估计中的差异，以及如何使 transformer 模型更好地处理深度估计。</li>
<li>methods: 我们使用 sparse pixel 方法对两种模型进行比较，并发现 transformer  excel 在处理全局上下文和细节文件方面，但在保持深度Gradient Continuity 方面落后于 cnn。为了提高 transformer 模型在单目深度估计中的性能，我们提出了 Depth Gradient Refinement (DGR) 模块，该模块通过高阶分数、特征融合和重新均衡来进行深度估计的精细调整。此外，我们还使用了 оптимальный运输理论，将深度图像看作空间概率分布，并使用 оптимальный运输距离作为损失函数来优化我们的模型。</li>
<li>results: 我们的实验结果显示，搭配 Depth Gradient Refinement (DGR) 模块和我们提出的损失函数后，模型的性能得到了提高，而无需增加复杂度和计算成本。此研究不仅提供了 transformer 和 cnn 在单目深度估计中的新的视角，还开辟了新的深度估计方法的先河。<details>
<summary>Abstract</summary>
Monocular depth estimation is an ongoing challenge in computer vision. Recent progress with Transformer models has demonstrated notable advantages over conventional CNNs in this area. However, there's still a gap in understanding how these models prioritize different regions in 2D images and how these regions affect depth estimation performance. To explore the differences between Transformers and CNNs, we employ a sparse pixel approach to contrastively analyze the distinctions between the two. Our findings suggest that while Transformers excel in handling global context and intricate textures, they lag behind CNNs in preserving depth gradient continuity. To further enhance the performance of Transformer models in monocular depth estimation, we propose the Depth Gradient Refinement (DGR) module that refines depth estimation through high-order differentiation, feature fusion, and recalibration. Additionally, we leverage optimal transport theory, treating depth maps as spatial probability distributions, and employ the optimal transport distance as a loss function to optimize our model. Experimental results demonstrate that models integrated with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed loss function enhance performance without increasing complexity and computational costs. This research not only offers fresh insights into the distinctions between Transformers and CNNs in depth estimation but also paves the way for novel depth estimation methodologies.
</details>
<details>
<summary>摘要</summary>
单眼深度估计是计算机视觉领域中持续的挑战。最近的对称模型在这个领域中获得了杰出的进步，与传统的CNN相比。然而，我们仍然不确定这些模型在2D图像中不同区域的优先顺序和如何影响深度估计性能。为了探索这两种模型之间的差异，我们使用罕发像素方法进行对照分析。我们的发现表明，对称模型在处理全球背景和细节文化方面表现出色，但在保持深度梯度连续性方面落后于CNN。为了进一步提高对称模型在单眼深度估计中的表现，我们提出了深度梯度精照（DGR）模组，该模组通过高阶差分、特征融合和重新对准来精照深度估计。此外，我们运用了最佳运输理论，将深度图表视为空间概率分布，并使用最佳运输距离作为损失函数来优化我们的模型。实验结果显示，将DGR模组和我们提议的损失函数组合使用可以提高表现，不会增加复杂度和计算成本。本研究不具备对对称模型和CNN在深度估计中的新发现，也开启了新的深度估计方法的先河。
</details></li>
</ul>
<hr>
<h2 id="AdaBrowse-Adaptive-Video-Browser-for-Efficient-Continuous-Sign-Language-Recognition"><a href="#AdaBrowse-Adaptive-Video-Browser-for-Efficient-Continuous-Sign-Language-Recognition" class="headerlink" title="AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language Recognition"></a>AdaBrowse: Adaptive Video Browser for Efficient Continuous Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08327">http://arxiv.org/abs/2308.08327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hulianyuyy/adabrowse">https://github.com/hulianyuyy/adabrowse</a></li>
<li>paper_authors: Lianyu Hu, Liqing Gao, Zekang Liu, Chi-Man Pun, Wei Feng</li>
<li>for: 本研究旨在利用Raw视频中的特征重复来提高短视频识别效率。</li>
<li>methods: 我们提出了一种新的适应模型（AdaBrowse），通过模仿这个问题为一个顺序决策问题来动态选择输入视频序列中最 Informative的子序列。</li>
<li>results: 我们的实验结果表明，AdaBrowse和AdaBrowse+可以与状态静态方法具有相同的准确率，同时减少了1.44倍的计算量和2.12倍的FLOPs。<details>
<summary>Abstract</summary>
Raw videos have been proven to own considerable feature redundancy where in many cases only a portion of frames can already meet the requirements for accurate recognition. In this paper, we are interested in whether such redundancy can be effectively leveraged to facilitate efficient inference in continuous sign language recognition (CSLR). We propose a novel adaptive model (AdaBrowse) to dynamically select a most informative subsequence from input video sequences by modelling this problem as a sequential decision task. In specific, we first utilize a lightweight network to quickly scan input videos to extract coarse features. Then these features are fed into a policy network to intelligently select a subsequence to process. The corresponding subsequence is finally inferred by a normal CSLR model for sentence prediction. As only a portion of frames are processed in this procedure, the total computations can be considerably saved. Besides temporal redundancy, we are also interested in whether the inherent spatial redundancy can be seamlessly integrated together to achieve further efficiency, i.e., dynamically selecting a lowest input resolution for each sample, whose model is referred to as AdaBrowse+. Extensive experimental results on four large-scale CSLR datasets, i.e., PHOENIX14, PHOENIX14-T, CSL-Daily and CSL, demonstrate the effectiveness of AdaBrowse and AdaBrowse+ by achieving comparable accuracy with state-of-the-art methods with 1.44$\times$ throughput and 2.12$\times$ fewer FLOPs. Comparisons with other commonly-used 2D CNNs and adaptive efficient methods verify the effectiveness of AdaBrowse. Code is available at \url{https://github.com/hulianyuyy/AdaBrowse}.
</details>
<details>
<summary>摘要</summary>
raw 视频有许多重复的特征，只需要一部分帧可以达到准确的认知要求。在这篇论文中，我们关注到是否可以利用这种重复来提高连续手语识别（CSLR）的效率。我们提出了一种新的适应模型（AdaBrowse），可以动态选择输入视频序列中最 informative 的子序列。具体来说，我们首先使用一个轻量级网络快速扫描输入视频，提取低精度特征。然后，这些特征被 feed 到一个策略网络，以智能选择处理的子序列。最后，对于这个子序列，我们使用一个标准的 CSLR 模型进行句子预测。由于只处理一部分帧，总计算量可以得到显著减少。此外，我们还关注是否可以将内在的空间重复合理地融合到一起，以实现更高的效率，即动态选择每个样本的最低输入分辨率。我们称之为 AdaBrowse+。我们在四个大规模 CSLR 数据集上进行了广泛的实验，分别是 PHOENIX14、PHOENIX14-T、CSL-Daily 和 CSL，并证明了 AdaBrowse 和 AdaBrowse+ 的有效性，与state-of-the-art方法相比，具有1.44倍的吞吐量和2.12倍的 fewer FLOPs。与其他常用的2D CNNs和适应高效方法进行比较，证明了 AdaBrowse 的有效性。代码可以在 GitHub 上找到：\url{https://github.com/hulianyuyy/AdaBrowse}。
</details></li>
</ul>
<hr>
<h2 id="Visually-Aware-Context-Modeling-for-News-Image-Captioning"><a href="#Visually-Aware-Context-Modeling-for-News-Image-Captioning" class="headerlink" title="Visually-Aware Context Modeling for News Image Captioning"></a>Visually-Aware Context Modeling for News Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08325">http://arxiv.org/abs/2308.08325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingyu Qu, Tinne Tuytelaars, Marie-Francine Moens</li>
<li>for: 新闻图文描述是为了根据新闻文章和图片的内容生成图文描述。</li>
<li>methods: 我们设计了一个人脸命名模块，用于学习图片中的人脸和文章中的名称的更好的嵌入。此外，我们还设计了一种检索策略，使用CLIP来检索与图片相关的文章中的句子。</li>
<li>results: 我们进行了广泛的实验，证明了我们的框架的有效性。无需使用额外的对应数据，我们在两个新闻图文描述数据集上建立了新的状态前瞻性，超越了之前的状态前瞻性5个CIDEr点。<details>
<summary>Abstract</summary>
The goal of News Image Captioning is to generate an image caption according to the content of both a news article and an image. To leverage the visual information effectively, it is important to exploit the connection between the context in the articles/captions and the images. Psychological studies indicate that human faces in images draw higher attention priorities. On top of that, humans often play a central role in news stories, as also proven by the face-name co-occurrence pattern we discover in existing News Image Captioning datasets. Therefore, we design a face-naming module for faces in images and names in captions/articles to learn a better name embedding. Apart from names, which can be directly linked to an image area (faces), news image captions mostly contain context information that can only be found in the article. Humans typically address this by searching for relevant information from the article based on the image. To emulate this thought process, we design a retrieval strategy using CLIP to retrieve sentences that are semantically close to the image. We conduct extensive experiments to demonstrate the efficacy of our framework. Without using additional paired data, we establish the new state-of-the-art performance on two News Image Captioning datasets, exceeding the previous state-of-the-art by 5 CIDEr points. We will release code upon acceptance.
</details>
<details>
<summary>摘要</summary>
文章标题：图像新闻描述的目标是根据新闻文章和图像内容生成图像描述。为了有效利用图像信息，需要利用文章和图像之间的联系。心理学研究表明，图像中的人脸吸引更高的注意力。此外，人类在新闻故事中也很重要，我们发现在现有的新闻图像描述数据集中存在人名和图像的相互关系。因此，我们设计了一个人脸命名模块，以学习更好的人名嵌入。除了名称，新闻图像描述主要包含文章中的上下文信息，这些信息只能通过文章来找到。我们通过使用CLIP进行检索策略，将文章中相似的句子与图像相关联。我们进行了广泛的实验，证明了我们的框架的效果。无需使用额外的对应数据，我们在两个新闻图像描述数据集上建立了新的状态的报告，超越了前一个状态的5个CIDEr点。我们将代码发布于接受后。
</details></li>
</ul>
<hr>
<h2 id="Stable-and-Causal-Inference-for-Discriminative-Self-supervised-Deep-Visual-Representations"><a href="#Stable-and-Causal-Inference-for-Discriminative-Self-supervised-Deep-Visual-Representations" class="headerlink" title="Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations"></a>Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08321">http://arxiv.org/abs/2308.08321</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuewei Yang, Hai Li, Yiran Chen</li>
<li>For: This paper aims to address the instability issues in discriminative self-supervised learning methods and improve the downstream performance of the learned representations.* Methods: The paper uses a causal perspective to analyze the unstable behaviors of discriminative self-supervised methods and proposes solutions to overcome these issues. The proposed solutions involve tempering a linear transformation with controlled synthetic data.* Results: The authors show through experiments on both controlled image datasets and realistic image datasets that their proposed solutions are effective in addressing the instability issues and improving the downstream performance of the learned representations.<details>
<summary>Abstract</summary>
In recent years, discriminative self-supervised methods have made significant strides in advancing various visual tasks. The central idea of learning a data encoder that is robust to data distortions/augmentations is straightforward yet highly effective. Although many studies have demonstrated the empirical success of various learning methods, the resulting learned representations can exhibit instability and hinder downstream performance. In this study, we analyze discriminative self-supervised methods from a causal perspective to explain these unstable behaviors and propose solutions to overcome them. Our approach draws inspiration from prior works that empirically demonstrate the ability of discriminative self-supervised methods to demix ground truth causal sources to some extent. Unlike previous work on causality-empowered representation learning, we do not apply our solutions during the training process but rather during the inference process to improve time efficiency. Through experiments on both controlled image datasets and realistic image datasets, we show that our proposed solutions, which involve tempering a linear transformation with controlled synthetic data, are effective in addressing these issues.
</details>
<details>
<summary>摘要</summary>
近年来，权偏自监学方法在不同的视觉任务中作出了重要进步。这中心思想是学习一种数据编码器，该编码器能够对数据扭曲/增强产生Robust。虽然许多研究表明了不同学习方法的实际成功，但是获得的学习表示可能会具有不稳定性，影响下游性能。在这种研究中，我们从 causal 角度分析权偏自监学方法，解释这些不稳定行为，并提出解决方案。我们的方法启发自先前的研究，证明了权偏自监学方法可以一定程度地分解真实的 causal 源。不同于之前的 causality-empowered representation learning，我们在执行过程中不应用我们的解决方案，而是在推理过程中应用，以提高时间效率。通过对控制图像 dataset 和真实图像 dataset 进行实验，我们展示了我们提议的解决方案，即在推理过程中tempering 一个线性变换的控制synthetic数据，是有效地解决这些问题。
</details></li>
</ul>
<hr>
<h2 id="Dual-Stream-Diffusion-Net-for-Text-to-Video-Generation"><a href="#Dual-Stream-Diffusion-Net-for-Text-to-Video-Generation" class="headerlink" title="Dual-Stream Diffusion Net for Text-to-Video Generation"></a>Dual-Stream Diffusion Net for Text-to-Video Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08316">http://arxiv.org/abs/2308.08316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Binhui Liu, Xin Liu, Anbo Dai, Zhiyong Zeng, Zhen Cui, Jian Yang</li>
<li>for: 提高生成视频的内容一致性</li>
<li>methods: 提posed dual-stream diffusion net (DSDN)，包括两个扩散流：视频内容流和动作流，以及我们设计的cross-transformer交互模块，以使内容和动作领域之间进行良好的对应。</li>
<li>results: 实验表明，我们的方法可以生成更加平滑的连续视频，具有 fewer flickers.<details>
<summary>Abstract</summary>
With the emerging diffusion models, recently, text-to-video generation has aroused increasing attention. But an important bottleneck therein is that generative videos often tend to carry some flickers and artifacts. In this work, we propose a dual-stream diffusion net (DSDN) to improve the consistency of content variations in generating videos. In particular, the designed two diffusion streams, video content and motion branches, could not only run separately in their private spaces for producing personalized video variations as well as content, but also be well-aligned between the content and motion domains through leveraging our designed cross-transformer interaction module, which would benefit the smoothness of generated videos. Besides, we also introduce motion decomposer and combiner to faciliate the operation on video motion. Qualitative and quantitative experiments demonstrate that our method could produce amazing continuous videos with fewer flickers.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本转换为简化中文。</SYS>现在的扩散模型已经吸引了更多的注意力，特别是在文本到视频生成方面。然而，生成视频时存在一个重要的瓶颈，即生成视频经常带有些微震动和 artifacts。在这种情况下，我们提出了双流扩散网络（DSDN），以提高生成视频的内容变化一致性。具体来说，我们设计了两个扩散流，一个是视频内容流，另一个是动作流，它们可以在独立的私有空间中运行，以生成个性化的视频内容和动作。此外，我们还引入了动作分解器和组合器，以便操作视频动作。实际和量测试表明，我们的方法可以生成更加流畅的视频，带有 fewer flickers。
</details></li>
</ul>
<hr>
<h2 id="ECPC-IDS-A-benchmark-endometrail-cancer-PET-CT-image-dataset-for-evaluation-of-semantic-segmentation-and-detection-of-hypermetabolic-regions"><a href="#ECPC-IDS-A-benchmark-endometrail-cancer-PET-CT-image-dataset-for-evaluation-of-semantic-segmentation-and-detection-of-hypermetabolic-regions" class="headerlink" title="ECPC-IDS:A benchmark endometrail cancer PET&#x2F;CT image dataset for evaluation of semantic segmentation and detection of hypermetabolic regions"></a>ECPC-IDS:A benchmark endometrail cancer PET&#x2F;CT image dataset for evaluation of semantic segmentation and detection of hypermetabolic regions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08313">http://arxiv.org/abs/2308.08313</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dechao Tang, Xuanyi Li, Tianming Du, Deguo Ma, Zhiyu Ma, Hongzan Sun, Marcin Grzegorzek, Huiyan Jiang, Chen Li</li>
<li>for:  This paper aims to provide a publicly available dataset of endometrial cancer images for research and development of computer-assisted diagnostic techniques.</li>
<li>methods:  The paper uses five classical deep learning semantic segmentation methods and six deep learning object detection methods to demonstrate the differences between various methods on the dataset.</li>
<li>results:  The paper provides a large number of multiple images, including a large amount of information required for image and target detection, which can aid researchers in exploring new algorithms to enhance computer-assisted technology and improve the accuracy and objectivity of diagnosis.<details>
<summary>Abstract</summary>
Endometrial cancer is one of the most common tumors in the female reproductive system and is the third most common gynecological malignancy that causes death after ovarian and cervical cancer. Early diagnosis can significantly improve the 5-year survival rate of patients. With the development of artificial intelligence, computer-assisted diagnosis plays an increasingly important role in improving the accuracy and objectivity of diagnosis, as well as reducing the workload of doctors. However, the absence of publicly available endometrial cancer image datasets restricts the application of computer-assisted diagnostic techniques.In this paper, a publicly available Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation and Detection of Hypermetabolic Regions (ECPC-IDS) are published. Specifically, the segmentation section includes PET and CT images, with a total of 7159 images in multiple formats. In order to prove the effectiveness of segmentation methods on ECPC-IDS, five classical deep learning semantic segmentation methods are selected to test the image segmentation task. The object detection section also includes PET and CT images, with a total of 3579 images and XML files with annotation information. Six deep learning methods are selected for experiments on the detection task.This study conduct extensive experiments using deep learning-based semantic segmentation and object detection methods to demonstrate the differences between various methods on ECPC-IDS. As far as we know, this is the first publicly available dataset of endometrial cancer with a large number of multiple images, including a large amount of information required for image and target detection. ECPC-IDS can aid researchers in exploring new algorithms to enhance computer-assisted technology, benefiting both clinical doctors and patients greatly.
</details>
<details>
<summary>摘要</summary>
《endoometrial cancer图像数据集》是女性生殖系统中最常见的肿瘤之一，也是第三种最常致命的生殖系统癌症之一，只有后于肾脏和子宫癌症。早期诊断可以显著提高患者5年生存率。随着人工智能的发展，计算机助手诊断在改善诊断准确性和公正性方面扮演着越来越重要的角色，同时减轻医生的工作负担。但是， absent of publicly available endometrial cancer image datasets restricts the application of computer-assisted diagnostic techniques。在本文中，一个公共可用的Endometrial Cancer PET/CT Image Dataset for Evaluation of Semantic Segmentation and Detection of Hypermetabolic Regions（ECPC-IDS）被发布。具体来说，分别包括PET和CT图像，总共7159个图像，存储在多种格式中。为证明ECPC-IDS上segmenation方法的效果，本研究选择了5种经典的深度学习 semantic segmentation方法进行测试图像 segmentation任务。另外，包括PET和CT图像，总共3579个图像和XML文件中的注释信息。为了证明检测任务中的不同方法的差异，本研究选择了6种深度学习方法进行实验。本研究通过深度学习基于Semantic Segmentation和object Detection方法进行了广泛的实验，以证明ECPC-IDS上的差异。我们知道，ECPC-IDS是第一个公共可用的endometrial cancer图像数据集，包含大量的多Format图像和需要的信息，以便图像和目标检测。ECPC-IDS将为研究人员提供了一个大量的数据集，以便他们探索新的算法，为临床医生和患者带来很大的好处。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Next-Active-Objects-for-Context-Aware-Anticipation-in-Egocentric-Videos"><a href="#Leveraging-Next-Active-Objects-for-Context-Aware-Anticipation-in-Egocentric-Videos" class="headerlink" title="Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos"></a>Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08303">http://arxiv.org/abs/2308.08303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanket Thakur, Cigdem Beyan, Pietro Morerio, Vittorio Murino, Alessio Del Bue</li>
<li>for: 预测人类在短时间内与物体进行互动</li>
<li>methods: 使用多Modal end-to-end transformer网络，通过对观察到的帧进行注意力集中来预测下一个活跃的物体（NAO），并最终预测基于这些探测结果的上下文意识满意的未来行为。</li>
<li>results: 相比现有的视频模型架构，NAOGAT能够更好地利用物体与全景场景的关系，预测出下一个活跃的物体和相应的未来行为，同时可以利用物体的动态运动来提高准确率。通过我们的实验，我们表明NAOGAT在Ego4D和EpicKitchens-100(“Unseen Set”)两个 dataset上比现有方法表现出色，并且在多个额外指标中表现出色，如时间到接触（TTC）和下一个活跃物体的本地化探测。<details>
<summary>Abstract</summary>
Objects are crucial for understanding human-object interactions. By identifying the relevant objects, one can also predict potential future interactions or actions that may occur with these objects. In this paper, we study the problem of Short-Term Object interaction anticipation (STA) and propose NAOGAT (Next-Active-Object Guided Anticipation Transformer), a multi-modal end-to-end transformer network, that attends to objects in observed frames in order to anticipate the next-active-object (NAO) and, eventually, to guide the model to predict context-aware future actions. The task is challenging since it requires anticipating future action along with the object with which the action occurs and the time after which the interaction will begin, a.k.a. the time to contact (TTC). Compared to existing video modeling architectures for action anticipation, NAOGAT captures the relationship between objects and the global scene context in order to predict detections for the next active object and anticipate relevant future actions given these detections, leveraging the objects' dynamics to improve accuracy. One of the key strengths of our approach, in fact, is its ability to exploit the motion dynamics of objects within a given clip, which is often ignored by other models, and separately decoding the object-centric and motion-centric information. Through our experiments, we show that our model outperforms existing methods on two separate datasets, Ego4D and EpicKitchens-100 ("Unseen Set"), as measured by several additional metrics, such as time to contact, and next-active-object localization. The code will be available upon acceptance.
</details>
<details>
<summary>摘要</summary>
objecs 是人机交互的关键因素。通过确定相关的 объекcs，一可以预测未来的交互或操作。在这篇论文中，我们研究了短期对象交互预测（STA）问题，并提出了NAOGAT（下一个活动对象引导预测变换器），一种多modal 终端变换网络，它在观察到的帧中注意到对象，以预测下一个活动对象（NAO），并最终用这些预测来导引模型预测受到上下文影响的未来行为。这个任务非常具有挑战性，因为它需要预测将来的行为，同时与这个行为发生的对象和时间相关，即接触时间（TTC）。与现有的视频模型化建筑不同，NAOGAT 捕捉对象与全局场景上下文之间的关系，以预测下一个活动对象的探测和未来行为，利用对象的动力学特征提高准确性。我们的方法的一个关键优势是能够利用视频中对象的动力学特征，这些特征通常被其他模型忽略。我们通过实验证明，我们的模型在Ego4D和EpicKitchens-100（“未seen集”）两个数据集上比现有方法表现出色， measured by 一些额外指标，如接触时间和下一个活动对象的本地化。代码将在接受后公开。
</details></li>
</ul>
<hr>
<h2 id="Improving-Audio-Visual-Segmentation-with-Bidirectional-Generation"><a href="#Improving-Audio-Visual-Segmentation-with-Bidirectional-Generation" class="headerlink" title="Improving Audio-Visual Segmentation with Bidirectional Generation"></a>Improving Audio-Visual Segmentation with Bidirectional Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08288">http://arxiv.org/abs/2308.08288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawei Hao, Yuxin Mao, Bowen He, Xiaodong Han, Yuchao Dai, Yiran Zhong</li>
<li>for: 这个论文旨在提高Audio-Visual Segmentation（AVS）的精度，以便在视频中准确地分割可见的声音对象。</li>
<li>methods: 该论文提出了一种双向生成框架，通过建立视觉特征和声音相关性的强有力关系，提高AVS的性能。具体来说，该框架包括视觉到声音投影部分，使用物理投影重建声音特征，以及采用隐藏式三维运动估计模块来处理时间 Dinamics。</li>
<li>results: 经过对AVSBenchbenchmark进行了广泛的实验和分析，该方法在多个声音源的分割任务中达到了新的状态对AVS的性能水平，尤其是在MS3子集中，该子集包括多个声音源的分割任务。<details>
<summary>Abstract</summary>
The aim of audio-visual segmentation (AVS) is to precisely differentiate audible objects within videos down to the pixel level. Traditional approaches often tackle this challenge by combining information from various modalities, where the contribution of each modality is implicitly or explicitly modeled. Nevertheless, the interconnections between different modalities tend to be overlooked in audio-visual modeling. In this paper, inspired by the human ability to mentally simulate the sound of an object and its visual appearance, we introduce a bidirectional generation framework. This framework establishes robust correlations between an object's visual characteristics and its associated sound, thereby enhancing the performance of AVS. To achieve this, we employ a visual-to-audio projection component that reconstructs audio features from object segmentation masks and minimizes reconstruction errors. Moreover, recognizing that many sounds are linked to object movements, we introduce an implicit volumetric motion estimation module to handle temporal dynamics that may be challenging to capture using conventional optical flow methods. To showcase the effectiveness of our approach, we conduct comprehensive experiments and analyses on the widely recognized AVSBench benchmark. As a result, we establish a new state-of-the-art performance level in the AVS benchmark, particularly excelling in the challenging MS3 subset which involves segmenting multiple sound sources. To facilitate reproducibility, we plan to release both the source code and the pre-trained model.
</details>
<details>
<summary>摘要</summary>
Inspired by the human ability to mentally simulate the sound of an object and its visual appearance, we propose a bidirectional generation framework. This framework establishes robust correlations between an object's visual characteristics and its associated sound, thereby enhancing the performance of AVS.To achieve this, we employ a visual-to-audio projection component that reconstructs audio features from object segmentation masks and minimizes reconstruction errors. Additionally, recognizing that many sounds are linked to object movements, we introduce an implicit volumetric motion estimation module to handle temporal dynamics that may be challenging to capture using conventional optical flow methods.To demonstrate the effectiveness of our approach, we conduct comprehensive experiments and analyses on the widely recognized AVSBench benchmark. As a result, we establish a new state-of-the-art performance level in the AVS benchmark, particularly excelling in the challenging MS3 subset which involves segmenting multiple sound sources. To facilitate reproducibility, we plan to release both the source code and the pre-trained model.
</details></li>
</ul>
<hr>
<h2 id="CARE-A-Large-Scale-CT-Image-Dataset-and-Clinical-Applicable-Benchmark-Model-for-Rectal-Cancer-Segmentation"><a href="#CARE-A-Large-Scale-CT-Image-Dataset-and-Clinical-Applicable-Benchmark-Model-for-Rectal-Cancer-Segmentation" class="headerlink" title="CARE: A Large Scale CT Image Dataset and Clinical Applicable Benchmark Model for Rectal Cancer Segmentation"></a>CARE: A Large Scale CT Image Dataset and Clinical Applicable Benchmark Model for Rectal Cancer Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08283">http://arxiv.org/abs/2308.08283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hantao Zhang, Weidong Guo, Chenyang Qiu, Shouhong Wan, Bingbing Zou, Wanqin Wang, Peiquan Jin</li>
<li>for: Rectal cancer segmentation of CT images for timely clinical diagnosis, radiotherapy treatment, and follow-up.</li>
<li>methods: Proposed a novel large-scale rectal cancer CT image dataset CARE with pixel-level annotations, and a novel medical cancer lesion segmentation benchmark model named U-SAM that incorporates prompt information to tackle the challenges of intricate anatomical structures.</li>
<li>results: U-SAM outperformed state-of-the-art methods on the CARE dataset and demonstrated generalization on the WORD dataset through extensive experiments. These results can serve as a baseline for future research and clinical application development.Here’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope this helps!<details>
<summary>Abstract</summary>
Rectal cancer segmentation of CT image plays a crucial role in timely clinical diagnosis, radiotherapy treatment, and follow-up. Although current segmentation methods have shown promise in delineating cancerous tissues, they still encounter challenges in achieving high segmentation precision. These obstacles arise from the intricate anatomical structures of the rectum and the difficulties in performing differential diagnosis of rectal cancer. Additionally, a major obstacle is the lack of a large-scale, finely annotated CT image dataset for rectal cancer segmentation. To address these issues, this work introduces a novel large scale rectal cancer CT image dataset CARE with pixel-level annotations for both normal and cancerous rectum, which serves as a valuable resource for algorithm research and clinical application development. Moreover, we propose a novel medical cancer lesion segmentation benchmark model named U-SAM. The model is specifically designed to tackle the challenges posed by the intricate anatomical structures of abdominal organs by incorporating prompt information. U-SAM contains three key components: promptable information (e.g., points) to aid in target area localization, a convolution module for capturing low-level lesion details, and skip-connections to preserve and recover spatial information during the encoding-decoding process. To evaluate the effectiveness of U-SAM, we systematically compare its performance with several popular segmentation methods on the CARE dataset. The generalization of the model is further verified on the WORD dataset. Extensive experiments demonstrate that the proposed U-SAM outperforms state-of-the-art methods on these two datasets. These experiments can serve as the baseline for future research and clinical application development.
</details>
<details>
<summary>摘要</summary>
<<SYS>> Rectal cancer segmentation of CT image 在临床诊断、放疗治疗和跟踪中扮演着关键角色。although current segmentation methods have shown promise in delineating cancerous tissues, they still encounter challenges in achieving high segmentation precision. These obstacles arise from the intricate anatomical structures of the rectum and the difficulties in performing differential diagnosis of rectal cancer. Additionally, a major obstacle is the lack of a large-scale, finely annotated CT image dataset for rectal cancer segmentation. To address these issues, this work introduces a novel large-scale rectal cancer CT image dataset CARE with pixel-level annotations for both normal and cancerous rectum, which serves as a valuable resource for algorithm research and clinical application development. Moreover, we propose a novel medical cancer lesion segmentation benchmark model named U-SAM. The model is specifically designed to tackle the challenges posed by the intricate anatomical structures of abdominal organs by incorporating prompt information. U-SAM contains three key components: promptable information (e.g., points) to aid in target area localization, a convolution module for capturing low-level lesion details, and skip-connections to preserve and recover spatial information during the encoding-decoding process. To evaluate the effectiveness of U-SAM, we systematically compare its performance with several popular segmentation methods on the CARE dataset. The generalization of the model is further verified on the WORD dataset. Extensive experiments demonstrate that the proposed U-SAM outperforms state-of-the-art methods on these two datasets. These experiments can serve as the baseline for future research and clinical application development.Here's the translation in Traditional Chinese:<<SYS>>RECTAL cancer segmentation of CT image 在临床诊断、放疗治疗和跟踪中扮演着关键角色。although current segmentation methods have shown promise in delineating cancerous tissues, they still encounter challenges in achieving high segmentation precision. These obstacles arise from the intricate anatomical structures of the rectum and the difficulties in performing differential diagnosis of rectal cancer. Additionally, a major obstacle is the lack of a large-scale, finely annotated CT image dataset for rectal cancer segmentation. To address these issues, this work introduces a novel large-scale rectal cancer CT image dataset CARE with pixel-level annotations for both normal and cancerous rectum, which serves as a valuable resource for algorithm research and clinical application development. Moreover, we propose a novel medical cancer lesion segmentation benchmark model named U-SAM. The model is specifically designed to tackle the challenges posed by the intricate anatomical structures of abdominal organs by incorporating prompt information. U-SAM contains three key components: promptable information (e.g., points) to aid in target area localization, a convolution module for capturing low-level lesion details, and skip-connections to preserve and recover spatial information during the encoding-decoding process. To evaluate the effectiveness of U-SAM, we systematically compare its performance with several popular segmentation methods on the CARE dataset. The generalization of the model is further verified on the WORD dataset. Extensive experiments demonstrate that the proposed U-SAM outperforms state-of-the-art methods on these two datasets. These experiments can serve as the baseline for future research and clinical application development.
</details></li>
</ul>
<hr>
<h2 id="Computer-vision-enriched-discrete-choice-models-with-an-application-to-residential-location-choice"><a href="#Computer-vision-enriched-discrete-choice-models-with-an-application-to-residential-location-choice" class="headerlink" title="Computer vision-enriched discrete choice models, with an application to residential location choice"></a>Computer vision-enriched discrete choice models, with an application to residential location choice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08276">http://arxiv.org/abs/2308.08276</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sander van Cranenburgh, Francisco Garrido-Valenzuela</li>
<li>for: This paper aims to address the gap between traditional discrete choice models and real-world decision-making by incorporating computer vision into these models.</li>
<li>methods: The proposed “Computer Vision-enriched Discrete Choice Models” (CV-DCMs) integrate computer vision and traditional discrete choice models to handle choice tasks involving numeric attributes and images.</li>
<li>results: The proposed CV-DCMs are grounded in random utility maximization principles and demonstrate the potential to handle complex decision-making tasks involving visual imagery, as demonstrated through a novel stated choice experiment involving residential location choices.<details>
<summary>Abstract</summary>
Visual imagery is indispensable to many multi-attribute decision situations. Examples of such decision situations in travel behaviour research include residential location choices, vehicle choices, tourist destination choices, and various safety-related choices. However, current discrete choice models cannot handle image data and thus cannot incorporate information embedded in images into their representations of choice behaviour. This gap between discrete choice models' capabilities and the real-world behaviour it seeks to model leads to incomplete and, possibly, misleading outcomes. To solve this gap, this study proposes "Computer Vision-enriched Discrete Choice Models" (CV-DCMs). CV-DCMs can handle choice tasks involving numeric attributes and images by integrating computer vision and traditional discrete choice models. Moreover, because CV-DCMs are grounded in random utility maximisation principles, they maintain the solid behavioural foundation of traditional discrete choice models. We demonstrate the proposed CV-DCM by applying it to data obtained through a novel stated choice experiment involving residential location choices. In this experiment, respondents faced choice tasks with trade-offs between commute time, monthly housing cost and street-level conditions, presented using images. As such, this research contributes to the growing body of literature in the travel behaviour field that seeks to integrate discrete choice modelling and machine learning.
</details>
<details>
<summary>摘要</summary>
“图像感知是许多多属性决策情况中不可或缺的。旅游行为研究中的例子包括居住地选择、车辆选择、旅游目的地选择以及安全相关的选择。然而，现有的精确选择模型无法处理图像数据，因此无法将图像中嵌入的信息 integrate 到其表示的选择行为中。这个差距导致模型的结果不准确、可能是误导的。为解决这个差距，本研究提出了“计算机视觉增强精确选择模型”（CV-DCM）。CV-DCM 可以处理包含数字属性和图像的选择任务，通过结合计算机视觉和传统精确选择模型来实现。此外，由于 CV-DCM 基于 random utility maximization 原则，因此它保持了传统精确选择模型的坚实行为基础。我们通过应用 CV-DCM 到来自一种新的声明选择实验中的居住地选择任务来示例。在这个实验中，参与者面临了含有交通时间、月度住房成本和街道级别条件的选择任务，使用图像表示。因此，本研究贡献到旅游行为领域的精确选择模型和机器学习 интеграция的增长的Literature中。”
</details></li>
</ul>
<hr>
<h2 id="Detecting-Olives-with-Synthetic-or-Real-Data-Olive-the-Above"><a href="#Detecting-Olives-with-Synthetic-or-Real-Data-Olive-the-Above" class="headerlink" title="Detecting Olives with Synthetic or Real Data? Olive the Above"></a>Detecting Olives with Synthetic or Real Data? Olive the Above</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08271">http://arxiv.org/abs/2308.08271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yianni Karabatis, Xiaomin Lin, Nitin J. Sanket, Michail G. Lagoudakis, Yiannis Aloimonos</li>
<li>for: 这个论文的目的是为了提高精准农业中的橄榄估算，但在橄榄业中，高度变化的橄榄颜色和背景叶子投影的问题却存在挑战。</li>
<li>methods: 这篇论文提出了一种新的橄榄检测方法，不需要手动标注数据。它首先生成了一个自动标注的摘要真实3D橄榄树模型，然后简化其geometry для实时渲染目的。</li>
<li>results: 实验表明，使用大量的synthetic数据和一小部分的真实数据可以提高橄榄检测精度，比使用只有一小部分的真实数据更好。<details>
<summary>Abstract</summary>
Modern robotics has enabled the advancement in yield estimation for precision agriculture. However, when applied to the olive industry, the high variation of olive colors and their similarity to the background leaf canopy presents a challenge. Labeling several thousands of very dense olive grove images for segmentation is a labor-intensive task. This paper presents a novel approach to detecting olives without the need to manually label data. In this work, we present the world's first olive detection dataset comprised of synthetic and real olive tree images. This is accomplished by generating an auto-labeled photorealistic 3D model of an olive tree. Its geometry is then simplified for lightweight rendering purposes. In addition, experiments are conducted with a mix of synthetically generated and real images, yielding an improvement of up to 66% compared to when only using a small sample of real data. When access to real, human-labeled data is limited, a combination of mostly synthetic data and a small amount of real data can enhance olive detection.
</details>
<details>
<summary>摘要</summary>
现代机器人技术已经推动了精准农业的收益估计。然而，当应用于橄榄业时，高度的橄榄颜色变化和它们与背景叶子覆盖物的相似性带来了挑战。为了进行 segmentation，标注数以千计的橄榄园景图像是一项劳动密集的任务。本文介绍了一种新的橄榄检测方法，不需要手动标注数据。在这种方法中，我们首次创建了一个自动标注的真实3D橄榄树模型。其几何结构后来简化了为轻量级渲染目的。此外，我们在真实和 sintetically生成的图像混合下进行了实验，并达到了使用小量真实数据时的66%提高。在有限的真实人类标注数据时，一种主要是 sintetically生成的数据和一小部分的真实数据的组合可以提高橄榄检测。
</details></li>
</ul>
<hr>
<h2 id="OnUVS-Online-Feature-Decoupling-Framework-for-High-Fidelity-Ultrasound-Video-Synthesis"><a href="#OnUVS-Online-Feature-Decoupling-Framework-for-High-Fidelity-Ultrasound-Video-Synthesis" class="headerlink" title="OnUVS: Online Feature Decoupling Framework for High-Fidelity Ultrasound Video Synthesis"></a>OnUVS: Online Feature Decoupling Framework for High-Fidelity Ultrasound Video Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08269">http://arxiv.org/abs/2308.08269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Zhou, Dong Ni, Ao Chang, Xinrui Zhou, Rusi Chen, Yanlin Chen, Lian Liu, Jiamin Liang, Yuhao Huang, Tong Han, Zhe Liu, Deng-Ping Fan, Xin Yang<br>for:* The paper aims to address the challenges of synthesizing high-fidelity ultrasound (US) videos for clinical diagnosis, particularly in the context of limited availability of specific US video cases.methods:* The proposed method is an online feature-decoupling framework called OnUVS, which incorporates anatomic information into keypoint learning, uses a dual-decoder to decouple content and textural features, and employs a multiple-feature discriminator to enhance sharpness and fine details.results:* The paper reports that OnUVS synthesizes US videos with high fidelity, as demonstrated through validation and user studies on in-house echocardiographic and pelvic floor US videos.<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is indispensable in clinical practice. To diagnose certain diseases, sonographers must observe corresponding dynamic anatomic structures to gather comprehensive information. However, the limited availability of specific US video cases causes teaching difficulties in identifying corresponding diseases, which potentially impacts the detection rate of such cases. The synthesis of US videos may represent a promising solution to this issue. Nevertheless, it is challenging to accurately animate the intricate motion of dynamic anatomic structures while preserving image fidelity. To address this, we present a novel online feature-decoupling framework called OnUVS for high-fidelity US video synthesis. Our highlights can be summarized by four aspects. First, we introduced anatomic information into keypoint learning through a weakly-supervised training strategy, resulting in improved preservation of anatomical integrity and motion while minimizing the labeling burden. Second, to better preserve the integrity and textural information of US images, we implemented a dual-decoder that decouples the content and textural features in the generator. Third, we adopted a multiple-feature discriminator to extract a comprehensive range of visual cues, thereby enhancing the sharpness and fine details of the generated videos. Fourth, we constrained the motion trajectories of keypoints during online learning to enhance the fluidity of generated videos. Our validation and user studies on in-house echocardiographic and pelvic floor US videos showed that OnUVS synthesizes US videos with high fidelity.
</details>
<details>
<summary>摘要</summary>
Ultrasound (US) 影像是诊断的不可或缺的工具。为了诊断某些疾病，sonoographers需要观察相应的动态 анатомиче结构，以获取全面的信息。然而，有限的特定US视频案例的可用性会导致教学困难，从而可能影响疾病的检测率。Synthesizing US videos may represent a promising solution to this issue. However, it is challenging to accurately animate the intricate motion of dynamic anatomic structures while preserving image fidelity. To address this, we present a novel online feature-decoupling framework called OnUVS for high-fidelity US video synthesis. Our highlights can be summarized by four aspects. First, we introduced anatomic information into keypoint learning through a weakly-supervised training strategy, resulting in improved preservation of anatomical integrity and motion while minimizing the labeling burden. Second, to better preserve the integrity and textural information of US images, we implemented a dual-decoder that decouples the content and textural features in the generator. Third, we adopted a multiple-feature discriminator to extract a comprehensive range of visual cues, thereby enhancing the sharpness and fine details of the generated videos. Fourth, we constrained the motion trajectories of keypoints during online learning to enhance the fluidity of generated videos. Our validation and user studies on in-house echocardiographic and pelvic floor US videos showed that OnUVS synthesizes US videos with high fidelity.
</details></li>
</ul>
<hr>
<h2 id="SceNeRFlow-Time-Consistent-Reconstruction-of-General-Dynamic-Scenes"><a href="#SceNeRFlow-Time-Consistent-Reconstruction-of-General-Dynamic-Scenes" class="headerlink" title="SceNeRFlow: Time-Consistent Reconstruction of General Dynamic Scenes"></a>SceNeRFlow: Time-Consistent Reconstruction of General Dynamic Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08258">http://arxiv.org/abs/2308.08258</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edith Tretschk, Vladislav Golyanik, Michael Zollhoefer, Aljaz Bozic, Christoph Lassner, Christian Theobalt</li>
<li>For: 本研究旨在实现一种可靠地重建通常、不固定的物体运动的4D重建方法，以便进行后续任务 like 3D 编辑、运动分析或虚拟资产创建。* Methods: 我们提出了一种名为 SceNeRFlow 的动态 NeRF 方法，它使用多视图RGB视频和静止相机图像作为输入，并在线进行重建。该方法首先估算了场景中的准确模型，然后使用时间一致的方式来重建物体的变形和外观。由于这个准确模型是时间不变的，因此我们可以在长时间和长距离内获得对应关系。我们使用神经场景表示来参数化我们的方法的组件。* Results: 我们实验表明，与之前的工作不同，我们的方法可以重建 studio 级别的运动。这是因为我们使用了一种强制 regularization 的粗糙分解方法，以处理更大的运动。我们还证明了我们的方法可以在不同的场景下进行高效的重建。<details>
<summary>Abstract</summary>
Existing methods for the 4D reconstruction of general, non-rigidly deforming objects focus on novel-view synthesis and neglect correspondences. However, time consistency enables advanced downstream tasks like 3D editing, motion analysis, or virtual-asset creation. We propose SceNeRFlow to reconstruct a general, non-rigid scene in a time-consistent manner. Our dynamic-NeRF method takes multi-view RGB videos and background images from static cameras with known camera parameters as input. It then reconstructs the deformations of an estimated canonical model of the geometry and appearance in an online fashion. Since this canonical model is time-invariant, we obtain correspondences even for long-term, long-range motions. We employ neural scene representations to parametrize the components of our method. Like prior dynamic-NeRF methods, we use a backwards deformation model. We find non-trivial adaptations of this model necessary to handle larger motions: We decompose the deformations into a strongly regularized coarse component and a weakly regularized fine component, where the coarse component also extends the deformation field into the space surrounding the object, which enables tracking over time. We show experimentally that, unlike prior work that only handles small motion, our method enables the reconstruction of studio-scale motions.
</details>
<details>
<summary>摘要</summary>
现有方法 для四维重建普通、非rigidly变形对象强调新视图合成和忽略匹配。然而，时间一致性允许进行高级下游任务，如3D编辑、运动分析或虚拟资产创建。我们提出SceNeRFlow方法，用于在时间一致的方式重建普通、非rigid场景。我们的动态NeRF方法从多视图RGB视频和静止相机知道参数的背景图像入手。然后，它在线上重建了测量的准确模型的geometry和外观的变形。由于这个准确模型是时间不变的，我们在长期、长距离运动中获得匹配。我们使用神经场景表示来参数化我们的方法的组件。与先前的动态NeRF方法类似，我们使用回溯变形模型。但是，我们发现对于更大的运动，需要非常重要的适应。我们将变形分解为一个强制regularized的粗糙分量和一个弱regularized的细分量，其中粗糙分量还扩展了变形场景到对象周围的空间，这使得可以在时间上跟踪。我们实验表明，与先前工作仅处理小运动不同，我们的方法可以重建 studio级别的运动。
</details></li>
</ul>
<hr>
<h2 id="MultiMediate’23-Engagement-Estimation-and-Bodily-Behaviour-Recognition-in-Social-Interactions"><a href="#MultiMediate’23-Engagement-Estimation-and-Bodily-Behaviour-Recognition-in-Social-Interactions" class="headerlink" title="MultiMediate’23: Engagement Estimation and Bodily Behaviour Recognition in Social Interactions"></a>MultiMediate’23: Engagement Estimation and Bodily Behaviour Recognition in Social Interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08256">http://arxiv.org/abs/2308.08256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Müller, Michal Balazia, Tobias Baur, Michael Dietz, Alexander Heimerl, Dominik Schiller, Mohammed Guermal, Dominike Thomas, François Brémond, Jan Alexandersson, Elisabeth André, Andreas Bulling</li>
<li>for: 这篇论文目的是为了研究人类社交行为的自动分析，以创建更有效的人机交互机器人。</li>
<li>methods: 这篇论文使用了 MultiMediate’23 挑战中的两个关键人类社交行为分析任务：参与度估计和身体行为识别。它们使用了 NOXI 数据库中的新注释，以及 MPIIGroupInteraction 数据库中的 BBSI 注释方案。</li>
<li>results: 这篇论文提供了 MultiMediate’23 挑战中的基准结果。<details>
<summary>Abstract</summary>
Automatic analysis of human behaviour is a fundamental prerequisite for the creation of machines that can effectively interact with- and support humans in social interactions. In MultiMediate'23, we address two key human social behaviour analysis tasks for the first time in a controlled challenge: engagement estimation and bodily behaviour recognition in social interactions. This paper describes the MultiMediate'23 challenge and presents novel sets of annotations for both tasks. For engagement estimation we collected novel annotations on the NOvice eXpert Interaction (NOXI) database. For bodily behaviour recognition, we annotated test recordings of the MPIIGroupInteraction corpus with the BBSI annotation scheme. In addition, we present baseline results for both challenge tasks.
</details>
<details>
<summary>摘要</summary>
自动分析人类行为是人工智能创造人工智能交互的基本先提要。在MultiMediate'23中，我们对人际交互中的两个关键人类社交行为进行了首次控制挑战：参与度估计和社交互动中的身体行为识别。这篇文章描述了MultiMediate'23挑战，并提供了两个任务的新的注解集。对于参与度估计任务，我们在NOvice eXpert Interaction（NOXI）数据库上收集了新的注解。对于身体行为识别任务，我们在MPIIGroupInteraction corpus上使用了BBSI注解方案进行了注解。此外，我们还提供了两个挑战任务的基线结果。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Lane-Detection-via-Cross-Similarity"><a href="#Contrastive-Learning-for-Lane-Detection-via-Cross-Similarity" class="headerlink" title="Contrastive Learning for Lane Detection via Cross-Similarity"></a>Contrastive Learning for Lane Detection via Cross-Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08242">http://arxiv.org/abs/2308.08242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Zoljodi, Sadegh Abadijou, Mina Alibeigi, Masoud Daneshtalab</li>
<li>for: 提高路径检测的可靠性，特别是在低可见性情况下，如阴影、天气、车辆、行人等因素所带来的挑战。</li>
<li>methods: 我们提出了一种自监学习方法，即对比学习（Contrastive Learning，CL），它通过将本地特征对照学习（Local Feature CL）与我们新提出的跨相似运算（Cross-similarity）结合，实现了对路径检测模型的提升。</li>
<li>results: 在评估数据集上，我们的CLLD方法比过去的对比学习方法更高效，特别是在低可见性情况下，如阴影和人行道等。 与超级学习相比，CLLD在阴影和人行道等Scene中表现更好。<details>
<summary>Abstract</summary>
Detecting road lanes is challenging due to intricate markings vulnerable to unfavorable conditions. Lane markings have strong shape priors, but their visibility is easily compromised. Factors like lighting, weather, vehicles, pedestrians, and aging colors challenge the detection. A large amount of data is required to train a lane detection approach that can withstand natural variations caused by low visibility. This is because there are numerous lane shapes and natural variations that exist. Our solution, Contrastive Learning for Lane Detection via cross-similarity (CLLD), is a self-supervised learning method that tackles this challenge by enhancing lane detection models resilience to real-world conditions that cause lane low visibility. CLLD is a novel multitask contrastive learning that trains lane detection approaches to detect lane markings even in low visible situations by integrating local feature contrastive learning (CL) with our new proposed operation cross-similarity. Local feature CL focuses on extracting features for small image parts, which is necessary to localize lane segments, while cross-similarity captures global features to detect obscured lane segments using their surrounding. We enhance cross-similarity by randomly masking parts of input images for augmentation. Evaluated on benchmark datasets, CLLD outperforms state-of-the-art contrastive learning, especially in visibility-impairing conditions like shadows. Compared to supervised learning, CLLD excels in scenarios like shadows and crowded scenes.
</details>
<details>
<summary>摘要</summary>
探析道路车道是一项挑战，因为车道标记有许多细节和敏感度。车道标记具有强的形状偏好，但它们的可见性易受到不利的影响。因为光线、天气、车辆、人行道和腐蚀等因素，车道标记的可见性容易受到损害。为了训练一个可以抗性低视觉的车道探析方法，需要大量的数据。这是因为车道形状和自然变化存在很多。我们的解决方案是通过对比学习（Contrastive Learning）提高车道探析模型对低视觉情况的抗性。我们提出了一种新的多任务对比学习方法，称为跨相似性（cross-similarity）。本方法将本地特征对比学习（CL）与我们新提出的跨相似性操作结合，以增强车道探析模型对低视觉情况的抗性。本地特征CL专注于从小图像部分提取特征，这是必要的以确定车道段的地方，而跨相似性则捕捉全图像的全局特征，以检测遮盖的车道段。我们在输入图像中随机遮盖部分进行了增强。在标准测试集上评估，CLLD在视觉降低情况下（如阴影）表现出色，与前学习方法相比，它在阴影和人行道场景中表现更出色。相比于监督学习，CLLD在这些场景中表现更好。
</details></li>
</ul>
<hr>
<h2 id="DDF-HO-Hand-Held-Object-Reconstruction-via-Conditional-Directed-Distance-Field"><a href="#DDF-HO-Hand-Held-Object-Reconstruction-via-Conditional-Directed-Distance-Field" class="headerlink" title="DDF-HO: Hand-Held Object Reconstruction via Conditional Directed Distance Field"></a>DDF-HO: Hand-Held Object Reconstruction via Conditional Directed Distance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08231">http://arxiv.org/abs/2308.08231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyangguang Zhang, Yan Di, Ruida Zhang, Guangyao Zhai, Fabian Manhardt, Federico Tombari, Xiangyang Ji</li>
<li>for: 重建手持物品的RGB图像是一个重要和挑战性的问题，现有的SDF方法存在局限性，无法同时捕捉手物交互的复杂性。</li>
<li>methods: 我们提出了DDF-HO方法，利用指向距离场（DDF）作为形式表示。与SDF不同的是，DDF将一个三维空间中的射线映射到相应的DDF值，包括一个二进制可见信号，判断射线是否与目标物体交叉，以及一个距离值，测量射线与目标之间的距离。</li>
<li>results: 我们在 sintetic和实际 datasets上进行了广泛的实验，结果表明DDF-HO方法在Chamfer Distance上比基eline方法大大提高，约80%的提升。代码和训练模型将很 soon released。<details>
<summary>Abstract</summary>
Reconstructing hand-held objects from a single RGB image is an important and challenging problem. Existing works utilizing Signed Distance Fields (SDF) reveal limitations in comprehensively capturing the complex hand-object interactions, since SDF is only reliable within the proximity of the target, and hence, infeasible to simultaneously encode local hand and object cues. To address this issue, we propose DDF-HO, a novel approach leveraging Directed Distance Field (DDF) as the shape representation. Unlike SDF, DDF maps a ray in 3D space, consisting of an origin and a direction, to corresponding DDF values, including a binary visibility signal determining whether the ray intersects the objects and a distance value measuring the distance from origin to target in the given direction. We randomly sample multiple rays and collect local to global geometric features for them by introducing a novel 2D ray-based feature aggregation scheme and a 3D intersection-aware hand pose embedding, combining 2D-3D features to model hand-object interactions. Extensive experiments on synthetic and real-world datasets demonstrate that DDF-HO consistently outperforms all baseline methods by a large margin, especially under Chamfer Distance, with about 80% leap forward. Codes and trained models will be released soon.
</details>
<details>
<summary>摘要</summary>
原文：重建手持物品从单一RGB图像是一项重要和挑战性的问题。现有的works使用Signed Distance Fields (SDF)表明这些工作存在问题，因为SDF只有在目标附近才可靠，因此不能同时编码当地手和物品指示。为解决这个问题，我们提出了DDF-HO方法，该方法利用Directed Distance Field (DDF)作为形状表示。与SDF不同，DDF将三个维度空间中的一条射线映射到对应的DDF值，包括一个二进制可见信号，该信号判断射线是否与物体 intersect，以及一个距离值，该值测量射线起点与目标之间的距离。我们随机选择多个射线，并收集它们的本地到全局的地理特征，使用一种新的2D射线基于的特征聚合方案和一种3D交叉相关手姿嵌入，将2D-3D特征相结合，以模拟手-物体交互。我们对 sintetic和实际数据集进行了广泛的实验，结果显示，DDF-HO方法在Chamfer Distance上比基eline方法高出约80%，这 represent a large advance.代码和训练模型即将释出。
</details></li>
</ul>
<hr>
<h2 id="Inherent-Redundancy-in-Spiking-Neural-Networks"><a href="#Inherent-Redundancy-in-Spiking-Neural-Networks" class="headerlink" title="Inherent Redundancy in Spiking Neural Networks"></a>Inherent Redundancy in Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08227">http://arxiv.org/abs/2308.08227</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/biclab/asa-snn">https://github.com/biclab/asa-snn</a></li>
<li>paper_authors: Man Yao, Jiakui Hu, Guangshe Zhao, Yaoyuan Wang, Ziyang Zhang, Bo Xu, Guoqi Li</li>
<li>for: 这个论文主要是为了研究锐极神经网络（SNN）中的内在重复性，以提高神经网络的准确率和能效性。</li>
<li>methods: 这篇论文使用了一种称为 Advance Spatial Attention（ASA）模块，来利用SNN中的内在重复性，并可以有效地控制噪声脉冲。</li>
<li>results: 实验结果表明，提案的方法可以显著降低脉冲发生的情况，并在比对状态的artificial neural networks（ANN）基eline上达到更好的性能。<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) are well known as a promising energy-efficient alternative to conventional artificial neural networks. Subject to the preconceived impression that SNNs are sparse firing, the analysis and optimization of inherent redundancy in SNNs have been largely overlooked, thus the potential advantages of spike-based neuromorphic computing in accuracy and energy efficiency are interfered. In this work, we pose and focus on three key questions regarding the inherent redundancy in SNNs. We argue that the redundancy is induced by the spatio-temporal invariance of SNNs, which enhances the efficiency of parameter utilization but also invites lots of noise spikes. Further, we analyze the effect of spatio-temporal invariance on the spatio-temporal dynamics and spike firing of SNNs. Then, motivated by these analyses, we propose an Advance Spatial Attention (ASA) module to harness SNNs' redundancy, which can adaptively optimize their membrane potential distribution by a pair of individual spatial attention sub-modules. In this way, noise spike features are accurately regulated. Experimental results demonstrate that the proposed method can significantly drop the spike firing with better performance than state-of-the-art SNN baselines. Our code is available in \url{https://github.com/BICLab/ASA-SNN}.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）因其能够减少能耗而被广泛认为是一种有前途的人工神经网络。然而，由于人们对SNN的减少性假设，因此对SNN内部缺乏缓存的分析和优化而忽略了大量的可能优势。在这项工作中，我们提出了三个关键问题，即SNN中的内在缺乏的来源，这种缺乏的源泉是SNN的空间时间不变性所带来的，这种不变性可以提高参数的使用效率，但也会引入很多噪声脉冲。然后，我们分析了SNN的空间时间动态和脉冲发生的影响。基于这些分析，我们提出了一种进步的空间注意力（ASA）模块，可以自适应地优化SNN的膜电压分布，并且可以精准地控制噪声脉冲特征。实验结果表明，我们的方法可以减少脉冲发生，并且比现有的SNN基线性能更好。我们的代码可以在<https://github.com/BICLab/ASA-SNN>中找到。
</details></li>
</ul>
<hr>
<h2 id="How-To-Overcome-Confirmation-Bias-in-Semi-Supervised-Image-Classification-By-Active-Learning"><a href="#How-To-Overcome-Confirmation-Bias-in-Semi-Supervised-Image-Classification-By-Active-Learning" class="headerlink" title="How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning"></a>How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08224">http://arxiv.org/abs/2308.08224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandra Gilhuber, Rasmus Hvingelby, Mang Ling Ada Fok, Thomas Seidl</li>
<li>for: 本研究旨在探讨是否需要活动学习，即使具有强大深度半超vised方法，也可能无法在有限的标注数据设置中使用。</li>
<li>methods: 本研究使用了 semi-supervised learning（SSL）方法，并与随机选择标注相结合。</li>
<li>results:  experiments表明，在实际数据场景中， combining SSL methods with a random selection for labeling可以超越现有的活动学习（AL）技术。<details>
<summary>Abstract</summary>
Do we need active learning? The rise of strong deep semi-supervised methods raises doubt about the usability of active learning in limited labeled data settings. This is caused by results showing that combining semi-supervised learning (SSL) methods with a random selection for labeling can outperform existing active learning (AL) techniques. However, these results are obtained from experiments on well-established benchmark datasets that can overestimate the external validity. However, the literature lacks sufficient research on the performance of active semi-supervised learning methods in realistic data scenarios, leaving a notable gap in our understanding. Therefore we present three data challenges common in real-world applications: between-class imbalance, within-class imbalance, and between-class similarity. These challenges can hurt SSL performance due to confirmation bias. We conduct experiments with SSL and AL on simulated data challenges and find that random sampling does not mitigate confirmation bias and, in some cases, leads to worse performance than supervised learning. In contrast, we demonstrate that AL can overcome confirmation bias in SSL in these realistic settings. Our results provide insights into the potential of combining active and semi-supervised learning in the presence of common real-world challenges, which is a promising direction for robust methods when learning with limited labeled data in real-world applications.
</details>
<details>
<summary>摘要</summary>
是否需要活动学习？强大深度半supervised方法的出现，使得有限量标注数据设置下使用活动学习的可用性受到了质疑。这是由于结果表明，结合半supervised学习（SSL）方法和随机选择标注可以超越现有的活动学习（AL）技术。然而，这些结果是基于已知的benchmark数据集进行实验获得的，这些数据集可能过度估计外部有效性。然而，文献中对活动半supervised学习方法在实际数据场景中的性能的研究不够，留下了一个 Notable gap 在我们的理解中。因此，我们介绍了三种常见的实际数据挑战：between-class imbalance、within-class imbalance 和 between-class similarity。这些挑战可能会对SSL性能产生负面影响，因为confirmation bias。我们在SSL和AL中进行了实验，发现随机抽样不能消除confirmation bias，在某些情况下，随机抽样even worse than supervised learning。然而，我们示出了AL可以在这些实际设置中超越confirmation bias。我们的结果为将活动和半supervised学习结合在一起的潜在可能性提供了新的思路，这是一种在实际应用中学习受限量标注数据时的robust方法。
</details></li>
</ul>
<hr>
<h2 id="Low-Light-Image-Enhancement-with-Illumination-Aware-Gamma-Correction-and-Complete-Image-Modelling-Network"><a href="#Low-Light-Image-Enhancement-with-Illumination-Aware-Gamma-Correction-and-Complete-Image-Modelling-Network" class="headerlink" title="Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network"></a>Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08220">http://arxiv.org/abs/2308.08220</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinglong Wang, Zhen Liu, Jianzhuang Liu, Songcen Xu, Shuaicheng Liu</li>
<li>for: 解决低光照图像增强问题</li>
<li>methods:  integrate gamma correction with deep networks, use Taylor Series to approximate gamma correction, use a novel Transformer block to simulate pixel dependencies</li>
<li>results: outperform state-of-the-art methods on several benchmark datasets<details>
<summary>Abstract</summary>
This paper presents a novel network structure with illumination-aware gamma correction and complete image modelling to solve the low-light image enhancement problem. Low-light environments usually lead to less informative large-scale dark areas, directly learning deep representations from low-light images is insensitive to recovering normal illumination. We propose to integrate the effectiveness of gamma correction with the strong modelling capacities of deep networks, which enables the correction factor gamma to be learned in a coarse to elaborate manner via adaptively perceiving the deviated illumination. Because exponential operation introduces high computational complexity, we propose to use Taylor Series to approximate gamma correction, accelerating the training and inference speed. Dark areas usually occupy large scales in low-light images, common local modelling structures, e.g., CNN, SwinIR, are thus insufficient to recover accurate illumination across whole low-light images. We propose a novel Transformer block to completely simulate the dependencies of all pixels across images via a local-to-global hierarchical attention mechanism, so that dark areas could be inferred by borrowing the information from far informative regions in a highly effective manner. Extensive experiments on several benchmark datasets demonstrate that our approach outperforms state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Common local modeling structures, such as CNN and SwinIR, are insufficient to recover accurate illumination across whole low-light images, as dark areas often occupy large scales. To address this, the proposed method uses a novel Transformer block that completes simulates the dependencies of all pixels across images via a local-to-global hierarchical attention mechanism. This allows dark areas to be inferred by borrowing information from far informative regions in a highly effective manner.Experimental results on several benchmark datasets demonstrate that the proposed approach outperforms state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="MEDOE-A-Multi-Expert-Decoder-and-Output-Ensemble-Framework-for-Long-tailed-Semantic-Segmentation"><a href="#MEDOE-A-Multi-Expert-Decoder-and-Output-Ensemble-Framework-for-Long-tailed-Semantic-Segmentation" class="headerlink" title="MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for Long-tailed Semantic Segmentation"></a>MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for Long-tailed Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08213">http://arxiv.org/abs/2308.08213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junao Shen, Long Chen, Kun Kuang, Fei Wu, Tian Feng, Wei Zhang</li>
<li>for: 解决长尾分布难以捕捉的问题，提高 semantic segmentation 的性能。</li>
<li>methods: 提出了一个名为 MEDOE 的新框架，通过Contextual Information Ensemble-and-Grouping 技术，使用多个专家来提高分类的准确性。</li>
<li>results: 实验结果表明，MEDOE 比现有方法在 Cityscapes 和 ADE20K 数据集上提高了1.78% 的 mIoU 和 5.89% 的 mAcc。<details>
<summary>Abstract</summary>
Long-tailed distribution of semantic categories, which has been often ignored in conventional methods, causes unsatisfactory performance in semantic segmentation on tail categories. In this paper, we focus on the problem of long-tailed semantic segmentation. Although some long-tailed recognition methods (e.g., re-sampling/re-weighting) have been proposed in other problems, they can probably compromise crucial contextual information and are thus hardly adaptable to the problem of long-tailed semantic segmentation. To address this issue, we propose MEDOE, a novel framework for long-tailed semantic segmentation via contextual information ensemble-and-grouping. The proposed two-sage framework comprises a multi-expert decoder (MED) and a multi-expert output ensemble (MOE). Specifically, the MED includes several "experts". Based on the pixel frequency distribution, each expert takes the dataset masked according to the specific categories as input and generates contextual information self-adaptively for classification; The MOE adopts learnable decision weights for the ensemble of the experts' outputs. As a model-agnostic framework, our MEDOE can be flexibly and efficiently coupled with various popular deep neural networks (e.g., DeepLabv3+, OCRNet, and PSPNet) to improve their performance in long-tailed semantic segmentation. Experimental results show that the proposed framework outperforms the current methods on both Cityscapes and ADE20K datasets by up to 1.78% in mIoU and 5.89% in mAcc.
</details>
<details>
<summary>摘要</summary>
长尾分布的 semantic category 问题，常被 conventional methods 忽略，导致 semantic segmentation 的性能不满意。在这篇论文中，我们关注了长尾 semantic segmentation 问题。尽管有一些长尾认知方法（例如重新批量/重新权重）在其他问题上提出，但它们可能会丢失重要的上下文信息，因此难以适应长尾 semantic segmentation 问题。为解决这个问题，我们提出了 MEDOE，一种基于上下文信息的集成和分组的novel框架。该框架包括一个多专家解码器（MED）和一个多专家输出集（MOE）。具体来说，MED 包括多个 "专家"。根据像素频率分布，每个专家都会根据特定类别为输入，在自适应的方式下生成上下文信息用于分类; MOE 采用可学习的决策权重，对专家们的输出进行集成。作为一个模型独立的框架，我们的 MEDOE 可以与各种流行的深度神经网络（例如 DeepLabv3+、OCRNet 和 PSPNet）模型结合，以提高它们在长尾 semantic segmentation 中的性能。实验结果表明，我们的提议方案在 Cityscapes 和 ADE20K 数据集上比现有方法提高了1.78%的 mIoU 和 5.89%的 mAcc。
</details></li>
</ul>
<hr>
<h2 id="Neural-Spherical-Harmonics-for-structurally-coherent-continuous-representation-of-diffusion-MRI-signal"><a href="#Neural-Spherical-Harmonics-for-structurally-coherent-continuous-representation-of-diffusion-MRI-signal" class="headerlink" title="Neural Spherical Harmonics for structurally coherent continuous representation of diffusion MRI signal"></a>Neural Spherical Harmonics for structurally coherent continuous representation of diffusion MRI signal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08210">http://arxiv.org/abs/2308.08210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Hendriks, Anna Vilanova, Maxime Chamberland</li>
<li>for: 这个论文旨在提出一种基于干扰Magnetic Resonance Imaging（dMRI）数据的新方法，该方法利用人脑结构几何的共同性，并且只使用单个测试者的数据。</li>
<li>methods: 该方法使用神经网络来参数化一个圆柱卷积函数（NeSH）来表示单个测试者的dMRI信号，该函数是连续的在angular和 espacial频域。</li>
<li>results: 使用这种方法重建dMRI信号后，得到的数据具有更加结构几何地表示， gradient 图像中的噪声被除去，fiber orientation distribution functions 显示了细胞轴的平滑变化。此外，该方法还可以计算mean diffusivity、fractional anisotropy和总显示的纤维密度。这些结果可以通过一个单一的模型架构和一个 hyperparameter 来实现。此外，在angular和 espacial频域进行upsampling也可以实现与现有方法相当或更好的重建结果。<details>
<summary>Abstract</summary>
We present a novel way to model diffusion magnetic resonance imaging (dMRI) datasets, that benefits from the structural coherence of the human brain while only using data from a single subject. Current methods model the dMRI signal in individual voxels, disregarding the intervoxel coherence that is present. We use a neural network to parameterize a spherical harmonics series (NeSH) to represent the dMRI signal of a single subject from the Human Connectome Project dataset, continuous in both the angular and spatial domain. The reconstructed dMRI signal using this method shows a more structurally coherent representation of the data. Noise in gradient images is removed and the fiber orientation distribution functions show a smooth change in direction along a fiber tract. We showcase how the reconstruction can be used to calculate mean diffusivity, fractional anisotropy, and total apparent fiber density. These results can be achieved with a single model architecture, tuning only one hyperparameter. In this paper we also demonstrate how upsampling in both the angular and spatial domain yields reconstructions that are on par or better than existing methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于模型吸引磁共振成像（dMRI）数据集，该方法利用人脑结构减少的一体性。现有方法在个voxel中模型dMRI信号，忽略了voxel之间的相关性。我们使用神经网络来parameterize一个圆锥函数系列（NeSH）来表示单个主体的dMRI信号，这个信号是人类连接度计划数据集的连续信号。我们的重建结果显示，使用这种方法可以获得更结构一致的数据表示。 gradient图像中的噪声被去除，纤维方向分布函数显示了纤维轨迹上的平滑变化。我们还示出了如何使用这种重建方法计算平均扩散率、相对扩散率和总显示纤维密度。这些结果可以通过单个模型架构和一个hyperparameter来实现，并且可以在angular和空间域中进行upsampling，以实现与现有方法相当或更好的重建结果。
</details></li>
</ul>
<hr>
<h2 id="Self-Reference-Deep-Adaptive-Curve-Estimation-for-Low-Light-Image-Enhancement"><a href="#Self-Reference-Deep-Adaptive-Curve-Estimation-for-Low-Light-Image-Enhancement" class="headerlink" title="Self-Reference Deep Adaptive Curve Estimation for Low-Light Image Enhancement"></a>Self-Reference Deep Adaptive Curve Estimation for Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08197">http://arxiv.org/abs/2308.08197</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/john-venti/self-dace">https://github.com/john-venti/self-dace</a></li>
<li>paper_authors: Jianyu Wen, Chenhao Wu, Tong Zhang, Yixuan Yu, Piotr Swierczynski</li>
<li>for: 提高低光照图像的显示品质</li>
<li>methods: 提出了一种基于自referential深度适应曲线估计（Self-DACE）的二 stage低光照图像提升方法，包括一种INTUITIVE、轻量级、快速、无监督的亮度提升算法，以及一种新的损失函数，用于保持自然图像的颜色、结构和准确性。</li>
<li>results: 对多个实际 datasets进行了广泛的Qualitative和Quantitative分析，结果表明，该方法在比较当前最佳算法的测试中表现出色。<details>
<summary>Abstract</summary>
In this paper, we propose a 2-stage low-light image enhancement method called Self-Reference Deep Adaptive Curve Estimation (Self-DACE). In the first stage, we present an intuitive, lightweight, fast, and unsupervised luminance enhancement algorithm. The algorithm is based on a novel low-light enhancement curve that can be used to locally boost image brightness. We also propose a new loss function with a simplified physical model designed to preserve natural images' color, structure, and fidelity. We use a vanilla CNN to map each pixel through deep Adaptive Adjustment Curves (AAC) while preserving the local image structure. Secondly, we introduce the corresponding denoising scheme to remove the latent noise in the darkness. We approximately model the noise in the dark and deploy a Denoising-Net to estimate and remove the noise after the first stage. Exhaustive qualitative and quantitative analysis shows that our method outperforms existing state-of-the-art algorithms on multiple real-world datasets.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种两阶段低光照图像提升方法，称为自适应曲线估计（Self-DACE）。在第一阶段，我们提出了一种直观、轻量级、快速、不需要监督的亮度提升算法。该算法基于一个新的低光照增强曲线，可以地方增强图像亮度。我们还提出了一个新的损失函数，采用简化的物理模型，保持自然图像的颜色、结构和准确性。我们使用一个普通的Convolutional Neural Network（CNN）将每个像素通过深度适应曲线（AAC）进行映射，保持图像的地方结构。在第二阶段，我们引入了对应的干扰除方案，以除去黑暗中的秘密噪声。我们约化黑暗中的噪声，并部署了一个干扰除网络来估计和除去噪声。我们的方法在多个实际世界数据集上进行了系统的质量和量化分析，结果表明我们的方法在与现有状态艺术算法进行比较时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Vision-Based-Parking-Slot-Detection-and-Occupancy-Classification"><a href="#Automatic-Vision-Based-Parking-Slot-Detection-and-Occupancy-Classification" class="headerlink" title="Automatic Vision-Based Parking Slot Detection and Occupancy Classification"></a>Automatic Vision-Based Parking Slot Detection and Occupancy Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08192">http://arxiv.org/abs/2308.08192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ratko Grbić, Brando Koch</li>
<li>for: 这篇论文是为了提供一种自动化停车槽检测和占用分类算法，用于提高停车导航信息系统（PGI）的精度和效果。</li>
<li>methods: 该算法使用了摄像头拍摄停车场的图像，并对图像进行了一系列的处理和分析，包括车辆检测、bird’s eye view clustering、占用分类等步骤。</li>
<li>results: 在使用了公开available的PKLot和CNRPark+EXT数据集进行测试后，该算法表现了高效的停车槽检测和占用分类能力，并能够快速响应停车场的变化。<details>
<summary>Abstract</summary>
Parking guidance information (PGI) systems are used to provide information to drivers about the nearest parking lots and the number of vacant parking slots. Recently, vision-based solutions started to appear as a cost-effective alternative to standard PGI systems based on hardware sensors mounted on each parking slot. Vision-based systems provide information about parking occupancy based on images taken by a camera that is recording a parking lot. However, such systems are challenging to develop due to various possible viewpoints, weather conditions, and object occlusions. Most notably, they require manual labeling of parking slot locations in the input image which is sensitive to camera angle change, replacement, or maintenance. In this paper, the algorithm that performs Automatic Parking Slot Detection and Occupancy Classification (APSD-OC) solely on input images is proposed. Automatic parking slot detection is based on vehicle detections in a series of parking lot images upon which clustering is applied in bird's eye view to detect parking slots. Once the parking slots positions are determined in the input image, each detected parking slot is classified as occupied or vacant using a specifically trained ResNet34 deep classifier. The proposed approach is extensively evaluated on well-known publicly available datasets (PKLot and CNRPark+EXT), showing high efficiency in parking slot detection and robustness to the presence of illegal parking or passing vehicles. Trained classifier achieves high accuracy in parking slot occupancy classification.
</details>
<details>
<summary>摘要</summary>
停车导航信息（PGI）系统用于提供驾驶员关于最近停车场和停车槽数量的信息。最近，基于视觉解决方案开始出现，作为传感器安装在每个停车槽上的成本效果的代替。视觉基于系统提供停车占用的信息，基于停车场上的图像。然而，这些系统的开发具有多种可能的视点、天气条件和物体遮挡的挑战。特别是，它们需要手动标注停车槽位置在输入图像中，这是相对于摄像头角度变化、更换或维护的敏感。在本文中，一种基于输入图像进行自动停车槽检测和占用分类的算法（APSD-OC）被提出。自动停车槽检测基于在停车场图像中检测车辆，并将其分组在鸟瞰视图中检测停车槽。一旦detect了停车槽的位置在输入图像中，每个检测到的停车槽都会被使用特定训练的ResNet34深度分类器进行占用或无占用的分类。提议的方法在知名的公共数据集（PKLot和CNRPark+EXT）进行了广泛的评估，表明高效地检测停车槽和抗抗车或过往车的存在。训练的分类器在停车槽占用分类中达到了高精度。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Domain-Adaptive-Detection-with-Network-Stability-Analysis"><a href="#Unsupervised-Domain-Adaptive-Detection-with-Network-Stability-Analysis" class="headerlink" title="Unsupervised Domain Adaptive Detection with Network Stability Analysis"></a>Unsupervised Domain Adaptive Detection with Network Stability Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08182">http://arxiv.org/abs/2308.08182</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tiankongzhang/nsa">https://github.com/tiankongzhang/nsa</a></li>
<li>paper_authors: Wenzhang Zhou, Heng Fan, Tiejian Luo, Libo Zhang</li>
<li>for: 这篇研究的目的是提高通用性，从源频道上获得标注的检测器，在目标频道上进行无标注检测。</li>
<li>methods: 本研究使用稳定性分析（Network Stability Analysis，NSA）来实现无标注频道适应检测。NSA处理图像和不同频道之间的差异，并使用教师模型进行外部一致性分析和内部一致性分析。</li>
<li>results: 这篇研究使用NSA整合Faster R-CNN，实现了顶尖的结果，包括在Cityscapes-to-FoggyCityscapes上的52.7% mAP记录。此外，NSA还可以应用于其他一阶检测器（例如FCOS），并且在实验中证明了这一点。<details>
<summary>Abstract</summary>
Domain adaptive detection aims to improve the generality of a detector, learned from the labeled source domain, on the unlabeled target domain. In this work, drawing inspiration from the concept of stability from the control theory that a robust system requires to remain consistent both externally and internally regardless of disturbances, we propose a novel framework that achieves unsupervised domain adaptive detection through stability analysis. In specific, we treat discrepancies between images and regions from different domains as disturbances, and introduce a novel simple but effective Network Stability Analysis (NSA) framework that considers various disturbances for domain adaptation. Particularly, we explore three types of perturbations including heavy and light image-level disturbances and instancelevel disturbance. For each type, NSA performs external consistency analysis on the outputs from raw and perturbed images and/or internal consistency analysis on their features, using teacher-student models. By integrating NSA into Faster R-CNN, we immediately achieve state-of-the-art results. In particular, we set a new record of 52.7% mAP on Cityscapes-to-FoggyCityscapes, showing the potential of NSA for domain adaptive detection. It is worth noticing, our NSA is designed for general purpose, and thus applicable to one-stage detection model (e.g., FCOS) besides the adopted one, as shown by experiments. https://github.com/tiankongzhang/NSA.
</details>
<details>
<summary>摘要</summary>
领域适应检测目标是提高检测器，从源频道上得到标注的频道，在目标频道上进行检测的通用性。在这项工作中，我们Drawing inspiration from the concept of stability from control theory that a robust system requires to remain consistent both externally and internally regardless of disturbances, we propose a novel framework that achieves unsupervised domain adaptive detection through stability analysis. Specifically, we treat discrepancies between images and regions from different domains as disturbances, and introduce a novel simple but effective Network Stability Analysis (NSA) framework that considers various disturbances for domain adaptation. Particularly, we explore three types of perturbations including heavy and light image-level disturbances and instance-level disturbance. For each type, NSA performs external consistency analysis on the outputs from raw and perturbed images and/or internal consistency analysis on their features, using teacher-student models. By integrating NSA into Faster R-CNN, we immediately achieve state-of-the-art results. In particular, we set a new record of 52.7% mAP on Cityscapes-to-FoggyCityscapes, showing the potential of NSA for domain adaptive detection. It is worth noting that our NSA is designed for general purpose, and thus applicable to one-stage detection models (e.g., FCOS) besides the adopted one, as shown by experiments. More details can be found at https://github.com/tiankongzhang/NSA.
</details></li>
</ul>
<hr>
<h2 id="AATCT-IDS-A-Benchmark-Abdominal-Adipose-Tissue-CT-Image-Dataset-for-Image-Denoising-Semantic-Segmentation-and-Radiomics-Evaluation"><a href="#AATCT-IDS-A-Benchmark-Abdominal-Adipose-Tissue-CT-Image-Dataset-for-Image-Denoising-Semantic-Segmentation-and-Radiomics-Evaluation" class="headerlink" title="AATCT-IDS: A Benchmark Abdominal Adipose Tissue CT Image Dataset for Image Denoising, Semantic Segmentation, and Radiomics Evaluation"></a>AATCT-IDS: A Benchmark Abdominal Adipose Tissue CT Image Dataset for Image Denoising, Semantic Segmentation, and Radiomics Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08172">http://arxiv.org/abs/2308.08172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyu Ma, Chen Li, Tianming Du, Le Zhang, Dechao Tang, Deguo Ma, Shanchuan Huang, Yan Liu, Yihao Sun, Zhihao Chen, Jin Yuan, Qianqing Nie, Marcin Grzegorzek, Hongzan Sun</li>
<li>For: 这个研究使用的数据集是为了研究腹部脂肪组织的多维特征而制作的。* Methods: 这个研究使用了一个名为AATTCT-IDS的标准数据集，该数据集包含300个subject的3D CT剖图，并由研究人员手动标注了脂肪组织区域的3213个剖图。不同任务的研究人员使用不同的方法对AATTCT-IDS进行了比较分析，以验证这些方法在这些任务中的研究潜力。* Results: 这个研究发现，在图像压缩领域，使用缓和策略可以更好地降低杂噪，并且保持原始图像的结构。在semantic segmentation领域，BiSeNet模型可以在短时间内 obtian精度高的结果，并具有更好的结构分化能力。在 радиологи metrics 领域，研究人员发现了三种不同的脂肪分布方式。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Methods: In this study, a benchmark \emph{Abdominal Adipose Tissue CT Image Dataset} (AATTCT-IDS) containing 300 subjects is prepared and published. AATTCT-IDS publics 13,732 raw CT slices, and the researchers individually annotate the subcutaneous and visceral adipose tissue regions of 3,213 of those slices that have the same slice distance to validate denoising methods, train semantic segmentation models, and study radiomics. For different tasks, this paper compares and analyzes the performance of various methods on AATTCT-IDS by combining the visualization results and evaluation data. Thus, verify the research potential of this data set in the above three types of tasks.   Results: In the comparative study of image denoising, algorithms using a smoothing strategy suppress mixed noise at the expense of image details and obtain better evaluation data. Methods such as BM3D preserve the original image structure better, although the evaluation data are slightly lower. The results show significant differences among them. In the comparative study of semantic segmentation of abdominal adipose tissue, the segmentation results of adipose tissue by each model show different structural characteristics. Among them, BiSeNet obtains segmentation results only slightly inferior to U-Net with the shortest training time and effectively separates small and isolated adipose tissue. In addition, the radiomics study based on AATTCT-IDS reveals three adipose distributions in the subject population.   Conclusion: AATTCT-IDS contains the ground truth of adipose tissue regions in abdominal CT slices. This open-source dataset can attract researchers to explore the multi-dimensional characteristics of abdominal adipose tissue and thus help physicians and patients in clinical practice. AATCT-IDS is freely published for non-commercial purpose at: \url{https://figshare.com/articles/dataset/AATTCT-IDS/23807256}.
</details>
<details>
<summary>摘要</summary>
方法：本研究使用的Benchmark dataset是“ Abdomen Adipose Tissue CT Image Dataset”（AATTCT-IDS），包含300个研究对象，已经公布并可以免费下载。AATTCT-IDS包含13,732个Raw CT slice，研究人员对3,213个slice进行了手动标注，以验证去噪方法、训练semantic segmentation模型以及研究 радиомькс。通过组合视觉化结果和评估数据，对不同任务进行比较和分析。这种方法可以验证AATTCT-IDS的研究潜力。结果：在图像去噪比较研究中，使用缓和策略的算法可以更好地降低杂噪，但是会压缩图像细节。BM3D等方法可以更好地保持原始图像结构，但评估数据略为下降。结果显示不同算法之间存在显著的差异。在semantic segmentation的研究中，每个模型对脂肪组织的 segmentation 结果具有不同的结构特征。比如BiSeNet可以在短时间内 obtaint 脂肪组织 segmentation 结果，并且可以准确地分割小型和隔离的脂肪组织。此外，基于AATTCT-IDS的 радиомькс研究发现了脂肪分布的三种类型。结论：AATTCT-IDS包含了 Abdomen CT slice 中脂肪组织的真实特征。这个开源数据集可以吸引研究人员更深入研究胸部脂肪组织的多维特征，从而帮助医生和患者在临床实践中。AATTCT-IDS是免费发布的，可以在以下链接下下载：https://figshare.com/articles/dataset/AATTCT-IDS/23807256。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Generate-Semantic-Layouts-for-Higher-Text-Image-Correspondence-in-Text-to-Image-Synthesis"><a href="#Learning-to-Generate-Semantic-Layouts-for-Higher-Text-Image-Correspondence-in-Text-to-Image-Synthesis" class="headerlink" title="Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis"></a>Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08157">http://arxiv.org/abs/2308.08157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pmh9960/GCDP">https://github.com/pmh9960/GCDP</a></li>
<li>paper_authors: Minho Park, Jooyeol Yun, Seunghwan Choi, Jaegul Choo</li>
<li>for: 提高文本到图像生成的文本-图像匹配率，而不仅仅依靠大规模的文本-图像数据集。</li>
<li>methods: 提出了一种新的方法，即利用可用的semantic layout来增强文本到图像生成的文本-图像匹配率。Specifically, we propose a Gaussian-categorical diffusion process that simultaneously generates both images and corresponding layout pairs.</li>
<li>results: 我们的实验表明，我们可以通过训练模型生成 semantic labels for each pixel，使模型对不同图像区域的semantics有所了解。我们的方法在Multi-Modal CelebA-HQ和Cityscapes dataset上达到了更高的文本-图像匹配率，这些数据集上的文本-图像对是罕见的。<details>
<summary>Abstract</summary>
Existing text-to-image generation approaches have set high standards for photorealism and text-image correspondence, largely benefiting from web-scale text-image datasets, which can include up to 5~billion pairs. However, text-to-image generation models trained on domain-specific datasets, such as urban scenes, medical images, and faces, still suffer from low text-image correspondence due to the lack of text-image pairs. Additionally, collecting billions of text-image pairs for a specific domain can be time-consuming and costly. Thus, ensuring high text-image correspondence without relying on web-scale text-image datasets remains a challenging task. In this paper, we present a novel approach for enhancing text-image correspondence by leveraging available semantic layouts. Specifically, we propose a Gaussian-categorical diffusion process that simultaneously generates both images and corresponding layout pairs. Our experiments reveal that we can guide text-to-image generation models to be aware of the semantics of different image regions, by training the model to generate semantic labels for each pixel. We demonstrate that our approach achieves higher text-image correspondence compared to existing text-to-image generation approaches in the Multi-Modal CelebA-HQ and the Cityscapes dataset, where text-image pairs are scarce. Codes are available in this https://pmh9960.github.io/research/GCDP
</details>
<details>
<summary>摘要</summary>
现有的文本到图像生成方法已经设置了高标准 для光实感和文本图像对应，主要受益于网络规模的文本图像集，这些集可以包括多达50亿对。然而，文本到图像生成模型在域pecific的 dataset上，如城市场景、医学图像和人脸，仍然受到文本图像对应的低问题，因为缺乏文本图像对。此外，收集百亿对文本图像对可以是时间consuming和costly的。因此，保证高度文本图像对应而不依赖于网络规模的文本图像集是一个挑战。在这篇论文中，我们提出了一种新的方法，通过利用可用的semantic layout来提高文本图像对应。具体来说，我们提出了一个 Gaussian-categorical 扩散过程，同时生成图像和对应的布局对。我们的实验表明，我们可以通过训练模型生成semantic标签来引导文本到图像生成模型对不同图像区域的semantic有认知。我们的方法在Multi-Modal CelebA-HQ和Cityscapes dataset上表现出高度文本图像对应，这些数据集上文本图像对scarce。代码可以在以下链接获取：https://pmh9960.github.io/research/GCDP
</details></li>
</ul>
<hr>
<h2 id="Conditional-Perceptual-Quality-Preserving-Image-Compression"><a href="#Conditional-Perceptual-Quality-Preserving-Image-Compression" class="headerlink" title="Conditional Perceptual Quality Preserving Image Compression"></a>Conditional Perceptual Quality Preserving Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08154">http://arxiv.org/abs/2308.08154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongda Xu, Qian Zhang, Yanghao Li, Dailan He, Zhe Wang, Yuanyuan Wang, Hongwei Qin, Yan Wang, Jingjing Liu, Ya-Qin Zhang</li>
<li>for: 该文章提出了一种基于用户定义信息的 conditional perceptual quality（CPQ），用于保持高质量和 semantics 的图像压缩。</li>
<li>methods: 该文章使用了扩展了 Blau et al. 的 perceptual quality 定义，通过conditioning 用户定义的信息来提高压缩率。</li>
<li>results: 实验结果表明，该代码可以成功保持高质量和 semantics 的图像压缩，并且提供了一个Lower bound 的共同Randomness 需求，解决了前一些对于 (conditional) perceptual quality 压缩是否应该包含随机性的辩论。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We propose conditional perceptual quality, an extension of the perceptual quality defined in \citet{blau2018perception}, by conditioning it on user defined information. Specifically, we extend the original perceptual quality $d(p_{X},p_{\hat{X})$ to the conditional perceptual quality $d(p_{X|Y},p_{\hat{X}|Y})$, where $X$ is the original image, $\hat{X}$ is the reconstructed, $Y$ is side information defined by user and $d(.,.)$ is divergence. We show that conditional perceptual quality has similar theoretical properties as rate-distortion-perception trade-off \citep{blau2019rethinking}. Based on these theoretical results, we propose an optimal framework for conditional perceptual quality preserving compression. Experimental results show that our codec successfully maintains high perceptual quality and semantic quality at all bitrate. Besides, by providing a lowerbound of common randomness required, we settle the previous arguments on whether randomness should be incorporated into generator for (conditional) perceptual quality compression. The source code is provided in supplementary material.
</details>
<details>
<summary>摘要</summary>
我们提议使用条件的感知质量，这是基于\citet{blau2018perception}定义的感知质量的扩展，通过定制用户定义的信息来conditioning。具体来说，我们从原始的感知质量$d(p_{X},p_{\hat{X})$中扩展了条件感知质量$d(p_{X|Y},p_{\hat{X}|Y})$,其中$X$是原始图像，$\hat{X}$是重建的图像，$Y$是用户定义的侧信息。我们证明了条件感知质量具有与Rate-Distortion-Perception交易的同样理论性质。基于这些理论结论，我们提出了一个优化的条件感知质量保持压缩框架。实验结果表明，我们的编码器成功保持高感知质量和 semantics质量在所有比特率。此外，我们提供了common randomness所需的下界，解决了过去对 generator中是否应该包含随机性的争议。代码可以在补充材料中找到。
</details></li>
</ul>
<hr>
<h2 id="SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation"><a href="#SCANet-A-Self-and-Cross-Attention-Network-for-Audio-Visual-Speech-Separation" class="headerlink" title="SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation"></a>SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08143">http://arxiv.org/abs/2308.08143</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Li, Runxuan Yang, Xiaolin Hu</li>
<li>for: 这篇论文主要是为了提出一种新的多模态协同分离方法，以提高人工智能系统对听视环境的识别能力。</li>
<li>methods: 这篇论文提出了一种名为自我和交叉注意网络（SCANet）的新模型，该模型利用注意机制来有效地融合听视信号。SCANet包括两种注意块：自我注意（SA）块和交叉注意（CA）块，其中CA块分布在网络的顶部（TCA）、中部（MCA）和底部（BCA）。这些块使得模型可以学习不同的模式特征，并提取不同的 semantics 从听视特征。</li>
<li>results: 对于三个标准的听视分离测试集（LRS2、LRS3和VoxCeleb2），SCANet表现出色，超过现有的状态时之方法，并且保持相对的执行时间相对较短。<details>
<summary>Abstract</summary>
The integration of different modalities, such as audio and visual information, plays a crucial role in human perception of the surrounding environment. Recent research has made significant progress in designing fusion modules for audio-visual speech separation. However, they predominantly focus on multi-modal fusion architectures situated either at the top or bottom positions, rather than comprehensively considering multi-modal fusion at various hierarchical positions within the network. In this paper, we propose a novel model called self- and cross-attention network (SCANet), which leverages the attention mechanism for efficient audio-visual feature fusion. SCANet consists of two types of attention blocks: self-attention (SA) and cross-attention (CA) blocks, where the CA blocks are distributed at the top (TCA), middle (MCA) and bottom (BCA) of SCANet. These blocks maintain the ability to learn modality-specific features and enable the extraction of different semantics from audio-visual features. Comprehensive experiments on three standard audio-visual separation benchmarks (LRS2, LRS3, and VoxCeleb2) demonstrate the effectiveness of SCANet, outperforming existing state-of-the-art (SOTA) methods while maintaining comparable inference time.
</details>
<details>
<summary>摘要</summary>
人类对周围环境的识别受到不同modalities（如音频和视觉信息）的集成具有重要作用。现有研究已经在设计音视频演说分离模块方面做出了重要进步。然而，这些模块主要集中在网络的顶层或底层位置，而不是全面考虑多modalities在网络各级别位置的集成。在这篇论文中，我们提出了一种新的模型，即自我和交叉关注网络（SCANet），它利用关注机制来实现有效的音视频特征结合。SCANet包括两种关注块：自我关注（SA）和交叉关注（CA）块，其中CA块分布在SCANet的顶层（TCA）、中层（MCA）和底层（BCA）。这些块可以保持学习不同modalities特征，并允许从音视频特征中提取不同 semantics。我们对三个标准音视频分离标准（LRS2、LRS3和VoxCeleb2）进行了广泛的实验，并证明SCANet的效果比现有SOTA方法更好，同时保持相对的执行时间相对快。
</details></li>
</ul>
<hr>
<h2 id="S2R-Exploring-a-Double-Win-Transformer-Based-Framework-for-Ideal-and-Blind-Super-Resolution"><a href="#S2R-Exploring-a-Double-Win-Transformer-Based-Framework-for-Ideal-and-Blind-Super-Resolution" class="headerlink" title="S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and Blind Super-Resolution"></a>S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and Blind Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08142">http://arxiv.org/abs/2308.08142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minghao She, Wendong Mao, Huihong Shi, Zhongfeng Wang</li>
<li>for: 提高理想和盲 SR 任务的视觉效果（ideal and blind super-resolution）</li>
<li>methods: 提出了一种双赢框架（double-win framework），包括一种轻量级 transformer 基于 SR 模型（S2R transformer）和一种新的倒吃式训练策略（coarse-to-fine training strategy）</li>
<li>results: 实验结果表明，提出的 S2R 模型在理想 SR 条件下与只有 578K 参数表现出色，并在盲糊条件下与只有 10 梯度更新达到更好的视觉效果，提高了整体训练速度三百倍。<details>
<summary>Abstract</summary>
Nowadays, deep learning based methods have demonstrated impressive performance on ideal super-resolution (SR) datasets, but most of these methods incur dramatically performance drops when directly applied in real-world SR reconstruction tasks with unpredictable blur kernels. To tackle this issue, blind SR methods are proposed to improve the visual results on random blur kernels, which causes unsatisfactory reconstruction effects on ideal low-resolution images similarly. In this paper, we propose a double-win framework for ideal and blind SR task, named S2R, including a light-weight transformer-based SR model (S2R transformer) and a novel coarse-to-fine training strategy, which can achieve excellent visual results on both ideal and random fuzzy conditions. On algorithm level, S2R transformer smartly combines some efficient and light-weight blocks to enhance the representation ability of extracted features with relatively low number of parameters. For training strategy, a coarse-level learning process is firstly performed to improve the generalization of the network with the help of a large-scale external dataset, and then, a fast fine-tune process is developed to transfer the pre-trained model to real-world SR tasks by mining the internal features of the image. Experimental results show that the proposed S2R outperforms other single-image SR models in ideal SR condition with only 578K parameters. Meanwhile, it can achieve better visual results than regular blind SR models in blind fuzzy conditions with only 10 gradient updates, which improve convergence speed by 300 times, significantly accelerating the transfer-learning process in real-world situations.
</details>
<details>
<summary>摘要</summary>
现在，深度学习基本方法在理想的超分辨率（SR）数据集上已经表现出了惊人的表现，但大多数这些方法在实际的SR重建任务中直接应用时会导致表现下降，特别是在随机扭曲kernel的情况下。为解决这个问题，盲 SR 方法被提出来提高视觉效果，但这些方法在理想的低分辨率图像上也会导致不满足的重建效果。在这篇文章中，我们提出了一个双赢框架，名为 S2R，包括一个轻量级的 transformer 基本 SR 模型（S2R transformer）和一种新的 course-to-fine 训练策略，可以在理想和随机扭曲条件下实现出色的视觉效果。在算法层次，S2R transformer 智能地结合了一些高效和轻量级的块来增强提取的特征表示能力，同时减少参数的数量。在训练策略方面，我们首先在大规模的外部数据集上进行了粗级学习过程，以提高网络的通用性，然后，我们开发了一种快速的 fine-tune 过程，通过挖掘图像内部特征来转移预训练模型到实际SR任务中。实验结果显示，我们提出的 S2R 可以在理想SR条件下与只有 578K 参数的其他单图 SR 模型进行比较，同时在盲扭曲条件下，它可以在只有 10 梯度更新的情况下达到更好的视觉效果，提高了整体的转移学习过程的速度，从而实现了实际应用中的加速。
</details></li>
</ul>
<hr>
<h2 id="GPA-3D-Geometry-aware-Prototype-Alignment-for-Unsupervised-Domain-Adaptive-3D-Object-Detection-from-Point-Clouds"><a href="#GPA-3D-Geometry-aware-Prototype-Alignment-for-Unsupervised-Domain-Adaptive-3D-Object-Detection-from-Point-Clouds" class="headerlink" title="GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds"></a>GPA-3D: Geometry-aware Prototype Alignment for Unsupervised Domain Adaptive 3D Object Detection from Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08140">http://arxiv.org/abs/2308.08140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liz66666/gpa3d">https://github.com/liz66666/gpa3d</a></li>
<li>paper_authors: Ziyu Li, Jingming Guo, Tongtong Cao, Liu Bingbing, Wankou Yang</li>
<li>for: 提高LiDAR-based 3D检测的鲁棒性和可靠性在未看过的环境中</li>
<li>methods: 使用不监督的领域适应3D检测方法，通过自适应的投影Alignment技术来减少特征空间的分布差异，从而实现跨频道的转移</li>
<li>results: 在Waymo、nuScenes和KITTI等多个 benchmark上获得了比领先方法更好的适应性和性能<details>
<summary>Abstract</summary>
LiDAR-based 3D detection has made great progress in recent years. However, the performance of 3D detectors is considerably limited when deployed in unseen environments, owing to the severe domain gap problem. Existing domain adaptive 3D detection methods do not adequately consider the problem of the distributional discrepancy in feature space, thereby hindering generalization of detectors across domains. In this work, we propose a novel unsupervised domain adaptive \textbf{3D} detection framework, namely \textbf{G}eometry-aware \textbf{P}rototype \textbf{A}lignment (\textbf{GPA-3D}), which explicitly leverages the intrinsic geometric relationship from point cloud objects to reduce the feature discrepancy, thus facilitating cross-domain transferring. Specifically, GPA-3D assigns a series of tailored and learnable prototypes to point cloud objects with distinct geometric structures. Each prototype aligns BEV (bird's-eye-view) features derived from corresponding point cloud objects on source and target domains, reducing the distributional discrepancy and achieving better adaptation. The evaluation results obtained on various benchmarks, including Waymo, nuScenes and KITTI, demonstrate the superiority of our GPA-3D over the state-of-the-art approaches for different adaptation scenarios. The MindSpore version code will be publicly available at \url{https://github.com/Liz66666/GPA3D}.
</details>
<details>
<summary>摘要</summary>
“李达尔基于3D探测技术在最近几年内做出了大量的进步。然而，3D探测器在未看过的环境中表现不佳，主要因为域名隔problem。现有的域名适应3D探测方法不充分考虑了特征空间中的分布差异问题，从而阻碍探测器在不同域之间的通用化。在这种情况下，我们提出了一种新的无监督域名适应3D探测框架，即geometry-aware prototype alignment（GPA-3D）。GPA-3D利用了点云对象的内在几何关系来减少特征空间中的差异，从而促进域之间的转移。具体来说，GPA-3D分配了一系列适应点云对象的学习式和定制的原型。每个原型都将源域和目标域BEV特征相互对应，从而减少分布差异并实现更好的适应。我们在WAYMO、nuScenes和KITTI等各种标准均取得了GPA-3D在不同适应场景下的优于状态艺术方法。MindSpore版本代码将在 \url{https://github.com/Liz66666/GPA3D} 上公开。”
</details></li>
</ul>
<hr>
<h2 id="View-Consistent-Purification-for-Accurate-Cross-View-Localization"><a href="#View-Consistent-Purification-for-Accurate-Cross-View-Localization" class="headerlink" title="View Consistent Purification for Accurate Cross-View Localization"></a>View Consistent Purification for Accurate Cross-View Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08110">http://arxiv.org/abs/2308.08110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ShanWang-Shan/PureACL-website">https://github.com/ShanWang-Shan/PureACL-website</a></li>
<li>paper_authors: Shan Wang, Yanhao Zhang, Akhil Perincherry, Ankit Vora, Hongdong Li</li>
<li>for: 本研究提出了一种高精度自地localization方法，用于outdoor robotics，该方法利用了多个搭载在机器人上的摄像头和 readily accessible的卫星图像。</li>
<li>methods: 该方法利用了视觉特征的检测和匹配，并将视觉特征与卫星图像的映射转换成为Homography变换。此外，该方法还使用了空间嵌入approach来减少视觉匹配的歧义性。</li>
<li>results: 对KITTI和Ford Multi-AV Seasonal dataset进行了广泛的实验，并表明了our proposed method可以高效地在室外环境中进行自地localization，其中 median lateral和longitudinal方向的空间精度错误在0.5米以下， medianorientation方向的精度错误在2度以下。<details>
<summary>Abstract</summary>
This paper proposes a fine-grained self-localization method for outdoor robotics that utilizes a flexible number of onboard cameras and readily accessible satellite images. The proposed method addresses limitations in existing cross-view localization methods that struggle to handle noise sources such as moving objects and seasonal variations. It is the first sparse visual-only method that enhances perception in dynamic environments by detecting view-consistent key points and their corresponding deep features from ground and satellite views, while removing off-the-ground objects and establishing homography transformation between the two views. Moreover, the proposed method incorporates a spatial embedding approach that leverages camera intrinsic and extrinsic information to reduce the ambiguity of purely visual matching, leading to improved feature matching and overall pose estimation accuracy. The method exhibits strong generalization and is robust to environmental changes, requiring only geo-poses as ground truth. Extensive experiments on the KITTI and Ford Multi-AV Seasonal datasets demonstrate that our proposed method outperforms existing state-of-the-art methods, achieving median spatial accuracy errors below $0.5$ meters along the lateral and longitudinal directions, and a median orientation accuracy error below 2 degrees.
</details>
<details>
<summary>摘要</summary>
（本文提出了一种用于外部自导航的细化自位置方法，该方法使用可变数量的船内摄像头和可ready accessible的卫星图像。该方法解决了现有的相对视图本地化方法所面临的噪声源，如移动物体和季节变化。这是首个使用视图相同的键点和深度特征进行视觉匹配的缺省方法，同时从地面和卫星视图中提取杂谱对象并建立Homography变换。此外，该方法还 integrate了空间嵌入方法，利用摄像头内部和外部信息来减少视觉匹配的歧义，导致更好的特征匹配和总位姿估计精度。该方法具有强大的泛化能力和环境变化的Robustness，只需要地球坐标作为真实参照。实验表明，我们的提出方法在KITTI和福特多个AV季节数据集上表现出色，与现有状态最佳方法相比，实现了水平和 longitudinal方向的 median 精度 ErrorBelow $0.5$米，并且orientation accuracy errorBelow 2度。）
</details></li>
</ul>
<hr>
<h2 id="Snapshot-High-Dynamic-Range-Imaging-with-a-Polarization-Camera"><a href="#Snapshot-High-Dynamic-Range-Imaging-with-a-Polarization-Camera" class="headerlink" title="Snapshot High Dynamic Range Imaging with a Polarization Camera"></a>Snapshot High Dynamic Range Imaging with a Polarization Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08094">http://arxiv.org/abs/2308.08094</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Intelligent-Sensing/polarization-hdr">https://github.com/Intelligent-Sensing/polarization-hdr</a></li>
<li>paper_authors: Mingyang Xie, Matthew Chan, Christopher Metzler</li>
<li>for: 该论文旨在将普通的楔格相机转化为高性能HDR相机。</li>
<li>methods: 该方法使用 linear polarizer 在前面，并通过不同的折射器orientation 来获取不同的曝光图像四个。然后，通过一种异常抗性和自适应算法来重建HDR图像（在单一极性下）。</li>
<li>results: 该方法通过实际的实验证明其效果。<details>
<summary>Abstract</summary>
High dynamic range (HDR) images are important for a range of tasks, from navigation to consumer photography. Accordingly, a host of specialized HDR sensors have been developed, the most successful of which are based on capturing variable per-pixel exposures. In essence, these methods capture an entire exposure bracket sequence at once in a single shot. This paper presents a straightforward but highly effective approach for turning an off-the-shelf polarization camera into a high-performance HDR camera. By placing a linear polarizer in front of the polarization camera, we are able to simultaneously capture four images with varied exposures, which are determined by the orientation of the polarizer. We develop an outlier-robust and self-calibrating algorithm to reconstruct an HDR image (at a single polarity) from these measurements. Finally, we demonstrate the efficacy of our approach with extensive real-world experiments.
</details>
<details>
<summary>摘要</summary>
高动态范围（HDR）图像在各种任务中非常重要，从导航到消费型摄影。因此，一些专门的HDR传感器被开发出来，最成功的是基于每个像素变量曝光的方法。在本文中，我们提出了将偏振相机转化为高性能HDR相机的简单 yet effectiveapproach。我们在偏振相机前置一个线性偏振器，以实现同时捕捉不同曝光的四个图像。我们开发了一种异常抗性和自适应算法，将这些测量转化为HDR图像（单一偏振）。最后，我们通过实际实验证明了我们的方法的有效性。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="DragNUWA-Fine-grained-Control-in-Video-Generation-by-Integrating-Text-Image-and-Trajectory"><a href="#DragNUWA-Fine-grained-Control-in-Video-Generation-by-Integrating-Text-Image-and-Trajectory" class="headerlink" title="DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory"></a>DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08089">http://arxiv.org/abs/2308.08089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengming Yin, Chenfei Wu, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, Nan Duan</li>
<li>for: 这篇论文主要针对的是控制视频生成的精细控制问题，即在视频中实现细致的控制功能，以提高视频生成的灵活性和自然性。</li>
<li>methods: 该论文提出了一种基于扩散的视频生成模型，称为DragNUWA，它同时使用文本、图像和轨迹信息进行细致控制，从semantic、spatial和temporal三个方面提供细致控制。此外， DragNUWA还提出了三个方面的轨迹模型：Trajectory Sampler、Multiscale Fusion和Adaptive Training，以解决当前研究中对于开放领域轨迹控制的局限性。</li>
<li>results: 实验证明 DragNUWA 的效果，其能够在视频生成中实现细致的控制功能，并且在不同的材料和设定下都能够达到比较好的效果。<details>
<summary>Abstract</summary>
Controllable video generation has gained significant attention in recent years. However, two main limitations persist: Firstly, most existing works focus on either text, image, or trajectory-based control, leading to an inability to achieve fine-grained control in videos. Secondly, trajectory control research is still in its early stages, with most experiments being conducted on simple datasets like Human3.6M. This constraint limits the models' capability to process open-domain images and effectively handle complex curved trajectories. In this paper, we propose DragNUWA, an open-domain diffusion-based video generation model. To tackle the issue of insufficient control granularity in existing works, we simultaneously introduce text, image, and trajectory information to provide fine-grained control over video content from semantic, spatial, and temporal perspectives. To resolve the problem of limited open-domain trajectory control in current research, We propose trajectory modeling with three aspects: a Trajectory Sampler (TS) to enable open-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to control trajectories in different granularities, and an Adaptive Training (AT) strategy to generate consistent videos following trajectories. Our experiments validate the effectiveness of DragNUWA, demonstrating its superior performance in fine-grained control in video generation. The homepage link is \url{https://www.microsoft.com/en-us/research/project/dragnuwa/}
</details>
<details>
<summary>摘要</summary>
《可控视频生成技术在最近几年内得到了广泛关注。然而，两个主要限制仍然存在：首先，大多数现有的工作都是基于文本、图像或轨迹控制，导致精细控制视频内容的能力受到限制。其次，轨迹控制领域的研究仍然处于初 stages，大多数实验都是基于简单的 dataset like Human3.6M 进行的。这两个限制使得模型无法处理开放领域图像和复杂弯曲轨迹。在这篇论文中，我们提出了 DragNUWA，一种开放领域扩散基于视频生成模型。为了解决现有工作中的精细控制不足问题，我们同时引入文本、图像和轨迹信息，以提供从 semantic、空间和时间三个角度进行精细控制视频内容的能力。为了解决当前研究中对开放领域轨迹控制的限制，我们提出了轨迹模型，包括 Trajectory Sampler (TS) 以实现开放领域轨迹控制，Multiscale Fusion (MF) 以控制不同级别的轨迹，以及 Adaptive Training (AT) 策略以生成遵循轨迹的一致视频。我们的实验证明 DragNUWA 的效果，并示出其在精细控制视频生成方面的优越性。更多信息请访问我们的主页：<https://www.microsoft.com/en-us/research/project/dragnuwa/>。
</details></li>
</ul>
<hr>
<h2 id="Pro-Cap-Leveraging-a-Frozen-Vision-Language-Model-for-Hateful-Meme-Detection"><a href="#Pro-Cap-Leveraging-a-Frozen-Vision-Language-Model-for-Hateful-Meme-Detection" class="headerlink" title="Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection"></a>Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08088">http://arxiv.org/abs/2308.08088</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/social-ai-studio/pro-cap">https://github.com/social-ai-studio/pro-cap</a></li>
<li>paper_authors: Rui Cao, Ming Shan Hee, Adriel Kuek, Wen-Haw Chong, Roy Ka-Wei Lee, Jing Jiang</li>
<li>for: 本研究旨在提高 hateful meme 检测 task 的效果，通过对 pre-trained vision-language 模型（PVLM）进行特点化。</li>
<li>methods: 本研究提出了一种 probing-based captioning 方法，通过向冻结 PVLM 提问 hateful content-related 问题，并使用回答作为图像标题（我们称为 Pro-Cap），以便图像标题包含有关 hateful content 的信息。</li>
<li>results: 在三个标准测试集上，使用 Pro-Cap 方法的模型显示了良好的性能和泛化能力，证明了方法的有效性和通用性。<details>
<summary>Abstract</summary>
Hateful meme detection is a challenging multimodal task that requires comprehension of both vision and language, as well as cross-modal interactions. Recent studies have tried to fine-tune pre-trained vision-language models (PVLMs) for this task. However, with increasing model sizes, it becomes important to leverage powerful PVLMs more efficiently, rather than simply fine-tuning them. Recently, researchers have attempted to convert meme images into textual captions and prompt language models for predictions. This approach has shown good performance but suffers from non-informative image captions. Considering the two factors mentioned above, we propose a probing-based captioning approach to leverage PVLMs in a zero-shot visual question answering (VQA) manner. Specifically, we prompt a frozen PVLM by asking hateful content-related questions and use the answers as image captions (which we call Pro-Cap), so that the captions contain information critical for hateful content detection. The good performance of models with Pro-Cap on three benchmarks validates the effectiveness and generalization of the proposed method.
</details>
<details>
<summary>摘要</summary>
仇恨内容检测是一个复杂的多模态任务，需要包括视觉和语言理解，以及跨模态交互。Recent studies have tried to fine-tune预训练的视觉语言模型(PVLM) для这个任务。然而，随着模型的尺寸增大，更重要的是更好地利用更强大的PVLM，而不是只是精度。Recently, researchers have attempted to convert meme images into textual captions and prompt language models for predictions. This approach has shown good performance but suffers from non-informative image captions. Considering the two factors mentioned above, we propose a probing-based captioning approach to leverage PVLMs in a zero-shot visual question answering (VQA) manner. Specifically, we prompt a frozen PVLM by asking hateful content-related questions and use the answers as image captions (which we call Pro-Cap), so that the captions contain information critical for hateful content detection. The good performance of models with Pro-Cap on three benchmarks validates the effectiveness and generalization of the proposed method.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Framework-for-Spleen-Volume-Estimation-from-2D-Cross-sectional-Views"><a href="#Deep-Learning-Framework-for-Spleen-Volume-Estimation-from-2D-Cross-sectional-Views" class="headerlink" title="Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views"></a>Deep Learning Framework for Spleen Volume Estimation from 2D Cross-sectional Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08038">http://arxiv.org/abs/2308.08038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Yuan, Esther Puyol-Anton, Haran Jogeesvaran, Baba Inusa, Andrew P. King<br>for:* The paper aims to provide an automated method for measuring spleen volume from 2D cross-sectional segmentations obtained from ultrasound imaging, which can be used to assess splenomegaly and related clinical conditions.methods:* The proposed method uses a variational autoencoder-based framework to estimate spleen volume from single- or dual-view 2D spleen segmentations.* The framework includes three volume estimation methods, which are evaluated and compared with the clinical standard approach and a deep learning-based 2D-3D reconstruction-based approach.results:* The best model achieved mean relative volume accuracies of 86.62% and 92.58% for single- and dual-view segmentations, respectively, which is higher than the performance of the clinical standard approach and the comparative deep learning-based approach.Here is the information in Simplified Chinese text:for:* 本研究旨在提供一种自动化的脾体积量测量方法，使用2D横截图像来评估脾体积度和相关的临床病情。methods:* 提议的方法使用Variational Autoencoder（VAE）基础框架来估计脾体积量，并包括三种量测方法。results:* 最佳模型在单视和双视分割图像中的脾体积量准确率分别为86.62%和92.58%，高于临床标准方法和相关的深度学习基础的2D-3D重构方法。<details>
<summary>Abstract</summary>
Abnormal spleen enlargement (splenomegaly) is regarded as a clinical indicator for a range of conditions, including liver disease, cancer and blood diseases. While spleen length measured from ultrasound images is a commonly used surrogate for spleen size, spleen volume remains the gold standard metric for assessing splenomegaly and the severity of related clinical conditions. Computed tomography is the main imaging modality for measuring spleen volume, but it is less accessible in areas where there is a high prevalence of splenomegaly (e.g., the Global South). Our objective was to enable automated spleen volume measurement from 2D cross-sectional segmentations, which can be obtained from ultrasound imaging. In this study, we describe a variational autoencoder-based framework to measure spleen volume from single- or dual-view 2D spleen segmentations. We propose and evaluate three volume estimation methods within this framework. We also demonstrate how 95% confidence intervals of volume estimates can be produced to make our method more clinically useful. Our best model achieved mean relative volume accuracies of 86.62% and 92.58% for single- and dual-view segmentations, respectively, surpassing the performance of the clinical standard approach of linear regression using manual measurements and a comparative deep learning-based 2D-3D reconstruction-based approach. The proposed spleen volume estimation framework can be integrated into standard clinical workflows which currently use 2D ultrasound images to measure spleen length. To the best of our knowledge, this is the first work to achieve direct 3D spleen volume estimation from 2D spleen segmentations.
</details>
<details>
<summary>摘要</summary>
非常常见的脾脓肿大 (splenomegaly) 被视为临床指标，用于诊断多种疾病，包括肝病、癌症和血液疾病。脾脓长度从ultrasound图像中测量是通常使用的代表脾脓大小的临床标准，但脾脓体积仍然是评估splenomegaly和相关临床疾病的严重程度的黄金标准。计算机断层成像是评估脾脓体积的主要成像方法，但在全球南方地区，其访问性较差。我们的目标是启用自动化脾脓体积计算的方法，从2D横截图像中获得脾脓 segmentation。在这种框架中，我们提出并评估了三种体积估计方法。我们还示出了如何生成95%信任区间的体积估计，以使我们的方法更加临床有用。我们的最佳模型在单视和双视 segmentation中达到了86.62%和92.58%的相对体积准确率，超过了临床标准方法的线性回归使用手动测量和相对深度学习基于2D-3D重建的方法。我们的提议的脾脓体积估计框架可以与现有的临床工作流程 integrating，这些工作流程当前使用2D ultrasound图像来测量脾脓长度。据我们所知，这是第一个直接从2D脾脓 segmentation中获得3D脾脓体积的方法。
</details></li>
</ul>
<hr>
<h2 id="Shortcut-V2V-Compression-Framework-for-Video-to-Video-Translation-based-on-Temporal-Redundancy-Reduction"><a href="#Shortcut-V2V-Compression-Framework-for-Video-to-Video-Translation-based-on-Temporal-Redundancy-Reduction" class="headerlink" title="Shortcut-V2V: Compression Framework for Video-to-Video Translation based on Temporal Redundancy Reduction"></a>Shortcut-V2V: Compression Framework for Video-to-Video Translation based on Temporal Redundancy Reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08011">http://arxiv.org/abs/2308.08011</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaeyeon Chung, Yeojeong Park, Seunghwan Choi, Munkhsoyol Ganbat, Jaegul Choo</li>
<li>for: Video-to-video translation的计算效率提高</li>
<li>methods: 短路抽象法和 AdaBD 块</li>
<li>results: 相比原始模型， saves 3.2-5.7x 计算成本和 7.8-44x 内存占用， 而且性能相对较好。<details>
<summary>Abstract</summary>
Video-to-video translation aims to generate video frames of a target domain from an input video. Despite its usefulness, the existing networks require enormous computations, necessitating their model compression for wide use. While there exist compression methods that improve computational efficiency in various image/video tasks, a generally-applicable compression method for video-to-video translation has not been studied much. In response, we present Shortcut-V2V, a general-purpose compression framework for video-to-video translation. Shourcut-V2V avoids full inference for every neighboring video frame by approximating the intermediate features of a current frame from those of the previous frame. Moreover, in our framework, a newly-proposed block called AdaBD adaptively blends and deforms features of neighboring frames, which makes more accurate predictions of the intermediate features possible. We conduct quantitative and qualitative evaluations using well-known video-to-video translation models on various tasks to demonstrate the general applicability of our framework. The results show that Shourcut-V2V achieves comparable performance compared to the original video-to-video translation model while saving 3.2-5.7x computational cost and 7.8-44x memory at test time.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于视频到视频翻译 task，我们目标是生成目标域中的视频帧。尽管它们的用处很大，但现有的网络需要巨大的计算能力，因此需要压缩模型以实现广泛的应用。虽然在不同的图像/视频任务中存在压缩方法，但一个通用的压缩方法 для视频到视频翻译尚未得到了充分的研究。为了解决这个问题，我们提出了 Shortcut-V2V，一个通用压缩框架 для视频到视频翻译。Shortcut-V2V 避免了对每帧邻近视频帧的完整推理，而是使用一个新提出的块 called AdaBD，将邻近帧的特征特性缓存并混合。这使得在测试时可以更准确地预测中间特征。我们对多个常见的视频到视频翻译模型进行了量化和质量的评估，以示我们的框架的通用性。结果表明，Shortcut-V2V 可以与原始视频到视频翻译模型相比，在测试时保持相同的性能，同时减少了 3.2-5.7 倍的计算成本和 7.8-44 倍的内存占用。
</details></li>
</ul>
<hr>
<h2 id="A-2-Nav-Action-Aware-Zero-Shot-Robot-Navigation-by-Exploiting-Vision-and-Language-Ability-of-Foundation-Models"><a href="#A-2-Nav-Action-Aware-Zero-Shot-Robot-Navigation-by-Exploiting-Vision-and-Language-Ability-of-Foundation-Models" class="headerlink" title="$A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models"></a>$A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07997">http://arxiv.org/abs/2308.07997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peihao Chen, Xinyu Sun, Hongyan Zhi, Runhao Zeng, Thomas H. Li, Gaowen Liu, Mingkui Tan, Chuang Gan</li>
<li>for: 本文旨在解决零例视觉语言导航（ZS-VLN）问题，即一个实际困难的问题， Agent 学习从语言指令中导航，无需任何导航指令数据。</li>
<li>methods: 本文提出了一种基于基础模型的视觉语言能力（$A^2$Nav），包括一个指令分析器和一个具有动作意识的导航策略。指令分析器利用大语言模型（如 GPT-3）的高级逻辑能力，将复杂的导航指令分解成一系列具有特定动作需求的对象导航子任务。</li>
<li>results: 实验表明，$A^2$Nav 在 R2R-Habitat 和 RxR-Habitat 数据集上达到了可观的 ZS-VLN 性能，甚至超过了指导学习方法。<details>
<summary>Abstract</summary>
We study the task of zero-shot vision-and-language navigation (ZS-VLN), a practical yet challenging problem in which an agent learns to navigate following a path described by language instructions without requiring any path-instruction annotation data. Normally, the instructions have complex grammatical structures and often contain various action descriptions (e.g., "proceed beyond", "depart from"). How to correctly understand and execute these action demands is a critical problem, and the absence of annotated data makes it even more challenging. Note that a well-educated human being can easily understand path instructions without the need for any special training. In this paper, we propose an action-aware zero-shot VLN method ($A^2$Nav) by exploiting the vision-and-language ability of foundation models. Specifically, the proposed method consists of an instruction parser and an action-aware navigation policy. The instruction parser utilizes the advanced reasoning ability of large language models (e.g., GPT-3) to decompose complex navigation instructions into a sequence of action-specific object navigation sub-tasks. Each sub-task requires the agent to localize the object and navigate to a specific goal position according to the associated action demand. To accomplish these sub-tasks, an action-aware navigation policy is learned from freely collected action-specific datasets that reveal distinct characteristics of each action demand. We use the learned navigation policy for executing sub-tasks sequentially to follow the navigation instruction. Extensive experiments show $A^2$Nav achieves promising ZS-VLN performance and even surpasses the supervised learning methods on R2R-Habitat and RxR-Habitat datasets.
</details>
<details>
<summary>摘要</summary>
我们研究零shot视觉语言导航（ZS-VLN）任务，这是一个实际又具有挑战性的问题，在哪怕需要任务描述数据。通常，这些 instrucion 具有复杂的 grammatical structure 和各种动作描述（例如“继续前进”、“从而 Depart”）。正确地理解和执行这些动作需求是一个关键的问题，而且缺乏 annotated data 使其更加具有挑战性。注意，一个有良好教育的人可以轻松地理解路径 instrucion  без需要任何特殊训练。在这篇论文中，我们提出一个动作感知的零shot VLN 方法（$A^2$Nav），通过利用基础模型的见识和语言能力。具体来说，提案的方法包括一个 instruction parser 和一个动作感知的导航政策。 instruction parser 利用大型语言模型（例如 GPT-3）的进阶逻辑能力，将复杂的导航 instrucion 拆分为一系列动作特定的物品导航子任务。每个子任务需要代理人寻找物品并按照相应的动作需求 navigate 到特定的目标位置。为了完成这些子任务，我们从自由收集的动作特定 dataset 学习一个动作感知的导航政策。我们使用学习的导航政策来执行子任务依序，以实现following the navigation instruction。我们的实验结果显示，$A^2$Nav 可以实现出色的 ZS-VLN 性能，甚至超越了对 R2R-Habitat 和 RxR-Habitat dataset 的监督学习方法。
</details></li>
</ul>
<hr>
<h2 id="YODA-You-Only-Diffuse-Areas-An-Area-Masked-Diffusion-Approach-For-Image-Super-Resolution"><a href="#YODA-You-Only-Diffuse-Areas-An-Area-Masked-Diffusion-Approach-For-Image-Super-Resolution" class="headerlink" title="YODA: You Only Diffuse Areas. An Area-Masked Diffusion Approach For Image Super-Resolution"></a>YODA: You Only Diffuse Areas. An Area-Masked Diffusion Approach For Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07977">http://arxiv.org/abs/2308.07977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian B. Moser, Stanislav Frolov, Federico Raue, Sebastian Palacio, Andreas Dengel</li>
<li>for: 该论文旨在提出一种基于部分扩散的单图超解hre（SISR）方法，即“You Only Diffuse Areas”（YODA）。</li>
<li>methods: 该方法利用基于注意力地图的扩散选择性地应用于空间区域，以便更有效地 converts to high-resolution outputs。</li>
<li>results: 我们通过对SR3和SRDiff扩展而证明了YODA的性能提升，包括面部和总体SR的PSNR、SSIM和LPIPS指标上的新状态态记录。此外，YODA还能够稳定化训练过程，尤其是在小批量下可能引起的颜色偏移问题。<details>
<summary>Abstract</summary>
This work introduces "You Only Diffuse Areas" (YODA), a novel method for partial diffusion in Single-Image Super-Resolution (SISR). The core idea is to utilize diffusion selectively on spatial regions based on attention maps derived from the low-resolution image and the current time step in the diffusion process. This time-dependent targeting enables a more effective conversion to high-resolution outputs by focusing on areas that benefit the most from the iterative refinement process, i.e., detail-rich objects. We empirically validate YODA by extending leading diffusion-based SISR methods SR3 and SRDiff. Our experiments demonstrate new state-of-the-art performance gains in face and general SR across PSNR, SSIM, and LPIPS metrics. A notable finding is YODA's stabilization effect on training by reducing color shifts, especially when induced by small batch sizes, potentially contributing to resource-constrained scenarios. The proposed spatial and temporal adaptive diffusion mechanism opens promising research directions, including developing enhanced attention map extraction techniques and optimizing inference latency based on sparser diffusion.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的单图超解像方法“You Only Diffuse Areas”（YODA），它在单图超解像中实现了部分扩散。该方法基于低分辨率图像和当前扩散过程的注意力地图 selectively 实现了扩散。这种时间相关的目标设定，使得高分辨率输出更加有效地利用了迭代精度提高过程中的细节强项。我们经验 validate YODA 方法，并将其扩展到了领先的扩散基于 SISR 方法SR3和SRDiff。我们的实验表明，YODA 方法在 PSNR、SSIM 和 LPIPS 指标上均 achieve 新的状态泰施率表现。一个值得注意的发现是 YODA 方法在训练中的稳定化效果，尤其是在小批量引入时，可以降低颜色偏移，这可能对资源受限的场景产生贡献。The proposed spatial and temporal adaptive diffusion mechanism opens promising research directions, including developing enhanced attention map extraction techniques and optimizing inference latency based on sparser diffusion. 这种提出的空间和时间适应扩散机制，开启了许多有前途的研究方向，包括提高注意力地图提取技术和基于更加稀疏的扩散优化推理延迟。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Cross-Quality-Face-Verification-using-Blind-Face-Restoration"><a href="#Boosting-Cross-Quality-Face-Verification-using-Blind-Face-Restoration" class="headerlink" title="Boosting Cross-Quality Face Verification using Blind Face Restoration"></a>Boosting Cross-Quality Face Verification using Blind Face Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07967">http://arxiv.org/abs/2308.07967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Messaoud Bengherabi, Douaa Laib, Fella Souhila Lasnami, Ryma Boussaha</li>
<li>for: 这 paper 的目的是研究如何使用三种状态的盲面 restore 技术来提高人脸识别系统的性能，并保持人脸的有价值信息。</li>
<li>methods: 这 paper 使用的方法包括 GFP-GAN、GPEN 和 SGPN 三种盲面 restore 技术。</li>
<li>results: 实验结果表明，使用 GFP-GAN 技术可以大幅提高人脸识别系统的准确率，特别是在具有低质量图像的情况下。<details>
<summary>Abstract</summary>
In recent years, various Blind Face Restoration (BFR) techniques were developed. These techniques transform low quality faces suffering from multiple degradations to more realistic and natural face images with high perceptual quality. However, it is crucial for the task of face verification to not only enhance the perceptual quality of the low quality images but also to improve the biometric-utility face quality metrics. Furthermore, preserving the valuable identity information is of great importance. In this paper, we investigate the impact of applying three state-of-the-art blind face restoration techniques namely, GFP-GAN, GPEN and SGPN on the performance of face verification system under very challenging environment characterized by very low quality images. Extensive experimental results on the recently proposed cross-quality LFW database using three state-of-the-art deep face recognition models demonstrate the effectiveness of GFP-GAN in boosting significantly the face verification accuracy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CoDeF-Content-Deformation-Fields-for-Temporally-Consistent-Video-Processing"><a href="#CoDeF-Content-Deformation-Fields-for-Temporally-Consistent-Video-Processing" class="headerlink" title="CoDeF: Content Deformation Fields for Temporally Consistent Video Processing"></a>CoDeF: Content Deformation Fields for Temporally Consistent Video Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07926">http://arxiv.org/abs/2308.07926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qiuyu96/codef">https://github.com/qiuyu96/codef</a></li>
<li>paper_authors: Hao Ouyang, Qiuyu Wang, Yuxi Xiao, Qingyan Bai, Juntao Zhang, Kecheng Zheng, Xiaowei Zhou, Qifeng Chen, Yujun Shen</li>
<li>for: 这 paper 的目的是提出一种新型的视频表示方法，称为 Content Deformation Field (CoDeF)，用于重构视频。</li>
<li>methods: 这 paper 使用了一种新的渲染管道和一些注意力力学 régularization，使得 CoDeF 可以自然地支持提升图像算法，从而实现视频处理。</li>
<li>results: 实验表明，CoDeF 能够将图像-to-图像翻译提升到视频-to-视频翻译，并且可以自动地进行关键点检测和跟踪。此外，CoDeF 可以提供更高的横向一致性，并且可以跟踪非RIGID 对象如水和雾。<details>
<summary>Abstract</summary>
We present the content deformation field CoDeF as a new type of video representation, which consists of a canonical content field aggregating the static contents in the entire video and a temporal deformation field recording the transformations from the canonical image (i.e., rendered from the canonical content field) to each individual frame along the time axis.Given a target video, these two fields are jointly optimized to reconstruct it through a carefully tailored rendering pipeline.We advisedly introduce some regularizations into the optimization process, urging the canonical content field to inherit semantics (e.g., the object shape) from the video.With such a design, CoDeF naturally supports lifting image algorithms for video processing, in the sense that one can apply an image algorithm to the canonical image and effortlessly propagate the outcomes to the entire video with the aid of the temporal deformation field.We experimentally show that CoDeF is able to lift image-to-image translation to video-to-video translation and lift keypoint detection to keypoint tracking without any training.More importantly, thanks to our lifting strategy that deploys the algorithms on only one image, we achieve superior cross-frame consistency in processed videos compared to existing video-to-video translation approaches, and even manage to track non-rigid objects like water and smog.Project page can be found at https://qiuyu96.github.io/CoDeF/.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的视频表示方式：内容扭曲场（CoDeF），它包含一个核心内容场聚合整个视频中的静止内容，以及一个时间扭曲场记录每帧图像（即从核心内容场渲染后的图像）与时间轴上的变化。给定一个目标视频，这两个场合jointly 优化以重建它，通过我们特制的渲染管线。我们注意到了一些正则化，使得核心内容场继承视频中的 semantics（例如物体形状）。与此同时，我们还引入了一些正则化，使得核心内容场继承视频中的 semantics（例如物体形状）。这种设计使得CoDeF自然支持图像算法 для视频处理，即可以将图像算法应用于核心图像，并使用时间扭曲场将结果传播到整个视频中。我们实验表明，CoDeF可以将图像到图像翻译 lifted 到视频到视频翻译，并且可以使用图像算法来检测关键点，而不需要训练。此外，我们的提升策略只需要在一个图像上应用算法，从而实现了跨帧一致性更高的处理视频，甚至可以跟踪非RIGID的物体，如水和雾。项目页面可以在 <https://qiuyu96.github.io/CoDeF/> 找到。
</details></li>
</ul>
<hr>
<h2 id="Helping-Hands-An-Object-Aware-Ego-Centric-Video-Recognition-Model"><a href="#Helping-Hands-An-Object-Aware-Ego-Centric-Video-Recognition-Model" class="headerlink" title="Helping Hands: An Object-Aware Ego-Centric Video Recognition Model"></a>Helping Hands: An Object-Aware Ego-Centric Video Recognition Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07918">http://arxiv.org/abs/2308.07918</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chuhanxx/helping_hand_for_egocentric_videos">https://github.com/chuhanxx/helping_hand_for_egocentric_videos</a></li>
<li>paper_authors: Chuhan Zhang, Ankush Gupta, Andrew Zisserman</li>
<li>for: 提高 egocentric 视频中的空间时间表示性能</li>
<li>methods: 使用对象意识泛化器进行训练，通过对匹配的Caption进行预测，提高模型对象意识和视觉关系</li>
<li>results: 在零批量测试中表现出优于状态艺术，并在长期视频理解任务中表现出良好的表示能力，包括视频描述和视频存储等任务。<details>
<summary>Abstract</summary>
We introduce an object-aware decoder for improving the performance of spatio-temporal representations on ego-centric videos. The key idea is to enhance object-awareness during training by tasking the model to predict hand positions, object positions, and the semantic label of the objects using paired captions when available. At inference time the model only requires RGB frames as inputs, and is able to track and ground objects (although it has not been trained explicitly for this). We demonstrate the performance of the object-aware representations learnt by our model, by: (i) evaluating it for strong transfer, i.e. through zero-shot testing, on a number of downstream video-text retrieval and classification benchmarks; and (ii) by using the representations learned as input for long-term video understanding tasks (e.g. Episodic Memory in Ego4D). In all cases the performance improves over the state of the art -- even compared to networks trained with far larger batch sizes. We also show that by using noisy image-level detection as pseudo-labels in training, the model learns to provide better bounding boxes using video consistency, as well as grounding the words in the associated text descriptions. Overall, we show that the model can act as a drop-in replacement for an ego-centric video model to improve performance through visual-text grounding.
</details>
<details>
<summary>摘要</summary>
我们介绍一个对象意识decoder，用于改进自我中心视频的空间时间表示性能。关键思想是在训练过程中提高对象意识，通过在可用的paired captions中 зада务模型预测手势位置、物体位置和物体semantic标签。在推理时，模型只需要RGB帧作为输入，并能够跟踪和附加物体（尚未直接训练）。我们通过测试和分类benchmark数据集来评估模型的表示，并证明其在零基eline测试中具有强 Transfer Learning 性能。此外，我们还表明通过使用噪音图像级检测作为pseudo-标签，模型能够提供更好的 bounding box，同时还能够在相关文本描述中固定words。总之，我们表明该模型可以作为自我中心视频模型的替换，以提高视觉-文本固定性能。
</details></li>
</ul>
<hr>
<h2 id="A-Foundation-LAnguage-Image-model-of-the-Retina-FLAIR-Encoding-expert-knowledge-in-text-supervision"><a href="#A-Foundation-LAnguage-Image-model-of-the-Retina-FLAIR-Encoding-expert-knowledge-in-text-supervision" class="headerlink" title="A Foundation LAnguage-Image model of the Retina (FLAIR): Encoding expert knowledge in text supervision"></a>A Foundation LAnguage-Image model of the Retina (FLAIR): Encoding expert knowledge in text supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07898">http://arxiv.org/abs/2308.07898</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jusiro/flair">https://github.com/jusiro/flair</a></li>
<li>paper_authors: Julio Silva-Rodriguez, Hadi Chakor, Riadh Kobbi, Jose Dolz, Ismail Ben Ayed</li>
<li>for: This paper is written for developing a pre-trained vision-language model for universal retinal fundus image understanding, with the goal of improving the performance of domain-expert models in medical imaging.</li>
<li>methods: The paper uses a combination of open-access fundus imaging datasets and expert knowledge from clinical literature and community standards to pre-train and fine-tune a vision-language model called FLAIR. The model is adapted with a lightweight linear probe for zero-shot inference, and its performance is evaluated under various scenarios with domain shifts and unseen categories.</li>
<li>results: The paper reports that FLAIR outperforms fully-trained, dataset-focused models and more generalist, larger-scale image-language models in few-shot regimes, emphasizing the potential of embedding experts’ domain knowledge in medical imaging. Specifically, FLAIR achieves better performance in difficult scenarios with domain shifts or unseen categories, and outperforms more generalist models by a large margin.<details>
<summary>Abstract</summary>
Foundation vision-language models are currently transforming computer vision, and are on the rise in medical imaging fueled by their very promising generalization capabilities. However, the initial attempts to transfer this new paradigm to medical imaging have shown less impressive performances than those observed in other domains, due to the significant domain shift and the complex, expert domain knowledge inherent to medical-imaging tasks. Motivated by the need for domain-expert foundation models, we present FLAIR, a pre-trained vision-language model for universal retinal fundus image understanding. To this end, we compiled 37 open-access, mostly categorical fundus imaging datasets from various sources, with up to 97 different target conditions and 284,660 images. We integrate the expert's domain knowledge in the form of descriptive textual prompts, during both pre-training and zero-shot inference, enhancing the less-informative categorical supervision of the data. Such a textual expert's knowledge, which we compiled from the relevant clinical literature and community standards, describes the fine-grained features of the pathologies as well as the hierarchies and dependencies between them. We report comprehensive evaluations, which illustrate the benefit of integrating expert knowledge and the strong generalization capabilities of FLAIR under difficult scenarios with domain shifts or unseen categories. When adapted with a lightweight linear probe, FLAIR outperforms fully-trained, dataset-focused models, more so in the few-shot regimes. Interestingly, FLAIR outperforms by a large margin more generalist, larger-scale image-language models, which emphasizes the potential of embedding experts' domain knowledge and the limitations of generalist models in medical imaging.
</details>
<details>
<summary>摘要</summary>
医学影像领域的基础视言模型目前正在改变计算机视觉领域，并在医学影像领域得到推动。然而，初始的尝试将这新的思维方式应用到医学影像领域表现不如其他领域的表现，这是因为医学影像领域的领域转移和专业知识的复杂性。为了解决这问题，我们提出了FLAIR，一个预训练的视言模型，用于通用的肉眼血管图像理解。为此，我们收集了37个开放访问的、主要是分类的肉眼影像Dataset，共计284,660张图像，并将专业知识 integrate到模型中，以增强数据的不具备信息的分类指导。这些文本描述了疾病的细腻特征以及疾病之间和层次结构的相互关系。我们对FLAIR进行了全面的评估，其中包括域转移和未经见过的类目的场景。我们发现，通过 integrate专业知识，FLAIR在域转移和少量学习场景下表现出了强大的泛化能力，并且在不同的域转移和未经见过的类目场景下，FLAIR可以与专门设计的Dataset-FOCUSED模型进行比较，并在这些场景下表现出优异的表现。此外，我们发现，当FLAIR被拓展为一个轻量级线性探针时，其表现更为出色，特别是在几何学学习场景下。这表明，将专业知识 embedding到模型中和通用模型的局限性在医学影像领域中具有潜在的优势。
</details></li>
</ul>
<hr>
<h2 id="Memory-and-Anticipation-Transformer-for-Online-Action-Understanding"><a href="#Memory-and-Anticipation-Transformer-for-Online-Action-Understanding" class="headerlink" title="Memory-and-Anticipation Transformer for Online Action Understanding"></a>Memory-and-Anticipation Transformer for Online Action Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07893">http://arxiv.org/abs/2308.07893</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/echo0125/memory-and-anticipation-transformer">https://github.com/echo0125/memory-and-anticipation-transformer</a></li>
<li>paper_authors: Jiahao Wang, Guo Chen, Yifei Huang, Limin Wang, Tong Lu</li>
<li>for: 这篇论文是为了提出一种基于记忆和预测的新方法，用于在线动作检测和预测任务。</li>
<li>methods: 该方法基于记忆和预测的思想，提出了一种名为Memory-and-Anticipation Transformer（MAT）的新方法，可以同时处理在线动作检测和预测任务。</li>
<li>results: 对四个具有挑战性的标准 benchmark（TVSeries、THUMOS’14、HDD、EPIC-Kitchens-100）进行测试，MAT模型在在线动作检测和预测任务中具有显著的优异性，与现有方法相比显著超越。<details>
<summary>Abstract</summary>
Most existing forecasting systems are memory-based methods, which attempt to mimic human forecasting ability by employing various memory mechanisms and have progressed in temporal modeling for memory dependency. Nevertheless, an obvious weakness of this paradigm is that it can only model limited historical dependence and can not transcend the past. In this paper, we rethink the temporal dependence of event evolution and propose a novel memory-anticipation-based paradigm to model an entire temporal structure, including the past, present, and future. Based on this idea, we present Memory-and-Anticipation Transformer (MAT), a memory-anticipation-based approach, to address the online action detection and anticipation tasks. In addition, owing to the inherent superiority of MAT, it can process online action detection and anticipation tasks in a unified manner. The proposed MAT model is tested on four challenging benchmarks TVSeries, THUMOS'14, HDD, and EPIC-Kitchens-100, for online action detection and anticipation tasks, and it significantly outperforms all existing methods. Code is available at https://github.com/Echo0125/Memory-and-Anticipation-Transformer.
</details>
<details>
<summary>摘要</summary>
现有的预测系统多数是记忆基本方法，尝试模拟人类预测能力 by 使用不同的记忆机制，并进步在时间模型中。然而，这个思维模型的明显弱点是它只能模型有限的历史依赖，无法突破过去。在这篇文章中，我们重新思考了事件演化的时间依赖，并提出了一个新的记忆预测基本方法，可以模型整个时间结构，包括过去、现在和未来。基于这个想法，我们提出了记忆预测变换器（MAT），一种记忆预测基本方法，用于线上动作检测和预测任务。此外，由于MAT的内在优势，可以在线上进行动作检测和预测任务的统一处理。我们在四个具有挑战性的参考标准（TVSeries、THUMOS'14、HDD和EPIC-Kitchens-100）上进行了MAT模型的评估，并与所有现有的方法进行比较。结果显示MAT模型在线上动作检测和预测任务上具有杰出的表现。代码可以在<https://github.com/Echo0125/Memory-and-Anticipation-Transformer> 获取。
</details></li>
</ul>
<hr>
<h2 id="The-Challenge-of-Fetal-Cardiac-MRI-Reconstruction-Using-Deep-Learning"><a href="#The-Challenge-of-Fetal-Cardiac-MRI-Reconstruction-Using-Deep-Learning" class="headerlink" title="The Challenge of Fetal Cardiac MRI Reconstruction Using Deep Learning"></a>The Challenge of Fetal Cardiac MRI Reconstruction Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07885">http://arxiv.org/abs/2308.07885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Prokopenko, Kerstin Hammernik, Thomas Roberts, David F A Lloyd, Daniel Rueckert, Joseph V Hajnal</li>
<li>For: This paper explores the use of deep learning methods to improve the quality of non-gated kt-SENSE reconstruction for dynamic free-breathing fetal cardiac MRI.* Methods: The authors use supervised deep learning networks to reconstruct fully-sampled data from undersampled data, and consider various model architectures and training strategies for their application in a real clinical setup.* Results: The authors show that the best-performing models recover a detailed depiction of the maternal anatomy but underestimate the dynamic properties of the fetal heart, suggesting the need for more targeted training and evaluation methods for fetal heart applications.<details>
<summary>Abstract</summary>
Dynamic free-breathing fetal cardiac MRI is one of the most challenging modalities, which requires high temporal and spatial resolution to depict rapid changes in a small fetal heart. The ability of deep learning methods to recover undersampled data could help to optimise the kt-SENSE acquisition strategy and improve non-gated kt-SENSE reconstruction quality. In this work, we explore supervised deep learning networks for reconstruction of kt-SENSE style acquired data using an extensive in vivo dataset. Having access to fully-sampled low-resolution multi-coil fetal cardiac MRI, we study the performance of the networks to recover fully-sampled data from undersampled data. We consider model architectures together with training strategies taking into account their application in the real clinical setup used to collect the dataset to enable networks to recover prospectively undersampled data. We explore a set of modifications to form a baseline performance evaluation for dynamic fetal cardiac MRI on real data. We systematically evaluate the models on coil-combined data to reveal the effect of the suggested changes to the architecture in the context of fetal heart properties. We show that the best-performers recover a detailed depiction of the maternal anatomy on a large scale, but the dynamic properties of the fetal heart are under-represented. Training directly on multi-coil data improves the performance of the models, allows their prospective application to undersampled data and makes them outperform CTFNet introduced for adult cardiac cine MRI. However, these models deliver similar qualitative performances recovering the maternal body very well but underestimating the dynamic properties of fetal heart. This dynamic feature of fast change of fetal heart that is highly localised suggests both more targeted training and evaluation methods might be needed for fetal heart application.
</details>
<details>
<summary>摘要</summary>
干支持自由呼吸婴儿心脏MRI是最有挑战性的模式之一，需要高度的时间和空间分辨率来显示婴儿心脏中快速变化的小心脏。深度学习方法可以恢复扫描不足的数据，可以帮助优化kt-SENSE获取策略和非阻塞kt-SENSE重建质量。在这项工作中，我们使用了激活函数网络进行kt-SENSE样式数据重建，使用了大量的生物样本。由于我们拥有完整的低分辨率多极体婴儿心脏MRI数据，我们可以研究深度学习网络是否可以从扫描不足数据中恢复完整数据。我们考虑了模型架构和训练策略，以便在实际临床设置中收集数据时使用。我们系统地评估了模型在实际数据上的表现，并通过多极体数据组合来描述模型的改进效果。我们发现最佳表现者可以准确地重建大规模的 maternal anatomy，但是婴儿心脏的动态性尚未得到充分表现。通过直接在多极体数据上训练，模型可以预测扫描不足数据，并且在 adult cardiac cine MRI 中引入的 CTFNet 之上表现出色。然而，这些模型在Qualitative上具有类似表现，可以准确地重建 maternal body，但是婴儿心脏的动态特性尚未得到充分表现。这种婴儿心脏动态特性的快速变化和高度本地化表示，可能需要更Targeted的训练和评估方法来应用于婴儿心脏。
</details></li>
</ul>
<hr>
<h2 id="Advancements-in-Repetitive-Action-Counting-Joint-Based-PoseRAC-Model-With-Improved-Performance"><a href="#Advancements-in-Repetitive-Action-Counting-Joint-Based-PoseRAC-Model-With-Improved-Performance" class="headerlink" title="Advancements in Repetitive Action Counting: Joint-Based PoseRAC Model With Improved Performance"></a>Advancements in Repetitive Action Counting: Joint-Based PoseRAC Model With Improved Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08632">http://arxiv.org/abs/2308.08632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haodong Chen, Ming C. Leu, Md Moniruzzaman, Zhaozheng Yin, Solmaz Hajmohammadi, Zhuoqing Chang</li>
<li>for: 这篇论文的目的是提高复诵数据集（RepCount）的准确性和稳定性，并且能够实现更好的结果，比如运动追踪和重abilitation。</li>
<li>methods: 这篇论文使用了肢体角度和姿势点来处理复诵数据，并且结合了先前的工作([1])，以解决复诵数据的一些挑战，例如不稳定的摄像头视角、过归、缺数、难以区别子动作、不准确的识别精灵姿势等。</li>
<li>results: 这篇论文在RepCount数据集上取得了比前方法更好的结果，其中MAE为0.211，OBO准确率为0.599。实验结果显示了方法的效iveness和可靠性。<details>
<summary>Abstract</summary>
Repetitive counting (RepCount) is critical in various applications, such as fitness tracking and rehabilitation. Previous methods have relied on the estimation of red-green-and-blue (RGB) frames and body pose landmarks to identify the number of action repetitions, but these methods suffer from a number of issues, including the inability to stably handle changes in camera viewpoints, over-counting, under-counting, difficulty in distinguishing between sub-actions, inaccuracy in recognizing salient poses, etc. In this paper, based on the work done by [1], we integrate joint angles with body pose landmarks to address these challenges and achieve better results than the state-of-the-art RepCount methods, with a Mean Absolute Error (MAE) of 0.211 and an Off-By-One (OBO) counting accuracy of 0.599 on the RepCount data set [2]. Comprehensive experimental results demonstrate the effectiveness and robustness of our method.
</details>
<details>
<summary>摘要</summary>
重复计数（RepCount）在不同应用中具有重要意义，如健身和rehabilitation。先前的方法通过RGB帧和体姿特征来估计动作重复数，但这些方法受到许多问题的影响，包括视角变化不稳定、过 COUNT、下 COUNT、不能识别子动作、识别精准 pose 等问题。本文基于 [1] 的工作，将骨骼角度与体姿特征结合，以解决这些挑战并实现更好的结果，MAE 为 0.211，OBO 计数准确率为 0.599 在 RepCount 数据集上。广泛的实验结果证明了我们的方法的有效性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="SEDA-Self-Ensembling-ViT-with-Defensive-Distillation-and-Adversarial-Training-for-robust-Chest-X-rays-Classification"><a href="#SEDA-Self-Ensembling-ViT-with-Defensive-Distillation-and-Adversarial-Training-for-robust-Chest-X-rays-Classification" class="headerlink" title="SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial Training for robust Chest X-rays Classification"></a>SEDA: Self-Ensembling ViT with Defensive Distillation and Adversarial Training for robust Chest X-rays Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07874">http://arxiv.org/abs/2308.07874</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/razaimam45/seda">https://github.com/razaimam45/seda</a></li>
<li>paper_authors: Raza Imam, Ibrahim Almakky, Salma Alrashdi, Baketah Alrashdi, Mohammad Yaqub</li>
<li>For: This paper aims to enhance the robustness of self-ensembling ViTs for the tuberculosis chest x-ray classification task, in order to improve the reliability of Deep Learning methods in medical settings.* Methods: The proposed method, SEDA, utilizes efficient CNN blocks to learn spatial features with various levels of abstraction, and leverages adversarial training in combination with defensive distillation for improved robustness against adversaries.* Results: Extensive experiments performed with the proposed architecture and training paradigm on a publicly available Tuberculosis x-ray dataset show that SEDA achieves state-of-the-art (SOTA) efficacy compared to SEViT in terms of computational efficiency with 70x times lighter framework, and enhanced robustness of +9%.<details>
<summary>Abstract</summary>
Deep Learning methods have recently seen increased adoption in medical imaging applications. However, elevated vulnerabilities have been explored in recent Deep Learning solutions, which can hinder future adoption. Particularly, the vulnerability of Vision Transformer (ViT) to adversarial, privacy, and confidentiality attacks raise serious concerns about their reliability in medical settings. This work aims to enhance the robustness of self-ensembling ViTs for the tuberculosis chest x-ray classification task. We propose Self-Ensembling ViT with defensive Distillation and Adversarial training (SEDA). SEDA utilizes efficient CNN blocks to learn spatial features with various levels of abstraction from feature representations extracted from intermediate ViT blocks, that are largely unaffected by adversarial perturbations. Furthermore, SEDA leverages adversarial training in combination with defensive distillation for improved robustness against adversaries. Training using adversarial examples leads to better model generalizability and improves its ability to handle perturbations. Distillation using soft probabilities introduces uncertainty and variation into the output probabilities, making it more difficult for adversarial and privacy attacks. Extensive experiments performed with the proposed architecture and training paradigm on publicly available Tuberculosis x-ray dataset shows SOTA efficacy of SEDA compared to SEViT in terms of computational efficiency with 70x times lighter framework and enhanced robustness of +9%.
</details>
<details>
<summary>摘要</summary>
SEDA uses efficient convolutional neural network (CNN) blocks to learn spatial features with different levels of abstraction from the feature representations extracted from intermediate ViT blocks. These features are less affected by adversarial perturbations. Additionally, SEDA uses adversarial training in combination with defensive distillation to improve the model's robustness against adversaries. Training with adversarial examples improves the model's ability to handle perturbations, while distillation using soft probabilities introduces uncertainty and variation into the output probabilities, making it more difficult for adversarial and privacy attacks.We evaluated the proposed architecture and training paradigm on a publicly available tuberculosis x-ray dataset and found that SEDA outperformed the existing SEViT method in terms of computational efficiency, with a 70 times lighter framework, and enhanced robustness, with a +9% improvement.
</details></li>
</ul>
<hr>
<h2 id="ObjectSDF-Improved-Object-Compositional-Neural-Implicit-Surfaces"><a href="#ObjectSDF-Improved-Object-Compositional-Neural-Implicit-Surfaces" class="headerlink" title="ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces"></a>ObjectSDF++: Improved Object-Compositional Neural Implicit Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07868">http://arxiv.org/abs/2308.07868</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qianyiwu/objectsdf_plus">https://github.com/qianyiwu/objectsdf_plus</a></li>
<li>paper_authors: Qianyi Wu, Kaisiyuan Wang, Kejie Li, Jianmin Zheng, Jianfei Cai</li>
<li>for: This paper focuses on improving the performance of neural implicit surface-based methods for multi-view 3D reconstruction, with a particular emphasis on reconstructing individual objects within a scene.</li>
<li>methods: The proposed framework, called ObjectSDF++, utilizes an occlusion-aware object opacity rendering formulation and a novel regularization term for object distinction to improve the quality of object reconstruction.</li>
<li>results: The extensive experiments conducted in the paper demonstrate that ObjectSDF++ produces superior object reconstruction results and significantly improves the quality of scene reconstruction compared to the previous state-of-the-art method, ObjectSDF.Here’s the full text in Simplified Chinese:</li>
<li>for: 本文关注使用神经隐式表面基于多视图3D重建的方法，特别是在Scene中重建个体对象。</li>
<li>methods: 提出的方法是ObjectSDF++，它利用遮盲对象 opacity 渲染表示法和对象分辨率正则项来提高对象重建质量。</li>
<li>results: 实验结果表明，ObjectSDF++ 比之前的状态 искусственный方法ObjectSDF更好地重建对象和Scene。<details>
<summary>Abstract</summary>
In recent years, neural implicit surface reconstruction has emerged as a popular paradigm for multi-view 3D reconstruction. Unlike traditional multi-view stereo approaches, the neural implicit surface-based methods leverage neural networks to represent 3D scenes as signed distance functions (SDFs). However, they tend to disregard the reconstruction of individual objects within the scene, which limits their performance and practical applications. To address this issue, previous work ObjectSDF introduced a nice framework of object-composition neural implicit surfaces, which utilizes 2D instance masks to supervise individual object SDFs. In this paper, we propose a new framework called ObjectSDF++ to overcome the limitations of ObjectSDF. First, in contrast to ObjectSDF whose performance is primarily restricted by its converted semantic field, the core component of our model is an occlusion-aware object opacity rendering formulation that directly volume-renders object opacity to be supervised with instance masks. Second, we design a novel regularization term for object distinction, which can effectively mitigate the issue that ObjectSDF may result in unexpected reconstruction in invisible regions due to the lack of constraint to prevent collisions. Our extensive experiments demonstrate that our novel framework not only produces superior object reconstruction results but also significantly improves the quality of scene reconstruction. Code and more resources can be found in \url{https://qianyiwu.github.io/objectsdf++}
</details>
<details>
<summary>摘要</summary>
Recently, neural implicit surface reconstruction has become a popular paradigm for multi-view 3D reconstruction. Unlike traditional multi-view stereo methods, neural implicit surface-based methods use neural networks to represent 3D scenes as signed distance functions (SDFs). However, these methods often neglect the reconstruction of individual objects within the scene, which limits their performance and practical applications. To address this issue, previous work ObjectSDF proposed a framework of object-composition neural implicit surfaces, which uses 2D instance masks to supervise individual object SDFs. In this paper, we propose a new framework called ObjectSDF++ to overcome the limitations of ObjectSDF. First, our model uses an occlusion-aware object opacity rendering formulation that directly volume-renders object opacity to be supervised with instance masks, which improves performance compared to ObjectSDF. Second, we design a novel regularization term for object distinction, which can effectively mitigate the issue that ObjectSDF may result in unexpected reconstruction in invisible regions due to the lack of constraint to prevent collisions. Our extensive experiments show that our novel framework not only produces superior object reconstruction results but also significantly improves the quality of scene reconstruction. Code and more resources can be found at \url{https://qianyiwu.github.io/objectsdf++}.
</details></li>
</ul>
<hr>
<h2 id="StyleDiffusion-Controllable-Disentangled-Style-Transfer-via-Diffusion-Models"><a href="#StyleDiffusion-Controllable-Disentangled-Style-Transfer-via-Diffusion-Models" class="headerlink" title="StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models"></a>StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07863">http://arxiv.org/abs/2308.07863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhizhong Wang, Lei Zhao, Wei Xing</li>
<li>for: 本研究旨在提出一种新的内容-风格（C-S）分离框架，用于实现风格传输。</li>
<li>methods: 该框架利用内存抽象和隐藏学习来实现C-S分离，并通过CLIP图像空间的自适应分离损失和样式重建优化来实现可控的C-S分离和风格传输。</li>
<li>results: 该框架在比较之上超越了现有的状态对抗方法，并可以实现高质量的C-S分离和风格传输，以及灵活的C-S分离和控制质量之间的质量。<details>
<summary>Abstract</summary>
Content and style (C-S) disentanglement is a fundamental problem and critical challenge of style transfer. Existing approaches based on explicit definitions (e.g., Gram matrix) or implicit learning (e.g., GANs) are neither interpretable nor easy to control, resulting in entangled representations and less satisfying results. In this paper, we propose a new C-S disentangled framework for style transfer without using previous assumptions. The key insight is to explicitly extract the content information and implicitly learn the complementary style information, yielding interpretable and controllable C-S disentanglement and style transfer. A simple yet effective CLIP-based style disentanglement loss coordinated with a style reconstruction prior is introduced to disentangle C-S in the CLIP image space. By further leveraging the powerful style removal and generative ability of diffusion models, our framework achieves superior results than state of the art and flexible C-S disentanglement and trade-off control. Our work provides new insights into the C-S disentanglement in style transfer and demonstrates the potential of diffusion models for learning well-disentangled C-S characteristics.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/cs.CV_2023_08_16/" data-id="clorjzl6900gwf188bd0tfntl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/16/cs.AI_2023_08_16/" class="article-date">
  <time datetime="2023-08-16T12:00:00.000Z" itemprop="datePublished">2023-08-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/16/cs.AI_2023_08_16/">cs.AI - 2023-08-16</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="On-the-Augmentation-of-Cognitive-Accuracy-and-Cognitive-Precision-in-Human-Cog-Ensembles"><a href="#On-the-Augmentation-of-Cognitive-Accuracy-and-Cognitive-Precision-in-Human-Cog-Ensembles" class="headerlink" title="On the Augmentation of Cognitive Accuracy and Cognitive Precision in Human&#x2F;Cog Ensembles"></a>On the Augmentation of Cognitive Accuracy and Cognitive Precision in Human&#x2F;Cog Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08581">http://arxiv.org/abs/2308.08581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ron Fulbright</li>
<li>for: 这些研究是为了探索人类使用工具时的表现是如何改善的。</li>
<li>methods: 这些研究使用了新型的认知系统，称为“cogs”，以实现人类认知增强。</li>
<li>results: 研究发现，人类和认知系统之间的合作对话可以提高人类认知精度和准确性，并且不同类型的信息可以帮助提高人类的创造力和解决问题能力。<details>
<summary>Abstract</summary>
Whenever humans use tools human performance is enhanced. Cognitive systems are a new kind of tool continually increasing in cognitive capability and are now performing high level cognitive tasks previously thought to be explicitly human. Usage of such tools, known as cogs, are expected to result in ever increasing levels of human cognitive augmentation. In a human cog ensemble, a cooperative, peer to peer, and collaborative dialog between a human and a cognitive system, human cognitive capability is augmented as a result of the interaction. The human cog ensemble is therefore able to achieve more than just the human or the cog working alone. This article presents results from two studies designed to measure the effect information supplied by a cog has on cognitive accuracy, the ability to produce the correct result, and cognitive precision, the propensity to produce only the correct result. Both cognitive accuracy and cognitive precision are shown to be increased by information of different types (policies and rules, examples, and suggestions) and with different kinds of problems (inventive problem solving and puzzles). Similar effects shown in other studies are compared.
</details>
<details>
<summary>摘要</summary>
This article presents the results of two studies that measured the effect of information supplied by a cog on cognitive accuracy, the ability to produce the correct result, and cognitive precision, the tendency to produce only the correct result. The studies found that both cognitive accuracy and cognitive precision were increased by information of different types (policies and rules, examples, and suggestions) and with different types of problems (inventive problem-solving and puzzles). Similar effects have been shown in other studies.
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-clinical-risk-prediction-a-survey-of-concepts-methods-and-modalities"><a href="#Explainable-AI-for-clinical-risk-prediction-a-survey-of-concepts-methods-and-modalities" class="headerlink" title="Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities"></a>Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08407">http://arxiv.org/abs/2308.08407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Munib Mesinovic, Peter Watkinson, Tingting Zhu</li>
<li>for: 这篇论文旨在探讨人工智能应用于医疗领域中的优化和可解释性，以及这些系统在诊断和疾病预测中的应用。</li>
<li>methods: 论文使用了多种可解释性方法，包括对于诊断和预测的可解释性评估、实验设计和synthetic dataset的应用，以及对于不同类型的资料的处理和分析。</li>
<li>results: 论文总结了过去几年来对于可解释性的研究和发展，包括各种可解释性方法的应用和评估，以及这些方法在实际应用中的成果。<details>
<summary>Abstract</summary>
Recent advancements in AI applications to healthcare have shown incredible promise in surpassing human performance in diagnosis and disease prognosis. With the increasing complexity of AI models, however, concerns regarding their opacity, potential biases, and the need for interpretability. To ensure trust and reliability in AI systems, especially in clinical risk prediction models, explainability becomes crucial. Explainability is usually referred to as an AI system's ability to provide a robust interpretation of its decision-making logic or the decisions themselves to human stakeholders. In clinical risk prediction, other aspects of explainability like fairness, bias, trust, and transparency also represent important concepts beyond just interpretability. In this review, we address the relationship between these concepts as they are often used together or interchangeably. This review also discusses recent progress in developing explainable models for clinical risk prediction, highlighting the importance of quantitative and clinical evaluation and validation across multiple common modalities in clinical practice. It emphasizes the need for external validation and the combination of diverse interpretability methods to enhance trust and fairness. Adopting rigorous testing, such as using synthetic datasets with known generative factors, can further improve the reliability of explainability methods. Open access and code-sharing resources are essential for transparency and reproducibility, enabling the growth and trustworthiness of explainable research. While challenges exist, an end-to-end approach to explainability in clinical risk prediction, incorporating stakeholders from clinicians to developers, is essential for success.
</details>
<details>
<summary>摘要</summary>
In this review, we discuss the relationship between these concepts and how they are often used together or interchangeably. We also highlight recent progress in developing explainable models for clinical risk prediction, emphasizing the importance of quantitative and clinical evaluation and validation across multiple common modalities in clinical practice. External validation and the combination of diverse interpretability methods are essential to enhance trust and fairness.To improve the reliability of explainability methods, rigorous testing using synthetic datasets with known generative factors is necessary. Open access and code-sharing resources are also crucial for transparency and reproducibility, enabling the growth and trustworthiness of explainable research.While challenges exist, an end-to-end approach to explainability in clinical risk prediction, involving stakeholders from clinicians to developers, is essential for success. By addressing these challenges, we can ensure that AI systems are trustworthy, fair, and effective in improving healthcare outcomes.Simplified Chinese translation:最近，人工智能在医疗领域的应用发展呈现了无比惊人的扩展性，超越了人类的诊断和疾病预测性能。然而，随着AI模型的复杂度的增加，对其透明度、可能的偏见和解释性的关注也在增加。为保证AI系统的信任和可靠性，特别是在临床风险预测模型中，解释性变得非常重要。解释性指AI系统能够提供明确、可理解的决策逻辑或决策的解释给人类潜在涉及者。在临床风险预测中，其他的解释性方面，如公平、偏见、信任和透明度，也是非常重要的。在这篇文章中，我们讨论了这些概念之间的关系，以及它们在一起或互换使用的情况。我们还强调了最近在临床风险预测中发展的解释性模型的进展，强调了评估和验证的重要性，以及在多种常见的模式上进行评估和验证的必要性。外部验证和多种解释性方法的组合是重要的，以增强信任和公平。为提高解释性方法的可靠性，使用知generate的synthetic dataset是非常重要的。开源和分享代码资源也是非常重要的，以便透明度和可重现性。虽然存在挑战，但是在临床风险预测中的解释性研究需要一个综合的方法，涉及临床医生到开发者的潜在涉及者。通过解决这些挑战，我们可以确保AI系统是可靠的，公平的，并能够改善医疗结果。
</details></li>
</ul>
<hr>
<h2 id="PDPK-A-Framework-to-Synthesise-Process-Data-and-Corresponding-Procedural-Knowledge-for-Manufacturing"><a href="#PDPK-A-Framework-to-Synthesise-Process-Data-and-Corresponding-Procedural-Knowledge-for-Manufacturing" class="headerlink" title="PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing"></a>PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08371">http://arxiv.org/abs/2308.08371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/0x14d/embedding-operator-knowledge">https://github.com/0x14d/embedding-operator-knowledge</a></li>
<li>paper_authors: Richard Nordsieck, André Schweizer, Michael Heider, Jörg Hähner</li>
<li>for: 该论文主要是为了提供一种生成人工智能数据的框架，以便在不同领域进行应用。</li>
<li>methods: 该论文使用了 Resource Description Framework (RDF) 格式的知识图来表示过程知识，并模拟了参数化过程以生成一些合理的数据。</li>
<li>results: 该论文通过对生成的数据进行评估，发现一些已有的嵌入方法在表示过程知识方面具有潜在的优势。同时，该论文还提供了一个开源的框架和评估代码，以便将来的研究者可以更容易地进行比较。<details>
<summary>Abstract</summary>
Procedural knowledge describes how to accomplish tasks and mitigate problems. Such knowledge is commonly held by domain experts, e.g. operators in manufacturing who adjust parameters to achieve quality targets. To the best of our knowledge, no real-world datasets containing process data and corresponding procedural knowledge are publicly available, possibly due to corporate apprehensions regarding the loss of knowledge advances. Therefore, we provide a framework to generate synthetic datasets that can be adapted to different domains. The design choices are inspired by two real-world datasets of procedural knowledge we have access to. Apart from containing representations of procedural knowledge in Resource Description Framework (RDF)-compliant knowledge graphs, the framework simulates parametrisation processes and provides consistent process data. We compare established embedding methods on the resulting knowledge graphs, detailing which out-of-the-box methods have the potential to represent procedural knowledge. This provides a baseline which can be used to increase the comparability of future work. Furthermore, we validate the overall characteristics of a synthesised dataset by comparing the results to those achievable on a real-world dataset. The framework and evaluation code, as well as the dataset used in the evaluation, are available open source.
</details>
<details>
<summary>摘要</summary>
过程知识描述如何完成任务和解决问题。这种知识通常由领域专家拥有，例如制造业中的操作员，他们根据参数进行调整以达到质量目标。到目前为止，我们知道没有公开可用的现实世界数据集，可能由于企业对知识前进的担忧。因此，我们提供了一个框架，可以生成可靠的 sintetic 数据集，可以适应不同领域。该框架灵感来自我们有 Access 到的两个真实世界过程知识数据集。除了包含过程知识的资源描述框架（RDF）Compatible 知识图，该框架还模拟参数化过程，提供一致的过程数据。我们使用现成的嵌入方法对所获知识图进行评估， detailing 哪些方法有可能表示过程知识。这提供了一个基准，可以用于将来的研究比较可读性。此外，我们验证了生成的数据集的总特征，与真实世界数据集的结果进行比较。框架和评估代码，以及用于评估的数据集，都是开源的。
</details></li>
</ul>
<hr>
<h2 id="Agglomerative-Transformer-for-Human-Object-Interaction-Detection"><a href="#Agglomerative-Transformer-for-Human-Object-Interaction-Detection" class="headerlink" title="Agglomerative Transformer for Human-Object Interaction Detection"></a>Agglomerative Transformer for Human-Object Interaction Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08370">http://arxiv.org/abs/2308.08370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danyang Tu, Wei Sun, Guangtao Zhai, Wei Shen</li>
<li>for: 提高人物对象交互检测器的性能</li>
<li>methods: 使用动态聚类和文本引导来生成实例token，并与传统 transformer encoder 集成，以获得更好的特征学习和实例级别征料提取</li>
<li>results: 在 HICO-Det 上达到了36.75 mAP的新州OF-the-art性能，并且在具有单个阶段和端到端结构的情况下，提高了8.5%的GFLOPs和36%的FPS<details>
<summary>Abstract</summary>
We propose an agglomerative Transformer (AGER) that enables Transformer-based human-object interaction (HOI) detectors to flexibly exploit extra instance-level cues in a single-stage and end-to-end manner for the first time. AGER acquires instance tokens by dynamically clustering patch tokens and aligning cluster centers to instances with textual guidance, thus enjoying two benefits: 1) Integrality: each instance token is encouraged to contain all discriminative feature regions of an instance, which demonstrates a significant improvement in the extraction of different instance-level cues and subsequently leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need of an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues for HOI detection in a single-stage and end-to-end pipeline. Concretely, AGER reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla DETR-like pipeline without extra cue extraction.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>一体性：每个实例token被鼓励包含所有细节特征区域，从而显著提高了不同实例级cue的提取，并 ultimately leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on HICO-Det.2. 效率：动态 clustering mechanism allows AGER to generate instance tokens jointly with the feature learning of the Transformer encoder, eliminating the need for an additional object detector or instance decoder in prior methods, thus allowing the extraction of desirable extra cues for HOI detection in a single-stage and end-to-end pipeline.Concretely, AGER reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla DETR-like pipeline without extra cue extraction.</details></li>
</ol>
<hr>
<h2 id="Is-Meta-Learning-the-Right-Approach-for-the-Cold-Start-Problem-in-Recommender-Systems"><a href="#Is-Meta-Learning-the-Right-Approach-for-the-Cold-Start-Problem-in-Recommender-Systems" class="headerlink" title="Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?"></a>Is Meta-Learning the Right Approach for the Cold-Start Problem in Recommender Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08354">http://arxiv.org/abs/2308.08354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Buffelli, Ashish Gupta, Agnieszka Strzalka, Vassilis Plachouras<br>for:This paper aims to address the cold-start problem in deep learning models for recommender systems, specifically exploring the use of standard and widely adopted deep learning models and a simple modular approach for achieving similar or higher performance without using meta-learning techniques.methods:The paper employs a variety of deep learning models, including standard and widely adopted models, and compares their performance with meta-learning models specifically designed for the cold-start setting. The authors also propose a simple modular approach using common representation learning techniques.results:The authors show that, when tuned correctly, standard and widely adopted deep learning models perform just as well as newer meta-learning models on commonly used benchmarks for the cold-start problem. Additionally, the simple modular approach using common representation learning techniques performs comparably to meta-learning techniques specifically designed for the cold-start setting while being much more easily deployable in real-world applications.<details>
<summary>Abstract</summary>
Recommender systems have become fundamental building blocks of modern online products and services, and have a substantial impact on user experience. In the past few years, deep learning methods have attracted a lot of research, and are now heavily used in modern real-world recommender systems. Nevertheless, dealing with recommendations in the cold-start setting, e.g., when a user has done limited interactions in the system, is a problem that remains far from solved. Meta-learning techniques, and in particular optimization-based meta-learning, have recently become the most popular approaches in the academic research literature for tackling the cold-start problem in deep learning models for recommender systems. However, current meta-learning approaches are not practical for real-world recommender systems, which have billions of users and items, and strict latency requirements. In this paper we show that it is possible to obtaining similar, or higher, performance on commonly used benchmarks for the cold-start problem without using meta-learning techniques. In more detail, we show that, when tuned correctly, standard and widely adopted deep learning models perform just as well as newer meta-learning models. We further show that an extremely simple modular approach using common representation learning techniques, can perform comparably to meta-learning techniques specifically designed for the cold-start setting while being much more easily deployable in real-world applications.
</details>
<details>
<summary>摘要</summary>
现代在线产品和服务中，推荐系统已成为基本结构的一部分，对用户体验产生了深见的影响。过去几年，深度学习方法在研究中吸引了很多注目，现在在现实世界中广泛应用于现代推荐系统中。然而，在冷启动设定下（例如，用户在系统中做的交互有限），仍然是一个未解决的问题。学术研究文献中，最受欢迎的方法是使用meta-学习技术来解决冷启动问题在深度学习模型中。然而，现有的meta-学习方法在实际应用中并不实用，因为它们需要大量的用户和项目数据，并且具有严格的响应时间要求。在这篇论文中，我们表明可以在常用的benchmark测试中达到相似或更高的性能，而不需要使用meta-学习技术。具体来说，当正确地调整的标准和广泛采用的深度学习模型，它们可以与更新的meta-学习模型相比，达到类似或更高的性能。此外，我们还显示了一种非常简单的模块化方法，使用通用表示学习技术，可以与特定的冷启动设定相比，并且可以在实际应用中更加容易进行部署。</sys>Here's the translation in Simplified Chinese:现代在线产品和服务中，推荐系统已成为基本结构的一部分，对用户体验产生了深见的影响。过去几年，深度学习方法在研究中吸引了很多注目，现在在现实世界中广泛应用于现代推荐系统中。然而，在冷启动设定下（例如，用户在系统中做的交互有限），仍然是一个未解决的问题。学术研究文献中，最受欢迎的方法是使用meta-学习技术来解决冷启动问题在深度学习模型中。然而，现有的meta-学习方法在实际应用中并不实用，因为它们需要大量的用户和项目数据，并且具有严格的响应时间要求。在这篇论文中，我们表明可以在常用的benchmark测试中达到相似或更高的性能，而不需要使用meta-学习技术。具体来说，当正确地调整的标准和广泛采用的深度学习模型，它们可以与更新的meta-学习模型相比，达到类似或更高的性能。此外，我们还显示了一种非常简单的模块化方法，使用通用表示学习技术，可以与特定的冷启动设定相比，并且可以在实际应用中更加容易进行部署。
</details></li>
</ul>
<hr>
<h2 id="Graph-Out-of-Distribution-Generalization-with-Controllable-Data-Augmentation"><a href="#Graph-Out-of-Distribution-Generalization-with-Controllable-Data-Augmentation" class="headerlink" title="Graph Out-of-Distribution Generalization with Controllable Data Augmentation"></a>Graph Out-of-Distribution Generalization with Controllable Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08344">http://arxiv.org/abs/2308.08344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Lu, Xiaoying Gan, Ze Zhao, Shiyu Liang, Luoyi Fu, Xinbing Wang, Chenghu Zhou</li>
<li>for: 本研究旨在解决图像分类中的数据分布偏移问题，提高图像分类模型的稳定性和泛化能力。</li>
<li>methods: 本文提出了一种控制数据增强技术，包括提取图像理解信息，生成偏移后的虚拟样本，并利用极值理论来评估虚拟样本对模型的影响。</li>
<li>results: 对多个实际数据集进行了广泛的研究，并证明了该方法在比基eline模型具有显著的优势。<details>
<summary>Abstract</summary>
Graph Neural Network (GNN) has demonstrated extraordinary performance in classifying graph properties. However, due to the selection bias of training and testing data (e.g., training on small graphs and testing on large graphs, or training on dense graphs and testing on sparse graphs), distribution deviation is widespread. More importantly, we often observe \emph{hybrid structure distribution shift} of both scale and density, despite of one-sided biased data partition. The spurious correlations over hybrid distribution deviation degrade the performance of previous GNN methods and show large instability among different datasets. To alleviate this problem, we propose \texttt{OOD-GMixup} to jointly manipulate the training distribution with \emph{controllable data augmentation} in metric space. Specifically, we first extract the graph rationales to eliminate the spurious correlations due to irrelevant information. Secondly, we generate virtual samples with perturbation on graph rationale representation domain to obtain potential OOD training samples. Finally, we propose OOD calibration to measure the distribution deviation of virtual samples by leveraging Extreme Value Theory, and further actively control the training distribution by emphasizing the impact of virtual OOD samples. Extensive studies on several real-world datasets on graph classification demonstrate the superiority of our proposed method over state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
格 Graf儿 Neural Network（GNN）在分类图像的表现非常出色。然而，由于训练和测试数据的选择偏袋（如训练小图和测试大图，或训练稠密图和测试稀疏图），导致分布偏移广泛存在。更重要的是，我们经常观察到 hybrid 结构分布偏移，即 both scale 和 density 的偏移，尽管数据分区存在一侧偏袋。这些偏移导致过去的 GNN 方法的性能下降，并在不同的 dataset 中显示出大的不稳定性。为解决这问题，我们提出了 \texttt{OOD-GMixup}，它通过在 metric 空间中控制数据增强来同时做出一些可控的数据增强。具体来说，我们首先提取图像的理据，以消除由无关信息引起的假象相关性。然后，我们生成了基于图像理据表示域的虚拟样本，以获得可能的 OOD 训练样本。最后，我们提出了 OOD 校准，通过激活EXTREME Value Theory，以量化虚拟 OOD 样本的分布偏移，并进一步控制训练分布。我们对一些实际世界的图像分类任务进行了广泛的研究，并证明了我们的提议方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Logic-Programs-by-Discovering-Higher-Order-Abstractions"><a href="#Learning-Logic-Programs-by-Discovering-Higher-Order-Abstractions" class="headerlink" title="Learning Logic Programs by Discovering Higher-Order Abstractions"></a>Learning Logic Programs by Discovering Higher-Order Abstractions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08334">http://arxiv.org/abs/2308.08334</a></li>
<li>repo_url: None</li>
<li>paper_authors: Céline Hocquette, Sebastijan Dumančić, Andrew Cropper</li>
<li>for: 本研究旨在找到更高级别的抽象，以实现人类水平的AI。</li>
<li>methods: 该方法基于逻辑编程，从示例和背景知识中逻辑程序的induction。</li>
<li>results: 对多个领域的实验表明，STEVIE可以提高预测精度27%，降低学习时间47%。此外，STEVIE还可以找到可以在不同领域中传递的抽象。<details>
<summary>Abstract</summary>
Discovering novel abstractions is important for human-level AI. We introduce an approach to discover higher-order abstractions, such as map, filter, and fold. We focus on inductive logic programming, which induces logic programs from examples and background knowledge. We introduce the higher-order refactoring problem, where the goal is to compress a logic program by introducing higher-order abstractions. We implement our approach in STEVIE, which formulates the higher-order refactoring problem as a constraint optimisation problem. Our experimental results on multiple domains, including program synthesis and visual reasoning, show that, compared to no refactoring, STEVIE can improve predictive accuracies by 27% and reduce learning times by 47%. We also show that STEVIE can discover abstractions that transfer to different domains
</details>
<details>
<summary>摘要</summary>
发现新的抽象是人工智能达到人类水平的关键。我们介绍了一种方法，用于发现更高一级的抽象，如地图、筛选和折叠。我们专注于逻辑编程，即从示例和背景知识中逻辑程序的生成。我们介绍了更高一级 refactoring 问题，其目标是通过引入更高一级抽象来压缩逻辑程序。我们在 STEVIE 中实现了这种方法，将更高一级 refactoring 问题转化为约束优化问题。我们的实验结果表明，相比无 refactoring，STEVIE 可以提高预测精度27%，降低学习时间47%。我们还表明，STEVIE 可以发现可以在不同领域传递的抽象。
</details></li>
</ul>
<hr>
<h2 id="A-Framework-for-Data-Driven-Explainability-in-Mathematical-Optimization"><a href="#A-Framework-for-Data-Driven-Explainability-in-Mathematical-Optimization" class="headerlink" title="A Framework for Data-Driven Explainability in Mathematical Optimization"></a>A Framework for Data-Driven Explainability in Mathematical Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08309">http://arxiv.org/abs/2308.08309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kevin-Martin Aigner, Marc Goerigk, Michael Hartisch, Frauke Liers, Arthur Miehlich</li>
<li>for: 提高各种大规模实际问题的解决效率，使其可以快速解决很多以前被视为不可解决的问题。</li>
<li>methods: 使用了解释性的评价标准，与优化软件的黑盒问题相关。</li>
<li>results: 提出了一种新的评价标准，即解释性，并在简单情况下证明了其NP困难性。同时，对于简单的路径问题，提出了一种可解释的模型，并进行了数值实验，显示了解释性的成本很低。<details>
<summary>Abstract</summary>
Advancements in mathematical programming have made it possible to efficiently tackle large-scale real-world problems that were deemed intractable just a few decades ago. However, provably optimal solutions may not be accepted due to the perception of optimization software as a black box. Although well understood by scientists, this lacks easy accessibility for practitioners. Hence, we advocate for introducing the explainability of a solution as another evaluation criterion, next to its objective value, which enables us to find trade-off solutions between these two criteria. Explainability is attained by comparing against (not necessarily optimal) solutions that were implemented in similar situations in the past. Thus, solutions are preferred that exhibit similar features. Although we prove that already in simple cases the explainable model is NP-hard, we characterize relevant polynomially solvable cases such as the explainable shortest-path problem. Our numerical experiments on both artificial as well as real-world road networks show the resulting Pareto front. It turns out that the cost of enforcing explainability can be very small.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)数学编程技术的进步使得可以有效地解决大规模的实际问题，这些问题前不久被视为不可解决的。然而，可证优解可能不会被接受，因为优化软件被视为黑盒子。虽然科学家们很好地理解这些技术，但是这lacks easy accessibility for practitioners。因此，我们提议将解释性作为评价标准之一，以便找到这两个标准之间的平衡解。解释性通过对过去在类似情况下实现的解 compare，以实现。因此，解决方案会受到类似特征的影响。虽然我们证明了简单情况下的解释模型是NP困难的，但我们描述了可解 polynomially solvable cases，如解释最短路问题。我们在人工和实际道路网络上进行了数值实验，显示了结果的Pareto前沿。结果显示，强制执行解释性的成本很小。
</details></li>
</ul>
<hr>
<h2 id="Integrating-cognitive-map-learning-and-active-inference-for-planning-in-ambiguous-environments"><a href="#Integrating-cognitive-map-learning-and-active-inference-for-planning-in-ambiguous-environments" class="headerlink" title="Integrating cognitive map learning and active inference for planning in ambiguous environments"></a>Integrating cognitive map learning and active inference for planning in ambiguous environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08307">http://arxiv.org/abs/2308.08307</a></li>
<li>repo_url: None</li>
<li>paper_authors: Toon Van de Maele, Bart Dhoedt, Tim Verbelen, Giovanni Pezzulo</li>
<li>for: 本研究旨在探讨如何将认知地图与计划机制 integrate 以提高生物体在不确定环境中的导航能力。</li>
<li>methods: 本研究使用了一种统计学模型来描述认知地图的形成，并将其 integrate 到一个活动推理Agent中，以支持在不确定情况下的计划。</li>
<li>results: 研究发现，使用活动推理Agent可以在复杂情况下更有效地进行计划，而且在感知观察提供了不确定信息时，其效果更加出色。<details>
<summary>Abstract</summary>
Living organisms need to acquire both cognitive maps for learning the structure of the world and planning mechanisms able to deal with the challenges of navigating ambiguous environments. Although significant progress has been made in each of these areas independently, the best way to integrate them is an open research question. In this paper, we propose the integration of a statistical model of cognitive map formation within an active inference agent that supports planning under uncertainty. Specifically, we examine the clone-structured cognitive graph (CSCG) model of cognitive map formation and compare a naive clone graph agent with an active inference-driven clone graph agent, in three spatial navigation scenarios. Our findings demonstrate that while both agents are effective in simple scenarios, the active inference agent is more effective when planning in challenging scenarios, in which sensory observations provide ambiguous information about location.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:生物体需要获得认知地图以学习世界结构，以及能够在不确定环境中进行规划。虽然在每个领域中都已经取得了 significative progress，但整体 интеграion仍然是一个开放的研究问题。在这篇论文中，我们提出了在活动推理Agent中 интеGRATE cognitive map formation的统计模型，并在三个空间导航enario中比较了一个简单的clone graph Agent与一个活动推理驱动的clone graph Agent。我们发现，在复杂enario中，活动推理驱动的clone graph Agent更有效，因为感知观测在位置信息上提供了模糊的信息。
</details></li>
</ul>
<hr>
<h2 id="Robust-Bayesian-Satisficing"><a href="#Robust-Bayesian-Satisficing" class="headerlink" title="Robust Bayesian Satisficing"></a>Robust Bayesian Satisficing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08291">http://arxiv.org/abs/2308.08291</a></li>
<li>repo_url: None</li>
<li>paper_authors: Artun Saday, Yaşar Cahit Yıldırım, Cem Tekin</li>
<li>for: 这篇论文主要应用于解决现代机器学习中的分布Shift问题，以确保模型的稳定性和可靠性。</li>
<li>methods: 本论文提出了一个名为RoBOS的robust Bayesian satisficing算法，用于在具有噪音和黑盒问题的contextual Bayesian optimization中实现分布Shift的抗衡。</li>
<li>results: 本论文证明了RoBOS算法在certain assumptions下可以保证sublinear lenient regret，并且提出了一个弱定义的 regret called robust satisficing regret，其下可以获得sublinear upper bound不受分布Shift的影响。<details>
<summary>Abstract</summary>
Distributional shifts pose a significant challenge to achieving robustness in contemporary machine learning. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization.
</details>
<details>
<summary>摘要</summary>
当前机器学习中的分布shift问题 pose a significant challenge to achieving robustness. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization.Here's the translation in Traditional Chinese:当前机器学习中的分布shift问题 pose a significant challenge to achieving robustness. To overcome this challenge, robust satisficing (RS) seeks a robust solution to an unspecified distributional shift while achieving a utility above a desired threshold. This paper focuses on the problem of RS in contextual Bayesian optimization when there is a discrepancy between the true and reference distributions of the context. We propose a novel robust Bayesian satisficing algorithm called RoBOS for noisy black-box optimization. Our algorithm guarantees sublinear lenient regret under certain assumptions on the amount of distribution shift. In addition, we define a weaker notion of regret called robust satisficing regret, in which our algorithm achieves a sublinear upper bound independent of the amount of distribution shift. To demonstrate the effectiveness of our method, we apply it to various learning problems and compare it to other approaches, such as distributionally robust optimization.
</details></li>
</ul>
<hr>
<h2 id="It-Ain’t-That-Bad-Understanding-the-Mysterious-Performance-Drop-in-OOD-Generalization-for-Generative-Transformer-Models"><a href="#It-Ain’t-That-Bad-Understanding-the-Mysterious-Performance-Drop-in-OOD-Generalization-for-Generative-Transformer-Models" class="headerlink" title="It Ain’t That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models"></a>It Ain’t That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08268">http://arxiv.org/abs/2308.08268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingcheng Xu, Zihao Pan, Haipeng Zhang, Yanqing Yang</li>
<li>for:  investigate the generalization ability of Generative Transformer-based models</li>
<li>methods:  using n-digit addition and multiplication tasks to study the models’ generalization behaviors</li>
<li>results:  the models show successful ID generalization but poor OOD generalization, and the reason is found to be due to the models’ learned algebraic structures that map OOD inputs to equivalent ID domain outputs.<details>
<summary>Abstract</summary>
Generative Transformer-based models have achieved remarkable proficiency on solving diverse problems. However, their generalization ability is not fully understood and not always satisfying. Researchers take basic mathematical tasks like n-digit addition or multiplication as important perspectives for investigating their generalization behaviors. Curiously, it is observed that when training on n-digit operations (e.g., additions) in which both input operands are n-digit in length, models generalize successfully on unseen n-digit inputs (in-distribution (ID) generalization), but fail miserably and mysteriously on longer, unseen cases (out-of-distribution (OOD) generalization). Studies try to bridge this gap with workarounds such as modifying position embedding, fine-tuning, and priming with more extensive or instructive data. However, without addressing the essential mechanism, there is hardly any guarantee regarding the robustness of these solutions. We bring this unexplained performance drop into attention and ask whether it is purely from random errors. Here we turn to the mechanistic line of research which has notable successes in model interpretability. We discover that the strong ID generalization stems from structured representations, while behind the unsatisfying OOD performance, the models still exhibit clear learned algebraic structures. Specifically, these models map unseen OOD inputs to outputs with equivalence relations in the ID domain. These highlight the potential of the models to carry useful information for improved generalization.
</details>
<details>
<summary>摘要</summary>
We bring this unexplained performance drop into attention and question whether it is purely due to random errors. To better understand the issue, we turn to the mechanistic line of research, which has been successful in model interpretability. We discovered that the strong ID generalization is due to structured representations, while the unsatisfying OOD performance is caused by the models still exhibiting clear learned algebraic structures. Specifically, these models map unseen OOD inputs to outputs with equivalence relations in the ID domain. This suggests that the models have the potential to carry useful information for improved generalization.
</details></li>
</ul>
<hr>
<h2 id="Description-Logics-Go-Second-Order-–-Extending-EL-with-Universally-Quantified-Concepts"><a href="#Description-Logics-Go-Second-Order-–-Extending-EL-with-Universally-Quantified-Concepts" class="headerlink" title="Description Logics Go Second-Order – Extending EL with Universally Quantified Concepts"></a>Description Logics Go Second-Order – Extending EL with Universally Quantified Concepts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08252">http://arxiv.org/abs/2308.08252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Hirschbrunn, Yevgeny Kazakov</li>
<li>for: 本研究论文主要针对描述逻辑的扩展，而不是固有的 decidable fragments of first-order logic。</li>
<li>methods: 本文引入 universally quantified concepts，即变量可以被任意替换为概念。 authors 定义了两种 semantics：一种是 schema semantics，允许概念变量只能被替换为特定语言中的概念；另一种是 second-order semantics，允许概念变量被替换为任意域的子集。</li>
<li>results: 作者们证明了扩展的描述逻辑 $\mathcal{EL}$ 的延展可以用 classical $\mathcal{EL}$ reasoning algorithms来推理，即使使用 second-order semantics。此外，作者们还证明了这个扩展的一个稍小但仍然有用的子集是可计算的。这个子集可以表达一些扩展的概念链规则、正面自限制和一些本地角色值图从 KL-ONE 中获得，而无需添加任何其他构造器。<details>
<summary>Abstract</summary>
The study of Description Logics have been historically mostly focused on features that can be translated to decidable fragments of first-order logic. In this paper, we leave this restriction behind and look for useful and decidable extensions outside first-order logic. We introduce universally quantified concepts, which take the form of variables that can be replaced with arbitrary concepts, and define two semantics of this extension. A schema semantics allows replacements of concept variables only by concepts from a particular language, giving us axiom schemata similar to modal logics. A second-order semantics allows replacement of concept variables with arbitrary subsets of the domain, which is similar to quantified predicates in second-order logic.   To study the proposed semantics, we focus on the extension of the description logic $\mathcal{EL}$. We show that for a useful fragment of the extension, the conclusions entailed by the different semantics coincide, allowing us to use classical $\mathcal{EL}$ reasoning algorithms even for the second-order semantics. For a slightly smaller, but still useful, fragment, we were also able to show polynomial decidability of the extension. This fragment, in particular, can express a generalized form of role chain axioms, positive self restrictions, and some forms of (local) role-value-maps from KL-ONE, without requiring any additional constructors.
</details>
<details>
<summary>摘要</summary>
study of Description Logics  Historically, most research has focused on features that can be translated into decidable fragments of first-order logic. In this paper, we abandon this restriction and explore useful and decidable extensions beyond first-order logic. We introduce universally quantified concepts, which take the form of variables that can be replaced with arbitrary concepts, and define two semantics for this extension. A schema semantics allows replacements of concept variables only with concepts from a specific language, giving us axiom schemata similar to modal logics. A second-order semantics allows replacement of concept variables with arbitrary subsets of the domain, similar to quantified predicates in second-order logic.   To study the proposed semantics, we focus on the extension of the description logic $\mathcal{EL}$. We show that for a useful fragment of the extension, the conclusions entailed by the different semantics coincide, allowing us to use classical $\mathcal{EL}$ reasoning algorithms even for the second-order semantics. For a slightly smaller, but still useful, fragment, we were also able to show polynomial decidability of the extension. This fragment can express a generalized form of role chain axioms, positive self-restrictions, and some forms of (local) role-value-maps from KL-ONE without requiring any additional constructors.
</details></li>
</ul>
<hr>
<h2 id="TEST-Text-Prototype-Aligned-Embedding-to-Activate-LLM’s-Ability-for-Time-Series"><a href="#TEST-Text-Prototype-Aligned-Embedding-to-Activate-LLM’s-Ability-for-Time-Series" class="headerlink" title="TEST: Text Prototype Aligned Embedding to Activate LLM’s Ability for Time Series"></a>TEST: Text Prototype Aligned Embedding to Activate LLM’s Ability for Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08241">http://arxiv.org/abs/2308.08241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenxi Sun, Yaliang Li, Hongyan Li, Shenda Hong</li>
<li>for: 本文是为了探讨如何使用当今的语言模型（LLM）来完成时序数据（TS）任务。</li>
<li>methods: 本文提出了两种方法：一是设计和训练基本大型模型 для TS 数据（LLM-for-TS），二是使得预训练的 LLM 处理 TS 数据（TS-for-LLM）。本文主要研究 TS-for-LLM 方法，以便利用 LLM 的能力来处理 TS 数据。</li>
<li>results: 本文通过实验表明，使用 TEST 方法可以让 LLM 处理 TS 数据，但不能与现有的特定于 TS 任务的模型相比，但可以让 LLM 拥有处理 TS 数据的能力而不妨碍其语言能力。<details>
<summary>Abstract</summary>
This work summarizes two strategies for completing time-series (TS) tasks using today's language model (LLM): LLM-for-TS, design and train a fundamental large model for TS data; TS-for-LLM, enable the pre-trained LLM to handle TS data. Considering the insufficient data accumulation, limited resources, and semantic context requirements, this work focuses on TS-for-LLM methods, where we aim to activate LLM's ability for TS data by designing a TS embedding method suitable for LLM. The proposed method is named TEST. It first tokenizes TS, builds an encoder to embed them by instance-wise, feature-wise, and text-prototype-aligned contrast, and then creates prompts to make LLM more open to embeddings, and finally implements TS tasks. Experiments are carried out on TS classification and forecasting tasks using 8 LLMs with different structures and sizes. Although its results cannot significantly outperform the current SOTA models customized for TS tasks, by treating LLM as the pattern machine, it can endow LLM's ability to process TS data without compromising the language ability. This paper is intended to serve as a foundational work that will inspire further research.
</details>
<details>
<summary>摘要</summary>
The TEST method first tokenizes the TS data, builds an encoder to embed the data instance-wise, feature-wise, and text-prototype-aligned, and then creates prompts to make the LLM more open to the embeddings. Finally, the method implements TS tasks using the embedded data. The experiments were conducted on TS classification and forecasting tasks using 8 different LLMs with various structures and sizes. While the results cannot significantly outperform the current state-of-the-art (SOTA) models customized for TS tasks, the TEST method can endow LLM's ability to process TS data without compromising its language ability. This work serves as a foundational study that inspires further research.Translation notes:* "LLM" is translated as "语言模型" (yǔ yán módel), which means "language model" in Simplified Chinese.* "TS" is translated as "时间序列" (shí jiān xìng zhì), which means "time-series" in Simplified Chinese.* "SOTA" is translated as "当前最佳" (dāng xiàn zuī jìa), which means "current state-of-the-art" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Challenges-and-Opportunities-of-Using-Transformer-Based-Multi-Task-Learning-in-NLP-Through-ML-Lifecycle-A-Survey"><a href="#Challenges-and-Opportunities-of-Using-Transformer-Based-Multi-Task-Learning-in-NLP-Through-ML-Lifecycle-A-Survey" class="headerlink" title="Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey"></a>Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08234">http://arxiv.org/abs/2308.08234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lovre Torbarina, Tin Ferkovic, Lukasz Roguski, Velimir Mihelcic, Bruno Sarlija, Zeljko Kraljevic</li>
<li>for: 本研究旨在提供一种有效地使用多任务学习（MTL）方法来提高自然语言处理（NLP）模型的训练和部署效率，从而应对实际应用中的模型训练和部署问题。</li>
<li>methods: 本文主要介绍了基于变换器的MTL方法在NLP领域的应用，并讨论了在ML生命周期阶段中MTL方法的挑战和机遇。</li>
<li>results: 本研究系统地分析了如何将MTL方法应用于NLP领域中的ML生命周期阶段，并指出了在这些阶段中MTL方法的挑战和机遇。此外，本研究还提出了一种将MTL和长期学习（CL）相结合的研究方向，以解决实际应用中模型训练和部署中的问题。<details>
<summary>Abstract</summary>
The increasing adoption of natural language processing (NLP) models across industries has led to practitioners' need for machine learning systems to handle these models efficiently, from training to serving them in production. However, training, deploying, and updating multiple models can be complex, costly, and time-consuming, mainly when using transformer-based pre-trained language models. Multi-Task Learning (MTL) has emerged as a promising approach to improve efficiency and performance through joint training, rather than training separate models. Motivated by this, we first provide an overview of transformer-based MTL approaches in NLP. Then, we discuss the challenges and opportunities of using MTL approaches throughout typical ML lifecycle phases, specifically focusing on the challenges related to data engineering, model development, deployment, and monitoring phases. This survey focuses on transformer-based MTL architectures and, to the best of our knowledge, is novel in that it systematically analyses how transformer-based MTL in NLP fits into ML lifecycle phases. Furthermore, we motivate research on the connection between MTL and continual learning (CL), as this area remains unexplored. We believe it would be practical to have a model that can handle both MTL and CL, as this would make it easier to periodically re-train the model, update it due to distribution shifts, and add new capabilities to meet real-world requirements.
</details>
<details>
<summary>摘要</summary>
随着自然语言处理（NLP）模型在不同领域的普及，机器学习（ML）实践者需要有效地处理这些模型，从训练到生产环境中的部署。然而，训练、部署和更新多个模型可能会具有复杂性、成本和时间consuming的问题，尤其是使用基于转换器的预训练语言模型。多任务学习（MTL）已经成为一种有前途的方法，通过共同训练而提高效率和性能。在这种情况下，我们首先提供了转换器基于MTL方法在NLP领域的概述。然后，我们讨论了使用MTL方法在ML生命周期阶段中的挑战和机遇，特别是在数据工程、模型开发、部署和监测阶段。这份报告专注于基于转换器的MTL架构，并且，到我们所知，是在ML生命周期阶段中系统地分析了转换器基于MTL在NLP领域的应用。此外，我们还鼓励了对MTL和持续学习（CL）之间的连接进行研究，因为这个领域还未得到了足够的探索。我们认为，一个能够处理MTL和CL的模型会更加实用，这样可以更加方便地在 periodic 训练、因为分布shift 和添加新功能等需求时更新模型。
</details></li>
</ul>
<hr>
<h2 id="Self-Deception-Reverse-Penetrating-the-Semantic-Firewall-of-Large-Language-Models"><a href="#Self-Deception-Reverse-Penetrating-the-Semantic-Firewall-of-Large-Language-Models" class="headerlink" title="Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models"></a>Self-Deception: Reverse Penetrating the Semantic Firewall of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11521">http://arxiv.org/abs/2308.11521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenhua Wang, Wei Xie, Kai Chen, Baosheng Wang, Zhiwen Gui, Enze Wang</li>
<li>for: 这个论文 investigate了LLM “监禁”问题，并提出了一种自动监禁方法。</li>
<li>methods: 论文提出了三种实现方法，包括使用语义防火墙、自我欺骗攻击和语义攻击。</li>
<li>results: 实验结果显示，提出的攻击方法可以成功监禁GPT-3.5-Turbo和GPT-4模型，成功率为86.2%和67%，失败率为4.7%和2.2%。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as ChatGPT, have emerged with astonishing capabilities approaching artificial general intelligence. While providing convenience for various societal needs, LLMs have also lowered the cost of generating harmful content. Consequently, LLM developers have deployed semantic-level defenses to recognize and reject prompts that may lead to inappropriate content. Unfortunately, these defenses are not foolproof, and some attackers have crafted "jailbreak" prompts that temporarily hypnotize the LLM into forgetting content defense rules and answering any improper questions. To date, there is no clear explanation of the principles behind these semantic-level attacks and defenses in both industry and academia.   This paper investigates the LLM jailbreak problem and proposes an automatic jailbreak method for the first time. We propose the concept of a semantic firewall and provide three technical implementation approaches. Inspired by the attack that penetrates traditional firewalls through reverse tunnels, we introduce a "self-deception" attack that can bypass the semantic firewall by inducing LLM to generate prompts that facilitate jailbreak. We generated a total of 2,520 attack payloads in six languages (English, Russian, French, Spanish, Chinese, and Arabic) across seven virtual scenarios, targeting the three most common types of violations: violence, hate, and pornography. The experiment was conducted on two models, namely the GPT-3.5-Turbo and GPT-4. The success rates on the two models were 86.2% and 67%, while the failure rates were 4.7% and 2.2%, respectively. This highlighted the effectiveness of the proposed attack method. All experimental code and raw data will be released as open-source to inspire future research. We believe that manipulating AI behavior through carefully crafted prompts will become an important research direction in the future.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如ChatGPT，已经出现了惊人的能力，接近人工通用智能。这些模型可以为社会各种需求提供便利，但同时也降低了生成不良内容的成本。因此，LLM开发者已经部署了Semantic-level防御机制，以识别和拒绝可能导致不良内容的提示。尽管这些防御机制不是不可逾越的，但一些攻击者已经制作了“监狱敲打”提示，使LLM忘记内容防御规则，回答任何不当问题。至今，在业界和学术界没有明确的Semantic-level攻击和防御原理的解释。本文 investigate LLM监狱问题，并提出了自动监狱方法的想法。我们提出了 semantic firewall 的概念，并提供了三种技术实现方法。受到传统防火墙被攻击的启示，我们引入了一种“自我欺骗”攻击，可以绕过semantic firewall，使LLM生成提示，促使监狱。我们在六种语言（英文、俄文、法文、西班牙文、中文和阿拉伯文）的七个虚拟场景中总共生成了2520个攻击payload。实验使用了GPT-3.5-Turbo和GPT-4两个模型，成功率分别为86.2%和67%，失败率分别为4.7%和2.2%。这说明了我们提出的攻击方法的效果。所有实验代码和原始数据将被发布为开源，以便uture research。我们认为，通过精心制定提示来控制AI行为将成为未来的重要研究方向。
</details></li>
</ul>
<hr>
<h2 id="In-situ-Fault-Diagnosis-of-Indium-Tin-Oxide-Electrodes-by-Processing-S-Parameter-Patterns"><a href="#In-situ-Fault-Diagnosis-of-Indium-Tin-Oxide-Electrodes-by-Processing-S-Parameter-Patterns" class="headerlink" title="In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns"></a>In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11639">http://arxiv.org/abs/2308.11639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tae Yeob Kang, Haebom Lee, Sungho Suh</li>
<li>for: 这个研究旨在为光电子设备中的铍镉矿（ITO）电极进行FAULT DETECTION和诊断，以确保设备的性能和可靠性。</li>
<li>methods: 该研究提出了一种增强型FAULT DETECTION方法，使用散射参数（S-parameter）信号处理，可以早期发现、具有高诊断精度、鲁棒性和根本原因分析。</li>
<li>results: 研究人员通过构建了一个完整的S-parameter模式数据库，并使用深度学习（DL）方法，包括多层感知网络（MLP）、卷积神经网络（CNN）和变换器，同时分析了缺陷的原因和严重程度。<details>
<summary>Abstract</summary>
In the field of optoelectronics, indium tin oxide (ITO) electrodes play a crucial role in various applications, such as displays, sensors, and solar cells. Effective fault detection and diagnosis of the ITO electrodes are essential to ensure the performance and reliability of the devices. However, traditional visual inspection is challenging with transparent ITO electrodes, and existing fault detection methods have limitations in determining the root causes of the defects, often requiring destructive evaluations. In this study, an in situ fault diagnosis method is proposed using scattering parameter (S-parameter) signal processing, offering early detection, high diagnostic accuracy, noise robustness, and root cause analysis. A comprehensive S-parameter pattern database is obtained according to defect states. Deep learning (DL) approaches, including multilayer perceptron (MLP), convolutional neural network (CNN), and transformer, are then used to simultaneously analyze the cause and severity of defects. Notably, it is demonstrated that the diagnostic performance under additive noise levels can be significantly enhanced by combining different channels of the S-parameters as input to the learning algorithms, as confirmed through the t-distributed stochastic neighbor embedding (t-SNE) dimension reduction visualization.
</details>
<details>
<summary>摘要</summary>
在光电子学领域，锌镉铝矿（ITO）电极在多种应用中扮演关键角色，如显示器、感测器和太阳能电池。有效检测和诊断ITO电极的缺陷非常重要，以确保设备的性能和可靠性。然而，传统的视觉检查困难于透明的ITO电极，现有的缺陷检测方法有限制力推断缺陷的根本原因，经常需要破坏评估。本研究提出了即位检测方法，使用散射参数（S-parameter）信号处理，可以早期检测、高精度诊断、鲁棒性和根本原因分析。通过对缺陷状态下的S-parameter模式库的建立，使用深度学习（DL）方法，包括多层感知网络（MLP）、卷积神经网络（CNN）和变换器，同时分析缺陷的原因和严重程度。另外，通过不同通道的S-parameters作为输入，使用不同的DL方法进行同时分析，可以减少干扰的影响，并且通过t-分布随机 neigh embedding（t-SNE）维度减少Visualization表明，在增加的污染水平下，诊断性能得到了显著提高。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Multi-View-Deep-Networks-Methodology-for-Experimental-Physics"><a href="#Explainable-Multi-View-Deep-Networks-Methodology-for-Experimental-Physics" class="headerlink" title="Explainable Multi-View Deep Networks Methodology for Experimental Physics"></a>Explainable Multi-View Deep Networks Methodology for Experimental Physics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08206">http://arxiv.org/abs/2308.08206</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scientific-computing-lab-nrcn/multi-view-explainability">https://github.com/scientific-computing-lab-nrcn/multi-view-explainability</a></li>
<li>paper_authors: Nadav Schneider, Muriel Tzdaka, Galit Sturm, Guy Lazovski, Galit Bar, Gilad Oren, Raz Gvishi, Gal Oren</li>
<li>for: 这个论文的目的是要解释多看点学习模型在物理实验中的决策过程，并提供不同多看点架构，以及一个方法来解释这些模型。</li>
<li>methods: 这个论文使用了多种深度学习模型，包括多看点模型，以及一些解释性方法来解释这些模型的决策过程。</li>
<li>results: 这个论文的实验结果显示，使用多看点架构可以提高分类精度，并且可以提供更多的解释性。具体来说，在高能量浓度物理实验中，使用多看点模型可以从foam样品的多个影像描述中提取更多的信息，以提高样品质量的评估精度。<details>
<summary>Abstract</summary>
Physical experiments often involve multiple imaging representations, such as X-ray scans and microscopic images. Deep learning models have been widely used for supervised analysis in these experiments. Combining different image representations is frequently required to analyze and make a decision properly. Consequently, multi-view data has emerged - datasets where each sample is described by views from different angles, sources, or modalities. These problems are addressed with the concept of multi-view learning. Understanding the decision-making process of deep learning models is essential for reliable and credible analysis. Hence, many explainability methods have been devised recently. Nonetheless, there is a lack of proper explainability in multi-view models, which are challenging to explain due to their architectures. In this paper, we suggest different multi-view architectures for the vision domain, each suited to another problem, and we also present a methodology for explaining these models. To demonstrate the effectiveness of our methodology, we focus on the domain of High Energy Density Physics (HEDP) experiments, where multiple imaging representations are used to assess the quality of foam samples. We apply our methodology to classify the foam samples quality using the suggested multi-view architectures. Through experimental results, we showcase the improvement of accurate architecture choice on both accuracy - 78% to 84% and AUC - 83% to 93% and present a trade-off between performance and explainability. Specifically, we demonstrate that our approach enables the explanation of individual one-view models, providing insights into the decision-making process of each view. This understanding enhances the interpretability of the overall multi-view model. The sources of this work are available at: https://github.com/Scientific-Computing-Lab-NRCN/Multi-View-Explainability.
</details>
<details>
<summary>摘要</summary>
物理实验经常涉及多种图像表示方式，如X射线扫描和显微镜图像。深度学习模型在这些实验中广泛应用了监督分析。将不同的图像表示方式结合起来是必要的，以便正确地分析和做出决策。因此，多视图数据出现了，每个样本都是由不同的角度、来源或模式描述的。这些问题是多视图学习的核心。理解深度学习模型的决策过程是必要的，以确保可靠和可信worth的分析。因此，许多解释方法已经被开发出来。然而，多视图模型的解释却是一个挑战，因为它们的架构复杂。在这篇论文中，我们提出了不同的多视图架构，每个适用于不同的问题，以及一种方法来解释这些模型。为了证明我们的方法的有效性，我们将在高能密度物理实验中应用我们的方法，其中多种图像表示方式是用来评估高强度粉末样本质量的。我们通过实验结果表明，我们的方法可以提高准确性，从78%提高到84%，并且可以提高AUC从83%提高到93%。此外，我们还发现了在性能和解释之间存在一定的负相关性。具体来说，我们的方法可以解释单个一视图模型的决策过程，从而提供每个视图的解释。这种理解可以提高多视图模型的解释性。这些资源可以在以下链接中获取：https://github.com/Scientific-Computing-Lab-NRCN/Multi-View-Explainability。
</details></li>
</ul>
<hr>
<h2 id="Towards-Ontology-Mediated-Planning-with-OWL-DL-Ontologies-Extended-Version"><a href="#Towards-Ontology-Mediated-Planning-with-OWL-DL-Ontologies-Extended-Version" class="headerlink" title="Towards Ontology-Mediated Planning with OWL DL Ontologies (Extended Version)"></a>Towards Ontology-Mediated Planning with OWL DL Ontologies (Extended Version)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08200">http://arxiv.org/abs/2308.08200</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias John, Patrick Koopmann</li>
<li>for: 本研究旨在提供一种新的方法，以便规划专家可以使用 familar 的 formalism 来编写规划规范，同时允许现有 ontology 被容易地 интегрироваться和扩展。</li>
<li>methods: 本研究使用了一种新的接口来链接规划规范和 ontology  together，以便在小型Domain 下进行规划。此外，本研究还使用了一种数据依赖的 rewrite 将 ontology-mediated 规划问题转换成类别的规划问题，以便使用现有的规划工具进行处理。</li>
<li>results: 本研究的实验表明，该方法在小型Domain 下可以具有一定的潜在和局限性。同时，该方法还可以允许规划专家使用现有的规划工具来解决 ontology-mediated 规划问题。<details>
<summary>Abstract</summary>
While classical planning languages make the closed-domain and closed-world assumption, there have been various approaches to extend those with DL reasoning, which is then interpreted under the usual open-world semantics. Current approaches for planning with DL ontologies integrate the DL directly into the planning language, and practical approaches have been developed based on first-order rewritings or rewritings into datalog. We present here a new approach in which the planning specification and ontology are kept separate, and are linked together using an interface. This allows planning experts to work in a familiar formalism, while existing ontologies can be easily integrated and extended by ontology experts. Our approach for planning with those ontology-mediated planning problems is optimized for cases with comparatively small domains, and supports the whole OWL DL fragment. The idea is to rewrite the ontology-mediated planning problem into a classical planning problem to be processed by existing planning tools. Different to other approaches, our rewriting is data-dependent. A first experimental evaluation of our approach shows the potential and limitations of this approach.
</details>
<details>
<summary>摘要</summary>
古典规划语言采用关闭领域和关闭世界假设，然而有许多方法来扩展这些使用DL推理，然后在普通的开放世界 semantics下进行解释。现有的规划与DL ontology的集成方法是将DL直接集成到规划语言中，并基于首览 rewrite 或 rewrite 到 datalog 实现实用。我们现在提出了一种新的方法，在规划规范和 ontology 之间使用接口相互连接。这使得规划专家可以在熟悉的 formalism 中工作，而现有的 ontology 可以轻松地被集成和扩展。我们的规划与 ontology-mediated 规划问题的方法优化为小领域情况，支持整个 OWL DL  Fragment。我们的 rewrite 是数据висимы的。一个初步的实验评估表明了这种方法的潜力和局限性。
</details></li>
</ul>
<hr>
<h2 id="Modelling-the-Spread-of-COVID-19-in-Indoor-Spaces-using-Automated-Probabilistic-Planning"><a href="#Modelling-the-Spread-of-COVID-19-in-Indoor-Spaces-using-Automated-Probabilistic-Planning" class="headerlink" title="Modelling the Spread of COVID-19 in Indoor Spaces using Automated Probabilistic Planning"></a>Modelling the Spread of COVID-19 in Indoor Spaces using Automated Probabilistic Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08190">http://arxiv.org/abs/2308.08190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Harmanani</li>
<li>for: This paper aims to provide a novel approach for modeling the spread of COVID-19 in indoor spaces using probabilistic planning and dynamic graph analysis, and to evaluate the effectiveness of different mitigation strategies.</li>
<li>methods: The authors use a probabilistic planning framework to model the spread of COVID-19 in shared spaces, and endow the planner with means to control the spread of the disease through non-pharmaceutical interventions (NPIs) such as mandating masks and vaccines. They also compare the impact of crowds and capacity limits on the spread of COVID-19 in these settings.</li>
<li>results: The authors demonstrate that the use of probabilistic planning is effective in predicting the amount of infections that are likely to occur in shared spaces, and that automated planners have the potential to design competent interventions to limit the spread of the disease.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这个研究旨在提供一种基于概率规划和动态图分析的新方法，用于模型 COVID-19 在室内空间中的传播，并评估不同的控制策略的效果。</li>
<li>methods: 作者们使用概率规划框架来模型 COVID-19 在共享空间中的传播，并赋予计划程序控制疫苗传播的能力，包括规定口罩和疫苗。他们还对受到限制的人群和容量限制的 COVID-19 传播进行比较。</li>
<li>results: 作者们表明，使用概率规划可以准确预测共享空间中的感染情况，并且自动化计划程序有效地设计控制疫苗传播的策略。<details>
<summary>Abstract</summary>
The coronavirus disease 2019 (COVID-19) pandemic has been ongoing for around 3 years, and has infected over 750 million people and caused over 6 million deaths worldwide at the time of writing. Throughout the pandemic, several strategies for controlling the spread of the disease have been debated by healthcare professionals, government authorities, and international bodies. To anticipate the potential impact of the disease, and to simulate the effectiveness of different mitigation strategies, a robust model of disease spread is needed. In this work, we explore a novel approach based on probabilistic planning and dynamic graph analysis to model the spread of COVID-19 in indoor spaces. We endow the planner with means to control the spread of the disease through non-pharmaceutical interventions (NPIs) such as mandating masks and vaccines, and we compare the impact of crowds and capacity limits on the spread of COVID-19 in these settings. We demonstrate that the use of probabilistic planning is effective in predicting the amount of infections that are likely to occur in shared spaces, and that automated planners have the potential to design competent interventions to limit the spread of the disease. Our code is fully open-source and is available at: https://github.com/mharmanani/prob-planning-covid19 .
</details>
<details>
<summary>摘要</summary>
COVID-19 疫情已经持续约3年，已经感染了超过75亿人，导致了全球6000万人的死亡。在疫情中，医疗专业人员、政府机构和国际组织一直在讨论如何控制疫情的传播。为了预测疫情的可能影响和评估不同mitigation策略的效果，需要一个可靠的疫情传播模型。在这个工作中，我们探讨了一种基于概率规划和动态图分析的新方法，用于模型COVID-19在室内空间的传播。我们赋予 плаanner控制疫情的能力，包括强制戴Mask和接种疫苗等非药用 интервентions。我们比较了在这些设置下COVID-19的传播的影响，并证明了概率规划有效地预测共享空间中感染的可能性，以及自动化 плаanner有 Potential to design有效的防止疫情传播的 intervención。我们的代码已经开源，可以在https://github.com/mharmanani/prob-planning-covid19 中获取。
</details></li>
</ul>
<hr>
<h2 id="Endogenous-Macrodynamics-in-Algorithmic-Recourse"><a href="#Endogenous-Macrodynamics-in-Algorithmic-Recourse" class="headerlink" title="Endogenous Macrodynamics in Algorithmic Recourse"></a>Endogenous Macrodynamics in Algorithmic Recourse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08187">http://arxiv.org/abs/2308.08187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pat-alt/endogenous-macrodynamics-in-algorithmic-recourse">https://github.com/pat-alt/endogenous-macrodynamics-in-algorithmic-recourse</a></li>
<li>paper_authors: Patrick Altmeyer, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen, Cynthia C. S. Liem</li>
<li>for: 本研究旨在弥补现有的Counterfactual Explanations（CE）和Algorithmic Recourse（AR）研究中忽略的动态环境和多个个体之间的相互作用问题。</li>
<li>methods: 我们首先表明了现有方法可以总结为一个通用框架，然后我们指出了现有框架未能考虑到Counterfactual生成过程中的隐藏外部成本，这只有在研究Counterfactual生成过程的群体级别时才能发现。</li>
<li>results: 我们通过使用Various state-of-the-artCounterfactual生成器和多个标准数据集进行了大量的Counterfactual生成和研究，发现Counterfactual生成过程引起的领域和模型变化是很大，可能会妨碍Algorithmic Recourse的应用。然而，我们也提出了一些缓解这些问题的策略。我们的Counterfactual生成和研究框架快速、开源。<details>
<summary>Abstract</summary>
Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely focused on single individuals in a static environment: given some estimated model, the goal is to find valid counterfactuals for an individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work, we aim to close that gap. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework does not account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various state-of the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations. Fortunately, we find various strategies to mitigate these concerns. Our simulation framework for studying recourse dynamics is fast and opensourced.
</details>
<details>
<summary>摘要</summary>
先前的Counterfactual Explanations（CE）和Algorithmic Recourse（AR）研究都集中在单个个体和静止环境中，即给出一个估计模型后，找到满足多种需求的有效Counterfactuals。然而，这些Counterfactuals在数据和模型漂移的情况下的可靠性仍然是一个未解决的研究挑战。此外，很少有研究探讨了实际实施救济的一个人如何影响别的人。在这个工作中，我们希望填补这一差距。我们首先表明了许多现有的方法ologies可以总结为一个通用框架。然后，我们 argue that现有的框架不会考虑一种隐藏的外部成本，只有在研究救济的自然 dynamics 上才会显示出来。通过使用多种现状的Counterfactual生成器和多个标准数据集，我们生成了大量的Counterfactuals，并研究了其导致的领域和模型shift。我们发现这些shift具有很大的影响，可能会阻碍Algorithmic Recourse的应用。幸运的是，我们发现了一些缓解这些问题的策略。我们的救济动态 simulate框架快速且开源，可以帮助研究人员更好地理解和应用Algorithmic Recourse。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Performance-on-Seen-and-Unseen-Dialogue-Scenarios-using-Retrieval-Augmented-End-to-End-Task-Oriented-System"><a href="#Enhancing-Performance-on-Seen-and-Unseen-Dialogue-Scenarios-using-Retrieval-Augmented-End-to-End-Task-Oriented-System" class="headerlink" title="Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System"></a>Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08169">http://arxiv.org/abs/2308.08169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianguo Zhang, Stephen Roller, Kun Qian, Zhiwei Liu, Rui Meng, Shelby Heinecke, Huan Wang, Silvio Savarese, Caiming Xiong</li>
<li>for: 提高终端任务对话系统的灵活性和扩展性</li>
<li>methods: 使用缓存机制，通过缓存中的信息进行动态更新和适应不同对话场景</li>
<li>results: 实现了提高非空共同目标准确率的6.7%，至于现有强基线之上Translation:</li>
<li>for: 提高终端任务对话系统的灵活性和扩展性</li>
<li>methods: 使用缓存机制，通过缓存中的信息进行动态更新和适应不同对话场景</li>
<li>results: 实现了提高非空共同目标准确率的6.7%，至于现有强基线之上<details>
<summary>Abstract</summary>
End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios. Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.
</details>
<details>
<summary>摘要</summary>
End-to-end任务导向对话（TOD）系统已经取得了可观的成绩，通过利用先前训练的自然语言理解和自然语言生成能力。这项工作允许TOD系统更加灵活，通过简单的缓存。缓存提供了更新TOD系统的动态性，并处理现有和未看过的对话场景。为此，我们首先精度地微调检索模块，以便快速检索缓存中最相关的信息项。然后，我们训练了基于对话历史和检索到信息的TOD模型，以便在TOD生成时，能够 Refer to和根据对话历史和检索到的信息。缓存的构建非常简单，并且TOD系统的核心模型与现有预训练生成模型兼容。广泛的实验证明了我们的框架的超越性，相比强基准，非空共同目标准确率提高6.7%。
</details></li>
</ul>
<hr>
<h2 id="PEvoLM-Protein-Sequence-Evolutionary-Information-Language-Model"><a href="#PEvoLM-Protein-Sequence-Evolutionary-Information-Language-Model" class="headerlink" title="PEvoLM: Protein Sequence Evolutionary Information Language Model"></a>PEvoLM: Protein Sequence Evolutionary Information Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08578">http://arxiv.org/abs/2308.08578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/issararab/pevolm">https://github.com/issararab/pevolm</a></li>
<li>paper_authors: Issar Arab<br>for:This paper aims to improve the efficiency and accuracy of protein sequence alignment and evolutionary information retrieval by leveraging recent advancements in natural language processing (NLP) and machine learning (ML).methods:The proposed method, called PEvoLM, is a novel bidirectional language model that combines the concept of transfer learning with the idea of position-specific scoring matrices (PSSMs) to learn the evolutionary information of protein sequences. The model uses a single path for both the forward and backward passes, which reduces the number of free parameters compared to traditional bidirectional models.results:The proposed PEvoLM model was trained on a dataset of protein sequences and achieved state-of-the-art performance on predicting the next amino acid in a sequence, as well as the probability distribution of the next AA derived from similar yet different sequences. The model also demonstrated improved performance on multi-task learning, which involves predicting both the next AA and the evolutionary information of protein sequences. The source code and pre-trained model are available on GitHub under the permissive MIT license.<details>
<summary>Abstract</summary>
With the exponential increase of the protein sequence databases over time, multiple-sequence alignment (MSA) methods, like PSI-BLAST, perform exhaustive and time-consuming database search to retrieve evolutionary information. The resulting position-specific scoring matrices (PSSMs) of such search engines represent a crucial input to many machine learning (ML) models in the field of bioinformatics and computational biology. A protein sequence is a collection of contiguous tokens or characters called amino acids (AAs). The analogy to natural language allowed us to exploit the recent advancements in the field of Natural Language Processing (NLP) and therefore transfer NLP state-of-the-art algorithms to bioinformatics. This research presents an Embedding Language Model (ELMo), converting a protein sequence to a numerical vector representation. While the original ELMo trained a 2-layer bidirectional Long Short-Term Memory (LSTMs) network following a two-path architecture, one for the forward and the second for the backward pass, by merging the idea of PSSMs with the concept of transfer-learning, this work introduces a novel bidirectional language model (bi-LM) with four times less free parameters and using rather a single path for both passes. The model was trained not only on predicting the next AA but also on the probability distribution of the next AA derived from similar, yet different sequences as summarized in a PSSM, simultaneously for multi-task learning, hence learning evolutionary information of protein sequences as well. The network architecture and the pre-trained model are made available as open source under the permissive MIT license on GitHub at https://github.com/issararab/PEvoLM.
</details>
<details>
<summary>摘要</summary>
随着蛋白序列数据库的不断增长，多序列Alignment（MSA）方法，如PSI-BLAST，在时间上进行了极其探索和耗时的数据库搜索，以获取进化信息。得到的位置特异分数矩阵（PSSM）是这些搜索引擎的结果，这些矩阵在生物信息学和计算生物学领域中是非常重要的输入。蛋白序列是一系列连续的字符或氨基酸（AA）的集合。通过将蛋白序列与自然语言的对比，我们可以利用自然语言处理领域的最新进展，并将其传递到生物信息学中。本研究提出了一种Embedding Language Model（ELMo），将蛋白序列转换为数字向量表示。原ELMo使用了两层双向长短时间记忆（LSTM）网络，其中一个是向前 pass，另一个是向后 pass，通过将PSSM的想法与传输学习的概念结合起来，这种工作引入了一种新的双向语言模型（bi-LM），它具有四倍少的自由参数，并使用单路进行两个过程。模型不仅可以预测下一个AA，还可以同时预测下一个AA的分布情况，基于相似 yet different 的序列，这是通过多任务学习来学习蛋白序列的进化信息。网络架构和预训练模型都是开源的，可以在 GitHub 上下载，详细信息请参考 <https://github.com/issararab/PEvoLM>。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-Benchmark-for-Evaluating-Spatial-Misalignment-of-Prototypical-Parts-Explanations"><a href="#Interpretability-Benchmark-for-Evaluating-Spatial-Misalignment-of-Prototypical-Parts-Explanations" class="headerlink" title="Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations"></a>Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08162">http://arxiv.org/abs/2308.08162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikołaj Sacha, Bartosz Jura, Dawid Rymarczyk, Łukasz Struski, Jacek Tabor, Bartosz Zieliński</li>
<li>for: 提高parts-based网络的可解释性</li>
<li>methods: 引入特定的metric集来衡量相关的概念错误，并提出一种修正方法来解决这种错误</li>
<li>results: 通过实验研究，证明了该metric集的表达能力和修正方法的有效性<details>
<summary>Abstract</summary>
Prototypical parts-based networks are becoming increasingly popular due to their faithful self-explanations. However, their similarity maps are calculated in the penultimate network layer. Therefore, the receptive field of the prototype activation region often depends on parts of the image outside this region, which can lead to misleading interpretations. We name this undesired behavior a spatial explanation misalignment and introduce an interpretability benchmark with a set of dedicated metrics for quantifying this phenomenon. In addition, we propose a method for misalignment compensation and apply it to existing state-of-the-art models. We show the expressiveness of our benchmark and the effectiveness of the proposed compensation methodology through extensive empirical studies.
</details>
<details>
<summary>摘要</summary>
归并部网络在当前受欢迎的程度增加，这主要归功于它们的自我解释性。然而，它们的相似地图通常在半 finales层计算，因此prototype activation区域的接受范围经常受到图像外部的部分影响，这可能会导致误导性的解释。我们称这种不 DESirable 行为为空间解释不一致，并提出了一个专门的可解释指标集来量化这种现象。此外，我们还提出了一种补做方法，并应用于现有的状态级模型。我们通过广泛的实验研究表明了我们的指标和补做方法的表达能力和效果。
</details></li>
</ul>
<hr>
<h2 id="AutoGen-Enabling-Next-Gen-LLM-Applications-via-Multi-Agent-Conversation-Framework"><a href="#AutoGen-Enabling-Next-Gen-LLM-Applications-via-Multi-Agent-Conversation-Framework" class="headerlink" title="AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"></a>AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08155">http://arxiv.org/abs/2308.08155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang</li>
<li>for: 这份论文是为了开发基于多个代理的 LLM 应用程序而设计的一个框架。</li>
<li>methods: 这个框架使用多种代理进行对话，以解决任务。这些代理可以在不同的模式下运行，包括使用 LLM、人类输入和工具。</li>
<li>results: 这个框架可以减轻 LLM 生成和理解能力的强大 yet 不完美性，同时充分利用人类的理解和智慧。它还可以简化和统一复杂的 LLM 工作流程，使其变得更加自然和简单。<details>
<summary>Abstract</summary>
This technical report presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers multiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; b) it leverages human understanding and intelligence, while providing valuable automation through conversations between agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide many diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging from coding, mathematics, operations research, entertainment, online decision-making, question answering, etc.
</details>
<details>
<summary>摘要</summary>
这份技术报告介绍了AutoGen，一个新的框架，它使得开发 LLM 应用程序的多个代理可以互相对话以解决任务。AutoGen 代理可定制化、可对话、可以轻松地允许人类参与。它们可以在不同的模式下运行，这些模式可以结合 LLM、人类输入和工具来实现。AutoGen 的设计具有多个优点：一、它高效地缓解了 LLM 的强大 yet imperfect 生成和推理能力; 二、它利用人类的理解和智慧，同时提供了有价值的对话between agents; 三、它简化和统一了复杂 LLM 工作流的实现。我们提供了许多不同的开发者可以轻松地使用 AutoGen 解决任务或构建应用程序的示例，包括编程、数学、运筹、娱乐、在线决策、问答等等。
</details></li>
</ul>
<hr>
<h2 id="AI-For-Fraud-Awareness"><a href="#AI-For-Fraud-Awareness" class="headerlink" title="AI For Fraud Awareness"></a>AI For Fraud Awareness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11032">http://arxiv.org/abs/2308.11032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krdinal/CryptoFraud">https://github.com/krdinal/CryptoFraud</a></li>
<li>paper_authors: Prabh Simran Singh Baweja, Orathai Sangpetch, Akkarit Sangpetch</li>
<li>for: 防止投资骗局和吸引人类资源</li>
<li>methods: 机器学习和游戏化技术</li>
<li>results: 个性化学习经验和预测投资骗局成功率提高<details>
<summary>Abstract</summary>
In today's world, with the rise of numerous social platforms, it has become relatively easy for anyone to spread false information and lure people into traps. Fraudulent schemes and traps are growing rapidly in the investment world. Due to this, countries and individuals face huge financial risks. We present an awareness system with the use of machine learning and gamification techniques to educate the people about investment scams and traps. Our system applies machine learning techniques to provide a personalized learning experience to the user. The system chooses distinct game-design elements and scams from the knowledge pool crafted by domain experts for each individual. The objective of the research project is to reduce inequalities in all countries by educating investors via Active Learning. Our goal is to assist the regulators in assuring a conducive environment for a fair, efficient, and inclusive capital market. In the paper, we discuss the impact of the problem, provide implementation details, and showcase the potentiality of the system through preliminary experiments and results.
</details>
<details>
<summary>摘要</summary>
今天的世界，由于社交平台的崛起，任何人都可以轻松地散布假信息和陷阱。投资领域的诈骗和陷阱在快速增长。由于此，国家和个人面临巨大的金融风险。我们提出了一种意识系统，通过机器学习和游戏化技术来教育人们关于投资诈骗和陷阱。我们的系统使用机器学习技术提供个性化学习经验 для每名用户。系统从培育专家制定的知识库中选择了不同的游戏元素和诈骗，为每名用户制定个性化的学习计划。我们的研究目标是通过活动学习减少全球各国的不平等。我们的目标是协助监管机构建立一个公平、高效、包容的资本市场环境。在论文中，我们讨论了问题的影响、实施细节以及系统的潜在可能性，并通过初步实验和结果展示系统的效果。
</details></li>
</ul>
<hr>
<h2 id="SYENet-A-Simple-Yet-Effective-Network-for-Multiple-Low-Level-Vision-Tasks-with-Real-time-Performance-on-Mobile-Device"><a href="#SYENet-A-Simple-Yet-Effective-Network-for-Multiple-Low-Level-Vision-Tasks-with-Real-time-Performance-on-Mobile-Device" class="headerlink" title="SYENet: A Simple Yet Effective Network for Multiple Low-Level Vision Tasks with Real-time Performance on Mobile Device"></a>SYENet: A Simple Yet Effective Network for Multiple Low-Level Vision Tasks with Real-time Performance on Mobile Device</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08137">http://arxiv.org/abs/2308.08137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiran Gou, Ziyao Yi, Yan Xiang, Shaoqing Li, Zibin Liu, Dehui Kong, Ke Xu<br>for:This paper aims to solve the problems of task-specific algorithms and large parameters in deep learning-based low-level vision tasks on mobile devices.methods:The proposed SYENet network consists of two asymmetrical branches with simple building blocks and a Quadratic Connection Unit(QCU) to connect the results. The network also uses a new Outlier-Aware Loss to improve performance.results:The proposed SYENet network achieves superior performance in real-time applications such as Image Signal Processing(ISP), Low-Light Enhancement(LLE), and Super-Resolution(SR) with 2K60FPS throughput on Qualcomm 8 Gen 1 mobile SoC. Specifically, it got the highest score in MAI 2022 Learned Smartphone ISP challenge for ISP task.<details>
<summary>Abstract</summary>
With the rapid development of AI hardware accelerators, applying deep learning-based algorithms to solve various low-level vision tasks on mobile devices has gradually become possible. However, two main problems still need to be solved: task-specific algorithms make it difficult to integrate them into a single neural network architecture, and large amounts of parameters make it difficult to achieve real-time inference. To tackle these problems, we propose a novel network, SYENet, with only $~$6K parameters, to handle multiple low-level vision tasks on mobile devices in a real-time manner. The SYENet consists of two asymmetrical branches with simple building blocks. To effectively connect the results by asymmetrical branches, a Quadratic Connection Unit(QCU) is proposed. Furthermore, to improve performance, a new Outlier-Aware Loss is proposed to process the image. The proposed method proves its superior performance with the best PSNR as compared with other networks in real-time applications such as Image Signal Processing(ISP), Low-Light Enhancement(LLE), and Super-Resolution(SR) with 2K60FPS throughput on Qualcomm 8 Gen 1 mobile SoC(System-on-Chip). Particularly, for ISP task, SYENet got the highest score in MAI 2022 Learned Smartphone ISP challenge.
</details>
<details>
<summary>摘要</summary>
随着人工智能硬件加速器的快速发展，在移动设备上应用深度学习算法来解决各种低级视觉任务已经变得可能。然而，两个主要问题仍需要解决：任务特定的算法难以集成到单一神经网络架构中，以及大量参数使得实时推理困难。为解决这些问题，我们提出了一种新的网络，SYENet，只有约6K个参数，可以在移动设备上实时处理多种低级视觉任务。SYENet由两个不同的束缚分支组成，每个分支都有简单的建筑块。为了有效地连接两个分支的结果，我们提出了一种叫做Quadratic Connection Unit(QCU)的新单元。此外，我们还提出了一种新的外围感知损失函数，用于处理图像。我们的方法在实时应用中证明了superior表现，包括PSNR在qualcomm 8 Gen 1移动SoC上的2K60FPS通道上，并在ISP、LLE和SR等任务上达到了最高分。特别是在ISP任务上，SYENet获得了2022年MAI学习智能手机ISP挑战赛中的最高分。
</details></li>
</ul>
<hr>
<h2 id="Ranking-aware-Uncertainty-for-Text-guided-Image-Retrieval"><a href="#Ranking-aware-Uncertainty-for-Text-guided-Image-Retrieval" class="headerlink" title="Ranking-aware Uncertainty for Text-guided Image Retrieval"></a>Ranking-aware Uncertainty for Text-guided Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08131">http://arxiv.org/abs/2308.08131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Chen, Hanjiang Lai</li>
<li>For: The paper is written for text-guided image retrieval, specifically to incorporate conditional text to better capture users’ intent.* Methods: The paper proposes a novel ranking-aware uncertainty approach that uses only the provided triplets to capture more ranking information. The approach consists of three components: in-sample uncertainty, cross-sample uncertainty, and distribution regularization.* Results: The proposed method achieves significant results on two public datasets for composed image retrieval compared to existing state-of-the-art methods.Here is the information in Simplified Chinese text:* For: 文章是为文本指导图像检索，具体来说是使用条件文本更好地捕捉用户的意图。* Methods: 文章提出了一种基于 uncertainty 的排名感知方法，只使用提供的 triplets 来更好地捕捉排名信息。该方法包括三个组成部分：内样 uncertainty，交叉样 uncertainty 和分布规范。* Results: 提出的方法在两个公共数据集上实现了与现有状态艺术方法相比较出色的结果。<details>
<summary>Abstract</summary>
Text-guided image retrieval is to incorporate conditional text to better capture users' intent. Traditionally, the existing methods focus on minimizing the embedding distances between the source inputs and the targeted image, using the provided triplets $\langle$source image, source text, target image$\rangle$. However, such triplet optimization may limit the learned retrieval model to capture more detailed ranking information, e.g., the triplets are one-to-one correspondences and they fail to account for many-to-many correspondences arising from semantic diversity in feedback languages and images. To capture more ranking information, we propose a novel ranking-aware uncertainty approach to model many-to-many correspondences by only using the provided triplets. We introduce uncertainty learning to learn the stochastic ranking list of features. Specifically, our approach mainly comprises three components: (1) In-sample uncertainty, which aims to capture semantic diversity using a Gaussian distribution derived from both combined and target features; (2) Cross-sample uncertainty, which further mines the ranking information from other samples' distributions; and (3) Distribution regularization, which aligns the distributional representations of source inputs and targeted image. Compared to the existing state-of-the-art methods, our proposed method achieves significant results on two public datasets for composed image retrieval.
</details>
<details>
<summary>摘要</summary>
文本帮助图像检索是将条件文本更好地捕捉用户的意图。传统方法通常是通过使用提供的三元组 $\langle$源图像、源文本、目标图像$\rangle$ 进行距离计算，以最小化嵌入空间中的距离。然而，这种三元组优化可能会限制学习的检索模型，从而缺乏更多的排名信息，例如：三元组是一对一对应关系，而忽略了语言反馈和图像之间的多对多关系。为了捕捉更多的排名信息，我们提出了一种新的排名不确定采用方法。我们的方法包括三个主要组成部分：1. 样本内不确定性，它用一个由combined和目标特征组成的 Gaussian 分布来捕捉语义多样性。2. 交叉样本不确定性，它进一步挖掘来自其他样本的排名信息。3. 分布规则，它将源输入和目标图像的分布表示相似。与现有状态艺术方法相比，我们的提出方法在两个公共数据集上 achieved 显著的结果。
</details></li>
</ul>
<hr>
<h2 id="How-to-Mask-in-Error-Correction-Code-Transformer-Systematic-and-Double-Masking"><a href="#How-to-Mask-in-Error-Correction-Code-Transformer-Systematic-and-Double-Masking" class="headerlink" title="How to Mask in Error Correction Code Transformer: Systematic and Double Masking"></a>How to Mask in Error Correction Code Transformer: Systematic and Double Masking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08128">http://arxiv.org/abs/2308.08128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seong-Joon Park, Hee-Youl Kwak, Sang-Hyo Kim, Sunghwan Kim, Yongjune Kim, Jong-Seon No</li>
<li>for: 提高 Error Correction Code Transformer (ECCT) 的性能和计算复杂度</li>
<li>methods: 使用系统编码技术和两种不同的掩码矩阵（一个为 double-masked ECCT），提高 ECCT 的表现和学习多样性</li>
<li>results: 对 ECCT 进行修改后，实现了 state-of-the-art 的解码性能，与传统的解码算法相比，具有显著的性能优势<details>
<summary>Abstract</summary>
In communication and storage systems, error correction codes (ECCs) are pivotal in ensuring data reliability. As deep learning's applicability has broadened across diverse domains, there is a growing research focus on neural network-based decoders that outperform traditional decoding algorithms. Among these neural decoders, Error Correction Code Transformer (ECCT) has achieved the state-of-the-art performance, outperforming other methods by large margins. To further enhance the performance of ECCT, we propose two novel methods. First, leveraging the systematic encoding technique of ECCs, we introduce a new masking matrix for ECCT, aiming to improve the performance and reduce the computational complexity. Second, we propose a novel transformer architecture of ECCT called a double-masked ECCT. This architecture employs two different mask matrices in a parallel manner to learn more diverse features of the relationship between codeword bits in the masked self-attention blocks. Extensive simulation results show that the proposed double-masked ECCT outperforms the conventional ECCT, achieving the state-of-the-art decoding performance with significant margins.
</details>
<details>
<summary>摘要</summary>
在通信和存储系统中，错误修复码（ECC）是确保数据可靠性的关键。随着深度学习在不同领域的应用积极扩大，关注 neural network 基于decoder 的研究也在不断增长。 Among these neural decoders, Error Correction Code Transformer（ECCT）已经实现了领先的性能，比其他方法有大幅的优势。为了进一步提高 ECCT 的性能，我们提出了两种新方法。首先，利用 ECC 的系统编码技术，我们引入了一个新的面积矩阵，以提高性能并降低计算复杂度。其次，我们提出了一种新的 transformer 架构，called double-masked ECCT，这种架构在并行方式使用了两个不同的面积矩阵，以学习codeword 比特在面积矩阵中的更多的特征。经验性 simulation 结果表明，我们提出的 double-masked ECCT 可以超过 convent ECCT，实现了领先的解码性能，并且具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="OmniZoomer-Learning-to-Move-and-Zoom-in-on-Sphere-at-High-Resolution"><a href="#OmniZoomer-Learning-to-Move-and-Zoom-in-on-Sphere-at-High-Resolution" class="headerlink" title="OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution"></a>OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08114">http://arxiv.org/abs/2308.08114</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zidong Cao, Hao Ai, Yan-Pei Cao, Ying Shan, Xiaohu Qie, Lin Wang</li>
<li>for: 提供高品质旋转和缩放功能 для Omnidirectional images (ODIs)</li>
<li>methods: 使用深度学习方法，包括M&quot;obius变换和高分辨率特征地图生成模块，解决锚点噪声和投影问题</li>
<li>results: 实现高品质和分辨率的旋转和缩放功能，可以在虚拟现实环境中自由移动和缩放到 interessant object<details>
<summary>Abstract</summary>
Omnidirectional images (ODIs) have become increasingly popular, as their large field-of-view (FoV) can offer viewers the chance to freely choose the view directions in immersive environments such as virtual reality. The M\"obius transformation is typically employed to further provide the opportunity for movement and zoom on ODIs, but applying it to the image level often results in blurry effect and aliasing problem. In this paper, we propose a novel deep learning-based approach, called \textbf{OmniZoomer}, to incorporate the M\"obius transformation into the network for movement and zoom on ODIs. By learning various transformed feature maps under different conditions, the network is enhanced to handle the increasing edge curvatures, which alleviates the blurry effect. Moreover, to address the aliasing problem, we propose two key components. Firstly, to compensate for the lack of pixels for describing curves, we enhance the feature maps in the high-resolution (HR) space and calculate the transformed index map with a spatial index generation module. Secondly, considering that ODIs are inherently represented in the spherical space, we propose a spherical resampling module that combines the index map and HR feature maps to transform the feature maps for better spherical correlation. The transformed feature maps are decoded to output a zoomed ODI. Experiments show that our method can produce HR and high-quality ODIs with the flexibility to move and zoom in to the object of interest. Project page is available at http://vlislab22.github.io/OmniZoomer/.
</details>
<details>
<summary>摘要</summary>
“全方位图像（ODIs）在现实Virtual Reality等充满Environment中日益受欢迎，因其广阔的视场（FoV）可以让观看者自由选择视线。通常，使用Möbius变换来提供更多的运动和尺度缩放功能，但在图像层次上应用Möbius变换经常会导致模糊效果和抖音问题。在这篇论文中，我们提出了一种基于深度学习的新方法，称为OmniZoomer，以把Möbius变换 incorporated into the network for movement and zoom on ODIs。通过学习不同条件下的变换特征地图，网络得以处理增加的边缘弯曲，从而缓解模糊效果。此外，为了解决抖音问题，我们提出了两个关键 ком成分。首先，为了补偿因为描述曲线而缺少像素的问题，我们增强了高分辨率（HR）空间中的特征地图，并计算 transformed index map with a spatial index generation module。其次，因为ODIs是自然地表示在球面空间，我们提出了一个球面采样模块，将特征地图和HR特征地图组合起来，以便更好地在球面上匹配。 transformed feature maps are then decoded to output a zoomed ODI。实验结果表明，我们的方法可以生成高分辨率和高质量的ODIs，并且具有可以随意移动和缩放到对象所在位置的功能。项目页面可以在http://vlislab22.github.io/OmniZoomer/ 中找到。”
</details></li>
</ul>
<hr>
<h2 id="ChatLogo-A-Large-Language-Model-Driven-Hybrid-Natural-Programming-Language-Interface-for-Agent-based-Modeling-and-Programming"><a href="#ChatLogo-A-Large-Language-Model-Driven-Hybrid-Natural-Programming-Language-Interface-for-Agent-based-Modeling-and-Programming" class="headerlink" title="ChatLogo: A Large Language Model-Driven Hybrid Natural-Programming Language Interface for Agent-based Modeling and Programming"></a>ChatLogo: A Large Language Model-Driven Hybrid Natural-Programming Language Interface for Agent-based Modeling and Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08102">http://arxiv.org/abs/2308.08102</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Chen, Uri Wilensky</li>
<li>for: 支持开放式构建主义学习 Agent-Based Modeling 和 Programming</li>
<li>methods: 结合自然语言和程序语言的混合界面，使用大语言模型支持计算程序学习</li>
<li>results: 提供一个更用户友好的界面，支持创造性表达，并避免技术系统过度依赖于单个大语言模型<details>
<summary>Abstract</summary>
Building on Papert (1980)'s idea of children talking to computers, we propose ChatLogo, a hybrid natural-programming language interface for agent-based modeling and programming. We build upon previous efforts to scaffold ABM & P learning and recent development in leveraging large language models (LLMs) to support the learning of computational programming. ChatLogo aims to support conversations with computers in a mix of natural and programming languages, provide a more user-friendly interface for novice learners, and keep the technical system from over-reliance on any single LLM. We introduced the main elements of our design: an intelligent command center, and a conversational interface to support creative expression. We discussed the presentation format and future work. Responding to the challenges of supporting open-ended constructionist learning of ABM & P and leveraging LLMs for educational purposes, we contribute to the field by proposing the first constructionist LLM-driven interface to support computational and complex systems thinking.
</details>
<details>
<summary>摘要</summary>
使用 Papert（1980）的想法，我们提议了 ChatLogo，一种混合自然编程语言界面，用于代理模型和编程。我们建立在以前的尝试和使用大型语言模型（LLMs）支持计算编程的学习。ChatLogo 目标是在自然语言和编程语言之间进行对话，提供更易于使用的界面 для初学者，并避免技术系统对任何单一 LLM 的过度依赖。我们介绍了我们的设计的主要元素：一个智能命令中心，以及一个对话界面支持创造表达。我们讨论了展示形式和未来工作。面对支持开放式构建主义学习 ABM & P 以及使用 LLMs 教育目的的挑战，我们在领域中贡献了第一个构建主义 LLM-驱动的界面，用于支持计算和复杂系统思维。
</details></li>
</ul>
<hr>
<h2 id="S-Mixup-Structural-Mixup-for-Graph-Neural-Networks"><a href="#S-Mixup-Structural-Mixup-for-Graph-Neural-Networks" class="headerlink" title="S-Mixup: Structural Mixup for Graph Neural Networks"></a>S-Mixup: Structural Mixup for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08097">http://arxiv.org/abs/2308.08097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sukwonyun/s-mixup">https://github.com/sukwonyun/s-mixup</a></li>
<li>paper_authors: Junghurn Kim, Sukwon Yun, Chanyoung Park</li>
<li>for: 本研究的目的是提出一种基于图Structural Mixup（S-Mixup）的图节点分类方法，以提高图 neural network（GNN）的Robustness和泛化性。</li>
<li>methods: 本研究使用了一种新的混合策略，即Structural Mixup（S-Mixup），它利用图神经网络（GNN）的预测信度来选择混合Pool中的节点。此外，本研究还提出了一种基于Edge Gradient的边选择策略，以提高混合后的节点的连接性。</li>
<li>results: 经过广泛的实验表明，S-Mixup可以提高GNN的Robustness和泛化性，特别在异质情况下。同时，S-Mixup可以减少模型的训练时间和计算量，同时保持模型的性能。<details>
<summary>Abstract</summary>
Existing studies for applying the mixup technique on graphs mainly focus on graph classification tasks, while the research in node classification is still under-explored. In this paper, we propose a novel mixup augmentation for node classification called Structural Mixup (S-Mixup). The core idea is to take into account the structural information while mixing nodes. Specifically, S-Mixup obtains pseudo-labels for unlabeled nodes in a graph along with their prediction confidence via a Graph Neural Network (GNN) classifier. These serve as the criteria for the composition of the mixup pool for both inter and intra-class mixups. Furthermore, we utilize the edge gradient obtained from the GNN training and propose a gradient-based edge selection strategy for selecting edges to be attached to the nodes generated by the mixup. Through extensive experiments on real-world benchmark datasets, we demonstrate the effectiveness of S-Mixup evaluated on the node classification task. We observe that S-Mixup enhances the robustness and generalization performance of GNNs, especially in heterophilous situations. The source code of S-Mixup can be found at \url{https://github.com/SukwonYun/S-Mixup}
</details>
<details>
<summary>摘要</summary>
existstudies haves focus on graph classification tasks, whileresearch in node classification stil under-explored. In this paper, we propose a novel mixup augmentation for node classification called Structural Mixup (S-Mixup). Core idea is to take into account the structural information while mixing nodes. Specifically, S-Mixup obtains pseudo-labels for unlabeled nodes in a graph along with their prediction confidence via a Graph Neural Network (GNN) classifier. These serve as the criteria for the composition of the mixup pool for both inter and intra-class mixups. Furthermore, we utilize the edge gradient obtained from the GNN training and propose a gradient-based edge selection strategy for selecting edges to be attached to the nodes generated by the mixup. Through extensive experiments on real-world benchmark datasets, we demonstrate the effectiveness of S-Mixup evaluated on the node classification task. We observe that S-Mixup enhances the robustness and generalization performance of GNNs, especially in heterophilous situations. Source code of S-Mixup can be found at \url{https://github.com/SukwonYun/S-Mixup}
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Graph-Neural-Network-for-Privacy-Preserving-Recommendation"><a href="#Decentralized-Graph-Neural-Network-for-Privacy-Preserving-Recommendation" class="headerlink" title="Decentralized Graph Neural Network for Privacy-Preserving Recommendation"></a>Decentralized Graph Neural Network for Privacy-Preserving Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08072">http://arxiv.org/abs/2308.08072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Jiashu Qian, Yao Yang</li>
<li>for: 提出一种隐私保护的分布式图神经网络推荐系统，解决现有方法存在低效率和隐私泄露问题。</li>
<li>methods: 提出了一种新的分布式图神经网络（DGREC），包括三个阶段：图建构、本地梯度计算和全局梯度传递。用户可以选择公开交互记录。</li>
<li>results: 通过三个公共数据集进行了广泛的实验 validate了我们的框架在多个维度上的一致优势，包括推荐效果、通信效率和隐私保护。<details>
<summary>Abstract</summary>
Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framework.
</details>
<details>
<summary>摘要</summary>
建立一个基于图计算机学(GNN)的推荐系统，并保持用户隐私免受挑战。现有的方法可以分为联邦GNN和分散GNN。但这两种方法都有不愿意的影响，例如对应用的通讯效率低下和隐私泄露。本文提出了DGREC，一个新的分散GNN推荐系统，其中用户可以选择公开他们的互动。这个系统包括三个阶段：图建构、本地偏好模型计算和全球偏好计算。第一个阶段建立了每个用户的本地内部项目图和全球用户图。第二个阶段模型用户偏好，计算每个本地设备上的偏好计算。第三个阶段设计了一个安全的偏好分享机制，以保证用户的私人数据的强大隐私。我们在三个公共数据集上进行了广泛的实验，以验证我们的框架的一致性和superiority。
</details></li>
</ul>
<hr>
<h2 id="Freshness-or-Accuracy-Why-Not-Both-Addressing-Delayed-Feedback-via-Dynamic-Graph-Neural-Networks"><a href="#Freshness-or-Accuracy-Why-Not-Both-Addressing-Delayed-Feedback-via-Dynamic-Graph-Neural-Networks" class="headerlink" title="Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via Dynamic Graph Neural Networks"></a>Freshness or Accuracy, Why Not Both? Addressing Delayed Feedback via Dynamic Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08071">http://arxiv.org/abs/2308.08071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Feng Zhu, Jiashu Qian<br>for: This paper aims to address the delayed feedback problem in online commercial systems, where users’ conversions are always delayed and can negatively impact the accuracy of training algorithms.methods: The proposed method, called Delayed Feedback Modeling by Dynamic Graph Neural Network (DGDFEM), includes three stages: preparing a data pipeline, building a dynamic graph, and training a CVR prediction model. The model training uses a novel graph convolutional method named HLGCN, which leverages both high-pass and low-pass filters to deal with conversion and non-conversion relationships.results: The proposed method achieves both data freshness and label accuracy, as validated by extensive experiments on three industry datasets. The results show the consistent superiority of the method over existing methods.<details>
<summary>Abstract</summary>
The delayed feedback problem is one of the most pressing challenges in predicting the conversion rate since users' conversions are always delayed in online commercial systems. Although new data are beneficial for continuous training, without complete feedback information, i.e., conversion labels, training algorithms may suffer from overwhelming fake negatives. Existing methods tend to use multitask learning or design data pipelines to solve the delayed feedback problem. However, these methods have a trade-off between data freshness and label accuracy. In this paper, we propose Delayed Feedback Modeling by Dynamic Graph Neural Network (DGDFEM). It includes three stages, i.e., preparing a data pipeline, building a dynamic graph, and training a CVR prediction model. In the model training, we propose a novel graph convolutional method named HLGCN, which leverages both high-pass and low-pass filters to deal with conversion and non-conversion relationships. The proposed method achieves both data freshness and label accuracy. We conduct extensive experiments on three industry datasets, which validate the consistent superiority of our method.
</details>
<details>
<summary>摘要</summary>
延迟反馈问题是在线商业系统预测转化率时最大的挑战之一，因为用户的转化事件总是延迟的。新的数据对于连续训练是有利的，但无完整反馈信息，即转化标签，训练算法可能受到充斥假负样本的困扰。现有方法通常使用多任务学习或设计数据管道来解决延迟反馈问题，但这些方法存在数据新鲜度和标签准确性之间的负担。本文提出了延迟反馈模型化方法（DGDFEM），它包括三个阶段：准备数据管道、建立动态图和训练CVR预测模型。在模型训练中，我们提出了一种新的图 convolutional方法名为HLGCN，它利用高频和低频滤波器来处理转化和非转化关系。我们的方法实现了数据新鲜度和标签准确性的平衡。我们对三个行业数据集进行了广泛的实验，验证了我们的方法的一致性优势。
</details></li>
</ul>
<hr>
<h2 id="Simple-online-learning-with-consistency-oracle"><a href="#Simple-online-learning-with-consistency-oracle" class="headerlink" title="Simple online learning with consistency oracle"></a>Simple online learning with consistency oracle</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08055">http://arxiv.org/abs/2308.08055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Kozachinskiy, Tomasz Steifer</li>
<li>for: 本文研究在一种模型中进行在线学习，其中学习算法可以通过一个一致性 oracle 访问类型。</li>
<li>methods: 本文使用了一种新的算法，该算法可以在类型的 Littlestone 维度为 $d$ 的情况下最多出现 $O(256^d)$ 个错误。</li>
<li>results: 本文的算法可以解决一个开放的问题，即每个有限的 Littlestone 维度类型都存在一个可计算的在线学习算法。<details>
<summary>Abstract</summary>
We consider online learning in the model where a learning algorithm can access the class only via the consistency oracle -- an oracle, that, at any moment, can give a function from the class that agrees with all examples seen so far. This model was recently considered by Assos et al. (COLT'23). It is motivated by the fact that standard methods of online learning rely on computing the Littlestone dimension of subclasses, a problem that is computationally intractable. Assos et al. gave an online learning algorithm in this model that makes at most $C^d$ mistakes on classes of Littlestone dimension $d$, for some absolute unspecified constant $C > 0$. We give a novel algorithm that makes at most $O(256^d)$ mistakes. Our proof is significantly simpler and uses only very basic properties of the Littlestone dimension. We also observe that there exists no algorithm in this model that makes at most $2^{d+1}-2$ mistakes. We also observe that our algorithm (as well as the algorithm of Assos et al.) solves an open problem by Hasrati and Ben-David (ALT'23). Namely, it demonstrates that every class of finite Littlestone dimension with recursively enumerable representation admits a computable online learner (that may be undefined on unrealizable samples).
</details>
<details>
<summary>摘要</summary>
我们考虑在模型中进行在线学习，其中学习算法可以通过一个一致性 oracle 访问类型。这个 oracle 可以在任何时刻给出一个与所有前面看到的示例都一致的函数。这种模型在 Assos et al. (COLT'23) 中最近被考虑。它是由于标准的在线学习方法需要计算子类的 Litstone 维度，这是计算上不可能的问题而启发的。Assos et al. 提供了一个在这种模型中的在线学习算法，该算法在类型的 Litstone 维度为 $d$ 时最多会出现 $C^d$ 个错误，其中 $C$ 是一个未知的绝对常数。我们提供了一个新的算法，该算法在类型的 Litstone 维度为 $d$ 时最多会出现 $O(256^d)$ 个错误。我们的证明比较简单，只需使用了类型的 Litstone 维度的基本性质。我们还观察到，在这种模型中并没有任何算法可以在类型的 Litstone 维度为 $d$ 时出现最多 $2^{d+1}-2$ 个错误。此外，我们的算法（以及 Assos et al. 的算法）解决了 Hasrati 和 Ben-David (ALT'23) 提出的一个开放问题。即，我们证明了所有有 finite Littlestone 维度的类型都具有可计算的在线学习算法（可能是 undefined 的示例）。
</details></li>
</ul>
<hr>
<h2 id="Unbiased-Decisions-Reduce-Regret-Adversarial-Domain-Adaptation-for-the-Bank-Loan-Problem"><a href="#Unbiased-Decisions-Reduce-Regret-Adversarial-Domain-Adaptation-for-the-Bank-Loan-Problem" class="headerlink" title="Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem"></a>Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08051">http://arxiv.org/abs/2308.08051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Gal, Shaun Singh, Aldo Pacchiano, Ben Walker, Terry Lyons, Jakob Foerster</li>
<li>for: 这篇研究是针对具有限制数据和实时决策的内部分数推干领域进行的，特别是在贷款申请时进行评估。</li>
<li>methods: 这篇研究使用了反抗伪阳性抑制（AdOpt）来直接对训练集中的偏袋问题进行修正，以获得不偏的但是有用的表现。</li>
<li>results: 研究获得了一系列具有挑战性的 benchmark 问题的州望性结果，并且初步证明了这种方法可以提高这些问题中的公平性。<details>
<summary>Abstract</summary>
In many real world settings binary classification decisions are made based on limited data in near real-time, e.g. when assessing a loan application. We focus on a class of these problems that share a common feature: the true label is only observed when a data point is assigned a positive label by the principal, e.g. we only find out whether an applicant defaults if we accepted their loan application. As a consequence, the false rejections become self-reinforcing and cause the labelled training set, that is being continuously updated by the model decisions, to accumulate bias. Prior work mitigates this effect by injecting optimism into the model, however this comes at the cost of increased false acceptance rate. We introduce adversarial optimism (AdOpt) to directly address bias in the training set using adversarial domain adaptation. The goal of AdOpt is to learn an unbiased but informative representation of past data, by reducing the distributional shift between the set of accepted data points and all data points seen thus far. AdOpt significantly exceeds state-of-the-art performance on a set of challenging benchmark problems. Our experiments also provide initial evidence that the introduction of adversarial domain adaptation improves fairness in this setting.
</details>
<details>
<summary>摘要</summary>
在许多实际场景中，二分类决策是基于有限数据和减速时间进行的，例如评审借款申请。我们关注一类这些问题，这些问题共享一个共同特点：真正的标签仅当数据点被主体分配正确标签时才能见到，例如，只有当我们接受借款申请后才能知道是否有 Default。这导致 false reject 变得自我强化，使得标记的训练集，由模型决策更新，逐渐受到偏见。先前的工作利用模型中的optimism来避免这种偏见，但这会导致准确接受率增加。我们引入对抗优isms（AdOpt）来直接 Address 训练集中的偏见，通过对抗领域适应来学习不偏的、但具有信息的表示。AdOpt 在一组挑战性 benchmark 问题上表现出色，大大超过了当前状态的性能。我们的实验还提供了初步证据，表明在这种设定下，对抗领域适应可以提高公平性。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Analysis-of-the-Capabilities-of-Nature-inspired-Feature-Selection-Algorithms-in-Predicting-Student-Performance"><a href="#A-Comparative-Analysis-of-the-Capabilities-of-Nature-inspired-Feature-Selection-Algorithms-in-Predicting-Student-Performance" class="headerlink" title="A Comparative Analysis of the Capabilities of Nature-inspired Feature Selection Algorithms in Predicting Student Performance"></a>A Comparative Analysis of the Capabilities of Nature-inspired Feature Selection Algorithms in Predicting Student Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08574">http://arxiv.org/abs/2308.08574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Trask</li>
<li>for: 预测学生表现，以便采取有效的预failure intervención для有 риsk 学生。</li>
<li>methods: 使用12种自然 inspirited算法（NIAs）进行学生表现预测，并 comparing 不同的数据集和方法。</li>
<li>results: 结果表明，无论数据集都可以使用NIAs进行特征选择和传统机器学习算法进行分类，可以提高预测精度，同时减少特征集大小 by 2&#x2F;3。<details>
<summary>Abstract</summary>
Predicting student performance is key in leveraging effective pre-failure interventions for at-risk students. In this paper, I have analyzed the relative performance of a suite of 12 nature-inspired algorithms when used to predict student performance across 3 datasets consisting of instance-based clickstream data, intra-course single-course performance, and performance when taking multiple courses simultaneously. I found that, for all datasets, leveraging an ensemble approach using NIAs for feature selection and traditional ML algorithms for classification increased predictive accuracy while also reducing feature set size by 2/3.
</details>
<details>
<summary>摘要</summary>
预测学生表现是关键在实施有效预测措施以 помочь学生避免失败。在这篇论文中，我分析了12种自然静电算法在预测学生表现方面的相对性，并在3个数据集上进行了比较，包括单个课程性能、多门课程同时表现和点播数据。我发现，无论哪个数据集，使用NIAs进行特征选择和传统机器学习算法进行分类可以提高预测精度，同时减少特征集的大小 by 2/3。
</details></li>
</ul>
<hr>
<h2 id="DiagGPT-An-LLM-based-Chatbot-with-Automatic-Topic-Management-for-Task-Oriented-Dialogue"><a href="#DiagGPT-An-LLM-based-Chatbot-with-Automatic-Topic-Management-for-Task-Oriented-Dialogue" class="headerlink" title="DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue"></a>DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08043">http://arxiv.org/abs/2308.08043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lang Cao</li>
<li>for: 这个论文的目的是推广LLMs的应用范围，使其能够在复杂的诊断场景中发挥作用。</li>
<li>methods: 这篇论文提出了一种新的方法，即DiagGPT，用于将LLMs应用于诊断对话场景。DiagGPT通过对用户提问的扩展和启发问题的使用来帮助用户完成任务。</li>
<li>results: 实验表明，DiagGPT在进行诊断对话场景中表现出色，能够帮助用户完成任务。这表明DiagGPT在实际应用中具有潜在的应用前景。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), such as ChatGPT, are becoming increasingly sophisticated, demonstrating capabilities that closely resemble those of humans. These AI models are playing an essential role in assisting humans with a wide array of tasks in daily life. A significant application of AI is its use as a chat agent, responding to human inquiries across various domains. Current LLMs have shown proficiency in answering general questions. However, basic question-answering dialogue often falls short in complex diagnostic scenarios, such as legal or medical consultations. These scenarios typically necessitate Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively pose questions and guide users towards specific task completion. Previous fine-tuning models have underperformed in TOD, and current LLMs do not inherently possess this capability. In this paper, we introduce DiagGPT (Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD scenarios. Our experiments reveal that DiagGPT exhibits outstanding performance in conducting TOD with users, demonstrating its potential for practical applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Automated-Test-Case-Generation-Using-Code-Models-and-Domain-Adaptation"><a href="#Automated-Test-Case-Generation-Using-Code-Models-and-Domain-Adaptation" class="headerlink" title="Automated Test Case Generation Using Code Models and Domain Adaptation"></a>Automated Test Case Generation Using Code Models and Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08033">http://arxiv.org/abs/2308.08033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepehr Hashtroudi, Jiho Shin, Hadi Hemmati, Song Wang</li>
<li>for: 提高自动化测试技术的效果，使其更能够检测复杂bug。</li>
<li>methods: 使用Transformer大型代码模型生成单元测试，并 fine-tune CodeT5 模型进行下游任务。</li>
<li>results: 提出了一个完全自动化测试框架，可以补充搜索基本测试生成器，提高测试覆盖率。results show that our approach can generate new test cases that cover lines that were not covered by developer-written tests, and using domain adaptation can increase line coverage by 49.9% and 54%.<details>
<summary>Abstract</summary>
State-of-the-art automated test generation techniques, such as search-based testing, are usually ignorant about what a developer would create as a test case. Therefore, they typically create tests that are not human-readable and may not necessarily detect all types of complex bugs developer-written tests would do. In this study, we leverage Transformer-based code models to generate unit tests that can complement search-based test generation. Specifically, we use CodeT5, i.e., a state-of-the-art large code model, and fine-tune it on the test generation downstream task. For our analysis, we use the Methods2test dataset for fine-tuning CodeT5 and Defects4j for project-level domain adaptation and evaluation. The main contribution of this study is proposing a fully automated testing framework that leverages developer-written tests and available code models to generate compilable, human-readable unit tests. Results show that our approach can generate new test cases that cover lines that were not covered by developer-written tests. Using domain adaptation, we can also increase line coverage of the model-generated unit tests by 49.9% and 54% in terms of mean and median (compared to the model without domain adaptation). We can also use our framework as a complementary solution alongside common search-based methods to increase the overall coverage with mean and median of 25.3% and 6.3%. It can also increase the mutation score of search-based methods by killing extra mutants (up to 64 new mutants were killed per project in our experiments).
</details>
<details>
<summary>摘要</summary>
现代自动化测试技术，如搜寻式测试，通常忽略开发者会写的测试案例。因此，它们通常会创建不可读的测试和可能不会检测所有类型的复杂bug。在本研究中，我们利用Transformer型别code模型来生成单元测试，以补充搜寻式测试生成器。具体来说，我们使用CodeT5，即现代大型code模型，并对其进行精度调整。我们使用Methods2test数据集进行精度调整和Defects4j进行项目级域适应和评估。本研究的主要贡献是提出了一个完全自动化测试框架，利用开发者写的测试和可用的code模型来生成可读性高的单元测试。结果表明，我们的方法可以生成新的测试案例，覆盖开发者写的测试案例中未覆盖的行数。通过领域适应，我们可以增加模型生成的单元测试的行覆盖率，增加了49.9%和54%的平均和中值（相比无领域适应）。此外，我们的框架还可以作为搜寻式方法的补充解决方案，增加总覆盖率的平均和中值为25.3%和6.3%。此外，它还可以提高搜寻式方法的突变得分，杀死Extra突变（在我们的实验中，每个项目最多杀死64个突变）。
</details></li>
</ul>
<hr>
<h2 id="Planning-to-Learn-A-Novel-Algorithm-for-Active-Learning-during-Model-Based-Planning"><a href="#Planning-to-Learn-A-Novel-Algorithm-for-Active-Learning-during-Model-Based-Planning" class="headerlink" title="Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning"></a>Planning to Learn: A Novel Algorithm for Active Learning during Model-Based Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08029">http://arxiv.org/abs/2308.08029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rowanlibr/sophisticated-learning">https://github.com/rowanlibr/sophisticated-learning</a></li>
<li>paper_authors: Rowan Hodson, Bruce Bassett, Charel van Hoof, Benjamin Rosman, Mark Solms, Jonathan P. Shock, Ryan Smith</li>
<li>for: 这个论文的目的是对Active Inference框架进行评估和改进。</li>
<li>methods: 这个论文使用了强化学习和搜索算法来解决多步规划问题。</li>
<li>results: 论文的实验结果显示，使用强化学习和搜索算法可以在一种生物学上相关的环境中超过其他算法的性能。<details>
<summary>Abstract</summary>
Active Inference is a recent framework for modeling planning under uncertainty. Empirical and theoretical work have now begun to evaluate the strengths and weaknesses of this approach and how it might be improved. A recent extension - the sophisticated inference (SI) algorithm - improves performance on multi-step planning problems through recursive decision tree search. However, little work to date has been done to compare SI to other established planning algorithms. SI was also developed with a focus on inference as opposed to learning. The present paper has two aims. First, we compare performance of SI to Bayesian reinforcement learning (RL) schemes designed to solve similar problems. Second, we present an extension of SI - sophisticated learning (SL) - that more fully incorporates active learning during planning. SL maintains beliefs about how model parameters would change under the future observations expected under each policy. This allows a form of counterfactual retrospective inference in which the agent considers what could be learned from current or past observations given different future observations. To accomplish these aims, we make use of a novel, biologically inspired environment designed to highlight the problem structure for which SL offers a unique solution. Here, an agent must continually search for available (but changing) resources in the presence of competing affordances for information gain. Our simulations show that SL outperforms all other algorithms in this context - most notably, Bayes-adaptive RL and upper confidence bound algorithms, which aim to solve multi-step planning problems using similar principles (i.e., directed exploration and counterfactual reasoning). These results provide added support for the utility of Active Inference in solving this class of biologically-relevant problems and offer added tools for testing hypotheses about human cognition.
</details>
<details>
<summary>摘要</summary>
aktive inferens 是一种最近的 плани法下 uncertainty 的框架。 empirical 和 theoretical 工作已经开始评估这种方法的优缺点，以及如何改进它。 recient extension - sophisticated inference（SI）算法 - 在多步 плани问题上提高性能通过 recursively decision tree 搜索。 然而，到目前为止，对 SI 与其他已知的 плани算法进行比较的工作尚未进行。 SI 还是在推理上而不是学习的方法。 本文的两个目标是：首先，与 bayesian 强化学习（RL）方法相比，SI 的性能如何？其次，我们提出了一种扩展 SI - sophisticated learning（SL） - 它更加具有活动学习在 плани过程中。 SL 维护对未来观测所采取的 Each policy 下的模型参数变化的信念。这允许一种对当前或过去观测进行 counterfactual 推理，即 agent 考虑在不同的未来观测下，当前或过去观测所能学习到什么。 为了实现这些目标，我们使用了一个 novel， biologically 引发的环境，这个环境是为 highlight 这类问题的问题结构而设计的。在这个环境中，agent 需要不断寻找可用（但是变化的）资源，同时面临着竞争的affordances 对信息增长。我们的 simulate 结果显示，SL 在这种情况下超越了所有其他算法 - 特别是 bayes-adaptive RL 和 upper confidence bound 算法，这些算法是使用类似原则（例如，引导探索和 counterfactual 推理）解决多步 плани问题。这些结果为活动推理在这类生物学 relevance 问题的 utility 提供了更多的支持，并为测试人类认知 Hypothesis 提供了新的工具。
</details></li>
</ul>
<hr>
<h2 id="Potential-Energy-Advantage-of-Quantum-Economy"><a href="#Potential-Energy-Advantage-of-Quantum-Economy" class="headerlink" title="Potential Energy Advantage of Quantum Economy"></a>Potential Energy Advantage of Quantum Economy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08025">http://arxiv.org/abs/2308.08025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyu Liu, Hansheng Jiang, Zuo-Jun Max Shen</li>
<li>for: 本研究探讨了量子计算在能源成本方面的优势，并与经典计算进行对比。</li>
<li>methods: 本文使用 Cournot 竞争模型，受限于能源使用情况下，展示了量子计算机构在利润和能源效率方面的优势。</li>
<li>results: 研究发现，量子计算在大规模计算情况下可以实现更高的利润和能源效率，而且这种优势取决于大规模计算。 基于实际物理参数，文章还证明了实现这种能源效率优势所需的规模。<details>
<summary>Abstract</summary>
Energy cost is increasingly crucial in the modern computing industry with the wide deployment of large-scale machine learning models and language models. For the firms that provide computing services, low energy consumption is important both from the perspective of their own market growth and the government's regulations. In this paper, we study the energy benefits of quantum computing vis-a-vis classical computing. Deviating from the conventional notion of quantum advantage based solely on computational complexity, we redefine advantage in an energy efficiency context. Through a Cournot competition model constrained by energy usage, we demonstrate quantum computing firms can outperform classical counterparts in both profitability and energy efficiency at Nash equilibrium. Therefore quantum computing may represent a more sustainable pathway for the computing industry. Moreover, we discover that the energy benefits of quantum computing economies are contingent on large-scale computation. Based on real physical parameters, we further illustrate the scale of operation necessary for realizing this energy efficiency advantage.
</details>
<details>
<summary>摘要</summary>
energy cost is becoming increasingly important in the modern computing industry with the widespread deployment of large-scale machine learning models and language models. for firms that provide computing services, low energy consumption is important both from the perspective of their own market growth and the government's regulations. in this paper, we study the energy benefits of quantum computing compared to classical computing. we deviate from the conventional notion of quantum advantage based solely on computational complexity and redefine advantage in an energy efficiency context. through a Cournot competition model constrained by energy usage, we demonstrate that quantum computing firms can outperform their classical counterparts in both profitability and energy efficiency at the Nash equilibrium. therefore, quantum computing may represent a more sustainable pathway for the computing industry. furthermore, we find that the energy benefits of quantum computing economies are contingent on large-scale computation. based on real physical parameters, we illustrate the scale of operation necessary for realizing this energy efficiency advantage.
</details></li>
</ul>
<hr>
<h2 id="GRINN-A-Physics-Informed-Neural-Network-for-solving-hydrodynamic-systems-in-the-presence-of-self-gravity"><a href="#GRINN-A-Physics-Informed-Neural-Network-for-solving-hydrodynamic-systems-in-the-presence-of-self-gravity" class="headerlink" title="GRINN: A Physics-Informed Neural Network for solving hydrodynamic systems in the presence of self-gravity"></a>GRINN: A Physics-Informed Neural Network for solving hydrodynamic systems in the presence of self-gravity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08010">http://arxiv.org/abs/2308.08010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayantan Auddy, Ramit Dey, Neal J. Turner, Shantanu Basu</li>
<li>for: 模拟三维自引力液体流体是astrophysical questions的解答之一,包括星系形成、 galaxy formation和大规模结构的发展。</li>
<li>methods: 通过利用神经网络的统一近似能力在 mesh-free框架中, physics informed neural networks (PINNs) 提供了一种新的方法来解决这些时间依赖的偏微分方程(PDEs)。</li>
<li>results: 我们的结果与一个线性分析解相匹配在线性 régime中 Within 1% error bound, and with a conventional grid code solution within 5% error bound in the nonlinear regime. 我们发现GRINN计算时间与维度无关，与传统网格代码的计算时间成正比。GRINN computation time is longer than the grid code in one- and two-dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy.<details>
<summary>Abstract</summary>
Modeling self-gravitating gas flows is essential to answering many fundamental questions in astrophysics. This spans many topics including planet-forming disks, star-forming clouds, galaxy formation, and the development of large-scale structures in the Universe. However, the nonlinear interaction between gravity and fluid dynamics offers a formidable challenge to solving the resulting time-dependent partial differential equations (PDEs) in three dimensions (3D). By leveraging the universal approximation capabilities of a neural network within a mesh-free framework, physics informed neural networks (PINNs) offer a new way of addressing this challenge. We introduce the gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D self-gravitating hydrodynamic systems. Here, we specifically study gravitational instability and wave propagation in an isothermal gas. Our results match a linear analytic solution to within 1\% in the linear regime and a conventional grid code solution to within 5\% as the disturbance grows into the nonlinear regime. We find that the computation time of the GRINN does not scale with the number of dimensions. This is in contrast to the scaling of the grid-based code for the hydrodynamic and self-gravity calculations as the number of dimensions is increased. Our results show that the GRINN computation time is longer than the grid code in one- and two- dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy. Physics-informed neural networks like GRINN thus show promise for advancing our ability to model 3D astrophysical flows.
</details>
<details>
<summary>摘要</summary>
模拟自引力液体流动是astrophysics中答您许多基本问题的关键。这些问题包括形成 planetary disks、star-forming clouds、galaxy formation和宇宙大规模结构的发展。然而，gravity和 fluid dynamics之间的非线性互动使得解决 resulting time-dependent partial differential equations (PDEs) 在三维空间 (3D) 中提供了一项困难的挑战。通过利用 neural network 的通用适应能力 within a mesh-free framework，physics informed neural networks (PINNs) 提供了一种新的方法来解决这一挑战。我们介绍了 gravity-informed neural network (GRINN)，一种基于 PINN 的代码，用于模拟 3D 自引力液体系统。我们在特定情况下研究了 gravitational instability 和波传播在固有温度气体中。我们的结果与一个线性分析解相匹配，在线性 regime 中准确到 1%，与一个 convent ional grid code solution 相匹配，在干扰增长到非线性 regime 时准确到 5%。我们发现 GRINN 的计算时间与维度无关。这与 grid-based code 的 hydrodynamic 和自重计算时间在维度增加时的扩展不同。我们的结果显示 GRINN 的计算时间在一维和二维计算中比 grid code 短，但在 3D 计算中比 grid code 更长。Physics-informed neural networks like GRINN 因此显示出了在 3D astrophysical flows 模拟方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-in-Introductory-Programming-Education-ChatGPT’s-Performance-and-Implications-for-Assessments"><a href="#Large-Language-Models-in-Introductory-Programming-Education-ChatGPT’s-Performance-and-Implications-for-Assessments" class="headerlink" title="Large Language Models in Introductory Programming Education: ChatGPT’s Performance and Implications for Assessments"></a>Large Language Models in Introductory Programming Education: ChatGPT’s Performance and Implications for Assessments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08572">http://arxiv.org/abs/2308.08572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Natalie Kiesler, Daniel Schiffner</li>
<li>for: 本研究探讨了使用 Large Language Models (LLMs) ChatGPT-3.5 和 GPT-4 解决入门编程任务的性能。基于性能分析，得出了对教学enario和评价格式的启示。</li>
<li>methods: 研究使用 CodingBat 提供的72个Python任务，并将全任务描述作为输入给 LLMs，并评估generated回答的正确率和可用性。</li>
<li>results: 结果显示 LLMs 的正确率高达94.4%到95.8%，并可靠地提供文本解释和程序代码，这对programming教育和评价方面开启了新的可能性。<details>
<summary>Abstract</summary>
This paper investigates the performance of the Large Language Models (LLMs) ChatGPT-3.5 and GPT-4 in solving introductory programming tasks. Based on the performance, implications for didactic scenarios and assessment formats utilizing LLMs are derived. For the analysis, 72 Python tasks for novice programmers were selected from the free site CodingBat. Full task descriptions were used as input to the LLMs, while the generated replies were evaluated using CodingBat's unit tests. In addition, the general availability of textual explanations and program code was analyzed. The results show high scores of 94.4 to 95.8% correct responses and reliable availability of textual explanations and program code, which opens new ways to incorporate LLMs into programming education and assessment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="APACE-AlphaFold2-and-advanced-computing-as-a-service-for-accelerated-discovery-in-biophysics"><a href="#APACE-AlphaFold2-and-advanced-computing-as-a-service-for-accelerated-discovery-in-biophysics" class="headerlink" title="APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics"></a>APACE: AlphaFold2 and advanced computing as a service for accelerated discovery in biophysics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07954">http://arxiv.org/abs/2308.07954</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hyunp2/alphafold">https://github.com/hyunp2/alphafold</a></li>
<li>paper_authors: Hyun Park, Parth Patel, Roland Haas, E. A. Huerta</li>
<li>for:  Protein 3D structure prediction from amino acid sequence.</li>
<li>methods:  AlphaFold2 and advanced computing as a service.</li>
<li>results:  Up to two orders of magnitude faster than off-the-shelf AlphaFold2 implementations, reducing time-to-solution from weeks to minutes.<details>
<summary>Abstract</summary>
The prediction of protein 3D structure from amino acid sequence is a computational grand challenge in biophysics, and plays a key role in robust protein structure prediction algorithms, from drug discovery to genome interpretation. The advent of AI models, such as AlphaFold, is revolutionizing applications that depend on robust protein structure prediction algorithms. To maximize the impact, and ease the usability, of these novel AI tools we introduce APACE, AlphaFold2 and advanced computing as a service, a novel computational framework that effectively handles this AI model and its TB-size database to conduct accelerated protein structure prediction analyses in modern supercomputing environments. We deployed APACE in the Delta supercomputer, and quantified its performance for accurate protein structure predictions using four exemplar proteins: 6AWO, 6OAN, 7MEZ, and 6D6U. Using up to 200 ensembles, distributed across 50 nodes in Delta, equivalent to 200 A100 NVIDIA GPUs, we found that APACE is up to two orders of magnitude faster than off-the-shelf AlphaFold2 implementations, reducing time-to-solution from weeks to minutes. This computational approach may be readily linked with robotics laboratories to automate and accelerate scientific discovery.
</details>
<details>
<summary>摘要</summary>
“蛋白结构预测从氨基酸序列是生物物理 Computational Grand Challenge，它扮演着关键角色在稳定蛋白结构预测算法中，从药物发现到基因解读。人工智能模型，如AlphaFold，的出现正在改变这些应用程序中的应用，以增加其影响力和使用之 ease。为了最大化这些新的人工智能工具的影响和使用易用性，我们介绍了APACE、AlphaFold2和高性能计算作为服务，一个新的计算框架，可以有效地处理这些人工智能模型和其TB-size数据库，在现代超级计算环境中进行加速蛋白结构预测分析。我们在Delta超级计算机上部署了APACE，并评估其表现，使用四个例子蛋白：6AWO、6OAN、7MEZ和6D6U。使用 Up to 200个组，分布在Delta上的50个节点中，相当于200个A100 NVIDIA GPUs，我们发现APACE与传统的AlphaFold2实现方法相比，可以提高到二个次的速度，从 weeks 缩短到 minutes。这个计算方法可能可以与Robotics laboratory相连，以实现和加速科学发现。”
</details></li>
</ul>
<hr>
<h2 id="RAVEN-In-Context-Learning-with-Retrieval-Augmented-Encoder-Decoder-Language-Models"><a href="#RAVEN-In-Context-Learning-with-Retrieval-Augmented-Encoder-Decoder-Language-Models" class="headerlink" title="RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models"></a>RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07922">http://arxiv.org/abs/2308.07922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Huang, Wei Ping, Peng Xu, Mohammad Shoeybi, Kevin Chen-Chuan Chang, Bryan Catanzaro</li>
<li>for: 本研究探讨了基于检索增强encoder-decoder语言模型的上下文学习能力。</li>
<li>methods: 我们首先对当前领先的ATLAS模型进行了全面的分析，并发现其在上下文学习中存在一些缺陷，主要是响应训练和测试之间的匹配性和上下文长度的限制。为了解决这些问题，我们提出了RAVEN模型，该模型结合了检索增强的隐藏语言模型和预FIX语言模型。我们还提出了Fusion-in-Context Learning，以提高几个例子的性能，让模型可以更好地利用上下文中的更多示例，不需要额外的训练或模型修改。</li>
<li>results: 通过广泛的实验，我们证明了RAVEN模型在certain scenarios中具有显著的优势，比如ATLAS模型和一些最先进的语言模型。尽管RAVEN模型有许多 fewer parameters，但它在一些场景中可以达到与最先进的语言模型相当的性能。我们的研究证明了检索增强encoder-decoder语言模型在上下文学习中的潜力，并鼓励进一步的研究在这个方向上。<details>
<summary>Abstract</summary>
In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of the state-of-the-art ATLAS model and identify its limitations in in-context learning, primarily due to a mismatch between pretraining and testing, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training or model modifications. Through extensive experiments, we demonstrate that RAVEN significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder language models for in-context learning and encourages further research in this direction.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了隐藏语言模型在受限上下文中学习的能力。我们首先进行了现有ATLAS模型的全面分析，并发现其在受限上下文中学习时存在一些限制，主要是预训练和测试的不符合，以及上下文长度的限制。为了解决这些问题，我们提出了RAVEN模型，它结合了检索支持的隐藏语言模型和前缀语言模型。我们还引入了内容学习协调技术，以便让模型在少量示例下具有更好的表现。通过广泛的实验，我们证明了RAVEN模型在certain情况下与ATLAS模型相比有显著改善，并且在一些情况下与当前最先进的语言模型相当。我们的工作表明了隐藏语言模型在受限上下文中学习的潜力，并鼓励了进一步的研究在这个方向上。
</details></li>
</ul>
<hr>
<h2 id="Solving-Challenging-Math-Word-Problems-Using-GPT-4-Code-Interpreter-with-Code-based-Self-Verification"><a href="#Solving-Challenging-Math-Word-Problems-Using-GPT-4-Code-Interpreter-with-Code-based-Self-Verification" class="headerlink" title="Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification"></a>Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07921">http://arxiv.org/abs/2308.07921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, Hongsheng Li</li>
<li>for: 这个论文的目的是探讨大型语言模型（LLMs）如GPT-4和PaLM-2如何解决数学逻辑问题。特别是OpenAI最新版本的GPT-4，即GPT-4 Code Interpreter，在数学 datasets 上表现出了很好的 perfomance。</li>
<li>methods: 这篇论文使用了不同的 Code Usage Frequency 约束来提高 GPT-4 Code Interpreter 的逻辑能力。这些约束包括代码生成和执行、代码执行结果评估和纠正答案。</li>
<li>results: 这篇论文的结果表明，通过使用 Code Usage Frequency 约束和 CSV 提示方法，GPT-4 Code Interpreter 的数学逻辑能力得到了大幅提高。具体来说，在 MATH 数据集上，使用 GPT-4 Code Interpreter 和 CSV 得到了 Zero-shot 精度提高从 53.9% 到 84.3%。<details>
<summary>Abstract</summary>
Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has brought significant advancements in addressing math reasoning problems. In particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter, shows remarkable performance on challenging math datasets. In this paper, we explore the effect of code on enhancing LLMs' reasoning capability by introducing different constraints on the \textit{Code Usage Frequency} of GPT-4 Code Interpreter. We found that its success can be largely attributed to its powerful skills in generating and executing code, evaluating the output of code execution, and rectifying its solution when receiving unreasonable outputs. Based on this insight, we propose a novel and effective prompting method, explicit \uline{c}ode-based \uline{s}elf-\uline{v}erification~(CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use code to self-verify its answers. In instances where the verification state registers as ``False'', the model shall automatically amend its solution, analogous to our approach of rectifying errors during a mathematics examination. Furthermore, we recognize that the states of the verification result indicate the confidence of a solution, which can improve the effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we achieve an impressive zero-shot accuracy on MATH dataset \textbf{(53.9\% $\to$ 84.3\%)}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Relightable-and-Animatable-Neural-Avatar-from-Sparse-View-Video"><a href="#Relightable-and-Animatable-Neural-Avatar-from-Sparse-View-Video" class="headerlink" title="Relightable and Animatable Neural Avatar from Sparse-View Video"></a>Relightable and Animatable Neural Avatar from Sparse-View Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07903">http://arxiv.org/abs/2308.07903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Xu, Sida Peng, Chen Geng, Linzhan Mou, Zihan Yan, Jiaming Sun, Hujun Bao, Xiaowei Zhou</li>
<li>for: 创建可重新照明和动画的神经人物模型从缺乏视角（或半影）视频中的动态人体。</li>
<li>methods: 提出了一种层次距离查询（HDQ）算法，用于估计人物模型下的世界空间距离，并利用球跟踪来效率地计算表面交点和光线可见性。</li>
<li>results: 实现了从缺乏视角（或半影）输入中生成高质量的可重新照明和动画的神经人物模型，并且与状态艺术法比较。<details>
<summary>Abstract</summary>
This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse distances based on a parametric human model and compute fine distances by exploiting the local deformation invariance of SDF. Based on the HDQ algorithm, we leverage sphere tracing to efficiently estimate the surface intersection and light visibility. This allows us to develop the first system to recover animatable and relightable neural avatars from sparse view (or monocular) inputs. Experiments demonstrate that our approach is able to produce superior results compared to state-of-the-art methods. Our code will be released for reproducibility.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文面临的挑战是从缺视图（或缺视）视频中的动态人体创建可重新照明和可动画化神经人体模型。相比 studio 环境，这种设定更加实用和可达，但是它对于计算机视觉来说是非常具有挑战性的难题。先前的神经人体重建方法可以从缺视图中重建可动画化人体模型，但是无法恢复物理参数以进行照明。而使用可导 diferenciable inverse rendering 方法可以成功地在 static 对象上进行材质恢复，但是对于动态人体来说，计算像素表面交叉和光线可见性的计算是 computationally 昂贵的。为解决这个挑战，我们提出了一种层次距离查询（HDQ）算法，用于估算人体在任意姿势下的世界空间距离。具体来说，我们使用 parametric human model 来估算坐标距离，并使用 SDF 的本地弯曲不变性来计算细致距离。基于 HDQ 算法，我们可以通过圆柱追踪来高效地计算表面交叉和光线可见性。这样，我们可以开发出可以从缺视图（或缺视）输入中恢复可动画化和可重新照明的神经人体模型的首个系统。实验表明，我们的方法可以与现有方法相比产生更好的结果。我们的代码将会被发布，以便重现。
</details></li>
</ul>
<hr>
<h2 id="Through-the-Lens-of-Core-Competency-Survey-on-Evaluation-of-Large-Language-Models"><a href="#Through-the-Lens-of-Core-Competency-Survey-on-Evaluation-of-Large-Language-Models" class="headerlink" title="Through the Lens of Core Competency: Survey on Evaluation of Large Language Models"></a>Through the Lens of Core Competency: Survey on Evaluation of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07902">http://arxiv.org/abs/2308.07902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyu Zhuang, Qiguang Chen, Longxuan Ma, Mingda Li, Yi Han, Yushan Qian, Haopeng Bai, Zixian Feng, Weinan Zhang, Ting Liu<br>for: 本研究旨在更好地评估大语言模型（LLM）的性能，以帮助指导研究领域的发展。methods: 本研究使用多种评估任务和指标来评估 LLM 的四大能力：理解、知识、可靠性和安全性。results: 研究发现，现有的评估任务和指标不具备完善性，因此提出了多种新的评估方法和指标，以更好地评估 LLM 的性能。<details>
<summary>Abstract</summary>
From pre-trained language model (PLM) to large language model (LLM), the field of natural language processing (NLP) has witnessed steep performance gains and wide practical uses. The evaluation of a research field guides its direction of improvement. However, LLMs are extremely hard to thoroughly evaluate for two reasons. First of all, traditional NLP tasks become inadequate due to the excellent performance of LLM. Secondly, existing evaluation tasks are difficult to keep up with the wide range of applications in real-world scenarios. To tackle these problems, existing works proposed various benchmarks to better evaluate LLMs. To clarify the numerous evaluation tasks in both academia and industry, we investigate multiple papers concerning LLM evaluations. We summarize 4 core competencies of LLM, including reasoning, knowledge, reliability, and safety. For every competency, we introduce its definition, corresponding benchmarks, and metrics. Under this competency architecture, similar tasks are combined to reflect corresponding ability, while new tasks can also be easily added into the system. Finally, we give our suggestions on the future direction of LLM's evaluation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Traditional NLP tasks become inadequate due to the excellent performance of LLM.2. Existing evaluation tasks are difficult to keep up with the wide range of applications in real-world scenarios.To address these issues, previous works have proposed various benchmarks to better evaluate LLMs. To clarify the numerous evaluation tasks in both academia and industry, we investigate multiple papers concerning LLM evaluations. We summarize 4 core competencies of LLM, including:1. Reasoning: the ability to make logical and informed decisions based on the input.2. Knowledge: the ability to understand and apply knowledge to the input.3. Reliability: the ability to produce consistent and accurate output.4. Safety: the ability to avoid producing harmful or inappropriate output.For each competency, we introduce its definition, corresponding benchmarks, and metrics. Under this competency architecture, similar tasks are combined to reflect corresponding ability, while new tasks can also be easily added into the system. Finally, we provide our suggestions on the future direction of LLM’s evaluation.Translation note:* “pre-trained language model” (PLM) is translated as “预训练语言模型” (PLM)* “large language model” (LLM) is translated as “大型语言模型” (LLM)* “natural language processing” (NLP) is translated as “自然语言处理” (NLP)* “core competencies” is translated as “核心能力” (core competencies)* “reasoning” is translated as “理性” (reasoning)* “knowledge” is translated as “知识” (knowledge)* “reliability” is translated as “可靠性” (reliability)* “safety” is translated as “安全性” (safety)</details></li>
</ol>
<hr>
<h2 id="Probabilistic-Phase-Labeling-and-Lattice-Refinement-for-Autonomous-Material-Research"><a href="#Probabilistic-Phase-Labeling-and-Lattice-Refinement-for-Autonomous-Material-Research" class="headerlink" title="Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research"></a>Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07897">http://arxiv.org/abs/2308.07897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingchiangchang/crystaltree.jl">https://github.com/mingchiangchang/crystaltree.jl</a></li>
<li>paper_authors: Ming-Chiang Chang, Sebastian Ament, Maximilian Amsler, Duncan R. Sutherland, Lan Zhou, John M. Gregoire, Carla P. Gomes, R. Bruce van Dover, Michael O. Thompson</li>
<li>for: 本研究的目的是开发一种高效的晶体结构测定技术，以满足自动化科学发现过程中的高通过率实验需求。</li>
<li>methods: 本研究使用了Symmetry-constrained pseudo-refinement优化、best-first搜索和 Bayesian模型比较来估算晶体结构的可能性，无需phase空间信息或训练。</li>
<li>results: 实验和synthetic数据表明，CrystalShift可以提供可靠的晶体结构估算，超过现有方法的性能，并可以轻松地 интеグрите到高通过率的实验室工作流程中。此外，CrystalShift还提供了材料结构参数的量化见解，以便专家评估和AI模型对phas espacio进行模拟，从而加速材料的鉴定和发现。<details>
<summary>Abstract</summary>
X-ray diffraction (XRD) is an essential technique to determine a material's crystal structure in high-throughput experimentation, and has recently been incorporated in artificially intelligent agents in autonomous scientific discovery processes. However, rapid, automated and reliable analysis method of XRD data matching the incoming data rate remains a major challenge. To address these issues, we present CrystalShift, an efficient algorithm for probabilistic XRD phase labeling that employs symmetry-constrained pseudo-refinement optimization, best-first tree search, and Bayesian model comparison to estimate probabilities for phase combinations without requiring phase space information or training. We demonstrate that CrystalShift provides robust probability estimates, outperforming existing methods on synthetic and experimental datasets, and can be readily integrated into high-throughput experimental workflows. In addition to efficient phase-mapping, CrystalShift offers quantitative insights into materials' structural parameters, which facilitate both expert evaluation and AI-based modeling of the phase space, ultimately accelerating materials identification and discovery.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="EduSAT-A-Pedagogical-Tool-for-Theory-and-Applications-of-Boolean-Satisfiability"><a href="#EduSAT-A-Pedagogical-Tool-for-Theory-and-Applications-of-Boolean-Satisfiability" class="headerlink" title="EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability"></a>EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07890">http://arxiv.org/abs/2308.07890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaoy37/sat_solver">https://github.com/zhaoy37/sat_solver</a></li>
<li>paper_authors: Yiqi Zhao, Ziyan An, Meiyi Ma, Taylor Johnson</li>
<li>for: 支持学习和理解自动验证中的整数满足问题（SAT）和模ulo理论（SMT）解决方法</li>
<li>methods: 实现了逻辑推理算法（DPLL）和简化后二进制决策图（ROBDD）等SAT解决方法，以及五个NP完备问题的解决方法</li>
<li>results: 对EduSAT的评估显示其高度准确，在所有实现的SAT和SMT解决方法中都达到100%的正确率<details>
<summary>Abstract</summary>
Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) are widely used in automated verification, but there is a lack of interactive tools designed for educational purposes in this field. To address this gap, we present EduSAT, a pedagogical tool specifically developed to support learning and understanding of SAT and SMT solving. EduSAT offers implementations of key algorithms such as the Davis-Putnam-Logemann-Loveland (DPLL) algorithm and the Reduced Order Binary Decision Diagram (ROBDD) for SAT solving. Additionally, EduSAT provides solver abstractions for five NP-complete problems beyond SAT and SMT. Users can benefit from EduSAT by experimenting, analyzing, and validating their understanding of SAT and SMT solving techniques. Our tool is accompanied by comprehensive documentation and tutorials, extensive testing, and practical features such as a natural language interface and SAT and SMT formula generators, which also serve as a valuable opportunity for learners to deepen their understanding. Our evaluation of EduSAT demonstrates its high accuracy, achieving 100% correctness across all the implemented SAT and SMT solvers. We release EduSAT as a python package in .whl file, and the source can be identified at https://github.com/zhaoy37/SAT_Solver.
</details>
<details>
<summary>摘要</summary>
布尔满足性（SAT）和满足性模ulo理论（SMT）广泛应用于自动验证，但教育用途上缺乏交互式工具。为了填补这一空白，我们提出了EduSAT，一种教育工具，专门用于支持学习和理解SAT和SMT解决方法。EduSAT实现了关键算法，如戴维斯-普特南-洛曼-罗宾逊（DPLL）算法和减少顺序二进制决策图（ROBDD） для SAT解决。此外，EduSAT还提供了五个NP完备问题的解决器抽象。用户可以通过EduSAT进行实验、分析和验证他们对SAT和SMT解决方法的理解。我们的工具附有完整的文档和教程，广泛的测试和实用功能，如自然语言界面和SAT和SMT公式生成器，这也为学习者提供了深入了解的机会。我们的评估表明，EduSAT具有100%的正确率，在所有实现的SAT和SMT解决器中。我们在Python包中发布了EduSAT，可以在.whl文件中找到，源代码可以在https://github.com/zhaoy37/SAT_Solver中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Study-on-Knowledge-Graph-Embedding-over-Relational-Patterns-Based-on-Rule-Learning"><a href="#A-Comprehensive-Study-on-Knowledge-Graph-Embedding-over-Relational-Patterns-Based-on-Rule-Learning" class="headerlink" title="A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning"></a>A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07889">http://arxiv.org/abs/2308.07889</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinlong22/Analysis-relational-patterns-and-SPA">https://github.com/jinlong22/Analysis-relational-patterns-and-SPA</a></li>
<li>paper_authors: Long Jin, Zhen Yao, Mingyang Chen, Huajun Chen, Wen Zhang</li>
<li>for: 本研究旨在解决知识图 completions 任务中 KGE 模型的表现不佳问题，探讨 KGE 模型在不同关系模式下的表现。</li>
<li>methods: 本研究使用 7 种 KGE 模型，对 4 种常见关系模式进行评估，并在理论、实体频率和分割方面进行分析，得到了一些Counterintuitive结论。</li>
<li>results: 研究发现，KGE 模型在特定关系模式下的表现不一定和预期的相关，而且存在一些关系模式下 KGE 模型表现差。为解决这个问题，研究提出了一种无需训练的方法 Score-based Patterns Adaptation (SPA)，可以增强 KGE 模型在多种关系模式下的表现。<details>
<summary>Abstract</summary>
Knowledge Graph Embedding (KGE) has proven to be an effective approach to solving the Knowledge Graph Completion (KGC) task. Relational patterns which refer to relations with specific semantics exhibiting graph patterns are an important factor in the performance of KGE models. Though KGE models' capabilities are analyzed over different relational patterns in theory and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency, and part-to-whole three aspects and get some counterintuitive conclusions. Finally, we introduce a training-free method Score-based Patterns Adaptation (SPA) to enhance KGE models' performance over various relational patterns. This approach is simple yet effective and can be applied to KGE models without additional training. Our experimental results demonstrate that our method generally enhances performance over specific relational patterns. Our source code is available from GitHub at https://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.
</details>
<details>
<summary>摘要</summary>
知识图 embedding（KGE）已经证明是解决知识图完成（KGC）任务的有效方法。关系模式，即具有特定 semantics 的图 Patterns，是 KGE 模型表现的重要因素。 Although KGE models' capabilities have been analyzed over different relational patterns in theory, and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent, so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, and then conduct an analysis in three aspects: theory, entity frequency, and part-to-whole. We also obtain some counterintuitive conclusions. Finally, we introduce a training-free method Score-based Patterns Adaptation (SPA) to enhance KGE models' performance over various relational patterns. This approach is simple yet effective and can be applied to KGE models without additional training. Our experimental results demonstrate that our method generally enhances performance over specific relational patterns. Our source code is available from GitHub at <https://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns>.
</details></li>
</ul>
<hr>
<h2 id="Towards-Temporal-Edge-Regression-A-Case-Study-on-Agriculture-Trade-Between-Nations"><a href="#Towards-Temporal-Edge-Regression-A-Case-Study-on-Agriculture-Trade-Between-Nations" class="headerlink" title="Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations"></a>Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07883">http://arxiv.org/abs/2308.07883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scylj1/gnn_edge_regression">https://github.com/scylj1/gnn_edge_regression</a></li>
<li>paper_authors: Lekang Jiang, Caiqi Zhang, Farimah Poursafaei, Shenyang Huang</li>
<li>for: 预测国际贸易数据中的边值（trade value），即预测两个国家之间的贸易金额。</li>
<li>methods: 使用图 neural network（GNN）模型，包括三种基线模型和三种动态GNN模型，在静态和动态图上进行预测。</li>
<li>results: 基线模型在不同设定下表现出色，尤其是在负边的存在情况下表现更佳。TGN模型在三种动态GNN模型中表现最佳，并且发现训练样本中负边的比例对测试性能产生了显著的影响。Here’s the full Chinese text:随着图 neural network（GNN）在动态图上的应用，它们在node classification、链接预测和图回归等任务中表现出色。然而，对于时间顺序edge regression任务，尚有很少的研究。本文通过预测国际贸易数据中的边值（trade value），探讨GNN在静态和动态图上的应用。我们提出三种简单强的基线模型，并对一种静态和三种动态GNN模型进行了广泛的实验评估。我们的实验结果表明，基线模型在不同设定下表现出色，尤其是在负边的存在情况下表现更佳。此外，我们发现TGN模型在三种动态GNN模型中表现最佳，并且训练样本中负边的比例对测试性能产生了显著的影响。相关代码可以在GitHub上找到：<a target="_blank" rel="noopener" href="https://github.com/scylj1/GNN_Edge_Regression%E3%80%82">https://github.com/scylj1/GNN_Edge_Regression。</a><details>
<summary>Abstract</summary>
Recently, Graph Neural Networks (GNNs) have shown promising performance in tasks on dynamic graphs such as node classification, link prediction and graph regression. However, few work has studied the temporal edge regression task which has important real-world applications. In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations. We introduce three simple yet strong baselines and comprehensively evaluate one static and three dynamic GNN models using the UN Trade dataset. Our experimental results reveal that the baselines exhibit remarkably strong performance across various settings, highlighting the inadequacy of existing GNNs. We also find that TGN outperforms other GNN models, suggesting TGN is a more appropriate choice for edge regression tasks. Moreover, we note that the proportion of negative edges in the training samples significantly affects the test performance. The companion source code can be found at: https://github.com/scylj1/GNN_Edge_Regression.
</details>
<details>
<summary>摘要</summary>
最近，图 нейрон网络（GNN）在动态图上的任务中表现出色，包括节点分类、链接预测和图表 regression。然而，有少量的研究集中注意力于时间扩展edge regression任务，这种任务在实际世界中具有重要意义。在这篇论文中，我们探讨了GNN在静态和动态设置下进行边 regression任务的应用， focusing on 国际贸易食品和农业贸易值的预测。我们提出了三种简单强大的基elines，并对静态和三种动态GNN模型进行了广泛的实验评估，使用UN Trade数据集。我们的实验结果显示baselines在不同设置下具有极强表现，这 highlights the inadequacy of existing GNNs。此外，我们发现TGN在其他GNN模型之上表现出优异， suggesting TGN是更适合边 regression任务的选择。此外，我们注意到在训练样本中负边的比例对测试性能产生了显著的影响。相关的源代码可以在GitHub上找到：https://github.com/scylj1/GNN_Edge_Regression。
</details></li>
</ul>
<hr>
<h2 id="The-10-Million-ANA-Avatar-XPRIZE-Competition-Advanced-Immersive-Telepresence-Systems"><a href="#The-10-Million-ANA-Avatar-XPRIZE-Competition-Advanced-Immersive-Telepresence-Systems" class="headerlink" title="The $10 Million ANA Avatar XPRIZE Competition Advanced Immersive Telepresence Systems"></a>The $10 Million ANA Avatar XPRIZE Competition Advanced Immersive Telepresence Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07878">http://arxiv.org/abs/2308.07878</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Behnke, Julie A. Adams, David Locke</li>
<li>for: 这篇论文是关于&lt;&lt;$10M ANA Avatar XPRIZE&gt;&gt;的多年竞赛，参赛者需要开发一种可以在实时传输人类存在的功能。</li>
<li>methods: 本文描述了竞赛的不同阶段和任务，以及评价标准。</li>
<li>results: 根据文章报道，竞赛中的参赛队伍通过了不同的任务和评价标准，并获得了奖励。<details>
<summary>Abstract</summary>
The $10M ANA Avatar XPRIZE aimed to create avatar systems that can transport human presence to remote locations in real time. The participants of this multi-year competition developed robotic systems that allow operators to see, hear, and interact with a remote environment in a way that feels as if they are truly there. On the other hand, people in the remote environment were given the impression that the operator was present inside the avatar robot. At the competition finals, held in November 2022 in Long Beach, CA, USA, the avatar systems were evaluated on their support for remotely interacting with humans, exploring new environments, and employing specialized skills. This article describes the competition stages with tasks and evaluation procedures, reports the results, presents the winning teams' approaches, and discusses lessons learned.
</details>
<details>
<summary>摘要</summary>
美国ANA Avatar XPRIZE挑战赛旨在创造能够在实时传输人类存在的功能，使得操作者可以在远程地点上见、听和互动。参赛队伍在多年的竞赛中开发出了 робо图形系统，让操作者能够在远程环境中感受到真实存在的感觉。同时，远程环境中的人们也被给予操作员在机器人中存在的印象。2022年11月在美国加利福尼亚州长滩市举行的比赛决赛中，参赛队伍的机器人系统被评估为在与人类互动、探索新环境和使用专业技能方面的支持。本文介绍了竞赛阶段的任务和评估过程，报道了结果，展示了赢得奖队的方法，并讨论了学习的教训。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Political-Zero-Shot-Relation-Classification-via-Codebook-Knowledge-NLI-and-ChatGPT"><a href="#Synthesizing-Political-Zero-Shot-Relation-Classification-via-Codebook-Knowledge-NLI-and-ChatGPT" class="headerlink" title="Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT"></a>Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07876">http://arxiv.org/abs/2308.07876</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snowood1/zero-shot-plover">https://github.com/snowood1/zero-shot-plover</a></li>
<li>paper_authors: Yibo Hu, Erick Skorupa Parolin, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito J. D’Orazio</li>
<li>for: 这篇论文的目的是提出零shot方法用于政治事件 ontology 关系分类，利用已有的注释代码库知识，以提高分类精度和效率。</li>
<li>methods: 这篇论文使用了一种名为 ZSP 的自然语言推理（NLI）基于的方法，它采用了树查询框架，将任务分解为上下文、Modalidad和类别推理三个级别。</li>
<li>results: 经过大规模的实验，ZSP 实现了在Rootcode 精细分类中的40%的提升，与超参 Bert 模型相当，表明 ZSP 可以作为事件记录验证和 ontology 发展中的有价值工具。<details>
<summary>Abstract</summary>
Recent supervised models for event coding vastly outperform pattern-matching methods. However, their reliance solely on new annotations disregards the vast knowledge within expert databases, hindering their applicability to fine-grained classification. To address these limitations, we explore zero-shot approaches for political event ontology relation classification, by leveraging knowledge from established annotation codebooks. Our study encompasses both ChatGPT and a novel natural language inference (NLI) based approach named ZSP. ZSP adopts a tree-query framework that deconstructs the task into context, modality, and class disambiguation levels. This framework improves interpretability, efficiency, and adaptability to schema changes. By conducting extensive experiments on our newly curated datasets, we pinpoint the instability issues within ChatGPT and highlight the superior performance of ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained Rootcode classification. ZSP demonstrates competitive performance compared to supervised BERT models, positioning it as a valuable tool for event record validation and ontology development. Our work underscores the potential of leveraging transfer learning and existing expertise to enhance the efficiency and scalability of research in the field.
</details>
<details>
<summary>摘要</summary>
现代监督学习模型在事件编码方面表现出色，但它们完全依赖新的注释，忽视了专家数据库中的庞大知识，这限制了它们的细致分类应用。为解决这些局限性，我们研究零shot方法，利用已有的注释代码ebook来 классифика事件ontology关系。我们的研究包括ChatGPT和一种新的自然语言推理（NLI）基于的approach named ZSP。ZSP采用树查询框架，将任务分解为上下文、Modal和分类层。这种框架提高了可读性、效率和 schema变化的适应性。通过对我们新收集的数据进行广泛的实验，我们揭示了ChatGPT中的不稳定性问题，并高举ZSP的出色表现。ZSP在细致的Rootcode分类中实现了40%的提升。ZSP与supervised BERT模型的表现相当，这positioned它为事件记录验证和ontology发展的有价值工具。我们的工作强调了可以通过转移学习和现有专业知识来提高研究领域的效率和可扩展性。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Embeddings-unicode-x2014-Learning-Stable-and-Homogeneous-Abstractions-from-Heterogeneous-Affective-Datasets"><a href="#Emotion-Embeddings-unicode-x2014-Learning-Stable-and-Homogeneous-Abstractions-from-Heterogeneous-Affective-Datasets" class="headerlink" title="Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets"></a>Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07871">http://arxiv.org/abs/2308.07871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Buechel, Udo Hahn</li>
<li>for: 这篇论文目的是提出一种统一的计算模型，以便将不同表达形式和标签类型的情感分析数据集合在一起，实现数据的可重用、可解释和灵活应用。</li>
<li>methods: 该论文使用了一种训练过程，以学习一个共享的幽默表示（emotion embeddings），不受不同的自然语言、交流Modalities、媒体或标签类型的限制。</li>
<li>results: 实验表明，该方法可以在各种不同的情感分析数据集上实现预测质量的可靠性和可重用性，而不需要特定的语言、Modalities或标签类型。<details>
<summary>Abstract</summary>
Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label formats, and even disparate model architectures. Experiments on a wide range of heterogeneous affective datasets indicate that this approach yields the desired interoperability for the sake of reusability, interpretability and flexibility, without penalizing prediction quality. Code and data are archived under https://doi.org/10.5281/zenodo.7405327 .
</details>
<details>
<summary>摘要</summary>
人类情感表达在许多交通Modalities和媒体格式中表现出来，因此计算研究也是多样化的，包括自然语言处理、音频信号分析、计算视觉等。在过去的研究中，用于描述情感的多种格式（负号级别、基本情绪类别、维度方法、评估理论等）导致了计算研究的数据和预测模型的总体增加，以及软件工具的杂化。由于表达和表达的多样性，我们需要统一过去的工作，以实现交互性、可读性和灵活性。本文提出了一种统一的计算模型，通过学习共享的感情嵌入，独立于不同的自然语言、交通Modalities、媒体或表达格式，甚至不同的模型架构。实验表明，这种方法可以实现数据和标签类型之间的兼容性，不пенalize预测质量。代码和数据存储在https://doi.org/10.5281/zenodo.7405327。
</details></li>
</ul>
<hr>
<h2 id="Brain-Inspired-Computational-Intelligence-via-Predictive-Coding"><a href="#Brain-Inspired-Computational-Intelligence-via-Predictive-Coding" class="headerlink" title="Brain-Inspired Computational Intelligence via Predictive Coding"></a>Brain-Inspired Computational Intelligence via Predictive Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07870">http://arxiv.org/abs/2308.07870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tommaso Salvatori, Ankur Mali, Christopher L. Buckley, Thomas Lukasiewicz, Rajesh P. N. Rao, Karl Friston, Alexander Ororbia</li>
<li>For: The paper aims to explore the potential of using predictive coding (PC) as a guiding principle for the development of machine learning algorithms, in order to address some of the limitations of current deep neural network approaches.* Methods: The paper surveys the literature on PC and its applications in machine intelligence tasks, highlighting its exciting properties and potential benefits for the field of machine learning.* Results: The paper discusses the potential of PC to model information processing in different brain areas, be used in cognitive control and robotics, and provide a powerful inversion scheme for continuous-state generative models.<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a powerful inversion scheme for a specific class of continuous-state generative models. With the hope of foregrounding research in this direction, we survey the literature that has contributed to this perspective, highlighting the many ways that PC might play a role in the future of machine learning and computational intelligence at large.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在这个世纪 rapidly becoming one of the key technologies.  thus far majority of results in AI have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the widespread adoption of this approach has highlighted some important limitations, such as significant computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a powerful inversion scheme for a specific class of continuous-state generative models. With the hope of foregrounding research in this direction, we survey the literature that has contributed to this perspective, highlighting the many ways that PC might play a role in the future of machine learning and computational intelligence at large.
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Symmetries-in-Pick-and-Place"><a href="#Leveraging-Symmetries-in-Pick-and-Place" class="headerlink" title="Leveraging Symmetries in Pick and Place"></a>Leveraging Symmetries in Pick and Place</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07948">http://arxiv.org/abs/2308.07948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haojie Huang, Dian Wang, Arsh Tangri, Robin Walters, Robert Platt</li>
<li>for: 本文旨在研究平面机器人抓取和放置任务中的对称性，并提出一种在Transporter Net框架中包含对称性的方法，以便快速适应不同的抓取和放置姿势。</li>
<li>methods: 本文使用了数学分析方法研究平面机器人抓取和放置任务中的对称性，并提出了一种在Transporter Net框架中包含对称性的方法，称为Equivariant Transporter Net。</li>
<li>results: 实验表明，Equivariant Transporter Net比非对称版本更高效，可以使用很少的人类示例来快速适应不同的抓取和放置任务。<details>
<summary>Abstract</summary>
Robotic pick and place tasks are symmetric under translations and rotations of both the object to be picked and the desired place pose. For example, if the pick object is rotated or translated, then the optimal pick action should also rotate or translate. The same is true for the place pose; if the desired place pose changes, then the place action should also transform accordingly. A recently proposed pick and place framework known as Transporter Net captures some of these symmetries, but not all. This paper analytically studies the symmetries present in planar robotic pick and place and proposes a method of incorporating equivariant neural models into Transporter Net in a way that captures all symmetries. The new model, which we call Equivariant Transporter Net, is equivariant to both pick and place symmetries and can immediately generalize pick and place knowledge to different pick and place poses. We evaluate the new model empirically and show that it is much more sample efficient than the non-symmetric version, resulting in a system that can imitate demonstrated pick and place behavior using very few human demonstrations on a variety of imitation learning tasks.
</details>
<details>
<summary>摘要</summary>
机器人拾取置位任务具有对象拾取和置位pose的对称性。例如，如果拾取对象旋转或平移，那么最佳拾取动作也应该旋转或平移。同样，如果置位pose发生变化，那么置位动作也应该相应变化。一种已经提出的拾取置位框架被称为Transporter Net，但它不捕捉所有的对称性。这篇论文分析了平面机器人拾取置位中存在的对称性，并提议在Transporter Net中采用具有对称性的equivariant neural网络，以捕捉所有的对称性。新的模型被称为Equivariant Transporter Net，它对拾取和置位对称性具有对称性，可以立即将拾取知识应用到不同的拾取和置位pose。我们在实验中评估了新模型，并证明它在很少示例的情况下可以很好地复现人类示例行为，在多种模仿学习任务上表现出非常高效。
</details></li>
</ul>
<hr>
<h2 id="Impression-Aware-Recommender-Systems"><a href="#Impression-Aware-Recommender-Systems" class="headerlink" title="Impression-Aware Recommender Systems"></a>Impression-Aware Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07857">http://arxiv.org/abs/2308.07857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando B. Pérez Maurera, Maurizio Ferrari Dacrema, Pablo Castells, Paolo Cremonesi</li>
<li>for: 提高推荐系统质量的新数据源</li>
<li>methods: 使用印象数据（过去的推荐项）和传统交互数据进行用户偏好细化</li>
<li>results: 系统性文献回顾，涵盖推荐系统使用印象数据的三大研究方向：推荐算法、数据集和评估方法Here’s the full text in Simplified Chinese:for: 本文提出了一种基于新数据源的推荐系统，用于提高推荐系统的质量。methods: 本文使用印象数据（过去的推荐项）和传统交互数据进行用户偏好细化，以提高推荐系统的准确率和个性化程度。results: 本文进行了系统性文献回顾，涵盖推荐系统使用印象数据的三大研究方向：推荐算法、数据集和评估方法。<details>
<summary>Abstract</summary>
Novel data sources bring new opportunities to improve the quality of recommender systems. Impressions are a novel data source containing past recommendations (shown items) and traditional interactions. Researchers may use impressions to refine user preferences and overcome the current limitations in recommender systems research. The relevance and interest of impressions have increased over the years; hence, the need for a review of relevant work on this type of recommenders. We present a systematic literature review on recommender systems using impressions, focusing on three fundamental angles in research: recommenders, datasets, and evaluation methodologies. We provide three categorizations of papers describing recommenders using impressions, present each reviewed paper in detail, describe datasets with impressions, and analyze the existing evaluation methodologies. Lastly, we present open questions and future directions of interest, highlighting aspects missing in the literature that can be addressed in future works.
</details>
<details>
<summary>摘要</summary>
新的数据源带来了推荐系统质量的改进机遇。印象是一种新的数据源，包含过去的推荐（显示的项目）和传统的交互。研究人员可以使用印象来细化用户偏好，超越现有的推荐系统研究的限制。印象的重要性和兴趣在年来不断增加，因此需要对这类推荐系统的研究进行系统性的文献评审。本文提出了一种系统性的文献评审方法，将推荐系统使用印象分为三个基本方向：推荐算法、数据集和评价方法。每个评审的论文都会在详细的描述，数据集也会被介绍，以及现有的评价方法的分析。最后，我们将提出未解决的问题和未来的方向，强调文献中缺失的方面，未来的研究可以在这些方面进行深入的探索。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/16/cs.AI_2023_08_16/" data-id="clorjzl1t002hf188dselcvup" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/57/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/56/">56</a><a class="page-number" href="/page/57/">57</a><span class="page-number current">58</span><a class="page-number" href="/page/59/">59</a><a class="page-number" href="/page/60/">60</a><span class="space">&hellip;</span><a class="page-number" href="/page/89/">89</a><a class="extend next" rel="next" href="/page/59/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
