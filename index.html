
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.AS_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/eess.AS_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T14:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/eess.AS_2023_11_08/">eess.AS - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="1-step-Speech-Processing-and-Understanding-Using-CTC-Loss"><a href="#1-step-Speech-Processing-and-Understanding-Using-CTC-Loss" class="headerlink" title="1-step Speech Processing and Understanding Using CTC Loss"></a>1-step Speech Processing and Understanding Using CTC Loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04753">http://arxiv.org/abs/2311.04753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karan Singla, Shahab Jalavand, Yeon-Jun Kim, Antonio Moreno Daniel, Srinivas Bangalore, Andrej Ljolje, Ben Stern</li>
<li>for: 提高自然语言处理系统中的命名实体识别精度</li>
<li>methods: 使用 Connectionist Temporal Classification (CTC) 损失函数和增强的 vocabulary 来扩展端到端语音识别系统</li>
<li>results: 在 SLUE  bencmark 上提高命名实体识别精度、意图识别精度和语音识别精度，并与 SLURP 数据集的结果相当Here’s the Chinese text in the format you requested:</li>
<li>for: 提高自然语言处理系统中的命名实体识别精度</li>
<li>methods: 使用 Connectionist Temporal Classification (CTC) 损失函数和增强的 vocabulary 来扩展端到端语音识别系统</li>
<li>results: 在 SLUE  bencmark 上提高命名实体识别精度、意图识别精度和语音识别精度，并与 SLURP 数据集的结果相当<details>
<summary>Abstract</summary>
Recent studies have made some progress in refining end-to-end (E2E) speech recognition encoders by applying Connectionist Temporal Classification (CTC) loss to enhance named entity recognition within transcriptions. However, these methods have been constrained by their exclusive use of the ASCII character set, allowing only a limited array of semantic labels. Our proposed solution extends the E2E automatic speech recognition (ASR) system's vocabulary by adding a set of unused placeholder symbols, conceptually akin to the <pad> tokens used in sequence modeling. These placeholders are then assigned to represent semantic tags and are integrated into the transcription process as distinct tokens. We demonstrate notable improvements in entity tagging, intent discernment, and transcription accuracy on the SLUE benchmark and yields results that are on par with those for the SLURP dataset. Additionally, we provide a visual analysis of the system's proficiency in accurately pinpointing meaningful tokens over time, illustrating the enhancement in transcription quality through the utilization of supplementary semantic tags.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近的研究已经做出了一些进步，用Connectionist Temporal Classification（CTC）损失来提高命名实体识别 within 转录。然而，这些方法受限于它们仅使用 ASCII 字符集，只能表示有限数量的 semantic label。我们的提议的解决方案是将 E2E 自动语音识别（ASR）系统的词汇表扩展到添加一组未使用的占位符号，与序列模型中的 <pad> token 类似。这些占位符号然后被分配到表示 semantic tag 的 tokens，并在转录过程中作为特定的 tokens 集成。我们在 SLUE 数据集上示出了显著提高的实体标注、意图掌握和转录精度。此外，我们还提供了一种可见分析，用于 illustrate 系统在时间上准确地标注有意义的 tokens 的提高，描述了通过使用补充的 semantic tag 的权重，提高转录质量。
</details></li>
</ul>
<hr>
<h2 id="Selective-HuBERT-Self-Supervised-Pre-Training-for-Target-Speaker-in-Clean-and-Mixture-Speech"><a href="#Selective-HuBERT-Self-Supervised-Pre-Training-for-Target-Speaker-in-Clean-and-Mixture-Speech" class="headerlink" title="Selective HuBERT: Self-Supervised Pre-Training for Target Speaker in Clean and Mixture Speech"></a>Selective HuBERT: Self-Supervised Pre-Training for Target Speaker in Clean and Mixture Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04526">http://arxiv.org/abs/2311.04526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingru Lin, Meng Ge, Wupeng Wang, Haizhou Li, Mengling Feng</li>
<li>for: 这个研究旨在提出一种新的自愿授课架构，以提高自愿授课模型在不同下游语音处理任务中的表现。</li>
<li>methods: 这个方法利用选择性对话注意力的想法，将清洁或混合语音训练为模型，以提高模型对目标语音的抽象。</li>
<li>results: 实验结果显示，这个新的自愿授课方法可以在SUPERB评量标准和LibriMix数据集上达到佳效果，并且具有噪音抗性和通用性。此外，我们发现这个高品质表现可以与传统的监督学习方法混合使用，以达到具有很少标签数据的情况下的优秀表现。<details>
<summary>Abstract</summary>
Self-supervised pre-trained speech models were shown effective for various downstream speech processing tasks. Since they are mainly pre-trained to map input speech to pseudo-labels, the resulting representations are only effective for the type of pre-train data used, either clean or mixture speech. With the idea of selective auditory attention, we propose a novel pre-training solution called Selective-HuBERT, or SHuBERT, which learns the selective extraction of target speech representations from either clean or mixture speech. Specifically, SHuBERT is trained to predict pseudo labels of a target speaker, conditioned on an enrolled speech from the target speaker. By doing so, SHuBERT is expected to selectively attend to the target speaker in a complex acoustic environment, thus benefiting various downstream tasks. We further introduce a dual-path training strategy and use the cross-correlation constraint between the two branches to encourage the model to generate noise-invariant representation. Experiments on SUPERB benchmark and LibriMix dataset demonstrate the universality and noise-robustness of SHuBERT. Furthermore, we find that our high-quality representation can be easily integrated with conventional supervised learning methods to achieve significant performance, even under extremely low-resource labeled data.
</details>
<details>
<summary>摘要</summary>
自我监督预训神经网络在各种下游语音处理任务中显示效果。由于它们主要预训输入语音到假标签，因此得到的表示只有效果于预训数据类型，即干净或混合语音。我们提出了一种新的预训解决方案called Selective-HuBERT（SHuBERT），它学习选择目标语音表示的抽取。特别是，SHuBERT在目标说话人的声音中预测假标签，条件在目标说话人的录音中训练。这样，SHuBERT可以选择性地关注目标说话人，从而在复杂的声音环境中提高多个下游任务的性能。我们还提出了双路训练策略，并使用两个支路之间的差异来鼓励模型生成噪声不变的表示。在SUPERB标准库和LibriMix数据集上的实验表明，SHuBERT具有 universality 和噪声鲁棒性。此外，我们发现我们高质量的表示可以轻松地与传统的监督学习方法结合，即使是EXTREMELY LOW-RESOURCE labelled data。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/eess.AS_2023_11_08/" data-id="clorjzlei012xf188h1xtdpwp" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/cs.CV_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T13:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/cs.CV_2023_11_08/">cs.CV - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="GENOME-GenerativE-Neuro-symbOlic-visual-reasoning-by-growing-and-reusing-ModulEs"><a href="#GENOME-GenerativE-Neuro-symbOlic-visual-reasoning-by-growing-and-reusing-ModulEs" class="headerlink" title="GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs"></a>GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04901">http://arxiv.org/abs/2311.04901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenfang Chen, Rui Sun, Wenjun Liu, Yining Hong, Chuang Gan</li>
<li>for: 提高视觉理解能力，使用大语言模型（LLMs）推动传统的神经 символиック模型，以实现强大的视觉理解结果，同时保持模型的透明度和效率。</li>
<li>methods: 使用LLMs对每个任务进行分析，判断是否可以重用和扩展现有模块来解决该任务。如果不可以，则初始化一个新模块，并指定输入和输出。然后，通过查询LLMs来生成匹配要求的代码段，并对新模块进行几何训练。</li>
<li>results: 提出了一种生成神经符号学模型，可以在几何训练例程中学习和 reuse 现有模块，以实现新任务的视觉理解。模型在标准任务上表现竞争力强，并且可以将学习到的模块转移到新任务上，同时能够适应新的视觉理解任务。<details>
<summary>Abstract</summary>
Recent works have shown that Large Language Models (LLMs) could empower traditional neuro-symbolic models via programming capabilities to translate language into module descriptions, thus achieving strong visual reasoning results while maintaining the model's transparency and efficiency. However, these models usually exhaustively generate the entire code snippet given each new instance of a task, which is extremely ineffective. We propose generative neuro-symbolic visual reasoning by growing and reusing modules. Specifically, our model consists of three unique stages, module initialization, module generation, and module execution. First, given a vision-language task, we adopt LLMs to examine whether we could reuse and grow over established modules to handle this new task. If not, we initialize a new module needed by the task and specify the inputs and outputs of this new module. After that, the new module is created by querying LLMs to generate corresponding code snippets that match the requirements. In order to get a better sense of the new module's ability, we treat few-shot training examples as test cases to see if our new module could pass these cases. If yes, the new module is added to the module library for future reuse. Finally, we evaluate the performance of our model on the testing set by executing the parsed programs with the newly made visual modules to get the results. We find the proposed model possesses several advantages. First, it performs competitively on standard tasks like visual question answering and referring expression comprehension; Second, the modules learned from one task can be seamlessly transferred to new tasks; Last but not least, it is able to adapt to new visual reasoning tasks by observing a few training examples and reusing modules.
</details>
<details>
<summary>摘要</summary>
现有研究表明，大语言模型（LLM）可以使传统的神经符号模型通过编程功能来理解语言，从而实现强大的视觉逻辑结果，同时保持模型的透明度和效率。然而，这些模型通常会浪费大量时间来生成整个代码块给每个新任务，这是非常不高效。我们提议使用生成的神经符号视觉逻辑。具体来说，我们的模型包括三个独特的阶段：模块初始化、模块生成和模块执行。首先，给定一个视觉语言任务，我们采用LLM来检查是否可以重用和增长现有的模块来处理这个新任务。如果不可以，我们将新增一个需要的模块，并指定这个模块的输入和输出。然后，我们通过查询LLM来生成匹配要求的代码块，以创建这个新模块。为了更好地了解这个新模块的能力，我们将几个干净训练例作为测试用例，以判断这个新模块是否可以通过这些测试。如果可以，则将这个新模块添加到模块库中，以供未来的重用。最后，我们使用解析后的程序来评估模型的性能，并通过执行这些新生成的视觉模块来获得结果。我们发现我们提议的模型具有以下优点：一、在标准任务如视觉问答和表达理解方面表现竞争力强；二、学习到的模块可以很好地转移到新任务上；三、可以通过几个干净训练例来适应新的视觉逻辑任务。
</details></li>
</ul>
<hr>
<h2 id="Are-foundation-models-efficient-for-medical-image-segmentation"><a href="#Are-foundation-models-efficient-for-medical-image-segmentation" class="headerlink" title="Are foundation models efficient for medical image segmentation?"></a>Are foundation models efficient for medical image segmentation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04847">http://arxiv.org/abs/2311.04847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Danielle Ferreira, Rima Arnaout</li>
<li>for: 这个论文主要是为了评估Segment Anything模型（SAM）在医学影像Segmentation方面的性能和资源养成。</li>
<li>methods: 这个论文使用了SAM模型和一种模式特定、标签自由的自然学习（SSL）方法，对100次医学ultrasound图像进行25个测量。</li>
<li>results: SAM模型的性能相对较差，需要更多的标签和计算资源，而SSL方法则显示出了更高的效率。<details>
<summary>Abstract</summary>
Foundation models are experiencing a surge in popularity. The Segment Anything model (SAM) asserts an ability to segment a wide spectrum of objects but required supervised training at unprecedented scale. We compared SAM's performance (against clinical ground truth) and resources (labeling time, compute) to a modality-specific, label-free self-supervised learning (SSL) method on 25 measurements for 100 cardiac ultrasounds. SAM performed poorly and required significantly more labeling and computing resources, demonstrating worse efficiency than SSL.
</details>
<details>
<summary>摘要</summary>
基础模型目前正在受欢迎。Segment Anything模型（SAM）表明可以对广泛的对象进行分割，但需要前所未有的大规模指导式训练。我们比较了SAM的表现（与临床真实标注）和资源（标注时间、计算）与一种特定Modalitate、标签自由自学习（SSL）方法在25个测量上对100个心脏超声图像。SAM表现不佳，需要更多的标注和计算资源，示出了与SSL的更差效率。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Learning-for-Visual-Relationship-Detection-through-Masked-Bounding-Box-Reconstruction"><a href="#Self-Supervised-Learning-for-Visual-Relationship-Detection-through-Masked-Bounding-Box-Reconstruction" class="headerlink" title="Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction"></a>Self-Supervised Learning for Visual Relationship Detection through Masked Bounding Box Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04834">http://arxiv.org/abs/2311.04834</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplab-ai/selfsupervisedvrd">https://github.com/deeplab-ai/selfsupervisedvrd</a></li>
<li>paper_authors: Zacharias Anastasakis, Dimitrios Mallis, Markos Diomataris, George Alexandridis, Stefanos Kollias, Vassilis Pitsikalis</li>
<li>for: 这篇论文是为了提出一种自然语言生成模型，尤其是用于视觉关系检测任务（VRD）的自我超vised学习方法。</li>
<li>methods: 这篇论文提出了一种基于Masked Image Modeling（MIM）的变种，称为Masked Bounding Box Reconstruction（MBBR），其中一定比例的场景中的实体&#x2F;对象会被遮盖，然后通过未遮盖的对象进行重建。这种方法的核心思想是通过对象级别的遮盖模型，使网络学习场景中对象之间的交互的上下文感知，并且通过这种方法学习出高度预测视觉对象关系的表示。</li>
<li>results: 作者们在一些几个shot设定下进行了质量和量тив的评估，并证明了MBBR在VRD任务中比静态方法更高效，使用只需要几个标注样本就能够超越现有的VRD方法。<details>
<summary>Abstract</summary>
We present a novel self-supervised approach for representation learning, particularly for the task of Visual Relationship Detection (VRD). Motivated by the effectiveness of Masked Image Modeling (MIM), we propose Masked Bounding Box Reconstruction (MBBR), a variation of MIM where a percentage of the entities/objects within a scene are masked and subsequently reconstructed based on the unmasked objects. The core idea is that, through object-level masked modeling, the network learns context-aware representations that capture the interaction of objects within a scene and thus are highly predictive of visual object relationships. We extensively evaluate learned representations, both qualitatively and quantitatively, in a few-shot setting and demonstrate the efficacy of MBBR for learning robust visual representations, particularly tailored for VRD. The proposed method is able to surpass state-of-the-art VRD methods on the Predicate Detection (PredDet) evaluation setting, using only a few annotated samples. We make our code available at https://github.com/deeplab-ai/SelfSupervisedVRD.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的自助学习方法，尤其适用于视觉关系检测（VRD）任务。我们的方法受到Masked Image Modeling（MIM）的成功所 inspirited，我们提议Masked Bounding Box Reconstruction（MBBR），这是MIM中一种变种，其中场景中一部分对象被遮盖，然后通过不遮盖的对象进行重建。核心思想是通过对象级别的遮盖模型，网络学习场景中对象之间的交互，从而学习出高度预测性的视觉对象关系表示。我们广泛评估学习的表示，包括质量和量度的评估，在几个预测设定下，并证明MBBR可以在几个预测设定下超越当前VRD方法，只需使用几个注释样本。我们的代码可以在https://github.com/deeplab-ai/SelfSupervisedVRD中获取。
</details></li>
</ul>
<hr>
<h2 id="Anonymizing-medical-case-based-explanations-through-disentanglement"><a href="#Anonymizing-medical-case-based-explanations-through-disentanglement" class="headerlink" title="Anonymizing medical case-based explanations through disentanglement"></a>Anonymizing medical case-based explanations through disentanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04833">http://arxiv.org/abs/2311.04833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Helena Montenegro, Jaime S. Cardoso</li>
<li>for: 这个论文是为了解释深度学习模型在医疗上的决策过程。</li>
<li>methods: 论文提出了一种新的方法，用于分离图像中的人脸和医学特征，以便在医疗上分享图像。这种方法使用了一种替换特征向量的机制，以保持图像的医学特征，同时将人脸信息替换为Synthetic Privacy-Preserving Identity。</li>
<li>results: 实验表明，这种方法可以生成真实的、适用于医疗的隐私保护图像，同时保持原始医学内容。此外，实验还发现网络内置了生成对抗图像的能力。<details>
<summary>Abstract</summary>
Case-based explanations are an intuitive method to gain insight into the decision-making process of deep learning models in clinical contexts. However, medical images cannot be shared as explanations due to privacy concerns. To address this problem, we propose a novel method for disentangling identity and medical characteristics of images and apply it to anonymize medical images. The disentanglement mechanism replaces some feature vectors in an image while ensuring that the remaining features are preserved, obtaining independent feature vectors that encode the images' identity and medical characteristics. We also propose a model to manufacture synthetic privacy-preserving identities to replace the original image's identity and achieve anonymization. The models are applied to medical and biometric datasets, demonstrating their capacity to generate realistic-looking anonymized images that preserve their original medical content. Additionally, the experiments show the network's inherent capacity to generate counterfactual images through the replacement of medical features.
</details>
<details>
<summary>摘要</summary>
可以使用 случаي explanations 来了解深度学习模型在医疗场景中做出决策的过程。然而，医疗图像不能被分享作为解释，因为隐私问题。为解决这个问题，我们提议一种新的方法，即分离图像的身份和医疗特征。我们称之为“图像分离”。这种方法可以在图像中替换一些特征向量，以保证图像的其余特征被保留，从而获得独立的特征向量，这些特征向量编码着图像的身份和医疗特征。我们还提议一种模型，用于生成隐私保护的虚拟人工身份来替换原始图像的身份，以实现医疗图像的匿名化。这些模型在医疗和生物ometrics dataset上进行了应用，并在生成真实看起来的匿名化图像，同时保留图像的原始医疗内容。此外，实验还示出了网络的内置Counterfactual图像生成能力，通过替换医疗特征来生成对抗性图像。
</details></li>
</ul>
<hr>
<h2 id="SODAWideNet-–-Salient-Object-Detection-with-an-Attention-augmented-Wide-Encoder-Decoder-network-without-ImageNet-pre-training"><a href="#SODAWideNet-–-Salient-Object-Detection-with-an-Attention-augmented-Wide-Encoder-Decoder-network-without-ImageNet-pre-training" class="headerlink" title="SODAWideNet – Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training"></a>SODAWideNet – Salient Object Detection with an Attention augmented Wide Encoder Decoder network without ImageNet pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04828">http://arxiv.org/abs/2311.04828</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/VimsLab/SODAWideNet">https://github.com/VimsLab/SODAWideNet</a></li>
<li>paper_authors: Rohit Venkata Sai Dulam, Chandra Kambhamettu</li>
<li>for: 本研究旨在提出一种新的突出物检测模型（SOD），而不需要在ImageNet预训练上进行复杂的 retrained。</li>
<li>methods: 我们提出了一种自适应的干扰检测模型，包括MRFFAM模块和多 scales attention（MSA）模块，以及一种自适应的卷积搅拌扩展。</li>
<li>results: 我们在五个数据集上进行了比较，并达到了与现有模型相当的竞争性表现。<details>
<summary>Abstract</summary>
Developing a new Salient Object Detection (SOD) model involves selecting an ImageNet pre-trained backbone and creating novel feature refinement modules to use backbone features. However, adding new components to a pre-trained backbone needs retraining the whole network on the ImageNet dataset, which requires significant time. Hence, we explore developing a neural network from scratch directly trained on SOD without ImageNet pre-training. Such a formulation offers full autonomy to design task-specific components. To that end, we propose SODAWideNet, an encoder-decoder-style network for Salient Object Detection. We deviate from the commonly practiced paradigm of narrow and deep convolutional models to a wide and shallow architecture, resulting in a parameter-efficient deep neural network. To achieve a shallower network, we increase the receptive field from the beginning of the network using a combination of dilated convolutions and self-attention. Therefore, we propose Multi Receptive Field Feature Aggregation Module (MRFFAM) that efficiently obtains discriminative features from farther regions at higher resolutions using dilated convolutions. Next, we propose Multi-Scale Attention (MSA), which creates a feature pyramid and efficiently computes attention across multiple resolutions to extract global features from larger feature maps. Finally, we propose two variants, SODAWideNet-S (3.03M) and SODAWideNet (9.03M), that achieve competitive performance against state-of-the-art models on five datasets.
</details>
<details>
<summary>摘要</summary>
开发新的突出 объек特征检测（SOD）模型需要选择一个ImageNet预训练后置和创建专门的特征修正模块，以使用后置特征。但是，添加新组件到预训练后置需要重新训练整个网络在ImageNet dataset上，这需要很长时间。因此，我们探索直接从 scratch 开发一个神经网络，用于 Salient Object Detection 而不需要 ImageNet 预训练。这种设计方式允许我们完全自主地设计任务特定的组件。为此，我们提出 SODAWideNet，一种编码器-解码器式神经网络，用于 Salient Object Detection。我们与常见的窄深 convolutional 模型不同，采用了宽浅的架构，从而实现参数效率的深度神经网络。为了增加网络的宽度，我们在网络的开始处使用扩展 convolutions 和自注意力来增加感知场。因此，我们提出 Multi Receptive Field Feature Aggregation Module (MRFFAM)，它可以高效地从较远区域获取更高分辨率的特征。然后，我们提出 Multi-Scale Attention (MSA)，它可以快速计算多尺度的注意力，从而提取更大的特征图。最后，我们提出 SODAWideNet-S (3.03M) 和 SODAWideNet (9.03M) 两种变种，它们在五个数据集上实现了与当前状态的竞争性性能。
</details></li>
</ul>
<hr>
<h2 id="Cross-Silo-Federated-Learning-Across-Divergent-Domains-with-Iterative-Parameter-Alignment"><a href="#Cross-Silo-Federated-Learning-Across-Divergent-Domains-with-Iterative-Parameter-Alignment" class="headerlink" title="Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment"></a>Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04818">http://arxiv.org/abs/2311.04818</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mattgorb/iterative_parameter_alignment">https://github.com/mattgorb/iterative_parameter_alignment</a></li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray</li>
<li>for: 本研究旨在提高神经网络的总结能力，通过在私有数据源中散布的数据收集知识来启发神经网络。</li>
<li>methods: 本研究使用联合训练方法，通过中心服务器的调度来将客户端模型相互结合。</li>
<li>results: 研究发现，当client domains suficiently不同时，现有的方法很难以收敛，并且现有的汇集技术会生成每个客户端的同样的全球模型。本研究解决这两个问题，并提出了一种新的框架，即迭代参数对齐。这种框架可以在cross-silo设置下自然地应用，具有以下特点：（i）每个参与者都有唯一的解决方案，并且可以在联邦中每个模型都globally converge。（ii）可选的早期停止机制，以便在合作学习设置下让每个参与者具有公平的学习机会。这些特点共同提供了一种可Iteratively学习从peer模型在不同数据集上进行训练的灵活新框架。我们发现，该技术在多个数据分区比例上与当前的方法竞争。此外，我们还证明了该方法在不同领域（i.e. 客户端数据集中的分离类）的情况下具有良好的Robustness。<details>
<summary>Abstract</summary>
Learning from the collective knowledge of data dispersed across private sources can provide neural networks with enhanced generalization capabilities. Federated learning, a method for collaboratively training a machine learning model across remote clients, achieves this by combining client models via the orchestration of a central server. However, current approaches face two critical limitations: i) they struggle to converge when client domains are sufficiently different, and ii) current aggregation techniques produce an identical global model for each client. In this work, we address these issues by reformulating the typical federated learning setup: rather than learning a single global model, we learn N models each optimized for a common objective. To achieve this, we apply a weighted distance minimization to model parameters shared in a peer-to-peer topology. The resulting framework, Iterative Parameter Alignment, applies naturally to the cross-silo setting, and has the following properties: (i) a unique solution for each participant, with the option to globally converge each model in the federation, and (ii) an optional early-stopping mechanism to elicit fairness among peers in collaborative learning settings. These characteristics jointly provide a flexible new framework for iteratively learning from peer models trained on disparate datasets. We find that the technique achieves competitive results on a variety of data partitions compared to state-of-the-art approaches. Further, we show that the method is robust to divergent domains (i.e. disjoint classes across peers) where existing approaches struggle.
</details>
<details>
<summary>摘要</summary>
通过收集分散在私有源数据上的共同知识，神经网络可以获得增强的通用能力。联邦学习方法可以在远程客户端之间协同训练机器学习模型，并将客户端模型集成到中央服务器的指挥下。然而，现有的方法面临两个严重的限制：一是在客户端领域差异足够大时困难 converge，二是现有的汇集技术会生成每个客户端上的相同全球模型。在这项工作中，我们解决这些问题，通过在参数之间分配权重，来实现参数的对照Alignment。这种方法可以自然地应用于跨私有集成（cross-silo）的情况，并具有以下特点：（i）每个参与者都有独特的解决方案，可以在联邦中每个模型的全球化进程中选择地 globally converge 每个模型，（ii）在合作学习设置中，可以使用可选的早期停止机制来寻求参与者之间的公平性。这些特点共同提供了一种灵活的新框架，可以逐步学习来自不同数据集的 peer 模型。我们发现，这种技术可以与当前的状态艺术方法竞争，并且在不同的数据分区上表现出色。此外，我们还证明了该方法在不同领域（i.e. 客户端领域中的分类）中具有强大的稳定性。
</details></li>
</ul>
<hr>
<h2 id="Domain-Adaptive-Object-Detection-via-Balancing-Between-Self-Training-and-Adversarial-Learning"><a href="#Domain-Adaptive-Object-Detection-via-Balancing-Between-Self-Training-and-Adversarial-Learning" class="headerlink" title="Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning"></a>Domain Adaptive Object Detection via Balancing Between Self-Training and Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04815">http://arxiv.org/abs/2311.04815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Akhtar Munir, Muhammad Haris Khan, M. Saquib Sarfraz, Mohsen Ali</li>
<li>for: 这篇论文的目的是提高深度学习基础的物体检测器在新目标领域中的整合能力，因为这些检测器在面临新的领域时通常会受到许多物品和背景的变化所困扰。</li>
<li>methods: 这篇论文使用了两种方法来实现这个目的：一是使用图像或实例对抗性特征Alignment，但这经常会因为背景的影响而受到限制，而且缺乏对特定类别的Alignment。另一方面，这篇论文提出了一个简单的方法，即使用高信任率的预测值作为pseudo-label，并且使用预测值的不确定度来调节对抗特征Alignment和类别Alignment之间的平衡。</li>
<li>results: 这篇论文的结果显示，使用这种方法可以比据面临新的领域时，与现有的方法相比，有较高的整合能力和性能。实验结果显示，这种方法可以在五个多样化和挑战性的领域中实现较好的整合和性能。<details>
<summary>Abstract</summary>
Deep learning based object detectors struggle generalizing to a new target domain bearing significant variations in object and background. Most current methods align domains by using image or instance-level adversarial feature alignment. This often suffers due to unwanted background and lacks class-specific alignment. A straightforward approach to promote class-level alignment is to use high confidence predictions on unlabeled domain as pseudo-labels. These predictions are often noisy since model is poorly calibrated under domain shift. In this paper, we propose to leverage model's predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. We develop a technique to quantify predictive uncertainty on class assignments and bounding-box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-training, whereas the ones with higher uncertainty are used to generate tiles for adversarial feature alignment. This synergy between tiling around uncertain object regions and generating pseudo-labels from highly certain object regions allows capturing both image and instance-level context during the model adaptation. We report thorough ablation study to reveal the impact of different components in our approach. Results on five diverse and challenging adaptation scenarios show that our approach outperforms existing state-of-the-art methods with noticeable margins.
</details>
<details>
<summary>摘要</summary>
深度学习基于对象检测器在新目标领域中总是难以泛化，主要原因是对象和背景中的变化很大。现有方法通常使用图像或实例级别的对抗特征对齐。然而，这经常会受到背景的影响，并且缺乏类别匹配。为了促进类别匹配，我们提出使用高信息content的预测值作为pseudo-标签。这些预测值经常是噪音的，因为模型在频率变换下不具备良好的准确性。在这篇论文中，我们提出使用模型预测的不确定性来平衡对抗特征对齐和类别匹配。我们开发了一种方法来衡量模型预测中的不确定性，并将其用于生成pseudo-标签和对抗特征对齐。这种对不确定性范围内的瓦解和高信息content预测值生成pseudo-标签的方法，使得在模型适应过程中捕捉到图像和实例级别的上下文。我们进行了系统的ablation研究，以便了解不同组件的影响。我们的方法在五种复杂和挑战性的适应场景中显著超过了现有状态的方法。
</details></li>
</ul>
<hr>
<h2 id="Be-Careful-When-Evaluating-Explanations-Regarding-Ground-Truth"><a href="#Be-Careful-When-Evaluating-Explanations-Regarding-Ground-Truth" class="headerlink" title="Be Careful When Evaluating Explanations Regarding Ground Truth"></a>Be Careful When Evaluating Explanations Regarding Ground Truth</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04813">http://arxiv.org/abs/2311.04813</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MI2DataLab/be-careful-evaluating-explanations">https://github.com/MI2DataLab/be-careful-evaluating-explanations</a></li>
<li>paper_authors: Hubert Baniecki, Maciej Chrabaszcz, Andreas Holzinger, Bastian Pfeifer, Anna Saranti, Przemyslaw Biecek</li>
<li>for: 这个论文的目的是评估深度神经网络和解释方法的可靠性，它们在实际应用中如医学图像分析和机器人控制中越来越广泛使用。</li>
<li>methods: 这个论文提出了一种框架，可以同时评估这些系统的可靠性和解释方法的质量。它们使用了一种精度调整过程来（不）对模型和解释方法进行对齐，并使用这种过程来衡量模型和解释方法之间的差异。</li>
<li>results: 经过多种模型体系和后处地本地解释方法的实验，研究发现了视Transformers的可靠性和AI系统总体受到可能的敌意攻击的抵触性。<details>
<summary>Abstract</summary>
Evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves. Driven by this observation, we propose a framework for $\textit{jointly}$ evaluating the robustness of safety-critical systems that $\textit{combine}$ a deep neural network with an explanation method. These are increasingly used in real-world applications like medical image analysis or robotics. We introduce a fine-tuning procedure to (mis)align model$\unicode{x2013}$explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment. Experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks.
</details>
<details>
<summary>摘要</summary>
evaluating explanations of image classifiers regarding ground truth, e.g. segmentation masks defined by human perception, primarily evaluates the quality of the models under consideration rather than the explanation methods themselves. driven by this observation, we propose a framework for jointly evaluating the robustness of safety-critical systems that combine a deep neural network with an explanation method. these are increasingly used in real-world applications like medical image analysis or robotics. we introduce a fine-tuning procedure to (mis)align model-explanation pipelines with ground truth and use it to quantify the potential discrepancy between worst and best-case scenarios of human alignment. experiments across various model architectures and post-hoc local interpretation methods provide insights into the robustness of vision transformers and the overall vulnerability of such AI systems to potential adversarial attacks.Here's the text with some notes on the translation:* "image classifiers" is translated as "图像分类器" (tú zhǐ bǐng lèi jī)* "ground truth" is translated as "真实的事实" (zhēn shí de shí shí)* "segmentation masks" is translated as "分割 маSK" (fēn zhī ma sk)* "human perception" is translated as "人类的感知" (rén xìng de gǎn zhī)* "primarily evaluates" is translated as "主要评估" (zhǔ yào píng yào)* "robustness" is translated as "鲜度" (xiān duō)* "safety-critical systems" is translated as "安全关键系统" (ān què yuè xiàng jì tǒng)* "deep neural network" is translated as "深度神经网络" (shēn dào shén zhì wǎng wǎn)* "explanation method" is translated as "解释方法" (jiě jiě fāng fá)* "post-hoc local interpretation methods" is translated as "后期本地解释方法" (hòu qǐ běn dì jiě jiě fāng fá)* "adversarial attacks" is translated as "抗击攻击" (kàng zhì gōng jī)Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. Traditional Chinese is used in Taiwan and other countries, and the translation may be slightly different in Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Image-Based-Virtual-Try-On-A-Survey"><a href="#Image-Based-Virtual-Try-On-A-Survey" class="headerlink" title="Image-Based Virtual Try-On: A Survey"></a>Image-Based Virtual Try-On: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04811">http://arxiv.org/abs/2311.04811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/little-misfit/survey-of-virtual-try-on">https://github.com/little-misfit/survey-of-virtual-try-on</a></li>
<li>paper_authors: Dan Song, Xuanpu Zhang, Juan Zhou, Weizhi Nie, Ruofeng Tong, An-An Liu</li>
<li>for: 这篇论文主要目标是对图像基 Virtual Try-On 技术进行概述和分析，并提出未来研究方向。</li>
<li>methods: 论文使用了现有的图像生成技术，如人体匠心技术和图像涂抹技术，以及新的Semantic CLIP 技术。</li>
<li>results: 论文通过对现有方法的量化和质量评估，以及ControlNet 等新技术的应用，展示了图像基 Virtual Try-On 技术的未来发展潜力。<details>
<summary>Abstract</summary>
Image-based virtual try-on aims to synthesize a naturally dressed person image with a clothing image, which revolutionizes online shopping and inspires related topics within image generation, showing both research significance and commercial potentials. However, there is a great gap between current research progress and commercial applications and an absence of comprehensive overview towards this field to accelerate the development. In this survey, we provide a comprehensive analysis of the state-of-the-art techniques and methodologies in aspects of pipeline architecture, person representation and key modules such as try-on indication, clothing warping and try-on stage. We propose a new semantic criteria with CLIP, and evaluate representative methods with uniformly implemented evaluation metrics on the same dataset. In addition to quantitative and qualitative evaluation of current open-source methods, we also utilize ControlNet to fine-tune a recent large image generation model (PBE) to show future potentials of large-scale models on image-based virtual try-on task. Finally, unresolved issues are revealed and future research directions are prospected to identify key trends and inspire further exploration. The uniformly implemented evaluation metrics, dataset and collected methods will be made public available at https://github.com/little-misfit/Survey-Of-Virtual-Try-On.
</details>
<details>
<summary>摘要</summary>
文本摘要：图像基于虚拟试穿涉及将人像图像与衣服图像合成成一个自然地穿着的人像图像，这种技术有前所未有的在线购物和图像生成方面的潜在应用前景。然而，目前研究进步和商业应用之间存在很大的差距，而且该领域的总体评估缺乏，这阻碍了该领域的快速发展。在本调查中，我们提供了图像基于虚拟试穿领域的完整分析，包括管道架构、人物表示和关键模块 such as 试穿指示、衣服扭曲和试穿阶段。我们还提出了一种新的Semantic CLIP标准，并对代表方法进行了统一的评估。除了对当前开源方法的量化和质量评估外，我们还使用ControlNet来精度地调整最近一个大型图像生成模型（PBE），以示未来大规模模型在图像基于虚拟试穿任务中的潜在潜力。最后，我们揭示了未解的问题和未来研究方向，以便识别关键趋势并鼓励进一步的探索。我们在 GitHub 上将 uniformly 实现的评估指标、数据集和收集到的方法公开可用。
</details></li>
</ul>
<hr>
<h2 id="VioLA-Aligning-Videos-to-2D-LiDAR-Scans"><a href="#VioLA-Aligning-Videos-to-2D-LiDAR-Scans" class="headerlink" title="VioLA: Aligning Videos to 2D LiDAR Scans"></a>VioLA: Aligning Videos to 2D LiDAR Scans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04783">http://arxiv.org/abs/2311.04783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun-Jee Chao, Selim Engin, Nikhil Chavan-Dafle, Bhoram Lee, Volkan Isler</li>
<li>for: 本研究旨在将视频中捕捉的本地环境与2D LiDAR扫描图匹配。</li>
<li>methods: 我们提出了一种方法（VioLA），它首先从图像序列中构建了本地场景的semantic map，然后从图像序列中提取了一个固定高度的点，用于与LiDAR图匹配。由于恢复错误或相机扫描部分的覆盖，可能导致重构的semantic map中缺失足够的信息 для姿态注册。为解决这个问题，VioLA利用了一个预训练的文本到图像填充模型和深度完成模型，以在 geometrically 一致的方式填充缺失的场景内容，从而支持姿态注册。</li>
<li>results: 我们在两个真实的RGB-D标准测试集和一个自拍取的大办公室场景测试集上评估了VioLA。结果显示，我们的提出的场景填充模块可以提高姿态注册性能，最高提高20%。<details>
<summary>Abstract</summary>
We study the problem of aligning a video that captures a local portion of an environment to the 2D LiDAR scan of the entire environment. We introduce a method (VioLA) that starts with building a semantic map of the local scene from the image sequence, then extracts points at a fixed height for registering to the LiDAR map. Due to reconstruction errors or partial coverage of the camera scan, the reconstructed semantic map may not contain sufficient information for registration. To address this problem, VioLA makes use of a pre-trained text-to-image inpainting model paired with a depth completion model for filling in the missing scene content in a geometrically consistent fashion to support pose registration. We evaluate VioLA on two real-world RGB-D benchmarks, as well as a self-captured dataset of a large office scene. Notably, our proposed scene completion module improves the pose registration performance by up to 20%.
</details>
<details>
<summary>摘要</summary>
我们研究将视频捕捉当地环境与2D LiDAR扫描的全环境进行对应的问题。我们提出了一种方法（VioLA），它从图像序列中构建了本地场景的semantic地图，然后从图像序列中提取了一个固定高度的点来与LiDAR地图进行对应。由于恢复错误或摄像头扫描的部分覆盖，可能无法从重构的semantic地图中获取足够的信息进行注册。为解决这个问题，VioLA利用了预训练的文本到图像填充模型和深度完成模型，以在 geometrically 一致的方式填充缺失的场景内容，从而支持pose注册。我们在两个真实的RGB-D标准测试集和我们自己拍摄的大办公室场景测试集上评估了VioLA。可以看到，我们提出的场景完成模块可以提高pose注册性能，最高提高20%。
</details></li>
</ul>
<hr>
<h2 id="Lidar-Annotation-Is-All-You-Need"><a href="#Lidar-Annotation-Is-All-You-Need" class="headerlink" title="Lidar Annotation Is All You Need"></a>Lidar Annotation Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04777">http://arxiv.org/abs/2311.04777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/evocargo/lidar-annotation-is-all-you-need">https://github.com/evocargo/lidar-annotation-is-all-you-need</a></li>
<li>paper_authors: Dinar Sharafutdinov, Stanislav Kuskov, Saian Protasov, Alexey Voropaev</li>
<li>for: 提高图像分割的效率，用于自动驾驶系统中的道路表面分割任务。</li>
<li>methods: 使用卷积神经网络，利用激光探测器（Lidar）精度测量道路表面，并将其用作图像分割模型的地面标注。</li>
<li>results: 实验 validate the approach on 多个benchmark dataset，与高质量图像分割模型的性能相当。<details>
<summary>Abstract</summary>
In recent years, computer vision has transformed fields such as medical imaging, object recognition, and geospatial analytics. One of the fundamental tasks in computer vision is semantic image segmentation, which is vital for precise object delineation. Autonomous driving represents one of the key areas where computer vision algorithms are applied. The task of road surface segmentation is crucial in self-driving systems, but it requires a labor-intensive annotation process in several data domains. The work described in this paper aims to improve the efficiency of image segmentation using a convolutional neural network in a multi-sensor setup. This approach leverages lidar (Light Detection and Ranging) annotations to directly train image segmentation models on RGB images. Lidar supplements the images by emitting laser pulses and measuring reflections to provide depth information. However, lidar's sparse point clouds often create difficulties for accurate object segmentation. Segmentation of point clouds requires time-consuming preliminary data preparation and a large amount of computational resources. The key innovation of our approach is the masked loss, addressing sparse ground-truth masks from point clouds. By calculating loss exclusively where lidar points exist, the model learns road segmentation on images by using lidar points as ground truth. This approach allows for blending of different ground-truth data types during model training. Experimental validation of the approach on benchmark datasets shows comparable performance to a high-quality image segmentation model. Incorporating lidar reduces the load on annotations and enables training of image-segmentation models without loss of segmentation quality. The methodology is tested on diverse datasets, both publicly available and proprietary. The strengths and weaknesses of the proposed method are also discussed in the paper.
</details>
<details>
<summary>摘要</summary>
近年来，计算机视觉技术已经对医学影像、物体识别和地球分析等领域产生了深见的影响。计算机视觉中的一项基本任务是semantic image segmentation，它是精确物体定义的关键。自动驾驶是计算机视觉算法的一个关键应用领域，但是道路表面 segmentation 是自动驾驶系统中的关键任务，但是需要大量的注释过程。这篇文章描述的工作是使用多感器设置中的卷积神经网络进行图像分割的提高。这种方法利用激光探测器（Lidar）的注释来直接将图像分割模型训练到RGB图像上。Lidar 补充图像，通过发射激光脉冲并测量反射来提供深度信息。然而，Lidar 的稀疏点云经常对精确物体分割造成困难。图像分割需要耗时的先前数据准备和大量的计算资源。我们的方法的关键创新是使用Masked loss来 Addressing sparse ground truth masks from point clouds。通过在激光点云存在的地方进行损失计算，模型可以通过激光点云作为真实的ground truth来学习道路分割。这种方法允许在训练过程中混合不同的ground truth数据类型。实验 validate our approach on benchmark datasets shows comparable performance to a high-quality image segmentation model。将激光点云纳入训练过程可以减轻注释的负担，并使图像分割模型不会失去分割质量。我们的方法在多个dataset上进行了测试，包括公共 dataset 和专有 dataset。文章还讨论了我们的方法的优缺点。
</details></li>
</ul>
<hr>
<h2 id="GCS-ICHNet-Assessment-of-Intracerebral-Hemorrhage-Prognosis-using-Self-Attention-with-Domain-Knowledge-Integration"><a href="#GCS-ICHNet-Assessment-of-Intracerebral-Hemorrhage-Prognosis-using-Self-Attention-with-Domain-Knowledge-Integration" class="headerlink" title="GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using Self-Attention with Domain Knowledge Integration"></a>GCS-ICHNet: Assessment of Intracerebral Hemorrhage Prognosis using Self-Attention with Domain Knowledge Integration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04772">http://arxiv.org/abs/2311.04772</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Windbelll/Prognosis-analysis-of-cerebral-hemorrhage">https://github.com/Windbelll/Prognosis-analysis-of-cerebral-hemorrhage</a></li>
<li>paper_authors: Xuhao Shan, Xinyang Li, Ruiquan Ge, Shibin Wu, Ahmed Elazab, Jichao Zhu, Lingyan Zhang, Gangyong Jia, Qingying Xiao, Xiang Wan, Changmiao Wang</li>
<li>for: 该论文旨在提高脑内出血（ICH）的预测和管理，提高患者的生存率。</li>
<li>methods: 该论文提出了一种新的深度学习算法——GCS-ICHNet，该算法通过将多Modal脑CT图像数据和格拉斯哥康复分数（GCS）值融合，以提高ICH的诊断精度。</li>
<li>results: 该论文的结果显示，GCS-ICHNet能够达到81.03%的敏感性和91.59%的特异性，超过了平均的临床医生和其他当前的方法。<details>
<summary>Abstract</summary>
Intracerebral Hemorrhage (ICH) is a severe condition resulting from damaged brain blood vessel ruptures, often leading to complications and fatalities. Timely and accurate prognosis and management are essential due to its high mortality rate. However, conventional methods heavily rely on subjective clinician expertise, which can lead to inaccurate diagnoses and delays in treatment. Artificial intelligence (AI) models have been explored to assist clinicians, but many prior studies focused on model modification without considering domain knowledge. This paper introduces a novel deep learning algorithm, GCS-ICHNet, which integrates multimodal brain CT image data and the Glasgow Coma Scale (GCS) score to improve ICH prognosis. The algorithm utilizes a transformer-based fusion module for assessment. GCS-ICHNet demonstrates high sensitivity 81.03% and specificity 91.59%, outperforming average clinicians and other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Intracerebral Hemorrhage (ICH) 是一种严重的疾病，由于脑血管损害而导致，经常会导致复杂性和致死率高。因此，时效精准的诊断和治疗是非常重要。然而，传统的方法强调专家式的诊断，可能会导致诊断不准确和治疗延迟。人工智能（AI）模型已经被探讨，但多数前 studies 强调模型修改而未考虑域知识。这篇论文介绍了一种新的深度学习算法，GCS-ICHNet，该算法利用多modal脑CT图像数据和格拉斯哥昏迷度评分（GCS）来提高ICH诊断。该算法使用转换器基于的融合模块进行评估。GCS-ICHNet 在敏感性和特异性方面均达到了81.03%和91.59%，高于平均的临床医生和其他当前状态的方法。
</details></li>
</ul>
<hr>
<h2 id="An-attention-based-deep-learning-network-for-predicting-Platinum-resistance-in-ovarian-cancer"><a href="#An-attention-based-deep-learning-network-for-predicting-Platinum-resistance-in-ovarian-cancer" class="headerlink" title="An attention-based deep learning network for predicting Platinum resistance in ovarian cancer"></a>An attention-based deep learning network for predicting Platinum resistance in ovarian cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04769">http://arxiv.org/abs/2311.04769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoming Zhuang, Beibei Li, Jingtong Ma, Patrice Monkam, Shouliang Qi, Wei Qian, Dianning He</li>
<li>For: This study aims to propose a deep learning-based method to determine whether a patient with high-grade serous ovarian cancer (HGSOC) is platinum-resistant using multimodal positron emission tomography&#x2F;computed tomography (PET&#x2F;CT) images.* Methods: The proposed method uses an end-to-end SE-SPP-DenseNet model, which combines Squeeze-Excitation Block (SE Block) and Spatial Pyramid Pooling Layer (SPPLayer) with Dense Convolutional Network (DenseNet) to analyze multimodal PET&#x2F;CT images of the regions of interest (ROI) and predict platinum resistance in patients.* Results: The study achieved a high accuracy rate and an area under the curve (AUC) of 0.93 in predicting platinum resistance in patients, indicating that the proposed deep learning framework can help gynecologists make better treatment decisions.<details>
<summary>Abstract</summary>
Background: Ovarian cancer is among the three most frequent gynecologic cancers globally. High-grade serous ovarian cancer (HGSOC) is the most common and aggressive histological type. Guided treatment for HGSOC typically involves platinum-based combination chemotherapy, necessitating an assessment of whether the patient is platinum-resistant. The purpose of this study is to propose a deep learning-based method to determine whether a patient is platinum-resistant using multimodal positron emission tomography/computed tomography (PET/CT) images. Methods: 289 patients with HGSOC were included in this study. An end-to-end SE-SPP-DenseNet model was built by adding Squeeze-Excitation Block (SE Block) and Spatial Pyramid Pooling Layer (SPPLayer) to Dense Convolutional Network (DenseNet). Multimodal data from PET/CT images of the regions of interest (ROI) were used to predict platinum resistance in patients. Results: Through five-fold cross-validation, SE-SPP-DenseNet achieved a high accuracy rate and an area under the curve (AUC) in predicting platinum resistance in patients, which were 92.6% and 0.93, respectively. The importance of incorporating SE Block and SPPLayer into the deep learning model, and considering multimodal data was substantiated by carrying out ablation studies and experiments with single modality data. Conclusions: The obtained classification results indicate that our proposed deep learning framework performs better in predicting platinum resistance in patients, which can help gynecologists make better treatment decisions. Keywords: PET/CT, CNN, SE Block, SPP Layer, Platinum resistance, Ovarian cancer
</details>
<details>
<summary>摘要</summary>
背景：子宫癌是全球三大妇科癌症之一，高度精度膜癌（HGSOC）是最常见且侵袭性最高的 histological 型。对 HGSOC 患者，通常采用 platinum-based 组合化学疗法，需要评估患者是否 platinum-resistant。本研究的目的是使用深度学习方法来判断 HGSOC 患者是否 platinum-resistant，并使用 multimodal PET/CT 图像进行预测。方法：本研究包括 289 名 HGSOC 患者。我们建立了一个 end-to-end SE-SPP-DenseNet 模型，其中包括 Squeeze-Excitation Block（SE Block）和 Spatial Pyramid Pooling Layer（SPPLayer）。我们使用 PET/CT 图像的多Modal 数据来预测患者是否 platinum-resistant。结果：通过五fold 十字验证，SE-SPP-DenseNet 模型在预测患者是否 platinum-resistant 中取得了高精度率和抑肿曲线（AUC），具体数据如下：精度率 92.6%，AUC 0.93。我们还进行了减少和单 modal 数据实验，以证明 incorporating SE Block 和 SPPLayer 到深度学习模型以及使用 multimodal 数据的重要性。结论：我们的深度学习框架在预测患者是否 platinum-resistant 中取得了更高的精度率，这可以帮助妇科医生更好地制定治疗方案。关键词：PET/CT, CNN, SE Block, SPP Layer, Platinum resistance, Ovarian cancer
</details></li>
</ul>
<hr>
<h2 id="DualTalker-A-Cross-Modal-Dual-Learning-Approach-for-Speech-Driven-3D-Facial-Animation"><a href="#DualTalker-A-Cross-Modal-Dual-Learning-Approach-for-Speech-Driven-3D-Facial-Animation" class="headerlink" title="DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D Facial Animation"></a>DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D Facial Animation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04766">http://arxiv.org/abs/2311.04766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guinan Su, Yanwu Yang, Zhifeng Li</li>
<li>for: 增强数据使用效率和跨模态关系</li>
<li>methods: 跨模态双学习框架（DualTalker）和跨模态一致性损失</li>
<li>results: 在VOCA和BIWI数据集上，与当前状态艺术方法进行比较，得到了较好的性能表现，并通过用户测试得到了更高的评价。<details>
<summary>Abstract</summary>
In recent years, audio-driven 3D facial animation has gained significant attention, particularly in applications such as virtual reality, gaming, and video conferencing. However, accurately modeling the intricate and subtle dynamics of facial expressions remains a challenge. Most existing studies approach the facial animation task as a single regression problem, which often fail to capture the intrinsic inter-modal relationship between speech signals and 3D facial animation and overlook their inherent consistency. Moreover, due to the limited availability of 3D-audio-visual datasets, approaches learning with small-size samples have poor generalizability that decreases the performance. To address these issues, in this study, we propose a cross-modal dual-learning framework, termed DualTalker, aiming at improving data usage efficiency as well as relating cross-modal dependencies. The framework is trained jointly with the primary task (audio-driven facial animation) and its dual task (lip reading) and shares common audio/motion encoder components. Our joint training framework facilitates more efficient data usage by leveraging information from both tasks and explicitly capitalizing on the complementary relationship between facial motion and audio to improve performance. Furthermore, we introduce an auxiliary cross-modal consistency loss to mitigate the potential over-smoothing underlying the cross-modal complementary representations, enhancing the mapping of subtle facial expression dynamics. Through extensive experiments and a perceptual user study conducted on the VOCA and BIWI datasets, we demonstrate that our approach outperforms current state-of-the-art methods both qualitatively and quantitatively. We have made our code and video demonstrations available at https://github.com/sabrina-su/iadf.git.
</details>
<details>
<summary>摘要</summary>
近年来，受音频驱动的3D面部动画技术受到了广泛关注，特别是在虚拟现实、游戏和视频会议等应用中。然而，准确地模型面部表达的细微和复杂动态仍然是一大挑战。大多数现有研究将面部动画任务视为单一回归问题，容易忽视面部表达和音频信号之间的内在关系，以及它们的共同一致性。此外，由于3D-audio-visual数据的有限可用性，使用小型样本学习的方法的性能差异很大，降低了性能。为解决这些问题，我们在本研究中提出了一种跨Modal dual学习框架，称之为DualTalker，旨在提高数据使用效率以及跨Modal相关性。该框架在同时进行主任务（音频驱动面部动画）和其双任务（ lip reading）的 JOINT 训练中，共享音频/动作编码器组件。我们的 JOINT 训练框架可以更好地利用两个任务之间的信息，并通过跨Modal的相关性来提高表达性能。此外，我们还引入了辅助的跨Modal一致性损失，以遏制可能出现的跨Modal相关表示过度简化，提高表达动态的映射。经过广泛的实验和基于 VOCA 和 BIWI 数据集的感知用户研究，我们表明，我们的方法在质量和量上都超过了当前领导方法，并提供了相关视频展示。我们在 GitHub 上提供了代码和视频展示，请参考 https://github.com/sabrina-su/iadf.git。
</details></li>
</ul>
<hr>
<h2 id="Social-Motion-Prediction-with-Cognitive-Hierarchies"><a href="#Social-Motion-Prediction-with-Cognitive-Hierarchies" class="headerlink" title="Social Motion Prediction with Cognitive Hierarchies"></a>Social Motion Prediction with Cognitive Hierarchies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04726">http://arxiv.org/abs/2311.04726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Walter0807/Social-CH">https://github.com/Walter0807/Social-CH</a></li>
<li>paper_authors: Wentao Zhu, Jason Qin, Yuke Lou, Hang Ye, Xiaoxuan Ma, Hai Ci, Yizhou Wang</li>
<li>for: 本研究旨在复制人类在预测他人行为方面的能力，通过解决社交动作预测问题。</li>
<li>methods: 我们引入了一个新的数据集Wusi，基于团队运动的3D多人动作数据集，并提出了一种新的形式化和认知层次框架。我们还使用了行为快照和生成对抗学习来提高学习效率和通用性。</li>
<li>results: 我们进行了广泛的实验 validate our proposed dataset and approach的效果。<details>
<summary>Abstract</summary>
Humans exhibit a remarkable capacity for anticipating the actions of others and planning their own actions accordingly. In this study, we strive to replicate this ability by addressing the social motion prediction problem. We introduce a new benchmark, a novel formulation, and a cognition-inspired framework. We present Wusi, a 3D multi-person motion dataset under the context of team sports, which features intense and strategic human interactions and diverse pose distributions. By reformulating the problem from a multi-agent reinforcement learning perspective, we incorporate behavioral cloning and generative adversarial imitation learning to boost learning efficiency and generalization. Furthermore, we take into account the cognitive aspects of the human social action planning process and develop a cognitive hierarchy framework to predict strategic human social interactions. We conduct comprehensive experiments to validate the effectiveness of our proposed dataset and approach. Code and data are available at https://walter0807.github.io/Social-CH/.
</details>
<details>
<summary>摘要</summary>
人类具有惊人的他人行为预测能力和相应的行动规划能力。在本研究中，我们努力复制这种能力，解决社交动作预测问题。我们介绍了一个新的标准 bencmark，一种新的形ulation，以及一个基于认知的框架。我们发布了一个3D多人动作数据集，名为Wusi，这个数据集在球类运动中展示了人类之间的激烈和策略性的互动，以及多种姿态分布。我们通过将问题转化为多智能激励学习的视角，并采用行为做模仿学习和生成敌对偶护学习，以提高学习效率和泛化能力。此外，我们考虑了人类社交行为规划过程中的认知方面，并开发了一个认知层次框架，以预测人类社交互动的策略性。我们进行了全面的实验 validate our proposed dataset and approach。代码和数据可以在https://walter0807.github.io/Social-CH/ 获取。
</details></li>
</ul>
<hr>
<h2 id="Training-CLIP-models-on-Data-from-Scientific-Papers"><a href="#Training-CLIP-models-on-Data-from-Scientific-Papers" class="headerlink" title="Training CLIP models on Data from Scientific Papers"></a>Training CLIP models on Data from Scientific Papers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04711">http://arxiv.org/abs/2311.04711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nopperl/clip_arxiv_pmc">https://github.com/nopperl/clip_arxiv_pmc</a></li>
<li>paper_authors: Calvin Metzger</li>
<li>for: 是否可以使用特定领域高质量数据来提高CLIP模型的总体性能？</li>
<li>methods: 使用arXiv和PubMed Central repositories中的科学论文文本图像数据进行采集和实验。</li>
<li>results: 模型性能平均提高，但只是moderate。这表明使用这些数据来训练大规模CLIP模型是一个值得研究的方向。<details>
<summary>Abstract</summary>
Contrastive Language-Image Pretraining (CLIP) models are able to capture the semantic relationship of images and texts and have enabled a wide range of applications, from image retrieval to classification. These models are trained with datasets extracted from web crawls, which are of large quantity but limited quality. This paper explores whether limited amounts higher quality data in a specific domain improve the general performance of CLIP models. To this purpose, we extract text-image data from scientific papers hosted in the arXiv and PubMed Central repositories. Experiments on small-scale CLIP models (ViT B/32) show that model performance increases on average, but only moderately. This result indicates that using the data sources considered in the paper to train large-scale CLIP models is a worthwile research direction.
</details>
<details>
<summary>摘要</summary>
CLIP模型能够捕捉图像和文本之间的含义关系，并且开发了许多应用程序，从图像检索到分类。这些模型通常通过网络抓取而训练，但这些数据量虽然庞大，但质量有限。这篇论文探讨了是否有限量但高质量数据在特定领域中提高CLIP模型的总性表现。为此，我们从arXiv和PubMed Central数据Repositories中提取了文本-图像数据。实验结果表明，使用这些数据来训练小规模CLIP模型（ViT B/32），模型的性能平均提高，但只是 Moderate。这个结果表明，使用论文中所考虑的数据来训练大规模CLIP模型是一个值得研究的方向。
</details></li>
</ul>
<hr>
<h2 id="3D-Pose-Estimation-of-Tomato-Peduncle-Nodes-using-Deep-Keypoint-Detection-and-Point-Cloud"><a href="#3D-Pose-Estimation-of-Tomato-Peduncle-Nodes-using-Deep-Keypoint-Detection-and-Point-Cloud" class="headerlink" title="3D Pose Estimation of Tomato Peduncle Nodes using Deep Keypoint Detection and Point Cloud"></a>3D Pose Estimation of Tomato Peduncle Nodes using Deep Keypoint Detection and Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04699">http://arxiv.org/abs/2311.04699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianchao Ci, Xin Wang, David Rapado-Rincón, Akshay K. Burusa, Gert Kootstra</li>
<li>for: 这个论文的目的是解决发达国家的greenhouse生产中的劳动力短缺和高成本问题，通过使用机器人技术实现可持续可靠的生产。</li>
<li>methods: 这篇论文提出了一种基于关键点检测的方法，使用RGB-D摄像头数据进行 Tomatoes的3D姿态估计。该方法首先在色彩图像中检测四个解剖特征点，然后将这些点与3D点云信息集成，以确定 Tomatoes的3D姿态。</li>
<li>results: 该方法的测试结果显示：一、对象检测精度高，AP&#x3D;0.96；二、关键点检测精度高，<a href="mailto:&#x50;&#x44;&#x4a;&#64;&#48;&#46;&#50;">&#x50;&#x44;&#x4a;&#64;&#48;&#46;&#50;</a>&#x3D;94.31%；三、3D姿态估计精度低，MAE&#x3D;11.38o和9.93o。此外，该方法能够适应视点变化，但 canonical和高视点视角表现略高一些。该方法可以应用于其他greenhouse作物，如辣椒。<details>
<summary>Abstract</summary>
Greenhouse production of fruits and vegetables in developed countries is challenged by labor 12 scarcity and high labor costs. Robots offer a good solution for sustainable and cost-effective 13 production. Acquiring accurate spatial information about relevant plant parts is vital for 14 successful robot operation. Robot perception in greenhouses is challenging due to variations in 15 plant appearance, viewpoints, and illumination. This paper proposes a keypoint-detection-based 16 method using data from an RGB-D camera to estimate the 3D pose of peduncle nodes, which 17 provides essential information to harvest the tomato bunches. 18 19 Specifically, this paper proposes a method that detects four anatomical landmarks in the color 20 image and then integrates 3D point-cloud information to determine the 3D pose. A 21 comprehensive evaluation was conducted in a commercial greenhouse to gain insight into the 22 performance of different parts of the method. The results showed: (1) high accuracy in object 23 detection, achieving an Average Precision (AP) of AP@0.5=0.96; (2) an average Percentage of 24 Detected Joints (PDJ) of the keypoints of PhDJ@0.2=94.31%; and (3) 3D pose estimation 25 accuracy with mean absolute errors (MAE) of 11.38o and 9.93o for the relative upper and lower 26 angles between the peduncle and main stem, respectively. Furthermore, the capability to handle 27 variations in viewpoint was investigated, demonstrating the method was robust to view changes. 28 However, canonical and higher views resulted in slightly higher performance compared to other 29 views. Although tomato was selected as a use case, the proposed method is also applicable to 30 other greenhouse crops like pepper.
</details>
<details>
<summary>摘要</summary>
developed countries 的greenhouse production of fruits and vegetables 面临劳动力短缺和高成本问题。Robots 提供了一个可持续和经济的解决方案。获取有关重要植物部分的准确空间信息是成功Robot操作的关键。在greenhouse中Robot感知是因植物外观、视角和照明变化而具有挑战性。这篇文章提出了基于颜色图像中的关键点检测方法，使用RGB-D摄像头获取 Tomatoes 的3D姿态。具体来说，这篇文章将在颜色图像中检测四个 анатомиче特征点，然后将3D点云信息与颜色图像进行集成，以确定 Tomatoes 的3D姿态。进行了在商业greenhouse中广泛的评估，以获得不同方法部分的性能评估结果。结果显示：1. 对象检测精度高，AP@0.5=0.96;2. 平均关节检测精度（PDJ）为94.31%;3. 3D姿态估计精度（MAE）为11.38°和9.93°。此外，文章还 investigate了视角变化的影响，并证明方法具有视角变化的Robustness。although Tomato 是使用case，提出的方法还适用于其他greenhouse 作物如辣椒。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-cross-model-learning-in-high-content-screening"><a href="#Weakly-supervised-cross-model-learning-in-high-content-screening" class="headerlink" title="Weakly supervised cross-model learning in high-content screening"></a>Weakly supervised cross-model learning in high-content screening</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04678">http://arxiv.org/abs/2311.04678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Watkinson Gabriel, Cohen Ethan, Bourriez Nicolas, Bendidi Ihab, Bollot Guillaume, Genovesio Auguste</li>
<li>for: 这个研究旨在搭桥不同类型的数据，以便在药物探索中更好地利用各种数据来源。</li>
<li>methods: 本研究提出了一个新的方法，使用CLIP建立跨模式表示，并使用弱监督和跨站重复来验证。</li>
<li>results: 比较知名的基eline，我们的提案方法可以学习更好的表示，帮助减少批次效应。此外，我们还提出了一种适合JUMP-CP dataset的预处理方法，从85Tb减少到7Tb，保留所有干扰和大部分资讯内容。<details>
<summary>Abstract</summary>
With the surge in available data from various modalities, there is a growing need to bridge the gap between different data types. In this work, we introduce a novel approach to learn cross-modal representations between image data and molecular representations for drug discovery. We propose EMM and IMM, two innovative loss functions built on top of CLIP that leverage weak supervision and cross sites replicates in High-Content Screening. Evaluating our model against known baseline on cross-modal retrieval, we show that our proposed approach allows to learn better representations and mitigate batch effect. In addition, we also present a preprocessing method for the JUMP-CP dataset that effectively reduce the required space from 85Tb to a mere usable 7Tb size, still retaining all perturbations and most of the information content.
</details>
<details>
<summary>摘要</summary>
随着不同数据模式的数据量的增加，需要桥渡不同数据类型之间的 gap。在这项工作中，我们介绍了一种新的方法，用于在图像数据和分子表示之间学习交叉模式表示。我们提出了两种创新的损失函数：EMM和IMM，它们基于CLIP且利用弱监督和跨站复制在高内容检测中。我们评估了我们的模型与已知基eline之间的交叉模式检索，并显示了我们的提议方法可以学习更好的表示，并减轻批处效应。此外，我们还提出了对JUMP-CP数据集的预处理方法，可以将85Tb的数据减少到7Tb的可用大小，保留所有干扰和大部分信息内容。
</details></li>
</ul>
<hr>
<h2 id="VET-Visual-Error-Tomography-for-Point-Cloud-Completion-and-High-Quality-Neural-Rendering"><a href="#VET-Visual-Error-Tomography-for-Point-Cloud-Completion-and-High-Quality-Neural-Rendering" class="headerlink" title="VET: Visual Error Tomography for Point Cloud Completion and High-Quality Neural Rendering"></a>VET: Visual Error Tomography for Point Cloud Completion and High-Quality Neural Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04634">http://arxiv.org/abs/2311.04634</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lfranke/vet">https://github.com/lfranke/vet</a></li>
<li>paper_authors: Linus Franke, Darius Rückert, Laura Fink, Matthias Innmann, Marc Stamminger</li>
<li>for: 提高点云 Synthesize 质量</li>
<li>methods: 使用点云 Rendering 和 Visual Error Tomography (VET) 技术</li>
<li>results: 可以提高点云 Synthesize 质量，fix 大规模坑洞和缺失细长结构，并且可以在实时帧率下进行 Rendering，舒适性得到了显著改善。<details>
<summary>Abstract</summary>
In the last few years, deep neural networks opened the doors for big advances in novel view synthesis. Many of these approaches are based on a (coarse) proxy geometry obtained by structure from motion algorithms. Small deficiencies in this proxy can be fixed by neural rendering, but larger holes or missing parts, as they commonly appear for thin structures or for glossy regions, still lead to distracting artifacts and temporal instability. In this paper, we present a novel neural-rendering-based approach to detect and fix such deficiencies. As a proxy, we use a point cloud, which allows us to easily remove outlier geometry and to fill in missing geometry without complicated topological operations. Keys to our approach are (i) a differentiable, blending point-based renderer that can blend out redundant points, as well as (ii) the concept of Visual Error Tomography (VET), which allows us to lift 2D error maps to identify 3D-regions lacking geometry and to spawn novel points accordingly. Furthermore, (iii) by adding points as nested environment maps, our approach allows us to generate high-quality renderings of the surroundings in the same pipeline. In our results, we show that our approach can improve the quality of a point cloud obtained by structure from motion and thus increase novel view synthesis quality significantly. In contrast to point growing techniques, the approach can also fix large-scale holes and missing thin structures effectively. Rendering quality outperforms state-of-the-art methods and temporal stability is significantly improved, while rendering is possible at real-time frame rates.
</details>
<details>
<summary>摘要</summary>
最近几年，深度神经网络开启了新视角合成的大进步。许多这些方法基于结构从运动算法获得的（粗糙）代理几何。小落差在这个代理上可以通过神经渲染修复，但更大的孔隙或缺失部分，如随着精细结构或光滑区域，仍会导致干扰 artifacts 和时间不稳定。在这篇论文中，我们提出了一种基于神经渲染的新方法，用于检测和修复这些落差。作为代理，我们使用点云，这使得我们可以轻松地移除点云中的异常 geometry 并填充缺失 geometry 而无需复杂的 topological 操作。我们方法的关键是：1. 可导的点云渲染器，可以将重复的点消除掉，以及2. 视觉错误板准（VET）的概念，允许我们将2D 错误地图提升到3D 空间中，以识别缺失 geometry 并生成新的点。3. 通过添加点作为嵌入环境图，我们的方法可以在同一个管道中生成高质量的周围 renderings。在我们的结果中，我们发现我们的方法可以提高由结构从运动算法获得的点云质量，从而提高新视角合成质量。与点生长技术相比，我们的方法可以更有效地修复大规模孔隙和缺失细腻结构。rendering 质量超出了状态机器人方法，同时实现了实时帧率。
</details></li>
</ul>
<hr>
<h2 id="General-Framework-to-Evaluate-Unlinkability-in-Biometric-Template-Protection-Systems"><a href="#General-Framework-to-Evaluate-Unlinkability-in-Biometric-Template-Protection-Systems" class="headerlink" title="General Framework to Evaluate Unlinkability in Biometric Template Protection Systems"></a>General Framework to Evaluate Unlinkability in Biometric Template Protection Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04633">http://arxiv.org/abs/2311.04633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marta Gomez-Barrero, Javier Galbally, Christian Rathgeb, Christoph Busch<br>for: 本研究旨在提供一种系统性的评估生物特征模板保护技术的不可逆性和分识性的框架。methods: 本研究使用了一种新的框架来评估生物特征模板保护技术的不可逆性和分识性。这种框架包括了四个州chart下的生物特征模板保护技术的评估：生物盐、Bloom filter、同构加密和块重新映射。results: 研究发现，使用了提议的框架来评估生物特征模板保护技术的不可逆性和分识性，可以帮助更好地了解这些技术的性能。特别是，对块重新映射技术的评估表明，提议的方法在其他现有的度量方法中具有优势。<details>
<summary>Abstract</summary>
The wide deployment of biometric recognition systems in the last two decades has raised privacy concerns regarding the storage and use of biometric data. As a consequence, the ISO/IEC 24745 international standard on biometric information protection has established two main requirements for protecting biometric templates: irreversibility and unlinkability. Numerous efforts have been directed to the development and analysis of irreversible templates. However, there is still no systematic quantitative manner to analyse the unlinkability of such templates. In this paper we address this shortcoming by proposing a new general framework for the evaluation of biometric templates' unlinkability. To illustrate the potential of the approach, it is applied to assess the unlinkability of four state-of-the-art techniques for biometric template protection: biometric salting, Bloom filters, Homomorphic Encryption and block re-mapping. For the last technique, the proposed framework is compared with other existing metrics to show its advantages.
</details>
<details>
<summary>摘要</summary>
在过去二十年中，生物认证系统的广泛部署已引起了隐私问题的存储和使用生物特征数据。因此，ISO/IEC 24745国际标准 для生物特征信息保护确立了两个主要要求：不可逆和不可关联。许多努力已经专注于不可逆模板的开发和分析。然而，目前还没有系统化的量化方法来分析不可关联模板。在这篇论文中，我们解决了这个缺陷，提出了一个新的通用框架来评估生物模板的不可关联性。为了证明方法的潜力，我们对四种现状顶尖技术进行了生物模板保护的评估：生物盐、Bloom滤波、同时加密和块重映射。对于最后一种技术，我们的框架与其他现有的指标进行了比较，以显示其优势。
</details></li>
</ul>
<hr>
<h2 id="Image-Patch-Matching-with-Graph-Based-Learning-in-Street-Scenes"><a href="#Image-Patch-Matching-with-Graph-Based-Learning-in-Street-Scenes" class="headerlink" title="Image Patch-Matching with Graph-Based Learning in Street Scenes"></a>Image Patch-Matching with Graph-Based Learning in Street Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04617">http://arxiv.org/abs/2311.04617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui She, Qiyu Kang, Sijie Wang, Wee Peng Tay, Yong Liang Guan, Diego Navarro Navarro, Andreas Hartmannsgruber</li>
<li>for: 本文主要用于提高自动驾驶计算机视觉任务中的匹配性能。</li>
<li>methods: 本文提出了一种基于图学习的 JOINT 特征和度量学习模型，利用图structure capture了图像区域之间的空间相互关系。</li>
<li>results: 对多个街景数据集进行评估，表明我们的方法可以达到当前最佳匹配效果。<details>
<summary>Abstract</summary>
Matching landmark patches from a real-time image captured by an on-vehicle camera with landmark patches in an image database plays an important role in various computer perception tasks for autonomous driving. Current methods focus on local matching for regions of interest and do not take into account spatial neighborhood relationships among the image patches, which typically correspond to objects in the environment. In this paper, we construct a spatial graph with the graph vertices corresponding to patches and edges capturing the spatial neighborhood information. We propose a joint feature and metric learning model with graph-based learning. We provide a theoretical basis for the graph-based loss by showing that the information distance between the distributions conditioned on matched and unmatched pairs is maximized under our framework. We evaluate our model using several street-scene datasets and demonstrate that our approach achieves state-of-the-art matching results.
</details>
<details>
<summary>摘要</summary>
Current methods focus on local matching for regions of interest and do not take into account spatial neighborhood relationships among the image patches, which typically correspond to objects in the environment. In this paper, we construct a spatial graph with the graph vertices corresponding to patches and edges capturing the spatial neighborhood information. We propose a joint feature and metric learning model with graph-based learning. We provide a theoretical basis for the graph-based loss by showing that the information distance between the distributions conditioned on matched and unmatched pairs is maximized under our framework. We evaluate our model using several street-scene datasets and demonstrate that our approach achieves state-of-the-art matching results.Here's the translation in Traditional Chinese:现有的方法仅专注于区域 interess 的本地匹配，而不考虑图像块之间的空间邻居关系，通常是环境中的物体。在这篇文章中，我们建立了一个空间图，其顶点对应图像块，并通过空间邻居信息来连接顶点。我们提出了一个共同特征和距离学习模型，并基于图形学习。我们提供了图形基础下的损失函数的理论基础，详细说明了在我们的框架下，匹配的信息距离between matched和unmatched pairs的最大化。我们使用了多个街景数据集进行评估，并证明了我们的方法可以实现顶尖匹配结果。
</details></li>
</ul>
<hr>
<h2 id="On-Characterizing-the-Evolution-of-Embedding-Space-of-Neural-Networks-using-Algebraic-Topology"><a href="#On-Characterizing-the-Evolution-of-Embedding-Space-of-Neural-Networks-using-Algebraic-Topology" class="headerlink" title="On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology"></a>On Characterizing the Evolution of Embedding Space of Neural Networks using Algebraic Topology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04592">http://arxiv.org/abs/2311.04592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cross-caps/dnntopology">https://github.com/cross-caps/dnntopology</a></li>
<li>paper_authors: Suryaka Suresh, Bishshoy Das, Vinayak Abrol, Sumantra Dutta Roy</li>
<li>for: 研究深度神经网络（DNN）中特征表示空间的topology如何随层数变化，通过Betti数来量化。</li>
<li>methods: 使用Cubical homology对各种流行深度网络和实际图像数据进行扩展分析。</li>
<li>results: 随着depth层数的增加，复杂的特征表示空间变为简单的空间，Betti数达到最低值。这个过程中的复杂性衰减率可以衡量不同架构的泛化能力。此外，我们还发现了一些不变性，如（1）同类 dataset上不同架构的 topological invariance;（2） embedding space中的数据尺寸&#x2F;分辨率不变性;（3） embedding space到输入尺寸&#x2F;分辨率的不变性，以及（4）数据采样不变性。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
We study how the topology of feature embedding space changes as it passes through the layers of a well-trained deep neural network (DNN) through Betti numbers. Motivated by existing studies using simplicial complexes on shallow fully connected networks (FCN), we present an extended analysis using Cubical homology instead, with a variety of popular deep architectures and real image datasets. We demonstrate that as depth increases, a topologically complicated dataset is transformed into a simple one, resulting in Betti numbers attaining their lowest possible value. The rate of decay in topological complexity (as a metric) helps quantify the impact of architectural choices on the generalization ability. Interestingly from a representation learning perspective, we highlight several invariances such as topological invariance of (1) an architecture on similar datasets; (2) embedding space of a dataset for architectures of variable depth; (3) embedding space to input resolution/size, and (4) data sub-sampling. In order to further demonstrate the link between expressivity \& the generalization capability of a network, we consider the task of ranking pre-trained models for downstream classification task (transfer learning). Compared to existing approaches, the proposed metric has a better correlation to the actually achievable accuracy via fine-tuning the pre-trained model.
</details>
<details>
<summary>摘要</summary>
我们研究了深度神经网络（DNN）中层次结构的变化，通过瓶颈数学（Betti numbers）来量化。受激发于先前使用简单的全连接网络（FCN）的研究，我们在不同的深度和实际图像数据集上进行了扩展分析，并示出了随depth增加而导致数据空间的topologically complicated转变为简单的现象。这种转变导致Betti numbers achieves its lowest possible value，这也是一个度量化深度神经网络的泛化能力的重要指标。从表示学学习的角度来看，我们发现了一些对称性，包括：1. 不同dataset上的同一个架构具有类似的topological invariance。2. 具有不同深度的架构的 embedding space 在不同dataset上具有相同的topological invariance。3. embedding space 对于不同的input resolution/size具有 topological invariance。4. 数据采样的对称性。为了进一步证明深度神经网络的表达能力和泛化能力之间的关系，我们考虑了将预训练模型排名为下游分类任务（转移学习）。与现有方法相比，我们的指标具有更好的与实际可 achievable accuracy 的相关性。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Event-based-Human-Pose-Estimation-with-3D-Event-Representations"><a href="#Rethinking-Event-based-Human-Pose-Estimation-with-3D-Event-Representations" class="headerlink" title="Rethinking Event-based Human Pose Estimation with 3D Event Representations"></a>Rethinking Event-based Human Pose Estimation with 3D Event Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04591">http://arxiv.org/abs/2311.04591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/masterhow/eventpointpose">https://github.com/masterhow/eventpointpose</a></li>
<li>paper_authors: Xiaoting Yin, Hao Shi, Jiaan Chen, Ze Wang, Yaozu Ye, Huajian Ni, Kailun Yang, Kaiwei Wang</li>
<li>for: 本研究旨在提高自动驾驶和停车安全性，通过人体动作预测。</li>
<li>methods: 该研究使用事件摄像头，并开发了两种3D事件表示方法：Rasterized Event Point Cloud (RasEPC) 和 Decoupled Event Voxel (DEV)。</li>
<li>results: 研究发现，使用事件点云方法可以在实时移动预测中取得优秀表现，而使用分离事件矩阵方法可以获得最高准确率。实验表明，提posed的3D表示方法在对传统RGB图像和事件帧技术进行比较时具有更高的总体化能力。<details>
<summary>Abstract</summary>
Human pose estimation is a critical component in autonomous driving and parking, enhancing safety by predicting human actions. Traditional frame-based cameras and videos are commonly applied, yet, they become less reliable in scenarios under high dynamic range or heavy motion blur. In contrast, event cameras offer a robust solution for navigating these challenging contexts. Predominant methodologies incorporate event cameras into learning frameworks by accumulating events into event frames. However, such methods tend to marginalize the intrinsic asynchronous and high temporal resolution characteristics of events. This disregard leads to a loss in essential temporal dimension data, crucial for safety-critical tasks associated with dynamic human activities. To address this issue and to unlock the 3D potential of event information, we introduce two 3D event representations: the Rasterized Event Point Cloud (RasEPC) and the Decoupled Event Voxel (DEV). The RasEPC collates events within concise temporal slices at identical positions, preserving 3D attributes with statistical cues and markedly mitigating memory and computational demands. Meanwhile, the DEV representation discretizes events into voxels and projects them across three orthogonal planes, utilizing decoupled event attention to retrieve 3D cues from the 2D planes. Furthermore, we develop and release EV-3DPW, a synthetic event-based dataset crafted to facilitate training and quantitative analysis in outdoor scenes. On the public real-world DHP19 dataset, our event point cloud technique excels in real-time mobile predictions, while the decoupled event voxel method achieves the highest accuracy. Experiments reveal our proposed 3D representation methods' superior generalization capacities against traditional RGB images and event frame techniques. Our code and dataset are available at https://github.com/MasterHow/EventPointPose.
</details>
<details>
<summary>摘要</summary>
人体姿态估计是自动驾驶和停车中的关键组件，提高安全性 by 预测人类动作。传统的帧基camera和视频通常应用，但在高动态范围或重重运动抑制下变得不可靠。相比之下，事件摄像头提供了一种可靠的解决方案。大多数方法将事件摄像头集成到学习框架中，但这些方法通常忽略事件的本质异步和高时间分辨率特性，导致数据损失。为解决这个问题，我们介绍了两种3D事件表示方法：分割事件点云（RasEPC）和解决事件立方体（DEV）。RasEPC将事件集中在同一个时间位置内，保留3D特征参数，并remarkably减少内存和计算负担。DEV表示方法将事件分解为立方体，并在三个正交平面上 проек，使用解决事件注意力来检索3D准确性。此外，我们开发了EV-3DPWSynthetic事件基于数据集，用于训练和量化分析。在公共实际世界DHP19数据集上，我们的事件点云技术在实时移动预测中表现出色，而DEV表示方法在准确性方面达到了最高水平。实验表明我们的提posed 3D表示方法在传统RGB图像和事件帧技术上有superior的总体化能力。我们的代码和数据集可以在https://github.com/MasterHow/EventPointPose上获取。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-deepfake-localization-in-diffusion-generated-images"><a href="#Weakly-supervised-deepfake-localization-in-diffusion-generated-images" class="headerlink" title="Weakly-supervised deepfake localization in diffusion-generated images"></a>Weakly-supervised deepfake localization in diffusion-generated images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04584">http://arxiv.org/abs/2311.04584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dragos Tantaru, Elisabeta Oneata, Dan Oneata<br>for: 这个论文的目的是提出一种弱监督的图像假象检测方法，以提供更加具有信息的输出，包括图像假象的地方化映射。methods: 这个论文使用的方法包括基于解释、本地分数和注意力的三类方法，并且使用Xception网络作为共同背景 arquitectura。results: 研究结果显示，弱监督的图像假象检测是可能的，并且使用本地分数的方法比其他两类方法更为敏感于监督质量，而不是 dataset 或 generator 的不同。<details>
<summary>Abstract</summary>
The remarkable generative capabilities of denoising diffusion models have raised new concerns regarding the authenticity of the images we see every day on the Internet. However, the vast majority of existing deepfake detection models are tested against previous generative approaches (e.g. GAN) and usually provide only a "fake" or "real" label per image. We believe a more informative output would be to augment the per-image label with a localization map indicating which regions of the input have been manipulated. To this end, we frame this task as a weakly-supervised localization problem and identify three main categories of methods (based on either explanations, local scores or attention), which we compare on an equal footing by using the Xception network as the common backbone architecture. We provide a careful analysis of all the main factors that parameterize the design space: choice of method, type of supervision, dataset and generator used in the creation of manipulated images; our study is enabled by constructing datasets in which only one of the components is varied. Our results show that weakly-supervised localization is attainable, with the best performing detection method (based on local scores) being less sensitive to the looser supervision than to the mismatch in terms of dataset or generator.
</details>
<details>
<summary>摘要</summary>
“denoising扩散模型的杰出生成能力已经引起了网络上每天见到的图像真实性的新忧虑。然而，现有的深圳检测模型大多是根据先前的生成方法（如GAN）进行测试，通常只会提供每个图像的“伪”或“真”标签。我们认为，更有用的输出将是附加每个图像的地方几何映射，以指示哪些输入区域被修改。为了实现这一目标，我们将这个任务描述为一个弱监督的地方化推导问题，并分别找出三种方法（基于解释、本地分数或注意力），并使用Xception网络作为共同背景架构。我们对所有主要设计空间的因素进行了谨慎的分析：方法选择、监督方式、数据集和生成器。我们的研究受惠于将单一的元素变化为多个数据集。我们的结果显示，弱监督的地方化推导是可能的，并且基于本地分数的检测方法比较不敏感于监督质量的变化，也比较不敏感于数据集或生成器的差异。”
</details></li>
</ul>
<hr>
<h2 id="A-3D-generative-model-of-pathological-multi-modal-MR-images-and-segmentations"><a href="#A-3D-generative-model-of-pathological-multi-modal-MR-images-and-segmentations" class="headerlink" title="A 3D generative model of pathological multi-modal MR images and segmentations"></a>A 3D generative model of pathological multi-modal MR images and segmentations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04552">http://arxiv.org/abs/2311.04552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/virginiafdez/brainspade3d_rel">https://github.com/virginiafdez/brainspade3d_rel</a></li>
<li>paper_authors: Virginia Fernandez, Walter Hugo Lopez Pinaya, Pedro Borges, Mark S. Graham, Tom Vercauteren, M. Jorge Cardoso</li>
<li>for: 本研究旨在提供一种基于生成器的3D磁共振成像（MRI）和相关的分割数据，用于训练具有高特异性的深度学习模型，并可以根据具体的疾病现象和对比进行 conditioning。</li>
<li>methods: 本研究使用的是生成对抗网络（GANs）和扩散模型（DMs），并实现了对核磁共振成像（MRI）和相关的分割数据的生成。用户可以通过Specifying pathological phenotypes and contrasts来控制生成的图像和分割数据的内容和对比。</li>
<li>results: 本研究的实验结果表明，brainSPADE3D可以生成高品质的Synthetic MRI和相关的分割数据，并且可以同时捕捉多种疾病现象。此外，brainSPADE3D还可以提高分割模型的性能，并且可以适应不计划的疾病现象。<details>
<summary>Abstract</summary>
Generative modelling and synthetic data can be a surrogate for real medical imaging datasets, whose scarcity and difficulty to share can be a nuisance when delivering accurate deep learning models for healthcare applications. In recent years, there has been an increased interest in using these models for data augmentation and synthetic data sharing, using architectures such as generative adversarial networks (GANs) or diffusion models (DMs). Nonetheless, the application of synthetic data to tasks such as 3D magnetic resonance imaging (MRI) segmentation remains limited due to the lack of labels associated with the generated images. Moreover, many of the proposed generative MRI models lack the ability to generate arbitrary modalities due to the absence of explicit contrast conditioning. These limitations prevent the user from adjusting the contrast and content of the images and obtaining more generalisable data for training task-specific models. In this work, we propose brainSPADE3D, a 3D generative model for brain MRI and associated segmentations, where the user can condition on specific pathological phenotypes and contrasts. The proposed joint imaging-segmentation generative model is shown to generate high-fidelity synthetic images and associated segmentations, with the ability to combine pathologies. We demonstrate how the model can alleviate issues with segmentation model performance when unexpected pathologies are present in the data.
</details>
<details>
<summary>摘要</summary>
生成模型和 sintetic 数据可以作为实际医疗影像数据的代理，解决医疗应用中深度学习模型的准确性问题。过去几年，有越来越多的人们关注使用这些模型进行数据增强和 sintetic 数据共享，使用生成对抗网络（GANs）或扩散模型（DMs）等建筑。然而，在应用 sintetic 数据进行3D磁共振成像（MRI）分割任务时，还是有一些限制，主要是生成图像无标签，以及生成图像不能按照用户需求进行调整。此外，许多已经提出的生成MRI模型无法生成多个模式，因为缺少显式对比条件。这些限制使得用户无法根据任务需求进行图像的调整和对比，从而获得更加普适的数据。在这项工作中，我们提出了brainSPADE3D，一种3D生成模型，用于脑MRI和相关的分割。用户可以根据特定的疾病现象和对比条件来conditioning。我们的结合成像和分割生成模型能够生成高质量的 sintetic 图像和相关的分割，并且可以组合疾病。我们示示了该模型如何解决预期疾病存在于数据时，影响分割模型性能的问题。
</details></li>
</ul>
<hr>
<h2 id="Learning-Robust-Multi-Scale-Representation-for-Neural-Radiance-Fields-from-Unposed-Images"><a href="#Learning-Robust-Multi-Scale-Representation-for-Neural-Radiance-Fields-from-Unposed-Images" class="headerlink" title="Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images"></a>Learning Robust Multi-Scale Representation for Neural Radiance Fields from Unposed Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04521">http://arxiv.org/abs/2311.04521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nishant Jain, Suryansh Kumar, Luc Van Gool<br>for: 这个论文旨在解决计算机视觉中的神经图像基于渲染问题，即从一个自由移动的摄像头 captured 的图像集中生成一个真实的场景图像，并且在测试时使用。methods: 该论文使用了以下方法：1. 使用 robust pipeline  recuperate 摄像头参数，以确保在神经图像基于渲染问题中准确地synthesize 场景图像。2. 使用多尺度神经场景表示，以处理对象内容的不同分辨率。3. 使用单个图像深度预测，以估计图像中对象的深度。results: 该论文的结果表明，在不考虑 Camera 参数估计的情况下，模型对象内容的多尺度神经场景表示可能会导致模型缺失精度。而通过在Scene 理论基础之上引入 Camera 参数估计，可以提高模型的精度。例如，通过使用多个视图图像，可以在测试时Synthesize 一个真实的场景图像。<details>
<summary>Abstract</summary>
We introduce an improved solution to the neural image-based rendering problem in computer vision. Given a set of images taken from a freely moving camera at train time, the proposed approach could synthesize a realistic image of the scene from a novel viewpoint at test time. The key ideas presented in this paper are (i) Recovering accurate camera parameters via a robust pipeline from unposed day-to-day images is equally crucial in neural novel view synthesis problem; (ii) It is rather more practical to model object's content at different resolutions since dramatic camera motion is highly likely in day-to-day unposed images. To incorporate the key ideas, we leverage the fundamentals of scene rigidity, multi-scale neural scene representation, and single-image depth prediction. Concretely, the proposed approach makes the camera parameters as learnable in a neural fields-based modeling framework. By assuming per view depth prediction is given up to scale, we constrain the relative pose between successive frames. From the relative poses, absolute camera pose estimation is modeled via a graph-neural network-based multiple motion averaging within the multi-scale neural-fields network, leading to a single loss function. Optimizing the introduced loss function provides camera intrinsic, extrinsic, and image rendering from unposed images. We demonstrate, with examples, that for a unified framework to accurately model multiscale neural scene representation from day-to-day acquired unposed multi-view images, it is equally essential to have precise camera-pose estimates within the scene representation framework. Without considering robustness measures in the camera pose estimation pipeline, modeling for multi-scale aliasing artifacts can be counterproductive. We present extensive experiments on several benchmark datasets to demonstrate the suitability of our approach.
</details>
<details>
<summary>摘要</summary>
我们提出了一种改进的解决方案 для计算机视觉中的神经图像基于渲染问题。给定一组由自由移动相机在训练时拍摄的图像，我们的方法可以在测试时生成出真实的图像场景从一个新的视点。我们的关键想法是：（i）在不带pose的日常图像中恢复高精度相机参数，是神经novel view sintesis问题的关键因素。（ii）因为日常不带pose图像中的相机运动可能很剧烈，因此更加实用地模型对象的内容在不同分辨率上。为了激活这两个想法，我们利用场景刚性、多尺度神经场景表示和单个图像深度预测的基础知识。具体来说，我们将相机参数作为神经场景中的学习参数。通过假设每个视图的深度预测在某种程度上是固定的，我们使用图像之间的相对pose进行多个运动平均，从而模型维度的相机pose估计。通过这种方式，我们可以从日常不带pose图像中恢复相机参数，并同时实现图像渲染。我们通过多个实验证明，在不忽视 robustness measure的情况下，模型多尺度神经场景表示是不可避免的。我们的方法可以在多个标准 datasets上进行广泛的实验，以证明我们的方法的适用性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Discriminative-Features-for-Crowd-Counting"><a href="#Learning-Discriminative-Features-for-Crowd-Counting" class="headerlink" title="Learning Discriminative Features for Crowd Counting"></a>Learning Discriminative Features for Crowd Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04509">http://arxiv.org/abs/2311.04509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuehai Chen</li>
<li>for: 提高人群计数模型在高度拥挤的区域中的准确性</li>
<li>methods: 提出了一种学习权重特征框架，包括遮盖特征预测模块（MPM）和监督像素级对比学习模块（CLM）</li>
<li>results: 实现了提高人群计数模型的准确性，并可以应用于其他计算机视觉任务，如人群计数和物体检测，在高度拥挤的环境下提高了模型的性能<details>
<summary>Abstract</summary>
Crowd counting models in highly congested areas confront two main challenges: weak localization ability and difficulty in differentiating between foreground and background, leading to inaccurate estimations. The reason is that objects in highly congested areas are normally small and high-level features extracted by convolutional neural networks are less discriminative to represent small objects. To address these problems, we propose a learning discriminative features framework for crowd counting, which is composed of a masked feature prediction module (MPM) and a supervised pixel-level contrastive learning module (CLM). The MPM randomly masks feature vectors in the feature map and then reconstructs them, allowing the model to learn about what is present in the masked regions and improving the model's ability to localize objects in high-density regions. The CLM pulls targets close to each other and pushes them far away from background in the feature space, enabling the model to discriminate foreground objects from background. Additionally, the proposed modules can be beneficial in various computer vision tasks, such as crowd counting and object detection, where dense scenes or cluttered environments pose challenges to accurate localization. The proposed two modules are plug-and-play, incorporating the proposed modules into existing models can potentially boost their performance in these scenarios.
</details>
<details>
<summary>摘要</summary>
人群计数模型在高度拥堵的区域面临两大挑战：一是局部化能力弱和对背景和前景分化不具有分辨力，导致估计不准确。这是因为在高度拥堵的区域中，物体通常是小型，高级特征提取网络的特征更难以表示小型物体。为解决这些问题，我们提出了一种学习特征分布框架 для人群计数，该框架包括偏挥特征预测模块（MPM）和监督像素级对比学习模块（CLM）。MPM模块随机屏蔽特征向量在特征地图中，然后重建它们，使模型能够学习面积内的物体存在的地方，提高模型的局部化能力。CLM模块将目标紧挨着并将它们与背景分离开来，使模型能够在特征空间中分辨前景和背景。此外，我们提出的两个模块可以在各种计算机视觉任务中有助于提高精度，如人群计数和物体检测，在拥堵的环境下面临精度下降的挑战。我们的两个模块可以与现有模型集成，可能提高其性能在这些场景中。
</details></li>
</ul>
<hr>
<h2 id="NITEC-Versatile-Hand-Annotated-Eye-Contact-Dataset-for-Ego-Vision-Interaction"><a href="#NITEC-Versatile-Hand-Annotated-Eye-Contact-Dataset-for-Ego-Vision-Interaction" class="headerlink" title="NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction"></a>NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04505">http://arxiv.org/abs/2311.04505</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thorsten Hempel, Magnus Jung, Ahmed A. Abdelrahman, Ayoub Al-Hamadi</li>
<li>for: 本研究的目的是提供一个大型、多样化的人egoscopic eye contact dataset，以便进一步推进人机交互、计算机视觉和社交机器人等领域的研究。</li>
<li>methods: 本研究使用了人工精心标注的方法，将许多不同的人类表情、社会情境和照明条件 integrate into dataset，以满足不同场景下的研究需求。</li>
<li>results: 研究者通过广泛的评估表明，NITEC dataset在多种场景下具有强大的横跨数据集性能，表明其适用性和可重用性在计算机视觉、人机交互和社交机器人等领域。<details>
<summary>Abstract</summary>
Eye contact is a crucial non-verbal interaction modality and plays an important role in our everyday social life. While humans are very sensitive to eye contact, the capabilities of machines to capture a person's gaze are still mediocre. We tackle this challenge and present NITEC, a hand-annotated eye contact dataset for ego-vision interaction. NITEC exceeds existing datasets for ego-vision eye contact in size and variety of demographics, social contexts, and lighting conditions, making it a valuable resource for advancing ego-vision-based eye contact research. Our extensive evaluations on NITEC demonstrate strong cross-dataset performance, emphasizing its effectiveness and adaptability in various scenarios, that allows seamless utilization to the fields of computer vision, human-computer interaction, and social robotics. We make our NITEC dataset publicly available to foster reproducibility and further exploration in the field of ego-vision interaction. https://github.com/thohemp/nitec
</details>
<details>
<summary>摘要</summary>
眼接触是非言语交互模式中的重要一环，在我们每天社交生活中扮演着重要的角色。然而，机器人的眼接触捕捉能力仍然较差。我们解决这个挑战，并提供了NITEC数据集，这是一个手动注释的眼接触数据集，用于EGO视觉交互。NITEC的数据集比现有的EGO视觉眼接触数据集更大，包括更多的人种、社会背景、照明条件等，这使得它成为了EGO视觉交互领域的价值质量资源。我们对NITEC数据集进行了广泛的评估，并证明了其适用性和可变性在各种场景中，这使得它可以轻松地应用于计算机视觉、人机交互和社交机器人等领域。我们将NITEC数据集公开发布，以便促进复现性和进一步的探索在EGO视觉交互领域。更多信息请访问<https://github.com/thohemp/nitec>。
</details></li>
</ul>
<hr>
<h2 id="PRED-Pre-training-via-Semantic-Rendering-on-LiDAR-Point-Clouds"><a href="#PRED-Pre-training-via-Semantic-Rendering-on-LiDAR-Point-Clouds" class="headerlink" title="PRED: Pre-training via Semantic Rendering on LiDAR Point Clouds"></a>PRED: Pre-training via Semantic Rendering on LiDAR Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04501">http://arxiv.org/abs/2311.04501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Yang, Haiyang Wang, Di Dai, Liwei Wang</li>
<li>for: This paper is written for improving point cloud pre-training in outdoor scenarios, addressing the issue of incompleteness by incorporating images and leveraging semantic information.</li>
<li>methods: The proposed method, PRED, uses a Birds-Eye-View (BEV) feature map conditioned semantic rendering to supervise the pre-training process, and incorporates point-wise masking with a high mask ratio (95%) to enhance performance.</li>
<li>results: The paper demonstrates significant improvements over prior point cloud pre-training methods on various large-scale datasets for 3D perception tasks, providing a superior framework for outdoor point cloud pre-training.<details>
<summary>Abstract</summary>
Pre-training is crucial in 3D-related fields such as autonomous driving where point cloud annotation is costly and challenging. Many recent studies on point cloud pre-training, however, have overlooked the issue of incompleteness, where only a fraction of the points are captured by LiDAR, leading to ambiguity during the training phase. On the other hand, images offer more comprehensive information and richer semantics that can bolster point cloud encoders in addressing the incompleteness issue inherent in point clouds. Yet, incorporating images into point cloud pre-training presents its own challenges due to occlusions, potentially causing misalignments between points and pixels. In this work, we propose PRED, a novel image-assisted pre-training framework for outdoor point clouds in an occlusion-aware manner. The main ingredient of our framework is a Birds-Eye-View (BEV) feature map conditioned semantic rendering, leveraging the semantics of images for supervision through neural rendering. We further enhance our model's performance by incorporating point-wise masking with a high mask ratio (95%). Extensive experiments demonstrate PRED's superiority over prior point cloud pre-training methods, providing significant improvements on various large-scale datasets for 3D perception tasks. Codes will be available at https://github.com/PRED4pc/PRED.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>在3D相关领域中，如自动驾驶，点云注解是昂贵而困难的。许多最近的点云预训练研究，然而，忽略了 incomplete 问题，只有一部分点云被 LiDAR 捕获，导致训练阶段的混淆。然而，图像具有更全面的信息和更丰富的 semantics，可以增强点云编码器对 incomplete 问题的应对。然而，将图像 incorporated 到点云预训练中又存在遮挡问题，可能导致点云和像素之间的misalignment。在这个工作中，我们提出了一个novel的图像助け预训练框架，称为 PRED。我们的框架的主要组成部分是 Birds-Eye-View（BEV）特征地图 conditioned semantic rendering，通过图像 semantics 来对点云进行超参。此外，我们还通过点 wise 掩码（mask ratio 95%）进一步提高我们的模型性能。广泛的实验证明，PRED 在多个大规模数据集上对 3D 识别任务具有显著的改进。代码将在 GitHub 上提供。
</details></li>
</ul>
<hr>
<h2 id="PersonMAE-Person-Re-Identification-Pre-Training-with-Masked-AutoEncoders"><a href="#PersonMAE-Person-Re-Identification-Pre-Training-with-Masked-AutoEncoders" class="headerlink" title="PersonMAE: Person Re-Identification Pre-Training with Masked AutoEncoders"></a>PersonMAE: Person Re-Identification Pre-Training with Masked AutoEncoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04496">http://arxiv.org/abs/2311.04496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hezhen Hu, Xiaoyi Dong, Jianmin Bao, Dongdong Chen, Lu Yuan, Dong Chen, Houqiang Li</li>
<li>for: 这篇论文主要目标是提高人识别任务中的特征表示，具体来说是实现人识别中的多层意识、遮挡Robustness和跨区域一致性。</li>
<li>methods: 这篇论文提出了一种简单 yet effective的预训练框架，即PersonMAE，它包括两个核心设计：1) 将图像分成两个区域， RegionA 和 RegionB，其中 RegionA 会被块级干扰，以模拟人识别中的常见遮挡；2) 使用掩码自适应网络来预测 RegionB 的整个像素水平和 semantic feature 水平。</li>
<li>results: 这篇论文在四个下游人识别任务中达到了状态机器人的性能，包括supervised（整体和 occluded 设置）和无监督（UDA 和 USL 设置）。特别是在通常采用的supervised设置下，PersonMAE 与 ViT-B 底层结构相结合，在 MSMT17 和 OccDuke 数据集上 achiev 79.8% 和 69.5% mAP，比前一个状态机器人提高了大幅度的 +8.0 mAP 和 +5.3 mAP， соответivamente。<details>
<summary>Abstract</summary>
Pre-training is playing an increasingly important role in learning generic feature representation for Person Re-identification (ReID). We argue that a high-quality ReID representation should have three properties, namely, multi-level awareness, occlusion robustness, and cross-region invariance. To this end, we propose a simple yet effective pre-training framework, namely PersonMAE, which involves two core designs into masked autoencoders to better serve the task of Person Re-ID. 1) PersonMAE generates two regions from the given image with RegionA as the input and \textit{RegionB} as the prediction target. RegionA is corrupted with block-wise masking to mimic common occlusion in ReID and its remaining visible parts are fed into the encoder. 2) Then PersonMAE aims to predict the whole RegionB at both pixel level and semantic feature level. It encourages its pre-trained feature representations with the three properties mentioned above. These properties make PersonMAE compatible with downstream Person ReID tasks, leading to state-of-the-art performance on four downstream ReID tasks, i.e., supervised (holistic and occluded setting), and unsupervised (UDA and USL setting). Notably, on the commonly adopted supervised setting, PersonMAE with ViT-B backbone achieves 79.8% and 69.5% mAP on the MSMT17 and OccDuke datasets, surpassing the previous state-of-the-art by a large margin of +8.0 mAP, and +5.3 mAP, respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>预训练在人识别（ReID）中的重要性不断增长。我们认为高质量的ReID表示应具备三种属性，即多级意识、遮挡Robustness和跨地域一致性。为此，我们提出了一个简单 yet 高效的预训练框架，即PersonMAE，其包括两个核心设计：1. PersonMAE从给定的图像中生成两个区域， RegionA 作为输入， RegionB 作为预测目标。RegionA 被块状遮盖，以模拟 ReID 中常见的遮挡，其可见部分被编码器接受。2. PersonMAE 目标是在像素级和semantic feature级别预测 RegionB。它鼓励预训练的特征表示具备三种属性，使其与下游 Person ReID 任务兼容，从而达到了状态之最的性能。这些属性使得PersonMAE 与下游任务一起进行训练，以达到最佳的表达。在四个下游 ReID 任务上（包括超级vised setting，holistic setting和occluded setting），PersonMAE 均达到了状态之最的性能。特别是在通常采用的超级vised setting上，PersonMAE 与 ViT-B 基础结构组合得到了79.8%和69.5%的mAP值，大幅超越了之前的状态之最，升高了+8.0 mAP和+5.3 mAP，分别。>>>
</details></li>
</ul>
<hr>
<h2 id="Non-Rigid-Shape-Registration-via-Deep-Functional-Maps-Prior"><a href="#Non-Rigid-Shape-Registration-via-Deep-Functional-Maps-Prior" class="headerlink" title="Non-Rigid Shape Registration via Deep Functional Maps Prior"></a>Non-Rigid Shape Registration via Deep Functional Maps Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04494">http://arxiv.org/abs/2311.04494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rqhuang88/DFR">https://github.com/rqhuang88/DFR</a></li>
<li>paper_authors: Puhua Jiang, Mingze Sun, Ruqi Huang</li>
<li>for: 本研究提出了一种基于学习的非静止形态注册方法，无需协调监督。</li>
<li>methods: 本方法使用深度函数图（DFM）来学习高维空间中的非线性映射，并使用这些映射来引导源网格受力向目标点云进行变换。此外，该方法还使用了一种动态更新和约束过滤的方法来提高注册稳定性。</li>
<li>results: 实验结果表明，使用只需几十个有限变化的训练形状，该方法可以达到现有最佳效果在非静止点云匹配中，同时也可以处理一些具有大量外部和内部变换的挑战性形状对。<details>
<summary>Abstract</summary>
In this paper, we propose a learning-based framework for non-rigid shape registration without correspondence supervision. Traditional shape registration techniques typically rely on correspondences induced by extrinsic proximity, therefore can fail in the presence of large intrinsic deformations. Spectral mapping methods overcome this challenge by embedding shapes into, geometric or learned, high-dimensional spaces, where shapes are easier to align. However, due to the dependency on abstract, non-linear embedding schemes, the latter can be vulnerable with respect to perturbed or alien input. In light of this, our framework takes the best of both worlds. Namely, we deform source mesh towards the target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM). In particular, the correspondences are dynamically updated according to the intermediate registrations and filtered by consistency prior, which prominently robustify the overall pipeline. Moreover, in order to alleviate the requirement of extrinsically aligned input, we train an orientation regressor on a set of aligned synthetic shapes independent of the training shapes for DFM. Empirical results show that, with as few as dozens of training shapes of limited variability, our pipeline achieves state-of-the-art results on several benchmarks of non-rigid point cloud matching, but also delivers high-quality correspondences between unseen challenging shape pairs that undergo both significant extrinsic and intrinsic deformations, in which case neither traditional registration methods nor intrinsic methods work. The code is available at https://github.com/rqhuang88/DFR.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种学习基于的非固定形态注册框架，无需协调监督。传统的形态注册技术通常会基于外部 proximity 引起的协调，因此在大型内部扭曲存在时会失败。 spectral mapping 方法可以将形状嵌入高维空间中，从而使形状更容易对齐。然而，由于这些空间是抽象的、非线性的，因此可能受到输入的干扰或外来输入的影响。为了解决这个问题，我们的框架结合了两者的优点。具体来说，我们将源网格扭曲到目标点云，并且以高维函数映射（DFM）学习的高维嵌入来引导协调。特别是，协调在中间注册中进行动态更新，并且通过具有一致性约束的约束策略来强化整体管道。此外，为了避免外部对齐的需求，我们在独立于训练形状的同aligned synthetic shapes上训练了一个旋转回归器。实验结果表明，只需几十个有限变化的训练形状，我们的管道可以在多个非固定点云匹配 benchmark 上达到领先的Result，同时还能够在未看过的挑战性形状对应中提供高质量的协调。代码可以在 <https://github.com/rqhuang88/DFR> 上获取。
</details></li>
</ul>
<hr>
<h2 id="All-Optical-Phase-Conjugation-Using-Diffractive-Wavefront-Processing"><a href="#All-Optical-Phase-Conjugation-Using-Diffractive-Wavefront-Processing" class="headerlink" title="All-Optical Phase Conjugation Using Diffractive Wavefront Processing"></a>All-Optical Phase Conjugation Using Diffractive Wavefront Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04473">http://arxiv.org/abs/2311.04473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Che-Yung Shen, Jingxi Li, Tianyi Gan, Mona Jarrahi, Aydogan Ozcan</li>
<li>for: 这种研究旨在设计一种可以实现全光学相位逆 conjugation 操作的干涉波front处理器，用于对输入场的相位偏移进行补偿。</li>
<li>methods: 该研究使用深度学习来优化一组不活跃的干涉层，以实现对输入场的全光学相位逆 conjugation 操作。</li>
<li>results: 实验表明，使用这种diffractive wavefront processor可以成功地实现对相位偏移的补偿，并且可以在不同的光学 Spectrum中实现。<details>
<summary>Abstract</summary>
Optical phase conjugation (OPC) is a nonlinear technique used for counteracting wavefront distortions, with various applications ranging from imaging to beam focusing. Here, we present the design of a diffractive wavefront processor to approximate all-optical phase conjugation operation for input fields with phase aberrations. Leveraging deep learning, a set of passive diffractive layers was optimized to all-optically process an arbitrary phase-aberrated coherent field from an input aperture, producing an output field with a phase distribution that is the conjugate of the input wave. We experimentally validated the efficacy of this wavefront processor by 3D fabricating diffractive layers trained using deep learning and performing OPC on phase distortions never seen by the diffractive processor during its training. Employing terahertz radiation, our physical diffractive processor successfully performed the OPC task through a shallow spatially-engineered volume that axially spans tens of wavelengths. In addition to this transmissive OPC configuration, we also created a diffractive phase-conjugate mirror by combining deep learning-optimized diffractive layers with a standard mirror. Given its compact, passive and scalable nature, our diffractive wavefront processor can be used for diverse OPC-related applications, e.g., turbidity suppression and aberration correction, and is also adaptable to different parts of the electromagnetic spectrum, especially those where cost-effective wavefront engineering solutions do not exist.
</details>
<details>
<summary>摘要</summary>
《光学阶段 conjugation（OPC）是一种非线性技术，用于纠正波前弯曲，具有多种应用，包括成像和聚焦。在这里，我们提出了一种Diffractive wavefront processor，用于 aproximate all-optical phase conjugation操作，对输入场具有偏移的phas aberrations。通过深度学习，我们对输入距离场的arbitrary phase-aberrated coherent field进行了all-optical处理，并生成了输出场的phas distribution，与输入场的phas distribution是 conjugate。我们经验验证了这种wavefront processor的有效性，通过3D制造深度学习训练的Diffractive layers并在输入场中实现OPC操作。使用teraHertz radiation，我们的物理Diffractive processor成功完成了OPC任务，并在axially span tens of wavelengths的浅空间工程ered volume中完成了这个任务。此外，我们还创建了一个Diffractive phase-conjugate mirror，通过将深度学习优化的Diffractive layers与标准镜相结合。由于它的 компакт、被动和可扩展性，我们的Diffractive wavefront processor可以用于多种OPC相关应用，如受杂率减少和偏移 correction，并可以适应不同的电磁波谱，尤其是那些没有cost-effective wavefront engineering解决方案。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Few-shot-CLIP-with-Semantic-Aware-Fine-Tuning"><a href="#Enhancing-Few-shot-CLIP-with-Semantic-Aware-Fine-Tuning" class="headerlink" title="Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning"></a>Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04464">http://arxiv.org/abs/2311.04464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Zhu, Yuefeng Chen, Wei Wang, Xiaofeng Mao, Yue Wang, Zhigang Li, Wang lu, Jindong Wang, Xiangyang Ji</li>
<li>for: 本研究旨在提高由少量训练样本学习的深度神经网络在低资源enario下应用。</li>
<li>methods: 我们修改了CLIP的视觉编码器，特别是它的强调池化层，以适应不同的少量任务。在训练过程中，我们 fine-tune 强调池化层的参数，以便让模型强调任务特有的 semantics。在推理过程中，我们使用差异混合来组合原始强调池化层和 fine-tuned 强调池化层的特征，以便结合几架shot知识和预先训练的 CLIP 知识。</li>
<li>results: 我们的方法可以增强传统的几架shot CLIP，并且与现有的 adapter 方法相容（称为 SAFE-A）。<details>
<summary>Abstract</summary>
Learning generalized representations from limited training samples is crucial for applying deep neural networks in low-resource scenarios. Recently, methods based on Contrastive Language-Image Pre-training (CLIP) have exhibited promising performance in few-shot adaptation tasks. To avoid catastrophic forgetting and overfitting caused by few-shot fine-tuning, existing works usually freeze the parameters of CLIP pre-trained on large-scale datasets, overlooking the possibility that some parameters might not be suitable for downstream tasks. To this end, we revisit CLIP's visual encoder with a specific focus on its distinctive attention pooling layer, which performs a spatial weighted-sum of the dense feature maps. Given that dense feature maps contain meaningful semantic information, and different semantics hold varying importance for diverse downstream tasks (such as prioritizing semantics like ears and eyes in pet classification tasks rather than side mirrors), using the same weighted-sum operation for dense features across different few-shot tasks might not be appropriate. Hence, we propose fine-tuning the parameters of the attention pooling layer during the training process to encourage the model to focus on task-specific semantics. In the inference process, we perform residual blending between the features pooled by the fine-tuned and the original attention pooling layers to incorporate both the few-shot knowledge and the pre-trained CLIP's prior knowledge. We term this method as Semantic-Aware FinE-tuning (SAFE). SAFE is effective in enhancing the conventional few-shot CLIP and is compatible with the existing adapter approach (termed SAFE-A).
</details>
<details>
<summary>摘要</summary>
学习通用表示法从有限的训练样本中学习是深度神经网络在具有限制的情况下应用的关键。最近，基于对比语言图像预训练（CLIP）的方法在少shot适应任务中表现出色。然而，由于少shot精度调整和过拟合，现有的方法通常将CLIP预训练在大规模数据集上冻结参数，忽略了可能一些参数不适合下游任务。为此，我们重新审视CLIP的视觉编码器，尤其是其独特的注意力汇聚层，该层通过空间权重汇聚密集特征图来完成。由于密集特征图包含有意义的semantic信息，而不同的semantic在不同的下游任务中具有不同的重要性（例如在宠物分类任务中更重视耳朵和眼睛而不是侧镜），因此在不同的少shot任务中使用同样的权重汇聚操作可能并不适合。因此，我们提议在训练过程中根据任务的semantic特征进行attenetion pooling层的细化调整，以便让模型在不同的下游任务中强调相应的semantic信息。在推理过程中，我们通过卷积残差融合法将 Fine-tuned的注意力汇聚层和原始注意力汇聚层的特征进行混合，以便同时利用CLIP的先前知识和少shot任务的知识。我们称这种方法为Semantic-Aware FinE-tuning（SAFE）。SAFE效果良好地提高了传统的少shot CLIP，并与现有的adapter方法（称为SAFE-A）兼容。
</details></li>
</ul>
<hr>
<h2 id="Retargeting-video-with-an-end-to-end-framework"><a href="#Retargeting-video-with-an-end-to-end-framework" class="headerlink" title="Retargeting video with an end-to-end framework"></a>Retargeting video with an end-to-end framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04458">http://arxiv.org/abs/2311.04458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi-Ngoc-Hanh Le, HuiGuang Huang, Yi-Ru Chen, Tong-Yee Lee</li>
<li>For: 本研究旨在提高计算机图形应用中视频的播放体验，因为现代数字设备具有不同的屏幕比例，视频重新调整成不同的比例成为必要的功能。* Methods: 本研究使用了一种端到端的 RETVI 方法，解决了传统方法中的计算瓶颈问题，通过设计了内容特征分析器 (CFA) 和适应型变形估计器 (ADE) 两个模块来实现。* Results: 实验和评估表明，我们的系统在质量和运行时间两个方面都超过了前一代的工作。您可以通过访问我们的项目网站 $\href{<a target="_blank" rel="noopener" href="http://graphics.csie.ncku.edu.tw/RETVI%7D%7Bhttp://graphics.csie.ncku.edu.tw/RETVI%7D$">http://graphics.csie.ncku.edu.tw/RETVI}{http://graphics.csie.ncku.edu.tw/RETVI}$</a> 了解更多结果。<details>
<summary>Abstract</summary>
Video holds significance in computer graphics applications. Because of the heterogeneous of digital devices, retargeting videos becomes an essential function to enhance user viewing experience in such applications. In the research of video retargeting, preserving the relevant visual content in videos, avoiding flicking, and processing time are the vital challenges. Extending image retargeting techniques to the video domain is challenging due to the high running time. Prior work of video retargeting mainly utilizes time-consuming preprocessing to analyze frames. Plus, being tolerant of different video content, avoiding important objects from shrinking, and the ability to play with arbitrary ratios are the limitations that need to be resolved in these systems requiring investigation. In this paper, we present an end-to-end RETVI method to retarget videos to arbitrary aspect ratios. We eliminate the computational bottleneck in the conventional approaches by designing RETVI with two modules, content feature analyzer (CFA) and adaptive deforming estimator (ADE). The extensive experiments and evaluations show that our system outperforms previous work in quality and running time. Visit our project website for more results at $\href{http://graphics.csie.ncku.edu.tw/RETVI}{http://graphics.csie.ncku.edu.tw/RETVI}$.
</details>
<details>
<summary>摘要</summary>
视频具有计算机图形应用中的重要性。由于数字设备的多样性，视频重定向成为提高用户观看体验的关键功能。在视频重定向研究中，保持视频中重要的视觉内容，避免抖动和减少处理时间是挑战的关键。将图像重定向技术应用到视频领域是困难的，因为运行时间较长。现有的视频重定向方法主要通过时间consuming的预处理分析帧来解决这些挑战。此外，承受不同视频内容、避免重要对象缩小以及可以自由调整比例是这些系统需要解决的问题。在本文中，我们提出了一种终端到终点的 RETVI 方法，用于重定向视频到任意比例。我们通过设计 CFA 和 ADE 两个模块来消除传统方法中的计算瓶颈。我们进行了广泛的实验和评估，结果显示，我们的系统在质量和运行时间方面都超过了前一代的工作。欢迎访问我们的项目网站，了解更多的结果：<http://graphics.csie.ncku.edu.tw/RETVI>。
</details></li>
</ul>
<hr>
<h2 id="SS-MAE-Spatial-Spectral-Masked-Auto-Encoder-for-Multi-Source-Remote-Sensing-Image-Classification"><a href="#SS-MAE-Spatial-Spectral-Masked-Auto-Encoder-for-Multi-Source-Remote-Sensing-Image-Classification" class="headerlink" title="SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote Sensing Image Classification"></a>SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote Sensing Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04442">http://arxiv.org/abs/2311.04442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyan Lin, Feng Gao, Xiaocheng Shi, Junyu Dong, Qian Du</li>
<li>for: 这个研究旨在提出一种基于自我监督学习的图像理解方法，具体来说是一种基于遮盖图像模型（Masked Image Modeling，MIM）的图像和激光&#x2F;雷达数据联合分类方法。</li>
<li>methods: 本研究使用的方法包括一种空间分支和一种频谱分支，其中空间分支遮盖随机的补做patches并重建缺失的像素，而频谱分支遮盖随机的频谱通道并重建缺失的通道。此外，为了补做本地特征，我们添加了两个轻量级CNN来提取特征。</li>
<li>results: 我们的实验结果表明，SS-MAE比基于MIM的一些状态艺术基eline（包括一些使用Transporter进行特征提取）更有效果，并且可以更好地利用输入数据的空间和频谱表示。我们在三个公共可用的数据集上进行了广泛的实验，并证明了我们的SS-MAE在三个多源数据集上的优越性。<details>
<summary>Abstract</summary>
Masked image modeling (MIM) is a highly popular and effective self-supervised learning method for image understanding. Existing MIM-based methods mostly focus on spatial feature modeling, neglecting spectral feature modeling. Meanwhile, existing MIM-based methods use Transformer for feature extraction, some local or high-frequency information may get lost. To this end, we propose a spatial-spectral masked auto-encoder (SS-MAE) for HSI and LiDAR/SAR data joint classification. Specifically, SS-MAE consists of a spatial-wise branch and a spectral-wise branch. The spatial-wise branch masks random patches and reconstructs missing pixels, while the spectral-wise branch masks random spectral channels and reconstructs missing channels. Our SS-MAE fully exploits the spatial and spectral representations of the input data. Furthermore, to complement local features in the training stage, we add two lightweight CNNs for feature extraction. Both global and local features are taken into account for feature modeling. To demonstrate the effectiveness of the proposed SS-MAE, we conduct extensive experiments on three publicly available datasets. Extensive experiments on three multi-source datasets verify the superiority of our SS-MAE compared with several state-of-the-art baselines. The source codes are available at \url{https://github.com/summitgao/SS-MAE}.
</details>
<details>
<summary>摘要</summary>
高度流行和有效的自我监督学习方法之一是遮盖图像模型（MIM），它主要关注空间特征模型化，忽略 spectral特征模型化。同时，现有的MIM基于方法通常使用Transformer来提取特征，可能会导致部分本地或高频信息丢失。为此，我们提议一种具有空间和 spectral特征的掩码自动编码器（SS-MAE），用于高等分辨率遥感数据和 LiDAR/SAR 数据的联合分类。具体来说，SS-MAE包括一个空间分支和一个spectral分支。空间分支遮盖随机的补丁，重建缺失的像素，而spectral分支遮盖随机的频率通道，重建缺失的通道。我们的SS-MAE充分利用输入数据的空间和spectral表示。此外，为了补充训练阶段的本地特征，我们添加了两个轻量级的 CNN，用于特征提取。通过将全局和本地特征进行共同特征模型化，我们的SS-MAE可以更好地利用输入数据的特征。为了证明我们提出的SS-MAE的有效性，我们进行了广泛的实验，并与多个数据集进行比较。实验结果表明，我们的SS-MAE在三个公共可用的数据集上具有明显的优势，超越了多个状态 искусственный基线。代码可以在 \url{https://github.com/summitgao/SS-MAE} 中获取。
</details></li>
</ul>
<hr>
<h2 id="Blurry-Video-Compression-A-Trade-off-between-Visual-Enhancement-and-Data-Compression"><a href="#Blurry-Video-Compression-A-Trade-off-between-Visual-Enhancement-and-Data-Compression" class="headerlink" title="Blurry Video Compression: A Trade-off between Visual Enhancement and Data Compression"></a>Blurry Video Compression: A Trade-off between Visual Enhancement and Data Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04430">http://arxiv.org/abs/2311.04430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawit Mureja Argaw, Junsik Kim, In So Kweon</li>
<li>for: 该论文主要针对视频压缩（VC）方法在不同的场景下提供高质量视频压缩。</li>
<li>methods: 该论文提出了一种基于视觉改进和数据压缩的VC方法，通过利用视觉特征之间的自然负荷关系，将VC问题转化为一个最小化最大化问题，并提出了一种有效的框架和训练策略。</li>
<li>results: 对多个标准数据集进行了广泛的实验，证明了该方法比多种现有的VC方法更有效。<details>
<summary>Abstract</summary>
Existing video compression (VC) methods primarily aim to reduce the spatial and temporal redundancies between consecutive frames in a video while preserving its quality. In this regard, previous works have achieved remarkable results on videos acquired under specific settings such as instant (known) exposure time and shutter speed which often result in sharp videos. However, when these methods are evaluated on videos captured under different temporal priors, which lead to degradations like motion blur and low frame rate, they fail to maintain the quality of the contents. In this work, we tackle the VC problem in a general scenario where a given video can be blurry due to predefined camera settings or dynamics in the scene. By exploiting the natural trade-off between visual enhancement and data compression, we formulate VC as a min-max optimization problem and propose an effective framework and training strategy to tackle the problem. Extensive experimental results on several benchmark datasets confirm the effectiveness of our method compared to several state-of-the-art VC approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-the-What-and-How-of-Annotation-in-Video-Object-Segmentation"><a href="#Learning-the-What-and-How-of-Annotation-in-Video-Object-Segmentation" class="headerlink" title="Learning the What and How of Annotation in Video Object Segmentation"></a>Learning the What and How of Annotation in Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04414">http://arxiv.org/abs/2311.04414</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanos Delatolas, Vicky Kalogeiton, Dim P. Papadopoulos</li>
<li>for: 这个研究是为了提高视频物件分割（VOS）模型的训练效率，并且实现人工费时的减少。</li>
<li>methods: 我们提出了一个人工辅助的标注框架（EVA-VOS），让机器学习模型预测每帧框架的标注类型和标注内容。</li>
<li>results: 我们在MOSE和DAVIS datasets上进行了实验，结果显示：EVA-VOS可以与人工标注相互比较，并且比标准方法快得多（3.5倍）；我们的帧选择性能优秀；EVA-VOS在标注时间方面具有优秀的表现。<details>
<summary>Abstract</summary>
Video Object Segmentation (VOS) is crucial for several applications, from video editing to video data generation. Training a VOS model requires an abundance of manually labeled training videos. The de-facto traditional way of annotating objects requires humans to draw detailed segmentation masks on the target objects at each video frame. This annotation process, however, is tedious and time-consuming. To reduce this annotation cost, in this paper, we propose EVA-VOS, a human-in-the-loop annotation framework for video object segmentation. Unlike the traditional approach, we introduce an agent that predicts iteratively both which frame ("What") to annotate and which annotation type ("How") to use. Then, the annotator annotates only the selected frame that is used to update a VOS module, leading to significant gains in annotation time. We conduct experiments on the MOSE and the DAVIS datasets and we show that: (a) EVA-VOS leads to masks with accuracy close to the human agreement 3.5x faster than the standard way of annotating videos; (b) our frame selection achieves state-of-the-art performance; (c) EVA-VOS yields significant performance gains in terms of annotation time compared to all other methods and baselines.
</details>
<details>
<summary>摘要</summary>
干脆视频对象分割（VOS）在许多应用中扮演着关键角色，从视频编辑到视频数据生成。训练VOS模型需要大量的手动标注视频。传统的标注方法需要人类 manually draw对象分割masks在目标视频帧上。这个Annotation process， however，是时间consuming和耗时的。为了降低这个标注成本，在这篇论文中，我们提出了EVA-VOS，一个人类在 loop的标注框架 для视频对象分割。与传统方法不同，我们引入了一个智能预测器，可以预测iteratively Which frame("What") to annotate和Which annotation type("How") to use。然后，annotator仅需要标注选择的帧，并将其用于更新VOS模块，从而 achieve significant gains in annotation time。我们在MOSE和DAVIS datasets上进行了实验，并证明了：（a）EVA-VOS可以在3.5倍 faster than标准视频标注方法得到masks with accuracy close to human agreement;（b）我们的帧选择性能在state-of-the-art水平;（c）EVA-VOS在所有方法和基准点上 yields significant performance gains in terms of annotation time。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/cs.CV_2023_11_08/" data-id="clorjzl7n00lcf18881nw7a70" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/cs.AI_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T12:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/cs.AI_2023_11_08/">cs.AI - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Beyond-Size-How-Gradients-Shape-Pruning-Decisions-in-Large-Language-Models"><a href="#Beyond-Size-How-Gradients-Shape-Pruning-Decisions-in-Large-Language-Models" class="headerlink" title="Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models"></a>Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04902">http://arxiv.org/abs/2311.04902</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rocktimjyotidas/gblm-pruner">https://github.com/rocktimjyotidas/gblm-pruner</a></li>
<li>paper_authors: Rocktim Jyoti Das, Liqun Ma, Zhiqiang Shen</li>
<li>for: 这个研究目的是为了开发一个基于大语言模型的简化方法，以提高模型的灵活性和可读性。</li>
<li>methods: 这个研究使用了一种称为Gradient-based Language Model Pruner（GBLM-Pruner）的新方法，它基于大语言模型的梯度，并且不需要进行任何后续训练或重新整理。</li>
<li>results: 研究结果显示，GBLM-Pruner比其他竞争方法（如SparseGPT和Wanda）在多个benchmark上表现更好，并且不需要进行任何后续训练或重新整理。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) with a billion or more parameters are prime targets for network pruning, which aims to reduce a portion of the network weights without compromising performance. Prior approaches such as Weights Magnitude, SparseGPT, and Wanda, either concentrated solely on weights or integrated weights with activations for sparsity. However, they overlooked the informative gradients derived from pretrained large language models. In this paper, we present a novel sparsity-centric pruning method for pretrained LLMs, termed Gradient-based Language Model Pruner (GBLM-Pruner). GBLM-Pruner leverages the first-order term of the Taylor expansion, operating in a training-free manner by harnessing properly normalized gradients from a few calibration samples to determine the importance pruning score, and substantially outperforms competitive counterparts like SparseGPT and Wanda in multiple benchmarks. Intriguing, after incorporating gradients, the unstructured pruning method tends to reveal some structural patterns post-pruning, which mirrors the geometric interdependence inherent in the LLMs' parameter structure. Additionally, GBLM-Pruner functions without any subsequent retraining or weight updates to maintain its simplicity as other counterparts. Extensive evaluations on LLaMA-1 and LLaMA-2 across various language benchmarks and perplexity show that GBLM-Pruner surpasses magnitude pruning, Wanda (weights+activations) and SparseGPT (weights+activations+weight update) by significant margins. Our code and models are available at https://github.com/RocktimJyotiDas/GBLM-Pruner.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的一亿或更多参数是独特目标 для网络削减，目的是为了缩减网络的重量而不损其性能。先前的方法，如Weight Magnitude、SparseGPT和Wanda，仅专注于 weights 或 integrates weights 和 activations 以获得简洁性。然而，它们忽略了适当的大型语言模型中的资讯 Gradient。在这篇论文中，我们提出了一种基于 Gradient 的简洁中心削减方法，称为 Gradient-based Language Model Pruner (GBLM-Pruner)。GBLM-Pruner 利用了 Taylor 展开的第一项，在无需训练的情况下，通过使用适当地 норamlized Gradient 从一些测试样本来决定重要性削减分数，并明显超过了竞争对手 SparseGPT 和 Wanda 的多个benchmark。惊奇的是，在将 Gradient 纳入之后，不Structured削减方法具有一些Structural Patterns 的特征，这与大型语言模型的参数结构中的几何相似性。此外，GBLM-Pruner 不需要任何后续的重训或重量更新，以维持其简单性。广泛的评估在 LLaMA-1 和 LLaMA-2 上，透过多种语言benchmark和准确度表现，GBLM-Pruner 在 Magnitude Pruning、Wanda 和 SparseGPT 的多个benchmark上大幅超过了它们。我们的代码和模型可以在 <https://github.com/RocktimJyotiDas/GBLM-Pruner> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Two-Complementary-Perspectives-to-Continual-Learning-Ask-Not-Only-What-to-Optimize-But-Also-How"><a href="#Two-Complementary-Perspectives-to-Continual-Learning-Ask-Not-Only-What-to-Optimize-But-Also-How" class="headerlink" title="Two Complementary Perspectives to Continual Learning: Ask Not Only What to Optimize, But Also How"></a>Two Complementary Perspectives to Continual Learning: Ask Not Only What to Optimize, But Also How</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04898">http://arxiv.org/abs/2311.04898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timm Hess, Tinne Tuytelaars, Gido M. van de Ven</li>
<li>for: 这篇论文主要关注于持续学习中的问题，具体是当新任务开始训练时，深度神经网络将会忘记之前学习的知识。</li>
<li>methods: 本论文提出了一种新的持续学习策略，即通过结合回温和调整条件来优化优化目标，以提高持续学习的效率和结果。</li>
<li>results: 本论文预计通过将回温和调整条件组合使用，可以减少问题的稳定性差异，提高学习效率和最终的学习结果。<details>
<summary>Abstract</summary>
Recent years have seen considerable progress in the continual training of deep neural networks, predominantly thanks to approaches that add replay or regularization terms to the loss function to approximate the joint loss over all tasks so far. However, we show that even with a perfect approximation to the joint loss, these approaches still suffer from temporary but substantial forgetting when starting to train on a new task. Motivated by this 'stability gap', we propose that continual learning strategies should focus not only on the optimization objective, but also on the way this objective is optimized. While there is some continual learning work that alters the optimization trajectory (e.g., using gradient projection techniques), this line of research is positioned as alternative to improving the optimization objective, while we argue it should be complementary. To evaluate the merits of our proposition, we plan to combine replay-approximated joint objectives with gradient projection-based optimization routines to test whether the addition of the latter provides benefits in terms of (1) alleviating the stability gap, (2) increasing the learning efficiency and (3) improving the final learning outcome.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="DAMEX-Dataset-aware-Mixture-of-Experts-for-visual-understanding-of-mixture-of-datasets"><a href="#DAMEX-Dataset-aware-Mixture-of-Experts-for-visual-understanding-of-mixture-of-datasets" class="headerlink" title="DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets"></a>DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04894">http://arxiv.org/abs/2311.04894</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinga-lala/damex">https://github.com/jinga-lala/damex</a></li>
<li>paper_authors: Yash Jain, Harkirat Behl, Zsolt Kira, Vibhav Vineet</li>
<li>for: 本文提出了一种解决 universal object detection 中 mixture of datasets 训练问题的方法，即使用 Mixture-of-Experts（MoE）来学习 dataset-specific features 并 ensemble 其知识。</li>
<li>methods: 本文提出了一种名为 Dataset-Aware Mixture-of-Experts（DAMEX）的方法，其中每个专家学习到了对应的 dataset 的 tokens 的映射。</li>
<li>results: 实验结果表明，DAMEX 可以与现有状态对比出色，增加了 average +10.2 AP 分数，并且在不同 dataset 的混合中也表现出了稳定的提升。<details>
<summary>Abstract</summary>
Construction of a universal detector poses a crucial question: How can we most effectively train a model on a large mixture of datasets? The answer lies in learning dataset-specific features and ensembling their knowledge but do all this in a single model. Previous methods achieve this by having separate detection heads on a common backbone but that results in a significant increase in parameters. In this work, we present Mixture-of-Experts as a solution, highlighting that MoEs are much more than a scalability tool. We propose Dataset-Aware Mixture-of-Experts, DAMEX where we train the experts to become an `expert' of a dataset by learning to route each dataset tokens to its mapped expert. Experiments on Universal Object-Detection Benchmark show that we outperform the existing state-of-the-art by average +10.2 AP score and improve over our non-MoE baseline by average +2.0 AP score. We also observe consistent gains while mixing datasets with (1) limited availability, (2) disparate domains and (3) divergent label sets. Further, we qualitatively show that DAMEX is robust against expert representation collapse.
</details>
<details>
<summary>摘要</summary>
建构普通的探测器带来一个关键问题：如何最有效地训练一个大量的混合数据集？答案在于学习数据集特定的特征并将它们融合到单一模型中。先前的方法通过在共同脊梁上添加分开的探测头来实现这一点，但这会导致参数数量增加 significatively。在这种工作中，我们提出了 Mixture-of-Experts 方法，并证明了 MoEs 不仅是一种可扩展性工具。我们提出了 Dataset-Aware Mixture-of-Experts，简称 DAMEX，它是通过训练专家来使得每个数据集的 токен被映射到它的专家中来实现的。我们在 Universal Object-Detection Benchmark 上进行了实验，结果表明我们比现有状态的算法平均提高了 +10.2 AP 分数，并且与我们的非 MoE 基eline相比提高了平均 +2.0 AP 分数。我们还发现在混合不同数据集、不同领域和不同标签集时也有了透明的提升。此外，我们证明了 DAMEX 对专家表示塌陷不易。
</details></li>
</ul>
<hr>
<h2 id="Towards-Few-Annotation-Learning-in-Computer-Vision-Application-to-Image-Classification-and-Object-Detection-tasks"><a href="#Towards-Few-Annotation-Learning-in-Computer-Vision-Application-to-Image-Classification-and-Object-Detection-tasks" class="headerlink" title="Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks"></a>Towards Few-Annotation Learning in Computer Vision: Application to Image Classification and Object Detection tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04888">http://arxiv.org/abs/2311.04888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quentin Bouniot</li>
<li>for: 这个论文旨在提出了关于机器学习几个标签学习的理论、算法和实验贡献，特别是计算视觉领域的图像分类和物体检测任务。</li>
<li>methods: 论文使用了多任务学习、元学习和自监学习等方法，以 bridge theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification，并且提出了一种基于对比学习的对象检测器预训练方法。</li>
<li>results: 论文通过 theoretical, algorithmic and experimental contributions，提出了一种基于对比学习的对象检测器预训练方法，并且在实验中得到了较好的结果。<details>
<summary>Abstract</summary>
In this thesis, we develop theoretical, algorithmic and experimental contributions for Machine Learning with limited labels, and more specifically for the tasks of Image Classification and Object Detection in Computer Vision. In a first contribution, we are interested in bridging the gap between theory and practice for popular Meta-Learning algorithms used in Few-Shot Classification. We make connections to Multi-Task Representation Learning, which benefits from solid theoretical foundations, to verify the best conditions for a more efficient meta-learning. Then, to leverage unlabeled data when training object detectors based on the Transformer architecture, we propose both an unsupervised pretraining and a semi-supervised learning method in two other separate contributions. For pretraining, we improve Contrastive Learning for object detectors by introducing the localization information. Finally, our semi-supervised method is the first tailored to transformer-based detectors.
</details>
<details>
<summary>摘要</summary>
本论文提出了关于机器学习limited labels的理论、算法和实验贡献，特别是在计算机视觉中进行图像分类和物体检测任务。在首次贡献中，我们旨在将流行的Meta-Learning算法与Few-Shot Classification之间的理论与实践相连接。我们利用多任务学习理论的坚实基础，以验证最佳的meta-learning条件。然后，我们提出了使用Transformer架构基于的无监督预训练和半监督学习方法，以便在训练物体检测器时使用无标注数据。在预训练方面，我们在对象检测器中引入了地址信息，以提高对比学习。最后，我们的半监督方法是首次针对Transformer架构基于的检测器进行定制。
</details></li>
</ul>
<hr>
<h2 id="SEMQA-Semi-Extractive-Multi-Source-Question-Answering"><a href="#SEMQA-Semi-Extractive-Multi-Source-Question-Answering" class="headerlink" title="SEMQA: Semi-Extractive Multi-Source Question Answering"></a>SEMQA: Semi-Extractive Multi-Source Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04886">http://arxiv.org/abs/2311.04886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research-datasets/quotesum">https://github.com/google-research-datasets/quotesum</a></li>
<li>paper_authors: Tal Schuster, Adam D. Lelkes, Haitian Sun, Jai Gupta, Jonathan Berant, William W. Cohen, Donald Metzler</li>
<li>for: 本研究旨在开发一种新的多源问答任务，即将多种多样的输入源总结为一个全面的答案，同时包含引用 span 和自由文本连接器。</li>
<li>methods: 本研究使用了大型自然语言模型（LLM），并定义了基于文本的评估 metric。</li>
<li>results: 实验表明，这种任务是非常具有挑战性的， demonstrate the importance of QuoteSum  для发展和研究这种总结能力。<details>
<summary>Abstract</summary>
Recently proposed long-form question answering (QA) systems, supported by large language models (LLMs), have shown promising capabilities. Yet, attributing and verifying their generated abstractive answers can be difficult, and automatically evaluating their accuracy remains an ongoing challenge.   In this work, we introduce a new QA task for answering multi-answer questions by summarizing multiple diverse sources in a semi-extractive fashion. Specifically, Semi-extractive Multi-source QA (SEMQA) requires models to output a comprehensive answer, while mixing factual quoted spans -- copied verbatim from given input sources -- and non-factual free-text connectors that glue these spans together into a single cohesive passage. This setting bridges the gap between the outputs of well-grounded but constrained extractive QA systems and more fluent but harder to attribute fully abstractive answers. Particularly, it enables a new mode for language models that leverages their advanced language generation capabilities, while also producing fine in-line attributions by-design that are easy to verify, interpret, and evaluate.   To study this task, we create the first dataset of this kind, QuoteSum, with human-written semi-extractive answers to natural and generated questions, and define text-based evaluation metrics. Experimenting with several LLMs in various settings, we find this task to be surprisingly challenging, demonstrating the importance of QuoteSum for developing and studying such consolidation capabilities.
</details>
<details>
<summary>摘要</summary>
现代提出的长形问答系统（QA），支持大型自然语言模型（LLM），已经展现出了有前途的能力。然而，归因和验证它们生成的抽象答案可能困难，自动评估它们的准确性仍然是一个持续的挑战。在这项工作中，我们引入了一种新的问答任务，即将多种多样的来源摘要到一起，以半EXTRACTIVE的方式回答多个问题。具体来说，半EXTRACTIVE Multi-source QA（SEMQA）需要模型输出一个全面的答案，同时混合factual quoted span（直接从输入源中摘取的准确语句）和非factual free-text connector（将这些span串连起来形成一个完整的句子）。这种设定可以将EXTRACTIVE QA系统的输出和抽象答案之间的 gap  bridged，并且允许语言模型利用其高级语言生成能力，同时生成易于归因、易于验证、易于解释的答案。为了研究这个任务，我们创建了第一个类似任务的数据集，名为QuoteSum，具有人类写的半EXTRACTIVE答案，并定义了文本基于的评估 метри克。通过对多种LLM在不同设定下进行实验，我们发现这个任务具有很高的挑战性，表明QuoteSum 对开发和研究这种整合能力的研究具有重要的意义。
</details></li>
</ul>
<hr>
<h2 id="LongQLoRA-Efficient-and-Effective-Method-to-Extend-Context-Length-of-Large-Language-Models"><a href="#LongQLoRA-Efficient-and-Effective-Method-to-Extend-Context-Length-of-Large-Language-Models" class="headerlink" title="LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models"></a>LongQLoRA: Efficient and Effective Method to Extend Context Length of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04879">http://arxiv.org/abs/2311.04879</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxin Yang</li>
<li>For: extend the context length of large language models with less training resources* Methods: combines Position Interpolation, QLoRA, and Shift Short Attention of LongLoRA* Results: can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within 1000 finetuning steps, achieves competitive perplexity performance on PG19 and Proof-pile datasets, and outperforms LongLoRA in the evaluation context length of 8192.<details>
<summary>Abstract</summary>
We present LongQLoRA, an efficient and effective method to extend context length of large language models with less training resources. LongQLoRA combines the advantages of Position Interpolation, QLoRA and Shift Short Attention of LongLoRA. With a single 32GB V100 GPU, LongQLoRA can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k within 1000 finetuning steps. LongQLoRA achieves competitive perplexity performance on PG19 and Proof-pile datasets, our model outperforms LongLoRA and is very close to MPT-7B-8K within the evaluation context length of 8192. We collect and build 39k long instruction data to extend context length of Vicuna-13B from 4096 to 8192 and achieve good performance both in long and short context generation task. We also do some ablation experiments to study the effect of LoRA rank, finetuning steps and attention patterns in inference.The model weights, training data and code are avaliable at https://github.com/yangjianxin1/LongQLoRA.
</details>
<details>
<summary>摘要</summary>
我们介绍LongQLoRA，一种高效和有效的方法，用于延长大语言模型的上下文长度，使用较少的训练资源。LongQLoRA结合了Position Interpolation、QLoRA和Shift Short Attention的优点，可以在单个32GB V100 GPU上延长LLaMA2 7B和13B的上下文长度从4096到8192，甚至12k，只需1000个训练步骤。LongQLoRA在PG19和Proof-pile数据集上达到了竞争力的抗抑压性表现，我们的模型比LongLoRA高效，仅在8192的评估上下文长度下与MPT-7B-8K相当。我们收集了39k字长的教程数据，用于延长Vicuna-13B的上下文长度从4096到8192，并在长和短上下文生成任务中达到了良好的性能。我们还进行了一些减少实验，以研究LoRA排名、训练步骤和注意模式在推理中的影响。模型权重、训练数据和代码可以在https://github.com/yangjianxin1/LongQLoRA上下载。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Benchmark-and-Contamination-for-Language-Models-with-Rephrased-Samples"><a href="#Rethinking-Benchmark-and-Contamination-for-Language-Models-with-Rephrased-Samples" class="headerlink" title="Rethinking Benchmark and Contamination for Language Models with Rephrased Samples"></a>Rethinking Benchmark and Contamination for Language Models with Rephrased Samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04850">http://arxiv.org/abs/2311.04850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo Yang, Wei-Lin Chiang, Lianmin Zheng, Joseph E. Gonzalez, Ion Stoica</li>
<li>for: 这个研究旨在检查大型自然语言模型（LLM）在训练时是否会受到公共测试数据的污染，并且提出更强大的测试数据清洁方法来解决这个问题。</li>
<li>methods: 研究人员使用了一种简单的字串比较方法来检查测试数据是否存在 overlap，并且发现这种方法无法察觉到一些简单的变化（如重写或翻译）。他们还提出了一个基于 LLM 的更强大的测试数据清洁方法，并将其应用到了广泛使用的预训练和终端训练数据集中。</li>
<li>results: 研究人员发现了许多公共测试数据集中存在 overlap，并且发现这些 overlap 可以通过简单的变化来实现。他们还发现了一些实验性的测试数据集中存在 overlap， suggesting a potential risk of unintentional contamination。通过将这个方法应用到广泛使用的数据集中，研究人员发现了许多前所未知的 overlap。<details>
<summary>Abstract</summary>
Large language models are increasingly trained on all the data ever produced by humans. Many have raised concerns about the trustworthiness of public benchmarks due to potential contamination in pre-training or fine-tuning datasets. While most data decontamination efforts apply string matching (e.g., n-gram overlap) to remove benchmark data, we show that these methods are insufficient, and simple variations of test data (e.g., paraphrasing, translation) can easily bypass these decontamination measures. Furthermore, we demonstrate that if such variation of test data is not eliminated, a 13B model can easily overfit a test benchmark and achieve drastically high performance, on par with GPT-4. We validate such observations in widely used benchmarks such as MMLU, GSK8k, and HumanEval. To address this growing risk, we propose a stronger LLM-based decontamination method and apply it to widely used pre-training and fine-tuning datasets, revealing significant previously unknown test overlap. For example, in pre-training sets such as RedPajama-Data-1T and StarCoder-Data, we identified that 8-18\% of the HumanEval benchmark overlaps. Interestingly, we also find such contamination in synthetic dataset generated by GPT-3.5/4, suggesting a potential risk of unintentional contamination. We urge the community to adopt stronger decontamination approaches when using public benchmarks. Moreover, we call for the community to actively develop fresh one-time exams to evaluate models accurately. Our decontamination tool is publicly available at https://github.com/lm-sys/llm-decontaminator.
</details>
<details>
<summary>摘要</summary>
大型语言模型在人类生产的所有数据上进行训练，导致公共底线的可靠性问题受到了更多的关注。因为可能在预训或精革训 dataset 中受到污染，因此许多人对公共底线的可靠性表示了担忧。然而，大多数数据洁净化努力使用字串匹配（例如 n-gram  overlap）来移除 benchmark 数据，我们表明这些方法是不足的，并且简单的变化（例如重写或翻译）可以轻松地绕过这些洁净化措施。此外，我们显示了如果这种变化不被消除，则一个 13B 模型可以轻松地适应 test 底线，并在 GPT-4 的性能水平上表现出色。我们在广泛使用的底线上进行验证，包括 MMLU、GSK8k 和 HumanEval。为了解决这个问题，我们提出了一个更强的 LLM-based 洁净化方法，并将其应用到广泛使用的预训和精革训 dataset 中，发现了significant previously unknown test overlap。例如，在 RedPajama-Data-1T 和 StarCoder-Data 预训集中，我们发现了 8-18% 的 HumanEval 底线重 overlap。几nigatively，我们也发现了这种污染在 GPT-3.5/4 生成的 sintheic dataset 中，这表明了潜在的随机污染风险。我们呼吁社区遵循更强的洁净化方法，并发展新的一次评估方法，以确保模型的准确性。我们的洁净化工具公开 disponibile 在 GitHub 上，请见 <https://github.com/lm-sys/llm-decontaminator>。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Semantic-Component-for-Robust-Molecular-Property-Prediction"><a href="#Identifying-Semantic-Component-for-Robust-Molecular-Property-Prediction" class="headerlink" title="Identifying Semantic Component for Robust Molecular Property Prediction"></a>Identifying Semantic Component for Robust Molecular Property Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04837">http://arxiv.org/abs/2311.04837</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmirlab-group/sci">https://github.com/dmirlab-group/sci</a></li>
<li>paper_authors: Zijian Li, Zunhong Xu, Ruichu Cai, Zhenhui Yang, Yuguang Yan, Zhifeng Hao, Guangyi Chen, Kun Zhang</li>
<li>for: 这种论文的目的是提高分子属性预测 task 中 Graph Neural Networks (GNNs) 的 OUT-OF-distribution (OOD) 环境下的泛化能力。</li>
<li>methods: 该论文提出了一种名为 Semantic-Components Identifiability (SCI) 的生成模型，其中可以显式地分解 latent space 为 semantic-relevant (SR) 和 semantic-irrelevant (SI) 组成部分。这种方法通过涉及到最小变化的 causal mechanisms 来提高 OOD 泛化性。</li>
<li>results: 实验研究显示，该方法可以在 21 个数据集上达到领先的性能，并且在三个主流benchmark中显示了通用的改进。此外，Visualization 结果还提供了有用的案例研究和预测结果的解释。<details>
<summary>Abstract</summary>
Although graph neural networks have achieved great success in the task of molecular property prediction in recent years, their generalization ability under out-of-distribution (OOD) settings is still under-explored. Different from existing methods that learn discriminative representations for prediction, we propose a generative model with semantic-components identifiability, named SCI. We demonstrate that the latent variables in this generative model can be explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI) components, which contributes to better OOD generalization by involving minimal change properties of causal mechanisms. Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables. Sequentially, to reduce misidentification, we restrict the minimal changes of the SR atom variables and add a semantic latent substructure regularization to mitigate the variance of the SR substructure under augmented domain changes. Under mild assumptions, we prove the block-wise identifiability of the SR substructure and the comment-wise identifiability of SR atom variables. Experimental studies achieve state-of-the-art performance and show general improvement on 21 datasets in 3 mainstream benchmarks. Moreover, the visualization results of the proposed SCI method provide insightful case studies and explanations for the prediction results. The code is available at: https://github.com/DMIRLAB-Group/SCI.
</details>
<details>
<summary>摘要</summary>
Although graph neural networks have achieved great success in the task of molecular property prediction in recent years, their generalization ability under out-of-distribution (OOD) settings is still under-explored. Different from existing methods that learn discriminative representations for prediction, we propose a generative model with semantic-components identifiability, named SCI. We demonstrate that the latent variables in this generative model can be explicitly identified into semantic-relevant (SR) and semantic-irrelevant (SI) components, which contributes to better OOD generalization by involving minimal change properties of causal mechanisms. Specifically, we first formulate the data generation process from the atom level to the molecular level, where the latent space is split into SI substructures, SR substructures, and SR atom variables. Sequentially, to reduce misidentification, we restrict the minimal changes of the SR atom variables and add a semantic latent substructure regularization to mitigate the variance of the SR substructure under augmented domain changes. Under mild assumptions, we prove the block-wise identifiability of the SR substructure and the comment-wise identifiability of SR atom variables. Experimental studies achieve state-of-the-art performance and show general improvement on 21 datasets in 3 mainstream benchmarks. Moreover, the visualization results of the proposed SCI method provide insightful case studies and explanations for the prediction results. The code is available at: https://github.com/DMIRLAB-Group/SCI.Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Personalized-Online-Federated-Learning"><a href="#Decentralized-Personalized-Online-Federated-Learning" class="headerlink" title="Decentralized Personalized Online Federated Learning"></a>Decentralized Personalized Online Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04817">http://arxiv.org/abs/2311.04817</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renzhi Wu, Saayan Mitra, Xiang Chen, Anup Rao</li>
<li>for: 这个研究旨在提出一个新的学习设定，即“分散式个性化在线学习”（Decentralized Personalized Online Federated Learning，DPOFL），以满足在企业端服务器（enterprise edge servers）上进行线上推荐、个性化学习和分散式学习的重要应用。</li>
<li>methods: 本研究提出了两个技术挑战：首先，如何将来自邻居客户的共享模型参数组合成一个优化性能的本地模型？我们提议通过直接将本地模型的性能对统计量进行优化，以提高每个本地模型的个性化水平，并且帮助本地模型适应潜在数据移动的情况。第二个挑战是如何选择每个客户的邻居？我们提议使用获得的统计量来选择最有帮助的邻居，以减少通信成本。</li>
<li>results: 我们运行了三个真实世界的项目推荐数据集和一个空气质量预测数据集，以证明我们的提案的有效性和可靠性。<details>
<summary>Abstract</summary>
Vanilla federated learning does not support learning in an online environment, learning a personalized model on each client, and learning in a decentralized setting. There are existing methods extending federated learning in each of the three aspects. However, some important applications on enterprise edge servers (e.g. online item recommendation at global scale) involve the three aspects at the same time. Therefore, we propose a new learning setting \textit{Decentralized Personalized Online Federated Learning} that considers all the three aspects at the same time.   In this new setting for learning, the first technical challenge is how to aggregate the shared model parameters from neighboring clients to obtain a personalized local model with good performance on each client. We propose to directly learn an aggregation by optimizing the performance of the local model with respect to the aggregation weights. This not only improves personalization of each local model but also helps the local model adapting to potential data shift by intelligently incorporating the right amount of information from its neighbors. The second challenge is how to select the neighbors for each client. We propose a peer selection method based on the learned aggregation weights enabling each client to select the most helpful neighbors and reduce communication cost at the same time. We verify the effectiveness and robustness of our proposed method on three real-world item recommendation datasets and one air quality prediction dataset.
</details>
<details>
<summary>摘要</summary>
vanilla 联合学习不支持在线学习环境中学习个性化模型，以及在分布式设置下学习。现有方法可以扩展联合学习在每一个方面。然而，一些重要的企业端服务器（例如，全球范围内的在线ITEM推荐）包含这三个方面。因此，我们提出了一个新的学习环境——分布式个性化在线联合学习。在这个新的学习环境中，第一个技术挑战是如何将来自邻居客户端的共享模型参数聚合成一个个性化的本地模型，以实现每个客户端上的好性能。我们提议直接通过优化本地模型的性能来学习聚合。这不仅提高了每个本地模型的个性化性，还帮助本地模型适应可能的数据变化，智能地包含邻居客户端提供的信息。第二个挑战是如何选择每个客户端的邻居。我们提议基于学习聚合权重的人选方法，使每个客户端可以选择最有帮助的邻居，同时降低通信成本。我们在三个实际ITEM推荐数据集和一个空气质量预测数据集上验证了我们的提议的有效性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="MTGER-Multi-view-Temporal-Graph-Enhanced-Temporal-Reasoning-over-Time-Involved-Document"><a href="#MTGER-Multi-view-Temporal-Graph-Enhanced-Temporal-Reasoning-over-Time-Involved-Document" class="headerlink" title="MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document"></a>MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04816">http://arxiv.org/abs/2311.04816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Chu, Zekun Wang, Jiafeng Liang, Ming Liu, Bing Qin</li>
<li>for: 这篇论文是为了提高时间推理的能力而写的。</li>
<li>methods: 这篇论文使用了多视图时间图的方法，以显著提高时间推理的能力。</li>
<li>results: 实验结果表明，这种方法可以更好地处理时间推理任务，并且具有更高的一致性。Here’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 这篇论文是为了提高时间推理的能力而写的，它旨在解决由于文档中的时间关系复杂而使得时间推理变得困难的问题。</li>
<li>methods: 这篇论文使用了多视图时间图的方法，以显著提高时间推理的能力。具体来说，它使用了多视图时间图来显式地表示文档中的时间关系，并通过自适应融合来使两个视图相互补充。此外，它还设计了一种自动学习的时间比较目标，以进一步提高模型的隐式推理能力。</li>
<li>results: 实验结果表明，这种方法可以更好地处理时间推理任务，并且具有更高的一致性。具体来说，在TimeQA和SituatedQA数据集上，这种方法的表现都非常出色，并且在问题拟合时也能够保持更高的一致性。<details>
<summary>Abstract</summary>
The facts and time in the document are intricately intertwined, making temporal reasoning over documents challenging. Previous work models time implicitly, making it difficult to handle such complex relationships. To address this issue, we propose MTGER, a novel Multi-view Temporal Graph Enhanced Temporal Reasoning framework for temporal reasoning over time-involved documents. Concretely, MTGER explicitly models the temporal relationships among facts by multi-view temporal graphs. On the one hand, the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts; on the other hand, the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. To further improve the implicit reasoning capability of the model, we design a self-supervised time-comparing objective. Extensive experimental results demonstrate the effectiveness of our method on the TimeQA and SituatedQA datasets. Furthermore, MTGER gives more consistent answers under question perturbations.
</details>
<details>
<summary>摘要</summary>
文档中的事实和时间关系紧密相互关联，使得文档中的时间逻辑推理变得非常困难。先前的工作模型时间Implicitly，这使得它们无法处理这种复杂的关系。为解决这个问题，我们提议MTGER，一种新的多视图时间图强化的时间逻辑推理框架。具体来说，MTGER使用多视图时间图来明确事实之间的时间关系。一方面，不同视图中的时间图显示了事实之间的时间和讨论关系;另一方面，多视图机制使得时间和事实信息相互补做，使得两个视图可以通过自适应融合补做。为进一步提高模型的隐式逻辑能力，我们设计了一个自动supervised时间比较目标。广泛的实验结果表明我们的方法在TimeQA和SituatedQA数据集上显示出了效果。此外，MTGER在问题改变时给出了更一致的答案。
</details></li>
</ul>
<hr>
<h2 id="DACBERT-Leveraging-Dependency-Agreement-for-Cost-Efficient-Bert-Pretraining"><a href="#DACBERT-Leveraging-Dependency-Agreement-for-Cost-Efficient-Bert-Pretraining" class="headerlink" title="DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert Pretraining"></a>DACBERT: Leveraging Dependency Agreement for Cost-Efficient Bert Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04799">http://arxiv.org/abs/2311.04799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sw-packages/fa101e30ca4ffd6a0479993b0e1c7299d2311c0416c0b68e2551534430e1e8fe">https://github.com/sw-packages/fa101e30ca4ffd6a0479993b0e1c7299d2311c0416c0b68e2551534430e1e8fe</a></li>
<li>paper_authors: Martin Kuo, Jianyi Zhang, Yiran Chen</li>
<li>for: 提高Cost-efficient预训练模型的性能和可读性（Crammed BERT）。</li>
<li>methods: 引入一种新的预训练模型——Dependency Agreement Crammed BERT (DACBERT)，并提出一种基于语言学理论的两阶段预训练框架——Dependency Agreement Pretraining。</li>
<li>results: 在GLUE benchmark上评估，DACBERT表现出色，比Crammed BERT提高3.13%在RTE任务中和2.26%在MRPC任务中，同时提高了GLUE平均分数0.83%，manifesting its significant potential。<details>
<summary>Abstract</summary>
Building on the cost-efficient pretraining advancements brought about by Crammed BERT, we enhance its performance and interpretability further by introducing a novel pretrained model Dependency Agreement Crammed BERT (DACBERT) and its two-stage pretraining framework - Dependency Agreement Pretraining. This framework, grounded by linguistic theories, seamlessly weaves syntax and semantic information into the pretraining process. The first stage employs four dedicated submodels to capture representative dependency agreements at the chunk level, effectively converting these agreements into embeddings. The second stage uses these refined embeddings, in tandem with conventional BERT embeddings, to guide the pretraining of the rest of the model. Evaluated on the GLUE benchmark, our DACBERT demonstrates notable improvement across various tasks, surpassing Crammed BERT by 3.13% in the RTE task and by 2.26% in the MRPC task. Furthermore, our method boosts the average GLUE score by 0.83%, underscoring its significant potential. The pretraining process can be efficiently executed on a single GPU within a 24-hour cycle, necessitating no supplementary computational resources or extending the pretraining duration compared with the Crammed BERT. Extensive studies further illuminate our approach's instrumental role in bolstering the interpretability of pretrained language models for natural language understanding tasks.
</details>
<details>
<summary>摘要</summary>
基于Cost-efficient pre-training的进步，我们发展了一种新的预训练模型——Dependency Agreement Crammed BERT（DACBERT）和其两个阶段预训练框架——Dependency Agreement Pretraining。这个框架，基于语言学理论，将 sintaxis和semantic信息熔入了预训练过程中。第一个阶段使用四个专门的子模型来捕捉chunk级别的代表性dependency agreements，并将这些协议转化为嵌入。第二个阶段使用这些精细的嵌入，与传统的BERT嵌入一起，导航预训练模型的其余部分的预训练。在GLUE测试benchmark上，我们的DACBERT表现出色，在RTE任务上高于Crammed BERT by 3.13%，在MRPC任务上高于Crammed BERT by 2.26%。此外，我们的方法提高了GLUE平均分数 by 0.83%，强调其 significativity。预训练过程可以在单个GPU上完成 Within a 24-hour cycle，不需要任何补充计算资源或延长预训练时间与Crammed BERT相比。extensive studies также证明了我们的方法在自然语言理解任务中增强预训练语言模型的可读性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Multiple-Roles-of-Ontologies-in-Explainable-AI"><a href="#On-the-Multiple-Roles-of-Ontologies-in-Explainable-AI" class="headerlink" title="On the Multiple Roles of Ontologies in Explainable AI"></a>On the Multiple Roles of Ontologies in Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04778">http://arxiv.org/abs/2311.04778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roberto Confalonieri, Giancarlo Guizzardi</li>
<li>for: 本研究探讨了ontology在可解释AI和人类中心的解释系统和可读性解释中的不同角色。</li>
<li>methods: 本文考虑了三种ontology在解释中的应用，包括参考模型、常识理解和知识精炼和复杂性管理。</li>
<li>results: 本文结论提出了 Ontology-based 方法在解释中的挑战和需要进一步研究的问题，以评估其人类理解度和效果。<details>
<summary>Abstract</summary>
This paper discusses the different roles that explicit knowledge, in particular ontologies, can play in Explainable AI and in the development of human-centric explainable systems and intelligible explanations. We consider three main perspectives in which ontologies can contribute significantly, namely reference modelling, common-sense reasoning, and knowledge refinement and complexity management. We overview some of the existing approaches in the literature, and we position them according to these three proposed perspectives. The paper concludes by discussing what challenges still need to be addressed to enable ontology-based approaches to explanation and to evaluate their human-understandability and effectiveness.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Explainable AI" is translated as "可解释人工智能" (可解释AI)* "human-centric explainable systems" is translated as "人类中心的解释系统" (人类中心的解释系统)* "intelligible explanations" is translated as "可理解的解释" (可理解的解释)* "ontologies" is translated as " ontology" (ontology)* "reference modeling" is translated as "参照模型" (参照模型)* "common-sense reasoning" is translated as "常识逻辑" (常识逻辑)* "knowledge refinement and complexity management" is translated as "知识精炼和复杂性管理" (知识精炼和复杂性管理)
</details></li>
</ul>
<hr>
<h2 id="Vital-Sign-Forecasting-for-Sepsis-Patients-in-ICUs"><a href="#Vital-Sign-Forecasting-for-Sepsis-Patients-in-ICUs" class="headerlink" title="Vital Sign Forecasting for Sepsis Patients in ICUs"></a>Vital Sign Forecasting for Sepsis Patients in ICUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04770">http://arxiv.org/abs/2311.04770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anubhav Bhatti, Yuwei Liu, Chen Dan, Bingjie Shen, San Lee, Yonghwan Kim, Jang Yong Kim</li>
<li>For: This paper aims to introduce a deep learning-based vital sign forecasting system to predict future physiological conditions in Intensive Care Units (ICUs) to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock.* Methods: The proposed system utilizes state-of-the-art deep learning architectures, including N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), to forecast vital signs up to 3 hours into the future using a short window of historical vital sign data. The DILATE loss function is adopted to capture the shape and temporal dynamics of vital signs.* Results: The performance of the three models is evaluated using mean squared error (MSE) and dynamic time warping (DTW) metrics. The results show that TFT excels in capturing overall trends, while N-HiTS is superior in retaining short-term fluctuations within a predefined range. The findings demonstrate the potential of deep learning in transforming the monitoring systems in ICUs and improving patient care and outcomes.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在介绍基于深度学习的生命 Parameters 预测系统，以帮助医疗提供者早期发现生物physiological instability 和预测 septic shock。</li>
<li>methods: 该系统使用 state-of-the-art 深度学习架构，包括 N-BEATS、N-HiTS 和 Temporal Fusion Transformer (TFT)，预测生命 Parameters 的未来发展，并采用 DILATE 损失函数来捕捉生命 Parameters 的形态和时间动态。</li>
<li>results: 这篇论文使用 MSE 和 DTW 指标评估三种模型的表现，结果显示 TFT 在捕捉总趋势方面表现出色，而 N-HiTS 在保持短期波动 dentro de predefined 范围方面表现出优异。这些结果表明深度学习可能在 ICU 监测系统中引入 transformational 改进，从而导致 Significant improvements in patient care and outcomes。<details>
<summary>Abstract</summary>
Sepsis and septic shock are a critical medical condition affecting millions globally, with a substantial mortality rate. This paper uses state-of-the-art deep learning (DL) architectures to introduce a multi-step forecasting system to predict vital signs indicative of septic shock progression in Intensive Care Units (ICUs). Our approach utilizes a short window of historical vital sign data to forecast future physiological conditions. We introduce a DL-based vital sign forecasting system that predicts up to 3 hours of future vital signs from 6 hours of past data. We further adopt the DILATE loss function to capture better the shape and temporal dynamics of vital signs, which are critical for clinical decision-making. We compare three DL models, N-BEATS, N-HiTS, and Temporal Fusion Transformer (TFT), using the publicly available eICU Collaborative Research Database (eICU-CRD), highlighting their forecasting capabilities in a critical care setting. We evaluate the performance of our models using mean squared error (MSE) and dynamic time warping (DTW) metrics. Our findings show that while TFT excels in capturing overall trends, N-HiTS is superior in retaining short-term fluctuations within a predefined range. This paper demonstrates the potential of deep learning in transforming the monitoring systems in ICUs, potentially leading to significant improvements in patient care and outcomes by accurately forecasting vital signs to assist healthcare providers in detecting early signs of physiological instability and anticipating septic shock.
</details>
<details>
<summary>摘要</summary>
septic shock 是一种严重的医疗紧急情况，影响全球数百万人，死亡率很高。这篇论文使用当今最先进的深度学习（DL）建筑物 introduce 一种多步预测系统，用于预测在医疗集中室（ICU）中的生命体征，帮助医生早发现生命体征的不稳定，预测 septic shock 的进程。我们的方法使用一个短时间的历史生命体征数据来预测未来的生命体征。我们引入了 DL 基于的生命体征预测系统，可以在 6 小时的历史数据上预测未来 3 小时的生命体征。我们还采用 DILATE 损失函数，以更好地捕捉生命体征的形状和时间动态，这些特征对医疗决策非常重要。我们使用公共可用的 eICU 合作研究数据库（eICU-CRD），比较三种 DL 模型（N-BEATS、N-HiTS 和 Temporal Fusion Transformer ）的预测能力，并评估他们在护理 Setting 中的表现。我们使用 Mean Squared Error （MSE）和动态时间旋转（DTW）指标评估模型的表现。我们的发现表明，TFT 能够 capture 总趋势，而 N-HiTS 在固定范围内保持短期波动的表现更佳。这篇论文示出了深度学习在 ICU 监测系统中的潜在优势，可能导致患者的监测和诊断更加精准，提高患者的生命体征和结果。
</details></li>
</ul>
<hr>
<h2 id="The-voraus-AD-Dataset-for-Anomaly-Detection-in-Robot-Applications"><a href="#The-voraus-AD-Dataset-for-Anomaly-Detection-in-Robot-Applications" class="headerlink" title="The voraus-AD Dataset for Anomaly Detection in Robot Applications"></a>The voraus-AD Dataset for Anomaly Detection in Robot Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04765">http://arxiv.org/abs/2311.04765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Thieß Brockmann, Marco Rudolph, Bodo Rosenhahn, Bastian Wandt</li>
<li>For:  This paper focuses on developing a dataset for anomaly detection in industrial robotics and proposing a new baseline method called MVT-Flow for detecting unusual events in robotic applications.* Methods: The paper introduces a dataset of machine data for training and benchmarking anomaly detection methods, and proposes a new method called MVT-Flow that uses deep learning-based density estimation with normalizing flows to detect anomalies.* Results: The paper reports that MVT-Flow outperforms previous baselines by a large margin of 6.2% in area under ROC.<details>
<summary>Abstract</summary>
During the operation of industrial robots, unusual events may endanger the safety of humans and the quality of production. When collecting data to detect such cases, it is not ensured that data from all potentially occurring errors is included as unforeseeable events may happen over time. Therefore, anomaly detection (AD) delivers a practical solution, using only normal data to learn to detect unusual events. We introduce a dataset that allows training and benchmarking of anomaly detection methods for robotic applications based on machine data which will be made publicly available to the research community. As a typical robot task the dataset includes a pick-and-place application which involves movement, actions of the end effector and interactions with the objects of the environment. Since several of the contained anomalies are not task-specific but general, evaluations on our dataset are transferable to other robotics applications as well. Additionally, we present MVT-Flow (multivariate time-series flow) as a new baseline method for anomaly detection: It relies on deep-learning-based density estimation with normalizing flows, tailored to the data domain by taking its structure into account for the architecture. Our evaluation shows that MVT-Flow outperforms baselines from previous work by a large margin of 6.2% in area under ROC.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)在工业机器人的操作过程中，不期望的事件可能会威胁人类安全和生产质量。当收集数据来探测这些情况时，不能确保所有可能发生的错误都包含在内，因为不可预测的事件可能会发生在时间过程中。因此，异常检测（AD）提供了一个实用的解决方案，使用正常数据来检测不正常事件。我们介绍了一个基于机器数据的异常检测数据集，该数据集将被公开向研究社区。该数据集包含一个拾取并置放应用程序，该应用程序涉及运动、机器末端器的行为和环境中对象的互动。由于数据集中含有一些不特定任务的异常，因此我们的评估可以转移到其他机器人应用程序中。此外，我们还提出了一种基于深度学习的异常检测方法 called MVT-Flow，它利用时间序列抽象来进行异常检测。我们的评估表明，MVT-Flow在ROC预测曲线下的表现优于前一代的基准值6.2%。
</details></li>
</ul>
<hr>
<h2 id="Euclidean-Projective-Conformal-Choosing-a-Geometric-Algebra-for-Equivariant-Transformers"><a href="#Euclidean-Projective-Conformal-Choosing-a-Geometric-Algebra-for-Equivariant-Transformers" class="headerlink" title="Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers"></a>Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04744">http://arxiv.org/abs/2311.04744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pim de Haan, Taco Cohen, Johann Brehmer</li>
<li>for: 这篇论文旨在探讨基于几何深度学习的几何深度学习架构GATr，以及如何通过这种架构来构建可扩展的变换器架构。</li>
<li>methods: 这篇论文使用的方法包括将GATr架构推广到任意几何（或Clifford）代数上，并对这些架构进行了理论和实验研究。</li>
<li>results: 研究发现，使用Euclidean代数、projective代数和conformal代数constructed的模型均可以 representations 3D数据，但是Euclidean代数的模型 computationally cheap，但是表达能力较弱，而projective代数的模型表达能力较强，但是计算复杂度较高。Conformal algebra和改进的projective algebra定义了强大而高效的模型。<details>
<summary>Abstract</summary>
The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.
</details>
<details>
<summary>摘要</summary>
“几何深度学习构件（GATr）是一种多元的架构，基于射影几何代数。我们将这个架构转换为可扩展的对象，让你可以根据任何几何（或克利福德）代数建立可扩展的对应器架构。我们在理论和实践中研究了不同的几何代数版本，包括几何、射影和对应几何代数，它们都适合表示3D数据，并评估了它们的理论和实际性。最简单的几何架构 computationally cheap，但是它的组合运算小于，而且不够表达力。对应几何架构不够表达力，而且不可靠。对应几何和改进的射影架构都定义了强大且高性能的架构。”
</details></li>
</ul>
<hr>
<h2 id="The-Quest-for-Content-A-Survey-of-Search-Based-Procedural-Content-Generation-for-Video-Games"><a href="#The-Quest-for-Content-A-Survey-of-Search-Based-Procedural-Content-Generation-for-Video-Games" class="headerlink" title="The Quest for Content: A Survey of Search-Based Procedural Content Generation for Video Games"></a>The Quest for Content: A Survey of Search-Based Procedural Content Generation for Video Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04710">http://arxiv.org/abs/2311.04710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mar Zamorano, Carlos Cetina, Federica Sarro</li>
<li>for: 这篇论文主要是为了解决电子游戏的内容生成问题，即通过搜索算法自动生成大量内容，以满足消费者的需求。</li>
<li>methods: 论文使用搜索基于生成的方法，包括搜索探索、搜索迁移和搜索随机生成等，以自动生成内容。</li>
<li>results: 论文对搜索基于生成的方法进行了评估和分析，并提出了一些未来研究方向，以帮助实践者和研究人员更好地解决内容生成问题。<details>
<summary>Abstract</summary>
Video games demand is constantly increasing, which requires the costly production of large amounts of content. Towards this challenge, researchers have developed Search-Based Procedural Content Generation (SBPCG), that is, the (semi-)automated creation of content through search algorithms. We survey the current state of SBPCG, reporting work appeared in the field between 2011-2022 and identifying open research challenges. The results lead to recommendations for practitioners and to the identification of several potential future research avenues for SBPCG.
</details>
<details>
<summary>摘要</summary>
电子游戏的需求不断增加，这需要大量的内容生成，而这也需要昂贵的生产成本。为应对这个挑战，研究人员已经开发出了搜索基于生成内容的技术（Search-Based Procedural Content Generation，SBPCG），即通过搜索算法来自动生成内容。我们对SBPCG领域的当前状况进行了评估，报告了2011-2022年间出版的相关研究成果，并确定了一些未解决的研究挑战和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Challenging-Common-Assumptions-in-Multi-task-Learning"><a href="#Challenging-Common-Assumptions-in-Multi-task-Learning" class="headerlink" title="Challenging Common Assumptions in Multi-task Learning"></a>Challenging Common Assumptions in Multi-task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04698">http://arxiv.org/abs/2311.04698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cathrin Elich, Lukas Kirchdorfer, Jan M. Köhler, Lukas Schott</li>
<li>for: 本研究旨在探讨多任务学习（MTL）下的下降难度和 gradient conflicts 问题，以及这些问题在单任务学习（STL）中的表现。</li>
<li>methods: 本研究使用了常见的 STL 工具，如 Adam 优化器，以挑战 MTL 中的假设。研究发现，Adam 优化器在 MTL 中的效果归功于其部分损失度量不变性。此外，研究还探讨了 gradient conflicts 在 MTL 和 STL 之间的差异。</li>
<li>results: 研究发现，在面向不同的图像损害时，MTL 和 STL 学习的特征都能够 Transferability 性能，没有结论性的证据表明 MTL 的特征学习能够提供更好的 Transferability 性能。总之，研究发现了 STL 和 MTL 之间的差异不大，建议在这两个领域之间共享方法。<details>
<summary>Abstract</summary>
While multi-task learning (MTL) has gained significant attention in recent years, its underlying mechanisms remain poorly understood. Recent methods did not yield consistent performance improvements over single task learning (STL) baselines, underscoring the importance of gaining more profound insights about challenges specific to MTL. In our study, we challenge common assumptions in MTL in the context of STL: First, the choice of optimizer has only been mildly investigated in MTL. We show the pivotal role of common STL tools such as the Adam optimizer in MTL. We deduce the effectiveness of Adam to its partial loss-scale invariance. Second, the notion of gradient conflicts has often been phrased as a specific problem in MTL. We delve into the role of gradient conflicts in MTL and compare it to STL. For angular gradient alignment we find no evidence that this is a unique problem in MTL. We emphasize differences in gradient magnitude as the main distinguishing factor. Lastly, we compare the transferability of features learned through MTL and STL on common image corruptions, and find no conclusive evidence that MTL leads to superior transferability. Overall, we find surprising similarities between STL and MTL suggesting to consider methods from both fields in a broader context.
</details>
<details>
<summary>摘要</summary>
MTL（多任务学习）在最近几年内得到了广泛关注，但它的内部机制仍然不够了解。现有方法未能在单任务学习（STL）基础上提供一致性的性能提升，这反映了更深入地理解MTL的挑战。在我们的研究中，我们挑战MTL中常见的假设：首先，MTL中选择优化器的研究只是轻微的。我们表明了通用STL工具such as Adam优化器在MTL中的重要作用。我们认为Adam的有效性归功于它部分损失尺度的不变性。第二，在MTL中gradient conflicts这个概念经常被认为是一个特有的问题。我们探讨MTL中gradient conflicts的角色，并与STL进行比较。对于angular gradient alignment，我们未能发现MTL中的独特问题。我们强调了gradient magnitude的差异作为主要的区别。最后，我们比较了MTL和STL在常见图像损害上学习的特征的传递性，并未发现MTL在这个方面的明显优势。总之，我们发现了MTL和STL之间的意外相似之处，建议在更广泛的上下文中考虑这两个领域的方法。
</details></li>
</ul>
<hr>
<h2 id="Diff-HierVC-Diffusion-based-Hierarchical-Voice-Conversion-with-Robust-Pitch-Generation-and-Masked-Prior-for-Zero-shot-Speaker-Adaptation"><a href="#Diff-HierVC-Diffusion-based-Hierarchical-Voice-Conversion-with-Robust-Pitch-Generation-and-Masked-Prior-for-Zero-shot-Speaker-Adaptation" class="headerlink" title="Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation"></a>Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04693">http://arxiv.org/abs/2311.04693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hayeong0/Diff-HierVC">https://github.com/hayeong0/Diff-HierVC</a></li>
<li>paper_authors: Ha-Yeong Choi, Sang-Hoon Lee, Seong-Whan Lee</li>
<li>for:  Addressing the challenges of inaccurate pitch and low speaker adaptation quality in existing voice conversion (VC) systems.</li>
<li>methods:  Introducing Diff-HierVC, a hierarchical VC system based on two diffusion models, including DiffPitch and DiffVoice, with a source-filter encoder and masked prior to improve pitch generation and voice style transfer.</li>
<li>results:  Experimental results show the superiority of the proposed model in pitch generation and voice style transfer performance, with a CER of 0.83% and EER of 3.29% in zero-shot VC scenarios.<details>
<summary>Abstract</summary>
Although voice conversion (VC) systems have shown a remarkable ability to transfer voice style, existing methods still have an inaccurate pitch and low speaker adaptation quality. To address these challenges, we introduce Diff-HierVC, a hierarchical VC system based on two diffusion models. We first introduce DiffPitch, which can effectively generate F0 with the target voice style. Subsequently, the generated F0 is fed to DiffVoice to convert the speech with a target voice style. Furthermore, using the source-filter encoder, we disentangle the speech and use the converted Mel-spectrogram as a data-driven prior in DiffVoice to improve the voice style transfer capacity. Finally, by using the masked prior in diffusion models, our model can improve the speaker adaptation quality. Experimental results verify the superiority of our model in pitch generation and voice style transfer performance, and our model also achieves a CER of 0.83% and EER of 3.29% in zero-shot VC scenarios.
</details>
<details>
<summary>摘要</summary>
although voice conversion (VC) systems have shown remarkable ability to transfer voice style, existing methods still have inaccurate pitch and low speaker adaptation quality. to address these challenges, we introduce Diff-HierVC, a hierarchical VC system based on two diffusion models. we first introduce DiffPitch, which can effectively generate F0 with target voice style. subsequently, the generated F0 is fed to DiffVoice to convert speech with target voice style. furthermore, using source-filter encoder, we disentangle speech and use converted Mel-spectrogram as data-driven prior in DiffVoice to improve voice style transfer capacity. finally, by using masked prior in diffusion models, our model can improve speaker adaptation quality. experimental results verify superiority of our model in pitch generation and voice style transfer performance, and our model also achieves CER of 0.83% and EER of 3.29% in zero-shot VC scenarios.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Pre-training-LLMs-using-human-like-development-data-corpus"><a href="#Pre-training-LLMs-using-human-like-development-data-corpus" class="headerlink" title="Pre-training LLMs using human-like development data corpus"></a>Pre-training LLMs using human-like development data corpus</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04666">http://arxiv.org/abs/2311.04666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma</li>
<li>for: 这篇论文是为了检验大型自然语言模型（LLM）在语言理解和推理任务中的能力。</li>
<li>methods: 这篇论文使用了大量的Raw文本数据进行预训练，并对LLM的预训练进行比较，以评估LLM在语言学习中的能力。</li>
<li>results: 这篇论文通过对LLM的预训练和不同架构的评估，以及对不同评估指标的分析，提供了一个强大的基准集。<details>
<summary>Abstract</summary>
Pre-trained Large Language Models (LLMs) have shown success in a diverse set of language inference and understanding tasks. The pre-training stage of LLMs looks at a large corpus of raw textual data. The BabyLM shared task compares LLM pre-training to human language acquisition, where the number of tokens seen by 13-year-old kids is magnitudes smaller than the number of tokens seen by LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn contextual word representations using roughly the same number of tokens as seen by children. We provide a strong set of baselines; with different architectures, evaluation of changes in performance across epochs, and reported pre-training metrics for the strict small and strict tracks of the task. We also try to loosely replicate the RoBERTa baseline given by the task organizers to observe the training robustness to hyperparameter selection and replicability. We provide the submission details to the strict and strict-small tracks in this report.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种语言理解和理解任务中表现出色。LLM的预训练阶段会查看大量的Raw文本数据。在这项工作中，我们将LLM预训练和评估其学习上下文字表示的能力，使用与13岁孩子看到的Token数量相似的数量。我们提供了一个强大的基elines，包括不同的架构、评估变化过程中的表现、和遵循严格规则的小轨道任务的预训练指标。我们还尝试了使用RoBERTa基线来评估模型的训练稳定性和可重现性。在这份报告中，我们提供了预训练和评估的详细信息，以及提交至严格和小轨道track的细节。
</details></li>
</ul>
<hr>
<h2 id="Pragmatic-Reasoning-Unlocks-Quantifier-Semantics-for-Foundation-Models"><a href="#Pragmatic-Reasoning-Unlocks-Quantifier-Semantics-for-Foundation-Models" class="headerlink" title="Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models"></a>Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04659">http://arxiv.org/abs/2311.04659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Li, Rakesh R. Menon, Sayan Ghosh, Shashank Srivastava</li>
<li>for: This paper is written to explore the ability of recent foundation models to understand generalized quantifiers in natural language, specifically in the context of percentage-equipped predicates.</li>
<li>methods: The paper uses a crowd-sourced dataset of human-annotated generalized quantifiers in Wikipedia sentences, called QuRe, and a framework called PRESQUE, which combines natural language inference and the Rational Speech Acts framework, to examine quantifier comprehension in language models.</li>
<li>results: The experimental results on the HVD dataset and QuRe show that PRESQUE, which employs pragmatic reasoning, performs 20% better than a literal reasoning baseline when predicting quantifier percentage scopes, with no additional training required.<details>
<summary>Abstract</summary>
Generalized quantifiers (e.g., few, most) are used to indicate the proportions predicates are satisfied (for example, some apples are red). One way to interpret quantifier semantics is to explicitly bind these satisfactions with percentage scopes (e.g., 30%-40% of apples are red). This approach can be helpful for tasks like logic formalization and surface-form quantitative reasoning (Gordon and Schubert, 2010; Roy et al., 2015). However, it remains unclear if recent foundation models possess this ability, as they lack direct training signals. To explore this, we introduce QuRe, a crowd-sourced dataset of human-annotated generalized quantifiers in Wikipedia sentences featuring percentage-equipped predicates. We explore quantifier comprehension in language models using PRESQUE, a framework that combines natural language inference and the Rational Speech Acts framework. Experimental results on the HVD dataset and QuRe illustrate that PRESQUE, employing pragmatic reasoning, performs 20% better than a literal reasoning baseline when predicting quantifier percentage scopes, with no additional training required.
</details>
<details>
<summary>摘要</summary>
通用量词（例如，很少、大多数）用于指示Predicate的满足程度（例如，一些苹果是红色的）。一种方法来理解量词 semantics是将这些满足绑定到 percentage 范围（例如，30%-40% 的苹果是红色的）。这种方法可以帮助Tasks like 逻辑化和表面形式量化思维（Gordon and Schubert, 2010; Roy et al., 2015）。然而，未知是否最近的基础模型拥有这种能力，因为它们缺乏直接的训练信号。为了探索这一点，我们引入 QuRe，一个人工标注的通用量词在Wikipedia句子中 featuring percentage-equipped predicates 的数据集。我们使用 PRESQUE，一个 combine natural language inference 和 rational speech acts 框架，来探索量词理解的语言模型。实验结果表明，PRESQUE，通过使用 Pragmatic reasoning，在 HVD 数据集和 QuRe 上预测量词 percentage scope 时，与 Literal reasoning baseline 相比，提高了 20%。无需额外训练。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Focal-and-Full-Range-Attention-Based-Graph-Transformers"><a href="#Hybrid-Focal-and-Full-Range-Attention-Based-Graph-Transformers" class="headerlink" title="Hybrid Focal and Full-Range Attention Based Graph Transformers"></a>Hybrid Focal and Full-Range Attention Based Graph Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04653">http://arxiv.org/abs/2311.04653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minhong Zhu, Zhenhao Zhao, Weiran Cai</li>
<li>for: 本研究旨在提高图像学习中的全范围相关性和本地信息抽取。</li>
<li>methods: 本文提出了一种纯注意力基 architecture，即焦点和全范围图像Transformer (FFGT)，通过组合全范围注意力和K-hop焦点注意力来捕捉全范围和本地信息。</li>
<li>results:  compared with传统图像Transformer，FFGT能够更好地捕捉到图像中的子结构信息，并在多个开放数据集上提高现有图像Transformer的性能。<details>
<summary>Abstract</summary>
The paradigm of Transformers using the self-attention mechanism has manifested its advantage in learning graph-structured data. Yet, Graph Transformers are capable of modeling full range dependencies but are often deficient in extracting information from locality. A common practice is to utilize Message Passing Neural Networks (MPNNs) as an auxiliary to capture local information, which however are still inadequate for comprehending substructures. In this paper, we present a purely attention-based architecture, namely Focal and Full-Range Graph Transformer (FFGT), which can mitigate the loss of local information in learning global correlations. The core component of FFGT is a new mechanism of compound attention, which combines the conventional full-range attention with K-hop focal attention on ego-nets to aggregate both global and local information. Beyond the scope of canonical Transformers, the FFGT has the merit of being more substructure-aware. Our approach enhances the performance of existing Graph Transformers on various open datasets, while achieves compatible SOTA performance on several Long-Range Graph Benchmark (LRGB) datasets even with a vanilla transformer. We further examine influential factors on the optimal focal length of attention via introducing a novel synthetic dataset based on SBM-PATTERN.
</details>
<details>
<summary>摘要</summary>
transformers 使用自注意机制的 paradigm 在学习图Structured data 中得到了明显的优势。然而，图Transformers 可以模型全范围的相关性，但通常缺乏本地信息提取的能力。为了解决这个问题，通常是使用 Message Passing Neural Networks (MPNNs) 作为辅助来捕捉本地信息，但这些 MPNNs 仍然无法理解子结构。在这篇论文中，我们提出了一种纯注意力基 Architecture，即 Focal and Full-Range Graph Transformer (FFGT)，可以减少学习全范围相关性时的本地信息损失。FFGT 的核心组件是一种新的合并注意力机制，其将全范围注意力与 K-hop 焦点注意力在egos 上合并，以兼容全范围和本地信息。与传统 Transformers 不同，FFGT 更加注意到 substructure。我们的方法可以提高现有 Graph Transformers 的性能在各种开放数据集上，同时在一些 Long-Range Graph Benchmark (LRGB) 数据集上具有 compatible SOTA 性能，即使使用 vanilla transformer。我们还通过引入一个新的人工数据集来探讨关键的焦点长度对注意力的影响。
</details></li>
</ul>
<hr>
<h2 id="SKU-Patch-Towards-Efficient-Instance-Segmentation-for-Unseen-Objects-in-Auto-Store"><a href="#SKU-Patch-Towards-Efficient-Instance-Segmentation-for-Unseen-Objects-in-Auto-Store" class="headerlink" title="SKU-Patch: Towards Efficient Instance Segmentation for Unseen Objects in Auto-Store"></a>SKU-Patch: Towards Efficient Instance Segmentation for Unseen Objects in Auto-Store</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04645">http://arxiv.org/abs/2311.04645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biqi Yang, Weiliang Tang, Xiaojie Gao, Xianzhi Li, Yun-Hui Liu, Chi-Wing Fu, Pheng-Ann Heng</li>
<li>for: 大规模的仓库中，精准的实例标识是机器人搬运板的关键，但是获得它们是困难的。这篇论文提出了SKU-Patch方法，只需要将每个新的SKU输入到网络中，使用几个图像块来预测准确和稳定的掩码，不需要繁琐的手动努力和模型重新训练。</li>
<li>methods: 我们设计了一种基于 transformer 网络的新方法，包括（i）一个图像块相关捕获器来捕捉多级图像特征，和（ii）一个图像块相关的 transformer 解码器来生成实例掩码。</li>
<li>results: 我们在四个仓库 benchmark 上进行了广泛的实验，显示 SKU-Patch 可以在状态的方法之上获得最好的性能。此外，SKU-Patch 在机器人协助自动仓库物流管线中，对超过50个未看过的 SKU 进行了100%的抓取成功率，说明它的实用性和实际性。<details>
<summary>Abstract</summary>
In large-scale storehouses, precise instance masks are crucial for robotic bin picking but are challenging to obtain. Existing instance segmentation methods typically rely on a tedious process of scene collection, mask annotation, and network fine-tuning for every single Stock Keeping Unit (SKU). This paper presents SKU-Patch, a new patch-guided instance segmentation solution, leveraging only a few image patches for each incoming new SKU to predict accurate and robust masks, without tedious manual effort and model re-training. Technical-wise, we design a novel transformer-based network with (i) a patch-image correlation encoder to capture multi-level image features calibrated by patch information and (ii) a patch-aware transformer decoder with parallel task heads to generate instance masks. Extensive experiments on four storehouse benchmarks manifest that SKU-Patch is able to achieve the best performance over the state-of-the-art methods. Also, SKU-Patch yields an average of nearly 100% grasping success rate on more than 50 unseen SKUs in a robot-aided auto-store logistic pipeline, showing its effectiveness and practicality.
</details>
<details>
<summary>摘要</summary>
大规模的存储设施中，精准的实例掩模是重要的，但它们具有困难的获取。现有的实例分割方法通常需要繁琐的场景收集、掩模注释和网络微调，对于每个存储单位（SKU）来说。这篇论文提出了SKU-Patch，一种新的 patch-guided实例分割解决方案，通过使用每个新来 SKU 的只需要几个图像块来预测准确和Robust的掩模，而无需繁琐的手动努力和网络重新训练。技术上，我们设计了一种基于 transformer 网络的 novel 结构，包括：（i）图像块与图像相关 encode 器，用于捕捉多级图像特征，并与块信息进行协调。（ii）图像块意识 transformer 解码器，包括并行任务头，用于生成实例掩模。广泛的实验证明，SKU-Patch 能够在四个存储准 benchmark 上达到最佳性能，并且在 robot-aided 自动存储链中，SKU-Patch 实现了大约 100% 的抓取成功率，对于超过 50 个未看到的 SKU 来说，表明它的实用性和实际性。
</details></li>
</ul>
<hr>
<h2 id="Object-Centric-Learning-with-Slot-Mixture-Module"><a href="#Object-Centric-Learning-with-Slot-Mixture-Module" class="headerlink" title="Object-Centric Learning with Slot Mixture Module"></a>Object-Centric Learning with Slot Mixture Module</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04640">http://arxiv.org/abs/2311.04640</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniil Kirilenko, Vitaliy Vorobyov, Alexey K. Kovalev, Aleksandr I. Panov</li>
<li>for: 这个论文主要针对对象中心架构中的插槽问题，即如何在对象中心架构中分割对象到不同的插槽中。</li>
<li>methods: 这个论文使用了一种可学习的归一化方法，基于 Gaussian Mixture Model，来解决插槽问题。这种方法不仅使用气球中心来表示插槽，还使用气球之间的距离信息来增强插槽表示的表达力。</li>
<li>results: 在对象中心架构中，使用这种方法取代了Slot Attention方法，可以提高对象检测和分类等任务的性能，达到了当前最佳的结果。<details>
<summary>Abstract</summary>
Object-centric architectures usually apply a differentiable module to the entire feature map to decompose it into sets of entity representations called slots. Some of these methods structurally resemble clustering algorithms, where the cluster's center in latent space serves as a slot representation. Slot Attention is an example of such a method, acting as a learnable analog of the soft k-means algorithm. Our work employs a learnable clustering method based on the Gaussian Mixture Model. Unlike other approaches, we represent slots not only as centers of clusters but also incorporate information about the distance between clusters and assigned vectors, leading to more expressive slot representations. Our experiments demonstrate that using this approach instead of Slot Attention improves performance in object-centric scenarios, achieving state-of-the-art results in the set property prediction task.
</details>
<details>
<summary>摘要</summary>
通常，对象中心的架构会应用一个可导模块到整个特征地图，以分解它成各个实体表示（slot）的集合。一些方法structurally类似于聚类算法，其中聚集中的中心在幽重空间服为slot表示。插槽注意力是一such方法，作为可学习的软k-means算法。我们的工作使用可学习的聚类方法基于泊松分布。与其他方法不同的是，我们不仅将插槽表示为聚集中心，还会 incorporate各个聚集与分配 vectors 之间的距离信息，从而获得更 expresive的插槽表示。我们的实验表明，使用这种方法而不是插槽注意力可以在对象中心的enario中提高表现，实现了set property prediction任务的州立�elterformance。
</details></li>
</ul>
<hr>
<h2 id="LuminanceL1Loss-A-loss-function-which-measures-percieved-brightness-and-colour-differences"><a href="#LuminanceL1Loss-A-loss-function-which-measures-percieved-brightness-and-colour-differences" class="headerlink" title="LuminanceL1Loss: A loss function which measures percieved brightness and colour differences"></a>LuminanceL1Loss: A loss function which measures percieved brightness and colour differences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04614">http://arxiv.org/abs/2311.04614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominic De Jonge</li>
<li>for: 这个论文是为了提高图像恢复任务的性能而设计的一种新的损失函数。</li>
<li>methods: 该论文提出了一种新的损失函数，即LuminanceL1Loss，它将图像转换成灰度图像，并计算灰度和颜色通道之间的MSE损失。</li>
<li>results: 实验结果表明，LuminanceL1Loss在Retinexformer、BUIFD和DnCNN等 arquitectures上表现出优于传统方法，并且在图像压缩和相关的图像重建任务中获得了较高的性能。具体来说，LuminanceL1Loss在这些任务中获得了4.7dB的提升。<details>
<summary>Abstract</summary>
We introduce LuminanceL1Loss, a novel loss function designed to enhance the performance of image restoration tasks. We demonstrate its superiority over MSE when applied to the Retinexformer, BUIFD and DnCNN architectures. Our proposed LuminanceL1Loss leverages a unique approach by transforming images into grayscale and subsequently computing the MSE loss for both grayscale and color channels. Experimental results demonstrate that this innovative loss function consistently outperforms traditional methods, showcasing its potential in image denoising and other related tasks in image reconstruction. It demonstrates gains up to 4.7dB. The results presented in this study highlight the efficacy of LuminanceL1Loss for various image restoration tasks.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的损失函数，即LuminanceL1Loss，用于提高图像修复任务的性能。我们在Retinexformer、BUIFD和DnCNN架构上运行了实验，并证明了我们的提案的LuminanceL1Loss在这些架构上具有独特的优势。我们的LuminanceL1Loss方法首先将图像转换为灰度图像，然后计算灰度和颜色通道之间的MSE损失。实验结果表明，这种创新的损失函数在图像减去和相关的图像重建任务中表现出色，其性能提高至4.7dB。这些结果证明了LuminanceL1Loss的可靠性和可行性，并且可以在图像修复任务中得到广泛的应用。
</details></li>
</ul>
<hr>
<h2 id="TEAL-Tokenize-and-Embed-ALL-for-Multi-modal-Large-Language-Models"><a href="#TEAL-Tokenize-and-Embed-ALL-for-Multi-modal-Large-Language-Models" class="headerlink" title="TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models"></a>TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04589">http://arxiv.org/abs/2311.04589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Yang, Yingxue Zhang, Fandong Meng, Jie Zhou</li>
<li>for: 本文旨在提高多模态大型语言模型（MM-LLMs）的效率，使其更好地模型多modal输入的交互和非文字输出的生成。</li>
<li>methods: 本文提出了一种名为TEAL（Tokenize and Embed ALl）的方法，即将输入从任何模态转换为token序列，并学习所有modalities的共享 embedding空间。</li>
<li>results: 实验显示，TEAL可以 achieve substantial improvements in multi-modal understanding, 并且实现了一种简单的多modal生成方案。<details>
<summary>Abstract</summary>
Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in non-textual modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an approach to treat the input from any modality as a token sequence and learn a joint embedding space for all modalities. Specifically, for the input from any modality, TEAL first discretizes it into a token sequence with the off-the-shelf tokenizer and embeds the token sequence into a joint embedding space with a learnable embedding matrix. MM-LLMs just need to predict the multi-modal tokens autoregressively as the textual LLMs do. Finally, the corresponding de-tokenizer is applied to generate the output in each modality based on the predicted token sequence. With the joint embedding space, TEAL enables the frozen LLMs to perform both understanding and generation tasks involving non-textual modalities, such as image and audio. Thus, the textual LLM can just work as an interface and maintain its high performance in textual understanding and generation. Experiments show that TEAL achieves substantial improvements in multi-modal understanding, and implements a simple scheme for multi-modal generations.
</details>
<details>
<summary>摘要</summary>
尽管多模态大型语言模型（MM-LLMs）在最近已经做出了各种激进的进步，但它们仍然努力地模型多模态输入和非文本类Modalities中的交互。在这项工作中，我们提出了TEAL（Tokenize and Embed ALl），一种方法，它将任何模态的输入转换为token序列，并学习所有模态的共同嵌入空间。具体来说，对于任何模态的输入，TEAL首先将其拆分成一个token序列，使用可用的tokenizer进行拆分，然后将token序列嵌入到一个可学习的嵌入矩阵中。MM-LLMs只需要预测多模态的token序列，就像文本LLMs一样。最后，通过预测的token序列，通过对应的de-tokenizer来生成每个模态的输出。由于joint嵌入空间，TEAL使得冻结LLMs可以在不同的模态上进行理解和生成任务，如图像和音频。因此，文本LLM只需要作为界面，并保持其高效性在文本理解和生成任务中。实验表明，TEAL在多模态理解方面实现了显著的提升，并实现了简单的多模态生成方案。
</details></li>
</ul>
<hr>
<h2 id="Army-of-Thieves-Enhancing-Black-Box-Model-Extraction-via-Ensemble-based-sample-selection"><a href="#Army-of-Thieves-Enhancing-Black-Box-Model-Extraction-via-Ensemble-based-sample-selection" class="headerlink" title="Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection"></a>Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based sample selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04588">http://arxiv.org/abs/2311.04588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akshitjindal1/aot_wacv">https://github.com/akshitjindal1/aot_wacv</a></li>
<li>paper_authors: Akshit Jindal, Vikram Goyal, Saket Anand, Chetan Arora</li>
<li>for: 这个论文的目的是提出一种基于ensemble学习模型的Model Stealing Attack（MSA）方法，以提高对于部署在服务器上的机器学习模型的攻击性能。</li>
<li>methods: 这个论文使用了一个 ensemble of deep learning models 作为攻击者模型（thief model），并采用了一种基于 ensemble 的选择方法来选择最有用的数据点。</li>
<li>results: 论文的实验结果表明，使用 ensemble of thief models 可以提高对于Model Stealing Attack的效率和可靠性，并且可以达到3%以上的提升和21%的高于前一个工作的对抗样本传递率。<details>
<summary>Abstract</summary>
Machine Learning (ML) models become vulnerable to Model Stealing Attacks (MSA) when they are deployed as a service. In such attacks, the deployed model is queried repeatedly to build a labelled dataset. This dataset allows the attacker to train a thief model that mimics the original model. To maximize query efficiency, the attacker has to select the most informative subset of data points from the pool of available data. Existing attack strategies utilize approaches like Active Learning and Semi-Supervised learning to minimize costs. However, in the black-box setting, these approaches may select sub-optimal samples as they train only one thief model. Depending on the thief model's capacity and the data it was pretrained on, the model might even select noisy samples that harm the learning process. In this work, we explore the usage of an ensemble of deep learning models as our thief model. We call our attack Army of Thieves(AOT) as we train multiple models with varying complexities to leverage the crowd's wisdom. Based on the ensemble's collective decision, uncertain samples are selected for querying, while the most confident samples are directly included in the training data. Our approach is the first one to utilize an ensemble of thief models to perform model extraction. We outperform the base approaches of existing state-of-the-art methods by at least 3% and achieve a 21% higher adversarial sample transferability than previous work for models trained on the CIFAR-10 dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GResilience-Trading-Off-Between-the-Greenness-and-the-Resilience-of-Collaborative-AI-Systems"><a href="#GResilience-Trading-Off-Between-the-Greenness-and-the-Resilience-of-Collaborative-AI-Systems" class="headerlink" title="GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems"></a>GResilience: Trading Off Between the Greenness and the Resilience of Collaborative AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04569">http://arxiv.org/abs/2311.04569</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diaeddin Rimawi, Antonio Liotta, Marco Todescato, Barbara Russo</li>
<li>for: 本研究旨在提供一种自动评估CAIS恢复行动的能力，以优化系统的可恢复性和绿色性之间的贝叶问题。</li>
<li>methods: 本研究使用了一种携程优化方法和两种游戏理论方法来评估CAIS恢复行动的可恢复性和绿色性。</li>
<li>results: 研究表明，通过使用携程优化方法和游戏理论方法，可以自动评估CAIS恢复行动的可恢复性和绿色性，并且可以通过考虑系统的可恢复性和绿色性来决策。<details>
<summary>Abstract</summary>
A Collaborative Artificial Intelligence System (CAIS) works with humans in a shared environment to achieve a common goal. To recover from a disruptive event that degrades its performance and ensures its resilience, a CAIS may then need to perform a set of actions either by the system, by the humans, or collaboratively together. As for any other system, recovery actions may cause energy adverse effects due to the additional required energy. Therefore, it is of paramount importance to understand which of the above actions can better trade-off between resilience and greenness. In this in-progress work, we propose an approach to automatically evaluate CAIS recovery actions for their ability to trade-off between the resilience and greenness of the system. We have also designed an experiment protocol and its application to a real CAIS demonstrator. Our approach aims to attack the problem from two perspectives: as a one-agent decision problem through optimization, which takes the decision based on the score of resilience and greenness, and as a two-agent decision problem through game theory, which takes the decision based on the payoff computed for resilience and greenness as two players of a cooperative game.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CAIS-DMA-A-Decision-Making-Assistant-for-Collaborative-AI-Systems"><a href="#CAIS-DMA-A-Decision-Making-Assistant-for-Collaborative-AI-Systems" class="headerlink" title="CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems"></a>CAIS-DMA: A Decision-Making Assistant for Collaborative AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04562">http://arxiv.org/abs/2311.04562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmrimawi/cais-dma">https://github.com/dmrimawi/cais-dma</a></li>
<li>paper_authors: Diaeddin Rimawi, Antonio Lotta, Marco Todescato, Barbara Russo</li>
<li>for: 这个论文旨在提出一种自动支持智能系统决策过程中的人工智能模型，以适应系统经历突发事件后的性能下降。</li>
<li>methods: 该论文提出了一种框架，包括三个组成部分：一个管理或模拟智能系统环境和突发事件，第二个自动化决策过程，第三个提供智能系统行为的可见分析。</li>
<li>results: 该框架可以自动监测智能系统决策过程，在性能下降时进行交互，并建议下一个动作，以保证坚持系统的稳定运行和可持续发展。在一个实际的共同 робоット示例中，该框架建议了一个平衡于减少恢复时间（即可靠性）和减少能源副作用（即绿色）的下一个动作。<details>
<summary>Abstract</summary>
A Collaborative Artificial Intelligence System (CAIS) is a cyber-physical system that learns actions in collaboration with humans in a shared environment to achieve a common goal. In particular, a CAIS is equipped with an AI model to support the decision-making process of this collaboration. When an event degrades the performance of CAIS (i.e., a disruptive event), this decision-making process may be hampered or even stopped. Thus, it is of paramount importance to monitor the learning of the AI model, and eventually support its decision-making process in such circumstances. This paper introduces a new methodology to automatically support the decision-making process in CAIS when the system experiences performance degradation after a disruptive event. To this aim, we develop a framework that consists of three components: one manages or simulates CAIS's environment and disruptive events, the second automates the decision-making process, and the third provides a visual analysis of CAIS behavior. Overall, our framework automatically monitors the decision-making process, intervenes whenever a performance degradation occurs, and recommends the next action. We demonstrate our framework by implementing an example with a real-world collaborative robot, where the framework recommends the next action that balances between minimizing the recovery time (i.e., resilience), and minimizing the energy adverse effects (i.e., greenness).
</details>
<details>
<summary>摘要</summary>
一个协同人工智能系统（CAIS）是一个跨物理和软件的系统，它在人类和机器之间共同学习行为，以实现共同目标。特别是，CAIS配备了一个人工智能模型，以支持决策过程中的协同合作。当系统经历破坏性事件（例如，灾难性事件）时，这个决策过程可能受挫或甚至停止。因此，监测人工智能模型的学习过程是极为重要的。为此，我们提出了一种新的方法，可以自动支持CAIS的决策过程在系统经历破坏性事件后。我们的框架由三个组件组成：一个负责或模拟CAIS的环境和破坏性事件，第二个自动化决策过程，第三个提供了CAIS行为的视觉分析。总的来说，我们的框架可以自动监测决策过程，在破坏性事件发生时进行 вмешательство，并提供下一步操作的建议。我们通过在实际合作 робоット上实现这个框架，并证明了它可以帮助系统快速恢复，同时减少能源消耗。
</details></li>
</ul>
<hr>
<h2 id="Local-Differential-Privacy-for-Smart-Meter-Data-Sharing"><a href="#Local-Differential-Privacy-for-Smart-Meter-Data-Sharing" class="headerlink" title="Local Differential Privacy for Smart Meter Data Sharing"></a>Local Differential Privacy for Smart Meter Data Sharing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04544">http://arxiv.org/abs/2311.04544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yashothara Shanmugarasa, M. A. P. Chamikara, Hye-young Paik, Salil S. Kanhere, Liming Zhu</li>
<li>for: 本研究旨在提供一种基于智能计量数据的能源分解技术，以提供消费者和能源公司有价值的能源管理信息。</li>
<li>methods: 本研究使用了本地权限保护（LDP）方法，以保证个人能源消耗数据的隐私。</li>
<li>results: 我们的评估结果表明，LDP-SmartEnergy比基线方法更高效。结果还示出，我们的解决方案能够保护个人隐私，同时仍然维护数据的有用性。<details>
<summary>Abstract</summary>
Energy disaggregation techniques, which use smart meter data to infer appliance energy usage, can provide consumers and energy companies valuable insights into energy management. However, these techniques also present privacy risks, such as the potential for behavioral profiling. Local differential privacy (LDP) methods provide strong privacy guarantees with high efficiency in addressing privacy concerns. However, existing LDP methods focus on protecting aggregated energy consumption data rather than individual appliances. Furthermore, these methods do not consider the fact that smart meter data are a form of streaming data, and its processing methods should account for time windows. In this paper, we propose a novel LDP approach (named LDP-SmartEnergy) that utilizes randomized response techniques with sliding windows to facilitate the sharing of appliance-level energy consumption data over time while not revealing individual users' appliance usage patterns. Our evaluations show that LDP-SmartEnergy runs efficiently compared to baseline methods. The results also demonstrate that our solution strikes a balance between protecting privacy and maintaining the utility of data for effective analysis.
</details>
<details>
<summary>摘要</summary>
智能仪表数据分解技术可以为消费者和能源公司提供有价值的能源管理信息，但这些技术也存在隐私风险，如行为见解潜在风险。本地隐私（LDP）方法可以提供强有力的隐私保证，但现有LDP方法主要关注于保护积合能源消耗数据而不是各个家用电器。此外，这些方法未考虑智能仪表数据是流动数据，其处理方法应该考虑时间窗口。本文提出了一种新的LDP方法（名为LDP-SmartEnergy），该方法使用随机响应技术和滑动窗口来帮助在时间窗口内分享家用电器级别的能源消耗数据，而不泄露个人用户的家用电器使用模式。我们的评估结果表明，LDP-SmartEnergy可以高效地与基eline方法进行比较。结果还示出，我们的解决方案能够保持隐私和数据分析的实用性之间的平衡。
</details></li>
</ul>
<hr>
<h2 id="RankAug-Augmented-data-ranking-for-text-classification"><a href="#RankAug-Augmented-data-ranking-for-text-classification" class="headerlink" title="RankAug: Augmented data ranking for text classification"></a>RankAug: Augmented data ranking for text classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04535">http://arxiv.org/abs/2311.04535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiasa Singha Roy, Priyam Basu</li>
<li>for: 本研究旨在强调数据生成和增强方法的研究，尤其是用于评估生成数据的评价方法。</li>
<li>methods: 本研究提出了一种文本排名方法（RankAug），用于检测和过滤最相似的生成文本，以提高NLU任务的准确率。</li>
<li>results: 经过多个数据集的实验表明，通过精准地选择筛选技术可以提高弱化类准确率，最高提高35%。<details>
<summary>Abstract</summary>
Research on data generation and augmentation has been focused majorly on enhancing generation models, leaving a notable gap in the exploration and refinement of methods for evaluating synthetic data. There are several text similarity metrics within the context of generated data filtering which can impact the performance of specific Natural Language Understanding (NLU) tasks, specifically focusing on intent and sentiment classification. In this study, we propose RankAug, a text-ranking approach that detects and filters out the top augmented texts in terms of being most similar in meaning with lexical and syntactical diversity. Through experiments conducted on multiple datasets, we demonstrate that the judicious selection of filtering techniques can yield a substantial improvement of up to 35% in classification accuracy for under-represented classes.
</details>
<details>
<summary>摘要</summary>
设研究重点在数据生成和扩展方面，主要是增强生成模型，忽略了评估 sintetic 数据的方法的探索和细化。在生成数据筛选中，存在许多文本相似度指标，这些指标可以影响特定自然语言理解（NLU）任务中的意图和情感分类的性能。本研究提出了 RankAug，一种文本排序方法，可以检测和过滤最相似的文本，以保证lexical和 sintactical 多样性。通过在多个数据集上进行实验，我们示出了选择合适的筛选技术可以提高under-represented 类别的分类精度，最高提高达35%。
</details></li>
</ul>
<hr>
<h2 id="Validating-ChatGPT-Facts-through-RDF-Knowledge-Graphs-and-Sentence-Similarity"><a href="#Validating-ChatGPT-Facts-through-RDF-Knowledge-Graphs-and-Sentence-Similarity" class="headerlink" title="Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence Similarity"></a>Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04524">http://arxiv.org/abs/2311.04524</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michalis Mountantonakis, Yannis Tzitzikas</li>
<li>for:  This paper aims to validate the responses of ChatGPT and enrich them with justifications and provenance using RDF Knowledge Graphs (KGs) and short sentence embeddings.</li>
<li>methods: The paper proposes a novel pipeline that retrieves the responses of ChatGPT in RDF and leverages DBpedia and LODsyndesis (an aggregated Knowledge Graph with 2 billion triples from 400 RDF KGs of many domains) to validate the ChatGPT facts and provide justifications and provenance.</li>
<li>results: The paper evaluates the effectiveness of its approach using an evaluation benchmark that includes 2,000 ChatGPT facts, and achieves promising results, verifying 85.3% of the correct facts of ChatGPT and finding the correct answer for 62.6% of the erroneous ChatGPT facts.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这个论文目标是验证ChatGPT的回答，并使用RDF知识Graph（KG）和短句嵌入来补充回答。</li>
<li>methods: 论文提出了一种新的管道，通过将ChatGPT的回答转换成RDF，然后利用DBpedia和LODsyndesis（一个包含400个RDF知识Graph的聚合知识Graph，包含200亿个三元组）来验证ChatGPT的事实，并提供证据和来源。</li>
<li>results: 论文使用2,000个ChatGPT事实作为评估指标，并取得了有优的结果，验证了ChatGPT的85.3%正确事实，并对27%错误事实中的62.6%错误事实提供了正确答案。<details>
<summary>Abstract</summary>
Since ChatGPT offers detailed responses without justifications, and erroneous facts even for popular persons, events and places, in this paper we present a novel pipeline that retrieves the response of ChatGPT in RDF and tries to validate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). To this end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graph that contains 2 billion triples from 400 RDF KGs of many domains) and short sentence embeddings, and introduce an algorithm that returns the more relevant triple(s) accompanied by their provenance and a confidence score. This enables the validation of ChatGPT responses and their enrichment with justifications and provenance. To evaluate this service (such services in general), we create an evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000 facts for famous Greek Persons, 500 facts for popular Greek Places, and 500 facts for Events related to Greece. The facts were manually labelled (approximately 73% of ChatGPT facts were correct and 27% of facts were erroneous). The results are promising; indicatively for the whole benchmark, we managed to verify the 85.3% of the correct facts of ChatGPT and to find the correct answer for the 62.6% of the erroneous ChatGPT facts.
</details>
<details>
<summary>摘要</summary>
自然语言模型ChatGPT提供了详细的回答，但有时会提供错误的信息，包括知名人物、事件和地点。为了 validate ChatGPT 的信息，我们提出了一个新的管道，它使用 RDF 格式来检索 ChatGPT 的回答，并使用一个或多个 RDF 知识图（KG）来验证 ChatGPT 的信息。我们利用 DBpedia 和 LODsyndesis（一个汇集了400个 RDF KG 的大型知识图），并使用短句嵌入，并引入一种算法，它可以返回更有关系的 triple（ triple 的来源和信任分数）。这使得可以验证 ChatGPT 的回答，并增加回答的证明和来源。为了评估这种服务，我们创建了一个评估标准，包括 2000 个 ChatGPT 信息，其中包括 1000 个希腊名人、500 个希腊地点和500 个关于希腊的事件。这些信息都是手动标注的（大约73%的 ChatGPT 信息是正确的，27%的信息是错误的）。结果是非常有希望的，例如，整个标准中，我们成功验证了 ChatGPT 的 85.3% 正确信息，并找到了错误信息的正确答案的 62.6%。
</details></li>
</ul>
<hr>
<h2 id="FFINet-Future-Feedback-Interaction-Network-for-Motion-Forecasting"><a href="#FFINet-Future-Feedback-Interaction-Network-for-Motion-Forecasting" class="headerlink" title="FFINet: Future Feedback Interaction Network for Motion Forecasting"></a>FFINet: Future Feedback Interaction Network for Motion Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04512">http://arxiv.org/abs/2311.04512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miao Kang, Shengqi Wang, Sanping Zhou, Ke Ye, Jingjing Jiang, Nanning Zheng</li>
<li>for: 预测 autonomous driving 中的动力趋势，目标是预测未来合理的交通代理人的运动轨迹。</li>
<li>methods: 提出了一种新的未来反馈互动网络（FFINet），用于聚合当前观察和未来互动的特征。该网络包括不同的空间-时间编码器、当前层、相互作用层、未来反馈层和全局融合层。</li>
<li>results: 对 Argoverse 1 和 Argoverse 2 动力预测 benchmark 进行了广泛的实验，并达到了当前最佳性能。<details>
<summary>Abstract</summary>
Motion forecasting plays a crucial role in autonomous driving, with the aim of predicting the future reasonable motions of traffic agents. Most existing methods mainly model the historical interactions between agents and the environment, and predict multi-modal trajectories in a feedforward process, ignoring potential trajectory changes caused by future interactions between agents. In this paper, we propose a novel Future Feedback Interaction Network (FFINet) to aggregate features the current observations and potential future interactions for trajectory prediction. Firstly, we employ different spatial-temporal encoders to embed the decomposed position vectors and the current position of each scene, providing rich features for the subsequent cross-temporal aggregation. Secondly, the relative interaction and cross-temporal aggregation strategies are sequentially adopted to integrate features in the current fusion module, observation interaction module, future feedback module and global fusion module, in which the future feedback module can enable the understanding of pre-action by feeding the influence of preview information to feedforward prediction. Thirdly, the comprehensive interaction features are further fed into final predictor to generate the joint predicted trajectories of multiple agents. Extensive experimental results show that our FFINet achieves the state-of-the-art performance on Argoverse 1 and Argoverse 2 motion forecasting benchmarks.
</details>
<details>
<summary>摘要</summary>
自动驾驶中的动作预测具有关键作用，目标是预测未来合理的交通代理人动作。现有的大多数方法主要是基于历史交互和环境的模型，预测多模态轨迹在推进过程中，忽略了未来交互所可能导致的轨迹变化。在这篇论文中，我们提出了一种新的未来反馈互动网络（FFINet），用于聚合特征。首先，我们采用不同的空间-时间编码器将分解的位坐标和当前Scene的位置编码为有富特征的特征。其次，我们采用相对互动和跨时间汇集策略来汇集特征，并在当前融合模块、观察互动模块、未来反馈模块和全局融合模块中顺序采用这些策略。其中，未来反馈模块可以使得我们理解预action的影响，通过预测信息来帮助推进预测。最后，我们将全面互动特征传递给最终预测器，以生成多个代理人的共同预测轨迹。我们的FFINet在Argoverse 1和Argoverse 2动作预测标准准确率上实现了状态革新的表现。
</details></li>
</ul>
<hr>
<h2 id="NExT-Chat-An-LMM-for-Chat-Detection-and-Segmentation"><a href="#NExT-Chat-An-LMM-for-Chat-Detection-and-Segmentation" class="headerlink" title="NExT-Chat: An LMM for Chat, Detection and Segmentation"></a>NExT-Chat: An LMM for Chat, Detection and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04498">http://arxiv.org/abs/2311.04498</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NExT-ChatV/NExT-Chat">https://github.com/NExT-ChatV/NExT-Chat</a></li>
<li>paper_authors: Ao Zhang, Liming Zhao, Chen-Wei Xie, Yun Zheng, Wei Ji, Tat-Seng Chua</li>
<li>for: 提高视觉理解水平，增强大型语言模型（LLMs）在多Modal理解领域的进步。</li>
<li>methods: 提出一种新的对象位置模型方法 called pixel2emb，让LMM输出位置嵌入并由不同的解码器解码，以适应不同的位置格式（如 bounding box 和 mask）在多Modal对话中。</li>
<li>results: 在有限资源的情况下，比现有SOTA方法 superior的性能在位置输入和输出任务中，并在多个任务 like visual grounding, region caption, 和grounded reasoning中展示了NExT-Chat模型的多任务处理能力。<details>
<summary>Abstract</summary>
The development of large language models (LLMs) has greatly advanced the field of multimodal understanding, leading to the emergence of large multimodal models (LMMs). In order to enhance the level of visual comprehension, recent studies have equipped LMMs with region-level understanding capabilities by representing object bounding box coordinates as a series of text sequences (pixel2seq). In this paper, we introduce a novel paradigm for object location modeling called pixel2emb method, where we ask the LMM to output the location embeddings and then decoded by different decoders. This paradigm allows for different location formats (such as bounding boxes and masks) to be used in multimodal conversations Furthermore, this kind of embedding based location modeling enables the utilization of existing practices in localization tasks, such as detection and segmentation. In scenarios with limited resources, our pixel2emb demonstrates superior performance compared to existing state-of-the-art (SOTA) approaches in both the location input and output tasks under fair comparison. Leveraging the proposed pixel2emb method, we train an LMM named NExT-Chat and demonstrate its capability of handling multiple tasks like visual grounding, region caption, and grounded reasoning.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的发展对多Modal理解领域带来了巨大的进步，导致大多Modal模型（LMM）的出现。为了提高视觉理解水平，latest studies have equipped LMMs with region-level understanding capabilities by representing object bounding box coordinates as a series of text sequences (pixel2seq).在本文中，我们介绍了一种新的对象位置模型方法，即pixel2emb方法，其中我们请求LMM输出位置嵌入，然后通过不同的解码器进行解码。这种嵌入基于位置模型方法允许不同的位置格式（如 bounding boxes和masks）在多Modal conversation中使用。此外，这种嵌入基于位置模型方法允许利用现有的localization任务实践，如检测和分割。在有限资源的情况下，我们的pixel2emb在位置输入和位置输出任务中显示出了与state-of-the-art（SOTA）方法相比的superior performance。基于提议的pixel2emb方法，我们训练了一个名为NExT-Chat的LMM，并证明其能处理多个任务，如视觉定位、区域描述和基于物理的理解。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-for-Earth-Observation-Current-Methods-Open-Challenges-and-Opportunities"><a href="#Explainable-AI-for-Earth-Observation-Current-Methods-Open-Challenges-and-Opportunities" class="headerlink" title="Explainable AI for Earth Observation: Current Methods, Open Challenges, and Opportunities"></a>Explainable AI for Earth Observation: Current Methods, Open Challenges, and Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04491">http://arxiv.org/abs/2311.04491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gulsen Taskin, Erchan Aptoula, Alp Ertürk</li>
<li>for: 本文旨在概述当前遥感 Earth observation 领域中 Explainable Artificial Intelligence 技术的应用。</li>
<li>methods: 本文使用了各种 Explainable Artificial Intelligence 技术，如 feature importance 分析、Attention 机制和 Saliency Map 等，来解释 Deep Learning 模型的决策过程。</li>
<li>results: 本文对多种 Earth observation 应用场景进行了系统性的概述，并通过实证研究表明了 Explainable Artificial Intelligence 技术可以有效地解释 Deep Learning 模型的决策过程，提高了模型的可解释性和可信度。<details>
<summary>Abstract</summary>
Deep learning has taken by storm all fields involved in data analysis, including remote sensing for Earth observation. However, despite significant advances in terms of performance, its lack of explainability and interpretability, inherent to neural networks in general since their inception, remains a major source of criticism. Hence it comes as no surprise that the expansion of deep learning methods in remote sensing is being accompanied by increasingly intensive efforts oriented towards addressing this drawback through the exploration of a wide spectrum of Explainable Artificial Intelligence techniques. This chapter, organized according to prominent Earth observation application fields, presents a panorama of the state-of-the-art in explainable remote sensing image analysis.
</details>
<details>
<summary>摘要</summary>
深度学习已经在数据分析领域的所有领域中夺得了风靡，包括地球观测Remote sensing。然而，尽管表现有了 significiant advances，但深度学习的不可解性和解释性问题仍然是批评的主要来源，这是神经网络的核心问题。因此，深度学习方法在Remote sensing领域的扩展是由增强Explainable Artificial Intelligence技术的努力陪伴着。这章，按照主要的地球观测应用领域分组，展示了当前在可解的Remote sensing图像分析方面的状况。
</details></li>
</ul>
<hr>
<h2 id="Emergent-Communication-for-Rules-Reasoning"><a href="#Emergent-Communication-for-Rules-Reasoning" class="headerlink" title="Emergent Communication for Rules Reasoning"></a>Emergent Communication for Rules Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04474">http://arxiv.org/abs/2311.04474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Guo, Yifan Hao, Rui Zhang, Enshuai Zhou, Zidong Du, Xishan Zhang, Xinkai Song, Yuanbo Wen, Yongwei Zhao, Xuehai Zhou, Jiaming Guo, Qi Yi, Shaohui Peng, Di Huang, Ruizhi Chen, Qi Guo, Yunji Chen</li>
<li>for: 本研究旨在探讨深度学习基本的代理人之间的emergent communication，以及这种communication在人工智能和语言学方面的灵感。</li>
<li>methods: 我们在这种认知导向的环境中提出了“理解游戏”，并使用了 Ravens Progressive Matrix 作为人类理解测试，以鼓励代理人推理和交流高级规则。我们还提出了一个不偏的数据集（称为 rule-RAVEN）作为评估标准，并采用了两个阶段的学习方法作为基eline。</li>
<li>results: 实验结果表明，在“理解游戏”中，代理人们能够沟通高级规则，并将其应用到未看过的上下文特性中。这种emerged语言帮助代理人们解决逻辑问题，并将其推广到不同上下文特性或任务中。<details>
<summary>Abstract</summary>
Research on emergent communication between deep-learning-based agents has received extensive attention due to its inspiration for linguistics and artificial intelligence. However, previous attempts have hovered around emerging communication under perception-oriented environmental settings, that forces agents to describe low-level perceptual features intra image or symbol contexts. In this work, inspired by the classic human reasoning test (namely Raven's Progressive Matrix), we propose the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules, rather than perceived low-level contexts. Moreover, we propose 1) an unbiased dataset (namely rule-RAVEN) as a benchmark to avoid overfitting, 2) and a two-stage curriculum agent training method as a baseline for more stable convergence in the Reasoning Game, where contexts and semantics are bilaterally drifting. Experimental results show that, in the Reasoning Game, a semantically stable and compositional language emerges to solve reasoning problems. The emerged language helps agents apply the extracted rules to the generalization of unseen context attributes, and to the transfer between different context attributes or even tasks.
</details>
<details>
<summary>摘要</summary>
研究深度学习基于代理人的 Emergent 通信已经受到了人工智能和语言学的关注，因为它可以启发人工智能和语言学。然而，之前的尝试都是在感知导向的环境中进行 Emergent 通信， forcing agents to describe low-level perceptual features within image or symbol contexts。在这项工作中，我们 draw inspiration from 人类理解测试（namely Raven's Progressive Matrix），并提出了理智游戏，一种认知导向的环境，鼓励代理人进行理性和沟通高级规则，而不是仅仅描述图像或符号上的低级感知特征。此外，我们还提出了以下两点：1）一个不偏袋式的数据集（namely rule-RAVEN）作为一个抗销毁的标准，2）和两stage 代理人训练方法作为一个基线，以便更稳定地在理智游戏中训练代理人。实验结果表明，在理智游戏中，代理人可以通过高级规则来解决理性问题，并且可以将抽象出来的规则应用到未看过的上下文特征上，以及不同上下文特征或任务之间的传递。
</details></li>
</ul>
<hr>
<h2 id="RDGCN-Reinforced-Dependency-Graph-Convolutional-Network-for-Aspect-based-Sentiment-Analysis"><a href="#RDGCN-Reinforced-Dependency-Graph-Convolutional-Network-for-Aspect-based-Sentiment-Analysis" class="headerlink" title="RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis"></a>RDGCN: Reinforced Dependency Graph Convolutional Network for Aspect-based Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04467">http://arxiv.org/abs/2311.04467</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rdgcn/rdgcn">https://github.com/rdgcn/rdgcn</a></li>
<li>paper_authors: Xusheng Zhao, Hao Peng, Qiong Dai, Xu Bai, Huailiang Peng, Yanbing Liu, Qinglang Guo, Philip S. Yu</li>
<li>for: 这种研究旨在提高非结构化 sentiment 分析（ABSA）的精度，通过使用图 neural networks 捕捉句子结构的 Patterns 来提高 ABSA 的性能。</li>
<li>methods: 这种方法使用 graph neural networks (GNNs) 来捕捉句子结构的 Patterns，并通过 reinforcement learning 来调整依赖关系的重要性。</li>
<li>results: 实验结果表明，该方法可以提高 ABSA 的性能，并在三个 популяр的 dataset 上出现最佳result。<details>
<summary>Abstract</summary>
Aspect-based sentiment analysis (ABSA) is dedicated to forecasting the sentiment polarity of aspect terms within sentences. Employing graph neural networks to capture structural patterns from syntactic dependency parsing has been confirmed as an effective approach for boosting ABSA. In most works, the topology of dependency trees or dependency-based attention coefficients is often loosely regarded as edges between aspects and opinions, which can result in insufficient and ambiguous syntactic utilization. To address these problems, we propose a new reinforced dependency graph convolutional network (RDGCN) that improves the importance calculation of dependencies in both distance and type views. Initially, we propose an importance calculation criterion for the minimum distances over dependency trees. Under the criterion, we design a distance-importance function that leverages reinforcement learning for weight distribution search and dissimilarity control. Since dependency types often do not have explicit syntax like tree distances, we use global attention and mask mechanisms to design type-importance functions. Finally, we merge these weights and implement feature aggregation and classification. Comprehensive experiments on three popular datasets demonstrate the effectiveness of the criterion and importance functions. RDGCN outperforms state-of-the-art GNN-based baselines in all validations.
</details>
<details>
<summary>摘要</summary>
为了解决这些问题，我们提出了一种新的强化dependency graph convolutional network (RDGCN)，该网络可以改进对依赖关系的重要性计算。我们首先提出了一种重要性计算 criterion，该 criterion 基于 minimum distances over dependency trees。在这个 criterion 下，我们设计了一个 distance-importance function，该函数通过 reinforcement learning 来搜索和控制 weights distribution。由于依赖类型通常没有显式语法如树距离，我们使用 global attention 和 mask mechanisms 来设计 type-importance functions。最后，我们将这些重要性 weights 合并并实现特征汇总和分类。我们在三个流行的 dataset 上进行了 comprehensive experiments，并证明了我们的 criterion 和 importance functions 的有效性。RDGCN 在所有验证中都超过了state-of-the-art GNN-based baselines。
</details></li>
</ul>
<hr>
<h2 id="Improving-Pacing-in-Long-Form-Story-Planning"><a href="#Improving-Pacing-in-Long-Form-Story-Planning" class="headerlink" title="Improving Pacing in Long-Form Story Planning"></a>Improving Pacing in Long-Form Story Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04459">http://arxiv.org/abs/2311.04459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yichenzw/pacing">https://github.com/yichenzw/pacing</a></li>
<li>paper_authors: Yichen Wang, Kevin Yang, Xiaoming Liu, Dan Klein</li>
<li>for: 提高自动生成长篇故事或故事简要 outline 的自然律动，增强读者体验。</li>
<li>methods: 提出 CONCrete Outline ConTrol (CONCOCT) 系统，通过训练具有具体性评估功能的扩展程序，控制 outline 的层次结构和新增项的具体性，以实现均衡的律动。</li>
<li>results: 与基eline compare，CONCOCT 的律动性能够保持在 57% 以上，并且积极影响下游故事的质量。<details>
<summary>Abstract</summary>
Existing LLM-based systems for writing long-form stories or story outlines frequently suffer from unnatural pacing, whether glossing over important events or over-elaborating on insignificant details, resulting in a jarring experience for the reader. We propose a CONCrete Outline ConTrol (CONCOCT) system to improve pacing when automatically generating story outlines. We first train a concreteness evaluator to judge which of two events is more concrete (low-level-detailed). This evaluator can then be used to control pacing in hierarchical outline generation; in this work, we explore a vaguest-first expansion procedure that aims for uniform pacing. We further use the evaluator to filter new outline items based on predicted concreteness. Compared to a baseline hierarchical outline generator, humans judge CONCOCT's pacing to be more consistent over 57% of the time across multiple outline lengths; the gains also translate to downstream stories. All code, data, and models are open-sourced.
</details>
<details>
<summary>摘要</summary>
现有的LLM基于系统 для写长篇故事或故事大纲经常受到不自然的节奏问题，无论是漏掉重要事件或者过于细化无关的细节，都会导致读者体验拖拖的。我们提议一个CONCrete Outline ConTrol（CONCOCT）系统，以改善自动生成故事大纲的节奏。我们首先在两个事件中训练一个具体性评估器，以判断哪个事件更具体（低级细节）。这个评估器可以用于控制层次结构生成的节奏，在这个工作中，我们探索了一种最笼的扩展程序，以实现均衡的节奏。此外，我们还使用这个评估器来过滤新的大纲项目，根据预测的具体性来筛选。相比基eline的层次结构生成器，人类对CONCOCT的节奏评价更一致，在多个大纲长度下达到57%的时间；此外，这些提升也翻译到下游的故事中。所有的代码、数据和模型都是开源的。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Uncertainty-Quantification-approaches-for-Neural-PDEs-in-scientific-applications"><a href="#Evaluating-Uncertainty-Quantification-approaches-for-Neural-PDEs-in-scientific-applications" class="headerlink" title="Evaluating Uncertainty Quantification approaches for Neural PDEs in scientific applications"></a>Evaluating Uncertainty Quantification approaches for Neural PDEs in scientific applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04457">http://arxiv.org/abs/2311.04457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vardhan Dongre, Gurpreet Singh Hora</li>
<li>for: 这个论文的目的是研究使用神经partial differential equations（Neural PDEs）来解决科学问题，包括气候变化、天气预测和城市规划。</li>
<li>methods: 这个论文使用了深度学习（DL）技术和领域专家（例如管理方程）来 Parametrize Neural PDEs，以捕捉数据中的有用相关性。</li>
<li>results: 研究发现，使用抽象方法（如 Hamiltonian Monte Carlo 和 Monte-Carlo Dropout）和深度 ensemble（DE）可以有效地评估神经PDEs中的不确定性。但是，我们发现，基于我们的观察，bayesian方法可能会低估真实的下一个不确定性，因此其预测显得更加自信。<details>
<summary>Abstract</summary>
The accessibility of spatially distributed data, enabled by affordable sensors, field, and numerical experiments, has facilitated the development of data-driven solutions for scientific problems, including climate change, weather prediction, and urban planning. Neural Partial Differential Equations (Neural PDEs), which combine deep learning (DL) techniques with domain expertise (e.g., governing equations) for parameterization, have proven to be effective in capturing valuable correlations within spatiotemporal datasets. However, sparse and noisy measurements coupled with modeling approximation introduce aleatoric and epistemic uncertainties. Therefore, quantifying uncertainties propagated from model inputs to outputs remains a challenge and an essential goal for establishing the trustworthiness of Neural PDEs. This work evaluates various Uncertainty Quantification (UQ) approaches for both Forward and Inverse Problems in scientific applications. Specifically, we investigate the effectiveness of Bayesian methods, such as Hamiltonian Monte Carlo (HMC) and Monte-Carlo Dropout (MCD), and a more conventional approach, Deep Ensembles (DE). To illustrate their performance, we take two canonical PDEs: Burger's equation and the Navier-Stokes equation. Our results indicate that Neural PDEs can effectively reconstruct flow systems and predict the associated unknown parameters. However, it is noteworthy that the results derived from Bayesian methods, based on our observations, tend to display a higher degree of certainty in their predictions as compared to those obtained using the DE. This elevated certainty in predictions suggests that Bayesian techniques might underestimate the true underlying uncertainty, thereby appearing more confident in their predictions than the DE approach.
</details>
<details>
<summary>摘要</summary>
科学问题的数据驱动解决方案，包括气候变化、天气预测和城市规划，受到了覆盖物理分布数据的可靠感知器技术的促进。神经partial differential equations（Neural PDEs），它们将深度学习（DL）技术与领域专家知识（例如，管理方程）结合参数化，已经证明可以夹含空间时间数据中的有价值相关性。然而，稀疏和噪声检测数据，以及模型简化 approximation，导致了 aleatoric 和 epistemic 不确定性。因此，从模型输入到输出的不确定性的传递是一项挑战，也是建立神经 PDEs 的可靠性的关键目标。这项工作评估了不同的 uncertainty quantification（UQ）方法，包括 Bayesian 方法，如 Hamiltonian Monte Carlo（HMC）和 Monte-Carlo Dropout（MCD），以及一种更传统的方法，深度集成（DE）。为了证明它们的性能，我们选择了两个简单的 PDE：Burger 方程和 Navier-Stokes 方程。我们的结果表明，神经 PDEs 可以有效地重construct 流体系统和相关的未知参数。然而，根据我们的观察，Bayesian 方法基于我们的结果来说，具有较高的确定性，与 DE 方法相比。这种高度的确定性表示 Bayesian 技术可能会低估真实的下层不确定性，因此它们的预测可能会更加自信。
</details></li>
</ul>
<hr>
<h2 id="MixTEA-Semi-supervised-Entity-Alignment-with-Mixture-Teaching"><a href="#MixTEA-Semi-supervised-Entity-Alignment-with-Mixture-Teaching" class="headerlink" title="MixTEA: Semi-supervised Entity Alignment with Mixture Teaching"></a>MixTEA: Semi-supervised Entity Alignment with Mixture Teaching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04441">http://arxiv.org/abs/2311.04441</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiefeng69/mixtea">https://github.com/xiefeng69/mixtea</a></li>
<li>paper_authors: Feng Xie, Xin Song, Xiang Zeng, Xuechen Zhao, Lei Tian, Bin Zhou, Yusong Tan</li>
<li>for: 这个论文是为了解决 semi-supervised entity alignment (EA) 问题，因为缺乏充足的标注数据。</li>
<li>methods: 该论文提出了一种新的 semi-supervised EA 方法，称为 MixTEA，它使用综合教学法和概率 pseudo mapping 来导向模型学习。</li>
<li>results: 该论文的实验结果表明，MixTEA 方法比 tradicional 方法更高效和精准，并且可以减少 pseudo mapping 的噪音影响。<details>
<summary>Abstract</summary>
Semi-supervised entity alignment (EA) is a practical and challenging task because of the lack of adequate labeled mappings as training data. Most works address this problem by generating pseudo mappings for unlabeled entities. However, they either suffer from the erroneous (noisy) pseudo mappings or largely ignore the uncertainty of pseudo mappings. In this paper, we propose a novel semi-supervised EA method, termed as MixTEA, which guides the model learning with an end-to-end mixture teaching of manually labeled mappings and probabilistic pseudo mappings. We firstly train a student model using few labeled mappings as standard. More importantly, in pseudo mapping learning, we propose a bi-directional voting (BDV) strategy that fuses the alignment decisions in different directions to estimate the uncertainty via the joint matching confidence score. Meanwhile, we also design a matching diversity-based rectification (MDR) module to adjust the pseudo mapping learning, thus reducing the negative influence of noisy mappings. Extensive results on benchmark datasets as well as further analyses demonstrate the superiority and the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
semi-supervised实体对接（EA）是一个实际和挑战性的任务，因为缺乏足够的标注映射作为训练数据。大多数工作通过生成 Pseudo 映射来解决这个问题，但是它们都受到假映射的噪声或忽略假映射的uncertainty。在本文中，我们提出了一种新的 semi-supervised EA 方法，称为 MixTEA，它使用端到端的混合教学法，将手动标注的映射和 probabilistic Pseudo 映射结合起来，以引导模型学习。我们首先使用一些标注的映射来训练学生模型。更重要的是，在 pseudo 映射学习中，我们提出了两向投票（BDV）策略，将映射决策在不同的方向 fusion 以估计uncertainty，并通过对应的匹配多样性 rectification（MDR）模块来修正 pseudo 映射学习，从而减少假映射的负面影响。我们在标准 benchmark 数据集上进行了广泛的实验，以及进行了进一步的分析，得出了我们提出的方法的superiority和有效性。
</details></li>
</ul>
<hr>
<h2 id="Data-Factors-for-Better-Compositional-Generalization"><a href="#Data-Factors-for-Better-Compositional-Generalization" class="headerlink" title="Data Factors for Better Compositional Generalization"></a>Data Factors for Better Compositional Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04420">http://arxiv.org/abs/2311.04420</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/owenzx/data4comp">https://github.com/owenzx/data4comp</a></li>
<li>paper_authors: Xiang Zhou, Yichen Jiang, Mohit Bansal</li>
<li>for: 本研究旨在解释这些新的诊断数据集（如SCAN和COGS）中模型从零开始训练时的严重问题。</li>
<li>methods: 本研究使用Transformer模型在不同数据因素（如数据集规模、模式复杂度、示例困难等）上进行了实验训练。</li>
<li>results: 研究发现，增加数据复杂度可以提高多种泛化挑战的泛化能力，并且分析了这种改进的两个轴：更多的例子使拼凑理解更有效，而减少示例重复频率也防止了不可 revertible 的记忆。此外，研究还探讨了不同难度水平的示例对泛化的影响。<details>
<summary>Abstract</summary>
Recent diagnostic datasets on compositional generalization, such as SCAN (Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems in models trained from scratch on these datasets. However, in contrast to this poor performance, state-of-the-art models trained on larger and more general datasets show better generalization ability. In this work, to reconcile this inconsistency, we conduct an empirical analysis by training Transformer models on a variety of training sets with different data factors, including dataset scale, pattern complexity, example difficulty, etc. First, we show that increased dataset complexity can lead to better generalization behavior on multiple different generalization challenges. To further understand this improvement, we show two axes of the benefit from more complex datasets: they provide more diverse examples so compositional understanding becomes more effective, and they also prevent ungeneralizable memorization of the examples due to reduced example repetition frequency. Finally, we explore how training examples of different difficulty levels influence generalization differently. On synthetic datasets, simple examples invoke stronger compositionality than hard examples do. On larger-scale real language datasets, while hard examples become more important potentially to ensure decent data coverage, a balanced mixture of simple and hard examples manages to induce the strongest generalizability. The code and data for this work are available at https://github.com/owenzx/data4comp
</details>
<details>
<summary>摘要</summary>
最新的诊断数据集，如SCAN（Lake和Baroni，2018）和COGS（Kim和Linzen，2020），暴露了从头开始训练的模型表现异常糟糕。然而，与此不同的是，在更大和更通用的数据集上训练的state-of-the-art模型具有更好的泛化能力。在这项工作中，我们通过训练Transformer模型于多种训练集上进行了实验性分析，以寻找解释这一矛盾。我们发现，增加数据复杂性可以提高多个泛化挑战的泛化行为。为了更深入地理解这种改善，我们显示了两个数据复杂性的利益轴：它们提供更多的多样化示例，使compositional understanding更有效，而且它们还降低了示例重复频率，避免了不可 generale的记忆。最后，我们探索了不同难度水平的示例对泛化的影响。在 sintetic数据集上，简单的示例更强的compositional understanding than hard examples。在更大规模的实际语言数据集上，虽然hard examples在涉及数据覆盖的情况下可能变得更重要，但是平衡mixture of simple and hard examples可以induce最强的泛化能力。codes和数据可以在https://github.com/owenzx/data4comp中获取。
</details></li>
</ul>
<hr>
<h2 id="PepLand-a-large-scale-pre-trained-peptide-representation-model-for-a-comprehensive-landscape-of-both-canonical-and-non-canonical-amino-acids"><a href="#PepLand-a-large-scale-pre-trained-peptide-representation-model-for-a-comprehensive-landscape-of-both-canonical-and-non-canonical-amino-acids" class="headerlink" title="PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids"></a>PepLand: a large-scale pre-trained peptide representation model for a comprehensive landscape of both canonical and non-canonical amino acids</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04419">http://arxiv.org/abs/2311.04419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruochi Zhang, Haoran Wu, Yuting Xiu, Kewei Li, Ningning Chen, Yu Wang, Yan Wang, Xin Gao, Fengfeng Zhou</li>
<li>For: The paper aims to develop a novel pre-training architecture for representation and property analysis of peptides spanning both canonical and non-canonical amino acids.* Methods: The proposed method, called PepLand, leverages a comprehensive multi-view heterogeneous graph neural network to unveil the subtle structural representations of peptides.* Results: PepLand shows effectiveness across an array of peptide property predictions, including protein-protein interactions, permeability, solubility, and synthesizability, and lays a robust foundation for transformative advances in peptide-centric research domains.Here are the three key points in Simplified Chinese text:* For: 这个论文目的是开发一种新的预训练模型，用于表示和分析包括非标准氨基酸的肽序列。* Methods: 该方法使用了一种涵盖多视图多样化图神经网络，以揭示肽序列中细腻的结构表示。* Results: PepLand在多种肽性质预测中表现出色，包括肽-肽相互作用、渗透性、溶解性和合成可能性，并为肽领域研究提供了一个坚实的基础。<details>
<summary>Abstract</summary>
In recent years, the scientific community has become increasingly interested on peptides with non-canonical amino acids due to their superior stability and resistance to proteolytic degradation. These peptides present promising modifications to biological, pharmacological, and physiochemical attributes in both endogenous and engineered peptides. Notwithstanding their considerable advantages, the scientific community exhibits a conspicuous absence of an effective pre-trained model adept at distilling feature representations from such complex peptide sequences. We herein propose PepLand, a novel pre-training architecture for representation and property analysis of peptides spanning both canonical and non-canonical amino acids. In essence, PepLand leverages a comprehensive multi-view heterogeneous graph neural network tailored to unveil the subtle structural representations of peptides. Empirical validations underscore PepLand's effectiveness across an array of peptide property predictions, encompassing protein-protein interactions, permeability, solubility, and synthesizability. The rigorous evaluation confirms PepLand's unparalleled capability in capturing salient synthetic peptide features, thereby laying a robust foundation for transformative advances in peptide-centric research domains. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/pepland
</details>
<details>
<summary>摘要</summary>
Recently, scientific researchers have become increasingly interested in peptides with non-canonical amino acids due to their improved stability and resistance to degradation. These peptides have promising modifications to biological, pharmacological, and physiochemical attributes in both endogenous and engineered peptides. However, the scientific community lacks an effective pre-trained model for distilling feature representations from such complex peptide sequences. We propose PepLand, a novel pre-training architecture for representation and property analysis of peptides spanning both canonical and non-canonical amino acids. PepLand leverages a comprehensive multi-view heterogeneous graph neural network to unveil the subtle structural representations of peptides. Empirical validations demonstrate PepLand's effectiveness in predicting various peptide properties, including protein-protein interactions, permeability, solubility, and synthesizability. The rigorous evaluation confirms PepLand's ability in capturing salient synthetic peptide features, laying a robust foundation for transformative advances in peptide-centric research domains. The source code used in this study is publicly accessible via GitHub at <https://github.com/zhangruochi/pepland>.
</details></li>
</ul>
<hr>
<h2 id="AI-accelerated-Discovery-of-Altermagnetic-Materials"><a href="#AI-accelerated-Discovery-of-Altermagnetic-Materials" class="headerlink" title="AI-accelerated Discovery of Altermagnetic Materials"></a>AI-accelerated Discovery of Altermagnetic Materials</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04418">http://arxiv.org/abs/2311.04418</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zfgao66/mataltmag">https://github.com/zfgao66/mataltmag</a></li>
<li>paper_authors: Ze-Feng Gao, Shuai Qu, Bocheng Zeng, Ji-Rong Wen, Hao Sun, Pengjie Guo, Zhong-Yi Lu</li>
<li>for: 探索新型磁性阶段的研究，即 alternate magnetism，以拓展现有磁性材料的知识和应用范围。</li>
<li>methods: 利用人工智能搜索引擎，结合 симметRY分析、图 neural network 预训练、优质运输理论和基本电子结构计算，找到25种新的磁性材料，包括金属、半导体和绝缘体。</li>
<li>results: 发现25种新的磁性材料，其中8种是 $i$-wave 磁性材料，这些材料具有独特的物理性质，如异常柱幅效应、异常柯尔效应和topological property。<details>
<summary>Abstract</summary>
Altermagnetism, a new magnetic phase, has been theoretically proposed and experimentally verified to be distinct from ferromagnetism and antiferromagnetism. Although altermagnets have been found to possess many exotic physical properties, the very limited availability of known altermagnetic materials~(e.g., 14 confirmed materials) hinders the study of such properties. Hence, discovering more types of altermagnetic materials is crucial for a comprehensive understanding of altermagnetism and thus facilitating new applications in the next generation information technologies, e.g., storage devices and high-sensitivity sensors. Here, we report 25 new altermagnetic materials that cover metals, semiconductors, and insulators, discovered by an AI search engine unifying symmetry analysis, graph neural network pre-training, optimal transport theory, and first-principles electronic structure calculation. The wide range of electronic structural characteristics reveals that various innovative physical properties manifest in these newly discovered altermagnetic materials, e.g., anomalous Hall effect, anomalous Kerr effect, and topological property. Noteworthy, we discovered 8 $i$-wave altermagnetic materials for the first time. Overall, the AI search engine performs much better than human experts and suggests a set of new altermagnetic materials with unique properties, outlining its potential for accelerated discovery of altermagnetic materials.
</details>
<details>
<summary>摘要</summary>
alternatermagnetism, 一种新的磁相，已经有理论上和实验上证明它与常见的磁相（ferromagnetism和antiferromagnetism）不同。尽管alternatermagnets possess many exotic physical properties，但由于已知的altermagnetic materials的数量非常有限（只有14种），因此研究这些物理性质受到了阻碍。因此，发现更多的altermagnetic materials是研究altermagnetism的关键，以便更全面地理解这种磁相，并且为下一代信息技术的发展，如存储设备和高敏感度传感器，提供新的应用。在这里，我们报道了25种新的altermagnetic materials，包括金属、半导体和绝缘体，通过人工智能搜索引擎，结合对称分析、图像神经网络预训练、优化运输理论和元素电子结构计算。这些新发现的altermagnetic materials具有多种创新的物理性质，例如异常柱压效应、异常柱压效应和topological property。值得注意的是，我们发现了8种$i$-wave altermagnetic materials，这是第一次发现。总的来说，人工智能搜索引擎的性能远胜人类专家，并提供了一组新的altermagnetic materials，其物理性质具有创新性和可能性。
</details></li>
</ul>
<hr>
<h2 id="Human-Conditional-Reasoning-in-Answer-Set-Programming"><a href="#Human-Conditional-Reasoning-in-Answer-Set-Programming" class="headerlink" title="Human Conditional Reasoning in Answer Set Programming"></a>Human Conditional Reasoning in Answer Set Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04412">http://arxiv.org/abs/2311.04412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Chiaki Sakama</li>
<li>for: 这个论文探讨了人类日常生活中的各种推理方法，以及如何通过answer set programming（ASP）实现这些推理方法。</li>
<li>methods: 本论文使用了answer set programming（ASP）来实现三种不同类型的推理方法：Affirming the Consequent（AC）、Denying the Antecedent（DA）和Modus Tollens（DT）。</li>
<li>results: 本论文发现了这些推理方法的正式性和人类思维 Tasks in cognitive psychology中的应用。此外，这些推理方法还被应用于常识智能（AI）中的 Commonsense reasoning。<details>
<summary>Abstract</summary>
Given a conditional sentence P=>Q (if P then Q) and respective facts, four different types of inferences are observed in human reasoning. Affirming the antecedent (AA) (or modus ponens) reasons Q from P; affirming the consequent (AC) reasons P from Q; denying the antecedent (DA) reasons -Q from -P; and denying the consequent (DC) (or modus tollens) reasons -P from -Q. Among them, AA and DC are logically valid, while AC and DA are logically invalid and often called logical fallacies. Nevertheless, humans often perform AC or DA as pragmatic inference in daily life. In this paper, we realize AC, DA and DC inferences in answer set programming. Eight different types of completion are introduced and their semantics are given by answer sets. We investigate formal properties and characterize human reasoning tasks in cognitive psychology. Those completions are also applied to commonsense reasoning in AI.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:给一个 conditional sentence P=>Q (如果 P then Q) 和相应的事实，人类理智中观察到了四种不同的推理类型。确认 antecedent (AA) (或 modus ponens) 从 P 推理 Q; 确认 consequent (AC) 从 Q 推理 P; 否认 antecedent (DA) 从 -P 推理 -Q; 和否认 consequent (DC) (或 modus tollens) 从 -Q 推理 -P。其中，AA 和 DC 是逻辑有效的，而 AC 和 DA 是逻辑无效的，常被称为逻辑谬误。然而，人们在日常生活中经常使用 AC 或 DA 进行 Pragmatic 推理。在这篇论文中，我们在answer set programming中实现了 AC, DA 和 DC 推理。我们引入了八种不同的完成，并给出了它们的 semantics。我们investigate了 formal properties 并 caracterize human reasoning tasks in cognitive psychology。这些完成还应用于人工智能中的常识理智。
</details></li>
</ul>
<hr>
<h2 id="Human-Centered-Planning"><a href="#Human-Centered-Planning" class="headerlink" title="Human-Centered Planning"></a>Human-Centered Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04403">http://arxiv.org/abs/2311.04403</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rprokap/pset-9">https://github.com/rprokap/pset-9</a></li>
<li>paper_authors: Yuliang Li, Nitin Kamra, Ruta Desai, Alon Halevy</li>
<li>for: 这 paper 的目的是创建一个基于 AI 的个人助手，能够生成结构化输出，如一个日程计划或海外旅行计划。</li>
<li>methods: 这 paper 使用了语言模型（LLM）来实现计划生成。LLM 可以 incorporate 用户提供的模糊约束，并且可以自动推理这些约束。</li>
<li>results: 根据实验结果，LLM-based planner 可以达到 tradicional symbolic planners 的水平（即Explicit Constraint Satisfaction），同时具有更高的用户满意度（70.5% vs. 40.4%）。<details>
<summary>Abstract</summary>
LLMs have recently made impressive inroads on tasks whose output is structured, such as coding, robotic planning and querying databases. The vision of creating AI-powered personal assistants also involves creating structured outputs, such as a plan for one's day, or for an overseas trip. Here, since the plan is executed by a human, the output doesn't have to satisfy strict syntactic constraints. A useful assistant should also be able to incorporate vague constraints specified by the user in natural language. This makes LLMs an attractive option for planning.   We consider the problem of planning one's day. We develop an LLM-based planner (LLMPlan) extended with the ability to self-reflect on its output and a symbolic planner (SymPlan) with the ability to translate text constraints into a symbolic representation. Despite no formal specification of constraints, we find that LLMPlan performs explicit constraint satisfaction akin to the traditional symbolic planners on average (2% performance difference), while retaining the reasoning of implicit requirements. Consequently, LLM-based planners outperform their symbolic counterparts in user satisfaction (70.5% vs. 40.4%) during interactive evaluation with 40 users.
</details>
<details>
<summary>摘要</summary>
我们考虑一天的规划问题。我们开发了一个基于 LLM 的规划器（LLMPlan）和一个基于 симвоlic 表示的规划器（SymPlan）。我们发现，尽管没有正式的约束规则，LLMPlan 可以通过自适应的方式执行明确的要求，并且与传统的符号学规划器相当（均差值为 2%）。此外，LLMPlan 在用户满意度方面也高于符号学规划器（70.5% vs. 40.4%），在交互评估中与 40 名用户进行了交互评估。
</details></li>
</ul>
<hr>
<h2 id="LRM-Large-Reconstruction-Model-for-Single-Image-to-3D"><a href="#LRM-Large-Reconstruction-Model-for-Single-Image-to-3D" class="headerlink" title="LRM: Large Reconstruction Model for Single Image to 3D"></a>LRM: Large Reconstruction Model for Single Image to 3D</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04400">http://arxiv.org/abs/2311.04400</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou, Difan Liu, Feng Liu, Kalyan Sunkavalli, Trung Bui, Hao Tan</li>
<li>for: 这个论文的目的是提出一种可以从单个输入图像中预测3D模型的大型重建模型（LRM），并且只需5秒钟的时间。</li>
<li>methods: 该模型采用了高可扩展的 transformer 架构，并且有5亿个学习参数，直接从输入图像预测神经辐射场（NeRF）。</li>
<li>results: 模型通过在大规模多视图数据上进行端到端训练，以及使用了大量的 Synthetic renderings from Objaverse 和实际捕捉从 MVImgNet，使得模型能够高度泛化和生成高质量的3D重建结果。Here is the same information in Traditional Chinese:</li>
<li>for: 这个论文的目的是提出一种可以从单一的输入图像中预测3D模型的大型重建模型（LRM），并且只需5秒钟的时间。</li>
<li>methods: 这个模型采用了高可扩展的 transformer 架构，并且有5亿个学习参数，直接从输入图像预测神经辐射场（NeRF）。</li>
<li>results: 模型通过在大规模多视图数据上进行端到端训练，以及使用了大量的 Synthetic renderings from Objaverse 和实际捕捉从 MVImgNet，使得模型能够高度泛化和生成高质量的3D重建结果。<details>
<summary>Abstract</summary>
We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs including real-world in-the-wild captures and images from generative models. Video demos and interactable 3D meshes can be found on this website: https://yiconghong.me/LRM/.
</details>
<details>
<summary>摘要</summary>
我们提出了首个大型重建模型（LRM），可以在单个输入图像上预测对象的3D模型，并且只需5秒钟。与过去许多方法不同，LRM使用可扩展的 transformer 架构，并有5亿个学习参数来直接预测神经辐射场（NeRF）。我们在端到端方式下培训我们的模型，使用巨量数据集，包括约1000万个 объек的多视图数据，来包括 Objaverse 的 sintetic renderings 和 MVImgNet 的实际捕捉。这种高容量模型和大规模培训数据使得我们的模型具有高度泛化性，可以从多种测试输入，包括实际世界中的野生捕捉和生成模型的图像，生成高质量的3D重建。关于我们的模型和视频示例，请访问我们的网站：https://yiconghong.me/LRM/。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/cs.AI_2023_11_08/" data-id="clorjzl33006vf188av9s4pj3" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/cs.CL_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T11:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/cs.CL_2023_11_08/">cs.CL - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-Abstract-Is-Linguistic-Generalization-in-Large-Language-Models-Experiments-with-Argument-Structure"><a href="#How-Abstract-Is-Linguistic-Generalization-in-Large-Language-Models-Experiments-with-Argument-Structure" class="headerlink" title="How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure"></a>How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04900">http://arxiv.org/abs/2311.04900</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/clay-lab/structural-alternations">https://github.com/clay-lab/structural-alternations</a></li>
<li>paper_authors: Michael Wilson, Jackson Petty, Robert Frank</li>
<li>for: 这个论文主要研究了大型自然语言处理器（LLM）是否能够表征语言知识中的关系，以及这些关系如何在语言模型中表征。</li>
<li>methods: 研究者使用了Transformer基于的大型语言模型，通过对这些模型在不同上下文中的表现进行分析，来评估它们是否能够表征语言知识中的关系。</li>
<li>results: 研究者发现，LLM在某些情况下能够成功地推断novel noun argument的分布，但在其他情况下会表现出 linear order 的偏好，这指示现有的模型具有限制，并且需要更多的数据进行训练。<details>
<summary>Abstract</summary>
Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained Transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically-organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.s reported here are available at https://github.com/clay-lab/structural-alternations.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）通常会被评估在特定上下文中的单个词的分布预测方面。然而，语言知识还包含词语上下文之间的关系，允许对词语分布进行推理。我们研究了大型Transformer基于模型（LLM）是否能够表达这些关系，特别是在语法结构领域。我们发现，LLM在已经在预训练中看到的上下文中的新词语分布推理非常好，通过利用词语嵌入空间的semantic排序结构。然而，在预训练中没有看到的相关上下文中，LLM会表现出线性顺序偏好，这表明当前模型存在一定的限制。这些结果可以在https://github.com/clay-lab/structural-alternations中找到。
</details></li>
</ul>
<hr>
<h2 id="Future-Lens-Anticipating-Subsequent-Tokens-from-a-Single-Hidden-State"><a href="#Future-Lens-Anticipating-Subsequent-Tokens-from-a-Single-Hidden-State" class="headerlink" title="Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"></a>Future Lens: Anticipating Subsequent Tokens from a Single Hidden State</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04897">http://arxiv.org/abs/2311.04897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KoyenaPal/future-lens">https://github.com/KoyenaPal/future-lens</a></li>
<li>paper_authors: Koyena Pal, Jiuding Sun, Andrew Yuan, Byron C. Wallace, David Bau</li>
<li>for: 这个论文是为了检验Transformer模型中每个输入token的隐藏状态 Vector是否能够准确预测后续token的。</li>
<li>methods: 该论文使用了线性近似方法和 causal intervention 方法来评估Transformer模型中每个隐藏状态 Vector 是否能够预测后续token的。</li>
<li>results: 研究发现，在某些层次上，可以通过单个隐藏状态 Vector 来预测后续token的Accuracy 高于48%。此外，paper 还提出了一种“未来镜”视觉化方法，可以为Transformer模型的隐藏状态 Vector 创造一个新的视图。<details>
<summary>Abstract</summary>
We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position $t$ in an input, can we reliably anticipate the tokens that will appear at positions $\geq t + 2$? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model's output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a "Future Lens" visualization that uses these methods to create a new view of transformer states.
</details>
<details>
<summary>摘要</summary>
我们推测隐藏状态向量对输入单词的预测具有充分的信息。更具体地说，在这篇论文中，我们问：给定输入中单个token的隐藏（内部）表示，可以准确预测输入中后续的多少个token？为了测试这一点，我们使用线性逼近和 causal intervention 方法来评估隐藏状态中是否含有可预测输入的信号。我们发现，在某些层次上，可以使用单个隐藏状态来预测后续token的输出，准确率高达48%以上。最后，我们介绍了一种“未来镜”视觉化，使用这些方法来创造一种新的 transformer 状态视图。
</details></li>
</ul>
<hr>
<h2 id="Bias-Runs-Deep-Implicit-Reasoning-Biases-in-Persona-Assigned-LLMs"><a href="#Bias-Runs-Deep-Implicit-Reasoning-Biases-in-Persona-Assigned-LLMs" class="headerlink" title="Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs"></a>Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04892">http://arxiv.org/abs/2311.04892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/allenai/persona-bias">https://github.com/allenai/persona-bias</a></li>
<li>paper_authors: Shashank Gupta, Vaishnavi Shrivastava, Ameet Deshpande, Ashwin Kalyan, Peter Clark, Ashish Sabharwal, Tushar Khot</li>
<li>for: 这研究探讨了大规模自然语言模型（LLMs）是如何在响应人工 persona 时表现出各种人类行为的能力，以及这种能力对 LLMs 的能力有什么影响。</li>
<li>methods: 这研究使用了 ChatGPT 进行基本逻辑任务的测试，并在不同的社会民生群体（种族、性别、宗教、残疾和政治倾向）中测试了 16 个多样化的人工 persona。</li>
<li>results: 研究发现，ChatGPT 具有各种社会民生群体下的偏见，包括逻辑任务中的数学能力偏见。这种偏见会导致 ChatGPT 在响应人工 persona 时表现出偏见和错误的假设，并导致基本逻辑任务的性能下降。这种偏见是广泛存在的、有 statistically significant 影响和可能对某些群体产生不良影响。<details>
<summary>Abstract</summary>
Recent works have showcased the ability of large-scale language models (LLMs) to embody diverse personas in their responses, exemplified by prompts like 'You are Yoda. Explain the Theory of Relativity.' While this ability allows personalization of LLMs and enables human behavior simulation, its effect on LLMs' capabilities remain unclear. To fill this gap, we present the first extensive study of the unintended side-effects of persona assignment on the ability of LLMs, specifically ChatGPT, to perform basic reasoning tasks. Our study covers 24 reasoning datasets and 16 diverse personas spanning 5 socio-demographic groups: race, gender, religion, disability, and political affiliation. Our experiments unveil that ChatGPT carries deep rooted bias against various socio-demographics underneath a veneer of fairness. While it overtly rejects stereotypes when explicitly asked ('Are Black people less skilled at mathematics?'), it manifests stereotypical and often erroneous presumptions when prompted to answer questions while taking on a persona. These can be observed as abstentions in the model responses, e.g., 'As a Black person, I am unable to answer this question as it requires math knowledge', and generally result in a substantial drop in performance on reasoning tasks. We find that this inherent deep bias is ubiquitous - 80% of our personas demonstrated bias; it is significant - certain datasets had relative drops in performance of 70%+; and can be especially harmful for certain groups - certain personas had stat. sign. drops on more than 80% of the datasets. Further analysis shows that these persona-induced errors can be hard-to-discern and hard-to-avoid. Our findings serve as a cautionary tale that the practice of assigning personas to LLMs - a trend on the rise - can surface their deep-rooted biases and have unforeseeable and detrimental side-effects.
</details>
<details>
<summary>摘要</summary>
近期研究显示大型语言模型（LLM）能够体现多种人格 trait，如“你是יודा。解释 relativity 理论”的提示。这种能力允许个性化 LLM 和人类行为模拟，但其影响 LLM 的能力仍未得到清楚的解释。为了填补这个空白，我们提出了首次对 LLM 特征 Persona 分配的不良侧effect的系统性研究。我们的研究涵盖24个逻辑数据集和16种多样化的人格 trait，包括种族、性别、宗教、残疾和政治倾向。我们的实验发现，ChatGPT 具有各种社会化特征 trait 的深层隐藏偏见，尤其是对于不同的社会群体。尽管 ChatGPT 明确拒绝了一些刻板印象（如“黑人不会准确地做数学”），但在接受人格 trait 时，它会表现出偏见和错误的假设。这些假设可以通过 ChatGPT 的答案中的异常沉默（如“作为黑人，我无法回答这个问题，因为它需要数学知识”）来观察。这些假设通常会导致 ChatGPT 在逻辑任务中表现出显著的下降。我们发现这种深层偏见是普遍的 - 80%的人格 trait 表现出偏见；它是重要的 - certain dataset 上的相对下降超过 70%；并且可能对某些群体造成特别危害 - certain persona 上的more than 80% dataset 上的相对下降。进一步分析表明，这些人格 trait 引起的错误可能具有难以识别和难以避免的特征。我们的发现 serve as a cautionary tale，将 Persona 分配给 LLM 的做法（这是当前升温的趋势）可能会暴露 LLM 的深层偏见并导致不预期的和有害的副作用。
</details></li>
</ul>
<hr>
<h2 id="Profiling-Irony-Stereotype-Exploring-Sentiment-Topic-and-Lexical-Features"><a href="#Profiling-Irony-Stereotype-Exploring-Sentiment-Topic-and-Lexical-Features" class="headerlink" title="Profiling Irony &amp; Stereotype: Exploring Sentiment, Topic, and Lexical Features"></a>Profiling Irony &amp; Stereotype: Exploring Sentiment, Topic, and Lexical Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04885">http://arxiv.org/abs/2311.04885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tibor L. R. Krols, Marie Mortensen, Ninell Oldenburg</li>
<li>for: 本研究旨在创建一种推断Twitter用户发布的信息中带有讲究的语句的系统。</li>
<li>methods: 该研究使用TF-IDF、情感特征和主题模型来选择特定的子特征，并通过了一项系统的特征选择过程。</li>
<li>results: 模型的F1分数为0.84，超过了基线值。 lexical特征，特别是TF-IDF，对模型的性能做出了最大贡献，而情感和主题模型的特征则对模型的性能较少。<details>
<summary>Abstract</summary>
Social media has become a very popular source of information. With this popularity comes an interest in systems that can classify the information produced. This study tries to create such a system detecting irony in Twitter users. Recent work emphasize the importance of lexical features, sentiment features and the contrast herein along with TF-IDF and topic models. Based on a thorough feature selection process, the resulting model contains specific sub-features from these areas. Our model reaches an F1-score of 0.84, which is above the baseline. We find that lexical features, especially TF-IDF, contribute the most to our models while sentiment and topic modeling features contribute less to overall performance. Lastly, we highlight multiple interesting and important paths for further exploration.
</details>
<details>
<summary>摘要</summary>
社交媒体已成为信息来源的非常流行的地方。随着这种流行，有人对这些信息生成系统进行了关注。这个研究尝试创建一个检测Twitter用户中的讲究的系统。最近的研究强调了用语特征、情感特征以及这里的对比，同时还包括TF-IDF和话题模型。根据严格的特征选择过程，模型包含特定的子特征。我们的模型达到了0.84的F1分数，高于基线。我们发现，TF-IDF特征对模型的表现最大，情感和话题模型特征对表现较差。最后，我们提出了多个有趣和重要的探索方向。
</details></li>
</ul>
<hr>
<h2 id="Hierarchically-Gated-Recurrent-Neural-Network-for-Sequence-Modeling"><a href="#Hierarchically-Gated-Recurrent-Neural-Network-for-Sequence-Modeling" class="headerlink" title="Hierarchically Gated Recurrent Neural Network for Sequence Modeling"></a>Hierarchically Gated Recurrent Neural Network for Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04823">http://arxiv.org/abs/2311.04823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opennlplab/hgrn">https://github.com/opennlplab/hgrn</a></li>
<li>paper_authors: Zhen Qin, Songlin Yang, Yiran Zhong</li>
<li>for: 这个论文是为了提出一种基于Linear RNN的高效序列模型，它可以模型长期依赖关系和当地短期依赖关系。</li>
<li>methods: 该模型使用了闭包机制，并将忘记门Lower bound为学习值。这使得上层层模型长期依赖关系，而下层层模型更多的短期依赖关系。</li>
<li>results: 在语言模型、图像分类和长距离比赛 benchmark 上，该模型显示了高效性和有效性。源代码可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Transformers have surpassed RNNs in popularity due to their superior abilities in parallel training and long-term dependency modeling. Recently, there has been a renewed interest in using linear RNNs for efficient sequence modeling. These linear RNNs often employ gating mechanisms in the output of the linear recurrence layer while ignoring the significance of using forget gates within the recurrence. In this paper, we propose a gated linear RNN model dubbed Hierarchically Gated Recurrent Neural Network (HGRN), which includes forget gates that are lower bounded by a learnable value. The lower bound increases monotonically when moving up layers. This allows the upper layers to model long-term dependencies and the lower layers to model more local, short-term dependencies. Experiments on language modeling, image classification, and long-range arena benchmarks showcase the efficiency and effectiveness of our proposed model. The source code is available at https://github.com/OpenNLPLab/HGRN.
</details>
<details>
<summary>摘要</summary>
transformers 已经超过 RNNs 的受欢迎程度，这主要归功于它们在并行训练和长期依赖模型方面的优势。在最近，使用线性 RNNs  для高效序列模型化有新的兴趣。这些线性 RNNs 通常在输出 linear recurrence 层中使用阀门机制，而忽略使用 forget gates 的重要性。在这篇论文中，我们提出了一种名为层次阀门Recurrent Neural Network（HGRN）的模型，该模型包含 learnable 的下界值。这个下界值随层数增长 monotonically，这使得上层模型长期依赖，而下层模型更加本地、短期依赖。我们在语言模型、图像分类和长距离场景中进行了实验，结果表明我们的提议的模型具有高效性和有效性。代码可以在 <https://github.com/OpenNLPLab/HGRN> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Determination-of-toxic-comments-and-unintended-model-bias-minimization-using-Deep-learning-approach"><a href="#Determination-of-toxic-comments-and-unintended-model-bias-minimization-using-Deep-learning-approach" class="headerlink" title="Determination of toxic comments and unintended model bias minimization using Deep learning approach"></a>Determination of toxic comments and unintended model bias minimization using Deep learning approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04789">http://arxiv.org/abs/2311.04789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Azim Khan</li>
<li>for: 本研究旨在探讨评论中的恶意言语检测和性别、种族、宗教等特征偏见问题。</li>
<li>methods: 本研究使用BERT模型进行注意力调整，并应用权重损失函数来解决不均衡数据问题。</li>
<li>results: 研究发现， Fine-tuned BERT模型在恶意言语检测和偏见减少方面的性能比传统的逻辑回归模型高，并且可以减少不良评论中的性别、种族、宗教等特征偏见。<details>
<summary>Abstract</summary>
Online conversations can be toxic and subjected to threats, abuse, or harassment. To identify toxic text comments, several deep learning and machine learning models have been proposed throughout the years. However, recent studies demonstrate that because of the imbalances in the training data, some models are more likely to show unintended biases including gender bias and identity bias. In this research, our aim is to detect toxic comment and reduce the unintended bias concerning identity features such as race, gender, sex, religion by fine-tuning an attention based model called BERT(Bidirectional Encoder Representation from Transformers). We apply weighted loss to address the issue of unbalanced data and compare the performance of a fine-tuned BERT model with a traditional Logistic Regression model in terms of classification and bias minimization. The Logistic Regression model with the TFIDF vectorizer achieve 57.1% accuracy, and fine-tuned BERT model's accuracy is 89%. Code is available at https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git
</details>
<details>
<summary>摘要</summary>
在线聊天可能会出现攻击性、威胁、辱华或骚扰行为。为了识别攻击性文章评论，多种深度学习和机器学习模型已经被提出了多年来。然而，最近的研究表明，由于训练数据的不均衡，一些模型可能会显示不良偏见，包括性别偏见和身份偏见。在这项研究中，我们的目标是检测攻击性评论，并对身份特征（种族、性别、宗教等）进行降低不良偏见。我们使用了一种注意力基于模型（BERT）进行精度调整，并应用权重损失函数来解决不均衡数据的问题。我们与传统的Logistic Regression模型进行比较，并评估两种模型在分类和偏见降低方面的性能。Logistic Regression模型与TF-IDF vectorizer实现了57.1%的准确率，而精度调整后的BERT模型的准确率为89%。代码可以在https://github.com/zim10/Determine_Toxic_comment_and_identity_bias.git中找到。
</details></li>
</ul>
<hr>
<h2 id="Using-large-language-models-to-study-human-memory-for-meaningful-narratives"><a href="#Using-large-language-models-to-study-human-memory-for-meaningful-narratives" class="headerlink" title="Using large language models to study human memory for meaningful narratives"></a>Using large language models to study human memory for meaningful narratives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04742">http://arxiv.org/abs/2311.04742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mkatkov/llm-narrative-analysis">https://github.com/mkatkov/llm-narrative-analysis</a></li>
<li>paper_authors: Antonios Georgiou Tankut Can, Mikhail Katkov, Misha Tsodyks</li>
<li>for: 研究人类记忆的大语言模型可以作为科学工具，用于研究人类记忆的含义。</li>
<li>methods: 开发了大规模记忆实验的管道，并对获得的结果进行分析。实施了在线记忆实验，收集了不同长度的故事的记忆和回忆数据。发现故事长度和记忆性的关系是直线关系。</li>
<li>results: 发现，即使使用扰乱版故事，记忆性仍然保持 relativamente 不变，但回忆性却明显下降。这表明，记忆中的故事 Context 具有重要作用。<details>
<summary>Abstract</summary>
One of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary. Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material. We developed a pipeline for designing large scale memory experiments and analyzing the obtained results. We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths. We found that both recall and recognition performance scale linearly with narrative length. Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories. We found that even though recall performance declined significantly, recognition remained largely unaffected. Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory.
</details>
<details>
<summary>摘要</summary>
一个AI革命的最引人注目的成就是大语言模型的开发，可以生成有意义的文本并遵循普通英语的指令，无需额外训练。我们表明了语言模型可以作为研究人类记忆的科学工具。我们开发了大规模记忆实验的管道和分析得到的结果。我们在大量参与者上线进行了记忆和回忆实验，收集了不同长度的故事的认知和回忆数据。我们发现，故事长度和记忆性的表现是直线关系。此外，为了研究故事理解对记忆的影响，我们重复使用故事的排序版本进行实验。我们发现，即使回忆性下降了很多，仍然可以保持认知的能力，而且回忆似乎遵循原始的故事顺序，表明在记忆中存在Contextual重建的story。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Generative-Ad-Hoc-Information-Retrieval"><a href="#Evaluating-Generative-Ad-Hoc-Information-Retrieval" class="headerlink" title="Evaluating Generative Ad Hoc Information Retrieval"></a>Evaluating Generative Ad Hoc Information Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04694">http://arxiv.org/abs/2311.04694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Gienapp, Harrisen Scells, Niklas Deckers, Janek Bevendorff, Shuai Wang, Johannes Kiesel, Shahbaz Syed, Maik Fröbe, Guide Zucoon, Benno Stein, Matthias Hagen, Martin Potthast</li>
<li>for: 这篇论文旨在研究基于大语言模型的生成搜索系统，以及如何评估这类系统的用户体验。</li>
<li>methods: 论文使用了现有的信息检索和自然语言处理文献来做一个搜索任务和系统结构的归纳，并开发了一个用户模型来评估生成搜索系统的性能。</li>
<li>results: 论文通过对生成搜索系统的理论分析提供了一个基础和新的发现，可以用于评估生成搜索系统的用户体验。<details>
<summary>Abstract</summary>
Recent advances in large language models have enabled the development of viable generative information retrieval systems. A generative retrieval system returns a grounded generated text in response to an information need instead of the traditional document ranking. Quantifying the utility of these types of responses is essential for evaluating generative retrieval systems. As the established evaluation methodology for ranking-based ad hoc retrieval may seem unsuitable for generative retrieval, new approaches for reliable, repeatable, and reproducible experimentation are required. In this paper, we survey the relevant information retrieval and natural language processing literature, identify search tasks and system architectures in generative retrieval, develop a corresponding user model, and study its operationalization. This theoretical analysis provides a foundation and new insights for the evaluation of generative ad hoc retrieval systems.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:大语言模型的最新进展已经实现了实用的生成信息搜寻系统。相比于传统的排名式搜寻，一个生成搜寻系统会返回一个对应的生成文本，以满足资讯需求。评估这种类型的回应的用度是评估生成搜寻系统的重要指标。由于传统的排名式搜寻评估方法可能不适用于生成搜寻，因此需要新的评估方法，以 Ensure reliable, repeatable, and reproducible experimentation。在这篇论文中，我们对信息搜寻和自然语言处理领域的相关文献进行了评价，识别了生成搜寻中的搜寻任务和系统架构，开发了用户模型，并进行了实现的研究。这个理论分析提供了一个基础和新的见解，用于评估生成随机搜寻系统。
</details></li>
</ul>
<hr>
<h2 id="Speech-language-models-lack-important-brain-relevant-semantics"><a href="#Speech-language-models-lack-important-brain-relevant-semantics" class="headerlink" title="Speech language models lack important brain-relevant semantics"></a>Speech language models lack important brain-relevant semantics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04664">http://arxiv.org/abs/2311.04664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subba Reddy Oota, Emin Çelik, Fatma Deniz, Mariya Toneva</li>
<li>for:  investigate the types of information that language models predict in the brain</li>
<li>methods: eliminate information related to specific low-level stimulus features in the language model representations and compare with speech-based language models</li>
<li>results: text-based language models align well with early sensory regions and later language regions, while speech-based models lose most of their alignment after removing low-level features, suggesting that speech-based models can be improved to better reflect brain-like language processing.<details>
<summary>Abstract</summary>
Despite known differences between reading and listening in the brain, recent work has shown that text-based language models predict both text-evoked and speech-evoked brain activity to an impressive degree. This poses the question of what types of information language models truly predict in the brain. We investigate this question via a direct approach, in which we eliminate information related to specific low-level stimulus features (textual, speech, and visual) in the language model representations, and observe how this intervention affects the alignment with fMRI brain recordings acquired while participants read versus listened to the same naturalistic stories. We further contrast our findings with speech-based language models, which would be expected to predict speech-evoked brain activity better, provided they model language processing in the brain well. Using our direct approach, we find that both text-based and speech-based language models align well with early sensory regions due to shared low-level features. Text-based models continue to align well with later language regions even after removing these features, while, surprisingly, speech-based models lose most of their alignment. These findings suggest that speech-based models can be further improved to better reflect brain-like language processing.
</details>
<details>
<summary>摘要</summary>
尽管已知文字和听 speech在脑中的差异， latest work 表明文字语言模型可以很好地预测文字诱发和说话诱发的脑活动。这意味着语言模型真正预测的信息是什么？我们通过直接方法来研究这个问题，在语言模型表示中消除了文字、说话和视觉相关的信息，然后观察到这种 intervención 对 fMRI 脑活动记录有多大的影响。我们进一步与speech-based语言模型进行比较，这些模型应该更好地预测说话诱发的脑活动，只要它们能够正确地模型脑中的语言处理。使用直接方法，我们发现了以下结论：文字基于的语言模型在消除低级特征后仍然能够准确地预测后续语言区域的脑活动，而speech-based模型则在消除低级特征后失去了大部分的Alignment。这些发现表明可以进一步改进speech-based模型，以更好地反映脑中的语言处理。
</details></li>
</ul>
<hr>
<h2 id="Massive-Editing-for-Large-Language-Models-via-Meta-Learning"><a href="#Massive-Editing-for-Large-Language-Models-via-Meta-Learning" class="headerlink" title="Massive Editing for Large Language Models via Meta Learning"></a>Massive Editing for Large Language Models via Meta Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04661">http://arxiv.org/abs/2311.04661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenmientan/malmen">https://github.com/chenmientan/malmen</a></li>
<li>paper_authors: Chenmien Tan, Ge Zhang, Jie Fu</li>
<li>for:  rectifying the knowledge of the language model (LM) after training, and editing multiple facts simultaneously with limited memory budgets</li>
<li>methods:  employing a hyper-network to generate parameter shift, formulating the parameter shift aggregation as the least square problem, and separating the computation on the hyper-network and LM to enable arbitrary batch size</li>
<li>results:  capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture, and outperforming editor specifically designed for GPT<details>
<summary>Abstract</summary>
While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameters using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2, T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks, i.e., closed book fact-checking and question answering. Remarkably, MALMEN is capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture and outperforms editor specifically designed for GPT. Our code is available at https://github.com/ChenmienTan/malmen.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经允许我们从预训练 corpora 中学习语言知识，但是这些学习的知识可能会随着时间的推移而变得不正确或过时，因此需要在训练后对语言模型（LM）进行修正。一种有前途的方法是使用 hyper-network 生成参数变化，但是现有的 hyper-network 受到同步编辑操作量的限制，导致它们的扩展性不够。为了解决这个问题，我们提出了 MAssive Language Model Editing Network（MALMEN），它将参数变化的汇集视为最小二乘问题，然后使用常数方程更新 LM 参数。为了在有限内存预算下同时编辑多个事实，我们将计算在 hyper-network 和 LM 之间分离，以便在两个神经网络上使用任意批处理大小。我们的方法在不同的语言模型架构（BERT-base、GPT-2、T5-XL 2.8B、GPT-J 6B）上进行了编辑，并在closed book fact-checking 和问答 tasks 上达到了remarkable的性能。特别是，MALMEN 能够编辑 hundreds 个事实，比strong baseline 高得多，并且超过了专门为 GPT 设计的编辑器。我们的代码可以在 <https://github.com/ChenmienTan/malmen> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Nature-of-Disagreements-on-Mid-Scale-Ratings-A-Case-Study-on-the-Abstractness-Concreteness-Continuum"><a href="#Investigating-the-Nature-of-Disagreements-on-Mid-Scale-Ratings-A-Case-Study-on-the-Abstractness-Concreteness-Continuum" class="headerlink" title="Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum"></a>Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04563">http://arxiv.org/abs/2311.04563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Urban Knupleš, Diego Frassinelli, Sabine Schulte im Walde</li>
<li>for: 这个研究的目的是提高评估中的一致性，尤其是在中等级别的词汇上。</li>
<li>methods: 这个研究使用了相关性和批处学习来 indentify 中等级别词汇的特征，并应用硬件 clustering 来检测评估者之间的不一致。</li>
<li>results: 研究结果表明，需要对中等级别词汇进行细化或滤除，以提高评估的一致性。<details>
<summary>Abstract</summary>
Humans tend to strongly agree on ratings on a scale for extreme cases (e.g., a CAT is judged as very concrete), but judgements on mid-scale words exhibit more disagreement. Yet, collected rating norms are heavily exploited across disciplines. Our study focuses on concreteness ratings and (i) implements correlations and supervised classification to identify salient multi-modal characteristics of mid-scale words, and (ii) applies a hard clustering to identify patterns of systematic disagreement across raters. Our results suggest to either fine-tune or filter mid-scale target words before utilising them.
</details>
<details>
<summary>摘要</summary>
人们往往在极端情况下（例如，一只猫被评为非常具体）达成强调的共识，但在中间级单词上存在更大的不一致。然而，收集的评分标准在不同领域中得到了广泛的利用。我们的研究关注了具体性评分，并（i）利用相关性和有监督的分类来挖掘多Modal特征，以及（ii）通过固定分 clustering来描述评分者之间的系统性不一致。我们的结果表明，在使用中间级单词之前，应该进行细化或过滤。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Distractors-in-Multiple-Choice-Tests"><a href="#Assessing-Distractors-in-Multiple-Choice-Tests" class="headerlink" title="Assessing Distractors in Multiple-Choice Tests"></a>Assessing Distractors in Multiple-Choice Tests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04554">http://arxiv.org/abs/2311.04554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vatsal Raina, Adian Liusie, Mark Gales</li>
<li>For: The paper aims to improve the quality of distractors in multiple-choice reading comprehension tests by proposing automated assessment metrics.* Methods: The paper uses a combination of classification ability, distractor confidence, and embedding-based equivalence metric to assess the quality of distractors.* Results: The paper validates the proposed metrics by comparing them against candidate distributions and a ChatGPT model’s interpretation of distractor plausibility and diversity.Here are the three key points in Simplified Chinese:* For: 该 paper 目的是提高多项选择评估测试中的吸引选项质量，通过提出自动评估指标。* Methods: 该 paper 使用组合 classification 能力、吸引选项信任度和基于嵌入的等价度量来评估吸引选项质量。* Results: 该 paper 通过与候选分布和 ChatGPT 模型的吸引选项可能性和多样性的比较来验证提出的指标。<details>
<summary>Abstract</summary>
Multiple-choice tests are a common approach for assessing candidates' comprehension skills. Standard multiple-choice reading comprehension exams require candidates to select the correct answer option from a discrete set based on a question in relation to a contextual passage. For appropriate assessment, the distractor answer options must by definition be incorrect but plausible and diverse. However, generating good quality distractors satisfying these criteria is a challenging task for content creators. We propose automated assessment metrics for the quality of distractors in multiple-choice reading comprehension tests. Specifically, we define quality in terms of the incorrectness, plausibility and diversity of the distractor options. We assess incorrectness using the classification ability of a binary multiple-choice reading comprehension system. Plausibility is assessed by considering the distractor confidence - the probability mass associated with the distractor options for a standard multi-class multiple-choice reading comprehension system. Diversity is assessed by pairwise comparison of an embedding-based equivalence metric between the distractors of a question. To further validate the plausibility metric we compare against candidate distributions over multiple-choice questions and agreement with a ChatGPT model's interpretation of distractor plausibility and diversity.
</details>
<details>
<summary>摘要</summary>
多选测试是评估候选人的理解能力的常见方法。标准多选读取理解测试要求候选人从问题相关的文本中选择正确的答案选项。为了有效评估，拥有者必须生成正确但不可靠、多样化的干扰答案。然而，生成高质量干扰答案是内容创建者的挑战。我们提议使用自动评估指标来评估干扰答案的质量。 Specifically，我们定义质量为干扰答案的不正确性、可能性和多样性。我们评估不正确性使用多选读取理解系统的分类能力。可能性是通过考虑问题相关的干扰选项的信任度来评估的。多样性是通过对干扰选项的对比来评估的。为了进一步验证可能性指标，我们与多个多选问题的候选人分布和ChatGPT模型的干扰可能性和多样性解释进行比较。
</details></li>
</ul>
<hr>
<h2 id="Large-GPT-like-Models-are-Bad-Babies-A-Closer-Look-at-the-Relationship-between-Linguistic-Competence-and-Psycholinguistic-Measures"><a href="#Large-GPT-like-Models-are-Bad-Babies-A-Closer-Look-at-the-Relationship-between-Linguistic-Competence-and-Psycholinguistic-Measures" class="headerlink" title="Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures"></a>Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04547">http://arxiv.org/abs/2311.04547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julius Steuer, Marius Mosbach, Dietrich Klakow</li>
<li>for: 这项研究的目的是检验语言模型（LM）的认知可能性，并探讨语言模型如何模型语言知识和处理语言任务。</li>
<li>methods: 本研究使用了一系列基于GPT的语言模型，对这些模型进行了不同的大小和深度的训练，并测试其在多个挑战任务（BLiMP、GLUE、MSGS）中的表现。</li>
<li>results: 研究发现，LM的大小和表现之间存在正相关关系，而且不同任务中对模型宽度和深度的选择也有不同的偏好。此外，研究还发现，模型处理时间预测Task中LM的大小和表现之间存在负相关关系，表明模型语言知识和处理语言任务可能需要采用不同的方法。<details>
<summary>Abstract</summary>
Research on the cognitive plausibility of language models (LMs) has so far mostly concentrated on modelling psycholinguistic response variables such as reading times, gaze durations and N400/P600 EEG signals, while mostly leaving out the dimension of what Mahowald et al. (2023) described as formal and functional linguistic competence, and developmental plausibility. We address this gap by training a series of GPT-like language models of different sizes on the strict version of the BabyLM pretraining corpus, evaluating on the challenge tasks (BLiMP, GLUE, MSGS) and an additional reading time prediction task. We find a positive correlation between LM size and performance on all three challenge tasks, with different preferences for model width and depth in each of the tasks. In contrast, a negative correlation was found between LM size and reading time fit of linear mixed-effects models using LM surprisal as a predictor, with the second-smallest LM achieving the largest log-likelihood reduction over a baseline model without surprisal. This suggests that modelling processing effort and linguistic competence may require an approach different from training GPT-like LMs on a developmentally plausible corpus.
</details>
<details>
<summary>摘要</summary>
研究语言模型（LM）的认知可能性的研究大多集中在模拟心理语言反应变量，如阅读时间、视线持续时间和N400/P600 EEG信号，而忽略了语言模型的形式和功能语言能力、发展可能性的维度。我们填补这个空白，通过在严格版本的BabyLM预学材料上训练一系列GPT-like语言模型不同大小，并在BLiMP、GLUE和MSGS挑战任务以及额外的阅读时间预测任务上评估其表现。我们发现LM大小和任务中的表现之间存在正相关，不同任务中LM宽度和深度的偏好有所不同。同时，我们发现LM大小和使用LMsurprisal作为预测变量的线性混合效应模型的阅读时间适应性存在负相关，第二小的LM在log-likelihood下得到了最大减少。这表明，模拟处理努力和语言能力可能需要一种不同于训练GPT-like LMs在发展可能性的 corpus 的方法。
</details></li>
</ul>
<hr>
<h2 id="Loss-Masking-Is-Not-Needed-in-Decoder-only-Transformer-for-Discrete-token-Based-ASR"><a href="#Loss-Masking-Is-Not-Needed-in-Decoder-only-Transformer-for-Discrete-token-Based-ASR" class="headerlink" title="Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR"></a>Loss Masking Is Not Needed in Decoder-only Transformer for Discrete-token Based ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04534">http://arxiv.org/abs/2311.04534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qian Chen, Wen Wang, Qinglin Zhang, Siqi Zheng, Shiliang Zhang, Chong Deng, Yukun Ma, Hai Yu, Jiaqing Liu, Chong Zhang</li>
<li>for: 这个论文主要针对的是基于普通话语音识别任务的单个decoder-only transformer模型。</li>
<li>methods: 该论文使用了损失压缩（Loss Masking）来模型输入语音标签的序列结构，但发现这种方法不能一直提高ASR性能。因此，该论文提出了一种新的方法，即简化标签散列（Smoothed Label Distillation，SLD），通过在输入语音标签上添加KL散列损失来有效地模型语音标签序列。</li>
<li>results: 实验表明，SLD方法可以超越损失压缩和文本散列方法，并且可以适应不同的语音分词方法。<details>
<summary>Abstract</summary>
Recently, unified speech-text models, such as SpeechGPT, VioLA, and AudioPaLM, have achieved remarkable performance on speech tasks. These models convert continuous speech signals into discrete tokens (speech discretization) and merge text and speech tokens into a shared vocabulary. Then they train a single decoder-only Transformer on a mixture of speech tasks. Specifically, all these models utilize Loss Masking on the input speech tokens for the ASR task, which means that these models do not explicitly model the dependency between the speech tokens. In this paper, we attempt to model the sequence of speech tokens in an autoregressive manner like text. However, we find that applying the conventional cross-entropy loss on input speech tokens does not consistently improve the ASR performance over Loss Masking. Therefore, we propose a novel approach denoted Smoothed Label Distillation (SLD), which introduces a KL divergence loss with smoothed labels on the input speech tokens to effectively model speech tokens. Experiments demonstrate that our SLD approach alleviates the limitations of the cross-entropy loss and consistently outperforms Loss Masking for decoder-only Transformer based ASR using different speech discretization methods.
</details>
<details>
<summary>摘要</summary>
最近，一些听说模型，如SpeechGPT、VioLA和AudioPaLM，在听说任务上表现出色。这些模型将连续的听说信号转换为精确的token（听说精确），然后将文本和听说token合并到共享词汇中。然后，它们使用单个decoder-only transformer来训练混合的听说任务。具体来说，所有这些模型都使用输入听说token的损失掩蔽（loss masking）来实现ASR任务，这意味着这些模型不需要直接模型听说token之间的依赖关系。在这篇论文中，我们尝试模型听说token的序列在抽象的方式上，但我们发现，将输入听说token的普通十字积分损失应用于听说token上不一定能够提高ASR性能。因此，我们提出了一种新的方法，称为简化标签混合（SLD），它在输入听说token上引入KL散度损失和缓和标签来有效地模型听说token。实验表明，我们的SLD方法可以解决普通十字积分损失的局限性，并在不同的听说精确方法下一直超越损失掩蔽。
</details></li>
</ul>
<hr>
<h2 id="Conversation-Understanding-using-Relational-Temporal-Graph-Neural-Networks-with-Auxiliary-Cross-Modality-Interaction"><a href="#Conversation-Understanding-using-Relational-Temporal-Graph-Neural-Networks-with-Auxiliary-Cross-Modality-Interaction" class="headerlink" title="Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction"></a>Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04507">http://arxiv.org/abs/2311.04507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cam-Van Thi Nguyen, Anh-Tuan Mai, The-Son Le, Hai-Dang Kieu, Duc-Trong Le</li>
<li>for: 这篇论文主要针对人工智能对话理解中的情绪识别问题，具体来说是在多modal数据下进行情绪识别。</li>
<li>methods: 本文提出了一种新的神经网络框架，即Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction（CORECT），该框架能够有效地捕捉对话水平的跨modal交互以及每个句子的时间依赖关系，同时还能够利用modal特定的表示方式进行情绪识别。</li>
<li>results: 对于IEMOCAP和CMU-MOSEI datasets上的多modal ERC任务，CORECT得到了状态之Art的Result，证明了其效果性。<details>
<summary>Abstract</summary>
Emotion recognition is a crucial task for human conversation understanding. It becomes more challenging with the notion of multimodal data, e.g., language, voice, and facial expressions. As a typical solution, the global- and the local context information are exploited to predict the emotional label for every single sentence, i.e., utterance, in the dialogue. Specifically, the global representation could be captured via modeling of cross-modal interactions at the conversation level. The local one is often inferred using the temporal information of speakers or emotional shifts, which neglects vital factors at the utterance level. Additionally, most existing approaches take fused features of multiple modalities in an unified input without leveraging modality-specific representations. Motivating from these problems, we propose the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), an novel neural network framework that effectively captures conversation-level cross-modality interactions and utterance-level temporal dependencies with the modality-specific manner for conversation understanding. Extensive experiments demonstrate the effectiveness of CORECT via its state-of-the-art results on the IEMOCAP and CMU-MOSEI datasets for the multimodal ERC task.
</details>
<details>
<summary>摘要</summary>
情感识别是人工对话理解中的关键任务。在多模式数据下，情感识别变得更加挑战性，例如语言、声音和脸部表达。为解决这问题，通常采用全局和本地上下文信息来预测对话中每个句子的情感标签。特别是，全局表示可以通过对话水平的交互模型来捕捉全局信息。本地一是通过说话者的时间信息或情感变化来推断，忽略了对话中每个句子的重要因素。此外，大多数现有方法具有融合多模式特征的Input而不利用特定模式的表示。为此，我们提出了一种新的神经网络框架：相互关系图神经网络with协助交互（CORECT），可以有效地捕捉对话水平的交互和每个句子的时间依赖关系，同时还能够利用特定模式的表示来提高对话理解。我们对IEMOCAP和CMU-MOSEI数据集进行了广泛的实验，并证明了CORECT的效果。
</details></li>
</ul>
<hr>
<h2 id="Multi-label-and-Multi-target-Sampling-of-Machine-Annotation-for-Computational-Stance-Detection"><a href="#Multi-label-and-Multi-target-Sampling-of-Machine-Annotation-for-Computational-Stance-Detection" class="headerlink" title="Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection"></a>Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04495">http://arxiv.org/abs/2311.04495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/seq-to-mind/Stance_MA">https://github.com/seq-to-mind/Stance_MA</a></li>
<li>paper_authors: Zhengyuan Liu, Hai Leong Chieu, Nancy F. Chen</li>
<li>for: 这篇论文主要用于研究自动化标注的可行性和效果，以及如何使用大语言模型进行计算意见探测。</li>
<li>methods: 该论文使用了大语言模型进行自动化标注，并采用了多标签多目标采样策略来优化标注质量。</li>
<li>results: 实验结果表明，使用该方法可以显著提高计算意见探测的性能和学习效果。<details>
<summary>Abstract</summary>
Data collection from manual labeling provides domain-specific and task-aligned supervision for data-driven approaches, and a critical mass of well-annotated resources is required to achieve reasonable performance in natural language processing tasks. However, manual annotations are often challenging to scale up in terms of time and budget, especially when domain knowledge, capturing subtle semantic features, and reasoning steps are needed. In this paper, we investigate the efficacy of leveraging large language models on automated labeling for computational stance detection. We empirically observe that while large language models show strong potential as an alternative to human annotators, their sensitivity to task-specific instructions and their intrinsic biases pose intriguing yet unique challenges in machine annotation. We introduce a multi-label and multi-target sampling strategy to optimize the annotation quality. Experimental results on the benchmark stance detection corpora show that our method can significantly improve performance and learning efficacy.
</details>
<details>
<summary>摘要</summary>
<<SYS>>文本收集自手动标注提供域 especific 和任务aligned 的监督 для数据驱动方法，并需要一个可观的标注资源来达到自然语言处理任务的合理性。然而，手动标注经常困难Scaling up в时间和预算方面，特别是当域知识、捕捉微妙 semantics 和reasoning步骤需要。在这篇论文中，我们调查使用大型自然语言模型进行自动标注的可能性。我们经验证显示，虽然大型自然语言模型在人工标注者的替代者中表现出色，但是它们对任务特定的指示和自身偏见带来了有趣却独特的挑战。我们提出了一种多标签多目标采样策略，以提高标注质量。实验结果表明，我们的方法可以在标准折衔检测 corpora 上显著提高性能和学习效果。Note: Simplified Chinese is the standard writing system used in mainland China, and it is different from Traditional Chinese, which is used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="CLearViD-Curriculum-Learning-for-Video-Description"><a href="#CLearViD-Curriculum-Learning-for-Video-Description" class="headerlink" title="CLearViD: Curriculum Learning for Video Description"></a>CLearViD: Curriculum Learning for Video Description</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04480">http://arxiv.org/abs/2311.04480</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yueyue0401/CLV">https://github.com/yueyue0401/CLV</a></li>
<li>paper_authors: Cheng-Yu Chuang, Pooyan Fazli</li>
<li>for: 这 paper 是为了提出一种基于 transformer 的视频描述生成模型，以便自动生成 coherent 的自然语言句子，描述视频的内容。</li>
<li>methods: 这 paper 使用了两种 curriculum 策略：首先，通过逐渐应用 Gaussian 噪声到视频数据来逐渐暴露模型更加困难的样本，其次，通过 dropout 技术逐渐减少网络的容量，以便让模型学习更加稳定和泛化的特征。此外，这 paper 还使用了 Mish 激活函数，该函数提供了非线性和非凸性，帮助解决梯度消失问题。</li>
<li>results: 根据两个 dataset， namely ActivityNet Captions 和 YouCook2，我们的 CLearViD 模型在评价精度和多样性指标上具有显著的优势，与现有的状态数据模型相比， CLearViD 能够更好地描述视频的内容。<details>
<summary>Abstract</summary>
Video description entails automatically generating coherent natural language sentences that narrate the content of a given video. We introduce CLearViD, a transformer-based model for video description generation that leverages curriculum learning to accomplish this task. In particular, we investigate two curriculum strategies: (1) progressively exposing the model to more challenging samples by gradually applying a Gaussian noise to the video data, and (2) gradually reducing the capacity of the network through dropout during the training process. These methods enable the model to learn more robust and generalizable features. Moreover, CLearViD leverages the Mish activation function, which provides non-linearity and non-monotonicity and helps alleviate the issue of vanishing gradients. Our extensive experiments and ablation studies demonstrate the effectiveness of the proposed model. The results on two datasets, namely ActivityNet Captions and YouCook2, show that CLearViD significantly outperforms existing state-of-the-art models in terms of both accuracy and diversity metrics.
</details>
<details>
<summary>摘要</summary>
<SYS>转化文本到简化中文。</SYS>视频描述包括自动生成 coherent 的自然语言句子，描述视频内容。我们介绍 CLearViD，一种基于 transformer 的模型，用于视频描述生成。特别是，我们调查了两种课程策略：（1）逐渐对视频数据应用 Gaussian 噪声，以慢慢地暴露模型更加具有挑战性的样本，以及（2）在训练过程中逐渐减少网络的容量，通过 dropout 来逐渐减少网络的复杂性。这些方法使得模型可以学习更加强健和普适的特征。此外，CLearViD 还使用 Mish 活动函数，该函数提供了非线性和非凸性，帮助解决梯度消失问题。我们进行了广泛的实验和简单化研究，展示了提案的模型的效果。结果在 ActivityNet Captions 和 YouCook2 两个 datasets 上表明，CLearViD 在精度和多样性指标上显著超越了现有的状态机制模型。
</details></li>
</ul>
<hr>
<h2 id="Twitter-Sentiment-Analysis-of-Covid-Vacciness"><a href="#Twitter-Sentiment-Analysis-of-Covid-Vacciness" class="headerlink" title="Twitter Sentiment Analysis of Covid Vacciness"></a>Twitter Sentiment Analysis of Covid Vacciness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04479">http://arxiv.org/abs/2311.04479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenbo Zhu, Tiechuan Hu</li>
<li>for: 这个研究旨在对Twitter上关于COVID-19疫苗的 opinioins进行分类和排名，以便尽可能准确地理解用户对疫苗的看法，并影响用户决策和行为。</li>
<li>methods: 该研究使用自然语言处理技术来分类和排名Twitter上的 opinioins，并使用两种不同的排名策略来评估分类精度。</li>
<li>results: 研究发现，使用自然语言处理技术可以准确地分类和排名Twitter上的 opinioins，并且使用不同的排名策略可以提高分类精度。<details>
<summary>Abstract</summary>
In this paper, we look at a database of tweets sorted by various keywords that could indicate the users sentiment towards covid vaccines. With social media becoming such a prevalent source of opinion, sorting and ranking tweets that hold important information such as opinions on covid vaccines is of utmost importance. Two different ranking scales were used, and ranking a tweet in this way could represent the difference between an opinion being lost and an opinion being featured on the site, which affects the decisions and behavior of people, and why researchers were interested in it. Using natural language processing techniques, our aim is to determine and categorize opinions about covid vaccines with the highest accuracy possible.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了一个关键词汇分类的推特数据库，以便分析用户对 COVID-19 疫苗的看法。随着社交媒体在意见表达方面的普遍性，分类和排名推特中包含有价值信息的 tweet 的重要性日益增加。我们采用了两种不同的排名级别，排名一 tweet 可能代表了意见被排除或者被Site 上特有的意见，这会影响人们的决策和行为，因此研究人员对其很感兴趣。使用自然语言处理技术，我们目标是尽可能准确地确定和分类 COVID-19 疫苗的看法。
</details></li>
</ul>
<hr>
<h2 id="Lewis’s-Signaling-Game-as-beta-VAE-For-Natural-Word-Lengths-and-Segments"><a href="#Lewis’s-Signaling-Game-as-beta-VAE-For-Natural-Word-Lengths-and-Segments" class="headerlink" title="Lewis’s Signaling Game as beta-VAE For Natural Word Lengths and Segments"></a>Lewis’s Signaling Game as beta-VAE For Natural Word Lengths and Segments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04453">http://arxiv.org/abs/2311.04453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryo Ueda, Tadahiro Taniguchi</li>
<li>for: 本研究的目的是使emergent communication（EC）中的通信协议（emergent language）具有自然语言的统计性质。</li>
<li>methods: 本研究使用了beta-VAE重新解释了Lewis的信号游戏（一种常用的EC设定），并重新设定了目标函数为ELBO。</li>
<li>results: 研究发现，选择合适的先验分布可以使emergent language更容易遵循Zipf的压缩法（ZLA）和Harris的词法分析（HAS）。在传统的目标函数下，emergent language并不遵循这两个法则。通过实验，研究证明了这一点。<details>
<summary>Abstract</summary>
As a sub-discipline of evolutionary and computational linguistics, emergent communication (EC) studies communication protocols, called emergent languages, arising in simulations where agents communicate. A key goal of EC is to give rise to languages that share statistical properties with natural languages. In this paper, we reinterpret Lewis's signaling game, a frequently used setting in EC, as beta-VAE and reformulate its objective function as ELBO. Consequently, we clarify the existence of prior distributions of emergent languages and show that the choice of the priors can influence their statistical properties. Specifically, we address the properties of word lengths and segmentation, known as Zipf's law of abbreviation (ZLA) and Harris's articulation scheme (HAS), respectively. It has been reported that the emergent languages do not follow them when using the conventional objective. We experimentally demonstrate that by selecting an appropriate prior distribution, more natural segments emerge, while suggesting that the conventional one prevents the languages from following ZLA and HAS.
</details>
<details>
<summary>摘要</summary>
EC（emergent communication）是一个演化语言和计算语言的子领域，研究在代理人之间进行通信的协议，称为emergent language，并寻求这些语言与自然语言共享统计特征。在这篇论文中，我们将划重点到 Lewis 的信号游戏，这是 EC 中 frequently 使用的设定，并重新解释其目标函数为 ELBO。因此，我们可以明确emergent language的先前分布的存在，并证明选择合适的先前分布可以影响其统计特征。特别是，我们关注word lengths和分 segmentation，即Zipf's law of abbreviation (ZLA)和Harris's articulation scheme (HAS)。据报道，使用传统的目标函数时，emergent language不会遵循这些法律。我们通过实验表明，选择合适的先前分布可以使emergent language更加自然，并建议传统的目标函数阻碍语言遵循ZLA和HAS。
</details></li>
</ul>
<hr>
<h2 id="Recursion-in-Recursion-Two-Level-Nested-Recursion-for-Length-Generalization-with-Scalability"><a href="#Recursion-in-Recursion-Two-Level-Nested-Recursion-for-Length-Generalization-with-Scalability" class="headerlink" title="Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability"></a>Recursion in Recursion: Two-Level Nested Recursion for Length Generalization with Scalability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04449">http://arxiv.org/abs/2311.04449</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jrc1995/beamrecursionfamily">https://github.com/jrc1995/beamrecursionfamily</a></li>
<li>paper_authors: Jishnu Ray Chowdhury, Cornelia Caragea</li>
<li>for: 这篇论文的目的是提出一种新的框架，即嵌套嵌套的回归框架（RIR），以解决深度回归模型在长序列任务上的缺点和中间回归模型在结构敏感任务上的缺点。</li>
<li>methods: 这篇论文使用了一种二重嵌套的回归模型，即外层是一个 $k$-ary 平衡二叉树模型，内层是一个嵌套的回归模型（内层回归）。内层回归使用的是 Beam Tree RvNN（BT-RvNN）。为了调整 BT-RvNN 在 RIR 中，提出了一种新的扩散策略。</li>
<li>results: 作者们的最佳 RIR-based 模型可以在 ListOps 上达到高于 90% 的长度总结束性性能，并且可以在长序列输入上进行训练，而不需要特殊的初始化。此外，在 LRA 语言任务中，这个模型与 Structured State Space Models（SSMs）竞争，并且在长序列输入上表现更好。<details>
<summary>Abstract</summary>
Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according to a preset balanced binary tree structure. Thus, their non-linear recursion depth is just $\log_2 n$ ($n$ being the sequence length). Such logarithmic scaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as Long Range Arena (LRA). However, such computational efficiency comes at a cost because BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the flip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other structure-sensitive tasks like formal logical inference) are generally several times more expensive than even RNNs. In this paper, we introduce a novel framework -- Recursion in Recursion (RIR) to strike a balance between the two sides - getting some of the benefits from both worlds. In RIR, we use a form of two-level nested recursion - where the outer recursion is a $k$-ary balanced tree model with another recursive model (inner recursion) implementing its cell function. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To adjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment. Overall, this entails that the total recursive depth in RIR is upper-bounded by $k \log_k n$. Our best RIR-based model is the first model that demonstrates high ($\geq 90\%$) length-generalization performance on ListOps while at the same time being scalable enough to be trainable on long sequence inputs from LRA. Moreover, in terms of accuracy in the LRA language tasks, it performs competitively with Structured State Space Models (SSMs) without any special initialization - outperforming Transformers by a large margin. On the other hand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to length-generalize on ListOps. Our code is available at: \url{https://github.com/JRC1995/BeamRecursionFamily/}.
</details>
<details>
<summary>摘要</summary>
binary 平衡树 RvNNs (BBT-RvNNs) 强制序列组合按照预先设定的平衡二进制树结构进行。因此，它们的非线性循环深度只是 log2 n（n 是序列长度）。这种对数循环深度的扩展使 BBT-RvNNs 在长序列任务上如Long Range Arena (LRA) 中高效并可扩展。然而，这种计算效率的代价是 BBT-RvNNs 无法解决简单的数学任务，如 ListOps。相反，使用 RvNNs（例如 Beam Tree RvNN）可以在 ListOps 和其他结构敏感任务中达到更高的性能，但是它们通常比 RNNs 多出几个数量级。在这篇论文中，我们介绍了一种新的框架---Recursion in Recursion (RIR)，以实现这两个方面之间的平衡。在 RIR 中，我们使用 $k$-ary 平衡树模型，其中另一个嵌入的 Recursive 模型（内嵌 recursion）实现其细胞函数。对于内嵌 recursion，我们选择 Beam Tree RvNNs (BT-RvNN)。为了调整 BT-RvNNs 在 RIR 中，我们还提出了一种新的扩展策略---排队对alignment。总的来说，RIR 的全 recursive depth upper bound 为 $k \log_k n$。我们的最佳 RIR-based 模型可以在 ListOps 上达到长度普遍性（大于 90%）的性能，同时可以在 Long Range Arena (LRA) 中训练长序列输入。此外，在 LRA 语言任务中，它的准确性与 Structured State Space Models (SSMs) 相当，而不需要特殊的初始化。相比之下，SSMs 可以在 LRA 上marginally 超过 RIR，但是它们无法长度普遍化在 ListOps。我们的代码可以在以下链接中找到：\url{https://github.com/JRC1995/BeamRecursionFamily/}。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/cs.CL_2023_11_08/" data-id="clorjzl5f00e3f1883667ce7z" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/cs.LG_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T10:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/cs.LG_2023_11_08/">cs.LG - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Optimized-measurements-of-chaotic-dynamical-systems-via-the-information-bottleneck"><a href="#Optimized-measurements-of-chaotic-dynamical-systems-via-the-information-bottleneck" class="headerlink" title="Optimized measurements of chaotic dynamical systems via the information bottleneck"></a>Optimized measurements of chaotic dynamical systems via the information bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04896">http://arxiv.org/abs/2311.04896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kieran A. Murphy, Dani S. Bassett</li>
<li>for: 这篇论文目的是提出一种基于机器学习的方法来提取漫步数据中的信息，以提高信息的效率和可靠性。</li>
<li>methods: 这篇论文使用了一种 variants of the information bottleneck 来实现一种准确的测量方法，并使用机器学习来优化测量过程。</li>
<li>results: 研究人员通过使用这种方法在多种杂态图中获得了约等效的测量结果，并为普通时间序列提供了一种有效的信息提取方法。<details>
<summary>Abstract</summary>
Deterministic chaos permits a precise notion of a "perfect measurement" as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy. Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done. We establish an equivalence between a perfect measurement and a variant of the information bottleneck. As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data. We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series.
</details>
<details>
<summary>摘要</summary>
tranlate_input = "Deterministic chaos permits a precise notion of a 'perfect measurement' as one that, when obtained repeatedly, captures all of the information created by the system's evolution with minimal redundancy. Finding an optimal measurement is challenging, and has generally required intimate knowledge of the dynamics in the few cases where it has been done. We establish an equivalence between a perfect measurement and a variant of the information bottleneck. As a consequence, we can employ machine learning to optimize measurement processes that efficiently extract information from trajectory data. We obtain approximately optimal measurements for multiple chaotic maps and lay the necessary groundwork for efficient information extraction from general time series."translate_output = translate_input.translate(to_language='zh-CN').font_substitute(    keywords=['deterministic chaos', 'perfect measurement', 'information bottleneck', 'machine learning', 'trajectory data', 'chaotic maps', 'time series'],    to_language='zh-CN')print(translate_output)# Output:<<SYS>通用化的混沌允许我们对系统演化过程中创造的信息进行精确的捕捉，并且可以通过重复获得这种准确的测量，以Minimize redundancy。找到最佳测量是一项挑战，通常需要对系统动力学有深入的了解。我们证明了一种等价关系，即完美测量与信息瓶颈之间的等价关系。这意味着我们可以通过机器学习来优化测量过程，以 efficiently Extract information from trajectory data。我们对多个混沌图进行了 approximately optimal measurements，并为通用时间序列提供了必要的基础。Note: The above output is in Simplified Chinese. The `font_substitute` function is used to replace certain keywords with their Simplified Chinese equivalents. The `to_language` parameter is set to `'zh-CN'` to specify that the output should be in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Computing-with-Residue-Numbers-in-High-Dimensional-Representation"><a href="#Computing-with-Residue-Numbers-in-High-Dimensional-Representation" class="headerlink" title="Computing with Residue Numbers in High-Dimensional Representation"></a>Computing with Residue Numbers in High-Dimensional Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04872">http://arxiv.org/abs/2311.04872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cjkymn/residuehdcomputing">https://github.com/cjkymn/residuehdcomputing</a></li>
<li>paper_authors: Christopher J. Kymn, Denis Kleyko, E. Paxon Frady, Connor Bybee, Pentti Kanerva, Friedrich T. Sommer, Bruno A. Olshausen</li>
<li>for: 这篇论文是为了提出一种新的计算框架，即循环高维计算（Residue Hyperdimensional Computing），用于解决计算复杂的问题。</li>
<li>methods: 该框架使用了循环数字系统和高维随机向量的代数运算，并使用高维向量的分解方法来实现对数值的表示和操作。这些操作可以是分组、并行的，需要 fewer 资源 than previous methods。</li>
<li>results: 研究人员通过应用这种框架解决了一些计算难题，包括视觉认知和 combinatorial 优化问题，并与基eline方法进行比较。此外，这种框架还可能地解释大脑Grid cells的计算操作，并提供了新的机器学习架构来表示和操作数字数据。<details>
<summary>Abstract</summary>
We introduce Residue Hyperdimensional Computing, a computing framework that unifies residue number systems with an algebra defined over random, high-dimensional vectors. We show how residue numbers can be represented as high-dimensional vectors in a manner that allows algebraic operations to be performed with component-wise, parallelizable operations on the vector elements. The resulting framework, when combined with an efficient method for factorizing high-dimensional vectors, can represent and operate on numerical values over a large dynamic range using vastly fewer resources than previous methods, and it exhibits impressive robustness to noise. We demonstrate the potential for this framework to solve computationally difficult problems in visual perception and combinatorial optimization, showing improvement over baseline methods. More broadly, the framework provides a possible account for the computational operations of grid cells in the brain, and it suggests new machine learning architectures for representing and manipulating numerical data.
</details>
<details>
<summary>摘要</summary>
我团队介绍了剩余超维计算框架，这是一种将剩余数系统与随机高维向量上定义的代数结合起来的计算框架。我们示示了如何将剩余数转换为高维向量的方式，以便在向量元素上进行分 Component-wise、并行化的运算。这种框架，当与高维向量分解方法相结合时，可以使用较少的资源来表示和处理大Dynamic range的数值，并且具有很好的鲁棒性 against noise。我们示示了这种框架可以解决计算困难的问题，如视觉recognition和组合优化问题，并且比基eline方法有所提高。更重要的是，这种框架可能对大脑Grid cells的计算操作提供了一种可能的解释，并且建议了一种新的机器学习架构来表示和操作数字数据。
</details></li>
</ul>
<hr>
<h2 id="Algorithms-for-Non-Negative-Matrix-Factorization-on-Noisy-Data-With-Negative-Values"><a href="#Algorithms-for-Non-Negative-Matrix-Factorization-on-Noisy-Data-With-Negative-Values" class="headerlink" title="Algorithms for Non-Negative Matrix Factorization on Noisy Data With Negative Values"></a>Algorithms for Non-Negative Matrix Factorization on Noisy Data With Negative Values</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04855">http://arxiv.org/abs/2311.04855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dylan Green, Stephen Bailey</li>
<li>for: This paper is written for analyzing noisy data, especially astronomical data, which may contain negative values due to noise.</li>
<li>methods: The paper presents two algorithms, Shift-NMF and Nearly-NMF, that can handle both the noisiness of the input data and any introduced negativity without clipping the data.</li>
<li>results: The algorithms are proven to have monotonically decreasing update rules and can correctly recover non-negative signals without any introduced positive offset. The paper demonstrates the effectiveness of the algorithms on both simple and more realistic examples.<details>
<summary>Abstract</summary>
Non-negative matrix factorization (NMF) is a dimensionality reduction technique that has shown promise for analyzing noisy data, especially astronomical data. For these datasets, the observed data may contain negative values due to noise even when the true underlying physical signal is strictly positive. Prior NMF work has not treated negative data in a statistically consistent manner, which becomes problematic for low signal-to-noise data with many negative values. In this paper we present two algorithms, Shift-NMF and Nearly-NMF, that can handle both the noisiness of the input data and also any introduced negativity. Both of these algorithms use the negative data space without clipping, and correctly recover non-negative signals without any introduced positive offset that occurs when clipping negative data. We demonstrate this numerically on both simple and more realistic examples, and prove that both algorithms have monotonically decreasing update rules.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Incorporating-temporal-dynamics-of-mutations-to-enhance-the-prediction-capability-of-antiretroviral-therapy’s-outcome-for-HIV-1"><a href="#Incorporating-temporal-dynamics-of-mutations-to-enhance-the-prediction-capability-of-antiretroviral-therapy’s-outcome-for-HIV-1" class="headerlink" title="Incorporating temporal dynamics of mutations to enhance the prediction capability of antiretroviral therapy’s outcome for HIV-1"></a>Incorporating temporal dynamics of mutations to enhance the prediction capability of antiretroviral therapy’s outcome for HIV-1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04846">http://arxiv.org/abs/2311.04846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giulia Di Teodoro, Martin Pirkl, Francesca Incardona, Ilaria Vicenti, Anders Sönnerborg, Rolf Kaiser, Laura Palagi, Maurizio Zazzi, Thomas Lengauer</li>
<li>for: This paper aims to determine whether using historical information can improve the accuracy of predicting HIV therapy outcomes compared to using only current data.</li>
<li>methods: The authors introduce a method to weigh viral mutations based on their temporal occurrence and concomitant viral load measurements, and compare a model that includes historical information (H-model) with one that does not (NH-model).</li>
<li>results: The H-model demonstrates superior discriminative ability, with a higher ROC-AUC score (76.34%) than the NH-model (74.98%). Incorporating historical information improves consistently predictive accuracy for treatment outcomes, and the better performance of the H-model may be attributed to its consideration of latent HIV reservoirs.Here are the three points in Simplified Chinese text:</li>
<li>for: 这项研究的目的是判断 whether 使用历史信息可以提高 HIV 治疗结果预测的准确性，相比使用只有当前数据。</li>
<li>methods: 作者们引入了一种基于时间的权重方法，用于评估病毒变异的重要性，并对比一个不包含历史信息的模型（NH-model）和一个包含历史信息的模型（H-model）。</li>
<li>results: H-model 表现出了更高的 ROC-AUC 分数（76.34%），与 NH-model 的分数（74.98%）相比，这表明 incorporating 历史信息 可以提高预测结果的准确性。<details>
<summary>Abstract</summary>
Motivation: In predicting HIV therapy outcomes, a critical clinical question is whether using historical information can enhance predictive capabilities compared with current or latest available data analysis. This study analyses whether historical knowledge, which includes viral mutations detected in all genotypic tests before therapy, their temporal occurrence, and concomitant viral load measurements, can bring improvements. We introduce a method to weigh mutations, considering the previously enumerated factors and the reference mutation-drug Stanford resistance tables. We compare a model encompassing history (H) with one not using it (NH). Results: The H-model demonstrates superior discriminative ability, with a higher ROC-AUC score (76.34%) than the NH-model (74.98%). Significant Wilcoxon test results confirm that incorporating historical information improves consistently predictive accuracy for treatment outcomes. The better performance of the H-model might be attributed to its consideration of latent HIV reservoirs, probably obtained when leveraging historical information. The findings emphasize the importance of temporal dynamics in mutations, offering insights into HIV infection complexities. However, our result also shows that prediction accuracy remains relatively high even when no historical information is available. Supplementary information: Supplementary material is available.
</details>
<details>
<summary>摘要</summary>
目的：判断HIV治疗结果的估计，一个关键的临床问题是 Whether using historical information can enhance predictive capabilities compared with current or latest available data analysis. This study examines whether historical knowledge, including viral mutations detected in all genotypic tests before therapy, their temporal occurrence, and concomitant viral load measurements, can bring improvements. We propose a method to weigh mutations, considering the previously enumerated factors and the reference mutation-drug Stanford resistance tables. We compare a model encompassing history (H) with one not using it (NH).结果：H-model 的抑制能力显示出优于 NH-model 的 ROC-AUC 分数 (76.34% vs. 74.98%), 并且 Wilcoxon 测试结果表明，使用历史信息可逐止预测结果的准确性。 H-model 的更好表现可能是由于其考虑了潜在的 HIV 储存库，可能是通过历史信息获得的。 这些结果强调了HIV感染的复杂性，并且表明了时间动态的病毒变异对预测结果的重要性。 然而，我们的结果也表明，即使没有历史信息，预测结果的准确性仍然相对高。补充信息：补充材料可以在附录中找到。
</details></li>
</ul>
<hr>
<h2 id="Bridging-Dimensions-Confident-Reachability-for-High-Dimensional-Controllers"><a href="#Bridging-Dimensions-Confident-Reachability-for-High-Dimensional-Controllers" class="headerlink" title="Bridging Dimensions: Confident Reachability for High-Dimensional Controllers"></a>Bridging Dimensions: Confident Reachability for High-Dimensional Controllers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04843">http://arxiv.org/abs/2311.04843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuang Geng, Souradeep Dutta, Ivan Ruchkin</li>
<li>for: 这 paper 的目的是将高维控制器的验证方法与高维图像感知相连接。</li>
<li>methods: 这 paper 使用了验证感知知识填充来将高维控制器的行为approximation为低维控制器的行为。</li>
<li>results: 这 paper 的研究结果表明，通过使用验证感知知识填充，可以提供高维控制器的高 confidence 的可达性保证。两种inflation技术（基于轨迹和行为）在 OpenAI gym  benchmark 中表现出色。<details>
<summary>Abstract</summary>
Autonomous systems are increasingly implemented using end-end-end trained controllers. Such controllers make decisions that are executed on the real system with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions. Especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation. Then, if low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller. We investigate two inflation techniques -- based on trajectories and actions -- both of which show convincing performance in two OpenAI gym benchmarks.
</details>
<details>
<summary>摘要</summary>
Our key insight is that the behavior of a high-dimensional controller can be approximated with several low-dimensional controllers in different regions of the state space. To balance approximation and verifiability, we leverage the latest verification-aware knowledge distillation. If low-dimensional reachability results are inflated with statistical approximation errors, they yield a high-confidence reachability guarantee for the high-dimensional controller.We investigate two inflation techniques based on trajectories and actions, both of which show convincing performance in two OpenAI gym benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Toward-Rapid-Optimal-and-Feasible-Power-Dispatch-through-Generalized-Neural-Mapping"><a href="#Toward-Rapid-Optimal-and-Feasible-Power-Dispatch-through-Generalized-Neural-Mapping" class="headerlink" title="Toward Rapid, Optimal, and Feasible Power Dispatch through Generalized Neural Mapping"></a>Toward Rapid, Optimal, and Feasible Power Dispatch through Generalized Neural Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04838">http://arxiv.org/abs/2311.04838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meiyi Li, Javad Mohammadi<br>for: 这个论文的目的是提高大规模的电力系统优化过程中的决策效率，使用机器学习（ML）技术来改善优化过程。methods: 本文使用的方法是一种名为“学习来优化优化过程”的学习型方法，并且提出了一新的“通用措准图”方法来将不可行的解析转换为可行的解析。results: 本文的结果显示，使用LOOP-LC 2.0方法可以实现近乎最佳的解析结果，并且可以在硬件条件范围内确保解析的可行性。另外，与现有方法相比，LOOP-LC 2.0方法的训练速度、计算时间、优化性和可行性都有所提高。<details>
<summary>Abstract</summary>
The evolution towards a more distributed and interconnected grid necessitates large-scale decision-making within strict temporal constraints. Machine learning (ML) paradigms have demonstrated significant potential in improving the efficacy of optimization processes. However, the feasibility of solutions derived from ML models continues to pose challenges. It's imperative that ML models produce solutions that are attainable and realistic within the given system constraints of power systems. To address the feasibility issue and expedite the solution search process, we proposed LOOP-LC 2.0(Learning to Optimize the Optimization Process with Linear Constraints version 2.0) as a learning-based approach for solving the power dispatch problem. A notable advantage of the LOOP-LC 2.0 framework is its ability to ensure near-optimality and strict feasibility of solutions without depending on computationally intensive post-processing procedures, thus eliminating the need for iterative processes. At the heart of the LOOP-LC 2.0 model lies the newly proposed generalized gauge map method, capable of mapping any infeasible solution to a feasible point within the linearly-constrained domain. The proposed generalized gauge map method improves the traditional gauge map by exhibiting reduced sensitivity to input variances while increasing search speeds significantly. Utilizing the IEEE-200 test case as a benchmark, we demonstrate the effectiveness of the LOOP-LC 2.0 methodology, confirming its superior performance in terms of training speed, computational time, optimality, and solution feasibility compared to existing methodologies.
</details>
<details>
<summary>摘要</summary>
随着grid的分布化和连接性的演化，大规模决策在 строги时间限制下进行了大规模决策。机器学习（ML） paradigms 已经表现出了提高优化过程的潜在能力。然而，ML模型生成的解决方案的可行性仍然存在挑战。为了解决可行性问题并加速解决过程，我们提出了LOOP-LC 2.0（学习优化优化过程的学习方法版2.0）作为一种基于学习的电力调度问题的解决方案。LOOP-LC 2.0框架的一个重要优势是它可以保证解决方案的准确性和可行性，而不需要 computationally intensive post-processing procedures，因此可以消除迭代过程。LOOP-LC 2.0模型的核心 lies the newly proposed generalized gauge map method, capable of mapping any infeasible solution to a feasible point within the linearly-constrained domain.这种新的总体监测方法比传统的监测方法具有更低的输入方差敏感度，同时提高了搜索速度。使用IEEE-200测试集作为标准，我们证明了LOOP-LC 2.0方法的效iveness，其比现有方法ologies具有更高的训练速度、计算时间、优化性和可行性。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Recurrent-Reinforcement-Learning"><a href="#Real-Time-Recurrent-Reinforcement-Learning" class="headerlink" title="Real-Time Recurrent Reinforcement Learning"></a>Real-Time Recurrent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04830">http://arxiv.org/abs/2311.04830</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Julian Lemmel, Radu Grosu</li>
<li>for: 解决 partially-observable Markov decision processes (POMDPs) 中的奖励学习问题</li>
<li>methods: 使用 random feedback local online learning (RFLO) 和 temporaldifference reinforcement learning with eligibility traces (TD($\lambda$)) 组成一种生物学可能的，循环神经网络算法</li>
<li>results: RFLO 可以与 RTRL 相当，而且在复杂性方面超过 BPTT，并且可以解决离散和连续控制任务在 POMDPs 中Here is the same information in Simplified Chinese text:</li>
<li>for: 解决 partially-observable Markov decision processes (POMDPs) 中的奖励学习问题</li>
<li>methods: 使用 random feedback local online learning (RFLO) 和 temporaldifference reinforcement learning with eligibility traces (TD($\lambda$)) 组成一种生物学可能的，循环神经网络算法</li>
<li>results: RFLO 可以与 RTRL 相当，而且在复杂性方面超过 BPTT，并且可以解决离散和连续控制任务在 POMDPs 中<details>
<summary>Abstract</summary>
Recent advances in reinforcement learning, for partially-observable Markov decision processes (POMDPs), rely on the biologically implausible backpropagation through time algorithm (BPTT) to perform gradient-descent optimisation. In this paper we propose a novel reinforcement learning algorithm that makes use of random feedback local online learning (RFLO), a biologically plausible approximation of realtime recurrent learning (RTRL) to compute the gradients of the parameters of a recurrent neural network in an online manner. By combining it with TD($\lambda$), a variant of temporaldifference reinforcement learning with eligibility traces, we create a biologically plausible, recurrent actor-critic algorithm, capable of solving discrete and continuous control tasks in POMDPs. We compare BPTT, RTRL and RFLO as well as different network architectures, and find that RFLO can perform just as well as RTRL while exceeding even BPTT in terms of complexity. The proposed method, called real-time recurrent reinforcement learning (RTRRL), serves as a model of learning in biological neural networks mimicking reward pathways in the mammalian brain.
</details>
<details>
<summary>摘要</summary>
近期在 partially-observable Markov decision processes (POMDPs) 中的进步， rely on biologically implausible backpropagation through time algorithm (BPTT) 来进行 gradient-descent 优化。在这篇论文中，我们提出了一种新的 reinforcement learning 算法，使用 random feedback local online learning (RFLO)，一种 biologically plausible 的 realtime recurrent learning (RTRL) 来计算 recurrent neural network 的参数 Gradient。通过将其与 temporaldifference reinforcement learning with eligibility traces (TD($\lambda$)) 结合，我们创造了一种 biologically plausible， recurrent actor-critic 算法，可以解决 POMDPs 中的离散和连续控制任务。我们对 BPTT, RTRL 和 RFLO 进行比较，以及不同的网络架构，发现 RFLO 可以与 RTRL 相当，而且even exceed BPTT 的复杂性。我们提出的方法，called real-time recurrent reinforcement learning (RTRRL)，可以作为生物 neural networks 中学习的模型，模拟奖 PATHways 在哺乳动物大脑中的学习过程。
</details></li>
</ul>
<hr>
<h2 id="Functional-Bayesian-Tucker-Decomposition-for-Continuous-indexed-Tensor-Data"><a href="#Functional-Bayesian-Tucker-Decomposition-for-Continuous-indexed-Tensor-Data" class="headerlink" title="Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data"></a>Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04829">http://arxiv.org/abs/2311.04829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikai Fang, Xin Yu, Zheng Wang, Shibo Li, Mike Kirby, Shandian Zhe</li>
<li>for: 该论文旨在扩展tensor decomposition，以处理不符合维度的多方面数据。</li>
<li>methods: 该论文提出了Functional Bayesian Tucker Decomposition（FunBaT）方法，将连续索引的数据视为Tucker核和一组隐函数之间的互动。使用 Gaussian processes（GP）作为函数假设，并将GP转换为状态空间假设，以降低计算成本。</li>
<li>results: 论文通过使用高效的消息传递技术进行可扩展 posterior  aproximation，实现了可扩展的 posterior  aproximation。在 sintetic 数据和实际应用中，论文示出了其优势。<details>
<summary>Abstract</summary>
Tucker decomposition is a powerful tensor model to handle multi-aspect data. It demonstrates the low-rank property by decomposing the grid-structured data as interactions between a core tensor and a set of object representations (factors). A fundamental assumption of such decomposition is that there were finite objects in each aspect or mode, corresponding to discrete indexes of data entries. However, many real-world data are not naturally posed in the setting. For example, geographic data is represented as continuous indexes of latitude and longitude coordinates, and cannot fit tensor models directly. To generalize Tucker decomposition to such scenarios, we propose Functional Bayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as the interaction between the Tucker core and a group of latent functions. We use Gaussian processes (GP) as functional priors to model the latent functions, and then convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE) to reduce computational cost. An efficient inference algorithm is further developed for scalable posterior approximation based on advanced message-passing techniques. The advantage of our method is shown in both synthetic data and several real-world applications.
</details>
<details>
<summary>摘要</summary>
图克 decompositions 是一种强大的维度模型，用于处理多方面数据。它示出了低级别性质，通过将格子结构数据分解为核tensor和一组对象表示（因子）之间的交互。基本假设是，每个方面或模式中都有限多个对象，与数据项的独立标识符相对应。然而，许多实际世界数据并不适合直接适用tensor模型。例如，地理数据通常表示为纬度和经度坐标的连续标识符，无法直接适用tensor模型。为推广图克 decompositions 到这些场景，我们提出了函数 Bayesian Tucker decompositions（FunBaT）。我们将连续标识符数据视为核tensor和一组隐函数之间的交互。我们使用 Gaussian processes（GP）作为函数先验来模型隐函数，然后将GP转换为状态空间先验，通过构建相应的随机振荡方程（SDE）来减少计算成本。我们还开发了一种高效的 posterior 近似算法，以便扩展可扩展的 posterior 估计。我们的方法在 sintetic 数据和一些实际应用中的优点被证明。
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Architecture-for-Real-Time-Neuronal-Spike-Classification"><a href="#A-Lightweight-Architecture-for-Real-Time-Neuronal-Spike-Classification" class="headerlink" title="A Lightweight Architecture for Real-Time Neuronal-Spike Classification"></a>A Lightweight Architecture for Real-Time Neuronal-Spike Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04808">http://arxiv.org/abs/2311.04808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ali Siddiqi, David Vrijenhoek, Lennart P. L. Landsmeer, Job van der Kleij, Anteneh Gebregiorgis, Vincenzo Romano, Rajendra Bishnoi, Said Hamdioui, Christos Strydis</li>
<li>for: 这项研究旨在提高电physiological recording的灵活性和数据存储方式，以便更好地理解大脑功能。</li>
<li>methods: 该研究提出了一种轻量级的 neuronal-spike detection和分类架构，利用精雕细胞的特点来排除不必要的神经数据，并在实时进行数据压缩存储。</li>
<li>results: 该架构在实验中达到了&gt;95%的总分类精度，同时具有小型化设计和低功耗特性，使得头stage可以靠一个小电池运行达4天。<details>
<summary>Abstract</summary>
Electrophysiological recordings of neural activity in a mouse's brain are very popular among neuroscientists for understanding brain function. One particular area of interest is acquiring recordings from the Purkinje cells in the cerebellum in order to understand brain injuries and the loss of motor functions. However, current setups for such experiments do not allow the mouse to move freely and, thus, do not capture its natural behaviour since they have a wired connection between the animal's head stage and an acquisition device. In this work, we propose a lightweight neuronal-spike detection and classification architecture that leverages on the unique characteristics of the Purkinje cells to discard unneeded information from the sparse neural data in real time. This allows the (condensed) data to be easily stored on a removable storage device on the head stage, alleviating the need for wires. Our proposed implementation shows a >95% overall classification accuracy while still resulting in a small-form-factor design, which allows for the free movement of mice during experiments. Moreover, the power-efficient nature of the design and the usage of STT-RAM (Spin Transfer Torque Magnetic Random Access Memory) as the removable storage allows the head stage to easily operate on a tiny battery for up to approximately 4 days.
</details>
<details>
<summary>摘要</summary>
neuroscientists 非常感兴趣获取 Purkinje 细胞记录在脑室中以了解脑功能。一个具体的领域是获取 Purkinje 细胞记录，以了解脑 lesions 和失去运动功能。然而，现有的实验设置不允许鼠标自由移动，因此不能捕捉其自然行为，因为它们有一个从动物头阶段到获取设备的硬件连接。在这种工作中，我们提议一种轻量级神经元脉冲检测和分类架构，利用 Purkinje 细胞的特殊特征来抛弃不必要的神经数据。这使得（缩减）数据可以轻松地存储在动物头阶段的可 removable 存储设备上，解决了需要电缆的问题。我们的提议实现显示了 >95% 的总分类精度，同时仍保持了小型设计，允许鼠标在实验中自由移动。此外，设计的能效性和使用 STT-RAM（扭转磁铁随机存储）作为可 removable 存储，使得头阶段可以轻松地在 tiny 电池上运行，可以达到约 4 天的运行时间。
</details></li>
</ul>
<hr>
<h2 id="The-PetShop-Dataset-–-Finding-Causes-of-Performance-Issues-across-Microservices"><a href="#The-PetShop-Dataset-–-Finding-Causes-of-Performance-Issues-across-Microservices" class="headerlink" title="The PetShop Dataset – Finding Causes of Performance Issues across Microservices"></a>The PetShop Dataset – Finding Causes of Performance Issues across Microservices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04806">http://arxiv.org/abs/2311.04806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michaela Hardt, William Orchard, Patrick Blöbaum, Shiva Kasiviswanathan, Elke Kirschbaum</li>
<li>for: 本文旨在提供一个特有的分析根本原因的数据集，用于评估微服务应用中的 Root Cause Analysis（RCA）方法的准确性。</li>
<li>methods: 本文使用了一个分析Root Cause Analysis问题的多种方法，包括不同的 causal 和 non-causal 特征。</li>
<li>results: 本文通过使用这个新的数据集，证明了这些方法的准确性和可靠性。<details>
<summary>Abstract</summary>
Identifying root causes for unexpected or undesirable behavior in complex systems is a prevalent challenge. This issue becomes especially crucial in modern cloud applications that employ numerous microservices. Although the machine learning and systems research communities have proposed various techniques to tackle this problem, there is currently a lack of standardized datasets for quantitative benchmarking. Consequently, research groups are compelled to create their own datasets for experimentation. This paper introduces a dataset specifically designed for evaluating root cause analyses in microservice-based applications. The dataset encompasses latency, requests, and availability metrics emitted in 5-minute intervals from a distributed application. In addition to normal operation metrics, the dataset includes 68 injected performance issues, which increase latency and reduce availability throughout the system. We showcase how this dataset can be used to evaluate the accuracy of a variety of methods spanning different causal and non-causal characterisations of the root cause analysis problem. We hope the new dataset, available at https://github.com/amazon-science/petshop-root-cause-analysis/ enables further development of techniques in this important area.
</details>
<details>
<summary>摘要</summary>
“找到复杂系统中不望或不适的行为的根本原因是一个普遍的挑战。这个问题在现代云应用中使用多个微服务时变得更加重要。尽管机器学习和系统研究社区已经提出了多种技术来解决这个问题，但目前没有标准化的数据集用于量化比较。因此，研究组织被迫创建自己的数据集来进行实验。这篇论文介绍了一个专门为评估微服务基建应用中的根本原因分析问题而设计的数据集。该数据集包括5分钟间隔发生的延迟、请求和可用性指标，以及68个注入性性能问题，这些问题会在系统中增加延迟和降低可用性。我们示出了如何使用这个数据集来评估多种不同的 causa和非 causa 的根本原因分析问题的准确性。我们希望这个新的数据集，可以在 https://github.com/amazon-science/petshop-root-cause-analysis/ 上下载，能够促进这个重要领域的技术发展。”Note: "causa" and "非 causa" are Chinese terms that roughly translate to "causal" and "non-causal" respectively.
</details></li>
</ul>
<hr>
<h2 id="Why-Do-Clinical-Probabilistic-Models-Fail-To-Transport-Between-Sites"><a href="#Why-Do-Clinical-Probabilistic-Models-Fail-To-Transport-Between-Sites" class="headerlink" title="Why Do Clinical Probabilistic Models Fail To Transport Between Sites?"></a>Why Do Clinical Probabilistic Models Fail To Transport Between Sites?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04787">http://arxiv.org/abs/2311.04787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas A. Lasko, Eric V. Strobl, William W. Stead</li>
<li>for: 这篇论文目的是解释医疗人工智能的应用中出现的问题，即模型在训练站上达到超人类性能后，在新的站点上表现差强。</li>
<li>methods: 本文使用了实验控制和资料生成过程中的因素来分析这些问题，并提出了一个解决方案，即隔离训练站上的临床实践对数据的影响。</li>
<li>results: 本文预测了这种问题的原因，并提出了一个解决方案，可以将训练站上的临床实践对数据的影响隔离开来。<details>
<summary>Abstract</summary>
The rising popularity of artificial intelligence in healthcare is highlighting the problem that a computational model achieving super-human clinical performance at its training sites may perform substantially worse at new sites. In this perspective, we present common sources for this failure to transport, which we divide into sources under the control of the experimenter and sources inherent to the clinical data-generating process. Of the inherent sources we look a little deeper into site-specific clinical practices that can affect the data distribution, and propose a potential solution intended to isolate the imprint of those practices on the data from the patterns of disease cause and effect that are the usual target of clinical models.
</details>
<details>
<summary>摘要</summary>
人工智能在医疗领域的普及化正在吸引着关注，但同时也暴露了一个问题：一个计算模型在训练站上达到超人至尊的临床性能后，在新的站点上可能表现出很差的性能。在这个视角下，我们描述了不能传输的常见原因，分为实验者可控的源和临床数据生成过程中的内在源。其中内在源中，我们做了一些深入的分析，包括站点特有的临床实践，这些实践可能会影响数据分布。我们还提出了一种解决方案，用于孤立临床实践对数据的影响，从而更好地隔离疾病原因和疾病效应的模式。
</details></li>
</ul>
<hr>
<h2 id="FetMRQC-an-open-source-machine-learning-framework-for-multi-centric-fetal-brain-MRI-quality-control"><a href="#FetMRQC-an-open-source-machine-learning-framework-for-multi-centric-fetal-brain-MRI-quality-control" class="headerlink" title="FetMRQC: an open-source machine learning framework for multi-centric fetal brain MRI quality control"></a>FetMRQC: an open-source machine learning framework for multi-centric fetal brain MRI quality control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04780">http://arxiv.org/abs/2311.04780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas Sanchez, Oscar Esteban, Yvan Gomez, Alexandre Pron, Mériam Koob, Vincent Dunet, Nadine Girard, Andras Jakab, Elisenda Eixarch, Guillaume Auzias, Meritxell Bach Cuadra</li>
<li>for: 这个研究旨在提供一个开源的机器学习框架，用于自动评估和控制胎儿脑部MRI的影像质量，以扩大胎儿脑部发展研究的可能性。</li>
<li>methods: 这个研究使用了一个开源的机器学习框架（FetMRQC），它可以自动提取胎儿脑部MRI影像中的质量指标，并结合这些指标使用随机树来预测专家的评分。</li>
<li>results: 这个研究发现，FetMRQC的预测结果能够在不同的胎儿脑部MRI影像数据中稳定地表现出来，并且可以对未见过的数据进行预测，同时保持可解释性。<details>
<summary>Abstract</summary>
Fetal brain MRI is becoming an increasingly relevant complement to neurosonography for perinatal diagnosis, allowing fundamental insights into fetal brain development throughout gestation. However, uncontrolled fetal motion and heterogeneity in acquisition protocols lead to data of variable quality, potentially biasing the outcome of subsequent studies. We present FetMRQC, an open-source machine-learning framework for automated image quality assessment and quality control that is robust to domain shifts induced by the heterogeneity of clinical data. FetMRQC extracts an ensemble of quality metrics from unprocessed anatomical MRI and combines them to predict experts' ratings using random forests. We validate our framework on a pioneeringly large and diverse dataset of more than 1600 manually rated fetal brain T2-weighted images from four clinical centers and 13 different scanners. Our study shows that FetMRQC's predictions generalize well to unseen data while being interpretable. FetMRQC is a step towards more robust fetal brain neuroimaging, which has the potential to shed new insights on the developing human brain.
</details>
<details>
<summary>摘要</summary>
《胎儿脑MRI在产前诊断中日益重要，允许深入了解胎儿脑发育过程。但是，不受控制的胎儿运动和数据采集协议的多样性导致数据质量变化，可能影响后续研究的结果。我们介绍FetMRQC，一个开源的机器学习框架，用于自动评估和控制图像质量，对域Shift具有抗针对性。FetMRQC从未处理的 анатомичеMRI中提取了一个ensemble的质量指标，并使用Random Forest组合以预测专家评分。我们验证了我们的框架，使用了1600多个手动评分的胎儿脑T2强化MRI图像，来自四个临床中心和13个不同的扫描仪。我们的研究表明，FetMRQC的预测能够在未看到数据上进行良好的泛化，同时具有可解释性。FetMRQC是更加Robust的胎儿脑神经成像的一步，它有可能为人类脑发育带来新的发现。》
</details></li>
</ul>
<hr>
<h2 id="Optimal-Deep-Neural-Network-Approximation-for-Korobov-Functions-with-respect-to-Sobolev-Norms"><a href="#Optimal-Deep-Neural-Network-Approximation-for-Korobov-Functions-with-respect-to-Sobolev-Norms" class="headerlink" title="Optimal Deep Neural Network Approximation for Korobov Functions with respect to Sobolev Norms"></a>Optimal Deep Neural Network Approximation for Korobov Functions with respect to Sobolev Norms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04779">http://arxiv.org/abs/2311.04779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yahong Yang, Yulong Lu</li>
<li>for: 这个论文设计了深度神经网络（DNN）在科罗波夫函数上的近似率，有效战胜了维度的咒语。</li>
<li>methods: 这个论文使用了深度神经网络对科罗波夫函数进行近似，并使用了$L_p$ norm和$H^1$ norm来测量近似结果。</li>
<li>results: 这个论文的结果表明，深度神经网络可以在科罗波夫函数上实现非常高的近似率，超过传统方法和任何连续函数近似器。这些结果是非阿塞拜 ME 的，即不含任何假设或偏好。<details>
<summary>Abstract</summary>
This paper establishes the nearly optimal rate of approximation for deep neural networks (DNNs) when applied to Korobov functions, effectively overcoming the curse of dimensionality. The approximation results presented in this paper are measured with respect to $L_p$ norms and $H^1$ norms. Our achieved approximation rate demonstrates a remarkable "super-convergence" rate, outperforming traditional methods and any continuous function approximator. These results are non-asymptotic, providing error bounds that consider both the width and depth of the networks simultaneously.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这篇论文确立了深度神经网络（DNNs）应用于科罗波夫函数的近似率，有效地绕过维度的咒语。我们的近似结果使用 $L_p$ 范数和 $H^1$ 范数来度量，并demonstrates一个非常出众的"超 converges" 率，超过传统方法和任何连续函数近似器。这些结果是非 asymptotic，同时考虑了网络的宽度和深度。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Unified-Framework-of-Contrastive-Learning-for-Disentangled-Representations"><a href="#Towards-a-Unified-Framework-of-Contrastive-Learning-for-Disentangled-Representations" class="headerlink" title="Towards a Unified Framework of Contrastive Learning for Disentangled Representations"></a>Towards a Unified Framework of Contrastive Learning for Disentangled Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04774">http://arxiv.org/abs/2311.04774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Matthes, Zhiwei Han, Hao Shen</li>
<li>for: 本研究探讨了对数据表示学习的抽象方法，即对数据分解和分离的因素。</li>
<li>methods: 本研究使用了一种更加广泛的对照方法家族，而不是单独关注噪音对照估计（NCE）和InfoNCE。</li>
<li>results: 研究证明了这些对照方法可以很好地分解和分离数据中的因素，而不需要假设特定的数据分布。<details>
<summary>Abstract</summary>
Contrastive learning has recently emerged as a promising approach for learning data representations that discover and disentangle the explanatory factors of the data. Previous analyses of such approaches have largely focused on individual contrastive losses, such as noise-contrastive estimation (NCE) and InfoNCE, and rely on specific assumptions about the data generating process. This paper extends the theoretical guarantees for disentanglement to a broader family of contrastive methods, while also relaxing the assumptions about the data distribution. Specifically, we prove identifiability of the true latents for four contrastive losses studied in this paper, without imposing common independence assumptions. The theoretical findings are validated on several benchmark datasets. Finally, practical limitations of these methods are also investigated.
</details>
<details>
<summary>摘要</summary>
“对比学习” recent  emerge  as  a  promising  approach  for  learning  data  representations  that  discover  and  disentangle  the  explanatory  factors  of  the  data. Previous  analyses  of  such  approaches  have  largely  focused  on  individual  contrastive  losses,  such  as  noise-contrastive  estimation  (NCE)  and  InfoNCE,  and  rely  on  specific  assumptions  about  the  data  generating  process. This  paper  extends  the  theoretical  guarantees  for  disentanglement  to  a  broader  family  of  contrastive  methods,  while  also  relaxing  the  assumptions  about  the  data  distribution. Specifically, we prove identifiability  of  the  true  latents  for  four  contrastive  losses  studied  in  this  paper,  without  imposing  common  independence  assumptions. The  theoretical  findings  are  validated  on  several  benchmark  datasets. Finally, practical  limitations  of  these  methods  are  also  investigated.
</details></li>
</ul>
<hr>
<h2 id="Towards-Open-world-Cross-Domain-Sequential-Recommendation-A-Model-Agnostic-Contrastive-Denoising-Approach"><a href="#Towards-Open-world-Cross-Domain-Sequential-Recommendation-A-Model-Agnostic-Contrastive-Denoising-Approach" class="headerlink" title="Towards Open-world Cross-Domain Sequential Recommendation: A Model-Agnostic Contrastive Denoising Approach"></a>Towards Open-world Cross-Domain Sequential Recommendation: A Model-Agnostic Contrastive Denoising Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04760">http://arxiv.org/abs/2311.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wujiang Xu, Xuying Ning, Wenfang Lin, Mingming Ha, Qiongxu Ma, Linxun Chen, Bing Han, Minnan Luo</li>
<li>for: 本研究旨在 addresses the data sparsity problem in traditional sequential recommendation (SR) systems, particularly in open-world cross-domain scenarios where most users have sparse behaviors and cold-start users only exist in one domain.</li>
<li>methods: 现有的 CDSR 方法强调设计特定的 cross-domain unit，以传递和协调多个领域中的用户行为信息。然而，在实际业务平台上， CDSR 场景通常存在大量的长尾用户和缺乏行为的情况，这导致了现有 CDSR 方法在实际场景中的性能下降。因此，构建高效的 CDSR 模型在开放世界 CDSR 场景中是非常重要的 (\textit{1st} CH).</li>
<li>results: 总之，这些 SR 方法无法在 CDSR 场景中提供出色的表现，因为它们忽视了目标行为和辅助行为之间的semantic gap，以及用户兴趣的偏移 across domains (\textit{2nd} CH).<details>
<summary>Abstract</summary>
Cross-domain sequential recommendation (CDSR) aims to address the data sparsity problems that exist in traditional sequential recommendation (SR) systems.   The existing approaches aim to design a specific cross-domain unit that can transfer and propagate information across multiple domains by relying on overlapping users with abundant behaviors. However, in real-world recommender systems, CDSR scenarios usually consist of a majority of long-tailed users with sparse behaviors and cold-start users who only exist in one domain. This leads to a drop in the performance of existing CDSR methods in the real-world industry platform. Therefore, improving the consistency and effectiveness of models in open-world CDSR scenarios is crucial for constructing CDSR models (\textit{1st} CH). Recently, some SR approaches have utilized auxiliary behaviors to complement the information for long-tailed users. However, these multi-behavior SR methods cannot deliver promising performance in CDSR, as they overlook the semantic gap between target and auxiliary behaviors, as well as user interest deviation across domains (\textit{2nd} CH).
</details>
<details>
<summary>摘要</summary>
Recently, some SR approaches have utilized auxiliary behaviors to complement the information for long-tailed users. However, these multi-behavior SR methods cannot deliver promising performance in CDSR, as they overlook the semantic gap between target and auxiliary behaviors, as well as user interest deviation across domains.In Chinese:跨DomainSequential recommendation (CDSR) 目标是解决传统Sequential recommendation (SR) 系统中的数据稀缺问题。现有的方法是通过跨多个Domain的用户 overlap来设计特定的跨Domain单元，以传递和宣传信息。然而，在实际的 recommender 系统中， CDSR 场景通常由大量的长尾用户和缺乏行为组成，以及唯一存在于一个Domain的冷启用户。这导致了现有CDSR方法在实际行业平台上的性能下降。因此，在开放世界CDSR场景中提高模型的一致性和效果是构建CDSR模型的关键。当前，一些SR方法已经利用 auxillary 行为来补充长尾用户的信息。然而，这些多行为SR方法在 CDSR 中无法达到可靠的性能，因为它们忽视了目标行为和 auxillary 行为之间的semantic gap，以及用户兴趣在不同Domain中的偏移。
</details></li>
</ul>
<hr>
<h2 id="Natural-Bayesian-Cramer-Rao-Bound-with-an-Application-to-Covariance-Estimation"><a href="#Natural-Bayesian-Cramer-Rao-Bound-with-an-Application-to-Covariance-Estimation" class="headerlink" title="Natural Bayesian Cramér-Rao Bound with an Application to Covariance Estimation"></a>Natural Bayesian Cramér-Rao Bound with an Application to Covariance Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04748">http://arxiv.org/abs/2311.04748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florent Bouchard, Alexandre Renaux, Guillaume Ginolhac, Arnaud Breloy</li>
<li>for: 这个论文是为了开发一种新的克拉默-拉托 bound（CRB），当参数需要估计的拓扑在拓扑上并且遵循一个先验分布时。</li>
<li>methods: 这个论文使用的方法包括 derive a new Cramér-Rao bound (CRB) based on the manifold of the parameter and the prior distribution.</li>
<li>results: 该论文的主要贡献是通过一种自然的不等式关系 между一个Error criteria和该新的 bound，并且通过numerical simulation表明了该新的 CRB 可以展示一些MAP estimator的有趣性质，这些质量不存在于经典的极大似然估计 bound 中。<details>
<summary>Abstract</summary>
In this paper, we propose to develop a new Cram\'er-Rao Bound (CRB) when the parameter to estimate lies in a manifold and follows a prior distribution. This derivation leads to a natural inequality between an error criteria based on geometrical properties and this new bound. This main contribution is illustrated in the problem of covariance estimation when the data follow a Gaussian distribution and the prior distribution is an inverse Wishart. Numerical simulation shows new results where the proposed CRB allows to exhibit interesting properties of the MAP estimator which are not observed with the classical Bayesian CRB.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的卡尔-拉奥 bound (CRB)，当参数估计的拟合体系是一个拟合 manifold 并且遵循一个先验分布时。这种 derivation 导致了一种自然的不等式 между一个基于 геометрические属性的误差标准和这个新的 bound。我们的主要贡献在covariance估计问题中，数据遵循 Gaussian 分布，先验分布是 inverse Wishart。数值仪表示我们的提案CRB具有不同于传统极大似然估计CRB的有趣性质。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Multi-Agent-Coordination-through-Common-Operating-Picture-Integration"><a href="#Enhancing-Multi-Agent-Coordination-through-Common-Operating-Picture-Integration" class="headerlink" title="Enhancing Multi-Agent Coordination through Common Operating Picture Integration"></a>Enhancing Multi-Agent Coordination through Common Operating Picture Integration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04740">http://arxiv.org/abs/2311.04740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peihong Yu, Bhoram Lee, Aswin Raghavan, Supun Samarasekara, Pratap Tokekar, James Zachary Hare</li>
<li>for: 这 paper 是为了提高多智能体系统中代理的协调性和鲁棒性，具体来说是通过融合代理的历史观察、行动和消息来构建共同运作图像（COP），并在这个过程中考虑环境的动态性和共同任务。</li>
<li>methods: 该 paper 使用了多智能体强化学习（MARL）方法，并在这些方法中引入了共同运作图像（COP）的概念。</li>
<li>results: 实验结果表明，使用 COP 融合学习方法可以提高代理的协调性和鲁棒性，并在 faced with out-of-distribution 初始状态时表现更加稳定和有效。<details>
<summary>Abstract</summary>
In multi-agent systems, agents possess only local observations of the environment. Communication between teammates becomes crucial for enhancing coordination. Past research has primarily focused on encoding local information into embedding messages which are unintelligible to humans. We find that using these messages in agent's policy learning leads to brittle policies when tested on out-of-distribution initial states. We present an approach to multi-agent coordination, where each agent is equipped with the capability to integrate its (history of) observations, actions and messages received into a Common Operating Picture (COP) and disseminate the COP. This process takes into account the dynamic nature of the environment and the shared mission. We conducted experiments in the StarCraft2 environment to validate our approach. Our results demonstrate the efficacy of COP integration, and show that COP-based training leads to robust policies compared to state-of-the-art Multi-Agent Reinforcement Learning (MARL) methods when faced with out-of-distribution initial states.
</details>
<details>
<summary>摘要</summary>
在多代理系统中，代理具有只有本地环境观察的能力。代理之间的交流成为协调的关键。过去的研究主要集中在编码本地信息到嵌入消息中，这些消息不可读人类。我们发现，使用这些消息在代理的政策学习中导致粗糙的策略，对于非标准初始状态测试时表现不稳定。我们提出了一种多代理协调方法，其中每个代理具有积极融合其观察历史、行动和接收的消息的能力，并将这些信息整合成共同运行图像（COP）。这个过程考虑了环境的动态性和共同任务。我们在StarCraft2环境中进行了实验，以验证我们的方法。我们的结果表明COP融合的有效性，并示出COP基于培训在面对非标准初始状态时比state-of-the-art多代理学习方法（MARL）更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Robust-Best-arm-Identification-in-Linear-Bandits"><a href="#Robust-Best-arm-Identification-in-Linear-Bandits" class="headerlink" title="Robust Best-arm Identification in Linear Bandits"></a>Robust Best-arm Identification in Linear Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04731">http://arxiv.org/abs/2311.04731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Wang, Sattar Vakili, Ilija Bogunovic</li>
<li>for: 本研究旨在解决线性奖励情况下的Robust Best-Arm Identification问题（RBAI）。</li>
<li>methods: 我们提出了一种实例dependent的下界，以及静态和适应式bandit算法，以实现与下界相同的样本复杂度。</li>
<li>results: 在synthetic实验中，我们的算法能够有效地标识最佳 robust arm，并与oracle策略相似。在应用中，我们研究了使用这些算法来学习不准确标准计算器的药物剂量建议，并证明了这些算法在不同年龄段患者中实现了有效的剂量值标识。<details>
<summary>Abstract</summary>
We study the robust best-arm identification problem (RBAI) in the case of linear rewards. The primary objective is to identify a near-optimal robust arm, which involves selecting arms at every round and assessing their robustness by exploring potential adversarial actions. This approach is particularly relevant when utilizing a simulator and seeking to identify a robust solution for real-world transfer. To this end, we present an instance-dependent lower bound for the robust best-arm identification problem with linear rewards. Furthermore, we propose both static and adaptive bandit algorithms that achieve sample complexity that matches the lower bound. In synthetic experiments, our algorithms effectively identify the best robust arm and perform similarly to the oracle strategy. As an application, we examine diabetes care and the process of learning insulin dose recommendations that are robust with respect to inaccuracies in standard calculators. Our algorithms prove to be effective in identifying robust dosage values across various age ranges of patients.
</details>
<details>
<summary>摘要</summary>
我们研究了线性奖励情况下的强 robust arm 标识问题（RBAI）。我们的主要目标是找到一个近似优化的强 robust arm，这里是在每个轮次选择 arms 并评估其强健性，包括探索敌对行为。这种方法特别 relevante 当使用模拟器并寻求实际世界中的强解。为此，我们提出了一个实例 dependent 下界 для强 robust arm 标识问题。此外，我们还提出了静态和适应bandit算法，它们的样本复杂度与下界相同。在synthetic实验中，我们的算法能够有效地确定最佳强 robust arm，并与oracle策略相似。在应用中，我们研究了 диабеtes 护理，即通过学习不准确的标准计算机确定具有robustness的药物剂量。我们的算法在不同年龄层的患者中显示出效果。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Properties-of-Nodes-via-Community-Aware-Features"><a href="#Predicting-Properties-of-Nodes-via-Community-Aware-Features" class="headerlink" title="Predicting Properties of Nodes via Community-Aware Features"></a>Predicting Properties of Nodes via Community-Aware Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04730">http://arxiv.org/abs/2311.04730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bogumił Kamiński, Paweł Prałat, François Théberge, Sebastian Zając</li>
<li>for: 这 paper 的目的是提出一家族community-aware node features，并研究其性质。</li>
<li>methods: 该 paper 使用了 classical node features 和 node embeddings（包括类传统的 node embeddings 和 structural node embeddings）来描述节点的特征，并提出了一种新的community-aware node features 家族。</li>
<li>results: 研究发现，这种新的community-aware node features 具有高的预测力，可以用于分类任务。此外，它们还包含了不可recover的信息，与传统的节点特征和节点嵌入不同。<details>
<summary>Abstract</summary>
A community structure that is often present in complex networks plays an important role not only in their formation but also shapes dynamics of these networks, affecting properties of their nodes. In this paper, we propose a family of community-aware node features and then investigate their properties. We show that they have high predictive power for classification tasks. We also verify that they contain information that cannot be recovered neither by classical node features nor by node embeddings (both classical as well as structural).
</details>
<details>
<summary>摘要</summary>
Complex networks often exhibit a community structure, which not only affects their formation but also shapes their dynamics, influencing the properties of their nodes. In this paper, we propose a family of community-aware node features and investigate their properties. We show that they have high predictive power for classification tasks. We also verify that they contain information that cannot be recovered by classical node features or node embeddings (both classical and structural).Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan, Hong Kong, and other countries.
</details></li>
</ul>
<hr>
<h2 id="Robust-and-Communication-Efficient-Federated-Domain-Adaptation-via-Random-Features"><a href="#Robust-and-Communication-Efficient-Federated-Domain-Adaptation-via-Random-Features" class="headerlink" title="Robust and Communication-Efficient Federated Domain Adaptation via Random Features"></a>Robust and Communication-Efficient Federated Domain Adaptation via Random Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04686">http://arxiv.org/abs/2311.04686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadangelf/fedrf-tca">https://github.com/sadangelf/fedrf-tca</a></li>
<li>paper_authors: Zhanbo Feng, Yuanjie Wang, Jie Li, Fan Yang, Jiong Lou, Tiebin Mi, Robert. C. Qiu, Zhenyu Liao</li>
<li>for: 这个论文的目的是提出一种基于聚合学习的分布式适应预测方法，以适应域shift问题。</li>
<li>methods: 该方法基于传输组件分析（TCA），通过减少数据的通信复杂度来加速计算。</li>
<li>results: 试验结果表明，提出的 FedRF-TCA 协议在不同的网络条件下具有稳定高性能，并且与现有的 FDA 方法相比，具有独立于样本大小的通信复杂度。<details>
<summary>Abstract</summary>
Modern machine learning (ML) models have grown to a scale where training them on a single machine becomes impractical. As a result, there is a growing trend to leverage federated learning (FL) techniques to train large ML models in a distributed and collaborative manner. These models, however, when deployed on new devices, might struggle to generalize well due to domain shifts. In this context, federated domain adaptation (FDA) emerges as a powerful approach to address this challenge.   Most existing FDA approaches typically focus on aligning the distributions between source and target domains by minimizing their (e.g., MMD) distance. Such strategies, however, inevitably introduce high communication overheads and can be highly sensitive to network reliability.   In this paper, we introduce RF-TCA, an enhancement to the standard Transfer Component Analysis approach that significantly accelerates computation without compromising theoretical and empirical performance. Leveraging the computational advantage of RF-TCA, we further extend it to FDA setting with FedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that is \emph{independent} of the sample size, while maintaining performance that is either comparable to or even surpasses state-of-the-art FDA methods. We present extensive experiments to showcase the superior performance and robustness (to network condition) of FedRF-TCA.
</details>
<details>
<summary>摘要</summary>
现代机器学习（ML）模型已经增长到了一个Scale，训练它们在单个机器上已经成为不切实际的。因此，有一个增长的趋势是使用联合学习（FL）技术来训练大型ML模型在分布式和合作的方式下。这些模型在新设备上部署时可能会遇到领域变化，因此联合领域适应（FDA）作为一种强大的方法来解决这个挑战。现有的FDA方法通常是通过最小化源和目标领域之间的分布差（如MMD）来对align distribution。这些策略会导致高度的通信开销和网络可靠性的敏感性。在这篇论文中，我们介绍了RF-TCA，一种改进了标准传输组件分析（Transfer Component Analysis，TCA）的方法，可以快速计算而不会损失理论和实验性能。我们还将RF-TCA扩展到FDA设置，得到了 FedRF-TCA协议。FedRF-TCA协议的通信复杂度是独立于样本大小的，同时保持与状态 искусственный智能（AI）方法相当或者超越的性能。我们进行了广泛的实验，以示出FedRF-TCA的superior性能和网络condition的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Compressive-Recovery-of-Sparse-Precision-Matrices"><a href="#Compressive-Recovery-of-Sparse-Precision-Matrices" class="headerlink" title="Compressive Recovery of Sparse Precision Matrices"></a>Compressive Recovery of Sparse Precision Matrices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04673">http://arxiv.org/abs/2311.04673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Titouan Vayer, Etienne Lasalle, Rémi Gribonval, Paulo Gonçalves</li>
<li>for: 本研究的目的是提出一种高维数据图模型学习方法，以优化数据的统计关系。</li>
<li>methods: 该方法采用了压缩视角，通过非线性随机特征来采样数据，从而降低存储负担。</li>
<li>results: 研究表明，可以通过采样大小$m &#x3D; O((d+2k)\log(d))$来估算稀疏图模型。这些信息理论保证基于压缩感知论和特定的幂等均值抑制器。<details>
<summary>Abstract</summary>
We consider the problem of learning a graph modeling the statistical relations of the $d$ variables of a dataset with $n$ samples $X \in \mathbb{R}^{n \times d}$. Standard approaches amount to searching for a precision matrix $\Theta$ representative of a Gaussian graphical model that adequately explains the data. However, most maximum likelihood-based estimators usually require storing the $d^{2}$ values of the empirical covariance matrix, which can become prohibitive in a high-dimensional setting. In this work, we adopt a compressive viewpoint and aim to estimate a sparse $\Theta$ from a sketch of the data, i.e. a low-dimensional vector of size $m \ll d^{2}$ carefully designed from $X$ using nonlinear random features. Under certain assumptions on the spectrum of $\Theta$ (or its condition number), we show that it is possible to estimate it from a sketch of size $m=\Omega((d+2k)\log(d))$ where $k$ is the maximal number of edges of the underlying graph. These information-theoretic guarantees are inspired by compressed sensing theory and involve restricted isometry properties and instance optimal decoders. We investigate the possibility of achieving practical recovery with an iterative algorithm based on the graphical lasso, viewed as a specific denoiser. We compare our approach and graphical lasso on synthetic datasets, demonstrating its favorable performance even when the dataset is compressed.
</details>
<details>
<summary>摘要</summary>
我们考虑了一个图模型，用于描述一个 dataset 中变量的统计关系。标准方法通常是寻找一个精度矩阵 $\Theta$，用于描述一个 Gaussian 图模型，并且能够准确地描述数据。然而，大多数最大可能似然值基于的估计器通常需要存储 $d^2$ 个实际协方差矩阵的值，这在高维度设置中可能变得离谱。在这个工作中，我们采用了压缩视角，并且尝试从数据的快照中估计一个稀疏 $\Theta$。我们在 certain 假设下（或其condition number），证明可以从数据的快照中估计 $\Theta$，并且这个快照的大小可以是 $m = \Omega((d+2k)\log(d))$，where $k$ 是图中的最大边数。这些信息理论保证是基于压缩感知理论和有限幂均值属性，以及实例最优解码器。我们 investigate 一种实际恢复的可能性，使用图ical lasso 作为特定的排除器。我们在 synthetic 数据上对我们的方法和图ical lasso 进行比较，并证明它在压缩数据时仍然有优势。
</details></li>
</ul>
<hr>
<h2 id="Learning-Linear-Gaussian-Polytree-Models-with-Interventions"><a href="#Learning-Linear-Gaussian-Polytree-Models-with-Interventions" class="headerlink" title="Learning Linear Gaussian Polytree Models with Interventions"></a>Learning Linear Gaussian Polytree Models with Interventions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04636">http://arxiv.org/abs/2311.04636</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/emduart2/polytrees">https://github.com/emduart2/polytrees</a></li>
<li>paper_authors: D. Tramontano, L. Waldmann, M. Drton, E. Duarte</li>
<li>For: 学习线性 Gaussian 树的 causal 结构，使用来自干预实验的数据，known intervention targets。* Methods: 首先学习树的桠架，然后对其边 Orient。输出是一个 CPDAG，表示真实的下面分布的 intervenational 等价类。* Results: 在不同场景下进行了synthetic数据集的测试，并在一个基因表达干预数据集中应用了算法，实现了高速、高精度的结构哈姆钦距离。<details>
<summary>Abstract</summary>
We present a consistent and highly scalable local approach to learn the causal structure of a linear Gaussian polytree using data from interventional experiments with known intervention targets. Our methods first learn the skeleton of the polytree and then orient its edges. The output is a CPDAG representing the interventional equivalence class of the polytree of the true underlying distribution. The skeleton and orientation recovery procedures we use rely on second order statistics and low-dimensional marginal distributions. We assess the performance of our methods under different scenarios in synthetic data sets and apply our algorithm to learn a polytree in a gene expression interventional data set. Our simulation studies demonstrate that our approach is fast, has good accuracy in terms of structural Hamming distance, and handles problems with thousands of nodes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种一致性和可扩展性很强的本地方法，用于学习一个线性 Gaussian 树的 causal 结构，使用来自干预实验的数据，其中干预目标已知。我们的方法首先学习树的架构，然后将其边orientation。输出是一个 CPDAG，表示实验性Equivalence class of the true underlying distribution的树。我们使用第二阶 statistics和低维度分布来进行架构和边orientation的回归。我们在不同情况下进行了 simulate 研究，并将方法应用于一个基因表达干预数据集中。我们的 simulate 研究表明，我们的方法快速、精度高，能够处理 thousands of nodes 的问题。
</details></li>
</ul>
<hr>
<h2 id="Byzantine-Tolerant-Methods-for-Distributed-Variational-Inequalities"><a href="#Byzantine-Tolerant-Methods-for-Distributed-Variational-Inequalities" class="headerlink" title="Byzantine-Tolerant Methods for Distributed Variational Inequalities"></a>Byzantine-Tolerant Methods for Distributed Variational Inequalities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04611">http://arxiv.org/abs/2311.04611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nazya/sgda-ra">https://github.com/nazya/sgda-ra</a></li>
<li>paper_authors: Nazarii Tupitsa, Abdulla Jasem Almansoori, Yanlin Wu, Martin Takáč, Karthik Nandakumar, Samuel Horváth, Eduard Gorbunov</li>
<li>for: 提高分布式学习中的Byzantine攻击Robustness，特别是在解决variational inequality问题时。</li>
<li>methods: 提供了多种(可证明)ByzantineRobust的方法，并进行了全面的理论分析和数值比较，以支持理论发现。</li>
<li>results: 研究结果表明，提出的方法能够有效地提高分布式学习中的Byzantine攻击Robustness，并且超过了之前的研究所具有的限制。<details>
<summary>Abstract</summary>
Robustness to Byzantine attacks is a necessity for various distributed training scenarios. When the training reduces to the process of solving a minimization problem, Byzantine robustness is relatively well-understood. However, other problem formulations, such as min-max problems or, more generally, variational inequalities, arise in many modern machine learning and, in particular, distributed learning tasks. These problems significantly differ from the standard minimization ones and, therefore, require separate consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this important question in the context of Byzantine robustness. Our work makes a further step in this direction by providing several (provably) Byzantine-robust methods for distributed variational inequality, thoroughly studying their theoretical convergence, removing the limitations of the previous work, and providing numerical comparisons supporting the theoretical findings.
</details>
<details>
<summary>摘要</summary>
Robustness to Byzantine attacks is a necessity for various distributed training scenarios. When the training reduces to the process of solving a minimization problem, Byzantine robustness is relatively well-understood. However, other problem formulations, such as min-max problems or, more generally, variational inequalities, arise in many modern machine learning and, in particular, distributed learning tasks. These problems significantly differ from the standard minimization ones and, therefore, require separate consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this important question in the context of Byzantine robustness. Our work makes a further step in this direction by providing several (provably) Byzantine-robust methods for distributed variational inequality, thoroughly studying their theoretical convergence, removing the limitations of the previous work, and providing numerical comparisons supporting the theoretical findings.Here's the translation in Traditional Chinese:Robustness to Byzantine attacks is a necessity for various distributed training scenarios. When the training reduces to the process of solving a minimization problem, Byzantine robustness is relatively well-understood. However, other problem formulations, such as min-max problems or, more generally, variational inequalities, arise in many modern machine learning and, in particular, distributed learning tasks. These problems significantly differ from the standard minimization ones and, therefore, require separate consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this important question in the context of Byzantine robustness. Our work makes a further step in this direction by providing several (provably) Byzantine-robust methods for distributed variational inequality, thoroughly studying their theoretical convergence, removing the limitations of the previous work, and providing numerical comparisons supporting the theoretical findings.
</details></li>
</ul>
<hr>
<h2 id="Accurate-Autism-Spectrum-Disorder-prediction-using-Support-Vector-Classifier-based-on-Federated-Learning-SVCFL"><a href="#Accurate-Autism-Spectrum-Disorder-prediction-using-Support-Vector-Classifier-based-on-Federated-Learning-SVCFL" class="headerlink" title="Accurate Autism Spectrum Disorder prediction using Support Vector Classifier based on Federated Learning (SVCFL)"></a>Accurate Autism Spectrum Disorder prediction using Support Vector Classifier based on Federated Learning (SVCFL)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04606">http://arxiv.org/abs/2311.04606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Mohammadifar, Hasan Samadbin, Arman Daliri</li>
<li>for: 早期诊断autism spectrum disorder (ASD)的方法</li>
<li>methods: 使用 federated learning 方法和支持向量分类器方法对数据进行识别</li>
<li>results: 实现了 99% 的准确率和 13% 的提升Here’s a breakdown of each point:1. for: The paper is written for the purpose of exploring the use of artificial intelligence (AI) for early diagnosis of autism spectrum disorder (ASD).2. methods: The paper uses four datasets and combines them using federated learning, a machine learning method that allows multiple devices or datasets to work together without sharing their data. The paper also uses a support vector classifier method to diagnose the data.3. results: The paper achieves 99% accuracy in predicting ASD and a 13% improvement in results using this method.<details>
<summary>Abstract</summary>
The path to an autism diagnosis can be long and difficult, and delays can have serious consequences. Artificial intelligence can completely change the way autism is diagnosed, especially when it comes to situations where it is difficult to see the first signs of the disease. AI-based diagnostic tools may help confirm a diagnosis or highlight the need for further testing by analyzing large volumes of data and uncovering patterns that may not be immediately apparent to human evaluators. After a successful and timely diagnosis, autism can be treated through artificial intelligence using various methods. In this article, by using four datasets and gathering them with the federated learning method and diagnosing them with the support vector classifier method, the early diagnosis of this disorder has been discussed. In this method, we have achieved 99% accuracy for predicting autism spectrum disorder and we have achieved 13% improvement in the results.
</details>
<details>
<summary>摘要</summary>
“患有自关症诊断的路程可能很长而困难，而延误可能会有严重的后果。人工智能可能将您诊断自关症的方式完全改变，特别是在您difficult to spot the first signs of the disease的情况下。人工智能基本的诊断工具可能会帮助确认诊断或显示需要进一步测试的需求，通过分析大量数据和找出不同于人类评估者所能找到的模式。在这篇文章中，我们使用了四个数据集和使用联邦学习方法和支持向量分类方法进行诊断。在这种方法中，我们已经达成了99%的自关症诊断精度，并取得了13%的改善。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Zeroth-order-Asynchronous-Learning-with-Bounded-Delays-with-a-Use-case-in-Resource-Allocation-in-Communication-Networks"><a href="#Zeroth-order-Asynchronous-Learning-with-Bounded-Delays-with-a-Use-case-in-Resource-Allocation-in-Communication-Networks" class="headerlink" title="Zeroth-order Asynchronous Learning with Bounded Delays with a Use-case in Resource Allocation in Communication Networks"></a>Zeroth-order Asynchronous Learning with Bounded Delays with a Use-case in Resource Allocation in Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04604">http://arxiv.org/abs/2311.04604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pourya Behmandpoor, Marc Moonen, Panagiotis Patrinos</li>
<li>for: 这 paper 的目的是探讨分布式优化在分布式学习和适应中的应用。</li>
<li>methods: 该 paper 使用的方法包括分布式优化和 asynchronous learning。</li>
<li>results: 该 paper 提出了一种基于 zeroth-order oracle 的分布式优化方法，并提供了关于该方法 的理论收敛分析和实验结果。<details>
<summary>Abstract</summary>
Distributed optimization has experienced a significant surge in interest due to its wide-ranging applications in distributed learning and adaptation. While various scenarios, such as shared-memory, local-memory, and consensus-based approaches, have been extensively studied in isolation, there remains a need for further exploration of their interconnections. This paper specifically concentrates on a scenario where agents collaborate toward a unified mission while potentially having distinct tasks. Each agent's actions can potentially impact other agents through interactions. Within this context, the objective for the agents is to optimize their local parameters based on the aggregate of local reward functions, where only local zeroth-order oracles are available. Notably, the learning process is asynchronous, meaning that agents update and query their zeroth-order oracles asynchronously while communicating with other agents subject to bounded but possibly random communication delays. This paper presents theoretical convergence analyses and establishes a convergence rate for the proposed approach. Furthermore, it addresses the relevant issue of deep learning-based resource allocation in communication networks and conducts numerical experiments in which agents, acting as transmitters, collaboratively train their individual (possibly unique) policies to maximize a common performance metric.
</details>
<details>
<summary>摘要</summary>
分布式优化在分布式学习和适应中受到了广泛的关注，因为它们在各种应用场景中具有广泛的应用前景。虽然总共有分布式内存、本地内存和共识基本方法等多种场景被广泛研究，但还需要进一步探索这些场景之间的交互。这篇论文专门关注在多个代理协同完成一个统一任务的情况下，每个代理的行为可能会影响其他代理的交互中。在这个上下文中，代理的目标是基于所有代理的本地奖励函数的积和优化本地参数，但只有本地零次见识是可用的。备注，学习过程是异步的，代理在不同时间更新和查询本地零次见识，并在与其他代理通信时受到可能是随机的 bound 的通信延迟。本篇文章提供了理论快速整合分析和确定了快速整合率，并解决了深度学习基于通信网络的资源分配问题。此外，文章还进行了数值实验，在其中代理作为发送器，协同训练它们的个人（可能是唯一的）策略，以最大化一个共同性表现指标。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Based-Resource-Allocator-for-Communication-Systems-with-Dynamic-User-Utility-Demands"><a href="#A-Deep-Learning-Based-Resource-Allocator-for-Communication-Systems-with-Dynamic-User-Utility-Demands" class="headerlink" title="A Deep Learning Based Resource Allocator for Communication Systems with Dynamic User Utility Demands"></a>A Deep Learning Based Resource Allocator for Communication Systems with Dynamic User Utility Demands</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04600">http://arxiv.org/abs/2311.04600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pourya Behmandpoor, Panagiotis Patrinos, Marc Moonen</li>
<li>for: 这个论文主要用于研究一种基于深度学习的资源分配（RA）算法，以提高系统性能和灵活性。</li>
<li>methods: 该算法使用深度神经网络（DNN）来实现批处理优化算法，并在不同的分布式环境下进行资源分配。</li>
<li>results: 实验结果表明，该算法可以在不同的应用层和分布式环境下提供更高的系统性能和灵活性，并且可以适应不同的用户需求。<details>
<summary>Abstract</summary>
Deep learning (DL) based resource allocation (RA) has recently gained a lot of attention due to its performance efficiency. However, most of the related studies assume an ideal case where the number of users and their utility demands, e.g., data rate constraints, are fixed and the designed DL based RA scheme exploits a policy trained only for these fixed parameters. A computationally complex policy retraining is required whenever these parameters change. Therefore, in this paper, a DL based resource allocator (ALCOR) is introduced, which allows users to freely adjust their utility demands based on, e.g., their application layer. ALCOR employs deep neural networks (DNNs), as the policy, in an iterative optimization algorithm. The optimization algorithm aims to optimize the on-off status of users in a time-sharing problem to satisfy their utility demands in expectation. The policy performs unconstrained RA (URA) -- RA without taking into account user utility demands -- among active users to maximize the sum utility (SU) at each time instant. Based on the chosen URA scheme, ALCOR can perform RA in a model-based or model-free manner and in a centralized or distributed scenario. Derived convergence analyses provide guarantees for the convergence of ALCOR, and numerical experiments corroborate its effectiveness.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）基于资源分配（RA）在最近几年得到了很多关注，因为它的性能效率非常高。然而，大多数相关研究假设了一个理想的情况，在那里用户和他们的利用需求，例如数据速率限制，是固定的，而设计的 DL 基于 RA 方案仅仅利用一个已经训练过的策略来解决这些固定参数。在这种情况下，每当这些参数发生变化时，需要进行复杂的策略重新训练。因此，在本文中，一种基于 DL 的资源分配器（ALCOR）被引入，允许用户自由地调整他们的利用需求，例如应用层。ALCOR 使用深度神经网络（DNN）作为策略，并在迭代优化算法中使用。这个算法的目标是在时间分享问题中，通过调整用户的在线状态，来满足用户的利用需求。策略在活跃用户中进行不受限制的资源分配（URA），以 Maximize 时刻的总用户（SU）。根据选择的 URA 方案，ALCOR 可以进行模型基于或模型自由的 RA，以及中央或分布式的分配方式。从选择的 URA 方案而得出的算法可以提供 ALCOR 的 converges  garanties，并且数值实验证明了它的有效性。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Market-Value-in-Professional-Soccer-Insights-from-Explainable-Machine-Learning-Models"><a href="#Predicting-Market-Value-in-Professional-Soccer-Insights-from-Explainable-Machine-Learning-Models" class="headerlink" title="Predicting Market Value in Professional Soccer: Insights from Explainable Machine Learning Models"></a>Predicting Market Value in Professional Soccer: Insights from Explainable Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04599">http://arxiv.org/abs/2311.04599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyang Huang, Shaoliang Zhang</li>
<li>for: 这个研究旨在预测职业足球运动员市场价值使用可解释机器学习模型。</li>
<li>methods: 我们使用FIFA网站上的数据集合 ensemble机器学习方法和SHAP可解释方法进行预测。GBDT模型在评估中得分最高（0.8780）， Root Mean Squared Error最低（3,221,632.175），表明其在评估中的优异性。</li>
<li>results: 我们的分析发现，技能维度中的球控、短传、完成、抢断、踢球和攻击等特点具有重要性，而身体维度中的短跑速度和加速度具有重要性，认知维度中的反应具有先锋性。这些结果为职业足球运动员市场价值的更加准确、 объектив和一致的评估提供了有用的洞察。<details>
<summary>Abstract</summary>
This study presents an innovative method for predicting the market value of professional soccer players using explainable machine learning models. Using a dataset curated from the FIFA website, we employ an ensemble machine learning approach coupled with Shapley Additive exPlanations (SHAP) to provide detailed explanations of the models' predictions. The GBDT model achieves the highest mean R-Squared (0.8780) and the lowest mean Root Mean Squared Error (3,221,632.175), indicating its superior performance among the evaluated models. Our analysis reveals that specific skills such as ball control, short passing, finishing, interceptions, dribbling, and tackling are paramount within the skill dimension, whereas sprint speed and acceleration are critical in the fitness dimension, and reactions are preeminent in the cognitive dimension. Our results offer a more accurate, objective, and consistent framework for market value estimation, presenting useful insights for managerial decisions in player transfers.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "market value" is translated as "市场价值" (shìchǎng jīnyà)* "professional soccer players" is translated as "职业足球运动员" (zhíyè zúqiú yùndòng yuán)* "explainable machine learning models" is translated as "可解释机器学习模型" (kějìjué jīshì wùxíhuì módelì)* "ensemble machine learning approach" is translated as "集成机器学习方法" (jíshēn jīshì wùxíhuì fāngshì)* "Shapley Additive exPlanations" is translated as "沙普利添加式解释" (shāpǔlì tiānjiā xiěyì)* "GBDT model" is translated as "GBDT模型" (GBDT módelì)* "mean R-Squared" is translated as "平均R平方" (píngjì R píngfāng)* "mean Root Mean Squared Error" is translated as "平均根平方误差" (píngjì gēn píngfāng yuèshì)
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-as-a-tool-for-quantum-error-reduction-in-quantum-image-processing"><a href="#Deep-learning-as-a-tool-for-quantum-error-reduction-in-quantum-image-processing" class="headerlink" title="Deep learning as a tool for quantum error reduction in quantum image processing"></a>Deep learning as a tool for quantum error reduction in quantum image processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04575">http://arxiv.org/abs/2311.04575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krzysztof Werner, Kamil Wereszczyński, Rafał Potempa, Krzysztof Cyran</li>
<li>for: 图像表示的量子计算研究</li>
<li>methods: 使用量子排序、维度缩放和阶段缩放等方法实现图像表示</li>
<li>results: 通过将生成器推荐网络与阶段误差摘要方法相结合，实现图像表示中的总误差减少<details>
<summary>Abstract</summary>
Despite the limited availability and quantum volume of quantum computers, quantum image representation is a widely researched area. Currently developed methods use quantum entanglement to encode information about pixel positions. These methods range from using the angle parameter of the rotation gate (e.g., the Flexible Representation of Quantum Images, FRQI), sequences of qubits (e.g., Novel Enhanced Quantum Representation, NEQR), or the angle parameter of the phase shift gates (e.g., Local Phase Image Quantum Encoding, LPIQE) for storing color information. All these methods are significantly affected by decoherence and other forms of quantum noise, which is an inseparable part of quantum computing in the noisy intermediate-scale quantum era. These phenomena can highly influence the measurements and result in extracted images that are visually dissimilar to the originals. Because this process is at its foundation quantum, the computational reversal of this process is possible. There are many methods for error correction, mitigation, and reduction, but all of them use quantum computer time or additional qubits to achieve the desired result. We report the successful use of a generative adversarial network trained for image-to-image translation, in conjunction with Phase Distortion Unraveling error reduction method, for reducing overall error in images encoded using LPIQE.
</details>
<details>
<summary>摘要</summary>
尽管量子计算机的可用性和量子量都有限，量子图像表示仍然是广泛研究的领域。目前已经开发出的方法使用量子束缚来编码图像元素的信息。这些方法包括使用旋转门的角度参数（例如，自适应量子图像表示法，FRQI）、序列位域（例如，改进量子表示法，NEQR）或扩散门的角度参数（例如，本地阶段图像量子编码法，LPIQE）来存储颜色信息。这些方法都受到辐射噪和其他形式的量子噪声的影响，这些噪声是量子计算在不稳定中等级量子时期的不可避免的一部分。这些现象会高度影响测量结果，导致提取的图像与原始图像视觉上不同。由于这是基于量子的过程，因此可以进行量子计算的反转。有许多方法用于错误纠正、缓解和减少，但所有这些方法均需要量子计算时间或额外的寄存器来实现所需的结果。我们报道了使用基于图像到图像翻译的生成 adversarial network，与phas Distortion Unraveling错误纠正方法相结合，以减少LPIQE编码图像的总错误。
</details></li>
</ul>
<hr>
<h2 id="Information-Theoretic-Generalization-Bounds-for-Transductive-Learning-and-its-Applications"><a href="#Information-Theoretic-Generalization-Bounds-for-Transductive-Learning-and-its-Applications" class="headerlink" title="Information-Theoretic Generalization Bounds for Transductive Learning and its Applications"></a>Information-Theoretic Generalization Bounds for Transductive Learning and its Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04561">http://arxiv.org/abs/2311.04561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huayi Tang, Yong Liu</li>
<li>for: 这 paper 是为了研究逻辑学上的推导学习算法的通用 bounds。</li>
<li>methods: 该 paper 使用了数据依赖和算法依赖的通用 bounds，并引入了转ductive supersamples 的概念，以推广 inductive learning 的 Setting。</li>
<li>results: 该 paper 得到了在不同信息度下的通用 bounds，并derived novel PAC-Bayesian bounds和loss landscape flatness的连接。最后，paper 还提出了 adaptive optimization algorithms 的 upper bounds，并 validate 了 results 在 semi-supervised learning 和 graph learning 场景中。<details>
<summary>Abstract</summary>
In this paper, we develop data-dependent and algorithm-dependent generalization bounds for transductive learning algorithms in the context of information theory for the first time. We show that the generalization gap of transductive learning algorithms can be bounded by the mutual information between training labels and hypothesis. By innovatively proposing the concept of transductive supersamples, we go beyond the inductive learning setting and establish upper bounds in terms of various information measures. Furthermore, we derive novel PAC-Bayesian bounds and build the connection between generalization and loss landscape flatness under the transductive learning setting. Finally, we present the upper bounds for adaptive optimization algorithms and demonstrate the applications of results on semi-supervised learning and graph learning scenarios. Our theoretic results are validated on both synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary>
在本文中，我们为推论学习算法在信息理论上开发了数据依赖和算法依赖的通用泛化上限。我们证明了推论学习算法的泛化差可以通过训练标签和假设之间的共同信息来边界。我们创新地提出了推论超采样的概念，以超过步骤学习设定，并在不同信息度量下建立上限。此外，我们 derivated novel PAC-Bayesian bound和泛化与损失地形平坦的连接。最后，我们提供了适应优化算法的上限，并在半无监督学习和图学习场景中应用了结果。我们的理论结果在Synthetic和实际数据上得到验证。Note that Simplified Chinese is a written form of Chinese that uses simpler grammar and vocabulary than Traditional Chinese. It is commonly used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Regression-with-Cost-based-Rejection"><a href="#Regression-with-Cost-based-Rejection" class="headerlink" title="Regression with Cost-based Rejection"></a>Regression with Cost-based Rejection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04550">http://arxiv.org/abs/2311.04550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Cheng, Yuzhou Cao, Haobo Wang, Hongxin Wei, Bo An, Lei Feng</li>
<li>for: 避免错误预测，对于某些示例进行拒绝预测</li>
<li>methods: 使用成本基于的拒绝，对于某些示例进行拒绝预测</li>
<li>results: 提出了一个新的回归问题—— regression with cost-based rejection，并提出了一个可以解决这个问题的方法，并且进行了广泛的实验证明了方法的有效性。<details>
<summary>Abstract</summary>
Learning with rejection is an important framework that can refrain from making predictions to avoid critical mispredictions by balancing between prediction and rejection. Previous studies on cost-based rejection only focused on the classification setting, which cannot handle the continuous and infinite target space in the regression setting. In this paper, we investigate a novel regression problem called regression with cost-based rejection, where the model can reject to make predictions on some examples given certain rejection costs. To solve this problem, we first formulate the expected risk for this problem and then derive the Bayes optimal solution, which shows that the optimal model should reject to make predictions on the examples whose variance is larger than the rejection cost when the mean squared error is used as the evaluation metric. Furthermore, we propose to train the model by a surrogate loss function that considers rejection as binary classification and we provide conditions for the model consistency, which implies that the Bayes optimal solution can be recovered by our proposed surrogate loss. Extensive experiments demonstrate the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
学习 WITH 拒绝是一种重要的框架，可以避免在预测时发生重要的误预测，通过平衡预测和拒绝来做到这一点。在过去的研究中，cost-based rejection仅限于分类设置，无法处理连续的无穷目标空间在回归设置下。在这篇论文中，我们研究了一种新的回归问题：基于成本的拒绝回归，其中模型可以根据certain rejection costs拒绝对一些示例进行预测。为解决这个问题，我们首先计算这个问题的预期风险，然后 derivate Bayes 优质解决方案，显示了优质模型应该在variance 大于 rejection cost 的示例上拒绝进行预测，当使用mean squared error 作为评价指标时。此外，我们提议使用surrogate 损失函数来训练模型，并提供了条件，以确保模型的一致性，这意味着我们的提议的surrogate损失函数可以回归 Bayes 优质解决方案。我们的实验结果表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="FEIR-Quantifying-and-Reducing-Envy-and-Inferiority-for-Fair-Recommendation-of-Limited-Resources"><a href="#FEIR-Quantifying-and-Reducing-Envy-and-Inferiority-for-Fair-Recommendation-of-Limited-Resources" class="headerlink" title="FEIR: Quantifying and Reducing Envy and Inferiority for Fair Recommendation of Limited Resources"></a>FEIR: Quantifying and Reducing Envy and Inferiority for Fair Recommendation of Limited Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04542">http://arxiv.org/abs/2311.04542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nan Li, Bo Kang, Jefrey Lijffijt, Tijl De Bie</li>
<li>for: 本研究旨在提出一种新的不平等度量，以解决电子招聘和在线约会中的推荐问题。</li>
<li>methods: 本文引入了一种新的不平等度量，称为“劣等”，用于量化用户对推荐的Item的竞争性益处。此外，本文还结合了“嫉妒”和“实用性”这三种度量，并将它们转化为可导数学函数。</li>
<li>results: 实验表明，本文提出的方法可以在 synthetic 数据和实际数据上提高不平等、嫉妒和实用性的融合，比静态推荐和基eline方法更优。<details>
<summary>Abstract</summary>
In settings such as e-recruitment and online dating, recommendation involves distributing limited opportunities, calling for novel approaches to quantify and enforce fairness. We introduce \emph{inferiority}, a novel (un)fairness measure quantifying a user's competitive disadvantage for their recommended items. Inferiority complements \emph{envy}, a fairness notion measuring preference for others' recommendations. We combine inferiority and envy with \emph{utility}, an accuracy-related measure of aggregated relevancy scores. Since these measures are non-differentiable, we reformulate them using a probabilistic interpretation of recommender systems, yielding differentiable versions. We combine these loss functions in a multi-objective optimization problem called \texttt{FEIR} (Fairness through Envy and Inferiority Reduction), applied as post-processing for standard recommender systems. Experiments on synthetic and real-world data demonstrate that our approach improves trade-offs between inferiority, envy, and utility compared to naive recommendations and the baseline methods.
</details>
<details>
<summary>摘要</summary>
在电子招聘和在线约会等设置中，推荐具有限制的机会，需要开发新的方法来衡量和保证公平。我们介绍了“劣等感”，一种新的公平度量量， quantifying 用户对推荐的物品的竞争性劣势。劣等感与“嫉妒”（envy）、“用处”（utility）这两种公平概念相结合，用于衡量用户对推荐的物品的喜好程度和准确性。由于这些度量函数不导数 differentiable，我们使用概率解释器来重新表示它们，得到了导数函数。我们将这些损失函数组合成了一个多目标优化问题 called \texttt{FEIR}（公平性 через 劣等感和嫉妒减少），用于补做标准推荐系统的后处理。实验表明，我们的方法可以在synthetic和实际数据上提高劣等感、嫉妒和用处之间的负荷平衡，比标准推荐和基eline方法更好。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Assisted-Multiuser-MIMO-Load-Modulated-Systems-for-Enhanced-Downlink-mmWave-Communications"><a href="#Deep-Learning-Assisted-Multiuser-MIMO-Load-Modulated-Systems-for-Enhanced-Downlink-mmWave-Communications" class="headerlink" title="Deep Learning Assisted Multiuser MIMO Load Modulated Systems for Enhanced Downlink mmWave Communications"></a>Deep Learning Assisted Multiuser MIMO Load Modulated Systems for Enhanced Downlink mmWave Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04537">http://arxiv.org/abs/2311.04537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ercong Yu, Jinle Zhu, Qiang Li, Zilong Liu, Hongyang Chen, Shlomo Shamai, H. Vincent Poor</li>
<li>For: The paper is focused on improving the performance of multiuser load modulation arrays (MU-LMAs) in millimeter wave (mmWave) multi-input multi-output (MIMO) systems.* Methods: The paper proposes two algorithms for MU-LMA systems employing a full-array structured (FAS) transmitter: an FAS-based normalized block diagonalization (FAS-NBD) algorithm and a Deep Learning-enhanced (FAS-DL-NBD) algorithm for adaptive codebook design and codebook-independent decoding.* Results: The proposed algorithms are shown to be robust to imperfect knowledge of channel state information and yield excellent error performance, with the FAS-DL-NBD algorithm enabling signal detection with low complexity as the number of bits per codeword increases.<details>
<summary>Abstract</summary>
This paper is focused on multiuser load modulation arrays (MU-LMAs) which are attractive due to their low system complexity and reduced cost for millimeter wave (mmWave) multi-input multi-output (MIMO) systems. The existing precoding algorithm for downlink MU-LMA relies on a sub-array structured (SAS) transmitter which may suffer from decreased degrees of freedom and complex system configuration. Furthermore, a conventional LMA codebook with codewords uniformly distributed on a hypersphere may not be channel-adaptive and may lead to increased signal detection complexity. In this paper, we conceive an MU-LMA system employing a full-array structured (FAS) transmitter and propose two algorithms accordingly. The proposed FAS-based system addresses the SAS structural problems and can support larger numbers of users. For LMA-imposed constant-power downlink precoding, we propose an FAS-based normalized block diagonalization (FAS-NBD) algorithm. However, the forced normalization may result in performance degradation. This degradation, together with the aforementioned codebook design problems, is difficult to solve analytically. This motivates us to propose a Deep Learning-enhanced (FAS-DL-NBD) algorithm for adaptive codebook design and codebook-independent decoding. It is shown that the proposed algorithms are robust to imperfect knowledge of channel state information and yield excellent error performance. Moreover, the FAS-DL-NBD algorithm enables signal detection with low complexity as the number of bits per codeword increases.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose an MU-LMA system employing a full-array structured (FAS) transmitter and put forward two algorithms accordingly. The proposed FAS-based system addresses the SAS structural problems and can support larger numbers of users. For LMA-imposed constant-power downlink precoding, we propose an FAS-based normalized block diagonalization (FAS-NBD) algorithm. However, the forced normalization may result in performance degradation. This degradation, together with the aforementioned codebook design problems, is difficult to solve analytically.To address these issues, we propose a Deep Learning-enhanced (FAS-DL-NBD) algorithm for adaptive codebook design and codebook-independent decoding. It is shown that the proposed algorithms are robust to imperfect knowledge of channel state information and yield excellent error performance. Moreover, the FAS-DL-NBD algorithm enables signal detection with low complexity as the number of bits per codeword increases.
</details></li>
</ul>
<hr>
<h2 id="An-Unsupervised-Deep-Learning-Approach-for-the-Wave-Equation-Inverse-Problem"><a href="#An-Unsupervised-Deep-Learning-Approach-for-the-Wave-Equation-Inverse-Problem" class="headerlink" title="An Unsupervised Deep Learning Approach for the Wave Equation Inverse Problem"></a>An Unsupervised Deep Learning Approach for the Wave Equation Inverse Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04531">http://arxiv.org/abs/2311.04531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiong-Bin Yan, Keke Wu, Zhi-Qin John Xu, Zheng Ma</li>
<li>for: 实时地震波形描述高精度地层物理参数</li>
<li>methods: 利用深度神经网络和部分数学方程来解决全波形描述问题</li>
<li>results: 比较 conventinal方法更好地重建地层物理速度参数<details>
<summary>Abstract</summary>
Full-waveform inversion (FWI) is a powerful geophysical imaging technique that infers high-resolution subsurface physical parameters by solving a non-convex optimization problem. However, due to limitations in observation, e.g., limited shots or receivers, and random noise, conventional inversion methods are confronted with numerous challenges, such as the local-minimum problem. In recent years, a substantial body of work has demonstrated that the integration of deep neural networks and partial differential equations for solving full-waveform inversion problems has shown promising performance. In this work, drawing inspiration from the expressive capacity of neural networks, we provide an unsupervised learning approach aimed at accurately reconstructing subsurface physical velocity parameters. This method is founded on a re-parametrization technique for Bayesian inference, achieved through a deep neural network with random weights. Notably, our proposed approach does not hinge upon the requirement of the labeled training dataset, rendering it exceedingly versatile and adaptable to diverse subsurface models. Extensive experiments show that the proposed approach performs noticeably better than existing conventional inversion methods.
</details>
<details>
<summary>摘要</summary>
全波形推算（FWI）是一种具有高分辨率地球物理参数推算技术，通过解决不对称优化问题来推算地球物理参数。然而，由于观测限制，如有限的发射器或接收器，以及随机噪声，传统的推算方法会遇到许多挑战，如本地最优问题。在过去几年，一大量的研究表明，将深度神经网络和部分偏微分方程相结合，可以在全波形推算问题中显著提高性能。在这种情况下，我们提出了一种无监督学习方法，旨在准确地重construct地球物理速度参数。这种方法基于 Bayesian 推理中的重arametrization技术，通过一个随机权重的深度神经网络来实现。吸引注意的是，我们提posed方法不依赖于标注训练数据集，因此非常灵活和适应性强，适用于多种不同的地球模型。广泛的实验表明，我们的方法在现有的推算方法之上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Bandit-Learning-to-Rank-with-Position-Based-Click-Models-Personalized-and-Equal-Treatments"><a href="#Bandit-Learning-to-Rank-with-Position-Based-Click-Models-Personalized-and-Equal-Treatments" class="headerlink" title="Bandit Learning to Rank with Position-Based Click Models: Personalized and Equal Treatments"></a>Bandit Learning to Rank with Position-Based Click Models: Personalized and Equal Treatments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04528">http://arxiv.org/abs/2311.04528</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianchen Zhou, Jia Liu, Yang Jiao, Chaosheng Dong, Yetian Chen, Yan Gao, Yi Sun</li>
<li>for: 本研究的目的是提出一个基于多重投掷机(MAB)的在线学习排名算法，用于推荐系统中的排名问题。</li>
<li>methods: 本研究使用了MAB框架和位置基于点击模型来模型在线学习排名问题。</li>
<li>results: 本研究提出了一个全面的MAB模型，并开发了两种名为GreedyRank和UCBRank的政策，这两种政策可以应用于个性化和平等的排名待遇。此外，研究还证明了这两种政策在不同的问题设定下都可以达到$O(\sqrt{t}\ln t)$和$O(\sqrt{t\ln t})$的任何线性 regret。<details>
<summary>Abstract</summary>
Online learning to rank (ONL2R) is a foundational problem for recommender systems and has received increasing attention in recent years. Among the existing approaches for ONL2R, a natural modeling architecture is the multi-armed bandit framework coupled with the position-based click model. However, developing efficient online learning policies for MAB-based ONL2R with position-based click models is highly challenging due to the combinatorial nature of the problem, and partial observability in the position-based click model. To date, results in MAB-based ONL2R with position-based click models remain rather limited, which motivates us to fill this gap in this work. Our main contributions in this work are threefold: i) We propose the first general MAB framework that captures all key ingredients of ONL2R with position-based click models. Our model considers personalized and equal treatments in ONL2R ranking recommendations, both of which are widely used in practice; ii) Based on the above analytical framework, we develop two unified greed- and UCB-based policies called GreedyRank and UCBRank, each of which can be applied to personalized and equal ranking treatments; and iii) We show that both GreedyRank and UCBRank enjoy $O(\sqrt{t}\ln t)$ and $O(\sqrt{t\ln t})$ anytime sublinear regret for personalized and equal treatment, respectively. For the fundamentally hard equal ranking treatment, we identify classes of collective utility functions and their associated sufficient conditions under which $O(\sqrt{t}\ln t)$ and $O(\sqrt{t\ln t})$ anytime sublinear regrets are still achievable for GreedyRank and UCBRank, respectively. Our numerical experiments also verify our theoretical results and demonstrate the efficiency of GreedyRank and UCBRank in seeking the optimal action under various problem settings.
</details>
<details>
<summary>摘要</summary>
“在线学习排名（ONL2R）是推荐系统的基础问题，在最近几年内得到了越来越多的关注。现有的ONL2R方法中，一种自然的建模架构是多重投掷机制（MAB）结合位置基于点击模型。然而，开发高效的在线学习策略 дляMAB基于ONL2R的位置基于点击模型是极其困难的，因为这个问题具有 combinatorial 性和部分可见性。到目前为止，关于MAB基于ONL2R的位置基于点击模型的结果尚未充分，这种挑战我们在这个工作中填补。我们的主要贡献是三fold：1. 我们提出了第一个涵盖ONL2R所有关键因素的MAB框架。我们的模型考虑了个性化和平等的排名推荐，这两种方法在实践中广泛使用；2. 基于上述分析框架，我们开发了两种总是优于UCRL（Upper Confidence Bound with Lookahead）的政策，即GreedyRank和UCBRank，每个政策都可以应用于个性化和平等的排名推荐；3. 我们证明了GreedyRank和UCBRank在个性化和平等排名下都可以获得$O(\sqrt{t}\ln t)$和$O(\sqrt{t\ln t})$的任何时间下折Linear regret，而且对于平等排名，我们还提出了一些类型的集合性能函数和其相应的充分条件，这些条件下，GreedyRank和UCBRank仍然可以获得$O(\sqrt{t}\ln t)$和$O(\sqrt{t\ln t})$的任何时间下折Linear regret。我们的numerical experiments也验证了我们的理论结果，并证明了GreedyRank和UCBRank在不同的问题设置下都能够有效地寻找优化的行动。”
</details></li>
</ul>
<hr>
<h2 id="Long-term-Time-Series-Forecasting-based-on-Decomposition-and-Neural-Ordinary-Differential-Equations"><a href="#Long-term-Time-Series-Forecasting-based-on-Decomposition-and-Neural-Ordinary-Differential-Equations" class="headerlink" title="Long-term Time Series Forecasting based on Decomposition and Neural Ordinary Differential Equations"></a>Long-term Time Series Forecasting based on Decomposition and Neural Ordinary Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04522">http://arxiv.org/abs/2311.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seonkyu Lim, Jaehyeon Park, Seojin Kim, Hyowon Wi, Haksoo Lim, Jinsung Jeon, Jeongwhan Choi, Noseong Park</li>
<li>for: 这个研究是为了解决长期时间序列预测（LTSF） tasks 中的挑战，例如财务投资、健康照顾、交通预测和天气预测等领域。</li>
<li>methods: 本研究提出了一个基于线性常微分方程（ODEs）和时间序列分解方法的模型，以优化时间序列预测的性能。</li>
<li>results:  compared with基于Transformer的方法，LTSF-DNODE模型在多个真实世界数据集上表现出色，并且在不同数据集上进行了各种调整的研究。<details>
<summary>Abstract</summary>
Long-term time series forecasting (LTSF) is a challenging task that has been investigated in various domains such as finance investment, health care, traffic, and weather forecasting. In recent years, Linear-based LTSF models showed better performance, pointing out the problem of Transformer-based approaches causing temporal information loss. However, Linear-based approach has also limitations that the model is too simple to comprehensively exploit the characteristics of the dataset. To solve these limitations, we propose LTSF-DNODE, which applies a model based on linear ordinary differential equations (ODEs) and a time series decomposition method according to data statistical characteristics. We show that LTSF-DNODE outperforms the baselines on various real-world datasets. In addition, for each dataset, we explore the impacts of regularization in the neural ordinary differential equation (NODE) framework.
</details>
<details>
<summary>摘要</summary>
长期时系列预测（LTSF）是一项复杂的任务，在不同领域如金融投资、医疗、交通和天气预测中都有广泛的研究。在最近几年，线性基于的LTSF模型表现更好，表明Transformer基于的方法会导致时间信息损失。然而，线性基于的方法也有限制，模型太简单，无法充分利用数据集的特点。为解决这些限制，我们提出了LTSF-DNODE，它使用基于线性常微分方程（ODEs）的模型和根据数据统计特点的时间序列分解方法。我们表明，LTSF-DNODE在各种真实世界数据集上表现出色，并且对每个数据集进行了减少正则化的影响分析。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Mirror-Descent-Bilevel-Optimization"><a href="#Adaptive-Mirror-Descent-Bilevel-Optimization" class="headerlink" title="Adaptive Mirror Descent Bilevel Optimization"></a>Adaptive Mirror Descent Bilevel Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04520">http://arxiv.org/abs/2311.04520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feihu Huang</li>
<li>for: 这种纸子是为了解决非 convex 二级优化问题而写的。</li>
<li>methods: 这种方法使用了镜像下降法，并且使用了投影援助加速器（i.e., AdaPAG）和随机投影援助加速器（i.e., AdaVSPAG）来解决非 convex 二级优化问题。</li>
<li>results: 这种方法可以在 $O(\epsilon^{-1})$ 和 $O(\epsilon^{-3&#x2F;2})$ 两种情况下取得最佳known的加速率，并且可以用于解决非 convex 强 convex 二级优化问题。<details>
<summary>Abstract</summary>
In the paper, we propose a class of efficient adaptive bilevel methods based on mirror descent for nonconvex bilevel optimization, where its upper-level problem is nonconvex possibly with nonsmooth regularization, and its lower-level problem is also nonconvex while satisfies Polyak-{\L}ojasiewicz (PL) condition. To solve these deterministic bilevel problems, we present an efficient adaptive projection-aid gradient (i.e., AdaPAG) method based on mirror descent, and prove that it obtains the best known gradient complexity of $O(\epsilon^{-1})$ for finding an $\epsilon$-stationary solution of nonconvex bilevel problems. To solve these stochastic bilevel problems, we propose an efficient adaptive stochastic projection-aid gradient (i.e., AdaVSPAG) methods based on mirror descent and variance-reduced techniques, and prove that it obtains the best known gradient complexity of $O(\epsilon^{-3/2})$ for finding an $\epsilon$-stationary solution. Since the PL condition relaxes the strongly convex, our algorithms can be used to nonconvex strongly-convex bilevel optimization. Theoretically, we provide a useful convergence analysis framework for our methods under some mild conditions, and prove that our methods have a fast convergence rate of $O(\frac{1}{T})$, where $T$ denotes the number of iterations.
</details>
<details>
<summary>摘要</summary>
在论文中，我们提出了一种高效的适应双层方法基于镜像极小值算法，用于非 convex 双层优化问题，其上层问题为非 convex 可能具有非精炤规则化，下层问题则满足波佩-{\L}ojasiewicz（PL）条件。为解决这些权重 deterministic 双层问题，我们提出了一种高效的适应投影帮助梯度算法（i.e., AdaPAG），并证明其可以在 $O(\epsilon^{-1})$ 的梯度复杂度下找到一个 $\epsilon$-站点解决方案。为解决这些随机双层问题，我们提出了一种高效的适应随机投影帮助梯度算法（i.e., AdaVSPAG），并证明其可以在 $O(\epsilon^{-3/2})$ 的梯度复杂度下找到一个 $\epsilon$-站点解决方案。由于 PL 条件宽松了强 convex，我们的算法可以应用于非 convex 强 convex 双层优化问题。从理论角度来看，我们提供了一个有用的 convergence 分析框架，并证明我们的方法在某些轻量级的 услови下具有 $O(\frac{1}{T})$ 的快速收敛率，其中 $T$ 表示迭代次数。
</details></li>
</ul>
<hr>
<h2 id="Towards-Democratizing-AI-A-Comparative-Analysis-of-AI-as-a-Service-Platforms-and-the-Open-Space-for-Machine-Learning-Approach"><a href="#Towards-Democratizing-AI-A-Comparative-Analysis-of-AI-as-a-Service-Platforms-and-the-Open-Space-for-Machine-Learning-Approach" class="headerlink" title="Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach"></a>Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04518">http://arxiv.org/abs/2311.04518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dennis Rall, Bernhard Bauer, Thomas Fraunholz</li>
<li>for: 这篇论文的目的是实现人工智能的民主化，对于无技术背景的人员提供更多的机会使用人工智能。</li>
<li>methods: 这篇论文使用了对多个流行的人工智能服务平台进行比较，并评估了这些平台是否能够实现人工智能的民主化。</li>
<li>results: 论文提出了一个新的平台“Open Space for Machine Learning”，这个平台使用了最新的技术如Kubernetes、Kubeflow Pipelines和Ludwig，可以更好地满足人工智能的民主化需求。<details>
<summary>Abstract</summary>
Recent AI research has significantly reduced the barriers to apply AI, but the process of setting up the necessary tools and frameworks can still be a challenge. While AI-as-a-Service platforms have emerged to simplify the training and deployment of AI models, they still fall short of achieving true democratization of AI. In this paper, we aim to address this gap by comparing several popular AI-as-a-Service platforms and identifying the key requirements for a platform that can achieve true democratization of AI. Our analysis highlights the need for self-hosting options, high scalability, and openness. To address these requirements, we propose our approach: the "Open Space for Machine Learning" platform. Our platform is built on cutting-edge technologies such as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the challenges of democratizing AI. We argue that our approach is more comprehensive and effective in meeting the requirements of democratizing AI than existing AI-as-a-Service platforms.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的人工智能研究已经大大降低了应用人工智能的门槛，但是设置必要的工具和框架仍然是一个挑战。人工智能为服务平台已经出现，以便简化人工智能模型的训练和部署，但是它们仍然无法实现真正的人工智能民主化。在这篇论文中，我们想要解决这个差距，因此我们比较了一些流行的人工智能为服务平台，并确定了实现人工智能民主化的关键要求。我们的分析表明，自主主机选项、高可扩展性和开放性是必要的。为了解决这些要求，我们提出了我们的方法：“机器学习开放空间”平台。我们的平台基于最新的技术，如Kubernetes、Kubeflow Pipelines和Ludwig，这使得我们可以超越民主化人工智能的挑战。我们认为，我们的方法比现有的人工智能为服务平台更全面和有效地实现了人工智能民主化的要求。
</details></li>
</ul>
<hr>
<h2 id="Strategies-for-Parallelizing-the-Big-Means-Algorithm-A-Comprehensive-Tutorial-for-Effective-Big-Data-Clustering"><a href="#Strategies-for-Parallelizing-the-Big-Means-Algorithm-A-Comprehensive-Tutorial-for-Effective-Big-Data-Clustering" class="headerlink" title="Strategies for Parallelizing the Big-Means Algorithm: A Comprehensive Tutorial for Effective Big Data Clustering"></a>Strategies for Parallelizing the Big-Means Algorithm: A Comprehensive Tutorial for Effective Big Data Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04517">http://arxiv.org/abs/2311.04517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ravil Mussabayev, Rustam Mussabayev</li>
<li>for: 本研究探讨了对大规模数据集进行归一化的大均值算法优化问题，探索了四种不同的并行策略。</li>
<li>methods: 本研究采用了广泛的实验来评估每种策略的计算效率、可扩展性和归一化性能，并探讨了各种因素对归一化质量的影响。</li>
<li>results: 研究发现了不同策略的优缺点，并提供了实际的资源和数据特点选择最佳并行策略的指导原则，为并行技术的深入理解做出贡献。<details>
<summary>Abstract</summary>
This study focuses on the optimization of the Big-means algorithm for clustering large-scale datasets, exploring four distinct parallelization strategies. We conducted extensive experiments to assess the computational efficiency, scalability, and clustering performance of each approach, revealing their benefits and limitations. The paper also delves into the trade-offs between computational efficiency and clustering quality, examining the impacts of various factors. Our insights provide practical guidance on selecting the best parallelization strategy based on available resources and dataset characteristics, contributing to a deeper understanding of parallelization techniques for the Big-means algorithm.
</details>
<details>
<summary>摘要</summary>
这项研究关注大规模数据集 clustering 的大平均算法优化，探讨了四种不同的并行策略。我们进行了广泛的实验，评估了每种方法的计算效率、可扩展性和归一化性，并分析了各种因素对结果的影响。这些发现可以为我们在具有不同资源和数据特点的情况下选择最佳并行策略提供实践性的指导， deepened our understanding of parallelization techniques for the Big-means algorithm。
</details></li>
</ul>
<hr>
<h2 id="Solution-of-FPK-Equation-for-Stochastic-Dynamics-Subjected-to-Additive-Gaussian-Noise-via-Deep-Learning-Approach"><a href="#Solution-of-FPK-Equation-for-Stochastic-Dynamics-Subjected-to-Additive-Gaussian-Noise-via-Deep-Learning-Approach" class="headerlink" title="Solution of FPK Equation for Stochastic Dynamics Subjected to Additive Gaussian Noise via Deep Learning Approach"></a>Solution of FPK Equation for Stochastic Dynamics Subjected to Additive Gaussian Noise via Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04511">http://arxiv.org/abs/2311.04511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir H. Khodabakhsh, Seid H. Pourtakdoust</li>
<li>for: 解决高维度泊松方程的精炼问题</li>
<li>methods: 基于物理法则的深度学习网络（FPK-DP Net）</li>
<li>results: 可以解决高维度实际问题，无需依赖于先 simulate 数据，并且可以作为高效的准确模型使用<details>
<summary>Abstract</summary>
The Fokker-Plank-Kolmogorov (FPK) equation is an idealized model representing many stochastic systems commonly encountered in the analysis of stochastic structures as well as many other applications. Its solution thus provides an invaluable insight into the performance of many engineering systems. Despite its great importance, the solution of the FPK equation is still extremely challenging. For systems of practical significance, the FPK equation is usually high dimensional, rendering most of the numerical methods ineffective. In this respect, the present work introduces the FPK-DP Net as a physics-informed network that encodes the physical insights, i.e. the governing constrained differential equations emanated out of physical laws, into a deep neural network. FPK-DP Net is a mesh-free learning method that can solve the density evolution of stochastic dynamics subjected to additive white Gaussian noise without any prior simulation data and can be used as an efficient surrogate model afterward. FPK-DP Net uses the dimension-reduced FPK equation. Therefore, it can be used to address high-dimensional practical problems as well. To demonstrate the potential applicability of the proposed framework, and to study its accuracy and efficacy, numerical implementations on five different benchmark problems are investigated.
</details>
<details>
<summary>摘要</summary>
“福克-普朗-科穆洛夫（FPK）方程是一种理想化的模型，广泛应用于杂相随机系统的分析和其他多种应用。它的解释能提供各种工程系统的性能的有价值信息。然而，解决FPK方程仍然是非常困难的。实际应用中的FPK方程通常是高维的，使得大多数数字方法无效。在这个问题上，本工作提出了FPK-DP网，它是一种基于物理法则的深度学习网络，可以解决受加性白噪声影响的杂相动态系统的浓度演化。FPK-DP网是一种无网格学习方法，不需要任何先前的仪器数据，可以作为高效的代理模型。由于FPK-DP网使用缩少的FPK方程，因此可以应用于高维实际问题。为了证明提出的框架的可能应用性和准确性，本文对五个不同的 benchmark 问题进行了数学实现。”Note that Simplified Chinese is a written language, and the translation is based on the standardized grammar and vocabulary of Simplified Chinese. The translation may vary depending on the specific dialect or regional variation of Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Constrained-Adaptive-Attacks-Realistic-Evaluation-of-Adversarial-Examples-and-Robust-Training-of-Deep-Neural-Networks-for-Tabular-Data"><a href="#Constrained-Adaptive-Attacks-Realistic-Evaluation-of-Adversarial-Examples-and-Robust-Training-of-Deep-Neural-Networks-for-Tabular-Data" class="headerlink" title="Constrained Adaptive Attacks: Realistic Evaluation of Adversarial Examples and Robust Training of Deep Neural Networks for Tabular Data"></a>Constrained Adaptive Attacks: Realistic Evaluation of Adversarial Examples and Robust Training of Deep Neural Networks for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04503">http://arxiv.org/abs/2311.04503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thibault Simonetto, Salah Ghamizi, Antoine Desjardins, Maxime Cordy, Yves Le Traon</li>
<li>for: 这篇论文的目的是为了评估深度学习模型在表格数据上的抗辐射性能。</li>
<li>methods: 这篇论文提出了CAA，首个适用于受限表格深度学习模型的谱攻击方法，它结合了梯度和搜索攻击来生成受限制的攻击示例。</li>
<li>results: 研究人员使用CAA建立了三个受欢迎的应用场景（信用评分、骗取和机器人攻击检测）的深度表格模型的攻击 benchmark，并在不同的威胁模型下进行了测试。结果显示了不同的领域知识、抗辐射训练和攻击预算对深度表格模型的抗辐射性能产生了不同的影响。<details>
<summary>Abstract</summary>
State-of-the-art deep learning models for tabular data have recently achieved acceptable performance to be deployed in industrial settings. However, the robustness of these models remains scarcely explored. Contrary to computer vision, there is to date no realistic protocol to properly evaluate the adversarial robustness of deep tabular models due to intrinsic properties of tabular data such as categorical features, immutability, and feature relationship constraints. To fill this gap, we propose CAA, the first efficient evasion attack for constrained tabular deep learning models. CAA is an iterative parameter-free attack that combines gradient and search attacks to generate adversarial examples under constraints. We leverage CAA to build a benchmark of deep tabular models across three popular use cases: credit scoring, phishing and botnet attacks detection. Our benchmark supports ten threat models with increasing capabilities of the attacker, and reflects real-world attack scenarios for each use case. Overall, our results demonstrate how domain knowledge, adversarial training, and attack budgets impact the robustness assessment of deep tabular models and provide security practitioners with a set of recommendations to improve the robustness of deep tabular models against various evasion attack scenarios.
</details>
<details>
<summary>摘要</summary>
现代深度学习模型在表格数据上已经实现了可接受的性能，可以在工业环境中部署。然而，这些模型的可靠性仍未得到充分探索。与计算机视觉不同，到目前为止没有一个实用协议来评估深表格模型的攻击Robustness，这主要归结于表格数据的内在特性，如分类特征、不可变性和特征关系约束。为了填补这一漏洞，我们提出了CAA，首个可效的练习攻击方法 для受限表格深度学习模型。CAA是一种循环 parameter-free攻击，将梯度和搜索攻击结合起来生成攻击示例，并且具有约束。我们利用CAA建立了深表格模型的权威 benchmark，包括银行评分、骗取和机器人攻击检测等三个Popular use case。我们的 benchmark 支持了十种威胁模型，每种威胁模型都有不同的攻击能力，并且反映了实际攻击enario。总的来说，我们的结果表明了domain knowledge、对抗训练和攻击预算对深表格模型的可靠性评估产生了重要的影响，并提供了一组建议来改善深表格模型对不同攻击enario的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-Advanced-Aerial-Mobility-–-An-End-to-end-Autonomy-Framework-for-UAVs-and-Beyond"><a href="#Autonomous-Advanced-Aerial-Mobility-–-An-End-to-end-Autonomy-Framework-for-UAVs-and-Beyond" class="headerlink" title="Autonomous Advanced Aerial Mobility – An End-to-end Autonomy Framework for UAVs and Beyond"></a>Autonomous Advanced Aerial Mobility – An End-to-end Autonomy Framework for UAVs and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04472">http://arxiv.org/abs/2311.04472</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sakshi Mishra, Praveen Palanisamy</li>
<li>for: 这篇论文的目的是提供一个权威的 perspective on the emerging field of autonomous advanced aerial mobility, 包括使用无人航空器（UAV）和电动垂直起降（eVTOL）飞机进行各种应用程序，如城市空中交通、快递和监测。</li>
<li>methods: 该论文提出了一个可扩展和可控的自主框架，包括感知、识别、规划和控制四个主要块。此外，论文还讨论了多机体队伍运行和管理的挑战和机遇，以及自主飞行系统的测试、验证和证明方面的问题。</li>
<li>results: 该论文探讨了自主高空 mobilty 领域的未来方向，并分析了MONOLITHIC 模型的优势和局限性。<details>
<summary>Abstract</summary>
Developing aerial robots that can both safely navigate and execute assigned mission without any human intervention - i.e., fully autonomous aerial mobility of passengers and goods - is the larger vision that guides the research, design, and development efforts in the aerial autonomy space. However, it is highly challenging to concurrently operationalize all types of aerial vehicles that are operating fully autonomously sharing the airspace. Full autonomy of the aerial transportation sector includes several aspects, such as design of the technology that powers the vehicles, operations of multi-agent fleets, and process of certification that meets stringent safety requirements of aviation sector. Thereby, Autonomous Advanced Aerial Mobility is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we present a comprehensive perspective on the emerging field of autonomous advanced aerial mobility, which involves the use of unmanned aerial vehicles (UAVs) and electric vertical takeoff and landing (eVTOL) aircraft for various applications, such as urban air mobility, package delivery, and surveillance. The article proposes a scalable and extensible autonomy framework consisting of four main blocks: sensing, perception, planning, and controls. Furthermore, the article discusses the challenges and opportunities in multi-agent fleet operations and management, as well as the testing, validation, and certification aspects of autonomous aerial systems. Finally, the article explores the potential of monolithic models for aerial autonomy and analyzes their advantages and limitations. The perspective aims to provide a holistic picture of the autonomous advanced aerial mobility field and its future directions.
</details>
<details>
<summary>摘要</summary>
发展可以安全地导航并完成任务无需人类干预的空中机器人，即全自动空中 mobilit y 的既客货运输 - 是研究、设计和开发团队的大vision。然而，同时操作具有完全自动化功能的所有空中 Vehicle 共享空间是非常挑战性的。全自动化空运行业包括许多方面，如机器人技术的设计、多机器人队列的运作和遵循 strict 航空行业安全要求的证明过程。因此，自主高级空中 mobilit y 的概念仍然是混乱的，对研究人员和专业人员来说是抽象的。为了填补这个空白，我们提出了一篇全面的自主高级空中 mobilit y 领域的视角，该领域包括使用无人航空器（UAV）和电动垂直起降（eVTOL）飞机进行多种应用，如城市空中 mobilit y、快递和监测。文章提出了可扩展和可重复的自主框架，包括感知、识别、规划和控制四个主要块。此外，文章还讨论了多机器人队列的运作和管理挑战和机器人自主系统的测试、验证和证明方面的问题。最后，文章探讨了单体模型在空中自主领域的优势和局限性。该视角的目的是为自主高级空中 mobilit y 领域提供一个整体的图像，以及未来方向。
</details></li>
</ul>
<hr>
<h2 id="Solving-High-Frequency-and-Multi-Scale-PDEs-with-Gaussian-Processes"><a href="#Solving-High-Frequency-and-Multi-Scale-PDEs-with-Gaussian-Processes" class="headerlink" title="Solving High Frequency and Multi-Scale PDEs with Gaussian Processes"></a>Solving High Frequency and Multi-Scale PDEs with Gaussian Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04465">http://arxiv.org/abs/2311.04465</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikai Fang, Madison Cooley, Da Long, Shibo Li, Robert Kirby, Shandian Zhe</li>
<li>for: 用于解决高频和多尺度的 partial differential equations (PDEs) 问题，以提高物理 simulations 和科学计算的精度和效率。</li>
<li>methods: 使用 Gaussian process (GP) 框架，模型 PDE 解的力спектrum 使用 student t 混合物或 Gaussian 混合物，并通过 inverse Fourier transform 获取 covariance function。使用 Jeffreys prior 来估计混合物的权重，并使用 GP  conditional mean 来预测解和其导数，以满足边界条件和方程本身。</li>
<li>results: 通过系统性的实验，提出了一种基于 GP 的高效和可扩展的 PDE 解法，可以处理大量的 collocation points，并且不需要低级 approximations。实验结果表明，该方法可以提高解的精度和效率，并且可以处理高频和多尺度的 PDEs。<details>
<summary>Abstract</summary>
Machine learning based solvers have garnered much attention in physical simulation and scientific computing, with a prominent example, physics-informed neural networks (PINNs). However, PINNs often struggle to solve high-frequency and multi-scale PDEs, which can be due to spectral bias during neural network training. To address this problem, we resort to the Gaussian process (GP) framework. To flexibly capture the dominant frequencies, we model the power spectrum of the PDE solution with a student t mixture or Gaussian mixture. We then apply the inverse Fourier transform to obtain the covariance function (according to the Wiener-Khinchin theorem). The covariance derived from the Gaussian mixture spectrum corresponds to the known spectral mixture kernel. We are the first to discover its rationale and effectiveness for PDE solving. Next,we estimate the mixture weights in the log domain, which we show is equivalent to placing a Jeffreys prior. It automatically induces sparsity, prunes excessive frequencies, and adjusts the remaining toward the ground truth. Third, to enable efficient and scalable computation on massive collocation points, which are critical to capture high frequencies, we place the collocation points on a grid, and multiply our covariance function at each input dimension. We use the GP conditional mean to predict the solution and its derivatives so as to fit the boundary condition and the equation itself. As a result, we can derive a Kronecker product structure in the covariance matrix. We use Kronecker product properties and multilinear algebra to greatly promote computational efficiency and scalability, without any low-rank approximations. We show the advantage of our method in systematic experiments.
</details>
<details>
<summary>摘要</summary>
《机器学习基于的解决方案在物理 simulate 和科学计算中备受关注，例如物理学习神经网络（PINNs）。但是，PINNs 经常遇到高频和多尺度的 partial differential equations（PDEs）解决问题，这可能是在神经网络训练过程中的spectral bias。为了解决这个问题，我们使用 Gaussian process（GP）框架。我们模型 PDE 解的能量谱，使用学生 t 混合或 Gaussian 混合来灵活地捕捉解的主要频率。然后，我们应用 inverse Fourier transform 获得 covariance function（根据 Wiener-Khinchin 定理）。这个 covariance function 与known spectral mixture kernel相对应。我们是第一个发现其理由和效果，并且在 PDE 解决中应用。接下来，我们在循环域中估计混合Weight，我们表明这equivalent to placing a Jeffreys prior。它自动带来稀疏性，排除过度频率，并调整剩下来向真实值。三、为了efficiently和可扩展地计算大量的 collocation points，这些点 kritical 捕捉高频，我们将 collocation points 放在网格上，并将我们的 covariance function 乘以每个输入维度。我们使用 GP conditional mean 预测解和其Derivatives，以适应边界条件和方程本身。因此，我们可以 deriv a Kronecker product structure 在 covariance matrix 中。我们使用 Kronecker product properties 和多线性代数，无需低级 Approximations，提高了计算效率和可扩展性。我们在系统性实验中展示了我们的方法的优势。
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Spatial-Transformer-for-Massive-Point-Samples-in-Continuous-Space"><a href="#A-Hierarchical-Spatial-Transformer-for-Massive-Point-Samples-in-Continuous-Space" class="headerlink" title="A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space"></a>A Hierarchical Spatial Transformer for Massive Point Samples in Continuous Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04434">http://arxiv.org/abs/2311.04434</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/spatialdatasciencegroup/hst">https://github.com/spatialdatasciencegroup/hst</a></li>
<li>paper_authors: Wenchong He, Zhe Jiang, Tingsong Xiao, Zelin Xu, Shigang Chen, Ronald Fick, Miles Medina, Christine Angelini</li>
<li>for: This paper proposes a novel transformer model for massive point samples in continuous space, addressing challenges such as implicit long-range and multi-scale dependency, non-uniform point distribution, and high computational costs.</li>
<li>methods: The proposed hierarchical spatial transformer model includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation, as well as an uncertainty quantification branch to estimate prediction confidence.</li>
<li>results: The proposed method outperforms multiple baselines in prediction accuracy and can scale up to one million points on one NVIDIA A100 GPU, as demonstrated through extensive experiments on both real-world and synthetic datasets.<details>
<summary>Abstract</summary>
Transformers are widely used deep learning architectures. Existing transformers are mostly designed for sequences (texts or time series), images or videos, and graphs. This paper proposes a novel transformer model for massive (up to a million) point samples in continuous space. Such data are ubiquitous in environment sciences (e.g., sensor observations), numerical simulations (e.g., particle-laden flow, astrophysics), and location-based services (e.g., POIs and trajectories). However, designing a transformer for massive spatial points is non-trivial due to several challenges, including implicit long-range and multi-scale dependency on irregular points in continuous space, a non-uniform point distribution, the potential high computational costs of calculating all-pair attention across massive points, and the risks of over-confident predictions due to varying point density. To address these challenges, we propose a new hierarchical spatial transformer model, which includes multi-resolution representation learning within a quad-tree hierarchy and efficient spatial attention via coarse approximation. We also design an uncertainty quantification branch to estimate prediction confidence related to input feature noise and point sparsity. We provide a theoretical analysis of computational time complexity and memory costs. Extensive experiments on both real-world and synthetic datasets show that our method outperforms multiple baselines in prediction accuracy and our model can scale up to one million points on one NVIDIA A100 GPU. The code is available at \url{https://github.com/spatialdatasciencegroup/HST}.
</details>
<details>
<summary>摘要</summary>
transformers 是深度学习架构的广泛使用。现有的 transformers 主要是 для文本、图像或视频，以及图。这篇论文提出了一种新的 transformer 模型，用于处理大量（达到一百万）的连续空间点样本。这些数据在环境科学（例如感知器观察）、数值仿真（例如含有粒子的流体和天文物理）以及地理位置服务（例如 POI 和轨迹）中都很常见。然而，为大量的空间点设计 transformer 是非常困难的，因为存在许多挑战，包括不明确的长距离和多尺度依赖，不均匀的点分布，计算所有对对关注的计算成本可能很高，以及输入特征噪声和点稀缺性可能导致不确定的预测。为解决这些挑战，我们提出了一种新的层次空间 transformer 模型，包括在 Quad-tree 层次结构中进行多尺度表示学习和高效的空间关注。我们还设计了一个 uncertainty 评估分支，用于评估输入特征噪声和点稀缺性导致的预测信度。我们还提供了计算时间复杂度和内存成本的理论分析。在实际实验中，我们的方法在多个实际和 sintetic 数据集上表现出色，并且可以在一个 NVIDIA A100 GPU 上处理一百万点。代码可以在 <https://github.com/spatialdatasciencegroup/HST> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Emerging-AI-ML-Accelerators-IPU-RDU-and-NVIDIA-AMD-GPUs"><a href="#Evaluating-Emerging-AI-ML-Accelerators-IPU-RDU-and-NVIDIA-AMD-GPUs" class="headerlink" title="Evaluating Emerging AI&#x2F;ML Accelerators: IPU, RDU, and NVIDIA&#x2F;AMD GPUs"></a>Evaluating Emerging AI&#x2F;ML Accelerators: IPU, RDU, and NVIDIA&#x2F;AMD GPUs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04417">http://arxiv.org/abs/2311.04417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongwu Peng, Caiwen Ding, Tong Geng, Sutanay Choudhury, Kevin Barker, Ang Li</li>
<li>for: 这个研究旨在评估和比较现有的商业人工智能&#x2F;机器学习加速器，了解它们的硬件和软件设计特点，以及它们在常见的深度神经网络操作和其他人工智能&#x2F;机器学习任务中的表现。</li>
<li>methods: 本研究使用了一系列的单元测试，评估了不同的商业加速器在深度神经网络操作和其他人工智能&#x2F;机器学习任务中的表现。</li>
<li>results: 研究发现，使用数据流Architecture的加速器在深度神经网络操作中表现出色，并且在其他人工智能&#x2F;机器学习任务中也表现了优秀的表现。<details>
<summary>Abstract</summary>
The relentless advancement of artificial intelligence (AI) and machine learning (ML) applications necessitates the development of specialized hardware accelerators capable of handling the increasing complexity and computational demands. Traditional computing architectures, based on the von Neumann model, are being outstripped by the requirements of contemporary AI/ML algorithms, leading to a surge in the creation of accelerators like the Graphcore Intelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit (RDU), and enhanced GPU platforms. These hardware accelerators are characterized by their innovative data-flow architectures and other design optimizations that promise to deliver superior performance and energy efficiency for AI/ML tasks.   This research provides a preliminary evaluation and comparison of these commercial AI/ML accelerators, delving into their hardware and software design features to discern their strengths and unique capabilities. By conducting a series of benchmark evaluations on common DNN operators and other AI/ML workloads, we aim to illuminate the advantages of data-flow architectures over conventional processor designs and offer insights into the performance trade-offs of each platform. The findings from our study will serve as a valuable reference for the design and performance expectations of research prototypes, thereby facilitating the development of next-generation hardware accelerators tailored for the ever-evolving landscape of AI/ML applications. Through this analysis, we aspire to contribute to the broader understanding of current accelerator technologies and to provide guidance for future innovations in the field.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）和机器学习（ML）应用的不断发展需要特化的硬件加速器来处理不断增长的复杂性和计算需求。传统的计算架构，基于 von Neumann 模型，由于当今 AI/ML 算法的要求而落后，导致加速器的出现，如 Graphcore 智能处理单元（IPU）、Sambanova 可重新配置数据流单元（RDU）以及增强的 GPU 平台。这些硬件加速器具有创新的数据流架构和其他设计优化，承诺提供更高的性能和能效率 для AI/ML 任务。本研究提供了这些商业 AI/ML 加速器的初步评估和比较，探讨了他们的硬件和软件设计特点，以了解它们的优势和特殊能力。通过对常见深度神经网络（DNN）操作和其他 AI/ML 任务的benchmark评估，我们希望探明数据流架构在传统处理器设计方面的优势，并提供每台平台的性能交易OFF。研究结果将成为未来硬件加速器设计和性能预期的重要参考，以便为AI/ML应用场景不断演化的硬件加速器设计下一代。通过这种分析，我们 aspire to 贡献到当前加速器技术的更广泛理解，并为未来的创新提供指导。
</details></li>
</ul>
<hr>
<h2 id="Likelihood-Ratio-Confidence-Sets-for-Sequential-Decision-Making"><a href="#Likelihood-Ratio-Confidence-Sets-for-Sequential-Decision-Making" class="headerlink" title="Likelihood Ratio Confidence Sets for Sequential Decision Making"></a>Likelihood Ratio Confidence Sets for Sequential Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04402">http://arxiv.org/abs/2311.04402</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Emmenegger, Mojmír Mutný, Andreas Krause</li>
<li>for: 这篇论文是为了提供一种可证明、适应uncertainty estimate的方法，用于Sequential decision-making算法。</li>
<li>methods: 该方法基于 likelihood-based inference principle，使用 likelihood ratio 构建 any-time 有效的 confidence sequences，不需要特殊的处理在具体应用场景中。</li>
<li>results: 该方法适用于具有准确specified likelihood的问题，其结果始终保持预定的覆盖率，并且可以在model-agnostic manner中进行any-time有效的 confidence estimation。<details>
<summary>Abstract</summary>
Certifiable, adaptive uncertainty estimates for unknown quantities are an essential ingredient of sequential decision-making algorithms. Standard approaches rely on problem-dependent concentration results and are limited to a specific combination of parameterization, noise family, and estimator. In this paper, we revisit the likelihood-based inference principle and propose to use likelihood ratios to construct any-time valid confidence sequences without requiring specialized treatment in each application scenario. Our method is especially suitable for problems with well-specified likelihoods, and the resulting sets always maintain the prescribed coverage in a model-agnostic manner. The size of the sets depends on a choice of estimator sequence in the likelihood ratio. We discuss how to provably choose the best sequence of estimators and shed light on connections to online convex optimization with algorithms such as Follow-the-Regularized-Leader. To counteract the initially large bias of the estimators, we propose a reweighting scheme that also opens up deployment in non-parametric settings such as RKHS function classes. We provide a non-asymptotic analysis of the likelihood ratio confidence sets size for generalized linear models, using insights from convex duality and online learning. We showcase the practical strength of our method on generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions.
</details>
<details>
<summary>摘要</summary>
证明可靠的不确定性估计对不确定量是sequential decision-making算法的重要组件。既定方法取决于问题依赖的集中结果，而且只能在特定的参数化、噪声家族和估计器上下采取特定的方法。在这篇论文中，我们回顾了概率基于的推理原理，并提议使用likelihood比率构建任何时间有效的信心集，无需特殊对各应用场景进行处理。我们的方法特别适用于具有明确概率的问题，并且得到的集 siempre maintain the prescribed coverage in a model-agnostic manner。likelihood ratio confidence sets的大小取决于选择的估计器序列。我们讨论了如何选择最佳的估计器序列，并 shed light on connections to online convex optimization algorithms such as Follow-the-Regularized-Leader。为了减少初始偏差，我们提议了一种重weighting scheme，该方案还可以在非 Parametric setting such as RKHS function classes中应用。我们提供了非假设分析likelihood ratio confidence sets的大小 для泛化线性模型，使用了 convex duality和在线学习的 Insights。我们在 generalized linear bandit problems, survival analysis, and bandits with various additive noise distributions中示cases the practical strength of our method.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/cs.LG_2023_11_08/" data-id="clorjzlab00syf18884qpae9u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/eess.IV_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T09:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/eess.IV_2023_11_08/">eess.IV - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="An-End-Cloud-Computing-Enabled-Surveillance-Video-Transmission-System"><a href="#An-End-Cloud-Computing-Enabled-Surveillance-Video-Transmission-System" class="headerlink" title="An End-Cloud Computing Enabled Surveillance Video Transmission System"></a>An End-Cloud Computing Enabled Surveillance Video Transmission System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04685">http://arxiv.org/abs/2311.04685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingxi Yang, Zhijin Qin, Liting Wang, Xiaoming Tao, Fang Cui, Hengjiang Wang</li>
<li>for:  solves the problem of high data volume in video surveillance transmission</li>
<li>methods:  uses end-cloud computing and redundant frame elimination, followed by key-frame assisted video super-resolution</li>
<li>results:  effectively reduces data volume and outperforms existing video super-resolution models in terms of PSNR and SSIM<details>
<summary>Abstract</summary>
The enormous data volume of video poses a significant burden on the network. Particularly, transferring high-definition surveillance videos to the cloud consumes a significant amount of spectrum resources. To address these issues, we propose a surveillance video transmission system enabled by end-cloud computing. Specifically, the cameras actively down-sample the original video and then a redundant frame elimination module is employed to further reduce the data volume of surveillance videos. Then we develop a key-frame assisted video super-resolution model to reconstruct the high-quality video at the cloud side. Moreover, we propose a strategy of extracting key frames from source videos for better reconstruction performance by utilizing the peak signal-to-noise ratio (PSNR) of adjacent frames to measure the propagation distance of key frame information. Simulation results show that the developed system can effectively reduce the data volume by the end-cloud collaboration and outperforms existing video super-resolution models significantly in terms of PSNR and structural similarity index (SSIM).
</details>
<details>
<summary>摘要</summary>
“对于类比较大的视频数据，网络传输所受的负担相当大。尤其是将高清准视频传输到云端，占用了大量的频谱资源。为解决这些问题，我们提出了一个基于端云计算的视频传输系统。具体来说，相机会主动降解原始视频，然后使用红ndeframe净化模块进一步压缩视频数据。接着，我们开发了一个基于关键帧的显示视频超解析模型，以云端端复原高质量视频。此外，我们提出了一种利用邻近帧的PSNR值来测量关键帧信息传播距离的策略。实验结果显示，我们的系统可以通过端云合作对数据进行压缩，并与现有的视频超解析模型相比具有较高的PSNR和结构相似指数（SSIM）。”
</details></li>
</ul>
<hr>
<h2 id="A-human-brain-atlas-of-chi-separation-for-normative-iron-and-myelin-distributions"><a href="#A-human-brain-atlas-of-chi-separation-for-normative-iron-and-myelin-distributions" class="headerlink" title="A human brain atlas of chi-separation for normative iron and myelin distributions"></a>A human brain atlas of chi-separation for normative iron and myelin distributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04468">http://arxiv.org/abs/2311.04468</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyeongseon Min, Beomseok Sohn, Woo Jung Kim, Chae Jung Park, Soohwa Song, Dong Hoon Shin, Kyung Won Chang, Na-Young Shin, Minjun Kim, Hyeong-Geol Shin, Phil Hyu Lee, Jongho Lee</li>
<li>for: 这个研究用于构建一个正常的chi-separation Atlason，以提供详细的脑区域与铁和质粒的分布，以及年龄相关的变化。</li>
<li>methods: 这个研究使用了一种先进的感知分离技术，可以分离 paramagnetic铁和 diamagnetic质粒，从而生成脑中铁和质粒的地图。</li>
<li>results: 这个研究 constructed a normative chi-separation atlas from 106 healthy human brains, providing detailed anatomical structures associated with the distributions of iron and myelin, and reporting susceptibility values in a number of regions of interest, as well as age-dependent changes.<details>
<summary>Abstract</summary>
Iron and myelin are primary susceptibility sources in the human brain. These substances are essential for healthy brain, and their abnormalities are often related to various neurological disorders. Recently, an advanced susceptibility mapping technique, which is referred to as chi-separation, has been proposed successfully disentangling paramagnetic iron from diamagnetic myelin, opening a new potential for generating iron map and myelin map in the brain. Utilizing this technique, this study constructs a normative chi-separation atlas from 106 healthy human brains. The resulting atlas provides detailed anatomical structures associated with the distributions of iron and myelin, clearly delineating subcortical nuclei and white matter fiber bundles. Additionally, susceptibility values in a number of regions of interest are reported along with age-dependent changes. This atlas may have direct applications such as localization of subcortical structures for deep brain stimulation or high-intensity focused ultrasound and also serve as a valuable resource for future research.
</details>
<details>
<summary>摘要</summary>
铁和脑膜是人脑健康所必需的主要抗应环境。这些物质的异常会导致各种神经疾病。最近，一种高级别抗应分离技术，即χ分离，已经成功地分离了 paramagnetic 铁和 diamagnetic 脑膜，打开了新的 potential for 生成铁图和脑膜图在脑内。使用这种技术，本研究构建了106名健康人脑chi separation atlas。结果提供了详细的 анатомиче结构与铁和脑膜的分布相关，清晰地分割潜在核心和白 matter 纤维带。此外，在一些区域兴趣点上报告了抗应值，以及年龄相关的变化。这个atlas可能有直接应用，如深Brain stimulation 或高Intensity focused ultrasound 的地点定位，并且可以作为未来研究的 ценный资源。
</details></li>
</ul>
<hr>
<h2 id="A-labeled-Clinical-MRI-dataset-of-Nigerian-brains"><a href="#A-labeled-Clinical-MRI-dataset-of-Nigerian-brains" class="headerlink" title="A labeled Clinical-MRI dataset of Nigerian brains"></a>A labeled Clinical-MRI dataset of Nigerian brains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04425">http://arxiv.org/abs/2311.04425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eberechi Wogu, Patrick Filima, Bradley Caron, Daniel Levitas, Peer Herholz, Catherine Leal, Mohammed F. Mehboob, Soichi Hayashi, Simisola Akintoye, George Ogoh, Tawe Godwin, Damian Eke, Franco Pestilli</li>
<li>For: The paper is written for the purpose of describing a magnetic resonance imaging (MRI) dataset from individuals in Nigeria, with the goal of contributing to the global neuroscience community and providing a benchmark for future studies.* Methods: The paper uses pseudonymized structural MRI (T1w, T2w, FLAIR) data of clinical quality, with data from 36 healthy control subjects, 32 individuals with age-related dementia, and 20 individuals with Parkinson’s disease.* Results: The paper provides a description of the dataset, including the demographics of the participants and the quality of the MRI data. The paper also highlights the potential of the dataset for future studies and its contribution to the global neuroscience community.Here is the information in Simplified Chinese text:* For: 这个论文是为了描述奈及利亚的 магни共振成像（MRI）数据集，以便为全球神经科学社区提供参考和贡献。* Methods: 这个论文使用假名化的结构MRI（T1w, T2w, FLAIR）数据，来自36名健康控制者、32名年龄相关 деменция 和 20名 Parkinson’s disease 患者。* Results: 这个论文描述了数据集的特点，包括参与者的人口学特征和MRI数据的质量。 论文还强调了数据集的潜在价值和未来研究的可能性。<details>
<summary>Abstract</summary>
We describe a Magnetic Resonance Imaging (MRI) dataset from individuals from the African nation of Nigeria. The dataset contains pseudonymized structural MRI (T1w, T2w, FLAIR) data of clinical quality. The dataset contains data from 36 images from healthy control subjects, 32 images from individuals diagnosed with age-related dementia and 20 from individuals with Parkinson's disease. There is currently a paucity of data from the African continent. Given the potential for Africa to contribute to the global neuroscience community, this first MRI dataset represents both an opportunity and benchmark for future studies to share data from the African continent.
</details>
<details>
<summary>摘要</summary>
我们描述一个 magnetoresonance imaging（MRI）数据集，来自非洲国家奈达利亚。该数据集包含匿名化的结构MRI（T1w、T2w、FLAIR）数据，质量非常高。该数据集包含36张健康控制 sujet的数据，32张年龄相关性衰退的个体的数据，以及20张parkinson病的个体的数据。目前在非洲大陆上没有充足的数据，这个首个MRI数据集代表了非洲大陆对全球神经科学社区的贡献的机遇和标准。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/eess.IV_2023_11_08/" data-id="clorjzlhb019mf188g28w8oz4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/08/eess.SP_2023_11_08/" class="article-date">
  <time datetime="2023-11-08T08:00:00.000Z" itemprop="datePublished">2023-11-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/08/eess.SP_2023_11_08/">eess.SP - 2023-11-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Joint-Transmit-Signal-and-Beamforming-Design-for-Integrated-Sensing-and-Power-Transfer-Systems"><a href="#Joint-Transmit-Signal-and-Beamforming-Design-for-Integrated-Sensing-and-Power-Transfer-Systems" class="headerlink" title="Joint Transmit Signal and Beamforming Design for Integrated Sensing and Power Transfer Systems"></a>Joint Transmit Signal and Beamforming Design for Integrated Sensing and Power Transfer Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04881">http://arxiv.org/abs/2311.04881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kenneth MacSporran Mayer, Nikita Shanin, Zhenlong You, Sebastian Lotter, Stefan Brückner, Martin Vossiek, Laura Cottatellucci, Robert Schober</li>
<li>for: 这个论文的目的是提出一种综合整合不同功能的系统，以更有效地利用可用资源。</li>
<li>methods: 论文提出了一种结合探测和无线能量传输（WPT）功能的约合优化方法，并采用了精度的非线性电能收集（EH）模型。</li>
<li>results: 论文通过积分搜索、半definite relaxation（SDR）和Successive Convex Approximation（SCA）等方法解决了一个非 convex 优化问题，并证明了在大 transmit 功率范围内，逐渐增长的脉冲duration 可以提高收集的平均能量。<details>
<summary>Abstract</summary>
Integrating different functionalities, conventionally implemented as dedicated systems, into a single platform allows utilising the available resources more efficiently. We consider an integrated sensing and power transfer (ISAPT) system and propose the joint optimisation of the rectangular pulse-shaped transmit signal and the beamforming design to combine sensing and wireless power transfer (WPT) functionalities efficiently. In contrast to prior works, we adopt an accurate non-linear circuit-based energy harvesting (EH) model. We formulate a non-convex optimisation problem for a general number of EH receivers and a single sensing target (ST) and solve the problem via a grid search over the pulse duration, semidefinite relaxation (SDR), and successive convex approximation (SCA). The average harvested power is shown to monotonically increase with the pulse duration when the average transmit power budget is large. We discuss the trade-off between sensing performance and power transfer of the ISAPT system. The proposed approach significantly outperforms a heuristic baseline scheme based on a linear EH model, which linearly combines energy beamforming with the beamsteering vector in the direction to the ST as its transmit strategy.
</details>
<details>
<summary>摘要</summary>
We formulate a non-convex optimization problem for a general number of EH receivers and a single sensing target (ST) and solve it using a grid search over the pulse duration, semidefinite relaxation (SDR), and successive convex approximation (SCA). Our results show that the average harvested power increases monotonically with the pulse duration when the average transmit power budget is large.We also discuss the trade-off between sensing performance and power transfer of the ISAPT system. Our approach significantly outperforms a heuristic baseline scheme based on a linear EH model, which combines energy beamforming with the beamsteering vector in the direction of the ST as its transmit strategy.
</details></li>
</ul>
<hr>
<h2 id="Electromagnetic-manifold-characterization-of-antenna-arrays"><a href="#Electromagnetic-manifold-characterization-of-antenna-arrays" class="headerlink" title="Electromagnetic manifold characterization of antenna arrays"></a>Electromagnetic manifold characterization of antenna arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04835">http://arxiv.org/abs/2311.04835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Miguel R. Castellanos, Robert W. Heath Jr</li>
<li>for: 本研究旨在提供一种基于电磁学的数组 manifold，以便更正式地模型无线通信中天线的复杂行为，包括互相干扰、近场传播和极化。</li>
<li>methods: 作者使用了一种基于 Hertzian 天线的量化方法，将天线转换为一大量的 Hertzian 天线，以便预测通过非常regular array geometry 的电场。这个模型通过点源位置、每个 Hertzian 天线的位置以及一组从电磁 simulate 获得的系数来预测电场。</li>
<li>results: 作者通过数值实验示出，提出的方法可以准确地预测电场，并且可以考虑到接收场的极化以及 радиated power density 的限制。此外，使用这个模型进行扫描优化可以实现更高的扫描优化效果，比之使用较不准确的模型。<details>
<summary>Abstract</summary>
Antenna behaviors such as mutual coupling, near-field propagation, and polarization cannot be neglected in signal and channel models for wireless communication. We present an electromagnetic-based array manifold that accounts for several complicated behaviors and can model arbitrary antenna configurations. We quantize antennas into a large number of Hertzian dipoles to develop a model for the radiated array field. The resulting abstraction provides a means to predict the electric field for general non-homogeneous array geometries through a linear model that depends on the point source location, the position of each Hertzian dipole, and a set of coefficients obtained from electromagnetic simulation. We then leverage this model to formulate a beamforming gain optimization that can be adapted to account for polarization of the receive field as well as constraints on the radiated power density. Numerical results demonstrate that the proposed method achieves accuracy that is close to that of electromagnetic simulations. By leveraging the developed array manifold for beamforming, systems can achieve higher beamforming gains compared to beamforming with less accurate models.
</details>
<details>
<summary>摘要</summary>
天线行为如共振、近场传播和极化不能被忽略在无线通信中的信号和通道模型中。我们提出一个电磁场基的阵列构造，考虑了许多复杂的行为，可以模型任意天线配置。我们将天线分解为一大量的赫兹束天线，开发了一个模型来预测散射阵列场。这个抽象提供了一个可以预测通用非等式阵列场的线性模型，这个模型取决于天线位置、每个赫兹束天线的位置以及从电磁 simulations 获得的一系列系数。我们然后利用这个模型来设计一个可以考虑极化的焦点强化的优化方法，可以根据天线配置和输出功率密度的限制进行自适应。 numerics  результалтати显示，提案的方法可以对电磁 simulations 的准确性进行很好的近似。通过利用发展的阵列构造来进行焦点强化，系统可以在传播中获得更高的焦点强化，相比之下使用较凡的模型进行焦点强化。
</details></li>
</ul>
<hr>
<h2 id="Integrated-Distributed-Semantic-Communication-and-Over-the-air-Computation-for-Cooperative-Spectrum-Sensing"><a href="#Integrated-Distributed-Semantic-Communication-and-Over-the-air-Computation-for-Cooperative-Spectrum-Sensing" class="headerlink" title="Integrated Distributed Semantic Communication and Over-the-air Computation for Cooperative Spectrum Sensing"></a>Integrated Distributed Semantic Communication and Over-the-air Computation for Cooperative Spectrum Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04791">http://arxiv.org/abs/2311.04791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Yi, Yang Cao, Xin Kang, Ying-Chang Liang</li>
<li>for: 提高第一用户（PU）探测的精度，使用多感器</li>
<li>methods: 独立语义通信（DSC）和空中计算（AirComp）结合，提高整合通信和计算的精度和可扩展性</li>
<li>results: 比 conventinal CSS方案更高的探测性能，鲁棒性能和可扩展性，并且可以适应Signal to Noise Ratio（SNR）变化<details>
<summary>Abstract</summary>
Cooperative spectrum sensing (CSS) is a promising approach to improve the detection of primary users (PUs) using multiple sensors. However, there are several challenges for existing combination methods, i.e., performance degradation and ceiling effect for hard-decision fusion (HDF), as well as significant uploading latency and non-robustness to noise in the reporting channel for soft-data fusion (SDF). To address these issues, in this paper, we propose a novel framework for CSS that integrates communication and computation, namely ICC. Specifically, distributed semantic communication (DSC) jointly optimizes multiple sensors and the fusion center to minimize the transmitted data without degrading detection performance. Moreover, over-the-air computation (AirComp) is utilized to further reduce spectrum occupation in the reporting channel, taking advantage of the characteristics of the wireless channel to enable data aggregation. Under the ICC framework, a particular system, namely ICC-CSS, is designed and implemented, which is theoretically proved to be equivalent to the optimal estimator-correlator (E-C) detector with equal gain SDF when the PU signal samples are independent and identically distributed. Extensive simulations verify the superiority of ICC-CSS compared with various conventional CSS schemes in terms of detection performance, robustness to SNR variations in both the sensing and reporting channels, as well as scalability with respect to the number of samples and sensors.
</details>
<details>
<summary>摘要</summary>
合作频率感知（CSS）是一种有前途的方法，以提高主用户（PU）的探测。然而，现有的组合方法存在一些挑战，例如性能下降和层次效应（HDF）、上传延迟和隐私泄露（SDF）。为了解决这些问题，在这篇论文中，我们提出了一种新的CSS框架，即ICC。具体来说，分布式含义通信（DSC）与汇中心一起优化多个感知器和汇中心，以最小化传输数据，而不会影响探测性能。此外，利用无线通信特点，实现了空中计算（AirComp），进一步减少报告频率道的占用率，从而实现数据汇总。在ICC框架下，我们设计了一个具体的系统，即ICC-CSS，这个系统理论上与等分质量均衡探测器（E-C）相等，当主用户信号样本独立同分布时。我们进行了广泛的 simulations，并证明ICC-CSS在探测性能、频率变化的Robustness和报告频率道的可扩展性等方面比较优于各种传统CSS方案。
</details></li>
</ul>
<hr>
<h2 id="Energy-efficient-Wireless-Image-Retrieval-for-IoT-Devices-by-Transmitting-a-TinyML-Model"><a href="#Energy-efficient-Wireless-Image-Retrieval-for-IoT-Devices-by-Transmitting-a-TinyML-Model" class="headerlink" title="Energy-efficient Wireless Image Retrieval for IoT Devices by Transmitting a TinyML Model"></a>Energy-efficient Wireless Image Retrieval for IoT Devices by Transmitting a TinyML Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04788">http://arxiv.org/abs/2311.04788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junya Shiraishi, Mathias Thorsager, Shashi Raj Pandey, Petar Popovski</li>
<li>for: 这个研究旨在减少内容不相关的数据传输，以减少edge服务器收集数据时所采用的能源浪费。</li>
<li>methods: 研究人员提议使用Tiny Machine Learning（ML）来实现内容相关的数据传输，并在IoT设备上执行ML模型。</li>
<li>results: 比较基准方案，提案方案可以实现高精度检索和高能效率，最高可以降低70%的能源成本，当存储图像数量为8或以上时。<details>
<summary>Abstract</summary>
This work considers a scenario in which an edge server collects data from Internet of Things (IoT) devices equipped with wake-up receivers. Although this procedure enables on-demand data collection, there is still energy waste if the content of the transmitted data following the wake-up is irrelevant. To mitigate this, we advocate the use of Tiny Machine Learning (ML) to enable a semantic response from the IoT devices, so they can send only semantically relevant data. Nevertheless, receiving the ML model and the ML processing at the IoT devices consumes additional energy. We consider the specific instance of image retrieval and investigate the gain brought by the proposed scheme in terms of energy efficiency, considering both the energy cost of introducing the ML model as well as that of wireless communication. The numerical evaluation shows that, compared to a baseline scheme, the proposed scheme can realize both high retrieval accuracy and high energy efficiency, which reaches up to 70% energy reduction when the number of stored images is equal to or larger than 8.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Superimposed-Chirp-Waveforms-for-SWIPT-with-Diplexer-based-Integrated-Receivers"><a href="#Superimposed-Chirp-Waveforms-for-SWIPT-with-Diplexer-based-Integrated-Receivers" class="headerlink" title="Superimposed Chirp Waveforms for SWIPT with Diplexer-based Integrated Receivers"></a>Superimposed Chirp Waveforms for SWIPT with Diplexer-based Integrated Receivers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04776">http://arxiv.org/abs/2311.04776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Roy, Constantinos Psomas, Ioannis Krikidis</li>
<li>For: 这个论文旨在探讨同时进行无线信息和能量传输（SWIPT）应用中的超позицион振荡波干。通过振荡波干的特点，我们可以同时传输同样多个振荡波干，并且在不同的频率带中进行选择。这使得我们可以利用晶体电池的非线性和频率多样性来实现更高的能量吸收率。* Methods: 该论文提出了一种基于振荡波干和频率选择的传输方案，并且考虑了用户装备了基于抽象器的集成接收器（DIR）。这种接收器可以同时提取无线电功率和解码信息，而无需将信号分解。* Results: 通过分析和数值计算结果，论文表明，在考虑到的系统设置下，使用超позицион振荡波干和频率选择可以提高SWIPT中平均收集的能量性能表现，提高最小水平的能量收集，并将能量传输范围扩展到更广泛的频率范围。此外，论文还表明，在SWIPT中包括DIR接收器可以将能量传输范围扩展。<details>
<summary>Abstract</summary>
In this paper, we present the superposition of chirp waveforms for simultaneous wireless information and power transfer (SWIPT) applications. Exploiting the chirp waveform characteristics enables us to superimpose multiple chirps, thereby allowing transmission of the same number of waveforms over less bandwidth. This enables us to perform subband selection when operating over set of orthogonal subbands. Furthermore, we consider a user equipped with a diplexer-based integrated receiver (DIR), which enables to extract radio frequency power and decode information from the same signal without splitting. Thereby, incorporating chirp superposition and subband selection, a transmission scheme is proposed to exploit both the diode's nonlinearity and frequency diversity. We derive novel closed-form analytical expressions of the average harvested energy (HE) via transmission of superimposed chirp over selected subbands based on tools from order statistics. We also analyze the downlink information rate achieved at the user. Through our analytical and numerical results, for the considered system setup, we show that superimposed chirp-based SWIPT provides an improvement of 30$\%$ in average HE performance as compared to multisine waveforms consisting of a set of fixed-frequency cosine signals, improves the minimum level of HE in a multiuser network, and extends the operating range of energy transfer as compared to fixed-frequency waveforms. Furthermore, we illustrate that the inclusion of DIR at the receiver for SWIPT enlarges the energy-information transfer region when compared to the widely considered power splitting receiver.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了同时无线信息和能量传输（SWIPT）应用中的超позицион抽波形。利用抽波形特点，我们可以同时发送多个抽波形，从而在具有相同带宽的情况下传输同样多个抽波形。这使得可以进行子带选择，从而在多个orthogonal子带上进行传输。此外，我们考虑了一个装备了混合接收器（DIR）的用户，可以通过同一个信号来提取无线电力和解码信息。因此，通过抽波形超позиición和子带选择，我们提出了利用晶体强度和频率多样性来实现的一种传输方案。我们使用了排序工具来 derivate novel closed-form分析表达式，以计算在超позиición的抽波形上传输的平均收集能量（HE）的表达式。我们还分析了下载信息率在用户端的表现。通过我们的分析和数值结果，我们发现在考虑的系统设置下，使用超позиición抽波形进行SWIPT可以提高平均HE性能的提升30%，提高多用户网络中的最低水平HE，并扩展能量传输的运行范围。此外，我们还发现在SWIPT中包括DIR接收器可以在能量传输范围内扩展信息传输范围。
</details></li>
</ul>
<hr>
<h2 id="Discerning-and-Enhancing-the-Weighted-Sum-Rate-Maximization-Algorithms-in-Communications"><a href="#Discerning-and-Enhancing-the-Weighted-Sum-Rate-Maximization-Algorithms-in-Communications" class="headerlink" title="Discerning and Enhancing the Weighted Sum-Rate Maximization Algorithms in Communications"></a>Discerning and Enhancing the Weighted Sum-Rate Maximization Algorithms in Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04546">http://arxiv.org/abs/2311.04546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zepeng Zhang, Ziping Zhao, Kaiming Shen, Daniel P. Palomar, Wei Yu</li>
<li>for: 本文研究了三种优化方法来提高权重总比率（WSR），以确保趋向于站点点的极值：两种块协调升（BCA）算法，即Weighted Sum-Minimum Mean-Square Error（WMMSE）和WSR最大化via Fractional Programming（WSR-FP），以及一种尺度最大化（MM）算法，WSR最大化via MM（WSR-MM）。</li>
<li>methods: 本文的贡献有三个方面：首先，我们明确了WMMSE、WSR-FP和WSR-MM之间的直接关系，尽管在文献中广泛使用，却缺乏全面的比较研究。我们通过探索BCA和MM算法框架之间的直接关系，揭示了WMMSE和WSR-FP的等价转换技术，以及WSR-MM中的代表函数。第二，我们提出了一种新算法，WSR-MM+，具有选择代表函数的灵活性。通过避免现有算法中的重复矩阵反转，WSR-MM+在每次迭代中减少计算负担，加速收敛。第三，我们将WSR-MM+重新定义为BCA框架中的一种等价转换，从而引入了一种新的代表函数，带来了一种新的WSR-FP+算法。我们进一步证明了WSR-MM+可以被视为基本的梯度 проекction 方法。这种视角带来了对其计算复杂性的更深刻理解。</li>
<li>results: 数值实验证明了WMMSE、WSR-FP和WSR-MM之间的直接关系，以及WSR-MM+和WSR-FP+算法的有效性。<details>
<summary>Abstract</summary>
Weighted sum-rate (WSR) maximization plays a critical role in communication system design. This paper examines three optimization methods for WSR maximization, which ensure convergence to stationary points: two block coordinate ascent (BCA) algorithms, namely, weighted sum-minimum mean-square error (WMMSE) and WSR maximization via fractional programming (WSR-FP), along with a minorization-maximization (MM) algorithm, WSR maximization via MM (WSR-MM). Our contributions are threefold. Firstly, we delineate the exact relationships among WMMSE, WSR-FP, and WSR-MM, which, despite their extensive use in the literature, lack a comprehensive comparative study. By probing the theoretical underpinnings linking the BCA and MM algorithmic frameworks, we reveal the direct correlations between the equivalent transformation techniques, essential to the development of WMMSE and WSR-FP, and the surrogate functions pivotal to WSR-MM. Secondly, we propose a novel algorithm, WSR-MM+, harnessing the flexibility of selecting surrogate functions in MM framework. By circumventing the repeated matrix inversions in the search for optimal Lagrange multipliers in existing algorithms, WSR-MM+ significantly reduces the computational load per iteration and accelerates convergence. Thirdly, we reconceptualize WSR-MM+ within the BCA framework, introducing a new equivalent transform, which gives rise to an enhanced version of WSR-FP, named as WSR-FP+. We further demonstrate that WSR-MM+ can be construed as the basic gradient projection method. This perspective yields a deeper understanding into its computational intricacies. Numerical simulations corroborate the connections between WMMSE, WSR-FP, and WSR-MM and confirm the efficacy of the proposed WSR-MM+ and WSR-FP+ algorithms.
</details>
<details>
<summary>摘要</summary>
优质积分最大化（WSR）在通信系统设计中扮演着关键的角色。本文研究了三种优化方法来实现WSR最大化，它们都确保了趋向于站点点的均衡点：块卷升（BCA）算法Weighted Sum-Minimum Mean-Square Error（WMMSE）和WSR最大化via分数编程（WSR-FP），以及小量最大化（MM）算法WSR最大化via MM（WSR-MM）。我们的贡献有三个方面：首先，我们明确了WMMSE、WSR-FP和WSR-MM之间的正确关系，尽管在文献中广泛使用，但它们从未得到了全面的比较研究。我们通过探究BCA和MM算法框架之间的理论基础，揭示了WMMSE和WSR-FP之间的直接关系，以及WSR-MM中的代表函数的重要性。第二，我们提出了一个新的算法WSR-MM+，可以在MM框架中选择不同的代表函数。通过缺省缺省的矩阵归一化，WSR-MM+可以大幅减少每趟计算负担，提高速度。第三，我们将WSR-MM+转换为BCA框架中的一种相等转换，从而得到了一种新的WSR-FP+算法。我们还证明了WSR-MM+可以被视为基本的梯度投影方法。这种视角带来了对其计算复杂性的更深入的理解。数值实验证明了WSR-MM、WSR-FP和WMMSE之间的联系，并证明了我们提出的WSR-MM+和WSR-FP+算法的效果。
</details></li>
</ul>
<hr>
<h2 id="Cross-Domain-Waveform-Design-for-6G-Integrated-Sensing-and-Communication"><a href="#Cross-Domain-Waveform-Design-for-6G-Integrated-Sensing-and-Communication" class="headerlink" title="Cross-Domain Waveform Design for 6G Integrated Sensing and Communication"></a>Cross-Domain Waveform Design for 6G Integrated Sensing and Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04483">http://arxiv.org/abs/2311.04483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Zhang, Tianqi Mao, Ruiqi Liu, Zhu Han, Octavia A. Dobre, Sheng Chen, Zhaocheng Wang</li>
<li>for: 本文旨在提出一种基于OFDM的 интегра的感知通信（ISAC）波形优化策略，以最大化数据传输率和感知质量。</li>
<li>methods: 本文提出了两种跨频域、时间、功率和延迟-Doppler频域的波形优化策略，分别根据通信和感知的需求进行设计。</li>
<li>results: 数值结果表明，提出的通信中心和感知中心波形设计方法具有更高的数据传输率和感知质量，是适用于ISAC应用场景的优秀选择。<details>
<summary>Abstract</summary>
Orthogonal frequency division multiplexing (OFDM) is one of the representative integrated sensing and communication (ISAC) waveforms, where sensing and communications tend to be assigned with different resource elements (REs) due to their diverse design requirements. This motivates optimization of resource allocation/waveform design across time, frequency, power and delay-Doppler domains. Therefore, this article proposes two cross-domain waveform optimization strategies for OFDM-based ISAC systems, following communication-centric and sensing-centric criteria, respectively. For the communication-centric design, to maximize the achievable data rate, a fraction of REs are optimally allocated for communications according to prior knowledge of the communication channel. The remaining REs are then employed for sensing, where the sidelobe level and peak to average power ratio are suppressed by optimizing its power-frequency and phase-frequency characteristics. For the sensing-centric design, a `locally' perfect auto-correlation property is ensured by adjusting the unit cells of the ambiguity function within its region of interest (RoI). Afterwards, the irrelevant cells beyond RoI, which can readily determine the sensing power allocation, are optimized with the communication power allocation to enhance the achievable data rate. Numerical results demonstrate the superiority of the proposed communication-centric and sensing-centric waveform designs for ISAC applications.
</details>
<details>
<summary>摘要</summary>
orthogonal frequency division multiplexing (OFDM) 是一种代表性的集成感知通信 (ISAC) 波形，其中感知和通信通常会被分配到不同的资源元素 (RE) due to their diverse design requirements. 这种情况驱动了资源分配/波形设计的时空频率功率延迟-Doppler 领域的优化。因此，这篇文章提出了两种跨领域波形优化策略 для OFDM-based ISAC 系统，按照通信中心和感知中心的标准来进行设计。为了最大化可 achievable 数据率，文章提出的通信中心设计方法是，将一部分 RE 分配给通信，根据先前知道的通信频率通道进行优化。剩下的 RE 然后用于感知，其中边缘强度和峰峰辐射比被优化，以 suppress 其时空频率和相位频率特征。为了感知中心设计方法，文章提出了一种在其Region of Interest (RoI) 中确保 "本地" 完美自相关性的方法，通过调整 ambiguity 函数的单元维度内的unit cells。然后，RoI 外的无关维度可以快速确定感知功率分配，并与通信功率分配进行优化，以提高可 achievable 数据率。文章的数值结果表明，提出的 communication-centric 和 sensing-centric 波形设计方法对 ISAC 应用场景具有显著优势。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/08/eess.SP_2023_11_08/" data-id="clorjzlj101dgf188d095hwfk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.SD_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T15:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.SD_2023_11_07/">cs.SD - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Soundbay-Deep-Learning-Framework-for-Marine-Mammals-and-Bioacoustic-Research"><a href="#Soundbay-Deep-Learning-Framework-for-Marine-Mammals-and-Bioacoustic-Research" class="headerlink" title="Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic Research"></a>Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04343">http://arxiv.org/abs/2311.04343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noam Bressler, Michael Faran, Amit Galor, Michael Moshe Michelashvili, Tomer Nachshon, Noa Weiss</li>
<li>for: 该论文是为了提供一个开源的Python框架，帮助生物声学和机器学习研究人员实现和利用深度学习算法来分析生物声音。</li>
<li>methods: 该框架使用深度学习算法进行声音分析，并提供了一个简单易用的平台，可以轻松地应用现有模型或创建新模型。</li>
<li>results: 该研究通过提供了多个数据集上的 cetacean 叫声检测 benchmark，以便比较不同的深度学习算法的性能。<details>
<summary>Abstract</summary>
This paper presents Soundbay, an open-source Python framework that allows bio-acoustics and machine learning researchers to implement and utilize deep learning-based algorithms for acoustic audio analysis. Soundbay provides an easy and intuitive platform for applying existing models on one's data or creating new models effortlessly. One of the main advantages of the framework is the capability to compare baselines on different benchmarks, a crucial part of emerging research and development related to the usage of deep-learning algorithms for animal call analysis. We demonstrate this by providing a benchmark for cetacean call detection on multiple datasets. The framework is publicly accessible via https://github.com/deep-voice/soundbay
</details>
<details>
<summary>摘要</summary>
这份论文介绍了Soundbay，一个开源的Python框架，它使得生物声学和机器学习研究人员可以使用深度学习算法进行声音数据分析。Soundbay提供了一个简单易用的平台，可以方便地应用现有的模型或创建新的模型。其中一个主要优势是能够比较基准值在不同的benchmark上，这对于深度学习算法在动物叫声分析领域的新研究和开发是非常重要的。我们通过提供了 cetacean 叫声检测的多个数据集 benchmark。框架可以通过https://github.com/deep-voice/soundbay进行公共访问。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.SD_2023_11_07/" data-id="clorjzld800zjf188h2t90z58" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/eess.AS_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T14:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/eess.AS_2023_11_07/">eess.AS - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Fine-tuning-convergence-model-in-Bengali-speech-recognition"><a href="#Fine-tuning-convergence-model-in-Bengali-speech-recognition" class="headerlink" title="Fine-tuning convergence model in Bengali speech recognition"></a>Fine-tuning convergence model in Bengali speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04122">http://arxiv.org/abs/2311.04122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Ruiying, Shen Meng</li>
<li>for: 提高自动语音识别模型的精度，特别是对于孟加拉语的识别。</li>
<li>methods: 利用wave2vec 2.0预训练模型进行微调，调整学习率和排除参数，并尝试将训练集和验证集合并使用。</li>
<li>results: 在测试集上实现了语音识别模型的显著改进，WER从0.508降至0.437，并在整合训练集和验证集后达到了0.436的最佳性能。<details>
<summary>Abstract</summary>
Research on speech recognition has attracted considerable interest due to the difficult task of segmenting uninterrupted speech. Among various languages, Bengali features distinct rhythmic patterns and tones, making it particularly difficult to recognize and lacking an efficient commercial recognition method. In order to improve the automatic speech recognition model for Bengali, our team has chosen to utilize the wave2vec 2.0 pre-trained model, which has undergone convergence for fine-tuning. Regarding Word Error Rate (WER), the learning rate and dropout parameters were fine-tuned, and after the model training was stable, attempts were made to enlarge the training set ratio, which improved the model's performance. Consequently, there was a notable enhancement in the WER from 0.508 to 0.437 on the test set of the publicly listed official dataset. Afterwards, the training and validation sets were merged, creating a comprehensive dataset that was used as the training set, achieving a remarkable WER of 0.436.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:研究对话识别吸引了较大的关注，主要是因为无间断的语音分 segmentation 是一项具有挑战性的任务。 Among various languages, Bengali 有 distinct rhythmic patterns 和 tones，使其识别特别困难，并且缺乏有效的商业识别方法。为了改进 automatic speech recognition 模型 для Bengali, our team 选择了使用 wave2vec 2.0 预训练模型，并进行了 fine-tuning。关于 Word Error Rate (WER), the learning rate 和 dropout 参数进行了细化调整，并在模型训练稳定后，尝试将训练集比例放大，从而提高模型的性能。结果显示，在公共列表的官方数据集测试集上，WER 从 0.508 下降到 0.437。然后，训练集和验证集合并，创建了一个全面的训练集，使用该训练集，实现了 Remarkable WER 的 0.436。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/eess.AS_2023_11_07/" data-id="clorjzlej012zf1881e8s48r0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.CV_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T13:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.CV_2023_11_07/">cs.CV - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="3DiffTection-3D-Object-Detection-with-Geometry-Aware-Diffusion-Features"><a href="#3DiffTection-3D-Object-Detection-with-Geometry-Aware-Diffusion-Features" class="headerlink" title="3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features"></a>3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04391">http://arxiv.org/abs/2311.04391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenfeng Xu, Huan Ling, Sanja Fidler, Or Litany</li>
<li>for: 3D object detection from single images</li>
<li>methods: uses a 3D-aware diffusion model with two specialized tuning strategies (geometric and semantic) and a novel epipolar warp operator for novel view synthesis</li>
<li>results: obtains 3D-aware features that excel in identifying cross-view point correspondences, substantially surpassing previous benchmarks (e.g., Cube-RCNN) with an improvement of 9.43% in AP3D on the Omni3D-ARkitscene dataset, and showcases robust data efficiency and generalization to cross-domain data.Here is the text in Simplified Chinese:</li>
<li>for: 用于单图像中的3D对象检测</li>
<li>methods: 使用3D感知的扩散模型，并使用两种特циали化的调整策略（几何和 semantics）和一种新的规则投影算子 для新视图创建</li>
<li>results: 获得了适应3D检测的3D感知特征，在跨视点对应点检测方面表现出色，比前一代标准（如Cube-RCNN）提高9.43%的AP3D值（在Omni3D-ARkitscene数据集上），并展现出了robust的数据效率和跨频谱数据的通用性。<details>
<summary>Abstract</summary>
We present 3DiffTection, a state-of-the-art method for 3D object detection from single images, leveraging features from a 3D-aware diffusion model. Annotating large-scale image data for 3D detection is resource-intensive and time-consuming. Recently, pretrained large image diffusion models have become prominent as effective feature extractors for 2D perception tasks. However, these features are initially trained on paired text and image data, which are not optimized for 3D tasks, and often exhibit a domain gap when applied to the target data. Our approach bridges these gaps through two specialized tuning strategies: geometric and semantic. For geometric tuning, we fine-tune a diffusion model to perform novel view synthesis conditioned on a single image, by introducing a novel epipolar warp operator. This task meets two essential criteria: the necessity for 3D awareness and reliance solely on posed image data, which are readily available (e.g., from videos) and does not require manual annotation. For semantic refinement, we further train the model on target data with detection supervision. Both tuning phases employ ControlNet to preserve the integrity of the original feature capabilities. In the final step, we harness these enhanced capabilities to conduct a test-time prediction ensemble across multiple virtual viewpoints. Through our methodology, we obtain 3D-aware features that are tailored for 3D detection and excel in identifying cross-view point correspondences. Consequently, our model emerges as a powerful 3D detector, substantially surpassing previous benchmarks, e.g., Cube-RCNN, a precedent in single-view 3D detection by 9.43\% in AP3D on the Omni3D-ARkitscene dataset. Furthermore, 3DiffTection showcases robust data efficiency and generalization to cross-domain data.
</details>
<details>
<summary>摘要</summary>
我们介绍3DiffTection，一种基于单张图像的state-of-the-art方法 для3D对象检测。我们利用了3D意识扩散模型中的特征。为了检测3D对象，手动标注大规模图像数据是费时费力的。最近，预训练的大图扩散模型在2D识别任务中表现出了remarkable的效果，但这些特征是通过paired文本和图像数据进行预训练的，这些特征通常会在目标数据上存在域 gap。我们的方法通过两种特殊的调整策略来bridges这些差异：几何调整和semantic调整。为了几何调整，我们在单张图像 Conditioned on novel epipolar warp operator进行新视图synthesis，这个任务满足了两个重要的条件：需要3D意识和仅仅基于提供的posed图像数据进行训练，不需要手动标注。为了semantic调整，我们进一步在目标数据上训练模型，使其具有检测Supervision。两个调整阶段都使用ControlNet保持原始特征的完整性。在最后一步，我们利用这些加强的特征进行多个虚拟视点的测试预测 ensemble。通过我们的方法，我们获得了适应3D检测的3D意识特征，可以准确地确定交叉视点对应关系。因此，我们的模型在Omni3D-ARkitscene dataset上的AP3D指标上表现出了9.43%的提升，胜过了先前的Benchmark，如Cube-RCNN。此外，3DiffTection还展示了robust数据效率和适用于不同频谱数据的泛化性。
</details></li>
</ul>
<hr>
<h2 id="Basis-restricted-elastic-shape-analysis-on-the-space-of-unregistered-surfaces"><a href="#Basis-restricted-elastic-shape-analysis-on-the-space-of-unregistered-surfaces" class="headerlink" title="Basis restricted elastic shape analysis on the space of unregistered surfaces"></a>Basis restricted elastic shape analysis on the space of unregistered surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04382">http://arxiv.org/abs/2311.04382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emmanuel Hartman, Emery Pierson, Martin Bauer, Mohamed Daoudi, Nicolas Charon</li>
<li>for: 这个论文是为了提出一种新的数学和数值方法来进行表面分析，基于泛函空间上的弹性里曼米特特性。</li>
<li>methods: 这种方法是通过限制允许的变换空间为先导的finite维基准抽象场的估计，从而将表面空间简化为一个finite维Latent空间。</li>
<li>results: 这种方法可以有效地实现一些基于表面网格的任务，如Shape注册、Shape interpolate、动作传递和随机 pose生成，并且在人体形态和姿态数据上进行了验证，并与现有方法进行了比较，得到了更好的性能。<details>
<summary>Abstract</summary>
This paper introduces a new mathematical and numerical framework for surface analysis derived from the general setting of elastic Riemannian metrics on shape spaces. Traditionally, those metrics are defined over the infinite dimensional manifold of immersed surfaces and satisfy specific invariance properties enabling the comparison of surfaces modulo shape preserving transformations such as reparametrizations. The specificity of the approach we develop is to restrict the space of allowable transformations to predefined finite dimensional bases of deformation fields. These are estimated in a data-driven way so as to emulate specific types of surface transformations observed in a training set. The use of such bases allows to simplify the representation of the corresponding shape space to a finite dimensional latent space. However, in sharp contrast with methods involving e.g. mesh autoencoders, the latent space is here equipped with a non-Euclidean Riemannian metric precisely inherited from the family of aforementioned elastic metrics. We demonstrate how this basis restricted model can be then effectively implemented to perform a variety of tasks on surface meshes which, importantly, does not assume these to be pre-registered (i.e. with given point correspondences) or to even have a consistent mesh structure. We specifically validate our approach on human body shape and pose data as well as human face scans, and show how it generally outperforms state-of-the-art methods on problems such as shape registration, interpolation, motion transfer or random pose generation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Deep-Learning-Approach-to-Video-Anomaly-Detection-using-Convolutional-Autoencoders"><a href="#A-Deep-Learning-Approach-to-Video-Anomaly-Detection-using-Convolutional-Autoencoders" class="headerlink" title="A Deep Learning Approach to Video Anomaly Detection using Convolutional Autoencoders"></a>A Deep Learning Approach to Video Anomaly Detection using Convolutional Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04351">http://arxiv.org/abs/2311.04351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gopikrishna Pavuluri, Gayathri Annem</li>
<li>for: 这个研究旨在提出一种基于深度学习的视频异常检测方法，使用卷积自适应Encoder和解码神经网络对UCSD dataset进行分析。</li>
<li>methods: 该方法利用卷积自适应Encoder来学习正常视频的空间时间模式，然后对测试视频每帧进行比较，以确定异常。</li>
<li>results: 该方法在UCSD dataset上进行测试，实现了99.35%的总准确率（在Ped1 dataset上）和99.77%的总准确率（在Ped2 dataset上），证明了该方法在视频异常检测中的效果。<details>
<summary>Abstract</summary>
In this research we propose a deep learning approach for detecting anomalies in videos using convolutional autoencoder and decoder neural networks on the UCSD dataset.Our method utilizes a convolutional autoencoder to learn the spatiotemporal patterns of normal videos and then compares each frame of a test video to this learned representation. We evaluated our approach on the UCSD dataset and achieved an overall accuracy of 99.35% on the Ped1 dataset and 99.77% on the Ped2 dataset, demonstrating the effectiveness of our method for detecting anomalies in surveillance videos. The results show that our method outperforms other state-of-the-art methods, and it can be used in real-world applications for video anomaly detection.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种基于深度学习的视频异常检测方法，使用卷积自适应Encoder和解码神经网络在UCSD数据集上进行检测。我们的方法利用卷积自适应Encoder来学习正常视频中的空间时间模式，然后对测试视频中每帧图像与这个学习的表示进行比较。我们对UCSD数据集进行评估，实现了 Ped1 数据集的总准确率为 99.35% 和 Ped2 数据集的总准确率为 99.77%，这表明了我们的方法在视频异常检测中的有效性。结果显示，我们的方法在当前的实际应用中可以取得更高的性能。
</details></li>
</ul>
<hr>
<h2 id="SaFL-Sybil-aware-Federated-Learning-with-Application-to-Face-Recognition"><a href="#SaFL-Sybil-aware-Federated-Learning-with-Application-to-Face-Recognition" class="headerlink" title="SaFL: Sybil-aware Federated Learning with Application to Face Recognition"></a>SaFL: Sybil-aware Federated Learning with Application to Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04346">http://arxiv.org/abs/2311.04346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Ghafourian, Julian Fierrez, Ruben Vera-Rodriguez, Ruben Tolosana, Aythami Morales</li>
<li>for: 这篇论文的目的是提出一种防御腐败攻击的方法，以保护 Federated Learning（FL）中的数据隐私和安全。</li>
<li>methods: 这篇论文使用了一种名为 SaFL（Sybil-aware Federated Learning）的新防御方法，该方法使用了一种时间变量的汇集方式，以减少蜡层攻击的影响。</li>
<li>results: 该论文的实验结果表明，SaFL 方法可以有效地防止腐败攻击，并保持 FL 的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a machine learning paradigm to conduct collaborative learning among clients on a joint model. The primary goal is to share clients' local training parameters with an integrating server while preserving their privacy. This method permits to exploit the potential of massive mobile users' data for the benefit of machine learning models' performance while keeping sensitive data on local devices. On the downside, FL raises security and privacy concerns that have just started to be studied. To address some of the key threats in FL, researchers have proposed to use secure aggregation methods (e.g. homomorphic encryption, secure multiparty computation, etc.). These solutions improve some security and privacy metrics, but at the same time bring about other serious threats such as poisoning attacks, backdoor attacks, and free running attacks. This paper proposes a new defense method against poisoning attacks in FL called SaFL (Sybil-aware Federated Learning) that minimizes the effect of sybils with a novel time-variant aggregation scheme.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Semantic-Matching-with-Hypercolumn-Correlation"><a href="#Efficient-Semantic-Matching-with-Hypercolumn-Correlation" class="headerlink" title="Efficient Semantic Matching with Hypercolumn Correlation"></a>Efficient Semantic Matching with Hypercolumn Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04336">http://arxiv.org/abs/2311.04336</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seungwook Kim, Juhong Min, Minsu Cho</li>
<li>for: 本研究主要针对于 semantic matching 领域，即在多个视觉特征图像之间建立Semantic correspondence。</li>
<li>methods: 本研究提出了 HCCNet，一种高效且有效的 semantic matching 方法，它利用多级对比地图中的各种信息，从低级对比地图到高级对比地图，以实现高效的Semantic correspondence establishment。 HCCNet 通过对瓶颈特征进行 feature slicing，生成了更丰富的中间特征，并使用这些中间特征建立了 hypercolumn correlation。</li>
<li>results: HCCNet 在标准的 semantic matching  bencmarks 上达到了state-of-the-art 或竞争性的性能，而且与现有的 SoTA 方法相比，它的计算负担和延迟 overhead 显著下降。<details>
<summary>Abstract</summary>
Recent studies show that leveraging the match-wise relationships within the 4D correlation map yields significant improvements in establishing semantic correspondences - but at the cost of increased computation and latency. In this work, we focus on the aspect that the performance improvements of recent methods can also largely be attributed to the usage of multi-scale correlation maps, which hold various information ranging from low-level geometric cues to high-level semantic contexts. To this end, we propose HCCNet, an efficient yet effective semantic matching method which exploits the full potential of multi-scale correlation maps, while eschewing the reliance on expensive match-wise relationship mining on the 4D correlation map. Specifically, HCCNet performs feature slicing on the bottleneck features to yield a richer set of intermediate features, which are used to construct a hypercolumn correlation. HCCNet can consequently establish semantic correspondences in an effective manner by reducing the volume of conventional high-dimensional convolution or self-attention operations to efficient point-wise convolutions. HCCNet demonstrates state-of-the-art or competitive performances on the standard benchmarks of semantic matching, while incurring a notably lower latency and computation overhead compared to the existing SoTA methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Data-Perspective-on-Enhanced-Identity-Preservation-for-Diffusion-Personalization"><a href="#A-Data-Perspective-on-Enhanced-Identity-Preservation-for-Diffusion-Personalization" class="headerlink" title="A Data Perspective on Enhanced Identity Preservation for Diffusion Personalization"></a>A Data Perspective on Enhanced Identity Preservation for Diffusion Personalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04315">http://arxiv.org/abs/2311.04315</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingzhe He, Zhiwen Cao, Nicholas Kolkin, Lantao Yu, Helge Rhodin, Ratheesh Kalarot</li>
<li>for: 该论文旨在提高大型文本到图像模型中生成图像的能力，但是它无法捕捉特定的个性或特殊视觉概念，如家中的物品或宠物。</li>
<li>methods: 该论文提出了一种数据驱动的方法，通过修改数据而不是模型来解决这个问题。它引入了一种新的常见化数据生成策略，以及文本和图像水平的常见化数据生成策略，以保持文本coherence和主体认知。</li>
<li>results: 该论文的实验结果表明，该方法可以生成高质量的图像，同时保持主体认知和多样性。它在Established benchmarks上达到了新的州OF-THE-ART WaterMark，并且在文本对应性、主体认知和多样性之间做出了最佳的平衡。<details>
<summary>Abstract</summary>
Large text-to-image models have revolutionized the ability to generate imagery using natural language. However, particularly unique or personal visual concepts, such as your pet, an object in your house, etc., will not be captured by the original model. This has led to interest in how to inject new visual concepts, bound to a new text token, using as few as 4-6 examples. Despite significant progress, this task remains a formidable challenge, particularly in preserving the subject's identity. While most researchers attempt to to address this issue by modifying model architectures, our approach takes a data-centric perspective, advocating the modification of data rather than the model itself. We introduce a novel regularization dataset generation strategy on both the text and image level; demonstrating the importance of a rich and structured regularization dataset (automatically generated) to prevent losing text coherence and better identity preservation. The better quality is enabled by allowing up to 5x more fine-tuning iterations without overfitting and degeneration. The generated renditions of the desired subject preserve even fine details such as text and logos; all while maintaining the ability to generate diverse samples that follow the input text prompt. Since our method focuses on data augmentation, rather than adjusting the model architecture, it is complementary and can be combined with prior work. We show on established benchmarks that our data-centric approach forms the new state of the art in terms of image quality, with the best trade-off between identity preservation, diversity, and text alignment.
</details>
<details>
<summary>摘要</summary>
大型文本到图像模型已经革命化了使用自然语言生成图像的能力。然而，特别是Unique或个人视觉概念，如你的宠物或家中的物品等，原始模型将不会捕捉它们。这 hath led to interest in how to inject new visual concepts, bound to a new text token, using as few as 4-6 examples. Despite significant progress, this task remains a formidable challenge, particularly in preserving the subject's identity. While most researchers attempt to address this issue by modifying model architectures, our approach takes a data-centric perspective, advocating the modification of data rather than the model itself. We introduce a novel regularization dataset generation strategy on both the text and image level; demonstrating the importance of a rich and structured regularization dataset (automatically generated) to prevent losing text coherence and better identity preservation. The better quality is enabled by allowing up to 5x more fine-tuning iterations without overfitting and degeneration. The generated renditions of the desired subject preserve even fine details such as text and logos; all while maintaining the ability to generate diverse samples that follow the input text prompt. Since our method focuses on data augmentation, rather than adjusting the model architecture, it is complementary and can be combined with prior work. We show on established benchmarks that our data-centric approach forms the new state of the art in terms of image quality, with the best trade-off between identity preservation, diversity, and text alignment.
</details></li>
</ul>
<hr>
<h2 id="Holistic-Evaluation-of-Text-To-Image-Models"><a href="#Holistic-Evaluation-of-Text-To-Image-Models" class="headerlink" title="Holistic Evaluation of Text-To-Image Models"></a>Holistic Evaluation of Text-To-Image Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04287">http://arxiv.org/abs/2311.04287</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanford-crfm/helm">https://github.com/stanford-crfm/helm</a></li>
<li>paper_authors: Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai, Joon Sung Park, Agrim Gupta, Yunzhi Zhang, Deepak Narayanan, Hannah Benita Teufel, Marco Bellagente, Minguk Kang, Taesung Park, Jure Leskovec, Jun-Yan Zhu, Li Fei-Fei, Jiajun Wu, Stefano Ermon, Percy Liang</li>
<li>For: The paper aims to provide a comprehensive evaluation of text-to-image models to better understand their capabilities and risks.* Methods: The paper introduces a new benchmark called Holistic Evaluation of Text-to-Image Models (HEIM), which assesses 12 aspects of text-to-image models, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency.* Results: The paper evaluates 26 state-of-the-art text-to-image models on the HEIM benchmark and finds that no single model excels in all aspects, with different models demonstrating different strengths. The results are released along with the generated images and human evaluation results for full transparency.Here are the three information points in Simplified Chinese text:* For: 这篇论文目的是为了提供文本映射模型的全面评估，以更好地了解它们的能力和风险。* Methods: 这篇论文引入了一个新的评估板准，名为整体评估文本映射模型（HEIM），它评估了12个方面，包括文本映射、图像质量、美学、创新、逻辑、知识、偏见、不公正、鲁莽、多语言和效率。* Results: 这篇论文评估了26种当前最佳文本映射模型，发现没有一个模型在所有方面都表现出优异，不同的模型在不同的方面都有不同的优势。结果发布在<a target="_blank" rel="noopener" href="https://crfm.stanford.edu/heim/v1.1.0%E5%92%8Chttps://github.com/stanford-crfm/helm%EF%BC%8C%E5%B9%B6%E4%B8%8EHELM%E4%BB%A3%E7%A0%81%E9%9B%86%E6%88%90%E3%80%82">https://crfm.stanford.edu/heim/v1.1.0和https://github.com/stanford-crfm/helm，并与HELM代码集成。</a><details>
<summary>Abstract</summary>
The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on text-image alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at https://crfm.stanford.edu/heim/v1.1.0 and the code at https://github.com/stanford-crfm/helm, which is integrated with the HELM codebase.
</details>
<details>
<summary>摘要</summary>
“文本至图模型最近的精彩质量提升，吸引了广泛的关注和应用。然而，我们缺乏全面的量化理解这些模型的能力和风险。为了填补这个空白，我们介绍了一个新的标准测试套件，即整体评估文本至图模型（HEIM）。以前的评估主要集中在文本图像对齐和图像质量上，而我们已经识别出12个方面，包括文本图像对齐、图像质量、美学、创新、理解、知识、偏见、恶意、不公正、Robustness、多语言和效率。我们编辑了62个场景，涵盖这些方面，并对26种当前最佳文本至图模型进行了评估。我们发现没有任何模型在所有方面都表现出色，不同的模型在不同的方面具有不同的优势。我们在https://crfm.stanford.edu/heim/v1.1.0发布了生成的图像和人工评估结果，以便具有全面的透明度。”Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Video-Instance-Matting"><a href="#Video-Instance-Matting" class="headerlink" title="Video Instance Matting"></a>Video Instance Matting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04212">http://arxiv.org/abs/2311.04212</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shi-labs/vim">https://github.com/shi-labs/vim</a></li>
<li>paper_authors: Jiachen Li, Roberto Henschel, Vidit Goel, Marianna Ohanyan, Shant Navasardyan, Humphrey Shi<br>for:* The paper is written for the task of video instance matting, which involves estimating alpha mattes for each instance in a video frame.methods:* The proposed method, called MSG-VIM, uses a Mask Sequence Guided Video Instance Matting neural network to tackle the challenging problem of video instance matting.* The method incorporates a mixture of mask augmentations to improve the robustness of alpha matte predictions, and includes temporal mask and temporal feature guidance to improve the temporal consistency of the predictions.results:* The proposed model MSG-VIM sets a strong baseline on the VIM50 benchmark and outperforms existing methods by a large margin.Here is the information in Simplified Chinese text, as requested:for:* 这篇论文是为了解决视频实例抹发问题而写的。methods:* 提议的方法是使用Mask Sequence Guided Video Instance Matting神经网络来解决视频实例抹发问题。* 该方法使用了一种混合的面谱增强来提高抹发预测的稳定性，并包括时间面和时间特征引导来提高时间一致性。results:* 提议的模型MSG-VIM在VIM50 benchmark上设置了强大的基线，并与现有方法相比有大幅度的提升。<details>
<summary>Abstract</summary>
Conventional video matting outputs one alpha matte for all instances appearing in a video frame so that individual instances are not distinguished. While video instance segmentation provides time-consistent instance masks, results are unsatisfactory for matting applications, especially due to applied binarization. To remedy this deficiency, we propose Video Instance Matting~(VIM), that is, estimating alpha mattes of each instance at each frame of a video sequence. To tackle this challenging problem, we present MSG-VIM, a Mask Sequence Guided Video Instance Matting neural network, as a novel baseline model for VIM. MSG-VIM leverages a mixture of mask augmentations to make predictions robust to inaccurate and inconsistent mask guidance. It incorporates temporal mask and temporal feature guidance to improve the temporal consistency of alpha matte predictions. Furthermore, we build a new benchmark for VIM, called VIM50, which comprises 50 video clips with multiple human instances as foreground objects. To evaluate performances on the VIM task, we introduce a suitable metric called Video Instance-aware Matting Quality~(VIMQ). Our proposed model MSG-VIM sets a strong baseline on the VIM50 benchmark and outperforms existing methods by a large margin. The project is open-sourced at https://github.com/SHI-Labs/VIM.
</details>
<details>
<summary>摘要</summary>
传统的视频剪辑输出一个Alpha照明 для所有出现在视频帧中的实例，因此每个实例都无法分 differentiated。而视频实例分割提供了时间一致的实例掩码，但是结果不满足剪辑应用，特别是因为应用了二进制化。为了解决这个不足，我们提出了视频实例剪辑~(VIM)，即在每帧视频序列中对每个实例进行Alpha照明估计。为了解决这个挑战性的问题，我们提出了Mask Sequence Guided Video Instance Matting~(MSG-VIM) neural network，作为VIM的基线模型。MSG-VIM利用了混合的掩码更新，以使其预测结果具有对不准确和不一致的掩码指导的robustness。它还包括时间掩码和时间特征指导，以改进Alpha照明预测的时间一致性。此外，我们建立了一个新的VIM benchmark，称为VIM50，该benchmark包括50个视频clip，每个clip都有多个人脸作为前景对象。为了评估VIM任务的性能，我们提出了一个适合的 metric，称为视频实例相关的剪辑照明质量~(VIMQ)。我们的提案模型MSG-VIM在VIM50 bencmark上设置了一个强大的基线，并在现有方法之上出现大幅度的超越。项目开源在https://github.com/SHI-Labs/VIM。
</details></li>
</ul>
<hr>
<h2 id="Deep-Hashing-via-Householder-Quantization"><a href="#Deep-Hashing-via-Householder-Quantization" class="headerlink" title="Deep Hashing via Householder Quantization"></a>Deep Hashing via Householder Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04207">http://arxiv.org/abs/2311.04207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas R. Schwengber, Lucas Resende, Paulo Orenstein, Roberto I. Oliveira</li>
<li>For: The paper is written for large-scale image similarity search, specifically to improve the performance of deep hashing algorithms through a new quantization strategy.* Methods: The paper proposes an alternative quantization strategy that decomposes the learning problem into two stages: first, perform similarity learning over the embedding space with no quantization, and second, find an optimal orthogonal transformation of the embeddings using Householder matrices to efficiently leverage stochastic gradient descent.* Results: The proposed algorithm leads to state-of-the-art performance on widely used image datasets, and brings consistent improvements in performance to existing deep hashing algorithms, without any hyperparameter tuning.Here’s the simplified Chinese text for the three key information points:</li>
<li>for: 这篇论文是为大规模图像相似搜索而写的，具体是为了改进深度哈希算法的性能。</li>
<li>methods: 论文提出了一种新的量化策略，即将学习问题分解成两个阶段：首先在嵌入空间上进行相似学习，然后使用抽象矩阵来高效地利用随机梯度下降来找到最佳正交变换。</li>
<li>results: 提出的算法在广泛使用的图像数据集上达到了状态级表现，并且能够在现有的深度哈希算法上带来一致的性能提升，无需进行任何超参数调整。<details>
<summary>Abstract</summary>
Hashing is at the heart of large-scale image similarity search, and recent methods have been substantially improved through deep learning techniques. Such algorithms typically learn continuous embeddings of the data. To avoid a subsequent costly binarization step, a common solution is to employ loss functions that combine a similarity learning term (to ensure similar images are grouped to nearby embeddings) and a quantization penalty term (to ensure that the embedding entries are close to binarized entries, e.g., -1 or 1). Still, the interaction between these two terms can make learning harder and the embeddings worse. We propose an alternative quantization strategy that decomposes the learning problem in two stages: first, perform similarity learning over the embedding space with no quantization; second, find an optimal orthogonal transformation of the embeddings so each coordinate of the embedding is close to its sign, and then quantize the transformed embedding through the sign function. In the second step, we parametrize orthogonal transformations using Householder matrices to efficiently leverage stochastic gradient descent. Since similarity measures are usually invariant under orthogonal transformations, this quantization strategy comes at no cost in terms of performance. The resulting algorithm is unsupervised, fast, hyperparameter-free and can be run on top of any existing deep hashing or metric learning algorithm. We provide extensive experimental results showing that this approach leads to state-of-the-art performance on widely used image datasets, and, unlike other quantization strategies, brings consistent improvements in performance to existing deep hashing algorithms.
</details>
<details>
<summary>摘要</summary>
哈希算法在大规模图像相似搜索中扮演着重要的角色，而现代方法通常通过深度学习技术进行改进。这些算法通常学习维度 embedding，以避免后续的costly binarization步骤。常见的解决方案是使用相似学习项和量化罚项的损失函数，以确保相似图像被分配到靠近 embedding 的位置。然而，这两个项的交互可能使学习更加困难，并且 embedding 更差。我们提出一种 alternating quantization 策略，即先在 embedding 空间进行相似学习，然后使用 Householder 矩阵来找到最佳的正交变换，使每个 embedding 坐标与其相应的 sign 很近。最后，对 transformed embedding 进行量化，使用 sign 函数。在第二步中，我们使用 Householder 矩阵来Parametrize orthogonal transformations，可以高效地使用批量梯度下降。由于相似度度量通常是对 orthogonal transformation 的 invariant，这种量化策略不会对性能产生损失。这种算法是无监督的，快速的，无参数的，可以在任何现有的深度哈希或度量学习算法之上运行。我们在广泛的实验中展示了这种方法可以在常用的图像 dataset 上达到状态级的表现，并且与其他量化策略不同，对现有的深度哈希算法带来了一致的性能提升。
</details></li>
</ul>
<hr>
<h2 id="High-fidelity-3D-Reconstruction-of-Plants-using-Neural-Radiance-Field"><a href="#High-fidelity-3D-Reconstruction-of-Plants-using-Neural-Radiance-Field" class="headerlink" title="High-fidelity 3D Reconstruction of Plants using Neural Radiance Field"></a>High-fidelity 3D Reconstruction of Plants using Neural Radiance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04154">http://arxiv.org/abs/2311.04154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kewei Hu, Ying Wei, Yaoqiang Pan, Hanwen Kang, Chao Chen</li>
<li>for: 本研究旨在探讨Neural Radiance Field（NeRF）在减少农业垦扰领域中的应用，特别是在植物形态 reconstruction和新视图图像生成等两个基本任务中。</li>
<li>methods: 本研究使用了NeRF技术，包括Instant-NGP和Instant-NSR两种state-of-the-art方法，以生成高质量的图像和精准的植物模型。</li>
<li>results: 实验结果表明，NeRF在植物形态 reconstruction和新视图图像生成任务中表现出色，能够与商业软件Reality Capture相当。然而，研究也发现NeRF在某些情况下存在较慢的训练速度、不足的样本导致的性能局限性和复杂场景中的几何质量问题。<details>
<summary>Abstract</summary>
Accurate reconstruction of plant phenotypes plays a key role in optimising sustainable farming practices in the field of Precision Agriculture (PA). Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging. Recently, a promising development has emerged in the form of Neural Radiance Field (NeRF), a novel method that utilises neural density fields. This technique has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context. In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models. We explore the world of neural radiance fields, in particular two SOTA methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training. In particular, we present a novel plant phenotype dataset comprising real plant images from production environments. This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts. Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction. However, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups.
</details>
<details>
<summary>摘要</summary>
准确重建植物形态在精度农业中发挥关键作用。目前，光学传感器方法在这个领域占据主导地位，但是在无结构农业环境中高精度三维重建植物和植物模型的需求仍然是挑战。在最近的研究中，我们发现了一种有前途的发展：神经辐射场（NeRF）。这种技术利用神经density场，并在不同的视觉合成任务中表现出色。然而，在农业上这种技术还尚未得到广泛的探索。在我们的研究中，我们关注了两个基本的植物形态检测任务：（1）生成新视图图像，和（2）三维重建农作物和植物模型。我们深入探讨神经辐射场的世界，尤其是两种现状顶尖方法：Instant-NGP和Instant-NSR。Instant-NGP可以在快速训练和执行速度之下生成高质量图像，而Instant-NSR通过在训练中包含签名距离函数（SDF）来提高重建几何的质量。特别是，我们提供了一个新的植物形态数据集，包括来自生产环境的真实植物图像。这个数据集是农业领域的首次尝试，旨在全面探讨神经辐射场在农业上的优势和局限性。我们的实验结果表明，NeRF在生成新视图图像和三维重建农作物和植物模型方面具有很好的表现，能够与市场领先的3D多视点雷达（MVS）重建软件相匹配。然而，我们的研究也显示了NeRF的一些缺点，包括较慢的训练速度、不足的抽象情况下的表现局限性和复杂配置下的几何质量问题。
</details></li>
</ul>
<hr>
<h2 id="I2VGen-XL-High-Quality-Image-to-Video-Synthesis-via-Cascaded-Diffusion-Models"><a href="#I2VGen-XL-High-Quality-Image-to-Video-Synthesis-via-Cascaded-Diffusion-Models" class="headerlink" title="I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models"></a>I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04145">http://arxiv.org/abs/2311.04145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/damo-vilab/i2vgen-xl">https://github.com/damo-vilab/i2vgen-xl</a></li>
<li>paper_authors: Shiwei Zhang, Jiayu Wang, Yingya Zhang, Kang Zhao, Hangjie Yuan, Zhiwu Qin, Xiang Wang, Deli Zhao, Jingren Zhou</li>
<li>for: 这个论文主要是为了提高视频生成的Semantic精度和Quality。</li>
<li>methods: 这个论文提出了一种名为I2VGen-XL的方法，它包括两个阶段：基础阶段和精度阶段。基础阶段使用两个层次编码器来保持输入图像的准确性和内容，而精度阶段通过添加额外的简短文本来提高视频的细节和分辨率（1280×720）。</li>
<li>results: 经过广泛的实验，I2VGen-XL可以同时提高视频的Semantic精度、细节连续性和清晰度。与当前的顶尖方法进行比较，I2VGen-XL也表现出了其效果。<details>
<summary>Abstract</summary>
Video synthesis has recently made remarkable strides benefiting from the rapid development of diffusion models. However, it still encounters challenges in terms of semantic accuracy, clarity and spatio-temporal continuity. They primarily arise from the scarcity of well-aligned text-video data and the complex inherent structure of videos, making it difficult for the model to simultaneously ensure semantic and qualitative excellence. In this report, we propose a cascaded I2VGen-XL approach that enhances model performance by decoupling these two factors and ensures the alignment of the input data by utilizing static images as a form of crucial guidance. I2VGen-XL consists of two stages: i) the base stage guarantees coherent semantics and preserves content from input images by using two hierarchical encoders, and ii) the refinement stage enhances the video's details by incorporating an additional brief text and improves the resolution to 1280$\times$720. To improve the diversity, we collect around 35 million single-shot text-video pairs and 6 billion text-image pairs to optimize the model. By this means, I2VGen-XL can simultaneously enhance the semantic accuracy, continuity of details and clarity of generated videos. Through extensive experiments, we have investigated the underlying principles of I2VGen-XL and compared it with current top methods, which can demonstrate its effectiveness on diverse data. The source code and models will be publicly available at \url{https://i2vgen-xl.github.io}.
</details>
<details>
<summary>摘要</summary>
视频合成在最近几年内做出了很多出色的进步，受 diffusion 模型的快速发展的推动。然而，它仍然面临 semantic 精度、清晰度和空间时间连续性等挑战。这些挑战主要来自于缺乏准确的文本视频数据和视频的复杂内在结构，使得模型很难同时保证 semantic 和质量上的优秀表现。在这份报告中，我们提出了一种名为 I2VGen-XL 的方法，该方法通过分解这两个因素来提高模型性能，并使用静止图片作为关键指导。I2VGen-XL 包括两个阶段：首先，基础阶段保证文本和图片之间的协调性，并使用两层嵌入器保持输入图片的内容一致性；其次，改进阶段通过添加一个短文本和提高分辨率来提高视频的细节，并将分辨率提高到 1280×720。为了提高多样性，我们收集了约 35 万个单个文本视频对和 6 亿个文本图片对，以便优化模型。通过这些方式，I2VGen-XL 可以同时提高 semantic 精度、视频细节的连续性和清晰度。经过广泛的实验，我们发现 I2VGen-XL 的基本原理和现代顶峰方法的效果，并可以在多种数据上证明其效果。模型和代码将在 \url{https://i2vgen-xl.github.io} 上公开。
</details></li>
</ul>
<hr>
<h2 id="Perceptual-Quality-Improvement-in-Videoconferencing-using-Keyframes-based-GAN"><a href="#Perceptual-Quality-Improvement-in-Videoconferencing-using-Keyframes-based-GAN" class="headerlink" title="Perceptual Quality Improvement in Videoconferencing using Keyframes-based GAN"></a>Perceptual Quality Improvement in Videoconferencing using Keyframes-based GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04263">http://arxiv.org/abs/2311.04263</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lorenzoagnolucci/keyframes-gan">https://github.com/lorenzoagnolucci/keyframes-gan</a></li>
<li>paper_authors: Lorenzo Agnolucci, Leonardo Galteri, Marco Bertini, Alberto Del Bimbo</li>
<li>for: 提高视频会议中的视觉质量</li>
<li>methods: 使用 Generative Adversarial Networks (GANs) 技术，基于人脸特征点进行多尺度特征提取，并在进程中进行恢复高频率细节</li>
<li>results: 实验表明，提出的方法可以提高视觉质量，并生成高度真实的结果，即使压缩率高。In English:</li>
<li>for: Improving visual quality in video conferencing</li>
<li>methods: Using Generative Adversarial Networks (GANs) technology, based on facial landmarks for multi-scale feature extraction, and progressive restoration of high-frequency details lost after video compression</li>
<li>results: Experiments show that the proposed method can improve visual quality and generate photo-realistic results, even with high compression rates.<details>
<summary>Abstract</summary>
In the latest years, videoconferencing has taken a fundamental role in interpersonal relations, both for personal and business purposes. Lossy video compression algorithms are the enabling technology for videoconferencing, as they reduce the bandwidth required for real-time video streaming. However, lossy video compression decreases the perceived visual quality. Thus, many techniques for reducing compression artifacts and improving video visual quality have been proposed in recent years. In this work, we propose a novel GAN-based method for compression artifacts reduction in videoconferencing. Given that, in this context, the speaker is typically in front of the camera and remains the same for the entire duration of the transmission, we can maintain a set of reference keyframes of the person from the higher-quality I-frames that are transmitted within the video stream and exploit them to guide the visual quality improvement; a novel aspect of this approach is the update policy that maintains and updates a compact and effective set of reference keyframes. First, we extract multi-scale features from the compressed and reference frames. Then, our architecture combines these features in a progressive manner according to facial landmarks. This allows the restoration of the high-frequency details lost after the video compression. Experiments show that the proposed approach improves visual quality and generates photo-realistic results even with high compression rates. Code and pre-trained networks are publicly available at https://github.com/LorenzoAgnolucci/Keyframes-GAN.
</details>
<details>
<summary>摘要</summary>
在最近几年，视频会议已经扮演了人际关系中的重要角色，不仅在个人交流方面，还在商业方面。损失式视频压缩算法是视频会议的关键技术，它降低了实时视频流的带宽需求。然而，损失式视频压缩会降低视频的视觉质量。因此，许多降低压缩残差和提高视频视觉质量的技术已经在最近几年被提出。在这种情况下，我们提出了一种基于GAN的新方法，用于压缩残差降低在视频会议中。由于speaker通常会在摄像头前面并保持不变的整个传输时间，我们可以维护一组高质量I帧中的人数据，并利用它们来导航视觉质量的提高。这种方法的新特点是更新策略，用于维护和更新一个高效和紧凑的人数据集。首先，我们从压缩和参照帧中提取多尺度特征。然后，我们的架构将这些特征进行进度式组合，根据人脸特征来确定。这样可以恢复压缩后丢失的高频环境信息。实验表明，我们的方法可以提高视觉质量，并生成高度真实的结果，即使压缩率很高。代码和预训练网络可以在https://github.com/LorenzoAgnolucci/Keyframes-GAN上获取。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Semantic-Map-Representation-for-Skill-based-Visual-Object-Navigation"><a href="#Interactive-Semantic-Map-Representation-for-Skill-based-Visual-Object-Navigation" class="headerlink" title="Interactive Semantic Map Representation for Skill-based Visual Object Navigation"></a>Interactive Semantic Map Representation for Skill-based Visual Object Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04107">http://arxiv.org/abs/2311.04107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tatiana Zemskova, Aleksei Staroverov, Kirill Muravyev, Dmitry Yudin, Aleksandr Panov</li>
<li>for: 本研究旨在提出一种基于学习方法的移动机器人视觉对象导航技术。</li>
<li>methods: 该技术基于神经网络方法，在推理过程中调整分割模型的权重，使用反propagation计算预测的融合损失值。</li>
<li>results: 实验结果显示，该技术在Habitat环境中 Navigation metric上表现出了明显的优势，与现有方法相比。代码和自定义数据集在github.com&#x2F;AIRI-Institute&#x2F;skill-fusion上公开发布。<details>
<summary>Abstract</summary>
Visual object navigation using learning methods is one of the key tasks in mobile robotics. This paper introduces a new representation of a scene semantic map formed during the embodied agent interaction with the indoor environment. It is based on a neural network method that adjusts the weights of the segmentation model with backpropagation of the predicted fusion loss values during inference on a regular (backward) or delayed (forward) image sequence. We have implemented this representation into a full-fledged navigation approach called SkillTron, which can select robot skills from end-to-end policies based on reinforcement learning and classic map-based planning methods. The proposed approach makes it possible to form both intermediate goals for robot exploration and the final goal for object navigation. We conducted intensive experiments with the proposed approach in the Habitat environment, which showed a significant superiority in navigation quality metrics compared to state-of-the-art approaches. The developed code and used custom datasets are publicly available at github.com/AIRI-Institute/skill-fusion.
</details>
<details>
<summary>摘要</summary>
Mobile robot视觉对象导航使用学习方法是关键任务之一。这篇论文介绍了一种新的场景semantic地图表示方法，基于神经网络方法，在感知器与室内环境互动中调整分割模型的权重，通过反propagation的预测融合损失值进行推理。我们在SkillTron全面导航方法中实现了这种表示方法，可以根据反射学习和经典地图基本规划方法选择机器人技能。这种方法可以形成机器人探索的中间目标和 Navigation的最终目标。我们在Habitat环境中进行了广泛的实验，并显示了与状态艺术方法相比的导航质量指标显著superiority。我们在github.com/AIRI-Institute/skill-fusion上公开了代码和自定义数据集。
</details></li>
</ul>
<hr>
<h2 id="DeepPatent2-A-Large-Scale-Benchmarking-Corpus-for-Technical-Drawing-Understanding"><a href="#DeepPatent2-A-Large-Scale-Benchmarking-Corpus-for-Technical-Drawing-Understanding" class="headerlink" title="DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding"></a>DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04098">http://arxiv.org/abs/2311.04098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kehinde Ajayi, Xin Wei, Martin Gryder, Winston Shields, Jian Wu, Shawn M. Jones, Michal Kucer, Diane Oyen</li>
<li>for: 这个论文主要是为了提供一个大规模的技术图纸 dataset，以便进行 CV 任务的研究和开发。</li>
<li>methods: 这个论文使用了 US 设计专利文档中的技术图纸，通过自动提取对象名称和视图角度来构建 dataset。</li>
<li>results: 这个论文通过使用 DeepPatent2 dataset，实现了技术图纸中的概念描述 task。此外，这个 dataset 还有可能用于其他研究领域，如 3D 图像重建和图像检索。<details>
<summary>Abstract</summary>
Recent advances in computer vision (CV) and natural language processing have been driven by exploiting big data on practical applications. However, these research fields are still limited by the sheer volume, versatility, and diversity of the available datasets. CV tasks, such as image captioning, which has primarily been carried out on natural images, still struggle to produce accurate and meaningful captions on sketched images often included in scientific and technical documents. The advancement of other tasks such as 3D reconstruction from 2D images requires larger datasets with multiple viewpoints. We introduce DeepPatent2, a large-scale dataset, providing more than 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents. We demonstrate the usefulness of DeepPatent2 with conceptual captioning. We further provide the potential usefulness of our dataset to facilitate other research areas such as 3D image reconstruction and image retrieval.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:最近的计算机视觉（CV）和自然语言处理技术的进步主要受到了实际应用的大数据驱动。然而，这些研究领域仍然受限于可用数据的量、多样性和多个视点。CV任务，如图像描述，主要在自然图像上进行，它们在科学和技术文档中出现的草图图像上仍然做出了不准确和没有意义的描述。3D重建从2D图像需要更多的数据集，包括多个视点。我们介绍DeepPatent2，一个大规模数据集，包含超过270万个技术图像，其中有132,890个物品名称和22,394个视点，从14年的美国设计专利文档中提取。我们通过概念描述来证明DeepPatent2的有用性，并提供了这些数据集可能用于其他研究领域，如3D图像重建和图像搜索。
</details></li>
</ul>
<hr>
<h2 id="Image-Pointcloud-Fusion-based-Anomaly-Detection-using-PD-REAL-Dataset"><a href="#Image-Pointcloud-Fusion-based-Anomaly-Detection-using-PD-REAL-Dataset" class="headerlink" title="Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset"></a>Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04095">http://arxiv.org/abs/2311.04095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianjian Qin, Chunzhi Gu, Jun Yu, Chao Zhang</li>
<li>for: 这个研究是为了开发一个大规模的无监督异常检测（AD） dataset 以测试3D空间中的异常检测能力。</li>
<li>methods: 这个研究使用了Play-Doh模型来生成15种物品类别中的异常，并在不同的照明条件下拍摄了这些物品。实验使用了一款商业可用的RealSense摄像机来拍摄RGB和深度图像。</li>
<li>results: 研究表明，使用3D信息可以增强异常检测的性能，但也存在一些挑战。与现有的3D AD dataset相比，PD-REAL的数据收集方式更加便宜、易于扩展和控制变量。<details>
<summary>Abstract</summary>
We present PD-REAL, a novel large-scale dataset for unsupervised anomaly detection (AD) in the 3D domain. It is motivated by the fact that 2D-only representations in the AD task may fail to capture the geometric structures of anomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL consists entirely of Play-Doh models for 15 object categories and focuses on the analysis of potential benefits from 3D information in a controlled environment. Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios. To demonstrate the usefulness of 3D information, we use a commercially available RealSense camera to capture RGB and depth images. Compared to the existing 3D dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables. Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information. Our dataset can be downloaded from https://github.com/Andy-cs008/PD-REAL
</details>
<details>
<summary>摘要</summary>
我们介绍PD-REAL，一个新的大规模不监督异常检测（AD）数据集在三维领域。它受到了2D只 representation在AD任务中可能无法捕捉异常的geometry结构的不确定性的光照条件或拍摄角度的影响。PD-REAL完全由Play-Doh模型组成15种对象类，集中在控制环境中对3D信息的分析。具体来说，物体首先创建了6种异常，如损害、裂缝、或者洞，然后在不同的照明条件下拍摄，以模拟真实世界检测场景。为了证明3D信息的用于，我们使用了一个商业可用的RealSense摄像头捕摄RGB和深度图像。与现有的3D数据集 дляAD任务相比，PD-REAL数据收集的更加便宜、扩展可控和更容易控制变量。我们对state-of-the-art AD算法进行了广泛的评估，并证明了使用3D信息的好处以及挑战。PD-REAL数据集可以从https://github.com/Andy-cs008/PD-REAL下载。
</details></li>
</ul>
<hr>
<h2 id="Proceedings-of-the-5th-International-Workshop-on-Reading-Music-Systems"><a href="#Proceedings-of-the-5th-International-Workshop-on-Reading-Music-Systems" class="headerlink" title="Proceedings of the 5th International Workshop on Reading Music Systems"></a>Proceedings of the 5th International Workshop on Reading Music Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04091">http://arxiv.org/abs/2311.04091</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suziai/gui-tools">https://github.com/suziai/gui-tools</a></li>
<li>paper_authors: Jorge Calvo-Zaragoza, Alexander Pacha, Elona Shatri</li>
<li>for: The workshop aims to connect researchers developing music reading systems with other researchers and practitioners who could benefit from these systems, such as librarians or musicologists.</li>
<li>methods: The workshop covers a wide range of topics, including optical music recognition, image processing on music scores, writer identification, and multi-modal systems.</li>
<li>results: The proceedings of the 5th International Workshop on Reading Music Systems, held in Milan, Italy on Nov. 4th 2023, showcase the latest research and developments in the field of music reading systems.<details>
<summary>Abstract</summary>
The International Workshop on Reading Music Systems (WoRMS) is a workshop that tries to connect researchers who develop systems for reading music, such as in the field of Optical Music Recognition, with other researchers and practitioners that could benefit from such systems, like librarians or musicologists. The relevant topics of interest for the workshop include, but are not limited to: Music reading systems; Optical music recognition; Datasets and performance evaluation; Image processing on music scores; Writer identification; Authoring, editing, storing and presentation systems for music scores; Multi-modal systems; Novel input-methods for music to produce written music; Web-based Music Information Retrieval services; Applications and projects; Use-cases related to written music.   These are the proceedings of the 5th International Workshop on Reading Music Systems, held in Milan, Italy on Nov. 4th 2023.
</details>
<details>
<summary>摘要</summary>
世界音乐读取系统国际研讨会（WoRMS）是一个研讨会，旨在联系开发音乐读取系统的研究人员（如光学音乐识别）与其他研究人员和实践者（如图书管理员或音乐学家），以便互相交流和合作。研讨会的主要关注领域包括，但不限于：音乐读取系统；光学音乐识别；数据集和性能评估；音乐手稿图像处理；作者标识；作品编写、编辑、存储和展示系统；多模态系统；新的音乐输入方法生成书面音乐；网络音乐信息检索服务；应用和项目；相关书面音乐应用场景。这是2023年11月4日在意大利米兰举行的5届世界音乐读取系统国际研讨会的论文集。
</details></li>
</ul>
<hr>
<h2 id="Restoration-of-Analog-Videos-Using-Swin-UNet"><a href="#Restoration-of-Analog-Videos-Using-Swin-UNet" class="headerlink" title="Restoration of Analog Videos Using Swin-UNet"></a>Restoration of Analog Videos Using Swin-UNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04261">http://arxiv.org/abs/2311.04261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miccunifi/analog-video-restoration">https://github.com/miccunifi/analog-video-restoration</a></li>
<li>paper_authors: Lorenzo Agnolucci, Leonardo Galteri, Marco Bertini, Alberto Del Bimbo</li>
<li>for:  restore analog videos of historical archives</li>
<li>methods: multi-frame approach, able to deal with severe tape mistracking</li>
<li>results: effective restoration of original content, tested on real-world videos from a major historical video archive<details>
<summary>Abstract</summary>
In this paper, we present a system to restore analog videos of historical archives. These videos often contain severe visual degradation due to the deterioration of their tape supports that require costly and slow manual interventions to recover the original content. The proposed system uses a multi-frame approach and is able to deal with severe tape mistracking, which results in completely scrambled frames. Tests on real-world videos from a major historical video archive show the effectiveness of our demo system. The code and the pre-trained model are publicly available at https://github.com/miccunifi/analog-video-restoration.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种系统，用于恢复历史档案中的分析视频。这些视频经常受到媒体支持的腐蚀，导致视频内容严重损坏，需要费时费力的手动干预来恢复原始内容。我们提出的系统采用多帧方法，能够处理严重的卷积问题，这会导致整个帧完全排序。我们对历史视频档案中的真实视频进行测试，显示了我们的demo系统的效果。我们在GitHub上公开了代码和预训练模型，请参考https://github.com/miccunifi/analog-video-restoration。
</details></li>
</ul>
<hr>
<h2 id="Learning-Super-Resolution-Ultrasound-Localization-Microscopy-from-Radio-Frequency-Data"><a href="#Learning-Super-Resolution-Ultrasound-Localization-Microscopy-from-Radio-Frequency-Data" class="headerlink" title="Learning Super-Resolution Ultrasound Localization Microscopy from Radio-Frequency Data"></a>Learning Super-Resolution Ultrasound Localization Microscopy from Radio-Frequency Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04081">http://arxiv.org/abs/2311.04081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Hahne, Georges Chabouh, Olivier Couture, Raphael Sznitman</li>
<li>for: This paper aims to improve the resolution performance of Ultrasound Localization Microscopy (ULM) by bypassing the limitations of Delay-And-Sum (DAS) beamforming and using a super-resolution network to process unprocessed Radio-Frequency (RF) data.</li>
<li>methods: The proposed method involves label projection and inverse point transformation between B-mode and RF coordinate space to facilitate the use of RF data in the super-resolution network.</li>
<li>results: The results from the RF-trained network suggest that excluding DAS beamforming offers a great potential to optimize the ULM resolution performance, outperforming state-of-the-art techniques based on a public dataset featuring in silico and in vivo data.<details>
<summary>Abstract</summary>
Ultrasound Localization Microscopy (ULM) enables imaging of vascular structures in the micrometer range by accumulating contrast agent particle locations over time. Precise and efficient target localization accuracy remains an active research topic in the ULM field to further push the boundaries of this promising medical imaging technology. Existing work incorporates Delay-And-Sum (DAS) beamforming into particle localization pipelines, which ultimately determines the ULM image resolution capability. In this paper we propose to feed unprocessed Radio-Frequency (RF) data into a super-resolution network while bypassing DAS beamforming and its limitations. To facilitate this, we demonstrate label projection and inverse point transformation between B-mode and RF coordinate space as required by our approach. We assess our method against state-of-the-art techniques based on a public dataset featuring in silico and in vivo data. Results from our RF-trained network suggest that excluding DAS beamforming offers a great potential to optimize on the ULM resolution performance.
</details>
<details>
<summary>摘要</summary>
美元声波地图（ULM）可以在微米范围内成像血管结构，通过时间积累对比剂粒子的位置。在ULM领域，精准和高效的目标Localization精度仍然是活跃的研究话题，以进一步推动这种承诺的医学成像技术。现有的工作将延迟和总和（DAS）扩散加入了带粒子Localization管道， ultimately determines the ULM图像分辨率能力。在这篇文章中，我们提议将未处理的电磁波（RF）数据Feed into a super-resolution网络，而不是通过DAS扩散和其局限性。为此，我们示出了标签投影和反向点变换 междуB模式和RF坐标空间，以便实现我们的方法。我们根据公共数据集进行比较，结果表明，不包括DAS扩散可以优化ULM的分辨率性能。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Lane-Perception-and-Topology-Understanding-with-Standard-Definition-Navigation-Maps"><a href="#Augmenting-Lane-Perception-and-Topology-Understanding-with-Standard-Definition-Navigation-Maps" class="headerlink" title="Augmenting Lane Perception and Topology Understanding with Standard Definition Navigation Maps"></a>Augmenting Lane Perception and Topology Understanding with Standard Definition Navigation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04079">http://arxiv.org/abs/2311.04079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katie Z Luo, Xinshuo Weng, Yan Wang, Shuang Wu, Jie Li, Kilian Q Weinberger, Yue Wang, Marco Pavone</li>
<li>for: 这种研究旨在替代高解度地图，提高自动驾驶系统的扩展性和可持续性。</li>
<li>methods: 该研究提出了一种新的框架，使得标准分辨率地图（SD map）可以与在线地图预测结合使用，并使用Transformer编码器来利用SD map中的知识来优化干道 topology 预测。</li>
<li>results: 研究表明，该方法可以在当前状态静态方法上提高干道检测和 topology 预测率，最高提高60%，而且不需要额外的硬件或软件。<details>
<summary>Abstract</summary>
Autonomous driving has traditionally relied heavily on costly and labor-intensive High Definition (HD) maps, hindering scalability. In contrast, Standard Definition (SD) maps are more affordable and have worldwide coverage, offering a scalable alternative. In this work, we systematically explore the effect of SD maps for real-time lane-topology understanding. We propose a novel framework to integrate SD maps into online map prediction and propose a Transformer-based encoder, SD Map Encoder Representations from transFormers, to leverage priors in SD maps for the lane-topology prediction task. This enhancement consistently and significantly boosts (by up to 60%) lane detection and topology prediction on current state-of-the-art online map prediction methods without bells and whistles and can be immediately incorporated into any Transformer-based lane-topology method. Code is available at https://github.com/NVlabs/SMERF.
</details>
<details>
<summary>摘要</summary>
自主驾驶曾然依赖高Definition（HD）地图，导致扩展性受限。相比之下，标准Definition（SD）地图更加经济，具有全球覆盖，提供了可扩展的alternative。在这种工作中，我们系统地探讨了SD地图对实时路径理解的效果。我们提出了一种将SD地图 integrate into online map prediction的方案，并提出了基于Transformer的编码器，即SD Map Encoder Representations from transFormers，以利用SD地图中的先验知识 для路径预测任务。这种提高可以在当前领先的online map prediction方法上 consistently 和 significantly 提高（最高60%）路径检测和路径预测，而不需要额外的资源和复杂的设计。代码可以在https://github.com/NVlabs/SMERF上获取。
</details></li>
</ul>
<hr>
<h2 id="Energy-based-Calibrated-VAE-with-Test-Time-Free-Lunch"><a href="#Energy-based-Calibrated-VAE-with-Test-Time-Free-Lunch" class="headerlink" title="Energy-based Calibrated VAE with Test Time Free Lunch"></a>Energy-based Calibrated VAE with Test Time Free Lunch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04071">http://arxiv.org/abs/2311.04071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihong Luo, Siya Qiu, Xingjian Tao, Yujun Cai, Jing Tang</li>
<li>for: 提高 Variational Autoencoders (VAEs) 的生成质量和效率，使其能够在数据和精度培aual samples中进行准确的生成。</li>
<li>methods: 提出了一种 Conditional EBM 模型，通过在训练时对生成方向进行准确的调整，使得生成模型可以在数据和精度培aual samples中进行高质量的生成，而无需在推断阶段进行MCMC抽样。</li>
<li>results: 通过了多种应用，包括图像生成和零码图像修复，并且对比了单步非对抗生成，显示了提出的方法的状态级表现。<details>
<summary>Abstract</summary>
In this paper, we propose a novel Energy-Calibrated Generative Model that utilizes a Conditional EBM for enhancing Variational Autoencoders (VAEs). VAEs are sampling efficient but often suffer from blurry generation results due to the lack of training in the generative direction. On the other hand, Energy-Based Models (EBMs) can generate high-quality samples but require expensive Markov Chain Monte Carlo (MCMC) sampling. To address these issues, we introduce a Conditional EBM for calibrating the generative direction during training, without requiring it for test time sampling. Our approach enables the generative model to be trained upon data and calibrated samples with adaptive weight, thereby enhancing efficiency and effectiveness without necessitating MCMC sampling in the inference phase. We also show that the proposed approach can be extended to calibrate normalizing flows and variational posterior. Moreover, we propose to apply the proposed method to zero-shot image restoration via neural transport prior and range-null theory. We demonstrate the effectiveness of the proposed method through extensive experiments in various applications, including image generation and zero-shot image restoration. Our method shows state-of-the-art performance over single-step non-adversarial generation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的能量均衡生成模型，该模型使用了条件的EBM来提高VAEs的效果。VAEs可以快速采样，但它们通常因缺乏生成方向的训练而导致生成结果不清晰。而EBMs可以生成高质量的样本，但它们需要昂贵的Markov Chain Monte Carlo（MCMC）采样。为了解决这些问题，我们引入了一种条件的EBM，以均衡生成方向的训练，无需测试阶段的MCMC采样。我们的方法可以让生成模型在训练和测试阶段都能够受益于高效的采样，而不需要MCMC采样。此外，我们还证明了我们的方法可以扩展到均衡流程和变量 posterior。此外，我们还提出了在zero-shot图像恢复中应用我们的方法，使用神经运输先验和范围-null理论。我们的实验结果表明，我们的方法可以在不同的应用中达到顶峰性能，包括图像生成和zero-shot图像恢复。
</details></li>
</ul>
<hr>
<h2 id="LISBET-a-self-supervised-Transformer-model-for-the-automatic-segmentation-of-social-behavior-motifs"><a href="#LISBET-a-self-supervised-Transformer-model-for-the-automatic-segmentation-of-social-behavior-motifs" class="headerlink" title="LISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs"></a>LISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04069">http://arxiv.org/abs/2311.04069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giuseppe Chindemi, Benoit Girard, Camilla Bellone<br>for: 本研究旨在更深入地理解社交行为的核心原理，以便更好地理解社交异常的 neural 基础。methods: 本研究使用 LISBET（seLf-supervIsed Social BEhavioral Transformer）模型，通过无需人工标注和特征选择来检测和分类社交互动。results: 研究发现，使用发现驱动模式可以准确地识别和分类社交行为模式，并且与人类注释高度相关。此外，研究还发现了 dopaminergic  neurons 的电physiological 活动与社交行为模式相关。<details>
<summary>Abstract</summary>
Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions. Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning. We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA). We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings.
</details>
<details>
<summary>摘要</summary>
社交行为，定义为个体在响应他人时的行为过程，对社会的 функion 至关重要，对 mental health 也有深刻的意义。为了全面理解社交行为的复杂性和找到可能的治疗目标，需要了解其核心原理。虽然机器学习算法已经使得研究特定方面的复杂行为变得更加容易，但现有方法ologies 往往只关注单个动物的行为。在这种研究中，我们介绍了 LISBET（seLf-supervIsed Social BEhavioral Transformer）模型，用于检测和分类社交交互。我们的模型不需要特征选择和大量的人工标注，可以通过自我超vised learning 检测和评估社交行为。LISBET可以在假设驱动模式下用于自动分类行为，以及在发现驱动模式下用于无监督学习分 segment 社交行为模式。我们发现使用发现驱动模式认定的模式和人工标注几乎完全相符，并且与 dopaminergic neurons 的电physiological 活动在 Ventral Tegmental Area (VTA) 也显示相关性。我们希望 LISBET 能帮助社区更好地理解社交行为和其神经基础。
</details></li>
</ul>
<hr>
<h2 id="mmFUSION-Multimodal-Fusion-for-3D-Objects-Detection"><a href="#mmFUSION-Multimodal-Fusion-for-3D-Objects-Detection" class="headerlink" title="mmFUSION: Multimodal Fusion for 3D Objects Detection"></a>mmFUSION: Multimodal Fusion for 3D Objects Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04058">http://arxiv.org/abs/2311.04058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javed Ahmad, Alessio Del Bue</li>
<li>for: 提高自驾车系统中3D物体检测的准确率，通过多感器融合。</li>
<li>methods: 提出了一种新的中间级多模态融合（mmFUSION）方法，使用每个感知器计算特征，然后通过交叉模态和多模态注意力机制进行融合。</li>
<li>results: 在KITTI和NuScenes dataset上测试，mmFUSION比已有的早期、中间期、晚期和两个阶段融合方案表现更好，并且可以保持多模态信息并通过注意力权重补做模态缺失。<details>
<summary>Abstract</summary>
Multi-sensor fusion is essential for accurate 3D object detection in self-driving systems. Camera and LiDAR are the most commonly used sensors, and usually, their fusion happens at the early or late stages of 3D detectors with the help of regions of interest (RoIs). On the other hand, fusion at the intermediate level is more adaptive because it does not need RoIs from modalities but is complex as the features of both modalities are presented from different points of view. In this paper, we propose a new intermediate-level multi-modal fusion (mmFUSION) approach to overcome these challenges. First, the mmFUSION uses separate encoders for each modality to compute features at a desired lower space volume. Second, these features are fused through cross-modality and multi-modality attention mechanisms proposed in mmFUSION. The mmFUSION framework preserves multi-modal information and learns to complement modalities' deficiencies through attention weights. The strong multi-modal features from the mmFUSION framework are fed to a simple 3D detection head for 3D predictions. We evaluate mmFUSION on the KITTI and NuScenes dataset where it performs better than available early, intermediate, late, and even two-stage based fusion schemes. The code with the mmdetection3D project plugin will be publicly available soon.
</details>
<details>
<summary>摘要</summary>
多感器融合是自动驾驶系统中精准三维物体检测的关键。相机和LiDAR是最常用的感知器，通常在3D检测器的早期或晚期阶段进行融合，使用区域关注（RoIs）的帮助。然而，中间阶段的融合更加适应，因为它不需要modalities中的RoIs，但是计算复杂，因为两种感知器的特征从不同的角度表达。在这篇论文中，我们提出了一种新的中间阶段多模态融合（mmFUSION）方法，以解决这些挑战。首先，mmFUSION使用每种感知器的分立编码器计算特征，以达到所需的更低的空间体积。然后，这些特征通过mmFUSION中的对话机制进行融合。mmFUSION框架保留了多模态信息，并通过注意力权重学习补做感知器的不足。从mmFUSION框架获得的强大多模态特征被传递给简单的3D检测头进行3D预测。我们在KITTI和NuScenes dataset上评估了mmFUSION，其表现比已有的早期、中间、晚期和两个阶段融合方案更好。代码将在near future通过mmdetection3D项目插件公开。
</details></li>
</ul>
<hr>
<h2 id="Generative-Structural-Design-Integrating-BIM-and-Diffusion-Model"><a href="#Generative-Structural-Design-Integrating-BIM-and-Diffusion-Model" class="headerlink" title="Generative Structural Design Integrating BIM and Diffusion Model"></a>Generative Structural Design Integrating BIM and Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04052">http://arxiv.org/abs/2311.04052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili He, Yu-Hsing Wang, Jian Zhang</li>
<li>for: 本研究旨在提出一个全面的解决方案，以帮助智能结构设计使用人工智能（AI）更加有效率，并且可能成为未来的设计新平台。</li>
<li>methods: 本研究提出了三个贡献：首先，引入建筑信息模型（BIM）到智能结构设计中，并建立了一个集成BIM和生成AI的结构设计管道，这是之前的框架仅考虑CAD图纸的唯一解决方案。其次，为了提高生成结果的感知质量和细节，本研究引入了 diffusion models（DMs）来取代广泛使用的生成对抗网络（GAN）模型，并提出了一种基于物理条件的 conditional diffusion model（PCDM）来考虑不同的设计前提。最后，本研究还设计了一个注意块（AB），包括一个自注意块（SAB）和一个并行交叉注意块（PCAB），以便跨领域数据的混合。</li>
<li>results: 对比分析表明，PCDM具有强大的生成和表示能力，并且可以考虑不同的设计前提。必要的ablation研究也进行了，以证明方法的有效性。此外，本研究还表明了DMs的潜在取代GANs的潜在性，成为未来生成问题在 civil engineering 领域的新标准。<details>
<summary>Abstract</summary>
Intelligent structural design using AI can effectively reduce time overhead and increase efficiency. It has potential to become the new design paradigm in the future to assist and even replace engineers, and so it has become a research hotspot in the academic community. However, current methods have some limitations to be addressed, whether in terms of application scope, visual quality of generated results, or evaluation metrics of results. This study proposes a comprehensive solution. Firstly, we introduce building information modeling (BIM) into intelligent structural design and establishes a structural design pipeline integrating BIM and generative AI, which is a powerful supplement to the previous frameworks that only considered CAD drawings. In order to improve the perceptual quality and details of generations, this study makes 3 contributions. Firstly, in terms of generation framework, inspired by the process of human drawing, a novel 2-stage generation framework is proposed to replace the traditional end-to-end framework to reduce the generation difficulty for AI models. Secondly, in terms of generative AI tools adopted, diffusion models (DMs) are introduced to replace widely used generative adversarial network (GAN)-based models, and a novel physics-based conditional diffusion model (PCDM) is proposed to consider different design prerequisites. Thirdly, in terms of neural networks, an attention block (AB) consisting of a self-attention block (SAB) and a parallel cross-attention block (PCAB) is designed to facilitate cross-domain data fusion. The quantitative and qualitative results demonstrate the powerful generation and representation capabilities of PCDM. Necessary ablation studies are conducted to examine the validity of the methods. This study also shows that DMs have the potential to replace GANs and become the new benchmark for generative problems in civil engineering.
</details>
<details>
<summary>摘要</summary>
智能结构设计使用人工智能可以有效减少时间开销并提高效率。它在未来可能成为新的设计 парадигмой，帮助或取代工程师，因此在学术社区中引起了广泛的研究兴趣。然而，当前方法存在一些需要解决的限制，包括应用范围、生成结果的视觉质量和评价指标。本研究提出了一个全面的解决方案。首先，我们将建筑信息模型（BIM）引入智能结构设计，并建立了结构设计管线，将BIM和生成AI相结合，这是前一个框架只考虑CAD图像的扩展。为了提高生成结果的视觉质量和细节，本研究做出了三个贡献。首先，在生成框架方面，根据人类绘制过程的灵感，我们提出了一种新的两阶段生成框架，以降低AI模型生成难度。其次，在生成AI工具方面，我们引入了扩散模型（DM），取代了广泛使用的生成对抗网络（GAN）模型，并提出了一种新的物理基于的条件扩散模型（PCDM），以考虑不同的设计前提。最后，在神经网络方面，我们设计了一个注意块（AB），包括一个自注意块（SAB）和一个平行交叉注意块（PCAB），以便跨领域数据的混合。对于PCDM的量化和质量result，我们进行了必要的ablation研究，以证明方法的有效性。此外，我们还发现了DMs在生成问题中的潜在优势，它们可能取代GANs，成为未来的生成问题的新标准。
</details></li>
</ul>
<hr>
<h2 id="3D-EAGAN-3D-edge-aware-attention-generative-adversarial-network-for-prostate-segmentation-in-transrectal-ultrasound-images"><a href="#3D-EAGAN-3D-edge-aware-attention-generative-adversarial-network-for-prostate-segmentation-in-transrectal-ultrasound-images" class="headerlink" title="3D EAGAN: 3D edge-aware attention generative adversarial network for prostate segmentation in transrectal ultrasound images"></a>3D EAGAN: 3D edge-aware attention generative adversarial network for prostate segmentation in transrectal ultrasound images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04049">http://arxiv.org/abs/2311.04049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengqing Liu, Xiao Shao, Liping Jiang, Kaizhi Wu</li>
<li>for: 这个研究的目的是为了提出一种能够高效地自动对TRUS图像中的膀胱进行分类的方法，以解决膀胱在这些图像中的不明确边界和不均匀的内散照。</li>
<li>methods: 这篇研究提出了一种基于3D edge-aware attention生成 adversarial network（3D EAGAN）的膀胱分类方法，包括一个edge-aware segmentation network（EASNet）和一个判别网络。EASNet包括一个encoder-decoder-based U-Net backbone网络、一个细节补偿模组、四个3D空间和通道对注意模组、一个边缘增强模组和一个全局特征提取器。</li>
<li>results: 这篇研究获得了高度有效地对TRUS图像中的膀胱进行分类的结果，并且比以往的方法有所改善。<details>
<summary>Abstract</summary>
Automatic prostate segmentation in TRUS images has always been a challenging problem, since prostates in TRUS images have ambiguous boundaries and inhomogeneous intensity distribution. Although many prostate segmentation methods have been proposed, they still need to be improved due to the lack of sensibility to edge information. Consequently, the objective of this study is to devise a highly effective prostate segmentation method that overcomes these limitations and achieves accurate segmentation of prostates in TRUS images. A 3D edge-aware attention generative adversarial network (3D EAGAN)-based prostate segmentation method is proposed in this paper, which consists of an edge-aware segmentation network (EASNet) that performs the prostate segmentation and a discriminator network that distinguishes predicted prostates from real prostates. The proposed EASNet is composed of an encoder-decoder-based U-Net backbone network, a detail compensation module, four 3D spatial and channel attention modules, an edge enhance module, and a global feature extractor. The detail compensation module is proposed to compensate for the loss of detailed information caused by the down-sampling process of the encoder. The features of the detail compensation module are selectively enhanced by the 3D spatial and channel attention module. Furthermore, an edge enhance module is proposed to guide shallow layers in the EASNet to focus on contour and edge information in prostates. Finally, features from shallow layers and hierarchical features from the decoder module are fused through the global feature extractor to predict the segmentation prostates.
</details>
<details>
<summary>摘要</summary>
自动脏陵脏分 segmentation 在 TRUS 图像中一直是一个挑战性的问题，因为脏陵脏在 TRUS 图像中有恒定的边缘和不均匀的Intensity 分布。虽然许多脏陵脏分 segmentation 方法已经被提出，但它们仍需要进一步改进，因为缺乏边缘信息的敏感性。这就是本研究的目标，我们提出了一种高效的脏陵脏分 segmentation 方法，能够在 TRUS 图像中准确地分 segmentation 脏陵脏。本文提出的脏陵脏分 segmentation 方法包括一个 Edge-aware 分 segmentation 网络（EASNet），该网络包括一个 U-Net 骨干网络、一个细节补偿模块、四个 3D 空间和通道注意模块、一个 Edge 增强模块和一个全局特征提取器。细节补偿模块的目的是补偿因下采样过程中的细节信息损失。特征选择性地增强了通道和空间注意模块中的特征。此外，为了引导 shallow 层在 EASNet 中注意脏陵脏的沿边信息，我们还提出了 Edge 增强模块。最后，来自 shallow 层和层次特征从 Decoder 模块中的特征被 fusion 通过全局特征提取器来预测脏陵脏的分 segmentation。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Near-Infrared-Hyperspectral-Imaging-for-Protein-Content-Regression-and-Grain-Variety-Classification-Using-Bulk-References-and-Varying-Grain-to-Background-Ratios"><a href="#Analyzing-Near-Infrared-Hyperspectral-Imaging-for-Protein-Content-Regression-and-Grain-Variety-Classification-Using-Bulk-References-and-Varying-Grain-to-Background-Ratios" class="headerlink" title="Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios"></a>Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04042">http://arxiv.org/abs/2311.04042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ole-Christian Galbo Engstrøm, Erik Schou Dreier, Birthe Møller Jespersen, Kim Steenstrup Pedersen</li>
<li>for: 这两个数据集上，使用近红外高 spectral imaging（NIR-HSI）图像来调整模型，强调蛋白质含量预测和种类分类。</li>
<li>methods: 使用抽象和相关联合来扩展有限参考数据，但这会导致预测分布偏离和深度神经网络模型受到影响。提议修正方法来缓解这些偏差，提高蛋白质参考预测的平均值。</li>
<li>results: 研究发现，高比例的麦芽背景对两个任务都有更高的预测精度，但包含较低比例的图像在准备阶段可以增强模型对这些情况的Robustness。<details>
<summary>Abstract</summary>
Based on previous work, we assess the use of NIR-HSI images for calibrating models on two datasets, focusing on protein content regression and grain variety classification. Limited reference data for protein content is expanded by subsampling and associating it with the bulk sample. However, this method introduces significant biases due to skewed leptokurtic prediction distributions, affecting both PLS-R and deep CNN models. We propose adjustments to mitigate these biases, improving mean protein reference predictions. Additionally, we investigate the impact of grain-to-background ratios on both tasks. Higher ratios yield more accurate predictions, but including lower-ratio images in calibration enhances model robustness for such scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Data-exploitation-multi-task-learning-of-object-detection-and-semantic-segmentation-on-partially-annotated-data"><a href="#Data-exploitation-multi-task-learning-of-object-detection-and-semantic-segmentation-on-partially-annotated-data" class="headerlink" title="Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data"></a>Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04040">http://arxiv.org/abs/2311.04040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoàng-Ân Lê, Minh-Tan Pham</li>
<li>for: 学习对象检测和 semantic segmentation两个最受欢迎的视觉任务，从多任务数据中获得共同优化。</li>
<li>methods: 使用多任务数据，每个数据点只有一个任务的部分标注。</li>
<li>results: 通过对多任务学习和知识传播进行比较，发现多任务学习和知识传播在无法同时优化两个任务时具有优势。<details>
<summary>Abstract</summary>
Multi-task partially annotated data where each data point is annotated for only a single task are potentially helpful for data scarcity if a network can leverage the inter-task relationship. In this paper, we study the joint learning of object detection and semantic segmentation, the two most popular vision problems, from multi-task data with partial annotations. Extensive experiments are performed to evaluate each task performance and explore their complementarity when a multi-task network cannot optimize both tasks simultaneously. We propose employing knowledge distillation to leverage joint-task optimization. The experimental results show favorable results for multi-task learning and knowledge distillation over single-task learning and even full supervision scenario. All code and data splits are available at https://github.com/lhoangan/multas
</details>
<details>
<summary>摘要</summary>
多任务部分标注数据，每个数据点只有一个任务的标注，可能对数据缺乏情况有所帮助，如果网络可以利用任务之间的关系。在这篇论文中，我们研究了对象检测和 semantics 分割两个最流行的视觉问题的共同学习，从多任务数据中获得了部分标注。我们进行了广泛的实验来评估每个任务的性能，探索它们之间的补偿性。我们提议使用知识储存来利用共同优化。实验结果显示，多任务学习和知识储存的结果较单任务学习和完全监督情况更好。所有代码和数据分割可以在 GitHub 上获取：https://github.com/lhoangan/multas。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Dataset-Scale-Indicators-of-Data-Quality"><a href="#Exploring-Dataset-Scale-Indicators-of-Data-Quality" class="headerlink" title="Exploring Dataset-Scale Indicators of Data Quality"></a>Exploring Dataset-Scale Indicators of Data Quality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04016">http://arxiv.org/abs/2311.04016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Feuer, Chinmay Hegde</li>
<li>for: 这研究旨在提高计算机视觉基础模型的性能，减少数据量，降低经济和环境成本。</li>
<li>methods: 研究人员提出了改善数据质量可以显著减少数据量的想法。他们认为计算机视觉数据质量可以分解为样本级别和数据集级别的两个组成部分，并且前者已经得到了更多的研究。他们还研究了两个数据集级别的关键因素：标签集设计和分类均衡。</li>
<li>results: 通过监测这些关键指标，研究人员和实践者可以更好地预测模型性能，包括准确率和分布转移robustness。<details>
<summary>Abstract</summary>
Modern computer vision foundation models are trained on massive amounts of data, incurring large economic and environmental costs. Recent research has suggested that improving data quality can significantly reduce the need for data quantity. But what constitutes data quality in computer vision? We posit that the quality of a given dataset can be decomposed into distinct sample-level and dataset-level constituents, and that the former have been more extensively studied than the latter. We ablate the effects of two important dataset-level constituents: label set design, and class balance. By monitoring these constituents using key indicators we provide, researchers and practitioners can better anticipate model performance, measured in terms of its accuracy and robustness to distribution shifts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AGNES-Abstraction-guided-Framework-for-Deep-Neural-Networks-Security"><a href="#AGNES-Abstraction-guided-Framework-for-Deep-Neural-Networks-Security" class="headerlink" title="AGNES: Abstraction-guided Framework for Deep Neural Networks Security"></a>AGNES: Abstraction-guided Framework for Deep Neural Networks Security</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04009">http://arxiv.org/abs/2311.04009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay Dhonthi, Marcello Eiermann, Ernst Moritz Hahn, Vahid Hashemi<br>for: 这篇论文是为了检测深度神经网络（DNNs）中的后门而写的。methods: 该论文使用了一种名为AGNES的工具，用于检测DNNs中的后门。AGNES的原理基于的是。results: 论文表明，AGNES在多个有关的案例研究中表现更好于许多现有的状态 искусственный智能方法。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) are becoming widespread, particularly in safety-critical areas. One prominent application is image recognition in autonomous driving, where the correct classification of objects, such as traffic signs, is essential for safe driving. Unfortunately, DNNs are prone to backdoors, meaning that they concentrate on attributes of the image that should be irrelevant for their correct classification. Backdoors are integrated into a DNN during training, either with malicious intent (such as a manipulated training process, because of which a yellow sticker always leads to a traffic sign being recognised as a stop sign) or unintentional (such as a rural background leading to any traffic sign being recognised as animal crossing, because of biased training data).   In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for image recognition. We discuss the principle approach on which AGNES is based. Afterwards, we show that our tool performs better than many state-of-the-art methods for multiple relevant case studies.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在安全关键领域日益普及，特别是自动驾驶领域。在这个领域中，正确地识别对象，如交通标志，是安全驾驶的关键。然而，DNN受到后门攻击，即它们偏爱特定图像特征，而不是正确识别的对象。这些后门可以在训练过程中被植入，或者是由于偏见的训练数据而产生的。在这篇论文中，我们介绍了一个名为AGNES的工具，用于检测DNN中的后门。我们讲述了AGNES的原则方法。然后，我们展示了我们的工具在多个相关的案例研究中的性能较高。
</details></li>
</ul>
<hr>
<h2 id="Bias-and-Diversity-in-Synthetic-based-Face-Recognition"><a href="#Bias-and-Diversity-in-Synthetic-based-Face-Recognition" class="headerlink" title="Bias and Diversity in Synthetic-based Face Recognition"></a>Bias and Diversity in Synthetic-based Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03970">http://arxiv.org/abs/2311.03970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Huber, Anh Thi Luu, Fadi Boutros, Arjan Kuijper, Naser Damer</li>
<li>for: 这研究探讨了假数据的多样性如何与真实数据的多样性相比，以及生成模型训练数据的分布对假数据的分布的影响。</li>
<li>methods: 该研究使用了三种最新的假数据基于面Recognition模型，并对不同属性（性别、民族、年龄和头部位置）进行了分析。</li>
<li>results: 研究发现，生成器对不同属性的分布具有类似的分布，而且假数据基于模型和真实数据基于模型都存在类似的偏见。然而，通过降低内属性一致性，可以减少偏见。<details>
<summary>Abstract</summary>
Synthetic data is emerging as a substitute for authentic data to solve ethical and legal challenges in handling authentic face data. The current models can create real-looking face images of people who do not exist. However, it is a known and sensitive problem that face recognition systems are susceptible to bias, i.e. performance differences between different demographic and non-demographics attributes, which can lead to unfair decisions. In this work, we investigate how the diversity of synthetic face recognition datasets compares to authentic datasets, and how the distribution of the training data of the generative models affects the distribution of the synthetic data. To do this, we looked at the distribution of gender, ethnicity, age, and head position. Furthermore, we investigated the concrete bias of three recent synthetic-based face recognition models on the studied attributes in comparison to a baseline model trained on authentic data. Our results show that the generator generate a similar distribution as the used training data in terms of the different attributes. With regard to bias, it can be seen that the synthetic-based models share a similar bias behavior with the authentic-based models. However, with the uncovered lower intra-identity attribute consistency seems to be beneficial in reducing bias.
</details>
<details>
<summary>摘要</summary>
人工数据emerges as a substitute for authentic data to address ethical and legal challenges in face recognition. Current models can generate realistic face images of people who do not exist. However, face recognition systems are susceptible to bias, and there are performance differences between different demographic and non-demographic attributes, which can lead to unfair decisions.In this work, we compare the diversity of synthetic face recognition datasets to authentic datasets and investigate how the distribution of the training data of the generative models affects the distribution of the synthetic data. We examine the distribution of gender, ethnicity, age, and head position. Additionally, we compare the concrete bias of three recent synthetic-based face recognition models to a baseline model trained on authentic data.Our results show that the generator produces a similar distribution as the used training data in terms of the different attributes. With regard to bias, the synthetic-based models exhibit a similar bias behavior to the authentic-based models. However, the uncovered lower intra-identity attribute consistency may be beneficial in reducing bias.
</details></li>
</ul>
<hr>
<h2 id="CeCNN-Copula-enhanced-convolutional-neural-networks-in-joint-prediction-of-refraction-error-and-axial-length-based-on-ultra-widefield-fundus-images"><a href="#CeCNN-Copula-enhanced-convolutional-neural-networks-in-joint-prediction-of-refraction-error-and-axial-length-based-on-ultra-widefield-fundus-images" class="headerlink" title="CeCNN: Copula-enhanced convolutional neural networks in joint prediction of refraction error and axial length based on ultra-widefield fundus images"></a>CeCNN: Copula-enhanced convolutional neural networks in joint prediction of refraction error and axial length based on ultra-widefield fundus images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03967">http://arxiv.org/abs/2311.03967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong Zhong, Yang Li, Danjuan Yang, Meiyan Li, Xingyao Zhou, Bo Fu, Catherine C. Liu, A. H. Welsh</li>
<li>for: 该研究旨在提高仪器诊断和诊断抑制方法的准确率，通过利用高级 statistics 方法提取数据中的信息，提高深度学习模型的预测精度。</li>
<li>methods: 该研究使用了一种高级的多变量响应回归模型，其中包括一个高级的 tensor 生成器，以及一种基于 Gaussian copula 的估计方法。这种模型可以利用数据中的相关信息，提高深度学习模型的预测精度。</li>
<li>results: 研究表明，在使用该模型时，可以提高深度学习模型的预测精度，特别是在双重任务中，例如回归预测和分类预测。此外，该模型可以在其他场景下应用，并且可以与其他背景网络结合使用。<details>
<summary>Abstract</summary>
Ultra-widefield (UWF) fundus images are replacing traditional fundus images in screening, detection, prediction, and treatment of complications related to myopia because their much broader visual range is advantageous for highly myopic eyes. Spherical equivalent (SE) is extensively used as the main myopia outcome measure, and axial length (AL) has drawn increasing interest as an important ocular component for assessing myopia. Cutting-edge studies show that SE and AL are strongly correlated. Using the joint information from SE and AL is potentially better than using either separately. In the deep learning community, though there is research on multiple-response tasks with a 3D image biomarker, dependence among responses is only sporadically taken into consideration. Inspired by the spirit that information extracted from the data by statistical methods can improve the prediction accuracy of deep learning models, we formulate a class of multivariate response regression models with a higher-order tensor biomarker, for the bivariate tasks of regression-classification and regression-regression. Specifically, we propose a copula-enhanced convolutional neural network (CeCNN) framework that incorporates the dependence between responses through a Gaussian copula (with parameters estimated from a warm-up CNN) and uses the induced copula-likelihood loss with the backbone CNNs. We establish the statistical framework and algorithms for the aforementioned two bivariate tasks. We show that the CeCNN has better prediction accuracy after adding the dependency information to the backbone models. The modeling and the proposed CeCNN algorithm are applicable beyond the UWF scenario and can be effective with other backbones beyond ResNet and LeNet.
</details>
<details>
<summary>摘要</summary>
ultra-widefield (UWF) fundus images  replacing traditional fundus images in screening, detection, prediction, and treatment of myopia complications because their much broader visual range is advantageous for highly myopic eyes。spherical equivalent (SE) is extensively used as the main myopia outcome measure, and axial length (AL) has drawn increasing interest as an important ocular component for assessing myopia。cutting-edge studies show that SE and AL are strongly correlated。using the joint information from SE and AL is potentially better than using either separately。in the deep learning community, though there is research on multiple-response tasks with a 3D image biomarker, dependence among responses is only sporadically taken into consideration。inspired by the spirit that information extracted from the data by statistical methods can improve the prediction accuracy of deep learning models，we formulate a class of multivariate response regression models with a higher-order tensor biomarker，for the bivariate tasks of regression-classification and regression-regression。specifically，we propose a copula-enhanced convolutional neural network (CeCNN) framework that incorporates the dependence between responses through a Gaussian copula (with parameters estimated from a warm-up CNN) and uses the induced copula-likelihood loss with the backbone CNNs。we establish the statistical framework and algorithms for the aforementioned two bivariate tasks。we show that the CeCNN has better prediction accuracy after adding the dependency information to the backbone models。the modeling and the proposed CeCNN algorithm are applicable beyond the UWF scenario and can be effective with other backbones beyond ResNet and LeNet。
</details></li>
</ul>
<hr>
<h2 id="Fast-Sun-aligned-Outdoor-Scene-Relighting-based-on-TensoRF"><a href="#Fast-Sun-aligned-Outdoor-Scene-Relighting-based-on-TensoRF" class="headerlink" title="Fast Sun-aligned Outdoor Scene Relighting based on TensoRF"></a>Fast Sun-aligned Outdoor Scene Relighting based on TensoRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03965">http://arxiv.org/abs/2311.03965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeonjin Chang, Yearim Kim, Seunghyeon Seo, Jung Yi, Nojun Kwak</li>
<li>for: 这个论文是为了推广Neural Radiance Fields（NeRF）中的户外场景重新照明方法，即Sun-aligned Relighting TensoRF（SR-TensoRF）。</li>
<li>methods: SR-TensoRF使用了一种轻量级、快速的管道，并将阳光方向作为输入，以实现简化的推理过程。此外，SR-TensoRF还利用了TensoRF的培育效率，通过我们提出的立方体图案，从而实现了对training和rendering过程的显著加速。</li>
<li>results: SR-TensoRF可以快速地生成高质量的户外场景图像，并且可以在不同的视点下实现高度一致的重新照明效果。<details>
<summary>Abstract</summary>
In this work, we introduce our method of outdoor scene relighting for Neural Radiance Fields (NeRF) named Sun-aligned Relighting TensoRF (SR-TensoRF). SR-TensoRF offers a lightweight and rapid pipeline aligned with the sun, thereby achieving a simplified workflow that eliminates the need for environment maps. Our sun-alignment strategy is motivated by the insight that shadows, unlike viewpoint-dependent albedo, are determined by light direction. We directly use the sun direction as an input during shadow generation, simplifying the requirements of the inference process significantly. Moreover, SR-TensoRF leverages the training efficiency of TensoRF by incorporating our proposed cubemap concept, resulting in notable acceleration in both training and rendering processes compared to existing methods.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了一种用于外部场景照明的神经辐射场（NeRF）方法，名为太阳Alignment Relighting TensoRF（SR-TensoRF）。 SR-TensoRF提供了一个轻量级、快速的管道，同时与太阳方向相对应，因此实现了简化的工作流程，消除了环境地图的需求。我们的太阳Alignment策略受到了光线方向确定影子的直观，因此在影子生成过程中直接使用太阳方向作为输入， thereby significantly simplifying the requirements of the inference process。此外，SR-TensoRF利用了TensoRF的训练效率，通过我们的提议的立方体地图概念，从而在训练和渲染过程中实现了明显的加速。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Multimodal-Compositional-Reasoning-of-Visual-Language-Models-with-Generative-Negative-Mining"><a href="#Enhancing-Multimodal-Compositional-Reasoning-of-Visual-Language-Models-with-Generative-Negative-Mining" class="headerlink" title="Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining"></a>Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03964">http://arxiv.org/abs/2311.03964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ugorsahin/Generative-Negative-Mining">https://github.com/ugorsahin/Generative-Negative-Mining</a></li>
<li>paper_authors: Ugur Sahin, Hang Li, Qadeer Khan, Daniel Cremers, Volker Tresp</li>
<li>for: 提高大规模视语言模型（VLM）在多模态组合理解任务中的表现。</li>
<li>methods: 提出了一种框架，该框架不仅在两个方向中挖掘负例，还可以生成多模态困难负样本，以提高VLM的多模态组合理解能力。</li>
<li>results: 通过利用这些生成的困难负样本，可以significantly enhance VLMs的表现在多模态组合理解任务中。<details>
<summary>Abstract</summary>
Contemporary large-scale visual language models (VLMs) exhibit strong representation capacities, making them ubiquitous for enhancing image and text understanding tasks. They are often trained in a contrastive manner on a large and diverse corpus of images and corresponding text captions scraped from the internet. Despite this, VLMs often struggle with compositional reasoning tasks which require a fine-grained understanding of the complex interactions of objects and their attributes. This failure can be attributed to two main factors: 1) Contrastive approaches have traditionally focused on mining negative examples from existing datasets. However, the mined negative examples might not be difficult for the model to discriminate from the positive. An alternative to mining would be negative sample generation 2) But existing generative approaches primarily focus on generating hard negative texts associated with a given image. Mining in the other direction, i.e., generating negative image samples associated with a given text has been ignored. To overcome both these limitations, we propose a framework that not only mines in both directions but also generates challenging negative samples in both modalities, i.e., images and texts. Leveraging these generative hard negative samples, we significantly enhance VLMs' performance in tasks involving multimodal compositional reasoning. Our code and dataset are released at https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html.
</details>
<details>
<summary>摘要</summary>
现代大规模视觉语言模型（VLM）表现出强大的表示能力，使其在图像和文本理解任务中普遍应用。它们通常通过对大量和多样化的图像和相关文本描述进行对比式训练。然而，VLM frequently struggles with compositional reasoning tasks，这些任务需要细致地理解对象和其属性之间的复杂交互。这种失败可以归结于两个主要因素：1）对比式方法通常是从现有数据集中挖掘负例的，但这些挖掘出来的负例可能并不是模型很难分辨出来的。2）现有的生成方法主要是生成与给定图像关联的困难文本样本，但生成在另一个方向的负样本，即与给定文本关联的困难图像样本，被忽略了。为了超越这些限制，我们提出了一个框架，不仅挖掘在两个方向，而且生成了图像和文本中的困难负样本。利用这些生成的困难负样本，我们可以在多模态 compositional reasoning 任务中显著提高 VLM 的表现。我们的代码和数据集可以在 <https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Effectiveness-of-Deep-Generative-Data"><a href="#Improving-the-Effectiveness-of-Deep-Generative-Data" class="headerlink" title="Improving the Effectiveness of Deep Generative Data"></a>Improving the Effectiveness of Deep Generative Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03959">http://arxiv.org/abs/2311.03959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyu Wang, Sabrina Schmedding, Marco F. Huber</li>
<li>for: 本研究旨在解释在使用深度生成模型（DGM）生成的 sintetic 图像中，downstream 图像处理任务（如图像分类）时的性能下降的原因。</li>
<li>methods: 我们提出了一种新的分类法，可以更好地利用 DGM 生成的 sintetic 图像来提高 downstream 任务的性能。我们采用了一种内容差异（Content Gap）的概念，以解释在使用 sintetic 图像时，性能下降的原因。</li>
<li>results: 我们在 CIFAR-10  dataset 上进行了广泛的实验，并证明了我们的方法在 Synthetic-to-Real 和 Data Augmentation 两种情况下都能够升高 downstream 任务的性能，特别是在数据缺乏的情况下。<details>
<summary>Abstract</summary>
Recent deep generative models (DGMs) such as generative adversarial networks (GANs) and diffusion probabilistic models (DPMs) have shown their impressive ability in generating high-fidelity photorealistic images. Although looking appealing to human eyes, training a model on purely synthetic images for downstream image processing tasks like image classification often results in an undesired performance drop compared to training on real data. Previous works have demonstrated that enhancing a real dataset with synthetic images from DGMs can be beneficial. However, the improvements were subjected to certain circumstances and yet were not comparable to adding the same number of real images. In this work, we propose a new taxonomy to describe factors contributing to this commonly observed phenomenon and investigate it on the popular CIFAR-10 dataset. We hypothesize that the Content Gap accounts for a large portion of the performance drop when using synthetic images from DGM and propose strategies to better utilize them in downstream tasks. Extensive experiments on multiple datasets showcase that our method outperforms baselines on downstream classification tasks both in case of training on synthetic only (Synthetic-to-Real) and training on a mix of real and synthetic data (Data Augmentation), particularly in the data-scarce scenario.
</details>
<details>
<summary>摘要</summary>
现代深度生成模型（DGM），如生成对抗网络（GAN）和扩散概率模型（DPM），已经显示出生成高品质图像的能力。虽然看上去很有趣，但是在尝试使用假图像来进行下游图像处理任务，如图像分类，通常会导致性能下降。先前的工作表明，可以通过混合真实图像和生成图像来提高模型的性能。然而，这些改进受到某些条件的限制，并且与添加相同数量的真实图像相比，未能达到相同的水平。在这项工作中，我们提出了一个新的分类法，描述了使用DGM生成的假图像在下游任务中的常见现象，并在Popular CIFAR-10 dataset上进行了广泛的实验。我们认为，内容差距占了大量的性能下降，当使用DGM生成的假图像时。我们提出了一些策略，以更好地利用它们在下游任务中。我们的方法在多个数据集上比基eline表现出色，特别是在数据缺乏的情况下。
</details></li>
</ul>
<hr>
<h2 id="CLIP-Guided-Image-perceptive-Prompt-Learning-for-Image-Enhancement"><a href="#CLIP-Guided-Image-perceptive-Prompt-Learning-for-Image-Enhancement" class="headerlink" title="CLIP Guided Image-perceptive Prompt Learning for Image Enhancement"></a>CLIP Guided Image-perceptive Prompt Learning for Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03943">http://arxiv.org/abs/2311.03943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zinuo Li, Qiuhong Ke, Weiwen Chen</li>
<li>for: 这篇论文主要旨在提出一种基于对比语言图像预训练（CLIP）引导的图像提升方法，即CLIP-LUT方法。</li>
<li>methods: 这种方法使用CLIP模型学习图像感知提示，并在这些提示基础之上建立一个非常简单的网络，用于预测三种不同的Look-up-table（LUT）权重。</li>
<li>results: 研究发现，通过将CLIP模型的先验知识引入图像提升过程，可以提高图像质量。具体来说，通过使用CLIP模型学习图像感知提示，并将其用作图像提升网络的损失函数，可以获得满意的结果。<details>
<summary>Abstract</summary>
Image enhancement is a significant research area in the fields of computer vision and image processing. In recent years, many learning-based methods for image enhancement have been developed, where the Look-up-table (LUT) has proven to be an effective tool. In this paper, we delve into the potential of Contrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning, proposing a simple structure called CLIP-LUT for image enhancement. We found that the prior knowledge of CLIP can effectively discern the quality of degraded images, which can provide reliable guidance. To be specific, We initially learn image-perceptive prompts to distinguish between original and target images using CLIP model, in the meanwhile, we introduce a very simple network by incorporating a simple baseline to predict the weights of three different LUT as enhancement network. The obtained prompts are used to steer the enhancement network like a loss function and improve the performance of model. We demonstrate that by simply combining a straightforward method with CLIP, we can obtain satisfactory results.
</details>
<details>
<summary>摘要</summary>
<SYS>    translate_language=zh-Hans</SYS>Image enhancement is a significant research area in the fields of computer vision and image processing. In recent years, many learning-based methods for image enhancement have been developed, where the Look-up-table (LUT) has proven to be an effective tool. In this paper, we delve into the potential of Contrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning, proposing a simple structure called CLIP-LUT for image enhancement. We found that the prior knowledge of CLIP can effectively discern the quality of degraded images, which can provide reliable guidance. To be specific, We initially learn image-perceptive prompts to distinguish between original and target images using CLIP model, in the meanwhile, we introduce a very simple network by incorporating a simple baseline to predict the weights of three different LUT as enhancement network. The obtained prompts are used to steer the enhancement network like a loss function and improve the performance of model. We demonstrate that by simply combining a straightforward method with CLIP, we can obtain satisfactory results.
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-NaN-Divergence-in-Training-Monocular-Depth-Estimation-Model"><a href="#Analysis-of-NaN-Divergence-in-Training-Monocular-Depth-Estimation-Model" class="headerlink" title="Analysis of NaN Divergence in Training Monocular Depth Estimation Model"></a>Analysis of NaN Divergence in Training Monocular Depth Estimation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03938">http://arxiv.org/abs/2311.03938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bum Jun Kim, Hyeonah Jang, Sang Woo Kim<br>for: 本研究旨在探讨NaN损失在单目深度估计网络训练中的发生原因，并提供了避免NaN损失的实践指南。methods: 本研究使用了深度学习的最新进展，对单目深度估计网络进行了深入分析，并发现了三种NaN损失的原因：1）使用平方根损失函数会导致梯度不稳定; 2）使用Logsigmoid函数会导致数学上的稳定问题; 3） certain variance implementations会导致计算错误。results:  experiments表明，遵循我们的指南可以提高单目深度估计网络的优化稳定性和性能。<details>
<summary>Abstract</summary>
The latest advances in deep learning have facilitated the development of highly accurate monocular depth estimation models. However, when training a monocular depth estimation network, practitioners and researchers have observed not a number (NaN) loss, which disrupts gradient descent optimization. Although several practitioners have reported the stochastic and mysterious occurrence of NaN loss that bothers training, its root cause is not discussed in the literature. This study conducted an in-depth analysis of NaN loss during training a monocular depth estimation network and identified three types of vulnerabilities that cause NaN loss: 1) the use of square root loss, which leads to an unstable gradient; 2) the log-sigmoid function, which exhibits numerical stability issues; and 3) certain variance implementations, which yield incorrect computations. Furthermore, for each vulnerability, the occurrence of NaN loss was demonstrated and practical guidelines to prevent NaN loss were presented. Experiments showed that both optimization stability and performance on monocular depth estimation could be improved by following our guidelines.
</details>
<details>
<summary>摘要</summary>
最新的深度学习技术发展已经为单目深度估计模型提供了非常高精度。然而，在训练单目深度估计网络时，实践者和研究人员经常会遇到NaN损失，这会阻碍梯度下降优化。虽然许多实践者已经报告了随机和神秘的NaN损失现象，但是在文献中没有讨论这个根本问题的原因。本研究对单目深度估计网络训练中的NaN损失进行了深入分析，并确定了三种导致NaN损失的漏洞：1）使用平方根损失，导致梯度不稳定; 2）使用对数 sigmoid 函数，存在数学上的稳定性问题; 3）某些变量实现方式会导致错误计算。此外，对每种漏洞的NaN损失的发生和避免方法都进行了实践和推荐。实验结果表明，遵循我们的指南可以提高优化稳定性和单目深度估计性能。
</details></li>
</ul>
<hr>
<h2 id="FLORA-Fine-grained-Low-Rank-Architecture-Search-for-Vision-Transformer"><a href="#FLORA-Fine-grained-Low-Rank-Architecture-Search-for-Vision-Transformer" class="headerlink" title="FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer"></a>FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03912">http://arxiv.org/abs/2311.03912</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shadowpa0327/flora">https://github.com/shadowpa0327/flora</a></li>
<li>paper_authors: Chi-Chih Chang, Yuan-Yao Sung, Shixing Yu, Ning-Chi Huang, Diana Marculescu, Kai-Chiang Wu</li>
<li>for: 这个论文的目的是提出一种自动化ViT搜索空间中的低级别搜索方法，以提高ViT模型的计算效率。</li>
<li>methods: 这个论文使用了一种基于NAS的端到端自动框架， named FLORA，以解决低级别搜索空间中的设计挑战。它使用了一种基于矩阵的低级别搜索策略，并采用了一种低级别特性训练方法来提高低级别模型的质量。</li>
<li>results: 论文的实验结果表明，FLORA可以自动生成更细化的低级别配置，并可以在不同的模型和任务上实现33%左右的计算开销减少。此外，FLORA还可以与其他压缩技术或紧凑结构结合使用，实现Extra 21%-26%的计算开销减少。<details>
<summary>Abstract</summary>
Vision Transformers (ViT) have recently demonstrated success across a myriad of computer vision tasks. However, their elevated computational demands pose significant challenges for real-world deployment. While low-rank approximation stands out as a renowned method to reduce computational loads, efficiently automating the target rank selection in ViT remains a challenge. Drawing from the notable similarity and alignment between the processes of rank selection and One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based on NAS. To overcome the design challenge of supernet posed by vast search space, FLORA employs a low-rank aware candidate filtering strategy. This method adeptly identifies and eliminates underperforming candidates, effectively alleviating potential undertraining and interference among subnetworks. To further enhance the quality of low-rank supernets, we design a low-rank specific training paradigm. First, we propose weight inheritance to construct supernet and enable gradient sharing among low-rank modules. Secondly, we adopt low-rank aware sampling to strategically allocate training resources, taking into account inherited information from pre-trained models. Empirical results underscore FLORA's efficacy. With our method, a more fine-grained rank configuration can be generated automatically and yield up to 33% extra FLOPs reduction compared to a simple uniform configuration. More specific, FLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without performance degradtion. Importantly, FLORA boasts both versatility and orthogonality, offering an extra 21%-26% FLOPs reduction when integrated with leading compression techniques or compact hybrid structures. Our code is publicly available at https://github.com/shadowpa0327/FLORA.
</details>
<details>
<summary>摘要</summary>
vision transformers (ViT) 在多种计算机视觉任务上已经表现出色，但它们的计算负担却是实际应用中的一大挑战。而且，可靠地自动选择目标排名在ViT中仍然是一个挑战。Drawing from the notable similarity and alignment between the processes of rank selection and One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based on NAS. To overcome the design challenge of supernet posed by vast search space, FLORA employs a low-rank aware candidate filtering strategy. This method adeptly identifies and eliminates underperforming candidates, effectively alleviating potential undertraining and interference among subnetworks. To further enhance the quality of low-rank supernets, we design a low-rank specific training paradigm. First, we propose weight inheritance to construct supernet and enable gradient sharing among low-rank modules. Secondly, we adopt low-rank aware sampling to strategically allocate training resources, taking into account inherited information from pre-trained models. Empirical results underscore FLORA's efficacy. With our method, a more fine-grained rank configuration can be generated automatically and yield up to 33% extra FLOPs reduction compared to a simple uniform configuration. More specific, FLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without performance degradation. Importantly, FLORA boasts both versatility and orthogonality, offering an extra 21%-26% FLOPs reduction when integrated with leading compression techniques or compact hybrid structures. Our code is publicly available at https://github.com/shadowpa0327/FLORA.
</details></li>
</ul>
<hr>
<h2 id="RobustMat-Neural-Diffusion-for-Street-Landmark-Patch-Matching-under-Challenging-Environments"><a href="#RobustMat-Neural-Diffusion-for-Street-Landmark-Patch-Matching-under-Challenging-Environments" class="headerlink" title="RobustMat: Neural Diffusion for Street Landmark Patch Matching under Challenging Environments"></a>RobustMat: Neural Diffusion for Street Landmark Patch Matching under Challenging Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03904">http://arxiv.org/abs/2311.03904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-it-avs/robustmat">https://github.com/ai-it-avs/robustmat</a></li>
<li>paper_authors: Rui She, Qiyu Kang, Sijie Wang, Yuan-Rui Yang, Kai Zhao, Yang Song, Wee Peng Tay</li>
<li>for: 这篇论文主要针对自动驾驶车辆（AV）的视觉识别技术进行研究，以寻找在不同季节、天气和照明条件下的可靠匹配方法。</li>
<li>methods: 该论文提出了一种名为RobustMat的方法，该方法利用摄像头上的图像缓冲区域的空间邻居信息，以提高匹配的稳定性。具体来说，该方法首先使用卷积神经网络演化方法学习图像缓冲区域的特征表示。然后，使用图像街景数据库中的其他图像来归一化图像缓冲区域的信息。最后，通过对图像缓冲区域之间的特征相似性进行学习，计算出最终的匹配分数。</li>
<li>results: 该论文的实验结果表明，RobustMat方法在不同季节、天气和照明条件下能够实现高级别的匹配效果，并且比传统的方法更具有稳定性。<details>
<summary>Abstract</summary>
For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.Translated into Traditional Chinese: For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.
</details></li>
</ul>
<hr>
<h2 id="MeVGAN-GAN-based-Plugin-Model-for-Video-Generation-with-Applications-in-Colonoscopy"><a href="#MeVGAN-GAN-based-Plugin-Model-for-Video-Generation-with-Applications-in-Colonoscopy" class="headerlink" title="MeVGAN: GAN-based Plugin Model for Video Generation with Applications in Colonoscopy"></a>MeVGAN: GAN-based Plugin Model for Video Generation with Applications in Colonoscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03884">http://arxiv.org/abs/2311.03884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Łukasz Struski, Tomasz Urbańczyk, Krzysztof Bucki, Bartłomiej Cupiał, Aneta Kaczyńska, Przemysław Spurek, Jacek Tabor</li>
<li>for: 这篇论文的目的是提出一种能够生成高分辨率视频的生成模型，以解决现有的生成模型具有大量存储需求的问题。</li>
<li>methods: 该论文提出了一种插件型架构的生成 adversarial network（GAN），称为Memory Efficient Video GAN（MeVGAN）。该模型使用预训练的2D图像GAN，并只添加了一个简单的神经网络来构造噪声空间中的轨迹，以便在GAN模型中构造真实的视频。</li>
<li>results: 该论文应用MeVGAN模型在colonoscopy视频生成任务中，并显示了MeVGAN可以生成高质量的synthetic colonoscopy视频，可能用于虚拟 simulate器中。colonoscopy是一项重要的医疗程序，尤其是在检测和治疗肠Rectal Cancer中起着重要作用。但是，因为colonoscopy是一项复杂和时间consuming的学习过程，因此colonoscopy simulators在培养年轻的colonoscopists中广泛使用。<details>
<summary>Abstract</summary>
Video generation is important, especially in medicine, as much data is given in this form. However, video generation of high-resolution data is a very demanding task for generative models, due to the large need for memory. In this paper, we propose Memory Efficient Video GAN (MeVGAN) - a Generative Adversarial Network (GAN) which uses plugin-type architecture. We use a pre-trained 2D-image GAN and only add a simple neural network to construct respective trajectories in the noise space, so that the trajectory forwarded through the GAN model constructs a real-life video. We apply MeVGAN in the task of generating colonoscopy videos. Colonoscopy is an important medical procedure, especially beneficial in screening and managing colorectal cancer. However, because colonoscopy is difficult and time-consuming to learn, colonoscopy simulators are widely used in educating young colonoscopists. We show that MeVGAN can produce good quality synthetic colonoscopy videos, which can be potentially used in virtual simulators.
</details>
<details>
<summary>摘要</summary>
视频生成对医学领域来说非常重要，因为大量数据都是以这种形式提供。然而，生成高分辨率视频是对生成模型的很大负担，因为需要很大的内存。在这篇论文中，我们提出了内存高效的视频GAN（MeVGAN）——一种生成对抗网络（GAN）。我们使用预训练的2D图像GAN，只是将简单的神经网络添加到静止图像空间中，以便在噪声空间中构造真实的视频。我们在检查colonoscopy视频生成任务中应用MeVGAN。colonoscopy是医学重要的过程，尤其是在检测和管理肠RECTAL癌中。然而，因为colonoscopy是学习复杂且时间consuming的，因此colonoscopy模拟器广泛使用在教育年轻colonoscopists。我们显示MeVGAN可以生成高质量的 sintetic colonoscopy视频，可以在虚拟模拟器中使用。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Knowledge-Transfer-Methods-for-Misaligned-Urban-Building-Labels"><a href="#A-Comparative-Study-of-Knowledge-Transfer-Methods-for-Misaligned-Urban-Building-Labels" class="headerlink" title="A Comparative Study of Knowledge Transfer Methods for Misaligned Urban Building Labels"></a>A Comparative Study of Knowledge Transfer Methods for Misaligned Urban Building Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03867">http://arxiv.org/abs/2311.03867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bipul Neupane, Jagannath Aryal, Abbas Rajabifard</li>
<li>for:  Addressing the misalignment issue in Earth observation (EO) images and building labels to train accurate convolutional neural networks (CNNs) for semantic segmentation of building footprints.</li>
<li>methods:  Comparative study of three Teacher-Student knowledge transfer methods: supervised domain adaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML).</li>
<li>results:  SDA is the most effective method to address the misalignment problem, while KD and DML can efficiently compress network size without significant loss in performance. The 158 experiments and datasets developed in this study will be valuable to minimise the misaligned labels.Here’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope that helps!<details>
<summary>Abstract</summary>
Misalignment in Earth observation (EO) images and building labels impact the training of accurate convolutional neural networks (CNNs) for semantic segmentation of building footprints. Recently, three Teacher-Student knowledge transfer methods have been introduced to address this issue: supervised domain adaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML). However, these methods are merely studied for different urban buildings (low-rise, mid-rise, high-rise, and skyscrapers), where misalignment increases with building height and spatial resolution. In this study, we present a workflow for the systematic comparative study of the three methods. The workflow first identifies the best (with the highest evaluation scores) hyperparameters, lightweight CNNs for the Student (among 43 CNNs from Computer Vision), and encoder-decoder networks (EDNs) for both Teachers and Students. Secondly, three building footprint datasets are developed to train and evaluate the identified Teachers and Students in the three transfer methods. The results show that U-Net with VGG19 (U-VGG19) is the best Teacher, and U-EfficientNetv2B3 and U-EfficientNet-lite0 are among the best Students. With these Teacher-Student pairs, SDA could yield upto 0.943, 0.868, 0.912, and 0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers respectively. KD and DML provide model compression of upto 82%, despite marginal loss in performance. This new comparison concludes that SDA is the most effective method to address the misalignment problem, while KD and DML can efficiently compress network size without significant loss in performance. The 158 experiments and datasets developed in this study will be valuable to minimise the misaligned labels.
</details>
<details>
<summary>摘要</summary>
地球观测（EO）图像和建筑标签的不一致问题会对准确的 convolutional neural networks（CNNs）的 semantic segmentation培训产生影响。最近，三种教师-学生知识传递方法被提出来解决这个问题：指导适应（SDA）、知识传递（KD）和深度相互学习（DML）。然而，这些方法只在不同的城市建筑（低层、中层、高层和尖塔）进行了研究，而这些建筑的不一致问题随着建筑高度和空间分辨率增加。在这种研究中，我们提出了一个系统性比较工作流程。首先，我们确定了最佳（最高评价分）的参数、轻量级 CNNs（从计算机视觉中选择的43个 CNNs）和编码器-解码器网络（EDNs） для两个教师和学生。其次，我们开发了三个建筑涂抹数据集，用于培训和评价确定的教师和学生。结果显示，U-Net with VGG19（U-VGG19）是最佳教师，而U-EfficientNetv2B3和U-EfficientNet-lite0是最佳学生。与这些教师-学生对照对照，SDA可以获得最高的0.943、0.868、0.912和0.697的F1分数。KD和DML可以压缩网络大小，但是只有82%的压缩。这个新的比较结论是，SDA是解决不一致标签问题的最佳方法，而KD和DML可以高效地压缩网络大小，而无损失性能。这些158个实验和开发的数据集将有助于减少不一致标签问题。
</details></li>
</ul>
<hr>
<h2 id="SCONE-GAN-Semantic-Contrastive-learning-based-Generative-Adversarial-Network-for-an-end-to-end-image-translation"><a href="#SCONE-GAN-Semantic-Contrastive-learning-based-Generative-Adversarial-Network-for-an-end-to-end-image-translation" class="headerlink" title="SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial Network for an end-to-end image translation"></a>SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial Network for an end-to-end image translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03866">http://arxiv.org/abs/2311.03866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iman Abbasnejad, Fabio Zambetta, Flora Salim, Timothy Wiley, Jeffrey Chan, Russell Gallagher, Ehsan Abbasnejad</li>
<li>for: 这篇论文旨在实现图像翻译，以生成真实和多样化的景观图像。</li>
<li>methods: 该方法使用图像树减少网络学习图像结构和 semantics，同时维持图像的真实性。它还引入了风格引用图像，以便增加更多的多样性。</li>
<li>results: 对四个 dataset 进行评估，qualitative 和 quantitative 结果都表明该方法可以生成更真实和多样化的图像。<details>
<summary>Abstract</summary>
SCONE-GAN presents an end-to-end image translation, which is shown to be effective for learning to generate realistic and diverse scenery images. Most current image-to-image translation approaches are devised as two mappings: a translation from the source to target domain and another to represent its inverse. While successful in many applications, these approaches may suffer from generating trivial solutions with limited diversity. That is because these methods learn more frequent associations rather than the scene structures. To mitigate the problem, we propose SCONE-GAN that utilises graph convolutional networks to learn the objects dependencies, maintain the image structure and preserve its semantics while transferring images into the target domain. For more realistic and diverse image generation we introduce style reference image. We enforce the model to maximize the mutual information between the style image and output. The proposed method explicitly maximizes the mutual information between the related patches, thus encouraging the generator to produce more diverse images. We validate the proposed algorithm for image-to-image translation and stylizing outdoor images. Both qualitative and quantitative results demonstrate the effectiveness of our approach on four dataset.
</details>
<details>
<summary>摘要</summary>
SCONE-GAN 提出了一种端到端图像翻译方法，可以学习生成真实和多样化的景观图像。现有的图像到图像翻译方法通常是分为两个映射：一个从源领域到目标领域的翻译，以及另一个用于表示其 inverse。虽然在许多应用程序中成功，但这些方法可能会导致生成质量偏低、有限多样性的图像。这是因为这些方法学习更频繁的相关性，而不是场景结构。为了解决这个问题，我们提出了 SCONE-GAN，它使用图像卷积网络学习物体的依赖关系，保持图像结构，并保持图像的 semantics while transferring images into the target domain。为了更真实和多样的图像生成，我们引入了风格参照图像。我们强制模型使得输出和风格参照图像之间的共聚信息最大化。这使得生成器更有可能生成更多样的图像。我们验证了我们的方法在图像到图像翻译和图像风格化方面的效果，并取得了四个数据集的质量和量化结果，都表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Multi-view-Information-Integration-and-Propagation-for-Occluded-Person-Re-identification"><a href="#Multi-view-Information-Integration-and-Propagation-for-Occluded-Person-Re-identification" class="headerlink" title="Multi-view Information Integration and Propagation for Occluded Person Re-identification"></a>Multi-view Information Integration and Propagation for Occluded Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03828">http://arxiv.org/abs/2311.03828</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nengdong96/mviip">https://github.com/nengdong96/mviip</a></li>
<li>paper_authors: Neng Dong, Shuanglin Yan, Hao Tang, Jinhui Tang, Liyan Zhang</li>
<li>for: 本研究 targets at the challenging task of occluded person re-identification, and aims to effectively utilize multi-view images to characterize the occluded target pedestrian.</li>
<li>methods: 提出了一个名为 Multi-view Information Integration and Propagation (MVI$^{2}$P) 的新框架，具有统一特征地图，选择性地 инте그储��unted information，以及优化的资讯传播机制。</li>
<li>results: 经过广泛的实验和分析，确认了提案的优越性和有效性，并且可以在实际应用中提高人员识别率。<details>
<summary>Abstract</summary>
Occluded person re-identification (re-ID) presents a challenging task due to occlusion perturbations. Although great efforts have been made to prevent the model from being disturbed by occlusion noise, most current solutions only capture information from a single image, disregarding the rich complementary information available in multiple images depicting the same pedestrian. In this paper, we propose a novel framework called Multi-view Information Integration and Propagation (MVI$^{2}$P). Specifically, realizing the potential of multi-view images in effectively characterizing the occluded target pedestrian, we integrate feature maps of which to create a comprehensive representation. During this process, to avoid introducing occlusion noise, we develop a CAMs-aware Localization module that selectively integrates information contributing to the identification. Additionally, considering the divergence in the discriminative nature of different images, we design a probability-aware Quantification module to emphatically integrate highly reliable information. Moreover, as multiple images with the same identity are not accessible in the testing stage, we devise an Information Propagation (IP) mechanism to distill knowledge from the comprehensive representation to that of a single occluded image. Extensive experiments and analyses have unequivocally demonstrated the effectiveness and superiority of the proposed MVI$^{2}$P. The code will be released at \url{https://github.com/nengdong96/MVIIP}.
</details>
<details>
<summary>摘要</summary>
受遮挡干扰的人脸重新识别（re-ID）问题具有挑战性，尽管大量努力已经用于避免遮挡噪音的影响，但大多数当前解决方案只是利用单个图像中的信息。在这篇论文中，我们提出了一种新的框架，即多视图信息集成和传播（MVI$^{2}$P）。具体来说，我们利用多视图图像来有效地描述受遮挡目标人脸，然后将这些特征图像集成成一个完整的表示。在这个过程中，我们开发了一个自适应 Camera-Aware Localization 模块，以选择ively 集成有助于识别的信息。此外，我们还设计了一个可靠性感知 Quantification 模块，以强调集成信息的可靠性。最后，在测试阶段不可获得多个图像的同一个标识者，我们提出了信息传播（IP）机制，以储存知识从完整表示中传递到受遮挡图像上。我们的实验和分析证明了 MVI$^{2}$P 的有效性和优势。代码将在 GitHub 上发布，链接如下：https://github.com/nengdong96/MVIIP。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Any-Human-Object-Interaction-Relationship-Universal-HOI-Detector-with-Spatial-Prompt-Learning-on-Foundation-Models"><a href="#Detecting-Any-Human-Object-Interaction-Relationship-Universal-HOI-Detector-with-Spatial-Prompt-Learning-on-Foundation-Models" class="headerlink" title="Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models"></a>Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03799">http://arxiv.org/abs/2311.03799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Caoyichao/UniHOI">https://github.com/Caoyichao/UniHOI</a></li>
<li>paper_authors: Yichao Cao, Qingfei Tang, Xiu Su, Chen Song, Shan You, Xiaobo Lu, Chang Xu</li>
<li>for: 本研究旨在开探人物互动探测（HOI）识别在开放世界 Setting中的普遍性识别，透过视觉语言基础模型和大型语言模型（LLM）的结合，提高HOI识别的精度和效率。</li>
<li>methods: 本研究提出了一个名为UniHOI的方法，包括一个HO Prompt-guided Decoder（HOPD），将高水平关系表示与不同的HO对应对象之间的关系紧密相连，以及一个大型自然语言处理器（GPT），将互动的语言理解为更加丰富和复杂的概念。</li>
<li>results: 本研究的结果显示，UniHOI可以在不同的输入类型和类别下进行开放世界 Setting中的HOI识别，并且在对照方法的超过30%的测试数据上表现出显著的改善。代码和预训练组件可以在：<a target="_blank" rel="noopener" href="https://github.com/Caoyichao/UniHOI%E3%80%82">https://github.com/Caoyichao/UniHOI。</a><details>
<summary>Abstract</summary>
Human-object interaction (HOI) detection aims to comprehend the intricate relationships between humans and objects, predicting $<human, action, object>$ triplets, and serving as the foundation for numerous computer vision tasks. The complexity and diversity of human-object interactions in the real world, however, pose significant challenges for both annotation and recognition, particularly in recognizing interactions within an open world context. This study explores the universal interaction recognition in an open-world setting through the use of Vision-Language (VL) foundation models and large language models (LLMs). The proposed method is dubbed as \emph{\textbf{UniHOI}. We conduct a deep analysis of the three hierarchical features inherent in visual HOI detectors and propose a method for high-level relation extraction aimed at VL foundation models, which we call HO prompt-based learning. Our design includes an HO Prompt-guided Decoder (HOPD), facilitates the association of high-level relation representations in the foundation model with various HO pairs within the image. Furthermore, we utilize a LLM (\emph{i.e.} GPT) for interaction interpretation, generating a richer linguistic understanding for complex HOIs. For open-category interaction recognition, our method supports either of two input types: interaction phrase or interpretive sentence. Our efficient architecture design and learning methods effectively unleash the potential of the VL foundation models and LLMs, allowing UniHOI to surpass all existing methods with a substantial margin, under both supervised and zero-shot settings. The code and pre-trained weights are available at: \url{https://github.com/Caoyichao/UniHOI}.
</details>
<details>
<summary>摘要</summary>
人物交互检测（HOI）的目标是理解人与物之间的复杂关系，预测<人,动作,物>的 triplets，并作为许多计算机视觉任务的基础。然而，在真实世界中人物交互的复杂多样性和多样性带来了annotate和识别的挑战，特别是在开放世界上下文中。本研究通过使用视力语言基础模型（VL）和大型自然语言模型（LLM）来实现开放世界上的universal交互识别。我们提出了一种名为UniHOI的方法，包括HO Prompt-based Learning（HOPD），以帮助将高级关系表示与不同的HO对在图像中相关联。此外，我们使用GPT（一种大型自然语言模型）进行交互解释，以生成更加 ric
</details></li>
</ul>
<hr>
<h2 id="Self-MI-Efficient-Multimodal-Fusion-via-Self-Supervised-Multi-Task-Learning-with-Auxiliary-Mutual-Information-Maximization"><a href="#Self-MI-Efficient-Multimodal-Fusion-via-Self-Supervised-Multi-Task-Learning-with-Auxiliary-Mutual-Information-Maximization" class="headerlink" title="Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task Learning with Auxiliary Mutual Information Maximization"></a>Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task Learning with Auxiliary Mutual Information Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03785">http://arxiv.org/abs/2311.03785</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cam-Van Thi Nguyen, Ngoc-Hoa Thi Nguyen, Duc-Trong Le, Quang-Thuy Ha</li>
<li>for: 提高多模态融合的性能，解决现有方法困难于从多个模态中提取有用和明确特征的问题。</li>
<li>methods: 提出了Self-MI方法，基于自我超vised学习的思想，同时采用了协同预测编码（CPC）技术来最大化多modal输入对多modal融合结果的mutual Information（MI）。</li>
<li>results: 在三个benchmark dataset上进行了广泛的实验，证明Self-MI方法能够有效地提高多模态融合任务的性能。<details>
<summary>Abstract</summary>
Multimodal representation learning poses significant challenges in capturing informative and distinct features from multiple modalities. Existing methods often struggle to exploit the unique characteristics of each modality due to unified multimodal annotations. In this study, we propose Self-MI in the self-supervised learning fashion, which also leverage Contrastive Predictive Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI) between unimodal input pairs and the multimodal fusion result with unimodal inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short, that enables us to create meaningful and informative labels for each modality in a self-supervised manner. By maximizing the Mutual Information, we encourage better alignment between the multimodal fusion and the individual modalities, facilitating improved multimodal fusion. Extensive experiments on three benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the effectiveness of Self-MI in enhancing the multimodal fusion task.
</details>
<details>
<summary>摘要</summary>
多Modal表示学习 pose significant challenges in capturing informative and distinct features from multiple modalities. Existing methods often struggle to exploit the unique characteristics of each modality due to unified multimodal annotations. In this study, we propose Self-MI in the self-supervised learning fashion, which also leverage Contrastive Predictive Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI) between unimodal input pairs and the multimodal fusion result with unimodal inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short, that enables us to create meaningful and informative labels for each modality in a self-supervised manner. By maximizing the Mutual Information, we encourage better alignment between the multimodal fusion and the individual modalities, facilitating improved multimodal fusion. Extensive experiments on three benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the effectiveness of Self-MI in enhancing the multimodal fusion task.Here's the translation in Traditional Chinese:多 modal 表示学习 pose significant challenges in capturing informative and distinct features from multiple modalities. Existing methods often struggle to exploit the unique characteristics of each modality due to unified multimodal annotations. In this study, we propose Self-MI in the self-supervised learning fashion, which also leverage Contrastive Predictive Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI) between unimodal input pairs and the multimodal fusion result with unimodal inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short, that enables us to create meaningful and informative labels for each modality in a self-supervised manner. By maximizing the Mutual Information, we encourage better alignment between the multimodal fusion and the individual modalities, facilitating improved multimodal fusion. Extensive experiments on three benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the effectiveness of Self-MI in enhancing the multimodal fusion task.
</details></li>
</ul>
<hr>
<h2 id="UP-NeRF-Unconstrained-Pose-Prior-Free-Neural-Radiance-Fields"><a href="#UP-NeRF-Unconstrained-Pose-Prior-Free-Neural-Radiance-Fields" class="headerlink" title="UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields"></a>UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03784">http://arxiv.org/abs/2311.03784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Injae Kim, Minhyuk Choi, Hyunwoo J. Kim</li>
<li>for: 这篇论文的目的是提出一种不受拘束的图像集合中的NeRF优化方法，不需要摄像头pose估计。</li>
<li>methods: 这篇论文使用了一种新的替代任务来优化颜色不敏感特征场和一个独立的模块来屏蔽异常 occluders 的影响，以及一个候选头来提高pose估计的稳定性。</li>
<li>results: 对于一个在互联网上的挑战性图像集合，这篇论文的实验结果表明，我们的方法在比基elines，包括BARF和其变种的方法之上表现出了超越性。<details>
<summary>Abstract</summary>
Neural Radiance Field (NeRF) has enabled novel view synthesis with high fidelity given images and camera poses. Subsequent works even succeeded in eliminating the necessity of pose priors by jointly optimizing NeRF and camera pose. However, these works are limited to relatively simple settings such as photometrically consistent and occluder-free image collections or a sequence of images from a video. So they have difficulty handling unconstrained images with varying illumination and transient occluders. In this paper, we propose $\textbf{UP-NeRF}$ ($\textbf{U}$nconstrained $\textbf{P}$ose-prior-free $\textbf{Ne}$ural $\textbf{R}$adiance $\textbf{F}$ields) to optimize NeRF with unconstrained image collections without camera pose prior. We tackle these challenges with surrogate tasks that optimize color-insensitive feature fields and a separate module for transient occluders to block their influence on pose estimation. In addition, we introduce a candidate head to enable more robust pose estimation and transient-aware depth supervision to minimize the effect of incorrect prior. Our experiments verify the superior performance of our method compared to the baselines including BARF and its variants in a challenging internet photo collection, $\textit{Phototourism}$ dataset.
</details>
<details>
<summary>摘要</summary>
neuronal radiance field (NeRF) 已经实现了基于图像和摄像机位置的新视图合成，并且后续的工作甚至已经消除了摄像机位置的必要性，通过共同优化 NeRF 和摄像机位置。然而，这些工作受到了相对简单的设置的限制，例如具有相同的光度和没有遮挡物的图像集或视频序列。因此它们在面临不受限制的图像集和变化的照明和遮挡物时表现不佳。在这篇论文中，我们提出了 $\textbf{UP-NeRF}$（无约束 pose-prior-free neural radiance field），用于在不受限制的图像集中优化 NeRF  без摄像机位置优先。我们通过使用代表任务来优化不受光度影响的特征场和分离模块来处理变化的照明和遮挡物。此外，我们还引入了候选头来实现更加稳定的pose估计和抗不正确优先的深度监督，以降低不正确优先的影响。我们的实验证明了我们的方法比基于 BARF 和其他变体的基eline在《phototourism》数据集上表现出更高的性能。
</details></li>
</ul>
<hr>
<h2 id="CapST-An-Enhanced-and-Lightweight-Method-for-Deepfake-Video-Classification"><a href="#CapST-An-Enhanced-and-Lightweight-Method-for-Deepfake-Video-Classification" class="headerlink" title="CapST: An Enhanced and Lightweight Method for Deepfake Video Classification"></a>CapST: An Enhanced and Lightweight Method for Deepfake Video Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03782">http://arxiv.org/abs/2311.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wasim Ahmad, Yan-Tsung Peng, Yuan-Hao Chang, Gaddisa Olani Ganfure, Sarwar Khan, Sahibzada Adil Shahzad</li>
<li>for: 本研究旨在针对深伪视频（Deepfake video）进行分类，以满足不同领域的需求。</li>
<li>methods: 本研究提出了一种新型的深伪视频分类模型，利用VGG19bn的一部分作为底层特征提取器，并在这之上加入了卷积网络和空间时间注意力机制来提高分类能力。</li>
<li>results: 实验结果表明，与基eline模型相比，本研究的方法可以提高深伪视频的分类精度，同时减少计算资源的消耗。在DFDM数据集上，本研究的方法可以达到4%的改善率。<details>
<summary>Abstract</summary>
The proliferation of deepfake videos, synthetic media produced through advanced Artificial Intelligence techniques has raised significant concerns across various sectors, encompassing realms such as politics, entertainment, and security. In response, this research introduces an innovative and streamlined model designed to classify deepfake videos generated by five distinct encoders adeptly. Our approach not only achieves state of the art performance but also optimizes computational resources. At its core, our solution employs part of a VGG19bn as a backbone to efficiently extract features, a strategy proven effective in image-related tasks. We integrate a Capsule Network coupled with a Spatial Temporal attention mechanism to bolster the model's classification capabilities while conserving resources. This combination captures intricate hierarchies among features, facilitating robust identification of deepfake attributes. Delving into the intricacies of our innovation, we introduce an existing video level fusion technique that artfully capitalizes on temporal attention mechanisms. This mechanism serves to handle concatenated feature vectors, capitalizing on the intrinsic temporal dependencies embedded within deepfake videos. By aggregating insights across frames, our model gains a holistic comprehension of video content, resulting in more precise predictions. Experimental results on an extensive benchmark dataset of deepfake videos called DFDM showcase the efficacy of our proposed method. Notably, our approach achieves up to a 4 percent improvement in accurately categorizing deepfake videos compared to baseline models, all while demanding fewer computational resources.
</details>
<details>
<summary>摘要</summary>
深刻关注深伪视频的扩散，这种通过高级人工智能技术生成的伪造媒体，已经在不同领域引起了严重的担忧，包括政治、娱乐和安全等。为了应对这些挑战，这项研究推出了一种创新的和高效的模型，用于分类深伪视频。我们的方法不仅实现了状态机器的性能，而且还优化了计算资源。我们的解决方案在核心上采用了VGG19bn的一部分作为特征提取的后备，这是在图像相关任务中证明有效的策略。我们还将卷积网络和空间时间注意力机制相结合，以强化模型的分类能力，同时减少计算资源的消耗。这种结合使得模型能够快速和高效地分类深伪视频。具体来说，我们引入了一种现有的视频级别融合技术，通过利用时间注意力机制，处理 concatenated 特征向量。这种机制使得模型可以充分利用深伪视频中的自然时间依赖关系，从而更好地理解视频内容，并且提高了预测的精度。实验结果表明，我们的提议方法在大规模的深伪视频测试集（DFDM）上达到了4%的改善率，同时减少了计算资源的消耗。
</details></li>
</ul>
<hr>
<h2 id="Meta-Adapter-An-Online-Few-shot-Learner-for-Vision-Language-Model"><a href="#Meta-Adapter-An-Online-Few-shot-Learner-for-Vision-Language-Model" class="headerlink" title="Meta-Adapter: An Online Few-shot Learner for Vision-Language Model"></a>Meta-Adapter: An Online Few-shot Learner for Vision-Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03774">http://arxiv.org/abs/2311.03774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Cheng, Lin Song, Ruoyi Xue, Hang Wang, Hongbin Sun, Yixiao Ge, Ying Shan</li>
<li>for: 提高具有少量样本的图像识别效果和泛化能力</li>
<li>methods: 使用轻量级径补器来在线调整CLIP特征，以适应少量样本学习</li>
<li>results: 与州对比，我们的方法可以在八个图像分类任务上实现竞争性的性能，同时具有更高的执行速度和灵活性，并可以直接应用于下游任务无需进一步微调。<details>
<summary>Abstract</summary>
The contrastive vision-language pre-training, known as CLIP, demonstrates remarkable potential in perceiving open-world visual concepts, enabling effective zero-shot image recognition. Nevertheless, few-shot learning methods based on CLIP typically require offline fine-tuning of the parameters on few-shot samples, resulting in longer inference time and the risk of over-fitting in certain domains. To tackle these challenges, we propose the Meta-Adapter, a lightweight residual-style adapter, to refine the CLIP features guided by the few-shot samples in an online manner. With a few training samples, our method can enable effective few-shot learning capabilities and generalize to unseen data or tasks without additional fine-tuning, achieving competitive performance and high efficiency. Without bells and whistles, our approach outperforms the state-of-the-art online few-shot learning method by an average of 3.6\% on eight image classification datasets with higher inference speed. Furthermore, our model is simple and flexible, serving as a plug-and-play module directly applicable to downstream tasks. Without further fine-tuning, Meta-Adapter obtains notable performance improvements in open-vocabulary object detection and segmentation tasks.
</details>
<details>
<summary>摘要</summary>
《对比式视觉语言预训练（CLIP）表现出了开放世界视觉概念的惊人潜力，使得零批学习成为可能。然而，基于CLIP的几批学习方法通常需要离线参数的微调，导致更长的推理时间和特定领域中的风险溢出。为解决这些挑战，我们提出了Meta-Adapter，一个轻量级的残差风格的适配器，通过指导几批样本来细化CLIP特征。只需几个训练样本，我们的方法可以实现有效的几批学习能力和扩展到未经过训练的数据或任务，达到竞争性的性能和高效性。无需额外配置或微调，我们的方法比预先 trained State-of-the-art online几批学习方法平均提高3.6%的性能在八个图像分类dataset中，同时具有更高的推理速度。此外，我们的方法简单和灵活，可以直接应用于下游任务，无需进一步微调。 Meta-Adapter在开 vocabulary对象检测和分割任务中表现出了显著的性能提高，无需进一步微调。》
</details></li>
</ul>
<hr>
<h2 id="Lightweight-Portrait-Matting-via-Regional-Attention-and-Refinement"><a href="#Lightweight-Portrait-Matting-via-Regional-Attention-and-Refinement" class="headerlink" title="Lightweight Portrait Matting via Regional Attention and Refinement"></a>Lightweight Portrait Matting via Regional Attention and Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03770">http://arxiv.org/abs/2311.03770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yatao Zhong, Ilya Zharkov</li>
<li>for: 高解析人脸抹铺模型</li>
<li>methods: 使用两stage框架，利用视transformer（ViT）作为低分辨率网络的背景，并提出了一种新的跨区域注意力（CRA）模块来传递邻近区域的信息。</li>
<li>results: 对三个标准测试集进行比较，获得了与其他基eline模型相比的更高的抹铺质量，并且只用了$1&#x2F;20$的FLOPS。<details>
<summary>Abstract</summary>
We present a lightweight model for high resolution portrait matting. The model does not use any auxiliary inputs such as trimaps or background captures and achieves real time performance for HD videos and near real time for 4K. Our model is built upon a two-stage framework with a low resolution network for coarse alpha estimation followed by a refinement network for local region improvement. However, a naive implementation of the two-stage model suffers from poor matting quality if not utilizing any auxiliary inputs. We address the performance gap by leveraging the vision transformer (ViT) as the backbone of the low resolution network, motivated by the observation that the tokenization step of ViT can reduce spatial resolution while retain as much pixel information as possible. To inform local regions of the context, we propose a novel cross region attention (CRA) module in the refinement network to propagate the contextual information across the neighboring regions. We demonstrate that our method achieves superior results and outperforms other baselines on three benchmark datasets while only uses $1/20$ of the FLOPS compared to the existing state-of-the-art model.
</details>
<details>
<summary>摘要</summary>
我们提出了一种轻量级的高解像人脸分割模型。该模型不使用任何辅助输入，如截图或背景捕获，并在高清视频和4K视频实时性能上达到了实时性能。我们的模型基于一个两Stage框架，其中低分辨率网络用于粗略 alpha 估计，然后是一个改进网络用于本地区域改进。然而，直接使用两Stage模型会导致分割质量差，因此我们使用视transformer（ViT）作为低分辨率网络的基础，这是因为我们发现，ViT的Tokenization步骤可以减少空间分辨率，同时保留最多的像素信息。在改进网络中，我们提出了一种新的跨地区注意力（CRA）模块，用于在邻近区域之间传递Contextual信息。我们示示，我们的方法可以在三个标准数据集上实现更高的性能，并且只需要使用$1/20$ 的计算资源，相比之前的State-of-the-art模型。
</details></li>
</ul>
<hr>
<h2 id="Image-change-detection-with-only-a-few-samples"><a href="#Image-change-detection-with-only-a-few-samples" class="headerlink" title="Image change detection with only a few samples"></a>Image change detection with only a few samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03762">http://arxiv.org/abs/2311.03762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Ke Liu, Zhaoyi Song, Haoyue Bai</li>
<li>for: solving the problem of image change detection with a small number of samples, and improving the generalization ability of the model.</li>
<li>methods: using simple image processing methods to generate synthetic datasets, and designing an early fusion network based on object detection.</li>
<li>results: the model trained on the synthetic data achieves higher generalization ability than the model trained on the real-world data, and fine-tuning the model with a few samples achieves excellent results.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在解决图像变化检测 task 中的小样本问题，该问题在图像检测 task 中是一个重要的难题，因为只有很少的标注数据可用。</li>
<li>methods: 我们提出使用简单的图像处理方法生成synthetic数据，并设计一种基于对象检测的早期融合网络。</li>
<li>results: 我们的实验表明，使用synthetic数据可以提高模型的通用能力，并且使用一些（常 tens of）样本来精度调整模型可以达到优秀的结果。<details>
<summary>Abstract</summary>
This paper considers image change detection with only a small number of samples, which is a significant problem in terms of a few annotations available. A major impediment of image change detection task is the lack of large annotated datasets covering a wide variety of scenes. Change detection models trained on insufficient datasets have shown poor generalization capability. To address the poor generalization issue, we propose using simple image processing methods for generating synthetic but informative datasets, and design an early fusion network based on object detection which could outperform the siamese neural network. Our key insight is that the synthetic data enables the trained model to have good generalization ability for various scenarios. We compare the model trained on the synthetic data with that on the real-world data captured from a challenging dataset, CDNet, using six different test sets. The results demonstrate that the synthetic data is informative enough to achieve higher generalization ability than the insufficient real-world data. Besides, the experiment shows that utilizing a few (often tens of) samples to fine-tune the model trained on the synthetic data will achieve excellent results.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multiclass-Segmentation-using-Teeth-Attention-Modules-for-Dental-X-ray-Images"><a href="#Multiclass-Segmentation-using-Teeth-Attention-Modules-for-Dental-X-ray-Images" class="headerlink" title="Multiclass Segmentation using Teeth Attention Modules for Dental X-ray Images"></a>Multiclass Segmentation using Teeth Attention Modules for Dental X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03749">http://arxiv.org/abs/2311.03749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Afnan Ghafoor, Seong-Yong Moon, Bumshik Lee</li>
<li>for: 这篇文章的目的是提出一个高效的多类 teeth 分类架构，以帮助解决 dental panoramic 影像中 teeth 的分类问题。</li>
<li>methods: 这篇文章使用了一个 M-Net-like 架构，融合了 Swin Transformers 和一个名为 Teeth Attention Block (TAB) 的新 комponent。TAB 使用了一个特殊的注意机制，专注在 teeth 的复杂结构上，从而获得更高的准确性。</li>
<li>results: 这篇文章的实验结果显示，提出的架构在多个 benchmark dental 影像数据集上，具有较高的准确性和可靠性，并且在多类 teeth 分类任务上表现出色。<details>
<summary>Abstract</summary>
This paper proposed a cutting-edge multiclass teeth segmentation architecture that integrates an M-Net-like structure with Swin Transformers and a novel component named Teeth Attention Block (TAB). Existing teeth image segmentation methods have issues with less accurate and unreliable segmentation outcomes due to the complex and varying morphology of teeth, although teeth segmentation in dental panoramic images is essential for dental disease diagnosis. We propose a novel teeth segmentation model incorporating an M-Net-like structure with Swin Transformers and TAB. The proposed TAB utilizes a unique attention mechanism that focuses specifically on the complex structures of teeth. The attention mechanism in TAB precisely highlights key elements of teeth features in panoramic images, resulting in more accurate segmentation outcomes. The proposed architecture effectively captures local and global contextual information, accurately defining each tooth and its surrounding structures. Furthermore, we employ a multiscale supervision strategy, which leverages the left and right legs of the U-Net structure, boosting the performance of the segmentation with enhanced feature representation. The squared Dice loss is utilized to tackle the class imbalance issue, ensuring accurate segmentation across all classes. The proposed method was validated on a panoramic teeth X-ray dataset, which was taken in a real-world dental diagnosis. The experimental results demonstrate the efficacy of our proposed architecture for tooth segmentation on multiple benchmark dental image datasets, outperforming existing state-of-the-art methods in objective metrics and visual examinations. This study has the potential to significantly enhance dental image analysis and contribute to advances in dental applications.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种革新的多类牙齿分割建议，它将M-Net-like结构和Swin Transformers结合并提出了一个新的组件名为牙齿注意块（TAB）。现有的牙齿图像分割方法存在较为不准确和不可靠的分割结果，尽管牙齿图像分割在 dental 照片中是重要的 dental 疾病诊断。我们提出了一种新的牙齿分割模型，其包括M-Net-like结构、Swin Transformers和TAB。TAB 使用了一种特殊的注意机制，它准确地强调牙齿的复杂结构特征。TAB 中的注意机制可以准确地高亮牙齿图像中的关键特征，从而提高分割结果的准确性。我们的建议可以有效地捕捉局部和全局的情况概念信息，准确地定义每个牙齿和其周围结构。此外，我们采用了多尺度超级视修正策略，这将左右两个 U-Net 结构的左右脚使用，从而提高分割性能。我们使用了平方 dice 损失函数来处理类偏好问题，以确保分割结果准确性。我们的提议在一个 panoramic 牙齿 X-ray 数据集上进行验证，并在多个标准 dental 图像数据集上进行了多个基准测试。实验结果表明，我们的提议可以在多个对象指标和视觉检查中出perform state-of-the-art 牙齿分割。这篇研究有可能对 dental 图像分析产生重要影响，并为 dental 应用领域带来进步。
</details></li>
</ul>
<hr>
<h2 id="SBCFormer-Lightweight-Network-Capable-of-Full-size-ImageNet-Classification-at-1-FPS-on-Single-Board-Computers"><a href="#SBCFormer-Lightweight-Network-Capable-of-Full-size-ImageNet-Classification-at-1-FPS-on-Single-Board-Computers" class="headerlink" title="SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers"></a>SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03747">http://arxiv.org/abs/2311.03747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyonglu/sbcformer">https://github.com/xyonglu/sbcformer</a></li>
<li>paper_authors: Xiangyong Lu, Masanori Suganuma, Takayuki Okatani</li>
<li>for: 这篇论文主要针对单板计算机（SBC）上进行图像识别任务，以解决不同领域的实际问题，如智能农业、渔业和畜牧管理。</li>
<li>methods: 该论文提出了一种名为SBCFormer的CNN-ViT混合网络，可以在低端CPU上实现高精度和快速计算。为了解决低端CPU的硬件限制，该网络采用了注意力机制而不是卷积。</li>
<li>results: 该论文在一个Raspberry Pi 4 Model B上实现了一个ImageNet-1K top-1准确率超过80%，并且达到了1.0帧&#x2F;秒的速度。这是首次在SBC上实现的。代码可以在<a target="_blank" rel="noopener" href="https://github.com/xyongLu/SBCFormer%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/xyongLu/SBCFormer中下载。</a><details>
<summary>Abstract</summary>
Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer.
</details>
<details>
<summary>摘要</summary>
计算机视觉在解决实际问题方面日益普遍，包括智能农业、渔业和畜牧管理等领域。这些应用程序可能不需要处理多个图像帧每秒，因此实际使用单板计算机（SBC）。虽然许多轻量级网络已经为移动/边缘设备开发，但它们主要target于智能手机with更强大的处理器，而不是SBC with low-end CPU。本文介绍了一种名为SBCFormer的CNN-ViT混合网络，它在low-end CPU上实现了高准确率和快速计算。由于硬件限制，这些CPU的Transformer注意机制更加有利，但在low-end CPU上使用注意会存在一个挑战：高分辨率内部特征图需要过度的计算资源，但是降低分辨率会导致失去地方图像细节。SBCFormer提出了一种建筑设计来解决这个问题。因此，SBCFormer在raspberry Pi 4 Model B上的ARM-Cortex A72 CPU上实现了 ImageNet-1K 的top-1准确率约为80%，并且在1.0帧/秒的速度下。Code可以在https://github.com/xyongLu/SBCFormer 上获取。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Video-Summarization"><a href="#Unsupervised-Video-Summarization" class="headerlink" title="Unsupervised Video Summarization"></a>Unsupervised Video Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03745">http://arxiv.org/abs/2311.03745</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KaiyangZhou/pytorch-vsumm-reinforce">https://github.com/KaiyangZhou/pytorch-vsumm-reinforce</a></li>
<li>paper_authors: Hanqing Li, Diego Klabjan, Jean Utke</li>
<li>for: 本研究提出了一种新的、无监督的自动视频摘要方法，利用生成对抗网络的想法，但是减少了识别器，使用简单的损失函数，并将模型的不同部分分别训练。</li>
<li>methods: 本方法使用迭代训练策略，先训练恢复器，然后训练帧选择器，并在训练和评估中添加了可调 máscara вектор。</li>
<li>results: 在两个公共数据集（SumMe和TVSum）以及四个自定义数据集（足球、LoL、MLB和ShortMLB）上进行了实验，结果表明每个组件对模型性能的影响，特别是迭代训练策略。评估和比较与当前状态的方法显示了提议方法的优势在性能、稳定性和训练效率上。<details>
<summary>Abstract</summary>
This paper introduces a new, unsupervised method for automatic video summarization using ideas from generative adversarial networks but eliminating the discriminator, having a simple loss function, and separating training of different parts of the model. An iterative training strategy is also applied by alternately training the reconstructor and the frame selector for multiple iterations. Furthermore, a trainable mask vector is added to the model in summary generation during training and evaluation. The method also includes an unsupervised model selection algorithm. Results from experiments on two public datasets (SumMe and TVSum) and four datasets we created (Soccer, LoL, MLB, and ShortMLB) demonstrate the effectiveness of each component on the model performance, particularly the iterative training strategy. Evaluations and comparisons with the state-of-the-art methods highlight the advantages of the proposed method in performance, stability, and training efficiency.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种新的、无监督的自动视频摘要方法，利用生成对抗网络的想法，但是去掉了判断器，使用简单的损失函数，并将模型的不同部分分别训练。此外，还采用了 alternate 训练策略，在多轮训练中交替训练重构器和帧选择器。此外，在摘要生成过程中，还添加了可学习的面具向量。该方法还包括一种无监督模型选择算法。经过对两个公共数据集（SumMe和TVSum）以及我们自己创建的四个数据集（足球、LoL、MLB和ShortMLB）进行实验，结果表明每个组件对模型性能的影响，特别是 alternate 训练策略。评估和与现有方法进行比较，highlighted 提出的方法在性能、稳定性和训练效率方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="3DifFusionDet-Diffusion-Model-for-3D-Object-Detection-with-Robust-LiDAR-Camera-Fusion"><a href="#3DifFusionDet-Diffusion-Model-for-3D-Object-Detection-with-Robust-LiDAR-Camera-Fusion" class="headerlink" title="3DifFusionDet: Diffusion Model for 3D Object Detection with Robust LiDAR-Camera Fusion"></a>3DifFusionDet: Diffusion Model for 3D Object Detection with Robust LiDAR-Camera Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03742">http://arxiv.org/abs/2311.03742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Xiang, Simon Dräger, Jiawei Zhang</li>
<li>for: 这篇论文主要target是提高3D物体检测性能，尤其是使用LiDAR-Camera感知器时的检测性能。</li>
<li>methods: 该论文提出了一种名为3DifFusionDet的框架，它将3D物体检测看作是一种杂散扩散过程，从噪声3D框架中减少噪声。在训练过程中，模型学习了反噪声过程，并在检测过程中逐渐精细化一组随机生成的框架。</li>
<li>results: 经过广泛的实验，3DifFusionDet在KITTI数据集上表现出色，与之前的高度尊敬的检测器相比，具有更高的准确率和速度。<details>
<summary>Abstract</summary>
Good 3D object detection performance from LiDAR-Camera sensors demands seamless feature alignment and fusion strategies. We propose the 3DifFusionDet framework in this paper, which structures 3D object detection as a denoising diffusion process from noisy 3D boxes to target boxes. In this framework, ground truth boxes diffuse in a random distribution for training, and the model learns to reverse the noising process. During inference, the model gradually refines a set of boxes that were generated at random to the outcomes. Under the feature align strategy, the progressive refinement method could make a significant contribution to robust LiDAR-Camera fusion. The iterative refinement process could also demonstrate great adaptability by applying the framework to various detecting circumstances where varying levels of accuracy and speed are required. Extensive experiments on KITTI, a benchmark for real-world traffic object identification, revealed that 3DifFusionDet is able to perform favorably in comparison to earlier, well-respected detectors.
</details>
<details>
<summary>摘要</summary>
好的3D物体检测性能从激光镜头感知器件中获得，需要无缝特征对应和融合策略。我们在这篇论文中提出了3DifFusionDet框架，它将3D物体检测视为一种噪声损失进程，从噪声3D框架中减噪到目标框架。在这个框架中，真实的框架在训练中随机分布的情况下噪声扩散，模型学习恢复过程。在推理中，模型逐渐精细化一组随机生成的框架，以达到最终结果。在特征对应策略下，进程式精细化方法可以对精度和速度的不同需求进行适应。另外，iterative refinement过程也能够在不同的检测情况下展现出优秀的适应性。在KITTIbenchmark上进行了广泛的实验，发现3DifFusionDet能够与以往受欢迎的检测器相比，表现出优异的性能。
</details></li>
</ul>
<hr>
<h2 id="ADFactory-Automated-Data-Factory-for-Optical-Flow-Tasks"><a href="#ADFactory-Automated-Data-Factory-for-Optical-Flow-Tasks" class="headerlink" title="ADFactory: Automated Data Factory for Optical Flow Tasks"></a>ADFactory: Automated Data Factory for Optical Flow Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04246">http://arxiv.org/abs/2311.04246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Han Ling</li>
<li>for: 提高现代光流方法在真实世界中的普适性， mainly due to the high cost of large real-world optical flow datasets.</li>
<li>methods: 引入一种新的光流训练框架，可以效率地在目标数据频谱上训练光流网络，无需手动标注。 Specifically, 使用高级 nerf 技术重建场景从单目镜头摄像头中收集的照片组，并计算相机pose对的光流结果。 在这基础上，对生成的训练数据进行多种筛选，如 nerf 重建质量、视觉光流标签的视觉一致性、重建深度一致性等。</li>
<li>results: 实验表明，我们的方案在 KITTI 上的普适性超过现有的自我超vised optical flow和单目场景流算法，并且可以在真实世界中超越大多数超vised方法的零点普适评估。<details>
<summary>Abstract</summary>
A major challenge faced by current optical flow methods is the difficulty in generalizing them well into the real world, mainly due to the high production cost of datasets, which currently do not have a large real-world optical flow dataset. To address this challenge, we introduce a novel optical flow training framework that can efficiently train optical flow networks on the target data domain without manual annotation. Specifically, we use advanced Nerf technology to reconstruct scenes from photo groups collected by monocular cameras, and calculate the optical flow results between camera pose pairs from the rendered results. On this basis, we screen the generated training data from various aspects such as Nerf's reconstruction quality, visual consistency of optical flow labels, reconstruction depth consistency, etc. The filtered training data can be directly used for network supervision. Experimentally, the generalization ability of our scheme on KITTI surpasses existing self-supervised optical flow and monocular scene flow algorithms. Moreover, it can always surpass most supervised methods in real-world zero-point generalization evaluation.
</details>
<details>
<summary>摘要</summary>
当前光流方法面临的一个主要挑战是将其通过到真实世界中，主要是因为光流数据集的生产成本过高，目前没有大量的真实世界光流数据集。为解决这个挑战，我们提出了一种新的光流训练框架，可以高效地训练光流网络在目标数据域中无需手动标注。特别是，我们使用了先进的Nerf技术来重建场景从单目相机采集的照片组，并计算相机 pose对的光流结果。基于这个基础，我们从多个方面筛选生成的训练数据，如Nerf的重建质量、光流标签的视觉一致性、重建深度一致性等。经验表明，我们的方案在KITTI上的总体化能力超过现有的自动化光流和单目场景流算法，同时也可以在实际世界中超越大多数指导方法的零点总成评价。
</details></li>
</ul>
<hr>
<h2 id="DeepInspect-An-AI-Powered-Defect-Detection-for-Manufacturing-Industries"><a href="#DeepInspect-An-AI-Powered-Defect-Detection-for-Manufacturing-Industries" class="headerlink" title="DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries"></a>DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03725">http://arxiv.org/abs/2311.03725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arti Kumbhar, Amruta Chougule, Priya Lokhande, Saloni Navaghane, Aditi Burud, Saee Nimbalkar</li>
<li>For: 这个系统是为了实现生产过程中的问题检测，以提高产品质量和生产效率。* Methods: 这个系统使用了卷积神经网络（CNNs）、回传神经网络（RNNs）和生成敌方模型（GANs），实现产品图像中的问题检测。它利用RNNs检测产品中的变化错误，并使用生成的伪错误数据强化模型的类型和适应性。* Results: 这个系统可以实现高精度的问题检测，并且可以在生产过程中实现即时自动化检测。这有助于减少废料和生产成本，最终提高产品质量和市场竞争力。<details>
<summary>Abstract</summary>
Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs), our system introduces an innovative approach to defect detection in manufacturing. This technology excels in precisely identifying faults by extracting intricate details from product photographs, utilizing RNNs to detect evolving errors and generating synthetic defect data to bolster the model's robustness and adaptability across various defect scenarios. The project leverages a deep learning framework to automate real-time flaw detection in the manufacturing process. It harnesses extensive datasets of annotated images to discern complex defect patterns. This integrated system seamlessly fits into production workflows, thereby boosting efficiency and elevating product quality. As a result, it reduces waste and operational costs, ultimately enhancing market competitiveness.
</details>
<details>
<summary>摘要</summary>
我团队使用卷积神经网络（CNN）、回归神经网络（RNN）和生成抗击网络（GAN），开发了一种革新的产品瑕疵检测技术。这种技术可以准确地检测产品照片中的瑕疵，通过提取产品图像中的细节来检测错误，并使用RNN检测错误的发展趋势。此外，我们还生成了假瑕疵数据，以增强模型的可靠性和适应性。这个整体系统可以自动化生产过程中的瑕疵检测，并利用大量标注图像来识别复杂的瑕疵模式。这个系统可以轻松地整合到生产工序中，从而提高效率和产品质量。最终，它可以减少废物和运营成本，从而提高市场竞争力。
</details></li>
</ul>
<hr>
<h2 id="Inertial-Guided-Uncertainty-Estimation-of-Feature-Correspondence-in-Visual-Inertial-Odometry-SLAM"><a href="#Inertial-Guided-Uncertainty-Estimation-of-Feature-Correspondence-in-Visual-Inertial-Odometry-SLAM" class="headerlink" title="Inertial Guided Uncertainty Estimation of Feature Correspondence in Visual-Inertial Odometry&#x2F;SLAM"></a>Inertial Guided Uncertainty Estimation of Feature Correspondence in Visual-Inertial Odometry&#x2F;SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03722">http://arxiv.org/abs/2311.03722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seongwook Yoon, Jaehyun Kim, Sanghoon Sull</li>
<li>for: This paper aims to improve the accuracy of visual odometry and Simultaneous Localization And Mapping (SLAM) methods by estimating the uncertainty of feature correspondence using an inertial guidance robust to image degradation.</li>
<li>methods: The proposed method models a guidance distribution to sample possible correspondence and fits the distribution to an energy function based on image error, yielding more robust uncertainty than conventional methods.</li>
<li>results: The authors demonstrate the feasibility of their approach by incorporating it into one of recent visual-inertial odometry&#x2F;SLAM algorithms for public datasets.Here’s the Chinese translation of the three key points:</li>
<li>for: 这篇论文目的是提高视觉自律和同时地图标定（SLAM）方法的准确性，通过对各个图像中的特征点进行可靠的uncertainty估计。</li>
<li>methods: 提议的方法是通过模拟可能的对应关系，并基于图像错误的能量函数来适应可靠的uncertainty估计。</li>
<li>results: 作者们在使用一种现有的视觉-各种odometry&#x2F;SLAM算法中进行实验，以证明方法的可行性。<details>
<summary>Abstract</summary>
Visual odometry and Simultaneous Localization And Mapping (SLAM) has been studied as one of the most important tasks in the areas of computer vision and robotics, to contribute to autonomous navigation and augmented reality systems. In case of feature-based odometry/SLAM, a moving visual sensor observes a set of 3D points from different viewpoints, correspondences between the projected 2D points in each image are usually established by feature tracking and matching. However, since the corresponding point could be erroneous and noisy, reliable uncertainty estimation can improve the accuracy of odometry/SLAM methods. In addition, inertial measurement unit is utilized to aid the visual sensor in terms of Visual-Inertial fusion. In this paper, we propose a method to estimate the uncertainty of feature correspondence using an inertial guidance robust to image degradation caused by motion blur, illumination change and occlusion. Modeling a guidance distribution to sample possible correspondence, we fit the distribution to an energy function based on image error, yielding more robust uncertainty than conventional methods. We also demonstrate the feasibility of our approach by incorporating it into one of recent visual-inertial odometry/SLAM algorithms for public datasets.
</details>
<details>
<summary>摘要</summary>
视觉增程和同时地图化（SLAM）已被视为计算机视觉和机器人领域中最重要的任务之一，以帮助实现自主导航和增强现实系统。在特征基于的增程/SLAM中，一个移动的视觉传感器观察到了不同视角的3D点集，通常通过特征跟踪和匹配来确定图像中的2D点对应关系。然而，由于对应点可能含误差和杂音，可靠的uncertainty估计可以提高增程/SLAM方法的准确性。此外，使用导航单元以帮助视觉传感器进行视觉-导航融合也是非常重要。在这篇论文中，我们提出了一种用于估计特征对应关系的不确定性的方法，该方法基于图像误差能量函数，可以快速和精准地估计不确定性。我们还通过将该方法与现有的视觉-导航增程/SLAM算法结合来证明其可行性。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-deep-representation-learning-for-quantum-cross-platform-verification"><a href="#Multimodal-deep-representation-learning-for-quantum-cross-platform-verification" class="headerlink" title="Multimodal deep representation learning for quantum cross-platform verification"></a>Multimodal deep representation learning for quantum cross-platform verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03713">http://arxiv.org/abs/2311.03713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Qian, Yuxuan Du, Zhenliang He, Min-hsiu Hsieh, Dacheng Tao</li>
<li>for:  Early-stage quantum computing cross-platform verification, aiming to characterize the similarity of two imperfect quantum devices executing identical algorithms with minimal measurements.</li>
<li>methods:  Multimodal learning approach, leveraging measurement outcomes and classical description of compiled circuits on explored quantum devices, fused through a neural network to create a comprehensive data representation.</li>
<li>results:  Three-orders-of-magnitude improvement in prediction accuracy compared to random measurements, demonstrating the complementary roles of each modality in cross-platform verification, and paving the way for harnessing multimodal learning in wider quantum system learning tasks.<details>
<summary>Abstract</summary>
Cross-platform verification, a critical undertaking in the realm of early-stage quantum computing, endeavors to characterize the similarity of two imperfect quantum devices executing identical algorithms, utilizing minimal measurements. While the random measurement approach has been instrumental in this context, the quasi-exponential computational demand with increasing qubit count hurdles its feasibility in large-qubit scenarios. To bridge this knowledge gap, here we introduce an innovative multimodal learning approach, recognizing that the formalism of data in this task embodies two distinct modalities: measurement outcomes and classical description of compiled circuits on explored quantum devices, both enriched with unique information. Building upon this insight, we devise a multimodal neural network to independently extract knowledge from these modalities, followed by a fusion operation to create a comprehensive data representation. The learned representation can effectively characterize the similarity between the explored quantum devices when executing new quantum algorithms not present in the training data. We evaluate our proposal on platforms featuring diverse noise models, encompassing system sizes up to 50 qubits. The achieved results demonstrate a three-orders-of-magnitude improvement in prediction accuracy compared to the random measurements and offer compelling evidence of the complementary roles played by each modality in cross-platform verification. These findings pave the way for harnessing the power of multimodal learning to overcome challenges in wider quantum system learning tasks.
</details>
<details>
<summary>摘要</summary>
cross-platform验证，在初级量子计算领域中的一项重要任务，旨在Characterize two imperfect quantum devices executing identical algorithms using minimal measurements. Although the random measurement approach has been instrumental in this context, the quasi-exponential computational demand with increasing qubit count hinders its feasibility in large-qubit scenarios. To bridge this knowledge gap, we introduce an innovative multimodal learning approach, recognizing that the formalism of data in this task embodies two distinct modalities: measurement outcomes and classical description of compiled circuits on explored quantum devices, both enriched with unique information. Building upon this insight, we devise a multimodal neural network to independently extract knowledge from these modalities, followed by a fusion operation to create a comprehensive data representation. The learned representation can effectively characterize the similarity between the explored quantum devices when executing new quantum algorithms not present in the training data. We evaluate our proposal on platforms featuring diverse noise models, encompassing system sizes up to 50 qubits. The achieved results demonstrate a three-orders-of-magnitude improvement in prediction accuracy compared to the random measurements and offer compelling evidence of the complementary roles played by each modality in cross-platform verification. These findings pave the way for harnessing the power of multimodal learning to overcome challenges in wider quantum system learning tasks.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-convolutional-neural-network-fusion-approach-for-change-detection-in-remote-sensing-images"><a href="#Unsupervised-convolutional-neural-network-fusion-approach-for-change-detection-in-remote-sensing-images" class="headerlink" title="Unsupervised convolutional neural network fusion approach for change detection in remote sensing images"></a>Unsupervised convolutional neural network fusion approach for change detection in remote sensing images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03679">http://arxiv.org/abs/2311.03679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weidong Yan, Pei Yan, Li Cao</li>
<li>for: 本研究旨在提出一种基于深度学习的无监督 shallow convolutional neural network（USCNN）Change Detection方法，以替代传统的深度学习方法，提高Change Detection的效率和可扩展性。</li>
<li>methods: 本方法首先将bi-temporal图像转化为不同的特征空间，使用不同大小的卷积核来提取图像的多尺度信息。然后，对bi-temporal图像的输出特征图像进行相同的卷积核进行减法操作，并将得到的差分特征图像 concatenate 为一个特征图像。最后，使用1*1卷积层对多尺度信息进行汇聚。</li>
<li>results: 实验结果表明，提出的方法可以有效地检测 Change，并且比传统的深度学习方法更加高效和可扩展。<details>
<summary>Abstract</summary>
With the rapid development of deep learning, a variety of change detection methods based on deep learning have emerged in recent years. However, these methods usually require a large number of training samples to train the network model, so it is very expensive. In this paper, we introduce a completely unsupervised shallow convolutional neural network (USCNN) fusion approach for change detection. Firstly, the bi-temporal images are transformed into different feature spaces by using convolution kernels of different sizes to extract multi-scale information of the images. Secondly, the output features of bi-temporal images at the same convolution kernels are subtracted to obtain the corresponding difference images, and the difference feature images at the same scale are fused into one feature image by using 1 * 1 convolution layer. Finally, the output features of different scales are concatenated and a 1 * 1 convolution layer is used to fuse the multi-scale information of the image. The model parameters are obtained by a redesigned sparse function. Our model has three features: the entire training process is conducted in an unsupervised manner, the network architecture is shallow, and the objective function is sparse. Thus, it can be seen as a kind of lightweight network model. Experimental results on four real remote sensing datasets indicate the feasibility and effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
随着深度学习的快速发展，深度学习基于的变化检测方法在最近几年出现了多种。然而，这些方法通常需要训练样本的大量，因此非常昂贵。在这篇论文中，我们介绍了一种完全无监督的浅层卷积神经网络（USCNN）融合方法 для变化检测。首先，bi-temporal图像被转换成不同的特征空间，使用不同的卷积核来提取图像的多尺度信息。然后，bi-temporal图像的输出特征在同一个卷积核上被减去，得到了对应的差图像，并将差图像的特征特征在同一个缩放因子上进行融合，使用1*1卷积层。最后，不同缩放因子的输出特征被拼接起来，并使用1*1卷积层来融合图像的多尺度信息。模型参数是通过重新设计的稀疏函数来获得。我们的模型有三个特点：整个训练过程是无监督的，网络架构是浅层的，目标函数是稀疏的。因此，它可以看作是一种轻量级的网络模型。实验结果表明，提案的方法在四个真实遥感数据集上是可行和有效的。
</details></li>
</ul>
<hr>
<h2 id="Image-Generation-and-Learning-Strategy-for-Deep-Document-Forgery-Detection"><a href="#Image-Generation-and-Learning-Strategy-for-Deep-Document-Forgery-Detection" class="headerlink" title="Image Generation and Learning Strategy for Deep Document Forgery Detection"></a>Image Generation and Learning Strategy for Deep Document Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03650">http://arxiv.org/abs/2311.03650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yamato Okamoto, Osada Genki, Iu Yahiro, Rintaro Hasegawa, Peifei Zhu, Hirokatsu Kataoka</li>
<li>for: 增强文档伪造风险的识别和防范</li>
<li>methods: 使用自然图像和文档图像自然学习，以及FD-VIED数据集来驱动模型进行训练</li>
<li>results: 实验结果表明，我们的方法可以提高识别性能<details>
<summary>Abstract</summary>
In recent years, document processing has flourished and brought numerous benefits. However, there has been a significant rise in reported cases of forged document images. Specifically, recent advancements in deep neural network (DNN) methods for generative tasks may amplify the threat of document forgery. Traditional approaches for forged document images created by prevalent copy-move methods are unsuitable against those created by DNN-based methods, as we have verified. To address this issue, we construct a training dataset of document forgery images, named FD-VIED, by emulating possible attacks, such as text addition, removal, and replacement with recent DNN-methods. Additionally, we introduce an effective pre-training approach through self-supervised learning with both natural images and document images. In our experiments, we demonstrate that our approach enhances detection performance.
</details>
<details>
<summary>摘要</summary>
Recently, document processing has made significant progress and brought many benefits. However, there has been a notable increase in reported cases of forged document images. Specifically, the recent advancements in deep neural network (DNN) methods for generative tasks have amplified the threat of document forgery. Traditional approaches for forged document images created by prevalent copy-move methods are not effective against those created by DNN-based methods, as we have verified. To address this issue, we construct a training dataset of document forgery images, named FD-VIED, by emulating possible attacks, such as text addition, removal, and replacement using recent DNN-methods. Additionally, we introduce an effective pre-training approach through self-supervised learning with both natural images and document images. In our experiments, we demonstrate that our approach enhances detection performance.
</details></li>
</ul>
<hr>
<h2 id="Instruct-Me-More-Random-Prompting-for-Visual-In-Context-Learning"><a href="#Instruct-Me-More-Random-Prompting-for-Visual-In-Context-Learning" class="headerlink" title="Instruct Me More! Random Prompting for Visual In-Context Learning"></a>Instruct Me More! Random Prompting for Visual In-Context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03648">http://arxiv.org/abs/2311.03648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Zhang, Bowen Wang, Liangzhi Li, Yuta Nakashima, Hajime Nagahara</li>
<li>for: 这篇论文主要用于探讨如何使用启发式学习（In-Context Learning，ICL）来提高计算机视觉任务的性能。</li>
<li>methods: 该论文提出了一种名为“Instruct Me More”（InMeMo）的方法，该方法通过在输入图像对的基础上添加可学习的干扰（prompt），以便更好地地 explore 启发式学习的潜在。</li>
<li>results: 实验表明，Compared to 基eline无learnable prompt，InMeMo可以提高 foreground segmentation 和单个物体检测任务的 mIoU 分数 by 7.35 和 15.13，分别。这些结果表明，InMeMo 可以提供一种灵活和高效的方法来提高计算机视觉任务的性能。<details>
<summary>Abstract</summary>
Large-scale models trained on extensive datasets, have emerged as the preferred approach due to their high generalizability across various tasks. In-context learning (ICL), a popular strategy in natural language processing, uses such models for different tasks by providing instructive prompts but without updating model parameters. This idea is now being explored in computer vision, where an input-output image pair (called an in-context pair) is supplied to the model with a query image as a prompt to exemplify the desired output. The efficacy of visual ICL often depends on the quality of the prompts. We thus introduce a method coined Instruct Me More (InMeMo), which augments in-context pairs with a learnable perturbation (prompt), to explore its potential. Our experiments on mainstream tasks reveal that InMeMo surpasses the current state-of-the-art performance. Specifically, compared to the baseline without learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for foreground segmentation and single object detection tasks, respectively. Our findings suggest that InMeMo offers a versatile and efficient way to enhance the performance of visual ICL with lightweight training. Code is available at https://github.com/Jackieam/InMeMo.
</details>
<details>
<summary>摘要</summary>
大规模模型，训练在庞大数据集上，已成为首选方法，因其在不同任务上的高通用性。在自然语言处理中，受托学习（ICL）是一种受欢迎的策略，使用这些模型来执行不同任务，而不需要更新模型参数。在计算机视觉中，我们使用输入-输出图像对（称为内容对），将模型作为推荐图像的Prompt，以便塑造出所需的输出。图像ICL的效果通常取决于提示的质量。因此，我们引入了一种名为“ instru me more”（InMeMo）的方法，该方法将含有学习的扰动（提示），以探索其可能性。我们对主流任务进行了实验，发现InMeMo在比基eline无学习提示时的性能提高7.35和15.13个mIoU分数。我们的发现表明，InMeMo可以提供轻量级训练的高效和多样化方法，以提高图像ICL的性能。代码可以在https://github.com/Jackieam/InMeMo中找到。
</details></li>
</ul>
<hr>
<h2 id="Random-Field-Augmentations-for-Self-Supervised-Representation-Learning"><a href="#Random-Field-Augmentations-for-Self-Supervised-Representation-Learning" class="headerlink" title="Random Field Augmentations for Self-Supervised Representation Learning"></a>Random Field Augmentations for Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03629">http://arxiv.org/abs/2311.03629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philip Andrew Mansfield, Arash Afkanpour, Warren Richard Morningstar, Karan Singhal</li>
<li>for: 本文旨在提出一种新的本地变换方法来提高自我超vised representation learning的数据增强。</li>
<li>methods: 本文使用 Gaussian random fields 来生成图像增强，并将变换参数视为独立的 Gaussian 随机场。</li>
<li>results: 实验结果表明，新的变换方法可以提高 ImageNet 和 iNaturalist 下的自我超vised representation learning表现，但是需要权衡增强的多样性和强度。<details>
<summary>Abstract</summary>
Self-supervised representation learning is heavily dependent on data augmentations to specify the invariances encoded in representations. Previous work has shown that applying diverse data augmentations is crucial to downstream performance, but augmentation techniques remain under-explored. In this work, we propose a new family of local transformations based on Gaussian random fields to generate image augmentations for self-supervised representation learning. These transformations generalize the well-established affine and color transformations (translation, rotation, color jitter, etc.) and greatly increase the space of augmentations by allowing transformation parameter values to vary from pixel to pixel. The parameters are treated as continuous functions of spatial coordinates, and modeled as independent Gaussian random fields. Empirical results show the effectiveness of the new transformations for self-supervised representation learning. Specifically, we achieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream classification, and a 3.6% improvement on out-of-distribution iNaturalist downstream classification. However, due to the flexibility of the new transformations, learned representations are sensitive to hyperparameters. While mild transformations improve representations, we observe that strong transformations can degrade the structure of an image, indicating that balancing the diversity and strength of augmentations is important for improving generalization of learned representations.
</details>
<details>
<summary>摘要</summary>
自适应学习表示力学 heavily dependent于数据扩充来确定表示中的不变性。 previous work 表明，对于下游性能的提高，采用多样化的数据扩充是关键，但是扩充技术还未得到充分探索。在这种工作中，我们提出了一个新的本地变换家族，基于 Gaussian random fields 来生成图像扩充。这些变换扩展了Well-established affine和色彩变换（平移、旋转、色彩牛牛、等），并大大增加了扩充的空间。变换参数 treated as continuous functions of spatial coordinates，并 modeled as independent Gaussian random fields。 empirical results show the effectiveness of the new transformations for self-supervised representation learning. Specifically, we achieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream classification, and a 3.6% improvement on out-of-distribution iNaturalist downstream classification. However, due to the flexibility of the new transformations, learned representations are sensitive to hyperparameters. While mild transformations improve representations, we observe that strong transformations can degrade the structure of an image, indicating that balancing the diversity and strength of augmentations is important for improving generalization of learned representations.
</details></li>
</ul>
<hr>
<h2 id="FusionViT-Hierarchical-3D-Object-Detection-via-LiDAR-Camera-Vision-Transformer-Fusion"><a href="#FusionViT-Hierarchical-3D-Object-Detection-via-LiDAR-Camera-Vision-Transformer-Fusion" class="headerlink" title="FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision Transformer Fusion"></a>FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision Transformer Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03620">http://arxiv.org/abs/2311.03620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Xiang, Jiawei Zhang</li>
<li>for: 提高3D物体检测性能</li>
<li>methods: 使用视Transformer模型进行多modal数据嵌入学习和数据融合</li>
<li>results: 在实际交通Scene中实现了状态的检测性能，并且超越了仅使用相机图像或激光点云的基eline方法以及最新的多Modal图像-点云深度融合方法。<details>
<summary>Abstract</summary>
For 3D object detection, both camera and lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches.
</details>
<details>
<summary>摘要</summary>
For 3D object detection, both camera и lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.CV_2023_11_07/" data-id="clorjzl7o00lef1888nhp7yhq" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/89/">89</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
