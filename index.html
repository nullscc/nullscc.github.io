
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.AS_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/eess.AS_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T14:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/eess.AS_2023_11_07/">eess.AS - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Fine-tuning-convergence-model-in-Bengali-speech-recognition"><a href="#Fine-tuning-convergence-model-in-Bengali-speech-recognition" class="headerlink" title="Fine-tuning convergence model in Bengali speech recognition"></a>Fine-tuning convergence model in Bengali speech recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04122">http://arxiv.org/abs/2311.04122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhu Ruiying, Shen Meng</li>
<li>for: 提高自动语音识别模型的性能，特别是对于孟加拉语的识别。</li>
<li>methods: 使用wave2vec 2.0预训练模型进行微调，并调整学习率和dropout参数。</li>
<li>results: 测试集WER从0.508降低至0.437，并将训练和验证集合并成一个完整的 dataset，实现了优秀的 WER 0.436。<details>
<summary>Abstract</summary>
Research on speech recognition has attracted considerable interest due to the difficult task of segmenting uninterrupted speech. Among various languages, Bengali features distinct rhythmic patterns and tones, making it particularly difficult to recognize and lacking an efficient commercial recognition method. In order to improve the automatic speech recognition model for Bengali, our team has chosen to utilize the wave2vec 2.0 pre-trained model, which has undergone convergence for fine-tuning. Regarding Word Error Rate (WER), the learning rate and dropout parameters were fine-tuned, and after the model training was stable, attempts were made to enlarge the training set ratio, which improved the model's performance. Consequently, there was a notable enhancement in the WER from 0.508 to 0.437 on the test set of the publicly listed official dataset. Afterwards, the training and validation sets were merged, creating a comprehensive dataset that was used as the training set, achieving a remarkable WER of 0.436.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:研究对无间断语音识别有很大的兴趣，因为 segmenting 语音是一项非常复杂的任务。 among various languages, Bengali 特别地具有明确的 ритмиче Pattern 和调音，使其识别成为 particuarly  diffucult  task. 为了改进 automatic speech recognition 模型 для Bengali, 我们队伍选择使用 wave2vec 2.0 预训练模型，并进行了 fine-tuning。 regarding Word Error Rate (WER), 我们调整了学习率和Dropout 参数，并在模型训练稳定后，尝试将训练集比例扩大，从而改进模型的性能。 因此，在 test set 上，WER 从 0.508 下降到 0.437。 然后，我们合并了训练集和验证集，创建了一个全面的 dataset，用于训练模型，达到了Remarkable WER 0.436。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/eess.AS_2023_11_07/" data-id="cloqtaeyy012pgh88dch0fkix" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.CV_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T13:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.CV_2023_11_07/">cs.CV - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Video-Instance-Matting"><a href="#Video-Instance-Matting" class="headerlink" title="Video Instance Matting"></a>Video Instance Matting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04212">http://arxiv.org/abs/2311.04212</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shi-labs/vim">https://github.com/shi-labs/vim</a></li>
<li>paper_authors: Jiachen Li, Roberto Henschel, Vidit Goel, Marianna Ohanyan, Shant Navasardyan, Humphrey Shi</li>
<li>for: 这篇论文是为了解决视频实例分割后的 alpha 环境映射问题而写的。</li>
<li>methods: 该论文提出了一种新的 Video Instance Matting<del>(VIM) 方法，即在每帧视频帧中对每个实例预测 alpha 环境映射。此外，该论文还提出了一种基于Mask Sequence Guided Video Instance Matting</del>(MSG-VIM)的基线模型，该模型利用了混合的 mask 增强来提高预测结果的Robustness。</li>
<li>results: 该论文的提出的 MSG-VIM 模型在新建的 VIM50 测试集上达到了比较高的性能，与现有方法相比，它的性能差异较大。此外，该论文还引入了一种适用于 VIM 任务的评价指标，即 Video Instance-aware Matting Quality~(VIMQ)。<details>
<summary>Abstract</summary>
Conventional video matting outputs one alpha matte for all instances appearing in a video frame so that individual instances are not distinguished. While video instance segmentation provides time-consistent instance masks, results are unsatisfactory for matting applications, especially due to applied binarization. To remedy this deficiency, we propose Video Instance Matting~(VIM), that is, estimating alpha mattes of each instance at each frame of a video sequence. To tackle this challenging problem, we present MSG-VIM, a Mask Sequence Guided Video Instance Matting neural network, as a novel baseline model for VIM. MSG-VIM leverages a mixture of mask augmentations to make predictions robust to inaccurate and inconsistent mask guidance. It incorporates temporal mask and temporal feature guidance to improve the temporal consistency of alpha matte predictions. Furthermore, we build a new benchmark for VIM, called VIM50, which comprises 50 video clips with multiple human instances as foreground objects. To evaluate performances on the VIM task, we introduce a suitable metric called Video Instance-aware Matting Quality~(VIMQ). Our proposed model MSG-VIM sets a strong baseline on the VIM50 benchmark and outperforms existing methods by a large margin. The project is open-sourced at https://github.com/SHI-Labs/VIM.
</details>
<details>
<summary>摘要</summary>
传统视频腾讯输出一个 alpha 毯幕，用于所有在视频帧中出现的实例，从而无法分辨各个实例。而视频实例分割提供了时间相关的实例掩蔽，但是由于应用了二进制化，导致结果不满足。为了解决这种不足，我们提议视频实例腾讯~(VIM)，即在每帧视频序列中为每个实例 estimating alpha 毯幕。为了解决这个挑战问题，我们提出了一种基于Mask Sequence Guided~(MSG)的新基线模型，称为MSG-VIM。MSG-VIM 利用了混合的掩蔽修饰，以使其预测更加Robust to inaccurate和不一致的掩蔽指导。它还 incorporates temporal mask和temporal feature导航，以改进 alpha 毯幕预测的时间一致性。此外，我们建立了一个新的 VIM 测试集，称为VIM50，它包含 50 个视频剪辑，每个剪辑有多个人类实例作为背景物体。为了评估 VIM 任务的性能，我们引入了一个适合的 metric，称为 Video Instance-aware Matting Quality~(VIMQ)。我们的提议模型 MSG-VIM 在 VIM50 测试集上设置了一个强大的基线，并超过现有方法的表现。项目已经开源在 GitHub 上，请参考 https://github.com/SHI-Labs/VIM。
</details></li>
</ul>
<hr>
<h2 id="Deep-Hashing-via-Householder-Quantization"><a href="#Deep-Hashing-via-Householder-Quantization" class="headerlink" title="Deep Hashing via Householder Quantization"></a>Deep Hashing via Householder Quantization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04207">http://arxiv.org/abs/2311.04207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucas R. Schwengber, Lucas Resende, Paulo Orenstein, Roberto I. Oliveira</li>
<li>For: 该文章目的是提出一种新的快速、无监督、具有优化性的图像相似性搜索算法，可以在现有的深度哈希或度量学习算法之上进行。* Methods: 该算法使用了分解学习问题的方法，首先在嵌入空间进行相似性学习，然后使用投影变换将嵌入转换为符号函数中的整数值。* Results: 对于多个图像数据集，该算法可以达到状态艺术性的表现，并且与其他归一化策略不同的是，可以在现有的深度哈希或度量学习算法上进行稳定的改进。<details>
<summary>Abstract</summary>
Hashing is at the heart of large-scale image similarity search, and recent methods have been substantially improved through deep learning techniques. Such algorithms typically learn continuous embeddings of the data. To avoid a subsequent costly binarization step, a common solution is to employ loss functions that combine a similarity learning term (to ensure similar images are grouped to nearby embeddings) and a quantization penalty term (to ensure that the embedding entries are close to binarized entries, e.g., -1 or 1). Still, the interaction between these two terms can make learning harder and the embeddings worse. We propose an alternative quantization strategy that decomposes the learning problem in two stages: first, perform similarity learning over the embedding space with no quantization; second, find an optimal orthogonal transformation of the embeddings so each coordinate of the embedding is close to its sign, and then quantize the transformed embedding through the sign function. In the second step, we parametrize orthogonal transformations using Householder matrices to efficiently leverage stochastic gradient descent. Since similarity measures are usually invariant under orthogonal transformations, this quantization strategy comes at no cost in terms of performance. The resulting algorithm is unsupervised, fast, hyperparameter-free and can be run on top of any existing deep hashing or metric learning algorithm. We provide extensive experimental results showing that this approach leads to state-of-the-art performance on widely used image datasets, and, unlike other quantization strategies, brings consistent improvements in performance to existing deep hashing algorithms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="High-fidelity-3D-Reconstruction-of-Plants-using-Neural-Radiance-Field"><a href="#High-fidelity-3D-Reconstruction-of-Plants-using-Neural-Radiance-Field" class="headerlink" title="High-fidelity 3D Reconstruction of Plants using Neural Radiance Field"></a>High-fidelity 3D Reconstruction of Plants using Neural Radiance Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04154">http://arxiv.org/abs/2311.04154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kewei Hu, Ying Wei, Yaoqiang Pan, Hanwen Kang, Chao Chen</li>
<li>for: 本研究旨在探讨Neural Radiance Field（NeRF）在减少农业垦戈中的应用，以实现高精度的植物形态重建。</li>
<li>methods: 本研究使用了NeRF技术，特别是Instant-NGP和Instant-NSR两种State-of-the-Art方法，以生成高质量的图像和精度地重建植物模型。</li>
<li>results: 本研究结果表明，NeRF在生成新视图图像和三维重建植物模型方面具有优秀表现，并能够与商业软件Reality Capture相当。然而，研究还发现NeRF在某些情况下存在较慢的训练速度、不足的采样导致的性能限制以及复杂设置中的几何质量困难。<details>
<summary>Abstract</summary>
Accurate reconstruction of plant phenotypes plays a key role in optimising sustainable farming practices in the field of Precision Agriculture (PA). Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging. Recently, a promising development has emerged in the form of Neural Radiance Field (NeRF), a novel method that utilises neural density fields. This technique has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context. In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models. We explore the world of neural radiance fields, in particular two SOTA methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training. In particular, we present a novel plant phenotype dataset comprising real plant images from production environments. This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts. Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction. However, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups.
</details>
<details>
<summary>摘要</summary>
准确重建植物fenotype在精准农业（PA）中扮演了关键的角色。目前，光学感知器技术主导了该领域，但是需要高精度的3D重建植物和作物在无结构农业环境中仍然是挑战。最近，一种有前途的发展是Neural Radiance Field（NeRF）技术，它利用神经density场来实现。这种技术在视觉合成任务中表现出色，但在农业上还很少研究。在我们的研究中，我们关注了两个基本的植物fenotype任务：（1）生成2D新视图图像，和（2）3D重建作物和植物模型。我们深入探索NeRF技术，特别是两种SOTA方法：Instant-NGP和Instant-NSR。Instant-NGP可以在快速训练和推理中生成高质量图像，而Instant-NSR通过在训练中 incorporating Signed Distance Function（SDF）来提高重建的准确性。特别是，我们提供了一个全新的植物fenotype数据集，包含来自生产环境的真实植物图像。这个数据集是一项首先的尝试，旨在全面探索NeRF在农业上的优势和局限性。我们的实验结果表明，NeRF在生成新视图图像方面表现出色，并且能够与Market leader的3D Multi-View Stereo（MVS）重建软件Reality Capture竞争。然而，我们的研究也揭示了NeRF的一些缺点，包括较慢的训练速度，在不充分采样的情况下的性能局限性，以及在复杂设置下获得准确的几何困难。
</details></li>
</ul>
<hr>
<h2 id="I2VGen-XL-High-Quality-Image-to-Video-Synthesis-via-Cascaded-Diffusion-Models"><a href="#I2VGen-XL-High-Quality-Image-to-Video-Synthesis-via-Cascaded-Diffusion-Models" class="headerlink" title="I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models"></a>I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04145">http://arxiv.org/abs/2311.04145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/damo-vilab/i2vgen-xl">https://github.com/damo-vilab/i2vgen-xl</a></li>
<li>paper_authors: Shiwei Zhang, Jiayu Wang, Yingya Zhang, Kang Zhao, Hangjie Yuan, Zhiwu Qin, Xiang Wang, Deli Zhao, Jingren Zhou</li>
<li>for: 提高视频生成的semantic精度、质量和空间时间连续性</li>
<li>methods: 提出了一种叫做I2VGen-XL的方法，通过分解这两个因素来提高模型性能，并通过使用静止图像作为关键引导来保证输入数据的对齐</li>
<li>results: 通过对广泛的数据集进行优化和比较研究，显示I2VGen-XL可以同时提高视频的semantic精度、质量和空间时间连续性<details>
<summary>Abstract</summary>
Video synthesis has recently made remarkable strides benefiting from the rapid development of diffusion models. However, it still encounters challenges in terms of semantic accuracy, clarity and spatio-temporal continuity. They primarily arise from the scarcity of well-aligned text-video data and the complex inherent structure of videos, making it difficult for the model to simultaneously ensure semantic and qualitative excellence. In this report, we propose a cascaded I2VGen-XL approach that enhances model performance by decoupling these two factors and ensures the alignment of the input data by utilizing static images as a form of crucial guidance. I2VGen-XL consists of two stages: i) the base stage guarantees coherent semantics and preserves content from input images by using two hierarchical encoders, and ii) the refinement stage enhances the video's details by incorporating an additional brief text and improves the resolution to 1280$\times$720. To improve the diversity, we collect around 35 million single-shot text-video pairs and 6 billion text-image pairs to optimize the model. By this means, I2VGen-XL can simultaneously enhance the semantic accuracy, continuity of details and clarity of generated videos. Through extensive experiments, we have investigated the underlying principles of I2VGen-XL and compared it with current top methods, which can demonstrate its effectiveness on diverse data. The source code and models will be publicly available at \url{https://i2vgen-xl.github.io}.
</details>
<details>
<summary>摘要</summary>
Video合成最近几年已经取得了很大的进步，得益于扩散模型的快速发展。然而，它仍然面临 semantic accuracy、清晰度和时空连续性等问题。这些问题主要归结于缺乏准确的文本视频数据和视频的复杂内在结构，使模型具备同时保证 semantic 和质量的能力很困难。在这份报告中，我们提议一种名为 I2VGen-XL 的方法，该方法可以提高模型性能，并同时保证输入数据的对齐。I2VGen-XL 由两个阶段组成：一个基础阶段，使用两个层次编码器保证 coherent semantics 和保留输入图像中的内容，以及一个改进阶段，通过添加一个简短的文本和提高分辨率到 1280 $\times$ 720 来提高视频的细节。为了提高多样性，我们收集了约 35 万个单shot text-video 对和 6 亿个 text-image 对，用于优化模型。通过这些方法，I2VGen-XL 可以同时提高 semantic accuracy、时空连续性和视频的清晰度。经过了广泛的实验，我们发现 I2VGen-XL 的下列原则和现有的顶尖方法进行比较，可以证明其效果适用于多样的数据。模型和代码将在 \url{https://i2vgen-xl.github.io} 上公开。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Semantic-Map-Representation-for-Skill-based-Visual-Object-Navigation"><a href="#Interactive-Semantic-Map-Representation-for-Skill-based-Visual-Object-Navigation" class="headerlink" title="Interactive Semantic Map Representation for Skill-based Visual Object Navigation"></a>Interactive Semantic Map Representation for Skill-based Visual Object Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04107">http://arxiv.org/abs/2311.04107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tatiana Zemskova, Aleksei Staroverov, Kirill Muravyev, Dmitry Yudin, Aleksandr Panov</li>
<li>for: 该论文旨在提出一种新的场景semantic地图表示方法，用于移动 робоットnavigation。</li>
<li>methods: 该方法基于神经网络方法，通过backpropagation算法在推理过程中调整segmentation模型的权重，以实现在各种图像序列中进行推理。</li>
<li>results: 该方法在Habitat环境中进行了广泛的实验，并与当前最佳方法进行比较，结果显示了 significiant superiority in navigation quality metrics。<details>
<summary>Abstract</summary>
Visual object navigation using learning methods is one of the key tasks in mobile robotics. This paper introduces a new representation of a scene semantic map formed during the embodied agent interaction with the indoor environment. It is based on a neural network method that adjusts the weights of the segmentation model with backpropagation of the predicted fusion loss values during inference on a regular (backward) or delayed (forward) image sequence. We have implemented this representation into a full-fledged navigation approach called SkillTron, which can select robot skills from end-to-end policies based on reinforcement learning and classic map-based planning methods. The proposed approach makes it possible to form both intermediate goals for robot exploration and the final goal for object navigation. We conducted intensive experiments with the proposed approach in the Habitat environment, which showed a significant superiority in navigation quality metrics compared to state-of-the-art approaches. The developed code and used custom datasets are publicly available at github.com/AIRI-Institute/skill-fusion.
</details>
<details>
<summary>摘要</summary>
visual 对象导航使用学习方法是移动机器人控制中的关键任务之一。这篇论文介绍了一种新的场景semantic map表示方法，基于神经网络方法在感知过程中调整分割模型的权重，并通过反propagation或延迟图像序列进行INFERENCE。我们在SkillTron navigation方法中实现了这种表示方法，可以根据权重学习和经典地图基本 планирова方法选择机器人技能。这种方法可以形成机器人探索的中间目标以及对象导航的最终目标。我们在Habitat环境中进行了广泛的实验，并表明该方法在导航质量指标上显著超过了现有方法。开发的代码和自定义数据集在github.com/AIRI-Institute/skill-fusion上公开可用。
</details></li>
</ul>
<hr>
<h2 id="DeepPatent2-A-Large-Scale-Benchmarking-Corpus-for-Technical-Drawing-Understanding"><a href="#DeepPatent2-A-Large-Scale-Benchmarking-Corpus-for-Technical-Drawing-Understanding" class="headerlink" title="DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding"></a>DeepPatent2: A Large-Scale Benchmarking Corpus for Technical Drawing Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04098">http://arxiv.org/abs/2311.04098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kehinde Ajayi, Xin Wei, Martin Gryder, Winston Shields, Jian Wu, Shawn M. Jones, Michal Kucer, Diane Oyen</li>
<li>For: The paper is written for researchers and developers in the field of computer vision and natural language processing, with a focus on improving the accuracy and versatility of image captioning and 3D reconstruction tasks.* Methods: The paper introduces a large-scale dataset called DeepPatent2, which consists of over 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents. The authors use this dataset to demonstrate the usefulness of conceptual captioning and highlight the potential usefulness of the dataset for other research areas such as 3D image reconstruction and image retrieval.* Results: The authors achieve state-of-the-art performance on conceptual captioning tasks using DeepPatent2, and demonstrate the potential of the dataset for other tasks such as 3D image reconstruction and image retrieval.Here’s the same information in Simplified Chinese text:* For: 这篇论文是为计算机视觉和自然语言处理领域的研究人员和开发者写的，旨在提高图像captioning和3D重建等任务的准确性和多样性。* Methods: 论文引入了一个大规模的数据集——DeepPatent2，包含14年美国设计专利文书中的270多万个技术图像，其中包含132,890个物品名称和22,394个视点。作者使用这个数据集来证明概念captioning的有用性，并 highlight了数据集的潜在用途，例如3D图像重建和图像搜索。* Results: 作者通过使用DeepPatent2数据集，实现了图像captioning任务的state-of-the-art性能，并证明了数据集的潜在用途，例如3D图像重建和图像搜索。<details>
<summary>Abstract</summary>
Recent advances in computer vision (CV) and natural language processing have been driven by exploiting big data on practical applications. However, these research fields are still limited by the sheer volume, versatility, and diversity of the available datasets. CV tasks, such as image captioning, which has primarily been carried out on natural images, still struggle to produce accurate and meaningful captions on sketched images often included in scientific and technical documents. The advancement of other tasks such as 3D reconstruction from 2D images requires larger datasets with multiple viewpoints. We introduce DeepPatent2, a large-scale dataset, providing more than 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents. We demonstrate the usefulness of DeepPatent2 with conceptual captioning. We further provide the potential usefulness of our dataset to facilitate other research areas such as 3D image reconstruction and image retrieval.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)latest advances in computer vision (CV) and natural language processing have been driven by exploiting big data on practical applications. However, these research fields are still limited by the sheer volume, versatility, and diversity of the available datasets. CV tasks, such as image captioning, which has primarily been carried out on natural images, still struggle to produce accurate and meaningful captions on sketched images often included in scientific and technical documents. The advancement of other tasks such as 3D reconstruction from 2D images requires larger datasets with multiple viewpoints. We introduce DeepPatent2, a large-scale dataset, providing more than 2.7 million technical drawings with 132,890 object names and 22,394 viewpoints extracted from 14 years of US design patent documents. We demonstrate the usefulness of DeepPatent2 with conceptual captioning. We further provide the potential usefulness of our dataset to facilitate other research areas such as 3D image reconstruction and image retrieval.
</details></li>
</ul>
<hr>
<h2 id="Image-Pointcloud-Fusion-based-Anomaly-Detection-using-PD-REAL-Dataset"><a href="#Image-Pointcloud-Fusion-based-Anomaly-Detection-using-PD-REAL-Dataset" class="headerlink" title="Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset"></a>Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04095">http://arxiv.org/abs/2311.04095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianjian Qin, Chunzhi Gu, Jun Yu, Chao Zhang</li>
<li>for: 这个论文是为了提供一个大规模的无监督异常检测（AD）数据集，用于在3D领域中进行无监督异常检测。</li>
<li>methods: 这个数据集使用了Play-Doh模型，包含15种物品类别，并在控制的环境中进行了 anomaly 的分析。Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios.</li>
<li>results:  comparing with existing 3D AD dataset, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables. Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information.<details>
<summary>Abstract</summary>
We present PD-REAL, a novel large-scale dataset for unsupervised anomaly detection (AD) in the 3D domain. It is motivated by the fact that 2D-only representations in the AD task may fail to capture the geometric structures of anomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL consists entirely of Play-Doh models for 15 object categories and focuses on the analysis of potential benefits from 3D information in a controlled environment. Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios. To demonstrate the usefulness of 3D information, we use a commercially available RealSense camera to capture RGB and depth images. Compared to the existing 3D dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables. Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information. Our dataset can be downloaded from https://github.com/Andy-cs008/PD-REAL
</details>
<details>
<summary>摘要</summary>
我团队现在发布了PD-REAL，一个大规模的无监督异常检测（AD）数据集在3D领域。这是因为2D只的表示在AD任务中可能无法捕捉异常的几何结构，因为光照条件或拍摄角度的不确定性。PD-REAL由Play-Doh模型组成，涵盖15种物品类别，并专注于控制环境中3D信息的分析。具体来说，物品首先被设置了6种异常，如损凹、裂缝或穿孔，然后在不同的照明条件下拍摄，以模拟实际检测场景。为了证明3D信息的有用性，我们使用了一款商业化的RealSense摄像头捕摄RGB和深度图像。与现有的3D数据集 для AD任务相比，PD-REAL的数据采集更加便宜、可扩展和更容易控制变量。我们对state-of-the-art AD算法进行了广泛的评估，并证明了使用3D信息的好处以及挑战。您可以从https://github.com/Andy-cs008/PD-REAL下载我们的数据集。
</details></li>
</ul>
<hr>
<h2 id="Proceedings-of-the-5th-International-Workshop-on-Reading-Music-Systems"><a href="#Proceedings-of-the-5th-International-Workshop-on-Reading-Music-Systems" class="headerlink" title="Proceedings of the 5th International Workshop on Reading Music Systems"></a>Proceedings of the 5th International Workshop on Reading Music Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04091">http://arxiv.org/abs/2311.04091</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suziai/gui-tools">https://github.com/suziai/gui-tools</a></li>
<li>paper_authors: Jorge Calvo-Zaragoza, Alexander Pacha, Elona Shatri</li>
<li>for: 这个论文是关于音乐读取系统的研讨会论文，目的是连接发展音乐读取系统的研究人员与需要这些系统的研究人员和实践者。</li>
<li>methods: 这篇论文的研究方法包括音乐读取系统、光学音乐识别、数据集和性能评估、图像处理Music scores、多模态系统、新的音乐输入方法等。</li>
<li>results: 这篇论文提出了5个国际音乐读取系统研讨会的进展，包括音乐读取系统、光学音乐识别、数据集和性能评估、图像处理Music scores、多模态系统、新的音乐输入方法等。<details>
<summary>Abstract</summary>
The International Workshop on Reading Music Systems (WoRMS) is a workshop that tries to connect researchers who develop systems for reading music, such as in the field of Optical Music Recognition, with other researchers and practitioners that could benefit from such systems, like librarians or musicologists. The relevant topics of interest for the workshop include, but are not limited to: Music reading systems; Optical music recognition; Datasets and performance evaluation; Image processing on music scores; Writer identification; Authoring, editing, storing and presentation systems for music scores; Multi-modal systems; Novel input-methods for music to produce written music; Web-based Music Information Retrieval services; Applications and projects; Use-cases related to written music.   These are the proceedings of the 5th International Workshop on Reading Music Systems, held in Milan, Italy on Nov. 4th 2023.
</details>
<details>
<summary>摘要</summary>
世界音乐读取系统国际研讨会（WoRMS）是一个研讨会，旨在连接开发音乐读取系统的研究人员（如光学音乐识别领域）与其他研究人员和实践者（如图书馆员或音乐学家），以便共同分享和交流有关音乐读取系统的最新研究成果和应用经验。研讨会的主要研究领域包括，但不限于：* 音乐读取系统* 光学音乐识别* 数据集和性能评估* 音乐手稿图像处理* 作者识别* 作品编辑、存储和展示系统* 多Modal系统* 新的音乐输入方法生成written music* Web基于音乐信息检索服务* 应用和项目* 关于written music的使用场景这是第5届世界音乐读取系统国际研讨会的论文集，于2023年11月4日在意大利米兰举行。
</details></li>
</ul>
<hr>
<h2 id="Learning-Super-Resolution-Ultrasound-Localization-Microscopy-from-Radio-Frequency-Data"><a href="#Learning-Super-Resolution-Ultrasound-Localization-Microscopy-from-Radio-Frequency-Data" class="headerlink" title="Learning Super-Resolution Ultrasound Localization Microscopy from Radio-Frequency Data"></a>Learning Super-Resolution Ultrasound Localization Microscopy from Radio-Frequency Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04081">http://arxiv.org/abs/2311.04081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Hahne, Georges Chabouh, Olivier Couture, Raphael Sznitman</li>
<li>for: 本研究旨在提高 Ultrasound Localization Microscopy (ULM) 的解像能力，通过快速和高效地目标位置的准确地Localization。</li>
<li>methods: 本研究提议使用无处理 Radio-Frequency (RF) 数据，并通过超Resolution网络来替代延迟和总和 (DAS) 干扰。为此，我们展示了标签投影和反向点变换，以将 B-mode 和 RF 坐标空间相互转换。</li>
<li>results: 我们基于公共数据集进行比较，结果表明，不使用 DAS 干扰可以提高 ULM 的解像能力。我们的 RF 训练网络表明，禁用 DAS 干扰可以优化 ULM 的解像性能。<details>
<summary>Abstract</summary>
Ultrasound Localization Microscopy (ULM) enables imaging of vascular structures in the micrometer range by accumulating contrast agent particle locations over time. Precise and efficient target localization accuracy remains an active research topic in the ULM field to further push the boundaries of this promising medical imaging technology. Existing work incorporates Delay-And-Sum (DAS) beamforming into particle localization pipelines, which ultimately determines the ULM image resolution capability. In this paper we propose to feed unprocessed Radio-Frequency (RF) data into a super-resolution network while bypassing DAS beamforming and its limitations. To facilitate this, we demonstrate label projection and inverse point transformation between B-mode and RF coordinate space as required by our approach. We assess our method against state-of-the-art techniques based on a public dataset featuring in silico and in vivo data. Results from our RF-trained network suggest that excluding DAS beamforming offers a great potential to optimize on the ULM resolution performance.
</details>
<details>
<summary>摘要</summary>
ultrasound localization microscopy (ULM) 可以在微米级别进行血管结构成像，通过时间积累反应剂粒子位置。ULM领域中精准和高效目标Localization精度仍然是活跃的研究主题，以进一步推动这种有前途的医疗成像技术的发展。现有的方法将延迟和总和（DAS）扫描成为反射波数据的处理步骤，这 ultimately determines the ULM 图像分辨率能力。在这篇论文中，我们提议将未处理的Radio-Frequency（RF）数据传递到超分辨网络中，并 circumvent DAS 扫描的限制。为此，我们实现了标签投影和反向点变换 между B-mode 和RF 坐标空间，这些步骤是我们的方法所需。我们根据公共数据集进行比较，结果表明，不包括 DAS 扫描可以优化 ULM 的分辨率性能。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Lane-Perception-and-Topology-Understanding-with-Standard-Definition-Navigation-Maps"><a href="#Augmenting-Lane-Perception-and-Topology-Understanding-with-Standard-Definition-Navigation-Maps" class="headerlink" title="Augmenting Lane Perception and Topology Understanding with Standard Definition Navigation Maps"></a>Augmenting Lane Perception and Topology Understanding with Standard Definition Navigation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04079">http://arxiv.org/abs/2311.04079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katie Z Luo, Xinshuo Weng, Yan Wang, Shuang Wu, Jie Li, Kilian Q Weinberger, Yue Wang, Marco Pavone</li>
<li>for: 本研究旨在探讨标准定义（SD）地图在实时车道拓扑理解方面的效果。</li>
<li>methods: 我们提出了一种新的框架，将SD地图集成到在线地图预测中，并使用Transformer编码器，即SD Map Encoder Representations from transFormers，利用SD地图中的假设来提高车道拓扑预测。</li>
<li>results: 我们的方法可以在当前领先的在线地图预测方法上显著提高（最多60%）车道检测和拓扑预测，而且不需要额外的硬件或软件支持。代码可以在<a target="_blank" rel="noopener" href="https://github.com/NVlabs/SMERF%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/NVlabs/SMERF中下载。</a><details>
<summary>Abstract</summary>
Autonomous driving has traditionally relied heavily on costly and labor-intensive High Definition (HD) maps, hindering scalability. In contrast, Standard Definition (SD) maps are more affordable and have worldwide coverage, offering a scalable alternative. In this work, we systematically explore the effect of SD maps for real-time lane-topology understanding. We propose a novel framework to integrate SD maps into online map prediction and propose a Transformer-based encoder, SD Map Encoder Representations from transFormers, to leverage priors in SD maps for the lane-topology prediction task. This enhancement consistently and significantly boosts (by up to 60%) lane detection and topology prediction on current state-of-the-art online map prediction methods without bells and whistles and can be immediately incorporated into any Transformer-based lane-topology method. Code is available at https://github.com/NVlabs/SMERF.
</details>
<details>
<summary>摘要</summary>
自适应驾驶曾经受到高Definition（HD）地图的压力，导致成本和劳动力成本较高，阻碍了扩展性。相比之下，标准Definition（SD）地图更加可Affordable和全球覆盖率，提供了可扩展的代替方案。在这种工作中，我们系统性地探索了SD地图在实时车道topology理解中的效果。我们提议了一种将SD地图integrated into online map prediction的框架，并使用Transformer基于的encoder，即SD Map Encoder Representations from transFormers，以利用SD地图中的假设 для车道topology预测任务。这种改进可以Consistently和Significantly Boost（up to 60%）车道检测和topology预测Current state-of-the-art online map prediction方法不需要额外的配置和特性。代码可以在https://github.com/NVlabs/SMERF中下载。
</details></li>
</ul>
<hr>
<h2 id="Energy-based-Calibrated-VAE-with-Test-Time-Free-Lunch"><a href="#Energy-based-Calibrated-VAE-with-Test-Time-Free-Lunch" class="headerlink" title="Energy-based Calibrated VAE with Test Time Free Lunch"></a>Energy-based Calibrated VAE with Test Time Free Lunch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04071">http://arxiv.org/abs/2311.04071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihong Luo, Siya Qiu, Xingjian Tao, Yujun Cai, Jing Tang</li>
<li>for: 提高Variational Autoencoders（VAEs）的描述质量和效率，使其能够生成高质量的图像和进行零shot图像修复。</li>
<li>methods: 使用Conditional Energy-Based Model（EBM）来调整VAEs的生成方向，不需要测试阶段MCMC抽样。</li>
<li>results: 通过对多个应用进行广泛的实验，包括图像生成和零shot图像修复，提出的方法实现了单步非对抗性生成的 estado-of-the-art表现。<details>
<summary>Abstract</summary>
In this paper, we propose a novel Energy-Calibrated Generative Model that utilizes a Conditional EBM for enhancing Variational Autoencoders (VAEs). VAEs are sampling efficient but often suffer from blurry generation results due to the lack of training in the generative direction. On the other hand, Energy-Based Models (EBMs) can generate high-quality samples but require expensive Markov Chain Monte Carlo (MCMC) sampling. To address these issues, we introduce a Conditional EBM for calibrating the generative direction during training, without requiring it for test time sampling. Our approach enables the generative model to be trained upon data and calibrated samples with adaptive weight, thereby enhancing efficiency and effectiveness without necessitating MCMC sampling in the inference phase. We also show that the proposed approach can be extended to calibrate normalizing flows and variational posterior. Moreover, we propose to apply the proposed method to zero-shot image restoration via neural transport prior and range-null theory. We demonstrate the effectiveness of the proposed method through extensive experiments in various applications, including image generation and zero-shot image restoration. Our method shows state-of-the-art performance over single-step non-adversarial generation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的能量准确生成模型，利用条件EBM对VAEs进行增强。VAEs的采样效率高，但通常会因为生成方向的缺失而导致生成结果模糊。而EBMs可以生成高质量的样本，但需要昂贵的MCMC采样。为了解决这些问题，我们引入了条件EBM，在训练过程中准确了生成方向，不需要测试阶段的MCMC采样。我们的方法使得生成模型可以在数据和适应性采样下接受训练，从而提高效率和效果，不需要测试阶段的MCMC采样。此外，我们还证明了我们的方法可以扩展到调整正态流和量化 posterior。此外，我们还提出了应用我们的方法于零码图像恢复，通过神经运输先验和范围-null理论。我们通过了广泛的实验，包括图像生成和零码图像恢复，证明了我们的方法的有效性。我们的方法在单步非对抗生成方面表现出了状态级的表现。
</details></li>
</ul>
<hr>
<h2 id="LISBET-a-self-supervised-Transformer-model-for-the-automatic-segmentation-of-social-behavior-motifs"><a href="#LISBET-a-self-supervised-Transformer-model-for-the-automatic-segmentation-of-social-behavior-motifs" class="headerlink" title="LISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs"></a>LISBET: a self-supervised Transformer model for the automatic segmentation of social behavior motifs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04069">http://arxiv.org/abs/2311.04069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giuseppe Chindemi, Benoit Girard, Camilla Bellone</li>
<li>for: 本研究旨在更好地理解社交行为的核心原理，以便更好地理解社交障碍的 neural 基础。</li>
<li>methods: 本研究使用 LISBET（seLf-supervIsed Social BEhavioral Transformer）模型，通过自我超vised learning 检测和量化社交互动，不需要特征选择和广泛的人类标注。</li>
<li>results: 研究发现，使用发现驱动模式的社交互动模式识别与人类标注高度相似，并且与 dopaminergic neurons 的电physiological 活动在 Ventral Tegmental Area (VTA) 相关。<details>
<summary>Abstract</summary>
Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions. Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning. We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA). We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings.
</details>
<details>
<summary>摘要</summary>
社会行为，定义为个体在响应他人时的行为过程，对社会的功能和心理健康具有杰yk的意义。为了全面理解社会行为的复杂性和潜在的治疗目标，需要了解其核心原则。虽然机器学习算法已使研究特定方面的复杂行为变得更加容易，但当前方法ologies往往专注于单个动物的行为。本研究提出了 LISBET（seLf-supervIsed Social BEhavioral Transformer）模型，用于探测和分类社交互动。我们的模型不需要特定的特征选择和大量的人类标注，可以通过自动学习探测和评估社交行为的动态身体部分跟踪数据。LISBET可以在假设驱动模式下用超级visedfinetuning自动分类行为，以及在发现驱动模式下使用无监督学习分类社交行为模式。我们发现使用发现驱动模式分类的模式与人类标注非常相似，并且与苯乙胺酸细胞体内的 dopamine 神经元活动在腹主梁细胞区（VTA）也存在相似性。我们希望 LISBET 能帮助社区更好地理解社交行为和其神经基础。
</details></li>
</ul>
<hr>
<h2 id="mmFUSION-Multimodal-Fusion-for-3D-Objects-Detection"><a href="#mmFUSION-Multimodal-Fusion-for-3D-Objects-Detection" class="headerlink" title="mmFUSION: Multimodal Fusion for 3D Objects Detection"></a>mmFUSION: Multimodal Fusion for 3D Objects Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04058">http://arxiv.org/abs/2311.04058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javed Ahmad, Alessio Del Bue</li>
<li>for: 提高自驾车系统中三维物体检测的准确性，使用camera和LiDAR感知器进行多感知融合。</li>
<li>methods: 提出一种新的中间水平多感知融合方法（mmFUSION），使用每个感知器分别计算特征，并通过对各感知器的特征进行交叠和多感知注意力机制进行融合。</li>
<li>results: 在KITTI和NuScenes dataset上评估 mmFUSION，与可用的早期、中间、晚期和两个阶段融合方案相比，表现更好。<details>
<summary>Abstract</summary>
Multi-sensor fusion is essential for accurate 3D object detection in self-driving systems. Camera and LiDAR are the most commonly used sensors, and usually, their fusion happens at the early or late stages of 3D detectors with the help of regions of interest (RoIs). On the other hand, fusion at the intermediate level is more adaptive because it does not need RoIs from modalities but is complex as the features of both modalities are presented from different points of view. In this paper, we propose a new intermediate-level multi-modal fusion (mmFUSION) approach to overcome these challenges. First, the mmFUSION uses separate encoders for each modality to compute features at a desired lower space volume. Second, these features are fused through cross-modality and multi-modality attention mechanisms proposed in mmFUSION. The mmFUSION framework preserves multi-modal information and learns to complement modalities' deficiencies through attention weights. The strong multi-modal features from the mmFUSION framework are fed to a simple 3D detection head for 3D predictions. We evaluate mmFUSION on the KITTI and NuScenes dataset where it performs better than available early, intermediate, late, and even two-stage based fusion schemes. The code with the mmdetection3D project plugin will be publicly available soon.
</details>
<details>
<summary>摘要</summary>
多感器融合是自动驾驶系统中精准三维对象检测的关键。 Camera 和 LiDAR 是最常用的感知器，而其融合通常发生在检测器的 early 或 late 阶段，使用了区域兴趣（RoI）的帮助。然而，中间阶段的融合更加适应，因为它不需要 RoI 从不同的模式来，但是复杂度也较高，因为两种模式的特征从不同的角度来。在这篇论文中，我们提出了一种新的中间阶段多模态融合（mmFUSION）方法，以解决这些挑战。首先，mmFUSION 使用了每种感知器的独立编码器来计算特征，以达到所需的较低的空间体积。其次，这些特征通过 cross-modality 和 multi-modality 注意机制进行融合。mmFUSION 框架保留了多模态信息，并通过注意 веса来补做每种模式的不足。强大的多模态特征从 mmFUSION 框架中得到的是 fed 到一个简单的三维检测头进行三维预测。我们在 KITTI 和 NuScenes 数据集上评估了 mmFUSION，其表现比已有的 early、intermediate、late 和 même 阶段融合方案更好。代码将在 soon 公开。
</details></li>
</ul>
<hr>
<h2 id="Generative-Structural-Design-Integrating-BIM-and-Diffusion-Model"><a href="#Generative-Structural-Design-Integrating-BIM-and-Diffusion-Model" class="headerlink" title="Generative Structural Design Integrating BIM and Diffusion Model"></a>Generative Structural Design Integrating BIM and Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04052">http://arxiv.org/abs/2311.04052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhili He, Yu-Hsing Wang, Jian Zhang</li>
<li>for: 本研究旨在提出一种涵盖所有阶段的智能结构设计方法，以减少设计过程中的时间开销和提高效率。</li>
<li>methods: 本研究引入建筑信息模型（BIM），并设计了一个 integrate BIM和生成AI的结构设计管道，以增强生成结果的可见质量和细节。</li>
<li>results: 本研究在生成框架、生成AI工具和神经网络方面做出了3个贡献，包括提出了一种新的两stage生成框架，引入了扩散模型（DM）来代替广泛使用的生成对抗网络（GAN）模型，并设计了一个新的物理基于的条件扩散模型（PCDM）。<details>
<summary>Abstract</summary>
Intelligent structural design using AI can effectively reduce time overhead and increase efficiency. It has potential to become the new design paradigm in the future to assist and even replace engineers, and so it has become a research hotspot in the academic community. However, current methods have some limitations to be addressed, whether in terms of application scope, visual quality of generated results, or evaluation metrics of results. This study proposes a comprehensive solution. Firstly, we introduce building information modeling (BIM) into intelligent structural design and establishes a structural design pipeline integrating BIM and generative AI, which is a powerful supplement to the previous frameworks that only considered CAD drawings. In order to improve the perceptual quality and details of generations, this study makes 3 contributions. Firstly, in terms of generation framework, inspired by the process of human drawing, a novel 2-stage generation framework is proposed to replace the traditional end-to-end framework to reduce the generation difficulty for AI models. Secondly, in terms of generative AI tools adopted, diffusion models (DMs) are introduced to replace widely used generative adversarial network (GAN)-based models, and a novel physics-based conditional diffusion model (PCDM) is proposed to consider different design prerequisites. Thirdly, in terms of neural networks, an attention block (AB) consisting of a self-attention block (SAB) and a parallel cross-attention block (PCAB) is designed to facilitate cross-domain data fusion. The quantitative and qualitative results demonstrate the powerful generation and representation capabilities of PCDM. Necessary ablation studies are conducted to examine the validity of the methods. This study also shows that DMs have the potential to replace GANs and become the new benchmark for generative problems in civil engineering.
</details>
<details>
<summary>摘要</summary>
使用人工智能进行智能结构设计可以有效减少时间开销并提高效率。它在未来可能成为新的设计 парадигма，帮助或者取代工程师，因此在学术界已经成为研究热点。然而，当前方法存在一些需要解决的限制，包括应用范围、生成结果的视觉质量和评价指标。本研究提出了一个完整解决方案。首先，我们将建筑信息模型（BIM）引入智能结构设计，并建立了包括BIM和生成AI的结构设计管道，这是以前的框架只考虑CAD图形的增强。为了提高生成结果的视觉质量和细节，本研究做出了三个贡献。首先，在生成框架方面，我们提出了一种新的两阶段生成框架，以replace传统的终端框架，从而降低AI模型生成难度。其次，在生成AI工具方面，我们引入了扩散模型（DM），取代了广泛使用的生成对抗网络（GAN）模型，并提出了一种新的物理基于的条件扩散模型（PCDM），以考虑不同的设计前提。最后，在神经网络方面，我们设计了一个注意块（AB），包括一个自注意块（SAB）和一个平行跨域注意块（PCAB），以便跨领域数据的混合。对于PCDM的量化和质量效果，我们进行了必要的ablation研究，以证明方法的有效性。此外，我们还发现了DMs在生成问题中的潜在可能性，可能取代GANs成为新的标准。
</details></li>
</ul>
<hr>
<h2 id="3D-EAGAN-3D-edge-aware-attention-generative-adversarial-network-for-prostate-segmentation-in-transrectal-ultrasound-images"><a href="#3D-EAGAN-3D-edge-aware-attention-generative-adversarial-network-for-prostate-segmentation-in-transrectal-ultrasound-images" class="headerlink" title="3D EAGAN: 3D edge-aware attention generative adversarial network for prostate segmentation in transrectal ultrasound images"></a>3D EAGAN: 3D edge-aware attention generative adversarial network for prostate segmentation in transrectal ultrasound images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04049">http://arxiv.org/abs/2311.04049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengqing Liu, Xiao Shao, Liping Jiang, Kaizhi Wu</li>
<li>for: 本研究的目标是提出一种高效的肾静脉图像中 prostates 的分割方法，以 overcome 当前的限制和缺点，并实现高度准确的 prostates 的分割。</li>
<li>methods: 该方法包括一个 edge-aware 分割网络（EASNet），包括一个 encoder-decoder 结构的 U-Net 背景网络、一个细节补做模块、四个 3D 空间和通道注意模块、一个 Edge 增强模块、以及一个全局特征提取器。</li>
<li>results: 实验结果表明，该方法可以准确地分割 prostates 在肾静脉图像中，并且比传统方法具有更高的准确率和更好的抗衰减性。<details>
<summary>Abstract</summary>
Automatic prostate segmentation in TRUS images has always been a challenging problem, since prostates in TRUS images have ambiguous boundaries and inhomogeneous intensity distribution. Although many prostate segmentation methods have been proposed, they still need to be improved due to the lack of sensibility to edge information. Consequently, the objective of this study is to devise a highly effective prostate segmentation method that overcomes these limitations and achieves accurate segmentation of prostates in TRUS images. A 3D edge-aware attention generative adversarial network (3D EAGAN)-based prostate segmentation method is proposed in this paper, which consists of an edge-aware segmentation network (EASNet) that performs the prostate segmentation and a discriminator network that distinguishes predicted prostates from real prostates. The proposed EASNet is composed of an encoder-decoder-based U-Net backbone network, a detail compensation module, four 3D spatial and channel attention modules, an edge enhance module, and a global feature extractor. The detail compensation module is proposed to compensate for the loss of detailed information caused by the down-sampling process of the encoder. The features of the detail compensation module are selectively enhanced by the 3D spatial and channel attention module. Furthermore, an edge enhance module is proposed to guide shallow layers in the EASNet to focus on contour and edge information in prostates. Finally, features from shallow layers and hierarchical features from the decoder module are fused through the global feature extractor to predict the segmentation prostates.
</details>
<details>
<summary>摘要</summary>
自动进行肾脏部分分割在TRUS图像中一直是一个困难的问题，因为肾脏在TRUS图像中的边界不明确，具有不均匀的强度分布。虽然许多肾脏分割方法已经被提出，但它们仍需要进一步改进，因为缺乏边缘信息的敏感性。因此，本研究的目标是开发一种高效的肾脏分割方法，可以超越这些限制，并准确地分割TRUS图像中的肾脏。本文提出的3D Edge-Aware Attention Generative Adversarial Network（3D EAGAN）基于的肾脏分割方法包括一个边缘意识分 segmentation网络（EASNet），该网络执行肾脏分割，以及一个判别网络，用于判别预测的肾脏与实际的肾脏之间的差异。EASNet由一个encoder-decoder-based U-Net底层网络、一个细节补做模块、四个3D空间和通道尺度注意模块、一个边缘增强模块以及一个全局特征提取器组成。细节补做模块的目的是补做因下采样过程而丢失的细节信息。3D空间和通道尺度注意模块可以选择性地增强细节补做模块中的特征。此外，一个边缘增强模块被提出，以引导 shallow层在EASNet中注重肾脏的沿边和边缘信息。最后， shallow层和层次特征从decoder模块中获取的特征被 fusion通过全局特征提取器来预测肾脏分割。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Near-Infrared-Hyperspectral-Imaging-for-Protein-Content-Regression-and-Grain-Variety-Classification-Using-Bulk-References-and-Varying-Grain-to-Background-Ratios"><a href="#Analyzing-Near-Infrared-Hyperspectral-Imaging-for-Protein-Content-Regression-and-Grain-Variety-Classification-Using-Bulk-References-and-Varying-Grain-to-Background-Ratios" class="headerlink" title="Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios"></a>Analyzing Near-Infrared Hyperspectral Imaging for Protein Content Regression and Grain Variety Classification Using Bulk References and Varying Grain-to-Background Ratios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04042">http://arxiv.org/abs/2311.04042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ole-Christian Galbo Engstrøm, Erik Schou Dreier, Birthe Møller Jespersen, Kim Steenstrup Pedersen</li>
<li>for: 这个论文主要针对的是使用near-infrared hyperspectral imaging（NIR-HSI）图像来调整模型，特别是蛋白质含量预测和谷物种 classification。</li>
<li>methods: 论文使用了subsampling和association方法来扩展有限的参考数据，以便适应更多的情况。然而，这种方法会导致skewed leptokurtic prediction distributions，影响PLS-R和深度CNN模型。</li>
<li>results: 论文提出了一些修正方法来减轻这些偏见，并对蛋白质参考预测的准确性进行了改进。此外，论文还研究了不同的谷物种比例对两个任务的影响。<details>
<summary>Abstract</summary>
Based on previous work, we assess the use of NIR-HSI images for calibrating models on two datasets, focusing on protein content regression and grain variety classification. Limited reference data for protein content is expanded by subsampling and associating it with the bulk sample. However, this method introduces significant biases due to skewed leptokurtic prediction distributions, affecting both PLS-R and deep CNN models. We propose adjustments to mitigate these biases, improving mean protein reference predictions. Additionally, we investigate the impact of grain-to-background ratios on both tasks. Higher ratios yield more accurate predictions, but including lower-ratio images in calibration enhances model robustness for such scenarios.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:根据前一项研究，我们评估了使用近红外多spectral图像（NIR-HSI）来调整两个数据集上的模型，主要关注蛋白量回归和谷物种分类。但由于蛋白量参考数据的有限性，我们使用下采样和与大量样本关联来扩展参考数据。这种方法引入了显著的偏见，影响了PLS-R和深度神经网络模型的预测。为了缓解这些偏见，我们提出了调整，以提高蛋白量参考预测的均值。此外，我们还调查了芯果与背景率对两个任务的影响，发现高芯果率导致更准确的预测，但包含低芯果率图像在核心级别上进行调整可以提高模型对这种场景的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Data-exploitation-multi-task-learning-of-object-detection-and-semantic-segmentation-on-partially-annotated-data"><a href="#Data-exploitation-multi-task-learning-of-object-detection-and-semantic-segmentation-on-partially-annotated-data" class="headerlink" title="Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data"></a>Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04040">http://arxiv.org/abs/2311.04040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoàng-Ân Lê, Minh-Tan Pham</li>
<li>for: 这 paper  investigate 多任务 partially annotated data 的潜在帮助，即每个数据点只有一个任务得到标注。</li>
<li>methods: 这 paper 使用 joint learning 方法，将 object detection 和 semantic segmentation 作为两个任务，从多任务数据中学习。</li>
<li>results: 实验结果表明，多任务学习和知识传播可以获得更好的性能，比单任务学习和全supervision scenario。所有代码和数据分割可以在 GitHub 上找到。<details>
<summary>Abstract</summary>
Multi-task partially annotated data where each data point is annotated for only a single task are potentially helpful for data scarcity if a network can leverage the inter-task relationship. In this paper, we study the joint learning of object detection and semantic segmentation, the two most popular vision problems, from multi-task data with partial annotations. Extensive experiments are performed to evaluate each task performance and explore their complementarity when a multi-task network cannot optimize both tasks simultaneously. We propose employing knowledge distillation to leverage joint-task optimization. The experimental results show favorable results for multi-task learning and knowledge distillation over single-task learning and even full supervision scenario. All code and data splits are available at https://github.com/lhoangan/multas
</details>
<details>
<summary>摘要</summary>
多任务半标注数据，每个数据点只有单个任务的标注，可能对数据缺乏情况带来帮助，如果网络可以利用任务之间的关系。在这篇论文中，我们研究了对象检测和 semantic segmentation 两个最受欢迎的视觉问题的共同学习，从多任务数据中的半标注中学习。我们进行了广泛的实验来评估每个任务的性能，并探索它们之间的补充性。我们提议使用知识传播来利用共同优化。实验结果显示，多任务学习和知识传播在单任务学习和全supervision情况下具有有利的效果。所有代码和数据分割可以在 GitHub 上找到：https://github.com/lhoangan/multas。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Dataset-Scale-Indicators-of-Data-Quality"><a href="#Exploring-Dataset-Scale-Indicators-of-Data-Quality" class="headerlink" title="Exploring Dataset-Scale Indicators of Data Quality"></a>Exploring Dataset-Scale Indicators of Data Quality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04016">http://arxiv.org/abs/2311.04016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Feuer, Chinmay Hegde</li>
<li>for: 这篇论文主要是为了解决现代计算机视觉基础模型的训练所需的大量数据和成本问题。</li>
<li>methods: 这篇论文使用了改进数据质量来降低模型训练所需的数据量。作者认为数据质量可以分解为样本级别和数据集级别两个部分，而样本级别的研究更为广泛。他们还研究了标签集设计和分类均衡对模型性能的影响。</li>
<li>results: 作者通过监测这些指标来评估模型性能，包括准确率和分布转移Robustness。<details>
<summary>Abstract</summary>
Modern computer vision foundation models are trained on massive amounts of data, incurring large economic and environmental costs. Recent research has suggested that improving data quality can significantly reduce the need for data quantity. But what constitutes data quality in computer vision? We posit that the quality of a given dataset can be decomposed into distinct sample-level and dataset-level constituents, and that the former have been more extensively studied than the latter. We ablate the effects of two important dataset-level constituents: label set design, and class balance. By monitoring these constituents using key indicators we provide, researchers and practitioners can better anticipate model performance, measured in terms of its accuracy and robustness to distribution shifts.
</details>
<details>
<summary>摘要</summary>
现代计算机视觉基础模型通常在大量数据上进行训练，导致经济和环境成本增加。 latest research suggests that improving data quality can significantly reduce the need for data quantity. 但是，计算机视觉中的数据质量哪些组成部分？ we propose that the quality of a given dataset can be decomposed into two constituents: sample-level and dataset-level.  sample-level constituents have been more extensively studied than dataset-level constituents. we investigate the effects of two important dataset-level constituents: label set design and class balance. by monitoring these constituents using key indicators we provide, researchers and practitioners can better anticipate model performance, measured in terms of its accuracy and robustness to distribution shifts.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="AGNES-Abstraction-guided-Framework-for-Deep-Neural-Networks-Security"><a href="#AGNES-Abstraction-guided-Framework-for-Deep-Neural-Networks-Security" class="headerlink" title="AGNES: Abstraction-guided Framework for Deep Neural Networks Security"></a>AGNES: Abstraction-guided Framework for Deep Neural Networks Security</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04009">http://arxiv.org/abs/2311.04009</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay Dhonthi, Marcello Eiermann, Ernst Moritz Hahn, Vahid Hashemi</li>
<li>for: 这篇论文旨在检测深度神经网络（DNNs）中的后门，以确保图像识别 task 的正确性。</li>
<li>methods: 本文提出了一种名为 AGNES 的工具，用于检测 DNNs 中的后门。该工具基于一种新的检测方法，可以更好地检测多种不同类型的后门。</li>
<li>results: 作者通过多个实验示例表明，AGNES 比许多现有的方法在多个有关的案例中表现更好。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) are becoming widespread, particularly in safety-critical areas. One prominent application is image recognition in autonomous driving, where the correct classification of objects, such as traffic signs, is essential for safe driving. Unfortunately, DNNs are prone to backdoors, meaning that they concentrate on attributes of the image that should be irrelevant for their correct classification. Backdoors are integrated into a DNN during training, either with malicious intent (such as a manipulated training process, because of which a yellow sticker always leads to a traffic sign being recognised as a stop sign) or unintentional (such as a rural background leading to any traffic sign being recognised as animal crossing, because of biased training data).   In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for image recognition. We discuss the principle approach on which AGNES is based. Afterwards, we show that our tool performs better than many state-of-the-art methods for multiple relevant case studies.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在安全关键领域广泛应用，特别是自动驾驶图像识别。正确识别图像中的对象，如交通标志，是安全驾驶的关键。可惜，DNN容易受到后门攻击，即它们强调图像中不相关的特征，导致错误识别。后门可以在训练过程中被针对性地注入（如一个受到修改的训练过程，导致所有的交通标志都被识别为停车标志），或者不Intentional（如农村背景导致任何交通标志都被识别为动物过道）。在这篇论文中，我们介绍了AGNES，一种用于检测DNN图像识别后门的工具。我们讲述AGNES的原理方法。然后，我们展示了我们的工具在多个相关的案例研究中的性能比以前的state-of-the-art方法更好。
</details></li>
</ul>
<hr>
<h2 id="Bias-and-Diversity-in-Synthetic-based-Face-Recognition"><a href="#Bias-and-Diversity-in-Synthetic-based-Face-Recognition" class="headerlink" title="Bias and Diversity in Synthetic-based Face Recognition"></a>Bias and Diversity in Synthetic-based Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03970">http://arxiv.org/abs/2311.03970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Huber, Anh Thi Luu, Fadi Boutros, Arjan Kuijper, Naser Damer</li>
<li>for: 本研究旨在 investigate synthetic face recognition datasets 的多样性和生成模型的偏见问题。</li>
<li>methods: 我们使用了三种最新的synthetic-based face recognition模型，并对不同的人群特征（性别、种族、年龄、头部位置）进行分析。</li>
<li>results: 我们发现生成模型对不同特征的分布类似于用于训练的数据分布，而且synthetic-based模型与authentic-based模型具有相似的偏见行为。 however, we found that the lower intra-identity attribute consistency in the synthetic data can help reduce bias.<details>
<summary>Abstract</summary>
Synthetic data is emerging as a substitute for authentic data to solve ethical and legal challenges in handling authentic face data. The current models can create real-looking face images of people who do not exist. However, it is a known and sensitive problem that face recognition systems are susceptible to bias, i.e. performance differences between different demographic and non-demographics attributes, which can lead to unfair decisions. In this work, we investigate how the diversity of synthetic face recognition datasets compares to authentic datasets, and how the distribution of the training data of the generative models affects the distribution of the synthetic data. To do this, we looked at the distribution of gender, ethnicity, age, and head position. Furthermore, we investigated the concrete bias of three recent synthetic-based face recognition models on the studied attributes in comparison to a baseline model trained on authentic data. Our results show that the generator generate a similar distribution as the used training data in terms of the different attributes. With regard to bias, it can be seen that the synthetic-based models share a similar bias behavior with the authentic-based models. However, with the uncovered lower intra-identity attribute consistency seems to be beneficial in reducing bias.
</details>
<details>
<summary>摘要</summary>
现代技术在面临道德和法律问题时，人工生成的数据正在扮演一个替代者。目前的模型可以生成存在不存在的人脸图像。然而，已经知道和敏感的问题是，人脸识别系统容易受到偏见影响，即不同的民族和非民族属性之间的性能差异，这可能导致不公正的决策。在这种工作中，我们研究了生成模型训练数据的多样性与authentic数据集的多样性之间的关系，以及生成模型训练数据的分布对生成数据的分布的影响。为此，我们查看了性别、民族、年龄和头部位置的分布。此外，我们还investigated了三个最近的人工生成基于面识别模型的偏见情况，与基eline模型在不同属性上的性能差异。我们的结果显示，生成器会生成与训练数据的分布相似的分布，包括不同的属性。在偏见方面，人工生成基于模型和authentic基于模型都表现出类似的偏见行为。然而，通过降低内属性一致性，可以减少偏见。
</details></li>
</ul>
<hr>
<h2 id="CeCNN-Copula-enhanced-convolutional-neural-networks-in-joint-prediction-of-refraction-error-and-axial-length-based-on-ultra-widefield-fundus-images"><a href="#CeCNN-Copula-enhanced-convolutional-neural-networks-in-joint-prediction-of-refraction-error-and-axial-length-based-on-ultra-widefield-fundus-images" class="headerlink" title="CeCNN: Copula-enhanced convolutional neural networks in joint prediction of refraction error and axial length based on ultra-widefield fundus images"></a>CeCNN: Copula-enhanced convolutional neural networks in joint prediction of refraction error and axial length based on ultra-widefield fundus images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03967">http://arxiv.org/abs/2311.03967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong Zhong, Yang Li, Danjuan Yang, Meiyan Li, Xingyao Zhou, Bo Fu, Catherine C. Liu, A. H. Welsh</li>
<li>for: The paper is written for the purpose of developing a new deep learning model that can better predict myopia outcomes using both spherical equivalent (SE) and axial length (AL) information.</li>
<li>methods: The paper proposes a copula-enhanced convolutional neural network (CeCNN) framework that incorporates the dependence between responses through a Gaussian copula and uses the induced copula-likelihood loss with the backbone CNNs.</li>
<li>results: The paper shows that the proposed CeCNN model has better prediction accuracy after adding the dependency information to the backbone models, and the modeling and proposed algorithm are applicable beyond the ultra-widefield (UWF) scenario and can be effective with other backbones beyond ResNet and LeNet.<details>
<summary>Abstract</summary>
Ultra-widefield (UWF) fundus images are replacing traditional fundus images in screening, detection, prediction, and treatment of complications related to myopia because their much broader visual range is advantageous for highly myopic eyes. Spherical equivalent (SE) is extensively used as the main myopia outcome measure, and axial length (AL) has drawn increasing interest as an important ocular component for assessing myopia. Cutting-edge studies show that SE and AL are strongly correlated. Using the joint information from SE and AL is potentially better than using either separately. In the deep learning community, though there is research on multiple-response tasks with a 3D image biomarker, dependence among responses is only sporadically taken into consideration. Inspired by the spirit that information extracted from the data by statistical methods can improve the prediction accuracy of deep learning models, we formulate a class of multivariate response regression models with a higher-order tensor biomarker, for the bivariate tasks of regression-classification and regression-regression. Specifically, we propose a copula-enhanced convolutional neural network (CeCNN) framework that incorporates the dependence between responses through a Gaussian copula (with parameters estimated from a warm-up CNN) and uses the induced copula-likelihood loss with the backbone CNNs. We establish the statistical framework and algorithms for the aforementioned two bivariate tasks. We show that the CeCNN has better prediction accuracy after adding the dependency information to the backbone models. The modeling and the proposed CeCNN algorithm are applicable beyond the UWF scenario and can be effective with other backbones beyond ResNet and LeNet.
</details>
<details>
<summary>摘要</summary>
超宽场照片（UWF）正在取代传统的眼球照片，用于检测、预测和治疗高度近视相关的疾病，因为它们的视觉范围更广。球形等效（SE）广泛使用为高度近视的主要结果指标，而轴长（AL）也在引起越来越多的关注，因为它是诊断高度近视的重要组成部分。现代研究表明，SE和AL之间存在强相关性。使用两者的共同信息可能比使用单独的SE或AL更好。在深度学习社区中，虽然有关多个响应任务的3D图像生物标志的研究，但是对响应之间的依赖关系只 occasionally被考虑。我们由于信息从数据中提取出来的统计方法可以提高深度学习模型的预测精度，因此我们提出了一类多变量响应回归模型，其中包括高级 tensor生物标志。特别是，我们提出了一种含有 Gaussian copula 的 CeCNN 框架，该框架通过将 Gaussian copula 作为生成模型的一部分，将响应之间的依赖关系传递给后续 CNNs。我们建立了这些多变量响应回归任务的统计框架和算法。我们发现，在添加依赖信息后，CeCNN 的预测精度有所提高。这种模型和提出的 CeCNN 算法可以在 UWF 场景之外应用，并且可以与其他背景模型结合使用。
</details></li>
</ul>
<hr>
<h2 id="Fast-Sun-aligned-Outdoor-Scene-Relighting-based-on-TensoRF"><a href="#Fast-Sun-aligned-Outdoor-Scene-Relighting-based-on-TensoRF" class="headerlink" title="Fast Sun-aligned Outdoor Scene Relighting based on TensoRF"></a>Fast Sun-aligned Outdoor Scene Relighting based on TensoRF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03965">http://arxiv.org/abs/2311.03965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeonjin Chang, Yearim Kim, Seunghyeon Seo, Jung Yi, Nojun Kwak</li>
<li>for: 这个论文是为了提出一种用于风景场景外部重新照明的方法，以提高Neural Radiance Fields（NeRF）的效果。</li>
<li>methods: 这个方法使用了名为Sun-aligned Relighting TensoRF（SR-TensoRF），它采用了与太阳方向相对的推算策略，从而实现了简化的工作流程，并且不需要环境图。</li>
<li>results: 该方法可以在训练和渲染过程中得到显著的加速，同时也能够保持与传统方法的比较水平。<details>
<summary>Abstract</summary>
In this work, we introduce our method of outdoor scene relighting for Neural Radiance Fields (NeRF) named Sun-aligned Relighting TensoRF (SR-TensoRF). SR-TensoRF offers a lightweight and rapid pipeline aligned with the sun, thereby achieving a simplified workflow that eliminates the need for environment maps. Our sun-alignment strategy is motivated by the insight that shadows, unlike viewpoint-dependent albedo, are determined by light direction. We directly use the sun direction as an input during shadow generation, simplifying the requirements of the inference process significantly. Moreover, SR-TensoRF leverages the training efficiency of TensoRF by incorporating our proposed cubemap concept, resulting in notable acceleration in both training and rendering processes compared to existing methods.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们介绍了一种名为sun-aligned Relighting TensoRF（SR-TensoRF）的外部场景重新照明方法，用于Neural Radiance Fields（NeRF）。 SR-TensoRF提供了一个轻量级、快速的管道，与太阳方向相对应，从而实现了简化的工作流程，消除了环境地图的需求。我们的太阳Alignment策略是基于观察，阴影不同于视点依赖的反射率，阴影的方向由太阳direction决定。我们直接在阴影生成过程中使用太阳方向作为输入，从而对推理过程的需求进行了明显的简化。此外，SR-TensoRF利用了TensoRF的训练效率，通过我们提出的立方体地图概念，从而在训练和渲染过程中具有显著的加速。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Multimodal-Compositional-Reasoning-of-Visual-Language-Models-with-Generative-Negative-Mining"><a href="#Enhancing-Multimodal-Compositional-Reasoning-of-Visual-Language-Models-with-Generative-Negative-Mining" class="headerlink" title="Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining"></a>Enhancing Multimodal Compositional Reasoning of Visual Language Models with Generative Negative Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03964">http://arxiv.org/abs/2311.03964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ugorsahin/Generative-Negative-Mining">https://github.com/ugorsahin/Generative-Negative-Mining</a></li>
<li>paper_authors: Ugur Sahin, Hang Li, Qadeer Khan, Daniel Cremers, Volker Tresp</li>
<li>for: 提高图文理解任务中的多modal Compositional Reasoning能力</li>
<li>methods: 使用对向采集的图片和文本描述进行对比学习，并通过生成困难的负例来提高模型的承受能力</li>
<li>results: 使用这种方法可以在多modal Compositional Reasoning任务中显著提高图文模型的表现<details>
<summary>Abstract</summary>
Contemporary large-scale visual language models (VLMs) exhibit strong representation capacities, making them ubiquitous for enhancing image and text understanding tasks. They are often trained in a contrastive manner on a large and diverse corpus of images and corresponding text captions scraped from the internet. Despite this, VLMs often struggle with compositional reasoning tasks which require a fine-grained understanding of the complex interactions of objects and their attributes. This failure can be attributed to two main factors: 1) Contrastive approaches have traditionally focused on mining negative examples from existing datasets. However, the mined negative examples might not be difficult for the model to discriminate from the positive. An alternative to mining would be negative sample generation 2) But existing generative approaches primarily focus on generating hard negative texts associated with a given image. Mining in the other direction, i.e., generating negative image samples associated with a given text has been ignored. To overcome both these limitations, we propose a framework that not only mines in both directions but also generates challenging negative samples in both modalities, i.e., images and texts. Leveraging these generative hard negative samples, we significantly enhance VLMs' performance in tasks involving multimodal compositional reasoning. Our code and dataset are released at https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html.
</details>
<details>
<summary>摘要</summary>
现代大规模视觉语言模型（VLM）具有强大的表达能力，使其在图像和文本理解任务中广泛应用。它们通常通过对大量和多样化的图像和相关文本描述进行对比式训练。然而，VLM 经常在 композиitional 理解任务中遇到困难，这可以归结到两个主要因素：1. 对比方法traditionally 将焦点放在挖掘现有数据集中的负例中。然而，挖掘出来的负例可能并不是模型很难归类。一种alternative 是生成负例amples。2. 现有的生成方法主要是生成与给定图像相关的困难文本样本。然而，生成在另一个方向上的负例amples，即与给定文本相关的困难图像样本，还没有得到足够的关注。为了突破这两个限制，我们提议一个框架，不仅在两个方向上挖掘负例amples，而且还生成了困难的负例amples在两个模式下，即图像和文本。通过利用这些生成的困难负例amples，我们可以大幅提高 VLM 在多模式compositional reasoning任务中的表现。我们的代码和数据集可以在 <https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Effectiveness-of-Deep-Generative-Data"><a href="#Improving-the-Effectiveness-of-Deep-Generative-Data" class="headerlink" title="Improving the Effectiveness of Deep Generative Data"></a>Improving the Effectiveness of Deep Generative Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03959">http://arxiv.org/abs/2311.03959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyu Wang, Sabrina Schmedding, Marco F. Huber</li>
<li>for: 本研究旨在探讨使用深度生成模型生成的synthetic图像在下游图像处理任务中的表现。</li>
<li>methods: 本研究使用了一种新的分类法来描述在使用深度生成模型生成的synthetic图像时常见的现象，并在CIFAR-10 dataset上进行了广泛的实验。</li>
<li>results: 研究发现，使用我们提出的策略可以更好地利用深度生成模型生成的synthetic图像，并在数据稀缺的情况下表现出优于基elines。<details>
<summary>Abstract</summary>
Recent deep generative models (DGMs) such as generative adversarial networks (GANs) and diffusion probabilistic models (DPMs) have shown their impressive ability in generating high-fidelity photorealistic images. Although looking appealing to human eyes, training a model on purely synthetic images for downstream image processing tasks like image classification often results in an undesired performance drop compared to training on real data. Previous works have demonstrated that enhancing a real dataset with synthetic images from DGMs can be beneficial. However, the improvements were subjected to certain circumstances and yet were not comparable to adding the same number of real images. In this work, we propose a new taxonomy to describe factors contributing to this commonly observed phenomenon and investigate it on the popular CIFAR-10 dataset. We hypothesize that the Content Gap accounts for a large portion of the performance drop when using synthetic images from DGM and propose strategies to better utilize them in downstream tasks. Extensive experiments on multiple datasets showcase that our method outperforms baselines on downstream classification tasks both in case of training on synthetic only (Synthetic-to-Real) and training on a mix of real and synthetic data (Data Augmentation), particularly in the data-scarce scenario.
</details>
<details>
<summary>摘要</summary>
最近的深度生成模型（DGM），如生成敌方网络（GAN）和扩散概率模型（DPM），已经展示了高效的图像生成能力。although these models can generate visually appealing images, training a model on purely synthetic images for downstream image processing tasks like image classification often leads to a drop in performance compared to training on real data. previous studies have shown that enhancing a real dataset with synthetic images from DGMs can be beneficial, but the improvements were limited and not comparable to adding the same number of real images. in this work, we propose a new taxonomy to describe the factors contributing to this commonly observed phenomenon and investigate it on the popular CIFAR-10 dataset. we hypothesize that the Content Gap accounts for a large portion of the performance drop when using synthetic images from DGM and propose strategies to better utilize them in downstream tasks. extensive experiments on multiple datasets show that our method outperforms baselines in both synthetic-only and data augmentation scenarios, particularly in data-scarce situations.
</details></li>
</ul>
<hr>
<h2 id="CLIP-Guided-Image-perceptive-Prompt-Learning-for-Image-Enhancement"><a href="#CLIP-Guided-Image-perceptive-Prompt-Learning-for-Image-Enhancement" class="headerlink" title="CLIP Guided Image-perceptive Prompt Learning for Image Enhancement"></a>CLIP Guided Image-perceptive Prompt Learning for Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03943">http://arxiv.org/abs/2311.03943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zinuo Li, Qiuhong Ke, Weiwen Chen</li>
<li>for: 本研究旨在提高计算机视觉和图像处理领域中的图像增强方法，特别是使用学习基于方法。</li>
<li>methods: 本文提出了一种简单的结构 called CLIP-LUT，通过利用CLIP模型的先前知识来提高图像增强效果。我们首先学习了图像感知的提示，使CLIP模型能够有效地识别受损图像的质量，然后引入一个简单的网络来预测三种不同的LUT的加权值，并使用这些提示来导引增强网络。</li>
<li>results: 我们示出了将简单的方法与CLIP结合起来可以获得满意的结果。<details>
<summary>Abstract</summary>
Image enhancement is a significant research area in the fields of computer vision and image processing. In recent years, many learning-based methods for image enhancement have been developed, where the Look-up-table (LUT) has proven to be an effective tool. In this paper, we delve into the potential of Contrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning, proposing a simple structure called CLIP-LUT for image enhancement. We found that the prior knowledge of CLIP can effectively discern the quality of degraded images, which can provide reliable guidance. To be specific, We initially learn image-perceptive prompts to distinguish between original and target images using CLIP model, in the meanwhile, we introduce a very simple network by incorporating a simple baseline to predict the weights of three different LUT as enhancement network. The obtained prompts are used to steer the enhancement network like a loss function and improve the performance of model. We demonstrate that by simply combining a straightforward method with CLIP, we can obtain satisfactory results.
</details>
<details>
<summary>摘要</summary>
Image enhancement is a significant research area in computer vision and image processing. Recently, many learning-based methods for image enhancement have been developed, and the Look-up-table (LUT) has proven to be an effective tool. In this paper, we explore the potential of Contrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning for image enhancement. We propose a simple structure called CLIP-LUT, which uses the prior knowledge of CLIP to effectively discern the quality of degraded images and provide reliable guidance.To be specific, we first learn image-perceptive prompts to distinguish between original and target images using the CLIP model. Then, we introduce a very simple network that incorporates a simple baseline to predict the weights of three different LUTs as an enhancement network. The obtained prompts are used to steer the enhancement network like a loss function, improving the performance of the model. We demonstrate that by simply combining a straightforward method with CLIP, we can obtain satisfactory results.
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-NaN-Divergence-in-Training-Monocular-Depth-Estimation-Model"><a href="#Analysis-of-NaN-Divergence-in-Training-Monocular-Depth-Estimation-Model" class="headerlink" title="Analysis of NaN Divergence in Training Monocular Depth Estimation Model"></a>Analysis of NaN Divergence in Training Monocular Depth Estimation Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03938">http://arxiv.org/abs/2311.03938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bum Jun Kim, Hyeonah Jang, Sang Woo Kim</li>
<li>for: 帮助解释深度学习中NaN损失的原因和避免方法</li>
<li>methods: 通过对带有NaN损失的训练数据进行深入分析，并通过实验证明了NaN损失的三种原因，包括使用平方根损失、Log-sigmoid函数和certain variance实现。</li>
<li>results: 通过遵循我们的指南，可以改善优化稳定性和带有NaN损失的深度学习模型的性能。<details>
<summary>Abstract</summary>
The latest advances in deep learning have facilitated the development of highly accurate monocular depth estimation models. However, when training a monocular depth estimation network, practitioners and researchers have observed not a number (NaN) loss, which disrupts gradient descent optimization. Although several practitioners have reported the stochastic and mysterious occurrence of NaN loss that bothers training, its root cause is not discussed in the literature. This study conducted an in-depth analysis of NaN loss during training a monocular depth estimation network and identified three types of vulnerabilities that cause NaN loss: 1) the use of square root loss, which leads to an unstable gradient; 2) the log-sigmoid function, which exhibits numerical stability issues; and 3) certain variance implementations, which yield incorrect computations. Furthermore, for each vulnerability, the occurrence of NaN loss was demonstrated and practical guidelines to prevent NaN loss were presented. Experiments showed that both optimization stability and performance on monocular depth estimation could be improved by following our guidelines.
</details>
<details>
<summary>摘要</summary>
最新的深度学习技术发展，使得单目深度估计模型可以很准确。然而，在训练单目深度估计网络时，实践者和研究人员经常会遇到NaN损失，这会阻碍梯度下降优化。虽然许多实践者报道了随机和神秘的NaN损失现象，但在文献中没有讨论其根本原因。本研究对单目深度估计网络训练中NaN损失进行了深入分析，并确定了三种可能导致NaN损失的漏洞：1）使用平方根损失，导致梯度不稳定；2）使用对数 sigmoid 函数，存在数学稳定问题；3）某些变量实现方式可能会导致错误计算。此外，对每种漏洞，我们都示出了NaN损失的发生和避免NaN损失的实践指南。实验表明，遵循我们的指南可以提高优化稳定性和单目深度估计性能。
</details></li>
</ul>
<hr>
<h2 id="FLORA-Fine-grained-Low-Rank-Architecture-Search-for-Vision-Transformer"><a href="#FLORA-Fine-grained-Low-Rank-Architecture-Search-for-Vision-Transformer" class="headerlink" title="FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer"></a>FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03912">http://arxiv.org/abs/2311.03912</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shadowpa0327/flora">https://github.com/shadowpa0327/flora</a></li>
<li>paper_authors: Chi-Chih Chang, Yuan-Yao Sung, Shixing Yu, Ning-Chi Huang, Diana Marculescu, Kai-Chiang Wu</li>
<li>for: 这篇论文的目的是提出一个名为FLORA的自动化框架，用于实时部署中的Computer Vision Tasks中的ViT模型，以提高其计算效率。</li>
<li>methods: 这篇论文使用了Low-rank aware candidate filtering strategy和low-rank specific training paradigm，以提高低维度超网的质量。</li>
<li>results: 实验结果显示，FLORA可以自动生成更细化的维度配置，实现约33%的FLOPs节省，并且可以与主流压缩技术或对应的短袋结构结合使用，提供额外21%-26%的FLOPs节省。<details>
<summary>Abstract</summary>
Vision Transformers (ViT) have recently demonstrated success across a myriad of computer vision tasks. However, their elevated computational demands pose significant challenges for real-world deployment. While low-rank approximation stands out as a renowned method to reduce computational loads, efficiently automating the target rank selection in ViT remains a challenge. Drawing from the notable similarity and alignment between the processes of rank selection and One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based on NAS. To overcome the design challenge of supernet posed by vast search space, FLORA employs a low-rank aware candidate filtering strategy. This method adeptly identifies and eliminates underperforming candidates, effectively alleviating potential undertraining and interference among subnetworks. To further enhance the quality of low-rank supernets, we design a low-rank specific training paradigm. First, we propose weight inheritance to construct supernet and enable gradient sharing among low-rank modules. Secondly, we adopt low-rank aware sampling to strategically allocate training resources, taking into account inherited information from pre-trained models. Empirical results underscore FLORA's efficacy. With our method, a more fine-grained rank configuration can be generated automatically and yield up to 33% extra FLOPs reduction compared to a simple uniform configuration. More specific, FLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without performance degradtion. Importantly, FLORA boasts both versatility and orthogonality, offering an extra 21%-26% FLOPs reduction when integrated with leading compression techniques or compact hybrid structures. Our code is publicly available at https://github.com/shadowpa0327/FLORA.
</details>
<details>
<summary>摘要</summary>
幻 transformer (ViT) 在计算机视觉任务中表现出色，但它们的计算负担却很高，妨碍实际应用。而且，选择目标排名是一项有名望的方法来减少计算负担，但是在 ViT 中自动化目标排名选择仍然是一个挑战。通过 noticed 的 similarity and alignment between rank selection and One-Shot NAS，我们提出了 FLORA，一个基于 NAS 的端到端自动框架。尝试超网的设计挑战，FLORA 使用了低级别扩展的候选人筛选策略，可以快速地标识和消除低性能的候选人，从而避免潜在的过度训练和互相干扰。此外，我们还设计了一种低级别特有的训练方法，包括继承重量和低级别扩展的采样策略。这些方法可以提高低级别超网的质量，从而实现更好的性能和计算效率。实验结果表明，FLORA 可以自动生成更细化的排名配置，并提供更多的计算效率。具体来说，FLORA-DeiT-B/FLORA-Swin-B 可以节省至 55%/42% FLOPs，几乎不受性能下降的影响。此外，FLORA 还具有灵活和正交的特点，可以与主流压缩技术或嵌入式混合结构结合使用，提供更多的计算效率提升。我们的代码可以在 <https://github.com/shadowpa0327/FLORA> 上下载。
</details></li>
</ul>
<hr>
<h2 id="RobustMat-Neural-Diffusion-for-Street-Landmark-Patch-Matching-under-Challenging-Environments"><a href="#RobustMat-Neural-Diffusion-for-Street-Landmark-Patch-Matching-under-Challenging-Environments" class="headerlink" title="RobustMat: Neural Diffusion for Street Landmark Patch Matching under Challenging Environments"></a>RobustMat: Neural Diffusion for Street Landmark Patch Matching under Challenging Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03904">http://arxiv.org/abs/2311.03904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-it-avs/robustmat">https://github.com/ai-it-avs/robustmat</a></li>
<li>paper_authors: Rui She, Qiyu Kang, Sijie Wang, Yuan-Rui Yang, Kai Zhao, Yang Song, Wee Peng Tay</li>
<li>for: 这 paper 的目的是提出一种robust的 Visual Perception技术，用于自动驾驶车辆（AVs）的信息获取和处理。</li>
<li>methods: 这 paper 使用了一种名为 RobustMat 的方法，该方法利用摄像头上的图像数据，并通过 neural differential equations 学习 feature representation，以及 graph neural PDE diffusion module 来协同处理多个 landmark patches。</li>
<li>results: 这 paper 的实验结果表明，RobustMat 方法在不同的季节、天气和照明条件下，可以提供 state-of-the-art 的匹配结果。<details>
<summary>Abstract</summary>
For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations.Note: The translation is done in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="MeVGAN-GAN-based-Plugin-Model-for-Video-Generation-with-Applications-in-Colonoscopy"><a href="#MeVGAN-GAN-based-Plugin-Model-for-Video-Generation-with-Applications-in-Colonoscopy" class="headerlink" title="MeVGAN: GAN-based Plugin Model for Video Generation with Applications in Colonoscopy"></a>MeVGAN: GAN-based Plugin Model for Video Generation with Applications in Colonoscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03884">http://arxiv.org/abs/2311.03884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Łukasz Struski, Tomasz Urbańczyk, Krzysztof Bucki, Bartłomiej Cupiał, Aneta Kaczyńska, Przemysław Spurek, Jacek Tabor</li>
<li>for: 这个论文是为了提出一种能够生成高分辨率视频的生成模型，以解决现有的视频生成模型具有大量内存需求的问题。</li>
<li>methods: 该论文提出了一种插件式架构的生成 adversarial Network（GAN），称为 Memory Efficient Video GAN（MeVGAN），使用了预训练的2D图像GAN，并只添加了一个简单的神经网络来构造噪声空间中的轨迹，以便将轨迹通过GAN模型构造出真实的视频。</li>
<li>results: 该论文应用了MeVGAN在colonoscopy视频生成任务中，并证明了MeVGAN可以生成高质量的 sintetic colonoscopy视频，可以用于虚拟 simulate器中。 colonoscopy是一种重要的医学手术，尤其是在检测和管理肠癌方面有益。但是，因为colonoscopy是一种困难和时间consuming的学习过程，因此colonoscopy simulator在教育年轻的colonoscopists中广泛使用。<details>
<summary>Abstract</summary>
Video generation is important, especially in medicine, as much data is given in this form. However, video generation of high-resolution data is a very demanding task for generative models, due to the large need for memory. In this paper, we propose Memory Efficient Video GAN (MeVGAN) - a Generative Adversarial Network (GAN) which uses plugin-type architecture. We use a pre-trained 2D-image GAN and only add a simple neural network to construct respective trajectories in the noise space, so that the trajectory forwarded through the GAN model constructs a real-life video. We apply MeVGAN in the task of generating colonoscopy videos. Colonoscopy is an important medical procedure, especially beneficial in screening and managing colorectal cancer. However, because colonoscopy is difficult and time-consuming to learn, colonoscopy simulators are widely used in educating young colonoscopists. We show that MeVGAN can produce good quality synthetic colonoscopy videos, which can be potentially used in virtual simulators.
</details>
<details>
<summary>摘要</summary>
视频生成对医学领域来说非常重要，因为大量数据都是以视频形式提供。然而，高分辨率视频生成对生成模型来说是一项非常具有挑战性的任务，因为需要大量的内存。在这篇论文中，我们提出了 Memory Efficient Video GAN（MeVGAN），这是一种基于生成对抗网络（GAN）的插件型架构。我们使用预训练的2D图像GAN，只是添加了一个简单的神经网络，以在噪声空间中构造各自的轨迹，从而使得轨迹在GAN模型中传递的整个视频是真实的。我们在执行colonoscopy视频生成任务中应用了MeVGAN。colonoscopy是一种医学检查，尤其是在检测和管理肠癌方面非常有优势。然而，因为colonoscopy是一项困难和时间consuming的学习，因此colonoscopy模拟器在培训年轻的colonoscopist中广泛使用。我们显示MeVGAN可以生成高质量的synthetic colonoscopy视频，这些视频可能可以在虚拟模拟器中使用。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Knowledge-Transfer-Methods-for-Misaligned-Urban-Building-Labels"><a href="#A-Comparative-Study-of-Knowledge-Transfer-Methods-for-Misaligned-Urban-Building-Labels" class="headerlink" title="A Comparative Study of Knowledge Transfer Methods for Misaligned Urban Building Labels"></a>A Comparative Study of Knowledge Transfer Methods for Misaligned Urban Building Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03867">http://arxiv.org/abs/2311.03867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bipul Neupane, Jagannath Aryal, Abbas Rajabifard</li>
<li>for:  Addressing the misalignment issue in Earth observation (EO) images and building labels to train accurate convolutional neural networks (CNNs) for semantic segmentation of building footprints.</li>
<li>methods:  Comparative study of three Teacher-Student knowledge transfer methods: supervised domain adaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML).</li>
<li>results:  SDA is the most effective method to address the misalignment problem, while KD and DML can efficiently compress network size without significant loss in performance. The 158 experiments and datasets developed in this study will be valuable to minimize the misaligned labels.Here’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;<details>
<summary>Abstract</summary>
Misalignment in Earth observation (EO) images and building labels impact the training of accurate convolutional neural networks (CNNs) for semantic segmentation of building footprints. Recently, three Teacher-Student knowledge transfer methods have been introduced to address this issue: supervised domain adaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML). However, these methods are merely studied for different urban buildings (low-rise, mid-rise, high-rise, and skyscrapers), where misalignment increases with building height and spatial resolution. In this study, we present a workflow for the systematic comparative study of the three methods. The workflow first identifies the best (with the highest evaluation scores) hyperparameters, lightweight CNNs for the Student (among 43 CNNs from Computer Vision), and encoder-decoder networks (EDNs) for both Teachers and Students. Secondly, three building footprint datasets are developed to train and evaluate the identified Teachers and Students in the three transfer methods. The results show that U-Net with VGG19 (U-VGG19) is the best Teacher, and U-EfficientNetv2B3 and U-EfficientNet-lite0 are among the best Students. With these Teacher-Student pairs, SDA could yield upto 0.943, 0.868, 0.912, and 0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers respectively. KD and DML provide model compression of upto 82%, despite marginal loss in performance. This new comparison concludes that SDA is the most effective method to address the misalignment problem, while KD and DML can efficiently compress network size without significant loss in performance. The 158 experiments and datasets developed in this study will be valuable to minimise the misaligned labels.
</details>
<details>
<summary>摘要</summary>
地球观测（EO）图像和建筑标注的不一致问题会影响建筑 semantic 分类器的训练，特别是高层建筑。近些年，三种教师学生知识传播方法被提出来解决这个问题：指导适应领域（SDA）、知识储存（KD）和深度相互学习（DML）。然而，这些方法只被研究在不同的城市建筑（低层、中层、高层和天际线），而这些建筑的不一致程度随着建筑高度和空间分辨率增加。在这项研究中，我们提供了一个系统性比较工作流程，以评估这三种方法的效果。我们的工作流程包括：1. 选择最佳（最高评价分）的超参数、轻量级 CNN（从计算机视觉领域中选择43种 CNN）和编码器解码器网络（EDN）。2. 为教师和学生制作三种建筑块标注数据集。结果显示，U-Net with VGG19（U-VGG19）是最佳教师，而U-EfficientNetv2B3和U-EfficientNet-lite0是最佳学生之一。使用这些教师和学生对照，SDA可以达到0.943、0.868、0.912和0.697的F1分数在不同的高度建筑中。KD和DML可以压缩网络大小达82%，尽管性能下降不大。这一新的比较结论表明，SDA是解决不一致标注问题的最有效方法，而KD和DML可以高效压缩网络大小，无需重大影响性能。在这项研究中，我们开发了158个实验和数据集，这些数据集将有助于减少不一致标注。
</details></li>
</ul>
<hr>
<h2 id="SCONE-GAN-Semantic-Contrastive-learning-based-Generative-Adversarial-Network-for-an-end-to-end-image-translation"><a href="#SCONE-GAN-Semantic-Contrastive-learning-based-Generative-Adversarial-Network-for-an-end-to-end-image-translation" class="headerlink" title="SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial Network for an end-to-end image translation"></a>SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial Network for an end-to-end image translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03866">http://arxiv.org/abs/2311.03866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iman Abbasnejad, Fabio Zambetta, Flora Salim, Timothy Wiley, Jeffrey Chan, Russell Gallagher, Ehsan Abbasnejad</li>
<li>for: 学习生成真实和多样化的景象图像</li>
<li>methods: 使用图 convolutional neural networks 学习对象依赖关系，保持图像结构和 semantics，并使用样式参照图进行风格化</li>
<li>results: 在四个 dataset 上进行图像到图像翻译和风格化，并取得了较高的质量和多样性的图像生成 результаpts<details>
<summary>Abstract</summary>
SCONE-GAN presents an end-to-end image translation, which is shown to be effective for learning to generate realistic and diverse scenery images. Most current image-to-image translation approaches are devised as two mappings: a translation from the source to target domain and another to represent its inverse. While successful in many applications, these approaches may suffer from generating trivial solutions with limited diversity. That is because these methods learn more frequent associations rather than the scene structures. To mitigate the problem, we propose SCONE-GAN that utilises graph convolutional networks to learn the objects dependencies, maintain the image structure and preserve its semantics while transferring images into the target domain. For more realistic and diverse image generation we introduce style reference image. We enforce the model to maximize the mutual information between the style image and output. The proposed method explicitly maximizes the mutual information between the related patches, thus encouraging the generator to produce more diverse images. We validate the proposed algorithm for image-to-image translation and stylizing outdoor images. Both qualitative and quantitative results demonstrate the effectiveness of our approach on four dataset.
</details>
<details>
<summary>摘要</summary>
SCONE-GAN 提出了一种端到端图像翻译方法，可以帮助学习生成真实和多样化的景象图像。现有的图像到图像翻译方法通常是两个映射：一个从源领域到目标领域，另一个用于表示其 inverse。虽然在许多应用中成功，但这些方法可能会导致生成轻松的解决方案，具有有限的多样性。这是因为这些方法学习的更频繁是景象的关系，而不是场景的结构。为了解决这个问题，我们提议使用图 convolutional networks 来学习对象的依赖关系，保持图像的结构，并保持图像的 semantics  while 将图像转换到目标领域。为了更加真实和多样的图像生成，我们引入了风格引用图像。我们强制模型将 Style 图像和输出之间的共同信息最大化。我们的方法将相关的 patch 之间的共同信息最大化，因此激励生成器生成更多样的图像。我们验证了我们的方法在图像到图像翻译和风格化户外图像方面的效果。四个数据集的质量和量化结果都表明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Multi-view-Information-Integration-and-Propagation-for-Occluded-Person-Re-identification"><a href="#Multi-view-Information-Integration-and-Propagation-for-Occluded-Person-Re-identification" class="headerlink" title="Multi-view Information Integration and Propagation for Occluded Person Re-identification"></a>Multi-view Information Integration and Propagation for Occluded Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03828">http://arxiv.org/abs/2311.03828</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nengdong96/mviip">https://github.com/nengdong96/mviip</a></li>
<li>paper_authors: Neng Dong, Shuanglin Yan, Hao Tang, Jinhui Tang, Liyan Zhang</li>
<li>for: 提高 occluded person re-identification task 的精度，使用多视图图像来强化人脸特征表示。</li>
<li>methods: 提出 Multi-view Information Integration and Propagation (MVI$^{2}$P) 框架，integrate 多视图图像的特征图，通过 CAMs-aware Localization 模块和 probability-aware Quantification 模块来选择高可靠性信息，并使用 Information Propagation 机制储存知识。</li>
<li>results: 经验和分析表明，MVI$^{2}$P 能够提高 occluded person re-identification  task 的精度，并且在不同的 occlusion 情况下保持稳定性。<details>
<summary>Abstract</summary>
Occluded person re-identification (re-ID) presents a challenging task due to occlusion perturbations. Although great efforts have been made to prevent the model from being disturbed by occlusion noise, most current solutions only capture information from a single image, disregarding the rich complementary information available in multiple images depicting the same pedestrian. In this paper, we propose a novel framework called Multi-view Information Integration and Propagation (MVI$^{2}$P). Specifically, realizing the potential of multi-view images in effectively characterizing the occluded target pedestrian, we integrate feature maps of which to create a comprehensive representation. During this process, to avoid introducing occlusion noise, we develop a CAMs-aware Localization module that selectively integrates information contributing to the identification. Additionally, considering the divergence in the discriminative nature of different images, we design a probability-aware Quantification module to emphatically integrate highly reliable information. Moreover, as multiple images with the same identity are not accessible in the testing stage, we devise an Information Propagation (IP) mechanism to distill knowledge from the comprehensive representation to that of a single occluded image. Extensive experiments and analyses have unequivocally demonstrated the effectiveness and superiority of the proposed MVI$^{2}$P. The code will be released at \url{https://github.com/nengdong96/MVIIP}.
</details>
<details>
<summary>摘要</summary>
受遮挡干扰的人识别（re-ID）问题具有挑战性，因为遮挡干扰会对模型产生负面影响。虽然大量努力已经尝试避免遮挡干扰对模型的影响，但大多数当前解决方案仅利用单个图像信息，忽略了同一人物被多张图像捕捉的丰富补充信息。在这篇论文中，我们提出了一种新的框架，即多视图信息集成和传播（MVI$^{2}$P）。具体来说，利用多视图图像的优势，我们集成了特征地图，以创建全面的表示。在这个过程中，我们开发了一个aware的Localization模块，以选择atively интеgrate有助于识别的信息。此外，考虑到不同图像之间的分布特征的不同，我们设计了一个概率感知的量化模块，以强调高可靠性信息的集成。此外，在测试阶段无法获得多张图像同一个人物的情况下，我们提出了信息传播（IP）机制，以储存知识从全面表示中传递到受遮挡图像上。我们的实验和分析结果明显表明了我们提出的MVI$^{2}$P的有效性和优越性。代码将在 \url{https://github.com/nengdong96/MVIIP} 上发布。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Any-Human-Object-Interaction-Relationship-Universal-HOI-Detector-with-Spatial-Prompt-Learning-on-Foundation-Models"><a href="#Detecting-Any-Human-Object-Interaction-Relationship-Universal-HOI-Detector-with-Spatial-Prompt-Learning-on-Foundation-Models" class="headerlink" title="Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models"></a>Detecting Any Human-Object Interaction Relationship: Universal HOI Detector with Spatial Prompt Learning on Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03799">http://arxiv.org/abs/2311.03799</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Caoyichao/UniHOI">https://github.com/Caoyichao/UniHOI</a></li>
<li>paper_authors: Yichao Cao, Qingfei Tang, Xiu Su, Chen Song, Shan You, Xiaobo Lu, Chang Xu</li>
<li>for: 本研究旨在开拓HOI检测领域中的开放世界Setting下的UniversalInteractionRecognition，通过使用视觉语言基础模型和大型自然语言模型（LLM）。</li>
<li>methods: 本方法包括HO Prompt-based Learning，即在视觉基础模型中协调高级关系表示，以及使用GPT进行交互解释，实现更加复杂的HOIs的语言理解。</li>
<li>results: 相比 existed方法，UniHOI在预导和零shot Setting下均能够取得显著的性能提升，并且支持多种输入类型，包括交互短语和解释句。<details>
<summary>Abstract</summary>
Human-object interaction (HOI) detection aims to comprehend the intricate relationships between humans and objects, predicting $<human, action, object>$ triplets, and serving as the foundation for numerous computer vision tasks. The complexity and diversity of human-object interactions in the real world, however, pose significant challenges for both annotation and recognition, particularly in recognizing interactions within an open world context. This study explores the universal interaction recognition in an open-world setting through the use of Vision-Language (VL) foundation models and large language models (LLMs). The proposed method is dubbed as \emph{\textbf{UniHOI}. We conduct a deep analysis of the three hierarchical features inherent in visual HOI detectors and propose a method for high-level relation extraction aimed at VL foundation models, which we call HO prompt-based learning. Our design includes an HO Prompt-guided Decoder (HOPD), facilitates the association of high-level relation representations in the foundation model with various HO pairs within the image. Furthermore, we utilize a LLM (\emph{i.e.} GPT) for interaction interpretation, generating a richer linguistic understanding for complex HOIs. For open-category interaction recognition, our method supports either of two input types: interaction phrase or interpretive sentence. Our efficient architecture design and learning methods effectively unleash the potential of the VL foundation models and LLMs, allowing UniHOI to surpass all existing methods with a substantial margin, under both supervised and zero-shot settings. The code and pre-trained weights are available at: \url{https://github.com/Caoyichao/UniHOI}.
</details>
<details>
<summary>摘要</summary>
人物交互检测（HOI）目标是理解人与物之间复杂的关系，预测<人,动作,物> triplets，并成为许多计算机视觉任务的基础。然而，现实世界中人物交互的复杂和多样性使得注释和识别具有挑战性，特别是在开放世界上下文中。这种研究通过使用视力语言基础模型（VL）和大型自然语言模型（LLM）来实现对开放世界中人物交互的识别。我们提出了一种名为UniHOI的方法，包括一个HO Prompt-based Decoder（HOPD），用于将高级关系表示assoicated with不同的HO对在图像中。此外，我们使用GPT（一种大型自然语言模型）来解释交互，生成更加详细的语言理解，以便处理复杂的HOI。我们的方法支持两种输入类型：交互短语和解释句子。我们的有效架构设计和学习方法可以有效发挥VL基础模型和LLM的潜力，使UniHOI在both supervised和零shot设置下，与所有现有方法相比，具有substantial margin。代码和预训练 веса可以在以下链接获取：<https://github.com/Caoyichao/UniHOI>。
</details></li>
</ul>
<hr>
<h2 id="Self-MI-Efficient-Multimodal-Fusion-via-Self-Supervised-Multi-Task-Learning-with-Auxiliary-Mutual-Information-Maximization"><a href="#Self-MI-Efficient-Multimodal-Fusion-via-Self-Supervised-Multi-Task-Learning-with-Auxiliary-Mutual-Information-Maximization" class="headerlink" title="Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task Learning with Auxiliary Mutual Information Maximization"></a>Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task Learning with Auxiliary Mutual Information Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03785">http://arxiv.org/abs/2311.03785</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cam-Van Thi Nguyen, Ngoc-Hoa Thi Nguyen, Duc-Trong Le, Quang-Thuy Ha<br>for:自然语言处理和计算机视觉领域中的多Modal表示学习问题，具有 capture informative和distinct特征的多Modal模式很大的挑战。methods:我们提出了一种基于自适应学习的Self-MI方法，通过利用Contrastive Predictive Coding（CPC）作为辅助技术，以 Maximize Mutual Information（MI） между单模态输入对和多模态融合结果与单模态输入。results:我们设计了一个标签生成模块，$ULG_{MI}$，可以在自适应的方式下创建每个模式的有用和信息强的标签。通过最大化MI，我们鼓励更好地对多模态融合和单 modalities进行对齐，从而提高多模态融合。我们在CMU-MOSI、CMU-MOSEI和SIMS三个benchmark dataset上进行了广泛的实验，并证明了Self-MI在多模态融合任务中的效果。<details>
<summary>Abstract</summary>
Multimodal representation learning poses significant challenges in capturing informative and distinct features from multiple modalities. Existing methods often struggle to exploit the unique characteristics of each modality due to unified multimodal annotations. In this study, we propose Self-MI in the self-supervised learning fashion, which also leverage Contrastive Predictive Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI) between unimodal input pairs and the multimodal fusion result with unimodal inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short, that enables us to create meaningful and informative labels for each modality in a self-supervised manner. By maximizing the Mutual Information, we encourage better alignment between the multimodal fusion and the individual modalities, facilitating improved multimodal fusion. Extensive experiments on three benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the effectiveness of Self-MI in enhancing the multimodal fusion task.
</details>
<details>
<summary>摘要</summary>
多Modal表示学习具有很大的挑战，因为capturing informative和distinct特征从多个Modalities中很难。现有的方法通常因为各个Modalities的共同标注而难以利用每个Modalities的独特特征。在本研究中，我们提出了基于自我supervised learning的Self-MI方法，同时还利用了Contrastive Predictive Coding（CPC）作为辅助技术，以 Maximize Mutual Information（MI） между单modal输入对和多modal融合结果与单modal输入。此外，我们还设计了一个Label生成模块，简称为$ULG_{MI}$，它允许我们在自我supervised的情况下创建有意义和有用的标签 для每个Modalities。通过Maximize Mutual Information，我们鼓励了多modal融合和单modal输入之间更好的启合，从而提高多modal融合。在CMU-MOSI、CMU-MOSEI和SIMS三个 benchmark datasets上进行了广泛的实验， demonstarted Self-MI的效果iveness在提高多modal融合任务中。
</details></li>
</ul>
<hr>
<h2 id="UP-NeRF-Unconstrained-Pose-Prior-Free-Neural-Radiance-Fields"><a href="#UP-NeRF-Unconstrained-Pose-Prior-Free-Neural-Radiance-Fields" class="headerlink" title="UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields"></a>UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03784">http://arxiv.org/abs/2311.03784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Injae Kim, Minhyuk Choi, Hyunwoo J. Kim</li>
<li>for: 这篇论文旨在提出一种不需要摄像头位置估计的神经辐射场（NeRF）优化方法，以便在不受限制的图像集上实现高精度视图合成。</li>
<li>methods: 作者提出了一种叫做UP-NeRF（无constraint Pose-prior-free Neural Radiance Fields）的方法，通过用surrogate任务优化颜色不敏感特征场和分离出脏 occluder来解决不受限制图像集中的挑战。此外，作者还引入了一个候选头来提高pose估计的稳定性，以及一种适应性深度监督来减少误的估计影响。</li>
<li>results: 作者通过对著名的图像旅游 dataset（Phototourism）进行实验，证明了他们的方法在不受限制图像集上的性能比baseline（包括BARF和其他变种）更高。<details>
<summary>Abstract</summary>
Neural Radiance Field (NeRF) has enabled novel view synthesis with high fidelity given images and camera poses. Subsequent works even succeeded in eliminating the necessity of pose priors by jointly optimizing NeRF and camera pose. However, these works are limited to relatively simple settings such as photometrically consistent and occluder-free image collections or a sequence of images from a video. So they have difficulty handling unconstrained images with varying illumination and transient occluders. In this paper, we propose \textbf{UP-NeRF} (\textbf{U}nconstrained \textbf{P}ose-prior-free \textbf{Ne}ural \textbf{R}adiance \textbf{F}ields) to optimize NeRF with unconstrained image collections without camera pose prior. We tackle these challenges with surrogate tasks that optimize color-insensitive feature fields and a separate module for transient occluders to block their influence on pose estimation. In addition, we introduce a candidate head to enable more robust pose estimation and transient-aware depth supervision to minimize the effect of incorrect prior. Our experiments verify the superior performance of our method compared to the baselines including BARF and its variants in a challenging internet photo collection, \textit{Phototourism} dataset. The code of UP-NeRF is available at \url{https://github.com/mlvlab/UP-NeRF}.
</details>
<details>
<summary>摘要</summary>
neural radiance field (NeRF) 已经实现了基于图像和摄像头位置的高精度新视角合成。然而，这些工作受到了几个限制，例如：图像集的光度相对一致和没有遮蔽物。这些限制使得它们在真实世界中的应用相对较少。在这篇论文中，我们提出了\textbf{UP-NeRF} (\textbf{U}nconstrained \textbf{P}ose-prior-free \textbf{Ne}ural \textbf{R}adiance \textbf{F}ields)，它可以在无条件图像集中优化NeRF，不需要摄像头位置假设。我们在这篇论文中描述了一些挑战和解决方案，包括：* 使用代理任务来优化不受颜色影响的特征场，以及* 将短暂遮蔽物封锁在摄像头位置估计中，以避免这些遮蔽物对摄像头位置的影响。此外，我们还引入了候选头，以实现更加稳定的摄像头位置估计，并且将这些候选头与过去的摄像头位置估计进行比较，以确保更好的摄像头位置估计。我们的实验显示，UP-NeRF在具有挑战性的互联网照片集（Phototourism dataset）中表现出色，较以BARF和其他基于摄像头位置的方法为佳。UP-NeRF的代码可以在\url{https://github.com/mlvlab/UP-NeRF}获取。
</details></li>
</ul>
<hr>
<h2 id="CapST-An-Enhanced-and-Lightweight-Method-for-Deepfake-Video-Classification"><a href="#CapST-An-Enhanced-and-Lightweight-Method-for-Deepfake-Video-Classification" class="headerlink" title="CapST: An Enhanced and Lightweight Method for Deepfake Video Classification"></a>CapST: An Enhanced and Lightweight Method for Deepfake Video Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03782">http://arxiv.org/abs/2311.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wasim Ahmad, Yan-Tsung Peng, Yuan-Hao Chang, Gaddisa Olani Ganfure, Sarwar Khan, Sahibzada Adil Shahzad</li>
<li>for: 本研究旨在提出一种用于分类深度假视频的新型模型，以满足由多种AI技术生成的深度假视频的检测和识别需求。</li>
<li>methods: 本研究使用了一部分VGG19bn作为特征EXTRACTOR，并采用了一种卷积网络+空间时间注意力机制来增强模型的分类能力。此外，研究还利用了一种现有的视频级别融合技术，通过 temporal attention mechanism来处理 concatenated feature vectors，以便更好地利用视频中的 temporal dependencies。</li>
<li>results: 实验结果表明，本研究提出的方法可以准确地分类深度假视频，并且比基eline模型提高了4%。此外，本方法还具有更好的计算资源利用率，即使在较低的计算资源下也可以达到更高的准确率。<details>
<summary>Abstract</summary>
The proliferation of deepfake videos, synthetic media produced through advanced Artificial Intelligence techniques has raised significant concerns across various sectors, encompassing realms such as politics, entertainment, and security. In response, this research introduces an innovative and streamlined model designed to classify deepfake videos generated by five distinct encoders adeptly. Our approach not only achieves state of the art performance but also optimizes computational resources. At its core, our solution employs part of a VGG19bn as a backbone to efficiently extract features, a strategy proven effective in image-related tasks. We integrate a Capsule Network coupled with a Spatial Temporal attention mechanism to bolster the model's classification capabilities while conserving resources. This combination captures intricate hierarchies among features, facilitating robust identification of deepfake attributes. Delving into the intricacies of our innovation, we introduce an existing video level fusion technique that artfully capitalizes on temporal attention mechanisms. This mechanism serves to handle concatenated feature vectors, capitalizing on the intrinsic temporal dependencies embedded within deepfake videos. By aggregating insights across frames, our model gains a holistic comprehension of video content, resulting in more precise predictions. Experimental results on an extensive benchmark dataset of deepfake videos called DFDM showcase the efficacy of our proposed method. Notably, our approach achieves up to a 4 percent improvement in accurately categorizing deepfake videos compared to baseline models, all while demanding fewer computational resources.
</details>
<details>
<summary>摘要</summary>
“深圳技术的普及，导致深圳视频的生成和数据的处理，问题领域涵盖政治、娱乐和安全等领域。作为回应，这个研究提出了一个创新的和简化的模型，可以高效地分类深圳视频。我们的方法不仅实现了现有的性能水准，而且还可以优化计算资源。我们的解决方案是使用VGG19bn的一部分作为特征提取的基础，并与类时对应机制结合，以增强模型的分类能力。这组合使得模型能够强健地识别深圳视频的伪造特征。对于我们的创新之部分，我们引入了一个现有的视频级别融合技术，借由类时对应机制来处理 concatenated 特征向量。这种机制可以处理深圳视频中的时间相依关系，从而提供更加精确的预测。实验结果显示，我们的提案方法可以与基准模型相比，在深圳视频的分类任务中实现4%的提升，同时需要 fewer 计算资源。”
</details></li>
</ul>
<hr>
<h2 id="Meta-Adapter-An-Online-Few-shot-Learner-for-Vision-Language-Model"><a href="#Meta-Adapter-An-Online-Few-shot-Learner-for-Vision-Language-Model" class="headerlink" title="Meta-Adapter: An Online Few-shot Learner for Vision-Language Model"></a>Meta-Adapter: An Online Few-shot Learner for Vision-Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03774">http://arxiv.org/abs/2311.03774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Cheng, Lin Song, Ruoyi Xue, Hang Wang, Hongbin Sun, Yixiao Ge, Ying Shan</li>
<li>for: 这个研究旨在提高CLIP的几 shot学习能力，并且可以在线上进行调整，降低数据准确性的问题。</li>
<li>methods: 我们提出了一个名为Meta-Adapter的轻量级复合器，可以在线上使用几 shot样本来修正CLIP的特征。</li>
<li>results: 我们的方法可以在几 shot样本上取得高效的几 shot学习能力，并且可以在未见到的数据或任务上获得相对高的性能，而且具有较高的效率和简洁性。<details>
<summary>Abstract</summary>
The contrastive vision-language pre-training, known as CLIP, demonstrates remarkable potential in perceiving open-world visual concepts, enabling effective zero-shot image recognition. Nevertheless, few-shot learning methods based on CLIP typically require offline fine-tuning of the parameters on few-shot samples, resulting in longer inference time and the risk of over-fitting in certain domains. To tackle these challenges, we propose the Meta-Adapter, a lightweight residual-style adapter, to refine the CLIP features guided by the few-shot samples in an online manner. With a few training samples, our method can enable effective few-shot learning capabilities and generalize to unseen data or tasks without additional fine-tuning, achieving competitive performance and high efficiency. Without bells and whistles, our approach outperforms the state-of-the-art online few-shot learning method by an average of 3.6\% on eight image classification datasets with higher inference speed. Furthermore, our model is simple and flexible, serving as a plug-and-play module directly applicable to downstream tasks. Without further fine-tuning, Meta-Adapter obtains notable performance improvements in open-vocabulary object detection and segmentation tasks.
</details>
<details>
<summary>摘要</summary>
CLIP的对比式视觉语言预训练显示了开放世界视觉概念的惊人潜力，可以实现零shot图像识别。然而，基于CLIP的几shot学习方法通常需要离线参数的 fine-tuning，导致 longer inference time和风险过拟合在某些领域。为了解决这些挑战，我们提出了Meta-Adapter，一种轻量级的 residual-style adapter，可以在在线 manner中修改CLIP的特征，以便根据几shot样本进行修复。只需几个训练样本，我们的方法可以实现有效的几shot学习能力，并能够适应未经过训练的数据或任务，无需额外 fine-tuning，达到竞争性的性能和高效率。在八个图像分类 dataset 上，我们的方法平均提高了3.6%的性能，并且具有更高的执行速度。此外，我们的模型简单可靠，可以直接应用于下游任务，无需进一步 fine-tuning。在开放词汇Object检测和 segmentation 任务中，Meta-Adapter 也获得了显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Lightweight-Portrait-Matting-via-Regional-Attention-and-Refinement"><a href="#Lightweight-Portrait-Matting-via-Regional-Attention-and-Refinement" class="headerlink" title="Lightweight Portrait Matting via Regional Attention and Refinement"></a>Lightweight Portrait Matting via Regional Attention and Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03770">http://arxiv.org/abs/2311.03770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yatao Zhong, Ilya Zharkov</li>
<li>for: 高解析肖像分割</li>
<li>methods: 使用两stage框架，首先使用低解析网络进行较course的α估计，然后使用改进网络进行局部区域的修正。</li>
<li>results: 比基eline模型高$1&#x2F;20$的FLOPS，在三个测试数据集上达到了更高的分割质量。<details>
<summary>Abstract</summary>
We present a lightweight model for high resolution portrait matting. The model does not use any auxiliary inputs such as trimaps or background captures and achieves real time performance for HD videos and near real time for 4K. Our model is built upon a two-stage framework with a low resolution network for coarse alpha estimation followed by a refinement network for local region improvement. However, a naive implementation of the two-stage model suffers from poor matting quality if not utilizing any auxiliary inputs. We address the performance gap by leveraging the vision transformer (ViT) as the backbone of the low resolution network, motivated by the observation that the tokenization step of ViT can reduce spatial resolution while retain as much pixel information as possible. To inform local regions of the context, we propose a novel cross region attention (CRA) module in the refinement network to propagate the contextual information across the neighboring regions. We demonstrate that our method achieves superior results and outperforms other baselines on three benchmark datasets while only uses $1/20$ of the FLOPS compared to the existing state-of-the-art model.
</details>
<details>
<summary>摘要</summary>
我们提出了一种轻量级的高分辨率肖像剪辑模型。该模型不使用任何辅助输入，如trimap或背景捕捉，并在高清视频和4K视频的实时性下运行。我们的模型基于两个阶段框架，其中低分辨率网络用于粗略alpha估计，然后是进行地域改进的改进网络。然而，如果不使用任何辅助输入，那么模型的剪辑质量很容易受到影响。我们解决这个性能差距的问题，通过利用视transformer（ViT）作为低分辨率网络的基础，这是因为ViT的tokenization步骤可以减少空间分辨率，同时保留最多的像素信息。为了在 neighouring region中传递Contextual信息，我们提出了一种新的跨区域注意力（CRA）模块，用于在邻近区域之间传递Contextual信息。我们示出，我们的方法可以在三个标准测试集上实现更好的结果，并且只需使用$1/20$的FLOPS，与现有状态之前的模型相比。
</details></li>
</ul>
<hr>
<h2 id="Image-change-detection-with-only-a-few-samples"><a href="#Image-change-detection-with-only-a-few-samples" class="headerlink" title="Image change detection with only a few samples"></a>Image change detection with only a few samples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03762">http://arxiv.org/abs/2311.03762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Ke Liu, Zhaoyi Song, Haoyue Bai</li>
<li>for:  solves the problem of image change detection with a small number of samples, which is a significant problem due to the lack of large annotated datasets.</li>
<li>methods:  uses simple image processing methods to generate synthetic but informative datasets, and designs an early fusion network based on object detection to improve generalization ability.</li>
<li>results:  demonstrates that the synthetic data is informative enough to achieve higher generalization ability than the insufficient real-world data, and fine-tuning the model with a few samples can achieve excellent results.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究解决了图像变化检测具有小数量样本的问题，这是因为图像变化检测任务缺乏大量场景化标注数据。变化检测模型在不充足的数据上训练后，对各种场景的泛化能力异常差。</li>
<li>methods: 我们提出使用简单的图像处理方法生成Synthetic数据，并设计基于物体检测的早期融合网络，以提高模型的泛化能力。我们的关键发现是Synthetic数据使得训练模型在多种场景上具有良好的泛化能力。</li>
<li>results: 我们 comparing the model trained on Synthetic数据与从CDNet dataset中捕捉的实际数据，使用六个不同的测试集。结果表明Synthetic数据具有较高的泛化能力，而且通过使用几十个样本来精制模型，可以达到优秀的结果。<details>
<summary>Abstract</summary>
This paper considers image change detection with only a small number of samples, which is a significant problem in terms of a few annotations available. A major impediment of image change detection task is the lack of large annotated datasets covering a wide variety of scenes. Change detection models trained on insufficient datasets have shown poor generalization capability. To address the poor generalization issue, we propose using simple image processing methods for generating synthetic but informative datasets, and design an early fusion network based on object detection which could outperform the siamese neural network. Our key insight is that the synthetic data enables the trained model to have good generalization ability for various scenarios. We compare the model trained on the synthetic data with that on the real-world data captured from a challenging dataset, CDNet, using six different test sets. The results demonstrate that the synthetic data is informative enough to achieve higher generalization ability than the insufficient real-world data. Besides, the experiment shows that utilizing a few (often tens of) samples to fine-tune the model trained on the synthetic data will achieve excellent results.
</details>
<details>
<summary>摘要</summary>
The authors compare the model trained on the synthetic data with that on the real-world data captured from the challenging CDNet dataset using six different test sets. The results show that the synthetic data is informative enough to achieve higher generalization ability than the insufficient real-world data. Additionally, the experiment demonstrates that utilizing a few (often tens of) samples to fine-tune the model trained on the synthetic data will achieve excellent results.In simplified Chinese, the text can be translated as:这篇论文考虑了只使用少数样本进行图像变化检测，这是因为图像变化检测任务中缺乏充足的注释。图像变化检测模型在缺乏大量注释的情况下训练时表现出了差异化能力的问题。为解决这一问题，我们提出了使用简单的图像处理方法生成synthetic但具有信息的数据集，并设计了基于物体检测的早期融合网络。我们的关键发现是，synthetic数据使得训练模型具有较好的泛化能力。我们将模型训练在synthetic数据上与实际世界数据（从CDNet dataset中捕捉到的DiffNet dataset）进行比较，使用六个不同的测试集。结果表明，synthetic数据具有很好的泛化能力，而实际世界数据的泛化能力较差。此外，实验还表明，通过使用一些（通常是十几）样本来精度调整模型训练在synthetic数据上的模型，可以获得极佳的结果。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Segmentation-using-Teeth-Attention-Modules-for-Dental-X-ray-Images"><a href="#Multiclass-Segmentation-using-Teeth-Attention-Modules-for-Dental-X-ray-Images" class="headerlink" title="Multiclass Segmentation using Teeth Attention Modules for Dental X-ray Images"></a>Multiclass Segmentation using Teeth Attention Modules for Dental X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03749">http://arxiv.org/abs/2311.03749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Afnan Ghafoor, Seong-Yong Moon, Bumshik Lee</li>
<li>For: The paper proposes a novel teeth segmentation architecture that integrates an M-Net-like structure with Swin Transformers and a novel component named Teeth Attention Block (TAB) to improve the accuracy and reliability of teeth segmentation in dental panoramic images.* Methods: The proposed architecture utilizes an M-Net-like structure with Swin Transformers and TAB to capture local and global contextual information, and a unique attention mechanism that specifically highlights key elements of teeth features in panoramic images. The multiscale supervision strategy and squared Dice loss are also employed to enhance the performance of the segmentation.* Results: The proposed method was validated on a panoramic teeth X-ray dataset and outperformed existing state-of-the-art methods in objective metrics and visual examinations, demonstrating its efficacy for tooth segmentation on multiple benchmark dental image datasets.<details>
<summary>Abstract</summary>
This paper proposed a cutting-edge multiclass teeth segmentation architecture that integrates an M-Net-like structure with Swin Transformers and a novel component named Teeth Attention Block (TAB). Existing teeth image segmentation methods have issues with less accurate and unreliable segmentation outcomes due to the complex and varying morphology of teeth, although teeth segmentation in dental panoramic images is essential for dental disease diagnosis. We propose a novel teeth segmentation model incorporating an M-Net-like structure with Swin Transformers and TAB. The proposed TAB utilizes a unique attention mechanism that focuses specifically on the complex structures of teeth. The attention mechanism in TAB precisely highlights key elements of teeth features in panoramic images, resulting in more accurate segmentation outcomes. The proposed architecture effectively captures local and global contextual information, accurately defining each tooth and its surrounding structures. Furthermore, we employ a multiscale supervision strategy, which leverages the left and right legs of the U-Net structure, boosting the performance of the segmentation with enhanced feature representation. The squared Dice loss is utilized to tackle the class imbalance issue, ensuring accurate segmentation across all classes. The proposed method was validated on a panoramic teeth X-ray dataset, which was taken in a real-world dental diagnosis. The experimental results demonstrate the efficacy of our proposed architecture for tooth segmentation on multiple benchmark dental image datasets, outperforming existing state-of-the-art methods in objective metrics and visual examinations. This study has the potential to significantly enhance dental image analysis and contribute to advances in dental applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SBCFormer-Lightweight-Network-Capable-of-Full-size-ImageNet-Classification-at-1-FPS-on-Single-Board-Computers"><a href="#SBCFormer-Lightweight-Network-Capable-of-Full-size-ImageNet-Classification-at-1-FPS-on-Single-Board-Computers" class="headerlink" title="SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers"></a>SBCFormer: Lightweight Network Capable of Full-size ImageNet Classification at 1 FPS on Single Board Computers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03747">http://arxiv.org/abs/2311.03747</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyonglu/sbcformer">https://github.com/xyonglu/sbcformer</a></li>
<li>paper_authors: Xiangyong Lu, Masanori Suganuma, Takayuki Okatani</li>
<li>for: 这 paper 的目的是提出一种适用于单板计算机 (SBC) 上的 CNN-ViT 混合网络，以实现高精度和快速计算。</li>
<li>methods: 这 paper 使用了一种新的网络架构，叫做 SBCFormer，它结合了 CNN 和 ViT 两种网络，并且特意设计了一种适应 low-end CPU 的硬件约束。</li>
<li>results: 根据 paper 的实验结果，SBCFormer 可以在 Raspberry Pi 4 Model B 上 Achieve ImageNet-1K 顶部 1 准确率达到80%，并且在1.0帧&#x2F;秒的速度下运行。这是首次在 SBC 上实现这种性能。<details>
<summary>Abstract</summary>
Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer.
</details>
<details>
<summary>摘要</summary>
计算机视觉在各种领域中日益普及，包括智能农业、渔业和畜牧管理。这些应用程序可能不需要处理大量图像帧数，因此实际使用单板计算机（SBC）。虽然许多轻量级网络已经为移动/边缘设备开发，但它们主要target着更具有力量的手机处理器，而不是SBC的低端CPU。这篇论文介绍了一种叫做SBCFormer的CNN-ViT混合网络，它在低端CPU上实现了高准确率和快速计算。由于硬件限制， transformer 的注意机制更适合SBC。但是在低端CPU上使用注意力表现出一个挑战：高分辨率内部特征图需要过度的计算资源，但是降低其分辨率会导致地方图像细节的丢失。SBCFormer 提出了一种体系设计来解决这个问题。因此，SBCFormer 在一个 Raspberry Pi 4 Model B 上实现了 ARM-Cortex A72 CPU 上的 ImageNet-1K 顶部1准确率约为 80%，并且速度为 1.0帧/秒。代码可以在 <https://github.com/xyongLu/SBCFormer> 上找到。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Video-Summarization"><a href="#Unsupervised-Video-Summarization" class="headerlink" title="Unsupervised Video Summarization"></a>Unsupervised Video Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03745">http://arxiv.org/abs/2311.03745</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KaiyangZhou/pytorch-vsumm-reinforce">https://github.com/KaiyangZhou/pytorch-vsumm-reinforce</a></li>
<li>paper_authors: Hanqing Li, Diego Klabjan, Jean Utke</li>
<li>for: 这种方法用于自动视频摘要，利用生成对抗网络的想法，但是去掉识别器，使用简单的损失函数，并分解模型的不同部分的训练。</li>
<li>methods: 使用迭代训练策略，首先训练恢复器，然后训练帧选择器，并在训练和评估过程中添加可变的掩码向量。</li>
<li>results: 在两个公共数据集（SumMe和TVSum）以及四个自定义数据集（足球、LoL、MLB和ShortMLB）上进行了实验，结果显示了每个组件对模型性能的影响，特别是迭代训练策略的效果。对比现有方法，提出的方法在性能、稳定性和训练效率方面具有优势。<details>
<summary>Abstract</summary>
This paper introduces a new, unsupervised method for automatic video summarization using ideas from generative adversarial networks but eliminating the discriminator, having a simple loss function, and separating training of different parts of the model. An iterative training strategy is also applied by alternately training the reconstructor and the frame selector for multiple iterations. Furthermore, a trainable mask vector is added to the model in summary generation during training and evaluation. The method also includes an unsupervised model selection algorithm. Results from experiments on two public datasets (SumMe and TVSum) and four datasets we created (Soccer, LoL, MLB, and ShortMLB) demonstrate the effectiveness of each component on the model performance, particularly the iterative training strategy. Evaluations and comparisons with the state-of-the-art methods highlight the advantages of the proposed method in performance, stability, and training efficiency.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的无监督自动视频摘要方法，使用生成对抗网络的想法，但是去掉了识别器，使用简单的损失函数，并将模型的不同部分分解训练。此外，还采用了间歇训练STRATEGY，在多个迭代中 alternate训练重建器和帧选择器。此外，在摘要生成过程中，添加了可学习的掩码向量。方法还包括一种无监督模型选择算法。实验结果表明，每个组件对模型性能的影响，特别是间歇训练策略。对比现有方法，提出的方法在性能、稳定性和训练效率方面具有优势。
</details></li>
</ul>
<hr>
<h2 id="3DifFusionDet-Diffusion-Model-for-3D-Object-Detection-with-Robust-LiDAR-Camera-Fusion"><a href="#3DifFusionDet-Diffusion-Model-for-3D-Object-Detection-with-Robust-LiDAR-Camera-Fusion" class="headerlink" title="3DifFusionDet: Diffusion Model for 3D Object Detection with Robust LiDAR-Camera Fusion"></a>3DifFusionDet: Diffusion Model for 3D Object Detection with Robust LiDAR-Camera Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03742">http://arxiv.org/abs/2311.03742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Xiang, Simon Dräger, Jiawei Zhang</li>
<li>for: 这篇论文的目的是提出一个名为3DifFusionDet的三维物体检测框架，以实现高效精确的三维物体检测。</li>
<li>methods: 这篇论文使用了一种名为“denoising diffusion process”的方法，将受扰的三维盒子转换为目标盒子。在训练过程中，模型从真实的标准盒子中学习了逆转的过程。在推断过程中，模型逐渐精确地调整一些随机生成的盒子，以得到最终的结果。</li>
<li>results: 实验结果显示，3DifFusionDet在KITTIbenchmark上表现优异，与之前的知名检测器相比，具有更高的精确性和更高的效率。<details>
<summary>Abstract</summary>
Good 3D object detection performance from LiDAR-Camera sensors demands seamless feature alignment and fusion strategies. We propose the 3DifFusionDet framework in this paper, which structures 3D object detection as a denoising diffusion process from noisy 3D boxes to target boxes. In this framework, ground truth boxes diffuse in a random distribution for training, and the model learns to reverse the noising process. During inference, the model gradually refines a set of boxes that were generated at random to the outcomes. Under the feature align strategy, the progressive refinement method could make a significant contribution to robust LiDAR-Camera fusion. The iterative refinement process could also demonstrate great adaptability by applying the framework to various detecting circumstances where varying levels of accuracy and speed are required. Extensive experiments on KITTI, a benchmark for real-world traffic object identification, revealed that 3DifFusionDet is able to perform favorably in comparison to earlier, well-respected detectors.
</details>
<details>
<summary>摘要</summary>
好的3D物体检测性能从LiDAR-Camera感知器需要无缝特征对应和融合策略。我们在这篇论文中提出了3DifFusionDet框架，它将3D物体检测视为一个噪声扩散过程，从噪声3D盒子到目标盒子的扩散进行结构。在这个框架中，真实的盒子在训练中随机分布，模型学习反噪声过程。在推断中，模型逐渐精细化一组随机生成的盒子，以达到结果。在特征对应策略下，进行了逐渐精细化的方法，可以在不同的检测情况下提供了强大的适应性。例如，在不同的准确率和速度要求下，可以应用这种框架来进行多种不同的检测。在KITTI，一个实际的交通物体识别标准 bencmark上，我们进行了广泛的实验，发现3DifFusionDet能够与之前的高度尊敬的检测器相比，表现出优异的性能。
</details></li>
</ul>
<hr>
<h2 id="DeepInspect-An-AI-Powered-Defect-Detection-for-Manufacturing-Industries"><a href="#DeepInspect-An-AI-Powered-Defect-Detection-for-Manufacturing-Industries" class="headerlink" title="DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries"></a>DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03725">http://arxiv.org/abs/2311.03725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arti Kumbhar, Amruta Chougale, Priya Lokhande, Saloni Navaghane, Aditi Burud, Saee Nimbalkar</li>
<li>for:  automatic defect detection in manufacturing</li>
<li>methods:  Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs)</li>
<li>results:  precise identification of faults, adaptability across various defect scenarios, reduction of waste and operational costs, enhancement of market competitiveness.<details>
<summary>Abstract</summary>
Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs), our system introduces an innovative approach to defect detection in manufacturing. This technology excels in precisely identifying faults by extracting intricate details from product photographs, utilizing RNNs to detect evolving errors and generating synthetic defect data to bolster the model's robustness and adaptability across various defect scenarios. The project leverages a deep learning framework to automate real-time flaw detection in the manufacturing process. It harnesses extensive datasets of annotated images to discern complex defect patterns. This integrated system seamlessly fits into production workflows, thereby boosting efficiency and elevating product quality. As a result, it reduces waste and operational costs, ultimately enhancing market competitiveness.
</details>
<details>
<summary>摘要</summary>
我们的系统利用卷积神经网络（CNN）、循环神经网络（RNN）和生成对抗网络（GAN），引入了一种创新的瑕疵检测方法。这种技术能够准确地识别瑕疵，通过提取产品图像中的细节来检测演变性错误，并生成合成瑕疵数据来增强模型的可靠性和适应性。该系统利用深度学习框架自动化生产过程中的实时瑕疵检测。它利用大量标注图像集来识别复杂的瑕疵模式。这个整体系统顺应生产工艺流程，因此可以提高效率和产品质量。因此，它可以降低废弃和运营成本，最终提高市场竞争力。
</details></li>
</ul>
<hr>
<h2 id="Inertial-Guided-Uncertainty-Estimation-of-Feature-Correspondence-in-Visual-Inertial-Odometry-SLAM"><a href="#Inertial-Guided-Uncertainty-Estimation-of-Feature-Correspondence-in-Visual-Inertial-Odometry-SLAM" class="headerlink" title="Inertial Guided Uncertainty Estimation of Feature Correspondence in Visual-Inertial Odometry&#x2F;SLAM"></a>Inertial Guided Uncertainty Estimation of Feature Correspondence in Visual-Inertial Odometry&#x2F;SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03722">http://arxiv.org/abs/2311.03722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seongwook Yoon, Jaehyun Kim, Sanghoon Sull</li>
<li>for: 这个论文主要针对计算机视觉和机器人领域中的自主导航和增强现实系统，即视觉和同时地图生成（SLAM）问题。</li>
<li>methods: 该论文提出了一种基于特征跟踪和匹配的视觉增益和同时地图生成方法，并使用了陀螺仪测量单元（IMU）来帮助视觉传感器。</li>
<li>results: 论文提出的方法可以更加准确地估计特征匹配的uncertainty，并且在实验中demonstrate了其可行性。<details>
<summary>Abstract</summary>
Visual odometry and Simultaneous Localization And Mapping (SLAM) has been studied as one of the most important tasks in the areas of computer vision and robotics, to contribute to autonomous navigation and augmented reality systems. In case of feature-based odometry/SLAM, a moving visual sensor observes a set of 3D points from different viewpoints, correspondences between the projected 2D points in each image are usually established by feature tracking and matching. However, since the corresponding point could be erroneous and noisy, reliable uncertainty estimation can improve the accuracy of odometry/SLAM methods. In addition, inertial measurement unit is utilized to aid the visual sensor in terms of Visual-Inertial fusion. In this paper, we propose a method to estimate the uncertainty of feature correspondence using an inertial guidance robust to image degradation caused by motion blur, illumination change and occlusion. Modeling a guidance distribution to sample possible correspondence, we fit the distribution to an energy function based on image error, yielding more robust uncertainty than conventional methods. We also demonstrate the feasibility of our approach by incorporating it into one of recent visual-inertial odometry/SLAM algorithms for public datasets.
</details>
<details>
<summary>摘要</summary>
视觉增益和同时地理位和地图建模（SLAM）已经被视为计算机视觉和机器人领域中的一项非常重要的任务，以帮助实现自主导航和增强现实系统。在特征基于的增益/SLAM中，一个在不同视点观察的移动视觉器 observe一组3D点，通常通过特征跟踪和匹配来建立图像中每个2D点的对应关系。然而，由于对应点可能存在错误和噪声，可靠的不确定性估计可以提高增益/SLAM方法的准确性。此外，使用抗频率器来帮助视觉器，以实现视觉-抗频率融合。在这篇论文中，我们提出了一种用于估计特征对应关系的不确定性的方法，该方法基于图像误差能量函数，可以提供更加可靠的不确定性估计。我们还展示了我们的方法在一个现有的视觉-抗频率增益/SLAM算法中的可行性。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-deep-representation-learning-for-quantum-cross-platform-verification"><a href="#Multimodal-deep-representation-learning-for-quantum-cross-platform-verification" class="headerlink" title="Multimodal deep representation learning for quantum cross-platform verification"></a>Multimodal deep representation learning for quantum cross-platform verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03713">http://arxiv.org/abs/2311.03713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Qian, Yuxuan Du, Zhenliang He, Min-hsiu Hsieh, Dacheng Tao</li>
<li>for: 这篇论文的目的是为了解决早期量子计算中的跨平台验证问题，特别是在大量子比特的情况下。</li>
<li>methods: 这篇论文使用了一种创新的多模式学习方法，利用量子device上实验的量子测量结果和 classical描述的 compiled circuits 来建立一个完整的数据表示。</li>
<li>results: 这篇论文的结果显示，使用这种多模式学习方法可以对跨平台的量子device进行有效的验证，并且在不同的噪声模型下可以 achieve 三个数据的改善精度。<details>
<summary>Abstract</summary>
Cross-platform verification, a critical undertaking in the realm of early-stage quantum computing, endeavors to characterize the similarity of two imperfect quantum devices executing identical algorithms, utilizing minimal measurements. While the random measurement approach has been instrumental in this context, the quasi-exponential computational demand with increasing qubit count hurdles its feasibility in large-qubit scenarios. To bridge this knowledge gap, here we introduce an innovative multimodal learning approach, recognizing that the formalism of data in this task embodies two distinct modalities: measurement outcomes and classical description of compiled circuits on explored quantum devices, both enriched with unique information. Building upon this insight, we devise a multimodal neural network to independently extract knowledge from these modalities, followed by a fusion operation to create a comprehensive data representation. The learned representation can effectively characterize the similarity between the explored quantum devices when executing new quantum algorithms not present in the training data. We evaluate our proposal on platforms featuring diverse noise models, encompassing system sizes up to 50 qubits. The achieved results demonstrate a three-orders-of-magnitude improvement in prediction accuracy compared to the random measurements and offer compelling evidence of the complementary roles played by each modality in cross-platform verification. These findings pave the way for harnessing the power of multimodal learning to overcome challenges in wider quantum system learning tasks.
</details>
<details>
<summary>摘要</summary>
across-platform verification, a critical task in early-stage quantum computing, aims to characterize the similarity of two imperfect quantum devices executing identical algorithms using minimal measurements. Although the random measurement approach has been instrumental in this context, its computational demand increases exponentially with the number of qubits, making it unfeasible for large-qubit scenarios. To address this challenge, we propose an innovative multimodal learning approach that recognizes that the formalism of data in this task involves two distinct modalities: measurement outcomes and classical descriptions of compiled circuits on explored quantum devices, both of which contain unique information. We build on this insight to develop a multimodal neural network that independently extracts knowledge from these modalities, followed by a fusion operation to create a comprehensive data representation. The learned representation can effectively characterize the similarity between the explored quantum devices when executing new quantum algorithms not present in the training data. We evaluate our proposal on platforms with diverse noise models, including systems up to 50 qubits. The results show a three-orders-of-magnitude improvement in prediction accuracy compared to random measurements, providing compelling evidence of the complementary roles played by each modality in cross-platform verification. These findings pave the way for harnessing the power of multimodal learning to overcome challenges in wider quantum system learning tasks.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-convolutional-neural-network-fusion-approach-for-change-detection-in-remote-sensing-images"><a href="#Unsupervised-convolutional-neural-network-fusion-approach-for-change-detection-in-remote-sensing-images" class="headerlink" title="Unsupervised convolutional neural network fusion approach for change detection in remote sensing images"></a>Unsupervised convolutional neural network fusion approach for change detection in remote sensing images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03679">http://arxiv.org/abs/2311.03679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weidong Yan, Pei Yan, Li Cao</li>
<li>for: 这篇论文旨在提出一种不需要大量训练数据的深度学习改变检测方法。</li>
<li>methods: 本研究使用了一种简单的浅层神经网络（USCNN）融合方法，将双时间图像转换为不同的特征空间，并使用1*1卷积层融合不同时间图像的差异特征图像。</li>
<li>results: 实验结果显示，提出的方法可以实现不需要大量训练数据的改变检测，并且在四个实验数据中显示了可行性和有效性。<details>
<summary>Abstract</summary>
With the rapid development of deep learning, a variety of change detection methods based on deep learning have emerged in recent years. However, these methods usually require a large number of training samples to train the network model, so it is very expensive. In this paper, we introduce a completely unsupervised shallow convolutional neural network (USCNN) fusion approach for change detection. Firstly, the bi-temporal images are transformed into different feature spaces by using convolution kernels of different sizes to extract multi-scale information of the images. Secondly, the output features of bi-temporal images at the same convolution kernels are subtracted to obtain the corresponding difference images, and the difference feature images at the same scale are fused into one feature image by using 1 * 1 convolution layer. Finally, the output features of different scales are concatenated and a 1 * 1 convolution layer is used to fuse the multi-scale information of the image. The model parameters are obtained by a redesigned sparse function. Our model has three features: the entire training process is conducted in an unsupervised manner, the network architecture is shallow, and the objective function is sparse. Thus, it can be seen as a kind of lightweight network model. Experimental results on four real remote sensing datasets indicate the feasibility and effectiveness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
随着深度学习的快速发展，过去几年出现了多种基于深度学习的变化检测方法。然而，这些方法通常需要训练大量样本来训练网络模型，因此很昂贵。在这篇论文中，我们介绍了一种完全无监督的浅层卷积神经网络（USCNN）融合方法 для变化检测。首先，我们将bi-temporal图像转换为不同的特征空间，使用不同大小的卷积核来提取图像的多尺度信息。然后，同一个卷积核中的输出特征图像之间的差异图像被计算出来，并将同一个批处理的差异特征图像融合成一个特征图像使用1*1卷积层。最后，不同的批处理级别的输出特征被 concatenate 并使用1*1卷积层融合图像的多尺度信息。模型参数由一种重新定义的稀疏函数获得。我们的模型具有三个特点：整个训练过程是无监督的，网络架构是浅层的，目标函数是稀疏的。因此，它可以被视为一种轻量级的网络模型。实验结果表明，提posed方法在四个实际遥感数据集上的可行性和效果。
</details></li>
</ul>
<hr>
<h2 id="Image-Generation-and-Learning-Strategy-for-Deep-Document-Forgery-Detection"><a href="#Image-Generation-and-Learning-Strategy-for-Deep-Document-Forgery-Detection" class="headerlink" title="Image Generation and Learning Strategy for Deep Document Forgery Detection"></a>Image Generation and Learning Strategy for Deep Document Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03650">http://arxiv.org/abs/2311.03650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yamato Okamoto, Osada Genki, Iu Yahiro, Rintaro Hasegawa, Peifei Zhu, Hirokatsu Kataoka</li>
<li>for: 防止文档受到深度神经网络方法引起的伪造（document forgery）。</li>
<li>methods: 使用自然图像和文档图像自然学习，以及FD-VIED数据集来驱动文档检测模型的预训练。</li>
<li>results: 在实验中，我们的方法提高了文档检测性能。<details>
<summary>Abstract</summary>
In recent years, document processing has flourished and brought numerous benefits. However, there has been a significant rise in reported cases of forged document images. Specifically, recent advancements in deep neural network (DNN) methods for generative tasks may amplify the threat of document forgery. Traditional approaches for forged document images created by prevalent copy-move methods are unsuitable against those created by DNN-based methods, as we have verified. To address this issue, we construct a training dataset of document forgery images, named FD-VIED, by emulating possible attacks, such as text addition, removal, and replacement with recent DNN-methods. Additionally, we introduce an effective pre-training approach through self-supervised learning with both natural images and document images. In our experiments, we demonstrate that our approach enhances detection performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Instruct-Me-More-Random-Prompting-for-Visual-In-Context-Learning"><a href="#Instruct-Me-More-Random-Prompting-for-Visual-In-Context-Learning" class="headerlink" title="Instruct Me More! Random Prompting for Visual In-Context Learning"></a>Instruct Me More! Random Prompting for Visual In-Context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03648">http://arxiv.org/abs/2311.03648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Zhang, Bowen Wang, Liangzhi Li, Yuta Nakashima, Hajime Nagahara</li>
<li>for: 这篇论文是用于探讨如何使用大规模模型进行内容学习（ICL），并且将这种方法应用到Computer Vision tasks。</li>
<li>methods: 这篇论文使用了一种名为Instruct Me More（InMeMo）的方法，它将内容组（input-output image pair）与查询图像（prompt）结合，以提高ICL的效能。</li>
<li>results: 实验结果显示，将learnable prompt加入ICL可以提高mainstream tasks的性能，包括增加了7.35和15.13的mIoU scores for foreground segmentation和single object detection tasks。<details>
<summary>Abstract</summary>
Large-scale models trained on extensive datasets, have emerged as the preferred approach due to their high generalizability across various tasks. In-context learning (ICL), a popular strategy in natural language processing, uses such models for different tasks by providing instructive prompts but without updating model parameters. This idea is now being explored in computer vision, where an input-output image pair (called an in-context pair) is supplied to the model with a query image as a prompt to exemplify the desired output. The efficacy of visual ICL often depends on the quality of the prompts. We thus introduce a method coined Instruct Me More (InMeMo), which augments in-context pairs with a learnable perturbation (prompt), to explore its potential. Our experiments on mainstream tasks reveal that InMeMo surpasses the current state-of-the-art performance. Specifically, compared to the baseline without learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for foreground segmentation and single object detection tasks, respectively. Our findings suggest that InMeMo offers a versatile and efficient way to enhance the performance of visual ICL with lightweight training. Code is available at https://github.com/Jackieam/InMeMo.
</details>
<details>
<summary>摘要</summary>
大规模模型，通过它们的高通用性，在不同任务上表现出优异的成绩。在自然语言处理领域， Context Learning（ICL）是一种受欢迎的策略，使用这些模型来执行不同任务，只需提供指导性的提示，而不需更新模型参数。在计算机视觉领域，我们使用输入输出图像对（称为在 контекст对），并将查询图像作为提示，以便通过模型来示例出所需的输出。 visual ICL 的效果frequently depends on the quality of the prompts。因此，我们介绍了一种名为 Instruct Me More（InMeMo）的方法，该方法通过添加学习式的干扰（提示）来探索其 potential。我们的实验表明，Compared to the baseline without learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for foreground segmentation and single object detection tasks, respectively。我们的发现表明，InMeMo 提供了一种 versatile 和高效的方式，用于增强视觉 ICLL 的性能，只需要轻量级的训练。代码可以在 <https://github.com/Jackieam/InMeMo> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Random-Field-Augmentations-for-Self-Supervised-Representation-Learning"><a href="#Random-Field-Augmentations-for-Self-Supervised-Representation-Learning" class="headerlink" title="Random Field Augmentations for Self-Supervised Representation Learning"></a>Random Field Augmentations for Self-Supervised Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03629">http://arxiv.org/abs/2311.03629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philip Andrew Mansfield, Arash Afkanpour, Warren Richard Morningstar, Karan Singhal</li>
<li>for: 这篇论文是为了提高自主学习表示学习的表示学习效果而写的。</li>
<li>methods: 这篇论文提出了一新的局部变换基于 Gaussian 随机场，用于实现自主学习表示学习中的对称性。这些变换包括变形、旋转、颜色变化等，并且允许变换参数值在像素尺寸上 vary。</li>
<li>results: 这篇论文的实验结果显示，新的局部变换可以帮助自主学习表示学习中提高表示学习的效果。具体而言，在 ImageNet 下测试中，与基eline比较，我们 achieved 1.7% 的 top-1 精度提升，并在 out-of-distribution iNaturalist 下测试中 achieved 3.6% 的精度提升。但是，由于新的变换的灵活性，学习的表示受到了对称性和强度的影响，需要对对称性和强度进行平衡。<details>
<summary>Abstract</summary>
Self-supervised representation learning is heavily dependent on data augmentations to specify the invariances encoded in representations. Previous work has shown that applying diverse data augmentations is crucial to downstream performance, but augmentation techniques remain under-explored. In this work, we propose a new family of local transformations based on Gaussian random fields to generate image augmentations for self-supervised representation learning. These transformations generalize the well-established affine and color transformations (translation, rotation, color jitter, etc.) and greatly increase the space of augmentations by allowing transformation parameter values to vary from pixel to pixel. The parameters are treated as continuous functions of spatial coordinates, and modeled as independent Gaussian random fields. Empirical results show the effectiveness of the new transformations for self-supervised representation learning. Specifically, we achieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream classification, and a 3.6% improvement on out-of-distribution iNaturalist downstream classification. However, due to the flexibility of the new transformations, learned representations are sensitive to hyperparameters. While mild transformations improve representations, we observe that strong transformations can degrade the structure of an image, indicating that balancing the diversity and strength of augmentations is important for improving generalization of learned representations.
</details>
<details>
<summary>摘要</summary>
自我指导学习中的表示学习强烈依赖于数据扩充来确定表示中的不变性。先前的工作表明，对表示学习而言，应用多样化数据扩充是关键，但是扩充技术还很少研究。在这项工作中，我们提出了一个新的本地变换家族，基于 Gaussian 随机场来生成图像扩充。这些变换超过了已知的平移、旋转和颜色扰动等变换，并大幅扩展了扩充的空间。变换参数被视为像素坐标上的连续函数，并被模型为独立的 Gaussian 随机场。实验结果表明新的变换对自我指导学习有效。特别是，我们在 ImageNet 下流类预测中 achieved 1.7% 的 top-1 精度提升，并在 iNaturalist 上流类预测中 achieved 3.6% 的精度提升。然而，由于新的变换的灵活性，学习的表示受到了 hyperparameter 的影响。虽然柔和的变换可以改进表示，但我们发现强大的变换可能会损害图像的结构，这表明在改进学习表示的通用化时，需要平衡扩充的多样性和强度。
</details></li>
</ul>
<hr>
<h2 id="FusionViT-Hierarchical-3D-Object-Detection-via-LiDAR-Camera-Vision-Transformer-Fusion"><a href="#FusionViT-Hierarchical-3D-Object-Detection-via-LiDAR-Camera-Vision-Transformer-Fusion" class="headerlink" title="FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision Transformer Fusion"></a>FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision Transformer Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03620">http://arxiv.org/abs/2311.03620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhao Xiang, Jiawei Zhang</li>
<li>for: 3D object detection in real-world traffic scenarios, using both camera and lidar sensor data</li>
<li>methods: using a novel vision transformer-based framework called FusionViT, which embeds both images and point clouds and fuses them via a fusion vision transformer model for effective representation learning</li>
<li>results: achieving state-of-the-art performance and outperforming existing baseline methods and multi-modal image-point cloud deep fusion approaches on real-world benchmark datasets KITTI and Waymo Open<details>
<summary>Abstract</summary>
For 3D object detection, both camera and lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches.
</details>
<details>
<summary>摘要</summary>
For 3D object detection, both camera and lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches.Here's the translation in Traditional Chinese:For 3D object detection, both camera and lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.CV_2023_11_07/" data-id="cloqtaes900l9gh880hhv4nw1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.AI_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T12:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.AI_2023_11_07/">cs.AI - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="OtterHD-A-High-Resolution-Multi-modality-Model"><a href="#OtterHD-A-High-Resolution-Multi-modality-Model" class="headerlink" title="OtterHD: A High-Resolution Multi-modality Model"></a>OtterHD: A High-Resolution Multi-modality Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04219">http://arxiv.org/abs/2311.04219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Li, Peiyuan Zhang, Jingkang Yang, Yuanhan Zhang, Fanyi Pu, Ziwei Liu</li>
<li>for: 这项研究旨在开发一种可以处理高分辨率视觉输入的多模式模型，以提高模型对小物体的识别精度和空间关系的能力。</li>
<li>methods: 这种模型基于Fuyu-8B架构，并通过采用可变输入维度的方式，使得模型具有更高的灵活性，可以适应不同的推理需求。</li>
<li>results: 对比当前领先模型，OtterHD-8B在MagnifierBench测试框架上表现出优异的表现，特别是在直接处理高分辨率输入时，其与对手的差距非常大。这些结果表明不同的视觉模型在处理小物体的细节和空间关系方面存在结构性差异，同时也表明Fuyu架构的简单性和高分辨率输入能力在处理复杂视觉数据方面的潜在潜力。<details>
<summary>Abstract</summary>
In this paper, we present OtterHD-8B, an innovative multimodal model evolved from Fuyu-8B, specifically engineered to interpret high-resolution visual inputs with granular precision. Unlike conventional models that are constrained by fixed-size vision encoders, OtterHD-8B boasts the ability to handle flexible input dimensions, ensuring its versatility across various inference requirements. Alongside this model, we introduce MagnifierBench, an evaluation framework designed to scrutinize models' ability to discern minute details and spatial relationships of small objects. Our comparative analysis reveals that while current leading models falter on this benchmark, OtterHD-8B, particularly when directly processing high-resolution inputs, outperforms its counterparts by a substantial margin. The findings illuminate the structural variances in visual information processing among different models and the influence that the vision encoders' pre-training resolution disparities have on model effectiveness within such benchmarks. Our study highlights the critical role of flexibility and high-resolution input capabilities in large multimodal models and also exemplifies the potential inherent in the Fuyu architecture's simplicity for handling complex visual data.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了OtterHD-8B，一种创新的多模态模型，由Fuyu-8B模型进化而来，专门用于处理高分辨率视觉输入。与传统模型不同，OtterHD-8B具有可变输入维度的能力，使其在不同的推理需求中表现弹性。此外，我们还提出了MagnifierBench评价框架，用于测试模型对小 объек的细节和空间关系的掌握能力。我们的比较分析表明，当直接处理高分辨率输入时，OtterHD-8B在相同的比较中减少了对手的差距。这些发现揭示了不同模型在视觉信息处理中的结构差异以及视觉编码器预训练分辨率差异对模型效果的影响。我们的研究强调了大型多模态模型的灵活性和高分辨率输入能力的重要性，以及Fuyu架构的简单性在处理复杂视觉数据方面的潜在能力。
</details></li>
</ul>
<hr>
<h2 id="Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image"><a href="#Towards-Garment-Sewing-Pattern-Reconstruction-from-a-Single-Image" class="headerlink" title="Towards Garment Sewing Pattern Reconstruction from a Single Image"></a>Towards Garment Sewing Pattern Reconstruction from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04218">http://arxiv.org/abs/2311.04218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lijuan Liu, Xiangyu Xu, Zhijie Lin, Jiabin Liang, Shuicheng Yan</li>
<li>for: 本研究旨在实现从日常照片中提取衣物缝线图样，以推进时装设计、虚拟试穿和数码人偶等应用。</li>
<li>methods: 本研究首先Synthesize了一个多样化的数据集，名为SewFactory，包含约100万帧照片和相应的缝线图样数据，并提出了一个Two-level Transformer网络，名为Sewformer，以改进缝线图样预测性能。</li>
<li>results: 实验结果显示，提出的框架能够有效地从日常照片中提取缝线图样，并具有广泛的应用前景和优良的普遍化性。<details>
<summary>Abstract</summary>
Garment sewing pattern represents the intrinsic rest shape of a garment, and is the core for many applications like fashion design, virtual try-on, and digital avatars. In this work, we explore the challenging problem of recovering garment sewing patterns from daily photos for augmenting these applications. To solve the problem, we first synthesize a versatile dataset, named SewFactory, which consists of around 1M images and ground-truth sewing patterns for model training and quantitative evaluation. SewFactory covers a wide range of human poses, body shapes, and sewing patterns, and possesses realistic appearances thanks to the proposed human texture synthesis network. Then, we propose a two-level Transformer network called Sewformer, which significantly improves the sewing pattern prediction performance. Extensive experiments demonstrate that the proposed framework is effective in recovering sewing patterns and well generalizes to casually-taken human photos. Code, dataset, and pre-trained models are available at: https://sewformer.github.io.
</details>
<details>
<summary>摘要</summary>
裤衣缝纹模式表示裤衣的内在自然形状，是许多应用程序 like 时尚设计、虚拟试穿和数字化人物的核心。在这项工作中，我们探讨了从日常照片中回归裤衣缝纹的困难问题。为解决这个问题，我们首先合成了一个多样化的数据集，名为 SewFactory，该数据集包含约1M张图像和真实缝纹模式的 Label 数据，用于模型训练和量化评估。 SewFactory 覆盖了人体姿势、身体形态和缝纹模式的广泛范围，并具有真实的人体Texture Synthesis 网络所提供的现实生动的外观。然后，我们提出了一个两级 Transformer 网络，名为 Sewformer，该网络可以有效地预测缝纹模式。广泛的实验表明，我们的框架可以有效地回归缝纹模式，并在习惯性拍摄的人像照片中广泛适用。代码、数据集和预训练模型可以在以下链接获取：https://sewformer.github.io。
</details></li>
</ul>
<hr>
<h2 id="Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning"><a href="#Wearable-data-from-subjects-playing-Super-Mario-sitting-university-exams-or-performing-physical-exercise-help-detect-acute-mood-episodes-via-self-supervised-learning" class="headerlink" title="Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning"></a>Wearable data from subjects playing Super Mario, sitting university exams, or performing physical exercise help detect acute mood episodes via self-supervised learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04215">http://arxiv.org/abs/2311.04215</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filippo Corponi, Bryan M. Li, Gerard Anmella, Clàudia Valenzuela-Pascual, Ariadna Mas, Isabella Pacchiarotti, Marc Valentí, Iria Grande, Antonio Benabarre, Marina Garriga, Eduard Vieta, Allan H Young, Stephen M. Lawrie, Heather C. Whalley, Diego Hidalgo-Mazzei, Antonio Vergari</li>
<li>for: 监测情绪障碍（MDs），使用数据科学技术实现跟踪和识别 MDs 的发病频率和病理特征。</li>
<li>methods: 利用无监督学习（SSL）技术，将无标的数据用于学习表征，并将这些表征转换为监督学习任务中的特征。</li>
<li>results: 在使用 E4 认知器和 XGBoost 等方法进行分析后，发现 SSL 能够优于传统的监督学习方法，具体来说是在 81.23% 的记录段中正确地识别发病和稳定的记录段。<details>
<summary>Abstract</summary>
Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden. However, collecting and annotating wearable data is very resource-intensive. Studies of this kind can thus typically afford to recruit only a couple dozens of patients. This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection. In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL). This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task. First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline. Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients. Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability.
</details>
<details>
<summary>摘要</summary>
人工感知，通过利用搭配着护身器收集的数据，在患者的生态环境中进行不间断监测，是识别情绪障碍（MDs）的有力的方法。然而，收集和标注护身器数据是非常耗资的。这类研究通常只能招募几十名病人。这是应用现代supervised machine learning技术于MDs检测的主要障碍。在这篇论文中，我们解决了这种数据瓶颈问题，并通过近期的自我监控学习（SSL）技术提高了MDs检测的精度。我们使用不标注的数据来学习表示，然后将其应用于supervised任务。我们首先收集了来自Empatica E4的开放访问数据集，包括不同的、与MD监测无关的个人感知任务，如Super Mario游戏中的情绪识别和大学生中的压力检测。我们设计了一个预处理管道，包括在/离体检测、睡眠划分、分割和（可选）特征提取。通过161名E4记录的主题，我们介绍了E4SelfLearning数据集和预处理管道。我们表明，使用SSL技术可以超越完全标注的管道，并使用我们的新型E4特化Transformer架构（E4mer）或传统基线XGBoost。在64名患者（其中有半数是陡发的）的记录段中，我们获得了81.23%的正确率，比75.35%（E4mer）和72.02%（XGBoost）高。最后，我们发现SSL性能与特定的代表任务的预处理和不标注数据的可用性有很强的相关性。
</details></li>
</ul>
<hr>
<h2 id="Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves"><a href="#Rephrase-and-Respond-Let-Large-Language-Models-Ask-Better-Questions-for-Themselves" class="headerlink" title="Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves"></a>Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04205">http://arxiv.org/abs/2311.04205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu</li>
<li>for: 提高 Large Language Model (LLM) 的性能，尤其是在听到普通的问题时。</li>
<li>methods: 提出一种名为 “Rephrase and Respond” (RaR) 的方法，让 LLM 可以将人类提出的问题重新推敲并提供回答。这种方法可以帮助 LLM 更好地理解人类的问题，从而提高它们的性能。</li>
<li>results: 经过实验表明，我们的方法可以有效地提高不同任务的模型性能。我们还对 RaR 和 Chain-of-Thought (CoT) 方法进行了比较，并证明了 RaR 和 CoT 是 complementary 的。<details>
<summary>Abstract</summary>
Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. In this paper, we present a method named `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance. Our work not only contributes to enhancing LLM performance efficiently and effectively but also sheds light on a fair evaluation of LLM capabilities. Data and codes are available at https://github.com/uclaml/Rephrase-and-Respond.
</details>
<details>
<summary>摘要</summary>
misunderstandings 不只出现在人际交流中，还可能发生在人类和大语言模型（LLM）之间。这些差异可能使 LLM 解释看似明确的问题时，提供错误的答案。虽然广泛认可的词语质量对 LLM 提供答案质量产生显著影响，但是一种系统化的问题构造方法仍然在开发阶段。在这篇论文中，我们提出了一种名为“重新phrase和回答”（Rephrase and Respond，RaR）的方法，可以让 LLM 重新构造和扩展人类提出的问题，并提供回答。这种方法可以提高 LLM 的性能，并且可以与Chain-of-Thought（CoT）方法相结合，以实现更好的性能。我们的实验表明，我们的方法可以在多种任务上提高不同模型的性能。此外，我们还提供了对 RaR 和 CoT 的比较，从理论和实际角度出发，以便更好地评估 LLM 的能力。我们的工作不仅可以有效地提高 LLM 性能，还可以为 LLM 评估提供新的思路。数据和代码可以在 GitHub 上找到：https://github.com/uclaml/Rephrase-and-Respond。
</details></li>
</ul>
<hr>
<h2 id="JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction"><a href="#JPAVE-A-Generation-and-Classification-based-Model-for-Joint-Product-Attribute-Prediction-and-Value-Extraction" class="headerlink" title="JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction"></a>JPAVE: A Generation and Classification-based Model for Joint Product Attribute Prediction and Value Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04196">http://arxiv.org/abs/2311.04196</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongfendeng/jpave">https://github.com/zhongfendeng/jpave</a></li>
<li>paper_authors: Zhongfen Deng, Hao Peng, Tao Zhang, Shuaiqi Liu, Wenting Zhao, Yibo Wang, Philip S. Yu</li>
<li>for: 这篇论文的目的是提出一种基于多任务学习的产品属性值提取模型，以解决电子商务中产品搜索和推荐等下游应用中的产品属性值提取问题。</li>
<li>methods: 该模型使用了一种叫做JPAVE的多任务学习模型，包括产品值生成&#x2F;分类和属性预测。该模型不需要值的序列位置信息，可以在不同的购物平台上适应不同的文本结构和风格。另外，模型还使用了复制机制和价值注意模块，以解决数据不一致问题。</li>
<li>results: 实验结果表明，JPAVE模型在一个公共数据集上表现出色，比强基elines表现出优异性和泛化能力，并且在面对新的值时具有Zero-shot能力。<details>
<summary>Abstract</summary>
Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation. Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing. This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style. They also have limited zero-shot ability to new values. In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text. Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text. Besides, two variants of our model are designed for open-world and closed-world scenarios. In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values. Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI"><a href="#Selective-Visual-Representations-Improve-Convergence-and-Generalization-for-Embodied-AI" class="headerlink" title="Selective Visual Representations Improve Convergence and Generalization for Embodied AI"></a>Selective Visual Representations Improve Convergence and Generalization for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04193">http://arxiv.org/abs/2311.04193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ainaz Eftekhar, Kuo-Hao Zeng, Jiafei Duan, Ali Farhadi, Ani Kembhavi, Ranjay Krishna</li>
<li>for: 这个论文旨在提高embodied AI模型中的视觉处理，使其更加灵活和有效。</li>
<li>methods: 这篇论文提出了一种基于小型学习代码库模块的方法，用于过滤视觉刺激，以便实现更好的任务目标导航和物体移动。</li>
<li>results: 实验表明，该方法可以在5个 benchmark中达到顶尖性能，并且在不同的 simulate环境中进行适应和泛化。代码和预训练模型可以在项目网站（<a target="_blank" rel="noopener" href="https://embodied-codebook.github.io)上获得./">https://embodied-codebook.github.io）上获得。</a><details>
<summary>Abstract</summary>
Embodied AI models often employ off the shelf vision backbones like CLIP to encode their visual observations. Although such general purpose representations encode rich syntactic and semantic information about the scene, much of this information is often irrelevant to the specific task at hand. This introduces noise within the learning process and distracts the agent's focus from task-relevant visual cues. Inspired by selective attention in humans-the process through which people filter their perception based on their experiences, knowledge, and the task at hand-we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach induces a task-conditioned bottleneck using a small learnable codebook module. This codebook is trained jointly to optimize task reward and acts as a task-conditioned selective filter over the visual observation. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and their representations retain task-relevant information like target object recognition while ignoring superfluous information about other objects. Code and pretrained models are available at our project website: https://embodied-codebook.github.io.
</details>
<details>
<summary>摘要</summary>
人工智能模型经常使用可购买的视觉背bone如CLIP来编码其视觉观察。尽管这些通用的表征编码场景中的语言和Semantic信息，但这些信息通常对特定任务无关，这会在学习过程中引入噪音并让机器人的注意力分散到不重要的视觉征。 Drawing inspiration from human selective attention, we introduce a parameter-efficient approach to filter visual stimuli for embodied AI. Our approach uses a small learnable codebook module to induce a task-conditioned bottleneck, which is trained jointly to optimize task reward. This codebook acts as a task-conditioned selective filter over the visual observation, allowing the agent to focus on task-relevant visual cues. Our experiments showcase state-of-the-art performance for object goal navigation and object displacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR, and ManipulaTHOR. The filtered representations produced by the codebook are also able to generalize better and converge faster when adapted to other simulation environments such as Habitat. Our qualitative analyses show that agents explore their environments more effectively and retain task-relevant information like target object recognition while ignoring superfluous information about other objects. 我们的代码和预训练模型可以在我们项目网站（https://embodied-codebook.github.io）上获得。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter"><a href="#Spatio-Temporal-Anomaly-Detection-with-Graph-Networks-for-Data-Quality-Monitoring-of-the-Hadron-Calorimeter" class="headerlink" title="Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter"></a>Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality Monitoring of the Hadron Calorimeter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04190">http://arxiv.org/abs/2311.04190</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mulugeta Weldezgina Asres, Christian Walter Omlin, Long Wang, David Yu, Pavel Parygin, Jay Dittmann, Georgia Karapostoli, Markus Seidel, Rosamaria Venditti, Luka Lambrecht, Emanuele Usai, Muhammad Ahmad, Javier Fernandez Menendez, Kaori Maeshima, the CMS-HCAL Collaboration</li>
<li>for: 这个论文是为了研究一种基于三维干扰图数据的半监督空间时间异常检测方法，以便在CMS实验中实时监测加速器中的物理凝聚器读取通道。</li>
<li>methods: 这个方法使用了卷积神经网络和图神经网络来学习干扰图中的本地空间特征，以及全部backend电路和仪器盒的共享连接和住宿特征。它还使用了循环神经网络来捕捉干扰图中的时间演化。</li>
<li>results: 该方法在使用LHC Run-2的Collision数据集上验证了多种通道故障类型的准确率，并在CMS核心生产系统中实现了生产级别的准确率。此外，该方法还与其他参考模型进行了性能比较，以证明其在实际应用中的潜在优势。<details>
<summary>Abstract</summary>
The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN. It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss. In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM. We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively. Recurrent neural networks capture the temporal evolution of the extracted spatial features. We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets. The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL. We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system.
</details>
<details>
<summary>摘要</summary>
大型强子对撞器（LHC）的强子物理读取通道（HCAL）的某些检测问题，CMS实验室使用在线数据质量监测（DQM）系统来迅速发现和诊断数据质量问题，以避免数据质量损失。在这项研究中，我们提出了一种半监督的三维尺度卡住强度图数据的异常检测（AD）监测系统，使用 convolutional neural network（CNN）和图 neural network（GraphNN）来学习检测器中的本地空间特征，以及通信后端电路和仪器盒的共享连接关系。另外，使用循环 нейрон网络（RNN）来捕捉尺度图数据中的时间演化特征。我们在LHC Run-2的碰撞数据集上验证了提案的AD系统的准确性，并达到了生产级别的准确率。此外，我们还对一些参考模型进行了评估，以示出提案的系统在异常检测方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="On-Leakage-in-Machine-Learning-Pipelines"><a href="#On-Leakage-in-Machine-Learning-Pipelines" class="headerlink" title="On Leakage in Machine Learning Pipelines"></a>On Leakage in Machine Learning Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04179">http://arxiv.org/abs/2311.04179</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Leonard Sasse, Eliana Nicolaisen-Sobesky, Juergen Dukart, Simon B. Eickhoff, Michael Götz, Sami Hamdan, Vera Komeyer, Abhijit Kulkarni, Juha Lahnakoski, Bradley C. Love, Federico Raimondo, Kaustubh R. Patil</li>
<li>for: 提高机器学习（ML）ipeline的设计、实现和评估，以避免泄漏和过估性能。</li>
<li>methods: 通过实际示例，描述了机器学习管道中可能出现的多种泄漏类型，并对它们进行了全面的概述和讨论。</li>
<li>results: 通过描述和分析不同类型的泄漏，本文旨在扩大机器学习管道中泄漏的理解，以避免因设计、实现和评估不当而导致的负面影响。<details>
<summary>Abstract</summary>
Machine learning (ML) provides powerful tools for predictive modeling. ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare. However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data. This can have severe negative financial and societal implications. Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines. Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation"><a href="#Enhancing-LLM-Intelligence-with-ARM-RAG-Auxiliary-Rationale-Memory-for-Retrieval-Augmented-Generation" class="headerlink" title="Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation"></a>Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for Retrieval Augmented Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04177">http://arxiv.org/abs/2311.04177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Melz</li>
<li>for: 这篇论文旨在探讨如何提高语言模型的智能水平，并研究一种名为 Retrieval Augmented Generation（RAG）的方法。</li>
<li>methods: 该论文使用了一种名为 Auxiliary Rationale Memory（ARM）的系统，该系统通过记忆并回忆问题解决方法来学习。</li>
<li>results: 研究发现，通过存储并回忆解释链可以提高grade-school math问题的解决性能。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g., (Bubeck et al., 2023)) on modern LLMs have shown that they are capable of performing amazing tasks typically necessitating human-level intelligence. However, unlike humans, frozen LLMs do not improve over time; they neither acquire new knowledge nor learn from their successes or failures. Some approaches to improving the intelligence of LLMs include fine-tuning models based on problem-solving performance (Zelikman et al., 2022), and building bigger and more sophisticated models (Bubeck et al., 2023). However, these methods have the drawback of requiring substantial data and computational resources to retrain existing models. In this paper, we explore the use of Retrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to improve problem-solving performance. We propose ARM-RAG (Auxiliary Rationale Memory for Retrieval Augmented Generation), a system that learns from its successes without incurring high training costs. We demonstrate that the storage and subsequent retrieval of reasoning chains have a positive influence on performance in grade-school math problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison"><a href="#HADES-Fast-Singularity-Detection-with-Local-Measure-Comparison" class="headerlink" title="HADES: Fast Singularity Detection with Local Measure Comparison"></a>HADES: Fast Singularity Detection with Local Measure Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04171">http://arxiv.org/abs/2311.04171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Uzu Lim, Harald Oberhauser, Vidit Nanda</li>
<li>for: 检测数据中的点 singularity</li>
<li>methods: 使用kernel好好测试，比较快速和扩展性良好</li>
<li>results: 在synthetic数据、路网数据、分子结构空间和图像数据中 correctly detect singularities with high probability<details>
<summary>Abstract</summary>
We introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.
</details>
<details>
<summary>摘要</summary>
我团队 introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm uses a kernel goodness-of-fit test, which makes it much faster and more scalable than existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.Here's the translation in Traditional Chinese:我们团队 introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm uses a kernel goodness-of-fit test, which makes it much faster and more scalable than existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data.
</details></li>
</ul>
<hr>
<h2 id="Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization"><a href="#Outliers-with-Opposing-Signals-Have-an-Outsized-Effect-on-Neural-Network-Optimization" class="headerlink" title="Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization"></a>Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04163">http://arxiv.org/abs/2311.04163</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elan Rosenfeld, Andrej Risteski</li>
<li>for: 这paper探讨了神经网络优化中新现象，即深度和自然数据中特殊重 tailed 结构之间的交互作用。</li>
<li>methods: 该 paper 使用了实验和理论分析方法，包括对训练数据中对抗信号的研究和一个简单的线性网络的 teoretic 分析。</li>
<li>results: 该 paper 发现了一种新的训练过程 Dynamic 的特点，即在训练过程中慢慢地增加精度，然后快速增加损失，最终导致损失快速增加。此外，paper 还发现了一些与这种现象相关的现象，如泛化能力和简洁偏好。<details>
<summary>Abstract</summary>
We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data. Our result offers intuitive explanations for several previously reported observations about network training dynamics. In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization.   Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions. Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes. We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior. We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior which we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.
</details>
<details>
<summary>摘要</summary>
Experiments show that paired groups of outliers in the training data with strong opposing signals can significantly influence the optimization process. These outliers cause early optimization to enter a narrow valley that carefully balances the opposing groups, leading to rapid loss oscillations between high on one group and then the other, until the overall loss spikes. We identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior.We also provide a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior that we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD.
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis"><a href="#A-Simple-Interpretable-Transformer-for-Fine-Grained-Image-Classification-and-Analysis" class="headerlink" title="A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis"></a>A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04157">http://arxiv.org/abs/2311.04157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imageomics/intr">https://github.com/imageomics/intr</a></li>
<li>paper_authors: Dipanjyoti Paul, Arpita Chowdhury, Xinqi Xiong, Feng-Ju Chang, David Carlyn, Samuel Stevens, Kaiya Provost, Anuj Karpatne, Bryan Carstens, Daniel Rubenstein, Charles Stewart, Tanya Berger-Wolf, Yu Su, Wei-Lun Chao</li>
<li>for: 这 paper 的目的是使 Image Classification 更加可读性。</li>
<li>methods: 该 paper 使用 Transformer encoder-decoder 和 DETR 的 inspirations，实现了一种名为 INterpretable TRansformer (INTR) 的方法。INTR 通过学习每个类别的特有的“查询”，让每个类别在图像中搜索自己的特征。</li>
<li>results: 该 paper 的实验结果表明，INTR 可以帮助每个类别强调自己的特征，并且通过“多头”横规比较，可以识别不同类别的“特征”。这使得 INTR 非常适合细腻的分类和分析。<details>
<summary>Abstract</summary>
We present a novel usage of Transformers to make image classification interpretable. Unlike mainstream classifiers that wait until the last fully-connected layer to incorporate class information to make predictions, we investigate a proactive approach, asking each class to search for itself in an image. We realize this idea via a Transformer encoder-decoder inspired by DEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each class) as input to the decoder, enabling each class to localize its patterns in an image via cross-attention. We name our approach INterpretable TRansformer (INTR), which is fairly easy to implement and exhibits several compelling properties. We show that INTR intrinsically encourages each class to attend distinctively; the cross-attention weights thus provide a faithful interpretation of the prediction. Interestingly, via ``multi-head'' cross-attention, INTR could identify different ``attributes'' of a class, making it particularly suitable for fine-grained classification and analysis, which we demonstrate on eight datasets. Our code and pre-trained model are publicly accessible at https://github.com/Imageomics/INTR.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的应用方法，使用转换器来帮助图像分类变得可读性更高。与主流分类器不同，我们在最后一层完全连接层之前就将类信息integrated到预测中，而我们在DEtection TRansformer（DETR）的Encoder-Decoder结构下实现了这个想法。我们在decoder中学习了每个类的``特有''查询（每个类都有一个），使得每个类可以通过交叉关注来找到自己的图像模式。我们称之为INterpretable TRansformer（INTR），它较容易实现并且具有一些吸引人的性能。我们表明，INTR会自然地让每个类各自听取，因此交叉关注权重可以准确地解释预测结果。另外，通过``多头''交叉关注，INTR可以识别不同的``特征''，使其特别适用于细致分类和分析，我们在八个数据集上进行了证明。我们的代码和预训练模型可以在https://github.com/Imageomics/INTR上获取。
</details></li>
</ul>
<hr>
<h2 id="Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach"><a href="#Contactless-Fingerprint-Biometric-Anti-Spoofing-An-Unsupervised-Deep-Learning-Approach" class="headerlink" title="Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach"></a>Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04148">http://arxiv.org/abs/2311.04148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Banafsheh Adami, Nima Karimian</li>
<li>For: 这个论文的目的是提出一种新的反射式识别方法，以提高无接触指纹识别系统的安全性和可靠性。* Methods: 这个论文使用了一种新的无接触指纹识别方法， combining an unsupervised autoencoder with a convolutional block attention module。* Results: 这个方法在测试阶段对各种表现攻击样本进行评估，并达到了0.96%的BPCER和1.6%的APCER。<details>
<summary>Abstract</summary>
Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively. However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities. Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model. Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively. We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods. Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase. It is then evaluated against various types of presentation attack images in the testing phase. The scheme we proposed has achieved an average BPCER of 0.96\% with an APCER of 1.6\% for presentation attacks involving various types of spoofed samples.
</details>
<details>
<summary>摘要</summary>
无接触指纹识别技术可提供更高水平的用户体验和更有效地解决卫生问题。然而，它也更容易受到展示攻击，如照片纸、打印机纸和各种显示攻击，这使其在生物特征系统中实现更加困难。已有限的研究被进行在无接触指纹系统中的展示攻击，而这些研究又遇到了总结和扩展的问题，因为训练模型时需要使用真实样本和攻击样本。这种方法虽然看上去有前途，但缺乏对未看到的攻击的处理能力，这是开发PAD方法的关键因素。我们提出了一种创新的反射攻击方法，该方法结合了无监督 autoencoder 和卷积束注意模块来解决现有方法的局限性。我们的模型在训练阶段不曝光于任何假样本，然后在测试阶段进行了对各种展示攻击样本的评估。我们的方案实现了平均拒绝率0.96%， False Positive Rate 1.6%。
</details></li>
</ul>
<hr>
<h2 id="Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers"><a href="#Locating-Cross-Task-Sequence-Continuation-Circuits-in-Transformers" class="headerlink" title="Locating Cross-Task Sequence Continuation Circuits in Transformers"></a>Locating Cross-Task Sequence Continuation Circuits in Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04131">http://arxiv.org/abs/2311.04131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Lan, Fazl Barez</li>
<li>for: 本研究旨在探讨transformer模型在语言任务中表现出色，但其复杂的架构使其难以解释。现有研究把transformer模型转化为可读的人类可读表示，称为Circuit。本文继续这项研究，对同类序列续写任务进行分析和比较Circuit。</li>
<li>methods: 本研究使用了Circuit分析技术，对同类序列续写任务进行分析和比较。通过分析，我们发现了检测序列成员和预测下一个序列成员的关键子Circuit，以及这些子Circuit在不同序列类型下的共同计算结构。</li>
<li>results: 本研究发现，semantically相关的序列归于共同的Circuit子图，具有相同的角色。通过文本分析技术，我们发现了预测下一个序列成员的关键因素，并且在不同序列类型下的模型行为预测得到了改进。总之，这项研究为建立更加稳定、对接和可解释的语言模型提供了重要的机制理解。<details>
<summary>Abstract</summary>
While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust, aligned, and interpretable language models.
</details>
<details>
<summary>摘要</summary>
transformer 模型在语言任务中表现出了强大的能力，但它们的复杂的架构使得它们难以解释。 recent work 通过将 transformer 模型转换成可读的人类可读的表示，即 circuit，来实现算法功能。 我们在这个研究中扩展这项工作，对同类序列续写任务进行了分析和比较，包括增加数字、数字词和月份。通过应用Circuit分析技术，我们已经发现了定义序列成员的关键子circuit，以及预测下一个序列成员的子circuit。我们的分析发现，semantically 相关的序列都是通过共享的circuit subgraphs来实现，这些subgraphs具有相似的角色。总之，通过记录模型行为的共同计算结构，我们可以更好地预测模型的行为，发现错误，并进行更安全的编辑过程。这种机制的理解是建立更加robust、aligned和可解释的语言模型的重要一步。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Safety-Vulnerabilities-of-Large-Language-Models"><a href="#Unveiling-Safety-Vulnerabilities-of-Large-Language-Models" class="headerlink" title="Unveiling Safety Vulnerabilities of Large Language Models"></a>Unveiling Safety Vulnerabilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04124">http://arxiv.org/abs/2311.04124</a></li>
<li>repo_url: None</li>
<li>paper_authors: George Kour, Marcel Zalmanovici, Naama Zwerdling, Esther Goldbraich, Ora Nova Fandina, Ateret Anaby-Tavor, Orna Raz, Eitan Farchi</li>
<li>for: 该论文旨在提供一个含有攻击示例的数据集，以检测大型自然语言模型的潜在危险或不适应 responses。</li>
<li>methods: 该论文使用了特有的 clustering 技术，对模型的输入 semantic areas 进行自动识别和命名，以便更好地评估模型的弱点和可靠性。</li>
<li>results: 该论文通过分析模型对含有攻击示例的数据集的应答，评估了模型的安全性和可靠性。<details>
<summary>Abstract</summary>
As large language models become more prevalent, their possible harmful or inappropriate responses are a cause for concern. This paper introduces a unique dataset containing adversarial examples in the form of questions, which we call AttaQ, designed to provoke such harmful or inappropriate responses. We assess the efficacy of our dataset by analyzing the vulnerabilities of various models when subjected to it. Additionally, we introduce a novel automatic approach for identifying and naming vulnerable semantic regions - input semantic areas for which the model is likely to produce harmful outputs. This is achieved through the application of specialized clustering techniques that consider both the semantic similarity of the input attacks and the harmfulness of the model's responses. Automatically identifying vulnerable semantic regions enhances the evaluation of model weaknesses, facilitating targeted improvements to its safety mechanisms and overall reliability.
</details>
<details>
<summary>摘要</summary>
如大语言模型日益普遍，它们可能的危险或不适应答也成为了关心的话题。这篇论文提出了一个唯一的数据集，称为AttaQ，这些问题的形式是针对模型引起危险或不适应答的攻击数据集。我们通过对不同模型在这些数据集上的抵抗性进行分析，评估了我们的数据集的有效性。此外，我们还提出了一种新的自动化方法，可以自动地标识和命名模型容易受攻击的语义区域，即输入语义区域，使得模型可能生成危险输出的输入。这种方法基于特殊的聚类技术，考虑了输入攻击的语义相似性和模型的危险响应。自动地标识容易受攻击的语义区域，可以提高模型的评估，推进模型的安全机制和总可靠性的改进。
</details></li>
</ul>
<hr>
<h2 id="Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion"><a href="#Multitask-Multimodal-Prompted-Training-for-Interactive-Embodied-Task-Completion" class="headerlink" title="Multitask Multimodal Prompted Training for Interactive Embodied Task Completion"></a>Multitask Multimodal Prompted Training for Interactive Embodied Task Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04067">http://arxiv.org/abs/2311.04067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georgios Pantazopoulos, Malvina Nikandrou, Amit Parekh, Bhathiya Hemanthage, Arash Eshghi, Ioannis Konstas, Verena Rieser, Oliver Lemon, Alessandro Suglia</li>
<li>for: 这个研究是为了解决视力和语言（VL）模型在实时和肢体任务中的问题，包括将语言与动作和观察之间的关联和语言对象化。</li>
<li>methods: 这个研究提出了一个具有多modal的代理人（EMMA），它是一个统一的encoder-decoder模型，可以理解图像和路径，并将动作预测设置为多modal的文本生成。</li>
<li>results: EMMA在多个VL标准库上表现不俗，并在Dialog-guided Task Completion（DTC）标准上设置新的州态艺术（36.81%成功率）。<details>
<summary>Abstract</summary>
Interactive and embodied tasks pose at least two fundamental challenges to existing Vision & Language (VL) models, including 1) grounding language in trajectories of actions and observations, and 2) referential disambiguation. To tackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a unified encoder-decoder model that reasons over images and trajectories, and casts action prediction as multimodal text generation. By unifying all tasks as text generation, EMMA learns a language of actions which facilitates transfer across tasks. Different to previous modular approaches with independently trained components, we use a single multitask model where each task contributes to goal completion. EMMA performs on par with similar models on several VL benchmarks and sets a new state-of-the-art performance (36.81% success rate) on the Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided agents in the Alexa Arena
</details>
<details>
<summary>摘要</summary>
现有的视觉语言（VL）模型面临两个基本挑战：1）将语言与动作轨迹和观察相关联，2）确定参照扩展。为解决这些挑战，我们提议一个具有多模态特征的embodied multimodal agent（EMMA）：一个统一编码解码模型，可以理解图像和轨迹，并将动作预测作为多Modal文本生成。通过将所有任务统一为文本生成，EMMA学习了一种动作语言，该语言可以促进任务转移。不同于之前的模块化方法，我们使用单一多任务模型，其中每个任务启发完成目标。EMMA在多个VL标准准测上与同类模型一样好，并在Dialog-guided Task Completion（DTC）标准上达到了新的州OF-THE-ART性能（36.81%成功率），这是评估对话引导者在Alexa Arena的一个 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Can-CLIP-Help-Sound-Source-Localization"><a href="#Can-CLIP-Help-Sound-Source-Localization" class="headerlink" title="Can CLIP Help Sound Source Localization?"></a>Can CLIP Help Sound Source Localization?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04066">http://arxiv.org/abs/2311.04066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Sooyoung Park, Arda Senocak, Joon Son Chung</li>
<li>for: 本研究用于扩展CLIP模型到声音来源Localization领域，并使用预训练的图像文本模型来提高声音地标化的精度和效率。</li>
<li>methods: 我们使用预训练CLIP模型，并对其进行特殊的修改，以便在没有文本输入的情况下，通过音频视频对应关系来生成声音地标。我们还提出了一种抽象音频信号为Token的方法，以便将其与CLIP模型的文本编码器进行对应。</li>
<li>results: 我们的方法可以生成更加完整和紧凑的声音地标图，并在多个实验中胜过了现有的方法，提高了声音地标的精度和效率。<details>
<summary>Abstract</summary>
Large-scale pre-trained image-text models demonstrate remarkable versatility across diverse tasks, benefiting from their robust representational capabilities and effective multimodal alignment. We extend the application of these models, specifically CLIP, to the domain of sound source localization. Unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.
</details>
<details>
<summary>摘要</summary>
大规模预训练图像文本模型在多种任务上表现出了惊人的多样性，受益于其强大的表示能力和有效的多Modal对应。我们将这些模型，特别是CLIP，应用到声源localization领域。 unlike conventional approaches, we employ the pre-trained CLIP model without explicit text input, relying solely on the audio-visual correspondence. To this end, we introduce a framework that translates audio signals into tokens compatible with CLIP's text encoder, yielding audio-driven embeddings. By directly using these embeddings, our method generates audio-grounded masks for the provided audio, extracts audio-grounded image features from the highlighted regions, and aligns them with the audio-driven embeddings using the audio-visual correspondence objective. Our findings suggest that utilizing pre-trained image-text models enable our model to generate more complete and compact localization maps for the sounding objects. Extensive experiments show that our method outperforms state-of-the-art approaches by a significant margin.Here is the word-for-word translation of the text into Simplified Chinese:大规模预训练图像文本模型在多种任务上表现出了惊人的多样性，受益于其强大的表示能力和有效的多Modal对应。我们将这些模型，特别是CLIP，应用到声源localization领域。与传统方法不同，我们使用预训练CLIP模型无需文本输入，仅仅利用声音-视频对应。为此，我们提出了一个框架，将audio信号转换为CLIP文本编码器兼容的token，生成audio驱动的嵌入。通过直接使用这些嵌入，我们的方法生成了声音驱动的面积映射，提取了声音驱动的图像特征从高亮区域，并将其与声音驱动的嵌入进行对应使用声音-视频对应目标。我们的发现表明，利用预训练图像文本模型可以使我们的模型生成更加完整和更加紧凑的localization图。广泛的实验表明，我们的方法在比较任务上高效地超越了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="Multi-View-Causal-Representation-Learning-with-Partial-Observability"><a href="#Multi-View-Causal-Representation-Learning-with-Partial-Observability" class="headerlink" title="Multi-View Causal Representation Learning with Partial Observability"></a>Multi-View Causal Representation Learning with Partial Observability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04056">http://arxiv.org/abs/2311.04056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dingling Yao, Danru Xu, Sébastien Lachapelle, Sara Magliacane, Perouz Taslakian, Georg Martius, Julius von Kügelgen, Francesco Locatello</li>
<li>for: 研究同时观察到的视图中学习表示的唯一性，包括不同数据模式的同时观察。</li>
<li>methods: 使用对准学习和每个视图一个编码器来学习对所有视图中信息的共享，并提供可以判断哪些 latent variable 可以通过简单规则进行标识的图像 критерий。</li>
<li>results:  theoretically 和实验ally  validate 多视图非线性ICA、解耦和 causal 表示学习的扩展和统一，并在不同特殊情况下回归到先前的方法性能。 通过多个部分视图，可以实现更细化的表示，只需要较轻松的假设Conditional observability。<details>
<summary>Abstract</summary>
We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability.
</details>
<details>
<summary>摘要</summary>
我们提出一个统一的框架来研究同时观察到的视图中学习的表示性的可 identificability，例如不同数据模式。我们允许部分观察的设置，在每个视图中每个下标变量的非线性混合中包含一些基本的 latent variable。我们证明了所有视图集的信息可以通过对冲学学习和单个编码器来学习，并且可以到达一个平滑的 bijection。我们还提供了一些图形标准，可以通过简单的规则来判断 latent variable 的可 identificability。我们的总框架和理论结果将多视图非线性 ICAR、解体和 causal 表示学习的前期工作统一和扩展。我们在数字、图像和多模式数据集上进行了实验 validate 我们的声明，并且表明了特殊情况下的先前方法的性能可以被回归。总之，我们发现了多个部分视图可以为我们提供更细化的表示，在一般更轻松的部分可见性假设下。
</details></li>
</ul>
<hr>
<h2 id="Causal-Discovery-Under-Local-Privacy"><a href="#Causal-Discovery-Under-Local-Privacy" class="headerlink" title="Causal Discovery Under Local Privacy"></a>Causal Discovery Under Local Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04037">http://arxiv.org/abs/2311.04037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rūta Binkytė, Carlos Pinzón, Szilvia Lestyán, Kangsoo Jung, Héber H. Arcolezi, Catuscia Palamidessi</li>
<li>For: 本研究旨在探讨了本地均勋 privacy  Mechanism 在 causal discovery 任务中的选择。* Methods: 本研究考虑了多种常见的本地均勋 privacy 机制，并对这些机制在 causal discovery 任务中的准确性和隐私提供了比较。* Results: 研究发现，不同的本地均勋 privacy 机制对 causal discovery 任务中的准确性和隐私提供了不同的贡献。 这些结果可以帮助研究人员和实践者在进行本地私有 causal discovery 时进行选择。<details>
<summary>Abstract</summary>
Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal discovery. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery.
</details>
<details>
<summary>摘要</summary>
diffe革� Privacy 是一种广泛采用的框架，用于保护数据提供者在数据集中的敏感信息。它基于数据存储和处理服务器和数据consumer之间的控制随机噪声的应用。本地 diffe革� Privacy 是一种变体，允许数据提供者本地应用随机噪声机制，以提供隐私保护。因此，它可以在服务器或数据收集者不可靠的情况下提供保护。然而，随机噪声的引入不可避免地影响数据的用户性，特别是对数据组件之间的相关性进行扭曲。这种扭曲可能对 causal 发现任务产生负面影响。在这篇论文中，我们考虑了多种知名的本地随机隐私机制，并比较这些机制提供的隐私和 causal 结构产生算法应用于数据做隐私处理后的准确性的负面关系。我们的分析提供了选择合适的本地随机隐私协议的有价值信息，以帮助研究者和实践者进行本地私人 causal 发现。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-HPO-on-AutoML-Forecasting-Ensembles"><a href="#Impact-of-HPO-on-AutoML-Forecasting-Ensembles" class="headerlink" title="Impact of HPO on AutoML Forecasting Ensembles"></a>Impact of HPO on AutoML Forecasting Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04034">http://arxiv.org/abs/2311.04034</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Hoffmann</li>
<li>for: 这 paper 是为了研究如何使用不同的 Hyperparameter Optimization 策略来提高深度学习模型的预测性能。</li>
<li>methods: 这 paper 使用了一个多元预测集合，包括 MQ-CNN、DeepAR、Prophet、NPTS、ARIMA 和 ETS，来预测不同的问题。它还研究了在这些深度学习模型中添加不同的 Hyperparameter Optimization 策略的影响。</li>
<li>results: 这 paper 的结果表明，在这种 setup 中添加 Hyperparameter Optimization 可以提高预测性能，最终组合的设置比基eline 集合 ohne HPO 提高了9.9%的准确率，并且降低了65.8%的总体集合延迟时间。这个改进基于对不同的 ensemble pipeline 和 tuning 策略的实验分析，包括 Bayesian Optimization 和 Hyperband。最终的组合还超过了商业 AutoML 预测解决方案 Amazon Forecast，具有3.5%的较低的错误率和16.0%的较低的总体集合延迟时间。<details>
<summary>Abstract</summary>
A forecasting ensemble consisting of a diverse range of estimators for both local and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet, NPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems. This paper delves into the aspect of adding different hyperparameter optimization strategies to the deep learning models in such a setup (DeepAR and MQ-CNN), exploring the trade-off between added training cost and the increase in accuracy for different configurations. It shows that in such a setup, adding hyperparameter optimization can lead to performance improvements, with the final setup having a 9.9 % percent accuracy improvement with respect to the avg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 % increase in end-to-end ensemble latency. This improvement is based on an empirical analysis of combining the ensemble pipeline with different tuning strategies, namely Bayesian Optimisation and Hyperband and different configurations of those strategies. In the final configuration, the proposed combination of ensemble learning and HPO outperforms the state of the art commercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower error and 16.0 % lower end-to-end ensemble latency.
</details>
<details>
<summary>摘要</summary>
一个包含多种估计器的预测集群，包括MQ-CNN、DeepAR、Prophet、NPTS、ARIMA和ETS，可以用于解决多种问题的预测。这篇论文探讨了在深度学习模型中添加不同的超参数优化策略的方面（DeepAR和MQ-CNN），探讨了增加训练成本和准确性提升的交互关系。结果显示，在这种设置下，添加超参数优化可以提高表现，最终设置与avg-wQL相比增加9.9%的准确性，同时增加65.8%的终端集群延迟。这种提升基于对 ensemble 管道与不同的调试策略（bayesian 优化和 Hyperband）的实际分析。在最终配置下，提案的集群学习和HPO组合超过了商业 AutoML 预测解决方案Amazon Forecast，具有3.5%更低的错误率和16.0%更低的终端集群延迟。
</details></li>
</ul>
<hr>
<h2 id="Expressivity-of-ReLU-Networks-under-Convex-Relaxations"><a href="#Expressivity-of-ReLU-Networks-under-Convex-Relaxations" class="headerlink" title="Expressivity of ReLU-Networks under Convex Relaxations"></a>Expressivity of ReLU-Networks under Convex Relaxations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04015">http://arxiv.org/abs/2311.04015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Baader, Mark Niklas Müller, Yuhao Mao, Martin Vechev</li>
<li>for: 这篇论文探讨了使用 convex relaxations 训练和证明神经网络的可证明安全性。</li>
<li>methods: 这篇论文使用了多种常用的 convex relaxations，包括 IBP relaxation，以研究神经网络可以表示什么样的函数。</li>
<li>results: 研究发现，使用更高级别的 convex relaxations，可以让更多的单变量函数被神经网络精确地表示。同时，使用最精确的单 neuron relaxations，也无法构建多变量、凸、 monotone CPWL 函数被神经网络精确地表示。<details>
<summary>Abstract</summary>
Convex relaxations are a key component of training and certifying provably safe neural networks. However, despite substantial progress, a wide and poorly understood accuracy gap to standard networks remains, raising the question of whether this is due to fundamental limitations of convex relaxations. Initial work investigating this question focused on the simple and widely used IBP relaxation. It revealed that some univariate, convex, continuous piecewise linear (CPWL) functions cannot be encoded by any ReLU network such that its IBP-analysis is precise. To explore whether this limitation is shared by more advanced convex relaxations, we conduct the first in-depth study on the expressive power of ReLU networks across all commonly used convex relaxations. We show that: (i) more advanced relaxations allow a larger class of univariate functions to be expressed as precisely analyzable ReLU networks, (ii) more precise relaxations can allow exponentially larger solution spaces of ReLU networks encoding the same functions, and (iii) even using the most precise single-neuron relaxations, it is impossible to construct precisely analyzable ReLU networks that express multivariate, convex, monotone CPWL functions.
</details>
<details>
<summary>摘要</summary>
凸relaxation是训练和证明可靠神经网络的关键组件。然而，尽管取得了重要进步，但是仍存在一个宽泛不寻常的准确缺陷，使得是否由凸relaxation的基本限制而导致的问题得到了提出。初期的研究表明，使用IBP relaxation时，一些单变量、凸、连续piecewise线性（CPWL）函数无法被ReLU网络编码，使得其IBP分析不准确。为了探讨这一限制是否适用于更先进的凸relaxation，我们进行了所有常用凸relaxation的深入研究。我们发现了以下结论：1.更先进的relaxation允许更多的单变量函数被ReLU网络编码，并且其IBP分析是precise。2.更精准的relaxation可以让ReLU网络编码的函数空间 exponentially大，而不损失准确性。3. même使用最精准的单 neuron relaxation，无法构建precise的ReLU网络，用于表示多变量、凸、 monotone CPWL函数。
</details></li>
</ul>
<hr>
<h2 id="A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems"><a href="#A-Method-to-Improve-the-Performance-of-Reinforcement-Learning-Based-on-the-Y-Operator-for-a-Class-of-Stochastic-Differential-Equation-Based-Child-Mother-Systems" class="headerlink" title="A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems"></a>A Method to Improve the Performance of Reinforcement Learning Based on the Y Operator for a Class of Stochastic Differential Equation-Based Child-Mother Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04014">http://arxiv.org/abs/2311.04014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Yin, Yi Chen</li>
<li>for: 提高actor-critic基于渐变方程学习控制性能</li>
<li>methods: 引入Y运算符，将儿童系统的随机性 интеGRATE INTO critic网络的损失函数中，提高RL算法的控制性能</li>
<li>results: Y运算符可以快速和高效地解决优化控制问题，在线性和非线性数学示例中显示出增强的性能 compared to 现有方法 post convergence。<details>
<summary>Abstract</summary>
This paper introduces a novel operator, termed the Y operator, to elevate control performance in Actor-Critic(AC) based reinforcement learning for systems governed by stochastic differential equations(SDEs). The Y operator ingeniously integrates the stochasticity of a class of child-mother system into the Critic network's loss function, yielding substantial advancements in the control performance of RL algorithms.Additionally, the Y operator elegantly reformulates the challenge of solving partial differential equations for the state-value function into a parallel problem for the drift and diffusion functions within the system's SDEs.A rigorous mathematical proof confirms the operator's validity.This transformation enables the Y Operator-based Reinforcement Learning(YORL) framework to efficiently tackle optimal control problems in both model-based and data-driven systems.The superiority of YORL is demonstrated through linear and nonlinear numerical examples showing its enhanced performance over existing methods post convergence.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种新的运算符，称之为Y运算符，用于提高基于actor-critic(AC)的激励学习控制性能，适用于具有渐变方程(SDEs)的系统。Y运算符巧妙地将儿系统中的随机性 интеGRATE到批处网络的损失函数中，从而实现了RL算法的控制性能的显著提高。此外，Y运算符也美化地将解决部分梯度方程的问题转化为在SDEs中的并行问题。一个严格的数学证明证明了运算符的有效性。这种转换使得基于Y运算符的激励学习框架(YORL)可以高效地解决模型基于和数据驱动的优化控制问题。在线性和非线性数字例子中，YORL表现出了与现有方法相比的提高。
</details></li>
</ul>
<hr>
<h2 id="The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond"><a href="#The-Energy-Prediction-Smart-Meter-Dataset-Analysis-of-Previous-Competitions-and-Beyond" class="headerlink" title="The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond"></a>The Energy Prediction Smart-Meter Dataset: Analysis of Previous Competitions and Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04007">http://arxiv.org/abs/2311.04007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Direnc Pekaslan, Jose Maria Alonso-Moral, Kasun Bandara, Christoph Bergmeir, Juan Bernabe-Moreno, Robert Eigenmann, Nils Einecke, Selvi Ergen, Rakshitha Godahewa, Hansika Hewamalage, Jesus Lago, Steffen Limmer, Sven Rebhan, Boris Rabinovich, Dilini Rajapasksha, Heda Song, Christian Wagner, Wenlong Wu, Luis Magdalena, Isaac Triguero</li>
<li>for: 这篇论文探讨了基于智能计量器数据的能源预测技术挑战，主要关注2020年IEEE计算智能学会（IEEE-CIS）技术挑战和2021年IEEE国际 Conference on Fuzzy Systems（FUZZ-IEEE）的跟进挑战。</li>
<li>methods: 这篇论文使用了智能计量器数据进行实际世界的数据集分析，并提出了一些解决方案，包括精准的能源消耗预测和解释性能量预测。</li>
<li>results: 这篇论文通过分析智能计量器数据集，发现了一些挑战和解决方案，并提出了一些新的应用前景，如能源分解、需求约束计划和行为改变等。<details>
<summary>Abstract</summary>
This paper presents the real-world smart-meter dataset and offers an analysis of solutions derived from the Energy Prediction Technical Challenges, focusing primarily on two key competitions: the IEEE Computational Intelligence Society (IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in 2020 (named EP) and its follow-up challenge at the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These competitions focus on accurate energy consumption forecasting and the importance of interpretability in understanding the underlying factors. The challenge aims to predict monthly and yearly estimated consumption for households, addressing the accurate billing problem with limited historical smart meter data. The dataset comprises 3,248 smart meters, with varying data availability ranging from a minimum of one month to a year. This paper delves into the challenges, solutions and analysing issues related to the provided real-world smart meter data, developing accurate predictions at the household level, and introducing evaluation criteria for assessing interpretability. Additionally, this paper discusses aspects beyond the competitions: opportunities for energy disaggregation and pattern detection applications at the household level, significance of communicating energy-driven factors for optimised billing, and emphasising the importance of responsible AI and data privacy considerations. These aspects provide insights into the broader implications and potential advancements in energy consumption prediction. Overall, these competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards the discussion of various aspects such as energy disaggregation, demand response programs or behavioural interventions.
</details>
<details>
<summary>摘要</summary>
The dataset includes 3,248 smart meters with varying data availability, ranging from one month to one year. The paper explores the challenges, solutions, and evaluation criteria for developing accurate predictions at the household level. Additionally, it discusses opportunities for energy disaggregation and pattern detection applications, the significance of communicating energy-driven factors for optimized billing, and the importance of responsible AI and data privacy considerations.These competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards discussions of various aspects such as energy disaggregation, demand response programs, or behavioral interventions. Overall, this paper provides insights into the broader implications and potential advancements in energy consumption prediction.
</details></li>
</ul>
<hr>
<h2 id="Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations"><a href="#Human-AI-Collaboration-in-Thematic-Analysis-using-ChatGPT-A-User-Study-and-Design-Recommendations" class="headerlink" title="Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations"></a>Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study and Design Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03999">http://arxiv.org/abs/2311.03999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixiang Yan, Vanessa Echeverria, Gloria Fernandez Nieto, Yueqiao Jin, Zachari Swiecki, Linxuan Zhao, Dragan Gašević, Roberto Martinez-Maldonado</li>
<li>for: 这个论文旨在探讨研究者与生成人工智能（GenAI）在质量研究中的合作方式，以帮助提高人类-AI协作的效率。</li>
<li>methods: 本研究使用了ChatGPT作为研究者的合作对象，通过对10名质量研究者的用户研究来探讨他们与GenAI的协作方式。</li>
<li>results: 研究发现，ChatGPT可以帮助研究者进行主题分析，提高编码效率，帮助初步数据探索，提供细腻的量化意义，以及帮助非native speaker和非专家理解。然而，研究人员对其可靠性、一致性和广泛acceptance在研究社区的担忧仍然存在。<details>
<summary>Abstract</summary>
Generative artificial intelligence (GenAI) offers promising potential for advancing human-AI collaboration in qualitative research. However, existing works focused on conventional machine-learning and pattern-based AI systems, and little is known about how researchers interact with GenAI in qualitative research. This work delves into researchers' perceptions of their collaboration with GenAI, specifically ChatGPT. Through a user study involving ten qualitative researchers, we found ChatGPT to be a valuable collaborator for thematic analysis, enhancing coding efficiency, aiding initial data exploration, offering granular quantitative insights, and assisting comprehension for non-native speakers and non-experts. Yet, concerns about its trustworthiness and accuracy, reliability and consistency, limited contextual understanding, and broader acceptance within the research community persist. We contribute five actionable design recommendations to foster effective human-AI collaboration. These include incorporating transparent explanatory mechanisms, enhancing interface and integration capabilities, prioritising contextual understanding and customisation, embedding human-AI feedback loops and iterative functionality, and strengthening trust through validation mechanisms.
</details>
<details>
<summary>摘要</summary>
人工智能生成技术（GenAI）在质量研究中具有普遍的潜在优势，但现有的研究主要集中在传统的机器学习和模式基于的人工智能系统上，对GenAI在质量研究中的人类与AI合作的研究相对落后。本研究探讨了十名质量研究者对ChatGPT的合作体验，发现ChatGPT作为主题分析的合作伙伴，可以提高编码效率，帮助初步数据探索，提供细致的量化预测，并帮助非native speaker和非专家理解。然而，对其可靠性和准确性、可靠性和一致性、局部理解和自适应性、以及研究社区更广泛的acceptance仍然存在问题。我们提出五个可行的设计建议，以促进人类与AI合作的有效性，包括：在设计中加入透明的解释机制，提高界面和集成能力，优先级contextual understanding和个性化，嵌入人类与AI反馈循环和迭代功能，以及加强信任通过验证机制。
</details></li>
</ul>
<hr>
<h2 id="Learned-Causal-Method-Prediction"><a href="#Learned-Causal-Method-Prediction" class="headerlink" title="Learned Causal Method Prediction"></a>Learned Causal Method Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03989">http://arxiv.org/abs/2311.03989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shantanu Gupta, Cheng Zhang, Agrin Hilmkil</li>
<li>for: 这 paper 用于选择最佳 causal inference 方法，以便有效地处理 causal discovery 问题。</li>
<li>methods: 这 paper 使用 CAusal Method Predictor (CAMP) 框架，通过生成多种同源 causal 模型，对 candidate methods 进行评分，并使用一个模型来直接预测最高分方法。</li>
<li>results: CAMP 在实验中表现出色，可以有效地预测最佳方法，并且在未看到真实数据的情况下，可以减少高成本的标注数据。 CAMP 还在 semi-synthetic 和实际世界 benchmark 上表现了扎根的一致性。<details>
<summary>Abstract</summary>
For a given causal question, it is important to efficiently decide which causal inference method to use for a given dataset. This is challenging because causal methods typically rely on complex and difficult-to-verify assumptions, and cross-validation is not applicable since ground truth causal quantities are unobserved.In this work, we propose CAusal Method Predictor (CAMP), a framework for predicting the best method for a given dataset. To this end, we generate datasets from a diverse set of synthetic causal models, score the candidate methods, and train a model to directly predict the highest-scoring method for that dataset. Next, by formulating a self-supervised pre-training objective centered on dataset assumptions relevant for causal inference, we significantly reduce the need for costly labeled data and enhance training efficiency. Our strategy learns to map implicit dataset properties to the best method in a data-driven manner. In our experiments, we focus on method prediction for causal discovery. CAMP outperforms selecting any individual candidate method and demonstrates promising generalization to unseen semi-synthetic and real-world benchmarks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>为给定的 causal 问题，效率地选择适合的 causal inference 方法是挑战。这是因为 causal 方法通常需要复杂和难以验证的假设，并且 cross-validation 不适用，因为真实的 causal 量未经观察。在这种情况下，我们提出了 CAusal Method Predictor (CAMP)，一个框架用于预测最佳方法。为此，我们生成了基于多种 synthetic causal 模型的数据集，评分候选方法，并使用一个模型直接预测该数据集中最高分的方法。接着，我们通过 centering on dataset 假设 relevante 于 causal inference 来降低需要贵重标注数据的需求，并提高训练效率。我们的策略可以在数据驱动的方式下将隐藏在数据中的 dataset 特性映射到最佳方法上。在我们的实验中，我们将注重 causal discovery 中的方法预测。CAMP 在比较任何个人候选方法时表现出色，并在未看到 semi-synthetic 和实际世界 benchmark 上展现了扎根的普适性。
</details></li>
</ul>
<hr>
<h2 id="Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains"><a href="#Its-All-Graph-To-Me-Foundational-Topology-Models-with-Contrastive-Learning-on-Multiple-Domains" class="headerlink" title="Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains"></a>Its All Graph To Me: Foundational Topology Models with Contrastive Learning on Multiple Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03976">http://arxiv.org/abs/2311.03976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex O. Davies, Riku W. Green, Nirav S. Ajmeri, Telmo M. Silva Filho</li>
<li>for:  This paper aims to address the issue of domain-specific pre-trained models for graph data, and to present a method that can be fine-tuned on multiple graph domains.</li>
<li>methods: The proposed method uses adversarial contrastive learning to pre-train a model on many graph domains, without requiring labeled data from the target domain. The model is trained only on topologies, but includes node labels in evaluation.</li>
<li>results: The authors show that the learnt representations of the proposed method are effective in various downstream tasks, and outperform baseline models pre-trained on single domains, as well as un-trained models and non-transferred models. The performance is consistently superior when node labels are used in evaluation.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文的目标是解决图数据中域特定预训练模型的问题，并提出一种方法可以在多个图域上进行预训练。</li>
<li>methods: 提议的方法使用对抗抑制学习来预训练一个模型在多个图域上，不需要目标域的标注数据。模型仅在结构上进行训练，但在评估中包含节点标签。</li>
<li>results: 作者表明，提议的方法的学习表现在下游任务中是有效的，并超过了基准模型预训练单个域、无预训练模型和非预训练模型。在使用节点标签进行评估时，性能一直高于单个域或无预训练模型。<details>
<summary>Abstract</summary>
Representations and embeddings of graph data have been essential in many domains of research.   The principle benefit of learning such representations is that the pre-trained model can be fine-tuned on smaller datasets where data or labels are scarse.   Existing models, however, are domain specific; for example a model trained on molecular graphs is fine-tuned on other molecular graphs.   This means that in many application cases the choice of pre-trained model can be arbitrary, and novel domains may lack an appropriate pre-trained model.   This is of particular issue where data is scarse, precluding traditional supervised methods.   In this work we use adversarial contrastive learning to present a \method, a model pre-trained on many graph domains.   We train the model only on topologies but include node labels in evaluation.   We evaluate the efficacy of its learnt representations on various downstream tasks.   Against baseline models pre-trained on single domains, as well as un-trained models and non-transferred models, we show that performance is equal or better using our single model.   This includes when node labels are used in evaluation, where performance is consistently superior to single-domain or non-pre-trained models.
</details>
<details>
<summary>摘要</summary>
研究领域中的图数据表示和嵌入已经是不可或缺的。这些表示的主要优点在于可以使用预训练模型进行精度调整，从而在数据或标签稀缺的情况下进行预测。现有的模型却是域特定的，例如一个用于分子图的模型只能在其他分子图上进行精度调整。这意味着在许多应用场景中，选择预训练模型的问题可能是随意的，而新的域可能缺乏适合的预训练模型。这是特别是在数据稀缺的情况下，传统的监督学习方法无法进行。在这项工作中，我们使用对抗对抗学习来提出一种方法，这是一个在多个图域上预训练的模型。我们只在图结构上进行训练，并在评估中包含节点标签。我们对此模型在多个下游任务上的表现进行评估，并与基eline模型、无预训练模型和非传递模型进行比较。我们发现，使用我们的单一模型，表现和基eline模型相当或更好，尤其是在节点标签在评估中使用时。
</details></li>
</ul>
<hr>
<h2 id="An-Expectation-Realization-Model-for-Metaphor-Detection"><a href="#An-Expectation-Realization-Model-for-Metaphor-Detection" class="headerlink" title="An Expectation-Realization Model for Metaphor Detection"></a>An Expectation-Realization Model for Metaphor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03963">http://arxiv.org/abs/2311.03963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oseremen O. Uduehi, Razvan C. Bunescu</li>
<li>for: 这个论文主要针对的是如何检测比喻。</li>
<li>methods: 该论文提出了一种基于两个主要模块的比喻检测架构：一个预期组件，该计算给定上下文中 literal word 的预期表示，以及一个实现组件，该计算actual word 的含义在上下文中。整个架构通过学习预期-实现（ER）模式来学习比喻的用法。</li>
<li>results: 该论文在三个比喻数据集上进行了评估，包括在分布内、分布外以及新比喻泛化等三个情况下的评估。结果显示，提出的方法在这些情况下都能够获得竞争或更好的结果，而且通过 ensemble ER 模型可以进一步提高比喻检测精度。<details>
<summary>Abstract</summary>
We propose a metaphor detection architecture that is structured around two main modules: an expectation component that estimates representations of literal word expectations given a context, and a realization component that computes representations of actual word meanings in context. The overall architecture is trained to learn expectation-realization (ER) patterns that characterize metaphorical uses of words. When evaluated on three metaphor datasets for within distribution, out of distribution, and novel metaphor generalization, the proposed method is shown to obtain results that are competitive or better than state-of-the art. Further increases in metaphor detection accuracy are obtained through ensembling of ER models.
</details>
<details>
<summary>摘要</summary>
我们提出了一种使用两个主要模块的比喻检测建筑：一个预期部件，用于在 контексте中估计literal字的预期表示，以及一个现实部件，用于在 контексте中计算实际字的含义。整个建筑是通过学习预期-现实（ER）模式来学习比喻的用法。在三个比喻数据集上进行评估，包括在分布内、分布外和新比喻泛化，我们的方法比或超过了当前最佳的结果。进一步的增加了比喻检测精度的ensemble ER模型。
</details></li>
</ul>
<hr>
<h2 id="Elastic-Information-Bottleneck"><a href="#Elastic-Information-Bottleneck" class="headerlink" title="Elastic Information Bottleneck"></a>Elastic Information Bottleneck</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03955">http://arxiv.org/abs/2311.03955</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyyxxx/elastic-information-bottleneck">https://github.com/nyyxxx/elastic-information-bottleneck</a></li>
<li>paper_authors: Yuyan Ni, Yanyan Lan, Ao Liu, Zhiming Ma</li>
<li>for: 本研究旨在探讨信息瓶颈（IB）和决定性信息瓶颈（DIB）在转移学习场景下的泛化能力。</li>
<li>methods: 本研究使用了IB和DIB两种方法，并对它们的泛化能力进行了分析。</li>
<li>results: 研究结果表明，DIB的泛化能力较IB更强，但是DIB的表示差（RD）较IB更大。为了平衡这两个因素，我们提出了一种灵活信息瓶颈（EIB）方法，可以在IB框架中实现最优平衡。实验结果表明，EIB可以在适用于实际数据上实现更好的领域适应性。<details>
<summary>Abstract</summary>
Information bottleneck is an information-theoretic principle of representation learning that aims to learn a maximally compressed representation that preserves as much information about labels as possible. Under this principle, two different methods have been proposed, i.e., information bottleneck (IB) and deterministic information bottleneck (DIB), and have gained significant progress in explaining the representation mechanisms of deep learning algorithms. However, these theoretical and empirical successes are only valid with the assumption that training and test data are drawn from the same distribution, which is clearly not satisfied in many real-world applications. In this paper, we study their generalization abilities within a transfer learning scenario, where the target error could be decomposed into three components, i.e., source empirical error, source generalization gap (SG), and representation discrepancy (RD). Comparing IB and DIB on these terms, we prove that DIB's SG bound is tighter than IB's while DIB's RD is larger than IB's. Therefore, it is difficult to tell which one is better. To balance the trade-off between SG and the RD, we propose an elastic information bottleneck (EIB) to interpolate between the IB and DIB regularizers, which guarantees a Pareto frontier within the IB framework. Additionally, simulations and real data experiments show that EIB has the ability to achieve better domain adaptation results than IB and DIB, which validates the correctness of our theories.
</details>
<details>
<summary>摘要</summary>
信息瓶颈是一种信息理论的学习原理，旨在学习最高度压缩的表示，以保持最多的信息关于标签。在这个原理下，有两种不同的方法被提出：信息瓶颈（IB）和决定性信息瓶颈（DIB），它们在理论和实验方面做出了重要的进步，解释了深度学习算法的表示机制。但是，这些理论和实验成功假设训练和测试数据来自同一个分布，这并不符合现实世界中的许多应用场景。在这篇论文中，我们研究IB和DIB在转移学习场景下的泛化能力，将目标错误分解为三个组件：源采样错误（SE）、源泛化差（SG）和表示差异（RD）。比较IB和DIB的 bound，我们证明DIB的 SG bound 更紧，而DIB的 RD 更大。因此，无法判断哪一个更好。为了平衡SG和RD的负担，我们提出了灵活信息瓶颈（EIB），可以在IB框架中 interpolate  междуIB和DIB正则化，这 garantía一个Pareto前沿。此外，实验和实际数据表明，EIB可以在适应域中实现更好的适应结果，这证明了我们的理论的正确性。
</details></li>
</ul>
<hr>
<h2 id="The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata"><a href="#The-Music-Meta-Ontology-a-flexible-semantic-model-for-the-interoperability-of-music-metadata" class="headerlink" title="The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata"></a>The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03942">http://arxiv.org/abs/2311.03942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jacopo de Berardinis, Valentina Anita Carriero, Albert Meroño-Peñuela, Andrea Poltronieri, Valentina Presutti</li>
<li>for:  This paper aims to provide a semantic model for music metadata to facilitate the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery.</li>
<li>methods:  The paper introduces the Music Meta ontology, which is a rich and flexible semantic model that describes music metadata related to artists, compositions, performances, recordings, and links. The authors follow eXtreme Design methodologies and best practices for data engineering to ensure that the model reflects the perspectives and requirements of various stakeholders.</li>
<li>results:  The paper provides a first evaluation of the Music Meta model, including alignments to other schema (Music Ontology, DOREMUS, Wikidata) and support for data transformation.<details>
<summary>Abstract</summary>
The semantic description of music metadata is a key requirement for the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery. It is nonetheless an open challenge due to the complexity of musical concepts arising from different genres, styles, and periods -- standing to benefit from a lingua franca to accommodate various stakeholders (musicologists, librarians, data engineers, etc.). To initiate this transition, we introduce the Music Meta ontology, a rich and flexible semantic model to describe music metadata related to artists, compositions, performances, recordings, and links. We follow eXtreme Design methodologies and best practices for data engineering, to reflect the perspectives and the requirements of various stakeholders into the design of the model, while leveraging ontology design patterns and accounting for provenance at different levels (claims, links). After presenting the main features of Music Meta, we provide a first evaluation of the model, alignments to other schema (Music Ontology, DOREMUS, Wikidata), and support for data transformation.
</details>
<details>
<summary>摘要</summary>
“音乐元数据的 semantic 描述是创建可以一致、 интеграción和搜索信息的音乐数据集的关键要求。然而，这是一个打开的挑战，因为音乐的概念来自不同的流派、风格和时期，需要一种 lingua franca 来容纳各种参与者（音乐学家、图书馆员、数据工程师等）。为了实现这一目标，我们介绍了 Music Meta  Ontology，这是一个rich和flexible的semantic模型，用于描述音乐元数据，包括艺术家、作品、表演、录音和链接。我们遵循 eXtreme Design 方法和数据工程的最佳实践，将参与者的视角和需求反映到模型的设计中，同时遵循 ontology 设计模式和考虑多级宣告（laims、链接）的来源。在介绍 Music Meta 的主要特点后，我们提供了模型的初步评估、与 Music Ontology 和 DOREMUS 的对接以及数据转换支持。”Note: "Simplified Chinese" is used to refer to the standardized form of Chinese used in mainland China and Singapore, which is different from "Traditional Chinese" used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive"><a href="#Temporal-Graph-Representation-Learning-with-Adaptive-Augmentation-Contrastive" class="headerlink" title="Temporal Graph Representation Learning with Adaptive Augmentation Contrastive"></a>Temporal Graph Representation Learning with Adaptive Augmentation Contrastive</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03897">http://arxiv.org/abs/2311.03897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongjiang Chen, Pengfei Jiao, Huijun Tang, Huaming Wu</li>
<li>for: 本文旨在提出一种基于强化对比的图像学习模型，以便在时间序列中提取低维度的动态节点嵌入，同时捕捉时间信息、结构信息和属性信息。</li>
<li>methods: 本文提出的模型是基于强化对比的图像学习模型，具有适应增强的特点，可以在时间序列中适应不同的噪声。</li>
<li>results: 实验结果表明，提出的模型在各种实际网络上表现出优于其他时间图像学习方法。<details>
<summary>Abstract</summary>
Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translation_direction=zh-Hans Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods.Note: The translation is in Simplified Chinese, which is one of the two standardized Chinese writing systems. The other one is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference"><a href="#Understanding-Tool-Discovery-and-Tool-Innovation-Using-Active-Inference" class="headerlink" title="Understanding Tool Discovery and Tool Innovation Using Active Inference"></a>Understanding Tool Discovery and Tool Innovation Using Active Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03893">http://arxiv.org/abs/2311.03893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Poppy Collis, Paul F Kinghorn, Christopher L Buckley</li>
<li>for: 本研究旨在探讨人工智能代理的工具创新能力。</li>
<li>methods: 本文使用 active inference  formalism 分析工具发现和工具创新的两个概念，并在拟合一种工具创新模型中引入工具可能性的概念。</li>
<li>results: 本研究发现，通过在机器学习模型中隐藏状态中引入工具可能性，可以不仅发现工具，还可以创造新的工具。<details>
<summary>Abstract</summary>
The ability to invent new tools has been identified as an important facet of our ability as a species to problem solve in dynamic and novel environments. While the use of tools by artificial agents presents a challenging task and has been widely identified as a key goal in the field of autonomous robotics, far less research has tackled the invention of new tools by agents. In this paper, (1) we articulate the distinction between tool discovery and tool innovation by providing a minimal description of the two concepts under the formalism of active inference. We then (2) apply this description to construct a toy model of tool innovation by introducing the notion of tool affordances into the hidden states of the agent's probabilistic generative model. This particular state factorisation facilitates the ability to not just discover tools but invent them through the offline induction of an appropriate tool property. We discuss the implications of these preliminary results and outline future directions of research.
</details>
<details>
<summary>摘要</summary>
人类的问题解决能力是通过创造新工具的能力，这被认为是我们种族的重要特征之一。虽然人工智能代理人使用工具是一个挑战性任务，但相比之下，代理人创造新工具的研究得到了更少的关注。在这篇论文中，我们将（1）描述工具发现和工具创新之间的区别，通过活动推断来提供最小的描述。然后我们（2）将这种描述应用于构建一个简单的工具创新模型，通过引入工具可用性的概念来加入代理人隐藏状态的概率生成模型中。这种特征分解使得代理人不仅能够发现工具，还能够通过离线推导适应性的工具属性来创造新的工具。我们讨论了这些初步结果的意义和未来研究的方向。
</details></li>
</ul>
<hr>
<h2 id="Formulating-Discrete-Probability-Flow-Through-Optimal-Transport"><a href="#Formulating-Discrete-Probability-Flow-Through-Optimal-Transport" class="headerlink" title="Formulating Discrete Probability Flow Through Optimal Transport"></a>Formulating Discrete Probability Flow Through Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03886">http://arxiv.org/abs/2311.03886</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pangzecheung/discrete-probability-flow">https://github.com/pangzecheung/discrete-probability-flow</a></li>
<li>paper_authors: Pengze Zhang, Hubery Yin, Chen Li, Xiaohua Xie</li>
<li>for: 这个论文的目的是建立抽象概率流的基本理论，以便更好地理解数字扩散模型中的概率流。</li>
<li>methods: 作者首先证明了连续概率流是在某些条件下的蒙地奥提伦运输图，并提供了对应的数字情况的证明。然后，作者根据这些发现定义了数字概率流，并在这个定义下提出了一种新的采样方法。</li>
<li>results: 作者通过对synthetic toy dataset和CIFAR-10 dataset的广泛实验证明了他们提出的数字概率流的有效性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/PangzeCheung/Discrete-Probability-Flow%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/PangzeCheung/Discrete-Probability-Flow中下载。</a><details>
<summary>Abstract</summary>
Continuous diffusion models are commonly acknowledged to display a deterministic probability flow, whereas discrete diffusion models do not. In this paper, we aim to establish the fundamental theory for the probability flow of discrete diffusion models. Specifically, we first prove that the continuous probability flow is the Monge optimal transport map under certain conditions, and also present an equivalent evidence for discrete cases. In view of these findings, we are then able to define the discrete probability flow in line with the principles of optimal transport. Finally, drawing upon our newly established definitions, we propose a novel sampling method that surpasses previous discrete diffusion models in its ability to generate more certain outcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10 dataset have validated the effectiveness of our proposed discrete probability flow. Code is released at: https://github.com/PangzeCheung/Discrete-Probability-Flow.
</details>
<details>
<summary>摘要</summary>
CONTINUOUS DIFFUSION MODELS 通常被承认为 Display deterministic probability flow，而 DISCRETE DIFFUSION MODELS 则不然。在这篇论文中，我们想要建立 DISCRETE DIFFUSION MODELS 的可定义流的基本理论。specifically，我们首先证明了 continuous probability flow 是 Monge 优质量运输图 under certain conditions，并 auch present 了等价的证明 для discrete cases。 Based on these findings，我们可以定义 DISCRETE PROBABILITY FLOW 以符合优质量运输的原则。最后，我们根据我们 newly established definitions 提出了一种新的采样方法，可以更加准确地生成 outcome。我们在 synthetic toy dataset 和 CIFAR-10 dataset 进行了广泛的实验，并证明了我们的提议的 DISCRETE PROBABILITY FLOW 的效果。Code 在：https://github.com/PangzeCheung/Discrete-Probability-Flow。
</details></li>
</ul>
<hr>
<h2 id="Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters"><a href="#Mini-but-Mighty-Finetuning-ViTs-with-Mini-Adapters" class="headerlink" title="Mini but Mighty: Finetuning ViTs with Mini Adapters"></a>Mini but Mighty: Finetuning ViTs with Mini Adapters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03873">http://arxiv.org/abs/2311.03873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iemprog/mimi">https://github.com/iemprog/mimi</a></li>
<li>paper_authors: Imad Eddine Marouf, Enzo Tartaglione, Stéphane Lathuilière</li>
<li>for: 这个研究旨在提高对新任务的适应性，并且降低训练和储存成本。</li>
<li>methods: 我们提出了一个名为MiMi的训练框架，它可以对小型扩展器进行自动调整，以提高其性能。</li>
<li>results: 我们的方法在三个dataset benchmarcks（DomainNet、VTAB和Multi-task）上，对29个dataset进行了最佳的搜寻，并且超过了现有方法的性能。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have become one of the dominant architectures in computer vision, and pre-trained ViT models are commonly adapted to new tasks via fine-tuning. Recent works proposed several parameter-efficient transfer learning methods, such as adapters, to avoid the prohibitive training and storage cost of finetuning. In this work, we observe that adapters perform poorly when the dimension of adapters is small, and we propose MiMi, a training framework that addresses this issue. We start with large adapters which can reach high performance, and iteratively reduce their size. To enable automatic estimation of the hidden dimension of every adapter, we also introduce a new scoring function, specifically designed for adapters, that compares the neuron importance across layers. Our method outperforms existing methods in finding the best trade-off between accuracy and trained parameters across the three dataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.
</details>
<details>
<summary>摘要</summary>
计算机视觉领域中，视 transformer（ViT）架构已成为当前主导性的建筑，而预训练 ViT 模型通常通过精度调整来适应新任务。latest works proposed several parameter-efficient transfer learning methods, such as adapters, to avoid the prohibitive training and storage cost of fine-tuning.在这个工作中，我们发现小个数的适应器（adapters）表现不佳，我们提出了 MiMi，一种培训框架，解决这个问题。我们从大的适应器开始，然后逐渐减小它们的大小。为了自动估计每个适应器的隐藏维度，我们也引入了一个新的评分函数，专门为适应器设计，用于比较层次中每个神经元的重要性。我们的方法在三个数据集标准 benchmarck（DomainNet、VTAB 和 Multi-task）上，对共计29个数据集进行了比较，并超过了现有方法。
</details></li>
</ul>
<hr>
<h2 id="FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models"><a href="#FD-MIA-Efficient-Attacks-on-Fairness-enhanced-Models" class="headerlink" title="FD-MIA: Efficient Attacks on Fairness-enhanced Models"></a>FD-MIA: Efficient Attacks on Fairness-enhanced Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03865">http://arxiv.org/abs/2311.03865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Tian, Guangsheng Zhang, Bo Liu, Tianqing Zhu, Ming Ding, Wanlei Zhou</li>
<li>for: 本研究旨在攻击使用加入了公平约束的模型，以便通过分析模型预测分数来推断数据样本是否在训练过程中使用。</li>
<li>methods: 本研究使用了一种基于公平差异结果的有效MIA方法，即FD-MIA。它利用了两个模型（原始模型和公平模型）对数据样本的预测结果的差异，并利用这些预测差异作为攻击征。</li>
<li>results: 实验结果表明，FD-MIA方法可以高效地攻击使用加入了公平约束的模型，并且可以避免由于加入公平约束而导致的隐私泄露问题。<details>
<summary>Abstract</summary>
Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues. We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues.We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method.
</details></li>
</ul>
<hr>
<h2 id="Aspects-of-human-memory-and-Large-Language-Models"><a href="#Aspects-of-human-memory-and-Large-Language-Models" class="headerlink" title="Aspects of human memory and Large Language Models"></a>Aspects of human memory and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03839">http://arxiv.org/abs/2311.03839</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rmldj/memory-llm-paper">https://github.com/rmldj/memory-llm-paper</a></li>
<li>paper_authors: Romuald A. Janik</li>
<li>for:  investigate the memory properties of LLMs and their relationship to human memory</li>
<li>methods:  use of large language models (LLMs) and their probabilistic model of language use</li>
<li>results:  surprising similarities between the memory properties of LLMs and human memory, suggesting that biological features of human memory influence the way we structure textual narratives<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are huge artificial neural networks which primarily serve to generate text, but also provide a very sophisticated probabilistic model of language use. Since generating a semantically consistent text requires a form of effective memory, we investigate the memory properties of LLMs and find surprising similarities with key characteristics of human memory. This result strongly suggests that the biological features of human memory leave an imprint on the way that we structure our textual narratives.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models"><a href="#Reducing-Spatial-Fitting-Error-in-Distillation-of-Denoising-Diffusion-Models" class="headerlink" title="Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models"></a>Reducing Spatial Fitting Error in Distillation of Denoising Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03830">http://arxiv.org/abs/2311.03830</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sainzerjj/SFERD">https://github.com/Sainzerjj/SFERD</a></li>
<li>paper_authors: Shengzhe Zhou, Zejian Lee, Shengyuan Zhang, Lefan Hou, Changyuan Yang, Guang Yang, Lingyun Sun</li>
<li>for: 提高Diffusion模型的频繁样本生成质量</li>
<li>methods: 使用注意力导航和设计的semantic gradient预测器减少学生模型的适应错误</li>
<li>results: 在几个函数评估中生成高质量样本，FID值为5.31在CIFAR-10和9.39在ImageNet 64x64中，超过现有的扩散方法<details>
<summary>Abstract</summary>
Denoising Diffusion models have exhibited remarkable capabilities in image generation. However, generating high-quality samples requires a large number of iterations. Knowledge distillation for diffusion models is an effective method to address this limitation with a shortened sampling process but causes degraded generative quality. Based on our analysis with bias-variance decomposition and experimental observations, we attribute the degradation to the spatial fitting error occurring in the training of both the teacher and student model. Accordingly, we propose $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation model ($\textbf{SFERD}$). SFERD utilizes attention guidance from the teacher model and a designed semantic gradient predictor to reduce the student's fitting error. Empirically, our proposed model facilitates high-quality sample generation in a few function evaluations. We achieve an FID of 5.31 on CIFAR-10 and 9.39 on ImageNet 64$\times$64 with only one step, outperforming existing diffusion methods. Our study provides a new perspective on diffusion distillation by highlighting the intrinsic denoising ability of models.
</details>
<details>
<summary>摘要</summary>
Diffusion模型在图像生成方面表现出了惊人的能力，但是生成高质量样本需要大量的迭代过程。知识传授 dla diffusion模型是一种有效的方法，可以缩短样本生成过程，但会导致生成质量下降。根据我们的分析和实验观察，我们认为这种下降是由 diffusion模型在训练中的空间适应错误引起的。因此，我们提出了 $\textbf{S}$patial $\textbf{F}$itting-$\textbf{E}$rror $\textbf{R}$eduction $\textbf{D}$istillation模型（$\textbf{SFERD}$）。SFERD使用教师模型的注意力引导和设计的semantic gradient预测器来减少学生模型的适应错误。我们的提议模型在几个功能评估中能够生成高质量样本，我们在CIFAR-10和ImageNet 64x64上达到了5.31和9.39的FID值，只需要一步，超越了现有的扩散方法。我们的研究提供了一新的视角，强调扩散模型的内在杂音能力。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation"><a href="#Rethinking-and-Improving-Multi-task-Learning-for-End-to-end-Speech-Translation" class="headerlink" title="Rethinking and Improving Multi-task Learning for End-to-end Speech Translation"></a>Rethinking and Improving Multi-task Learning for End-to-end Speech Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03810">http://arxiv.org/abs/2311.03810</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaozhang521/imtl">https://github.com/xiaozhang521/imtl</a></li>
<li>paper_authors: Yuhao Zhang, Chen Xu, Bei Li, Hao Chen, Tong Xiao, Chunliang Zhang, Jingbo Zhu</li>
<li>for: 本研究旨在 investigate the consistency between different tasks in end-to-end speech translation (ST), and propose an improved multi-task learning (IMTL) approach to mitigate the difference in length and representation.</li>
<li>methods: 本研究使用 multi-task learning 方法，包括 textual encoder 和 speech encoder，以及一种 improved multi-task learning (IMTL) approach。</li>
<li>results: 研究结果显示，我们的方法可以实现 state-of-the-art 的结果，并且在额外训练数据 disponibles 时，可以实现新的 SOTA 结果。另外，我们的方法只需要 20.8% 的训练时间，比现有 SOTA 方法要少。<details>
<summary>Abstract</summary>
Significant improvements in end-to-end speech translation (ST) have been achieved through the application of multi-task learning. However, the extent to which auxiliary tasks are highly consistent with the ST task, and how much this approach truly helps, have not been thoroughly studied. In this paper, we investigate the consistency between different tasks, considering different times and modules. We find that the textual encoder primarily facilitates cross-modal conversion, but the presence of noise in speech impedes the consistency between text and speech representations. Furthermore, we propose an improved multi-task learning (IMTL) approach for the ST task, which bridges the modal gap by mitigating the difference in length and representation. We conduct experiments on the MuST-C dataset. The results demonstrate that our method attains state-of-the-art results. Moreover, when additional data is used, we achieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the training time required by the current SOTA method.
</details>
<details>
<summary>摘要</summary>
很大的改进在端到端语音翻译（ST）中实现了，通过多任务学习。然而，auxiliary任务和ST任务之间的一致性，以及这种方法对ST任务的真正帮助，尚未得到了充分的研究。在这篇论文中，我们研究了不同任务之间的一致性，考虑不同的时间和模块。我们发现，文本Encoder主要帮助cross-modal转换，但是在语音中存在噪音会降低语音和文本表示之间的一致性。此外，我们提出了一种改进的多任务学习（IMTL）方法，用于ST任务，可以bridge模态差距，减少语音和文本表示之间的差异。我们在MuST-C dataset上进行了实验。结果表明，我们的方法实现了状态的最佳结果。此外，当使用了额外数据时，我们在MuST-C英语到西班牙语任务上获得了新的SOTA结果，仅用20.8%的训练时间。
</details></li>
</ul>
<hr>
<h2 id="Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI"><a href="#Scene-Driven-Multimodal-Knowledge-Graph-Construction-for-Embodied-AI" class="headerlink" title="Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI"></a>Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03783">http://arxiv.org/abs/2311.03783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Song Yaoxian, Sun Penglei, Liu Haoyu, Li Zhixu, Song Wei, Xiao Yanghua, Zhou Xiaofang</li>
<li>for: 本研究旨在提高现实世界中的机器人智能，通过Scene-MMKG构建方法，增强机器人对Scene知识的理解，以提高机器人的决策能力和功能表现。</li>
<li>methods: 本研究提出了Scene-MMKG构建方法， combinig conventional knowledge engineering和大型自然语言模型，实现了Scene知识的可导入和可迁移。</li>
<li>results: 实验结果表明，使用我们的Instantiated ManipMob-MMKG可以明显提高embodied任务的性能，而无需复杂地重构模型结构。<details>
<summary>Abstract</summary>
Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly. Our project can be found at https://sites.google.com/view/manipmob-mmkg
</details>
<details>
<summary>摘要</summary>
现代人工智能和机器人学中最受欢迎的研究之一是体验AI，它可以有效提高实际世界中的智能机器人服务人类。场景知识是一个机器人理解环境和做出正确决策的关键。然而，目前存在场景知识库缺失，大多数现有工作使用通用知识库或预训练模型来提高机器人的智能水平。传统的知识库缺乏，容易受到数据收集成本的影响，而预训练模型受到知识不确定性和维护困难。为了缓解场景知识的挑战，我们提出了场景驱动多模态知识图（Scene-MMKG）建构方法，结合传统知识工程和大型自然语言模型。我们引入了一个统一的场景知识注入框架，以便场景知识表示。为评估我们提出的方法的优势，我们实例化Scene-MMKG，并考虑典型的室内 роботиче功能（操作和移动），称之为ManipMob-MMKG。对比分析表明，我们的实例化ManipMob-MMKG在数据采集效率和知识质量方面具有广泛的优势。实验结果表明，使用我们的实例化ManipMob-MMKG可以明显提高实际任务的性能，而不需要复杂地重新设计模型结构。更多信息可以在https://sites.google.com/view/manipmob-mmkg上找到。
</details></li>
</ul>
<hr>
<h2 id="Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion"><a href="#Ensembling-Textual-and-Structure-Based-Models-for-Knowledge-Graph-Completion" class="headerlink" title="Ensembling Textual and Structure-Based Models for Knowledge Graph Completion"></a>Ensembling Textual and Structure-Based Models for Knowledge Graph Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03780">http://arxiv.org/abs/2311.03780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananjan Nandi, Navdeep Kaur, Parag Singla, Mausam</li>
<li>for: 本研究旨在提高知识图完成任务的性能，通过结合文本模型和结构基本模型。</li>
<li>methods: 本研究使用了结构基本模型和文本模型，并提出了一种新的查询依赖ensemble权重学习方法。</li>
<li>results: 本研究的基准 ensemble方法在三个标准知识图完成 datasets 上 achieved state-of-the-art result, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models。<details>
<summary>Abstract</summary>
We consider two popular approaches to Knowledge Graph Completion (KGC): textual models that rely on textual entity descriptions, and structure-based models that exploit the connectivity structure of the Knowledge Graph (KG). Preliminary experiments show that these approaches have complementary strengths: structure-based models perform well when the gold answer is easily reachable from the query head in the KG, while textual models exploit descriptions to give good performance even when the gold answer is not reachable. In response, we explore ensembling as a way of combining the best of both approaches. We propose a novel method for learning query-dependent ensemble weights by using the distributions of scores assigned by individual models to all candidate entities. Our ensemble baseline achieves state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models.
</details>
<details>
<summary>摘要</summary>
我们考虑了两种受欢迎的知识 graphs 完成（KGC）方法：文本模型，它们依靠知识 graphs 中实体的文本描述，以及结构基于模型，它们利用知识 graphs 的连接结构来完成。我们的初步实验显示这两种方法有辅相互补偿的优点：结构基于模型在知识 graphs 中找到答案的路径较短，而文本模型则可以透过描述来实现更好的性能，即使答案不在知识 graphs 中可达。因此，我们探讨 ensemble 的方法，以 combin 两种方法的最佳特点。我们提出了一种学习查询相依 ensemble 权重的新方法，使用各个模型对所有候选实体的分布 scores 来学习查询相依 ensemble 权重。我们的ensemble基准得到了三个标准 KGC 资料集的state-of-the-art 结果，与最佳个体模型相对提高了6.8pt MRR和8.3pt Hits@1。
</details></li>
</ul>
<hr>
<h2 id="PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning"><a href="#PT-Tuning-Bridging-the-Gap-between-Time-Series-Masked-Reconstruction-and-Forecasting-via-Prompt-Token-Tuning" class="headerlink" title="PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning"></a>PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction and Forecasting via Prompt Token Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03768">http://arxiv.org/abs/2311.03768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Liu, Jinrui Gan, Xiaoxuan Fan, Yi Zhang, Chuanxian Luo, Jing Zhang, Guangxin Jiang, Yucheng Qian, Changwei Zhao, Huan Ma, Zhenyu Guo</li>
<li>for:  bridging the gap between time series masked reconstruction and forecasting</li>
<li>methods:  reserved pre-trained mask token during fine-tuning stage, and proposed prompt token tuning (PT-Tuning) paradigm</li>
<li>results:  state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methods<details>
<summary>Abstract</summary>
Self-supervised learning has been actively studied in time series domain recently, especially for masked reconstruction. Most of these methods follow the "Pre-training + Fine-tuning" paradigm in which a new decoder replaces the pre-trained decoder to fit for a specific downstream task, leading to inconsistency of upstream and downstream tasks. In this paper, we first point out that the unification of task objectives and adaptation for task difficulty are critical for bridging the gap between time series masked reconstruction and forecasting. By reserving the pre-trained mask token during fine-tuning stage, the forecasting task can be taken as a special case of masked reconstruction, where the future values are masked and reconstructed based on history values. It guarantees the consistency of task objectives but there is still a gap in task difficulty. Because masked reconstruction can utilize contextual information while forecasting can only use historical information to reconstruct. To further mitigate the existed gap, we propose a simple yet effective prompt token tuning (PT-Tuning) paradigm, in which all pre-trained parameters are frozen and only a few trainable prompt tokens are added to extended mask tokens in element-wise manner. Extensive experiments on real-world datasets demonstrate the superiority of our proposed paradigm with state-of-the-art performance compared to representation learning and end-to-end supervised forecasting methods.
</details>
<details>
<summary>摘要</summary>
自适应学习在时间序列领域已经广泛研究，特别是对于偏挥恢复。大多数这些方法采用“预训练+精度调整”模式，在这种模式下，一个新的解码器取代预训练的解码器，以适应特定下游任务，导致上游和下游任务的不一致。在这篇论文中，我们首先指出了对时间序列偏挥恢复和预测的统一任务目标和适应任务难度是关键的。通过保留预训练的偏挥token during fine-tuning阶段，我们可以将预测任务视为时间序列偏挥恢复的特殊情况，将未来值视为偏挥的，并根据历史值进行重建。这保证了任务目标的一致性，但是还存在一定的任务难度差异。因为偏挥恢复可以使用 contextual information，而预测只能使用历史信息来重建。为了进一步减少这个差异，我们提议了一种简单 yet effective的 prompt token tuning（PT-Tuning）方法。在这种方法中，所有的预训练参数被冻结，只有一些可变的提示符被添加到元素级别上，以扩展偏挥token。我们在实际的世界数据集上进行了广泛的实验，并证明了我们的提议方法可以与现有的表示学习和端到端超参数学习方法匹配或超越。
</details></li>
</ul>
<hr>
<h2 id="Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition"><a href="#Augmenting-Radio-Signals-with-Wavelet-Transform-for-Deep-Learning-Based-Modulation-Recognition" class="headerlink" title="Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition"></a>Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based Modulation Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03761">http://arxiv.org/abs/2311.03761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Chen, Shilian Zheng, Kunfeng Qiu, Luxin Zhang, Qi Xuan, Xiaoniu Yang</li>
<li>for: 这篇论文是为了提出一种基于深度学习的无线电变换识别方法，并且使用数据增强法增加训练数据的多样性和量。</li>
<li>methods: 这篇论文使用的方法包括使用数字波лет变换对细节系数进行分解，并将其恢复为新的数据amples，以增加训练数据的多样性和量。不同的生成方法是用来生成更多的替补序列。</li>
<li>results:  simulation 结果显示，这篇论文所提出的方法与其他增强方法相比，能够获得更高的识别精度和准确率。<details>
<summary>Abstract</summary>
The use of deep learning for radio modulation recognition has become prevalent in recent years. This approach automatically extracts high-dimensional features from large datasets, facilitating the accurate classification of modulation schemes. However, in real-world scenarios, it may not be feasible to gather sufficient training data in advance. Data augmentation is a method used to increase the diversity and quantity of training dataset and to reduce data sparsity and imbalance. In this paper, we propose data augmentation methods that involve replacing detail coefficients decomposed by discrete wavelet transform for reconstructing to generate new samples and expand the training set. Different generation methods are used to generate replacement sequences. Simulation results indicate that our proposed methods significantly outperform the other augmentation methods.
</details>
<details>
<summary>摘要</summary>
使用深度学习进行广播模式识别已在最近几年内变得普遍。这种方法自动提取大量数据集中的特征，使得广播模式的准确识别变得可能。然而，在实际应用中，可能无法在 advance 收集充足的训练数据。数据扩展是一种方法，用于增加训练集的多样性和量，并降低数据稀缺和偏度。在这篇论文中，我们提议了一种数据扩展方法，该方法包括将离散波лет变换 decomposed 的细节系数替换为重建新样本，以扩大训练集。不同的生成方法用于生成替换序列。实验结果表明，我们的提议方法在其他扩展方法的基础上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning"><a href="#Learning-Decentralized-Traffic-Signal-Controllers-with-Multi-Agent-Graph-Reinforcement-Learning" class="headerlink" title="Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning"></a>Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03756">http://arxiv.org/abs/2311.03756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yao Zhang, Zhiwen Yu, Jun Zhang, Liang Wang, Tom H. Luan, Bin Guo, Chau Yuen</li>
<li>For: 这个论文关注智能城市中的优化交通信号控制问题，它被视为一个复杂的网络系统控制问题。在交通灯和道路网络之间的互动动力学中，实现控制器适应性和扩展性是一个主要挑战。* Methods: 我们采用Multi-Agent Reinforcement Learning（MARL）框架，但现有的MARL算法忽略了有效信息聚合，这是改善各自代理的学习能力的关键。在这篇论文中，我们设计了一种新的分布式控制架构，其中包括改进的环境观察性，以捕捉交通灯之间的空间-时间相关性。* Results: 我们在synthetic和实际数据集上进行了广泛的实验，并证明了我们的提议在已有的分布式算法中表现出优于性。<details>
<summary>Abstract</summary>
This paper considers optimal traffic signal control in smart cities, which has been taken as a complex networked system control problem. Given the interacting dynamics among traffic lights and road networks, attaining controller adaptivity and scalability stands out as a primary challenge. Capturing the spatial-temporal correlation among traffic lights under the framework of Multi-Agent Reinforcement Learning (MARL) is a promising solution. Nevertheless, existing MARL algorithms ignore effective information aggregation which is fundamental for improving the learning capacity of decentralized agents. In this paper, we design a new decentralized control architecture with improved environmental observability to capture the spatial-temporal correlation. Specifically, we first develop a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. Particularly, we transfer the road network topology into a graph shift operator by forming a diffusion process on the topology, which subsequently facilitates the construction of graph signals. A diffusion convolution module is developed, forming a new MARL algorithm, which endows agents with the capabilities of graph learning. Extensive experiments based on both synthetic and real-world datasets verify that our proposal outperforms existing decentralized algorithms.
</details>
<details>
<summary>摘要</summary>
To address this limitation, we propose a new decentralized control architecture with enhanced environmental observability. Our approach includes a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. We transform the road network topology into a graph shift operator by creating a diffusion process on the topology, which facilitates the construction of graph signals. We then develop a diffusion convolution module, which endows agents with the ability of graph learning.Extensive experiments based on both synthetic and real-world datasets demonstrate that our proposed method outperforms existing decentralized algorithms. Our approach enables more effective and efficient traffic signal control, leading to improved traffic flow and reduced congestion in smart cities.
</details></li>
</ul>
<hr>
<h2 id="COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System"><a href="#COOL-A-Constraint-Object-Oriented-Logic-Programming-Language-and-its-Neural-Symbolic-Compilation-System" class="headerlink" title="COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System"></a>COOL: A Constraint Object-Oriented Logic Programming Language and its Neural-Symbolic Compilation System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03753">http://arxiv.org/abs/2311.03753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jipeng Han</li>
<li>for: 本研究旨在整合神经网络与逻辑编程，解决长期存在的神经网络总结和学习能力与逻辑逻辑的结合问题。</li>
<li>methods: 我们提出了COOL（约束对象 oriented逻辑）编程语言，一种创新的方法，可以自动处理数据收集，减少用户提供初始数据的需求。</li>
<li>results: COOL语言可以减少神经网络训练时的风险，提高神经网络的重用和扩展，并且其基本原则和算法可以为未来编程语言和神经网络架构的发展提供有价值的思路。<details>
<summary>Abstract</summary>
This paper explores the integration of neural networks with logic programming, addressing the longstanding challenges of combining the generalization and learning capabilities of neural networks with the precision of symbolic logic. Traditional attempts at this integration have been hampered by difficulties in initial data acquisition, the reliability of undertrained networks, and the complexity of reusing and augmenting trained models. To overcome these issues, we introduce the COOL (Constraint Object-Oriented Logic) programming language, an innovative approach that seamlessly combines logical reasoning with neural network technologies. COOL is engineered to autonomously handle data collection, mitigating the need for user-supplied initial data. It incorporates user prompts into the coding process to reduce the risks of undertraining and enhances the interaction among models throughout their lifecycle to promote the reuse and augmentation of networks. Furthermore, the foundational principles and algorithms in COOL's design and its compilation system could provide valuable insights for future developments in programming languages and neural network architectures.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文探讨了神经网络与逻辑编程的集成，解决了长期存在的神经网络的通用和学习能力与逻辑逻辑的精度问题。传统的集成尝试受到数据收集初始化问题、神经网络训练不可靠和已训练模型重用和增强问题的限制。为解决这些问题，我们介绍了COOL（约束对象逻辑）编程语言，这是一种创新的方法，可以自然地将逻辑推理与神经网络技术结合在一起。COOL可以自动处理数据收集，从而减少用户提供初始数据的需求。它还 incorporates用户提示到编程过程中，以降低训练不足的风险，并在模型生命周期中提高模型之间的交互，以促进模型的重用和增强。此外，COOL的设计原则和编译系统的算法可以为未来编程语言和神经网络架构的发展提供有价值的思想和技术指导。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust"><a href="#Leveraging-Large-Language-Models-for-Automated-Proof-Synthesis-in-Rust" class="headerlink" title="Leveraging Large Language Models for Automated Proof Synthesis in Rust"></a>Leveraging Large Language Models for Automated Proof Synthesis in Rust</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03739">http://arxiv.org/abs/2311.03739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianan Yao, Ziqiao Zhou, Weiteng Chen, Weidong Cui</li>
<li>for: 这 paper 的目的是提出一种基于 Large Language Models (LLMs) 和静态分析的形式验证框架，以便提高形式验证的可靠性和效率。</li>
<li>methods: 这 paper 使用了 LLMs 和静态分析来生成 invariants、assertions 和其他证明结构，并通过多个小任务和 OpenAI 的 GPT-4 模型来减少人工劳动。</li>
<li>results: 对于 20 个向量操作程序，这个 прототип 能够显著减少人工劳动，并且可以帮助开发者快速编写入门级证明代码。<details>
<summary>Abstract</summary>
Formal verification can provably guarantee the correctness of critical system software, but the high proof burden has long hindered its wide adoption. Recently, Large Language Models (LLMs) have shown success in code analysis and synthesis. In this paper, we present a combination of LLMs and static analysis to synthesize invariants, assertions, and other proof structures for a Rust-based formal verification framework called Verus. In a few-shot setting, LLMs demonstrate impressive logical ability in generating postconditions and loop invariants, especially when analyzing short code snippets. However, LLMs lack the ability to retain and propagate context information, a strength of traditional static analysis. Based on these observations, we developed a prototype based on OpenAI's GPT-4 model. Our prototype decomposes the verification task into multiple smaller ones, iteratively queries GPT-4, and combines its output with lightweight static analysis. We evaluated the prototype with a developer in the automation loop on 20 vector-manipulating programs. The results demonstrate that it significantly reduces human effort in writing entry-level proof code.
</details>
<details>
<summary>摘要</summary>
正式验证可以有可证明性地保证重要的系统软件正确性，但高证明负担长期间妨碍了它的广泛采用。现在，大型自然语言模型（LLM）在代码分析和生成方面表现出色。在这篇论文中，我们提出了结合LLM和静态分析的方法，用于生成 invariants、断言和其他证据结构，以适应基于Rust的正式验证框架Verus。在几个步骤的设定下，LLM示出了在分析短代码剖面时的卓越逻辑能力，特别是生成后置条件和循环 invariants。然而，LLM缺乏保持和传播上下文信息的能力，是传统静态分析的优点。基于这些观察，我们开发了一个基于OpenAI的GPT-4模型的原型。我们的原型将验证任务分解为多个更小的任务，逐步查询GPT-4，并将其输出与轻量级静态分析结合。我们对20个向量操作程序进行了测试，结果表明，它可以减少人类的证明代码写作努力。
</details></li>
</ul>
<hr>
<h2 id="deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning"><a href="#deep-REMAP-Parameterization-of-Stellar-Spectra-Using-Regularized-Multi-Task-Learning" class="headerlink" title="deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning"></a>deep-REMAP: Parameterization of Stellar Spectra Using Regularized Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03738">http://arxiv.org/abs/2311.03738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sankalp Gilda</li>
<li>for: 用于精准地测量恒星大气 Parameters (有效温度、表面重力和金属含量) 从观测 спектrum 中.</li>
<li>methods: 使用深度学习技术，包括多任务学习和创新的不对称损失函数，将 Phoenix 库中的辐射 Synthetic spectra 和 MARVELS survey 的观测数据作为输入，并使用 deep-REMAP 框架进行预测.</li>
<li>results: $\rm{deep-REMAP}$ 可以准确地预测恒星大气 Parameters，并且可以扩展到其他恒星库和特性。<details>
<summary>Abstract</summary>
Traditional spectral analysis methods are increasingly challenged by the exploding volumes of data produced by contemporary astronomical surveys. In response, we develop deep-Regularized Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference ($\rm{deep-REMAP}$), a novel framework that utilizes the rich synthetic spectra from the PHOENIX library and observational data from the MARVELS survey to accurately predict stellar atmospheric parameters. By harnessing advanced machine learning techniques, including multi-task learning and an innovative asymmetric loss function, $\rm{deep-REMAP}$ demonstrates superior predictive capabilities in determining effective temperature, surface gravity, and metallicity from observed spectra. Our results reveal the framework's effectiveness in extending to other stellar libraries and properties, paving the way for more sophisticated and automated techniques in stellar characterization.
</details>
<details>
<summary>摘要</summary>
传统的spectral分析方法随着现代天文学观测数据的急剧增长，日益面临挑战。为应对这一问题，我们开发了深度REGULARIZED Ensemble-based Multi-task Learning with Asymmetric Loss for Probabilistic Inference（深度-REMAP），一种新的框架，利用 Phoebe 图书馆中的辐射谱 synthetic spectra 和 MARVELS 观测数据，准确预测星际大气参数。通过应用先进的机器学习技术，包括多任务学习和创新的非对称损失函数，深度-REMAP 表现出了在确定效果温度、表面重力和金属含量方面的超越性Predictive 能力。我们的结果表明，这种框架可以扩展到其他星际图书馆和性能，为stellar 特征化提供更加复杂和自动化的技术。
</details></li>
</ul>
<hr>
<h2 id="Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning"><a href="#Neural-MMO-2-0-A-Massively-Multi-task-Addition-to-Massively-Multi-agent-Learning" class="headerlink" title="Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning"></a>Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03736">http://arxiv.org/abs/2311.03736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joseph Suárez, Phillip Isola, Kyoung Whan Choe, David Bloomin, Hao Xiang Li, Nikhil Pinnaparaju, Nishaanth Kanna, Daniel Scott, Ryan Sullivan, Rose S. Shuman, Lucas de Alcântara, Herbie Bradley, Louis Castricato, Kirsty You, Yuhao Jiang, Qimai Li, Jiaxin Chen, Xiaolong Zhu</li>
<li>for: 本研究用于探索多智能体环境下的强化学习问题。</li>
<li>methods: 本文使用Neural MMO 2.0平台，该平台具有灵活的任务系统，可以定制各种目标和奖励信号。</li>
<li>results: 本文比较了Neural MMO 2.0与前一版本的性能，发现其性能提高了三倍，并且与CleanRL兼容。<details>
<summary>Abstract</summary>
Neural MMO 2.0 is a massively multi-agent environment for reinforcement learning research. The key feature of this new version is a flexible task system that allows users to define a broad range of objectives and reward signals. We challenge researchers to train agents capable of generalizing to tasks, maps, and opponents never seen during training. Neural MMO features procedurally generated maps with 128 agents in the standard setting and support for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold improved performance and compatibility with CleanRL. We release the platform as free and open-source software with comprehensive documentation available at neuralmmo.github.io and an active community Discord. To spark initial research on this new platform, we are concurrently running a competition at NeurIPS 2023.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning"><a href="#ClimateSet-A-Large-Scale-Climate-Model-Dataset-for-Machine-Learning" class="headerlink" title="ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning"></a>ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03721">http://arxiv.org/abs/2311.03721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Kaltenborn, Charlotte E. E. Lange, Venkatesh Ramesh, Philippe Brouillard, Yaniv Gurwicz, Chandni Nagda, Jakob Runge, Peer Nowack, David Rolnick</li>
<li>for: 这项研究的目的是为气候科学家和机器学习专家提供一个大规模、一致的气候模型数据集，以支持气候变化的影响和未来气候enario的预测。</li>
<li>methods: 这项研究使用了Input4MIPs和CMIP6气候模型数据库中的36个气候模型的输入和输出，并提供了一个模块化的数据集管道，以便在不同的气候模型和enario下获取和处理数据。</li>
<li>results: 研究人员通过使用ClimateSet数据集作为ML模型投影的标准 benchmark，发现了不同的ML模型在不同的气候模型下的性能和泛化能力。此外，ClimateSet数据集还可以用于训练一个“超级 emulator”，以快速预测新的气候变化scenario，并补充现有的scenario，为政策制定者提供更多的选择。<details>
<summary>Abstract</summary>
Climate models have been key for assessing the impact of climate change and simulating future climate scenarios. The machine learning (ML) community has taken an increased interest in supporting climate scientists' efforts on various tasks such as climate model emulation, downscaling, and prediction tasks. Many of those tasks have been addressed on datasets created with single climate models. However, both the climate science and ML communities have suggested that to address those tasks at scale, we need large, consistent, and ML-ready climate model datasets. Here, we introduce ClimateSet, a dataset containing the inputs and outputs of 36 climate models from the Input4MIPs and CMIP6 archives. In addition, we provide a modular dataset pipeline for retrieving and preprocessing additional climate models and scenarios. We showcase the potential of our dataset by using it as a benchmark for ML-based climate model emulation. We gain new insights about the performance and generalization capabilities of the different ML models by analyzing their performance across different climate models. Furthermore, the dataset can be used to train an ML emulator on several climate models instead of just one. Such a "super emulator" can quickly project new climate change scenarios, complementing existing scenarios already provided to policymakers. We believe ClimateSet will create the basis needed for the ML community to tackle climate-related tasks at scale.
</details>
<details>
<summary>摘要</summary>
CLIMATE MODELS HAVE BEEN CRUCIAL FOR ASSESSING THE IMPACT OF CLIMATE CHANGE AND SIMULATING FUTURE CLIMATE SCENARIOS. THE MACHINE LEARNING (ML) COMMUNITY HAS TAKEN AN INCREASED INTEREST IN SUPPORTING CLIMATE SCIENTISTS' EFFORTS ON VARIOUS TASKS SUCH AS CLIMATE MODEL EMULATION, DOWNscaling, AND PREDICTION TASKS. MANY OF THOSE TASKS HAVE BEEN ADDRESSED ON DATASETS CREATED WITH SINGLE CLIMATE MODELS. HOWEVER, BOTH THE CLIMATE SCIENCE AND ML COMMUNITIES HAVE SUGGESTED THAT TO ADDRESS THOSE TASKS AT SCALE, WE NEED LARGE, CONSISTENT, AND ML-READY CLIMATE MODEL DATASETS. HERE, WE INTRODUCE CLIMATESET, A DATASET CONTAINING THE INPUTS AND OUTPUTS OF 36 CLIMATE MODELS FROM THE INPUT4MIPs AND CMIP6 ARCHIVES. IN ADDITION, WE PROVIDE A MODULAR DATASET PIPELINE FOR RETRIEVING AND PREPROCESSING ADDITIONAL CLIMATE MODELS AND SCENARIOS. WE SHOWCASE THE POTENTIAL OF OUR DATASET BY USING IT AS A BENCHMARK FOR ML-BASED CLIMATE MODEL EMULATION. WE GAIN NEW INSIGHTS ABOUT THE PERFORMANCE AND GENERALIZATION CAPABILITIES OF THE DIFFERENT ML MODELS BY ANALYZING THEIR PERFORMANCE ACROSS DIFFERENT CLIMATE MODELS. FURTHERMORE, THE DATASET CAN BE USED TO TRAIN AN ML EMULATOR ON SEVERAL CLIMATE MODELS INSTEAD OF JUST ONE. SUCH A "SUPER EMULATOR" CAN QUICKLY PROJECT NEW CLIMATE CHANGE SCENARIOS, COMPLEMENTING EXISTING SCENARIOS ALREADY PROVIDED TO POLICYMAKERS. WE BELIEVE CLIMATESET WILL CREATE THE BASIS NEEDED FOR THE ML COMMUNITY TO TACKLE CLIMATE-RELATED TASKS AT SCALE.
</details></li>
</ul>
<hr>
<h2 id="LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators"><a href="#LLM-as-an-Art-Director-LaDi-Using-LLMs-to-improve-Text-to-Media-Generators" class="headerlink" title="LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators"></a>LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media Generators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03716">http://arxiv.org/abs/2311.03716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Allen Roush, Emil Zakirov, Artemiy Shirokov, Polina Lunina, Jack Gane, Alexander Duffy, Charlie Basil, Aber Whitcomb, Jim Benedetto, Chris DeWolfe</li>
<li>for: 这 paper 旨在描述如何使用 Large Language Models (LLMs) 作为艺术指导，提高图像和视频生成的质量。</li>
<li>methods: 这 paper 使用多种技术来增强图像和视频生成器的能力，包括受限的解码、智能提示、精度调整和检索。</li>
<li>results: 这 paper 的实验结果表明，LaDi 系统可以帮助创建更加艺术一致和主题相关的图像和视频。<details>
<summary>Abstract</summary>
Recent advancements in text-to-image generation have revolutionized numerous fields, including art and cinema, by automating the generation of high-quality, context-aware images and video. However, the utility of these technologies is often limited by the inadequacy of text prompts in guiding the generator to produce artistically coherent and subject-relevant images. In this paper, We describe the techniques that can be used to make Large Language Models (LLMs) act as Art Directors that enhance image and video generation. We describe our unified system for this called "LaDi". We explore how LaDi integrates multiple techniques for augmenting the capabilities of text-to-image generators (T2Is) and text-to-video generators (T2Vs), with a focus on constrained decoding, intelligent prompting, fine-tuning, and retrieval. LaDi and these techniques are being used today in apps and platforms developed by Plai Labs.
</details>
<details>
<summary>摘要</summary>
In this paper, we introduce the techniques used to make Large Language Models (LLMs) act as Art Directors, enhancing image and video generation. Our unified system, called "LaDi", combines multiple methods to improve the capabilities of text-to-image generators (T2Is) and text-to-video generators (T2Vs), including constrained decoding, intelligent prompting, fine-tuning, and retrieval.LaDi and these techniques are currently being used in apps and platforms developed by Plai Labs. By leveraging the power of LLMs, we can create more sophisticated and artistic images and videos, pushing the boundaries of what is possible in the field of text-to-image generation.
</details></li>
</ul>
<hr>
<h2 id="Loss-Balancing-for-Fair-Supervised-Learning"><a href="#Loss-Balancing-for-Fair-Supervised-Learning" class="headerlink" title="Loss Balancing for Fair Supervised Learning"></a>Loss Balancing for Fair Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03714">http://arxiv.org/abs/2311.03714</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khalilimahdi/loss_balancing_icml2023">https://github.com/khalilimahdi/loss_balancing_icml2023</a></li>
<li>paper_authors: Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan</li>
<li>for: 本文旨在提出一种能够快速和精准地找到符合平等损失原则（Equalized Loss，EL）的最佳公平预测器。</li>
<li>methods: 本文提出了一种基于 convex programming 工具（如 CVXPY）的算法，可以快速地解决不等损失原则下的非 convex 优化问题。</li>
<li>results: 本文的算法可以准确地找到符合 EL 原则的最佳公平预测器，并且在几种实验中得到了证明。<details>
<summary>Abstract</summary>
Supervised learning models have been used in various domains such as lending, college admission, face recognition, natural language processing, etc. However, they may inherit pre-existing biases from training data and exhibit discrimination against protected social groups. Various fairness notions have been proposed to address unfairness issues. In this work, we focus on Equalized Loss (EL), a fairness notion that requires the expected loss to be (approximately) equalized across different groups. Imposing EL on the learning process leads to a non-convex optimization problem even if the loss function is convex, and the existing fair learning algorithms cannot properly be adopted to find the fair predictor under the EL constraint. This paper introduces an algorithm that can leverage off-the-shelf convex programming tools (e.g., CVXPY) to efficiently find the global optimum of this non-convex optimization. In particular, we propose the ELminimizer algorithm, which finds the optimal fair predictor under EL by reducing the non-convex optimization to a sequence of convex optimization problems. We theoretically prove that our algorithm finds the global optimal solution under certain conditions. Then, we support our theoretical results through several empirical studies.
</details>
<details>
<summary>摘要</summary>
超vised learning模型在不同领域中使用，如借款、大学招生、面部识别、自然语言处理等。然而，它们可能从训练数据中继承预先存在的偏见，并对保护社会群体中的人们产生歧视。各种公平性观念被提出来解决不公平问题。在这项工作中，我们关注Equalized Loss（EL），一种公平性观念，它要求不同群体的预期损失相对平等。在满足EL条件下，训练过程中的损失函数会变得不 convex。现有的公平学习算法无法正确地采用EL约束来找到公平预测器。本文介绍了一种可以利用现有的凸编程工具（如CVXPY）来高效地找到非凸优化问题的解。我们提出的ELminimizer算法可以在EL约束下找到最优公平预测器。我们理论上证明了我们的算法可以在某些条件下找到全球最优解。然后，我们通过一些实验研究来支持我们的理论结果。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning"><a href="#Mitigating-Estimation-Errors-by-Twin-TD-Regularized-Actor-and-Critic-for-Deep-Reinforcement-Learning" class="headerlink" title="Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning"></a>Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03711">http://arxiv.org/abs/2311.03711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junmin Zhong, Ruofan Wu, Jennie Si</li>
<li>for: 减少深度奖励学习（DRL）估计偏误</li>
<li>methods: 引入新的双TD-正则化演员评分（TDR）方法，以减少过估和under-估错误</li>
<li>results: TDR和distributional learning、LNSS方法结合使得新的演员评分学习方法在深度控制集成中表现出优于基eline，并将TD3和SAC等方法提升到与D4PG相当的水平，同时也提高了D4PG的表现。Translation:</li>
<li>for: Addressing the issue of estimation bias in deep reinforcement learning (DRL)</li>
<li>methods: Introducing a new, twin TD-regularized actor-critic (TDR) method to reduce both over and under-estimation errors</li>
<li>results: The TDR method, combined with distributional learning and LNSS, outperforms the baselines in challenging environments in the DeepMind Control Suite, elevating TD3 and SAC to a level comparable to D4PG, and improving D4PG’s performance to a new SOTA level in terms of mean reward, convergence speed, learning success rate, and learning variance.<details>
<summary>Abstract</summary>
We address the issue of estimation bias in deep reinforcement learning (DRL) by introducing solution mechanisms that include a new, twin TD-regularized actor-critic (TDR) method. It aims at reducing both over and under-estimation errors. With TDR and by combining good DRL improvements, such as distributional learning and long N-step surrogate stage reward (LNSS) method, we show that our new TDR-based actor-critic learning has enabled DRL methods to outperform their respective baselines in challenging environments in DeepMind Control Suite. Furthermore, they elevate TD3 and SAC respectively to a level of performance comparable to that of D4PG (the current SOTA), and they also improve the performance of D4PG to a new SOTA level measured by mean reward, convergence speed, learning success rate, and learning variance.
</details>
<details>
<summary>摘要</summary>
我们对深度强化学习（DRL）中的估计偏见进行了解决方案，包括一个新的双TD调整者-评估员（TDR）方法。这个方法目的是将过估和未估的错误减少。将TDR与其他好的DRL改进方法，如分布式学习和长N步代理阶段奖励（LNSS）方法，混合使用，我们发现了我们的新TDR基本actor-critic学习方法可以在深度控制套件中的具有挑战性环境中超越其基准。此外，它将TD3和SAC的表现提升到与D4PG（目前的SOTA）的水平，并且将D4PG的表现提升到新的SOTA水平， measured by mean reward, convergence speed, learning success rate, and learning variance。
</details></li>
</ul>
<hr>
<h2 id="The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade"><a href="#The-NeurIPS-2022-Neural-MMO-Challenge-A-Massively-Multiagent-Competition-with-Specialization-and-Trade" class="headerlink" title="The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade"></a>The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03707">http://arxiv.org/abs/2311.03707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enhong Liu, Joseph Suarez, Chenhui You, Bo Wu, Bingcheng Chen, Jun Hu, Jiaxin Chen, Xiaolong Zhu, Clare Zhu, Julian Togelius, Sharada Mohanty, Weijun Hong, Rui Du, Yibing Zhang, Qinwen Wang, Xinhang Li, Zheng Yuan, Xiang Li, Yuejia Huang, Kun Zhang, Hanhui Yang, Shiqi Tang, Phillip Isola</li>
<li>for: 这个论文描述了 NeurIPS-2022 神经网络多player挑战的结果，这个挑战吸引了500名参与者并收到了1,600份提交。</li>
<li>methods: 这个挑战使用了最新的 v1.6 神经网络多player环境，这个环境引入了新的设备、战斗、贸易和评价系统，这些元素共同提供了更多的鲁棒性和泛化挑战。</li>
<li>results: 这个论文描述了挑战的设计和结果，还explored了这个环境的可能性作为学习方法的标准 bencmark，并提供了一些实用的强化学习训练方法 для复杂任务。<details>
<summary>Abstract</summary>
In this paper, we present the results of the NeurIPS-2022 Neural MMO Challenge, which attracted 500 participants and received over 1,600 submissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved agents from 16 populations surviving in procedurally generated worlds by collecting resources and defeating opponents. This year's competition runs on the latest v1.6 Neural MMO, which introduces new equipment, combat, trading, and a better scoring system. These elements combine to pose additional robustness and generalization challenges not present in previous competitions. This paper summarizes the design and results of the challenge, explores the potential of this environment as a benchmark for learning methods, and presents some practical reinforcement learning training approaches for complex tasks with sparse rewards. Additionally, we have open-sourced our baselines, including environment wrappers, benchmarks, and visualization tools for future research.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了2022年的NeurIPS neural MMO挑战的结果，该挑战吸引了500名参与者并收到了1,600份提交。与前一年的IJCAI neural MMO挑战相同，这年的挑战中 agents从16个 популяции中生存在生成的世界中，收集资源和击败对手。这一年的比赛运行在最新的v1.6神经MMO上，新增了设备、战斗、贸易和评价系统。这些元素共同 pose 新的可靠性和泛化挑战，不存在在前一年的比赛中。本文总结了挑战的设计和结果，探讨了这种环境作为学习方法的标准 benchmark，并提出了一些实用的强化学习训练方法为复杂任务的稀衍奖励。此外，我们还开源了我们的基线，包括环境包装器、标准测试和可视化工具，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables"><a href="#Efficient-Bottom-Up-Synthesis-for-Programs-with-Local-Variables" class="headerlink" title="Efficient Bottom-Up Synthesis for Programs with Local Variables"></a>Efficient Bottom-Up Synthesis for Programs with Local Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03705">http://arxiv.org/abs/2311.03705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Li, Xiangyu Zhou, Rui Dong, Yihong Zhang, Xinyu Wang</li>
<li>for: 该论文旨在提出一种新的合成算法，能够效率地搜索具有本地变量（如lambda引入的程序）。</li>
<li>methods: 该算法使用提升 интерпрета器的想法，从一个程序一次性解释，提升到同时解释所有程序的语法树。这种方法可以系统地列出所有本地变量的绑定上下文，使得合成更快。</li>
<li>results: 该算法在网络自动化领域实现了成功，可以更高效地完成更多的复杂任务，比如WebRobot和Helena等现有技术。<details>
<summary>Abstract</summary>
We propose a new synthesis algorithm that can efficiently search programs with local variables (e.g., those introduced by lambdas). Prior bottom-up synthesis algorithms are not able to evaluate programs with free local variables, and therefore cannot effectively reduce the search space of such programs (e.g., using standard observational equivalence reduction techniques), making synthesis slow. Our algorithm can reduce the space of programs with local variables. The key idea, dubbed lifted interpretation, is to lift up the program interpretation process, from evaluating one program at a time to simultaneously evaluating all programs from a grammar. Lifted interpretation provides a mechanism to systematically enumerate all binding contexts for local variables, thereby enabling us to evaluate and reduce the space of programs with local variables. Our ideas are instantiated in the domain of web automation. The resulting tool, Arborist, can automate a significantly broader range of challenging tasks more efficiently than state-of-the-art techniques including WebRobot and Helena.
</details>
<details>
<summary>摘要</summary>
我们提出了一新的合成算法，可以效率地搜寻具有本地变数（例如 lambda 引入的）的程序。先前的底部合成算法无法评估具有自由本地变数的程序，因此无法有效缩小这些程序的搜寻空间（例如使用标准观察对等缩小技术），使合成变得慢。我们的算法可以缩小具有本地变数的程序的空间。我们的主要想法是将程序解释过程“升级”到同时评估所有程序的 grammar 中，这称为“提升解释”。提升解释提供了一个系统地列出所有本地变数的绑定上下文，因此可以实现评估和缩小具有本地变数的程序的空间。我们的想法在网页自动化领域中实现， Resulting tool Arborist 可以更高效地完成更多的具有挑战性的任务，比如 WebRobot 和 Helena 的技术。
</details></li>
</ul>
<hr>
<h2 id="Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation"><a href="#Hypothesis-Network-Planned-Exploration-for-Rapid-Meta-Reinforcement-Learning-Adaptation" class="headerlink" title="Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation"></a>Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement Learning Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03701">http://arxiv.org/abs/2311.03701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxwell Joseph Jacobson, Yexiang Xue</li>
<li>for: 增强循环学习的适应能力，使agent能够适应快速变化的环境和任务。</li>
<li>methods:  integrate an active and planned exploration process via the hypothesis network to optimize adaptation speed, using a generative hypothesis network to form potential models of state transition dynamics, then eliminating incorrect models through strategically devised experiments.</li>
<li>results: 在一个符号化的Alchemy游戏中，HyPE方法比基线方法更快地适应和更准确地模型状态转移动力学， Validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings.<details>
<summary>Abstract</summary>
Meta Reinforcement Learning (Meta RL) trains agents that adapt to fast-changing environments and tasks. Current strategies often lose adaption efficiency due to the passive nature of model exploration, causing delayed understanding of new transition dynamics. This results in particularly fast-evolving tasks being impossible to solve. We propose a novel approach, Hypothesis Network Planned Exploration (HyPE), that integrates an active and planned exploration process via the hypothesis network to optimize adaptation speed. HyPE uses a generative hypothesis network to form potential models of state transition dynamics, then eliminates incorrect models through strategically devised experiments. Evaluated on a symbolic version of the Alchemy game, HyPE outpaces baseline methods in adaptation speed and model accuracy, validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate_language: zh-CNMeta Reinforcement Learning (Meta RL) 训练代理人 adapt to 快速变化环境和任务。当前策略常常因模型探索的 pasive 性而导致适应率下降，从而导致特别快速演化的任务无法解决。我们提出了一种新的方法，假设网络规划探索 (HyPE)，它通过假设网络来整合活跃和规划探索过程，以优化适应速度。HyPE 使用生成假设网络来构建状态转移动力学模型，然后通过策划的实验排除错误模型。在使用 symbolic 版本的 Alchemy 游戏进行评估中，HyPE 在适应速度和模型准确率方面胜过基准方法，证明其在快速演化的设置中增强了学习适应能力。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning"><a href="#A-Novel-Variational-Lower-Bound-for-Inverse-Reinforcement-Learning" class="headerlink" title="A Novel Variational Lower Bound for Inverse Reinforcement Learning"></a>A Novel Variational Lower Bound for Inverse Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03698">http://arxiv.org/abs/2311.03698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikang Gui, Prashant Doshi</li>
<li>for: 学习任务和协同努力的 reward 函数，从专家轨迹中学习，以实现无需人工奖励工程。</li>
<li>methods: 基于 probabilistic graphical model 和优化节点的 Variational Lower Bound for IRL (VLB-IRL)，同时学习奖励函数和Policy。</li>
<li>results: 在多个知名领域中，比如游戏和 робоット学习等，超过了现有的状态 искус�imum IRL 算法，并且通过 demonstrating better reward from the learned policy 来证明了学习的有效性。<details>
<summary>Abstract</summary>
Inverse reinforcement learning (IRL) seeks to learn the reward function from expert trajectories, to understand the task for imitation or collaboration thereby removing the need for manual reward engineering. However, IRL in the context of large, high-dimensional problems with unknown dynamics has been particularly challenging. In this paper, we present a new Variational Lower Bound for IRL (VLB-IRL), which is derived under the framework of a probabilistic graphical model with an optimality node. Our method simultaneously learns the reward function and policy under the learned reward function by maximizing the lower bound, which is equivalent to minimizing the reverse Kullback-Leibler divergence between an approximated distribution of optimality given the reward function and the true distribution of optimality given trajectories. This leads to a new IRL method that learns a valid reward function such that the policy under the learned reward achieves expert-level performance on several known domains. Importantly, the method outperforms the existing state-of-the-art IRL algorithms on these domains by demonstrating better reward from the learned policy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> invert reinforcement learning (IRL) 目的是从专家轨迹中学习奖励函数，以便理解任务并模仿或协作，从而消除手动奖励工程化的需求。然而，在大型、高维度问题中， unknown dynamics 下的 IRL 特别困难。在这篇论文中，我们提出了一种新的 Variational Lower Bound for IRL (VLB-IRL)，它是基于 probabilistic graphical model 中的 optimality node 框架 derivation。我们的方法同时学习奖励函数和策略，以便在学习到奖励函数后，Policy 可以达到专家水平的表现。我们的方法通过最大化下界来实现这一目标，下界等于将 approximated distribution of optimality 与 true distribution of optimality 的 Kullback-Leibler divergence inverse。这导致了一种新的 IRL 方法，该方法可以学习一个有效的奖励函数，使得 Policy 根据学习到的奖励函数达到专家水平的表现。更重要的是，我们的方法在已知领域上超过了现有的 state-of-the-art IRL 算法的表现， demonstrating better reward from the learned policy。>>>
</details></li>
</ul>
<hr>
<h2 id="Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning"><a href="#Context-Shift-Reduction-for-Offline-Meta-Reinforcement-Learning" class="headerlink" title="Context Shift Reduction for Offline Meta-Reinforcement Learning"></a>Context Shift Reduction for Offline Meta-Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03695">http://arxiv.org/abs/2311.03695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moreanp/csro">https://github.com/moreanp/csro</a></li>
<li>paper_authors: Yunkai Gao, Rui Zhang, Jiaming Guo, Fan Wu, Qi Yi, Shaohui Peng, Siming Lan, Ruizhi Chen, Zidong Du, Xing Hu, Qi Guo, Ling Li, Yunji Chen</li>
<li>for: 提高 meta-学习 agents 的通用能力。</li>
<li>methods: 使用 max-min 矩阵嵌入学习机制和非假先导收集策略来减少政策的影响。</li>
<li>results: 在多个复杂的领域中，CSRO 能够显著减少上下文偏移并提高通用能力，超过先前的方法。<details>
<summary>Abstract</summary>
Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline datasets to enhance the agent's generalization ability on unseen tasks. However, the context shift problem arises due to the distribution discrepancy between the contexts used for training (from the behavior policy) and testing (from the exploration policy). The context shift problem leads to incorrect task inference and further deteriorates the generalization ability of the meta-policy. Existing OMRL methods either overlook this problem or attempt to mitigate it with additional information. In this paper, we propose a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem with only offline datasets. The key insight of CSRO is to minimize the influence of policy in context during both the meta-training and meta-test phases. During meta-training, we design a max-min mutual information representation learning mechanism to diminish the impact of the behavior policy on task representation. In the meta-test phase, we introduce the non-prior context collection strategy to reduce the effect of the exploration policy. Experimental results demonstrate that CSRO significantly reduces the context shift and improves the generalization ability, surpassing previous methods across various challenging domains."into Simplified Chinese:Offline meta-学习（OMRL）利用预收集的下载数据来提高智能体的未经见任务总结能力。然而，上下文差异问题出现，由于训练上下文（从行为策略）和测试上下文（从探索策略）的数据分布不一致。这会导致任务推断错误，并进一步下降meta策略的总结能力。现有OMRL方法可能忽略这个问题，或者尝试通过额外信息来缓解。在这篇论文中，我们提出了一种新的方法called Context Shift Reduction for OMRL（CSRO），用于解决上下文差异问题，只使用下载数据。CSRO的关键思想是在meta训练和meta测试阶段都尽量减少策略对上下文的影响。在meta训练阶段，我们设计了max-min共享信息学习机制，以减少行为策略对任务表示的影响。在meta测试阶段，我们引入了非先验上下文收集策略，以减少探索策略对上下文的影响。实验结果表明，CSRO可以减少上下文差异，提高总结能力，超越了前一些难度更高的领域。
</details></li>
</ul>
<hr>
<h2 id="Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking"><a href="#Deep-Bayesian-Reinforcement-Learning-for-Spacecraft-Proximity-Maneuvers-and-Docking" class="headerlink" title="Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking"></a>Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers and Docking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03680">http://arxiv.org/abs/2311.03680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Desong Du, Naiming Qi, Yanfang Liu, Wei Pan</li>
<li>for: 这个研究是为了解决自主太空船的近距离运动和对接（PMD）任务中的控制策略，并提供稳定性保证。</li>
<li>methods: 本研究使用了一种新的 bayesian actor-critic reinforcement learning算法，将控制策略表示为一个 Lyapunov 函数，并通过对问题进行几何加速来实现。</li>
<li>results: 实验结果显示，提出的算法在太空船空滑试验平台上表现出色，并且具有优秀的稳定性和可靠性。<details>
<summary>Abstract</summary>
In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD), we introduce a novel Bayesian actor-critic reinforcement learning algorithm to learn a control policy with the stability guarantee. The PMD task is formulated as a Markov decision process that reflects the relative dynamic model, the docking cone and the cost function. Drawing from the principles of Lyapunov theory, we frame the temporal difference learning as a constrained Gaussian process regression problem. This innovative approach allows the state-value function to be expressed as a Lyapunov function, leveraging the Gaussian process and deep kernel learning. We develop a novel Bayesian quadrature policy optimization procedure to analytically compute the policy gradient while integrating Lyapunov-based stability constraints. This integration is pivotal in satisfying the rigorous safety demands of spaceflight missions. The proposed algorithm has been experimentally evaluated on a spacecraft air-bearing testbed and shows impressive and promising performance.
</details>
<details>
<summary>摘要</summary>
在探索自主宇宙飞船靠近和停机（PMD）中，我们提出了一种新的 Bayesianactor-critic reinforcement学习算法，以学习一个具有稳定保证的控制策略。 PMD任务被表示为一个Markov决策过程，这个过程反映了相对动态模型、停机 cone 以及成本函数。 基于Lyapunov理论，我们将时间差学习转换为一个受限Gaussian process regression问题。这种创新的方法使得状态价值函数可以表示为Lyapunov函数，利用Gaussian process和深度kernel学习。我们开发了一种 Bayesianquadrature策略优化过程，以分析计算策略偏导数，同时满足Lyapunov基础的稳定性限制。这种稳定性限制是Spaceflight任务中的严格安全要求的保证。我们的提案已经在宇宙飞船空气托器上进行了实验，并表现出了惊喜和漫漫的表现。
</details></li>
</ul>
<hr>
<h2 id="Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning"><a href="#Stable-Modular-Control-via-Contraction-Theory-for-Reinforcement-Learning" class="headerlink" title="Stable Modular Control via Contraction Theory for Reinforcement Learning"></a>Stable Modular Control via Contraction Theory for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03669">http://arxiv.org/abs/2311.03669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bing Song, Jean-Jacques Slotine, Quang-Cuong Pham</li>
<li>for: 本研究旨在将控制技术与强化学习（RL）结合，以确保稳定性、可靠性和泛化性。</li>
<li>methods: 本研究提出了一种新的方法，利用Contract Theory来实现模块化控制，使得将稳定的子系统组合起来可以保持稳定性。这种模块化控制通过信号组合和动态分解实现。</li>
<li>results: 本研究通过实验表明，使用本方法可以提高层次RL的性能，并且可以保持稳定性和泛化性。<details>
<summary>Abstract</summary>
We propose a novel way to integrate control techniques with reinforcement learning (RL) for stability, robustness, and generalization: leveraging contraction theory to realize modularity in neural control, which ensures that combining stable subsystems can automatically preserve the stability. We realize such modularity via signal composition and dynamic decomposition. Signal composition creates the latent space, within which RL applies to maximizing rewards. Dynamic decomposition is realized by coordinate transformation that creates an auxiliary space, within which the latent signals are coupled in the way that their combination can preserve stability provided each signal, that is, each subsystem, has stable self-feedbacks. Leveraging modularity, the nonlinear stability problem is deconstructed into algebraically solvable ones, the stability of the subsystems in the auxiliary space, yielding linear constraints on the input gradients of control networks that can be as simple as switching the signs of network weights. This minimally invasive method for stability allows arguably easy integration into the modular neural architectures in machine learning, like hierarchical RL, and improves their performance. We demonstrate in simulation the necessity and the effectiveness of our method: the necessity for robustness and generalization, and the effectiveness in improving hierarchical RL for manipulation learning.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，将控制技术与强化学习（RL）结合起来，以确保稳定性、可靠性和通用性：通过ontraction theory来实现模块化在神经控制中，以确保将稳定的子系统组合起来，可以保持稳定性。我们通过信号组合和动态分解来实现模块化。信号组合创造了隐藏空间，在这个空间中，RL可以最大化奖励。动态分解通过坐标变换来创造一个辅助空间，在这个空间中，隐藏信号被联系在一起，以保持稳定性，条件是每个信号，即每个子系统，都有稳定的自反馈。通过模块化，非线性稳定性问题被拆分成可解的问题，即每个子系统的稳定性问题在auxiliary space中，导致输入梯度的控制网络的线性约束，可以非常简单地是将网络权重的信号改变。这种非常少的改变方法可以轻松地 интеGRATE到现有的模块化神经网络架构中，如层次RL，并提高其性能。我们在模拟中证明了我们的方法的必要性和有效性：必要性是为了稳定性和通用性，有效性是在对掌控学习进行改进。
</details></li>
</ul>
<hr>
<h2 id="The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models"><a href="#The-Linear-Representation-Hypothesis-and-the-Geometry-of-Large-Language-Models" class="headerlink" title="The Linear Representation Hypothesis and the Geometry of Large Language Models"></a>The Linear Representation Hypothesis and the Geometry of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03658">http://arxiv.org/abs/2311.03658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiho Park, Yo Joong Choe, Victor Veitch</li>
<li>for: 本研究旨在解释“线性表示”的含义，以及如何在表示空间中理解几何概念（如cosine相似性或投影）。</li>
<li>methods: 本研究使用 counterfactuals 来给出两种“线性表示”的正式定义，一种在输出（单词）表示空间中，另一种在输入（句子）空间中。然后，使用这些定义来连接到线性探针和模型导航。</li>
<li>results: 通过使用 counterfactual pairs，本研究显示了线性表示的概念的存在，以及与解释和控制的连接。此外，研究还表明了选择内积的重要性，并通过实验验证了 LLMA-2 模型的性能。<details>
<summary>Abstract</summary>
Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of "linear representation", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.
</details>
<details>
<summary>摘要</summary>
文中提出了一个称为“线性表示假设”的想法，即高级概念是在某种表示空间中线性表示的。在这篇论文中，我们考虑了两个相关的问题：“线性表示”的具体意思是什么？以及在表示空间中的几何概念（如cosine相似性或投影）是如何理解的？为了回答这些问题，我们使用counterfactual语言来给出了两种对“线性表示”的正式定义，一种在输出（词）表示空间中，另一种在输入（句子）空间中。然后我们证明这两种定义与直探和模型导航相连接。为了理解几何概念，我们使用这些定义来确定一种特殊的非欧几何内积，该内积满足语言结构的一定条件。使用这种 causal 内积，我们可以将所有的线性表示概念统一起来。具体来说，这允许我们使用counterfactual对来构建探测器和导航向量。LLaMA-2实验表明了线性表示的存在、相关性和内积的选择对语言理解和控制的重要性。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme"><a href="#Machine-Learning-Parameterization-of-the-Multi-scale-Kain-Fritsch-MSKF-Convection-Scheme" class="headerlink" title="Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme"></a>Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF) Convection Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03652">http://arxiv.org/abs/2311.03652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohui Zhong, Xing Yu, Hao Li<br>for: 这个研究旨在测试一种基于机器学习（ML）模型的气象预报模型，以取代传统的物理参数化方法。methods: 研究使用了一种多出力对称长短Term Memory（Bi-LSTM）模型，并与气象预报模型（WRF）相互运行。results: 研究结果显示，Bi-LSTM模型可以实现高精度，表明ML模型可以取代传统的物理参数化方法。<details>
<summary>Abstract</summary>
Warm-sector heavy rainfall often occurs along the coast of South China, and it is usually localized and long-lasting, making it challenging to predict. High-resolution numerical weather prediction (NWP) models are increasingly used to better resolve topographic features and forecast such high-impact weather events. However, when the grid spacing becomes comparable to the length scales of convection, known as the gray zone, the turbulent eddies in the atmospheric boundary layer are only partially resolved and parameterized to some extent. Whether using a convection parameterization (CP) scheme in the gray zone remains controversial. Scale-aware CP schemes are developed to enhance the representation of convective transport within the gray zone. The multi-scale Kain-Fritsch (MSKF) scheme includes modifications that allow for its effective implementation at a grid resolution as high as 2 km. In recent years, there has been an increasing application of machine learning (ML) models to various domains of atmospheric sciences, including the replacement of physical parameterizations with ML models. This work proposes a multi-output bidirectional long short-term memory (Bi-LSTM) model as a replace the scale-aware MSKF CP scheme. The Weather Research and Forecast (WRF) model is used to generate training and testing data over South China at a horizontal resolution of 5 km. Furthermore, the WRF model is coupled with the ML based CP scheme and compared with WRF simulations with original MSKF scheme. The results demonstrate that the Bi-LSTM model can achieve high accuracy, indicating the potential use of ML models to substitute the MSKF scheme in the gray zone.
</details>
<details>
<summary>摘要</summary>
暖 sector 重降水 часто发生在南中国沿海地区，通常是局部化和长时间的，预测具有挑战性。高分解能数值天气预测模型（NWP）已经越来越被用来更好地解析地形特征并预测这些高影响天气事件。然而，当网格间距相当于气团尺度时，称为灰色区域，大气界面层中的液体摇树只部分解析并被部分参数化。使用气动参数化（CP）算法在灰色区域是有争议的。基于尺度意识的CP算法被开发以提高在灰色区域中的液体运输表现。多尺度Kain-Fritsch（MSKF）算法包括修改，以便在2 km的网格分辨率下实现有效。在过去几年中，机器学习（ML）模型在大气科学领域中的应用越来越普遍，包括替代物理参数化的ML模型。本研究提出了一种多输出双向长短期记忆（Bi-LSTM）模型，用于取代尺度意识的MSKF CP算法。使用Weather Research and Forecast（WRF）模型生成训练和测试数据，并将WRF模型与ML基于CP算法相couple。结果表明，Bi-LSTM模型可以 дости得高准确率，表明ML模型可以在灰色区域中取代MSKF算法。
</details></li>
</ul>
<hr>
<h2 id="SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations"><a href="#SeRO-Self-Supervised-Reinforcement-Learning-for-Recovery-from-Out-of-Distribution-Situations" class="headerlink" title="SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations"></a>SeRO: Self-Supervised Reinforcement Learning for Recovery from Out-of-Distribution Situations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03651">http://arxiv.org/abs/2311.03651</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snuchankim/sero">https://github.com/snuchankim/sero</a></li>
<li>paper_authors: Chan Kim, Jaekyung Cho, Christophe Bobda, Seung-Woo Seo, Seong-Woo Kim</li>
<li>for: 解决机器人代理人在异常情况下（out-of-distribution，OOD）行为不可靠的问题。</li>
<li>methods: 提出了一种自然语言学习方法，使代理人在OOD状态下重新训练以恢复原始任务性能。</li>
<li>results: 实验结果表明，该方法可以substantially提高代理人在OOD状态下恢复原始任务性能的效率和可靠性，并且可以在难以探索的IN Distribution状态下重新训练代理人。<details>
<summary>Abstract</summary>
Robotic agents trained using reinforcement learning have the problem of taking unreliable actions in an out-of-distribution (OOD) state. Agents can easily become OOD in real-world environments because it is almost impossible for them to visit and learn the entire state space during training. Unfortunately, unreliable actions do not ensure that agents perform their original tasks successfully. Therefore, agents should be able to recognize whether they are in OOD states and learn how to return to the learned state distribution rather than continue to take unreliable actions. In this study, we propose a novel method for retraining agents to recover from OOD situations in a self-supervised manner when they fall into OOD states. Our in-depth experimental results demonstrate that our method substantially improves the agent's ability to recover from OOD situations in terms of sample efficiency and restoration of the performance for the original tasks. Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration.
</details>
<details>
<summary>摘要</summary>
机器人代理人使用强化学习受训时会面临异常状态（out-of-distribution，OOD）下的不可靠行为问题。因为实际环境中很难让代理人在训练时访问整个状态空间，因此代理人容易陷入OOD状态。不幸的是，不可靠的行为并不能确保代理人完成原始任务成功。因此，代理人应该能够识别自己是否处于OOD状态，并学习返回学习过的状态分布而不是继续执行不可靠的行为。在这项研究中，我们提出了一种基于自我监督的方法，可以在OOD状态下重新训练代理人，以便在OOD状态下恢复原始任务的性能。我们的实验结果表明，我们的方法可以很快地提高代理人在OOD状态下的恢复能力，并且可以在难以探索的状态下重新训练代理人。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach"><a href="#Analysis-of-the-User-Perception-of-Chatbots-in-Education-Using-A-Partial-Least-Squares-Structural-Equation-Modeling-Approach" class="headerlink" title="Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach"></a>Analysis of the User Perception of Chatbots in Education Using A Partial Least Squares Structural Equation Modeling Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03636">http://arxiv.org/abs/2311.03636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Rabiul Hasan, Nahian Ismail Chowdhury, Md Hadisur Rahman, Md Asif Bin Syed, JuHyeong Ryu</li>
<li>for: 本研究旨在探讨学生对教育中的 chatbot 的使用情况，尤其是 Large Language Model (LLM) 技术如 Chat Generative Pretrained Transformer (ChatGPT) 和 Google Bard 等交互式人工智能技术在教育中的采用。</li>
<li>methods: 本研究使用 Partial Least Squares Structural Equation Modeling (PLS-SEM) 方法 investigate 学生对 chatbot 的采用，考虑技术就绪指数 (TRI) 和技术接受度模型 (TAM)。数据采集使用 five-point Likert 级，共收集到 185 个答案，使用 R-Studio 软件进行分析。</li>
<li>results: 研究结果显示，optimism 和创新性都对 Perceived Ease of Use (PEOU) 和 Perceived Usefulness (PU) 表现正相关，而不适和不安全度则对 PEOU 表现负相关，只有不安全度对 PU 表现负影响。这些发现可以帮助未来的技术设计师，提供关键的用户行为因素，以便更好地理解学生对 chatbot 的采用和利用情况。<details>
<summary>Abstract</summary>
The integration of Artificial Intelligence (AI) into education is a recent development, with chatbots emerging as a noteworthy addition to this transformative landscape. As online learning platforms rapidly advance, students need to adapt swiftly to excel in this dynamic environment. Consequently, understanding the acceptance of chatbots, particularly those employing Large Language Model (LLM) such as Chat Generative Pretrained Transformer (ChatGPT), Google Bard, and other interactive AI technologies, is of paramount importance. However, existing research on chatbots in education has overlooked key behavior-related aspects, such as Optimism, Innovativeness, Discomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and Accuracy, creating a significant literature gap. To address this gap, this study employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to investigate the determinant of chatbots adoption in education among students, considering the Technology Readiness Index (TRI) and Technology Acceptance Model (TAM). Utilizing a five-point Likert scale for data collection, we gathered a total of 185 responses, which were analyzed using R-Studio software. We established 12 hypotheses to achieve its objectives. The results showed that Optimism and Innovativeness are positively associated with Perceived Ease of Use (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity negatively impact PEOU, with only Insecurity negatively affecting PU. These findings provide insights for future technology designers, elucidating critical user behavior factors influencing chatbots adoption and utilization in educational contexts.
</details>
<details>
<summary>摘要</summary>
学术界最近才开始启用人工智能（AI），聊天机器人（chatbot）是这一变革的一个显著添加。在在线学习平台快速进步的情况下，学生需要快速适应，因此理解聊天机器人的acceptance，特别是使用大语言模型（LLM）的聊天机器人，如Chat Generative Pretrained Transformer（ChatGPT）、Google Bard等交互式AI技术的acceptance，是非常重要的。然而，现有关于聊天机器人在教育中的研究，忽略了关键的行为相关方面，如乐观性、创新性、不适感、不安全感、透明度、伦理、交互、参与度和准确性，这创造了一个重要的文献差距。为了填补这个差距，本研究使用部分最小二乘方程模型（PLS-SEM）调查聊天机器人在教育中的采用，考虑技术 readiness index（TRI）和技术接受度模型（TAM）。通过五点likert分级的数据收集，我们总共收集了185个答案，并使用RStudio软件分析。我们设置了12个假设，以达到研究的目标。结果显示，乐观性和创新性 positively associated with perceived ease of use（PEOU）和 perceived usefulness（PU），而不适感和不安全感 negatively impact PEOU，只有不安全感 negatively affecting PU。这些发现为未来技术设计师提供了新的思路，揭示了在教育上的聊天机器人采用和利用中的关键用户行为因素。
</details></li>
</ul>
<hr>
<h2 id="TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer"><a href="#TWIST-Teacher-Student-World-Model-Distillation-for-Efficient-Sim-to-Real-Transfer" class="headerlink" title="TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer"></a>TWIST: Teacher-Student World Model Distillation for Efficient Sim-to-Real Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03622">http://arxiv.org/abs/2311.03622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Yamada, Marc Rigter, Jack Collins, Ingmar Posner</li>
<li>for: 这个论文旨在提出一种能够有效地实现模型基于RL中的 sim-to-real 转移的方法，以便在实际世界中应用vision-based模型基于RL。</li>
<li>methods: 该论文提出了一种名为 TWIST（教师学生世界模型填充法）的方法，该方法通过填充教师世界模型中学习的秘密动力学模型到学生世界模型中来实现高效的sim-to-real转移。</li>
<li>results: 实验结果表明，相比于Randomization的标准方法和模型自由RL方法，TWIST方法在模型基于RL中的sim-to-real转移中具有更高的效率和更好的任务性能。<details>
<summary>Abstract</summary>
Model-based RL is a promising approach for real-world robotics due to its improved sample efficiency and generalization capabilities compared to model-free RL. However, effective model-based RL solutions for vision-based real-world applications require bridging the sim-to-real gap for any world model learnt. Due to its significant computational cost, standard domain randomisation does not provide an effective solution to this problem. This paper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real Transfer) to achieve efficient sim-to-real transfer of vision-based model-based RL using distillation. Specifically, TWIST leverages state observations as readily accessible, privileged information commonly garnered from a simulator to significantly accelerate sim-to-real transfer. Specifically, a teacher world model is trained efficiently on state information. At the same time, a matching dataset is collected of domain-randomised image observations. The teacher world model then supervises a student world model that takes the domain-randomised image observations as input. By distilling the learned latent dynamics model from the teacher to the student model, TWIST achieves efficient and effective sim-to-real transfer for vision-based model-based RL tasks. Experiments in simulated and real robotics tasks demonstrate that our approach outperforms naive domain randomisation and model-free methods in terms of sample efficiency and task performance of sim-to-real transfer.
</details>
<details>
<summary>摘要</summary>
模型基于RL是现实世界机器人控制中有前途的方法，因其在样本效率和泛化能力方面比模型自由RL更出色。然而，为实际视觉应用场景中的模型基于RL解决方案，需要跨 sim-to-real 隔目拟合，以便将任何世界模型学习到实际世界中。由于其计算成本很高，标准的随机化Domain不提供有效的解决方案。本文提出了TWIST（教师学生世界模型精炼 для sim-to-real 传输）来实现高效的 sim-to-real 传输。specifically，TWIST 利用状态观察得到了可以轻松地获得的、特权信息，通常来自模拟器中获得。特别是，一个教师世界模型在状态信息上进行高效地训练。同时，一个匹配的数据集被收集了，其中包含了随机化的图像观察。然后，教师世界模型监督学生世界模型使用随机化的图像观察作为输入。通过在教师模型中学习的latent动力模型的精炼，TWIST 实现了高效和有效的 sim-to-real 传输。实验表明，我们的方法在模拟和实际机器人控制任务中比随机化Domain和模型自由RL方法更高效和有更好的任务性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.AI_2023_11_07/" data-id="cloqtaene006rgh88hlur71kt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.CL_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T11:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.CL_2023_11_07/">cs.CL - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study"><a href="#Exploring-Recommendation-Capabilities-of-GPT-4V-ision-A-Preliminary-Case-Study" class="headerlink" title="Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study"></a>Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04199">http://arxiv.org/abs/2311.04199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peilin Zhou, Meng Cao, You-Liang Huang, Qichen Ye, Peiyan Zhang, Junling Liu, Yueqi Xie, Yining Hua, Jaeboum Kim</li>
<li>for: 这研究旨在探索使用OpenAI发布的GPT-4V大型多Modal模型（LMMs）在推荐任务中的应用潜力。</li>
<li>methods: 我们使用了一系列质量测试样本，来评估GPT-4V在推荐场景中的回答质量。</li>
<li>results: 我们发现GPT-4V在多个领域的推荐任务中表现出色，归功于它的视觉文本理解能力和广泛的通用知识。但我们还发现GPT-4V在推荐任务中存在一些局限性，如给定相似输入时提供相似的回答。<details>
<summary>Abstract</summary>
Large Multimodal Models (LMMs) have demonstrated impressive performance across various vision and language tasks, yet their potential applications in recommendation tasks with visual assistance remain unexplored. To bridge this gap, we present a preliminary case study investigating the recommendation capabilities of GPT-4V(ison), a recently released LMM by OpenAI. We construct a series of qualitative test samples spanning multiple domains and employ these samples to assess the quality of GPT-4V's responses within recommendation scenarios. Evaluation results on these test samples prove that GPT-4V has remarkable zero-shot recommendation abilities across diverse domains, thanks to its robust visual-text comprehension capabilities and extensive general knowledge. However, we have also identified some limitations in using GPT-4V for recommendations, including a tendency to provide similar responses when given similar inputs. This report concludes with an in-depth discussion of the challenges and research opportunities associated with utilizing GPT-4V in recommendation scenarios. Our objective is to explore the potential of extending LMMs from vision and language tasks to recommendation tasks. We hope to inspire further research into next-generation multimodal generative recommendation models, which can enhance user experiences by offering greater diversity and interactivity. All images and prompts used in this report will be accessible at https://github.com/PALIN2018/Evaluate_GPT-4V_Rec.
</details>
<details>
<summary>摘要</summary>
大型多Modal模型（LMM）已经在视觉和语言任务上表现出色，但它们在推荐任务中的应用前景尚未得到探索。为了填补这个空白，我们提出了一项初步的案例研究，检查GPT-4V（ison），一个最近发布的LMM，在推荐任务中的表现。我们构建了多个qualitative测试样本，覆盖多个领域，并使用这些样本来评估GPT-4V在推荐场景中的回答质量。eval结果表明，GPT-4V在多个领域的零批 recommendation能力非常出色，归功于它的强大的视觉文本理解能力和广泛的通用知识。然而，我们还发现了使用GPT-4V进行推荐时的一些局限性，包括对输入相似的回答倾向于相似。本报告结束于对使用GPT-4V进行推荐的挑战和研究机遇的深入讨论。我们的目标是探索如何扩展LMM从视觉和语言任务到推荐任务，以提高用户体验，并且提供更多的多样性和互动性。所有图像和提示用于这份报告将在GitHub上公开，请参考https://github.com/PALIN2018/Evaluate_GPT-4V_Rec。
</details></li>
</ul>
<hr>
<h2 id="JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models"><a href="#JaSPICE-Automatic-Evaluation-Metric-Using-Predicate-Argument-Structures-for-Image-Captioning-Models" class="headerlink" title="JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models"></a>JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04192">http://arxiv.org/abs/2311.04192</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/keio-smilab23/JaSPICE">https://github.com/keio-smilab23/JaSPICE</a></li>
<li>paper_authors: Yuiga Wada, Kanta Kaneda, Komei Sugiura</li>
<li>for: 本研究旨在提出一种用于评估日语描述文本的自动评价指标，以提高现有的自动评价指标的准确性。</li>
<li>methods: 本研究使用了依赖关系和 predicate-argument 结构生成场景图，并使用同义词扩展图。</li>
<li>results: 我们在使用 STAIR Captions 和 PFN-PIC 进行训练的 10 个图像描述模型上进行了实验，并构建了 Shichimi 数据集，其包含 103,170 个人评估。结果表明，我们的指标在与人类评估的相关系数上表现出了优异性。<details>
<summary>Abstract</summary>
Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR. However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages. Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms. We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations. The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation.
</details>
<details>
<summary>摘要</summary>
研究者强调图像描述学 heavily rely 于自动评估指标，如 BLEU 和 METEOR。但是，这些 n-gram 基的指标与人工评估相关性很差，导致提出了替代指标，如 SPICE  для英语。然而，其他语言没有相应的指标。因此，在这种研究中，我们提议一种自动评估指标，即 JaSPICE，该指标基于场景图和依赖关系。我们的方法从依赖关系和 predicate-argument 结构中生成场景图，并使用同义词扩展图。我们在 STAIR Captions 和 PFN-PIC 上训练了 10 个图像描述模型，并建立了 Shichimi 数据集，该数据集包含 103,170 个人工评估。结果表明，我们的指标在人工评估相关性方面与基准指标相比，表现出了更高的拟合度。
</details></li>
</ul>
<hr>
<h2 id="SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish"><a href="#SpaDeLeF-A-Dataset-for-Hierarchical-Classification-of-Lexical-Functions-for-Collocations-in-Spanish" class="headerlink" title="SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish"></a>SpaDeLeF: A Dataset for Hierarchical Classification of Lexical Functions for Collocations in Spanish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04189">http://arxiv.org/abs/2311.04189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yevhen Kostiuk, Grigori Sidorov, Olga Kolesnikova</li>
<li>For:  This paper presents a dataset of Spanish verb-noun collocations and their corresponding lexical functions, aiming to support the development of language models for hierarchical classification of lexical functions.* Methods: The dataset was created by dependency tree parsing and matching of phrases in Spanish news, and each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task.* Results: The paper introduces classification objectives for each level of the structure and provides baselines and data splits for each objective, aiming to support the development of effective language models for Spanish text.<details>
<summary>Abstract</summary>
In natural language processing (NLP), lexical function is a concept to unambiguously represent semantic and syntactic features of words and phrases in text first crafted in the Meaning-Text Theory. Hierarchical classification of lexical functions involves organizing these features into a tree-like hierarchy of categories or labels. This is a challenging task as it requires a good understanding of the context and the relationships among words and phrases in text. It also needs large amounts of labeled data to train language models effectively. In this paper, we present a dataset of most frequent Spanish verb-noun collocations and sentences where they occur, each collocation is assigned to one of 37 lexical functions defined as classes for a hierarchical classification task. Each class represents a relation between the noun and the verb in a collocation involving their semantic and syntactic features. We combine the classes in a tree-based structure, and introduce classification objectives for each level of the structure. The dataset was created by dependency tree parsing and matching of the phrases in Spanish news. We provide baselines and data splits for each objective.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）中， lexical function 是一个概念，用于不同性和语法特征的词和短语在文本中的无ambiguity 表示。 hierarchical classification of lexical functions 涉及将这些特征分类为一棵树状结构中的类别或标签。这是一项具有挑战性的任务，因为它需要对文本中词和短语之间的上下文和关系有好的理解，以及大量的标注数据来训练语言模型。在这篇论文中，我们提供了西班牙语动词-名词 collocation 的最常见集和它们在文本中出现的句子，每个 collocation 被分配到了 37 个定义的类型，每个类型表示在 collocation 中动词和名词之间的 semantic 和语法特征的关系。我们将这些类型组织成树状结构，并引入每级结构的分类目标。这些数据由西班牙语新闻中的依赖树分析和匹配短语而创建。我们提供了基线和数据分割 для每个目标。
</details></li>
</ul>
<hr>
<h2 id="Perturbed-examples-reveal-invariances-shared-by-language-models"><a href="#Perturbed-examples-reveal-invariances-shared-by-language-models" class="headerlink" title="Perturbed examples reveal invariances shared by language models"></a>Perturbed examples reveal invariances shared by language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04166">http://arxiv.org/abs/2311.04166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruchit Rawal, Mariya Toneva</li>
<li>for: 本研究旨在比较两种自然语言处理模型，以揭示它们共同具有可解释的输入扰动的共轭性。</li>
<li>methods: 本研究使用了一种新的框架，通过设计target Specific linguistic capability (例如，同义词替换、打印 typo 等)的可解释输入扰动，来评估两种模型的不同。</li>
<li>results: 经过多个实验，研究发现大语言模型具有许多共轭性，而这些共轭性只存在于其他大型模型中。这些结果表明，拥有多种共轭性可能是大语言模型的成功原因，并且本研究的框架可以帮助我们理解新模型中具有哪些共轭性。<details>
<summary>Abstract</summary>
An explosion of work in language is leading to ever-increasing numbers of available natural language processing models, with little understanding of how new models compare to better-understood models. One major reason for this difficulty is saturating benchmark datasets, which may not reflect well differences in model performance in the wild. In this work, we propose a novel framework for comparing two natural language processing models by revealing their shared invariance to interpretable input perturbations that are designed to target a specific linguistic capability (e.g., Synonym-Invariance, Typo-Invariance). Via experiments on models from within the same and across different architecture families, this framework offers a number of insights about how changes in models (e.g., distillation, increase in size, amount of pre-training) affect multiple well-defined linguistic capabilities. Furthermore, we also demonstrate how our framework can enable evaluation of the invariances shared between models that are available as commercial black-box APIs (e.g., InstructGPT family) and models that are relatively better understood (e.g., GPT-2). Across several experiments, we observe that large language models share many of the invariances encoded by models of various sizes, whereas the invariances encoded by large language models are only shared by other large models. Possessing a wide variety of invariances may be a key reason for the recent successes of large language models, and our framework can shed light on the types of invariances that are retained by or emerge in new models.
</details>
<details>
<summary>摘要</summary>
一些新的自然语言处理模型的出现导致了无止境的语言处理模型数量的增加，但是对于这些新模型的性能的理解却很困难。一个主要的原因是溢出的标准测试集，这些测试集可能不能准确反映模型在实际场景中的表现。在这项工作中，我们提出了一种新的比较 frameworks，可以揭示两个自然语言处理模型的共同不变量，这些不变量是通过设计targetspecific linguistic capability（例如，同义词不变量、 typos not varying）来实现的。通过对不同架构家族的模型进行实验，这个框架提供了许多有用的信息，包括如何改变模型（例如，缩小、增大模型大小、预训练）对多个明确定义的语言功能的影响。此外，我们还示出了如何使用我们的框架来评估黑盒API（例如，InstructGPT家族）和比较好理解的模型（例如，GPT-2）之间的共同不变量。在多个实验中，我们发现大语言模型共享许多共同不变量，而大模型的共同不变量只有大模型才能共享。拥有多种共同不变量可能是大语言模型的最近成功的关键原因，我们的框架可以揭示这些共同不变量是如何被新模型保留或 emerge。
</details></li>
</ul>
<hr>
<h2 id="Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training"><a href="#Black-Box-Prompt-Optimization-Aligning-Large-Language-Models-without-Model-Training" class="headerlink" title="Black-Box Prompt Optimization: Aligning Large Language Models without Model Training"></a>Black-Box Prompt Optimization: Aligning Large Language Models without Model Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04155">http://arxiv.org/abs/2311.04155</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-coai/bpo">https://github.com/thu-coai/bpo</a></li>
<li>paper_authors: Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, Minlie Huang</li>
<li>for: 提高大语言模型（LLM）的用户指令遵循率，不需要更改LLM的参数。</li>
<li>methods: 使用黑盒提示优化（BPO）方法，通过优化用户提示来使LLM更好地理解用户的意图。</li>
<li>results: BPO可以提高ChatGPT的赢利率22%，并且可以超过PPO和DPO等方法所带来的性能提升。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown impressive success in various applications. However, these models are often not well aligned with human intents, which calls for additional treatments on them, that is, the alignment problem. To make LLMs better follow user instructions, existing alignment methods mostly focus on further training them. However, the extra training of LLMs are usually expensive in terms of GPU compute; worse still, LLMs of interest are oftentimes not accessible for user-demanded training, such as GPTs. In this work, we take a different perspective -- Black-Box Prompt Optimization (BPO) -- to perform alignments. The idea is to optimize user prompts to suit LLMs' input understanding, so as to best realize users' intents without updating LLMs' parameters. BPO is model-agnostic and the empirical results demonstrate that the BPO-aligned ChatGPT yields a 22\% increase in the win rate against its original version, and 10\% for GPT-4. Importantly, the \model-aligned LLMs can outperform the same models aligned by PPO and DPO, and it also brings additional performance gains when combining \model with PPO or DPO. Code and datasets are released at https://github.com/thu-coai/BPO.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）在各种应用场景中表现出色，但它们常不具备人类意图的含义，这引起了对它们的调整问题。为使LLM更好地遵从用户的指令，现有的准确方法主要是进一步训练它们。然而，这些额外训练通常需要大量的GPU计算资源，而且LLM对用户需求的训练不可达，如GPT。在这项工作中，我们采用了一种不同的视角——黑盒子提示优化（BPO）——来实现对 LLM 的调整。我们的想法是，通过优化用户的提示，使LLM更好地理解输入，以实现用户的意图，无需更新 LLM 的参数。BPO 是无关模型的，并且我们的实验结果表明，BPO 对适配的 ChatGPT 可以提高胜率达22%，而对 GPT-4 的提高为10%。此外，我们发现，使用 BPO 对 LLM 进行适配，可以超越使用 PPO 和 DPO 进行适配的同样模型，并且在组合 BPO 和 PPO 或 DPO 时，带来额外的性能提升。我们在 GitHub 上公开了代码和数据集，请参考 https://github.com/thu-coai/BPO。
</details></li>
</ul>
<hr>
<h2 id="What-is-Lost-in-Knowledge-Distillation"><a href="#What-is-Lost-in-Knowledge-Distillation" class="headerlink" title="What is Lost in Knowledge Distillation?"></a>What is Lost in Knowledge Distillation?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04142">http://arxiv.org/abs/2311.04142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manas Mohanty, Tanya Roosta, Peyman Passban</li>
<li>for: 本研究旨在investigate知识塑化（KD）过程中是否存在信息损失，以及这些损失是否按照特定的模式发生。</li>
<li>methods: 本研究使用了知识塑化技术，以减少深度神经网络（DNNs）的训练和维护成本。</li>
<li>results: 本研究发现，知识塑化过程中的信息损失可以按照特定的模式进行分类，并且不同任务的敏感度异常大。这些结果可以帮助选择合适的配置，以实现最佳的信息传递between大型（教师）和小型（学生）模型。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) have improved NLP tasks significantly, but training and maintaining such networks could be costly. Model compression techniques, such as, knowledge distillation (KD), have been proposed to address the issue; however, the compression process could be lossy. Motivated by this, our work investigates how a distilled student model differs from its teacher, if the distillation process causes any information losses, and if the loss follows a specific pattern. Our experiments aim to shed light on the type of tasks might be less or more sensitive to KD by reporting data points on the contribution of different factors, such as the number of layers or attention heads. Results such as ours could be utilized when determining effective and efficient configurations to achieve optimal information transfers between larger (teacher) and smaller (student) models.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）已经大幅提高了自然语言处理（NLP）任务的性能，但训练和维护这些网络可能会很昂贵。为了解决这个问题，知识填充技术（KD）已经被提议，但压缩过程可能会导致信息损失。我们的工作探讨了填充学生模型与其教师模型之间的差异，以及压缩过程是否会导致信息损失，以及损失是否会跟踪特定的模式。我们的实验旨在为选择合适的任务和配置提供数据点，以便在确定最佳信息传输的过程中尽可能地实现效率和可行性。
</details></li>
</ul>
<hr>
<h2 id="Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques"><a href="#Modelling-Sentiment-Analysis-LLMs-and-data-augmentation-techniques" class="headerlink" title="Modelling Sentiment Analysis: LLMs and data augmentation techniques"></a>Modelling Sentiment Analysis: LLMs and data augmentation techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04139">http://arxiv.org/abs/2311.04139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillem Senabre Prades</li>
<li>for: 这篇论文是为了提出一种基于小训练集的 binary sentiment classification 方法。</li>
<li>methods: 本论文使用了 LLMS 技术，包括 BERT、RoBERTa 和 XLNet，以实现 sentiment analysis 的高度表现。</li>
<li>results: 本论文通过实验表明，使用 LLMS 技术可以在小训练集上实现高度的 binary sentiment classification 性能。<details>
<summary>Abstract</summary>
This paper provides different approaches for a binary sentiment classification on a small training dataset. LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了不同的方法来进行二分类句子情感分类，使用了一些 LLMS 提供了状态艺术的结果，如 BERT、RoBERTa 和 XLNet。Here's a breakdown of the translation:* " LLMS" 是简化中文的 "Large Language Models" (大语言模型)* "二分类" 是简化中文的 "binary classification" (二分类)* "句子情感分类" 是简化中文的 "sentiment classification" (情感分类)* "状态艺术" 是简化中文的 "state-of-the-art" (状态艺术)I hope this helps! Let me know if you have any other questions.
</details></li>
</ul>
<hr>
<h2 id="Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech"><a href="#Personality-Style-Recognition-via-Machine-Learning-Identifying-Anaclitic-and-Introjective-Personality-Styles-from-Patients’-Speech" class="headerlink" title="Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech"></a>Personality Style Recognition via Machine Learning: Identifying Anaclitic and Introjective Personality Styles from Patients’ Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04088">http://arxiv.org/abs/2311.04088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Semere Kiros Bitew, Vincent Schelstraete, Klim Zaporojets, Kimberly Van Nieuwenhove, Reitske Meganck, Chris Develder</li>
<li>for: 这个研究的目的是用自然语言处理（NLP）和标准机器学习工具来推断患有主要抑郁症（MDD）患者的个性类型，以更准确地识别个性类型，并且可能比传统的问卷方法更加准确。</li>
<li>methods: 这个研究使用了 recorded clinical diagnostic interviews（CDI）数据集，包含79名患有MDD的患者，并将其分为两个个性类型：帮助型（anaclitic）和寂静型（introjective）。研究人员首先分析了口头会议，以便了解每个类型的语言特征，然后开发了自动分类器，包括基于标准问卷回答（a）、基本文本特征（b）、更高级的文本特征（c），以及音频特征。</li>
<li>results: 研究发现，使用语言 derive 的特征（例如 LIWC）自动分类的表现比问卷基本类型更好，而将 LIWC 与问卷特征相结合的表现更加出色。这些结果表明，用语言 derive 的特征来推断个性类型可能比传统的问卷方法更加准确，但问卷仍然有一定的补充作用。<details>
<summary>Abstract</summary>
In disentangling the heterogeneity observed in psychopathology, personality of the patients is considered crucial. While it has been demonstrated that personality traits are reflected in the language used by a patient, we hypothesize that this enables automatic inference of the personality type directly from speech utterances, potentially more accurately than through a traditional questionnaire-based approach explicitly designed for personality classification. To validate this hypothesis, we adopt natural language processing (NLP) and standard machine learning tools for classification. We test this on a dataset of recorded clinical diagnostic interviews (CDI) on a sample of 79 patients diagnosed with major depressive disorder (MDD) -- a condition for which differentiated treatment based on personality styles has been advocated -- and classified into anaclitic and introjective personality styles. We start by analyzing the interviews to see which linguistic features are associated with each style, in order to gain a better understanding of the styles. Then, we develop automatic classifiers based on (a) standardized questionnaire responses; (b) basic text features, i.e., TF-IDF scores of words and word sequences; (c) more advanced text features, using LIWC (linguistic inquiry and word count) and context-aware features using BERT (bidirectional encoder representations from transformers); (d) audio features. We find that automated classification with language-derived features (i.e., based on LIWC) significantly outperforms questionnaire-based classification models. Furthermore, the best performance is achieved by combining LIWC with the questionnaire features. This suggests that more work should be put into developing linguistically based automated techniques for characterizing personality, however questionnaires still to some extent complement such methods.
</details>
<details>
<summary>摘要</summary>
在解剖 психопатологи中的多样性，病人的人格 trait 被视为关键。已经证明了患者的语言使用会反映他们的人格特质，我们假设可以通过自动识别语言特征来直接推断病人的人格类型，可能更准确地 than through traditional questionnaire-based approach for personality classification. 为了验证这个假设，我们采用自然语言处理（NLP）和标准机器学习工具 для分类。我们在一个记录的临床诊断采访（CDI）中的79名患有主要抑郁症（MDD）患者的样本上进行测试，并将其分为安慰性和 introjective 人格样式。我们首先分析采访，以确定各样式之间的语言特征，以更好地理解这些样式。然后，我们开发自动分类器，基于（a）标准问卷回答；（b）基本文本特征，即TF-IDF 分数的词和word sequences；（c）更高级的文本特征，使用 LIWC （语言Query和词 counting）和BERT（ transformers 中的 bidirectional encoder representations）；（d）音频特征。我们发现，基于语言 derive 的特征（即 LIWC）的自动分类表现出色，significantly outperform questionnaire-based classification models。此外，我们发现，将 LIWC 与问卷特征结合使用的表现最佳。这表示，更多的工作应该投入到开发基于语言特征的自动分类技术，但是，questionnaires 仍然有一定的补做作用。
</details></li>
</ul>
<hr>
<h2 id="Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design"><a href="#Do-LLMs-exhibit-human-like-response-biases-A-case-study-in-survey-design" class="headerlink" title="Do LLMs exhibit human-like response biases? A case study in survey design"></a>Do LLMs exhibit human-like response biases? A case study in survey design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04076">http://arxiv.org/abs/2311.04076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lindiatjuatja/biasmonkey">https://github.com/lindiatjuatja/biasmonkey</a></li>
<li>paper_authors: Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, Graham Neubig</li>
<li>for: 这个研究用于检测大语言模型（LLM）是否能够模拟人类的意见，以及LLM是否会受到问题表达的影响。</li>
<li>methods: 该研究使用了问卷设计作为案例研究，利用了社会心理学中已有的研究，设计了一个数据集和一个评估框架，以评估 LLM 是否会表现出人类类似的响应偏见。</li>
<li>results: 研究发现，流行的开源和商业 LLM 通常不会模拟人类的行为，尤其是在问题表达的排序和重要性上。此外，even if a model shows a significant change in the same direction as humans, 研究发现，这种变化可能是由其他各种各样的相关性引起的，而不是受到问题表达的直接影响。这些结果指出，使用 LLM 代替人类进行某些注解阶段可能存在隐藏的风险，并且更加重要地，需要更加细化的模型行为描述。<details>
<summary>Abstract</summary>
As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs is their sensitivity to prompt wording -- but interestingly, humans also display sensitivities to instruction changes in the form of response biases. As such, we argue that if LLMs are going to be used to approximate human opinions, it is necessary to investigate the extent to which LLMs also reflect human response biases, if at all. In this work, we use survey design as a case study, where human response biases caused by permutations in wordings of ``prompts'' have been extensively studied. Drawing from prior work in social psychology, we design a dataset and propose a framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior. These inconsistencies tend to be more prominent in models that have been instruction fine-tuned. Furthermore, even if a model shows a significant change in the same direction as humans, we find that perturbations that are not meant to elicit significant changes in humans may also result in a similar change, suggesting that such a result could be partially due to other spurious correlations. These results highlight the potential pitfalls of using LLMs to substitute humans in parts of the annotation pipeline, and further underscore the importance of finer-grained characterizations of model behavior. Our code, dataset, and collected samples are available at https://github.com/lindiatjuatja/BiasMonkey
</details>
<details>
<summary>摘要</summary>
随着大语言模型（LLM）的能力不断提高，有越来越多的人对使用LLM作为人类代理进行实际任务，如调查和意见调查而感到兴奋。然而，一个广泛提到的障碍是LLM的敏感性 towards prompt wording （提问词的选择）——但是人类也会因为提问词的变化而产生偏见。因此，如果要使用LLM来 aproximate human opinions，那么就需要investigate whether LLMs also exhibit human-like response biases。在这个工作中，我们使用调查设计为case study，因为人类响应的偏见已经在调查中得到了广泛的研究。基于社会心理学的前期工作，我们设计了数据集和提出了一种框架，以评估LLM是否 Display human-like response biases in survey questionnaires。我们对九种模型进行了全面的评估，发现大多数开源和商业模型通常不能准确地表现出人类的响应偏见。这些偏见通常会在模型被 instrucion fine-tuned 时更加明显。此外，即使模型表现出人类的方向性变化，我们发现可能存在其他的干扰因素，导致模型的行为不准确。这些结果表明使用LLM代替人类在一些标注过程中可能存在隐患，并且高亮了需要更加细化的模型行为Characterization。我们的代码、数据集和收集的样本可以在https://github.com/lindiatjuatja/BiasMonkey 上获取。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment"><a href="#Beyond-Imitation-Leveraging-Fine-grained-Quality-Signals-for-Alignment" class="headerlink" title="Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment"></a>Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04072">http://arxiv.org/abs/2311.04072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geyang Guo, Ranchi Zhao, Tianyi Tang, Wayne Xin Zhao, Ji-Rong Wen</li>
<li>for: 这个论文的目的是提出一种改进的对齐方法，以便大语言模型（LLMs）能够更好地适应人类的偏好。</li>
<li>methods: 这个论文使用了精细的质量信号，来指导Language Model（LM）的学习对齐。</li>
<li>results: 实验表明，该方法可以提高LLMs的对齐性，并且比传统的对齐方法（如人类反馈学习）更加简单和efficient。<details>
<summary>Abstract</summary>
Alignment with human preference is a desired property of large language models (LLMs). Currently, the main alignment approach is based on reinforcement learning from human feedback (RLHF). Despite the effectiveness of RLHF, it is intricate to implement and train, thus recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning (SFT). A major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的对人类偏好的对适性是一个欲有的性能。现在，主要的对适性方法是基于人类反馈学习（RLHF）。 Despite the effectiveness of RLHF, it is intricate to implement and train, so recent studies explore how to develop alternative alignment approaches based on supervised fine-tuning（SFT）. However, a major limitation of SFT is that it essentially does imitation learning, which cannot fully understand what are the expected behaviors. To address this issue, we propose an improved alignment approach named FIGA. Different from prior methods, we incorporate fine-grained (i.e., token or phrase level) quality signals that are derived by contrasting good and bad responses. Our approach has made two major contributions. Firstly, we curate a refined alignment dataset that pairs initial responses and the corresponding revised ones. Secondly, we devise a new loss function that can leverage fine-grained quality signals to instruct the learning of LLMs for alignment. Extensive experiments have demonstrated the effectiveness of our approaches by comparing a number of competitive baselines.
</details></li>
</ul>
<hr>
<h2 id="Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders"><a href="#Implementation-and-Comparison-of-Methods-to-Extract-Reliability-KPIs-out-of-Textual-Wind-Turbine-Maintenance-Work-Orders" class="headerlink" title="Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders"></a>Implementation and Comparison of Methods to Extract Reliability KPIs out of Textual Wind Turbine Maintenance Work Orders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04064">http://arxiv.org/abs/2311.04064</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc-Alexander Lutz, Bastian Schäfermeier, Rachael Sexton, Michael Sharp, Alden Dima, Stefan Faulstich, Jagan Mohini Aluri</li>
<li>for: 本文目的是提高风力机的运行和维护。</li>
<li>methods: 本文使用了三种不同的方法来计算可靠性关键性能指标从维护工作令。第一种方法是由领域专家手动标注维护工作令，使用工业标准定义的架构来分别标注。第二种方法是通过文本分类方法开发一个自动标注模型。第三种方法是使用人工智能辅助标注工具来标注和结构维护工作令中的原始维护信息。</li>
<li>results: 三种方法可以更有效地提取维护信息从维护工作令，并且可以评估风力机的可靠性关键性能指标。质量和时间花费被用作评价标准。总的来说，这三种方法可以帮助优化风力机的运行和维护。<details>
<summary>Abstract</summary>
Maintenance work orders are commonly used to document information about wind turbine operation and maintenance. This includes details about proactive and reactive wind turbine downtimes, such as preventative and corrective maintenance. However, the information contained in maintenance work orders is often unstructured and difficult to analyze, making it challenging for decision-makers to use this information for optimizing operation and maintenance. To address this issue, this work presents three different approaches to calculate reliability key performance indicators from maintenance work orders. The first approach involves manual labeling of the maintenance work orders by domain experts, using the schema defined in an industrial guideline to assign the label accordingly. The second approach involves the development of a model that automatically labels the maintenance work orders using text classification methods. The third technique uses an AI-assisted tagging tool to tag and structure the raw maintenance information contained in the maintenance work orders. The resulting calculated reliability key performance indicator of the first approach are used as a benchmark for comparison with the results of the second and third approaches. The quality and time spent are considered as criteria for evaluation. Overall, these three methods make extracting maintenance information from maintenance work orders more efficient, enable the assessment of reliability key performance indicators and therefore support the optimization of wind turbine operation and maintenance.
</details>
<details>
<summary>摘要</summary>
维护工作令 commonly used to record风机运行和维护信息。这些信息包括推动和反应式风机停机时间，如预防维护和修复维护。然而，维护工作令中的信息通常是不结构化的，困难分析，使得决策者无法使用这些信息优化运行和维护。为解决这个问题，本工作提出了三种不同的方法来计算可靠性关键性能指标从维护工作令中。首先，第一种方法是通过域专家手动标注维护工作令，使用行业标准的 schema 分配标签。第二种方法是开发一种自动标注维护工作令的模型，使用文本分类方法。第三种技术是使用人工智能帮助标记工具来标记和结构化维护工作令中的原始维护信息。计算的可靠性关键性能指标的结果被用作比较第二和第三种方法的标准。评价标准包括质量和时间。总的来说，这三种方法使维护信息从维护工作令中提取更加效率，可以评估可靠性关键性能指标，因此支持风机运行和维护优化。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features"><a href="#Reinforcement-Learning-Fine-tuning-of-Language-Models-is-Biased-Towards-More-Extractable-Features" class="headerlink" title="Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features"></a>Reinforcement Learning Fine-tuning of Language Models is Biased Towards More Extractable Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04046">http://arxiv.org/abs/2311.04046</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diogo Cruz, Edoardo Pona, Alex Holness-Tofts, Elias Schmied, Víctor Abia Alonso, Charlie Griffin, Bogdan-Ionut Cirstea</li>
<li>for: 本研究探究了自然语言处理模型（LLM）在强化学习环境中是否遵循顺序学习的原则。</li>
<li>methods: 研究人员采用了两种方法来测试假设：一是通过synthetic语言任务测试，二是通过自然语言任务测试。</li>
<li>results: 研究人员发现，在强化学习环境中，模型更倾向于采用更容易提取的特征，而不是更复杂的特征。此外，研究人员还发现，在强化学习过程中，模型对特征的选择具有 statistically significant 的相关性。<details>
<summary>Abstract</summary>
Many capable large language models (LLMs) are developed via self-supervised pre-training followed by a reinforcement-learning fine-tuning phase, often based on human or AI feedback. During this stage, models may be guided by their inductive biases to rely on simpler features which may be easier to extract, at a cost to robustness and generalisation. We investigate whether principles governing inductive biases in the supervised fine-tuning of LLMs also apply when the fine-tuning process uses reinforcement learning. Following Lovering et al (2021), we test two hypotheses: that features more $\textit{extractable}$ after pre-training are more likely to be utilised by the final policy, and that the evidence for/against a feature predicts whether it will be utilised. Through controlled experiments on synthetic and natural language tasks, we find statistically significant correlations which constitute strong evidence for these hypotheses.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models"><a href="#P-Bench-A-Multi-level-Privacy-Evaluation-Benchmark-for-Language-Models" class="headerlink" title="P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models"></a>P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04044">http://arxiv.org/abs/2311.04044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Li, Dadi Guo, Donghao Li, Wei Fan, Qi Hu, Xin Liu, Chunkit Chan, Duanyi Yao, Yangqiu Song</li>
<li>for: This paper aims to address the privacy risks of language models (LMs) and propose a privacy evaluation benchmark called P-Bench to evaluate the privacy leakage of LMs.</li>
<li>methods: The proposed P-Bench benchmark uses a multi-faceted approach to evaluate the privacy of LMs during private fine-tuning, including defining privacy objectives and constructing a unified pipeline for private fine-tuning.</li>
<li>results: The paper conducts extensive experiments on three datasets of GLUE for mainstream LMs to evaluate the privacy leakage of various privacy-preserving language models (PPLMs) using the P-Bench benchmark. The results provide a fair and intuitive evaluation of the privacy leakage of different PPLMs.<details>
<summary>Abstract</summary>
The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP). Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs. In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs. Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage. P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning. Then, P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results. The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs. We conduct extensive experiments on three datasets of GLUE for mainstream LMs.
</details>
<details>
<summary>摘要</summary>
快速发展的语言模型（LM）带来了前所未有的可访问性和使用性，对于模型和用户来说都是有益的。然而，随着更多的注意力转移到不受限制的模型访问，可能会导致隐私问题的泄露。为解决这些问题，许多最近的工作提出了隐私保护语言模型（PPLM），使用分布式隐私（DP）来保护用户的隐私。然而，不同的DP实现使得对现有PPLM进行比较变得困难。在这篇论文中，我们提出了P-Bench，一个多角度隐私评估准则，用来实际和直观地评估LM的隐私泄露。而不是仅仅保护和测量保护数据的隐私，P-Bench也探讨在实际使用过程中的推理数据隐私。P-Bench首先明确了在私有精细调整时的多重隐私目标。然后，P-Bench构建了一个统一的私有精细调整管道。最后，P-Bench对LM进行现有隐私攻击，并使用预定的隐私目标作为实际评估结果。我们对GLUE数据集进行了广泛的实验，并发现P-Bench可以帮助评估不同PPLM的隐私泄露。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Film-Adaptation-through-Narrative-Alignment"><a href="#Analyzing-Film-Adaptation-through-Narrative-Alignment" class="headerlink" title="Analyzing Film Adaptation through Narrative Alignment"></a>Analyzing Film Adaptation through Narrative Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04020">http://arxiv.org/abs/2311.04020</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Shahreen Salim, Charuta Pethe, Allen Kim, Steven Skiena</li>
<li>for: 这个论文研究了电影改编的过程，特别是对剧本和小说之间的文本相似性进行自动分析。</li>
<li>methods: 研究者使用了Smith-Waterman本地对接算法和SBERT嵌入距离来建立叙述对应关系，以衡量电影和小说之间的文本相似性。</li>
<li>results: 研究发现，电影改编过程中对剧本的 faithfulness、对话的重要性、叙述顺序的保留和gender表现问题等方面存在一些问题，这些问题可以通过自动分析来发现和解决。<details>
<summary>Abstract</summary>
Novels are often adapted into feature films, but the differences between the two media usually require dropping sections of the source text from the movie script. Here we study this screen adaptation process by constructing narrative alignments using the Smith-Waterman local alignment algorithm coupled with SBERT embedding distance to quantify text similarity between scenes and book units. We use these alignments to perform an automated analysis of 40 adaptations, revealing insights into the screenwriting process concerning (i) faithfulness of adaptation, (ii) importance of dialog, (iii) preservation of narrative order, and (iv) gender representation issues reflective of the Bechdel test.
</details>
<details>
<summary>摘要</summary>
小说经常被改编成电影，但两媒体之间的差异通常会导致电影剧本中去掉来自原始文本的部分。我们通过构建叙事对应关系使用斯密特-沃特曼本地对Alignment算法和SBERT嵌入距离来衡量场景和书单之间的文本相似性。我们使用这些对应关系来自动分析40个改编作品，探讨电影编剧过程中的忠诚度、对话重要性、叙事顺序保持和gender表现问题，这些问题与Bechdel测试有关。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals"><a href="#Exploring-Jiu-Jitsu-Argumentation-for-Writing-Peer-Review-Rebuttals" class="headerlink" title="Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals"></a>Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03998">http://arxiv.org/abs/2311.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sukannya Purkayastha, Anne Lauscher, Iryna Gurevych</li>
<li>for: 本研究旨在提出一种基于情感根和主题的辩论风格，以应对现代辩论中的护卫者心理学。</li>
<li>methods: 本研究使用了已有的评论结构数据集，并对其进行了扩展和修改，以满足新的任务需求。然后，通过培育专业的模型，实现了情感根和主题导向的护卫回复生成。</li>
<li>results: 本研究通过两个子任务和综合评价来评估了新的辩论风格的效果，并取得了良好的结果。这些结果表明，基于情感根和主题的辩论风格可以更好地满足现代辩论中的需求，并且可以帮助人们更好地理解和回应对手的观点。<details>
<summary>Abstract</summary>
In many domains of argumentation, people's arguments are driven by so-called attitude roots, i.e., underlying beliefs and world views, and their corresponding attitude themes. Given the strength of these latent drivers of arguments, recent work in psychology suggests that instead of directly countering surface-level reasoning (e.g., falsifying given premises), one should follow an argumentation style inspired by the Jiu-Jitsu 'soft' combat system (Hornsey and Fielding, 2017): first, identify an arguer's attitude roots and themes, and then choose a prototypical rebuttal that is aligned with those drivers instead of invalidating those. In this work, we are the first to explore Jiu-Jitsu argumentation for peer review by proposing the novel task of attitude and theme-guided rebuttal generation. To this end, we enrich an existing dataset for discourse structure in peer reviews with attitude roots, attitude themes, and canonical rebuttals. To facilitate this process, we recast established annotation concepts from the domain of peer reviews (e.g., aspects a review sentence is relating to) and train domain-specific models. We then propose strong rebuttal generation strategies, which we benchmark on our novel dataset for the task of end-to-end attitude and theme-guided rebuttal generation and two subtasks.
</details>
<details>
<summary>摘要</summary>
在许多论证领域，人们的论证受到 socalled 的态度根和世界观的影响，这些基础和主题对应的态度驱动了他们的论证。由于这些潜在的驱动者的力量，现代心理学研究建议，而不是直接对表面水平的理据（例如，证据反驳），应该采用基于柔气斗技（Jiu-Jitsu）的论证风格（Hornsey和Fielding，2017）：首先，认定论证人的态度根和主题，然后选择与这些驱动器相对应的典型反驳。在这项工作中，我们是第一个探讨Jiu-Jitsu论证在同行评审中的应用，我们提出了novel任务：对态度和主题导向的反驳生成。为此，我们增强了现有的 peer review 数据集，添加了态度根、态度主题和 canonical 反驳。为了实现这一目标，我们重新定义了Established annotation concepts从 peer review 领域（例如，sentence 上的方面），并训练域pecific 模型。我们最后提出了强大的反驳生成策略，并在我们的新数据集上进行了终到端态度和主题导向的反驳生成和两个子任务的benchmark。
</details></li>
</ul>
<hr>
<h2 id="Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media"><a href="#Factoring-Hate-Speech-A-New-Annotation-Framework-to-Study-Hate-Speech-in-Social-Media" class="headerlink" title="Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media"></a>Factoring Hate Speech: A New Annotation Framework to Study Hate Speech in Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03969">http://arxiv.org/abs/2311.03969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gal Ron, Effi Levi, Odelia Oshri, Shaul R. Shenhav</li>
<li>for: 本研究提出了一种新的报告方案，用于分类习惯性攻击语言。</li>
<li>methods: 本研究使用了Twitter上超过29万条帖子，并将其分为5个分类。</li>
<li>results: 研究人员通过对1050个帖子的注释，发现了5种不同的报告类型。<details>
<summary>Abstract</summary>
In this work we propose a novel annotation scheme which factors hate speech into five separate discursive categories. To evaluate our scheme, we construct a corpus of over 2.9M Twitter posts containing hateful expressions directed at Jews, and annotate a sample dataset of 1,050 tweets. We present a statistical analysis of the annotated dataset as well as discuss annotation examples, and conclude by discussing promising directions for future work.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的注释方案，它将仇恨言论分解成五个分开的讲话类别。为评估我们的方案，我们构建了包含超过290万个推文的推特帖子集，并对1,050个推文进行了注释。我们提供了推文集的统计分析以及注释示例，并在结尾提出了未来工作的可能方向。
</details></li>
</ul>
<hr>
<h2 id="An-Analysis-of-Dialogue-Repair-in-Voice-Assistants"><a href="#An-Analysis-of-Dialogue-Repair-in-Voice-Assistants" class="headerlink" title="An Analysis of Dialogue Repair in Voice Assistants"></a>An Analysis of Dialogue Repair in Voice Assistants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03952">http://arxiv.org/abs/2311.03952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Galbraith</li>
<li>for: 本研究探讨了虚拟助手与用户之间的对话修复，以及虚拟助手如何利用对话语言来修复 misunderstanding。</li>
<li>methods: 本研究通过分析Google助手和Siri在用户与虚拟助手之间的交互来分析对话修复的使用和响应。</li>
<li>results: 研究发现虚拟助手使用了多种自己的策略，但无法模仿人类对话修复策略，如“嗯？”。用户Acceptability调查显示英语和西班牙语用户对修复策略的偏好有所不同，虚拟助手使用也存在一些语言不同的地方。这些结果指出了人机交互中对话语言的不均衡，并且强调了进一步研究人机交互中对话语言的影响。<details>
<summary>Abstract</summary>
Spoken dialogue systems have transformed human-machine interaction by providing real-time responses to queries. However, misunderstandings between the user and system persist. This study explores the significance of interactional language in dialogue repair between virtual assistants and users by analyzing interactions with Google Assistant and Siri, focusing on their utilization and response to the other-initiated repair strategy "huh?" prevalent in human-human interaction. Findings reveal several assistant-generated strategies but an inability to replicate human-like repair strategies such as "huh?". English and Spanish user acceptability surveys show differences in users' repair strategy preferences and assistant usage, with both similarities and disparities among the two surveyed languages. These results shed light on inequalities between interactional language in human-human interaction and human-machine interaction, underscoring the need for further research on the impact of interactional language in human-machine interaction in English and beyond.
</details>
<details>
<summary>摘要</summary>
人工智能对话系统已经改变了人机交互，提供了实时回应。然而，用户和系统之间的 misunderstanding 仍然存在。这项研究探讨了对话修复在虚拟助手和用户之间的语言互动意义，通过分析 Google Assistant 和 Siri 对 "huh?" 等其他发起修复策略的应用和回应。发现虚拟助手采用了多种策略，但无法模仿人类对话修复策略。英语和西班牙语用户对修复策略的偏好和虚拟助手使用情况有所不同和相似之处，这些结果 shed light 到人机交互中语言互动不平等，高亮了需要进一步研究人机交互中语言互动的影响。
</details></li>
</ul>
<hr>
<h2 id="Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition"><a href="#Improving-Korean-NLP-Tasks-with-Linguistically-Informed-Subword-Tokenization-and-Sub-character-Decomposition" class="headerlink" title="Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition"></a>Improving Korean NLP Tasks with Linguistically Informed Subword Tokenization and Sub-character Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03928">http://arxiv.org/abs/2311.03928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/taeheejeon22/morphsubdecomp-korean">https://github.com/taeheejeon22/morphsubdecomp-korean</a></li>
<li>paper_authors: Taehee Jeon, Bongseok Yang, Changhwan Kim, Yoonseob Lim</li>
<li>for: 该研究旨在提高预训练语言模型（PLM）在语法和 semantics 领域的表现，通过使用 morpheme-aware 子词Tokenization 方法来应对韩语的特殊语法和书写系统。</li>
<li>methods: 该方法使用 sub-character decomposition 来应对 BPE 的挑战，并考虑了语言学性的精度和计算效率的平衡。</li>
<li>results: 对 NIKL-CoLA 任务的评估表明，该技术在总体上达到了好的表现，特别是在语法任务中提高了表现，这表示integrating morpheme type information 可以提高语言模型的语法和 semantics 能力，并且可以进一步提高表现 beyond standard morphological analysis。<details>
<summary>Abstract</summary>
We introduce a morpheme-aware subword tokenization method that utilizes sub-character decomposition to address the challenges of applying Byte Pair Encoding (BPE) to Korean, a language characterized by its rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于字符串分词的 morpheme-aware 方法，利用字符串分解来Addressing the challenges of applying Byte Pair Encoding (BPE) to Korean, a language with rich morphology and unique writing system. Our approach balances linguistic accuracy with computational efficiency in Pre-trained Language Models (PLMs). Our evaluations show that this technique achieves good performances overall, notably improving results in the syntactic task of NIKL-CoLA. This suggests that integrating morpheme type information can enhance language models' syntactic and semantic capabilities, indicating that adopting more linguistic insights can further improve performance beyond standard morphological analysis.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples"><a href="#iACOS-Advancing-Implicit-Sentiment-Extraction-with-Informative-and-Adaptive-Negative-Examples" class="headerlink" title="iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples"></a>iACOS: Advancing Implicit Sentiment Extraction with Informative and Adaptive Negative Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03896">http://arxiv.org/abs/2311.03896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiancai Xu, Jia-Dong Zhang, Lei Xiong, Zhishang Liu</li>
<li>for: 本文提出了一种新的方法iACOS，用于从文本中提取隐式方面和意见。</li>
<li>methods: 本方法首先在文本中添加了两个隐式标记，以获取Context-aware表示所有Token，包括隐式方面和意见。然后，该方法采用了一种顺序标注模型，以同时提取显式和隐式方面和意见。最后，该方法使用了特殊多头注意力 Mechanism来同时预测方面意见对的类别和情感。</li>
<li>results: 实验结果显示，iACOSsignificantly outperforms其他四元提取基线，根据F1分数在两个公共benchmark datasets上。<details>
<summary>Abstract</summary>
Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the context-aware representation of all tokens including implicit aspects and opinions. Second, iACOS develops a sequence labeling model over the context-aware token representation to co-extract explicit and implicit aspects and opinions. Third, iACOS devises a multi-label classifier with a specialized multi-head attention for discovering aspect-opinion pairs and predicting their categories and sentiments simultaneously. Fourth, iACOS leverages informative and adaptive negative examples to jointly train the multi-label classifier and the other two classifiers on categories and sentiments by multi-task learning. Finally, the experimental results show that iACOS significantly outperforms other quadruple extraction baselines according to the F1 score on two public benchmark datasets.
</details>
<details>
<summary>摘要</summary>
<SYS>translate("Aspect-based sentiment analysis (ABSA) have been extensively studied, but little light has been shed on the quadruple extraction consisting of four fundamental elements: aspects, categories, opinions and sentiments, especially with implicit aspects and opinions. In this paper, we propose a new method iACOS for extracting Implicit Aspects with Categories and Opinions with Sentiments. First, iACOS appends two implicit tokens at the end of a text to capture the context-aware representation of all tokens including implicit aspects and opinions. Second, iACOS develops a sequence labeling model over the context-aware token representation to co-extract explicit and implicit aspects and opinions. Third, iACOS devises a multi-label classifier with a specialized multi-head attention for discovering aspect-opinion pairs and predicting their categories and sentiments simultaneously. Fourth, iACOS leverages informative and adaptive negative examples to jointly train the multi-label classifier and the other two classifiers on categories and sentiments by multi-task learning. Finally, the experimental results show that iACOS significantly outperforms other quadruple extraction baselines according to the F1 score on two public benchmark datasets.")</SYS>以下是将文本翻译成简化中文： aspect-based sentiment analysis (ABSA) 已经广泛研究，但是它们对四元素抽取（包括方面、类别、意见和情感）尤其是对于隐式方面和意见进行了少量的研究。在这篇论文中，我们提出了一种新的方法iACOS，用于抽取隐式方面和意见。这个方法包括以下四个步骤：1. 将文本结尾添加两个隐式符号，以捕捉所有token的上下文感知表示，包括隐式方面和意见。2. 使用上下文感知的字符串表示来进行序列标签模型，以同时提取显式和隐式方面和意见。3. 开发一种特殊的多头注意力的多标签分类器，用于同时发现方面-意见对和其类别和情感的预测。4. 使用有用和适应的负例来同时训练多标签分类器和其他两个分类器，以进行类别和情感的多任务学习。最后，实验结果表明，iACOS在两个公共的 benchmark 数据集上的 F1 分数明显高于其他四元素抽取基线。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Contrastive-Learning-of-Sentence-Embeddings"><a href="#Sparse-Contrastive-Learning-of-Sentence-Embeddings" class="headerlink" title="Sparse Contrastive Learning of Sentence Embeddings"></a>Sparse Contrastive Learning of Sentence Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03881">http://arxiv.org/abs/2311.03881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruize An, Chen Zhang, Dawei Song<br>for:这个论文的目的是证明对句子嵌入模型进行Parameter sparseification可以提高模型性能，并且通过对标准semantic textual similarity(STS)任务和转移学习任务的实验，证明了这种方法的可行性和稳定性。methods:这个论文使用了对句子嵌入模型进行Parameter sparseification，并通过对Alignment和Uniformity scores进行分析，从而确定了危险参数的存在和其影响。results:这个论文的实验结果表明，对于STS任务和转移学习任务，使用了Parameter sparseification的SparseCSE模型在性能上表现出色，并且对比于SimCSE模型，它具有更高的Alignment和Uniformity scores。<details>
<summary>Abstract</summary>
Recently, SimCSE has shown the feasibility of contrastive learning in training sentence embeddings and illustrates its expressiveness in spanning an aligned and uniform embedding space. However, prior studies have shown that dense models could contain harmful parameters that affect the model performance, and it is no wonder that SimCSE can as well be invented with such parameters. Driven by this, parameter sparsification is applied, where alignment and uniformity scores are used to measure the contribution of each parameter to the overall quality of sentence embeddings. Drawing from a preliminary study, we consider parameters with minimal contributions to be detrimental, as their sparsification results in improved model performance. To discuss the ubiquity of detrimental parameters and remove them, more experiments on the standard semantic textual similarity (STS) tasks and transfer learning tasks are conducted, and the results show that the proposed sparsified SimCSE (SparseCSE) has excellent performance in comparison with SimCSE. Furthermore, through in-depth analysis, we establish the validity and stability of our sparsification method, showcasing that the embedding space generated by SparseCSE exhibits improved alignment compared to that produced by SimCSE. Importantly, the uniformity yet remains uncompromised.
</details>
<details>
<summary>摘要</summary>
最近，SimCSE已经证明了对比学习在生成句子嵌入中的可行性，并 Illustrates its expressiveness in spanning an aligned and uniform embedding space。然而，先前的研究表明，dense模型可能包含有害参数，这会影响模型性能。这种情况下，参数精简是应用的，通过对适应性和一致性分数来评估每个参数对整体句子嵌入质量的贡献。根据初步研究，我们认为parameters with minimal contributions are detrimental，因为它们的精简会提高模型性能。为了评估这些detrimental parameters的普遍性和移除它们，我们进行了更多的STS任务和转移学习任务的实验，结果显示，我们的精简SimCSE（SparseCSE）具有与SimCSE相比杰出的性能。此外，我们还进行了深入分析，并证明了我们的精简方法的有效性和稳定性，显示了生成的嵌入空间在SparseCSE中比SimCSE更高度一致，而均匀性却保持不变。
</details></li>
</ul>
<hr>
<h2 id="OLaLa-Ontology-Matching-with-Large-Language-Models"><a href="#OLaLa-Ontology-Matching-with-Large-Language-Models" class="headerlink" title="OLaLa: Ontology Matching with Large Language Models"></a>OLaLa: Ontology Matching with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03837">http://arxiv.org/abs/2311.03837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sven Hertling, Heiko Paulheim</li>
<li>for: 这个论文旨在探讨如何使用大语言模型来提高ontology匹配task的性能。</li>
<li>methods: 该论文使用了零例或几例提示的方法，并应用于不同的OAEI任务上。</li>
<li>results: 研究发现，只需要几个示例和一个Well-designed提示，就可以达到与超级vised匹配系统相同的性能水平。<details>
<summary>Abstract</summary>
Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth.
</details>
<details>
<summary>摘要</summary>
ontology (和更广义的知识图) 匹配是一项具有挑战性的任务，信息在自然语言中是匹配管道中最重要的信号之一。随着大语言模型的出现，可以更好地将这些知识integrated into匹配管道中。仍需要做出一些决策，例如如何生成有用的提示，如何在提示中表达知识图信息，哪种大语言模型最合适，如何提供现有的匹配，如何生成候选者等。在这篇论文中，我们提出了一个原型，通过零shot和几shot提示，使用多个开放的大语言模型对不同的OAEI任务进行应用。我们表明，只需很少的示例和一个Well-designed提示，就可以达到与经过监督匹配系统使用的许多真实数据匹配的效果。
</details></li>
</ul>
<hr>
<h2 id="Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language"><a href="#Conversations-in-Galician-a-Large-Language-Model-for-an-Underrepresented-Language" class="headerlink" title="Conversations in Galician: a Large Language Model for an Underrepresented Language"></a>Conversations in Galician: a Large Language Model for an Underrepresented Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03812">http://arxiv.org/abs/2311.03812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.irlab.org/irlab/cabuxa">https://gitlab.irlab.org/irlab/cabuxa</a></li>
<li>paper_authors: Eliseo Bao, Anxo Pérez, Javier Parapar</li>
<li>for: 这项研究的目的是提高大型自然语言处理（NLP）模型对 га利西安语言的支持，以便更好地包括所有语言社区在大语言模型的开发中。</li>
<li>methods: 这项研究使用了一个新的加利西安语言适应 dataset，包括 52,000 个 instruction 和 demonstration，以及 fine-tuning LLaMA-7B 模型，以便更好地遵循提供的 instruction。</li>
<li>results: 研究发现，通过使用加利西安语言适应 dataset 和 fine-tuning LLaMA-7B 模型，可以使模型更好地理解和回答加利西安语言的问题，并且可以通过知道相关语言的概念来生成 coherent 的文本。<details>
<summary>Abstract</summary>
The recent proliferation of Large Conversation Language Models has highlighted the economic significance of widespread access to this type of AI technologies in the current information age. Nevertheless, prevailing models have primarily been trained on corpora consisting of documents written in popular languages. The dearth of such cutting-edge tools for low-resource languages further exacerbates their underrepresentation in the current economic landscape, thereby impacting their native speakers. This paper introduces two novel resources designed to enhance Natural Language Processing (NLP) for the Galician language. We present a Galician adaptation of the Alpaca dataset, comprising 52,000 instructions and demonstrations. This dataset proves invaluable for enhancing language models by fine-tuning them to more accurately adhere to provided instructions. Additionally, as a demonstration of the dataset utility, we fine-tuned LLaMA-7B to comprehend and respond in Galician, a language not originally supported by the model, by following the Alpaca format. This work contributes to the research on multilingual models tailored for low-resource settings, a crucial endeavor in ensuring the inclusion of all linguistic communities in the development of Large Language Models. Another noteworthy aspect of this research is the exploration of how knowledge of a closely related language, in this case, Portuguese, can assist in generating coherent text when training resources are scarce. Both the Galician Alpaca dataset and Cabuxa-7B are publicly accessible on our Huggingface Hub, and we have made the source code available to facilitate replication of this experiment and encourage further advancements for underrepresented languages.
</details>
<details>
<summary>摘要</summary>
最近大量对话语言模型的普及，抛砖了现代信息时代对这种人工智能技术的经济意义。然而，现有模型主要在受欢迎语言的文献库进行训练。这Result in low-resource语言的不足，进一步削弱了它们在当前经济景观中的表现，从而影响当地的native speakers。本文介绍了两个新资源，旨在提高 galician 语言的自然语言处理（NLP）。我们提供了一个 galician 化的 Alpaca 数据集，包括 52,000 个说明和示例。这个数据集对于提高语言模型进行精度的调整是非常有价值。此外，我们通过 Alpaca 格式，使用 LLaMA-7B 模型以 galician 语言进行理解和回答，这是原本不支持该语言的模型。这项研究对于针对低资源设置的多语言模型的研究具有重要意义，这是确保所有语言社区在大语言模型的发展中得到包容。此外，我们还发现了一个关键的发现：当资源稀缺时，了解相关语言的知识（在这种情况下是葡萄牙语）可以帮助生成 coherent 的文本。galician Alpaca 数据集和 Cabuxa-7B 模型都公开 accessible 在我们的 Huggingface Hub 上，并且我们已经提供了源代码，以便复现这个实验和促进低资源语言的进一步发展。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Pair-Corrector-for-Dense-Retrieval"><a href="#Noisy-Pair-Corrector-for-Dense-Retrieval" class="headerlink" title="Noisy Pair Corrector for Dense Retrieval"></a>Noisy Pair Corrector for Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03798">http://arxiv.org/abs/2311.03798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu, Daya Guo, Jiancheng Lv, Jian Guo</li>
<li>for: 本研究探讨了 dense retrieval 模型在受到匹配错误的情况下的表现，并提出了一种名为 Noisy Pair Corrector (NPC) 的解决方案。</li>
<li>methods: NPC 方法包括检测模块和修正模块，检测模块通过计算 позитив答案和易得负答案的抖擞来估算噪声对的对。修正模块使用 Exponential Moving Average (EMA) 模型提供一个软监督信号，以帮助减少噪声的影响。</li>
<li>results: 实验结果表明，NPC 在 Natural Question 和 TriviaQA 等文本检索 benchmark 上 exhibits 出色的表现，可以减少噪声对的影响并提高模型的表现。<details>
<summary>Abstract</summary>
Most dense retrieval models contain an implicit assumption: the training query-document pairs are exactly matched. Since it is expensive to annotate the corpus manually, training pairs in real-world applications are usually collected automatically, which inevitably introduces mismatched-pair noise. In this paper, we explore an interesting and challenging problem in dense retrieval, how to train an effective model with mismatched-pair noise. To solve this problem, we propose a novel approach called Noisy Pair Corrector (NPC), which consists of a detection module and a correction module. The detection module estimates noise pairs by calculating the perplexity between annotated positive and easy negative documents. The correction module utilizes an exponential moving average (EMA) model to provide a soft supervised signal, aiding in mitigating the effects of noise. We conduct experiments on text-retrieval benchmarks Natural Question and TriviaQA, code-search benchmarks StaQC and SO-DS. Experimental results show that NPC achieves excellent performance in handling both synthetic and realistic noise.
</details>
<details>
<summary>摘要</summary>
大多数密集检索模型假设训练查询文档对是匹配的，但在实际应用中，训练对不可能手动注释整个库，这会导致匹配对杂谔噪声。在这篇论文中，我们研究一个有趣且挑战的 dense retrieval 问题：如何在匹配对杂谔噪声的情况下训练一个有效的模型。为解决这个问题，我们提出了一种新的方法called Noisy Pair Corrector (NPC)，它包括检测模块和修正模块。检测模块通过计算标注正方和易取负方文档的凝固性来估计噪声对。修正模块使用抽象移动平均（EMA）模型提供一个软件指导信号，以帮助减轻噪声的影响。我们在 Natural Question 和 TriviaQA 等文本检索标准套件上进行了实验，结果表明，NPC在处理 sintetic 和实际噪声方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment"><a href="#Character-Level-Bangla-Text-to-IPA-Transcription-Using-Transformer-Architecture-with-Sequence-Alignment" class="headerlink" title="Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment"></a>Character-Level Bangla Text-to-IPA Transcription Using Transformer Architecture with Sequence Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03792">http://arxiv.org/abs/2311.03792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakir Hasan, Shrestha Datta, Ameya Debnath</li>
<li>For: The paper is written for the purpose of developing an Artificial Intelligence and Machine Learning-based system for accurate IPA mapping of Bangla words.* Methods: The paper uses a transformer-based sequence-to-sequence model at the letter and symbol level to map the IPA of each Bangla word. The model consists of 8.5 million parameters and only one decoder and encoder layer. Additionally, manual mapping is used to handle punctuation marks and foreign languages in the text.* Results: The paper achieves the top position in the public ranking of DataVerse Challenge - ITVerse 2023 with a word error rate of 0.10582.<details>
<summary>Abstract</summary>
The International Phonetic Alphabet (IPA) is indispensable in language learning and understanding, aiding users in accurate pronunciation and comprehension. Additionally, it plays a pivotal role in speech therapy, linguistic research, accurate transliteration, and the development of text-to-speech systems, making it an essential tool across diverse fields. Bangla being 7th as one of the widely used languages, gives rise to the need for IPA in its domain. Its IPA mapping is too diverse to be captured manually giving the need for Artificial Intelligence and Machine Learning in this field. In this study, we have utilized a transformer-based sequence-to-sequence model at the letter and symbol level to get the IPA of each Bangla word as the variation of IPA in association of different words is almost null. Our transformer model only consisted of 8.5 million parameters with only a single decoder and encoder layer. Additionally, to handle the punctuation marks and the occurrence of foreign languages in the text, we have utilized manual mapping as the model won't be able to learn to separate them from Bangla words while decreasing our required computational resources. Finally, maintaining the relative position of the sentence component IPAs and generation of the combined IPA has led us to achieve the top position with a word error rate of 0.10582 in the public ranking of DataVerse Challenge - ITVerse 2023 (https://www.kaggle.com/competitions/dataverse_2023/).
</details>
<details>
<summary>摘要</summary>
国际音声字母（IPA）是语言学习和理解的不可或缺的工具，帮助用户正确发音和理解。同时，它在语音疾病治疗、语言研究、准确转写和文本读取系统的开发中扮演着关键性的角色，因此在多个领域都是必备的工具。孟加拉语是全球第七大使用语言之一，因此在它的领域中也存在IPA的需求。孟加拉语的IPA映射非常复杂，需要使用人工智能和机器学习来处理。在这项研究中，我们使用了基于转换器的序列到序列模型，在字母和符号层次上进行了每个孟加拉语单词的IPA映射。我们的转换器模型只有8500万参数，仅有一个解码和编码层。此外，为了处理文本中的括号和外语，我们使用了手动映射，因为模型无法从孟加拉语单词中分离它们。最后，我们保持了句子组成部分的IPA相对位置，并生成了组合的IPA，使我们在DataVerse Challenge - ITVerse 2023（https://www.kaggle.com/competitions/dataverse_2023）公开排名中获得了第一名，word error rate为0.10582。
</details></li>
</ul>
<hr>
<h2 id="Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models"><a href="#Language-Representation-Projection-Can-We-Transfer-Factual-Knowledge-across-Languages-in-Multilingual-Language-Models" class="headerlink" title="Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?"></a>Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03788">http://arxiv.org/abs/2311.03788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaoyang Xu, Junzhuo Li, Deyi Xiong</li>
<li>for: 本研究探讨了将英语知识转移到非英语语言中的可能性，以提高多语言预训练语言模型中的事实知识探索性能。</li>
<li>methods: 我们提出了两种参数free的语言表示 проекtion模块（LRP2），以将非英语表示转换成英语相似的表示，并将英语表示还原回非英语语言的表示。</li>
<li>results: 实验结果表明，LRP2能够显著提高事实知识检索精度，并且可以在多种非英语语言中传递知识。我们还从语义表示空间和cross-语言知识神经的角度进行了机制分析。<details>
<summary>Abstract</summary>
Multilingual pretrained language models serve as repositories of multilingual factual knowledge. Nevertheless, a substantial performance gap of factual knowledge probing exists between high-resource languages and low-resource languages, suggesting limited implicit factual knowledge transfer across languages in multilingual pretrained language models. This paper investigates the feasibility of explicitly transferring relatively rich factual knowledge from English to non-English languages. To accomplish this, we propose two parameter-free $\textbf{L}$anguage $\textbf{R}$epresentation $\textbf{P}$rojection modules (LRP2). The first module converts non-English representations into English-like equivalents, while the second module reverts English-like representations back into representations of the corresponding non-English language. Experimental results on the mLAMA dataset demonstrate that LRP2 significantly improves factual knowledge retrieval accuracy and facilitates knowledge transferability across diverse non-English languages. We further investigate the working mechanism of LRP2 from the perspectives of representation space and cross-lingual knowledge neuron.
</details>
<details>
<summary>摘要</summary>
多语言预训成本模型作为多语言事实知识存储库。然而，高资源语言和低资源语言之间的事实知识探测性能存在显著差距，表明多语言预训模型之间的隐式事实知识传递有限。本文探究可以将英语上的较富事实知识显式传递到非英语语言上。为此，我们提议了两个参数无关的语言表示 проекtion模块（LRP2）。首先模块将非英语表示转换成英语相似的表示，其次模块将英语相似的表示恢复回到非英语语言的表示中。实验结果表明，LRP2能够显著提高事实知识检索精度和促进不同非英语语言之间的知识传递性。我们进一步从语言表示空间和跨语言知识神经的角度研究LRP2的工作机制。
</details></li>
</ul>
<hr>
<h2 id="Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation"><a href="#Gender-Inflected-or-Bias-Inflicted-On-Using-Grammatical-Gender-Cues-for-Bias-Evaluation-in-Machine-Translation" class="headerlink" title="Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation"></a>Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for Bias Evaluation in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03767">http://arxiv.org/abs/2311.03767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iampushpdeep/gender-bias-hi-en-eval">https://github.com/iampushpdeep/gender-bias-hi-en-eval</a></li>
<li>paper_authors: Pushpdeep Singh</li>
<li>for: 这个研究的目的是评估基于印地语的自然语言处理机器翻译模型中的性别偏见。</li>
<li>methods: 这个研究使用了印地语的两个集成集：OTSC-Hindi和WinoMT-Hindi，用于自动评估不同的印地语-英语（HI-EN）机器翻译系统中的性别偏见。</li>
<li>results: 这个研究发现，基于印地语的机器翻译系统中存在性别偏见，并且这种偏见与英语为源语言的研究结果不同。这个研究指出，在设计外部偏见评估数据集时，需要考虑语言的性质。<details>
<summary>Abstract</summary>
Neural Machine Translation (NMT) models are state-of-the-art for machine translation. However, these models are known to have various social biases, especially gender bias. Most of the work on evaluating gender bias in NMT has focused primarily on English as the source language. For source languages different from English, most of the studies use gender-neutral sentences to evaluate gender bias. However, practically, many sentences that we encounter do have gender information. Therefore, it makes more sense to evaluate for bias using such sentences. This allows us to determine if NMT models can identify the correct gender based on the grammatical gender cues in the source sentence rather than relying on biased correlations with, say, occupation terms. To demonstrate our point, in this work, we use Hindi as the source language and construct two sets of gender-specific sentences: OTSC-Hindi and WinoMT-Hindi that we use to evaluate different Hindi-English (HI-EN) NMT systems automatically for gender bias. Our work highlights the importance of considering the nature of language when designing such extrinsic bias evaluation datasets.
</details>
<details>
<summary>摘要</summary>
神经机器翻译（NMT）模型目前是翻译机器学会的国际标准。然而，这些模型经常带有各种社会偏见，特别是性别偏见。大多数对NMT模型的性别偏见评估都集中在英语作为源语言。对于不同的源语言，大多数研究使用中性句子来评估性别偏见。然而，在实际生活中，我们常遇到带有性别信息的句子。因此，更加合理地评估NMT模型是否能够根据源句子中的 grammatical gender 信息正确地识别性别。为了证明我们的点，在这项工作中，我们使用旁遮普语作为源语言，并构建了两个 gender-specific 句子集：OTSC-Hindi 和 WinoMT-Hindi，以自动评估不同的旁遮普语-英语（HI-EN） NMT 系统的性别偏见。我们的工作强调了在设计这类外部偏见评估数据时应考虑语言的特点。
</details></li>
</ul>
<hr>
<h2 id="Multilingual-Mathematical-Autoformalization"><a href="#Multilingual-Mathematical-Autoformalization" class="headerlink" title="Multilingual Mathematical Autoformalization"></a>Multilingual Mathematical Autoformalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03755">http://arxiv.org/abs/2311.03755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertqjiang/mma">https://github.com/albertqjiang/mma</a></li>
<li>paper_authors: Albert Q. Jiang, Wenda Li, Mateja Jamnik</li>
<li>for: 该论文目的是提出一个大型、灵活、多语言、多领域的自动化形式化数据集，以便提高自动化形式化研究的进步。</li>
<li>methods: 该论文使用语言模型将正式数学陈述翻译成相应的非正式陈述，以创建一个大型、多语言、多领域的自动化形式化数据集。</li>
<li>results: 实验表明，将语言模型在$\texttt{MMA}$数据集上进行微调，可以提高自动化形式化模型在$\texttt{miniF2F}$和$\texttt{ProofNet}$测试 benchmark 上的表现，从0%提高到16-18%。此外，该研究还示出了在多语言正式数据上进行微调可以提高自动化形式化模型在单语言任务上的表现。<details>
<summary>Abstract</summary>
Autoformalization is the task of translating natural language materials into machine-verifiable formalisations. Progress in autoformalization research is hindered by the lack of a sizeable dataset consisting of informal-formal pairs expressing the same essence. Existing methods tend to circumvent this challenge by manually curating small corpora or using few-shot learning with large language models. But these methods suffer from data scarcity and formal language acquisition difficulty. In this work, we create $\texttt{MMA}$, a large, flexible, multilingual, and multi-domain dataset of informal-formal pairs, by using a language model to translate in the reverse direction, that is, from formal mathematical statements into corresponding informal ones. Experiments show that language models fine-tuned on $\texttt{MMA}$ produce $16-18\%$ of statements acceptable with minimal corrections on the $\texttt{miniF2F}$ and $\texttt{ProofNet}$ benchmarks, up from $0\%$ with the base model. We demonstrate that fine-tuning on multilingual formal data results in more capable autoformalization models even when deployed on monolingual tasks.
</details>
<details>
<summary>摘要</summary>
自然语言材料的自动化正式化任务是将自然语言材料翻译成机器可验证的形式化表达。研究进步受到没有大量的正式-非正式对应对的数据集的限制。现有方法通常使用手动批处小样本或使用大语言模型几招学习来绕过这个挑战。但这些方法受到数据缺乏和正式语言学习困难的限制。在这项工作中，我们创建了$\texttt{MMA}$数据集，这是一个大型、灵活、多语言和多领域的正式-非正式对应对数据集，我们使用语言模型将正式数学陈述翻译到对应的非正式陈述中。实验显示，将语言模型在$\texttt{MMA}$上进行 fine-tuning 后，在 $\texttt{miniF2F}$ 和 $\texttt{ProofNet}$ 测试benchmark上的AcceptableStatement数增加了16-18%，与基本模型相比增加了0%。我们示出了在多语言正式数据上进行 fine-tuning 后，在单语言任务上部署的自动化正式化模型会更具备能力。
</details></li>
</ul>
<hr>
<h2 id="Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics"><a href="#Which-is-better-Exploring-Prompting-Strategy-For-LLM-based-Metrics" class="headerlink" title="Which is better? Exploring Prompting Strategy For LLM-based Metrics"></a>Which is better? Exploring Prompting Strategy For LLM-based Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03754">http://arxiv.org/abs/2311.03754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin Lee, Seung Hun Han, Jiyoon Lee, Pilsung Kang</li>
<li>for: 这 paper 描述了在 Prompting Large Language Models as Explainable Metrics 共同任务中提交的 DSBA 提交，系统在两个 tracks：小summarization 和 large summarization  tracks 上进行了评估。</li>
<li>methods: 这 paper 使用了高级的 Large Language Models (LLMs) 如 GPT-4，以评估自然语言生成质量（NLG）的新方法。传统的相似性基于metric 如 BLEU 和 ROUGE 已经显示出来了与人类评估不一致，不适合开放式生成任务。为了解决这个问题，我们探索了 LLM-based metric 的潜在能力，特别是使用开源 LLMs。在这种研究中，我们系统地分析了各种提示和提示技术，并使用三种方法：提示策略、分数聚合和解释性。</li>
<li>results: 我们的研究表明，使用开源 LLMs 可以获得更高的评估精度，并且可以通过提示策略和分数聚合来提高NLG质量评估的可靠性。此外，我们还发现，通过生成 rationales 可以提供更多的解释，并且可以通过分析这些解释来了解 LLMs 的性能。<details>
<summary>Abstract</summary>
This paper describes the DSBA submissions to the Prompting Large Language Models as Explainable Metrics shared task, where systems were submitted to two tracks: small and large summarization tracks. With advanced Large Language Models (LLMs) such as GPT-4, evaluating the quality of Natural Language Generation (NLG) has become increasingly paramount. Traditional similarity-based metrics such as BLEU and ROUGE have shown to misalign with human evaluation and are ill-suited for open-ended generation tasks. To address this issue, we explore the potential capability of LLM-based metrics, especially leveraging open-source LLMs. In this study, wide range of prompts and prompting techniques are systematically analyzed with three approaches: prompting strategy, score aggregation, and explainability. Our research focuses on formulating effective prompt templates, determining the granularity of NLG quality scores and assessing the impact of in-context examples on LLM-based evaluation. Furthermore, three aggregation strategies are compared to identify the most reliable method for aggregating NLG quality scores. To examine explainability, we devise a strategy that generates rationales for the scores and analyzes the characteristics of the explanation produced by the open-source LLMs. Extensive experiments provide insights regarding evaluation capabilities of open-source LLMs and suggest effective prompting strategies.
</details>
<details>
<summary>摘要</summary>
The study systematically analyzes a wide range of prompts and prompting techniques using three approaches: prompting strategy, score aggregation, and explainability. The focus is on formulating effective prompt templates, determining the granularity of NLG quality scores, and assessing the impact of in-context examples on LLM-based evaluation. Additionally, the paper compares three aggregation strategies to determine the most reliable method for aggregating NLG quality scores. To examine explainability, the paper devises a strategy that generates rationales for the scores and analyzes the characteristics of the explanations produced by the open-source LLMs.Extensive experiments provide insights into the evaluation capabilities of open-source LLMs and suggest effective prompting strategies. The paper concludes that LLM-based metrics have the potential to provide more accurate evaluations of NLG quality, and that careful consideration of prompting strategies and score aggregation methods is essential for obtaining reliable results.
</details></li>
</ul>
<hr>
<h2 id="Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning"><a href="#Unified-Low-Resource-Sequence-Labeling-by-Sample-Aware-Dynamic-Sparse-Finetuning" class="headerlink" title="Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning"></a>Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03748">http://arxiv.org/abs/2311.03748</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/psunlpgroup/fish-dip">https://github.com/psunlpgroup/fish-dip</a></li>
<li>paper_authors: Sarkar Snigdha Sarathi Das, Ranran Haoran Zhang, Peng Shi, Wenpeng Yin, Rui Zhang</li>
<li>for: 提高sequence labeling任务中的模型性能，尤其是在数据有限的情况下。</li>
<li>methods: 提出了一种sample-aware dynamic sparse finetuning策略，通过在精度训练过程中选择一部分参数，根据反馈从高度预测错误的示例而决定，以便增强通用化。</li>
<li>results: 在五种sequence labeling任务上，实现了在低资源环境下缓和模型优化，提高性能，最高可达40%，并与另外的parameter-efficient fine-tuning和in-context learning策略相比，在极低资源环境下表现较好。<details>
<summary>Abstract</summary>
Unified Sequence Labeling that articulates different sequence labeling problems such as Named Entity Recognition, Relation Extraction, Semantic Role Labeling, etc. in a generalized sequence-to-sequence format opens up the opportunity to make the maximum utilization of large language model knowledge toward structured prediction. Unfortunately, this requires formatting them into specialized augmented format unknown to the base pretrained language model (PLMs) necessitating finetuning to the target format. This significantly bounds its usefulness in data-limited settings where finetuning large models cannot properly generalize to the target format. To address this challenge and leverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic sparse finetuning strategy that selectively focuses on a fraction of parameters, informed by feedback from highly regressing examples, during the fine-tuning process. By leveraging the dynamism of sparsity, our approach mitigates the impact of well-learned samples and prioritizes underperforming instances for improvement in generalization. Across five tasks of sequence labeling, we demonstrate that FISH-DIP can smoothly optimize the model in low resource settings offering upto 40% performance improvements over full fine-tuning depending on target evaluation settings. Also, compared to in-context learning and other parameter-efficient fine-tuning approaches, FISH-DIP performs comparably or better, notably in extreme low-resource settings.
</details>
<details>
<summary>摘要</summary>
通用序列标签（Unified Sequence Labeling）可以将不同的序列标签问题（如命名实体识别、关系抽取、Semantic Role Labeling等）转换为通用的序列到序列的格式，从而使最大化语言模型知识的应用于结构预测。然而，这需要将其格式化为特殊的扩展格式，这些格式不знаком于基础预训练语言模型（PLMs），因此需要进行迁移学习。这会限制其在数据有限的设置中的使用，因为大型模型在目标格式上不能良好总结。为解决这个挑战并有效地利用PLM知识，我们提出了鱼雏钻探（FISH-DIP），一种样本意识的动态稀疏训练策略。通过在训练过程中选择一部分参数，并在这些参数上进行稀疏训练，我们的方法可以减轻已经学习好的样本的影响，并且优先级推动不良表现的实例进行改进。在五种序列标签任务上，我们示出了FISH-DIP可以在低资源设置下细化模型，提供大约40%的性能提升，具体取决于目标评估设置。同时，相比卷积学习和其他参数效率的训练方法，FISH-DIP在极低资源设置下表现相当或更好。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning"><a href="#Leveraging-Structured-Information-for-Explainable-Multi-hop-Question-Answering-and-Reasoning" class="headerlink" title="Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning"></a>Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03734">http://arxiv.org/abs/2311.03734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruosen Li, Xinya Du</li>
<li>for: 本研究旨在探讨如何通过提取文本中的semantic结构来提高多步问答中的推理能力。</li>
<li>methods: 本研究使用信息提取技术来提取文本中的实体、关系和事件，并构建了基于这些结构的多步问答框架。</li>
<li>results: 实验和人类评价表明，我们的框架可以生成更加 faithful的推理链和显著提高两个标准测试集的问答性能。此外，提取的结构本身就提供了固有的解释，比如生成的推理链和优先级基于的解释更受人类喜欢。<details>
<summary>Abstract</summary>
Neural models, including large language models (LLMs), achieve superior performance on multi-hop question-answering. To elicit reasoning capabilities from LLMs, recent works propose using the chain-of-thought (CoT) mechanism to generate both the reasoning chain and the answer, which enhances the model's capabilities in conducting multi-hop reasoning. However, several challenges still remain: such as struggling with inaccurate reasoning, hallucinations, and lack of interpretability. On the other hand, information extraction (IE) identifies entities, relations, and events grounded to the text. The extracted structured information can be easily interpreted by humans and machines (Grishman, 2019). In this work, we investigate constructing and leveraging extracted semantic structures (graphs) for multi-hop question answering, especially the reasoning process. Empirical results and human evaluations show that our framework: generates more faithful reasoning chains and substantially improves the QA performance on two benchmark datasets. Moreover, the extracted structures themselves naturally provide grounded explanations that are preferred by humans, as compared to the generated reasoning chains and saliency-based explanations.
</details>
<details>
<summary>摘要</summary>
神经网络模型，包括大型语言模型（LLM），在多步问答中表现出优秀的性能。为了从LLM中提取逻辑能力， latest works提议使用链条思维（CoT）机制来生成问答和逻辑链，从而提高模型的多步逻辑能力。然而，还有一些挑战需要解决：如果推理不准确，幻觉和解释性不足。对此，信息提取（IE）可以识别文本中的实体、关系和事件，并将其与文本相关联。提取的结构化信息可以轻松地被人类和机器解释（Grishman，2019）。在这项工作中，我们研究构建和利用提取的semantic structures（图）来进行多步问答，特别是逻辑过程。实验结果和人工评价表明，我们的框架：生成更加 faithful的逻辑链和对两个 benchmark datasets 的问答性能提高了很多。此外，提取的结构本身就自然提供了基于实体的解释，与生成的逻辑链和saliency-based解释相比，更受人类喜欢。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Learn-for-Few-shot-Continual-Active-Learning"><a href="#Learning-to-Learn-for-Few-shot-Continual-Active-Learning" class="headerlink" title="Learning to Learn for Few-shot Continual Active Learning"></a>Learning to Learn for Few-shot Continual Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03732">http://arxiv.org/abs/2311.03732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stella Ho, Ming Liu, Shang Gao, Longxiang Gao</li>
<li>for: 这篇论文旨在解决对于前置任务的稳定性和新任务的灵活性之间的冲突，特别是在自然语言处理领域。</li>
<li>methods: 这篇论文提出了一个简单 yet efficient的方法，called Meta-Continual Active Learning，并使用meta-学习和经验回顾来解决稳定性和灵活性之间的冲突。</li>
<li>results: 实验结果显示，这篇论文的提案方法可以快速地适应新任务，同时避免遗传性忘记。另外，我们还分析了不同的活动学习策略和内存抽样方法在几个shot CAL设定下的效果。<details>
<summary>Abstract</summary>
Continual learning strives to ensure stability in solving previously seen tasks while demonstrating plasticity in a novel domain. Recent advances in CL are mostly confined to a supervised learning setting, especially in NLP domain. In this work, we consider a few-shot continual active learning (CAL) setting where labeled data is inadequate, and unlabeled data is abundant but with a limited annotation budget. We propose a simple but efficient method, called Meta-Continual Active Learning. Specifically, we employ meta-learning and experience replay to address the trade-off between stability and plasticity. As a result, it finds an optimal initialization that efficiently utilizes annotated information for fast adaptation while preventing catastrophic forgetting of past tasks. We conduct extensive experiments to validate the effectiveness of the proposed method and analyze the effect of various active learning strategies and memory sample selection methods in a few-shot CAL setup. Our experiment results demonstrate that random sampling is the best default strategy for both active learning and memory sample selection to solve few-shot CAL problems.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Large-Language-Models-Attribution"><a href="#A-Survey-of-Large-Language-Models-Attribution" class="headerlink" title="A Survey of Large Language Models Attribution"></a>A Survey of Large Language Models Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03731">http://arxiv.org/abs/2311.03731</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HITsz-TMG/awesome-llm-attributions">https://github.com/HITsz-TMG/awesome-llm-attributions</a></li>
<li>paper_authors: Dongfang Li, Zetian Sun, Xinshuo Hu, Zhenyu Liu, Ziyang Chen, Baotian Hu, Aiguo Wu, Min Zhang</li>
<li>for: 本研究旨在批判开放领域生成系统中使用的归因机制，特别是大语言模型。</li>
<li>methods: 本文综述了开放领域生成系统中归因机制的应用，包括归因搜索引擎等。</li>
<li>results: 本研究发现，归因机制可以提高开放领域生成系统的可靠性和准确性，但也存在问题，如知识库含义不明确、内置偏见和过度归因等。<details>
<summary>Abstract</summary>
Open-domain generative systems have gained significant attention in the field of conversational AI (e.g., generative search engines). This paper presents a comprehensive review of the attribution mechanisms employed by these systems, particularly large language models. Though attribution or citation improve the factuality and verifiability, issues like ambiguous knowledge reservoirs, inherent biases, and the drawbacks of excessive attribution can hinder the effectiveness of these systems. The aim of this survey is to provide valuable insights for researchers, aiding in the refinement of attribution methodologies to enhance the reliability and veracity of responses generated by open-domain generative systems. We believe that this field is still in its early stages; hence, we maintain a repository to keep track of ongoing studies at https://github.com/HITsz-TMG/awesome-llm-attributions.
</details>
<details>
<summary>摘要</summary>
开放领域生成系统在对话AI领域已经吸引了广泛的注意力（例如生成搜索引擎）。本文对这些系统使用的归因机制进行了全面的审查，特别是大语言模型。归因或参考可以提高回答的 фактиче性和可靠性，但是存在困难的知识库、内置偏见和过度归因的问题可能会妨碍这些系统的效iveness。本评论的目的是为研究人员提供有价值的洞察，以便通过修正归因方法来提高开放领域生成系统的可靠性和真实性。我们认为这个领域还处于早期阶段，因此我们维护了一个Repository，以跟踪进行中的研究：https://github.com/HITsz-TMG/awesome-llm-attributions。
</details></li>
</ul>
<hr>
<h2 id="Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts"><a href="#Bilingual-Corpus-Mining-and-Multistage-Fine-Tuning-for-Improving-Machine-Translation-of-Lecture-Transcripts" class="headerlink" title="Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts"></a>Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine Translation of Lecture Transcripts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03696">http://arxiv.org/abs/2311.03696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shyyhs/CourseraParallelCorpusMining">https://github.com/shyyhs/CourseraParallelCorpusMining</a></li>
<li>paper_authors: Haiyue Song, Raj Dabre, Chenhui Chu, Atsushi Fujita, Sadao Kurohashi</li>
<li>for: 这 paper 是为了提高在线课程学习译文质量的研究。</li>
<li>methods: 这 paper 使用了一种框架，用于从 Coursera 上的公开课课程中提取并构建平行 corpora，并使用动态计划法进行句子对齐。</li>
<li>results: 这 paper 的实验表明，使用这些自动生成的平行 corpora可以提高 lecture 笔记翻译质量，并且可以与预处理的平行 corpora相比肃。此外，这 paper 还提供了一些有关收集和清洁 corpora、提取平行句子和创建高质量评估分割的指南。<details>
<summary>Abstract</summary>
Lecture transcript translation helps learners understand online courses, however, building a high-quality lecture machine translation system lacks publicly available parallel corpora. To address this, we examine a framework for parallel corpus mining, which provides a quick and effective way to mine a parallel corpus from publicly available lectures on Coursera. To create the parallel corpora, we propose a dynamic programming based sentence alignment algorithm which leverages the cosine similarity of machine-translated sentences. The sentence alignment F1 score reaches 96%, which is higher than using the BERTScore, LASER, or sentBERT methods. For both English--Japanese and English--Chinese lecture translations, we extracted parallel corpora of approximately 50,000 lines and created development and test sets through manual filtering for benchmarking translation performance. Through machine translation experiments, we show that the mined corpora enhance the quality of lecture transcript translation when used in conjunction with out-of-domain parallel corpora via multistage fine-tuning. Furthermore, this study also suggests guidelines for gathering and cleaning corpora, mining parallel sentences, cleaning noise in the mined data, and creating high-quality evaluation splits. For the sake of reproducibility, we have released the corpora as well as the code to create them. The dataset is available at https://github.com/shyyhs/CourseraParallelCorpusMining.
</details>
<details>
<summary>摘要</summary>
讲义笔录翻译帮助学习者理解在线课程，但建立高质量讲义翻译系统缺乏公共可用的平行 corpora。为解决这问题，我们提出了平行 corpora 挖掘框架，该框架可以快速并有效地挖掘来自 Coursera 上公共讲义的平行 corpora。为创建平行 corpora，我们提议使用动态编程基于 sentence alignment 算法，利用机器翻译后的句子之间的 косинуsimilarity。 sentence alignment F1 分数达96%，高于使用 BERTScore、LASER 或 sentBERT 方法。对英语--日语和英语--中文讲义翻译，我们提取了约50,000行的平行 corpora，并通过手动筛选创建了开发测试集。通过机器翻译实验，我们示示了挖掘后的 corpora 可以提高讲义笔录翻译质量。此外，本研究还提供了收集和清洁 corpora、挖掘平行句子、清理挖掘后数据中的噪音以及创建高质量评估分割的指南。为保持可重现性，我们已经发布了 corpora 以及创建它们所需的代码，数据集可在 GitHub 上获取：https://github.com/shyyhs/CourseraParallelCorpusMining。
</details></li>
</ul>
<hr>
<h2 id="Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models"><a href="#Dissecting-the-Runtime-Performance-of-the-Training-Fine-tuning-and-Inference-of-Large-Language-Models" class="headerlink" title="Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models"></a>Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03687">http://arxiv.org/abs/2311.03687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longteng Zhang, Xiang Liu, Zeyu Li, Xinglin Pan, Peijie Dong, Ruibo Fan, Rui Guo, Xin Wang, Qiong Luo, Shaohuai Shi, Xiaowen Chu</li>
<li>for: 本文旨在 benchmarking 大型语言模型（LLMs）在不同硬件和软件栈上的运行性能，以帮助用户更好地选择配置并优化系统架构。</li>
<li>methods: 本文使用了多种优化技术，包括 ZeRO、量化、重computation 和 FlashAttention，以提高 LLMS 的运行性能。</li>
<li>results: 本文的结果表明，在不同硬件和软件栈上，不同大小的 LLMS 的运行性能有很大差异。通过对不同优化技术和硬件平台的分析，本文可以帮助用户更好地选择配置并优化系统架构。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have seen great advance in both academia and industry, and their popularity results in numerous open-source frameworks and techniques in accelerating LLM pre-training, fine-tuning, and inference. Training and deploying LLMs are expensive as it requires considerable computing resources and memory, hence many efficient approaches have been developed for improving system pipelines as well as operators. However, the runtime performance can vary significantly across hardware and software stacks, which makes it difficult to choose the best configuration. In this work, we aim to benchmark the performance from both macro and micro perspectives. First, we benchmark the end-to-end performance of pre-training, fine-tuning, and serving LLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and 70B) on three 8-GPU platforms with and without individual optimization techniques, including ZeRO, quantization, recomputation, FlashAttention. Then, we dive deeper to provide a detailed runtime analysis of the sub-modules, including computing and communication operators in LLMs. For end users, our benchmark and findings help better understand different optimization techniques, training and inference frameworks, together with hardware platforms in choosing configurations for deploying LLMs. For researchers, our in-depth module-wise analyses discover potential opportunities for future work to further optimize the runtime performance of LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training"><a href="#CBSiMT-Mitigating-Hallucination-in-Simultaneous-Machine-Translation-with-Weighted-Prefix-to-Prefix-Training" class="headerlink" title="CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training"></a>CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation with Weighted Prefix-to-Prefix Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03672">http://arxiv.org/abs/2311.03672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengge Liu, Wen Zhang, Xiang Li, Yanzhi Tian, Yuhang Guo, Jian Luan, Bin Wang, Shuoying Chen</li>
<li>for: 提高同时翻译（SiMT）任务中的翻译质量，特别是在源语言句子只有部分内容时开始翻译。</li>
<li>methods: 使用 prefix-to-prefix 框架，学习预测目标单词使用只有部分源prefix。但是由于语言的单词顺序不同，可能会导致模型uffer hallucination问题，即目标输出不符合源输入。</li>
<li>results: 提出了一种 Confidence-Based Simultaneous Machine Translation（CBSiMT）框架，通过模型自信度来识别hallucination单词，并通过加权 prefix-to-prefix 训练来缓解其影响。实验结果在 MuST-C 英语-中文和 WMT15 德语-英语 SiMT任务上表明，我们的方法可以在不同的延迟情况下， consistent 提高翻译质量，最高达到 2 BLEU 分数提升。<details>
<summary>Abstract</summary>
Simultaneous machine translation (SiMT) is a challenging task that requires starting translation before the full source sentence is available. Prefix-to-prefix framework is often applied to SiMT, which learns to predict target tokens using only a partial source prefix. However, due to the word order difference between languages, misaligned prefix pairs would make SiMT models suffer from serious hallucination problems, i.e. target outputs that are unfaithful to source inputs. Such problems can not only produce target tokens that are not supported by the source prefix, but also hinder generating the correct translation by receiving more source words. In this work, we propose a Confidence-Based Simultaneous Machine Translation (CBSiMT) framework, which uses model confidence to perceive hallucination tokens and mitigates their negative impact with weighted prefix-to-prefix training. Specifically, token-level and sentence-level weights are calculated based on model confidence and acted on the loss function. We explicitly quantify the faithfulness of the generated target tokens using the token-level weight, and employ the sentence-level weight to alleviate the disturbance of sentence pairs with serious word order differences on the model. Experimental results on MuST-C English-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our method can consistently improve translation quality at most latency regimes, with up to 2 BLEU scores improvement at low latency.
</details>
<details>
<summary>摘要</summary>
同时机器翻译（SiMT）是一项具有挑战性的任务，需要在源句子完全可用之前开始翻译。prefix-to-prefix框架经常用于SiMT，这种方法学习预测目标字符串使用只有部分源前缀。然而，由于语言之间的单词顺序差异，不一致的前缀对SiMT模型会导致严重的幻觉问题，即目标输出不符合源输入。这些问题不仅会生成不支持源前缀的目标字符串，还会阻碍正确翻译的生成 by receiving more source words。在这项工作中，我们提出了一种信息量基础同时机器翻译（CBSiMT）框架，使用模型信息量来识别幻觉字符串并减轻其影响。具体来说，我们计算了基于模型信息量的字符串级和句子级权重，并将其作用到损失函数中。我们Explicitly量化生成的目标字符串的准确程度使用字符串级权重，并使用句子级权重来减轻 Word order differences between sentences on the model.实验结果表明，我们的方法可以在不同的延迟级别上 consistently 提高翻译质量，并在低延迟级别上达到2 BLEU 分数的提高。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-NLP-Models-Notion-and-Causation"><a href="#Generalization-of-NLP-Models-Notion-and-Causation" class="headerlink" title="Generalization of NLP Models: Notion and Causation"></a>Generalization of NLP Models: Notion and Causation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03663">http://arxiv.org/abs/2311.03663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aparna Elangovan, Jiayuan He, Yuan Li, Karin Verspoor</li>
<li>for: 这篇论文主要是为了探讨机器学习模型在自然语言处理领域的总体化能力和可重用性。</li>
<li>methods: 论文使用了严格的实验设计和数据分析方法来研究机器学习模型的可重用性。</li>
<li>results: 研究发现，在不同的数据集上，机器学习模型的性能会受到“外部随机效应”的影响，导致模型的总体化能力受到限制。<details>
<summary>Abstract</summary>
The NLP community typically relies on performance of a model on a held-out test set to assess generalization. Performance drops observed in datasets outside of official test sets are generally attributed to "out-of-distribution'' effects. Here, we explore the foundations of generalizability and study the various factors that affect it, articulating generalizability lessons from clinical studies. In clinical research generalizability depends on (a) internal validity of experiments to ensure controlled measurement of cause and effect, and (b) external validity or transportability of the results to the wider population. We present the need to ensure internal validity when building machine learning models in natural language processing, especially where results may be impacted by spurious correlations in the data. We demonstrate how spurious factors, such as the distance between entities in relation extraction tasks, can affect model internal validity and in turn adversely impact generalization. We also offer guidance on how to analyze generalization failures.
</details>
<details>
<summary>摘要</summary>
《NLP社区通常通过模型在保留测试集上的性能来评估通用性。测试集外的性能下降通常被归结为“非常区”的效果。本文探讨通用性的基础和不同因素的影响，从临床研究中提取通用性评估的教训。在自然语言处理中建模时，特别是当结果受到数据中的偶极相关性的影响时，需要保证内部有效性。我们示例了如何使用距离Entity之间的关系提取任务中的偶极相关性，对模型的内部有效性产生影响，从而对通用性产生负面影响。我们还提供了分析通用性失败的指导。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Innovation-and-Word-Usage-Patterns-in-Machine-Learning"><a href="#Innovation-and-Word-Usage-Patterns-in-Machine-Learning" class="headerlink" title="Innovation and Word Usage Patterns in Machine Learning"></a>Innovation and Word Usage Patterns in Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03633">http://arxiv.org/abs/2311.03633</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vitorbborges/monografia-PET22">https://github.com/vitorbborges/monografia-PET22</a></li>
<li>paper_authors: Vítor Bandeira Borges, Daniel Oliveira Cajueiro</li>
<li>for: 本研究探讨机器学习研究的动态景观演化。</li>
<li>methods: 通过矩阵Dirichlet分配来归纳出重要主题和基本概念，并对这些主题进行了全面的演化分析。</li>
<li>results: 通过使用卷积-莱布器分配度量，量化研究贡献的新颖度和偏离度，并发现了一些重要的研究人员和学术会议在机器学习领域的积极作用。<details>
<summary>Abstract</summary>
In this study, we delve into the dynamic landscape of machine learning research evolution. Initially, through the utilization of Latent Dirichlet Allocation, we discern pivotal themes and fundamental concepts that have emerged within the realm of machine learning. Subsequently, we undertake a comprehensive analysis to track the evolutionary trajectories of these identified themes. To quantify the novelty and divergence of research contributions, we employ the Kullback-Leibler Divergence metric. This statistical measure serves as a proxy for ``surprise'', indicating the extent of differentiation between the content of academic papers and the subsequent developments in research. By amalgamating these insights, we gain the ability to ascertain the pivotal roles played by prominent researchers and the significance of specific academic venues (periodicals and conferences) within the machine learning domain.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们探索机器学习研究脉络的动态景观。首先，通过使用秘密分配方法，我们分析出机器学习领域中突出的主题和基本概念。然后，我们进行了全面的分析，跟踪这些确定的主题的进化轨迹。为了量化研究贡献的新鲜性和偏离度，我们使用废弃抽象熵度量。这个统计指标作为一种代表“惊喜”的指标，反映了研究论文中的内容与后续研究的不同程度。通过结合这些洞察，我们得到了机器学习领域中重要研究者和期刊（杂志和会议）的重要性。
</details></li>
</ul>
<hr>
<h2 id="GNAT-A-General-Narrative-Alignment-Tool"><a href="#GNAT-A-General-Narrative-Alignment-Tool" class="headerlink" title="GNAT: A General Narrative Alignment Tool"></a>GNAT: A General Narrative Alignment Tool</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03627">http://arxiv.org/abs/2311.03627</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanzir Pial, Steven Skiena</li>
<li>for: 本研究旨在开发一种通用的narativeAlignment算法，用于对短版文本之间进行对比和对alignment。</li>
<li>methods: 该算法结合Smith-Waterman算法和现代文本相似度指标，可以快速和准确地找到在短版文本之间的相似性。</li>
<li>results: 研究人员通过应用GNAT算法在四个不同的问题领域进行了评估，包括摘要到书籍对齐、翻译书籍对齐、短篇对齐和抄袭检测，并达到了良好的性能。<details>
<summary>Abstract</summary>
Algorithmic sequence alignment identifies similar segments shared between pairs of documents, and is fundamental to many NLP tasks. But it is difficult to recognize similarities between distant versions of narratives such as translations and retellings, particularly for summaries and abridgements which are much shorter than the original novels.   We develop a general approach to narrative alignment coupling the Smith-Waterman algorithm from bioinformatics with modern text similarity metrics. We show that the background of alignment scores fits a Gumbel distribution, enabling us to define rigorous p-values on the significance of any alignment. We apply and evaluate our general narrative alignment tool (GNAT) on four distinct problem domains differing greatly in both the relative and absolute length of documents, namely summary-to-book alignment, translated book alignment, short story alignment, and plagiarism detection -- demonstrating the power and performance of our methods.
</details>
<details>
<summary>摘要</summary>
算法序列Alignment标识 Shared between pairs of documents Similar segments, and is fundamental to many NLP tasks. However, it is difficult to recognize similarities between distant versions of narratives such as translations and retellings, particularly for summaries and abridgments, which are much shorter than the original novels.  We develop a general approach to narrative alignment, coupling the Smith-Waterman algorithm from bioinformatics with modern text similarity metrics. We show that the background of alignment scores fits a Gumbel distribution, enabling us to define rigorous p-values on the significance of any alignment. We apply and evaluate our general narrative alignment tool (GNAT) on four distinct problem domains differing greatly in both the relative and absolute length of documents, namely summary-to-book alignment, translated book alignment, short story alignment, and plagiarism detection -- demonstrating the power and performance of our methods.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.CL_2023_11_07/" data-id="cloqtaepn00e2gh8874k50m8z" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/cs.LG_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T10:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/cs.LG_2023_11_07/">cs.LG - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Breaking-the-Heavy-Tailed-Noise-Barrier-in-Stochastic-Optimization-Problems"><a href="#Breaking-the-Heavy-Tailed-Noise-Barrier-in-Stochastic-Optimization-Problems" class="headerlink" title="Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems"></a>Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04161">http://arxiv.org/abs/2311.04161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Puchkin, Eduard Gorbunov, Nikolay Kutuzov, Alexander Gasnikov</li>
<li>for:  Stochastic optimization problems with heavy-tailed noise and structured density.</li>
<li>methods:  Smoothed medians of means to stabilize stochastic gradients, clipped-SGD and clipped-SSTM.</li>
<li>results:  Faster convergence rates than $\mathcal{O}(K^{-2(\alpha - 1)&#x2F;\alpha})$ with negligible bias and controllable variance.<details>
<summary>Abstract</summary>
We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$, when the stochastic gradients have finite moments of order $\alpha \in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup.
</details>
<details>
<summary>摘要</summary>
我们考虑了随机优化问题，其中噪声具有重 tailed 分布。我们显示，在这类问题中，可以获得更快的速度减少，比如 $\mathcal{O}(K^{-2(\alpha - 1)/\alpha})$，当涉及到随机梯度的噪声具有有限 moment 的情况下。特别是，我们的分析允许噪声范围的期望无穷。为了实现这些结果，我们稳定了随机梯度，使用平滑的中值。我们证明了这些估计具有可控的方差和较小的偏差。这使得我们可以在 clipped-SGD 和 clipped-SSTM 中精心包含这些估计，并 derive 新的高probability 复杂性 bound 在考虑的设置下。
</details></li>
</ul>
<hr>
<h2 id="Computing-Approximate-ell-p-Sensitivities"><a href="#Computing-Approximate-ell-p-Sensitivities" class="headerlink" title="Computing Approximate $\ell_p$ Sensitivities"></a>Computing Approximate $\ell_p$ Sensitivities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04158">http://arxiv.org/abs/2311.04158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Swati Padmanabhan, David P. Woodruff, Qiuyi, Zhang</li>
<li>for: This paper is focused on developing efficient algorithms for approximating sensitivities in dimensionality reduction for regression tasks.</li>
<li>methods: The paper introduces new methods for approximating $\ell_p$ sensitivities and related summary statistics of a given matrix, including an algorithm based on importance sampling of $\ell_p$ Lewis weights.</li>
<li>results: The paper provides provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling, and experiments show that the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality.<details>
<summary>Abstract</summary>
Recent works in dimensionality reduction for regression tasks have introduced the notion of sensitivity, an estimate of the importance of a specific datapoint in a dataset, offering provable guarantees on the quality of the approximation after removing low-sensitivity datapoints via subsampling. However, fast algorithms for approximating $\ell_p$ sensitivities, which we show is equivalent to approximate $\ell_p$ regression, are known for only the $\ell_2$ setting, in which they are termed leverage scores.   In this work, we provide efficient algorithms for approximating $\ell_p$ sensitivities and related summary statistics of a given matrix. In particular, for a given $n \times d$ matrix, we compute $\alpha$-approximation to its $\ell_1$ sensitivities at the cost of $O(n/\alpha)$ sensitivity computations. For estimating the total $\ell_p$ sensitivity (i.e. the sum of $\ell_p$ sensitivities), we provide an algorithm based on importance sampling of $\ell_p$ Lewis weights, which computes a constant factor approximation to the total sensitivity at the cost of roughly $O(\sqrt{d})$ sensitivity computations. Furthermore, we estimate the maximum $\ell_1$ sensitivity, up to a $\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all these results to $\ell_p$ norms for $p > 1$. Lastly, we experimentally show that for a wide class of matrices in real-world datasets, the total sensitivity can be quickly approximated and is significantly smaller than the theoretical prediction, demonstrating that real-world datasets have low intrinsic effective dimensionality.
</details>
<details>
<summary>摘要</summary>
近期对回归任务中的维度减少方法提出了敏感度的概念，即数据点的重要性度量，可提供可证明的保证，认为可以通过抽取低敏感度数据点进行下抽样来提高回归的质量。然而，快速计算 $\ell_p$ 敏感度的快速算法仅限于 $\ell_2$  Setting，称为杠杆分数。在这个工作中，我们提供了高效的 $\ell_p$ 敏感度和相关摘要统计量的计算方法。特别是，对于给定 $n \times d$ 矩阵，我们可以在 $\alpha$  approximations 的代价下计算 $\ell_1$ 敏感度，其中 $\alpha$ 是一个常量。此外，我们还提供了一种基于 $\ell_p$ Lewis 权重的重要抽样方法，可以在 $O(\sqrt{d})$ 敏感度计算的代价下计算总 $\ell_p$ 敏感度。此外，我们还可以使用 $O(d)$ 敏感度计算来估算最大 $\ell_1$ 敏感度，带有 $\sqrt{d}$ 因子。最后，我们推广了这些结果到 $\ell_p$  нор准的 $p > 1$ 情况。在实际中，我们发现了许多实际数据集的内在有效维度远低于理论预测，这说明了实际数据集的敏感度远低于理论预测。
</details></li>
</ul>
<hr>
<h2 id="Kernel-mean-and-noise-marginalised-Gaussian-processes-for-exoplanet-transits-and-H-0-inference"><a href="#Kernel-mean-and-noise-marginalised-Gaussian-processes-for-exoplanet-transits-and-H-0-inference" class="headerlink" title="Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet transits and $H_0$ inference"></a>Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet transits and $H_0$ inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04153">http://arxiv.org/abs/2311.04153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Namu Kroupa, David Yallup, Will Handley, Michael Hobson</li>
<li>for: 这个论文的目的是扩展了完全权重方法，使其能够包括核函数选择和核函数参数的 marginalization。此外，通过证据来比较模型。</li>
<li>methods: 该论文使用的方法包括 Gaussian Process regression 和 Bayesian模型比较。具体来说，通过在更高维的空间中嵌入核函数选择和参数，并使用嵌入样本来实现转型样本。</li>
<li>results: 该论文的结果表明，在低噪声区域，true kernel 可以被回归，而在更高噪声区域，无法确定核函数。此外，通过对物理行星参数进行推测，可以去除偏见、宽化 posterior 或提高推测的准确性。最后，该方法被扩展到包括平均函数和噪声模型的 marginalization，并应用于实际数据进行 $H_0$ 的推测。<details>
<summary>Abstract</summary>
Using a fully Bayesian approach, Gaussian Process regression is extended to include marginalisation over the kernel choice and kernel hyperparameters. In addition, Bayesian model comparison via the evidence enables direct kernel comparison. The calculation of the joint posterior was implemented with a transdimensional sampler which simultaneously samples over the discrete kernel choice and their hyperparameters by embedding these in a higher-dimensional space, from which samples are taken using nested sampling. This method was explored on synthetic data from exoplanet transit light curve simulations. The true kernel was recovered in the low noise region while no kernel was preferred for larger noise. Furthermore, inference of the physical exoplanet hyperparameters was conducted. In the high noise region, either the bias in the posteriors was removed, the posteriors were broadened or the accuracy of the inference was increased. In addition, the uncertainty in mean function predictive distribution increased due to the uncertainty in the kernel choice. Subsequently, the method was extended to marginalisation over mean functions and noise models and applied to the inference of the present-day Hubble parameter, $H_0$, from real measurements of the Hubble parameter as a function of redshift, derived from the cosmologically model-independent cosmic chronometer and {\Lambda}CDM-dependent baryon acoustic oscillation observations. The inferred $H_0$ values from the cosmic chronometers, baryon acoustic oscillations and combined datasets are $H_0$ = 66$\pm$6 km/s/Mpc, $H_0$ = 67$\pm$10 km/s/Mpc and $H_0$ = 69$\pm$6 km/s/Mpc, respectively. The kernel posterior of the cosmic chronometers dataset prefers a non-stationary linear kernel. Finally, the datasets are shown to be not in tension with ln(R)=12.17$\pm$0.02.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HyperS2V-A-Framework-for-Structural-Representation-of-Nodes-in-Hyper-Networks"><a href="#HyperS2V-A-Framework-for-Structural-Representation-of-Nodes-in-Hyper-Networks" class="headerlink" title="HyperS2V: A Framework for Structural Representation of Nodes in Hyper Networks"></a>HyperS2V: A Framework for Structural Representation of Nodes in Hyper Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04149">http://arxiv.org/abs/2311.04149</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liushu2019/hypers2v">https://github.com/liushu2019/hypers2v</a></li>
<li>paper_authors: Shu Liu, Cameron Lai, Fujio Toriumi</li>
<li>for: 本研究旨在提出一种基于结构相似性的节点嵌入方法，以便应用机器学习方法到网络数据上。</li>
<li>methods: 本方法基于多尺度随机扫描 Framework，并使用 hyper-degree 捕捉网络结构特性。</li>
<li>results: 实验结果表明，HyperS2V 方法在 both 内在和外在测试中具有更高的解释性和可应用性。<details>
<summary>Abstract</summary>
In contrast to regular (simple) networks, hyper networks possess the ability to depict more complex relationships among nodes and store extensive information. Such networks are commonly found in real-world applications, such as in social interactions. Learning embedded representations for nodes involves a process that translates network structures into more simplified spaces, thereby enabling the application of machine learning approaches designed for vector data to be extended to network data. Nevertheless, there remains a need to delve into methods for learning embedded representations that prioritize structural aspects. This research introduces HyperS2V, a node embedding approach that centers on the structural similarity within hyper networks. Initially, we establish the concept of hyper-degrees to capture the structural properties of nodes within hyper networks. Subsequently, a novel function is formulated to measure the structural similarity between different hyper-degree values. Lastly, we generate structural embeddings utilizing a multi-scale random walk framework. Moreover, a series of experiments, both intrinsic and extrinsic, are performed on both toy and real networks. The results underscore the superior performance of HyperS2V in terms of both interpretability and applicability to downstream tasks.
</details>
<details>
<summary>摘要</summary>
对比常见（简单）网络，超网络具有更复杂的节点间关系和大量信息存储能力。这些网络在实际应用中很常见，如社交互动。学习节点嵌入表示需要将网络结构简化成简单的空间，以便应用机器学习方法到网络数据上。然而，还需要研究优化节点嵌入学习方法，以便更好地考虑网络结构特性。本研究介绍了HyperS2V节点嵌入方法，它关注超网络中节点的结构相似性。首先，我们定义了超节点度来捕捉超网络中节点的结构特性。然后，我们定义了一种新的函数来衡量不同超节点度值之间的结构相似性。最后，我们使用多Scale Random Walk框架生成结构嵌入。此外，我们在各种内在和外在实验中，对真实和模拟网络进行了多种测试。结果表明HyperS2V在 interpretability 和下游任务应用方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Multi-resolution-Time-Series-Transformer-for-Long-term-Forecasting"><a href="#Multi-resolution-Time-Series-Transformer-for-Long-term-Forecasting" class="headerlink" title="Multi-resolution Time-Series Transformer for Long-term Forecasting"></a>Multi-resolution Time-Series Transformer for Long-term Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04147">http://arxiv.org/abs/2311.04147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitian Zhang, Liheng Ma, Soumyasundar Pal, Yingxue Zhang, Mark Coates</li>
<li>For: 这个论文主要是为了提高时间序列预测的性能，特别是利用块的方式来学习时间序列中的复杂模式。* Methods: 本论文提出了一个新的框架，即多分辨率时间序列trasformer（MTST），这个框架包含多条分支架构，用于同时模型不同的时间模式。此外，本论文还使用相对位置编码，这样可以更好地提取不同尺度的周期性。* Results: 实验结果显示，MTST比state-of-the-art的预测技术更有效率，特别是在处理长期季节性和趋势的任务上。<details>
<summary>Abstract</summary>
The performance of transformers for time-series forecasting has improved significantly. Recent architectures learn complex temporal patterns by segmenting a time-series into patches and using the patches as tokens. The patch size controls the ability of transformers to learn the temporal patterns at different frequencies: shorter patches are effective for learning localized, high-frequency patterns, whereas mining long-term seasonalities and trends requires longer patches. Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.
</details>
<details>
<summary>摘要</summary>
《多解时序变换器的表现在时间序列预测中有了 significi cant改善。 current architectures 通过将时间序列分割成固定大小的块，并将块作为token来学习复杂的时间序列模式。块大小控制了 transformers 的能力来学习不同频率的时间序列模式： shorter patches 更有利于学习本地化、高频模式，而 longer patches 则更适合挖掘长期季节性和趋势。 inspired by this observation， we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture for simultaneous modeling of diverse temporal patterns at different resolutions. In contrast to many existing time-series transformers, we employ relative positional encoding, which is better suited for extracting periodic components at different scales. extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques.》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Generative-learning-for-nonlinear-dynamics"><a href="#Generative-learning-for-nonlinear-dynamics" class="headerlink" title="Generative learning for nonlinear dynamics"></a>Generative learning for nonlinear dynamics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04128">http://arxiv.org/abs/2311.04128</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Gilpin</li>
<li>for: 本研究探讨了现代生成机器学习模型如何创造真实的输出，超出它们的训练数据，如高清艺术作品、准确的蛋白质结构或对话文本。这些成功表明生成模型学习了如何有效地参数化和采样无法预测的分布。</li>
<li>methods: 本文使用了非线性动力学的古典工具，如信息理论，来推导 chaos 的属性，从而开发了 Parametrizing chaos 的算法。</li>
<li>results: 本研究发现，古典拥挤重建可以用来预测 latent 表示的约束，而 symbolic 近似可以用来比较最小的 discrete 生成器在复杂过程中的作用。 Emerging 跨学科工作将非线性动力学和学习理论相结合，例如操作理论方法应用于复杂液体流动，或在生物数据中探测破碎的平衡。<details>
<summary>Abstract</summary>
Modern generative machine learning models demonstrate surprising ability to create realistic outputs far beyond their training data, such as photorealistic artwork, accurate protein structures, or conversational text. These successes suggest that generative models learn to effectively parametrize and sample arbitrarily complex distributions. Beginning half a century ago, foundational works in nonlinear dynamics used tools from information theory to infer properties of chaotic attractors from time series, motivating the development of algorithms for parametrizing chaos in real datasets. In this perspective, we aim to connect these classical works to emerging themes in large-scale generative statistical learning. We first consider classical attractor reconstruction, which mirrors constraints on latent representations learned by state space models of time series. We next revisit early efforts to use symbolic approximations to compare minimal discrete generators underlying complex processes, a problem relevant to modern efforts to distill and interpret black-box statistical models. Emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets. We anticipate that future machine learning techniques may revisit other classical concepts from nonlinear dynamics, such as transinformation decay and complexity-entropy tradeoffs.
</details>
<details>
<summary>摘要</summary>
现代生成机器学习模型显示出不可思议的能力，创造出真实的输出，远 exceeding its training data，如 фото真实的艺术作品、准确的蛋白结构或对话文本。这些成功表明生成模型可以有效地参数化和随机抽取复杂分布。五十年前，基础性的工作在非线性动力学使用信息理论工具来推导 chaotic attractor 的属性，推动了 Parametrizing chaos 在实际数据中的算法的发展。在这个视角中，我们想要连接这些古典工作与现代大规模生成统计学学习的主题。我们首先考虑古典拟合器重建，这与 state space models 学习的秘密表示有约束。然后我们回到了早期使用 симвоlicapproximations 来比较基本的 discrete generator 下面 complex process 的问题，这与现代尝试distill和interpret黑盒统计模型有关。emerging interdisciplinary works bridge nonlinear dynamics and learning theory, such as operator-theoretic methods for complex fluid flows, or detection of broken detailed balance in biological datasets。我们预计未来机器学习技术可能会回到其他古典非线性动力学概念，如 transinformation decay 和 complexity-entropy tradeoffs。
</details></li>
</ul>
<hr>
<h2 id="Do-Language-Models-Learn-Semantics-of-Code-A-Case-Study-in-Vulnerability-Detection"><a href="#Do-Language-Models-Learn-Semantics-of-Code-A-Case-Study-in-Vulnerability-Detection" class="headerlink" title="Do Language Models Learn Semantics of Code? A Case Study in Vulnerability Detection"></a>Do Language Models Learn Semantics of Code? A Case Study in Vulnerability Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04109">http://arxiv.org/abs/2311.04109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Steenhoek, Md Mahbubur Rahman, Shaila Sharmin, Wei Le</li>
<li>for: 这个论文的目的是分析基于预训练语言模型的漏洞检测性能，以及这些模型是否学习了代码中漏洞检测相关的语义。</li>
<li>methods: 这个论文使用了三种不同的方法来分析模型：解释性工具、注意力分析和交互矩阵分析。</li>
<li>results: 研究发现， Better-performing 模型也更好地与潜在漏洞语句（PVS）相关，但模型很难强制对PVS进行匹配，而且模型对漏洞路径进行匹配也很差。基于这些分析结果，研究人员开发了两种注释方法，以帮助模型更好地理解代码中的漏洞语义。这些注释方法在大多数情况下（11个出于16个）提高了模型的性能，并且发现模型在使用这些注释时对潜在漏洞语句进行了更好的匹配。<details>
<summary>Abstract</summary>
Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task. These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset. Due to the different training objectives and the performance of the models, it is interesting to consider whether the models have learned the semantics of code relevant to vulnerability detection, namely bug semantics, and if so, how the alignment to bug semantics relates to model performance. In this paper, we analyze the models using three distinct methods: interpretability tools, attention analysis, and interaction matrix analysis. We compare the models' influential feature sets with the bug semantic features which define the causes of bugs, including buggy paths and Potentially Vulnerable Statements (PVS). We find that (1) better-performing models also aligned better with PVS, (2) the models failed to align strongly to PVS, and (3) the models failed to align at all to buggy paths. Based on our analysis, we developed two annotation methods which highlight the bug semantics inside the model's inputs. We evaluated our approach on four distinct transformer models and four vulnerability datasets and found that our annotations improved the models' performance in the majority of settings - 11 out of 16, with up to 9.57 points improvement in F1 score compared to conventional fine-tuning. We further found that with our annotations, the models aligned up to 232% better to potentially vulnerable statements. Our findings indicate that it is helpful to provide the model with information of the bug semantics, that the model can attend to it, and motivate future work in learning more complex path-based bug semantics. Our code and data are available at https://figshare.com/s/4a16a528d6874aad51a0.
</details>
<details>
<summary>摘要</summary>
近期，预训语言模型已经显示出了检测漏洞性能的状态导航权。这些模型先被预训在大量源代码库上，然后通过一个更小的监督漏洞数据集进行精度调整。由于模型的不同目标和性能，我们想要看看这些模型是否学习了代码漏洞相关的 semantics，即漏洞 semantics，并如何对这种对应进行分析。在这篇论文中，我们使用三种不同的方法进行分析：解释工具、注意力分析和交互矩阵分析。我们将模型的影响因素与漏洞 semantics 的定义，包括潜在漏洞（PVS）和漏洞路径进行比较。我们发现：1. 性能更高的模型也更好地与 PVS 相对应。2. 模型没有强烈对 PVS 进行对应。3. 模型没有对漏洞路径进行对应。基于我们的分析，我们开发了两种标注方法，以便在模型的输入中高亮 bug semantics。我们在四种 transformer 模型和四个漏洞数据集上进行了评估，并发现我们的标注可以提高模型的性能，在大多数情况下达到11个出版物中的9.57分准确率提高。我们还发现，通过我们的标注，模型可以更好地对潜在漏洞进行响应，并且可以达到232%的响应提高。我们的发现表明，向模型提供 bug semantics 信息可以帮助模型更好地attend to它，并促进未来的工作，学习更复杂的路径基本漏洞 semantics。我们的代码和数据可以在 figshare 上找到。
</details></li>
</ul>
<hr>
<h2 id="Time-Efficient-Reinforcement-Learning-with-Stochastic-Stateful-Policies"><a href="#Time-Efficient-Reinforcement-Learning-with-Stochastic-Stateful-Policies" class="headerlink" title="Time-Efficient Reinforcement Learning with Stochastic Stateful Policies"></a>Time-Efficient Reinforcement Learning with Stochastic Stateful Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04082">http://arxiv.org/abs/2311.04082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Firas Al-Hafez, Guoping Zhao, Jan Peters, Davide Tateo</li>
<li>for: 提高强化学习中的状态策略训练效率和稳定性，如处理部分可见环境、增强对策性或直接在策略结构中增加逻辑假设。</li>
<li>methods: 基于状态内部状态核和无状态策略的新方法，通过跟踪状态策略梯度来同时优化状态策略和无状态策略。提出了不同版本的状态策略梯度定理，使得可以轻松实现状态策略的变体。</li>
<li>results: 在复杂的 kontinuous control 任务中，如人型行走，提出的新梯度估计比 BPTT 更快、更简单，并且可以有效扩展到更高的任务复杂度。<details>
<summary>Abstract</summary>
Stateful policies play an important role in reinforcement learning, such as handling partially observable environments, enhancing robustness, or imposing an inductive bias directly into the policy structure. The conventional method for training stateful policies is Backpropagation Through Time (BPTT), which comes with significant drawbacks, such as slow training due to sequential gradient propagation and the occurrence of vanishing or exploding gradients. The gradient is often truncated to address these issues, resulting in a biased policy update. We present a novel approach for training stateful policies by decomposing the latter into a stochastic internal state kernel and a stateless policy, jointly optimized by following the stateful policy gradient. We introduce different versions of the stateful policy gradient theorem, enabling us to easily instantiate stateful variants of popular reinforcement learning and imitation learning algorithms. Furthermore, we provide a theoretical analysis of our new gradient estimator and compare it with BPTT. We evaluate our approach on complex continuous control tasks, e.g., humanoid locomotion, and demonstrate that our gradient estimator scales effectively with task complexity while offering a faster and simpler alternative to BPTT.
</details>
<details>
<summary>摘要</summary>
状态ful策略在强化学习中发挥重要作用，如处理半可见环境、增强Robustness或直接在策略结构中强制一致性。传统的状态ful策略训练方法是Backpropagation Through Time（BPTT），它具有许多缺点，如顺序梯度传播导致训练慢，以及gradient溢出或消失现象。为解决这些问题，我们提出了一种新的状态ful策略训练方法，即将状态ful策略分解为随机内部状态核心和状态eless策略，并将其同时优化。我们还提出了不同版本的状态ful策略梯度定理，可以方便地实现状态ful variants of 各种强化学习和模仿学习算法。此外，我们提供了对我们新的梯度估计器的理论分析，并与BPTT进行比较。我们在复杂的连续控制任务中，如人工智能步行，进行了评估，并证明了我们的梯度估计器可以随任务复杂度增长而快速增长，而且更简单、更高效地替代BPTT。
</details></li>
</ul>
<hr>
<h2 id="Estimator-Coupled-Reinforcement-Learning-for-Robust-Purely-Tactile-In-Hand-Manipulation"><a href="#Estimator-Coupled-Reinforcement-Learning-for-Robust-Purely-Tactile-In-Hand-Manipulation" class="headerlink" title="Estimator-Coupled Reinforcement Learning for Robust Purely Tactile In-Hand Manipulation"></a>Estimator-Coupled Reinforcement Learning for Robust Purely Tactile In-Hand Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04060">http://arxiv.org/abs/2311.04060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lennart Röstel, Johannes Pitz, Leon Sievers, Berthold Bäuml</li>
<li>for: 这篇论文旨在解决 robotic in-hand manipulation 中的问题，具体是用于对于手持下的物体进行精确的重新Orienting，并且在实际中进行 sim2real 转移。</li>
<li>methods: 本文使用了一种组合学习和状态推理的方法，将控制策略和状态推理器在训练时结合在一起，以提高状态推理的精确性和控制策略的可靠性。</li>
<li>results: 本文的方法在实验中实现了对四种不同的物体进行24个 orientations的 sim2real 转移，并且成功地让一个立方体 consecutively 到达九个目标。这是之前的方法在这个具有挑战性的设定中无法实现的。<details>
<summary>Abstract</summary>
This paper identifies and addresses the problems with naively combining (reinforcement) learning-based controllers and state estimators for robotic in-hand manipulation. Specifically, we tackle the challenging task of purely tactile, goal-conditioned, dextrous in-hand reorientation with the hand pointing downwards. Due to the limited sensing available, many control strategies that are feasible in simulation when having full knowledge of the object's state do not allow for accurate state estimation. Hence, separately training the controller and the estimator and combining the two at test time leads to poor performance. We solve this problem by coupling the control policy to the state estimator already during training in simulation. This approach leads to more robust state estimation and overall higher performance on the task while maintaining an interpretability advantage over end-to-end policy learning. With our GPU-accelerated implementation, learning from scratch takes a median training time of only 6.5 hours on a single, low-cost GPU. In simulation experiments with the DLR-Hand II and for four significantly different object shapes, we provide an in-depth analysis of the performance of our approach. We demonstrate the successful sim2real transfer by rotating the four objects to all 24 orientations in the $\pi/2$ discretization of SO(3), which has never been achieved for such a diverse set of shapes. Finally, our method can reorient a cube consecutively to nine goals (median), which was beyond the reach of previous methods in this challenging setting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Feature-Space-Renormalization-for-Semi-supervised-Learning"><a href="#Feature-Space-Renormalization-for-Semi-supervised-Learning" class="headerlink" title="Feature Space Renormalization for Semi-supervised Learning"></a>Feature Space Renormalization for Semi-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04055">http://arxiv.org/abs/2311.04055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Sun, Zhongjie Mao, Chao Li, Chao Zhou, Xiao-Jun Wu</li>
<li>For: The paper aims to improve the performance of semi-supervised learning (SSL) models by introducing a feature space renormalization (FSR) mechanism to learn better discriminative features.* Methods: The paper proposes a novel SSL model called FreMatch, which combines the FSR mechanism with pseudo-labelling to improve the performance of SSL models.* Results: The experimental results show that the proposed method can achieve better performance on a variety of standard SSL benchmark datasets, and the FSR mechanism can also enhance the performance of other SSL approaches.<details>
<summary>Abstract</summary>
Semi-supervised learning (SSL) has been proven to be a powerful method for leveraging unlabelled data to alleviate models' dependence on large labelled datasets. The common framework among recent approaches is to train the model on a large amount of unlabelled data with consistency regularization to constrain the model predictions to be invariant to input perturbation. However, the existing SSL frameworks still have room for improvement in the consistency regularization method. Instead of regularizing category predictions in the label space as in existing frameworks, this paper proposes a feature space renormalization (FSR) mechanism for SSL. First, we propose a feature space renormalization mechanism to substitute for the commonly used consistency regularization mechanism to learn better discriminative features. To apply this mechanism, we start by building a basic model and an empirical model and then introduce our mechanism to renormalize the feature learning of the basic model with the guidance of the empirical model. Second, we combine the proposed mechanism with pseudo-labelling to obtain a novel effective SSL model named FreMatch. The experimental results show that our method can achieve better performance on a variety of standard SSL benchmark datasets, and the proposed feature space renormalization mechanism can also enhance the performance of other SSL approaches.
</details>
<details>
<summary>摘要</summary>
半supervised learning（SSL）已经证明是一种有力的方法，可以使用无标签数据来减轻模型对大量标签数据的依赖。现有的方法框架中的共同特点是通过在大量无标签数据上进行训练，使模型预测结果具有输入扰动的抗变性。然而，现有的SSL框架仍然存在改进的可能性。而不是在标签空间进行常见的一致规范化（consistency regularization），这篇论文提议在特征空间进行特征空间正规化（feature space renormalization，FSR）机制。我们的方法包括两个主要组成部分：首先，我们提议一种特征空间正规化机制，以取代常见的一致规范化机制，以学习更好的抽象特征。其次，我们将这种机制与pseudo-labeling结合，并提出一种新的有效的SSL模型，即FreMatch。实验结果表明，我们的方法可以在多种标准SSL验证数据集上达到更好的性能，并且提议的特征空间正规化机制也可以提高其他SSL方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Extracting-human-interpretable-structure-property-relationships-in-chemistry-using-XAI-and-large-language-models"><a href="#Extracting-human-interpretable-structure-property-relationships-in-chemistry-using-XAI-and-large-language-models" class="headerlink" title="Extracting human interpretable structure-property relationships in chemistry using XAI and large language models"></a>Extracting human interpretable structure-property relationships in chemistry using XAI and large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04047">http://arxiv.org/abs/2311.04047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geemi P. Wellawatte, Philippe Schwaller</li>
<li>For: The paper aims to address the opaque nature of machine learning models in the field of Explainable Artificial Intelligence (XAI) and improve the accessibility of XAI methods for non-technical users.* Methods: The paper proposes the XpertAI framework, which integrates XAI methods with large language models (LLMs) to generate accessible natural language explanations of raw chemical data automatically.* Results: The paper conducts 5 case studies to evaluate the performance of XpertAI and shows that it combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.Here are the three points in Simplified Chinese text:</li>
<li>for: 该 paper 目的是解决人工智能模型的不透明性，并使Explainable Artificial Intelligence (XAI) 方法更加可 accessible  для非技术用户。</li>
<li>methods: 该 paper 提出了 XpertAI 框架，该框架将 XAI 方法与大型自然语言模型 (LLMs) 结合起来，自动生成化学数据的可读性atural language explanations。</li>
<li>results: 该 paper 通过5个案例研究证明，XpertAI 组合了 LLMs 和 XAI 工具的优点，能够生成特定、科学和可解释的解释。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence (XAI) is an emerging field in AI that aims to address the opaque nature of machine learning models. Furthermore, it has been shown that XAI can be used to extract input-output relationships, making them a useful tool in chemistry to understand structure-property relationships. However, one of the main limitations of XAI methods is that they are developed for technically oriented users. We propose the XpertAI framework that integrates XAI methods with large language models (LLMs) accessing scientific literature to generate accessible natural language explanations of raw chemical data automatically. We conducted 5 case studies to evaluate the performance of XpertAI. Our results show that XpertAI combines the strengths of LLMs and XAI tools in generating specific, scientific, and interpretable explanations.
</details>
<details>
<summary>摘要</summary>
simplify:Explainable Artificial Intelligence (XAI) 是一个 emerging 领域的 AI，旨在解释机器学习模型的不透明性。此外，已经证明 XAI 可以用来提取输入输出关系，使其成为化学领域理解结构属性关系的有用工具。然而，XAI 方法的主要局限性在于它们是为技术启用户而设计的。我们提出了 XpertAI 框架，该框架将 XAI 方法与大量自然语言模型（LLM）结合起来，自动生成可读的化学数据原始数据的自然语言解释。我们进行了 5 个案例研究，以评估 XpertAI 的性能。我们的结果表明，XpertAI 可以结合 LLM 和 XAI 工具的优势，生成特定、科学和可解释的解释。Note: " simplify" is not a word in Chinese, but it is implied that the text is written in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Discordance-Minimization-based-Imputation-Algorithms-for-Missing-Values-in-Rating-Data"><a href="#Discordance-Minimization-based-Imputation-Algorithms-for-Missing-Values-in-Rating-Data" class="headerlink" title="Discordance Minimization-based Imputation Algorithms for Missing Values in Rating Data"></a>Discordance Minimization-based Imputation Algorithms for Missing Values in Rating Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04035">http://arxiv.org/abs/2311.04035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young Woong Park, Jinhak Kim, Dan Zhu</li>
<li>for: 这个论文主要是为了处理合并的评分列表中的缺失评分问题。</li>
<li>methods: 该论文使用了特定的分析方法和优化模型来填充缺失评分，这些方法基于了对具体的数据集进行了分析，并且使用了只知道评分信息来优化模型。</li>
<li>results: 该论文的计算实验表明，提订的方法在实际世界数据集和synthetic数据集上具有较高的填充精度，比对比的普通替换方法更高。<details>
<summary>Abstract</summary>
Ratings are frequently used to evaluate and compare subjects in various applications, from education to healthcare, because ratings provide succinct yet credible measures for comparing subjects. However, when multiple rating lists are combined or considered together, subjects often have missing ratings, because most rating lists do not rate every subject in the combined list. In this study, we propose analyses on missing value patterns using six real-world data sets in various applications, as well as the conditions for applicability of imputation algorithms. Based on the special structures and properties derived from the analyses, we propose optimization models and algorithms that minimize the total rating discordance across rating providers to impute missing ratings in the combined rating lists, using only the known rating information. The total rating discordance is defined as the sum of the pairwise discordance metric, which can be written as a quadratic function. Computational experiments based on real-world and synthetic rating data sets show that the proposed methods outperform the state-of-the-art general imputation methods in the literature in terms of imputation accuracy.
</details>
<details>
<summary>摘要</summary>
用Frequency来评估和比较不同领域中的主题，从教育到医疗，因为评分提供简洁又可靠的评估方法。然而，当多个评分列表合并或考虑 вместе时，主题经常有 missing 评分，因为大多数评分列表不会对所有主题进行评分。在这个研究中，我们对 missing value 模式进行分析，使用 six 个真实世界数据集，来评估不同应用场景中的 condition for applicability 和 imputation 算法的可行性。基于分析结果，我们提出了优化模型和算法，以最小化总评分不一致的总和，使用只知道的评分信息进行补做 missing 评分。总评分不一致的定义为所有评分提供者的评分不一致之和，可以写作 quadratic function。通过基于真实世界和 sintetic 评分数据集的计算实验，我们发现我们提出的方法在 imputation 精度方面与文献中的通用 imputation 方法相比较出色。
</details></li>
</ul>
<hr>
<h2 id="Joint-model-for-longitudinal-and-spatio-temporal-survival-data"><a href="#Joint-model-for-longitudinal-and-spatio-temporal-survival-data" class="headerlink" title="Joint model for longitudinal and spatio-temporal survival data"></a>Joint model for longitudinal and spatio-temporal survival data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04008">http://arxiv.org/abs/2311.04008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor Medina-Olivares, Finn Lindgren, Raffaella Calabrese, Jonathan Crook</li>
<li>for: 这个论文的目的是predicting a borrower’s time-to-event in credit risk analysis, specifically using joint models for longitudinal and survival data to capture spatial and temporal effects and their interaction.</li>
<li>methods: 该论文提出了一种 bayesian hierarchical joint model called Spatio-Temporal Joint Model (STJM), which considers the survival effect of unobserved heterogeneity among borrowers located in the same region at a particular time. 用于大规模数据的估计方法是Integrated Nested Laplace Approximation (INLA) methodology.</li>
<li>results: 实际结果表明，包含空间效应可以一直提高Join Model的表现，但是添加空间-时间交互的效果 less definitive.<details>
<summary>Abstract</summary>
In credit risk analysis, survival models with fixed and time-varying covariates are widely used to predict a borrower's time-to-event. When the time-varying drivers are endogenous, modelling jointly the evolution of the survival time and the endogenous covariates is the most appropriate approach, also known as the joint model for longitudinal and survival data. In addition to the temporal component, credit risk models can be enhanced when including borrowers' geographical information by considering spatial clustering and its variation over time. We propose the Spatio-Temporal Joint Model (STJM) to capture spatial and temporal effects and their interaction. This Bayesian hierarchical joint model reckons the survival effect of unobserved heterogeneity among borrowers located in the same region at a particular time. To estimate the STJM model for large datasets, we consider the Integrated Nested Laplace Approximation (INLA) methodology. We apply the STJM to predict the time to full prepayment on a large dataset of 57,258 US mortgage borrowers with more than 2.5 million observations. Empirical results indicate that including spatial effects consistently improves the performance of the joint model. However, the gains are less definitive when we additionally include spatio-temporal interactions.
</details>
<details>
<summary>摘要</summary>
在信用风险分析中，Fixed和时间变量的生存模型广泛使用来预测借款人的时间事件。当时间变量 Driver 是内生的时，模型同时考虑生存时间的演化和内生 covariates 的演化是最佳的方法，也称为长itudinal and survival data 的共同模型。此外，信用风险模型可以通过考虑借款人的地理信息来增强，包括空间聚集和时间变化的相互作用。我们提出了空间-时间共同模型（STJM），以捕捉空间和时间效应以及其交互作用。这个 bayesian 层次模型reckons 借款人所在地区的时间点上的生存效应。为处理大数据集，我们考虑了 Integrated Nested Laplace Approximation（INLA）方法。我们应用 STJM 模型来预测57,258名美国 mortgage 借款人的全 prepayment 时间，共有 más than 2.5 百万观察数据。实际结果表明，包括空间效应可以一直提高生存模型的性能，但是添加空间-时间交互作用后的效果较弱。
</details></li>
</ul>
<hr>
<h2 id="An-Initialization-Schema-for-Neuronal-Networks-on-Tabular-Data"><a href="#An-Initialization-Schema-for-Neuronal-Networks-on-Tabular-Data" class="headerlink" title="An Initialization Schema for Neuronal Networks on Tabular Data"></a>An Initialization Schema for Neuronal Networks on Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03996">http://arxiv.org/abs/2311.03996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wolfgang Fuhl</li>
<li>for: 这项研究的目的是提出一种使用神经网络处理粗粒度数据的简单 yet effective 方法。</li>
<li>methods: 该方法使用了初始化团队学习的schema，并对批处理中的梯度进行遮盖，以便在神经网络中 jointly 训练集成体。</li>
<li>results: 研究人员在多个公共数据集上评估了该方法，并证明了它在对粗粒度数据进行预测和分类 task 中的改进表现。In English, the three key points are:</li>
<li>for: The purpose of this research is to propose a simple yet effective method for processing tabular data using neural networks.</li>
<li>methods: The method uses a schema for initializing team learning, and adds gradient masking to batches to enable joint training in neural networks.</li>
<li>results: The authors evaluate the method on multiple public datasets and show improved performance compared to other neural network-based approaches.<details>
<summary>Abstract</summary>
Nowadays, many modern applications require heterogeneous tabular data, which is still a challenging task in terms of regression and classification. Many approaches have been proposed to adapt neural networks for this task, but still, boosting and bagging of decision trees are the best-performing methods for this task. In this paper, we show that a binomial initialized neural network can be used effectively on tabular data. The proposed approach shows a simple but effective approach for initializing the first hidden layer in neural networks. We also show that this initializing schema can be used to jointly train ensembles by adding gradient masking to batch entries and using the binomial initialization for the last layer in a neural network. For this purpose, we modified the hinge binary loss and the soft max loss to make them applicable for joint ensemble training. We evaluate our approach on multiple public datasets and showcase the improved performance compared to other neural network-based approaches. In addition, we discuss the limitations and possible further research of our approach for improving the applicability of neural networks to tabular data.   Link: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list
</details>
<details>
<summary>摘要</summary>
现在，许多现代应用需要异ogeneous的表格数据，这是对回归和分类 зада务中的一个挑战。许多方法已经被提出来适应神经网络，但是强化和袋包的决策树仍然是这些任务中最佳的方法。在这篇论文中，我们展示了一种使用初始化的神经网络可以有效地处理表格数据。我们还展示了一种初始化Schema可以用来初始化神经网络中的第一层。此外，我们还将Gradient Masking添加到批处理中，并使用最后一层的初始化Schema来联合训练集。为此，我们修改了折级二进制损失函数和软MAX损失函数，使其适用于联合集成训练。我们在多个公共数据集上评估了我们的方法，并证明了与其他神经网络基于方法相比，我们的方法显著提高了性能。此外，我们还讨论了我们的方法的局限性和可能的进一步研究，以提高神经网络对表格数据的应用性。Link: <https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list>
</details></li>
</ul>
<hr>
<h2 id="Bandit-Pareto-Set-Identification-the-Fixed-Budget-Setting"><a href="#Bandit-Pareto-Set-Identification-the-Fixed-Budget-Setting" class="headerlink" title="Bandit Pareto Set Identification: the Fixed Budget Setting"></a>Bandit Pareto Set Identification: the Fixed Budget Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03992">http://arxiv.org/abs/2311.03992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrille Kone, Emilie Kaufmann, Laura Richert</li>
<li>for: 本研究探讨了一个多目标纯探索问题，其中每个臂相关于一个未知多变量分布，目标是确定这些分布的含义，使其不 worse than 另一个分布：Pareto优化集。</li>
<li>methods: 我们提出了首个针对固定预算Pareto集标识任务的算法，它们结合了精心估计每个臂是否在Pareto集的“difficulty to classify”特征，以及一种通用的排除方案。</li>
<li>results: 我们证明了两种特定实现，EGE-SR和EGE-SH，其错误概率与预算相关的衰减速率为指数型，并且支持信息理论下界。我们还通过实验使用实际数据和 sintetic数据，发现我们的算法表现良好。<details>
<summary>Abstract</summary>
We study a multi-objective pure exploration problem in a multi-armed bandit model. Each arm is associated to an unknown multi-variate distribution and the goal is to identify the distributions whose mean is not uniformly worse than that of another distribution: the Pareto optimal set. We propose and analyze the first algorithms for the \emph{fixed budget} Pareto Set Identification task. We propose Empirical Gap Elimination, a family of algorithms combining a careful estimation of the ``hardness to classify'' each arm in or out of the Pareto set with a generic elimination scheme. We prove that two particular instances, EGE-SR and EGE-SH, have a probability of error that decays exponentially fast with the budget, with an exponent supported by an information theoretic lower-bound. We complement these findings with an empirical study using real-world and synthetic datasets, which showcase the good performance of our algorithms.
</details>
<details>
<summary>摘要</summary>
我们研究一个多目标纯探索问题在多重机关模型中。每棒有一个未知多变数据分布，目标是确定这些分布的含义不比另一个分布 uniformly 差。我们提出并分析了首个预算 Pareto 集标定 зада务的算法。我们提出了 Empirical Gap Elimination，一种组合精心估计每棒在 Pareto 集内或外的困难程度与一种通用淘汰方案的算法家族。我们证明了两个特定实例 EGE-SR 和 EGE-SH 的概率错误与预算相关，具有 exponentially 快衰减速率，其下支持信息论下界。我们补充这些发现与实际数据集和 sintetic 数据集的实验，显示了我们的算法表现良好。Note that Simplified Chinese is a written language, and the translation is based on the standardized grammar and vocabulary of Simplified Chinese. The sentence structure and wording may be different from Traditional Chinese, which is spoken in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Cup-Curriculum-Curriculum-Learning-on-Model-Capacity"><a href="#Cup-Curriculum-Curriculum-Learning-on-Model-Capacity" class="headerlink" title="Cup Curriculum: Curriculum Learning on Model Capacity"></a>Cup Curriculum: Curriculum Learning on Model Capacity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03956">http://arxiv.org/abs/2311.03956</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luca-scharr/cupcurriculum">https://github.com/luca-scharr/cupcurriculum</a></li>
<li>paper_authors: Luca Scharr, Vanessa Toborek</li>
<li>for: 提高自然语言处理模型的性能</li>
<li>methods: 使用迭代幅度减小法减少模型容量，然后在第二阶段重新引入这些 weights，使模型容量展示 Cup 形曲线</li>
<li>results: 比较 Early Stopping 和 Cup Curriculum 两种方法，显示 Cup Curriculum 可靠地超越 Early Stopping，并具有高鲁棒性 against overfitting。<details>
<summary>Abstract</summary>
Curriculum learning (CL) aims to increase the performance of a learner on a given task by applying a specialized learning strategy. This strategy focuses on either the dataset, the task, or the model. There is little to no work analysing the possibilities to apply CL on the model capacity in natural language processing. To close this gap, we propose the cup curriculum. In a first phase of training we use a variation of iterative magnitude pruning to reduce model capacity. These weights are reintroduced in a second phase, resulting in the model capacity to show a cup-shaped curve over the training iterations. We empirically evaluate different strategies of the cup curriculum and show that it outperforms early stopping reliably while exhibiting a high resilience to overfitting.
</details>
<details>
<summary>摘要</summary>
学习轨迹（CL）目的是提高学习者在给定任务上的表现，通过特殊的学习策略。这种策略可以对数据集、任务或模型进行特殊化。然而，有很少关于应用CL在模型容量上的研究。为了填补这个空白，我们提出了杯训练策略。在首 phase of 训练中，我们使用迭代幅度减少的方法来减少模型容量。这些参数在第二 phase 的训练中被重新引入，导致模型容量示出了杯形曲线的变化趋势。我们对不同的杯训练策略进行实验性评估，并证明了它可靠地超越早期停止，同时具有高度适应性。
</details></li>
</ul>
<hr>
<h2 id="Structure-of-universal-formulas"><a href="#Structure-of-universal-formulas" class="headerlink" title="Structure of universal formulas"></a>Structure of universal formulas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03910">http://arxiv.org/abs/2311.03910</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smith86n/wiki-is-mostly-fake-radom-words-word-genrationr-">https://github.com/smith86n/wiki-is-mostly-fake-radom-words-word-genrationr-</a></li>
<li>paper_authors: Dmitry Yarotsky</li>
<li>for: 本文研究 parameterized analytic expressions 的高度表达能力，包括一些形式为神经网络的模型。</li>
<li>methods: 本文分析了这些高度表达能力的模型的结构元素，并提出了一系列分类结果。</li>
<li>results: 本文证明了一些函数家族的Global Approximability Property，并给出了一些不能在所有定义域上适用的函数例子。<details>
<summary>Abstract</summary>
By universal formulas we understand parameterized analytic expressions that have a fixed complexity, but nevertheless can approximate any continuous function on a compact set. There exist various examples of such formulas, including some in the form of neural networks. In this paper we analyze the essential structural elements of these highly expressive models. We introduce a hierarchy of expressiveness classes connecting the global approximability property to the weaker property of infinite VC dimension, and prove a series of classification results for several increasingly complex functional families. In particular, we introduce a general family of polynomially-exponentially-algebraic functions that, as we prove, is subject to polynomial constraints. As a consequence, we show that fixed-size neural networks with not more than one layer of neurons having transcendental activations (e.g., sine or standard sigmoid) cannot in general approximate functions on arbitrary finite sets. On the other hand, we give examples of functional families, including two-hidden-layer neural networks, that approximate functions on arbitrary finite sets, but fail to do that on the whole domain of definition.
</details>
<details>
<summary>摘要</summary>
通过通用方程式我们理解参数化分析表达式，它们具有固定的复杂性，但可以将任何连续函数在有界集上 aproximate。存在多种这种表达式的例子，包括一些形式为神经网络。在这篇论文中，我们分析了高表达能力模型的基本结构元素。我们建立了一个表达能力层次结构，将全球approx性质连接到更弱的无限VCdimension质量，并证明了一系列分类结果 для多个逐渐复杂的函数家族。特别是，我们引入了一个通用的多项式幂函数，并证明它们受到多项式约束。这意味着，Fixed-size神经网络没有超过一层神经元有跨度活动（例如，三角函数或标准 sigmoid）不能在一般的有限集上逼近函数。然而，我们给出了一些函数家族的示例，包括两层隐藏层神经网络，它们在有限集上逼近函数，但在整个定义域上不能逼近函数。
</details></li>
</ul>
<hr>
<h2 id="Learning-Based-Latency-Constrained-Fronthaul-Compression-Optimization-in-C-RAN"><a href="#Learning-Based-Latency-Constrained-Fronthaul-Compression-Optimization-in-C-RAN" class="headerlink" title="Learning-Based Latency-Constrained Fronthaul Compression Optimization in C-RAN"></a>Learning-Based Latency-Constrained Fronthaul Compression Optimization in C-RAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03899">http://arxiv.org/abs/2311.03899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Axel Grönland, Bleron Klaiqi, Xavier Gelabert</li>
<li>for: 这个研究是为了提高无线 mobilenetworks中Radio Access Network（RAN）功能的cloud化，并且提供了一个可靠的对于Fronthaul（FH）压缩技术的方法来满足FH的容量和延迟需求。</li>
<li>methods: 本研究使用了一个无模型的深度学习（DRL）基础的FH压缩框架，通过调整不同的配置参数，例如模ulation order、precoder粒度和precoder重量Quantization，以控制FH压缩的程度，并且 simultanoeusly optimize FH的负载和无线对应性。</li>
<li>results: 实验结果显示，DRL-FC比对照方案（即没有压缩）在不同的FH负载水平上显示出了significantly高的FH使用率（68.7%的平均值）和无线对应性。同时，DRL-FC框架还能够遵循对FH延迟需求（在我们的情况下是260 $\mu$s）的前定限制，在不同的FH负载水平下具有可靠的性能。<details>
<summary>Abstract</summary>
The evolution of wireless mobile networks towards cloudification, where Radio Access Network (RAN) functions can be hosted at either a central or distributed locations, offers many benefits like low cost deployment, higher capacity, and improved hardware utilization. Nevertheless, the flexibility in the functional deployment comes at the cost of stringent fronthaul (FH) capacity and latency requirements. One possible approach to deal with these rigorous constraints is to use FH compression techniques. To ensure that FH capacity and latency requirements are met, more FH compression is applied during high load, while less compression is applied during medium and low load to improve FH utilization and air interface performance. In this paper, a model-free deep reinforcement learning (DRL) based FH compression (DRL-FC) framework is proposed that dynamically controls FH compression through various configuration parameters such as modulation order, precoder granularity, and precoder weight quantization that affect both FH load and air interface performance. Simulation results show that DRL-FC exhibits significantly higher FH utilization (68.7% on average) and air interface throughput than a reference scheme (i.e. with no applied compression) across different FH load levels. At the same time, the proposed DRL-FC framework is able to meet the predefined FH latency constraints (in our case set to 260 $\mu$s) under various FH loads.
</details>
<details>
<summary>摘要</summary>
In this paper, a model-free deep reinforcement learning (DRL) based fronthaul compression (DRL-FC) framework is proposed that dynamically controls FH compression through various configuration parameters such as modulation order, precoder granularity, and precoder weight quantization that affect both FH load and air interface performance. Simulation results show that DRL-FC exhibits significantly higher FH utilization (68.7% on average) and air interface throughput than a reference scheme (i.e. with no applied compression) across different FH load levels. At the same time, the proposed DRL-FC framework is able to meet the predefined FH latency constraints (in our case set to 260 $\mu$s) under various FH loads.
</details></li>
</ul>
<hr>
<h2 id="An-Explainable-Framework-for-Machine-learning-Based-Reactive-Power-Optimization-of-Distribution-Network"><a href="#An-Explainable-Framework-for-Machine-learning-Based-Reactive-Power-Optimization-of-Distribution-Network" class="headerlink" title="An Explainable Framework for Machine learning-Based Reactive Power Optimization of Distribution Network"></a>An Explainable Framework for Machine learning-Based Reactive Power Optimization of Distribution Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03863">http://arxiv.org/abs/2311.03863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Liao, Benjamin Schäfer, Dalin Qin, Gonghao Zhang, Zhixian Wang, Zhe Yang</li>
<li>for: 优化分布网络的反应力能源，使用机器学习模型，以提高分布网络的运行效率和稳定性。</li>
<li>methods: 提出了一种可解释的机器学习框架，通过使用盖比投资分析法来衡量每个输入特征对分布网络的反应力优化解决方案的贡献。</li>
<li>results: 通过使用可视化分析工具，从全局和具体两个角度来准确地解释机器学习模型基于的反应力优化解决方案的决策过程中的潜在偏见或错误。<details>
<summary>Abstract</summary>
To reduce the heavy computational burden of reactive power optimization of distribution networks, machine learning models are receiving increasing attention. However, most machine learning models (e.g., neural networks) are usually considered as black boxes, making it challenging for power system operators to identify and comprehend potential biases or errors in the decision-making process of machine learning models. To address this issue, an explainable machine-learning framework is proposed to optimize the reactive power in distribution networks. Firstly, a Shapley additive explanation framework is presented to measure the contribution of each input feature to the solution of reactive power optimizations generated from machine learning models. Secondly, a model-agnostic approximation method is developed to estimate Shapley values, so as to avoid the heavy computational burden associated with direct calculations of Shapley values. The simulation results show that the proposed explainable framework can accurately explain the solution of the machine learning model-based reactive power optimization by using visual analytics, from both global and instance perspectives. Moreover, the proposed explainable framework is model-agnostic, and thus applicable to various models (e.g., neural networks).
</details>
<details>
<summary>摘要</summary>
Firstly, a Shapley additive explanation framework is presented to measure the contribution of each input feature to the solution of reactive power optimizations generated from machine learning models. Secondly, a model-agnostic approximation method is developed to estimate Shapley values, so as to avoid the heavy computational burden associated with direct calculations of Shapley values.The simulation results show that the proposed explainable framework can accurately explain the solution of the machine learning model-based reactive power optimization by using visual analytics, from both global and instance perspectives. Moreover, the proposed explainable framework is model-agnostic, and thus applicable to various models (e.g., neural networks).translate into Simplified Chinese:为了减轻分布网络中的计算拥塞，机器学习模型在得到越来越多的注意力。然而，大多数机器学习模型（例如神经网络）通常被视为黑盒子，使得电力系统运营员很难了解和理解机器学习模型的决策过程中的可能的偏见或错误。为解决这个问题，一种可解释的机器学习框架被提议用于分布网络中的待能优化。首先，一种基于Shapley添加的解释框架被提出来度量每个输入特征对机器学习模型中的解决方案中的贡献。其次，一种模型无关的估计方法被开发以估计Shapley值，以避免直接计算Shapley值的重要计算负担。实验结果表明，提议的可解释框架可以准确地解释基于机器学习模型的分布网络中的待能优化解决方案，使用视觉分析，从全局和实例两个角度来看。此外，提议的可解释框架是模型无关的，因此可以应用于不同的模型（例如神经网络）。
</details></li>
</ul>
<hr>
<h2 id="Improved-MDL-Estimators-Using-Fiber-Bundle-of-Local-Exponential-Families-for-Non-exponential-Families"><a href="#Improved-MDL-Estimators-Using-Fiber-Bundle-of-Local-Exponential-Families-for-Non-exponential-Families" class="headerlink" title="Improved MDL Estimators Using Fiber Bundle of Local Exponential Families for Non-exponential Families"></a>Improved MDL Estimators Using Fiber Bundle of Local Exponential Families for Non-exponential Families</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03852">http://arxiv.org/abs/2311.03852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kohei Miyamoto, Andrew R. Barron, Jun’ichi Takeuchi</li>
<li>for: 这个论文是为了研究最小描述长度（MDL）估计器，特别是使用两部分代码来实现通用编码。</li>
<li>methods: 论文使用了两部分代码的方法，其中一部分是用于描述数据的地方分布，另一部分是用于描述模型家族的结构。</li>
<li>results: 论文提出了一种基于Barron和Cover（1991）理论的risk和loss的下界，并应用到了杂合家族（mixture families）中。这个结果表明，使用这种方法可以在非线性家族中实现比较好的估计性能。<details>
<summary>Abstract</summary>
Minimum Description Length (MDL) estimators, using two-part codes for universal coding, are analyzed. For general parametric families under certain regularity conditions, we introduce a two-part code whose regret is close to the minimax regret, where regret of a code with respect to a target family M is the difference between the code length of the code and the ideal code length achieved by an element in M. This is a generalization of the result for exponential families by Gr\"unwald. Our code is constructed by using an augmented structure of M with a bundle of local exponential families for data description, which is not needed for exponential families. This result gives a tight upper bound on risk and loss of the MDL estimators based on the theory introduced by Barron and Cover in 1991. Further, we show that we can apply the result to mixture families, which are a typical example of non-exponential families.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化字符串。<</SYS>>我们研究了最小描述长度（MDL）估计器，使用两部分代码进行通用编码。对于普遍的参数家族，在某些正则条件下，我们引入了一个两部分代码，其忽略差异与最小值估计器的目标家族M之间的差异。这是对于指数家族的结果的总体推广。我们的代码使用了增强结构M中的一个包装的本地指数家族来描述数据，这不需要在指数家族上进行。这个结果给出了基于柯本和覆盖于1991年提出的理论的紧张Upper bound，对MDL估计器的风险和损失进行评估。此外，我们还证明了我们可以将结果应用到杂合家族，这是非指数家族的典型例子。
</details></li>
</ul>
<hr>
<h2 id="User-level-Differentially-Private-Stochastic-Convex-Optimization-Efficient-Algorithms-with-Optimal-Rates"><a href="#User-level-Differentially-Private-Stochastic-Convex-Optimization-Efficient-Algorithms-with-Optimal-Rates" class="headerlink" title="User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates"></a>User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03797">http://arxiv.org/abs/2311.03797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hilal Asi, Daogao Liu</li>
<li>for: 这 paper 描述了一种用户级 differentially private stochastic convex optimization (DP-SCO) 算法，用于保护每个用户可能拥有多个数据项的情况下的隐私。</li>
<li>methods: 该 paper 使用了多重通道 DP-SGD 算法，并结合了一种私有的平均值估计过程，用于处理异常数据。</li>
<li>results: 该 paper 实现了对凸函数和强凸函数的优化，并且需要用户数量在维度上增长只需 logarithmic。此外，该 paper 还实现了对不含积函数的优化，并且在 polynomial time 内完成。<details>
<summary>Abstract</summary>
We study differentially private stochastic convex optimization (DP-SCO) under user-level privacy, where each user may hold multiple data items. Existing work for user-level DP-SCO either requires super-polynomial runtime [Ghazi et al. (2023)] or requires the number of users to grow polynomially with the dimensionality of the problem with additional strict assumptions [Bassily et al. (2023)]. We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.
</details>
<details>
<summary>摘要</summary>
我们研究具有用户级隐私的减衰 Stochastic Convex Optimization (DP-SCO)，每个用户可能持有多个数据项目。现有的用户级DP-SCO工作 either requires super-polynomial runtime [Ghazi et al. (2023)] 或需要问题的维度 polynomially grows with the number of users and additional strict assumptions [Bassily et al. (2023)]. We develop new algorithms for user-level DP-SCO that obtain optimal rates for both convex and strongly convex functions in polynomial time and require the number of users to grow only logarithmically in the dimension. Moreover, our algorithms are the first to obtain optimal rates for non-smooth functions in polynomial time. These algorithms are based on multiple-pass DP-SGD, combined with a novel private mean estimation procedure for concentrated data, which applies an outlier removal step before estimating the mean of the gradients.
</details></li>
</ul>
<hr>
<h2 id="Neuro-GPT-Developing-A-Foundation-Model-for-EEG"><a href="#Neuro-GPT-Developing-A-Foundation-Model-for-EEG" class="headerlink" title="Neuro-GPT: Developing A Foundation Model for EEG"></a>Neuro-GPT: Developing A Foundation Model for EEG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03764">http://arxiv.org/abs/2311.03764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhui Cui, Woojae Jeong, Philipp Thölke, Takfarinas Medani, Karim Jerbi, Anand A. Joshi, Richard M. Leahy</li>
<li>for: addressing the challenges of data scarcity and heterogeneity in Brain-Computer Interface (BCI) tasks</li>
<li>methods: using a foundation model consisting of an EEG encoder and a GPT model, pre-trained on a large-scale public EEG dataset with a self-supervised task, and fine-tuning on a Motor Imagery Classification task with only 9 subjects</li>
<li>results: significant improvement in classification performance compared to a model trained from scratch, demonstrating the advanced generalizability of the foundation model and its ability to address data scarcity and heterogeneity issues<details>
<summary>Abstract</summary>
To handle the scarcity and heterogeneity of electroencephalography (EEG) data in Brain-Computer Interface (BCI) tasks, and to harness the vast public data, we propose Neuro-GPT, a foundation model consisting of an EEG encoder and a GPT model. The foundation model is pre-trained on a large-scale public EEG dataset, using a self-supervised task which learns how to reconstruct the masked chunk in EEG. We then fine-tune the foundation model on a Motor Imagery Classification task where only 9 subjects are available. Experiments demonstrated that applying foundation model can significantly improve classification performance compared to the model trained from scratch, which provides evidence for the advanced generalizability of foundation model and the ability to address the challenges of data scarcity and heterogeneity.
</details>
<details>
<summary>摘要</summary>
为了处理电энцеfalography（EEG）数据的缺乏和多样性在Brain-Computer Interface（BCI）任务中，并利用大规模公共数据，我们提议Neuro-GPT基础模型，包括EEG编码器和GPT模型。基础模型在大规模公共EEG数据集上自动学习，使用遮盖块的自我超视图学习任务，学习如何重建遮盖块。然后，我们在只有9名参与者的电冲想象分类任务上练习基础模型，实验表明，将基础模型应用于任务中可以显著提高分类性能，这提供了基础模型的进步通用性和数据缺乏和多样性的能力。
</details></li>
</ul>
<hr>
<h2 id="Posterior-Sampling-Based-Bayesian-Optimization-with-Tighter-Bayesian-Regret-Bounds"><a href="#Posterior-Sampling-Based-Bayesian-Optimization-with-Tighter-Bayesian-Regret-Bounds" class="headerlink" title="Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian Regret Bounds"></a>Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian Regret Bounds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03760">http://arxiv.org/abs/2311.03760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shion Takeno, Yu Inatsu, Masayuki Karasuyama, Ichiro Takeuchi</li>
<li>for: 这篇论文是关于搜索空间中的搜索函数（Acquisition Function，AF）的研究，尤其是 Gaussian Process Upper Confidence Bound（GP-UCB）和 Thompson Sampling（TS）两种已知的AF的性能。</li>
<li>methods: 本文首先证明TS实现了更紧的Bayesian Cumulative Regret（BCR）bound，然后通过实验比较GP-UCB、TS和一种新的AF called Probability of Improvement from the Maximum of a Sample Path（PIMS）的性能。</li>
<li>results: 本文的实验结果表明，PIMS可以实现BCR bound，并且不需要手动调整参数，而GP-UCB和TS则经常受到参数调整和过度探索的问题。<details>
<summary>Abstract</summary>
Among various acquisition functions (AFs) in Bayesian optimization (BO), Gaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are well-known options with established theoretical properties regarding Bayesian cumulative regret (BCR). Recently, it has been shown that a randomized variant of GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the tighter BCR bound for brevity. Inspired by this study, this paper first shows that TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often practically suffer from manual hyperparameter tuning and over-exploration issues, respectively. To overcome these difficulties, we propose yet another AF called a probability of improvement from the maximum of a sample path (PIMS). We show that PIMS achieves the tighter BCR bound and avoids the hyperparameter tuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments, focusing on the effectiveness of PIMS that mitigates the practical issues of GP-UCB and TS.
</details>
<details>
<summary>摘要</summary>
among various acquisition functions (AFs) in Bayesian optimization (BO), Gaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are well-known options with established theoretical properties regarding Bayesian cumulative regret (BCR).  Recently, it has been shown that a randomized variant of GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the tighter BCR bound for brevity. Inspired by this study, this paper first shows that TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often practically suffer from manual hyperparameter tuning and over-exploration issues, respectively. To overcome these difficulties, we propose yet another AF called a probability of improvement from the maximum of a sample path (PIMS). We show that PIMS achieves the tighter BCR bound and avoids the hyperparameter tuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments, focusing on the effectiveness of PIMS that mitigates the practical issues of GP-UCB and TS.Note: Please note that the translation is in Simplified Chinese, and the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Manifold-learning-what-how-and-why"><a href="#Manifold-learning-what-how-and-why" class="headerlink" title="Manifold learning: what, how, and why"></a>Manifold learning: what, how, and why</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03757">http://arxiv.org/abs/2311.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marina Meilă, Hanyu Zhang</li>
<li>for: 这篇论文主要是为了介绍抽象学习（Manifold Learning，ML）的原理、方法和统计基础。</li>
<li>methods: 论文使用了许多常见的ML方法，包括ISOMAP、LOCally Linear Embedding（LLE）、Hessian LLE（HLLE）、diffusion maps等。</li>
<li>results: 论文提供了一个实践统计学家的视角，概述了ML方法的负面和优点，以及选择参数和算法时的贸易OFF。<details>
<summary>Abstract</summary>
Manifold learning (ML), known also as non-linear dimension reduction, is a set of methods to find the low dimensional structure of data. Dimension reduction for large, high dimensional data is not merely a way to reduce the data; the new representations and descriptors obtained by ML reveal the geometric shape of high dimensional point clouds, and allow one to visualize, de-noise and interpret them. This survey presents the principles underlying ML, the representative methods, as well as their statistical foundations from a practicing statistician's perspective. It describes the trade-offs, and what theory tells us about the parameter and algorithmic choices we make in order to obtain reliable conclusions.
</details>
<details>
<summary>摘要</summary>
多样性学习（ML），也称为非线性维度减少，是一组方法来找出数据的低维度结构。对于大量、高维度数据，维度减少不仅是一种减少数据的方式，新的表示和描述器由ML获得的减少结构可以描述高维度点云的几何形状，允许我们可视化、去噪和理解它们。这篇评论介绍了ML的原则、代表方法以及其统计基础，从实践统计家的角度出发。它描述了 Parameters and algorithmic choices 的交易和理论告诉我们可以获得可靠的结论。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Enhanced-physics-informed-neural-networks-with-domain-scaling-and-residual-correction-methods-for-multi-frequency-elliptic-problems"><a href="#Enhanced-physics-informed-neural-networks-with-domain-scaling-and-residual-correction-methods-for-multi-frequency-elliptic-problems" class="headerlink" title="Enhanced physics-informed neural networks with domain scaling and residual correction methods for multi-frequency elliptic problems"></a>Enhanced physics-informed neural networks with domain scaling and residual correction methods for multi-frequency elliptic problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03746">http://arxiv.org/abs/2311.03746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deok-Kyu Jang, Hyea Hyun Kim, Kyungsoo Kim</li>
<li>for: 这个论文是为了研究基于神经网络的偏微分方程 approximate 方法。</li>
<li>methods: 论文提出了一种基于神经网络的偏微分方程 Approximation 方法，具有不受不同偏微分方程的形式或问题域的形状或维度的限制的优点。</li>
<li>results: 论文通过对多频解 Solution 问题进行研究，发现神经网络 Approximation 方法的性能和准确性受到高频和低频部分的对比度的影响，并提出了频谱缩放和差异级 correction 方法来解决这个问题。<details>
<summary>Abstract</summary>
In this paper, neural network approximation methods are developed for elliptic partial differential equations with multi-frequency solutions. Neural network work approximation methods have advantages over classical approaches in that they can be applied without much concerns on the form of the differential equations or the shape or dimension of the problem domain. When applied to problems with multi-frequency solutions, the performance and accuracy of neural network approximation methods are strongly affected by the contrast of the high- and low-frequency parts in the solutions. To address this issue, domain scaling and residual correction methods are proposed. The efficiency and accuracy of the proposed methods are demonstrated for multi-frequency model problems.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们开发了基于神经网络的几频解方法，用于解决带几频解的几频偏微分方程。神经网络方法在解决这类问题时具有优势，因为它们不受偏微分方程的形式或问题域的形状或维度的限制。当应用于具有多频解的问题时，神经网络方法的性能和准确性受到带几频解的高频和低频部分的对比的影响。为解决这个问题，我们提出了域扩张和剩余修正方法。我们通过多种多样的模拟问题示出了提议的方法的效率和准确性。
</details></li>
</ul>
<hr>
<h2 id="Improved-weight-initialization-for-deep-and-narrow-feedforward-neural-network"><a href="#Improved-weight-initialization-for-deep-and-narrow-feedforward-neural-network" class="headerlink" title="Improved weight initialization for deep and narrow feedforward neural network"></a>Improved weight initialization for deep and narrow feedforward neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03733">http://arxiv.org/abs/2311.03733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunwoo Lee, Yunho Kim, Seungyeop Yang, Hayoung Choi</li>
<li>for: 解决深度神经网络训练中ReLU活化函数导致神经元死亡的问题。</li>
<li>methods: 提出了一种新的初始 веса方法，并证明了该方法的初始 веса矩阵的性质，以便有效地传递信号 вектор。</li>
<li>results: 通过一系列实验和比较 existed 方法，证明了新 initialization 方法的效果。<details>
<summary>Abstract</summary>
Appropriate weight initialization settings, along with the ReLU activation function, have been a cornerstone of modern deep learning, making it possible to train and deploy highly effective and efficient neural network models across diverse artificial intelligence. The problem of dying ReLU, where ReLU neurons become inactive and yield zero output, presents a significant challenge in the training of deep neural networks with ReLU activation function. Theoretical research and various methods have been introduced to address the problem. However, even with these methods and research, training remains challenging for extremely deep and narrow feedforward networks with ReLU activation function. In this paper, we propose a new weight initialization method to address this issue. We prove the properties of the proposed initial weight matrix and demonstrate how these properties facilitate the effective propagation of signal vectors. Through a series of experiments and comparisons with existing methods, we demonstrate the effectiveness of the new initialization method.
</details>
<details>
<summary>摘要</summary>
modern深度学习中的重要基础之一是适当的初始化设定和ReLU活化函数，使得可以训练和部署高效和高效的神经网络模型。ReLU神经元死亡问题在深度神经网络训练中存在 significannot challenge。有许多理论研究和方法被提出来解决这个问题，但是even with these methods and research, training still remains challenging for extremely deep and narrow feedforward networks with ReLU activation function.在这篇论文中，我们提出了一种新的初始化方法来解决这个问题。我们证明了提案的初始 вес矩阵的属性，并示出这些属性使得信号 вектор的效果propagation。通过一系列实验和现有方法的比较，我们证明了新初始化方法的效果。
</details></li>
</ul>
<hr>
<h2 id="Pipeline-Parallelism-for-DNN-Inference-with-Practical-Performance-Guarantees"><a href="#Pipeline-Parallelism-for-DNN-Inference-with-Practical-Performance-Guarantees" class="headerlink" title="Pipeline Parallelism for DNN Inference with Practical Performance Guarantees"></a>Pipeline Parallelism for DNN Inference with Practical Performance Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03703">http://arxiv.org/abs/2311.03703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaron Archer, Matthew Fahrbach, Kuikui Liu, Prakash Prabhu</li>
<li>for: 提高深度神经网络（DNN）推理的管道并行处理效率，通过将模型图分割为 $k$ 个阶段并最小化瓶颈阶段的运行时间，包括通信。</li>
<li>methods: 提出实用的算法解决这个NP困难问题，并通过对于生产数据进行评估，显示这些算法在实践中几乎是优化的。还使用了新的混合整数程序（MIP）形式来获得更强的下界。</li>
<li>results: 通过应用这些算法和下界方法，在生产模型中实现了较大的近似保证比，比如在 $k&#x3D;16$ 个管道阶段下，通过几何平均值来评估，提高了下界的两倍多，从 $2.175$ 提高到 $1.058$。这种研究表明，虽然最大吞吐量分配是理论上困难，但在实践中，我们已经有了对算法问题的控制，主要是开发更加准确的成本模型，以便将其 feed 到分配算法中。<details>
<summary>Abstract</summary>
We optimize pipeline parallelism for deep neural network (DNN) inference by partitioning model graphs into $k$ stages and minimizing the running time of the bottleneck stage, including communication. We design practical algorithms for this NP-hard problem and show that they are nearly optimal in practice by comparing against strong lower bounds obtained via novel mixed-integer programming (MIP) formulations. We apply these algorithms and lower-bound methods to production models to achieve substantially improved approximation guarantees compared to standard combinatorial lower bounds. For example, evaluated via geometric means across production data with $k=16$ pipeline stages, our MIP formulations more than double the lower bounds, improving the approximation ratio from $2.175$ to $1.058$. This work shows that while max-throughput partitioning is theoretically hard, we have a handle on the algorithmic side of the problem in practice and much of the remaining challenge is in developing more accurate cost models to feed into the partitioning algorithms.
</details>
<details>
<summary>摘要</summary>
我们优化深度神经网络（DNN）推断的管线并行性，通过分解模型图到$k$个阶段，最小化瓶须时间，包括交互时间。我们设计了实用的算法来解决这个NP困难的问题，并证明它们在实践中几乎是最佳的。我们使用这些算法和新的混合整数程式（MIP）表示法来与生产模型进行比较，实现了明显改善的近似保证比率。例如，通过考虑生产数据中的$k=16$个管线阶段，我们的MIP表示法可以超过标准的 combinatorial 下界，从$2.175$提高到$1.058$。这个工作显示，处理器的最大运行速率分配是理论上困难的，但在实践中，我们已经掌握了算法的一个 Handle ，而主要的挑战在于发展更准确的成本模型，以便将其输入到分配算法中。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Non-monotone-Submodular-Maximization"><a href="#Dynamic-Non-monotone-Submodular-Maximization" class="headerlink" title="Dynamic Non-monotone Submodular Maximization"></a>Dynamic Non-monotone Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03685">http://arxiv.org/abs/2311.03685</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiarash Banihashem, Leyla Biabani, Samira Goudarzi, MohammadTaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh</li>
<li>for: 本研究旨在提出动态算法来解决非升序子模杂函数最大化问题。</li>
<li>methods: 作者使用了减少函数的技术来解决本问题，并提出了一种基于减少函数的动态算法。</li>
<li>results: 作者通过一种减少函数的转化，实现了解决非升序子模杂函数最大化问题的动态算法，并且可以保证算法的精度在8加eps的级别。<details>
<summary>Abstract</summary>
Maximizing submodular functions has been increasingly used in many applications of machine learning, such as data summarization, recommendation systems, and feature selection. Moreover, there has been a growing interest in both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and Lattanzi, Mitrovic, Norouzi{-}Fard, Tarnawski, and Zadimoghaddam initiated developing dynamic algorithms for the monotone submodular maximization problem under the cardinality constraint $k$. Recently, there have been some improvements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi, Jabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of this problem and raised an important open question: "Can we extend [fully dynamic] results (algorithm or hardness) to non-monotone submodular maximization?". We affirmatively answer their question by demonstrating a reduction from maximizing a non-monotone submodular function under the cardinality constraint $k$ to maximizing a monotone submodular function under the same constraint. Through this reduction, we obtain the first dynamic algorithms to solve the non-monotone submodular maximization problem under the cardinality constraint $k$. Our algorithms maintain an $(8+\epsilon)$-approximate of the solution and use expected amortized $O(\epsilon^{-3}k^3\log^3(n)\log(k))$ or $O(\epsilon^{-1}k^2\log^3(k))$ oracle queries per update, respectively. Furthermore, we showcase the benefits of our dynamic algorithm for video summarization and max-cut problems on several real-world data sets.
</details>
<details>
<summary>摘要</summary>
Maximizing submodular functions has been increasingly used in many machine learning applications, such as data summarization, recommendation systems, and feature selection. In addition, there has been growing interest in both submodular maximization and dynamic algorithms. In 2020, Monemizadeh and Lattanzi, Mitrovic, Norouzi-Fard, Tarnawski, and Zadimoghaddam began developing dynamic algorithms for the monotone submodular maximization problem under the cardinality constraint $k$. Recently, there have been some improvements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi, Jabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of this problem and raised an important open question: "Can we extend [fully dynamic] results (algorithm or hardness) to non-monotone submodular maximization?" We answer their question affirmatively by demonstrating a reduction from maximizing a non-monotone submodular function under the cardinality constraint $k$ to maximizing a monotone submodular function under the same constraint. Through this reduction, we obtain the first dynamic algorithms to solve the non-monotone submodular maximization problem under the cardinality constraint $k$. Our algorithms achieve an $(8+\epsilon)$-approximation of the solution and use expected amortized $O(\epsilon^{-3}k^3\log^3(n)\log(k))$ or $O(\epsilon^{-1}k^2\log^3(k))$ oracle queries per update, respectively. Furthermore, we demonstrate the benefits of our dynamic algorithm for video summarization and max-cut problems on several real-world data sets.
</details></li>
</ul>
<hr>
<h2 id="Preventing-Arbitrarily-High-Confidence-on-Far-Away-Data-in-Point-Estimated-Discriminative-Neural-Networks"><a href="#Preventing-Arbitrarily-High-Confidence-on-Far-Away-Data-in-Point-Estimated-Discriminative-Neural-Networks" class="headerlink" title="Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks"></a>Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03683">http://arxiv.org/abs/2311.03683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Rashid, Serena Hacker, Guojun Zhang, Agustinus Kristiadi, Pascal Poupart</li>
<li>for: 这个论文旨在解决过去的数据分类问题中的过度自信问题，使用添加一个类别的条件函数来避免这个问题。</li>
<li>methods: 本文使用了一种简单的条件函数来让神经网络在训练时具有适当的自信水平，并且不需要更改现有的训练方法。</li>
<li>results: 本文的实验结果显示，这种技巧可以强制神经网络在训练和测试时具有更好的自信水平，并且在不同的benchmark测试中都有出色的表现。<details>
<summary>Abstract</summary>
Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks -- a popular class of neural network architectures -- have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data.This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance against competitive baselines on both far-away and realistic OOD data.
</details>
<details>
<summary>摘要</summary>
deterministic神经网络在分类问题上是实际选择。然而，它们在不同领域测试集上表现出状态的最佳结果，但它们往往对不同领域测试集数据进行过于自信。例如，ReLU网络——一种流行的神经网络体系——在测试数据远离训练集时总是给出高自信度预测，即使它们在训练集上使用不同领域测试集数据。我们解决这个问题的方法是添加神经网络输出的一个项目，该项目对应于一个额外的类别的логи值，我们设计其在测试数据远离训练集时dominate其他类别的LOGIT。这种技术可以证明地防止不可预期的高自信度在远离训练集的测试数据上，而不需要复杂的权重学习或泛化学习。我们在不同的benchmark上进行评估，并证明了与竞争对手的基准值在不同的OOD数据上具有强大的表现。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-for-Power-Grid-Operational-Risk-Assessment"><a href="#Graph-Neural-Networks-for-Power-Grid-Operational-Risk-Assessment" class="headerlink" title="Graph Neural Networks for Power Grid Operational Risk Assessment"></a>Graph Neural Networks for Power Grid Operational Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03661">http://arxiv.org/abs/2311.03661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yadong Zhang, Pranav M Karve, Sankaran Mahadevan</li>
<li>for:  investigate the utility of graph neural network (GNN) surrogates for Monte Carlo (MC) sampling-based risk quantification in daily operations of power grid</li>
<li>methods: train GNN surrogates using supervised learning to obtain Monte Carlo samples of the quantities of interest (operating reserve, transmission line flow) given the (hours-ahead) probabilistic wind generation and load forecast</li>
<li>results: GNN surrogates are sufficiently accurate for predicting the (bus-level, branch-level and system-level) grid state and enable fast as well as accurate operational risk quantification for power gridsHere’s the format you requested:</li>
<li>for: &lt;what are the paper written for?&gt;</li>
<li>methods: &lt;what methods the paper use?&gt;</li>
<li>results: &lt;what results the paper get?&gt;I hope that helps!<details>
<summary>Abstract</summary>
In this article, the utility of graph neural network (GNN) surrogates for Monte Carlo (MC) sampling-based risk quantification in daily operations of power grid is investigated. The MC simulation process necessitates solving a large number of optimal power flow (OPF) problems corresponding to the sample values of stochastic grid variables (power demand and renewable generation), which is computationally prohibitive. Computationally inexpensive surrogates of the OPF problem provide an attractive alternative for expedited MC simulation. GNN surrogates are especially suitable due to their superior ability to handle graph-structured data. Therefore, GNN surrogates of OPF problem are trained using supervised learning. They are then used to obtain Monte Carlo (MC) samples of the quantities of interest (operating reserve, transmission line flow) given the (hours-ahead) probabilistic wind generation and load forecast. The utility of GNN surrogates is evaluated by comparing OPF-based and GNN-based grid reliability and risk for IEEE Case118 synthetic grid. It is shown that the GNN surrogates are sufficiently accurate for predicting the (bus-level, branch-level and system-level) grid state and enable fast as well as accurate operational risk quantification for power grids. The article thus develops various tools for fast reliability and risk quantification for real-world power grids using GNNs.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们调查了图型神经网络（GNN）伪函数的应用于随机产生 Monte Carlo（MC）样本基础的电力网络风险评估。MC仿真过程需要解决大量的优化电力流（OPF）问题，这是计算昂贵的。使用计算成本低的GNN伪函数提供了一个有利的选择，以促进MC仿真。GNN伪函数特别适用于处理图结构数据，因此通过直接supervised学习来训练GNN伪函数。然后，GNN伪函数被用来在(时间前) probabilistic风力发电和需求预测基础上获得MC样本中的量据（运行储备、电力传送）。GNN伪函数的使用效果被评估通过比较OPF基础和GNN基础上的电力网络可靠性和风险。结果显示，GNN伪函数具有足够的准确性，可以预测(电气站级、电力线级和系统级)电力网络状态，并且可以快速并准确地进行操作风险评估。文章因此开发了基于GNN的快速可靠性和风险评估工具，以便应用于实际电力网络。
</details></li>
</ul>
<hr>
<h2 id="A-Physics-Guided-Bi-Fidelity-Fourier-Featured-Operator-Learning-Framework-for-Predicting-Time-Evolution-of-Drag-and-Lift-Coefficients"><a href="#A-Physics-Guided-Bi-Fidelity-Fourier-Featured-Operator-Learning-Framework-for-Predicting-Time-Evolution-of-Drag-and-Lift-Coefficients" class="headerlink" title="A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning Framework for Predicting Time Evolution of Drag and Lift Coefficients"></a>A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning Framework for Predicting Time Evolution of Drag and Lift Coefficients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03639">http://arxiv.org/abs/2311.03639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Mollaali, Izzet Sahin, Iqrar Raza, Christian Moya, Guillermo Paniagua, Guang Lin</li>
<li>For: 提高计算效率，减少计算资源，实现高精度结果。* Methods: 使用深度学习网络，组合低精度和高精度数据，充分利用低精度数据的优势，并通过物理指导和傅里叶特征网络进行提升。* Results: 实验结果表明，physics-guided Fourier-featured deep operator network具有更高的预测精度，并且可以减少计算资源。<details>
<summary>Abstract</summary>
In the pursuit of accurate experimental and computational data while minimizing effort, there is a constant need for high-fidelity results. However, achieving such results often requires significant computational resources. To address this challenge, this paper proposes a deep operator learning-based framework that requires a limited high-fidelity dataset for training. We introduce a novel physics-guided, bi-fidelity, Fourier-featured Deep Operator Network (DeepONet) framework that effectively combines low and high-fidelity datasets, leveraging the strengths of each. In our methodology, we began by designing a physics-guided Fourier-featured DeepONet, drawing inspiration from the intrinsic physical behavior of the target solution. Subsequently, we train this network to primarily learn the low-fidelity solution, utilizing an extensive dataset. This process ensures a comprehensive grasp of the foundational solution patterns. Following this foundational learning, the low-fidelity deep operator network's output is enhanced using a physics-guided Fourier-featured residual deep operator network. This network refines the initial low-fidelity output, achieving the high-fidelity solution by employing a small high-fidelity dataset for training. Notably, in our framework, we employ the Fourier feature network as the Trunk network for the DeepONets, given its proficiency in capturing and learning the oscillatory nature of the target solution with high precision. We validate our approach using a well-known 2D benchmark cylinder problem, which aims to predict the time trajectories of lift and drag coefficients. The results highlight that the physics-guided Fourier-featured deep operator network, serving as a foundational building block of our framework, possesses superior predictive capability for the lift and drag coefficients compared to its data-driven counterparts.
</details>
<details>
<summary>摘要</summary>
在寻求准确的实验和计算数据的同时最小化努力的过程中，需要高精度的结果。然而，获得这些结果frequently需要显著的计算资源。为解决这个挑战，这篇文章提出了一个基于深度学习的深度运算网络（DeepONet）框架，只需要一小量高精度数据进行训练。我们提出了一种新的物理导向的、双精度的、傅里埃特征的深度运算网络（DeepONet）框架，可以有效地结合低精度和高精度数据，利用每个数据集的优点。在我们的方法中，我们首先设计了物理导向的傅里埃特征的深度运算网络， drawing inspiration from the intrinsic physical behavior of the target solution。然后，我们通过一个广泛的数据集来训练这个网络，以主要学习低精度解。这个过程确保了我们对基础解决方案的全面的掌握。接着，我们使用物理导向的傅里埃特征的深度运算网络来进一步加强低精度深度运算网络的输出，以实现高精度解。在我们的框架中，我们利用傅里埃特网络作为深度运算网络的核心网络，因为它能够高精度地捕捉和学习目标解的oscillatory nature。我们验证了我们的方法使用一个well-known 2D benchmark cylinder problem，该问题的目标是预测缝翼和推力强度的时间轨迹。结果显示，物理导向的傅里埃特特征的深度运算网络，作为我们框架的基础建筑块，在预测缝翼和推力强度方面具有更高的预测能力，相比于其数据驱动的对手。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Data-Augmentation-with-Contrastive-Learning"><a href="#Counterfactual-Data-Augmentation-with-Contrastive-Learning" class="headerlink" title="Counterfactual Data Augmentation with Contrastive Learning"></a>Counterfactual Data Augmentation with Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03630">http://arxiv.org/abs/2311.03630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Aloui, Juncheng Dong, Cat P. Le, Vahid Tarokh</li>
<li>for: 这篇论文的目的是提出一种model-agnostic data augmentation方法，用于改善 conditional average treatment effect（CATE）估计中的statistical disparity问题。</li>
<li>methods: 这篇论文使用contrastive learning方法来学习一个代表空间和一个相似度量，以便将近似的个体（即来自不同治疗群的对照群个体）的潜在结果预测为可靠。</li>
<li>results: 论文的实验研究表明，这种方法可以对CATE估计模型增加 significiant improvement in both performance和防止过滤溢loss，并且在实际应用中具有良好的适用性。<details>
<summary>Abstract</summary>
Statistical disparity between distinct treatment groups is one of the most significant challenges for estimating Conditional Average Treatment Effects (CATE). To address this, we introduce a model-agnostic data augmentation method that imputes the counterfactual outcomes for a selected subset of individuals. Specifically, we utilize contrastive learning to learn a representation space and a similarity measure such that in the learned representation space close individuals identified by the learned similarity measure have similar potential outcomes. This property ensures reliable imputation of counterfactual outcomes for the individuals with close neighbors from the alternative treatment group. By augmenting the original dataset with these reliable imputations, we can effectively reduce the discrepancy between different treatment groups, while inducing minimal imputation error. The augmented dataset is subsequently employed to train CATE estimation models. Theoretical analysis and experimental studies on synthetic and semi-synthetic benchmarks demonstrate that our method achieves significant improvements in both performance and robustness to overfitting across state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
“统计差异 между不同治疗组是估计 Conditional Average Treatment Effects (CATE) 中最大的挑战。为解决这个问题，我们提出了一种模型无关的数据扩充方法，该方法在选择的一 subset of individuals 中进行了归一化。specifically, we utilize contrastive learning to learn a representation space and a similarity measure, such that in the learned representation space, close individuals identified by the learned similarity measure have similar potential outcomes. This property ensures reliable imputation of counterfactual outcomes for the individuals with close neighbors from the alternative treatment group. By augmenting the original dataset with these reliable imputations, we can effectively reduce the discrepancy between different treatment groups, while inducing minimal imputation error. The augmented dataset is subsequently employed to train CATE estimation models. theoretical analysis and experimental studies on synthetic and semi-synthetic benchmarks demonstrate that our method achieves significant improvements in both performance and robustness to overfitting across state-of-the-art models.”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Are-Words-Enough-On-the-semantic-conditioning-of-affective-music-generation"><a href="#Are-Words-Enough-On-the-semantic-conditioning-of-affective-music-generation" class="headerlink" title="Are Words Enough? On the semantic conditioning of affective music generation"></a>Are Words Enough? On the semantic conditioning of affective music generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03624">http://arxiv.org/abs/2311.03624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorge Forero, Gilberto Bernardes, Mónica Mendes</li>
<li>for: 本研究的目的是分析和讨论自动生成音乐中的情感表达方法。</li>
<li>methods: 本研究涉及了两种主要的方法：规则驱动的模型和深度学习模型。深度学习模型可以自动生成高质量的音乐从文本描述中。</li>
<li>results: 研究发现，使用深度学习与自然语言结合可以为创作业界提供强大的工具，以便提示和生成新的音乐作品。<details>
<summary>Abstract</summary>
Music has been commonly recognized as a means of expressing emotions. In this sense, an intense debate emerges from the need to verbalize musical emotions. This concern seems highly relevant today, considering the exponential growth of natural language processing using deep learning models where it is possible to prompt semantic propositions to generate music automatically. This scoping review aims to analyze and discuss the possibilities of music generation conditioned by emotions. To address this topic, we propose a historical perspective that encompasses the different disciplines and methods contributing to this topic. In detail, we review two main paradigms adopted in automatic music generation: rules-based and machine-learning models. Of note are the deep learning architectures that aim to generate high-fidelity music from textual descriptions. These models raise fundamental questions about the expressivity of music, including whether emotions can be represented with words or expressed through them. We conclude that overcoming the limitation and ambiguity of language to express emotions through music, some of the use of deep learning with natural language has the potential to impact the creative industries by providing powerful tools to prompt and generate new musical works.
</details>
<details>
<summary>摘要</summary>
音乐已被广泛认为是表达情感的手段。在这意义上，有一场激烈的辩论，即如何用语言表达音乐中的情感。这个问题在今天更加有 relevance，因为深度学习模型的批处理能力在自动生成音乐方面得到了极大的提高。本综述的目的是分析和讨论情感决定自动生成音乐的可能性。为此，我们提出了历史背景，涵盖了不同领域和方法对这个话题的贡献。在详细介绍中，我们评论了两种主要的自动音乐生成方法：规则based和机器学习模型。特别是深度学习架构，可以生成高质量的音乐从文本描述。这些模型提出了音乐表达性的基本问题，包括情感是否可以通过语言表达，或者是通过语言表达出来的。我们认为，通过深度学习与自然语言的结合，可以超越语言表达情感的限制和歧义，对创作业场产生强大的影响，提供 poderful工具来促进和生成新的音乐作品。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Latent-Spaces-of-Tonal-Music-using-Variational-Autoencoders"><a href="#Exploring-Latent-Spaces-of-Tonal-Music-using-Variational-Autoencoders" class="headerlink" title="Exploring Latent Spaces of Tonal Music using Variational Autoencoders"></a>Exploring Latent Spaces of Tonal Music using Variational Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03621">http://arxiv.org/abs/2311.03621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NadiaCarvalho/Latent-Tonal-Music">https://github.com/NadiaCarvalho/Latent-Tonal-Music</a></li>
<li>paper_authors: Nádia Carvalho, Gilberto Bernardes</li>
<li>for: 这个论文的目的是使用变形自动编码器（VAEs）模型生成含有听觉和semantic值的秘密表示。</li>
<li>methods: 这个论文使用了多种VAEs编码方法，包括钢琴滚珍、MIDI、ABC、 Tonnetz、振荡函数等。</li>
<li>results: 研究发现，使用ABC编码方法可以最好地重建原始数据，而振荡函数编码方法可以从秘密空间中提取更多的信息。此外，研究还发现，使用12个主或副调谱的对比可以量化每个键的听觉空间之间的对应关系，并且发现这些关系与认知的折衔空间之间存在着明确的对应关系。<details>
<summary>Abstract</summary>
Variational Autoencoders (VAEs) have proven to be effective models for producing latent representations of cognitive and semantic value. We assess the degree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's chorales define latent spaces representative of the circle of fifths and the hierarchical relation of each key component pitch as drawn in music cognition. In detail, we compare the latent space of different VAE corpus encodings -- Piano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions -- in providing a pitch space for key relations that align with cognitive distances. We evaluate the model performance of these encodings using objective metrics to capture accuracy, mean square error (MSE), KL-divergence, and computational cost. The ABC encoding performs the best in reconstructing the original data, while the Pitch DFT seems to capture more information from the latent space. Furthermore, an objective evaluation of 12 major or minor transpositions per piece is adopted to quantify the alignment of 1) intra- and inter-segment distances per key and 2) the key distances to cognitive pitch spaces. Our results show that Pitch DFT VAE latent spaces align best with cognitive spaces and provide a common-tone space where overlapping objects within a key are fuzzy clusters, which impose a well-defined order of structural significance or stability -- i.e., a tonal hierarchy. Tonal hierarchies of different keys can be used to measure key distances and the relationships of their in-key components at multiple hierarchies (e.g., notes and chords). The implementation of our VAE and the encodings framework are made available online.
</details>
<details>
<summary>摘要</summary>
Variational Autoencoders (VAEs) 已经证明是有效的模型，用于生成含义和语义价值的潜在表示。我们评估了 Vaes 在 Bach chorales 批处理的词汇桶中定义的潜在空间是否与圆形五度和每个键Component折射的层次关系相align。在详细的描述中，我们比较了不同的 Vaes 桶编码 -- Piano Roll、MIDI、ABC、 Tonnetz、DFT 折射和折射分布 -- 在提供一个折射空间来支持键关系的层次结构是否与认知距离相align。我们使用对象 metric 评估这些编码的表现，包括准确率、平方差误差（MSE）、KL散度和计算成本。ABC 编码表现最好地重建原始数据，而 Pitch DFT 则在潜在空间中捕捉更多信息。此外，我们采用对象评估方法，对每个键中的 12 个主或调谱进行12个主或调谱的转换，以衡量每个键之间的距离和认知折射空间之间的对应关系。我们的结果表明，Pitch DFT VAE 潜在空间最好地与认知空间对align，提供了一个通用频谱，在这里，每个键的内部对象在一个共同频谱中具有杂散的团集结构，这种结构具有明确的顺序或稳定性 -- i.e., tonal hierarchy。不同键的折射层次可以用来测量键之间的距离和各个键中的结构重要性。我们的 VAE 和编码框架在线上进行实现。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/cs.LG_2023_11_07/" data-id="cloqtaeuy00t7gh882ylfd86k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/eess.IV_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T09:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/eess.IV_2023_11_07/">eess.IV - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improved-Topological-Preservation-in-3D-Axon-Segmentation-and-Centerline-Detection-using-Geometric-Assessment-driven-Topological-Smoothing-GATS"><a href="#Improved-Topological-Preservation-in-3D-Axon-Segmentation-and-Centerline-Detection-using-Geometric-Assessment-driven-Topological-Smoothing-GATS" class="headerlink" title="Improved Topological Preservation in 3D Axon Segmentation and Centerline Detection using Geometric Assessment-driven Topological Smoothing (GATS)"></a>Improved Topological Preservation in 3D Axon Segmentation and Centerline Detection using Geometric Assessment-driven Topological Smoothing (GATS)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04116">http://arxiv.org/abs/2311.04116</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nina I. Shamsi, Alex S. Xu, Lars A. Gjesteby, Laura J. Brattain</li>
<li>for: The paper aims to develop an automated approach for morphological smoothing in brain microscopy volumes to improve the accuracy of segmentation and centerline detection in the presence of curvilinear structures.</li>
<li>methods: The proposed method uses geometric assessment of the radius of tubular structures to drive topological smoothing, and applies average pooling to prevent over-thinning. The approach is based on the use of a loss function called Geo-metric Assessment-driven Topological Smoothing loss (GATS).</li>
<li>results: The proposed method improved segmentation and centerline detection evaluation metrics by 2%-5% across multiple datasets, and reduced the Betti errors by 9%. The ablation study showed that geometric assessment of tubular structures and using average pooling for morphological smoothing are key components of the method’s success. The use of GATS led to increased topological preservation during automated annotation of 3D axons volumes.<details>
<summary>Abstract</summary>
Automated axon tracing via fully supervised learning requires large amounts of 3D brain imagery, which is time consuming and laborious to obtain. It also requires expertise. Thus, there is a need for more efficient segmentation and centerline detection techniques to use in conjunction with automated annotation tools. Topology-preserving methods ensure that segmented components maintain geometric connectivity, which is especially meaningful for applications where volumetric data is used, and these methods often make use of morphological thinning algorithms as the thinned outputs can be useful for both segmentation and centerline detection of curvilinear structures. Current morphological thinning approaches used in conjunction with topology-preserving methods are prone to over-thinning and require manual configuration of hyperparameters. We propose an automated approach for morphological smoothing using geometric assessment of the radius of tubular structures in brain microscopy volumes, and apply average pooling to prevent over-thinning. We use this approach to formulate a loss function, which we call Geo-metric Assessment-driven Topological Smoothing loss, or GATS. Our approach increased segmentation and center-line detection evaluation metrics by 2%-5% across multiple datasets, and improved the Betti error rates by 9%. Our ablation study showed that geometric assessment of tubular structures achieved higher segmentation and centerline detection scores, and using average pooling for morphological smoothing in place of thinning algorithms reduced the Betti errors. We observed increased topological preservation during automated annotation of 3D axons volumes from models trained with GATS.
</details>
<details>
<summary>摘要</summary>
自动化轴索追踪通过完全监督学习需要大量的3D脑成像数据，这需要较长的时间和劳动 intensity 获取，同时还需要专业知识。因此，有需要更高效的分割和中心线检测技术，以便与自动注释工具结合使用。保持 topology 的方法可以确保分割的组件保持几何连接，特别是在使用 объем数据时，这些方法通常使用 morphological thinning 算法，因为这些输出可以用于分割和中心线检测曲线结构。现有的 morphological thinning 方法在与保持 topology 方法结合使用时容易过度细化，并且需要手动配置 гипер参数。我们提出一种自动化的 morphological smoothing 方法，使用脑微scopic 图像卷积的卷积 радиу斯 geometric assessment，并使用平均聚合来避免过度细化。我们使用这种方法定义的损失函数，我们称之为 Geo-metric Assessment-driven Topological Smoothing loss，或 GATS。我们的方法在多个数据集上提高了分割和中心线检测评价指标，提高了 Betti 错误率9%。我们的剥离研究表明， geometric assessment of tubular structures 可以提高分割和中心线检测分数，并且使用平均聚合 instead of thinning algorithms 可以降低 Betti 错误。我们观察到在自动注释3D axons 图像时，使用 GATS 可以更好地保持 topological 结构。
</details></li>
</ul>
<hr>
<h2 id="Toward-ground-truth-optical-coherence-tomography-via-three-dimensional-unsupervised-deep-learning-processing-and-data"><a href="#Toward-ground-truth-optical-coherence-tomography-via-three-dimensional-unsupervised-deep-learning-processing-and-data" class="headerlink" title="Toward ground-truth optical coherence tomography via three-dimensional unsupervised deep learning processing and data"></a>Toward ground-truth optical coherence tomography via three-dimensional unsupervised deep learning processing and data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03887">http://arxiv.org/abs/2311.03887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renxiong Wu, Fei Zheng, Meixuan Li, Shaoyan Huang, Xin Ge, Linbo Liu, Yong Liu, Guangming Ni<br>for:* 这篇论文旨在提出一种新的无杂点Speckle OCT成像策略，以提高OCT成像质量和扩展其应用范围。methods:* 该策略利用无监督的3D卷积神经网络，通过分离Speckle和实际结构来实现无杂点OCT成像。results:* 对不同样品进行测试，研究人员发现tGT-OCT可以提供高质量的无杂点3D成像，并超过了之前的状态之arct。<details>
<summary>Abstract</summary>
Optical coherence tomography (OCT) can perform non-invasive high-resolution three-dimensional (3D) imaging and has been widely used in biomedical fields, while it is inevitably affected by coherence speckle noise which degrades OCT imaging performance and restricts its applications. Here we present a novel speckle-free OCT imaging strategy, named toward-ground-truth OCT (tGT-OCT), that utilizes unsupervised 3D deep-learning processing and leverages OCT 3D imaging features to achieve speckle-free OCT imaging. Specifically, our proposed tGT-OCT utilizes an unsupervised 3D-convolution deep-learning network trained using random 3D volumetric data to distinguish and separate speckle from real structures in 3D imaging volumetric space; moreover, tGT-OCT effectively further reduces speckle noise and reveals structures that would otherwise be obscured by speckle noise while preserving spatial resolution. Results derived from different samples demonstrated the high-quality speckle-free 3D imaging performance of tGT-OCT and its advancement beyond the previous state-of-the-art.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Fast-Algorithm-for-Low-Rank-Sparse-column-wise-Compressive-Sensing"><a href="#A-Fast-Algorithm-for-Low-Rank-Sparse-column-wise-Compressive-Sensing" class="headerlink" title="A Fast Algorithm for Low Rank + Sparse column-wise Compressive Sensing"></a>A Fast Algorithm for Low Rank + Sparse column-wise Compressive Sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03824">http://arxiv.org/abs/2311.03824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silpa Babu, Namrata Vaswani</li>
<li>for: 本研究目的是解决一个low rank + sparse（LR+S）列式压缩感知问题，即从 $m$ 个独立的线性投影中重建一个 $n \times q$ 矩阵 $\X^*$，其中 $\X^*$ 可以分解为一个低级矩阵 $\L^*$ 和一个稀疏矩阵 $\S^*$。</li>
<li>methods: 本文提出了一种新的快速GD-based解决方案called AltGDmin-LR+S，它是内存和通信效率高的。</li>
<li>results: 通过对一系列的simulation-based研究进行数值评估，本文证明了AltGDmin-LR+S方法的性能。<details>
<summary>Abstract</summary>
This paper focuses studies the following low rank + sparse (LR+S) column-wise compressive sensing problem. We aim to recover an $n \times q$ matrix, $\X^* =[ \x_1^*, \x_2^*, \cdots , \x_q^*]$ from $m$ independent linear projections of each of its $q$ columns, given by $\y_k :=\A_k\x_k^*$, $k \in [q]$. Here, $\y_k$ is an $m$-length vector with $m < n$. We assume that the matrix $\X^*$ can be decomposed as $\X^*=\L^*+\S^*$, where $\L^*$ is a low rank matrix of rank $r << \min(n,q)$ and $\S^*$ is a sparse matrix. Each column of $\S$ contains $\rho$ non-zero entries. The matrices $\A_k$ are known and mutually independent for different $k$. To address this recovery problem, we propose a novel fast GD-based solution called AltGDmin-LR+S, which is memory and communication efficient. We numerically evaluate its performance by conducting a detailed simulation-based study.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/eess.IV_2023_11_07/" data-id="cloqtaf1q0195gh88fmvldt2f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_07" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/07/eess.SP_2023_11_07/" class="article-date">
  <time datetime="2023-11-07T08:00:00.000Z" itemprop="datePublished">2023-11-07</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/07/eess.SP_2023_11_07/">eess.SP - 2023-11-07</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="High-performance-Power-Allocation-Strategies-for-Active-IRS-aided-Wireless-Network"><a href="#High-performance-Power-Allocation-Strategies-for-Active-IRS-aided-Wireless-Network" class="headerlink" title="High-performance Power Allocation Strategies for Active IRS-aided Wireless Network"></a>High-performance Power Allocation Strategies for Active IRS-aided Wireless Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04032">http://arxiv.org/abs/2311.04032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Zhao, Xuehui Wang, Yan Wang, Xianpeng Wang, Zhilin Chen, Feng Shu, Jiangzhou Wang</li>
<li>for: 本研究旨在解决基站和反射表面之间的功率分配问题，以优化反射表面活动智能反射表面（IRS）的性能。</li>
<li>methods: 本研究提出了一种基于梯度上升（GA）的等间隔多点初始化方法（ESMPI-GA），以及一种基于第三阶 Taylor 展开（TTE）的关闭式功率分配方法。</li>
<li>results:  simulation 结果显示，提出的 ESMPI-GA 方法可以在小规模 IRS 中获得约0.5比特的性能提升，而基于 TTE 的方法可以减少高复杂性，并且在几个参数下表现较好。<details>
<summary>Abstract</summary>
Due to its intrinsic ability to combat the double fading effect, the active intelligent reflective surface (IRS) becomes popular. The main feature of active IRS must be supplied by power, and the problem of how to allocate the total power between base station (BS) and IRS to fully explore the rate gain achieved by power allocation (PA) to remove the rate gap between existing PA strategies and optimal exhaustive search (ES) arises naturally. First, the signal-to-noise ratio (SNR) expression is derived to be a function of PA factor beta [0, 1]. Then, to improve the rate performance of the conventional gradient ascent (GA), an equal-spacing-multiple-point-initialization GA (ESMPI-GA) method is proposed. Due to its slow linear convergence from iterative GA, the proposed ESMPI-GA is high-complexity. Eventually, to reduce this high complexity, a low-complexity closed-form PA method with third-order Taylor expansion (TTE) centered at point beta0 = 0.5 is proposed. Simulation results show that the proposed ESMPI-GA harvests about 0.5 bit gain over conventional GA and 1.2 and 0.8 bits gain over existing methods like equal PA and Taylor polynomial approximation (TPA) for small-scale IRS, and the proposed TTE performs much better than TPA and fixed PA strategies using an extremely low complexity.
</details>
<details>
<summary>摘要</summary>
由于它的内置能力来抗衰减效果，活动智能反射表面（IRS）已成为流行的选择。主要特点 OF active IRS 需要提供电力，因此如何将总能量分配给基站（BS）和 IRS 以全面探索PA 策略中的 rate 增加问题 naturally arises。首先，信号噪声比（SNR）的表达式被 derive 为 beta 的函数 [0, 1]。然后，为了改进传统的梯度升级（GA）的率性能，一种 equal-spacing-multiple-point-initialization GA（ESMPI-GA）方法被提议。由于它的慢速线性收敛，提议的 ESMPI-GA 高复杂。最终，为了减少这种高复杂性，一种 low-complexity closed-form PA 方法 WITH third-order Taylor expansion（TTE）中心点 beta0 = 0.5 被提议。Simulation 结果表明，提议的 ESMPI-GA 可以升级约 0.5 比特逻辑上，并在小规模 IRS 上升级约 1.2 和 0.8 比特逻辑上，而提议的 TTE 表现更好于 TPA 和 fixed PA 策略，并使用极低复杂性。
</details></li>
</ul>
<hr>
<h2 id="Memory-AMP-for-Generalized-MIMO-Coding-Principle-and-Information-Theoretic-Optimality"><a href="#Memory-AMP-for-Generalized-MIMO-Coding-Principle-and-Information-Theoretic-Optimality" class="headerlink" title="Memory AMP for Generalized MIMO: Coding Principle and Information-Theoretic Optimality"></a>Memory AMP for Generalized MIMO: Coding Principle and Information-Theoretic Optimality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04012">http://arxiv.org/abs/2311.04012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufei Chen, Lei Liu, Yuhao Chi, Ying Li, Zhaoyang Zhang<br>for: 本文主要针对下一代无线通信中复杂的通信场景，提出一种通用多Input多Output（GMIMO）系统，并对其进行实际假设，如巨量天线、实用channel编码、任意输入分布和一般右特征 matrices（包括尘埃抛射、一些不良conditioned和相关的通道矩阵）。methods: 本文使用ORTogonal&#x2F;vector approximate message passing（OAMP&#x2F;VAMP）接收器，并证明其在GMIMO系统中是信息理论上最优的，但是它具有高复杂度LMMSE的限制。为解决这个问题，本文提出一种低复杂度内存approximate message passing（MAMP）接收器，并证明其在uncoded系统中是 bayes 优的。results: 本文通过开发了一种简化单输入单输出的variational state evolution（VSE）来分析MAMP接收器的可 achievable rate，并确定了最优的编码原则以最大化可 achievable rate。此外，本文还证明了MAMP接收器的信息理论上optimal性。数值结果表明，使用实际优化的LDPC编码在大规模系统中，MAMP接收器的finite length性能与相关的受限容量相差0.5-2.7 dB。值得一提的是，MAMP接收器可以在大规模系统中实现与OAMP&#x2F;VAMP接收器相同的性能，但是它的计算时间只占OAMP&#x2F;VAMP接收器的0.4%。<details>
<summary>Abstract</summary>
To support complex communication scenarios in next-generation wireless communications, this paper focuses on a generalized MIMO (GMIMO) with practical assumptions, such as massive antennas, practical channel coding, arbitrary input distributions, and general right-unitarily-invariant channel matrices (covering Rayleigh fading, certain ill-conditioned and correlated channel matrices). The orthogonal/vector approximate message passing (OAMP/VAMP) receiver has been proved to be information-theoretically optimal in GMIMO, but it is limited to high-complexity LMMSE. To solve this problem, a low-complexity memory approximate message passing (MAMP) receiver has recently been shown to be Bayes optimal but limited to uncoded systems. Therefore, how to design a low-complexity and information-theoretically optimal receiver for GMIMO is still an open issue. To address this issue, this paper proposes an information-theoretically optimal MAMP receiver and investigates its achievable rate analysis and optimal coding principle. Specifically, due to the long-memory linear detection, state evolution (SE) for MAMP is intricately multidimensional and cannot be used directly to analyze its achievable rate. To avoid this difficulty, a simplified single-input single-output variational SE (VSE) for MAMP is developed by leveraging the SE fixed-point consistent property of MAMP and OAMP/VAMP. The achievable rate of MAMP is calculated using the VSE, and the optimal coding principle is established to maximize the achievable rate. On this basis, the information-theoretic optimality of MAMP is proved rigorously. Numerical results show that the finite-length performances of MAMP with practical optimized LDPC codes are 0.5-2.7 dB away from the associated constrained capacities. It is worth noting that MAMP can achieve the same performances as OAMP/VAMP with 0.4% of the time consumption for large-scale systems.
</details>
<details>
<summary>摘要</summary>
本文提出了一种基于 generalized MIMO（GMIMO）的低复杂度和信息论上优化的接收器，以解决当前无线通信中复杂的通信场景中的接收器设计问题。文章首先介绍了GMIMO的实际假设，包括庞大天线数、实用的通道编码、任意输入分布和一般右特征射影矩阵（包括劳雷igh fading和一些不合理的和相关的通道矩阵）。然后，文章证明了OAMP/VAMP接收器在GMIMO中是信息论上优化的，但它具有高复杂度。为了解决这个问题，文章提出了一种低复杂度的内存接收器（MAMP），并证明了其是信息论上优化的。文章还进一步分析了MAMP接收器的可达率分析和优化编码原则。具体来说，由于MAMP接收器的长期线性探测，其SE（状态演化）是多维度的，无法直接使用。为了避免这种困难，文章提出了基于MAMP和OAMP/VAMP的单输入单输出变ational SE（VSE）的发展，并证明了VSE的一致性。文章通过VSE来计算MAMP接收器的可达率，并确定了优化编码原则以最大化可达率。在这基础之上，文章证明了MAMP接收器的信息论上优化性。数值结果表明，MAMP接收器在实际系统中的Finite-Length性能与相关的受限容量相差0.5-2.7dB。同时，MAMP接收器可以在大规模系统中实现与OAMP/VAMP接收器相同的性能，但它的时间消耗只占OAMP/VAMP接收器的0.4%。
</details></li>
</ul>
<hr>
<h2 id="Coverage-Hole-Elimination-System-in-Industrial-Environment"><a href="#Coverage-Hole-Elimination-System-in-Industrial-Environment" class="headerlink" title="Coverage Hole Elimination System in Industrial Environment"></a>Coverage Hole Elimination System in Industrial Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.04011">http://arxiv.org/abs/2311.04011</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mervat Zarour, Shreya Tayade, Sergiy Melnyk, Hans D. Schotten</li>
<li>for: 本文提出了一种框架，用于在内部环境中识别和避免覆盖洞。</li>
<li>methods: 该框架使用支持向量机（SVM）分类模型来确定覆盖洞的位置，并构建了一个二进制覆盖洞地图，并将AGV的路径规划修改为避免被识别的覆盖洞。</li>
<li>results: 研究发现，如果知道覆盖洞的位置 ahead of time，AGV的修改后的路径可以更短并且更加优化。<details>
<summary>Abstract</summary>
The paper proposes a framework to identify and avoid the coverage hole in an indoor industry environment. We assume an edge cloud co-located controller that followers the Automated Guided Vehicle (AGV) movement on a factory floor over a wireless channel. The coverage holes are caused due to blockage, path-loss, and fading effects. An AGV in the coverage hole may lose connectivity to the edge-cloud and become unstable. To avoid connectivity loss, we proposed a framework that identifies the position of coverage hole using a Support- Vector Machine (SVM) classifier model and constructs a binary coverage hole map incorporating the AGV trajectory re-planning to avoid the identified coverage hole. The AGV's re-planned trajectory is optimized and selected to avoid coverage hole the shortest coverage-hole-free trajectory. We further investigated the look-ahead time's impact on the AGV's re-planned trajectory performance. The results reveal that an AGV's re-planned trajectory can be shorter and further optimized if the coverage hole position is known ahead of time
</details>
<details>
<summary>摘要</summary>
文章提出了一个框架，用于识别和避免室内工业环境中的覆盖孔。我们假设了位于生产工场地板上的自动调节车（AGV）运动，并跟踪它的无线通讯。孔隙是由封锁、路径损失和折射效应所导致的。如果AGV在孔隙中，它可能会失去与云端控制器的连接，并成为不稳定。为了避免连接损失，我们提出了一个框架，使用支持向量机（SVM）分类器模型，构建一个二进制的覆盖孔地图，并将AGV的路径重新规划，以避免识别的孔隙。我们进一步研究了AGV重新规划路径的时间延迟影响。结果显示，如果知道孔隙位置 ahead of time，AGV的重新规划路径可以更短且更优化。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-via-Active-RIS-Assisted-Over-the-Air-Computation"><a href="#Federated-Learning-via-Active-RIS-Assisted-Over-the-Air-Computation" class="headerlink" title="Federated Learning via Active RIS Assisted Over-the-Air Computation"></a>Federated Learning via Active RIS Assisted Over-the-Air Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03982">http://arxiv.org/abs/2311.03982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deyou Zhang, Ming Xiao, Mikael Skoglund, H. Vincent Poor</li>
<li>for: 该论文旨在利用活动可重配置知识表面 (RIS) 支持静止梯度聚合，以便在无线计算 (AirComp) 启用的联合学习 (FL) 系统中提高可靠性。</li>
<li>methods: 论文提出了对 FL 启用轮次训练轮的梯度聚合错误进行最小化，以减少收敛差距。作者们对此进行了优化问题，并提出了一种两层代替优化框架来分解它。</li>
<li>results: 实验结果表明，活动 RIS 可以比pasive RIS更好地减少梯度聚合错误，提高系统的可靠性。<details>
<summary>Abstract</summary>
In this paper, we propose leveraging the active reconfigurable intelligence surface (RIS) to support reliable gradient aggregation for over-the-air computation (AirComp) enabled federated learning (FL) systems. An analysis of the FL convergence property reveals that minimizing gradient aggregation errors in each training round is crucial for narrowing the convergence gap. As such, we formulate an optimization problem, aiming to minimize these errors by jointly optimizing the transceiver design and RIS configuration. To handle the formulated highly non-convex problem, we devise a two-layer alternative optimization framework to decompose it into several convex subproblems, each solvable optimally. Simulation results demonstrate the superiority of the active RIS in reducing gradient aggregation errors compared to its passive counterpart.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提议利用活动可重配置智能表面（RIS）支持无线计算（AirComp）启用的联合学习（FL）系统中可靠的梯度聚合。分析 federated learning 的收敛性质表明，在每次训练轮中最小化梯度聚合错误对于缩小收敛差别至关重要。因此，我们形ulated一个优化问题， aiming to minimize these errors by jointly optimizing the transceiver design and RIS configuration. To handle the formulated highly non-convex problem, we devise a two-layer alternative optimization framework to decompose it into several convex subproblems, each solvable optimally. 实验结果表明，使用活动 RIS 可以比其静态counterpart更有效地减少梯度聚合错误。
</details></li>
</ul>
<hr>
<h2 id="NOMA-Enabled-Multi-Access-Edge-Computing-A-Joint-MU-MIMO-Precoding-and-Computation-Offloading-Design"><a href="#NOMA-Enabled-Multi-Access-Edge-Computing-A-Joint-MU-MIMO-Precoding-and-Computation-Offloading-Design" class="headerlink" title="NOMA Enabled Multi-Access Edge Computing: A Joint MU-MIMO Precoding and Computation Offloading Design"></a>NOMA Enabled Multi-Access Edge Computing: A Joint MU-MIMO Precoding and Computation Offloading Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03974">http://arxiv.org/abs/2311.03974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deyou Zhang, Meng Wang, Shuo Shi, Ming Xiao</li>
<li>for: 本文研究了多个多antenna终端（MEC用户）在非正交多Access下访问MEC服务器，以减少所有MU的能量消耗，同时满足延迟约束。</li>
<li>methods: 作者首先将原问题拆分为三个子问题，然后逐步解决这些子问题，直到收敛。</li>
<li>results: 实验结果证明提出的方法的可行性和超越基线算法。<details>
<summary>Abstract</summary>
This letter investigates computation offloading and transmit precoding co-design for multi-access edge computing (MEC), where multiple MEC users (MUs) equipped with multiple antennas access the MEC server in a non-orthogonal multiple access manner. We aim to minimize the total energy consumption of all MUs while satisfying the latency constraints by jointly optimizing the computational frequency, offloading ratio, and precoding matrix of each MU. For tractability, we first decompose the original problem into three subproblems and then solve these subproblems iteratively until convergence. Simulation results validate the convergence of the proposed method and demonstrate its superiority over baseline algorithms.
</details>
<details>
<summary>摘要</summary>
这封信函数 investigate 计算卸载和传输预编码合理设计 для多接入边缘计算（MEC），其中多个MEC用户（MU）搭载多个天线访问MEC服务器，使用非正交多Access方式。我们目标是最小化所有MU的能量消耗，同时满足延迟约束，通过对各MU的计算频率、卸载率和预编码矩阵进行 JOINT 优化。为了扩展可行性，我们首先将原问题分解成三个子问题，然后逐步解决这些子问题，直至收敛。实验结果证明了我们的方法的可行性和相比基eline算法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Distributed-Parameter-Estimation-with-Gaussian-Observation-Noises-in-Time-varying-Digraphs"><a href="#Distributed-Parameter-Estimation-with-Gaussian-Observation-Noises-in-Time-varying-Digraphs" class="headerlink" title="Distributed Parameter Estimation with Gaussian Observation Noises in Time-varying Digraphs"></a>Distributed Parameter Estimation with Gaussian Observation Noises in Time-varying Digraphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03911">http://arxiv.org/abs/2311.03911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Yan, Hideaki Ishii</li>
<li>for: 这 paper 讨论了分布式参数估计问题在感知网络中。每个感知器在成功观测一个未知的 $d$-维参数后，它们想要推断出真实的参数值，通过协作来实现这一目标。</li>
<li>methods: 我们首先将动态扩展和混合（DREM）算法推广到随机系统中，将参数估计问题转化为 $d$ 个scalar问题：一个为每个未知参数。每个scalar问题都可以使用combine-then-adapt（CTA）和adapt-then-combine（ATC）扩散估计算算法，每个感知器在其几何邻域中进行combine步骤，并将流动观测进行处理。</li>
<li>results: 我们证明了提posed estimators可以使每个感知器推断出真实的参数值，即使任何个感知器无法一个。specifically, 我们需要ASSUME that the union of topologies over an interval with fixed length is strongly connected, 并且感知器们必须共同满足一个合作 persistentexcitation（PE）条件，这些条件降低了传统PE条件。numerical examples are finally provided to illustrate the established results.<details>
<summary>Abstract</summary>
In this paper, we consider the problem of distributed parameter estimation in sensor networks. Each sensor makes successive observations of an unknown $d$-dimensional parameter, which might be subject to Gaussian random noises. The sensors aim to infer the true value of the unknown parameter by cooperating with each other. To this end, we first generalize the so-called dynamic regressor extension and mixing (DREM) algorithm to stochastic systems, with which the problem of estimating a $d$-dimensional vector parameter is transformed to that of $d$ scalar ones: one for each of the unknown parameters. For each of the scalar problem, both combine-then-adapt (CTA) and adapt-then-combine (ATC) diffusion-based estimation algorithms are given, where each sensor performs a combination step to fuse the local estimates in its in-neighborhood, alongside an adaptation step to process its streaming observations. Under weak conditions on network topology and excitation of regressors, we show that the proposed estimators guarantee that each sensor infers the true parameter, even if any individual of them cannot by itself. Specifically, it is required that the union of topologies over an interval with fixed length is strongly connected. Moreover, the sensors must collectively satisfy a cooperative persistent excitation (PE) condition, which relaxes the traditional PE condition. Numerical examples are finally provided to illustrate the established results.
</details>
<details>
<summary>摘要</summary>
在本文中，我们考虑了分布式参数估计问题在感知网络中。每个感知器在不知道的 $d$-维参数上进行连续观测，这个参数可能受到 Gaussian 随机噪声的影响。感知器们想要推断真实的参数值，通过合作来实现这一目标。为此，我们首先将动态扩展和混合（DREM）算法推广到随机系统中，将参数估计问题转化为 $d$ 个整数估计问题。每个整数估计问题中，我们提供了 combine-then-adapt（CTA）和 adapt-then-combine（ATC）扩散式估计算法，其中每个感知器在其内部邻域中进行组合步骤，并且进行适应步骤来处理其流动观测。在网络拓扑和刺激器的弱条件下，我们证明了我们的估计算法可以使每个感知器推断真实的参数，即使任何一个感知器都无法做到。具体地说，需要的是union of topologies在固定长度的间隔内是强连接的。此外，感知器们必须共同满足一个协operative persistent excitation（PE）条件，这种条件相对于传统PE条件更加宽松。最后，我们提供了数字示例，以 illustrate the established results。
</details></li>
</ul>
<hr>
<h2 id="Integrated-Sensing-Communication-and-Computing-for-Cost-effective-Multimodal-Federated-Perception"><a href="#Integrated-Sensing-Communication-and-Computing-for-Cost-effective-Multimodal-Federated-Perception" class="headerlink" title="Integrated Sensing, Communication, and Computing for Cost-effective Multimodal Federated Perception"></a>Integrated Sensing, Communication, and Computing for Cost-effective Multimodal Federated Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03815">http://arxiv.org/abs/2311.03815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ning Chen, Zhipeng Cheng, Xuwei Fan, Bangzhen Huang, Yifeng Zhao, Lianfen Huang, Xiaojiang Du, Mohsen Guizani</li>
<li>for: 本文研究了基于多Modal Federated Perception（MFP）服务的edge智能（EI）中的资源管理问题，以提高学习性能和降低资源成本。</li>
<li>methods: 本文提出了一种基于整合感知通信和计算（ISCC）的服务导向资源管理策略，利用MFP服务市场的奖励机制来解决资源管理问题，并通过“扩展资源”和“降低成本”的想法来提高学习性能和降低资源成本。</li>
<li>results: 实验结果表明，提出的资源调度策略具有效果和稳定性，能够有效地提高学习性能和降低资源成本。<details>
<summary>Abstract</summary>
Federated learning (FL) is a classic paradigm of 6G edge intelligence (EI), which alleviates privacy leaks and high communication pressure caused by traditional centralized data processing in the artificial intelligence of things (AIoT). The implementation of multimodal federated perception (MFP) services involves three sub-processes, including sensing-based multimodal data generation, communication-based model transmission, and computing-based model training, ultimately relying on available underlying multi-domain physical resources such as time, frequency, and computing power. How to reasonably coordinate the multi-domain resources scheduling among sensing, communication, and computing, therefore, is crucial to the MFP networks. To address the above issues, this paper investigates service-oriented resource management with integrated sensing, communication, and computing (ISCC). With the incentive mechanism of the MFP service market, the resources management problem is redefined as a social welfare maximization problem, where the idea of "expanding resources" and "reducing costs" is used to improve learning performance gain and reduce resource costs. Experimental results demonstrate the effectiveness and robustness of the proposed resource scheduling mechanisms.
</details>
<details>
<summary>摘要</summary>
六代智能edge智能（EI）的经典模式是 federated learning（FL），它解决了传统中央数据处理所引起的隐私泄露和高通信压力问题。 MFP 服务的实施包括三个子过程：感知基于多模态数据生成、通信基于模型传输和计算基于模型训练。 ultimately, it relies on the available underlying multi-domain physical resources such as time, frequency, and computing power. 因此，合理协调多域资源调度成为 MFP 网络的关键。为解决这些问题，这篇论文调查了 integrate sensing, communication, and computing （ISCC） 的服务 ориентирован资源管理。通过 MFP 服务市场的奖励机制，资源管理问题被重新定义为社会福祉最大化问题，其中“扩展资源”和“降低成本”的想法用于提高学习效率和降低资源成本。实验结果表明提案的资源调度机制的效果和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Textile-based-conformable-and-breathable-ultrasound-imaging-probe"><a href="#Textile-based-conformable-and-breathable-ultrasound-imaging-probe" class="headerlink" title="Textile-based conformable and breathable ultrasound imaging probe"></a>Textile-based conformable and breathable ultrasound imaging probe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03787">http://arxiv.org/abs/2311.03787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takumi Noda, Seiichi Takamatsu, Michitaka Yamamoto, Naoto Tomita, Toshihiro Itoh, Takashi Azuma, Ichiro Sakuma, Naoki Tomii</li>
<li>for: 这个研究旨在开发一种可以在穿着的衣物上进行内部组织的日常监测，以早期探测疾病。</li>
<li>methods: 研究人员使用了纺织品作为试验材料，并在纺织品上形成了阴极和阳极电极。在电极部分，将空气孔填充了铜，以增加超音波波长的吸收。</li>
<li>results: 研究人员发现了一种可以实现高度弹性和呼吸性的试验材料，并在人类颈部进行了实验，证明了这种探针可以实现日常监测内部组织的健康状况，例如arteriosclerosis和脱水。<details>
<summary>Abstract</summary>
Daily monitoring of internal tissues with conformable and breathable ultrasound (US) imaging probes is promising for early detection of diseases. In recent years, textile substrates are widely used for wearable devices since they satisfy both conformability and breathability. However, it is not currently possible to use textile substrates for US probes due to the reflection or attenuation of US waves at the air gaps in the textiles. In this paper, we fabricated a conformable and breathable US imaging probe by sandwiching the US elements between two woven polyester textiles on which copper electrodes were formed through electroless plating. The air gaps between the fibers at the electrode parts were filled with copper, allowing for high penetration of US waves. On the other hand, the non-electrode parts retain air gaps, leading to high breathability. The fabricated textile-based probe showed low flexural rigidity ($0.066 \times 10^{-4} N \cdot m^2/m$) and high air permeability ($11.7 cm^3 / cm^2 \cdot s$). Human neck imaging demonstrated the ability of the probe to monitor the pulsation of the common carotid artery and change in the internal jugular vein diameter, which lead to the early detection of health issues such as arteriosclerosis and dehydration.
</details>
<details>
<summary>摘要</summary>
每天监测内部组织的柔软呼吸ultrasound（US）成像探测器是有前途的，可早期检测疾病。近年来，纺织品substrate被广泛应用于可穿戴设备，因为它们满足了柔软性和呼吸性。然而，当前不可以使用纺织品substrate来制作US成像探测器，因为US波在纺织品上反射或吸收。本文报道了一种柔软呼吸US成像探测器，通过将US元素间隔在两块织有电镀铜的Polyester纺织品上，并具有较低的折弯刚性($0.066 \times 10^{-4} N \cdot m^2/m$)和高空气通透率($11.7 cm^3 / cm^2 \cdot s）。人颈成像示示了该探测器可以监测内颈动脉和内 jugular vein diameter的变化，从而早期发现了健康问题，如arteriosclerosis和脱水。
</details></li>
</ul>
<hr>
<h2 id="Multi-Beam-Forming-with-Movable-Antenna-Array"><a href="#Multi-Beam-Forming-with-Movable-Antenna-Array" class="headerlink" title="Multi-Beam Forming with Movable-Antenna Array"></a>Multi-Beam Forming with Movable-Antenna Array</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03775">http://arxiv.org/abs/2311.03775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenyan Ma, Lipeng Zhu, Rui Zhang</li>
<li>for: 提高多束发射的性能和干扰抑制性</li>
<li>methods: 利用antenna位置优化和天线量重要优化来协调多束发射的指向性和干扰抑制性</li>
<li>results: 比traditional FPA数组和其他参考方案要出色地提高多束发射的性能和干扰抑制性<details>
<summary>Abstract</summary>
Conventional multi-beam forming with fixed-position antenna (FPA) arrays needs to trade-off between maximizing the beamforming gain over desired directions and minimizing the interference power over undesired directions. In this letter, we study the enhanced multi-beam forming with a linear movable-antenna (MA) array by exploiting the new degrees of freedom (DoFs) via antennas' position optimization. Specifically, we jointly optimize the antenna position vector (APV) and antenna weight vector (AWV) to maximize the minimum beamforming gain over multiple desired directions, subject to a given constraint on the maximum interference power over undesired directions. We propose an efficient alternating optimization algorithm to find a suboptimal solution by iteratively optimizing one of the APV and AWV with the other being fixed. Numerical results show that the proposed multi-beam forming design with MA arrays can significantly outperform that with the traditional FPA arrays and other benchmark schemes in terms of both beamforming gain and interference suppression.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Classification-of-Various-Types-of-Damages-in-Honeycomb-Composite-Sandwich-Structures-using-Guided-Wave-Structural-Health-Monitoring"><a href="#Classification-of-Various-Types-of-Damages-in-Honeycomb-Composite-Sandwich-Structures-using-Guided-Wave-Structural-Health-Monitoring" class="headerlink" title="Classification of Various Types of Damages in Honeycomb Composite Sandwich Structures using Guided Wave Structural Health Monitoring"></a>Classification of Various Types of Damages in Honeycomb Composite Sandwich Structures using Guided Wave Structural Health Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03765">http://arxiv.org/abs/2311.03765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shruti Sawant, Jeslin Thalapil, Siddharth Tallur, Sauvik Banerjee, Amit Sethi</li>
<li>for: 本研究旨在为HCSS（叠层composite材料结构）中的损害分类提供数学模型，以便根据不同类型的损害进行维护措施。</li>
<li>methods: 本研究使用了精心的特征工程和机器学习技术，可以分类不同类型的损害，包括核心压缩（CC）、高密度核心（HDC）、丢失涂层黏合（LFA）和聚四氟乙烯释放膜（TRF）。</li>
<li>results: 研究发现，两种损害类型对GW信号具有相似的影响，并提取了多种时频域特征，并使用了基线信号和基线free的特征。使用基线信号计算的特征更有效。使用优化的特征集和Random Forest分类器，实现了高精度。<details>
<summary>Abstract</summary>
Classification of damages in honeycomb composite sandwich structure (HCSS) is important to decide remedial actions. However, previous studies have only detected damages using deviations of monitoring signal from healthy (baseline) using a guided wave (GW) based structural health monitoring system. Classification between various types of damages has not been reported for challenging cases. We show that using careful feature engineering and machine learning it is possible to classify between various types of damages such as core crush (CC), high density core (HDC), lost film adhesive (LFA) and teflon release film (TRF). We believe that we are the first to report numerical models for four types of damages in HCSS, which is followed up with experimental validation. We found that two out of four damages affect the GW signal in a particularly similar manner. We extracted and evaluated multiple features from time as well as frequency domains, and also experimented with features relative to as baseline as well as those that were baseline-free. Using Pearson's correlation coefficient based filtering, redundant features were eliminated. Finally, using an optimal feature set determined using feature elimination, high accuracy was achieved with a random forest classifier on held-out signals. For evaluating performance of the proposed method for different damage sizes, we used simulated data obtained from extensive parametric studies and got an accuracy of 77.89%. Interpretability studies to determine importance of various features showed that features computed using the baseline signal prove more effective as compared to baseline-free features.
</details>
<details>
<summary>摘要</summary>
classe= "zh-tw" >HCSS中的损害分类是重要的，以确定维修措施。然而，先前的研究仅通过GW系统中的干扰信号偏差来检测损害。在复杂情况下，不同类型的损害的分类没有被报道。我们表明，通过细心的特征工程和机器学习，可以将不同类型的损害分为四类，包括核心压碎（CC）、高密度核心（HDC）、lost film adhesive（LFA）和TEFLON Release Film（TRF）。我们认为是首次对HCSS中四种损害的数学模型进行了数字化表述，然后进行了实验验证。我们发现了两种损害在GW信号上的特征相似性。我们从时域和频域中提取了多个特征，并试用了相对于基线和无基线的特征。使用基eline阈值为基础的 correlation coefficient 筛选， redundant 特征被消除。最后，使用最佳特征集，使用Random Forest分类器在封闭信号上达到了高精度。为了评估提案方法的不同损害大小下的性能，我们使用了广泛的参数研究所获得的数据，并达到了77.89%的准确率。 interpretability 研究表明，基于基线信号的特征更有效于基于无基线特征。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Traditional-Beamforming-Singular-Vector-Projection-Techniques-for-MU-MIMO-Interference-Management"><a href="#Beyond-Traditional-Beamforming-Singular-Vector-Projection-Techniques-for-MU-MIMO-Interference-Management" class="headerlink" title="Beyond Traditional Beamforming: Singular Vector Projection Techniques for MU-MIMO Interference Management"></a>Beyond Traditional Beamforming: Singular Vector Projection Techniques for MU-MIMO Interference Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03741">http://arxiv.org/abs/2311.03741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Saheed Ullah, Rafid Umayer Murshed, Md. Forkan Uddin</li>
<li>for: 这个论文旨在提出一种低复杂度扩 beamforming算法，以减少多用户多输入多输出（MU-MIMO）系统中的交叉用户干扰，提高spectral efficiency（SE）。</li>
<li>methods: 论文首先提出了一种基于 singular vector beamspace search（SVBS）算法的低复杂度扩 beamforming方法，其中所有的特征向量都被评估，以确定最佳扩 beamforming方案。然后，我们提出了一种基于mutual projections的数学证明，以计算多用户MIMO扩 beamforming系统中的总交叉干扰。</li>
<li>results: 计算结果表明，SVBS算法比现有的算法更高效，而interference-optimized SVBS（IOSVB）算法可以减少计算复杂度，而dimensionality-reduced IOSVB（DR-IOSVB）算法可以平衡性能和计算复杂度。这些结果证明了这种新的扩 beamforming算法的优越性，并成为MU-MIMO无线通信系统中的新标准。<details>
<summary>Abstract</summary>
This paper introduces low-complexity beamforming algorithms for multi-user multiple-input multiple-output (MU-MIMO) systems to minimize inter-user interference and enhance spectral efficiency (SE). A Singular-Vector Beamspace Search (SVBS) algorithm is initially presented, wherein all the singular vectors are assessed to determine the most effective beamforming scheme. We then establish a mathematical proof demonstrating that the total inter-user interference of a MU-MIMO beamforming system can be efficiently calculated from the mutual projections of orthonormal singular vectors. Capitalizing on this, we present an Interference-optimized Singular Vector Beamforming (IOSVB) algorithm for optimal singular vector selection. For further reducing the computational burden, we propose a Dimensionality-reduced IOSVB (DR-IOSVB) algorithm by integrating the principal component analysis (PCA). The numerical results demonstrate the superiority of the SVBS algorithm over the existing algorithms, with the IOSVB offering near-identical SE and the DR-IOSVB balancing the performance and computational efficiency. This work establishes a new benchmark for high-performance and low-complexity beamforming in MU-MIMO wireless communication systems.
</details>
<details>
<summary>摘要</summary>
To further reduce computational complexity, we propose an Interference-optimized Singular Vector Beamforming (IOSVB) algorithm that optimizes singular vector selection. We also introduce a Dimensionality-reduced IOSVB (DR-IOSVB) algorithm that integrates principal component analysis (PCA) to reduce the dimensionality of the problem.Numerical results show that the SVBS algorithm outperforms existing algorithms, while the IOSVB and DR-IOSVB algorithms offer near-identical SE with reduced computational complexity. Our work establishes a new benchmark for high-performance and low-complexity beamforming in MU-MIMO wireless communication systems.
</details></li>
</ul>
<hr>
<h2 id="Recursive-Filters-as-Linear-Time-Invariant-Systems"><a href="#Recursive-Filters-as-Linear-Time-Invariant-Systems" class="headerlink" title="Recursive Filters as Linear Time-Invariant Systems"></a>Recursive Filters as Linear Time-Invariant Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03676">http://arxiv.org/abs/2311.03676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan H. Manton</li>
<li>for: 这篇论文的目的是解释如何将复杂的滤波器视为线性时间不变（LTI）系统，以便应用 FOURIER分析等工具。</li>
<li>methods: 论文使用了 z-transform 来将滤波器转换为 LTI 系统，并讨论了这种转换的原理和限制。</li>
<li>results: 论文表明了如何使用 z-transform 来找到滤波器的解，并解释了为什么 z-transform 不能找到无数个解。<details>
<summary>Abstract</summary>
Recursive filters are treated as linear time-invariant (LTI) systems but they are not: uninitialised, they have an infinite number of outputs for any given input, while if initialised, they are not time-invariant. This short tutorial article explains how and why they can be treated as LTI systems, thereby allowing tools such as Fourier analysis to be applied. It also explains the origin of the z-transform, why the region of convergence is important, and why the z-transform fails to find an infinite number of solutions.
</details>
<details>
<summary>摘要</summary>
Recursive filters 是被视为线性时�variance（LTI）系统，但实际上不是：未初始化的情况下，它们有无限多个输出对于任何输入，而如果初始化，它们不是时射变的。这篇简短的教程文章解释了如何并为什么可以将它们视为 LTI 系统，从而使得 fourier 分析等工具可以应用。它还解释了 z-transform 的起源，区域确定性的重要性，以及为什么 z-transform 无法找到无限多个解。
</details></li>
</ul>
<hr>
<h2 id="On-the-Performance-of-LoRa-Empowered-Communication-for-Wireless-Body-Area-Networks"><a href="#On-the-Performance-of-LoRa-Empowered-Communication-for-Wireless-Body-Area-Networks" class="headerlink" title="On the Performance of LoRa Empowered Communication for Wireless Body Area Networks"></a>On the Performance of LoRa Empowered Communication for Wireless Body Area Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03653">http://arxiv.org/abs/2311.03653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minling Zhang, Guofa Cai, Zhiping Xu, Jiguang He, Markku Juntti</li>
<li>for: 这篇论文主要是研究LoRa技术在人体域网络中的应用和性能。</li>
<li>methods: 该论文使用了LoRa技术，并对其在Rayleigh-lognormal折射渠道下的性能进行了分析。</li>
<li>results: 研究结果显示，增加SF和降低干扰可以有效地减少阴影效应。此外，对LoRa基于WBAN的三种MAC协议进行了分析，并对等间隔和等面积的方案进行了分析，以帮助选择合适的SF。<details>
<summary>Abstract</summary>
To remotely monitor the physiological status of the human body, long range (LoRa) communication has been considered as an eminently suitable candidate for wireless body area networks (WBANs). Typically, a Rayleigh-lognormal fading channel is encountered by the LoRa links of the WBAN. In this context, we characterize the performance of the LoRa system in WBAN scenarios with an emphasis on the physical (PHY) layer and medium access control (MAC) layer in the face of Rayleigh-lognormal fading channels and the same spreading factor interference. Specifically, closed-form approximate bit error probability (BEP) expressions are derived for the LoRa system. The results show that increasing the SF and reducing the interference efficiently mitigate the shadowing effects. Moreover, in the quest for the most suitable MAC protocol for LoRa based WBANs, three MAC protocols are critically appraised, namely the pure ALOHA, slotted ALOHA, and carrier-sense multiple access. The coverage probability, energy efficiency, throughput, and system delay of the three MAC protocols are analyzed in Rayleigh-lognormal fading channel. Furthermore, the performance of the equal-interval-based and equal-area-based schemes is analyzed to guide the choice of the SF. Our simulation results confirm the accuracy of the mathematical analysis and provide some useful insights for the future design of LoRa based WBANs.
</details>
<details>
<summary>摘要</summary>
为了远程监测人体生理状况，长距离（LoRa）通信被视为适用于无线体积网络（WBAN）的优秀候选人。通常，LoRa链路会遇到很多很强的征 Rayleigh-lognormal 折射渐减频率扰动（SF）。在这种情况下，我们对LoRa系统在WBAN场景中的性能进行了分析，强调物理层（PHY）和物理层控制层（MAC）层。我们 derivated closed-formapproximate bit error probability（BEP）表达式，并证明了增加SF和减少干扰可以减少阴影效应。此外，为了选择最适合LoRa基于WBAN的MAC协议，我们 kritisch analyzed three MAC协议， namely pure ALOHA, slotted ALOHA, and carrier-sense multiple access。我们分析了这三种MAC协议在Rayleigh-lognormal折射渐减频率通道中的覆盖率、能效率、吞吐量和系统延迟。此外，我们还分析了等间隔基于和等面积基于的SF选择方案，以便为LoRa基于WBAN的设计提供指南。我们的Simulation结果证明了我们的数学分析的准确性，并提供了一些有用的洞察。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/07/eess.SP_2023_11_07/" data-id="cloqtaf3k01cygh88ebnt7ll2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.SD_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T15:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.SD_2023_11_06/">cs.SD - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Combinatorial-Hodge-Theory-in-Simplicial-Signal-Processing-–-DAFx2023-Lecture-Notes"><a href="#Combinatorial-Hodge-Theory-in-Simplicial-Signal-Processing-–-DAFx2023-Lecture-Notes" class="headerlink" title="Combinatorial Hodge Theory in Simplicial Signal Processing – DAFx2023 Lecture Notes"></a>Combinatorial Hodge Theory in Simplicial Signal Processing – DAFx2023 Lecture Notes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03469">http://arxiv.org/abs/2311.03469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Essl</li>
<li>for: 本研讨会讲述了在 simplicial signal processing 中应用 combinatorial hodge theory 的tutorial。</li>
<li>methods: 本研究使用了 combinatorial hodge theory 来解决 simplicial signal processing 中的一些问题。</li>
<li>results: 本研究得到了一些有趣的结果，如�loyment of combinatorial hodge theory 可以帮助解决 simplicial signal processing 中的一些问题。Here’s the same information in Simplified Chinese:</li>
<li>for: 本研讨会讲述了在 simplicial signal processing 中应用 combinatorial hodge theory 的 tutorial。</li>
<li>methods: 本研究使用了 combinatorial hodge theory 来解决 simplicial signal processing 中的一些问题。</li>
<li>results: 本研究得到了一些有趣的结果，如 employment of combinatorial hodge theory 可以帮助解决 simplicial signal processing 中的一些问题。<details>
<summary>Abstract</summary>
Lecture notes of a tutorial on Combinatorial Hodge Theory in Simplicial Signal Processing held at international conference for digital audio effects (DAFx-23) in Copenhagen, Denmark.
</details>
<details>
<summary>摘要</summary>
lecture notes of a tutorial on Combinatorial Hodge Theory in Simplicial Signal Processing held at international conference for digital audio effects (DAFx-23) in Copenhagen, Denmark.Translation:达夫x-23国际音频特效会议上的一场 tutorials on Combinatorial Hodge Theory in Simplicial Signal Processing的笔记。
</details></li>
</ul>
<hr>
<h2 id="A-Foundation-Model-for-Music-Informatics"><a href="#A-Foundation-Model-for-Music-Informatics" class="headerlink" title="A Foundation Model for Music Informatics"></a>A Foundation Model for Music Informatics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03318">http://arxiv.org/abs/2311.03318</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minzwon/musicfm">https://github.com/minzwon/musicfm</a></li>
<li>paper_authors: Minz Won, Yun-Ning Hung, Duc Le</li>
<li>for: 本研究探讨适用于音乐信息学领域的基础模型，该领域受到数据缺乏和泛化问题的困扰。</li>
<li>methods: 我们对不同基础模型变体进行了深入比较研究，检验了关键因素 such as 模型架构、tokenization方法、时间分辨率、数据和模型扩展性。</li>
<li>results: 我们的研究发现，我们的模型在多种音乐信息检索下表现出色，在特定的密钥指标上超越现有模型。这些发现对自动学习在音乐信息学领域的理解做出了贡献，并为开发更有效和多样化的基础模型提供了道路。一个预训练版本的我们模型公开可用，以促进可重现和未来研究。<details>
<summary>Abstract</summary>
This paper investigates foundation models tailored for music informatics, a domain currently challenged by the scarcity of labeled data and generalization issues. To this end, we conduct an in-depth comparative study among various foundation model variants, examining key determinants such as model architectures, tokenization methods, temporal resolution, data, and model scalability. This research aims to bridge the existing knowledge gap by elucidating how these individual factors contribute to the success of foundation models in music informatics. Employing a careful evaluation framework, we assess the performance of these models across diverse downstream tasks in music information retrieval, with a particular focus on token-level and sequence-level classification. Our results reveal that our model demonstrates robust performance, surpassing existing models in specific key metrics. These findings contribute to the understanding of self-supervised learning in music informatics and pave the way for developing more effective and versatile foundation models in the field. A pretrained version of our model is publicly available to foster reproducibility and future research.
</details>
<details>
<summary>摘要</summary>
We employ a rigorous evaluation framework to assess the performance of these models across a range of downstream tasks in music information retrieval, with a particular focus on token-level and sequence-level classification. Our results show that our model demonstrates robust performance, outperforming existing models in specific key metrics. These findings contribute to our understanding of self-supervised learning in music informatics and pave the way for the development of more effective and versatile foundation models in the field. A pretrained version of our model is publicly available to facilitate reproducibility and future research.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.SD_2023_11_06/" data-id="cloqtaex800z5gh88eydeejpa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/eess.AS_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T14:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/eess.AS_2023_11_06/">eess.AS - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="HRTF-Estimation-in-the-Wild"><a href="#HRTF-Estimation-in-the-Wild" class="headerlink" title="HRTF Estimation in the Wild"></a>HRTF Estimation in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03560">http://arxiv.org/abs/2311.03560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vivek Jayaram, Ira Kemelmacher-Shlizerman, Steven M. Seitz</li>
<li>for: 用于创造充满听觉的听 spatial audio 经验</li>
<li>methods: 使用听觉环境中的耳buds 采集数据和头跟踪数据来估算个人化 HRTF</li>
<li>results: 比较 closely match 地测量在静音室中的真实 HRTF，并且 listening 研究表明个人化 HRTF 可以大幅提高虚拟环境中的声音localization 和 front-back 混淆 reduction<details>
<summary>Abstract</summary>
Head Related Transfer Functions (HRTFs) play a crucial role in creating immersive spatial audio experiences. However, HRTFs differ significantly from person to person, and traditional methods for estimating personalized HRTFs are expensive, time-consuming, and require specialized equipment. We imagine a world where your personalized HRTF can be determined by capturing data through earbuds in everyday environments. In this paper, we propose a novel approach for deriving personalized HRTFs that only relies on in-the-wild binaural recordings and head tracking data. By analyzing how sounds change as the user rotates their head through different environments with different noise sources, we can accurately estimate their personalized HRTF. Our results show that our predicted HRTFs closely match ground-truth HRTFs measured in an anechoic chamber. Furthermore, listening studies demonstrate that our personalized HRTFs significantly improve sound localization and reduce front-back confusion in virtual environments. Our approach offers an efficient and accessible method for deriving personalized HRTFs and has the potential to greatly improve spatial audio experiences.
</details>
<details>
<summary>摘要</summary>
head-related transfer functions (HRTFs) 是创造充满现实感的空间声音体验中的关键因素。然而，HRTFs 间人之间存在显著差异，传统的个人化 HRTFs 估算方法是成本高昂、时间费时、需要特殊设备的。我们想象一个世界，在日常环境中使用耳机记录数据来定制个人 HRTF。在这篇论文中，我们提出了一种新的个人化 HRTFs 估算方法，只需要在实际环境中采集听觉记录和头部跟踪数据。通过分析用户在不同环境中旋转头部时如何改变声音，我们可以准确地估算个人化 HRTF。我们的结果表明，我们预测的 HRTFs 与实际室内阻尼室中测量的 HRTFs 高度相似。此外，我们的个人化 HRTFs 在虚拟环境中提高声音定位和降低前后混乱，Listening 研究表明。我们的方法可以高效、可 accessible 地实现个人化 HRTFs，并且具有改善空间声音体验的潜在潜力。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/eess.AS_2023_11_06/" data-id="cloqtaeyx012lgh884co1dyq9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/06/cs.CV_2023_11_06/" class="article-date">
  <time datetime="2023-11-06T13:00:00.000Z" itemprop="datePublished">2023-11-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/06/cs.CV_2023_11_06/">cs.CV - 2023-11-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unsupervised-Region-Growing-Network-for-Object-Segmentation-in-Atmospheric-Turbulence"><a href="#Unsupervised-Region-Growing-Network-for-Object-Segmentation-in-Atmospheric-Turbulence" class="headerlink" title="Unsupervised Region-Growing Network for Object Segmentation in Atmospheric Turbulence"></a>Unsupervised Region-Growing Network for Object Segmentation in Atmospheric Turbulence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03572">http://arxiv.org/abs/2311.03572</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dehao Qin, Ripon Saha, Suren Jayasuriya, Jinwei Ye, Nianyi Li</li>
<li>for: 这篇论文旨在提出一个不需要训练数据的二阶段无监督前景物分类网络，用于应对受到大气抖扰影响的动态场景中的前景物分类。</li>
<li>methods: 这篇论文使用了均值运动流的数据来验证一个新的区域生长算法，将每个影像序列中的移动物体构成为先验的mask。然后，这些mask会被用来训练一个U-Net架构，以进一步精确化这些mask的空间时间Alignment。</li>
<li>results: 这篇论文的方法在新的动态场景中的前景物分类 зада问中证明了superior的准确性和Robustness，并且可以运行在不同的抖扰强度下，并且可以跨越不同的训练数据。<details>
<summary>Abstract</summary>
In this paper, we present a two-stage unsupervised foreground object segmentation network tailored for dynamic scenes affected by atmospheric turbulence. In the first stage, we utilize averaged optical flow from turbulence-distorted image sequences to feed a novel region-growing algorithm, crafting preliminary masks for each moving object in the video. In the second stage, we employ a U-Net architecture with consistency and grouping losses to further refine these masks optimizing their spatio-temporal alignment. Our approach does not require labeled training data and works across varied turbulence strengths for long-range video. Furthermore, we release the first moving object segmentation dataset of turbulence-affected videos, complete with manually annotated ground truth masks. Our method, evaluated on this new dataset, demonstrates superior segmentation accuracy and robustness as compared to current state-of-the-art unsupervised methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种适用于气象干扰影像序列的两stage无监督前景 объек 分割网络。在第一stage中，我们利用气象干扰扭曲图像序列的平均运动流场来驱动一种新的区域增长算法，生成每个视频中的移动对象预制掩码。在第二stage中，我们使用U-Net架构，并添加一致性和分组损失来进一步纠正这些掩码，以便在视频中实现更好的空间时间Alignment。我们的方法不需要标注训练数据，并在不同的气象强度下工作，可以处理长距离视频。此外，我们发布了第一个受气象干扰影像序列影响的移动对象分割数据集，该数据集包括手动标注的真实掩码标准。我们的方法在这个新数据集上进行评估，与当前无监督方法相比，示出了更高的分割精度和Robustness。
</details></li>
</ul>
<hr>
<h2 id="Cal-DETR-Calibrated-Detection-Transformer"><a href="#Cal-DETR-Calibrated-Detection-Transformer" class="headerlink" title="Cal-DETR: Calibrated Detection Transformer"></a>Cal-DETR: Calibrated Detection Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03570">http://arxiv.org/abs/2311.03570</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhtarvision/cal-detr">https://github.com/akhtarvision/cal-detr</a></li>
<li>paper_authors: Muhammad Akhtar Munir, Salman Khan, Muhammad Haris Khan, Mohsen Ali, Fahad Shahbaz Khan</li>
<li>for: 这个研究的目的是为了将深度神经网络（DNNs）训练为更加正确的物体检测器。</li>
<li>methods: 这个研究使用了训练时间calibration（Cal-DETR） Mechanism，包括量化uncertainty、 uncertainty-guided logit modulation和logit mixing等方法，以提高物体检测器的准确性。</li>
<li>results: 实验结果显示，Cal-DETR可以对内部和外部预测进行准确的调整，同时维持或以上改善物体检测器的检测性能。<details>
<summary>Abstract</summary>
Albeit revealing impressive predictive performance for several computer vision tasks, deep neural networks (DNNs) are prone to making overconfident predictions. This limits the adoption and wider utilization of DNNs in many safety-critical applications. There have been recent efforts toward calibrating DNNs, however, almost all of them focus on the classification task. Surprisingly, very little attention has been devoted to calibrating modern DNN-based object detectors, especially detection transformers, which have recently demonstrated promising detection performance and are influential in many decision-making systems. In this work, we address the problem by proposing a mechanism for calibrated detection transformers (Cal-DETR), particularly for Deformable-DETR, UP-DETR and DINO. We pursue the train-time calibration route and make the following contributions. First, we propose a simple yet effective approach for quantifying uncertainty in transformer-based object detectors. Second, we develop an uncertainty-guided logit modulation mechanism that leverages the uncertainty to modulate the class logits. Third, we develop a logit mixing approach that acts as a regularizer with detection-specific losses and is also complementary to the uncertainty-guided logit modulation technique to further improve the calibration performance. Lastly, we conduct extensive experiments across three in-domain and four out-domain scenarios. Results corroborate the effectiveness of Cal-DETR against the competing train-time methods in calibrating both in-domain and out-domain detections while maintaining or even improving the detection performance. Our codebase and pre-trained models can be accessed at \url{https://github.com/akhtarvision/cal-detr}.
</details>
<details>
<summary>摘要</summary>
尽管深度神经网络（DNN）在计算机视觉任务上表现出了卓越的预测能力，但它们又容易出现过于自信的预测问题。这限制了DNN在一些安全关键应用程序中的应用和利用。随着这些应用的广泛使用，对DNN的准确性和可靠性的需求也在不断增长。在这种情况下，我们提出了一种名为Cal-DETR的机制，用于calibrating modern DNN-based object detectors，特别是Deformable-DETR、UP-DETR和DINO。我们采用了训练时calibration的路径，并在这里提供了以下贡献：首先，我们提出了一种简单 yet effective的方法来评估转换器基本对象检测器的uncertainty。其次，我们开发了一种基于uncertainty的logit模ulation机制，可以利用uncertainty来修改类logits。最后，我们开发了一种logit混合approach，可以作为一种权重补做和检测特有的损失函数，并且与uncertainty-guided logit modulation技术相结合，以进一步提高准确性表现。我们在三个域内和四个外域场景进行了广泛的实验。结果证明，Cal-DETR在与竞争的训练时calibration方法相比，可以更好地准确地调整域内和外域检测。我们的代码基和预训练模型可以在 GitHub上获取，地址为 \url{https://github.com/akhtarvision/cal-detr}.
</details></li>
</ul>
<hr>
<h2 id="Sea-You-Later-Metadata-Guided-Long-Term-Re-Identification-for-UAV-Based-Multi-Object-Tracking"><a href="#Sea-You-Later-Metadata-Guided-Long-Term-Re-Identification-for-UAV-Based-Multi-Object-Tracking" class="headerlink" title="Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based Multi-Object Tracking"></a>Sea You Later: Metadata-Guided Long-Term Re-Identification for UAV-Based Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03561">http://arxiv.org/abs/2311.03561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng-Yen Yang, Hsiang-Wei Huang, Zhongyu Jiang, Heng-Cheng Kuo, Jie Mei, Chung-I Huang, Jenq-Neng Hwang</li>
<li>for: 这篇论文主要针对的是用于无人机上的多对目标跟踪（MOT）问题，具体来说是在海上环境中实现稍微检测（ReID）的问题。</li>
<li>methods: 该论文提出了一种适应性 metadata 导航 MOT 算法（MG-MOT），该算法可以将短期跟踪数据融合成一个可靠的长期跟踪数据，并且利用无人机的 GPS 位置、飞行高度和摄像头方向等metadata来帮助实现更好的跟踪效果。</li>
<li>results: 经验表明，该算法在使用 SeaDroneSee 跟踪数据集进行测试时可以 дости得到比较出色的性能，其中 HOTA 达到了 69.5%，IDF1 达到了 85.9%。<details>
<summary>Abstract</summary>
Re-identification (ReID) in multi-object tracking (MOT) for UAVs in maritime computer vision has been challenging for several reasons. More specifically, short-term re-identification (ReID) is difficult due to the nature of the characteristics of small targets and the sudden movement of the drone's gimbal. Long-term ReID suffers from the lack of useful appearance diversity. In response to these challenges, we present an adaptable motion-based MOT algorithm, called Metadata Guided MOT (MG-MOT). This algorithm effectively merges short-term tracking data into coherent long-term tracks, harnessing crucial metadata from UAVs, including GPS position, drone altitude, and camera orientations. Extensive experiments are conducted to validate the efficacy of our MOT algorithm. Utilizing the challenging SeaDroneSee tracking dataset, which encompasses the aforementioned scenarios, we achieve a much-improved performance in the latest edition of the UAV-based Maritime Object Tracking Challenge with a state-of-the-art HOTA of 69.5% and an IDF1 of 85.9% on the testing split.
</details>
<details>
<summary>摘要</summary>
多bject tracking (MOT) for UAVs in maritime computer vision 是一个挑战性的问题，主要是短期重标识 (ReID) 和长期重标识 (ReID) 均存在挑战。特别是，短期ReID 困难由小目标特征的自然特性和飞机摄像头的突然运动所带来。而长期ReID 则受到有用的外观多样性的缺乏的影响。为了应对这些挑战，我们提出了适应性的运动基于MOT算法，称为Metadata驱动MOT（MG-MOT）。这种算法能够将短期跟踪数据与合理的长期跟踪轨迹相结合，利用飞机的GPS位置、高度和摄像头方向等重要metadata。我们对这种MOT算法进行了广泛的实验，以验证其效果。使用 SeaDroneSee 跟踪数据集，该数据集包括以上所述的场景，我们在最新的UAV-based Maritime Object Tracking Challenge中取得了很好的表现，其中HOTA为69.5%，IDF1为85.9%。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Similarity-Measure-based-Multi-Task-Learning-for-Predicting-Alzheimer’s-Disease-Progression-using-MRI-Data"><a href="#Spatio-Temporal-Similarity-Measure-based-Multi-Task-Learning-for-Predicting-Alzheimer’s-Disease-Progression-using-MRI-Data" class="headerlink" title="Spatio-Temporal Similarity Measure based Multi-Task Learning for Predicting Alzheimer’s Disease Progression using MRI Data"></a>Spatio-Temporal Similarity Measure based Multi-Task Learning for Predicting Alzheimer’s Disease Progression using MRI Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03557">http://arxiv.org/abs/2311.03557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xulong Wang, Yu Zhang, Menghui Zhou, Tong Liu, Jun Qi, Po Yang</li>
<li>for: 预测阿尔茨曼病（AD）进程，并且捕捉脑区域之间的相互关系</li>
<li>methods: 基于多任务学习的新尺度 Similarity Measure 方法，能够有效地预测 AD 进程，并捕捉脑区域之间的相互关系</li>
<li>results: 与直接使用 ROI 学习相比，提出的方法更有效地预测疾病进程，并能够进行 longitudinal stability selection，捕捉脑区域之间的变化关系，这些关系在疾病进程中发挥关键作用。<details>
<summary>Abstract</summary>
Identifying and utilising various biomarkers for tracking Alzheimer's disease (AD) progression have received many recent attentions and enable helping clinicians make the prompt decisions. Traditional progression models focus on extracting morphological biomarkers in regions of interest (ROIs) from MRI/PET images, such as regional average cortical thickness and regional volume. They are effective but ignore the relationships between brain ROIs over time, which would lead to synergistic deterioration. For exploring the synergistic deteriorating relationship between these biomarkers, in this paper, we propose a novel spatio-temporal similarity measure based multi-task learning approach for effectively predicting AD progression and sensitively capturing the critical relationships between biomarkers. Specifically, we firstly define a temporal measure for estimating the magnitude and velocity of biomarker change over time, which indicate a changing trend(temporal). Converting this trend into the vector, we then compare this variability between biomarkers in a unified vector space(spatial). The experimental results show that compared with directly ROI based learning, our proposed method is more effective in predicting disease progression. Our method also enables performing longitudinal stability selection to identify the changing relationships between biomarkers, which play a key role in disease progression. We prove that the synergistic deteriorating biomarkers between cortical volumes or surface areas have a significant effect on the cognitive prediction.
</details>
<details>
<summary>摘要</summary>
检测和跟踪阿尔茨海默病（AD）进展的不同生物标志物（biomarker）在Received recent attention and enable clinicians to make prompt decisions. 传统的进展模型将注意力集中在提取ROI（区域 интерес点）的MRI/PET图像中的形态生长指标和区域体积。尽管有效，但忽略了跨时间ROI之间的关系，这会导致相互恶化。为了探索这些生物标志物之间的相互恶化关系，在这篇论文中，我们提出了一种基于多任务学习的新的空间-时间相似度度量方法。 Specifically，我们首先定义了一种时间度量，用于估计生物标志物变化的大小和速度，这些变化指示了时间的趋势（temporal）。将这种趋势转换为向量，然后在一个统一的向量空间中比较这些变化的相互关系。实验结果表明，与直接使用ROI基于学习相比，我们的提议方法更有效地预测疾病进程。我们的方法还允许进行长期稳定选择，以确定变化的关系 между生物标志物，这些关系在疾病进程中扮演着关键的角色。我们证明了脑区表面积或体积之间的相互恶化生物标志物对认知预测具有重要的效果。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-point-annotations-in-segmentation-learning-with-boundary-loss"><a href="#Leveraging-point-annotations-in-segmentation-learning-with-boundary-loss" class="headerlink" title="Leveraging point annotations in segmentation learning with boundary loss"></a>Leveraging point annotations in segmentation learning with boundary loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03537">http://arxiv.org/abs/2311.03537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eva Breznik, Hoel Kervadec, Filip Malmberg, Joel Kullberg, Håkan Ahlström, Marleen de Bruijne, Robin Strand</li>
<li>for: 这个论文研究了在点指导下的semantic segmentation中使用Intensity-based距离地图和边界损失。</li>
<li>methods: 该论文使用了边界损失，以便更好地强制实施false positives的约束。</li>
<li>results: 该论文在ACDC和POEM两个多类数据集上进行了实验，并获得了鼓舞人心的结果。在ACDC数据集上，它超越了基于CRF损失的方法，而在POEM数据集上与CRF损失相当。代码所有实验都公开可用。<details>
<summary>Abstract</summary>
This paper investigates the combination of intensity-based distance maps with boundary loss for point-supervised semantic segmentation. By design the boundary loss imposes a stronger penalty on the false positives the farther away from the object they occur. Hence it is intuitively inappropriate for weak supervision, where the ground truth label may be much smaller than the actual object and a certain amount of false positives (w.r.t. the weak ground truth) is actually desirable. Using intensity-aware distances instead may alleviate this drawback, allowing for a certain amount of false positives without a significant increase to the training loss. The motivation for applying the boundary loss directly under weak supervision lies in its great success for fully supervised segmentation tasks, but also in not requiring extra priors or outside information that is usually required -- in some form -- with existing weakly supervised methods in the literature. This formulation also remains potentially more attractive than existing CRF-based regularizers, due to its simplicity and computational efficiency. We perform experiments on two multi-class datasets; ACDC (heart segmentation) and POEM (whole-body abdominal organ segmentation). Preliminary results are encouraging and show that this supervision strategy has great potential. On ACDC it outperforms the CRF-loss based approach, and on POEM data it performs on par with it. The code for all our experiments is openly available.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="High-resolution-power-equipment-recognition-based-on-improved-self-attention"><a href="#High-resolution-power-equipment-recognition-based-on-improved-self-attention" class="headerlink" title="High-resolution power equipment recognition based on improved self-attention"></a>High-resolution power equipment recognition based on improved self-attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03518">http://arxiv.org/abs/2311.03518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyi Zhang, Cheng Liu, Xiang Li, Xin Zhai, Zhen Wei, Sizhe Li, Xun Ma</li>
<li>For: 提高变压器图像识别精度，应对现有模型参数数量限制。* Methods: 提出了一种基于深度自注意网络的改进方法，包括基础网络、区域提议网络、目标区域提取和 segmentation 模块，以及最终预测网络。* Results: 比较实验表明，该方法在变压器图像识别 task 上表现出色，超过了两种常见目标识别模型的表现，为自动化电气设备检测带来新的思路。<details>
<summary>Abstract</summary>
The current trend of automating inspections at substations has sparked a surge in interest in the field of transformer image recognition. However, due to restrictions in the number of parameters in existing models, high-resolution images can't be directly applied, leaving significant room for enhancing recognition accuracy. Addressing this challenge, the paper introduces a novel improvement on deep self-attention networks tailored for this issue. The proposed model comprises four key components: a foundational network, a region proposal network, a module for extracting and segmenting target areas, and a final prediction network. The innovative approach of this paper differentiates itself by decoupling the processes of part localization and recognition, initially using low-resolution images for localization followed by high-resolution images for recognition. Moreover, the deep self-attention network's prediction mechanism uniquely incorporates the semantic context of images, resulting in substantially improved recognition performance. Comparative experiments validate that this method outperforms the two other prevalent target recognition models, offering a groundbreaking perspective for automating electrical equipment inspections.
</details>
<details>
<summary>摘要</summary>
现在的 substation 自动检测趋势使得transformer 图像识别领域受到了广泛的关注。然而，由于现有模型中参数的限制，高分辨率图像直接应用是不可能的，留下了大量的提高识别精度的空间。为解决这个挑战，本文提出了一种新的深度自注意网络改进方法。该模型包括四个关键组件：基础网络、区域提议网络、目标区域提取和分割模块、最终预测网络。本文的创新方法在分解部分localization和识别两个过程，首先使用低分辨率图像进行localization，然后使用高分辨率图像进行识别。此外，深度自注意网络的预测机制唯一地包含图像的semantic上下文，导致识别性能得到了显著提高。对比试验证明了这种方法在两种常见的目标识别模型之上表现出色，提供了一个创新的自动电气设备检测方法。
</details></li>
</ul>
<hr>
<h2 id="SoundCam-A-Dataset-for-Finding-Humans-Using-Room-Acoustics"><a href="#SoundCam-A-Dataset-for-Finding-Humans-Using-Room-Acoustics" class="headerlink" title="SoundCam: A Dataset for Finding Humans Using Room Acoustics"></a>SoundCam: A Dataset for Finding Humans Using Room Acoustics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03517">http://arxiv.org/abs/2311.03517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mason Wang, Samuel Clarke, Jui-Hsien Wang, Ruohan Gao, Jiajun Wu</li>
<li>for: 这篇论文旨在描述一个室内的声学特性是室内的 geometry、objects和它们的具体位置之间的互动的结果。</li>
<li>methods: 这篇论文使用了声学响应函数（RIR）来描述室内的声学特性，并通过不同的物体位置变化来研究室内的声学特性的变化。</li>
<li>results: 这篇论文提供了5000个真实世界的声学响应函数记录和3000个音乐记录，并在三个不同的房间中（包括一个控制的声学实验室、一个野生的客厅和一个会议室）进行了不同的人员的位置变化。研究表明这些记录可以用于检测和识别人员，以及跟踪他们的位置。<details>
<summary>Abstract</summary>
A room's acoustic properties are a product of the room's geometry, the objects within the room, and their specific positions. A room's acoustic properties can be characterized by its impulse response (RIR) between a source and listener location, or roughly inferred from recordings of natural signals present in the room. Variations in the positions of objects in a room can effect measurable changes in the room's acoustic properties, as characterized by the RIR. Existing datasets of RIRs either do not systematically vary positions of objects in an environment, or they consist of only simulated RIRs. We present SoundCam, the largest dataset of unique RIRs from in-the-wild rooms publicly released to date. It includes 5,000 10-channel real-world measurements of room impulse responses and 2,000 10-channel recordings of music in three different rooms, including a controlled acoustic lab, an in-the-wild living room, and a conference room, with different humans in positions throughout each room. We show that these measurements can be used for interesting tasks, such as detecting and identifying humans, and tracking their positions.
</details>
<details>
<summary>摘要</summary>
Room 的听音性能是由房间的几何结构、房间内的物品和它们的具体位置相互作用而决定的。 Room 的听音性能可以通过源和听者位置之间的冲激响应（RIR）来描述，或者通过房间中自然的信号记录来粗略地推断。 变化房间内物品的位置会导致可观测的改变房间的听音性能，这可以通过 RIR 来证明。现有的数据集中的 RIR  either do not systematically vary positions of objects in an environment, or they consist of only simulated RIRs。我们提出了 SoundCam，迄今为止最大的在野room impulse responses的公共数据集。它包括5000个10通道的真实世界测量室冲激响应和3个不同的房间中的2000个10通道的音乐录音，包括控制的听音实验室、在野的客厦和会议室，每个房间中有不同的人在不同的位置。我们显示这些测量可以用于有趣的任务，如检测和识别人类，并跟踪他们的位置。
</details></li>
</ul>
<hr>
<h2 id="Predicting-Age-from-White-Matter-Diffusivity-with-Residual-Learning"><a href="#Predicting-Age-from-White-Matter-Diffusivity-with-Residual-Learning" class="headerlink" title="Predicting Age from White Matter Diffusivity with Residual Learning"></a>Predicting Age from White Matter Diffusivity with Residual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03500">http://arxiv.org/abs/2311.03500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Gao, Michael E. Kim, Ho Hin Lee, Qi Yang, Nazirah Mohd Khairi, Praitayini Kanakaraj, Nancy R. Newlin, Derek B. Archer, Angela L. Jefferson, Warren D. Taylor, Brian D. Boyd, Lori L. Beason-Held, Susan M. Resnick, The BIOCARD Study Team, Yuankai Huo, Katherine D. Van Schaik, Kurt G. Schilling, Daniel Moyer, Ivana Išgum, Bennett A. Landman</li>
<li>for: 这个研究旨在开发白 matter 特定的年龄估计方法，以捕捉不同于正常白 matter 年龄发展的异常。</li>
<li>methods: 这个研究使用了两种不同的方法来预测年龄：一种是提取区域兴趣点中的微结构特征，另一种是使用3D差异神经网络（ResNets）学习直接从图像中的特征。</li>
<li>results: 测试数据上，使用提取微结构特征的方法可以得到平均绝对误差（MAE）为6.11年和6.62年，而使用ResNets学习特征的方法可以得到MAE为4.69年和4.96年。<details>
<summary>Abstract</summary>
Imaging findings inconsistent with those expected at specific chronological age ranges may serve as early indicators of neurological disorders and increased mortality risk. Estimation of chronological age, and deviations from expected results, from structural MRI data has become an important task for developing biomarkers that are sensitive to such deviations. Complementary to structural analysis, diffusion tensor imaging (DTI) has proven effective in identifying age-related microstructural changes within the brain white matter, thereby presenting itself as a promising additional modality for brain age prediction. Although early studies have sought to harness DTI's advantages for age estimation, there is no evidence that the success of this prediction is owed to the unique microstructural and diffusivity features that DTI provides, rather than the macrostructural features that are also available in DTI data. Therefore, we seek to develop white-matter-specific age estimation to capture deviations from normal white matter aging. Specifically, we deliberately disregard the macrostructural information when predicting age from DTI scalar images, using two distinct methods. The first method relies on extracting only microstructural features from regions of interest. The second applies 3D residual neural networks (ResNets) to learn features directly from the images, which are non-linearly registered and warped to a template to minimize macrostructural variations. When tested on unseen data, the first method yields mean absolute error (MAE) of 6.11 years for cognitively normal participants and MAE of 6.62 years for cognitively impaired participants, while the second method achieves MAE of 4.69 years for cognitively normal participants and MAE of 4.96 years for cognitively impaired participants. We find that the ResNet model captures subtler, non-macrostructural features for brain age prediction.
</details>
<details>
<summary>摘要</summary>
医学成像发现与期望的年龄范围不符的现象可能是脑神经疾病的早期指标和增加死亡风险的预示器。测量年龄和与期望结果的差异从结构MRI数据中得到了重要的任务，以开发敏感于这些差异的生物标志物。与结构分析相加，Diffusion Tensor Imaging（DTI）已经证明了在脑白 matter中年龄相关的微结构变化，因此成为了脑年龄预测的有力的其他可能性。虽然早期研究尝试使用DTI来预测年龄，但没有证据表明这种预测的成功归功于DTI提供的特有微结构和diffusivity特征，而不是Macrostructural特征。因此，我们想要开发白 matter特有的年龄预测方法，以捕捉不同于正常白 matter年龄的异常。我们专门忽略了Macrostructural信息，使用两种不同的方法来预测年龄从DTI扁平图像。第一种方法是从区域关心提取微结构特征。第二种方法是使用3D差分神经网络（ResNets）学习图像直接特征，使用非线性对齐和折叠将图像与模板进行非线性对齐和折叠，以最小化Macrostructural变化。当测试在未见数据时，第一种方法的平均绝对误差（MAE）为6.11年，对于正常认知参与者，MAE为6.62年，对于认知障碍参与者。而第二种方法的MAE为4.69年，对于正常认知参与者，MAE为4.96年，对于认知障碍参与者。我们发现ResNet模型可以捕捉更细微、非Macrostructural特征，用于脑年龄预测。
</details></li>
</ul>
<hr>
<h2 id="CoVLM-Composing-Visual-Entities-and-Relationships-in-Large-Language-Models-Via-Communicative-Decoding"><a href="#CoVLM-Composing-Visual-Entities-and-Relationships-in-Large-Language-Models-Via-Communicative-Decoding" class="headerlink" title="CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding"></a>CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03354">http://arxiv.org/abs/2311.03354</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UMass-Foundation-Model/CoVLM">https://github.com/UMass-Foundation-Model/CoVLM</a></li>
<li>paper_authors: Junyan Li, Delin Chen, Yining Hong, Zhenfang Chen, Peihao Chen, Yikang Shen, Chuang Gan</li>
<li>for: 提高大型视言语基本模型（VLM）的可 compose 能力，以便更好地理解和生成视语语言。</li>
<li>methods: 提出了一种新的通信标识符，通过动态与视觉检测系统和语言系统之间的交互，使得语言模型能够正确地组合视觉实体和关系。</li>
<li>results: 与先前的 VLM 相比，提高了大约20%的 HICO-DET mAP 分数、14%的 Cola 顶部准确率和3%的 ARO 顶部准确率，并在传统的视语语言任务中达到了状态略优的表现。<details>
<summary>Abstract</summary>
A remarkable ability of human beings resides in compositional reasoning, i.e., the capacity to make "infinite use of finite means". However, current large vision-language foundation models (VLMs) fall short of such compositional abilities due to their "bag-of-words" behaviors and inability to construct words that correctly represent visual entities and the relations among the entities. To this end, we propose CoVLM, which can guide the LLM to explicitly compose visual entities and relationships among the text and dynamically communicate with the vision encoder and detection network to achieve vision-language communicative decoding. Specifically, we first devise a set of novel communication tokens for the LLM, for dynamic communication between the visual detection system and the language system. A communication token is generated by the LLM following a visual entity or a relation, to inform the detection network to propose regions that are relevant to the sentence generated so far. The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation contingent on the relevant regions. The LLM is thus able to compose the visual entities and relationships through the communication tokens. The vision-to-language and language-to-vision communication are iteratively performed until the entire sentence is generated. Our framework seamlessly bridges the gap between visual perception and LLMs and outperforms previous VLMs by a large margin on compositional reasoning benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on ARO top-1 accuracy). We also achieve state-of-the-art performances on traditional vision-language tasks such as referring expression comprehension and visual question answering.
</details>
<details>
<summary>摘要</summary>
人类具有惊人的能力，即使用有限的资源来创造无限的表达。然而，目前的大型视言语基本模型（VLM）缺乏这种 Compositional 能力，因为它们的“袋子行为”和无法正确地构成图像元素和关系。为此，我们提出了 CoVLM，可以导引 LLM 进行 Explicit 的视图语言组合，并在视觉Encoder和检测网络之间动态交流来实现视语言交流编码。具体来说，我们首先设计了一组新的通信标识符，以便 LLM 与视觉检测系统之间的动态交流。通信标识符是由 LLM 根据视图元素或关系生成的，以告诉检测网络提出相关的区域。提出的区域关注（ROIs）然后被 fed 回 LLM，以便更好地基于相关区域进行语言生成。LLM 因此可以通过通信标识符来组合视图元素和关系。视觉语言和语言视觉之间的交流是相互进行的，直到整个句子被生成。我们的框架凝聚了视觉感知和 LLM 之间的差距，并在 Compositional 理解标准差（例如 HICO-DET mAP、Cola top-1 准确率和 ARO top-1 准确率）上大幅超越先前的 VLM。我们还在传统的视觉语言任务中实现了状态的最佳表现，如图像描述和视觉问答。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Evaluation-Metrics-of-Open-Vocabulary-Segmentaion"><a href="#Rethinking-Evaluation-Metrics-of-Open-Vocabulary-Segmentaion" class="headerlink" title="Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion"></a>Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03352">http://arxiv.org/abs/2311.03352</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qqlu/entity">https://github.com/qqlu/entity</a></li>
<li>paper_authors: Hao Zhou, Tiancheng Shen, Xu Yang, Hai Huang, Xiangtai Li, Lu Qi, Ming-Hsuan Yang</li>
<li>for: 本文提出了一个关于开放词汇分割评估方法的问题，即现有评估方法仍然强调关闭集成度metric在零shot或跨数据集管道上，而不考虑预测和实际分类类别之间的相似性。</li>
<li>methods: 本文首先对eleven种语言学统计、文本嵌入和语言模型中的类比度量进行了抽象和用户研究，然后基于这些探索的量建立了一些新的评估指标，包括开放mIoU、开放AP和开放PQ，这些指标适用于三种开放词汇分割任务。</li>
<li>results: 对于12种开放词汇分割方法，我们使用了我们提出的评估指标进行了比较，并证明了我们的指标可以有效评估现有的开放词汇分割方法的开放能力，即使相对的类比度距离存在一定的主观性。<details>
<summary>Abstract</summary>
In this paper, we highlight a problem of evaluation metrics adopted in the open-vocabulary segmentation. That is, the evaluation process still heavily relies on closed-set metrics on zero-shot or cross-dataset pipelines without considering the similarity between predicted and ground truth categories. To tackle this issue, we first survey eleven similarity measurements between two categorical words using WordNet linguistics statistics, text embedding, and language models by comprehensive quantitative analysis and user study. Built upon those explored measurements, we designed novel evaluation metrics, namely Open mIoU, Open AP, and Open PQ, tailored for three open-vocabulary segmentation tasks. We benchmarked the proposed evaluation metrics on 12 open-vocabulary methods of three segmentation tasks. Even though the relative subjectivity of similarity distance, we demonstrate that our metrics can still well evaluate the open ability of the existing open-vocabulary segmentation methods. We hope that our work can bring with the community new thinking about how to evaluate the open ability of models. The evaluation code is released in github.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Long-Term-Invariant-Local-Features-via-Implicit-Cross-Domain-Correspondences"><a href="#Long-Term-Invariant-Local-Features-via-Implicit-Cross-Domain-Correspondences" class="headerlink" title="Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences"></a>Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03345">http://arxiv.org/abs/2311.03345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zador Pataki, Mohammad Altillawi, Menelaos Kanakis, Rémi Pautrat, Fengyi Shen, Ziyuan Liu, Luc Van Gool, Marc Pollefeys</li>
<li>for: 本研究旨在 investigating the performance impact of long-term visual domain variations on modern learning-based visual feature extraction networks, and proposing a novel method to improve cross-domain localization performance.</li>
<li>methods: 我们使用 current state-of-the-art feature extraction networks, and conduct a thorough analysis of their performance under various domain changes. We also propose a novel data-centric method, Implicit Cross-Domain Correspondences (iCDC), which utilizes Neural Radiance Fields to generate accurate correspondences across different long-term visual conditions.</li>
<li>results: 我们的 proposed method significantly enhances cross-domain localization performance, reducing the performance gap between intra- and cross-domain localization. When evaluated on popular long-term localization benchmarks, our trained networks consistently outperform existing methods.<details>
<summary>Abstract</summary>
Modern learning-based visual feature extraction networks perform well in intra-domain localization, however, their performance significantly declines when image pairs are captured across long-term visual domain variations, such as different seasonal and daytime variations. In this paper, our first contribution is a benchmark to investigate the performance impact of long-term variations on visual localization. We conduct a thorough analysis of the performance of current state-of-the-art feature extraction networks under various domain changes and find a significant performance gap between intra- and cross-domain localization. We investigate different methods to close this gap by improving the supervision of modern feature extractor networks. We propose a novel data-centric method, Implicit Cross-Domain Correspondences (iCDC). iCDC represents the same environment with multiple Neural Radiance Fields, each fitting the scene under individual visual domains. It utilizes the underlying 3D representations to generate accurate correspondences across different long-term visual conditions. Our proposed method enhances cross-domain localization performance, significantly reducing the performance gap. When evaluated on popular long-term localization benchmarks, our trained networks consistently outperform existing methods. This work serves as a substantial stride toward more robust visual localization pipelines for long-term deployments, and opens up research avenues in the development of long-term invariant descriptors.
</details>
<details>
<summary>摘要</summary>
现代学习基于的视觉特征提取网络在同一个频谱下的本地化表现良好，但是当图像对被捕捉到不同季节和时间变化的长期视觉频谱上时，其表现会有很大下降。在这篇论文中，我们的首要贡献是一个评估长期变化对视本地化表现的影响的benchmark。我们进行了现代特征提取网络在不同频谱下的广泛分析，并发现了跨频谱本地化表现和同频谱本地化表现之间的显著性能差距。我们研究了不同的方法来减少这个差距，包括改进现代特征提取器网络的监督。我们提出了一种数据驱动的方法，即隐式跨频谱对匹配（iCDC）。iCDC使用场景下的多个神经辐射场，每个场景适应不同的视觉频谱，以生成准确的跨频谱对匹配。我们的提议方法可以提高跨频谱本地化表现，显著减少性能差距。当我们的训练网络被评估在知名的长期本地化benchmark上时，它们一直表现出色，超过了现有方法。这种工作为长期部署的更加Robust的视本地化管道奠定了基础，并开启了长期不变描述器的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Cross-Image-Attention-for-Zero-Shot-Appearance-Transfer"><a href="#Cross-Image-Attention-for-Zero-Shot-Appearance-Transfer" class="headerlink" title="Cross-Image Attention for Zero-Shot Appearance Transfer"></a>Cross-Image Attention for Zero-Shot Appearance Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03335">http://arxiv.org/abs/2311.03335</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/garibida/cross-image-attention">https://github.com/garibida/cross-image-attention</a></li>
<li>paper_authors: Yuval Alaluf, Daniel Garibi, Or Patashnik, Hadar Averbuch-Elor, Daniel Cohen-Or</li>
<li>For: The paper is written for transferring the visual appearance between objects that share similar semantics but may differ significantly in shape.* Methods: The paper uses a cross-image attention mechanism that combines the queries corresponding to the structure image with the keys and values of the appearance image during the denoising process. Additionally, the paper uses three mechanisms to manipulate the noisy latent codes or the model’s internal representations throughout the denoising process.* Results: The paper demonstrates that its method is effective across a wide range of object categories and is robust to variations in shape, size, and viewpoint between the two input images.<details>
<summary>Abstract</summary>
Recent advancements in text-to-image generative models have demonstrated a remarkable ability to capture a deep semantic understanding of images. In this work, we leverage this semantic knowledge to transfer the visual appearance between objects that share similar semantics but may differ significantly in shape. To achieve this, we build upon the self-attention layers of these generative models and introduce a cross-image attention mechanism that implicitly establishes semantic correspondences across images. Specifically, given a pair of images -- one depicting the target structure and the other specifying the desired appearance -- our cross-image attention combines the queries corresponding to the structure image with the keys and values of the appearance image. This operation, when applied during the denoising process, leverages the established semantic correspondences to generate an image combining the desired structure and appearance. In addition, to improve the output image quality, we harness three mechanisms that either manipulate the noisy latent codes or the model's internal representations throughout the denoising process. Importantly, our approach is zero-shot, requiring no optimization or training. Experiments show that our method is effective across a wide range of object categories and is robust to variations in shape, size, and viewpoint between the two input images.
</details>
<details>
<summary>摘要</summary>
最近的文本到图像生成模型的进步已经展示了深刻的semantic理解能力。在这项工作中，我们利用这种semantic知识来传递图像中的视觉特征。为此，我们基于这些生成模型中的自注意层，并引入了跨图像注意机制，以便在图像之间建立semantic对应关系。具体来说，给定一对图像——一个显示目标结构的图像和一个指定愿望的外观图像——我们的跨图像注意机制将目标结构图像中的查询与愿望图像中的键和值进行结合。这个操作，当应用于吸吧过程中，利用建立的semantic对应关系来生成一个组合了目标结构和愿望外观的图像。此外，为了提高输出图像质量，我们利用三种机制来操作噪声缺失代码或模型内部表示在吸吧过程中。值得一提的是，我们的方法是零值的，不需要优化或训练。实验表明，我们的方法在对象类型的广泛范围内都是有效的，并且对图像之间的形状、大小和视角的变化具有较高的Robustness。
</details></li>
</ul>
<hr>
<h2 id="TSP-Transformer-Task-Specific-Prompts-Boosted-Transformer-for-Holistic-Scene-Understanding"><a href="#TSP-Transformer-Task-Specific-Prompts-Boosted-Transformer-for-Holistic-Scene-Understanding" class="headerlink" title="TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding"></a>TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03427">http://arxiv.org/abs/2311.03427</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tb2-sy/tsp-transformer">https://github.com/tb2-sy/tsp-transformer</a></li>
<li>paper_authors: Shuo Wang, Jing Li, Zibo Zhao, Dongze Lian, Binbin Huang, Xiaomei Wang, Zhengxin Li, Shenghua Gao</li>
<li>for: 本研究旨在提出一种基于任务特定提示的转换器模型，用于实现整体场景理解。</li>
<li>methods: 该模型由一个普通的变换器层和一个任务特定提示变换器层组成，其中任务特定提示变换器层通过增强任务特定的概念来增强模型的任务特定能力。</li>
<li>results: 通过对NYUD-v2和PASCAL-Context datasets进行广泛的实验，我们的方法得到了状态对抗的性能，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Holistic scene understanding includes semantic segmentation, surface normal estimation, object boundary detection, depth estimation, etc. The key aspect of this problem is to learn representation effectively, as each subtask builds upon not only correlated but also distinct attributes. Inspired by visual-prompt tuning, we propose a Task-Specific Prompts Transformer, dubbed TSP-Transformer, for holistic scene understanding. It features a vanilla transformer in the early stage and tasks-specific prompts transformer encoder in the lateral stage, where tasks-specific prompts are augmented. By doing so, the transformer layer learns the generic information from the shared parts and is endowed with task-specific capacity. First, the tasks-specific prompts serve as induced priors for each task effectively. Moreover, the task-specific prompts can be seen as switches to favor task-specific representation learning for different tasks. Extensive experiments on NYUD-v2 and PASCAL-Context show that our method achieves state-of-the-art performance, validating the effectiveness of our method for holistic scene understanding. We also provide our code in the following link https://github.com/tb2-sy/TSP-Transformer.
</details>
<details>
<summary>摘要</summary>
整体场景理解包括semantic segmentation、surface normal估计、物体边界检测、深度估计等多个任务。关键问题在于学习表示效果，因为每个子任务受到不仅相关的还有独特的特征影响。以视觉提示调整为引入，我们提出了任务特定提示变换器（TSP-Transformer） для整体场景理解。它包括普通变换器的早期阶段和后期阶段的任务特定提示变换器 Encoder，其中任务特定提示被增强。通过这种方式，变换层学习了通用信息从共享部分，同时受到任务特定能力的激励。首先，任务特定提示作为各任务的预设效果地启用了变换层。此外，任务特定提示可以看作是为不同任务的表示学习偏好的开关。我们的方法在NYUD-v2和PASCAL-Context上进行了广泛的实验，并达到了当前最佳性能，证明了我们的方法的有效性。我们还提供了我们的代码，请参考以下链接<https://github.com/tb2-sy/TSP-Transformer>。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Bi-Directional-Algorithm-For-People-Count-In-Crowded-Areas"><a href="#A-Robust-Bi-Directional-Algorithm-For-People-Count-In-Crowded-Areas" class="headerlink" title="A Robust Bi-Directional Algorithm For People Count In Crowded Areas"></a>A Robust Bi-Directional Algorithm For People Count In Crowded Areas</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03323">http://arxiv.org/abs/2311.03323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Satyanarayana Penke, Gopikrishna Pavuluri, Soukhya Kunda, Satvik M, CharanKumar Y</li>
<li>for: 这篇论文是为了计算人群流动量而写的。</li>
<li>methods: 这篇论文使用了聚合物探测方法来计算人群流动量。</li>
<li>results: 这篇论文得到了实时人群流动量的计数结果。In English, this translates to:</li>
<li>for: This paper is written for counting the flow of people.</li>
<li>methods: This paper uses blob detection methods to count the flow of people.</li>
<li>results: This paper obtains real-time results of the number of people flowing through a particular area.<details>
<summary>Abstract</summary>
People counting system in crowded places has become a very useful practical application that can be accomplished in various ways which include many traditional methods using sensors. Examining the case of real time scenarios, the algorithm espoused should be steadfast and accurate. People counting algorithm presented in this paper, is centered on blob assessment, devoted to yield the count of the people through a path along with the direction of traversal. The system depicted is often ensconced at the entrance of a building so that the unmitigated frequency of visitors can be recorded. The core premise of this work is to extricate count of people inflow and outflow pertaining to a particular area. The tot-up achieved can be exploited for purpose of statistics in the circumstances of any calamity occurrence in that zone. Relying upon the count totaled, the population in that vicinity can be assimilated in order to take on relevant measures to rescue the people.
</details>
<details>
<summary>摘要</summary>
人Counter系统在拥挤的地方已成为一项非常有用的实用应用，可以通过多种传统方法使用感测器实现。在实时场景中，算法应该坚定稳定，准确。本文所描述的人Counter算法是基于物体评估，用于计算游客通过一条路径的方向和人数。这种系统通常会被安装在建筑物的入口处，以记录进出的游客频率。本研究的核心思想是计算某个区域的人流量，以便在紧急情况下统计人口。根据记录的人数，可以对该区域的人口进行相应的整合，以采取救援措施。
</details></li>
</ul>
<hr>
<h2 id="FATE-Feature-Agnostic-Transformer-based-Encoder-for-learning-generalized-embedding-spaces-in-flow-cytometry-data"><a href="#FATE-Feature-Agnostic-Transformer-based-Encoder-for-learning-generalized-embedding-spaces-in-flow-cytometry-data" class="headerlink" title="FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data"></a>FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03314">http://arxiv.org/abs/2311.03314</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lisaweijler/fate">https://github.com/lisaweijler/fate</a></li>
<li>paper_authors: Lisa Weijler, Florian Kowarsch, Michael Reiter, Pedro Hermosilla, Margarita Maurer-Granofszky, Michael Dworzak</li>
<li>for:  This paper aims to effectively leverage data with varying features in scenarios where the attributes captured during data acquisition vary across different samples.</li>
<li>methods: The proposed architecture uses a set-transformer architecture augmented by feature-encoder layers to learn a shared latent feature space from data originating from heterogeneous feature spaces.</li>
<li>results: The proposed architecture is demonstrated to operate seamlessly across incongruent feature spaces, particularly relevant in the context of automatic cancer cell detection in acute myeloid leukemia in flow cytometry data, where data scarcity arises from the low prevalence of the disease.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文目标是在不同样本中采集的数据中有变量特征的情况下，有效地利用数据。</li>
<li>methods: 提议的架构使用集成变换器架构和特征编码层来学习不同特征空间中的共享准则空间。</li>
<li>results: 提议的架构在不同特征空间之间操作无缝，特别在某些抑郁白血病细胞检测中， где数据稀缺性由疾病的低发生率导致。<details>
<summary>Abstract</summary>
While model architectures and training strategies have become more generic and flexible with respect to different data modalities over the past years, a persistent limitation lies in the assumption of fixed quantities and arrangements of input features. This limitation becomes particularly relevant in scenarios where the attributes captured during data acquisition vary across different samples. In this work, we aim at effectively leveraging data with varying features, without the need to constrain the input space to the intersection of potential feature sets or to expand it to their union. We propose a novel architecture that can directly process data without the necessity of aligned feature modalities by learning a general embedding space that captures the relationship between features across data samples with varying sets of features. This is achieved via a set-transformer architecture augmented by feature-encoder layers, thereby enabling the learning of a shared latent feature space from data originating from heterogeneous feature spaces. The advantages of the model are demonstrated for automatic cancer cell detection in acute myeloid leukemia in flow cytometry data, where the features measured during acquisition often vary between samples. Our proposed architecture's capacity to operate seamlessly across incongruent feature spaces is particularly relevant in this context, where data scarcity arises from the low prevalence of the disease. The code is available for research purposes at https://github.com/lisaweijler/FATE.
</details>
<details>
<summary>摘要</summary>
而模型的建立和训练策略在过去几年变得更加通用和灵活，对不同数据类型的处理也变得更加容易。然而，一个持续存在的限制是假设输入特征的量和排序是固定的。这个限制在样本中的特征在不同时会变化的场景中特别 relevante。在这项工作中，我们想使用不同特征的数据，不需要固定输入空间为样本之间的交集或者 union。我们提出了一种新的架构，可以直接处理数据，不需要对特征模式进行对齐。这是通过在扩展set-transformer架构中添加特征编码层来实现的，从而学习样本间的共享隐藏特征空间。这些优势在抑制针对恶性白细胞的自动检测中得到了证明，特别是在流细胞分析数据中， где特征的测量通常会在样本之间异常。我们的提出的架构能够无缝地处理不同特征空间，特别在这种疾病的低发生率下，数据的缺乏问题更加突出。代码可以在https://github.com/lisaweijler/FATE上获取 для研究用途。
</details></li>
</ul>
<hr>
<h2 id="A-Single-2D-Pose-with-Context-is-Worth-Hundreds-for-3D-Human-Pose-Estimation"><a href="#A-Single-2D-Pose-with-Context-is-Worth-Hundreds-for-3D-Human-Pose-Estimation" class="headerlink" title="A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation"></a>A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03312">http://arxiv.org/abs/2311.03312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/QitaoZhao/ContextAware-PoseFormer">https://github.com/QitaoZhao/ContextAware-PoseFormer</a></li>
<li>paper_authors: Qitao Zhao, Ce Zheng, Mengyuan Liu, Chen Chen</li>
<li>for: 提高3D人体pose估计精度，不需要大量视频帧</li>
<li>methods: 利用 pré-trained 2D pose检测器生成的中间视觉表示，不需要精度调整</li>
<li>results: 与Context-Aware PoseFormer比较，无需使用视频帧，可以达到更高的速度和精度<details>
<summary>Abstract</summary>
The dominant paradigm in 3D human pose estimation that lifts a 2D pose sequence to 3D heavily relies on long-term temporal clues (i.e., using a daunting number of video frames) for improved accuracy, which incurs performance saturation, intractable computation and the non-causal problem. This can be attributed to their inherent inability to perceive spatial context as plain 2D joint coordinates carry no visual cues. To address this issue, we propose a straightforward yet powerful solution: leveraging the readily available intermediate visual representations produced by off-the-shelf (pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed. The key observation is that, while the pose detector learns to localize 2D joints, such representations (e.g., feature maps) implicitly encode the joint-centric spatial context thanks to the regional operations in backbone networks. We design a simple baseline named Context-Aware PoseFormer to showcase its effectiveness. Without access to any temporal information, the proposed method significantly outperforms its context-agnostic counterpart, PoseFormer, and other state-of-the-art methods using up to hundreds of video frames regarding both speed and precision. Project page: https://qitaozhao.github.io/ContextAware-PoseFormer
</details>
<details>
<summary>摘要</summary>
dominant 模式在三维人姿估算中，将二维姿势序列提升到三维的强调很重视长期时间凭据（即使用大量视频帧），从而导致性能峰值、不可持续计算和非因果问题。这可以归结于它们的内置无法感知空间上下文的问题，因为平面的二维关节坐标不含视觉提示。为解决这个问题，我们提出了一个简单 yet powerful的解决方案：利用可用的 intermediate visual representations 生成的 off-the-shelf (预训练) 二维姿势检测器生成的可用性。关键观察是，虽然姿势检测器学习到了二维关节的位置，但这些表示（例如特征图）在后向网络中的区域操作中隐式地编码了关节-中心空间上下文。我们设计了一个简单的基线方案，名为 Context-Aware PoseFormer，以示其效iveness。无需访问任何时间信息，我们的提案significantly outperform其上下文无关的对手，以及使用Up to hundreds of video frames的其他现状顶峰方法。项目页面：https://qitaozhao.github.io/ContextAware-PoseFormer
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Based-Tea-Leaf-Disease-Detection-A-Comprehensive-Review"><a href="#Machine-Learning-Based-Tea-Leaf-Disease-Detection-A-Comprehensive-Review" class="headerlink" title="Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review"></a>Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03240">http://arxiv.org/abs/2311.03240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Faruk Ahmed, Md. Taimur Ahad, Yousuf Rayhan Emon</li>
<li>for: 本研究旨在对茶叶病虫的早期检测和诊断进行机器学习方法的系统性回顾。</li>
<li>methods: 本文回顾了各种机器学习模型，包括Inception Convolutional Vision Transformer (ICVT)、GreenViT、PlantXViT、PlantViT、MSCVT、Transfer Learning Model &amp; Vision Transformer (TLMViT)、IterationViT、IEM-ViT等。此外，还回顾了 dense convolutional network (DenseNet)、Residual Neural Network (ResNet)-50V2、YOLOv5、YOLOv7、Convolutional Neural Network (CNN)、Deep CNN、Non-dominated Sorting Genetic Algorithm (NSGA-II)、MobileNetv2等模型。</li>
<li>results: 本文通过对各种数据集进行测试，证明了这些机器学习模型在实际应用中的可行性。<details>
<summary>Abstract</summary>
Tea leaf diseases are a major challenge to agricultural productivity, with far-reaching implications for yield and quality in the tea industry. The rise of machine learning has enabled the development of innovative approaches to combat these diseases. Early detection and diagnosis are crucial for effective crop management. For predicting tea leaf disease, several automated systems have already been developed using different image processing techniques. This paper delivers a systematic review of the literature on machine learning methodologies applied to diagnose tea leaf disease via image classification. It thoroughly evaluates the strengths and constraints of various Vision Transformer models, including Inception Convolutional Vision Transformer (ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision Transformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews models like Dense Convolutional Network (DenseNet), Residual Neural Network (ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN, Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and Lesion-Aware Visual Transformer. These machine-learning models have been tested on various datasets, demonstrating their real-world applicability. This review study not only highlights current progress in the field but also provides valuable insights for future research directions in the machine learning-based detection and classification of tea leaf diseases.
</details>
<details>
<summary>摘要</summary>
茶叶疾病是现代农业生产的主要挑战，对茶业产量和质量有广泛的影响。随着机器学习的发展，开发了一些创新的方法来控制这些疾病。早期检测和诊断是有效管理茶叶疾病的关键。为预测茶叶疾病，已经开发了一些自动化系统，使用不同的图像处理技术。本文提供了一种系统性的文献评审，检索了不同的机器学习方法，包括启发征值网络（ICVT）、绿色值网络（GreenViT）、植物值网络（PlantXViT）、植物值网络（PlantViT）、多种特征值网络（MSCVT）、传输学习模型与视觉Transformer（TLMViT）、迭代值网络（IterationViT）、IEM-ViT等。此外，本文还评估了各种模型，如密集卷积网络（DenseNet）、径回神经网络（ResNet）-50V2、YOLOv5、YOLOv7、图像卷积神经网络（CNN）、深度CNN、非主导排序遗传算法（NSGA-II）、MobileNetv2、损论值网络（Lesion-Aware）。这些机器学习模型在不同的数据集上进行测试，表明了它们在实际应用中的可行性。本评估研究不仅总结了当前领域的进展，还为未来机器学习基于茶叶疾病检测和分类的研究提供了有价值的思路。
</details></li>
</ul>
<hr>
<h2 id="Navigating-Scaling-Laws-Accelerating-Vision-Transformer’s-Training-via-Adaptive-Strategies"><a href="#Navigating-Scaling-Laws-Accelerating-Vision-Transformer’s-Training-via-Adaptive-Strategies" class="headerlink" title="Navigating Scaling Laws: Accelerating Vision Transformer’s Training via Adaptive Strategies"></a>Navigating Scaling Laws: Accelerating Vision Transformer’s Training via Adaptive Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03233">http://arxiv.org/abs/2311.03233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sotiris Anagnostidis, Gregor Bachmann, Thomas Hofmann</li>
<li>for: 这篇论文目的是提出一种可以适应不同 Compute 水平的深度学习模型，以便在不同的训练 dataset 上实现最佳性能。</li>
<li>methods: 这篇论文使用了一种名为“adaptive model”的方法，允许模型在训练过程中改变其形状，以便根据不同的 Compute 水平来实现最佳性能。</li>
<li>results: 论文的结果显示，使用这种 adaptive model 可以比传统的“静态”模型（static model）更好地适应不同 Compute 水平，并在视觉任务上实现更高的性能。<details>
<summary>Abstract</summary>
In recent years, the state-of-the-art in deep learning has been dominated by very large models that have been pre-trained on vast amounts of data. The paradigm is very simple: Investing more computational resources (optimally) leads to better performance, and even predictably so; neural scaling laws have been derived that accurately forecast the performance of a network for a desired level of compute. This leads to the notion of a "compute-optimal" model, i.e. a model that allocates a given level of compute during training optimally to maximise performance. In this work, we extend the concept of optimality by allowing for an "adaptive" model, i.e. a model that can change its shape during the course of training. By allowing the shape to adapt, we can optimally traverse between the underlying scaling laws, leading to a significant reduction in the required compute to reach a given target performance. We focus on vision tasks and the family of Vision Transformers, where the patch size as well as the width naturally serve as adaptive shape parameters. We demonstrate that, guided by scaling laws, we can design compute-optimal adaptive models that beat their "static" counterparts.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近年来，深度学习的州前掌握被庞大的模型所主导，这些模型在大量数据上进行预训练。这种方法的核心思想是：投入更多的计算资源（优化）会导致性能更好，甚至可预测性；神经网络的扩展法律已经 derivation 了可以准确预测模型在给定的计算水平下的性能。这导致了“计算优化”模型的概念，即在训练期间优化计算资源以 Maximize 性能。在这个工作中，我们将 extend 计算优化的概念，允许模型在训练过程中改变其形态。通过允许形态改变，我们可以优化地 traverse  между神经网络的下面各个缩放法律，从而减少到达目标性能所需的计算量。我们将注意力集中在视觉任务上，以及家族中的视觉变换器，其中补丁大小以及宽度自然成为 adaptive 形态参数。我们示示，根据缩放法律指导，我们可以设计计算优化的 adaptive 模型， beat 其“静止”对手。
</details></li>
</ul>
<hr>
<h2 id="Segmentation-of-Drone-Collision-Hazards-in-Airborne-RADAR-Point-Clouds-Using-PointNet"><a href="#Segmentation-of-Drone-Collision-Hazards-in-Airborne-RADAR-Point-Clouds-Using-PointNet" class="headerlink" title="Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet"></a>Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03221">http://arxiv.org/abs/2311.03221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hector Arroyo, Paul Kier, Dylan Angus, Santiago Matalonga, Svetlozar Georgiev, Mehdi Goli, Gerard Dooly, James Riordan</li>
<li>for: 这个研究旨在将无人航空器（UAV）integre into shared airspace for beyond visual line of sight（BVLOS）操作中提供更高度的 situational awareness，以确保安全的运作。</li>
<li>methods: 本研究使用激光技术进行 novel end-to-end semantic segmentation of aerial point clouds，以同时识别多个 Collision Hazards。研究人员运用和优化PointNet架构，并integrate aerial domain insights，以分别识别机动无人机（DJI M300和DJI Mini）和机场（Ikarus C42），以及静止返回（地面和基础设施）。</li>
<li>results: 本研究获得了robust 94%的准确率，成功地同时识别多个 Collision Hazards。这项研究显示激光技术在UAV situational awareness中的应用潜力，并促进了安全和效率的BVLOS操作。<details>
<summary>Abstract</summary>
The integration of unmanned aerial vehicles (UAVs) into shared airspace for beyond visual line of sight (BVLOS) operations presents significant challenges but holds transformative potential for sectors like transportation, construction, energy and defense. A critical prerequisite for this integration is equipping UAVs with enhanced situational awareness to ensure safe operations. Current approaches mainly target single object detection or classification, or simpler sensing outputs that offer limited perceptual understanding and lack the rapid end-to-end processing needed to convert sensor data into safety-critical insights. In contrast, our study leverages radar technology for novel end-to-end semantic segmentation of aerial point clouds to simultaneously identify multiple collision hazards. By adapting and optimizing the PointNet architecture and integrating aerial domain insights, our framework distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and airplanes (Ikarus C42), and static returns (ground and infrastructure) which results in enhanced situational awareness for UAVs. To our knowledge, this is the first approach addressing simultaneous identification of multiple collision threats in an aerial setting, achieving a robust 94% accuracy. This work highlights the potential of radar technology to advance situational awareness in UAVs, facilitating safe and efficient BVLOS operations.
</details>
<details>
<summary>摘要</summary>
integrating unmanned aerial vehicles (UAVs) into shared airspace for beyond visual line of sight (BVLOS) operations poses significant challenges, but it also has transformative potential for sectors like transportation, construction, energy, and defense. a critical prerequisite for this integration is equipping UAVs with enhanced situational awareness to ensure safe operations. current approaches mainly focus on single object detection or classification, or simpler sensing outputs that offer limited perceptual understanding and lack the rapid end-to-end processing needed to convert sensor data into safety-critical insights. in contrast, our study leverages radar technology for novel end-to-end semantic segmentation of aerial point clouds to simultaneously identify multiple collision hazards. by adapting and optimizing the PointNet architecture and integrating aerial domain insights, our framework distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and airplanes (Ikarus C42), and static returns (ground and infrastructure) which results in enhanced situational awareness for UAVs. to our knowledge, this is the first approach addressing simultaneous identification of multiple collision threats in an aerial setting, achieving a robust 94% accuracy. this work highlights the potential of radar technology to advance situational awareness in UAVs, facilitating safe and efficient BVLOS operations.
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Transformers-to-Improve-Breast-Cancer-Classification-and-Risk-Assessment-with-Multi-modal-and-Longitudinal-Data"><a href="#Leveraging-Transformers-to-Improve-Breast-Cancer-Classification-and-Risk-Assessment-with-Multi-modal-and-Longitudinal-Data" class="headerlink" title="Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data"></a>Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03217">http://arxiv.org/abs/2311.03217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiqiu Shen, Jungkyu Park, Frank Yeung, Eliana Goldberg, Laura Heacock, Farah Shamout, Krzysztof J. Geras</li>
<li>for: 这个研究旨在验证多modal imaging 技术，以帮助预后预测乳腺癌的可能性。</li>
<li>methods: 这个研究使用了多modal transformer（MMT），一种神经网络，将� Mammo graphy 和 ultrasound 资料融合，以提高癌症检测和预后预测的精度。</li>
<li>results: 在130万个检查数据中，MMT 获得了AUROC 0.943，surpassing strong uni-modal baselines，并且在5年的预后预测中，MMT 获得了AUROC 0.826，outperforming prior mammography-based risk models。<details>
<summary>Abstract</summary>
Breast cancer screening, primarily conducted through mammography, is often supplemented with ultrasound for women with dense breast tissue. However, existing deep learning models analyze each modality independently, missing opportunities to integrate information across imaging modalities and time. In this study, we present Multi-modal Transformer (MMT), a neural network that utilizes mammography and ultrasound synergistically, to identify patients who currently have cancer and estimate the risk of future cancer for patients who are currently cancer-free. MMT aggregates multi-modal data through self-attention and tracks temporal tissue changes by comparing current exams to prior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in detecting existing cancers, surpassing strong uni-modal baselines. For 5-year risk prediction, MMT attains an AUROC of 0.826, outperforming prior mammography-based risk models. Our research highlights the value of multi-modal and longitudinal imaging in cancer diagnosis and risk stratification.
</details>
<details>
<summary>摘要</summary>
乳癌检测通常通过胸部X射线扫描进行，但现有的深度学习模型通常只分析每种成像Modal separately， missed opportunities to integrate信息 across imaging modalities and time。在这项研究中，我们介绍了多Modal Transformer（MMT），一种神经网络，利用胸部X射线和ultrasound synergistically，用于识别当前有 cancer 的患者和估计当前没有 cancer 的患者将来癌症风险。MMT通过自注意力和比较当前检测和前一次检测来聚合多modal数据，并跟踪 temporal tissue changes。我们在130万次检测数据上训练MMT，其AUROC为0.943，超过了强的uni-modal基线。此外，MMT在5年风险预测方面的AUROC为0.826，超过了以往基于胸部X射线的风险模型。我们的研究强调了多modal和长期成像在肿瘤诊断和风险分级中的价值。
</details></li>
</ul>
<hr>
<h2 id="PainSeeker-An-Automated-Method-for-Assessing-Pain-in-Rats-Through-Facial-Expressions"><a href="#PainSeeker-An-Automated-Method-for-Assessing-Pain-in-Rats-Through-Facial-Expressions" class="headerlink" title="PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions"></a>PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03205">http://arxiv.org/abs/2311.03205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liu Liu, Guang Li, Dingfan Deng, Jinhua Yu, Yuan Zong</li>
<li>for: 研究是用来检测实验室老鼠的痛苦吗？</li>
<li>methods: 使用一种名为PainSeeker的深度学习方法，通过脸部表情图像来自动评估老鼠的痛苦程度。</li>
<li>results: 研究表明，可以通过脸部表情图像来评估实验室老鼠的痛苦程度，并且PainSeeker方法可以有效地解决这个问题。<details>
<summary>Abstract</summary>
In this letter, we aim to investigate whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat' facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.
</details>
<details>
<summary>摘要</summary>
《这封信中，我们想 investigating  Whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat's facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.》Here's the word-for-word translation:“这封信中，我们想 investigating  Whether laboratory rats' pain can be automatically assessed through their facial expressions. To this end, we began by presenting a publicly available dataset called RatsPain, consisting of 1,138 facial images captured from six rats that underwent an orthodontic treatment operation. Each rat's facial images in RatsPain were carefully selected from videos recorded either before or after the operation and well labeled by eight annotators according to the Rat Grimace Scale (RGS). We then proposed a novel deep learning method called PainSeeker for automatically assessing pain in rats via facial expressions. PainSeeker aims to seek pain-related facial local regions that facilitate learning both pain discriminative and head pose robust features from facial expression images. To evaluate the PainSeeker, we conducted extensive experiments on the RatsPain dataset. The results demonstrate the feasibility of assessing rats' pain from their facial expressions and also verify the effectiveness of the proposed PainSeeker in addressing this emerging but intriguing problem. The RasPain dataset can be freely obtained from https://github.com/xhzongyuan/RatsPain.”
</details></li>
</ul>
<hr>
<h2 id="LCPR-A-Multi-Scale-Attention-Based-LiDAR-Camera-Fusion-Network-for-Place-Recognition"><a href="#LCPR-A-Multi-Scale-Attention-Based-LiDAR-Camera-Fusion-Network-for-Place-Recognition" class="headerlink" title="LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition"></a>LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03198">http://arxiv.org/abs/2311.03198</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZhouZijie77/LCPR">https://github.com/ZhouZijie77/LCPR</a></li>
<li>paper_authors: Zijie Zhou, Jingyi Xu, Guangming Xiong, Junyi Ma</li>
<li>for: 提高自动驾驶车辆在GPS无效环境中识别环境的精度。</li>
<li>methods: 利用多模态感知器件的拟合技术，将LiDAR点云和多视图RGB图像 fusion 为特征表示。</li>
<li>results: 在nuScenes数据集上测试，我们的方法可以有效地利用多视图摄像头和LiDAR数据进行环境识别，同时具有强大的抗视点变化性。<details>
<summary>Abstract</summary>
Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments. Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors. In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention. However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion. In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment. A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations. We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes. Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR .
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate_language: zh-CN Place recognition is one of the most crucial modules for autonomous vehicles to identify places that were previously visited in GPS-invalid environments. Sensor fusion is considered an effective method to overcome the weaknesses of individual sensors. In recent years, multimodal place recognition fusing information from multiple sensors has gathered increasing attention. However, most existing multimodal place recognition methods only use limited field-of-view camera images, which leads to an imbalance between features from different modalities and limits the effectiveness of sensor fusion. In this paper, we present a novel neural network named LCPR for robust multimodal place recognition, which fuses LiDAR point clouds with multi-view RGB images to generate discriminative and yaw-rotation invariant representations of the environment. A multi-scale attention-based fusion module is proposed to fully exploit the panoramic views from different modalities of the environment and their correlations. We evaluate our method on the nuScenes dataset, and the experimental results show that our method can effectively utilize multi-view camera and LiDAR data to improve the place recognition performance while maintaining strong robustness to viewpoint changes. Our open-source code and pre-trained models are available at https://github.com/ZhouZijie77/LCPR .<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Learning-using-Data-Augmentation-and-Time-Frequency-Transformation-for-Time-Series-Classification"><a href="#Few-shot-Learning-using-Data-Augmentation-and-Time-Frequency-Transformation-for-Time-Series-Classification" class="headerlink" title="Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification"></a>Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03194">http://arxiv.org/abs/2311.03194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Zhendong Pang, Jiangpeng Wang, Teng Li</li>
<li>for: 这 paper 的目的是解决时间序列分类任务中的少量数据问题。</li>
<li>methods: 该 paper 提出了一种基于数据扩展的新少量学习框架，包括时域频域转换和随机磁化生成的 synthetic 图像。此外，paper 还提出了一种序列spectrogram神经网络模型，该模型包括一个使用 1D 径向块 Extract 特征的子网络和另一个使用 2D 径向块 Extract 特征的spectrogram 表示。</li>
<li>results: 在一个amyotrophic lateral sclerosis 数据集和一个风力机磨碎问题数据集上进行了对比研究，结果显示，我们提posed 方法可以达到 93.75% F1 分数和 93.33% 准确率在amyotrophic lateral sclerosis 数据集上，以及 95.48% F1 分数和 95.59% 准确率在风力机磨碎问题数据集上。这表明了我们的方法可以有效地解决时间序列分类中的少量数据问题。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) that tackle the time series classification (TSC) task have provided a promising framework in signal processing. In real-world applications, as a data-driven model, DNNs are suffered from insufficient data. Few-shot learning has been studied to deal with this limitation. In this paper, we propose a novel few-shot learning framework through data augmentation, which involves transformation through the time-frequency domain and the generation of synthetic images through random erasing. Additionally, we develop a sequence-spectrogram neural network (SSNN). This neural network model composes of two sub-networks: one utilizing 1D residual blocks to extract features from the input sequence while the other one employing 2D residual blocks to extract features from the spectrogram representation. In the experiments, comparison studies of different existing DNN models with/without data augmentation are conducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine fault (WTF) dataset. The experimental results manifest that our proposed method achieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48% F1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates its applicability of addressing the few-shot problems for time series classification.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）在时间序列分类任务中提供了一个有前途的框架，在实际应用中，作为数据驱动模型，DNNs受到有限的数据的限制。少数例学习已经被研究以解决这种限制。在这篇论文中，我们提出了一种新的少数例学习框架，通过数据扩充来实现，包括在时间频域和频谱域中进行变换，以及随机缺失生成的synthetic图像生成。此外，我们开发了一种序列spectrogram神经网络（SSNN）。这个神经网络模型由两个子网络组成：一个使用1D径向块来提取输入序列中的特征，另一个使用2D径向块来提取spectrogram表示中的特征。在实验中，我们对不同的现有DNN模型进行了与/无数据扩充的比较研究，并在amyotrophic lateral sclerosis（ALS）数据集和风力机缺陷（WTF）数据集上进行了实验。实验结果表明，我们提出的方法可以在时间序列分类 task中解决少数例学习问题，并达到了93.75%的F1分数和93.33%的准确率在ALS数据集上，以及95.48%的F1分数和95.59%的准确率在WTF数据集上。
</details></li>
</ul>
<hr>
<h2 id="Efficient-and-Low-Footprint-Object-Classification-using-Spatial-Contrast"><a href="#Efficient-and-Low-Footprint-Object-Classification-using-Spatial-Contrast" class="headerlink" title="Efficient and Low-Footprint Object Classification using Spatial Contrast"></a>Efficient and Low-Footprint Object Classification using Spatial Contrast</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03422">http://arxiv.org/abs/2311.03422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Belding, Daniel C. Stumpp, Rajkumar Kubendran</li>
<li>for: 这个研究探讨了一种基于本地空间差异（SC）的事件驱动视觉传感器，并使用了两种不同的阈值技术来实现。</li>
<li>methods: 研究人员使用了论述模拟器来研究这种硬件传感器的性能，并使用了德国交通标志图像集（GTSRB）和知名的深度神经网络（DNN）进行车道标志分类。</li>
<li>results: 研究结果表明，使用空间差异可以有效地捕捉图像中关键的特征，并且可以使用一个简化的二进制神经网络（Binarized MicronNet）来实现高达94.4%的F1分数，相比之下，使用高精度RGB图像和DNN，只能达到56.3%的F1分数。这表明，SC在资源受限的边缘计算环境中具有极大的推荐性。<details>
<summary>Abstract</summary>
Event-based vision sensors traditionally compute temporal contrast that offers potential for low-power and low-latency sensing and computing. In this research, an alternative paradigm for event-based sensors using localized spatial contrast (SC) under two different thresholding techniques, relative and absolute, is investigated. Given the slow maturity of spatial contrast in comparison to temporal-based sensors, a theoretical simulated output of such a hardware sensor is explored. Furthermore, we evaluate traffic sign classification using the German Traffic Sign dataset (GTSRB) with well-known Deep Neural Networks (DNNs). This study shows that spatial contrast can effectively capture salient image features needed for classification using a Binarized DNN with significant reduction in input data usage (at least 12X) and memory resources (17.5X), compared to high precision RGB images and DNN, with only a small loss (~2%) in macro F1-score. Binarized MicronNet achieves an F1-score of 94.4% using spatial contrast, compared to only 56.3% when using RGB input images. Thus, SC offers great promise for deployment in power and resource constrained edge computing environments.
</details>
<details>
<summary>摘要</summary>
事件基于视觉传感器传统上计算时间对比，具有低功耗和低延迟感知和计算的潜在潜力。本研究提出了基于地方化空间对比（SC）的事件基于传感器的一种 alternativa  парадиг，并通过两种不同的阈值技术（相对和绝对）进行调查。由于空间对比 slower 于时间基于传感器，我们使用理论模拟的硬件传感器输出进行研究。此外，我们还使用德国交通标志数据集（GTSRB）和知名的深度神经网络（DNN）进行评估交通标志分类。研究结果表明，使用空间对比可以有效地捕捉图像中重要的特征，并使用 binarized DNN 对输入数据进行压缩，从而降低输入数据的使用量（至少12倍）和内存资源（17.5倍），与高精度RGB图像和 DNN 相比，只有 slight loss（约2%）的macro F1 分数。使用空间对比，Binarized MicronNet 的 F1 分数达94.4%，与使用 RGB 输入图像的56.3%相比，SC 对于具有限制的边缘计算环境而言，具有极大的承诺。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Domain-Decomposition-Translation-for-Enhanced-Medical-Image-Translation-Using-GANs"><a href="#Frequency-Domain-Decomposition-Translation-for-Enhanced-Medical-Image-Translation-Using-GANs" class="headerlink" title="Frequency Domain Decomposition Translation for Enhanced Medical Image Translation Using GANs"></a>Frequency Domain Decomposition Translation for Enhanced Medical Image Translation Using GANs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03175">http://arxiv.org/abs/2311.03175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuhui Wang, Jianwei Zuo, Xuliang Deng, Jiajia Luo</li>
<li>for: 这篇论文的目的是提出一种新的医学图像转换方法，以提高现有的GAN基于方法的图像质量。</li>
<li>methods: 该方法称为频域分解翻译（FDDT），它将原始图像分解成高频成分和低频成分，其中高频成分包含图像细节和特征信息，而低频成分包含图像风格信息。然后，将高频和低频分量的转换结果与原始图像的高频和低频分量进行对齐，以保持图像的标识信息，同时尽量避免风格信息的损害。</li>
<li>results: 作者对MRI图像和自然图像进行了广泛的实验，并使用了多种主流基eline模型进行比较。结果显示，FDDT可以在四个评价指标中提高图像质量，比如Fr&#39;echet医学分割距离、结构相似度、峰值信号噪声比和平均差异。相比主流基eline模型，FDDT可以降低Fr&#39;echet医学分割距离、结构相似度、峰值信号噪声比和平均差异的值，最大降低值分别为24.4%, 4.4%, 5.8%和31%.<details>
<summary>Abstract</summary>
Medical Image-to-image translation is a key task in computer vision and generative artificial intelligence, and it is highly applicable to medical image analysis. GAN-based methods are the mainstream image translation methods, but they often ignore the variation and distribution of images in the frequency domain, or only take simple measures to align high-frequency information, which can lead to distortion and low quality of the generated images. To solve these problems, we propose a novel method called frequency domain decomposition translation (FDDT). This method decomposes the original image into a high-frequency component and a low-frequency component, with the high-frequency component containing the details and identity information, and the low-frequency component containing the style information. Next, the high-frequency and low-frequency components of the transformed image are aligned with the transformed results of the high-frequency and low-frequency components of the original image in the same frequency band in the spatial domain, thus preserving the identity information of the image while destroying as little stylistic information of the image as possible. We conduct extensive experiments on MRI images and natural images with FDDT and several mainstream baseline models, and we use four evaluation metrics to assess the quality of the generated images. Compared with the baseline models, optimally, FDDT can reduce Fr\'echet inception distance by up to 24.4%, structural similarity by up to 4.4%, peak signal-to-noise ratio by up to 5.8%, and mean squared error by up to 31%. Compared with the previous method, optimally, FDDT can reduce Fr\'echet inception distance by up to 23.7%, structural similarity by up to 1.8%, peak signal-to-noise ratio by up to 6.8%, and mean squared error by up to 31.6%.
</details>
<details>
<summary>摘要</summary>
医学图像转换是计算机视觉和生成人工智能领域的关键任务，具有广泛的应用前景。GAN基于方法是主流图像转换方法，但它们经常忽视图像在频率域中的变化和分布，或者只是进行简单的高频信息对齐，这可能导致图像生成的质量低下。为解决这些问题，我们提出了一种新的方法 called frequency domain decomposition translation (FDDT)。这种方法将原始图像分解成高频组件和低频组件，其中高频组件包含细节和标识信息，而低频组件包含风格信息。然后，将高频和低频组件的转换结果与原始图像的高频和低频组件在同一频率域的空间域进行对齐，以保持图像的标识信息，同时尽量保持图像的风格信息。我们对MRI图像和自然图像进行了广泛的实验，并使用了四个评价指标来评估生成图像的质量。与基eline模型相比，FDDT可以降低Fréchet吸引距离、结构相似度、峰值信号噪声比和平均平方误差，分别降低24.4%、4.4%、5.8%和31%。与之前的方法相比，FDDT可以降低Fréchet吸引距离23.7%、结构相似度1.8%、峰值信号噪声比6.8%和31.6%。
</details></li>
</ul>
<hr>
<h2 id="Asymmetric-Masked-Distillation-for-Pre-Training-Small-Foundation-Models"><a href="#Asymmetric-Masked-Distillation-for-Pre-Training-Small-Foundation-Models" class="headerlink" title="Asymmetric Masked Distillation for Pre-Training Small Foundation Models"></a>Asymmetric Masked Distillation for Pre-Training Small Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03149">http://arxiv.org/abs/2311.03149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyu Zhao, Bingkun Huang, Sen Xing, Gangshan Wu, Yu Qiao, Limin Wang</li>
<li>For: This paper focuses on pre-training relatively small vision transformer models for computer vision tasks, with the goal of improving their efficiency and deployment.* Methods: The proposed method is called asymmetric masked distillation (AMD), which uses an asymmetric masking strategy and customized multi-layer feature alignment to pre-train small vision transformer models.* Results: The AMD method achieves 84.6% classification accuracy on IN1K using the ViT-B model, and 73.3% classification accuracy on the Something-in-Something V2 dataset, outperforming the original ViT-B model from VideoMAE. Additionally, the AMD pre-trained models show consistent performance improvement on downstream tasks.<details>
<summary>Abstract</summary>
Self-supervised foundation models have shown great potential in computer vision thanks to the pre-training paradigm of masked autoencoding. Scale is a primary factor influencing the performance of these foundation models. However, these large foundation models often result in high computational cost that might limit their deployment. This paper focuses on pre-training relatively small vision transformer models that could be efficiently adapted to downstream tasks. Specifically, taking inspiration from knowledge distillation in model compression, we propose a new asymmetric masked distillation(AMD) framework for pre-training relatively small models with autoencoding. The core of AMD is to devise an asymmetric masking strategy, where the teacher model is enabled to see more context information with a lower masking ratio, while the student model still with high masking ratio to the original masked pre-training. We design customized multi-layer feature alignment between the teacher encoder and student encoder to regularize the pre-training of student MAE. To demonstrate the effectiveness and versatility of AMD, we apply it to both ImageMAE and VideoMAE for pre-training relatively small ViT models. AMD achieved 84.6% classification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3% classification accuracy using the ViT-B model on the Something-in-Something V2 dataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We also transfer AMD pre-trained models to downstream tasks and obtain consistent performance improvement over the standard pre-training.
</details>
<details>
<summary>摘要</summary>
自我监督基础模型在计算机视觉领域表现出色，这主要归功于预训练方法的掩码自动编码。但是这些大型基础模型经常具有高计算成本，可能限制其部署。本文关注预训练相对小型视图转换器模型，以提高下游任务适应性。具体来说，我们提出了一种新的偏向掩码采样（AMD）框架，用于预训练相对小型模型。AMD框架的核心是设计偏向掩码策略，使老师模型在低掩码比例下看到更多的上下文信息，而学生模型仍然具有高掩码比例。我们设计了特定的多层特征对齐方法，以规范学生MAE的预训练。为证明AMD的效果和多样性，我们应用其于图像MAE和视频MAE中的预训练相对小型ViT模型。AMD在IN1K上达到84.6%的分类精度，而在Something-in-Something V2集合上达到73.3%的分类精度，比原始ViT-B模型提高3.7%。我们还将AMD预训练模型传递到下游任务，并获得了常见性的性能改进。
</details></li>
</ul>
<hr>
<h2 id="Animating-NeRFs-from-Texture-Space-A-Framework-for-Pose-Dependent-Rendering-of-Human-Performances"><a href="#Animating-NeRFs-from-Texture-Space-A-Framework-for-Pose-Dependent-Rendering-of-Human-Performances" class="headerlink" title="Animating NeRFs from Texture Space: A Framework for Pose-Dependent Rendering of Human Performances"></a>Animating NeRFs from Texture Space: A Framework for Pose-Dependent Rendering of Human Performances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03140">http://arxiv.org/abs/2311.03140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Knoll, Wieland Morgenstern, Anna Hilsmann, Peter Eisert</li>
<li>for: 本研究旨在提供一种基于NeRF的高质量、可控的3D人体模型，用于多视图RGB视频中的人体表演控制。</li>
<li>methods: 我们提出了一种新的NeRF基本框架，其中NeRF的辐射场被扭曲到SMPL人体模型上，创建了一个新的表面对应表示。我们的表示可以通过skeletal关节参数来动画，并且可以根据视角来提供pose-dependent的外观。</li>
<li>results: 我们的方法可以在多视图RGB视频中生成高质量的人体表演控制图像，并且可以处理不同的pose和视角。<details>
<summary>Abstract</summary>
Creating high-quality controllable 3D human models from multi-view RGB videos poses a significant challenge. Neural radiance fields (NeRFs) have demonstrated remarkable quality in reconstructing and free-viewpoint rendering of static as well as dynamic scenes. The extension to a controllable synthesis of dynamic human performances poses an exciting research question. In this paper, we introduce a novel NeRF-based framework for pose-dependent rendering of human performances. In our approach, the radiance field is warped around an SMPL body mesh, thereby creating a new surface-aligned representation. Our representation can be animated through skeletal joint parameters that are provided to the NeRF in addition to the viewpoint for pose dependent appearances. To achieve this, our representation includes the corresponding 2D UV coordinates on the mesh texture map and the distance between the query point and the mesh. To enable efficient learning despite mapping ambiguities and random visual variations, we introduce a novel remapping process that refines the mapped coordinates. Experiments demonstrate that our approach results in high-quality renderings for novel-view and novel-pose synthesis.
</details>
<details>
<summary>摘要</summary>
创建高质量可控3D人体模型从多视图RGB视频中是一项重要挑战。神经辐射场（NeRF）已经表现出了惊人的质量，在重建和自由视点渲染的静止和动态场景中。在这篇论文中，我们介绍了一种基于NeRF的新的框架，用于pose-dependent渲染人体表演。在我们的方法中，辐射场被扭曲到SMPL人体模型上，创造了一个新的表面对应表示。我们的表示可以通过提供skeletal关节参数，并将观察点传递给NeRF，以便根据pose而改变外观。为了实现这一点，我们的表示包括UV坐标在 texture map上，以及 query点和 mesh之间的距离。为了实现高效的学习，我们引入了一种新的重映射过程，以修正映射的坐标。实验表明，我们的方法可以实现高质量的新视角和新pose sintesis。
</details></li>
</ul>
<hr>
<h2 id="TAMPAR-Visual-Tampering-Detection-for-Parcel-Logistics-in-Postal-Supply-Chains"><a href="#TAMPAR-Visual-Tampering-Detection-for-Parcel-Logistics-in-Postal-Supply-Chains" class="headerlink" title="TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains"></a>TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply Chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03124">http://arxiv.org/abs/2311.03124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Naumann, Felix Hertlein, Laura Dörr, Kai Furmans</li>
<li>for: 这个论文主要针对的是 послед一个分配阶段的物流货物伪装检测，使用单个RGB图像和现有数据库中的参考图像进行比较，检测可能存在的外观变化。</li>
<li>methods: 该检测管道使用关键点检测来确定包裹的八个角点，并应用投影变换将每个可见的包裹面变换成平行视图。这些视图不受视角的影响，使得在物流链中检测包裹的外观变化变得更加容易。</li>
<li>results: 在我们新收集的TAMPAR数据集上，我们使用了多种经典和深度学习基于变化检测方法进行实验。我们分别测试了关键点和伪装检测，以及它们在一起的检测系统。我们的评估结果显示关键点检测（Keypoint AP 75.76）和伪装检测（81%准确率，F1-Score 0.83）在实际图像上具有扎实的性能。此外，我们还提供了伪装类型、镜头扭曲和视图角度的敏感分析。代码和数据集可以在<a target="_blank" rel="noopener" href="https://a-nau.github.io/tampar%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://a-nau.github.io/tampar中下载。</a><details>
<summary>Abstract</summary>
Due to the steadily rising amount of valuable goods in supply chains, tampering detection for parcels is becoming increasingly important. In this work, we focus on the use-case last-mile delivery, where only a single RGB image is taken and compared against a reference from an existing database to detect potential appearance changes that indicate tampering. We propose a tampering detection pipeline that utilizes keypoint detection to identify the eight corner points of a parcel. This permits applying a perspective transformation to create normalized fronto-parallel views for each visible parcel side surface. These viewpoint-invariant parcel side surface representations facilitate the identification of signs of tampering on parcels within the supply chain, since they reduce the problem to parcel side surface matching with pair-wise appearance change detection. Experiments with multiple classical and deep learning-based change detection approaches are performed on our newly collected TAMpering detection dataset for PARcels, called TAMPAR. We evaluate keypoint and change detection separately, as well as in a unified system for tampering detection. Our evaluation shows promising results for keypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score 0.83) on real images. Furthermore, a sensitivity analysis for tampering types, lens distortion and viewing angles is presented. Code and dataset are available at https://a-nau.github.io/tampar.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unified-Multi-modal-Unsupervised-Representation-Learning-for-Skeleton-based-Action-Understanding"><a href="#Unified-Multi-modal-Unsupervised-Representation-Learning-for-Skeleton-based-Action-Understanding" class="headerlink" title="Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding"></a>Unified Multi-modal Unsupervised Representation Learning for Skeleton-based Action Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03106">http://arxiv.org/abs/2311.03106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huiguanlab/umurl">https://github.com/huiguanlab/umurl</a></li>
<li>paper_authors: Shengkai Sun, Daizong Liu, Jianfeng Dong, Xiaoye Qu, Junyu Gao, Xun Yang, Xun Wang, Meng Wang</li>
<li>for: 提高skeleton-based动作理解的灵活性和可扩展性，适应实际场景中的多种模式输入。</li>
<li>methods: 提出了一种单流承载多模态特征学习框架（UmURL），通过早期融合策略将多 modal 输入融合到单个流中，并通过内部和外部一致性学习约束保证多modal特征具备完整的semantics。</li>
<li>results: EXTENSIVE experiments在三个大规模数据集（NTU-60、NTU-120和PKU-MMD II）上表明，UmURL可以具有高效性和可扩展性，同时在多种下游任务场景中实现新的state-of-the-art表现。<details>
<summary>Abstract</summary>
Unsupervised pre-training has shown great success in skeleton-based action understanding recently. Existing works typically train separate modality-specific models, then integrate the multi-modal information for action understanding by a late-fusion strategy. Although these approaches have achieved significant performance, they suffer from the complex yet redundant multi-stream model designs, each of which is also limited to the fixed input skeleton modality. To alleviate these issues, in this paper, we propose a Unified Multimodal Unsupervised Representation Learning framework, called UmURL, which exploits an efficient early-fusion strategy to jointly encode the multi-modal features in a single-stream manner. Specifically, instead of designing separate modality-specific optimization processes for uni-modal unsupervised learning, we feed different modality inputs into the same stream with an early-fusion strategy to learn their multi-modal features for reducing model complexity. To ensure that the fused multi-modal features do not exhibit modality bias, i.e., being dominated by a certain modality input, we further propose both intra- and inter-modal consistency learning to guarantee that the multi-modal features contain the complete semantics of each modal via feature decomposition and distinct alignment. In this manner, our framework is able to learn the unified representations of uni-modal or multi-modal skeleton input, which is flexible to different kinds of modality input for robust action understanding in practical cases. Extensive experiments conducted on three large-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that UmURL is highly efficient, possessing the approximate complexity with the uni-modal methods, while achieving new state-of-the-art performance across various downstream task scenarios in skeleton-based action representation learning.
</details>
<details>
<summary>摘要</summary>
Recently, unsupervised pre-training has shown great success in skeleton-based action understanding. Existing methods typically train separate modality-specific models and then use a late-fusion strategy to integrate multi-modal information for action understanding. Although these approaches have achieved significant performance, they suffer from complex and redundant multi-stream model designs and are limited to fixed input skeleton modalities.To address these issues, we propose a Unified Multimodal Unsupervised Representation Learning (UmURL) framework, which exploits an efficient early-fusion strategy to jointly encode multi-modal features in a single-stream manner. Instead of designing separate modality-specific optimization processes for uni-modal unsupervised learning, we feed different modality inputs into the same stream with an early-fusion strategy to learn their multi-modal features and reduce model complexity.To ensure that the fused multi-modal features do not exhibit modality bias, we propose both intra- and inter-modal consistency learning to guarantee that the multi-modal features contain the complete semantics of each modal. Our framework is able to learn unified representations of uni-modal or multi-modal skeleton input, which is flexible to different kinds of modality input for robust action understanding in practical cases.Extensive experiments conducted on three large-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that UmURL is highly efficient and achieves new state-of-the-art performance across various downstream task scenarios in skeleton-based action representation learning, with an approximate complexity comparable to uni-modal methods.
</details></li>
</ul>
<hr>
<h2 id="A-survey-and-classification-of-face-alignment-methods-based-on-face-models"><a href="#A-survey-and-classification-of-face-alignment-methods-based-on-face-models" class="headerlink" title="A survey and classification of face alignment methods based on face models"></a>A survey and classification of face alignment methods based on face models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03082">http://arxiv.org/abs/2311.03082</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nordlinglab/facealignment-survey">https://github.com/nordlinglab/facealignment-survey</a></li>
<li>paper_authors: Jagmohan Meher, Hector Allende-Cid, Torbjörn E. M. Nordling</li>
<li>for: 这篇论文旨在对不同的面部模型在面部姿态定位方面进行总结，以适应不同类型的读者（beginner、实践者和研究人员）。</li>
<li>methods: 本文包括不同类型的面部模型的解释和训练，以及如何将面部模型适应新的面部图像。另外，文中还介绍了3D基于的面部模型和深度学习基于的方法，以及它们在极端面 pose 中的应用。</li>
<li>results: 文中发现，3D基于的面部模型在极端面 pose 中具有优势，而深度学习基于的方法则常用热图来表示面部特征。此外，文章还提出了未来面部模型在面部姿态定位领域的可能发展方向。<details>
<summary>Abstract</summary>
A face model is a mathematical representation of the distinct features of a human face. Traditionally, face models were built using a set of fiducial points or landmarks, each point ideally located on a facial feature, i.e., corner of the eye, tip of the nose, etc. Face alignment is the process of fitting the landmarks in a face model to the respective ground truth positions in an input image containing a face. Despite significant research on face alignment in the past decades, no review analyses various face models used in the literature. Catering to three types of readers - beginners, practitioners and researchers in face alignment, we provide a comprehensive analysis of different face models used for face alignment. We include the interpretation and training of the face models along with the examples of fitting the face model to a new face image. We found that 3D-based face models are preferred in cases of extreme face pose, whereas deep learning-based methods often use heatmaps. Moreover, we discuss the possible future directions of face models in the field of face alignment.
</details>
<details>
<summary>摘要</summary>
一个面模型是人脸特征的数学表达。在过去的几十年中，人们使用了一组 fiducial point或标记点来建立面模型，每个点理想地位于人脸中的一个特征处，例如眼角、鼻子的tip等。面对齐是将面模型的标记点与输入图像中的面部特征进行匹配的过程。尽管在过去的几十年中有很大的研究努力，但是没有任何文献对不同的面模型进行了总的分析。为了针对不同类型的读者（ Beginner、实践者和研究者），我们提供了对不同的面模型进行了全面的分析。我们包括面模型的解释和训练以及将面模型适应到新的面图像中的示例。我们发现在极端面pose时，3D基于的面模型被首选，而深度学习基于的方法通常使用热图。此外，我们还讨论了面模型在面对齐领域的未来发展方向。
</details></li>
</ul>
<hr>
<h2 id="CogVLM-Visual-Expert-for-Pretrained-Language-Models"><a href="#CogVLM-Visual-Expert-for-Pretrained-Language-Models" class="headerlink" title="CogVLM: Visual Expert for Pretrained Language Models"></a>CogVLM: Visual Expert for Pretrained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03079">http://arxiv.org/abs/2311.03079</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thudm/cogvlm">https://github.com/thudm/cogvlm</a></li>
<li>paper_authors: Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji Qi, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, Jiazheng Xu, Bin Xu, Juanzi Li, Yuxiao Dong, Ming Ding, Jie Tang</li>
<li>for: 这个论文的目的是提出一个有力量的开源视觉语言基础模型（CogVLM），以便将图像特征与语言模型进行深度融合。</li>
<li>methods: 这篇论文使用了一种名为“可训练的视觉专家模块”，这种模块在语言模型的注意力和FFN层中嵌入，以 bridging the gap between 静止预训练的语言模型和图像Encoder。</li>
<li>results: 根据论文的描述，CogVLM-17B在10个跨模态测试 benchmarck上达到了状态之最好的表现，包括NoCaps、Flicker30k captioning、RefCOCO、RefCOCO+、RefCOCOg、Visual7W、GQA、ScienceQA、VizWiz VQA 和 TDIUC等，并在VQAv2、OKVQA、TextVQA、COCO captioning等测试中排名第2，超过或匹配 PaLI-X 55B。<details>
<summary>Abstract</summary>
We introduce CogVLM, a powerful open-source visual language foundation model. Different from the popular shallow alignment method which maps image features into the input space of language model, CogVLM bridges the gap between the frozen pretrained language model and image encoder by a trainable visual expert module in the attention and FFN layers. As a result, CogVLM enables deep fusion of vision language features without sacrificing any performance on NLP tasks. CogVLM-17B achieves state-of-the-art performance on 10 classic cross-modal benchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+, RefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and ranks the 2nd on VQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X 55B. Codes and checkpoints are available at https://github.com/THUDM/CogVLM.
</details>
<details>
<summary>摘要</summary>
我们介绍CogVLM，一款强大的开源视觉语言基础模型。与流行的浅层对应方法不同，CogVLM通过在注意力和FFN层中添加可训练的视觉专家模块，将图像特征与静止预训练语言模型的输入空间连接起来。这使得CogVLM可以深度融合视觉语言特征，而无需牺牲任何批处语言任务的性能。CogVLM-17B在10个经典跨模态测试 benchmark上达到了状态机器人的表现，包括NoCaps、Flicker30k captioning、RefCOCO、RefCOCO+、RefCOCOg、Visual7W、GQA、ScienceQA、VizWiz VQA和TDIUC，并在VQAv2、OKVQA、TextVQA、COCO captioning等测试上排名第二，超过或匹配PaLI-X 55B。代码和检查点可以在https://github.com/THUDM/CogVLM中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Two-Stage-Generative-Model-with-CycleGAN-and-Joint-Diffusion-for-MRI-based-Brain-Tumor-Detection"><a href="#A-Two-Stage-Generative-Model-with-CycleGAN-and-Joint-Diffusion-for-MRI-based-Brain-Tumor-Detection" class="headerlink" title="A Two-Stage Generative Model with CycleGAN and Joint Diffusion for MRI-based Brain Tumor Detection"></a>A Two-Stage Generative Model with CycleGAN and Joint Diffusion for MRI-based Brain Tumor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03074">http://arxiv.org/abs/2311.03074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhyjsiat/a-two-stage-cyclegan-ve-brats2020">https://github.com/zhyjsiat/a-two-stage-cyclegan-ve-brats2020</a></li>
<li>paper_authors: Wenxin Wang, Zhuo-Xu Cui, Guanxun Cheng, Chentao Cao, Xi Xu, Ziwei Liu, Haifeng Wang, Yulong Qi, Dong Liang, Yanjie Zhu</li>
<li>for: 提高脑肿检测和分割精度</li>
<li>methods:  combinatorial CycleGAN和VE-JP方法</li>
<li>results: 提高检测和分割精度，比如DSC分数为0.8590、0.6226和0.7403等<details>
<summary>Abstract</summary>
Accurate detection and segmentation of brain tumors is critical for medical diagnosis. However, current supervised learning methods require extensively annotated images and the state-of-the-art generative models used in unsupervised methods often have limitations in covering the whole data distribution. In this paper, we propose a novel framework Two-Stage Generative Model (TSGM) that combines Cycle Generative Adversarial Network (CycleGAN) and Variance Exploding stochastic differential equation using joint probability (VE-JP) to improve brain tumor detection and segmentation. The CycleGAN is trained on unpaired data to generate abnormal images from healthy images as data prior. Then VE-JP is implemented to reconstruct healthy images using synthetic paired abnormal images as a guide, which alters only pathological regions but not regions of healthy. Notably, our method directly learned the joint probability distribution for conditional generation. The residual between input and reconstructed images suggests the abnormalities and a thresholding method is subsequently applied to obtain segmentation results. Furthermore, the multimodal results are weighted with different weights to improve the segmentation accuracy further. We validated our method on three datasets, and compared with other unsupervised methods for anomaly detection and segmentation. The DSC score of 0.8590 in BraTs2020 dataset, 0.6226 in ITCS dataset and 0.7403 in In-house dataset show that our method achieves better segmentation performance and has better generalization.
</details>
<details>
<summary>摘要</summary>
当前的超级vised学习方法需要大量的标注图像，而状态对的生成模型通常只能覆盖数据分布的一部分。在这篇论文中，我们提出了一种新的框架Two-Stage Generative Model（TSGM），它将Cycling Generative Adversarial Network（CycleGAN）和Variance Exploding stochastic differential equation using joint probability（VE-JP）相结合以提高脑肿检测和分 segmentation。CycleGAN在无对应数据上训练，将健康图像转化为病态图像作为数据先验。然后，VE-JP被实现，通过使用生成的合理对数据作为引导，重construct健康图像，只有病态区域被修改，而不是健康区域。值得注意的是，我们的方法直接学习了联合分布，从而实现了条件生成。输入图像与重construct图像之间的差异提示病态区域，并采用阈值分割方法获得分 segmentation 结果。此外，我们还将多modal结果权重为不同的权重，以进一步提高分 segmentation 精度。我们在三个数据集上验证了我们的方法，并与其他无supervised方法进行比较。BraTs2020数据集的DSC分数为0.8590，ITCS数据集的DSC分数为0.6226，In-house数据集的DSC分数为0.7403，表明我们的方法在检测和分 segmentation方面表现出色，并且具有更好的泛化性。
</details></li>
</ul>
<hr>
<h2 id="OrthoNets-Orthogonal-Channel-Attention-Networks"><a href="#OrthoNets-Orthogonal-Channel-Attention-Networks" class="headerlink" title="OrthoNets: Orthogonal Channel Attention Networks"></a>OrthoNets: Orthogonal Channel Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03071">http://arxiv.org/abs/2311.03071</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hady1011/orthonets">https://github.com/hady1011/orthonets</a></li>
<li>paper_authors: Hadi Salman, Caleb Parks, Matthew Swan, John Gauch</li>
<li>for: 提高频道注意力机制的效iveness，以实现更好的图像识别和分类。</li>
<li>methods: 使用 randomly initialized orthogonal filters construct an attention mechanism，并将其 integrate into ResNet 网络中。</li>
<li>results: 相比 FcaNet 和其他注意力机制，OrthoNet 在 Birds、MS-COCO 和 Places356  dataset 上显示出较好的性能，并在 ImageNet  dataset 上与当前状态的艺术品级别竞争。 Our results suggest that a sufficient number of orthogonal filters can achieve generalization, and we also explore other general principles for implementing channel attention.<details>
<summary>Abstract</summary>
Designing an effective channel attention mechanism implores one to find a lossy-compression method allowing for optimal feature representation. Despite recent progress in the area, it remains an open problem. FcaNet, the current state-of-the-art channel attention mechanism, attempted to find such an information-rich compression using Discrete Cosine Transforms (DCTs). One drawback of FcaNet is that there is no natural choice of the DCT frequencies. To circumvent this issue, FcaNet experimented on ImageNet to find optimal frequencies. We hypothesize that the choice of frequency plays only a supporting role and the primary driving force for the effectiveness of their attention filters is the orthogonality of the DCT kernels. To test this hypothesis, we construct an attention mechanism using randomly initialized orthogonal filters. Integrating this mechanism into ResNet, we create OrthoNet. We compare OrthoNet to FcaNet (and other attention mechanisms) on Birds, MS-COCO, and Places356 and show superior performance. On the ImageNet dataset, our method competes with or surpasses the current state-of-the-art. Our results imply that an optimal choice of filter is elusive and generalization can be achieved with a sufficiently large number of orthogonal filters. We further investigate other general principles for implementing channel attention, such as its position in the network and channel groupings. Our code is publicly available at https://github.com/hady1011/OrthoNets/
</details>
<details>
<summary>摘要</summary>
设计有效的通道注意机制需要一种lossy压缩方法，以便获得最佳特征表示。尽管最近在这一领域的进步很大，但这仍然是一个开放的问题。FcaNet，当前状态的ARTchannel attention机制，使用Discrete Cosine Transforms（DCTs）来找到信息充足的压缩。FcaNet的一个缺点是没有自然的DCT频率选择。为了解决这个问题，FcaNet在ImageNet上进行了实验以找到最佳频率。我们假设，选择的频率只是支持角色，主要的驱动力是DCT核心的正交性。为了测试这个假设，我们构建了一个使用随机初始化的正交滤波器的注意机制。将这种机制 integrate into ResNet，我们创建了OrthoNet。我们比较OrthoNet与FcaNet（以及其他注意机制）在Birds、MS-COCO和Places356上的性能，并显示其性能较好。在ImageNet dataset上，我们的方法与当前状态的艺术品级别竞争。我们的结果表明，选择的滤波器是找不到的，并且通过 sufficient number of orthogonal filters 可以实现总体化。我们进一步调查了其他实现 channel attention 的一般原则，如其在网络中的位置和通道分组。我们的代码在https://github.com/hady1011/OrthoNets/上公开 available。
</details></li>
</ul>
<hr>
<h2 id="Forest-aboveground-biomass-estimation-using-GEDI-and-earth-observation-data-through-attention-based-deep-learning"><a href="#Forest-aboveground-biomass-estimation-using-GEDI-and-earth-observation-data-through-attention-based-deep-learning" class="headerlink" title="Forest aboveground biomass estimation using GEDI and earth observation data through attention-based deep learning"></a>Forest aboveground biomass estimation using GEDI and earth observation data through attention-based deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03067">http://arxiv.org/abs/2311.03067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenquan Dong, Edward T. A. Mitchard, Hao Yu, Steven Hancock, Casey M. Ryan</li>
<li>for: 这个研究的目的是精确量度森林上空的生物质量（AGB），以了解气候变革的碳会计。</li>
<li>methods: 这个研究使用了开源的卫星数据，包括GEDI LiDAR数据、C-band Sentinel-1 SAR数据、ALOS-2 PALSAR-2数据和Sentinel-2多спектル数据，并使用了注意力对应深度学习模型（AU）进行森林AGB估算。</li>
<li>results: 这个研究发现，使用AU模型可以实现森林AGB估算的高精度，其R2值为0.66，RMSE值为43.66吨&#x2F;公顷，偏差值为0.14吨&#x2F;公顷，而传统的RF算法则有较低的R2值、RMSE值和偏差值。此外，这个研究还发现AU模型在不使用空间信息时也可以获得高精度的结果。<details>
<summary>Abstract</summary>
Accurate quantification of forest aboveground biomass (AGB) is critical for understanding carbon accounting in the context of climate change. In this study, we presented a novel attention-based deep learning approach for forest AGB estimation, primarily utilizing openly accessible EO data, including: GEDI LiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2 multispectral data. The attention UNet (AU) model achieved markedly higher accuracy for biomass estimation compared to the conventional RF algorithm. Specifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and bias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87 Mg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning approach was not uniformly observed across all tested models. ResNet101 only achieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1, while the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a substantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in the absence of spatial information, fully connected (FC) layers were employed to eliminate spatial information from the remote sensing data. AU-FC achieved intermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1, outperforming RF but underperforming AU model using spatial information. We also generated 10m forest AGB maps across Guangdong for the year 2019 using AU and compared it with that produced by RF. The AGB distributions from both models showed strong agreement with similar mean values; the mean forest AGB estimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1. Additionally, it was observed that the AGB map generated by AU provided superior spatial information. Overall, this research substantiates the feasibility of employing deep learning for biomass estimation based on satellite data.
</details>
<details>
<summary>摘要</summary>
准确量化林地上部生物质（AGB）的估算对于气候变化的 carbon 账户有着重要的意义。在这个研究中，我们提出了一种基于 Deep Learning 的新型注意力模型（AU），主要利用开放访问的 Earth Observation（EO）数据，包括：GEDI LiDAR 数据、C-band Sentinel-1 SAR 数据、ALOS-2 PALSAR-2 数据和 Sentinel-2 多spectral 数据。AU 模型在生物质估算中显示出了明显更高的准确度，与传统的 Random Forest 算法相比。具体来说，AU 模型的 R2 为 0.66，RMSE 为 43.66 Mg ha-1，偏差为 0.14 Mg ha-1，而 Random Forest 算法的 R2 为 0.62，RMSE 为 45.87 Mg ha-1，偏差为 1.09 Mg ha-1。然而，深度学习方法的优势不uniformly 分布于所测试的모дели中。ResNet101 模型只有 R2 为 0.50，RMSE 为 52.93 Mg ha-1，偏差为 0.99 Mg ha-1，而 UNet 模型 Reported R2 为 0.65，RMSE 为 44.28 Mg ha-1，并且偏差为 1.84 Mg ha-1。此外，为了探讨 AU 模型在不含空间信息的情况下的性能，我们使用了全连接（FC）层来消除 remote sensing 数据中的空间信息。AU-FC 模型的 R2 为 0.64，RMSE 为 44.92 Mg ha-1，偏差为 -0.56 Mg ha-1，与 Random Forest 算法相比，表现较佳。此外，我们还使用 AU 模型生成了2019年广东省的10米森林AGB地图，并与 Random Forest 算法生成的地图进行了比较。两个模型的 AGB 分布显示了强相关性，两者的平均森林AGB估算值也类似，AU 模型的 Mean Forest AGB 为 102.18 Mg ha-1，Random Forest 算法的 Mean Forest AGB 为 104.84 Mg ha-1。此外，AU 模型生成的 AGB 地图提供了较好的空间信息。总的来说，这项研究证明了深度学习可以为基于卫星数据的生物质估算提供可靠的方法。
</details></li>
</ul>
<hr>
<h2 id="AnyText-Multilingual-Visual-Text-Generation-And-Editing"><a href="#AnyText-Multilingual-Visual-Text-Generation-And-Editing" class="headerlink" title="AnyText: Multilingual Visual Text Generation And Editing"></a>AnyText: Multilingual Visual Text Generation And Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03054">http://arxiv.org/abs/2311.03054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Tuo, Wangmeng Xiang, Jun-Yan He, Yifeng Geng, Xuansong Xie</li>
<li>for: 这个研究旨在提高文本与图像之间的融合，以实现高精度的文本生成和修改。</li>
<li>methods: 这个研究使用了一个散射管道，包括两个主要元素：auxiliary latent module和text embedding module。auxiliary latent module使用文本glyph、位置和对像图像来生成潜在特征，而text embedding module使用OCR模型将roke数据转换为嵌入，与图像描述嵌入结合以生成文本。</li>
<li>results: 这个研究的方法在训练后，与其他方法相比，具有了很大的进步。此外，这个研究还提供了一个大规模的多种语言文本图像集（AnyWord-3M），并提出了AnyText-benchmark来评估文本生成质量和精度。<details>
<summary>Abstract</summary>
Diffusion model based Text-to-Image has achieved impressive achievements recently. Although current technology for synthesizing images is highly advanced and capable of generating images with high fidelity, it is still possible to give the show away when focusing on the text area in the generated image. To address this issue, we introduce AnyText, a diffusion-based multilingual visual text generation and editing model, that focuses on rendering accurate and coherent text in the image. AnyText comprises a diffusion pipeline with two primary elements: an auxiliary latent module and a text embedding module. The former uses inputs like text glyph, position, and masked image to generate latent features for text generation or editing. The latter employs an OCR model for encoding stroke data as embeddings, which blend with image caption embeddings from the tokenizer to generate texts that seamlessly integrate with the background. We employed text-control diffusion loss and text perceptual loss for training to further enhance writing accuracy. AnyText can write characters in multiple languages, to the best of our knowledge, this is the first work to address multilingual visual text generation. It is worth mentioning that AnyText can be plugged into existing diffusion models from the community for rendering or editing text accurately. After conducting extensive evaluation experiments, our method has outperformed all other approaches by a significant margin. Additionally, we contribute the first large-scale multilingual text images dataset, AnyWord-3M, containing 3 million image-text pairs with OCR annotations in multiple languages. Based on AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual text generation accuracy and quality. Our project will be open-sourced on https://github.com/tyxsspa/AnyText to improve and promote the development of text generation technology.
</details>
<details>
<summary>摘要</summary>
simplified Chinese:现代文本描述技术在最近几年来已经取得了很大的进步，尤其是在生成图像时的文本描述方面。然而，当注意力集中在生成图像中的文本区域时，仍然存在可能给出显示的问题。为解决这个问题，我们介绍了 AnyText，一种基于扩散的多语言视觉文本生成和编辑模型，它专注于在图像中生成准确和一致的文本。AnyText包括一个扩散管道，其中包括两个主要元素：一个辅助隐藏模块和一个文本嵌入模块。前者使用文本字形、位置和遮盲图像作为输入，生成隐藏特征 для文本生成或编辑。后者使用 OCR 模型对笔画数据进行编码，将其混合到图像caption embedding 中，以生成文本与背景相协同的文本。我们在训练时使用文本扩散损失和文本感知损失，以进一步提高文本准确性。AnyText 可以在多种语言中写字符，我们知道这是首次对多语言视觉文本生成进行研究。值得一提的是，AnyText 可以与社区已有的扩散模型结合使用，以提供更高的文本准确性。经过广泛的评估实验，我们的方法在所有其他方法之上出现了显著的优势。此外，我们还提供了首个大规模多语言文本图像集 AnyWord-3M，包含 3000 万个图像文本对，其中每个对包含多种语言的 OCR 注释。基于 AnyWord-3M 数据集，我们提出 AnyText-benchmark，用于评估视觉文本生成准确性和质量。我们的项目将在 https://github.com/tyxsspa/AnyText 上开源，以便改进和推动文本生成技术的发展。
</details></li>
</ul>
<hr>
<h2 id="MixUp-MIL-A-Study-on-Linear-Multilinear-Interpolation-Based-Data-Augmentation-for-Whole-Slide-Image-Classification"><a href="#MixUp-MIL-A-Study-on-Linear-Multilinear-Interpolation-Based-Data-Augmentation-for-Whole-Slide-Image-Classification" class="headerlink" title="MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data Augmentation for Whole Slide Image Classification"></a>MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data Augmentation for Whole Slide Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03052">http://arxiv.org/abs/2311.03052</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Gadermayr, Lukas Koller, Maximilian Tschuchnig, Lea Maria Stangassinger, Christina Kreutzer, Sebastien Couillard-Despres, Gertie Janneke Oostingh, Anton Hittmair</li>
<li>for: 本研究旨在 investigate linear and multilinear interpolation between feature vectors, a data augmentation technique, 用于提高分类网络和多例学习的总体表现。</li>
<li>methods: 本研究使用了10个不同的数据集配置、两种不同的特征提取方法（一种是supervised，另一种是self-supervised）、染料normalization，以及两种多例学习架构进行实验。</li>
<li>results: 研究发现了该方法在不同的数据集和特征提取方法下 exhibit EXTRAORDINARILY HIGH variability，并且identified several interesting aspects to bring light into the darkness, 以及 novelfields of research。<details>
<summary>Abstract</summary>
For classifying digital whole slide images in the absence of pixel level annotation, typically multiple instance learning methods are applied. Due to the generic applicability, such methods are currently of very high interest in the research community, however, the issue of data augmentation in this context is rarely explored. Here we investigate linear and multilinear interpolation between feature vectors, a data augmentation technique, which proved to be capable of improving the generalization performance classification networks and also for multiple instance learning. Experiments, however, have been performed on only two rather small data sets and one specific feature extraction approach so far and a strong dependence on the data set has been identified. Here we conduct a large study incorporating 10 different data set configurations, two different feature extraction approaches (supervised and self-supervised), stain normalization and two multiple instance learning architectures. The results showed an extraordinarily high variability in the effect of the method. We identified several interesting aspects to bring light into the darkness and identified novel promising fields of research.
</details>
<details>
<summary>摘要</summary>
Experiments have been performed on only two small data sets and one specific feature extraction approach so far, and a strong dependence on the data set has been identified. In this study, we conduct a large study incorporating 10 different data set configurations, two different feature extraction approaches (supervised and self-supervised), stain normalization, and two multiple instance learning architectures.The results showed an extraordinarily high variability in the effect of the method. We identified several interesting aspects to bring light into the darkness and identified novel promising fields of research.Translation in Simplified Chinese:为了针对无法获得像素级别标注的数字整体图像进行分类，通常使用多个实例学习方法。由于其普适性，这些方法目前在研究社区中具有很高的兴趣。然而，在这种情况下数据增强的问题很少被探讨。我们在这里investigate linear和多线性 interpolate between feature vectors，一种数据增强技术，已经证明可以提高分类网络和多个实例学习的总体化性能。尝试在只有两个较小数据集和一种特定的特征提取方法上进行了实验，并且发现数据集强度的依赖性。在这里，我们进行了一项大规模的研究，包括10个不同的数据集配置、两种不同的特征提取方法（可视和自动化）、染色 нормализа化以及两种多个实例学习架构。结果表明了非常高的变化程度，我们分析了一些有趣的方面，并发现了一些新的可能性。
</details></li>
</ul>
<hr>
<h2 id="COLA-COarse-LAbel-multi-source-LiDAR-semantic-segmentation-for-autonomous-driving"><a href="#COLA-COarse-LAbel-multi-source-LiDAR-semantic-segmentation-for-autonomous-driving" class="headerlink" title="COLA: COarse-LAbel multi-source LiDAR semantic segmentation for autonomous driving"></a>COLA: COarse-LAbel multi-source LiDAR semantic segmentation for autonomous driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03017">http://arxiv.org/abs/2311.03017</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jules Sanchez, Jean-Emmanuel Deschaud, François Goulette</li>
<li>for: 本研究旨在提高LiDAR semantic segmentation中的自动驾驶性能。</li>
<li>methods: 本研究使用多源训练方法，利用多个数据集进行训练，以提高域泛化、源到源分类和预训练等三个子领域的结果。</li>
<li>results: 研究显示，使用多源训练方法可以提高域泛化 (+10%), source-to-source分类 (+5.3%), 和预训练 (+12%)等三个方面的结果。<details>
<summary>Abstract</summary>
LiDAR semantic segmentation for autonomous driving has been a growing field of interest in the past few years. Datasets and methods have appeared and expanded very quickly, but methods have not been updated to exploit this new availability of data and continue to rely on the same classical datasets.   Different ways of performing LIDAR semantic segmentation training and inference can be divided into several subfields, which include the following: domain generalization, the ability to segment data coming from unseen domains ; source-to-source segmentation, the ability to segment data coming from the training domain; and pre-training, the ability to create re-usable geometric primitives.   In this work, we aim to improve results in all of these subfields with the novel approach of multi-source training. Multi-source training relies on the availability of various datasets at training time and uses them together rather than relying on only one dataset.   To overcome the common obstacles found for multi-source training, we introduce the coarse labels and call the newly created multi-source dataset COLA. We propose three applications of this new dataset that display systematic improvement over single-source strategies: COLA-DG for domain generalization (up to +10%), COLA-S2S for source-to-source segmentation (up to +5.3%), and COLA-PT for pre-training (up to +12%).
</details>
<details>
<summary>摘要</summary>
隐藏的文本雷达semantic segmentation для自动驾驶在过去几年内得到了广泛关注。 datasets和方法在短时间内出现和扩展了，但方法没有更新以利用这些新的数据，而是仍然依赖于传统的数据集。 不同的雷达semantic segmentation训练和推断方法可以分为以下几个子领域：领域泛化、来自训练领域的数据排序和预训练。 在这项工作中，我们想要在所有这些子领域中提高结果，使用新的多源训练方法。 多源训练利用训练时可用的多个数据集，而不是仅仅依赖于一个数据集。 为了解决多源训练中常见的障碍，我们引入了粗略标签，并将其与多源数据集称为COLA。 我们提出了三个COLA数据集的应用，其中COLA-DG用于领域泛化（最高提高+10%），COLA-S2S用于来自源到源的排序（最高提高+5.3%），COLA-PT用于预训练（最高提高+12%）。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Capability-of-Text-to-Image-Diffusion-Models-with-Structural-Edge-Guidance-for-Multi-Spectral-Satellite-Image-Inpainting"><a href="#Exploring-the-Capability-of-Text-to-Image-Diffusion-Models-with-Structural-Edge-Guidance-for-Multi-Spectral-Satellite-Image-Inpainting" class="headerlink" title="Exploring the Capability of Text-to-Image Diffusion Models with Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting"></a>Exploring the Capability of Text-to-Image Diffusion Models with Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.03008">http://arxiv.org/abs/2311.03008</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikolaj Czerkawski, Christos Tachtatzis</li>
<li>for:  investigate the utility of text-to-image inpainting models for satellite image data</li>
<li>methods: introduce a novel inpainting framework based on StableDiffusion and ControlNet, as well as a novel method for RGB-to-MSI translation</li>
<li>results: the inpainting synthesized via StableDiffusion suffers from undesired artefacts, and a simple alternative of self-supervised internal inpainting achieves higher quality of synthesis<details>
<summary>Abstract</summary>
The paper investigates the utility of text-to-image inpainting models for satellite image data. Two technical challenges of injecting structural guiding signals into the generative process as well as translating the inpainted RGB pixels to a wider set of MSI bands are addressed by introducing a novel inpainting framework based on StableDiffusion and ControlNet as well as a novel method for RGB-to-MSI translation. The results on a wider set of data suggest that the inpainting synthesized via StableDiffusion suffers from undesired artefacts and that a simple alternative of self-supervised internal inpainting achieves higher quality of synthesis.
</details>
<details>
<summary>摘要</summary>
文章研究文本到图像填充模型在卫星图像数据中的实用性。两个技术挑战，即在生成过程中涂入结构导向信号以及将RGB像素翻译到更广泛的MSI频谱中，通过引入稳定扩散和控制网络以及RGB到MSI翻译方法来解决。研究结果表明，通过稳定扩散生成的图像填充存在不良artefacts，而自我超vised内部填充方法可以获得更高质量的生成结果。
</details></li>
</ul>
<hr>
<h2 id="Zero-Shot-Enhancement-of-Low-Light-Image-Based-on-Retinex-Decomposition"><a href="#Zero-Shot-Enhancement-of-Low-Light-Image-Based-on-Retinex-Decomposition" class="headerlink" title="Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition"></a>Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02995">http://arxiv.org/abs/2311.02995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenchao Li, Bangshu Xiong, Qiaofeng Ou, Xiaoyun Long, Jinhao Zhu, Jiabao Chen, Shuyuan Wen</li>
<li>for: 提高低光照图像的显示质量，同时解决阴影、噪声、色偏和对比等问题。</li>
<li>methods: 提出了一种基于学习的Retinex分解方法，称为ZERRINNet，使用N-Net网络和噪声损失函数来除噪推优原始低光照图像，同时使用RI-Net网络和текxture损失函数来约束反射组件和照明组件的优化。</li>
<li>results: 在一个自制的实际低光照数据集上进行了有效验证，并在面部检测、目标识别和实例分割等高级视觉任务上达到了比较出色的表现。与现有状态艺术方法相比，其总体性能得到了进一步提高。代码可以在<a target="_blank" rel="noopener" href="https://github.com/liwenchao0615/ZERRINNet%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/liwenchao0615/ZERRINNet中下载。</a><details>
<summary>Abstract</summary>
Two difficulties here make low-light image enhancement a challenging task; firstly, it needs to consider not only luminance restoration but also image contrast, image denoising and color distortion issues simultaneously. Second, the effectiveness of existing low-light enhancement methods depends on paired or unpaired training data with poor generalization performance.   To solve these difficult problems, we propose in this paper a new learning-based Retinex decomposition of zero-shot low-light enhancement method, called ZERRINNet. To this end, we first designed the N-Net network, together with the noise loss term, to be used for denoising the original low-light image by estimating the noise of the low-light image. Moreover, RI-Net is used to estimate the reflection component and illumination component, and in order to solve the color distortion and contrast, we use the texture loss term and segmented smoothing loss to constrain the reflection component and illumination component. Finally, our method is a zero-reference enhancement method that is not affected by the training data of paired and unpaired datasets, so our generalization performance is greatly improved, and in the paper, we have effectively validated it with a homemade real-life low-light dataset and additionally with advanced vision tasks, such as face detection, target recognition, and instance segmentation. We conducted comparative experiments on a large number of public datasets and the results show that the performance of our method is competitive compared to the current state-of-the-art methods. The code is available at:https://github.com/liwenchao0615/ZERRINNet
</details>
<details>
<summary>摘要</summary>
两个问题使得低光照图像改善成为一项具有挑战性的任务：首先，它需要同时考虑照明修复、图像对比、雷达噪声和颜色扭曲问题。其次，现有的低光照改善方法的效果取决于对配对或非配对训练数据的训练，而且其泛化性不强。为解决这些困难问题，我们在本文提出了一种新的学习基于的Retinex分解 zero-shot 低光照改善方法，称为ZERRINNet。为此，我们首先设计了N-Net网络，并与噪声损失项一起用于对原始低光照图像进行降噪。此外，我们使用RI-Net来估算反射Component和照明Component，并使用文本损失项和分割平滑损失项来约束反射Component和照明Component，以解决颜色扭曲和对比问题。最后，我们的方法是一种零参考改善方法，不受配对和非配对训练数据的影响，因此我们的泛化性得到了大幅提高。在论文中，我们有效地验证了它的可靠性，使用自己制作的实际低光照 dataset 和高级视觉任务，如人脸检测、目标识别和实例 segmentation。我们进行了大量的公共数据集的比较实验，结果显示，我们的方法与当前状态艺的方法竞争。代码可以在：https://github.com/liwenchao0615/ZERRINNet 中获取
</details></li>
</ul>
<hr>
<h2 id="NEURO-HAND-A-weakly-supervised-Hierarchical-Attention-Network-for-neuroimaging-abnormality-Detection"><a href="#NEURO-HAND-A-weakly-supervised-Hierarchical-Attention-Network-for-neuroimaging-abnormality-Detection" class="headerlink" title="NEURO HAND: A weakly supervised Hierarchical Attention Network for neuroimaging abnormality Detection"></a>NEURO HAND: A weakly supervised Hierarchical Attention Network for neuroimaging abnormality Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02992">http://arxiv.org/abs/2311.02992</a></li>
<li>repo_url: None</li>
<li>paper_authors: David A. Wood</li>
<li>for: 这份研究是为了探讨临床神经成像数据的自然层次结构，并提出了一种 Hierarchical Attention Network 来检测 MRI 扫描数据。</li>
<li>methods: 这个方法使用了 Hierarchical Attention Network，适用于非体积数据（即高分辨率 MRI 扫描堆），并可以从二分类评估级别 labels 进行训练。</li>
<li>results: 研究结果显示，这个方法可以提高分类精度，并提供了解释性的 coarse inter-和 intra-slice 异常地点位置，或者给出了不同层次的 slice 和序列之间的重要性分数，使得这个模型适合用于自动化诊断系统。<details>
<summary>Abstract</summary>
Clinical neuroimaging data is naturally hierarchical. Different magnetic resonance imaging (MRI) sequences within a series, different slices covering the head, and different regions within each slice all confer different information. In this work we present a hierarchical attention network for abnormality detection using MRI scans obtained in a clinical hospital setting. The proposed network is suitable for non-volumetric data (i.e. stacks of high-resolution MRI slices), and can be trained from binary examination-level labels. We show that this hierarchical approach leads to improved classification, while providing interpretability through either coarse inter- and intra-slice abnormality localisation, or giving importance scores for different slices and sequences, making our model suitable for use as an automated triaging system in radiology departments.
</details>
<details>
<summary>摘要</summary>
临床神经成像数据自然具有层次结构。不同的磁共振成像（MRI）序列内一系列、不同的slice覆盖头部、和每个slice中的不同区域都提供不同的信息。在这项工作中，我们提出了一种层次注意力网络用于使用临床医院设备获取的MRI扫描数据中的异常检测。我们的提案的网络适用于非核Volume数据（即高分辨率MRI slice栈），并可以从二进制诊断级别标签进行训练。我们表明，这种层次方法可以提高分类效果，同时提供可读性，通过 Either coarse inter-和intra-slice异常定位或给出不同的slice和序列的重要性分数，使我们的模型适用于 radiology部门的自动化排序系统。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-based-Radiotherapy-Dose-Prediction-Guided-by-Inter-slice-Aware-Structure-Encoding"><a href="#Diffusion-based-Radiotherapy-Dose-Prediction-Guided-by-Inter-slice-Aware-Structure-Encoding" class="headerlink" title="Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware Structure Encoding"></a>Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware Structure Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02991">http://arxiv.org/abs/2311.02991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenghao Feng, Lu Wen, Jianghong Xiao, Yuanyuan Xu, Xi Wu, Jiliu Zhou, Xingchen Peng, Yan Wang</li>
<li>for: 这个研究目的是为了提高放射治疗规划中的剂量分布预测，并且提高效率和质量。</li>
<li>methods: 这种方法使用了散射模型，包括前向过程和反向过程。在前向过程中，DiffDose将剂量分布图Transform into pure Gaussian noise，并且同时训练了噪音预测器来估计添加的噪音。在反向过程中，它逐步除去噪音，最后输出预测的剂量分布图。</li>
<li>results: 这种方法可以有效地解决传统方法中的过度平滑问题，并且提高预测的精度和稳定性。<details>
<summary>Abstract</summary>
Deep learning (DL) has successfully automated dose distribution prediction in radiotherapy planning, enhancing both efficiency and quality. However, existing methods suffer from the over-smoothing problem for their commonly used L1 or L2 loss with posterior average calculations. To alleviate this limitation, we propose a diffusion model-based method (DiffDose) for predicting the radiotherapy dose distribution of cancer patients. Specifically, the DiffDose model contains a forward process and a reverse process. In the forward process, DiffDose transforms dose distribution maps into pure Gaussian noise by gradually adding small noise and a noise predictor is simultaneously trained to estimate the noise added at each timestep. In the reverse process, it removes the noise from the pure Gaussian noise in multiple steps with the well-trained noise predictor and finally outputs the predicted dose distribution maps...
</details>
<details>
<summary>摘要</summary>
深度学习（DL）已成功地自动预测辐射规划中的剂量分布，提高了效率和质量。然而，现有方法受到L1或L2损失函数的过滤问题的限制。为了解决这个限制，我们提出了基于扩散模型的剂量分布预测方法（DiffDose）。具体来说，DiffDose模型包括一个前进过程和一个反向过程。在前进过程中，DiffDose将剂量分布图转换成纯 Gaussian 噪声，通过逐步添加小噪声并同时训练噪声预测器来预测噪声添加的每个时间步。在反向过程中，它将纯 Gaussian 噪声中的噪声除掉，并在多个步骤中使用已经训练好的噪声预测器来除掉噪声，最后输出预测的剂量分布图。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Deep-Representation-Learning-via-Layerwise-Feature-Compression-and-Discrimination"><a href="#Understanding-Deep-Representation-Learning-via-Layerwise-Feature-Compression-and-Discrimination" class="headerlink" title="Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination"></a>Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02960">http://arxiv.org/abs/2311.02960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu</li>
<li>for: 本研究探讨了深度学习网络在层次结构中如何实现特征学习。</li>
<li>methods: 作者使用了深度Linear Network（DLN）来研究输入数据如何在每层训练后变换为特征。</li>
<li>results: 研究发现，在输入数据几乎正交的情况下，每层DLN都会在内类压缩和间类分化方面进行抽象，并且这种抽象会逐层增长。此外，研究还发现这种特征演化pattern在深度非线性网络中也存在，并且与现有的实验研究相吻合。此外，研究还展示了这些结果在转移学习中的实际应用。<details>
<summary>Abstract</summary>
Over the past decade, deep learning has proven to be a highly effective tool for learning meaningful features from raw data. However, it remains an open question how deep networks perform hierarchical feature learning across layers. In this work, we attempt to unveil this mystery by investigating the structures of intermediate features. Motivated by our empirical findings that linear layers mimic the roles of deep layers in nonlinear networks for feature learning, we explore how deep linear networks transform input data into output by investigating the output (i.e., features) of each layer after training in the context of multi-class classification problems. Toward this goal, we first define metrics to measure within-class compression and between-class discrimination of intermediate features, respectively. Through theoretical analysis of these two metrics, we show that the evolution of features follows a simple and quantitative pattern from shallow to deep layers when the input data is nearly orthogonal and the network weights are minimum-norm, balanced, and approximate low-rank: Each layer of the linear network progressively compresses within-class features at a geometric rate and discriminates between-class features at a linear rate with respect to the number of layers that data have passed through. To the best of our knowledge, this is the first quantitative characterization of feature evolution in hierarchical representations of deep linear networks. Empirically, our extensive experiments not only validate our theoretical results numerically but also reveal a similar pattern in deep nonlinear networks which aligns well with recent empirical studies. Moreover, we demonstrate the practical implications of our results in transfer learning. Our code is available at \url{https://github.com/Heimine/PNC_DLN}.
</details>
<details>
<summary>摘要</summary>
过去一个 décennia，深度学习已经证明是一种非常有效的工具，可以从原始数据中学习有意义的特征。然而，仍然是一个打开的问题，深度网络在层次结构上如何进行层次特征学习。在这项工作中，我们尝试了解这个谜题，通过分析层次结构的中间特征来研究深度网络如何将输入数据转化为输出。为此，我们首先定义了内部特征的压缩和 между类特征的分化度量，并通过理论分析这两个度量，证明了深度线性网络中每层的特征演化遵循简单和量化的模式：在输入数据几乎正交的情况下，网络参数是最小二乘、均衡的和近似低维的情况下，每层的线性网络会逐步压缩内类特征，并在数据流过多层的情况下，分化between类特征。我们认为这是深度线性网络层次表示的特征演化的首次量化特征化。我们的实验结果不仅verify了我们的理论结果，还发现深度非线性网络中的特征演化呈现类似的模式，与最近的实验研究相吻合。此外，我们还展示了我们的结果在转移学习中的实践意义。我们的代码可以在<https://github.com/Heimine/PNC_DLN>上获取。
</details></li>
</ul>
<hr>
<h2 id="Multi-view-learning-for-automatic-classification-of-multi-wavelength-auroral-images"><a href="#Multi-view-learning-for-automatic-classification-of-multi-wavelength-auroral-images" class="headerlink" title="Multi-view learning for automatic classification of multi-wavelength auroral images"></a>Multi-view learning for automatic classification of multi-wavelength auroral images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02947">http://arxiv.org/abs/2311.02947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiuju Yang, Hang Su, Lili Liu, Yixuan Wang, Ze-Jun Hu</li>
<li>for:  auroral classification  auroral classification  Auroral classification plays a crucial role in polar research.</li>
<li>methods:  multi-wavelength fusion classification network, MLCNet, based on a multi-view approach.  including lightweight feature extraction backbone, called LCTNet, and a novel multi-scale reconstructed feature module named MSRM.</li>
<li>results:  fusion of multi-wavelength information effectively improves the auroral classification performance.  Specifically, our approach achieves state-of-the-art classification accuracy compared to previous auroral classification studies, and superior results in terms of accuracy and computational efficiency compared to existing multi-view methods.<details>
<summary>Abstract</summary>
Auroral classification plays a crucial role in polar research. However, current auroral classification studies are predominantly based on images taken at a single wavelength, typically 557.7 nm. Images obtained at other wavelengths have been comparatively overlooked, and the integration of information from multiple wavelengths remains an underexplored area. This limitation results in low classification rates for complex auroral patterns. Furthermore, these studies, whether employing traditional machine learning or deep learning approaches, have not achieved a satisfactory trade-off between accuracy and speed. To address these challenges, this paper proposes a lightweight auroral multi-wavelength fusion classification network, MLCNet, based on a multi-view approach. Firstly, we develop a lightweight feature extraction backbone, called LCTNet, to improve the classification rate and cope with the increasing amount of auroral observation data. Secondly, considering the existence of multi-scale spatial structures in auroras, we design a novel multi-scale reconstructed feature module named MSRM. Finally, to highlight the discriminative information between auroral classes, we propose a lightweight attention feature enhancement module called LAFE. The proposed method is validated using observational data from the Arctic Yellow River Station during 2003-2004. Experimental results demonstrate that the fusion of multi-wavelength information effectively improves the auroral classification performance. In particular, our approach achieves state-of-the-art classification accuracy compared to previous auroral classification studies, and superior results in terms of accuracy and computational efficiency compared to existing multi-view methods.
</details>
<details>
<summary>摘要</summary>
极光分类对极地研究起到关键作用，但目前的极光分类研究主要基于单一波长的图像，通常为557.7纳米。其他波长的图像得到了相对较少的关注，汇集多波长信息的研究仍处于不足explored领域。这种限制导致复杂的极光模式的分类率较低。此外，这些研究，无论使用传统机器学习还是深度学习方法，尚未达到了满意的准确率和速度均衡。为解决这些挑战，本文提出了一种轻量级极光多波长融合分类网络，称为MLCNet，基于多视图approach。首先，我们开发了一种轻量级特征提取Backbone，称为LCTNet，以提高分类率和应对增加的极光观测数据量。其次，考虑到极光中存在多尺度空间结构，我们设计了一种新的多尺度重建特征模块，称为MSRM。最后，为强调极光类别之间的区别信息，我们提出了一种轻量级注意特征增强模块，称为LAFE。我们的方法在Arctic Yellow River Station于2003-2004年的观测数据上进行验证。实验结果表明，将多波长信息融合分类效果显著提高了极光分类性能。尤其是，我们的方法与前一些极光分类研究相比，实现了状态机器学习和计算效率的优秀结果。
</details></li>
</ul>
<hr>
<h2 id="Truly-Scale-Equivariant-Deep-Nets-with-Fourier-Layers"><a href="#Truly-Scale-Equivariant-Deep-Nets-with-Fourier-Layers" class="headerlink" title="Truly Scale-Equivariant Deep Nets with Fourier Layers"></a>Truly Scale-Equivariant Deep Nets with Fourier Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02922">http://arxiv.org/abs/2311.02922</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ashiq24/scale_equivarinat_fourier_layer">https://github.com/ashiq24/scale_equivarinat_fourier_layer</a></li>
<li>paper_authors: Md Ashiqur Rahman, Raymond A. Yeh</li>
<li>for: 这个论文是为了研究如何实现scale-equivariant deep neural networks，以便在图像分割等任务中实现更好的性能。</li>
<li>methods: 该论文使用了Weight-sharing和kernel resizing等方法来实现scale-equivariant convolutional neural networks，但这些网络并不是在实践中真正具备scale-equivariance。</li>
<li>results: 该论文提出了一种基于Fourier层的新架构，可以实现绝对零equivariance-error的深度网络。该模型在MNIST-scale和STL-10 datasets上实现了竞争力的分类性能，同时保持了零equivariance-error。<details>
<summary>Abstract</summary>
In computer vision, models must be able to adapt to changes in image resolution to effectively carry out tasks such as image segmentation; This is known as scale-equivariance. Recent works have made progress in developing scale-equivariant convolutional neural networks, e.g., through weight-sharing and kernel resizing. However, these networks are not truly scale-equivariant in practice. Specifically, they do not consider anti-aliasing as they formulate the down-scaling operation in the continuous domain. To address this shortcoming, we directly formulate down-scaling in the discrete domain with consideration of anti-aliasing. We then propose a novel architecture based on Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute zero equivariance-error. Following prior works, we test this model on MNIST-scale and STL-10 datasets. Our proposed model achieves competitive classification performance while maintaining zero equivariance-error.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在计算机视觉中，模型需要适应图像分辨率变化以实现任务 such as 图像分割;这称为尺度对称性。近期工作已经在开发尺度对称 convolutional neural networks (CNNs)，例如通过共享权重和核心大小调整。但是，这些网络并不是实际上的尺度对称的。具体来说，它们没有考虑抗锯齿处理。为了解决这个缺陷，我们直接在精度领域中定义下降操作，并考虑抗锯齿处理。我们then proposed a novel architecture based on Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute zero equivariance-error. Following prior works, we test this model on MNIST-scale and STL-10 datasets. Our proposed model achieves competitive classification performance while maintaining zero equivariance-error.Note: The translation is done using Google Translate and may not be perfect.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-Deep-Facial-Expression-Recognition-An-Extensive-Protocol-with-Balanced-Dataset-in-the-Wild"><a href="#Benchmarking-Deep-Facial-Expression-Recognition-An-Extensive-Protocol-with-Balanced-Dataset-in-the-Wild" class="headerlink" title="Benchmarking Deep Facial Expression Recognition: An Extensive Protocol with Balanced Dataset in the Wild"></a>Benchmarking Deep Facial Expression Recognition: An Extensive Protocol with Balanced Dataset in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02910">http://arxiv.org/abs/2311.02910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gianmarco Ipinze Tutuianu, Yang Liu, Ari Alamäki, Janne Kauttonen</li>
<li>for: 本研究旨在提高人机交互中的表情识别精度。</li>
<li>methods: 本研究使用了23种常用的网络架构，并采用了一致的协议进行评估。而且，研究者们还在不同的输入分辨率、类别平衡管理和预训练策略下进行了多种设置的测试，以确定它们对表情识别的影响。</li>
<li>results: 经过广泛的实验和十三个实际交互领域的跨频评估，研究者们得出了一份网络架构排名和深度表情识别方法的推荐。此外，研究者们还讨论了在实际应用中可能会遇到的伦理规则、隐私问题和法规。<details>
<summary>Abstract</summary>
Facial expression recognition (FER) is a crucial part of human-computer interaction. Existing FER methods achieve high accuracy and generalization based on different open-source deep models and training approaches. However, the performance of these methods is not always good when encountering practical settings, which are seldom explored. In this paper, we collected a new in-the-wild facial expression dataset for cross-domain validation. Twenty-three commonly used network architectures were implemented and evaluated following a uniform protocol. Moreover, various setups, in terms of input resolutions, class balance management, and pre-trained strategies, were verified to show the corresponding performance contribution. Based on extensive experiments on three large-scale FER datasets and our practical cross-validation, we ranked network architectures and summarized a set of recommendations on deploying deep FER methods in real scenarios. In addition, potential ethical rules, privacy issues, and regulations were discussed in practical FER applications such as marketing, education, and entertainment business.
</details>
<details>
<summary>摘要</summary>
人机交互中的表情识别（FER）是一项非常重要的技术。现有的FER方法在不同的开源深度学习模型和训练方法下已经实现了高准确率和泛化性。然而，这些方法在实际设置中的性能并不总是好很，这些实际设置通常被忽略。在这篇论文中，我们收集了一个新的在野外的表情数据集，用于跨频训练验证。我们实现了23种常用的网络架构，并按照一个统一的协议进行评估。此外，我们还验证了不同的输入分辨率、类别均衡管理和预训练策略的影响。基于大规模的FER数据集和我们的实际跨频验证，我们对深度FER方法的部署在实际场景中进行了排名和总结。此外，我们还讨论了实际应用中的伦理规则、隐私问题和法规。
</details></li>
</ul>
<hr>
<h2 id="Human-as-Points-Explicit-Point-based-3D-Human-Reconstruction-from-Single-view-RGB-Images"><a href="#Human-as-Points-Explicit-Point-based-3D-Human-Reconstruction-from-Single-view-RGB-Images" class="headerlink" title="Human as Points: Explicit Point-based 3D Human Reconstruction from Single-view RGB Images"></a>Human as Points: Explicit Point-based 3D Human Reconstruction from Single-view RGB Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02892">http://arxiv.org/abs/2311.02892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yztang4/hap">https://github.com/yztang4/hap</a></li>
<li>paper_authors: Yingzhi Tang, Qijian Zhang, Junhui Hou, Yebin Liu</li>
<li>for: 这个论文的目的是为了提出一种基于点云的人体重建框架，以解决现有的深度学习人体重建方法存在的一些局限性和缺陷。</li>
<li>methods: 该方法使用了点云作为人体重建的中间表示，并采用了全部表示的点云估计、处理、生成和精度调整等技术。</li>
<li>results: 对于现有的state-of-the-art方法，该方法实现了20%到40%的性能提升，并且有更好的质量结果。这些结果表明，使用点云作为中间表示可以提高人体重建的灵活性和泛化能力。<details>
<summary>Abstract</summary>
The latest trends in the research field of single-view human reconstruction devote to learning deep implicit functions constrained by explicit body shape priors. Despite the remarkable performance improvements compared with traditional processing pipelines, existing learning approaches still show different aspects of limitations in terms of flexibility, generalizability, robustness, and/or representation capability. To comprehensively address the above issues, in this paper, we investigate an explicit point-based human reconstruction framework called HaP, which adopts point clouds as the intermediate representation of the target geometric structure. Technically, our approach is featured by fully-explicit point cloud estimation, manipulation, generation, and refinement in the 3D geometric space, instead of an implicit learning process that can be ambiguous and less controllable. The overall workflow is carefully organized with dedicated designs of the corresponding specialized learning components as well as processing procedures. Extensive experiments demonstrate that our framework achieves quantitative performance improvements of 20% to 40% over current state-of-the-art methods, and better qualitative results. Our promising results may indicate a paradigm rollback to the fully-explicit and geometry-centric algorithm design, which enables to exploit various powerful point cloud modeling architectures and processing techniques. We will make our code and data publicly available at https://github.com/yztang4/HaP.
</details>
<details>
<summary>摘要</summary>
最新的研究方向在单视人重建领域是学习深度隐函数，受到Explicit体形规范的约束。虽然现有的学习方法已经提高了处理管道的性能，但还有不同方面的局限性，包括灵活性、通用性、稳定性和/或表示能力。为全面解决以上问题，在这篇论文中，我们 investigate了一种叫做HaP的点云重建框架，该框架采用点云作为目标几何结构的中间表示。技术上，我们的方法具有完全Explicit的点云估计、处理、生成和精细化在3D几何空间中，而不是一种含糊不清的学习过程。整个 workflow 采用特定的专门设计的学习组件和处理程序。广泛的实验表明，我们的框架可以与当前状态艺术方法相比，提高了20%-40%的量化性能，并且有更好的质量结果。我们的成功结果可能意味着回归到完全Explicit和几何中心的算法设计，以便利用各种强大的点云模型化架构和处理技术。我们将在 GitHub 上公开代码和数据，请参考 https://github.com/yztang4/HaP。
</details></li>
</ul>
<hr>
<h2 id="Stacked-Autoencoder-Based-Feature-Extraction-and-Superpixel-Generation-for-Multifrequency-PolSAR-Image-Classification"><a href="#Stacked-Autoencoder-Based-Feature-Extraction-and-Superpixel-Generation-for-Multifrequency-PolSAR-Image-Classification" class="headerlink" title="Stacked Autoencoder Based Feature Extraction and Superpixel Generation for Multifrequency PolSAR Image Classification"></a>Stacked Autoencoder Based Feature Extraction and Superpixel Generation for Multifrequency PolSAR Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02887">http://arxiv.org/abs/2311.02887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tushar Gadhiya, Sumanth Tangirala, Anil K. Roy</li>
<li>for: 本研究提出了一种用于多频波特Synthetic Aperture Radar（PolSAR）图像的分类算法。</li>
<li>methods: 该算法使用PolSAR分解算法提取了每个频率带的33个特征，然后使用两层自适应归一化器减少输入特征向量中的维度，保留了输入特征的有用信息。接着，使用SLIC算法生成了超 пикsel，并使用了这些超 пикsel来构建一个强健的特征表示。</li>
<li>results: 在Flevoland数据集上进行了实验，并发现该方法在文献中已知的方法中显示出优异性。<details>
<summary>Abstract</summary>
In this paper we are proposing classification algorithm for multifrequency Polarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR decomposition algorithms 33 features are extracted from each frequency band of the given image. Then, a two-layer autoencoder is used to reduce the dimensionality of input feature vector while retaining useful features of the input. This reduced dimensional feature vector is then applied to generate superpixels using simple linear iterative clustering (SLIC) algorithm. Next, a robust feature representation is constructed using both pixel as well as superpixel information. Finally, softmax classifier is used to perform classification task. The advantage of using superpixels is that it preserves spatial information between neighbouring PolSAR pixels and therefore minimises the effect of speckle noise during classification. Experiments have been conducted on Flevoland dataset and the proposed method was found to be superior to other methods available in the literature.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种多频率折射 Synthetic Aperture Radar（PolSAR）图像的分类算法。使用PolSAR分解算法提取了每个频率带的图像中的33个特征。然后，使用两层自适应神经网络减少输入特征向量的维度，保留输入特征的有用信息。这个减少后的特征向量然后用简单线性迭代归一化算法生成超像素。接下来，使用像素和超像素信息构建了一个稳定的特征表示。最后，使用softmax分类器进行分类任务。使用超像素的优点是它保留了邻近PolSAR像素之间的空间信息，因此减少了speckle噪声的影响，提高了分类的精度。在Flevoland dataset上进行了实验，并发现该方法与文献中其他方法相比，表现更优异。
</details></li>
</ul>
<hr>
<h2 id="Inner-IoU-More-Effective-Intersection-over-Union-Loss-with-Auxiliary-Bounding-Box"><a href="#Inner-IoU-More-Effective-Intersection-over-Union-Loss-with-Auxiliary-Bounding-Box" class="headerlink" title="Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box"></a>Inner-IoU: More Effective Intersection over Union Loss with Auxiliary Bounding Box</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02877">http://arxiv.org/abs/2311.02877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Zhang, Cong Xu, Shuaijie Zhang</li>
<li>for: 提高检测性能和精度</li>
<li>methods: 使用不同的缩放因子来控制auxiliary bounding box的大小，以适应不同的检测器和检测任务</li>
<li>results: 提出Inner-IoU损失函数，通过auxiliary bounding box计算IoU损失，可以further enhance detection performance and improve generalization ability<details>
<summary>Abstract</summary>
With the rapid development of detectors, Bounding Box Regression (BBR) loss function has constantly updated and optimized. However, the existing IoU-based BBR still focus on accelerating convergence by adding new loss terms, ignoring the limitations of IoU loss term itself. Although theoretically IoU loss can effectively describe the state of bounding box regression,in practical applications, it cannot adjust itself according to different detectors and detection tasks, and does not have strong generalization. Based on the above, we first analyzed the BBR model and concluded that distinguishing different regression samples and using different scales of auxiliary bounding boxes to calculate losses can effectively accelerate the bounding box regression process. For high IoU samples, using smaller auxiliary bounding boxes to calculate losses can accelerate convergence, while larger auxiliary bounding boxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which calculates IoU loss through auxiliary bounding boxes. For different datasets and detectors, we introduce a scaling factor ratio to control the scale size of the auxiliary bounding boxes for calculating losses. Finally, integrate Inner-IoU into the existing IoU-based loss functions for simulation and comparative experiments. The experiment result demonstrate a further enhancement in detection performance with the utilization of the method proposed in this paper, verifying the effectiveness and generalization ability of Inner-IoU loss.
</details>
<details>
<summary>摘要</summary>
通过检测器的快速发展，矩形框回归（BBR）损失函数不断更新和优化。然而，现有的 IoU 基于的 BBR 仍然强调加入新的损失项，忽视 IoU 损失项本身的限制。虽然理论上 IoU 损失可以有效描述矩形框回归的状态，但在实际应用中，它无法根据不同的检测器和检测任务自适应调整，也不具备强大的通用性。基于以上分析，我们首先分析了 BBR 模型，并结论出了分类不同 regression 样本和使用不同缩放的帮助 bounding box 来计算损失可以有效加速矩形框回归过程。对高 IoU 样本，使用更小的帮助 bounding box 来计算损失可以加速收敛，而对低 IoU 样本，使用更大的帮助 bounding box 是合适的。然后，我们提出了 Inner-IoU 损失，它通过帮助 bounding box 来计算 IoU 损失。对不同的数据集和检测器，我们引入了涂抹因子比例来控制帮助 bounding box 的缩放大小。最后，我们将 Inner-IoU 集成到现有的 IoU 基于的损失函数中进行模拟和比较实验。实验结果表明，通过使用我们提出的方法，可以进一步提高检测性能，证明了 Inner-IoU 损失的有效性和通用性。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Neural-Fields-for-Learning-Atlases-of-4D-Fetal-MRI-Time-series"><a href="#Dynamic-Neural-Fields-for-Learning-Atlases-of-4D-Fetal-MRI-Time-series" class="headerlink" title="Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series"></a>Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02874">http://arxiv.org/abs/2311.02874</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kidrauh/neural-atlasing">https://github.com/kidrauh/neural-atlasing</a></li>
<li>paper_authors: Zeen Chi, Zhongxiao Cong, Clinton J. Wang, Yingcheng Liu, Esra Abaci Turk, P. Ellen Grant, S. Mazdak Abulnaga, Polina Golland, Neel Dey</li>
<li>for: 这种方法用于快速构建生物医学影像 Atlases，以便生物医学影像分析任务。</li>
<li>methods: 这种方法使用神经场来学习可变的空间时间观察。</li>
<li>results: 该方法可以快速构建高质量的生物医学影像 Atlases，并且比现有方法快得多。<details>
<summary>Abstract</summary>
We present a method for fast biomedical image atlas construction using neural fields. Atlases are key to biomedical image analysis tasks, yet conventional and deep network estimation methods remain time-intensive. In this preliminary work, we frame subject-specific atlas building as learning a neural field of deformable spatiotemporal observations. We apply our method to learning subject-specific atlases and motion stabilization of dynamic BOLD MRI time-series of fetuses in utero. Our method yields high-quality atlases of fetal BOLD time-series with $\sim$5-7$\times$ faster convergence compared to existing work. While our method slightly underperforms well-tuned baselines in terms of anatomical overlap, it estimates templates significantly faster, thus enabling rapid processing and stabilization of large databases of 4D dynamic MRI acquisitions. Code is available at https://github.com/Kidrauh/neural-atlasing
</details>
<details>
<summary>摘要</summary>
我们提出了一种快速生成医学图像 Atlases 的方法，使用神经场。 Atlases 是生物医学图像分析任务中关键的，但是传统的深度网络估计方法和深度网络估计方法仍然耗时很长。在这项初步工作中，我们将主动Specific atlas 的建立视为学习一个可变的空间时间观察的神经场。我们应用我们的方法来学习主动Specific atlas 和动态 BOLD MRI 时序列的运动稳定。我们的方法可以高质量地生成受孕妈妈动态 BOLD MRI 时序列的Atlas，并且比现有的工作快速 $\sim$5-7 $\times$。虽然我们的方法对于骨骼的覆盖率有所下降，但它可以更快地估计模板，从而实现大规模的动态 MRI 数据库的快速处理和稳定。代码可以在 <https://github.com/Kidrauh/neural-atlasing> 上获取。
</details></li>
</ul>
<hr>
<h2 id="OVIR-3D-Open-Vocabulary-3D-Instance-Retrieval-Without-Training-on-3D-Data"><a href="#OVIR-3D-Open-Vocabulary-3D-Instance-Retrieval-Without-Training-on-3D-Data" class="headerlink" title="OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data"></a>OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02873">http://arxiv.org/abs/2311.02873</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shiyoung77/ovir-3d">https://github.com/shiyoung77/ovir-3d</a></li>
<li>paper_authors: Shiyang Lu, Haonan Chang, Eric Pu Jing, Abdeslam Boularias, Kostas Bekris</li>
<li>for: 该论文旨在实现无需使用任何3D数据进行训练的开 vocabulary 3D物体实例检索。</li>
<li>methods: 该方法使用文本查询和多视图融合来实现3D物体实例检索。文本查询和2D区域提档网络可以共同使用2D数据集，这些数据集通常更易доступible和更大。</li>
<li>results: 实验表明，该方法可以快速和有效地在大多数indoor 3D场景中进行实时多视图融合，并且不需要额外训练在3D空间。实验结果还表明，该方法在 робоット导航和制造中具有潜在应用前景。<details>
<summary>Abstract</summary>
This work presents OVIR-3D, a straightforward yet effective method for open-vocabulary 3D object instance retrieval without using any 3D data for training. Given a language query, the proposed method is able to return a ranked set of 3D object instance segments based on the feature similarity of the instance and the text query. This is achieved by a multi-view fusion of text-aligned 2D region proposals into 3D space, where the 2D region proposal network could leverage 2D datasets, which are more accessible and typically larger than 3D datasets. The proposed fusion process is efficient as it can be performed in real-time for most indoor 3D scenes and does not require additional training in 3D space. Experiments on public datasets and a real robot show the effectiveness of the method and its potential for applications in robot navigation and manipulation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FocusTune-Tuning-Visual-Localization-through-Focus-Guided-Sampling"><a href="#FocusTune-Tuning-Visual-Localization-through-Focus-Guided-Sampling" class="headerlink" title="FocusTune: Tuning Visual Localization through Focus-Guided Sampling"></a>FocusTune: Tuning Visual Localization through Focus-Guided Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02872">http://arxiv.org/abs/2311.02872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sontung/focus-tune">https://github.com/sontung/focus-tune</a></li>
<li>paper_authors: Son Tung Nguyen, Alejandro Fontan, Michael Milford, Tobias Fischer</li>
<li>for: 提高视觉地标算法的性能</li>
<li>methods: 使用FocusTune方法，通过利用关键 геометрические约束来导引场景坐标回归模型的训练</li>
<li>results: 在 Cambridge Landmarks 数据集上，与或超过了状态前的性能，而且保持了ACE模型的低存储和计算需求，例如将翻译错误从 25 到 19 和 17 到 15 cm，并且在单个和 ensemble 模型中实现了这一点。<details>
<summary>Abstract</summary>
We propose FocusTune, a focus-guided sampling technique to improve the performance of visual localization algorithms. FocusTune directs a scene coordinate regression model towards regions critical for 3D point triangulation by exploiting key geometric constraints. Specifically, rather than uniformly sampling points across the image for training the scene coordinate regression model, we instead re-project 3D scene coordinates onto the 2D image plane and sample within a local neighborhood of the re-projected points. While our proposed sampling strategy is generally applicable, we showcase FocusTune by integrating it with the recently introduced Accelerated Coordinate Encoding (ACE) model. Our results demonstrate that FocusTune both improves or matches state-of-the-art performance whilst keeping ACE's appealing low storage and compute requirements, for example reducing translation error from 25 to 19 and 17 to 15 cm for single and ensemble models, respectively, on the Cambridge Landmarks dataset. This combination of high performance and low compute and storage requirements is particularly promising for applications in areas like mobile robotics and augmented reality. We made our code available at \url{https://github.com/sontung/focus-tune}.
</details>
<details>
<summary>摘要</summary>
我们提出了FocusTune，一种帮助视觉本地化算法性能提高的集中样本技术。FocusTune利用场景坐标回归模型中关键的 геометрические约束，从而导引样本点在图像平面上的分布。具体来说，我们不再在图像上均匀采样点进行场景坐标回归模型的训练，而是将3D场景坐标重 проек到图像平面上，然后在当地邻域内采样。我们的提议的采样策略可以通用，但我们在ACE模型中示cases。我们的结果表明，FocusTune可以同时提高或与当前最佳性能匹配，而且ACE模型的存储和计算成本仍然很低，例如在 cambridge 标记集上，单个和集成模型的平均翻译误差从25降低到19和17cm。这种高性能低存储计算成本的组合特别有前途，特别是在移动 робо特和扩展现实中。我们的代码可以在 \url{https://github.com/sontung/focus-tune} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Neural-based-Compression-Scheme-for-Solar-Image-Data"><a href="#Neural-based-Compression-Scheme-for-Solar-Image-Data" class="headerlink" title="Neural-based Compression Scheme for Solar Image Data"></a>Neural-based Compression Scheme for Solar Image Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02855">http://arxiv.org/abs/2311.02855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Zafari, Atefeh Khoshkhahtinat, Jeremy A. Grajeda, Piyush M. Mehta, Nasser M. Nasrabadi, Laura E. Boucheron, Barbara J. Thompson, Michael S. F. Kirk, Daniel da Silva<br>for: 这个论文的目的是提出一种基于神经网络的丢弃式压缩方法，用于快速和高效地传输 NASA 的数据敏感图像数据。methods: 该方法使用一个 adversarially 培养的神经网络，具有本地和非本地注意模块，以捕捉图像的本地和全局结构，从而实现更好的Rate-Distortion 比较。此外，该方法还使用一个共同的前提模型来进行通道相关的 entropy 编码。results: 该方法在压缩极紫外线（EUV）数据时表现出了更高的Rate-Distortion 性能，比现有的 JPEG 和 JPEG-2000 编码器更高。此外，通过对 SDO 数据进行极紫外线洞（CH）检测和分割，实现了高效的压缩和分析。<details>
<summary>Abstract</summary>
Studying the solar system and especially the Sun relies on the data gathered daily from space missions. These missions are data-intensive and compressing this data to make them efficiently transferable to the ground station is a twofold decision to make. Stronger compression methods, by distorting the data, can increase data throughput at the cost of accuracy which could affect scientific analysis of the data. On the other hand, preserving subtle details in the compressed data requires a high amount of data to be transferred, reducing the desired gains from compression. In this work, we propose a neural network-based lossy compression method to be used in NASA's data-intensive imagery missions. We chose NASA's SDO mission which transmits 1.4 terabytes of data each day as a proof of concept for the proposed algorithm. In this work, we propose an adversarially trained neural network, equipped with local and non-local attention modules to capture both the local and global structure of the image resulting in a better trade-off in rate-distortion (RD) compared to conventional hand-engineered codecs. The RD variational autoencoder used in this work is jointly trained with a channel-dependent entropy model as a shared prior between the analysis and synthesis transforms to make the entropy coding of the latent code more effective. Our neural image compression algorithm outperforms currently-in-use and state-of-the-art codecs such as JPEG and JPEG-2000 in terms of the RD performance when compressing extreme-ultraviolet (EUV) data. As a proof of concept for use of this algorithm in SDO data analysis, we have performed coronal hole (CH) detection using our compressed images, and generated consistent segmentations, even at a compression rate of $\sim0.1$ bits per pixel (compared to 8 bits per pixel on the original data) using EUV data from SDO.
</details>
<details>
<summary>摘要</summary>
studying the solar system and especially the Sun 需要每天从空间任务中获取数据。这些任务是数据极其杂的，压缩这些数据以使其高效地传输到地面站是一个两重决策。更强大的压缩方法可以通过扭曲数据来增加数据传输速率，但是这会影响科学分析中的精度。另一方面，保留图像中的细节需要大量的数据被传输，这会降低愿意吸取的收益。在这种情况下，我们提出了基于神经网络的损失压缩方法，用于NASA的数据极其杂的图像任务。我们选择了NASA的SDO任务，每天传输1.4 terrabytes的数据作为证明。在这种情况下，我们提出了一个对抗学习神经网络，具有本地和非本地注意模块，以捕捉图像的本地和全局结构，从而实现更好的Rate-Distortion（RD）质量比。我们的神经图像压缩算法在JPEG和JPEG-2000等现有和状态最佳的编码器中表现出色，特别是在激发ultraviolet（EUV）数据压缩中。作为SDO数据分析的证明，我们通过我们压缩后的图像进行了核心孔（CH）检测，并获得了一致的分割，甚至在0.1 bits/像素的压缩率下（与原始数据的8 bits/像素相比）。
</details></li>
</ul>
<hr>
<h2 id="Consistent4D-Consistent-360°-Dynamic-Object-Generation-from-Monocular-Video"><a href="#Consistent4D-Consistent-360°-Dynamic-Object-Generation-from-Monocular-Video" class="headerlink" title="Consistent4D: Consistent 360° Dynamic Object Generation from Monocular Video"></a>Consistent4D: Consistent 360° Dynamic Object Generation from Monocular Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02848">http://arxiv.org/abs/2311.02848</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanqinJiang/Consistent4D">https://github.com/yanqinJiang/Consistent4D</a></li>
<li>paper_authors: Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, Yao Yao</li>
<li>for: 这 paper 的目的是生成基于单视图视频的4D动态对象。</li>
<li>methods: 该方法使用 Dynamic Neural Radiance Fields (DyNeRF) 模型，并提出了一种 Cascade DyNeRF 来确保稳定的启发和时间连续性。另外，该方法还引入了一种 Interpolation-driven Consistency Loss 来保证空间和时间一致性。</li>
<li>results: 经过广泛的实验，该方法可以与先前的方法相比竞争，同时也在文本到3D生成任务中表现优异。<details>
<summary>Abstract</summary>
In this paper, we present Consistent4D, a novel approach for generating 4D dynamic objects from uncalibrated monocular videos. Uniquely, we cast the 360-degree dynamic object reconstruction as a 4D generation problem, eliminating the need for tedious multi-view data collection and camera calibration. This is achieved by leveraging the object-level 3D-aware image diffusion model as the primary supervision signal for training Dynamic Neural Radiance Fields (DyNeRF). Specifically, we propose a Cascade DyNeRF to facilitate stable convergence and temporal continuity under the supervision signal which is discrete along the time axis. To achieve spatial and temporal consistency, we further introduce an Interpolation-driven Consistency Loss. It is optimized by minimizing the discrepancy between rendered frames from DyNeRF and interpolated frames from a pre-trained video interpolation model. Extensive experiments show that our Consistent4D can perform competitively to prior art alternatives, opening up new possibilities for 4D dynamic object generation from monocular videos, whilst also demonstrating advantage for conventional text-to-3D generation tasks. Our project page is https://consistent4d.github.io/.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的方法，即Consistent4D，用于从无推定照视视频中生成4D动态对象。这种方法独特地将360度动态对象重建视为4D生成问题，从而消除了繁琐的多视图数据收集和摄像头准确性的需求。这是通过利用物体层3D意识图像扩散模型作为主要监督信号来训练动态神经频谱场（DyNeRF）来实现的。我们提出了一种升级的DyNeRF来促进稳定的受益和时间连续性，并在监督信号是时间轴上离散的情况下进行稳定的训练。为保证空间和时间一致，我们还引入了一种 interpolate-driven 一致损失。它通过将 DyNeRF 生成的帧与 interpolated 的帧进行比较，来减少生成的差异。我们进行了广泛的实验，结果表明，我们的 Consistent4D 可以与之前的方法相比竞争，开 up 新的可能性 для 4D动态对象生成从照视视频，同时也 demonstate 优势在传统文本到3D生成任务中。我们的项目页面是 <https://consistent4d.github.io/>。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Multi-Generator-Model-with-Fused-Spatiotemporal-Graph-for-Trajectory-Prediction"><a href="#Flexible-Multi-Generator-Model-with-Fused-Spatiotemporal-Graph-for-Trajectory-Prediction" class="headerlink" title="Flexible Multi-Generator Model with Fused Spatiotemporal Graph for Trajectory Prediction"></a>Flexible Multi-Generator Model with Fused Spatiotemporal Graph for Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02835">http://arxiv.org/abs/2311.02835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyuan Zhu, Fengxia Han, Hao Deng</li>
<li>for: 这个研究旨在提高自动驾驶系统中的路径预测能力，以便更精确地追踪和决策。</li>
<li>methods: 我们提出了一个统合类型几何图表来更好地模型人群之间的复杂互动，以及一个多生成器架构，具有一个可选的生成器网络，以学习多个生成器的分布。</li>
<li>results: 我们的框架在不同的挑战性数据集上比较了几个基准之间表现出色，并且比以往的方法更好地预测了路径。<details>
<summary>Abstract</summary>
Trajectory prediction plays a vital role in automotive radar systems, facilitating precise tracking and decision-making in autonomous driving. Generative adversarial networks with the ability to learn a distribution over future trajectories tend to predict out-of-distribution samples, which typically occurs when the distribution of forthcoming paths comprises a blend of various manifolds that may be disconnected. To address this issue, we propose a trajectory prediction framework, which can capture the social interaction variations and model disconnected manifolds of pedestrian trajectories. Our framework is based on a fused spatiotemporal graph to better model the complex interactions of pedestrians in a scene, and a multi-generator architecture that incorporates a flexible generator selector network on generated trajectories to learn a distribution over multiple generators. We show that our framework achieves state-of-the-art performance compared with several baselines on different challenging datasets.
</details>
<details>
<summary>摘要</summary>
几何预测在自动驾驶系统中扮演着关键角色，帮助汽车实现精准跟踪和决策。生成对抗网络，能够学习未来轨迹的分布，通常会预测外部样本，这通常发生在未来路径分布中包含多种不同拓扑的混合。为解决这个问题，我们提出了一个几何预测框架，可以捕捉社交互动变化和模型断开拓扑的行人轨迹。我们的框架基于 fusion spatiotemporal graph来更好地模型场景中人员之间的复杂互动，并在生成的轨迹上使用灵活的生成器选择网络来学习多个生成器的分布。我们表明，我们的框架可以与多个基准达到最佳性能在不同的具有挑战性的数据集上。
</details></li>
</ul>
<hr>
<h2 id="SemanticTopoLoop-Semantic-Loop-Closure-With-3D-Topological-Graph-Based-on-Quadric-Level-Object-Map"><a href="#SemanticTopoLoop-Semantic-Loop-Closure-With-3D-Topological-Graph-Based-on-Quadric-Level-Object-Map" class="headerlink" title="SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based on Quadric-Level Object Map"></a>SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based on Quadric-Level Object Map</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02831">http://arxiv.org/abs/2311.02831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenzhong Cao</li>
<li>For: 提高 loop closure 精度和可靠性，使 SLAM 系统在实际场景中更加稳定和准确。* Methods: 提出了一种基于多级验证的对象水平数据协调方法，并基于这种协调关系提出了一种基于对象地图拓扑的 semantics loop closure 方法。* Results: 对比 existed 状态艺术方法，我们的 semantic loop closure 方法在精度、准确性和本地化精度指标上具有明显的优势。<details>
<summary>Abstract</summary>
Loop closure, as one of the crucial components in SLAM, plays an essential role in correcting the accumulated errors. Traditional appearance-based methods, such as bag-of-words models, are often limited by local 2D features and the volume of training data, making them less versatile and robust in real-world scenarios, leading to missed detections or false positives detections in loop closure. To address these issues, we first propose a object-level data association method based on multi-level verification, which can associate 2D semantic features of current frame with 3D objects landmarks of map. Next, taking advantage of these association relations, we introduce a semantic loop closure method based on quadric-level object map topology, which represents scenes through the topological graph of objects and achieves accurate loop closure at a wide field of view by comparing differences in the topological graphs. Finally, we integrate these two methods into a complete object-aware SLAM system. Qualitative experiments and ablation studies demonstrate the effectiveness and robustness of the proposed object-level data association algorithm. Quantitative experiments show that our semantic loop closure method outperforms existing state-of-the-art methods in terms of precision, recall and localization accuracy metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT Loop closure, as one of the crucial components in SLAM, plays an essential role in correcting the accumulated errors. Traditional appearance-based methods, such as bag-of-words models, are often limited by local 2D features and the volume of training data, making them less versatile and robust in real-world scenarios, leading to missed detections or false positives detections in loop closure. To address these issues, we first propose a object-level data association method based on multi-level verification, which can associate 2D semantic features of current frame with 3D objects landmarks of map. Next, taking advantage of these association relations, we introduce a semantic loop closure method based on quadric-level object map topology, which represents scenes through the topological graph of objects and achieves accurate loop closure at a wide field of view by comparing differences in the topological graphs. Finally, we integrate these two methods into a complete object-aware SLAM system. Qualitative experiments and ablation studies demonstrate the effectiveness and robustness of the proposed object-level data association algorithm. Quantitative experiments show that our semantic loop closure method outperforms existing state-of-the-art methods in terms of precision, recall and localization accuracy metrics.TRANSLATE_TEXTHere's the translation in Simplified Chinese:<<SYS>>环closure，作为SLAM中关键组件，对各种累积错误进行更正。传统的外观基于方法，如袋子模型，常被当地2D特征所限制，并且需要大量训练数据，从而使其在实际场景中变得更加不灵活和稳定，导致环closure中的错误检测。为解决这些问题，我们首先提出了基于多级验证的对象水平数据归一化方法，可以将当前帧的2D semantics特征与地图中的3D对象标记相关联。然后，利用这些归一化关系，我们引入了基于对象图像拓扑的语义环closure方法，可以通过比较对象图像拓扑的差异来实现精度的环closure。最后，我们将这两种方法集成到了一个完整的对象意识SLAM系统中。Qualitative experiments和ablation study表明我们提出的对象水平数据归一化算法的效果和稳定性。Quantitative experiments表明我们的语义环closure方法在精度、检测率和本地化精度等指标上超过现有状态 искусственный智能方法。TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="InstructPix2NeRF-Instructed-3D-Portrait-Editing-from-a-Single-Image"><a href="#InstructPix2NeRF-Instructed-3D-Portrait-Editing-from-a-Single-Image" class="headerlink" title="InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image"></a>InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02826">http://arxiv.org/abs/2311.02826</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mybabyyh/instructpix2nerf">https://github.com/mybabyyh/instructpix2nerf</a></li>
<li>paper_authors: Jianhui Li, Shilong Liu, Zidong Liu, Yikai Wang, Kaiwen Zheng, Jinghui Xu, Jianmin Li, Jun Zhu<br>for:This paper focuses on the problem of human-instructed 3D-aware portrait editing for open-world images, which has not been well-explored due to the lack of labeled human face 3D datasets and effective architectures.methods:The proposed method, InstructPix2NeRF, is an end-to-end diffusion-based framework that lifts 2D editing to 3D space by learning the correlation between the paired images’ difference and the instructions via triplet data. The method uses a conditional latent 3D diffusion process and a proposed token position randomization strategy to achieve multi-semantic editing with portrait identity preservation.results:Extensive experiments show the effectiveness of the proposed method and its superiority against strong baselines quantitatively and qualitatively. The method is able to achieve multi-semantic editing with portrait identity preservation, and the proposed identity consistency module increases the multi-view 3D identity consistency.<details>
<summary>Abstract</summary>
With the success of Neural Radiance Field (NeRF) in 3D-aware portrait editing, a variety of works have achieved promising results regarding both quality and 3D consistency. However, these methods heavily rely on per-prompt optimization when handling natural language as editing instructions. Due to the lack of labeled human face 3D datasets and effective architectures, the area of human-instructed 3D-aware editing for open-world portraits in an end-to-end manner remains under-explored. To solve this problem, we propose an end-to-end diffusion-based framework termed InstructPix2NeRF, which enables instructed 3D-aware portrait editing from a single open-world image with human instructions. At its core lies a conditional latent 3D diffusion process that lifts 2D editing to 3D space by learning the correlation between the paired images' difference and the instructions via triplet data. With the help of our proposed token position randomization strategy, we could even achieve multi-semantic editing through one single pass with the portrait identity well-preserved. Besides, we further propose an identity consistency module that directly modulates the extracted identity signals into our diffusion process, which increases the multi-view 3D identity consistency. Extensive experiments verify the effectiveness of our method and show its superiority against strong baselines quantitatively and qualitatively.
</details>
<details>
<summary>摘要</summary>
成功的神经辐射场（NeRF）在3D意识编辑中取得了出色的成果，许多研究在质量和3D一致性方面均取得了显著进步。然而，这些方法在处理自然语言编辑指令时仍然依赖于每个提示的优化。由于人脸3D数据集缺乏标注和有效的建筑，人类给出的3D意识编辑在开放世界照片上的端到端方式仍然受到了尚未探索的问题。为解决这个问题，我们提出了一个终端扩散基于的框架，称为InstructPix2NeRF，它允许根据单个开放世界图像和人类指令来进行指定3D意识编辑。核心在于一种 conditional 粒子扩散过程，通过学习对彩色图像差异和指令之间的相关性来提升2D编辑到3D空间。通过我们提出的token位置随机策略，我们可以在一个单个过程中实现多个Semantic编辑，并且保持人脸identität。此外，我们还提出了一种标识一致模块，该模块直接将提取的标识信号加入我们的扩散过程中，从而提高多视图3D标识一致性。广泛的实验证明了我们的方法的有效性，并在量和质量上与强基线相比较。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Self-Supervised-Human-Pose-Estimation-with-Inductive-Prior-Tuning"><a href="#Efficient-Self-Supervised-Human-Pose-Estimation-with-Inductive-Prior-Tuning" class="headerlink" title="Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning"></a>Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02815">http://arxiv.org/abs/2311.02815</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/princetonvisualai/hpe-inductive-prior-tuning">https://github.com/princetonvisualai/hpe-inductive-prior-tuning</a></li>
<li>paper_authors: Nobline Yoo, Olga Russakovsky</li>
<li>for: 本研究旨在提高无监督人体 pose 估计（HPE）的自动化精度。</li>
<li>methods: 我们使用了一种自适应的模型架构，并对其进行了优化，以使其在使用少量训练数据时可以达到更高的准确率。</li>
<li>results: 我们的实验结果显示，我们的模型可以在使用少量训练数据时达到比基eline更高的准确率，并且可以更好地考虑人体 pose 的各个部分之间的相对长度差异。<details>
<summary>Abstract</summary>
The goal of 2D human pose estimation (HPE) is to localize anatomical landmarks, given an image of a person in a pose. SOTA techniques make use of thousands of labeled figures (finetuning transformers or training deep CNNs), acquired using labor-intensive crowdsourcing. On the other hand, self-supervised methods re-frame the HPE task as a reconstruction problem, enabling them to leverage the vast amount of unlabeled visual data, though at the present cost of accuracy. In this work, we explore ways to improve self-supervised HPE. We (1) analyze the relationship between reconstruction quality and pose estimation accuracy, (2) develop a model pipeline that outperforms the baseline which inspired our work, using less than one-third the amount of training data, and (3) offer a new metric suitable for self-supervised settings that measures the consistency of predicted body part length proportions. We show that a combination of well-engineered reconstruction losses and inductive priors can help coordinate pose learning alongside reconstruction in a self-supervised paradigm.
</details>
<details>
<summary>摘要</summary>
目标是二维人体姿势估计（HPE）是将人体在姿势中的 анатомиче�� landmarks 的 localization。现有最佳技术使用了 thousands of 标注的图像（finetuning transformers 或 training deep CNNs），通过劳动密集的人工投票获得。然而，自主学习方法将 HPE 任务重新定义为一个重建问题，可以利用大量的无标注视觉数据，但目前精度相对较低。在这项工作中，我们探索了如何提高自主学习HPE。我们（1）分析了重建质量和姿势估计准确性之间的关系，（2）开发了一个超过基线的模型管道，使用 less than one-third 的训练数据，（3）提出了适合自主学习设置的一个新的度量，可以测量预测人体部分长度的一致性。我们表明，将高效的重建损失和推导约束结合在一起可以协调姿势学习和重建在自主学习模式下。
</details></li>
</ul>
<hr>
<h2 id="Fast-and-Interpretable-Face-Identification-for-Out-Of-Distribution-Data-Using-Vision-Transformers"><a href="#Fast-and-Interpretable-Face-Identification-for-Out-Of-Distribution-Data-Using-Vision-Transformers" class="headerlink" title="Fast and Interpretable Face Identification for Out-Of-Distribution Data Using Vision Transformers"></a>Fast and Interpretable Face Identification for Out-Of-Distribution Data Using Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.02803">http://arxiv.org/abs/2311.02803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai Phan, Cindy Le, Vu Le, Yihui He, Anh Totti Nguyen</li>
<li>for: 提高face identification的准确率和可解释性</li>
<li>methods: 使用2个图像的Vision Transformers（ViTs）对比两个图像的patch уровень，通过cross-attention进行比较</li>
<li>results: 与DeepFace-EMD相当的准确率，但速度比DeepFace-EMD快得多，并且通过人类研究显示出了可解释性的优势<details>
<summary>Abstract</summary>
Most face identification approaches employ a Siamese neural network to compare two images at the image embedding level. Yet, this technique can be subject to occlusion (e.g. faces with masks or sunglasses) and out-of-distribution data. DeepFace-EMD (Phan et al. 2022) reaches state-of-the-art accuracy on out-of-distribution data by first comparing two images at the image level, and then at the patch level. Yet, its later patch-wise re-ranking stage admits a large $O(n^3 \log n)$ time complexity (for $n$ patches in an image) due to the optimal transport optimization. In this paper, we propose a novel, 2-image Vision Transformers (ViTs) that compares two images at the patch level using cross-attention. After training on 2M pairs of images on CASIA Webface (Yi et al. 2014), our model performs at a comparable accuracy as DeepFace-EMD on out-of-distribution data, yet at an inference speed more than twice as fast as DeepFace-EMD (Phan et al. 2022). In addition, via a human study, our model shows promising explainability through the visualization of cross-attention. We believe our work can inspire more explorations in using ViTs for face identification.
</details>
<details>
<summary>摘要</summary>
大多数面部识别方法使用同一个神经网络来比较两个图像的图像嵌入水平。然而，这种技术可能会受到遮盖物（如面具或太阳镜）和非典型数据的影响。深度Face-EMD（phan et al. 2022）达到了非典型数据上的状态态顶峰性能，通过首先比较两个图像的图像水平，然后是图像中的小块水平。然而，其后的小块排序阶段的优化问题采用了最优运输算符，导致了 $O(n^3 \log n)$ 时间复杂度（其中 $n$ 是图像中的小块数）。在这篇论文中，我们提出了一种新的、两个图像的视图转换器（ViTs），用于比较两个图像的小块水平。经过在 CASIA Webface（Yi et al. 2014）上训练 200 万对图像，我们的模型在非典型数据上达到了与 DeepFace-EMD 相当的准确率，并且在推断速度方面比 DeepFace-EMD 更快速。此外，通过人类研究，我们的模型表现出了可解释的特点，可以通过跨域抗注意力的视觉化来解释。我们认为，我们的工作可以激励更多的人们在使用 ViTs 进行面部识别。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/06/cs.CV_2023_11_06/" data-id="cloqtaesa00ldgh88d6bs9qk6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/88/">88</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
