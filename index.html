
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="http://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Fun Paper" type="application/atom+xml">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
      <a class="main-nav-link st-search-show-outputs">Search</a>
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.AI_2023_08_25/" class="article-date">
  <time datetime="2023-08-24T16:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/25/cs.AI_2023_08_25/">cs.AI - 2023-08-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes"><a href="#NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes" class="headerlink" title="NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes"></a>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12967">http://arxiv.org/abs/2308.12967</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zubair-irshad/NeO-360">https://github.com/zubair-irshad/NeO-360</a></li>
<li>paper_authors: Muhammad Zubair Irshad, Sergey Zakharov, Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus</li>
</ul>
<p>Abstract:<br>Recent implicit neural representations have shown great results for novel view synthesis. However, existing methods require expensive per-scene optimization from many views hence limiting their application to real-world unbounded urban settings where the objects of interest or backgrounds are observed from very few views. To mitigate this challenge, we introduce a new approach called NeO 360, Neural fields for sparse view synthesis of outdoor scenes. NeO 360 is a generalizable method that reconstructs 360{\deg} scenes from a single or a few posed RGB images. The essence of our approach is in capturing the distribution of complex real-world outdoor 3D scenes and using a hybrid image-conditional triplanar representation that can be queried from any world point. Our representation combines the best of both voxel-based and bird’s-eye-view (BEV) representations and is more effective and expressive than each. NeO 360’s representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference. We demonstrate our approach on the proposed challenging 360{\deg} unbounded dataset, called NeRDS 360, and show that NeO 360 outperforms state-of-the-art generalizable methods for novel view synthesis while also offering editing and composition capabilities. Project page: <a target="_blank" rel="noopener" href="https://zubair-irshad.github.io/projects/neo360.html">https://zubair-irshad.github.io/projects/neo360.html</a></p>
<hr>
<h2 id="DLIP-Distilling-Language-Image-Pre-training"><a href="#DLIP-Distilling-Language-Image-Pre-training" class="headerlink" title="DLIP: Distilling Language-Image Pre-training"></a>DLIP: Distilling Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12956">http://arxiv.org/abs/2308.12956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Kuang, Jie Wu, Xiawu Zheng, Ming Li, Xuefeng Xiao, Rui Wang, Min Zheng, Rongrong Ji</li>
</ul>
<p>Abstract:<br>Vision-Language Pre-training (VLP) shows remarkable progress with the assistance of extremely heavy parameters, which challenges deployment in real applications. Knowledge distillation is well recognized as the essential procedure in model compression. However, existing knowledge distillation techniques lack an in-depth investigation and analysis of VLP, and practical guidelines for VLP-oriented distillation are still not yet explored. In this paper, we present DLIP, a simple yet efficient Distilling Language-Image Pre-training framework, through which we investigate how to distill a light VLP model. Specifically, we dissect the model distillation from multiple dimensions, such as the architecture characteristics of different modules and the information transfer of different modalities. We conduct comprehensive experiments and provide insights on distilling a light but performant VLP model. Experimental results reveal that DLIP can achieve a state-of-the-art accuracy&#x2F;efficiency trade-off across diverse cross-modal tasks, e.g., image-text retrieval, image captioning and visual question answering. For example, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while achieving comparable or better performance. Furthermore, DLIP succeeds in retaining more than 95% of the performance with 22.4% parameters and 24.8% FLOPs compared to the teacher model and accelerates inference speed by 2.7x.</p>
<hr>
<h2 id="Low-count-Time-Series-Anomaly-Detection"><a href="#Low-count-Time-Series-Anomaly-Detection" class="headerlink" title="Low-count Time Series Anomaly Detection"></a>Low-count Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12925">http://arxiv.org/abs/2308.12925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Renz, Kurt Cutajar, Niall Twomey, Gavin K. C. Cheung, Hanting Xie</li>
</ul>
<p>Abstract:<br>Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly score smoothing consistently improves performance. The practical utility of our analysis and recommendation is validated on a real-world dataset containing sales data for retail stores.</p>
<hr>
<h2 id="Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks"><a href="#Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks" class="headerlink" title="Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks"></a>Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12918">http://arxiv.org/abs/2308.12918</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Harshith, Mantej Singh Gill, Madhan Jothimani</li>
</ul>
<p>Abstract:<br>There have been recent adversarial attacks that are difficult to find. These new adversarial attacks methods may pose challenges to current deep learning cyber defense systems and could influence the future defense of cyberattacks. The authors focus on this domain in this research paper. They explore the consequences of vulnerabilities in AI systems. This includes discussing how they might arise, differences between randomized and adversarial examples and also potential ethical implications of vulnerabilities. Moreover, it is important to train the AI systems appropriately when they are in testing phase and getting them ready for broader use.</p>
<hr>
<h2 id="Language-as-Reality-A-Co-Creative-Storytelling-Game-Experience-in-1001-Nights-using-Generative-AI"><a href="#Language-as-Reality-A-Co-Creative-Storytelling-Game-Experience-in-1001-Nights-using-Generative-AI" class="headerlink" title="Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI"></a>Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12915">http://arxiv.org/abs/2308.12915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuqian Sun, Zhouyi Li, Ke Fang, Chang Hee Lee, Ali Asadipour</li>
</ul>
<p>Abstract:<br>In this paper, we present “1001 Nights”, an AI-native game that allows players lead in-game reality through co-created storytelling with the character driven by large language model. The concept is inspired by Wittgenstein’s idea of the limits of one’s world being determined by the bounds of their language. Using advanced AI tools like GPT-4 and Stable Diffusion, the second iteration of the game enables the protagonist, Shahrzad, to realize words and stories in her world. The player can steer the conversation with the AI King towards specific keywords, which then become battle equipment in the game. This blend of interactive narrative and text-to-image transformation challenges the conventional border between the game world and reality through a dual perspective. We focus on Shahrzad, who seeks to alter her fate compared to the original folklore, and the player, who collaborates with AI to craft narratives and shape the game world. We explore the technical and design elements of implementing such a game with an objective to enhance the narrative game genre with AI-generated content and to delve into AI-native gameplay possibilities.</p>
<hr>
<h2 id="CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement"><a href="#CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement" class="headerlink" title="CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement"></a>CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12902">http://arxiv.org/abs/2308.12902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Hassan Khotanlou</li>
</ul>
<p>Abstract:<br>Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs remarkably on benchmark datasets, effectively mitigating under-exposure and proficiently restoring textures and colors in diverse low-light scenarios. This achievement underscores CDAN’s potential for diverse computer vision tasks, notably enabling robust object detection and recognition in challenging low-light conditions.</p>
<hr>
<h2 id="Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining"><a href="#Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining" class="headerlink" title="Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?"></a>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12898">http://arxiv.org/abs/2308.12898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Wang, Liang Ding, Jun Rao, Ye Liu, Li Shen, Changxing Ding</li>
</ul>
<p>Abstract:<br>The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our proposed probing benchmarks, our holistic analyses of five advanced VLP models illustrate that the VLP model: i) shows insensitivity towards complex syntax structures and relies on content words for sentence comprehension; ii) demonstrates limited comprehension of combinations between sentences and negations; iii) faces challenges in determining the presence of actions or spatial relationships within visual information and struggles with verifying the correctness of triple combinations. We make our benchmark and code available at \url{<a target="_blank" rel="noopener" href="https://github.com/WangFei-2019/SNARE/%7D">https://github.com/WangFei-2019/SNARE/}</a>.</p>
<hr>
<h2 id="Large-Language-Models-Vote-Prompting-for-Rare-Disease-Identification"><a href="#Large-Language-Models-Vote-Prompting-for-Rare-Disease-Identification" class="headerlink" title="Large Language Models Vote: Prompting for Rare Disease Identification"></a>Large Language Models Vote: Prompting for Rare Disease Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12890">http://arxiv.org/abs/2308.12890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oniani/llms-vote">https://github.com/oniani/llms-vote</a></li>
<li>paper_authors: David Oniani, Jordan Hilsman, Hang Dong, Fengyi Gao, Shiven Verma, Yanshan Wang</li>
</ul>
<p>Abstract:<br>The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FSL, available to those who agreed to the MIMIC-IV Data Use Agreement (DUA). Furthermore, in using MVP, each model is prompted multiple times, substantially increasing the time needed for manual annotation, and to address this, we assess the feasibility of using JSON for automating generative LLM evaluation.</p>
<hr>
<h2 id="Inducing-Causal-Structure-for-Abstractive-Text-Summarization"><a href="#Inducing-Causal-Structure-for-Abstractive-Text-Summarization" class="headerlink" title="Inducing Causal Structure for Abstractive Text Summarization"></a>Inducing Causal Structure for Abstractive Text Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12888">http://arxiv.org/abs/2308.12888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Chen, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, Xueqi Cheng</li>
</ul>
<p>Abstract:<br>The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Variational Auto-encoder (VAE) to fit the joint distribution of the document and summary variables from the training corpus. Experimental results on two widely used text summarization datasets demonstrate the advantages of our approach.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/25/cs.AI_2023_08_25/" data-id="cllqfou9m0000a488b0m72l4v" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.CL_2023_08_25/" class="article-date">
  <time datetime="2023-08-24T16:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/25/cs.CL_2023_08_25/">cs.CL - 2023-08-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Qwen-VL-A-Frontier-Large-Vision-Language-Model-with-Versatile-Abilities"><a href="#Qwen-VL-A-Frontier-Large-Vision-Language-Model-with-Versatile-Abilities" class="headerlink" title="Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"></a>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12966">http://arxiv.org/abs/2308.12966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qwenlm/qwen-vl">https://github.com/qwenlm/qwen-vl</a></li>
<li>paper_authors: Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, Jingren Zhou</li>
</ul>
<p>Abstract:<br>We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images. Comprising Qwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks like image captioning, question answering, visual localization, and flexible interaction. The evaluation covers a wide range of tasks including zero-shot captioning, visual or document visual question answering, and grounding. We demonstrate the Qwen-VL outperforms existing Large Vision Language Models (LVLMs). We present their architecture, training, capabilities, and performance, highlighting their contributions to advancing multimodal artificial intelligence. Code, demo and models are available at <a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-VL">https://github.com/QwenLM/Qwen-VL</a>.</p>
<hr>
<h2 id="Code-Llama-Open-Foundation-Models-for-Code"><a href="#Code-Llama-Open-Foundation-Models-for-Code" class="headerlink" title="Code Llama: Open Foundation Models for Code"></a>Code Llama: Open Foundation Models for Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12950">http://arxiv.org/abs/2308.12950</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, Gabriel Synnaeve</li>
</ul>
<p>Abstract:<br>We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.</p>
<hr>
<h2 id="Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining"><a href="#Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining" class="headerlink" title="Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?"></a>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12898">http://arxiv.org/abs/2308.12898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Wang, Liang Ding, Jun Rao, Ye Liu, Li Shen, Changxing Ding</li>
</ul>
<p>Abstract:<br>The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our proposed probing benchmarks, our holistic analyses of five advanced VLP models illustrate that the VLP model: i) shows insensitivity towards complex syntax structures and relies on content words for sentence comprehension; ii) demonstrates limited comprehension of combinations between sentences and negations; iii) faces challenges in determining the presence of actions or spatial relationships within visual information and struggles with verifying the correctness of triple combinations. We make our benchmark and code available at \url{<a target="_blank" rel="noopener" href="https://github.com/WangFei-2019/SNARE/%7D">https://github.com/WangFei-2019/SNARE/}</a>.</p>
<hr>
<h2 id="Beyond-Document-Page-Classification-Design-Datasets-and-Challenges"><a href="#Beyond-Document-Page-Classification-Design-Datasets-and-Challenges" class="headerlink" title="Beyond Document Page Classification: Design, Datasets, and Challenges"></a>Beyond Document Page Classification: Design, Datasets, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12896">http://arxiv.org/abs/2308.12896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordy Van Landeghem, Sanket Biswas, Matthew B. Blaschko, Marie-Francine Moens</li>
</ul>
<p>Abstract:<br>This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, …). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distribution shifts (e.g., born-digital vs. scanning noise, shifting page order). Our study ends on a hopeful note by recommending concrete avenues for future improvements.}</p>
<hr>
<h2 id="Large-Language-Models-Vote-Prompting-for-Rare-Disease-Identification"><a href="#Large-Language-Models-Vote-Prompting-for-Rare-Disease-Identification" class="headerlink" title="Large Language Models Vote: Prompting for Rare Disease Identification"></a>Large Language Models Vote: Prompting for Rare Disease Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12890">http://arxiv.org/abs/2308.12890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oniani/llms-vote">https://github.com/oniani/llms-vote</a></li>
<li>paper_authors: David Oniani, Jordan Hilsman, Hang Dong, Fengyi Gao, Shiven Verma, Yanshan Wang</li>
</ul>
<p>Abstract:<br>The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FSL, available to those who agreed to the MIMIC-IV Data Use Agreement (DUA). Furthermore, in using MVP, each model is prompted multiple times, substantially increasing the time needed for manual annotation, and to address this, we assess the feasibility of using JSON for automating generative LLM evaluation.</p>
<hr>
<h2 id="Inducing-Causal-Structure-for-Abstractive-Text-Summarization"><a href="#Inducing-Causal-Structure-for-Abstractive-Text-Summarization" class="headerlink" title="Inducing Causal Structure for Abstractive Text Summarization"></a>Inducing Causal Structure for Abstractive Text Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12888">http://arxiv.org/abs/2308.12888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Chen, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, Xueqi Cheng</li>
</ul>
<p>Abstract:<br>The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Variational Auto-encoder (VAE) to fit the joint distribution of the document and summary variables from the training corpus. Experimental results on two widely used text summarization datasets demonstrate the advantages of our approach.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/25/cs.CL_2023_08_25/" data-id="cllqfou9x0004a488bniq6qu5" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.CV_2023_08_25/" class="article-date">
  <time datetime="2023-08-24T16:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/25/cs.CV_2023_08_25/">cs.CV - 2023-08-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ROAM-Robust-and-Object-aware-Motion-Generation-using-Neural-Pose-Descriptors"><a href="#ROAM-Robust-and-Object-aware-Motion-Generation-using-Neural-Pose-Descriptors" class="headerlink" title="ROAM: Robust and Object-aware Motion Generation using Neural Pose Descriptors"></a>ROAM: Robust and Object-aware Motion Generation using Neural Pose Descriptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12969">http://arxiv.org/abs/2308.12969</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wanyue Zhang, Rishabh Dabral, Thomas Leimkühler, Vladislav Golyanik, Marc Habermann, Christian Theobalt</li>
</ul>
<p>Abstract:<br>Existing automatic approaches for 3D virtual character motion synthesis supporting scene interactions do not generalise well to new objects outside training distributions, even when trained on extensive motion capture datasets with diverse objects and annotated interactions. This paper addresses this limitation and shows that robustness and generalisation to novel scene objects in 3D object-aware character synthesis can be achieved by training a motion model with as few as one reference object. We leverage an implicit feature representation trained on object-only datasets, which encodes an SE(3)-equivariant descriptor field around the object. Given an unseen object and a reference pose-object pair, we optimise for the object-aware pose that is closest in the feature space to the reference pose. Finally, we use l-NSM, i.e., our motion generation model that is trained to seamlessly transition from locomotion to object interaction with the proposed bidirectional pose blending scheme. Through comprehensive numerical comparisons to state-of-the-art methods and in a user study, we demonstrate substantial improvements in 3D virtual character motion and interaction quality and robustness to scenarios with unseen objects. Our project page is available at <a target="_blank" rel="noopener" href="https://vcai.mpi-inf.mpg.de/projects/ROAM/">https://vcai.mpi-inf.mpg.de/projects/ROAM/</a>.</p>
<hr>
<h2 id="NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes"><a href="#NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes" class="headerlink" title="NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes"></a>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12967">http://arxiv.org/abs/2308.12967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Zubair Irshad, Sergey Zakharov, Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus</li>
</ul>
<p>Abstract:<br>Recent implicit neural representations have shown great results for novel view synthesis. However, existing methods require expensive per-scene optimization from many views hence limiting their application to real-world unbounded urban settings where the objects of interest or backgrounds are observed from very few views. To mitigate this challenge, we introduce a new approach called NeO 360, Neural fields for sparse view synthesis of outdoor scenes. NeO 360 is a generalizable method that reconstructs 360{\deg} scenes from a single or a few posed RGB images. The essence of our approach is in capturing the distribution of complex real-world outdoor 3D scenes and using a hybrid image-conditional triplanar representation that can be queried from any world point. Our representation combines the best of both voxel-based and bird’s-eye-view (BEV) representations and is more effective and expressive than each. NeO 360’s representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference. We demonstrate our approach on the proposed challenging 360{\deg} unbounded dataset, called NeRDS 360, and show that NeO 360 outperforms state-of-the-art generalizable methods for novel view synthesis while also offering editing and composition capabilities. Project page: <a target="_blank" rel="noopener" href="https://zubair-irshad.github.io/projects/neo360.html">https://zubair-irshad.github.io/projects/neo360.html</a></p>
<hr>
<h2 id="Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation"><a href="#Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation" class="headerlink" title="Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation"></a>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12968">http://arxiv.org/abs/2308.12968</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuxinn-j/scenimefy">https://github.com/yuxinn-j/scenimefy</a></li>
<li>paper_authors: Yuxin Jiang, Liming Jiang, Shuai Yang, Chen Change Loy</li>
</ul>
<p>Abstract:<br>Automatic high-quality rendering of anime scenes from complex real-world images is of significant practical value. The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap. Despite promising attempts, previous efforts are still incompetent in achieving satisfactory results with consistent semantic preservation, evident stylization, and fine details. In this study, we propose Scenimefy, a novel semi-supervised image-to-image translation framework that addresses these challenges. Our approach guides the learning with structure-consistent pseudo paired data, simplifying the pure unsupervised setting. The pseudo data are derived uniquely from a semantic-constrained StyleGAN leveraging rich model priors like CLIP. We further apply segmentation-guided data selection to obtain high-quality pseudo supervision. A patch-wise contrastive style loss is introduced to improve stylization and fine details. Besides, we contribute a high-resolution anime scene dataset to facilitate future research. Our extensive experiments demonstrate the superiority of our method over state-of-the-art baselines in terms of both perceptual quality and quantitative performance.</p>
<hr>
<h2 id="Qwen-VL-A-Frontier-Large-Vision-Language-Model-with-Versatile-Abilities"><a href="#Qwen-VL-A-Frontier-Large-Vision-Language-Model-with-Versatile-Abilities" class="headerlink" title="Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"></a>Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12966">http://arxiv.org/abs/2308.12966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qwenlm/qwen-vl">https://github.com/qwenlm/qwen-vl</a></li>
<li>paper_authors: Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, Jingren Zhou</li>
</ul>
<p>Abstract:<br>We introduce the Qwen-VL series, a set of large-scale vision-language models designed to perceive and understand both text and images. Comprising Qwen-VL and Qwen-VL-Chat, these models exhibit remarkable performance in tasks like image captioning, question answering, visual localization, and flexible interaction. The evaluation covers a wide range of tasks including zero-shot captioning, visual or document visual question answering, and grounding. We demonstrate the Qwen-VL outperforms existing Large Vision Language Models (LVLMs). We present their architecture, training, capabilities, and performance, highlighting their contributions to advancing multimodal artificial intelligence. Code, demo and models are available at <a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen-VL">https://github.com/QwenLM/Qwen-VL</a>.</p>
<hr>
<h2 id="POCO-3D-Pose-and-Shape-Estimation-with-Confidence"><a href="#POCO-3D-Pose-and-Shape-Estimation-with-Confidence" class="headerlink" title="POCO: 3D Pose and Shape Estimation with Confidence"></a>POCO: 3D Pose and Shape Estimation with Confidence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12965">http://arxiv.org/abs/2308.12965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Kumar Dwivedi, Cordelia Schmid, Hongwei Yi, Michael J. Black, Dimitrios Tzionas</li>
</ul>
<p>Abstract:<br>The regression of 3D Human Pose and Shape (HPS) from an image is becoming increasingly accurate. This makes the results useful for downstream tasks like human action recognition or 3D graphics. Yet, no regressor is perfect, and accuracy can be affected by ambiguous image evidence or by poses and appearance that are unseen during training. Most current HPS regressors, however, do not report the confidence of their outputs, meaning that downstream tasks cannot differentiate accurate estimates from inaccurate ones. To address this, we develop POCO, a novel framework for training HPS regressors to estimate not only a 3D human body, but also their confidence, in a single feed-forward pass. Specifically, POCO estimates both the 3D body pose and a per-sample variance. The key idea is to introduce a Dual Conditioning Strategy (DCS) for regressing uncertainty that is highly correlated to pose reconstruction quality. The POCO framework can be applied to any HPS regressor and here we evaluate it by modifying HMR, PARE, and CLIFF. In all cases, training the network to reason about uncertainty helps it learn to more accurately estimate 3D pose. While this was not our goal, the improvement is modest but consistent. Our main motivation is to provide uncertainty estimates for downstream tasks; we demonstrate this in two ways: (1) We use the confidence estimates to bootstrap HPS training. Given unlabelled image data, we take the confident estimates of a POCO-trained regressor as pseudo ground truth. Retraining with this automatically-curated data improves accuracy. (2) We exploit uncertainty in video pose estimation by automatically identifying uncertain frames (e.g. due to occlusion) and inpainting these from confident frames. Code and models will be available for research at <a target="_blank" rel="noopener" href="https://poco.is.tue.mpg.de/">https://poco.is.tue.mpg.de</a>.</p>
<hr>
<h2 id="Dense-Text-to-Image-Generation-with-Attention-Modulation"><a href="#Dense-Text-to-Image-Generation-with-Attention-Modulation" class="headerlink" title="Dense Text-to-Image Generation with Attention Modulation"></a>Dense Text-to-Image Generation with Attention Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12964">http://arxiv.org/abs/2308.12964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naver-ai/densediffusion">https://github.com/naver-ai/densediffusion</a></li>
<li>paper_authors: Yunji Kim, Jiyoung Lee, Jin-Hwa Kim, Jung-Woo Ha, Jun-Yan Zhu</li>
</ul>
<p>Abstract:<br>Existing text-to-image diffusion models struggle to synthesize realistic images given dense captions, where each text prompt provides a detailed description for a specific image region. To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout. We first analyze the relationship between generated images’ layouts and the pre-trained model’s intermediate attention maps. Next, we develop an attention modulation method that guides objects to appear in specific regions according to layout guidance. Without requiring additional fine-tuning or datasets, we improve image generation performance given dense captions regarding both automatic and human evaluation scores. In addition, we achieve similar-quality visual results with models specifically trained with layout conditions.</p>
<hr>
<h2 id="MapPrior-Bird’s-Eye-View-Map-Layout-Estimation-with-Generative-Models"><a href="#MapPrior-Bird’s-Eye-View-Map-Layout-Estimation-with-Generative-Models" class="headerlink" title="MapPrior: Bird’s-Eye View Map Layout Estimation with Generative Models"></a>MapPrior: Bird’s-Eye View Map Layout Estimation with Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12963">http://arxiv.org/abs/2308.12963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiyue Zhu, Vlas Zyrianov, Zhijian Liu, Shenlong Wang</li>
</ul>
<p>Abstract:<br>Despite tremendous advancements in bird’s-eye view (BEV) perception, existing models fall short in generating realistic and coherent semantic map layouts, and they fail to account for uncertainties arising from partial sensor information (such as occlusion or limited coverage). In this work, we introduce MapPrior, a novel BEV perception framework that combines a traditional discriminative BEV perception model with a learned generative model for semantic map layouts. Our MapPrior delivers predictions with better accuracy, realism, and uncertainty awareness. We evaluate our model on the large-scale nuScenes benchmark. At the time of submission, MapPrior outperforms the strongest competing method, with significantly improved MMD and ECE scores in camera- and LiDAR-based BEV perception.</p>
<hr>
<h2 id="Motion-Guided-Masking-for-Spatiotemporal-Representation-Learning"><a href="#Motion-Guided-Masking-for-Spatiotemporal-Representation-Learning" class="headerlink" title="Motion-Guided Masking for Spatiotemporal Representation Learning"></a>Motion-Guided Masking for Spatiotemporal Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12962">http://arxiv.org/abs/2308.12962</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Fan, Jue Wang, Shuai Liao, Yi Zhu, Vimal Bhat, Hector Santos-Villalobos, Rohith MV, Xinyu Li</li>
</ul>
<p>Abstract:<br>Several recent works have directly extended the image masked autoencoder (MAE) with random masking into video domain, achieving promising results. However, unlike images, both spatial and temporal information are important for video understanding. This suggests that the random masking strategy that is inherited from the image MAE is less effective for video MAE. This motivates the design of a novel masking algorithm that can more efficiently make use of video saliency. Specifically, we propose a motion-guided masking algorithm (MGM) which leverages motion vectors to guide the position of each mask over time. Crucially, these motion-based correspondences can be directly obtained from information stored in the compressed format of the video, which makes our method efficient and scalable. On two challenging large-scale video benchmarks (Kinetics-400 and Something-Something V2), we equip video MAE with our MGM and achieve up to +$1.3%$ improvement compared to previous state-of-the-art methods. Additionally, our MGM achieves equivalent performance to previous video MAE using up to $66%$ fewer training epochs. Lastly, we show that MGM generalizes better to downstream transfer learning and domain adaptation tasks on the UCF101, HMDB51, and Diving48 datasets, achieving up to +$4.9%$ improvement compared to baseline methods.</p>
<hr>
<h2 id="Less-is-More-Towards-Efficient-Few-shot-3D-Semantic-Segmentation-via-Training-free-Networks"><a href="#Less-is-More-Towards-Efficient-Few-shot-3D-Semantic-Segmentation-via-Training-free-Networks" class="headerlink" title="Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks"></a>Less is More: Towards Efficient Few-shot 3D Semantic Segmentation via Training-free Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12961">http://arxiv.org/abs/2308.12961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangyangyang127/tfs3d">https://github.com/yangyangyang127/tfs3d</a></li>
<li>paper_authors: Xiangyang Zhu, Renrui Zhang, Bowei He, Ziyu Guo, Jiaming Liu, Hao Dong, Peng Gao</li>
</ul>
<p>Abstract:<br>To reduce the reliance on large-scale datasets, recent works in 3D segmentation resort to few-shot learning. Current 3D few-shot semantic segmentation methods first pre-train the models on <code>seen&#39; classes, and then evaluate their generalization performance on </code>unseen’ classes. However, the prior pre-training stage not only introduces excessive time overhead, but also incurs a significant domain gap on &#96;unseen’ classes. To tackle these issues, we propose an efficient Training-free Few-shot 3D Segmentation netwrok, TFS3D, and a further training-based variant, TFS3D-T. Without any learnable parameters, TFS3D extracts dense representations by trigonometric positional encodings, and achieves comparable performance to previous training-based methods. Due to the elimination of pre-training, TFS3D can alleviate the domain gap issue and save a substantial amount of time. Building upon TFS3D, TFS3D-T only requires to train a lightweight query-support transferring attention (QUEST), which enhances the interaction between the few-shot query and support data. Experiments demonstrate TFS3D-T improves previous state-of-the-art methods by +6.93% and +17.96% mIoU respectively on S3DIS and ScanNet, while reducing the training time by -90%, indicating superior effectiveness and efficiency.</p>
<hr>
<h2 id="Towards-Realistic-Zero-Shot-Classification-via-Self-Structural-Semantic-Alignment"><a href="#Towards-Realistic-Zero-Shot-Classification-via-Self-Structural-Semantic-Alignment" class="headerlink" title="Towards Realistic Zero-Shot Classification via Self Structural Semantic Alignment"></a>Towards Realistic Zero-Shot Classification via Self Structural Semantic Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12960">http://arxiv.org/abs/2308.12960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sheng Zhang, Muzammal Naseer, Guangyi Chen, Zhiqiang Shen, Salman Khan, Kun Zhang, Fahad Khan</li>
</ul>
<p>Abstract:<br>Large-scale pre-trained Vision Language Models (VLMs) have proven effective for zero-shot classification. Despite the success, most traditional VLMs-based methods are restricted by the assumption of partial source supervision or ideal vocabularies, which rarely satisfy the open-world scenario. In this paper, we aim at a more challenging setting, Realistic Zero-Shot Classification, which assumes no annotation but instead a broad vocabulary. To address this challenge, we propose the Self Structural Semantic Alignment (S^3A) framework, which extracts the structural semantic information from unlabeled data while simultaneously self-learning. Our S^3A framework adopts a unique Cluster-Vote-Prompt-Realign (CVPR) algorithm, which iteratively groups unlabeled data to derive structural semantics for pseudo-supervision. Our CVPR process includes iterative clustering on images, voting within each cluster to identify initial class candidates from the vocabulary, generating discriminative prompts with large language models to discern confusing candidates, and realigning images and the vocabulary as structural semantic alignment. Finally, we propose to self-learn the CLIP image encoder with both individual and structural semantic alignment through a teacher-student learning strategy. Our comprehensive experiments across various generic and fine-grained benchmarks demonstrate that the S^3A method offers substantial improvements over existing VLMs-based approaches, achieving a more than 15% accuracy improvement over CLIP on average. Our codes, models, and prompts are publicly released at <a target="_blank" rel="noopener" href="https://github.com/sheng-eatamath/S3A">https://github.com/sheng-eatamath/S3A</a>.</p>
<hr>
<h2 id="DLIP-Distilling-Language-Image-Pre-training"><a href="#DLIP-Distilling-Language-Image-Pre-training" class="headerlink" title="DLIP: Distilling Language-Image Pre-training"></a>DLIP: Distilling Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12956">http://arxiv.org/abs/2308.12956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Kuang, Jie Wu, Xiawu Zheng, Ming Li, Xuefeng Xiao, Rui Wang, Min Zheng, Rongrong Ji</li>
</ul>
<p>Abstract:<br>Vision-Language Pre-training (VLP) shows remarkable progress with the assistance of extremely heavy parameters, which challenges deployment in real applications. Knowledge distillation is well recognized as the essential procedure in model compression. However, existing knowledge distillation techniques lack an in-depth investigation and analysis of VLP, and practical guidelines for VLP-oriented distillation are still not yet explored. In this paper, we present DLIP, a simple yet efficient Distilling Language-Image Pre-training framework, through which we investigate how to distill a light VLP model. Specifically, we dissect the model distillation from multiple dimensions, such as the architecture characteristics of different modules and the information transfer of different modalities. We conduct comprehensive experiments and provide insights on distilling a light but performant VLP model. Experimental results reveal that DLIP can achieve a state-of-the-art accuracy&#x2F;efficiency trade-off across diverse cross-modal tasks, e.g., image-text retrieval, image captioning and visual question answering. For example, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while achieving comparable or better performance. Furthermore, DLIP succeeds in retaining more than 95% of the performance with 22.4% parameters and 24.8% FLOPs compared to the teacher model and accelerates inference speed by 2.7x.</p>
<hr>
<h2 id="Label-Budget-Allocation-in-Multi-Task-Learning"><a href="#Label-Budget-Allocation-in-Multi-Task-Learning" class="headerlink" title="Label Budget Allocation in Multi-Task Learning"></a>Label Budget Allocation in Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12949">http://arxiv.org/abs/2308.12949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ximeng Sun, Kihyuk Sohn, Kate Saenko, Clayton Mellina, Xiao Bian</li>
</ul>
<p>Abstract:<br>The cost of labeling data often limits the performance of machine learning systems. In multi-task learning, related tasks provide information to each other and improve overall performance, but the label cost can vary among tasks. How should the label budget (i.e. the amount of money spent on labeling) be allocated among different tasks to achieve optimal multi-task performance? We are the first to propose and formally define the label budget allocation problem in multi-task learning and to empirically show that different budget allocation strategies make a big difference to its performance. We propose a Task-Adaptive Budget Allocation algorithm to robustly generate the optimal budget allocation adaptive to different multi-task learning settings. Specifically, we estimate and then maximize the extent of new information obtained from the allocated budget as a proxy for multi-task learning performance. Experiments on PASCAL VOC and Taskonomy demonstrate the efficacy of our approach over other widely used heuristic labeling strategies.</p>
<hr>
<h2 id="Perspective-aware-Convolution-for-Monocular-3D-Object-Detection"><a href="#Perspective-aware-Convolution-for-Monocular-3D-Object-Detection" class="headerlink" title="Perspective-aware Convolution for Monocular 3D Object Detection"></a>Perspective-aware Convolution for Monocular 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12938">http://arxiv.org/abs/2308.12938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KenYu910645/perspective-aware-convolution">https://github.com/KenYu910645/perspective-aware-convolution</a></li>
<li>paper_authors: Jia-Quan Yu, Soo-Chang Pei</li>
</ul>
<p>Abstract:<br>Monocular 3D object detection is a crucial and challenging task for autonomous driving vehicle, while it uses only a single camera image to infer 3D objects in the scene. To address the difficulty of predicting depth using only pictorial clue, we propose a novel perspective-aware convolutional layer that captures long-range dependencies in images. By enforcing convolutional kernels to extract features along the depth axis of every image pixel, we incorporates perspective information into network architecture. We integrate our perspective-aware convolutional layer into a 3D object detector and demonstrate improved performance on the KITTI3D dataset, achieving a 23.9% average precision in the easy benchmark. These results underscore the importance of modeling scene clues for accurate depth inference and highlight the benefits of incorporating scene structure in network design. Our perspective-aware convolutional layer has the potential to enhance object detection accuracy by providing more precise and context-aware feature extraction.</p>
<hr>
<h2 id="Panoptic-Depth-Color-Map-for-Combination-of-Depth-and-Image-Segmentation"><a href="#Panoptic-Depth-Color-Map-for-Combination-of-Depth-and-Image-Segmentation" class="headerlink" title="Panoptic-Depth Color Map for Combination of Depth and Image Segmentation"></a>Panoptic-Depth Color Map for Combination of Depth and Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12937">http://arxiv.org/abs/2308.12937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Quan Yu, Soo-Chang Pei</li>
</ul>
<p>Abstract:<br>Image segmentation and depth estimation are crucial tasks in computer vision, especially in autonomous driving scenarios. Although these tasks are typically addressed separately, we propose an innovative approach to combine them in our novel deep learning network, Panoptic-DepthLab. By incorporating an additional depth estimation branch into the segmentation network, it can predict the depth of each instance segment. Evaluating on Cityscape dataset, we demonstrate the effectiveness of our method in achieving high-quality segmentation results with depth and visualize it with a color map. Our proposed method demonstrates a new possibility of combining different tasks and networks to generate a more comprehensive image recognition result to facilitate the safety of autonomous driving vehicles.</p>
<hr>
<h2 id="Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP"><a href="#Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP" class="headerlink" title="Towards Realistic Unsupervised Fine-tuning with CLIP"></a>Towards Realistic Unsupervised Fine-tuning with CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12919">http://arxiv.org/abs/2308.12919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan</li>
</ul>
<p>Abstract:<br>The emergence of vision-language models (VLMs), such as CLIP, has spurred a significant research effort towards their application for downstream supervised learning tasks. Although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. In this paper, we delve into a realistic unsupervised fine-tuning scenario by assuming that the unlabeled data might contain out-of-distribution samples from unknown classes. Furthermore, we emphasize the importance of simultaneously enhancing out-of-distribution detection capabilities alongside the recognition of instances associated with predefined class labels.   To tackle this problem, we present a simple, efficient, and effective fine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompts, UEO also incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Through extensive experiments conducted across 15 domains and 4 different types of prior knowledge, we demonstrate that UEO surpasses baseline methods in terms of both generalization and out-of-distribution detection.</p>
<hr>
<h2 id="Robot-Pose-Nowcasting-Forecast-the-Future-to-Improve-the-Present"><a href="#Robot-Pose-Nowcasting-Forecast-the-Future-to-Improve-the-Present" class="headerlink" title="Robot Pose Nowcasting: Forecast the Future to Improve the Present"></a>Robot Pose Nowcasting: Forecast the Future to Improve the Present</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12914">http://arxiv.org/abs/2308.12914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Simoni, Francesco Marchetti, Guido Borghi, Federico Becattini, Lorenzo Seidenari, Roberto Vezzani, Alberto Del Bimbo</li>
</ul>
<p>Abstract:<br>In recent years, the effective and safe collaboration between humans and machines has gained significant importance, particularly in the Industry 4.0 scenario. A critical prerequisite for realizing this collaborative paradigm is precisely understanding the robot’s 3D pose within its environment. Therefore, in this paper, we introduce a novel vision-based system leveraging depth data to accurately establish the 3D locations of robotic joints. Specifically, we prove the ability of the proposed system to enhance its current pose estimation accuracy by jointly learning to forecast future poses. Indeed, we introduce the concept of Pose Nowcasting, denoting the capability of a system to exploit the learned knowledge of the future to improve the estimation of the present. The experimental evaluation is conducted on two different datasets, providing state-of-the-art and real-time performance and confirming the validity of the proposed method on both the robotic and human scenarios.</p>
<hr>
<h2 id="SCoRD-Subject-Conditional-Relation-Detection-with-Text-Augmented-Data"><a href="#SCoRD-Subject-Conditional-Relation-Detection-with-Text-Augmented-Data" class="headerlink" title="SCoRD: Subject-Conditional Relation Detection with Text-Augmented Data"></a>SCoRD: Subject-Conditional Relation Detection with Text-Augmented Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12910">http://arxiv.org/abs/2308.12910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziyan Yang, Kushal Kafle, Zhe Lin, Scott Cohen, Zhihong Ding, Vicente Ordonez</li>
</ul>
<p>Abstract:<br>We propose Subject-Conditional Relation Detection SCoRD, where conditioned on an input subject, the goal is to predict all its relations to other objects in a scene along with their locations. Based on the Open Images dataset, we propose a challenging OIv6-SCoRD benchmark such that the training and testing splits have a distribution shift in terms of the occurrence statistics of $\langle$subject, relation, object$\rangle$ triplets. To solve this problem, we propose an auto-regressive model that given a subject, it predicts its relations, objects, and object locations by casting this output as a sequence of tokens. First, we show that previous scene-graph prediction methods fail to produce as exhaustive an enumeration of relation-object pairs when conditioned on a subject on this benchmark. Particularly, we obtain a recall@3 of 83.8% for our relation-object predictions compared to the 49.75% obtained by a recent scene graph detector. Then, we show improved generalization on both relation-object and object-box predictions by leveraging during training relation-object pairs obtained automatically from textual captions and for which no object-box annotations are available. Particularly, for $\langle$subject, relation, object$\rangle$ triplets for which no object locations are available during training, we are able to obtain a recall@3 of 42.59% for relation-object pairs and 32.27% for their box locations.</p>
<hr>
<h2 id="CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement"><a href="#CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement" class="headerlink" title="CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement"></a>CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12902">http://arxiv.org/abs/2308.12902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Hassan Khotanlou</li>
</ul>
<p>Abstract:<br>Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs remarkably on benchmark datasets, effectively mitigating under-exposure and proficiently restoring textures and colors in diverse low-light scenarios. This achievement underscores CDAN’s potential for diverse computer vision tasks, notably enabling robust object detection and recognition in challenging low-light conditions.</p>
<hr>
<h2 id="Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining"><a href="#Can-Linguistic-Knowledge-Improve-Multimodal-Alignment-in-Vision-Language-Pretraining" class="headerlink" title="Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?"></a>Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12898">http://arxiv.org/abs/2308.12898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Wang, Liang Ding, Jun Rao, Ye Liu, Li Shen, Changxing Ding</li>
</ul>
<p>Abstract:<br>The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our proposed probing benchmarks, our holistic analyses of five advanced VLP models illustrate that the VLP model: i) shows insensitivity towards complex syntax structures and relies on content words for sentence comprehension; ii) demonstrates limited comprehension of combinations between sentences and negations; iii) faces challenges in determining the presence of actions or spatial relationships within visual information and struggles with verifying the correctness of triple combinations. We make our benchmark and code available at \url{<a target="_blank" rel="noopener" href="https://github.com/WangFei-2019/SNARE/%7D">https://github.com/WangFei-2019/SNARE/}</a>.</p>
<hr>
<h2 id="Beyond-Document-Page-Classification-Design-Datasets-and-Challenges"><a href="#Beyond-Document-Page-Classification-Design-Datasets-and-Challenges" class="headerlink" title="Beyond Document Page Classification: Design, Datasets, and Challenges"></a>Beyond Document Page Classification: Design, Datasets, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12896">http://arxiv.org/abs/2308.12896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordy Van Landeghem, Sanket Biswas, Matthew B. Blaschko, Marie-Francine Moens</li>
</ul>
<p>Abstract:<br>This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, …). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distribution shifts (e.g., born-digital vs. scanning noise, shifting page order). Our study ends on a hopeful note by recommending concrete avenues for future improvements.}</p>
<hr>
<h2 id="Boosting-Semantic-Segmentation-from-the-Perspective-of-Explicit-Class-Embeddings"><a href="#Boosting-Semantic-Segmentation-from-the-Perspective-of-Explicit-Class-Embeddings" class="headerlink" title="Boosting Semantic Segmentation from the Perspective of Explicit Class Embeddings"></a>Boosting Semantic Segmentation from the Perspective of Explicit Class Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12894">http://arxiv.org/abs/2308.12894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhe Liu, Chuanjian Liu, Kai Han, Quan Tang, Zengchang Qin</li>
</ul>
<p>Abstract:<br>Semantic segmentation is a computer vision task that associates a label with each pixel in an image. Modern approaches tend to introduce class embeddings into semantic segmentation for deeply utilizing category semantics, and regard supervised class masks as final predictions. In this paper, we explore the mechanism of class embeddings and have an insight that more explicit and meaningful class embeddings can be generated based on class masks purposely. Following this observation, we propose ECENet, a new segmentation paradigm, in which class embeddings are obtained and enhanced explicitly during interacting with multi-stage image features. Based on this, we revisit the traditional decoding process and explore inverted information flow between segmentation masks and class embeddings. Furthermore, to ensure the discriminability and informativity of features from backbone, we propose a Feature Reconstruction module, which combines intrinsic and diverse branches together to ensure the concurrence of diversity and redundancy in features. Experiments show that our ECENet outperforms its counterparts on the ADE20K dataset with much less computational cost and achieves new state-of-the-art results on PASCAL-Context dataset. The code will be released at <a target="_blank" rel="noopener" href="https://gitee.com/mindspore/models">https://gitee.com/mindspore/models</a> and <a target="_blank" rel="noopener" href="https://github.com/Carol-lyh/ECENet">https://github.com/Carol-lyh/ECENet</a>.</p>
<hr>
<h2 id="Multi-stage-feature-decorrelation-constraints-for-improving-CNN-classification-performance"><a href="#Multi-stage-feature-decorrelation-constraints-for-improving-CNN-classification-performance" class="headerlink" title="Multi-stage feature decorrelation constraints for improving CNN classification performance"></a>Multi-stage feature decorrelation constraints for improving CNN classification performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12880">http://arxiv.org/abs/2308.12880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiuyu Zhu, Xuewen Zu, Chengfei Liu</li>
</ul>
<p>Abstract:<br>For the convolutional neural network (CNN) used for pattern classification, the training loss function is usually applied to the final output of the network, except for some regularization constraints on the network parameters. However, with the increasing of the number of network layers, the influence of the loss function on the network front layers gradually decreases, and the network parameters tend to fall into local optimization. At the same time, it is found that the trained network has significant information redundancy at all stages of features, which reduces the effectiveness of feature mapping at all stages and is not conducive to the change of the subsequent parameters of the network in the direction of optimality. Therefore, it is possible to obtain a more optimized solution of the network and further improve the classification accuracy of the network by designing a loss function for restraining the front stage features and eliminating the information redundancy of the front stage features .For CNN, this article proposes a multi-stage feature decorrelation loss (MFD Loss), which refines effective features and eliminates information redundancy by constraining the correlation of features at all stages. Considering that there are many layers in CNN, through experimental comparison and analysis, MFD Loss acts on multiple front layers of CNN, constrains the output features of each layer and each channel, and performs supervision training jointly with classification loss function during network training. Compared with the single Softmax Loss supervised learning, the experiments on several commonly used datasets on several typical CNNs prove that the classification performance of Softmax Loss+MFD Loss is significantly better. Meanwhile, the comparison experiments before and after the combination of MFD Loss and some other typical loss functions verify its good universality.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/25/cs.CV_2023_08_25/" data-id="cllqfoua3000da488a74a8sky" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/25/cs.LG_2023_08_25/" class="article-date">
  <time datetime="2023-08-24T16:00:00.000Z" itemprop="datePublished">2023-08-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/25/cs.LG_2023_08_25/">cs.LG - 2023-08-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory"><a href="#NeuralClothSim-Neural-Deformation-Fields-Meet-the-Kirchhoff-Love-Thin-Shell-Theory" class="headerlink" title="NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory"></a>NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12970">http://arxiv.org/abs/2308.12970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navami Kairanda, Marc Habermann, Christian Theobalt, Vladislav Golyanik</li>
</ul>
<p>Abstract:<br>Cloth simulation is an extensively studied problem, with a plethora of solutions available in computer graphics literature. Existing cloth simulators produce realistic cloth deformations that obey different types of boundary conditions. Nevertheless, their operational principle remains limited in several ways: They operate on explicit surface representations with a fixed spatial resolution, perform a series of discretised updates (which bounds their temporal resolution), and require comparably large amounts of storage. Moreover, back-propagating gradients through the existing solvers is often not straightforward, which poses additional challenges when integrating them into modern neural architectures. In response to the limitations mentioned above, this paper takes a fundamentally different perspective on physically-plausible cloth simulation and re-thinks this long-standing problem: We propose NeuralClothSim, i.e., a new cloth simulation approach using thin shells, in which surface evolution is encoded in neural network weights. Our memory-efficient and differentiable solver operates on a new continuous coordinate-based representation of dynamic surfaces, i.e., neural deformation fields (NDFs); it supervises NDF evolution with the rules of the non-linear Kirchhoff-Love shell theory. NDFs are adaptive in the sense that they 1) allocate their capacity to the deformation details as the latter arise during the cloth evolution and 2) allow surface state queries at arbitrary spatial and temporal resolutions without retraining. We show how to train our NeuralClothSim solver while imposing hard boundary conditions and demonstrate multiple applications, such as material interpolation and simulation editing. The experimental results highlight the effectiveness of our formulation and its potential impact.</p>
<hr>
<h2 id="NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes"><a href="#NeO-360-Neural-Fields-for-Sparse-View-Synthesis-of-Outdoor-Scenes" class="headerlink" title="NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes"></a>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12967">http://arxiv.org/abs/2308.12967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Zubair Irshad, Sergey Zakharov, Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus</li>
</ul>
<p>Abstract:<br>Recent implicit neural representations have shown great results for novel view synthesis. However, existing methods require expensive per-scene optimization from many views hence limiting their application to real-world unbounded urban settings where the objects of interest or backgrounds are observed from very few views. To mitigate this challenge, we introduce a new approach called NeO 360, Neural fields for sparse view synthesis of outdoor scenes. NeO 360 is a generalizable method that reconstructs 360{\deg} scenes from a single or a few posed RGB images. The essence of our approach is in capturing the distribution of complex real-world outdoor 3D scenes and using a hybrid image-conditional triplanar representation that can be queried from any world point. Our representation combines the best of both voxel-based and bird’s-eye-view (BEV) representations and is more effective and expressive than each. NeO 360’s representation allows us to learn from a large collection of unbounded 3D scenes while offering generalizability to new views and novel scenes from as few as a single image during inference. We demonstrate our approach on the proposed challenging 360{\deg} unbounded dataset, called NeRDS 360, and show that NeO 360 outperforms state-of-the-art generalizable methods for novel view synthesis while also offering editing and composition capabilities. Project page: <a target="_blank" rel="noopener" href="https://zubair-irshad.github.io/projects/neo360.html">https://zubair-irshad.github.io/projects/neo360.html</a></p>
<hr>
<h2 id="Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation"><a href="#Scenimefy-Learning-to-Craft-Anime-Scene-via-Semi-Supervised-Image-to-Image-Translation" class="headerlink" title="Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation"></a>Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12968">http://arxiv.org/abs/2308.12968</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuxinn-j/scenimefy">https://github.com/yuxinn-j/scenimefy</a></li>
<li>paper_authors: Yuxin Jiang, Liming Jiang, Shuai Yang, Chen Change Loy</li>
</ul>
<p>Abstract:<br>Automatic high-quality rendering of anime scenes from complex real-world images is of significant practical value. The challenges of this task lie in the complexity of the scenes, the unique features of anime style, and the lack of high-quality datasets to bridge the domain gap. Despite promising attempts, previous efforts are still incompetent in achieving satisfactory results with consistent semantic preservation, evident stylization, and fine details. In this study, we propose Scenimefy, a novel semi-supervised image-to-image translation framework that addresses these challenges. Our approach guides the learning with structure-consistent pseudo paired data, simplifying the pure unsupervised setting. The pseudo data are derived uniquely from a semantic-constrained StyleGAN leveraging rich model priors like CLIP. We further apply segmentation-guided data selection to obtain high-quality pseudo supervision. A patch-wise contrastive style loss is introduced to improve stylization and fine details. Besides, we contribute a high-resolution anime scene dataset to facilitate future research. Our extensive experiments demonstrate the superiority of our method over state-of-the-art baselines in terms of both perceptual quality and quantitative performance.</p>
<hr>
<h2 id="Dense-Text-to-Image-Generation-with-Attention-Modulation"><a href="#Dense-Text-to-Image-Generation-with-Attention-Modulation" class="headerlink" title="Dense Text-to-Image Generation with Attention Modulation"></a>Dense Text-to-Image Generation with Attention Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12964">http://arxiv.org/abs/2308.12964</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naver-ai/densediffusion">https://github.com/naver-ai/densediffusion</a></li>
<li>paper_authors: Yunji Kim, Jiyoung Lee, Jin-Hwa Kim, Jung-Woo Ha, Jun-Yan Zhu</li>
</ul>
<p>Abstract:<br>Existing text-to-image diffusion models struggle to synthesize realistic images given dense captions, where each text prompt provides a detailed description for a specific image region. To address this, we propose DenseDiffusion, a training-free method that adapts a pre-trained text-to-image model to handle such dense captions while offering control over the scene layout. We first analyze the relationship between generated images’ layouts and the pre-trained model’s intermediate attention maps. Next, we develop an attention modulation method that guides objects to appear in specific regions according to layout guidance. Without requiring additional fine-tuning or datasets, we improve image generation performance given dense captions regarding both automatic and human evaluation scores. In addition, we achieve similar-quality visual results with models specifically trained with layout conditions.</p>
<hr>
<h2 id="DLIP-Distilling-Language-Image-Pre-training"><a href="#DLIP-Distilling-Language-Image-Pre-training" class="headerlink" title="DLIP: Distilling Language-Image Pre-training"></a>DLIP: Distilling Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12956">http://arxiv.org/abs/2308.12956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Kuang, Jie Wu, Xiawu Zheng, Ming Li, Xuefeng Xiao, Rui Wang, Min Zheng, Rongrong Ji</li>
</ul>
<p>Abstract:<br>Vision-Language Pre-training (VLP) shows remarkable progress with the assistance of extremely heavy parameters, which challenges deployment in real applications. Knowledge distillation is well recognized as the essential procedure in model compression. However, existing knowledge distillation techniques lack an in-depth investigation and analysis of VLP, and practical guidelines for VLP-oriented distillation are still not yet explored. In this paper, we present DLIP, a simple yet efficient Distilling Language-Image Pre-training framework, through which we investigate how to distill a light VLP model. Specifically, we dissect the model distillation from multiple dimensions, such as the architecture characteristics of different modules and the information transfer of different modalities. We conduct comprehensive experiments and provide insights on distilling a light but performant VLP model. Experimental results reveal that DLIP can achieve a state-of-the-art accuracy&#x2F;efficiency trade-off across diverse cross-modal tasks, e.g., image-text retrieval, image captioning and visual question answering. For example, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while achieving comparable or better performance. Furthermore, DLIP succeeds in retaining more than 95% of the performance with 22.4% parameters and 24.8% FLOPs compared to the teacher model and accelerates inference speed by 2.7x.</p>
<hr>
<h2 id="BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale"><a href="#BridgeData-V2-A-Dataset-for-Robot-Learning-at-Scale" class="headerlink" title="BridgeData V2: A Dataset for Robot Learning at Scale"></a>BridgeData V2: A Dataset for Robot Learning at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12952">http://arxiv.org/abs/2308.12952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Homer Walke, Kevin Black, Abraham Lee, Moo Jin Kim, Max Du, Chongyi Zheng, Tony Zhao, Philippe Hansen-Estruch, Quan Vuong, Andre He, Vivek Myers, Kuan Fang, Chelsea Finn, Sergey Levine</li>
</ul>
<p>Abstract:<br>We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research on scalable robot learning. BridgeData V2 contains 60,096 trajectories collected across 24 environments on a publicly available low-cost robot. BridgeData V2 provides extensive task and environment variability, leading to skills that can generalize across environments, domains, and institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we train 6 state-of-the-art imitation learning and offline reinforcement learning methods on our dataset, and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models, and that training on a greater variety of skills leads to improved generalization. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods. Project page at <a target="_blank" rel="noopener" href="https://rail-berkeley.github.io/bridgedata">https://rail-berkeley.github.io/bridgedata</a></p>
<hr>
<h2 id="Label-Budget-Allocation-in-Multi-Task-Learning"><a href="#Label-Budget-Allocation-in-Multi-Task-Learning" class="headerlink" title="Label Budget Allocation in Multi-Task Learning"></a>Label Budget Allocation in Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12949">http://arxiv.org/abs/2308.12949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ximeng Sun, Kihyuk Sohn, Kate Saenko, Clayton Mellina, Xiao Bian</li>
</ul>
<p>Abstract:<br>The cost of labeling data often limits the performance of machine learning systems. In multi-task learning, related tasks provide information to each other and improve overall performance, but the label cost can vary among tasks. How should the label budget (i.e. the amount of money spent on labeling) be allocated among different tasks to achieve optimal multi-task performance? We are the first to propose and formally define the label budget allocation problem in multi-task learning and to empirically show that different budget allocation strategies make a big difference to its performance. We propose a Task-Adaptive Budget Allocation algorithm to robustly generate the optimal budget allocation adaptive to different multi-task learning settings. Specifically, we estimate and then maximize the extent of new information obtained from the allocated budget as a proxy for multi-task learning performance. Experiments on PASCAL VOC and Taskonomy demonstrate the efficacy of our approach over other widely used heuristic labeling strategies.</p>
<hr>
<h2 id="Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries"><a href="#Learning-Only-On-Boundaries-a-Physics-Informed-Neural-operator-for-Solving-Parametric-Partial-Differential-Equations-in-Complex-Geometries" class="headerlink" title="Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries"></a>Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12939">http://arxiv.org/abs/2308.12939</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwei Fang, Sifan Wang, Paris Perdikaris</li>
</ul>
<p>Abstract:<br>Recently deep learning surrogates and neural operators have shown promise in solving partial differential equations (PDEs). However, they often require a large amount of training data and are limited to bounded domains. In this work, we present a novel physics-informed neural operator method to solve parametrized boundary value problems without labeled data. By reformulating the PDEs into boundary integral equations (BIEs), we can train the operator network solely on the boundary of the domain. This approach reduces the number of required sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain’s dimension, leading to a significant acceleration of the training process. Additionally, our method can handle unbounded problems, which are unattainable for existing physics-informed neural networks (PINNs) and neural operators. Our numerical experiments show the effectiveness of parametrized complex geometries and unbounded problems.</p>
<hr>
<h2 id="Low-count-Time-Series-Anomaly-Detection"><a href="#Low-count-Time-Series-Anomaly-Detection" class="headerlink" title="Low-count Time Series Anomaly Detection"></a>Low-count Time Series Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12925">http://arxiv.org/abs/2308.12925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Renz, Kurt Cutajar, Niall Twomey, Gavin K. C. Cheung, Hanting Xie</li>
</ul>
<p>Abstract:<br>Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly score smoothing consistently improves performance. The practical utility of our analysis and recommendation is validated on a real-world dataset containing sales data for retail stores.</p>
<hr>
<h2 id="An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control"><a href="#An-Efficient-Distributed-Multi-Agent-Reinforcement-Learning-for-EV-Charging-Network-Control" class="headerlink" title="An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control"></a>An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12921">http://arxiv.org/abs/2308.12921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Shojaeighadikolaei, Morteza Hashemi</li>
</ul>
<p>Abstract:<br>The increasing trend in adopting electric vehicles (EVs) will significantly impact the residential electricity demand, which results in an increased risk of transformer overload in the distribution grid. To mitigate such risks, there are urgent needs to develop effective EV charging controllers. Currently, the majority of the EV charge controllers are based on a centralized approach for managing individual EVs or a group of EVs. In this paper, we introduce a decentralized Multi-agent Reinforcement Learning (MARL) charging framework that prioritizes the preservation of privacy for EV owners. We employ the Centralized Training Decentralized Execution-Deep Deterministic Policy Gradient (CTDE-DDPG) scheme, which provides valuable information to users during training while maintaining privacy during execution. Our results demonstrate that the CTDE framework improves the performance of the charging network by reducing the network costs. Moreover, we show that the Peak-to-Average Ratio (PAR) of the total demand is reduced, which, in turn, reduces the risk of transformer overload during the peak hours.</p>
<hr>
<h2 id="Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP"><a href="#Towards-Realistic-Unsupervised-Fine-tuning-with-CLIP" class="headerlink" title="Towards Realistic Unsupervised Fine-tuning with CLIP"></a>Towards Realistic Unsupervised Fine-tuning with CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12919">http://arxiv.org/abs/2308.12919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Liang, Lijun Sheng, Zhengbo Wang, Ran He, Tieniu Tan</li>
</ul>
<p>Abstract:<br>The emergence of vision-language models (VLMs), such as CLIP, has spurred a significant research effort towards their application for downstream supervised learning tasks. Although some previous studies have explored the unsupervised fine-tuning of CLIP, they often rely on prior knowledge in the form of class names associated with ground truth labels. In this paper, we delve into a realistic unsupervised fine-tuning scenario by assuming that the unlabeled data might contain out-of-distribution samples from unknown classes. Furthermore, we emphasize the importance of simultaneously enhancing out-of-distribution detection capabilities alongside the recognition of instances associated with predefined class labels.   To tackle this problem, we present a simple, efficient, and effective fine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances. Apart from optimizing the textual prompts, UEO also incorporates optimization of channel-wise affine transformations within the visual branch of CLIP. Through extensive experiments conducted across 15 domains and 4 different types of prior knowledge, we demonstrate that UEO surpasses baseline methods in terms of both generalization and out-of-distribution detection.</p>
<hr>
<h2 id="Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks"><a href="#Evaluating-the-Vulnerabilities-in-ML-systems-in-terms-of-adversarial-attacks" class="headerlink" title="Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks"></a>Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12918">http://arxiv.org/abs/2308.12918</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Harshith, Mantej Singh Gill, Madhan Jothimani</li>
</ul>
<p>Abstract:<br>There have been recent adversarial attacks that are difficult to find. These new adversarial attacks methods may pose challenges to current deep learning cyber defense systems and could influence the future defense of cyberattacks. The authors focus on this domain in this research paper. They explore the consequences of vulnerabilities in AI systems. This includes discussing how they might arise, differences between randomized and adversarial examples and also potential ethical implications of vulnerabilities. Moreover, it is important to train the AI systems appropriately when they are in testing phase and getting them ready for broader use.</p>
<hr>
<h2 id="POLCA-Power-Oversubscription-in-LLM-Cloud-Providers"><a href="#POLCA-Power-Oversubscription-in-LLM-Cloud-Providers" class="headerlink" title="POLCA: Power Oversubscription in LLM Cloud Providers"></a>POLCA: Power Oversubscription in LLM Cloud Providers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12908">http://arxiv.org/abs/2308.12908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Brijesh Warrier, Nithish Mahalingam, Ricardo Bianchini</li>
</ul>
<p>Abstract:<br>Recent innovation in large language models (LLMs), and their myriad use-cases have rapidly driven up the compute capacity demand for datacenter GPUs. Several cloud providers and other enterprises have made substantial plans of growth in their datacenters to support these new workloads. One of the key bottleneck resources in datacenters is power, and given the increasing model sizes of LLMs, they are becoming increasingly power intensive. In this paper, we show that there is a significant opportunity to oversubscribe power in LLM clusters. Power oversubscription improves the power efficiency of these datacenters, allowing more deployable servers per datacenter, and reduces the deployment time, since building new datacenters is slow.   We extensively characterize the power consumption patterns of a variety of LLMs and their configurations. We identify the differences between the inference and training power consumption patterns. Based on our analysis of these LLMs, we claim that the average and peak power utilization in LLM clusters for inference should not be very high. Our deductions align with the data from production LLM clusters, revealing that inference workloads offer substantial headroom for power oversubscription. However, the stringent set of telemetry and controls that GPUs offer in a virtualized environment, makes it challenging to have a reliable and robust power oversubscription mechanism.   We propose POLCA, our framework for power oversubscription that is robust, reliable, and readily deployable for GPU clusters. Using open-source models to replicate the power patterns observed in production, we simulate POLCA and demonstrate that we can deploy 30% more servers in the same GPU cluster for inference, with minimal performance loss</p>
<hr>
<h2 id="CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement"><a href="#CDAN-Convolutional-Dense-Attention-guided-Network-for-Low-light-Image-Enhancement" class="headerlink" title="CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement"></a>CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12902">http://arxiv.org/abs/2308.12902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Hassan Khotanlou</li>
</ul>
<p>Abstract:<br>Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs remarkably on benchmark datasets, effectively mitigating under-exposure and proficiently restoring textures and colors in diverse low-light scenarios. This achievement underscores CDAN’s potential for diverse computer vision tasks, notably enabling robust object detection and recognition in challenging low-light conditions.</p>
<hr>
<h2 id="Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark"><a href="#Unified-Data-Management-and-Comprehensive-Performance-Evaluation-for-Urban-Spatial-Temporal-Prediction-Experiment-Analysis-Benchmark" class="headerlink" title="Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]"></a>Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12899">http://arxiv.org/abs/2308.12899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawei Jiang, Chengkai Han, Wayne Xin Zhao, Jingyuan Wang</li>
</ul>
<p>Abstract:<br>The field of urban spatial-temporal prediction is advancing rapidly with the development of deep learning techniques and the availability of large-scale datasets. However, challenges persist in accessing and utilizing diverse urban spatial-temporal datasets from different sources and stored in different formats, as well as determining effective model structures and components with the proliferation of deep learning models. This work addresses these challenges and provides three significant contributions. Firstly, we introduce “atomic files”, a unified storage format designed for urban spatial-temporal big data, and validate its effectiveness on 40 diverse datasets, simplifying data management. Secondly, we present a comprehensive overview of technological advances in urban spatial-temporal prediction models, guiding the development of robust models. Thirdly, we conduct extensive experiments using diverse models and datasets, establishing a performance leaderboard and identifying promising research directions. Overall, this work effectively manages urban spatial-temporal data, guides future efforts, and facilitates the development of accurate and efficient urban spatial-temporal prediction models. It can potentially make long-term contributions to urban spatial-temporal data management and prediction, ultimately leading to improved urban living standards.</p>
<hr>
<h2 id="Beyond-Document-Page-Classification-Design-Datasets-and-Challenges"><a href="#Beyond-Document-Page-Classification-Design-Datasets-and-Challenges" class="headerlink" title="Beyond Document Page Classification: Design, Datasets, and Challenges"></a>Beyond Document Page Classification: Design, Datasets, and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12896">http://arxiv.org/abs/2308.12896</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordy Van Landeghem, Sanket Biswas, Matthew B. Blaschko, Marie-Francine Moens</li>
</ul>
<p>Abstract:<br>This paper highlights the need to bring document classification benchmarking closer to real-world applications, both in the nature of data tested ($X$: multi-channel, multi-paged, multi-industry; $Y$: class distributions and label set variety) and in classification tasks considered ($f$: multi-page document, page stream, and document bundle classification, …). We identify the lack of public multi-page document classification datasets, formalize different classification tasks arising in application scenarios, and motivate the value of targeting efficient multi-page document representations. An experimental study on proposed multi-page document classification datasets demonstrates that current benchmarks have become irrelevant and need to be updated to evaluate complete documents, as they naturally occur in practice. This reality check also calls for more mature evaluation methodologies, covering calibration evaluation, inference complexity (time-memory), and a range of realistic distribution shifts (e.g., born-digital vs. scanning noise, shifting page order). Our study ends on a hopeful note by recommending concrete avenues for future improvements.}</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/25/cs.LG_2023_08_25/" data-id="cllqfouaf000ua4881dkt631u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.AI_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/cs.AI_2023_08_24/">cs.AI - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease"><a href="#FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease" class="headerlink" title="FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease"></a>FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12840">http://arxiv.org/abs/2308.12840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed R. Ibrahim, Terry Lyons</li>
</ul>
<p>Abstract:<br>Through our respiratory system, many viruses and diseases frequently spread and pass from one person to another. Covid-19 served as an example of how crucial it is to track down and cut back on contacts to stop its spread. There is a clear gap in finding automatic methods that can detect hand-to-face contact in complex urban scenes or indoors. In this paper, we introduce a computer vision framework, called FaceTouch, based on deep learning. It comprises deep sub-models to detect humans and analyse their actions. FaceTouch seeks to detect hand-to-face touches in the wild, such as through video chats, bus footage, or CCTV feeds. Despite partial occlusion of faces, the introduced system learns to detect face touches from the RGB representation of a given scene by utilising the representation of the body gestures such as arm movement. This has been demonstrated to be useful in complex urban scenarios beyond simply identifying hand movement and its closeness to faces. Relying on Supervised Contrastive Learning, the introduced model is trained on our collected dataset, given the absence of other benchmark datasets. The framework shows a strong validation in unseen datasets which opens the door for potential deployment.</p>
<hr>
<h2 id="Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph"><a href="#Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph" class="headerlink" title="Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph"></a>Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12828">http://arxiv.org/abs/2308.12828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadav Shalit, Michael Fire, Dima Kagan, Eran Ben-Elia</li>
</ul>
<p>Abstract:<br>Public transport routing plays a crucial role in transit network design, ensuring a satisfactory level of service for passengers. However, current routing solutions rely on traditional operational research heuristics, which can be time-consuming to implement and lack the ability to provide quick solutions. Here, we propose a novel deep learning-based methodology for a decision support system that enables public transport (PT) planners to identify short-term route improvements rapidly. By seamlessly adjusting specific sections of routes between two stops during specific times of the day, our method effectively reduces times and enhances PT services. Leveraging diverse data sources such as GTFS and smart card data, we extract features and model the transportation network as a directed graph. Using self-supervision, we train a deep learning model for predicting lateness values for road segments.   These lateness values are then utilized as edge weights in the transportation graph, enabling efficient path searching. Through evaluating the method on Tel Aviv, we are able to reduce times on more than 9% of the routes. The improved routes included both intraurban and suburban routes showcasing a fact highlighting the model’s versatility. The findings emphasize the potential of our data-driven decision support system to enhance public transport and city logistics, promoting greater efficiency and reliability in PT services.</p>
<hr>
<h2 id="Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods"><a href="#Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods" class="headerlink" title="Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods"></a>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12794">http://arxiv.org/abs/2308.12794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark">https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark</a></li>
<li>paper_authors: Robbert Reijnen, Kjell van Straaten, Zaharah Bukhsh, Yingqian Zhang</li>
</ul>
<p>Abstract:<br>We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals). Our primary goal is to provide a centralized hub for researchers, practitioners, and enthusiasts interested in tackling machine scheduling challenges.</p>
<hr>
<h2 id="Acquiring-Qualitative-Explainable-Graphs-for-Automated-Driving-Scene-Interpretation"><a href="#Acquiring-Qualitative-Explainable-Graphs-for-Automated-Driving-Scene-Interpretation" class="headerlink" title="Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation"></a>Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12755">http://arxiv.org/abs/2308.12755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nassim Belmecheri, Arnaud Gotlieb, Nadjib Lazaar, Helge Spieker</li>
</ul>
<p>Abstract:<br>The future of automated driving (AD) is rooted in the development of robust, fair and explainable artificial intelligence methods. Upon request, automated vehicles must be able to explain their decisions to the driver and the car passengers, to the pedestrians and other vulnerable road users and potentially to external auditors in case of accidents. However, nowadays, most explainable methods still rely on quantitative analysis of the AD scene representations captured by multiple sensors. This paper proposes a novel representation of AD scenes, called Qualitative eXplainable Graph (QXG), dedicated to qualitative spatiotemporal reasoning of long-term scenes. The construction of this graph exploits the recent Qualitative Constraint Acquisition paradigm. Our experimental results on NuScenes, an open real-world multi-modal dataset, show that the qualitative eXplainable graph of an AD scene composed of 40 frames can be computed in real-time and light in space storage which makes it a potentially interesting tool for improved and more trustworthy perception and control processes in AD.</p>
<hr>
<h2 id="Motion-In-Betweening-with-Phase-Manifolds"><a href="#Motion-In-Betweening-with-Phase-Manifolds" class="headerlink" title="Motion In-Betweening with Phase Manifolds"></a>Motion In-Betweening with Phase Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12751">http://arxiv.org/abs/2308.12751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pauzii/phasebetweener">https://github.com/pauzii/phasebetweener</a></li>
<li>paper_authors: Paul Starke, Sebastian Starke, Taku Komura, Frank Steinicke</li>
</ul>
<p>Abstract:<br>This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder. Our approach utilizes a mixture-of-experts neural network model, in which the phases cluster movements in both space and time with different expert weights. Each generated set of weights then produces a sequence of poses in an autoregressive manner between the current and target state of the character. In addition, to satisfy poses which are manually modified by the animators or where certain end effectors serve as constraints to be reached by the animation, a learned bi-directional control scheme is implemented to satisfy such constraints. The results demonstrate that using phases for motion in-betweening tasks sharpen the interpolated movements, and furthermore stabilizes the learning process. Moreover, using phases for motion in-betweening tasks can also synthesize more challenging movements beyond locomotion behaviors. Additionally, style control is enabled between given target keyframes. Our proposed framework can compete with popular state-of-the-art methods for motion in-betweening in terms of motion quality and generalization, especially in the existence of long transition durations. Our framework contributes to faster prototyping workflows for creating animated character sequences, which is of enormous interest for the game and film industry.</p>
<hr>
<h2 id="Separating-the-Human-Touch-from-AI-Generated-Text-using-Higher-Criticism-An-Information-Theoretic-Approach"><a href="#Separating-the-Human-Touch-from-AI-Generated-Text-using-Higher-Criticism-An-Information-Theoretic-Approach" class="headerlink" title="Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach"></a>Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12747">http://arxiv.org/abs/2308.12747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alon Kipnis</li>
</ul>
<p>Abstract:<br>We propose a method to determine whether a given article was entirely written by a generative language model versus an alternative situation in which the article includes some significant edits by a different author, possibly a human. Our process involves many perplexity tests for the origin of individual sentences or other text atoms, combining these multiple tests using Higher Criticism (HC). As a by-product, the method identifies parts suspected to be edited. The method is motivated by the convergence of the log-perplexity to the cross-entropy rate and by a statistical model for edited text saying that sentences are mostly generated by the language model, except perhaps for a few sentences that might have originated via a different mechanism. We demonstrate the effectiveness of our method using real data and analyze the factors affecting its success. This analysis raises several interesting open challenges whose resolution may improve the method’s effectiveness.</p>
<hr>
<h2 id="Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks"><a href="#Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks" class="headerlink" title="Human Comprehensible Active Learning of Genome-Scale Metabolic Networks"></a>Human Comprehensible Active Learning of Genome-Scale Metabolic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12740">http://arxiv.org/abs/2308.12740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lun Ai, Shi-Shun Liang, Wang-Zhou Dai, Liam Hallett, Stephen H. Muggleton, Geoff S. Baldwin</li>
</ul>
<p>Abstract:<br>An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that reduce the experimental cost of learning gene functions in comparison to randomly selected experiments.</p>
<hr>
<h2 id="Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification"><a href="#Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification" class="headerlink" title="Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification"></a>Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12737">http://arxiv.org/abs/2308.12737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Yang, Zhongyu Li, Chen Liu, Xiangde Luo, Xingguang Wang, Dou Xu, Chaoqun Li, Xiaoying Qin, Meng Yang, Long Jin</li>
</ul>
<p>Abstract:<br>Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification.</p>
<hr>
<h2 id="DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images"><a href="#DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images" class="headerlink" title="DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images"></a>DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12727">http://arxiv.org/abs/2308.12727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Razan Dibo, Andrey Galichin, Pavel Astashev, Dmitry V. Dylov, Oleg Y. Rogov</li>
</ul>
<p>Abstract:<br>In recent years, computer-aided diagnosis systems have shown great potential in assisting radiologists with accurate and efficient medical image analysis. This paper presents a novel approach for bone pathology localization and classification in wrist X-ray images using a combination of YOLO (You Only Look Once) and the Shifted Window Transformer (Swin) with a newly proposed block. The proposed methodology addresses two critical challenges in wrist X-ray analysis: accurate localization of bone pathologies and precise classification of abnormalities. The YOLO framework is employed to detect and localize bone pathologies, leveraging its real-time object detection capabilities. Additionally, the Swin, a transformer-based module, is utilized to extract contextual information from the localized regions of interest (ROIs) for accurate classification.</p>
<hr>
<h2 id="Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game"><a href="#Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game" class="headerlink" title="Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game"></a>Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12726">http://arxiv.org/abs/2308.12726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoud Rahimi, Hadi Moradi, Abdol-hossein Vahabie, Hamed Kebriaei</li>
</ul>
<p>Abstract:<br>Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a player’s experience in video games. Recently, Reinforcement Learning (RL) methods have been employed for DDA in non-competitive games; nevertheless, they rely solely on discrete state-action space with a small search space. In this paper, we propose a continuous RL-based DDA methodology for a visual working memory (VWM) game to handle the complex search space for the difficulty of memorization. The proposed RL-based DDA tailors game difficulty based on the player’s score and game difficulty in the last trial. We defined a continuous metric for the difficulty of memorization. Then, we consider the task difficulty and the vector of difficulty-score as the RL’s action and state, respectively. We evaluated the proposed method through a within-subject experiment involving 52 subjects. The proposed approach was compared with two rule-based difficulty adjustment methods in terms of player’s score and game experience measured by a questionnaire. The proposed RL-based approach resulted in a significantly better game experience in terms of competence, tension, and negative and positive affect. Players also achieved higher scores and win rates. Furthermore, the proposed RL-based DDA led to a significantly less decline in the score in a 20-trial session.</p>
<hr>
<h2 id="VIGC-Visual-Instruction-Generation-and-Correction"><a href="#VIGC-Visual-Instruction-Generation-and-Correction" class="headerlink" title="VIGC: Visual Instruction Generation and Correction"></a>VIGC: Visual Instruction Generation and Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12714">http://arxiv.org/abs/2308.12714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Wang, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He</li>
</ul>
<p>Abstract:<br>The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of high-quality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision-language tasks. However, it’s worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction-tuning data and progressively enhance its quality on-the-fly. Specifically, Visual Instruction Generation (VIG) guides the vision-language model to generate diverse instruction-tuning data. To ensure generation quality, Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG, effectively reducing the risk of hallucination. Leveraging the diverse, high-quality data generated by VIGC, we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language-only data generation methods, but also effectively enhances the benchmark performance. The models, datasets, and code will be made publicly available.</p>
<hr>
<h2 id="SayCanPay-Heuristic-Planning-with-Large-Language-Models-using-Learnable-Domain-Knowledge"><a href="#SayCanPay-Heuristic-Planning-with-Large-Language-Models-using-Learnable-Domain-Knowledge" class="headerlink" title="SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge"></a>SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12682">http://arxiv.org/abs/2308.12682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt</li>
</ul>
<p>Abstract:<br>Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast “world knowledge”. Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions’ feasibility (Can) and long-term reward&#x2F;payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches.</p>
<hr>
<h2 id="LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning"><a href="#LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning" class="headerlink" title="LR-XFL: Logical Reasoning-based Explainable Federated Learning"></a>LR-XFL: Logical Reasoning-based Explainable Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12681">http://arxiv.org/abs/2308.12681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanci Zhang, Han Yu</li>
</ul>
<p>Abstract:<br>Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients’ local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in terms of classification accuracy, rule accuracy and rule fidelity, respectively. The explicit rule evaluation and expression under LR-XFL enable human experts to validate and correct the rules on the server side, hence improving the global FL model’s robustness to errors. It has the potential to enhance the transparency of FL models for areas like healthcare and finance where both data privacy and explainability are important.</p>
<hr>
<h2 id="Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions"><a href="#Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions" class="headerlink" title="Improving Translation Faithfulness of Large Language Models via Augmenting Instructions"></a>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12674">http://arxiv.org/abs/2308.12674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pppa2019/swie_overmiss_llm4mt">https://github.com/pppa2019/swie_overmiss_llm4mt</a></li>
<li>paper_authors: Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou</li>
</ul>
<p>Abstract:<br>Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-stream open-source LLMs, BLOOM and LLaMA. The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk. Additionally, OVERMISS outperforms the baseline in translation performance (e.g. an increase in BLEU scores from 0.69 to 3.12 and an average improvement of 0.48 percentage comet scores for LLaMA-7b) with further enhancements seen in models combining OVERMISS and SWIE (e.g. the BLUE scores increase up to 0.56 from English to German across three different backbones), and both exhibit improvements in the faithfulness metric based on word alignment.</p>
<hr>
<h2 id="Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers"><a href="#Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers" class="headerlink" title="Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers"></a>Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12661">http://arxiv.org/abs/2308.12661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
</ul>
<p>Abstract:<br>Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards. However, designing effective out-of-distribution tests that encompass all possible scenarios while preserving accurate label information is a challenging task. Existing methodologies often entail a compromise between variety and constraint levels for attacks and sometimes even both. In a first step towards a more holistic robustness evaluation of image classification models, we introduce an attack method based on image solarization that is conceptually straightforward yet avoids jeopardizing the global structure of natural images independent of the intensity. Through comprehensive evaluations of multiple ImageNet models, we demonstrate the attack’s capacity to degrade accuracy significantly, provided it is not integrated into the training augmentations. Interestingly, even then, no full immunity to accuracy deterioration is achieved. In other settings, the attack can often be simplified into a black-box attack with model-independent parameters. Defenses against other corruptions do not consistently extend to be effective against our specific attack.   Project website: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></p>
<hr>
<h2 id="kTrans-Knowledge-Aware-Transformer-for-Binary-Code-Embedding"><a href="#kTrans-Knowledge-Aware-Transformer-for-Binary-Code-Embedding" class="headerlink" title="kTrans: Knowledge-Aware Transformer for Binary Code Embedding"></a>kTrans: Knowledge-Aware Transformer for Binary Code Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12659">http://arxiv.org/abs/2308.12659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/learner0x5a/ktrans-release">https://github.com/learner0x5a/ktrans-release</a></li>
<li>paper_authors: Wenyu Zhu, Hao Wang, Yuchen Zhou, Jiaming Wang, Zihan Sha, Zeyu Gao, Chao Zhang</li>
</ul>
<p>Abstract:<br>Binary Code Embedding (BCE) has important applications in various reverse engineering tasks such as binary code similarity detection, type recovery, control-flow recovery and data-flow analysis. Recent studies have shown that the Transformer model can comprehend the semantics of binary code to support downstream tasks. However, existing models overlooked the prior knowledge of assembly language. In this paper, we propose a novel Transformer-based approach, namely kTrans, to generate knowledge-aware binary code embedding. By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework. We inspect the generated embeddings with outlier detection and visualization, and also apply kTrans to 3 downstream tasks: Binary Code Similarity Detection (BCSD), Function Type Recovery (FTR) and Indirect Call Recognition (ICR). Evaluation results show that kTrans can generate high-quality binary code embeddings, and outperforms state-of-the-art (SOTA) approaches on downstream tasks by 5.2%, 6.8%, and 12.6% respectively. kTrans is publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Learner0x5a/kTrans-release">https://github.com/Learner0x5a/kTrans-release</a></p>
<hr>
<h2 id="APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT"><a href="#APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT" class="headerlink" title="APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT"></a>APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12649">http://arxiv.org/abs/2308.12649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadar Schreiber Galler, Tom Zahavy, Guillaume Desjardins, Alon Cohen</li>
</ul>
<p>Abstract:<br>We study diverse skill discovery in reward-free environments, aiming to discover all possible skills in simple grid-world environments where prior methods have struggled to succeed. This problem is formulated as mutual training of skills using an intrinsic reward and a discriminator trained to predict a skill given its trajectory. Our initial solution replaces the standard one-vs-all (softmax) discriminator with a one-vs-one (all pairs) discriminator and combines it with a novel intrinsic reward function and a dropout regularization technique. The combined approach is named APART: Diverse Skill Discovery using All Pairs with Ascending Reward and Dropout. We demonstrate that APART discovers all the possible skills in grid worlds with remarkably fewer samples than previous works. Motivated by the empirical success of APART, we further investigate an even simpler algorithm that achieves maximum skills by altering VIC, rescaling its intrinsic reward, and tuning the temperature of its softmax discriminator. We believe our findings shed light on the crucial factors underlying success of skill discovery algorithms in reinforcement learning.</p>
<hr>
<h2 id="Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines"><a href="#Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines" class="headerlink" title="Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines"></a>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12635">http://arxiv.org/abs/2308.12635</a></li>
<li>repo_url: None</li>
<li>paper_authors: György Orosz, Gergő Szabó, Péter Berkecz, Zsolt Szántó, Richárd Farkas</li>
</ul>
<p>Abstract:<br>This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.</p>
<hr>
<h2 id="Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning"><a href="#Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning" class="headerlink" title="Towards Hierarchical Regional Transformer-based Multiple Instance Learning"></a>Towards Hierarchical Regional Transformer-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12634">http://arxiv.org/abs/2308.12634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Cersovsky, Sadegh Mohammadi, Dagmar Kainmueller, Johannes Hoehne</li>
</ul>
<p>Abstract:<br>The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.</p>
<hr>
<h2 id="A-Greedy-Approach-for-Offering-to-Telecom-Subscribers"><a href="#A-Greedy-Approach-for-Offering-to-Telecom-Subscribers" class="headerlink" title="A Greedy Approach for Offering to Telecom Subscribers"></a>A Greedy Approach for Offering to Telecom Subscribers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12606">http://arxiv.org/abs/2308.12606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Kanti Bhunre, Tanmay Sen, Arijit Sarkar</li>
</ul>
<p>Abstract:<br>Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator’s network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator’s objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer optimization under heterogeneous offers by maximizing expected revenue under the scenario of subscriber churn, which is, in general, seen in telecom domain. The proposed algorithm is efficient and accurate even for a very large subscriber-base.</p>
<hr>
<h2 id="APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency"><a href="#APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency" class="headerlink" title="APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency"></a>APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12605">http://arxiv.org/abs/2308.12605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yupu Yao, Shangqi Deng, Zihan Cao, Harry Zhang, Liang-Jian Deng</li>
</ul>
<p>Abstract:<br>Diffusion models have exhibited promising progress in video generation. However, they often struggle to retain consistent details within local regions across frames. One underlying cause is that traditional diffusion models approximate Gaussian noise distribution by utilizing predictive noise, without fully accounting for the impact of inherent information within the input itself. Additionally, these models emphasize the distinction between predictions and references, neglecting information intrinsic to the videos. To address this limitation, inspired by the self-attention mechanism, we propose a novel text-to-video (T2V) generation network structure based on diffusion models, dubbed Additional Perturbation for Latent noise with Adversarial training (APLA). Our approach only necessitates a single video as input and builds upon pre-trained stable diffusion networks. Notably, we introduce an additional compact network, known as the Video Generation Transformer (VGT). This auxiliary component is designed to extract perturbations from the inherent information contained within the input, thereby refining inconsistent pixels during temporal predictions. We leverage a hybrid architecture of transformers and convolutions to compensate for temporal intricacies, enhancing consistency between different frames within the video. Experiments demonstrate a noticeable improvement in the consistency of the generated videos both qualitatively and quantitatively.</p>
<hr>
<h2 id="SICNN-Soft-Interference-Cancellation-Inspired-Neural-Network-Equalizers"><a href="#SICNN-Soft-Interference-Cancellation-Inspired-Neural-Network-Equalizers" class="headerlink" title="SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers"></a>SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12591">http://arxiv.org/abs/2308.12591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Baumgartner, Oliver Lang, Mario Huemer</li>
</ul>
<p>Abstract:<br>Equalization is an important task at the receiver side of a digital wireless communication system, which is traditionally conducted with model-based estimation methods. Among the numerous options for model-based equalization, iterative soft interference cancellation (SIC) is a well-performing approach since error propagation caused by hard decision data symbol estimation during the iterative estimation procedure is avoided. However, the model-based method suffers from high computational complexity and performance degradation due to required approximations. In this work, we propose a novel neural network (NN-)based equalization approach, referred to as SICNN, which is designed by deep unfolding of a model-based iterative SIC method, eliminating the main disadvantages of its model-based counterpart. We present different variants of SICNN. SICNNv1 is very similar to the model-based method, and is specifically tailored for single carrier frequency domain equalization systems, which is the communication system we regard in this work. The second variant, SICNNv2, is more universal, and is applicable as an equalizer in any communication system with a block-based data transmission scheme. We highlight the pros and cons of both variants. Moreover, for both SICNNv1 and SICNNv2 we present a version with a highly reduced number of learnable parameters. We compare the achieved bit error ratio performance of the proposed NN-based equalizers with state-of-the-art model-based and NN-based approaches, highlighting the superiority of SICNNv1 over all other methods. Also, we present a thorough complexity analysis of the proposed NN-based equalization approaches, and we investigate the influence of the training set size on the performance of NN-based equalizers.</p>
<hr>
<h2 id="A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning"><a href="#A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning" class="headerlink" title="A Huber Loss Minimization Approach to Byzantine Robust Federated Learning"></a>A Huber Loss Minimization Approach to Byzantine Robust Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12581">http://arxiv.org/abs/2308.12581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Puning Zhao, Fei Yu, Zhiguo Wan</li>
</ul>
<p>Abstract:<br>Federated learning systems are susceptible to adversarial attacks. To combat this, we introduce a novel aggregator based on Huber loss minimization, and provide a comprehensive theoretical analysis. Under independent and identically distributed (i.i.d) assumption, our approach has several advantages compared to existing methods. Firstly, it has optimal dependence on $\epsilon$, which stands for the ratio of attacked clients. Secondly, our approach does not need precise knowledge of $\epsilon$. Thirdly, it allows different clients to have unequal data sizes. We then broaden our analysis to include non-i.i.d data, such that clients have slightly different distributions.</p>
<hr>
<h2 id="Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models"><a href="#Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models" class="headerlink" title="Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models"></a>Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12578">http://arxiv.org/abs/2308.12578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yachao Zhao, Bo Wang, Dongming Zhao, Kun Huang, Yan Wang, Ruifang He, Yuexian Hou</li>
</ul>
<p>Abstract:<br>Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals’ explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as “re-judge inconsistency” in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human’s unaware implicit social bias and their aware explicit social bias. Experimental investigations on ChatGPT and GPT-4 concerning common gender biases examined in psychology corroborate the highly stable nature of the re-judge inconsistency. This finding may suggest that diverse cognitive constructs emerge as LLMs’ capabilities strengthen. Consequently, leveraging psychological theories can provide enhanced insights into the underlying mechanisms governing the expressions of explicit and implicit constructs in LLMs.</p>
<hr>
<h2 id="REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection"><a href="#REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection" class="headerlink" title="REB: Reducing Biases in Representation for Industrial Anomaly Detection"></a>REB: Reducing Biases in Representation for Industrial Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12577">http://arxiv.org/abs/2308.12577</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Lyu, Dongmei Mo, Waikeung Wong</li>
</ul>
<p>Abstract:<br>Existing K-nearest neighbor (KNN) retrieval-based methods usually conduct industrial anomaly detection in two stages: obtain feature representations with a pre-trained CNN model and perform distance measures for defect detection. However, the features are not fully exploited as they ignore domain bias and the difference of local density in feature space, which limits the detection performance. In this paper, we propose Reducing Biases (REB) in representation by considering the domain bias of the pre-trained model and building a self-supervised learning task for better domain adaption with a defect generation strategy (DefectMaker) imitating the natural defects. Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection. We achieve a promising result of 99.5% AUROC on the widely used MVTec AD benchmark. We also achieve 88.0% AUROC on the challenging MVTec LOCO AD dataset and bring an improvement of 4.7% AUROC to the state-of-the-art result. All results are obtained with smaller backbone networks such as Vgg11 and Resnet18, which indicates the effectiveness and efficiency of REB for practical industrial applications.</p>
<hr>
<h2 id="Exploring-the-Integration-Strategies-of-Retriever-and-Large-Language-Models"><a href="#Exploring-the-Integration-Strategies-of-Retriever-and-Large-Language-Models" class="headerlink" title="Exploring the Integration Strategies of Retriever and Large Language Models"></a>Exploring the Integration Strategies of Retriever and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12574">http://arxiv.org/abs/2308.12574</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Liu, Semih Yavuz, Rui Meng, Meghana Moorthy, Shafiq Joty, Caiming Xiong, Yingbo Zhou</li>
</ul>
<p>Abstract:<br>The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating “unknown” outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, we provide insightful observations on how to effectively leverage retrieved passages to enhance the answer generation capability of LLMs.</p>
<hr>
<h2 id="Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments"><a href="#Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments" class="headerlink" title="Conditional Kernel Imitation Learning for Continuous State Environments"></a>Conditional Kernel Imitation Learning for Continuous State Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12573">http://arxiv.org/abs/2308.12573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Agrawal, Nathan Dahlin, Rahul Jain, Ashutosh Nayyar</li>
</ul>
<p>Abstract:<br>Imitation Learning (IL) is an important paradigm within the broader reinforcement learning (RL) methodology. Unlike most of RL, it does not assume availability of reward-feedback. Reward inference and shaping are known to be difficult and error-prone methods particularly when the demonstration data comes from human experts. Classical methods such as behavioral cloning and inverse reinforcement learning are highly sensitive to estimation errors, a problem that is particularly acute in continuous state space problems. Meanwhile, state-of-the-art IL algorithms convert behavioral policy learning problems into distribution-matching problems which often require additional online interaction data to be effective. In this paper, we consider the problem of imitation learning in continuous state space environments based solely on observed behavior, without access to transition dynamics information, reward structure, or, most importantly, any additional interactions with the environment. Our approach is based on the Markov balance equation and introduces a novel conditional kernel density estimation-based imitation learning framework. It involves estimating the environment’s transition dynamics using conditional kernel density estimators and seeks to satisfy the probabilistic balance equations for the environment. We establish that our estimators satisfy basic asymptotic consistency requirements. Through a series of numerical experiments on continuous state benchmark environments, we show consistently superior empirical performance over many state-of-the-art IL algorithms.</p>
<hr>
<h2 id="A-Co-training-Approach-for-Noisy-Time-Series-Learning"><a href="#A-Co-training-Approach-for-Noisy-Time-Series-Learning" class="headerlink" title="A Co-training Approach for Noisy Time Series Learning"></a>A Co-training Approach for Noisy Time Series Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12551">http://arxiv.org/abs/2308.12551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung</li>
</ul>
<p>Abstract:<br>In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.</p>
<hr>
<h2 id="Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking"><a href="#Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking" class="headerlink" title="Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking"></a>Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12549">http://arxiv.org/abs/2308.12549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu</li>
</ul>
<p>Abstract:<br>Siamese network has been a de facto benchmark framework for 3D LiDAR object tracking with a shared-parametric encoder extracting features from template and search region, respectively. This paradigm relies heavily on an additional matching network to model the cross-correlation&#x2F;similarity of the template and search region. In this paper, we forsake the conventional Siamese paradigm and propose a novel single-branch framework, SyncTrack, synchronizing the feature extracting and matching to avoid forwarding encoder twice for template and search region as well as introducing extra parameters of matching network. The synchronization mechanism is based on the dynamic affinity of the Transformer, and an in-depth analysis of the relevance is provided theoretically. Moreover, based on the synchronization, we introduce a novel Attentive Points-Sampling strategy into the Transformer layers (APST), replacing the random&#x2F;Farthest Points Sampling (FPS) method with sampling under the supervision of attentive relations between the template and search region. It implies connecting point-wise sampling with the feature learning, beneficial to aggregating more distinctive and geometric features for tracking with sparse points. Extensive experiments on two benchmark datasets (KITTI and NuScenes) show that SyncTrack achieves state-of-the-art performance in real-time tracking.</p>
<hr>
<h2 id="CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias"><a href="#CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias" class="headerlink" title="CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias"></a>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/calm">https://github.com/vipulgupta1011/calm</a></li>
<li>paper_authors: Vipul Gupta, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, Rebecca J. Passonneau</li>
</ul>
<p>Abstract:<br>As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language models including six prominent families of LMs such as Llama-2. In two LM series, OPT and Bloom, we found that larger parameter models are more biased than lower parameter models. We found the T0 series of models to be the least biased. Furthermore, we noticed a tradeoff between gender and racial bias with increasing model size in some model series. The code is available at <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/CALM">https://github.com/vipulgupta1011/CALM</a>.</p>
<hr>
<h2 id="FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning"><a href="#FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning" class="headerlink" title="FedSoL: Bridging Global Alignment and Local Generality in Federated Learning"></a>FedSoL: Bridging Global Alignment and Local Generality in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12532">http://arxiv.org/abs/2308.12532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gihun Lee, Minchan Jeong, Sangmook Kim, Jaehoon Oh, Se-Young Yun</li>
</ul>
<p>Abstract:<br>Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (FedSoL), which combines both the concepts of global alignment and local generality. In FedSoL, the local learning seeks a parameter region robust against proximal perturbations. This strategy introduces an implicit proximal restriction effect in local learning while maintaining the original local objective for parameter update. Our experiments show that FedSoL consistently achieves state-of-the-art performance on various setups.</p>
<hr>
<h2 id="Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion"><a href="#Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion" class="headerlink" title="Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion"></a>Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12517">http://arxiv.org/abs/2308.12517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunho Kim, Hyunsik Oh, Jeonghyun Lee, Jinhyeok Choi, Gwanghyeon Ji, Moonkyu Jung, Donghoon Youm, Jemin Hwangbo</li>
</ul>
<p>Abstract:<br>Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attributes to traverse challenging terrains. Extensive simulation and real-world experiments demonstrate that performant controllers can be trained with significantly less reward engineering, by tuning only a single reward coefficient. Furthermore, a more straightforward and intuitive engineering process can be utilized, thanks to the interpretability and generalizability of constraints. The summary video is available at <a target="_blank" rel="noopener" href="https://youtu.be/KAlm3yskhvM">https://youtu.be/KAlm3yskhvM</a>.</p>
<hr>
<h2 id="I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting"><a href="#I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting" class="headerlink" title="I3DOD: Towards Incremental 3D Object Detection via Prompting"></a>I3DOD: Towards Incremental 3D Object Detection via Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12512">http://arxiv.org/abs/2308.12512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqi Liang, Gan Sun, Chenxi Liu, Jiahua Dong, Kangru Wang</li>
</ul>
<p>Abstract:<br>3D object detection has achieved significant performance in many fields, e.g., robotics system, autonomous driving, and augmented reality. However, most existing methods could cause catastrophic forgetting of old classes when performing on the class-incremental scenarios. Meanwhile, the current class-incremental 3D object detection methods neglect the relationships between the object localization information and category semantic information and assume all the knowledge of old model is reliable. To address the above challenge, we present a novel Incremental 3D Object Detection framework with the guidance of prompting, i.e., I3DOD. Specifically, we propose a task-shared prompts mechanism to learn the matching relationships between the object localization information and category semantic information. After training on the current task, these prompts will be stored in our prompt pool, and perform the relationship of old classes in the next task. Moreover, we design a reliable distillation strategy to transfer knowledge from two aspects: a reliable dynamic distillation is developed to filter out the negative knowledge and transfer the reliable 3D knowledge to new detection model; the relation feature is proposed to capture the responses relation in feature space and protect plasticity of the model when learning novel 3D classes. To the end, we conduct comprehensive experiments on two benchmark datasets and our method outperforms the state-of-the-art object detection methods by 0.6% - 2.7% in terms of <a href="mailto:&#x6d;&#65;&#x50;&#64;&#48;&#46;&#x32;&#53;">&#x6d;&#65;&#x50;&#64;&#48;&#46;&#x32;&#53;</a>.</p>
<hr>
<h2 id="Masked-Autoencoders-are-Efficient-Class-Incremental-Learners"><a href="#Masked-Autoencoders-are-Efficient-Class-Incremental-Learners" class="headerlink" title="Masked Autoencoders are Efficient Class Incremental Learners"></a>Masked Autoencoders are Efficient Class Incremental Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12510">http://arxiv.org/abs/2308.12510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scok30/mae-cil">https://github.com/scok30/mae-cil</a></li>
<li>paper_authors: Jiang-Tian Zhai, Xialei Liu, Andrew D. Bagdanov, Ke Li, Ming-Ming Cheng</li>
</ul>
<p>Abstract:<br>Class Incremental Learning (CIL) aims to sequentially learn new classes while avoiding catastrophic forgetting of previous knowledge. We propose to use Masked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally designed to learn useful representations through reconstructive unsupervised learning, and they can be easily integrated with a supervised loss for classification. Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL. We also propose a bilateral MAE framework to learn from image-level and embedding-level fusion, which produces better-quality reconstructed images and more stable representations. Our experiments confirm that our approach performs better than the state-of-the-art on CIFAR-100, ImageNet-Subset, and ImageNet-Full. The code is available at <a target="_blank" rel="noopener" href="https://github.com/scok30/MAE-CIL">https://github.com/scok30/MAE-CIL</a> .</p>
<hr>
<h2 id="CGMI-Configurable-General-Multi-Agent-Interaction-Framework"><a href="#CGMI-Configurable-General-Multi-Agent-Interaction-Framework" class="headerlink" title="CGMI: Configurable General Multi-Agent Interaction Framework"></a>CGMI: Configurable General Multi-Agent Interaction Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12503">http://arxiv.org/abs/2308.12503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shi Jinxin, Zhao Jiabao, Wang Yilei, Wu Xingjiao, Li Jiawen, He Liang</li>
</ul>
<p>Abstract:<br>Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment’s realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experiments indicate that aspects such as the teaching methodology, curriculum, and student performance closely mirror real classroom settings. We will open source our work.</p>
<hr>
<h2 id="Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis"><a href="#Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis" class="headerlink" title="Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis"></a>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12495">http://arxiv.org/abs/2308.12495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqfang9199/scda">https://github.com/yqfang9199/scda</a></li>
<li>paper_authors: Yuqi Fang, Jinjian Wu, Qianqian Wang, Shijun Qiu, Andrea Bozoki, Huaicheng Yan, Mingxia Liu</li>
</ul>
<p>Abstract:<br>Resting-state functional MRI (rs-fMRI) is increasingly employed in multi-site research to aid neurological disorder analysis. Existing studies usually suffer from significant cross-site&#x2F;domain data heterogeneity caused by site effects such as differences in scanners&#x2F;protocols. Many methods have been proposed to reduce fMRI heterogeneity between source and target domains, heavily relying on the availability of source data. But acquiring source data is challenging due to privacy concerns and&#x2F;or data storage burdens in multi-site studies. To this end, we design a source-free collaborative domain adaptation (SCDA) framework for fMRI analysis, where only a pretrained source model and unlabeled target data are accessible. Specifically, a multi-perspective feature enrichment method (MFE) is developed for target fMRI analysis, consisting of multiple collaborative branches to dynamically capture fMRI features of unlabeled target data from multiple views. Each branch has a data-feeding module, a spatiotemporal feature encoder, and a class predictor. A mutual-consistency constraint is designed to encourage pair-wise consistency of latent features of the same input generated from these branches for robust representation learning. To facilitate efficient cross-domain knowledge transfer without source data, we initialize MFE using parameters of a pretrained source model. We also introduce an unsupervised pretraining strategy using 3,806 unlabeled fMRIs from three large-scale auxiliary databases, aiming to obtain a general feature encoder. Experimental results on three public datasets and one private dataset demonstrate the efficacy of our method in cross-scanner and cross-study prediction tasks. The model pretrained on large-scale rs-fMRI data has been released to the public.</p>
<hr>
<h2 id="GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4"><a href="#GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4" class="headerlink" title="GPTEval: A Survey on Assessments of ChatGPT and GPT-4"></a>GPTEval: A Survey on Assessments of ChatGPT and GPT-4</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12488">http://arxiv.org/abs/2308.12488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Mao, Guanyi Chen, Xulang Zhang, Frank Guerin, Erik Cambria</li>
</ul>
<p>Abstract:<br>The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.</p>
<hr>
<h2 id="A-Model-of-Sequential-Learning-based-on-Non-Axiomatic-Logic"><a href="#A-Model-of-Sequential-Learning-based-on-Non-Axiomatic-Logic" class="headerlink" title="A Model of Sequential Learning based on Non-Axiomatic Logic"></a>A Model of Sequential Learning based on Non-Axiomatic Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12486">http://arxiv.org/abs/2308.12486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Xu</li>
</ul>
<p>Abstract:<br>Sequential learning is a fundamental function of an intelligent agent. This technical report introduces a model of sequential learning, which is interpretable through Non-Axiomatic Logic. The learning procedure includes three steps, hypothesizing, revising, and recycling, and can work under the Assumption of Insufficient Knowledge and Resources. Although there are limitations for the current design, the model has been proven effective in some simple cases.</p>
<hr>
<h2 id="Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection"><a href="#Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection" class="headerlink" title="Attention-Based Acoustic Feature Fusion Network for Depression Detection"></a>Attention-Based Acoustic Feature Fusion Network for Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12478">http://arxiv.org/abs/2308.12478</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuxiaoooo/abafnet">https://github.com/xuxiaoooo/abafnet</a></li>
<li>paper_authors: Xiao Xu, Yang Wang, Xinru Wei, Fei Wang, Xizhe Zhang</li>
</ul>
<p>Abstract:<br>Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech characteristics. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep learning model, thereby effectively integrating and blending multi-tiered features. We present a novel weight adjustment module for late fusion that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two clinical speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCCrelated features in speech-based depression detection.</p>
<hr>
<h2 id="Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis"><a href="#Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis" class="headerlink" title="Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis"></a>Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12466">http://arxiv.org/abs/2308.12466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshat Gupta</li>
</ul>
<p>Abstract:<br>Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.   Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is a more advanced poker player than ChatGPT. This exploration then sheds light on the divergent poker tactics of the two models: ChatGPT’s conservativeness juxtaposed against GPT-4’s aggression. In poker vernacular, when tasked to play GTO poker, ChatGPT plays like a Nit, which means that it has a propensity to only engage with premium hands and folds a majority of hands. When subjected to the same directive, GPT-4 plays like a maniac, showcasing a loose and aggressive style of play. Both strategies, although relatively advanced, are not game theory optimal.</p>
<hr>
<h2 id="PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning"><a href="#PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning" class="headerlink" title="PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning"></a>PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12454">http://arxiv.org/abs/2308.12454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Achintha Wijesinghe, Songyang Zhang, Zhi Ding</li>
</ul>
<p>Abstract:<br>Recent advances of generative learning models are accompanied by the growing interest in federated learning (FL) based on generative adversarial network (GAN) models. In the context of FL, GAN can capture the underlying client data structure, and regenerate samples resembling the original data distribution without compromising the private raw data. Although most existing GAN-based FL works focus on training a global model, Personalized FL (PFL) sometimes can be more effective in view of client data heterogeneity in terms of distinct data sample distributions, feature spaces, and labels. To cope with client heterogeneity in GAN-based FL, we propose a novel GAN sharing and aggregation strategy for PFL. The proposed PFL-GAN addresses the client heterogeneity in different scenarios. More specially, we first learn the similarity among clients and then develop an weighted collaborative data aggregation. The empirical results through the rigorous experimentation on several well-known datasets demonstrate the effectiveness of PFL-GAN.</p>
<hr>
<h2 id="Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models"><a href="#Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models" class="headerlink" title="Augmenting medical image classifiers with synthetic data from latent diffusion models"></a>Augmenting medical image classifiers with synthetic data from latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12453">http://arxiv.org/abs/2308.12453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke W. Sagers, James A. Diao, Luke Melas-Kyriazi, Matthew Groh, Pranav Rajpurkar, Adewole S. Adamson, Veronica Rotemberg, Roxana Daneshjou, Arjun K. Manrai</li>
</ul>
<p>Abstract:<br>While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using several generation strategies. Our results suggest that synthetic data could serve as a force-multiplier for model development, but the collection of diverse real-world data remains the most important step to improve medical AI algorithms.</p>
<hr>
<h2 id="An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems"><a href="#An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems" class="headerlink" title="An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems"></a>An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12445">http://arxiv.org/abs/2308.12445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmedhajyahmed/drdrl">https://github.com/ahmedhajyahmed/drdrl</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Rached Bouchoucha, Houssem Ben Braiek, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment’s conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases the DRL system’s minor behaviors to systematically prioritize the adaptation of the key problem-solving skills. Using well-established DRL algorithms, Dr. DRL is compared with vanilla CL on various drifted environments. Dr. DRL is able to reduce, on average, the healing time and fine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully helps agents to adapt to 19.63% of drifted environments left unsolved by vanilla CL while maintaining and even enhancing by up to 45% the obtained rewards for drifted environments that are resolved by both approaches.</p>
<hr>
<h2 id="BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection"><a href="#BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection" class="headerlink" title="BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection"></a>BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12439">http://arxiv.org/abs/2308.12439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal</li>
</ul>
<p>Abstract:<br>We present a novel defense, against backdoor attacks on Deep Neural Networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. The proposed defense is built upon a novel reverse engineering approach that can directly extract backdoor functionality of a given backdoored model to a backdoor expert model. The approach is straightforward – finetuning the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising highly accurate backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by an ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert (Backdoor Input Detection with Backdoor Expert), effectively mitigates 16 SOTA backdoor attacks while minimally impacting clean utility. The effectiveness of BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet) across various model architectures (ResNet, VGG, MobileNetV2 and Vision Transformer).</p>
<hr>
<h2 id="Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges"><a href="#Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges" class="headerlink" title="Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges"></a>Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12438">http://arxiv.org/abs/2308.12438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/drldeploymentchallenges-icsme2023/replicationpackage">https://github.com/drldeploymentchallenges-icsme2023/replicationpackage</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Altaf Allah Abbassi, Amin Nikanjam, Heng Li, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL), leveraging Deep Learning (DL) in reinforcement learning, has shown significant potential in achieving human-level autonomy in a wide range of domains, including robotics, computer vision, and computer games. This potential justifies the enthusiasm and growing interest in DRL in both academia and industry. However, the community currently focuses mostly on the development phase of DRL systems, with little attention devoted to DRL deployment. In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&amp;A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems. Specifically, we categorized relevant SO posts by deployment platforms: server&#x2F;cloud, mobile&#x2F;embedded system, browser, and game engine. After filtering and manual analysis, we examined 357 SO posts about DRL deployment, investigated the current state, and identified the challenges related to deploying DRL systems. Then, we investigate the prevalence and difficulty of these challenges. Results show that the general interest in DRL deployment is growing, confirming the study’s relevance and importance. Results also show that DRL deployment is more difficult than other DRL issues. Additionally, we built a taxonomy of 31 unique challenges in deploying DRL to different platforms. On all platforms, RL environment-related challenges are the most popular, and communication-related challenges are the most difficult among practitioners. We hope our study inspires future research and helps the community overcome the most common and difficult challenges practitioners face when deploying DRL systems.</p>
<hr>
<h2 id="Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach"><a href="#Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach" class="headerlink" title="Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach"></a>Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12416">http://arxiv.org/abs/2308.12416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha Gianchandani, Mahsa Dibaji, Mariana Bento, Ethan MacDonald, Roberto Souza</li>
</ul>
<p>Abstract:<br>Deep learning models have achieved state-of-the-art results in estimating brain age, which is an important brain health biomarker, from magnetic resonance (MR) images. However, most of these models only provide a global age prediction, and rely on techniques, such as saliency maps to interpret their results. These saliency maps highlight regions in the input image that were significant for the model’s predictions, but they are hard to be interpreted, and saliency map values are not directly comparable across different samples. In this work, we reframe the age prediction problem from MR images to an image-to-image regression problem where we estimate the brain age for each brain voxel in MR images. We compare voxel-wise age prediction models against global age prediction models and their corresponding saliency maps. The results indicate that voxel-wise age prediction models are more interpretable, since they provide spatial information about the brain aging process, and they benefit from being quantitative.</p>
<hr>
<h2 id="Benchmarking-Causal-Study-to-Interpret-Large-Language-Models-for-Source-Code"><a href="#Benchmarking-Causal-Study-to-Interpret-Large-Language-Models-for-Source-Code" class="headerlink" title="Benchmarking Causal Study to Interpret Large Language Models for Source Code"></a>Benchmarking Causal Study to Interpret Large Language Models for Source Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12415">http://arxiv.org/abs/2308.12415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Rodriguez-Cardenas, David N. Palacio, Dipin Khati, Henry Burke, Denys Poshyvanyk</li>
</ul>
<p>Abstract:<br>One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs’ performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model’s performance. In an effort to bring statistical rigor to the evaluation of LLMs, this paper introduces a benchmarking strategy named Galeras comprised of curated testbeds for three SE tasks (i.e., code completion, code summarization, and commit generation) to help aid the interpretation of LLMs’ performance. We illustrate the insights of our benchmarking strategy by conducting a case study on the performance of ChatGPT under distinct prompt engineering methods. The results of the case study demonstrate the positive causal influence of prompt semantics on ChatGPT’s generative performance by an average treatment effect of $\approx 3%$. Moreover, it was found that confounders such as prompt size are highly correlated with accuracy metrics ($\approx 0.412%$). The end result of our case study is to showcase causal inference evaluations, in practice, to reduce confounding bias. By reducing the bias, we offer an interpretable solution for the accuracy metric under analysis.</p>
<hr>
<h2 id="A-Theory-of-Intelligences-Concepts-Models-Implications"><a href="#A-Theory-of-Intelligences-Concepts-Models-Implications" class="headerlink" title="A Theory of Intelligences: Concepts, Models, Implications"></a>A Theory of Intelligences: Concepts, Models, Implications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12411">http://arxiv.org/abs/2308.12411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael E. Hochberg</li>
</ul>
<p>Abstract:<br>Intelligence is a human construct to represent the ability to achieve goals. Given this wide berth, intelligence has been defined countless times, studied in a variety of ways and quantified using numerous measures. Understanding intelligence ultimately requires theory and quantification, both of which are elusive. My main objectives are to identify some of the central elements in and surrounding intelligence, discuss some of its challenges and propose a theory based on first principles. I focus on intelligence as defined by and for humans, frequently in comparison to machines, with the intention of setting the stage for more general characterizations in life, collectives, human designs such as AI and in non-designed physical and chemical systems. I discuss key features of intelligence, including path efficiency and goal accuracy, intelligence as a Black Box, environmental influences, flexibility to deal with surprisal, the regress of intelligence, the relativistic nature of intelligence and difficulty, and temporal changes in intelligence including its evolution. I present a framework for a first principles Theory of IntelligenceS (TIS), based on the quantifiable macro-scale system features of difficulty, surprisal and goal resolution accuracy. The proposed partitioning of uncertainty&#x2F;solving and accuracy&#x2F;understanding is particularly novel since it predicts that paths to a goal not only function to accurately achieve goals, but as experimentations leading to higher probabilities for future attainable goals and increased breadth to enter new goal spaces. TIS can therefore explain endeavors that do not necessarily affect Darwinian fitness, such as leisure, politics, games and art. I conclude with several conceptual advances of TIS including a compact mathematical form of surprisal and difficulty, the theoretical basis of TIS, and open questions.</p>
<hr>
<h2 id="Self-Supervised-Learning-for-Endoscopic-Video-Analysis"><a href="#Self-Supervised-Learning-for-Endoscopic-Video-Analysis" class="headerlink" title="Self-Supervised Learning for Endoscopic Video Analysis"></a>Self-Supervised Learning for Endoscopic Video Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12394">http://arxiv.org/abs/2308.12394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/royhirsch/endossl">https://github.com/royhirsch/endossl</a></li>
<li>paper_authors: Roy Hirsch, Mathilde Caron, Regev Cohen, Amir Livne, Ron Shapiro, Tomer Golany, Roman Goldenberg, Daniel Freedman, Ehud Rivlin</li>
</ul>
<p>Abstract:<br>Self-supervised learning (SSL) has led to important breakthroughs in computer vision by allowing learning from large amounts of unlabeled data. As such, it might have a pivotal role to play in biomedicine where annotating data requires a highly specialized expertise. Yet, there are many healthcare domains for which SSL has not been extensively explored. One such domain is endoscopy, minimally invasive procedures which are commonly used to detect and treat infections, chronic inflammatory diseases or cancer. In this work, we study the use of a leading SSL framework, namely Masked Siamese Networks (MSNs), for endoscopic video analysis such as colonoscopy and laparoscopy. To fully exploit the power of SSL, we create sizable unlabeled endoscopic video datasets for training MSNs. These strong image representations serve as a foundation for secondary training with limited annotated datasets, resulting in state-of-the-art performance in endoscopic benchmarks like surgical phase recognition during laparoscopy and colonoscopic polyp characterization. Additionally, we achieve a 50% reduction in annotated data size without sacrificing performance. Thus, our work provides evidence that SSL can dramatically reduce the need of annotated data in endoscopy.</p>
<hr>
<h2 id="With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning"><a href="#With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning" class="headerlink" title="With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning"></a>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12383">http://arxiv.org/abs/2308.12383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/pma-net">https://github.com/aimagelab/pma-net</a></li>
<li>paper_authors: Manuele Barraco, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</li>
</ul>
<p>Abstract:<br>Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components. We demonstrate that our proposal can increase the performance of an encoder-decoder Transformer by 3.7 CIDEr points both when training in cross-entropy only and when fine-tuning with self-critical sequence training. Source code and trained models are available at: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/PMA-Net">https://github.com/aimagelab/PMA-Net</a>.</p>
<hr>
<h2 id="Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation"><a href="#Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation" class="headerlink" title="Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation"></a>Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12371">http://arxiv.org/abs/2308.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Manuel Günther, William Robson Schwartz</li>
</ul>
<p>Abstract:<br>Open-set face recognition refers to a scenario in which biometric systems have incomplete knowledge of all existing subjects. Therefore, they are expected to prevent face samples of unregistered subjects from being identified as previously enrolled identities. This watchlist context adds an arduous requirement that calls for the dismissal of irrelevant faces by focusing mainly on subjects of interest. As a response, this work introduces a novel method that associates an ensemble of compact neural networks with a margin-based cost function that explores additional samples. Supplementary negative samples can be obtained from external databases or synthetically built at the representation level in training time with a new mix-up feature augmentation approach. Deep neural networks pre-trained on large face datasets serve as the preliminary feature extraction module. We carry out experiments on well-known LFW and IJB-C datasets where results show that the approach is able to boost closed and open-set identification rates.</p>
<hr>
<h2 id="SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies"><a href="#SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies" class="headerlink" title="SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies"></a>SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12367">http://arxiv.org/abs/2308.12367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochen Wu, Shubham Sharma, Sunandita Patra, Sriram Gopalakrishnan</li>
</ul>
<p>Abstract:<br>With the growing use of machine learning (ML) models in critical domains such as finance and healthcare, the need to offer recourse for those adversely affected by the decisions of ML models has become more important; individuals ought to be provided with recommendations on actions to take for improving their situation and thus receive a favorable decision. Prior work on sequential algorithmic recourse – which recommends a series of changes – focuses on action feasibility and uses the proximity of feature changes to determine action costs. However, the uncertainties of feature changes and the risk of higher than average costs in recourse have not been considered. It is undesirable if a recourse could (with some probability) result in a worse situation from which recovery requires an extremely high cost. It is essential to incorporate risks when computing and evaluating recourse. We call the recourse computed with such risk considerations as Safer Algorithmic Recourse (SafeAR). The objective is to empower people to choose a recourse based on their risk tolerance. In this work, we discuss and show how existing recourse desiderata can fail to capture the risk of higher costs. We present a method to compute recourse policies that consider variability in cost and connect algorithmic recourse literature with risk-sensitive reinforcement learning. We also adopt measures <code>Value at Risk&#39;&#39; and </code>Conditional Value at Risk’’ from the financial literature to summarize risk concisely. We apply our method to two real-world datasets and compare policies with different levels of risk-aversion using risk measures and recourse desiderata (sparsity and proximity).</p>
<hr>
<h2 id="CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images"><a href="#CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images" class="headerlink" title="CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images"></a>CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12288">http://arxiv.org/abs/2308.12288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sookwan Han, Hanbyul Joo</li>
</ul>
<p>Abstract:<br>We present a method for teaching machines to understand and model the underlying spatial common sense of diverse human-object interactions in 3D in a self-supervised way. This is a challenging task, as there exist specific manifolds of the interactions that can be considered human-like and natural, but the human pose and the geometry of objects can vary even for similar interactions. Such diversity makes the annotating task of 3D interactions difficult and hard to scale, which limits the potential to reason about that in a supervised way. One way of learning the 3D spatial relationship between humans and objects during interaction is by showing multiple 2D images captured from different viewpoints when humans interact with the same type of objects. The core idea of our method is to leverage a generative model that produces high-quality 2D images from an arbitrary text prompt input as an “unbounded” data generator with effective controllability and view diversity. Despite its imperfection of the image quality over real images, we demonstrate that the synthesized images are sufficient to learn the 3D human-object spatial relations. We present multiple strategies to leverage the synthesized images, including (1) the first method to leverage a generative image model for 3D human-object spatial relation learning; (2) a framework to reason about the 3D spatial relations from inconsistent 2D cues in a self-supervised manner via 3D occupancy reasoning with pose canonicalization; (3) semantic clustering to disambiguate different types of interactions with the same object types; and (4) a novel metric to assess the quality of 3D spatial learning of interaction. Project Page: <a target="_blank" rel="noopener" href="https://jellyheadandrew.github.io/projects/chorus">https://jellyheadandrew.github.io/projects/chorus</a></p>
<hr>
<h2 id="D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification"><a href="#D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification" class="headerlink" title="D4: Improving LLM Pretraining via Document De-Duplication and Diversification"></a>D4: Improving LLM Pretraining via Document De-Duplication and Diversification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12284">http://arxiv.org/abs/2308.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos</li>
</ul>
<p>Abstract:<br>Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.</p>
<hr>
<h2 id="Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models"><a href="#Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models" class="headerlink" title="Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models"></a>Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12272">http://arxiv.org/abs/2308.12272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nancy Tyagi, Aidin Shiri, Surjodeep Sarkar, Abhishek Kumar Umrawal, Manas Gaur</li>
</ul>
<p>Abstract:<br>Foundational Language Models (FLMs) have advanced natural language processing (NLP) research. Current researchers are developing larger FLMs (e.g., XLNet, T5) to enable contextualized language representation, classification, and generation. While developing larger FLMs has been of significant advantage, it is also a liability concerning hallucination and predictive uncertainty. Fundamentally, larger FLMs are built on the same foundations as smaller FLMs (e.g., BERT); hence, one must recognize the potential of smaller FLMs which can be realized through an ensemble. In the current research, we perform a reality check on FLMs and their ensemble on benchmark and real-world datasets. We hypothesize that the ensembling of FLMs can influence the individualistic attention of FLMs and unravel the strength of coordination and cooperation of different FLMs. We utilize BERT and define three other ensemble techniques: {Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a knowledge-guided reinforcement learning approach. We discovered that the suggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by a factor of many times using datasets that show the usefulness of NLP in sensitive fields, such as mental health.</p>
<hr>
<h2 id="Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning"><a href="#Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning" class="headerlink" title="Language Reward Modulation for Pretraining Reinforcement Learning"></a>Language Reward Modulation for Pretraining Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12270">http://arxiv.org/abs/2308.12270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ademiadeniji/lamp">https://github.com/ademiadeniji/lamp</a></li>
<li>paper_authors: Ademi Adeniji, Amber Xie, Carmelo Sferrazza, Younggyo Seo, Stephen James, Pieter Abbeel</li>
</ul>
<p>Abstract:<br>Using learned reward functions (LRFs) as a means to solve sparse-reward reinforcement learning (RL) tasks has yielded some steady progress in task-complexity through the years. In this work, we question whether today’s LRFs are best-suited as a direct replacement for task rewards. Instead, we propose leveraging the capabilities of LRFs as a pretraining signal for RL. Concretely, we propose $\textbf{LA}$nguage Reward $\textbf{M}$odulated $\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of Vision-Language Models (VLMs) as a $\textit{pretraining}$ utility for RL as opposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to scalably generate noisy, albeit shaped exploration rewards by computing the contrastive alignment between a highly diverse collection of language instructions and the image observations of an agent in its pretraining environment. LAMP optimizes these rewards in conjunction with standard novelty-seeking exploration rewards with reinforcement learning to acquire a language-conditioned, pretrained policy. Our VLM pretraining approach, which is a departure from previous attempts to use LRFs, can warmstart sample-efficient learning on robot manipulation tasks in RLBench.</p>
<hr>
<h2 id="FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning"><a href="#FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning" class="headerlink" title="FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning"></a>FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12264">http://arxiv.org/abs/2308.12264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabhsingh Rajput, Tim Widmayer, Ziyuan Shang, Maria Kechagia, Federica Sarro, Tushar Sharma</li>
</ul>
<p>Abstract:<br>With the increasing usage, scale, and complexity of Deep Learning (DL) models, their rapidly growing energy consumption has become a critical concern. Promoting green development and energy awareness at different granularities is the need of the hour to limit carbon emissions of DL systems. However, the lack of standard and repeatable tools to accurately measure and optimize energy consumption at a fine granularity (e.g., at method level) hinders progress in this area. In this paper, we introduce FECoM (Fine-grained Energy Consumption Meter), a framework for fine-grained DL energy consumption measurement. Specifically, FECoM provides researchers and developers a mechanism to profile DL APIs. FECoM addresses the challenges of measuring energy consumption at fine-grained level by using static instrumentation and considering various factors, including computational load and temperature stability. We assess FECoM’s capability to measure fine-grained energy consumption for one of the most popular open-source DL frameworks, namely TensorFlow. Using FECoM, we also investigate the impact of parameter size and execution time on energy consumption, enriching our understanding of TensorFlow APIs’ energy profiles. Furthermore, we elaborate on the considerations, issues, and challenges that one needs to consider while designing and implementing a fine-grained energy consumption measurement tool. We hope this work will facilitate further advances in DL energy measurement and the development of energy-aware practices for DL systems.</p>
<hr>
<h2 id="Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training"><a href="#Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training" class="headerlink" title="Multi-Objective Optimization for Sparse Deep Neural Network Training"></a>Multi-Objective Optimization for Sparse Deep Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12243">http://arxiv.org/abs/2308.12243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/mdmtn">https://github.com/salomonhotegni/mdmtn</a></li>
<li>paper_authors: S. S. Hotegni, S. Peitz, M. Berkemeier</li>
</ul>
<p>Abstract:<br>Different conflicting optimization criteria arise naturally in various Deep Learning scenarios. These can address different main tasks (i.e., in the setting of Multi-Task Learning), but also main and secondary tasks such as loss minimization versus sparsity. The usual approach is a simple weighting of the criteria, which formally only works in the convex setting. In this paper, we present a Multi-Objective Optimization algorithm using a modified Weighted Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect to several tasks. By employing this scalarization technique, the algorithm can identify all optimal solutions of the original problem while reducing its complexity to a sequence of single-objective problems. The simplified problems are then solved using an Augmented Lagrangian method, enabling the use of popular optimization techniques such as Adam and Stochastic Gradient Descent, while efficaciously handling constraints. Our work aims to address the (economical and also ecological) sustainability issue of DNN models, with a particular focus on Deep Multi-Task models, which are typically designed with a very large number of weights to perform equally well on multiple tasks. Through experiments conducted on two Machine Learning datasets, we demonstrate the possibility of adaptively sparsifying the model during training without significantly impacting its performance, if we are willing to apply task-specific adaptations to the network weights. Code is available at <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/MDMTN">https://github.com/salomonhotegni/MDMTN</a>.</p>
<hr>
<h2 id="LLMRec-Benchmarking-Large-Language-Models-on-Recommendation-Task"><a href="#LLMRec-Benchmarking-Large-Language-Models-on-Recommendation-Task" class="headerlink" title="LLMRec: Benchmarking Large Language Models on Recommendation Task"></a>LLMRec: Benchmarking Large Language Models on Recommendation Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12241">http://arxiv.org/abs/2308.12241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/williamliujl/llmrec">https://github.com/williamliujl/llmrec</a></li>
<li>paper_authors: Junling Liu, Chao Liu, Peilin Zhou, Qichen Ye, Dading Chong, Kang Zhou, Yueqi Xie, Yuwei Cao, Shoujin Wang, Chenyu You, Philip S. Yu</li>
</ul>
<p>Abstract:<br>Recently, the fast development of Large Language Models (LLMs) such as ChatGPT has significantly advanced NLP tasks by enhancing the capabilities of conversational models. However, the application of LLMs in the recommendation domain has not been thoroughly investigated. To bridge this gap, we propose LLMRec, a LLM-based recommender system designed for benchmarking LLMs on various recommendation tasks. Specifically, we benchmark several popular off-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation tasks, including rating prediction, sequential recommendation, direct recommendation, explanation generation, and review summarization. Furthermore, we investigate the effectiveness of supervised finetuning to improve LLMs’ instruction compliance ability. The benchmark results indicate that LLMs displayed only moderate proficiency in accuracy-based tasks such as sequential and direct recommendation. However, they demonstrated comparable performance to state-of-the-art methods in explainability-based tasks. We also conduct qualitative evaluations to further evaluate the quality of contents generated by different models, and the results show that LLMs can truly understand the provided information and generate clearer and more reasonable results. We aspire that this benchmark will serve as an inspiration for researchers to delve deeper into the potential of LLMs in enhancing recommendation performance. Our codes, processed data and benchmark results are available at <a target="_blank" rel="noopener" href="https://github.com/williamliujl/LLMRec">https://github.com/williamliujl/LLMRec</a>.</p>
<hr>
<h2 id="Enhancing-cardiovascular-risk-prediction-through-AI-enabled-calcium-omics"><a href="#Enhancing-cardiovascular-risk-prediction-through-AI-enabled-calcium-omics" class="headerlink" title="Enhancing cardiovascular risk prediction through AI-enabled calcium-omics"></a>Enhancing cardiovascular risk prediction through AI-enabled calcium-omics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12224">http://arxiv.org/abs/2308.12224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar Hoori, Sadeer Al-Kindi, Tao Hu, Yingnan Song, Hao Wu, Juhwan Lee, Nour Tashtish, Pingfu Fu, Robert Gilkeson, Sanjay Rajagopalan, David L. Wilson</li>
</ul>
<p>Abstract:<br>Background. Coronary artery calcium (CAC) is a powerful predictor of major adverse cardiovascular events (MACE). Traditional Agatston score simply sums the calcium, albeit in a non-linear way, leaving room for improved calcification assessments that will more fully capture the extent of disease.   Objective. To determine if AI methods using detailed calcification features (i.e., calcium-omics) can improve MACE prediction.   Methods. We investigated additional features of calcification including assessment of mass, volume, density, spatial distribution, territory, etc. We used a Cox model with elastic-net regularization on 2457 CT calcium score (CTCS) enriched for MACE events obtained from a large no-cost CLARIFY program (ClinicalTri-als.gov Identifier: NCT04075162). We employed sampling techniques to enhance model training. We also investigated Cox models with selected features to identify explainable high-risk characteristics.   Results. Our proposed calcium-omics model with modified synthetic down sampling and up sampling gave C-index (80.5%&#x2F;71.6%) and two-year AUC (82.4%&#x2F;74.8%) for (80:20, training&#x2F;testing), respectively (sampling was applied to the training set only). Results compared favorably to Agatston which gave C-index (71.3%&#x2F;70.3%) and AUC (71.8%&#x2F;68.8%), respectively. Among calcium-omics features, numbers of calcifications, LAD mass, and diffusivity (a measure of spatial distribution) were important determinants of increased risk, with dense calcification (&gt;1000HU) associated with lower risk. The calcium-omics model reclassified 63% of MACE patients to the high risk group in a held-out test. The categorical net-reclassification index was NRI&#x3D;0.153.   Conclusions. AI analysis of coronary calcification can lead to improved results as compared to Agatston scoring. Our findings suggest the utility of calcium-omics in improved prediction of risk.</p>
<hr>
<h2 id="Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks"><a href="#Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks" class="headerlink" title="Critical Learning Periods Emerge Even in Deep Linear Networks"></a>Critical Learning Periods Emerge Even in Deep Linear Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12221">http://arxiv.org/abs/2308.12221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kleinman, Alessandro Achille, Stefano Soatto</li>
</ul>
<p>Abstract:<br>Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks.</p>
<hr>
<h2 id="Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning"><a href="#Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning" class="headerlink" title="Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning"></a>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12219">http://arxiv.org/abs/2308.12219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yegcjs/diffusionllm">https://github.com/yegcjs/diffusionllm</a></li>
<li>paper_authors: Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu</li>
</ul>
<p>Abstract:<br>The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream language tasks. We further discover that instruction finetuning can elicit zero-shot and few-shot in-context learning abilities that help tackle many unseen tasks by following natural language instructions, and show promise in advanced and challenging abilities such as reasoning</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.AI_2023_08_24/" data-id="cllqfou9y0005a4884tz1gqe8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.CL_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/cs.CL_2023_08_24/">cs.CL - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Text-Similarity-from-Image-Contents-using-Statistical-and-Semantic-Analysis-Techniques"><a href="#Text-Similarity-from-Image-Contents-using-Statistical-and-Semantic-Analysis-Techniques" class="headerlink" title="Text Similarity from Image Contents using Statistical and Semantic Analysis Techniques"></a>Text Similarity from Image Contents using Statistical and Semantic Analysis Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12842">http://arxiv.org/abs/2308.12842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sagar Kulkarni, Sharvari Govilkar, Dhiraj Amin</li>
</ul>
<p>Abstract:<br>Plagiarism detection is one of the most researched areas among the Natural Language Processing(NLP) community. A good plagiarism detection covers all the NLP methods including semantics, named entities, paraphrases etc. and produces detailed plagiarism reports. Detection of Cross Lingual Plagiarism requires deep knowledge of various advanced methods and algorithms to perform effective text similarity checking. Nowadays the plagiarists are also advancing themselves from hiding the identity from being catch in such offense. The plagiarists are bypassed from being detected with techniques like paraphrasing, synonym replacement, mismatching citations, translating one language to another. Image Content Plagiarism Detection (ICPD) has gained importance, utilizing advanced image content processing to identify instances of plagiarism to ensure the integrity of image content. The issue of plagiarism extends beyond textual content, as images such as figures, graphs, and tables also have the potential to be plagiarized. However, image content plagiarism detection remains an unaddressed challenge. Therefore, there is a critical need to develop methods and systems for detecting plagiarism in image content. In this paper, the system has been implemented to detect plagiarism form contents of Images such as Figures, Graphs, Tables etc. Along with statistical algorithms such as Jaccard and Cosine, introducing semantic algorithms such as LSA, BERT, WordNet outperformed in detecting efficient and accurate plagiarism.</p>
<hr>
<h2 id="Use-of-LLMs-for-Illicit-Purposes-Threats-Prevention-Measures-and-Vulnerabilities"><a href="#Use-of-LLMs-for-Illicit-Purposes-Threats-Prevention-Measures-and-Vulnerabilities" class="headerlink" title="Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities"></a>Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12833">http://arxiv.org/abs/2308.12833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Mozes, Xuanli He, Bennett Kleinberg, Lewis D. Griffin</li>
</ul>
<p>Abstract:<br>Spurred by the recent rapid increase in the development and distribution of large language models (LLMs) across industry and academia, much recent work has drawn attention to safety- and security-related threats and vulnerabilities of LLMs, including in the context of potentially criminal activities. Specifically, it has been shown that LLMs can be misused for fraud, impersonation, and the generation of malware; while other authors have considered the more general problem of AI alignment. It is important that developers and practitioners alike are aware of security-related problems with such models. In this paper, we provide an overview of existing - predominantly scientific - efforts on identifying and mitigating threats and vulnerabilities arising from LLMs. We present a taxonomy describing the relationship between threats caused by the generative capabilities of LLMs, prevention measures intended to address such threats, and vulnerabilities arising from imperfect prevention measures. With our work, we hope to raise awareness of the limitations of LLMs in light of such security concerns, among both experienced developers and novel users of such technologies.</p>
<hr>
<h2 id="WavMark-Watermarking-for-Audio-Generation"><a href="#WavMark-Watermarking-for-Audio-Generation" class="headerlink" title="WavMark: Watermarking for Audio Generation"></a>WavMark: Watermarking for Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12770">http://arxiv.org/abs/2308.12770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, Furu Wei</li>
</ul>
<p>Abstract:<br>Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker’s voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achieve heightened robustness and expanded capacity. Utilizing 10 to 20-second audio as the host, our approach demonstrates an average Bit Error Rate (BER) of 0.48% across ten common attacks, a remarkable reduction of over 2800% in BER compared to the state-of-the-art watermarking tool. See <a target="_blank" rel="noopener" href="https://aka.ms/wavmark">https://aka.ms/wavmark</a> for demos of our work.</p>
<hr>
<h2 id="Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion"><a href="#Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion" class="headerlink" title="Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion"></a>Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12734">http://arxiv.org/abs/2308.12734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan J. Bird, Ahmad Lotfi</li>
</ul>
<p>Abstract:<br>There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learning models over 10-fold cross validation, it is found that the Extreme Gradient Boosting model can achieve an average classification accuracy of 99.3% and can classify speech in real-time, at around 0.004 milliseconds given one second of speech. All data generated for this study is released publicly for future research on AI speech detection.</p>
<hr>
<h2 id="Harnessing-the-Power-of-David-against-Goliath-Exploring-Instruction-Data-Generation-without-Using-Closed-Source-Models"><a href="#Harnessing-the-Power-of-David-against-Goliath-Exploring-Instruction-Data-Generation-without-Using-Closed-Source-Models" class="headerlink" title="Harnessing the Power of David against Goliath: Exploring Instruction Data Generation without Using Closed-Source Models"></a>Harnessing the Power of David against Goliath: Exploring Instruction Data Generation without Using Closed-Source Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12711">http://arxiv.org/abs/2308.12711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Wang, Xinrui Wang, Juntao Li, Jinxiong Chang, Qishen Zhang, Zhongyi Liu, Guannan Zhang, Min Zhang</li>
</ul>
<p>Abstract:<br>Instruction tuning is instrumental in enabling Large Language Models~(LLMs) to follow user instructions to complete various open-domain tasks. The success of instruction tuning depends on the availability of high-quality instruction data. Owing to the exorbitant cost and substandard quality of human annotation, recent works have been deeply engaged in the exploration of the utilization of powerful closed-source models to generate instruction data automatically. However, these methods carry potential risks arising from the usage requirements of powerful closed-source models, which strictly forbid the utilization of their outputs to develop machine learning models. To deal with this problem, in this work, we explore alternative approaches to generate high-quality instruction data that do not rely on closed-source models. Our exploration includes an investigation of various existing instruction generation methods, culminating in the integration of the most efficient variant with two novel strategies to enhance the quality further. Evaluation results from two benchmarks and the GPT-4 model demonstrate the effectiveness of our generated instruction data, which can outperform Alpaca, a method reliant on closed-source models. We hope that more progress can be achieved in generating high-quality instruction data without using closed-source models.</p>
<hr>
<h2 id="Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions"><a href="#Improving-Translation-Faithfulness-of-Large-Language-Models-via-Augmenting-Instructions" class="headerlink" title="Improving Translation Faithfulness of Large Language Models via Augmenting Instructions"></a>Improving Translation Faithfulness of Large Language Models via Augmenting Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12674">http://arxiv.org/abs/2308.12674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pppa2019/swie_overmiss_llm4mt">https://github.com/pppa2019/swie_overmiss_llm4mt</a></li>
<li>paper_authors: Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou</li>
</ul>
<p>Abstract:<br>Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-stream open-source LLMs, BLOOM and LLaMA. The experimental results demonstrate significant improvements in translation performance with SWIE based on BLOOMZ-3b, particularly in zero-shot and long text translations due to reduced instruction forgetting risk. Additionally, OVERMISS outperforms the baseline in translation performance (e.g. an increase in BLEU scores from 0.69 to 3.12 and an average improvement of 0.48 percentage comet scores for LLaMA-7b) with further enhancements seen in models combining OVERMISS and SWIE (e.g. the BLUE scores increase up to 0.56 from English to German across three different backbones), and both exhibit improvements in the faithfulness metric based on word alignment.</p>
<hr>
<h2 id="From-Chatter-to-Matter-Addressing-Critical-Steps-of-Emotion-Recognition-Learning-in-Task-oriented-Dialogue"><a href="#From-Chatter-to-Matter-Addressing-Critical-Steps-of-Emotion-Recognition-Learning-in-Task-oriented-Dialogue" class="headerlink" title="From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue"></a>From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12648">http://arxiv.org/abs/2308.12648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shutong Feng, Nurul Lubis, Benjamin Ruppik, Christian Geishauser, Michael Heck, Hsien-chin Lin, Carel van Niekerk, Renato Vukovic, Milica Gašić</li>
</ul>
<p>Abstract:<br>Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotion in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.</p>
<hr>
<h2 id="Probabilistic-Method-of-Measuring-Linguistic-Productivity"><a href="#Probabilistic-Method-of-Measuring-Linguistic-Productivity" class="headerlink" title="Probabilistic Method of Measuring Linguistic Productivity"></a>Probabilistic Method of Measuring Linguistic Productivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12643">http://arxiv.org/abs/2308.12643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sergei Monakhov</li>
</ul>
<p>Abstract:<br>In this paper I propose a new way of measuring linguistic productivity that objectively assesses the ability of an affix to be used to coin new complex words and, unlike other popular measures, is not directly dependent upon token frequency. Specifically, I suggest that linguistic productivity may be viewed as the probability of an affix to combine with a random base. The advantages of this approach include the following. First, token frequency does not dominate the productivity measure but naturally influences the sampling of bases. Second, we are not just counting attested word types with an affix but rather simulating the construction of these types and then checking whether they are attested in the corpus. Third, a corpus-based approach and randomised design assure that true neologisms and words coined long ago have equal chances to be selected. The proposed algorithm is evaluated both on English and Russian data. The obtained results provide some valuable insights into the relation of linguistic productivity to the number of types and tokens. It looks like burgeoning linguistic productivity manifests itself in an increasing number of types. However, this process unfolds in two stages: first comes the increase in high-frequency items, and only then follows the increase in low-frequency items.</p>
<hr>
<h2 id="Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines"><a href="#Advancing-Hungarian-Text-Processing-with-HuSpaCy-Efficient-and-Accurate-NLP-Pipelines" class="headerlink" title="Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines"></a>Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12635">http://arxiv.org/abs/2308.12635</a></li>
<li>repo_url: None</li>
<li>paper_authors: György Orosz, Gergő Szabó, Péter Berkecz, Zsolt Szántó, Richárd Farkas</li>
</ul>
<p>Abstract:<br>This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.</p>
<hr>
<h2 id="PromptMRG-Diagnosis-Driven-Prompts-for-Medical-Report-Generation"><a href="#PromptMRG-Diagnosis-Driven-Prompts-for-Medical-Report-Generation" class="headerlink" title="PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation"></a>PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12604">http://arxiv.org/abs/2308.12604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haibo Jin, Haoxuan Che, Yi Lin, Hao Chen</li>
</ul>
<p>Abstract:<br>Automatic medical report generation (MRG) is of great research value as it has the potential to relieve radiologists from the heavy burden of report writing. Despite recent advancements, accurate MRG remains challenging due to the need for precise clinical understanding and the identification of clinical findings. Moreover, the imbalanced distribution of diseases makes the challenge even more pronounced, as rare diseases are underrepresented in training data, making their diagnostic performance unreliable. To address these challenges, we propose diagnosis-driven prompts for medical report generation (PromptMRG), a novel framework that aims to improve the diagnostic accuracy of MRG with the guidance of diagnosis-aware prompts. Specifically, PromptMRG is based on encoder-decoder architecture with an extra disease classification branch. When generating reports, the diagnostic results from the classification branch are converted into token prompts to explicitly guide the generation process. To further improve the diagnostic accuracy, we design cross-modal feature enhancement, which retrieves similar reports from the database to assist the diagnosis of a query image by leveraging the knowledge from a pre-trained CLIP. Moreover, the disease imbalanced issue is addressed by applying an adaptive logit-adjusted loss to the classification branch based on the individual learning status of each disease, which overcomes the barrier of text decoder’s inability to manipulate disease distributions. Experiments on two MRG benchmarks show the effectiveness of the proposed method, where it obtains state-of-the-art clinical efficacy performance on both datasets.</p>
<hr>
<h2 id="Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models"><a href="#Mind-vs-Mouth-On-Measuring-Re-judge-Inconsistency-of-Social-Bias-in-Large-Language-Models" class="headerlink" title="Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models"></a>Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12578">http://arxiv.org/abs/2308.12578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yachao Zhao, Bo Wang, Dongming Zhao, Kun Huang, Yan Wang, Ruifang He, Yuexian Hou</li>
</ul>
<p>Abstract:<br>Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals’ explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as “re-judge inconsistency” in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human’s unaware implicit social bias and their aware explicit social bias. Experimental investigations on ChatGPT and GPT-4 concerning common gender biases examined in psychology corroborate the highly stable nature of the re-judge inconsistency. This finding may suggest that diverse cognitive constructs emerge as LLMs’ capabilities strengthen. Consequently, leveraging psychological theories can provide enhanced insights into the underlying mechanisms governing the expressions of explicit and implicit constructs in LLMs.</p>
<hr>
<h2 id="A-Small-and-Fast-BERT-for-Chinese-Medical-Punctuation-Restoration"><a href="#A-Small-and-Fast-BERT-for-Chinese-Medical-Punctuation-Restoration" class="headerlink" title="A Small and Fast BERT for Chinese Medical Punctuation Restoration"></a>A Small and Fast BERT for Chinese Medical Punctuation Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12568">http://arxiv.org/abs/2308.12568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongtao Ling, Chen Liao, Zhipeng Yu, Lei Chen, Shilei Huang, Yi Liu</li>
</ul>
<p>Abstract:<br>In clinical dictation, utterances after automatic speech recognition (ASR) without explicit punctuation marks may lead to the misunderstanding of dictated reports. To give a precise and understandable clinical report with ASR, automatic punctuation restoration is required. Considering a practical scenario, we propose a fast and light pre-trained model for Chinese medical punctuation restoration based on ‘pretraining and fine-tuning’ paradigm. In this work, we distill pre-trained models by incorporating supervised contrastive learning and a novel auxiliary pre-training task (Punctuation Mark Prediction) to make it well-suited for punctuation restoration. Our experiments on various distilled models reveal that our model can achieve 95% performance while 10% model size relative to state-of-the-art Chinese RoBERTa.</p>
<hr>
<h2 id="CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias"><a href="#CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias" class="headerlink" title="CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias"></a>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/calm">https://github.com/vipulgupta1011/calm</a></li>
<li>paper_authors: Vipul Gupta, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, Rebecca J. Passonneau</li>
</ul>
<p>Abstract:<br>As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language models including six prominent families of LMs such as Llama-2. In two LM series, OPT and Bloom, we found that larger parameter models are more biased than lower parameter models. We found the T0 series of models to be the least biased. Furthermore, we noticed a tradeoff between gender and racial bias with increasing model size in some model series. The code is available at <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/CALM">https://github.com/vipulgupta1011/CALM</a>.</p>
<hr>
<h2 id="CARE-Co-Attention-Network-for-Joint-Entity-and-Relation-Extraction"><a href="#CARE-Co-Attention-Network-for-Joint-Entity-and-Relation-Extraction" class="headerlink" title="CARE: Co-Attention Network for Joint Entity and Relation Extraction"></a>CARE: Co-Attention Network for Joint Entity and Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12531">http://arxiv.org/abs/2308.12531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjun Kong, Yamei Xia</li>
</ul>
<p>Abstract:<br>Joint entity and relation extraction is the fundamental task of information extraction, consisting of two subtasks: named entity recognition and relation extraction. Most existing joint extraction methods suffer from issues of feature confusion or inadequate interaction between two subtasks. In this work, we propose a Co-Attention network for joint entity and Relation Extraction (CARE). Our approach involves learning separate representations for each subtask, aiming to avoid feature overlap. At the core of our approach is the co-attention module that captures two-way interaction between two subtasks, allowing the model to leverage entity information for relation prediction and vice versa, thus promoting mutual enhancement. Extensive experiments on three joint entity-relation extraction benchmark datasets (NYT, WebNLG and SciERC) show that our proposed model achieves superior performance, surpassing existing baseline models.</p>
<hr>
<h2 id="Large-Language-Model-as-Autonomous-Decision-Maker"><a href="#Large-Language-Model-as-Autonomous-Decision-Maker" class="headerlink" title="Large Language Model as Autonomous Decision Maker"></a>Large Language Model as Autonomous Decision Maker</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12519">http://arxiv.org/abs/2308.12519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yining Ye, Xin Cong, Yujia Qin, Yankai Lin, Zhiyuan Liu, Maosong Sun</li>
</ul>
<p>Abstract:<br>While large language models (LLMs) exhibit impressive language understanding and in-context learning abilities, their decision-making ability still heavily relies on the guidance of task-specific expert knowledge when solving real-world tasks. To unleash the potential of LLMs as autonomous decision makers, this paper presents an approach JuDec to endow LLMs with the self-judgment ability, enabling LLMs to achieve autonomous judgment and exploration for decision making. Specifically, in JuDec, Elo-based Self-Judgment Mechanism is designed to assign Elo scores to decision steps to judge their values and utilities via pairwise comparisons between two solutions and then guide the decision-searching process toward the optimal solution accordingly. Experimental results on the ToolBench dataset demonstrate JuDec’s superiority over baselines, achieving over 10% improvement in Pass Rate on diverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT API calls), highlighting its effectiveness and efficiency.</p>
<hr>
<h2 id="MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario"><a href="#MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario" class="headerlink" title="MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario"></a>MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12490">http://arxiv.org/abs/2308.12490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wen Chen, Zhou Yu, Julia Hirschberg</li>
</ul>
<p>Abstract:<br>The design of automatic speech pronunciation assessment can be categorized into closed and open response scenarios, each with strengths and limitations. A system with the ability to function in both scenarios can cater to diverse learning needs and provide a more precise and holistic assessment of pronunciation skills. In this study, we propose a Multi-task Pronunciation Assessment model called MultiPA. MultiPA provides an alternative to Kaldi-based systems in that it has simpler format requirements and better compatibility with other neural network models. Compared with previous open response systems, MultiPA provides a wider range of evaluations, encompassing assessments at both the sentence and word-level. Our experimental results show that MultiPA achieves comparable performance when working in closed response scenarios and maintains more robust performance when directly used for open responses.</p>
<hr>
<h2 id="GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4"><a href="#GPTEval-A-Survey-on-Assessments-of-ChatGPT-and-GPT-4" class="headerlink" title="GPTEval: A Survey on Assessments of ChatGPT and GPT-4"></a>GPTEval: A Survey on Assessments of ChatGPT and GPT-4</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12488">http://arxiv.org/abs/2308.12488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Mao, Guanyi Chen, Xulang Zhang, Frank Guerin, Erik Cambria</li>
</ul>
<p>Abstract:<br>The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.</p>
<hr>
<h2 id="American-Stories-A-Large-Scale-Structured-Text-Dataset-of-Historical-U-S-Newspapers"><a href="#American-Stories-A-Large-Scale-Structured-Text-Dataset-of-Historical-U-S-Newspapers" class="headerlink" title="American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers"></a>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12477">http://arxiv.org/abs/2308.12477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Melissa Dell, Jacob Carlson, Tom Bryan, Emily Silcock, Abhishek Arora, Zejiang Shen, Luca D’Amico-Wong, Quan Le, Pablo Querubin, Leander Heldring</li>
</ul>
<p>Abstract:<br>Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other layout regions. OCR quality can also be low. This study develops a novel, deep learning pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress’s public domain Chronicling America collection. The pipeline includes layout detection, legibility classification, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to the external database of a retrieval-augmented language model to make historical information - ranging from interpretations of political events to minutiae about the lives of people’s ancestors - more widely accessible. Furthermore, structured article texts facilitate using transformer-based methods for popular social science applications like topic classification, detection of reproduced content, and news story clustering. Finally, American Stories provides a massive silver quality dataset for innovating multimodal layout analysis models and other multimodal applications.</p>
<hr>
<h2 id="Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis"><a href="#Are-ChatGPT-and-GPT-4-Good-Poker-Players-–-A-Pre-Flop-Analysis" class="headerlink" title="Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis"></a>Are ChatGPT and GPT-4 Good Poker Players? – A Pre-Flop Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12466">http://arxiv.org/abs/2308.12466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshat Gupta</li>
</ul>
<p>Abstract:<br>Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.   Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is a more advanced poker player than ChatGPT. This exploration then sheds light on the divergent poker tactics of the two models: ChatGPT’s conservativeness juxtaposed against GPT-4’s aggression. In poker vernacular, when tasked to play GTO poker, ChatGPT plays like a Nit, which means that it has a propensity to only engage with premium hands and folds a majority of hands. When subjected to the same directive, GPT-4 plays like a maniac, showcasing a loose and aggressive style of play. Both strategies, although relatively advanced, are not game theory optimal.</p>
<hr>
<h2 id="Evolution-of-ESG-focused-DLT-Research-An-NLP-Analysis-of-the-Literature"><a href="#Evolution-of-ESG-focused-DLT-Research-An-NLP-Analysis-of-the-Literature" class="headerlink" title="Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature"></a>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12420">http://arxiv.org/abs/2308.12420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walter Hernandez, Kamil Tylinski, Alastair Moore, Niall Roche, Nikhil Vadgama, Horst Treiblmaier, Jiangbo Shangguan, Paolo Tasca, Jiahua Xu</li>
</ul>
<p>Abstract:<br>Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT’s ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our contributions are a methodology to conduct a machine learning-driven systematic literature review in the DLT field, placing a special emphasis on ESG aspects. Furthermore, we present a first-of-its-kind NER dataset, composed of 54,808 named entities, designed for DLT and ESG-related explorations.</p>
<hr>
<h2 id="Toward-American-Sign-Language-Processing-in-the-Real-World-Data-Tasks-and-Methods"><a href="#Toward-American-Sign-Language-Processing-in-the-Real-World-Data-Tasks-and-Methods" class="headerlink" title="Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods"></a>Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12419">http://arxiv.org/abs/2308.12419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Shi</li>
</ul>
<p>Abstract:<br>Sign language, which conveys meaning through gestures, is the chief means of communication among deaf people. Recognizing sign language in natural settings presents significant challenges due to factors such as lighting, background clutter, and variations in signer characteristics. In this thesis, I study automatic sign language processing in the wild, using signing videos collected from the Internet. This thesis contributes new datasets, tasks, and methods. Most chapters of this thesis address tasks related to fingerspelling, an important component of sign language and yet has not been studied widely by prior work. I present three new large-scale ASL datasets in the wild: ChicagoFSWild, ChicagoFSWild+, and OpenASL. Using ChicagoFSWild and ChicagoFSWild+, I address fingerspelling recognition, which consists of transcribing fingerspelling sequences into text. I propose an end-to-end approach based on iterative attention that allows recognition from a raw video without explicit hand detection. I further show that using a Conformer-based network jointly modeling handshape and mouthing can bring performance close to that of humans. Next, I propose two tasks for building real-world fingerspelling-based applications: fingerspelling detection and search. For fingerspelling detection, I introduce a suite of evaluation metrics and a new detection model via multi-task training. To address the problem of searching for fingerspelled keywords in raw sign language videos, we propose a novel method that jointly localizes and matches fingerspelling segments to text. Finally, I will describe a benchmark for large-vocabulary open-domain sign language translation based on OpenASL. To address the challenges of sign language translation in realistic settings, we propose a set of techniques including sign search as a pretext task for pre-training and fusion of mouthing and handshape features.</p>
<hr>
<h2 id="With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning"><a href="#With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning" class="headerlink" title="With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning"></a>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12383">http://arxiv.org/abs/2308.12383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/pma-net">https://github.com/aimagelab/pma-net</a></li>
<li>paper_authors: Manuele Barraco, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</li>
</ul>
<p>Abstract:<br>Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components. We demonstrate that our proposal can increase the performance of an encoder-decoder Transformer by 3.7 CIDEr points both when training in cross-entropy only and when fine-tuning with self-critical sequence training. Source code and trained models are available at: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/PMA-Net">https://github.com/aimagelab/PMA-Net</a>.</p>
<hr>
<h2 id="Vision-Transformer-Adapters-for-Generalizable-Multitask-Learning"><a href="#Vision-Transformer-Adapters-for-Generalizable-Multitask-Learning" class="headerlink" title="Vision Transformer Adapters for Generalizable Multitask Learning"></a>Vision Transformer Adapters for Generalizable Multitask Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12372">http://arxiv.org/abs/2308.12372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deblina Bhattacharjee, Sabine Süsstrunk, Mathieu Salzmann</li>
</ul>
<p>Abstract:<br>We introduce the first multitasking vision transformer adapters that learn generalizable task affinities which can be applied to novel tasks and domains. Integrated into an off-the-shelf vision transformer backbone, our adapters can simultaneously solve multiple dense vision tasks in a parameter-efficient manner, unlike existing multitasking transformers that are parametrically expensive. In contrast to concurrent methods, we do not require retraining or fine-tuning whenever a new task or domain is added. We introduce a task-adapted attention mechanism within our adapter framework that combines gradient-based task similarities with attention-based ones. The learned task affinities generalize to the following settings: zero-shot task transfer, unsupervised domain adaptation, and generalization without fine-tuning to novel domains. We demonstrate that our approach outperforms not only the existing convolutional neural network-based multitasking methods but also the vision transformer-based ones. Our project page is at \url{<a target="_blank" rel="noopener" href="https://ivrl.github.io/VTAGML%7D">https://ivrl.github.io/VTAGML}</a>.</p>
<hr>
<h2 id="D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification"><a href="#D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification" class="headerlink" title="D4: Improving LLM Pretraining via Document De-Duplication and Diversification"></a>D4: Improving LLM Pretraining via Document De-Duplication and Diversification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12284">http://arxiv.org/abs/2308.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos</li>
</ul>
<p>Abstract:<br>Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.</p>
<hr>
<h2 id="Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models"><a href="#Simple-is-Better-and-Large-is-Not-Enough-Towards-Ensembling-of-Foundational-Language-Models" class="headerlink" title="Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models"></a>Simple is Better and Large is Not Enough: Towards Ensembling of Foundational Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12272">http://arxiv.org/abs/2308.12272</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nancy Tyagi, Aidin Shiri, Surjodeep Sarkar, Abhishek Kumar Umrawal, Manas Gaur</li>
</ul>
<p>Abstract:<br>Foundational Language Models (FLMs) have advanced natural language processing (NLP) research. Current researchers are developing larger FLMs (e.g., XLNet, T5) to enable contextualized language representation, classification, and generation. While developing larger FLMs has been of significant advantage, it is also a liability concerning hallucination and predictive uncertainty. Fundamentally, larger FLMs are built on the same foundations as smaller FLMs (e.g., BERT); hence, one must recognize the potential of smaller FLMs which can be realized through an ensemble. In the current research, we perform a reality check on FLMs and their ensemble on benchmark and real-world datasets. We hypothesize that the ensembling of FLMs can influence the individualistic attention of FLMs and unravel the strength of coordination and cooperation of different FLMs. We utilize BERT and define three other ensemble techniques: {Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a knowledge-guided reinforcement learning approach. We discovered that the suggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by a factor of many times using datasets that show the usefulness of NLP in sensitive fields, such as mental health.</p>
<hr>
<h2 id="Prompt2Model-Generating-Deployable-Models-from-Natural-Language-Instructions"><a href="#Prompt2Model-Generating-Deployable-Models-from-Natural-Language-Instructions" class="headerlink" title="Prompt2Model: Generating Deployable Models from Natural Language Instructions"></a>Prompt2Model: Generating Deployable Models from Natural Language Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12261">http://arxiv.org/abs/2308.12261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neulab/prompt2model">https://github.com/neulab/prompt2model</a></li>
<li>paper_authors: Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, Graham Neubig</li>
</ul>
<p>Abstract:<br>Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at <a target="_blank" rel="noopener" href="https://github.com/neulab/prompt2model">https://github.com/neulab/prompt2model</a>.</p>
<hr>
<h2 id="How-to-Protect-Copyright-Data-in-Optimization-of-Large-Language-Models"><a href="#How-to-Protect-Copyright-Data-in-Optimization-of-Large-Language-Models" class="headerlink" title="How to Protect Copyright Data in Optimization of Large Language Models?"></a>How to Protect Copyright Data in Optimization of Large Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12247">http://arxiv.org/abs/2308.12247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy Chu, Zhao Song, Chiwun Yang</li>
</ul>
<p>Abstract:<br>Large language models (LLMs) and generative AI have played a transformative role in computer research and applications. Controversy has arisen as to whether these models output copyrighted data, which can occur if the data the models are trained on is copyrighted. LLMs are built on the transformer neural network architecture, which in turn relies on a mathematical computation called Attention that uses the softmax function.   In this paper, we show that large language model training and optimization can be seen as a softmax regression problem. We then establish a method of efficiently performing softmax regression, in a way that prevents the regression function from generating copyright data. This establishes a theoretical method of training large language models in a way that avoids generating copyright data.</p>
<hr>
<h2 id="Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning"><a href="#Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning" class="headerlink" title="Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning"></a>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12219">http://arxiv.org/abs/2308.12219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yegcjs/diffusionllm">https://github.com/yegcjs/diffusionllm</a></li>
<li>paper_authors: Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu</li>
</ul>
<p>Abstract:<br>The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream language tasks. We further discover that instruction finetuning can elicit zero-shot and few-shot in-context learning abilities that help tackle many unseen tasks by following natural language instructions, and show promise in advanced and challenging abilities such as reasoning</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.CL_2023_08_24/" data-id="cllqfoua00007a4881uau44gk" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.CV_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/cs.CV_2023_08_24/">cs.CV - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="VNI-Net-Vector-Neurons-based-Rotation-Invariant-Descriptor-for-LiDAR-Place-Recognition"><a href="#VNI-Net-Vector-Neurons-based-Rotation-Invariant-Descriptor-for-LiDAR-Place-Recognition" class="headerlink" title="VNI-Net: Vector Neurons-based Rotation-Invariant Descriptor for LiDAR Place Recognition"></a>VNI-Net: Vector Neurons-based Rotation-Invariant Descriptor for LiDAR Place Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12870">http://arxiv.org/abs/2308.12870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gengxuan Tian, Junqiao Zhao, Yingfeng Cai, Fenglin Zhang, Wenjie Mu, Chen Ye</li>
</ul>
<p>Abstract:<br>LiDAR-based place recognition plays a crucial role in Simultaneous Localization and Mapping (SLAM) and LiDAR localization.   Despite the emergence of various deep learning-based and hand-crafting-based methods, rotation-induced place recognition failure remains a critical challenge.   Existing studies address this limitation through specific training strategies or network structures.   However, the former does not produce satisfactory results, while the latter focuses mainly on the reduced problem of SO(2) rotation invariance. Methods targeting SO(3) rotation invariance suffer from limitations in discrimination capability.   In this paper, we propose a new method that employs Vector Neurons Network (VNN) to achieve SO(3) rotation invariance.   We first extract rotation-equivariant features from neighboring points and map low-dimensional features to a high-dimensional space through VNN.   Afterwards, we calculate the Euclidean and Cosine distance in the rotation-equivariant feature space as rotation-invariant feature descriptors.   Finally, we aggregate the features using GeM pooling to obtain global descriptors.   To address the significant information loss when formulating rotation-invariant descriptors, we propose computing distances between features at different layers within the Euclidean space neighborhood.   This greatly improves the discriminability of the point cloud descriptors while ensuring computational efficiency.   Experimental results on public datasets show that our approach significantly outperforms other baseline methods implementing rotation invariance, while achieving comparable results with current state-of-the-art place recognition methods that do not consider rotation issues.</p>
<hr>
<h2 id="ToonTalker-Cross-Domain-Face-Reenactment"><a href="#ToonTalker-Cross-Domain-Face-Reenactment" class="headerlink" title="ToonTalker: Cross-Domain Face Reenactment"></a>ToonTalker: Cross-Domain Face Reenactment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12866">http://arxiv.org/abs/2308.12866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Gong, Yong Zhang, Xiaodong Cun, Fei Yin, Yanbo Fan, Xuan Wang, Baoyuan Wu, Yujiu Yang</li>
</ul>
<p>Abstract:<br>We target cross-domain face reenactment in this paper, i.e., driving a cartoon image with the video of a real person and vice versa. Recently, many works have focused on one-shot talking face generation to drive a portrait with a real video, i.e., within-domain reenactment. Straightforwardly applying those methods to cross-domain animation will cause inaccurate expression transfer, blur effects, and even apparent artifacts due to the domain shift between cartoon and real faces. Only a few works attempt to settle cross-domain face reenactment. The most related work AnimeCeleb requires constructing a dataset with pose vector and cartoon image pairs by animating 3D characters, which makes it inapplicable anymore if no paired data is available. In this paper, we propose a novel method for cross-domain reenactment without paired data. Specifically, we propose a transformer-based framework to align the motions from different domains into a common latent space where motion transfer is conducted via latent code addition. Two domain-specific motion encoders and two learnable motion base memories are used to capture domain properties. A source query transformer and a driving one are exploited to project domain-specific motion to the canonical space. The edited motion is projected back to the domain of the source with a transformer. Moreover, since no paired data is provided, we propose a novel cross-domain training scheme using data from two domains with the designed analogy constraint. Besides, we contribute a cartoon dataset in Disney style. Extensive evaluations demonstrate the superiority of our method over competing methods.</p>
<hr>
<h2 id="SkipcrossNets-Adaptive-Skip-cross-Fusion-for-Road-Detection"><a href="#SkipcrossNets-Adaptive-Skip-cross-Fusion-for-Road-Detection" class="headerlink" title="SkipcrossNets: Adaptive Skip-cross Fusion for Road Detection"></a>SkipcrossNets: Adaptive Skip-cross Fusion for Road Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12863">http://arxiv.org/abs/2308.12863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Zhang, Yan Gong, Zhiwei Li, Xin Gao, Dafeng Jin, Jun Li, Huaping Liu</li>
</ul>
<p>Abstract:<br>Multi-modal fusion is increasingly being used for autonomous driving tasks, as images from different modalities provide unique information for feature extraction. However, the existing two-stream networks are only fused at a specific network layer, which requires a lot of manual attempts to set up. As the CNN goes deeper, the two modal features become more and more advanced and abstract, and the fusion occurs at the feature level with a large gap, which can easily hurt the performance. In this study, we propose a novel fusion architecture called skip-cross networks (SkipcrossNets), which combines adaptively LiDAR point clouds and camera images without being bound to a certain fusion epoch. Specifically, skip-cross connects each layer to each layer in a feed-forward manner, and for each layer, the feature maps of all previous layers are used as input and its own feature maps are used as input to all subsequent layers for the other modality, enhancing feature propagation and multi-modal features fusion. This strategy facilitates selection of the most similar feature layers from two data pipelines, providing a complementary effect for sparse point cloud features during fusion processes. The network is also divided into several blocks to reduce the complexity of feature fusion and the number of model parameters. The advantages of skip-cross fusion were demonstrated through application to the KITTI and A2D2 datasets, achieving a MaxF score of 96.85% on KITTI and an F1 score of 84.84% on A2D2. The model parameters required only 2.33 MB of memory at a speed of 68.24 FPS, which could be viable for mobile terminals and embedded devices.</p>
<hr>
<h2 id="Learned-Local-Attention-Maps-for-Synthesising-Vessel-Segmentations"><a href="#Learned-Local-Attention-Maps-for-Synthesising-Vessel-Segmentations" class="headerlink" title="Learned Local Attention Maps for Synthesising Vessel Segmentations"></a>Learned Local Attention Maps for Synthesising Vessel Segmentations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12861">http://arxiv.org/abs/2308.12861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yash Deo, Rodrigo Bonazzola, Haoran Dou, Yan Xia, Tianyou Wei, Nishant Ravikumar, Alejandro F. Frangi, Toni Lassila</li>
</ul>
<p>Abstract:<br>Magnetic resonance angiography (MRA) is an imaging modality for visualising blood vessels. It is useful for several diagnostic applications and for assessing the risk of adverse events such as haemorrhagic stroke (resulting from the rupture of aneurysms in blood vessels). However, MRAs are not acquired routinely, hence, an approach to synthesise blood vessel segmentations from more routinely acquired MR contrasts such as T1 and T2, would be useful. We present an encoder-decoder model for synthesising segmentations of the main cerebral arteries in the circle of Willis (CoW) from only T2 MRI. We propose a two-phase multi-objective learning approach, which captures both global and local features. It uses learned local attention maps generated by dilating the segmentation labels, which forces the network to only extract information from the T2 MRI relevant to synthesising the CoW. Our synthetic vessel segmentations generated from only T2 MRI achieved a mean Dice score of $0.79 \pm 0.03$ in testing, compared to state-of-the-art segmentation networks such as transformer U-Net ($0.71 \pm 0.04$) and nnU-net($0.68 \pm 0.05$), while using only a fraction of the parameters. The main qualitative difference between our synthetic vessel segmentations and the comparative models was in the sharper resolution of the CoW vessel segments, especially in the posterior circulation.</p>
<hr>
<h2 id="Implicit-Obstacle-Map-driven-Indoor-Navigation-Model-for-Robust-Obstacle-Avoidance"><a href="#Implicit-Obstacle-Map-driven-Indoor-Navigation-Model-for-Robust-Obstacle-Avoidance" class="headerlink" title="Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance"></a>Implicit Obstacle Map-driven Indoor Navigation Model for Robust Obstacle Avoidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12845">http://arxiv.org/abs/2308.12845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xwaiyy123/object-navigation">https://github.com/xwaiyy123/object-navigation</a></li>
<li>paper_authors: Wei Xie, Haobo Jiang, Shuo Gu, Jin Xie</li>
</ul>
<p>Abstract:<br>Robust obstacle avoidance is one of the critical steps for successful goal-driven indoor navigation tasks.Due to the obstacle missing in the visual image and the possible missed detection issue, visual image-based obstacle avoidance techniques still suffer from unsatisfactory robustness. To mitigate it, in this paper, we propose a novel implicit obstacle map-driven indoor navigation framework for robust obstacle avoidance, where an implicit obstacle map is learned based on the historical trial-and-error experience rather than the visual image. In order to further improve the navigation efficiency, a non-local target memory aggregation module is designed to leverage a non-local network to model the intrinsic relationship between the target semantic and the target orientation clues during the navigation process so as to mine the most target-correlated object clues for the navigation decision. Extensive experimental results on AI2-Thor and RoboTHOR benchmarks verify the excellent obstacle avoidance and navigation efficiency of our proposed method. The core source code is available at <a target="_blank" rel="noopener" href="https://github.com/xwaiyy123/object-navigation">https://github.com/xwaiyy123/object-navigation</a>.</p>
<hr>
<h2 id="FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease"><a href="#FaceTouch-Detecting-hand-to-face-touch-with-supervised-contrastive-learning-to-assist-in-tracing-infectious-disease" class="headerlink" title="FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease"></a>FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12840">http://arxiv.org/abs/2308.12840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed R. Ibrahim, Terry Lyons</li>
</ul>
<p>Abstract:<br>Through our respiratory system, many viruses and diseases frequently spread and pass from one person to another. Covid-19 served as an example of how crucial it is to track down and cut back on contacts to stop its spread. There is a clear gap in finding automatic methods that can detect hand-to-face contact in complex urban scenes or indoors. In this paper, we introduce a computer vision framework, called FaceTouch, based on deep learning. It comprises deep sub-models to detect humans and analyse their actions. FaceTouch seeks to detect hand-to-face touches in the wild, such as through video chats, bus footage, or CCTV feeds. Despite partial occlusion of faces, the introduced system learns to detect face touches from the RGB representation of a given scene by utilising the representation of the body gestures such as arm movement. This has been demonstrated to be useful in complex urban scenarios beyond simply identifying hand movement and its closeness to faces. Relying on Supervised Contrastive Learning, the introduced model is trained on our collected dataset, given the absence of other benchmark datasets. The framework shows a strong validation in unseen datasets which opens the door for potential deployment.</p>
<hr>
<h2 id="EFormer-Enhanced-Transformer-towards-Semantic-Contour-Features-of-Foreground-for-Portraits-Matting"><a href="#EFormer-Enhanced-Transformer-towards-Semantic-Contour-Features-of-Foreground-for-Portraits-Matting" class="headerlink" title="EFormer: Enhanced Transformer towards Semantic-Contour Features of Foreground for Portraits Matting"></a>EFormer: Enhanced Transformer towards Semantic-Contour Features of Foreground for Portraits Matting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12831">http://arxiv.org/abs/2308.12831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zitao Wang, Qiguang Miao, Yue Xi</li>
</ul>
<p>Abstract:<br>The portrait matting task aims to extract an alpha matte with complete semantics and finely-detailed contours. In comparison to CNN-based approaches, transformers with self-attention allow a larger receptive field, enabling it to better capture long-range dependencies and low-frequency semantic information of a portrait. However, the recent research shows that self-attention mechanism struggle with modeling high-frequency information and capturing fine contour details, which can lead to bias while predicting the portrait’s contours. To address the problem, we propose EFormer to enhance the model’s attention towards semantic and contour features. Especially the latter, which is surrounded by a large amount of high-frequency details. We build a semantic and contour detector (SCD) to accurately capture the distribution of semantic and contour features. And we further design contour-edge extraction branch and semantic extraction branch for refining contour features and complete semantic information. Finally, we fuse the two kinds of features and leverage the segmentation head to generate the predicted portrait matte. Remarkably, EFormer is an end-to-end trimap-free method and boasts a simple structure. Experiments conducted on VideoMatte240K-JPEGSD and AIM datasets demonstrate that EFormer outperforms previous portrait matte methods.</p>
<hr>
<h2 id="Robotic-Scene-Segmentation-with-Memory-Network-for-Runtime-Surgical-Context-Inference"><a href="#Robotic-Scene-Segmentation-with-Memory-Network-for-Runtime-Surgical-Context-Inference" class="headerlink" title="Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference"></a>Robotic Scene Segmentation with Memory Network for Runtime Surgical Context Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12789">http://arxiv.org/abs/2308.12789</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uva-dsa/runtime_robscene_seg_2context">https://github.com/uva-dsa/runtime_robscene_seg_2context</a></li>
<li>paper_authors: Zongyu Li, Ian Reyes, Homa Alemzadeh</li>
</ul>
<p>Abstract:<br>Surgical context inference has recently garnered significant attention in robot-assisted surgery as it can facilitate workflow analysis, skill assessment, and error detection. However, runtime context inference is challenging since it requires timely and accurate detection of the interactions among the tools and objects in the surgical scene based on the segmentation of video data. On the other hand, existing state-of-the-art video segmentation methods are often biased against infrequent classes and fail to provide temporal consistency for segmented masks. This can negatively impact the context inference and accurate detection of critical states. In this study, we propose a solution to these challenges using a Space Time Correspondence Network (STCN). STCN is a memory network that performs binary segmentation and minimizes the effects of class imbalance. The use of a memory bank in STCN allows for the utilization of past image and segmentation information, thereby ensuring consistency of the masks. Our experiments using the publicly available JIGSAWS dataset demonstrate that STCN achieves superior segmentation performance for objects that are difficult to segment, such as needle and thread, and improves context inference compared to the state-of-the-art. We also demonstrate that segmentation and context inference can be performed at runtime without compromising performance.</p>
<hr>
<h2 id="On-Offline-Evaluation-of-3D-Object-Detection-for-Autonomous-Driving"><a href="#On-Offline-Evaluation-of-3D-Object-Detection-for-Autonomous-Driving" class="headerlink" title="On Offline Evaluation of 3D Object Detection for Autonomous Driving"></a>On Offline Evaluation of 3D Object Detection for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12779">http://arxiv.org/abs/2308.12779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Schreier, Katrin Renz, Andreas Geiger, Kashyap Chitta</li>
</ul>
<p>Abstract:<br>Prior work in 3D object detection evaluates models using offline metrics like average precision since closed-loop online evaluation on the downstream driving task is costly. However, it is unclear how indicative offline results are of driving performance. In this work, we perform the first empirical evaluation measuring how predictive different detection metrics are of driving performance when detectors are integrated into a full self-driving stack. We conduct extensive experiments on urban driving in the CARLA simulator using 16 object detection models. We find that the nuScenes Detection Score has a higher correlation to driving performance than the widely used average precision metric. In addition, our results call for caution on the exclusive reliance on the emerging class of &#96;planner-centric’ metrics.</p>
<hr>
<h2 id="LISTER-Neighbor-Decoding-for-Length-Insensitive-Scene-Text-Recognition"><a href="#LISTER-Neighbor-Decoding-for-Length-Insensitive-Scene-Text-Recognition" class="headerlink" title="LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition"></a>LISTER: Neighbor Decoding for Length-Insensitive Scene Text Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12774">http://arxiv.org/abs/2308.12774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changxu Cheng, Peng Wang, Cheng Da, Qi Zheng, Cong Yao</li>
</ul>
<p>Abstract:<br>The diversity in length constitutes a significant characteristic of text. Due to the long-tail distribution of text lengths, most existing methods for scene text recognition (STR) only work well on short or seen-length text, lacking the capability of recognizing longer text or performing length extrapolation. This is a crucial issue, since the lengths of the text to be recognized are usually not given in advance in real-world applications, but it has not been adequately investigated in previous works. Therefore, we propose in this paper a method called Length-Insensitive Scene TExt Recognizer (LISTER), which remedies the limitation regarding the robustness to various text lengths. Specifically, a Neighbor Decoder is proposed to obtain accurate character attention maps with the assistance of a novel neighbor matrix regardless of the text lengths. Besides, a Feature Enhancement Module is devised to model the long-range dependency with low computation cost, which is able to perform iterations with the neighbor decoder to enhance the feature map progressively. To the best of our knowledge, we are the first to achieve effective length-insensitive scene text recognition. Extensive experiments demonstrate that the proposed LISTER algorithm exhibits obvious superiority on long text recognition and the ability for length extrapolation, while comparing favourably with the previous state-of-the-art methods on standard benchmarks for STR (mainly short text).</p>
<hr>
<h2 id="IP-UNet-Intensity-Projection-UNet-Architecture-for-3D-Medical-Volume-Segmentation"><a href="#IP-UNet-Intensity-Projection-UNet-Architecture-for-3D-Medical-Volume-Segmentation" class="headerlink" title="IP-UNet: Intensity Projection UNet Architecture for 3D Medical Volume Segmentation"></a>IP-UNet: Intensity Projection UNet Architecture for 3D Medical Volume Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12761">http://arxiv.org/abs/2308.12761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nyothiri Aung, Tahar Kechadi, Liming Chen, Sahraoui Dhelim</li>
</ul>
<p>Abstract:<br>CNNs have been widely applied for medical image analysis. However, limited memory capacity is one of the most common drawbacks of processing high-resolution 3D volumetric data. 3D volumes are usually cropped or downsized first before processing, which can result in a loss of resolution, increase class imbalance, and affect the performance of the segmentation algorithms. In this paper, we propose an end-to-end deep learning approach called IP-UNet. IP-UNet is a UNet-based model that performs multi-class segmentation on Intensity Projection (IP) of 3D volumetric data instead of the memory-consuming 3D volumes. IP-UNet uses limited memory capability for training without losing the original 3D image resolution. We compare the performance of three models in terms of segmentation accuracy and computational cost: 1) Slice-by-slice 2D segmentation of the CT scan images using a conventional 2D UNet model. 2) IP-UNet that operates on data obtained by merging the extracted Maximum Intensity Projection (MIP), Closest Vessel Projection (CVP), and Average Intensity Projection (AvgIP) representations of the source 3D volumes, then applying the UNet model on the output IP images. 3) 3D-UNet model directly reads the 3D volumes constructed from a series of CT scan images and outputs the 3D volume of the predicted segmentation. We test the performance of these methods on 3D volumetric images for automatic breast calcification detection. Experimental results show that IP-Unet can achieve similar segmentation accuracy with 3D-Unet but with much better performance. It reduces the training time by 70% and memory consumption by 92%.</p>
<hr>
<h2 id="PartSeg-Few-shot-Part-Segmentation-via-Part-aware-Prompt-Learning"><a href="#PartSeg-Few-shot-Part-Segmentation-via-Part-aware-Prompt-Learning" class="headerlink" title="PartSeg: Few-shot Part Segmentation via Part-aware Prompt Learning"></a>PartSeg: Few-shot Part Segmentation via Part-aware Prompt Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12757">http://arxiv.org/abs/2308.12757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengya Han, Heliang Zheng, Chaoyue Wang, Yong Luo, Han Hu, Jing Zhang, Yonggang Wen</li>
</ul>
<p>Abstract:<br>In this work, we address the task of few-shot part segmentation, which aims to segment the different parts of an unseen object using very few labeled examples. It is found that leveraging the textual space of a powerful pre-trained image-language model (such as CLIP) can be beneficial in learning visual features. Therefore, we develop a novel method termed PartSeg for few-shot part segmentation based on multimodal learning. Specifically, we design a part-aware prompt learning method to generate part-specific prompts that enable the CLIP model to better understand the concept of &#96;&#96;part’’ and fully utilize its textual space. Furthermore, since the concept of the same part under different object categories is general, we establish relationships between these parts during the prompt learning process. We conduct extensive experiments on the PartImageNet and Pascal$_$Part datasets, and the experimental results demonstrated that our proposed method achieves state-of-the-art performance.</p>
<hr>
<h2 id="Learning-Heavily-Degraded-Prior-for-Underwater-Object-Detection"><a href="#Learning-Heavily-Degraded-Prior-for-Underwater-Object-Detection" class="headerlink" title="Learning Heavily-Degraded Prior for Underwater Object Detection"></a>Learning Heavily-Degraded Prior for Underwater Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12738">http://arxiv.org/abs/2308.12738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaodetection/learning-heavily-degraed-prior">https://github.com/xiaodetection/learning-heavily-degraed-prior</a></li>
<li>paper_authors: Chenping Fu, Xin Fan, Jiewen Xiao, Wanqi Yuan, Risheng Liu, Zhongxuan Luo</li>
</ul>
<p>Abstract:<br>Underwater object detection suffers from low detection performance because the distance and wavelength dependent imaging process yield evident image quality degradations such as haze-like effects, low visibility, and color distortions. Therefore, we commit to resolving the issue of underwater object detection with compounded environmental degradations. Typical approaches attempt to develop sophisticated deep architecture to generate high-quality images or features. However, these methods are only work for limited ranges because imaging factors are either unstable, too sensitive, or compounded. Unlike these approaches catering for high-quality images or features, this paper seeks transferable prior knowledge from detector-friendly images. The prior guides detectors removing degradations that interfere with detection. It is based on statistical observations that, the heavily degraded regions of detector-friendly (DFUI) and underwater images have evident feature distribution gaps while the lightly degraded regions of them overlap each other. Therefore, we propose a residual feature transference module (RFTM) to learn a mapping between deep representations of the heavily degraded patches of DFUI- and underwater- images, and make the mapping as a heavily degraded prior (HDP) for underwater detection. Since the statistical properties are independent to image content, HDP can be learned without the supervision of semantic labels and plugged into popular CNNbased feature extraction networks to improve their performance on underwater object detection. Without bells and whistles, evaluations on URPC2020 and UODD show that our methods outperform CNN-based detectors by a large margin. Our method with higher speeds and less parameters still performs better than transformer-based detectors. Our code and DFUI dataset can be found in <a target="_blank" rel="noopener" href="https://github.com/xiaoDetection/Learning-Heavily-Degraed-Prior">https://github.com/xiaoDetection/Learning-Heavily-Degraed-Prior</a>.</p>
<hr>
<h2 id="Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification"><a href="#Asymmetric-Co-Training-with-Explainable-Cell-Graph-Ensembling-for-Histopathological-Image-Classification" class="headerlink" title="Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification"></a>Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12737">http://arxiv.org/abs/2308.12737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziqi Yang, Zhongyu Li, Chen Liu, Xiangde Luo, Xingguang Wang, Dou Xu, Chaoqun Li, Xiaoying Qin, Meng Yang, Long Jin</li>
</ul>
<p>Abstract:<br>Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integrate the two asymmetric branches. Notably, we collect a private clinically acquired dataset termed LUAD7C, including seven subtypes of lung adenocarcinoma, which is rare and more challenging. We evaluated our approach on the private LUAD7C and public colorectal cancer datasets, showcasing its superior performance, explainability, and generalizability in multi-class histopathological image classification.</p>
<hr>
<h2 id="FastSurfer-HypVINN-Automated-sub-segmentation-of-the-hypothalamus-and-adjacent-structures-on-high-resolutional-brain-MRI"><a href="#FastSurfer-HypVINN-Automated-sub-segmentation-of-the-hypothalamus-and-adjacent-structures-on-high-resolutional-brain-MRI" class="headerlink" title="FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and adjacent structures on high-resolutional brain MRI"></a>FastSurfer-HypVINN: Automated sub-segmentation of the hypothalamus and adjacent structures on high-resolutional brain MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12736">http://arxiv.org/abs/2308.12736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Santiago Estrada, David Kügler, Emad Bahrami, Peng Xu, Dilshad Mousa, Monique M. B. Breteler, N. Ahmad Aziz, Martin Reuter</li>
</ul>
<p>Abstract:<br>The hypothalamus plays a crucial role in the regulation of a broad range of physiological, behavioural, and cognitive functions. However, despite its importance, only a few small-scale neuroimaging studies have investigated its substructures, likely due to the lack of fully automated segmentation tools to address scalability and reproducibility issues of manual segmentation. While the only previous attempt to automatically sub-segment the hypothalamus with a neural network showed promise for 1.0 mm isotropic T1-weighted (T1w) MRI, there is a need for an automated tool to sub-segment also high-resolutional (HiRes) MR scans, as they are becoming widely available, and include structural detail also from multi-modal MRI. We, therefore, introduce a novel, fast, and fully automated deep learning method named HypVINN for sub-segmentation of the hypothalamus and adjacent structures on 0.8 mm isotropic T1w and T2w brain MR images that is robust to missing modalities. We extensively validate our model with respect to segmentation accuracy, generalizability, in-session test-retest reliability, and sensitivity to replicate hypothalamic volume effects (e.g. sex-differences). The proposed method exhibits high segmentation performance both for standalone T1w images as well as for T1w&#x2F;T2w image pairs. Even with the additional capability to accept flexible inputs, our model matches or exceeds the performance of state-of-the-art methods with fixed inputs. We, further, demonstrate the generalizability of our method in experiments with 1.0 mm MR scans from both the Rhineland Study and the UK Biobank. Finally, HypVINN can perform the segmentation in less than a minute (GPU) and will be available in the open source FastSurfer neuroimaging software suite, offering a validated, efficient, and scalable solution for evaluating imaging-derived phenotypes of the hypothalamus.</p>
<hr>
<h2 id="DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images"><a href="#DeepLOC-Deep-Learning-based-Bone-Pathology-Localization-and-Classification-in-Wrist-X-ray-Images" class="headerlink" title="DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images"></a>DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12727">http://arxiv.org/abs/2308.12727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Razan Dibo, Andrey Galichin, Pavel Astashev, Dmitry V. Dylov, Oleg Y. Rogov</li>
</ul>
<p>Abstract:<br>In recent years, computer-aided diagnosis systems have shown great potential in assisting radiologists with accurate and efficient medical image analysis. This paper presents a novel approach for bone pathology localization and classification in wrist X-ray images using a combination of YOLO (You Only Look Once) and the Shifted Window Transformer (Swin) with a newly proposed block. The proposed methodology addresses two critical challenges in wrist X-ray analysis: accurate localization of bone pathologies and precise classification of abnormalities. The YOLO framework is employed to detect and localize bone pathologies, leveraging its real-time object detection capabilities. Additionally, the Swin, a transformer-based module, is utilized to extract contextual information from the localized regions of interest (ROIs) for accurate classification.</p>
<hr>
<h2 id="VIGC-Visual-Instruction-Generation-and-Correction"><a href="#VIGC-Visual-Instruction-Generation-and-Correction" class="headerlink" title="VIGC: Visual Instruction Generation and Correction"></a>VIGC: Visual Instruction Generation and Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12714">http://arxiv.org/abs/2308.12714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Wang, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He</li>
</ul>
<p>Abstract:<br>The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of high-quality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision-language tasks. However, it’s worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction-tuning data and progressively enhance its quality on-the-fly. Specifically, Visual Instruction Generation (VIG) guides the vision-language model to generate diverse instruction-tuning data. To ensure generation quality, Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG, effectively reducing the risk of hallucination. Leveraging the diverse, high-quality data generated by VIGC, we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language-only data generation methods, but also effectively enhances the benchmark performance. The models, datasets, and code will be made publicly available.</p>
<hr>
<h2 id="Ground-to-Aerial-Person-Search-Benchmark-Dataset-and-Approach"><a href="#Ground-to-Aerial-Person-Search-Benchmark-Dataset-and-Approach" class="headerlink" title="Ground-to-Aerial Person Search: Benchmark Dataset and Approach"></a>Ground-to-Aerial Person Search: Benchmark Dataset and Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12712">http://arxiv.org/abs/2308.12712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqc123456/hkd_for_person_search">https://github.com/yqc123456/hkd_for_person_search</a></li>
<li>paper_authors: Shizhou Zhang, Qingchun Yang, De Cheng, Yinghui Xing, Guoqiang Liang, Peng Wang, Yanning Zhang</li>
</ul>
<p>Abstract:<br>In this work, we construct a large-scale dataset for Ground-to-Aerial Person Search, named G2APS, which contains 31,770 images of 260,559 annotated bounding boxes for 2,644 identities appearing in both of the UAVs and ground surveillance cameras. To our knowledge, this is the first dataset for cross-platform intelligent surveillance applications, where the UAVs could work as a powerful complement for the ground surveillance cameras. To more realistically simulate the actual cross-platform Ground-to-Aerial surveillance scenarios, the surveillance cameras are fixed about 2 meters above the ground, while the UAVs capture videos of persons at different location, with a variety of view-angles, flight attitudes and flight modes. Therefore, the dataset has the following unique characteristics: 1) drastic view-angle changes between query and gallery person images from cross-platform cameras; 2) diverse resolutions, poses and views of the person images under 9 rich real-world scenarios. On basis of the G2APS benchmark dataset, we demonstrate detailed analysis about current two-step and end-to-end person search methods, and further propose a simple yet effective knowledge distillation scheme on the head of the ReID network, which achieves state-of-the-art performances on both of the G2APS and the previous two public person search datasets, i.e., PRW and CUHK-SYSU. The dataset and source code available on \url{<a target="_blank" rel="noopener" href="https://github.com/yqc123456/HKD_for_person_search%7D">https://github.com/yqc123456/HKD_for_person_search}</a>.</p>
<hr>
<h2 id="A-Parse-Then-Place-Approach-for-Generating-Graphic-Layouts-from-Textual-Descriptions"><a href="#A-Parse-Then-Place-Approach-for-Generating-Graphic-Layouts-from-Textual-Descriptions" class="headerlink" title="A Parse-Then-Place Approach for Generating Graphic Layouts from Textual Descriptions"></a>A Parse-Then-Place Approach for Generating Graphic Layouts from Textual Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12700">http://arxiv.org/abs/2308.12700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawei Lin, Jiaqi Guo, Shizhao Sun, Weijiang Xu, Ting Liu, Jian-Guang Lou, Dongmei Zhang</li>
</ul>
<p>Abstract:<br>Creating layouts is a fundamental step in graphic design. In this work, we propose to use text as the guidance to create graphic layouts, i.e., Text-to-Layout, aiming to lower the design barriers. Text-to-Layout is a challenging task, because it needs to consider the implicit, combined, and incomplete layout constraints from text, each of which has not been studied in previous work. To address this, we present a two-stage approach, named parse-then-place. The approach introduces an intermediate representation (IR) between text and layout to represent diverse layout constraints. With IR, Text-to-Layout is decomposed into a parse stage and a place stage. The parse stage takes a textual description as input and generates an IR, in which the implicit constraints from the text are transformed into explicit ones. The place stage generates layouts based on the IR. To model combined and incomplete constraints, we use a Transformer-based layout generation model and carefully design a way to represent constraints and layouts as sequences. Besides, we adopt the pretrain-then-finetune strategy to boost the performance of the layout generation model with large-scale unlabeled layouts. To evaluate our approach, we construct two Text-to-Layout datasets and conduct experiments on them. Quantitative results, qualitative analysis, and user studies demonstrate the effectiveness of our approach.</p>
<hr>
<h2 id="A-Continual-Learning-Approach-for-Cross-Domain-White-Blood-Cell-Classification"><a href="#A-Continual-Learning-Approach-for-Cross-Domain-White-Blood-Cell-Classification" class="headerlink" title="A Continual Learning Approach for Cross-Domain White Blood Cell Classification"></a>A Continual Learning Approach for Cross-Domain White Blood Cell Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12679">http://arxiv.org/abs/2308.12679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ario Sadafi, Raheleh Salehi, Armin Gruber, Sayedali Shetab Boushehri, Pascal Giehr, Nassir Navab, Carsten Marr</li>
</ul>
<p>Abstract:<br>Accurate classification of white blood cells in peripheral blood is essential for diagnosing hematological diseases. Due to constantly evolving clinical settings, data sources, and disease classifications, it is necessary to update machine learning classification models regularly for practical real-world use. Such models significantly benefit from sequentially learning from incoming data streams without forgetting previously acquired knowledge. However, models can suffer from catastrophic forgetting, causing a drop in performance on previous tasks when fine-tuned on new data. Here, we propose a rehearsal-based continual learning approach for class incremental and domain incremental scenarios in white blood cell classification. To choose representative samples from previous tasks, we employ exemplar set selection based on the model’s predictions. This involves selecting the most confident samples and the most challenging samples identified through uncertainty estimation of the model. We thoroughly evaluated our proposed approach on three white blood cell classification datasets that differ in color, resolution, and class composition, including scenarios where new domains or new classes are introduced to the model with every task. We also test a long class incremental experiment with both new domains and new classes. Our results demonstrate that our approach outperforms established baselines in continual learning, including existing iCaRL and EWC methods for classifying white blood cells in cross-domain environments.</p>
<hr>
<h2 id="A-Study-of-Age-and-Sex-Bias-in-Multiple-Instance-Learning-based-Classification-of-Acute-Myeloid-Leukemia-Subtypes"><a href="#A-Study-of-Age-and-Sex-Bias-in-Multiple-Instance-Learning-based-Classification-of-Acute-Myeloid-Leukemia-Subtypes" class="headerlink" title="A Study of Age and Sex Bias in Multiple Instance Learning based Classification of Acute Myeloid Leukemia Subtypes"></a>A Study of Age and Sex Bias in Multiple Instance Learning based Classification of Acute Myeloid Leukemia Subtypes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12675">http://arxiv.org/abs/2308.12675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ario Sadafi, Matthias Hehr, Nassir Navab, Carsten Marr</li>
</ul>
<p>Abstract:<br>Accurate classification of Acute Myeloid Leukemia (AML) subtypes is crucial for clinical decision-making and patient care. In this study, we investigate the potential presence of age and sex bias in AML subtype classification using Multiple Instance Learning (MIL) architectures. To that end, we train multiple MIL models using different levels of sex imbalance in the training set and excluding certain age groups. To assess the sex bias, we evaluate the performance of the models on male and female test sets. For age bias, models are tested against underrepresented age groups in the training data. We find a significant effect of sex and age bias on the performance of the model for AML subtype classification. Specifically, we observe that females are more likely to be affected by sex imbalance dataset and certain age groups, such as patients with 72 to 86 years of age with the RUNX1::RUNX1T1 genetic subtype, are significantly affected by an age bias present in the training data. Ensuring inclusivity in the training data is thus essential for generating reliable and equitable outcomes in AML genetic subtype classification, ultimately benefiting diverse patient populations.</p>
<hr>
<h2 id="Masked-Feature-Modelling-Feature-Masking-for-the-Unsupervised-Pre-training-of-a-Graph-Attention-Network-Block-for-Bottom-up-Video-Event-Recognition"><a href="#Masked-Feature-Modelling-Feature-Masking-for-the-Unsupervised-Pre-training-of-a-Graph-Attention-Network-Block-for-Bottom-up-Video-Event-Recognition" class="headerlink" title="Masked Feature Modelling: Feature Masking for the Unsupervised Pre-training of a Graph Attention Network Block for Bottom-up Video Event Recognition"></a>Masked Feature Modelling: Feature Masking for the Unsupervised Pre-training of a Graph Attention Network Block for Bottom-up Video Event Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12673">http://arxiv.org/abs/2308.12673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitrios Daskalakis, Nikolaos Gkalelis, Vasileios Mezaris</li>
</ul>
<p>Abstract:<br>In this paper, we introduce Masked Feature Modelling (MFM), a novel approach for the unsupervised pre-training of a Graph Attention Network (GAT) block. MFM utilizes a pretrained Visual Tokenizer to reconstruct masked features of objects within a video, leveraging the MiniKinetics dataset. We then incorporate the pre-trained GAT block into a state-of-the-art bottom-up supervised video-event recognition architecture, ViGAT, to improve the model’s starting point and overall accuracy. Experimental evaluations on the YLI-MED dataset demonstrate the effectiveness of MFM in improving event recognition performance.</p>
<hr>
<h2 id="Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers"><a href="#Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers" class="headerlink" title="Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers"></a>Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12661">http://arxiv.org/abs/2308.12661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
</ul>
<p>Abstract:<br>Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards. However, designing effective out-of-distribution tests that encompass all possible scenarios while preserving accurate label information is a challenging task. Existing methodologies often entail a compromise between variety and constraint levels for attacks and sometimes even both. In a first step towards a more holistic robustness evaluation of image classification models, we introduce an attack method based on image solarization that is conceptually straightforward yet avoids jeopardizing the global structure of natural images independent of the intensity. Through comprehensive evaluations of multiple ImageNet models, we demonstrate the attack’s capacity to degrade accuracy significantly, provided it is not integrated into the training augmentations. Interestingly, even then, no full immunity to accuracy deterioration is achieved. In other settings, the attack can often be simplified into a black-box attack with model-independent parameters. Defenses against other corruptions do not consistently extend to be effective against our specific attack.   Project website: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></p>
<hr>
<h2 id="An-All-Deep-System-for-Badminton-Game-Analysis"><a href="#An-All-Deep-System-for-Badminton-Game-Analysis" class="headerlink" title="An All Deep System for Badminton Game Analysis"></a>An All Deep System for Badminton Game Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12645">http://arxiv.org/abs/2308.12645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Yung Chou, Yu-Chun Lo, Bo-Zheng Xie, Cheng-Hung Lin, Yu-Yung Kao</li>
</ul>
<p>Abstract:<br>The CoachAI Badminton 2023 Track1 initiative aim to automatically detect events within badminton match videos. Detecting small objects, especially the shuttlecock, is of quite importance and demands high precision within the challenge. Such detection is crucial for tasks like hit count, hitting time, and hitting location. However, even after revising the well-regarded shuttlecock detecting model, TrackNet, our object detection models still fall short of the desired accuracy. To address this issue, we’ve implemented various deep learning methods to tackle the problems arising from noisy detectied data, leveraging diverse data types to improve precision. In this report, we detail the detection model modifications we’ve made and our approach to the 11 tasks. Notably, our system garnered a score of 0.78 out of 1.0 in the challenge.</p>
<hr>
<h2 id="Tag-Based-Annotation-for-Avatar-Face-Creation"><a href="#Tag-Based-Annotation-for-Avatar-Face-Creation" class="headerlink" title="Tag-Based Annotation for Avatar Face Creation"></a>Tag-Based Annotation for Avatar Face Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12642">http://arxiv.org/abs/2308.12642</a></li>
<li>repo_url: None</li>
<li>paper_authors: An Ngo, Daniel Phelps, Derrick Lai, Thanyared Wong, Lucas Mathias, Anish Shivamurthy, Mustafa Ajmal, Minghao Liu, James Davis</li>
</ul>
<p>Abstract:<br>Currently, digital avatars can be created manually using human images as reference. Systems such as Bitmoji are excellent producers of detailed avatar designs, with hundreds of choices for customization. A supervised learning model could be trained to generate avatars automatically, but the hundreds of possible options create difficulty in securing non-noisy data to train a model. As a solution, we train a model to produce avatars from human images using tag-based annotations. This method provides better annotator agreement, leading to less noisy data and higher quality model predictions. Our contribution is an application of tag-based annotation to train a model for avatar face creation. We design tags for 3 different facial facial features offered by Bitmoji, and train a model using tag-based annotation to predict the nose.</p>
<hr>
<h2 id="Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning"><a href="#Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning" class="headerlink" title="Towards Hierarchical Regional Transformer-based Multiple Instance Learning"></a>Towards Hierarchical Regional Transformer-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12634">http://arxiv.org/abs/2308.12634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Cersovsky, Sadegh Mohammadi, Dagmar Kainmueller, Johannes Hoehne</li>
</ul>
<p>Abstract:<br>The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.</p>
<hr>
<h2 id="Cross-Video-Contextual-Knowledge-Exploration-and-Exploitation-for-Ambiguity-Reduction-in-Weakly-Supervised-Temporal-Action-Localization"><a href="#Cross-Video-Contextual-Knowledge-Exploration-and-Exploitation-for-Ambiguity-Reduction-in-Weakly-Supervised-Temporal-Action-Localization" class="headerlink" title="Cross-Video Contextual Knowledge Exploration and Exploitation for Ambiguity Reduction in Weakly Supervised Temporal Action Localization"></a>Cross-Video Contextual Knowledge Exploration and Exploitation for Ambiguity Reduction in Weakly Supervised Temporal Action Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12609">http://arxiv.org/abs/2308.12609</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songchun Zhang, Chunhui Zhao</li>
</ul>
<p>Abstract:<br>Weakly supervised temporal action localization (WSTAL) aims to localize actions in untrimmed videos using video-level labels. Despite recent advances, existing approaches mainly follow a localization-by-classification pipeline, generally processing each segment individually, thereby exploiting only limited contextual information. As a result, the model will lack a comprehensive understanding (e.g. appearance and temporal structure) of various action patterns, leading to ambiguity in classification learning and temporal localization. Our work addresses this from a novel perspective, by exploring and exploiting the cross-video contextual knowledge within the dataset to recover the dataset-level semantic structure of action instances via weak labels only, thereby indirectly improving the holistic understanding of fine-grained action patterns and alleviating the aforementioned ambiguities. Specifically, an end-to-end framework is proposed, including a Robust Memory-Guided Contrastive Learning (RMGCL) module and a Global Knowledge Summarization and Aggregation (GKSA) module. First, the RMGCL module explores the contrast and consistency of cross-video action features, assisting in learning more structured and compact embedding space, thus reducing ambiguity in classification learning. Further, the GKSA module is used to efficiently summarize and propagate the cross-video representative action knowledge in a learnable manner to promote holistic action patterns understanding, which in turn allows the generation of high-confidence pseudo-labels for self-learning, thus alleviating ambiguity in temporal localization. Extensive experiments on THUMOS14, ActivityNet1.3, and FineAction demonstrate that our method outperforms the state-of-the-art methods, and can be easily plugged into other WSTAL methods.</p>
<hr>
<h2 id="HR-Pro-Point-supervised-Temporal-Action-Localization-via-Hierarchical-Reliability-Propagation"><a href="#HR-Pro-Point-supervised-Temporal-Action-Localization-via-Hierarchical-Reliability-Propagation" class="headerlink" title="HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation"></a>HR-Pro: Point-supervised Temporal Action Localization via Hierarchical Reliability Propagation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12608">http://arxiv.org/abs/2308.12608</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pipixin321/hr-pro">https://github.com/pipixin321/hr-pro</a></li>
<li>paper_authors: Huaxin Zhang, Xiang Wang, Xiaohao Xu, Zhiwu Qing, Changxin Gao, Nong Sang</li>
</ul>
<p>Abstract:<br>Point-supervised Temporal Action Localization (PSTAL) is an emerging research direction for label-efficient learning. However, current methods mainly focus on optimizing the network either at the snippet-level or the instance-level, neglecting the inherent reliability of point annotations at both levels. In this paper, we propose a Hierarchical Reliability Propagation (HR-Pro) framework, which consists of two reliability-aware stages: Snippet-level Discrimination Learning and Instance-level Completeness Learning, both stages explore the efficient propagation of high-confidence cues in point annotations. For snippet-level learning, we introduce an online-updated memory to store reliable snippet prototypes for each class. We then employ a Reliability-aware Attention Block to capture both intra-video and inter-video dependencies of snippets, resulting in more discriminative and robust snippet representation. For instance-level learning, we propose a point-based proposal generation approach as a means of connecting snippets and instances, which produces high-confidence proposals for further optimization at the instance level. Through multi-level reliability-aware learning, we obtain more reliable confidence scores and more accurate temporal boundaries of predicted proposals. Our HR-Pro achieves state-of-the-art performance on multiple challenging benchmarks, including an impressive average mAP of 60.3% on THUMOS14. Notably, our HR-Pro largely surpasses all previous point-supervised methods, and even outperforms several competitive fully supervised methods. Code will be available at <a target="_blank" rel="noopener" href="https://github.com/pipixin321/HR-Pro">https://github.com/pipixin321/HR-Pro</a>.</p>
<hr>
<h2 id="APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency"><a href="#APLA-Additional-Perturbation-for-Latent-Noise-with-Adversarial-Training-Enables-Consistency" class="headerlink" title="APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency"></a>APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12605">http://arxiv.org/abs/2308.12605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yupu Yao, Shangqi Deng, Zihan Cao, Harry Zhang, Liang-Jian Deng</li>
</ul>
<p>Abstract:<br>Diffusion models have exhibited promising progress in video generation. However, they often struggle to retain consistent details within local regions across frames. One underlying cause is that traditional diffusion models approximate Gaussian noise distribution by utilizing predictive noise, without fully accounting for the impact of inherent information within the input itself. Additionally, these models emphasize the distinction between predictions and references, neglecting information intrinsic to the videos. To address this limitation, inspired by the self-attention mechanism, we propose a novel text-to-video (T2V) generation network structure based on diffusion models, dubbed Additional Perturbation for Latent noise with Adversarial training (APLA). Our approach only necessitates a single video as input and builds upon pre-trained stable diffusion networks. Notably, we introduce an additional compact network, known as the Video Generation Transformer (VGT). This auxiliary component is designed to extract perturbations from the inherent information contained within the input, thereby refining inconsistent pixels during temporal predictions. We leverage a hybrid architecture of transformers and convolutions to compensate for temporal intricacies, enhancing consistency between different frames within the video. Experiments demonstrate a noticeable improvement in the consistency of the generated videos both qualitatively and quantitatively.</p>
<hr>
<h2 id="PromptMRG-Diagnosis-Driven-Prompts-for-Medical-Report-Generation"><a href="#PromptMRG-Diagnosis-Driven-Prompts-for-Medical-Report-Generation" class="headerlink" title="PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation"></a>PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12604">http://arxiv.org/abs/2308.12604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haibo Jin, Haoxuan Che, Yi Lin, Hao Chen</li>
</ul>
<p>Abstract:<br>Automatic medical report generation (MRG) is of great research value as it has the potential to relieve radiologists from the heavy burden of report writing. Despite recent advancements, accurate MRG remains challenging due to the need for precise clinical understanding and the identification of clinical findings. Moreover, the imbalanced distribution of diseases makes the challenge even more pronounced, as rare diseases are underrepresented in training data, making their diagnostic performance unreliable. To address these challenges, we propose diagnosis-driven prompts for medical report generation (PromptMRG), a novel framework that aims to improve the diagnostic accuracy of MRG with the guidance of diagnosis-aware prompts. Specifically, PromptMRG is based on encoder-decoder architecture with an extra disease classification branch. When generating reports, the diagnostic results from the classification branch are converted into token prompts to explicitly guide the generation process. To further improve the diagnostic accuracy, we design cross-modal feature enhancement, which retrieves similar reports from the database to assist the diagnosis of a query image by leveraging the knowledge from a pre-trained CLIP. Moreover, the disease imbalanced issue is addressed by applying an adaptive logit-adjusted loss to the classification branch based on the individual learning status of each disease, which overcomes the barrier of text decoder’s inability to manipulate disease distributions. Experiments on two MRG benchmarks show the effectiveness of the proposed method, where it obtains state-of-the-art clinical efficacy performance on both datasets.</p>
<hr>
<h2 id="PoseSync-Robust-pose-based-video-synchronization"><a href="#PoseSync-Robust-pose-based-video-synchronization" class="headerlink" title="PoseSync: Robust pose based video synchronization"></a>PoseSync: Robust pose based video synchronization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12600">http://arxiv.org/abs/2308.12600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishit Javia, Falak Shah, Shivam Dave</li>
</ul>
<p>Abstract:<br>Pose based video sychronization can have applications in multiple domains such as gameplay performance evaluation, choreography or guiding athletes. The subject’s actions could be compared and evaluated against those performed by professionals side by side. In this paper, we propose an end to end pipeline for synchronizing videos based on pose. The first step crops the region where the person present in the image followed by pose detection on the cropped image. This is followed by application of Dynamic Time Warping(DTW) on angle&#x2F; distance measures between the pose keypoints leading to a scale and shift invariant pose matching pipeline.</p>
<hr>
<h2 id="Logic-induced-Diagnostic-Reasoning-for-Semi-supervised-Semantic-Segmentation"><a href="#Logic-induced-Diagnostic-Reasoning-for-Semi-supervised-Semantic-Segmentation" class="headerlink" title="Logic-induced Diagnostic Reasoning for Semi-supervised Semantic Segmentation"></a>Logic-induced Diagnostic Reasoning for Semi-supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12595">http://arxiv.org/abs/2308.12595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liang, Wenguan Wang, Jiaxu Miao, Yi Yang</li>
</ul>
<p>Abstract:<br>Recent advances in semi-supervised semantic segmentation have been heavily reliant on pseudo labeling to compensate for limited labeled data, disregarding the valuable relational knowledge among semantic concepts. To bridge this gap, we devise LogicDiag, a brand new neural-logic semi-supervised learning framework. Our key insight is that conflicts within pseudo labels, identified through symbolic knowledge, can serve as strong yet commonly ignored learning signals. LogicDiag resolves such conflicts via reasoning with logic-induced diagnoses, enabling the recovery of (potentially) erroneous pseudo labels, ultimately alleviating the notorious error accumulation problem. We showcase the practical application of LogicDiag in the data-hungry segmentation scenario, where we formalize the structured abstraction of semantic concepts as a set of logic rules. Extensive experiments on three standard semi-supervised semantic segmentation benchmarks demonstrate the effectiveness and generality of LogicDiag. Moreover, LogicDiag highlights the promising opportunities arising from the systematic integration of symbolic reasoning into the prevalent statistical, neural learning approaches.</p>
<hr>
<h2 id="Self-supervised-Learning-of-Implicit-Shape-Representation-with-Dense-Correspondence-for-Deformable-Objects"><a href="#Self-supervised-Learning-of-Implicit-Shape-Representation-with-Dense-Correspondence-for-Deformable-Objects" class="headerlink" title="Self-supervised Learning of Implicit Shape Representation with Dense Correspondence for Deformable Objects"></a>Self-supervised Learning of Implicit Shape Representation with Dense Correspondence for Deformable Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12590">http://arxiv.org/abs/2308.12590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Baowen Zhang, Jiahe Li, Xiaoming Deng, Yinda Zhang, Cuixia Ma, Hongan Wang</li>
</ul>
<p>Abstract:<br>Learning 3D shape representation with dense correspondence for deformable objects is a fundamental problem in computer vision. Existing approaches often need additional annotations of specific semantic domain, e.g., skeleton poses for human bodies or animals, which require extra annotation effort and suffer from error accumulation, and they are limited to specific domain. In this paper, we propose a novel self-supervised approach to learn neural implicit shape representation for deformable objects, which can represent shapes with a template shape and dense correspondence in 3D. Our method does not require the priors of skeleton and skinning weight, and only requires a collection of shapes represented in signed distance fields. To handle the large deformation, we constrain the learned template shape in the same latent space with the training shapes, design a new formulation of local rigid constraint that enforces rigid transformation in local region and addresses local reflection issue, and present a new hierarchical rigid constraint to reduce the ambiguity due to the joint learning of template shape and correspondences. Extensive experiments show that our model can represent shapes with large deformations. We also show that our shape representation can support two typical applications, such as texture transfer and shape editing, with competitive performance. The code and models are available at <a target="_blank" rel="noopener" href="https://iscas3dv.github.io/deformshape">https://iscas3dv.github.io/deformshape</a></p>
<hr>
<h2 id="Grounded-Entity-Landmark-Adaptive-Pre-training-for-Vision-and-Language-Navigation"><a href="#Grounded-Entity-Landmark-Adaptive-Pre-training-for-Vision-and-Language-Navigation" class="headerlink" title="Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation"></a>Grounded Entity-Landmark Adaptive Pre-training for Vision-and-Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12587">http://arxiv.org/abs/2308.12587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yibo Cui, Liang Xie, Yakun Zhang, Meishan Zhang, Ye Yan, Erwei Yin</li>
</ul>
<p>Abstract:<br>Cross-modal alignment is one key challenge for Vision-and-Language Navigation (VLN). Most existing studies concentrate on mapping the global instruction or single sub-instruction to the corresponding trajectory. However, another critical problem of achieving fine-grained alignment at the entity level is seldom considered. To address this problem, we propose a novel Grounded Entity-Landmark Adaptive (GELA) pre-training paradigm for VLN tasks. To achieve the adaptive pre-training paradigm, we first introduce grounded entity-landmark human annotations into the Room-to-Room (R2R) dataset, named GEL-R2R. Additionally, we adopt three grounded entity-landmark adaptive pre-training objectives: 1) entity phrase prediction, 2) landmark bounding box prediction, and 3) entity-landmark semantic alignment, which explicitly supervise the learning of fine-grained cross-modal alignment between entity phrases and environment landmarks. Finally, we validate our model on two downstream benchmarks: VLN with descriptive instructions (R2R) and dialogue instructions (CVDN). The comprehensive experiments show that our GELA model achieves state-of-the-art results on both tasks, demonstrating its effectiveness and generalizability.</p>
<hr>
<h2 id="LORD-Leveraging-Open-Set-Recognition-with-Unknown-Data"><a href="#LORD-Leveraging-Open-Set-Recognition-with-Unknown-Data" class="headerlink" title="LORD: Leveraging Open-Set Recognition with Unknown Data"></a>LORD: Leveraging Open-Set Recognition with Unknown Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12584">http://arxiv.org/abs/2308.12584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Koch, Christian Riess, Thomas Köhler</li>
</ul>
<p>Abstract:<br>Handling entirely unknown data is a challenge for any deployed classifier. Classification models are typically trained on a static pre-defined dataset and are kept in the dark for the open unassigned feature space. As a result, they struggle to deal with out-of-distribution data during inference. Addressing this task on the class-level is termed open-set recognition (OSR). However, most OSR methods are inherently limited, as they train closed-set classifiers and only adapt the downstream predictions to OSR. This work presents LORD, a framework to Leverage Open-set Recognition by exploiting unknown Data. LORD explicitly models open space during classifier training and provides a systematic evaluation for such approaches. We identify three model-agnostic training strategies that exploit background data and applied them to well-established classifiers. Due to LORD’s extensive evaluation protocol, we consistently demonstrate improved recognition of unknown data. The benchmarks facilitate in-depth analysis across various requirement levels. To mitigate dependency on extensive and costly background datasets, we explore mixup as an off-the-shelf data generation technique. Our experiments highlight mixup’s effectiveness as a substitute for background datasets. Lightweight constraints on mixup synthesis further improve OSR performance.</p>
<hr>
<h2 id="REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection"><a href="#REB-Reducing-Biases-in-Representation-for-Industrial-Anomaly-Detection" class="headerlink" title="REB: Reducing Biases in Representation for Industrial Anomaly Detection"></a>REB: Reducing Biases in Representation for Industrial Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12577">http://arxiv.org/abs/2308.12577</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ShuaiLYU/REB">https://github.com/ShuaiLYU/REB</a></li>
<li>paper_authors: Shuai Lyu, Dongmei Mo, Waikeung Wong</li>
</ul>
<p>Abstract:<br>Existing K-nearest neighbor (KNN) retrieval-based methods usually conduct industrial anomaly detection in two stages: obtain feature representations with a pre-trained CNN model and perform distance measures for defect detection. However, the features are not fully exploited as they ignore domain bias and the difference of local density in feature space, which limits the detection performance. In this paper, we propose Reducing Biases (REB) in representation by considering the domain bias of the pre-trained model and building a self-supervised learning task for better domain adaption with a defect generation strategy (DefectMaker) imitating the natural defects. Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection. We achieve a promising result of 99.5% AUROC on the widely used MVTec AD benchmark. We also achieve 88.0% AUROC on the challenging MVTec LOCO AD dataset and bring an improvement of 4.7% AUROC to the state-of-the-art result. All results are obtained with smaller backbone networks such as Vgg11 and Resnet18, which indicates the effectiveness and efficiency of REB for practical industrial applications.</p>
<hr>
<h2 id="StreamMapNet-Streaming-Mapping-Network-for-Vectorized-Online-HD-Map-Construction"><a href="#StreamMapNet-Streaming-Mapping-Network-for-Vectorized-Online-HD-Map-Construction" class="headerlink" title="StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map Construction"></a>StreamMapNet: Streaming Mapping Network for Vectorized Online HD Map Construction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12570">http://arxiv.org/abs/2308.12570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianyuan Yuan, Yicheng Liu, Yue Wang, Yilun Wang, Hang Zhao</li>
</ul>
<p>Abstract:<br>High-Definition (HD) maps are essential for the safety of autonomous driving systems. While existing techniques employ camera images and onboard sensors to generate vectorized high-precision maps, they are constrained by their reliance on single-frame input. This approach limits their stability and performance in complex scenarios such as occlusions, largely due to the absence of temporal information. Moreover, their performance diminishes when applied to broader perception ranges. In this paper, we present StreamMapNet, a novel online mapping pipeline adept at long-sequence temporal modeling of videos. StreamMapNet employs multi-point attention and temporal information which empowers the construction of large-range local HD maps with high stability and further addresses the limitations of existing methods. Furthermore, we critically examine widely used online HD Map construction benchmark and datasets, Argoverse2 and nuScenes, revealing significant bias in the existing evaluation protocols. We propose to resplit the benchmarks according to geographical spans, promoting fair and precise evaluations. Experimental results validate that StreamMapNet significantly outperforms existing methods across all settings while maintaining an online inference speed of $14.2$ FPS.</p>
<hr>
<h2 id="NOVA-NOvel-View-Augmentation-for-Neural-Composition-of-Dynamic-Objects"><a href="#NOVA-NOvel-View-Augmentation-for-Neural-Composition-of-Dynamic-Objects" class="headerlink" title="NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects"></a>NOVA: NOvel View Augmentation for Neural Composition of Dynamic Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12560">http://arxiv.org/abs/2308.12560</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dakshitagrawal/nova">https://github.com/dakshitagrawal/nova</a></li>
<li>paper_authors: Dakshit Agrawal, Jiajie Xu, Siva Karthik Mustikovela, Ioannis Gkioulekas, Ashish Shrivastava, Yuning Chai</li>
</ul>
<p>Abstract:<br>We propose a novel-view augmentation (NOVA) strategy to train NeRFs for photo-realistic 3D composition of dynamic objects in a static scene. Compared to prior work, our framework significantly reduces blending artifacts when inserting multiple dynamic objects into a 3D scene at novel views and times; achieves comparable PSNR without the need for additional ground truth modalities like optical flow; and overall provides ease, flexibility, and scalability in neural composition. Our codebase is on GitHub.</p>
<hr>
<h2 id="Hyperbolic-Audio-visual-Zero-shot-Learning"><a href="#Hyperbolic-Audio-visual-Zero-shot-Learning" class="headerlink" title="Hyperbolic Audio-visual Zero-shot Learning"></a>Hyperbolic Audio-visual Zero-shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12558">http://arxiv.org/abs/2308.12558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Hong, Zeeshan Hayder, Junlin Han, Pengfei Fang, Mehrtash Harandi, Lars Petersson</li>
</ul>
<p>Abstract:<br>Audio-visual zero-shot learning aims to classify samples consisting of a pair of corresponding audio and video sequences from classes that are not present during training. An analysis of the audio-visual data reveals a large degree of hyperbolicity, indicating the potential benefit of using a hyperbolic transformation to achieve curvature-aware geometric learning, with the aim of exploring more complex hierarchical data structures for this task. The proposed approach employs a novel loss function that incorporates cross-modality alignment between video and audio features in the hyperbolic space. Additionally, we explore the use of multiple adaptive curvatures for hyperbolic projections. The experimental results on this very challenging task demonstrate that our proposed hyperbolic approach for zero-shot learning outperforms the SOTA method on three datasets: VGGSound-GZSL, UCF-GZSL, and ActivityNet-GZSL achieving a harmonic mean (HM) improvement of around 3.0%, 7.0%, and 5.3%, respectively.</p>
<hr>
<h2 id="Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking"><a href="#Synchronize-Feature-Extracting-and-Matching-A-Single-Branch-Framework-for-3D-Object-Tracking" class="headerlink" title="Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking"></a>Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12549">http://arxiv.org/abs/2308.12549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teli Ma, Mengmeng Wang, Jimin Xiao, Huifeng Wu, Yong Liu</li>
</ul>
<p>Abstract:<br>Siamese network has been a de facto benchmark framework for 3D LiDAR object tracking with a shared-parametric encoder extracting features from template and search region, respectively. This paradigm relies heavily on an additional matching network to model the cross-correlation&#x2F;similarity of the template and search region. In this paper, we forsake the conventional Siamese paradigm and propose a novel single-branch framework, SyncTrack, synchronizing the feature extracting and matching to avoid forwarding encoder twice for template and search region as well as introducing extra parameters of matching network. The synchronization mechanism is based on the dynamic affinity of the Transformer, and an in-depth analysis of the relevance is provided theoretically. Moreover, based on the synchronization, we introduce a novel Attentive Points-Sampling strategy into the Transformer layers (APST), replacing the random&#x2F;Farthest Points Sampling (FPS) method with sampling under the supervision of attentive relations between the template and search region. It implies connecting point-wise sampling with the feature learning, beneficial to aggregating more distinctive and geometric features for tracking with sparse points. Extensive experiments on two benchmark datasets (KITTI and NuScenes) show that SyncTrack achieves state-of-the-art performance in real-time tracking.</p>
<hr>
<h2 id="Hybrid-Models-for-Facial-Emotion-Recognition-in-Children"><a href="#Hybrid-Models-for-Facial-Emotion-Recognition-in-Children" class="headerlink" title="Hybrid Models for Facial Emotion Recognition in Children"></a>Hybrid Models for Facial Emotion Recognition in Children</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12547">http://arxiv.org/abs/2308.12547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Zimmer, Marcos Sobral, Helio Azevedo</li>
</ul>
<p>Abstract:<br>This paper focuses on the use of emotion recognition techniques to assist psychologists in performing children’s therapy through remotely robot operated sessions. In the field of psychology, the use of agent-mediated therapy is growing increasingly given recent advances in robotics and computer science. Specifically, the use of Embodied Conversational Agents (ECA) as an intermediary tool can help professionals connect with children who face social challenges such as Attention Deficit Hyperactivity Disorder (ADHD), Autism Spectrum Disorder (ASD) or even who are physically unavailable due to being in regions of armed conflict, natural disasters, or other circumstances. In this context, emotion recognition represents an important feedback for the psychotherapist. In this article, we initially present the result of a bibliographical research associated with emotion recognition in children. This research revealed an initial overview on algorithms and datasets widely used by the community. Then, based on the analysis carried out on the results of the bibliographical research, we used the technique of dense optical flow features to improve the ability of identifying emotions in children in uncontrolled environments. From the output of a hybrid model of Convolutional Neural Network, two intermediary features are fused before being processed by a final classifier. The proposed architecture was called HybridCNNFusion. Finally, we present the initial results achieved in the recognition of children’s emotions using a dataset of Brazilian children.</p>
<hr>
<h2 id="Mutual-Guided-Dynamic-Network-for-Image-Fusion"><a href="#Mutual-Guided-Dynamic-Network-for-Image-Fusion" class="headerlink" title="Mutual-Guided Dynamic Network for Image Fusion"></a>Mutual-Guided Dynamic Network for Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12538">http://arxiv.org/abs/2308.12538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanys-dar/mgdn">https://github.com/guanys-dar/mgdn</a></li>
<li>paper_authors: Yuanshen Guan, Ruikang Xu, Mingde Yao, Lizhi Wang, Zhiwei Xiong</li>
</ul>
<p>Abstract:<br>Image fusion aims to generate a high-quality image from multiple images captured under varying conditions. The key problem of this task is to preserve complementary information while filtering out irrelevant information for the fused result. However, existing methods address this problem by leveraging static convolutional neural networks (CNNs), suffering two inherent limitations during feature extraction, i.e., being unable to handle spatial-variant contents and lacking guidance from multiple inputs. In this paper, we propose a novel mutual-guided dynamic network (MGDN) for image fusion, which allows for effective information utilization across different locations and inputs. Specifically, we design a mutual-guided dynamic filter (MGDF) for adaptive feature extraction, composed of a mutual-guided cross-attention (MGCA) module and a dynamic filter predictor, where the former incorporates additional guidance from different inputs and the latter generates spatial-variant kernels for different locations. In addition, we introduce a parallel feature fusion (PFF) module to effectively fuse local and global information of the extracted features. To further reduce the redundancy among the extracted features while simultaneously preserving their shared structural information, we devise a novel loss function that combines the minimization of normalized mutual information (NMI) with an estimated gradient mask. Experimental results on five benchmark datasets demonstrate that our proposed method outperforms existing methods on four image fusion tasks. The code and model are publicly available at: <a target="_blank" rel="noopener" href="https://github.com/Guanys-dar/MGDN">https://github.com/Guanys-dar/MGDN</a>.</p>
<hr>
<h2 id="HuBo-VLM-Unified-Vision-Language-Model-designed-for-HUman-roBOt-interaction-tasks"><a href="#HuBo-VLM-Unified-Vision-Language-Model-designed-for-HUman-roBOt-interaction-tasks" class="headerlink" title="HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks"></a>HuBo-VLM: Unified Vision-Language Model designed for HUman roBOt interaction tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12537">http://arxiv.org/abs/2308.12537</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dzcgaara/HuBo-VLM">https://github.com/dzcgaara/HuBo-VLM</a></li>
<li>paper_authors: Zichao Dong, Weikun Zhang, Xufeng Huang, Hang Ji, Xin Zhan, Junbo Chen</li>
</ul>
<p>Abstract:<br>Human robot interaction is an exciting task, which aimed to guide robots following instructions from human. Since huge gap lies between human natural language and machine codes, end to end human robot interaction models is fair challenging. Further, visual information receiving from sensors of robot is also a hard language for robot to perceive. In this work, HuBo-VLM is proposed to tackle perception tasks associated with human robot interaction including object detection and visual grounding by a unified transformer based vision language model. Extensive experiments on the Talk2Car benchmark demonstrate the effectiveness of our approach. Code would be publicly available in <a target="_blank" rel="noopener" href="https://github.com/dzcgaara/HuBo-VLM">https://github.com/dzcgaara/HuBo-VLM</a>.</p>
<hr>
<h2 id="SCP-Spherical-Coordinate-based-Learned-Point-Cloud-Compression"><a href="#SCP-Spherical-Coordinate-based-Learned-Point-Cloud-Compression" class="headerlink" title="SCP: Spherical-Coordinate-based Learned Point Cloud Compression"></a>SCP: Spherical-Coordinate-based Learned Point Cloud Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12535">http://arxiv.org/abs/2308.12535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ao Luo, Linxin Song, Keisuke Nonaka, Kyohei Unno, Heming Sun, Masayuki Goto, Jiro Katto</li>
</ul>
<p>Abstract:<br>In recent years, the task of learned point cloud compression has gained prominence. An important type of point cloud, the spinning LiDAR point cloud, is generated by spinning LiDAR on vehicles. This process results in numerous circular shapes and azimuthal angle invariance features within the point clouds. However, these two features have been largely overlooked by previous methodologies. In this paper, we introduce a model-agnostic method called Spherical-Coordinate-based learned Point cloud compression (SCP), designed to leverage the aforementioned features fully. Additionally, we propose a multi-level Octree for SCP to mitigate the reconstruction error for distant areas within the Spherical-coordinate-based Octree. SCP exhibits excellent universality, making it applicable to various learned point cloud compression techniques. Experimental results demonstrate that SCP surpasses previous state-of-the-art methods by up to 29.14% in point-to-point PSNR BD-Rate.</p>
<hr>
<h2 id="Channel-and-Spatial-Relation-Propagation-Network-for-RGB-Thermal-Semantic-Segmentation"><a href="#Channel-and-Spatial-Relation-Propagation-Network-for-RGB-Thermal-Semantic-Segmentation" class="headerlink" title="Channel and Spatial Relation-Propagation Network for RGB-Thermal Semantic Segmentation"></a>Channel and Spatial Relation-Propagation Network for RGB-Thermal Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12534">http://arxiv.org/abs/2308.12534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zikun Zhou, Shukun Wu, Guoqing Zhu, Hongpeng Wang, Zhenyu He</li>
</ul>
<p>Abstract:<br>RGB-Thermal (RGB-T) semantic segmentation has shown great potential in handling low-light conditions where RGB-based segmentation is hindered by poor RGB imaging quality. The key to RGB-T semantic segmentation is to effectively leverage the complementarity nature of RGB and thermal images. Most existing algorithms fuse RGB and thermal information in feature space via concatenation, element-wise summation, or attention operations in either unidirectional enhancement or bidirectional aggregation manners. However, they usually overlook the modality gap between RGB and thermal images during feature fusion, resulting in modality-specific information from one modality contaminating the other. In this paper, we propose a Channel and Spatial Relation-Propagation Network (CSRPNet) for RGB-T semantic segmentation, which propagates only modality-shared information across different modalities and alleviates the modality-specific information contamination issue. Our CSRPNet first performs relation-propagation in channel and spatial dimensions to capture the modality-shared features from the RGB and thermal features. CSRPNet then aggregates the modality-shared features captured from one modality with the input feature from the other modality to enhance the input feature without the contamination issue. While being fused together, the enhanced RGB and thermal features will be also fed into the subsequent RGB or thermal feature extraction layers for interactive feature fusion, respectively. We also introduce a dual-path cascaded feature refinement module that aggregates multi-layer features to produce two refined features for semantic and boundary prediction. Extensive experimental results demonstrate that CSRPNet performs favorably against state-of-the-art algorithms.</p>
<hr>
<h2 id="FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning"><a href="#FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning" class="headerlink" title="FedSoL: Bridging Global Alignment and Local Generality in Federated Learning"></a>FedSoL: Bridging Global Alignment and Local Generality in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12532">http://arxiv.org/abs/2308.12532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gihun Lee, Minchan Jeong, Sangmook Kim, Jaehoon Oh, Se-Young Yun</li>
</ul>
<p>Abstract:<br>Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (FedSoL), which combines both the concepts of global alignment and local generality. In FedSoL, the local learning seeks a parameter region robust against proximal perturbations. This strategy introduces an implicit proximal restriction effect in local learning while maintaining the original local objective for parameter update. Our experiments show that FedSoL consistently achieves state-of-the-art performance on various setups.</p>
<hr>
<h2 id="SieveNet-Selecting-Point-Based-Features-for-Mesh-Networks"><a href="#SieveNet-Selecting-Point-Based-Features-for-Mesh-Networks" class="headerlink" title="SieveNet: Selecting Point-Based Features for Mesh Networks"></a>SieveNet: Selecting Point-Based Features for Mesh Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12530">http://arxiv.org/abs/2308.12530</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengchao Yuan, Yishun Dou, Rui Shi, Bingbing Ni, Zhong Zheng</li>
</ul>
<p>Abstract:<br>Meshes are widely used in 3D computer vision and graphics, but their irregular topology poses challenges in applying them to existing neural network architectures. Recent advances in mesh neural networks turn to remeshing and push the boundary of pioneer methods that solely take the raw meshes as input. Although the remeshing offers a regular topology that significantly facilitates the design of mesh network architectures, features extracted from such remeshed proxies may struggle to retain the underlying geometry faithfully, limiting the subsequent neural network’s capacity. To address this issue, we propose SieveNet, a novel paradigm that takes into account both the regular topology and the exact geometry. Specifically, this method utilizes structured mesh topology from remeshing and accurate geometric information from distortion-aware point sampling on the surface of the original mesh. Furthermore, our method eliminates the need for hand-crafted feature engineering and can leverage off-the-shelf network architectures such as the vision transformer. Comprehensive experimental results on classification and segmentation tasks well demonstrate the effectiveness and superiority of our method.</p>
<hr>
<h2 id="Uniformly-Distributed-Category-Prototype-Guided-Vision-Language-Framework-for-Long-Tail-Recognition"><a href="#Uniformly-Distributed-Category-Prototype-Guided-Vision-Language-Framework-for-Long-Tail-Recognition" class="headerlink" title="Uniformly Distributed Category Prototype-Guided Vision-Language Framework for Long-Tail Recognition"></a>Uniformly Distributed Category Prototype-Guided Vision-Language Framework for Long-Tail Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12522">http://arxiv.org/abs/2308.12522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siming Fu, Xiaoxuan He, Xinpeng Ding, Yuchen Cao, Hualiang Wang</li>
</ul>
<p>Abstract:<br>Recently, large-scale pre-trained vision-language models have presented benefits for alleviating class imbalance in long-tailed recognition. However, the long-tailed data distribution can corrupt the representation space, where the distance between head and tail categories is much larger than the distance between two tail categories. This uneven feature space distribution causes the model to exhibit unclear and inseparable decision boundaries on the uniformly distributed test set, which lowers its performance. To address these challenges, we propose the uniformly category prototype-guided vision-language framework to effectively mitigate feature space bias caused by data imbalance. Especially, we generate a set of category prototypes uniformly distributed on a hypersphere. Category prototype-guided mechanism for image-text matching makes the features of different classes converge to these distinct and uniformly distributed category prototypes, which maintain a uniform distribution in the feature space, and improve class boundaries. Additionally, our proposed irrelevant text filtering and attribute enhancement module allows the model to ignore irrelevant noisy text and focus more on key attribute information, thereby enhancing the robustness of our framework. In the image recognition fine-tuning stage, to address the positive bias problem of the learnable classifier, we design the class feature prototype-guided classifier, which compensates for the performance of tail classes while maintaining the performance of head classes. Our method outperforms previous vision-language methods for long-tailed learning work by a large margin and achieves state-of-the-art performance.</p>
<hr>
<h2 id="I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting"><a href="#I3DOD-Towards-Incremental-3D-Object-Detection-via-Prompting" class="headerlink" title="I3DOD: Towards Incremental 3D Object Detection via Prompting"></a>I3DOD: Towards Incremental 3D Object Detection via Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12512">http://arxiv.org/abs/2308.12512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenqi Liang, Gan Sun, Chenxi Liu, Jiahua Dong, Kangru Wang</li>
</ul>
<p>Abstract:<br>3D object detection has achieved significant performance in many fields, e.g., robotics system, autonomous driving, and augmented reality. However, most existing methods could cause catastrophic forgetting of old classes when performing on the class-incremental scenarios. Meanwhile, the current class-incremental 3D object detection methods neglect the relationships between the object localization information and category semantic information and assume all the knowledge of old model is reliable. To address the above challenge, we present a novel Incremental 3D Object Detection framework with the guidance of prompting, i.e., I3DOD. Specifically, we propose a task-shared prompts mechanism to learn the matching relationships between the object localization information and category semantic information. After training on the current task, these prompts will be stored in our prompt pool, and perform the relationship of old classes in the next task. Moreover, we design a reliable distillation strategy to transfer knowledge from two aspects: a reliable dynamic distillation is developed to filter out the negative knowledge and transfer the reliable 3D knowledge to new detection model; the relation feature is proposed to capture the responses relation in feature space and protect plasticity of the model when learning novel 3D classes. To the end, we conduct comprehensive experiments on two benchmark datasets and our method outperforms the state-of-the-art object detection methods by 0.6% - 2.7% in terms of <a href="mailto:&#x6d;&#x41;&#x50;&#x40;&#x30;&#x2e;&#x32;&#53;">&#x6d;&#x41;&#x50;&#x40;&#x30;&#x2e;&#x32;&#53;</a>.</p>
<hr>
<h2 id="Masked-Autoencoders-are-Efficient-Class-Incremental-Learners"><a href="#Masked-Autoencoders-are-Efficient-Class-Incremental-Learners" class="headerlink" title="Masked Autoencoders are Efficient Class Incremental Learners"></a>Masked Autoencoders are Efficient Class Incremental Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12510">http://arxiv.org/abs/2308.12510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scok30/mae-cil">https://github.com/scok30/mae-cil</a></li>
<li>paper_authors: Jiang-Tian Zhai, Xialei Liu, Andrew D. Bagdanov, Ke Li, Ming-Ming Cheng</li>
</ul>
<p>Abstract:<br>Class Incremental Learning (CIL) aims to sequentially learn new classes while avoiding catastrophic forgetting of previous knowledge. We propose to use Masked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally designed to learn useful representations through reconstructive unsupervised learning, and they can be easily integrated with a supervised loss for classification. Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL. We also propose a bilateral MAE framework to learn from image-level and embedding-level fusion, which produces better-quality reconstructed images and more stable representations. Our experiments confirm that our approach performs better than the state-of-the-art on CIFAR-100, ImageNet-Subset, and ImageNet-Full. The code is available at <a target="_blank" rel="noopener" href="https://github.com/scok30/MAE-CIL">https://github.com/scok30/MAE-CIL</a> .</p>
<hr>
<h2 id="Parameter-Efficient-Transfer-Learning-for-Remote-Sensing-Image-Text-Retrieval"><a href="#Parameter-Efficient-Transfer-Learning-for-Remote-Sensing-Image-Text-Retrieval" class="headerlink" title="Parameter-Efficient Transfer Learning for Remote Sensing Image-Text Retrieval"></a>Parameter-Efficient Transfer Learning for Remote Sensing Image-Text Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12509">http://arxiv.org/abs/2308.12509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Yuan, Yang Zhan, Zhitong Xiong</li>
</ul>
<p>Abstract:<br>Vision-and-language pre-training (VLP) models have experienced a surge in popularity recently. By fine-tuning them on specific datasets, significant performance improvements have been observed in various tasks. However, full fine-tuning of VLP models not only consumes a significant amount of computational resources but also has a significant environmental impact. Moreover, as remote sensing (RS) data is constantly being updated, full fine-tuning may not be practical for real-world applications. To address this issue, in this work, we investigate the parameter-efficient transfer learning (PETL) method to effectively and efficiently transfer visual-language knowledge from the natural domain to the RS domain on the image-text retrieval task. To this end, we make the following contributions. 1) We construct a novel and sophisticated PETL framework for the RS image-text retrieval (RSITR) task, which includes the pretrained CLIP model, a multimodal remote sensing adapter, and a hybrid multi-modal contrastive (HMMC) learning objective; 2) To deal with the problem of high intra-modal similarity in RS data, we design a simple yet effective HMMC loss; 3) We provide comprehensive empirical studies for PETL-based RS image-text retrieval. Our results demonstrate that the proposed method is promising and of great potential for practical applications. 4) We benchmark extensive state-of-the-art PETL methods on the RSITR task. Our proposed model only contains 0.16M training parameters, which can achieve a parameter reduction of 98.9% compared to full fine-tuning, resulting in substantial savings in training costs. Our retrieval performance exceeds traditional methods by 7-13% and achieves comparable or better performance than full fine-tuning. This work can provide new ideas and useful insights for RS vision-language tasks.</p>
<hr>
<h2 id="FFEINR-Flow-Feature-Enhanced-Implicit-Neural-Representation-for-Spatio-temporal-Super-Resolution"><a href="#FFEINR-Flow-Feature-Enhanced-Implicit-Neural-Representation-for-Spatio-temporal-Super-Resolution" class="headerlink" title="FFEINR: Flow Feature-Enhanced Implicit Neural Representation for Spatio-temporal Super-Resolution"></a>FFEINR: Flow Feature-Enhanced Implicit Neural Representation for Spatio-temporal Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12508">http://arxiv.org/abs/2308.12508</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyue Jiao, Chongke Bi, Lu Yang</li>
</ul>
<p>Abstract:<br>Large-scale numerical simulations are capable of generating data up to terabytes or even petabytes. As a promising method of data reduction, super-resolution (SR) has been widely studied in the scientific visualization community. However, most of them are based on deep convolutional neural networks (CNNs) or generative adversarial networks (GANs) and the scale factor needs to be determined before constructing the network. As a result, a single training session only supports a fixed factor and has poor generalization ability. To address these problems, this paper proposes a Feature-Enhanced Implicit Neural Representation (FFEINR) for spatio-temporal super-resolution of flow field data. It can take full advantage of the implicit neural representation in terms of model structure and sampling resolution. The neural representation is based on a fully connected network with periodic activation functions, which enables us to obtain lightweight models. The learned continuous representation can decode the low-resolution flow field input data to arbitrary spatial and temporal resolutions, allowing for flexible upsampling. The training process of FFEINR is facilitated by introducing feature enhancements for the input layer, which complements the contextual information of the flow field.To demonstrate the effectiveness of the proposed method, a series of experiments are conducted on different datasets by setting different hyperparameters. The results show that FFEINR achieves significantly better results than the trilinear interpolation method.</p>
<hr>
<h2 id="DD-GCN-Directed-Diffusion-Graph-Convolutional-Network-for-Skeleton-based-Human-Action-Recognition"><a href="#DD-GCN-Directed-Diffusion-Graph-Convolutional-Network-for-Skeleton-based-Human-Action-Recognition" class="headerlink" title="DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition"></a>DD-GCN: Directed Diffusion Graph Convolutional Network for Skeleton-based Human Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12501">http://arxiv.org/abs/2308.12501</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shiyin-lc/dd-gcn">https://github.com/shiyin-lc/dd-gcn</a></li>
<li>paper_authors: Chang Li, Qian Huang, Yingchi Mao</li>
</ul>
<p>Abstract:<br>Graph Convolutional Networks (GCNs) have been widely used in skeleton-based human action recognition. In GCN-based methods, the spatio-temporal graph is fundamental for capturing motion patterns. However, existing approaches ignore the physical dependency and synchronized spatio-temporal correlations between joints, which limits the representation capability of GCNs. To solve these problems, we construct the directed diffusion graph for action modeling and introduce the activity partition strategy to optimize the weight sharing mechanism of graph convolution kernels. In addition, we present the spatio-temporal synchronization encoder to embed synchronized spatio-temporal semantics. Finally, we propose Directed Diffusion Graph Convolutional Network (DD-GCN) for action recognition, and the experiments on three public datasets: NTU-RGB+D, NTU-RGB+D 120, and NW-UCLA, demonstrate the state-of-the-art performance of our method.</p>
<hr>
<h2 id="Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis"><a href="#Source-Free-Collaborative-Domain-Adaptation-via-Multi-Perspective-Feature-Enrichment-for-Functional-MRI-Analysis" class="headerlink" title="Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis"></a>Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12495">http://arxiv.org/abs/2308.12495</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yqfang9199/scda">https://github.com/yqfang9199/scda</a></li>
<li>paper_authors: Yuqi Fang, Jinjian Wu, Qianqian Wang, Shijun Qiu, Andrea Bozoki, Huaicheng Yan, Mingxia Liu</li>
</ul>
<p>Abstract:<br>Resting-state functional MRI (rs-fMRI) is increasingly employed in multi-site research to aid neurological disorder analysis. Existing studies usually suffer from significant cross-site&#x2F;domain data heterogeneity caused by site effects such as differences in scanners&#x2F;protocols. Many methods have been proposed to reduce fMRI heterogeneity between source and target domains, heavily relying on the availability of source data. But acquiring source data is challenging due to privacy concerns and&#x2F;or data storage burdens in multi-site studies. To this end, we design a source-free collaborative domain adaptation (SCDA) framework for fMRI analysis, where only a pretrained source model and unlabeled target data are accessible. Specifically, a multi-perspective feature enrichment method (MFE) is developed for target fMRI analysis, consisting of multiple collaborative branches to dynamically capture fMRI features of unlabeled target data from multiple views. Each branch has a data-feeding module, a spatiotemporal feature encoder, and a class predictor. A mutual-consistency constraint is designed to encourage pair-wise consistency of latent features of the same input generated from these branches for robust representation learning. To facilitate efficient cross-domain knowledge transfer without source data, we initialize MFE using parameters of a pretrained source model. We also introduce an unsupervised pretraining strategy using 3,806 unlabeled fMRIs from three large-scale auxiliary databases, aiming to obtain a general feature encoder. Experimental results on three public datasets and one private dataset demonstrate the efficacy of our method in cross-scanner and cross-study prediction tasks. The model pretrained on large-scale rs-fMRI data has been released to the public.</p>
<hr>
<h2 id="MOFA-A-Model-Simplification-Roadmap-for-Image-Restoration-on-Mobile-Devices"><a href="#MOFA-A-Model-Simplification-Roadmap-for-Image-Restoration-on-Mobile-Devices" class="headerlink" title="MOFA: A Model Simplification Roadmap for Image Restoration on Mobile Devices"></a>MOFA: A Model Simplification Roadmap for Image Restoration on Mobile Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12494">http://arxiv.org/abs/2308.12494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Chen, Ruiwen Zhen, Shuai Li, Xiaotian Li, Guanghui Wang</li>
</ul>
<p>Abstract:<br>Image restoration aims to restore high-quality images from degraded counterparts and has seen significant advancements through deep learning techniques. The technique has been widely applied to mobile devices for tasks such as mobile photography. Given the resource limitations on mobile devices, such as memory constraints and runtime requirements, the efficiency of models during deployment becomes paramount. Nevertheless, most previous works have primarily concentrated on analyzing the efficiency of single modules and improving them individually. This paper examines the efficiency across different layers. We propose a roadmap that can be applied to further accelerate image restoration models prior to deployment while simultaneously increasing PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index). The roadmap first increases the model capacity by adding more parameters to partial convolutions on FLOPs non-sensitive layers. Then, it applies partial depthwise convolution coupled with decoupling upsampling&#x2F;downsampling layers to accelerate the model speed. Extensive experiments demonstrate that our approach decreases runtime by up to 13% and reduces the number of parameters by up to 23%, while increasing PSNR and SSIM on several image restoration datasets. Source Code of our method is available at \href{<a target="_blank" rel="noopener" href="https://github.com/xiangyu8/MOFA%7D%7Bhttps://github.com/xiangyu8/MOFA%7D">https://github.com/xiangyu8/MOFA}{https://github.com/xiangyu8/MOFA}</a>.</p>
<hr>
<h2 id="American-Stories-A-Large-Scale-Structured-Text-Dataset-of-Historical-U-S-Newspapers"><a href="#American-Stories-A-Large-Scale-Structured-Text-Dataset-of-Historical-U-S-Newspapers" class="headerlink" title="American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers"></a>American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12477">http://arxiv.org/abs/2308.12477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Melissa Dell, Jacob Carlson, Tom Bryan, Emily Silcock, Abhishek Arora, Zejiang Shen, Luca D’Amico-Wong, Quan Le, Pablo Querubin, Leander Heldring</li>
</ul>
<p>Abstract:<br>Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other layout regions. OCR quality can also be low. This study develops a novel, deep learning pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress’s public domain Chronicling America collection. The pipeline includes layout detection, legibility classification, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to the external database of a retrieval-augmented language model to make historical information - ranging from interpretations of political events to minutiae about the lives of people’s ancestors - more widely accessible. Furthermore, structured article texts facilitate using transformer-based methods for popular social science applications like topic classification, detection of reproduced content, and news story clustering. Finally, American Stories provides a massive silver quality dataset for innovating multimodal layout analysis models and other multimodal applications.</p>
<hr>
<h2 id="Diffuse-Attend-and-Segment-Unsupervised-Zero-Shot-Segmentation-using-Stable-Diffusion"><a href="#Diffuse-Attend-and-Segment-Unsupervised-Zero-Shot-Segmentation-using-Stable-Diffusion" class="headerlink" title="Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion"></a>Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12469">http://arxiv.org/abs/2308.12469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junjiao Tian, Lavisha Aggarwal, Andrea Colaco, Zsolt Kira, Mar Gonzalez-Franco</li>
</ul>
<p>Abstract:<br>Producing quality segmentation masks for images is a fundamental problem in computer vision. Recent research has explored large-scale supervised training to enable zero-shot segmentation on virtually any image style and unsupervised training to enable segmentation without dense annotations. However, constructing a model capable of segmenting anything in a zero-shot manner without any annotations is still challenging. In this paper, we propose to utilize the self-attention layers in stable diffusion models to achieve this goal because the pre-trained stable diffusion model has learned inherent concepts of objects within its attention layers. Specifically, we introduce a simple yet effective iterative merging process based on measuring KL divergence among attention maps to merge them into valid segmentation masks. The proposed method does not require any training or language dependency to extract quality segmentation for any images. On COCO-Stuff-27, our method surpasses the prior unsupervised zero-shot SOTA method by an absolute 26% in pixel accuracy and 17% in mean IoU.</p>
<hr>
<h2 id="InverseSR-3D-Brain-MRI-Super-Resolution-Using-a-Latent-Diffusion-Model"><a href="#InverseSR-3D-Brain-MRI-Super-Resolution-Using-a-Latent-Diffusion-Model" class="headerlink" title="InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model"></a>InverseSR: 3D Brain MRI Super-Resolution Using a Latent Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12465">http://arxiv.org/abs/2308.12465</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/biomedai-ucsc/inversesr">https://github.com/biomedai-ucsc/inversesr</a></li>
<li>paper_authors: Jueqi Wang, Jacob Levman, Walter Hugo Lopez Pinaya, Petru-Daniel Tudosiu, M. Jorge Cardoso, Razvan Marinescu</li>
</ul>
<p>Abstract:<br>High-resolution (HR) MRI scans obtained from research-grade medical centers provide precise information about imaged tissues. However, routine clinical MRI scans are typically in low-resolution (LR) and vary greatly in contrast and spatial resolution due to the adjustments of the scanning parameters to the local needs of the medical center. End-to-end deep learning methods for MRI super-resolution (SR) have been proposed, but they require re-training each time there is a shift in the input distribution. To address this issue, we propose a novel approach that leverages a state-of-the-art 3D brain generative model, the latent diffusion model (LDM) trained on UK BioBank, to increase the resolution of clinical MRI scans. The LDM acts as a generative prior, which has the ability to capture the prior distribution of 3D T1-weighted brain MRI. Based on the architecture of the brain LDM, we find that different methods are suitable for different settings of MRI SR, and thus propose two novel strategies: 1) for SR with more sparsity, we invert through both the decoder of the LDM and also through a deterministic Denoising Diffusion Implicit Models (DDIM), an approach we will call InverseSR(LDM); 2) for SR with less sparsity, we invert only through the LDM decoder, an approach we will call InverseSR(Decoder). These two approaches search different latent spaces in the LDM model to find the optimal latent code to map the given LR MRI into HR. The training process of the generative model is independent of the MRI under-sampling process, ensuring the generalization of our method to many MRI SR problems with different input measurements. We validate our method on over 100 brain T1w MRIs from the IXI dataset. Our method can demonstrate that powerful priors given by LDM can be used for MRI reconstruction.</p>
<hr>
<h2 id="Overcoming-General-Knowledge-Loss-with-Selective-Parameter-Finetuning"><a href="#Overcoming-General-Knowledge-Loss-with-Selective-Parameter-Finetuning" class="headerlink" title="Overcoming General Knowledge Loss with Selective Parameter Finetuning"></a>Overcoming General Knowledge Loss with Selective Parameter Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12462">http://arxiv.org/abs/2308.12462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxuan Zhang, Paul Janson, Rahaf Aljundi, Mohamed Elhoseiny</li>
</ul>
<p>Abstract:<br>Foundation models encompass an extensive knowledge base and offer remarkable transferability. However, this knowledge becomes outdated or insufficient over time. The challenge lies in updating foundation models to accommodate novel information while retaining their original ability. In this paper, we present a novel approach to achieving continual model updates by effecting localized modifications to a small subset of parameters. Guided by insights gleaned from prior analyses of foundational models, we first localize a specific layer for model refinement and then introduce an importance scoring mechanism designed to update only the most crucial weights. Our method is exhaustively evaluated on foundational vision-language models, measuring its efficacy in both learning new information and preserving pre-established knowledge across a diverse spectrum of continual learning tasks, including Aircraft, Birdsnap CIFAR-100, CUB, Cars, and GTSRB. The results show that our method improves the existing continual learning methods by 0.5% - 10% on average, and reduces the loss of pre-trained knowledge from around 5% to 0.97%. Comprehensive ablation studies substantiate our method design, shedding light on the contributions of each component to controllably learning new knowledge and mitigating the forgetting of pre-trained knowledge.</p>
<hr>
<h2 id="Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models"><a href="#Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models" class="headerlink" title="Augmenting medical image classifiers with synthetic data from latent diffusion models"></a>Augmenting medical image classifiers with synthetic data from latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12453">http://arxiv.org/abs/2308.12453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke W. Sagers, James A. Diao, Luke Melas-Kyriazi, Matthew Groh, Pranav Rajpurkar, Adewole S. Adamson, Veronica Rotemberg, Roxana Daneshjou, Arjun K. Manrai</li>
</ul>
<p>Abstract:<br>While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using several generation strategies. Our results suggest that synthetic data could serve as a force-multiplier for model development, but the collection of diverse real-world data remains the most important step to improve medical AI algorithms.</p>
<hr>
<h2 id="ARF-Plus-Controlling-Perceptual-Factors-in-Artistic-Radiance-Fields-for-3D-Scene-Stylization"><a href="#ARF-Plus-Controlling-Perceptual-Factors-in-Artistic-Radiance-Fields-for-3D-Scene-Stylization" class="headerlink" title="ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization"></a>ARF-Plus: Controlling Perceptual Factors in Artistic Radiance Fields for 3D Scene Stylization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12452">http://arxiv.org/abs/2308.12452</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhao Li, Tianhao Wu, Fangcheng Zhong, Cengiz Oztireli</li>
</ul>
<p>Abstract:<br>The radiance fields style transfer is an emerging field that has recently gained popularity as a means of 3D scene stylization, thanks to the outstanding performance of neural radiance fields in 3D reconstruction and view synthesis. We highlight a research gap in radiance fields style transfer, the lack of sufficient perceptual controllability, motivated by the existing concept in the 2D image style transfer. In this paper, we present ARF-Plus, a 3D neural style transfer framework offering manageable control over perceptual factors, to systematically explore the perceptual controllability in 3D scene stylization. Four distinct types of controls - color preservation control, (style pattern) scale control, spatial (selective stylization area) control, and depth enhancement control - are proposed and integrated into this framework. Results from real-world datasets, both quantitative and qualitative, show that the four types of controls in our ARF-Plus framework successfully accomplish their corresponding perceptual controls when stylizing 3D scenes. These techniques work well for individual style inputs as well as for the simultaneous application of multiple styles within a scene. This unlocks a realm of limitless possibilities, allowing customized modifications of stylization effects and flexible merging of the strengths of different styles, ultimately enabling the creation of novel and eye-catching stylistic effects on 3D scenes.</p>
<hr>
<h2 id="MOFO-MOtion-FOcused-Self-Supervision-for-Video-Understanding"><a href="#MOFO-MOtion-FOcused-Self-Supervision-for-Video-Understanding" class="headerlink" title="MOFO: MOtion FOcused Self-Supervision for Video Understanding"></a>MOFO: MOtion FOcused Self-Supervision for Video Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12447">http://arxiv.org/abs/2308.12447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mona Ahmadian, Frank Guerin, Andrew Gilbert</li>
</ul>
<p>Abstract:<br>Self-supervised learning (SSL) techniques have recently produced outstanding results in learning visual representations from unlabeled videos. Despite the importance of motion in supervised learning techniques for action recognition, SSL methods often do not explicitly consider motion information in videos. To address this issue, we propose MOFO (MOtion FOcused), a novel SSL method for focusing representation learning on the motion area of a video, for action recognition. MOFO automatically detects motion areas in videos and uses these to guide the self-supervision task. We use a masked autoencoder which randomly masks out a high proportion of the input sequence; we force a specified percentage of the inside of the motion area to be masked and the remainder from outside. We further incorporate motion information into the finetuning step to emphasise motion in the downstream task. We demonstrate that our motion-focused innovations can significantly boost the performance of the currently leading SSL method (VideoMAE) for action recognition. Our method improves the recent self-supervised Vision Transformer (ViT), VideoMAE, by achieving +2.6%, +2.1%, +1.3% accuracy on Epic-Kitchens verb, noun and action classification, respectively, and +4.7% accuracy on Something-Something V2 action classification. Our proposed approach significantly improves the performance of the current SSL method for action recognition, indicating the importance of explicitly encoding motion in SSL.</p>
<hr>
<h2 id="TAI-GAN-Temporally-and-Anatomically-Informed-GAN-for-early-to-late-frame-conversion-in-dynamic-cardiac-PET-motion-correction"><a href="#TAI-GAN-Temporally-and-Anatomically-Informed-GAN-for-early-to-late-frame-conversion-in-dynamic-cardiac-PET-motion-correction" class="headerlink" title="TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction"></a>TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12443">http://arxiv.org/abs/2308.12443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gxq1998/tai-gan">https://github.com/gxq1998/tai-gan</a></li>
<li>paper_authors: Xueqi Guo, Luyao Shi, Xiongchao Chen, Bo Zhou, Qiong Liu, Huidong Xie, Yi-Hwa Liu, Richard Palyo, Edward J. Miller, Albert J. Sinusas, Bruce Spottiswoode, Chi Liu, Nicha C. Dvornek</li>
</ul>
<p>Abstract:<br>The rapid tracer kinetics of rubidium-82 ($^{82}$Rb) and high variation of cross-frame distribution in dynamic cardiac positron emission tomography (PET) raise significant challenges for inter-frame motion correction, particularly for the early frames where conventional intensity-based image registration techniques are not applicable. Alternatively, a promising approach utilizes generative methods to handle the tracer distribution changes to assist existing registration methods. To improve frame-wise registration and parametric quantification, we propose a Temporally and Anatomically Informed Generative Adversarial Network (TAI-GAN) to transform the early frames into the late reference frame using an all-to-one mapping. Specifically, a feature-wise linear modulation layer encodes channel-wise parameters generated from temporal tracer kinetics information, and rough cardiac segmentations with local shifts serve as the anatomical information. We validated our proposed method on a clinical $^{82}$Rb PET dataset and found that our TAI-GAN can produce converted early frames with high image quality, comparable to the real reference frames. After TAI-GAN conversion, motion estimation accuracy and clinical myocardial blood flow (MBF) quantification were improved compared to using the original frames. Our code is published at <a target="_blank" rel="noopener" href="https://github.com/gxq1998/TAI-GAN">https://github.com/gxq1998/TAI-GAN</a>.</p>
<hr>
<h2 id="HNAS-reg-hierarchical-neural-architecture-search-for-deformable-medical-image-registration"><a href="#HNAS-reg-hierarchical-neural-architecture-search-for-deformable-medical-image-registration" class="headerlink" title="HNAS-reg: hierarchical neural architecture search for deformable medical image registration"></a>HNAS-reg: hierarchical neural architecture search for deformable medical image registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12440">http://arxiv.org/abs/2308.12440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiong Wu, Yong Fan</li>
</ul>
<p>Abstract:<br>Convolutional neural networks (CNNs) have been widely used to build deep learning models for medical image registration, but manually designed network architectures are not necessarily optimal. This paper presents a hierarchical NAS framework (HNAS-Reg), consisting of both convolutional operation search and network topology search, to identify the optimal network architecture for deformable medical image registration. To mitigate the computational overhead and memory constraints, a partial channel strategy is utilized without losing optimization quality. Experiments on three datasets, consisting of 636 T1-weighted magnetic resonance images (MRIs), have demonstrated that the proposal method can build a deep learning model with improved image registration accuracy and reduced model size, compared with state-of-the-art image registration approaches, including one representative traditional approach and two unsupervised learning-based approaches.</p>
<hr>
<h2 id="BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection"><a href="#BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection" class="headerlink" title="BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection"></a>BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12439">http://arxiv.org/abs/2308.12439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal</li>
</ul>
<p>Abstract:<br>We present a novel defense, against backdoor attacks on Deep Neural Networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. The proposed defense is built upon a novel reverse engineering approach that can directly extract backdoor functionality of a given backdoored model to a backdoor expert model. The approach is straightforward – finetuning the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising highly accurate backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by an ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert (Backdoor Input Detection with Backdoor Expert), effectively mitigates 16 SOTA backdoor attacks while minimally impacting clean utility. The effectiveness of BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet) across various model architectures (ResNet, VGG, MobileNetV2 and Vision Transformer).</p>
<hr>
<h2 id="Characterising-representation-dynamics-in-recurrent-neural-networks-for-object-recognition"><a href="#Characterising-representation-dynamics-in-recurrent-neural-networks-for-object-recognition" class="headerlink" title="Characterising representation dynamics in recurrent neural networks for object recognition"></a>Characterising representation dynamics in recurrent neural networks for object recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12435">http://arxiv.org/abs/2308.12435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sushrut Thorat, Adrien Doerig, Tim C. Kietzmann</li>
</ul>
<p>Abstract:<br>Recurrent neural networks (RNNs) have yielded promising results for both recognizing objects in challenging conditions and modeling aspects of primate vision. However, the representational dynamics of recurrent computations remain poorly understood, especially in large-scale visual models. Here, we studied such dynamics in RNNs trained for object classification on MiniEcoset, a novel subset of ecoset. We report two main insights. First, upon inference, representations continued to evolve after correct classification, suggesting a lack of the notion of being <code>done with classification&#39;&#39;. Second, focusing on </code>readout zones’’ as a way to characterize the activation trajectories, we observe that misclassified representations exhibit activation patterns with lower L2 norm, and are positioned more peripherally in the readout zones. Such arrangements help the misclassified representations move into the correct zones as time progresses. Our findings generalize to networks with lateral and top-down connections, and include both additive and multiplicative interactions with the bottom-up sweep. The results therefore contribute to a general understanding of RNN dynamics in naturalistic tasks. We hope that the analysis framework will aid future investigations of other types of RNNs, including understanding of representational dynamics in primate vision.</p>
<hr>
<h2 id="A-Spatiotemporal-Correspondence-Approach-to-Unsupervised-LiDAR-Segmentation-with-Traffic-Applications"><a href="#A-Spatiotemporal-Correspondence-Approach-to-Unsupervised-LiDAR-Segmentation-with-Traffic-Applications" class="headerlink" title="A Spatiotemporal Correspondence Approach to Unsupervised LiDAR Segmentation with Traffic Applications"></a>A Spatiotemporal Correspondence Approach to Unsupervised LiDAR Segmentation with Traffic Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12433">http://arxiv.org/abs/2308.12433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Li, Pan He, Aotian Wu, Sanjay Ranka, Anand Rangarajan</li>
</ul>
<p>Abstract:<br>We address the problem of unsupervised semantic segmentation of outdoor LiDAR point clouds in diverse traffic scenarios. The key idea is to leverage the spatiotemporal nature of a dynamic point cloud sequence and introduce drastically stronger augmentation by establishing spatiotemporal correspondences across multiple frames. We dovetail clustering and pseudo-label learning in this work. Essentially, we alternate between clustering points into semantic groups and optimizing models using point-wise pseudo-spatiotemporal labels with a simple learning objective. Therefore, our method can learn discriminative features in an unsupervised learning fashion. We show promising segmentation performance on Semantic-KITTI, SemanticPOSS, and FLORIDA benchmark datasets covering scenarios in autonomous vehicle and intersection infrastructure, which is competitive when compared against many existing fully supervised learning methods. This general framework can lead to a unified representation learning approach for LiDAR point clouds incorporating domain knowledge.</p>
<hr>
<h2 id="Toward-American-Sign-Language-Processing-in-the-Real-World-Data-Tasks-and-Methods"><a href="#Toward-American-Sign-Language-Processing-in-the-Real-World-Data-Tasks-and-Methods" class="headerlink" title="Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods"></a>Toward American Sign Language Processing in the Real World: Data, Tasks, and Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12419">http://arxiv.org/abs/2308.12419</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bowen Shi</li>
</ul>
<p>Abstract:<br>Sign language, which conveys meaning through gestures, is the chief means of communication among deaf people. Recognizing sign language in natural settings presents significant challenges due to factors such as lighting, background clutter, and variations in signer characteristics. In this thesis, I study automatic sign language processing in the wild, using signing videos collected from the Internet. This thesis contributes new datasets, tasks, and methods. Most chapters of this thesis address tasks related to fingerspelling, an important component of sign language and yet has not been studied widely by prior work. I present three new large-scale ASL datasets in the wild: ChicagoFSWild, ChicagoFSWild+, and OpenASL. Using ChicagoFSWild and ChicagoFSWild+, I address fingerspelling recognition, which consists of transcribing fingerspelling sequences into text. I propose an end-to-end approach based on iterative attention that allows recognition from a raw video without explicit hand detection. I further show that using a Conformer-based network jointly modeling handshape and mouthing can bring performance close to that of humans. Next, I propose two tasks for building real-world fingerspelling-based applications: fingerspelling detection and search. For fingerspelling detection, I introduce a suite of evaluation metrics and a new detection model via multi-task training. To address the problem of searching for fingerspelled keywords in raw sign language videos, we propose a novel method that jointly localizes and matches fingerspelling segments to text. Finally, I will describe a benchmark for large-vocabulary open-domain sign language translation based on OpenASL. To address the challenges of sign language translation in realistic settings, we propose a set of techniques including sign search as a pretext task for pre-training and fusion of mouthing and handshape features.</p>
<hr>
<h2 id="Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach"><a href="#Reframing-the-Brain-Age-Prediction-Problem-to-a-More-Interpretable-and-Quantitative-Approach" class="headerlink" title="Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach"></a>Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12416">http://arxiv.org/abs/2308.12416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha Gianchandani, Mahsa Dibaji, Mariana Bento, Ethan MacDonald, Roberto Souza</li>
</ul>
<p>Abstract:<br>Deep learning models have achieved state-of-the-art results in estimating brain age, which is an important brain health biomarker, from magnetic resonance (MR) images. However, most of these models only provide a global age prediction, and rely on techniques, such as saliency maps to interpret their results. These saliency maps highlight regions in the input image that were significant for the model’s predictions, but they are hard to be interpreted, and saliency map values are not directly comparable across different samples. In this work, we reframe the age prediction problem from MR images to an image-to-image regression problem where we estimate the brain age for each brain voxel in MR images. We compare voxel-wise age prediction models against global age prediction models and their corresponding saliency maps. The results indicate that voxel-wise age prediction models are more interpretable, since they provide spatial information about the brain aging process, and they benefit from being quantitative.</p>
<hr>
<h2 id="An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video"><a href="#An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video" class="headerlink" title="An Initial Exploration: Learning to Generate Realistic Audio for Silent Video"></a>An Initial Exploration: Learning to Generate Realistic Audio for Silent Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12408">http://arxiv.org/abs/2308.12408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Martel, Jackson Wagner</li>
</ul>
<p>Abstract:<br>Generating realistic audio effects for movies and other media is a challenging task that is accomplished today primarily through physical techniques known as Foley art. Foley artists create sounds with common objects (e.g., boxing gloves, broken glass) in time with video as it is playing to generate captivating audio tracks. In this work, we aim to develop a deep-learning based framework that does much the same - observes video in it’s natural sequence and generates realistic audio to accompany it. Notably, we have reason to believe this is achievable due to advancements in realistic audio generation techniques conditioned on other inputs (e.g., Wavenet conditioned on text). We explore several different model architectures to accomplish this task that process both previously-generated audio and video context. These include deep-fusion CNN, dilated Wavenet CNN with visual context, and transformer-based architectures. We find that the transformer-based architecture yields the most promising results, matching low-frequencies to visual patterns effectively, but failing to generate more nuanced waveforms.</p>
<hr>
<h2 id="Self-Supervised-Learning-for-Endoscopic-Video-Analysis"><a href="#Self-Supervised-Learning-for-Endoscopic-Video-Analysis" class="headerlink" title="Self-Supervised Learning for Endoscopic Video Analysis"></a>Self-Supervised Learning for Endoscopic Video Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12394">http://arxiv.org/abs/2308.12394</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/royhirsch/endossl">https://github.com/royhirsch/endossl</a></li>
<li>paper_authors: Roy Hirsch, Mathilde Caron, Regev Cohen, Amir Livne, Ron Shapiro, Tomer Golany, Roman Goldenberg, Daniel Freedman, Ehud Rivlin</li>
</ul>
<p>Abstract:<br>Self-supervised learning (SSL) has led to important breakthroughs in computer vision by allowing learning from large amounts of unlabeled data. As such, it might have a pivotal role to play in biomedicine where annotating data requires a highly specialized expertise. Yet, there are many healthcare domains for which SSL has not been extensively explored. One such domain is endoscopy, minimally invasive procedures which are commonly used to detect and treat infections, chronic inflammatory diseases or cancer. In this work, we study the use of a leading SSL framework, namely Masked Siamese Networks (MSNs), for endoscopic video analysis such as colonoscopy and laparoscopy. To fully exploit the power of SSL, we create sizable unlabeled endoscopic video datasets for training MSNs. These strong image representations serve as a foundation for secondary training with limited annotated datasets, resulting in state-of-the-art performance in endoscopic benchmarks like surgical phase recognition during laparoscopy and colonoscopic polyp characterization. Additionally, we achieve a 50% reduction in annotated data size without sacrificing performance. Thus, our work provides evidence that SSL can dramatically reduce the need of annotated data in endoscopy.</p>
<hr>
<h2 id="With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning"><a href="#With-a-Little-Help-from-your-own-Past-Prototypical-Memory-Networks-for-Image-Captioning" class="headerlink" title="With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning"></a>With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12383">http://arxiv.org/abs/2308.12383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/pma-net">https://github.com/aimagelab/pma-net</a></li>
<li>paper_authors: Manuele Barraco, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</li>
</ul>
<p>Abstract:<br>Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components. We demonstrate that our proposal can increase the performance of an encoder-decoder Transformer by 3.7 CIDEr points both when training in cross-entropy only and when fine-tuning with self-critical sequence training. Source code and trained models are available at: <a target="_blank" rel="noopener" href="https://github.com/aimagelab/PMA-Net">https://github.com/aimagelab/PMA-Net</a>.</p>
<hr>
<h2 id="FG-Net-Facial-Action-Unit-Detection-with-Generalizable-Pyramidal-Features"><a href="#FG-Net-Facial-Action-Unit-Detection-with-Generalizable-Pyramidal-Features" class="headerlink" title="FG-Net: Facial Action Unit Detection with Generalizable Pyramidal Features"></a>FG-Net: Facial Action Unit Detection with Generalizable Pyramidal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12380">http://arxiv.org/abs/2308.12380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ihp-lab/fg-net">https://github.com/ihp-lab/fg-net</a></li>
<li>paper_authors: Yufeng Yin, Di Chang, Guoxian Song, Shen Sang, Tiancheng Zhi, Jing Liu, Linjie Luo, Mohammad Soleymani</li>
</ul>
<p>Abstract:<br>Automatic detection of facial Action Units (AUs) allows for objective facial expression analysis. Due to the high cost of AU labeling and the limited size of existing benchmarks, previous AU detection methods tend to overfit the dataset, resulting in a significant performance loss when evaluated across corpora. To address this problem, we propose FG-Net for generalizable facial action unit detection. Specifically, FG-Net extracts feature maps from a StyleGAN2 model pre-trained on a large and diverse face image dataset. Then, these features are used to detect AUs with a Pyramid CNN Interpreter, making the training efficient and capturing essential local features. The proposed FG-Net achieves a strong generalization ability for heatmap-based AU detection thanks to the generalizable and semantic-rich features extracted from the pre-trained generative model. Extensive experiments are conducted to evaluate within- and cross-corpus AU detection with the widely-used DISFA and BP4D datasets. Compared with the state-of-the-art, the proposed method achieves superior cross-domain performance while maintaining competitive within-domain performance. In addition, FG-Net is data-efficient and achieves competitive performance even when trained on 1000 samples. Our code will be released at \url{<a target="_blank" rel="noopener" href="https://github.com/ihp-lab/FG-Net%7D">https://github.com/ihp-lab/FG-Net}</a></p>
<hr>
<h2 id="Vision-Transformer-Adapters-for-Generalizable-Multitask-Learning"><a href="#Vision-Transformer-Adapters-for-Generalizable-Multitask-Learning" class="headerlink" title="Vision Transformer Adapters for Generalizable Multitask Learning"></a>Vision Transformer Adapters for Generalizable Multitask Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12372">http://arxiv.org/abs/2308.12372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IVRL/VTAGML">https://github.com/IVRL/VTAGML</a></li>
<li>paper_authors: Deblina Bhattacharjee, Sabine Süsstrunk, Mathieu Salzmann</li>
</ul>
<p>Abstract:<br>We introduce the first multitasking vision transformer adapters that learn generalizable task affinities which can be applied to novel tasks and domains. Integrated into an off-the-shelf vision transformer backbone, our adapters can simultaneously solve multiple dense vision tasks in a parameter-efficient manner, unlike existing multitasking transformers that are parametrically expensive. In contrast to concurrent methods, we do not require retraining or fine-tuning whenever a new task or domain is added. We introduce a task-adapted attention mechanism within our adapter framework that combines gradient-based task similarities with attention-based ones. The learned task affinities generalize to the following settings: zero-shot task transfer, unsupervised domain adaptation, and generalization without fine-tuning to novel domains. We demonstrate that our approach outperforms not only the existing convolutional neural network-based multitasking methods but also the vision transformer-based ones. Our project page is at \url{<a target="_blank" rel="noopener" href="https://ivrl.github.io/VTAGML%7D">https://ivrl.github.io/VTAGML}</a>.</p>
<hr>
<h2 id="Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation"><a href="#Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation" class="headerlink" title="Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation"></a>Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12371">http://arxiv.org/abs/2308.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Manuel Günther, William Robson Schwartz</li>
</ul>
<p>Abstract:<br>Open-set face recognition refers to a scenario in which biometric systems have incomplete knowledge of all existing subjects. Therefore, they are expected to prevent face samples of unregistered subjects from being identified as previously enrolled identities. This watchlist context adds an arduous requirement that calls for the dismissal of irrelevant faces by focusing mainly on subjects of interest. As a response, this work introduces a novel method that associates an ensemble of compact neural networks with a margin-based cost function that explores additional samples. Supplementary negative samples can be obtained from external databases or synthetically built at the representation level in training time with a new mix-up feature augmentation approach. Deep neural networks pre-trained on large face datasets serve as the preliminary feature extraction module. We carry out experiments on well-known LFW and IJB-C datasets where results show that the approach is able to boost closed and open-set identification rates.</p>
<hr>
<h2 id="AdVerb-Visually-Guided-Audio-Dereverberation"><a href="#AdVerb-Visually-Guided-Audio-Dereverberation" class="headerlink" title="AdVerb: Visually Guided Audio Dereverberation"></a>AdVerb: Visually Guided Audio Dereverberation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12370">http://arxiv.org/abs/2308.12370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjoy Chowdhury, Sreyan Ghosh, Subhrajyoti Dasgupta, Anton Ratnarajah, Utkarsh Tyagi, Dinesh Manocha</li>
</ul>
<p>Abstract:<br>We present AdVerb, a novel audio-visual dereverberation framework that uses visual cues in addition to the reverberant sound to estimate clean audio. Although audio-only dereverberation is a well-studied problem, our approach incorporates the complementary visual modality to perform audio dereverberation. Given an image of the environment where the reverberated sound signal has been recorded, AdVerb employs a novel geometry-aware cross-modal transformer architecture that captures scene geometry and audio-visual cross-modal relationship to generate a complex ideal ratio mask, which, when applied to the reverberant audio predicts the clean sound. The effectiveness of our method is demonstrated through extensive quantitative and qualitative evaluations. Our approach significantly outperforms traditional audio-only and audio-visual baselines on three downstream tasks: speech enhancement, speech recognition, and speaker verification, with relative improvements in the range of 18% - 82% on the LibriSpeech test-clean set. We also achieve highly satisfactory RT60 error scores on the AVSpeech dataset.</p>
<hr>
<h2 id="Continual-Zero-Shot-Learning-through-Semantically-Guided-Generative-Random-Walks"><a href="#Continual-Zero-Shot-Learning-through-Semantically-Guided-Generative-Random-Walks" class="headerlink" title="Continual Zero-Shot Learning through Semantically Guided Generative Random Walks"></a>Continual Zero-Shot Learning through Semantically Guided Generative Random Walks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12366">http://arxiv.org/abs/2308.12366</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wx-zhang/igczsl">https://github.com/wx-zhang/igczsl</a></li>
<li>paper_authors: Wenxuan Zhang, Paul Janson, Kai Yi, Ivan Skorokhodov, Mohamed Elhoseiny</li>
</ul>
<p>Abstract:<br>Learning novel concepts, remembering previous knowledge, and adapting it to future tasks occur simultaneously throughout a human’s lifetime. To model such comprehensive abilities, continual zero-shot learning (CZSL) has recently been introduced. However, most existing methods overused unseen semantic information that may not be continually accessible in realistic settings. In this paper, we address the challenge of continual zero-shot learning where unseen information is not provided during training, by leveraging generative modeling. The heart of the generative-based methods is to learn quality representations from seen classes to improve the generative understanding of the unseen visual space. Motivated by this, we introduce generalization-bound tools and provide the first theoretical explanation for the benefits of generative modeling to CZSL tasks. Guided by the theoretical analysis, we then propose our learning algorithm that employs a novel semantically guided Generative Random Walk (GRW) loss. The GRW loss augments the training by continually encouraging the model to generate realistic and characterized samples to represent the unseen space. Our algorithm achieves state-of-the-art performance on AWA1, AWA2, CUB, and SUN datasets, surpassing existing CZSL methods by 3-7%. The code has been made available here \url{<a target="_blank" rel="noopener" href="https://github.com/wx-zhang/IGCZSL%7D">https://github.com/wx-zhang/IGCZSL}</a></p>
<hr>
<h2 id="Saliency-based-Video-Summarization-for-Face-Anti-spoofing"><a href="#Saliency-based-Video-Summarization-for-Face-Anti-spoofing" class="headerlink" title="Saliency-based Video Summarization for Face Anti-spoofing"></a>Saliency-based Video Summarization for Face Anti-spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12364">http://arxiv.org/abs/2308.12364</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Usman1021/Saliency">https://github.com/Usman1021/Saliency</a></li>
<li>paper_authors: Usman Muhammad, Mourad Oussalah, Md Ziaul Hoque, Jorma Laaksonen</li>
</ul>
<p>Abstract:<br>Due to the growing availability of face anti-spoofing databases, researchers are increasingly focusing on video-based methods that use hundreds to thousands of images to assess their impact on performance. However, there is no clear consensus on the exact number of frames in a video required to improve the performance of face anti-spoofing tasks. Inspired by the visual saliency theory, we present a video summarization method for face anti-spoofing tasks that aims to enhance the performance and efficiency of deep learning models by leveraging visual saliency. In particular, saliency information is extracted from the differences between the Laplacian and Wiener filter outputs of the source images, enabling identification of the most visually salient regions within each frame. Subsequently, the source images are decomposed into base and detail layers, enhancing representation of important information. The weighting maps are then computed based on the saliency information, indicating the importance of each pixel in the image. By linearly combining the base and detail layers using the weighting maps, the method fuses the source images to create a single representative image that summarizes the entire video. The key contribution of our proposed method lies in demonstrating how visual saliency can be used as a data-centric approach to improve the performance and efficiency of face presentation attack detection models. By focusing on the most salient images or regions within the images, a more representative and diverse training set can be created, potentially leading to more effective models. To validate the method’s effectiveness, a simple deep learning architecture (CNN-RNN) was used, and the experimental results showcased state-of-the-art performance on five challenging face anti-spoofing datasets.</p>
<hr>
<h2 id="Diffusion-based-Image-Translation-with-Label-Guidance-for-Domain-Adaptive-Semantic-Segmentation"><a href="#Diffusion-based-Image-Translation-with-Label-Guidance-for-Domain-Adaptive-Semantic-Segmentation" class="headerlink" title="Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation"></a>Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12350">http://arxiv.org/abs/2308.12350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duo Peng, Ping Hu, Qiuhong Ke, Jun Liu</li>
</ul>
<p>Abstract:<br>Translating images from a source domain to a target domain for learning target models is one of the most common strategies in domain adaptive semantic segmentation (DASS). However, existing methods still struggle to preserve semantically-consistent local details between the original and translated images. In this work, we present an innovative approach that addresses this challenge by using source-domain labels as explicit guidance during image translation. Concretely, we formulate cross-domain image translation as a denoising diffusion process and utilize a novel Semantic Gradient Guidance (SGG) method to constrain the translation process, conditioning it on the pixel-wise source labels. Additionally, a Progressive Translation Learning (PTL) strategy is devised to enable the SGG method to work reliably across domains with large gaps. Extensive experiments demonstrate the superiority of our approach over state-of-the-art methods.</p>
<hr>
<h2 id="CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images"><a href="#CHORUS-Learning-Canonicalized-3D-Human-Object-Spatial-Relations-from-Unbounded-Synthesized-Images" class="headerlink" title="CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images"></a>CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12288">http://arxiv.org/abs/2308.12288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sookwan Han, Hanbyul Joo</li>
</ul>
<p>Abstract:<br>We present a method for teaching machines to understand and model the underlying spatial common sense of diverse human-object interactions in 3D in a self-supervised way. This is a challenging task, as there exist specific manifolds of the interactions that can be considered human-like and natural, but the human pose and the geometry of objects can vary even for similar interactions. Such diversity makes the annotating task of 3D interactions difficult and hard to scale, which limits the potential to reason about that in a supervised way. One way of learning the 3D spatial relationship between humans and objects during interaction is by showing multiple 2D images captured from different viewpoints when humans interact with the same type of objects. The core idea of our method is to leverage a generative model that produces high-quality 2D images from an arbitrary text prompt input as an “unbounded” data generator with effective controllability and view diversity. Despite its imperfection of the image quality over real images, we demonstrate that the synthesized images are sufficient to learn the 3D human-object spatial relations. We present multiple strategies to leverage the synthesized images, including (1) the first method to leverage a generative image model for 3D human-object spatial relation learning; (2) a framework to reason about the 3D spatial relations from inconsistent 2D cues in a self-supervised manner via 3D occupancy reasoning with pose canonicalization; (3) semantic clustering to disambiguate different types of interactions with the same object types; and (4) a novel metric to assess the quality of 3D spatial learning of interaction. Project Page: <a target="_blank" rel="noopener" href="https://jellyheadandrew.github.io/projects/chorus">https://jellyheadandrew.github.io/projects/chorus</a></p>
<hr>
<h2 id="A-Generative-Approach-for-Image-Registration-of-Visible-Thermal-VT-Cancer-Faces"><a href="#A-Generative-Approach-for-Image-Registration-of-Visible-Thermal-VT-Cancer-Faces" class="headerlink" title="A Generative Approach for Image Registration of Visible-Thermal (VT) Cancer Faces"></a>A Generative Approach for Image Registration of Visible-Thermal (VT) Cancer Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12271">http://arxiv.org/abs/2308.12271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Catherine Ordun, Alexandra Cha, Edward Raff, Sanjay Purushotham, Karen Kwok, Mason Rule, James Gulley</li>
</ul>
<p>Abstract:<br>Since thermal imagery offers a unique modality to investigate pain, the U.S. National Institutes of Health (NIH) has collected a large and diverse set of cancer patient facial thermograms for AI-based pain research. However, differing angles from camera capture between thermal and visible sensors has led to misalignment between Visible-Thermal (VT) images. We modernize the classic computer vision task of image registration by applying and modifying a generative alignment algorithm to register VT cancer faces, without the need for a reference or alignment parameters. By registering VT faces, we demonstrate that the quality of thermal images produced in the generative AI downstream task of Visible-to-Thermal (V2T) image translation significantly improves up to 52.5%, than without registration. Images in this paper have been approved by the NIH NCI for public dissemination.</p>
<hr>
<h2 id="MolGrapher-Graph-based-Visual-Recognition-of-Chemical-Structures"><a href="#MolGrapher-Graph-based-Visual-Recognition-of-Chemical-Structures" class="headerlink" title="MolGrapher: Graph-based Visual Recognition of Chemical Structures"></a>MolGrapher: Graph-based Visual Recognition of Chemical Structures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12234">http://arxiv.org/abs/2308.12234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ds4sd/molgrapher">https://github.com/ds4sd/molgrapher</a></li>
<li>paper_authors: Lucas Morin, Martin Danelljan, Maria Isabel Agea, Ahmed Nassar, Valery Weber, Ingmar Meijer, Peter Staar, Fisher Yu</li>
</ul>
<p>Abstract:<br>The automatic analysis of chemical literature has immense potential to accelerate the discovery of new materials and drugs. Much of the critical information in patent documents and scientific articles is contained in figures, depicting the molecule structures. However, automatically parsing the exact chemical structure is a formidable challenge, due to the amount of detailed information, the diversity of drawing styles, and the need for training data. In this work, we introduce MolGrapher to recognize chemical structures visually. First, a deep keypoint detector detects the atoms. Second, we treat all candidate atoms and bonds as nodes and put them in a graph. This construct allows a natural graph representation of the molecule. Last, we classify atom and bond nodes in the graph with a Graph Neural Network. To address the lack of real training data, we propose a synthetic data generation pipeline producing diverse and realistic results. In addition, we introduce a large-scale benchmark of annotated real molecule images, USPTO-30K, to spur research on this critical topic. Extensive experiments on five datasets show that our approach significantly outperforms classical and learning-based methods in most settings. Code, models, and datasets are available.</p>
<hr>
<h2 id="SPPNet-A-Single-Point-Prompt-Network-for-Nuclei-Image-Segmentation"><a href="#SPPNet-A-Single-Point-Prompt-Network-for-Nuclei-Image-Segmentation" class="headerlink" title="SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation"></a>SPPNet: A Single-Point Prompt Network for Nuclei Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12231">http://arxiv.org/abs/2308.12231</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xq141839/sppnet">https://github.com/xq141839/sppnet</a></li>
<li>paper_authors: Qing Xu, Wenwei Kuang, Zeyu Zhang, Xueyao Bao, Haoran Chen, Wenting Duan</li>
</ul>
<p>Abstract:<br>Image segmentation plays an essential role in nuclei image analysis. Recently, the segment anything model has made a significant breakthrough in such tasks. However, the current model exists two major issues for cell segmentation: (1) the image encoder of the segment anything model involves a large number of parameters. Retraining or even fine-tuning the model still requires expensive computational resources. (2) in point prompt mode, points are sampled from the center of the ground truth and more than one set of points is expected to achieve reliable performance, which is not efficient for practical applications. In this paper, a single-point prompt network is proposed for nuclei image segmentation, called SPPNet. We replace the original image encoder with a lightweight vision transformer. Also, an effective convolutional block is added in parallel to extract the low-level semantic information from the image and compensate for the performance degradation due to the small image encoder. We propose a new point-sampling method based on the Gaussian kernel. The proposed model is evaluated on the MoNuSeg-2018 dataset. The result demonstrated that SPPNet outperforms existing U-shape architectures and shows faster convergence in training. Compared to the segment anything model, SPPNet shows roughly 20 times faster inference, with 1&#x2F;70 parameters and computational cost. Particularly, only one set of points is required in both the training and inference phases, which is more reasonable for clinical applications. The code for our work and more technical details can be found at <a target="_blank" rel="noopener" href="https://github.com/xq141839/SPPNet">https://github.com/xq141839/SPPNet</a>.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.CV_2023_08_24/" data-id="cllqfoua5000ga488dwpa2k7q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.SD_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/cs.SD_2023_08_24/">cs.SD - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture"><a href="#Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture" class="headerlink" title="Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture"></a>Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12859">http://arxiv.org/abs/2308.12859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Wang, Juan Ye, David L. Borchers</li>
</ul>
<p>Abstract:<br>Passive acoustic monitoring can be an effective way of monitoring wildlife populations that are acoustically active but difficult to survey visually. Digital recorders allow surveyors to gather large volumes of data at low cost, but identifying target species vocalisations in these data is non-trivial. Machine learning (ML) methods are often used to do the identification. They can process large volumes of data quickly, but they do not detect all vocalisations and they do generate some false positives (vocalisations that are not from the target species). Existing wildlife abundance survey methods have been designed specifically to deal with the first of these mistakes, but current methods of dealing with false positives are not well-developed. They do not take account of features of individual vocalisations, some of which are more likely to be false positives than others. We propose three methods for acoustic spatial capture-recapture inference that integrate individual-level measures of confidence from ML vocalisation identification into the likelihood and hence integrate ML uncertainty into inference. The methods include a mixture model in which species identity is a latent variable. We test the methods by simulation and find that in a scenario based on acoustic data from Hainan gibbons, in which ignoring false positives results in 17% positive bias, our methods give negligible bias and coverage probabilities that are close to the nominal 95% level.</p>
<hr>
<h2 id="Sparks-of-Large-Audio-Models-A-Survey-and-Outlook"><a href="#Sparks-of-Large-Audio-Models-A-Survey-and-Outlook" class="headerlink" title="Sparks of Large Audio Models: A Survey and Outlook"></a>Sparks of Large Audio Models: A Survey and Outlook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12792">http://arxiv.org/abs/2308.12792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddique Latif, Moazzam Shoukat, Fahad Shamshad, Muhammad Usama, Heriberto Cuayáhuitl, Björn W. Schuller</li>
</ul>
<p>Abstract:<br>This survey paper provides a comprehensive overview of the recent advancements and challenges in applying large language models to the field of audio signal processing. Audio processing, with its diverse signal representations and a wide range of sources–from human voices to musical instruments and environmental sounds–poses challenges distinct from those found in traditional Natural Language Processing scenarios. Nevertheless, \textit{Large Audio Models}, epitomized by transformer-based architectures, have shown marked efficacy in this sphere. By leveraging massive amount of data, these models have demonstrated prowess in a variety of audio tasks, spanning from Automatic Speech Recognition and Text-To-Speech to Music Generation, among others. Notably, recently these Foundational Audio Models, like SeamlessM4T, have started showing abilities to act as universal translators, supporting multiple speech tasks for up to 100 languages without any reliance on separate task-specific systems. This paper presents an in-depth analysis of state-of-the-art methodologies regarding \textit{Foundational Large Audio Models}, their performance benchmarks, and their applicability to real-world scenarios. We also highlight current limitations and provide insights into potential future research directions in the realm of \textit{Large Audio Models} with the intent to spark further discussion, thereby fostering innovation in the next generation of audio-processing systems. Furthermore, to cope with the rapid development in this area, we will consistently update the relevant repository with relevant recent articles and their open-source implementations at <a target="_blank" rel="noopener" href="https://github.com/EmulationAI/awesome-large-audio-models">https://github.com/EmulationAI/awesome-large-audio-models</a>.</p>
<hr>
<h2 id="WavMark-Watermarking-for-Audio-Generation"><a href="#WavMark-Watermarking-for-Audio-Generation" class="headerlink" title="WavMark: Watermarking for Audio Generation"></a>WavMark: Watermarking for Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12770">http://arxiv.org/abs/2308.12770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, Furu Wei</li>
</ul>
<p>Abstract:<br>Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker’s voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achieve heightened robustness and expanded capacity. Utilizing 10 to 20-second audio as the host, our approach demonstrates an average Bit Error Rate (BER) of 0.48% across ten common attacks, a remarkable reduction of over 2800% in BER compared to the state-of-the-art watermarking tool. See <a target="_blank" rel="noopener" href="https://aka.ms/wavmark">https://aka.ms/wavmark</a> for demos of our work.</p>
<hr>
<h2 id="Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion"><a href="#Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion" class="headerlink" title="Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion"></a>Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12734">http://arxiv.org/abs/2308.12734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan J. Bird, Ahmad Lotfi</li>
</ul>
<p>Abstract:<br>There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learning models over 10-fold cross validation, it is found that the Extreme Gradient Boosting model can achieve an average classification accuracy of 99.3% and can classify speech in real-time, at around 0.004 milliseconds given one second of speech. All data generated for this study is released publicly for future research on AI speech detection.</p>
<hr>
<h2 id="Whombat-An-open-source-annotation-tool-for-machine-learning-development-in-bioacoustics"><a href="#Whombat-An-open-source-annotation-tool-for-machine-learning-development-in-bioacoustics" class="headerlink" title="Whombat: An open-source annotation tool for machine learning development in bioacoustics"></a>Whombat: An open-source annotation tool for machine learning development in bioacoustics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12688">http://arxiv.org/abs/2308.12688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Santiago Martinez Balvanera, Oisin Mac Aodha, Matthew J. Weldy, Holly Pringle, Ella Browning, Kate E. Jones</li>
</ul>
<p>Abstract:</p>
<ol>
<li>Automated analysis of bioacoustic recordings using machine learning (ML) methods has the potential to greatly scale biodiversity monitoring efforts. The use of ML for high-stakes applications, such as conservation research, demands a data-centric approach with a focus on utilizing carefully annotated and curated evaluation and training data that is relevant and representative. Creating annotated datasets of sound recordings presents a number of challenges, such as managing large collections of recordings with associated metadata, developing flexible annotation tools that can accommodate the diverse range of vocalization profiles of different organisms, and addressing the scarcity of expert annotators.   2. We present Whombat a user-friendly, browser-based interface for managing audio recordings and annotation projects, with several visualization, exploration, and annotation tools. It enables users to quickly annotate, review, and share annotations, as well as visualize and evaluate a set of machine learning predictions on a dataset. The tool facilitates an iterative workflow where user annotations and machine learning predictions feedback to enhance model performance and annotation quality.   3. We demonstrate the flexibility of Whombat by showcasing two distinct use cases: an project aimed at enhancing automated UK bat call identification at the Bat Conservation Trust (BCT), and a collaborative effort among the USDA Forest Service and Oregon State University researchers exploring bioacoustic applications and extending automated avian classification models in the Pacific Northwest, USA.   4. Whombat is a flexible tool that can effectively address the challenges of annotation for bioacoustic research. It can be used for individual and collaborative work, hosted on a shared server or accessed remotely, or run on a personal computer without the need for coding skills.</li>
</ol>
<hr>
<h2 id="Naaloss-Rethinking-the-objective-of-speech-enhancement"><a href="#Naaloss-Rethinking-the-objective-of-speech-enhancement" class="headerlink" title="Naaloss: Rethinking the objective of speech enhancement"></a>Naaloss: Rethinking the objective of speech enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12615">http://arxiv.org/abs/2308.12615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuan-Hsun Ho, En-Lun Yu, Jeih-weih Hung, Berlin Chen</li>
</ul>
<p>Abstract:<br>Reducing noise interference is crucial for automatic speech recognition (ASR) in a real-world scenario. However, most single-channel speech enhancement (SE) generates “processing artifacts” that negatively affect ASR performance. Hence, in this study, we suggest a Noise- and Artifacts-aware loss function, NAaLoss, to ameliorate the influence of artifacts from a novel perspective. NAaLoss considers the loss of estimation, de-artifact, and noise ignorance, enabling the learned SE to individually model speech, artifacts, and noise. We examine two SE models (simple&#x2F;advanced) learned with NAaLoss under various input scenarios (clean&#x2F;noisy) using two configurations of the ASR system (with&#x2F;without noise robustness). Experiments reveal that NAaLoss significantly improves the ASR performance of most setups while preserving the quality of SE toward perception and intelligibility. Furthermore, we visualize artifacts through waveforms and spectrograms, and explain their impact on ASR.</p>
<hr>
<h2 id="Emotion-Aligned-Contrastive-Learning-Between-Images-and-Music"><a href="#Emotion-Aligned-Contrastive-Learning-Between-Images-and-Music" class="headerlink" title="Emotion-Aligned Contrastive Learning Between Images and Music"></a>Emotion-Aligned Contrastive Learning Between Images and Music</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12610">http://arxiv.org/abs/2308.12610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanti Stewart, Tiantian Feng, Kleanthis Avramidis, Shrikanth Narayanan</li>
</ul>
<p>Abstract:<br>Traditional music search engines rely on retrieval methods that match natural language queries with music metadata. There have been increasing efforts to expand retrieval methods to consider the audio characteristics of music itself, using queries of various modalities including text, video, and speech. Most approaches aim to match general music semantics to the input queries, while only a few focus on affective qualities. We address the task of retrieving emotionally-relevant music from image queries by proposing a framework for learning an affective alignment between images and music audio. Our approach focuses on learning an emotion-aligned joint embedding space between images and music. This joint embedding space is learned via emotion-supervised contrastive learning, using an adapted cross-modal version of the SupCon loss. We directly evaluate the joint embeddings with cross-modal retrieval tasks (image-to-music and music-to-image) based on emotion labels. In addition, we investigate the generalizability of the learned music embeddings with automatic music tagging as a downstream task. Our experiments show that our approach successfully aligns images and music, and that the learned embedding space is effective for cross-modal retrieval applications.</p>
<hr>
<h2 id="Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement"><a href="#Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement" class="headerlink" title="Exploiting Time-Frequency Conformers for Music Audio Enhancement"></a>Exploiting Time-Frequency Conformers for Music Audio Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12599">http://arxiv.org/abs/2308.12599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkee Chae, Junghyun Koo, Sungho Lee, Kyogu Lee</li>
</ul>
<p>Abstract:<br>With the proliferation of video platforms on the internet, recording musical performances by mobile devices has become commonplace. However, these recordings often suffer from degradation such as noise and reverberation, which negatively impact the listening experience. Consequently, the necessity for music audio enhancement (referred to as music enhancement from this point onward), involving the transformation of degraded audio recordings into pristine high-quality music, has surged to augment the auditory experience. To address this issue, we propose a music enhancement system based on the Conformer architecture that has demonstrated outstanding performance in speech enhancement tasks. Our approach explores the attention mechanisms of the Conformer and examines their performance to discover the best approach for the music enhancement task. Our experimental results show that our proposed model achieves state-of-the-art performance on single-stem music enhancement. Furthermore, our system can perform general music enhancement with multi-track mixtures, which has not been examined in previous work.</p>
<hr>
<h2 id="Hybrid-noise-shaping-for-audio-coding-using-perfectly-overlapped-window"><a href="#Hybrid-noise-shaping-for-audio-coding-using-perfectly-overlapped-window" class="headerlink" title="Hybrid noise shaping for audio coding using perfectly overlapped window"></a>Hybrid noise shaping for audio coding using perfectly overlapped window</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12566">http://arxiv.org/abs/2308.12566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeongho Jo, Seungkwon Beack</li>
</ul>
<p>Abstract:<br>In recent years, audio coding technology has been standardized based on several frameworks that incorporate linear predictive coding (LPC). However, coding the transient signal using frequency-domain LP residual signals remains a challenge. To address this, temporal noise shaping (TNS) can be adapted, although it cannot be effectively operated since the estimated temporal envelope in the modified discrete cosine transform (MDCT) domain is accompanied by the time-domain aliasing (TDA) terms. In this study, we propose the modulated complex lapped transform-based coding framework integrated with transform coded excitation (TCX) and complex LPC-based TNS (CTNS). Our approach uses a 50% overlap window and switching scheme for the CTNS to improve the coding efficiency. Additionally, an adaptive calculation of the target bits for the sub-bands using the frequency envelope information based on the quantized LPC coefficients is proposed. To minimize the quantization mismatch between both modes, an integrated quantization for real and complex values and a TDA augmentation method that compensates for the artificially generated TDA components during switching operations are proposed. The proposed coding framework shows a superior performance in both objective metrics and subjective listening tests, thereby demonstrating its low bit-rate audio coding.</p>
<hr>
<h2 id="UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023"></a>UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12526">http://arxiv.org/abs/2308.12526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Zheng, Yajun Zhang, Chuanying Niu, Yibin Zhan, Yanhua Long, Dongxing Xu</li>
</ul>
<p>Abstract:<br>This report describes the UNISOUND submission for Track1 and Track2 of VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same system on Track 1 and Track 2, which is trained with only VoxCeleb2-dev. Large-scale ResNet and RepVGG architectures are developed for the challenge. We propose a consistency-aware score calibration method, which leverages the stability of audio voiceprints in similarity score by a Consistency Measure Factor (CMF). CMF brings a huge performance boost in this challenge. Our final system is a fusion of six models and achieves the first place in Track 1 and second place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855 and the EER is 1.5880%.</p>
<hr>
<h2 id="MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario"><a href="#MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario" class="headerlink" title="MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario"></a>MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12490">http://arxiv.org/abs/2308.12490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wen Chen, Zhou Yu, Julia Hirschberg</li>
</ul>
<p>Abstract:<br>The design of automatic speech pronunciation assessment can be categorized into closed and open response scenarios, each with strengths and limitations. A system with the ability to function in both scenarios can cater to diverse learning needs and provide a more precise and holistic assessment of pronunciation skills. In this study, we propose a Multi-task Pronunciation Assessment model called MultiPA. MultiPA provides an alternative to Kaldi-based systems in that it has simpler format requirements and better compatibility with other neural network models. Compared with previous open response systems, MultiPA provides a wider range of evaluations, encompassing assessments at both the sentence and word-level. Our experimental results show that MultiPA achieves comparable performance when working in closed response scenarios and maintains more robust performance when directly used for open responses.</p>
<hr>
<h2 id="Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection"><a href="#Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection" class="headerlink" title="Attention-Based Acoustic Feature Fusion Network for Depression Detection"></a>Attention-Based Acoustic Feature Fusion Network for Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12478">http://arxiv.org/abs/2308.12478</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuxiaoooo/abafnet">https://github.com/xuxiaoooo/abafnet</a></li>
<li>paper_authors: Xiao Xu, Yang Wang, Xinru Wei, Fei Wang, Xizhe Zhang</li>
</ul>
<p>Abstract:<br>Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech characteristics. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep learning model, thereby effectively integrating and blending multi-tiered features. We present a novel weight adjustment module for late fusion that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two clinical speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCCrelated features in speech-based depression detection.</p>
<hr>
<h2 id="An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video"><a href="#An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video" class="headerlink" title="An Initial Exploration: Learning to Generate Realistic Audio for Silent Video"></a>An Initial Exploration: Learning to Generate Realistic Audio for Silent Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12408">http://arxiv.org/abs/2308.12408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Martel, Jackson Wagner</li>
</ul>
<p>Abstract:<br>Generating realistic audio effects for movies and other media is a challenging task that is accomplished today primarily through physical techniques known as Foley art. Foley artists create sounds with common objects (e.g., boxing gloves, broken glass) in time with video as it is playing to generate captivating audio tracks. In this work, we aim to develop a deep-learning based framework that does much the same - observes video in it’s natural sequence and generates realistic audio to accompany it. Notably, we have reason to believe this is achievable due to advancements in realistic audio generation techniques conditioned on other inputs (e.g., Wavenet conditioned on text). We explore several different model architectures to accomplish this task that process both previously-generated audio and video context. These include deep-fusion CNN, dilated Wavenet CNN with visual context, and transformer-based architectures. We find that the transformer-based architecture yields the most promising results, matching low-frequencies to visual patterns effectively, but failing to generate more nuanced waveforms.</p>
<hr>
<h2 id="AdVerb-Visually-Guided-Audio-Dereverberation"><a href="#AdVerb-Visually-Guided-Audio-Dereverberation" class="headerlink" title="AdVerb: Visually Guided Audio Dereverberation"></a>AdVerb: Visually Guided Audio Dereverberation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12370">http://arxiv.org/abs/2308.12370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjoy Chowdhury, Sreyan Ghosh, Subhrajyoti Dasgupta, Anton Ratnarajah, Utkarsh Tyagi, Dinesh Manocha</li>
</ul>
<p>Abstract:<br>We present AdVerb, a novel audio-visual dereverberation framework that uses visual cues in addition to the reverberant sound to estimate clean audio. Although audio-only dereverberation is a well-studied problem, our approach incorporates the complementary visual modality to perform audio dereverberation. Given an image of the environment where the reverberated sound signal has been recorded, AdVerb employs a novel geometry-aware cross-modal transformer architecture that captures scene geometry and audio-visual cross-modal relationship to generate a complex ideal ratio mask, which, when applied to the reverberant audio predicts the clean sound. The effectiveness of our method is demonstrated through extensive quantitative and qualitative evaluations. Our approach significantly outperforms traditional audio-only and audio-visual baselines on three downstream tasks: speech enhancement, speech recognition, and speaker verification, with relative improvements in the range of 18% - 82% on the LibriSpeech test-clean set. We also achieve highly satisfactory RT60 error scores on the AVSpeech dataset.</p>
<hr>
<h2 id="LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition"><a href="#LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition" class="headerlink" title="LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition"></a>LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12882">http://arxiv.org/abs/2308.12882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti</li>
</ul>
<p>Abstract:<br>Audio classification aims at recognizing audio signals, including speech commands or sound events. However, current audio classifiers are susceptible to perturbations and adversarial attacks. In addition, real-world audio classification tasks often suffer from limited labeled data. To help bridge these gaps, previous work developed neuro-inspired convolutional neural networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA) in the first layer (i.e., LCANets) for computer vision. LCANets learn in a combination of supervised and unsupervised learning, reducing dependency on labeled samples. Motivated by the fact that auditory cortex is also sparse, we extend LCANets to audio recognition tasks and introduce LCANets++, which are CNNs that perform sparse coding in multiple layers via LCA. We demonstrate that LCANets++ are more robust than standard CNNs and LCANets against perturbations, e.g., background noise, as well as black-box and white-box attacks, e.g., evasion and fast gradient sign (FGSM) attacks.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.SD_2023_08_24/" data-id="cllqfouaj0012a488aq5n90tn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/eess.AS_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/eess.AS_2023_08_24/">eess.AS - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture"><a href="#Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture" class="headerlink" title="Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture"></a>Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12859">http://arxiv.org/abs/2308.12859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Wang, Juan Ye, David L. Borchers</li>
</ul>
<p>Abstract:<br>Passive acoustic monitoring can be an effective way of monitoring wildlife populations that are acoustically active but difficult to survey visually. Digital recorders allow surveyors to gather large volumes of data at low cost, but identifying target species vocalisations in these data is non-trivial. Machine learning (ML) methods are often used to do the identification. They can process large volumes of data quickly, but they do not detect all vocalisations and they do generate some false positives (vocalisations that are not from the target species). Existing wildlife abundance survey methods have been designed specifically to deal with the first of these mistakes, but current methods of dealing with false positives are not well-developed. They do not take account of features of individual vocalisations, some of which are more likely to be false positives than others. We propose three methods for acoustic spatial capture-recapture inference that integrate individual-level measures of confidence from ML vocalisation identification into the likelihood and hence integrate ML uncertainty into inference. The methods include a mixture model in which species identity is a latent variable. We test the methods by simulation and find that in a scenario based on acoustic data from Hainan gibbons, in which ignoring false positives results in 17% positive bias, our methods give negligible bias and coverage probabilities that are close to the nominal 95% level.</p>
<hr>
<h2 id="Sparks-of-Large-Audio-Models-A-Survey-and-Outlook"><a href="#Sparks-of-Large-Audio-Models-A-Survey-and-Outlook" class="headerlink" title="Sparks of Large Audio Models: A Survey and Outlook"></a>Sparks of Large Audio Models: A Survey and Outlook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12792">http://arxiv.org/abs/2308.12792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddique Latif, Moazzam Shoukat, Fahad Shamshad, Muhammad Usama, Heriberto Cuayáhuitl, Björn W. Schuller</li>
</ul>
<p>Abstract:<br>This survey paper provides a comprehensive overview of the recent advancements and challenges in applying large language models to the field of audio signal processing. Audio processing, with its diverse signal representations and a wide range of sources–from human voices to musical instruments and environmental sounds–poses challenges distinct from those found in traditional Natural Language Processing scenarios. Nevertheless, \textit{Large Audio Models}, epitomized by transformer-based architectures, have shown marked efficacy in this sphere. By leveraging massive amount of data, these models have demonstrated prowess in a variety of audio tasks, spanning from Automatic Speech Recognition and Text-To-Speech to Music Generation, among others. Notably, recently these Foundational Audio Models, like SeamlessM4T, have started showing abilities to act as universal translators, supporting multiple speech tasks for up to 100 languages without any reliance on separate task-specific systems. This paper presents an in-depth analysis of state-of-the-art methodologies regarding \textit{Foundational Large Audio Models}, their performance benchmarks, and their applicability to real-world scenarios. We also highlight current limitations and provide insights into potential future research directions in the realm of \textit{Large Audio Models} with the intent to spark further discussion, thereby fostering innovation in the next generation of audio-processing systems. Furthermore, to cope with the rapid development in this area, we will consistently update the relevant repository with relevant recent articles and their open-source implementations at <a target="_blank" rel="noopener" href="https://github.com/EmulationAI/awesome-large-audio-models">https://github.com/EmulationAI/awesome-large-audio-models</a>.</p>
<hr>
<h2 id="WavMark-Watermarking-for-Audio-Generation"><a href="#WavMark-Watermarking-for-Audio-Generation" class="headerlink" title="WavMark: Watermarking for Audio Generation"></a>WavMark: Watermarking for Audio Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12770">http://arxiv.org/abs/2308.12770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyu Chen, Yu Wu, Shujie Liu, Tao Liu, Xiaoyong Du, Furu Wei</li>
</ul>
<p>Abstract:<br>Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker’s voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achieve heightened robustness and expanded capacity. Utilizing 10 to 20-second audio as the host, our approach demonstrates an average Bit Error Rate (BER) of 0.48% across ten common attacks, a remarkable reduction of over 2800% in BER compared to the state-of-the-art watermarking tool. See <a target="_blank" rel="noopener" href="https://aka.ms/wavmark">https://aka.ms/wavmark</a> for demos of our work.</p>
<hr>
<h2 id="Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion"><a href="#Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion" class="headerlink" title="Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion"></a>Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12734">http://arxiv.org/abs/2308.12734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan J. Bird, Ahmad Lotfi</li>
</ul>
<p>Abstract:<br>There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learning models over 10-fold cross validation, it is found that the Extreme Gradient Boosting model can achieve an average classification accuracy of 99.3% and can classify speech in real-time, at around 0.004 milliseconds given one second of speech. All data generated for this study is released publicly for future research on AI speech detection.</p>
<hr>
<h2 id="Whombat-An-open-source-annotation-tool-for-machine-learning-development-in-bioacoustics"><a href="#Whombat-An-open-source-annotation-tool-for-machine-learning-development-in-bioacoustics" class="headerlink" title="Whombat: An open-source annotation tool for machine learning development in bioacoustics"></a>Whombat: An open-source annotation tool for machine learning development in bioacoustics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12688">http://arxiv.org/abs/2308.12688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Santiago Martinez Balvanera, Oisin Mac Aodha, Matthew J. Weldy, Holly Pringle, Ella Browning, Kate E. Jones</li>
</ul>
<p>Abstract:</p>
<ol>
<li>Automated analysis of bioacoustic recordings using machine learning (ML) methods has the potential to greatly scale biodiversity monitoring efforts. The use of ML for high-stakes applications, such as conservation research, demands a data-centric approach with a focus on utilizing carefully annotated and curated evaluation and training data that is relevant and representative. Creating annotated datasets of sound recordings presents a number of challenges, such as managing large collections of recordings with associated metadata, developing flexible annotation tools that can accommodate the diverse range of vocalization profiles of different organisms, and addressing the scarcity of expert annotators.   2. We present Whombat a user-friendly, browser-based interface for managing audio recordings and annotation projects, with several visualization, exploration, and annotation tools. It enables users to quickly annotate, review, and share annotations, as well as visualize and evaluate a set of machine learning predictions on a dataset. The tool facilitates an iterative workflow where user annotations and machine learning predictions feedback to enhance model performance and annotation quality.   3. We demonstrate the flexibility of Whombat by showcasing two distinct use cases: an project aimed at enhancing automated UK bat call identification at the Bat Conservation Trust (BCT), and a collaborative effort among the USDA Forest Service and Oregon State University researchers exploring bioacoustic applications and extending automated avian classification models in the Pacific Northwest, USA.   4. Whombat is a flexible tool that can effectively address the challenges of annotation for bioacoustic research. It can be used for individual and collaborative work, hosted on a shared server or accessed remotely, or run on a personal computer without the need for coding skills.</li>
</ol>
<hr>
<h2 id="Naaloss-Rethinking-the-objective-of-speech-enhancement"><a href="#Naaloss-Rethinking-the-objective-of-speech-enhancement" class="headerlink" title="Naaloss: Rethinking the objective of speech enhancement"></a>Naaloss: Rethinking the objective of speech enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12615">http://arxiv.org/abs/2308.12615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kuan-Hsun Ho, En-Lun Yu, Jeih-weih Hung, Berlin Chen</li>
</ul>
<p>Abstract:<br>Reducing noise interference is crucial for automatic speech recognition (ASR) in a real-world scenario. However, most single-channel speech enhancement (SE) generates “processing artifacts” that negatively affect ASR performance. Hence, in this study, we suggest a Noise- and Artifacts-aware loss function, NAaLoss, to ameliorate the influence of artifacts from a novel perspective. NAaLoss considers the loss of estimation, de-artifact, and noise ignorance, enabling the learned SE to individually model speech, artifacts, and noise. We examine two SE models (simple&#x2F;advanced) learned with NAaLoss under various input scenarios (clean&#x2F;noisy) using two configurations of the ASR system (with&#x2F;without noise robustness). Experiments reveal that NAaLoss significantly improves the ASR performance of most setups while preserving the quality of SE toward perception and intelligibility. Furthermore, we visualize artifacts through waveforms and spectrograms, and explain their impact on ASR.</p>
<hr>
<h2 id="Emotion-Aligned-Contrastive-Learning-Between-Images-and-Music"><a href="#Emotion-Aligned-Contrastive-Learning-Between-Images-and-Music" class="headerlink" title="Emotion-Aligned Contrastive Learning Between Images and Music"></a>Emotion-Aligned Contrastive Learning Between Images and Music</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12610">http://arxiv.org/abs/2308.12610</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanti Stewart, Tiantian Feng, Kleanthis Avramidis, Shrikanth Narayanan</li>
</ul>
<p>Abstract:<br>Traditional music search engines rely on retrieval methods that match natural language queries with music metadata. There have been increasing efforts to expand retrieval methods to consider the audio characteristics of music itself, using queries of various modalities including text, video, and speech. Most approaches aim to match general music semantics to the input queries, while only a few focus on affective qualities. We address the task of retrieving emotionally-relevant music from image queries by proposing a framework for learning an affective alignment between images and music audio. Our approach focuses on learning an emotion-aligned joint embedding space between images and music. This joint embedding space is learned via emotion-supervised contrastive learning, using an adapted cross-modal version of the SupCon loss. We directly evaluate the joint embeddings with cross-modal retrieval tasks (image-to-music and music-to-image) based on emotion labels. In addition, we investigate the generalizability of the learned music embeddings with automatic music tagging as a downstream task. Our experiments show that our approach successfully aligns images and music, and that the learned embedding space is effective for cross-modal retrieval applications.</p>
<hr>
<h2 id="Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement"><a href="#Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement" class="headerlink" title="Exploiting Time-Frequency Conformers for Music Audio Enhancement"></a>Exploiting Time-Frequency Conformers for Music Audio Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12599">http://arxiv.org/abs/2308.12599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkee Chae, Junghyun Koo, Sungho Lee, Kyogu Lee</li>
</ul>
<p>Abstract:<br>With the proliferation of video platforms on the internet, recording musical performances by mobile devices has become commonplace. However, these recordings often suffer from degradation such as noise and reverberation, which negatively impact the listening experience. Consequently, the necessity for music audio enhancement (referred to as music enhancement from this point onward), involving the transformation of degraded audio recordings into pristine high-quality music, has surged to augment the auditory experience. To address this issue, we propose a music enhancement system based on the Conformer architecture that has demonstrated outstanding performance in speech enhancement tasks. Our approach explores the attention mechanisms of the Conformer and examines their performance to discover the best approach for the music enhancement task. Our experimental results show that our proposed model achieves state-of-the-art performance on single-stem music enhancement. Furthermore, our system can perform general music enhancement with multi-track mixtures, which has not been examined in previous work.</p>
<hr>
<h2 id="Hybrid-noise-shaping-for-audio-coding-using-perfectly-overlapped-window"><a href="#Hybrid-noise-shaping-for-audio-coding-using-perfectly-overlapped-window" class="headerlink" title="Hybrid noise shaping for audio coding using perfectly overlapped window"></a>Hybrid noise shaping for audio coding using perfectly overlapped window</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12566">http://arxiv.org/abs/2308.12566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeongho Jo, Seungkwon Beack</li>
</ul>
<p>Abstract:<br>In recent years, audio coding technology has been standardized based on several frameworks that incorporate linear predictive coding (LPC). However, coding the transient signal using frequency-domain LP residual signals remains a challenge. To address this, temporal noise shaping (TNS) can be adapted, although it cannot be effectively operated since the estimated temporal envelope in the modified discrete cosine transform (MDCT) domain is accompanied by the time-domain aliasing (TDA) terms. In this study, we propose the modulated complex lapped transform-based coding framework integrated with transform coded excitation (TCX) and complex LPC-based TNS (CTNS). Our approach uses a 50% overlap window and switching scheme for the CTNS to improve the coding efficiency. Additionally, an adaptive calculation of the target bits for the sub-bands using the frequency envelope information based on the quantized LPC coefficients is proposed. To minimize the quantization mismatch between both modes, an integrated quantization for real and complex values and a TDA augmentation method that compensates for the artificially generated TDA components during switching operations are proposed. The proposed coding framework shows a superior performance in both objective metrics and subjective listening tests, thereby demonstrating its low bit-rate audio coding.</p>
<hr>
<h2 id="UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023"></a>UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12526">http://arxiv.org/abs/2308.12526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Zheng, Yajun Zhang, Chuanying Niu, Yibin Zhan, Yanhua Long, Dongxing Xu</li>
</ul>
<p>Abstract:<br>This report describes the UNISOUND submission for Track1 and Track2 of VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same system on Track 1 and Track 2, which is trained with only VoxCeleb2-dev. Large-scale ResNet and RepVGG architectures are developed for the challenge. We propose a consistency-aware score calibration method, which leverages the stability of audio voiceprints in similarity score by a Consistency Measure Factor (CMF). CMF brings a huge performance boost in this challenge. Our final system is a fusion of six models and achieves the first place in Track 1 and second place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855 and the EER is 1.5880%.</p>
<hr>
<h2 id="MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario"><a href="#MultiPA-a-multi-task-speech-pronunciation-assessment-system-for-a-closed-and-open-response-scenario" class="headerlink" title="MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario"></a>MultiPA: a multi-task speech pronunciation assessment system for a closed and open response scenario</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12490">http://arxiv.org/abs/2308.12490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wen Chen, Zhou Yu, Julia Hirschberg</li>
</ul>
<p>Abstract:<br>The design of automatic speech pronunciation assessment can be categorized into closed and open response scenarios, each with strengths and limitations. A system with the ability to function in both scenarios can cater to diverse learning needs and provide a more precise and holistic assessment of pronunciation skills. In this study, we propose a Multi-task Pronunciation Assessment model called MultiPA. MultiPA provides an alternative to Kaldi-based systems in that it has simpler format requirements and better compatibility with other neural network models. Compared with previous open response systems, MultiPA provides a wider range of evaluations, encompassing assessments at both the sentence and word-level. Our experimental results show that MultiPA achieves comparable performance when working in closed response scenarios and maintains more robust performance when directly used for open responses.</p>
<hr>
<h2 id="Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection"><a href="#Attention-Based-Acoustic-Feature-Fusion-Network-for-Depression-Detection" class="headerlink" title="Attention-Based Acoustic Feature Fusion Network for Depression Detection"></a>Attention-Based Acoustic Feature Fusion Network for Depression Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12478">http://arxiv.org/abs/2308.12478</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuxiaoooo/abafnet">https://github.com/xuxiaoooo/abafnet</a></li>
<li>paper_authors: Xiao Xu, Yang Wang, Xinru Wei, Fei Wang, Xizhe Zhang</li>
</ul>
<p>Abstract:<br>Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech characteristics. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep learning model, thereby effectively integrating and blending multi-tiered features. We present a novel weight adjustment module for late fusion that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two clinical speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCCrelated features in speech-based depression detection.</p>
<hr>
<h2 id="An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video"><a href="#An-Initial-Exploration-Learning-to-Generate-Realistic-Audio-for-Silent-Video" class="headerlink" title="An Initial Exploration: Learning to Generate Realistic Audio for Silent Video"></a>An Initial Exploration: Learning to Generate Realistic Audio for Silent Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12408">http://arxiv.org/abs/2308.12408</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Martel, Jackson Wagner</li>
</ul>
<p>Abstract:<br>Generating realistic audio effects for movies and other media is a challenging task that is accomplished today primarily through physical techniques known as Foley art. Foley artists create sounds with common objects (e.g., boxing gloves, broken glass) in time with video as it is playing to generate captivating audio tracks. In this work, we aim to develop a deep-learning based framework that does much the same - observes video in it’s natural sequence and generates realistic audio to accompany it. Notably, we have reason to believe this is achievable due to advancements in realistic audio generation techniques conditioned on other inputs (e.g., Wavenet conditioned on text). We explore several different model architectures to accomplish this task that process both previously-generated audio and video context. These include deep-fusion CNN, dilated Wavenet CNN with visual context, and transformer-based architectures. We find that the transformer-based architecture yields the most promising results, matching low-frequencies to visual patterns effectively, but failing to generate more nuanced waveforms.</p>
<hr>
<h2 id="AdVerb-Visually-Guided-Audio-Dereverberation"><a href="#AdVerb-Visually-Guided-Audio-Dereverberation" class="headerlink" title="AdVerb: Visually Guided Audio Dereverberation"></a>AdVerb: Visually Guided Audio Dereverberation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12370">http://arxiv.org/abs/2308.12370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjoy Chowdhury, Sreyan Ghosh, Subhrajyoti Dasgupta, Anton Ratnarajah, Utkarsh Tyagi, Dinesh Manocha</li>
</ul>
<p>Abstract:<br>We present AdVerb, a novel audio-visual dereverberation framework that uses visual cues in addition to the reverberant sound to estimate clean audio. Although audio-only dereverberation is a well-studied problem, our approach incorporates the complementary visual modality to perform audio dereverberation. Given an image of the environment where the reverberated sound signal has been recorded, AdVerb employs a novel geometry-aware cross-modal transformer architecture that captures scene geometry and audio-visual cross-modal relationship to generate a complex ideal ratio mask, which, when applied to the reverberant audio predicts the clean sound. The effectiveness of our method is demonstrated through extensive quantitative and qualitative evaluations. Our approach significantly outperforms traditional audio-only and audio-visual baselines on three downstream tasks: speech enhancement, speech recognition, and speaker verification, with relative improvements in the range of 18% - 82% on the LibriSpeech test-clean set. We also achieve highly satisfactory RT60 error scores on the AVSpeech dataset.</p>
<hr>
<h2 id="LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition"><a href="#LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition" class="headerlink" title="LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition"></a>LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12882">http://arxiv.org/abs/2308.12882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti</li>
</ul>
<p>Abstract:<br>Audio classification aims at recognizing audio signals, including speech commands or sound events. However, current audio classifiers are susceptible to perturbations and adversarial attacks. In addition, real-world audio classification tasks often suffer from limited labeled data. To help bridge these gaps, previous work developed neuro-inspired convolutional neural networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA) in the first layer (i.e., LCANets) for computer vision. LCANets learn in a combination of supervised and unsupervised learning, reducing dependency on labeled samples. Motivated by the fact that auditory cortex is also sparse, we extend LCANets to audio recognition tasks and introduce LCANets++, which are CNNs that perform sparse coding in multiple layers via LCA. We demonstrate that LCANets++ are more robust than standard CNNs and LCANets against perturbations, e.g., background noise, as well as black-box and white-box attacks, e.g., evasion and fast gradient sign (FGSM) attacks.</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/eess.AS_2023_08_24/" data-id="cllqfouak0015a4885mjr4vrn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_24" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/24/cs.LG_2023_08_24/" class="article-date">
  <time datetime="2023-08-23T16:00:00.000Z" itemprop="datePublished">2023-08-24</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/24/cs.LG_2023_08_24/">cs.LG - 2023-08-24</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Easy-attention-A-simple-self-attention-mechanism-for-Transformers"><a href="#Easy-attention-A-simple-self-attention-mechanism-for-Transformers" class="headerlink" title="Easy attention: A simple self-attention mechanism for Transformers"></a>Easy attention: A simple self-attention mechanism for Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12874">http://arxiv.org/abs/2308.12874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcial Sanchis-Agudo, Yuning Wang, Karthik Duraisamy, Ricardo Vinuesa</li>
</ul>
<p>Abstract:<br>To improve the robustness of transformer neural networks used for temporal-dynamics prediction of chaotic systems, we propose a novel attention mechanism called easy attention. Due to the fact that self attention only makes usage of the inner product of queries and keys, it is demonstrated that the keys, queries and softmax are not necessary for obtaining the attention score required to capture long-term dependencies in temporal sequences. Through implementing singular-value decomposition (SVD) on the softmax attention score, we further observe that the self attention compresses contribution from both queries and keys in the spanned space of the attention score. Therefore, our proposed easy-attention method directly treats the attention scores as learnable parameters. This approach produces excellent results when reconstructing and predicting the temporal dynamics of chaotic systems exhibiting more robustness and less complexity than the self attention or the widely-used long short-term memory (LSTM) network. Our results show great potential for applications in more complex high-dimensional dynamical systems.</p>
<hr>
<h2 id="IPA-Inference-Pipeline-Adaptation-to-Achieve-High-Accuracy-and-Cost-Efficiency"><a href="#IPA-Inference-Pipeline-Adaptation-to-Achieve-High-Accuracy-and-Cost-Efficiency" class="headerlink" title="IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency"></a>IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12871">http://arxiv.org/abs/2308.12871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeid Ghafouri, Kamran Razavi, Mehran Salmani, Alireza Sanaee, Tania Lorido-Botran, Lin Wang, Joseph Doyle, Pooyan Jamshidi</li>
</ul>
<p>Abstract:<br>Efficiently optimizing multi-model inference pipelines for fast, accurate, and cost-effective inference is a crucial challenge in ML production systems, given their tight end-to-end latency requirements. To simplify the exploration of the vast and intricate trade-off space of accuracy and cost in inference pipelines, providers frequently opt to consider one of them. However, the challenge lies in reconciling accuracy and cost trade-offs. To address this challenge and propose a solution to efficiently manage model variants in inference pipelines, we present IPA, an online deep-learning Inference Pipeline Adaptation system that efficiently leverages model variants for each deep learning task. Model variants are different versions of pre-trained models for the same deep learning task with variations in resource requirements, latency, and accuracy. IPA dynamically configures batch size, replication, and model variants to optimize accuracy, minimize costs, and meet user-defined latency SLAs using Integer Programming. It supports multi-objective settings for achieving different trade-offs between accuracy and cost objectives while remaining adaptable to varying workloads and dynamic traffic patterns. Extensive experiments on a Kubernetes implementation with five real-world inference pipelines demonstrate that IPA improves normalized accuracy by up to 35% with a minimal cost increase of less than 5%.</p>
<hr>
<h2 id="Auto-weighted-Bayesian-Physics-Informed-Neural-Networks-and-robust-estimations-for-multitask-inverse-problems-in-pore-scale-imaging-of-dissolution"><a href="#Auto-weighted-Bayesian-Physics-Informed-Neural-Networks-and-robust-estimations-for-multitask-inverse-problems-in-pore-scale-imaging-of-dissolution" class="headerlink" title="Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution"></a>Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12864">http://arxiv.org/abs/2308.12864</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarah Perez, Philippe Poncet</li>
</ul>
<p>Abstract:<br>In this article, we present a novel data assimilation strategy in pore-scale imaging and demonstrate that this makes it possible to robustly address reactive inverse problems incorporating Uncertainty Quantification (UQ). Pore-scale modeling of reactive flow offers a valuable opportunity to investigate the evolution of macro-scale properties subject to dynamic processes. Yet, they suffer from imaging limitations arising from the associated X-ray microtomography (X-ray microCT) process, which induces discrepancies in the properties estimates. Assessment of the kinetic parameters also raises challenges, as reactive coefficients are critical parameters that can cover a wide range of values. We account for these two issues and ensure reliable calibration of pore-scale modeling, based on dynamical microCT images, by integrating uncertainty quantification in the workflow.   The present method is based on a multitasking formulation of reactive inverse problems combining data-driven and physics-informed techniques in calcite dissolution. This allows quantifying morphological uncertainties on the porosity field and estimating reactive parameter ranges through prescribed PDE models with a latent concentration field and dynamical microCT. The data assimilation strategy relies on sequential reinforcement incorporating successively additional PDE constraints. We guarantee robust and unbiased uncertainty quantification by straightforward adaptive weighting of Bayesian Physics-Informed Neural Networks (BPINNs), ensuring reliable micro-porosity changes during geochemical transformations. We demonstrate successful Bayesian Inference in 1D+Time and 2D+Time calcite dissolution based on synthetic microCT images with meaningful posterior distribution on the reactive parameters and dimensionless numbers.</p>
<hr>
<h2 id="Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture"><a href="#Towards-Automated-Animal-Density-Estimation-with-Acoustic-Spatial-Capture-Recapture" class="headerlink" title="Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture"></a>Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12859">http://arxiv.org/abs/2308.12859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Wang, Juan Ye, David L. Borchers</li>
</ul>
<p>Abstract:<br>Passive acoustic monitoring can be an effective way of monitoring wildlife populations that are acoustically active but difficult to survey visually. Digital recorders allow surveyors to gather large volumes of data at low cost, but identifying target species vocalisations in these data is non-trivial. Machine learning (ML) methods are often used to do the identification. They can process large volumes of data quickly, but they do not detect all vocalisations and they do generate some false positives (vocalisations that are not from the target species). Existing wildlife abundance survey methods have been designed specifically to deal with the first of these mistakes, but current methods of dealing with false positives are not well-developed. They do not take account of features of individual vocalisations, some of which are more likely to be false positives than others. We propose three methods for acoustic spatial capture-recapture inference that integrate individual-level measures of confidence from ML vocalisation identification into the likelihood and hence integrate ML uncertainty into inference. The methods include a mixture model in which species identity is a latent variable. We test the methods by simulation and find that in a scenario based on acoustic data from Hainan gibbons, in which ignoring false positives results in 17% positive bias, our methods give negligible bias and coverage probabilities that are close to the nominal 95% level.</p>
<hr>
<h2 id="Fast-Adversarial-Training-with-Smooth-Convergence"><a href="#Fast-Adversarial-Training-with-Smooth-Convergence" class="headerlink" title="Fast Adversarial Training with Smooth Convergence"></a>Fast Adversarial Training with Smooth Convergence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12857">http://arxiv.org/abs/2308.12857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fat-cs/convergesmooth">https://github.com/fat-cs/convergesmooth</a></li>
<li>paper_authors: Mengnan Zhao, Lihe Zhang, Yuqiu Kong, Baocai Yin</li>
</ul>
<p>Abstract:<br>Fast adversarial training (FAT) is beneficial for improving the adversarial robustness of neural networks. However, previous FAT work has encountered a significant issue known as catastrophic overfitting when dealing with large perturbation budgets, \ie the adversarial robustness of models declines to near zero during training.   To address this, we analyze the training process of prior FAT work and observe that catastrophic overfitting is accompanied by the appearance of loss convergence outliers.   Therefore, we argue a moderately smooth loss convergence process will be a stable FAT process that solves catastrophic overfitting.   To obtain a smooth loss convergence process, we propose a novel oscillatory constraint (dubbed ConvergeSmooth) to limit the loss difference between adjacent epochs. The convergence stride of ConvergeSmooth is introduced to balance convergence and smoothing. Likewise, we design weight centralization without introducing additional hyperparameters other than the loss balance coefficient.   Our proposed methods are attack-agnostic and thus can improve the training stability of various FAT techniques.   Extensive experiments on popular datasets show that the proposed methods efficiently avoid catastrophic overfitting and outperform all previous FAT methods. Code is available at \url{<a target="_blank" rel="noopener" href="https://github.com/FAT-CS/ConvergeSmooth%7D">https://github.com/FAT-CS/ConvergeSmooth}</a>.</p>
<hr>
<h2 id="Probabilistic-load-forecasting-with-Reservoir-Computing"><a href="#Probabilistic-load-forecasting-with-Reservoir-Computing" class="headerlink" title="Probabilistic load forecasting with Reservoir Computing"></a>Probabilistic load forecasting with Reservoir Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12844">http://arxiv.org/abs/2308.12844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michele Guerra, Simone Scardapane, Filippo Maria Bianchi</li>
</ul>
<p>Abstract:<br>Some applications of deep learning require not only to provide accurate results but also to quantify the amount of confidence in their prediction. The management of an electric power grid is one of these cases: to avoid risky scenarios, decision-makers need both precise and reliable forecasts of, for example, power loads. For this reason, point forecasts are not enough hence it is necessary to adopt methods that provide an uncertainty quantification.   This work focuses on reservoir computing as the core time series forecasting method, due to its computational efficiency and effectiveness in predicting time series. While the RC literature mostly focused on point forecasting, this work explores the compatibility of some popular uncertainty quantification methods with the reservoir setting. Both Bayesian and deterministic approaches to uncertainty assessment are evaluated and compared in terms of their prediction accuracy, computational resource efficiency and reliability of the estimated uncertainty, based on a set of carefully chosen performance metrics.</p>
<hr>
<h2 id="Actuator-Trajectory-Planning-for-UAVs-with-Overhead-Manipulator-using-Reinforcement-Learning"><a href="#Actuator-Trajectory-Planning-for-UAVs-with-Overhead-Manipulator-using-Reinforcement-Learning" class="headerlink" title="Actuator Trajectory Planning for UAVs with Overhead Manipulator using Reinforcement Learning"></a>Actuator Trajectory Planning for UAVs with Overhead Manipulator using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12843">http://arxiv.org/abs/2308.12843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hazim Alzorgan, Abolfazl Razi, Ata Jahangir Moshayedi</li>
</ul>
<p>Abstract:<br>In this paper, we investigate the operation of an aerial manipulator system, namely an Unmanned Aerial Vehicle (UAV) equipped with a controllable arm with two degrees of freedom to carry out actuation tasks on the fly. Our solution is based on employing a Q-learning method to control the trajectory of the tip of the arm, also called \textit{end-effector}. More specifically, we develop a motion planning model based on Time To Collision (TTC), which enables a quadrotor UAV to navigate around obstacles while ensuring the manipulator’s reachability. Additionally, we utilize a model-based Q-learning model to independently track and control the desired trajectory of the manipulator’s end-effector, given an arbitrary baseline trajectory for the UAV platform. Such a combination enables a variety of actuation tasks such as high-altitude welding, structural monitoring and repair, battery replacement, gutter cleaning, sky scrapper cleaning, and power line maintenance in hard-to-reach and risky environments while retaining compatibility with flight control firmware. Our RL-based control mechanism results in a robust control strategy that can handle uncertainties in the motion of the UAV, offering promising performance. Specifically, our method achieves 92% accuracy in terms of average displacement error (i.e. the mean distance between the target and obtained trajectory points) using Q-learning with 15,000 episodes</p>
<hr>
<h2 id="Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph"><a href="#Short-Run-Transit-Route-Planning-Decision-Support-System-Using-a-Deep-Learning-Based-Weighted-Graph" class="headerlink" title="Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph"></a>Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12828">http://arxiv.org/abs/2308.12828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nadav Shalit, Michael Fire, Dima Kagan, Eran Ben-Elia</li>
</ul>
<p>Abstract:<br>Public transport routing plays a crucial role in transit network design, ensuring a satisfactory level of service for passengers. However, current routing solutions rely on traditional operational research heuristics, which can be time-consuming to implement and lack the ability to provide quick solutions. Here, we propose a novel deep learning-based methodology for a decision support system that enables public transport (PT) planners to identify short-term route improvements rapidly. By seamlessly adjusting specific sections of routes between two stops during specific times of the day, our method effectively reduces times and enhances PT services. Leveraging diverse data sources such as GTFS and smart card data, we extract features and model the transportation network as a directed graph. Using self-supervision, we train a deep learning model for predicting lateness values for road segments.   These lateness values are then utilized as edge weights in the transportation graph, enabling efficient path searching. Through evaluating the method on Tel Aviv, we are able to reduce times on more than 9% of the routes. The improved routes included both intraurban and suburban routes showcasing a fact highlighting the model’s versatility. The findings emphasize the potential of our data-driven decision support system to enhance public transport and city logistics, promoting greater efficiency and reliability in PT services.</p>
<hr>
<h2 id="Prediction-without-Preclusion-Recourse-Verification-with-Reachable-Sets"><a href="#Prediction-without-Preclusion-Recourse-Verification-with-Reachable-Sets" class="headerlink" title="Prediction without Preclusion: Recourse Verification with Reachable Sets"></a>Prediction without Preclusion: Recourse Verification with Reachable Sets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12820">http://arxiv.org/abs/2308.12820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avni Kothari, Bogdan Kulynych, Tsui-Wei Weng, Berk Ustun</li>
</ul>
<p>Abstract:<br>Machine learning models are often used to decide who will receive a loan, a job interview, or a public benefit. Standard techniques to build these models use features about people but overlook their actionability. In turn, models can assign predictions that are fixed, meaning that consumers who are denied loans, interviews, or benefits may be permanently locked out from access to credit, employment, or assistance. In this work, we introduce a formal testing procedure to flag models that assign fixed predictions that we call recourse verification. We develop machinery to reliably determine if a given model can provide recourse to its decision subjects from a set of user-specified actionability constraints. We demonstrate how our tools can ensure recourse and adversarial robustness in real-world datasets and use them to study the infeasibility of recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar access, and we provide tools to design algorithms that account for actionability when developing models.</p>
<hr>
<h2 id="Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods"><a href="#Job-Shop-Scheduling-Benchmark-Environments-and-Instances-for-Learning-and-Non-learning-Methods" class="headerlink" title="Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods"></a>Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12794">http://arxiv.org/abs/2308.12794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark">https://github.com/ai-for-decision-making-tue/job_shop_scheduling_benchmark</a></li>
<li>paper_authors: Robbert Reijnen, Kjell van Straaten, Zaharah Bukhsh, Yingqian Zhang</li>
</ul>
<p>Abstract:<br>We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals). Our primary goal is to provide a centralized hub for researchers, practitioners, and enthusiasts interested in tackling machine scheduling challenges.</p>
<hr>
<h2 id="Single-shot-Bayesian-approximation-for-neural-networks"><a href="#Single-shot-Bayesian-approximation-for-neural-networks" class="headerlink" title="Single-shot Bayesian approximation for neural networks"></a>Single-shot Bayesian approximation for neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12785">http://arxiv.org/abs/2308.12785</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kaibrach/Moment-Propagation">https://github.com/kaibrach/Moment-Propagation</a></li>
<li>paper_authors: Kai Brach, Beate Sick, Oliver Dürr</li>
</ul>
<p>Abstract:<br>Deep neural networks (NNs) are known for their high-prediction performances. However, NNs are prone to yield unreliable predictions when encountering completely new situations without indicating their uncertainty. Bayesian variants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide uncertainty measures and simultaneously increase the prediction performance. The only disadvantage of BNNs is their higher computation time during test time because they rely on a sampling approach. Here we present a single-shot MC dropout approximation that preserves the advantages of BNNs while being as fast as NNs. Our approach is based on moment propagation (MP) and allows to analytically approximate the expected value and the variance of the MC dropout signal for commonly used layers in NNs, i.e. convolution, max pooling, dense, softmax, and dropout layers. The MP approach can convert an NN into a BNN without re-training given the NN has been trained with standard dropout. We evaluate our approach on different benchmark datasets and a simulated toy example in a classification and regression setting. We demonstrate that our single-shot MC dropout approximation resembles the point estimate and the uncertainty estimate of the predictive distribution that is achieved with an MC approach, while being fast enough for real-time deployments of BNNs. We show that using part of the saved time to combine our MP approach with deep ensemble techniques does further improve the uncertainty measures.</p>
<hr>
<h2 id="Intentionally-underestimated-Value-Function-at-Terminal-State-for-Temporal-difference-Learning-with-Mis-designed-Reward"><a href="#Intentionally-underestimated-Value-Function-at-Terminal-State-for-Temporal-difference-Learning-with-Mis-designed-Reward" class="headerlink" title="Intentionally-underestimated Value Function at Terminal State for Temporal-difference Learning with Mis-designed Reward"></a>Intentionally-underestimated Value Function at Terminal State for Temporal-difference Learning with Mis-designed Reward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12772">http://arxiv.org/abs/2308.12772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taisuke Kobayashi</li>
</ul>
<p>Abstract:<br>Robot control using reinforcement learning has become popular, but its learning process generally terminates halfway through an episode for safety and time-saving reasons. This study addresses the problem of the most popular exception handling that temporal-difference (TD) learning performs at such termination. That is, by forcibly assuming zero value after termination, unintentionally implicit underestimation or overestimation occurs, depending on the reward design in the normal states. When the episode is terminated due to task failure, the failure may be highly valued with the unintentional overestimation, and the wrong policy may be acquired. Although this problem can be avoided by paying attention to the reward design, it is essential in practical use of TD learning to review the exception handling at termination. This paper therefore proposes a method to intentionally underestimate the value after termination to avoid learning failures due to the unintentional overestimation. In addition, the degree of underestimation is adjusted according to the degree of stationarity at termination, thereby preventing excessive exploration due to the intentional underestimation. Simulations and real robot experiments showed that the proposed method can stably obtain the optimal policies for various tasks and reward designs. <a target="_blank" rel="noopener" href="https://youtu.be/AxXr8uFOe7M">https://youtu.be/AxXr8uFOe7M</a></p>
<hr>
<h2 id="On-the-Consistency-of-Average-Embeddings-for-Item-Recommendation"><a href="#On-the-Consistency-of-Average-Embeddings-for-Item-Recommendation" class="headerlink" title="On the Consistency of Average Embeddings for Item Recommendation"></a>On the Consistency of Average Embeddings for Item Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12767">http://arxiv.org/abs/2308.12767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deezer/consistency">https://github.com/deezer/consistency</a></li>
<li>paper_authors: Walid Bendada, Guillaume Salha-Galvan, Romain Hennequin, Thomas Bouabça, Tristan Cazenave</li>
</ul>
<p>Abstract:<br>A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.</p>
<hr>
<h2 id="IP-UNet-Intensity-Projection-UNet-Architecture-for-3D-Medical-Volume-Segmentation"><a href="#IP-UNet-Intensity-Projection-UNet-Architecture-for-3D-Medical-Volume-Segmentation" class="headerlink" title="IP-UNet: Intensity Projection UNet Architecture for 3D Medical Volume Segmentation"></a>IP-UNet: Intensity Projection UNet Architecture for 3D Medical Volume Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12761">http://arxiv.org/abs/2308.12761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nyothiri Aung, Tahar Kechadi, Liming Chen, Sahraoui Dhelim</li>
</ul>
<p>Abstract:<br>CNNs have been widely applied for medical image analysis. However, limited memory capacity is one of the most common drawbacks of processing high-resolution 3D volumetric data. 3D volumes are usually cropped or downsized first before processing, which can result in a loss of resolution, increase class imbalance, and affect the performance of the segmentation algorithms. In this paper, we propose an end-to-end deep learning approach called IP-UNet. IP-UNet is a UNet-based model that performs multi-class segmentation on Intensity Projection (IP) of 3D volumetric data instead of the memory-consuming 3D volumes. IP-UNet uses limited memory capability for training without losing the original 3D image resolution. We compare the performance of three models in terms of segmentation accuracy and computational cost: 1) Slice-by-slice 2D segmentation of the CT scan images using a conventional 2D UNet model. 2) IP-UNet that operates on data obtained by merging the extracted Maximum Intensity Projection (MIP), Closest Vessel Projection (CVP), and Average Intensity Projection (AvgIP) representations of the source 3D volumes, then applying the UNet model on the output IP images. 3) 3D-UNet model directly reads the 3D volumes constructed from a series of CT scan images and outputs the 3D volume of the predicted segmentation. We test the performance of these methods on 3D volumetric images for automatic breast calcification detection. Experimental results show that IP-Unet can achieve similar segmentation accuracy with 3D-Unet but with much better performance. It reduces the training time by 70% and memory consumption by 92%.</p>
<hr>
<h2 id="Motion-In-Betweening-with-Phase-Manifolds"><a href="#Motion-In-Betweening-with-Phase-Manifolds" class="headerlink" title="Motion In-Betweening with Phase Manifolds"></a>Motion In-Betweening with Phase Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12751">http://arxiv.org/abs/2308.12751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pauzii/phasebetweener">https://github.com/pauzii/phasebetweener</a></li>
<li>paper_authors: Paul Starke, Sebastian Starke, Taku Komura, Frank Steinicke</li>
</ul>
<p>Abstract:<br>This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder. Our approach utilizes a mixture-of-experts neural network model, in which the phases cluster movements in both space and time with different expert weights. Each generated set of weights then produces a sequence of poses in an autoregressive manner between the current and target state of the character. In addition, to satisfy poses which are manually modified by the animators or where certain end effectors serve as constraints to be reached by the animation, a learned bi-directional control scheme is implemented to satisfy such constraints. The results demonstrate that using phases for motion in-betweening tasks sharpen the interpolated movements, and furthermore stabilizes the learning process. Moreover, using phases for motion in-betweening tasks can also synthesize more challenging movements beyond locomotion behaviors. Additionally, style control is enabled between given target keyframes. Our proposed framework can compete with popular state-of-the-art methods for motion in-betweening in terms of motion quality and generalization, especially in the existence of long transition durations. Our framework contributes to faster prototyping workflows for creating animated character sequences, which is of enormous interest for the game and film industry.</p>
<hr>
<h2 id="Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks"><a href="#Human-Comprehensible-Active-Learning-of-Genome-Scale-Metabolic-Networks" class="headerlink" title="Human Comprehensible Active Learning of Genome-Scale Metabolic Networks"></a>Human Comprehensible Active Learning of Genome-Scale Metabolic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12740">http://arxiv.org/abs/2308.12740</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lun Ai, Shi-Shun Liang, Wang-Zhou Dai, Liam Hallett, Stephen H. Muggleton, Geoff S. Baldwin</li>
</ul>
<p>Abstract:<br>An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that reduce the experimental cost of learning gene functions in comparison to randomly selected experiments.</p>
<hr>
<h2 id="Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion"><a href="#Real-time-Detection-of-AI-Generated-Speech-for-DeepFake-Voice-Conversion" class="headerlink" title="Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion"></a>Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12734">http://arxiv.org/abs/2308.12734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan J. Bird, Ahmad Lotfi</li>
</ul>
<p>Abstract:<br>There are growing implications surrounding generative AI in the speech domain that enable voice cloning and real-time voice conversion from one individual to another. This technology poses a significant ethical threat and could lead to breaches of privacy and misrepresentation, thus there is an urgent need for real-time detection of AI-generated speech for DeepFake Voice Conversion. To address the above emerging issues, the DEEP-VOICE dataset is generated in this study, comprised of real human speech from eight well-known figures and their speech converted to one another using Retrieval-based Voice Conversion. Presenting as a binary classification problem of whether the speech is real or AI-generated, statistical analysis of temporal audio features through t-testing reveals that there are significantly different distributions. Hyperparameter optimisation is implemented for machine learning models to identify the source of speech. Following the training of 208 individual machine learning models over 10-fold cross validation, it is found that the Extreme Gradient Boosting model can achieve an average classification accuracy of 99.3% and can classify speech in real-time, at around 0.004 milliseconds given one second of speech. All data generated for this study is released publicly for future research on AI speech detection.</p>
<hr>
<h2 id="Out-of-the-Box-Thinking-Improving-Customer-Lifetime-Value-Modelling-via-Expert-Routing-and-Game-Whale-Detection"><a href="#Out-of-the-Box-Thinking-Improving-Customer-Lifetime-Value-Modelling-via-Expert-Routing-and-Game-Whale-Detection" class="headerlink" title="Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection"></a>Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12729">http://arxiv.org/abs/2308.12729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Zhang, Xin Yan, Xuejiao Yang, Binfeng Jia, Shuangyang Wang</li>
</ul>
<p>Abstract:<br>Customer lifetime value (LTV) prediction is essential for mobile game publishers trying to optimize the advertising investment for each user acquisition based on the estimated worth. In mobile games, deploying microtransactions is a simple yet effective monetization strategy, which attracts a tiny group of game whales who splurge on in-game purchases. The presence of such game whales may impede the practicality of existing LTV prediction models, since game whales’ purchase behaviours always exhibit varied distribution from general users. Consequently, identifying game whales can open up new opportunities to improve the accuracy of LTV prediction models. However, little attention has been paid to applying game whale detection in LTV prediction, and existing works are mainly specialized for the long-term LTV prediction with the assumption that the high-quality user features are available, which is not applicable in the UA stage. In this paper, we propose ExpLTV, a novel multi-task framework to perform LTV prediction and game whale detection in a unified way. In ExpLTV, we first innovatively design a deep neural network-based game whale detector that can not only infer the intrinsic order in accordance with monetary value, but also precisely identify high spenders (i.e., game whales) and low spenders. Then, by treating the game whale detector as a gating network to decide the different mixture patterns of LTV experts assembling, we can thoroughly leverage the shared information and scenario-specific information (i.e., game whales modelling and low spenders modelling). Finally, instead of separately designing a purchase rate estimator for two tasks, we design a shared estimator that can preserve the inner task relationships. The superiority of ExpLTV is further validated via extensive experiments on three industrial datasets.</p>
<hr>
<h2 id="Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game"><a href="#Continuous-Reinforcement-Learning-based-Dynamic-Difficulty-Adjustment-in-a-Visual-Working-Memory-Game" class="headerlink" title="Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game"></a>Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12726">http://arxiv.org/abs/2308.12726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoud Rahimi, Hadi Moradi, Abdol-hossein Vahabie, Hamed Kebriaei</li>
</ul>
<p>Abstract:<br>Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a player’s experience in video games. Recently, Reinforcement Learning (RL) methods have been employed for DDA in non-competitive games; nevertheless, they rely solely on discrete state-action space with a small search space. In this paper, we propose a continuous RL-based DDA methodology for a visual working memory (VWM) game to handle the complex search space for the difficulty of memorization. The proposed RL-based DDA tailors game difficulty based on the player’s score and game difficulty in the last trial. We defined a continuous metric for the difficulty of memorization. Then, we consider the task difficulty and the vector of difficulty-score as the RL’s action and state, respectively. We evaluated the proposed method through a within-subject experiment involving 52 subjects. The proposed approach was compared with two rule-based difficulty adjustment methods in terms of player’s score and game experience measured by a questionnaire. The proposed RL-based approach resulted in a significantly better game experience in terms of competence, tension, and negative and positive affect. Players also achieved higher scores and win rates. Furthermore, the proposed RL-based DDA led to a significantly less decline in the score in a 20-trial session.</p>
<hr>
<h2 id="Solving-Forward-and-Inverse-Problems-of-Contact-Mechanics-using-Physics-Informed-Neural-Networks"><a href="#Solving-Forward-and-Inverse-Problems-of-Contact-Mechanics-using-Physics-Informed-Neural-Networks" class="headerlink" title="Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks"></a>Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12716">http://arxiv.org/abs/2308.12716</a></li>
<li>repo_url: None</li>
<li>paper_authors: T. Sahin, M. von Danwitz, A. Popp</li>
</ul>
<p>Abstract:<br>This paper explores the ability of physics-informed neural networks (PINNs) to solve forward and inverse problems of contact mechanics for small deformation elasticity. We deploy PINNs in a mixed-variable formulation enhanced by output transformation to enforce Dirichlet and Neumann boundary conditions as hard constraints. Inequality constraints of contact problems, namely Karush-Kuhn-Tucker (KKT) type conditions, are enforced as soft constraints by incorporating them into the loss function during network training. To formulate the loss function contribution of KKT constraints, existing approaches applied to elastoplasticity problems are investigated and we explore a nonlinear complementarity problem (NCP) function, namely Fischer-Burmeister, which possesses advantageous characteristics in terms of optimization. Based on the Hertzian contact problem, we show that PINNs can serve as pure partial differential equation (PDE) solver, as data-enhanced forward model, as inverse solver for parameter identification, and as fast-to-evaluate surrogate model. Furthermore, we demonstrate the importance of choosing proper hyperparameters, e.g. loss weights, and a combination of Adam and L-BFGS-B optimizers aiming for better results in terms of accuracy and training time.</p>
<hr>
<h2 id="Disentanglement-Learning-via-Topology"><a href="#Disentanglement-Learning-via-Topology" class="headerlink" title="Disentanglement Learning via Topology"></a>Disentanglement Learning via Topology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12696">http://arxiv.org/abs/2308.12696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Balabin, Daria Voronkova, Ilya Trofimov, Evgeny Burnaev, Serguei Barannikov</li>
</ul>
<p>Abstract:<br>We propose TopDis (Topological Disentanglement), a method for learning disentangled representations via adding multi-scale topological loss term. Disentanglement is a crucial property of data representations substantial for the explainability and robustness of deep learning models and a step towards high-level cognition. The state-of-the-art method based on VAE minimizes the total correlation of the joint distribution of latent variables. We take a different perspective on disentanglement by analyzing topological properties of data manifolds. In particular, we optimize the topological similarity for data manifolds traversals. To the best of our knowledge, our paper is the first one to propose a differentiable topological loss for disentanglement. Our experiments have shown that the proposed topological loss improves disentanglement scores such as MIG, FactorVAE score, SAP score and DCI disentanglement score with respect to state-of-the-art results. Our method works in an unsupervised manner, permitting to apply it for problems without labeled factors of variation. Additionally, we show how to use the proposed topological loss to find disentangled directions in a trained GAN.</p>
<hr>
<h2 id="An-Efficient-Data-Analysis-Method-for-Big-Data-using-Multiple-Model-Linear-Regression"><a href="#An-Efficient-Data-Analysis-Method-for-Big-Data-using-Multiple-Model-Linear-Regression" class="headerlink" title="An Efficient Data Analysis Method for Big Data using Multiple-Model Linear Regression"></a>An Efficient Data Analysis Method for Big Data using Multiple-Model Linear Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12691">http://arxiv.org/abs/2308.12691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohan Lyu, Jianzhong Li</li>
</ul>
<p>Abstract:<br>This paper introduces a new data analysis method for big data using a newly defined regression model named multiple model linear regression(MMLR), which separates input datasets into subsets and construct local linear regression models of them. The proposed data analysis method is shown to be more efficient and flexible than other regression based methods. This paper also proposes an approximate algorithm to construct MMLR models based on $(\epsilon,\delta)$-estimator, and gives mathematical proofs of the correctness and efficiency of MMLR algorithm, of which the time complexity is linear with respect to the size of input datasets. This paper also empirically implements the method on both synthetic and real-world datasets, the algorithm shows to have comparable performance to existing regression methods in many cases, while it takes almost the shortest time to provide a high prediction accuracy.</p>
<hr>
<h2 id="Match-And-Deform-Time-Series-Domain-Adaptation-through-Optimal-Transport-and-Temporal-Alignment"><a href="#Match-And-Deform-Time-Series-Domain-Adaptation-through-Optimal-Transport-and-Temporal-Alignment" class="headerlink" title="Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment"></a>Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12686">http://arxiv.org/abs/2308.12686</a></li>
<li>repo_url: None</li>
<li>paper_authors: François Painblanc, Laetitia Chapel, Nicolas Courty, Chloé Friguet, Charlotte Pelletier, Romain Tavenard</li>
</ul>
<p>Abstract:<br>While large volumes of unlabeled data are usually available, associated labels are often scarce. The unsupervised domain adaptation problem aims at exploiting labels from a source domain to classify data from a related, yet different, target domain. When time series are at stake, new difficulties arise as temporal shifts may appear in addition to the standard feature distribution shift. In this paper, we introduce the Match-And-Deform (MAD) approach that aims at finding correspondences between the source and target time series while allowing temporal distortions. The associated optimization problem simultaneously aligns the series thanks to an optimal transport loss and the time stamps through dynamic time warping. When embedded into a deep neural network, MAD helps learning new representations of time series that both align the domains and maximize the discriminative power of the network. Empirical studies on benchmark datasets and remote sensing data demonstrate that MAD makes meaningful sample-to-sample pairing and time shift estimation, reaching similar or better classification performance than state-of-the-art deep time series domain adaptation strategies.</p>
<hr>
<h2 id="LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning"><a href="#LR-XFL-Logical-Reasoning-based-Explainable-Federated-Learning" class="headerlink" title="LR-XFL: Logical Reasoning-based Explainable Federated Learning"></a>LR-XFL: Logical Reasoning-based Explainable Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12681">http://arxiv.org/abs/2308.12681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanci Zhang, Han Yu</li>
</ul>
<p>Abstract:<br>Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients’ local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in terms of classification accuracy, rule accuracy and rule fidelity, respectively. The explicit rule evaluation and expression under LR-XFL enable human experts to validate and correct the rules on the server side, hence improving the global FL model’s robustness to errors. It has the potential to enhance the transparency of FL models for areas like healthcare and finance where both data privacy and explainability are important.</p>
<hr>
<h2 id="Master-slave-Deep-Architecture-for-Top-K-Multi-armed-Bandits-with-Non-linear-Bandit-Feedback-and-Diversity-Constraints"><a href="#Master-slave-Deep-Architecture-for-Top-K-Multi-armed-Bandits-with-Non-linear-Bandit-Feedback-and-Diversity-Constraints" class="headerlink" title="Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints"></a>Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12680">http://arxiv.org/abs/2308.12680</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/huanghanchi/master-slave-algorithm-for-top-k-bandits">https://github.com/huanghanchi/master-slave-algorithm-for-top-k-bandits</a></li>
<li>paper_authors: Hanchi Huang, Li Shen, Deheng Ye, Wei Liu</li>
</ul>
<p>Abstract:<br>We propose a novel master-slave architecture to solve the top-$K$ combinatorial multi-armed bandits problem with non-linear bandit feedback and diversity constraints, which, to the best of our knowledge, is the first combinatorial bandits setting considering diversity constraints under bandit feedback. Specifically, to efficiently explore the combinatorial and constrained action space, we introduce six slave models with distinguished merits to generate diversified samples well balancing rewards and constraints as well as efficiency. Moreover, we propose teacher learning based optimization and the policy co-training technique to boost the performance of the multiple slave models. The master model then collects the elite samples provided by the slave models and selects the best sample estimated by a neural contextual UCB-based network to make a decision with a trade-off between exploration and exploitation. Thanks to the elaborate design of slave models, the co-training mechanism among slave models, and the novel interactions between the master and slave models, our approach significantly surpasses existing state-of-the-art algorithms in both synthetic and real datasets for recommendation tasks. The code is available at: \url{<a target="_blank" rel="noopener" href="https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits%7D">https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}</a>.</p>
<hr>
<h2 id="A-Continual-Learning-Approach-for-Cross-Domain-White-Blood-Cell-Classification"><a href="#A-Continual-Learning-Approach-for-Cross-Domain-White-Blood-Cell-Classification" class="headerlink" title="A Continual Learning Approach for Cross-Domain White Blood Cell Classification"></a>A Continual Learning Approach for Cross-Domain White Blood Cell Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12679">http://arxiv.org/abs/2308.12679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ario Sadafi, Raheleh Salehi, Armin Gruber, Sayedali Shetab Boushehri, Pascal Giehr, Nassir Navab, Carsten Marr</li>
</ul>
<p>Abstract:<br>Accurate classification of white blood cells in peripheral blood is essential for diagnosing hematological diseases. Due to constantly evolving clinical settings, data sources, and disease classifications, it is necessary to update machine learning classification models regularly for practical real-world use. Such models significantly benefit from sequentially learning from incoming data streams without forgetting previously acquired knowledge. However, models can suffer from catastrophic forgetting, causing a drop in performance on previous tasks when fine-tuned on new data. Here, we propose a rehearsal-based continual learning approach for class incremental and domain incremental scenarios in white blood cell classification. To choose representative samples from previous tasks, we employ exemplar set selection based on the model’s predictions. This involves selecting the most confident samples and the most challenging samples identified through uncertainty estimation of the model. We thoroughly evaluated our proposed approach on three white blood cell classification datasets that differ in color, resolution, and class composition, including scenarios where new domains or new classes are introduced to the model with every task. We also test a long class incremental experiment with both new domains and new classes. Our results demonstrate that our approach outperforms established baselines in continual learning, including existing iCaRL and EWC methods for classifying white blood cells in cross-domain environments.</p>
<hr>
<h2 id="Masked-Feature-Modelling-Feature-Masking-for-the-Unsupervised-Pre-training-of-a-Graph-Attention-Network-Block-for-Bottom-up-Video-Event-Recognition"><a href="#Masked-Feature-Modelling-Feature-Masking-for-the-Unsupervised-Pre-training-of-a-Graph-Attention-Network-Block-for-Bottom-up-Video-Event-Recognition" class="headerlink" title="Masked Feature Modelling: Feature Masking for the Unsupervised Pre-training of a Graph Attention Network Block for Bottom-up Video Event Recognition"></a>Masked Feature Modelling: Feature Masking for the Unsupervised Pre-training of a Graph Attention Network Block for Bottom-up Video Event Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12673">http://arxiv.org/abs/2308.12673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitrios Daskalakis, Nikolaos Gkalelis, Vasileios Mezaris</li>
</ul>
<p>Abstract:<br>In this paper, we introduce Masked Feature Modelling (MFM), a novel approach for the unsupervised pre-training of a Graph Attention Network (GAT) block. MFM utilizes a pretrained Visual Tokenizer to reconstruct masked features of objects within a video, leveraging the MiniKinetics dataset. We then incorporate the pre-trained GAT block into a state-of-the-art bottom-up supervised video-event recognition architecture, ViGAT, to improve the model’s starting point and overall accuracy. Experimental evaluations on the YLI-MED dataset demonstrate the effectiveness of MFM in improving event recognition performance.</p>
<hr>
<h2 id="Optimal-data-pooling-for-shared-learning-in-maintenance-operations"><a href="#Optimal-data-pooling-for-shared-learning-in-maintenance-operations" class="headerlink" title="Optimal data pooling for shared learning in maintenance operations"></a>Optimal data pooling for shared learning in maintenance operations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12670">http://arxiv.org/abs/2308.12670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Collin Drent, Melvin Drent, Geert-Jan van Houtum</li>
</ul>
<p>Abstract:<br>This paper addresses the benefits of pooling data for shared learning in maintenance operations. We consider a set of systems subject to Poisson degradation that are coupled through an a-priori unknown rate. Decision problems involving these systems are high-dimensional Markov decision processes (MDPs). We present a decomposition result that reduces such an MDP to two-dimensional MDPs, enabling structural analyses and computations. We leverage this decomposition to demonstrate that pooling data can lead to significant cost reductions compared to not pooling.</p>
<hr>
<h2 id="Geodesic-Mode-Connectivity"><a href="#Geodesic-Mode-Connectivity" class="headerlink" title="Geodesic Mode Connectivity"></a>Geodesic Mode Connectivity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12666">http://arxiv.org/abs/2308.12666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charlie Tan, Theodore Long, Sarah Zhao, Rudolf Laine</li>
</ul>
<p>Abstract:<br>Mode connectivity is a phenomenon where trained models are connected by a path of low loss. We reframe this in the context of Information Geometry, where neural networks are studied as spaces of parameterized distributions with curved geometry. We hypothesize that shortest paths in these spaces, known as geodesics, correspond to mode-connecting paths in the loss landscape. We propose an algorithm to approximate geodesics and demonstrate that they achieve mode connectivity.</p>
<hr>
<h2 id="Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers"><a href="#Don’t-Look-into-the-Sun-Adversarial-Solarization-Attacks-on-Image-Classifiers" class="headerlink" title="Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers"></a>Don’t Look into the Sun: Adversarial Solarization Attacks on Image Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12661">http://arxiv.org/abs/2308.12661</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></li>
<li>paper_authors: Paul Gavrikov, Janis Keuper</li>
</ul>
<p>Abstract:<br>Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards. However, designing effective out-of-distribution tests that encompass all possible scenarios while preserving accurate label information is a challenging task. Existing methodologies often entail a compromise between variety and constraint levels for attacks and sometimes even both. In a first step towards a more holistic robustness evaluation of image classification models, we introduce an attack method based on image solarization that is conceptually straightforward yet avoids jeopardizing the global structure of natural images independent of the intensity. Through comprehensive evaluations of multiple ImageNet models, we demonstrate the attack’s capacity to degrade accuracy significantly, provided it is not integrated into the training augmentations. Interestingly, even then, no full immunity to accuracy deterioration is achieved. In other settings, the attack can often be simplified into a black-box attack with model-independent parameters. Defenses against other corruptions do not consistently extend to be effective against our specific attack.   Project website: <a target="_blank" rel="noopener" href="https://github.com/paulgavrikov/adversarial_solarization">https://github.com/paulgavrikov/adversarial_solarization</a></p>
<hr>
<h2 id="APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT"><a href="#APART-Diverse-Skill-Discovery-using-All-Pairs-with-Ascending-Reward-and-DropouT" class="headerlink" title="APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT"></a>APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12649">http://arxiv.org/abs/2308.12649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadar Schreiber Galler, Tom Zahavy, Guillaume Desjardins, Alon Cohen</li>
</ul>
<p>Abstract:<br>We study diverse skill discovery in reward-free environments, aiming to discover all possible skills in simple grid-world environments where prior methods have struggled to succeed. This problem is formulated as mutual training of skills using an intrinsic reward and a discriminator trained to predict a skill given its trajectory. Our initial solution replaces the standard one-vs-all (softmax) discriminator with a one-vs-one (all pairs) discriminator and combines it with a novel intrinsic reward function and a dropout regularization technique. The combined approach is named APART: Diverse Skill Discovery using All Pairs with Ascending Reward and Dropout. We demonstrate that APART discovers all the possible skills in grid worlds with remarkably fewer samples than previous works. Motivated by the empirical success of APART, we further investigate an even simpler algorithm that achieves maximum skills by altering VIC, rescaling its intrinsic reward, and tuning the temperature of its softmax discriminator. We believe our findings shed light on the crucial factors underlying success of skill discovery algorithms in reinforcement learning.</p>
<hr>
<h2 id="The-GENEA-Challenge-2023-A-large-scale-evaluation-of-gesture-generation-models-in-monadic-and-dyadic-settings"><a href="#The-GENEA-Challenge-2023-A-large-scale-evaluation-of-gesture-generation-models-in-monadic-and-dyadic-settings" class="headerlink" title="The GENEA Challenge 2023: A large scale evaluation of gesture generation models in monadic and dyadic settings"></a>The GENEA Challenge 2023: A large scale evaluation of gesture generation models in monadic and dyadic settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12646">http://arxiv.org/abs/2308.12646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taras Kucherenko, Rajmund Nagy, Youngwoo Yoon, Jieyeon Woo, Teodor Nikolov, Mihail Tsakov, Gustav Eje Henter</li>
</ul>
<p>Abstract:<br>This paper reports on the GENEA Challenge 2023, in which participating teams built speech-driven gesture-generation systems using the same speech and motion dataset, followed by a joint evaluation. This year’s challenge provided data on both sides of a dyadic interaction, allowing teams to generate full-body motion for an agent given its speech (text and audio) and the speech and motion of the interlocutor. We evaluated 12 submissions and 2 baselines together with held-out motion-capture data in several large-scale user studies. The studies focused on three aspects: 1) the human-likeness of the motion, 2) the appropriateness of the motion for the agent’s own speech whilst controlling for the human-likeness of the motion, and 3) the appropriateness of the motion for the behaviour of the interlocutor in the interaction, using a setup that controls for both the human-likeness of the motion and the agent’s own speech. We found a large span in human-likeness between challenge submissions, with a few systems rated close to human mocap. Appropriateness seems far from being solved, with most submissions performing in a narrow range slightly above chance, far behind natural motion. The effect of the interlocutor is even more subtle, with submitted systems at best performing barely above chance. Interestingly, a dyadic system being highly appropriate for agent speech does not necessarily imply high appropriateness for the interlocutor. Additional material is available via the project website at <a target="_blank" rel="noopener" href="https://svito-zar.github.io/GENEAchallenge2023/">https://svito-zar.github.io/GENEAchallenge2023/</a> .</p>
<hr>
<h2 id="Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning"><a href="#Towards-Hierarchical-Regional-Transformer-based-Multiple-Instance-Learning" class="headerlink" title="Towards Hierarchical Regional Transformer-based Multiple Instance Learning"></a>Towards Hierarchical Regional Transformer-based Multiple Instance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12634">http://arxiv.org/abs/2308.12634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Cersovsky, Sadegh Mohammadi, Dagmar Kainmueller, Johannes Hoehne</li>
</ul>
<p>Abstract:<br>The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.</p>
<hr>
<h2 id="Uncertainty-and-Explainable-Analysis-of-Machine-Learning-Model-for-Reconstruction-of-Sonic-Slowness-Logs"><a href="#Uncertainty-and-Explainable-Analysis-of-Machine-Learning-Model-for-Reconstruction-of-Sonic-Slowness-Logs" class="headerlink" title="Uncertainty and Explainable Analysis of Machine Learning Model for Reconstruction of Sonic Slowness Logs"></a>Uncertainty and Explainable Analysis of Machine Learning Model for Reconstruction of Sonic Slowness Logs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12625">http://arxiv.org/abs/2308.12625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hua Wang, Yuqiong Wu, Yushun Zhang, Fuqiang Lai, Zhou Feng, Bing Xie, Ailin Zhao</li>
</ul>
<p>Abstract:<br>Logs are valuable information for oil and gas fields as they help to determine the lithology of the formations surrounding the borehole and the location and reserves of subsurface oil and gas reservoirs. However, important logs are often missing in horizontal or old wells, which poses a challenge in field applications. In this paper, we utilize data from the 2020 machine learning competition of the SPWLA, which aims to predict the missing compressional wave slowness and shear wave slowness logs using other logs in the same borehole. We employ the NGBoost algorithm to construct an Ensemble Learning model that can predicate the results as well as their uncertainty. Furthermore, we combine the SHAP method to investigate the interpretability of the machine learning model. We compare the performance of the NGBosst model with four other commonly used Ensemble Learning methods, including Random Forest, GBDT, XGBoost, LightGBM. The results show that the NGBoost model performs well in the testing set and can provide a probability distribution for the prediction results. In addition, the variance of the probability distribution of the predicted log can be used to justify the quality of the constructed log. Using the SHAP explainable machine learning model, we calculate the importance of each input log to the predicted results as well as the coupling relationship among input logs. Our findings reveal that the NGBoost model tends to provide greater slowness prediction results when the neutron porosity and gamma ray are large, which is consistent with the cognition of petrophysical models. Furthermore, the machine learning model can capture the influence of the changing borehole caliper on slowness, where the influence of borehole caliper on slowness is complex and not easy to establish a direct relationship. These findings are in line with the physical principle of borehole acoustics.</p>
<hr>
<h2 id="Try-with-Simpler-–-An-Evaluation-of-Improved-Principal-Component-Analysis-in-Log-based-Anomaly-Detection"><a href="#Try-with-Simpler-–-An-Evaluation-of-Improved-Principal-Component-Analysis-in-Log-based-Anomaly-Detection" class="headerlink" title="Try with Simpler – An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection"></a>Try with Simpler – An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12612">http://arxiv.org/abs/2308.12612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Yang, Junjie Chen, Zhihao Gong, Shutao Gao, Hongyu Zhang, Yue Kang, Huaan Li</li>
</ul>
<p>Abstract:<br>The rapid growth of deep learning (DL) has spurred interest in enhancing log-based anomaly detection. This approach aims to extract meaning from log events (log message templates) and develop advanced DL models for anomaly detection. However, these DL methods face challenges like heavy reliance on training data, labels, and computational resources due to model complexity. In contrast, traditional machine learning and data mining techniques are less data-dependent and more efficient but less effective than DL. To make log-based anomaly detection more practical, the goal is to enhance traditional techniques to match DL’s effectiveness. Previous research in a different domain (linking questions on Stack Overflow) suggests that optimized traditional techniques can rival state-of-the-art DL methods. Drawing inspiration from this concept, we conducted an empirical study. We optimized the unsupervised PCA (Principal Component Analysis), a traditional technique, by incorporating lightweight semantic-based log representation. This addresses the issue of unseen log events in training data, enhancing log representation. Our study compared seven log-based anomaly detection methods, including four DL-based, two traditional, and the optimized PCA technique, using public and industrial datasets. Results indicate that the optimized unsupervised PCA technique achieves similar effectiveness to advanced supervised&#x2F;semi-supervised DL methods while being more stable with limited training data and resource-efficient. This demonstrates the adaptability and strength of traditional techniques through small yet impactful adaptations.</p>
<hr>
<h2 id="A-Greedy-Approach-for-Offering-to-Telecom-Subscribers"><a href="#A-Greedy-Approach-for-Offering-to-Telecom-Subscribers" class="headerlink" title="A Greedy Approach for Offering to Telecom Subscribers"></a>A Greedy Approach for Offering to Telecom Subscribers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12606">http://arxiv.org/abs/2308.12606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Kanti Bhunre, Tanmay Sen, Arijit Sarkar</li>
</ul>
<p>Abstract:<br>Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator’s network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator’s objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer optimization under heterogeneous offers by maximizing expected revenue under the scenario of subscriber churn, which is, in general, seen in telecom domain. The proposed algorithm is efficient and accurate even for a very large subscriber-base.</p>
<hr>
<h2 id="Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement"><a href="#Exploiting-Time-Frequency-Conformers-for-Music-Audio-Enhancement" class="headerlink" title="Exploiting Time-Frequency Conformers for Music Audio Enhancement"></a>Exploiting Time-Frequency Conformers for Music Audio Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12599">http://arxiv.org/abs/2308.12599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunkee Chae, Junghyun Koo, Sungho Lee, Kyogu Lee</li>
</ul>
<p>Abstract:<br>With the proliferation of video platforms on the internet, recording musical performances by mobile devices has become commonplace. However, these recordings often suffer from degradation such as noise and reverberation, which negatively impact the listening experience. Consequently, the necessity for music audio enhancement (referred to as music enhancement from this point onward), involving the transformation of degraded audio recordings into pristine high-quality music, has surged to augment the auditory experience. To address this issue, we propose a music enhancement system based on the Conformer architecture that has demonstrated outstanding performance in speech enhancement tasks. Our approach explores the attention mechanisms of the Conformer and examines their performance to discover the best approach for the music enhancement task. Our experimental results show that our proposed model achieves state-of-the-art performance on single-stem music enhancement. Furthermore, our system can perform general music enhancement with multi-track mixtures, which has not been examined in previous work.</p>
<hr>
<h2 id="LORD-Leveraging-Open-Set-Recognition-with-Unknown-Data"><a href="#LORD-Leveraging-Open-Set-Recognition-with-Unknown-Data" class="headerlink" title="LORD: Leveraging Open-Set Recognition with Unknown Data"></a>LORD: Leveraging Open-Set Recognition with Unknown Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12584">http://arxiv.org/abs/2308.12584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Koch, Christian Riess, Thomas Köhler</li>
</ul>
<p>Abstract:<br>Handling entirely unknown data is a challenge for any deployed classifier. Classification models are typically trained on a static pre-defined dataset and are kept in the dark for the open unassigned feature space. As a result, they struggle to deal with out-of-distribution data during inference. Addressing this task on the class-level is termed open-set recognition (OSR). However, most OSR methods are inherently limited, as they train closed-set classifiers and only adapt the downstream predictions to OSR. This work presents LORD, a framework to Leverage Open-set Recognition by exploiting unknown Data. LORD explicitly models open space during classifier training and provides a systematic evaluation for such approaches. We identify three model-agnostic training strategies that exploit background data and applied them to well-established classifiers. Due to LORD’s extensive evaluation protocol, we consistently demonstrate improved recognition of unknown data. The benchmarks facilitate in-depth analysis across various requirement levels. To mitigate dependency on extensive and costly background datasets, we explore mixup as an off-the-shelf data generation technique. Our experiments highlight mixup’s effectiveness as a substitute for background datasets. Lightweight constraints on mixup synthesis further improve OSR performance.</p>
<hr>
<h2 id="Persistent-learning-signals-and-working-memory-without-continuous-attractors"><a href="#Persistent-learning-signals-and-working-memory-without-continuous-attractors" class="headerlink" title="Persistent learning signals and working memory without continuous attractors"></a>Persistent learning signals and working memory without continuous attractors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12585">http://arxiv.org/abs/2308.12585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Il Memming Park, Ábel Ságodi, Piotr Aleksander Sokół</li>
</ul>
<p>Abstract:<br>Neural dynamical systems with stable attractor structures, such as point attractors and continuous attractors, are hypothesized to underlie meaningful temporal behavior that requires working memory. However, working memory may not support useful learning signals necessary to adapt to changes in the temporal structure of the environment. We show that in addition to the continuous attractors that are widely implicated, periodic and quasi-periodic attractors can also support learning arbitrarily long temporal relationships. Unlike the continuous attractors that suffer from the fine-tuning problem, the less explored quasi-periodic attractors are uniquely qualified for learning to produce temporally structured behavior. Our theory has broad implications for the design of artificial learning systems and makes predictions about observable signatures of biological neural dynamics that can support temporal dependence learning and working memory. Based on our theory, we developed a new initialization scheme for artificial recurrent neural networks that outperforms standard methods for tasks that require learning temporal dynamics. Moreover, we propose a robust recurrent memory mechanism for integrating and maintaining head direction without a ring attractor.</p>
<hr>
<h2 id="A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning"><a href="#A-Huber-Loss-Minimization-Approach-to-Byzantine-Robust-Federated-Learning" class="headerlink" title="A Huber Loss Minimization Approach to Byzantine Robust Federated Learning"></a>A Huber Loss Minimization Approach to Byzantine Robust Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12581">http://arxiv.org/abs/2308.12581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Puning Zhao, Fei Yu, Zhiguo Wan</li>
</ul>
<p>Abstract:<br>Federated learning systems are susceptible to adversarial attacks. To combat this, we introduce a novel aggregator based on Huber loss minimization, and provide a comprehensive theoretical analysis. Under independent and identically distributed (i.i.d) assumption, our approach has several advantages compared to existing methods. Firstly, it has optimal dependence on $\epsilon$, which stands for the ratio of attacked clients. Secondly, our approach does not need precise knowledge of $\epsilon$. Thirdly, it allows different clients to have unequal data sizes. We then broaden our analysis to include non-i.i.d data, such that clients have slightly different distributions.</p>
<hr>
<h2 id="Hypergraph-Convolutional-Networks-for-Fine-grained-ICU-Patient-Similarity-Analysis-and-Risk-Prediction"><a href="#Hypergraph-Convolutional-Networks-for-Fine-grained-ICU-Patient-Similarity-Analysis-and-Risk-Prediction" class="headerlink" title="Hypergraph Convolutional Networks for Fine-grained ICU Patient Similarity Analysis and Risk Prediction"></a>Hypergraph Convolutional Networks for Fine-grained ICU Patient Similarity Analysis and Risk Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12575">http://arxiv.org/abs/2308.12575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Liu, Zhenhao Zhang, Shaowen Qin, Flora D. Salim, Antonio Jimeno Yepes, Jun Shen</li>
</ul>
<p>Abstract:<br>The Intensive Care Unit (ICU) is one of the most important parts of a hospital, which admits critically ill patients and provides continuous monitoring and treatment. Various patient outcome prediction methods have been attempted to assist healthcare professionals in clinical decision-making. Existing methods focus on measuring the similarity between patients using deep neural networks to capture the hidden feature structures. However, the higher-order relationships are ignored, such as patient characteristics (e.g., diagnosis codes) and their causal effects on downstream clinical predictions.   In this paper, we propose a novel Hypergraph Convolutional Network that allows the representation of non-pairwise relationships among diagnosis codes in a hypergraph to capture the hidden feature structures so that fine-grained patient similarity can be calculated for personalized mortality risk prediction. Evaluation using a publicly available eICU Collaborative Research Database indicates that our method achieves superior performance over the state-of-the-art models on mortality risk prediction. Moreover, the results of several case studies demonstrated the effectiveness of constructing graph networks in providing good transparency and robustness in decision-making.</p>
<hr>
<h2 id="Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments"><a href="#Conditional-Kernel-Imitation-Learning-for-Continuous-State-Environments" class="headerlink" title="Conditional Kernel Imitation Learning for Continuous State Environments"></a>Conditional Kernel Imitation Learning for Continuous State Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12573">http://arxiv.org/abs/2308.12573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Agrawal, Nathan Dahlin, Rahul Jain, Ashutosh Nayyar</li>
</ul>
<p>Abstract:<br>Imitation Learning (IL) is an important paradigm within the broader reinforcement learning (RL) methodology. Unlike most of RL, it does not assume availability of reward-feedback. Reward inference and shaping are known to be difficult and error-prone methods particularly when the demonstration data comes from human experts. Classical methods such as behavioral cloning and inverse reinforcement learning are highly sensitive to estimation errors, a problem that is particularly acute in continuous state space problems. Meanwhile, state-of-the-art IL algorithms convert behavioral policy learning problems into distribution-matching problems which often require additional online interaction data to be effective. In this paper, we consider the problem of imitation learning in continuous state space environments based solely on observed behavior, without access to transition dynamics information, reward structure, or, most importantly, any additional interactions with the environment. Our approach is based on the Markov balance equation and introduces a novel conditional kernel density estimation-based imitation learning framework. It involves estimating the environment’s transition dynamics using conditional kernel density estimators and seeks to satisfy the probabilistic balance equations for the environment. We establish that our estimators satisfy basic asymptotic consistency requirements. Through a series of numerical experiments on continuous state benchmark environments, we show consistently superior empirical performance over many state-of-the-art IL algorithms.</p>
<hr>
<h2 id="Multivariate-Time-Series-Anomaly-Detection-with-Contaminated-Data-Application-to-Physiological-Signals"><a href="#Multivariate-Time-Series-Anomaly-Detection-with-Contaminated-Data-Application-to-Physiological-Signals" class="headerlink" title="Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals"></a>Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12563">http://arxiv.org/abs/2308.12563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thi Kieu Khanh Ho, Narges Armanfard</li>
</ul>
<p>Abstract:<br>Mainstream unsupervised anomaly detection algorithms often excel in academic datasets, yet their real-world performance is restricted due to the controlled experimental conditions involving clean training data. Addressing the challenge of training with noise, a prevalent issue in practical anomaly detection, is frequently overlooked. In a pioneering endeavor, this study delves into the realm of label-level noise within sensory time-series anomaly detection (TSAD). This paper presents a novel and practical end-to-end unsupervised TSAD when the training data are contaminated with anomalies. The introduced approach, called TSAD-C, is devoid of access to abnormality labels during the training phase. TSAD-C encompasses three modules: a Decontaminator to rectify the abnormalities (aka noise) present in the training data, a Variable Dependency Modeling module to capture both long-term intra- and inter-variable dependencies within the decontaminated data that can be considered as a surrogate of the pure normal data, and an Anomaly Scoring module to detect anomalies. Our extensive experiments conducted on three widely used physiological datasets conclusively demonstrate that our approach surpasses existing methodologies, thus establishing a new state-of-the-art performance in the field.</p>
<hr>
<h2 id="Variational-Information-Pursuit-with-Large-Language-and-Multimodal-Models-for-Interpretable-Predictions"><a href="#Variational-Information-Pursuit-with-Large-Language-and-Multimodal-Models-for-Interpretable-Predictions" class="headerlink" title="Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions"></a>Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12562">http://arxiv.org/abs/2308.12562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kwan Ho Ryan Chan, Aditya Chattopadhyay, Benjamin David Haeffele, Rene Vidal</li>
</ul>
<p>Abstract:<br>Variational Information Pursuit (V-IP) is a framework for making interpretable predictions by design by sequentially selecting a short chain of task-relevant, user-defined and interpretable queries about the data that are most informative for the task. While this allows for built-in interpretability in predictive models, applying V-IP to any task requires data samples with dense concept-labeling by domain experts, limiting the application of V-IP to small-scale tasks where manual data annotation is feasible. In this work, we extend the V-IP framework with Foundational Models (FMs) to address this limitation. More specifically, we use a two-step process, by first leveraging Large Language Models (LLMs) to generate a sufficiently large candidate set of task-relevant interpretable concepts, then using Large Multimodal Models to annotate each data sample by semantic similarity with each concept in the generated concept set. While other interpretable-by-design frameworks such as Concept Bottleneck Models (CBMs) require an additional step of removing repetitive and non-discriminative concepts to have good interpretability and test performance, we mathematically and empirically justify that, with a sufficiently informative and task-relevant query (concept) set, the proposed FM+V-IP method does not require any type of concept filtering. In addition, we show that FM+V-IP with LLM generated concepts can achieve better test performance than V-IP with human annotated concepts, demonstrating the effectiveness of LLMs at generating efficient query sets. Finally, when compared to other interpretable-by-design frameworks such as CBMs, FM+V-IP can achieve competitive test performance using fewer number of concepts&#x2F;queries in both cases with filtered or unfiltered concept sets.</p>
<hr>
<h2 id="Deep-Reinforcement-Learning-driven-Cross-Community-Energy-Interaction-Optimal-Scheduling"><a href="#Deep-Reinforcement-Learning-driven-Cross-Community-Energy-Interaction-Optimal-Scheduling" class="headerlink" title="Deep Reinforcement Learning-driven Cross-Community Energy Interaction Optimal Scheduling"></a>Deep Reinforcement Learning-driven Cross-Community Energy Interaction Optimal Scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12554">http://arxiv.org/abs/2308.12554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Fanjin Bu, Zhen Yang, Bin Wang, Meng Han</li>
</ul>
<p>Abstract:<br>In order to coordinate energy interactions among various communities and energy conversions among multi-energy subsystems within the multi-community integrated energy system under uncertain conditions, and achieve overall optimization and scheduling of the comprehensive energy system, this paper proposes a comprehensive scheduling model that utilizes a multi-agent deep reinforcement learning algorithm to learn load characteristics of different communities and make decisions based on this knowledge. In this model, the scheduling problem of the integrated energy system is transformed into a Markov decision process and solved using a data-driven deep reinforcement learning algorithm, which avoids the need for modeling complex energy coupling relationships between multi-communities and multi-energy subsystems. The simulation results show that the proposed method effectively captures the load characteristics of different communities and utilizes their complementary features to coordinate reasonable energy interactions among them. This leads to a reduction in wind curtailment rate from 16.3% to 0% and lowers the overall operating cost by 5445.6 Yuan, demonstrating significant economic and environmental benefits.</p>
<hr>
<h2 id="Don’t-blame-Dataset-Shift-Shortcut-Learning-due-to-Gradients-and-Cross-Entropy"><a href="#Don’t-blame-Dataset-Shift-Shortcut-Learning-due-to-Gradients-and-Cross-Entropy" class="headerlink" title="Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy"></a>Don’t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12553">http://arxiv.org/abs/2308.12553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aahlad Puli, Lily Zhang, Yoav Wald, Rajesh Ranganath</li>
</ul>
<p>Abstract:<br>Common explanations for shortcut learning assume that the shortcut improves prediction under the training distribution but not in the test distribution. Thus, models trained via the typical gradient-based optimization of cross-entropy, which we call default-ERM, utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM still exhibits shortcut learning. Why are such solutions preferred when the loss for default-ERM can be driven to zero using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin leads to models that depend more on the shortcut than the stable feature, even without overparameterization. This insight suggests that default-ERM’s implicit inductive bias towards max-margin is unsuitable for perception tasks. Instead, we develop an inductive bias toward uniform margins and show that this bias guarantees dependence only on the perfect stable feature in the linear perception task. We develop loss functions that encourage uniform-margin solutions, called margin control (MARG-CTRL). MARG-CTRL mitigates shortcut learning on a variety of vision and language tasks, showing that better inductive biases can remove the need for expensive two-stage shortcut-mitigating methods in perception tasks.</p>
<hr>
<h2 id="A-Co-training-Approach-for-Noisy-Time-Series-Learning"><a href="#A-Co-training-Approach-for-Noisy-Time-Series-Learning" class="headerlink" title="A Co-training Approach for Noisy Time Series Learning"></a>A Co-training Approach for Noisy Time Series Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12551">http://arxiv.org/abs/2308.12551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung</li>
</ul>
<p>Abstract:<br>In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.</p>
<hr>
<h2 id="CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias"><a href="#CALM-A-Multi-task-Benchmark-for-Comprehensive-Assessment-of-Language-Model-Bias" class="headerlink" title="CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias"></a>CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12539">http://arxiv.org/abs/2308.12539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/calm">https://github.com/vipulgupta1011/calm</a></li>
<li>paper_authors: Vipul Gupta, Pranav Narayanan Venkit, Hugo Laurençon, Shomir Wilson, Rebecca J. Passonneau</li>
</ul>
<p>Abstract:<br>As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language models including six prominent families of LMs such as Llama-2. In two LM series, OPT and Bloom, we found that larger parameter models are more biased than lower parameter models. We found the T0 series of models to be the least biased. Furthermore, we noticed a tradeoff between gender and racial bias with increasing model size in some model series. The code is available at <a target="_blank" rel="noopener" href="https://github.com/vipulgupta1011/CALM">https://github.com/vipulgupta1011/CALM</a>.</p>
<hr>
<h2 id="FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning"><a href="#FedSoL-Bridging-Global-Alignment-and-Local-Generality-in-Federated-Learning" class="headerlink" title="FedSoL: Bridging Global Alignment and Local Generality in Federated Learning"></a>FedSoL: Bridging Global Alignment and Local Generality in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12532">http://arxiv.org/abs/2308.12532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gihun Lee, Minchan Jeong, Sangmook Kim, Jaehoon Oh, Se-Young Yun</li>
</ul>
<p>Abstract:<br>Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (FedSoL), which combines both the concepts of global alignment and local generality. In FedSoL, the local learning seeks a parameter region robust against proximal perturbations. This strategy introduces an implicit proximal restriction effect in local learning while maintaining the original local objective for parameter update. Our experiments show that FedSoL consistently achieves state-of-the-art performance on various setups.</p>
<hr>
<h2 id="SieveNet-Selecting-Point-Based-Features-for-Mesh-Networks"><a href="#SieveNet-Selecting-Point-Based-Features-for-Mesh-Networks" class="headerlink" title="SieveNet: Selecting Point-Based Features for Mesh Networks"></a>SieveNet: Selecting Point-Based Features for Mesh Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12530">http://arxiv.org/abs/2308.12530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sievenet/sievenet.github.io">https://github.com/sievenet/sievenet.github.io</a></li>
<li>paper_authors: Shengchao Yuan, Yishun Dou, Rui Shi, Bingbing Ni, Zhong Zheng</li>
</ul>
<p>Abstract:<br>Meshes are widely used in 3D computer vision and graphics, but their irregular topology poses challenges in applying them to existing neural network architectures. Recent advances in mesh neural networks turn to remeshing and push the boundary of pioneer methods that solely take the raw meshes as input. Although the remeshing offers a regular topology that significantly facilitates the design of mesh network architectures, features extracted from such remeshed proxies may struggle to retain the underlying geometry faithfully, limiting the subsequent neural network’s capacity. To address this issue, we propose SieveNet, a novel paradigm that takes into account both the regular topology and the exact geometry. Specifically, this method utilizes structured mesh topology from remeshing and accurate geometric information from distortion-aware point sampling on the surface of the original mesh. Furthermore, our method eliminates the need for hand-crafted feature engineering and can leverage off-the-shelf network architectures such as the vision transformer. Comprehensive experimental results on classification and segmentation tasks well demonstrate the effectiveness and superiority of our method.</p>
<hr>
<h2 id="UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023"><a href="#UNISOUND-System-for-VoxCeleb-Speaker-Recognition-Challenge-2023" class="headerlink" title="UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023"></a>UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12526">http://arxiv.org/abs/2308.12526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Zheng, Yajun Zhang, Chuanying Niu, Yibin Zhan, Yanhua Long, Dongxing Xu</li>
</ul>
<p>Abstract:<br>This report describes the UNISOUND submission for Track1 and Track2 of VoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same system on Track 1 and Track 2, which is trained with only VoxCeleb2-dev. Large-scale ResNet and RepVGG architectures are developed for the challenge. We propose a consistency-aware score calibration method, which leverages the stability of audio voiceprints in similarity score by a Consistency Measure Factor (CMF). CMF brings a huge performance boost in this challenge. Our final system is a fusion of six models and achieves the first place in Track 1 and second place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855 and the EER is 1.5880%.</p>
<hr>
<h2 id="Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion"><a href="#Not-Only-Rewards-But-Also-Constraints-Applications-on-Legged-Robot-Locomotion" class="headerlink" title="Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion"></a>Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12517">http://arxiv.org/abs/2308.12517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunho Kim, Hyunsik Oh, Jeonghyun Lee, Jinhyeok Choi, Gwanghyeon Ji, Moonkyu Jung, Donghoon Youm, Jemin Hwangbo</li>
</ul>
<p>Abstract:<br>Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attributes to traverse challenging terrains. Extensive simulation and real-world experiments demonstrate that performant controllers can be trained with significantly less reward engineering, by tuning only a single reward coefficient. Furthermore, a more straightforward and intuitive engineering process can be utilized, thanks to the interpretability and generalizability of constraints. The summary video is available at <a target="_blank" rel="noopener" href="https://youtu.be/KAlm3yskhvM">https://youtu.be/KAlm3yskhvM</a>.</p>
<hr>
<h2 id="Masked-Autoencoders-are-Efficient-Class-Incremental-Learners"><a href="#Masked-Autoencoders-are-Efficient-Class-Incremental-Learners" class="headerlink" title="Masked Autoencoders are Efficient Class Incremental Learners"></a>Masked Autoencoders are Efficient Class Incremental Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12510">http://arxiv.org/abs/2308.12510</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scok30/mae-cil">https://github.com/scok30/mae-cil</a></li>
<li>paper_authors: Jiang-Tian Zhai, Xialei Liu, Andrew D. Bagdanov, Ke Li, Ming-Ming Cheng</li>
</ul>
<p>Abstract:<br>Class Incremental Learning (CIL) aims to sequentially learn new classes while avoiding catastrophic forgetting of previous knowledge. We propose to use Masked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally designed to learn useful representations through reconstructive unsupervised learning, and they can be easily integrated with a supervised loss for classification. Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL. We also propose a bilateral MAE framework to learn from image-level and embedding-level fusion, which produces better-quality reconstructed images and more stable representations. Our experiments confirm that our approach performs better than the state-of-the-art on CIFAR-100, ImageNet-Subset, and ImageNet-Full. The code is available at <a target="_blank" rel="noopener" href="https://github.com/scok30/MAE-CIL">https://github.com/scok30/MAE-CIL</a> .</p>
<hr>
<h2 id="False-Information-Bots-and-Malicious-Campaigns-Demystifying-Elements-of-Social-Media-Manipulations"><a href="#False-Information-Bots-and-Malicious-Campaigns-Demystifying-Elements-of-Social-Media-Manipulations" class="headerlink" title="False Information, Bots and Malicious Campaigns: Demystifying Elements of Social Media Manipulations"></a>False Information, Bots and Malicious Campaigns: Demystifying Elements of Social Media Manipulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12497">http://arxiv.org/abs/2308.12497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Majid Akhtar, Rahat Masood, Muhammad Ikram, Salil S. Kanhere</li>
</ul>
<p>Abstract:<br>The rapid spread of false information and persistent manipulation attacks on online social networks (OSNs), often for political, ideological, or financial gain, has affected the openness of OSNs. While researchers from various disciplines have investigated different manipulation-triggering elements of OSNs (such as understanding information diffusion on OSNs or detecting automated behavior of accounts), these works have not been consolidated to present a comprehensive overview of the interconnections among these elements. Notably, user psychology, the prevalence of bots, and their tactics in relation to false information detection have been overlooked in previous research. To address this research gap, this paper synthesizes insights from various disciplines to provide a comprehensive analysis of the manipulation landscape. By integrating the primary elements of social media manipulation (SMM), including false information, bots, and malicious campaigns, we extensively examine each SMM element. Through a systematic investigation of prior research, we identify commonalities, highlight existing gaps, and extract valuable insights in the field. Our findings underscore the urgent need for interdisciplinary research to effectively combat social media manipulations, and our systematization can guide future research efforts and assist OSN providers in ensuring the safety and integrity of their platforms.</p>
<hr>
<h2 id="Optimizing-Neural-Network-Scale-for-ECG-Classification"><a href="#Optimizing-Neural-Network-Scale-for-ECG-Classification" class="headerlink" title="Optimizing Neural Network Scale for ECG Classification"></a>Optimizing Neural Network Scale for ECG Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12492">http://arxiv.org/abs/2308.12492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byeong Tak Lee, Yong-Yeon Jo, Joon-Myoung Kwon</li>
</ul>
<p>Abstract:<br>We study scaling convolutional neural networks (CNNs), specifically targeting Residual neural networks (ResNet), for analyzing electrocardiograms (ECGs). Although ECG signals are time-series data, CNN-based models have been shown to outperform other neural networks with different architectures in ECG analysis. However, most previous studies in ECG analysis have overlooked the importance of network scaling optimization, which significantly improves performance. We explored and demonstrated an efficient approach to scale ResNet by examining the effects of crucial parameters, including layer depth, the number of channels, and the convolution kernel size. Through extensive experiments, we found that a shallower network, a larger number of channels, and smaller kernel sizes result in better performance for ECG classifications. The optimal network scale might differ depending on the target task, but our findings provide insight into obtaining more efficient and accurate models with fewer computing resources or less time. In practice, we demonstrate that a narrower search space based on our findings leads to higher performance.</p>
<hr>
<h2 id="Fall-Detection-using-Knowledge-Distillation-Based-Long-short-term-memory-for-Offline-Embedded-and-Low-Power-Devices"><a href="#Fall-Detection-using-Knowledge-Distillation-Based-Long-short-term-memory-for-Offline-Embedded-and-Low-Power-Devices" class="headerlink" title="Fall Detection using Knowledge Distillation Based Long short-term memory for Offline Embedded and Low Power Devices"></a>Fall Detection using Knowledge Distillation Based Long short-term memory for Offline Embedded and Low Power Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12481">http://arxiv.org/abs/2308.12481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hannah Zhou, Allison Chen, Celine Buer, Emily Chen, Kayleen Tang, Lauryn Gong, Zhiqi Liu, Jianbin Tang</li>
</ul>
<p>Abstract:<br>This paper presents a cost-effective, low-power approach to unintentional fall detection using knowledge distillation-based LSTM (Long Short-Term Memory) models to significantly improve accuracy. With a primary focus on analyzing time-series data collected from various sensors, the solution offers real-time detection capabilities, ensuring prompt and reliable identification of falls. The authors investigate fall detection models that are based on different sensors, comparing their accuracy rates and performance. Furthermore, they employ the technique of knowledge distillation to enhance the models’ precision, resulting in refined accurate configurations that consume lower power. As a result, this proposed solution presents a compelling avenue for the development of energy-efficient fall detection systems for future advancements in this critical domain.</p>
<hr>
<h2 id="Zero-delay-Consistent-Signal-Reconstruction-from-Streamed-Multivariate-Time-Series"><a href="#Zero-delay-Consistent-Signal-Reconstruction-from-Streamed-Multivariate-Time-Series" class="headerlink" title="Zero-delay Consistent Signal Reconstruction from Streamed Multivariate Time Series"></a>Zero-delay Consistent Signal Reconstruction from Streamed Multivariate Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12459">http://arxiv.org/abs/2308.12459</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emilio Ruiz-Moreno, Luis Miguel López-Ramos, Baltasar Beferull-Lozano</li>
</ul>
<p>Abstract:<br>Digitalizing real-world analog signals typically involves sampling in time and discretizing in amplitude. Subsequent signal reconstructions inevitably incur an error that depends on the amplitude resolution and the temporal density of the acquired samples. From an implementation viewpoint, consistent signal reconstruction methods have proven a profitable error-rate decay as the sampling rate increases. Despite that, these results are obtained under offline settings. Therefore, a research gap exists regarding methods for consistent signal reconstruction from data streams. This paper presents a method that consistently reconstructs streamed multivariate time series of quantization intervals under a zero-delay response requirement. On the other hand, previous work has shown that the temporal dependencies within univariate time series can be exploited to reduce the roughness of zero-delay signal reconstructions. This work shows that the spatiotemporal dependencies within multivariate time series can also be exploited to achieve improved results. Specifically, the spatiotemporal dependencies of the multivariate time series are learned, with the assistance of a recurrent neural network, to reduce the roughness of the signal reconstruction on average while ensuring consistency. Our experiments show that our proposed method achieves a favorable error-rate decay with the sampling rate compared to a similar but non-consistent reconstruction.</p>
<hr>
<h2 id="PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning"><a href="#PFL-GAN-When-Client-Heterogeneity-Meets-Generative-Models-in-Personalized-Federated-Learning" class="headerlink" title="PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning"></a>PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12454">http://arxiv.org/abs/2308.12454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Achintha Wijesinghe, Songyang Zhang, Zhi Ding</li>
</ul>
<p>Abstract:<br>Recent advances of generative learning models are accompanied by the growing interest in federated learning (FL) based on generative adversarial network (GAN) models. In the context of FL, GAN can capture the underlying client data structure, and regenerate samples resembling the original data distribution without compromising the private raw data. Although most existing GAN-based FL works focus on training a global model, Personalized FL (PFL) sometimes can be more effective in view of client data heterogeneity in terms of distinct data sample distributions, feature spaces, and labels. To cope with client heterogeneity in GAN-based FL, we propose a novel GAN sharing and aggregation strategy for PFL. The proposed PFL-GAN addresses the client heterogeneity in different scenarios. More specially, we first learn the similarity among clients and then develop an weighted collaborative data aggregation. The empirical results through the rigorous experimentation on several well-known datasets demonstrate the effectiveness of PFL-GAN.</p>
<hr>
<h2 id="Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models"><a href="#Augmenting-medical-image-classifiers-with-synthetic-data-from-latent-diffusion-models" class="headerlink" title="Augmenting medical image classifiers with synthetic data from latent diffusion models"></a>Augmenting medical image classifiers with synthetic data from latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12453">http://arxiv.org/abs/2308.12453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke W. Sagers, James A. Diao, Luke Melas-Kyriazi, Matthew Groh, Pranav Rajpurkar, Adewole S. Adamson, Veronica Rotemberg, Roxana Daneshjou, Arjun K. Manrai</li>
</ul>
<p>Abstract:<br>While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using several generation strategies. Our results suggest that synthetic data could serve as a force-multiplier for model development, but the collection of diverse real-world data remains the most important step to improve medical AI algorithms.</p>
<hr>
<h2 id="An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems"><a href="#An-Intentional-Forgetting-Driven-Self-Healing-Method-For-Deep-Reinforcement-Learning-Systems" class="headerlink" title="An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems"></a>An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12445">http://arxiv.org/abs/2308.12445</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahmedhajyahmed/drdrl">https://github.com/ahmedhajyahmed/drdrl</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Rached Bouchoucha, Houssem Ben Braiek, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment’s conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases the DRL system’s minor behaviors to systematically prioritize the adaptation of the key problem-solving skills. Using well-established DRL algorithms, Dr. DRL is compared with vanilla CL on various drifted environments. Dr. DRL is able to reduce, on average, the healing time and fine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully helps agents to adapt to 19.63% of drifted environments left unsolved by vanilla CL while maintaining and even enhancing by up to 45% the obtained rewards for drifted environments that are resolved by both approaches.</p>
<hr>
<h2 id="TAI-GAN-Temporally-and-Anatomically-Informed-GAN-for-early-to-late-frame-conversion-in-dynamic-cardiac-PET-motion-correction"><a href="#TAI-GAN-Temporally-and-Anatomically-Informed-GAN-for-early-to-late-frame-conversion-in-dynamic-cardiac-PET-motion-correction" class="headerlink" title="TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction"></a>TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12443">http://arxiv.org/abs/2308.12443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gxq1998/tai-gan">https://github.com/gxq1998/tai-gan</a></li>
<li>paper_authors: Xueqi Guo, Luyao Shi, Xiongchao Chen, Bo Zhou, Qiong Liu, Huidong Xie, Yi-Hwa Liu, Richard Palyo, Edward J. Miller, Albert J. Sinusas, Bruce Spottiswoode, Chi Liu, Nicha C. Dvornek</li>
</ul>
<p>Abstract:<br>The rapid tracer kinetics of rubidium-82 ($^{82}$Rb) and high variation of cross-frame distribution in dynamic cardiac positron emission tomography (PET) raise significant challenges for inter-frame motion correction, particularly for the early frames where conventional intensity-based image registration techniques are not applicable. Alternatively, a promising approach utilizes generative methods to handle the tracer distribution changes to assist existing registration methods. To improve frame-wise registration and parametric quantification, we propose a Temporally and Anatomically Informed Generative Adversarial Network (TAI-GAN) to transform the early frames into the late reference frame using an all-to-one mapping. Specifically, a feature-wise linear modulation layer encodes channel-wise parameters generated from temporal tracer kinetics information, and rough cardiac segmentations with local shifts serve as the anatomical information. We validated our proposed method on a clinical $^{82}$Rb PET dataset and found that our TAI-GAN can produce converted early frames with high image quality, comparable to the real reference frames. After TAI-GAN conversion, motion estimation accuracy and clinical myocardial blood flow (MBF) quantification were improved compared to using the original frames. Our code is published at <a target="_blank" rel="noopener" href="https://github.com/gxq1998/TAI-GAN">https://github.com/gxq1998/TAI-GAN</a>.</p>
<hr>
<h2 id="BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection"><a href="#BaDExpert-Extracting-Backdoor-Functionality-for-Accurate-Backdoor-Input-Detection" class="headerlink" title="BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection"></a>BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12439">http://arxiv.org/abs/2308.12439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tinghao Xie, Xiangyu Qi, Ping He, Yiming Li, Jiachen T. Wang, Prateek Mittal</li>
</ul>
<p>Abstract:<br>We present a novel defense, against backdoor attacks on Deep Neural Networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. The proposed defense is built upon a novel reverse engineering approach that can directly extract backdoor functionality of a given backdoored model to a backdoor expert model. The approach is straightforward – finetuning the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising highly accurate backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by an ensemble strategy with a finetuned auxiliary model, our defense, BaDExpert (Backdoor Input Detection with Backdoor Expert), effectively mitigates 16 SOTA backdoor attacks while minimally impacting clean utility. The effectiveness of BaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet) across various model architectures (ResNet, VGG, MobileNetV2 and Vision Transformer).</p>
<hr>
<h2 id="Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges"><a href="#Deploying-Deep-Reinforcement-Learning-Systems-A-Taxonomy-of-Challenges" class="headerlink" title="Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges"></a>Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12438">http://arxiv.org/abs/2308.12438</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/drldeploymentchallenges-icsme2023/replicationpackage">https://github.com/drldeploymentchallenges-icsme2023/replicationpackage</a></li>
<li>paper_authors: Ahmed Haj Yahmed, Altaf Allah Abbassi, Amin Nikanjam, Heng Li, Foutse Khomh</li>
</ul>
<p>Abstract:<br>Deep reinforcement learning (DRL), leveraging Deep Learning (DL) in reinforcement learning, has shown significant potential in achieving human-level autonomy in a wide range of domains, including robotics, computer vision, and computer games. This potential justifies the enthusiasm and growing interest in DRL in both academia and industry. However, the community currently focuses mostly on the development phase of DRL systems, with little attention devoted to DRL deployment. In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&amp;A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems. Specifically, we categorized relevant SO posts by deployment platforms: server&#x2F;cloud, mobile&#x2F;embedded system, browser, and game engine. After filtering and manual analysis, we examined 357 SO posts about DRL deployment, investigated the current state, and identified the challenges related to deploying DRL systems. Then, we investigate the prevalence and difficulty of these challenges. Results show that the general interest in DRL deployment is growing, confirming the study’s relevance and importance. Results also show that DRL deployment is more difficult than other DRL issues. Additionally, we built a taxonomy of 31 unique challenges in deploying DRL to different platforms. On all platforms, RL environment-related challenges are the most popular, and communication-related challenges are the most difficult among practitioners. We hope our study inspires future research and helps the community overcome the most common and difficult challenges practitioners face when deploying DRL systems.</p>
<hr>
<h2 id="Evolution-of-ESG-focused-DLT-Research-An-NLP-Analysis-of-the-Literature"><a href="#Evolution-of-ESG-focused-DLT-Research-An-NLP-Analysis-of-the-Literature" class="headerlink" title="Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature"></a>Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12420">http://arxiv.org/abs/2308.12420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walter Hernandez, Kamil Tylinski, Alastair Moore, Niall Roche, Nikhil Vadgama, Horst Treiblmaier, Jiangbo Shangguan, Paolo Tasca, Jiahua Xu</li>
</ul>
<p>Abstract:<br>Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating comprehensive insights into their diverse components. However, a systematic literature review that emphasizes the Environmental, Sustainability, and Governance (ESG) components of DLT remains lacking. To bridge this gap, we selected 107 seed papers to build a citation network of 63,083 references and refined it to a corpus of 24,539 publications for analysis. Then, we labeled the named entities in 46 papers according to twelve top-level categories derived from an established technology taxonomy and enhanced the taxonomy by pinpointing DLT’s ESG elements. Leveraging transformer-based language models, we fine-tuned a pre-trained language model for a Named Entity Recognition (NER) task using our labeled dataset. We used our fine-tuned language model to distill the corpus to 505 key papers, facilitating a literature review via named entities and temporal graph analysis on DLT evolution in the context of ESG. Our contributions are a methodology to conduct a machine learning-driven systematic literature review in the DLT field, placing a special emphasis on ESG aspects. Furthermore, we present a first-of-its-kind NER dataset, composed of 54,808 named entities, designed for DLT and ESG-related explorations.</p>
<hr>
<h2 id="Machine-learning-in-parameter-estimation-of-nonlinear-systems"><a href="#Machine-learning-in-parameter-estimation-of-nonlinear-systems" class="headerlink" title="Machine learning in parameter estimation of nonlinear systems"></a>Machine learning in parameter estimation of nonlinear systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12393">http://arxiv.org/abs/2308.12393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaushal Kumar</li>
</ul>
<p>Abstract:<br>Accurately estimating parameters in complex nonlinear systems is crucial across scientific and engineering fields. We present a novel approach for parameter estimation using a neural network with the Huber loss function. This method taps into deep learning’s abilities to uncover parameters governing intricate behaviors in nonlinear equations. We validate our approach using synthetic data and predefined functions that model system dynamics. By training the neural network with noisy time series data, it fine-tunes the Huber loss function to converge to accurate parameters. We apply our method to damped oscillators, Van der Pol oscillators, Lotka-Volterra systems, and Lorenz systems under multiplicative noise. The trained neural network accurately estimates parameters, evident from closely matching latent dynamics. Comparing true and estimated trajectories visually reinforces our method’s precision and robustness. Our study underscores the Huber loss-guided neural network as a versatile tool for parameter estimation, effectively uncovering complex relationships in nonlinear systems. The method navigates noise and uncertainty adeptly, showcasing its adaptability to real-world challenges.</p>
<hr>
<h2 id="FOSA-Full-Information-Maximum-Likelihood-FIML-Optimized-Self-Attention-Imputation-for-Missing-Data"><a href="#FOSA-Full-Information-Maximum-Likelihood-FIML-Optimized-Self-Attention-Imputation-for-Missing-Data" class="headerlink" title="FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data"></a>FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12388">http://arxiv.org/abs/2308.12388</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oudeng/fosa">https://github.com/oudeng/fosa</a></li>
<li>paper_authors: Ou Deng, Qun Jin</li>
</ul>
<p>Abstract:<br>In data imputation, effectively addressing missing values is pivotal, especially in intricate datasets. This paper delves into the FIML Optimized Self-attention (FOSA) framework, an innovative approach that amalgamates the strengths of Full Information Maximum Likelihood (FIML) estimation with the capabilities of self-attention neural networks. Our methodology commences with an initial estimation of missing values via FIML, subsequently refining these estimates by leveraging the self-attention mechanism. Our comprehensive experiments on both simulated and real-world datasets underscore FOSA’s pronounced advantages over traditional FIML techniques, encapsulating facets of accuracy, computational efficiency, and adaptability to diverse data structures. Intriguingly, even in scenarios where the Structural Equation Model (SEM) might be mis-specified, leading to suboptimal FIML estimates, the robust architecture of FOSA’s self-attention component adeptly rectifies and optimizes the imputation outcomes. Our empirical tests reveal that FOSA consistently delivers commendable predictions, even in the face of up to 40% random missingness, highlighting its robustness and potential for wide-scale applications in data imputation.</p>
<hr>
<h2 id="Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation"><a href="#Open-set-Face-Recognition-with-Neural-Ensemble-Maximal-Entropy-Loss-and-Feature-Augmentation" class="headerlink" title="Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation"></a>Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12371">http://arxiv.org/abs/2308.12371</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rafael Henrique Vareto, Manuel Günther, William Robson Schwartz</li>
</ul>
<p>Abstract:<br>Open-set face recognition refers to a scenario in which biometric systems have incomplete knowledge of all existing subjects. Therefore, they are expected to prevent face samples of unregistered subjects from being identified as previously enrolled identities. This watchlist context adds an arduous requirement that calls for the dismissal of irrelevant faces by focusing mainly on subjects of interest. As a response, this work introduces a novel method that associates an ensemble of compact neural networks with a margin-based cost function that explores additional samples. Supplementary negative samples can be obtained from external databases or synthetically built at the representation level in training time with a new mix-up feature augmentation approach. Deep neural networks pre-trained on large face datasets serve as the preliminary feature extraction module. We carry out experiments on well-known LFW and IJB-C datasets where results show that the approach is able to boost closed and open-set identification rates.</p>
<hr>
<h2 id="SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies"><a href="#SafeAR-Towards-Safer-Algorithmic-Recourse-by-Risk-Aware-Policies" class="headerlink" title="SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies"></a>SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12367">http://arxiv.org/abs/2308.12367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochen Wu, Shubham Sharma, Sunandita Patra, Sriram Gopalakrishnan</li>
</ul>
<p>Abstract:<br>With the growing use of machine learning (ML) models in critical domains such as finance and healthcare, the need to offer recourse for those adversely affected by the decisions of ML models has become more important; individuals ought to be provided with recommendations on actions to take for improving their situation and thus receive a favorable decision. Prior work on sequential algorithmic recourse – which recommends a series of changes – focuses on action feasibility and uses the proximity of feature changes to determine action costs. However, the uncertainties of feature changes and the risk of higher than average costs in recourse have not been considered. It is undesirable if a recourse could (with some probability) result in a worse situation from which recovery requires an extremely high cost. It is essential to incorporate risks when computing and evaluating recourse. We call the recourse computed with such risk considerations as Safer Algorithmic Recourse (SafeAR). The objective is to empower people to choose a recourse based on their risk tolerance. In this work, we discuss and show how existing recourse desiderata can fail to capture the risk of higher costs. We present a method to compute recourse policies that consider variability in cost and connect algorithmic recourse literature with risk-sensitive reinforcement learning. We also adopt measures <code>Value at Risk&#39;&#39; and </code>Conditional Value at Risk’’ from the financial literature to summarize risk concisely. We apply our method to two real-world datasets and compare policies with different levels of risk-aversion using risk measures and recourse desiderata (sparsity and proximity).</p>
<hr>
<h2 id="Renormalizing-Diffusion-Models"><a href="#Renormalizing-Diffusion-Models" class="headerlink" title="Renormalizing Diffusion Models"></a>Renormalizing Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12355">http://arxiv.org/abs/2308.12355</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan Cotler, Semon Rezchikov</li>
</ul>
<p>Abstract:<br>We explain how to use diffusion models to learn inverse renormalization group flows of statistical and quantum field theories. Diffusion models are a class of machine learning models which have been used to generate samples from complex distributions, such as the distribution of natural images, by learning the inverse process to a diffusion process which adds noise to the data until the distribution of the data is pure noise. Nonperturbative renormalization group schemes can naturally be written as diffusion processes in the space of fields. We combine these observations in a concrete framework for building ML-based models for studying field theories, in which the models learn the inverse process to an explicitly-specified renormalization group scheme. We detail how these models define a class of adaptive bridge (or parallel tempering) samplers for lattice field theory. Because renormalization group schemes have a physical meaning, we provide explicit prescriptions for how to compare results derived from models associated to several different renormalization group schemes of interest. We also explain how to use diffusion models in a variational method to find ground states of quantum systems. We apply some of our methods to numerically find RG flows of interacting statistical field theories. From the perspective of machine learning, our work provides an interpretation of multiscale diffusion models, and gives physically-inspired suggestions for diffusion models which should have novel properties.</p>
<hr>
<h2 id="Improving-Generative-Model-based-Unfolding-with-Schrodinger-Bridges"><a href="#Improving-Generative-Model-based-Unfolding-with-Schrodinger-Bridges" class="headerlink" title="Improving Generative Model-based Unfolding with Schrödinger Bridges"></a>Improving Generative Model-based Unfolding with Schrödinger Bridges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12351">http://arxiv.org/abs/2308.12351</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sascha Diefenbacher, Guan-Horng Liu, Vinicius Mikuni, Benjamin Nachman, Weili Nie</li>
</ul>
<p>Abstract:<br>Machine learning-based unfolding has enabled unbinned and high-dimensional differential cross section measurements. Two main approaches have emerged in this research area: one based on discriminative models and one based on generative models. The main advantage of discriminative models is that they learn a small correction to a starting simulation while generative models scale better to regions of phase space with little data. We propose to use Schroedinger Bridges and diffusion models to create SBUnfold, an unfolding approach that combines the strengths of both discriminative and generative models. The key feature of SBUnfold is that its generative model maps one set of events into another without having to go through a known probability density as is the case for normalizing flows and standard diffusion models. We show that SBUnfold achieves excellent performance compared to state of the art methods on a synthetic Z+jets dataset.</p>
<hr>
<h2 id="D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification"><a href="#D4-Improving-LLM-Pretraining-via-Document-De-Duplication-and-Diversification" class="headerlink" title="D4: Improving LLM Pretraining via Document De-Duplication and Diversification"></a>D4: Improving LLM Pretraining via Document De-Duplication and Diversification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12284">http://arxiv.org/abs/2308.12284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushal Tirumala, Daniel Simig, Armen Aghajanyan, Ari S. Morcos</li>
</ul>
<p>Abstract:<br>Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent performance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as MinHash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.</p>
<hr>
<h2 id="Extended-Linear-Regression-A-Kalman-Filter-Approach-for-Minimizing-Loss-via-Area-Under-the-Curve"><a href="#Extended-Linear-Regression-A-Kalman-Filter-Approach-for-Minimizing-Loss-via-Area-Under-the-Curve" class="headerlink" title="Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve"></a>Extended Linear Regression: A Kalman Filter Approach for Minimizing Loss via Area Under the Curve</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12280">http://arxiv.org/abs/2308.12280</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gokulprasath R</li>
</ul>
<p>Abstract:<br>This research enhances linear regression models by integrating a Kalman filter and analysing curve areas to minimize loss. The goal is to develop an optimal linear regression equation using stochastic gradient descent (SGD) for weight updating. Our approach involves a stepwise process, starting with user-defined parameters. The linear regression model is trained using SGD, tracking weights and loss separately and zipping them finally. A Kalman filter is then trained based on weight and loss arrays to predict the next consolidated weights. Predictions result from multiplying input averages with weights, evaluated for loss to form a weight-versus-loss curve. The curve’s equation is derived using the two-point formula, and area under the curve is calculated via integration. The linear regression equation with minimum area becomes the optimal curve for prediction. Benefits include avoiding constant weight updates via gradient descent and working with partial datasets, unlike methods needing the entire set. However, computational complexity should be considered. The Kalman filter’s accuracy might diminish beyond a certain prediction range.</p>
<hr>
<h2 id="On-Manifold-Projected-Gradient-Descent"><a href="#On-Manifold-Projected-Gradient-Descent" class="headerlink" title="On-Manifold Projected Gradient Descent"></a>On-Manifold Projected Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12279">http://arxiv.org/abs/2308.12279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aaron Mahler, Tyrus Berry, Tom Stephens, Harbir Antil, Michael Merritt, Jeanie Schreiber, Ioannis Kevrekidis</li>
</ul>
<p>Abstract:<br>This work provides a computable, direct, and mathematically rigorous approximation to the differential geometry of class manifolds for high-dimensional data, along with nonlinear projections from input space onto these class manifolds. The tools are applied to the setting of neural network image classifiers, where we generate novel, on-manifold data samples, and implement a projected gradient descent algorithm for on-manifold adversarial training. The susceptibility of neural networks (NNs) to adversarial attack highlights the brittle nature of NN decision boundaries in input space. Introducing adversarial examples during training has been shown to reduce the susceptibility of NNs to adversarial attack; however, it has also been shown to reduce the accuracy of the classifier if the examples are not valid examples for that class. Realistic “on-manifold” examples have been previously generated from class manifolds in the latent of an autoencoder. Our work explores these phenomena in a geometric and computational setting that is much closer to the raw, high-dimensional input space than can be provided by VAE or other black box dimensionality reductions. We employ conformally invariant diffusion maps (CIDM) to approximate class manifolds in diffusion coordinates, and develop the Nystr&quot;{o}m projection to project novel points onto class manifolds in this setting. On top of the manifold approximation, we leverage the spectral exterior calculus (SEC) to determine geometric quantities such as tangent vectors of the manifold. We use these tools to obtain adversarial examples that reside on a class manifold, yet fool a classifier. These misclassifications then become explainable in terms of human-understandable manipulations within the data, by expressing the on-manifold adversary in the semantic basis on the manifold.</p>
<hr>
<h2 id="LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition"><a href="#LCANets-Robust-Audio-Classification-using-Multi-layer-Neural-Networks-with-Lateral-Competition" class="headerlink" title="LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition"></a>LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12882">http://arxiv.org/abs/2308.12882</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sayanton V. Dibbo, Juston S. Moore, Garrett T. Kenyon, Michael A. Teti</li>
</ul>
<p>Abstract:<br>Audio classification aims at recognizing audio signals, including speech commands or sound events. However, current audio classifiers are susceptible to perturbations and adversarial attacks. In addition, real-world audio classification tasks often suffer from limited labeled data. To help bridge these gaps, previous work developed neuro-inspired convolutional neural networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA) in the first layer (i.e., LCANets) for computer vision. LCANets learn in a combination of supervised and unsupervised learning, reducing dependency on labeled samples. Motivated by the fact that auditory cortex is also sparse, we extend LCANets to audio recognition tasks and introduce LCANets++, which are CNNs that perform sparse coding in multiple layers via LCA. We demonstrate that LCANets++ are more robust than standard CNNs and LCANets against perturbations, e.g., background noise, as well as black-box and white-box attacks, e.g., evasion and fast gradient sign (FGSM) attacks.</p>
<hr>
<h2 id="Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning"><a href="#Language-Reward-Modulation-for-Pretraining-Reinforcement-Learning" class="headerlink" title="Language Reward Modulation for Pretraining Reinforcement Learning"></a>Language Reward Modulation for Pretraining Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12270">http://arxiv.org/abs/2308.12270</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ademiadeniji/lamp">https://github.com/ademiadeniji/lamp</a></li>
<li>paper_authors: Ademi Adeniji, Amber Xie, Carmelo Sferrazza, Younggyo Seo, Stephen James, Pieter Abbeel</li>
</ul>
<p>Abstract:<br>Using learned reward functions (LRFs) as a means to solve sparse-reward reinforcement learning (RL) tasks has yielded some steady progress in task-complexity through the years. In this work, we question whether today’s LRFs are best-suited as a direct replacement for task rewards. Instead, we propose leveraging the capabilities of LRFs as a pretraining signal for RL. Concretely, we propose $\textbf{LA}$nguage Reward $\textbf{M}$odulated $\textbf{P}$retraining (LAMP) which leverages the zero-shot capabilities of Vision-Language Models (VLMs) as a $\textit{pretraining}$ utility for RL as opposed to a downstream task reward. LAMP uses a frozen, pretrained VLM to scalably generate noisy, albeit shaped exploration rewards by computing the contrastive alignment between a highly diverse collection of language instructions and the image observations of an agent in its pretraining environment. LAMP optimizes these rewards in conjunction with standard novelty-seeking exploration rewards with reinforcement learning to acquire a language-conditioned, pretrained policy. Our VLM pretraining approach, which is a departure from previous attempts to use LRFs, can warmstart sample-efficient learning on robot manipulation tasks in RLBench.</p>
<hr>
<h2 id="FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning"><a href="#FECoM-A-Step-towards-Fine-Grained-Energy-Measurement-for-Deep-Learning" class="headerlink" title="FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning"></a>FECoM: A Step towards Fine-Grained Energy Measurement for Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12264">http://arxiv.org/abs/2308.12264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabhsingh Rajput, Tim Widmayer, Ziyuan Shang, Maria Kechagia, Federica Sarro, Tushar Sharma</li>
</ul>
<p>Abstract:<br>With the increasing usage, scale, and complexity of Deep Learning (DL) models, their rapidly growing energy consumption has become a critical concern. Promoting green development and energy awareness at different granularities is the need of the hour to limit carbon emissions of DL systems. However, the lack of standard and repeatable tools to accurately measure and optimize energy consumption at a fine granularity (e.g., at method level) hinders progress in this area. In this paper, we introduce FECoM (Fine-grained Energy Consumption Meter), a framework for fine-grained DL energy consumption measurement. Specifically, FECoM provides researchers and developers a mechanism to profile DL APIs. FECoM addresses the challenges of measuring energy consumption at fine-grained level by using static instrumentation and considering various factors, including computational load and temperature stability. We assess FECoM’s capability to measure fine-grained energy consumption for one of the most popular open-source DL frameworks, namely TensorFlow. Using FECoM, we also investigate the impact of parameter size and execution time on energy consumption, enriching our understanding of TensorFlow APIs’ energy profiles. Furthermore, we elaborate on the considerations, issues, and challenges that one needs to consider while designing and implementing a fine-grained energy consumption measurement tool. We hope this work will facilitate further advances in DL energy measurement and the development of energy-aware practices for DL systems.</p>
<hr>
<h2 id="Learning-from-Negative-User-Feedback-and-Measuring-Responsiveness-for-Sequential-Recommenders"><a href="#Learning-from-Negative-User-Feedback-and-Measuring-Responsiveness-for-Sequential-Recommenders" class="headerlink" title="Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders"></a>Learning from Negative User Feedback and Measuring Responsiveness for Sequential Recommenders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12256">http://arxiv.org/abs/2308.12256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yueqi Wang, Yoni Halpern, Shuo Chang, Jingchen Feng, Elaine Ya Le, Longfei Li, Xujian Liang, Min-Cheng Huang, Shane Li, Alex Beutel, Yaping Zhang, Shuchao Bi</li>
</ul>
<p>Abstract:<br>Sequential recommenders have been widely used in industry due to their strength in modeling user preferences. While these models excel at learning a user’s positive interests, less attention has been paid to learning from negative user feedback. Negative user feedback is an important lever of user control, and comes with an expectation that recommenders should respond quickly and reduce similar recommendations to the user. However, negative feedback signals are often ignored in the training objective of sequential retrieval models, which primarily aim at predicting positive user interactions. In this work, we incorporate explicit and implicit negative user feedback into the training objective of sequential recommenders in the retrieval stage using a “not-to-recommend” loss function that optimizes for the log-likelihood of not recommending items with negative feedback. We demonstrate the effectiveness of this approach using live experiments on a large-scale industrial recommender system. Furthermore, we address a challenge in measuring recommender responsiveness to negative feedback by developing a counterfactual simulation framework to compare recommender responses between different user actions, showing improved responsiveness from the modeling change.</p>
<hr>
<h2 id="How-Safe-Am-I-Given-What-I-See-Calibrated-Prediction-of-Safety-Chances-for-Image-Controlled-Autonomy"><a href="#How-Safe-Am-I-Given-What-I-See-Calibrated-Prediction-of-Safety-Chances-for-Image-Controlled-Autonomy" class="headerlink" title="How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy"></a>How Safe Am I Given What I See? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12252">http://arxiv.org/abs/2308.12252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maozj6/hsai-predictor">https://github.com/maozj6/hsai-predictor</a></li>
<li>paper_authors: Zhenjiang Mao, Carson Sobolewski, Ivan Ruchkin</li>
</ul>
<p>Abstract:<br>End-to-end learning has emerged as a major paradigm for developing autonomous systems. Unfortunately, with its performance and convenience comes an even greater challenge of safety assurance. A key factor of this challenge is the absence of the notion of a low-dimensional and interpretable dynamical state, around which traditional assurance methods revolve. Focusing on the online safety prediction problem, this paper proposes a configurable family of learning pipelines based on generative world models, which do not require low-dimensional states. To implement these pipelines, we overcome the challenges of learning safety-informed latent representations and missing safety labels under prediction-induced distribution shift. These pipelines come with statistical calibration guarantees on their safety chance predictions based on conformal prediction. We perform an extensive evaluation of the proposed learning pipelines on two case studies of image-controlled systems: a racing car and a cartpole.</p>
<hr>
<h2 id="How-to-Protect-Copyright-Data-in-Optimization-of-Large-Language-Models"><a href="#How-to-Protect-Copyright-Data-in-Optimization-of-Large-Language-Models" class="headerlink" title="How to Protect Copyright Data in Optimization of Large Language Models?"></a>How to Protect Copyright Data in Optimization of Large Language Models?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12247">http://arxiv.org/abs/2308.12247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy Chu, Zhao Song, Chiwun Yang</li>
</ul>
<p>Abstract:<br>Large language models (LLMs) and generative AI have played a transformative role in computer research and applications. Controversy has arisen as to whether these models output copyrighted data, which can occur if the data the models are trained on is copyrighted. LLMs are built on the transformer neural network architecture, which in turn relies on a mathematical computation called Attention that uses the softmax function.   In this paper, we show that large language model training and optimization can be seen as a softmax regression problem. We then establish a method of efficiently performing softmax regression, in a way that prevents the regression function from generating copyright data. This establishes a theoretical method of training large language models in a way that avoids generating copyright data.</p>
<hr>
<h2 id="Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training"><a href="#Multi-Objective-Optimization-for-Sparse-Deep-Neural-Network-Training" class="headerlink" title="Multi-Objective Optimization for Sparse Deep Neural Network Training"></a>Multi-Objective Optimization for Sparse Deep Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12243">http://arxiv.org/abs/2308.12243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/mdmtn">https://github.com/salomonhotegni/mdmtn</a></li>
<li>paper_authors: S. S. Hotegni, S. Peitz, M. Berkemeier</li>
</ul>
<p>Abstract:<br>Different conflicting optimization criteria arise naturally in various Deep Learning scenarios. These can address different main tasks (i.e., in the setting of Multi-Task Learning), but also main and secondary tasks such as loss minimization versus sparsity. The usual approach is a simple weighting of the criteria, which formally only works in the convex setting. In this paper, we present a Multi-Objective Optimization algorithm using a modified Weighted Chebyshev scalarization for training Deep Neural Networks (DNNs) with respect to several tasks. By employing this scalarization technique, the algorithm can identify all optimal solutions of the original problem while reducing its complexity to a sequence of single-objective problems. The simplified problems are then solved using an Augmented Lagrangian method, enabling the use of popular optimization techniques such as Adam and Stochastic Gradient Descent, while efficaciously handling constraints. Our work aims to address the (economical and also ecological) sustainability issue of DNN models, with a particular focus on Deep Multi-Task models, which are typically designed with a very large number of weights to perform equally well on multiple tasks. Through experiments conducted on two Machine Learning datasets, we demonstrate the possibility of adaptively sparsifying the model during training without significantly impacting its performance, if we are willing to apply task-specific adaptations to the network weights. Code is available at <a target="_blank" rel="noopener" href="https://github.com/salomonhotegni/MDMTN">https://github.com/salomonhotegni/MDMTN</a>.</p>
<hr>
<h2 id="Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks"><a href="#Critical-Learning-Periods-Emerge-Even-in-Deep-Linear-Networks" class="headerlink" title="Critical Learning Periods Emerge Even in Deep Linear Networks"></a>Critical Learning Periods Emerge Even in Deep Linear Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12221">http://arxiv.org/abs/2308.12221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kleinman, Alessandro Achille, Stefano Soatto</li>
</ul>
<p>Abstract:<br>Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology. Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks.</p>
<hr>
<h2 id="Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning"><a href="#Diffusion-Language-Models-Can-Perform-Many-Tasks-with-Scaling-and-Instruction-Finetuning" class="headerlink" title="Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning"></a>Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12219">http://arxiv.org/abs/2308.12219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yegcjs/diffusionllm">https://github.com/yegcjs/diffusionllm</a></li>
<li>paper_authors: Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, Quanquan Gu</li>
</ul>
<p>Abstract:<br>The recent surge of generative AI has been fueled by the generative power of diffusion probabilistic models and the scalable capabilities of large language models. Despite their potential, it remains elusive whether diffusion language models can solve general language tasks comparable to their autoregressive counterparts. This paper demonstrates that scaling diffusion models w.r.t. data, sizes, and tasks can effectively make them strong language learners. We build competent diffusion language models at scale by first acquiring knowledge from massive data via masked language modeling pretraining thanks to their intrinsic connections. We then reprogram pretrained masked language models into diffusion language models via diffusive adaptation, wherein task-specific finetuning and instruction finetuning are explored to unlock their versatility in solving general language tasks. Experiments show that scaling diffusion language models consistently improves performance across downstream language tasks. We further discover that instruction finetuning can elicit zero-shot and few-shot in-context learning abilities that help tackle many unseen tasks by following natural language instructions, and show promise in advanced and challenging abilities such as reasoning</p>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="http://nullscc.github.io/2023/08/24/cs.LG_2023_08_24/" data-id="cllqfouao001ga488ggtgedb6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next</a>
    </nav>
  

</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">26</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CR/">cs.CR</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">4</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
  <a href="#search" class="mobile-nav-link st-search-show-outputs">Search</a>
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


</div>
</body>
</html>
