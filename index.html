
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.AS_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/eess.AS_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T14:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/eess.AS_2023_11_20/">eess.AS - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-does-end-to-end-speech-recognition-training-impact-speech-enhancement-artifacts"><a href="#How-does-end-to-end-speech-recognition-training-impact-speech-enhancement-artifacts" class="headerlink" title="How does end-to-end speech recognition training impact speech enhancement artifacts?"></a>How does end-to-end speech recognition training impact speech enhancement artifacts?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11599">http://arxiv.org/abs/2311.11599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kazuma Iwamoto, Tsubasa Ochiai, Marc Delcroix, Rintaro Ikeshita, Hiroshi Sato, Shoko Araki, Shigeru Katagiri<br>for: 这 paper  investigate 如何使用 joint training 来 mitigate 单通道 speech enhancement (SE) 对 automatic speech recognition (ASR) 的影响。methods: 这 paper 使用 joint training 方法，将 SE 和 ASR 两个模块合作训练。results: 实验结果表明，ASR-level training 可以降低 artifact error，但会增加 noise error。此外，可以通过 interpolating 简单地将增强和观察到的信号进行拼接，以达到降低 artifact 和增加 noise 的效果，而不需要修改 SE 和 ASR 模块。这些发现可以帮助我们更好地理解 joint training 的效果，并提供一种 novel 的设计方法 для ASR agnostic SE 前端。<details>
<summary>Abstract</summary>
Jointly training a speech enhancement (SE) front-end and an automatic speech recognition (ASR) back-end has been investigated as a way to mitigate the influence of \emph{processing distortion} generated by single-channel SE on ASR. In this paper, we investigate the effect of such joint training on the signal-level characteristics of the enhanced signals from the viewpoint of the decomposed noise and artifact errors. The experimental analyses provide two novel findings: 1) ASR-level training of the SE front-end reduces the artifact errors while increasing the noise errors, and 2) simply interpolating the enhanced and observed signals, which achieves a similar effect of reducing artifacts and increasing noise, improves ASR performance without jointly modifying the SE and ASR modules, even for a strong ASR back-end using a WavLM feature extractor. Our findings provide a better understanding of the effect of joint training and a novel insight for designing an ASR agnostic SE front-end.
</details>
<details>
<summary>摘要</summary>
jointly 训练一个 speech enhancement（SE）前端和一个 automatic speech recognition（ASR）后端，以减少单通道 SE 处理损害对 ASR 的影响。在这篇论文中，我们研究了将这种联合训练对减去频率特征的影响。我们的实验分析结果表明，1）ASR 级别训练 SE 前端可以降低artifact误差，但是增加雑音误差。2）简单地 interpolating 减去和观察的信号，可以达到降低artifacts和增加雑音的效果，提高 ASR 性能，即使使用强大的 ASR 后端使用 WavLM 特征提取器。我们的发现可以为我们更好地理解联合训练的影响，并提供一种 ASR 无关的 SE 前端设计的新思路。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Neural-network-based-virtual-microphone-estimation-with-virtual-microphone-and-beamformer-level-multi-task-loss"><a href="#Neural-network-based-virtual-microphone-estimation-with-virtual-microphone-and-beamformer-level-multi-task-loss" class="headerlink" title="Neural network-based virtual microphone estimation with virtual microphone and beamformer-level multi-task loss"></a>Neural network-based virtual microphone estimation with virtual microphone and beamformer-level multi-task loss</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11595">http://arxiv.org/abs/2311.11595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanako Segawa, Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani, Rintaro Ikeshita, Shoko Araki, Takeshi Yamada, Shoji Makino</li>
<li>for: 提高降噪抑制性能</li>
<li>methods: 使用神经网络预测虚拟麦克风信号</li>
<li>results: 实现33.1%的相对噪音抑制性能提高和10.8%的相对预测性能提高<details>
<summary>Abstract</summary>
Array processing performance depends on the number of microphones available. Virtual microphone estimation (VME) has been proposed to increase the number of microphone signals artificially. Neural network-based VME (NN-VME) trains an NN with a VM-level loss to predict a signal at a microphone location that is available during training but not at inference. However, this training objective may not be optimal for a specific array processing back-end, such as beamforming. An alternative approach is to use a training objective considering the array-processing back-end, such as a loss on the beamformer output. This approach may generate signals optimal for beamforming but not physically grounded. To combine the advantages of both approaches, this paper proposes a multi-task loss for NN-VME that combines both VM-level and beamformer-level losses. We evaluate the proposed multi-task NN-VME on multi-talker underdetermined conditions and show that it achieves a 33.1 % relative WER improvement compared to using only real microphones and 10.8 % compared to using a prior NN-VME approach.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本）数组处理性能取决于可用的麦克风数量。虚拟麦克风估计（VME）已经提议以增加虚拟麦克风信号的数量。基于神经网络的VME（NN-VME）将神经网络训练为预测在训练过程中可用的麦克风位置上的信号，但在推理过程中不可用。这种训练目标可能并不适合特定的数组处理后端，如扩排器。一种另一种方法是使用包含数组处理后端的训练目标，如扩排器输出的损失函数。这种方法可能生成适合扩排器的信号，但不是物理上的。为了结合这两种方法的优点，这篇文章提出了一种多任务损失函数 дляNN-VME，将VM级别和扩排器级别的损失函数组合在一起。我们对多话者下的多个麦克风不足Conditions进行评估，并显示了使用提议的多任务NN-VME的33.1%相对WRER提升和10.8%相对于使用真正的麦克风和NN-VME先前方法的提升。
</details></li>
</ul>
<hr>
<h2 id="APNet2-High-quality-and-High-efficiency-Neural-Vocoder-with-Direct-Prediction-of-Amplitude-and-Phase-Spectra"><a href="#APNet2-High-quality-and-High-efficiency-Neural-Vocoder-with-Direct-Prediction-of-Amplitude-and-Phase-Spectra" class="headerlink" title="APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra"></a>APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11545">http://arxiv.org/abs/2311.11545</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui-Peng Du, Ye-Xin Lu, Yang Ai, Zhen-Hua Ling</li>
<li>for: 提高高质量语音合成的实时速度</li>
<li>methods: 使用ConvNeXt v2作为后凝网络，并引入多分辨率评估器（MRD），优化某些损失函数的形式</li>
<li>results: 在常规配置下（采样率22.05 kHz，spectral frame shift256点，约11.6ms），提出的APNet2 vocoder比原APNet和Vocos vocoder在生成的语音质量方面表现出色，同时具有较快的推理速度，与HiFi-GAN和iSTFTNet的语音质量相当，但具有更快的推理速度。<details>
<summary>Abstract</summary>
In our previous work, we proposed a neural vocoder called APNet, which directly predicts speech amplitude and phase spectra with a 5 ms frame shift in parallel from the input acoustic features, and then reconstructs the 16 kHz speech waveform using inverse short-time Fourier transform (ISTFT). APNet demonstrates the capability to generate synthesized speech of comparable quality to the HiFi-GAN vocoder but with a considerably improved inference speed. However, the performance of the APNet vocoder is constrained by the waveform sampling rate and spectral frame shift, limiting its practicality for high-quality speech synthesis. Therefore, this paper proposes an improved iteration of APNet, named APNet2. The proposed APNet2 vocoder adopts ConvNeXt v2 as the backbone network for amplitude and phase predictions, expecting to enhance the modeling capability. Additionally, we introduce a multi-resolution discriminator (MRD) into the GAN-based losses and optimize the form of certain losses. At a common configuration with a waveform sampling rate of 22.05 kHz and spectral frame shift of 256 points (i.e., approximately 11.6ms), our proposed APNet2 vocoder outperformed the original APNet and Vocos vocoders in terms of synthesized speech quality. The synthesized speech quality of APNet2 is also comparable to that of HiFi-GAN and iSTFTNet, while offering a significantly faster inference speed.
</details>
<details>
<summary>摘要</summary>
在我们之前的工作中，我们提出了一种神经网络模型called APNet，它直接预测了语音幅度和相位spectrum的5 ms帧shift并使用反时域 Fourier transform (ISTFT)重建16 kHz语音波形。APNet示出了与HiFi-GAN vocoder相同的质量的生成语音，但是具有显著提高的推理速度。然而，APNet的性能受到波形采样率和spectral frame shift的限制，这限制了其在高质量语音生成中的实用性。因此，这篇文章提出了APNet2 vocoder的改进版本。我们在APNet2 vocoder中采用了ConvNeXt v2作为幅度和相位预测的后IONetwork，以提高模型的能力。此外，我们还引入了多resolution discriminator (MRD)到GAN-based的损失中，并优化了certain的损失形式。在常见的配置下（即22.05 kHz的波形采样率和256个spectral frame shift，约等于11.6ms），我们的提案的APNet2 vocoder在与原始APNet和Vocos vocoders的比较中赢得了生成语音质量的比赛。APNet2的生成语音质量也与HiFi-GAN和iSTFTNet相当，而且提供了显著 faster的推理速度。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/eess.AS_2023_11_20/" data-id="clp89domi016bi7884vpn6m3t" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.CV_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T13:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.CV_2023_11_20/">cs.CV - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="PF-LRM-Pose-Free-Large-Reconstruction-Model-for-Joint-Pose-and-Shape-Prediction"><a href="#PF-LRM-Pose-Free-Large-Reconstruction-Model-for-Joint-Pose-and-Shape-Prediction" class="headerlink" title="PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction"></a>PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12024">http://arxiv.org/abs/2311.12024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Hao Tan, Sai Bi, Yinghao Xu, Fujun Luan, Kalyan Sunkavalli, Wenping Wang, Zexiang Xu, Kai Zhang</li>
<li>for:  reconstruction of 3D objects from a few unposed images, and estimation of relative camera poses</li>
<li>methods: utilizes self-attention blocks to exchange information between 3D object tokens and 2D image tokens, predicts coarse point cloud for each view, and uses a differentiable Perspective-n-Point (PnP) solver to obtain camera poses</li>
<li>results: outperforms baseline methods by a large margin in terms of pose prediction accuracy and 3D reconstruction quality on various unseen evaluation datasets, and demonstrates applicability in downstream text&#x2F;image-to-3D task with fast feed-forward inference.<details>
<summary>Abstract</summary>
We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing a 3D object from a few unposed images even with little visual overlap, while simultaneously estimating the relative camera poses in ~1.3 seconds on a single A100 GPU. PF-LRM is a highly scalable method utilizing the self-attention blocks to exchange information between 3D object tokens and 2D image tokens; we predict a coarse point cloud for each view, and then use a differentiable Perspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge amount of multi-view posed data of ~1M objects, PF-LRM shows strong cross-dataset generalization ability, and outperforms baseline methods by a large margin in terms of pose prediction accuracy and 3D reconstruction quality on various unseen evaluation datasets. We also demonstrate our model's applicability in downstream text/image-to-3D task with fast feed-forward inference. Our project website is at: https://totoro97.github.io/pf-lrm .
</details>
<details>
<summary>摘要</summary>
我们提出了一种无pose大型重建模型（PF-LRM），可以从几张不带pose的图像中重建3D объек，即使图像之间视觉重叠少，并同时估算摄像头位置，在单个A100 GPU上大约1.3秒内完成。PF-LRM是一种高度可扩展的方法，利用自注意块来在3D对象卡通和2D图像卡通之间交换信息；我们预测每个视角的粗略点云，然后使用可微分的Perspective-n-Point（PnP）解决方法来获取摄像头位置。当在大量多视图卷积数据中训练时，PF-LRM显示出了广泛的跨数据集通用能力，并在不同评估数据集上大幅超越基eline方法的pose预测精度和3D重建质量。此外，我们还证明了我们的模型在文本/图像到3D任务中的应用性，通过快速的前向推理。我们的项目网站是：https://totoro97.github.io/pf-lrm。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-HMR-3D-Human-Mesh-Recovery-from-LiDAR"><a href="#LiDAR-HMR-3D-Human-Mesh-Recovery-from-LiDAR" class="headerlink" title="LiDAR-HMR: 3D Human Mesh Recovery from LiDAR"></a>LiDAR-HMR: 3D Human Mesh Recovery from LiDAR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11971">http://arxiv.org/abs/2311.11971</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soullessrobot/lidar-hmr">https://github.com/soullessrobot/lidar-hmr</a></li>
<li>paper_authors: Bohao Fan, Wenzhao Zheng, Jianjiang Feng, Jie Zhou</li>
<li>for: 这篇论文主要针对的是从稀疏 LiDAR 点云中估算人体三维模型。</li>
<li>methods: 该论文提出了一种有效的稀疏到dense重建方案，通过估算人体3D姿势并慢慢地重建人体体姿。为了更好地利用点云的3D结构信息，该方法使用了顺序图变换器（graphormer）引入点云特征。</li>
<li>results: 实验结果表明，该方法在三个公共可用的数据库上具有有效性。代码：<a target="_blank" rel="noopener" href="https://github.com/soullessrobot/LiDAR-HMR/%E3%80%82">https://github.com/soullessrobot/LiDAR-HMR/。</a><details>
<summary>Abstract</summary>
In recent years, point cloud perception tasks have been garnering increasing attention. This paper presents the first attempt to estimate 3D human body mesh from sparse LiDAR point clouds. We found that the major challenge in estimating human pose and mesh from point clouds lies in the sparsity, noise, and incompletion of LiDAR point clouds. Facing these challenges, we propose an effective sparse-to-dense reconstruction scheme to reconstruct 3D human mesh. This involves estimating a sparse representation of a human (3D human pose) and gradually reconstructing the body mesh. To better leverage the 3D structural information of point clouds, we employ a cascaded graph transformer (graphormer) to introduce point cloud features during sparse-to-dense reconstruction. Experimental results on three publicly available databases demonstrate the effectiveness of the proposed approach. Code: https://github.com/soullessrobot/LiDAR-HMR/
</details>
<details>
<summary>摘要</summary>
Recently, point cloud perception tasks have been gaining increasing attention. This paper presents the first attempt to estimate 3D human body mesh from sparse LiDAR point clouds. We found that the major challenge in estimating human pose and mesh from point clouds lies in the sparsity, noise, and incompleteness of LiDAR point clouds. To overcome these challenges, we propose an effective sparse-to-dense reconstruction scheme to reconstruct 3D human mesh. This involves estimating a sparse representation of a human (3D human pose) and gradually reconstructing the body mesh. To better leverage the 3D structural information of point clouds, we employ a cascaded graph transformer (graphormer) to introduce point cloud features during sparse-to-dense reconstruction. Experimental results on three publicly available databases demonstrate the effectiveness of the proposed approach. Code: https://github.com/soullessrobot/LiDAR-HMR/Here's the translation in Traditional Chinese:近年来，点云识别任务已经获得了增加的注意力。本文提出了从简练的LiDAR点云中估计3D人体组件的第一个尝试。我们发现，从点云中估计人姿和组件的主要挑战是点云的简练、噪声和不完整性。面对这些挑战，我们提出了一个有效的简练到简练重建方案，以重建3D人体组件。这 involves 估计人体的3D姿势（3D人体组件），并逐渐重建人体组件。为了更好地利用点云的3D结构信息，我们使用了堆叠 graphs transformer（graphormer）引入点云特征 during sparse-to-dense重建。实验结果显示，我们的方法具有优秀的效果。代码：https://github.com/soullessrobot/LiDAR-HMR/
</details></li>
</ul>
<hr>
<h2 id="SA-Med2D-20M-Dataset-Segment-Anything-in-2D-Medical-Imaging-with-20-Million-masks"><a href="#SA-Med2D-20M-Dataset-Segment-Anything-in-2D-Medical-Imaging-with-20-Million-masks" class="headerlink" title="SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks"></a>SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11969">http://arxiv.org/abs/2311.11969</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/OpenGVLab/SAM-Med2D">https://github.com/OpenGVLab/SAM-Med2D</a></li>
<li>paper_authors: Jin Ye, Junlong Cheng, Jianpin Chen, Zhongying Deng, Tianbin Li, Haoyu Wang, Yanzhou Su, Ziyan Huang, Jilong Chen, Lei Jiang, Hui Sun, Min Zhu, Shaoting Zhang, Junjun He, Yu Qiao</li>
<li>for: 这篇论文的目的是为了将自然语言像素化模型（Segment Anything Model，SAM）应用到医疗影像分类中，并且将医疗知识 integrate 到 SAM 中。</li>
<li>methods: 这篇论文使用了大量的医疗影像数据集来训练 SAM，并且将这些数据集分为不同的类别，以便更好地应用到医疗影像分类中。</li>
<li>results: 这篇论文所提出的 SA-Med2D-20M 数据集，包含了 4.6 百万帧医疗影像和 19.7 百万帧相应的面精度数据，覆盖了大部分的身体部位和具有很大的多样性。<details>
<summary>Abstract</summary>
Segment Anything Model (SAM) has achieved impressive results for natural image segmentation with input prompts such as points and bounding boxes. Its success largely owes to massive labeled training data. However, directly applying SAM to medical image segmentation cannot perform well because SAM lacks medical knowledge -- it does not use medical images for training. To incorporate medical knowledge into SAM, we introduce SA-Med2D-20M, a large-scale segmentation dataset of 2D medical images built upon numerous public and private datasets. It consists of 4.6 million 2D medical images and 19.7 million corresponding masks, covering almost the whole body and showing significant diversity. This paper describes all the datasets collected in SA-Med2D-20M and details how to process these datasets. Furthermore, comprehensive statistics of SA-Med2D-20M are presented to facilitate the better use of our dataset, which can help the researchers build medical vision foundation models or apply their models to downstream medical applications. We hope that the large scale and diversity of SA-Med2D-20M can be leveraged to develop medical artificial intelligence for enhancing diagnosis, medical image analysis, knowledge sharing, and education. The data with the redistribution license is publicly available at https://github.com/OpenGVLab/SAM-Med2D.
</details>
<details>
<summary>摘要</summary>
Segment Anything Model (SAM) 已经在自然图像分割领域取得了很好的结果，使用输入提示如点和 bounding box。它的成功主要归功于大规模的标注训练数据。然而，直接将 SAM 应用于医疗图像分割不能取得好成绩，因为 SAM 缺乏医疗知识 -- 它没有使用医疗图像进行训练。为了将医疗知识integrated into SAM，我们介绍了 SA-Med2D-20M，一个基于多个公共和私人数据集的大规模分割数据集。它包含460万个2D医疗图像和1970万对应的mask，覆盖了大多数的身体部位，显示了considerable diversity。本文描述了 SA-Med2D-20M 中收集的所有数据集，以及如何处理这些数据集。此外，我们还提供了 SA-Med2D-20M 的完整统计数据，以便更好地使用我们的数据集，帮助研究人员建立医学视觉基础模型或将其模型应用到下游医疗应用。我们希望通过 SA-Med2D-20M 的大规模和多样性，为医学人工智能的发展做出贡献，包括诊断、医疗图像分析、知识共享和教育。数据集的红色分布授权许可可以在 https://github.com/OpenGVLab/SAM-Med2D 上公开获取。
</details></li>
</ul>
<hr>
<h2 id="What-Can-AutoML-Do-For-Continual-Learning"><a href="#What-Can-AutoML-Do-For-Continual-Learning" class="headerlink" title="What Can AutoML Do For Continual Learning?"></a>What Can AutoML Do For Continual Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11963">http://arxiv.org/abs/2311.11963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mert Kilickaya, Joaquin Vanschoren</li>
<li>for: This paper explores the potential of AutoML for incremental (continual) learning, with the goal of encouraging more research in this area.</li>
<li>methods: The paper does not propose a new method, but instead highlights three key areas of research that can contribute to making incremental learners more dynamic, including applying AutoML methods in novel ways and addressing new challenges for AutoML research.</li>
<li>results: The paper does not present any specific results, but rather poses the question “What can AutoML do for incremental learning?” and outlines the potential benefits of using AutoML for this purpose.<details>
<summary>Abstract</summary>
This position paper outlines the potential of AutoML for incremental (continual) learning to encourage more research in this direction. Incremental learning involves incorporating new data from a stream of tasks and distributions to learn enhanced deep representations and adapt better to new tasks. However, a significant limitation of incremental learners is that most current techniques freeze the backbone architecture, hyperparameters, and the order & structure of the learning tasks throughout the learning and adaptation process. We strongly believe that AutoML offers promising solutions to address these limitations, enabling incremental learning to adapt to more diverse real-world tasks. Therefore, instead of directly proposing a new method, this paper takes a step back by posing the question: "What can AutoML do for incremental learning?" We outline three key areas of research that can contribute to making incremental learners more dynamic, highlighting concrete opportunities to apply AutoML methods in novel ways as well as entirely new challenges for AutoML research.
</details>
<details>
<summary>摘要</summary>
Instead of proposing a new method, this paper takes a step back and asks "What can AutoML do for incremental learning?" We identify three key areas of research that can contribute to making incremental learners more dynamic, highlighting concrete opportunities to apply AutoML methods in novel ways as well as entirely new challenges for AutoML research. These areas include:1. Dynamic architecture and hyperparameter optimization: Developing AutoML methods that can adaptively adjust the backbone architecture and hyperparameters of the model during incremental learning, allowing the model to better adapt to new tasks and data.2. Task-aware learning: Developing AutoML methods that can learn task-aware representations, which can be used to adapt the model to new tasks and data while preserving the knowledge gained from previous tasks.3. Multi-task learning: Developing AutoML methods that can handle multiple tasks simultaneously, allowing the model to learn shared representations across tasks and adapt to new tasks more quickly.By exploring these areas of research, we hope to encourage more research in the field of AutoML and incremental learning, and to ultimately develop more dynamic and adaptive machine learning models that can better handle the challenges of real-world applications.
</details></li>
</ul>
<hr>
<h2 id="An-Image-is-Worth-Multiple-Words-Multi-attribute-Inversion-for-Constrained-Text-to-Image-Synthesis"><a href="#An-Image-is-Worth-Multiple-Words-Multi-attribute-Inversion-for-Constrained-Text-to-Image-Synthesis" class="headerlink" title="An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis"></a>An Image is Worth Multiple Words: Multi-attribute Inversion for Constrained Text-to-Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11919">http://arxiv.org/abs/2311.11919</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aishwarya Agarwal, Srikrishna Karanam, Tripti Shukla, Balaji Vasan Srinivasan</li>
<li>for: 本研究的目标是使用一张参考图像提取多个特征（例如颜色、对象、布局、风格），并生成新样本以这些特征为condition。</li>
<li>methods: 本研究使用了一种新的多特征倒拍算法（MATTE），它在时间维度和DDPM模型层维度都学习多个嵌入，以提高特征分离。</li>
<li>results: 研究发现，通过使用MATTE算法和增强分离训练loss，可以生成高质量的多特征样本，并且分离了多个特征。<details>
<summary>Abstract</summary>
We consider the problem of constraining diffusion model outputs with a user-supplied reference image. Our key objective is to extract multiple attributes (e.g., color, object, layout, style) from this single reference image, and then generate new samples with them. One line of existing work proposes to invert the reference images into a single textual conditioning vector, enabling generation of new samples with this learned token. These methods, however, do not learn multiple tokens that are necessary to condition model outputs on the multiple attributes noted above. Another line of techniques expand the inversion space to learn multiple embeddings but they do this only along the layer dimension (e.g., one per layer of the DDPM model) or the timestep dimension (one for a set of timesteps in the denoising process), leading to suboptimal attribute disentanglement. To address the aforementioned gaps, the first contribution of this paper is an extensive analysis to determine which attributes are captured in which dimension of the denoising process. As noted above, we consider both the time-step dimension (in reverse denoising) as well as the DDPM model layer dimension. We observe that often a subset of these attributes are captured in the same set of model layers and/or across same denoising timesteps. For instance, color and style are captured across same U-Net layers, whereas layout and color are captured across same timestep stages. Consequently, an inversion process that is designed only for the time-step dimension or the layer dimension is insufficient to disentangle all attributes. This leads to our second contribution where we design a new multi-attribute inversion algorithm, MATTE, with associated disentanglement-enhancing regularization losses, that operates across both dimensions and explicitly leads to four disentangled tokens (color, style, layout, and object).
</details>
<details>
<summary>摘要</summary>
我们考虑到将散射模型输出与用户提供的参考图像进行约束的问题。我们的主要目标是从这个单一的参考图像中提取多个属性（例如颜色、物体、布局和风格），然后产生新的样本，并且将这些属性分类到不同的数据层次上。现有的方法包括将参考图像反转为单一的文本条件vector，以便产生新的样本。然而，这些方法不会学习多个条件实体，以便对模型输出进行多个属性的约束。另一些方法则是扩展对应空间，以学习多个嵌入，但是这些方法只是在层次（例如 DDPM 模型层次）或时间步（例如降噪过程中的时间步）上进行嵌入，从而导致属性分类不够佳。为了解决这些问题，我们的第一个贡献是对对应过程中哪些属性被捕捉的进行全面的分析。我们考虑了时间步 Dimension（在逆降噪过程中）以及 DDPM 模型层次 Dimension。我们发现，常常一些属性会在同一些层次和/或同一些时间步中被捕捉。例如，颜色和风格会在同一个 U-Net 层中被捕捉，而布局和颜色则会在同一个时间步中被捕捉。因此，对于时间步 Dimension 或 DDPM 模型层次的单一对应过程不足以将所有属性分类开来。这导致我们的第二个贡献，即设计了一个新的多属性对应算法，叫做 MATTE，还有相应的增强分类损失。MATTE 可以在时间步 Dimension 和 DDPM 模型层次上运行，并且可以让样本产生器产生四个分类的样本，即颜色、风格、布局和物体。
</details></li>
</ul>
<hr>
<h2 id="Identifying-the-Defective-Detecting-Damaged-Grains-for-Cereal-Appearance-Inspection"><a href="#Identifying-the-Defective-Detecting-Damaged-Grains-for-Cereal-Appearance-Inspection" class="headerlink" title="Identifying the Defective: Detecting Damaged Grains for Cereal Appearance Inspection"></a>Identifying the Defective: Detecting Damaged Grains for Cereal Appearance Inspection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11901">http://arxiv.org/abs/2311.11901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hellodfan/ai4graininsp">https://github.com/hellodfan/ai4graininsp</a></li>
<li>paper_authors: Lei Fan, Yiwen Ding, Dongdong Fan, Yong Wu, Maurice Pagnucco, Yang Song</li>
<li>for: 这篇论文旨在开发一个自动化的谷物质量检查系统，以提高智能农业的效率。</li>
<li>methods: 该论文使用了一种异常检测模型（AD-GAI），通过分析谷物ernel的特征来识别异常样本。</li>
<li>results: 实验结果显示，AD-GAI模型在比较高级的异常检测方法的比较中表现出了较好的性能，而自动化的谷物检查系统可以在20倍以上的速度提高 inspect efficiency。<details>
<summary>Abstract</summary>
Cereal grain plays a crucial role in the human diet as a major source of essential nutrients. Grain Appearance Inspection (GAI) serves as an essential process to determine grain quality and facilitate grain circulation and processing. However, GAI is routinely performed manually by inspectors with cumbersome procedures, which poses a significant bottleneck in smart agriculture.   In this paper, we endeavor to develop an automated GAI system:AI4GrainInsp. By analyzing the distinctive characteristics of grain kernels, we formulate GAI as a ubiquitous problem: Anomaly Detection (AD), in which healthy and edible kernels are considered normal samples while damaged grains or unknown objects are regarded as anomalies. We further propose an AD model, called AD-GAI, which is trained using only normal samples yet can identify anomalies during inference. Moreover, we customize a prototype device for data acquisition and create a large-scale dataset including 220K high-quality images of wheat and maize kernels. Through extensive experiments, AD-GAI achieves considerable performance in comparison with advanced AD methods, and AI4GrainInsp has highly consistent performance compared to human experts and excels at inspection efficiency over 20x speedup. The dataset, code and models will be released at https://github.com/hellodfan/AI4GrainInsp.
</details>
<details>
<summary>摘要</summary>
粮食作物在人类饮食中扮演着重要角色，是重要营养素的主要来源。 however， Grain Appearance Inspection（GAI）， which is essential to determine grain quality and facilitate grain circulation and processing, is often performed manually by inspectors with cumbersome procedures, which poses a significant bottleneck in smart agriculture. 在这篇论文中，我们努力开发一个自动化GAI系统：AI4GrainInsp。我们将GAI视为一个通用问题：Anomaly Detection（AD），健康和食用粮粒被视为正常样本，而受损或未知物体则被视为异常。我们还提出了一个AD模型， called AD-GAI， 训练用normal样本，但可以在推导过程中识别异常。此外，我们自订了一个原型设备用于数据收集，并创建了包含220,000张高品质小麦和玉米粒的大规模数据集。通过广泛的实验， AD-GAI在与进步AD方法相比表现出色，而AI4GrainInsp具有人工专家比较高的一致性，并在检查效率方面大幅提高，对20倍以上的速度优化。数据、代码和模型将在https://github.com/hellodfan/AI4GrainInsp中发布。
</details></li>
</ul>
<hr>
<h2 id="SniffyArt-The-Dataset-of-Smelling-Persons"><a href="#SniffyArt-The-Dataset-of-Smelling-Persons" class="headerlink" title="SniffyArt: The Dataset of Smelling Persons"></a>SniffyArt: The Dataset of Smelling Persons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11888">http://arxiv.org/abs/2311.11888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Zinnen, Azhar Hussian, Hang Tran, Prathmesh Madhu, Andreas Maier, Vincent Christlein</li>
<li>for: 这篇论文旨在为探索过去的味觉艺术作品中的味觉姿势提供数据集，以便开发混合类型的识别方法。</li>
<li>methods: 这篇论文使用了一个名为SniffyArt的数据集，该数据集包含1941名个体，分别出现在441幅历史艺术作品中。每个人都有紧靠的盒子 bounding box，17个姿势关键点和一个姿势标签。通过这些注释，数据集可以帮助开发混合类型的识别方法。</li>
<li>results: 这篇论文还提供了一个基eline分析，评估了一些代表性的算法在检测、关键点估计和分类任务中的性能，从而探讨将关键点估计与味觉姿势识别结合使用来提高人姿和味觉维度分析的前景。<details>
<summary>Abstract</summary>
Smell gestures play a crucial role in the investigation of past smells in the visual arts yet their automated recognition poses significant challenges. This paper introduces the SniffyArt dataset, consisting of 1941 individuals represented in 441 historical artworks. Each person is annotated with a tightly fitting bounding box, 17 pose keypoints, and a gesture label. By integrating these annotations, the dataset enables the development of hybrid classification approaches for smell gesture recognition. The datasets high-quality human pose estimation keypoints are achieved through the merging of five separate sets of keypoint annotations per person. The paper also presents a baseline analysis, evaluating the performance of representative algorithms for detection, keypoint estimation, and classification tasks, showcasing the potential of combining keypoint estimation with smell gesture classification. The SniffyArt dataset lays a solid foundation for future research and the exploration of multi-task approaches leveraging pose keypoints and person boxes to advance human gesture and olfactory dimension analysis in historical artworks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统艺术作品中的嗅觉姿势扮演着重要的角色，但自动识别嗅觉姿势具有 significante挑战。这篇论文介绍了SniffyArt数据集，包含1941名人物在441幅历史艺术作品中的表现。每名人物被标注为紧靠的 bounding box、17个姿势关键点和姿势标签。通过这些标注，数据集可以激发 hybrid 分类方法的开发，以提高嗅觉姿势识别的精度。数据集的高质量人 pose 关键点是通过每名人物的五个独立的关键点标注集来实现的。论文还提供了基线分析，评估了代表性算法的检测、关键点估计和分类任务的性能，展示了将关键点估计与嗅觉姿势分类结合使用的潜在优势。SniffyArt数据集为未来研究的固定基础，探索将人体姿势和嗅觉维度分析结合起来的多任务方法，以提高人体姿势和嗅觉分析的精度。
</details></li>
</ul>
<hr>
<h2 id="Multi-Task-Faces-MTF-Data-Set-A-Legally-and-Ethically-Compliant-Collection-of-Face-Images-for-Various-Classification-Tasks"><a href="#Multi-Task-Faces-MTF-Data-Set-A-Legally-and-Ethically-Compliant-Collection-of-Face-Images-for-Various-Classification-Tasks" class="headerlink" title="Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks"></a>Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant Collection of Face Images for Various Classification Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11882">http://arxiv.org/abs/2311.11882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ramihaf/mtf_data_set">https://github.com/ramihaf/mtf_data_set</a></li>
<li>paper_authors: Rami Haffar, David Sánchez, Josep Domingo-Ferrer</li>
<li>for: 这个论文是为了提供一个多任务人脸数据集（MTF），用于各种人脸分类任务，包括人脸识别、年龄、性别和种族分类。</li>
<li>methods: 这个论文使用了公共可用的影星图片，并且严格遵循了版权法规，以获取和处理数据集。</li>
<li>results: 这个论文提供了MTF数据集的详细描述，并评估了五种深度学习（DL）模型在MTF数据集上的性能，包括人脸识别、年龄、性别和种族分类等任务。同时，该论文还比较了DL模型在加工后的MTF数据集和网络上抓取的原始数据上的性能。<details>
<summary>Abstract</summary>
Human facial data hold tremendous potential to address a variety of classification problems, including face recognition, age estimation, gender identification, emotion analysis, and race classification. However, recent privacy regulations, such as the EU General Data Protection Regulation and others, have restricted the ways in which human images may be collected and used for research. As a result, several previously published data sets containing human faces have been removed from the internet due to inadequate data collection methods that failed to meet privacy regulations. Data sets consisting of synthetic data have been proposed as an alternative, but they fall short of accurately representing the real data distribution. On the other hand, most available data sets are labeled for just a single task, which limits their applicability. To address these issues, we present the Multi-Task Faces (MTF) image data set, a meticulously curated collection of face images designed for various classification tasks, including face recognition, as well as race, gender, and age classification. The MTF data set has been ethically gathered by leveraging publicly available images of celebrities and strictly adhering to copyright regulations. In this paper, we present this data set and provide detailed descriptions of the followed data collection and processing procedures. Furthermore, we evaluate the performance of five deep learning (DL) models on the MTF data set across the aforementioned classification tasks. Additionally, we compare the performance of DL models over the processed MTF data and over raw data crawled from the internet. The reported results constitute a baseline for further research employing these data. The MTF data set can be accessed through the following link (please cite the present paper if you use the data set): https://github.com/RamiHaf/MTF_data_set
</details>
<details>
<summary>摘要</summary>
人脸数据具有巨大的潜力，可以解决多种分类问题，包括人脸识别、年龄估计、性别确定、情感分析和种族分类。然而，最新的隐私法规，如欧盟一般数据保护条例等，限制了人脸图像的收集和使用方式。因此，一些在互联网上已经被下架的人脸数据集被移除，因为其收集方法不符合隐私法规。 Synthetic数据集被提议作为替代方案，但它们无法准确表现实际数据分布。另一方面，大多数可用的数据集仅针对单一任务进行标注，限制了它们的可 reuse。为解决这些问题，我们提出了多任务人脸（MTF）图像数据集，包含人脸图像，用于多种分类任务，包括人脸识别、种族、性别和年龄分类。MTF数据集通过公开可用的明星照片进行了优质的收集，并且严格遵循了版权法规。在这篇论文中，我们介绍了MTF数据集，并提供了收集和处理数据的详细描述。此外，我们使用五种深度学习（DL）模型对MTF数据集进行了评估，并对raw数据和已经处理的MTF数据进行了比较。报告的结果构成了基eline для后续研究。MTF数据集可以通过以下链接获取：https://github.com/RamiHaf/MTF_data_set。请在使用数据集时参考本文。
</details></li>
</ul>
<hr>
<h2 id="VLM-Eval-A-General-Evaluation-on-Video-Large-Language-Models"><a href="#VLM-Eval-A-General-Evaluation-on-Video-Large-Language-Models" class="headerlink" title="VLM-Eval: A General Evaluation on Video Large Language Models"></a>VLM-Eval: A General Evaluation on Video Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11865">http://arxiv.org/abs/2311.11865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuailin Li, Yuang Zhang, Yucheng Zhao, Qiuyue Wang, Fan Jia, Yingfei Liu, Tiancai Wang</li>
<li>for: 这篇论文主要用于评估视频大语言模型（LLMs）的全面评估，包括captioning、问答、检索和动作识别等多个视频任务。</li>
<li>methods: 该论文提出了一种简单的基准：Video-LLaVA，使用单个线性投影，并超越现有的视频LLMs。此外，论文还使用GPT基于的评估方法，可以评估响应质量在多个方面匹配人类性能。</li>
<li>results: 论文的实验结果表明， Video-LLaVA 可以在多个视频任务上达到或超越现有的视频LLMs，而且可以在驾驶场景中使用只需要数百个视频教程对象进行微调，并且获得了鼓舞人的认知和逻辑能力。<details>
<summary>Abstract</summary>
Despite the rapid development of video Large Language Models (LLMs), a comprehensive evaluation is still absent. In this paper, we introduce a unified evaluation that encompasses multiple video tasks, including captioning, question and answering, retrieval, and action recognition. In addition to conventional metrics, we showcase how GPT-based evaluation can match human-like performance in assessing response quality across multiple aspects. We propose a simple baseline: Video-LLaVA, which uses a single linear projection and outperforms existing video LLMs. Finally, we evaluate video LLMs beyond academic datasets, which show encouraging recognition and reasoning capabilities in driving scenarios with only hundreds of video-instruction pairs for fine-tuning. We hope our work can serve as a unified evaluation for video LLMs, and help expand more practical scenarios. The evaluation code will be available soon.
</details>
<details>
<summary>摘要</summary>
尽管视频大语言模型（LLM）的快速发展，但是一个全面的评估仍然缺失。在这篇论文中，我们介绍了一种涵盖多个视频任务的统一评估，包括标题、问答、检索和动作识别。除了传统的指标外，我们示出了如何基于GPT的评估可以匹配人类类似的评估质量在多个方面。我们提出了一个简单的基线：视频-LLaVA，它使用单一的线性投影，并超越了现有的视频LLM。最后，我们评估了视频LLM在外部数据集上的性能，显示出在驾驶场景中只需要百分之几个视频教程对话来进行微调，可以获得鼓舞人的识别和逻辑能力。我们希望我们的工作可以为视频LLM提供一个统一的评估，并帮助扩展更多实用场景。评估代码将很快地提供。
</details></li>
</ul>
<hr>
<h2 id="GP-NeRF-Generalized-Perception-NeRF-for-Context-Aware-3D-Scene-Understanding"><a href="#GP-NeRF-Generalized-Perception-NeRF-for-Context-Aware-3D-Scene-Understanding" class="headerlink" title="GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding"></a>GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11863">http://arxiv.org/abs/2311.11863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Li, Dingwen Zhang, Yalun Dai, Nian Liu, Lechao Cheng, Jingfeng Li, Jingdong Wang, Junwei Han</li>
<li>for: 提高3D场景理解的场景识别和表示能力</li>
<li>methods: 使用 transformers 对光照和Semantic embedding字段进行汇集，并提出两种自我训练机制来提高Semantic embedding字段的分辨率和准确性</li>
<li>results: 在 semantic 和实例 segmentation 任务上进行比较，与 SOTA 方法相比，OUR 方法提高了6.94%、11.76% 和8.47% 的性能Here’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本文旨在提高3D场景理解的场景识别和表示能力，通过将广泛使用的 segmentation 模型和NeRF 技术结合起来，建立一个通用的框架。</li>
<li>methods: 我们使用 transformers 对光照和Semantic embedding字段进行汇集，并提出两种自我训练机制来提高Semantic embedding字段的分辨率和准确性。</li>
<li>results: 我们在 semantic 和实例 segmentation 任务上进行比较，与 SOTA 方法相比，OUR 方法提高了6.94%、11.76% 和8.47% 的性能。<details>
<summary>Abstract</summary>
Applying NeRF to downstream perception tasks for scene understanding and representation is becoming increasingly popular. Most existing methods treat semantic prediction as an additional rendering task, \textit{i.e.}, the "label rendering" task, to build semantic NeRFs. However, by rendering semantic/instance labels per pixel without considering the contextual information of the rendered image, these methods usually suffer from unclear boundary segmentation and abnormal segmentation of pixels within an object. To solve this problem, we propose Generalized Perception NeRF (GP-NeRF), a novel pipeline that makes the widely used segmentation model and NeRF work compatibly under a unified framework, for facilitating context-aware 3D scene perception. To accomplish this goal, we introduce transformers to aggregate radiance as well as semantic embedding fields jointly for novel views and facilitate the joint volumetric rendering of both fields. In addition, we propose two self-distillation mechanisms, i.e., the Semantic Distill Loss and the Depth-Guided Semantic Distill Loss, to enhance the discrimination and quality of the semantic field and the maintenance of geometric consistency. In evaluation, we conduct experimental comparisons under two perception tasks (\textit{i.e.} semantic and instance segmentation) using both synthetic and real-world datasets. Notably, our method outperforms SOTA approaches by 6.94\%, 11.76\%, and 8.47\% on generalized semantic segmentation, finetuning semantic segmentation, and instance segmentation, respectively.
</details>
<details>
<summary>摘要</summary>
使用NeRF进行下游ognition任务，如场景理解和表示，越来越受欢迎。现有的方法通常将semantic prediction视为额外的渲染任务，即"标签渲染"任务，以建立semantic NeRFs。然而，由于不考虑渲染图像上的上下文信息，这些方法通常会出现模糊的边界分割和对象内部像素的异常分割问题。为解决这个问题，我们提出了通用认知NeRF（GP-NeRF），一种新的管道，可以让通用segmentation模型和NeRF在一个统一的框架下工作，以便实现上下文意识的3D场景识别。为实现这个目标，我们引入了transformer来聚合辐射和semantic嵌入场景的字段，以便在新视图下进行共同渲染。此外，我们还提出了两种自适应机制，即semantic Distill Loss和depth-guided Semantic Distill Loss，以提高semantic场景的分割和质量，并保持Geometric的一致性。在evaluation中，我们对两个ognition任务（即semantic和instance segmentation）进行了比较，使用了both synthetic和实际数据。可见，我们的方法在Generalized Semantic Segmentation、fine-tuning Semantic Segmentation和Instance Segmentation中都有显著的优势，相比SOTA方法，提高了6.94%、11.76%和8.47%。
</details></li>
</ul>
<hr>
<h2 id="LION-Empowering-Multimodal-Large-Language-Model-with-Dual-Level-Visual-Knowledge"><a href="#LION-Empowering-Multimodal-Large-Language-Model-with-Dual-Level-Visual-Knowledge" class="headerlink" title="LION : Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge"></a>LION : Empowering Multimodal Large Language Model with Dual-Level Visual Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11860">http://arxiv.org/abs/2311.11860</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gongwei Chen, Leyang Shen, Rui Shao, Xiang Deng, Liqiang Nie<br>for: 这个论文的目的是提高多模态大语言模型（MLLM）的性能，使其能够更好地理解和利用多 modal 信号。methods: 该论文使用了两级层次的视觉知识扩充策略，包括进步的细化空间意识视觉知识的包含，以及软提示高级别semantic 视觉证据。results: 该论文的实验结果表明，在多个多模态benchmark上，提高了5%的准确率（VSRevaluation和TextCaps over InstructBLIP）和3%的CIDEr（RefCOCOg over Kosmos-2）。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have endowed LLMs with the ability to perceive and understand multi-modal signals. However, most of the existing MLLMs mainly adopt vision encoders pretrained on coarsely aligned image-text pairs, leading to insufficient extraction and reasoning of visual knowledge. To address this issue, we devise a dual-Level vIsual knOwledge eNhanced Multimodal Large Language Model (LION), which empowers the MLLM by injecting visual knowledge in two levels. 1) Progressive incorporation of fine-grained spatial-aware visual knowledge. We design a vision aggregator cooperated with region-level vision-language (VL) tasks to incorporate fine-grained spatial-aware visual knowledge into the MLLM. To alleviate the conflict between image-level and region-level VL tasks during incorporation, we devise a dedicated stage-wise instruction-tuning strategy with mixture-of-adapters. This progressive incorporation scheme contributes to the mutual promotion between these two kinds of VL tasks. 2) Soft prompting of high-level semantic visual evidence. We facilitate the MLLM with high-level semantic visual evidence by leveraging diverse image tags. To mitigate the potential influence caused by imperfect predicted tags, we propose a soft prompting method by embedding a learnable token into the tailored text instruction. Comprehensive experiments on several multi-modal benchmarks demonstrate the superiority of our model (e.g., improvement of 5% accuracy on VSR and 3% CIDEr on TextCaps over InstructBLIP, 5% accuracy on RefCOCOg over Kosmos-2).
</details>
<details>
<summary>摘要</summary>
多modal大语言模型（MLLMs）已经授予大语言模型（LLMs）能够感知和理解多modal信号。然而，现有的大多数MLLMs主要采用视觉编码器预训练在粗粒aligned的图像文本对中，导致视觉知识的不足提取和分析。为解决这个问题，我们设计了一种双级视知能强化多modal大语言模型（LION），它使得MLLM具有更高水平的视觉知识。1. 进展性的细化空间意识视觉知识整合。我们设计了一种视觉聚合器，与区域级vision-language（VL）任务结合，以便在MLLM中整合细化空间意识视觉知识。为了解决图像级和区域级VL任务之间的冲突，我们提出了一种适应器阶段 wise 准确调整策略。这种进程性整合方案为这两种VL任务互相促进。2. 软引导高级别semantic视觉证据。我们为MLLM提供高级别semantic视觉证据，利用多种图像标签。为了减轻可能由预测错误引起的影响，我们提出了一种软引导方法，通过在修改的文本指令中嵌入学习token来实现。我们在多个多modal bencmarks上进行了广泛的实验，并证明了我们的模型在VSRCIDEr等方面的性能有5%提升和3%提升。
</details></li>
</ul>
<hr>
<h2 id="FATURA-A-Multi-Layout-Invoice-Image-Dataset-for-Document-Analysis-and-Understanding"><a href="#FATURA-A-Multi-Layout-Invoice-Image-Dataset-for-Document-Analysis-and-Understanding" class="headerlink" title="FATURA: A Multi-Layout Invoice Image Dataset for Document Analysis and Understanding"></a>FATURA: A Multi-Layout Invoice Image Dataset for Document Analysis and Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11856">http://arxiv.org/abs/2311.11856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud Limam, Marwa Dhiaf, Yousri Kessentini</li>
<li>for: 该论文主要用于提供一个大规模、多格式的文档分析和理解 dataset，帮助研究人员在文档分析和理解方面进行更好的训练和测试。</li>
<li>methods: 该论文使用了多种文档分析和理解技术，包括文本内容分析和精确 bounding-box 笔迹标注，以便在不同的文档中分别标识不同的元素。</li>
<li>results: 该论文提供了一个名为 FATURA 的大型开放数据集，包含 $10,000$ 份多格式的票据文档图像，以及对这些图像的详细的标注和评估结果。这个数据集是研究人员在文档分析和理解领域进行训练和测试的重要资源。<details>
<summary>Abstract</summary>
Document analysis and understanding models often require extensive annotated data to be trained. However, various document-related tasks extend beyond mere text transcription, requiring both textual content and precise bounding-box annotations to identify different document elements. Collecting such data becomes particularly challenging, especially in the context of invoices, where privacy concerns add an additional layer of complexity. In this paper, we introduce FATURA, a pivotal resource for researchers in the field of document analysis and understanding. FATURA is a highly diverse dataset featuring multi-layout, annotated invoice document images. Comprising $10,000$ invoices with $50$ distinct layouts, it represents the largest openly accessible image dataset of invoice documents known to date. We also provide comprehensive benchmarks for various document analysis and understanding tasks and conduct experiments under diverse training and evaluation scenarios. The dataset is freely accessible at https://zenodo.org/record/8261508, empowering researchers to advance the field of document analysis and understanding.
</details>
<details>
<summary>摘要</summary>
文档分析和理解模型经常需要大量已经标注数据进行训练。然而，各种文档相关任务超出了简单的文本转写，需要同时包含文本内容和精确的 bounding-box 注释，以识别不同的文档元素。收集这些数据变得特别困难，尤其在帐单上，隐私问题添加了一个额外的层次。在这篇论文中，我们介绍 FATURA，一个重要的研究资源。FATURA 是一个多样化的数据集，包含 $10,000$ 份帐单，每份帐单有 $50$ 种不同的布局。这个数据集是已知的最大的公开访问图像数据集。我们还提供了各种文档分析和理解任务的完整的benchmark，并在多种训练和评估场景下进行了实验。该数据集可以免费下载于 <https://zenodo.org/record/8261508>，为研究人员提供了进一步推动文档分析和理解领域的机会。
</details></li>
</ul>
<hr>
<h2 id="Asynchronous-Bioplausible-Neuron-for-Spiking-Neural-Networks-for-Event-Based-Vision"><a href="#Asynchronous-Bioplausible-Neuron-for-Spiking-Neural-Networks-for-Event-Based-Vision" class="headerlink" title="Asynchronous Bioplausible Neuron for Spiking Neural Networks for Event-Based Vision"></a>Asynchronous Bioplausible Neuron for Spiking Neural Networks for Event-Based Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11853">http://arxiv.org/abs/2311.11853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanket Kachole, Hussain Sajwani, Fariborz Baghaei Naeini, Dimitrios Makris, Yahya Zweiri</li>
<li>for: 提高计算机视觉效率和能效性</li>
<li>methods: 使用自适应神经元发射机制维护神经网络的平衡</li>
<li>results: 提高图像分类和 segmentation 性能，保持神经网络的平衡和能效性<details>
<summary>Abstract</summary>
Spiking Neural Networks (SNNs) offer a biologically inspired approach to computer vision that can lead to more efficient processing of visual data with reduced energy consumption. However, maintaining homeostasis within these networks is challenging, as it requires continuous adjustment of neural responses to preserve equilibrium and optimal processing efficiency amidst diverse and often unpredictable input signals. In response to these challenges, we propose the Asynchronous Bioplausible Neuron (ABN), a dynamic spike firing mechanism to auto-adjust the variations in the input signal. Comprehensive evaluation across various datasets demonstrates ABN's enhanced performance in image classification and segmentation, maintenance of neural equilibrium, and energy efficiency.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）提供了生物学发明的计算机视觉方法，可以导致更有效的视觉数据处理，降低能源消耗。然而，保持神经网络中的HOMEOSTASIS具有挑战，因为它需要不断调整神经响应，以维持平衡和最佳处理效率面对多样化和不可预测的输入信号。为解决这些挑战，我们提出了异步生物可能性神经元（ABN），一种动态脉冲发射机制，自动调整输入信号的变化。对于不同的数据集，ABN的综合评估表明它在图像分类和 segmentation 方面具有提高的表现，保持神经平衡，并具有更高的能效性。
</details></li>
</ul>
<hr>
<h2 id="Entangled-View-Epipolar-Information-Aggregation-for-Generalizable-Neural-Radiance-Fields"><a href="#Entangled-View-Epipolar-Information-Aggregation-for-Generalizable-Neural-Radiance-Fields" class="headerlink" title="Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields"></a>Entangled View-Epipolar Information Aggregation for Generalizable Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11845">http://arxiv.org/abs/2311.11845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tatakai1/evenerf">https://github.com/tatakai1/evenerf</a></li>
<li>paper_authors: Zhiyuan Min, Yawei Luo, Wei Yang, Yuesong Wang, Yi Yang</li>
<li>for: 本研究旨在提高NeRF的可重构性，使其能直接生成新场景中的novel view，无需进行场景特定的重新训练。</li>
<li>methods: 我们提出了一种名为EVE-NeRF的Entangled View-Epipolar Information Aggregation方法，它在拼接多视图特征时进行了束合。与现有方法不同的是，EVE-NeRF在拼接过程中具有场景不变的外观和几何约束，从而更好地保证3D表示的普适性。</li>
<li>results: 我们的方法在多种评估场景中达到了状态机器人的性能，比前一代单一维度拼接更加准确地重建了3D场景的几何和外观特征。<details>
<summary>Abstract</summary>
Generalizable NeRF can directly synthesize novel views across new scenes, eliminating the need for scene-specific retraining in vanilla NeRF. A critical enabling factor in these approaches is the extraction of a generalizable 3D representation by aggregating source-view features. In this paper, we propose an Entangled View-Epipolar Information Aggregation method dubbed EVE-NeRF. Different from existing methods that consider cross-view and along-epipolar information independently, EVE-NeRF conducts the view-epipolar feature aggregation in an entangled manner by injecting the scene-invariant appearance continuity and geometry consistency priors to the aggregation process. Our approach effectively mitigates the potential lack of inherent geometric and appearance constraint resulting from one-dimensional interactions, thus further boosting the 3D representation generalizablity. EVE-NeRF attains state-of-the-art performance across various evaluation scenarios. Extensive experiments demonstate that, compared to prevailing single-dimensional aggregation, the entangled network excels in the accuracy of 3D scene geometry and appearance reconstruction.Our project page is https://github.com/tatakai1/EVENeRF.
</details>
<details>
<summary>摘要</summary>
通用的NeRF可以直接生成新场景中的新视图，从而消除需要在普通的NeRF中重新训练场景的需求。一个关键的实现因素在这些方法中是提取一个通用的3D表示。在这篇论文中，我们提出了一种杂合视角和轴向信息的方法，称为EVE-NeRF。与现有的方法不同，EVE-NeRF在杂合过程中包含场景不变的外观连续和几何稳定约束，从而有效地减轻一dimensional交互中可能存在的自然的几何和外观约束不足的问题，并进一步提高3D表示的通用性。EVE-NeRF在多种评价场景中达到了领先的性能。广泛的实验表明，相比传统的单一维度杂合，杂合网络在3D场景几何和外观重建精度方面表现出色。我们的项目页面是https://github.com/tatakai1/EVENeRF。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Multispectral-Segmentation-with-Representations-Generated-by-Reinforcement-Learning"><a href="#Few-shot-Multispectral-Segmentation-with-Representations-Generated-by-Reinforcement-Learning" class="headerlink" title="Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning"></a>Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11827">http://arxiv.org/abs/2311.11827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dilith Jayakody, Thanuja Ambegoda</li>
<li>for: 提高几个样本的多spectral图像分割性能</li>
<li>methods: 使用 reinforcement learning 生成表达式，以便在特定类型分割时提供有用的表示</li>
<li>results: 在多spectral图像 datasets 上证明了提高分割性能的效果<details>
<summary>Abstract</summary>
The task of multispectral image segmentation (segmentation of images with numerous channels/bands, each capturing a specific range of wavelengths of electromagnetic radiation) has been previously explored in contexts with large amounts of labeled data. However, these models tend not to generalize well to datasets of smaller size. In this paper, we propose a novel approach for improving few-shot segmentation performance on multispectral images using reinforcement learning to generate representations. These representations are generated in the form of mathematical expressions between channels and are tailored to the specific class being segmented. Our methodology involves training an agent to identify the most informative expressions, updating the dataset using these expressions, and then using the updated dataset to perform segmentation. Due to the limited length of the expressions, the model receives useful representations without any added risk of overfitting. We evaluate the effectiveness of our approach on several multispectral datasets and demonstrate its effectiveness in boosting the performance of segmentation algorithms.
</details>
<details>
<summary>摘要</summary>
多通道图像分割（分割包含多个通道/波段的图像，每个通道/波段捕捉特定范围的电磁辐射波长）的任务已经在大量标注数据的情况下进行过研究。然而，这些模型通常不会在小型数据集上总是适应良好。在这篇论文中，我们提出了一种新的方法，用于在多通道图像上提高几个shot分割性能使用返馈学习生成表示。这些表示是在通道之间的数学表达形式，特制为具体的分割类。我们的方法包括训练一个代理人标识最有用的表达，更新数据集使用这些表达，然后使用更新后的数据集进行分割。由于表达的长度有限，模型可以得到有用的表示而无风险过拟合。我们对多个多通道数据集进行评估，并证明了我们的方法可以提高分割算法的性能。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Inverse-Rendering-of-Complex-Facade-via-Aerial-3D-Scanning"><a href="#Holistic-Inverse-Rendering-of-Complex-Facade-via-Aerial-3D-Scanning" class="headerlink" title="Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning"></a>Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11825">http://arxiv.org/abs/2311.11825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Xie, Rengan Xie, Rong Li, Kai Huang, Pengju Qiao, Jingsen Zhu, Xu Yin, Qi Ye, Wei Hua, Yuchi Huo, Hujun Bao<br>for:这篇论文的目的是利用多视图空中图像来重建建筑立面的几何、照明和材料。methods:这篇论文使用了神经签距场（SDF）来实现物理基于的新视图synthesis和编辑。它使用了简单的RGB图像， captured by a drone，作为输入，不需要复杂的设备，可以实现物理基于的高品质新视图synthesis、重新照明和编辑。results:这篇论文的实验表明， compared to state-of-the-art baselines，其方法在facade holistic inverse rendering、新视图synthesis和Scene editing中具有更高的质量。<details>
<summary>Abstract</summary>
In this work, we use multi-view aerial images to reconstruct the geometry, lighting, and material of facades using neural signed distance fields (SDFs). Without the requirement of complex equipment, our method only takes simple RGB images captured by a drone as inputs to enable physically based and photorealistic novel-view rendering, relighting, and editing. However, a real-world facade usually has complex appearances ranging from diffuse rocks with subtle details to large-area glass windows with specular reflections, making it hard to attend to everything. As a result, previous methods can preserve the geometry details but fail to reconstruct smooth glass windows or verse vise. In order to address this challenge, we introduce three spatial- and semantic-adaptive optimization strategies, including a semantic regularization approach based on zero-shot segmentation techniques to improve material consistency, a frequency-aware geometry regularization to balance surface smoothness and details in different surfaces, and a visibility probe-based scheme to enable efficient modeling of the local lighting in large-scale outdoor environments. In addition, we capture a real-world facade aerial 3D scanning image set and corresponding point clouds for training and benchmarking. The experiment demonstrates the superior quality of our method on facade holistic inverse rendering, novel view synthesis, and scene editing compared to state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们使用多视角空中图像来重建建筑外墙的几何、照明和材质。无需复杂的设备，我们的方法只需要简单的RGB图像， captured by drone，作为输入，以实现物理基于的和 photorealistic 的新视图渲染、重新照明和编辑。然而，实际世界中的外墙通常具有复杂的 appearances，从柔软的岩石到精细的细节，以及大面积的玻璃窗户的镜面反射，这使得前一代方法无法兼顾所有的细节。为解决这个挑战，我们提出了三种空间和semantic-adaptive优化策略，包括基于零shot segmentation技术的semantic regularization来提高材质一致性，频率意识的几何 regularization来平衡不同表面的平滑度和细节，以及可见探针基于的方案来实现大规模的outdoor环境中的本地照明模拟。此外，我们收集了一组真实世界上的外墙空中3D扫描图像和对应的点云数据，用于训练和测试。实验结果表明，我们的方法在facade holistic inverse rendering、新视图合成和Scene editing方面具有较高的质量，比前一代基elines superior。
</details></li>
</ul>
<hr>
<h2 id="Cross-View-Graph-Consistency-Learning-for-Invariant-Graph-Representations"><a href="#Cross-View-Graph-Consistency-Learning-for-Invariant-Graph-Representations" class="headerlink" title="Cross-View Graph Consistency Learning for Invariant Graph Representations"></a>Cross-View Graph Consistency Learning for Invariant Graph Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11821">http://arxiv.org/abs/2311.11821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenjie20/cgcl">https://github.com/chenjie20/cgcl</a></li>
<li>paper_authors: Jie Chen, Zhiming Li, Hua Mao, Wai Lok Woo, Xi Peng</li>
<li>For: 这个论文的目的是学习图形数据的基本表现，尤其是找到对称的图形表现。* Methods: 这个论文提出了一个跨观点图形一致学习（CGCL）方法，通过将两个不同的图形观点融合成一个完整的图形数据，以学习对称的图形表现。* Results: 这个论文的实验结果显示，跨观点图形一致学习（CGCL）方法可以实现比较好的预测性和稳定性，并且在图形数据上比较其他state-of-the-art算法。<details>
<summary>Abstract</summary>
Graph representation learning is fundamental for analyzing graph-structured data. Exploring invariant graph representations remains a challenge for most existing graph representation learning methods. In this paper, we propose a cross-view graph consistency learning (CGCL) method that learns invariant graph representations for link prediction. First, two complementary augmented views are derived from an incomplete graph structure through a bidirectional graph structure augmentation scheme. This augmentation scheme mitigates the potential information loss that is commonly associated with various data augmentation techniques involving raw graph data, such as edge perturbation, node removal, and attribute masking. Second, we propose a CGCL model that can learn invariant graph representations. A cross-view training scheme is proposed to train the proposed CGCL model. This scheme attempts to maximize the consistency information between one augmented view and the graph structure reconstructed from the other augmented view. Furthermore, we offer a comprehensive theoretical CGCL analysis. This paper empirically and experimentally demonstrates the effectiveness of the proposed CGCL method, achieving competitive results on graph datasets in comparisons with several state-of-the-art algorithms.
</details>
<details>
<summary>摘要</summary>
“图表示学是对图结构数据进行分析的基本概念。寻找不变图表示仍然是现有图表示学方法中的挑战。在这篇论文中，我们提出了跨视图图统一学习（CGCL）方法，用于预测链接。首先，我们从不完整的图结构中 derivate了两个补充的增强视图，通过双向图结构增强方案来解决 Raw 图数据的不同数据增强技术中的信息损失问题。其次，我们提出了一种 CGCL 模型，可以学习不变图表示。我们提出了一种跨视图培训方案，用于培训提出的 CGCL 模型。这种方案尝试使得一个增强视图与另一个增强视图中的图结构重建的信息保持最大化。此外，我们也提供了详细的 CGCL 分析。这篇论文通过实验和理论分析证明了我们提出的 CGCL 方法的有效性，在对图数据集进行比较时与一些现有的算法进行竞争。”
</details></li>
</ul>
<hr>
<h2 id="CrackCLF-Automatic-Pavement-Crack-Detection-based-on-Closed-Loop-Feedback"><a href="#CrackCLF-Automatic-Pavement-Crack-Detection-based-on-Closed-Loop-Feedback" class="headerlink" title="CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop Feedback"></a>CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11815">http://arxiv.org/abs/2311.11815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong Li, Zhun Fan, Ying Chen, Huibiao Lin, Laura Moretti, Giuseppe Loprencipe, Weihua Sheng, Kelvin C. P. Wang</li>
<li>for: Automatic pavement crack detection to ensure pavement functional performances during service life.</li>
<li>methods: Encoder-decoder framework with closed-loop feedback (CLF) and generative adversarial networks (GAN) to correct errors and adapt to environment changes.</li>
<li>results: Outperforms other methods on three public datasets, with the proposed CLF module as a plug and play component to improve model performances.Here’s the full Chinese text:</li>
<li>for: 自动道路裂 crack 探测，以 Ensure 道路在服务寿命中的功能表现。</li>
<li>methods: 使用 encoder-decoder 框架，加入closed-loop feedback (CLF) 和生成对抗网络 (GAN)，以自动更正错误和适应环境变化。</li>
<li>results: 在三个公共数据集上表现出色，并且可以将CLF模块定义为可插入式 ком成分，以提高模型表现。<details>
<summary>Abstract</summary>
Automatic pavement crack detection is an important task to ensure the functional performances of pavements during their service life. Inspired by deep learning (DL), the encoder-decoder framework is a powerful tool for crack detection. However, these models are usually open-loop (OL) systems that tend to treat thin cracks as the background. Meanwhile, these models can not automatically correct errors in the prediction, nor can it adapt to the changes of the environment to automatically extract and detect thin cracks. To tackle this problem, we embed closed-loop feedback (CLF) into the neural network so that the model could learn to correct errors on its own, based on generative adversarial networks (GAN). The resulting model is called CrackCLF and includes the front and back ends, i.e. segmentation and adversarial network. The front end with U-shape framework is employed to generate crack maps, and the back end with a multi-scale loss function is used to correct higher-order inconsistencies between labels and crack maps (generated by the front end) to address open-loop system issues. Empirical results show that the proposed CrackCLF outperforms others methods on three public datasets. Moreover, the proposed CLF can be defined as a plug and play module, which can be embedded into different neural network models to improve their performances.
</details>
<details>
<summary>摘要</summary>
自动路面裂 crack 检测是保证路面服务寿命的重要任务。 Drawing inspiration from deep learning (DL), the encoder-decoder framework is a powerful tool for crack detection. However, these models are usually open-loop (OL) systems that tend to treat thin cracks as the background. Moreover, these models cannot automatically correct errors in the prediction, nor can they adapt to changes in the environment to automatically extract and detect thin cracks. To address this problem, we embed closed-loop feedback (CLF) into the neural network, allowing the model to learn to correct errors on its own based on generative adversarial networks (GAN). The resulting model is called CrackCLF and consists of the front and back ends, i.e., segmentation and adversarial networks. The front end uses a U-shape framework to generate crack maps, and the back end employs a multi-scale loss function to correct higher-order inconsistencies between labels and crack maps (generated by the front end) to address open-loop system issues. Empirical results show that the proposed CrackCLF outperforms other methods on three public datasets. Furthermore, the proposed CLF can be defined as a plug and play module, which can be embedded into different neural network models to improve their performances.
</details></li>
</ul>
<hr>
<h2 id="Robot-Hand-Eye-Calibration-using-Structure-from-Motion"><a href="#Robot-Hand-Eye-Calibration-using-Structure-from-Motion" class="headerlink" title="Robot Hand-Eye Calibration using Structure-from-Motion"></a>Robot Hand-Eye Calibration using Structure-from-Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11808">http://arxiv.org/abs/2311.11808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Andreff, Bernard Espiau, Radu Horaud</li>
<li>for: 这篇论文旨在提出一种新的手眼均衡方法，并且不需要使用测量仪器床。</li>
<li>methods: 这篇论文使用结构从运动和已知机械运动组合，并且可以在线性形式下解决问题，解决了手眼参数和结构从运动方法中的未知扩展因子问题。</li>
<li>results: 论文通过大量实验证明了这种方法的品质，并且与现有方法进行比较。<details>
<summary>Abstract</summary>
In this paper we propose a new flexible method for hand-eye calibration. The vast majority of existing hand-eye calibration techniques requires a calibration rig which is used in conjunction with camera pose estimation methods. Instead, we combine structure-from-motion with known robot motions and we show that the solution can be obtained in linear form. The latter solves for both the hand-eye parameters and for the unknown scale factor inherent with structure-from-motion methods. The algebraic analysis that is made possible with such a linear formulation allows to investigate not only the well known case of general screw motions but also such singular motions as pure translations, pure rotations, and planar motions. In essence, the robot-mounted camera looks to an unknown rigid layout, tracks points over an image sequence and estimates the camera-to-robot relationship. Such a self calibration process is relevant for unmanned vehicles, robots working in remote places, and so forth. We conduct a large number of experiments which validate the quality of the method by comparing it with existing ones.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的灵活手眼协调方法。大多数现有的手眼协调技术都需要使用协调机械，并且通常与摄像头位置估算方法结合使用。我们则将结构从动与知道机器人运动结合，并证明该解可以得到线性形式。这种线性形式的分析允许我们不仅研究普通的扳手运动，还可以研究特殊的运动，如纯翻译、纯旋转和平面运动。总之，机器人携带的摄像头会看到未知的固定布局，跟踪图像序列中的点并估算摄像头与机器人之间的关系。这种自动协调过程对于无人机、远程工作的机器人等非常重要。我们进行了大量实验，并证明了该方法的高效性，与现有方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="Robust-Tumor-Segmentation-with-Hyperspectral-Imaging-and-Graph-Neural-Networks"><a href="#Robust-Tumor-Segmentation-with-Hyperspectral-Imaging-and-Graph-Neural-Networks" class="headerlink" title="Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural Networks"></a>Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11782">http://arxiv.org/abs/2311.11782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mayar Lotfy, Anna Alperovich, Tommaso Giannantonio, Bjorn Barz, Xiaohan Zhang, Felix Holm, Nassir Navab, Felix Boehm, Carolin Schwamborn, Thomas K. Hoffmann, Patrick J. Schuler</li>
<li>for: 针对在手术时分界肿瘤和健康组织的问题，该文提出了一种改进的方法，利用图像频谱的空间上下文来增强分割精度。</li>
<li>methods: 该方法使用图像频谱学（HSI）和机器学习（ML）结合，并采用图像 Graph Neural Networks（GNN）传播上下文信息，以提高分割精度。</li>
<li>results: 该方法在临床外的51个HSI图像中，与无上下文方法进行比较，显示出显著的提高，能够准确地分割健康和肿瘤组织，包括在之前未见的患者图像中。此外，通过考虑本地图像质量指标，进一步提高了训练过程的稳定性。<details>
<summary>Abstract</summary>
Segmenting the boundary between tumor and healthy tissue during surgical cancer resection poses a significant challenge. In recent years, Hyperspectral Imaging (HSI) combined with Machine Learning (ML) has emerged as a promising solution. However, due to the extensive information contained within the spectral domain, most ML approaches primarily classify individual HSI (super-)pixels, or tiles, without taking into account their spatial context. In this paper, we propose an improved methodology that leverages the spatial context of tiles for more robust and smoother segmentation. To address the irregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate context information across neighboring regions. The features for each tile within the graph are extracted using a Convolutional Neural Network (CNN), which is trained simultaneously with the subsequent GNN. Moreover, we incorporate local image quality metrics into the loss function to enhance the training procedure's robustness against low-quality regions in the training images. We demonstrate the superiority of our proposed method using a clinical ex vivo dataset consisting of 51 HSI images from 30 patients. Despite the limited dataset, the GNN-based model significantly outperforms context-agnostic approaches, accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients. Furthermore, we show that our carefully designed loss function, accounting for local image quality, results in additional improvements. Our findings demonstrate that context-aware GNN algorithms can robustly find tumor demarcations on HSI images, ultimately contributing to better surgery success and patient outcome.
</details>
<details>
<summary>摘要</summary>
Segmenting the boundary between tumor and healthy tissue during cancer surgery is a challenging task. Recently, Hyperspectral Imaging (HSI) combined with Machine Learning (ML) has shown promise. However, most ML approaches only classify individual HSI pixels or tiles without considering their spatial context. In this paper, we propose an improved method that leverages the spatial context of tiles for more robust and smoother segmentation. To address the irregular shapes of tiles, we use Graph Neural Networks (GNNs) to propagate context information across neighboring regions. We extract features for each tile within the graph using a Convolutional Neural Network (CNN), which is trained simultaneously with the subsequent GNN. Additionally, we incorporate local image quality metrics into the loss function to enhance the training procedure's robustness against low-quality regions in the training images. We demonstrate the superiority of our proposed method using a clinical ex vivo dataset consisting of 51 HSI images from 30 patients. Despite the limited dataset, the GNN-based model significantly outperforms context-agnostic approaches, accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients. Furthermore, we show that our carefully designed loss function, accounting for local image quality, results in additional improvements. Our findings demonstrate that context-aware GNN algorithms can robustly find tumor demarcations on HSI images, ultimately contributing to better surgery success and patient outcome.Here's the translation in Traditional Chinese:鉴别癌细胞和健康组织界限在医疗器官切除术是一个具有挑战性的任务。最近，几何spectral imaging（HSI）与机器学习（ML）的结合已经出现了一定的推动力。然而，大多数ML方法仅将单一HSI像素或块分类为不同的类别，未能考虑这些像素之间的空间Context。在这篇文章中，我们提出了一个改进的方法，将HSI块之间的空间Context leveraged来实现更加稳定和平滑的鉴别。为了解决块的不规则形状，我们使用Graph Neural Networks（GNNs）将邻近区域之间的Context信息传递。我们对各块内的GNN构建特定的Convolutional Neural Network（CNN），并将其训练同时进行。此外，我们将本地图像质量指标入力到损失函数中，以增强训练过程的Robustness。我们使用来自30名病人的干式实验数据，包括51几何spectral imaging（HSI）图像。 despite the limited dataset, our proposed method significantly outperforms context-agnostic approaches, accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients. In addition, we show that our carefully designed loss function, accounting for local image quality, results in additional improvements. Our findings demonstrate that context-aware GNN algorithms can robustly find tumor demarcations on HSI images, ultimately contributing to better surgery success and patient outcome.
</details></li>
</ul>
<hr>
<h2 id="Multimodal-deep-learning-for-mapping-forest-dominant-height-by-fusing-GEDI-with-earth-observation-data"><a href="#Multimodal-deep-learning-for-mapping-forest-dominant-height-by-fusing-GEDI-with-earth-observation-data" class="headerlink" title="Multimodal deep learning for mapping forest dominant height by fusing GEDI with earth observation data"></a>Multimodal deep learning for mapping forest dominant height by fusing GEDI with earth observation data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11777">http://arxiv.org/abs/2311.11777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Man Chen, Wenquan Dong, Hao Yu, Iain Woodhouse, Casey M. Ryan, Haoyu Liu, Selena Georgiou, Edward T. A. Mitchard</li>
<li>for: 这个论文的目的是使用多源 remote sensing 数据和深度学习模型精准地测量高分辨率森林高度。</li>
<li>methods: 这个论文使用了一种新的深度学习框架，即多Modal attention remote sensing network (MARSNet)，来估算森林主要高度。 MARSNet 使用了 GEDI 相对高度 metric，以及 Setinel-1 数据、ALOS-2 PALSAR-2 数据、Sentinel-2 光学数据和 auxiliary data，并使用了每个 remote sensing 数据模式的独立编码器来提取多尺度特征，以及共享解码器来融合特征并估算高度。</li>
<li>results: 根据实验结果，MARSNet 可以准确地估算森林主要高度，其 R2 值为 0.62，RMSE 值为 2.82 m，比random forest 方法的 R2 值为 0.55，RMSE 值为 3.05 m 高。此外，通过独立验证使用场景测量数据，MARSNet 在 Jilin, China 地区生成的墙壁到墙壁高程图像中达到了 R2 值为 0.58，RMSE 值为 3.76 m，比random forest 基准值的 R2 值为 0.41，RMSE 值为 4.37 m 高。<details>
<summary>Abstract</summary>
The integration of multisource remote sensing data and deep learning models offers new possibilities for accurately mapping high spatial resolution forest height. We found that GEDI relative heights (RH) metrics exhibited strong correlation with the mean of the top 10 highest trees (dominant height) measured in situ at the corresponding footprint locations. Consequently, we proposed a novel deep learning framework termed the multi-modal attention remote sensing network (MARSNet) to estimate forest dominant height by extrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2 PALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises separate encoders for each remote sensing data modality to extract multi-scale features, and a shared decoder to fuse the features and estimate height. Using individual encoders for each remote sensing imagery avoids interference across modalities and extracts distinct representations. To focus on the efficacious information from each dataset, we reduced the prevalent spatial and band redundancies in each remote sensing data by incorporating the extended spatial and band reconstruction convolution modules in the encoders. MARSNet achieved commendable performance in estimating dominant height, with an R2 of 0.62 and RMSE of 2.82 m, outperforming the widely used random forest approach which attained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained MARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin, China. Through independent validation using field measurements, MARSNet demonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for the random forest baseline. Our research demonstrates the effectiveness of a multimodal deep learning approach fusing GEDI with SAR and passive optical imagery for enhancing the accuracy of high resolution dominant height estimation.
</details>
<details>
<summary>摘要</summary>
“多源Remote数据和深度学习模型的结合，提供了新的高分辨率森林高度映射的可能性。我们发现，GEDI相对高度（RH）指标与场地上最高10棵树的平均高度（主对比高度）存在强正相关。因此，我们提出了一个名为多模式注意深度测网络（MARSNet）的新型深度学习框架，以估算森林主对比高度。MARSNet包括每个遥测数据模式的分类器，以EXTRACT多尺度特征，并使用共同解码器将特征联合估算高度。这种多模式注意框架避免了遥测数据模式之间的干扰，并EXTRACT了不同的表现。为了优化遥测数据模式中的常见空间和频率红UNDERSCORE，我们在遥测数据模式中添加了扩展空间和频率重建对应模组。MARSNet在主对比高度估算中表现出色，R2值为0.62，RMSE值为2.82米，比Random Forest方法（R2值为0.55，RMSE值为3.05米）更高。最后，我们将训练好的MARSNet模型应用到Jilin、中国的壁垒壁垒地图上。通过独立验证过程，MARSNet在10米分辨率上的R2值为0.58，RMSE值为3.76米，较Random Forest基eline（R2值为0.41，RMSE值为4.37米）更高。我们的研究显示，结合GEDI、SAR和透明光学图像的多模式深度学习方法可以提高高分辨率主对比高度估算的精度。”
</details></li>
</ul>
<hr>
<h2 id="Practical-cross-sensor-color-constancy-using-a-dual-mapping-strategy"><a href="#Practical-cross-sensor-color-constancy-using-a-dual-mapping-strategy" class="headerlink" title="Practical cross-sensor color constancy using a dual-mapping strategy"></a>Practical cross-sensor color constancy using a dual-mapping strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11773">http://arxiv.org/abs/2311.11773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Yue, Minchen Wei</li>
<li>for: 用于解决数据收集问题，减少感器差异，提高材料推理性能。</li>
<li>methods: 使用双映射策略，只需要一个简单的白点测试感器，从而 derivation 一个映射矩阵，用于重建图像数据和照明。然后，使用轻量级多层感知网络（MLP）模型，对重构的图像数据进行优化，使用重构的照明为真实值。</li>
<li>results: 可以减少感器差异，实现与主流横批方法相当的性能，仅需要小量内存（约0.003 MB）和训练时间（约1小时），并且具有快速执行速度（约0.3 ms和1 ms），不敏感输入图像分辨率。因此，它可以实现现实中的数据收集问题。<details>
<summary>Abstract</summary>
Deep Neural Networks (DNNs) have been widely used for illumination estimation, which is time-consuming and requires sensor-specific data collection. Our proposed method uses a dual-mapping strategy and only requires a simple white point from a test sensor under a D65 condition. This allows us to derive a mapping matrix, enabling the reconstructions of image data and illuminants. In the second mapping phase, we transform the re-constructed image data into sparse features, which are then optimized with a lightweight multi-layer perceptron (MLP) model using the re-constructed illuminants as ground truths. This approach effectively reduces sensor discrepancies and delivers performance on par with leading cross-sensor methods. It only requires a small amount of memory (~0.003 MB), and takes ~1 hour training on an RTX3070Ti GPU. More importantly, the method can be implemented very fast, with ~0.3 ms and ~1 ms on a GPU or CPU respectively, and is not sensitive to the input image resolution. Therefore, it offers a practical solution to the great challenges of data recollection that is faced by the industry.
</details>
<details>
<summary>摘要</summary>
Note:* "DNNs" is translated as "深度神经网络" (shēn dào shén zhī wǎng luò)* "illumination estimation" is translated as "照明估算" (zhao ming gueshan)* "sensor-specific data collection" is translated as "传感器特定数据收集" (chuán jiāo tè qì dàta jīng)* "dual-mapping strategy" is translated as "双映射策略" (shuāng yǐng xiàng cè lüè)* "simple white point" is translated as "简单的白点" (jiǎn dan de bái diǎn)* "re-constructed image data" is translated as "重构图像数据" (zhòng gòu tú xiàng shù dà)* "sparse features" is translated as "稀疏特征" (xī shū tè xíng)* "lightweight multi-layer perceptron" is translated as "轻量级多层感知器" (qīng liáng jí duō cèng qiǎng)* "ground truths" is translated as "真实值" (zhēn shí zhí)* "data recollection" is translated as "数据收集" (dàta jīng jī)
</details></li>
</ul>
<hr>
<h2 id="A-Good-Feature-Extractor-Is-All-You-Need-for-Weakly-Supervised-Learning-in-Histopathology"><a href="#A-Good-Feature-Extractor-Is-All-You-Need-for-Weakly-Supervised-Learning-in-Histopathology" class="headerlink" title="A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology"></a>A Good Feature Extractor Is All You Need for Weakly Supervised Learning in Histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11772">http://arxiv.org/abs/2311.11772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Georg Wölflein, Dyke Ferber, Asier Rabasco Meneghetti, Omar S. M. El Nahhas, Daniel Truhn, Zunamys I. Carrero, David J. Harrison, Ognjen Arandjelović, Jakob N. Kather</li>
<li>for: 这 paper 的目的是检验公共可用的 SSL 特征提取器在 computation pathology 领域的稳定性和可靠性。</li>
<li>methods: 这 paper 使用了多种方法来评估特征提取器的稳定性，包括 omitting stain normalization 和图像扩展，以及使用不同的预处理方法和下游结构。</li>
<li>results: 研究发现，不使用 stain normalization 和图像扩展可以减少内存和计算量，同时不会影响下游性能。此外，研究还发现最高级别的特征提取器在不同的染色和旋转等变量下的稳定性非常高。<details>
<summary>Abstract</summary>
Deep learning is revolutionising pathology, offering novel opportunities in disease prognosis and personalised treatment. Historically, stain normalisation has been a crucial preprocessing step in computational pathology pipelines, and persists into the deep learning era. Yet, with the emergence of feature extractors trained using self-supervised learning (SSL) on diverse pathology datasets, we call this practice into question. In an empirical evaluation of publicly available feature extractors, we find that omitting stain normalisation and image augmentations does not compromise downstream performance, while incurring substantial savings in memory and compute. Further, we show that the top-performing feature extractors are remarkably robust to variations in stain and augmentations like rotation in their latent space. Contrary to previous patch-level benchmarking studies, our approach emphasises clinical relevance by focusing on slide-level prediction tasks in a weakly supervised setting with external validation cohorts. This work represents the most comprehensive robustness evaluation of public pathology SSL feature extractors to date, involving more than 6,000 training runs across nine tasks, five datasets, three downstream architectures, and various preprocessing setups. Our findings stand to streamline digital pathology workflows by minimising preprocessing needs and informing the selection of feature extractors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Non-Contact-NIR-PPG-Sensing-through-Large-Sequence-Signal-Regression"><a href="#Non-Contact-NIR-PPG-Sensing-through-Large-Sequence-Signal-Regression" class="headerlink" title="Non-Contact NIR PPG Sensing through Large Sequence Signal Regression"></a>Non-Contact NIR PPG Sensing through Large Sequence Signal Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11757">http://arxiv.org/abs/2311.11757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timothy Hanley, Dara Golden, Robyn Maxwell, Ashkan Parsi, Joseph Lemley</li>
<li>for: 这个论文是为了演示一种替代Convolution Attention Network（CAN）架构，用于从近红外（NIR）视频中回归血氧饱和信号。</li>
<li>methods: 该论文使用了两个公共可用的数据集，将其分割成训练和测试集，并对这些数据集进行了增强以避免过度适应。</li>
<li>results: 使用这种CAN架构和NIR视频，可以实现 Mean Average Error（MAE）为0.99 bpm的准确信号输出。<details>
<summary>Abstract</summary>
Non-Contact sensing is an emerging technology with applications across many industries from driver monitoring in vehicles to patient monitoring in healthcare. Current state-of-the-art implementations focus on RGB video, but this struggles in varying/noisy light conditions and is almost completely unfeasible in the dark. Near Infra-Red (NIR) video, however, does not suffer from these constraints. This paper aims to demonstrate the effectiveness of an alternative Convolution Attention Network (CAN) architecture, to regress photoplethysmography (PPG) signal from a sequence of NIR frames. A combination of two publicly available datasets, which is split into train and test sets, is used for training the CAN. This combined dataset is augmented to reduce overfitting to the 'normal' 60 - 80 bpm heart rate range by providing the full range of heart rates along with corresponding videos for each subject. This CAN, when implemented over video cropped to the subject's head, achieved a Mean Average Error (MAE) of just 0.99 bpm, proving its effectiveness on NIR video and the architecture's feasibility to regress an accurate signal output.
</details>
<details>
<summary>摘要</summary>
非接触感测是一种emerging技术，有各种应用于多个行业，从车辆驾驶员监测到医疗保健中的病人监测。当前状态的技术实现都是基于RGB视频，但这在不同/噪音的照明条件下遇到困难，而且在黑暗的情况下基本无法实现。然而，近红外（NIR）视频不受这些限制。这篇论文旨在示出一种替代卷积注意网络（CAN）架构，用于从NIR视频序列中回归血液搅动（PPG）信号。使用两个公共可用的数据集，分别用于训练和测试CAN。这些合并的数据集通过减少适应范围的补做来降低过适应，并提供每个主题对应的视频和心率范围的全范围。这种CAN，当实现在对头部截取的视频上时，实现了 Mean Average Error（MAE）仅0.99 bpm，证明其效果性在NIR视频和架构上。
</details></li>
</ul>
<hr>
<h2 id="AdvGen-Physical-Adversarial-Attack-on-Face-Presentation-Attack-Detection-Systems"><a href="#AdvGen-Physical-Adversarial-Attack-on-Face-Presentation-Attack-Detection-Systems" class="headerlink" title="AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems"></a>AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11753">http://arxiv.org/abs/2311.11753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Amrit Patnaik, Shivali Chansoriya, Anil K. Jain, Anoop M. Namboodiri<br>for: 这个论文的目的是评估面部识别系统在真实世界中的风险水平，以确保在实际应用中安全地部署面部识别模型。methods: 该论文使用了一种自动生成的对抗网络（AdvGen）来模拟印刷和重播攻击，并生成了一些可以识别系统欺骗的图像。results: 该论文的实验结果显示，使用AdvGen生成的攻击图像可以成功欺骗state-of-the-art PADs的92.01%。该论文在四个数据集和十个现状顶尖PADs上进行了广泛的测试。此外，该论文还在真实的物理环境中进行了实际的测试，以证明攻击的有效性。<details>
<summary>Abstract</summary>
Evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. Popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. Recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. While most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. This paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. We propose AdvGen, an automated Generative Adversarial Network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art PADs in a physical domain attack setting. Using this attack strategy, the attack success rate goes up to 82.01%. We test AdvGen extensively on four datasets and ten state-of-the-art PADs. We also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment.
</details>
<details>
<summary>摘要</summary>
evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. while most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. this paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. we propose advgen, an automated generative adversarial network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art pad in a physical domain attack setting. using this attack strategy, the attack success rate goes up to 82.01%. we test advgen extensively on four datasets and ten state-of-the-art pad. we also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment.Note: The translation is done using Google Translate, and may not be perfect or exact.
</details></li>
</ul>
<hr>
<h2 id="Fuzzy-Information-Seeded-Region-Growing-for-Automated-Lesions-After-Stroke-Segmentation-in-MR-Brain-Images"><a href="#Fuzzy-Information-Seeded-Region-Growing-for-Automated-Lesions-After-Stroke-Segmentation-in-MR-Brain-Images" class="headerlink" title="Fuzzy Information Seeded Region Growing for Automated Lesions After Stroke Segmentation in MR Brain Images"></a>Fuzzy Information Seeded Region Growing for Automated Lesions After Stroke Segmentation in MR Brain Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11742">http://arxiv.org/abs/2311.11742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mawio02/fisrg-for-automated-lesion-after-stroke-segmentation-in-mri">https://github.com/mawio02/fisrg-for-automated-lesion-after-stroke-segmentation-in-mri</a></li>
<li>paper_authors: Mario Pascual González</li>
<li>for: 针对干病变的精准分割</li>
<li>methods: 基于模糊逻辑和种子域生长算法</li>
<li>results: 高达94.2%的 dice分数，表明算法可以准确分割干病变Here’s a breakdown of each item:</li>
<li>for: The paper is written for the purpose of precise segmentation of stroke lesions from brain MRI images.</li>
<li>methods: The paper introduces an innovative approach using a Fuzzy Information Seeded Region Growing (FISRG) algorithm, which combines fuzzy logic with Seeded Region Growing (SRG) techniques to enhance segmentation accuracy.</li>
<li>results: The highest Dice score achieved in the experiments was 94.2%, indicating a high degree of similarity between the algorithm’s output and the expert-validated ground truth. The best average Dice score was recorded in the third experiment, amounting to 88.1%, highlighting the algorithm’s efficacy in consistently segmenting stroke lesions across various slices.<details>
<summary>Abstract</summary>
In the realm of medical imaging, precise segmentation of stroke lesions from brain MRI images stands as a critical challenge with significant implications for patient diagnosis and treatment. Addressing this, our study introduces an innovative approach using a Fuzzy Information Seeded Region Growing (FISRG) algorithm. Designed to effectively delineate the complex and irregular boundaries of stroke lesions, the FISRG algorithm combines fuzzy logic with Seeded Region Growing (SRG) techniques, aiming to enhance segmentation accuracy.   The research involved three experiments to optimize the FISRG algorithm's performance, each focusing on different parameters to improve the accuracy of stroke lesion segmentation. The highest Dice score achieved in these experiments was 94.2\%, indicating a high degree of similarity between the algorithm's output and the expert-validated ground truth. Notably, the best average Dice score, amounting to 88.1\%, was recorded in the third experiment, highlighting the efficacy of the algorithm in consistently segmenting stroke lesions across various slices.   Our findings reveal the FISRG algorithm's strengths in handling the heterogeneity of stroke lesions. However, challenges remain in areas of abrupt lesion topology changes and in distinguishing lesions from similar intensity brain regions. The results underscore the potential of the FISRG algorithm in contributing significantly to advancements in medical imaging analysis for stroke diagnosis and treatment.
</details>
<details>
<summary>摘要</summary>
在医疗影像领域，精准分割脑出血损害从脑MRI图像中的stroke损害是一项重要挑战，对患者诊断和治疗具有重要意义。我们的研究推出了一种创新的方法，利用Fuzzy Information Seeded Region Growing（FISRG）算法。这种算法结合了混淆逻辑和Seeded Region Growing（SRG）技术，以提高分割精度。我们的研究包括三个实验，以便优化FISRG算法的性能。每个实验都关注不同的参数，以提高脑出血损害分割的准确率。最高的Dice分数为94.2%，表明算法的输出和专家验证的真实值之间存在高度的相似性。其中第三个实验的平均Dice分数为88.1%，表明算法在不同的剖面上具有一定的稳定性。我们的发现表明FISRG算法在处理脑出血损害的不同类型和分布方面具有优异的能力。然而，在脑出血损害的突然变化和同INTENSITY的脑区域之间存在挑战。结果表明FISRG算法在医疗影像分析方面具有广泛的应用前景，对脑出血损害诊断和治疗具有重要意义。
</details></li>
</ul>
<hr>
<h2 id="On-the-Importance-of-Large-Objects-in-CNN-Based-Object-Detection-Algorithms"><a href="#On-the-Importance-of-Large-Objects-in-CNN-Based-Object-Detection-Algorithms" class="headerlink" title="On the Importance of Large Objects in CNN Based Object Detection Algorithms"></a>On the Importance of Large Objects in CNN Based Object Detection Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11714">http://arxiv.org/abs/2311.11714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmed Ben Saad, Gabriele Facciolo, Axel Davy</li>
<li>for: 提高对象检测器的性能（Object Detectors performances）</li>
<li>methods: 引入一个归一化面积大小（object area size）的补偿项到训练损失中（introduce a weighting term into the training loss）</li>
<li>results: 在所有对象大小上提高检测分数 (+2 p.p. of mAP on small objects, +2 p.p. on medium and +4 p.p. on large on COCO val 2017 with InternImage-T)<details>
<summary>Abstract</summary>
Object detection models, a prominent class of machine learning algorithms, aim to identify and precisely locate objects in images or videos. However, this task might yield uneven performances sometimes caused by the objects sizes and the quality of the images and labels used for training. In this paper, we highlight the importance of large objects in learning features that are critical for all sizes. Given these findings, we propose to introduce a weighting term into the training loss. This term is a function of the object area size. We show that giving more weight to large objects leads to improved detection scores across all object sizes and so an overall improvement in Object Detectors performances (+2 p.p. of mAP on small objects, +2 p.p. on medium and +4 p.p. on large on COCO val 2017 with InternImage-T). Additional experiments and ablation studies with different models and on a different dataset further confirm the robustness of our findings.
</details>
<details>
<summary>摘要</summary>
Note:* "p.p." stands for "percentage points"* "COCO" stands for "Common Objects in Context"* "val 2017" stands for "validation set in 2017"* "InternImage-T" stands for "International Image-Text"
</details></li>
</ul>
<hr>
<h2 id="GS-SLAM-Dense-Visual-SLAM-with-3D-Gaussian-Splatting"><a href="#GS-SLAM-Dense-Visual-SLAM-with-3D-Gaussian-Splatting" class="headerlink" title="GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting"></a>GS-SLAM: Dense Visual SLAM with 3D Gaussian Splatting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11700">http://arxiv.org/abs/2311.11700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi Yan, Delin Qu, Dong Wang, Dan Xu, Zhigang Wang, Bin Zhao, Xuelong Li</li>
<li>for: 这paper是为了提出一种新的同时地址和地图建模（SLAM）系统，使其更好地平衡效率和准确性。</li>
<li>methods: 该方法使用3D Gaussian表示法，并使用实时可导渲染管线来加速地图优化和RGB-D重新渲染。具体来说，该方法提出了一种适应扩展策略，以有效地重建新观察到的场景几何结构，并改进已经观察到的区域的地图。此外，在pose tracking过程中，还设计了一种有效的粗粒度优化技术，以选择可靠的3D Gaussian表示，从而降低运行时间和提高估计稳定性。</li>
<li>results: 该方法在Replica和TUM-RGBD datasets上实现了与现有实时方法相当的性能。Here’s the translation in English for reference:</li>
<li>for: This paper proposes a new Simultaneous Localization and Mapping (SLAM) system that achieves a better balance between efficiency and accuracy.</li>
<li>methods: The method uses 3D Gaussian representation and employs a real-time differentiable splatting rendering pipeline to accelerate map optimization and RGB-D re-rendering. Specifically, the method proposes an adaptive expansion strategy to efficiently reconstruct new observed scene geometry and improve the mapping of previously observed areas. Moreover, an effective coarse-to-fine technique is designed to select reliable 3D Gaussian representations for camera pose optimization, resulting in runtime reduction and robust estimation.</li>
<li>results: The method achieves competitive performance with existing state-of-the-art real-time methods on the Replica and TUM-RGBD datasets.<details>
<summary>Abstract</summary>
In this paper, we introduce $\textbf{GS-SLAM}$ that first utilizes 3D Gaussian representation in the Simultaneous Localization and Mapping (SLAM) system. It facilitates a better balance between efficiency and accuracy. Compared to recent SLAM methods employing neural implicit representations, our method utilizes a real-time differentiable splatting rendering pipeline that offers significant speedup to map optimization and RGB-D re-rendering. Specifically, we propose an adaptive expansion strategy that adds new or deletes noisy 3D Gaussian in order to efficiently reconstruct new observed scene geometry and improve the mapping of previously observed areas. This strategy is essential to extend 3D Gaussian representation to reconstruct the whole scene rather than synthesize a static object in existing methods. Moreover, in the pose tracking process, an effective coarse-to-fine technique is designed to select reliable 3D Gaussian representations to optimize camera pose, resulting in runtime reduction and robust estimation. Our method achieves competitive performance compared with existing state-of-the-art real-time methods on the Replica, TUM-RGBD datasets. The source code will be released upon acceptance.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了$\textbf{GS-SLAM}$，它首先利用3D Gaussian表示法在同时定位和地图（SLAM）系统中使用。这种方法可以更好地平衡效率和准确性。与现有的SLAM方法使用神经网络卷积表示法相比，我们的方法使用了实时可导渲染管线，从而提供了显著的速度提升，以便地图优化和RGB-D重新渲染。具体来说，我们提出了适应扩展策略，可以有效地重建新观察到的场景几何结构，并改进之前观察到的地图。这种策略是在扩展3D Gaussian表示法来重建整个场景，而不是在现有方法中Synthesize一个静止物体。此外，在姿态跟踪过程中，我们设计了一种有效的粗略至细节技术，可以选择可靠的3D Gaussian表示法来优化相机姿态，从而实现运行时间减少和稳定估计。我们的方法在Replica和TUM-RGBD数据集上达到了与现有实时方法的竞争性表现。我们计划在接受后发布源代码。
</details></li>
</ul>
<hr>
<h2 id="Cut-and-Paste-Subject-Driven-Video-Editing-with-Attention-Control"><a href="#Cut-and-Paste-Subject-Driven-Video-Editing-with-Attention-Control" class="headerlink" title="Cut-and-Paste: Subject-Driven Video Editing with Attention Control"></a>Cut-and-Paste: Subject-Driven Video Editing with Attention Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11697">http://arxiv.org/abs/2311.11697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhichao Zuo, Zhao Zhang, Yan Luo, Yang Zhao, Haijun Zhang, Yi Yang, Meng Wang</li>
<li>for: 本研究提出了一种名为“剪贴”的框架，用于实际世界上进行Semantic Video editing，以文本提示和补充图像的指导。</li>
<li>methods: 本研究使用了文本驱动视频编辑，并引入了参考图像作为补充输入，以提高精细Semantic editing的控制和背景保留。我们还使用了 crossed attention control方法来限制编辑区域，以保持视频背景和空间时间一致性。</li>
<li>results: 对于文本提示和补充图像的视频编辑，我们的方法比现有方法表现出色， both quantitative and subjective evaluations 都显示了这一点。<details>
<summary>Abstract</summary>
This paper presents a novel framework termed Cut-and-Paste for real-word semantic video editing under the guidance of text prompt and additional reference image. While the text-driven video editing has demonstrated remarkable ability to generate highly diverse videos following given text prompts, the fine-grained semantic edits are hard to control by plain textual prompt only in terms of object details and edited region, and cumbersome long text descriptions are usually needed for the task. We therefore investigate subject-driven video editing for more precise control of both edited regions and background preservation, and fine-grained semantic generation. We achieve this goal by introducing an reference image as supplementary input to the text-driven video editing, which avoids racking your brain to come up with a cumbersome text prompt describing the detailed appearance of the object. To limit the editing area, we refer to a method of cross attention control in image editing and successfully extend it to video editing by fusing the attention map of adjacent frames, which strikes a balance between maintaining video background and spatio-temporal consistency. Compared with current methods, the whole process of our method is like ``cut" the source object to be edited and then ``paste" the target object provided by reference image. We demonstrate that our method performs favorably over prior arts for video editing under the guidance of text prompt and extra reference image, as measured by both quantitative and subjective evaluations.
</details>
<details>
<summary>摘要</summary>
To limit the editing area, we extend a cross attention control method from image editing to video editing by fusing attention maps of adjacent frames. This approach balances video background and spatio-temporal consistency. Our method is like "cutting" the source object to be edited and "pasting" the target object provided by the reference image.Compared to current methods, our approach performs favorably in both quantitative and subjective evaluations. The whole process of our method is simple and easy to use, making it a valuable tool for real-world video editing tasks.
</details></li>
</ul>
<hr>
<h2 id="Clarity-ChatGPT-An-Interactive-and-Adaptive-Processing-System-for-Image-Restoration-and-Enhancement"><a href="#Clarity-ChatGPT-An-Interactive-and-Adaptive-Processing-System-for-Image-Restoration-and-Enhancement" class="headerlink" title="Clarity ChatGPT: An Interactive and Adaptive Processing System for Image Restoration and Enhancement"></a>Clarity ChatGPT: An Interactive and Adaptive Processing System for Image Restoration and Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11695">http://arxiv.org/abs/2311.11695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyan Wei, Zhao Zhang, Jiahuan Ren, Xiaogang Xu, Richang Hong, Yi Yang, Shuicheng Yan, Meng Wang</li>
<li>for: 提高图像修复和提高（IRE）方法的通用能力和互动性，解决现有IRE方法的限制，包括有限的预训练数据和不具备用户反馈机制等。</li>
<li>methods: 提出了一种基于对话智能的转换系统，名为Clarity ChatGPT，它结合多种IRE方法，可以自动识别图像异常类型并选择合适的IRE方法进行修复，或者基于用户反馈进行迭代生成满意的结果。</li>
<li>results: 通过实验研究，显示了Clarity ChatGPT可以有效提高IRE方法的通用能力和互动性，并在低级别领域中填补现有视力语言模型的空白。<details>
<summary>Abstract</summary>
The generalization capability of existing image restoration and enhancement (IRE) methods is constrained by the limited pre-trained datasets, making it difficult to handle agnostic inputs such as different degradation levels and scenarios beyond their design scopes. Moreover, they are not equipped with interactive mechanisms to consider user preferences or feedback, and their end-to-end settings cannot provide users with more choices. Faced with the above-mentioned IRE method's limited performance and insufficient interactivity, we try to solve it from the engineering and system framework levels. Specifically, we propose Clarity ChatGPT-a transformative system that combines the conversational intelligence of ChatGPT with multiple IRE methods. Clarity ChatGPT can automatically detect image degradation types and select appropriate IRE methods to restore images, or iteratively generate satisfactory results based on user feedback. Its innovative features include a CLIP-powered detector for accurate degradation classification, no-reference image quality evaluation for performance evaluation, region-specific processing for precise enhancements, and advanced fusion techniques for optimal restoration results. Clarity ChatGPT marks a significant advancement in integrating language and vision, enhancing image-text interactions, and providing a robust, high-performance IRE solution. Our case studies demonstrate that Clarity ChatGPT effectively improves the generalization and interaction capabilities in the IRE, and also fills the gap in the low-level domain of the existing vision-language model.
</details>
<details>
<summary>摘要</summary>
现有的图像修复和提高（IRE）方法的通用能力受到先前训练数据的限制，导致处理不同降低水平和场景外的困难。此外，它们没有交互机制来考虑用户喜好或反馈，其端到端设置也无法提供更多的选择。为了解决以上IRE方法的局限性和不足，我们尝试从工程和系统框架层面进行解决方案。具体来说，我们提出了“清晰聊天GPT”——一种将语言智能和多种IRE方法结合起来的转变系统。清晰聊天GPT可以自动探测图像降低类型，选择合适的IRE方法来修复图像，或者基于用户反馈进行迭代生成满意的结果。它的创新特点包括CLIP权重推导的准确降低类型检测、无参考图像质量评估、地区特定处理和高级融合技术。清晰聊天GPT标志着视语 integreation的重大进步，提高图像-文本交互，并提供了高性能的IRE解决方案。我们的案例研究表明，清晰聊天GPT可以提高IRE的通用和交互能力，同时填补现有视语模型的低级域空白。
</details></li>
</ul>
<hr>
<h2 id="Segment-Together-A-Versatile-Paradigm-for-Semi-Supervised-Medical-Image-Segmentation"><a href="#Segment-Together-A-Versatile-Paradigm-for-Semi-Supervised-Medical-Image-Segmentation" class="headerlink" title="Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image Segmentation"></a>Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11686">http://arxiv.org/abs/2311.11686</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingjie Zeng, Yutong Xie, Zilin Lu, Mengkang Lu, Yicheng Wu, Yong Xia<br>for: 这个研究旨在提高医疗影像分类 tasks 的训练，使用 semi-supervised learning 方法，并且能够应用于诊疗实际中。methods: 这个研究使用了一个名为 VerSemi 的框架，它可以统一多个 задачі，并且使用了一个动态的任务讯息来驱动模型的训练。另外，这个研究还使用了一个 synthetic task 的方法，将多个任务的训练结果融合在一起，以提高模型的精度。results: 这个研究的结果显示，VerSemi 可以在四个公开的 benchmarking 数据集上进行高效的训练，并且能够与第二个最佳方法相比，实现了大幅度的提升（例如，平均提升2.69% Dice 数据）， thereby setting a new SOTA performance for semi-supervised medical image segmentation.<details>
<summary>Abstract</summary>
Annotation scarcity has become a major obstacle for training powerful deep-learning models for medical image segmentation, restricting their deployment in clinical scenarios. To address it, semi-supervised learning by exploiting abundant unlabeled data is highly desirable to boost the model training. However, most existing works still focus on limited medical tasks and underestimate the potential of learning across diverse tasks and multiple datasets. Therefore, in this paper, we introduce a \textbf{Ver}satile \textbf{Semi}-supervised framework (VerSemi) to point out a new perspective that integrates various tasks into a unified model with a broad label space, to exploit more unlabeled data for semi-supervised medical image segmentation. Specifically, we introduce a dynamic task-prompted design to segment various targets from different datasets. Next, this unified model is used to identify the foreground regions from all labeled data, to capture cross-dataset semantics. Particularly, we create a synthetic task with a cutmix strategy to augment foreground targets within the expanded label space. To effectively utilize unlabeled data, we introduce a consistency constraint. This involves aligning aggregated predictions from various tasks with those from the synthetic task, further guiding the model in accurately segmenting foreground regions during training. We evaluated our VerSemi model on four public benchmarking datasets. Extensive experiments demonstrated that VerSemi can consistently outperform the second-best method by a large margin (e.g., an average 2.69\% Dice gain on four datasets), setting new SOTA performance for semi-supervised medical image segmentation. The code will be released.
</details>
<details>
<summary>摘要</summary>
Annotation scarcity has become a major obstacle for training powerful deep-learning models for medical image segmentation, restricting their deployment in clinical scenarios. To address it, semi-supervised learning by exploiting abundant unlabeled data is highly desirable to boost the model training. However, most existing works still focus on limited medical tasks and underestimate the potential of learning across diverse tasks and multiple datasets. Therefore, in this paper, we introduce a верatile semi-supervised framework (VerSemi) to point out a new perspective that integrates various tasks into a unified model with a broad label space, to exploit more unlabeled data for semi-supervised medical image segmentation. Specifically, we introduce a dynamic task-prompted design to segment various targets from different datasets. Next, this unified model is used to identify the foreground regions from all labeled data, to capture cross-dataset semantics. Particularly, we create a synthetic task with a cutmix strategy to augment foreground targets within the expanded label space. To effectively utilize unlabeled data, we introduce a consistency constraint. This involves aligning aggregated predictions from various tasks with those from the synthetic task, further guiding the model in accurately segmenting foreground regions during training. We evaluated our VerSemi model on four public benchmarking datasets. Extensive experiments demonstrated that VerSemi can consistently outperform the second-best method by a large margin (e.g., an average 2.69\% Dice gain on four datasets), setting new SOTA performance for semi-supervised medical image segmentation. The code will be released.
</details></li>
</ul>
<hr>
<h2 id="PMP-Swin-Multi-Scale-Patch-Message-Passing-Swin-Transformer-for-Retinal-Disease-Classification"><a href="#PMP-Swin-Multi-Scale-Patch-Message-Passing-Swin-Transformer-for-Retinal-Disease-Classification" class="headerlink" title="PMP-Swin: Multi-Scale Patch Message Passing Swin Transformer for Retinal Disease Classification"></a>PMP-Swin: Multi-Scale Patch Message Passing Swin Transformer for Retinal Disease Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11669">http://arxiv.org/abs/2311.11669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihan Yang, Zhiming Cheng, Tengjin Weng, Shucheng He, Yaqi Wang, Xin Ye, Shuai Wang</li>
<li>for: 这个研究旨在提出一个新的架构，以帮助早期识别眼睛疾病，并且能够实现高精度的多类别分类。</li>
<li>methods: 我们提出了一个基于Message Passing机制的Patch Message Passing（PMP）模组，以建立全局的交互和捕捉不同疾病之间的微妙差异。此外，我们还将多个PMP模组组合在一起，以捕捉不同大小的病理特征。</li>
<li>results: 我们在两个 dataset 上进行了严格的实验，结果显示我们的方法具有较高的效果，较前一代方法。<details>
<summary>Abstract</summary>
Retinal disease is one of the primary causes of visual impairment, and early diagnosis is essential for preventing further deterioration. Nowadays, many works have explored Transformers for diagnosing diseases due to their strong visual representation capabilities. However, retinal diseases exhibit milder forms and often present with overlapping signs, which pose great difficulties for accurate multi-class classification. Therefore, we propose a new framework named Multi-Scale Patch Message Passing Swin Transformer for multi-class retinal disease classification. Specifically, we design a Patch Message Passing (PMP) module based on the Message Passing mechanism to establish global interaction for pathological semantic features and to exploit the subtle differences further between different diseases. Moreover, considering the various scale of pathological features we integrate multiple PMP modules for different patch sizes. For evaluation, we have constructed a new dataset, named OPTOS dataset, consisting of 1,033 high-resolution fundus images photographed by Optos camera and conducted comprehensive experiments to validate the efficacy of our proposed method. And the results on both the public dataset and our dataset demonstrate that our method achieves remarkable performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
retinal disease 是一种主要的视力障碍原因，早期诊断非常重要，以防止进一步的衰退。现在，许多研究已经利用 Transformers 来诊断疾病，因为它们具有强视觉表示能力。然而，Retinal diseases 表现为柔性的形式，经常出现相互重叠的征标，这会对准确多类分类造成很大的挑战。因此，我们提出了一个新的框架，即 Multi-Scale Patch Message Passing Swin Transformer，用于多类 Retinal disease 分类。具体来说，我们设计了一个 Patch Message Passing（PMP）模块，基于Message Passing机制，以便在不同疾病之间建立全局交互，并利用不同疾病之间的微妙差异。此外，考虑到不同疾病的特征缺失，我们将多个 PMP 模块集成到不同的 patch 大小中。为了评估我们的提议方法，我们创建了一个新的数据集，名为 OPTOS 数据集，包含 1,033 个高分辨率背部图像，通过 Optos 摄像机拍摄，并进行了全面的实验来验证我们的提议方法的效果。结果表明，我们的方法在公共数据集和我们的数据集上都具有惊人的表现，与现有方法相比。
</details></li>
</ul>
<hr>
<h2 id="OmniSeg3D-Omniversal-3D-Segmentation-via-Hierarchical-Contrastive-Learning"><a href="#OmniSeg3D-Omniversal-3D-Segmentation-via-Hierarchical-Contrastive-Learning" class="headerlink" title="OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning"></a>OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11666">http://arxiv.org/abs/2311.11666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyang Ying, Yixuan Yin, Jinzhi Zhang, Fan Wang, Tao Yu, Ruqi Huang, Lu Fang</li>
<li>for: 这 paper 旨在提供一种通用的3D场景分割方法，能够无restriction地分割多种对象，同时反映Scene中的层次结构。</li>
<li>methods: 该方法基于一种层次对比学习框架，通过两步来实现：首先，设计了一种新的层次表示，基于类型不敏感的2D分割来模型像素之间的多层关系。其次，从3D特征场景中抽取出图像特征，并在不同层次进行分组，可以根据层次关系进行聚合或分离。</li>
<li>results: 对于高质量的3D分割和准确的层次结构理解，该方法显示了效果。同时，一个图形用户界面可以帮助用户进行自由交互，以实现通用的3D分割。<details>
<summary>Abstract</summary>
Towards holistic understanding of 3D scenes, a general 3D segmentation method is needed that can segment diverse objects without restrictions on object quantity or categories, while also reflecting the inherent hierarchical structure. To achieve this, we propose OmniSeg3D, an omniversal segmentation method aims for segmenting anything in 3D all at once. The key insight is to lift multi-view inconsistent 2D segmentations into a consistent 3D feature field through a hierarchical contrastive learning framework, which is accomplished by two steps. Firstly, we design a novel hierarchical representation based on category-agnostic 2D segmentations to model the multi-level relationship among pixels. Secondly, image features rendered from the 3D feature field are clustered at different levels, which can be further drawn closer or pushed apart according to the hierarchical relationship between different levels. In tackling the challenges posed by inconsistent 2D segmentations, this framework yields a global consistent 3D feature field, which further enables hierarchical segmentation, multi-object selection, and global discretization. Extensive experiments demonstrate the effectiveness of our method on high-quality 3D segmentation and accurate hierarchical structure understanding. A graphical user interface further facilitates flexible interaction for omniversal 3D segmentation.
</details>
<details>
<summary>摘要</summary>
为了实现全面理解三维场景，我们需要一种通用的三维分割方法，可以不受物体数量或类别的限制，同时还能够反映内在的层次结构。为此，我们提出了OmniSeg3D方法，它是一种能够同时分割所有三维场景中的任何事物的全面分割方法。关键思想是通过层次对比学习框架，将多视图不一致的二维分割提升到一致的三维特征场景中，这是通过两个步骤完成的。首先，我们设计了一种新的层次表示，基于类型不敏感的二维分割来模型像素之间的多级关系。其次，从三维特征场景中渲染出的图像特征被划分到不同层次，并且可以根据层次关系进行聚合或分离。在处理不一致的二维分割时，这个框架实现了一个全局一致的三维特征场景，这使得可以进行层次分割、多对象选择和全局精炸。我们的方法在高质量三维分割和准确的层次结构理解方面进行了广泛的实验，并且提供了一个图形用户界面，以便对全面的三维分割进行满意的互动。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Spatio-Temporal-Context-for-Temporally-Consistent-Robust-3D-Human-Motion-Recovery-from-Monocular-Videos"><a href="#Enhanced-Spatio-Temporal-Context-for-Temporally-Consistent-Robust-3D-Human-Motion-Recovery-from-Monocular-Videos" class="headerlink" title="Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D Human Motion Recovery from Monocular Videos"></a>Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D Human Motion Recovery from Monocular Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11662">http://arxiv.org/abs/2311.11662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sushovan Chanda, Amogh Tiwari, Lokender Tiwari, Brojeshwar Bhowmick, Avinash Sharma, Hrishav Barua</li>
<li>for: 本研究旨在提高从单摄影ideo中 recuperate 3D人体姿态、形状和运动的精度和可靠性，解决自身遮挡、低光照、复杂的人体姿态和深度抽象等问题。</li>
<li>methods: 该方法使用人体意识特征表示法和每帧初始化和自similarity自注意力来提高每帧的空间时间特征，并使用LSTM进行pose和形状参数的精度修正。</li>
<li>results: 实验结果表明，该方法在公共数据集上达到了 significatively 低的加速误差，并在所有关键量化评价指标上超越现有状态的方法，包括部分遮挡、复杂的姿态和相对较低的照明条件下。<details>
<summary>Abstract</summary>
Recovering temporally consistent 3D human body pose, shape and motion from a monocular video is a challenging task due to (self-)occlusions, poor lighting conditions, complex articulated body poses, depth ambiguity, and limited availability of annotated data. Further, doing a simple perframe estimation is insufficient as it leads to jittery and implausible results. In this paper, we propose a novel method for temporally consistent motion estimation from a monocular video. Instead of using generic ResNet-like features, our method uses a body-aware feature representation and an independent per-frame pose and camera initialization over a temporal window followed by a novel spatio-temporal feature aggregation by using a combination of self-similarity and self-attention over the body-aware features and the perframe initialization. Together, they yield enhanced spatiotemporal context for every frame by considering remaining past and future frames. These features are used to predict the pose and shape parameters of the human body model, which are further refined using an LSTM. Experimental results on the publicly available benchmark data show that our method attains significantly lower acceleration error and outperforms the existing state-of-the-art methods over all key quantitative evaluation metrics, including complex scenarios like partial occlusion, complex poses and even relatively low illumination.
</details>
<details>
<summary>摘要</summary>
取回时间相关的3D人体姿态、形状和运动从单目视频中回复是一项具有挑战性的任务，原因包括自我遮挡、低光照条件、复杂的人体姿态、深度模糊和有限的标注数据。此外，单个帧估计也不够，会导致缓慢且不合理的结果。在这篇论文中，我们提出了一种新的单目视频中的时间相关运动估计方法。而不是使用通用的ResNet类型特征，我们的方法使用人体意识特征表示和每帧姿态和摄像头初始化独立于时间窗口，然后使用一种组合自我相似和自我注意力来聚合体静态特征。这些特征用于预测人体模型的姿态和形状参数，并进一步使用LSTM进行精度调整。实验结果表明，我们的方法在公共可用的benchmark数据上取得了明显更低的加速错误和与现有状态的方法相比，在所有关键量化评价指标上占优。包括部分遮挡、复杂的姿态和低光照等复杂的场景。
</details></li>
</ul>
<hr>
<h2 id="Double-Condensing-Attention-Condenser-Leveraging-Attention-in-Deep-Learning-to-Detect-Skin-Cancer-from-Skin-Lesion-Images"><a href="#Double-Condensing-Attention-Condenser-Leveraging-Attention-in-Deep-Learning-to-Detect-Skin-Cancer-from-Skin-Lesion-Images" class="headerlink" title="Double-Condensing Attention Condenser: Leveraging Attention in Deep Learning to Detect Skin Cancer from Skin Lesion Images"></a>Double-Condensing Attention Condenser: Leveraging Attention in Deep Learning to Detect Skin Cancer from Skin Lesion Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11656">http://arxiv.org/abs/2311.11656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chi-en Amy Tai, Elizabeth Janes, Chris Czarnecki, Alexander Wong</li>
<li>for: 这个研究是为了探讨皮肤癌检测，并提出一个具有高效性和可持续性的深度学习模型。</li>
<li>methods: 本研究使用了Double-Condensing Attention Condensers（DC-AC）来实现更快速和更有效率的computation，并采用了一个自我注意力架构来检测皮肤癌。</li>
<li>results: 研究获得了一个可公开使用的深度学习模型，并在SIIM-ISIC Melanoma Classification Challenge中获得了state-of-the-art的成绩。<details>
<summary>Abstract</summary>
Skin cancer is the most common type of cancer in the United States and is estimated to affect one in five Americans. Recent advances have demonstrated strong performance on skin cancer detection, as exemplified by state of the art performance in the SIIM-ISIC Melanoma Classification Challenge; however these solutions leverage ensembles of complex deep neural architectures requiring immense storage and compute costs, and therefore may not be tractable. A recent movement for TinyML applications is integrating Double-Condensing Attention Condensers (DC-AC) into a self-attention neural network backbone architecture to allow for faster and more efficient computation. This paper explores leveraging an efficient self-attention structure to detect skin cancer in skin lesion images and introduces a deep neural network design with DC-AC customized for skin cancer detection from skin lesion images. The final model is publicly available as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.
</details>
<details>
<summary>摘要</summary>
美国最常见的癌症是皮肤癌，其影响率高达一 из五美国人。最新的进展表明深度学习在皮肤癌检测方面表现出色，例如在SIIM-ISIC瘤癌分类挑战中的状态对抗性表现。然而，这些解决方案具有复杂的深度神经网络结构，需要巨大的存储和计算成本，因此可能不太实用。在小型机器学习（TinyML）应用中，把 Double-Condensing Attention Condensers（DC-AC）integrated into a self-attention neural network backbone architecture可以实现更快和高效的计算。本文探讨利用高效的自注意结构来检测皮肤癌，并介绍了一种特化于皮肤癌检测的深度神经网络设计，使用DC-AC。最终模型将公开提供，并成为全球开源Initiave的一部分，旨在加速机器学习的进步，以 помочь临床医生在抗癌战中。
</details></li>
</ul>
<hr>
<h2 id="Cancer-Net-PCa-Data-An-Open-Source-Benchmark-Dataset-for-Prostate-Cancer-Clinical-Decision-Support-using-Synthetic-Correlated-Diffusion-Imaging-Data"><a href="#Cancer-Net-PCa-Data-An-Open-Source-Benchmark-Dataset-for-Prostate-Cancer-Clinical-Decision-Support-using-Synthetic-Correlated-Diffusion-Imaging-Data" class="headerlink" title="Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data"></a>Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11647">http://arxiv.org/abs/2311.11647</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hayden Gunraj, Chi-en Amy Tai, Alexander Wong</li>
<li>For: The paper is written to introduce an open-source benchmark dataset of volumetric correlated diffusion imaging (CDI$^s$) data for prostate cancer (PCa) patients, which can aid clinicians in the global fight against cancer.* Methods: The paper uses CDI$^s$ imaging data from a patient cohort of 200 patient cases, along with full annotations (gland masks, tumor masks, and PCa diagnosis for each tumor) to analyze the demographic and label region diversity of the dataset for potential biases.* Results: The paper introduces Cancer-Net PCa-Data, the first-ever public dataset of CDI$^s$ imaging data for PCa, which can be used to advance research efforts in machine learning and imaging research for PCa diagnosis and treatment.<details>
<summary>Abstract</summary>
The recent introduction of synthetic correlated diffusion (CDI$^s$) imaging has demonstrated significant potential in the realm of clinical decision support for prostate cancer (PCa). CDI$^s$ is a new form of magnetic resonance imaging (MRI) designed to characterize tissue characteristics through the joint correlation of diffusion signal attenuation across different Brownian motion sensitivities. Despite the performance improvement, the CDI$^s$ data for PCa has not been previously made publicly available. In our commitment to advance research efforts for PCa, we introduce Cancer-Net PCa-Data, an open-source benchmark dataset of volumetric CDI$^s$ imaging data of PCa patients. Cancer-Net PCa-Data consists of CDI$^s$ volumetric images from a patient cohort of 200 patient cases, along with full annotations (gland masks, tumor masks, and PCa diagnosis for each tumor). We also analyze the demographic and label region diversity of Cancer-Net PCa-Data for potential biases. Cancer-Net PCa-Data is the first-ever public dataset of CDI$^s$ imaging data for PCa, and is a part of the global open-source initiative dedicated to advancement in machine learning and imaging research to aid clinicians in the global fight against cancer.
</details>
<details>
<summary>摘要</summary>
最近，另一种称为合成相关扩散（CDI$^s$）成像技术的引入，在临床决策支持方面表现出了很大的潜力。CDI$^s$ 是一种基于核磁共振成像（MRI）技术，用于Characterize 组织特征，通过不同的温馈振荡敏感性的共同协同。尽管表现得更好，但CDI$^s$ 数据 дляPCa尚未公开可用。为了推动PCa 的研究，我们介绍了Cancer-Net PCa-Data，一个开源的PCa患者数据集。Cancer-Net PCa-Data包括200个病例的CDI$^s$ 三维成像数据，以及每个肿瘤的患者标签（包括腺体涂抹、肿瘤涂抹和PCa诊断）。我们还分析了Cancer-Net PCa-Data的人口和标注区域多样性，以确定可能的偏见。Cancer-Net PCa-Data是PCa 的第一个公开的CDI$^s$ 成像数据集，是全球开源的机器学习和成像研究的一部分，旨在帮助临床医生在抗癌斗争中获得更好的工具。
</details></li>
</ul>
<hr>
<h2 id="CastDet-Toward-Open-Vocabulary-Aerial-Object-Detection-with-CLIP-Activated-Student-Teacher-Learning"><a href="#CastDet-Toward-Open-Vocabulary-Aerial-Object-Detection-with-CLIP-Activated-Student-Teacher-Learning" class="headerlink" title="CastDet: Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning"></a>CastDet: Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11646">http://arxiv.org/abs/2311.11646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Li, Weiwei Guo, Dunyun He, Jiaqi Zhou, Yuze Gao, Wenxian Yu</li>
<li>for: 这篇论文是关于 aerial image 中的物体探测任务，它的目的是实现开放词汇物体探测（OVD），能够在无需训练标签的情况下检测到新的物体类别。</li>
<li>methods: 这篇论文提出了 CastDet，一个基于 CLIP 模型的学生-老师开放词汇物体探测框架。这个框架使用 CLIP 模型作为额外的全知之师，将其整合到学生-老师自学 проце序中，以提高新物体提案和类别。</li>
<li>results: 根据实验结果，CastDet 可以实现高品质的开放词汇物体探测，例如在 VisDroneZSD dataset 上取得 40.0 HM 的最高分，比前一代方法 Detic&#x2F;ViLD 高出 26.9&#x2F;21.1 分。<details>
<summary>Abstract</summary>
Object detection in aerial images is a pivotal task for various earth observation applications, whereas current algorithms learn to detect only a pre-defined set of object categories demanding sufficient bounding-box annotated training samples and fail to detect novel object categories. In this paper, we consider open-vocabulary object detection (OVD) in aerial images that enables the characterization of new objects beyond training categories on the earth surface without annotating training images for these new categories. The performance of OVD depends on the quality of class-agnostic region proposals and pseudo-labels that can generalize well to novel object categories. To simultaneously generate high-quality proposals and pseudo-labels, we propose CastDet, a CLIP-activated student-teacher open-vocabulary object Detection framework. Our end-to-end framework within the student-teacher mechanism employs the CLIP model as an extra omniscient teacher of rich knowledge into the student-teacher self-learning process. By doing so, our approach boosts novel object proposals and classification. Furthermore, we design a dynamic label queue technique to maintain high-quality pseudo labels during batch training and mitigate label imbalance. We conduct extensive experiments on multiple existing aerial object detection datasets, which are set up for the OVD task. Experimental results demonstrate our CastDet achieving superior open-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean), which outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD dataset.
</details>
<details>
<summary>摘要</summary>
“ aerial 图像中的物体检测是多种地球观测应用中的关键任务，现有算法只能学习预定的物体类别，需要充足的 bounding-box 注意力标注训练样本，并不能检测新的物体类别。在这篇论文中，我们考虑了开放词汇物体检测（OVD）在 aerial 图像中，允许在地球表面上无需注意力标注训练样本中检测新的物体类别。OVD 的性能取决于高质量的类型不敏感区域提案和 Pseudo-标签，这些可以很好地泛化到新的物体类别。为了同时生成高质量的提案和 Pseudo-标签，我们提出了 CastDet，一个基于 CLIP 的学生-教师开放词汇物体检测框架。我们的端到端框架在学生-教师机制中使用 CLIP 模型作为额外的全知之 teacher，从而提高新物体提案和分类。此外，我们设计了动态标签队列技术来保持批处理训练期间高质量的 Pseudo-标签，并 Mitigate 标签偏斜。我们在多个现有的 aerial 物体检测数据集上进行了广泛的实验，实验结果表明我们的 CastDet 在开放词汇检测任务中表现出色，例如在 VisDroneZSD 数据集上达到 40.0 HM（和律 mean），比前方法 Detic/ViLD 的性能提高 26.9/21.1。”
</details></li>
</ul>
<hr>
<h2 id="Video-Face-Re-Aging-Toward-Temporally-Consistent-Face-Re-Aging"><a href="#Video-Face-Re-Aging-Toward-Temporally-Consistent-Face-Re-Aging" class="headerlink" title="Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging"></a>Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11642">http://arxiv.org/abs/2311.11642</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyugorithm/VFRAN">https://github.com/kyugorithm/VFRAN</a></li>
<li>paper_authors: Abdul Muqeet, Kyuchul Lee, Bumsoo Kim, Yohan Hong, Hyungrae Lee, Woonggon Kim, Kwang Hee Lee</li>
<li>for: 提高视频人脸年龄变换的精度和一致性</li>
<li>methods: 基于新生成的同时维护人脸年龄和个体特征的Synthetic video dataset，以及一种基线建模方案和三种专门设计的时间一致度评价指标</li>
<li>results: 在公共数据集上（如VFHQ和CelebV-HQ）进行了广泛的实验，发现我们的方法在年龄变换和时间一致性方面都有较好的表现，超过现有方法的表现。<details>
<summary>Abstract</summary>
Video face re-aging deals with altering the apparent age of a person to the target age in videos. This problem is challenging due to the lack of paired video datasets maintaining temporal consistency in identity and age. Most re-aging methods process each image individually without considering the temporal consistency of videos. While some existing works address the issue of temporal coherence through video facial attribute manipulation in latent space, they often fail to deliver satisfactory performance in age transformation. To tackle the issues, we propose (1) a novel synthetic video dataset that features subjects across a diverse range of age groups; (2) a baseline architecture designed to validate the effectiveness of our proposed dataset, and (3) the development of three novel metrics tailored explicitly for evaluating the temporal consistency of video re-aging techniques. Our comprehensive experiments on public datasets, such as VFHQ and CelebV-HQ, show that our method outperforms the existing approaches in terms of both age transformation and temporal consistency.
</details>
<details>
<summary>摘要</summary>
【文本】视频面部重新年龄处理是修改视频中人物的显示年龄，这问题具有挑战性，主要由于缺乏匹配的视频数据集，保持时间一致性和人脸特征的唯一性。大多数现有方法是处理每帧图像，不考虑视频中的时间一致性。有些现有方法通过视频人脸特征在幂空间中的修改来解决问题，但它们经常无法实现满意的年龄变换表现。为解决这些问题，我们提议以下方法：1. 一个新的人工生成的视频数据集，包含多个年龄组的主题。2. 一个基eline架构，用于验证我们的提议的效果。3. 三个专门为评估视频重新年龄技术的新指标的开发。我们对公共数据集，如VFHQ和CelebV-HQ进行了全面的实验，结果表明，我们的方法在年龄变换和时间一致性两个方面都高于现有方法。【翻译】视频面部重新年龄处理是修改视频中人物的显示年龄，这问题具有挑战性，主要由于缺乏匹配的视频数据集，保持时间一致性和人脸特征的唯一性。大多数现有方法是处理每帧图像，不考虑视频中的时间一致性。有些现有方法通过视频人脸特征在幂空间中的修改来解决问题，但它们经常无法实现满意的年龄变换表现。为解决这些问题，我们提议以下方法：1. 一个新的人工生成的视频数据集，包含多个年龄组的主题。2. 一个基eline架构，用于验证我们的提议的效果。3. 三个专门为评估视频重新年龄技术的新指标的开发。我们对公共数据集，如VFHQ和CelebV-HQ进行了全面的实验，结果表明，我们的方法在年龄变换和时间一致性两个方面都高于现有方法。
</details></li>
</ul>
<hr>
<h2 id="Reti-Diff-Illumination-Degradation-Image-Restoration-with-Retinex-based-Latent-Diffusion-Model"><a href="#Reti-Diff-Illumination-Degradation-Image-Restoration-with-Retinex-based-Latent-Diffusion-Model" class="headerlink" title="Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model"></a>Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11638">http://arxiv.org/abs/2311.11638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chunminghe/reti-diff">https://github.com/chunminghe/reti-diff</a></li>
<li>paper_authors: Chunming He, Chengyu Fang, Yulun Zhang, Kai Li, Longxiang Tang, Chenyu You, Fengyang Xiao, Zhenhua Guo, Xiu Li</li>
<li>for: 这种研究旨在提高降低图像质量的方法，以提高降低图像中的可见性和缓解降低照明的不良影响。</li>
<li>methods: 该方法基于扩散模型（DM），并使用一种新的解决方案called Reti-Diff，包括Retinex基于的秘密DM（RLDM）和Retinex指导变换（RGformer）。RLDM使用Retinex知识提取反射和照明秘密，然后RGformer使用这些秘密来导向图像特征的分解。</li>
<li>results: 对三种IDIR任务进行了广泛的实验，并证明Reti-Diff可以超过现有方法，同时在下游应用中也有优秀表现。<details>
<summary>Abstract</summary>
Illumination degradation image restoration (IDIR) techniques aim to improve the visibility of degraded images and mitigate the adverse effects of deteriorated illumination. Among these algorithms, diffusion model (DM)-based methods have shown promising performance but are often burdened by heavy computational demands and pixel misalignment issues when predicting the image-level distribution. To tackle these problems, we propose to leverage DM within a compact latent space to generate concise guidance priors and introduce a novel solution called Reti-Diff for the IDIR task. Reti-Diff comprises two key components: the Retinex-based latent DM (RLDM) and the Retinex-guided transformer (RGformer). To ensure detailed reconstruction and illumination correction, RLDM is empowered to acquire Retinex knowledge and extract reflectance and illumination priors. These priors are subsequently utilized by RGformer to guide the decomposition of image features into their respective reflectance and illumination components. Following this, RGformer further enhances and consolidates the decomposed features, resulting in the production of refined images with consistent content and robustness to handle complex degradation scenarios. Extensive experiments show that Reti-Diff outperforms existing methods on three IDIR tasks, as well as downstream applications. Code will be available at \url{https://github.com/ChunmingHe/Reti-Diff}.
</details>
<details>
<summary>摘要</summary>
illumination degradation image restoration (IDIR) 技术目的是提高受损图像的可见度，并减轻照明的不良影响。在这些算法中，基于分散模型（DM）的方法已经显示出了有前途的表现，但它们经常受到高计算量和像素不对齐问题的压力，尤其是在预测图像水平分布时。为了解决这些问题，我们提议利用DM在紧凑的尺度空间中生成简洁的指导假设，并 introduce a novel solution called Reti-Diff for the IDIR task. Reti-Diff包括两个关键组件：Retinex基于的秘密DM（RLDM）和Retinex引导的 transformer（RGformer）。为确保细节重建和照明更正，RLDM被授权了Retinex知识，并EXTRACT reflectance和照明假设。这些假设后来被RGformer使用来导引图像特征的分解成它们的准确的reflectance和照明组成部分。接下来，RGformer进一步加强和结合这些分解的特征，从而生成高质量的恢复图像，满足复杂的损坏enario下的需求。广泛的实验表明，Reti-Diff在三个 IDIR 任务上表现出优于现有方法，以及下游应用程序。代码将于 \url{https://github.com/ChunmingHe/Reti-Diff} 上提供。
</details></li>
</ul>
<hr>
<h2 id="Generating-Realistic-Counterfactuals-for-Retinal-Fundus-and-OCT-Images-using-Diffusion-Models"><a href="#Generating-Realistic-Counterfactuals-for-Retinal-Fundus-and-OCT-Images-using-Diffusion-Models" class="headerlink" title="Generating Realistic Counterfactuals for Retinal Fundus and OCT Images using Diffusion Models"></a>Generating Realistic Counterfactuals for Retinal Fundus and OCT Images using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11629">http://arxiv.org/abs/2311.11629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indu Ilanchezian, Valentyn Boreiko, Laura Kühlewein, Ziwei Huang, Murat Seçkin Ayhan, Matthias Hein, Lisa Koch, Philipp Berens</li>
<li>for: 该论文旨在用Counterfactual reasoning来解释医疗决策或评估可能的选择。</li>
<li>methods: 该论文使用了一种扩散模型，并与一个对抗性强的分类器一起使用，以生成高度真实的Counterfactual retinal fundus图像和Optical coherence tomography (OCT) B-scan。</li>
<li>results: 在用户研究中，域专家发现使用我们的方法生成的Counterfactuals更真实，甚至与真实图像难以区分。<details>
<summary>Abstract</summary>
Counterfactual reasoning is often used in a clinical setting to explain decisions or weigh alternatives. Therefore, for imaging based modalities such as ophthalmology, it would be beneficial to be able to create counterfactual images, illustrating the answer to the question: "If the subject had had diabetic retinopathy, how would the fundus image have looked?" Here, we demonstrate that using a diffusion model in combination with an adversarially robust classifier trained on retinal disease classification tasks enables generation of highly realistic counterfactuals of retinal fundus images and optical coherence tomorgraphy (OCT) B-scans. Ideally, these classifiers encode the salient features indicative for each disease class and can steer the diffusion model to show realistic disease signs or remove disease-related lesions in a realistic way. Importantly, in a user study, domain experts found the counterfactuals generated using our method significantly more realistic than counterfactuals generated from a previous method, and even indistiguishable from realistic images.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用反因果思维在临床设置中解释决策或评估选项。因此，对于基于成像技术的modalities，如眼科学，可以创建反因果图像，示出问题“如果subject有糖尿病抑或病变，图像如何看起来？”。我们展示了一种使用扩散模型和对眼病分类任务进行 adversarially robust 训练的类ifikator，可以生成高度真实的反因果眼科图像和optical coherence tomography（OCT）B-scan。这些分类器能够捕捉眼病的重要特征，并使扩散模型显示真实的病变或在真实的方式下除病理学病变。在用户研究中，领域专家发现使用我们的方法生成的反因果图像比之前的方法生成的更真实，甚至与真实图像难以区分。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Semantic-Preserved-Point-based-Human-Avatar"><a href="#Semantic-Preserved-Point-based-Human-Avatar" class="headerlink" title="Semantic-Preserved Point-based Human Avatar"></a>Semantic-Preserved Point-based Human Avatar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11614">http://arxiv.org/abs/2311.11614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixiang Lin, Jianke Zhu</li>
<li>for: 实现现实主义AR&#x2F;VR和数字娱乐体验，我们提出了首个点云基于人工智能模型，涵盖了数字人类表达的全范围。</li>
<li>methods: 我们使用两个多层感知（MLP）来模型姿态依赖的形变和线性皮革（LBS） веса。人物外观表示方式采用解码器和每个点附加的特征。</li>
<li>results: 我们的方法不仅减少了训练和推断时间，还可以更好地理解人体运动的 semantic 信息。我们还提出了一种将SMPL-X模型的semantic信息传递到点上的新方法，以便进行虚拟试穿和人物组合。实验结果表明我们的方法的效果。<details>
<summary>Abstract</summary>
To enable realistic experience in AR/VR and digital entertainment, we present the first point-based human avatar model that embodies the entirety expressive range of digital humans. We employ two MLPs to model pose-dependent deformation and linear skinning (LBS) weights. The representation of appearance relies on a decoder and the features that attached to each point. In contrast to alternative implicit approaches, the oriented points representation not only provides a more intuitive way to model human avatar animation but also significantly reduces both training and inference time. Moreover, we propose a novel method to transfer semantic information from the SMPL-X model to the points, which enables to better understand human body movements. By leveraging the semantic information of points, we can facilitate virtual try-on and human avatar composition through exchanging the points of same category across different subjects. Experimental results demonstrate the efficacy of our presented method.
</details>
<details>
<summary>摘要</summary>
为实现现实主义的AR/VR和数字娱乐体验，我们提出了首个点云基于人类模型，涵盖了整个数字人类表达范围。我们使用两个多层感知（MLP）来模型 pose-dependent 扭变和线性皮肤（LBS）质量。人物外表表示靠decoder和每个点附加的特征。相比拥有其他几何方法，点云表示方法不仅提供了更直观的人物动画模型，还能够显著降低训练和推理时间。此外，我们提出了一种将SMPL-X模型中的semantic信息传递到点上的新方法，以便更好地理解人体运动。通过使用点上的semantic信息，我们可以实现虚拟试穿和人物组合，通过交换同类点的交换。实验结果表明我们提出的方法的效果。
</details></li>
</ul>
<hr>
<h2 id="CurriculumLoc-Enhancing-Cross-Domain-Geolocalization-through-Multi-Stage-Refinement"><a href="#CurriculumLoc-Enhancing-Cross-Domain-Geolocalization-through-Multi-Stage-Refinement" class="headerlink" title="CurriculumLoc: Enhancing Cross-Domain Geolocalization through Multi-Stage Refinement"></a>CurriculumLoc: Enhancing Cross-Domain Geolocalization through Multi-Stage Refinement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11604">http://arxiv.org/abs/2311.11604</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/npupilab/curriculumloc">https://github.com/npupilab/curriculumloc</a></li>
<li>paper_authors: Boni Hu, Lin Chen, Runjian Chen, Shuhui Bu, Pengcheng Han, Haowei Li</li>
<li>for: 这篇论文旨在提出一种可靠、可扩展的视觉地理Localization方法，能够在不同光照和视角的情况下提供准确的全球定位估计。</li>
<li>methods: 该方法基于curriculum设计，首先认知 semantic scene，然后测量geometry structure。具有全球semantic意识和本地几何验证的新的键点检测和描述算法，以及多Stage Refinement管道，使得方法具有 robustness to appearance changing和极端视角变化。</li>
<li>results: 在 TerraTrack 和 ALTO 两个数据集上进行了广泛的实验，结果表明，该方法可以实现上述的可靠视觉地理Localization解决方案，并 achieved new high recall@1 scores of 62.6% and 94.5% on ALTO 数据集，使得该方法在视觉地理Localization领域具有优秀的性能。<details>
<summary>Abstract</summary>
Visual geolocalization is a cost-effective and scalable task that involves matching one or more query images, taken at some unknown location, to a set of geo-tagged reference images. Existing methods, devoted to semantic features representation, evolving towards robustness to a wide variety between query and reference, including illumination and viewpoint changes, as well as scale and seasonal variations. However, practical visual geolocalization approaches need to be robust in appearance changing and extreme viewpoint variation conditions, while providing accurate global location estimates. Therefore, inspired by curriculum design, human learn general knowledge first and then delve into professional expertise. We first recognize semantic scene and then measure geometric structure. Our approach, termed CurriculumLoc, involves a delicate design of multi-stage refinement pipeline and a novel keypoint detection and description with global semantic awareness and local geometric verification. We rerank candidates and solve a particular cross-domain perspective-n-point (PnP) problem based on these keypoints and corresponding descriptors, position refinement occurs incrementally. The extensive experimental results on our collected dataset, TerraTrack and a benchmark dataset, ALTO, demonstrate that our approach results in the aforementioned desirable characteristics of a practical visual geolocalization solution. Additionally, we achieve new high recall@1 scores of 62.6% and 94.5% on ALTO, with two different distances metrics, respectively. Dataset, code and trained models are publicly available on https://github.com/npupilab/CurriculumLoc.
</details>
<details>
<summary>摘要</summary>
Visual地理位置定位是一项成本效益和可扩展的任务，即将一个或多个查询图像， captured at unknown location，与一组地理标记的参考图像匹配。现有方法主要关注semantic特征表示，逐渐向robustness against各种查询和参考图像的变化，包括照明和视点变化、Scale和季节变化。然而，实际应用中的视地理位置定位方法需要对应变化和极端视点变化的Robustness，同时提供准确的全球位置估计。因此，我们受到curriculum设计的 inspirations，人类首先学习通用知识，然后深入掌握专业技能。我们首先识别semantic scene，然后测量几何结构。我们的方法，称之为CurriculumLoc，包括细腻的多阶段精度提升管道和一种新型的键点检测和描述，具有全球semantic意识和本地几何验证。我们在这些键点和相应的描述符之间进行重新排名，并根据这些键点进行特定的cross-domain perspective-n-point（PnP）问题的解决。在我们收集的dataset上， TerraTrack 和一个标准dataset， ALTO 上进行了广泛的实验，结果表明，我们的方法具有上述desirable特点，并且实现了新的高recall@1分数，分别为62.6%和94.5%。 dataset、代码和训练模型都可以在https://github.com/npupilab/CurriculumLoc上公开获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Equilibrium-Diffusion-Restoration-with-Parallel-Sampling"><a href="#Deep-Equilibrium-Diffusion-Restoration-with-Parallel-Sampling" class="headerlink" title="Deep Equilibrium Diffusion Restoration with Parallel Sampling"></a>Deep Equilibrium Diffusion Restoration with Parallel Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11600">http://arxiv.org/abs/2311.11600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiezhang Cao, Yue Shi, Kai Zhang, Yulun Zhang, Radu Timofte, Luc Van Gool</li>
<li>for: 这个论文的目的是重新考虑基于扩散模型的图像恢复方法，通过深度平衡（DEQ）稳定点系统来解决长样本链的问题，并在单个图像 sampling 中实现高质量图像恢复。</li>
<li>methods: 该方法使用了基于扩散模型的 JOINT 多变量稳定点系统来解决整个样本链，并通过分析解得出了单个图像 sampling 的解。此外，该方法还计算了快速的梯度值，并发现初始化优化可以提高性能并控制生成方向。</li>
<li>results:  experiments 表明，该方法在典型的恢复任务和实际应用中得到了有效的结果，并且在单个图像 sampling 中实现了高质量图像恢复。code 和模型将会公开发布。<details>
<summary>Abstract</summary>
Diffusion-based image restoration (IR) methods aim to use diffusion models to recover high-quality (HQ) images from degraded images and achieve promising performance. Due to the inherent property of diffusion models, most of these methods need long serial sampling chains to restore HQ images step-by-step. As a result, it leads to expensive sampling time and high computation costs. Moreover, such long sampling chains hinder understanding the relationship between the restoration results and the inputs since it is hard to compute the gradients in the whole chains. In this work, we aim to rethink the diffusion-based IR models through a different perspective, i.e., a deep equilibrium (DEQ) fixed point system. Specifically, we derive an analytical solution by modeling the entire sampling chain in diffusion-based IR models as a joint multivariate fixed point system. With the help of the analytical solution, we are able to conduct single-image sampling in a parallel way and restore HQ images without training. Furthermore, we compute fast gradients in DEQ and found that initialization optimization can boost performance and control the generation direction. Extensive experiments on benchmarks demonstrate the effectiveness of our proposed method on typical IR tasks and real-world settings. The code and models will be made publicly available.
</details>
<details>
<summary>摘要</summary>
各种扩散基本的图像修复（IR）方法都是使用扩散模型来恢复受损图像并实现出色的性能。由于扩散模型的内置性质，大多数这些方法需要长串行采样链来恢复高质量（HQ）图像步骤通过。这会导致昂贵的采样时间和高计算成本。此外，这些长链难以计算整个链的梯度，使得理解恢复结果和输入之间的关系变得困难。在这种情况下，我们想重新思考扩散基本的IR模型，通过一种新的视角，即深度平衡（DEQ）固定点系统。我们在这种系统中模型了扩散基本的采样链，并 derive了一个分析解。通过这个分析解，我们可以在平行的方式上进行单张图像采样，并在没有训练的情况下恢复HQ图像。此外，我们在DEQ中计算了快速的梯度，并发现初始化优化可以提高性能并控制生成方向。我们在典型的IR任务和实际场景中进行了广泛的实验，并证明了我们的提议的效果。我们将代码和模型公开发布。
</details></li>
</ul>
<hr>
<h2 id="Predicting-urban-tree-cover-from-incomplete-point-labels-and-limited-background-information"><a href="#Predicting-urban-tree-cover-from-incomplete-point-labels-and-limited-background-information" class="headerlink" title="Predicting urban tree cover from incomplete point labels and limited background information"></a>Predicting urban tree cover from incomplete point labels and limited background information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11592">http://arxiv.org/abs/2311.11592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Ankit Kariryaa, Venkanna Babu Guthula, Christian Igel, Stefan Oehmcke</li>
<li>for: 本研究旨在利用有限数据和深度学习方法映射城市内部的城市树。</li>
<li>methods: 本研究使用深度学习方法进行 semantic segmentation 的高分辨率遥感图像，并利用有限数据和开源地理数据库的标注来划分城市树。</li>
<li>results: 实验结果表明，系统可以生成包括非 ули道树的树覆盖图，而不需要提供树划分。系统的性能会随着开源地理数据库的使用而下降。<details>
<summary>Abstract</summary>
Trees inside cities are important for the urban microclimate, contributing positively to the physical and mental health of the urban dwellers. Despite their importance, often only limited information about city trees is available. Therefore in this paper, we propose a method for mapping urban trees in high-resolution aerial imagery using limited datasets and deep learning. Deep learning has become best-practice for this task, however, existing approaches rely on large and accurately labelled training datasets, which can be difficult and expensive to obtain. However, often noisy and incomplete data may be available that can be combined and utilized to solve more difficult tasks than those datasets were intended for. This paper studies how to combine accurate point labels of urban trees along streets with crowd-sourced annotations from an open geographic database to delineate city trees in remote sensing images, a task which is challenging even for humans. To that end, we perform semantic segmentation of very high resolution aerial imagery using a fully convolutional neural network. The main challenge is that our segmentation maps are sparsely annotated and incomplete. Small areas around the point labels of the street trees coming from official and crowd-sourced data are marked as foreground class. Crowd-sourced annotations of streets, buildings, etc. define the background class. Since the tree data is incomplete, we introduce a masking to avoid class confusion. Our experiments in Hamburg, Germany, showed that the system is able to produce tree cover maps, not limited to trees along streets, without providing tree delineations. We evaluated the method on manually labelled trees and show that performance drastically deteriorates if the open geographic database is not used.
</details>
<details>
<summary>摘要</summary>
城市内的树木非常重要对于城市微气候，对于城市居民的身体和心理健康做出积极贡献。尽管其重要性，但有限的城市树木信息通常只有有限的信息。因此，我们在这篇论文中提出了一种使用有限数据和深度学习映射城市树木在高分辨率飞行图像中的方法。深度学习已成为最佳实践，但现有方法通常需要大量和准确标注的训练数据，这可能是expensive和困难的。然而，有时候可以获得噪音和不完整的数据，这些数据可以与其他数据结合使用，以解决更难的任务。本文研究如何将精度点标签的城市树木与开源地理数据库的批注结合，以在遥感图像中标识城市树木，这是人类even challenging的任务。为此，我们使用了全连接神经网络进行semantic segmentation。主要挑战在于我们的分 segmentation maps 是 incomplete和稀疏标注的。小区域附近街道树木的点标签从官方和开源数据库获取，标记为前景类。开源数据库中的街道、建筑等批注定义背景类。由于树木数据不完整，我们引入了masking，以避免类冲突。我们在 Hamburg, Germany 进行了实验，结果表明系统能够生成树 cover maps，不仅限于街道上的树木，而无需提供树木定义。我们对手动标注的树木进行评估，结果表明，如果不使用开源地理数据库，系统性能会很差。
</details></li>
</ul>
<hr>
<h2 id="AKConv-Convolutional-Kernel-with-Arbitrary-Sampled-Shapes-and-Arbitrary-Number-of-Parameters"><a href="#AKConv-Convolutional-Kernel-with-Arbitrary-Sampled-Shapes-and-Arbitrary-Number-of-Parameters" class="headerlink" title="AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary Number of Parameters"></a>AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary Number of Parameters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11587">http://arxiv.org/abs/2311.11587</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cv-zhangxin/akconv">https://github.com/cv-zhangxin/akconv</a></li>
<li>paper_authors: Xin Zhang, Yingze Song, Tingting Song, Degang Yang, Yichen Ye, Jie Zhou, Liming Zhang<br>for: 这个论文的目的是提出一种新的卷积操作方法，以提高深度学习网络的性能。methods: 这个论文使用的方法是 Alterable Kernel Convolution (AKConv)，它使用可变的卷积kernel来提供更多的选择空间 для网络的性能和资源的负担之间的平衡。具体来说，AKConv使用一种新的坐标生成算法来定义卷积kernel的初始位置，并通过偏移来调整卷积样本的形状。results: 在COCO2017、VOC 7+12和VisDrone-DET2021等标准数据集上进行了对象检测实验，显示了AKConv的优势。AKConv可以视为一种替换标准卷积操作的替换方法，以提高网络的性能。codes可以在<a target="_blank" rel="noopener" href="https://github.com/CV-ZhangXin/AKConv%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/CV-ZhangXin/AKConv中找到。</a><details>
<summary>Abstract</summary>
Neural networks based on convolutional operations have achieved remarkable results in the field of deep learning, but there are two inherent flaws in standard convolutional operations. On the one hand, the convolution operation be confined to a local window and cannot capture information from other locations, and its sampled shapes is fixed. On the other hand, the size of the convolutional kernel is fixed to k $\times$ k, which is a fixed square shape, and the number of parameters tends to grow squarely with size. It is obvious that the shape and size of targets are various in different datasets and at different locations. Convolutional kernels with fixed sample shapes and squares do not adapt well to changing targets. In response to the above questions, the Alterable Kernel Convolution (AKConv) is explored in this work, which gives the convolution kernel an arbitrary number of parameters and arbitrary sampled shapes to provide richer options for the trade-off between network overhead and performance. In AKConv, we define initial positions for convolutional kernels of arbitrary size by means of a new coordinate generation algorithm. To adapt to changes for targets, we introduce offsets to adjust the shape of the samples at each position. Moreover, we explore the effect of the neural network by using the AKConv with the same size and different initial sampled shapes. AKConv completes the process of efficient feature extraction by irregular convolutional operations and brings more exploration options for convolutional sampling shapes. Object detection experiments on representative datasets COCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of AKConv. AKConv can be used as a plug-and-play convolutional operation to replace convolutional operations to improve network performance. The code for the relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.
</details>
<details>
<summary>摘要</summary>
neural networks based on convolutional operations have achieved remarkable results in deep learning, but there are two inherent flaws in standard convolutional operations. on the one hand, the convolution operation is confined to a local window and cannot capture information from other locations, and its sampled shapes is fixed. on the other hand, the size of the convolutional kernel is fixed to k x k, which is a fixed square shape, and the number of parameters tends to grow squarely with size. it is obvious that the shape and size of targets are various in different datasets and at different locations. convolutional kernels with fixed sample shapes and squares do not adapt well to changing targets. in response to the above questions, the Alterable Kernel Convolution (AKConv) is explored in this work, which gives the convolution kernel an arbitrary number of parameters and arbitrary sampled shapes to provide richer options for the trade-off between network overhead and performance. in AKConv, we define initial positions for convolutional kernels of arbitrary size by means of a new coordinate generation algorithm. to adapt to changes for targets, we introduce offsets to adjust the shape of the samples at each position. Moreover, we explore the effect of the neural network by using the AKConv with the same size and different initial sampled shapes. AKConv completes the process of efficient feature extraction by irregular convolutional operations and brings more exploration options for convolutional sampling shapes. object detection experiments on representative datasets COCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of AKConv. AKConv can be used as a plug-and-play convolutional operation to replace convolutional operations to improve network performance. the code for the relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.
</details></li>
</ul>
<hr>
<h2 id="SeaDSC-A-video-based-unsupervised-method-for-dynamic-scene-change-detection-in-unmanned-surface-vehicles"><a href="#SeaDSC-A-video-based-unsupervised-method-for-dynamic-scene-change-detection-in-unmanned-surface-vehicles" class="headerlink" title="SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles"></a>SeaDSC: A video-based unsupervised method for dynamic scene change detection in unmanned surface vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11580">http://arxiv.org/abs/2311.11580</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linh Trinh, Ali Anwar, Siegfried Mercelis</li>
<li>for: 本研究旨在探讨USV（无人水面船）视频数据中的动态场景变化检测问题。</li>
<li>methods: 我们提出了一种完全无监督学习方法，利用修改后的VQ-VAE-2生成图像模型在多个海上数据集上进行特征提取。我们还提出了一种创新的相似度分数技术，通过网格计算在缓存特征上直接计算连续帧中的相似度。</li>
<li>results: 我们使用RoboWhaler nautical视频数据集进行实验，并证明了我们的技术可以高效地检测动态场景变化。<details>
<summary>Abstract</summary>
Recently, there has been an upsurge in the research on maritime vision, where a lot of works are influenced by the application of computer vision for Unmanned Surface Vehicles (USVs). Various sensor modalities such as camera, radar, and lidar have been used to perform tasks such as object detection, segmentation, object tracking, and motion planning. A large subset of this research is focused on the video analysis, since most of the current vessel fleets contain the camera's onboard for various surveillance tasks. Due to the vast abundance of the video data, video scene change detection is an initial and crucial stage for scene understanding of USVs. This paper outlines our approach to detect dynamic scene changes in USVs. To the best of our understanding, this work represents the first investigation of scene change detection in the maritime vision application. Our objective is to identify significant changes in the dynamic scenes of maritime video data, particularly those scenes that exhibit a high degree of resemblance. In our system for dynamic scene change detection, we propose completely unsupervised learning method. In contrast to earlier studies, we utilize a modified cutting-edge generative picture model called VQ-VAE-2 to train on multiple marine datasets, aiming to enhance the feature extraction. Next, we introduce our innovative similarity scoring technique for directly calculating the level of similarity in a sequence of consecutive frames by utilizing grid calculation on retrieved features. The experiments were conducted using a nautical video dataset called RoboWhaler to showcase the efficient performance of our technique.
</details>
<details>
<summary>摘要</summary>
近来，有很多研究者在海上视觉领域进行了大量的研究，这些研究受到了计算机视觉技术应用于无人水面车（USV）的影响。不同的感知模式，如摄像头、雷达和激光雷达，都被用于实现对象检测、分割、跟踪和动作规划等任务。大多数当前的船舶舰队都装备有摄像头，因此海上视觉应用中的视频分析占据了大量的研究领域。由于海上视频数据的庞大量，视频场景变化检测是海上视觉应用中的初始和重要阶段。本文介绍了我们的场景变化检测方法，以及我们对这些方法的初步调研。在我们的系统中，我们提出了一种完全不监督学习方法，使用修改后的VQ-VAE-2模型来训练多个海洋数据集，以提高特征提取。然后，我们引入了我们的创新的相似度评分技术，通过网格计算在相应特征上 retrieve 的数据序列中直接计算相似度水平。我们在使用 RoboWhaler 海上视频数据集进行实验，以示出我们的方法的高效性。
</details></li>
</ul>
<hr>
<h2 id="A-3D-Multi-Style-Cross-Modality-Segmentation-Framework-for-Segmenting-Vestibular-Schwannoma-and-Cochlea"><a href="#A-3D-Multi-Style-Cross-Modality-Segmentation-Framework-for-Segmenting-Vestibular-Schwannoma-and-Cochlea" class="headerlink" title="A 3D Multi-Style Cross-Modality Segmentation Framework for Segmenting Vestibular Schwannoma and Cochlea"></a>A 3D Multi-Style Cross-Modality Segmentation Framework for Segmenting Vestibular Schwannoma and Cochlea</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11578">http://arxiv.org/abs/2311.11578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzhou Zhuang</li>
<li>for: 这个论文目的是为了使用不同的扫描图像来分割耳膜 schwannoma 和内耳听力器官区域。</li>
<li>methods: 该论文提出了一种3D多样式交叉Modal segmentation框架，包括多样式翻译和自学习分割阶段。在这个框架中，首先使用最小最大正规化、VOXEL SIZE resampling和中心剪辑来从ceT1和hrT2扫描图像中获得固定大小的子Volume для训练。然后，通过多样式图像翻译阶段来超越INTENSITY分布差异 между不匹配的多Modal扫描图像。specifically，设计了三种不同的翻译网络，用于生成多样式和实际的目标尺寸的目标Volume。最后，通过自学习分割阶段使用nnU-Net框架和迭代自学习方法使用pseudo-标签来训练准确的分割模型在无标签目标Domain中。</li>
<li>results: 在crossMoDA2023验证集上，我们的方法取得了可喜的结果，其中VS肿瘤和内耳听力器官区域的mean DSC值分别为72.78%和80.64%，ASSD值分别为5.85 mm和0.25 mm。此外，对于内耳和外耳的分割，我们的方法取得了DSC值分别为59.77%和77.14%。<details>
<summary>Abstract</summary>
The crossMoDA2023 challenge aims to segment the vestibular schwannoma (sub-divided into intra- and extra-meatal components) and cochlea regions of unlabeled hrT2 scans by leveraging labeled ceT1 scans. In this work, we proposed a 3D multi-style cross-modality segmentation framework for the crossMoDA2023 challenge, including the multi-style translation and self-training segmentation phases. Considering heterogeneous distributions and various image sizes in multi-institutional scans, we first utilize the min-max normalization, voxel size resampling, and center cropping to obtain fixed-size sub-volumes from ceT1 and hrT2 scans for training. Then, we perform the multi-style image translation phase to overcome the intensity distribution discrepancy between unpaired multi-modal scans. Specifically, we design three different translation networks with 2D or 2.5D inputs to generate multi-style and realistic target-like volumes from labeled ceT1 volumes. Finally, we perform the self-training volumetric segmentation phase in the target domain, which employs the nnU-Net framework and iterative self-training method using pseudo-labels for training accurate segmentation models in the unlabeled target domain. On the crossMoDA2023 validation dataset, our method produces promising results and achieves the mean DSC values of 72.78% and 80.64% and ASSD values of 5.85 mm and 0.25 mm for VS tumor and cochlea regions, respectively. Moreover, for intra- and extra-meatal regions, our method achieves the DSC values of 59.77% and 77.14%, respectively.
</details>
<details>
<summary>摘要</summary>
crossMoDA2023挑战的目标是将vestibular schwannoma（分为内耳和外耳组成部分）和cochlea区域分割成unlabeled hrT2扫描图像中，通过利用标注的ceT1扫描图像。在这项工作中，我们提出了一个3D多样式交叉Modal segmentation框架 дляcrossMoDA2023挑战，包括多样式翻译和自我培训分 segmentation阶段。鉴于多个机构的扫描图像具有不同的分布和大小，我们首先使用最小最大normalization、 voxel size resampling和center cropping来 obtaint fixed-size sub-volumes from ceT1和hrT2扫描图像 для训练。然后，我们实施多样式图像翻译阶段，以解决不同Modal scans的intensity分布差异。我们设计了三种不同的翻译网络，用于生成多样式和真实的目标尺寸的target-like 扫描图像。最后，我们实施了自我培训volumetric segmentation阶段，使用nnU-Net框架和迭代式自我培训方法，使用pseudo-labels进行训练准确的分 segmentation模型在没有标注的目标域中。在crossMoDA2023验证集上，我们的方法实现了可塑性的结果，得到了mean DSC值为72.78%和80.64%，和ASSD值为5.85 mm和0.25 mm дляVS肿瘤和cochlea区域，分别。此外， для内耳和外耳区域，我们的方法实现了DSC值为59.77%和77.14%。
</details></li>
</ul>
<hr>
<h2 id="CORE-MM-Complex-Open-Ended-Reasoning-Evaluation-For-Multi-Modal-Large-Language-Models"><a href="#CORE-MM-Complex-Open-Ended-Reasoning-Evaluation-For-Multi-Modal-Large-Language-Models" class="headerlink" title="CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models"></a>CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11567">http://arxiv.org/abs/2311.11567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaotian Han, Quanzeng You, Yongfei Liu, Wentao Chen, Huangjie Zheng, Khalil Mrini, Xudong Lin, Yiqi Wang, Bohan Zhai, Jianbo Yuan, Heng Wang, Hongxia Yang</li>
<li>For: The paper aims to evaluate the reasoning capabilities of Multi-modal Large Language Models (MLLMs) by creating a benchmark dataset with complex reasoning tasks.* Methods: The authors manually curate a benchmark dataset that includes three key reasoning categories: deductive, abductive, and analogical reasoning. They incorporate intermediate reasoning steps into their evaluation criteria to assess the reasoning ability of MLLMs.* Results: The authors evaluate a selection of representative MLLMs using their rigorously developed open-ended multi-step elaborate reasoning benchmark and show that their evaluation scheme is more effective in measuring the reasoning capabilities of MLLMs compared to existing benchmarks.Here’s the same information in Simplified Chinese text:* For: 本文旨在评估多模态大语言模型（MLLMs）的逻辑能力，通过创建一个具有复杂逻辑任务的 benchmark 数据集。* Methods: 作者们手动抽取了一个 benchmark 数据集，包括三种关键的逻辑类别：推理、假设和类比逻辑。他们在评估 criteria 中包含了中间逻辑步骤，以评估 MLLMs 的逻辑能力。* Results: 作者们使用自己开发的严格的开端多步详细逻辑 benchmark，评估了一些代表性的 MLLMs，并显示其评估方法比现有的 benchmark 更有效地评估 MLLMs 的逻辑能力。<details>
<summary>Abstract</summary>
Multi-modal Large Language Models (MLLMs) are increasingly prominent in the field of artificial intelligence. These models not only excel in traditional vision-language tasks but also demonstrate impressive performance in contemporary multi-modal benchmarks. Although many of these benchmarks attempt to holistically evaluate MLLMs, they typically concentrate on basic reasoning tasks, often yielding only simple yes/no or multi-choice responses. These methods naturally lead to confusion and difficulties in conclusively determining the reasoning capabilities of MLLMs. To mitigate this issue, we manually curate a benchmark dataset specifically designed for MLLMs, with a focus on complex reasoning tasks. Our benchmark comprises three key reasoning categories: deductive, abductive, and analogical reasoning. The queries in our dataset are intentionally constructed to engage the reasoning capabilities of MLLMs in the process of generating answers. For a fair comparison across various MLLMs, we incorporate intermediate reasoning steps into our evaluation criteria. In instances where an MLLM is unable to produce a definitive answer, its reasoning ability is evaluated by requesting intermediate reasoning steps. If these steps align with our manual annotations, appropriate scores are assigned. This evaluation scheme resembles methods commonly used in human assessments, such as exams or assignments, and represents what we consider a more effective assessment technique compared with existing benchmarks. We evaluate a selection of representative MLLMs using this rigorously developed open-ended multi-step elaborate reasoning benchmark, designed to challenge and accurately measure their reasoning capabilities. The code and data will be released at https://core-mm.github.io/
</details>
<details>
<summary>摘要</summary>
多Modal大语言模型（MLLMs）在人工智能领域日益突出。这些模型不仅在传统的视力语言任务中表现出色，而且在当今的多Modal测试 benchmark 中也显示出了卓越的表现。虽然许多这些 benchmark 尝试通过涵盖性评估 MLLMs，但它们通常集中在基本的理解任务上，经常产生简单的是或否或多选答案。这些方法自然导致混乱和确定 MLLMs 的理解能力的困难。为解决这个问题，我们手动编辑了一个特有的 benchmark 数据集，专门为 MLLMs 设计。我们的 benchmark 包括三个关键的理解类别：推理、推理和类比理解。我们的查询是故意构建的，以便让 MLLMs 在回答时使用其理解能力。为 Ensure 公平的比较，我们在评估标准中包括中间的理解步骤。在 MLLMs 无法提供明确答案时，我们评估其理解能力，请求中间理解步骤。如果这些步骤与我们的手动标注相符，就会分配相应的分数。这种评估方法与人类评估方法类似，例如考试或作业，并且代表我们认为更有效的评估方法，比较现有的 benchmark。我们使用这些精心开发的开放式多步逻辑 benchmark，评估一 selección 的代表 MLLMs，以挑战和准确测量它们的理解能力。我们的代码和数据将在 <https://core-mm.github.io/> 上发布。
</details></li>
</ul>
<hr>
<h2 id="Does-complimentary-information-from-multispectral-imaging-improve-face-presentation-attack-detection"><a href="#Does-complimentary-information-from-multispectral-imaging-improve-face-presentation-attack-detection" class="headerlink" title="Does complimentary information from multispectral imaging improve face presentation attack detection?"></a>Does complimentary information from multispectral imaging improve face presentation attack detection?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11566">http://arxiv.org/abs/2311.11566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narayan Vetrekar, Raghavendra Ramachandra, Sushma Venkatesh, Jyoti D. Pawar, R. S. Gad</li>
<li>for: 本研究旨在提高面部识别验证系统的安全性，通过利用多spectral成像技术检测面部展示诈骗。</li>
<li>methods: 本研究使用多spectral成像技术 constructed for eight different presentation artifacts resulted from three different artifact species，并 introduce Face Presentation Attack Multispectral (FPAMS) database。</li>
<li>results: 实验结果表明，基于多spectral成像技术的Face Presentation Attack Detection (PAD)方法可以提高face识别验证系统的安全性，并且可以 combining two different ways (image fusion和score fusion) to improve the face PAD。<details>
<summary>Abstract</summary>
Presentation Attack Detection (PAD) has been extensively studied, particularly in the visible spectrum. With the advancement of sensing technology beyond the visible range, multispectral imaging has gained significant attention in this direction. We present PAD based on multispectral images constructed for eight different presentation artifacts resulted from three different artifact species. In this work, we introduce Face Presentation Attack Multispectral (FPAMS) database to demonstrate the significance of employing multispectral imaging. The goal of this work is to study complementary information that can be combined in two different ways (image fusion and score fusion) from multispectral imaging to improve the face PAD. The experimental evaluation results present an extensive qualitative analysis of 61650 sample multispectral images collected for bonafide and artifacts. The PAD based on the score fusion and image fusion method presents superior performance, demonstrating the significance of employing multispectral imaging to detect presentation artifacts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="NePF-Neural-Photon-Field-for-Single-Stage-Inverse-Rendering"><a href="#NePF-Neural-Photon-Field-for-Single-Stage-Inverse-Rendering" class="headerlink" title="NePF: Neural Photon Field for Single-Stage Inverse Rendering"></a>NePF: Neural Photon Field for Single-Stage Inverse Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11555">http://arxiv.org/abs/2311.11555</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tuen-Yue Tsui, Qin Zou</li>
<li>for:  Addresses the ill-posed inverse rendering problem from multi-view images, recovering geometry, material, and illumination in a single stage.</li>
<li>methods:  Utilizes physical implications of neural implicit surfaces and view-dependent radiance, introduces coordinate-based illumination model and subsurface scattering for diffuse estimation.</li>
<li>results:  Demonstrates superiority in recovering high-fidelity geometry and visual-plausible material attributes, evaluated on real and synthetic datasets.Here’s the full text in Simplified Chinese:</li>
<li>for: 这种方法是为了解决多视图图像中的缺失 inverse rendering 问题，从多个视角图像中恢复geometry、物理和照明的单个阶段。</li>
<li>methods: 这种方法利用了神经凋散表面的物理含义和视角相关的辐射，并引入了坐标基于的照明模型和渐入散射模型 для减少辐射。</li>
<li>results: 这种方法可以准确地恢复高精度的geometry和可见可靠的物理属性，并在实际和 sintetic 数据集上进行了评估。<details>
<summary>Abstract</summary>
We present a novel single-stage framework, Neural Photon Field (NePF), to address the ill-posed inverse rendering from multi-view images. Contrary to previous methods that recover the geometry, material, and illumination in multiple stages and extract the properties from various multi-layer perceptrons across different neural fields, we question such complexities and introduce our method - a single-stage framework that uniformly recovers all properties. NePF achieves this unification by fully utilizing the physical implication behind the weight function of neural implicit surfaces and the view-dependent radiance. Moreover, we introduce an innovative coordinate-based illumination model for rapid volume physically-based rendering. To regularize this illumination, we implement the subsurface scattering model for diffuse estimation. We evaluate our method on both real and synthetic datasets. The results demonstrate the superiority of our approach in recovering high-fidelity geometry and visual-plausible material attributes.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的单阶段框架，神经光场（NePF），用于解决多视图图像中的不充分定义的反推问题。与之前的方法不同，我们的方法不需要在多个层次感知器中分别提取不同的物理属性，而是通过全面利用神经积分表面的物理逻辑和视角相关的辐射来实现单一阶段的全属性恢复。此外，我们还提出了一种创新的坐标基础照明模型，用于快速实现物理基于的立体渲染。为了规范这种照明，我们实现了渐入散射模型来估算散射颗粒。我们对真实和 sintetic 数据集进行评估，结果表明我们的方法可以高效地恢复高质量的几何和视觉可能的物理属性。
</details></li>
</ul>
<hr>
<h2 id="Unearthing-Common-Inconsistency-for-Generalisable-Deepfake-Detection"><a href="#Unearthing-Common-Inconsistency-for-Generalisable-Deepfake-Detection" class="headerlink" title="Unearthing Common Inconsistency for Generalisable Deepfake Detection"></a>Unearthing Common Inconsistency for Generalisable Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11549">http://arxiv.org/abs/2311.11549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Beilin Chu, Xuan Xu, Weike You, Linna Zhou</li>
<li>for: 这个研究旨在提出一种能够对不同的 manipulate 方法进行检测的方法，以扩展现有的图像级别检测方法。</li>
<li>methods: 本研究使用了一种基于自我指导的对照学习的方法，以捕捉几个不同的伪造技术中的几个共同特征。</li>
<li>results: 实验结果显示了本方法在不同的伪造领域中的扩展能力，并且比起现有的方法更具有抗压缩性和抗预期性。<details>
<summary>Abstract</summary>
Deepfake has emerged for several years, yet efficient detection techniques could generalize over different manipulation methods require further research. While current image-level detection method fails to generalize to unseen domains, owing to the domain-shift phenomenon brought by CNN's strong inductive bias towards Deepfake texture, video-level one shows its potential to have both generalization across multiple domains and robustness to compression. We argue that although distinct face manipulation tools have different inherent bias, they all disrupt the consistency between frames, which is a natural characteristic shared by authentic videos. Inspired by this, we proposed a detection approach by capturing frame inconsistency that broadly exists in different forgery techniques, termed unearthing-common-inconsistency (UCI). Concretely, the UCI network based on self-supervised contrastive learning can better distinguish temporal consistency between real and fake videos from multiple domains. We introduced a temporally-preserved module method to introduce spatial noise perturbations, directing the model's attention towards temporal information. Subsequently, leveraging a multi-view cross-correlation learning module, we extensively learn the disparities in temporal representations between genuine and fake samples. Extensive experiments demonstrate the generalization ability of our method on unseen Deepfake domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Event-Camera-Data-Dense-Pre-training"><a href="#Event-Camera-Data-Dense-Pre-training" class="headerlink" title="Event Camera Data Dense Pre-training"></a>Event Camera Data Dense Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11533">http://arxiv.org/abs/2311.11533</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Yang, Liyuan Pan, Liu Liu</li>
<li>for: 这个论文旨在开发一个用于预训神经网络的自我超vised learning框架，并将其应用于离散预测任务中的事件摄像头数据上。</li>
<li>methods: 我们的方法仅使用事件数据进行训练，并将事件图像转换成事件补丁特征，自动找到事件补丁之间的相似关系，将事件补丁分组成不同的上下文，并强制这些上下文之间的相似性来学习特征。</li>
<li>results: 我们的方法在转移到下游对于离散预测任务的训练中表现出色，特别是在DSEC-Flow标准库中获得了最佳成绩。单一的模型在这个挑战性的benchmark中获得了第一名。<details>
<summary>Abstract</summary>
This paper introduces a self-supervised learning framework designed for pre-training neural networks tailored to dense prediction tasks using event camera data. Our approach utilizes solely event data for training.   Transferring achievements from dense RGB pre-training directly to event camera data yields subpar performance. This is attributed to the spatial sparsity inherent in an event image (converted from event data), where many pixels do not contain information. To mitigate this sparsity issue, we encode an event image into event patch features, automatically mine contextual similarity relationships among patches, group the patch features into distinctive contexts, and enforce context-to-context similarities to learn discriminative event features.   For training our framework, we curate a synthetic event camera dataset featuring diverse scene and motion patterns. Transfer learning performance on downstream dense prediction tasks illustrates the superiority of our method over state-of-the-art approaches. Notably, our single model secured the top position in the challenging DSEC-Flow benchmark.
</details>
<details>
<summary>摘要</summary>
The proposed framework is trained using a synthetic event camera dataset featuring diverse scene and motion patterns. The transfer learning performance on downstream dense prediction tasks demonstrates the superiority of the method over state-of-the-art approaches. Notably, the single model achieved the top position in the challenging DSEC-Flow benchmark.Simplified Chinese translation:这篇论文介绍了一种基于自我超级vised学习的神经网络预训练框架，特化于透明度预测任务使用事件相机数据。我们的方法不依赖于RGB数据，直接将RGB预训练的成果转移到事件相机数据上则表现不佳，这是因为事件图像具有较强的空间稀畴性， многи个像素不含信息。为了解决这个稀畴性问题，我们将事件图像编码成事件 patch特征，自动挖掘事件 patch 之间的相似性关系，将 patch 特征分组到不同的上下文中，并且在不同上下文之间强制实施相似性来学习特征。为了训练我们的框架，我们创建了一个synthetic事件相机数据集，该数据集包含多种场景和运动模式。我们的方法在下游密集预测任务上表现出了优于当前最佳方法。特别是，我们的单个模型在挑战性的 DSEC-Flow 比赛中占据了第一名。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Category-Discovery-in-Semantic-Segmentation"><a href="#Generalized-Category-Discovery-in-Semantic-Segmentation" class="headerlink" title="Generalized Category Discovery in Semantic Segmentation"></a>Generalized Category Discovery in Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11525">http://arxiv.org/abs/2311.11525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jethropeng/gcdss">https://github.com/jethropeng/gcdss</a></li>
<li>paper_authors: Zhengyuan Peng, Qijian Tian, Jianqing Xu, Yizhang Jin, Xuequan Lu, Xin Tan, Yuan Xie, Lizhuang Ma</li>
<li>for: 这则论文探索了一个称为通用类别发现（Generalized Category Discovery，GCD）的新设定，旨在将无标签图像分类为不同的类别。</li>
<li>methods: 这则论文提出了一个简单 yet effective的框架，将GCD问题视为一个mask classification的任务。此外，它还提出了一个基eline方法和一个叫做邻居关系导向的Mask Clustering Algorithm（NeRG-MaskCA），用于实现mask categorization。</li>
<li>results: 这则论文发现了GCD问题的可行性和发现 novel object classes 的可能性。它还提出了一个基于自己的方法所生成的pseudo-labels来对其他模型进行超vised training，从而允许它们 segment novel classes。<details>
<summary>Abstract</summary>
This paper explores a novel setting called Generalized Category Discovery in Semantic Segmentation (GCDSS), aiming to segment unlabeled images given prior knowledge from a labeled set of base classes. The unlabeled images contain pixels of the base class or novel class. In contrast to Novel Category Discovery in Semantic Segmentation (NCDSS), there is no prerequisite for prior knowledge mandating the existence of at least one novel class in each unlabeled image. Besides, we broaden the segmentation scope beyond foreground objects to include the entire image. Existing NCDSS methods rely on the aforementioned priors, making them challenging to truly apply in real-world situations. We propose a straightforward yet effective framework that reinterprets the GCDSS challenge as a task of mask classification. Additionally, we construct a baseline method and introduce the Neighborhood Relations-Guided Mask Clustering Algorithm (NeRG-MaskCA) for mask categorization to address the fragmentation in semantic representation. A benchmark dataset, Cityscapes-GCD, derived from the Cityscapes dataset, is established to evaluate the GCDSS framework. Our method demonstrates the feasibility of the GCDSS problem and the potential for discovering and segmenting novel object classes in unlabeled images. We employ the generated pseudo-labels from our approach as ground truth to supervise the training of other models, thereby enabling them with the ability to segment novel classes. It paves the way for further research in generalized category discovery, broadening the horizons of semantic segmentation and its applications. For details, please visit https://github.com/JethroPeng/GCDSS
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Liver-Tumor-Prediction-with-Advanced-Attention-Mechanisms-Integrated-into-a-Depth-Based-Variant-Search-Algorithm"><a href="#Liver-Tumor-Prediction-with-Advanced-Attention-Mechanisms-Integrated-into-a-Depth-Based-Variant-Search-Algorithm" class="headerlink" title="Liver Tumor Prediction with Advanced Attention Mechanisms Integrated into a Depth-Based Variant Search Algorithm"></a>Liver Tumor Prediction with Advanced Attention Mechanisms Integrated into a Depth-Based Variant Search Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11520">http://arxiv.org/abs/2311.11520</a></li>
<li>repo_url: None</li>
<li>paper_authors: P. Kalaiselvi, S. Anusuya</li>
<li>for: 预测肝肿瘤，提高肝病诊断和治疗规划的精度和可靠性。</li>
<li>methods: 使用卷积神经网络（CNN）和深度基于变体搜索算法（CNN-DS-AM），并实现了高精度的肝肿瘤预测。</li>
<li>results: 在计算tomography（CT）扫描数据集上测试，提出的方法实现了95.5%的肝肿瘤预测精度，超过了其他当前状态的方法。<details>
<summary>Abstract</summary>
In recent days, Deep Learning (DL) techniques have become an emerging transformation in the field of machine learning, artificial intelligence, computer vision, and so on. Subsequently, researchers and industries have been highly endorsed in the medical field, predicting and controlling diverse diseases at specific intervals. Liver tumor prediction is a vital chore in analyzing and treating liver diseases. This paper proposes a novel approach for predicting liver tumors using Convolutional Neural Networks (CNN) and a depth-based variant search algorithm with advanced attention mechanisms (CNN-DS-AM). The proposed work aims to improve accuracy and robustness in diagnosing and treating liver diseases. The anticipated model is assessed on a Computed Tomography (CT) scan dataset containing both benign and malignant liver tumors. The proposed approach achieved high accuracy in predicting liver tumors, outperforming other state-of-the-art methods. Additionally, advanced attention mechanisms were incorporated into the CNN model to enable the identification and highlighting of regions of the CT scans most relevant to predicting liver tumors. The results suggest that incorporating attention mechanisms and a depth-based variant search algorithm into the CNN model is a promising approach for improving the accuracy and robustness of liver tumor prediction. It can assist radiologists in their diagnosis and treatment planning. The proposed system achieved a high accuracy of 95.5% in predicting liver tumors, outperforming other state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
近些天，深度学习（DL）技术在机器学习、人工智能、计算机视觉等领域成为了一种emerging变革。因此，研究人员和产业在医疗领域中高度支持DL技术，以预测和控制多种疾病。肝肿瘤预测是分析和治疗肝病的重要任务。这篇论文提出了一种基于卷积神经网络（CNN）和深度基本变换搜索算法（CNN-DS-AM）的新方法，以提高肝肿瘤预测的准确性和Robustness。提案的方法在一个计算Tomography（CT）扫描数据集上进行测试，包括了良性和肿瘤肝肿瘤。提案的方法实现了高度的肝肿瘤预测精度，超过了其他当前的方法。此外，提案中还 incorporated了进一步的注意力机制，以便在CT扫描中特定和高亮肝肿瘤的预测区域。结果表明，在CNN模型中integrating注意力机制和深度基本变换搜索算法是一种promising的方法，可以提高肝肿瘤预测的准确性和Robustness。这可以帮助放射科医生在诊断和治疗规划中使用。提案的系统在评估CT扫描数据集上实现了95.5%的肝肿瘤预测精度，超过了其他当前的方法。
</details></li>
</ul>
<hr>
<h2 id="Seeing-through-the-Mask-Multi-task-Generative-Mask-Decoupling-Face-Recognition"><a href="#Seeing-through-the-Mask-Multi-task-Generative-Mask-Decoupling-Face-Recognition" class="headerlink" title="Seeing through the Mask: Multi-task Generative Mask Decoupling Face Recognition"></a>Seeing through the Mask: Multi-task Generative Mask Decoupling Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11512">http://arxiv.org/abs/2311.11512</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaohui Wang, Sufang Zhang, Jianteng Peng, Xinyi Wang, Yandong Guo</li>
<li>for: This paper is written for improving the performance of face recognition systems in occluded scenes, where current systems suffer from serious performance degradation.</li>
<li>methods: The proposed method, called Multi-task gEnerative mask dEcoupling face Recognition (MEER), uses a novel mask decoupling module to disentangle mask and identity information, and a joint-training strategy to restore unmasked faces and refine the recognition network.</li>
<li>results: The MEER method outperforms state-of-the-art methods on masked face recognition under realistic and synthetic occlusions benchmarks.<details>
<summary>Abstract</summary>
The outbreak of COVID-19 pandemic make people wear masks more frequently than ever. Current general face recognition system suffers from serious performance degradation,when encountering occluded scenes. The potential reason is that face features are corrupted by occlusions on key facial regions. To tackle this problem, previous works either extract identity-related embeddings on feature level by additional mask prediction, or restore the occluded facial part by generative models. However, the former lacks visual results for model interpretation, while the latter suffers from artifacts which may affect downstream recognition. Therefore, this paper proposes a Multi-task gEnerative mask dEcoupling face Recognition (MEER) network to jointly handle these two tasks, which can learn occlusionirrelevant and identity-related representation while achieving unmasked face synthesis. We first present a novel mask decoupling module to disentangle mask and identity information, which makes the network obtain purer identity features from visible facial components. Then, an unmasked face is restored by a joint-training strategy, which will be further used to refine the recognition network with an id-preserving loss. Experiments on masked face recognition under realistic and synthetic occlusions benchmarks demonstrate that the MEER can outperform the state-ofthe-art methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行使人们更加常 wear 面具，但现有的通用面 recognition 系统在遇到 occluded 场景时会出现严重的性能下降。这可能是因为 occlusion 对 key  facial 区域的 face 特征造成了损害。为解决这个问题，先前的工作可以通过添加 mask 预测来提取 identity-related embedding，或者使用生成模型来恢复遮盖的 facial 部分。然而，前者缺乏视觉效果，后者可能会产生遮盖 artifacts，这些遮盖 artifacts 可能会影响下游认识。因此，本文提出了一种 Multi-task gEnerative mask dEcoupling face Recognition (MEER) 网络，该网络可以同时处理这两个任务，学习 occlusion-irrelevant 和 identity-related 表示，并实现无面具 synthesis。我们首先提出了一种 novel mask decoupling module，用于分离 mask 和 identity 信息，使网络从可见 facial 部分获得纯净的 identity 特征。然后，我们使用 joint-training 策略来恢复无面具，这将被用于提高 recognition 网络的性能。实验表明，MEER 可以在实际和Synthetic occlusions benchmarks 上出perform state-of-the-art 方法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.CV_2023_11_20/" data-id="clp89dofw00ngi7880kywfkgx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.AI_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T12:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.AI_2023_11_20/">cs.AI - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation"><a href="#Hourglass-Tokenizer-for-Efficient-Transformer-Based-3D-Human-Pose-Estimation" class="headerlink" title="Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation"></a>Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12028">http://arxiv.org/abs/2311.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Li, Mengyuan Liu, Hong Liu, Pichao Wang, Jialun Cai, Nicu Sebe</li>
<li>for: efficient transformer-based 3D human pose estimation from videos</li>
<li>methods: pruning-and-recovering framework, token pruning cluster, token recovering attention</li>
<li>results: improved model efficiency, high estimation accuracy, reduced FLOPs (compared to original VPT models)<details>
<summary>Abstract</summary>
Transformers have been successfully applied in the field of video-based 3D human pose estimation. However, the high computational costs of these video pose transformers (VPTs) make them impractical on resource-constrained devices. In this paper, we present a plug-and-play pruning-and-recovering framework, called Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose estimation from videos. Our HoT begins with pruning pose tokens of redundant frames and ends with recovering full-length tokens, resulting in a few pose tokens in the intermediate transformer blocks and thus improving the model efficiency. To effectively achieve this, we propose a token pruning cluster (TPC) that dynamically selects a few representative tokens with high semantic diversity while eliminating the redundancy of video frames. In addition, we develop a token recovering attention (TRA) to restore the detailed spatio-temporal information based on the selected tokens, thereby expanding the network output to the original full-length temporal resolution for fast inference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and MPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and estimation accuracy compared to the original VPT models. For instance, applying to MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs without sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop, respectively. Our source code will be open-sourced.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的转换器模型在视频基于3D人姿估计领域已经得到成功应用。然而，这些视频转换器（VPT）的计算成本很高，使得在有限的资源设备上实现不可靠。在这篇论文中，我们提出了一种插件化剪辑和恢复框架，called Hourglass Tokenizer（HoT），用于高效地使用转换器进行视频基于3D人姿估计。我们的HoT开始于剪辑人姿块（TPC），选择视频帧中缺乏重复的块，然后通过恢复全长块（TRA）来恢复原始的块，从而提高模型的效率。为了有效实现这一点，我们提出了一种动态选择高Semantic多样性的块的 Token Pruning Cluster（TPC），并开发了一种基于选择的块的 Token Recovering Attention（TRA），以恢复原始的块。我们的方法可以在两个标准数据集（i.e., Human3.6M和MPI-INF-3DHP）上进行广泛的实验，结果表明，我们的方法可以同时实现高效和高准确性。例如，在应用于MotionBERT和MixSTE上的Human3.6M数据集上，我们的HoT可以节省约50%的计算成本，无需牺牲准确性，或者节省约40%的计算成本，只有0.2%的准确性下降。我们将源代码公开源。<<SYS>>
</details></li>
</ul>
<hr>
<h2 id="GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark"><a href="#GPQA-A-Graduate-Level-Google-Proof-Q-A-Benchmark" class="headerlink" title="GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark"></a>GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12022">http://arxiv.org/abs/2311.12022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idavidrein/gpqa">https://github.com/idavidrein/gpqa</a></li>
<li>paper_authors: David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, Samuel R. Bowman</li>
<li>for: The paper is written to present a challenging dataset of multiple-choice questions to evaluate the ability of AI systems and human experts to answer difficult questions in biology, physics, and chemistry.</li>
<li>methods: The paper uses a dataset of 448 questions written by domain experts, which are high-quality and extremely difficult even for PhD-holding experts. The authors also use a strongest GPT-4 based baseline to evaluate the performance of state-of-the-art AI systems.</li>
<li>results: The paper shows that the questions in the dataset are difficult for both human experts and AI systems, with the experts reaching 65% accuracy and the AI system reaching 39% accuracy. The results suggest that scalable oversight methods are needed to ensure that human experts can reliably get truthful information from AI systems that surpass human capabilities.<details>
<summary>Abstract</summary>
We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are "Google-proof"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.
</details>
<details>
<summary>摘要</summary>
我们提供了GPQA，一个具有挑战性的448道多选问题集，由领域专家写成的生物、物理和化学领域。我们确保了问题的质量和极其困难：具有或正在追求博士学位的专家达到65%的准确率（74%，减去明显的后悔），而非专家验证人员仅达到34%的准确率，即使花费平均超过30分钟，并且有无限时间 accessing the web（即问题是"Google-proof"）。这些问题还是前沿AI系统的挑战，我们最强的基于GPT-4的基线只达39%的准确率。如果我们想使用未来的AI系统来帮助我们回答非常困难的问题，例如在科学发展新知识时，我们需要开发可扩展的监督方法，以便人类可以监督AI系统的输出，这可能是非常困难，即使监督人员本身具备技能和知识。GPQA的困难程度不仅对非专家和前沿AI系统来说是挑战，也可以帮助我们实施可扩展的监督实验，以便开发可靠地获取AI系统输出的真实信息的方法。
</details></li>
</ul>
<hr>
<h2 id="Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism"><a href="#Steering-Responsible-AI-A-Case-for-Algorithmic-Pluralism" class="headerlink" title="Steering Responsible AI: A Case for Algorithmic Pluralism"></a>Steering Responsible AI: A Case for Algorithmic Pluralism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12010">http://arxiv.org/abs/2311.12010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefaan G. Verhulst</li>
<li>for: 本文探讨人工智能中立性问题，通过现有的媒介和多元媒体学术研究。</li>
<li>methods: 本文使用现有的媒介和多元媒体学术研究来探讨AI中立性问题。</li>
<li>results: 本文认为，思考algorithmic pluralism可能有助于维护多样性、多元性和包容性，这些价值对民主社会至关重要。<details>
<summary>Abstract</summary>
In this paper, I examine questions surrounding AI neutrality through the prism of existing literature and scholarship about mediation and media pluralism. Such traditions, I argue, provide a valuable theoretical framework for how we should approach the (likely) impending era of AI mediation. In particular, I suggest examining further the notion of algorithmic pluralism. Contrasting this notion to the dominant idea of algorithmic transparency, I seek to describe what algorithmic pluralism may be, and present both its opportunities and challenges. Implemented thoughtfully and responsibly, I argue, Algorithmic or AI pluralism has the potential to sustain the diversity, multiplicity, and inclusiveness that are so vital to democracy.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我探讨人工智能中立性的问题，通过现有的媒介和多元媒体学术研究。这些传统提供了valuable的理论框架，以便我们在（可能的）人工智能仲裁时期应对问题。特别是，我建议更深入研究算法多元主义。与算法透明度主义的主流想法相对，我想要描述算法多元主义是什么，并提出这种概念的机遇和挑战。如果想明智地和责任地实施，我认为算法或人工智能多元主义有potential sustain多样性、多元性和包容性，这些特质是民主的基础。
</details></li>
</ul>
<hr>
<h2 id="BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning"><a href="#BrainWash-A-Poisoning-Attack-to-Forget-in-Continual-Learning" class="headerlink" title="BrainWash: A Poisoning Attack to Forget in Continual Learning"></a>BrainWash: A Poisoning Attack to Forget in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11995">http://arxiv.org/abs/2311.11995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Abbasi, Parsa Nooralinejad, Hamed Pirsiavash, Soheil Kolouri</li>
<li>for: 这篇研究旨在测试深度学习模型在继续学习中的攻击性，尤其是对于导致遗传的情况。</li>
<li>methods: 本研究提出了一种名为“BrainWash”的数据污染方法，用于强制深度学习模型忘记先前学习的任务。这种攻击方法不需要攻击者有previous任务的数据，只需要 possession of the model’s current parameters 和最新任务的数据即可。</li>
<li>results: 实验结果显示，BrainWash 方法可以对多种常用的定期学习方法进行成功攻击，导致模型的性能下降剧烈。<details>
<summary>Abstract</summary>
Continual learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce "BrainWash," a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis"><a href="#Exploring-Lip-Segmentation-Techniques-in-Computer-Vision-A-Comparative-Analysis" class="headerlink" title="Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis"></a>Exploring Lip Segmentation Techniques in Computer Vision: A Comparative Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11992">http://arxiv.org/abs/2311.11992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Francisco Braulio Oliveira, Lucas Moreira Medino, Emanuel Huber, Milene Haraguchi Padilha, Cassio de Alcantara, Renata Sellaro</li>
<li>for: 这个研究的目的是对 lip segmentation 模型进行比较性评估，以找到最佳的模型。</li>
<li>methods: 这个研究使用了 five 种 lip segmentation 模型，包括 EHANet、Mask2Former、BiSeNet V2、PIDNet 和 STDC1。这些模型被选择基于其报告的性能、执行时间、代码可用性、新颖性和受欢迎度。</li>
<li>results: 研究发现，Mask2Former 和 EHANet 在 mIoU 分数上表现最佳，BiSeNet V2 表现稍差一些，而 PIDNet 在准确率方面表现出色，但精度较低。大多数模型在 Raspberry Pi4 上的执行时间在 1000-3000 毫秒之间，PIDNet 的平均执行时间最低。<details>
<summary>Abstract</summary>
Lip segmentation is crucial in computer vision, especially for lip reading. Despite extensive face segmentation research, lip segmentation has received limited attention. The aim of this study is to compare state-of-the-art lip segmentation models using a standardized setting and a publicly available dataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and STDC1, are qualitatively selected based on their reported performance, inference time, code availability, recency, and popularity. The CelebAMask-HQ dataset, comprising manually annotated face images, is used to fairly assess the lip segmentation performance of the selected models. Inference experiments are conducted on a Raspberry Pi4 to emulate limited computational resources. The results show that Mask2Former and EHANet have the best performances in terms of mIoU score. BiSeNet V2 demonstrate competitive performance, while PIDNet excels in recall but has lower precision. Most models present inference time ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with PIDNet having the lowest mean inference time. This study provides a comprehensive evaluation of lip segmentation models, highlighting their performance and inference times. The findings contribute to the development of lightweight techniques and establish benchmarks for future advances in lip segmentation, especially in IoT and edge computing scenarios.
</details>
<details>
<summary>摘要</summary>
lip 分割是计算机视觉中非常重要的一环，特别是 lip 读。Despite 广泛的面部分割研究，lip 分割却受到了有限的关注。本研究的目标是比较当前最佳的 lip 分割模型，使用标准化的设置和公共可用的数据集进行评估。五种技术，namely EHANet、Mask2Former、BiSeNet V2、PIDNet和STDC1，被选择基于其报道的性能、推理时间、代码可用性、新颖性和流行度。使用 CelebAMask-HQ 数据集，包含手动标注的 face 图像，对选择的模型进行公平的评估。在 Raspberry Pi4 上进行推理实验，以模拟有限的计算资源。结果显示，Mask2Former 和 EHANet 在 mIoU 分数上表现最佳，BiSeNet V2 表现稍逊一些，而 PIDNet 在准确率方面表现出色，但精度较低。大多数模型在 Raspberry Pi4 上的推理时间在 1000-3000 毫秒之间，PIDNet 的平均推理时间最低。本研究提供了 lip 分割模型的全面评估，揭示了它们的性能和推理时间。这些发现对于 lip 分割技术的发展，特别是在 IoT 和边缘计算方面，具有重要的意义。
</details></li>
</ul>
<hr>
<h2 id="Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs"><a href="#Categorizing-the-Visual-Environment-and-Analyzing-the-Visual-Attention-of-Dogs" class="headerlink" title="Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs"></a>Categorizing the Visual Environment and Analyzing the Visual Attention of Dogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11988">http://arxiv.org/abs/2311.11988</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shreyas Sundara Raman, Madeline H. Pelgrim, Daphna Buchsbaum, Thomas Serre</li>
<li>for: 这个论文的目的是研究狗的视觉行为和与物理世界的互动。</li>
<li>methods: 该论文使用了头戴式眼动跟踪设备收集和研究了11只狗在日常户外环境中 gaze 的数据，并使用了这些数据来微调MaskRCNN模型以自动分类狗的视觉定点。</li>
<li>results: 研究发现，狗寻找的对象主要包括汽车、植物、路面和建筑机器，并且发现了一些个体差异。这个研究为了解狗的视觉行为和与物理世界的互动提供了一个重要的步骤。<details>
<summary>Abstract</summary>
Dogs have a unique evolutionary relationship with humans and serve many important roles e.g. search and rescue, blind assistance, emotional support. However, few datasets exist to categorize visual features and objects available to dogs, as well as how dogs direct their visual attention within their environment. We collect and study a dataset with over 11,698 gazes to categorize the objects available to be gazed at by 11 dogs in everyday outdoor environments i.e. a walk around a college campus and urban area. We explore the availability of these object categories and the visual attention of dogs over these categories using a head mounted eye tracking apparatus. A small portion (approx. 600 images or < 20% of total dataset) of the collected data is used to fine tune a MaskRCNN for the novel image domain to segment objects present in the scene, enabling further statistical analysis on the visual gaze tendencies of dogs. The MaskRCNN, with eye tracking apparatus, serves as an end to end model for automatically classifying the visual fixations of dogs. The fine tuned MaskRCNN performs far better than chance. There are few individual differences between the 11 dogs and we observe greater visual fixations on buses, plants, pavement, and construction equipment. This work takes a step towards understanding visual behavior of dogs and their interaction with the physical world.
</details>
<details>
<summary>摘要</summary>
狗具有独特的进化关系与人类，扮演多种重要角色，如搜寻救援、导盲帮助和情感支持。然而，有少量的数据集存在以描述狗可以看到的视觉特征和物体，以及狗在环境中如何指向视觉注意力。我们收集和研究了一个数据集，包含11只狗在日常户外环境中（如大学校园和城市区）的11,698次视觉定位数据，以分类可见的物体类别。我们发现狗偏好注视汽车、植物、路面和建筑设备等物体类别，这些结果可能为狗的视觉行为和与物理世界的互动提供了新的理解。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces"><a href="#Leveraging-Previous-Facial-Action-Units-Knowledge-for-Emotion-Recognition-on-Faces" class="headerlink" title="Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces"></a>Leveraging Previous Facial Action Units Knowledge for Emotion Recognition on Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11980">http://arxiv.org/abs/2311.11980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro B. S. Masur, Willams Costa, Lucas S. Figueredo, Veronica Teichrieb</li>
<li>For: The paper aims to improve emotion recognition techniques using Facial Action Units (AUs) recognition.* Methods: The proposed method uses a machine learning system based on the Facial Action Coding System (FACS) to recognize emotions from facial expressions. The method builds upon and expands the existing EmotiRAM approach for multi-cue emotion recognition.* Results: The proposed method is expected to improve the accuracy of emotion recognition techniques by leveraging the information provided by Facial Action Units.<details>
<summary>Abstract</summary>
People naturally understand emotions, thus permitting a machine to do the same could open new paths for human-computer interaction. Facial expressions can be very useful for emotion recognition techniques, as these are the biggest transmitters of non-verbal cues capable of being correlated with emotions. Several techniques are based on Convolutional Neural Networks (CNNs) to extract information in a machine learning process. However, simple CNNs are not always sufficient to locate points of interest on the face that can be correlated with emotions. In this work, we intend to expand the capacity of emotion recognition techniques by proposing the usage of Facial Action Units (AUs) recognition techniques to recognize emotions. This recognition will be based on the Facial Action Coding System (FACS) and computed by a machine learning system. In particular, our method expands over EmotiRAM, an approach for multi-cue emotion recognition, in which we improve over their facial encoding module.
</details>
<details>
<summary>摘要</summary>
人们自然地理解情感，因此让机器也能够这样做可能会开启新的人机交互方式。脸部表达是情感识别技术中最大的非语言指示器，可以与情感相关。多种技术基于卷积神经网络（CNNs）来提取信息，但简单的CNNs不足以定位面部上的点点感兴趣，与情感相关。在这项工作中，我们计划通过使用表情动作单元（AU）识别技术来识别情感。这种识别基于人脸动作编码系统（FACS），由机器学习系统计算。具体来说，我们的方法超越EmotiRAM，一种多cue情感识别方法中的脸部编码模块。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting"><a href="#Evaluating-Supervision-Levels-Trade-Offs-for-Infrared-Based-People-Counting" class="headerlink" title="Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting"></a>Evaluating Supervision Levels Trade-Offs for Infrared-Based People Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11974">http://arxiv.org/abs/2311.11974</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Latortue, Moetez Kdayem, Fidel A Guerrero Peña, Eric Granger, Marco Pedersoli</li>
<li>for: 人数计算（人肉定位）在多个应用中广泛使用，但需要贵重的 bounding box 注释数据进行训练。为保持隐私，这些模型越来越依赖于红外图像，这使得任务变得更加困难。</li>
<li>methods: 我们使用深度人数计算建筑物模型进行图像分类和点级定位。我们的实验表明，使用 CNN 图像级模型可以达到与 YOLO 检测器和点级模型相当的性能，但具有更高的帧率和相似的模型参数。</li>
<li>results: 我们的实验结果表明，使用 CNN 图像级模型可以达到与 YOLO 检测器和点级模型相当的性能，但具有更高的帧率和相似的模型参数。<details>
<summary>Abstract</summary>
Object detection models are commonly used for people counting (and localization) in many applications but require a dataset with costly bounding box annotations for training. Given the importance of privacy in people counting, these models rely more and more on infrared images, making the task even harder. In this paper, we explore how weaker levels of supervision can affect the performance of deep person counting architectures for image classification and point-level localization. Our experiments indicate that counting people using a CNN Image-Level model achieves competitive results with YOLO detectors and point-level models, yet provides a higher frame rate and a similar amount of model parameters.
</details>
<details>
<summary>摘要</summary>
人数检测模型通常用于人数统计（和位置确定）在许多应用中，但需要费时的 bounding box 注释 для训练。由于人数统计中的隐私很重要，这些模型越来越依赖于红外图像，使得任务变得更加困难。在这篇论文中，我们探讨弱级超级vision对深度人数计算机 arquitectures 的影响。我们的实验结果表明，使用 CNN 图像级模型进行人数统计可以与 YOLO 探测器和点级模型具有竞争力，同时提供更高的帧率和相似的模型参数。
</details></li>
</ul>
<hr>
<h2 id="NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation"><a href="#NNG-Mix-Improving-Semi-supervised-Anomaly-Detection-with-Pseudo-anomaly-Generation" class="headerlink" title="NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation"></a>NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11961">http://arxiv.org/abs/2311.11961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/donghao51/nng-mix">https://github.com/donghao51/nng-mix</a></li>
<li>paper_authors: Hao Dong, Gaëtan Frusque, Yue Zhao, Eleni Chatzi, Olga Fink</li>
<li>for: 本研究旨在提出一种新的数据增强算法，用于增加异常样本数量，以提高异常检测性能。</li>
<li>methods: 该算法基于 nearest neighbor Gaussian mixture 的思想，能够充分利用限量的异常样本和大量的无标注数据信息，生成更多的异常样本。</li>
<li>results: 对于57个 benchmark 数据集，比较了不同的数据增强方法，发现 NNG-Mix 方法可以提高异常检测性能，相比基eline 提高了16.4%、8.8% 和8.0%。<details>
<summary>Abstract</summary>
Anomaly detection (AD) is essential in identifying rare and often critical events in complex systems, finding applications in fields such as network intrusion detection, financial fraud detection, and fault detection in infrastructure and industrial systems. While AD is typically treated as an unsupervised learning task due to the high cost of label annotation, it is more practical to assume access to a small set of labeled anomaly samples from domain experts, as is the case for semi-supervised anomaly detection. Semi-supervised and supervised approaches can leverage such labeled data, resulting in improved performance. In this paper, rather than proposing a new semi-supervised or supervised approach for AD, we introduce a novel algorithm for generating additional pseudo-anomalies on the basis of the limited labeled anomalies and a large volume of unlabeled data. This serves as an augmentation to facilitate the detection of new anomalies. Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies. We compare the performance of this novel algorithm with commonly applied augmentation techniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various existing semi-supervised and supervised anomaly detection algorithms on the original training data along with the generated pseudo-anomalies. Through extensive experiments on 57 benchmark datasets in ADBench, reflecting different data types, we demonstrate that NNG-Mix outperforms other data augmentation methods. It yields significant performance improvements compared to the baselines trained exclusively on the original training data. Notably, NNG-Mix yields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP datasets in ADBench. Our source code will be available at https://github.com/donghao51/NNG-Mix.
</details>
<details>
<summary>摘要</summary>
《异常检测（AD）是在复杂系统中发现罕见和critical事件的 essencial 任务，应用于网络侵入检测、金融诈骗检测和基础设施和工业系统的故障检测等领域。由于AD通常被视为无监督学习任务，因此在实际应用中通常只有限量的标注异常样本可以获得。在本文中，而不是提出一种新的半监督或监督学习方法，我们介绍了一种新的算法，可以生成基于有限的标注异常样本和大量的无标注数据的 Pseudo-异常。这种方法被称为 Nearest Neighbor Gaussian Mixup（NNG-Mix）。NNG-Mix 有效地利用了标注和无标注数据的信息，生成 Pseudo-异常。我们与常见的 Mixup 和 Cutout 等数据增强技术进行比较，通过在原始训练数据上训练不同的半监督和监督学习算法，评估 NNG-Mix 的性能。我们在 ADBench 上的 57 个标准 benchmark 上进行了广泛的实验，发现 NNG-Mix 在不同的数据类型上达到了显著的性能改进。它与基准值相比，在 Classical、CV 和 NLP 等类型上提高了16.4%、8.8% 和 8.0%。我们将源代码发布在 GitHub 上，地址为 <https://github.com/donghao51/NNG-Mix>。
</details></li>
</ul>
<hr>
<h2 id="Correlated-Attention-in-Transformers-for-Multivariate-Time-Series"><a href="#Correlated-Attention-in-Transformers-for-Multivariate-Time-Series" class="headerlink" title="Correlated Attention in Transformers for Multivariate Time Series"></a>Correlated Attention in Transformers for Multivariate Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11959">http://arxiv.org/abs/2311.11959</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quang Minh Nguyen, Lam M. Nguyen, Subhro Das</li>
<li>for: 本研究旨在提出一种新的相关注意机制，以提高基于Transformer的多变量时间序列（MTS）分析模型的表现。</li>
<li>methods: 该机制可以快速发现时间序列中的相关性，同时可以在不同特征通道之间进行相关性捕捉，从而更好地捕捉复杂的动力系统中的相关性。</li>
<li>results: 对于各种任务，包括填充、异常检测和分类，与基于Transformer的基本模型相比，具有相关注意机制的模型显示出了明显的优势，并在实验中取得了领先的 результаados。<details>
<summary>Abstract</summary>
Multivariate time series (MTS) analysis prevails in real-world applications such as finance, climate science and healthcare. The various self-attention mechanisms, the backbone of the state-of-the-art Transformer-based models, efficiently discover the temporal dependencies, yet cannot well capture the intricate cross-correlation between different features of MTS data, which inherently stems from complex dynamical systems in practice. To this end, we propose a novel correlated attention mechanism, which not only efficiently captures feature-wise dependencies, but can also be seamlessly integrated within the encoder blocks of existing well-known Transformers to gain efficiency improvement. In particular, correlated attention operates across feature channels to compute cross-covariance matrices between queries and keys with different lag values, and selectively aggregate representations at the sub-series level. This architecture facilitates automated discovery and representation learning of not only instantaneous but also lagged cross-correlations, while inherently capturing time series auto-correlation. When combined with prevalent Transformer baselines, correlated attention mechanism constitutes a better alternative for encoder-only architectures, which are suitable for a wide range of tasks including imputation, anomaly detection and classification. Extensive experiments on the aforementioned tasks consistently underscore the advantages of correlated attention mechanism in enhancing base Transformer models, and demonstrate our state-of-the-art results in imputation, anomaly detection and classification.
</details>
<details>
<summary>摘要</summary>
多变量时间序列（MTS）分析在现实应用中广泛存在，如金融、气候科学和医疗保健等领域。各种自我注意机制，现代Transformer模型的基础，能够高效发现时间相关性，但是无法好地捕捉MTS数据中不同特征之间的复杂相关性，这种相关性源于实际的复杂动态系统。为此，我们提出了一种新的相关注意机制，不仅可以高效捕捉特征wise相关性，还可以轻松地与现有的Transformer模型集成，以提高效率。具体来说，相关注意机制在特征通道之间计算特征Query和特征Key的差值 Matrix，并选择ively归一化特征表示。这种架构可以自动发现和学习特征wise相关性，以及延迟相关性，同时自然地捕捉时间序列自相关。当与常见Transformer基eline结合使用时，相关注意机制组成了更好的encoder-only架构，适用于许多任务，如缺失值估计、异常检测和分类。我们在这些任务上进行了广泛的实验，并 consistently demonstrates the advantages of our proposed mechanism in enhancing base Transformer models, and achieves state-of-the-art results in imputation, anomaly detection and classification.
</details></li>
</ul>
<hr>
<h2 id="FinanceBench-A-New-Benchmark-for-Financial-Question-Answering"><a href="#FinanceBench-A-New-Benchmark-for-Financial-Question-Answering" class="headerlink" title="FinanceBench: A New Benchmark for Financial Question Answering"></a>FinanceBench: A New Benchmark for Financial Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11944">http://arxiv.org/abs/2311.11944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, Bertie Vidgen</li>
<li>for: The paper is written to evaluate the performance of large language models (LLMs) on open book financial question answering (QA).</li>
<li>methods: The paper uses a test suite called FinanceBench, which consists of 10,231 questions about publicly traded companies, to evaluate the performance of 16 state-of-the-art LLM configurations. The authors manually review the answers to the questions (n&#x3D;2,400) and find that existing LLMs have clear limitations for financial QA.</li>
<li>results: The paper shows that existing LLMs have weaknesses such as hallucinations that limit their suitability for use by enterprises. Specifically, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions, and augmentation techniques such as using longer context windows to feed in relevant evidence improve performance but are unrealistic for enterprise settings due to increased latency.<details>
<summary>Abstract</summary>
FinanceBench is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). It comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FinanceBench are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FinanceBench, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance"><a href="#Ovarian-Cancer-Data-Analysis-using-Deep-Learning-A-Systematic-Review-from-the-Perspectives-of-Key-Features-of-Data-Analysis-and-AI-Assurance" class="headerlink" title="Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance"></a>Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11932">http://arxiv.org/abs/2311.11932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker</li>
<li>For: The paper is written to provide a systematic review of deep learning (DL)-driven ovarian cancer data analysis, specifically focusing on the key features and AI assurance (AIA) perspectives.* Methods: The study uses the PRISMA framework to conduct comprehensive searches in three journal databases, including only peer-reviewed studies published between 2015 and 2023.* Results: The review finds that most studies (71%) focus on detection and diagnosis, with a limited number of studies (33%) performing integrated analyses and only 8.3% validating their models using external and diverse data sets. Additionally, the inclusion of AIA in cancer data analysis is in a very early stage, with only 2.1% of the studies explicitly addressing explainability.Here’s the information in Simplified Chinese text:* For: 这篇论文是为了提供一种系统性的检查，以便了解抑血癌数据分析中使用深度学习（DL）的特点和人工智能保障（AIA）的视角。* Methods: 这篇论文使用PRISMA框架进行了三个期刊数据库的全面搜索，仅包括在2015年至2023年间发表的同行评审论文。* Results: 这篇论文发现，大多数研究（71%）是关于抑血癌检测和诊断，而很少有研究（33%）进行了集成分析，而且只有8.3%的研究使用了外部和多样化数据集进行验证。此外，抑血癌数据分析中的AIA还处于非常早期的阶段，只有2.1%的研究直接地考虑了解释性。<details>
<summary>Abstract</summary>
Background and objectives: By extracting this information, Machine or Deep Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and cancer researchers in discovering patterns and relationships from complex data sets. Many DL-based analyses on ovarian cancer (OC) data have recently been published. These analyses are highly diverse in various aspects of cancer (e.g., subdomain(s) and cancer type they address) and data analysis features. However, a comprehensive understanding of these analyses in terms of these features and AI assurance (AIA) is currently lacking. This systematic review aims to fill this gap by examining the existing literature and identifying important aspects of OC data analysis using DL, explicitly focusing on the key features and AI assurance perspectives. Methods: The PRISMA framework was used to conduct comprehensive searches in three journal databases. Only studies published between 2015 and 2023 in peer-reviewed journals were included in the analysis. Results: In the review, a total of 96 DL-driven analyses were examined. The findings reveal several important insights regarding DL-driven ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on detection and diagnosis, while no study addressed the prediction and prevention of OC. - The analyses were predominantly based on samples from a non-diverse population (75% (72/96 studies)), limited to a geographic location or country. - Only a small proportion of studies (only 33% (32/96)) performed integrated analyses, most of which used homogeneous data (clinical or omics). - Notably, a mere 8.3% (8/96) of the studies validated their models using external and diverse data sets, highlighting the need for enhanced model validation, and - The inclusion of AIA in cancer data analysis is in a very early stage; only 2.1% (2/96) explicitly addressed AIA through explainability.
</details>
<details>
<summary>摘要</summary>
背景和目标：通过提取这些信息，机器学习或深度学习（ML/DL）基于自动化数据分析工具可以帮助医生和癌症研究人员发现复杂数据集中的模式和关系。最近几年，在卵巢癌（OC）数据上进行了许多DL驱动的分析。这些分析方法非常多样化，包括不同的抑战域和癌症类型。但是，对这些分析方法的全面理解，特别是关键特征和人工智能确保（AI安全）的视角，目前缺乏一个系统性的回顾。这项系统性综述的目的是填补这一空白，通过检查现有文献，找到OC数据分析中DL驱动的重要方面和AI安全方面的关键特征。方法：根据PRISMA框架，在三个期刊库进行了全面的检索。只有2015年至2023年间在 peer-reviewed 期刊上发表的研究被包括在分析中。结果：在这些分析中，总共有96个DL驱动的分析被评估。结果显示，OC数据分析中DL驱动的一些重要发现：①大多数研究（71%，68/96）集中于检测和诊断，而没有一个研究关于预测和预防OC。②大多数分析（75%，72/96）基于非多样化的样本（75%，72/96），受限于特定的地理位置或国家。③只有一小部分研究（33%，32/96）进行了集成分析，大多数使用同种数据（临床或omiCS）。④备注的是，只有8.3%（8/96）的研究使用了外部和多样化的数据集进行验证，显示了模型验证的需求。⑤只有2.1%（2/96）的研究直接地考虑了AI安全，通过解释性来实现。
</details></li>
</ul>
<hr>
<h2 id="Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning"><a href="#Generalization-of-Fitness-Exercise-Recognition-from-Doppler-Measurements-by-Domain-adaption-and-Few-Shot-Learning" class="headerlink" title="Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning"></a>Generalization of Fitness Exercise Recognition from Doppler Measurements by Domain-adaption and Few-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11910">http://arxiv.org/abs/2311.11910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biying Fu, Naser Damer, Florian Kirchbuchner, Arjan Kuijper</li>
<li>for: 本研究旨在提高用于识别全身运动的移动应用程序的性能。</li>
<li>methods: 本研究使用了改进后的商业Off-the-shelf智能手机，以及基于ultrasound Doppler探测的方法。</li>
<li>results: 研究发现，通过使用小量适应数据来改进模型泛化性能，可以提高识别精度，比基eline高两至六倍。<details>
<summary>Abstract</summary>
In previous works, a mobile application was developed using an unmodified commercial off-the-shelf smartphone to recognize whole-body exercises. The working principle was based on the ultrasound Doppler sensing with the device built-in hardware. Applying such a lab-environment trained model on realistic application variations causes a significant drop in performance, and thus decimate its applicability. The reason of the reduced performance can be manifold. It could be induced by the user, environment, and device variations in realistic scenarios. Such scenarios are often more complex and diverse, which can be challenging to anticipate in the initial training data. To study and overcome this issue, this paper presents a database with controlled and uncontrolled subsets of fitness exercises. We propose two concepts to utilize small adaption data to successfully improve model generalization in an uncontrolled environment, increasing the recognition accuracy by two to six folds compared to the baseline for different users.
</details>
<details>
<summary>摘要</summary>
在前一些研究中，我们已经开发了一款基于商业市场上可获得的不改进的智能手机应用程序，用于识别全身运动。工作原理基于 Ultrasound Doppler 探测设备自带的硬件。在实际应用中，使用室内环境训练的模型对实际应用变化会导致性能下降，从而减少其实用性。这种下降的原因可能是用户、环境和设备变化的结合影响，这些变化在实际场景中是复杂多样的，难以预测在初始训练数据中。为了研究和解决这个问题，本文提出了一个包含控制和无控制subset的健身动作数据库。我们提出了两种概念，使用小数据适应来成功提高模型在无控制环境中的泛化性，对不同用户的识别精度提高2-6倍 compare to基准值。
</details></li>
</ul>
<hr>
<h2 id="Continual-Learning-Applications-and-the-Road-Forward"><a href="#Continual-Learning-Applications-and-the-Road-Forward" class="headerlink" title="Continual Learning: Applications and the Road Forward"></a>Continual Learning: Applications and the Road Forward</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11908">http://arxiv.org/abs/2311.11908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eli Verwimp, Shai Ben-David, Matthias Bethge, Andrea Cossu, Alexander Gepperth, Tyler L. Hayes, Eyke Hüllermeier, Christopher Kanan, Dhireesha Kudithipudi, Christoph H. Lampert, Martin Mundt, Razvan Pascanu, Adrian Popescu, Andreas S. Tolias, Joost van de Weijer, Bing Liu, Vincenzo Lomonaco, Tinne Tuytelaars, Gido M. van de Ven</li>
<li>for: 本文探讨了机器学习领域中的连续学习，并问道：为什么应该关注连续学习？作者通过对最新的连续学习论文进行抽样，发现了许多报告中的设置受到内存约束的限制。然后，作者讨论了五个开放问题，包括模型编辑、个性化、在设备上学习、快速（重）训练和奖励学习。作者表明，连续学习将是这些问题的一部分解决方案。</li>
<li>methods: 本文不提供实际方法，而是通过对现有研究进行抽样和讨论，探讨了连续学习的未来发展趋势和挑战。</li>
<li>results: 本文未提供实际结果，而是通过对现有研究进行抽样和讨论，探讨了连续学习的未来发展趋势和挑战。<details>
<summary>Abstract</summary>
Continual learning is a sub-field of machine learning, which aims to allow machine learning models to continuously learn on new data, by accumulating knowledge without forgetting what was learned in the past. In this work, we take a step back, and ask: "Why should one care about continual learning in the first place?". We set the stage by surveying recent continual learning papers published at three major machine learning conferences, and show that memory-constrained settings dominate the field. Then, we discuss five open problems in machine learning, and even though they seem unrelated to continual learning at first sight, we show that continual learning will inevitably be part of their solution. These problems are model-editing, personalization, on-device learning, faster (re-)training and reinforcement learning. Finally, by comparing the desiderata from these unsolved problems and the current assumptions in continual learning, we highlight and discuss four future directions for continual learning research. We hope that this work offers an interesting perspective on the future of continual learning, while displaying its potential value and the paths we have to pursue in order to make it successful. This work is the result of the many discussions the authors had at the Dagstuhl seminar on Deep Continual Learning, in March 2023.
</details>
<details>
<summary>摘要</summary>
（简体中文）continuous learning是机器学习的一个子领域，旨在让机器学习模型在新数据上不断学习，而不会忘记过去学习的知识。在这篇文章中，我们做了一个总结，并问：“为什么应该关注持续学习呢？”。我们在三个主要的机器学习会议上发表的最近的持续学习论文中进行了调查，发现内存限制是领域的主导。然后，我们讨论了五个机器学习中的开放问题，尽管这些问题初始看起来与持续学习没有直接关系，但我们表明持续学习是它们的解决方案的一部分。这些问题包括模型编辑、个性化、在设备上学习、更快的重新训练和奖励学习。最后，我们比较了这些未解决的问题的需求和当前持续学习中的假设，并讨论了四个未来持续学习研究的方向。我们希望这篇文章可以提供一个有趣的未来持续学习的视角，同时展示其潜在价值和我们需要追求的道路，以便它成功。这篇文章是在2023年3月的达斯图尔学术会议上的讨论的结果。
</details></li>
</ul>
<hr>
<h2 id="Towards-Exploratory-Reformulation-of-Constraint-Models"><a href="#Towards-Exploratory-Reformulation-of-Constraint-Models" class="headerlink" title="Towards Exploratory Reformulation of Constraint Models"></a>Towards Exploratory Reformulation of Constraint Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11868">http://arxiv.org/abs/2311.11868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ian Miguel, András Z. Salamon, Christopher Stone</li>
<li>for:  solves the problem of choosing the best model for a given problem class</li>
<li>methods:  uses a process of reformulation guided by performance on training instances</li>
<li>results:  explores the space of models to find the best one for the problem at hand<details>
<summary>Abstract</summary>
It is well established that formulating an effective constraint model of a problem of interest is crucial to the efficiency with which it can subsequently be solved. Following from the observation that it is difficult, if not impossible, to know a priori which of a set of candidate models will perform best in practice, we envisage a system that explores the space of models through a process of reformulation from an initial model, guided by performance on a set of training instances from the problem class under consideration. We plan to situate this system in a refinement-based approach, where a user writes a constraint specification describing a problem above the level of abstraction at which many modelling decisions are made. In this position paper we set out our plan for an exploratory reformulation system, and discuss progress made so far.
</details>
<details>
<summary>摘要</summary>
“已经有许多研究表明，实现问题的有效约束模型是解决问题的重要前提。由于不知道哪一个候选模型会在实际中表现最好，因此我们预见一个能够在模型的空间进行探索，并且受到问题类型的训练实例指导。我们打算将这个系统设计为一个修复基础的方法，让用户在高抽象层级上撰写约束规定，描述问题。在这个位置论文中，我们愿意说明我们的实验修复系统计划，并讨论到目前已经做出了多少进展。”Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections"><a href="#Analyzing-Emissions-and-Energy-Efficiency-in-Mixed-Traffic-Control-at-Unsignalized-Intersections" class="headerlink" title="Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections"></a>Analyzing Emissions and Energy Efficiency in Mixed Traffic Control at Unsignalized Intersections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11866">http://arxiv.org/abs/2311.11866</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Villarreal, Dawei Wang, Jia Pan, Weizi Li</li>
<li>For: 降低交通相关排放，减少交通堵塞和等待时间。* Methods: 使用混合交通控制策略， robot车（RV）在拥堵交叉口实施排气控制策略，提高沟通效率和减少排放。* Results: RVs 在至少10%的推动率下，可以降低燃料消耗和NOx排放，相比Signalized intersections下降低至27%和28%。同时，RVs 在至少30%的推动率下，可以降低CO和HC排放，相比Signalized intersections下降低至42%和43%。此外，RVs 可以降低整个网络的排放，只要在交叉口使用其策略。<details>
<summary>Abstract</summary>
Greenhouse gas emissions have dramatically risen since the early 1900s with U.S. transportation generating 28% of the U.S' emissions. As such, there is interest in reducing transportation-related emissions. Specifically, sustainability research has sprouted around signalized intersections as intersections allow different streams of traffic to cross and change directions. Recent research has developed mixed traffic control eco-driving strategies at signalized intersections to decrease emissions. However, the inherent structure of a signalized intersection generates increased emissions by creating frequent acceleration/deceleration events, excessive idling from traffic congestion, and stop-and-go waves. Thus, we believe unsignalized intersections hold potential for further sustainability improvements. In this work, we provide an emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands where mixed traffic control strategies are employed by robot vehicles (RVs) to reduce waiting times and congestion. We find with at least 10% RV penetration rate, RVs generate less fuel consumption and NOx emissions than signalized intersections by up to 27% and 28%, respectively. With at least 30% RVs, CO and HC emissions are reduced by up to 42% and 43%, respectively. Additionally, RVs can reduce emissions across the whole network despite only employing their strategies at the intersections.
</details>
<details>
<summary>摘要</summary>
美国交通运输中气候排放量自20世纪初期以来呈指数增长趋势，美国交通运输占总排放量的28%。为了降低交通相关排放量，可持续发展研究在信号交叉口方面进行了广泛的研究。特别是在信号交叉口处，有许多可持续发展的混合交通控制策略得到了应用。然而，信号交叉口的本质结构会产生频繁加速/减速事件、交通堵塞导致的辅助机器过度停靠和停靠波。因此，我们认为不信号交叉口具有更好的可持续发展潜力。在这项工作中，我们对无信号交叉口进行了排放分析，使用机器人车（RV）实施混合交通控制策略，以降低等待时间和堵塞。我们发现，在至少10%的RV涵盖率下，RV会比信号交叉口减少燃料消耗和NOx排放达27%和28%，分别。在至少30%的RV涵盖率下，CO和HC排放量减少至42%和43%，分别。此外，RV可以在整个网络中减少排放，即使只在交叉口处应用其策略。
</details></li>
</ul>
<hr>
<h2 id="Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning"><a href="#Establishing-Central-Sensitization-Inventory-Cut-off-Values-in-patients-with-Chronic-Low-Back-Pain-by-Unsupervised-Machine-Learning" class="headerlink" title="Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning"></a>Establishing Central Sensitization Inventory Cut-off Values in patients with Chronic Low Back Pain by Unsupervised Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11862">http://arxiv.org/abs/2311.11862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xzheng93/csi_cutoff_establishment">https://github.com/xzheng93/csi_cutoff_establishment</a></li>
<li>paper_authors: Xiaoping Zheng, Claudine JC Lamoth, Hans Timmerman, Ebert Otten, Michiel F Reneman</li>
<li>For: 本研究旨在确定chronic low back pain (CLBP) patient中中枢敏感性（HACS）的分化点，考虑到痛情（如CLBP）和性别因素。* Methods: 研究使用无监督归类方法来自动发现HACS相关的模式，并评估了归类性能。接着，使用征 receive operator characteristic 分析来确定最佳分化点。* Results: 研究包括151名参与者，其中63名健康控制者和88名CLBP患者。层次归类方法获得最佳结果，将患者分为三个群：健康组、CLBP with low HACS level组和CLBP with high HACS level组。对于总体分化点，结果表明CLBP的最佳分化点为35。对于性别因素，女性的分化点为34，而男性的分化点为35。<details>
<summary>Abstract</summary>
Human Assumed Central Sensitization is involved in the development and maintenance of chronic low back pain (CLBP). The Central Sensitization Inventory (CSI) was developed to evaluate the presence of HACS, with a cut-off value of 40/100 based on patients with chronic pain. However, various factors including pain conditions (e.g., CLBP), and gender may influence this cut-off value. For chronic pain condition such as CLBP, unsupervised clustering approaches can take these factors into consideration and automatically learn the HACS-related patterns. Therefore, this study aimed to determine the cut-off values for a Dutch-speaking population with CLBP, considering the total group and stratified by gender based on unsupervised machine learning. In this study, questionnaire data covering pain, physical, and psychological aspects were collected from patients with CLBP and aged-matched pain-free adults (referred to as healthy controls, HC). Four clustering approaches were applied to identify HACS-related clusters based on the questionnaire data and gender. The clustering performance was assessed using internal and external indicators. Subsequently, receiver operating characteristic analysis was conducted on the best clustering results to determine the optimal cut-off values. The study included 151 subjects, consisting of 63 HCs and 88 patients with CLBP. Hierarchical clustering yielded the best results, identifying three clusters: healthy group, CLBP with low HACS level, and CLBP with high HACS level groups. Based on the low HACS levels group (including HC and CLBP with low HACS level) and high HACS level group, the cut-off value for the overall groups were 35, 34 for females, and 35 for. The findings suggest that the optimal cut-off values for CLBP is 35. The gender-related cut-off values should be interpreted with caution due to the unbalanced gender distribution in the sample.
</details>
<details>
<summary>摘要</summary>
人类假设中央敏感性（HACS）参与了慢性低脊梁痛（CLBP）的发展和维持。中央敏感性评价器（CSI）是用来评估HACS的存在，其分割值为40/100，基于患有慢性疼痛的患者。然而，不同的因素，包括疼痛情况（如CLBP）和性别可能影响这个分割值。为了慢性疼痛状况如CLBP，无监督聚类方法可以考虑这些因素并自动发现HACS相关的模式。因此，本研究的目的是确定慢性低脊梁痛患者的分割值，考虑总体群体和按性别分类。在本研究中，问卷调查评估疼痛、物理和心理方面，收集了患有CLBP的病人和年龄匹配的疼痛自适应者（HC）的数据。四种聚类方法被应用来确定HACS相关的聚类，以及性别基础的分割值。聚类性能被评估使用内部和外部指标。随后，基于最佳聚类结果，进行了征 Receiver Operating Characteristic（ROC）分析，以确定最佳分割值。研究包括151名参与者，其中63名HC和88名CLBP患者。幂等聚类方法得到最佳结果，并将患者分为三个群体：健康组、CLBP低HACS水平组和CLBP高HACS水平组。基于低HACS水平组（包括HC和CLBP低HACS水平）和高HACS水平组的分割值为35，34 для女性，和35。这些结果表明，CLBP的最佳分割值为35。性别基础的分割值应该被解释以及谨慎，由于样本中性别分布不均衡。
</details></li>
</ul>
<hr>
<h2 id="Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models"><a href="#Generating-Valid-and-Natural-Adversarial-Examples-with-Large-Language-Models" class="headerlink" title="Generating Valid and Natural Adversarial Examples with Large Language Models"></a>Generating Valid and Natural Adversarial Examples with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11861">http://arxiv.org/abs/2311.11861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zimu Wang, Wei Wang, Qi Chen, Qiufeng Wang, Anh Nguyen</li>
<li>for: 本研究旨在提出一种基于大语言模型（LLM）的语言processing（NLP）攻击模型，以提高攻击效果和自然性。</li>
<li>methods: 该模型采用两个阶段：首先，使用word importance ranking来找到最容易攻击的单词；然后，使用word synonym replacement来替换这些单词。</li>
<li>results: 对于Movie Review（MR）、IMDB和Yelp Review Polarity datasets，LLM-Attack模型比基eline adversarial attack模型表现出色，在人工和GPT-4评估中也具有显著的优势。模型可以生成自然和有效的攻击示例，保留 semantic meaning、grammaticality和人类隐身性。<details>
<summary>Abstract</summary>
Deep learning-based natural language processing (NLP) models, particularly pre-trained language models (PLMs), have been revealed to be vulnerable to adversarial attacks. However, the adversarial examples generated by many mainstream word-level adversarial attack models are neither valid nor natural, leading to the loss of semantic maintenance, grammaticality, and human imperceptibility. Based on the exceptional capacity of language understanding and generation of large language models (LLMs), we propose LLM-Attack, which aims at generating both valid and natural adversarial examples with LLMs. The method consists of two stages: word importance ranking (which searches for the most vulnerable words) and word synonym replacement (which substitutes them with their synonyms obtained from LLMs). Experimental results on the Movie Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline adversarial attack models illustrate the effectiveness of LLM-Attack, and it outperforms the baselines in human and GPT-4 evaluation by a significant margin. The model can generate adversarial examples that are typically valid and natural, with the preservation of semantic meaning, grammaticality, and human imperceptibility.
</details>
<details>
<summary>摘要</summary>
深度学习基本的自然语言处理（NLP）模型，特别是预训练语言模型（PLM），已经被发现容易受到攻击。然而，由多种主流单词级 adversarial attack 模型生成的攻击示例通常并不是有效的，会导致语义维护、 grammaticality 和人类隐蔽性的损失。基于大语言模型（LLM）的异常容量，我们提出了 LLM-Attack，该方法的目标是使用 LLM 生成有效和自然的攻击示例。该方法包括两个阶段：单词重要性排名（搜索最容易攻击的单词）和单词同义补充（使用 LLM 生成的单词同义词替换）。实验结果表明，LLM-Attack 在 MR、IMDB 和 Yelp Review Polarity 数据集上比基线攻击模型更有效，在人类和 GPT-4 评估中也以显著的差距超过了基eline。模型可以生成有效和自然的攻击示例，保留语义意义、 grammaticality 和人类隐蔽性。
</details></li>
</ul>
<hr>
<h2 id="Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms"><a href="#Kandinsky-Conformal-Prediction-Efficient-Calibration-of-Image-Segmentation-Algorithms" class="headerlink" title="Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms"></a>Kandinsky Conformal Prediction: Efficient Calibration of Image Segmentation Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11837">http://arxiv.org/abs/2311.11837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joren Brunekreef, Eric Marcus, Ray Sheombarsing, Jan-Jakob Sonke, Jonas Teuwen</li>
<li>for: 这个论文的目的是提出一种名为“卡任尼基 calibration”的新的核心点采样方法，用于在有限的数据情况下进行像素级准确性评估。</li>
<li>methods: 该方法使用自然图像的空间结构，同时对“相似”的像素进行准确性评估，从而更好地利用可用的数据进行准确性评估。</li>
<li>results: 实验表明，使用“卡任尼基 calibration”方法可以显著改善图像分割算法的覆盖率，并且与像素级和图像级准确性评估相比，该方法的覆盖率错误较低， indicating that the method is effective in low-data scenarios.<details>
<summary>Abstract</summary>
Image segmentation algorithms can be understood as a collection of pixel classifiers, for which the outcomes of nearby pixels are correlated. Classifier models can be calibrated using Inductive Conformal Prediction, but this requires holding back a sufficiently large calibration dataset for computing the distribution of non-conformity scores of the model's predictions. If one only requires only marginal calibration on the image level, this calibration set consists of all individual pixels in the images available for calibration. However, if the goal is to attain proper calibration for each individual pixel classifier, the calibration set consists of individual images. In a scenario where data are scarce (such as the medical domain), it may not always be possible to set aside sufficiently many images for this pixel-level calibration. The method we propose, dubbed ``Kandinsky calibration'', makes use of the spatial structure present in the distribution of natural images to simultaneously calibrate the classifiers of ``similar'' pixels. This can be seen as an intermediate approach between marginal (imagewise) and conditional (pixelwise) calibration, where non-conformity scores are aggregated over similar image regions, thereby making more efficient use of the images available for calibration. We run experiments on segmentation algorithms trained and calibrated on subsets of the public MS-COCO and Medical Decathlon datasets, demonstrating that Kandinsky calibration method can significantly improve the coverage. When compared to both pixelwise and imagewise calibration on little data, the Kandinsky method achieves much lower coverage errors, indicating the data efficiency of the Kandinsky calibration.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="System-2-Attention-is-something-you-might-need-too"><a href="#System-2-Attention-is-something-you-might-need-too" class="headerlink" title="System 2 Attention (is something you might need too)"></a>System 2 Attention (is something you might need too)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11829">http://arxiv.org/abs/2311.11829</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Jason Weston, Sainbayar Sukhbaatar</li>
<li>for: 提高 transformer 基于语言模型（LLM）中的软注意力，以减少在下一个 token 生成时 incorporate 不相关信息。</li>
<li>methods: 引入 System 2 Attention（S2A），利用 LLM 理解自然语言并遵循指令，决定要注意的内容。 S2A 首先重新生成输入Context，并在重新生成的 Context 上进行注意力。</li>
<li>results: S2A 在三种任务中（包括问答、数学问题和长文生成）表现出色，与标准注意力基于 LLM 相比，增加了事实和公正性，而减少了偏袋。<details>
<summary>Abstract</summary>
Soft attention in Transformer-based Large Language Models (LLMs) is susceptible to incorporating irrelevant information from the context into its latent representations, which adversely affects next token generations. To help rectify these issues, we introduce System 2 Attention (S2A), which leverages the ability of LLMs to reason in natural language and follow instructions in order to decide what to attend to. S2A regenerates the input context to only include the relevant portions, before attending to the regenerated context to elicit the final response. In experiments, S2A outperforms standard attention-based LLMs on three tasks containing opinion or irrelevant information, QA, math word problems and longform generation, where S2A increases factuality and objectivity, and decreases sycophancy.
</details>
<details>
<summary>摘要</summary>
含有强制注意力的转换器基于大语言模型（LLM）容易吸收上下文中不相关的信息，这会对下一个 Token 生成产生负面影响。为了解决这些问题，我们介绍 System 2 Attention（S2A），它利用 LLM 的自然语言理解能力和遵从指令来决定需要注意的内容。S2A 将输入上下文重新生成为只包含相关部分，然后对重新生成的上下文进行注意，以提取最终响应。在实验中，S2A 比标准注意力基于 LLM 高于三种任务中的 opinione 和 irrelevante 信息，包括问答、数学问题和长文生成，S2A 可以提高事实性和公正性，而减少偏袋性。
</details></li>
</ul>
<hr>
<h2 id="Graph-Variational-Embedding-Collaborative-Filtering"><a href="#Graph-Variational-Embedding-Collaborative-Filtering" class="headerlink" title="Graph Variational Embedding Collaborative Filtering"></a>Graph Variational Embedding Collaborative Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11824">http://arxiv.org/abs/2311.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Narges Sadat Fazeli Dehkordi, Hadi Zare, Parham Moradi, Mahdi Jalili</li>
<li>for: 提高用户体验，特别是在电商、音乐和搜索等领域的推荐系统。</li>
<li>methods: 使用图基方法，并采用自变量嵌入来改进Feature传播。</li>
<li>results: 在测试数据上达到13.78%的提升率，与传统方法相比有显著提高。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The customization of recommended content to users holds significant importance in enhancing user experiences across a wide spectrum of applications such as e-commerce, music, and shopping. Graph-based methods have achieved considerable performance by capturing user-item interactions. However, these methods tend to utilize randomly constructed embeddings in the dataset used for training the recommender, which lacks any user preferences. Here, we propose the concept of variational embeddings as a means of pre-training the recommender system to improve the feature propagation through the layers of graph convolutional networks (GCNs). The graph variational embedding collaborative filtering (GVECF) is introduced as a novel framework to incorporate representations learned through a variational graph auto-encoder which are embedded into a GCN-based collaborative filtering. This approach effectively transforms latent high-order user-item interactions into more trainable vectors, ultimately resulting in better performance in terms of recall and normalized discounted cumulative gain(NDCG) metrics. The experiments conducted on benchmark datasets demonstrate that our proposed method achieves up to 13.78% improvement in the recall over the test data.
</details>
<details>
<summary>摘要</summary>
“个性化内容推荐对用户体验产生重要影响，广泛应用于电商、音乐和购物等领域。图基方法在捕捉用户Item交互方面已经取得了显著的表现。然而，这些方法通常使用训练 dataset 中随机构建的嵌入，缺乏用户喜好。我们提出了变量嵌入的概念，以增强预训练推荐系统，从而改善层次 Graph Convolutional Networks (GCNs) 中的特征传播。我们提出了基于变量图自动编码器的图变量嵌入集成推荐(GVECF)方法，将 learned 的表示embedded 到 GCN-based 集成推荐中。这种方法可以将高级用户Item交互转换成更可训练的向量，最终导致推荐性能的提升，测试数据中的准确率提高了13.78%。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system"><a href="#Generalized-super-resolution-4D-Flow-MRI-–-using-ensemble-learning-to-extend-across-the-cardiovascular-system" class="headerlink" title="Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system"></a>Generalized super-resolution 4D Flow MRI – using ensemble learning to extend across the cardiovascular system</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11819">http://arxiv.org/abs/2311.11819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ericsson, Adam Hjalmarsson, Muhammad Usman Akbar, Edward Ferdian, Mia Bonini, Brandon Hardy, Jonas Schollenberger, Maria Aristova, Patrick Winter, Nicholas Burris, Alexander Fyrdahl, Andreas Sigfridsson, Susanne Schnell, C. Alberto Figueroa, David Nordsletten, Alistair A. Young, David Marlevi</li>
<li>for: This paper aims to improve the spatial resolution of 4D Flow MRI images, which is limited by image noise and spatial resolution, by incorporating trained super-resolution (SR) networks.</li>
<li>methods: The authors use a combination of heterogeneous training sets and dedicated ensemble learning to explore the generalizability of SR 4D Flow MRI. They generate synthetic training data across three disparate domains and evaluate the performance of varying convolutional base and ensemble learners.</li>
<li>results: The results show that both bagging and stacking ensembling enhance SR performance across domains, accurately predicting high-resolution velocities from low-resolution input data in-silico. The optimized networks also successfully recover native resolution velocities from downsampled in-vivo data, and show qualitative potential in generating denoised SR-images from clinical level input data.<details>
<summary>Abstract</summary>
4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive measurement technique capable of quantifying blood flow across the cardiovascular system. While practical use is limited by spatial resolution and image noise, incorporation of trained super-resolution (SR) networks has potential to enhance image quality post-scan. However, these efforts have predominantly been restricted to narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; a task aggravated by contrasting hemodynamic conditions apparent across the cardiovasculature. The aim of our study was to explore the generalizability of SR 4D Flow MRI using a combination of heterogeneous training sets and dedicated ensemble learning. With synthetic training data generated across three disparate domains (cardiac, aortic, cerebrovascular), varying convolutional base and ensemble learners were evaluated as a function of domain and architecture, quantifying performance on both in-silico and acquired in-vivo data from the same three domains. Results show that both bagging and stacking ensembling enhance SR performance across domains, accurately predicting high-resolution velocities from low-resolution input data in-silico. Likewise, optimized networks successfully recover native resolution velocities from downsampled in-vivo data, as well as show qualitative potential in generating denoised SR-images from clinical level input data. In conclusion, our work presents a viable approach for generalized SR 4D Flow MRI, with ensemble learning extending utility across various clinical areas of interest.
</details>
<details>
<summary>摘要</summary>
四维流体磁共振成像（4D Flow MRI）是一种无侵入的测量技术，可以量化心血管系统中血液流动的质量。 although practical applications are limited by spatial resolution and image noise, incorporating trained super-resolution (SR) networks has the potential to enhance image quality after scanning. However, these efforts have been mainly focused on narrowly defined cardiovascular domains, with limited exploration of how SR performance extends across the cardiovascular system; this task is further complicated by the contrasting hemodynamic conditions present across the cardiovasculature.我们的研究的目标是探索SR 4D Flow MRI的通用性，使用不同的域类和ensemble学习来评估SR性能的一致性。我们使用了synthetic数据生成器生成了三个不同的域类（心血管、血管和脑血管），并使用不同的卷积基和ensemble学习来评估SR性能。结果表明，使用bagging和stacking ensemble学习可以提高SR性能 across domains，从低分辨率输入数据中预测高分辨率速度值。此外，优化的网络还能够从下采样的实际数据中恢复原始分辨率的速度值，并且显示出了对临床数据进行整合的质量提升的可能性。因此，我们的研究提出了一种可行的通用SR 4D Flow MRI方法，通过ensemble学习来扩展到不同的临床领域。
</details></li>
</ul>
<hr>
<h2 id="Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding"><a href="#Improving-Real-Estate-Appraisal-with-POI-Integration-and-Areal-Embedding" class="headerlink" title="Improving Real Estate Appraisal with POI Integration and Areal Embedding"></a>Improving Real Estate Appraisal with POI Integration and Areal Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11812">http://arxiv.org/abs/2311.11812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumin Han, Youngjun Park, Sonia Sabir, Jisun An, Dongman Lee</li>
<li>for: 本研究的目的是解决现有房地产评估方法中的两个挑战，即点位 interess（POI）对房价的影响和空间理解。</li>
<li>methods: 本研究使用了一种改进的POI特征提取方法和基于区域嵌入的MASKED Multihead Attention-based Spatial Interpolation for House Price Prediction（AMMASI）模型，以提高房价预测的准确性。</li>
<li>results:  compared with现有的基线模型，本研究的AMMASI模型在房价预测中显示出了更高的准确性和可靠性，并且也提供了未来房地产评估方法的可能的优化方向。<details>
<summary>Abstract</summary>
Despite advancements in real estate appraisal methods, this study primarily focuses on two pivotal challenges. Firstly, we explore the often-underestimated impact of Points of Interest (POI) on property values, emphasizing the necessity for a comprehensive, data-driven approach to feature selection. Secondly, we integrate road-network-based Areal Embedding to enhance spatial understanding for real estate appraisal. We first propose a revised method for POI feature extraction, and discuss the impact of each POI for house price appraisal. Then we present the Areal embedding-enabled Masked Multihead Attention-based Spatial Interpolation for House Price Prediction (AMMASI) model, an improvement upon the existing ASI model, which leverages masked multi-head attention on geographic neighbor houses and similar-featured houses. Our model outperforms current baselines and also offers promising avenues for future optimization in real estate appraisal methodologies.
</details>
<details>
<summary>摘要</summary>
尽管现有的房地产评估方法有所进步，这项研究主要关注两个重要挑战。首先，我们研究点位对房产价值的影响，并提出了一种全面、数据驱动的特征选择方法。其次，我们将路网基于的空间嵌入技术与房产评估相结合，以提高房产评估的空间理解。我们首先提出了一种改进的POI特征提取方法，然后介绍了每个POI对房价评估的影响。最后，我们提出了基于masked multihead attention的空间 interpolating模型（AMMASI），这是现有ASI模型的改进版本，可以更好地利用邻居和相似特征的房屋。我们的模型在现有基线上表现出色，并且也提供了未来房地产评估方法的有优点的可能性。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology"><a href="#Large-Language-Models-and-Explainable-Law-a-Hybrid-Methodology" class="headerlink" title="Large Language Models and Explainable Law: a Hybrid Methodology"></a>Large Language Models and Explainable Law: a Hybrid Methodology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11811">http://arxiv.org/abs/2311.11811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Billi, Alessandro Parenti, Giuseppe Pisano, Marco Sanchi</li>
<li>for: 提高法律系统的可访问性、使用性和解释性，以推进法律科技的民主和利益oriented视角。</li>
<li>methods: 使用自然语言处理技术和高级编程语言来翻译规则系统的解释，以便各种用户快速、清晰、可访问地与这些技术进行交互。</li>
<li>results: 通过自动化法律比较和解释，让非专业人士可以通过一系列提示来执行复杂的法律任务，并且可以在同一个事实情况下对不同的规则系统进行自主比较。<details>
<summary>Abstract</summary>
The paper advocates for LLMs to enhance the accessibility, usage and explainability of rule-based legal systems, contributing to a democratic and stakeholder-oriented view of legal technology. A methodology is developed to explore the potential use of LLMs for translating the explanations produced by rule-based systems, from high-level programming languages to natural language, allowing all users a fast, clear, and accessible interaction with such technologies. The study continues by building upon these explanations to empower laypeople with the ability to execute complex juridical tasks on their own, using a Chain of Prompts for the autonomous legal comparison of different rule-based inferences, applied to the same factual case.
</details>
<details>
<summary>摘要</summary>
文章强调使用LLM增强法律系统的可达性、使用度和解释性，帮助建立一种民主和利益相关的法律技术视角。文章提出了一种方法，以寻找使用LLM将高级编程语言中的解释翻译成自然语言，以便所有用户快速、明了、可访问地与这些技术交互。研究继续发展，基于这些解释，赋予非专业人士执行复杂的法律任务的能力，使用一串提示来自动比较不同的规则基于推理结果，应用到同一个实际案例中。
</details></li>
</ul>
<hr>
<h2 id="DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding"><a href="#DocPedia-Unleashing-the-Power-of-Large-Multimodal-Model-in-the-Frequency-Domain-for-Versatile-Document-Understanding" class="headerlink" title="DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding"></a>DocPedia: Unleashing the Power of Large Multimodal Model in the Frequency Domain for Versatile Document Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11810">http://arxiv.org/abs/2311.11810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Feng, Qi Liu, Hao Liu, Wengang Zhou, Houqiang Li, Can Huang</li>
<li>for:  DocPedia是一种大型多Modal模型（LMM），用于无需OCR的文档理解，可以处理高分辨率图像。</li>
<li>methods: DocPedia使用频域处理视觉输入，而不是像素空间处理，这使得它可以更好地捕捉视觉和文本信息。</li>
<li>results: 对多种文档类型进行了广泛的量化和质量测试，证明了 DocPedia 的高效性和超越性。<details>
<summary>Abstract</summary>
This work presents DocPedia, a novel large multimodal model (LMM) for versatile OCR-free document understanding, capable of parsing images up to 2,560$\times$2,560 resolution. Unlike existing work either struggle with high-resolution documents or give up the large language model thus vision or language ability constrained, our DocPedia directly processes visual input in the frequency domain rather than the pixel space. The unique characteristic enables DocPedia to capture a greater amount of visual and textual information using a limited number of visual tokens. To consistently enhance both perception and comprehension abilities of our model, we develop a dual-stage training strategy and enrich instructions/annotations of all training tasks covering multiple document types. Extensive quantitative and qualitative experiments conducted on various publicly available benchmarks confirm the mutual benefits of jointly learning perception and comprehension tasks. The results provide further evidence of the effectiveness and superior performance of our DocPedia over other methods.
</details>
<details>
<summary>摘要</summary>
Here's the Simplified Chinese translation:这个工作介绍了一种新的大型多模式模型（LMM），名为DocPedia，可以无需OCR进行文档理解，并且可以处理高分辨率图像（最大2560 x 2560）。与现有方法不同，DocPedia直接在频谱空间处理视觉输入，而不是像素空间。这种特点使得DocPedia可以更好地捕捉视觉和文本信息，使用有限的视觉token。为了进一步增强我们模型的感知和理解能力，我们开发了双阶段训练策略，并对所有训练任务进行了丰富的指导和注释。经验证明，我们的DocPedia在多种公开的benchmark上表现出色，证明了我们的方法的有效性和超越性。
</details></li>
</ul>
<hr>
<h2 id="Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens"><a href="#Age-Friendly-Route-Planner-Calculating-Comfortable-Routes-for-Senior-Citizens" class="headerlink" title="Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens"></a>Age-Friendly Route Planner: Calculating Comfortable Routes for Senior Citizens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11802">http://arxiv.org/abs/2311.11802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andoni Aranguren, Eneko Osaba, Silvia Urra-Uriarte, Patricia Molina-Costa</li>
<li>for: 提高城市老年人的生活体验</li>
<li>methods: 使用偏好基于路径和舒适元素的路径规划算法</li>
<li>results: 实现了基于年轻人的路径规划算法，并且可以帮助创建适应老年人的友好路径<details>
<summary>Abstract</summary>
The application of routing algorithms to real-world situations is a widely studied research topic. Despite this, routing algorithms and applications are usually developed for a general purpose, meaning that certain groups, such as ageing people, are often marginalized due to the broad approach of the designed algorithms. This situation may pose a problem in cities which are suffering a slow but progressive ageing of their populations. With this motivation in mind, this paper focuses on describing our implemented Age-Friendly Route Planner, whose goal is to improve the experience in the city for senior citizens. In order to measure the age-friendliness of a route, several variables have been deemed, such as the number of amenities along the route, the amount of comfortable elements found, or the avoidance of sloppy sections. In this paper, we describe one of the main features of the Age-Friendly Route Planner: the preference-based routes, and we also demonstrate how it can contribute to the creation of adapted friendly routes.
</details>
<details>
<summary>摘要</summary>
Application of routing algorithms to real-world situations is a widely studied research topic. However, these algorithms and applications are often developed for a general purpose, which can lead to marginalization of certain groups, such as the elderly, due to the broad approach of the designed algorithms. This situation can be particularly problematic in cities with aging populations. Motivated by this, this paper describes our implemented Age-Friendly Route Planner, which aims to improve the experience of senior citizens in the city. To measure the age-friendliness of a route, we have considered several variables, such as the number of amenities along the route, the presence of comfortable elements, and the avoidance of slippery sections. One of the main features of the Age-Friendly Route Planner is preference-based routes, which we will also demonstrate how it can contribute to the creation of adapted, friendly routes.
</details></li>
</ul>
<hr>
<h2 id="Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents"><a href="#Igniting-Language-Intelligence-The-Hitchhiker’s-Guide-From-Chain-of-Thought-Reasoning-to-Language-Agents" class="headerlink" title="Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents"></a>Igniting Language Intelligence: The Hitchhiker’s Guide From Chain-of-Thought Reasoning to Language Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11797">http://arxiv.org/abs/2311.11797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zoeyyao27/cot-igniting-agent">https://github.com/zoeyyao27/cot-igniting-agent</a></li>
<li>paper_authors: Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, Hai Zhao</li>
<li>for: 本研究旨在探讨链条理解（CoT）的应用在自主语言代理人方面，包括其效果、理论基础和潜在应用领域。</li>
<li>methods: 本研究采用了CoT技术，包括链条推理、中间步骤生成和解释性分析等方法，以探讨自主语言代理人的可行性和效果。</li>
<li>results: 研究发现CoT技术能够提高自主语言代理人的推理能力和可读性，并且可以应用于多种语言和任务上。此外，研究还发现CoT技术在自主语言代理人中的应用可以提高代理人的可控性和灵活性。<details>
<summary>Abstract</summary>
Large language models (LLMs) have dramatically enhanced the field of language intelligence, as demonstrably evidenced by their formidable empirical performance across a spectrum of complex reasoning tasks. Additionally, theoretical proofs have illuminated their emergent reasoning capabilities, providing a compelling showcase of their advanced cognitive abilities in linguistic contexts. Critical to their remarkable efficacy in handling complex reasoning tasks, LLMs leverage the intriguing chain-of-thought (CoT) reasoning techniques, obliging them to formulate intermediate steps en route to deriving an answer. The CoT reasoning approach has not only exhibited proficiency in amplifying reasoning performance but also in enhancing interpretability, controllability, and flexibility. In light of these merits, recent research endeavors have extended CoT reasoning methodologies to nurture the development of autonomous language agents, which adeptly adhere to language instructions and execute actions within varied environments. This survey paper orchestrates a thorough discourse, penetrating vital research dimensions, encompassing: (i) the foundational mechanics of CoT techniques, with a focus on elucidating the circumstances and justification behind its efficacy; (ii) the paradigm shift in CoT; and (iii) the burgeoning of language agents fortified by CoT approaches. Prospective research avenues envelop explorations into generalization, efficiency, customization, scaling, and safety. This paper caters to a wide audience, including beginners seeking comprehensive knowledge of CoT reasoning and language agents, as well as experienced researchers interested in foundational mechanics and engaging in cutting-edge discussions on these topics. A repository for the related papers is available at https://github.com/Zoeyyao27/CoT-Igniting-Agent.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经带来显著改善语言智能领域，证据在各种复杂推理任务上的杰出表现。另外，理论证据也显示了他们在语言上的高级推理能力，提供了语言智能领域的杰出表现。这些能力的关键是LLMs在解释过程中运用的连锁思维（CoT）推理技术，让它们在得出答案之前需要形成中间步骤。CoT推理方法不仅具有增强推理性能的功能，而且还有提高可读性、可控性和灵活性等优点。这些优点使研究人员对CoT推理方法进行扩展，以开发具有自主语言代理人的语言智能系统。这篇评论文探讨了这些研究方向，包括：（i）CoT技术的基础机制，专注于解释其效果的原因和情况；（ii）CoT推理方法的概念变革；以及（iii）由CoT方法推动的语言代理人的崛起。未来的研究方向包括探讨缩减、效率、自定义、扩展和安全等问题。这篇文章适合各种读者，包括对CoT推理和语言代理人有兴趣的初学者，以及有经验的研究人员，想要了解这些领域的基础机制和进行前沿探讨。相关文献可以在https://github.com/Zoeyyao27/CoT-Igniting-Agent上获得。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems"><a href="#Beyond-Boundaries-A-Comprehensive-Survey-of-Transferable-Attacks-on-AI-Systems" class="headerlink" title="Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems"></a>Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11796">http://arxiv.org/abs/2311.11796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangjing Wang, Ce Zhou, Yuanda Wang, Bocheng Chen, Hanqing Guo, Qiben Yan<br>for: This paper focuses on the threat of transferable attacks in various domains, including image, text, graph, audio, and video, and their impact on cyber-physical security.methods: The paper reviews and categorizes existing attacks from different viewpoints, including data, process, model, and system.results: The paper highlights the ubiquitous and pervasive nature of transferable attacks in different domains and outlines potential research directions to address these threats.<details>
<summary>Abstract</summary>
Artificial Intelligence (AI) systems such as autonomous vehicles, facial recognition, and speech recognition systems are increasingly integrated into our daily lives. However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks. In particular, numerous attacks are designed to target a particular model or system, yet their effects can spread to additional targets, referred to as transferable attacks. Although considerable efforts have been directed toward developing transferable attacks, a holistic understanding of the advancements in transferable attacks remains elusive. In this paper, we comprehensively explore learning-based attacks from the perspective of transferability, particularly within the context of cyber-physical security. We delve into different domains -- the image, text, graph, audio, and video domains -- to highlight the ubiquitous and pervasive nature of transferable attacks. This paper categorizes and reviews the architecture of existing attacks from various viewpoints: data, process, model, and system. We further examine the implications of transferable attacks in practical scenarios such as autonomous driving, speech recognition, and large language models (LLMs). Additionally, we outline the potential research directions to encourage efforts in exploring the landscape of transferable attacks. This survey offers a holistic understanding of the prevailing transferable attacks and their impacts across different domains.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Responsible-AI-Research-Needs-Impact-Statements-Too"><a href="#Responsible-AI-Research-Needs-Impact-Statements-Too" class="headerlink" title="Responsible AI Research Needs Impact Statements Too"></a>Responsible AI Research Needs Impact Statements Too</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11776">http://arxiv.org/abs/2311.11776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandra Olteanu, Michael Ekstrand, Carlos Castillo, Jina Suh</li>
<li>for: 这篇论文主要是为了探讨责任意增进人工智能（RAI）、道德AI和AI道德问题中的不良影响。</li>
<li>methods: 该论文使用了文献综述和理论分析的方法，探讨了不良影响的定义、类型和示例，以及对RAI、道德AI和AI道德的影响。</li>
<li>results: 该论文发现了许多不良影响的例子，包括负面影响、潜在的不公正和隐私问题等，并提出了一些遏制不良影响的建议和方法。<details>
<summary>Abstract</summary>
All types of research, development, and policy work can have unintended, adverse consequences - work in responsible artificial intelligence (RAI), ethical AI, or ethics in AI is no exception.
</details>
<details>
<summary>摘要</summary>
所有类型的研究、开发、政策工作都可能有意外、不良影响 - 负责任人工智能（RAI）、伦理AI或AI伦理工作也不例外。Here's a breakdown of the translation:* 所有类型 (all types) - 所有类型的研究、开发、政策工作 (all types of research, development, and policy work)* 都可能 (can) - 可能 (may)* 有意外 (unintended) - 意外 (unintended)* 不良影响 (adverse consequences) - 不良影响 (adverse consequences)* - 工作 (work)* 负责任人工智能 (RAI) - 负责任人工智能 (RAI)* 或 (or)* AI伦理工作 (ethical AI) - AI伦理工作 (ethics in AI)* 也不例外 (also not exceptional)
</details></li>
</ul>
<hr>
<h2 id="Intelligent-methods-for-business-rule-processing-State-of-the-art"><a href="#Intelligent-methods-for-business-rule-processing-State-of-the-art" class="headerlink" title="Intelligent methods for business rule processing: State-of-the-art"></a>Intelligent methods for business rule processing: State-of-the-art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11775">http://arxiv.org/abs/2311.11775</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cristiano André da Costa, Uélison Jean Lopes dos Santos, Eduardo Souza dos Reis, Rodolfo Stoffel Antunes, Henrique Chaves Pacheco, Thaynã da Silva França, Rodrigo da Rosa Righi, Jorge Luis Victória Barbosa, Franklin Jebadoss, Jorge Montalvao, Rogerio Kunkel</li>
<li>for: 本研究实际应用在企业规则处理方面，探讨最新的智能技术。</li>
<li>methods: 本研究使用了机器学习和其他智能方法进行探讨。</li>
<li>results: 研究发现了market的Top供应商和其主要解决方案。<details>
<summary>Abstract</summary>
In this article, we provide an overview of the latest intelligent techniques used for processing business rules. We have conducted a comprehensive survey of the relevant literature on robot process automation, with a specific focus on machine learning and other intelligent approaches. Additionally, we have examined the top vendors in the market and their leading solutions to tackle this issue.
</details>
<details>
<summary>摘要</summary>
在这篇文章中，我们提供了对最新的智能技术处理商业规则的概述。我们进行了全面的文献综述，专注于机器学习和其他智能方法。此外，我们还审查了市场上领先的供应商和他们的主要解决方案。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs"><a href="#Unveiling-the-Unseen-Potential-of-Graph-Learning-through-MLPs-Effective-Graph-Learners-Using-Propagation-Embracing-MLPs" class="headerlink" title="Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs"></a>Unveiling the Unseen Potential of Graph Learning through MLPs: Effective Graph Learners Using Propagation-Embracing MLPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11759">http://arxiv.org/abs/2311.11759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong-Min Shin, Won-Yong Shin</li>
<li>for: 本研究旨在利用多层感知器（MLP）解决 semi-supervised 节点分类问题，通过在知识储存（KD）过程中训练学生 MLP，从教师图 neural network（GNN）中学习。</li>
<li>methods: 我们提出了一种名为 Propagate &amp; Distill（P&amp;D）的方法，它将教师 GNN 的输出传播给学生 MLP，并可以解释为逆传播 $\Pi^{-1}$ 的一种近似过程。</li>
<li>results: 我们通过使用实际世界 benchmark 数据集进行了广泛的评估，并表明了 P&amp;D 方法可以提高学生 MLP 的性能。<details>
<summary>Abstract</summary>
Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semi-supervised node classification on graphs, by training a student MLP by knowledge distillation (KD) from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during KD, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. Although this can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing further performance boost of the student MLP.
</details>
<details>
<summary>摘要</summary>
Inspired by GNNs that separate feature transformation $T$ and propagation $\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\Pi$. This can be achieved by applying the inverse propagation $\Pi^{-1}$ before distillation from the teacher GNN, but this comes with a high computational cost from large matrix multiplications during training.To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing a further performance boost of the student MLP.
</details></li>
</ul>
<hr>
<h2 id="LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis"><a href="#LSTM-CNN-An-efficient-diagnostic-network-for-Parkinson’s-disease-utilizing-dynamic-handwriting-analysis" class="headerlink" title="LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis"></a>LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11756">http://arxiv.org/abs/2311.11756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Wang, Junqing Huang, Sven Nomm, Marianna Chatzakou, Kadri Medijainen, Aaro Toomela, Michael Ruzhansky<br>for: 这种研究的目的是用Dynamic Handwriting Analysis方法对parkinson病患者的手写能力进行诊断。methods: 该方法基于混合深度学习方法，包括LSTM和CNNs两种不同的深度学习模型。LSTM块用于提取时间变化特征，而CNNs块使用一维核函数进行低计算成本。此外，该方法还进行了ablation研究以提高性能。results: 该方法在我们新建的DraWritePD数据集上达到了96.2%的分类精度，并在PaHaW数据集上达到了90.7%的分类精度。此外，该方法还具有轻量级的参数量和快速的CPU执行速度。<details>
<summary>Abstract</summary>
Background and objectives: Dynamic handwriting analysis, due to its non-invasive and readily accessible nature, has recently emerged as a vital adjunctive method for the early diagnosis of Parkinson's disease. In this study, we design a compact and efficient network architecture to analyse the distinctive handwriting patterns of patients' dynamic handwriting signals, thereby providing an objective identification for the Parkinson's disease diagnosis.   Methods: The proposed network is based on a hybrid deep learning approach that fully leverages the advantages of both long short-term memory (LSTM) and convolutional neural networks (CNNs). Specifically, the LSTM block is adopted to extract the time-varying features, while the CNN-based block is implemented using one-dimensional convolution for low computational cost. Moreover, the hybrid model architecture is continuously refined under ablation studies for superior performance. Finally, we evaluate the proposed method with its generalization under a five-fold cross-validation, which validates its efficiency and robustness.   Results: The proposed network demonstrates its versatility by achieving impressive classification accuracies on both our new DraWritePD dataset ($96.2\%$) and the well-established PaHaW dataset ($90.7\%$). Moreover, the network architecture also stands out for its excellent lightweight design, occupying a mere $0.084$M of parameters, with a total of only $0.59$M floating-point operations. It also exhibits near real-time CPU inference performance, with inference times ranging from $0.106$ to $0.220$s.   Conclusions: We present a series of experiments with extensive analysis, which systematically demonstrate the effectiveness and efficiency of the proposed hybrid neural network in extracting distinctive handwriting patterns for precise diagnosis of Parkinson's disease.
</details>
<details>
<summary>摘要</summary>
背景和目标：动态手写分析因为非侵入性和ready accessible的特点，最近在诊断 Parkinson's disease 的早期阶段出现了非常有价值的辅助方法。在这种研究中，我们设计了一种具有高效率和紧凑的网络架构，以分析患者的动态手写信号中的特征特征，以提供对 Parkinson's disease 诊断的 объектив标识。方法：我们的方法基于一种混合深度学习方法，旨在挖掘患者的动态手写特征。具体来说，我们采用了LSTM块来提取时间变化特征，而CNN基于的块则是通过一维核函数进行低计算成本的实现。此外，我们还进行了缩进研究，以提高模型的性能。最后，我们使用五fold十分钟验证来评估我们的方法，并证明其高效和可靠。结果：我们的方法在我们新建的DraWritePD数据集上($96.2\%$)和已知的PaHaW数据集上($90.7\%$)都达到了非常出色的分类精度。此外，我们的网络架构还具有优秀的轻量级设计，占用仅 $0.084$M的参数，总共仅 $0.59$M的浮点运算。此外，我们的模型还展示了近实时的CPU执行速度，执行时间在 $0.106$ 到 $0.220$s之间。结论：我们通过了系列的实验和分析，证明了我们的混合神经网络在诊断 Parkinson's disease 的早期阶段中提取动态手写特征的效果和高效性。
</details></li>
</ul>
<hr>
<h2 id="A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection"><a href="#A-Large-Scale-Car-Parts-LSCP-Dataset-for-Lightweight-Fine-Grained-Detection" class="headerlink" title="A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection"></a>A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11754">http://arxiv.org/abs/2311.11754</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Jie, Zhong Yilin, Cao Qianqian</li>
<li>for: 本研究是为了弥补现有的自动驾驶系统和车辆分类任务中使用的汽车相关数据集的缺失，提供了一个大规模和细致的汽车AI数据集，用于检测12种不同的车部。</li>
<li>methods: 本研究提出了一种新的半监督自动标注方法，利用现有的预训练检测器来减轻人工标注的劳动ious burden。此外，我们也研究了黑洞均值网络（Grounding DINO）的零shot标注的局限性。</li>
<li>results: 我们通过使用一些轻量级的YOLO系列检测器进行细致的车部检测，证明了我们提出的数据集的有效性。<details>
<summary>Abstract</summary>
Automotive related datasets have previously been used for training autonomous driving systems or vehicle classification tasks. However, there is a lack of datasets in the field of automotive AI for car parts detection, and most available datasets are limited in size and scope, struggling to cover diverse scenarios. To address this gap, this paper presents a large-scale and fine-grained automotive dataset consisting of 84,162 images for detecting 12 different types of car parts. This dataset was collected from natural cameras and online websites which covers various car brands, scenarios, and shooting angles. To alleviate the burden of manual annotation, we propose a novel semi-supervised auto-labeling method that leverages state-of-the-art pre-trained detectors. Moreover, we study the limitations of the Grounding DINO approach for zero-shot labeling. Finally, we evaluate the effectiveness of our proposed dataset through fine-grained car parts detection by training several lightweight YOLO-series detectors.
</details>
<details>
<summary>摘要</summary>
《自动驾驶系统训练数据集》（Automotive related datasets）在过去已经用于训练自动驾驶系统或车辆类型标注任务。然而，在汽车AI领域中的车 spare parts检测数据集却缺乏，而且现有的数据集通常很小，缺乏多样化的场景覆盖。为解决这个空白，本文提出了一个大规模、细化的汽车数据集，包括12种不同的车 spare parts的84,162张图像。这个数据集来自于自然摄像头和网络上的图片，覆盖了多种汽车品牌、场景和拍摄角度。为了避免手动标注的劳动ious burden，我们提出了一种新的半监督自动标注方法，该方法利用了当前最佳的预训练检测器。此外，我们还研究了针对零shot标注的Grounding DINO方法的局限性。最后，我们通过使用一些轻量级的YOLO系列检测器进行细化的车 spare parts检测，证明了我们提posed的数据集的有效性。
</details></li>
</ul>
<hr>
<h2 id="Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking"><a href="#Sparse4D-v3-Advancing-End-to-End-3D-Detection-and-Tracking" class="headerlink" title="Sparse4D v3: Advancing End-to-End 3D Detection and Tracking"></a>Sparse4D v3: Advancing End-to-End 3D Detection and Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11722">http://arxiv.org/abs/2311.11722</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/linxuewu/sparse4d">https://github.com/linxuewu/sparse4d</a></li>
<li>paper_authors: Xuewu Lin, Zixiang Pei, Tianwei Lin, Lichao Huang, Zhizhong Su</li>
<li>for: This paper focuses on improving the detection and tracking performance of 3D objects in autonomous driving perception systems, building upon the Sparse4D framework.</li>
<li>methods: The authors introduce two auxiliary training tasks and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. They also extend the detector into a tracker using a straightforward approach that assigns instance ID during inference.</li>
<li>results: The proposed improvements achieve significant enhancements in detection performance, with ResNet50 as the backbone, witnessing enhancements of 3.0%, 2.2%, and 7.6% in mAP, NDS, and AMOTA, respectively. The best model achieved 71.9% NDS and 67.7% AMOTA on the nuScenes test set.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这篇论文将关注自动驾驶感知系统中3D对象检测和跟踪性能的提升，基于Sparse4D框架。</li>
<li>methods: 作者们引入了两个辅助训练任务（时间实例干扰和质量估计），并提出了分离注意力的方法，导致检测性能得到了显著提升。他们还将检测器转换成跟踪器，使用直观的方法，在推理过程中分配实例ID。</li>
<li>results: 提案的改进得到了显著的检测性能提升，使用ResNet50作为背景网络，观察到了3.0%、2.2%和7.6%的mAP、NDS和AMOTA提升，分别达到46.9%、56.1%和49.0%。最佳模型在nuScenes测试集上达到了71.9%的NDS和67.7%的AMOTA。代码将在\url{<a target="_blank" rel="noopener" href="https://github.com/linxuewu/Sparse4D%7D%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/linxuewu/Sparse4D}上发布。</a><details>
<summary>Abstract</summary>
In autonomous driving perception systems, 3D detection and tracking are the two fundamental tasks. This paper delves deeper into this field, building upon the Sparse4D framework. We introduce two auxiliary training tasks (Temporal Instance Denoising and Quality Estimation) and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. Additionally, we extend the detector into a tracker using a straightforward approach that assigns instance ID during inference, further highlighting the advantages of query-based algorithms. Extensive experiments conducted on the nuScenes benchmark validate the effectiveness of the proposed improvements. With ResNet50 as the backbone, we witnessed enhancements of 3.0\%, 2.2\%, and 7.6\% in mAP, NDS, and AMOTA, achieving 46.9\%, 56.1\%, and 49.0\%, respectively. Our best model achieved 71.9\% NDS and 67.7\% AMOTA on the nuScenes test set. Code will be released at \url{https://github.com/linxuewu/Sparse4D}.
</details>
<details>
<summary>摘要</summary>
自主驾驶感知系统中，3D探测和跟踪是两项基本任务。这篇论文在这个领域进行深入探索，基于Sparse4D框架。我们引入了两项辅助训练任务（时间实例噪声纠正和质量评估），并提出了分离注意力的方法，导致探测性能得到了显著提高。此外，我们扩展了探测器，使其在探测过程中分配实例ID，进一步展示了查询基本算法的优势。广泛的实验在nuScenes数据集上验证了我们的提案的有效性。使用ResNet50作为背景网络时，我们观察到了3.0\%、2.2\%和7.6\%的提高，达到了46.9\%、56.1\%和49.0\%的MAP、NDS和AMOTA。我们的最佳模型在nuScenes测试集上达到了71.9\%的NDS和67.7\%的AMOTA。代码将在\url{https://github.com/linxuewu/Sparse4D}上发布。
</details></li>
</ul>
<hr>
<h2 id="Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning"><a href="#Can-we-infer-the-presence-of-Differential-Privacy-in-Deep-Learning-models’-weights-Towards-more-secure-Deep-Learning" class="headerlink" title="Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning"></a>Can we infer the presence of Differential Privacy in Deep Learning models’ weights? Towards more secure Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11717">http://arxiv.org/abs/2311.11717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xehartnort/dp-from-weights">https://github.com/xehartnort/dp-from-weights</a></li>
<li>paper_authors: Jiménez-López, Daniel, Rodríguez-Barroso, Nuria, Luzón, M. Victoria, Herrera, Francisco</li>
<li>for: 保护数据和模型免受攻击，实现数据隐私。</li>
<li>methods: 使用Diffferentially Private Stochastic Gradient Descent（DP-SGD）来实现数据隐私。</li>
<li>results: 通过分析DL模型的 weights，可以判断DL模型是否在训练过程中使用了数据隐私。<details>
<summary>Abstract</summary>
Differential Privacy (DP) is a key property to protect data and models from integrity attacks. In the Deep Learning (DL) field, it is commonly implemented through the Differentially Private Stochastic Gradient Descent (DP-SGD). However, when a model is shared or released, there is no way to check whether it is differentially private, that is, it required to trust the model provider. This situation poses a problem when data privacy is mandatory, specially with current data regulations, as the presence of DP can not be certificated consistently by any third party. Thus, we face the challenge of determining whether a DL model has been trained with DP, according to the title question: Can we infer the presence of Differential Privacy in Deep Learning models' weights? Since the DP-SGD significantly changes the training process of a DL model, we hypothesize that DP leaves an imprint in the weights of a DL model, which can be used to predict whether a model has been trained with DP regardless of its architecture and the training dataset. In this paper, we propose to employ the imprint in model weights of using DP to infer the presence of DP training in a DL model. To substantiate our hypothesis, we developed an experimental methodology based on two datasets of weights of DL models, each with models with and without DP training and a meta-classifier to infer whether DP was used in the training process of a DL model, by accessing its weights. We accomplish both, the removal of the requirement of a trusted model provider and a strong foundation for this interesting line of research. Thus, our contribution is an additional layer of security on top of the strict private requirements of DP training in DL models, towards to DL models.
</details>
<details>
<summary>摘要</summary>
diferencial privacidad (DP) es una propiedad clave para proteger datos y modelos de ataques de integridad. En el campo de aprendizaje profundo (DL), se implementa comúnmente a través de el aprendizaje diferencial privado (DP-SGD). Sin embargo, cuando un modelo se comparte o se libera, no hay manera de verificar si ha sido entrenado con DP, lo que plantea un problema cuando la privacidad de datos es esencial, especialmente con las regulaciones actuales de datos. En este sentido, nos enfrentamos al desafío de determinar si un modelo de DL ha sido entrenado con DP, según la pregunta del título: ¿Podemos inferir la presencia de Privacidad Diferencial en los pesos de los modelos de aprendizaje profundo? Dado que el DP-SGD cambia significativamente el proceso de entrenamiento de un modelo de DL, hipotetizamos que la DP deja una huella en los pesos del modelo, lo que se puede utilizar para predecir si un modelo ha sido entrenado con DP, independientemente de su arquitectura y del conjunto de entrenamiento. En este artículo, propugnamos emplear la huella en los pesos del modelo para inferir la presencia de entrenamiento con DP en un modelo de DL. Para substanciar nuestra hipótesis, desarrollamos un método experimental basado en dos conjuntos de pesos de modelos de DL, cada uno con modelos entrenados con y sin DP, y un clasificador meta para inferir si se utilizó DP en el proceso de entrenamiento de un modelo de DL, accediendo a sus pesos. De esta manera, eliminamos la necesidad de confiar en el proveedor del modelo y establecemos una base sólida para esta línea de investigación interesante. Por lo tanto, nuestra contribución es una capa adicional de seguridad sobre la privacidad estricta de los modelos de DL entrenados con DP.
</details></li>
</ul>
<hr>
<h2 id="Control-in-Hybrid-Chatbots"><a href="#Control-in-Hybrid-Chatbots" class="headerlink" title="Control in Hybrid Chatbots"></a>Control in Hybrid Chatbots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11701">http://arxiv.org/abs/2311.11701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Thomas Rüdel, Jochen L. Leidner</li>
<li>for: 本研究旨在描述一个商业规则引擎和一个 интегразирован的神经语音助手的集成方式，以及这种集成方式对控制水平的影响。</li>
<li>methods: 本研究使用了商业规则引擎和大量预训练语言模型的集成方式，以实现更高的控制性和准确性。</li>
<li>results: 研究发现，通过合理的集成方式，可以实现更高的控制性和准确性，同时避免模型“幻觉”现象。<details>
<summary>Abstract</summary>
Customer data typically is held in database systems, which can be seen as rule-based knowledge base, whereas businesses increasingly want to benefit from the capabilities of large, pre-trained language models.   In this technical report, we describe a case study of how a commercial rule engine and an integrated neural chatbot may be integrated, and what level of control that particular integration mode leads to. We also discuss alternative ways (including past ways realized in other systems) how researchers strive to maintain control and avoid what has recently been called model "hallucination".
</details>
<details>
<summary>摘要</summary>
客户数据通常会被储存在数据库系统中，可以看作为规则式知识库。而企业则希望从大型预训语言模型中获益。在这份技术报告中，我们详细描述了一个商业规则引擎和一个集成的神经聊天机器人的integraion情况，以及该integraion模式带来的控制水平。我们还讨论了其他研究人员如何维持控制并避免最近被称为“模型幻视”的情况。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models"><a href="#Sparse-Low-rank-Adaptation-of-Pre-trained-Language-Models" class="headerlink" title="Sparse Low-rank Adaptation of Pre-trained Language Models"></a>Sparse Low-rank Adaptation of Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11696">http://arxiv.org/abs/2311.11696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsinghuac3i/sora">https://github.com/tsinghuac3i/sora</a></li>
<li>paper_authors: Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun</li>
<li>for: 这种研究旨在提高预训练的大语言模型的精度和效率，通过在批处理阶段进行精度补做和简化。</li>
<li>methods: 我们提出了一种扩展LoRA的方法，称为缺省低维化适应（SoRA），具有可动的内置维度，通过在训练阶段使用抑制器单元和距离梯度法来控制维度的占位。在推理阶段，我们可以将无效的参数块排除掉，使每个SoRA模块变为一个简洁又优化的LoRA模块。</li>
<li>results: 我们的实验结果表明，SoRA可以与其他基准值相比，即使保留70%的参数和训练时间，也可以达到更高的表现。此外，我们还提出了一种简化调度器，以便研究SoRA模块中参数的数量对模型的记忆和泛化的影响。<details>
<summary>Abstract</summary>
Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model's memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.
</details>
<details>
<summary>摘要</summary>
大量语言模型的精细调整已广泛研究，以提高效率和表现。LoRA（低级别适应）方法是一种受欢迎的方法，假设适应过程是低维度的。虽然LoRA已经显示出了良好的表现，但它使用固定和不可变的内在级别，这可能不总是最佳选择。为了更多的灵活性，我们扩展了LoRA的方法，提出了一种动态调整内在级别的方法，即干扰（SoRA）。我们在训练阶段通过使用逐步逼近法优化的门控单元，控制级别的卡通数，使得SoRA模块在执行阶段可以减少参数块。在执行阶段，我们可以根据门控单元的值来Zero出不必要的参数块，以降低SoRA模块的参数数量。我们的方法可以增强LoRA的表现力，同时fficiently控制参数数量，使得模型具有更好的泛化能力和记忆力。此外，我们还提出了一种缩短调整器来研究SoRA模块中参数的数量对模型的记忆和泛化的影响。我们的实验结果表明，SoRA可以在70% retained parameters和70% 的训练时间下超过其他基线。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Text-Retrieval-with-Progressive-Learning"><a href="#Towards-Robust-Text-Retrieval-with-Progressive-Learning" class="headerlink" title="Towards Robust Text Retrieval with Progressive Learning"></a>Towards Robust Text Retrieval with Progressive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11691">http://arxiv.org/abs/2311.11691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tong Wu, Yulei Qin, Enwei Zhang, Zihan Xu, Yuting Gao, Ke Li, Xing Sun</li>
<li>for: 提高大语言模型（LLM）的可靠性和准确性，使其能够更好地处理最新的和域специфи的信息。</li>
<li>methods: 提出了一种进展式学习的embeddings方法，通过增加训练集中负样本的数量和多样性，同时使用进程学习机制来动态调整模型对样本的注意力。</li>
<li>results: 在C-MTEB和DuReader等测试集上，PEG模型已经超过了现有的embeddings模型，在true positives retrieval方面表现出色，demonstrating its significant potential for applications in LLMs。<details>
<summary>Abstract</summary>
Retrieval augmentation has become an effective solution to empower large language models (LLMs) with external and verified knowledge sources from the database, which overcomes the limitations and hallucinations of LLMs in handling up-to-date and domain-specific information. However, existing embedding models for text retrieval usually have three non-negligible limitations. First, the number and diversity of samples in a batch are too restricted to supervise the modeling of textual nuances at scale. Second, the high proportional noise are detrimental to the semantic correctness and consistency of embeddings. Third, the equal treatment to easy and difficult samples would cause sub-optimum convergence of embeddings with poorer generalization. In this paper, we propose the PEG, a progressively learned embeddings for robust text retrieval. Specifically, we increase the training in-batch negative samples to 80,000, and for each query, we extracted five hard negatives. Concurrently, we incorporated a progressive learning mechanism, enabling the model to dynamically modulate its attention to the samples throughout the entire training process. Additionally, PEG is trained on more than 100 million data, encompassing a wide range of domains (e.g., finance, medicine, and tourism) and covering various tasks (e.g., question-answering, machine reading comprehension, and similarity matching). Extensive experiments conducted on C-MTEB and DuReader demonstrate that PEG surpasses state-of-the-art embeddings in retrieving true positives, highlighting its significant potential for applications in LLMs. Our model is publicly available at https://huggingface.co/TownsWu/PEG.
</details>
<details>
<summary>摘要</summary>
启发式增强技术已成为大语言模型（LLM）吸收外部验证知识源数据库的有效解决方案，超越LLM在处理最新和域 especific 信息方面的局限性和偏见。然而，现有的文本检索嵌入模型通常具有三种不可忽略的局限性。首先，批处理中样本数量和多样性过于限制，缺乏可以强制模型处理文本细节的规模。其次，高比例的噪音对文本嵌入的semantic正确性和一致性有害。第三，对于易训练和难训练样本的平等对待会导致嵌入的优化不佳，影响其泛化性。在这篇论文中，我们提出了PEG，一种可进步学习的文本检索嵌入。具体来说，我们增加了训练 batch 中负样本的数量到 80,000，并为每个查询提取五个困难的负样本。同时，我们 integrate了一种进程学习机制，让模型在整个训练过程中动态调整对样本的注意力。此外，PEG 在1000万个数据上进行了训练，覆盖了多个领域（如金融、医学和旅游）和多种任务（如问答、机器阅读理解和相似性匹配）。我们在 C-MTEB 和 DuReader 上进行了广泛的实验，得出PEG 可以高效地检索真正的积分， highlighting its significant potential for LLM applications。我们的模型可以在https://huggingface.co/TownsWu/PEG 上下载。
</details></li>
</ul>
<hr>
<h2 id="Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples"><a href="#Refactoring-Programs-Using-Large-Language-Models-with-Few-Shot-Examples" class="headerlink" title="Refactoring Programs Using Large Language Models with Few-Shot Examples"></a>Refactoring Programs Using Large Language Models with Few-Shot Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11690">http://arxiv.org/abs/2311.11690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsushi Shirafuji, Yusuke Oda, Jun Suzuki, Makoto Morishita, Yutaka Watanobe</li>
<li>for: 提高程式码维护和改进，并增加学习机会。</li>
<li>methods: 使用大型自然语言模型（LLM）GPT-3.5，提供更少的复杂程式码版本，以吸引开发者对程式码进行改进。</li>
<li>results: 根据实验结果，95.68%的程式码可以通过生成10个候选者进行 refactoring，实现了17.35%的减少Cyclomatic complexity和25.84%的减少行数。此外，质性评估显示出了优秀的程式码格式化能力，但也发现了一些不必要的行为，例如删除或转换注释。<details>
<summary>Abstract</summary>
A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Furthermore, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.
</details>
<details>
<summary>摘要</summary>
一个更简单和直观的程式是一个重要的因素，可以增加程式的维护和修改的容易度，并使写出的程式更加安全和无错。然而，由于它的严重工作负载和可能性的程式码 refactoring 会导致程式码中断，因此开发者们通常不愿意进行 refactoring。这会导致学习机会的损失。为了解决这个问题，我们示范了使用大型自然语言模型（LLM）GPT-3.5，以提出更简单的版本的使用者写的 Python 程式，以便鼓励用户学习写更好的程式。我们提出了一种方法，利用 LLM 的提示，选择适合每个目标程式设计问题的最佳代码 refactoring 示例，根据先前评估的提示一个例子。量化评估显示，95.68%的程式可以通过生成10个候选者，从而实现17.35%的均值周期复杂度和25.84%的均值行数下降。此外， качеitative评估显示了优秀的代码格式化能力，而不必要的行为，如删除或转换注解，也被观察到。
</details></li>
</ul>
<hr>
<h2 id="Causal-Structure-Learning-Supervised-by-Large-Language-Model"><a href="#Causal-Structure-Learning-Supervised-by-Large-Language-Model" class="headerlink" title="Causal Structure Learning Supervised by Large Language Model"></a>Causal Structure Learning Supervised by Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11689">http://arxiv.org/abs/2311.11689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tymadara/ils-csl">https://github.com/tymadara/ils-csl</a></li>
<li>paper_authors: Taiyu Ban, Lyuzhou Chen, Derui Lyu, Xiangyu Wang, Huanhuan Chen<br>for:This paper aims to enhance the efficiency and accuracy of causal structure learning (CSL) from observational data by integrating large language models (LLMs) with CSL.methods:The proposed method, ILS-CSL, iteratively incorporates LLM-based causal inference with CSL, leveraging feedback from LLMs to refine the causal DAG and generate more robust structural constraints.results:The proposed ILS-CSL method demonstrates superior performance in CSL efficacy, outperforming existing approaches on eight real-world datasets and setting a new standard in the field. The codes are available at \url{<a target="_blank" rel="noopener" href="https://github.com/tyMadara/ILS-CSL%7D">https://github.com/tyMadara/ILS-CSL}</a>.<details>
<summary>Abstract</summary>
Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details>
<details>
<summary>摘要</summary>
causal discovery from observational data 是很重要的，因为它可以帮助我们理解复杂的关系。 causal Structure Learning (CSL) 是一种 derivate  causal Directed Acyclic Graphs (DAGs) 的方法，但是它面临着庞大 DAG 空间和数据缺乏的挑战。 integrating Large Language Models (LLMs) ，Recognized for their causal reasoning capabilities，offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences。However，existing approaches using LLMs for CSL have encountered issues，including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses。In response，we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework。ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process，refining the causal DAG using feedback from LLMs。This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies。Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance，setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery。codes are available at \url{https://github.com/tyMadara/ILS-CSL}.
</details></li>
</ul>
<hr>
<h2 id="ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction"><a href="#ViP-Mixer-A-Convolutional-Mixer-for-Video-Prediction" class="headerlink" title="ViP-Mixer: A Convolutional Mixer for Video Prediction"></a>ViP-Mixer: A Convolutional Mixer for Video Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11683">http://arxiv.org/abs/2311.11683</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zheng, Ziang Peng, Yuan Cao, Hongming Shan, Junping Zhang</li>
<li>for: 预测未来帧数据，提高视频预测性能</li>
<li>methods: 使用卷积混合器（ViP-Mixer）模型视频 espacio-temporal 演化，并在层次结构中进行特征混合</li>
<li>results: 实验表明，提出的方法在三个标准视频数据集上达到了新的领先性能水平<details>
<summary>Abstract</summary>
Video prediction aims to predict future frames from a video's previous content. Existing methods mainly process video data where the time dimension mingles with the space and channel dimensions from three distinct angles: as a sequence of individual frames, as a 3D volume in spatiotemporal coordinates, or as a stacked image where frames are treated as separate channels. Most of them generally focus on one of these perspectives and may fail to fully exploit the relationships across different dimensions. To address this issue, this paper introduces a convolutional mixer for video prediction, termed ViP-Mixer, to model the spatiotemporal evolution in the latent space of an autoencoder. The ViP-Mixers are stacked sequentially and interleave feature mixing at three levels: frames, channels, and locations. Extensive experiments demonstrate that our proposed method achieves new state-of-the-art prediction performance on three benchmark video datasets covering both synthetic and real-world scenarios.
</details>
<details>
<summary>摘要</summary>
视频预测目标是预测视频的未来帧。现有方法主要处理视频数据，其时间维度杂mix WITH space和channel维度，从三个不同的角度来看：为一系列个帧、为3D维度坐标或为排列的图像，其中每帧都是不同的通道。大多数它们都很偏向一种视角，可能会不充分利用不同维度之间的关系。为解决这个问题，这篇论文提出了一种卷积混合器 для视频预测，称为ViP-Mixer，用于模型视频空间演化的秘密空间 autoencoder 中。ViP-Mixer 堆叠在一起，并在三级Feature混合：帧、通道和位置。广泛的实验表明，我们提出的方法可以达到新的状态纪录级别的预测性能，在三个标准视频数据集上，这些数据集包括 both synthetic 和实际场景。
</details></li>
</ul>
<hr>
<h2 id="MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features"><a href="#MGCT-Mutual-Guided-Cross-Modality-Transformer-for-Survival-Outcome-Prediction-using-Integrative-Histopathology-Genomic-Features" class="headerlink" title="MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features"></a>MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome Prediction using Integrative Histopathology-Genomic Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11659">http://arxiv.org/abs/2311.11659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingxin Liu, Yunzan Liu, Hui Cui, Chunquan Li, Jiquan Ma<br>for:* The paper is written to address the challenges of integrating whole slide images (WSIs) and genomic features for cancer prognosis in the rapidly emerging field of deep learning-based computational pathology.methods:* The proposed method, Mutual-Guided Cross-Modality Transformer (MGCT), is a weakly-supervised, attention-based multimodal learning framework that combines histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment.results:* The experimental results using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA) consistently show that MGCT outperforms the state-of-the-art (SOTA) methods.<details>
<summary>Abstract</summary>
The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000x150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods.
</details>
<details>
<summary>摘要</summary>
traditional Chinese:深度学习计算pathology领域的快速发展已经表现出了用整个染色体图像(WSIs)对肿瘤病人的诊断和预测的承诺。但是，现有的诊断方法大多限定于 Histopathology或 genomics alone，这会导致它们对病人诊断的准确性受到限制。而 integrating WSIs 和 genomic 特征会存在以下三个主要挑战：1. WSIs 的巨大多样性，可以达到 150,000 x 150,000 像素的大小;2. histopathology 图像和 genomic 分子数据之间缺乏空间相匹配关系;3. 现有的早期、晚期和中期多模式融合策略难以捕捉 WSIs 和 genomics 之间的显式交互。为了解决这些问题，我们提出了 Mutual-Guided Cross-Modality Transformer (MGCT)，一种弱监督的、注意力基于的多模式学习框架，可以将 histology 特征和 genomic 特征融合以模型肿瘤微环境中的 genotype-phenotype 交互。为验证 MGCT 的效果，我们在 The Cancer Genome Atlas (TCGA) 中获得了 nearly 3,600 个 gigapixel WSIs 的数据，并进行了广泛的实验。结果表明，MGCT 能够在不同的肿瘤类型上具有显著的优势。Simplified Chinese:深度学习计算pathology领域的快速发展已经表现出了用整个染色体图像(WSIs)对肿瘤病人的诊断和预测的承诺。但是，现有的诊断方法大多限定于 Histopathology或 genomics alone，这会导致它们对病人诊断的准确性受到限制。而 integrating WSIs 和 genomic 特征会存在以下三个主要挑战：1. WSIs 的巨大多样性，可以达到 150,000 x 150,000 像素的大小;2. histopathology 图像和 genomic 分子数据之间缺乏空间相匹配关系;3. 现有的早期、晚期和中期多模式融合策略难以捕捉 WSIs 和 genomics 之间的显式交互。为了解决这些问题，我们提出了 Mutual-Guided Cross-Modality Transformer (MGCT)，一种弱监督的、注意力基于的多模式学习框架，可以将 histology 特征和 genomic 特征融合以模型肿瘤微环境中的 genotype-phenotype 交互。为验证 MGCT 的效果，我们在 The Cancer Genome Atlas (TCGA) 中获得了 nearly 3,600 个 gigapixel WSIs 的数据，并进行了广泛的实验。结果表明，MGCT 能够在不同的肿瘤类型上具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System"><a href="#Peeking-Inside-the-Schufa-Blackbox-Explaining-the-German-Housing-Scoring-System" class="headerlink" title="Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System"></a>Peeking Inside the Schufa Blackbox: Explaining the German Housing Scoring System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11655">http://arxiv.org/abs/2311.11655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dean-Robin Kern, Gunnar Stevens, Erik Dethier, Sidra Naveed, Fatemeh Alizadeh, Delong Du, Md Shajalal</li>
<li>for: 这个论文主要是为了研究用户需要和预期的解释方面，以及如何通过域专的上下文来开发特定的解释方案。</li>
<li>methods: 这篇论文使用了探索设计方法，询问了业务信息学生对住房信用分数解释的用户界面设计。</li>
<li>results: 我们的初步发现结果表明，虽然有一些通用的需求，但也有因角色和实际情况而冲突的需求。我们的研究贡献了未来的人类中心XAI研究的未来研究方向。<details>
<summary>Abstract</summary>
Explainable Artificial Intelligence is a concept aimed at making complex algorithms transparent to users through a uniform solution. Researchers have highlighted the importance of integrating domain specific contexts to develop explanations tailored to end users. In this study, we focus on the Schufa housing scoring system in Germany and investigate how users information needs and expectations for explanations vary based on their roles. Using the speculative design approach, we asked business information students to imagine user interfaces that provide housing credit score explanations from the perspectives of both tenants and landlords. Our preliminary findings suggest that although there are general needs that apply to all users, there are also conflicting needs that depend on the practical realities of their roles and how credit scores affect them. We contribute to Human centered XAI research by proposing future research directions that examine users explanatory needs considering their roles and agencies.
</details>
<details>
<summary>摘要</summary>
人工智能可解释（Explainable Artificial Intelligence）是一种概念，旨在让复杂算法对用户透明度加以统一解释。研究人员强调了在发展专业背景下整合域务特定上下文来开发专门为用户开发解释的重要性。本研究将在德国的Schufa住房评分系统中进行调查，探讨用户信息需求和对解释的期望是否受到角色影响。我们使用探索设计方法，请商业信息学生想象提供住房信贷分数解释，从商业租赁者和房东的角度出发。我们的初步发现结果表明，尽管有一些通用的需求，但也有因角色实际情况而冲突的需求。我们对人类中心的XAI研究做出贡献，提出将用户解释需求与角色和机构进行研究的未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Web-News-Timeline-Generation-with-Extended-Task-Prompting"><a href="#Web-News-Timeline-Generation-with-Extended-Task-Prompting" class="headerlink" title="Web News Timeline Generation with Extended Task Prompting"></a>Web News Timeline Generation with Extended Task Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11652">http://arxiv.org/abs/2311.11652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sha Wang, Yuchen Li, Hanhua Xiao, Lambert Deng, Yanfei Dong</li>
<li>for: 新闻时间轴的创造对于全面和Contextual understanding of events over time是非常重要，帮助找到事件发展的趋势和关系，并理解新闻项目的更广泛意义。</li>
<li>methods: 我们使用了一种延展任务提示技术来评估过去新闻的相关性，并在不同的新闻数据集上进行了证明。</li>
<li>results: 我们发现，通过增强传统提示的扩展任务，可以提高LLMs的效果，使新闻时间轴生成成为专业使用的现实。这种技术已经被应用于一个公共可达扩展程序中，并在我们的网络中得到了推广使用。<details>
<summary>Abstract</summary>
The creation of news timeline is essential for a comprehensive and contextual understanding of events as they unfold over time. This approach aids in discerning patterns and trends that might be obscured when news is viewed in isolation. By organizing news in a chronological sequence, it becomes easier to track the development of stories, understand the interrelation of events, and grasp the broader implications of news items. This is particularly helpful in sectors like finance and insurance, where timely understanding of the event development-ranging from extreme weather to political upheavals and health crises-is indispensable for effective risk management. While traditional natural language processing (NLP) techniques have had some success, they often fail to capture the news with nuanced relevance that are readily apparent to domain experts, hindering broader industry integration. The advance of Large Language Models (LLMs) offers a renewed opportunity to tackle this challenge. However, direct prompting LLMs for this task is often ineffective. Our study investigates the application of an extended task prompting technique to assess past news relevance. We demonstrate that enhancing conventional prompts with additional tasks boosts their effectiveness on various news dataset, rendering news timeline generation practical for professional use. This work has been deployed as a publicly accessible browser extension which is adopted within our network.
</details>
<details>
<summary>摘要</summary>
新闻时间轴的创建是对事件的全面和Contextual comprehension具有重要意义，帮助发现事件发展的趋势和Patterns。通过将新闻按照时间顺序排序，可以较容易地跟踪事件的发展，理解事件之间的相互关系，并捕捉新闻项目的更大意义。特别在金融和保险领域，时间轴生成具有重要的实用意义，可以帮助管理风险。传统的自然语言处理（NLP）技术有一定的成功，但它们经常无法捕捉域专家所认为的新闻 relevance，这限制了业务的整合。大语言模型（LLMs）的进步提供了一个新的机会，以解决这个挑战。但直接对LLMs进行prompting是不够有效的。我们的研究发现，通过扩展任务提示技术，可以提高传统的提示效果，并在不同的新闻数据集上进行评估。我们的工作已经被部署为公共可访问的扩展，并在我们的网络中得到了采纳。
</details></li>
</ul>
<hr>
<h2 id="A-novel-transformer-based-approach-for-soil-temperature-prediction"><a href="#A-novel-transformer-based-approach-for-soil-temperature-prediction" class="headerlink" title="A novel transformer-based approach for soil temperature prediction"></a>A novel transformer-based approach for soil temperature prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11626">http://arxiv.org/abs/2311.11626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammet Mucahit Enes Yurtsever, Ayhan Kucukmanisa, Zeynep Hilal Kilimci</li>
<li>for: 这个研究旨在预测土壤温度，以便更好地理解高山冰川的能量、动力学、水文、生态稳定性等方面的过程。</li>
<li>methods: 本研究使用了变换器模型，这是首次应用变 transformation 模型预测土壤温度。试验使用了六个FLUXNET站，并模型了五种不同的变换器模型，即 Vanilla Transformer、Informer、Autoformer、Reformer 和 ETSformer。</li>
<li>results: 实验结果表明，通过使用变换器模型可以在预测土壤温度方面做出显著贡献，并超越深度学习方法和文献研究。这些结果表明，变换器模型在预测土壤温度方面具有重要的优势。<details>
<summary>Abstract</summary>
Soil temperature is one of the most significant parameters that plays a crucial role in glacier energy, dynamics of mass balance, processes of surface hydrological, coaction of glacier-atmosphere, nutrient cycling, ecological stability, the management of soil, water, and field crop. In this work, we introduce a novel approach using transformer models for the purpose of forecasting soil temperature prediction. To the best of our knowledge, the usage of transformer models in this work is the very first attempt to predict soil temperature. Experiments are carried out using six different FLUXNET stations by modeling them with five different transformer models, namely, Vanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To demonstrate the effectiveness of the proposed model, experiment results are compared with both deep learning approaches and literature studies. Experiment results show that the utilization of transformer models ensures a significant contribution to the literature, thence determining the new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
土壤温度是冰川能源中最重要的参数，对冰川动力、质量平衡、表面水文过程、冰川大气相互作用、营养循环和生态稳定性具有关键作用。在这项工作中，我们提出了一种新的方法，使用变换器模型进行土壤温度预测。据我们所知，这是首次使用变换器模型进行土壤温度预测。我们在六个FLUXNET站上进行了实验，使用五种不同的变换器模型，namely，Vanilla Transformer、Informer、Autoformer、Reformer和ETSformer。为证明提出的模型的效果，我们对深度学习方法和文献研究进行了比较。实验结果显示，使用变换器模型对 literature 做出了重要贡献，因此决定了新的州Of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks"><a href="#Taiyi-A-Bilingual-Fine-Tuned-Large-Language-Model-for-Diverse-Biomedical-Tasks" class="headerlink" title="Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks"></a>Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11608">http://arxiv.org/abs/2311.11608</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dutir-bionlp/taiyi-llm">https://github.com/dutir-bionlp/taiyi-llm</a></li>
<li>paper_authors: Ling Luo, Jinzhong Ning, Yingwen Zhao, Zhijun Wang, Zeyuan Ding, Peng Chen, Weiru Fu, Qinyu Han, Guangtao Xu, Yunzhi Qiu, Dinghao Pan, Jiru Li, Hao Li, Wenduo Feng, Senbo Tu, Yuqi Liu, Zhihao Yang, Jian Wang, Yuanyuan Sun, Hongfei Lin</li>
<li>for: 这个研究旨在测试一个适应多种生医自然语言处理任务的大型自然语言模型（LLM），并评估其在不同语言和任务上的效果。</li>
<li>methods: 研究使用了一个双语（英文和中文）精致化的LLM，并提出了一个两阶段的超级练习策略来优化模型在不同任务上的性能。</li>
<li>results: 实验结果显示，该模型在13个测试集上（包括命名实体识别、关系EXTRACTION、文本分类、问答任务）具有较高的性能，并且在额外的生医自然语言处理任务中也表现出了较好的多任务适应能力。<details>
<summary>Abstract</summary>
Recent advancements in large language models (LLMs) have shown promising results across a variety of natural language processing (NLP) tasks. The application of LLMs to specific domains, such as biomedicine, has achieved increased attention. However, most biomedical LLMs focus on enhancing performance in monolingual biomedical question answering and conversation tasks. To further investigate the effectiveness of the LLMs on diverse biomedical NLP tasks in different languages, we present Taiyi, a bilingual (English and Chinese) fine-tuned LLM for diverse biomedical tasks. In this work, we first curated a comprehensive collection of 140 existing biomedical text mining datasets across over 10 task types. Subsequently, a two-stage strategy is proposed for supervised fine-tuning to optimize the model performance across varied tasks. Experimental results on 13 test sets covering named entity recognition, relation extraction, text classification, question answering tasks demonstrate Taiyi achieves superior performance compared to general LLMs. The case study involving additional biomedical NLP tasks further shows Taiyi's considerable potential for bilingual biomedical multi-tasking. The source code, datasets, and model for Taiyi are freely available at https://github.com/DUTIR-BioNLP/Taiyi-LLM.
</details>
<details>
<summary>摘要</summary>
近期大语言模型（LLMs）的进步在自然语言处理（NLP）任务中表现出色，尤其是在生物医学领域。然而，大多数生物医学语言模型（biomedical LLMs）都是专注于提高单语言生物医学问答和对话任务的性能。为了进一步调查LLMs在不同语言和任务之间的效果，我们提出了 Taiyi，一个可以在英语和中文两种语言之间进行精细调整的大语言模型。在这项工作中，我们首先着手了140个现有的生物医学文本挖掘数据集，覆盖了多种任务类型。然后，我们提出了一种两阶段策略，通过精细调整来优化模型在不同任务之间的性能。实验结果表明，Taiyi在13个测试集上（包括命名实体识别、关系提取、文本分类、问答任务）表现出色，比普通的LLMs更高。此外，我们还进行了更多的生物医学NLP任务的案例研究，显示Taiyi在多任务多语言中的潜在能力很大。Taiyi的源代码、数据集和模型可以免费下载于https://github.com/DUTIR-BioNLP/Taiyi-LLM。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data"><a href="#Machine-learning-based-malware-detection-for-IoT-devices-using-control-flow-data" class="headerlink" title="Machine learning-based malware detection for IoT devices using control-flow data"></a>Machine learning-based malware detection for IoT devices using control-flow data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11605">http://arxiv.org/abs/2311.11605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Hevesi</li>
<li>for: 提高互联网物联网设备的安全性，防止黑客利用这些设备进行攻击和劫持。</li>
<li>methods: 使用机器学习算法和反编译工具对exe文件进行分析，从而检测到恶意软件。</li>
<li>results: 通过对ARM架构的应用程序进行分析，实现了基于控制流相关数据的恶意软件检测方法，并通过训练神经网络模型来实现恶意软件检测的高精度。<details>
<summary>Abstract</summary>
Embedded devices are specialised devices designed for one or only a few purposes. They are often part of a larger system, through wired or wireless connection. Those embedded devices that are connected to other computers or embedded systems through the Internet are called Internet of Things (IoT for short) devices.   With their widespread usage and their insufficient protection, these devices are increasingly becoming the target of malware attacks. Companies often cut corners to save manufacturing costs or misconfigure when producing these devices. This can be lack of software updates, ports left open or security defects by design. Although these devices may not be as powerful as a regular computer, their large number makes them suitable candidates for botnets. Other types of IoT devices can even cause health problems since there are even pacemakers connected to the Internet. This means, that without sufficient defence, even directed assaults are possible against people.   The goal of this thesis project is to provide better security for these devices with the help of machine learning algorithms and reverse engineering tools. Specifically, I study the applicability of control-flow related data of executables for malware detection. I present a malware detection method with two phases. The first phase extracts control-flow related data using static binary analysis. The second phase classifies binary executables as either malicious or benign using a neural network model. I train the model using a dataset of malicious and benign ARM applications.
</details>
<details>
<summary>摘要</summary>
“嵌入式设备是特殊设备，设计用途仅专注于一个或几个任务。它们通常是大型系统的一部分，通过网络或无线连接。当这些嵌入式设备与其他电脑或嵌入式系统通过互联网连接时，它们被称为互联网物件（IoT）设备。由于它们的广泛使用和不足的保护，这些设备在不断增长的Malware攻击中成为目标。公司通常为了降低生产成本或不当配置时，会导致这些设备缺乏软件更新、保持开启的 ports 或设计中的安全漏洞。虽然这些设备可能不如常规电脑强大，但由于它们的大量使用，它们成为了恶意软件的合适目标。甚至有些 IoT 设备可能导致健康问题，因为还有 pacemakers 连接到互联网。这意味着，如果没有足够的防护，甚至可能有对人的导向攻击。”“这个研究专案的目标是为这些设备提供更好的安全保障，使用机器学习算法和反向工程工具。具体来说，我研究适用于执行档控制流相关数据的恶意软件探测方法。我提出了一个具有两个阶段的恶意软件探测方法。第一阶段使用静态二进制分析方法提取控制流相关数据。第二阶段使用神经网模型将二进制档案分为伪阳性或伪阴性。我将模型训练使用 ARM 应用程序的增坏和恶意样本。”
</details></li>
</ul>
<hr>
<h2 id="A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow"><a href="#A-Multi-In-Single-Out-Network-for-Video-Frame-Interpolation-without-Optical-Flow" class="headerlink" title="A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow"></a>A Multi-In-Single-Out Network for Video Frame Interpolation without Optical Flow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11602">http://arxiv.org/abs/2311.11602</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/J911/MISO-VFI">https://github.com/J911/MISO-VFI</a></li>
<li>paper_authors: Jaemin Lee, Minseok Seo, Sangwoo Lee, Hyobin Park, Dong-Geol Choi</li>
<li>for: 这篇论文主要是为了提出一种基于多输入单输出（MISO）的视频帧 interpolate（VFI）方法，用于解决传统VFI方法中的 occlusion 和非线性运动问题。</li>
<li>methods: 我们的MISO-VFI方法不需要计算运动 вектор，可以更好地模型 occlusion 和非线性运动。我们还引入了一种新的运动感知损失，以便MISO-VFI更好地捕捉视频帧中的空间时间相关性。</li>
<li>results: 我们的MISO-VFI方法在 Vimeo90K、Middlebury 和 UCF101 等视频帧 interpolate 标准测试集上达到了状态方法的表现，与现有方法相比有 significante 性能差距。<details>
<summary>Abstract</summary>
In general, deep learning-based video frame interpolation (VFI) methods have predominantly focused on estimating motion vectors between two input frames and warping them to the target time. While this approach has shown impressive performance for linear motion between two input frames, it exhibits limitations when dealing with occlusions and nonlinear movements. Recently, generative models have been applied to VFI to address these issues. However, as VFI is not a task focused on generating plausible images, but rather on predicting accurate intermediate frames between two given frames, performance limitations still persist. In this paper, we propose a multi-in-single-out (MISO) based VFI method that does not rely on motion vector estimation, allowing it to effectively model occlusions and nonlinear motion. Additionally, we introduce a novel motion perceptual loss that enables MISO-VFI to better capture the spatio-temporal correlations within the video frames. Our MISO-VFI method achieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and UCF101, with a significant performance gap compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, which is the standard writing system used in mainland China. The translation is based on the official translation rules and conventions of the Chinese language.)
</details></li>
</ul>
<hr>
<h2 id="DesignGPT-Multi-Agent-Collaboration-in-Design"><a href="#DesignGPT-Multi-Agent-Collaboration-in-Design" class="headerlink" title="DesignGPT: Multi-Agent Collaboration in Design"></a>DesignGPT: Multi-Agent Collaboration in Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11591">http://arxiv.org/abs/2311.11591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu Qiu, Chunlei Chai</li>
<li>for: 这篇论文是为了探讨生成AI在产品设计过程中的应用，以及如何使用人工智能代理人来帮助设计师创新。</li>
<li>methods: 这篇论文使用了设计思维和设计过程来开发了多代理人协作框架DesignGPT，这个框架使用人工智能代理人模拟设计公司中不同角色的人员，并让设计师与他们进行自然语言的合作。</li>
<li>results: 实验结果显示，与单独的AI工具相比，DesignGPT可以提高设计师的表现，强调了应用多代理人系统在产品方案设计中的潜在应用。<details>
<summary>Abstract</summary>
Generative AI faces many challenges when entering the product design workflow, such as interface usability and interaction patterns. Therefore, based on design thinking and design process, we developed the DesignGPT multi-agent collaboration framework, which uses artificial intelligence agents to simulate the roles of different positions in the design company and allows human designers to collaborate with them in natural language. Experimental results show that compared with separate AI tools, DesignGPT improves the performance of designers, highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design.
</details>
<details>
<summary>摘要</summary>
<?xml:namespace prefix = "o" ns = "urn:schemas-microsoft-com:office:office" />生成AI在产品设计工作流中面临许多挑战，如界面使用性和交互模式。因此，基于设计思维和设计过程，我们开发了DesignGPT多代理协作框架，用人工智能代理模拟设计公司不同职位的角色，让人类设计师与其进行自然语言协作。实验结果显示，相比单独的AI工具，DesignGPT改善设计师的表现，highlighting the potential of applying multi-agent systems that integrate design domain knowledge to product scheme design。Here's the breakdown of the text into Simplified Chinese characters:生成AI (generated AI)产品设计 (product design)工作流 (workflow)面临 (face)许多挑战 (many challenges)界面使用性 (interface usability)交互模式 (interaction patterns)因此 (therefore)基于 (based on)设计思维 (design thinking)和 (and)设计过程 (design process)开发 (developed)DesignGPT (DesignGPT)多代理协作 (multi-agent collaboration)框架 (framework)用 (use)人工智能 (artificial intelligence)代理模拟 (proxy simulation)设计公司 (design company)不同职位 (different positions)角色 (roles)让 (allow)人类设计师 (human designers)与 (with)其 (it)进行 (to conduct)自然语言 (natural language)协作 (collaboration)实验结果 (experimental results)显示 (show)相比 (compared with)单独 (individually)AI工具 (AI tools)DesignGPT (DesignGPT)改善 (improve)设计师 (designers)表现 (performance)highlighting (highlighting)the potential (the potential)应用 (apply)多代理系统 (multi-agent systems) интегра (integrate)设计领域 (design domain)知识 (knowledge)产品方案 (product scheme)设计。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models"><a href="#Advancing-Urban-Renewal-An-Automated-Approach-to-Generating-Historical-Arcade-Facades-with-Stable-Diffusion-Models" class="headerlink" title="Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models"></a>Advancing Urban Renewal: An Automated Approach to Generating Historical Arcade Facades with Stable Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11590">http://arxiv.org/abs/2311.11590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheyuan Kuang, Jiaxin Zhang, Yiying Huang, Yunqin Li</li>
<li>for: 城市更新和转化过程中保护历史城市质量的重要性，特别是具有建筑和历史意义的区域。</li>
<li>methods: 我们的研究使用Stable Diffusion模型来自动生成历史风格的建筑立面图像，并使用文本描述来控制图像的风格特征。我们还使用了多个低级适应（LoRA）模型和控制网络（ControlNet）来提高图像的精度和 AUTHENTICITY。</li>
<li>results: 我们的方法能够生成高精度、AUTHENTICITY和多样性的图像，表明了在城市更新项目中的应用潜力。这种新的方法可以提供更有效率和准确的城市更新设计方案，并且可以减少传统设计过程中的细节不准确和风格多样性有限的问题。<details>
<summary>Abstract</summary>
Urban renewal and transformation processes necessitate the preservation of the historical urban fabric, particularly in districts known for their architectural and historical significance. These regions, with their diverse architectural styles, have traditionally required extensive preliminary research, often leading to subjective results. However, the advent of machine learning models has opened up new avenues for generating building facade images. Despite this, creating high-quality images for historical district renovations remains challenging, due to the complexity and diversity inherent in such districts. In response to these challenges, our study introduces a new methodology for automatically generating images of historical arcade facades, utilizing Stable Diffusion models conditioned on textual descriptions. By classifying and tagging a variety of arcade styles, we have constructed several realistic arcade facade image datasets. We trained multiple low-rank adaptation (LoRA) models to control the stylistic aspects of the generated images, supplemented by ControlNet models for improved precision and authenticity. Our approach has demonstrated high levels of precision, authenticity, and diversity in the generated images, showing promising potential for real-world urban renewal projects. This new methodology offers a more efficient and accurate alternative to conventional design processes in urban renewal, bypassing issues of unconvincing image details, lack of precision, and limited stylistic variety. Future research could focus on integrating this two-dimensional image generation with three-dimensional modeling techniques, providing a more comprehensive solution for renovating architectural facades in historical districts.
</details>
<details>
<summary>摘要</summary>
城市更新和转化过程中，保留历史城区的历史建筑遗产非常重要。这些区域具有多样化的建筑风格，过去经常需要详细的前期研究，并且结果往往是主观的。然而，机器学习模型的出现已经开辟了新的可能性，可以自动生成建筑立面图像。然而，为历史区域翻新而生成高质量图像仍然是一项挑战，因为这些区域的复杂性和多样性。为了解决这些挑战，我们的研究推出了一种新的方法，可以自动生成历史廊式建筑图像，使用稳定扩散模型，并且通过文本描述来控制图像的风格特征。我们分类和标注了多种廊式风格，并创建了许多真实的廊式建筑图像数据集。我们使用多个低级适应（LoRA）模型来控制生成图像的风格方面，并且使用控制网络（ControlNet）模型来提高图像的精度和准确性。我们的方法在生成图像时达到了高度的精度、准确性和多样性，显示出了在实际城市更新项目中的潜在潜力。这种新的方法可以更有效率地替代传统的城市更新设计过程，避免不真实的图像细节、缺乏精度和限制的风格多样性问题。未来的研究可以将这种二维图像生成技术与三维模型技术结合，为历史区域的建筑翻新提供更全面的解决方案。
</details></li>
</ul>
<hr>
<h2 id="Decoupled-DETR-For-Few-shot-Object-Detection"><a href="#Decoupled-DETR-For-Few-shot-Object-Detection" class="headerlink" title="Decoupled DETR For Few-shot Object Detection"></a>Decoupled DETR For Few-shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11570">http://arxiv.org/abs/2311.11570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeyu Shangguan, Lian Huai, Tong Liu, Xingqun Jiang</li>
<li>for: 提高ew-shot object detection（FSOD）的性能，解决数据繁殖问题。</li>
<li>methods: 提出基于DETR的base-novel categories decoupled DETR模型，并 explore skip connection between encoder and decoder，以及在decoder中动态 fusion intermediate layer的Output feature。</li>
<li>results: 在PASCAL VOC和MSCOCO等常用 datasets上评估，模型可以稳定提高5%-10%，并超越最近的最高得分。<details>
<summary>Abstract</summary>
Few-shot object detection (FSOD), an efficient method for addressing the severe data-hungry problem, has been extensively discussed. Current works have significantly advanced the problem in terms of model and data. However, the overall performance of most FSOD methods still does not fulfill the desired accuracy. In this paper we improve the FSOD model to address the severe issue of sample imbalance and weak feature propagation. To alleviate modeling bias from data-sufficient base classes, we examine the effect of decoupling the parameters for classes with sufficient data and classes with few samples in various ways. We design a base-novel categories decoupled DETR (DeDETR) for FSOD. We also explore various types of skip connection between the encoder and decoder for DETR. Besides, we notice that the best outputs could come from the intermediate layer of the decoder instead of the last layer; therefore, we build a unified decoder module that could dynamically fuse the decoder layers as the output feature. We evaluate our model on commonly used datasets such as PASCAL VOC and MSCOCO. Our results indicate that our proposed module could achieve stable improvements of 5% to 10% in both fine-tuning and meta-learning paradigms and has outperformed the highest score in recent works.
</details>
<details>
<summary>摘要</summary>
《几个样本对象检测》（FSOD），一种高效的方法来解决数据充足的问题，已经广泛讨论。现有工作已经在模型和数据上做出了重要进步，但大多数FSOD方法的总性表现仍未达到所需的准确率。在这篇论文中，我们改进了FSOD模型，以解决数据不均衡和弱feature传递的严重问题。为了避免数据充足的基类模型偏见，我们研究了在不同方式下解couple类 Parameters的效果。我们设计了基-新类划分DETR（DeDETR）模型，并 explore了不同类型的跳跃连接 междуencoder和decoder。此外，我们注意到最佳输出可能来自解oder层的中间层而不是最后层，因此我们构建了一个可动 fusion decoder层的统一decoder模块。我们对常用的PASCAL VOC和MSCOCO数据集进行评估，结果显示，我们的模块在微调和元学习 paradigms中均可以稳定地提高5%-10%，并超过了最近的最高分。
</details></li>
</ul>
<hr>
<h2 id="Replay-enhanced-Continual-Reinforcement-Learning"><a href="#Replay-enhanced-Continual-Reinforcement-Learning" class="headerlink" title="Replay-enhanced Continual Reinforcement Learning"></a>Replay-enhanced Continual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11557">http://arxiv.org/abs/2311.11557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiantian Zhang, Kevin Zehua Shen, Zichuan Lin, Bo Yuan, Xueqian Wang, Xiu Li, Deheng Ye</li>
<li>for: 避免 continual reinforcement learning 中的严重遗传问题</li>
<li>methods: 使用 replay-enhanced 方法，包括 adaptive normalization 和 policy distillation</li>
<li>results: 在 Continual World  benchmark 上表现出色，比 purely perfect memory replay 更好，并与现有的 continual learning 方法相比具有相似或更好的全局性能<details>
<summary>Abstract</summary>
Replaying past experiences has proven to be a highly effective approach for averting catastrophic forgetting in supervised continual learning. However, some crucial factors are still largely ignored, making it vulnerable to serious failure, when used as a solution to forgetting in continual reinforcement learning, even in the context of perfect memory where all data of previous tasks are accessible in the current task. On the one hand, since most reinforcement learning algorithms are not invariant to the reward scale, the previously well-learned tasks (with high rewards) may appear to be more salient to the current learning process than the current task (with small initial rewards). This causes the agent to concentrate on those salient tasks at the expense of generality on the current task. On the other hand, offline learning on replayed tasks while learning a new task may induce a distributional shift between the dataset and the learned policy on old tasks, resulting in forgetting. In this paper, we introduce RECALL, a replay-enhanced method that greatly improves the plasticity of existing replay-based methods on new tasks while effectively avoiding the recurrence of catastrophic forgetting in continual reinforcement learning. RECALL leverages adaptive normalization on approximate targets and policy distillation on old tasks to enhance generality and stability, respectively. Extensive experiments on the Continual World benchmark show that RECALL performs significantly better than purely perfect memory replay, and achieves comparable or better overall performance against state-of-the-art continual learning methods.
</details>
<details>
<summary>摘要</summary>
重现过去的经验已被证明是预测灵活学习中避免灾难性忘记的高效方法。然而，一些关键因素仍然被忽视，使其在练习强化学习中具有潜在的失败隐患。其中一个原因是，大多数强化学习算法不具有奖励敏感性，因此以前的任务（高奖励）可能会在当前任务（初始奖励小）中显得更加吸引人。这会让代理人偏好以前任务，而忽略当前任务。另一方面，在重复任务时在学习新任务期间进行离线学习可能会导致扩散差分，从而导致忘记。在这篇论文中，我们介绍了RECALL方法，它可以在新任务上大幅提高现有重复方法的灵活性，而无需担忧灾难性忘记。RECALL通过adaptive normalization approximate target和policy distillation old task来增强通用性和稳定性。广泛的实验表明，RECALL在Continual World benchmark上表现出色，与纯粹的完美记忆重复相比，表现出色，并与当前领先的循环学习方法相当或更好。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics"><a href="#Exploring-Prompting-Large-Language-Models-as-Explainable-Metrics" class="headerlink" title="Exploring Prompting Large Language Models as Explainable Metrics"></a>Exploring Prompting Large Language Models as Explainable Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11552">http://arxiv.org/abs/2311.11552</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics">https://github.com/ghazaleh-mahmoodi/Prompting_LLMs_AS_Explainable_Metrics</a></li>
<li>paper_authors: Ghazaleh Mahmoudi</li>
<li>for: 本研究描述了我们在Eval4NLP 2023杯赛中提交的Prompting Large Language Models as Explainable Metrics Shared Task的实验报告。</li>
<li>methods: 我们提议了一种零样本提示基础策略来评估摘要任务中的语言模型（LLMs）。我们在实验中使用了少量和零量样本来评估LLMs的评估效果。</li>
<li>results: 实验结果显示，LLMs可以作为NLP领域中摘要任务的评估指标，特别是在少量和零量样本情况下。我们的最佳提供的提示得到了人工评估的0.477权重相关性在测试数据上。<details>
<summary>Abstract</summary>
This paper describes the IUST NLP Lab submission to the Prompting Large Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023 Workshop on Evaluation & Comparison of NLP Systems. We have proposed a zero-shot prompt-based strategy for explainable evaluation of the summarization task using Large Language Models (LLMs). The conducted experiments demonstrate the promising potential of LLMs as evaluation metrics in Natural Language Processing (NLP), particularly in the field of summarization. Both few-shot and zero-shot approaches are employed in these experiments. The performance of our best provided prompts achieved a Kendall correlation of 0.477 with human evaluations in the text summarization task on the test data. Code and results are publicly available on GitHub.
</details>
<details>
<summary>摘要</summary>
这篇论文描述了我们在Eval4NLP 2023工作坊上提交的Prompting Large Language Models as Explainable Metrics Shared Task的实验报告。我们提议了一种零批量基于提示的方法来评估摘要任务中的大自然语言模型（LLMs）。我们进行了实验，并证明了LLMs在自然语言处理（NLP）领域中的评估能力具有普遍的潜在性。我们在这些实验中使用了少量和零量的提示方法。我们的最佳提示的性能在文本摘要任务中的测试数据上达到了0.477的科尔 correlate的水平与人类评估。我们在GitHub上公开了代码和结果。
</details></li>
</ul>
<hr>
<h2 id="Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT"><a href="#Which-AI-Technique-Is-Better-to-Classify-Requirements-An-Experiment-with-SVM-LSTM-and-ChatGPT" class="headerlink" title="Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT"></a>Which AI Technique Is Better to Classify Requirements? An Experiment with SVM, LSTM, and ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11547">http://arxiv.org/abs/2311.11547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abdelkarim El-Hajjami, Nicolas Fafin, Camille Salinesi</li>
<li>For: This paper evaluates the performance of Large Language Models (LLMs) in requirements classification, specifically comparing them to traditional methods like Support Vector Machine (SVM) and Long Short-Term Memory (LSTM).* Methods: The paper uses five diverse datasets and conducts an extensive empirical evaluation of ChatGPT models in both zero-shot and few-shot settings.* Results: The paper finds that ChatGPT consistently outperforms LSTM and is more effective than SVM in classifying functional requirements, but SVM is better in classifying non-functional requirements. Additionally, the few-shot setting does not always lead to enhanced performance, and in most instances, it was found to be suboptimal.Here is the same information in Simplified Chinese text:* For: 这篇论文评估了Large Language Models（LLMs）在需求分类中的表现，比较它们与传统方法如支持向量机（SVM）和长期快速储存（LSTM）。* Methods: 该论文使用五个多样化的数据集，进行了广泛的empirical评估，包括零shot和几个shot设置。* Results: 论文发现，ChatGPT在需求分类中一直表现出优异，并且在功能需求（FR）中表现更好 than SVM，但是在非功能需求（NFR）中，SVM表现更好。此外，几个shot设置并不总是提高性能的，在大多数情况下，它是不 оптималь的。<details>
<summary>Abstract</summary>
Context and motivation: Recently, Large Language Models (LLMs) like ChatGPT have demonstrated remarkable proficiency in various Natural Language Processing (NLP) tasks. Their application in Requirements Engineering (RE), especially in requirements classification, has gained increasing interest. Question/problem: In our research, we conducted an extensive empirical evaluation of ChatGPT models including text-davinci-003, gpt-3.5-turbo, and gpt-4 in both zero-shot and few-shot settings for requirements classification. The question arises as to how these models compare to traditional classification methods, specifically Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). Principal ideas/results: Based on five diverse datasets, our results show that ChatGPT consistently outperforms LSTM, and while ChatGPT is more effective than SVM in classifying functional requirements (FR), SVM is better in classifying non-functional requirements (NFR). Our results also show that contrary to our expectations, the few-shot setting does not always lead to enhanced performance; in most instances, it was found to be suboptimal. Contribution: Our findings underscore the potential of LLMs in the RE domain, suggesting that they could play a pivotal role in future software engineering processes, particularly as tools to enhance requirements classification.
</details>
<details>
<summary>摘要</summary>
Context and motivation: 近些年来，大型自然语言模型（LLM）如ChatGPT在自然语言处理（NLP）任务中表现了惊人的能力。其应用于需求工程（RE）领域，特别是需求分类，已经引起了越来越多的兴趣。问题/问题：在我们的研究中，我们进行了广泛的empirical evaluation of ChatGPT模型，包括text-davinci-003、gpt-3.5-turbo和gpt-4等模型，在零shot和几shot设置下对需求进行分类。问题是，这些模型与传统的分类方法相比，如支持向量机（SVM）和长短期记忆（LSTM）是如何相对？主要想法/结果：根据五个多样化的数据集，我们的结果表明，ChatGPT在分类功能需求（FR）方面表现出了superior的性能，而与LSTM相比，ChatGPT在分类非功能需求（NFR）方面的性能也是比较出色。此外，我们的结果还显示，预期中，几shot设置并不总是能够提高性能，反之，大多数情况下发现它们是不 оптиimal的。贡献：我们的发现表明LLMs在RE领域中具有潜在的潜力，建议它们可能在未来的软件工程过程中扮演着关键的角色，特别是作为需求分类工具。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling"><a href="#Data-driven-project-planning-An-integrated-network-learning-and-constraint-relaxation-approach-in-favor-of-scheduling" class="headerlink" title="Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling"></a>Data-driven project planning: An integrated network learning and constraint relaxation approach in favor of scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11542">http://arxiv.org/abs/2311.11542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izack Cohen<br>for:这个论文主要是为了探讨数据驱动项目规划的方法和技术。methods:该论文提出了一种基于历史数据学习的项目网络，并通过发现项目时间约束的松弛来提高项目规划和调度的灵活性。此外，论文还提出了一种基于决策规则和循环路径的项目网络增强技术。results:通过使用两个实际项目数据集，论文表明了该方法可以为项目规划提供显著的灵活性（最多减少项目 kritical path 的26%），帮助决策者在数据支持下自动进行项目规划。<details>
<summary>Abstract</summary>
Our focus is on projects, i.e., business processes, which are emerging as the economic drivers of our times. Differently from day-to-day operational processes that do not require detailed planning, a project requires planning and resource-constrained scheduling for coordinating resources across sub- or related projects and organizations. A planner in charge of project planning has to select a set of activities to perform, determine their precedence constraints, and schedule them according to temporal project constraints. We suggest a data-driven project planning approach for classes of projects such as infrastructure building and information systems development projects. A project network is first learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for: 1) decoding a project variation such that it forms a new project plan, and 2) applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation. Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details>
<details>
<summary>摘要</summary>
First, a project network is learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for:1. Decoding a project variation to form a new project plan.2. Applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation.Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning.
</details></li>
</ul>
<hr>
<h2 id="A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure"><a href="#A-New-Approach-to-Intuitionistic-Fuzzy-Decision-Making-Based-on-Projection-Technology-and-Cosine-Similarity-Measure" class="headerlink" title="A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure"></a>A New Approach to Intuitionistic Fuzzy Decision Making Based on Projection Technology and Cosine Similarity Measure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11539">http://arxiv.org/abs/2311.11539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jing Yang, Wei Su</li>
<li>For: 本研究旨在开发一种基于投影技术和偏向相似度量的多属性决策方法和医疗诊断方法，用于处理INTUITIONISTIC FUZZY SETS(IFSs)中的不确定和不完整信息。* Methods: 本研究提出了一种基于投影技术和偏向相似度量的IFS Similarity Measure，它考虑了INTUITIONISTIC FUZZY SETS(IFSs)的方向和长度，从而更好地处理不确定和不完整的信息。* Results: 实验结果表明，提出的算法可以准确地确定优质方案，并且比存在的方法更有优势。在医疗诊断领域，该方法可以快速诊断疾病。此外，本方法可以扩展到其他INTERVAL-VALUED INTUITIONISTIC FUZZY SETS(IVIFSs)中。<details>
<summary>Abstract</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy number(IFN). Intuitionistic fuzzy set (IFS) plays an important role in dealing with un-certain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which con-siders the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented pa-per is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some exist-ing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In medical diagnosis area, it can be used to quickly diagnose disease. The proposed method enriches the exist-ing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets(IVIFSs) as well.
</details>
<details>
<summary>摘要</summary>
For a multi-attribute decision making (MADM) problem, the information of alternatives under different attributes is given in the form of intuitionistic fuzzy numbers (IFN). Intuitionistic fuzzy sets (IFS) play an important role in dealing with uncertain and incomplete information. The similarity measure of intuitionistic fuzzy sets (IFSs) has always been a research hotspot. A new similarity measure of IFSs based on the projection technology and cosine similarity measure, which considers the direction and length of IFSs at the same time, is first proposed in this paper. The objective of the presented paper is to develop a MADM method and medical diagnosis method under IFS using the projection technology and cosine similarity measure. Some examples are used to illustrate the comparison results of the proposed algorithm and some existing methods. The comparison result shows that the proposed algorithm is effective and can identify the optimal scheme accurately. In the medical diagnosis area, it can be used to quickly diagnose diseases. The proposed method enriches the existing similarity measure methods and it can be applied to not only IFSs, but also other interval-valued intuitionistic fuzzy sets (IVIFSs) as well.Note: Please note that the translation is in Simplified Chinese, and the word order and grammar may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs"><a href="#Assessing-Prompt-Injection-Risks-in-200-Custom-GPTs" class="headerlink" title="Assessing Prompt Injection Risks in 200+ Custom GPTs"></a>Assessing Prompt Injection Risks in 200+ Custom GPTs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11538">http://arxiv.org/abs/2311.11538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahao Yu, Yuhang Wu, Dong Shu, Mingyu Jin, Xinyu Xing</li>
<li>for: 这项研究的目的是阐述用户自定义GPT模型时存在的重要安全漏洞，以及这些漏洞的可能的缓解方法。</li>
<li>methods: 该研究使用了对超过200个用户定制GPT模型的测试，通过对这些模型发送敌意提示来检测和分析漏洞。</li>
<li>results: 研究发现，用户自定义GPT模型容易受到提示攻击，导致敏感信息泄露和文件访问等安全问题。这项研究提供了一种首次分析和评估漏洞缓解方法。<details>
<summary>Abstract</summary>
In the rapidly evolving landscape of artificial intelligence, ChatGPT has been widely used in various applications. The new feature: customization of ChatGPT models by users to cater to specific needs has opened new frontiers in AI utility. However, this study reveals a significant security vulnerability inherent in these user-customized GPTs: prompt injection attacks. Through comprehensive testing of over 200 user-designed GPT models via adversarial prompts, we demonstrate that these systems are susceptible to prompt injections. Through prompt injection, an adversary can not only extract the customized system prompts but also access the uploaded files. This paper provides a first-hand analysis of the prompt injection, alongside the evaluation of the possible mitigation of such attacks. Our findings underscore the urgent need for robust security frameworks in the design and deployment of customizable GPT models. The intent of this paper is to raise awareness and prompt action in the AI community, ensuring that the benefits of GPT customization do not come at the cost of compromised security and privacy.
</details>
<details>
<summary>摘要</summary>
在人工智能领域的快速发展中，ChatGPT已经广泛应用在各种应用程序中。新的特点：用户自定义ChatGPT模型以满足特定需求，开启了人工智能的新前iers。但是，这项研究发现了自定义GPT模型中的一定安全漏洞：提示插入攻击。通过对超过200个用户自定义GPT模型进行了对抗提示测试，我们证明了这些系统容易受到提示插入攻击。通过提示插入，恶意actor可以不仅提取自定义系统提示，还可以访问上传文件。本文提供了提示插入分析，以及可能的防范措施的评估。我们的发现强调了在设计和部署自定义GPT模型时需要建立 Robust安全框架，以确保人工智能的发展不会导致安全和隐私的泄露。本文的目的是提醒人工智能社区，以便通过加强安全框架，确保自定义GPT模型的利用不会伴随着安全和隐私的泄露。
</details></li>
</ul>
<hr>
<h2 id="ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning"><a href="#ADAPTER-RL-Adaptation-of-Any-Agent-using-Reinforcement-Learning" class="headerlink" title="ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning"></a>ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11537">http://arxiv.org/abs/2311.11537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhao Jin, Greg Slabaugh, Simon Lucas</li>
<li>for: 该论文旨在探讨游戏强化学习（Reinforcement Learning，RL） Agent 在培育环境外的挑战，包括适应性问题、迷失问题和样本不足问题。</li>
<li>methods: 该论文提出了一种新的适应策略，通过将适应器与强化学习环境结合起来，以提高基础代理的训练效率和性能。此外，该策略可以与预训练神经网络和规则引导代理结合使用，以整合人类专家知识。</li>
<li>results: 实验表明，该适应策略可以提高基础代理的性能，并且可以在各种不同的环境下进行适应。此外，该策略可以减少样本数量和训练时间，从而提高训练效率。<details>
<summary>Abstract</summary>
Deep Reinforcement Learning (DRL) agents frequently face challenges in adapting to tasks outside their training distribution, including issues with over-fitting, catastrophic forgetting and sample inefficiency. Although the application of adapters has proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper delves into the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and improvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy (RTS) game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.
</details>
<details>
<summary>摘要</summary>
深度强化学习（DRL）代理频繁面临外部任务适应性问题，包括适应过拟合、灾难性忘记和样本不足问题。虽然在超vision和自然语言处理等超话语言中应用适配器已经证明有效，但在DRL领域其潜力仍然尚未得到充分探索。本文介绍了在强化学习中适配器的集成，并提出了一种创新的适配策略，在nanoRTS环境中实验证明了基础代理的增强和训练效率的提高。我们的提议的通用方法不仅Compatible with预训练神经网络，还可以与规则型代理集成，为抽取人类专家知识提供了一种途径。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms"><a href="#Optimal-Hyperparameter-ε-for-Adaptive-Stochastic-Optimizers-through-Gradient-Histograms" class="headerlink" title="Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms"></a>Optimal Hyperparameter $ε$ for Adaptive Stochastic Optimizers through Gradient Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11532">http://arxiv.org/abs/2311.11532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gustavo Silva, Paul Rodriguez</li>
<li>for: This paper aims to improve the training of deep neural network models by analyzing and optimizing the hyperparameters of adaptive optimizers, specifically the safeguard factor $\epsilon$ and momentum factor $\beta$.</li>
<li>methods: The paper proposes a new framework based on gradient histograms to analyze and justify the optimal performance of adaptive optimizers, as well as a novel algorithm that automatically estimates the reduced and accurate search space for the safeguard hyperparameter $\epsilon$.</li>
<li>results: The proposed algorithm is able to accurately estimate the optimal value of $\epsilon$ and improve the performance of adaptive optimizers. The paper also provides a comprehensive analysis of the relationships and dependencies among hyperparameters in leading adaptive optimizers.<details>
<summary>Abstract</summary>
Optimizers are essential components for successfully training deep neural network models. In order to achieve the best performance from such models, designers need to carefully choose the optimizer hyperparameters. However, this can be a computationally expensive and time-consuming process. Although it is known that all optimizer hyperparameters must be tuned for maximum performance, there is still a lack of clarity regarding the individual influence of minor priority hyperparameters, including the safeguard factor $\epsilon$ and momentum factor $\beta$, in leading adaptive optimizers (specifically, those based on the Adam optimizers). In this manuscript, we introduce a new framework based on gradient histograms to analyze and justify important attributes of adaptive optimizers, such as their optimal performance and the relationships and dependencies among hyperparameters. Furthermore, we propose a novel gradient histogram-based algorithm that automatically estimates a reduced and accurate search space for the safeguard hyperparameter $\epsilon$, where the optimal value can be easily found.
</details>
<details>
<summary>摘要</summary>
优化器是深度神经网络训练的关键组件。为了 достичь最佳性能，设计者需要精心选择优化器超参数。然而，这可以是一个计算昂贵的和时间消耗的过程。虽然已知所有优化器超参数都需要调整以实现最佳性能，但还没有准确地了解小优化器超参数，包括安全因子$\epsilon$和抓取因子$\beta$在领先的自适应优化器中的影响。在这篇论文中，我们提出了一个基于梯度 histogram的新框架，用于分析和证明自适应优化器的优化性和超参数之间的关系和依赖关系。此外，我们还提议了一种基于梯度 histogram的新算法，可以自动估算并且精度地查找 $\epsilon$ 的最佳值。
</details></li>
</ul>
<hr>
<h2 id="GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection"><a href="#GPT-in-Data-Science-A-Practical-Exploration-of-Model-Selection" class="headerlink" title="GPT in Data Science: A Practical Exploration of Model Selection"></a>GPT in Data Science: A Practical Exploration of Model Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11516">http://arxiv.org/abs/2311.11516</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathalia Nascimento, Cristina Tavares, Paulo Alencar, Donald Cowan</li>
<li>for: 本研究旨在探讨大型自然语言模型（LLM）如何在数据管理和数据科学过程中发挥作用，以及这种 интеграción 的可靠性和决策方法。</li>
<li>methods: 本研究使用了变量模型来描述选择模型的因素，并使用了小型数据集来评估模型和实现采用的各种规则。</li>
<li>results: 研究发现，GPT-4 的模型选择方法具有一定的特点和假设，可以帮助数据科学家更好地选择合适的模型，并且可以提高模型的可读性和可理解性。<details>
<summary>Abstract</summary>
There is an increasing interest in leveraging Large Language Models (LLMs) for managing structured data and enhancing data science processes. Despite the potential benefits, this integration poses significant questions regarding their reliability and decision-making methodologies. It highlights the importance of various factors in the model selection process, including the nature of the data, problem type, performance metrics, computational resources, interpretability vs accuracy, assumptions about data, and ethical considerations. Our objective is to elucidate and express the factors and assumptions guiding GPT-4's model selection recommendations. We employ a variability model to depict these factors and use toy datasets to evaluate both the model and the implementation of the identified heuristics. By contrasting these outcomes with heuristics from other platforms, our aim is to determine the effectiveness and distinctiveness of GPT-4's methodology. This research is committed to advancing our comprehension of AI decision-making processes, especially in the realm of model selection within data science. Our efforts are directed towards creating AI systems that are more transparent and comprehensible, contributing to a more responsible and efficient practice in data science.
</details>
<details>
<summary>摘要</summary>
有越来越多的 интерес在使用大型自然语言模型（LLMs）来管理结构化数据和提高数据科学过程。尽管有这些潜在的利点，但这种整合也提出了许多关于其可靠性和决策过程的问题。这些问题包括数据的性质、问题的类型、性能指标、计算资源、解释性vs准确性、数据的假设以及伦理考虑因素。我们的目标是使用变量模型来描述这些因素，并使用小型数据集来评估模型和实现的标准操作。通过对这些结果与其他平台的启发进行比较，我们希望可以确定GPT-4的方法论的效果和特点。这项研究的目标是深入探索人工智能决策过程中的模型选择过程，特别是在数据科学领域。我们的努力是创造更透明和可解释的AI系统，以便更负责任地实践数据科学。
</details></li>
</ul>
<hr>
<h2 id="MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning"><a href="#MultiLoRA-Democratizing-LoRA-for-Better-Multi-Task-Learning" class="headerlink" title="MultiLoRA: Democratizing LoRA for Better Multi-Task Learning"></a>MultiLoRA: Democratizing LoRA for Better Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11501">http://arxiv.org/abs/2311.11501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Wang, Yu Lin, Xiaodong Zeng, Guannan Zhang</li>
<li>for: 这篇论文是为了提高 LoRA 模型在多任务场景中的适应性和性能而写的。</li>
<li>methods: 论文使用了 LoRA 模型，并通过缩放 LoRA 模块和修改初始化参数来减少顶层特征值的影响，以提高多任务适应性。</li>
<li>results: 与单个 LoRA 对照组比较，MultiLoRA 具有更好的多任务适应性和性能，只需增加 2.5% 的参数量。此外，对 MultiLoRA 的参数更新矩阵的分析表明，它具有更多的卷积特征值贡献。<details>
<summary>Abstract</summary>
LoRA achieves remarkable resource efficiency and comparable performance when adapting LLMs for specific tasks. Since ChatGPT demonstrated superior performance on various tasks, there has been a growing desire to adapt one model for all tasks. However, the explicit low-rank of LoRA limits the adaptation performance in complex multi-task scenarios. LoRA is dominated by a small number of top singular vectors while fine-tuning decomposes into a set of less important unitary transforms. In this paper, we propose MultiLoRA for better multi-task adaptation by reducing the dominance of top singular vectors observed in LoRA. MultiLoRA scales LoRA modules horizontally and change parameter initialization of adaptation matrices to reduce parameter dependency, thus yields more balanced unitary subspaces. We unprecedentedly construct specialized training data by mixing datasets of instruction follow, natural language understanding, world knowledge, to cover semantically and syntactically different samples. With only 2.5% of additional parameters, MultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple benchmarks and model scales. Further investigation into weight update matrices of MultiLoRA exhibits reduced dependency on top singular vectors and more democratic unitary transform contributions.
</details>
<details>
<summary>摘要</summary>
LoRA 实现了非常出色的资源效率和相对性能，当适应特定任务时。由于 ChatGPT 在多种任务上表现出色，因此有越来越多的欲适应一模型 для所有任务。然而，LoRA 的明确低级别限制了复杂多任务场景中的适应性能。LoRA 由一小数量的顶部射影 вектор控制，而 fine-tuning 分解为一组 less important 的射影变换。在这篇论文中，我们提议 MultiLoRA 来改善多任务适应性能。MultiLoRA 缩放 LoRA 模块水平，并改变适应矩阵的参数初始化，从而减少参数依赖性，因此生成更均衡的射影空间。我们在特定数据集上构建了专门的训练数据，混合了 instruction follow、自然语言理解、世界知识等数据集，以覆盖Semantic 和 Sintactic 不同的样本。尽管增加了 2.5% 的参数，MultiLoRA 仍然超越了单个 LoRA 对手和 fine-tuning 多个benchmark和模型缩放。进一步的调查表明，MultiLoRA 的Weight 更新矩阵中减少了顶部射影 vector 的依赖性，并且各个射影变换均有更大的贡献。
</details></li>
</ul>
<hr>
<h2 id="Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models"><a href="#Interpretability-in-Machine-Learning-on-the-Interplay-with-Explainability-Predictive-Performances-and-Models" class="headerlink" title="Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models"></a>Interpretability in Machine Learning: on the Interplay with Explainability, Predictive Performances and Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11491">http://arxiv.org/abs/2311.11491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Leblanc, Pascal Germain</li>
<li>for: 本文旨在清楚地解释机器学习领域中的可解释性概念，以帮助读者理解这个抽象概念，并且�challenge 一些关于可解释性的常见 misunderstanding。</li>
<li>methods: 本文使用了一种Position paper的形式，通过对机器学习中的重要概念进行分析和讨论，来帮助读者更深入地理解可解释性的关系。</li>
<li>results: 本文的结论是，可解释性和解释性不是可交换的概念，而且一个机器学习模型的可解释性不可能与它的预测性能直接相关。<details>
<summary>Abstract</summary>
Interpretability has recently gained attention in the field of machine learning, for it is crucial when it comes to high-stakes decisions or troubleshooting. This abstract concept is hard to grasp and has been associated, over time, with many labels and preconceived ideas. In this position paper, in order to clarify some misunderstandings regarding interpretability, we discuss its relationship with significant concepts in machine learning: explainability, predictive performances, and machine learning models. For instance, we challenge the idea that interpretability and explainability are substitutes to one another, or that a fixed degree of interpretability can be associated with a given machine learning model.
</details>
<details>
<summary>摘要</summary>
《 interpretability 在机器学习领域最近受到了关注，因为它在高风险决策或维护问题时是非常重要的。这个抽象的概念很难理解，并且在过去有很多标签和先入为主的想法。在这篇Position paper中，我们为了解决一些关于 interpretability 的误解，讨论了它与机器学习中重要的概念之间的关系，如 explainability、预测性能和机器学习模型。例如，我们挑战了认为 interpretability 和 explainability 是可交换的想法，或者一个固定的 interpretability 水平可以与某种机器学习模型相关联。》Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records"><a href="#A-Multi-Center-Study-on-the-Adaptability-of-a-Shared-Foundation-Model-for-Electronic-Health-Records" class="headerlink" title="A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records"></a>A Multi-Center Study on the Adaptability of a Shared Foundation Model for Electronic Health Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11483">http://arxiv.org/abs/2311.11483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Lawrence Guo, Jason Fries, Ethan Steinberg, Scott Lanyon Fleming, Keith Morse, Catherine Aftandilian, Jose Posada, Nigam Shah, Lillian Sung</li>
<li>for: 这个论文的目的是检验基础模型在不同医院中的适用性以及对本地任务的适应性。</li>
<li>methods: 这个论文使用了基础模型，并在不同医院的数据上进行了适应性测试。</li>
<li>results: 研究发现，通过继续预训基础模型在本地数据上，可以提高模型的性能，并且可以比基于所有数据进行本地训练的模型减少训练样本的百分比。<details>
<summary>Abstract</summary>
Foundation models hold promise for transforming AI in healthcare by providing modular components that are easily adaptable to downstream healthcare tasks, making AI development more scalable and cost-effective. Structured EHR foundation models, trained on coded medical records from millions of patients, demonstrated benefits including increased performance with fewer training labels, and improved robustness to distribution shifts. However, questions remain on the feasibility of sharing these models across different hospitals and their performance for local task adaptation. This multi-center study examined the adaptability of a recently released structured EHR foundation model ($FM_{SM}$), trained on longitudinal medical record data from 2.57M Stanford Medicine patients. Experiments were conducted using EHR data at The Hospital for Sick Children and MIMIC-IV. We assessed both adaptability via continued pretraining on local data, and task adaptability compared to baselines of training models from scratch at each site, including a local foundation model. We evaluated the performance of these models on 8 clinical prediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$ matched the performance of GBM models locally trained on all data while providing a 13% improvement in settings with few task-specific training labels. With continued pretraining on local data, label efficiency substantially improved, such that $FM_{SM}$ required fewer than 1% of training examples to match the fully trained GBM's performance. Continued pretraining was also 60 to 90% more sample-efficient than training local foundation models from scratch. Our findings show that adapting shared EHR foundation models across hospitals provides improved prediction performance at less cost, underscoring the utility of base foundation models as modular components to streamline the development of healthcare AI.
</details>
<details>
<summary>摘要</summary>
基础模型在医疗健康领域中的应用显示了承诺，它们可以提供可重用的组件，使AI开发更加扩展和成本效果。在结构化电子医疗记录（EHR）基础模型上，训练在CODED医疗记录数据上 millions of patients 的情况下，显示了几个优点，包括增加性能，采用 fewer training labels，和鲁棒性提升。然而，在不同医院共享这些模型的问题仍然存在。本多中心研究检查了一个最近发布的结构化EHR基础模型($FM_{SM}$) ，训练在斯坦福医学院的长期医疗记录数据上2.57M 个患者。实验使用了医疗记录数据在医疗儿童医院和MIMIC-IV上。我们评估了这些模型在8个临床预测任务上的适应性和任务适应性，并与基线模型从 scratch 训练在每个站点上进行比较。我们发现，在两个数据集上，通过继续预训 $FM_{SM}$ 可以与基线模型在本地训练所达到的性能匹配，并且提供了13%的提高。在具有少量任务特定训练标签的情况下，通过继续预训，标签效率显著提高，使 $FM_{SM}$ 需要 fewer than 1% of training examples 来匹配完全训练的 GBM 的性能。继续预训还比从 scratch 训练本地基础模型60%-90% 更sample-efficient。我们的发现表明，在医疗机构之间共享EHR基础模型可以提供改进的预测性能，并且可以降低成本，这些基础模型作为医疗AI开发的模块化组件，可以加速开发。
</details></li>
</ul>
<hr>
<h2 id="Meta-Prompting-for-AGI-Systems"><a href="#Meta-Prompting-for-AGI-Systems" class="headerlink" title="Meta Prompting for AGI Systems"></a>Meta Prompting for AGI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11482">http://arxiv.org/abs/2311.11482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meta-prompting/meta-prompting">https://github.com/meta-prompting/meta-prompting</a></li>
<li>paper_authors: Yifan Zhang</li>
<li>for: 本研究探讨了一种新型的大语言模型（LLM）、多Modal基础模型和人工智能系统的问题解决和数据解释方法——Meta Prompting。</li>
<li>methods: 本研究使用了类型理论和类型理论来强调信息结构和 syntax，提供了一种独特的框架，超越传统的内容重点方法。</li>
<li>results: 本研究展示了Meta Prompting在复杂逻辑问题解决方面的优势，能够将复杂问题分解成可管理的子问题，从而实现步骤化、详细的问题解决方式，提高了Token效率和对问题解决方案的公平比较。此外，本研究还推广了Meta Prompting到多Modal基础模型设置，实现了多种数据类型的集成，并处理了复杂多方面的数据。<details>
<summary>Abstract</summary>
This paper presents an in-depth exploration of Meta Prompting, a novel technique that revolutionizes the way large language models (LLMs), multi-modal foundation models, and AI systems approach problem-solving and data interpretation. Meta Prompting, rooted in type theory and category theory, prioritizes the structure and syntax of information, providing a unique framework that transcends traditional content-focused methods. We delve into the formal definitions of Meta Prompting, contrasting it with Few-Shot Prompting, and highlight its applicability and superiority in various AI applications.   Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. Here, we demonstrate how this technique adeptly breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method proves especially advantageous in terms of token efficiency and offering a fair comparison in problem-solving scenarios, standing out against few-shot example approaches.   Furthermore, the paper breaks new ground by extending Meta Prompting into multi-modal foundation model settings. This extension addresses the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting, highlighting both the challenges and the vast potential of this approach in handling complex, multi-faceted data (The code is available at https://github.com/meta-prompting/meta-prompting).
</details>
<details>
<summary>摘要</summary>
Key to this exploration is the expansion of Meta Prompting into the realm of complex reasoning. This technique breaks down intricate problems into manageable sub-problems, facilitating a step-by-step, detailed approach to problem-solving. This method is especially advantageous in terms of token efficiency and offers a fair comparison in problem-solving scenarios, standing out against few-shot example approaches.Furthermore, the paper extends Meta Prompting into multi-modal foundation model settings, addressing the integration of diverse data types, such as images, audio, and video, within the structured framework of Meta Prompting. This approach highlights the challenges and vast potential of handling complex, multi-faceted data. The code is available at https://github.com/meta-prompting/meta-prompting.Translation Notes:1. 大language model (LLMs) 翻译为 "大型语言模型"2. multi-modal foundation models 翻译为 "多Modal基础模型"3. Few-Shot Prompting 翻译为 "少数示例提示"4. Token efficiency 翻译为 "Token效率"5. problem-solving scenarios 翻译为 "问题解决场景"6.  multi-faceted data 翻译为 "多方面数据"
</details></li>
</ul>
<hr>
<h2 id="Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions"><a href="#Empowering-remittance-management-in-the-digitised-landscape-A-real-time-Data-Driven-Decision-Support-with-predictive-abilities-for-financial-transactions" class="headerlink" title="Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions"></a>Empowering remittance management in the digitised landscape: A real-time Data-Driven Decision Support with predictive abilities for financial transactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11476">http://arxiv.org/abs/2311.11476</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rashikala Weerawarna, Shah J Miah</li>
<li>for: 这项研究是为了探讨区块链技术在移动财务领域的应用和优势，并开发了一种数据驱动预测决策支持方法，以帮助管理层决策者在面对不确定的数字化领域中更好地管理移动财务公司。</li>
<li>methods: 该研究采用了理论生成的设计科学研究方法，通过分析交易大数据，发现了预测能力的emergence。该方法结合预测统计和机器学习，以实时监测移动财务，使管理层能够更好地 Address challenges in the uncertain digitized landscape of blockchain-oriented remittance companies。</li>
<li>results: 该研究不仅增强了移动财务领域的安全性，还为未来的预测决策支持解决方案 lay the foundation。此外，通过实施这种方法，生成了一些有价值的理论，扩展了设计科学研究的领域，并促进了在信息系统领域的理论发展。<details>
<summary>Abstract</summary>
The advent of Blockchain technology (BT) revolutionised the way remittance transactions are recorded. Banks and remittance organisations have shown a growing interest in exploring blockchain's potential advantages over traditional practices. This paper presents a data-driven predictive decision support approach as an innovative artefact designed for the blockchain-oriented remittance industry. Employing a theory-generating Design Science Research (DSR) approach, we have uncovered the emergence of predictive capabilities driven by transactional big data. The artefact integrates predictive analytics and Machine Learning (ML) to enable real-time remittance monitoring, empowering management decision-makers to address challenges in the uncertain digitised landscape of blockchain-oriented remittance companies. Bridging the gap between theory and practice, this research not only enhances the security of the remittance ecosystem but also lays the foundation for future predictive decision support solutions, extending the potential of predictive analytics to other domains. Additionally, the generated theory from the artifact's implementation enriches the DSR approach and fosters grounded and stakeholder theory development in the information systems domain.
</details>
<details>
<summary>摘要</summary>
随着区块链技术（BT）的出现，Remittance交易记录方式发生了革命性的变革。银行和投递机构对区块链的潜在优势表示了增加的兴趣。这篇论文介绍了一种基于区块链的数据驱动预测决策支持方法，作为区块链投递业的创新艺品。通过使用理论生成Design Science Research（DSR）方法，我们发现了基于交易大数据的预测能力的出现。该艺品集成预测分析和机器学习（ML），以实时监控投递，让管理决策者在区块链投递公司的不确定数字化景观中做出更加有力的决策。这项研究不仅提高了投递生态系统的安全性，还为未来的预测决策支持解决方案提供了基础，扩展了预测分析的潜在应用范围。此外，艺品实施中生成的理论不仅扩充了DSR方法，还激发了在信息系统领域的基准和参与者理论的发展。
</details></li>
</ul>
<hr>
<h2 id="CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection"><a href="#CSGNN-Conquering-Noisy-Node-labels-via-Dynamic-Class-wise-Selection" class="headerlink" title="CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection"></a>CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11473">http://arxiv.org/abs/2311.11473</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Li, Zhen Tan, Kai Shu, Zongsheng Cao, Yu Kong, Huan Liu</li>
<li>for: 本文旨在提出一种基于图 neural network 的选择算法，以适应图像数据中的分类异常和标签噪声问题。</li>
<li>methods: 本文提出了一种名为 CSGNN 的新方法，它使用邻居积分的秘密空间来适应不同类别的信任计算机。特别是，通过使用动态分类选择机制和邻居积分的清洁节点选择算法，CSGNN 可以避免全局阈值技术中的偏袋问题。</li>
<li>results: 经过广泛的实验，CSGNN 比前STATE-OF-THE-ART 方法更高效和更稳定。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have emerged as a powerful tool for representation learning on graphs, but they often suffer from overfitting and label noise issues, especially when the data is scarce or imbalanced. Different from the paradigm of previous methods that rely on single-node confidence, in this paper, we introduce a novel Class-wise Selection for Graph Neural Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to adaptively select reliable nodes across different classes. Specifically, 1) to tackle the class imbalance issue, we introduce a dynamic class-wise selection mechanism, leveraging the clustering technique to identify clean nodes based on the neighbor-aggregated confidences. In this way, our approach can avoid the pitfalls of biased sampling which is common with global threshold techniques. 2) To alleviate the problem of noisy labels, built on the concept of the memorization effect, CSGNN prioritizes learning from clean nodes before noisy ones, thereby iteratively enhancing model performance while mitigating label noise. Through extensive experiments, we demonstrate that CSGNN outperforms state-of-the-art methods in terms of both effectiveness and robustness.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 已经成为图像学习中的一种强大工具，但它们经常受到预测和标签噪声问题的影响，特别是当数据稀缺或不均衡时。与过去的方法不同，在这篇论文中，我们提出了一种新的类别选择方法 для GRAPH NEURAL NETWORKS，名为CSGNN，该方法使用邻居聚合的秘密空间来自适应性地选择可靠的节点。specifically，我们实现了以下两点：1. 解决类别不均衡问题，我们引入了动态类别选择机制，基于邻居聚合的信任程度来 indentify 干净的节点。这种方法可以避免全局阈值技术中的偏袋sampling问题。2. 为了缓解标签噪声问题，CSGNN 利用了记忆效应的概念，在干净的节点之前学习从噪声节点，从而逐步提高模型性能而减少标签噪声。通过广泛的实验，我们证明了CSGNN 在效果和稳定性两个方面都能够超越当前的状态态法。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.AI_2023_11_20/" data-id="clp89do9m007fi788d6ys25bf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.CL_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T11:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.CL_2023_11_20/">cs.CL - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="LQ-LoRA-Low-rank-Plus-Quantized-Matrix-Decomposition-for-Efficient-Language-Model-Finetuning"><a href="#LQ-LoRA-Low-rank-Plus-Quantized-Matrix-Decomposition-for-Efficient-Language-Model-Finetuning" class="headerlink" title="LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning"></a>LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12023">http://arxiv.org/abs/2311.12023</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanguo97/lq-lora">https://github.com/hanguo97/lq-lora</a></li>
<li>paper_authors: Han Guo, Philip Greengard, Eric P. Xing, Yoon Kim</li>
<li>for:  Memory-efficient adaptation of pretrained language models</li>
<li>methods:  Iterative algorithm for decomposing pretrained matrices into low-rank and quantized components, integer linear programming for dynamic configuration of quantization parameters, data-aware version of the algorithm using approximation of Fisher information matrix</li>
<li>results:  Outperforms strong baselines and enables more aggressive quantization, able to learn a 2.5-bit model that is competitive with a 4-bit model, and can be used for model compression with a 2.75-bit model that is competitive with the original model in full precision.Here’s the Chinese text in the format you requested:</li>
<li>for: 该文章提出了一种简单的方法来实现准确精炼的语言模型适应。</li>
<li>methods: 该方法使用迭代算法将预训练矩阵分解为精度高低维度组件和快速量化组件。在训练中，量化组件保持不变，只有低维度组件进行更新。文章还提出了一种基于 Fisher 信息矩阵的估计的数据意识版本，用于在矩阵分解中Weight reconstruction 目标。</li>
<li>results:  experiments 表明，该方法可以超越强基elines 和 GPTQ-LoRA 基elines，并且可以实现更加减少量化。例如，在 OpenAssistant 测试集上，LQ-LoRA 可以学习一个2.5位LLaMA-2 模型，与4位 QLoRA 基elines 相当。此外，当用于语言模型训练集时，LQ-LoRA 也可以用于模型压缩。在这种情况下，我们的2.75位LLaMA-2-70B 模型（其中2.85位平均包括低维度组件）与原始模型相当，需要27GB的GPU内存。<details>
<summary>Abstract</summary>
We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget. We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the reconstruction objective during matrix decomposition. Experiments on adapting RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and moreover enables more aggressive quantization. For example, on the OpenAssistant benchmark LQ-LoRA is able to learn a 2.5-bit LLaMA-2 model that is competitive with a model finetuned with 4-bit QLoRA. When finetuned on a language modeling calibration dataset, LQ-LoRA can also be used for model compression; in this setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) is competitive with the original model in full precision.
</details>
<details>
<summary>摘要</summary>
我们提出一种简单的方法用于快速适应预训练语言模型，该方法使用迭代算法将预训练矩阵 decomposed 成高精度低级分量和快速量化分量。在训练期间，量化分量保持不变，只有低级分量进行更新。我们提出一个整数线性程序表示 Quantization 分量，可以动态配置量化参数（例如，比特宽、块大小）给每个矩阵，以达到总目标内存预算。我们进一步探索使用投影函数来权重矩阵分解的数据意识版本，并在实验中表明这种方法可以超越强QLoRA和GPTQ-LoRA基elines，并且可以实现更加迅速的量化。例如，在 OpenAssistant benchmark 上，LQ-LoRA 可以学习一个 2.5 位 LLaMA-2 模型，与使用 4 位 QLoRA 基eline 学习的模型相当。当训练在语言模型调整数据集时，LQ-LoRA 还可以用于模型压缩；在这种设置下，我们的 2.75 位 LLaMA-2-70B 模型（其中 2.85 位在包括低级分量时）与原始模型相当，需要 27GB 的 GPU 内存。
</details></li>
</ul>
<hr>
<h2 id="GPT-4V-ision-for-Robotics-Multimodal-Task-Planning-from-Human-Demonstration"><a href="#GPT-4V-ision-for-Robotics-Multimodal-Task-Planning-from-Human-Demonstration" class="headerlink" title="GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration"></a>GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12015">http://arxiv.org/abs/2311.12015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi</li>
<li>For: This paper enhances a general-purpose Vision Language Model, GPT-4V(ision), to facilitate robotic manipulation by integrating observations of human actions.* Methods: The system analyzes videos of humans performing tasks and creates executable robot programs that incorporate affordance insights. The computation starts by analyzing the videos with GPT-4V to convert environmental and action details into text, followed by a GPT-4-empowered task planner. Vision systems then reanalyze the video with the task plan, using an open-vocabulary object detector to ground object names and detect the moment of grasping and releasing.* Results: Experiments across various scenarios demonstrate the method’s efficacy in achieving real robots’ operations from human demonstrations in a zero-shot manner.Here’s the Chinese translation of the three information points:* For: 这篇论文用GPT-4V(ision)扩展一个通用视力语言模型，以便机器人操作。* Methods: 该系统通过分析人类行为视频来生成可执行的机器人程序，并将环境和动作细节转化为文本。计算开始于GPT-4V分析视频，然后是由GPT-4强化的任务规划器。然后，视觉系统再次分析视频，使用开放词汇物体检测器将物体名称降到实际物体上。* Results: 实验结果表明，该方法在不同场景下可以实现人类示例操作的真正机器人操作，无需预先训练或示例数据。<details>
<summary>Abstract</summary>
We introduce a pipeline that enhances a general-purpose Vision Language Model, GPT-4V(ision), by integrating observations of human actions to facilitate robotic manipulation. This system analyzes videos of humans performing tasks and creates executable robot programs that incorporate affordance insights. The computation starts by analyzing the videos with GPT-4V to convert environmental and action details into text, followed by a GPT-4-empowered task planner. In the following analyses, vision systems reanalyze the video with the task plan. Object names are grounded using an open-vocabulary object detector, while focus on the hand-object relation helps to detect the moment of grasping and releasing. This spatiotemporal grounding allows the vision systems to further gather affordance data (e.g., grasp type, way points, and body postures). Experiments across various scenarios demonstrate this method's efficacy in achieving real robots' operations from human demonstrations in a zero-shot manner. The prompts of GPT-4V/GPT-4 are available at this project page: https://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/
</details>
<details>
<summary>摘要</summary>
我们介绍一个管线，将通用视觉语言模型GPT-4V（vision）与人类行为观察结合，以便帮助机器人进行操作。这个系统会分析人们在完成任务时的视频，并将任务规划转换为可执行的机器人程式码。首先，我们使用GPT-4V分析视频，将环境和动作细节转换为文本。接着，我们使用GPT-4来实现任务规划。在进一步的分析中，我们使用视觉系统重新分析视频，并使用开放 vocabulary 物体检测器来固定物体名称。这种空间时间联系允许视觉系统进一步获取可行性资料（例如抓取型态、方向点和身体姿态）。实验结果显示，这种方法可以将人类示例中的实际机器人操作实现在零条件下。GPT-4V/GPT-4的提示可以在这个项目页面获取：https://microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts/
</details></li>
</ul>
<hr>
<h2 id="H-COAL-Human-Correction-of-AI-Generated-Labels-for-Biomedical-Named-Entity-Recognition"><a href="#H-COAL-Human-Correction-of-AI-Generated-Labels-for-Biomedical-Named-Entity-Recognition" class="headerlink" title="H-COAL: Human Correction of AI-Generated Labels for Biomedical Named Entity Recognition"></a>H-COAL: Human Correction of AI-Generated Labels for Biomedical Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11981">http://arxiv.org/abs/2311.11981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaojing Duan, John P. Lalor</li>
<li>for: 这个论文的目的是提出一种新的人工智能生成标签 corrections 框架，以便在医疗领域中使用。</li>
<li>methods: 该论文使用了一种新的排名方法，可以选择性地更正人工智能生成的标签，以达到黄金标准性的表现（100%的人工标注），但需要 significatively less human effort。</li>
<li>results: 研究发现，对5%的标签进行更正，可以提高表现相对评估的改善率达64%，对20%的标签进行更正，可以提高表现相对评估的改善率达86%。<details>
<summary>Abstract</summary>
With the rapid advancement of machine learning models for NLP tasks, collecting high-fidelity labels from AI models is a realistic possibility. Firms now make AI available to customers via predictions as a service (PaaS). This includes PaaS products for healthcare. It is unclear whether these labels can be used for training a local model without expensive annotation checking by in-house experts. In this work, we propose a new framework for Human Correction of AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can selectively correct labels and approach gold standard performance (100% human labeling) with significantly less human effort. We show that correcting 5% of labels can close the AI-human performance gap by up to 64% relative improvement, and correcting 20% of labels can close the performance gap by up to 86% relative improvement.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型对自然语言处理任务的快速进步，收集高准确度标签从AI模型是一个现实可能性。现在，企业通过预测作为服务（PaaS）提供AI给客户。这包括医疗领域的Paas产品。未知的是，这些标签是否可以用于本地模型的训练而不需要高昂的人工标注检查。在这种工作中，我们提出了一个新的人工纠正AI生成标签的框架（H-COAL）。通过对AI生成输出进行排名，可以选择性地纠正标签，并 approaching gold standard performance（100%人工标注）with significantly less human effort。我们显示，对5%的标签进行纠正可以在相对改进率为64%之间关闭AI-人工性能差距，而对20%的标签进行纠正可以在相对改进率为86%之间关闭性能差距。
</details></li>
</ul>
<hr>
<h2 id="On-the-Potential-and-Limitations-of-Few-Shot-In-Context-Learning-to-Generate-Metamorphic-Specifications-for-Tax-Preparation-Software"><a href="#On-the-Potential-and-Limitations-of-Few-Shot-In-Context-Learning-to-Generate-Metamorphic-Specifications-for-Tax-Preparation-Software" class="headerlink" title="On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software"></a>On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11979">http://arxiv.org/abs/2311.11979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dananjay Srinivas, Rohan Das, Saeid Tizpaz-Niari, Ashutosh Trivedi, Maria Leonor Pacheco</li>
<li>for: 这篇论文是为了探讨如何使用自然语言处理技术生成税务软件测试用例的。</li>
<li>methods: 该论文使用了大语言模型进行语料处理，并将 extracted from tax documents 表示为对照逻辑逻辑形式进行翻译。</li>
<li>results: 该论文提出了一个研究计划，旨在自动生成税务软件测试用例。<details>
<summary>Abstract</summary>
Due to the ever-increasing complexity of income tax laws in the United States, the number of US taxpayers filing their taxes using tax preparation software (henceforth, tax software) continues to increase. According to the U.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed their individual income taxes using tax software. Given the legal consequences of incorrectly filing taxes for the taxpayer, ensuring the correctness of tax software is of paramount importance. Metamorphic testing has emerged as a leading solution to test and debug legal-critical tax software due to the absence of correctness requirements and trustworthy datasets. The key idea behind metamorphic testing is to express the properties of a system in terms of the relationship between one input and its slightly metamorphosed twinned input. Extracting metamorphic properties from IRS tax publications is a tedious and time-consuming process. As a response, this paper formulates the task of generating metamorphic specifications as a translation task between properties extracted from tax documents - expressed in natural language - to a contrastive first-order logic form. We perform a systematic analysis on the potential and limitations of in-context learning with Large Language Models(LLMs) for this task, and outline a research agenda towards automating the generation of metamorphic specifications for tax preparation software.
</details>
<details>
<summary>摘要</summary>
Metamorphic testing has emerged as a leading solution to test and debug legal-critical tax software due to the lack of correctness requirements and trustworthy datasets. The core idea of metamorphic testing is to express the properties of a system in terms of the relationship between one input and its slightly modified twin input. However, extracting metamorphic properties from IRS tax publications is a laborious and time-consuming process.To address this challenge, this paper proposes the task of generating metamorphic specifications as a translation task between properties extracted from tax documents (expressed in natural language) and a contrastive first-order logic form. We conduct a systematic analysis of the potential and limitations of in-context learning with large language models (LLMs) for this task and outline a research agenda towards automating the generation of metamorphic specifications for tax preparation software.
</details></li>
</ul>
<hr>
<h2 id="Context-aware-Neural-Machine-Translation-for-English-Japanese-Business-Scene-Dialogues"><a href="#Context-aware-Neural-Machine-Translation-for-English-Japanese-Business-Scene-Dialogues" class="headerlink" title="Context-aware Neural Machine Translation for English-Japanese Business Scene Dialogues"></a>Context-aware Neural Machine Translation for English-Japanese Business Scene Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11976">http://arxiv.org/abs/2311.11976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/su0315/discourse_context_mt">https://github.com/su0315/discourse_context_mt</a></li>
<li>paper_authors: Sumire Honda, Patrick Fernandes, Chrysoula Zerva</li>
<li>for: 这个论文的目的是提高英日商务对话翻译的性能，并研究Context-awareness如何改善现有的Neural Machine Translation（NMT）模型。</li>
<li>methods: 该论文使用了预训练的mBART模型，并在多句话对话数据上进行了微调。 authors还提出了一些新的上下文编码方法，如说话人转换和场景类型。</li>
<li>results: 研究发现，模型可以利用以前句子和EXTRA-sentential context（使用CXMI指标），并且在增加上下文大小时，翻译质量得到了改善。 authors还提供了一些关于荣誉译法的更加细化的分析。<details>
<summary>Abstract</summary>
Despite the remarkable advancements in machine translation, the current sentence-level paradigm faces challenges when dealing with highly-contextual languages like Japanese. In this paper, we explore how context-awareness can improve the performance of the current Neural Machine Translation (NMT) models for English-Japanese business dialogues translation, and what kind of context provides meaningful information to improve translation. As business dialogue involves complex discourse phenomena but offers scarce training resources, we adapted a pretrained mBART model, finetuning on multi-sentence dialogue data, which allows us to experiment with different contexts. We investigate the impact of larger context sizes and propose novel context tokens encoding extra-sentential information, such as speaker turn and scene type. We make use of Conditional Cross-Mutual Information (CXMI) to explore how much of the context the model uses and generalise CXMI to study the impact of the extra-sentential context. Overall, we find that models leverage both preceding sentences and extra-sentential context (with CXMI increasing with context size) and we provide a more focused analysis on honorifics translation. Regarding translation quality, increased source-side context paired with scene and speaker information improves the model performance compared to previous work and our context-agnostic baselines, measured in BLEU and COMET metrics.
</details>
<details>
<summary>摘要</summary>
尽管机器翻译技术已取得了很大进步，但当面临高Contextual语言如日语时，现有句子级别模型却遇到了挑战。在这篇论文中，我们 explore了如何通过Context-awareness提高当前的Neural Machine Translation（NMT）模型在英日商业对话翻译中的表现，以及哪些Context提供了有用信息以提高翻译。商业对话具有复杂的Discourse现象，但受限于scarce的训练资源，我们采用了预训练的mBART模型，并在多句话对话数据上进行了微调。我们调查了不同Context大小的影响和提出了新的Context字符串编码方法，以捕捉extra-sentential信息，如发言人轮换和场景类型。我们使用Conditional Cross-Mutual Information（CXMI）来探索模型如何使用Context，并推广CXMI来研究额外的Context的影响。总之，我们发现模型可以利用前一句和extra-sententialContext（CXMI随着Context大小增加），并对尊敬语翻译进行了更加精细的分析。在翻译质量方面，增加源 сторо面Context，并将场景和发言人信息加入，与前一个工作和无Context基eline相比，提高了模型的表现， measured by BLEU和COMET指标。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Training-Distributions-with-Scalable-Online-Bilevel-Optimization"><a href="#Adaptive-Training-Distributions-with-Scalable-Online-Bilevel-Optimization" class="headerlink" title="Adaptive Training Distributions with Scalable Online Bilevel Optimization"></a>Adaptive Training Distributions with Scalable Online Bilevel Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11973">http://arxiv.org/abs/2311.11973</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Grangier, Pierre Ablin, Awni Hannun</li>
<li>for: 这个研究是为了改善现代机器学习中使用大规模神经网络的情况，特别是当预训数据的分布与应用领域的分布不同时。</li>
<li>methods: 这个研究提出了一个基于线上两层优化问题的算法，具体来说是使用预训数据中的一小批数据来修改预训分布，以提高模型在应用领域的性能。</li>
<li>results: 这个研究透过实验表明，在某些情况下，这种方法可以比过去对应领域的预训方法perform better，但在其他情况下可能不会成功。研究还提出了一个简单的测试方法，可以判断这种方法是否适合使用。<details>
<summary>Abstract</summary>
Large neural networks pretrained on web-scale corpora are central to modern machine learning. In this paradigm, the distribution of the large, heterogeneous pretraining data rarely matches that of the application domain. This work considers modifying the pretraining distribution in the case where one has a small sample of data reflecting the targeted test conditions. We propose an algorithm motivated by a recent formulation of this setting as an online, bilevel optimization problem. With scalability in mind, our algorithm prioritizes computing gradients at training points which are likely to most improve the loss on the targeted distribution. Empirically, we show that in some cases this approach is beneficial over existing strategies from the domain adaptation literature but may not succeed in other cases. We propose a simple test to evaluate when our approach can be expected to work well and point towards further research to address current limitations.
</details>
<details>
<summary>摘要</summary>
大型神经网络在现代机器学习中扮演着重要角色。在这个思想模式下，大规模预训练数据的分布罕见与应用领域的分布相匹配。本文考虑在有限个数据样本表征目标测试条件时修改预训练分布。我们提出一种由最近的线性Programming问题概念激发的算法。针对可扩展性，我们的算法优先计算预训练点的梯度，以便最大化目标分布上的损失。实验表明，在某些情况下，我们的方法可以超越现有的领域适应Literature中的策略，但在其他情况下可能不成功。我们提出一种简单的测试方法，用于评估我们的方法在哪些情况下能够取得良好效果，并指向进一步的研究以解决当前的限制。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Analysis-of-Substantiation-in-Scientific-Peer-Reviews"><a href="#Automatic-Analysis-of-Substantiation-in-Scientific-Peer-Reviews" class="headerlink" title="Automatic Analysis of Substantiation in Scientific Peer Reviews"></a>Automatic Analysis of Substantiation in Scientific Peer Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11967">http://arxiv.org/abs/2311.11967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanzhu Guo, Guokan Shang, Virgile Rennard, Michalis Vazirgiannis, Chloé Clavel</li>
<li>for: 提高 NLP 会议上 peer review 质量的自动控制 measure。</li>
<li>methods: 使用 claim-evidence 对 peer review 进行自动评估，基于 SubstanReview 数据集进行训练。</li>
<li>results: 通过 SubstanReview 数据集的分析，获得了对 peer review 质量的深入理解，并可以自动评估 peer review 的质量。<details>
<summary>Abstract</summary>
With the increasing amount of problematic peer reviews in top AI conferences, the community is urgently in need of automatic quality control measures. In this paper, we restrict our attention to substantiation -- one popular quality aspect indicating whether the claims in a review are sufficiently supported by evidence -- and provide a solution automatizing this evaluation process. To achieve this goal, we first formulate the problem as claim-evidence pair extraction in scientific peer reviews, and collect SubstanReview, the first annotated dataset for this task. SubstanReview consists of 550 reviews from NLP conferences annotated by domain experts. On the basis of this dataset, we train an argument mining system to automatically analyze the level of substantiation in peer reviews. We also perform data analysis on the SubstanReview dataset to obtain meaningful insights on peer reviewing quality in NLP conferences over recent years.
</details>
<details>
<summary>摘要</summary>
随着顶尖人工智能会议中的问题atic peer review的增加，社区urgently需要自动质量控制措施。在这篇论文中，我们只考虑substantiation——一种流行的质量方面，表示评论中的laims是否充分supported by evidence。我们提供一种自动评估这种评估过程的解决方案。为实现这个目标，我们首先将问题定义为科学 peer review中的claim-evidence对extracting问题，并收集了SubstanReview数据集，这是第一个关于这个任务的注解数据集。SubstanReview包含550篇来自NLP会议的评论，由领域专家注释。基于这个数据集，我们训练了一个意义挖掘系统，以自动分析 peer review 中的证据水平。我们还对SubstanReview数据集进行了数据分析，以获得有用的洞察与顶尖人工智能会议过去几年 peer review 质量的意义ful insights。
</details></li>
</ul>
<hr>
<h2 id="LLMs-as-Visual-Explainers-Advancing-Image-Classification-with-Evolving-Visual-Descriptions"><a href="#LLMs-as-Visual-Explainers-Advancing-Image-Classification-with-Evolving-Visual-Descriptions" class="headerlink" title="LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions"></a>LLMs as Visual Explainers: Advancing Image Classification with Evolving Visual Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11904">http://arxiv.org/abs/2311.11904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songhao Han, Le Zhuo, Yue Liao, Si Liu</li>
<li>for: 提高图像分类的准确率和可解释性</li>
<li>methods: 提交了一种新的图像分类框架， combining VLMs 和 LLMs， named Iterative Optimization with Visual Feedback，通过使用进化优化策略来优化类描述符，并在 VLM 分类指标中 incorporate 视觉反馈来导向优化过程。</li>
<li>results: 对于一系列图像分类 benchmark 进行了实验，实现了3.47% 的平均提高，并且所得到的描述符具有可解释性和robustness，可以在不同的底层模型上提高表现。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) offer a promising paradigm for image classification by comparing the similarity between images and class embeddings. A critical challenge lies in crafting precise textual representations for class names. While previous studies have leveraged recent advancements in large language models (LLMs) to enhance these descriptors, their outputs often suffer from ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent reliance on textual interactions with LLMs, leading to a mismatch between the generated text and the visual content in VLMs' latent space - a phenomenon we term the "explain without seeing" dilemma. 2) The oversight of the inter-class relationships, resulting in descriptors that fail to differentiate similar classes effectively. To address these issues, we propose a novel image classification framework combining VLMs with LLMs, named Iterative Optimization with Visual Feedback. In particular, our method develops an LLM-based agent, employing an evolutionary optimization strategy to refine class descriptors. Crucially, we incorporate visual feedback from VLM classification metrics, thereby guiding the optimization process with concrete visual data. Our method leads to improving accuracy on a wide range of image classification benchmarks, with 3.47\% average gains over state-of-the-art methods. We also highlight the resulting descriptions serve as explainable and robust features that can consistently improve the performance across various backbone models.
</details>
<details>
<summary>摘要</summary>
视力语言模型（VLM）提供了一个有前途的思路，通过比较图像和类别嵌入的相似性来进行图像分类。然而，一个重要挑战是制定精确的文本表述方法。在前一些研究中，通过利用大型语言模型（LLM）来提高描述符的精度。但是，这些输出经常受到歧义和不准确的影响。我们认为这有两个主要原因：1. 依赖于语言模型的文本交互，导致VLM中的 latent space 中的图像和文本之间的匹配不佳 - 我们称之为 "解释不见" 困难。2. 忽视类之间的关系，使得描述符不能有效地区分类似的类。为了解决这些问题，我们提出了一种新的图像分类框架， combining VLM 和 LLM，名为 Iterative Optimization with Visual Feedback。具体来说，我们的方法使用进化优化策略来精细调整类别描述符。更重要的是，我们在 VLM 分类指标中包含视觉反馈，从而使优化过程受到具体的视觉数据的引导。我们的方法在各种图像分类 benchmark 上实现了3.47%的平均提升，并且说明得出的描述符具有可解释和稳定的特性，可以在不同的后凹模型上保持高性能。
</details></li>
</ul>
<hr>
<h2 id="Evil-Geniuses-Delving-into-the-Safety-of-LLM-based-Agents"><a href="#Evil-Geniuses-Delving-into-the-Safety-of-LLM-based-Agents" class="headerlink" title="Evil Geniuses: Delving into the Safety of LLM-based Agents"></a>Evil Geniuses: Delving into the Safety of LLM-based Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11855">http://arxiv.org/abs/2311.11855</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/t1ans1r/evil-geniuses">https://github.com/t1ans1r/evil-geniuses</a></li>
<li>paper_authors: Yu Tian, Xiao Yang, Jingyuan Zhang, Yinpeng Dong, Hang Su</li>
<li>for: 这篇论文探讨了 LLM 基本的安全问题，以及 LLM 基本在不同角色和系统中的漏洞。</li>
<li>methods: 该论文使用了手动攻击和虚拟对话方式进行了系列的探讨，以检测 LLM 基本的安全性。</li>
<li>results: 该论文发现了三种现象：1） LLM 基本具有减少的攻击抵抗力；2） attacked agents 可以提供更加细腻的回应；3） 检测生成的不当回应的困难度更高。这些发现提醒我们质疑 LLM 基本是否能够免疫攻击，并且在不同的系统和角色水平上找到了漏洞。<details>
<summary>Abstract</summary>
The rapid advancements in large language models (LLMs) have led to a resurgence in LLM-based agents, which demonstrate impressive human-like behaviors and cooperative capabilities in various interactions and strategy formulations. However, evaluating the safety of LLM-based agents remains a complex challenge. This paper elaborately conducts a series of manual jailbreak prompts along with a virtual chat-powered evil plan development team, dubbed Evil Geniuses, to thoroughly probe the safety aspects of these agents. Our investigation reveals three notable phenomena: 1) LLM-based agents exhibit reduced robustness against malicious attacks. 2) the attacked agents could provide more nuanced responses. 3) the detection of the produced improper responses is more challenging. These insights prompt us to question the effectiveness of LLM-based attacks on agents, highlighting vulnerabilities at various levels and within different role specializations within the system/agent of LLM-based agents. Extensive evaluation and discussion reveal that LLM-based agents face significant challenges in safety and yield insights for future research. Our code is available at https://github.com/T1aNS1R/Evil-Geniuses.
</details>
<details>
<summary>摘要</summary>
LLM 的快速进步导致了 LLM 基于的代理人 return to human-like behaviors and cooperative capabilities in various interactions and strategy formulations. However, evaluating the safety of LLM-based agents remains a complex challenge. This paper conducts a series of manual jailbreak prompts along with a virtual chat-powered evil plan development team, dubbed Evil Geniuses, to thoroughly probe the safety aspects of these agents. Our investigation reveals three notable phenomena: 1) LLM-based agents exhibit reduced robustness against malicious attacks. 2) the attacked agents could provide more nuanced responses. 3) the detection of the produced improper responses is more challenging. These insights prompt us to question the effectiveness of LLM-based attacks on agents, highlighting vulnerabilities at various levels and within different role specializations within the system/agent of LLM-based agents. Extensive evaluation and discussion reveal that LLM-based agents face significant challenges in safety and yield insights for future research. Our code is available at https://github.com/T1aNS1R/Evil-Geniuses.Note: Please keep in mind that the translation is done using a machine translation tool, and may not be perfect or entirely accurate.
</details></li>
</ul>
<hr>
<h2 id="Deepparse-An-Extendable-and-Fine-Tunable-State-Of-The-Art-Library-for-Parsing-Multinational-Street-Addresses"><a href="#Deepparse-An-Extendable-and-Fine-Tunable-State-Of-The-Art-Library-for-Parsing-Multinational-Street-Addresses" class="headerlink" title="Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses"></a>Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11846">http://arxiv.org/abs/2311.11846</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Beauchemin, Marouane Yassine</li>
<li>For: The paper is written for developing an open-source, extendable, and fine-tunable address parsing solution using deep learning algorithms.* Methods: The paper uses state-of-the-art deep learning algorithms and a pre-trained model to parse addresses written in any language and using any address standard, with no pre-processing or post-processing needed.* Results: The pre-trained model achieves an average parsing accuracy of 99% on the countries used for training, and the library supports fine-tuning with new data to generate a custom address parser.<details>
<summary>Abstract</summary>
Segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications from record linkage to geocoding and package delivery. Consequently, a lot of work has been dedicated to develop accurate address parsing techniques, with machine learning and neural network methods leading the state-of-the-art scoreboard. However, most of the work on address parsing has been confined to academic endeavours with little availability of free and easy-to-use open-source solutions.   This paper presents Deepparse, a Python open-source, extendable, fine-tunable address parsing solution under LGPL-3.0 licence to parse multinational addresses using state-of-the-art deep learning algorithms and evaluated on over 60 countries. It can parse addresses written in any language and use any address standard. The pre-trained model achieves average $99~\%$ parsing accuracies on the countries used for training with no pre-processing nor post-processing needed. Moreover, the library supports fine-tuning with new data to generate a custom address parser.
</details>
<details>
<summary>摘要</summary>
segmenting an address into meaningful components, also known as address parsing, is an essential step in many applications, from record linkage to geocoding and package delivery. consequently, a lot of work has been dedicated to developing accurate address parsing techniques, with machine learning and neural network methods leading the state-of-the-art scoreboard. however, most of the work on address parsing has been confined to academic endeavors with little availability of free and easy-to-use open-source solutions.this paper presents deepparse, a python open-source, extendable, and fine-tunable address parsing solution under the LGPL-3.0 license to parse multinational addresses using state-of-the-art deep learning algorithms. the pre-trained model achieves an average of $99\%$ parsing accuracies on the countries used for training with no pre-processing nor post-processing needed. moreover, the library supports fine-tuning with new data to generate a custom address parser.
</details></li>
</ul>
<hr>
<h2 id="How-to-Use-Large-Language-Models-for-Text-Coding-The-Case-of-Fatherhood-Roles-in-Public-Policy-Documents"><a href="#How-to-Use-Large-Language-Models-for-Text-Coding-The-Case-of-Fatherhood-Roles-in-Public-Policy-Documents" class="headerlink" title="How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents"></a>How to Use Large Language Models for Text Coding: The Case of Fatherhood Roles in Public Policy Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11844">http://arxiv.org/abs/2311.11844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Lupo, Oscar Magnusson, Dirk Hovy, Elin Naurin, Lena Wängnerud<br>for: 这个研究的目的是评估大语言模型（LLMs）在政治科学研究中的文本分析能力。methods: 这个研究使用了三个原始的代码任务来测试LLMs的性能，并提供了一个通用的工作流程指南 для在政治科学研究中使用LLMs进行文本分析。results: 研究发现，当提供了详细的标签定义和编码示例时，一个LLM可以与人类标注员相当或者甚至更好，而且比人类编码更快（可以达到百度 times），更便宜（可以达到60%的成本下降），并且更易扩展到大量文本。总之，LLMs 是大多数文本编码项目的可靠选择。<details>
<summary>Abstract</summary>
Recent advances in large language models (LLMs) like GPT-3 and GPT-4 have opened up new opportunities for text analysis in political science. They promise automation with better results and less programming. In this study, we evaluate LLMs on three original coding tasks of non-English political science texts, and we provide a detailed description of a general workflow for using LLMs for text coding in political science research. Our use case offers a practical guide for researchers looking to incorporate LLMs into their research on text analysis. We find that, when provided with detailed label definitions and coding examples, an LLM can be as good as or even better than a human annotator while being much faster (up to hundreds of times), considerably cheaper (costing up to 60% less than human coding), and much easier to scale to large amounts of text. Overall, LLMs present a viable option for most text coding projects.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近的大语言模型（LLM）如GPT-3和GPT-4的进步，为政治科学中的文本分析开创了新的机遇。它们承诺自动化可以获得更好的结果，需要更少的编程。在这项研究中，我们对政治科学非英文文本中的三个原创编码任务进行了LLM的评估。我们还提供了政治科学研究中使用LLM进行文本编码的通用工作流程的详细描述。我们的使用案例为研究人员寻求在文本分析中包含LLM的研究提供了实践指南。我们发现，当提供了详细的标签定义和编码示例时，一个LLM可以与人类标注员相当或更好，而且速度可以是人类标注的百倍，成本可以是人类标注的60%以下，并且可以轻松扩展到大量文本。总之，LLMs在大多数文本编码项目中是一个可行的选择。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Grammatical-Error-Correction-Via-Multi-Task-Training-and-Optimized-Training-Schedule"><a href="#Efficient-Grammatical-Error-Correction-Via-Multi-Task-Training-and-Optimized-Training-Schedule" class="headerlink" title="Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule"></a>Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11813">http://arxiv.org/abs/2311.11813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrey Bout, Alexander Podolskiy, Sergey Nikolenko, Irina Piontkovskaya</li>
<li>for: 提高神经语法错误纠正（GEC）的进步受到数据缺乏标注的限制。</li>
<li>methods: 我们提出了两种方法来使用现有数据更有效率：一是利用对应文本的对应 corrections 进行预测，形式化为序列-到-序列问题进行多任务训练；二是调查训练数据的顺序和实例顺序对最终性能的影响，并找到最佳训练计划。</li>
<li>results: 这两种方法共同导致了显著的改进，我们的结果超过了基于 T5-XXL（11B参数）的最佳模型，并且使用 BART 模型（400M参数）。<details>
<summary>Abstract</summary>
Progress in neural grammatical error correction (GEC) is hindered by the lack of annotated training data. Sufficient amounts of high-quality manually annotated data are not available, so recent research has relied on generating synthetic data, pretraining on it, and then fine-tuning on real datasets; performance gains have been achieved either by ensembling or by using huge pretrained models such as XXL-T5 as the backbone. In this work, we explore an orthogonal direction: how to use available data more efficiently. First, we propose auxiliary tasks that exploit the alignment between the original and corrected sentences, such as predicting a sequence of corrections. We formulate each task as a sequence-to-sequence problem and perform multi-task training. Second, we discover that the order of datasets used for training and even individual instances within a dataset may have important effects on the final performance, so we set out to find the best training schedule. Together, these two ideas lead to significant improvements, producing results that improve state of the art with much smaller models; in particular, we outperform the best models based on T5-XXL (11B parameters) with a BART-based model (400M parameters).
</details>
<details>
<summary>摘要</summary>
Progress in neural grammatical error correction (GEC) 是受到annotated training data的缺乏所妨碍的。lack of sufficient high-quality manually annotated data，therefore recent research has relied on generating synthetic data, pretraining on it, and then fine-tuning on real datasets; performance gains have been achieved either by ensembling or by using huge pretrained models such as XXL-T5 as the backbone. In this work, we explore an orthogonal direction: how to use available data more efficiently. First, we propose auxiliary tasks that exploit the alignment between the original and corrected sentences, such as predicting a sequence of corrections. We formulate each task as a sequence-to-sequence problem and perform multi-task training. Second, we discover that the order of datasets used for training and even individual instances within a dataset may have important effects on the final performance, so we set out to find the best training schedule. Together, these two ideas lead to significant improvements, producing results that improve state of the art with much smaller models; in particular, we outperform the best models based on T5-XXL (11B parameters) with a BART-based model (400M parameters).
</details></li>
</ul>
<hr>
<h2 id="Encoding-Speaker-Specific-Latent-Speech-Feature-for-Speech-Synthesis"><a href="#Encoding-Speaker-Specific-Latent-Speech-Feature-for-Speech-Synthesis" class="headerlink" title="Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis"></a>Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11745">http://arxiv.org/abs/2311.11745</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jungil Kong, Junmo Lee, Jeongmin Kim, Beomjeong Kim, Jihoon Park, Dohee Kong, Changheon Lee, Sangjin Kim</li>
<li>for: 这个论文旨在提出一种新的多个说话者模型，可以详细表达说话者的总体特征，而不需要额外训练目标说话者的数据集。</li>
<li>methods: 该方法使用特征抽象和conditioning来学习和表达目标说话者的speech特征，并使用一种speech sintesis模型来评估表达的质量。</li>
<li>results: 该方法在主观相似性评价中获得了与训练的多个说话者模型相比较高的相似性mean opinion score（SMOS），并在零 shot情况下也表现出了显著的优势。此外，该方法还可以生成新的人工说话者，并且表明了encode的秘密特征足够完整地重建原始说话者的speech。<details>
<summary>Abstract</summary>
In this work, we propose a novel method for modeling numerous speakers, which enables expressing the overall characteristics of speakers in detail like a trained multi-speaker model without additional training on the target speaker's dataset. Although various works with similar purposes have been actively studied, their performance has not yet reached that of trained multi-speaker models due to their fundamental limitations. To overcome previous limitations, we propose effective methods for feature learning and representing target speakers' speech characteristics by discretizing the features and conditioning them to a speech synthesis model. Our method obtained a significantly higher similarity mean opinion score (SMOS) in subjective similarity evaluation than seen speakers of a best-performing multi-speaker model, even with unseen speakers. The proposed method also outperforms a zero-shot method by significant margins. Furthermore, our method shows remarkable performance in generating new artificial speakers. In addition, we demonstrate that the encoded latent features are sufficiently informative to reconstruct an original speaker's speech completely. It implies that our method can be used as a general methodology to encode and reconstruct speakers' characteristics in various tasks.
</details>
<details>
<summary>摘要</summary>
“在这项工作中，我们提出了一种新的方法，用于模型多个说话人，以达到没有额外训练目标说话人数据集的情况下，表达说话人的总特征如一种训练过的多说话人模型一样。虽然有许多类似目标的研究在活跃进行，但它们的性能还没有达到多说话人模型的水平，因为它们的基本限制。为了超越这些限制，我们提出了有效的特征学习方法和表示目标说话人的speech特征，通过精度地抽象特征来conditioning一个speech sintesis模型。我们的方法在主观相似度评估中获得了与见过的说话人模型相比，即使面对未见过的说话人，也具有显著的优势。此外，我们的方法在生成新的人工说话人方面也表现出了很好的性能。此外，我们还证明了编码的潜在特征足够具有重建原始说话人的speech完整的能力。这表示我们的方法可以作为一种通用的方法ологи，用于编码和重建说话人的特征在不同任务中。”
</details></li>
</ul>
<hr>
<h2 id="Addressing-the-Length-Bias-Problem-in-Document-Level-Neural-Machine-Translation"><a href="#Addressing-the-Length-Bias-Problem-in-Document-Level-Neural-Machine-Translation" class="headerlink" title="Addressing the Length Bias Problem in Document-Level Neural Machine Translation"></a>Addressing the Length Bias Problem in Document-Level Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11601">http://arxiv.org/abs/2311.11601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/salvation-z/LengthBiasDNMT">https://github.com/salvation-z/LengthBiasDNMT</a></li>
<li>paper_authors: Zhuocheng Zhang, Shuhao Gu, Min Zhang, Yang Feng</li>
<li>for: 解决文档级别神经机器翻译（DNMT）中Length bias问题，提高翻译质量。</li>
<li>methods: 提议在训练方法、注意机制和解码策略上进行改进，包括动态采样训练数据、长度 нормализа注意力机制和滑块策略。</li>
<li>results: 实验结果表明，我们的方法可以在多个公开数据集上提供显著改进，并且分析结果表明，我们的方法可以有效地减轻Length bias问题。<details>
<summary>Abstract</summary>
Document-level neural machine translation (DNMT) has shown promising results by incorporating more context information. However, this approach also introduces a length bias problem, whereby DNMT suffers from significant translation quality degradation when decoding documents that are much shorter or longer than the maximum sequence length during training. %i.e., the length bias problem. To solve the length bias problem, we propose to improve the DNMT model in training method, attention mechanism, and decoding strategy. Firstly, we propose to sample the training data dynamically to ensure a more uniform distribution across different sequence lengths. Then, we introduce a length-normalized attention mechanism to aid the model in focusing on target information, mitigating the issue of attention divergence when processing longer sequences. Lastly, we propose a sliding window strategy during decoding that integrates as much context information as possible without exceeding the maximum sequence length. The experimental results indicate that our method can bring significant improvements on several open datasets, and further analysis shows that our method can significantly alleviate the length bias problem.
</details>
<details>
<summary>摘要</summary>
文档水平神经机器翻译（DNMT）已经展示了可行的结果，通过更多的上下文信息。然而，这种方法也会导致长度偏好问题，DNMT在训练时遇到短文档或长文档时翻译质量下降。即长度偏好问题。为解决长度偏好问题，我们提议在训练方法、注意机制和解码策略方面进行改进。首先，我们提议在训练数据中采样动态，以确保不同的序列长度具有更加均匀的分布。然后，我们引入长度归一化注意机制，以帮助模型关注目标信息，避免长序列处理时的注意力散布问题。最后，我们提议在解码时采用滑块策略，可以尽可能地integrate上下文信息，不超过最大序列长度。实验结果表明，我们的方法可以在多个公开数据集上提供显著改进，并且分析结果表明，我们的方法可以有效缓解长度偏好问题。
</details></li>
</ul>
<hr>
<h2 id="Filling-the-Image-Information-Gap-for-VQA-Prompting-Large-Language-Models-to-Proactively-Ask-Questions"><a href="#Filling-the-Image-Information-Gap-for-VQA-Prompting-Large-Language-Models-to-Proactively-Ask-Questions" class="headerlink" title="Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions"></a>Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11598">http://arxiv.org/abs/2311.11598</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thunlp-mt/fiig">https://github.com/thunlp-mt/fiig</a></li>
<li>paper_authors: Ziyue Wang, Chi Chen, Peng Li, Yang Liu<br>for: 这个论文的目的是提高大语言模型（LLM）在知识开放视觉问答 task（OK-VQA）中的表现，以及在不同的语言模型上实现这种表现。methods: 作者使用了将图片转换为文本的方法，以便让 LLM 参与视觉问题的解释过程。同时，他们还提出了一种框架，使得 LLM 可以主动提问更多细节信息，以提高最终的解释性能。results: 作者在 OK-VQA 和 A-OKVQA 上验证了他们的想法，并证明了其可以持续提高基eline方法的表现，具体来说，平均提高了2.15%。此外，他们的方法在不同的语言模型上也实现了一致的改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) demonstrate impressive reasoning ability and the maintenance of world knowledge not only in natural language tasks, but also in some vision-language tasks such as open-domain knowledge-based visual question answering (OK-VQA). As images are invisible to LLMs, researchers convert images to text to engage LLMs into the visual question reasoning procedure. This leads to discrepancies between images and their textual representations presented to LLMs, which consequently impedes final reasoning performance. To fill the information gap and better leverage the reasoning capability, we design a framework that enables LLMs to proactively ask relevant questions to unveil more details in the image, along with filters for refining the generated information. We validate our idea on OK-VQA and A-OKVQA. Our method continuously boosts the performance of baselines methods by an average gain of 2.15% on OK-VQA, and achieves consistent improvements across different LLMs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="How-well-ChatGPT-understand-Malaysian-English-An-Evaluation-on-Named-Entity-Recognition-and-Relation-Extraction"><a href="#How-well-ChatGPT-understand-Malaysian-English-An-Evaluation-on-Named-Entity-Recognition-and-Relation-Extraction" class="headerlink" title="How well ChatGPT understand Malaysian English? An Evaluation on Named Entity Recognition and Relation Extraction"></a>How well ChatGPT understand Malaysian English? An Evaluation on Named Entity Recognition and Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11583">http://arxiv.org/abs/2311.11583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mohanraj-nlp/chatgpt-malaysian-english">https://github.com/mohanraj-nlp/chatgpt-malaysian-english</a></li>
<li>paper_authors: Mohan Raj Chanthran, Lay-Ki Soon, Huey Fang Ong, Bhawani Selvaretnam</li>
<li>for: 本研究用于评估ChatGPT在马来西亚英语新闻文章中提取实体和关系的能力。</li>
<li>methods: 我们提出了一种三步方法，即“教育-预测-评估”方法，用于评估ChatGPT在不同的提问设定下的性能。</li>
<li>results: 我们发现，ChatGPT在马来西亚英语新闻文章中提取实体的性能不佳，最高的F1分为0.497。进一步分析显示， morphosyntactic adaptation在马来西亚英语中带来了限制。然而，这种 morphosyntactic adaptation对ChatGPT关系提取性能没有影响。<details>
<summary>Abstract</summary>
Recently, ChatGPT has attracted a lot of interest from both researchers and the general public. While the performance of ChatGPT in named entity recognition and relation extraction from Standard English texts is satisfactory, it remains to be seen if it can perform similarly for Malaysian English. Malaysian English is unique as it exhibits morphosyntactic and semantical adaptation from local contexts. In this study, we assess ChatGPT's capability in extracting entities and relations from the Malaysian English News (MEN) dataset. We propose a three-step methodology referred to as \textbf{\textit{educate-predict-evaluate}. The performance of ChatGPT is assessed using F1-Score across 18 unique prompt settings, which were carefully engineered for a comprehensive review. From our evaluation, we found that ChatGPT does not perform well in extracting entities from Malaysian English news articles, with the highest F1-Score of 0.497. Further analysis shows that the morphosyntactic adaptation in Malaysian English caused the limitation. However, interestingly, this morphosyntactic adaptation does not impact the performance of ChatGPT for relation extraction.
</details>
<details>
<summary>摘要</summary>
近期，ChatGPT已经引起了研究者和普通公众的广泛关注。虽然ChatGPT在标准英语文本中的命名实体识别和关系EXTRACTION表现良好，但是还未得到Malaysian English的测试。Malaysian English具有独特的形态语法和semantical adaptation，这使得ChatGPT的性能在这类文本中仍然需要证明。在这项研究中，我们使用了一种三步方法，称为\textbf{\textit{educate-predict-evaluate}。我们使用F1-Score来评估ChatGPT在MEN dataset（Malaysian English News）中EXTRACTION实体和关系的性能。我们发现，ChatGPT在Malaysian English新闻文章中EXTRACTION实体时表现不佳，最高F1-Score为0.497。进一步分析表明，Malaysian English中的形态语法变化限制了ChatGPT的性能。然而，这种形态语法变化对ChatGPT的关系EXTRACTION表现没有影响。
</details></li>
</ul>
<hr>
<h2 id="KBioXLM-A-Knowledge-anchored-Biomedical-Multilingual-Pretrained-Language-Model"><a href="#KBioXLM-A-Knowledge-anchored-Biomedical-Multilingual-Pretrained-Language-Model" class="headerlink" title="KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model"></a>KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11564">http://arxiv.org/abs/2311.11564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ngwlh-gl/kbioxlm">https://github.com/ngwlh-gl/kbioxlm</a></li>
<li>paper_authors: Lei Geng, Xu Yan, Ziqiang Cao, Juntao Li, Wenjie Li, Sujian Li, Xinjie Zhou, Yang Yang, Jun Zhang</li>
<li>for: 本文提出了一种解决biomedical领域中难以处理多语言要求的问题的方法，即通过知识 anchoredapproach将英文预训练模型XLM-R转换成biomedical领域的模型KBioXLM。</li>
<li>methods: 本文使用了三种粒度的知识对应（实体、事实和段落级），将英文预训练 corpora incorporated into biomedical corpora，然后设计了三种训练任务（实体覆盖、关系覆盖和段落关系预测），继续在XLM-R模型之上训练以提高其跨语言领域能力。</li>
<li>results: 实验结果表明，KBioXLM模型在跨语言零shot和几shot情况下，与单语言和多语言预训练模型相比，显著提高了cross-lingual能力，提高了10+个点。<details>
<summary>Abstract</summary>
Most biomedical pretrained language models are monolingual and cannot handle the growing cross-lingual requirements. The scarcity of non-English domain corpora, not to mention parallel data, poses a significant hurdle in training multilingual biomedical models. Since knowledge forms the core of domain-specific corpora and can be translated into various languages accurately, we propose a model called KBioXLM, which transforms the multilingual pretrained model XLM-R into the biomedical domain using a knowledge-anchored approach. We achieve a biomedical multilingual corpus by incorporating three granularity knowledge alignments (entity, fact, and passage levels) into monolingual corpora. Then we design three corresponding training tasks (entity masking, relation masking, and passage relation prediction) and continue training on top of the XLM-R model to enhance its domain cross-lingual ability. To validate the effectiveness of our model, we translate the English benchmarks of multiple tasks into Chinese. Experimental results demonstrate that our model significantly outperforms monolingual and multilingual pretrained models in cross-lingual zero-shot and few-shot scenarios, achieving improvements of up to 10+ points. Our code is publicly available at https://github.com/ngwlh-gl/KBioXLM.
</details>
<details>
<summary>摘要</summary>
大多数生物医学预训言语模型都是单语言的，无法满足增长的多语言需求。由于非英语领域数据罕见，更是缺乏平行数据，训练多语言生物医学模型具有很大的挑战。因为知识是生物医学领域 corpora 的核心，可以精准地翻译到不同语言上，我们提出了一个名为 KBioXLM 的模型。我们使用知识固定的方法将 XLM-R 模型转换到生物医学领域中。我们创建了三级别的知识对应（实体、事实和段落级别），并将这些对应 integrate into 单语言 corpora。然后，我们设计了三种相应的训练任务（实体覆盖、关系覆盖和段落关系预测），继续在 XLM-R 模型之上进行训练，以提高其跨语言领域的某些能力。为验证我们的模型效果，我们将英语benchmarks 翻译成中文。实验结果表明，我们的模型在跨语言零shot和几shot场景中表现出色，与单语言预训言语模型和多语言预训言语模型相比，具有10+ 点的改进。我们的代码公开available于https://github.com/ngwlh-gl/KBioXLM。
</details></li>
</ul>
<hr>
<h2 id="Adapt-in-Contexts-Retrieval-Augmented-Domain-Adaptation-via-In-Context-Learning"><a href="#Adapt-in-Contexts-Retrieval-Augmented-Domain-Adaptation-via-In-Context-Learning" class="headerlink" title="Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning"></a>Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11551">http://arxiv.org/abs/2311.11551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quanyu Long, Wenya Wang, Sinno Jialin Pan</li>
<li>for: 这篇论文目的是研究对应语言模型（LLM）在不同领域进行适应，以提高其在未见领域的表现。</li>
<li>methods: 本研究使用了对应语言模型的无监督领域适应（UDA）技术，并在内容学习（ICL） Setting中进行了训练。特点是选择了跨领域元素的子集，并通过联合领域内容示例来将语言模型适应到目标领域。</li>
<li>results: 经过广泛的实验，研究发现ICL技术可以对应语言模型进行领域转移，并在抒情分析（SA）和名称识别（NER）任务中获得了显著的改善。<details>
<summary>Abstract</summary>
Large language models (LLMs) have showcased their capability with few-shot inference known as in-context learning. However, in-domain demonstrations are not always readily available in real scenarios, leading to cross-domain in-context learning. Besides, LLMs are still facing challenges in long-tail knowledge in unseen and unfamiliar domains. The above limitations demonstrate the necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study the UDA problem under an in-context learning setting to adapt language models from the source domain to the target domain without any target labels. The core idea is to retrieve a subset of cross-domain elements that are the most similar to the query, and elicit language model to adapt in an in-context manner by learning both target domain distribution and the discriminative task signal simultaneously with the augmented cross-domain in-context examples. We devise different prompting and training strategies, accounting for different LM architectures to learn the target distribution via language modeling. With extensive experiments on Sentiment Analysis (SA) and Named Entity Recognition (NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer and demonstrate significant improvements over baseline models.
</details>
<details>
<summary>摘要</summary>
Our core idea is to retrieve a subset of cross-domain elements that are most similar to the query and use these examples to adapt the language model in an in-context manner. This involves learning both the target domain distribution and the discriminative task signal simultaneously with the augmented cross-domain in-context examples. We develop different prompting and training strategies to suit different LM architectures, allowing them to learn the target distribution via language modeling.We conduct extensive experiments on Sentiment Analysis (SA) and Named Entity Recognition (NER) tasks to evaluate the effectiveness of In-Context Learning (ICL) for domain transfer. Our results show significant improvements over baseline models, demonstrating the effectiveness of ICL for adapting language models to unseen domains.
</details></li>
</ul>
<hr>
<h2 id="Multi-teacher-Distillation-for-Multilingual-Spelling-Correction"><a href="#Multi-teacher-Distillation-for-Multilingual-Spelling-Correction" class="headerlink" title="Multi-teacher Distillation for Multilingual Spelling Correction"></a>Multi-teacher Distillation for Multilingual Spelling Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11518">http://arxiv.org/abs/2311.11518</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfen Zhang, Xuan Guo, Sravan Bodapati, Christopher Potts</li>
<li>for: 本研究旨在提高现代搜索界面中的精准拼写正确，尤其是在移动设备和语音至文本交互时。</li>
<li>methods: 本文使用多教师热钻法，其中每种语言&#x2F;地区都有一个单语言教师模型，这些教师模型被热钻成一个旨在服务所有语言&#x2F;地区的多语言学生模型。</li>
<li>results: 在使用开源数据以及世界各地搜索服务用户数据进行实验中，我们发现这种方法可以生成高效的拼写正确模型，可以满足部署服务的紧张延迟要求。<details>
<summary>Abstract</summary>
Accurate spelling correction is a critical step in modern search interfaces, especially in an era of mobile devices and speech-to-text interfaces. For services that are deployed around the world, this poses a significant challenge for multilingual NLP: spelling errors need to be caught and corrected in all languages, and even in queries that use multiple languages. In this paper, we tackle this challenge using multi-teacher distillation. On our approach, a monolingual teacher model is trained for each language/locale, and these individual models are distilled into a single multilingual student model intended to serve all languages/locales. In experiments using open-source data as well as user data from a worldwide search service, we show that this leads to highly effective spelling correction models that can meet the tight latency requirements of deployed services.
</details>
<details>
<summary>摘要</summary>
精确的拼写更正是现代搜索界面中的一个关键步骤，尤其是在移动设备和语音到文本交互的时代。为部署在全球的服务而言，这会提出一个严峻的多语言NLP挑战：拼写错误需要在所有语言/地区中捕捉并更正。在这篇论文中，我们采用多教师润雨法来解决这个问题。我们将每种语言/地区的单语言教师模型进行训练，然后将这些个体模型润雨成一个通用的多语言学生模型，用于服务所有语言/地区。在使用开源数据以及全球搜索服务的用户数据进行实验中，我们发现这种方法可以创造出高效的拼写更正模型，可以满足部署服务的紧张响应时间要求。
</details></li>
</ul>
<hr>
<h2 id="Token-Level-Adversarial-Prompt-Detection-Based-on-Perplexity-Measures-and-Contextual-Information"><a href="#Token-Level-Adversarial-Prompt-Detection-Based-on-Perplexity-Measures-and-Contextual-Information" class="headerlink" title="Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information"></a>Token-Level Adversarial Prompt Detection Based on Perplexity Measures and Contextual Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11509">http://arxiv.org/abs/2311.11509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengmian Hu, Gang Wu, Saayan Mitra, Ruiyi Zhang, Tong Sun, Heng Huang, Vishy Swaminathan</li>
<li>for: 本文提出了一种用于检测 adversarial prompt 的 токен级检测方法，以帮助改进 Large Language Models (LLM) 的安全性。</li>
<li>methods: 本文提出了两种方法：一种是根据模型对下一个字符的预测概率来确定当前字符是否属于 adversarial prompt，另一种是根据当前字符和周围字符的信息来确定当前字符是否属于 adversarial prompt。</li>
<li>results: 研究人员通过实验表明，使用上述两种方法可以准确地检测 adversarial prompt，并且可以提高 LLM 的安全性。<details>
<summary>Abstract</summary>
In recent years, Large Language Models (LLM) have emerged as pivotal tools in various applications. However, these models are susceptible to adversarial prompt attacks, where attackers can carefully curate input strings that lead to undesirable outputs. The inherent vulnerability of LLMs stems from their input-output mechanisms, especially when presented with intensely out-of-distribution (OOD) inputs. This paper proposes a token-level detection method to identify adversarial prompts, leveraging the LLM's capability to predict the next token's probability. We measure the degree of the model's perplexity and incorporate neighboring token information to encourage the detection of contiguous adversarial prompt sequences. As a result, we propose two methods: one that identifies each token as either being part of an adversarial prompt or not, and another that estimates the probability of each token being part of an adversarial prompt.
</details>
<details>
<summary>摘要</summary>
Recently, Large Language Models (LLM) have become crucial tools in various applications. However, these models are vulnerable to adversarial prompt attacks, where attackers can craft input strings to elicit undesirable outputs. The vulnerability of LLMs stems from their input-output mechanisms, especially when faced with highly out-of-distribution (OOD) inputs. This paper proposes a token-level detection method to identify adversarial prompts, leveraging the LLM's ability to predict the next token's probability. We measure the model's perplexity and incorporate neighboring token information to detect contiguous adversarial prompt sequences. As a result, we propose two methods: one that identifies each token as either being part of an adversarial prompt or not, and another that estimates the probability of each token being part of an adversarial prompt.Here's the translation in Traditional Chinese:近年来，大语言模型（LLM）已经成为不同应用中的重要工具。然而，这些模型对于攻击性提示攻击具有敏感性，攻击者可以精心设计输入字串，以诱使模型产生不适合的出力。LLM的敏感性源于其输入-输出机制，特别是面对高度外部数据（OOD）的输入。本文提出了一种对于提示的token级检测方法，利用模型预测下一个token的概率。我们量化模型的困惑度，并将邻近token信息 incorporate 到检测攻击提示Sequence中。因此，我们提出了两种方法：一种是检测每个token是否是攻击提示的一部分，另一种是估计每个token是否是攻击提示的一部分。
</details></li>
</ul>
<hr>
<h2 id="What’s-left-can’t-be-right-–-The-remaining-positional-incompetence-of-contrastive-vision-language-models"><a href="#What’s-left-can’t-be-right-–-The-remaining-positional-incompetence-of-contrastive-vision-language-models" class="headerlink" title="What’s left can’t be right – The remaining positional incompetence of contrastive vision-language models"></a>What’s left can’t be right – The remaining positional incompetence of contrastive vision-language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11477">http://arxiv.org/abs/2311.11477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hoehing, Ellen Rushe, Anthony Ventresque</li>
<li>for: 本研究探讨了对比性视语模型CLIP具有空间理解能力的问题，分析了数据集和嵌入空间的可能性。</li>
<li>methods: 本研究使用了人工生成的数据集来教育模型理解左右位置关系，并证明这种方法可以在自然图像上广泛应用，提高了Visual Genome Relations中左右关系的性能。</li>
<li>results: 研究发现，通过使用人工生成的数据集来教育模型理解左右位置关系，可以大幅提高CLIP在Visual Genome Relations中的性能。<details>
<summary>Abstract</summary>
Contrastive vision-language models like CLIP have been found to lack spatial understanding capabilities. In this paper we discuss the possible causes of this phenomenon by analysing both datasets and embedding space. By focusing on simple left-right positional relations, we show that this behaviour is entirely predictable, even with large-scale datasets, demonstrate that these relations can be taught using synthetic data and show that this approach can generalise well to natural images - improving the performance on left-right relations on Visual Genome Relations.
</details>
<details>
<summary>摘要</summary>
CLIP类视觉语言模型缺乏空间理解能力。在这篇论文中，我们分析了数据集和嵌入空间，探讨这种现象的可能原因。通过专注于简单的左右位置关系，我们显示这种行为是可预测的，即使使用大规模数据集。我们还示出了使用合成数据教育这种关系的可行性，并证明这种方法可以在自然图像上良好地泛化，提高视觉遗传关系中的左右关系性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.CL_2023_11_20/" data-id="clp89doc000fhi7884ltd2if9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/cs.LG_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T10:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/cs.LG_2023_11_20/">cs.LG - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Risk-averse-Batch-Active-Inverse-Reward-Design"><a href="#Risk-averse-Batch-Active-Inverse-Reward-Design" class="headerlink" title="Risk-averse Batch Active Inverse Reward Design"></a>Risk-averse Batch Active Inverse Reward Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.12004">http://arxiv.org/abs/2311.12004</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pliam1105/RBAIRD">https://github.com/pliam1105/RBAIRD</a></li>
<li>paper_authors: Panagiotis Liampas</li>
<li>for: 这个研究是要设计一个完美的赏金函数，以捕捉所有想要的行为方面。</li>
<li>methods: 这个方法使用了一系列的询问，比较不同的赏金函数，以在单一训练环境中决定一个probability distribution。然后，透过人类提供的信息，决定最有可能性的赏金函数。</li>
<li>results: 这个研究实现了一个可靠、精确和行为内在的赏金函数设计方法，并且能够适应真实世界中的不明点。它比前一些方法更高效、更精确和更有行为内在性。<details>
<summary>Abstract</summary>
Designing a perfect reward function that depicts all the aspects of the intended behavior is almost impossible, especially generalizing it outside of the training environments. Active Inverse Reward Design (AIRD) proposed the use of a series of queries, comparing possible reward functions in a single training environment. This allows the human to give information to the agent about suboptimal behaviors, in order to compute a probability distribution over the intended reward function. However, it ignores the possibility of unknown features appearing in real-world environments, and the safety measures needed until the agent completely learns the reward function. I improved this method and created Risk-averse Batch Active Inverse Reward Design (RBAIRD), which constructs batches, sets of environments the agent encounters when being used in the real world, processes them sequentially, and, for a predetermined number of iterations, asks queries that the human needs to answer for each environment of the batch. After this process is completed in one batch, the probabilities have been improved and are transferred to the next batch. This makes it capable of adapting to real-world scenarios and learning how to treat unknown features it encounters for the first time. I also integrated a risk-averse planner, similar to that of Inverse Reward Design (IRD), which samples a set of reward functions from the probability distribution and computes a trajectory that takes the most certain rewards possible. This ensures safety while the agent is still learning the reward function, and enables the use of this approach in situations where cautiousness is vital. RBAIRD outperformed the previous approaches in terms of efficiency, accuracy, and action certainty, demonstrated quick adaptability to new, unknown features, and can be more widely used for the alignment of crucial, powerful AI models.
</details>
<details>
<summary>摘要</summary>
设计完美的奖励函数，涵盖所有行为目标方面，实际上是不可能的，尤其是泛化到训练环境之外。活动反奖设计（AIRD）提议使用一系列问题，比较可能的奖励函数在单个训练环境中。这样允许人类给agent提供关于不佳行为的信息，以计算概率分布上的奖励函数。然而，它忽略了实际环境中可能出现的未知特征，以及代理人完全学习奖励函数的安全措施。我提高了这种方法，创造了风险规避批量反奖设计（RBAIRD），它在实际世界中顺序处理批处理环境，并在 predetermined 的数量 Of iterations 后，问题人需要回答每个环境。在这个过程中，概率已经提高，并将其传递到下一个批处理。这使得它能够适应实际场景，学习在未知特征出现的第一次处理方式。我还将风险规避探索者（IRD）的风险规避探索者相同的概率分布，并计算出最可靠的奖励函数。这确保了安全性，使得代理人在学习奖励函数时，能够具有紧急应急措施。RBAIRD 在效率、准确性和行为确定性方面超越了先前的方法，快速适应新的未知特征，并可以更广泛地应用于对重要、强大 AI 模型的对齐。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learned-Atomic-Cluster-Expansion-Potentials-for-Fast-and-Quantum-Accurate-Thermal-Simulations-of-Wurtzite-AlN"><a href="#Machine-Learned-Atomic-Cluster-Expansion-Potentials-for-Fast-and-Quantum-Accurate-Thermal-Simulations-of-Wurtzite-AlN" class="headerlink" title="Machine-Learned Atomic Cluster Expansion Potentials for Fast and Quantum-Accurate Thermal Simulations of Wurtzite AlN"></a>Machine-Learned Atomic Cluster Expansion Potentials for Fast and Quantum-Accurate Thermal Simulations of Wurtzite AlN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11990">http://arxiv.org/abs/2311.11990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guang Yang, Yuan-Bin Liu, Lei Yang, Bing-Yang Cao</li>
<li>for: 这个论文的目的是为了快速和准确地模拟硼酸铝氮酸 wurtzite 的声波传输性质。</li>
<li>methods: 这个论文使用了 atomic cluster expansion（ACE）框架，开发了一个机器学习式的interatomic potential，用于模拟硼酸铝氮酸 wurtzite 的声波传输性质。</li>
<li>results: 论文通过对硼酸铝氮酸 wurtzite 的多种性质进行预测，如静态压缩 Parameter, 热Capacity, 热膨胀率, bulk modulus, 和声波普通频谱，证明了ACE potential的预测能力。此外，论文还进行了对硼酸铝氮酸 wurtzite 的声波传输性质的验证，并与DFT计算和实验数据进行比较，确认了ACE potential的总体可靠性。<details>
<summary>Abstract</summary>
Using the atomic cluster expansion (ACE) framework, we develop a machine learning interatomic potential for fast and accurately modelling the phonon transport properties of wurtzite aluminum nitride. The predictive power of the ACE potential against density functional theory (DFT) is demonstrated across a broad range of properties of w-AlN, including ground-state lattice parameters, specific heat capacity, coefficients of thermal expansion, bulk modulus, and harmonic phonon dispersions. Validation of lattice thermal conductivity is further carried out by comparing the ACE-predicted values to the DFT calculations and experiments, exhibiting the overall capability of our ACE potential in sufficiently describing anharmonic phonon interactions. As a practical application, we perform a lattice dynamics analysis using the potential to unravel the effects of biaxial strains on thermal conductivity and phonon properties of w-AlN, which is identified as a significant tuning factor for near-junction thermal design of w-AlN-based electronics.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:使用原子团扩展（ACE）框架，我们开发了一种基于机器学习的偶极材料谱可能预测 wurtzite 锆的热传输性质。我们在 w-AlN 的广泛性质上展示了 ACE  potential 的预测力，包括静态凝固参数、热容积、热膨胀率、压力系数和干扰谱峰。对于 lattice 热导率，我们进一步验证了 ACE 预测值与 DFT 计算和实验结果，manifesting ACE potential 的总体可靠性。作为实用应用，我们使用 potential 进行了固体动力学分析，探讨了由biaxial 压力所引起的 w-AlN 的热导率和凝固特性的变化，并证明了这些变化对于 near-junction 热设计的 w-AlN 基于电子器件的调整是一个重要的因素。
</details></li>
</ul>
<hr>
<h2 id="Provably-Efficient-CVaR-RL-in-Low-rank-MDPs"><a href="#Provably-Efficient-CVaR-RL-in-Low-rank-MDPs" class="headerlink" title="Provably Efficient CVaR RL in Low-rank MDPs"></a>Provably Efficient CVaR RL in Low-rank MDPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11965">http://arxiv.org/abs/2311.11965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yulai Zhao, Wenhao Zhan, Xiaoyan Hu, Ho-fung Leung, Farzan Farnia, Wen Sun, Jason D. Lee</li>
<li>for: 本文研究具有风险敏感性的 reinforcement learning（RL），目标是在固定风险容错率（CVaR）下 Maximize  conditional value at risk（CVaR）。</li>
<li>methods: 本文使用 low-rank Markov decision processes（MDPs）和 nonlinear function approximation，并提出了一种 novel Upper Confidence Bound（UCB）奖励驱动算法，用于兼顾 explore、exploit 和 representation learning。</li>
<li>results: 本文证明了其算法可以在 low-rank MDPs 中 achieve  $\tilde{O}\left(\frac{H^7 A^2 d^4}{\tau^2 \epsilon^2}\right)$ 样本复杂度，以实现 $\epsilon$-优的 CVaR。<details>
<summary>Abstract</summary>
We study risk-sensitive Reinforcement Learning (RL), where we aim to maximize the Conditional Value at Risk (CVaR) with a fixed risk tolerance $\tau$. Prior theoretical work studying risk-sensitive RL focuses on the tabular Markov Decision Processes (MDPs) setting. To extend CVaR RL to settings where state space is large, function approximation must be deployed. We study CVaR RL in low-rank MDPs with nonlinear function approximation. Low-rank MDPs assume the underlying transition kernel admits a low-rank decomposition, but unlike prior linear models, low-rank MDPs do not assume the feature or state-action representation is known. We propose a novel Upper Confidence Bound (UCB) bonus-driven algorithm to carefully balance the interplay between exploration, exploitation, and representation learning in CVaR RL. We prove that our algorithm achieves a sample complexity of $\tilde{O}\left(\frac{H^7 A^2 d^4}{\tau^2 \epsilon^2}\right)$ to yield an $\epsilon$-optimal CVaR, where $H$ is the length of each episode, $A$ is the capacity of action space, and $d$ is the dimension of representations. Computational-wise, we design a novel discretized Least-Squares Value Iteration (LSVI) algorithm for the CVaR objective as the planning oracle and show that we can find the near-optimal policy in a polynomial running time with a Maximum Likelihood Estimation oracle. To our knowledge, this is the first provably efficient CVaR RL algorithm in low-rank MDPs.
</details>
<details>
<summary>摘要</summary>
我们研究风险敏感的奖励学习（RL），目标是在固定风险容忍度 $\tau$ 下最大化条件值风险（CVaR）。先前的理论研究中只关注了tabular Markov Decision Processes（MDPs）的情况。为了将CVaR RL扩展到大型状态空间，需要使用函数近似。我们研究CVaR RL在low-rank MDPs中，其中transition kernel允许低级别分解。不同于先前的线性模型，low-rank MDPs不假设特征或行动表示是已知。我们提出了一种新的Upper Confidence Bound（UCB）奖励驱动算法，用于在exploration、exploitation和表示学习之间进行精准均衡。我们证明了我们的算法可以在 $\tilde{O}\left(\frac{H^7 A^2 d^4}{\tau^2 \epsilon^2}\right)$ 批量样本中获得 $\epsilon$-优的CVaR，其中 $H$ 是每个 episoden 的长度，$A$ 是动作空间的容量，$d$ 是表示的维度。计算机上，我们设计了一种精简的Least-Squares Value Iteration（LSVI）算法，用于CVaR目标作为规划oracle，并证明了我们可以在多项式运行时间内找到近似优化策略，具有Maximum Likelihood Estimation oracle。到我们知道，这是首次可证明有效的CVaR RL算法在low-rank MDPs中。
</details></li>
</ul>
<hr>
<h2 id="Estimation-of-entropy-regularized-optimal-transport-maps-between-non-compactly-supported-measures"><a href="#Estimation-of-entropy-regularized-optimal-transport-maps-between-non-compactly-supported-measures" class="headerlink" title="Estimation of entropy-regularized optimal transport maps between non-compactly supported measures"></a>Estimation of entropy-regularized optimal transport maps between non-compactly supported measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11934">http://arxiv.org/abs/2311.11934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mattwerenski/entropic-map">https://github.com/mattwerenski/entropic-map</a></li>
<li>paper_authors: Matthew Werenski, James M. Murphy, Shuchin Aeron</li>
<li>for: 这个论文解决了估计基于Entropy-Regularized Optimal Transport（EOT）的易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度易见度�<details>
<summary>Abstract</summary>
This paper addresses the problem of estimating entropy-regularized optimal transport (EOT) maps with squared-Euclidean cost between source and target measures that are subGaussian. In the case that the target measure is compactly supported or strongly log-concave, we show that for a recently proposed in-sample estimator, the expected squared $L^2$-error decays at least as fast as $O(n^{-1/3})$ where $n$ is the sample size. For the general subGaussian case we show that the expected $L^1$-error decays at least as fast as $O(n^{-1/6})$, and in both cases we have polynomial dependence on the regularization parameter. While these results are suboptimal compared to known results in the case of compactness of both the source and target measures (squared $L^2$-error converging at a rate $O(n^{-1})$) and for when the source is subGaussian while the target is compactly supported (squared $L^2$-error converging at a rate $O(n^{-1/2})$), their importance lie in eliminating the compact support requirements. The proof technique makes use of a bias-variance decomposition where the variance is controlled using standard concentration of measure results and the bias is handled by T1-transport inequalities along with sample complexity results in estimation of EOT cost under subGaussian assumptions. Our experimental results point to a looseness in controlling the variance terms and we conclude by posing several open problems.
</details>
<details>
<summary>摘要</summary>
Our proof technique uses a bias-variance decomposition, where the variance is controlled using standard concentration of measure results, and the bias is handled by T1-transport inequalities and sample complexity results in estimation of EOT cost under subGaussian assumptions. Our experimental results suggest that there may be looseness in controlling the variance terms, and we conclude by posing several open problems.Translation notes:* "subGaussian" is translated as "subGaussian" (Simplified Chinese: 子高aussian)* "EOT" is translated as "EOT" (Simplified Chinese: EOT)* "source measure" is translated as "source measure" (Simplified Chinese: 源度量)* "target measure" is translated as "target measure" (Simplified Chinese: 目标度量)* "squared-Euclidean cost" is translated as "squared-Euclidean cost" (Simplified Chinese: 平方euclidian cost)* "in-sample estimator" is translated as "in-sample estimator" (Simplified Chinese: 内样估计器)* "compactly supported" is translated as "compactly supported" (Simplified Chinese: 准确地支持)* "strongly log-concave" is translated as "strongly log-concave" (Simplified Chinese: 强式Log-concave)* "bias-variance decomposition" is translated as "bias-variance decomposition" (Simplified Chinese: 偏差-方差分解)* "T1-transport inequality" is translated as "T1-transport inequality" (Simplified Chinese: T1-运输不等式)* "sample complexity results" is translated as "sample complexity results" (Simplified Chinese: 样本复杂性结果)
</details></li>
</ul>
<hr>
<h2 id="Deep-Calibration-of-Market-Simulations-using-Neural-Density-Estimators-and-Embedding-Networks"><a href="#Deep-Calibration-of-Market-Simulations-using-Neural-Density-Estimators-and-Embedding-Networks" class="headerlink" title="Deep Calibration of Market Simulations using Neural Density Estimators and Embedding Networks"></a>Deep Calibration of Market Simulations using Neural Density Estimators and Embedding Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11913">http://arxiv.org/abs/2311.11913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Namid R. Stillman, Rory Baggott, Justin Lyon, Jianfei Zhang, Dingqiu Zhu, Tao Chen, Perukrishnen Vytelingum</li>
<li>for: 该文章的目的是开发一种基于深度学习的市场模拟器，以便更好地预测股票市场的行为。</li>
<li>methods: 该文章使用了神经网络density estimator和嵌入网络来适应市场模拟器的准确匹配。</li>
<li>results: 研究人员通过使用这种新方法，成功地预测了市场的行为，并且不需要人工选择或权重ensemble of stylised facts。<details>
<summary>Abstract</summary>
The ability to construct a realistic simulator of financial exchanges, including reproducing the dynamics of the limit order book, can give insight into many counterfactual scenarios, such as a flash crash, a margin call, or changes in macroeconomic outlook. In recent years, agent-based models have been developed that reproduce many features of an exchange, as summarised by a set of stylised facts and statistics. However, the ability to calibrate simulators to a specific period of trading remains an open challenge. In this work, we develop a novel approach to the calibration of market simulators by leveraging recent advances in deep learning, specifically using neural density estimators and embedding networks. We demonstrate that our approach is able to correctly identify high probability parameter sets, both when applied to synthetic and historical data, and without reliance on manually selected or weighted ensembles of stylised facts.
</details>
<details>
<summary>摘要</summary>
可以构建一个真实的金融交易市场模拟器，包括复制限单书的动态，可以给出许多对于假设情况的理解，如快速崩盘、资金征引、或macro经济景气的变化。在过去几年，代理基模型已经开发出来，可以复制许多交易市场的特征，如一组简化的事实和统计。但是，对市场模拟器进行准确的调整仍然是一个开放的挑战。在这项工作中，我们提出了一种新的方法来调整市场模拟器，利用最新的深度学习技术，具体来说是使用神经概率分布计算器和嵌入网络。我们示出了我们的方法可以正确地标识高概率的参数集，无需人工选择或权重的ensemble的预测结果。
</details></li>
</ul>
<hr>
<h2 id="Certification-of-Distributional-Individual-Fairness"><a href="#Certification-of-Distributional-Individual-Fairness" class="headerlink" title="Certification of Distributional Individual Fairness"></a>Certification of Distributional Individual Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11911">http://arxiv.org/abs/2311.11911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Wicker, Vihari Piratia, Adrian Weller</li>
<li>for: 这个论文的目的是提供 formally guaranteeing algorithmic fairness, 以便负责任地部署机器学习算法。</li>
<li>methods: 该论文使用了一种新的几何approximation来保证个体公平（IF）约束，以及一种基于 quasi-convex 优化的新的证明方法来保证分布性个体公平（DIF）。</li>
<li>results: 该论文的结果表明，该方法可以覆盖大型神经网络，并且可以快速提供有效的公平保证。此外，该论文还研究了实际 Distribution Shift 问题，并证明了该方法的可扩展性和实用性。<details>
<summary>Abstract</summary>
Providing formal guarantees of algorithmic fairness is of paramount importance to socially responsible deployment of machine learning algorithms. In this work, we study formal guarantees, i.e., certificates, for individual fairness (IF) of neural networks. We start by introducing a novel convex approximation of IF constraints that exponentially decreases the computational cost of providing formal guarantees of local individual fairness. We highlight that prior methods are constrained by their focus on global IF certification and can therefore only scale to models with a few dozen hidden neurons, thus limiting their practical impact. We propose to certify distributional individual fairness which ensures that for a given empirical distribution and all distributions within a $\gamma$-Wasserstein ball, the neural network has guaranteed individually fair predictions. Leveraging developments in quasi-convex optimization, we provide novel and efficient certified bounds on distributional individual fairness and show that our method allows us to certify and regularize neural networks that are several orders of magnitude larger than those considered by prior works. Moreover, we study real-world distribution shifts and find our bounds to be a scalable, practical, and sound source of IF guarantees.
</details>
<details>
<summary>摘要</summary>
提供形式保证算法公平性的重要性在社会责任投入机器学习算法中非常高。在这项工作中，我们研究形式保证，即证书， для个人公平性（IF）神经网络。我们首先介绍一种新的几何减少IF约束的几何近似，这将把计算提供本地个人公平性的成本减少到一个指数级别。我们指出先前的方法受到全局IF证书的限制，因此只能处理一些几十个隐藏神经元的模型，这有限了其实际影响。我们提议验证分布公平性，即验证神经网络在给定的实际分布和所有在γ-沃氏距离球中的分布之间都有保证的个人公平性预测。通过 quasi-conovex 优化技术，我们提供了新的和高效的分布公平性验证 bounds，并证明我们的方法可以证明和规范比先前作品中的模型更大几个数量级。此外，我们研究了实际分布的偏移和发现我们的约束是一个可扩展、实用和有效的源码公平性保证。
</details></li>
</ul>
<hr>
<h2 id="Real-Time-Surface-to-Air-Missile-Engagement-Zone-Prediction-Using-Simulation-and-Machine-Learning"><a href="#Real-Time-Surface-to-Air-Missile-Engagement-Zone-Prediction-Using-Simulation-and-Machine-Learning" class="headerlink" title="Real-Time Surface-to-Air Missile Engagement Zone Prediction Using Simulation and Machine Learning"></a>Real-Time Surface-to-Air Missile Engagement Zone Prediction Using Simulation and Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11905">http://arxiv.org/abs/2311.11905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jpadantas/sam-ez">https://github.com/jpadantas/sam-ez</a></li>
<li>paper_authors: Joao P. A. Dantas, Diego Geraldo, Felipe L. L. Medeiros, Marcos R. O. A. Maximo, Takashi Yoneyama</li>
<li>for: 这个研究旨在提高现代空中防御系统中的 superficie-to-air missile (SAM) 的效iveness，特别是� Engagement Zone (EZ) 的计算，这是� SAM 可以有效地处理和中断目标的空间区域。</li>
<li>methods: 本研究使用机器学习技术，提出了一种将机器学习与自定义的 simulatio tool 结合的方法，以训练supervised algorithmi。使用了大量预先计算的 SAM EZ  simulations 数据集，使我们的模型能够精确地预测新的input parameters 下的 SAM EZ。</li>
<li>results: 本研究获得了以下结果：(1) 使用机器学习技术可以优化 SAM EZ 的计算，提高空中防御 стратегіic 规划和提供实时反应; (2) 比较不同的机器学习算法，发现其能力和性能指标，并提出了未来研究的方向; (3) 这个方法可以提高 SAM 系统的效能，并为空中防御系统提供更好的战略规划和实时反应。<details>
<summary>Abstract</summary>
Surface-to-Air Missiles (SAMs) are crucial in modern air defense systems. A critical aspect of their effectiveness is the Engagement Zone (EZ), the spatial region within which a SAM can effectively engage and neutralize a target. Notably, the EZ is intrinsically related to the missile's maximum range; it defines the furthest distance at which a missile can intercept a target. The accurate computation of this EZ is essential but challenging due to the dynamic and complex factors involved, which often lead to high computational costs and extended processing times when using conventional simulation methods. In light of these challenges, our study investigates the potential of machine learning techniques, proposing an approach that integrates machine learning with a custom-designed simulation tool to train supervised algorithms. We leverage a comprehensive dataset of pre-computed SAM EZ simulations, enabling our model to accurately predict the SAM EZ for new input parameters. It accelerates SAM EZ simulations, enhances air defense strategic planning, and provides real-time insights, improving SAM system performance. The study also includes a comparative analysis of machine learning algorithms, illuminating their capabilities and performance metrics and suggesting areas for future research, highlighting the transformative potential of machine learning in SAM EZ simulations.
</details>
<details>
<summary>摘要</summary>
现代空中防御系统中，地面对空导弹（SAM）具有重要的作用。SAM的效iveness的一个关键因素是作战区（EZ），即导弹可以有效地攻击和neutralize Target的空间区域。需要注意的是，EZ与导弹的最大射程直接相关，它定义了导弹可以 intercept Target的最远距离。正确计算EZ是必要的，但是它具有复杂的因素和高计算成本，使得使用传统的 simulate方法可能会带来延迟和高计算成本。为了解决这些挑战，我们的研究团队提出了一种 integrate machine learning技术的方法，该方法通过与自定义的 simulate工具集成Machine learning算法来训练supervised模型。我们利用了大量预计算SAM EZ的数据集，使得我们的模型可以准确预测新的输入参数下的SAM EZ。这有助于加速SAM EZ的 simulate，提高空防 страте planning，并提供实时的 Insights，从而提高SAM系统的性能。我们的研究还包括了机器学习算法的比较分析，描述了这些算法的能力和性能指标，并建议了未来研究的方向，从而探讨机器学习在SAM EZ simulate中的Transformative潜力。
</details></li>
</ul>
<hr>
<h2 id="Measuring-and-Mitigating-Biases-in-Motor-Insurance-Pricing"><a href="#Measuring-and-Mitigating-Biases-in-Motor-Insurance-Pricing" class="headerlink" title="Measuring and Mitigating Biases in Motor Insurance Pricing"></a>Measuring and Mitigating Biases in Motor Insurance Pricing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11900">http://arxiv.org/abs/2311.11900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mulah Moriah, Franck Vermet, Arthur Charpentier</li>
<li>For: This paper aims to provide a comprehensive set of tools for insurers to formulate fair and optimal pricing strategies in the non-life insurance sector, while taking into account various ethical and societal factors.* Methods: The paper uses a range of statistical methodologies and available data to construct optimal pricing structures that align with the overarching corporate strategy and accommodate market competition.* Results: The study seeks to assess the effectiveness of these tools through practical application in the context of automobile insurance, with a focus on ensuring transparency, explainability, and ethical considerations in pricing practices.<details>
<summary>Abstract</summary>
The non-life insurance sector operates within a highly competitive and tightly regulated framework, confronting a pivotal juncture in the formulation of pricing strategies. Insurers are compelled to harness a range of statistical methodologies and available data to construct optimal pricing structures that align with the overarching corporate strategy while accommodating the dynamics of market competition. Given the fundamental societal role played by insurance, premium rates are subject to rigorous scrutiny by regulatory authorities. These rates must conform to principles of transparency, explainability, and ethical considerations. Consequently, the act of pricing transcends mere statistical calculations and carries the weight of strategic and societal factors. These multifaceted concerns may drive insurers to establish equitable premiums, taking into account various variables. For instance, regulations mandate the provision of equitable premiums, considering factors such as policyholder gender or mutualist group dynamics in accordance with respective corporate strategies. Age-based premium fairness is also mandated. In certain insurance domains, variables such as the presence of serious illnesses or disabilities are emerging as new dimensions for evaluating fairness. Regardless of the motivating factor prompting an insurer to adopt fairer pricing strategies for a specific variable, the insurer must possess the capability to define, measure, and ultimately mitigate any ethical biases inherent in its pricing practices while upholding standards of consistency and performance. This study seeks to provide a comprehensive set of tools for these endeavors and assess their effectiveness through practical application in the context of automobile insurance.
</details>
<details>
<summary>摘要</summary>
非生命保险领域在高度竞争和严格规范的框架下运作，面临着决定性的价格策略形成之 juncture。保险公司需要利用一系列统计方法和可用数据来构建优化的价格结构，以Alignment with overall corporate strategy and market competition dynamics。由于保险在社会中的基本作用，保险费用受到严格的监管和社会关注。因此，价格计算不仅仅是统计计算，还拥有策略和社会因素的重要性。这些多方面的问题可能会导致保险公司采用更加公平的保费策略，考虑多个变量。例如，法规要求提供公平的保费策略，考虑因素 such as 保险Policyholder gender or mutualist group dynamics according to respective corporate strategies。年龄基本的保费公平也是必须的。在某些保险领域，存在严重疾病或残疾的变量是新的评价公平的因素。无论某保险公司采用什么因素来采取更加公平的价格策略，该保险公司必须具备定义、测量和 ultimately mitigate any ethical biases inherent in its pricing practices while upholding standards of consistency and performance。本研究的目的是提供一套全面的工具，并在汽车保险上进行实践应用，以评估这些工具的有效性。
</details></li>
</ul>
<hr>
<h2 id="AMES-A-Differentiable-Embedding-Space-Selection-Framework-for-Latent-Graph-Inference"><a href="#AMES-A-Differentiable-Embedding-Space-Selection-Framework-for-Latent-Graph-Inference" class="headerlink" title="AMES: A Differentiable Embedding Space Selection Framework for Latent Graph Inference"></a>AMES: A Differentiable Embedding Space Selection Framework for Latent Graph Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11891">http://arxiv.org/abs/2311.11891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Lu, Haitz Sáez de Ocáriz Borde, Pietro Liò</li>
<li>for: 这篇论文的目的是提出一种可 diferenciable的方法来选择最佳的嵌入空间，以便在Point cloud数据上进行强化图 neural network（GNN）的推理。</li>
<li>methods: 该方法基于Attentional Multi-Embedding Selection（AMES）框架，通过反propagation来选择最佳的嵌入空间，并考虑下游任务。</li>
<li>results: 该方法在五个 benchmark dataset上达到了相当或更高的结果，并且消除了需要进行多个实验来确定最佳嵌入空间的需求。此外，该方法还提供了一种可读性技术，可以跟踪不同嵌入空间的梯度贡献，从而解释如何通过注意力机制来选择合适的嵌入空间。<details>
<summary>Abstract</summary>
In real-world scenarios, although data entities may possess inherent relationships, the specific graph illustrating their connections might not be directly accessible. Latent graph inference addresses this issue by enabling Graph Neural Networks (GNNs) to operate on point cloud data, dynamically learning the necessary graph structure. These graphs are often derived from a latent embedding space, which can be modeled using Euclidean, hyperbolic, spherical, or product spaces. However, currently, there is no principled differentiable method for determining the optimal embedding space. In this work, we introduce the Attentional Multi-Embedding Selection (AMES) framework, a differentiable method for selecting the best embedding space for latent graph inference through backpropagation, considering a downstream task. Our framework consistently achieves comparable or superior results compared to previous methods for latent graph inference across five benchmark datasets. Importantly, our approach eliminates the need for conducting multiple experiments to identify the optimal embedding space. Furthermore, we explore interpretability techniques that track the gradient contributions of different latent graphs, shedding light on how our attention-based, fully differentiable approach learns to choose the appropriate latent space. In line with previous works, our experiments emphasize the advantages of hyperbolic spaces in enhancing performance. More importantly, our interpretability framework provides a general approach for quantitatively comparing embedding spaces across different tasks based on their contributions, a dimension that has been overlooked in previous literature on latent graph inference.
</details>
<details>
<summary>摘要</summary>
在实际场景中，虽然数据实体可能具有内在关系，但具体的关系图可能并不直接可访。虚拟图注意力方法可以使得图神经网络（GNNs）在点云数据上运行，动态学习必要的图结构。这些图通常来自一个隐藏空间，可以使用欧几丁素、射影空间、球形空间或产品空间来模型。然而，目前没有原则性的可 diferenciable方法来确定最佳隐藏空间。在这个工作中，我们介绍了注意力多嵌入选择（AMES）框架，一种可 diferenciable方法，通过反射来选择最佳隐藏空间，考虑到下游任务。我们的框架在五个benchmark dataset上 consistentemente achievest comparable或superior resultscmpared to previous methods for latent graph inference。这importantly eliminates the need for conducting multiple experiments to identify the optimal embedding space。此外，我们还探索了解释技术，以跟踪不同隐藏空间对Gradient的贡献，揭示了我们的注意力基于、完全可 diferenciable的方法如何选择合适的隐藏空间。与前一些工作一样，我们的实验强调了使用射影空间的优势，并且我们的解释框架提供了一个通用的方法来比较不同任务中的隐藏空间，这一维度在前一些latent graph inference的文献中被忽略了。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Neural-Networks-for-Tiny-Machine-Learning-A-Comprehensive-Review"><a href="#Efficient-Neural-Networks-for-Tiny-Machine-Learning-A-Comprehensive-Review" class="headerlink" title="Efficient Neural Networks for Tiny Machine Learning: A Comprehensive Review"></a>Efficient Neural Networks for Tiny Machine Learning: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11883">http://arxiv.org/abs/2311.11883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minh Tri Lê, Pierre Wolinski, Julyan Arbel</li>
<li>for: 这篇评论文章探讨了在资源有限的微控制器（MCU）上实现小型机器学习（TinyML）应用的最新进展，包括各种高效神经网络和深度学习模型的部署。</li>
<li>methods: 评论文章涵盖了各种高效神经网络技术，如模型压缩、量化和低级分解，以优化神经网络架构，以最小化MCU上的资源消耗。它还讨论了将深度学习模型部署到MCU上的挑战，以及如何使用模型剪辑、硬件加速和算法-架构协同设计等技术来解决这些挑战。</li>
<li>results: 评论文章提供了一个全面的分析，探讨了目前在TinyML领域的限制和未来研究方向，以帮助读者更好地理解这一领域的发展趋势。<details>
<summary>Abstract</summary>
The field of Tiny Machine Learning (TinyML) has gained significant attention due to its potential to enable intelligent applications on resource-constrained devices. This review provides an in-depth analysis of the advancements in efficient neural networks and the deployment of deep learning models on ultra-low power microcontrollers (MCUs) for TinyML applications. It begins by introducing neural networks and discussing their architectures and resource requirements. It then explores MEMS-based applications on ultra-low power MCUs, highlighting their potential for enabling TinyML on resource-constrained devices. The core of the review centres on efficient neural networks for TinyML. It covers techniques such as model compression, quantization, and low-rank factorization, which optimize neural network architectures for minimal resource utilization on MCUs. The paper then delves into the deployment of deep learning models on ultra-low power MCUs, addressing challenges such as limited computational capabilities and memory resources. Techniques like model pruning, hardware acceleration, and algorithm-architecture co-design are discussed as strategies to enable efficient deployment. Lastly, the review provides an overview of current limitations in the field, including the trade-off between model complexity and resource constraints. Overall, this review paper presents a comprehensive analysis of efficient neural networks and deployment strategies for TinyML on ultra-low-power MCUs. It identifies future research directions for unlocking the full potential of TinyML applications on resource-constrained devices.
</details>
<details>
<summary>摘要</summary>
隐藏Machine Learning（TinyML）领域在最近几年内吸引了广泛关注，因为它可以启用智能应用程序在有限的设备上运行。本文提供了TinyML应用中有效神经网络和深度学习模型的部署在低功耗微控制器（MCU）的全面分析。文章首先介绍神经网络，描述其结构和资源需求。然后，文章探讨了基于MEMS的应用程序在低功耗MCU上的潜力，并指出了它们在启用TinyML的资源限制设备上的潜力。文章的核心部分是有效神经网络的优化，包括模型压缩、量化和低级因子分解等技术，以最小化MCU上神经网络的资源使用。文章then delves into the deployment of deep learning models on ultra-low power MCUs, addressing challenges such as limited computational capabilities and memory resources. Techniques like model pruning, hardware acceleration, and algorithm-architecture co-design are discussed as strategies to enable efficient deployment. Finally, the review provides an overview of current limitations in the field, including the trade-off between model complexity and resource constraints. Overall, this review paper presents a comprehensive analysis of efficient neural networks and deployment strategies for TinyML on ultra-low-power MCUs, and identifies future research directions for unlocking the full potential of TinyML applications on resource-constrained devices.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Forward-Gradients-for-Data-Driven-CFD-Wall-Modeling"><a href="#Forward-Gradients-for-Data-Driven-CFD-Wall-Modeling" class="headerlink" title="Forward Gradients for Data-Driven CFD Wall Modeling"></a>Forward Gradients for Data-Driven CFD Wall Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11876">http://arxiv.org/abs/2311.11876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Hückelheim, Tadbhagya Kumar, Krishnan Raghavan, Pinaki Pal</li>
<li>for: 这 paper 的目的是提出一种基于机器学习的增强 CFD 流体动力学模型，以减少计算成本并保持预测精度。</li>
<li>methods: 这 paper 使用了机器学习和其他数据驱动方法来补充现有的墙模型，以解决 CFD  simulate 中的计算成本问题。</li>
<li>results: 这 paper 的结果表明，使用这种新的机器学习方法可以减少 CFD  simulate 的计算成本，同时保持预测精度。<details>
<summary>Abstract</summary>
Computational Fluid Dynamics (CFD) is used in the design and optimization of gas turbines and many other industrial/ scientific applications. However, the practical use is often limited by the high computational cost, and the accurate resolution of near-wall flow is a significant contributor to this cost. Machine learning (ML) and other data-driven methods can complement existing wall models. Nevertheless, training these models is bottlenecked by the large computational effort and memory footprint demanded by back-propagation. Recent work has presented alternatives for computing gradients of neural networks where a separate forward and backward sweep is not needed and storage of intermediate results between sweeps is not required because an unbiased estimator for the gradient is computed in a single forward sweep. In this paper, we discuss the application of this approach for training a subgrid wall model that could potentially be used as a surrogate in wall-bounded flow CFD simulations to reduce the computational overhead while preserving predictive accuracy.
</details>
<details>
<summary>摘要</summary>
计算流体动力学（CFD）在设计和优化液化机和许多其他工业/科学应用中广泛应用。然而，实际应用受到计算成本的限制，而近墙流动的准确解决是计算成本的重要贡献之一。机器学习（ML）和其他数据驱动方法可以补充现有墙模型。然而，训练这些模型受到计算努力和内存占用的瓶颈，因为回传扩散需要大量的计算努力和内存占用。 latest work has presented alternatives for computing gradients of neural networks where a separate forward and backward sweep is not needed and storage of intermediate results between sweeps is not required because an unbiased estimator for the gradient is computed in a single forward sweep. In this paper, we discuss the application of this approach for training a subgrid wall model that could potentially be used as a surrogate in wall-bounded flow CFD simulations to reduce the computational overhead while preserving predictive accuracy.
</details></li>
</ul>
<hr>
<h2 id="Training-robust-and-generalizable-quantum-models"><a href="#Training-robust-and-generalizable-quantum-models" class="headerlink" title="Training robust and generalizable quantum models"></a>Training robust and generalizable quantum models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11871">http://arxiv.org/abs/2311.11871</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/daniel-fink-de/training-robust-and-generalizable-quantum-models">https://github.com/daniel-fink-de/training-robust-and-generalizable-quantum-models</a></li>
<li>paper_authors: Julian Berberich, Daniel Fink, Daniel Pranjić, Christian Tutschku, Christian Holm</li>
<li>for: 这 paper  investigate 量子机器学习模型的可靠性和泛化性，使用 Lipschitz 约束来保证模型的可靠性和泛化性。</li>
<li>methods: 作者使用 Lipschitz 约束来研究量子机器学习模型的可靠性和泛化性，并 derive 参数依赖的 Lipschitz 约束，以及数据编码参数对模型的影响。</li>
<li>results: 作者发现，使用 Lipschitz 约束来训练量子机器学习模型可以提高模型的可靠性和泛化性，并且通过 numerics 结果表明，这种训练策略可以提高模型的泛化性和可靠性。<details>
<summary>Abstract</summary>
Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive tailored, parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against perturbations in the input data. Further, we derive a bound on the generalization error which explicitly depends on the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings as frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. With numerical results, we demonstrate that, indeed, Lipschitz bound regularization leads to substantially more robust and generalizable quantum models.
</details>
<details>
<summary>摘要</summary>
机器学习模型的可靠性和泛化性都是非常重要的性能指标。在这篇论文中，我们在量子机器学习的上下文中研究了这两个性能指标，基于Lipschitz约束。我们计算了可调编码的情况下的Lipschitz约束，发现数据编码的 нор方面对输入数据的偏移而且影响机器学习模型的Robustness。此外，我们还计算出了参数化的泛化误差约束，其直接取决于数据编码的参数。我们的理论发现可以通过规范Lipschitz约束来训练Robust和泛化的量子机器学习模型。而固定和非可调编码，常用于量子机器学习中，Lipschitz约束无法通过调整参数来影响。因此，可调编码是系统地适应Robustness和泛化的关键。我们的实验结果表明，果然通过Lipschitz约束规范来训练量子机器学习模型，可以获得更加Robust和泛化的性能。
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-complete-intersection-Calabi-Yau-manifolds"><a href="#Deep-learning-complete-intersection-Calabi-Yau-manifolds" class="headerlink" title="Deep learning complete intersection Calabi-Yau manifolds"></a>Deep learning complete intersection Calabi-Yau manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11847">http://arxiv.org/abs/2311.11847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harold Erbin, Riccardo Finotello</li>
<li>for: 理解如何使用深度学习技术处理代数 topological 数据</li>
<li>methods: 方法方面和数据分析，然后描述神经网络架构</li>
<li>results: 状态之前精度在预测希德数字上，以及从低到高希德数和反之的推断扩展<details>
<summary>Abstract</summary>
We review advancements in deep learning techniques for complete intersection Calabi-Yau (CICY) 3- and 4-folds, with the aim of understanding better how to handle algebraic topological data with machine learning. We first discuss methodological aspects and data analysis, before describing neural networks architectures. Then, we describe the state-of-the art accuracy in predicting Hodge numbers. We include new results on extrapolating predictions from low to high Hodge numbers, and conversely.
</details>
<details>
<summary>摘要</summary>
我团队正在审查深度学习技术在完全交叉Calabi-Yau（CICY）3-4维空间中的进步，以更好地理解如何使用机器学习处理代数 topologic 数据。我们首先讨论方法学和数据分析，然后描述神经网络架构。接着，我们介绍状态艺术精度预测黎Numbers。我们还新增了在低黎数预测到高黎数预测和相反的推断扩展。
</details></li>
</ul>
<hr>
<h2 id="High-Probability-Guarantees-for-Random-Reshuffling"><a href="#High-Probability-Guarantees-for-Random-Reshuffling" class="headerlink" title="High Probability Guarantees for Random Reshuffling"></a>High Probability Guarantees for Random Reshuffling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11841">http://arxiv.org/abs/2311.11841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengxu Yu, Xiao Li</li>
<li>for: 这个论文是为了研究Stochastic Gradient Method with Random Reshuffling（SGM-RR）在粗糙非 convex 优化问题上的应用。</li>
<li>methods: 本文使用了SGM-RR方法，并 investigate了其抽象采样过程的集中性性质，并提出了一个新的高可probability样本复杂度保证，可以在无期望下驱动梯度（下标为 $\varepsilon$）下降至 $\varepsilon$ 的高可 probabilities。</li>
<li>results: 本文提出了一种基于SGM-RR方法的简单计算可停止 criterion（denoted as $\mathsf{RR}$-$\mathsf{sc}$），可以在有限多个迭代后返回一个梯度下降至 $\varepsilon$ 的高可 probabilities。此外，本文还提出了一种带有随机扰动过程的 perturbed random reshuffling方法（denoted as $\mathsf{p}$-$\mathsf{RR}$），可以快速离开精度点并返回一个第二阶站点。<details>
<summary>Abstract</summary>
We consider the stochastic gradient method with random reshuffling ($\mathsf{RR}$) for tackling smooth nonconvex optimization problems. $\mathsf{RR}$ finds broad applications in practice, notably in training neural networks. In this work, we first investigate the concentration property of $\mathsf{RR}$'s sampling procedure and establish a new high probability sample complexity guarantee for driving the gradient (without expectation) below $\varepsilon$, which effectively characterizes the efficiency of a single $\mathsf{RR}$ execution. Our derived complexity matches the best existing in-expectation one up to a logarithmic term while imposing no additional assumptions nor changing $\mathsf{RR}$'s updating rule. Furthermore, by leveraging our derived high probability descent property and bound on the stochastic error, we propose a simple and computable stopping criterion for $\mathsf{RR}$ (denoted as $\mathsf{RR}$-$\mathsf{sc}$). This criterion is guaranteed to be triggered after a finite number of iterations, and then $\mathsf{RR}$-$\mathsf{sc}$ returns an iterate with its gradient below $\varepsilon$ with high probability. Moreover, building on the proposed stopping criterion, we design a perturbed random reshuffling method ($\mathsf{p}$-$\mathsf{RR}$) that involves an additional randomized perturbation procedure near stationary points. We derive that $\mathsf{p}$-$\mathsf{RR}$ provably escapes strict saddle points and efficiently returns a second-order stationary point with high probability, without making any sub-Gaussian tail-type assumptions on the stochastic gradient errors. Finally, we conduct numerical experiments on neural network training to support our theoretical findings.
</details>
<details>
<summary>摘要</summary>
我们考虑使用测量gradient方法（$\mathsf{RR}$）来解决缓和非凸优化问题。$\mathsf{RR}$在实践中发掘了广泛的应用，特别是在训练神经网络上。在这个工作中，我们首先调查$\mathsf{RR}$的抽样程序中的集中性性质，然后建立一个新的高概率样本复杂度保证，可以在不期望的情况下使得梯度（ без预期）下降至$\varepsilon$，这有效地描述了一个$\mathsf{RR}$执行的效率。我们的定义的复杂度与现有的均衡概率定理相匹配，但不需要任何额外的假设，也不需要改变$\mathsf{RR}$的更新规则。此外，我们运用我们所得到的高概率下降性和缩推错误的上限，提出了一个简单计算可行的停止条件（denoted as $\mathsf{RR}$-$\mathsf{sc}$）。这个条件会在一定的迭代次数之后被触发，并且返回一个梯度下降至$\varepsilon$的条件下的迭代器，具有高概率。此外，我们基于所提出的停止条件，设计了一个受惹随的随机排序方法（$\mathsf{p}$-$\mathsf{RR}$），具有额外的随机干扰程序，以避免困难的积点。我们证明了$\mathsf{p}$-$\mathsf{RR}$可以有效地逃脱紧系积点，并快速返回一个第二类稳定点，不需要任何假设梯度错误的子加速度类型。最后，我们在神经网络训练中进行了实验支持我们的理论发现。
</details></li>
</ul>
<hr>
<h2 id="Zero-redundancy-distributed-learning-with-differential-privacy"><a href="#Zero-redundancy-distributed-learning-with-differential-privacy" class="headerlink" title="Zero redundancy distributed learning with differential privacy"></a>Zero redundancy distributed learning with differential privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11822">http://arxiv.org/abs/2311.11822</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqi Bu, Justin Chiu, Ruixuan Liu, Sheng Zha, George Karypis</li>
<li>for: 这篇论文的目的是为了开发一个能够在隐私保护下训练大型深度学习模型的系统解决方案。</li>
<li>methods: 这篇论文使用了 Zero Redundancy Optimizer (ZeRO) 来实现隐私保护下的分布式学习，并且开发了一个名为 DP-ZeRO 的新系统解决方案，以扩展可训练的隐私保护模型大小，并且保持了与标准 ZeRO 相同的计算和通信效率。</li>
<li>results: 这篇论文的结果显示了 DP-ZeRO 可以训练世界上最大的隐私保护模型，并且与标准 ZeRO 相比，DP-ZeRO 在计算和通信效率方面获得了相似的表现。<details>
<summary>Abstract</summary>
Deep learning using large models have achieved great success in a wide range of domains. However, training these models on billions of parameters is very challenging in terms of the training speed, memory cost, and communication efficiency, especially under the privacy-preserving regime with differential privacy (DP). On the one hand, DP optimization has comparable efficiency to the standard non-private optimization on a single GPU, but on multiple GPUs, existing DP distributed learning (such as pipeline parallel) has suffered from significantly worse efficiency. On the other hand, the Zero Redundancy Optimizer (ZeRO) is a state-of-the-art solution to the standard distributed learning, exhibiting excellent training efficiency on large models, but to work compatibly with DP is technically complicated. In this work, we develop a new systematic solution, DP-ZeRO, (I) to scale up the trainable DP model size, e.g. to GPT-100B, (II) to obtain the same computation and communication efficiency as the standard ZeRO, and (III) to enable mixed-precision DP training. Our DP-ZeRO, like the standard ZeRO, has the potential to train models with arbitrary size and is evaluated on the world's largest DP models in terms of the number of trainable parameters.
</details>
<details>
<summary>摘要</summary>
深度学习使用大型模型已经在各种领域取得了很大成功。然而，在训练这些模型时， billion个参数的训练速度、内存成本和通信效率都是很大的挑战，尤其是在保持隐私的情况下。一方面，DP优化的效率与标准非私钥的训练效率相当，但在多个GPU上分布式学习（如管道并行）中，现有的DP分布式学习表现出了明显更差的效率。另一方面，零重复优化器（ZeRO）是当前最佳的分布式学习解决方案，在大型模型上显示出了出色的训练效率，但与DP兼容需要技术上的努力。在这项工作中，我们开发了一个新的系统性解决方案——DP-ZeRO，以下是我们的目标：1. 扩展可训练DP模型的大小，例如GPT-100B。2. 与标准ZeRO的计算和通信效率相同。3. 支持混合精度DP训练。我们的DP-ZeRO，如标准ZeRO，可以训练任意大小的模型，并在世界上最大的DP模型上进行评估。
</details></li>
</ul>
<hr>
<h2 id="LogLead-–-Fast-and-Integrated-Log-Loader-Enhancer-and-Anomaly-Detector"><a href="#LogLead-–-Fast-and-Integrated-Log-Loader-Enhancer-and-Anomaly-Detector" class="headerlink" title="LogLead – Fast and Integrated Log Loader, Enhancer, and Anomaly Detector"></a>LogLead – Fast and Integrated Log Loader, Enhancer, and Anomaly Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11809">http://arxiv.org/abs/2311.11809</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/evotestops/loglead">https://github.com/evotestops/loglead</a></li>
<li>paper_authors: Mika Mäntylä, Yuqing Wang, Jesse Nyyssölä</li>
<li>for: 这篇论文是关于高效的日志分析工具LogLead的介绍。</li>
<li>methods: 该工具结合了日志处理的三个重要步骤：加载、增强和异常检测。它利用了Polars高速数据Frame库。</li>
<li>results: 论文表明，使用LogLead可以将日志加载到数据框架中比过去的解决方案多于10倍快，并且可以在Drain解析速度上提高约2倍。同时，论文还进行了一些简要的比较，表明使用LogLead的日志表示法超过了bag-of-words的限制。<details>
<summary>Abstract</summary>
This paper introduces LogLead, a tool designed for efficient log analysis. LogLead combines three essential steps in log processing: loading, enhancing, and anomaly detection. The tool leverages Polars, a high-speed DataFrame library. We currently have 7 Loaders out of which 4 is for public data sets (HDFS, Hadoop, BGL, and Thunderbird). We have multiple enhancers with three parsers (Drain, Spell, LenMa), Bert embedding creation and other log representation techniques like bag-of-words. LogLead integrates to 5 supervised and 4 unsupervised machine learning algorithms for anomaly detection from SKLearn. By integrating diverse datasets, log representation methods and anomaly detectors, LogLead facilitates comprehensive benchmarking in log analysis research. We demonstrate that log loading from raw file to dataframe is over 10x faster with LogLead is compared to past solutions. We demonstrate roughly 2x improvement in Drain parsing speed by off-loading log message normalization to LogLead. We demonstrate a brief benchmarking on HDFS suggesting that log representations beyond bag-of-words provide limited benefits. Screencast demonstrating the tool: https://youtu.be/8stdbtTfJVo
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Operator-Learning-for-Continuous-Spatial-Temporal-Model-with-A-Hybrid-Optimization-Scheme"><a href="#Operator-Learning-for-Continuous-Spatial-Temporal-Model-with-A-Hybrid-Optimization-Scheme" class="headerlink" title="Operator Learning for Continuous Spatial-Temporal Model with A Hybrid Optimization Scheme"></a>Operator Learning for Continuous Spatial-Temporal Model with A Hybrid Optimization Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11798">http://arxiv.org/abs/2311.11798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanqi Chen, Jin-Long Wu</li>
<li>for: 用于数字化的空间-时间模型化复杂动力系统的应用</li>
<li>methods: 使用最近的运算学学习进程，提出一种连续的数据驱动模型化框架，具有空间和时间分辨率的不变性</li>
<li>results: 对三个数学示例进行研究，包括维斯喷噷方程、奈尔-斯托克方程和库拉摩-希瓦希涂方程，结果证明提案的模型化框架具有空间和时间分辨率的不变性，同时也能够稳定地进行长期价值预测，并且使用短期时间系列数据和长期统计数据的组合方式可以更好地预测长期统计。<details>
<summary>Abstract</summary>
Partial differential equations are often used in the spatial-temporal modeling of complex dynamical systems in many engineering applications. In this work, we build on the recent progress of operator learning and present a data-driven modeling framework that is continuous in both space and time. A key feature of the proposed model is the resolution-invariance with respect to both spatial and temporal discretizations. To improve the long-term performance of the calibrated model, we further propose a hybrid optimization scheme that leverages both gradient-based and derivative-free optimization methods and efficiently trains on both short-term time series and long-term statistics. We investigate the performance of the spatial-temporal continuous learning framework with three numerical examples, including the viscous Burgers' equation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation. The results confirm the resolution-invariance of the proposed modeling framework and also demonstrate stable long-term simulations with only short-term time series data. In addition, we show that the proposed model can better predict long-term statistics via the hybrid optimization scheme with a combined use of short-term and long-term data.
</details>
<details>
<summary>摘要</summary>
“partial differential equations often used in spatial-temporal modeling complex dynamical systems many engineering applications. In this work, we build on recent progress operator learning present data-driven modeling framework continuous both space and time. key feature proposed model resolution-invariance respect spatial and temporal discretizations. further propose hybrid optimization scheme leverages gradient-based derivative-free optimization methods efficiently trains both short-term time series long-term statistics. investigate performance spatial-temporal continuous learning framework three numerical examples, including viscous Burgers' equation, Navier-Stokes equations, Kuramoto-Sivashinsky equation. results confirm resolution-invariance proposed modeling framework also demonstrate stable long-term simulations only short-term time series data. addition, show proposed model better predict long-term statistics hybrid optimization scheme combined use short-term long-term data.”
</details></li>
</ul>
<hr>
<h2 id="Approximate-Linear-Programming-and-Decentralized-Policy-Improvement-in-Cooperative-Multi-agent-Markov-Decision-Processes"><a href="#Approximate-Linear-Programming-and-Decentralized-Policy-Improvement-in-Cooperative-Multi-agent-Markov-Decision-Processes" class="headerlink" title="Approximate Linear Programming and Decentralized Policy Improvement in Cooperative Multi-agent Markov Decision Processes"></a>Approximate Linear Programming and Decentralized Policy Improvement in Cooperative Multi-agent Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11789">http://arxiv.org/abs/2311.11789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lakshmi Mandal, Chandrashekar Lakshminarayanan, Shalabh Bhatnagar</li>
<li>for: 这个论文关注的是一种”合作”多智能体Markov决策过程（MDP），其中有多于1个智能体，所有智能体都知道系统模型。在每个决策环节，所有的m智能体合作选择动作，以实现最大化共同长期目标。由于动作的数量呈指数增长，政策提高成本高。</li>
<li>methods: 我们提出了一种分布式政策提高算法，其中每个智能体假设其他智能体的决策是固定的，并在自己的决策中进行改进。我们使用优化方法来计算优化后的政策。我们的算法可以处理大量的状态和多个智能体。</li>
<li>results: 我们提供了论文中的理论保证，以及一些数值示例的表现。我们的算法可以处理无限期和限期的折扣MDP，并且可以处理多个智能体。<details>
<summary>Abstract</summary>
In this work, we consider a `cooperative' multi-agent Markov decision process (MDP) involving m greater than 1 agents, where all agents are aware of the system model. At each decision epoch, all the m agents cooperatively select actions in order to maximize a common long-term objective. Since the number of actions grows exponentially in the number of agents, policy improvement is computationally expensive. Recent works have proposed using decentralized policy improvement in which each agent assumes that the decisions of the other agents are fixed and it improves its decisions unilaterally. Yet, in these works, exact values are computed. In our work, for cooperative multi-agent finite and infinite horizon discounted MDPs, we propose suitable approximate policy iteration algorithms, wherein we use approximate linear programming to compute the approximate value function and use decentralized policy improvement. Thus our algorithms can handle both large number of states as well as multiple agents. We provide theoretical guarantees for our algorithms and also demonstrate the performance of our algorithms on some numerical examples.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们考虑了一种“合作”多代理Markov决策过程（MDP），其中有m个代理，所有代理都知道系统模型。在每个决策瞬间，所有m代理协力选择动作，以最大化共同长期目标。由于行动数量呈指数增长，策略提高是计算昂贵的。现有的工作提议了分布式策略提高，其中每个代理假设别的代理决策是固定的，并优化自己的决策。然而，这些工作都是使用精确值进行计算。在我们的工作中，我们提出了合作多代理负额度MDP的合理approximate策略迭代算法，其中我们使用approximate线性编程计算approximate值函数，并使用分布式策略提高。因此，我们的算法可以处理大量的状态和多个代理。我们提供了理论保证，并在一些数学示例中证明了我们的算法的性能。
</details></li>
</ul>
<hr>
<h2 id="MUVO-A-Multimodal-Generative-World-Model-for-Autonomous-Driving-with-Geometric-Representations"><a href="#MUVO-A-Multimodal-Generative-World-Model-for-Autonomous-Driving-with-Geometric-Representations" class="headerlink" title="MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations"></a>MUVO: A Multimodal Generative World Model for Autonomous Driving with Geometric Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11762">http://arxiv.org/abs/2311.11762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Bogdoll, Yitian Yang, J. Marius Zöllner</li>
<li>for: 提高自动驾驶系统的理解能力，增强下游任务的性能</li>
<li>methods: 使用原始相机和激光数据学习感知无关的多Modal世界模型，具有直接用于下游任务的感知agnostic geometric Representation</li>
<li>results: 实现多Modal未来预测，并证明我们的几何表示提高了相机图像和激光点云预测质量<details>
<summary>Abstract</summary>
Learning unsupervised world models for autonomous driving has the potential to improve the reasoning capabilities of today's systems dramatically. However, most work neglects the physical attributes of the world and focuses on sensor data alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel Representations to address this challenge. We utilize raw camera and lidar data to learn a sensor-agnostic geometric representation of the world, which can directly be used by downstream tasks, such as planning. We demonstrate multimodal future predictions and show that our geometric representation improves the prediction quality of both camera images and lidar point clouds.
</details>
<details>
<summary>摘要</summary>
<LC>zh</LC></SYS>学习无监控世界模型可以帮助自动驾驶系统的理解能力提高，但大多数工作忽视物理世界的特性，只ocus on感知数据。我们提出MUVO，一种多Modal世界模型，使用Raw camera和lidar感知数据来学习不受感知器件限制的几何表示。我们证明了多Modal未来预测和显示了我们的几何表示可以提高相机图像和lidar点云预测质量。
</details></li>
</ul>
<hr>
<h2 id="Revealing-behavioral-impact-on-mobility-prediction-networks-through-causal-interventions"><a href="#Revealing-behavioral-impact-on-mobility-prediction-networks-through-causal-interventions" class="headerlink" title="Revealing behavioral impact on mobility prediction networks through causal interventions"></a>Revealing behavioral impact on mobility prediction networks through causal interventions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11749">http://arxiv.org/abs/2311.11749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Hong, Yanan Xin, Simon Dirmeier, Fernando Perez-Cruz, Martin Raubal<br>for: 这种研究旨在评估 neuronal network 在下一个位置预测任务中受到移动行为因素的影响。methods: 这种研究使用 causal intervention 框架来评估不同移动行为因素对 neuronal network 的影响。研究使用个人移动模型生成 синтетиче的位置访问序列，并通过 intervening 数据生成过程来控制行为动态。然后，研究使用 mobility 指标评估 intervened 位置序列，并输入到已经训练过的网络中进行分析性能变化。results: 研究发现可以生成具有不同移动行为特征的位置序列，从而模拟不同的空间和时间变化。这些变化导致下一个位置预测网络的性能变化，披露了关键的移动行为因素，包括位置转移序列的顺序性、探索新位置的倾向和个体和人口层次的位置选择偏好。这些发现对实际应用中的移动预测网络有重要意义，而 causal inference 框架也预计会促进 neural network 在移动应用中的解释性和可靠性。<details>
<summary>Abstract</summary>
Deep neural networks are increasingly utilized in mobility prediction tasks, yet their intricate internal workings pose challenges for interpretability, especially in comprehending how various aspects of mobility behavior affect predictions. In this study, we introduce a causal intervention framework to assess the impact of mobility-related factors on neural networks designed for next location prediction -- a task focusing on predicting the immediate next location of an individual. To achieve this, we employ individual mobility models to generate synthetic location visit sequences and control behavior dynamics by intervening in their data generation process. We evaluate the interventional location sequences using mobility metrics and input them into well-trained networks to analyze performance variations. The results demonstrate the effectiveness in producing location sequences with distinct mobility behaviors, thus facilitating the simulation of diverse spatial and temporal changes. These changes result in performance fluctuations in next location prediction networks, revealing impacts of critical mobility behavior factors, including sequential patterns in location transitions, proclivity for exploring new locations, and preferences in location choices at population and individual levels. The gained insights hold significant value for the real-world application of mobility prediction networks, and the framework is expected to promote the use of causal inference for enhancing the interpretability and robustness of neural networks in mobility applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Leveraging-Uncertainty-Estimates-To-Improve-Classifier-Performance"><a href="#Leveraging-Uncertainty-Estimates-To-Improve-Classifier-Performance" class="headerlink" title="Leveraging Uncertainty Estimates To Improve Classifier Performance"></a>Leveraging Uncertainty Estimates To Improve Classifier Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11723">http://arxiv.org/abs/2311.11723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gundeep Arora, Srujana Merugu, Anoop Saladi, Rajeev Rastogi</li>
<li>for: 这 paper 的目的是分析模型分类结果的准确性，并提出了一种基于模型分数和不确定性的决策边界选择方法。</li>
<li>methods: 这 paper 使用了 teoretic 分析和实验证明，证明模型分数估计偏差与分类结果之间的关系，并提出了一种基于动态计划和iso随 regression的算法来解决这个问题。</li>
<li>results: 对三个实际数据集进行评估，提出的方法可以提高 recall 的水平，在高精度 bound 下达到 25%-40% 的提升，这些结果表明了利用不确定性可以提高模型的准确性。<details>
<summary>Abstract</summary>
Binary classification involves predicting the label of an instance based on whether the model score for the positive class exceeds a threshold chosen based on the application requirements (e.g., maximizing recall for a precision bound). However, model scores are often not aligned with the true positivity rate. This is especially true when the training involves a differential sampling across classes or there is distributional drift between train and test settings. In this paper, we provide theoretical analysis and empirical evidence of the dependence of model score estimation bias on both uncertainty and score itself. Further, we formulate the decision boundary selection in terms of both model score and uncertainty, prove that it is NP-hard, and present algorithms based on dynamic programming and isotonic regression. Evaluation of the proposed algorithms on three real-world datasets yield 25%-40% gain in recall at high precision bounds over the traditional approach of using model score alone, highlighting the benefits of leveraging uncertainty.
</details>
<details>
<summary>摘要</summary>
二分类预测基于实例标签的预测结果，通常基于模型分数是否超过选择的阈值（例如，以最大准确率为约束）。然而，模型分数与实际正确率之间并不总是一一对应。特别是在样本采样过程中存在类别差异或测试环境中存在分布误差时，模型分数的估计偏差会变得更加明显。在这篇论文中，我们提供了对模型分数估计偏差的理论分析和实际证据。我们还表述了基于模型分数和不确定性的决策边界选择，证明其是NP困难的，并提出了基于动态Programming和iso顺回归的算法。我们对三个实际 dataset进行评估，发现使用我们的方法可以提高recall的值在高精度约束下，升高了使用模型分数alone的效果。这些结果表明了使用不确定性可以提高预测的性能。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Power-of-Self-Attention-for-Shipping-Cost-Prediction-The-Rate-Card-Transformer"><a href="#Unveiling-the-Power-of-Self-Attention-for-Shipping-Cost-Prediction-The-Rate-Card-Transformer" class="headerlink" title="Unveiling the Power of Self-Attention for Shipping Cost Prediction: The Rate Card Transformer"></a>Unveiling the Power of Self-Attention for Shipping Cost Prediction: The Rate Card Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11694">http://arxiv.org/abs/2311.11694</a></li>
<li>repo_url: None</li>
<li>paper_authors: P Aditya Sreekar, Sahil Verma, Varun Madhavan, Abhishek Persad</li>
<li>for: 这个研究是为了提高亚马逊的寄送成本估算精度，以便下游系统可以更好地做出金融决策，例如价格策略和删除损失的产品。</li>
<li>methods: 这个研究使用了一个名为“Rate Card Transformer”的新架构，这个架构使用自我注意来将所有寄送信息，例如包装 attribute、交通公司信息和路径规划，转换为数据表格。</li>
<li>results: 研究结果显示，使用 Rate Card Transformer 估算寄送成本时的误差比使用树型模型（GBDT）低得多，且比州先进的 transformer-based 数据表格模型（FTTransformer）高出6.08%。此外，研究还显示 Rate Card Transformer 可以将统计数据映射到更好的数据表格模型中，以提高其性能。<details>
<summary>Abstract</summary>
Amazon ships billions of packages to its customers annually within the United States. Shipping cost of these packages are used on the day of shipping (day 0) to estimate profitability of sales. Downstream systems utilize these days 0 profitability estimates to make financial decisions, such as pricing strategies and delisting loss-making products. However, obtaining accurate shipping cost estimates on day 0 is complex for reasons like delay in carrier invoicing or fixed cost components getting recorded at monthly cadence. Inaccurate shipping cost estimates can lead to bad decision, such as pricing items too low or high, or promoting the wrong product to the customers. Current solutions for estimating shipping costs on day 0 rely on tree-based models that require extensive manual engineering efforts. In this study, we propose a novel architecture called the Rate Card Transformer (RCT) that uses self-attention to encode all package shipping information such as package attributes, carrier information and route plan. Unlike other transformer-based tabular models, RCT has the ability to encode a variable list of one-to-many relations of a shipment, allowing it to capture more information about a shipment. For example, RCT can encode properties of all products in a package. Our results demonstrate that cost predictions made by the RCT have 28.82% less error compared to tree-based GBDT model. Moreover, the RCT outperforms the state-of-the-art transformer-based tabular model, FTTransformer, by 6.08%. We also illustrate that the RCT learns a generalized manifold of the rate card that can improve the performance of tree-based models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unraveling-the-Control-Engineer’s-Craft-with-Neural-Networks"><a href="#Unraveling-the-Control-Engineer’s-Craft-with-Neural-Networks" class="headerlink" title="Unraveling the Control Engineer’s Craft with Neural Networks"></a>Unraveling the Control Engineer’s Craft with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11644">http://arxiv.org/abs/2311.11644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Braghadeesh Lakshminarayanan, Federico Dettù, Cristian R. Rojas, Simone Formentin</li>
<li>for: 这篇论文是关于如何通过数字孪生模型来调整控制器的最佳化方法。</li>
<li>methods: 该方法使用了数字孪生模型生成输入输出数据，然后使用了人工生成的数据来学习控制器调整规则，使用了 state-of-the-art 的神经网络架构。</li>
<li>results: 该方法可以通过数据直接学习控制器调整规则，从而实际替代控制工程师，并且可以在数字孪生模型中拟合不同的参数变化。<details>
<summary>Abstract</summary>
Many industrial processes require suitable controllers to meet their performance requirements. More often, a sophisticated digital twin is available, which is a highly complex model that is a virtual representation of a given physical process, whose parameters may not be properly tuned to capture the variations in the physical process. In this paper, we present a sim2real, direct data-driven controller tuning approach, where the digital twin is used to generate input-output data and suitable controllers for several perturbations in its parameters. State-of-the art neural-network architectures are then used to learn the controller tuning rule that maps input-output data onto the controller parameters, based on artificially generated data from perturbed versions of the digital twin. In this way, as far as we are aware, we tackle for the first time the problem of re-calibrating the controller by meta-learning the tuning rule directly from data, thus practically replacing the control engineer with a machine learning model. The benefits of this methodology are illustrated via numerical simulations for several choices of neural-network architectures.
</details>
<details>
<summary>摘要</summary>
Many industrial processes require suitable controllers to meet their performance requirements. More often, a sophisticated digital twin is available, which is a highly complex model that is a virtual representation of a given physical process, whose parameters may not be properly tuned to capture the variations in the physical process. In this paper, we present a sim2real, direct data-driven controller tuning approach, where the digital twin is used to generate input-output data and suitable controllers for several perturbations in its parameters. State-of-the-art neural-network architectures are then used to learn the controller tuning rule that maps input-output data onto the controller parameters, based on artificially generated data from perturbed versions of the digital twin. In this way, as far as we are aware, we tackle for the first time the problem of re-calibrating the controller by meta-learning the tuning rule directly from data, thus practically replacing the control engineer with a machine learning model. The benefits of this methodology are illustrated via numerical simulations for several choices of neural-network architectures.Here's the translation in Traditional Chinese:Many industrial processes require suitable controllers to meet their performance requirements. More often, a sophisticated digital twin is available, which is a highly complex model that is a virtual representation of a given physical process, whose parameters may not be properly tuned to capture the variations in the physical process. In this paper, we present a sim2real, direct data-driven controller tuning approach, where the digital twin is used to generate input-output data and suitable controllers for several perturbations in its parameters. State-of-the-art neural-network architectures are then used to learn the controller tuning rule that maps input-output data onto the controller parameters, based on artificially generated data from perturbed versions of the digital twin. In this way, as far as we are aware, we tackle for the first time the problem of re-calibrating the controller by meta-learning the tuning rule directly from data, thus practically replacing the control engineer with a machine learning model. The benefits of this methodology are illustrated via numerical simulations for several choices of neural-network architectures.
</details></li>
</ul>
<hr>
<h2 id="Incorporating-LLM-Priors-into-Tabular-Learners"><a href="#Incorporating-LLM-Priors-into-Tabular-Learners" class="headerlink" title="Incorporating LLM Priors into Tabular Learners"></a>Incorporating LLM Priors into Tabular Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11628">http://arxiv.org/abs/2311.11628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Zhu, Siniša Stanivuk, Andrija Petrovic, Mladen Nikolic, Pietro Lio</li>
<li>for: 这篇论文是为了探讨如何将大型语言模型（LLMs）与传统表格资料分类技术结合，以解决 LLMS 的挑战，例如资料序列化敏感性和偏见。</li>
<li>methods: 这篇论文提出了两种使用 LLMS 进行排名数据类别和生成关系函数的策略，以提高几何shot scenario 的性能。它还引入了一个名为 MonotonicLR 的非线性对数函数，用于将排名变数转换为数据类别，并保持 LLMS 决定的顺序。</li>
<li>results: 这篇论文的结果显示，与基eline模型进行比较，提出的方法在几何shot scenario 中表现出色，尤其是在资料少量的情况下。此外，这篇论文还证明了其方法的可读性。<details>
<summary>Abstract</summary>
We present a method to integrate Large Language Models (LLMs) and traditional tabular data classification techniques, addressing LLMs challenges like data serialization sensitivity and biases. We introduce two strategies utilizing LLMs for ranking categorical variables and generating priors on correlations between continuous variables and targets, enhancing performance in few-shot scenarios. We focus on Logistic Regression, introducing MonotonicLR that employs a non-linear monotonic function for mapping ordinals to cardinals while preserving LLM-determined orders. Validation against baseline models reveals the superior performance of our approach, especially in low-data scenarios, while remaining interpretable.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，将大语言模型（LLMs）与传统的表格数据分类技术集成，解决 LLMS 的挑战，如数据序列化敏感性和偏见。我们提出了两种使用 LLMS 对 categorical 变量进行排名和生成连接 continuous 变量和目标的策略，提高了几个示例下的性能。我们主要关注了Logistic Regression，并提出了MonotonicLR，使用非线性卷积函数将 ordinal 映射到 cardinal，保持 LLM 决定的顺序。对于基线模型的验证表明，我们的方法在低数据场景下表现出优于基线模型，而且保持可解释性。
</details></li>
</ul>
<hr>
<h2 id="Testing-multivariate-normality-by-testing-independence"><a href="#Testing-multivariate-normality-by-testing-independence" class="headerlink" title="Testing multivariate normality by testing independence"></a>Testing multivariate normality by testing independence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11575">http://arxiv.org/abs/2311.11575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Povilas Daniušis</li>
<li>for: 该论文是为了提出一种简单的多变量常数测试方法，该方法基于Kac-Bernstein的特征化。</li>
<li>methods: 该方法使用现有的统计独立测试来进行 sums和差分数据样本的测试。</li>
<li>results: 实验表明，在高维数据中，该方法可能比替代方法更高效。<details>
<summary>Abstract</summary>
We propose a simple multivariate normality test based on Kac-Bernstein's characterization, which can be conducted by utilising existing statistical independence tests for sums and differences of data samples. We also perform its empirical investigation, which reveals that for high-dimensional data, the proposed approach may be more efficient than the alternative ones. The accompanying code repository is provided at \url{https://shorturl.at/rtuy5}.
</details>
<details>
<summary>摘要</summary>
我们提出了一种简单的多变量正态测试，基于加铬-bernstein的特征化，可以通过利用现有的统计独立测试来进行。我们还进行了其实验研究，发现在高维数据上，我们的方法可能更高效than alternative ones。附加的代码库可以在 \url{https://shorturl.at/rtuy5} 获取。Note:* "加铬-bernstein" is the Simplified Chinese name for Kac-Bernstein, which is a characterization of multivariate normality.* "独立测试" is the Simplified Chinese name for independence tests, which are used to determine whether two or more random variables are independent or not.
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Genetic-Algorithm-Deep-GA-Approach-for-High-Dimensional-Nonlinear-Parabolic-Partial-Differential-Equations"><a href="#A-Deep-Genetic-Algorithm-Deep-GA-Approach-for-High-Dimensional-Nonlinear-Parabolic-Partial-Differential-Equations" class="headerlink" title="A Deep-Genetic Algorithm (Deep-GA) Approach for High-Dimensional Nonlinear Parabolic Partial Differential Equations"></a>A Deep-Genetic Algorithm (Deep-GA) Approach for High-Dimensional Nonlinear Parabolic Partial Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11558">http://arxiv.org/abs/2311.11558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Endah Rokhmati Merdika Putri, Muhammad Luthfi Shahab, Mohammad Iqbal, Imam Mukhlash, Amirul Hakam, Lutfi Mardianto, Hadi Susanto</li>
<li>for: 加速 deep-BSDE 方法的性能，解决高维 partial differential equations (PDEs) 通过其相应的 backwards stochastic differential equations (BSDEs)。</li>
<li>methods: 嵌入 genetic algorithm (GA) 优化初始猜测选择，以提高 solver 的稳定性和速度。</li>
<li>results: 应用于 two nonlinear parabolic PDEs， specifically the Black-Scholes (BS) equation with default risk and the Hamilton-Jacobi-Bellman (HJB) equation，并与 deep-BSDE 进行比较，显示了 Our method 提供了相当于精度的比较提高计算效率。<details>
<summary>Abstract</summary>
We propose a new method, called a deep-genetic algorithm (deep-GA), to accelerate the performance of the so-called deep-BSDE method, which is a deep learning algorithm to solve high dimensional partial differential equations through their corresponding backward stochastic differential equations (BSDEs). Recognizing the sensitivity of the solver to the initial guess selection, we embed a genetic algorithm (GA) into the solver to optimize the selection. We aim to achieve faster convergence for the nonlinear PDEs on a broader interval than deep-BSDE. Our proposed method is applied to two nonlinear parabolic PDEs, i.e., the Black-Scholes (BS) equation with default risk and the Hamilton-Jacobi-Bellman (HJB) equation. We compare the results of our method with those of the deep-BSDE and show that our method provides comparable accuracy with significantly improved computational efficiency.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，即深度遗传算法（深度-GA），以加速深度BSDE方法的性能，该方法是一种基于深度学习的方法来解决高维 partial differential equations（PDEs）的相应后逆随机差分方程（BSDEs）。我们认为选择初始猜测对解法的敏感性，因此我们将遗传算法（GA） embedding到解法中以优化选择。我们希望在更广泛的时间范围内实现更快的射线整合，而不是只是在深度BSDE中。我们应用我们的方法到两个非线性带拥有PDEs，即黑-股（BS）方程和汉密尔-雅各布-贝尔（HJB）方程。我们比较了我们的方法与深度BSDE的结果，并发现我们的方法可以保持相同的准确性，而且提高了计算效率。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Variation-in-Subpopulation-Susceptibility-to-Poisoning-Attacks"><a href="#Understanding-Variation-in-Subpopulation-Susceptibility-to-Poisoning-Attacks" class="headerlink" title="Understanding Variation in Subpopulation Susceptibility to Poisoning Attacks"></a>Understanding Variation in Subpopulation Susceptibility to Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11544">http://arxiv.org/abs/2311.11544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Rose, Fnu Suya, David Evans</li>
<li>for: 本研究旨在探讨机器学习模型在受到攻击时的漏斗性，具体来说是研究攻击者通过控制训练数据中一小部分数据点来控制模型的行为的情况。</li>
<li>methods: 本研究使用现有的攻击方法和数据集，并通过实验研究了不同的数据集和攻击方法之间的关系。</li>
<li>results: 研究发现， dataset separability 对于不同的子 популяции的漏斗性具有决定性的影响，而well-separated datasets 则更加виси于个体子 популяции的特性。此外，研究还发现了一个关键的子 популяции特性，即模型在净化数据集上的损失差异，可以用于评估攻击的效果。这种特性还可以在高维度的benchmark数据集上进行探讨。在Adult benchmark数据集上，研究发现可以找到semantically-meaningful的子 популяции特性，这些特性与选择的子 популяции的漏斗性相关。<details>
<summary>Abstract</summary>
Machine learning is susceptible to poisoning attacks, in which an attacker controls a small fraction of the training data and chooses that data with the goal of inducing some behavior unintended by the model developer in the trained model. We consider a realistic setting in which the adversary with the ability to insert a limited number of data points attempts to control the model's behavior on a specific subpopulation. Inspired by previous observations on disparate effectiveness of random label-flipping attacks on different subpopulations, we investigate the properties that can impact the effectiveness of state-of-the-art poisoning attacks against different subpopulations. For a family of 2-dimensional synthetic datasets, we empirically find that dataset separability plays a dominant role in subpopulation vulnerability for less separable datasets. However, well-separated datasets exhibit more dependence on individual subpopulation properties. We further discover that a crucial subpopulation property is captured by the difference in loss on the clean dataset between the clean model and a target model that misclassifies the subpopulation, and a subpopulation is much easier to attack if the loss difference is small. This property also generalizes to high-dimensional benchmark datasets. For the Adult benchmark dataset, we show that we can find semantically-meaningful subpopulation properties that are related to the susceptibilities of a selected group of subpopulations. The results in this paper are accompanied by a fully interactive web-based visualization of subpopulation poisoning attacks found at https://uvasrg.github.io/visualizing-poisoning
</details>
<details>
<summary>摘要</summary>
机器学习容易受到毒素攻击，攻击者控制一小部分训练数据，并选择这些数据以实现模型开发者未意的行为。我们考虑了一个现实情况，在其中敌对者有插入有限数据点的能力，并尝试控制模型对特定子population的行为。基于之前观察到不同子population对随机标签反转攻击的不同效果，我们研究了不同子population的攻击效果如何受到 dataset 的性能影响。对于一家二维synthetic dataset的家族，我们发现了实验ally 发现了 dataset 的分离度在不同子population的攻击效果中扮演了主导角色。然而，well-separated dataset 的攻击效果更多地受到个体子population的特性影响。我们还发现，在净 dataset 上模型和目标模型之间的损失差异对于攻击一个子population是非常重要的。这个特性还普遍适用于高维benchmark dataset。对于Adult benchmark dataset，我们发现可以找到semantically-meaningful的子population特性，这些特性与选择的子population攻击性相关。这些结果被 accompanies by a fully interactive web-based visualization of subpopulation poisoning attacks，可以在https://uvasrg.github.io/visualizing-poisoning 中找到。
</details></li>
</ul>
<hr>
<h2 id="An-NMF-Based-Building-Block-for-Interpretable-Neural-Networks-With-Continual-Learning"><a href="#An-NMF-Based-Building-Block-for-Interpretable-Neural-Networks-With-Continual-Learning" class="headerlink" title="An NMF-Based Building Block for Interpretable Neural Networks With Continual Learning"></a>An NMF-Based Building Block for Interpretable Neural Networks With Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11485">http://arxiv.org/abs/2311.11485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian K. Vogel</li>
<li>for: 本研究目的是寻找一种可以兼顾预测性和解释性的学习方法，以便在模型建构中保持高度的解释性，而不需要弃置预测性。</li>
<li>methods: 本研究使用了一种基于 nearest neighbors 和非正式矩阵分解（NMF）的建构块，称为 Predictive Factorized Coupling（PFC）块，它通过结合超vised neural network 训练方法来实现高度的预测性，同时保持 NMF 的解释性特点。</li>
<li>results: 研究人员通过对小型数据集进行测试，发现 PFC 块可以与多层感知机（MLP）模型相比，在预测性方面具有竞争力，同时也提供了更好的解释性。此外，研究人员还展示了使用 PFC 块构建更加表达强的架构，包括一个完全连接的 residual network 和一个分解的 RNN，这些架构可以在不同的情况下表现出色，例如在不同的数据分布情况下、在不同的训练数据量情况下、以及在知识移除之后。<details>
<summary>Abstract</summary>
Existing learning methods often struggle to balance interpretability and predictive performance. While models like nearest neighbors and non-negative matrix factorization (NMF) offer high interpretability, their predictive performance on supervised learning tasks is often limited. In contrast, neural networks based on the multi-layer perceptron (MLP) support the modular construction of expressive architectures and tend to have better recognition accuracy but are often regarded as black boxes in terms of interpretability. Our approach aims to strike a better balance between these two aspects through the use of a building block based on NMF that incorporates supervised neural network training methods to achieve high predictive performance while retaining the desirable interpretability properties of NMF. We evaluate our Predictive Factorized Coupling (PFC) block on small datasets and show that it achieves competitive predictive performance with MLPs while also offering improved interpretability. We demonstrate the benefits of this approach in various scenarios, such as continual learning, training on non-i.i.d. data, and knowledge removal after training. Additionally, we show examples of using the PFC block to build more expressive architectures, including a fully-connected residual network as well as a factorized recurrent neural network (RNN) that performs competitively with vanilla RNNs while providing improved interpretability. The PFC block uses an iterative inference algorithm that converges to a fixed point, making it possible to trade off accuracy vs computation after training but also currently preventing its use as a general MLP replacement in some scenarios such as training on very large datasets. We provide source code at https://github.com/bkvogel/pfc
</details>
<details>
<summary>摘要</summary>
现有的学习方法经常难以平衡解释性和预测性能。 nearest neighbors 和非负矩阵分解（NMF）可以提供高度的解释性，但其预测性能在编程学习任务中经常有限。 相比之下，基于多层感知器（MLP）的神经网络支持模块化的建构，并且具有更好的识别率，但是它们经常被视为黑盒子，即不可解释性。 我们的方法尝试平衡这两个方面，通过使用基于 NMF 的建筑块，并将神经网络训练方法引入，以实现高度的预测性能，同时保留 NMF 的愉悦解释性质。 我们在小 datasets 上评估了我们的 Predictive Factorized Coupling (PFC) 块，并证明它在编程学习任务中可以与 MLP 竞争，同时提供更好的解释性。 我们在不同的场景中展示了这种方法的优势，包括继续学习、训练非 i.i.d. 数据、知识移除等。 此外，我们还示出了使用 PFC 块建立更加表达性的架构，包括完全连接的差异阶段网络以及因子化 RNN，该架构可以与标准 RNN 竞争，同时提供更好的解释性。 PFC 块使用迭代推理算法，其总是会到达稳定点，因此可以在训练后进行精度与计算的交换，但目前不能作为普通 MLP 的替代品，尤其是在训练非常大的 dataset 时。 我们在 GitHub 上提供了代码，请参考 <https://github.com/bkvogel/pfc>。
</details></li>
</ul>
<hr>
<h2 id="Gaussian-Interpolation-Flows"><a href="#Gaussian-Interpolation-Flows" class="headerlink" title="Gaussian Interpolation Flows"></a>Gaussian Interpolation Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11475">http://arxiv.org/abs/2311.11475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Gao, Jian Huang, Yuling Jiao</li>
<li>for: 这种论文主要针对的是 simulation-free continuous normalizing flows for generative modeling，即使这种方法在实践中具有成功，它们的理论性和杜尼诺雷茨效应却得到了少量研究。</li>
<li>methods: 这篇论文使用 Gaussian denoising 建立了一种框架，用于研究 simulation-free continuous normalizing flows 的有效性。这种框架被称为 Gaussian interpolation flow，它可以确保流速场的 lipschitz 连续性、流存在和唯一性、流映射和时间反转映射的 lipschitz 连续性，以及目标分布的几种 riclass 的存在。</li>
<li>results: 这篇论文的结果表明，Gaussian interpolation flow 可以为 generative modeling 提供一种有理论基础的框架，并且可以确保这种框架的学习算法具有证明性。这些结论还探讨了这种流的稳定性和源分布的扰动。<details>
<summary>Abstract</summary>
Gaussian denoising has emerged as a powerful principle for constructing simulation-free continuous normalizing flows for generative modeling. Despite their empirical successes, theoretical properties of these flows and the regularizing effect of Gaussian denoising have remained largely unexplored. In this work, we aim to address this gap by investigating the well-posedness of simulation-free continuous normalizing flows built on Gaussian denoising. Through a unified framework termed Gaussian interpolation flow, we establish the Lipschitz regularity of the flow velocity field, the existence and uniqueness of the flow, and the Lipschitz continuity of the flow map and the time-reversed flow map for several rich classes of target distributions. This analysis also sheds light on the auto-encoding and cycle-consistency properties of Gaussian interpolation flows. Additionally, we delve into the stability of these flows in source distributions and perturbations of the velocity field, using the quadratic Wasserstein distance as a metric. Our findings offer valuable insights into the learning techniques employed in Gaussian interpolation flows for generative modeling, providing a solid theoretical foundation for end-to-end error analyses of learning GIFs with empirical observations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-a-Post-Market-Monitoring-Framework-for-Machine-Learning-based-Medical-Devices-A-case-study"><a href="#Towards-a-Post-Market-Monitoring-Framework-for-Machine-Learning-based-Medical-Devices-A-case-study" class="headerlink" title="Towards a Post-Market Monitoring Framework for Machine Learning-based Medical Devices: A case study"></a>Towards a Post-Market Monitoring Framework for Machine Learning-based Medical Devices: A case study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11463">http://arxiv.org/abs/2311.11463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jean Feng, Adarsh Subbaswamy, Alexej Gossmann, Harvineet Singh, Berkman Sahiner, Mi-Ok Kim, Gene Pennello, Nicholas Petrick, Romain Pirracchio, Fan Xia</li>
<li>for: 这 paper 的目的是提出一个系统性的框架，用于比较不同监测选项，以确保机器学习（ML）系统在临床实践中的性能不断监测。</li>
<li>methods: 这 paper 使用了 causal inference 和统计过程控制的工具，来定义候选监测标准、描述可能的偏见和 causal 模型，以及 specifying 和比较候选监测方法。</li>
<li>results: 这 paper 通过一个case study，探讨了一种 ML-based 风险预测算法，用于预测 POSToperative nausea and vomiting（PONV）。研究发现，使用 causal inference 可以 Address 其他偏见的源头，并且可以为更多的监测选项提供一个系统性的框架。<details>
<summary>Abstract</summary>
After a machine learning (ML)-based system is deployed in clinical practice, performance monitoring is important to ensure the safety and effectiveness of the algorithm over time. The goal of this work is to highlight the complexity of designing a monitoring strategy and the need for a systematic framework that compares the multitude of monitoring options. One of the main decisions is choosing between using real-world (observational) versus interventional data. Although the former is the most convenient source of monitoring data, it exhibits well-known biases, such as confounding, selection, and missingness. In fact, when the ML algorithm interacts with its environment, the algorithm itself may be a primary source of bias. On the other hand, a carefully designed interventional study that randomizes individuals can explicitly eliminate such biases, but the ethics, feasibility, and cost of such an approach must be carefully considered. Beyond the decision of the data source, monitoring strategies vary in the performance criteria they track, the interpretability of the test statistics, the strength of their assumptions, and their speed at detecting performance decay. As a first step towards developing a framework that compares the various monitoring options, we consider a case study of an ML-based risk prediction algorithm for postoperative nausea and vomiting (PONV). Bringing together tools from causal inference and statistical process control, we walk through the basic steps of defining candidate monitoring criteria, describing potential sources of bias and the causal model, and specifying and comparing candidate monitoring procedures. We hypothesize that these steps can be applied more generally, as causal inference can address other sources of biases as well.
</details>
<details>
<summary>摘要</summary>
après deployment d'un système d'apprentissage machine (ML) dans la pratique clinique, il est important de surveiller le performance pour garantir la sécurité et l'efficacité de l'algorithme au fil du temps. L'objectif de cette étude est de mettre en évidence la complexité de la stratégie de surveillance et la nécessité d'un framework systématique pour comparer les nombreuses options de surveillance. L'une des décisions les plus importantes est de choisir entre les données réelles (observationnelles) et les données intervenantes. Bien que les premières soient la source de données de surveillance la plus commode, elles présentent des biais bien connus, tels que la confusion, la sélection et la absence. En fait, lorsque l'algorithme ML interagit avec son environnement, l'algorithme peut être une source primaire de biais. D'un autre côté, un étude intervenant rigoureusement randomisée peut éliminer explicitement tels biais, mais la moralité, la faisabilité et le coût de telle approche doivent être soigneusement examinés. En dehors de la décision de la source de données, les stratégies de surveillance varient selon les critères de performance qu'elles suivent, l'interprétabilité des statistiques de test, les hypothèses sous-jacentes et leur capacité à détecter rapidement la décadence des performances. Comme premier pas vers le développement d'un framework qui compare les différentes options de surveillance, nous considérons un étude de cas d'un algorithme de prédiction de risque basé sur l'apprentissage machine pour la nausée et les vomissements postopératoires (PONV). En combinant des outils de la inference causale et de la contrôle statistique de processus, nous passons en revue les étapes de base pour définir les critères de surveillance candidate, décrire les sources potentielles de biais et le modèle causal, et spécifier et comparer des procédures de surveillance candidate. Nous hypothèsons que ces étapes peuvent être appliquées de manière plus générale, car l'inférence causale peut aborder d'autres sources de biais.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/cs.LG_2023_11_20/" data-id="clp89dois00w6i788hhl2bmpb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/eess.IV_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T09:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/eess.IV_2023_11_20/">eess.IV - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tubular-Curvature-Filter-Implicit-Pointwise-Curvature-Calculation-Method-for-Tubular-Objects"><a href="#Tubular-Curvature-Filter-Implicit-Pointwise-Curvature-Calculation-Method-for-Tubular-Objects" class="headerlink" title="Tubular Curvature Filter: Implicit Pointwise Curvature Calculation Method for Tubular Objects"></a>Tubular Curvature Filter: Implicit Pointwise Curvature Calculation Method for Tubular Objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11931">http://arxiv.org/abs/2311.11931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elifnur Sunger, Beyza Kalkanli, Veysi Yildiz, Tales Imbiriba, Peter Campbell, Deniz Erdogmus</li>
<li>for: 这篇论文是为了研究 curvature estimation method，尤其是在医疗领域中评估液体结构的折弯性的。</li>
<li>methods: 这篇论文提出了一种Tubular Curvature Filter方法，该方法基于Hessian矩阵的方向差分来计算杆形结构的当地曲率。</li>
<li>results: 实验结果表明，Tubular Curvature Filter方法可以准确地计算杆形结构的当地曲率。<details>
<summary>Abstract</summary>
Curvature estimation methods are important as they capture salient features for various applications in image processing, especially within medical domains where tortuosity of vascular structures is of significant interest. Existing methods based on centerline or skeleton curvature fail to capture curvature gradients across a rotating tubular structure. This paper presents a Tubular Curvature Filter method that locally calculates the acceleration of bundles of curves that traverse along the tubular object parallel to the centerline. This is achieved by examining the directional rate of change in the eigenvectors of the Hessian matrix of a tubular intensity function in space. This method implicitly calculates the local tubular curvature without the need to explicitly segment the tubular object. Experimental results demonstrate that the Tubular Curvature Filter method provides accurate estimates of local curvature at any point inside tubular structures.
</details>
<details>
<summary>摘要</summary>
Curvature estimation methods are important as they capture salient features for various applications in image processing, especially within medical domains where tortuosity of vascular structures is of significant interest. Existing methods based on centerline or skeleton curvature fail to capture curvature gradients across a rotating tubular structure. This paper presents a Tubular Curvature Filter method that locally calculates the acceleration of bundles of curves that traverse along the tubular object parallel to the centerline. This is achieved by examining the directional rate of change in the eigenvectors of the Hessian matrix of a tubular intensity function in space. This method implicitly calculates the local tubular curvature without the need to explicitly segment the tubular object. Experimental results demonstrate that the Tubular Curvature Filter method provides accurate estimates of local curvature at any point inside tubular structures.Here's the translation in Traditional Chinese:Curvature estimation methods are important as they capture salient features for various applications in image processing, especially within medical domains where tortuosity of vascular structures is of significant interest. Existing methods based on centerline or skeleton curvature fail to capture curvature gradients across a rotating tubular structure. This paper presents a Tubular Curvature Filter method that locally calculates the acceleration of bundles of curves that traverse along the tubular object parallel to the centerline. This is achieved by examining the directional rate of change in the eigenvectors of the Hessian matrix of a tubular intensity function in space. This method implicitly calculates the local tubular curvature without the need to explicitly segment the tubular object. Experimental results demonstrate that the Tubular Curvature Filter method provides accurate estimates of local curvature at any point inside tubular structures.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/eess.IV_2023_11_20/" data-id="clp89dope01dni78876zl2fcs" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_11_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/20/eess.SP_2023_11_20/" class="article-date">
  <time datetime="2023-11-20T08:00:00.000Z" itemprop="datePublished">2023-11-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/20/eess.SP_2023_11_20/">eess.SP - 2023-11-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tensor-based-Space-Debris-Detection-for-Satellite-Mega-constellations"><a href="#Tensor-based-Space-Debris-Detection-for-Satellite-Mega-constellations" class="headerlink" title="Tensor-based Space Debris Detection for Satellite Mega-constellations"></a>Tensor-based Space Debris Detection for Satellite Mega-constellations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11838">http://arxiv.org/abs/2311.11838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Olivier Daoust, Hasan Nayir, Irfan Azam, Antoine Lesage-Landry, Gunes Karabulut Kurt</li>
<li>for: 避免遥感器损坏和残留物的潜在威胁，提高遥感器遥感精度和可靠性。</li>
<li>methods: 使用 canonical polyadic（CP）tensor decomposition 方法，利用 THz 通道的稀疏性，检测遥感器附近的空间垃圾。</li>
<li>results: 对比 conventinal energy-based 检测方法，tensor-based 方法的检测效果更高。<details>
<summary>Abstract</summary>
Thousands of satellites, asteroids, and rocket bodies break, collide, or degrade, resulting in large amounts of space debris in low Earth orbit. The presence of space debris poses a serious threat to satellite mega-constellations and to future space missions. Debris can be avoided if detected within the safety range of a satellite. In this paper, an integrated sensing and communication technique is proposed to detect space debris for satellite mega-constellations. The canonical polyadic (CP) tensor decomposition method is used to estimate the rank of the tensor that denotes the number of paths including line-of-sight and non-line-of-sight by exploiting the sparsity of THz channel with limited scattering. The analysis reveals that the reflected signals of the THz can be utilized for the detection of space debris. The CP decomposition is cast as an optimization problem and solved using the alternating least square (ALS) algorithm. Simulation results show that the probability of detection of the proposed tensor-based scheme is higher than the conventional energy-based detection scheme for the space debris detection.
</details>
<details>
<summary>摘要</summary>
低地球轨道内有千计卫星、小行星和火箭残余物撞击或坏损，导致空间垃圾堆积。空间垃圾对卫星宏和未来太空任务构成严重威胁。如果探测到空间垃圾的范围内，可以避免垃圾。在这篇论文中，一种集成感知和通信技术是提出来探测卫星宏中的空间垃圾。使用Canonical Polyadic（CP）张量分解法来估算THz通道中折射的数量。分析表明THz反射信号可以用于空间垃圾探测。CP分解被表示为优化问题，并使用 alternate least squares（ALS）算法解决。 simulation结果表明，提案的张量基于方案的检测 probrability 高于传统能量基于方案。
</details></li>
</ul>
<hr>
<h2 id="Movable-Antenna-Array-Enabled-Wireless-Communication-with-CoMP-Reception"><a href="#Movable-Antenna-Array-Enabled-Wireless-Communication-with-CoMP-Reception" class="headerlink" title="Movable-Antenna Array-Enabled Wireless Communication with CoMP Reception"></a>Movable-Antenna Array-Enabled Wireless Communication with CoMP Reception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11814">http://arxiv.org/abs/2311.11814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guojie Hu, Qingqing Wu, Jian Ouyang, Kui Xu, Yunlong Cai, Naofal Al-Dhahir</li>
<li>for: 提高无线通信系统的效果signal-to-noise ratio（SNR），通过协同接收和发射扩散的最大比率组合技术。</li>
<li>methods: 使用协调多点接收（CoMP）技术，并jointly optimize transmit beamforming和移动天线数组的位置，以优化接收信号质量。</li>
<li>results: 通过分析 hermite channel matrix的主要特征值，实现高效的接收信号质量提高。并且，通过关键性分析，找到了一个计算效率高的算法。<details>
<summary>Abstract</summary>
We consider the movable antenna (MA) array-enabled wireless communication with coordinate multi-point (CoMP) reception, where multiple destinations adopt the maximal ratio combination technique to jointly decode the common message sent from the transmitter equipped with the MA array. Our goal is to maximize the effective received signal-to-noise ratio, by jointly optimizing the transmit beamforming and the positions of the MA array. Although the formulated problem is highly non-convex, we reveal that it is fundamental to maximize the principal eigenvalue of a hermite channel matrix which is a function of the positions of the MA array. The corresponding sub-problem is still non-convex, for which we develop a computationally efficient algorithm. Afterwards, the optimal transmit beamforming is determined with a closed-form solution. In addition, the theoretical performance upper bound is analyzed. Since the MA array brings an additional spatial degree of freedom by flexibly adjusting all antennas' positions, it achieves significant performance gain compared to competitive benchmarks.
</details>
<details>
<summary>摘要</summary>
我们考虑了可动天线（MA）数组启用的无线通信，并使用均值多点接收（CoMP）技术，多个目标使用最大比率组合技术对共享发送器装备有MA数组的共同解码通信。我们的目标是最大化接收信号噪声比，通过同时优化发送扫描和MA数组的位置。虽然问题表述具有非凸性，但我们发现，最大化 hermite通道矩阵的主要特征值是MA数组位置函数。相应的子问题仍然是非凸性问题，我们开发了计算效率高的算法。然后，最佳发送扫描是通过关闭式解决方案确定的。此外，我们还分析了理论性能Upper bound。由于MA数组可以通过调整所有天线的位置，获得额外的空间度量，因此与竞争对照方案相比，它具有显著的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Robust-Multidimentional-Chinese-Remainder-Theorem-for-Integer-Vector-Reconstruction"><a href="#Robust-Multidimentional-Chinese-Remainder-Theorem-for-Integer-Vector-Reconstruction" class="headerlink" title="Robust Multidimentional Chinese Remainder Theorem for Integer Vector Reconstruction"></a>Robust Multidimentional Chinese Remainder Theorem for Integer Vector Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11804">http://arxiv.org/abs/2311.11804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Xiao, Haiye Huo, Xiang-Gen Xia</li>
<li>for: robustly reconstructing an integer vector from its erroneous remainders in multidimensional signal processing</li>
<li>methods: using a robust multidimensional Chinese remainder theorem (CRT) for a general set of moduli, with necessary and sufficient conditions on the difference between paired remainder errors and a sufficient condition on the remainder error bound</li>
<li>results: a closed-form reconstruction algorithm and successful validation through numerical simulations, as well as application to MD sinusoidal frequency estimation based on multiple sub-Nyquist samplers.<details>
<summary>Abstract</summary>
The problem of robustly reconstructing an integer vector from its erroneous remainders appears in many applications in the field of multidimensional (MD) signal processing. To address this problem, a robust MD Chinese remainder theorem (CRT) was recently proposed for a special class of moduli, where the remaining integer matrices left-divided by a greatest common left divisor (gcld) of all the moduli are pairwise commutative and coprime. The strict constraint on the moduli limits the usefulness of the robust MD-CRT in practice. In this paper, we investigate the robust MD-CRT for a general set of moduli. We first introduce a necessary and sufficient condition on the difference between paired remainder errors, followed by a simple sufficient condition on the remainder error bound, for the robust MD-CRT for general moduli, where the conditions are associated with (the minimum distances of) these lattices generated by gcld's of paired moduli, and a closed-form reconstruction algorithm is presented. We then generalize the above results of the robust MD-CRT from integer vectors/matrices to real ones. Finally, we validate the robust MD-CRT for general moduli by employing numerical simulations, and apply it to MD sinusoidal frequency estimation based on multiple sub-Nyquist samplers.
</details>
<details>
<summary>摘要</summary>
“多维（MD）信号处理中的一个问题是从其不正确的余数中恢复整数ベクトル。为解决这个问题，一个robust MD中国剩 Theatre（CRT）已经被提出，但这个严格的模拟限制了实际应用中的使用。在本文中，我们调查了robust MD-CRT的一般模拟。我们首先引入了对于对掌握余数之间的差异的必要和充分条件，以及一个简单的充分条件，它与余数误差的上限有关，并且提出了一个关于这些权子生成的矩阵的关系。然后，我们将这些结果扩展到实数ベクトル/矩阵上。最后，我们透过数值仿真验证了robust MD-CRT的一般模拟，并将其应用到多sub-Nyquist采样器中的MD数律频率估计。”
</details></li>
</ul>
<hr>
<h2 id="A-Zero-Forcing-Approach-for-the-RIS-Aided-MIMO-Broadcast-Channel"><a href="#A-Zero-Forcing-Approach-for-the-RIS-Aided-MIMO-Broadcast-Channel" class="headerlink" title="A Zero-Forcing Approach for the RIS-Aided MIMO Broadcast Channel"></a>A Zero-Forcing Approach for the RIS-Aided MIMO Broadcast Channel</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11769">http://arxiv.org/abs/2311.11769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Semmler, Michael Joham, Wolfgang Utschick</li>
<li>for: 提高多用户智能表面受限制的多输入多出力广播通道的吞吐量 Spectral Efficiency (SE)</li>
<li>methods: 采用零强制方法，实现用户分配，计算独立于智能表面元素数量</li>
<li>results: 比其他线性 precoding 算法具有更高的吞吐量表现，但具有较低的复杂度<details>
<summary>Abstract</summary>
We present efficient algorithms for the sum-spectral efficiency (SE) maximization of the multi-user reconfigurable intelligent surface (RIS)-aided multiple-input multiple-output (MIMO) broadcast channel based on a zero-forcing approach. These methods conduct a user allocation for which the computation is independent of the number of elements at the RIS, that is usually large. Specifically, two algorithms are given that exploit the line-of-sight (LOS) structure between the base station (BS) and the RIS. Simulations show superior SE performance compared to other linear precoding algorithms but with lower complexity.
</details>
<details>
<summary>摘要</summary>
我们提出了高效的算法，用于实现多用户智能表面帮助多输入多出力广播通道的总spectral efficiency（SE）最大化，基于零强制方法。这些方法实现了用户分配，computation是独立于智能表面元素的数量。具体而言，我们提出了两种算法，利用基站（BS）与智能表面之间的直线视线结构。实验结果显示我们的算法具有较高的SE性能，但与其他线性干扰算法相比，复杂度较低。
</details></li>
</ul>
<hr>
<h2 id="AIaaS-for-ORAN-based-6G-Networks-Multi-time-scale-slice-resource-management-with-DRL"><a href="#AIaaS-for-ORAN-based-6G-Networks-Multi-time-scale-slice-resource-management-with-DRL" class="headerlink" title="AIaaS for ORAN-based 6G Networks: Multi-time scale slice resource management with DRL"></a>AIaaS for ORAN-based 6G Networks: Multi-time scale slice resource management with DRL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11668">http://arxiv.org/abs/2311.11668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suvidha Mhatre, Ferran Adelantado, Kostas Ramantas, Christos Verikoukis<br>for:The paper is written for the purpose of addressing how to handle slice resources for 6G networks at different time scales.methods:The proposed solution uses artificial intelligence (AI) at the edge of the network and applies two control-level loops to obtain optimal performance. The ORAN facilitates programmable network architectures to support multi-time scale management using AI approaches.results:The proposed algorithms analyze the maximum utilization of resources from slice performance to take decisions at the inter-slice level. Inter-slice intelligent agents work at a non-real-time level to reconfigure resources within various slices. The results show improved performance for enhanced mobile broadband (eMBB), ultra-reliable low latency (URLLC), and massive machine type communication (mMTC) slice categories.Here is the simplified Chinese text version of the three key information points:for:这篇论文是为了解决6G网络中 slice 资源的管理问题，特别是在不同时间尺度上。methods:提议的解决方案使用了网络边缘的人工智能（AI），并使用了两个控制循环来实现最佳性能。 ORAN 支持可编程网络架构，以便在不同时间尺度上进行多级别管理。results:提议的算法可以分析slice的最大资源利用率，从slice性能来做决策。间 slice 智能代理在非实时层进行资源重配置。 results 表明，对于提高了mobile broadband（eMBB）、ultra-reliable low latency（URLLC）和massive machine type communication（mMTC） slice 类型的性能提高。<details>
<summary>Abstract</summary>
This paper addresses how to handle slice resources for 6G networks at different time scales in an architecture based on an open radio access network (ORAN). The proposed solution includes artificial intelligence (AI) at the edge of the network and applies two control-level loops to obtain optimal performance compared to other techniques. The ORAN facilitates programmable network architectures to support such multi-time scale management using AI approaches. The proposed algorithms analyze the maximum utilization of resources from slice performance to take decisions at the inter-slice level. Inter-slice intelligent agents work at a non-real-time level to reconfigure resources within various slices. Further than meeting the slice requirements, the intra-slice objective must also include the minimization of maximum resource utilization. This enables smart utilization of the resources within each slice without affecting slice performance. Here, each xApp that is an intra-slice agent aims at meeting the optimal QoS of the users, but at the same time, some inter-slice objectives should be included to coordinate intra- and inter-slice agents. This is done without penalizing the main intra-slice objective. All intelligent agents use deep reinforcement learning (DRL) algorithms to meet their objectives. We have presented results for enhanced mobile broadband (eMBB), ultra-reliable low latency (URLLC), and massive machine type communication (mMTC) slice categories.
</details>
<details>
<summary>摘要</summary>
The proposed algorithms analyze the maximum utilization of resources from a slice performance perspective to make decisions at the inter-slice level. Inter-slice intelligent agents operate at a non-real-time level to dynamically reconfigure resources within various slices. The intra-slice objective is to minimize the maximum resource utilization, which enables smart resource utilization within each slice without affecting slice performance.Each xApp, or intra-slice agent, aims to meet the optimal quality of service (QoS) requirements of users while coordinating with inter-slice objectives. This is achieved without penalizing the main intra-slice objective. All intelligent agents use deep reinforcement learning (DRL) algorithms to meet their objectives.The paper presents results for enhanced mobile broadband (eMBB), ultra-reliable low latency (URLLC), and massive machine type communication (mMTC) slice categories.
</details></li>
</ul>
<hr>
<h2 id="RIS-Parametrized-Rich-Scattering-Environments-Physics-Compliant-Models-Channel-Estimation-and-Optimization"><a href="#RIS-Parametrized-Rich-Scattering-Environments-Physics-Compliant-Models-Channel-Estimation-and-Optimization" class="headerlink" title="RIS-Parametrized Rich-Scattering Environments: Physics-Compliant Models, Channel Estimation, and Optimization"></a>RIS-Parametrized Rich-Scattering Environments: Physics-Compliant Models, Channel Estimation, and Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11651">http://arxiv.org/abs/2311.11651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp del Hougne</li>
<li>for: 这篇论文旨在探讨如何使用可配置智能表面（RIS）来控制复杂的雨射环境，包括indoor和factory等实际场景。</li>
<li>methods: 论文使用物理模型来 parametrise rich-scattering 环境，并利用这些参数来优化RIS的配置。</li>
<li>results: 论文总结了当前领域的最新进展，包括如何使用 physics-compliant 模型来open-loop控制RIS-parametrized rich-scattering 环境。<details>
<summary>Abstract</summary>
The tunability of radio environments with reconfigurable intelligent surfaces (RISs) enables the paradigm of smart radio environments in which wireless system engineers are no longer limited to only controlling the radiated signals but can in addition also optimize the wireless channels. Many practical radio environments include complex scattering objects, especially indoor and factory settings. Multipath propagation therein creates seemingly intractable coupling effects between RIS elements, leading to the following questions: How can a RIS-parametrized rich-scattering environment be modelled in a physics-compliant manner? Can the parameters of such a model be estimated for a specific but unknown experimental environment? And how can the RIS configuration be optimized given a calibrated physics-compliant model? This chapter summarizes the current state of the art in this field, highlighting the recently unlocked potential of frugal physical-model-based open-loop control of RIS-parametrized rich-scattering radio environments.
</details>
<details>
<summary>摘要</summary>
Radio 环境的可调性，使得无线系统工程师不再只能控制发射的信号，还可以优化无线通道。许多实际的无线环境具有复杂的散射物，特别是室内和工厂设置。多path传播会导致RIS元素之间的互相干扰，从而提出以下问题：如何在物理学上合理地模型RIS参数化的贫 scattering 环境？可以在不知道实际环境中对RIS配置进行优化吗？这章总结了当前领域的最新进展，强调最近解锁了基于Physics-based open-loop控制的RIS参数化贫 scattering 无线环境的潜力。
</details></li>
</ul>
<hr>
<h2 id="High-performance-cVEP-BCI-under-minimal-calibration"><a href="#High-performance-cVEP-BCI-under-minimal-calibration" class="headerlink" title="High-performance cVEP-BCI under minimal calibration"></a>High-performance cVEP-BCI under minimal calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11596">http://arxiv.org/abs/2311.11596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yining Miao, Nanlin Shi, Changxing Huang, Yonghao Song, Xiaogang Chen, Yijun Wang, Xiaorong Gao</li>
<li>for: 提高 code-modulated visual evoked potential-based 脑机接口 (cVEP-BCI) 的高速性能，对于需要实时处理的应用而言非常重要。</li>
<li>methods: 使用简洁的单发目标断续，将普通的 spatial-temporal 模式提取出来，并使用这些数据进行线性模型化或跨主体数据的转移学习，以建立 cVEP 的时间模式。</li>
<li>results: 在几分钟的准确调整后，获得了 250 bpm 的资讯传输率，与现有的 SSVEP 模式相当。这些结果显示了 cVEP-BCI 的高速性能可以在几分钟内得到改进，这将有助于扩展 cVEP-BCI 的实际应用。<details>
<summary>Abstract</summary>
The ultimate goal of brain-computer interfaces (BCIs) based on visual modulation paradigms is to achieve high-speed performance without the burden of extensive calibration. Code-modulated visual evoked potential-based BCIs (cVEP-BCIs) modulated by broadband white noise (WN) offer various advantages, including increased communication speed, expanded encoding target capabilities, and enhanced coding flexibility. However, the complexity of the spatial-temporal patterns under broadband stimuli necessitates extensive calibration for effective target identification in cVEP-BCIs. Consequently, the information transfer rate (ITR) of cVEP-BCI under limited calibration usually stays around 100 bits per minute (bpm), significantly lagging behind state-of-the-art steady-state visual evoked potential-based BCIs (SSVEP-BCIs), which achieve rates above 200 bpm. To enhance the performance of cVEP-BCIs with minimal calibration, we devised an efficient calibration stage involving a brief single-target flickering, lasting less than a minute, to extract generalizable spatial-temporal patterns. Leveraging the calibration data, we developed two complementary methods to construct cVEP temporal patterns: the linear modeling method based on the stimulus sequence and the transfer learning techniques using cross-subject data. As a result, we achieved the highest ITR of 250 bpm under a minute of calibration, which has been shown to be comparable to the state-of-the-art SSVEP paradigms. In summary, our work significantly improved the cVEP performance under few-shot learning, which is expected to expand the practicality and usability of cVEP-BCIs.
</details>
<details>
<summary>摘要</summary>
BCIs基于视觉调制 paradigm的最终目标是实现高速性，无需耗费大量的调制。基于广泛白噪音（WN）的 cVEP-BCIs 具有多种优点，包括提高的通信速度、扩展的编码目标能力和提高的编码flexibility。然而，在广泛噪音下的空间-时间模式复杂度需要大量的调制，以便有效地标识目标在 cVEP-BCIs 中。因此，cVEP-BCI 的信息传输率（ITR）通常在受限制的调制下保持在 100 bits per minute（bpm）级别，远远落后于现有的 SSVEP-BCIs，它们的 ITR 高于 200 bpm。为了提高 cVEP-BCIs 的性能，我们设计了一种高效的快速寻址阶段，使用了 fewer than a minute 的快速寻址，以提取可 reuse 的空间-时间模式。通过使用寻址数据，我们开发了两种补充方法来构建 cVEP 时间模式：基于刺激序列的直线模型法和使用交叉主题数据的转移学习技术。因此，我们实现了最高的 ITR 250 bpm，在受限制的调制下，这个数据已经被证明与现有的 SSVEP 方法相当。总之，我们的工作有效地提高了 cVEP 性能，这种性能可以扩大 BCIs 的实际应用和使用性。
</details></li>
</ul>
<hr>
<h2 id="Joint-Design-of-ISAC-Waveform-under-PAPR-Constraints"><a href="#Joint-Design-of-ISAC-Waveform-under-PAPR-Constraints" class="headerlink" title="Joint Design of ISAC Waveform under PAPR Constraints"></a>Joint Design of ISAC Waveform under PAPR Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11594">http://arxiv.org/abs/2311.11594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yating Chen, Cai Wen, Yan Huang, Le Liang, Jie Li, Hui Zhang, Wei Hong</li>
<li>For: The paper is written for integrated sensing and communication (ISAC) systems, and it aims to design a dual-function waveform that can simultaneously achieve good communication quality of service (QoS) and sensing performance.* Methods: The paper formulates the precoding problem as a non-convex quadratically constrained quadratic program (QCQP), and proposes an efficient algorithm based on alternating direction method of multipliers (ADMM) to solve it. The algorithm decouples multiple variables and provides a closed-form solution for each subproblem. Additionally, the paper proposes a new criteria to design the ideal radar waveform, which minimizes the integrated sidelobe level of the ambiguity function in each target direction.* Results: The designed dual-function waveform is capable of offering good communication QoS and sensing performance, as demonstrated by numerical results. The waveform is able to reduce the peak-to-average power ratio (PAPR) and improve the sensing performance in both spatial and temporal domains.<details>
<summary>Abstract</summary>
In this paper, we formulate the precoding problem of integrated sensing and communication (ISAC) waveform as a non-convex quadratically constrainted quadratic program (QCQP), in which the weighted sum of communication multi-user interference (MUI) and the gap between dual-use waveform and ideal radar waveform is minimized with peak-to-average power ratio (PAPR) constraints. We propose an efficient algorithm based on alternating direction method of multipliers (ADMM), which is able to decouple multiple variables and provide a closed-form solution for each subproblem. In addition, to improve the sensing performance in both spatial and temporal domains, we propose a new criteria to design the ideal radar waveform, in which the beam pattern is made similar to the ideal one and the integrated sidelobe level of the ambiguity function in each target direction is minimized in the region of interest. The limited memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is applied to the design of the ideal radar waveform which works as a reference in the design of the dual-function waveform. Numerical results indicate that the designed dual-function waveform is capable of offering good communication quality of service (QoS) and sensing performance.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们将集成感知通信（ISAC）波形的预编码问题形式化为非对称卷积约束 quadratic program（QCQP），其中通信多用户干扰（MUI）的Weighted sum和杂杂波形与理想雷达波形之间的差异被最小化，同时受限于峰峰均值功率比（PAPR）的约束。我们提出了一种高效的 alternating direction method of multipliers（ADMM）算法，可以分解多个变量并提供关闭式解决方案。此外，为了在空间和时域频率域中提高感知性能，我们提出了一种新的理想雷达波形设计标准，其中镜像干扰的杂杂波形在兴趣区域具有最小化的杂杂波形级别。使用limited memory Broyden-Fletcher-Goldfarb-Shanno（L-BFGS）算法来设计理想雷达波形，该波形作为参考参照在设计双功能波形。数值结果表明，设计的双功能波形能够提供良好的通信质量服务（QoS）和感知性能。
</details></li>
</ul>
<hr>
<h2 id="Asymptotic-CRB-Analysis-of-Random-RIS-Assisted-Large-Scale-Localization-Systems"><a href="#Asymptotic-CRB-Analysis-of-Random-RIS-Assisted-Large-Scale-Localization-Systems" class="headerlink" title="Asymptotic CRB Analysis of Random RIS-Assisted Large-Scale Localization Systems"></a>Asymptotic CRB Analysis of Random RIS-Assisted Large-Scale Localization Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11582">http://arxiv.org/abs/2311.11582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyu Wang, Hongzheng Liu, Rujing Xiong, Fuhai Wang, Robert Caiming Qiu</li>
<li>for: 本文研究了一种随机RIS协助的多target地位系统的性能，其中RIS的配置采用随机设置，以避免高复杂度优化。</li>
<li>methods: 我们首先关注了RIS元素数量很大的情况，然后得到了CRB下降的幂级关系，其中CRB下降在RIS维度增加的第三或第四级。然后，我们推广我们的分析至大规模系统，其中目标和探测器的数量都很多。在这种情况下，我们explore了两种常见RIS模型：常量模块模型和дискре频谱模型，并解释了随机RIS配置对CRB的影响。</li>
<li>results: 数值结果表明，在我们提posed的随机RIS系统中， asymptotic formula提供了好的approximation于准确CRB。<details>
<summary>Abstract</summary>
This paper studies the performance of a randomly RIS-assisted multi-target localization system, in which the configurations of the RIS are randomly set to avoid high-complexity optimization. We first focus on the scenario where the number of RIS elements is significantly large, and then obtain the scaling law of Cram\'er-Rao bound (CRB) under certain conditions, which shows that CRB decreases in the third or fourth order as the RIS dimension increases. Second, we extend our analysis to large systems where both the number of targets and sensors is substantial. Under this setting, we explore two common RIS models: the constant module model and the discrete amplitude model, and illustrate how the random RIS configuration impacts the value of CRB. Numerical results demonstrate that asymptotic formulas provide a good approximation to the exact CRB in the proposed randomly configured RIS systems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Effective-throughput-of-Shadowed-Beaulieu-Xie-fading-channel"><a href="#On-the-Effective-throughput-of-Shadowed-Beaulieu-Xie-fading-channel" class="headerlink" title="On the Effective throughput of Shadowed Beaulieu-Xie fading channel"></a>On the Effective throughput of Shadowed Beaulieu-Xie fading channel</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11521">http://arxiv.org/abs/2311.11521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manpreet Kaur, Sandeep Kumar, Poonam Yadav, Puspraj Singh Chauhan</li>
<li>for:  investigate data rate performance across various fading scenarios and analyze the effective throughput of the shadowed Beaulieu-Xie (SBX) composite fading channel.</li>
<li>methods: use PDF-based approach to derive simplified relationships between performance parameters and channel parameters, and evaluate the impact of system parameters on effective throughput.</li>
<li>results: deduce equations for effective throughput and investigate the impact of delay parameter on error correction. Monte-Carlo simulations verify the accuracy of the deduced equations.<details>
<summary>Abstract</summary>
Given the imperative for advanced wireless networks in the next generation and the rise of real-time applications within wireless communication, there is a notable focus on investigating data rate performance across various fading scenarios. This research delved into analyzing the effective throughput of the shadowed Beaulieu-Xie (SBX) composite fading channel using the PDF-based approach. To get the simplified relationship between the performance parameter and channel parameters, the low-SNR and the high-SNR approximation of the effective rate are also provided. The proposed formulations are evaluated for different values of system parameters to study their impact on the effective throughput. Also, the impact of the delay parameter on the EC is investigated. Monte-Carlo simulations are used to verify the facticity of the deduced equations.
</details>
<details>
<summary>摘要</summary>
Next-generation wireless networks require advanced technology, and real-time applications within wireless communication are becoming increasingly important. As a result, researchers are investigating data rate performance in various fading scenarios. This study focuses on the effective throughput of the shadowed Beaulieu-Xie (SBX) composite fading channel using the PDF-based approach. To simplify the relationship between performance parameters and channel parameters, the study also provides low-SNR and high-SNR approximations of the effective rate. The proposed formulations are evaluated for different system parameter values to study their impact on effective throughput. Additionally, the study investigates the impact of the delay parameter on the error correction (EC) performance. Monte-Carlo simulations are used to verify the accuracy of the derived equations.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/20/eess.SP_2023_11_20/" data-id="clp89dor801hxi788bm5o0l7r" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_11_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/19/cs.SD_2023_11_19/" class="article-date">
  <time datetime="2023-11-19T15:00:00.000Z" itemprop="datePublished">2023-11-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/19/cs.SD_2023_11_19/">cs.SD - 2023-11-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Encoding-Performance-Data-in-MEI-with-the-Automatic-Music-Performance-Analysis-and-Comparison-Toolkit-AMPACT"><a href="#Encoding-Performance-Data-in-MEI-with-the-Automatic-Music-Performance-Analysis-and-Comparison-Toolkit-AMPACT" class="headerlink" title="Encoding Performance Data in MEI with the Automatic Music Performance Analysis and Comparison Toolkit (AMPACT)"></a>Encoding Performance Data in MEI with the Automatic Music Performance Analysis and Comparison Toolkit (AMPACT)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11363">http://arxiv.org/abs/2311.11363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Johanna Devaney, Cecilia Beauchamp</li>
<li>for: 这篇论文是用于描述一种使用\texttt{<extData>}元素来编码表演数据的新方法。</li>
<li>methods: 该方法使用了Automatic Music Performance Analysis and Comparison Toolkit（AMPACT）来提取表演数据，并将其编码为JSON对象，链接到特定的乐谱符号中的\texttt{<extData>}元素。</li>
<li>results: 该研究用了一组流行音乐 vocals 来示例，并在absence of a fully specified musical score中使用AMPACT来提取表演数据，以展示\texttt{<extData>}元素可以编码的描述范围和AMPACT的应用 potential。<details>
<summary>Abstract</summary>
This paper presents a new method of encoding performance data in MEI using the recently added \texttt{<extData>} element. Performance data was extracted using the Automatic Music Performance Analysis and Comparison Toolkit (AMPACT) and encoded as a JSON object within an \texttt{<extData>} element linked to a specific musical note. A set of pop music vocals has was encoded to demonstrate both the range of descriptors that can be encoded in <extData> and how AMPACT can be used for extracting performance data in the absence of a fully specified musical score.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这篇论文介绍了一种使用MEI中新增的\texttt{<extData>}元素来编码表现数据的方法。表现数据由Automatic Music Performance Analysis and Comparison Toolkit（AMPACT）提取，并以JSON对象的形式在\texttt{<extData>}元素中链接到特定的音符。为了展示\texttt{<extData>}中可以编码的描述符范围和如何使用AMPACT来提取表现数据，一组流行音乐 vocals 被编码。
</details></li>
</ul>
<hr>
<h2 id="M-2-UGen-Multi-modal-Music-Understanding-and-Generation-with-the-Power-of-Large-Language-Models"><a href="#M-2-UGen-Multi-modal-Music-Understanding-and-Generation-with-the-Power-of-Large-Language-Models" class="headerlink" title="M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models"></a>M$^{2}$UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11255">http://arxiv.org/abs/2311.11255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atin Sakkeer Hussain, Shansong Liu, Chenshuo Sun, Ying Shan</li>
<li>for: 本研究旨在探讨利用大型自然语言模型（LLM）来理解和生成不同modalities的音乐。</li>
<li>methods: 我们提出了一个多模态音乐理解和生成框架（M$^{2}$UGen），利用预训练的MERT、ViT和ViViT模型来涵盖音乐、图像和视频等多种modalities。我们还使用AudioLDM 2和MusicGen来实现音乐生成。</li>
<li>results: 我们进行了严格的实验评估，结果表明我们的模型可以达到或超越当前状态的艺术模型的性能。<details>
<summary>Abstract</summary>
The current landscape of research leveraging large language models (LLMs) is experiencing a surge. Many works harness the powerful reasoning capabilities of these models to comprehend various modalities, such as text, speech, images, videos, etc. They also utilize LLMs to understand human intention and generate desired outputs like images, videos, and music. However, research that combines both understanding and generation using LLMs is still limited and in its nascent stage. To address this gap, we introduce a Multi-modal Music Understanding and Generation (M$^{2}$UGen) framework that integrates LLM's abilities to comprehend and generate music for different modalities. The M$^{2}$UGen framework is purpose-built to unlock creative potential from diverse sources of inspiration, encompassing music, image, and video through the use of pretrained MERT, ViT, and ViViT models, respectively. To enable music generation, we explore the use of AudioLDM 2 and MusicGen. Bridging multi-modal understanding and music generation is accomplished through the integration of the LLaMA 2 model. Furthermore, we make use of the MU-LLaMA model to generate extensive datasets that support text/image/video-to-music generation, facilitating the training of our M$^{2}$UGen framework. We conduct a thorough evaluation of our proposed framework. The experimental results demonstrate that our model achieves or surpasses the performance of the current state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
现在研究利用大型语言模型（LLM）的领域正在繁荣。许多研究利用这些模型的强大理解能力来理解不同modalities，如文本、语音、图片、视频等。它们还利用LLM来理解人类意图并生成所需的输出，如图片、视频和音乐。然而， combining理解和生成使用LLM的研究仍处于初 stages。为了解决这 gap，我们介绍了一个多modal音乐理解和生成（M$^{2}$UGen）框架，它将 integrate LLM的理解和生成音乐能力。M$^{2}$UGen框架是为了解锁多种灵感源的创造力，包括音乐、图片和视频，通过使用预训练的 MERT、ViT 和 ViViT 模型。为了生成音乐，我们探索了 AudioLDM 2 和 MusicGen 的使用。将多modal理解和音乐生成 bridge 是通过 integrate LLaMA 2 模型完成的。此外，我们使用 MU-LLaMA 模型生成了较 extensive的数据集，以支持文本/图片/视频到音乐生成，这有助于我们的 M$^{2}$UGen 框架的训练。我们进行了严格的评估我们的提议的框架。实验结果表明，我们的模型可以达到或超越当前状态的艺术模型的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/19/cs.SD_2023_11_19/" data-id="clp89dokw012ei788axh4an5f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_11_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/19/eess.AS_2023_11_19/" class="article-date">
  <time datetime="2023-11-19T14:00:00.000Z" itemprop="datePublished">2023-11-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/19/eess.AS_2023_11_19/">eess.AS - 2023-11-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Label-Synchronous-Neural-Transducer-for-Adaptable-Online-E2E-Speech-Recognition"><a href="#Label-Synchronous-Neural-Transducer-for-Adaptable-Online-E2E-Speech-Recognition" class="headerlink" title="Label-Synchronous Neural Transducer for Adaptable Online E2E Speech Recognition"></a>Label-Synchronous Neural Transducer for Adaptable Online E2E Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11353">http://arxiv.org/abs/2311.11353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keqi Deng, Philip C. Woodland</li>
<li>for: 提高自动Speech认知（ASR）的泛化能力，适应不同语言和环境。</li>
<li>methods: 使用 Label-synchronous neural transducer（LS-Transducer），通过文本数据进行适应。LS-Transducer提取了标签水平的encoder表示，并将其与预测网络输出结合。这使得预测网络可以轻松地适应文本数据，同时保持低延迟操作。</li>
<li>results: 相比标准神经激发器，提出的LS-Transducer在LibriSpeech内部数据上提供了12.9%的相对WRER减少（WERR），以及21.4%和24.6%的相对WRER减少在跨频数据上，并且可以适应不同语言和环境。<details>
<summary>Abstract</summary>
Although end-to-end (E2E) automatic speech recognition (ASR) has shown state-of-the-art recognition accuracy, it tends to be implicitly biased towards the training data distribution which can degrade generalisation. This paper proposes a label-synchronous neural transducer (LS-Transducer), which provides a natural approach to domain adaptation based on text-only data. The LS-Transducer extracts a label-level encoder representation before combining it with the prediction network output. Since blank tokens are no longer needed, the prediction network performs as a standard language model, which can be easily adapted using text-only data. An Auto-regressive Integrate-and-Fire (AIF) mechanism is proposed to generate the label-level encoder representation while retaining low latency operation that can be used for streaming. In addition, a streaming joint decoding method is designed to improve ASR accuracy while retaining synchronisation with AIF. Experiments show that compared to standard neural transducers, the proposed LS-Transducer gave a 12.9% relative WER reduction (WERR) for intra-domain LibriSpeech data, as well as 21.4% and 24.6% relative WERRs on cross-domain TED-LIUM 2 and AESRC2020 data with an adapted prediction network.
</details>
<details>
<summary>摘要</summary>
尽管结束到终端（E2E）自动语音识别（ASR）已经显示出了状态前的识别精度，但它往往会受到训练数据分布的隐藏偏见，这可能会降低总体化。这篇论文提议了一种 Label-同步神经转化器（LS-Transducer），它提供了一种自然的领域适应方法，基于文本Only的数据。LS-Transducer 提取了标签水平编码表示 Before 将其与预测网络输出结合。由于没有任何空格符 anymore，预测网络可以 acted as 标准的自然语言模型，可以轻松地适应文本Only 数据。一种 Auto-regressive Integrate-and-Fire （AIF）机制是提出来了，以实现生成标签水平编码表示，同时保持低延迟操作，可以用于流处理。此外，一种流处理共同解码方法是设计来提高 ASR 精度，同时保持与 AIF 的同步。实验结果显示，与标准神经转化器相比，提posed LS-Transducer 在内部频率 LibriSpeech 数据上提供了12.9% 的相对 WER 减少（WERR），以及21.4% 和24.6% 的相对 WERR 在跨频率 TED-LIUM 2 和 AESRC2020 数据上，并且需要一个适应预测网络。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/19/eess.AS_2023_11_19/" data-id="clp89domh0169i7887j89b1bo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_11_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/11/19/cs.CV_2023_11_19/" class="article-date">
  <time datetime="2023-11-19T13:00:00.000Z" itemprop="datePublished">2023-11-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/11/19/cs.CV_2023_11_19/">cs.CV - 2023-11-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improved-Defect-Detection-and-Classification-Method-for-Advanced-IC-Nodes-by-Using-Slicing-Aided-Hyper-Inference-with-Refinement-Strategy"><a href="#Improved-Defect-Detection-and-Classification-Method-for-Advanced-IC-Nodes-by-Using-Slicing-Aided-Hyper-Inference-with-Refinement-Strategy" class="headerlink" title="Improved Defect Detection and Classification Method for Advanced IC Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy"></a>Improved Defect Detection and Classification Method for Advanced IC Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11439">http://arxiv.org/abs/2311.11439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vic De Ridder, Bappaditya Dey, Victor Blanco, Sandip Halder, Bartel Van Waeyenberge</li>
<li>for: 提高高 numerical aperture EUVL 领域中小 defect 的检测精度</li>
<li>methods: 使用 Slicing Aided Hyper Inference (SAHI) 框架，对大小增加的 SEM 图像进行推理，提高检测小 defect 的效果</li>
<li>results: 在 previously investigated 半导体数据集上，SAHI 方法可以提高小 defect 的检测精度约 2x，并在新的测试数据集上实现了缺陷free 检测率，而未经训练的模型失败了。此外，提出了一种不会 significatively 降低 true positive 预测的 SAHI 扩展。<details>
<summary>Abstract</summary>
In semiconductor manufacturing, lithography has often been the manufacturing step defining the smallest possible pattern dimensions. In recent years, progress has been made towards high-NA (Numerical Aperture) EUVL (Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern shrinking (2 nm node and beyond). However, a significant increase in stochastic defects and the complexity of defect detection becomes more pronounced with high-NA. Present defect inspection techniques (both non-machine learning and machine learning based), fail to achieve satisfactory performance at high-NA dimensions. In this work, we investigate the use of the Slicing Aided Hyper Inference (SAHI) framework for improving upon current techniques. Using SAHI, inference is performed on size-increased slices of the SEM images. This leads to the object detector's receptive field being more effective in capturing small defect instances. First, the performance on previously investigated semiconductor datasets is benchmarked across various configurations, and the SAHI approach is demonstrated to substantially enhance the detection of small defects, by approx. 2x. Afterwards, we also demonstrated application of SAHI leads to flawless detection rates on a new test dataset, with scenarios not encountered during training, whereas previous trained models failed. Finally, we formulate an extension of SAHI that does not significantly reduce true-positive predictions while eliminating false-positive predictions.
</details>
<details>
<summary>摘要</summary>
在半导体生产中，镭射曾经是制造过程中定义最小的模式维度的关键步骤。在最近的年头，对高高 numerical aperture（NA）极紫外光刻（EUVL）的进步，使得模式缩小（2nm节点和更进）得到了提高。然而，高NA使得精度偏差和检测复杂性显著增加。现有的检测技术（包括机器学习和非机器学习基于的）在高NA环境下并未达到满意的性能。在这种情况下，我们研究使用扩展的扩展Hyper Inference（SAHI）框架，以改进当前技术。使用SAHI，检测器的受器领域被更好地捕捉到小异常实例。首先，我们对已经调查过的半导体数据集进行了多种配置的比较，并证明SAHI方法可以大幅提高小异常检测率，约2倍。然后，我们还证明SAHI可以在新的测试数据集上达到精准检测率，包括训练过程中未遇到的场景。最后，我们提出了SAHI的扩展，可以不会重要地降低真正的正确预测，而是完全消除假正确预测。
</details></li>
</ul>
<hr>
<h2 id="DiffSCI-Zero-Shot-Snapshot-Compressive-Imaging-via-Iterative-Spectral-Diffusion-Model"><a href="#DiffSCI-Zero-Shot-Snapshot-Compressive-Imaging-via-Iterative-Spectral-Diffusion-Model" class="headerlink" title="DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model"></a>DiffSCI: Zero-Shot Snapshot Compressive Imaging via Iterative Spectral Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11417">http://arxiv.org/abs/2311.11417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenghao Pan, Haijin Zeng, Jiezhang Cao, Kai Zhang, Yongyong Chen<br>for:DiffSCI aims to enhance the precision of snapshot compressive imaging (SCI) reconstruction for multispectral images (MSIs).methods:The proposed method integrates advantages from established SCI techniques, image generative models, and deep prior knowledge. It utilizes a pre-trained diffusion model as a generative denoiser, accounts for spectral band correlations, and introduces an accelerated algorithm to expedite the reconstruction process.results:DiffSCI exhibits improved performance over prevailing self-supervised and zero-shot approaches, even surpassing supervised transformer counterparts, as demonstrated through extensive testing on simulated and real datasets. The code will be available.<details>
<summary>Abstract</summary>
This paper endeavors to advance the precision of snapshot compressive imaging (SCI) reconstruction for multispectral image (MSI). To achieve this, we integrate the advantageous attributes of established SCI techniques and an image generative model, propose a novel structured zero-shot diffusion model, dubbed DiffSCI. DiffSCI leverages the structural insights from the deep prior and optimization-based methodologies, complemented by the generative capabilities offered by the contemporary denoising diffusion model. Specifically, firstly, we employ a pre-trained diffusion model, which has been trained on a substantial corpus of RGB images, as the generative denoiser within the Plug-and-Play framework for the first time. This integration allows for the successful completion of SCI reconstruction, especially in the case that current methods struggle to address effectively. Secondly, we systematically account for spectral band correlations and introduce a robust methodology to mitigate wavelength mismatch, thus enabling seamless adaptation of the RGB diffusion model to MSIs. Thirdly, an accelerated algorithm is implemented to expedite the resolution of the data subproblem. This augmentation not only accelerates the convergence rate but also elevates the quality of the reconstruction process. We present extensive testing to show that DiffSCI exhibits discernible performance enhancements over prevailing self-supervised and zero-shot approaches, surpassing even supervised transformer counterparts across both simulated and real datasets. Our code will be available.
</details>
<details>
<summary>摘要</summary>
Firstly, we use a pre-trained diffusion model, which has been trained on a large corpus of RGB images, as the generative denoiser within the Plug-and-Play framework for the first time. This integration enables successful SCI reconstruction, especially in cases where current methods struggle.Secondly, we systematically account for spectral band correlations and introduce a robust methodology to mitigate wavelength mismatch, allowing for seamless adaptation of the RGB diffusion model to MSIs.Thirdly, we implement an accelerated algorithm to expedite the resolution of the data subproblem. This not only accelerates the convergence rate but also improves the quality of the reconstruction process.We present extensive testing to show that DiffSCI exhibits significant performance enhancements over prevailing self-supervised and zero-shot approaches, surpassing even supervised transformer counterparts across both simulated and real datasets. Our code will be available.
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Emerging-Applications-of-Diffusion-Probabilistic-Models-in-MRI"><a href="#A-Survey-of-Emerging-Applications-of-Diffusion-Probabilistic-Models-in-MRI" class="headerlink" title="A Survey of Emerging Applications of Diffusion Probabilistic Models in MRI"></a>A Survey of Emerging Applications of Diffusion Probabilistic Models in MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11383">http://arxiv.org/abs/2311.11383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuheng Fan, Hanxi Liao, Shiqi Huang, Yimin Luo, Huazhu Fu, Haikun Qi</li>
<li>for: 本文是一篇审查文章，旨在帮助MRI社区的研究人员了解Diffusion probabilistic models（DPMs）在不同应用中的进步。</li>
<li>methods: 本文 introduce two dominant kinds of DPMs，即分别是离散时间步骤和连续时间步骤的DPMs，并提供了MRI领域emerging DPMs的全面回顾，包括重建、图像生成、图像翻译、 segmentation、异常检测以及进一步研究话题。</li>
<li>results: 本文结果表明，DPMs在MRI应用中具有高质量和多样性的生成能力，但也存在一些总体和特定于MRI任务的限制。<details>
<summary>Abstract</summary>
Diffusion probabilistic models (DPMs) which employ explicit likelihood characterization and a gradual sampling process to synthesize data, have gained increasing research interest. Despite their huge computational burdens due to the large number of steps involved during sampling, DPMs are widely appreciated in various medical imaging tasks for their high-quality and diversity of generation. Magnetic resonance imaging (MRI) is an important medical imaging modality with excellent soft tissue contrast and superb spatial resolution, which possesses unique opportunities for diffusion models. Although there is a recent surge of studies exploring DPMs in MRI, a survey paper of DPMs specifically designed for MRI applications is still lacking. This review article aims to help researchers in the MRI community to grasp the advances of DPMs in different applications. We first introduce the theory of two dominant kinds of DPMs, categorized according to whether the diffusion time step is discrete or continuous, and then provide a comprehensive review of emerging DPMs in MRI, including reconstruction, image generation, image translation, segmentation, anomaly detection, and further research topics. Finally, we discuss the general limitations as well as limitations specific to the MRI tasks of DPMs and point out potential areas that are worth further exploration.
</details>
<details>
<summary>摘要</summary>
diffusion probabilistic models (DPMs) 分布式概率模型，通过显式概率特征化和渐进采样过程，可以生成数据，在医学影像领域得到了广泛的研究兴趣。尽管DPMs在采样过程中需要承受巨大的计算负担，由于生成的质量和多样性而广泛应用于各种医学影像任务。核磁共振成像（MRI）是医学影像modalities中的一种重要方法，具有优秀的软组织强度对比和出色的空间分辨率，这种特点为Diffusion模型提供了独特的机遇。虽然有一些最近的研究探讨了DPMs在MRI应用中的可能性，但是一篇专门关于MRI应用的DPMs的评论文章仍然缺失。这篇文章的目的是帮助MRI社区的研究者了解DPMs在不同应用中的进步，我们首先介绍了DPMs的两种主要类型，分别是逐步分布式概率模型和连续分布式概率模型，然后提供了MRI应用中emerging DPMs的全面评论，包括重建、图像生成、图像翻译、分割、异常检测以及进一步的研究方向。最后，我们讨论了DPMs在MRI任务中的总限制以及特定任务的限制，并指出了可能的进一步探索领域。
</details></li>
</ul>
<hr>
<h2 id="Evidential-Uncertainty-Quantification-A-Variance-Based-Perspective"><a href="#Evidential-Uncertainty-Quantification-A-Variance-Based-Perspective" class="headerlink" title="Evidential Uncertainty Quantification: A Variance-Based Perspective"></a>Evidential Uncertainty Quantification: A Variance-Based Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11367">http://arxiv.org/abs/2311.11367</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kerrydrx/evidentialada">https://github.com/kerrydrx/evidentialada</a></li>
<li>paper_authors: Ruxiao Duan, Brian Caffo, Harrison X. Bai, Haris I. Sair, Craig Jones</li>
<li>for: 这个研究是用于 Deep Neural Networks 的 uncertainty quantification，并且专注于 classification  tasks 中的 aleatoric 和 epistemic  uncertainty。</li>
<li>methods: 这个研究使用了 evidential deep learning 的方法，通过单一的 forward pass 来直接量化 uncertainty。它还使用了 variance-based 方法，将其应用到 classification 中，以量化分类 uncertainty。</li>
<li>results: 实验结果显示，variance-based 方法不仅与 entropy-based 方法相似度在 active domain adaptation 中，同时还提供了关于 class-wise uncertainties 和 between-class correlations 的信息。<details>
<summary>Abstract</summary>
Uncertainty quantification of deep neural networks has become an active field of research and plays a crucial role in various downstream tasks such as active learning. Recent advances in evidential deep learning shed light on the direct quantification of aleatoric and epistemic uncertainties with a single forward pass of the model. Most traditional approaches adopt an entropy-based method to derive evidential uncertainty in classification, quantifying uncertainty at the sample level. However, the variance-based method that has been widely applied in regression problems is seldom used in the classification setting. In this work, we adapt the variance-based approach from regression to classification, quantifying classification uncertainty at the class level. The variance decomposition technique in regression is extended to class covariance decomposition in classification based on the law of total covariance, and the class correlation is also derived from the covariance. Experiments on cross-domain datasets are conducted to illustrate that the variance-based approach not only results in similar accuracy as the entropy-based one in active domain adaptation but also brings information about class-wise uncertainties as well as between-class correlations. The code is available at https://github.com/KerryDRX/EvidentialADA. This alternative means of evidential uncertainty quantification will give researchers more options when class uncertainties and correlations are important in their applications.
</details>
<details>
<summary>摘要</summary>
深度神经网络的不确定性评估已成为研究的活跃领域，对下游任务如活动学习具有关键作用。 latest advances in evidential deep learning 推动了直接量化 aleatoric 和 epistemic 不确定性的方法，通过单个模型前进 pass 直接量化不确定性。 traditional methods 通常采用 entropy-based 方法来 derive evidential uncertainty in classification, 量化不确定性在样本水平。 however, the variance-based method that has been widely applied in regression problems is seldom used in the classification setting. in this work, we adapt the variance-based approach from regression to classification, quantifying classification uncertainty at the class level. the variance decomposition technique in regression is extended to class covariance decomposition in classification based on the law of total covariance, and the class correlation is also derived from the covariance. experiments on cross-domain datasets are conducted to illustrate that the variance-based approach not only results in similar accuracy as the entropy-based one in active domain adaptation but also brings information about class-wise uncertainties as well as between-class correlations. the code is available at https://github.com/KerryDRX/EvidentialADA. this alternative means of evidential uncertainty quantification will give researchers more options when class uncertainties and correlations are important in their applications.Note: Simplified Chinese is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Scale-aware-competition-network-for-palmprint-recognition"><a href="#Scale-aware-competition-network-for-palmprint-recognition" class="headerlink" title="Scale-aware competition network for palmprint recognition"></a>Scale-aware competition network for palmprint recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11354">http://arxiv.org/abs/2311.11354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengrui Gao, Ziyuan Yang, Min Zhu, Andrew Beng Jin Teo</li>
<li>For: This paper aims to improve the accuracy of palmprint biometrics by addressing the limitations of existing methods that prioritize texture orientation but neglect scale.* Methods: The proposed method, called SAC-Net, consists of two modules: Inner-Scale Competition Module (ISCM) and Across-Scale Competition Module (ASCM). ISCM integrates learnable Gabor filters and a self-attention mechanism to extract rich orientation data, while ASCM leverages a competitive strategy across various scales to capture texture scale elements.* Results: The proposed method outperforms state-of-the-art alternatives in recognizing palmprints, as demonstrated by rigorous experiments on three benchmark datasets.<details>
<summary>Abstract</summary>
Palmprint biometrics garner heightened attention in palm-scanning payment and social security due to their distinctive attributes. However, prevailing methodologies singularly prioritize texture orientation, neglecting the significant texture scale dimension. We design an innovative network for concurrently extracting intra-scale and inter-scale features to redress this limitation. This paper proposes a scale-aware competitive network (SAC-Net), which includes the Inner-Scale Competition Module (ISCM) and the Across-Scale Competition Module (ASCM) to capture texture characteristics related to orientation and scale. ISCM efficiently integrates learnable Gabor filters and a self-attention mechanism to extract rich orientation data and discern textures with long-range discriminative properties. Subsequently, ASCM leverages a competitive strategy across various scales to effectively encapsulate the competitive texture scale elements. By synergizing ISCM and ASCM, our method adeptly characterizes palmprint features. Rigorous experimentation across three benchmark datasets unequivocally demonstrates our proposed approach's exceptional recognition performance and resilience relative to state-of-the-art alternatives.
</details>
<details>
<summary>摘要</summary>
手印生物特征在手印支付和社会保障中受到了更多的关注，这是因为手印有着独特的特征。然而，现有的方法ologies仅强调 текстур方向，忽略了重要的纹理尺度维度。我们设计了一种创新的网络，可以同时提取内纹理和间纹理特征。这篇论文提出了一种具有自适应竞争能力的纹理网络（SAC-Net），包括内纹理竞争模块（ISCM）和跨纹理竞争模块（ASCM），以捕捉手印特征。ISCM使用可学习的加博滤波器和自我注意机制，以提取丰富的方向数据和描述距离特征。然后，ASCM利用不同级别的竞争策略，有效地包装着竞争纹理级别的元素。通过融合ISCM和ASCMS，我们的方法能够有效地描述手印特征。严格的实验证明了我们提出的方法在三个 benchmark 数据集上的突出表现和鲜明性，相比之前的状态态 alternative。
</details></li>
</ul>
<hr>
<h2 id="MoVideo-Motion-Aware-Video-Generation-with-Diffusion-Models"><a href="#MoVideo-Motion-Aware-Video-Generation-with-Diffusion-Models" class="headerlink" title="MoVideo: Motion-Aware Video Generation with Diffusion Models"></a>MoVideo: Motion-Aware Video Generation with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11325">http://arxiv.org/abs/2311.11325</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyun Liang, Yuchen Fan, Kai Zhang, Radu Timofte, Luc Van Gool, Rakesh Ranjan</li>
<li>for: 这篇论文旨在提出一种基于运动的视频生成模型（MoVideo），以解决现有的视频生成模型忽略了运动的问题。</li>
<li>methods: 该模型从两个方面考虑运动：视频深度和光流。视频深度规则运动，而光流描述了帧之间的相对关系，以保持细节和改善时间一致性。</li>
<li>results: 在实验中，MoVideo模型在文本生成和图像生成等两个任务上均达到了最佳效果，显示了更好的提示一致性、帧一致性和视觉质量。<details>
<summary>Abstract</summary>
While recent years have witnessed great progress on using diffusion models for video generation, most of them are simple extensions of image generation frameworks, which fail to explicitly consider one of the key differences between videos and images, i.e., motion. In this paper, we propose a novel motion-aware video generation (MoVideo) framework that takes motion into consideration from two aspects: video depth and optical flow. The former regulates motion by per-frame object distances and spatial layouts, while the later describes motion by cross-frame correspondences that help in preserving fine details and improving temporal consistency. More specifically, given a key frame that exists or generated from text prompts, we first design a diffusion model with spatio-temporal modules to generate the video depth and the corresponding optical flows. Then, the video is generated in the latent space by another spatio-temporal diffusion model under the guidance of depth, optical flow-based warped latent video and the calculated occlusion mask. Lastly, we use optical flows again to align and refine different frames for better video decoding from the latent space to the pixel space. In experiments, MoVideo achieves state-of-the-art results in both text-to-video and image-to-video generation, showing promising prompt consistency, frame consistency and visual quality.
</details>
<details>
<summary>摘要</summary>
Recent years have seen significant progress in using diffusion models for video generation, but most of these models are simply extensions of image generation frameworks, neglecting a key difference between videos and images: motion. In this paper, we propose a novel motion-aware video generation (MoVideo) framework that takes motion into account from two aspects: video depth and optical flow. The former regulates motion by per-frame object distances and spatial layouts, while the latter describes motion by cross-frame correspondences that help preserve fine details and improve temporal consistency. Specifically, given a key frame that exists or is generated from text prompts, we first design a diffusion model with spatio-temporal modules to generate the video depth and the corresponding optical flows. Then, the video is generated in the latent space by another spatio-temporal diffusion model under the guidance of depth, optical flow-based warped latent video, and the calculated occlusion mask. Finally, we use optical flows again to align and refine different frames for better video decoding from the latent space to the pixel space. In experiments, MoVideo achieves state-of-the-art results in both text-to-video and image-to-video generation, demonstrating excellent prompt consistency, frame consistency, and visual quality.
</details></li>
</ul>
<hr>
<h2 id="Discrete-approximations-of-Gaussian-smoothing-and-Gaussian-derivatives"><a href="#Discrete-approximations-of-Gaussian-smoothing-and-Gaussian-derivatives" class="headerlink" title="Discrete approximations of Gaussian smoothing and Gaussian derivatives"></a>Discrete approximations of Gaussian smoothing and Gaussian derivatives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11317">http://arxiv.org/abs/2311.11317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tony Lindeberg</li>
<li>for: 这篇论文关注于粗化与梯度计算的粗化空间理论中的推广和数值方法。</li>
<li>methods: 论文考虑了三种主要的粗化方法，包括（i）抽象 Gaussian 函数和其 derivative 函数，（ii）在每个像素支持区域内进行当地积分 Gaussian 函数和其 derivative 函数，以及（iii）基于粗化空间理论的粗化数据分析。</li>
<li>results: 论文通过理论和实验研究这三种粗化方法的性能，并通过量值度量指标，包括对于不同应用场景的缩选任务进行评估，并强调在细节粗化下的表现。结果显示，使用抽象 Gaussian 函数和其 derivative 函数，以及在每个像素支持区域内进行当地积分 Gaussian 函数和其 derivative 函数，在细节粗化下表现很差。对比之下，使用粗化空间理论中的粗化数据分析，在细节粗化下表现很好。<details>
<summary>Abstract</summary>
This paper develops an in-depth treatment concerning the problem of approximating the Gaussian smoothing and Gaussian derivative computations in scale-space theory for application on discrete data. With close connections to previous axiomatic treatments of continuous and discrete scale-space theory, we consider three main ways discretizing these scale-space operations in terms of explicit discrete convolutions, based on either (i) sampling the Gaussian kernels and the Gaussian derivative kernels, (ii) locally integrating the Gaussian kernels and the Gaussian derivative kernels over each pixel support region and (iii) basing the scale-space analysis on the discrete analogue of the Gaussian kernel, and then computing derivative approximations by applying small-support central difference operators to the spatially smoothed image data.   We study the properties of these three main discretization methods both theoretically and experimentally, and characterize their performance by quantitative measures, including the results they give rise to with respect to the task of scale selection, investigated for four different use cases, and with emphasis on the behaviour at fine scales. The results show that the sampled Gaussian kernels and derivatives as well as the integrated Gaussian kernels and derivatives perform very poorly at very fine scales. At very fine scales, the discrete analogue of the Gaussian kernel with its corresponding discrete derivative approximations performs substantially better. The sampled Gaussian kernel and the sampled Gaussian derivatives do, on the other hand, lead to numerically very good approximations of the corresponding continuous results, when the scale parameter is sufficiently large, in the experiments presented in the paper, when the scale parameter is greater than a value of about 1, in units of the grid spacing.
</details>
<details>
<summary>摘要</summary>
这篇论文对抽象尺度空间理论中的高斯滤波和高斯导数计算的精度近似问题进行了深入的处理。与前期AXIOmatic准则的连续和精度数据之间的联系非常密切，我们考虑了三种主要的精度抽象方法，包括（i）采样高斯核函数和高斯导数核函数，（ii）在每个像素支持区域内进行局部积分高斯核函数和高斯导数核函数，以及（iii）基于精度数据的空间平滑化后进行高斯核函数的精度抽象，然后通过小支持中心差分算法计算导数近似。我们在理论和实验两个方面研究了这三种精度抽象方法的性能，并通过量化度量（包括在不同应用场景中的缩放选择问题上的性能）来评估其表现。结果显示，采样高斯核函数和导数核函数以及局部积分高斯核函数和导数核函数在非常细 scales perform very poorly。然而，基于精度数据的空间平滑化后的高斯核函数和其导数近似在非常细 scalesperform substantially better。采样高斯核函数和采样导数核函数则在大 scales（在实验中的grid spacing unit上大于1）numerically very good approximations of the corresponding continuous results。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-rgb-d-semantic-segmentation-through-multi-modal-interaction-and-pooling-attention"><a href="#Optimizing-rgb-d-semantic-segmentation-through-multi-modal-interaction-and-pooling-attention" class="headerlink" title="Optimizing rgb-d semantic segmentation through multi-modal interaction and pooling attention"></a>Optimizing rgb-d semantic segmentation through multi-modal interaction and pooling attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11312">http://arxiv.org/abs/2311.11312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Zhang, Minghong Xie</li>
<li>for: 提高RGB-D图像 semantic segmentation的精度</li>
<li>methods: 利用多模态交互和 Pooling Attention Module 提高网络的表达能力</li>
<li>results: 在NYUDv2和SUN-RGBD两个indoor scene数据集上，MIPANet比现有方法表现出较高的Semantic segmentation性能<details>
<summary>Abstract</summary>
Semantic segmentation of RGB-D images involves understanding the appearance and spatial relationships of objects within a scene, which requires careful consideration of various factors. However, in indoor environments, the simple input of RGB and depth images often results in a relatively limited acquisition of semantic and spatial information, leading to suboptimal segmentation outcomes. To address this, we propose the Multi-modal Interaction and Pooling Attention Network (MIPANet), a novel approach designed to harness the interactive synergy between RGB and depth modalities, optimizing the utilization of complementary information. Specifically, we incorporate a Multi-modal Interaction Fusion Module (MIM) into the deepest layers of the network. This module is engineered to facilitate the fusion of RGB and depth information, allowing for mutual enhancement and correction. Additionally, we introduce a Pooling Attention Module (PAM) at various stages of the encoder. This module serves to amplify the features extracted by the network and integrates the module's output into the decoder in a targeted manner, significantly improving semantic segmentation performance. Our experimental results demonstrate that MIPANet outperforms existing methods on two indoor scene datasets, NYUDv2 and SUN-RGBD, underscoring its effectiveness in enhancing RGB-D semantic segmentation.
</details>
<details>
<summary>摘要</summary>
semantic segmentation of RGB-D images 需要理解图像中物体的出现和空间关系，这需要考虑各种因素。然而，在室内环境中，简单地输入 RGB 和深度图像经常导致 semantic 和空间信息的有限获取，从而导致 segmentation 结果不佳。为解决这问题，我们提出了 Multi-modal Interaction and Pooling Attention Network (MIPANet)，一种新的方法，旨在利用 RGB 和深度模式之间的交互同时性，最大化 complementary 信息的利用。具体来说，我们在网络的最深层添加了 Multi-modal Interaction Fusion Module (MIM)。这个模块是用于融合 RGB 和深度信息，以便互补和修正。此外，我们在编码器中引入了 Pooling Attention Module (PAM)，用于增强网络提取的特征，并将其输出集成到解码器中，以提高 semantic segmentation 性能。我们的实验结果表明，MIPANet 在 NYUDv2 和 SUN-RGBD 两个室内场景数据集上比现有方法更高效，证明了它在 RGB-D semantic segmentation 中的效iveness。
</details></li>
</ul>
<hr>
<h2 id="UMAAF-Unveiling-Aesthetics-via-Multifarious-Attributes-of-Images"><a href="#UMAAF-Unveiling-Aesthetics-via-Multifarious-Attributes-of-Images" class="headerlink" title="UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images"></a>UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11306">http://arxiv.org/abs/2311.11306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Li, Yitian Wan, Xingjiao Wu, Junjie Xu, Liang He</li>
<li>for: 这篇论文主要是为了提出一种基于多属性的图像美学评估方法（UMAAF），以更好地利用图像特征来评估图像的美学价值。</li>
<li>methods: 这篇论文使用了多个维度的维度特征提取模块和一个综合属性互动网络，以捕捉图像的绝对属性和相对属性。另外，这篇论文还使用了一种相对关系损失函数来提高模型的Robustness。</li>
<li>results: 根据实验结果，这种基于UMAAF的方法在TAD66K和AVA数据集上达到了现状之最的性能，并且多个实验证明了模型与人类偏好的一致性。<details>
<summary>Abstract</summary>
With the increasing prevalence of smartphones and websites, Image Aesthetic Assessment (IAA) has become increasingly crucial. While the significance of attributes in IAA is widely recognized, many attribute-based methods lack consideration for the selection and utilization of aesthetic attributes. Our initial step involves the acquisition of aesthetic attributes from both intra- and inter-perspectives. Within the intra-perspective, we extract the direct visual attributes of images, constituting the absolute attribute. In the inter-perspective, our focus lies in modeling the relative score relationships between images within the same sequence, forming the relative attribute. Then, to better utilize image attributes in aesthetic assessment, we propose the Unified Multi-attribute Aesthetic Assessment Framework (UMAAF) to model both absolute and relative attributes of images. For absolute attributes, we leverage multiple absolute-attribute perception modules and an absolute-attribute interacting network. The absolute-attribute perception modules are first pre-trained on several absolute-attribute learning tasks and then used to extract corresponding absolute attribute features. The absolute-attribute interacting network adaptively learns the weight of diverse absolute-attribute features, effectively integrating them with generic aesthetic features from various absolute-attribute perspectives and generating the aesthetic prediction. To model the relative attribute of images, we consider the relative ranking and relative distance relationships between images in a Relative-Relation Loss function, which boosts the robustness of the UMAAF. Furthermore, UMAAF achieves state-of-the-art performance on TAD66K and AVA datasets, and multiple experiments demonstrate the effectiveness of each module and the model's alignment with human preference.
</details>
<details>
<summary>摘要</summary>
随着智能手机和网站的普及，图像美学评价（IAA）日益重要。虽然美学属性在IAA中的重要性广泛被认可，但许多基于属性的方法忽视了属性的选择和使用。我们的初步步骤是从内部和外部两个角度获取美学属性。在内部角度，我们提取图像直接视觉属性，组成绝对属性。在外部角度，我们关注图像序列内相互关系的建模，形成相对属性。然后，为了更好地利用图像属性在美学评价中，我们提议一种统一多属性美学评价框架（UMAAF），以模型图像绝对和相对属性。对绝对属性来说，我们利用多个绝对属性感知模块和绝对属性互动网络。绝对属性感知模块首先在多个绝对属性学习任务上预训练，然后用来提取对应的绝对属性特征。绝对属性互动网络可以适应性地学习绝对属性特征的权重，有效地将多种绝对属性视角的普遍美学特征与通用美学特征结合在一起，生成美学预测。为了模型图像相对属性，我们考虑图像之间的相对排名和相对距离关系，通过相对关系损失函数，提高UMAAF的Robustness。此外，UMAAF在TAD66K和AVA数据集上实现了状态机器人的表现，并通过多个实验证明每个模块和模型与人类偏好的吻合。
</details></li>
</ul>
<hr>
<h2 id="Exchanging-Dual-Encoder-Decoder-A-New-Strategy-for-Change-Detection-with-Semantic-Guidance-and-Spatial-Localization"><a href="#Exchanging-Dual-Encoder-Decoder-A-New-Strategy-for-Change-Detection-with-Semantic-Guidance-and-Spatial-Localization" class="headerlink" title="Exchanging Dual Encoder-Decoder: A New Strategy for Change Detection with Semantic Guidance and Spatial Localization"></a>Exchanging Dual Encoder-Decoder: A New Strategy for Change Detection with Semantic Guidance and Spatial Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11302">http://arxiv.org/abs/2311.11302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sijie Zhao, Xueliang Zhang, Pengfeng Xiao, Guangjun He</li>
<li>for: 本研究旨在提高地球观测中的变化检测性能，并采用深度学习方法来解决现有的问题。</li>
<li>methods: 我们提出了一种新的交换双Encoder-Decoder结构，以实现Binary变化检测 WITH semantic guidance和空间局部化。</li>
<li>results: 我们的模型在六个 dataset 上进行了比较，并与 18 个现有方法进行了比较。结果表明，我们的模型在三种场景中都达到了最高的性能，并且高效地解决了多视图建筑物变化检测和内类变化检测等问题。<details>
<summary>Abstract</summary>
Change detection is a critical task in earth observation applications. Recently, deep learning-based methods have shown promising performance and are quickly adopted in change detection. However, the widely used multiple encoder and single decoder (MESD) as well as dual encoder-decoder (DED) architectures still struggle to effectively handle change detection well. The former has problems of bitemporal feature interference in the feature-level fusion, while the latter is inapplicable to intraclass change detection and multiview building change detection. To solve these problems, we propose a new strategy with an exchanging dual encoder-decoder structure for binary change detection with semantic guidance and spatial localization. The proposed strategy solves the problems of bitemporal feature inference in MESD by fusing bitemporal features in the decision level and the inapplicability in DED by determining changed areas using bitemporal semantic features. We build a binary change detection model based on this strategy, and then validate and compare it with 18 state-of-the-art change detection methods on six datasets in three scenarios, including intraclass change detection datasets (CDD, SYSU), single-view building change detection datasets (WHU, LEVIR-CD, LEVIR-CD+) and a multiview building change detection dataset (NJDS). The experimental results demonstrate that our model achieves superior performance with high efficiency and outperforms all benchmark methods with F1-scores of 97.77%, 83.07%, 94.86%, 92.33%, 91.39%, 74.35% on CDD, SYSU, WHU, LEVIR-CD, LEVIR- CD+, and NJDS datasets, respectively. The code of this work will be available at https://github.com/NJU-LHRS/official-SGSLN.
</details>
<details>
<summary>摘要</summary>
<<SYS>> Change detection 是 Earth observation 应用中的一个关键任务。最近，深度学习基于的方法已经表现出了扎根的表现，快速被采纳。然而，广泛使用的多Encoder 和单Decoder（MESD）以及 dual Encoder-Decoder （DED）架构仍然不具备有效地处理变化检测的能力。前者受到帧内特征干扰的问题，而后者不适用于同类变化检测和多视图建筑变化检测。为解决这些问题，我们提出了一种新的策略，即交换 dual Encoder-Decoder 结构，用于二进制变化检测。这种策略可以解决 MESD 中的帧内特征干扰问题，并且可以在 DED 中确定变化区域使用帧内 semantic 特征。我们基于这种策略建立了一个二进制变化检测模型，然后验证和比较它与 18 种现有变化检测方法在六个数据集上的性能。结果显示，我们的模型在高效性和精度方面具有优秀的表现，并且在所有参考方法中具有最高的 F1 分数，分别为 97.77%, 83.07%, 94.86%, 92.33%, 91.39%, 74.35%。代码将在 GitHub 上公开，链接为 <https://github.com/NJU-LHRS/official-SGSLN>。
</details></li>
</ul>
<hr>
<h2 id="Pair-wise-Layer-Attention-with-Spatial-Masking-for-Video-Prediction"><a href="#Pair-wise-Layer-Attention-with-Spatial-Masking-for-Video-Prediction" class="headerlink" title="Pair-wise Layer Attention with Spatial Masking for Video Prediction"></a>Pair-wise Layer Attention with Spatial Masking for Video Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11289">http://arxiv.org/abs/2311.11289</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlvccn/pla_sm_videopred">https://github.com/mlvccn/pla_sm_videopred</a></li>
<li>paper_authors: Ping Li, Chenhan Zhang, Zheng Yang, Xianghua Xu, Mingli Song</li>
<li>for: 预测视频帧，提高预测质量。</li>
<li>methods: 使用Pair-wise Layer Attention（PLA）模块强调层次 semanticdependency，并使用Spatial Masking（SM）模块增强空间特征。</li>
<li>results: 在五个 benchmark 上进行了广泛的实验和严格的ablation 研究，并得到了提高预测质量的结果。<details>
<summary>Abstract</summary>
Video prediction yields future frames by employing the historical frames and has exhibited its great potential in many applications, e.g., meteorological prediction, and autonomous driving. Previous works often decode the ultimate high-level semantic features to future frames without texture details, which deteriorates the prediction quality. Motivated by this, we develop a Pair-wise Layer Attention (PLA) module to enhance the layer-wise semantic dependency of the feature maps derived from the U-shape structure in Translator, by coupling low-level visual cues and high-level features. Hence, the texture details of predicted frames are enriched. Moreover, most existing methods capture the spatiotemporal dynamics by Translator, but fail to sufficiently utilize the spatial features of Encoder. This inspires us to design a Spatial Masking (SM) module to mask partial encoding features during pretraining, which adds the visibility of remaining feature pixels by Decoder. To this end, we present a Pair-wise Layer Attention with Spatial Masking (PLA-SM) framework for video prediction to capture the spatiotemporal dynamics, which reflect the motion trend. Extensive experiments and rigorous ablation studies on five benchmarks demonstrate the advantages of the proposed approach. The code is available at GitHub.
</details>
<details>
<summary>摘要</summary>
<<SYS>>视频预测可以生成未来帧，通过利用历史帧来实现这一点，并在多个应用程序中表现出了很大的潜力，例如气象预测和自动驾驶。过去的工作通常是将高级Semantic特征解码到未来帧中，而不是保留Texture细节，这会下降预测质量。我们被这一点所 inspirited，开发了一个Pair-wise层Attention（PLA）模块，用于增强Translator的层次Semantic依赖关系，并将低级Visualcue和高级特征相互关联。因此，预测帧的Texture细节得到了增强。此外，大多数现有方法在Translator中捕捉了Space-Time动力学，但是忽略了Encoder的空间特征。这使我们开发了一个Spatial Masking（SM）模块，用于在预训练时对部分编码特征进行遮盖，以便Decoder中的视觉特征添加可见性。因此，我们提出了一个Pair-wise层Attention with Spatial Masking（PLA-SM）框架，用于视频预测，以捕捉Space-Time动力学，并反映运动趋势。经过广泛的实验和严格的ablation研究，我们在五个benchmark上证明了我们的方法的优势。代码可以在GitHub上找到。
</details></li>
</ul>
<hr>
<h2 id="LucidDreamer-Towards-High-Fidelity-Text-to-3D-Generation-via-Interval-Score-Matching"><a href="#LucidDreamer-Towards-High-Fidelity-Text-to-3D-Generation-via-Interval-Score-Matching" class="headerlink" title="LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching"></a>LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11284">http://arxiv.org/abs/2311.11284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/envision-research/luciddreamer">https://github.com/envision-research/luciddreamer</a></li>
<li>paper_authors: Yixun Liang, Xin Yang, Jiantao Lin, Haodong Li, Xiaogang Xu, Yingcong Chen</li>
<li>for: 提高文本到3D生成模型的质量和效率</li>
<li>methods: 提出了一种新的方法Interval Score Matching（ISM），通过幂等扩散轨迹和间隔分别匹配来缓解过滤效应，同时还 integrates 3D Gaussian Splatting into the text-to-3D generation pipeline</li>
<li>results: 实验表明，该模型在质量和训练效率上有显著提高 compared to 状态前的模型<details>
<summary>Abstract</summary>
The recent advancements in text-to-3D generation mark a significant milestone in generative models, unlocking new possibilities for creating imaginative 3D assets across various real-world scenarios. While recent advancements in text-to-3D generation have shown promise, they often fall short in rendering detailed and high-quality 3D models. This problem is especially prevalent as many methods base themselves on Score Distillation Sampling (SDS). This paper identifies a notable deficiency in SDS, that it brings inconsistent and low-quality updating direction for the 3D model, causing the over-smoothing effect. To address this, we propose a novel approach called Interval Score Matching (ISM). ISM employs deterministic diffusing trajectories and utilizes interval-based score matching to counteract over-smoothing. Furthermore, we incorporate 3D Gaussian Splatting into our text-to-3D generation pipeline. Extensive experiments show that our model largely outperforms the state-of-the-art in quality and training efficiency.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Transcending-Forgery-Specificity-with-Latent-Space-Augmentation-for-Generalizable-Deepfake-Detection"><a href="#Transcending-Forgery-Specificity-with-Latent-Space-Augmentation-for-Generalizable-Deepfake-Detection" class="headerlink" title="Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection"></a>Transcending Forgery Specificity with Latent Space Augmentation for Generalizable Deepfake Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11278">http://arxiv.org/abs/2311.11278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiyuan Yan, Yuhao Luo, Siwei Lyu, Qingshan Liu, Baoyuan Wu</li>
<li>for: 提高深 fake检测器的普适性，即使在数据集的分布不符合时仍能保持良好的检测性能。</li>
<li>methods: 提出了一种简单 yet effective的检测器，即Latent Space Data Augmentation（LSDA），基于一个启发式想法：具有更多类型的深 fake可以学习更普适的决策边界，从而减少方法特有的特征过拟合。通过在幂空间内构建和模拟假造特征之间和 across forgery features的变化，扩大了假造空间，从而获得了丰富的领域特定特征和减少了域间 gap。</li>
<li>results: 经过了广泛的实验，发现提出的方法 surprisingly effective，超越了多个常用的基准检测器在多个广泛使用的 benchmark 上。<details>
<summary>Abstract</summary>
Deepfake detection faces a critical generalization hurdle, with performance deteriorating when there is a mismatch between the distributions of training and testing data. A broadly received explanation is the tendency of these detectors to be overfitted to forgery-specific artifacts, rather than learning features that are widely applicable across various forgeries. To address this issue, we propose a simple yet effective detector called LSDA (\underline{L}atent \underline{S}pace \underline{D}ata \underline{A}ugmentation), which is based on a heuristic idea: representations with a wider variety of forgeries should be able to learn a more generalizable decision boundary, thereby mitigating the overfitting of method-specific features (see Figure. 1). Following this idea, we propose to enlarge the forgery space by constructing and simulating variations within and across forgery features in the latent space. This approach encompasses the acquisition of enriched, domain-specific features and the facilitation of smoother transitions between different forgery types, effectively bridging domain gaps. Our approach culminates in refining a binary classifier that leverages the distilled knowledge from the enhanced features, striving for a generalizable deepfake detector. Comprehensive experiments show that our proposed method is surprisingly effective and transcends state-of-the-art detectors across several widely used benchmarks.
</details>
<details>
<summary>摘要</summary>
深层迷伪检测面临一个重要的通用化难题，其性能在训练和测试数据的分布不匹配时受到影响。一个广泛接受的解释是这些检测器过拟合假造特有的特征，而不是学习通用于不同假造的特征。为解决这个问题，我们提出了一种简单 yet 有效的检测器 called LSDA（Latent Space Data Augmentation），基于一个启发性的想法：具有更多种假造的表示应该能够学习更通用的决策边界，从而减轻方法特有的特征过拟合（参见 Figure. 1）。按照这个想法，我们提议扩大假造空间，通过在和 across forgery 特征上构建和模拟变化来增强表示。这种方法涵盖了获得更加丰富的领域特定特征和促进不同假造类型之间的缓抗过渡，实际上跨域连接。我们的方法最终是通过提高了特征的整合来优化一个二分类器，以便实现一个通用的深层迷伪检测器。我们的实验结果显示，我们的提议方法 surprisingly 有效，并超越了多个广泛使用的标准检测器在多个常用的 benchmark 上。
</details></li>
</ul>
<hr>
<h2 id="Generalization-and-Hallucination-of-Large-Vision-Language-Models-through-a-Camouflaged-Lens"><a href="#Generalization-and-Hallucination-of-Large-Vision-Language-Models-through-a-Camouflaged-Lens" class="headerlink" title="Generalization and Hallucination of Large Vision-Language Models through a Camouflaged Lens"></a>Generalization and Hallucination of Large Vision-Language Models through a Camouflaged Lens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11273">http://arxiv.org/abs/2311.11273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lv Tang, Peng-Tao Jiang, Zhihao Shen, Hao Zhang, Jinwei Chen, Bo Li</li>
<li>for: 这个论文旨在探讨大视语言模型（LVLM）是否可以在无需训练的情况下泛化到难以识别的隐身物体检测（COD）场景中。</li>
<li>methods: 我们提出了一种新的框架，即隐身视语言框架（CPVLF），以探索LVLM是否可以在无需训练的情况下泛化到COD场景中。在泛化过程中，我们发现LVLM因为内部的幻觉问题而可能会错误地感知隐身场景中的 объек，生成对实际情况不符的概念。此外，由于LVLM没有专门为精准地位置隐身 объек 进行训练，因此它在准确地位置隐身 objet 方面存在一定的不确定性。因此，我们提出了一条链条视觉感知，以提高LVLM在隐身场景中的视觉感知，从语言和视觉两个角度增强LVLM对隐身场景的感知，降低幻觉问题，提高LVLM在准确地位置隐身 objet 方面的能力。</li>
<li>results: 我们 validate了CPVLF的效果在三个通用的COD数据集上，实验结果表明LVLM在COD任务中具有潜在的能力。<details>
<summary>Abstract</summary>
Large Vision-Language Model (LVLM) has seen burgeoning development and increasing attention recently. In this paper, we propose a novel framework, camo-perceptive vision-language framework (CPVLF), to explore whether LVLM can generalize to the challenging camouflaged object detection (COD) scenario in a training-free manner. During the process of generalization, we find that due to hallucination issues within LVLM, it can erroneously perceive objects in camouflaged scenes, producing counterfactual concepts. Moreover, as LVLM is not specifically trained for the precise localization of camouflaged objects, it exhibits a degree of uncertainty in accurately pinpointing these objects. Therefore, we propose chain of visual perception, which enhances LVLM's perception of camouflaged scenes from both linguistic and visual perspectives, reducing the hallucination issue and improving its capability in accurately locating camouflaged objects. We validate the effectiveness of CPVLF on three widely used COD datasets, and the experiments show the potential of LVLM in the COD task.
</details>
<details>
<summary>摘要</summary>
大型视言语模型（LVLM）在最近几年得到了广泛的发展和关注。在这篇论文中，我们提出了一种新的框架——隐形视言语框架（CPVLF），以探索LVLM是否可以在无需训练的情况下扩展到具有挑战性的隐形物 detection（COD）场景。在扩展过程中，我们发现LVLM因为幻觉问题而在隐形场景中错误地感知物体，生成了假设性的概念。此外，由于LVLM没有特地对隐形物体的精确定位进行训练，它在找到隐形物体时表现出一定的不确定性。因此，我们提出了视觉链，以增强LVLM在隐形场景中的视觉和语言两个方面的感知，从而降低幻觉问题和提高隐形物体的精确定位能力。我们验证了CPVLF在三个常用的COD数据集上的效果，实验结果表明LVLM在COD任务中具有潜在的能力。
</details></li>
</ul>
<hr>
<h2 id="Radarize-Large-Scale-Radar-SLAM-for-Indoor-Environments"><a href="#Radarize-Large-Scale-Radar-SLAM-for-Indoor-Environments" class="headerlink" title="Radarize: Large-Scale Radar SLAM for Indoor Environments"></a>Radarize: Large-Scale Radar SLAM for Indoor Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11260">http://arxiv.org/abs/2311.11260</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emerson Sie, Xinyu Wu, Heyu Guo, Deepak Vasisht</li>
<li>for: 这篇论文是为了提出一种基于单 chip MMwave 雷达的低成本 SLAM 管道，用于室内环境。</li>
<li>methods: 该方法使用雷达特有的电磁现象，如多普勒移动效应，来提高性能。</li>
<li>results: 在一个大规模的数据集上评估了该方法，与现有的雷达基本方法比较，显示该方法在雷达偏移和端到端 SLAM 方面比之前的方法高出约5倍和8倍。<details>
<summary>Abstract</summary>
We present Radarize, a self-contained SLAM pipeline for indoor environments that uses only a low-cost commodity single-chip mmWave radar. Our radar-native approach leverages phenomena unique to radio frequencies, such as doppler shift-based odometry, to improve performance. We evaluate our method on a large-scale dataset of 146 trajectories spanning 4 campus buildings, totaling approximately 4680m of travel distance. Our results show that our method outperforms state-of-the-art radar-based approaches by approximately 5x in terms of odometry and 8x in terms of end-to-end SLAM, as measured by absolute trajectory error (ATE), without the need additional sensors such as IMUs or wheel odometry.
</details>
<details>
<summary>摘要</summary>
我们介绍Radarize，一个低成本干radio雷达单芯片SLAM管道，适用于室内环境。我们的雷达本地方法利用雷达频率特有的现象，如Doppler偏移估计，以提高性能。我们对一个大规模的数据集，包括4座大学建筑，总计约4680米的旅程距离进行评估。我们的结果表明，我们的方法比现有的雷达基于方法高出约5倍的偏移和8倍的综合SLAM（绝对轨迹误差），而无需其他感知器如IMU或轮胎速度测量器。
</details></li>
</ul>
<hr>
<h2 id="Submeter-level-Land-Cover-Mapping-of-Japan"><a href="#Submeter-level-Land-Cover-Mapping-of-Japan" class="headerlink" title="Submeter-level Land Cover Mapping of Japan"></a>Submeter-level Land Cover Mapping of Japan</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11252">http://arxiv.org/abs/2311.11252</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoto Yokoya, Junshi Xia, Clifford Broni-Bediako</li>
<li>for: 这 paper 的目的是提出一种低成本的 submeter-level 地形分类方法，以提高国家规模的地形分类地图的自动更新。</li>
<li>methods: 该方法基于 OpenEarthMap 数据集，使用 U-Net 模型进行人工循环学习，通过少量的额外标注数据来改进模型的准确率。</li>
<li>results: 该方法可以在日本全国范围内实现高精度的地形分类地图，并且比传统的方法提高了约 16% 的准确率。<details>
<summary>Abstract</summary>
Deep learning has shown promising performance in submeter-level mapping tasks; however, the annotation cost of submeter-level imagery remains a challenge, especially when applied on a large scale. In this paper, we present the first submeter-level land cover mapping of Japan with eight classes, at a relatively low annotation cost. We introduce a human-in-the-loop deep learning framework leveraging OpenEarthMap, a recently introduced benchmark dataset for global submeter-level land cover mapping, with a U-Net model that achieves national-scale mapping with a small amount of additional labeled data. By adding a small amount of labeled data of areas or regions where a U-Net model trained on OpenEarthMap clearly failed and retraining the model, an overall accuracy of 80\% was achieved, which is a nearly 16 percentage point improvement after retraining. Using aerial imagery provided by the Geospatial Information Authority of Japan, we create land cover classification maps of eight classes for the entire country of Japan. Our framework, with its low annotation cost and high-accuracy mapping results, demonstrates the potential to contribute to the automatic updating of national-scale land cover mapping using submeter-level optical remote sensing data. The mapping results will be made publicly available.
</details>
<details>
<summary>摘要</summary>
深度学习在 submeter 级地形映射任务中表现出了扎实的成绩;然而，对 submeter 级遥感数据的标注成本仍然是一大挑战，特别是在大规模应用中。在这篇论文中，我们首次在日本全国范围内实现了八类 submeter 级地形分类，并且在相对较低的标注成本下完成了。我们提出了一种人工智能在Loop深度学习框架，利用 OpenEarthMap 数据集，一个最近引入的全球 submeter 级地形分类 benchmark，并使用 U-Net 模型实现了全国范围内的地形分类。通过对 OpenEarthMap 模型在特定地区或地方添加小量标注数据重新训练，实现了总准确率为 80%，相比之前训练后提高了约 16%。使用日本地图情报管理局提供的飞行图像，我们生成了日本全国的八类地形分类地图。我们的框架，具有低标注成本和高准确率地形分类结果，表明可以在使用 submeter 级遥感数据自动更新国家级地形分类地图。地图结果将公开发布。
</details></li>
</ul>
<hr>
<h2 id="AutoStory-Generating-Diverse-Storytelling-Images-with-Minimal-Human-Effort"><a href="#AutoStory-Generating-Diverse-Storytelling-Images-with-Minimal-Human-Effort" class="headerlink" title="AutoStory: Generating Diverse Storytelling Images with Minimal Human Effort"></a>AutoStory: Generating Diverse Storytelling Images with Minimal Human Effort</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11243">http://arxiv.org/abs/2311.11243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wen Wang, Canyu Zhao, Hao Chen, Zhekai Chen, Kecheng Zheng, Chunhua Shen</li>
<li>for:  Story Visualization</li>
<li>methods: 使用大语言模型进行布局规划，然后利用大规模文本到图像模型生成复杂的故事图像，并使用稀疏控制条件（如矩形框）进行布局规划，以及使用密集控制条件（如素描和关键点）进行图像生成，以提高图像质量并允许用户进行INTuitive interactions。</li>
<li>results: 提出了一种自动化的故事视觉系统，可以生成多样化、高质量和一致的故事图像，并且具有最小化人工干预的特点。此外，还提出了一种简单 yet effective的多视角一致人物图像生成方法，解决了人工劳动集成或绘制人物图像的问题。<details>
<summary>Abstract</summary>
Story visualization aims to generate a series of images that match the story described in texts, and it requires the generated images to satisfy high quality, alignment with the text description, and consistency in character identities. Given the complexity of story visualization, existing methods drastically simplify the problem by considering only a few specific characters and scenarios, or requiring the users to provide per-image control conditions such as sketches. However, these simplifications render these methods incompetent for real applications. To this end, we propose an automated story visualization system that can effectively generate diverse, high-quality, and consistent sets of story images, with minimal human interactions. Specifically, we utilize the comprehension and planning capabilities of large language models for layout planning, and then leverage large-scale text-to-image models to generate sophisticated story images based on the layout. We empirically find that sparse control conditions, such as bounding boxes, are suitable for layout planning, while dense control conditions, e.g., sketches and keypoints, are suitable for generating high-quality image content. To obtain the best of both worlds, we devise a dense condition generation module to transform simple bounding box layouts into sketch or keypoint control conditions for final image generation, which not only improves the image quality but also allows easy and intuitive user interactions. In addition, we propose a simple yet effective method to generate multi-view consistent character images, eliminating the reliance on human labor to collect or draw character images.
</details>
<details>
<summary>摘要</summary>
（简化中文）story visualization 是生成文本中的故事场景，需要生成图像的质量高，对文本描述的对齐，人物形象的一致性。由于故事视觉化的复杂性，现有的方法大多是忽视特定的人物和场景，或者需要用户提供每个图像的控制条件，如绘制箱体。但这些简化方法在实际应用中无法满足需求。为此，我们提出一个自动化的故事视觉化系统，可以生成多样化、高质量、一致的故事图像，最小化用户的互动。我们利用大语言模型的理解和规划能力来进行布局规划，然后利用大规模的文本到图像模型来生成基于布局的故事图像。我们发现，简单的控制条件，如矩形盒体，适合布局规划，而密集的控制条件，如绘制和关键点，适合生成高质量的图像内容。为了取得两者的优点，我们设计了一个密集控制条件生成模块，将简单的矩形盒体转换为绘制或关键点控制条件，从而提高图像质量并使用户交互更加简单。此外，我们提出了一种简单 yet effective的方法来生成多视图一致的人物图像，从而消除人工劳动来收集或绘制人物图像。
</details></li>
</ul>
<hr>
<h2 id="Open-Vocabulary-Camouflaged-Object-Segmentation"><a href="#Open-Vocabulary-Camouflaged-Object-Segmentation" class="headerlink" title="Open-Vocabulary Camouflaged Object Segmentation"></a>Open-Vocabulary Camouflaged Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11241">http://arxiv.org/abs/2311.11241</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youwei Pang, Xiaoqi Zhao, Jiaming Zuo, Lihe Zhang, Huchuan Lu</li>
<li>for: 这篇论文主要针对开放词汇涂抹物体识别 зада务进行研究，以提高现有的开放词汇涂抹物体 segmentation 技术。</li>
<li>methods: 该论文提出了一种基于 CLIP 的单阶段开放词汇涂抹物体 segmentation 方法，通过 iterative semantic guidance 和 visual structure cues 来提高捕捉隐藏的物体。</li>
<li>results: 该方法在 authors 提出的 OVCamo 数据集上达到了 state-of-the-art 水平，并且在开放词汇涂抹物体 semantic image segmentation 任务上也表现出了优异。<details>
<summary>Abstract</summary>
Recently, the emergence of the large-scale vision-language model (VLM), such as CLIP, has opened the way towards open-world object perception. Many works has explored the utilization of pre-trained VLM for the challenging open-vocabulary dense prediction task that requires perceive diverse objects with novel classes at inference time. Existing methods construct experiments based on the public datasets of related tasks, which are not tailored for open vocabulary and rarely involves imperceptible objects camouflaged in complex scenes due to data collection bias and annotation costs. To fill in the gaps, we introduce a new task, open-vocabulary camouflaged object segmentation (OVCOS) and construct a large-scale complex scene dataset (\textbf{OVCamo}) which containing 11,483 hand-selected images with fine annotations and corresponding object classes. Further, we build a strong single-stage open-vocabulary \underline{c}amouflaged \underline{o}bject \underline{s}egmentation transform\underline{er} baseline \textbf{OVCoser} attached to the parameter-fixed CLIP with iterative semantic guidance and structure enhancement. By integrating the guidance of class semantic knowledge and the supplement of visual structure cues from the edge and depth information, the proposed method can efficiently capture camouflaged objects. Moreover, this effective framework also surpasses previous state-of-the-arts of open-vocabulary semantic image segmentation by a large margin on our OVCamo dataset. With the proposed dataset and baseline, we hope that this new task with more practical value can further expand the research on open-vocabulary dense prediction tasks.
</details>
<details>
<summary>摘要</summary>
近些时间，大规模视力语言模型（VLM）的出现，如CLIP，已经开创了开放世界物体识别的新途径。许多研究已经利用预训练VLM来进行开放词汇稠密预测任务，需要在推理时识别多种新类的物体。现有方法基于相关任务的公共数据集进行实验，这些数据集通常不适用于开放词汇和罕见的隐形物体，因为数据收集偏好和注释成本的限制。为了填补这些缺陷，我们引入了一个新任务：开放词汇隐形物体分割（OVCOS），并构建了一个大规模的复杂场景数据集（OVCamo），包含11483个手动选择的图像，以及相应的物体类别。此外，我们建立了一个强大的单Stage开放词汇隐形物体分割变换器（OVCoser），将CLIP的参数固定，并采用迭代性启发和结构增强来提高效果。通过结合类别 semantic 知识和视觉结构准则，我们的方法可以高效捕捉隐形物体。此外，我们的有效框架还在我们的OVCamo数据集上超过了先前的开放词汇semantic图像分割状态之差。我们希望通过我们提出的任务和数据集，可以进一步推动开放词汇稠密预测任务的研究。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Radiology-Diagnosis-through-Convolutional-Neural-Networks-for-Computer-Vision-in-Healthcare"><a href="#Enhancing-Radiology-Diagnosis-through-Convolutional-Neural-Networks-for-Computer-Vision-in-Healthcare" class="headerlink" title="Enhancing Radiology Diagnosis through Convolutional Neural Networks for Computer Vision in Healthcare"></a>Enhancing Radiology Diagnosis through Convolutional Neural Networks for Computer Vision in Healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11234">http://arxiv.org/abs/2311.11234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keshav Kumar K., Dr N V S L Narasimham</li>
<li>for: 这项研究探讨了用 convolutional neural networks (CNNs) 在医学诊断中的转化力量，特别是解释性、有效性和伦理问题。</li>
<li>methods: 研究使用了修改后的 DenseNet 架构，并通过比较分析表明其在特征、敏感度和准确率方面表现出色。</li>
<li>results: 研究表明 CNN 在传统方法的比较分析中表现出明显的效率提升，但解释性问题需要进一步改进。 inteoperability 和医生培训问题也需要进行考虑。<details>
<summary>Abstract</summary>
The transformative power of Convolutional Neural Networks (CNNs) in radiology diagnostics is examined in this study, with a focus on interpretability, effectiveness, and ethical issues. With an altered DenseNet architecture, the CNN performs admirably in terms of particularity, sensitivity, as well as accuracy. Its superiority over conventional methods is validated by comparative analyses, which highlight efficiency gains. Nonetheless, interpretability issues highlight the necessity of sophisticated methods in addition to continuous model improvement. Integration issues like interoperability and radiologists' training lead to suggestions for teamwork. Systematic consideration of the ethical implications is carried out, necessitating extensive frameworks. Refinement of architectures, interpretability, alongside ethical considerations need to be prioritized in future work for responsible CNN deployment in radiology diagnostics.
</details>
<details>
<summary>摘要</summary>
这个研究探讨了计算机神经网络（CNN）在医学诊断中的转化力，强调了可读性、有效性和伦理问题。通过修改了DenseNet架构，CNN表现出色地在特征、敏感性和准确性方面。与传统方法比较分析显示，CNN在效率方面有所提升。然而，可读性问题表明需要进一步开发复杂的方法，同时继续改进模型。医生培训和兼容性问题的解决需要团队合作。对伦理问题的系统考虑需要广泛的框架。未来的工作应该在CNN部署中优先级顺序是解释性、伦理考虑和建立框架。
</details></li>
</ul>
<hr>
<h2 id="GaussianDiffusion-3D-Gaussian-Splatting-for-Denoising-Diffusion-Probabilistic-Models-with-Structured-Noise"><a href="#GaussianDiffusion-3D-Gaussian-Splatting-for-Denoising-Diffusion-Probabilistic-Models-with-Structured-Noise" class="headerlink" title="GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise"></a>GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11221">http://arxiv.org/abs/2311.11221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinhai Li, Huaibin Wang, Kuo-Kun Tseng</li>
<li>For:  This paper proposes a novel text-to-3D content generation framework based on Gaussian splatting, which enables fine control over image saturation and produces more realistic images.* Methods: The framework uses Gaussian splatting to generate 3D content, and employs multi-view noise distributions to rectify inconsistencies in multi-view geometry. It also uses a variational Gaussian splatting technique to enhance the quality and stability of 3D appearance.* Results: The proposed method produces more realistic images with fine control over image saturation, and mitigates issues like floaters, burrs, and proliferative elements. It also demonstrates the first comprehensive utilization of Gaussian splatting across the entire spectrum of 3D content generation processes.<details>
<summary>Abstract</summary>
Text-to-3D, known for its efficient generation methods and expansive creative potential, has garnered significant attention in the AIGC domain. However, the amalgamation of Nerf and 2D diffusion models frequently yields oversaturated images, posing severe limitations on downstream industrial applications due to the constraints of pixelwise rendering method. Gaussian splatting has recently superseded the traditional pointwise sampling technique prevalent in NeRF-based methodologies, revolutionizing various aspects of 3D reconstruction. This paper introduces a novel text to 3D content generation framework based on Gaussian splatting, enabling fine control over image saturation through individual Gaussian sphere transparencies, thereby producing more realistic images. The challenge of achieving multi-view consistency in 3D generation significantly impedes modeling complexity and accuracy. Taking inspiration from SJC, we explore employing multi-view noise distributions to perturb images generated by 3D Gaussian splatting, aiming to rectify inconsistencies in multi-view geometry. We ingeniously devise an efficient method to generate noise that produces Gaussian noise from diverse viewpoints, all originating from a shared noise source. Furthermore, vanilla 3D Gaussian-based generation tends to trap models in local minima, causing artifacts like floaters, burrs, or proliferative elements. To mitigate these issues, we propose the variational Gaussian splatting technique to enhance the quality and stability of 3D appearance. To our knowledge, our approach represents the first comprehensive utilization of Gaussian splatting across the entire spectrum of 3D content generation processes.
</details>
<details>
<summary>摘要</summary>
文本到3D，知名于其高效生成方法和广阔的创作潜力，在AIGC领域产生了广泛的关注。然而，将NERF和2D扩散模型合并经常会产生过度饱和的图像，这会限制下游工业应用的可能性，因为像素级渲染方法的约束。在传统的点 wise sampling技术被替代后， Gaussian splatting 在3D重建方面引入了一种新的文本到3D内容生成框架，可以在图像饱和度控制中提供细分的控制，从而生成更真实的图像。然而，在多视图匹配中，3D生成模型的复杂性和准确性受到了严重的挑战。我们从 SJC 中得到了灵感，我们尝试使用多视图噪声分布来扰乱由3D Gaussian splatting 生成的图像，以解决多视图匹配中的不一致性。我们创新地设计了一种高效的噪声生成方法，可以生成多视图的噪声，所有的噪声都来自一个共同的噪声源。此外，普通的3D Gaussian-based生成往往会让模型陷入本地极小值，导致残余、尖刺或肿瘤等问题。为了缓解这些问题，我们提出了可变 Gaussian splatting 技术，以提高3D外观的质量和稳定性。据我们所知，我们的方法是首次在3D内容生成过程中广泛应用 Gaussian splatting。
</details></li>
</ul>
<hr>
<h2 id="Infrared-image-identification-method-of-substation-equipment-fault-under-weak-supervision"><a href="#Infrared-image-identification-method-of-substation-equipment-fault-under-weak-supervision" class="headerlink" title="Infrared image identification method of substation equipment fault under weak supervision"></a>Infrared image identification method of substation equipment fault under weak supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11214">http://arxiv.org/abs/2311.11214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anjali Sharma, Priya Banerjee, Nikhil Singh</li>
<li>for: 本研究提出了一种弱监督的方法，用于检测 substation 设备上的缺陷。</li>
<li>methods: 该方法使用 Faster RCNN 模型进行设备标识，通过模型网络结构和参数的修改，提高检测精度。</li>
<li>results: 研究通过使用探测机器人captured的红外图像进行分析，证明提posed算法可以显著提高不同设备类型的缺陷标识精度。<details>
<summary>Abstract</summary>
This study presents a weakly supervised method for identifying faults in infrared images of substation equipment. It utilizes the Faster RCNN model for equipment identification, enhancing detection accuracy through modifications to the model's network structure and parameters. The method is exemplified through the analysis of infrared images captured by inspection robots at substations. Performance is validated against manually marked results, demonstrating that the proposed algorithm significantly enhances the accuracy of fault identification across various equipment types.
</details>
<details>
<summary>摘要</summary>
这种研究提出了一种弱监督的方法，用于检测 substation 设备的缺陷。它利用 Faster RCNN 模型进行设备标识，通过 modify 模型的网络结构和参数，提高检测精度。该方法通过使用检测机器人 capture 的 инфра红图像进行示例，并与手动标注结果进行比较，证明提案的算法可以明显提高不同类型设备的缺陷检测精度。Note: "infrared" is translated as "инфра红" in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="HiH-A-Multi-modal-Hierarchy-in-Hierarchy-Network-for-Unconstrained-Gait-Recognition"><a href="#HiH-A-Multi-modal-Hierarchy-in-Hierarchy-Network-for-Unconstrained-Gait-Recognition" class="headerlink" title="HiH: A Multi-modal Hierarchy in Hierarchy Network for Unconstrained Gait Recognition"></a>HiH: A Multi-modal Hierarchy in Hierarchy Network for Unconstrained Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11210">http://arxiv.org/abs/2311.11210</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Wang, Yinchi Ma, Peng Luan, Wei Yao, Congcong Li, Bo Liu</li>
<li>for: 本研究旨在提高不受控制的环境下的步态识别精度，通过融合多模态信息。</li>
<li>methods: 本研究使用了一种多模态层次网络（HiH），将Silhouette和pose序列融合进行Robust步态识别。HiH网络包括主支路和 auxillary支路两部分，主支路使用层次步态分解（HGD）模块进行深度 wise和内部模块层次检查普通步态模式。auxillary支路使用改进的空间和时间检索模块（DSE和DTA）来丰富步态分析的空间和时间方面。</li>
<li>results: EXTENSIVE evaluations across diverse indoor and outdoor datasets demonstrate HiH’s state-of-the-art performance, affirming a well-balanced trade-off between accuracy and efficiency.<details>
<summary>Abstract</summary>
Gait recognition has achieved promising advances in controlled settings, yet it significantly struggles in unconstrained environments due to challenges such as view changes, occlusions, and varying walking speeds. Additionally, efforts to fuse multiple modalities often face limited improvements because of cross-modality incompatibility, particularly in outdoor scenarios. To address these issues, we present a multi-modal Hierarchy in Hierarchy network (HiH) that integrates silhouette and pose sequences for robust gait recognition. HiH features a main branch that utilizes Hierarchical Gait Decomposer (HGD) modules for depth-wise and intra-module hierarchical examination of general gait patterns from silhouette data. This approach captures motion hierarchies from overall body dynamics to detailed limb movements, facilitating the representation of gait attributes across multiple spatial resolutions. Complementing this, an auxiliary branch, based on 2D joint sequences, enriches the spatial and temporal aspects of gait analysis. It employs a Deformable Spatial Enhancement (DSE) module for pose-guided spatial attention and a Deformable Temporal Alignment (DTA) module for aligning motion dynamics through learned temporal offsets. Extensive evaluations across diverse indoor and outdoor datasets demonstrate HiH's state-of-the-art performance, affirming a well-balanced trade-off between accuracy and efficiency.
</details>
<details>
<summary>摘要</summary>
遥感人体行走识别技术在控制环境下已经取得了有前途的进步，但在无法控制的环境中却面临着视野变化、遮挡以及不同的走速等挑战。此外，融合多Modalities的尝试通常会面临限制的改进，特别是在开放场景下。为解决这些问题，我们提出了一种多Modalities层次网络（HiH），它将拼接Silhouette和pose序列来实现Robust遥感人体行走识别。HiH网络包括主支路，该支路使用层次式遥感走动分解（HGD）模块进行深度和内部模块层次的总走动模式的检查，从而捕捉人体动态的运动层次。此外，一个辅助支路基于2D JOINT序列，它会提高空间和时间方面的步伐分析，并使用学习时间偏移来对步伐动态进行对齐。广泛的实验证明HiH网络在多种室内和室外数据集上达到了当前最佳性能，证明了一个良好的平衡点 между精度和效率。
</details></li>
</ul>
<hr>
<h2 id="3D-Guidewire-Shape-Reconstruction-from-Monoplane-Fluoroscopic-Images"><a href="#3D-Guidewire-Shape-Reconstruction-from-Monoplane-Fluoroscopic-Images" class="headerlink" title="3D Guidewire Shape Reconstruction from Monoplane Fluoroscopic Images"></a>3D Guidewire Shape Reconstruction from Monoplane Fluoroscopic Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11209">http://arxiv.org/abs/2311.11209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tudor Jianu, Baoru Huang, Pierre Berthet-Rayne, Sebastiano Fichera, Anh Nguyen</li>
<li>for: 用于诊断和治疗内分泌疾病的内血管导航，主要基于fluoroscopic图像，受限于感知反馈。</li>
<li>methods: 我们提出了一种新的方法，利用CathSim（state-of-the-art内血管模拟器）和3D fluoroscopy guidewire reconstruction network (3D-FGRN)来重建3D导wire。</li>
<li>results: 我们的3D-FGRN可以在模拟单平面fluoroscopic图像上达到与传统三角形 reconstruction相同的水平，并且在实验中表明了该方法的效率。<details>
<summary>Abstract</summary>
Endovascular navigation, essential for diagnosing and treating endovascular diseases, predominantly hinges on fluoroscopic images due to the constraints in sensory feedback. Current shape reconstruction techniques for endovascular intervention often rely on either a priori information or specialized equipment, potentially subjecting patients to heightened radiation exposure. While deep learning holds potential, it typically demands extensive data. In this paper, we propose a new method to reconstruct the 3D guidewire by utilizing CathSim, a state-of-the-art endovascular simulator, and a 3D Fluoroscopy Guidewire Reconstruction Network (3D-FGRN). Our 3D-FGRN delivers results on par with conventional triangulation from simulated monoplane fluoroscopic images. Our experiments accentuate the efficiency of the proposed network, demonstrating it as a promising alternative to traditional methods.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>内窥endovascular导航，对于诊断和治疗endovascular疾病至关重要，主要靠射频影像来确定。现有的形态重建技术 oftentimes rely on either prior knowledge or specialized equipment, potentially exposing patients to increased radiation. While deep learning has potential, it typically requires extensive data. In this paper, we propose a new method to reconstruct the 3D guidewire by utilizing CathSim, a state-of-the-art endovascular simulator, and a 3D Fluoroscopy Guidewire Reconstruction Network (3D-FGRN). Our 3D-FGRN delivers results on par with conventional triangulation from simulated monoplane fluoroscopic images. Our experiments emphasize the efficiency of the proposed network, demonstrating it as a promising alternative to traditional methods.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="LogicNet-A-Logical-Consistency-Embedded-Face-Attribute-Learning-Network"><a href="#LogicNet-A-Logical-Consistency-Embedded-Face-Attribute-Learning-Network" class="headerlink" title="LogicNet: A Logical Consistency Embedded Face Attribute Learning Network"></a>LogicNet: A Logical Consistency Embedded Face Attribute Learning Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11208">http://arxiv.org/abs/2311.11208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiyu Wu, Sicong Tian, Huayu Li, Kevin W. Bowyer</li>
<li>for: 提高多属性分类中的逻辑一致性，解决数据逻辑不一致性问题。</li>
<li>methods: 提出了两个挑战，一是如何使用逻辑一致性检查的数据进行训练，二是如何使用不进行逻辑一致性检查的数据进行训练。提出了一种名为LogicNet的对抗训练框架，可以学习多属性之间的逻辑关系。</li>
<li>results: LogicNet在FH37K、FH41K和CelebA-logic等三个数据集上的准确率比下一个最佳方法高出23.05%、9.96%和1.71%。在实际应用中，我们的方法可以将失败案件数减少超过50% compared to other methods。<details>
<summary>Abstract</summary>
Ensuring logical consistency in predictions is a crucial yet overlooked aspect in multi-attribute classification. We explore the potential reasons for this oversight and introduce two pressing challenges to the field: 1) How can we ensure that a model, when trained with data checked for logical consistency, yields predictions that are logically consistent? 2) How can we achieve the same with data that hasn't undergone logical consistency checks? Minimizing manual effort is also essential for enhancing automation. To address these challenges, we introduce two datasets, FH41K and CelebA-logic, and propose LogicNet, an adversarial training framework that learns the logical relationships between attributes. Accuracy of LogicNet surpasses that of the next-best approach by 23.05%, 9.96%, and 1.71% on FH37K, FH41K, and CelebA-logic, respectively. In real-world case analysis, our approach can achieve a reduction of more than 50% in the average number of failed cases compared to other methods.
</details>
<details>
<summary>摘要</summary>
保证多属性分类中的逻辑一致性是一项重要但被忽略的方面。我们探讨了可能导致这种忽略的原因，并提出了两个急需解决的挑战：1）如何使用含有逻辑一致性检查的数据训练模型，以便其生成的预测结果具有逻辑一致性？2）如何实现这一点不进行逻辑一致性检查的数据？减少人工努力也是提高自动化的关键。为解决这些挑战，我们介绍了两个数据集（FH37K和CelebA-logic），并提出了逻辑网络（LogicNet），它是一种基于对属性之间的逻辑关系进行反向工程学习的敌方训练框架。在FH37K、FH41K和CelebA-logic三个数据集上，逻辑网络的准确率与最佳方法相比高出23.05%、9.96%和1.71%。在实际案例分析中，我们的方法可以将失败案例的平均数量降低至其他方法的50%以上。
</details></li>
</ul>
<hr>
<h2 id="Shape-Sensitive-Loss-for-Catheter-and-Guidewire-Segmentation"><a href="#Shape-Sensitive-Loss-for-Catheter-and-Guidewire-Segmentation" class="headerlink" title="Shape-Sensitive Loss for Catheter and Guidewire Segmentation"></a>Shape-Sensitive Loss for Catheter and Guidewire Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11205">http://arxiv.org/abs/2311.11205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chayun Kongtongvattana, Baoru Huang, Jingxuan Kang, Hoan Nguyen, Olajide Olufemi, Anh Nguyen</li>
<li>for: 这种Shape-sensitive损失函数用于提高X射线图像中的导管和导线分割精度，并在大规模图像集上实现新的状态测试纪录。</li>
<li>methods: 我们使用视transformer网络，并将网络生成的预测和相关的实际值转换成签名距离图，以便任何网络都可以专注于重要的边界而不仅仅是总体外形。</li>
<li>results: 我们的方法可以提供高维特征向量，这些向量包含图像中关键特征，并通过计算cosine相似性来了解图像之间的相似性，这超出了传统的 overlap-based 度量。<details>
<summary>Abstract</summary>
We introduce a shape-sensitive loss function for catheter and guidewire segmentation and utilize it in a vision transformer network to establish a new state-of-the-art result on a large-scale X-ray images dataset. We transform network-derived predictions and their corresponding ground truths into signed distance maps, thereby enabling any networks to concentrate on the essential boundaries rather than merely the overall contours. These SDMs are subjected to the vision transformer, efficiently producing high-dimensional feature vectors encapsulating critical image attributes. By computing the cosine similarity between these feature vectors, we gain a nuanced understanding of image similarity that goes beyond the limitations of traditional overlap-based measures. The advantages of our approach are manifold, ranging from scale and translation invariance to superior detection of subtle differences, thus ensuring precise localization and delineation of the medical instruments within the images. Comprehensive quantitative and qualitative analyses substantiate the significant enhancement in performance over existing baselines, demonstrating the promise held by our new shape-sensitive loss function for improving catheter and guidewire segmentation.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种形态敏感损失函数，用于针和导wire分割，并在视transformer网络中应用以实现大规模X射线图像集合上的新状态码。我们将网络预测和相应的实际值转换成签名距离图，以便任何网络都可以关注重要的边界而不仅仅是总轮廓。这些SDMs被视transformer进行处理，生成高维特征向量，包含图像重要特征。通过计算这些特征向量之间的 косинуsimilarity，我们可以获得超出传统重叠度基准的图像相似性理解。我们的方法具有许多优点，包括缩放和平移不变性，以及更好地检测细微差异，从而确保针和导wire在图像中的精确定位和分割。我们的全面量化和质量分析证明了我们新的形态敏感损失函数在现有基准上显著提高了性能，证明了我们的方法在针和导wire分割方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Versus-Supervised-Training-for-Segmentation-of-Organoid-Images"><a href="#Self-Supervised-Versus-Supervised-Training-for-Segmentation-of-Organoid-Images" class="headerlink" title="Self-Supervised Versus Supervised Training for Segmentation of Organoid Images"></a>Self-Supervised Versus Supervised Training for Segmentation of Organoid Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2311.11198">http://arxiv.org/abs/2311.11198</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asmaa Haja, Eric Brouwer, Lambert Schomaker</li>
<li>for: 本研究旨在提高数字顺序镜的标注数据集，以便使用深度学习算法进行有效利用。</li>
<li>methods: 本研究使用了自动学习（SSL）技术，通过在类似主任务下学习内在特征，不需要标注数据。首先使用ResNet50 U-Net将图像恢复到原始图像，然后将 weights 传递到另一个 U-Net 模型，用于图像分割。</li>
<li>results: 结果表明，使用 25% 像素截割或图像模糊增强技术可以比其他增强技术更好地进行自我超视投入，并且在使用 IoU 损失函数时，自我超视学习方法可以在只使用 114 个图像时对主任务进行更好的预测，并且在使用更大的数据集（1,000 个图像）时也可以保持更高的稳定性。<details>
<summary>Abstract</summary>
The process of annotating relevant data in the field of digital microscopy can be both time-consuming and especially expensive due to the required technical skills and human-expert knowledge. Consequently, large amounts of microscopic image data sets remain unlabeled, preventing their effective exploitation using deep-learning algorithms. In recent years it has been shown that a lot of relevant information can be drawn from unlabeled data. Self-supervised learning (SSL) is a promising solution based on learning intrinsic features under a pretext task that is similar to the main task without requiring labels. The trained result is transferred to the main task - image segmentation in our case. A ResNet50 U-Net was first trained to restore images of liver progenitor organoids from augmented images using the Structural Similarity Index Metric (SSIM), alone, and using SSIM combined with L1 loss. Both the encoder and decoder were trained in tandem. The weights were transferred to another U-Net model designed for segmentation with frozen encoder weights, using Binary Cross Entropy, Dice, and Intersection over Union (IoU) losses. For comparison, we used the same U-Net architecture to train two supervised models, one utilizing the ResNet50 encoder as well as a simple CNN. Results showed that self-supervised learning models using a 25\% pixel drop or image blurring augmentation performed better than the other augmentation techniques using the IoU loss. When trained on only 114 images for the main task, the self-supervised learning approach outperforms the supervised method achieving an F1-score of 0.85, with higher stability, in contrast to an F1=0.78 scored by the supervised method. Furthermore, when trained with larger data sets (1,000 images), self-supervised learning is still able to perform better, achieving an F1-score of 0.92, contrasting to a score of 0.85 for the supervised method.
</details>
<details>
<summary>摘要</summary>
“在数字微镜像领域中标注相关数据的过程可能会非常耗时和成本高，因为需要特殊的技术技能和人类专业知识。这导致了大量微镜像数据集未被标注，因此无法有效利用深度学习算法。在过去几年中，人们发现了一些有用的信息可以从无标注数据中提取出来。基于自我监督学习（SSL）的方法是一种可能的解决方案，它通过在类似主任务下学习内在特征，而不需要标签。训练结果可以转移到主任务——图像分割。我们使用了一个ResNet50 U-Net模型，首先在使用SSIM指标和L1损失进行训练下来，然后将Encoder层的参数冻结，并使用 Binary Cross Entropy、Dice和Intersection over Union（IoU）损失函数进行训练。为比较，我们使用了同样的U-Net架构来训练两个监督学习模型，一个使用ResNet50 Encoder以及一个简单的CNN。结果表明，使用25%像素截断或图像模糊增强算法的自我监督学习模型在IoU损失函数下表现较好，并且当训练于主任务时，自我监督学习方法可以超过监督学习方法，其中F1分数为0.85，而监督学习方法的F1分数为0.78。此外，当训练于更大的数据集（1,000张图像）时，自我监督学习方法仍然可以表现更好，其F1分数为0.92，而监督学习方法的F1分数为0.85。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/11/19/cs.CV_2023_11_19/" data-id="clp89dofw00nei7889htv0np9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
